{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f5bd94-74fb-4588-b47b-273035eb2345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6823f8c1-608a-4865-aeca-1458b0610761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4335c011-7512-4fde-bf66-16bdb5591fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f015e48acc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4245931c-72c7-470f-9e6e-2f6de6e1c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_display(torch_img):\n",
    "    clean = torch_img.detach().cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c25d90-1bdd-46b4-ae86-a6e8170070d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain = EnhancedAgentBrain()\n",
    "brain.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "\n",
    "brain.load_state_dict(torch.load('brain_checkpoints/enhanced_brain_first_training_batch10000.pth', weights_only=True, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6a4389-e113-4dc7-bf96-7538570644e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optimizer = optim.Adam(brain.parameters(), lr=0.00001, eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c522ad35-e749-4b70-a282-f4489bd4069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should possibly also include mem_enc? Should just be gen_optimizer? \n",
    "text_optimizer = optim.Adam(list(brain.text_enc.parameters()) + list(brain.text_dec.parameters()), lr=0.00001, eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dedeb05-aeef-4cc0-8c32-41e4c74f92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful to randomize the order in which the tasks are trained\n",
    "class ReusableBuffer:\n",
    "    def __init__(self, L):\n",
    "        self.L = L\n",
    "        self.inds = list(range(len(L)))\n",
    "\n",
    "    def draw(self, ind):\n",
    "        return self.L[ind]\n",
    "\n",
    "    def random_draw(self):\n",
    "        ind_ind = random.randint(0, len(self.inds)-1)\n",
    "        ind = self.inds[ind_ind]\n",
    "        if ind_ind == (len(self.inds) - 1):\n",
    "            self.inds = self.inds[:-1]\n",
    "        else:\n",
    "            self.inds = self.inds[:ind_ind] + self.inds[ind_ind + 1:]\n",
    "        if len(self.inds) == 0:\n",
    "            self.inds = list(range(len(self.L)))\n",
    "        return self.L[ind], ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8113bf0-e27a-4964-b993-1511284e05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for first task (and really anywhere I want to not reset between tasks)\n",
    "# make sure the batch size matches\n",
    "rb = ReusableBuffer([(arrow_task_batch, gen_optimizer, 16), \\\n",
    "                     (qa_task_batch, text_optimizer, 16)]) # add further functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d0bf3cd-1207-4726-8983-3708c97ba125",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fcade85-fe40-4a68-b137-4c94c737614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_mins = [1000.0, 1000.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea6fc04a-8056-41bd-85c0-7e60970a13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_losses = [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88167a4b-dd8d-43e6-b4ae-8f77c51adaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d1940-ba13-4da2-bb5f-b1af6d45d7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atbolsh/anaconda3/envs/player/lib/python3.12/site-packages/torch/_tensor.py:955: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, task 1, task batch_num 0\n",
      "\n",
      "batch 1, task 0, task batch_num 0\n",
      "\n",
      "batch 2, task 0, task batch_num 1\n",
      "\n",
      "batch 3, task 1, task batch_num 1\n",
      "\n",
      "batch 4, task 1, task batch_num 2\n",
      "\n",
      "batch 5, task 0, task batch_num 2\n",
      "\n",
      "batch 6, task 1, task batch_num 3\n",
      "\n",
      "batch 7, task 0, task batch_num 3\n",
      "\n",
      "batch 8, task 1, task batch_num 4\n",
      "\n",
      "batch 9, task 0, task batch_num 4\n",
      "\n",
      "Total loss: 22.553747177124023:\n",
      "5.90061616897583 control,\n",
      "4.118896007537842 lrg,\n",
      "4.552083492279053 udg,\n",
      "3.9597909450531006 lra,\n",
      "4.022360324859619 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 30.17000051498413\n",
      "\n",
      "Total loss: 0.49829792976379395; that's 0.24864144623279572 task and 0.24760109186172485 recon and 10.277008056640625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.8703511562943459\n",
      "\n",
      "Total loss: 12.683548927307129:\n",
      "5.499452590942383 control,\n",
      "1.8017323017120361 lrg,\n",
      "2.1801743507385254 udg,\n",
      "1.4238511323928833 lra,\n",
      "1.7783384323120117 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 17.281756172180177\n",
      "\n",
      "Total loss: 0.4866833984851837; that's 0.2335004210472107 task and 0.25154611468315125 recon and 8.184311866760254 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.4909328338503838\n",
      "\n",
      "Total loss: 0.5050315260887146; that's 0.25817567110061646 task and 0.2452324479818344 recon and 8.116829872131348 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.45928038090467455\n",
      "\n",
      "Total loss: 10.138731956481934:\n",
      "6.377170085906982 control,\n",
      "0.8965486288070679 lrg,\n",
      "1.2501091957092285 udg,\n",
      "0.7482510805130005 lra,\n",
      "0.8666523694992065 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 11.34691481590271\n",
      "\n",
      "Total loss: 8.259605407714844:\n",
      "5.567933559417725 control,\n",
      "0.6878618597984314 lrg,\n",
      "0.9119501113891602 udg,\n",
      "0.5588011741638184 lra,\n",
      "0.5330588817596436 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 8.996881170272827\n",
      "\n",
      "Total loss: 0.4508500397205353; that's 0.22579239308834076 task and 0.22372306883335114 recon and 6.672938823699951 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.4630358603596687\n",
      "\n",
      "Total loss: 0.4482705891132355; that's 0.2247714251279831 task and 0.222275972366333 recon and 6.115939617156982 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.4573390254378319\n",
      "\n",
      "Total loss: 7.703762054443359:\n",
      "5.3517889976501465 control,\n",
      "0.6420815587043762 lrg,\n",
      "0.7585561871528625 udg,\n",
      "0.45886966586112976 lra,\n",
      "0.4924653172492981 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 8.196894960403442\n",
      "\n",
      "Total loss: 7.238184928894043:\n",
      "5.184377670288086 control,\n",
      "0.5429797768592834 lrg,\n",
      "0.6263812780380249 udg,\n",
      "0.4494229555130005 lra,\n",
      "0.43502330780029297 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.797910327911377\n",
      "\n",
      "Total loss: 0.14056381583213806; that's 0.07240144908428192 task and 0.06698562204837799 recon and 5.883692741394043 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.2966720761358738\n",
      "\n",
      "Total loss: 0.12789446115493774; that's 0.05556480959057808 task and 0.07094857841730118 recon and 6.90538215637207 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.12878637336194515\n",
      "\n",
      "Total loss: 8.260026931762695:\n",
      "6.334689617156982 control,\n",
      "0.5156065225601196 lrg,\n",
      "0.5645286440849304 udg,\n",
      "0.40730810165405273 lra,\n",
      "0.43789416551589966 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.573080921173096\n",
      "\n",
      "Total loss: 0.10727670043706894; that's 0.05472128465771675 task and 0.051231782883405685 recon and 6.618162155151367 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.11430917367339134\n",
      "\n",
      "Total loss: 7.947452068328857:\n",
      "6.059776782989502 control,\n",
      "0.5091887712478638 lrg,\n",
      "0.5480396747589111 udg,\n",
      "0.3993813991546631 lra,\n",
      "0.43106505274772644 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.61575553894043\n",
      "\n",
      "Total loss: 7.986446380615234:\n",
      "6.184212684631348 control,\n",
      "0.4784988760948181 lrg,\n",
      "0.5146611928939819 udg,\n",
      "0.40563100576400757 lra,\n",
      "0.40344223380088806 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.62965265750885\n",
      "\n",
      "Total loss: 0.10455796867609024; that's 0.05311354622244835 task and 0.05011395364999771 recon and 6.652359962463379 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.10851532571017743\n",
      "\n",
      "Total loss: 0.10899094492197037; that's 0.05262337252497673 task and 0.05526306480169296 recon and 5.522573947906494 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.10570700779557228\n",
      "\n",
      "Total loss: 6.844134330749512:\n",
      "5.139870643615723 control,\n",
      "0.4816208779811859 lrg,\n",
      "0.49552997946739197 udg,\n",
      "0.3638569116592407 lra,\n",
      "0.36325615644454956 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.104808082580567\n",
      "\n",
      "Total loss: 7.111235618591309:\n",
      "5.305211544036865 control,\n",
      "0.5101438164710999 lrg,\n",
      "0.5302289724349976 udg,\n",
      "0.3932132422924042 lra,\n",
      "0.3724377155303955 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.559808106422424\n",
      "\n",
      "Total loss: 0.1067299172282219; that's 0.05641883239150047 task and 0.04916175454854965 recon and 5.7466607093811035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.10451312892138959\n",
      "\n",
      "Total loss: 0.10200505703687668; that's 0.051902614533901215 task and 0.048872895538806915 recon and 6.14775276184082 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.10330689691007137\n",
      "\n",
      "Total loss: 7.459380626678467:\n",
      "5.696165561676025 control,\n",
      "0.4541223347187042 lrg,\n",
      "0.5616806149482727 udg,\n",
      "0.3707629144191742 lra,\n",
      "0.3766487240791321 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.582545948028565\n",
      "\n",
      "Total loss: 6.877572059631348:\n",
      "5.138911247253418 control,\n",
      "0.48627349734306335 lrg,\n",
      "0.5193048715591431 udg,\n",
      "0.3586856722831726 lra,\n",
      "0.37439748644828796 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.290009422302246\n",
      "\n",
      "Total loss: 0.10128821432590485; that's 0.052153829485177994 task and 0.0480225495994091 recon and 5.559161186218262 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.10226003259420395\n",
      "\n",
      "Total loss: 0.09875310212373734; that's 0.05054677650332451 task and 0.04719483107328415 recon and 5.057478904724121 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.1011459244787693\n",
      "\n",
      "Total loss: 6.205635070800781:\n",
      "4.43958854675293 control,\n",
      "0.4942784309387207 lrg,\n",
      "0.5211514830589294 udg,\n",
      "0.3666853904724121 lra,\n",
      "0.3839311897754669 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.046588563919068\n",
      "\n",
      "Total loss: 0.09916278719902039; that's 0.05082074552774429 task and 0.04726122319698334 recon and 5.404087543487549 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09985888689756393\n",
      "\n",
      "Total loss: 6.596215724945068:\n",
      "4.916755676269531 control,\n",
      "0.44850319623947144 lrg,\n",
      "0.48485660552978516 udg,\n",
      "0.3734447956085205 lra,\n",
      "0.3726555407047272 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.078212080001831\n",
      "\n",
      "Total loss: 7.111203193664551:\n",
      "5.353342533111572 control,\n",
      "0.4837398827075958 lrg,\n",
      "0.4815850555896759 udg,\n",
      "0.39650657773017883 lra,\n",
      "0.39602890610694885 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.939341831207275\n",
      "\n",
      "Total loss: 0.09704063087701797; that's 0.049305301159620285 task and 0.046583205461502075 recon and 5.760592460632324 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09846400707960129\n",
      "\n",
      "Total loss: 0.09572867304086685; that's 0.0490487739443779 task and 0.04557628184556961 recon and 5.518070697784424 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09703094750642777\n",
      "\n",
      "Total loss: 6.808216094970703:\n",
      "5.095158100128174 control,\n",
      "0.47156286239624023 lrg,\n",
      "0.5035003423690796 udg,\n",
      "0.37453269958496094 lra,\n",
      "0.3634618818759918 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.672108812332153\n",
      "\n",
      "Total loss: 0.09444553405046463; that's 0.04820885881781578 task and 0.045161500573158264 recon and 5.375839710235596 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09570456385612487\n",
      "\n",
      "Total loss: 6.712753772735596:\n",
      "5.0000200271606445 control,\n",
      "0.45942574739456177 lrg,\n",
      "0.5292031168937683 udg,\n",
      "0.3585106134414673 lra,\n",
      "0.3655945956707001 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.931922430992127\n",
      "\n",
      "Total loss: 0.09524263441562653; that's 0.04751106724143028 task and 0.04666387289762497 recon and 5.338478088378906 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09449861317873001\n",
      "\n",
      "Total loss: 6.4488091468811035:\n",
      "4.876107692718506 control,\n",
      "0.4259452223777771 lrg,\n",
      "0.4648319184780121 udg,\n",
      "0.3389720618724823 lra,\n",
      "0.3429524302482605 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.90749258518219\n",
      "\n",
      "Total loss: 7.260396480560303:\n",
      "5.514941692352295 control,\n",
      "0.49512356519699097 lrg,\n",
      "0.5419334769248962 udg,\n",
      "0.37261274456977844 lra,\n",
      "0.33578479290008545 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.760802631378174\n",
      "\n",
      "Total loss: 0.09223616868257523; that's 0.04808464273810387 task and 0.04299401864409447 recon and 5.787520408630371 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09295399330556392\n",
      "\n",
      "Total loss: 0.09009139239788055; that's 0.046218980103731155 task and 0.042866017669439316 recon and 5.031982898712158 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09086988471448422\n",
      "\n",
      "Total loss: 6.3641886711120605:\n",
      "4.701626777648926 control,\n",
      "0.46620866656303406 lrg,\n",
      "0.48636680841445923 udg,\n",
      "0.36441338062286377 lra,\n",
      "0.3455735445022583 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.804553151130676\n",
      "\n",
      "Total loss: 6.425493240356445:\n",
      "4.7165913581848145 control,\n",
      "0.4255281090736389 lrg,\n",
      "0.5279452800750732 udg,\n",
      "0.3933936655521393 lra,\n",
      "0.3620348572731018 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.965853018760681\n",
      "\n",
      "Total loss: 0.08803786337375641; that's 0.04477064684033394 task and 0.04225262999534607 recon and 5.072945594787598 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.08884520284831524\n",
      "\n",
      "Total loss: 0.08544982969760895; that's 0.04393240064382553 task and 0.04021171107888222 recon and 6.528567790985107 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.08667100191116334\n",
      "\n",
      "Total loss: 7.78481388092041:\n",
      "6.16501522064209 control,\n",
      "0.42689117789268494 lrg,\n",
      "0.46227335929870605 udg,\n",
      "0.36446139216423035 lra,\n",
      "0.36617234349250793 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.329177350997925\n",
      "\n",
      "Total loss: 0.08031895756721497; that's 0.04129956662654877 task and 0.038163814693689346 recon and 4.27790641784668 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0829025387018919\n",
      "\n",
      "Total loss: 5.587920188903809:\n",
      "3.939450979232788 control,\n",
      "0.41275957226753235 lrg,\n",
      "0.4548611640930176 udg,\n",
      "0.34644603729248047 lra,\n",
      "0.43440255522727966 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.852564134597778\n",
      "\n",
      "Total loss: 5.827221393585205:\n",
      "4.147067546844482 control,\n",
      "0.4770071804523468 lrg,\n",
      "0.48907509446144104 udg,\n",
      "0.3635139763355255 lra,\n",
      "0.3505573272705078 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.270781779289246\n",
      "\n",
      "Total loss: 0.07604721188545227; that's 0.039095886051654816 task and 0.036068402230739594 recon and 4.414602756500244 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0789516232907772\n",
      "\n",
      "Total loss: 6.651906967163086:\n",
      "4.917477130889893 control,\n",
      "0.452153742313385 lrg,\n",
      "0.5201489329338074 udg,\n",
      "0.3849092125892639 lra,\n",
      "0.37721800804138184 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.575291128158569\n",
      "\n",
      "Total loss: 0.07362200319766998; that's 0.03898032382130623 task and 0.03359973430633545 recon and 5.209747314453125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.07436780847609042\n",
      "\n",
      "Total loss: 6.802957534790039:\n",
      "5.13054084777832 control,\n",
      "0.42131635546684265 lrg,\n",
      "0.4776765704154968 udg,\n",
      "0.3781578540802002 lra,\n",
      "0.39526674151420593 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.535423903465271\n",
      "\n",
      "Total loss: 0.06563199311494827; that's 0.0336175374686718 task and 0.03092959150671959 recon and 5.424316883087158 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.06912756808102132\n",
      "\n",
      "Total loss: 7.698009490966797:\n",
      "6.057917594909668 control,\n",
      "0.45232832431793213 lrg,\n",
      "0.46828940510749817 udg,\n",
      "0.37365415692329407 lra,\n",
      "0.3458201587200165 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.60124370098114\n",
      "\n",
      "Total loss: 0.06110979616641998; that's 0.031580060720443726 task and 0.02824024297297001 recon and 6.4474687576293945 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0639059654995799\n",
      "\n",
      "Total loss: 6.474217891693115:\n",
      "4.75274658203125 control,\n",
      "0.4500091075897217 lrg,\n",
      "0.5629670023918152 udg,\n",
      "0.34700509905815125 lra,\n",
      "0.3614901900291443 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.027767028808594\n",
      "\n",
      "Total loss: 0.0563834123313427; that's 0.0299422238022089 task and 0.02542765624821186 recon and 5.067654132843018 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.058511741533875464\n",
      "\n",
      "Total loss: 0.050044044852256775; that's 0.025676026940345764 task and 0.023316914215683937 recon and 5.255526542663574 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.05362459346652031\n",
      "\n",
      "Total loss: 6.560187816619873:\n",
      "4.910270690917969 control,\n",
      "0.4461429715156555 lrg,\n",
      "0.49664708971977234 udg,\n",
      "0.3564354181289673 lra,\n",
      "0.3506920039653778 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.8866122484207155\n",
      "\n",
      "Total loss: 6.127711296081543:\n",
      "4.532339572906494 control,\n",
      "0.430046945810318 lrg,\n",
      "0.46937260031700134 udg,\n",
      "0.3469538986682892 lra,\n",
      "0.34899789094924927 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.808589148521423\n",
      "\n",
      "Total loss: 0.04648758843541145; that's 0.024393519386649132 task and 0.021128777414560318 recon and 4.8264689445495605 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.04884733136743307\n",
      "\n",
      "Total loss: 6.06424617767334:\n",
      "4.385249137878418 control,\n",
      "0.44038721919059753 lrg,\n",
      "0.48437055945396423 udg,\n",
      "0.36261141300201416 lra,\n",
      "0.3916279077529907 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.3652088069915775\n",
      "\n",
      "Total loss: 0.04512016475200653; that's 0.024965284392237663 task and 0.019190629944205284 recon and 4.821249961853027 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.04522345624864101\n",
      "\n",
      "Total loss: 0.038943205028772354; that's 0.020244572311639786 task and 0.01772463694214821 recon and 4.869973182678223 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.04133363325148821\n",
      "\n",
      "Total loss: 6.196595668792725:\n",
      "4.476412296295166 control,\n",
      "0.49987226724624634 lrg,\n",
      "0.4922613203525543 udg,\n",
      "0.370475709438324 lra,\n",
      "0.35757383704185486 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.891004014015198\n",
      "\n",
      "Total loss: 0.0384819470345974; that's 0.02088572084903717 task and 0.016507495194673538 recon and 5.4436540603637695 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.038889867700636384\n",
      "\n",
      "Total loss: 6.736996650695801:\n",
      "5.127436637878418 control,\n",
      "0.4220651686191559 lrg,\n",
      "0.4450581967830658 udg,\n",
      "0.3792000710964203 lra,\n",
      "0.36323633790016174 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.859900331497192\n",
      "\n",
      "Total loss: 0.03442652150988579; that's 0.018245959654450417 task and 0.015170351602137089 recon and 5.051053524017334 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.03650578293949366\n",
      "\n",
      "Total loss: 6.249738693237305:\n",
      "4.63918924331665 control,\n",
      "0.41744011640548706 lrg,\n",
      "0.4895709753036499 udg,\n",
      "0.3290122151374817 lra,\n",
      "0.37452617287635803 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.011431818008423\n",
      "\n",
      "Total loss: 0.03269222751259804; that's 0.017280444502830505 task and 0.014150709845125675 recon and 6.305372714996338 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.03387875191867352\n",
      "\n",
      "Total loss: 7.644423007965088:\n",
      "5.966886520385742 control,\n",
      "0.46559029817581177 lrg,\n",
      "0.4988546371459961 udg,\n",
      "0.37568792700767517 lra,\n",
      "0.33740341663360596 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.908941354751587\n",
      "\n",
      "Total loss: 0.03468366339802742; that's 0.01889283023774624 task and 0.014820750802755356 recon and 4.850423812866211 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.03276608387008309\n",
      "\n",
      "Total loss: 6.219552993774414:\n",
      "4.496963024139404 control,\n",
      "0.42474061250686646 lrg,\n",
      "0.5443011522293091 udg,\n",
      "0.3690635859966278 lra,\n",
      "0.38448482751846313 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.837392091751099\n",
      "\n",
      "Total loss: 0.02922949194908142; that's 0.015372561290860176 task and 0.01282433606684208 recon and 5.162973880767822 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.03215382538735866\n",
      "\n",
      "Total loss: 6.452742099761963:\n",
      "4.759613990783691 control,\n",
      "0.47414928674697876 lrg,\n",
      "0.48591744899749756 udg,\n",
      "0.3674919605255127 lra,\n",
      "0.3655693829059601 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.199408173561096\n",
      "\n",
      "Total loss: 5.715834140777588:\n",
      "4.105673789978027 control,\n",
      "0.438618928194046 lrg,\n",
      "0.48431116342544556 udg,\n",
      "0.3589034378528595 lra,\n",
      "0.3283264935016632 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.75316620349884\n",
      "\n",
      "Total loss: 0.026804883033037186; that's 0.014452232047915459 task and 0.01148674264550209 recon and 4.329542636871338 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.029208789877593518\n",
      "\n",
      "Total loss: 6.050023078918457:\n",
      "4.416409492492676 control,\n",
      "0.44507497549057007 lrg,\n",
      "0.4855511784553528 udg,\n",
      "0.331539124250412 lra,\n",
      "0.37144795060157776 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.4749526691436765\n",
      "\n",
      "Total loss: 0.025980260223150253; that's 0.013550428673624992 task and 0.011483896523714066 recon and 4.729676246643066 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.02751423029229045\n",
      "\n",
      "Total loss: 5.875304222106934:\n",
      "4.234046936035156 control,\n",
      "0.4165800213813782 lrg,\n",
      "0.5003262758255005 udg,\n",
      "0.354327529668808 lra,\n",
      "0.37002313137054443 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.238547258377075\n",
      "\n",
      "Total loss: 0.026347395032644272; that's 0.014379046857357025 task and 0.011051657609641552 recon and 4.5834527015686035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.026319114193320274\n",
      "\n",
      "Total loss: 5.3842573165893555:\n",
      "3.7971014976501465 control,\n",
      "0.4036791920661926 lrg,\n",
      "0.4828704595565796 udg,\n",
      "0.3545459806919098 lra,\n",
      "0.34605976939201355 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.079243383407593\n",
      "\n",
      "Total loss: 0.02404206246137619; that's 0.013044068589806557 task and 0.010195670649409294 recon and 4.011612892150879 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.02539775464683771\n",
      "\n",
      "Total loss: 0.028678109869360924; that's 0.015921106562018394 task and 0.011848238296806812 recon and 4.543819427490234 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.024838567413389682\n",
      "\n",
      "Total loss: 5.8854289054870605:\n",
      "4.219790458679199 control,\n",
      "0.4282551109790802 lrg,\n",
      "0.5099121928215027 udg,\n",
      "0.3429698348045349 lra,\n",
      "0.3845016658306122 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.139909543991089\n",
      "\n",
      "Total loss: 0.02250455878674984; that's 0.012309035286307335 task and 0.009253712370991707 recon and 4.7090582847595215 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.025103680323809385\n",
      "\n",
      "Total loss: 6.014991760253906:\n",
      "4.357061386108398 control,\n",
      "0.4776883125305176 lrg,\n",
      "0.4580276906490326 udg,\n",
      "0.37062081694602966 lra,\n",
      "0.35159361362457275 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.9434147596359255\n",
      "\n",
      "Total loss: 5.644326686859131:\n",
      "4.041412830352783 control,\n",
      "0.44947531819343567 lrg,\n",
      "0.45657265186309814 udg,\n",
      "0.37162160873413086 lra,\n",
      "0.325244277715683 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.686218056678772\n",
      "\n",
      "Total loss: 0.021417036652565002; that's 0.011712796986103058 task and 0.008842658251523972 recon and 4.307906627655029 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.02240136291831732\n",
      "\n",
      "Total loss: 5.907614707946777:\n",
      "4.267621040344238 control,\n",
      "0.45644402503967285 lrg,\n",
      "0.48104628920555115 udg,\n",
      "0.35306188464164734 lra,\n",
      "0.3494420647621155 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.75020504951477\n",
      "\n",
      "Total loss: 0.02241208776831627; that's 0.012322399765253067 task and 0.009175309911370277 recon and 4.57189416885376 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.02179698260501027\n",
      "\n",
      "Total loss: 6.3439435958862305:\n",
      "4.7137041091918945 control,\n",
      "0.4407041370868683 lrg,\n",
      "0.46078088879585266 udg,\n",
      "0.34749636054039 lra,\n",
      "0.38125768303871155 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.740206089019775\n",
      "\n",
      "Total loss: 0.021145140752196312; that's 0.011957722716033459 task and 0.008178898133337498 recon and 5.042603492736816 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.021199517343193294\n",
      "\n",
      "Total loss: 0.020043285563588142; that's 0.011381616815924644 task and 0.00789905060082674 recon and 3.813081979751587 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.02050580842420459\n",
      "\n",
      "Total loss: 5.073249340057373:\n",
      "3.4453728199005127 control,\n",
      "0.4434524178504944 lrg,\n",
      "0.46435320377349854 udg,\n",
      "0.37084636092185974 lra,\n",
      "0.34922441840171814 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.494744310379028\n",
      "\n",
      "Total loss: 0.02044825628399849; that's 0.010809596627950668 task and 0.008741173893213272 recon and 4.4874267578125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.020073933470994235\n",
      "\n",
      "Total loss: 5.843379497528076:\n",
      "4.101599216461182 control,\n",
      "0.48089462518692017 lrg,\n",
      "0.473962664604187 udg,\n",
      "0.382403165102005 lra,\n",
      "0.40451955795288086 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.869794907569886\n",
      "\n",
      "Total loss: 0.018476732075214386; that's 0.010094266384840012 task and 0.0072595952078700066 recon and 5.614346504211426 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.019506689570844175\n",
      "\n",
      "Total loss: 6.891243934631348:\n",
      "5.337105751037598 control,\n",
      "0.4246673882007599 lrg,\n",
      "0.4524780511856079 udg,\n",
      "0.33204153180122375 lra,\n",
      "0.34495100378990173 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.462767081260681\n",
      "\n",
      "Total loss: 6.516232967376709:\n",
      "4.954948902130127 control,\n",
      "0.38794317841529846 lrg,\n",
      "0.4867371618747711 udg,\n",
      "0.3414369225502014 lra,\n",
      "0.3451668620109558 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.661393818855285\n",
      "\n",
      "Total loss: 0.019093530252575874; that's 0.010641387663781643 task and 0.007400814443826675 recon and 5.2566375732421875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.019272414557635783\n",
      "\n",
      "Total loss: 6.626950740814209:\n",
      "5.029616355895996 control,\n",
      "0.42862847447395325 lrg,\n",
      "0.46817389130592346 udg,\n",
      "0.3402823507785797 lra,\n",
      "0.36024972796440125 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.697073454856873\n",
      "\n",
      "Total loss: 0.01804395206272602; that's 0.010011067613959312 task and 0.006968424189835787 recon and 5.322305202484131 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01892356775701046\n",
      "\n",
      "Total loss: 6.521953582763672:\n",
      "4.805526256561279 control,\n",
      "0.5101808905601501 lrg,\n",
      "0.46700242161750793 udg,\n",
      "0.3674332797527313 lra,\n",
      "0.3718108534812927 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.693500370979309\n",
      "\n",
      "Total loss: 0.019341550767421722; that's 0.010132691822946072 task and 0.008187846280634403 recon and 5.105066299438477 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.018497206158936023\n",
      "\n",
      "Total loss: 8.063295364379883:\n",
      "6.472601890563965 control,\n",
      "0.40083885192871094 lrg,\n",
      "0.5146088004112244 udg,\n",
      "0.30711814761161804 lra,\n",
      "0.36812812089920044 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.844834914207459\n",
      "\n",
      "Total loss: 0.017548006027936935; that's 0.00969349592924118 task and 0.006501856260001659 recon and 6.763261318206787 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.018476684968918564\n",
      "\n",
      "Total loss: 7.109743595123291:\n",
      "5.456962585449219 control,\n",
      "0.46110308170318604 lrg,\n",
      "0.4920857548713684 udg,\n",
      "0.34556734561920166 lra,\n",
      "0.3540249764919281 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.610577058792114\n",
      "\n",
      "Total loss: 0.01607268676161766; that's 0.008401235565543175 task and 0.00651650270447135 recon and 5.774744033813477 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.018014576956629752\n",
      "\n",
      "Total loss: 6.966802597045898:\n",
      "5.459688186645508 control,\n",
      "0.3837305009365082 lrg,\n",
      "0.45208680629730225 udg,\n",
      "0.32650917768478394 lra,\n",
      "0.34478822350502014 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.6547426414489745\n",
      "\n",
      "Total loss: 0.01837727427482605; that's 0.010807277634739876 task and 0.006434332113713026 recon and 5.678319931030273 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01776315610855818\n",
      "\n",
      "Total loss: 7.094893455505371:\n",
      "5.444926738739014 control,\n",
      "0.4307169020175934 lrg,\n",
      "0.5010458827018738 udg,\n",
      "0.3528625965118408 lra,\n",
      "0.36534106731414795 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.72474769115448\n",
      "\n",
      "Total loss: 0.01714750938117504; that's 0.009490077383816242 task and 0.006517264060676098 recon and 5.700836181640625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.017689555529505015\n",
      "\n",
      "Total loss: 6.923957347869873:\n",
      "5.393228054046631 control,\n",
      "0.40867117047309875 lrg,\n",
      "0.4194800853729248 udg,\n",
      "0.3358233869075775 lra,\n",
      "0.366754412651062 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.695981101989746\n",
      "\n",
      "Total loss: 0.01749693974852562; that's 0.010384844616055489 task and 0.005973178427666426 recon and 5.694584369659424 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.017283489694818854\n",
      "\n",
      "Total loss: 0.016802562400698662; that's 0.009014018811285496 task and 0.006525898817926645 recon and 6.313225269317627 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01701830042526126\n",
      "\n",
      "Total loss: 7.566057205200195:\n",
      "5.9356184005737305 control,\n",
      "0.4191785454750061 lrg,\n",
      "0.47376275062561035 udg,\n",
      "0.3519921600818634 lra,\n",
      "0.38550540804862976 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.695373964309693\n",
      "\n",
      "Total loss: 0.018144479021430016; that's 0.010003464296460152 task and 0.006953075528144836 recon and 5.939693450927734 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.017357900757342577\n",
      "\n",
      "Total loss: 7.257855415344238:\n",
      "5.640505313873291 control,\n",
      "0.4093409776687622 lrg,\n",
      "0.4871571362018585 udg,\n",
      "0.36441662907600403 lra,\n",
      "0.35643553733825684 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.8648107051849365\n",
      "\n",
      "Total loss: 0.016222894191741943; that's 0.009576075710356236 task and 0.005940062925219536 recon and 3.5337746143341064 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.017235193196684123\n",
      "\n",
      "Total loss: 4.724996089935303:\n",
      "3.163139581680298 control,\n",
      "0.4056461453437805 lrg,\n",
      "0.45505452156066895 udg,\n",
      "0.36642226576805115 lra,\n",
      "0.334733784198761 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.951584711074829\n",
      "\n",
      "Total loss: 5.541937828063965:\n",
      "3.9082367420196533 control,\n",
      "0.4060112237930298 lrg,\n",
      "0.4916623532772064 udg,\n",
      "0.34942781925201416 lra,\n",
      "0.3865995705127716 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.94240562915802\n",
      "\n",
      "Total loss: 0.01703280210494995; that's 0.009027224034070969 task and 0.007170862052589655 recon and 4.173583984375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01644579635001719\n",
      "\n",
      "Total loss: 0.01549314521253109; that's 0.008449207060039043 task and 0.006018193904310465 recon and 5.128720760345459 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016686296602711082\n",
      "\n",
      "Total loss: 6.3822832107543945:\n",
      "4.814033031463623 control,\n",
      "0.4065578579902649 lrg,\n",
      "0.4454330801963806 udg,\n",
      "0.3530019223690033 lra,\n",
      "0.3632569909095764 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.149649028778076\n",
      "\n",
      "Total loss: 6.149625778198242:\n",
      "4.439568042755127 control,\n",
      "0.47486868500709534 lrg,\n",
      "0.48313918709754944 udg,\n",
      "0.3753677010536194 lra,\n",
      "0.3766823410987854 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.97333333492279\n",
      "\n",
      "Total loss: 0.01578742079436779; that's 0.009003566578030586 task and 0.005833821836858988 recon and 4.7501630783081055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016477045789361\n",
      "\n",
      "Total loss: 5.437438011169434:\n",
      "3.8347482681274414 control,\n",
      "0.42358946800231934 lrg,\n",
      "0.44742244482040405 udg,\n",
      "0.3773369789123535 lra,\n",
      "0.3543405830860138 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.746241784095764\n",
      "\n",
      "Total loss: 0.019048627465963364; that's 0.01117656659334898 task and 0.007044239901006222 recon and 4.139101982116699 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016722502363845707\n",
      "\n",
      "Total loss: 5.377495765686035:\n",
      "3.754014730453491 control,\n",
      "0.4459270238876343 lrg,\n",
      "0.46178507804870605 udg,\n",
      "0.35943710803985596 lra,\n",
      "0.3563319742679596 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.720972952842712\n",
      "\n",
      "Total loss: 0.01603533886373043; that's 0.009415436536073685 task and 0.005820701830089092 recon and 3.996005058288574 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016006146781146525\n",
      "\n",
      "Total loss: 5.333067893981934:\n",
      "3.72965931892395 control,\n",
      "0.4609118402004242 lrg,\n",
      "0.447204053401947 udg,\n",
      "0.34093236923217773 lra,\n",
      "0.3543601334095001 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.741014790534973\n",
      "\n",
      "Total loss: 0.017096389085054398; that's 0.009679230861365795 task and 0.006608754396438599 recon and 4.042017459869385 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01688047987408936\n",
      "\n",
      "Total loss: 0.016245568171143532; that's 0.009135434404015541 task and 0.0062836045399308205 recon and 4.132650375366211 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01942861646413803\n",
      "\n",
      "Total loss: 5.485819339752197:\n",
      "3.8602428436279297 control,\n",
      "0.4442444443702698 lrg,\n",
      "0.45649829506874084 udg,\n",
      "0.37159115076065063 lra,\n",
      "0.3532427251338959 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.793305401802063\n",
      "\n",
      "Total loss: 0.014132129028439522; that's 0.008089644834399223 task and 0.005258046556264162 recon and 3.922192096710205 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016043111253529786\n",
      "\n",
      "Total loss: 5.2748847007751465:\n",
      "3.5570309162139893 control,\n",
      "0.4484751224517822 lrg,\n",
      "0.5134768486022949 udg,\n",
      "0.3583438992500305 lra,\n",
      "0.3975578546524048 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.500621700286866\n",
      "\n",
      "Total loss: 5.073206424713135:\n",
      "3.5097856521606445 control,\n",
      "0.38324156403541565 lrg,\n",
      "0.47823286056518555 udg,\n",
      "0.33298739790916443 lra,\n",
      "0.368958979845047 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.702600989341736\n",
      "\n",
      "Total loss: 0.015308808535337448; that's 0.008803279139101505 task and 0.005751296877861023 recon and 3.771162748336792 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015840130327269435\n",
      "\n",
      "Total loss: 0.015349438413977623; that's 0.008836043067276478 task and 0.005699646193534136 recon and 4.068745136260986 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015751943131908773\n",
      "\n",
      "Total loss: 5.384417533874512:\n",
      "3.7440860271453857 control,\n",
      "0.4287552535533905 lrg,\n",
      "0.4891173243522644 udg,\n",
      "0.36435410380363464 lra,\n",
      "0.35810497403144836 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.750196261405945\n",
      "\n",
      "Total loss: 5.750524044036865:\n",
      "4.164050102233887 control,\n",
      "0.4573722779750824 lrg,\n",
      "0.45585599541664124 udg,\n",
      "0.35031354427337646 lra,\n",
      "0.32293203473091125 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.718627371788025\n",
      "\n",
      "Total loss: 0.015885164961218834; that's 0.009167445823550224 task and 0.0058311764150857925 recon and 4.43271017074585 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016280009197071194\n",
      "\n",
      "Total loss: 0.01664045639336109; that's 0.009134795516729355 task and 0.006354283541440964 recon and 5.756889343261719 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015552843706682324\n",
      "\n",
      "Total loss: 6.95676326751709:\n",
      "5.419435024261475 control,\n",
      "0.4474301040172577 lrg,\n",
      "0.4220811724662781 udg,\n",
      "0.3417479991912842 lra,\n",
      "0.3260689079761505 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.8685321569442745\n",
      "\n",
      "Total loss: 0.01377763319760561; that's 0.007808406371623278 task and 0.00508979381993413 recon and 4.3971662521362305 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015575238987803459\n",
      "\n",
      "Total loss: 5.714729309082031:\n",
      "4.0435028076171875 control,\n",
      "0.4694315493106842 lrg,\n",
      "0.5161448121070862 udg,\n",
      "0.33560216426849365 lra,\n",
      "0.3500482738018036 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.978818373680115\n",
      "\n",
      "Total loss: 5.567049026489258:\n",
      "3.9329609870910645 control,\n",
      "0.4216517508029938 lrg,\n",
      "0.5115478038787842 udg,\n",
      "0.3648780286312103 lra,\n",
      "0.3360104560852051 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.842905173301697\n",
      "\n",
      "Total loss: 0.014750744216144085; that's 0.0084451949223876 task and 0.005459300708025694 recon and 4.231247425079346 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015268129957839847\n",
      "\n",
      "Total loss: 5.603994846343994:\n",
      "3.918574571609497 control,\n",
      "0.45859652757644653 lrg,\n",
      "0.5013235807418823 udg,\n",
      "0.3722919821739197 lra,\n",
      "0.35320812463760376 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.003272070884704\n",
      "\n",
      "Total loss: 0.015942972153425217; that's 0.009336485527455807 task and 0.005764523055404425 recon and 4.2098188400268555 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014919837899506093\n",
      "\n",
      "Total loss: 0.014594057574868202; that's 0.008209421299397945 task and 0.0055070375092327595 recon and 4.3879923820495605 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01485156487673521\n",
      "\n",
      "Total loss: 5.714846134185791:\n",
      "4.104495525360107 control,\n",
      "0.4236873686313629 lrg,\n",
      "0.4860773980617523 udg,\n",
      "0.3635537922382355 lra,\n",
      "0.3370317220687866 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.648143534660339\n",
      "\n",
      "Total loss: 5.266226768493652:\n",
      "3.761777639389038 control,\n",
      "0.3698768615722656 lrg,\n",
      "0.48189041018486023 udg,\n",
      "0.32086870074272156 lra,\n",
      "0.3318132162094116 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.605576992034912\n",
      "\n",
      "Total loss: 0.01451081968843937; that's 0.008289641700685024 task and 0.005401800852268934 recon and 4.096888542175293 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014903993578627706\n",
      "\n",
      "Total loss: 5.901041507720947:\n",
      "4.31516695022583 control,\n",
      "0.42052289843559265 lrg,\n",
      "0.44196709990501404 udg,\n",
      "0.3407759368419647 lra,\n",
      "0.3826090395450592 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.5226717710495\n",
      "\n",
      "Total loss: 0.01520602684468031; that's 0.008860128931701183 task and 0.005430291406810284 recon and 4.578034400939941 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014920189641416073\n",
      "\n",
      "Total loss: 0.014657323248684406; that's 0.008287984877824783 task and 0.0055410610511898994 recon and 4.141385555267334 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014808934107422829\n",
      "\n",
      "Total loss: 5.464764595031738:\n",
      "3.7917263507843018 control,\n",
      "0.40076354146003723 lrg,\n",
      "0.5074580907821655 udg,\n",
      "0.39372435212135315 lra,\n",
      "0.3710918128490448 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.574501218795777\n",
      "\n",
      "Total loss: 0.014308586716651917; that's 0.008271150290966034 task and 0.005319598130881786 recon and 3.589191198348999 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015011889934539795\n",
      "\n",
      "Total loss: 4.755914688110352:\n",
      "3.21728253364563 control,\n",
      "0.3996778130531311 lrg,\n",
      "0.43311721086502075 udg,\n",
      "0.3322501480579376 lra,\n",
      "0.37358716130256653 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.351203541755677\n",
      "\n",
      "Total loss: 7.040425777435303:\n",
      "5.440448760986328 control,\n",
      "0.4241087734699249 lrg,\n",
      "0.46301236748695374 udg,\n",
      "0.37504252791404724 lra,\n",
      "0.3378135859966278 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.261616291999817\n",
      "\n",
      "Total loss: 0.01489957608282566; that's 0.008878916501998901 task and 0.00488462345674634 recon and 5.680180549621582 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014854899533092976\n",
      "\n",
      "Total loss: 6.498401165008545:\n",
      "4.9511284828186035 control,\n",
      "0.39456185698509216 lrg,\n",
      "0.4465729296207428 udg,\n",
      "0.3786562383174896 lra,\n",
      "0.32748162746429443 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.3210190534591675\n",
      "\n",
      "Total loss: 0.01615433394908905; that's 0.009389777667820454 task and 0.0057056196965277195 recon and 5.294680118560791 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01498767975717783\n",
      "\n",
      "Total loss: 0.014842623844742775; that's 0.008683326654136181 task and 0.00528961606323719 recon and 4.34840726852417 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015147615987807513\n",
      "\n",
      "Total loss: 5.719814300537109:\n",
      "4.09722900390625 control,\n",
      "0.4164953827857971 lrg,\n",
      "0.480286568403244 udg,\n",
      "0.38390207290649414 lra,\n",
      "0.3419010639190674 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.211148829460144\n",
      "\n",
      "Total loss: 0.01435444038361311; that's 0.008220597170293331 task and 0.005118146073073149 recon and 5.078486919403076 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014648855524137616\n",
      "\n",
      "Total loss: 6.334697723388672:\n",
      "4.748878002166748 control,\n",
      "0.463460236787796 lrg,\n",
      "0.44204971194267273 udg,\n",
      "0.3468025326728821 lra,\n",
      "0.33350715041160583 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.511056180000305\n",
      "\n",
      "Total loss: 0.014488942921161652; that's 0.00806527491658926 task and 0.005186876747757196 recon and 6.1839518547058105 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014638965604826809\n",
      "\n",
      "Total loss: 7.398153305053711:\n",
      "5.888937950134277 control,\n",
      "0.37197667360305786 lrg,\n",
      "0.4563296437263489 udg,\n",
      "0.3148133456707001 lra,\n",
      "0.36609548330307007 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.424095096588135\n",
      "\n",
      "Total loss: 0.013307404704391956; that's 0.007559244055300951 task and 0.004627252463251352 recon and 5.604540824890137 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01450663199648261\n",
      "\n",
      "Total loss: 6.935419082641602:\n",
      "5.370177745819092 control,\n",
      "0.4130857288837433 lrg,\n",
      "0.48615357279777527 udg,\n",
      "0.3175608515739441 lra,\n",
      "0.3484410345554352 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.419994168281555\n",
      "\n",
      "Total loss: 6.498438358306885:\n",
      "4.9254069328308105 control,\n",
      "0.3696920573711395 lrg,\n",
      "0.5197557210922241 udg,\n",
      "0.3377670645713806 lra,\n",
      "0.345816433429718 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.56605477809906\n",
      "\n",
      "Total loss: 0.013983006589114666; that's 0.00780339352786541 task and 0.005134883336722851 recon and 5.223648548126221 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014248665105551481\n",
      "\n",
      "Total loss: 0.01380283385515213; that's 0.00785716064274311 task and 0.004695040173828602 recon and 6.253166198730469 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014155306397005915\n",
      "\n",
      "Total loss: 7.602659225463867:\n",
      "5.9766740798950195 control,\n",
      "0.40526458621025085 lrg,\n",
      "0.5182824730873108 udg,\n",
      "0.3595123589038849 lra,\n",
      "0.34292587637901306 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.453684616088867\n",
      "\n",
      "Total loss: 6.331967830657959:\n",
      "4.792665958404541 control,\n",
      "0.4267370104789734 lrg,\n",
      "0.43368375301361084 udg,\n",
      "0.32718518376350403 lra,\n",
      "0.3516959846019745 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.7012632465362545\n",
      "\n",
      "Total loss: 0.014160671271383762; that's 0.008214821107685566 task and 0.004934970289468765 recon and 5.054400444030762 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014262261977419257\n",
      "\n",
      "Total loss: 6.393856048583984:\n",
      "4.763552665710449 control,\n",
      "0.4157601594924927 lrg,\n",
      "0.48568373918533325 udg,\n",
      "0.35258010029792786 lra,\n",
      "0.3762793242931366 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.50829598903656\n",
      "\n",
      "Total loss: 0.013990126550197601; that's 0.008105277083814144 task and 0.00487943971529603 recon and 5.0270466804504395 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014097233256325125\n",
      "\n",
      "Total loss: 6.361944675445557:\n",
      "4.82309627532959 control,\n",
      "0.42488592863082886 lrg,\n",
      "0.4417451322078705 udg,\n",
      "0.33102017641067505 lra,\n",
      "0.3411972224712372 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.201302251815796\n",
      "\n",
      "Total loss: 0.014602412469685078; that's 0.008958891034126282 task and 0.004622726701200008 recon and 5.10397481918335 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014129983251914382\n",
      "\n",
      "Total loss: 5.913753509521484:\n",
      "4.272854328155518 control,\n",
      "0.4690580666065216 lrg,\n",
      "0.466074138879776 udg,\n",
      "0.34563061594963074 lra,\n",
      "0.36013638973236084 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.18876660823822\n",
      "\n",
      "Total loss: 0.013391486369073391; that's 0.007553961593657732 task and 0.004925787914544344 recon and 4.558686256408691 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013585639037191868\n",
      "\n",
      "Total loss: 7.165862083435059:\n",
      "5.590793132781982 control,\n",
      "0.44110170006752014 lrg,\n",
      "0.4425757825374603 udg,\n",
      "0.35826897621154785 lra,\n",
      "0.3331224024295807 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.402835383415222\n",
      "\n",
      "Total loss: 0.013552067801356316; that's 0.007803730200976133 task and 0.004577431362122297 recon and 5.8545331954956055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013864954989403487\n",
      "\n",
      "Total loss: 0.012905276380479336; that's 0.007390456739813089 task and 0.004359142389148474 recon and 5.77838659286499 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013650501538068056\n",
      "\n",
      "Total loss: 7.104819297790527:\n",
      "5.523390769958496 control,\n",
      "0.4431554079055786 lrg,\n",
      "0.41161325573921204 udg,\n",
      "0.3636931777000427 lra,\n",
      "0.36296653747558594 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.468948998451233\n",
      "\n",
      "Total loss: 6.526828289031982:\n",
      "5.008630275726318 control,\n",
      "0.4241618514060974 lrg,\n",
      "0.4252384901046753 udg,\n",
      "0.3401722013950348 lra,\n",
      "0.32862532138824463 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.626608729362488\n",
      "\n",
      "Total loss: 0.013902826234698296; that's 0.007937601767480373 task and 0.0049248188734054565 recon and 5.202030658721924 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013690121518447996\n",
      "\n",
      "Total loss: 6.933942794799805:\n",
      "5.3707966804504395 control,\n",
      "0.43267178535461426 lrg,\n",
      "0.4400237500667572 udg,\n",
      "0.34080344438552856 lra,\n",
      "0.3496466279029846 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.8523206758499144\n",
      "\n",
      "Total loss: 0.014325671829283237; that's 0.008277079090476036 task and 0.0049134669825434685 recon and 5.675630569458008 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013449424114078283\n",
      "\n",
      "Total loss: 6.221635818481445:\n",
      "4.635156154632568 control,\n",
      "0.43219563364982605 lrg,\n",
      "0.4463064968585968 udg,\n",
      "0.3533770442008972 lra,\n",
      "0.3546004295349121 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.66235921382904\n",
      "\n",
      "Total loss: 0.013551652431488037; that's 0.007687057834118605 task and 0.004884576890617609 recon and 4.900086879730225 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01328417825512588\n",
      "\n",
      "Total loss: 6.325997352600098:\n",
      "4.824681758880615 control,\n",
      "0.4094467759132385 lrg,\n",
      "0.4269247353076935 udg,\n",
      "0.33641892671585083 lra,\n",
      "0.3285251557826996 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.62241376876831\n",
      "\n",
      "Total loss: 0.012796256691217422; that's 0.007382998708635569 task and 0.0044062500819563866 recon and 5.03503942489624 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013195462748408318\n",
      "\n",
      "Total loss: 6.419342517852783:\n",
      "4.9807329177856445 control,\n",
      "0.38135015964508057 lrg,\n",
      "0.3939272165298462 udg,\n",
      "0.3615889847278595 lra,\n",
      "0.3017435073852539 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.566999077796936\n",
      "\n",
      "Total loss: 0.013079359196126461; that's 0.007730172481387854 task and 0.004292858764529228 recon and 5.2816386222839355 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012954572960734368\n",
      "\n",
      "Total loss: 0.012883725576102734; that's 0.0072869895957410336 task and 0.004553614649921656 recon and 5.215607643127441 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014113978957757354\n",
      "\n",
      "Total loss: 6.573238849639893:\n",
      "4.883342266082764 control,\n",
      "0.47185084223747253 lrg,\n",
      "0.49634072184562683 udg,\n",
      "0.36427581310272217 lra,\n",
      "0.3574291467666626 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.560672011375427\n",
      "\n",
      "Total loss: 0.012751606293022633; that's 0.007281354162842035 task and 0.0044179349206388 recon and 5.261587619781494 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013518062615767122\n",
      "\n",
      "Total loss: 6.5503387451171875:\n",
      "4.930320739746094 control,\n",
      "0.43499165773391724 lrg,\n",
      "0.45470869541168213 udg,\n",
      "0.34484556317329407 lra,\n",
      "0.38547202944755554 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.438619847297669\n",
      "\n",
      "Total loss: 0.013419483788311481; that's 0.008029275573790073 task and 0.004475198686122894 recon and 4.575047969818115 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01353621789254248\n",
      "\n",
      "Total loss: 5.851555824279785:\n",
      "4.2384257316589355 control,\n",
      "0.43399256467819214 lrg,\n",
      "0.4738529324531555 udg,\n",
      "0.35893523693084717 lra,\n",
      "0.34634923934936523 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.740459408760071\n",
      "\n",
      "Total loss: 0.013305521570146084; that's 0.007847757078707218 task and 0.0044186534360051155 recon and 5.195557117462158 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013241097265854478\n",
      "\n",
      "Total loss: 6.462684631347656:\n",
      "4.8942155838012695 control,\n",
      "0.45863810181617737 lrg,\n",
      "0.4295128881931305 udg,\n",
      "0.32211610674858093 lra,\n",
      "0.35820186138153076 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.921031608581543\n",
      "\n",
      "Total loss: 0.012908825650811195; that's 0.0076782894320786 task and 0.004305344540625811 recon and 4.6259589195251465 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012758042998611926\n",
      "\n",
      "Total loss: 5.972022533416748:\n",
      "4.2949066162109375 control,\n",
      "0.47665444016456604 lrg,\n",
      "0.48263058066368103 udg,\n",
      "0.37682032585144043 lra,\n",
      "0.34101077914237976 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.409224362373352\n",
      "\n",
      "Total loss: 6.139206886291504:\n",
      "4.622703552246094 control,\n",
      "0.41845202445983887 lrg,\n",
      "0.41158464550971985 udg,\n",
      "0.3285325765609741 lra,\n",
      "0.3579336404800415 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.69814024925232\n",
      "\n",
      "Total loss: 0.015027856454253197; that's 0.009160016663372517 task and 0.004885269794613123 recon and 4.912848949432373 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016009115613996983\n",
      "\n",
      "Total loss: 6.339616775512695:\n",
      "4.804079055786133 control,\n",
      "0.34764373302459717 lrg,\n",
      "0.4519418776035309 udg,\n",
      "0.3437969982624054 lra,\n",
      "0.3921546936035156 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.551338658332825\n",
      "\n",
      "Total loss: 0.012981765903532505; that's 0.007524735294282436 task and 0.004439512733370066 recon and 5.087587833404541 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013763922024518252\n",
      "\n",
      "Total loss: 0.013131371699273586; that's 0.0076412600465118885 task and 0.004373036790639162 recon and 5.585374355316162 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013583197211846709\n",
      "\n",
      "Total loss: 6.796685695648193:\n",
      "5.259654998779297 control,\n",
      "0.4268980324268341 lrg,\n",
      "0.4394315779209137 udg,\n",
      "0.3363688290119171 lra,\n",
      "0.3343318700790405 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.925402665138245\n",
      "\n",
      "Total loss: 6.647552013397217:\n",
      "5.032283306121826 control,\n",
      "0.43646740913391113 lrg,\n",
      "0.44913560152053833 udg,\n",
      "0.364566445350647 lra,\n",
      "0.3650988042354584 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.44716073513031\n",
      "\n",
      "Total loss: 0.01370205357670784; that's 0.008025585673749447 task and 0.004598422907292843 recon and 5.390224456787109 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013234492568299174\n",
      "\n",
      "Total loss: 6.343544006347656:\n",
      "4.718576431274414 control,\n",
      "0.44263148307800293 lrg,\n",
      "0.5022988319396973 udg,\n",
      "0.33098864555358887 lra,\n",
      "0.34904852509498596 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.451618304252625\n",
      "\n",
      "Total loss: 0.012520846910774708; that's 0.00730625307187438 task and 0.004214006010442972 recon and 5.002938270568848 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01295981926843524\n",
      "\n",
      "Total loss: 6.543291091918945:\n",
      "5.039183616638184 control,\n",
      "0.40132206678390503 lrg,\n",
      "0.4258110225200653 udg,\n",
      "0.33136382699012756 lra,\n",
      "0.34561124444007874 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.711593451499939\n",
      "\n",
      "Total loss: 0.012024871073663235; that's 0.006946370471268892 task and 0.003995084203779697 recon and 5.417081832885742 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012563646184280514\n",
      "\n",
      "Total loss: 0.012656138278543949; that's 0.007575951516628265 task and 0.004079363774508238 recon and 5.0041117668151855 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012658369215205311\n",
      "\n",
      "Total loss: 6.2833428382873535:\n",
      "4.717695236206055 control,\n",
      "0.4478771984577179 lrg,\n",
      "0.4277827739715576 udg,\n",
      "0.36728909611701965 lra,\n",
      "0.322698712348938 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.207391233444214\n",
      "\n",
      "Total loss: 0.012247675098478794; that's 0.006800635252147913 task and 0.004293765872716904 recon and 5.766373157501221 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012647906513884664\n",
      "\n",
      "Total loss: 7.015888214111328:\n",
      "5.480175018310547 control,\n",
      "0.4171120524406433 lrg,\n",
      "0.43611380457878113 udg,\n",
      "0.3354664742946625 lra,\n",
      "0.3470212519168854 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.6508269691467286\n",
      "\n",
      "Total loss: 5.824154376983643:\n",
      "4.191499710083008 control,\n",
      "0.4470808804035187 lrg,\n",
      "0.44873562455177307 udg,\n",
      "0.36705467104911804 lra,\n",
      "0.3697836101055145 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.120537691116333\n",
      "\n",
      "Total loss: 0.012477226555347443; that's 0.007488878443837166 task and 0.004109545610845089 recon and 4.394014358520508 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012357238046824932\n",
      "\n",
      "Total loss: 0.012012862600386143; that's 0.006995434407144785 task and 0.004093632102012634 recon and 4.618981838226318 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012476117303594946\n",
      "\n",
      "Total loss: 5.860980033874512:\n",
      "4.2681565284729 control,\n",
      "0.4375549256801605 lrg,\n",
      "0.4605727195739746 udg,\n",
      "0.3446299433708191 lra,\n",
      "0.3500659763813019 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.238139343261719\n",
      "\n",
      "Total loss: 5.8923492431640625:\n",
      "4.2716064453125 control,\n",
      "0.4532369077205658 lrg,\n",
      "0.4592586159706116 udg,\n",
      "0.34418997168540955 lra,\n",
      "0.3640572130680084 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.308250102996826\n",
      "\n",
      "Total loss: 0.01255911123007536; that's 0.007510176859796047 task and 0.004147999919950962 recon and 4.5046706199646 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012338967304676771\n",
      "\n",
      "Total loss: 0.012519126757979393; that's 0.007344092708081007 task and 0.004231730941683054 recon and 4.716513633728027 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01216492487117648\n",
      "\n",
      "Total loss: 5.989080905914307:\n",
      "4.3042988777160645 control,\n",
      "0.4226871728897095 lrg,\n",
      "0.47588711977005005 udg,\n",
      "0.41081565618515015 lra,\n",
      "0.37539178133010864 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.378265342712402\n",
      "\n",
      "Total loss: 0.011975753121078014; that's 0.006604078691452742 task and 0.004440249875187874 recon and 4.657121658325195 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012415925059467554\n",
      "\n",
      "Total loss: 5.974786281585693:\n",
      "4.304487228393555 control,\n",
      "0.43693631887435913 lrg,\n",
      "0.4997207224369049 udg,\n",
      "0.3842693269252777 lra,\n",
      "0.3493726849555969 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.2591168856620785\n",
      "\n",
      "Total loss: 0.012474137358367443; that's 0.0074846986681222916 task and 0.0042708455584943295 recon and 3.5929627418518066 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012880623042583465\n",
      "\n",
      "Total loss: 4.922478199005127:\n",
      "3.2401857376098633 control,\n",
      "0.44986864924430847 lrg,\n",
      "0.5114645957946777 udg,\n",
      "0.35057058930397034 lra,\n",
      "0.37038859724998474 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.346305727958679\n",
      "\n",
      "Total loss: 5.583626747131348:\n",
      "4.040735244750977 control,\n",
      "0.4128040373325348 lrg,\n",
      "0.4483353793621063 udg,\n",
      "0.35623422265052795 lra,\n",
      "0.3255183696746826 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.144050915241241\n",
      "\n",
      "Total loss: 0.012045840732753277; that's 0.007143249269574881 task and 0.004037459380924702 recon and 4.325662136077881 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012397536365315319\n",
      "\n",
      "Total loss: 6.210745334625244:\n",
      "4.592039585113525 control,\n",
      "0.44988322257995605 lrg,\n",
      "0.47245270013809204 udg,\n",
      "0.3484634757041931 lra,\n",
      "0.3479064404964447 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.130059061050415\n",
      "\n",
      "Total loss: 0.01260366290807724; that's 0.007685310207307339 task and 0.0039509739726781845 recon and 4.836893558502197 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012323383335024118\n",
      "\n",
      "Total loss: 0.011636673472821712; that's 0.0066598523408174515 task and 0.004176928196102381 recon and 3.999464988708496 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012072042310610414\n",
      "\n",
      "Total loss: 5.289102554321289:\n",
      "3.6086912155151367 control,\n",
      "0.43741804361343384 lrg,\n",
      "0.4842450022697449 udg,\n",
      "0.36577358841896057 lra,\n",
      "0.3929749131202698 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.966823449134827\n",
      "\n",
      "Total loss: 0.0122014619410038; that's 0.007613282650709152 task and 0.003854663809761405 recon and 3.667576789855957 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011820637071505189\n",
      "\n",
      "Total loss: 4.979823112487793:\n",
      "3.312493085861206 control,\n",
      "0.46779847145080566 lrg,\n",
      "0.4841064214706421 udg,\n",
      "0.355019748210907 lra,\n",
      "0.36040520668029785 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.386824717521668\n",
      "\n",
      "Total loss: 0.011292905546724796; that's 0.007051545660942793 task and 0.00346222217194736 recon and 3.8956878185272217 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011670204922556876\n",
      "\n",
      "Total loss: 5.080334186553955:\n",
      "3.514301061630249 control,\n",
      "0.43694502115249634 lrg,\n",
      "0.4261326491832733 udg,\n",
      "0.3407902717590332 lra,\n",
      "0.36216530203819275 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.22503321647644\n",
      "\n",
      "Total loss: 6.885082721710205:\n",
      "5.271607875823975 control,\n",
      "0.44509515166282654 lrg,\n",
      "0.4678681790828705 udg,\n",
      "0.35021913051605225 lra,\n",
      "0.35029205679893494 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.087703700065613\n",
      "\n",
      "Total loss: 0.012372080236673355; that's 0.007311256602406502 task and 0.003945665434002876 recon and 5.5757927894592285 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011922767646610736\n",
      "\n",
      "Total loss: 7.055898189544678:\n",
      "5.524948596954346 control,\n",
      "0.4203200340270996 lrg,\n",
      "0.42560720443725586 udg,\n",
      "0.34564757347106934 lra,\n",
      "0.3393751382827759 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.0907037687301635\n",
      "\n",
      "Total loss: 0.01271364651620388; that's 0.0078023807145655155 task and 0.0037466760259121656 recon and 5.822951793670654 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011890986012294888\n",
      "\n",
      "Total loss: 0.013146180659532547; that's 0.00799481850117445 task and 0.004071809817105532 recon and 5.397761344909668 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011800413262099027\n",
      "\n",
      "Total loss: 6.622325420379639:\n",
      "5.0537614822387695 control,\n",
      "0.46030816435813904 lrg,\n",
      "0.4294186234474182 udg,\n",
      "0.34359729290008545 lra,\n",
      "0.33524009585380554 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.004891614913941\n",
      "\n",
      "Total loss: 0.011920357123017311; that's 0.0071253469213843346 task and 0.0038168730679899454 recon and 4.890687942504883 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011860981369391083\n",
      "\n",
      "Total loss: 6.1688385009765625:\n",
      "4.605798721313477 control,\n",
      "0.42252153158187866 lrg,\n",
      "0.4538891911506653 udg,\n",
      "0.3272172212600708 lra,\n",
      "0.35941189527511597 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.136845908164978\n",
      "\n",
      "Total loss: 0.011614704504609108; that's 0.006918834988027811 task and 0.0038240912836045027 recon and 4.358893871307373 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011833573058247567\n",
      "\n",
      "Total loss: 5.64485502243042:\n",
      "4.08521032333374 control,\n",
      "0.42580169439315796 lrg,\n",
      "0.4122360050678253 udg,\n",
      "0.3684515655040741 lra,\n",
      "0.35315531492233276 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.13487847328186\n",
      "\n",
      "Total loss: 6.661007881164551:\n",
      "5.099366664886475 control,\n",
      "0.43113747239112854 lrg,\n",
      "0.43159595131874084 udg,\n",
      "0.36118391156196594 lra,\n",
      "0.3377237021923065 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.249724383354187\n",
      "\n",
      "Total loss: 0.012327381409704685; that's 0.007491121534258127 task and 0.003745402442291379 recon and 5.45428466796875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011850097710266709\n",
      "\n",
      "Total loss: 0.011965381912887096; that's 0.00690873060375452 task and 0.004044950939714909 recon and 5.058502674102783 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012053730878978968\n",
      "\n",
      "Total loss: 6.297446250915527:\n",
      "4.735414505004883 control,\n",
      "0.41333797574043274 lrg,\n",
      "0.44794145226478577 udg,\n",
      "0.34410718083381653 lra,\n",
      "0.3566451668739319 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.263654656410218\n",
      "\n",
      "Total loss: 0.011338087730109692; that's 0.00656748004257679 task and 0.0038592629134655 recon and 4.556723117828369 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011866593277081847\n",
      "\n",
      "Total loss: 5.8176960945129395:\n",
      "4.228427886962891 control,\n",
      "0.4086054861545563 lrg,\n",
      "0.4672695994377136 udg,\n",
      "0.3344205319881439 lra,\n",
      "0.37897247076034546 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.298318328857422\n",
      "\n",
      "Total loss: 5.778955936431885:\n",
      "4.203386306762695 control,\n",
      "0.4362068772315979 lrg,\n",
      "0.45684731006622314 udg,\n",
      "0.3400708734989166 lra,\n",
      "0.3424449563026428 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.092290830612183\n",
      "\n",
      "Total loss: 0.010939091444015503; that's 0.006355715449899435 task and 0.0036794953048229218 recon and 4.519400596618652 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011879715565592051\n",
      "\n",
      "Total loss: 0.01115386188030243; that's 0.006554563529789448 task and 0.003495911369100213 recon and 5.516934394836426 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011866574343293905\n",
      "\n",
      "Total loss: 6.877915382385254:\n",
      "5.209568500518799 control,\n",
      "0.519385576248169 lrg,\n",
      "0.46664494276046753 udg,\n",
      "0.338412344455719 lra,\n",
      "0.3439040780067444 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.301815009117126\n",
      "\n",
      "Total loss: 0.011447264812886715; that's 0.006836569868028164 task and 0.0036757984198629856 recon and 4.674480438232422 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01173671755939722\n",
      "\n",
      "Total loss: 5.923902988433838:\n",
      "4.325962066650391 control,\n",
      "0.4265005588531494 lrg,\n",
      "0.46687108278274536 udg,\n",
      "0.35384634137153625 lra,\n",
      "0.35072261095046997 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.224362630844116\n",
      "\n",
      "Total loss: 5.523443698883057:\n",
      "3.9347546100616455 control,\n",
      "0.45783114433288574 lrg,\n",
      "0.4329809546470642 udg,\n",
      "0.3293573558330536 lra,\n",
      "0.3685199022293091 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.198968725204468\n",
      "\n",
      "Total loss: 0.011724445968866348; that's 0.0070952014066278934 task and 0.003778962418437004 recon and 4.251410961151123 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011598201040178537\n",
      "\n",
      "Total loss: 0.012107215821743011; that's 0.007313946262001991 task and 0.0036686966195702553 recon and 5.622865676879883 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011545001743361354\n",
      "\n",
      "Total loss: 6.852447986602783:\n",
      "5.270706653594971 control,\n",
      "0.4255577623844147 lrg,\n",
      "0.4319818913936615 udg,\n",
      "0.3719702959060669 lra,\n",
      "0.3522316515445709 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.039063186645508\n",
      "\n",
      "Total loss: 0.011096658185124397; that's 0.006461006123572588 task and 0.003482900094240904 recon and 5.763759613037109 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011673852205276489\n",
      "\n",
      "Total loss: 6.9688825607299805:\n",
      "5.3746113777160645 control,\n",
      "0.42083853483200073 lrg,\n",
      "0.4633156657218933 udg,\n",
      "0.34005236625671387 lra,\n",
      "0.3700648248195648 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.967131013870239\n",
      "\n",
      "Total loss: 0.01245780661702156; that's 0.007568753324449062 task and 0.003970885183662176 recon and 4.590844631195068 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011555073810741305\n",
      "\n",
      "Total loss: 5.804379940032959:\n",
      "4.226980209350586 control,\n",
      "0.41118568181991577 lrg,\n",
      "0.46453309059143066 udg,\n",
      "0.34721580147743225 lra,\n",
      "0.3544648289680481 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.055139970779419\n",
      "\n",
      "Total loss: 0.012000503949820995; that's 0.007135567720979452 task and 0.0039000201504677534 recon and 4.824581146240234 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012167863612994552\n",
      "\n",
      "Total loss: 6.156163215637207:\n",
      "4.536527633666992 control,\n",
      "0.3873680531978607 lrg,\n",
      "0.4888589680194855 udg,\n",
      "0.35710933804512024 lra,\n",
      "0.386298805475235 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.000703101158142\n",
      "\n",
      "Total loss: 7.59147310256958:\n",
      "5.986669063568115 control,\n",
      "0.4189000427722931 lrg,\n",
      "0.46444717049598694 udg,\n",
      "0.3572509288787842 lra,\n",
      "0.3642060458660126 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.2511136436462404\n",
      "\n",
      "Total loss: 0.012107078917324543; that's 0.0072517856024205685 task and 0.0036108510103076696 recon and 6.222212791442871 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011712254956364632\n",
      "\n",
      "Total loss: 5.725264072418213:\n",
      "4.077964782714844 control,\n",
      "0.4334592819213867 lrg,\n",
      "0.477203369140625 udg,\n",
      "0.3692305386066437 lra,\n",
      "0.36740586161613464 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.0258648443222045\n",
      "\n",
      "Total loss: 0.011862408369779587; that's 0.0069593102671206 task and 0.004025173373520374 recon and 4.389623641967773 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011531449444592\n",
      "\n",
      "Total loss: 0.011964910663664341; that's 0.007158045656979084 task and 0.003782049287110567 recon and 5.124075412750244 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011467881547287107\n",
      "\n",
      "Total loss: 6.439888954162598:\n",
      "4.805878162384033 control,\n",
      "0.4209209382534027 lrg,\n",
      "0.4844588339328766 udg,\n",
      "0.36210304498672485 lra,\n",
      "0.36652812361717224 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.056709046363831\n",
      "\n",
      "Total loss: 6.389107704162598:\n",
      "4.841496467590332 control,\n",
      "0.3993941843509674 lrg,\n",
      "0.4584183096885681 udg,\n",
      "0.35204607248306274 lra,\n",
      "0.33775269985198975 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.115437021255493\n",
      "\n",
      "Total loss: 0.011597150936722755; that's 0.006821407470852137 task and 0.0037608628626912832 recon and 5.07440185546875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01160636192187667\n",
      "\n",
      "Total loss: 0.011562290601432323; that's 0.0067379167303442955 task and 0.0037867799401283264 recon and 5.187969207763672 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01172306681983173\n",
      "\n",
      "Total loss: 6.461695194244385:\n",
      "4.881635665893555 control,\n",
      "0.4071286916732788 lrg,\n",
      "0.4756375551223755 udg,\n",
      "0.3405165672302246 lra,\n",
      "0.35677674412727356 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.002654933929444\n",
      "\n",
      "Total loss: 0.011119178496301174; that's 0.006509454920887947 task and 0.0036335729528218508 recon and 4.880756378173828 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011433406444266438\n",
      "\n",
      "Total loss: 6.195573329925537:\n",
      "4.59080696105957 control,\n",
      "0.4365220367908478 lrg,\n",
      "0.4727383553981781 udg,\n",
      "0.3483841121196747 lra,\n",
      "0.3471224009990692 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.729217863082885\n",
      "\n",
      "Total loss: 0.011819389648735523; that's 0.007231110241264105 task and 0.0038360501639544964 recon and 3.7611474990844727 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011617688555270433\n",
      "\n",
      "Total loss: 5.036444187164307:\n",
      "3.4322962760925293 control,\n",
      "0.4345153570175171 lrg,\n",
      "0.44184184074401855 udg,\n",
      "0.36155930161476135 lra,\n",
      "0.36623117327690125 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.792048044204712\n",
      "\n",
      "Total loss: 0.01060669869184494; that's 0.006087473127990961 task and 0.0037012058310210705 recon and 4.090097427368164 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012135377814993263\n",
      "\n",
      "Total loss: 5.3412675857543945:\n",
      "3.771409034729004 control,\n",
      "0.4483788013458252 lrg,\n",
      "0.4404216408729553 udg,\n",
      "0.3388240337371826 lra,\n",
      "0.3422348201274872 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.165298795700073\n",
      "\n",
      "Total loss: 0.011559993028640747; that's 0.007145806681364775 task and 0.0037453777622431517 recon and 3.344045639038086 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011857932852581143\n",
      "\n",
      "Total loss: 4.543585777282715:\n",
      "2.9638657569885254 control,\n",
      "0.42453330755233765 lrg,\n",
      "0.44285207986831665 udg,\n",
      "0.3583492338657379 lra,\n",
      "0.3539851903915405 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.86882438659668\n",
      "\n",
      "Total loss: 6.993265151977539:\n",
      "5.434406757354736 control,\n",
      "0.3983004093170166 lrg,\n",
      "0.4243704080581665 udg,\n",
      "0.3632090985774994 lra,\n",
      "0.3729782998561859 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.820170025825501\n",
      "\n",
      "Total loss: 0.012413471937179565; that's 0.007207775488495827 task and 0.004058346152305603 recon and 5.736751079559326 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011691431859508156\n",
      "\n",
      "Total loss: 0.011228407733142376; that's 0.0066225724294781685 task and 0.003588919760659337 recon and 5.084579944610596 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011272253943607211\n",
      "\n",
      "Total loss: 6.325417518615723:\n",
      "4.787967681884766 control,\n",
      "0.4297747015953064 lrg,\n",
      "0.4538799226284027 udg,\n",
      "0.32033005356788635 lra,\n",
      "0.3334652781486511 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.90871561050415\n",
      "\n",
      "Total loss: 0.01189865916967392; that's 0.007281765341758728 task and 0.003708683652803302 recon and 4.541050434112549 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011426185183227062\n",
      "\n",
      "Total loss: 5.706377029418945:\n",
      "4.142394065856934 control,\n",
      "0.44319307804107666 lrg,\n",
      "0.45336049795150757 udg,\n",
      "0.3316569924354553 lra,\n",
      "0.33577266335487366 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.978817820549011\n",
      "\n",
      "Total loss: 0.011331766843795776; that's 0.006758411880582571 task and 0.0036169339437037706 recon and 4.7821044921875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011264075599610806\n",
      "\n",
      "Total loss: 6.105038166046143:\n",
      "4.483945846557617 control,\n",
      "0.4365469217300415 lrg,\n",
      "0.4760207235813141 udg,\n",
      "0.34639573097229004 lra,\n",
      "0.36212870478630066 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.909330234527588\n",
      "\n",
      "Total loss: 0.011221478693187237; that's 0.006666043773293495 task and 0.0038138912059366703 recon and 3.707720994949341 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01132615962997079\n",
      "\n",
      "Total loss: 5.016775608062744:\n",
      "3.3563714027404785 control,\n",
      "0.4645764231681824 lrg,\n",
      "0.5002310276031494 udg,\n",
      "0.3688682019710541 lra,\n",
      "0.3267281651496887 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.544561843872071\n",
      "\n",
      "Total loss: 6.252563953399658:\n",
      "4.6645612716674805 control,\n",
      "0.46964526176452637 lrg,\n",
      "0.4323449730873108 udg,\n",
      "0.343765527009964 lra,\n",
      "0.34224674105644226 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.6764382314682\n",
      "\n",
      "Total loss: 0.011099851690232754; that's 0.006515657063573599 task and 0.0035962590482085943 recon and 4.939678192138672 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011211372530087828\n",
      "\n",
      "Total loss: 4.837582111358643:\n",
      "3.240399122238159 control,\n",
      "0.414055734872818 lrg,\n",
      "0.4643981158733368 udg,\n",
      "0.3819665312767029 lra,\n",
      "0.3367624282836914 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.3708682012557984\n",
      "\n",
      "Total loss: 0.010625101625919342; that's 0.006445903331041336 task and 0.003475927049294114 recon and 3.516359329223633 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011237018126994371\n",
      "\n",
      "Total loss: 4.534252166748047:\n",
      "2.824690103530884 control,\n",
      "0.46146464347839355 lrg,\n",
      "0.48894909024238586 udg,\n",
      "0.3571542501449585 lra,\n",
      "0.4019941985607147 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.2515644836425786\n",
      "\n",
      "Total loss: 0.010777559131383896; that's 0.006606393959373236 task and 0.0035500051453709602 recon and 3.1058013439178467 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011007953761145472\n",
      "\n",
      "Total loss: 0.010409947484731674; that's 0.006214338820427656 task and 0.0035080057568848133 recon and 3.4380130767822266 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010964596532285214\n",
      "\n",
      "Total loss: 4.696972370147705:\n",
      "3.1075685024261475 control,\n",
      "0.43645110726356506 lrg,\n",
      "0.47811663150787354 udg,\n",
      "0.3384440541267395 lra,\n",
      "0.33639177680015564 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.967428455352783\n",
      "\n",
      "Total loss: 4.6811981201171875:\n",
      "3.02398419380188 control,\n",
      "0.47412407398223877 lrg,\n",
      "0.47961005568504333 udg,\n",
      "0.3639187812805176 lra,\n",
      "0.3395608365535736 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.11455715417862\n",
      "\n",
      "Total loss: 0.011110562831163406; that's 0.0066605182364583015 task and 0.0037923927884548903 recon and 3.2882559299468994 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011200537215918302\n",
      "\n",
      "Total loss: 5.978734016418457:\n",
      "4.467728137969971 control,\n",
      "0.39173373579978943 lrg,\n",
      "0.4422197639942169 udg,\n",
      "0.33792757987976074 lra,\n",
      "0.33912479877471924 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.724606719017029\n",
      "\n",
      "Total loss: 0.011566292494535446; that's 0.007088451646268368 task and 0.003516008146107197 recon and 4.809164524078369 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011104738945141435\n",
      "\n",
      "Total loss: 6.0371413230896:\n",
      "4.47518253326416 control,\n",
      "0.4507541358470917 lrg,\n",
      "0.4148976504802704 udg,\n",
      "0.34100425243377686 lra,\n",
      "0.3553026616573334 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.3946648430824276\n",
      "\n",
      "Total loss: 0.011203509755432606; that's 0.006758461240679026 task and 0.0034799063578248024 recon and 4.82570743560791 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011064718971028923\n",
      "\n",
      "Total loss: 0.010354605503380299; that's 0.006457998417317867 task and 0.003295411355793476 recon and 3.005977153778076 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010857152193784714\n",
      "\n",
      "Total loss: 4.199853897094727:\n",
      "2.631948232650757 control,\n",
      "0.4097614884376526 lrg,\n",
      "0.43899571895599365 udg,\n",
      "0.38006940484046936 lra,\n",
      "0.3390793800354004 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.630851535797119\n",
      "\n",
      "Total loss: 0.01071082428097725; that's 0.006282767280936241 task and 0.003562553320080042 recon and 4.327520370483398 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011024197405204177\n",
      "\n",
      "Total loss: 5.564147472381592:\n",
      "4.020681381225586 control,\n",
      "0.4373911917209625 lrg,\n",
      "0.4320414662361145 udg,\n",
      "0.32669416069984436 lra,\n",
      "0.3473391532897949 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.073736424446106\n",
      "\n",
      "Total loss: 6.3790788650512695:\n",
      "4.791419982910156 control,\n",
      "0.42007389664649963 lrg,\n",
      "0.46920526027679443 udg,\n",
      "0.33535513281822205 lra,\n",
      "0.3630242347717285 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.788973922729492\n",
      "\n",
      "Total loss: 0.011652933433651924; that's 0.007183219771832228 task and 0.0034579792991280556 recon and 5.0586748123168945 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011225174739956855\n",
      "\n",
      "Total loss: 4.004518508911133:\n",
      "2.2590529918670654 control,\n",
      "0.5082156658172607 lrg,\n",
      "0.5161222219467163 udg,\n",
      "0.3576611280441284 lra,\n",
      "0.3634662330150604 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.914421043395996\n",
      "\n",
      "Total loss: 0.010768497362732887; that's 0.006909296382218599 task and 0.003357056062668562 recon and 2.5107264518737793 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010937102697789669\n",
      "\n",
      "Total loss: 3.85715651512146:\n",
      "2.243363618850708 control,\n",
      "0.4432564377784729 lrg,\n",
      "0.4628064036369324 udg,\n",
      "0.3586401045322418 lra,\n",
      "0.3490898609161377 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.8206288957595826\n",
      "\n",
      "Total loss: 0.01122787594795227; that's 0.006810228805989027 task and 0.003906652331352234 recon and 2.5549697875976562 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010877802204340696\n",
      "\n",
      "Total loss: 0.013158302754163742; that's 0.007714204955846071 task and 0.0048048668541014194 recon and 3.1961569786071777 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011639916598796844\n",
      "\n",
      "Total loss: 4.395400047302246:\n",
      "2.853353261947632 control,\n",
      "0.4208342134952545 lrg,\n",
      "0.45003601908683777 udg,\n",
      "0.32953107357025146 lra,\n",
      "0.34164533019065857 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.472863087654114\n",
      "\n",
      "Total loss: 0.010897789150476456; that's 0.006898836232721806 task and 0.003506764303892851 recon and 2.4609436988830566 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011380050331354141\n",
      "\n",
      "Total loss: 3.6970949172973633:\n",
      "2.1056861877441406 control,\n",
      "0.42369288206100464 lrg,\n",
      "0.4574165642261505 udg,\n",
      "0.36132776737213135 lra,\n",
      "0.3489713668823242 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.719863383769989\n",
      "\n",
      "Total loss: 4.613260746002197:\n",
      "2.9880621433258057 control,\n",
      "0.4332912564277649 lrg,\n",
      "0.42099571228027344 udg,\n",
      "0.370368093252182 lra,\n",
      "0.40054380893707275 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.098694825172425\n",
      "\n",
      "Total loss: 0.010056079365313053; that's 0.005832700524479151 task and 0.0035708663053810596 recon and 3.2625620365142822 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01105239882133901\n",
      "\n",
      "Total loss: 0.010469036176800728; that's 0.006236890330910683 task and 0.0032439003698527813 recon and 4.941224575042725 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011110863648355007\n",
      "\n",
      "Total loss: 6.147370338439941:\n",
      "4.6187663078308105 control,\n",
      "0.4216374158859253 lrg,\n",
      "0.43817609548568726 udg,\n",
      "0.3250030279159546 lra,\n",
      "0.3437870442867279 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.113517589569092\n",
      "\n",
      "Total loss: 0.010857930406928062; that's 0.0065209222957491875 task and 0.003248745109885931 recon and 5.441318035125732 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011021380117163061\n",
      "\n",
      "Total loss: 6.650235176086426:\n",
      "5.083023548126221 control,\n",
      "0.42866313457489014 lrg,\n",
      "0.46018368005752563 udg,\n",
      "0.3333389461040497 lra,\n",
      "0.34502607583999634 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.61097897529602\n",
      "\n",
      "Total loss: 5.698651313781738:\n",
      "4.165119171142578 control,\n",
      "0.4080112874507904 lrg,\n",
      "0.46951109170913696 udg,\n",
      "0.32082927227020264 lra,\n",
      "0.335180401802063 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.9476023244857785\n",
      "\n",
      "Total loss: 0.011785577982664108; that's 0.007101585157215595 task and 0.0037868297658860683 recon and 4.485819339752197 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011208427669480443\n",
      "\n",
      "Total loss: 0.011968686245381832; that's 0.007050266023725271 task and 0.0038572284393012524 recon and 5.305959701538086 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011033672709017991\n",
      "\n",
      "Total loss: 6.540639400482178:\n",
      "4.91620397567749 control,\n",
      "0.4384394586086273 lrg,\n",
      "0.4496447443962097 udg,\n",
      "0.3831698000431061 lra,\n",
      "0.35318198800086975 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.644072663784027\n",
      "\n",
      "Total loss: 5.958622932434082:\n",
      "4.439896583557129 control,\n",
      "0.4099583029747009 lrg,\n",
      "0.40757235884666443 udg,\n",
      "0.3467664122581482 lra,\n",
      "0.3544292449951172 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.194488554000855\n",
      "\n",
      "Total loss: 0.011195579543709755; that's 0.006538759917020798 task and 0.0037050002720206976 recon and 4.759096145629883 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011144170742481948\n",
      "\n",
      "Total loss: 6.557833671569824:\n",
      "5.076140403747559 control,\n",
      "0.38349759578704834 lrg,\n",
      "0.42716580629348755 udg,\n",
      "0.34312704205513 lra,\n",
      "0.32790228724479675 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.865840458869934\n",
      "\n",
      "Total loss: 0.010735724121332169; that's 0.0061460151337087154 task and 0.0035084388218820095 recon and 5.406352519989014 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011040033530443907\n",
      "\n",
      "Total loss: 5.270488739013672:\n",
      "3.6367032527923584 control,\n",
      "0.42388641834259033 lrg,\n",
      "0.47325336933135986 udg,\n",
      "0.3745405077934265 lra,\n",
      "0.3621053695678711 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.045140454769134\n",
      "\n",
      "Total loss: 0.011050766333937645; that's 0.006854713428765535 task and 0.003391985548660159 recon and 4.020340442657471 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010901892492547631\n",
      "\n",
      "Total loss: 4.637200832366943:\n",
      "3.0541086196899414 control,\n",
      "0.42489975690841675 lrg,\n",
      "0.502037763595581 udg,\n",
      "0.32686296105384827 lra,\n",
      "0.3292917013168335 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.880627858638763\n",
      "\n",
      "Total loss: 0.010607167147099972; that's 0.006559344939887524 task and 0.0033852201886475086 recon and 3.3130056858062744 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010890126740559936\n",
      "\n",
      "Total loss: 5.969170093536377:\n",
      "4.442416191101074 control,\n",
      "0.39825141429901123 lrg,\n",
      "0.42881473898887634 udg,\n",
      "0.36788803339004517 lra,\n",
      "0.33179932832717896 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.304874587059021\n",
      "\n",
      "Total loss: 0.011043339036405087; that's 0.006585631053894758 task and 0.003516032826155424 recon and 4.708376407623291 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010945546431466937\n",
      "\n",
      "Total loss: 4.834682941436768:\n",
      "3.088510513305664 control,\n",
      "0.46252748370170593 lrg,\n",
      "0.48212987184524536 udg,\n",
      "0.4108368456363678 lra,\n",
      "0.3906783163547516 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.892186369895935\n",
      "\n",
      "Total loss: 0.01197401899844408; that's 0.007482046727091074 task and 0.0038147831801325083 recon and 3.38594388961792 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010881931204348803\n",
      "\n",
      "Total loss: 4.349233150482178:\n",
      "2.713883876800537 control,\n",
      "0.41787514090538025 lrg,\n",
      "0.5153411030769348 udg,\n",
      "0.35748887062072754 lra,\n",
      "0.34464412927627563 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.973580558300018\n",
      "\n",
      "Total loss: 0.009987196885049343; that's 0.00605997396633029 task and 0.003334934590384364 recon and 2.961442470550537 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010795806096866726\n",
      "\n",
      "Total loss: 4.627505302429199:\n",
      "2.996441602706909 control,\n",
      "0.4039221704006195 lrg,\n",
      "0.47569796442985535 udg,\n",
      "0.37855422496795654 lra,\n",
      "0.3728896379470825 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.071721563339233\n",
      "\n",
      "Total loss: 0.011792877689003944; that's 0.00753496028482914 task and 0.0035996907390654087 recon and 3.291137933731079 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011044644340872765\n",
      "\n",
      "Total loss: 0.01087246835231781; that's 0.006693555042147636 task and 0.003521279664710164 recon and 3.2881696224212646 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01092209156602621\n",
      "\n",
      "Total loss: 4.462601661682129:\n",
      "2.828040599822998 control,\n",
      "0.4261851906776428 lrg,\n",
      "0.48170506954193115 udg,\n",
      "0.36264368891716003 lra,\n",
      "0.3640272319316864 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.861465814113617\n",
      "\n",
      "Total loss: 5.367100715637207:\n",
      "3.7161800861358643 control,\n",
      "0.42864879965782166 lrg,\n",
      "0.5188701152801514 udg,\n",
      "0.32731348276138306 lra,\n",
      "0.3760879933834076 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.052197370529175\n",
      "\n",
      "Total loss: 0.011005722917616367; that's 0.006937824655324221 task and 0.0032806359231472015 recon and 3.9363155364990234 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010882805800065398\n",
      "\n",
      "Total loss: 5.434422492980957:\n",
      "3.835505485534668 control,\n",
      "0.43205225467681885 lrg,\n",
      "0.4570581018924713 udg,\n",
      "0.3336130678653717 lra,\n",
      "0.3761940896511078 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.457363922595977\n",
      "\n",
      "Total loss: 0.012123610824346542; that's 0.007088964339345694 task and 0.004206391982734203 recon and 4.1412763595581055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01135044489055872\n",
      "\n",
      "Total loss: 0.01132761687040329; that's 0.006832526531070471 task and 0.0037489691749215126 recon and 3.7306063175201416 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011914818082004786\n",
      "\n",
      "Total loss: 5.046458721160889:\n",
      "3.434657335281372 control,\n",
      "0.4605616331100464 lrg,\n",
      "0.4601201117038727 udg,\n",
      "0.35131847858428955 lra,\n",
      "0.33980152010917664 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.658191394805908\n",
      "\n",
      "Total loss: 0.0116637097671628; that's 0.007140406873077154 task and 0.0037195454351603985 recon and 4.018789291381836 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011789885023608804\n",
      "\n",
      "Total loss: 5.244795799255371:\n",
      "3.716036319732666 control,\n",
      "0.3798667788505554 lrg,\n",
      "0.4472644031047821 udg,\n",
      "0.3512577414512634 lra,\n",
      "0.35037076473236084 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.682023634910584\n",
      "\n",
      "Total loss: 3.999990224838257:\n",
      "2.4582653045654297 control,\n",
      "0.4036265015602112 lrg,\n",
      "0.4304584860801697 udg,\n",
      "0.3453407287597656 lra,\n",
      "0.3622991442680359 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.413424110412597\n",
      "\n",
      "Total loss: 0.011014698073267937; that's 0.00664819311350584 task and 0.0038197452668100595 recon and 2.73380184173584 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011653249049559236\n",
      "\n",
      "Total loss: 4.647316932678223:\n",
      "3.0044198036193848 control,\n",
      "0.45824941992759705 lrg,\n",
      "0.42961254715919495 udg,\n",
      "0.3533724546432495 lra,\n",
      "0.4016627073287964 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.476305563449859\n",
      "\n",
      "Total loss: 0.011152778752148151; that's 0.006862171459943056 task and 0.0036344025284051895 recon and 3.28102445602417 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011384155657142401\n",
      "\n",
      "Total loss: 5.0257415771484375:\n",
      "3.4768357276916504 control,\n",
      "0.4378606081008911 lrg,\n",
      "0.4211178719997406 udg,\n",
      "0.3386136293411255 lra,\n",
      "0.3513140082359314 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.593270404338837\n",
      "\n",
      "Total loss: 0.011240453459322453; that's 0.006942144129425287 task and 0.003536686534062028 recon and 3.8081109523773193 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011234105536714197\n",
      "\n",
      "Total loss: 5.523272514343262:\n",
      "4.00197172164917 control,\n",
      "0.3905673921108246 lrg,\n",
      "0.4257391691207886 udg,\n",
      "0.36741840839385986 lra,\n",
      "0.3375759720802307 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.954927260875702\n",
      "\n",
      "Total loss: 0.01105688326060772; that's 0.006369624752551317 task and 0.0038227150216698647 recon and 4.32271671295166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011117328330874443\n",
      "\n",
      "Total loss: 0.011079266667366028; that's 0.006839555688202381 task and 0.0033215389121323824 recon and 4.590859413146973 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011031776992604136\n",
      "\n",
      "Total loss: 5.871977806091309:\n",
      "4.267686367034912 control,\n",
      "0.43517056107521057 lrg,\n",
      "0.44127076864242554 udg,\n",
      "0.3716495931148529 lra,\n",
      "0.3561999797821045 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.232032864093781\n",
      "\n",
      "Total loss: 0.011345741339027882; that's 0.0065805683843791485 task and 0.0036212392151355743 recon and 5.719665050506592 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010968955075368285\n",
      "\n",
      "Total loss: 6.869237422943115:\n",
      "5.3540754318237305 control,\n",
      "0.38909220695495605 lrg,\n",
      "0.4225707948207855 udg,\n",
      "0.34992268681526184 lra,\n",
      "0.3535759747028351 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.151693687438965\n",
      "\n",
      "Total loss: 4.116458415985107:\n",
      "2.4880211353302 control,\n",
      "0.46954017877578735 lrg,\n",
      "0.46439146995544434 udg,\n",
      "0.32321789860725403 lra,\n",
      "0.37128791213035583 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.9395629906654355\n",
      "\n",
      "Total loss: 0.010665042325854301; that's 0.006660435348749161 task and 0.0034476048313081264 recon and 2.7850093841552734 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010728545729070902\n",
      "\n",
      "Total loss: 0.011138010770082474; that's 0.0070202527567744255 task and 0.003496619174256921 recon and 3.105696439743042 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010919815441593528\n",
      "\n",
      "Total loss: 4.380340576171875:\n",
      "2.769721746444702 control,\n",
      "0.45282435417175293 lrg,\n",
      "0.4651218056678772 udg,\n",
      "0.3252878189086914 lra,\n",
      "0.36738499999046326 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.873242425918579\n",
      "\n",
      "Total loss: 0.009896328672766685; that's 0.00589373242110014 task and 0.0034349544439464808 recon and 2.838212013244629 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010686795404180884\n",
      "\n",
      "Total loss: 4.040823459625244:\n",
      "2.4299895763397217 control,\n",
      "0.4270073175430298 lrg,\n",
      "0.4609953463077545 udg,\n",
      "0.33753135800361633 lra,\n",
      "0.3852995038032532 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.272704420089721\n",
      "\n",
      "Total loss: 7.0648603439331055:\n",
      "5.503716945648193 control,\n",
      "0.41162270307540894 lrg,\n",
      "0.45111900568008423 udg,\n",
      "0.3161579668521881 lra,\n",
      "0.3822439908981323 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.536760160923004\n",
      "\n",
      "Total loss: 0.01091487891972065; that's 0.006564909126609564 task and 0.003204007400199771 recon and 5.7298150062561035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010687672458589077\n",
      "\n",
      "Total loss: 3.998837947845459:\n",
      "2.2954821586608887 control,\n",
      "0.4854276776313782 lrg,\n",
      "0.47598353028297424 udg,\n",
      "0.3824618458747864 lra,\n",
      "0.3594827353954315 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.736817555427551\n",
      "\n",
      "Total loss: 0.010884499177336693; that's 0.00641977321356535 task and 0.003945199307054281 recon and 2.597635507583618 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010709241051226854\n",
      "\n",
      "Total loss: 3.986829996109009:\n",
      "2.3618714809417725 control,\n",
      "0.4313878118991852 lrg,\n",
      "0.45932841300964355 udg,\n",
      "0.37278008460998535 lra,\n",
      "0.3614620268344879 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.664001533985138\n",
      "\n",
      "Total loss: 0.010222779586911201; that's 0.00625774497166276 task and 0.0034370701760053635 recon and 2.6398258209228516 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010695817731320858\n",
      "\n",
      "Total loss: 7.153621196746826:\n",
      "5.598825931549072 control,\n",
      "0.43086349964141846 lrg,\n",
      "0.43639540672302246 udg,\n",
      "0.3384525775909424 lra,\n",
      "0.34908419847488403 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.35288162946701\n",
      "\n",
      "Total loss: 0.01081923022866249; that's 0.006357972975820303 task and 0.0032922609243541956 recon and 5.8449788093566895 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010743806697428226\n",
      "\n",
      "Total loss: 0.010384929366409779; that's 0.00644714804366231 task and 0.003298464696854353 recon and 3.1965830326080322 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010630729654803873\n",
      "\n",
      "Total loss: 4.403966426849365:\n",
      "2.8128108978271484 control,\n",
      "0.4392987787723541 lrg,\n",
      "0.4173027276992798 udg,\n",
      "0.3592991530895233 lra,\n",
      "0.3752548396587372 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.725439200401306\n",
      "\n",
      "Total loss: 6.120142459869385:\n",
      "4.531290054321289 control,\n",
      "0.42760229110717773 lrg,\n",
      "0.44463106989860535 udg,\n",
      "0.356939435005188 lra,\n",
      "0.3596796691417694 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.795835156440734\n",
      "\n",
      "Total loss: 0.01081661507487297; that's 0.006411782931536436 task and 0.0034302780404686928 recon and 4.872771739959717 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010860932022333146\n",
      "\n",
      "Total loss: 0.009924203157424927; that's 0.0062765213660895824 task and 0.003085906384512782 recon and 2.8088784217834473 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010616622241213918\n",
      "\n",
      "Total loss: 4.01657247543335:\n",
      "2.4688501358032227 control,\n",
      "0.41875237226486206 lrg,\n",
      "0.43279266357421875 udg,\n",
      "0.34500953555107117 lra,\n",
      "0.3511678874492645 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.336397655010224\n",
      "\n",
      "Total loss: 5.545974254608154:\n",
      "3.996281385421753 control,\n",
      "0.42792993783950806 lrg,\n",
      "0.43655428290367126 udg,\n",
      "0.3414994776248932 lra,\n",
      "0.3437090516090393 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.811958990097046\n",
      "\n",
      "Total loss: 0.010648440569639206; that's 0.0063003841787576675 task and 0.0034975006710737944 recon and 4.252775192260742 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010792344585061073\n",
      "\n",
      "Total loss: 0.010723805986344814; that's 0.0062825339846313 task and 0.0033747749403119087 recon and 5.332488059997559 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01077116945758462\n",
      "\n",
      "Total loss: 6.575948238372803:\n",
      "5.028542518615723 control,\n",
      "0.37993696331977844 lrg,\n",
      "0.4233535826206207 udg,\n",
      "0.3553779721260071 lra,\n",
      "0.3887367844581604 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.9464971685409544\n",
      "\n",
      "Total loss: 4.843898773193359:\n",
      "3.3070731163024902 control,\n",
      "0.42805394530296326 lrg,\n",
      "0.42590680718421936 udg,\n",
      "0.33713942766189575 lra,\n",
      "0.3457256555557251 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.69904746055603\n",
      "\n",
      "Total loss: 0.010537193156778812; that's 0.006464923266321421 task and 0.003361048875376582 recon and 3.556107997894287 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01075465489178896\n",
      "\n",
      "Total loss: 4.3561811447143555:\n",
      "2.818179130554199 control,\n",
      "0.401477575302124 lrg,\n",
      "0.4119541049003601 udg,\n",
      "0.3705819547176361 lra,\n",
      "0.3539879322052002 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.649247827529908\n",
      "\n",
      "Total loss: 0.010619902983307838; that's 0.006594486068934202 task and 0.0033861231058835983 recon and 3.1964659690856934 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010635806461796165\n",
      "\n",
      "Total loss: 0.010366952046751976; that's 0.00660555949434638 task and 0.0032022870145738125 recon and 2.795527696609497 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010463114026933909\n",
      "\n",
      "Total loss: 3.9790687561035156:\n",
      "2.463592052459717 control,\n",
      "0.3834127187728882 lrg,\n",
      "0.4387185871601105 udg,\n",
      "0.3386199474334717 lra,\n",
      "0.35472527146339417 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.448419377803803\n",
      "\n",
      "Total loss: 0.01074098888784647; that's 0.006746429949998856 task and 0.0032956579234451056 recon and 3.49450421333313 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010479724211618304\n",
      "\n",
      "Total loss: 4.895461082458496:\n",
      "3.233693838119507 control,\n",
      "0.45416364073753357 lrg,\n",
      "0.48529428243637085 udg,\n",
      "0.3394467830657959 lra,\n",
      "0.3828631341457367 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.4050768995285035\n",
      "\n",
      "Total loss: 4.248104572296143:\n",
      "2.620401382446289 control,\n",
      "0.4370523989200592 lrg,\n",
      "0.5045288801193237 udg,\n",
      "0.33550265431404114 lra,\n",
      "0.3506194055080414 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.274938833713532\n",
      "\n",
      "Total loss: 0.010286732576787472; that's 0.006600404158234596 task and 0.0030958347488194704 recon and 2.952467918395996 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010506084645166993\n",
      "\n",
      "Total loss: 0.010775687173008919; that's 0.006932769436389208 task and 0.003269751323387027 recon and 2.8658313751220703 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010431205667555333\n",
      "\n",
      "Total loss: 4.122379302978516:\n",
      "2.5155303478240967 control,\n",
      "0.4307468831539154 lrg,\n",
      "0.4689241647720337 udg,\n",
      "0.3541926443576813 lra,\n",
      "0.3529854416847229 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.276142499446869\n",
      "\n",
      "Total loss: 4.3095574378967285:\n",
      "2.691457748413086 control,\n",
      "0.4531891345977783 lrg,\n",
      "0.4806937277317047 udg,\n",
      "0.3537755310535431 lra,\n",
      "0.3304411768913269 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.305752627849579\n",
      "\n",
      "Total loss: 0.00947420485317707; that's 0.005746311973780394 task and 0.003128885291516781 recon and 2.9950385093688965 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010340122794732452\n",
      "\n",
      "Total loss: 4.007888317108154:\n",
      "2.343336343765259 control,\n",
      "0.5039060115814209 lrg,\n",
      "0.459121435880661 udg,\n",
      "0.3618052899837494 lra,\n",
      "0.339719295501709 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.238103539943695\n",
      "\n",
      "Total loss: 0.010445131920278072; that's 0.006793576758354902 task and 0.003111018566414714 recon and 2.702685832977295 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010357606522738934\n",
      "\n",
      "Total loss: 0.0159310232847929; that's 0.009282916784286499 task and 0.005522348452359438 recon and 5.628793716430664 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011293338993564248\n",
      "\n",
      "Total loss: 6.896933555603027:\n",
      "5.2960309982299805 control,\n",
      "0.4286089241504669 lrg,\n",
      "0.4913937747478485 udg,\n",
      "0.32386496663093567 lra,\n",
      "0.35703495144844055 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.827692627906799\n",
      "\n",
      "Total loss: 6.191658020019531:\n",
      "4.621365070343018 control,\n",
      "0.4205905795097351 lrg,\n",
      "0.45270058512687683 udg,\n",
      "0.33742162585258484 lra,\n",
      "0.35958054661750793 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.054004893302918\n",
      "\n",
      "Total loss: 0.01060571614652872; that's 0.006278528366237879 task and 0.0033522455487400293 recon and 4.8747100830078125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01210259595885873\n",
      "\n",
      "Total loss: 6.676517009735107:\n",
      "5.150420188903809 control,\n",
      "0.3922269344329834 lrg,\n",
      "0.4683910608291626 udg,\n",
      "0.34995099902153015 lra,\n",
      "0.31552788615226746 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.964658875465393\n",
      "\n",
      "Total loss: 0.01028124988079071; that's 0.006045338697731495 task and 0.0031473725102841854 recon and 5.442696571350098 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010900043779984117\n",
      "\n",
      "Total loss: 0.010459122247993946; that's 0.006411073263734579 task and 0.003334418870508671 recon and 3.568154811859131 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01064261570572853\n",
      "\n",
      "Total loss: 4.81114387512207:\n",
      "3.242755651473999 control,\n",
      "0.4396529197692871 lrg,\n",
      "0.4301903545856476 udg,\n",
      "0.34276503324508667 lra,\n",
      "0.35578030347824097 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.672446527481079\n",
      "\n",
      "Total loss: 0.009895356371998787; that's 0.006083522457629442 task and 0.0031487098895013332 recon and 3.3156182765960693 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010461690109223128\n",
      "\n",
      "Total loss: 4.578208923339844:\n",
      "2.952867031097412 control,\n",
      "0.4069361686706543 lrg,\n",
      "0.4992465376853943 udg,\n",
      "0.3809660077095032 lra,\n",
      "0.33819302916526794 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.730868628025055\n",
      "\n",
      "Total loss: 0.010775336995720863; that's 0.0067266784608364105 task and 0.003396512707695365 recon and 3.2607266902923584 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01037926464341581\n",
      "\n",
      "Total loss: 4.501568794250488:\n",
      "2.9379401206970215 control,\n",
      "0.41633710265159607 lrg,\n",
      "0.47538119554519653 udg,\n",
      "0.3361313045024872 lra,\n",
      "0.33577898144721985 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.542090852260589\n",
      "\n",
      "Total loss: 5.020724296569824:\n",
      "3.3455944061279297 control,\n",
      "0.5015535950660706 lrg,\n",
      "0.48596280813217163 udg,\n",
      "0.3269028067588806 lra,\n",
      "0.360710471868515 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.507994725704193\n",
      "\n",
      "Total loss: 0.00960712693631649; that's 0.005698549095541239 task and 0.0031587930861860514 recon and 3.7489213943481445 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010290454858914017\n",
      "\n",
      "Total loss: 4.800475120544434:\n",
      "3.2122957706451416 control,\n",
      "0.4124520421028137 lrg,\n",
      "0.4559505581855774 udg,\n",
      "0.3666016161441803 lra,\n",
      "0.35317540168762207 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.437839398384094\n",
      "\n",
      "Total loss: 0.010737106204032898; that's 0.0066166166216135025 task and 0.0034033586271107197 recon and 3.5856571197509766 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010345887644216418\n",
      "\n",
      "Total loss: 0.010168297216296196; that's 0.006330627948045731 task and 0.00317826634272933 recon and 3.297011137008667 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010389806739985942\n",
      "\n",
      "Total loss: 4.401269912719727:\n",
      "2.8366944789886475 control,\n",
      "0.4390558898448944 lrg,\n",
      "0.43317654728889465 udg,\n",
      "0.34706199169158936 lra,\n",
      "0.3452812731266022 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.383846218585968\n",
      "\n",
      "Total loss: 7.499465465545654:\n",
      "5.866666316986084 control,\n",
      "0.5038415193557739 lrg,\n",
      "0.47211018204689026 udg,\n",
      "0.33275899291038513 lra,\n",
      "0.3240884840488434 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.706043565273285\n",
      "\n",
      "Total loss: 0.012090707197785378; that's 0.007020856253802776 task and 0.0038329046219587326 recon and 6.1847333908081055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01042753191664815\n",
      "\n",
      "Total loss: 4.248388767242432:\n",
      "2.672480583190918 control,\n",
      "0.43425169587135315 lrg,\n",
      "0.43946847319602966 udg,\n",
      "0.34984010457992554 lra,\n",
      "0.3523479998111725 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.729400396347046\n",
      "\n",
      "Total loss: 0.011262585408985615; that's 0.006901102606207132 task and 0.0037841119337826967 recon and 2.8868510723114014 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012319740280508995\n",
      "\n",
      "Total loss: 0.011790079064667225; that's 0.007135741412639618 task and 0.003444277448579669 recon and 6.050300598144531 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010798715380951762\n",
      "\n",
      "Total loss: 7.389414310455322:\n",
      "5.698753356933594 control,\n",
      "0.477681040763855 lrg,\n",
      "0.4926919639110565 udg,\n",
      "0.3492748439311981 lra,\n",
      "0.37101298570632935 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.4923997139930725\n",
      "\n",
      "Total loss: 5.898566246032715:\n",
      "4.314553260803223 control,\n",
      "0.47719237208366394 lrg,\n",
      "0.4310343265533447 udg,\n",
      "0.3377736806869507 lra,\n",
      "0.3380122482776642 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.021885280609131\n",
      "\n",
      "Total loss: 0.010545196942985058; that's 0.006253195460885763 task and 0.003366189543157816 recon and 4.629061222076416 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010820777267217635\n",
      "\n",
      "Total loss: 0.010545055381953716; that's 0.006512225139886141 task and 0.0034241119865328074 recon and 3.0435914993286133 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010509607959538697\n",
      "\n",
      "Total loss: 4.2172932624816895:\n",
      "2.6411402225494385 control,\n",
      "0.415473073720932 lrg,\n",
      "0.4616614282131195 udg,\n",
      "0.3582196533679962 lra,\n",
      "0.3407992422580719 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.951015281677246\n",
      "\n",
      "Total loss: 0.01094517856836319; that's 0.006521561648696661 task and 0.003421436296775937 recon and 5.010903835296631 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01082702687010169\n",
      "\n",
      "Total loss: 6.128276824951172:\n",
      "4.580672264099121 control,\n",
      "0.39902350306510925 lrg,\n",
      "0.45411616563796997 udg,\n",
      "0.3411872386932373 lra,\n",
      "0.3532770574092865 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.696384124755859\n",
      "\n",
      "Total loss: 5.805811405181885:\n",
      "4.252816200256348 control,\n",
      "0.3967002332210541 lrg,\n",
      "0.43910935521125793 udg,\n",
      "0.3614470064640045 lra,\n",
      "0.3557385504245758 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.027961149215698\n",
      "\n",
      "Total loss: 0.011145943775773048; that's 0.006740445736795664 task and 0.00348974228836596 recon and 4.578777313232422 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010740268984809518\n",
      "\n",
      "Total loss: 6.347041130065918:\n",
      "4.8319525718688965 control,\n",
      "0.43112048506736755 lrg,\n",
      "0.41665738821029663 udg,\n",
      "0.3341716229915619 lra,\n",
      "0.33313918113708496 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.784101867675782\n",
      "\n",
      "Total loss: 0.01053356472402811; that's 0.006130545400083065 task and 0.0033714119344949722 recon and 5.1580376625061035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010550112957134842\n",
      "\n",
      "Total loss: 5.736486911773682:\n",
      "4.198143005371094 control,\n",
      "0.4790034294128418 lrg,\n",
      "0.41329240798950195 udg,\n",
      "0.3325914144515991 lra,\n",
      "0.3134565055370331 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.170606374740601\n",
      "\n",
      "Total loss: 0.010438969358801842; that's 0.006311037577688694 task and 0.0032258578576147556 recon and 4.510365962982178 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010679190196096897\n",
      "\n",
      "Total loss: 0.00959695503115654; that's 0.005626267287880182 task and 0.0031201078090816736 recon and 4.2528977394104 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010611220179125667\n",
      "\n",
      "Total loss: 5.521491050720215:\n",
      "4.002406597137451 control,\n",
      "0.39060455560684204 lrg,\n",
      "0.45529767870903015 udg,\n",
      "0.34079453349113464 lra,\n",
      "0.33238768577575684 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.764108271598816\n",
      "\n",
      "Total loss: 0.011074194684624672; that's 0.0066721560433506966 task and 0.003326102625578642 recon and 5.379683494567871 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010754202688112856\n",
      "\n",
      "Total loss: 6.5478196144104:\n",
      "5.017917156219482 control,\n",
      "0.41403767466545105 lrg,\n",
      "0.4420958459377289 udg,\n",
      "0.34226515889167786 lra,\n",
      "0.3315039277076721 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.9467225265502925\n",
      "\n",
      "Total loss: 0.009607821702957153; that's 0.005709659308195114 task and 0.003207047004252672 recon and 3.4555771350860596 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010434541022405028\n",
      "\n",
      "Total loss: 4.681881427764893:\n",
      "3.128753185272217 control,\n",
      "0.39933672547340393 lrg,\n",
      "0.4475122392177582 udg,\n",
      "0.33174851536750793 lra,\n",
      "0.37453073263168335 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.8739040565490725\n",
      "\n",
      "Total loss: 4.738065242767334:\n",
      "3.2229185104370117 control,\n",
      "0.3698354661464691 lrg,\n",
      "0.4561629593372345 udg,\n",
      "0.32735535502433777 lra,\n",
      "0.3617928922176361 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.600803232192993\n",
      "\n",
      "Total loss: 0.009956499561667442; that's 0.006018355954438448 task and 0.003249227534979582 recon and 3.4445815086364746 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010532988123595715\n",
      "\n",
      "Total loss: 0.010986469686031342; that's 0.006665273569524288 task and 0.0033213903661817312 recon and 4.999029159545898 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010565734058618546\n",
      "\n",
      "Total loss: 6.330911636352539:\n",
      "4.679105281829834 control,\n",
      "0.438687264919281 lrg,\n",
      "0.4671274721622467 udg,\n",
      "0.3545723855495453 lra,\n",
      "0.39141955971717834 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.013108582496643\n",
      "\n",
      "Total loss: 0.010467899031937122; that's 0.006175816524773836 task and 0.0033027403987944126 recon and 4.946710586547852 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010310339322313667\n",
      "\n",
      "Total loss: 6.333463191986084:\n",
      "4.653632640838623 control,\n",
      "0.45340874791145325 lrg,\n",
      "0.47837942838668823 udg,\n",
      "0.36808156967163086 lra,\n",
      "0.3799610137939453 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.18181088924408\n",
      "\n",
      "Total loss: 0.012130494229495525; that's 0.007508566603064537 task and 0.003684977302327752 recon and 4.684752464294434 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010880034202709794\n",
      "\n",
      "Total loss: 5.986055850982666:\n",
      "4.3471784591674805 control,\n",
      "0.4632546901702881 lrg,\n",
      "0.43536341190338135 udg,\n",
      "0.3691444993019104 lra,\n",
      "0.3711148202419281 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.363436734676361\n",
      "\n",
      "Total loss: 4.9533185958862305:\n",
      "3.386789321899414 control,\n",
      "0.45109695196151733 lrg,\n",
      "0.4082599878311157 udg,\n",
      "0.368486613035202 lra,\n",
      "0.3386858403682709 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.868146266937256\n",
      "\n",
      "Total loss: 0.010830153711140156; that's 0.006855181884020567 task and 0.003267022781074047 recon and 3.5397469997406006 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010793833248317241\n",
      "\n",
      "Total loss: 4.092531204223633:\n",
      "2.4752516746520996 control,\n",
      "0.42937085032463074 lrg,\n",
      "0.48021748661994934 udg,\n",
      "0.34533748030662537 lra,\n",
      "0.3623538911342621 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.562221331596374\n",
      "\n",
      "Total loss: 0.009227828122675419; that's 0.005489884410053492 task and 0.003175031393766403 recon and 2.8145642280578613 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010272004287689923\n",
      "\n",
      "Total loss: 6.29543399810791:\n",
      "4.764141082763672 control,\n",
      "0.3808876574039459 lrg,\n",
      "0.4580436646938324 udg,\n",
      "0.3544979691505432 lra,\n",
      "0.33786410093307495 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.617352843284607\n",
      "\n",
      "Total loss: 0.009592194110155106; that's 0.005613293964415789 task and 0.0029725481290370226 recon and 5.031761169433594 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010429859617725015\n",
      "\n",
      "Total loss: 0.010502111166715622; that's 0.006452631205320358 task and 0.003080114023759961 recon and 4.84683084487915 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01042965498752892\n",
      "\n",
      "Total loss: 6.115790367126465:\n",
      "4.5829973220825195 control,\n",
      "0.3999350965023041 lrg,\n",
      "0.4755030870437622 udg,\n",
      "0.3018922209739685 lra,\n",
      "0.35546258091926575 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.80997079372406\n",
      "\n",
      "Total loss: 0.010732796974480152; that's 0.006974000483751297 task and 0.0030029884073883295 recon and 3.7790422439575195 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010412453496828676\n",
      "\n",
      "Total loss: 5.028768539428711:\n",
      "3.454252243041992 control,\n",
      "0.4134294092655182 lrg,\n",
      "0.47122249007225037 udg,\n",
      "0.3494674265384674 lra,\n",
      "0.3403967618942261 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.937512340545655\n",
      "\n",
      "Total loss: 5.726497173309326:\n",
      "4.135629653930664 control,\n",
      "0.39617326855659485 lrg,\n",
      "0.4293423891067505 udg,\n",
      "0.3598233163356781 lra,\n",
      "0.40552836656570435 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.827081570625305\n",
      "\n",
      "Total loss: 0.011175066232681274; that's 0.0067370873875916 task and 0.003553097601979971 recon and 4.424407958984375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010328491320833563\n",
      "\n",
      "Total loss: 0.01040029339492321; that's 0.006500727962702513 task and 0.0031923027709126472 recon and 3.53631591796875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010386444581672549\n",
      "\n",
      "Total loss: 4.787629127502441:\n",
      "3.2088329792022705 control,\n",
      "0.4082931876182556 lrg,\n",
      "0.46503299474716187 udg,\n",
      "0.3425818085670471 lra,\n",
      "0.362888365983963 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.918721981048584\n",
      "\n",
      "Total loss: 0.010602233931422234; that's 0.006493769120424986 task and 0.003147771814838052 recon and 4.803465843200684 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010166334453970194\n",
      "\n",
      "Total loss: 6.004988670349121:\n",
      "4.413282871246338 control,\n",
      "0.4121878445148468 lrg,\n",
      "0.4339195787906647 udg,\n",
      "0.3691321015357971 lra,\n",
      "0.3764660954475403 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.924166431427002\n",
      "\n",
      "Total loss: 0.011206157505512238; that's 0.0069151571951806545 task and 0.0033991080708801746 recon and 4.45945930480957 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010413629813119768\n",
      "\n",
      "Total loss: 5.629371643066406:\n",
      "4.140255928039551 control,\n",
      "0.3636395335197449 lrg,\n",
      "0.41855305433273315 udg,\n",
      "0.35547518730163574 lra,\n",
      "0.3514482378959656 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.395175089836121\n",
      "\n",
      "Total loss: 0.01062585785984993; that's 0.006385427433997393 task and 0.003172887023538351 recon and 5.337719440460205 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010470102010294795\n",
      "\n",
      "Total loss: 6.483113765716553:\n",
      "4.990082740783691 control,\n",
      "0.382742315530777 lrg,\n",
      "0.42208677530288696 udg,\n",
      "0.35566526651382446 lra,\n",
      "0.3325366973876953 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.916182374954223\n",
      "\n",
      "Total loss: 0.009922363795340061; that's 0.006049634423106909 task and 0.0030523177701979876 recon and 4.1020588874816895 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010306654842570423\n",
      "\n",
      "Total loss: 5.2988715171813965:\n",
      "3.764371871948242 control,\n",
      "0.3967697322368622 lrg,\n",
      "0.4412696957588196 udg,\n",
      "0.33069881796836853 lra,\n",
      "0.36576133966445923 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.503137044906616\n",
      "\n",
      "Total loss: 5.786149024963379:\n",
      "4.229930400848389 control,\n",
      "0.4134191870689392 lrg,\n",
      "0.4605535864830017 udg,\n",
      "0.3082031309604645 lra,\n",
      "0.37404265999794006 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.630836305618286\n",
      "\n",
      "Total loss: 0.010268328711390495; that's 0.006274915300309658 task and 0.0030835906509310007 recon and 4.549116134643555 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010332357231527567\n",
      "\n",
      "Total loss: 6.103792667388916:\n",
      "4.604207515716553 control,\n",
      "0.41275832056999207 lrg,\n",
      "0.43436750769615173 udg,\n",
      "0.3352150321006775 lra,\n",
      "0.3172440826892853 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.983750932216644\n",
      "\n",
      "Total loss: 0.009692382998764515; that's 0.005715650040656328 task and 0.0029959790408611298 recon and 4.903770446777344 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0102399084251374\n",
      "\n",
      "Total loss: 5.363034725189209:\n",
      "3.794062852859497 control,\n",
      "0.4016551971435547 lrg,\n",
      "0.48311007022857666 udg,\n",
      "0.3309948146343231 lra,\n",
      "0.3532121479511261 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.963336257934571\n",
      "\n",
      "Total loss: 0.010179128497838974; that's 0.0063042719848454 task and 0.003055181121453643 recon and 4.098377704620361 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010292760683223606\n",
      "\n",
      "Total loss: 6.171119689941406:\n",
      "4.617160797119141 control,\n",
      "0.4037002623081207 lrg,\n",
      "0.49305886030197144 udg,\n",
      "0.3368910551071167 lra,\n",
      "0.3203088045120239 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.8170460510253905\n",
      "\n",
      "Total loss: 0.01000419445335865; that's 0.005879614967852831 task and 0.003146268893033266 recon and 4.891552448272705 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010485209980979562\n",
      "\n",
      "Total loss: 5.745234489440918:\n",
      "4.158905029296875 control,\n",
      "0.4628102481365204 lrg,\n",
      "0.4245816469192505 udg,\n",
      "0.3354276120662689 lra,\n",
      "0.36351022124290466 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.350808765888214\n",
      "\n",
      "Total loss: 0.010777599178254604; that's 0.006687316577881575 task and 0.0031883602496236563 recon and 4.509612083435059 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010173264695331453\n",
      "\n",
      "Total loss: 0.00968053936958313; that's 0.0056176199577748775 task and 0.0032703743781894445 recon and 3.962726593017578 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010232211193069815\n",
      "\n",
      "Total loss: 5.220327854156494:\n",
      "3.6439108848571777 control,\n",
      "0.45171016454696655 lrg,\n",
      "0.4676484167575836 udg,\n",
      "0.3255406618118286 lra,\n",
      "0.3315178155899048 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.503544311523438\n",
      "\n",
      "Total loss: 4.514893531799316:\n",
      "3.025956392288208 control,\n",
      "0.3835063576698303 lrg,\n",
      "0.43780434131622314 udg,\n",
      "0.3229508101940155 lra,\n",
      "0.34467536211013794 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.3208884382247925\n",
      "\n",
      "Total loss: 0.010186451487243176; that's 0.0065858070738613605 task and 0.0029448161367326975 recon and 3.2791409492492676 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010311324810609222\n",
      "\n",
      "Total loss: 0.010639797896146774; that's 0.0068599930964410305 task and 0.003140027401968837 recon and 3.19888973236084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010149170374497772\n",
      "\n",
      "Total loss: 4.484952449798584:\n",
      "2.8672473430633545 control,\n",
      "0.4184414744377136 lrg,\n",
      "0.4818917214870453 udg,\n",
      "0.3629542887210846 lra,\n",
      "0.354417622089386 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.808531365394592\n",
      "\n",
      "Total loss: 0.011180168949067593; that's 0.006463089492172003 task and 0.00353431049734354 recon and 5.913848876953125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01025632156059146\n",
      "\n",
      "Total loss: 7.07610559463501:\n",
      "5.57246732711792 control,\n",
      "0.3914874494075775 lrg,\n",
      "0.45362377166748047 udg,\n",
      "0.3451389968395233 lra,\n",
      "0.3133878707885742 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.607519392967224\n",
      "\n",
      "Total loss: 0.009338434785604477; that's 0.00575492437928915 task and 0.0029512003529816866 recon and 3.1615498065948486 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010094307092949749\n",
      "\n",
      "Total loss: 4.3920512199401855:\n",
      "2.8028314113616943 control,\n",
      "0.42615243792533875 lrg,\n",
      "0.44901397824287415 udg,\n",
      "0.3576097786426544 lra,\n",
      "0.3564434051513672 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.001705675125122\n",
      "\n",
      "Total loss: 0.010096246376633644; that's 0.006496423855423927 task and 0.0030660706106573343 recon and 2.668762445449829 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01008701446466148\n",
      "\n",
      "Total loss: 4.068571090698242:\n",
      "2.3817965984344482 control,\n",
      "0.4698266088962555 lrg,\n",
      "0.4752362370491028 udg,\n",
      "0.3786338269710541 lra,\n",
      "0.3630777597427368 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.074658443927765\n",
      "\n",
      "Total loss: 0.010024726390838623; that's 0.006284278817474842 task and 0.003039437346160412 recon and 3.5050528049468994 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010060317460447549\n",
      "\n",
      "Total loss: 4.718558311462402:\n",
      "3.1006319522857666 control,\n",
      "0.44907209277153015 lrg,\n",
      "0.47829943895339966 udg,\n",
      "0.3358346223831177 lra,\n",
      "0.35472017526626587 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.170678749084472\n",
      "\n",
      "Total loss: 4.7663445472717285:\n",
      "3.2079875469207764 control,\n",
      "0.4389810860157013 lrg,\n",
      "0.4304467737674713 udg,\n",
      "0.33584272861480713 lra,\n",
      "0.3530866503715515 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.0702972412109375\n",
      "\n",
      "Total loss: 0.00946908537298441; that's 0.005890092812478542 task and 0.002884679939597845 recon and 3.471564292907715 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01015601247549057\n",
      "\n",
      "Total loss: 5.351723670959473:\n",
      "3.7032389640808105 control,\n",
      "0.4487670063972473 lrg,\n",
      "0.47293660044670105 udg,\n",
      "0.3522564172744751 lra,\n",
      "0.37452447414398193 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.441245985031128\n",
      "\n",
      "Total loss: 0.010304977186024189; that's 0.006296955049037933 task and 0.003203641390427947 recon and 4.021902561187744 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009961758302524685\n",
      "\n",
      "Total loss: 0.009447108022868633; that's 0.0055473274551332 task and 0.003115918720141053 recon and 3.9193081855773926 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00993206369690597\n",
      "\n",
      "Total loss: 5.1359758377075195:\n",
      "3.5706305503845215 control,\n",
      "0.4284398555755615 lrg,\n",
      "0.4554862082004547 udg,\n",
      "0.3178274631500244 lra,\n",
      "0.3635919988155365 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.985742998123169\n",
      "\n",
      "Total loss: 3.781888484954834:\n",
      "2.2649974822998047 control,\n",
      "0.4173603057861328 lrg,\n",
      "0.404141366481781 udg,\n",
      "0.3635711669921875 lra,\n",
      "0.3318180739879608 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.9020050072669985\n",
      "\n",
      "Total loss: 0.009297101758420467; that's 0.005728990770876408 task and 0.003062095958739519 recon and 2.530071496963501 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00975268505513668\n",
      "\n",
      "Total loss: 0.009174257516860962; that's 0.005593837704509497 task and 0.0030179647728800774 recon and 2.8122799396514893 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00987062112428248\n",
      "\n",
      "Total loss: 4.1097517013549805:\n",
      "2.4883694648742676 control,\n",
      "0.4536137580871582 lrg,\n",
      "0.4332263469696045 udg,\n",
      "0.3548228144645691 lra,\n",
      "0.37971943616867065 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.9952275466918947\n",
      "\n",
      "Total loss: 6.0376482009887695:\n",
      "4.444685935974121 control,\n",
      "0.43685880303382874 lrg,\n",
      "0.46719107031822205 udg,\n",
      "0.3452753722667694 lra,\n",
      "0.34363701939582825 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.519370660781861\n",
      "\n",
      "Total loss: 0.009932363405823708; that's 0.005802687257528305 task and 0.0031830337829887867 recon and 4.733214378356934 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010120317665860057\n",
      "\n",
      "Total loss: 0.009837648831307888; that's 0.006033789366483688 task and 0.0029362631030380726 recon and 4.337984561920166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010203393157571555\n",
      "\n",
      "Total loss: 5.549554347991943:\n",
      "4.025383472442627 control,\n",
      "0.39870673418045044 lrg,\n",
      "0.43396180868148804 udg,\n",
      "0.34388694167137146 lra,\n",
      "0.34761518239974976 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.831406545639038\n",
      "\n",
      "Total loss: 5.809438228607178:\n",
      "4.29653787612915 control,\n",
      "0.3736797273159027 lrg,\n",
      "0.44739335775375366 udg,\n",
      "0.3378896415233612 lra,\n",
      "0.3539375364780426 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.918437061309814\n",
      "\n",
      "Total loss: 0.009404230862855911; that's 0.0055290404707193375 task and 0.002958400174975395 recon and 4.583951473236084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01007342653349042\n",
      "\n",
      "Total loss: 4.183321475982666:\n",
      "2.5962209701538086 control,\n",
      "0.4681645929813385 lrg,\n",
      "0.4388274550437927 udg,\n",
      "0.3467128872871399 lra,\n",
      "0.3333953320980072 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.182581348419189\n",
      "\n",
      "Total loss: 0.009570598602294922; that's 0.0060647474601864815 task and 0.0029377879109233618 recon and 2.8403170108795166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00990651291795075\n",
      "\n",
      "Total loss: 4.18200159072876:\n",
      "2.5979726314544678 control,\n",
      "0.40268474817276 lrg,\n",
      "0.4793021082878113 udg,\n",
      "0.3424791395664215 lra,\n",
      "0.3595626950263977 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.275911128520965\n",
      "\n",
      "Total loss: 0.009847222827374935; that's 0.006201138254255056 task and 0.0030586475040763617 recon and 2.9371867179870605 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009908081954345107\n",
      "\n",
      "Total loss: 0.008837280794978142; that's 0.005383805371820927 task and 0.0028355035465210676 recon and 3.0898585319519043 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00980378800071776\n",
      "\n",
      "Total loss: 4.333212852478027:\n",
      "2.716914176940918 control,\n",
      "0.4294971525669098 lrg,\n",
      "0.4282306134700775 udg,\n",
      "0.38851526379585266 lra,\n",
      "0.3700556457042694 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.313126399517059\n",
      "\n",
      "Total loss: 0.009575746022164822; that's 0.005693248938769102 task and 0.003020135685801506 recon and 4.311803817749023 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009906483860686422\n",
      "\n",
      "Total loss: 5.447782516479492:\n",
      "3.9200119972229004 control,\n",
      "0.40763169527053833 lrg,\n",
      "0.43214407563209534 udg,\n",
      "0.3257153332233429 lra,\n",
      "0.3622789978981018 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.342173082828522\n",
      "\n",
      "Total loss: 4.937742710113525:\n",
      "3.4564297199249268 control,\n",
      "0.38614556193351746 lrg,\n",
      "0.4297407865524292 udg,\n",
      "0.33333510160446167 lra,\n",
      "0.33209192752838135 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.602676057815552\n",
      "\n",
      "Total loss: 0.00988114532083273; that's 0.0061602662317454815 task and 0.0029835954774171114 recon and 3.6864173412323 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009747850187122821\n",
      "\n",
      "Total loss: 5.118331432342529:\n",
      "3.49914288520813 control,\n",
      "0.4382938742637634 lrg,\n",
      "0.46261489391326904 udg,\n",
      "0.3577438294887543 lra,\n",
      "0.3605358898639679 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.213690092563629\n",
      "\n",
      "Total loss: 0.009864667430520058; that's 0.006170138716697693 task and 0.002936961594969034 recon and 3.7878360748291016 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00996087952516973\n",
      "\n",
      "Total loss: 0.008924322202801704; that's 0.005153045058250427 task and 0.002992408350110054 recon and 3.8943448066711426 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009745076429098845\n",
      "\n",
      "Total loss: 5.022864818572998:\n",
      "3.4988138675689697 control,\n",
      "0.3857743442058563 lrg,\n",
      "0.4265727698802948 udg,\n",
      "0.3449251055717468 lra,\n",
      "0.3667788505554199 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.945598955154419\n",
      "\n",
      "Total loss: 4.9467315673828125:\n",
      "3.4516735076904297 control,\n",
      "0.3847450613975525 lrg,\n",
      "0.42305421829223633 udg,\n",
      "0.34510713815689087 lra,\n",
      "0.342151403427124 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.280639095306396\n",
      "\n",
      "Total loss: 0.009496643207967281; that's 0.005725902039557695 task and 0.0030108890496194363 recon and 3.799260139465332 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009828994292765856\n",
      "\n",
      "Total loss: 0.009343677200376987; that's 0.005507023073732853 task and 0.0031705466099083424 recon and 3.330533504486084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009565459610894323\n",
      "\n",
      "Total loss: 4.575263977050781:\n",
      "2.98740553855896 control,\n",
      "0.43755173683166504 lrg,\n",
      "0.48837950825691223 udg,\n",
      "0.3388948142528534 lra,\n",
      "0.3230323791503906 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.092349801063538\n",
      "\n",
      "Total loss: 4.325874328613281:\n",
      "2.7001290321350098 control,\n",
      "0.46149200201034546 lrg,\n",
      "0.47525888681411743 udg,\n",
      "0.35261696577072144 lra,\n",
      "0.33637720346450806 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.837477645874023\n",
      "\n",
      "Total loss: 0.009783062152564526; that's 0.00615266477689147 task and 0.0030355460476130247 recon and 2.974256992340088 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009616581359878182\n",
      "\n",
      "Total loss: 5.054950714111328:\n",
      "3.4074254035949707 control,\n",
      "0.4057995080947876 lrg,\n",
      "0.5081708431243896 udg,\n",
      "0.37176698446273804 lra,\n",
      "0.3617877960205078 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.779491386413574\n",
      "\n",
      "Total loss: 0.010298114269971848; that's 0.006433191709220409 task and 0.0031284175347536802 recon and 3.682525396347046 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009577077981084585\n",
      "\n",
      "Total loss: 0.010117738507688046; that's 0.006493972148746252 task and 0.0029740750323981047 recon and 3.2484586238861084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009444751525297761\n",
      "\n",
      "Total loss: 4.317605495452881:\n",
      "2.7702748775482178 control,\n",
      "0.40234488248825073 lrg,\n",
      "0.4664476215839386 udg,\n",
      "0.35892021656036377 lra,\n",
      "0.3196179270744324 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.158447387218476\n",
      "\n",
      "Total loss: 0.010405213572084904; that's 0.006814707536250353 task and 0.0028460375033318996 recon and 3.722341537475586 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009627611646428703\n",
      "\n",
      "Total loss: 4.950515270233154:\n",
      "3.29781174659729 control,\n",
      "0.4276405870914459 lrg,\n",
      "0.49862056970596313 udg,\n",
      "0.36316734552383423 lra,\n",
      "0.3632749617099762 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.966747779846191\n",
      "\n",
      "Total loss: 0.009870724752545357; that's 0.006038842257112265 task and 0.003026016987860203 recon and 4.029329299926758 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009600865682587027\n",
      "\n",
      "Total loss: 5.297504425048828:\n",
      "3.651479482650757 control,\n",
      "0.4186827540397644 lrg,\n",
      "0.5038866400718689 udg,\n",
      "0.3503655195236206 lra,\n",
      "0.37308982014656067 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.86082102060318\n",
      "\n",
      "Total loss: 0.009400789625942707; that's 0.005995193962007761 task and 0.0027243560180068016 recon and 3.406198024749756 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009663982382044196\n",
      "\n",
      "Total loss: 4.692910671234131:\n",
      "3.0744478702545166 control,\n",
      "0.433180034160614 lrg,\n",
      "0.4624364674091339 udg,\n",
      "0.3446890711784363 lra,\n",
      "0.37815701961517334 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.757073786258697\n",
      "\n",
      "Total loss: 0.009801147505640984; that's 0.0062288870103657246 task and 0.002795905340462923 recon and 3.881774425506592 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009571493873372673\n",
      "\n",
      "Total loss: 5.187156677246094:\n",
      "3.5908045768737793 control,\n",
      "0.4371147155761719 lrg,\n",
      "0.444681853055954 udg,\n",
      "0.377736896276474 lra,\n",
      "0.336818665266037 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.813589820861816\n",
      "\n",
      "Total loss: 5.804021835327148:\n",
      "4.290334701538086 control,\n",
      "0.3858431577682495 lrg,\n",
      "0.4507761001586914 udg,\n",
      "0.3391636610031128 lra,\n",
      "0.337904155254364 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.7868612456321715\n",
      "\n",
      "Total loss: 0.008954804390668869; that's 0.00534781301394105 task and 0.0026933990884572268 recon and 4.567959308624268 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009704273212701082\n",
      "\n",
      "Total loss: 0.009984925389289856; that's 0.00630944175645709 task and 0.0028134232852607965 recon and 4.310302257537842 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009584715384989976\n",
      "\n",
      "Total loss: 5.453476428985596:\n",
      "3.9038074016571045 control,\n",
      "0.43762052059173584 lrg,\n",
      "0.46876174211502075 udg,\n",
      "0.32040053606033325 lra,\n",
      "0.3228861391544342 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.526278095245361\n",
      "\n",
      "Total loss: 0.009881503880023956; that's 0.006386701017618179 task and 0.0028406900819391012 recon and 3.2705628871917725 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009588598879054189\n",
      "\n",
      "Total loss: 4.534915924072266:\n",
      "2.9699318408966064 control,\n",
      "0.3951948881149292 lrg,\n",
      "0.4595094919204712 udg,\n",
      "0.38151416182518005 lra,\n",
      "0.3287660777568817 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.630099339485168\n",
      "\n",
      "Total loss: 0.009437953121960163; that's 0.005609092302620411 task and 0.003134117228910327 recon and 3.4737179279327393 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009503382444381713\n",
      "\n",
      "Total loss: 4.728254318237305:\n",
      "3.177274465560913 control,\n",
      "0.4308384656906128 lrg,\n",
      "0.43273407220840454 udg,\n",
      "0.3497972786426544 lra,\n",
      "0.33761027455329895 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.368284785747528\n",
      "\n",
      "Total loss: 0.009170712903141975; that's 0.005544102750718594 task and 0.0028098812326788902 recon and 4.083643436431885 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009487875504419208\n",
      "\n",
      "Total loss: 5.268904209136963:\n",
      "3.766453742980957 control,\n",
      "0.36523666977882385 lrg,\n",
      "0.48002928495407104 udg,\n",
      "0.32574284076690674 lra,\n",
      "0.3314419388771057 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.753574254512787\n",
      "\n",
      "Total loss: 4.4857707023620605:\n",
      "2.9132187366485596 control,\n",
      "0.4115525782108307 lrg,\n",
      "0.4940014183521271 udg,\n",
      "0.3206320106983185 lra,\n",
      "0.346365749835968 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.5655053520202635\n",
      "\n",
      "Total loss: 0.00919936690479517; that's 0.005924636032432318 task and 0.0026260993909090757 recon and 3.2431588172912598 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009463387094438076\n",
      "\n",
      "Total loss: 0.009742727503180504; that's 0.006017512176185846 task and 0.0026845342945307493 recon and 5.203406810760498 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00939024168998003\n",
      "\n",
      "Total loss: 6.509916305541992:\n",
      "4.907289505004883 control,\n",
      "0.4015633165836334 lrg,\n",
      "0.4870598614215851 udg,\n",
      "0.35146960616111755 lra,\n",
      "0.36253413558006287 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.205258440971375\n",
      "\n",
      "Total loss: 0.009671410545706749; that's 0.006178513169288635 task and 0.0029357520397752523 recon and 2.785724639892578 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009275391492992639\n",
      "\n",
      "Total loss: 3.9637868404388428:\n",
      "2.408235549926758 control,\n",
      "0.4317043125629425 lrg,\n",
      "0.4307825267314911 udg,\n",
      "0.34997501969337463 lra,\n",
      "0.34308934211730957 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.598128654956818\n",
      "\n",
      "Total loss: 0.009867582470178604; that's 0.006284571718424559 task and 0.002760029397904873 recon and 4.114911079406738 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009303627908229828\n",
      "\n",
      "Total loss: 5.297923564910889:\n",
      "3.7558908462524414 control,\n",
      "0.4293402135372162 lrg,\n",
      "0.4386792480945587 udg,\n",
      "0.3232116997241974 lra,\n",
      "0.3508016765117645 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.227388064861298\n",
      "\n",
      "Total loss: 4.814938068389893:\n",
      "3.282775640487671 control,\n",
      "0.4055632948875427 lrg,\n",
      "0.4748595654964447 udg,\n",
      "0.3197970688343048 lra,\n",
      "0.33194273710250854 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.722905831336975\n",
      "\n",
      "Total loss: 0.008341392502188683; that's 0.005033231806010008 task and 0.002588854171335697 recon and 3.596534490585327 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009364785430952906\n",
      "\n",
      "Total loss: 5.823303699493408:\n",
      "4.357750415802002 control,\n",
      "0.36688894033432007 lrg,\n",
      "0.415881484746933 udg,\n",
      "0.32866913080215454 lra,\n",
      "0.35411351919174194 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.886388788223266\n",
      "\n",
      "Total loss: 0.009546449407935143; that's 0.006018354557454586 task and 0.002591557102277875 recon and 4.682689189910889 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00948594049550593\n",
      "\n",
      "Total loss: 7.320098400115967:\n",
      "5.72652530670166 control,\n",
      "0.4705076217651367 lrg,\n",
      "0.4255922734737396 udg,\n",
      "0.32962173223495483 lra,\n",
      "0.36785146594047546 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.963301267623901\n",
      "\n",
      "Total loss: 0.009505938738584518; that's 0.0056605832651257515 task and 0.0026435749605298042 recon and 6.0089030265808105 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009311989070847631\n",
      "\n",
      "Total loss: 4.4375715255737305:\n",
      "2.877936363220215 control,\n",
      "0.3956468403339386 lrg,\n",
      "0.48023903369903564 udg,\n",
      "0.3458307981491089 lra,\n",
      "0.3379182815551758 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.24440719127655\n",
      "\n",
      "Total loss: 0.008451459929347038; that's 0.005382869392633438 task and 0.0024379552341997623 recon and 3.153179168701172 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009180551571771502\n",
      "\n",
      "Total loss: 0.009353753179311752; that's 0.005962719209492207 task and 0.0025942481588572264 recon and 3.9839298725128174 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009147205092012882\n",
      "\n",
      "Total loss: 5.307705402374268:\n",
      "3.703169584274292 control,\n",
      "0.4354110360145569 lrg,\n",
      "0.42981433868408203 udg,\n",
      "0.3837684988975525 lra,\n",
      "0.3555417060852051 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.086137595176697\n",
      "\n",
      "Total loss: 0.008213241584599018; that's 0.004969226196408272 task and 0.002401734236627817 recon and 4.211406707763672 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009127996498718857\n",
      "\n",
      "Total loss: 5.483767509460449:\n",
      "3.8806869983673096 control,\n",
      "0.4329979717731476 lrg,\n",
      "0.4765689969062805 udg,\n",
      "0.34006303548812866 lra,\n",
      "0.3534504771232605 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.039324383735657\n",
      "\n",
      "Total loss: 4.434721946716309:\n",
      "2.88966965675354 control,\n",
      "0.44276028871536255 lrg,\n",
      "0.4032030999660492 udg,\n",
      "0.346214234828949 lra,\n",
      "0.3528745770454407 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.178548951148986\n",
      "\n",
      "Total loss: 0.008377911522984505; that's 0.0050147781148552895 task and 0.0027351805474609137 recon and 3.1397628784179688 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00898660003207624\n",
      "\n",
      "Total loss: 0.009625345468521118; that's 0.006156043615192175 task and 0.002710598986595869 recon and 3.7935163974761963 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00908351233229041\n",
      "\n",
      "Total loss: 4.947054862976074:\n",
      "3.4291391372680664 control,\n",
      "0.39841365814208984 lrg,\n",
      "0.42468884587287903 udg,\n",
      "0.3424625098705292 lra,\n",
      "0.35235077142715454 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.846756281852723\n",
      "\n",
      "Total loss: 0.00859601330012083; that's 0.005167499650269747 task and 0.0025851947721093893 recon and 4.2165937423706055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009258717047050596\n",
      "\n",
      "Total loss: 5.506704807281494:\n",
      "3.907045841217041 control,\n",
      "0.42790475487709045 lrg,\n",
      "0.4645993709564209 udg,\n",
      "0.33141136169433594 lra,\n",
      "0.37574347853660583 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.085683908462524\n",
      "\n",
      "Total loss: 0.008700930513441563; that's 0.0054496899247169495 task and 0.0025628386065363884 recon and 3.442009449005127 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008971003089100123\n",
      "\n",
      "Total loss: 4.591770172119141:\n",
      "3.0624136924743652 control,\n",
      "0.42658814787864685 lrg,\n",
      "0.42154979705810547 udg,\n",
      "0.35119304060935974 lra,\n",
      "0.33002567291259766 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.81869971036911\n",
      "\n",
      "Total loss: 0.009163966402411461; that's 0.005804805550724268 task and 0.002653492381796241 recon and 3.5283446311950684 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008934660437516869\n",
      "\n",
      "Total loss: 4.6606950759887695:\n",
      "3.085968255996704 control,\n",
      "0.4249471127986908 lrg,\n",
      "0.44440948963165283 udg,\n",
      "0.3547898232936859 lra,\n",
      "0.35058072209358215 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.610308451652527\n",
      "\n",
      "Total loss: 4.522586822509766:\n",
      "2.8513433933258057 control,\n",
      "0.4881722033023834 lrg,\n",
      "0.4681224524974823 udg,\n",
      "0.3565397262573242 lra,\n",
      "0.35840871930122375 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.533076963424683\n",
      "\n",
      "Total loss: 0.008260583505034447; that's 0.005322941578924656 task and 0.002302472712472081 recon and 3.1758480072021484 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008753918167203665\n",
      "\n",
      "Total loss: 4.746224403381348:\n",
      "3.2045938968658447 control,\n",
      "0.41724541783332825 lrg,\n",
      "0.4545239806175232 udg,\n",
      "0.33394891023635864 lra,\n",
      "0.3359123468399048 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.587532796859741\n",
      "\n",
      "Total loss: 0.008644024841487408; that's 0.005415222141891718 task and 0.002539000939577818 recon and 3.449009895324707 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008813533554784954\n",
      "\n",
      "Total loss: 0.010054025799036026; that's 0.006479342468082905 task and 0.0025016150902956724 recon and 5.3653411865234375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008938122428953648\n",
      "\n",
      "Total loss: 6.504306793212891:\n",
      "5.024753570556641 control,\n",
      "0.3814160227775574 lrg,\n",
      "0.4224936068058014 udg,\n",
      "0.33611413836479187 lra,\n",
      "0.3395300805568695 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.315562889575959\n",
      "\n",
      "Total loss: 0.008804104290902615; that's 0.005191256292164326 task and 0.0024855700321495533 recon and 5.6363911628723145 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00895268133841455\n",
      "\n",
      "Total loss: 6.9378790855407715:\n",
      "5.330272197723389 control,\n",
      "0.40686988830566406 lrg,\n",
      "0.48086392879486084 udg,\n",
      "0.33693739771842957 lra,\n",
      "0.3829355537891388 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.920919828414917\n",
      "\n",
      "Total loss: 4.485266208648682:\n",
      "2.890533208847046 control,\n",
      "0.45167574286460876 lrg,\n",
      "0.44182857871055603 udg,\n",
      "0.3614357113838196 lra,\n",
      "0.3397931456565857 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.849575476646423\n",
      "\n",
      "Total loss: 0.008649145253002644; that's 0.005570099223405123 task and 0.002432903740555048 recon and 3.2307095527648926 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00881491177715361\n",
      "\n",
      "Total loss: 4.876584529876709:\n",
      "3.301142692565918 control,\n",
      "0.41141942143440247 lrg,\n",
      "0.4471725523471832 udg,\n",
      "0.35560500621795654 lra,\n",
      "0.3612448275089264 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.5360065460205075\n",
      "\n",
      "Total loss: 0.008738242089748383; that's 0.005747538525611162 task and 0.0022668761666864157 recon and 3.6191399097442627 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008715893202461302\n",
      "\n",
      "Total loss: 0.008290420286357403; that's 0.00522635318338871 task and 0.0024072250816971064 recon and 3.2842092514038086 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008666280070319771\n",
      "\n",
      "Total loss: 4.439500331878662:\n",
      "2.8796472549438477 control,\n",
      "0.41467809677124023 lrg,\n",
      "0.47360000014305115 udg,\n",
      "0.31411561369895935 lra,\n",
      "0.3574593663215637 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.746990895271301\n",
      "\n",
      "Total loss: 0.009202673099935055; that's 0.00592668354511261 task and 0.0025553577579557896 recon and 3.6031627655029297 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008731241952627897\n",
      "\n",
      "Total loss: 4.857819080352783:\n",
      "3.229084014892578 control,\n",
      "0.43427401781082153 lrg,\n",
      "0.4490737020969391 udg,\n",
      "0.3834579288959503 lra,\n",
      "0.36192935705184937 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.554470849037171\n",
      "\n",
      "Total loss: 4.762520790100098:\n",
      "3.143533945083618 control,\n",
      "0.4291534423828125 lrg,\n",
      "0.5097929239273071 udg,\n",
      "0.3329821228981018 lra,\n",
      "0.3470580577850342 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.715749249458313\n",
      "\n",
      "Total loss: 0.008235936053097248; that's 0.005047250539064407 task and 0.002480038907378912 recon and 3.5432322025299072 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008749427385628223\n",
      "\n",
      "Total loss: 6.347797393798828:\n",
      "4.784276962280273 control,\n",
      "0.382027804851532 lrg,\n",
      "0.46965375542640686 udg,\n",
      "0.33130741119384766 lra,\n",
      "0.3805316984653473 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.892574257850647\n",
      "\n",
      "Total loss: 0.00918100867420435; that's 0.005742973182350397 task and 0.0024282787926495075 recon and 5.0487823486328125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008753621047362685\n",
      "\n",
      "Total loss: 0.008499450981616974; that's 0.0055366260930895805 task and 0.0023039840161800385 recon and 3.2942054271698 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008941388353705407\n",
      "\n",
      "Total loss: 4.606224536895752:\n",
      "2.9662890434265137 control,\n",
      "0.4045448899269104 lrg,\n",
      "0.5060777068138123 udg,\n",
      "0.3464939594268799 lra,\n",
      "0.38281866908073425 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.077450802326203\n",
      "\n",
      "Total loss: 4.018527030944824:\n",
      "2.406827688217163 control,\n",
      "0.42975226044654846 lrg,\n",
      "0.4599049389362335 udg,\n",
      "0.34971731901168823 lra,\n",
      "0.3723248839378357 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.804008569717407\n",
      "\n",
      "Total loss: 0.008397150784730911; that's 0.005525583401322365 task and 0.0023347593378275633 recon and 2.6840410232543945 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008839928545057774\n",
      "\n",
      "Total loss: 0.008729103021323681; that's 0.005725178401917219 task and 0.0023617884144186974 recon and 3.2106850147247314 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008396854642778635\n",
      "\n",
      "Total loss: 4.539911270141602:\n",
      "2.7934653759002686 control,\n",
      "0.5036147236824036 lrg,\n",
      "0.4762422442436218 udg,\n",
      "0.3914458751678467 lra,\n",
      "0.3751429617404938 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.7755407547950743\n",
      "\n",
      "Total loss: 0.007840062491595745; that's 0.0051185740157961845 task and 0.002350355964154005 recon and 1.8556609153747559 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008491400396451354\n",
      "\n",
      "Total loss: 3.1786720752716064:\n",
      "1.5692209005355835 control,\n",
      "0.44350486993789673 lrg,\n",
      "0.47245103120803833 udg,\n",
      "0.35220491886138916 lra,\n",
      "0.3412902057170868 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.87395272731781\n",
      "\n",
      "Total loss: 4.6169819831848145:\n",
      "2.970134973526001 control,\n",
      "0.4418736398220062 lrg,\n",
      "0.44998395442962646 udg,\n",
      "0.3945574164390564 lra,\n",
      "0.3604320287704468 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.914578211307526\n",
      "\n",
      "Total loss: 0.008906499482691288; that's 0.005698835477232933 task and 0.002580193569883704 recon and 3.1373531818389893 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008608355252072215\n",
      "\n",
      "Total loss: 0.008537843823432922; that's 0.005653157830238342 task and 0.002342473017051816 recon and 2.7110676765441895 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008832346289418638\n",
      "\n",
      "Total loss: 3.9749319553375244:\n",
      "2.352367401123047 control,\n",
      "0.4195490777492523 lrg,\n",
      "0.42707663774490356 udg,\n",
      "0.3889599144458771 lra,\n",
      "0.38697901368141174 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.912941524982452\n",
      "\n",
      "Total loss: 0.008560004644095898; that's 0.005508417263627052 task and 0.002390045439824462 recon and 3.307708740234375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008623259039595724\n",
      "\n",
      "Total loss: 4.511350631713867:\n",
      "2.9116392135620117 control,\n",
      "0.4092077910900116 lrg,\n",
      "0.4899851679801941 udg,\n",
      "0.347959965467453 lra,\n",
      "0.35255858302116394 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.098547258377075\n",
      "\n",
      "Total loss: 4.111230850219727:\n",
      "2.5383780002593994 control,\n",
      "0.4393795132637024 lrg,\n",
      "0.4353973865509033 udg,\n",
      "0.34546351432800293 lra,\n",
      "0.3526126444339752 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.229023456573486\n",
      "\n",
      "Total loss: 0.007915941067039967; that's 0.005060677416622639 task and 0.0022901389747858047 recon and 2.825624465942383 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00864278169348836\n",
      "\n",
      "Total loss: 0.009112648665904999; that's 0.006088931113481522 task and 0.002400691155344248 recon and 3.1151368618011475 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008459509005770088\n",
      "\n",
      "Total loss: 4.379659652709961:\n",
      "2.782620906829834 control,\n",
      "0.4272831976413727 lrg,\n",
      "0.4643539488315582 udg,\n",
      "0.3478556275367737 lra,\n",
      "0.3575459122657776 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.137799754142761\n",
      "\n",
      "Total loss: 4.234066963195801:\n",
      "2.6659903526306152 control,\n",
      "0.41497015953063965 lrg,\n",
      "0.47798654437065125 udg,\n",
      "0.34034159779548645 lra,\n",
      "0.3347783088684082 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.078668746948242\n",
      "\n",
      "Total loss: 0.008894771337509155; that's 0.005997186992317438 task and 0.002307176124304533 recon and 2.952040195465088 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008436123277060687\n",
      "\n",
      "Total loss: 4.037513256072998:\n",
      "2.4549946784973145 control,\n",
      "0.44015470147132874 lrg,\n",
      "0.44136202335357666 udg,\n",
      "0.33988723158836365 lra,\n",
      "0.36111438274383545 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.042927989959717\n",
      "\n",
      "Total loss: 0.008006343618035316; that's 0.005196976941078901 task and 0.0022556157782673836 recon and 2.76875376701355 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008459381530992688\n",
      "\n",
      "Total loss: 4.197856426239014:\n",
      "2.5490012168884277 control,\n",
      "0.45291683077812195 lrg,\n",
      "0.45348918437957764 udg,\n",
      "0.3697090446949005 lra,\n",
      "0.37274014949798584 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.0938134145736695\n",
      "\n",
      "Total loss: 0.008883547969162464; that's 0.005958906840533018 task and 0.0023524921853095293 recon and 2.8607420921325684 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008508295831270517\n",
      "\n",
      "Total loss: 0.007867462001740932; that's 0.004970222245901823 task and 0.0022999125067144632 recon and 2.986635446548462 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008454443318769336\n",
      "\n",
      "Total loss: 4.262721538543701:\n",
      "2.616886854171753 control,\n",
      "0.4096522033214569 lrg,\n",
      "0.49863937497138977 udg,\n",
      "0.3468646705150604 lra,\n",
      "0.3906782567501068 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.182184247970581\n",
      "\n",
      "Total loss: 5.607215404510498:\n",
      "4.070058345794678 control,\n",
      "0.4216991364955902 lrg,\n",
      "0.43074724078178406 udg,\n",
      "0.33302217721939087 lra,\n",
      "0.35168877243995667 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.871237814426422\n",
      "\n",
      "Total loss: 0.008828277699649334; that's 0.005681516136974096 task and 0.0022485179360955954 recon and 4.491219520568848 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008524085381068289\n",
      "\n",
      "Total loss: 0.009196706116199493; that's 0.005773698911070824 task and 0.002328050322830677 recon and 5.474785804748535 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008964024996384979\n",
      "\n",
      "Total loss: 6.758963584899902:\n",
      "5.178244113922119 control,\n",
      "0.42078593373298645 lrg,\n",
      "0.4709891676902771 udg,\n",
      "0.3321336507797241 lra,\n",
      "0.3568108081817627 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.401721549034119\n",
      "\n",
      "Total loss: 5.4142045974731445:\n",
      "3.906766176223755 control,\n",
      "0.38877302408218384 lrg,\n",
      "0.419548362493515 udg,\n",
      "0.3485013544559479 lra,\n",
      "0.350615531206131 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.7915042114257815\n",
      "\n",
      "Total loss: 0.008395453914999962; that's 0.005350728984922171 task and 0.0022000244352966547 recon and 4.223499298095703 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009094491750001907\n",
      "\n",
      "Total loss: 5.670815944671631:\n",
      "4.112037658691406 control,\n",
      "0.40317976474761963 lrg,\n",
      "0.41224995255470276 udg,\n",
      "0.37362775206565857 lra,\n",
      "0.36972111463546753 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.942503147125244\n",
      "\n",
      "Total loss: 0.007670823950320482; that's 0.004521506372839212 task and 0.002258663298562169 recon and 4.45327091217041 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008656391827389597\n",
      "\n",
      "Total loss: 3.943734884262085:\n",
      "2.4183881282806396 control,\n",
      "0.40256041288375854 lrg,\n",
      "0.44909000396728516 udg,\n",
      "0.32231321930885315 lra,\n",
      "0.3513829708099365 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.938756701946258\n",
      "\n",
      "Total loss: 0.008345693349838257; that's 0.00543720880523324 task and 0.002367564244195819 recon and 2.704601526260376 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008561356398276985\n",
      "\n",
      "Total loss: 0.00848337635397911; that's 0.005462614353746176 task and 0.0022776052355766296 recon and 3.7157816886901855 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008468831428326667\n",
      "\n",
      "Total loss: 4.902103424072266:\n",
      "3.349821090698242 control,\n",
      "0.42886340618133545 lrg,\n",
      "0.4471502900123596 udg,\n",
      "0.3279479444026947 lra,\n",
      "0.3483203947544098 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.5172848534584045\n",
      "\n",
      "Total loss: 0.008540029637515545; that's 0.00551991444081068 task and 0.002419643569737673 recon and 3.0023555755615234 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00855926367919892\n",
      "\n",
      "Total loss: 4.312330722808838:\n",
      "2.6827762126922607 control,\n",
      "0.49191367626190186 lrg,\n",
      "0.44155246019363403 udg,\n",
      "0.32253241539001465 lra,\n",
      "0.3735559284687042 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.453283927440643\n",
      "\n",
      "Total loss: 5.071878910064697:\n",
      "3.430527448654175 control,\n",
      "0.44389262795448303 lrg,\n",
      "0.44674360752105713 udg,\n",
      "0.38410282135009766 lra,\n",
      "0.36661258339881897 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.611091365814209\n",
      "\n",
      "Total loss: 0.008247326128184795; that's 0.005207049660384655 task and 0.0023035539779812098 recon and 3.6836133003234863 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008546895552426577\n",
      "\n",
      "Total loss: 5.608116149902344:\n",
      "4.128091335296631 control,\n",
      "0.38599690794944763 lrg,\n",
      "0.4337714910507202 udg,\n",
      "0.31760552525520325 lra,\n",
      "0.3426510691642761 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.7697192525863645\n",
      "\n",
      "Total loss: 0.00821597222238779; that's 0.005060127470642328 task and 0.0022695136722177267 recon and 4.431654930114746 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008753070952370762\n",
      "\n",
      "Total loss: 6.620262622833252:\n",
      "5.1014018058776855 control,\n",
      "0.3844257891178131 lrg,\n",
      "0.45711952447891235 udg,\n",
      "0.33195140957832336 lra,\n",
      "0.34536394476890564 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.6262238073349\n",
      "\n",
      "Total loss: 0.008813181892037392; that's 0.005471047013998032 task and 0.002268511336296797 recon and 5.3681182861328125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008699225429445505\n",
      "\n",
      "Total loss: 6.296585559844971:\n",
      "4.758591175079346 control,\n",
      "0.4405628442764282 lrg,\n",
      "0.4291013479232788 udg,\n",
      "0.33971232175827026 lra,\n",
      "0.3286178708076477 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.111689939498901\n",
      "\n",
      "Total loss: 0.00858793593943119; that's 0.005327966995537281 task and 0.002246237825602293 recon and 5.068657875061035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008592354427091777\n",
      "\n",
      "Total loss: 6.553854942321777:\n",
      "4.989584445953369 control,\n",
      "0.4190502464771271 lrg,\n",
      "0.466461718082428 udg,\n",
      "0.3279891908168793 lra,\n",
      "0.35076943039894104 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.761599774360657\n",
      "\n",
      "Total loss: 0.008489895612001419; that's 0.005126032512634993 task and 0.002322457730770111 recon and 5.207028388977051 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008609340535476804\n",
      "\n",
      "Total loss: 0.008884486742317677; that's 0.00578539352864027 task and 0.002239599823951721 recon and 4.2974653244018555 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008517899517901242\n",
      "\n",
      "Total loss: 5.519314289093018:\n",
      "3.939391613006592 control,\n",
      "0.4165182411670685 lrg,\n",
      "0.486467570066452 udg,\n",
      "0.3522772490978241 lra,\n",
      "0.3246598243713379 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.126154489517212\n",
      "\n",
      "Total loss: 0.00761192524805665; that's 0.00444430485367775 task and 0.002198786474764347 recon and 4.844170570373535 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00814276271034032\n",
      "\n",
      "Total loss: 6.090907573699951:\n",
      "4.533890724182129 control,\n",
      "0.41854050755500793 lrg,\n",
      "0.4540037214756012 udg,\n",
      "0.34242650866508484 lra,\n",
      "0.34204620122909546 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.013329195976257\n",
      "\n",
      "Total loss: 0.008639052510261536; that's 0.005660614464432001 task and 0.0018526001367717981 recon and 5.62918758392334 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007921084933914245\n",
      "\n",
      "Total loss: 6.854112148284912:\n",
      "5.32940673828125 control,\n",
      "0.3991856276988983 lrg,\n",
      "0.4438208341598511 udg,\n",
      "0.3443627655506134 lra,\n",
      "0.3373362421989441 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.822111830711365\n",
      "\n",
      "Total loss: 5.630650043487549:\n",
      "4.007538318634033 control,\n",
      "0.4191855788230896 lrg,\n",
      "0.47739464044570923 udg,\n",
      "0.33665961027145386 lra,\n",
      "0.3898722529411316 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.243697671890259\n",
      "\n",
      "Total loss: 0.007627153303474188; that's 0.0049768127501010895 task and 0.0017855990445241332 recon and 4.3237080574035645 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0077343650860711936\n",
      "\n",
      "Total loss: 4.776863098144531:\n",
      "3.2106175422668457 control,\n",
      "0.3944741189479828 lrg,\n",
      "0.44272100925445557 udg,\n",
      "0.359045147895813 lra,\n",
      "0.3700057864189148 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.755742406845092\n",
      "\n",
      "Total loss: 0.007213490083813667; that's 0.004799035843461752 task and 0.0017139521660283208 recon and 3.5025105476379395 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007550877914763987\n",
      "\n",
      "Total loss: 4.808296203613281:\n",
      "3.1582608222961426 control,\n",
      "0.45656219124794006 lrg,\n",
      "0.4495908319950104 udg,\n",
      "0.34062889218330383 lra,\n",
      "0.40325313806533813 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.101132225990296\n",
      "\n",
      "Total loss: 0.007571313064545393; that's 0.005158161744475365 task and 0.0017158023547381163 recon and 3.4867427349090576 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007370123672299087\n",
      "\n",
      "Total loss: 0.006826362572610378; that's 0.004306367598474026 task and 0.001787954824976623 recon and 3.6601996421813965 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007656042724847794\n",
      "\n",
      "Total loss: 4.983818531036377:\n",
      "3.3451876640319824 control,\n",
      "0.4438994526863098 lrg,\n",
      "0.47426745295524597 udg,\n",
      "0.35582515597343445 lra,\n",
      "0.3646394908428192 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.579058785438537\n",
      "\n",
      "Total loss: 5.108185768127441:\n",
      "3.5170199871063232 control,\n",
      "0.44603341817855835 lrg,\n",
      "0.45793211460113525 udg,\n",
      "0.3318517208099365 lra,\n",
      "0.3553483486175537 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.981663072109223\n",
      "\n",
      "Total loss: 0.007906300015747547; that's 0.005459142848849297 task and 0.0016801139572635293 recon and 3.835218667984009 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00723870909307152\n",
      "\n",
      "Total loss: 0.007615734823048115; that's 0.005307950545102358 task and 0.0016223927959799767 recon and 3.4269580841064453 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007282850686460733\n",
      "\n",
      "Total loss: 4.672060012817383:\n",
      "3.0443034172058105 control,\n",
      "0.43485718965530396 lrg,\n",
      "0.4774424433708191 udg,\n",
      "0.32794511318206787 lra,\n",
      "0.3875117599964142 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.117026920318604\n",
      "\n",
      "Total loss: 5.440901756286621:\n",
      "3.785250663757324 control,\n",
      "0.48790234327316284 lrg,\n",
      "0.46351325511932373 udg,\n",
      "0.3488466739654541 lra,\n",
      "0.355388879776001 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.440148220062256\n",
      "\n",
      "Total loss: 0.007253558840602636; that's 0.004771992564201355 task and 0.0016606778372079134 recon and 4.1044440269470215 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007362378393299878\n",
      "\n",
      "Total loss: 0.007032293826341629; that's 0.004681754391640425 task and 0.0015207461547106504 recon and 4.148967742919922 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007333311759866774\n",
      "\n",
      "Total loss: 5.427371978759766:\n",
      "3.84991192817688 control,\n",
      "0.43827927112579346 lrg,\n",
      "0.4581162631511688 udg,\n",
      "0.3149404525756836 lra,\n",
      "0.36612415313720703 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.630680584907532\n",
      "\n",
      "Total loss: 6.107964515686035:\n",
      "4.551998138427734 control,\n",
      "0.3841266632080078 lrg,\n",
      "0.4570227563381195 udg,\n",
      "0.34670954942703247 lra,\n",
      "0.3681073784828186 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.390137376785279\n",
      "\n",
      "Total loss: 0.00719608785584569; that's 0.004643941298127174 task and 0.0015921506565064192 recon and 4.799978256225586 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007320638014934957\n",
      "\n",
      "Total loss: 0.007157160900533199; that's 0.004566641058772802 task and 0.0014799152268096805 recon and 5.553023338317871 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007297723605297506\n",
      "\n",
      "Total loss: 6.738710880279541:\n",
      "5.209978103637695 control,\n",
      "0.39503124356269836 lrg,\n",
      "0.4263922870159149 udg,\n",
      "0.37476402521133423 lra,\n",
      "0.3325454294681549 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.080134406089782\n",
      "\n",
      "Total loss: 0.007077221758663654; that's 0.004505009390413761 task and 0.0014916789950802922 recon and 5.4026689529418945 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007279468784108758\n",
      "\n",
      "Total loss: 6.507331848144531:\n",
      "4.992580413818359 control,\n",
      "0.43670228123664856 lrg,\n",
      "0.4257177710533142 udg,\n",
      "0.3198438584804535 lra,\n",
      "0.33248764276504517 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.044441151618957\n",
      "\n",
      "Total loss: 0.006571306847035885; that's 0.004367545712739229 task and 0.0015103728510439396 recon and 3.4669418334960938 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00697702522855252\n",
      "\n",
      "Total loss: 4.657368183135986:\n",
      "3.1145179271698 control,\n",
      "0.43412551283836365 lrg,\n",
      "0.4416487216949463 udg,\n",
      "0.32959461212158203 lra,\n",
      "0.3374815583229065 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.030429120063782\n",
      "\n",
      "Total loss: 4.979923725128174:\n",
      "3.3504581451416016 control,\n",
      "0.4578533172607422 lrg,\n",
      "0.4922294020652771 udg,\n",
      "0.3630993664264679 lra,\n",
      "0.316283255815506 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.523683006763458\n",
      "\n",
      "Total loss: 0.006762485019862652; that's 0.004530511796474457 task and 0.001493435469456017 recon and 3.692690372467041 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006879636240191758\n",
      "\n",
      "Total loss: 3.9570815563201904:\n",
      "2.4616477489471436 control,\n",
      "0.38990354537963867 lrg,\n",
      "0.40299734473228455 udg,\n",
      "0.3359071910381317 lra,\n",
      "0.3666258752346039 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.375820286273957\n",
      "\n",
      "Total loss: 0.006785783916711807; that's 0.004773033782839775 task and 0.0014641927555203438 recon and 2.742786407470703 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006818939484655857\n",
      "\n",
      "Total loss: 6.431571006774902:\n",
      "4.878620147705078 control,\n",
      "0.4149131178855896 lrg,\n",
      "0.4513842761516571 udg,\n",
      "0.3206537961959839 lra,\n",
      "0.3659997880458832 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.652067325115204\n",
      "\n",
      "Total loss: 0.0073838792741298676; that's 0.00484078424051404 task and 0.0015009104972705245 recon and 5.2109222412109375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007032981277443468\n",
      "\n",
      "Total loss: 0.006647670175880194; that's 0.004409068264067173 task and 0.0014697808073833585 recon and 3.844106912612915 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007048617308028042\n",
      "\n",
      "Total loss: 5.019125938415527:\n",
      "3.5006022453308105 control,\n",
      "0.4348083436489105 lrg,\n",
      "0.4126082956790924 udg,\n",
      "0.333537220954895 lra,\n",
      "0.33757027983665466 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.691317324638367\n",
      "\n",
      "Total loss: 5.959605693817139:\n",
      "4.4554290771484375 control,\n",
      "0.3904845416545868 lrg,\n",
      "0.43543335795402527 udg,\n",
      "0.3354199528694153 lra,\n",
      "0.34283876419067383 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.610552597045898\n",
      "\n",
      "Total loss: 0.00737682543694973; that's 0.004690191242843866 task and 0.0017452571773901582 recon and 4.706884860992432 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007045051385648549\n",
      "\n",
      "Total loss: 0.00785850826650858; that's 0.005437791813164949 task and 0.0014384057139977813 recon and 4.911552906036377 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007104034568183124\n",
      "\n",
      "Total loss: 6.133784294128418:\n",
      "4.559072971343994 control,\n",
      "0.46543002128601074 lrg,\n",
      "0.43803656101226807 udg,\n",
      "0.3434940278530121 lra,\n",
      "0.32775112986564636 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.806503205299378\n",
      "\n",
      "Total loss: 4.695080757141113:\n",
      "3.127948760986328 control,\n",
      "0.4401100277900696 lrg,\n",
      "0.47844916582107544 udg,\n",
      "0.31312456727027893 lra,\n",
      "0.3354482650756836 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.289642758369446\n",
      "\n",
      "Total loss: 0.007182347122579813; that's 0.005044332705438137 task and 0.001460096682421863 recon and 3.389587640762329 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006981274336576462\n",
      "\n",
      "Total loss: 5.297876834869385:\n",
      "3.7082836627960205 control,\n",
      "0.43547290563583374 lrg,\n",
      "0.4577634930610657 udg,\n",
      "0.32098251581192017 lra,\n",
      "0.37537434697151184 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.423072171211243\n",
      "\n",
      "Total loss: 0.007362994831055403; that's 0.005105534568428993 task and 0.0014500904362648726 recon and 4.036849021911621 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0069446839811280366\n",
      "\n",
      "Total loss: 0.00593387708067894; that's 0.0037918873131275177 task and 0.0014223632169887424 recon and 3.598133087158203 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006993419476784766\n",
      "\n",
      "Total loss: 4.674081802368164:\n",
      "3.213242292404175 control,\n",
      "0.39647048711776733 lrg,\n",
      "0.4029444456100464 udg,\n",
      "0.32482507824897766 lra,\n",
      "0.3365992605686188 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.5892842626571655\n",
      "\n",
      "Total loss: 4.645576000213623:\n",
      "3.0520873069763184 control,\n",
      "0.4148887097835541 lrg,\n",
      "0.46398866176605225 udg,\n",
      "0.36182355880737305 lra,\n",
      "0.3527878522872925 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.339613575935363\n",
      "\n",
      "Total loss: 0.006785811856389046; that's 0.004680334124714136 task and 0.0014398869825527072 recon and 3.3279526233673096 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00690208300948143\n",
      "\n",
      "Total loss: 0.006565033923834562; that's 0.004049977287650108 task and 0.0016768872737884521 recon and 4.190846920013428 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006887160991318524\n",
      "\n",
      "Total loss: 5.413146495819092:\n",
      "3.8015811443328857 control,\n",
      "0.45608094334602356 lrg,\n",
      "0.47109779715538025 udg,\n",
      "0.3271544277667999 lra,\n",
      "0.3572317063808441 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.195122852325439\n",
      "\n",
      "Total loss: 0.006860175170004368; that's 0.004722066689282656 task and 0.001427196548320353 recon and 3.5545616149902344 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0069464013958349825\n",
      "\n",
      "Total loss: 4.745134353637695:\n",
      "3.2287137508392334 control,\n",
      "0.39377138018608093 lrg,\n",
      "0.4545506536960602 udg,\n",
      "0.32734599709510803 lra,\n",
      "0.34075281023979187 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.654978170394897\n",
      "\n",
      "Total loss: 6.57252311706543:\n",
      "5.004405498504639 control,\n",
      "0.44527778029441833 lrg,\n",
      "0.4478001892566681 udg,\n",
      "0.3379845917224884 lra,\n",
      "0.33705541491508484 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.352000503540039\n",
      "\n",
      "Total loss: 0.007518851198256016; that's 0.005046201404184103 task and 0.0014148051850497723 recon and 5.289222240447998 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006937568024732173\n",
      "\n",
      "Total loss: 0.006660523358732462; that's 0.0043418267741799355 task and 0.0014312731800600886 recon and 4.437116622924805 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006882391166873276\n",
      "\n",
      "Total loss: 5.565681457519531:\n",
      "4.002270698547363 control,\n",
      "0.40825802087783813 lrg,\n",
      "0.4537431299686432 udg,\n",
      "0.32927680015563965 lra,\n",
      "0.37213313579559326 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.560714521408081\n",
      "\n",
      "Total loss: 0.0067922635935246944; that's 0.0044524334371089935 task and 0.0013973457971587777 recon and 4.7124223709106445 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006896877815015614\n",
      "\n",
      "Total loss: 5.9252166748046875:\n",
      "4.351158142089844 control,\n",
      "0.4499252736568451 lrg,\n",
      "0.4631466269493103 udg,\n",
      "0.33138203620910645 lra,\n",
      "0.32960429787635803 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.511591749191284\n",
      "\n",
      "Total loss: 0.006900428794324398; that's 0.004509567283093929 task and 0.0014516001101583242 recon and 4.696304798126221 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006879229247570038\n",
      "\n",
      "Total loss: 5.905087947845459:\n",
      "4.351008892059326 control,\n",
      "0.4537560045719147 lrg,\n",
      "0.41336527466773987 udg,\n",
      "0.33820798993110657 lra,\n",
      "0.3487496078014374 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.469484968185425\n",
      "\n",
      "Total loss: 5.009842872619629:\n",
      "3.472083330154419 control,\n",
      "0.40420296788215637 lrg,\n",
      "0.4169946610927582 udg,\n",
      "0.35034045577049255 lra,\n",
      "0.3662213385105133 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.038776643276215\n",
      "\n",
      "Total loss: 0.006407412700355053; that's 0.004249318968504667 task and 0.0014135403325781226 recon and 3.722766399383545 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006872390769422055\n",
      "\n",
      "Total loss: 0.006636450067162514; that's 0.004670212976634502 task and 0.0013937631156295538 recon and 2.862368106842041 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006822491334751248\n",
      "\n",
      "Total loss: 4.162454128265381:\n",
      "2.491407632827759 control,\n",
      "0.4335936903953552 lrg,\n",
      "0.5100843906402588 udg,\n",
      "0.3800821900367737 lra,\n",
      "0.34728628396987915 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.887315146923065\n",
      "\n",
      "Total loss: 4.389132976531982:\n",
      "2.8370888233184814 control,\n",
      "0.41124844551086426 lrg,\n",
      "0.46879369020462036 udg,\n",
      "0.32307836413383484 lra,\n",
      "0.34892359375953674 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.878947865962982\n",
      "\n",
      "Total loss: 0.007286482024937868; that's 0.005093779880553484 task and 0.0015513435937464237 recon and 3.206791877746582 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006884115491993725\n",
      "\n",
      "Total loss: 5.27575159072876:\n",
      "3.705312490463257 control,\n",
      "0.4013023376464844 lrg,\n",
      "0.452846497297287 udg,\n",
      "0.33775630593299866 lra,\n",
      "0.3785339295864105 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.994664752483368\n",
      "\n",
      "Total loss: 0.0061010089702904224; that's 0.0038206649478524923 task and 0.0014764497755095363 recon and 4.019471168518066 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006967398887500167\n",
      "\n",
      "Total loss: 4.275311470031738:\n",
      "2.7337636947631836 control,\n",
      "0.38352707028388977 lrg,\n",
      "0.4469064772129059 udg,\n",
      "0.32666444778442383 lra,\n",
      "0.3844496011734009 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.139774317741394\n",
      "\n",
      "Total loss: 0.0069803898222744465; that's 0.00473480811342597 task and 0.0016422233311459422 recon and 3.016792058944702 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00723388722166419\n",
      "\n",
      "Total loss: 0.007255461998283863; that's 0.004839060362428427 task and 0.0014896233333274722 recon and 4.6338911056518555 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00703338049352169\n",
      "\n",
      "Total loss: 5.8501505851745605:\n",
      "4.283513069152832 control,\n",
      "0.44564858078956604 lrg,\n",
      "0.4274900555610657 udg,\n",
      "0.3282465636730194 lra,\n",
      "0.36525189876556396 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.428480286598205\n",
      "\n",
      "Total loss: 5.255566596984863:\n",
      "3.695354461669922 control,\n",
      "0.412880539894104 lrg,\n",
      "0.44524091482162476 udg,\n",
      "0.3551902770996094 lra,\n",
      "0.3469002842903137 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.497688405513763\n",
      "\n",
      "Total loss: 0.007743890397250652; that's 0.00527140311896801 task and 0.0016686351737007499 recon and 4.019260406494141 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006903155385516584\n",
      "\n",
      "Total loss: 0.007519018370658159; that's 0.004846504423767328 task and 0.0016259619733318686 recon and 5.232759475708008 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006913989367894828\n",
      "\n",
      "Total loss: 6.429239273071289:\n",
      "4.898716926574707 control,\n",
      "0.4189186692237854 lrg,\n",
      "0.4597262144088745 udg,\n",
      "0.31405574083328247 lra,\n",
      "0.33782124519348145 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.621279728412628\n",
      "\n",
      "Total loss: 5.341027736663818:\n",
      "3.814438581466675 control,\n",
      "0.4001706540584564 lrg,\n",
      "0.4484296441078186 udg,\n",
      "0.3060361444950104 lra,\n",
      "0.37195292115211487 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.157963080406189\n",
      "\n",
      "Total loss: 0.006686201319098473; that's 0.0044770915992558 task and 0.001393763581290841 recon and 4.0767292976379395 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0070089312456548215\n",
      "\n",
      "Total loss: 6.294238090515137:\n",
      "4.693643569946289 control,\n",
      "0.4413175880908966 lrg,\n",
      "0.4409514367580414 udg,\n",
      "0.3356778621673584 lra,\n",
      "0.38264769315719604 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.791786260604859\n",
      "\n",
      "Total loss: 0.007065683603286743; that's 0.004691479727625847 task and 0.0013797858264297247 recon and 4.972090244293213 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006951698758639395\n",
      "\n",
      "Total loss: 0.006779604125767946; that's 0.004693457391113043 task and 0.001418567611835897 recon and 3.337895154953003 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0068583875149488445\n",
      "\n",
      "Total loss: 4.553347110748291:\n",
      "2.978656530380249 control,\n",
      "0.40571820735931396 lrg,\n",
      "0.46982327103614807 udg,\n",
      "0.33079564571380615 lra,\n",
      "0.3683534860610962 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.614635448455811\n",
      "\n",
      "Total loss: 0.007508395239710808; that's 0.005235703662037849 task and 0.0014214444672688842 recon and 4.256234645843506 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006841155262663961\n",
      "\n",
      "Total loss: 5.5759453773498535:\n",
      "3.9505696296691895 control,\n",
      "0.4254609942436218 lrg,\n",
      "0.46766260266304016 udg,\n",
      "0.3677889406681061 lra,\n",
      "0.3644633889198303 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.626688175201416\n",
      "\n",
      "Total loss: 6.1183037757873535:\n",
      "4.554783821105957 control,\n",
      "0.45238417387008667 lrg,\n",
      "0.4246346950531006 udg,\n",
      "0.3473648428916931 lra,\n",
      "0.3391360938549042 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.467395830154419\n",
      "\n",
      "Total loss: 0.00691958237439394; that's 0.0045223478227853775 task and 0.0014278976013883948 recon and 4.846683979034424 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00681298749987036\n",
      "\n",
      "Total loss: 4.512390613555908:\n",
      "2.9638473987579346 control,\n",
      "0.40413081645965576 lrg,\n",
      "0.4580208957195282 udg,\n",
      "0.32735806703567505 lra,\n",
      "0.3590335547924042 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.961084294319153\n",
      "\n",
      "Total loss: 0.00660321582108736; that's 0.004556072875857353 task and 0.0013923760270699859 recon and 3.273833990097046 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0067351941904053095\n",
      "\n",
      "Total loss: 4.758481025695801:\n",
      "3.2021689414978027 control,\n",
      "0.42970898747444153 lrg,\n",
      "0.3998536765575409 udg,\n",
      "0.35695555806159973 lra,\n",
      "0.3697940707206726 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.153361248970032\n",
      "\n",
      "Total loss: 0.007055065594613552; that's 0.004977450706064701 task and 0.0013773870887234807 recon and 3.5011401176452637 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006827226867899299\n",
      "\n",
      "Total loss: 4.185932636260986:\n",
      "2.619987726211548 control,\n",
      "0.40623944997787476 lrg,\n",
      "0.4561087489128113 udg,\n",
      "0.3495642840862274 lra,\n",
      "0.3540322482585907 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.986517090797424\n",
      "\n",
      "Total loss: 0.006200913339853287; that's 0.004229916259646416 task and 0.0013856409350410104 recon and 2.9267807006835938 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006750549185089767\n",
      "\n",
      "Total loss: 5.823145866394043:\n",
      "4.228137016296387 control,\n",
      "0.39785000681877136 lrg,\n",
      "0.4765893816947937 udg,\n",
      "0.36749133467674255 lra,\n",
      "0.35307827591896057 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.989422430992127\n",
      "\n",
      "Total loss: 0.007247992791235447; that's 0.0049275909550487995 task and 0.0014228979125618935 recon and 4.487520694732666 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006794095076620579\n",
      "\n",
      "Total loss: 0.006491560954600573; that's 0.00456157885491848 task and 0.0013421856565400958 recon and 2.938981771469116 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006831679819151759\n",
      "\n",
      "Total loss: 4.171472072601318:\n",
      "2.5792205333709717 control,\n",
      "0.42606309056282043 lrg,\n",
      "0.46588361263275146 udg,\n",
      "0.34389597177505493 lra,\n",
      "0.356408953666687 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.212310523986816\n",
      "\n",
      "Total loss: 0.006303533911705017; that's 0.0041583687998354435 task and 0.001369314268231392 recon and 3.87925386428833 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006786356223747134\n",
      "\n",
      "Total loss: 5.126070499420166:\n",
      "3.564540147781372 control,\n",
      "0.43868178129196167 lrg,\n",
      "0.428920179605484 udg,\n",
      "0.362289160490036 lra,\n",
      "0.3316393792629242 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.180816431045532\n",
      "\n",
      "Total loss: 0.006358292885124683; that's 0.004165885969996452 task and 0.001339303213171661 recon and 4.265517234802246 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006753971725702286\n",
      "\n",
      "Total loss: 5.498729228973389:\n",
      "3.972593069076538 control,\n",
      "0.42392221093177795 lrg,\n",
      "0.4357970058917999 udg,\n",
      "0.3507140874862671 lra,\n",
      "0.3157024681568146 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.916581528186798\n",
      "\n",
      "Total loss: 5.865192890167236:\n",
      "4.417840003967285 control,\n",
      "0.36679667234420776 lrg,\n",
      "0.4241378903388977 udg,\n",
      "0.32481351494789124 lra,\n",
      "0.33160489797592163 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.201158754825592\n",
      "\n",
      "Total loss: 0.006742984522134066; that's 0.004490148741751909 task and 0.0013133728643879294 recon and 4.697314262390137 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006697733490727842\n",
      "\n",
      "Total loss: 4.887727737426758:\n",
      "3.3182969093322754 control,\n",
      "0.425886332988739 lrg,\n",
      "0.460199773311615 udg,\n",
      "0.34094855189323425 lra,\n",
      "0.3423960506916046 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.68880136013031\n",
      "\n",
      "Total loss: 0.006781349424272776; that's 0.004711158107966185 task and 0.0013352398527786136 recon and 3.674755811691284 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00682958344463259\n",
      "\n",
      "Total loss: 0.00698701711371541; that's 0.004814431071281433 task and 0.0013353065587580204 recon and 4.186398029327393 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006803590035997331\n",
      "\n",
      "Total loss: 5.393910884857178:\n",
      "3.8527915477752686 control,\n",
      "0.4083448648452759 lrg,\n",
      "0.43761733174324036 udg,\n",
      "0.3484668731689453 lra,\n",
      "0.34669023752212524 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.478414449691773\n",
      "\n",
      "Total loss: 4.861687660217285:\n",
      "3.2878530025482178 control,\n",
      "0.41952845454216003 lrg,\n",
      "0.47238224744796753 udg,\n",
      "0.3225417137145996 lra,\n",
      "0.35938194394111633 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.4777678823471065\n",
      "\n",
      "Total loss: 0.00634790351614356; that's 0.004301870241761208 task and 0.0013211999321356416 recon and 3.6241674423217773 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006879492970183492\n",
      "\n",
      "Total loss: 5.2544264793396:\n",
      "3.6175172328948975 control,\n",
      "0.4116888642311096 lrg,\n",
      "0.4676993191242218 udg,\n",
      "0.3739747405052185 lra,\n",
      "0.383545845746994 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.264815526008606\n",
      "\n",
      "Total loss: 0.006232508923858404; that's 0.004136961884796619 task and 0.0013105596881359816 recon and 3.9249355792999268 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00673737215809524\n",
      "\n",
      "Total loss: 0.006916774902492762; that's 0.004799359478056431 task and 0.0013391535030677915 recon and 3.8913097381591797 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006716148387640715\n",
      "\n",
      "Total loss: 5.12498664855957:\n",
      "3.5182714462280273 control,\n",
      "0.4489988386631012 lrg,\n",
      "0.43891441822052 udg,\n",
      "0.37202897667884827 lra,\n",
      "0.34677326679229736 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.281468491554261\n",
      "\n",
      "Total loss: 5.004035472869873:\n",
      "3.393151044845581 control,\n",
      "0.41116198897361755 lrg,\n",
      "0.4778440594673157 udg,\n",
      "0.3549633026123047 lra,\n",
      "0.36691516637802124 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.11726104259491\n",
      "\n",
      "Total loss: 0.0063556283712387085; that's 0.0042868140153586864 task and 0.001328518963418901 recon and 3.7014763355255127 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006741730533540249\n",
      "\n",
      "Total loss: 0.006007228046655655; that's 0.0038681840524077415 task and 0.0013018371537327766 recon and 4.18603515625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006693484508432448\n",
      "\n",
      "Total loss: 5.402981281280518:\n",
      "3.825202226638794 control,\n",
      "0.4352910816669464 lrg,\n",
      "0.425319641828537 udg,\n",
      "0.36037537455558777 lra,\n",
      "0.3567928969860077 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.208788237571716\n",
      "\n",
      "Total loss: 5.5334792137146:\n",
      "3.958442211151123 control,\n",
      "0.40174680948257446 lrg,\n",
      "0.4596843421459198 udg,\n",
      "0.3475208878517151 lra,\n",
      "0.3660852611064911 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.106004762649536\n",
      "\n",
      "Total loss: 0.006382725201547146; that's 0.004227054305374622 task and 0.0013093671295791864 recon and 4.231521129608154 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006618436179123819\n",
      "\n",
      "Total loss: 0.006522689014673233; that's 0.004360118880867958 task and 0.0013440254842862487 recon and 4.0927228927612305 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006623237091116607\n",
      "\n",
      "Total loss: 5.339354038238525:\n",
      "3.7360622882843018 control,\n",
      "0.4488717317581177 lrg,\n",
      "0.4717417359352112 udg,\n",
      "0.31931260228157043 lra,\n",
      "0.36336562037467957 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.146788578033448\n",
      "\n",
      "Total loss: 0.006502730306237936; that's 0.004414570052176714 task and 0.0013550992589443922 recon and 3.66530704498291 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006694785696454346\n",
      "\n",
      "Total loss: 4.893715858459473:\n",
      "3.3270866870880127 control,\n",
      "0.4017954170703888 lrg,\n",
      "0.44634583592414856 udg,\n",
      "0.36610400676727295 lra,\n",
      "0.35238343477249146 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.023062858581543\n",
      "\n",
      "Total loss: 0.006638450548052788; that's 0.004079469013959169 task and 0.0013159312075003982 recon and 6.2152509689331055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006666718646883964\n",
      "\n",
      "Total loss: 7.560784339904785:\n",
      "5.867892742156982 control,\n",
      "0.42471230030059814 lrg,\n",
      "0.5436553359031677 udg,\n",
      "0.3587985634803772 lra,\n",
      "0.3657255172729492 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.065708599090576\n",
      "\n",
      "Total loss: 0.007094734814018011; that's 0.0048721544444561005 task and 0.0013528012204915285 recon and 4.348897933959961 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006717262784950435\n",
      "\n",
      "Total loss: 5.523038387298584:\n",
      "4.023017883300781 control,\n",
      "0.39451131224632263 lrg,\n",
      "0.40248340368270874 udg,\n",
      "0.3447756767272949 lra,\n",
      "0.3582499921321869 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.549388909339905\n",
      "\n",
      "Total loss: 4.4194440841674805:\n",
      "2.8512234687805176 control,\n",
      "0.4123449921607971 lrg,\n",
      "0.4442245364189148 udg,\n",
      "0.34957578778266907 lra,\n",
      "0.362075537443161 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.590885415077209\n",
      "\n",
      "Total loss: 0.006509711034595966; that's 0.004582796711474657 task and 0.0012882704613730311 recon and 3.193218231201172 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006747891614213586\n",
      "\n",
      "Total loss: 4.29530668258667:\n",
      "2.698286533355713 control,\n",
      "0.4428195655345917 lrg,\n",
      "0.45481476187705994 udg,\n",
      "0.36537933349609375 lra,\n",
      "0.33400657773017883 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.113465685844421\n",
      "\n",
      "Total loss: 0.006537494249641895; that's 0.004606081172823906 task and 0.0013285995228216052 recon and 3.0140669345855713 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006661235797218978\n",
      "\n",
      "Total loss: 0.006718210875988007; that's 0.004642954561859369 task and 0.0013156590284779668 recon and 3.7979884147644043 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0066685020970180635\n",
      "\n",
      "Total loss: 5.008614540100098:\n",
      "3.4921321868896484 control,\n",
      "0.40385329723358154 lrg,\n",
      "0.4377964735031128 udg,\n",
      "0.33957919478416443 lra,\n",
      "0.33525341749191284 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.205465092658996\n",
      "\n",
      "Total loss: 4.988822937011719:\n",
      "3.4264767169952393 control,\n",
      "0.4267829954624176 lrg,\n",
      "0.43361908197402954 udg,\n",
      "0.3528151214122772 lra,\n",
      "0.3491286337375641 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.325734329223633\n",
      "\n",
      "Total loss: 0.006416308227926493; that's 0.00433738948777318 task and 0.0013361586024984717 recon and 3.7137999534606934 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006665059057995677\n",
      "\n",
      "Total loss: 0.007022900506854057; that's 0.004605189431458712 task and 0.0013104865793138742 recon and 5.536120891571045 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006755531230010092\n",
      "\n",
      "Total loss: 6.742353916168213:\n",
      "5.232766151428223 control,\n",
      "0.39193856716156006 lrg,\n",
      "0.4250435531139374 udg,\n",
      "0.3489685654640198 lra,\n",
      "0.3436371982097626 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.921972002983093\n",
      "\n",
      "Total loss: 4.263948917388916:\n",
      "2.7426564693450928 control,\n",
      "0.405808687210083 lrg,\n",
      "0.42693030834198 udg,\n",
      "0.33586984872817993 lra,\n",
      "0.3526833653450012 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.087752685546875\n",
      "\n",
      "Total loss: 0.006417450495064259; that's 0.004467160440981388 task and 0.0013410596875473857 recon and 3.0461513996124268 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006728405985049903\n",
      "\n",
      "Total loss: 4.582943916320801:\n",
      "3.016228199005127 control,\n",
      "0.4129505455493927 lrg,\n",
      "0.4540557861328125 udg,\n",
      "0.35249918699264526 lra,\n",
      "0.3472106456756592 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.464949758052826\n",
      "\n",
      "Total loss: 0.006956490222364664; that's 0.004942191764712334 task and 0.0013483681250363588 recon and 3.32965350151062 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006483665406703949\n",
      "\n",
      "Total loss: 4.273153781890869:\n",
      "2.7262580394744873 control,\n",
      "0.41763702034950256 lrg,\n",
      "0.4286190867424011 udg,\n",
      "0.3560418486595154 lra,\n",
      "0.34459763765335083 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.425406074523925\n",
      "\n",
      "Total loss: 0.0059896777383983135; that's 0.004093438386917114 task and 0.0012993719428777695 recon and 2.984337329864502 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006522534349933266\n",
      "\n",
      "Total loss: 4.874789714813232:\n",
      "3.2702109813690186 control,\n",
      "0.4170714020729065 lrg,\n",
      "0.47072163224220276 udg,\n",
      "0.35233160853385925 lra,\n",
      "0.3644544184207916 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.662151620388031\n",
      "\n",
      "Total loss: 0.006661604158580303; that's 0.0046308450400829315 task and 0.0013146401615813375 recon and 3.580594301223755 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006557925371453166\n",
      "\n",
      "Total loss: 6.41487979888916:\n",
      "4.738426208496094 control,\n",
      "0.48219063878059387 lrg,\n",
      "0.5110421776771545 udg,\n",
      "0.3505169749259949 lra,\n",
      "0.33270418643951416 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.84476836681366\n",
      "\n",
      "Total loss: 0.007043793797492981; that's 0.004694188479334116 task and 0.0013350681401789188 recon and 5.0726847648620605 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006851841108873487\n",
      "\n",
      "Total loss: 6.681188106536865:\n",
      "5.034041404724121 control,\n",
      "0.44350096583366394 lrg,\n",
      "0.4693804681301117 udg,\n",
      "0.38144955039024353 lra,\n",
      "0.3528155982494354 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.49327323436737\n",
      "\n",
      "Total loss: 0.007465968374162912; that's 0.005066428799182177 task and 0.001318654976785183 recon and 5.404422283172607 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0068808710481971505\n",
      "\n",
      "Total loss: 0.005865545477718115; that's 0.003919464536011219 task and 0.0012944425689056516 recon and 3.258193254470825 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006775652798824012\n",
      "\n",
      "Total loss: 4.456951141357422:\n",
      "2.9185163974761963 control,\n",
      "0.37453410029411316 lrg,\n",
      "0.43201950192451477 udg,\n",
      "0.39312973618507385 lra,\n",
      "0.3387511074542999 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.026725740432739\n",
      "\n",
      "Total loss: 4.161147594451904:\n",
      "2.711686372756958 control,\n",
      "0.41056784987449646 lrg,\n",
      "0.43494799733161926 udg,\n",
      "0.2965141236782074 lra,\n",
      "0.30743131041526794 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.800371994972229\n",
      "\n",
      "Total loss: 0.006930882576853037; that's 0.005065543111413717 task and 0.0012673079036176205 recon and 2.9901580810546875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006530141937546432\n",
      "\n",
      "Total loss: 0.0056578959338366985; that's 0.003813528222963214 task and 0.0013052528956905007 recon and 2.695573329925537 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0064082522178068755\n",
      "\n",
      "Total loss: 3.968341588973999:\n",
      "2.383870840072632 control,\n",
      "0.4123898148536682 lrg,\n",
      "0.4571673572063446 udg,\n",
      "0.34856703877449036 lra,\n",
      "0.3663465976715088 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.166755502223968\n",
      "\n",
      "Total loss: 0.00719813397154212; that's 0.0051509179174900055 task and 0.0012983822962269187 recon and 3.744169235229492 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006807358721271157\n",
      "\n",
      "Total loss: 4.962765216827393:\n",
      "3.4029541015625 control,\n",
      "0.4442896842956543 lrg,\n",
      "0.43906494975090027 udg,\n",
      "0.3365199565887451 lra,\n",
      "0.339936763048172 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.995461051464081\n",
      "\n",
      "Total loss: 0.006404707673937082; that's 0.004303725901991129 task and 0.0014207041822373867 recon and 3.401388645172119 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006477822866290808\n",
      "\n",
      "Total loss: 4.661876201629639:\n",
      "3.122898817062378 control,\n",
      "0.4184474050998688 lrg,\n",
      "0.4429147243499756 udg,\n",
      "0.3192691504955292 lra,\n",
      "0.35834580659866333 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.412461249828339\n",
      "\n",
      "Total loss: 0.0076207444071769714; that's 0.004936153069138527 task and 0.0017116385279223323 recon and 4.8647637367248535 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.007038172888569534\n",
      "\n",
      "Total loss: 6.1830363273620605:\n",
      "4.5712571144104 control,\n",
      "0.4802158772945404 lrg,\n",
      "0.44860002398490906 udg,\n",
      "0.3338899612426758 lra,\n",
      "0.3490736186504364 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.072515864372253\n",
      "\n",
      "Total loss: 0.009951284155249596; that's 0.0058310809545218945 task and 0.0029595172964036465 recon and 5.803427696228027 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006945485095493495\n",
      "\n",
      "Total loss: 7.160548210144043:\n",
      "5.569069862365723 control,\n",
      "0.4559784531593323 lrg,\n",
      "0.4655231833457947 udg,\n",
      "0.3488604724407196 lra,\n",
      "0.32111647725105286 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.463285965919495\n",
      "\n",
      "Total loss: 0.006842442322522402; that's 0.004764178302139044 task and 0.0013105643447488546 recon and 3.838498830795288 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006825684984214604\n",
      "\n",
      "Total loss: 5.054068565368652:\n",
      "3.552706003189087 control,\n",
      "0.3861614465713501 lrg,\n",
      "0.44478756189346313 udg,\n",
      "0.31573086977005005 lra,\n",
      "0.3546822667121887 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.706084914207459\n",
      "\n",
      "Total loss: 5.719005107879639:\n",
      "4.157704830169678 control,\n",
      "0.412536084651947 lrg,\n",
      "0.4431430995464325 udg,\n",
      "0.35865435004234314 lra,\n",
      "0.34696659445762634 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.598142743110657\n",
      "\n",
      "Total loss: 0.006302841939032078; that's 0.004113486967980862 task and 0.0013051942223683 recon and 4.420804500579834 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006591880405321718\n",
      "\n",
      "Total loss: 5.9685564041137695:\n",
      "4.3859429359436035 control,\n",
      "0.44828638434410095 lrg,\n",
      "0.43423449993133545 udg,\n",
      "0.33538803458213806 lra,\n",
      "0.3647039532661438 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.646878757476807\n",
      "\n",
      "Total loss: 0.007043831516057253; that's 0.004814657848328352 task and 0.0012945012422278523 recon and 4.6733622550964355 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006685357741080224\n",
      "\n",
      "Total loss: 7.0565996170043945:\n",
      "5.520373344421387 control,\n",
      "0.39655959606170654 lrg,\n",
      "0.48550793528556824 udg,\n",
      "0.32309862971305847 lra,\n",
      "0.3310597240924835 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.659220247268677\n",
      "\n",
      "Total loss: 0.006590747274458408; that's 0.004171289503574371 task and 0.0012665921822190285 recon and 5.764328956604004 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006745275971479714\n",
      "\n",
      "Total loss: 5.5680036544799805:\n",
      "3.9811289310455322 control,\n",
      "0.44175729155540466 lrg,\n",
      "0.43643918633461 udg,\n",
      "0.34074968099594116 lra,\n",
      "0.36792856454849243 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.567683758735657\n",
      "\n",
      "Total loss: 0.006461185868829489; that's 0.0043242257088422775 task and 0.0012734950287267566 recon and 4.317326068878174 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006719939988106489\n",
      "\n",
      "Total loss: 0.006884546019136906; that's 0.004588061943650246 task and 0.0012800757540389895 recon and 5.082041263580322 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006432512425817549\n",
      "\n",
      "Total loss: 6.335457801818848:\n",
      "4.765498638153076 control,\n",
      "0.42578646540641785 lrg,\n",
      "0.4611336588859558 udg,\n",
      "0.3496638834476471 lra,\n",
      "0.33337530493736267 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.9086563324928285\n",
      "\n",
      "Total loss: 3.9443955421447754:\n",
      "2.4111902713775635 control,\n",
      "0.41112634539604187 lrg,\n",
      "0.433027982711792 udg,\n",
      "0.349447637796402 lra,\n",
      "0.3396032452583313 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.146389088630676\n",
      "\n",
      "Total loss: 0.006345580331981182; that's 0.00451870821416378 task and 0.0012736821081489325 recon and 2.7659499645233154 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006673427023924887\n",
      "\n",
      "Total loss: 0.006144409067928791; that's 0.004367568995803595 task and 0.0012546564685180783 recon and 2.610917568206787 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006493399003520608\n",
      "\n",
      "Total loss: 3.8861570358276367:\n",
      "2.2812769412994385 control,\n",
      "0.4318367838859558 lrg,\n",
      "0.4312992990016937 udg,\n",
      "0.37807437777519226 lra,\n",
      "0.3636697232723236 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.593668529987335\n",
      "\n",
      "Total loss: 0.006241098046302795; that's 0.003868021070957184 task and 0.0013602497056126595 recon and 5.064136505126953 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00642814033664763\n",
      "\n",
      "Total loss: 6.252902030944824:\n",
      "4.7393035888671875 control,\n",
      "0.3900502622127533 lrg,\n",
      "0.4363389313220978 udg,\n",
      "0.3382241427898407 lra,\n",
      "0.3489851951599121 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.523507843017578\n",
      "\n",
      "Total loss: 3.9444806575775146:\n",
      "2.3465700149536133 control,\n",
      "0.46404924988746643 lrg,\n",
      "0.4629468619823456 udg,\n",
      "0.31823933124542236 lra,\n",
      "0.3526752293109894 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.632799446582794\n",
      "\n",
      "Total loss: 0.0065788449719548225; that's 0.004729146137833595 task and 0.001324440585449338 recon and 2.6262922286987305 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006532803708687425\n",
      "\n",
      "Total loss: 0.0065836310386657715; that's 0.004825963173061609 task and 0.0012768146116286516 recon and 2.4042651653289795 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006565963919274509\n",
      "\n",
      "Total loss: 3.694683074951172:\n",
      "2.043781280517578 control,\n",
      "0.4543124735355377 lrg,\n",
      "0.47863319516181946 udg,\n",
      "0.37533605098724365 lra,\n",
      "0.34261980652809143 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.8964125490188595\n",
      "\n",
      "Total loss: 5.5193376541137695:\n",
      "3.9592950344085693 control,\n",
      "0.44505032896995544 lrg,\n",
      "0.4523096978664398 udg,\n",
      "0.33460086584091187 lra,\n",
      "0.32808151841163635 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.847256579399109\n",
      "\n",
      "Total loss: 0.00615121703594923; that's 0.004049866925925016 task and 0.0012352719204500318 recon and 4.330390453338623 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006528830220922828\n",
      "\n",
      "Total loss: 0.006706321612000465; that's 0.004909520968794823 task and 0.001233668066561222 recon and 2.8156628608703613 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006494635315611959\n",
      "\n",
      "Total loss: 4.031321048736572:\n",
      "2.4756264686584473 control,\n",
      "0.43372154235839844 lrg,\n",
      "0.4517734944820404 udg,\n",
      "0.3385728597640991 lra,\n",
      "0.331626832485199 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.061468002796173\n",
      "\n",
      "Total loss: 0.005897095892578363; that's 0.0041605145670473576 task and 0.001228039967827499 recon and 2.5427067279815674 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0064655555039644244\n",
      "\n",
      "Total loss: 3.820021629333496:\n",
      "2.2327754497528076 control,\n",
      "0.4190138578414917 lrg,\n",
      "0.489692747592926 udg,\n",
      "0.35421767830848694 lra,\n",
      "0.324321985244751 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.834707357883453\n",
      "\n",
      "Total loss: 3.895014524459839:\n",
      "2.3168087005615234 control,\n",
      "0.4243238568305969 lrg,\n",
      "0.44541090726852417 udg,\n",
      "0.37102219462394714 lra,\n",
      "0.33744874596595764 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.775237038135528\n",
      "\n",
      "Total loss: 0.006484858691692352; that's 0.004711829591542482 task and 0.0012481114827096462 recon and 2.6245880126953125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006442479542456568\n",
      "\n",
      "Total loss: 0.00645569758489728; that's 0.004676637705415487 task and 0.0012561085168272257 recon and 2.614755630493164 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006355733871459961\n",
      "\n",
      "Total loss: 3.88810396194458:\n",
      "2.2858691215515137 control,\n",
      "0.4163973927497864 lrg,\n",
      "0.47477060556411743 udg,\n",
      "0.3513648211956024 lra,\n",
      "0.35970211029052734 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.885657694339752\n",
      "\n",
      "Total loss: 4.361724376678467:\n",
      "2.7972841262817383 control,\n",
      "0.4324547350406647 lrg,\n",
      "0.44102832674980164 udg,\n",
      "0.3309482932090759 lra,\n",
      "0.3600088357925415 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.6647577714920043\n",
      "\n",
      "Total loss: 0.0064056143164634705; that's 0.004496857523918152 task and 0.0012764594284817576 recon and 3.1614856719970703 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006145222103223205\n",
      "\n",
      "Total loss: 6.244754791259766:\n",
      "4.677178859710693 control,\n",
      "0.42103174328804016 lrg,\n",
      "0.46138325333595276 udg,\n",
      "0.35630014538764954 lra,\n",
      "0.32886019349098206 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.215200304985046\n",
      "\n",
      "Total loss: 0.006945684552192688; that's 0.004680020269006491 task and 0.0012689067516475916 recon and 4.983787536621094 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0065529133332893254\n",
      "\n",
      "Total loss: 0.007048781029880047; that's 0.004658831283450127 task and 0.0012181202182546258 recon and 5.859148025512695 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006735864640213549\n",
      "\n",
      "Total loss: 7.132203578948975:\n",
      "5.557722568511963 control,\n",
      "0.4218897521495819 lrg,\n",
      "0.45443469285964966 udg,\n",
      "0.350391149520874 lra,\n",
      "0.3477652370929718 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.080167536735535\n",
      "\n",
      "Total loss: 4.616398334503174:\n",
      "3.0601680278778076 control,\n",
      "0.4198632836341858 lrg,\n",
      "0.4277980625629425 udg,\n",
      "0.3763715922832489 lra,\n",
      "0.3321975767612457 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.925776872634888\n",
      "\n",
      "Total loss: 0.0064081717282533646; that's 0.00456982059404254 task and 0.0011813321616500616 recon and 3.28509521484375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006561221987940371\n",
      "\n",
      "Total loss: 7.348935604095459:\n",
      "5.8353352546691895 control,\n",
      "0.42266809940338135 lrg,\n",
      "0.39353805780410767 udg,\n",
      "0.3224026560783386 lra,\n",
      "0.37499168515205383 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.564456210136414\n",
      "\n",
      "Total loss: 0.007362809963524342; that's 0.00491879740729928 task and 0.0012205622624605894 recon and 6.117251873016357 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006760246506892145\n",
      "\n",
      "Total loss: 0.006463808007538319; that's 0.004577638581395149 task and 0.001244359533302486 recon and 3.209050178527832 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0063925329782068725\n",
      "\n",
      "Total loss: 4.461264610290527:\n",
      "2.89013409614563 control,\n",
      "0.423831969499588 lrg,\n",
      "0.46466678380966187 udg,\n",
      "0.34867051243782043 lra,\n",
      "0.33396098017692566 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.854954659938812\n",
      "\n",
      "Total loss: 3.4636030197143555:\n",
      "1.9150108098983765 control,\n",
      "0.39285650849342346 lrg,\n",
      "0.4711115062236786 udg,\n",
      "0.3423914313316345 lra,\n",
      "0.3422326147556305 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.879212098121643\n",
      "\n",
      "Total loss: 0.006295425351709127; that's 0.004639882128685713 task and 0.0012196452589705586 recon and 2.179490089416504 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006161938542500138\n",
      "\n",
      "Total loss: 0.006724681705236435; that's 0.004956755321472883 task and 0.001211795606650412 recon and 2.7806549072265625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0061823184136301276\n",
      "\n",
      "Total loss: 4.0301618576049805:\n",
      "2.4288344383239746 control,\n",
      "0.4163345992565155 lrg,\n",
      "0.44986534118652344 udg,\n",
      "0.3820786476135254 lra,\n",
      "0.3530486524105072 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.7805313992500307\n",
      "\n",
      "Total loss: 3.5716021060943604:\n",
      "2.1054868698120117 control,\n",
      "0.4035676121711731 lrg,\n",
      "0.43812042474746704 udg,\n",
      "0.2938879430294037 lra,\n",
      "0.3305395245552063 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.6003591227531433\n",
      "\n",
      "Total loss: 0.006087933201342821; that's 0.004425673745572567 task and 0.0011841055238619447 recon and 2.3907694816589355 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006120415884070098\n",
      "\n",
      "Total loss: 3.655632257461548:\n",
      "2.183560848236084 control,\n",
      "0.3971519470214844 lrg,\n",
      "0.4324186146259308 udg,\n",
      "0.3161216974258423 lra,\n",
      "0.32637903094291687 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.6551523780822754\n",
      "\n",
      "Total loss: 0.006465734448283911; that's 0.00477404473349452 task and 0.0011970341438427567 recon and 2.4732778072357178 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0061993487784639005\n",
      "\n",
      "Total loss: 0.0057248868979513645; that's 0.004073143936693668 task and 0.0012036814587190747 recon and 2.2403087615966797 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006123303156346083\n",
      "\n",
      "Total loss: 3.504300117492676:\n",
      "1.9151867628097534 control,\n",
      "0.40727391839027405 lrg,\n",
      "0.5012478828430176 udg,\n",
      "0.332050621509552 lra,\n",
      "0.3485410511493683 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.701701784133911\n",
      "\n",
      "Total loss: 3.575786590576172:\n",
      "2.052300453186035 control,\n",
      "0.4265856146812439 lrg,\n",
      "0.4152257740497589 udg,\n",
      "0.3038673996925354 lra,\n",
      "0.3778073489665985 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.6816392493247987\n",
      "\n",
      "Total loss: 0.0062899901531636715; that's 0.004639994353055954 task and 0.0011853931937366724 recon and 2.3230137825012207 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006155147165991366\n",
      "\n",
      "Total loss: 4.141246795654297:\n",
      "2.5910561084747314 control,\n",
      "0.43379777669906616 lrg,\n",
      "0.42052793502807617 udg,\n",
      "0.3439588248729706 lra,\n",
      "0.35190609097480774 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.603707449436188\n",
      "\n",
      "Total loss: 0.006408564746379852; that's 0.004640122409909964 task and 0.0011937947710976005 recon and 2.8732376098632812 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006124202637001872\n",
      "\n",
      "Total loss: 0.006588781252503395; that's 0.004802055191248655 task and 0.0011909797322005033 recon and 2.978733777999878 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006111553153023124\n",
      "\n",
      "Total loss: 4.212287425994873:\n",
      "2.681497573852539 control,\n",
      "0.40278834104537964 lrg,\n",
      "0.4372614324092865 udg,\n",
      "0.33515167236328125 lra,\n",
      "0.3555883467197418 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.5882293438911437\n",
      "\n",
      "Total loss: 3.603792190551758:\n",
      "2.0204687118530273 control,\n",
      "0.41440683603286743 lrg,\n",
      "0.44532907009124756 udg,\n",
      "0.3514373004436493 lra,\n",
      "0.3721502423286438 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.5470936942100524\n",
      "\n",
      "Total loss: 0.005976830143481493; that's 0.004322194494307041 task and 0.0011922053527086973 recon and 2.3121492862701416 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00603733291849494\n",
      "\n",
      "Total loss: 3.566502809524536:\n",
      "2.0684335231781006 control,\n",
      "0.39827674627304077 lrg,\n",
      "0.4594472050666809 udg,\n",
      "0.3208658695220947 lra,\n",
      "0.3194795250892639 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.541538598537445\n",
      "\n",
      "Total loss: 0.005775368306785822; that's 0.0041219317354261875 task and 0.0011847105342894793 recon and 2.343630075454712 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006020709392614663\n",
      "\n",
      "Total loss: 3.752106189727783:\n",
      "2.2420406341552734 control,\n",
      "0.40517017245292664 lrg,\n",
      "0.4528456926345825 udg,\n",
      "0.3254813253879547 lra,\n",
      "0.3265681266784668 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.589949426651001\n",
      "\n",
      "Total loss: 0.006764126941561699; that's 0.005073663778603077 task and 0.0011867987923324108 recon and 2.5183231830596924 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006045113638974726\n",
      "\n",
      "Total loss: 3.3964481353759766:\n",
      "1.838904857635498 control,\n",
      "0.39912521839141846 lrg,\n",
      "0.4752597510814667 udg,\n",
      "0.3321378827095032 lra,\n",
      "0.3510206341743469 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.5889638328552245\n",
      "\n",
      "Total loss: 0.006707040127366781; that's 0.0050470479764044285 task and 0.0012343550333753228 recon and 2.1281867027282715 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006135337445884943\n",
      "\n",
      "Total loss: 3.4995720386505127:\n",
      "1.9049320220947266 control,\n",
      "0.44149351119995117 lrg,\n",
      "0.4341840147972107 udg,\n",
      "0.3521859645843506 lra,\n",
      "0.3667764961719513 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.570435678958893\n",
      "\n",
      "Total loss: 0.00618028175085783; that's 0.00451824301853776 task and 0.0012138423044234514 recon and 2.2409820556640625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006033888864330947\n",
      "\n",
      "Total loss: 3.9496071338653564:\n",
      "2.4397168159484863 control,\n",
      "0.3857164978981018 lrg,\n",
      "0.45006608963012695 udg,\n",
      "0.32664328813552856 lra,\n",
      "0.34746453166007996 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.652872774600983\n",
      "\n",
      "Total loss: 0.006331100594252348; that's 0.004566669464111328 task and 0.0012274913024157286 recon and 2.6846985816955566 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006126872980967164\n",
      "\n",
      "Total loss: 0.006579018663614988; that's 0.004917188547551632 task and 0.0011779401684179902 recon and 2.419450044631958 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006064003179781139\n",
      "\n",
      "Total loss: 3.645906686782837:\n",
      "2.0765902996063232 control,\n",
      "0.4503312408924103 lrg,\n",
      "0.452897310256958 udg,\n",
      "0.3349723219871521 lra,\n",
      "0.33111557364463806 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.645167043209076\n",
      "\n",
      "Total loss: 3.6384928226470947:\n",
      "2.11495041847229 control,\n",
      "0.40200430154800415 lrg,\n",
      "0.46274834871292114 udg,\n",
      "0.32772403955459595 lra,\n",
      "0.3310658931732178 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.661985144615173\n",
      "\n",
      "Total loss: 0.006186740938574076; that's 0.004544627387076616 task and 0.0011649815132841468 recon and 2.385660171508789 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006054041031748056\n",
      "\n",
      "Total loss: 0.007049289997667074; that's 0.005339457653462887 task and 0.0011856926139444113 recon and 2.620696544647217 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006050198287703097\n",
      "\n",
      "Total loss: 3.849419593811035:\n",
      "2.2881593704223633 control,\n",
      "0.42561280727386475 lrg,\n",
      "0.44657763838768005 udg,\n",
      "0.3437628149986267 lra,\n",
      "0.3453069031238556 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.723358769416809\n",
      "\n",
      "Total loss: 0.005783428903669119; that's 0.0041363416239619255 task and 0.0012195351300761104 recon and 2.137759208679199 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006059607835486531\n",
      "\n",
      "Total loss: 3.3858816623687744:\n",
      "1.8440122604370117 control,\n",
      "0.4121800661087036 lrg,\n",
      "0.42455679178237915 udg,\n",
      "0.35429149866104126 lra,\n",
      "0.35084134340286255 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.791814329624176\n",
      "\n",
      "Total loss: 0.005741268862038851; that's 0.004162128083407879 task and 0.0011693256674334407 recon and 2.049074649810791 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006068587950430811\n",
      "\n",
      "Total loss: 3.231245994567871:\n",
      "1.7470372915267944 control,\n",
      "0.38065215945243835 lrg,\n",
      "0.4115809202194214 udg,\n",
      "0.3547365963459015 lra,\n",
      "0.3372389078140259 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.9044307017326356\n",
      "\n",
      "Total loss: 0.005654222331941128; that's 0.0039787511341273785 task and 0.0011761978967115283 recon and 2.496365547180176 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006086125141009689\n",
      "\n",
      "Total loss: 3.7185187339782715:\n",
      "2.1825735569000244 control,\n",
      "0.42596960067749023 lrg,\n",
      "0.42289087176322937 udg,\n",
      "0.3461586833000183 lra,\n",
      "0.340925931930542 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.6147231125831603\n",
      "\n",
      "Total loss: 0.006129673216491938; that's 0.004439660347998142 task and 0.001181075582280755 recon and 2.5446884632110596 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006064860541373491\n",
      "\n",
      "Total loss: 3.7491865158081055:\n",
      "2.172327995300293 control,\n",
      "0.43602877855300903 lrg,\n",
      "0.4633159935474396 udg,\n",
      "0.36003556847572327 lra,\n",
      "0.31747812032699585 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.6964198422431944\n",
      "\n",
      "Total loss: 0.006234645843505859; that's 0.004661169834434986 task and 0.0011623105965554714 recon and 2.055828094482422 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005993033898994327\n",
      "\n",
      "Total loss: 3.2352993488311768:\n",
      "1.7772650718688965 control,\n",
      "0.38664302229881287 lrg,\n",
      "0.4126525819301605 udg,\n",
      "0.32584869861602783 lra,\n",
      "0.33289024233818054 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.6296816658973694\n",
      "\n",
      "Total loss: 0.005929409060627222; that's 0.0042349472641944885 task and 0.0011857280042022467 recon and 2.543668270111084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006015617973171175\n",
      "\n",
      "Total loss: 3.7972700595855713:\n",
      "2.259216785430908 control,\n",
      "0.38522568345069885 lrg,\n",
      "0.44963538646698 udg,\n",
      "0.34732604026794434 lra,\n",
      "0.355866014957428 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.6356473565101624\n",
      "\n",
      "Total loss: 4.175447463989258:\n",
      "2.6491317749023438 control,\n",
      "0.42097151279449463 lrg,\n",
      "0.41766130924224854 udg,\n",
      "0.318830668926239 lra,\n",
      "0.3688521981239319 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.670956988334656\n",
      "\n",
      "Total loss: 0.0063688200898468494; that's 0.004597794730216265 task and 0.001192284980788827 recon and 2.8937015533447266 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00598152035381645\n",
      "\n",
      "Total loss: 0.00582452118396759; that's 0.004279609303921461 task and 0.0011233980767428875 recon and 2.1075680255889893 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00598387308884412\n",
      "\n",
      "Total loss: 3.363445997238159:\n",
      "1.817275047302246 control,\n",
      "0.444478303194046 lrg,\n",
      "0.43746694922447205 udg,\n",
      "0.3373463451862335 lra,\n",
      "0.3268795609474182 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.641721568107605\n",
      "\n",
      "Total loss: 4.163877487182617:\n",
      "2.5999605655670166 control,\n",
      "0.4145166873931885 lrg,\n",
      "0.4596266746520996 udg,\n",
      "0.36117827892303467 lra,\n",
      "0.32859528064727783 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.6136033582687377\n",
      "\n",
      "Total loss: 0.005855747498571873; that's 0.004136776551604271 task and 0.0011254333658143878 recon and 2.967686653137207 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00599217967595905\n",
      "\n",
      "Total loss: 0.00665302574634552; that's 0.005071917083114386 task and 0.0010974647011607885 recon and 2.4182205200195312 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00595772113185376\n",
      "\n",
      "Total loss: 3.7252237796783447:\n",
      "2.0881288051605225 control,\n",
      "0.4643746614456177 lrg,\n",
      "0.46702471375465393 udg,\n",
      "0.3528112769126892 lra,\n",
      "0.3528841435909271 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.602236659526825\n",
      "\n",
      "Total loss: 0.006309014745056629; that's 0.0046354844234883785 task and 0.0011074811918660998 recon and 2.830245018005371 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00597429049666971\n",
      "\n",
      "Total loss: 4.076491832733154:\n",
      "2.4768919944763184 control,\n",
      "0.44239163398742676 lrg,\n",
      "0.45454156398773193 udg,\n",
      "0.3332672119140625 lra,\n",
      "0.3693997263908386 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.647319107055664\n",
      "\n",
      "Total loss: 3.575402021408081:\n",
      "2.0051724910736084 control,\n",
      "0.43206584453582764 lrg,\n",
      "0.4351383447647095 udg,\n",
      "0.35378098487854004 lra,\n",
      "0.34924450516700745 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.6620626258850097\n",
      "\n",
      "Total loss: 0.006713413633406162; that's 0.0051604704931378365 task and 0.0010963070672005415 recon and 2.2831785678863525 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005979294953867793\n",
      "\n",
      "Total loss: 3.6978390216827393:\n",
      "2.1087684631347656 control,\n",
      "0.4184665381908417 lrg,\n",
      "0.4583795964717865 udg,\n",
      "0.35615310072898865 lra,\n",
      "0.3560713827610016 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.645416715145111\n",
      "\n",
      "Total loss: 0.005855906289070845; that's 0.00422163400799036 task and 0.0011451628524810076 recon and 2.4455490112304688 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005931489281356335\n",
      "\n",
      "Total loss: 0.00632366631180048; that's 0.004746541380882263 task and 0.0011329464614391327 recon and 2.2208919525146484 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005909679271280765\n",
      "\n",
      "Total loss: 3.3752191066741943:\n",
      "1.86394202709198 control,\n",
      "0.38107430934906006 lrg,\n",
      "0.43109601736068726 udg,\n",
      "0.3632921874523163 lra,\n",
      "0.33581453561782837 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.6918628931045534\n",
      "\n",
      "Total loss: 0.005974777974188328; that's 0.0043303463608026505 task and 0.0011302487691864371 recon and 2.5709149837493896 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0059024658566340805\n",
      "\n",
      "Total loss: 3.9949324131011963:\n",
      "2.3052127361297607 control,\n",
      "0.4577544629573822 lrg,\n",
      "0.4896230697631836 udg,\n",
      "0.36813339591026306 lra,\n",
      "0.3742089569568634 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.7015050148963926\n",
      "\n",
      "Total loss: 3.810741662979126:\n",
      "2.1765458583831787 control,\n",
      "0.45049434900283813 lrg,\n",
      "0.47347402572631836 udg,\n",
      "0.3505125939846039 lra,\n",
      "0.3597150146961212 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.694276742935181\n",
      "\n",
      "Total loss: 0.0058139618486166; that's 0.004246668424457312 task and 0.0010683551663532853 recon and 2.4946916103363037 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005907059125602246\n",
      "\n",
      "Total loss: 0.006436246447265148; that's 0.004461285192519426 task and 0.0011240908643230796 recon and 4.2543511390686035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0065244411397725344\n",
      "\n",
      "Total loss: 5.3915815353393555:\n",
      "3.8642807006835938 control,\n",
      "0.4060265123844147 lrg,\n",
      "0.45006102323532104 udg,\n",
      "0.3386595845222473 lra,\n",
      "0.3325536847114563 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.386446809768676\n",
      "\n",
      "Total loss: 0.005708969198167324; that's 0.00362174934707582 task and 0.0011098505929112434 recon and 4.886845111846924 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006468289457261562\n",
      "\n",
      "Total loss: 6.241170406341553:\n",
      "4.634305000305176 control,\n",
      "0.41907984018325806 lrg,\n",
      "0.5009613633155823 udg,\n",
      "0.3517856001853943 lra,\n",
      "0.3350384831428528 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.984407005310058\n",
      "\n",
      "Total loss: 4.050865173339844:\n",
      "2.5161681175231934 control,\n",
      "0.42717671394348145 lrg,\n",
      "0.4251856207847595 udg,\n",
      "0.36182284355163574 lra,\n",
      "0.3205115795135498 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.743507537841797\n",
      "\n",
      "Total loss: 0.006475568283349276; that's 0.0048350072465837 task and 0.0010991571471095085 recon and 2.7070202827453613 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006286785583943129\n",
      "\n",
      "Total loss: 4.099363327026367:\n",
      "2.5645534992218018 control,\n",
      "0.3843897581100464 lrg,\n",
      "0.4223474860191345 udg,\n",
      "0.36727017164230347 lra,\n",
      "0.36080241203308105 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.929425415992737\n",
      "\n",
      "Total loss: 0.0062802983447909355; that's 0.004628483671694994 task and 0.0010975087061524391 recon and 2.771531105041504 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006021176781505346\n",
      "\n",
      "Total loss: 0.005957460962235928; that's 0.0039575425907969475 task and 0.001255091279745102 recon and 3.7241368293762207 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00626809174194932\n",
      "\n",
      "Total loss: 5.058366298675537:\n",
      "3.3884363174438477 control,\n",
      "0.4726012945175171 lrg,\n",
      "0.43417391180992126 udg,\n",
      "0.3513879179954529 lra,\n",
      "0.41176658868789673 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.422119927406311\n",
      "\n",
      "Total loss: 0.005613558925688267; that's 0.004006152972579002 task and 0.0010716458782553673 recon and 2.6788010597229004 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006035289969295263\n",
      "\n",
      "Total loss: 3.8901655673980713:\n",
      "2.3773887157440186 control,\n",
      "0.4113997220993042 lrg,\n",
      "0.4480270743370056 udg,\n",
      "0.33026641607284546 lra,\n",
      "0.3230837285518646 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.853307373523712\n",
      "\n",
      "Total loss: 3.560739755630493:\n",
      "1.9931793212890625 control,\n",
      "0.45162612199783325 lrg,\n",
      "0.46730926632881165 udg,\n",
      "0.34336477518081665 lra,\n",
      "0.30526039004325867 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.653637158870697\n",
      "\n",
      "Total loss: 0.005577204283326864; that's 0.004037358332425356 task and 0.001083475537598133 recon and 2.281851291656494 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005938632399775088\n",
      "\n",
      "Total loss: 3.497567892074585:\n",
      "1.9298202991485596 control,\n",
      "0.38613587617874146 lrg,\n",
      "0.5017212629318237 udg,\n",
      "0.3436858355998993 lra,\n",
      "0.33620455861091614 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.5099187541007995\n",
      "\n",
      "Total loss: 0.006383037194609642; that's 0.004869752563536167 task and 0.001056886394508183 recon and 2.2819929122924805 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0058715779334306715\n",
      "\n",
      "Total loss: 0.0054614124819636345; that's 0.00395823922008276 task and 0.001067400211468339 recon and 2.178866386413574 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005872781313955784\n",
      "\n",
      "Total loss: 3.4702305793762207:\n",
      "1.8759667873382568 control,\n",
      "0.47614023089408875 lrg,\n",
      "0.4102628827095032 udg,\n",
      "0.3668729066848755 lra,\n",
      "0.34098756313323975 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.546882486343384\n",
      "\n",
      "Total loss: 3.947021961212158:\n",
      "2.3903307914733887 control,\n",
      "0.3996889889240265 lrg,\n",
      "0.48471173644065857 udg,\n",
      "0.344228595495224 lra,\n",
      "0.32806217670440674 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.563021376132965\n",
      "\n",
      "Total loss: 0.005566873587667942; that's 0.003953633829951286 task and 0.0010852852137759328 recon and 2.63977313041687 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005864583523944021\n",
      "\n",
      "Total loss: 3.594205617904663:\n",
      "2.002004861831665 control,\n",
      "0.4499175548553467 lrg,\n",
      "0.43932071328163147 udg,\n",
      "0.3650650382041931 lra,\n",
      "0.33789733052253723 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.5742647290229796\n",
      "\n",
      "Total loss: 0.006680171005427837; that's 0.005168414209038019 task and 0.0010542511008679867 recon and 2.287527322769165 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005768259768374264\n",
      "\n",
      "Total loss: 0.005730522330850363; that's 0.004207300022244453 task and 0.0010605357820168138 recon and 2.3134329319000244 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0058019994571805004\n",
      "\n",
      "Total loss: 3.6709494590759277:\n",
      "2.012482166290283 control,\n",
      "0.41188299655914307 lrg,\n",
      "0.47688764333724976 udg,\n",
      "0.39710402488708496 lra,\n",
      "0.3725927770137787 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.5762932658195496\n",
      "\n",
      "Total loss: 4.003778457641602:\n",
      "2.440152883529663 control,\n",
      "0.40868040919303894 lrg,\n",
      "0.4461812973022461 udg,\n",
      "0.34443798661231995 lra,\n",
      "0.36432555317878723 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.6105642223358156\n",
      "\n",
      "Total loss: 0.005678964778780937; that's 0.004083747509866953 task and 0.0010447913082316518 recon and 2.7521305084228516 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005846747742034495\n",
      "\n",
      "Total loss: 3.736394166946411:\n",
      "2.2328896522521973 control,\n",
      "0.3957451283931732 lrg,\n",
      "0.43420952558517456 udg,\n",
      "0.33457422256469727 lra,\n",
      "0.3389756381511688 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.7568375945091246\n",
      "\n",
      "Total loss: 0.00612649554386735; that's 0.004492203239351511 task and 0.001126653514802456 recon and 2.538193702697754 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005913141444325447\n",
      "\n",
      "Total loss: 3.2445597648620605:\n",
      "1.6365740299224854 control,\n",
      "0.4894118010997772 lrg,\n",
      "0.4587240517139435 udg,\n",
      "0.32795828580856323 lra,\n",
      "0.3318914771080017 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.578546280860901\n",
      "\n",
      "Total loss: 0.005141204223036766; that's 0.0036993958055973053 task and 0.0010526528349146247 recon and 1.9457768201828003 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0057480813097208735\n",
      "\n",
      "Total loss: 3.3146891593933105:\n",
      "1.7537981271743774 control,\n",
      "0.40916597843170166 lrg,\n",
      "0.45818814635276794 udg,\n",
      "0.3445625901222229 lra,\n",
      "0.3489744961261749 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.4758329653739928\n",
      "\n",
      "Total loss: 0.006297652143985033; that's 0.004839247092604637 task and 0.001039391616359353 recon and 2.0950677394866943 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005793937076814473\n",
      "\n",
      "Total loss: 0.0055333031341433525; that's 0.004079509060829878 task and 0.0010191757464781404 recon and 2.173092842102051 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005824899589642882\n",
      "\n",
      "Total loss: 3.401737689971924:\n",
      "1.8042653799057007 control,\n",
      "0.40497541427612305 lrg,\n",
      "0.46523240208625793 udg,\n",
      "0.34976333379745483 lra,\n",
      "0.37750089168548584 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.6662431716918946\n",
      "\n",
      "Total loss: 0.005961958318948746; that's 0.0037527084350585938 task and 0.0011941068805754185 recon and 5.075715065002441 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005982274110428989\n",
      "\n",
      "Total loss: 6.285661697387695:\n",
      "4.693162441253662 control,\n",
      "0.43557223677635193 lrg,\n",
      "0.4539962112903595 udg,\n",
      "0.352383017539978 lra,\n",
      "0.3505476117134094 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.827249128818512\n",
      "\n",
      "Total loss: 5.459216594696045:\n",
      "3.9659695625305176 control,\n",
      "0.37074458599090576 lrg,\n",
      "0.44395262002944946 udg,\n",
      "0.33852487802505493 lra,\n",
      "0.34002482891082764 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.86008189201355\n",
      "\n",
      "Total loss: 0.006697401404380798; that's 0.00469677010551095 task and 0.0011588610941544175 recon and 4.208852767944336 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006571737774647772\n",
      "\n",
      "Total loss: 0.0061312452889978886; that's 0.004280158318579197 task and 0.0010583901312202215 recon and 3.9634833335876465 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006206399425864219\n",
      "\n",
      "Total loss: 5.211603164672852:\n",
      "3.652371644973755 control,\n",
      "0.4465666115283966 lrg,\n",
      "0.4511061906814575 udg,\n",
      "0.3320169746875763 lra,\n",
      "0.32954147458076477 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.450802803039551\n",
      "\n",
      "Total loss: 4.494259834289551:\n",
      "2.9481453895568848 control,\n",
      "0.4568789303302765 lrg,\n",
      "0.4363757371902466 udg,\n",
      "0.3306514024734497 lra,\n",
      "0.3222081661224365 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.367514886856079\n",
      "\n",
      "Total loss: 0.006320337299257517; that's 0.004618978127837181 task and 0.0010683574946597219 recon and 3.165008544921875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006266098027117551\n",
      "\n",
      "Total loss: 4.325491905212402:\n",
      "2.7309937477111816 control,\n",
      "0.42510801553726196 lrg,\n",
      "0.4614325165748596 udg,\n",
      "0.36171093583106995 lra,\n",
      "0.3462468385696411 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.092941286563874\n",
      "\n",
      "Total loss: 0.006281563546508551; that's 0.004641523119062185 task and 0.0010412600822746754 recon and 2.993901014328003 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.006261668968945742\n",
      "\n",
      "Total loss: 4.346260070800781:\n",
      "2.842315912246704 control,\n",
      "0.40896302461624146 lrg,\n",
      "0.42279550433158875 udg,\n",
      "0.333336740732193 lra,\n",
      "0.3388490676879883 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.643905041217804\n",
      "\n",
      "Total loss: 0.006019738037139177; that's 0.0043257419019937515 task and 0.0010522771626710892 recon and 3.2085952758789062 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0060052573494613175\n",
      "\n",
      "Total loss: 0.005495075602084398; that's 0.004061315208673477 task and 0.0011271473485976458 recon and 1.533065676689148 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005826301309280097\n",
      "\n",
      "Total loss: 2.7380075454711914:\n",
      "1.183495044708252 control,\n",
      "0.44958338141441345 lrg,\n",
      "0.4360343813896179 udg,\n",
      "0.3564337193965912 lra,\n",
      "0.31246107816696167 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.529578831195831\n",
      "\n",
      "Total loss: 0.005183096509426832; that's 0.0036505949683487415 task and 0.0011026577558368444 recon and 2.149219274520874 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005786130116321147\n",
      "\n",
      "Total loss: 3.4203944206237793:\n",
      "1.8307591676712036 control,\n",
      "0.3957099914550781 lrg,\n",
      "0.4771896302700043 udg,\n",
      "0.35301852226257324 lra,\n",
      "0.36371728777885437 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.4237499618530274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_batches = 10000*100#6250*32\n",
    "\n",
    "for b in range(total_batches):\n",
    "    triplet, ind = rb.random_draw()\n",
    "    func, opt, batch_size = triplet\n",
    "    \n",
    "    batch_num = batches[ind]\n",
    "    batches[ind] += 1\n",
    "\n",
    "    #reset_model = True #default option; only transfer memory within the task files\n",
    "    reset_model = (b % 3 == 2)\n",
    "\n",
    "    printing = ((batch_num % 100) == 99)\n",
    "    full_results = func(batch_size, brain, optimizer=opt, batch_num=batch_num, compute_grad=True, random_order=True, model_eval=False, reset_model=reset_model, printing=printing, training=True)\n",
    "    L = full_results[0] # no need to look into the detailed loss report\n",
    "    total_losses[ind] += L\n",
    "\n",
    "    if printing: # if this is a significant batch\n",
    "        avg_loss = total_losses[ind] / 100\n",
    "        total_losses[ind] = 0\n",
    "        print(f\"Average total loss for task {ind}, last 100 batches: {avg_loss}\\n\")\n",
    "        \n",
    "        if avg_loss < curr_mins[ind]:\n",
    "            curr_mins[ind] = avg_loss\n",
    "            torch.save(brain.state_dict(), f\"brain_checkpoints/enhanced_brain_first_training_v2_batch{b + 1}.pth\")\n",
    "            \n",
    "    if b < 10:\n",
    "        print(f\"batch {b}, task {ind}, task batch_num {batch_num}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a9094-8dec-4a9c-92c2-4f7342e7345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: not even close on the results. Need several days (basically seems to be relearning task1; taskQA basically\n",
    "# completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0519dcb-f815-45e6-a46f-621620263fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerunning on top of the last results, with many more batches (so several days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb7c96-0ce6-4e96-99a6-0a2cddfd5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates: add sampling weights; add batch_num to print statement; split these two optimizers and optimize them separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa482e-91be-4bae-ac3c-f75ae99e23c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
