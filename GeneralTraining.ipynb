{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f5bd94-74fb-4588-b47b-273035eb2345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6823f8c1-608a-4865-aeca-1458b0610761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4335c011-7512-4fde-bf66-16bdb5591fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f015e48acc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4245931c-72c7-470f-9e6e-2f6de6e1c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_display(torch_img):\n",
    "    clean = torch_img.detach().cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c25d90-1bdd-46b4-ae86-a6e8170070d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain = EnhancedAgentBrain()\n",
    "brain.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "\n",
    "brain.load_state_dict(torch.load('brain_checkpoints/enhanced_brain_first_training_batch10000.pth', weights_only=True, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6a4389-e113-4dc7-bf96-7538570644e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optimizer = optim.Adam(brain.parameters(), lr=0.00001, eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c522ad35-e749-4b70-a282-f4489bd4069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should possibly also include mem_enc? Should just be gen_optimizer? \n",
    "text_optimizer = optim.Adam(list(brain.text_enc.parameters()) + list(brain.text_dec.parameters()), lr=0.00001, eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dedeb05-aeef-4cc0-8c32-41e4c74f92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful to randomize the order in which the tasks are trained\n",
    "class ReusableBuffer:\n",
    "    def __init__(self, L):\n",
    "        self.L = L\n",
    "        self.inds = list(range(len(L)))\n",
    "\n",
    "    def draw(self, ind):\n",
    "        return self.L[ind]\n",
    "\n",
    "    def random_draw(self):\n",
    "        ind_ind = random.randint(0, len(self.inds)-1)\n",
    "        ind = self.inds[ind_ind]\n",
    "        if ind_ind == (len(self.inds) - 1):\n",
    "            self.inds = self.inds[:-1]\n",
    "        else:\n",
    "            self.inds = self.inds[:ind_ind] + self.inds[ind_ind + 1:]\n",
    "        if len(self.inds) == 0:\n",
    "            self.inds = list(range(len(self.L)))\n",
    "        return self.L[ind], ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8113bf0-e27a-4964-b993-1511284e05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for first task (and really anywhere I want to not reset between tasks)\n",
    "# make sure the batch size matches\n",
    "rb = ReusableBuffer([(arrow_task_batch, gen_optimizer, 16), \\\n",
    "                     (qa_task_batch, text_optimizer, 16)]) # add further functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d0bf3cd-1207-4726-8983-3708c97ba125",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fcade85-fe40-4a68-b137-4c94c737614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_mins = [1000.0, 1000.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea6fc04a-8056-41bd-85c0-7e60970a13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_losses = [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88167a4b-dd8d-43e6-b4ae-8f77c51adaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d1940-ba13-4da2-bb5f-b1af6d45d7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atbolsh/anaconda3/envs/player/lib/python3.12/site-packages/torch/_tensor.py:955: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, task 1, task batch_num 0\n",
      "\n",
      "batch 1, task 0, task batch_num 0\n",
      "\n",
      "batch 2, task 0, task batch_num 1\n",
      "\n",
      "batch 3, task 1, task batch_num 1\n",
      "\n",
      "batch 4, task 1, task batch_num 2\n",
      "\n",
      "batch 5, task 0, task batch_num 2\n",
      "\n",
      "batch 6, task 1, task batch_num 3\n",
      "\n",
      "batch 7, task 0, task batch_num 3\n",
      "\n",
      "batch 8, task 1, task batch_num 4\n",
      "\n",
      "batch 9, task 0, task batch_num 4\n",
      "\n",
      "Total loss: 22.553747177124023:\n",
      "5.90061616897583 control,\n",
      "4.118896007537842 lrg,\n",
      "4.552083492279053 udg,\n",
      "3.9597909450531006 lra,\n",
      "4.022360324859619 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 30.17000051498413\n",
      "\n",
      "Total loss: 0.49829792976379395; that's 0.24864144623279572 task and 0.24760109186172485 recon and 10.277008056640625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.8703511562943459\n",
      "\n",
      "Total loss: 12.683548927307129:\n",
      "5.499452590942383 control,\n",
      "1.8017323017120361 lrg,\n",
      "2.1801743507385254 udg,\n",
      "1.4238511323928833 lra,\n",
      "1.7783384323120117 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 17.281756172180177\n",
      "\n",
      "Total loss: 0.4866833984851837; that's 0.2335004210472107 task and 0.25154611468315125 recon and 8.184311866760254 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.4909328338503838\n",
      "\n",
      "Total loss: 0.5050315260887146; that's 0.25817567110061646 task and 0.2452324479818344 recon and 8.116829872131348 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.45928038090467455\n",
      "\n",
      "Total loss: 10.138731956481934:\n",
      "6.377170085906982 control,\n",
      "0.8965486288070679 lrg,\n",
      "1.2501091957092285 udg,\n",
      "0.7482510805130005 lra,\n",
      "0.8666523694992065 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 11.34691481590271\n",
      "\n",
      "Total loss: 8.259605407714844:\n",
      "5.567933559417725 control,\n",
      "0.6878618597984314 lrg,\n",
      "0.9119501113891602 udg,\n",
      "0.5588011741638184 lra,\n",
      "0.5330588817596436 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 8.996881170272827\n",
      "\n",
      "Total loss: 0.4508500397205353; that's 0.22579239308834076 task and 0.22372306883335114 recon and 6.672938823699951 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.4630358603596687\n",
      "\n",
      "Total loss: 0.4482705891132355; that's 0.2247714251279831 task and 0.222275972366333 recon and 6.115939617156982 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.4573390254378319\n",
      "\n",
      "Total loss: 7.703762054443359:\n",
      "5.3517889976501465 control,\n",
      "0.6420815587043762 lrg,\n",
      "0.7585561871528625 udg,\n",
      "0.45886966586112976 lra,\n",
      "0.4924653172492981 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 8.196894960403442\n",
      "\n",
      "Total loss: 7.238184928894043:\n",
      "5.184377670288086 control,\n",
      "0.5429797768592834 lrg,\n",
      "0.6263812780380249 udg,\n",
      "0.4494229555130005 lra,\n",
      "0.43502330780029297 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.797910327911377\n",
      "\n",
      "Total loss: 0.14056381583213806; that's 0.07240144908428192 task and 0.06698562204837799 recon and 5.883692741394043 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.2966720761358738\n",
      "\n",
      "Total loss: 0.12789446115493774; that's 0.05556480959057808 task and 0.07094857841730118 recon and 6.90538215637207 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.12878637336194515\n",
      "\n",
      "Total loss: 8.260026931762695:\n",
      "6.334689617156982 control,\n",
      "0.5156065225601196 lrg,\n",
      "0.5645286440849304 udg,\n",
      "0.40730810165405273 lra,\n",
      "0.43789416551589966 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.573080921173096\n",
      "\n",
      "Total loss: 0.10727670043706894; that's 0.05472128465771675 task and 0.051231782883405685 recon and 6.618162155151367 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.11430917367339134\n",
      "\n",
      "Total loss: 7.947452068328857:\n",
      "6.059776782989502 control,\n",
      "0.5091887712478638 lrg,\n",
      "0.5480396747589111 udg,\n",
      "0.3993813991546631 lra,\n",
      "0.43106505274772644 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.61575553894043\n",
      "\n",
      "Total loss: 7.986446380615234:\n",
      "6.184212684631348 control,\n",
      "0.4784988760948181 lrg,\n",
      "0.5146611928939819 udg,\n",
      "0.40563100576400757 lra,\n",
      "0.40344223380088806 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.62965265750885\n",
      "\n",
      "Total loss: 0.10455796867609024; that's 0.05311354622244835 task and 0.05011395364999771 recon and 6.652359962463379 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.10851532571017743\n",
      "\n",
      "Total loss: 0.10899094492197037; that's 0.05262337252497673 task and 0.05526306480169296 recon and 5.522573947906494 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.10570700779557228\n",
      "\n",
      "Total loss: 6.844134330749512:\n",
      "5.139870643615723 control,\n",
      "0.4816208779811859 lrg,\n",
      "0.49552997946739197 udg,\n",
      "0.3638569116592407 lra,\n",
      "0.36325615644454956 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.104808082580567\n",
      "\n",
      "Total loss: 7.111235618591309:\n",
      "5.305211544036865 control,\n",
      "0.5101438164710999 lrg,\n",
      "0.5302289724349976 udg,\n",
      "0.3932132422924042 lra,\n",
      "0.3724377155303955 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.559808106422424\n",
      "\n",
      "Total loss: 0.1067299172282219; that's 0.05641883239150047 task and 0.04916175454854965 recon and 5.7466607093811035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.10451312892138959\n",
      "\n",
      "Total loss: 0.10200505703687668; that's 0.051902614533901215 task and 0.048872895538806915 recon and 6.14775276184082 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.10330689691007137\n",
      "\n",
      "Total loss: 7.459380626678467:\n",
      "5.696165561676025 control,\n",
      "0.4541223347187042 lrg,\n",
      "0.5616806149482727 udg,\n",
      "0.3707629144191742 lra,\n",
      "0.3766487240791321 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.582545948028565\n",
      "\n",
      "Total loss: 6.877572059631348:\n",
      "5.138911247253418 control,\n",
      "0.48627349734306335 lrg,\n",
      "0.5193048715591431 udg,\n",
      "0.3586856722831726 lra,\n",
      "0.37439748644828796 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.290009422302246\n",
      "\n",
      "Total loss: 0.10128821432590485; that's 0.052153829485177994 task and 0.0480225495994091 recon and 5.559161186218262 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.10226003259420395\n",
      "\n",
      "Total loss: 0.09875310212373734; that's 0.05054677650332451 task and 0.04719483107328415 recon and 5.057478904724121 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.1011459244787693\n",
      "\n",
      "Total loss: 6.205635070800781:\n",
      "4.43958854675293 control,\n",
      "0.4942784309387207 lrg,\n",
      "0.5211514830589294 udg,\n",
      "0.3666853904724121 lra,\n",
      "0.3839311897754669 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.046588563919068\n",
      "\n",
      "Total loss: 0.09916278719902039; that's 0.05082074552774429 task and 0.04726122319698334 recon and 5.404087543487549 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09985888689756393\n",
      "\n",
      "Total loss: 6.596215724945068:\n",
      "4.916755676269531 control,\n",
      "0.44850319623947144 lrg,\n",
      "0.48485660552978516 udg,\n",
      "0.3734447956085205 lra,\n",
      "0.3726555407047272 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.078212080001831\n",
      "\n",
      "Total loss: 7.111203193664551:\n",
      "5.353342533111572 control,\n",
      "0.4837398827075958 lrg,\n",
      "0.4815850555896759 udg,\n",
      "0.39650657773017883 lra,\n",
      "0.39602890610694885 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.939341831207275\n",
      "\n",
      "Total loss: 0.09704063087701797; that's 0.049305301159620285 task and 0.046583205461502075 recon and 5.760592460632324 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09846400707960129\n",
      "\n",
      "Total loss: 0.09572867304086685; that's 0.0490487739443779 task and 0.04557628184556961 recon and 5.518070697784424 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09703094750642777\n",
      "\n",
      "Total loss: 6.808216094970703:\n",
      "5.095158100128174 control,\n",
      "0.47156286239624023 lrg,\n",
      "0.5035003423690796 udg,\n",
      "0.37453269958496094 lra,\n",
      "0.3634618818759918 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.672108812332153\n",
      "\n",
      "Total loss: 0.09444553405046463; that's 0.04820885881781578 task and 0.045161500573158264 recon and 5.375839710235596 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09570456385612487\n",
      "\n",
      "Total loss: 6.712753772735596:\n",
      "5.0000200271606445 control,\n",
      "0.45942574739456177 lrg,\n",
      "0.5292031168937683 udg,\n",
      "0.3585106134414673 lra,\n",
      "0.3655945956707001 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.931922430992127\n",
      "\n",
      "Total loss: 0.09524263441562653; that's 0.04751106724143028 task and 0.04666387289762497 recon and 5.338478088378906 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09449861317873001\n",
      "\n",
      "Total loss: 6.4488091468811035:\n",
      "4.876107692718506 control,\n",
      "0.4259452223777771 lrg,\n",
      "0.4648319184780121 udg,\n",
      "0.3389720618724823 lra,\n",
      "0.3429524302482605 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.90749258518219\n",
      "\n",
      "Total loss: 7.260396480560303:\n",
      "5.514941692352295 control,\n",
      "0.49512356519699097 lrg,\n",
      "0.5419334769248962 udg,\n",
      "0.37261274456977844 lra,\n",
      "0.33578479290008545 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.760802631378174\n",
      "\n",
      "Total loss: 0.09223616868257523; that's 0.04808464273810387 task and 0.04299401864409447 recon and 5.787520408630371 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09295399330556392\n",
      "\n",
      "Total loss: 0.09009139239788055; that's 0.046218980103731155 task and 0.042866017669439316 recon and 5.031982898712158 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.09086988471448422\n",
      "\n",
      "Total loss: 6.3641886711120605:\n",
      "4.701626777648926 control,\n",
      "0.46620866656303406 lrg,\n",
      "0.48636680841445923 udg,\n",
      "0.36441338062286377 lra,\n",
      "0.3455735445022583 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.804553151130676\n",
      "\n",
      "Total loss: 6.425493240356445:\n",
      "4.7165913581848145 control,\n",
      "0.4255281090736389 lrg,\n",
      "0.5279452800750732 udg,\n",
      "0.3933936655521393 lra,\n",
      "0.3620348572731018 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.965853018760681\n",
      "\n",
      "Total loss: 0.08803786337375641; that's 0.04477064684033394 task and 0.04225262999534607 recon and 5.072945594787598 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.08884520284831524\n",
      "\n",
      "Total loss: 0.08544982969760895; that's 0.04393240064382553 task and 0.04021171107888222 recon and 6.528567790985107 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.08667100191116334\n",
      "\n",
      "Total loss: 7.78481388092041:\n",
      "6.16501522064209 control,\n",
      "0.42689117789268494 lrg,\n",
      "0.46227335929870605 udg,\n",
      "0.36446139216423035 lra,\n",
      "0.36617234349250793 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.329177350997925\n",
      "\n",
      "Total loss: 0.08031895756721497; that's 0.04129956662654877 task and 0.038163814693689346 recon and 4.27790641784668 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0829025387018919\n",
      "\n",
      "Total loss: 5.587920188903809:\n",
      "3.939450979232788 control,\n",
      "0.41275957226753235 lrg,\n",
      "0.4548611640930176 udg,\n",
      "0.34644603729248047 lra,\n",
      "0.43440255522727966 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.852564134597778\n",
      "\n",
      "Total loss: 5.827221393585205:\n",
      "4.147067546844482 control,\n",
      "0.4770071804523468 lrg,\n",
      "0.48907509446144104 udg,\n",
      "0.3635139763355255 lra,\n",
      "0.3505573272705078 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.270781779289246\n",
      "\n",
      "Total loss: 0.07604721188545227; that's 0.039095886051654816 task and 0.036068402230739594 recon and 4.414602756500244 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0789516232907772\n",
      "\n",
      "Total loss: 6.651906967163086:\n",
      "4.917477130889893 control,\n",
      "0.452153742313385 lrg,\n",
      "0.5201489329338074 udg,\n",
      "0.3849092125892639 lra,\n",
      "0.37721800804138184 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.575291128158569\n",
      "\n",
      "Total loss: 0.07362200319766998; that's 0.03898032382130623 task and 0.03359973430633545 recon and 5.209747314453125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.07436780847609042\n",
      "\n",
      "Total loss: 6.802957534790039:\n",
      "5.13054084777832 control,\n",
      "0.42131635546684265 lrg,\n",
      "0.4776765704154968 udg,\n",
      "0.3781578540802002 lra,\n",
      "0.39526674151420593 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.535423903465271\n",
      "\n",
      "Total loss: 0.06563199311494827; that's 0.0336175374686718 task and 0.03092959150671959 recon and 5.424316883087158 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.06912756808102132\n",
      "\n",
      "Total loss: 7.698009490966797:\n",
      "6.057917594909668 control,\n",
      "0.45232832431793213 lrg,\n",
      "0.46828940510749817 udg,\n",
      "0.37365415692329407 lra,\n",
      "0.3458201587200165 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.60124370098114\n",
      "\n",
      "Total loss: 0.06110979616641998; that's 0.031580060720443726 task and 0.02824024297297001 recon and 6.4474687576293945 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0639059654995799\n",
      "\n",
      "Total loss: 6.474217891693115:\n",
      "4.75274658203125 control,\n",
      "0.4500091075897217 lrg,\n",
      "0.5629670023918152 udg,\n",
      "0.34700509905815125 lra,\n",
      "0.3614901900291443 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.027767028808594\n",
      "\n",
      "Total loss: 0.0563834123313427; that's 0.0299422238022089 task and 0.02542765624821186 recon and 5.067654132843018 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.058511741533875464\n",
      "\n",
      "Total loss: 0.050044044852256775; that's 0.025676026940345764 task and 0.023316914215683937 recon and 5.255526542663574 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.05362459346652031\n",
      "\n",
      "Total loss: 6.560187816619873:\n",
      "4.910270690917969 control,\n",
      "0.4461429715156555 lrg,\n",
      "0.49664708971977234 udg,\n",
      "0.3564354181289673 lra,\n",
      "0.3506920039653778 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.8866122484207155\n",
      "\n",
      "Total loss: 6.127711296081543:\n",
      "4.532339572906494 control,\n",
      "0.430046945810318 lrg,\n",
      "0.46937260031700134 udg,\n",
      "0.3469538986682892 lra,\n",
      "0.34899789094924927 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.808589148521423\n",
      "\n",
      "Total loss: 0.04648758843541145; that's 0.024393519386649132 task and 0.021128777414560318 recon and 4.8264689445495605 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.04884733136743307\n",
      "\n",
      "Total loss: 6.06424617767334:\n",
      "4.385249137878418 control,\n",
      "0.44038721919059753 lrg,\n",
      "0.48437055945396423 udg,\n",
      "0.36261141300201416 lra,\n",
      "0.3916279077529907 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.3652088069915775\n",
      "\n",
      "Total loss: 0.04512016475200653; that's 0.024965284392237663 task and 0.019190629944205284 recon and 4.821249961853027 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.04522345624864101\n",
      "\n",
      "Total loss: 0.038943205028772354; that's 0.020244572311639786 task and 0.01772463694214821 recon and 4.869973182678223 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.04133363325148821\n",
      "\n",
      "Total loss: 6.196595668792725:\n",
      "4.476412296295166 control,\n",
      "0.49987226724624634 lrg,\n",
      "0.4922613203525543 udg,\n",
      "0.370475709438324 lra,\n",
      "0.35757383704185486 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.891004014015198\n",
      "\n",
      "Total loss: 0.0384819470345974; that's 0.02088572084903717 task and 0.016507495194673538 recon and 5.4436540603637695 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.038889867700636384\n",
      "\n",
      "Total loss: 6.736996650695801:\n",
      "5.127436637878418 control,\n",
      "0.4220651686191559 lrg,\n",
      "0.4450581967830658 udg,\n",
      "0.3792000710964203 lra,\n",
      "0.36323633790016174 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.859900331497192\n",
      "\n",
      "Total loss: 0.03442652150988579; that's 0.018245959654450417 task and 0.015170351602137089 recon and 5.051053524017334 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.03650578293949366\n",
      "\n",
      "Total loss: 6.249738693237305:\n",
      "4.63918924331665 control,\n",
      "0.41744011640548706 lrg,\n",
      "0.4895709753036499 udg,\n",
      "0.3290122151374817 lra,\n",
      "0.37452617287635803 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.011431818008423\n",
      "\n",
      "Total loss: 0.03269222751259804; that's 0.017280444502830505 task and 0.014150709845125675 recon and 6.305372714996338 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.03387875191867352\n",
      "\n",
      "Total loss: 7.644423007965088:\n",
      "5.966886520385742 control,\n",
      "0.46559029817581177 lrg,\n",
      "0.4988546371459961 udg,\n",
      "0.37568792700767517 lra,\n",
      "0.33740341663360596 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.908941354751587\n",
      "\n",
      "Total loss: 0.03468366339802742; that's 0.01889283023774624 task and 0.014820750802755356 recon and 4.850423812866211 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.03276608387008309\n",
      "\n",
      "Total loss: 6.219552993774414:\n",
      "4.496963024139404 control,\n",
      "0.42474061250686646 lrg,\n",
      "0.5443011522293091 udg,\n",
      "0.3690635859966278 lra,\n",
      "0.38448482751846313 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.837392091751099\n",
      "\n",
      "Total loss: 0.02922949194908142; that's 0.015372561290860176 task and 0.01282433606684208 recon and 5.162973880767822 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.03215382538735866\n",
      "\n",
      "Total loss: 6.452742099761963:\n",
      "4.759613990783691 control,\n",
      "0.47414928674697876 lrg,\n",
      "0.48591744899749756 udg,\n",
      "0.3674919605255127 lra,\n",
      "0.3655693829059601 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.199408173561096\n",
      "\n",
      "Total loss: 5.715834140777588:\n",
      "4.105673789978027 control,\n",
      "0.438618928194046 lrg,\n",
      "0.48431116342544556 udg,\n",
      "0.3589034378528595 lra,\n",
      "0.3283264935016632 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.75316620349884\n",
      "\n",
      "Total loss: 0.026804883033037186; that's 0.014452232047915459 task and 0.01148674264550209 recon and 4.329542636871338 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.029208789877593518\n",
      "\n",
      "Total loss: 6.050023078918457:\n",
      "4.416409492492676 control,\n",
      "0.44507497549057007 lrg,\n",
      "0.4855511784553528 udg,\n",
      "0.331539124250412 lra,\n",
      "0.37144795060157776 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.4749526691436765\n",
      "\n",
      "Total loss: 0.025980260223150253; that's 0.013550428673624992 task and 0.011483896523714066 recon and 4.729676246643066 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.02751423029229045\n",
      "\n",
      "Total loss: 5.875304222106934:\n",
      "4.234046936035156 control,\n",
      "0.4165800213813782 lrg,\n",
      "0.5003262758255005 udg,\n",
      "0.354327529668808 lra,\n",
      "0.37002313137054443 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.238547258377075\n",
      "\n",
      "Total loss: 0.026347395032644272; that's 0.014379046857357025 task and 0.011051657609641552 recon and 4.5834527015686035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.026319114193320274\n",
      "\n",
      "Total loss: 5.3842573165893555:\n",
      "3.7971014976501465 control,\n",
      "0.4036791920661926 lrg,\n",
      "0.4828704595565796 udg,\n",
      "0.3545459806919098 lra,\n",
      "0.34605976939201355 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.079243383407593\n",
      "\n",
      "Total loss: 0.02404206246137619; that's 0.013044068589806557 task and 0.010195670649409294 recon and 4.011612892150879 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.02539775464683771\n",
      "\n",
      "Total loss: 0.028678109869360924; that's 0.015921106562018394 task and 0.011848238296806812 recon and 4.543819427490234 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.024838567413389682\n",
      "\n",
      "Total loss: 5.8854289054870605:\n",
      "4.219790458679199 control,\n",
      "0.4282551109790802 lrg,\n",
      "0.5099121928215027 udg,\n",
      "0.3429698348045349 lra,\n",
      "0.3845016658306122 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.139909543991089\n",
      "\n",
      "Total loss: 0.02250455878674984; that's 0.012309035286307335 task and 0.009253712370991707 recon and 4.7090582847595215 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.025103680323809385\n",
      "\n",
      "Total loss: 6.014991760253906:\n",
      "4.357061386108398 control,\n",
      "0.4776883125305176 lrg,\n",
      "0.4580276906490326 udg,\n",
      "0.37062081694602966 lra,\n",
      "0.35159361362457275 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.9434147596359255\n",
      "\n",
      "Total loss: 5.644326686859131:\n",
      "4.041412830352783 control,\n",
      "0.44947531819343567 lrg,\n",
      "0.45657265186309814 udg,\n",
      "0.37162160873413086 lra,\n",
      "0.325244277715683 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.686218056678772\n",
      "\n",
      "Total loss: 0.021417036652565002; that's 0.011712796986103058 task and 0.008842658251523972 recon and 4.307906627655029 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.02240136291831732\n",
      "\n",
      "Total loss: 5.907614707946777:\n",
      "4.267621040344238 control,\n",
      "0.45644402503967285 lrg,\n",
      "0.48104628920555115 udg,\n",
      "0.35306188464164734 lra,\n",
      "0.3494420647621155 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.75020504951477\n",
      "\n",
      "Total loss: 0.02241208776831627; that's 0.012322399765253067 task and 0.009175309911370277 recon and 4.57189416885376 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.02179698260501027\n",
      "\n",
      "Total loss: 6.3439435958862305:\n",
      "4.7137041091918945 control,\n",
      "0.4407041370868683 lrg,\n",
      "0.46078088879585266 udg,\n",
      "0.34749636054039 lra,\n",
      "0.38125768303871155 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.740206089019775\n",
      "\n",
      "Total loss: 0.021145140752196312; that's 0.011957722716033459 task and 0.008178898133337498 recon and 5.042603492736816 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.021199517343193294\n",
      "\n",
      "Total loss: 0.020043285563588142; that's 0.011381616815924644 task and 0.00789905060082674 recon and 3.813081979751587 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.02050580842420459\n",
      "\n",
      "Total loss: 5.073249340057373:\n",
      "3.4453728199005127 control,\n",
      "0.4434524178504944 lrg,\n",
      "0.46435320377349854 udg,\n",
      "0.37084636092185974 lra,\n",
      "0.34922441840171814 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.494744310379028\n",
      "\n",
      "Total loss: 0.02044825628399849; that's 0.010809596627950668 task and 0.008741173893213272 recon and 4.4874267578125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.020073933470994235\n",
      "\n",
      "Total loss: 5.843379497528076:\n",
      "4.101599216461182 control,\n",
      "0.48089462518692017 lrg,\n",
      "0.473962664604187 udg,\n",
      "0.382403165102005 lra,\n",
      "0.40451955795288086 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.869794907569886\n",
      "\n",
      "Total loss: 0.018476732075214386; that's 0.010094266384840012 task and 0.0072595952078700066 recon and 5.614346504211426 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.019506689570844175\n",
      "\n",
      "Total loss: 6.891243934631348:\n",
      "5.337105751037598 control,\n",
      "0.4246673882007599 lrg,\n",
      "0.4524780511856079 udg,\n",
      "0.33204153180122375 lra,\n",
      "0.34495100378990173 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.462767081260681\n",
      "\n",
      "Total loss: 6.516232967376709:\n",
      "4.954948902130127 control,\n",
      "0.38794317841529846 lrg,\n",
      "0.4867371618747711 udg,\n",
      "0.3414369225502014 lra,\n",
      "0.3451668620109558 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.661393818855285\n",
      "\n",
      "Total loss: 0.019093530252575874; that's 0.010641387663781643 task and 0.007400814443826675 recon and 5.2566375732421875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.019272414557635783\n",
      "\n",
      "Total loss: 6.626950740814209:\n",
      "5.029616355895996 control,\n",
      "0.42862847447395325 lrg,\n",
      "0.46817389130592346 udg,\n",
      "0.3402823507785797 lra,\n",
      "0.36024972796440125 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.697073454856873\n",
      "\n",
      "Total loss: 0.01804395206272602; that's 0.010011067613959312 task and 0.006968424189835787 recon and 5.322305202484131 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01892356775701046\n",
      "\n",
      "Total loss: 6.521953582763672:\n",
      "4.805526256561279 control,\n",
      "0.5101808905601501 lrg,\n",
      "0.46700242161750793 udg,\n",
      "0.3674332797527313 lra,\n",
      "0.3718108534812927 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.693500370979309\n",
      "\n",
      "Total loss: 0.019341550767421722; that's 0.010132691822946072 task and 0.008187846280634403 recon and 5.105066299438477 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.018497206158936023\n",
      "\n",
      "Total loss: 8.063295364379883:\n",
      "6.472601890563965 control,\n",
      "0.40083885192871094 lrg,\n",
      "0.5146088004112244 udg,\n",
      "0.30711814761161804 lra,\n",
      "0.36812812089920044 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.844834914207459\n",
      "\n",
      "Total loss: 0.017548006027936935; that's 0.00969349592924118 task and 0.006501856260001659 recon and 6.763261318206787 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.018476684968918564\n",
      "\n",
      "Total loss: 7.109743595123291:\n",
      "5.456962585449219 control,\n",
      "0.46110308170318604 lrg,\n",
      "0.4920857548713684 udg,\n",
      "0.34556734561920166 lra,\n",
      "0.3540249764919281 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.610577058792114\n",
      "\n",
      "Total loss: 0.01607268676161766; that's 0.008401235565543175 task and 0.00651650270447135 recon and 5.774744033813477 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.018014576956629752\n",
      "\n",
      "Total loss: 6.966802597045898:\n",
      "5.459688186645508 control,\n",
      "0.3837305009365082 lrg,\n",
      "0.45208680629730225 udg,\n",
      "0.32650917768478394 lra,\n",
      "0.34478822350502014 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.6547426414489745\n",
      "\n",
      "Total loss: 0.01837727427482605; that's 0.010807277634739876 task and 0.006434332113713026 recon and 5.678319931030273 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01776315610855818\n",
      "\n",
      "Total loss: 7.094893455505371:\n",
      "5.444926738739014 control,\n",
      "0.4307169020175934 lrg,\n",
      "0.5010458827018738 udg,\n",
      "0.3528625965118408 lra,\n",
      "0.36534106731414795 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.72474769115448\n",
      "\n",
      "Total loss: 0.01714750938117504; that's 0.009490077383816242 task and 0.006517264060676098 recon and 5.700836181640625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.017689555529505015\n",
      "\n",
      "Total loss: 6.923957347869873:\n",
      "5.393228054046631 control,\n",
      "0.40867117047309875 lrg,\n",
      "0.4194800853729248 udg,\n",
      "0.3358233869075775 lra,\n",
      "0.366754412651062 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.695981101989746\n",
      "\n",
      "Total loss: 0.01749693974852562; that's 0.010384844616055489 task and 0.005973178427666426 recon and 5.694584369659424 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.017283489694818854\n",
      "\n",
      "Total loss: 0.016802562400698662; that's 0.009014018811285496 task and 0.006525898817926645 recon and 6.313225269317627 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01701830042526126\n",
      "\n",
      "Total loss: 7.566057205200195:\n",
      "5.9356184005737305 control,\n",
      "0.4191785454750061 lrg,\n",
      "0.47376275062561035 udg,\n",
      "0.3519921600818634 lra,\n",
      "0.38550540804862976 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.695373964309693\n",
      "\n",
      "Total loss: 0.018144479021430016; that's 0.010003464296460152 task and 0.006953075528144836 recon and 5.939693450927734 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.017357900757342577\n",
      "\n",
      "Total loss: 7.257855415344238:\n",
      "5.640505313873291 control,\n",
      "0.4093409776687622 lrg,\n",
      "0.4871571362018585 udg,\n",
      "0.36441662907600403 lra,\n",
      "0.35643553733825684 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.8648107051849365\n",
      "\n",
      "Total loss: 0.016222894191741943; that's 0.009576075710356236 task and 0.005940062925219536 recon and 3.5337746143341064 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.017235193196684123\n",
      "\n",
      "Total loss: 4.724996089935303:\n",
      "3.163139581680298 control,\n",
      "0.4056461453437805 lrg,\n",
      "0.45505452156066895 udg,\n",
      "0.36642226576805115 lra,\n",
      "0.334733784198761 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.951584711074829\n",
      "\n",
      "Total loss: 5.541937828063965:\n",
      "3.9082367420196533 control,\n",
      "0.4060112237930298 lrg,\n",
      "0.4916623532772064 udg,\n",
      "0.34942781925201416 lra,\n",
      "0.3865995705127716 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.94240562915802\n",
      "\n",
      "Total loss: 0.01703280210494995; that's 0.009027224034070969 task and 0.007170862052589655 recon and 4.173583984375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01644579635001719\n",
      "\n",
      "Total loss: 0.01549314521253109; that's 0.008449207060039043 task and 0.006018193904310465 recon and 5.128720760345459 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016686296602711082\n",
      "\n",
      "Total loss: 6.3822832107543945:\n",
      "4.814033031463623 control,\n",
      "0.4065578579902649 lrg,\n",
      "0.4454330801963806 udg,\n",
      "0.3530019223690033 lra,\n",
      "0.3632569909095764 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.149649028778076\n",
      "\n",
      "Total loss: 6.149625778198242:\n",
      "4.439568042755127 control,\n",
      "0.47486868500709534 lrg,\n",
      "0.48313918709754944 udg,\n",
      "0.3753677010536194 lra,\n",
      "0.3766823410987854 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.97333333492279\n",
      "\n",
      "Total loss: 0.01578742079436779; that's 0.009003566578030586 task and 0.005833821836858988 recon and 4.7501630783081055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016477045789361\n",
      "\n",
      "Total loss: 5.437438011169434:\n",
      "3.8347482681274414 control,\n",
      "0.42358946800231934 lrg,\n",
      "0.44742244482040405 udg,\n",
      "0.3773369789123535 lra,\n",
      "0.3543405830860138 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.746241784095764\n",
      "\n",
      "Total loss: 0.019048627465963364; that's 0.01117656659334898 task and 0.007044239901006222 recon and 4.139101982116699 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016722502363845707\n",
      "\n",
      "Total loss: 5.377495765686035:\n",
      "3.754014730453491 control,\n",
      "0.4459270238876343 lrg,\n",
      "0.46178507804870605 udg,\n",
      "0.35943710803985596 lra,\n",
      "0.3563319742679596 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.720972952842712\n",
      "\n",
      "Total loss: 0.01603533886373043; that's 0.009415436536073685 task and 0.005820701830089092 recon and 3.996005058288574 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016006146781146525\n",
      "\n",
      "Total loss: 5.333067893981934:\n",
      "3.72965931892395 control,\n",
      "0.4609118402004242 lrg,\n",
      "0.447204053401947 udg,\n",
      "0.34093236923217773 lra,\n",
      "0.3543601334095001 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.741014790534973\n",
      "\n",
      "Total loss: 0.017096389085054398; that's 0.009679230861365795 task and 0.006608754396438599 recon and 4.042017459869385 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01688047987408936\n",
      "\n",
      "Total loss: 0.016245568171143532; that's 0.009135434404015541 task and 0.0062836045399308205 recon and 4.132650375366211 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01942861646413803\n",
      "\n",
      "Total loss: 5.485819339752197:\n",
      "3.8602428436279297 control,\n",
      "0.4442444443702698 lrg,\n",
      "0.45649829506874084 udg,\n",
      "0.37159115076065063 lra,\n",
      "0.3532427251338959 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.793305401802063\n",
      "\n",
      "Total loss: 0.014132129028439522; that's 0.008089644834399223 task and 0.005258046556264162 recon and 3.922192096710205 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016043111253529786\n",
      "\n",
      "Total loss: 5.2748847007751465:\n",
      "3.5570309162139893 control,\n",
      "0.4484751224517822 lrg,\n",
      "0.5134768486022949 udg,\n",
      "0.3583438992500305 lra,\n",
      "0.3975578546524048 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.500621700286866\n",
      "\n",
      "Total loss: 5.073206424713135:\n",
      "3.5097856521606445 control,\n",
      "0.38324156403541565 lrg,\n",
      "0.47823286056518555 udg,\n",
      "0.33298739790916443 lra,\n",
      "0.368958979845047 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.702600989341736\n",
      "\n",
      "Total loss: 0.015308808535337448; that's 0.008803279139101505 task and 0.005751296877861023 recon and 3.771162748336792 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015840130327269435\n",
      "\n",
      "Total loss: 0.015349438413977623; that's 0.008836043067276478 task and 0.005699646193534136 recon and 4.068745136260986 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015751943131908773\n",
      "\n",
      "Total loss: 5.384417533874512:\n",
      "3.7440860271453857 control,\n",
      "0.4287552535533905 lrg,\n",
      "0.4891173243522644 udg,\n",
      "0.36435410380363464 lra,\n",
      "0.35810497403144836 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.750196261405945\n",
      "\n",
      "Total loss: 5.750524044036865:\n",
      "4.164050102233887 control,\n",
      "0.4573722779750824 lrg,\n",
      "0.45585599541664124 udg,\n",
      "0.35031354427337646 lra,\n",
      "0.32293203473091125 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.718627371788025\n",
      "\n",
      "Total loss: 0.015885164961218834; that's 0.009167445823550224 task and 0.0058311764150857925 recon and 4.43271017074585 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016280009197071194\n",
      "\n",
      "Total loss: 0.01664045639336109; that's 0.009134795516729355 task and 0.006354283541440964 recon and 5.756889343261719 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015552843706682324\n",
      "\n",
      "Total loss: 6.95676326751709:\n",
      "5.419435024261475 control,\n",
      "0.4474301040172577 lrg,\n",
      "0.4220811724662781 udg,\n",
      "0.3417479991912842 lra,\n",
      "0.3260689079761505 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.8685321569442745\n",
      "\n",
      "Total loss: 0.01377763319760561; that's 0.007808406371623278 task and 0.00508979381993413 recon and 4.3971662521362305 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015575238987803459\n",
      "\n",
      "Total loss: 5.714729309082031:\n",
      "4.0435028076171875 control,\n",
      "0.4694315493106842 lrg,\n",
      "0.5161448121070862 udg,\n",
      "0.33560216426849365 lra,\n",
      "0.3500482738018036 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.978818373680115\n",
      "\n",
      "Total loss: 5.567049026489258:\n",
      "3.9329609870910645 control,\n",
      "0.4216517508029938 lrg,\n",
      "0.5115478038787842 udg,\n",
      "0.3648780286312103 lra,\n",
      "0.3360104560852051 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.842905173301697\n",
      "\n",
      "Total loss: 0.014750744216144085; that's 0.0084451949223876 task and 0.005459300708025694 recon and 4.231247425079346 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015268129957839847\n",
      "\n",
      "Total loss: 5.603994846343994:\n",
      "3.918574571609497 control,\n",
      "0.45859652757644653 lrg,\n",
      "0.5013235807418823 udg,\n",
      "0.3722919821739197 lra,\n",
      "0.35320812463760376 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.003272070884704\n",
      "\n",
      "Total loss: 0.015942972153425217; that's 0.009336485527455807 task and 0.005764523055404425 recon and 4.2098188400268555 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014919837899506093\n",
      "\n",
      "Total loss: 0.014594057574868202; that's 0.008209421299397945 task and 0.0055070375092327595 recon and 4.3879923820495605 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01485156487673521\n",
      "\n",
      "Total loss: 5.714846134185791:\n",
      "4.104495525360107 control,\n",
      "0.4236873686313629 lrg,\n",
      "0.4860773980617523 udg,\n",
      "0.3635537922382355 lra,\n",
      "0.3370317220687866 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.648143534660339\n",
      "\n",
      "Total loss: 5.266226768493652:\n",
      "3.761777639389038 control,\n",
      "0.3698768615722656 lrg,\n",
      "0.48189041018486023 udg,\n",
      "0.32086870074272156 lra,\n",
      "0.3318132162094116 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.605576992034912\n",
      "\n",
      "Total loss: 0.01451081968843937; that's 0.008289641700685024 task and 0.005401800852268934 recon and 4.096888542175293 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014903993578627706\n",
      "\n",
      "Total loss: 5.901041507720947:\n",
      "4.31516695022583 control,\n",
      "0.42052289843559265 lrg,\n",
      "0.44196709990501404 udg,\n",
      "0.3407759368419647 lra,\n",
      "0.3826090395450592 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.5226717710495\n",
      "\n",
      "Total loss: 0.01520602684468031; that's 0.008860128931701183 task and 0.005430291406810284 recon and 4.578034400939941 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014920189641416073\n",
      "\n",
      "Total loss: 0.014657323248684406; that's 0.008287984877824783 task and 0.0055410610511898994 recon and 4.141385555267334 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014808934107422829\n",
      "\n",
      "Total loss: 5.464764595031738:\n",
      "3.7917263507843018 control,\n",
      "0.40076354146003723 lrg,\n",
      "0.5074580907821655 udg,\n",
      "0.39372435212135315 lra,\n",
      "0.3710918128490448 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.574501218795777\n",
      "\n",
      "Total loss: 0.014308586716651917; that's 0.008271150290966034 task and 0.005319598130881786 recon and 3.589191198348999 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015011889934539795\n",
      "\n",
      "Total loss: 4.755914688110352:\n",
      "3.21728253364563 control,\n",
      "0.3996778130531311 lrg,\n",
      "0.43311721086502075 udg,\n",
      "0.3322501480579376 lra,\n",
      "0.37358716130256653 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.351203541755677\n",
      "\n",
      "Total loss: 7.040425777435303:\n",
      "5.440448760986328 control,\n",
      "0.4241087734699249 lrg,\n",
      "0.46301236748695374 udg,\n",
      "0.37504252791404724 lra,\n",
      "0.3378135859966278 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.261616291999817\n",
      "\n",
      "Total loss: 0.01489957608282566; that's 0.008878916501998901 task and 0.00488462345674634 recon and 5.680180549621582 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014854899533092976\n",
      "\n",
      "Total loss: 6.498401165008545:\n",
      "4.9511284828186035 control,\n",
      "0.39456185698509216 lrg,\n",
      "0.4465729296207428 udg,\n",
      "0.3786562383174896 lra,\n",
      "0.32748162746429443 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.3210190534591675\n",
      "\n",
      "Total loss: 0.01615433394908905; that's 0.009389777667820454 task and 0.0057056196965277195 recon and 5.294680118560791 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01498767975717783\n",
      "\n",
      "Total loss: 0.014842623844742775; that's 0.008683326654136181 task and 0.00528961606323719 recon and 4.34840726852417 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.015147615987807513\n",
      "\n",
      "Total loss: 5.719814300537109:\n",
      "4.09722900390625 control,\n",
      "0.4164953827857971 lrg,\n",
      "0.480286568403244 udg,\n",
      "0.38390207290649414 lra,\n",
      "0.3419010639190674 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.211148829460144\n",
      "\n",
      "Total loss: 0.01435444038361311; that's 0.008220597170293331 task and 0.005118146073073149 recon and 5.078486919403076 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014648855524137616\n",
      "\n",
      "Total loss: 6.334697723388672:\n",
      "4.748878002166748 control,\n",
      "0.463460236787796 lrg,\n",
      "0.44204971194267273 udg,\n",
      "0.3468025326728821 lra,\n",
      "0.33350715041160583 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.511056180000305\n",
      "\n",
      "Total loss: 0.014488942921161652; that's 0.00806527491658926 task and 0.005186876747757196 recon and 6.1839518547058105 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014638965604826809\n",
      "\n",
      "Total loss: 7.398153305053711:\n",
      "5.888937950134277 control,\n",
      "0.37197667360305786 lrg,\n",
      "0.4563296437263489 udg,\n",
      "0.3148133456707001 lra,\n",
      "0.36609548330307007 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.424095096588135\n",
      "\n",
      "Total loss: 0.013307404704391956; that's 0.007559244055300951 task and 0.004627252463251352 recon and 5.604540824890137 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01450663199648261\n",
      "\n",
      "Total loss: 6.935419082641602:\n",
      "5.370177745819092 control,\n",
      "0.4130857288837433 lrg,\n",
      "0.48615357279777527 udg,\n",
      "0.3175608515739441 lra,\n",
      "0.3484410345554352 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 7.419994168281555\n",
      "\n",
      "Total loss: 6.498438358306885:\n",
      "4.9254069328308105 control,\n",
      "0.3696920573711395 lrg,\n",
      "0.5197557210922241 udg,\n",
      "0.3377670645713806 lra,\n",
      "0.345816433429718 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.56605477809906\n",
      "\n",
      "Total loss: 0.013983006589114666; that's 0.00780339352786541 task and 0.005134883336722851 recon and 5.223648548126221 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014248665105551481\n",
      "\n",
      "Total loss: 0.01380283385515213; that's 0.00785716064274311 task and 0.004695040173828602 recon and 6.253166198730469 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014155306397005915\n",
      "\n",
      "Total loss: 7.602659225463867:\n",
      "5.9766740798950195 control,\n",
      "0.40526458621025085 lrg,\n",
      "0.5182824730873108 udg,\n",
      "0.3595123589038849 lra,\n",
      "0.34292587637901306 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.453684616088867\n",
      "\n",
      "Total loss: 6.331967830657959:\n",
      "4.792665958404541 control,\n",
      "0.4267370104789734 lrg,\n",
      "0.43368375301361084 udg,\n",
      "0.32718518376350403 lra,\n",
      "0.3516959846019745 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.7012632465362545\n",
      "\n",
      "Total loss: 0.014160671271383762; that's 0.008214821107685566 task and 0.004934970289468765 recon and 5.054400444030762 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014262261977419257\n",
      "\n",
      "Total loss: 6.393856048583984:\n",
      "4.763552665710449 control,\n",
      "0.4157601594924927 lrg,\n",
      "0.48568373918533325 udg,\n",
      "0.35258010029792786 lra,\n",
      "0.3762793242931366 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.50829598903656\n",
      "\n",
      "Total loss: 0.013990126550197601; that's 0.008105277083814144 task and 0.00487943971529603 recon and 5.0270466804504395 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014097233256325125\n",
      "\n",
      "Total loss: 6.361944675445557:\n",
      "4.82309627532959 control,\n",
      "0.42488592863082886 lrg,\n",
      "0.4417451322078705 udg,\n",
      "0.33102017641067505 lra,\n",
      "0.3411972224712372 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.201302251815796\n",
      "\n",
      "Total loss: 0.014602412469685078; that's 0.008958891034126282 task and 0.004622726701200008 recon and 5.10397481918335 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014129983251914382\n",
      "\n",
      "Total loss: 5.913753509521484:\n",
      "4.272854328155518 control,\n",
      "0.4690580666065216 lrg,\n",
      "0.466074138879776 udg,\n",
      "0.34563061594963074 lra,\n",
      "0.36013638973236084 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.18876660823822\n",
      "\n",
      "Total loss: 0.013391486369073391; that's 0.007553961593657732 task and 0.004925787914544344 recon and 4.558686256408691 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013585639037191868\n",
      "\n",
      "Total loss: 7.165862083435059:\n",
      "5.590793132781982 control,\n",
      "0.44110170006752014 lrg,\n",
      "0.4425757825374603 udg,\n",
      "0.35826897621154785 lra,\n",
      "0.3331224024295807 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.402835383415222\n",
      "\n",
      "Total loss: 0.013552067801356316; that's 0.007803730200976133 task and 0.004577431362122297 recon and 5.8545331954956055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013864954989403487\n",
      "\n",
      "Total loss: 0.012905276380479336; that's 0.007390456739813089 task and 0.004359142389148474 recon and 5.77838659286499 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013650501538068056\n",
      "\n",
      "Total loss: 7.104819297790527:\n",
      "5.523390769958496 control,\n",
      "0.4431554079055786 lrg,\n",
      "0.41161325573921204 udg,\n",
      "0.3636931777000427 lra,\n",
      "0.36296653747558594 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.468948998451233\n",
      "\n",
      "Total loss: 6.526828289031982:\n",
      "5.008630275726318 control,\n",
      "0.4241618514060974 lrg,\n",
      "0.4252384901046753 udg,\n",
      "0.3401722013950348 lra,\n",
      "0.32862532138824463 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.626608729362488\n",
      "\n",
      "Total loss: 0.013902826234698296; that's 0.007937601767480373 task and 0.0049248188734054565 recon and 5.202030658721924 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013690121518447996\n",
      "\n",
      "Total loss: 6.933942794799805:\n",
      "5.3707966804504395 control,\n",
      "0.43267178535461426 lrg,\n",
      "0.4400237500667572 udg,\n",
      "0.34080344438552856 lra,\n",
      "0.3496466279029846 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.8523206758499144\n",
      "\n",
      "Total loss: 0.014325671829283237; that's 0.008277079090476036 task and 0.0049134669825434685 recon and 5.675630569458008 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013449424114078283\n",
      "\n",
      "Total loss: 6.221635818481445:\n",
      "4.635156154632568 control,\n",
      "0.43219563364982605 lrg,\n",
      "0.4463064968585968 udg,\n",
      "0.3533770442008972 lra,\n",
      "0.3546004295349121 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.66235921382904\n",
      "\n",
      "Total loss: 0.013551652431488037; that's 0.007687057834118605 task and 0.004884576890617609 recon and 4.900086879730225 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01328417825512588\n",
      "\n",
      "Total loss: 6.325997352600098:\n",
      "4.824681758880615 control,\n",
      "0.4094467759132385 lrg,\n",
      "0.4269247353076935 udg,\n",
      "0.33641892671585083 lra,\n",
      "0.3285251557826996 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.62241376876831\n",
      "\n",
      "Total loss: 0.012796256691217422; that's 0.007382998708635569 task and 0.0044062500819563866 recon and 5.03503942489624 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013195462748408318\n",
      "\n",
      "Total loss: 6.419342517852783:\n",
      "4.9807329177856445 control,\n",
      "0.38135015964508057 lrg,\n",
      "0.3939272165298462 udg,\n",
      "0.3615889847278595 lra,\n",
      "0.3017435073852539 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.566999077796936\n",
      "\n",
      "Total loss: 0.013079359196126461; that's 0.007730172481387854 task and 0.004292858764529228 recon and 5.2816386222839355 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012954572960734368\n",
      "\n",
      "Total loss: 0.012883725576102734; that's 0.0072869895957410336 task and 0.004553614649921656 recon and 5.215607643127441 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.014113978957757354\n",
      "\n",
      "Total loss: 6.573238849639893:\n",
      "4.883342266082764 control,\n",
      "0.47185084223747253 lrg,\n",
      "0.49634072184562683 udg,\n",
      "0.36427581310272217 lra,\n",
      "0.3574291467666626 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.560672011375427\n",
      "\n",
      "Total loss: 0.012751606293022633; that's 0.007281354162842035 task and 0.0044179349206388 recon and 5.261587619781494 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013518062615767122\n",
      "\n",
      "Total loss: 6.5503387451171875:\n",
      "4.930320739746094 control,\n",
      "0.43499165773391724 lrg,\n",
      "0.45470869541168213 udg,\n",
      "0.34484556317329407 lra,\n",
      "0.38547202944755554 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.438619847297669\n",
      "\n",
      "Total loss: 0.013419483788311481; that's 0.008029275573790073 task and 0.004475198686122894 recon and 4.575047969818115 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01353621789254248\n",
      "\n",
      "Total loss: 5.851555824279785:\n",
      "4.2384257316589355 control,\n",
      "0.43399256467819214 lrg,\n",
      "0.4738529324531555 udg,\n",
      "0.35893523693084717 lra,\n",
      "0.34634923934936523 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.740459408760071\n",
      "\n",
      "Total loss: 0.013305521570146084; that's 0.007847757078707218 task and 0.0044186534360051155 recon and 5.195557117462158 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013241097265854478\n",
      "\n",
      "Total loss: 6.462684631347656:\n",
      "4.8942155838012695 control,\n",
      "0.45863810181617737 lrg,\n",
      "0.4295128881931305 udg,\n",
      "0.32211610674858093 lra,\n",
      "0.35820186138153076 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.921031608581543\n",
      "\n",
      "Total loss: 0.012908825650811195; that's 0.0076782894320786 task and 0.004305344540625811 recon and 4.6259589195251465 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012758042998611926\n",
      "\n",
      "Total loss: 5.972022533416748:\n",
      "4.2949066162109375 control,\n",
      "0.47665444016456604 lrg,\n",
      "0.48263058066368103 udg,\n",
      "0.37682032585144043 lra,\n",
      "0.34101077914237976 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.409224362373352\n",
      "\n",
      "Total loss: 6.139206886291504:\n",
      "4.622703552246094 control,\n",
      "0.41845202445983887 lrg,\n",
      "0.41158464550971985 udg,\n",
      "0.3285325765609741 lra,\n",
      "0.3579336404800415 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.69814024925232\n",
      "\n",
      "Total loss: 0.015027856454253197; that's 0.009160016663372517 task and 0.004885269794613123 recon and 4.912848949432373 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.016009115613996983\n",
      "\n",
      "Total loss: 6.339616775512695:\n",
      "4.804079055786133 control,\n",
      "0.34764373302459717 lrg,\n",
      "0.4519418776035309 udg,\n",
      "0.3437969982624054 lra,\n",
      "0.3921546936035156 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.551338658332825\n",
      "\n",
      "Total loss: 0.012981765903532505; that's 0.007524735294282436 task and 0.004439512733370066 recon and 5.087587833404541 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013763922024518252\n",
      "\n",
      "Total loss: 0.013131371699273586; that's 0.0076412600465118885 task and 0.004373036790639162 recon and 5.585374355316162 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013583197211846709\n",
      "\n",
      "Total loss: 6.796685695648193:\n",
      "5.259654998779297 control,\n",
      "0.4268980324268341 lrg,\n",
      "0.4394315779209137 udg,\n",
      "0.3363688290119171 lra,\n",
      "0.3343318700790405 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.925402665138245\n",
      "\n",
      "Total loss: 6.647552013397217:\n",
      "5.032283306121826 control,\n",
      "0.43646740913391113 lrg,\n",
      "0.44913560152053833 udg,\n",
      "0.364566445350647 lra,\n",
      "0.3650988042354584 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.44716073513031\n",
      "\n",
      "Total loss: 0.01370205357670784; that's 0.008025585673749447 task and 0.004598422907292843 recon and 5.390224456787109 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.013234492568299174\n",
      "\n",
      "Total loss: 6.343544006347656:\n",
      "4.718576431274414 control,\n",
      "0.44263148307800293 lrg,\n",
      "0.5022988319396973 udg,\n",
      "0.33098864555358887 lra,\n",
      "0.34904852509498596 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.451618304252625\n",
      "\n",
      "Total loss: 0.012520846910774708; that's 0.00730625307187438 task and 0.004214006010442972 recon and 5.002938270568848 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01295981926843524\n",
      "\n",
      "Total loss: 6.543291091918945:\n",
      "5.039183616638184 control,\n",
      "0.40132206678390503 lrg,\n",
      "0.4258110225200653 udg,\n",
      "0.33136382699012756 lra,\n",
      "0.34561124444007874 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.711593451499939\n",
      "\n",
      "Total loss: 0.012024871073663235; that's 0.006946370471268892 task and 0.003995084203779697 recon and 5.417081832885742 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012563646184280514\n",
      "\n",
      "Total loss: 0.012656138278543949; that's 0.007575951516628265 task and 0.004079363774508238 recon and 5.0041117668151855 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012658369215205311\n",
      "\n",
      "Total loss: 6.2833428382873535:\n",
      "4.717695236206055 control,\n",
      "0.4478771984577179 lrg,\n",
      "0.4277827739715576 udg,\n",
      "0.36728909611701965 lra,\n",
      "0.322698712348938 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.207391233444214\n",
      "\n",
      "Total loss: 0.012247675098478794; that's 0.006800635252147913 task and 0.004293765872716904 recon and 5.766373157501221 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012647906513884664\n",
      "\n",
      "Total loss: 7.015888214111328:\n",
      "5.480175018310547 control,\n",
      "0.4171120524406433 lrg,\n",
      "0.43611380457878113 udg,\n",
      "0.3354664742946625 lra,\n",
      "0.3470212519168854 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.6508269691467286\n",
      "\n",
      "Total loss: 5.824154376983643:\n",
      "4.191499710083008 control,\n",
      "0.4470808804035187 lrg,\n",
      "0.44873562455177307 udg,\n",
      "0.36705467104911804 lra,\n",
      "0.3697836101055145 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.120537691116333\n",
      "\n",
      "Total loss: 0.012477226555347443; that's 0.007488878443837166 task and 0.004109545610845089 recon and 4.394014358520508 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012357238046824932\n",
      "\n",
      "Total loss: 0.012012862600386143; that's 0.006995434407144785 task and 0.004093632102012634 recon and 4.618981838226318 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012476117303594946\n",
      "\n",
      "Total loss: 5.860980033874512:\n",
      "4.2681565284729 control,\n",
      "0.4375549256801605 lrg,\n",
      "0.4605727195739746 udg,\n",
      "0.3446299433708191 lra,\n",
      "0.3500659763813019 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.238139343261719\n",
      "\n",
      "Total loss: 5.8923492431640625:\n",
      "4.2716064453125 control,\n",
      "0.4532369077205658 lrg,\n",
      "0.4592586159706116 udg,\n",
      "0.34418997168540955 lra,\n",
      "0.3640572130680084 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.308250102996826\n",
      "\n",
      "Total loss: 0.01255911123007536; that's 0.007510176859796047 task and 0.004147999919950962 recon and 4.5046706199646 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012338967304676771\n",
      "\n",
      "Total loss: 0.012519126757979393; that's 0.007344092708081007 task and 0.004231730941683054 recon and 4.716513633728027 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01216492487117648\n",
      "\n",
      "Total loss: 5.989080905914307:\n",
      "4.3042988777160645 control,\n",
      "0.4226871728897095 lrg,\n",
      "0.47588711977005005 udg,\n",
      "0.41081565618515015 lra,\n",
      "0.37539178133010864 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.378265342712402\n",
      "\n",
      "Total loss: 0.011975753121078014; that's 0.006604078691452742 task and 0.004440249875187874 recon and 4.657121658325195 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012415925059467554\n",
      "\n",
      "Total loss: 5.974786281585693:\n",
      "4.304487228393555 control,\n",
      "0.43693631887435913 lrg,\n",
      "0.4997207224369049 udg,\n",
      "0.3842693269252777 lra,\n",
      "0.3493726849555969 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.2591168856620785\n",
      "\n",
      "Total loss: 0.012474137358367443; that's 0.0074846986681222916 task and 0.0042708455584943295 recon and 3.5929627418518066 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012880623042583465\n",
      "\n",
      "Total loss: 4.922478199005127:\n",
      "3.2401857376098633 control,\n",
      "0.44986864924430847 lrg,\n",
      "0.5114645957946777 udg,\n",
      "0.35057058930397034 lra,\n",
      "0.37038859724998474 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.346305727958679\n",
      "\n",
      "Total loss: 5.583626747131348:\n",
      "4.040735244750977 control,\n",
      "0.4128040373325348 lrg,\n",
      "0.4483353793621063 udg,\n",
      "0.35623422265052795 lra,\n",
      "0.3255183696746826 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.144050915241241\n",
      "\n",
      "Total loss: 0.012045840732753277; that's 0.007143249269574881 task and 0.004037459380924702 recon and 4.325662136077881 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012397536365315319\n",
      "\n",
      "Total loss: 6.210745334625244:\n",
      "4.592039585113525 control,\n",
      "0.44988322257995605 lrg,\n",
      "0.47245270013809204 udg,\n",
      "0.3484634757041931 lra,\n",
      "0.3479064404964447 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.130059061050415\n",
      "\n",
      "Total loss: 0.01260366290807724; that's 0.007685310207307339 task and 0.0039509739726781845 recon and 4.836893558502197 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012323383335024118\n",
      "\n",
      "Total loss: 0.011636673472821712; that's 0.0066598523408174515 task and 0.004176928196102381 recon and 3.999464988708496 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012072042310610414\n",
      "\n",
      "Total loss: 5.289102554321289:\n",
      "3.6086912155151367 control,\n",
      "0.43741804361343384 lrg,\n",
      "0.4842450022697449 udg,\n",
      "0.36577358841896057 lra,\n",
      "0.3929749131202698 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.966823449134827\n",
      "\n",
      "Total loss: 0.0122014619410038; that's 0.007613282650709152 task and 0.003854663809761405 recon and 3.667576789855957 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011820637071505189\n",
      "\n",
      "Total loss: 4.979823112487793:\n",
      "3.312493085861206 control,\n",
      "0.46779847145080566 lrg,\n",
      "0.4841064214706421 udg,\n",
      "0.355019748210907 lra,\n",
      "0.36040520668029785 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.386824717521668\n",
      "\n",
      "Total loss: 0.011292905546724796; that's 0.007051545660942793 task and 0.00346222217194736 recon and 3.8956878185272217 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011670204922556876\n",
      "\n",
      "Total loss: 5.080334186553955:\n",
      "3.514301061630249 control,\n",
      "0.43694502115249634 lrg,\n",
      "0.4261326491832733 udg,\n",
      "0.3407902717590332 lra,\n",
      "0.36216530203819275 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.22503321647644\n",
      "\n",
      "Total loss: 6.885082721710205:\n",
      "5.271607875823975 control,\n",
      "0.44509515166282654 lrg,\n",
      "0.4678681790828705 udg,\n",
      "0.35021913051605225 lra,\n",
      "0.35029205679893494 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.087703700065613\n",
      "\n",
      "Total loss: 0.012372080236673355; that's 0.007311256602406502 task and 0.003945665434002876 recon and 5.5757927894592285 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011922767646610736\n",
      "\n",
      "Total loss: 7.055898189544678:\n",
      "5.524948596954346 control,\n",
      "0.4203200340270996 lrg,\n",
      "0.42560720443725586 udg,\n",
      "0.34564757347106934 lra,\n",
      "0.3393751382827759 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.0907037687301635\n",
      "\n",
      "Total loss: 0.01271364651620388; that's 0.0078023807145655155 task and 0.0037466760259121656 recon and 5.822951793670654 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011890986012294888\n",
      "\n",
      "Total loss: 0.013146180659532547; that's 0.00799481850117445 task and 0.004071809817105532 recon and 5.397761344909668 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011800413262099027\n",
      "\n",
      "Total loss: 6.622325420379639:\n",
      "5.0537614822387695 control,\n",
      "0.46030816435813904 lrg,\n",
      "0.4294186234474182 udg,\n",
      "0.34359729290008545 lra,\n",
      "0.33524009585380554 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.004891614913941\n",
      "\n",
      "Total loss: 0.011920357123017311; that's 0.0071253469213843346 task and 0.0038168730679899454 recon and 4.890687942504883 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011860981369391083\n",
      "\n",
      "Total loss: 6.1688385009765625:\n",
      "4.605798721313477 control,\n",
      "0.42252153158187866 lrg,\n",
      "0.4538891911506653 udg,\n",
      "0.3272172212600708 lra,\n",
      "0.35941189527511597 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.136845908164978\n",
      "\n",
      "Total loss: 0.011614704504609108; that's 0.006918834988027811 task and 0.0038240912836045027 recon and 4.358893871307373 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011833573058247567\n",
      "\n",
      "Total loss: 5.64485502243042:\n",
      "4.08521032333374 control,\n",
      "0.42580169439315796 lrg,\n",
      "0.4122360050678253 udg,\n",
      "0.3684515655040741 lra,\n",
      "0.35315531492233276 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.13487847328186\n",
      "\n",
      "Total loss: 6.661007881164551:\n",
      "5.099366664886475 control,\n",
      "0.43113747239112854 lrg,\n",
      "0.43159595131874084 udg,\n",
      "0.36118391156196594 lra,\n",
      "0.3377237021923065 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.249724383354187\n",
      "\n",
      "Total loss: 0.012327381409704685; that's 0.007491121534258127 task and 0.003745402442291379 recon and 5.45428466796875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011850097710266709\n",
      "\n",
      "Total loss: 0.011965381912887096; that's 0.00690873060375452 task and 0.004044950939714909 recon and 5.058502674102783 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012053730878978968\n",
      "\n",
      "Total loss: 6.297446250915527:\n",
      "4.735414505004883 control,\n",
      "0.41333797574043274 lrg,\n",
      "0.44794145226478577 udg,\n",
      "0.34410718083381653 lra,\n",
      "0.3566451668739319 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.263654656410218\n",
      "\n",
      "Total loss: 0.011338087730109692; that's 0.00656748004257679 task and 0.0038592629134655 recon and 4.556723117828369 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011866593277081847\n",
      "\n",
      "Total loss: 5.8176960945129395:\n",
      "4.228427886962891 control,\n",
      "0.4086054861545563 lrg,\n",
      "0.4672695994377136 udg,\n",
      "0.3344205319881439 lra,\n",
      "0.37897247076034546 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.298318328857422\n",
      "\n",
      "Total loss: 5.778955936431885:\n",
      "4.203386306762695 control,\n",
      "0.4362068772315979 lrg,\n",
      "0.45684731006622314 udg,\n",
      "0.3400708734989166 lra,\n",
      "0.3424449563026428 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.092290830612183\n",
      "\n",
      "Total loss: 0.010939091444015503; that's 0.006355715449899435 task and 0.0036794953048229218 recon and 4.519400596618652 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011879715565592051\n",
      "\n",
      "Total loss: 0.01115386188030243; that's 0.006554563529789448 task and 0.003495911369100213 recon and 5.516934394836426 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011866574343293905\n",
      "\n",
      "Total loss: 6.877915382385254:\n",
      "5.209568500518799 control,\n",
      "0.519385576248169 lrg,\n",
      "0.46664494276046753 udg,\n",
      "0.338412344455719 lra,\n",
      "0.3439040780067444 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.301815009117126\n",
      "\n",
      "Total loss: 0.011447264812886715; that's 0.006836569868028164 task and 0.0036757984198629856 recon and 4.674480438232422 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01173671755939722\n",
      "\n",
      "Total loss: 5.923902988433838:\n",
      "4.325962066650391 control,\n",
      "0.4265005588531494 lrg,\n",
      "0.46687108278274536 udg,\n",
      "0.35384634137153625 lra,\n",
      "0.35072261095046997 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.224362630844116\n",
      "\n",
      "Total loss: 5.523443698883057:\n",
      "3.9347546100616455 control,\n",
      "0.45783114433288574 lrg,\n",
      "0.4329809546470642 udg,\n",
      "0.3293573558330536 lra,\n",
      "0.3685199022293091 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.198968725204468\n",
      "\n",
      "Total loss: 0.011724445968866348; that's 0.0070952014066278934 task and 0.003778962418437004 recon and 4.251410961151123 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011598201040178537\n",
      "\n",
      "Total loss: 0.012107215821743011; that's 0.007313946262001991 task and 0.0036686966195702553 recon and 5.622865676879883 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011545001743361354\n",
      "\n",
      "Total loss: 6.852447986602783:\n",
      "5.270706653594971 control,\n",
      "0.4255577623844147 lrg,\n",
      "0.4319818913936615 udg,\n",
      "0.3719702959060669 lra,\n",
      "0.3522316515445709 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.039063186645508\n",
      "\n",
      "Total loss: 0.011096658185124397; that's 0.006461006123572588 task and 0.003482900094240904 recon and 5.763759613037109 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011673852205276489\n",
      "\n",
      "Total loss: 6.9688825607299805:\n",
      "5.3746113777160645 control,\n",
      "0.42083853483200073 lrg,\n",
      "0.4633156657218933 udg,\n",
      "0.34005236625671387 lra,\n",
      "0.3700648248195648 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.967131013870239\n",
      "\n",
      "Total loss: 0.01245780661702156; that's 0.007568753324449062 task and 0.003970885183662176 recon and 4.590844631195068 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011555073810741305\n",
      "\n",
      "Total loss: 5.804379940032959:\n",
      "4.226980209350586 control,\n",
      "0.41118568181991577 lrg,\n",
      "0.46453309059143066 udg,\n",
      "0.34721580147743225 lra,\n",
      "0.3544648289680481 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.055139970779419\n",
      "\n",
      "Total loss: 0.012000503949820995; that's 0.007135567720979452 task and 0.0039000201504677534 recon and 4.824581146240234 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012167863612994552\n",
      "\n",
      "Total loss: 6.156163215637207:\n",
      "4.536527633666992 control,\n",
      "0.3873680531978607 lrg,\n",
      "0.4888589680194855 udg,\n",
      "0.35710933804512024 lra,\n",
      "0.386298805475235 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.000703101158142\n",
      "\n",
      "Total loss: 7.59147310256958:\n",
      "5.986669063568115 control,\n",
      "0.4189000427722931 lrg,\n",
      "0.46444717049598694 udg,\n",
      "0.3572509288787842 lra,\n",
      "0.3642060458660126 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.2511136436462404\n",
      "\n",
      "Total loss: 0.012107078917324543; that's 0.0072517856024205685 task and 0.0036108510103076696 recon and 6.222212791442871 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011712254956364632\n",
      "\n",
      "Total loss: 5.725264072418213:\n",
      "4.077964782714844 control,\n",
      "0.4334592819213867 lrg,\n",
      "0.477203369140625 udg,\n",
      "0.3692305386066437 lra,\n",
      "0.36740586161613464 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.0258648443222045\n",
      "\n",
      "Total loss: 0.011862408369779587; that's 0.0069593102671206 task and 0.004025173373520374 recon and 4.389623641967773 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011531449444592\n",
      "\n",
      "Total loss: 0.011964910663664341; that's 0.007158045656979084 task and 0.003782049287110567 recon and 5.124075412750244 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011467881547287107\n",
      "\n",
      "Total loss: 6.439888954162598:\n",
      "4.805878162384033 control,\n",
      "0.4209209382534027 lrg,\n",
      "0.4844588339328766 udg,\n",
      "0.36210304498672485 lra,\n",
      "0.36652812361717224 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.056709046363831\n",
      "\n",
      "Total loss: 6.389107704162598:\n",
      "4.841496467590332 control,\n",
      "0.3993941843509674 lrg,\n",
      "0.4584183096885681 udg,\n",
      "0.35204607248306274 lra,\n",
      "0.33775269985198975 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.115437021255493\n",
      "\n",
      "Total loss: 0.011597150936722755; that's 0.006821407470852137 task and 0.0037608628626912832 recon and 5.07440185546875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01160636192187667\n",
      "\n",
      "Total loss: 0.011562290601432323; that's 0.0067379167303442955 task and 0.0037867799401283264 recon and 5.187969207763672 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01172306681983173\n",
      "\n",
      "Total loss: 6.461695194244385:\n",
      "4.881635665893555 control,\n",
      "0.4071286916732788 lrg,\n",
      "0.4756375551223755 udg,\n",
      "0.3405165672302246 lra,\n",
      "0.35677674412727356 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.002654933929444\n",
      "\n",
      "Total loss: 0.011119178496301174; that's 0.006509454920887947 task and 0.0036335729528218508 recon and 4.880756378173828 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011433406444266438\n",
      "\n",
      "Total loss: 6.195573329925537:\n",
      "4.59080696105957 control,\n",
      "0.4365220367908478 lrg,\n",
      "0.4727383553981781 udg,\n",
      "0.3483841121196747 lra,\n",
      "0.3471224009990692 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.729217863082885\n",
      "\n",
      "Total loss: 0.011819389648735523; that's 0.007231110241264105 task and 0.0038360501639544964 recon and 3.7611474990844727 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011617688555270433\n",
      "\n",
      "Total loss: 5.036444187164307:\n",
      "3.4322962760925293 control,\n",
      "0.4345153570175171 lrg,\n",
      "0.44184184074401855 udg,\n",
      "0.36155930161476135 lra,\n",
      "0.36623117327690125 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.792048044204712\n",
      "\n",
      "Total loss: 0.01060669869184494; that's 0.006087473127990961 task and 0.0037012058310210705 recon and 4.090097427368164 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012135377814993263\n",
      "\n",
      "Total loss: 5.3412675857543945:\n",
      "3.771409034729004 control,\n",
      "0.4483788013458252 lrg,\n",
      "0.4404216408729553 udg,\n",
      "0.3388240337371826 lra,\n",
      "0.3422348201274872 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.165298795700073\n",
      "\n",
      "Total loss: 0.011559993028640747; that's 0.007145806681364775 task and 0.0037453777622431517 recon and 3.344045639038086 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011857932852581143\n",
      "\n",
      "Total loss: 4.543585777282715:\n",
      "2.9638657569885254 control,\n",
      "0.42453330755233765 lrg,\n",
      "0.44285207986831665 udg,\n",
      "0.3583492338657379 lra,\n",
      "0.3539851903915405 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.86882438659668\n",
      "\n",
      "Total loss: 6.993265151977539:\n",
      "5.434406757354736 control,\n",
      "0.3983004093170166 lrg,\n",
      "0.4243704080581665 udg,\n",
      "0.3632090985774994 lra,\n",
      "0.3729782998561859 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.820170025825501\n",
      "\n",
      "Total loss: 0.012413471937179565; that's 0.007207775488495827 task and 0.004058346152305603 recon and 5.736751079559326 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011691431859508156\n",
      "\n",
      "Total loss: 0.011228407733142376; that's 0.0066225724294781685 task and 0.003588919760659337 recon and 5.084579944610596 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011272253943607211\n",
      "\n",
      "Total loss: 6.325417518615723:\n",
      "4.787967681884766 control,\n",
      "0.4297747015953064 lrg,\n",
      "0.4538799226284027 udg,\n",
      "0.32033005356788635 lra,\n",
      "0.3334652781486511 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.90871561050415\n",
      "\n",
      "Total loss: 0.01189865916967392; that's 0.007281765341758728 task and 0.003708683652803302 recon and 4.541050434112549 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011426185183227062\n",
      "\n",
      "Total loss: 5.706377029418945:\n",
      "4.142394065856934 control,\n",
      "0.44319307804107666 lrg,\n",
      "0.45336049795150757 udg,\n",
      "0.3316569924354553 lra,\n",
      "0.33577266335487366 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.978817820549011\n",
      "\n",
      "Total loss: 0.011331766843795776; that's 0.006758411880582571 task and 0.0036169339437037706 recon and 4.7821044921875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011264075599610806\n",
      "\n",
      "Total loss: 6.105038166046143:\n",
      "4.483945846557617 control,\n",
      "0.4365469217300415 lrg,\n",
      "0.4760207235813141 udg,\n",
      "0.34639573097229004 lra,\n",
      "0.36212870478630066 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.909330234527588\n",
      "\n",
      "Total loss: 0.011221478693187237; that's 0.006666043773293495 task and 0.0038138912059366703 recon and 3.707720994949341 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01132615962997079\n",
      "\n",
      "Total loss: 5.016775608062744:\n",
      "3.3563714027404785 control,\n",
      "0.4645764231681824 lrg,\n",
      "0.5002310276031494 udg,\n",
      "0.3688682019710541 lra,\n",
      "0.3267281651496887 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.544561843872071\n",
      "\n",
      "Total loss: 6.252563953399658:\n",
      "4.6645612716674805 control,\n",
      "0.46964526176452637 lrg,\n",
      "0.4323449730873108 udg,\n",
      "0.343765527009964 lra,\n",
      "0.34224674105644226 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.6764382314682\n",
      "\n",
      "Total loss: 0.011099851690232754; that's 0.006515657063573599 task and 0.0035962590482085943 recon and 4.939678192138672 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011211372530087828\n",
      "\n",
      "Total loss: 4.837582111358643:\n",
      "3.240399122238159 control,\n",
      "0.414055734872818 lrg,\n",
      "0.4643981158733368 udg,\n",
      "0.3819665312767029 lra,\n",
      "0.3367624282836914 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.3708682012557984\n",
      "\n",
      "Total loss: 0.010625101625919342; that's 0.006445903331041336 task and 0.003475927049294114 recon and 3.516359329223633 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011237018126994371\n",
      "\n",
      "Total loss: 4.534252166748047:\n",
      "2.824690103530884 control,\n",
      "0.46146464347839355 lrg,\n",
      "0.48894909024238586 udg,\n",
      "0.3571542501449585 lra,\n",
      "0.4019941985607147 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.2515644836425786\n",
      "\n",
      "Total loss: 0.010777559131383896; that's 0.006606393959373236 task and 0.0035500051453709602 recon and 3.1058013439178467 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011007953761145472\n",
      "\n",
      "Total loss: 0.010409947484731674; that's 0.006214338820427656 task and 0.0035080057568848133 recon and 3.4380130767822266 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010964596532285214\n",
      "\n",
      "Total loss: 4.696972370147705:\n",
      "3.1075685024261475 control,\n",
      "0.43645110726356506 lrg,\n",
      "0.47811663150787354 udg,\n",
      "0.3384440541267395 lra,\n",
      "0.33639177680015564 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.967428455352783\n",
      "\n",
      "Total loss: 4.6811981201171875:\n",
      "3.02398419380188 control,\n",
      "0.47412407398223877 lrg,\n",
      "0.47961005568504333 udg,\n",
      "0.3639187812805176 lra,\n",
      "0.3395608365535736 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.11455715417862\n",
      "\n",
      "Total loss: 0.011110562831163406; that's 0.0066605182364583015 task and 0.0037923927884548903 recon and 3.2882559299468994 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011200537215918302\n",
      "\n",
      "Total loss: 5.978734016418457:\n",
      "4.467728137969971 control,\n",
      "0.39173373579978943 lrg,\n",
      "0.4422197639942169 udg,\n",
      "0.33792757987976074 lra,\n",
      "0.33912479877471924 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.724606719017029\n",
      "\n",
      "Total loss: 0.011566292494535446; that's 0.007088451646268368 task and 0.003516008146107197 recon and 4.809164524078369 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011104738945141435\n",
      "\n",
      "Total loss: 6.0371413230896:\n",
      "4.47518253326416 control,\n",
      "0.4507541358470917 lrg,\n",
      "0.4148976504802704 udg,\n",
      "0.34100425243377686 lra,\n",
      "0.3553026616573334 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.3946648430824276\n",
      "\n",
      "Total loss: 0.011203509755432606; that's 0.006758461240679026 task and 0.0034799063578248024 recon and 4.82570743560791 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011064718971028923\n",
      "\n",
      "Total loss: 0.010354605503380299; that's 0.006457998417317867 task and 0.003295411355793476 recon and 3.005977153778076 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010857152193784714\n",
      "\n",
      "Total loss: 4.199853897094727:\n",
      "2.631948232650757 control,\n",
      "0.4097614884376526 lrg,\n",
      "0.43899571895599365 udg,\n",
      "0.38006940484046936 lra,\n",
      "0.3390793800354004 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.630851535797119\n",
      "\n",
      "Total loss: 0.01071082428097725; that's 0.006282767280936241 task and 0.003562553320080042 recon and 4.327520370483398 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011024197405204177\n",
      "\n",
      "Total loss: 5.564147472381592:\n",
      "4.020681381225586 control,\n",
      "0.4373911917209625 lrg,\n",
      "0.4320414662361145 udg,\n",
      "0.32669416069984436 lra,\n",
      "0.3473391532897949 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.073736424446106\n",
      "\n",
      "Total loss: 6.3790788650512695:\n",
      "4.791419982910156 control,\n",
      "0.42007389664649963 lrg,\n",
      "0.46920526027679443 udg,\n",
      "0.33535513281822205 lra,\n",
      "0.3630242347717285 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.788973922729492\n",
      "\n",
      "Total loss: 0.011652933433651924; that's 0.007183219771832228 task and 0.0034579792991280556 recon and 5.0586748123168945 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011225174739956855\n",
      "\n",
      "Total loss: 4.004518508911133:\n",
      "2.2590529918670654 control,\n",
      "0.5082156658172607 lrg,\n",
      "0.5161222219467163 udg,\n",
      "0.3576611280441284 lra,\n",
      "0.3634662330150604 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.914421043395996\n",
      "\n",
      "Total loss: 0.010768497362732887; that's 0.006909296382218599 task and 0.003357056062668562 recon and 2.5107264518737793 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010937102697789669\n",
      "\n",
      "Total loss: 3.85715651512146:\n",
      "2.243363618850708 control,\n",
      "0.4432564377784729 lrg,\n",
      "0.4628064036369324 udg,\n",
      "0.3586401045322418 lra,\n",
      "0.3490898609161377 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.8206288957595826\n",
      "\n",
      "Total loss: 0.01122787594795227; that's 0.006810228805989027 task and 0.003906652331352234 recon and 2.5549697875976562 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010877802204340696\n",
      "\n",
      "Total loss: 0.013158302754163742; that's 0.007714204955846071 task and 0.0048048668541014194 recon and 3.1961569786071777 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011639916598796844\n",
      "\n",
      "Total loss: 4.395400047302246:\n",
      "2.853353261947632 control,\n",
      "0.4208342134952545 lrg,\n",
      "0.45003601908683777 udg,\n",
      "0.32953107357025146 lra,\n",
      "0.34164533019065857 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.472863087654114\n",
      "\n",
      "Total loss: 0.010897789150476456; that's 0.006898836232721806 task and 0.003506764303892851 recon and 2.4609436988830566 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011380050331354141\n",
      "\n",
      "Total loss: 3.6970949172973633:\n",
      "2.1056861877441406 control,\n",
      "0.42369288206100464 lrg,\n",
      "0.4574165642261505 udg,\n",
      "0.36132776737213135 lra,\n",
      "0.3489713668823242 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.719863383769989\n",
      "\n",
      "Total loss: 4.613260746002197:\n",
      "2.9880621433258057 control,\n",
      "0.4332912564277649 lrg,\n",
      "0.42099571228027344 udg,\n",
      "0.370368093252182 lra,\n",
      "0.40054380893707275 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.098694825172425\n",
      "\n",
      "Total loss: 0.010056079365313053; that's 0.005832700524479151 task and 0.0035708663053810596 recon and 3.2625620365142822 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01105239882133901\n",
      "\n",
      "Total loss: 0.010469036176800728; that's 0.006236890330910683 task and 0.0032439003698527813 recon and 4.941224575042725 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011110863648355007\n",
      "\n",
      "Total loss: 6.147370338439941:\n",
      "4.6187663078308105 control,\n",
      "0.4216374158859253 lrg,\n",
      "0.43817609548568726 udg,\n",
      "0.3250030279159546 lra,\n",
      "0.3437870442867279 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.113517589569092\n",
      "\n",
      "Total loss: 0.010857930406928062; that's 0.0065209222957491875 task and 0.003248745109885931 recon and 5.441318035125732 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011021380117163061\n",
      "\n",
      "Total loss: 6.650235176086426:\n",
      "5.083023548126221 control,\n",
      "0.42866313457489014 lrg,\n",
      "0.46018368005752563 udg,\n",
      "0.3333389461040497 lra,\n",
      "0.34502607583999634 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.61097897529602\n",
      "\n",
      "Total loss: 5.698651313781738:\n",
      "4.165119171142578 control,\n",
      "0.4080112874507904 lrg,\n",
      "0.46951109170913696 udg,\n",
      "0.32082927227020264 lra,\n",
      "0.335180401802063 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.9476023244857785\n",
      "\n",
      "Total loss: 0.011785577982664108; that's 0.007101585157215595 task and 0.0037868297658860683 recon and 4.485819339752197 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011208427669480443\n",
      "\n",
      "Total loss: 0.011968686245381832; that's 0.007050266023725271 task and 0.0038572284393012524 recon and 5.305959701538086 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011033672709017991\n",
      "\n",
      "Total loss: 6.540639400482178:\n",
      "4.91620397567749 control,\n",
      "0.4384394586086273 lrg,\n",
      "0.4496447443962097 udg,\n",
      "0.3831698000431061 lra,\n",
      "0.35318198800086975 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.644072663784027\n",
      "\n",
      "Total loss: 5.958622932434082:\n",
      "4.439896583557129 control,\n",
      "0.4099583029747009 lrg,\n",
      "0.40757235884666443 udg,\n",
      "0.3467664122581482 lra,\n",
      "0.3544292449951172 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.194488554000855\n",
      "\n",
      "Total loss: 0.011195579543709755; that's 0.006538759917020798 task and 0.0037050002720206976 recon and 4.759096145629883 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011144170742481948\n",
      "\n",
      "Total loss: 6.557833671569824:\n",
      "5.076140403747559 control,\n",
      "0.38349759578704834 lrg,\n",
      "0.42716580629348755 udg,\n",
      "0.34312704205513 lra,\n",
      "0.32790228724479675 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.865840458869934\n",
      "\n",
      "Total loss: 0.010735724121332169; that's 0.0061460151337087154 task and 0.0035084388218820095 recon and 5.406352519989014 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011040033530443907\n",
      "\n",
      "Total loss: 5.270488739013672:\n",
      "3.6367032527923584 control,\n",
      "0.42388641834259033 lrg,\n",
      "0.47325336933135986 udg,\n",
      "0.3745405077934265 lra,\n",
      "0.3621053695678711 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.045140454769134\n",
      "\n",
      "Total loss: 0.011050766333937645; that's 0.006854713428765535 task and 0.003391985548660159 recon and 4.020340442657471 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010901892492547631\n",
      "\n",
      "Total loss: 4.637200832366943:\n",
      "3.0541086196899414 control,\n",
      "0.42489975690841675 lrg,\n",
      "0.502037763595581 udg,\n",
      "0.32686296105384827 lra,\n",
      "0.3292917013168335 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.880627858638763\n",
      "\n",
      "Total loss: 0.010607167147099972; that's 0.006559344939887524 task and 0.0033852201886475086 recon and 3.3130056858062744 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010890126740559936\n",
      "\n",
      "Total loss: 5.969170093536377:\n",
      "4.442416191101074 control,\n",
      "0.39825141429901123 lrg,\n",
      "0.42881473898887634 udg,\n",
      "0.36788803339004517 lra,\n",
      "0.33179932832717896 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.304874587059021\n",
      "\n",
      "Total loss: 0.011043339036405087; that's 0.006585631053894758 task and 0.003516032826155424 recon and 4.708376407623291 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010945546431466937\n",
      "\n",
      "Total loss: 4.834682941436768:\n",
      "3.088510513305664 control,\n",
      "0.46252748370170593 lrg,\n",
      "0.48212987184524536 udg,\n",
      "0.4108368456363678 lra,\n",
      "0.3906783163547516 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.892186369895935\n",
      "\n",
      "Total loss: 0.01197401899844408; that's 0.007482046727091074 task and 0.0038147831801325083 recon and 3.38594388961792 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010881931204348803\n",
      "\n",
      "Total loss: 4.349233150482178:\n",
      "2.713883876800537 control,\n",
      "0.41787514090538025 lrg,\n",
      "0.5153411030769348 udg,\n",
      "0.35748887062072754 lra,\n",
      "0.34464412927627563 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.973580558300018\n",
      "\n",
      "Total loss: 0.009987196885049343; that's 0.00605997396633029 task and 0.003334934590384364 recon and 2.961442470550537 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010795806096866726\n",
      "\n",
      "Total loss: 4.627505302429199:\n",
      "2.996441602706909 control,\n",
      "0.4039221704006195 lrg,\n",
      "0.47569796442985535 udg,\n",
      "0.37855422496795654 lra,\n",
      "0.3728896379470825 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.071721563339233\n",
      "\n",
      "Total loss: 0.011792877689003944; that's 0.00753496028482914 task and 0.0035996907390654087 recon and 3.291137933731079 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011044644340872765\n",
      "\n",
      "Total loss: 0.01087246835231781; that's 0.006693555042147636 task and 0.003521279664710164 recon and 3.2881696224212646 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01092209156602621\n",
      "\n",
      "Total loss: 4.462601661682129:\n",
      "2.828040599822998 control,\n",
      "0.4261851906776428 lrg,\n",
      "0.48170506954193115 udg,\n",
      "0.36264368891716003 lra,\n",
      "0.3640272319316864 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.861465814113617\n",
      "\n",
      "Total loss: 5.367100715637207:\n",
      "3.7161800861358643 control,\n",
      "0.42864879965782166 lrg,\n",
      "0.5188701152801514 udg,\n",
      "0.32731348276138306 lra,\n",
      "0.3760879933834076 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.052197370529175\n",
      "\n",
      "Total loss: 0.011005722917616367; that's 0.006937824655324221 task and 0.0032806359231472015 recon and 3.9363155364990234 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010882805800065398\n",
      "\n",
      "Total loss: 5.434422492980957:\n",
      "3.835505485534668 control,\n",
      "0.43205225467681885 lrg,\n",
      "0.4570581018924713 udg,\n",
      "0.3336130678653717 lra,\n",
      "0.3761940896511078 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.457363922595977\n",
      "\n",
      "Total loss: 0.012123610824346542; that's 0.007088964339345694 task and 0.004206391982734203 recon and 4.1412763595581055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01135044489055872\n",
      "\n",
      "Total loss: 0.01132761687040329; that's 0.006832526531070471 task and 0.0037489691749215126 recon and 3.7306063175201416 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011914818082004786\n",
      "\n",
      "Total loss: 5.046458721160889:\n",
      "3.434657335281372 control,\n",
      "0.4605616331100464 lrg,\n",
      "0.4601201117038727 udg,\n",
      "0.35131847858428955 lra,\n",
      "0.33980152010917664 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.658191394805908\n",
      "\n",
      "Total loss: 0.0116637097671628; that's 0.007140406873077154 task and 0.0037195454351603985 recon and 4.018789291381836 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011789885023608804\n",
      "\n",
      "Total loss: 5.244795799255371:\n",
      "3.716036319732666 control,\n",
      "0.3798667788505554 lrg,\n",
      "0.4472644031047821 udg,\n",
      "0.3512577414512634 lra,\n",
      "0.35037076473236084 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.682023634910584\n",
      "\n",
      "Total loss: 3.999990224838257:\n",
      "2.4582653045654297 control,\n",
      "0.4036265015602112 lrg,\n",
      "0.4304584860801697 udg,\n",
      "0.3453407287597656 lra,\n",
      "0.3622991442680359 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.413424110412597\n",
      "\n",
      "Total loss: 0.011014698073267937; that's 0.00664819311350584 task and 0.0038197452668100595 recon and 2.73380184173584 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011653249049559236\n",
      "\n",
      "Total loss: 4.647316932678223:\n",
      "3.0044198036193848 control,\n",
      "0.45824941992759705 lrg,\n",
      "0.42961254715919495 udg,\n",
      "0.3533724546432495 lra,\n",
      "0.4016627073287964 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.476305563449859\n",
      "\n",
      "Total loss: 0.011152778752148151; that's 0.006862171459943056 task and 0.0036344025284051895 recon and 3.28102445602417 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011384155657142401\n",
      "\n",
      "Total loss: 5.0257415771484375:\n",
      "3.4768357276916504 control,\n",
      "0.4378606081008911 lrg,\n",
      "0.4211178719997406 udg,\n",
      "0.3386136293411255 lra,\n",
      "0.3513140082359314 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.593270404338837\n",
      "\n",
      "Total loss: 0.011240453459322453; that's 0.006942144129425287 task and 0.003536686534062028 recon and 3.8081109523773193 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011234105536714197\n",
      "\n",
      "Total loss: 5.523272514343262:\n",
      "4.00197172164917 control,\n",
      "0.3905673921108246 lrg,\n",
      "0.4257391691207886 udg,\n",
      "0.36741840839385986 lra,\n",
      "0.3375759720802307 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.954927260875702\n",
      "\n",
      "Total loss: 0.01105688326060772; that's 0.006369624752551317 task and 0.0038227150216698647 recon and 4.32271671295166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011117328330874443\n",
      "\n",
      "Total loss: 0.011079266667366028; that's 0.006839555688202381 task and 0.0033215389121323824 recon and 4.590859413146973 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011031776992604136\n",
      "\n",
      "Total loss: 5.871977806091309:\n",
      "4.267686367034912 control,\n",
      "0.43517056107521057 lrg,\n",
      "0.44127076864242554 udg,\n",
      "0.3716495931148529 lra,\n",
      "0.3561999797821045 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.232032864093781\n",
      "\n",
      "Total loss: 0.011345741339027882; that's 0.0065805683843791485 task and 0.0036212392151355743 recon and 5.719665050506592 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010968955075368285\n",
      "\n",
      "Total loss: 6.869237422943115:\n",
      "5.3540754318237305 control,\n",
      "0.38909220695495605 lrg,\n",
      "0.4225707948207855 udg,\n",
      "0.34992268681526184 lra,\n",
      "0.3535759747028351 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.151693687438965\n",
      "\n",
      "Total loss: 4.116458415985107:\n",
      "2.4880211353302 control,\n",
      "0.46954017877578735 lrg,\n",
      "0.46439146995544434 udg,\n",
      "0.32321789860725403 lra,\n",
      "0.37128791213035583 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.9395629906654355\n",
      "\n",
      "Total loss: 0.010665042325854301; that's 0.006660435348749161 task and 0.0034476048313081264 recon and 2.7850093841552734 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010728545729070902\n",
      "\n",
      "Total loss: 0.011138010770082474; that's 0.0070202527567744255 task and 0.003496619174256921 recon and 3.105696439743042 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010919815441593528\n",
      "\n",
      "Total loss: 4.380340576171875:\n",
      "2.769721746444702 control,\n",
      "0.45282435417175293 lrg,\n",
      "0.4651218056678772 udg,\n",
      "0.3252878189086914 lra,\n",
      "0.36738499999046326 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.873242425918579\n",
      "\n",
      "Total loss: 0.009896328672766685; that's 0.00589373242110014 task and 0.0034349544439464808 recon and 2.838212013244629 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010686795404180884\n",
      "\n",
      "Total loss: 4.040823459625244:\n",
      "2.4299895763397217 control,\n",
      "0.4270073175430298 lrg,\n",
      "0.4609953463077545 udg,\n",
      "0.33753135800361633 lra,\n",
      "0.3852995038032532 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.272704420089721\n",
      "\n",
      "Total loss: 7.0648603439331055:\n",
      "5.503716945648193 control,\n",
      "0.41162270307540894 lrg,\n",
      "0.45111900568008423 udg,\n",
      "0.3161579668521881 lra,\n",
      "0.3822439908981323 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.536760160923004\n",
      "\n",
      "Total loss: 0.01091487891972065; that's 0.006564909126609564 task and 0.003204007400199771 recon and 5.7298150062561035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010687672458589077\n",
      "\n",
      "Total loss: 3.998837947845459:\n",
      "2.2954821586608887 control,\n",
      "0.4854276776313782 lrg,\n",
      "0.47598353028297424 udg,\n",
      "0.3824618458747864 lra,\n",
      "0.3594827353954315 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.736817555427551\n",
      "\n",
      "Total loss: 0.010884499177336693; that's 0.00641977321356535 task and 0.003945199307054281 recon and 2.597635507583618 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010709241051226854\n",
      "\n",
      "Total loss: 3.986829996109009:\n",
      "2.3618714809417725 control,\n",
      "0.4313878118991852 lrg,\n",
      "0.45932841300964355 udg,\n",
      "0.37278008460998535 lra,\n",
      "0.3614620268344879 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.664001533985138\n",
      "\n",
      "Total loss: 0.010222779586911201; that's 0.00625774497166276 task and 0.0034370701760053635 recon and 2.6398258209228516 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010695817731320858\n",
      "\n",
      "Total loss: 7.153621196746826:\n",
      "5.598825931549072 control,\n",
      "0.43086349964141846 lrg,\n",
      "0.43639540672302246 udg,\n",
      "0.3384525775909424 lra,\n",
      "0.34908419847488403 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.35288162946701\n",
      "\n",
      "Total loss: 0.01081923022866249; that's 0.006357972975820303 task and 0.0032922609243541956 recon and 5.8449788093566895 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010743806697428226\n",
      "\n",
      "Total loss: 0.010384929366409779; that's 0.00644714804366231 task and 0.003298464696854353 recon and 3.1965830326080322 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010630729654803873\n",
      "\n",
      "Total loss: 4.403966426849365:\n",
      "2.8128108978271484 control,\n",
      "0.4392987787723541 lrg,\n",
      "0.4173027276992798 udg,\n",
      "0.3592991530895233 lra,\n",
      "0.3752548396587372 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.725439200401306\n",
      "\n",
      "Total loss: 6.120142459869385:\n",
      "4.531290054321289 control,\n",
      "0.42760229110717773 lrg,\n",
      "0.44463106989860535 udg,\n",
      "0.356939435005188 lra,\n",
      "0.3596796691417694 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.795835156440734\n",
      "\n",
      "Total loss: 0.01081661507487297; that's 0.006411782931536436 task and 0.0034302780404686928 recon and 4.872771739959717 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010860932022333146\n",
      "\n",
      "Total loss: 0.009924203157424927; that's 0.0062765213660895824 task and 0.003085906384512782 recon and 2.8088784217834473 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010616622241213918\n",
      "\n",
      "Total loss: 4.01657247543335:\n",
      "2.4688501358032227 control,\n",
      "0.41875237226486206 lrg,\n",
      "0.43279266357421875 udg,\n",
      "0.34500953555107117 lra,\n",
      "0.3511678874492645 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.336397655010224\n",
      "\n",
      "Total loss: 5.545974254608154:\n",
      "3.996281385421753 control,\n",
      "0.42792993783950806 lrg,\n",
      "0.43655428290367126 udg,\n",
      "0.3414994776248932 lra,\n",
      "0.3437090516090393 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.811958990097046\n",
      "\n",
      "Total loss: 0.010648440569639206; that's 0.0063003841787576675 task and 0.0034975006710737944 recon and 4.252775192260742 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010792344585061073\n",
      "\n",
      "Total loss: 0.010723805986344814; that's 0.0062825339846313 task and 0.0033747749403119087 recon and 5.332488059997559 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01077116945758462\n",
      "\n",
      "Total loss: 6.575948238372803:\n",
      "5.028542518615723 control,\n",
      "0.37993696331977844 lrg,\n",
      "0.4233535826206207 udg,\n",
      "0.3553779721260071 lra,\n",
      "0.3887367844581604 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.9464971685409544\n",
      "\n",
      "Total loss: 4.843898773193359:\n",
      "3.3070731163024902 control,\n",
      "0.42805394530296326 lrg,\n",
      "0.42590680718421936 udg,\n",
      "0.33713942766189575 lra,\n",
      "0.3457256555557251 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.69904746055603\n",
      "\n",
      "Total loss: 0.010537193156778812; that's 0.006464923266321421 task and 0.003361048875376582 recon and 3.556107997894287 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01075465489178896\n",
      "\n",
      "Total loss: 4.3561811447143555:\n",
      "2.818179130554199 control,\n",
      "0.401477575302124 lrg,\n",
      "0.4119541049003601 udg,\n",
      "0.3705819547176361 lra,\n",
      "0.3539879322052002 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.649247827529908\n",
      "\n",
      "Total loss: 0.010619902983307838; that's 0.006594486068934202 task and 0.0033861231058835983 recon and 3.1964659690856934 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010635806461796165\n",
      "\n",
      "Total loss: 0.010366952046751976; that's 0.00660555949434638 task and 0.0032022870145738125 recon and 2.795527696609497 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010463114026933909\n",
      "\n",
      "Total loss: 3.9790687561035156:\n",
      "2.463592052459717 control,\n",
      "0.3834127187728882 lrg,\n",
      "0.4387185871601105 udg,\n",
      "0.3386199474334717 lra,\n",
      "0.35472527146339417 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.448419377803803\n",
      "\n",
      "Total loss: 0.01074098888784647; that's 0.006746429949998856 task and 0.0032956579234451056 recon and 3.49450421333313 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010479724211618304\n",
      "\n",
      "Total loss: 4.895461082458496:\n",
      "3.233693838119507 control,\n",
      "0.45416364073753357 lrg,\n",
      "0.48529428243637085 udg,\n",
      "0.3394467830657959 lra,\n",
      "0.3828631341457367 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.4050768995285035\n",
      "\n",
      "Total loss: 4.248104572296143:\n",
      "2.620401382446289 control,\n",
      "0.4370523989200592 lrg,\n",
      "0.5045288801193237 udg,\n",
      "0.33550265431404114 lra,\n",
      "0.3506194055080414 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.274938833713532\n",
      "\n",
      "Total loss: 0.010286732576787472; that's 0.006600404158234596 task and 0.0030958347488194704 recon and 2.952467918395996 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010506084645166993\n",
      "\n",
      "Total loss: 0.010775687173008919; that's 0.006932769436389208 task and 0.003269751323387027 recon and 2.8658313751220703 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010431205667555333\n",
      "\n",
      "Total loss: 4.122379302978516:\n",
      "2.5155303478240967 control,\n",
      "0.4307468831539154 lrg,\n",
      "0.4689241647720337 udg,\n",
      "0.3541926443576813 lra,\n",
      "0.3529854416847229 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.276142499446869\n",
      "\n",
      "Total loss: 4.3095574378967285:\n",
      "2.691457748413086 control,\n",
      "0.4531891345977783 lrg,\n",
      "0.4806937277317047 udg,\n",
      "0.3537755310535431 lra,\n",
      "0.3304411768913269 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.305752627849579\n",
      "\n",
      "Total loss: 0.00947420485317707; that's 0.005746311973780394 task and 0.003128885291516781 recon and 2.9950385093688965 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010340122794732452\n",
      "\n",
      "Total loss: 4.007888317108154:\n",
      "2.343336343765259 control,\n",
      "0.5039060115814209 lrg,\n",
      "0.459121435880661 udg,\n",
      "0.3618052899837494 lra,\n",
      "0.339719295501709 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.238103539943695\n",
      "\n",
      "Total loss: 0.010445131920278072; that's 0.006793576758354902 task and 0.003111018566414714 recon and 2.702685832977295 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010357606522738934\n",
      "\n",
      "Total loss: 0.0159310232847929; that's 0.009282916784286499 task and 0.005522348452359438 recon and 5.628793716430664 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.011293338993564248\n",
      "\n",
      "Total loss: 6.896933555603027:\n",
      "5.2960309982299805 control,\n",
      "0.4286089241504669 lrg,\n",
      "0.4913937747478485 udg,\n",
      "0.32386496663093567 lra,\n",
      "0.35703495144844055 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.827692627906799\n",
      "\n",
      "Total loss: 6.191658020019531:\n",
      "4.621365070343018 control,\n",
      "0.4205905795097351 lrg,\n",
      "0.45270058512687683 udg,\n",
      "0.33742162585258484 lra,\n",
      "0.35958054661750793 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.054004893302918\n",
      "\n",
      "Total loss: 0.01060571614652872; that's 0.006278528366237879 task and 0.0033522455487400293 recon and 4.8747100830078125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01210259595885873\n",
      "\n",
      "Total loss: 6.676517009735107:\n",
      "5.150420188903809 control,\n",
      "0.3922269344329834 lrg,\n",
      "0.4683910608291626 udg,\n",
      "0.34995099902153015 lra,\n",
      "0.31552788615226746 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.964658875465393\n",
      "\n",
      "Total loss: 0.01028124988079071; that's 0.006045338697731495 task and 0.0031473725102841854 recon and 5.442696571350098 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010900043779984117\n",
      "\n",
      "Total loss: 0.010459122247993946; that's 0.006411073263734579 task and 0.003334418870508671 recon and 3.568154811859131 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01064261570572853\n",
      "\n",
      "Total loss: 4.81114387512207:\n",
      "3.242755651473999 control,\n",
      "0.4396529197692871 lrg,\n",
      "0.4301903545856476 udg,\n",
      "0.34276503324508667 lra,\n",
      "0.35578030347824097 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.672446527481079\n",
      "\n",
      "Total loss: 0.009895356371998787; that's 0.006083522457629442 task and 0.0031487098895013332 recon and 3.3156182765960693 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010461690109223128\n",
      "\n",
      "Total loss: 4.578208923339844:\n",
      "2.952867031097412 control,\n",
      "0.4069361686706543 lrg,\n",
      "0.4992465376853943 udg,\n",
      "0.3809660077095032 lra,\n",
      "0.33819302916526794 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.730868628025055\n",
      "\n",
      "Total loss: 0.010775336995720863; that's 0.0067266784608364105 task and 0.003396512707695365 recon and 3.2607266902923584 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01037926464341581\n",
      "\n",
      "Total loss: 4.501568794250488:\n",
      "2.9379401206970215 control,\n",
      "0.41633710265159607 lrg,\n",
      "0.47538119554519653 udg,\n",
      "0.3361313045024872 lra,\n",
      "0.33577898144721985 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.542090852260589\n",
      "\n",
      "Total loss: 5.020724296569824:\n",
      "3.3455944061279297 control,\n",
      "0.5015535950660706 lrg,\n",
      "0.48596280813217163 udg,\n",
      "0.3269028067588806 lra,\n",
      "0.360710471868515 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.507994725704193\n",
      "\n",
      "Total loss: 0.00960712693631649; that's 0.005698549095541239 task and 0.0031587930861860514 recon and 3.7489213943481445 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010290454858914017\n",
      "\n",
      "Total loss: 4.800475120544434:\n",
      "3.2122957706451416 control,\n",
      "0.4124520421028137 lrg,\n",
      "0.4559505581855774 udg,\n",
      "0.3666016161441803 lra,\n",
      "0.35317540168762207 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.437839398384094\n",
      "\n",
      "Total loss: 0.010737106204032898; that's 0.0066166166216135025 task and 0.0034033586271107197 recon and 3.5856571197509766 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010345887644216418\n",
      "\n",
      "Total loss: 0.010168297216296196; that's 0.006330627948045731 task and 0.00317826634272933 recon and 3.297011137008667 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010389806739985942\n",
      "\n",
      "Total loss: 4.401269912719727:\n",
      "2.8366944789886475 control,\n",
      "0.4390558898448944 lrg,\n",
      "0.43317654728889465 udg,\n",
      "0.34706199169158936 lra,\n",
      "0.3452812731266022 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.383846218585968\n",
      "\n",
      "Total loss: 7.499465465545654:\n",
      "5.866666316986084 control,\n",
      "0.5038415193557739 lrg,\n",
      "0.47211018204689026 udg,\n",
      "0.33275899291038513 lra,\n",
      "0.3240884840488434 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.706043565273285\n",
      "\n",
      "Total loss: 0.012090707197785378; that's 0.007020856253802776 task and 0.0038329046219587326 recon and 6.1847333908081055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01042753191664815\n",
      "\n",
      "Total loss: 4.248388767242432:\n",
      "2.672480583190918 control,\n",
      "0.43425169587135315 lrg,\n",
      "0.43946847319602966 udg,\n",
      "0.34984010457992554 lra,\n",
      "0.3523479998111725 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.729400396347046\n",
      "\n",
      "Total loss: 0.011262585408985615; that's 0.006901102606207132 task and 0.0037841119337826967 recon and 2.8868510723114014 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.012319740280508995\n",
      "\n",
      "Total loss: 0.011790079064667225; that's 0.007135741412639618 task and 0.003444277448579669 recon and 6.050300598144531 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010798715380951762\n",
      "\n",
      "Total loss: 7.389414310455322:\n",
      "5.698753356933594 control,\n",
      "0.477681040763855 lrg,\n",
      "0.4926919639110565 udg,\n",
      "0.3492748439311981 lra,\n",
      "0.37101298570632935 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.4923997139930725\n",
      "\n",
      "Total loss: 5.898566246032715:\n",
      "4.314553260803223 control,\n",
      "0.47719237208366394 lrg,\n",
      "0.4310343265533447 udg,\n",
      "0.3377736806869507 lra,\n",
      "0.3380122482776642 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.021885280609131\n",
      "\n",
      "Total loss: 0.010545196942985058; that's 0.006253195460885763 task and 0.003366189543157816 recon and 4.629061222076416 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010820777267217635\n",
      "\n",
      "Total loss: 0.010545055381953716; that's 0.006512225139886141 task and 0.0034241119865328074 recon and 3.0435914993286133 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010509607959538697\n",
      "\n",
      "Total loss: 4.2172932624816895:\n",
      "2.6411402225494385 control,\n",
      "0.415473073720932 lrg,\n",
      "0.4616614282131195 udg,\n",
      "0.3582196533679962 lra,\n",
      "0.3407992422580719 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.951015281677246\n",
      "\n",
      "Total loss: 0.01094517856836319; that's 0.006521561648696661 task and 0.003421436296775937 recon and 5.010903835296631 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01082702687010169\n",
      "\n",
      "Total loss: 6.128276824951172:\n",
      "4.580672264099121 control,\n",
      "0.39902350306510925 lrg,\n",
      "0.45411616563796997 udg,\n",
      "0.3411872386932373 lra,\n",
      "0.3532770574092865 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.696384124755859\n",
      "\n",
      "Total loss: 5.805811405181885:\n",
      "4.252816200256348 control,\n",
      "0.3967002332210541 lrg,\n",
      "0.43910935521125793 udg,\n",
      "0.3614470064640045 lra,\n",
      "0.3557385504245758 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.027961149215698\n",
      "\n",
      "Total loss: 0.011145943775773048; that's 0.006740445736795664 task and 0.00348974228836596 recon and 4.578777313232422 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010740268984809518\n",
      "\n",
      "Total loss: 6.347041130065918:\n",
      "4.8319525718688965 control,\n",
      "0.43112048506736755 lrg,\n",
      "0.41665738821029663 udg,\n",
      "0.3341716229915619 lra,\n",
      "0.33313918113708496 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.784101867675782\n",
      "\n",
      "Total loss: 0.01053356472402811; that's 0.006130545400083065 task and 0.0033714119344949722 recon and 5.1580376625061035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010550112957134842\n",
      "\n",
      "Total loss: 5.736486911773682:\n",
      "4.198143005371094 control,\n",
      "0.4790034294128418 lrg,\n",
      "0.41329240798950195 udg,\n",
      "0.3325914144515991 lra,\n",
      "0.3134565055370331 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.170606374740601\n",
      "\n",
      "Total loss: 0.010438969358801842; that's 0.006311037577688694 task and 0.0032258578576147556 recon and 4.510365962982178 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010679190196096897\n",
      "\n",
      "Total loss: 0.00959695503115654; that's 0.005626267287880182 task and 0.0031201078090816736 recon and 4.2528977394104 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010611220179125667\n",
      "\n",
      "Total loss: 5.521491050720215:\n",
      "4.002406597137451 control,\n",
      "0.39060455560684204 lrg,\n",
      "0.45529767870903015 udg,\n",
      "0.34079453349113464 lra,\n",
      "0.33238768577575684 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.764108271598816\n",
      "\n",
      "Total loss: 0.011074194684624672; that's 0.0066721560433506966 task and 0.003326102625578642 recon and 5.379683494567871 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010754202688112856\n",
      "\n",
      "Total loss: 6.5478196144104:\n",
      "5.017917156219482 control,\n",
      "0.41403767466545105 lrg,\n",
      "0.4420958459377289 udg,\n",
      "0.34226515889167786 lra,\n",
      "0.3315039277076721 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.9467225265502925\n",
      "\n",
      "Total loss: 0.009607821702957153; that's 0.005709659308195114 task and 0.003207047004252672 recon and 3.4555771350860596 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010434541022405028\n",
      "\n",
      "Total loss: 4.681881427764893:\n",
      "3.128753185272217 control,\n",
      "0.39933672547340393 lrg,\n",
      "0.4475122392177582 udg,\n",
      "0.33174851536750793 lra,\n",
      "0.37453073263168335 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.8739040565490725\n",
      "\n",
      "Total loss: 4.738065242767334:\n",
      "3.2229185104370117 control,\n",
      "0.3698354661464691 lrg,\n",
      "0.4561629593372345 udg,\n",
      "0.32735535502433777 lra,\n",
      "0.3617928922176361 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.600803232192993\n",
      "\n",
      "Total loss: 0.009956499561667442; that's 0.006018355954438448 task and 0.003249227534979582 recon and 3.4445815086364746 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010532988123595715\n",
      "\n",
      "Total loss: 0.010986469686031342; that's 0.006665273569524288 task and 0.0033213903661817312 recon and 4.999029159545898 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010565734058618546\n",
      "\n",
      "Total loss: 6.330911636352539:\n",
      "4.679105281829834 control,\n",
      "0.438687264919281 lrg,\n",
      "0.4671274721622467 udg,\n",
      "0.3545723855495453 lra,\n",
      "0.39141955971717834 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 6.013108582496643\n",
      "\n",
      "Total loss: 0.010467899031937122; that's 0.006175816524773836 task and 0.0033027403987944126 recon and 4.946710586547852 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010310339322313667\n",
      "\n",
      "Total loss: 6.333463191986084:\n",
      "4.653632640838623 control,\n",
      "0.45340874791145325 lrg,\n",
      "0.47837942838668823 udg,\n",
      "0.36808156967163086 lra,\n",
      "0.3799610137939453 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.18181088924408\n",
      "\n",
      "Total loss: 0.012130494229495525; that's 0.007508566603064537 task and 0.003684977302327752 recon and 4.684752464294434 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010880034202709794\n",
      "\n",
      "Total loss: 5.986055850982666:\n",
      "4.3471784591674805 control,\n",
      "0.4632546901702881 lrg,\n",
      "0.43536341190338135 udg,\n",
      "0.3691444993019104 lra,\n",
      "0.3711148202419281 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.363436734676361\n",
      "\n",
      "Total loss: 4.9533185958862305:\n",
      "3.386789321899414 control,\n",
      "0.45109695196151733 lrg,\n",
      "0.4082599878311157 udg,\n",
      "0.368486613035202 lra,\n",
      "0.3386858403682709 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.868146266937256\n",
      "\n",
      "Total loss: 0.010830153711140156; that's 0.006855181884020567 task and 0.003267022781074047 recon and 3.5397469997406006 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010793833248317241\n",
      "\n",
      "Total loss: 4.092531204223633:\n",
      "2.4752516746520996 control,\n",
      "0.42937085032463074 lrg,\n",
      "0.48021748661994934 udg,\n",
      "0.34533748030662537 lra,\n",
      "0.3623538911342621 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.562221331596374\n",
      "\n",
      "Total loss: 0.009227828122675419; that's 0.005489884410053492 task and 0.003175031393766403 recon and 2.8145642280578613 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010272004287689923\n",
      "\n",
      "Total loss: 6.29543399810791:\n",
      "4.764141082763672 control,\n",
      "0.3808876574039459 lrg,\n",
      "0.4580436646938324 udg,\n",
      "0.3544979691505432 lra,\n",
      "0.33786410093307495 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.617352843284607\n",
      "\n",
      "Total loss: 0.009592194110155106; that's 0.005613293964415789 task and 0.0029725481290370226 recon and 5.031761169433594 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010429859617725015\n",
      "\n",
      "Total loss: 0.010502111166715622; that's 0.006452631205320358 task and 0.003080114023759961 recon and 4.84683084487915 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01042965498752892\n",
      "\n",
      "Total loss: 6.115790367126465:\n",
      "4.5829973220825195 control,\n",
      "0.3999350965023041 lrg,\n",
      "0.4755030870437622 udg,\n",
      "0.3018922209739685 lra,\n",
      "0.35546258091926575 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.80997079372406\n",
      "\n",
      "Total loss: 0.010732796974480152; that's 0.006974000483751297 task and 0.0030029884073883295 recon and 3.7790422439575195 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010412453496828676\n",
      "\n",
      "Total loss: 5.028768539428711:\n",
      "3.454252243041992 control,\n",
      "0.4134294092655182 lrg,\n",
      "0.47122249007225037 udg,\n",
      "0.3494674265384674 lra,\n",
      "0.3403967618942261 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.937512340545655\n",
      "\n",
      "Total loss: 5.726497173309326:\n",
      "4.135629653930664 control,\n",
      "0.39617326855659485 lrg,\n",
      "0.4293423891067505 udg,\n",
      "0.3598233163356781 lra,\n",
      "0.40552836656570435 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.827081570625305\n",
      "\n",
      "Total loss: 0.011175066232681274; that's 0.0067370873875916 task and 0.003553097601979971 recon and 4.424407958984375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010328491320833563\n",
      "\n",
      "Total loss: 0.01040029339492321; that's 0.006500727962702513 task and 0.0031923027709126472 recon and 3.53631591796875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010386444581672549\n",
      "\n",
      "Total loss: 4.787629127502441:\n",
      "3.2088329792022705 control,\n",
      "0.4082931876182556 lrg,\n",
      "0.46503299474716187 udg,\n",
      "0.3425818085670471 lra,\n",
      "0.362888365983963 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.918721981048584\n",
      "\n",
      "Total loss: 0.010602233931422234; that's 0.006493769120424986 task and 0.003147771814838052 recon and 4.803465843200684 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010166334453970194\n",
      "\n",
      "Total loss: 6.004988670349121:\n",
      "4.413282871246338 control,\n",
      "0.4121878445148468 lrg,\n",
      "0.4339195787906647 udg,\n",
      "0.3691321015357971 lra,\n",
      "0.3764660954475403 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.924166431427002\n",
      "\n",
      "Total loss: 0.011206157505512238; that's 0.0069151571951806545 task and 0.0033991080708801746 recon and 4.45945930480957 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010413629813119768\n",
      "\n",
      "Total loss: 5.629371643066406:\n",
      "4.140255928039551 control,\n",
      "0.3636395335197449 lrg,\n",
      "0.41855305433273315 udg,\n",
      "0.35547518730163574 lra,\n",
      "0.3514482378959656 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.395175089836121\n",
      "\n",
      "Total loss: 0.01062585785984993; that's 0.006385427433997393 task and 0.003172887023538351 recon and 5.337719440460205 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010470102010294795\n",
      "\n",
      "Total loss: 6.483113765716553:\n",
      "4.990082740783691 control,\n",
      "0.382742315530777 lrg,\n",
      "0.42208677530288696 udg,\n",
      "0.35566526651382446 lra,\n",
      "0.3325366973876953 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.916182374954223\n",
      "\n",
      "Total loss: 0.009922363795340061; that's 0.006049634423106909 task and 0.0030523177701979876 recon and 4.1020588874816895 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010306654842570423\n",
      "\n",
      "Total loss: 5.2988715171813965:\n",
      "3.764371871948242 control,\n",
      "0.3967697322368622 lrg,\n",
      "0.4412696957588196 udg,\n",
      "0.33069881796836853 lra,\n",
      "0.36576133966445923 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.503137044906616\n",
      "\n",
      "Total loss: 5.786149024963379:\n",
      "4.229930400848389 control,\n",
      "0.4134191870689392 lrg,\n",
      "0.4605535864830017 udg,\n",
      "0.3082031309604645 lra,\n",
      "0.37404265999794006 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.630836305618286\n",
      "\n",
      "Total loss: 0.010268328711390495; that's 0.006274915300309658 task and 0.0030835906509310007 recon and 4.549116134643555 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010332357231527567\n",
      "\n",
      "Total loss: 6.103792667388916:\n",
      "4.604207515716553 control,\n",
      "0.41275832056999207 lrg,\n",
      "0.43436750769615173 udg,\n",
      "0.3352150321006775 lra,\n",
      "0.3172440826892853 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.983750932216644\n",
      "\n",
      "Total loss: 0.009692382998764515; that's 0.005715650040656328 task and 0.0029959790408611298 recon and 4.903770446777344 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0102399084251374\n",
      "\n",
      "Total loss: 5.363034725189209:\n",
      "3.794062852859497 control,\n",
      "0.4016551971435547 lrg,\n",
      "0.48311007022857666 udg,\n",
      "0.3309948146343231 lra,\n",
      "0.3532121479511261 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.963336257934571\n",
      "\n",
      "Total loss: 0.010179128497838974; that's 0.0063042719848454 task and 0.003055181121453643 recon and 4.098377704620361 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010292760683223606\n",
      "\n",
      "Total loss: 6.171119689941406:\n",
      "4.617160797119141 control,\n",
      "0.4037002623081207 lrg,\n",
      "0.49305886030197144 udg,\n",
      "0.3368910551071167 lra,\n",
      "0.3203088045120239 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.8170460510253905\n",
      "\n",
      "Total loss: 0.01000419445335865; that's 0.005879614967852831 task and 0.003146268893033266 recon and 4.891552448272705 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010485209980979562\n",
      "\n",
      "Total loss: 5.745234489440918:\n",
      "4.158905029296875 control,\n",
      "0.4628102481365204 lrg,\n",
      "0.4245816469192505 udg,\n",
      "0.3354276120662689 lra,\n",
      "0.36351022124290466 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.350808765888214\n",
      "\n",
      "Total loss: 0.010777599178254604; that's 0.006687316577881575 task and 0.0031883602496236563 recon and 4.509612083435059 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010173264695331453\n",
      "\n",
      "Total loss: 0.00968053936958313; that's 0.0056176199577748775 task and 0.0032703743781894445 recon and 3.962726593017578 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010232211193069815\n",
      "\n",
      "Total loss: 5.220327854156494:\n",
      "3.6439108848571777 control,\n",
      "0.45171016454696655 lrg,\n",
      "0.4676484167575836 udg,\n",
      "0.3255406618118286 lra,\n",
      "0.3315178155899048 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.503544311523438\n",
      "\n",
      "Total loss: 4.514893531799316:\n",
      "3.025956392288208 control,\n",
      "0.3835063576698303 lrg,\n",
      "0.43780434131622314 udg,\n",
      "0.3229508101940155 lra,\n",
      "0.34467536211013794 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.3208884382247925\n",
      "\n",
      "Total loss: 0.010186451487243176; that's 0.0065858070738613605 task and 0.0029448161367326975 recon and 3.2791409492492676 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010311324810609222\n",
      "\n",
      "Total loss: 0.010639797896146774; that's 0.0068599930964410305 task and 0.003140027401968837 recon and 3.19888973236084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010149170374497772\n",
      "\n",
      "Total loss: 4.484952449798584:\n",
      "2.8672473430633545 control,\n",
      "0.4184414744377136 lrg,\n",
      "0.4818917214870453 udg,\n",
      "0.3629542887210846 lra,\n",
      "0.354417622089386 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.808531365394592\n",
      "\n",
      "Total loss: 0.011180168949067593; that's 0.006463089492172003 task and 0.00353431049734354 recon and 5.913848876953125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01025632156059146\n",
      "\n",
      "Total loss: 7.07610559463501:\n",
      "5.57246732711792 control,\n",
      "0.3914874494075775 lrg,\n",
      "0.45362377166748047 udg,\n",
      "0.3451389968395233 lra,\n",
      "0.3133878707885742 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.607519392967224\n",
      "\n",
      "Total loss: 0.009338434785604477; that's 0.00575492437928915 task and 0.0029512003529816866 recon and 3.1615498065948486 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010094307092949749\n",
      "\n",
      "Total loss: 4.3920512199401855:\n",
      "2.8028314113616943 control,\n",
      "0.42615243792533875 lrg,\n",
      "0.44901397824287415 udg,\n",
      "0.3576097786426544 lra,\n",
      "0.3564434051513672 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.001705675125122\n",
      "\n",
      "Total loss: 0.010096246376633644; that's 0.006496423855423927 task and 0.0030660706106573343 recon and 2.668762445449829 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01008701446466148\n",
      "\n",
      "Total loss: 4.068571090698242:\n",
      "2.3817965984344482 control,\n",
      "0.4698266088962555 lrg,\n",
      "0.4752362370491028 udg,\n",
      "0.3786338269710541 lra,\n",
      "0.3630777597427368 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.074658443927765\n",
      "\n",
      "Total loss: 0.010024726390838623; that's 0.006284278817474842 task and 0.003039437346160412 recon and 3.5050528049468994 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010060317460447549\n",
      "\n",
      "Total loss: 4.718558311462402:\n",
      "3.1006319522857666 control,\n",
      "0.44907209277153015 lrg,\n",
      "0.47829943895339966 udg,\n",
      "0.3358346223831177 lra,\n",
      "0.35472017526626587 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.170678749084472\n",
      "\n",
      "Total loss: 4.7663445472717285:\n",
      "3.2079875469207764 control,\n",
      "0.4389810860157013 lrg,\n",
      "0.4304467737674713 udg,\n",
      "0.33584272861480713 lra,\n",
      "0.3530866503715515 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.0702972412109375\n",
      "\n",
      "Total loss: 0.00946908537298441; that's 0.005890092812478542 task and 0.002884679939597845 recon and 3.471564292907715 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01015601247549057\n",
      "\n",
      "Total loss: 5.351723670959473:\n",
      "3.7032389640808105 control,\n",
      "0.4487670063972473 lrg,\n",
      "0.47293660044670105 udg,\n",
      "0.3522564172744751 lra,\n",
      "0.37452447414398193 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.441245985031128\n",
      "\n",
      "Total loss: 0.010304977186024189; that's 0.006296955049037933 task and 0.003203641390427947 recon and 4.021902561187744 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009961758302524685\n",
      "\n",
      "Total loss: 0.009447108022868633; that's 0.0055473274551332 task and 0.003115918720141053 recon and 3.9193081855773926 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00993206369690597\n",
      "\n",
      "Total loss: 5.1359758377075195:\n",
      "3.5706305503845215 control,\n",
      "0.4284398555755615 lrg,\n",
      "0.4554862082004547 udg,\n",
      "0.3178274631500244 lra,\n",
      "0.3635919988155365 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.985742998123169\n",
      "\n",
      "Total loss: 3.781888484954834:\n",
      "2.2649974822998047 control,\n",
      "0.4173603057861328 lrg,\n",
      "0.404141366481781 udg,\n",
      "0.3635711669921875 lra,\n",
      "0.3318180739879608 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.9020050072669985\n",
      "\n",
      "Total loss: 0.009297101758420467; that's 0.005728990770876408 task and 0.003062095958739519 recon and 2.530071496963501 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00975268505513668\n",
      "\n",
      "Total loss: 0.009174257516860962; that's 0.005593837704509497 task and 0.0030179647728800774 recon and 2.8122799396514893 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00987062112428248\n",
      "\n",
      "Total loss: 4.1097517013549805:\n",
      "2.4883694648742676 control,\n",
      "0.4536137580871582 lrg,\n",
      "0.4332263469696045 udg,\n",
      "0.3548228144645691 lra,\n",
      "0.37971943616867065 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 3.9952275466918947\n",
      "\n",
      "Total loss: 6.0376482009887695:\n",
      "4.444685935974121 control,\n",
      "0.43685880303382874 lrg,\n",
      "0.46719107031822205 udg,\n",
      "0.3452753722667694 lra,\n",
      "0.34363701939582825 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.519370660781861\n",
      "\n",
      "Total loss: 0.009932363405823708; that's 0.005802687257528305 task and 0.0031830337829887867 recon and 4.733214378356934 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010120317665860057\n",
      "\n",
      "Total loss: 0.009837648831307888; that's 0.006033789366483688 task and 0.0029362631030380726 recon and 4.337984561920166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.010203393157571555\n",
      "\n",
      "Total loss: 5.549554347991943:\n",
      "4.025383472442627 control,\n",
      "0.39870673418045044 lrg,\n",
      "0.43396180868148804 udg,\n",
      "0.34388694167137146 lra,\n",
      "0.34761518239974976 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.831406545639038\n",
      "\n",
      "Total loss: 5.809438228607178:\n",
      "4.29653787612915 control,\n",
      "0.3736797273159027 lrg,\n",
      "0.44739335775375366 udg,\n",
      "0.3378896415233612 lra,\n",
      "0.3539375364780426 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.918437061309814\n",
      "\n",
      "Total loss: 0.009404230862855911; that's 0.0055290404707193375 task and 0.002958400174975395 recon and 4.583951473236084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.01007342653349042\n",
      "\n",
      "Total loss: 4.183321475982666:\n",
      "2.5962209701538086 control,\n",
      "0.4681645929813385 lrg,\n",
      "0.4388274550437927 udg,\n",
      "0.3467128872871399 lra,\n",
      "0.3333953320980072 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.182581348419189\n",
      "\n",
      "Total loss: 0.009570598602294922; that's 0.0060647474601864815 task and 0.0029377879109233618 recon and 2.8403170108795166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00990651291795075\n",
      "\n",
      "Total loss: 4.18200159072876:\n",
      "2.5979726314544678 control,\n",
      "0.40268474817276 lrg,\n",
      "0.4793021082878113 udg,\n",
      "0.3424791395664215 lra,\n",
      "0.3595626950263977 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.275911128520965\n",
      "\n",
      "Total loss: 0.009847222827374935; that's 0.006201138254255056 task and 0.0030586475040763617 recon and 2.9371867179870605 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009908081954345107\n",
      "\n",
      "Total loss: 0.008837280794978142; that's 0.005383805371820927 task and 0.0028355035465210676 recon and 3.0898585319519043 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00980378800071776\n",
      "\n",
      "Total loss: 4.333212852478027:\n",
      "2.716914176940918 control,\n",
      "0.4294971525669098 lrg,\n",
      "0.4282306134700775 udg,\n",
      "0.38851526379585266 lra,\n",
      "0.3700556457042694 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.313126399517059\n",
      "\n",
      "Total loss: 0.009575746022164822; that's 0.005693248938769102 task and 0.003020135685801506 recon and 4.311803817749023 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009906483860686422\n",
      "\n",
      "Total loss: 5.447782516479492:\n",
      "3.9200119972229004 control,\n",
      "0.40763169527053833 lrg,\n",
      "0.43214407563209534 udg,\n",
      "0.3257153332233429 lra,\n",
      "0.3622789978981018 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.342173082828522\n",
      "\n",
      "Total loss: 4.937742710113525:\n",
      "3.4564297199249268 control,\n",
      "0.38614556193351746 lrg,\n",
      "0.4297407865524292 udg,\n",
      "0.33333510160446167 lra,\n",
      "0.33209192752838135 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.602676057815552\n",
      "\n",
      "Total loss: 0.00988114532083273; that's 0.0061602662317454815 task and 0.0029835954774171114 recon and 3.6864173412323 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009747850187122821\n",
      "\n",
      "Total loss: 5.118331432342529:\n",
      "3.49914288520813 control,\n",
      "0.4382938742637634 lrg,\n",
      "0.46261489391326904 udg,\n",
      "0.3577438294887543 lra,\n",
      "0.3605358898639679 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.213690092563629\n",
      "\n",
      "Total loss: 0.009864667430520058; that's 0.006170138716697693 task and 0.002936961594969034 recon and 3.7878360748291016 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00996087952516973\n",
      "\n",
      "Total loss: 0.008924322202801704; that's 0.005153045058250427 task and 0.002992408350110054 recon and 3.8943448066711426 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009745076429098845\n",
      "\n",
      "Total loss: 5.022864818572998:\n",
      "3.4988138675689697 control,\n",
      "0.3857743442058563 lrg,\n",
      "0.4265727698802948 udg,\n",
      "0.3449251055717468 lra,\n",
      "0.3667788505554199 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.945598955154419\n",
      "\n",
      "Total loss: 4.9467315673828125:\n",
      "3.4516735076904297 control,\n",
      "0.3847450613975525 lrg,\n",
      "0.42305421829223633 udg,\n",
      "0.34510713815689087 lra,\n",
      "0.342151403427124 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.280639095306396\n",
      "\n",
      "Total loss: 0.009496643207967281; that's 0.005725902039557695 task and 0.0030108890496194363 recon and 3.799260139465332 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009828994292765856\n",
      "\n",
      "Total loss: 0.009343677200376987; that's 0.005507023073732853 task and 0.0031705466099083424 recon and 3.330533504486084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009565459610894323\n",
      "\n",
      "Total loss: 4.575263977050781:\n",
      "2.98740553855896 control,\n",
      "0.43755173683166504 lrg,\n",
      "0.48837950825691223 udg,\n",
      "0.3388948142528534 lra,\n",
      "0.3230323791503906 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.092349801063538\n",
      "\n",
      "Total loss: 4.325874328613281:\n",
      "2.7001290321350098 control,\n",
      "0.46149200201034546 lrg,\n",
      "0.47525888681411743 udg,\n",
      "0.35261696577072144 lra,\n",
      "0.33637720346450806 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.837477645874023\n",
      "\n",
      "Total loss: 0.009783062152564526; that's 0.00615266477689147 task and 0.0030355460476130247 recon and 2.974256992340088 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009616581359878182\n",
      "\n",
      "Total loss: 5.054950714111328:\n",
      "3.4074254035949707 control,\n",
      "0.4057995080947876 lrg,\n",
      "0.5081708431243896 udg,\n",
      "0.37176698446273804 lra,\n",
      "0.3617877960205078 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.779491386413574\n",
      "\n",
      "Total loss: 0.010298114269971848; that's 0.006433191709220409 task and 0.0031284175347536802 recon and 3.682525396347046 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009577077981084585\n",
      "\n",
      "Total loss: 0.010117738507688046; that's 0.006493972148746252 task and 0.0029740750323981047 recon and 3.2484586238861084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009444751525297761\n",
      "\n",
      "Total loss: 4.317605495452881:\n",
      "2.7702748775482178 control,\n",
      "0.40234488248825073 lrg,\n",
      "0.4664476215839386 udg,\n",
      "0.35892021656036377 lra,\n",
      "0.3196179270744324 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.158447387218476\n",
      "\n",
      "Total loss: 0.010405213572084904; that's 0.006814707536250353 task and 0.0028460375033318996 recon and 3.722341537475586 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009627611646428703\n",
      "\n",
      "Total loss: 4.950515270233154:\n",
      "3.29781174659729 control,\n",
      "0.4276405870914459 lrg,\n",
      "0.49862056970596313 udg,\n",
      "0.36316734552383423 lra,\n",
      "0.3632749617099762 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.966747779846191\n",
      "\n",
      "Total loss: 0.009870724752545357; that's 0.006038842257112265 task and 0.003026016987860203 recon and 4.029329299926758 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009600865682587027\n",
      "\n",
      "Total loss: 5.297504425048828:\n",
      "3.651479482650757 control,\n",
      "0.4186827540397644 lrg,\n",
      "0.5038866400718689 udg,\n",
      "0.3503655195236206 lra,\n",
      "0.37308982014656067 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.86082102060318\n",
      "\n",
      "Total loss: 0.009400789625942707; that's 0.005995193962007761 task and 0.0027243560180068016 recon and 3.406198024749756 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009663982382044196\n",
      "\n",
      "Total loss: 4.692910671234131:\n",
      "3.0744478702545166 control,\n",
      "0.433180034160614 lrg,\n",
      "0.4624364674091339 udg,\n",
      "0.3446890711784363 lra,\n",
      "0.37815701961517334 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.757073786258697\n",
      "\n",
      "Total loss: 0.009801147505640984; that's 0.0062288870103657246 task and 0.002795905340462923 recon and 3.881774425506592 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009571493873372673\n",
      "\n",
      "Total loss: 5.187156677246094:\n",
      "3.5908045768737793 control,\n",
      "0.4371147155761719 lrg,\n",
      "0.444681853055954 udg,\n",
      "0.377736896276474 lra,\n",
      "0.336818665266037 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.813589820861816\n",
      "\n",
      "Total loss: 5.804021835327148:\n",
      "4.290334701538086 control,\n",
      "0.3858431577682495 lrg,\n",
      "0.4507761001586914 udg,\n",
      "0.3391636610031128 lra,\n",
      "0.337904155254364 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.7868612456321715\n",
      "\n",
      "Total loss: 0.008954804390668869; that's 0.00534781301394105 task and 0.0026933990884572268 recon and 4.567959308624268 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009704273212701082\n",
      "\n",
      "Total loss: 0.009984925389289856; that's 0.00630944175645709 task and 0.0028134232852607965 recon and 4.310302257537842 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009584715384989976\n",
      "\n",
      "Total loss: 5.453476428985596:\n",
      "3.9038074016571045 control,\n",
      "0.43762052059173584 lrg,\n",
      "0.46876174211502075 udg,\n",
      "0.32040053606033325 lra,\n",
      "0.3228861391544342 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.526278095245361\n",
      "\n",
      "Total loss: 0.009881503880023956; that's 0.006386701017618179 task and 0.0028406900819391012 recon and 3.2705628871917725 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009588598879054189\n",
      "\n",
      "Total loss: 4.534915924072266:\n",
      "2.9699318408966064 control,\n",
      "0.3951948881149292 lrg,\n",
      "0.4595094919204712 udg,\n",
      "0.38151416182518005 lra,\n",
      "0.3287660777568817 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.630099339485168\n",
      "\n",
      "Total loss: 0.009437953121960163; that's 0.005609092302620411 task and 0.003134117228910327 recon and 3.4737179279327393 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009503382444381713\n",
      "\n",
      "Total loss: 4.728254318237305:\n",
      "3.177274465560913 control,\n",
      "0.4308384656906128 lrg,\n",
      "0.43273407220840454 udg,\n",
      "0.3497972786426544 lra,\n",
      "0.33761027455329895 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.368284785747528\n",
      "\n",
      "Total loss: 0.009170712903141975; that's 0.005544102750718594 task and 0.0028098812326788902 recon and 4.083643436431885 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009487875504419208\n",
      "\n",
      "Total loss: 5.268904209136963:\n",
      "3.766453742980957 control,\n",
      "0.36523666977882385 lrg,\n",
      "0.48002928495407104 udg,\n",
      "0.32574284076690674 lra,\n",
      "0.3314419388771057 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.753574254512787\n",
      "\n",
      "Total loss: 4.4857707023620605:\n",
      "2.9132187366485596 control,\n",
      "0.4115525782108307 lrg,\n",
      "0.4940014183521271 udg,\n",
      "0.3206320106983185 lra,\n",
      "0.346365749835968 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.5655053520202635\n",
      "\n",
      "Total loss: 0.00919936690479517; that's 0.005924636032432318 task and 0.0026260993909090757 recon and 3.2431588172912598 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009463387094438076\n",
      "\n",
      "Total loss: 0.009742727503180504; that's 0.006017512176185846 task and 0.0026845342945307493 recon and 5.203406810760498 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00939024168998003\n",
      "\n",
      "Total loss: 6.509916305541992:\n",
      "4.907289505004883 control,\n",
      "0.4015633165836334 lrg,\n",
      "0.4870598614215851 udg,\n",
      "0.35146960616111755 lra,\n",
      "0.36253413558006287 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.205258440971375\n",
      "\n",
      "Total loss: 0.009671410545706749; that's 0.006178513169288635 task and 0.0029357520397752523 recon and 2.785724639892578 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009275391492992639\n",
      "\n",
      "Total loss: 3.9637868404388428:\n",
      "2.408235549926758 control,\n",
      "0.4317043125629425 lrg,\n",
      "0.4307825267314911 udg,\n",
      "0.34997501969337463 lra,\n",
      "0.34308934211730957 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.598128654956818\n",
      "\n",
      "Total loss: 0.009867582470178604; that's 0.006284571718424559 task and 0.002760029397904873 recon and 4.114911079406738 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009303627908229828\n",
      "\n",
      "Total loss: 5.297923564910889:\n",
      "3.7558908462524414 control,\n",
      "0.4293402135372162 lrg,\n",
      "0.4386792480945587 udg,\n",
      "0.3232116997241974 lra,\n",
      "0.3508016765117645 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.227388064861298\n",
      "\n",
      "Total loss: 4.814938068389893:\n",
      "3.282775640487671 control,\n",
      "0.4055632948875427 lrg,\n",
      "0.4748595654964447 udg,\n",
      "0.3197970688343048 lra,\n",
      "0.33194273710250854 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.722905831336975\n",
      "\n",
      "Total loss: 0.008341392502188683; that's 0.005033231806010008 task and 0.002588854171335697 recon and 3.596534490585327 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009364785430952906\n",
      "\n",
      "Total loss: 5.823303699493408:\n",
      "4.357750415802002 control,\n",
      "0.36688894033432007 lrg,\n",
      "0.415881484746933 udg,\n",
      "0.32866913080215454 lra,\n",
      "0.35411351919174194 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.886388788223266\n",
      "\n",
      "Total loss: 0.009546449407935143; that's 0.006018354557454586 task and 0.002591557102277875 recon and 4.682689189910889 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00948594049550593\n",
      "\n",
      "Total loss: 7.320098400115967:\n",
      "5.72652530670166 control,\n",
      "0.4705076217651367 lrg,\n",
      "0.4255922734737396 udg,\n",
      "0.32962173223495483 lra,\n",
      "0.36785146594047546 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.963301267623901\n",
      "\n",
      "Total loss: 0.009505938738584518; that's 0.0056605832651257515 task and 0.0026435749605298042 recon and 6.0089030265808105 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009311989070847631\n",
      "\n",
      "Total loss: 4.4375715255737305:\n",
      "2.877936363220215 control,\n",
      "0.3956468403339386 lrg,\n",
      "0.48023903369903564 udg,\n",
      "0.3458307981491089 lra,\n",
      "0.3379182815551758 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.24440719127655\n",
      "\n",
      "Total loss: 0.008451459929347038; that's 0.005382869392633438 task and 0.0024379552341997623 recon and 3.153179168701172 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009180551571771502\n",
      "\n",
      "Total loss: 0.009353753179311752; that's 0.005962719209492207 task and 0.0025942481588572264 recon and 3.9839298725128174 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009147205092012882\n",
      "\n",
      "Total loss: 5.307705402374268:\n",
      "3.703169584274292 control,\n",
      "0.4354110360145569 lrg,\n",
      "0.42981433868408203 udg,\n",
      "0.3837684988975525 lra,\n",
      "0.3555417060852051 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.086137595176697\n",
      "\n",
      "Total loss: 0.008213241584599018; that's 0.004969226196408272 task and 0.002401734236627817 recon and 4.211406707763672 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009127996498718857\n",
      "\n",
      "Total loss: 5.483767509460449:\n",
      "3.8806869983673096 control,\n",
      "0.4329979717731476 lrg,\n",
      "0.4765689969062805 udg,\n",
      "0.34006303548812866 lra,\n",
      "0.3534504771232605 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.039324383735657\n",
      "\n",
      "Total loss: 4.434721946716309:\n",
      "2.88966965675354 control,\n",
      "0.44276028871536255 lrg,\n",
      "0.4032030999660492 udg,\n",
      "0.346214234828949 lra,\n",
      "0.3528745770454407 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.178548951148986\n",
      "\n",
      "Total loss: 0.008377911522984505; that's 0.0050147781148552895 task and 0.0027351805474609137 recon and 3.1397628784179688 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00898660003207624\n",
      "\n",
      "Total loss: 0.009625345468521118; that's 0.006156043615192175 task and 0.002710598986595869 recon and 3.7935163974761963 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00908351233229041\n",
      "\n",
      "Total loss: 4.947054862976074:\n",
      "3.4291391372680664 control,\n",
      "0.39841365814208984 lrg,\n",
      "0.42468884587287903 udg,\n",
      "0.3424625098705292 lra,\n",
      "0.35235077142715454 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.846756281852723\n",
      "\n",
      "Total loss: 0.00859601330012083; that's 0.005167499650269747 task and 0.0025851947721093893 recon and 4.2165937423706055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.009258717047050596\n",
      "\n",
      "Total loss: 5.506704807281494:\n",
      "3.907045841217041 control,\n",
      "0.42790475487709045 lrg,\n",
      "0.4645993709564209 udg,\n",
      "0.33141136169433594 lra,\n",
      "0.37574347853660583 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.085683908462524\n",
      "\n",
      "Total loss: 0.008700930513441563; that's 0.0054496899247169495 task and 0.0025628386065363884 recon and 3.442009449005127 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008971003089100123\n",
      "\n",
      "Total loss: 4.591770172119141:\n",
      "3.0624136924743652 control,\n",
      "0.42658814787864685 lrg,\n",
      "0.42154979705810547 udg,\n",
      "0.35119304060935974 lra,\n",
      "0.33002567291259766 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.81869971036911\n",
      "\n",
      "Total loss: 0.009163966402411461; that's 0.005804805550724268 task and 0.002653492381796241 recon and 3.5283446311950684 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008934660437516869\n",
      "\n",
      "Total loss: 4.6606950759887695:\n",
      "3.085968255996704 control,\n",
      "0.4249471127986908 lrg,\n",
      "0.44440948963165283 udg,\n",
      "0.3547898232936859 lra,\n",
      "0.35058072209358215 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.610308451652527\n",
      "\n",
      "Total loss: 4.522586822509766:\n",
      "2.8513433933258057 control,\n",
      "0.4881722033023834 lrg,\n",
      "0.4681224524974823 udg,\n",
      "0.3565397262573242 lra,\n",
      "0.35840871930122375 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.533076963424683\n",
      "\n",
      "Total loss: 0.008260583505034447; that's 0.005322941578924656 task and 0.002302472712472081 recon and 3.1758480072021484 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008753918167203665\n",
      "\n",
      "Total loss: 4.746224403381348:\n",
      "3.2045938968658447 control,\n",
      "0.41724541783332825 lrg,\n",
      "0.4545239806175232 udg,\n",
      "0.33394891023635864 lra,\n",
      "0.3359123468399048 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.587532796859741\n",
      "\n",
      "Total loss: 0.008644024841487408; that's 0.005415222141891718 task and 0.002539000939577818 recon and 3.449009895324707 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008813533554784954\n",
      "\n",
      "Total loss: 0.010054025799036026; that's 0.006479342468082905 task and 0.0025016150902956724 recon and 5.3653411865234375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008938122428953648\n",
      "\n",
      "Total loss: 6.504306793212891:\n",
      "5.024753570556641 control,\n",
      "0.3814160227775574 lrg,\n",
      "0.4224936068058014 udg,\n",
      "0.33611413836479187 lra,\n",
      "0.3395300805568695 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.315562889575959\n",
      "\n",
      "Total loss: 0.008804104290902615; that's 0.005191256292164326 task and 0.0024855700321495533 recon and 5.6363911628723145 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00895268133841455\n",
      "\n",
      "Total loss: 6.9378790855407715:\n",
      "5.330272197723389 control,\n",
      "0.40686988830566406 lrg,\n",
      "0.48086392879486084 udg,\n",
      "0.33693739771842957 lra,\n",
      "0.3829355537891388 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 5.920919828414917\n",
      "\n",
      "Total loss: 4.485266208648682:\n",
      "2.890533208847046 control,\n",
      "0.45167574286460876 lrg,\n",
      "0.44182857871055603 udg,\n",
      "0.3614357113838196 lra,\n",
      "0.3397931456565857 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.849575476646423\n",
      "\n",
      "Total loss: 0.008649145253002644; that's 0.005570099223405123 task and 0.002432903740555048 recon and 3.2307095527648926 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00881491177715361\n",
      "\n",
      "Total loss: 4.876584529876709:\n",
      "3.301142692565918 control,\n",
      "0.41141942143440247 lrg,\n",
      "0.4471725523471832 udg,\n",
      "0.35560500621795654 lra,\n",
      "0.3612448275089264 uda\n",
      "\n",
      "\n",
      "Average total loss for task 1, last 100 batches: 4.5360065460205075\n",
      "\n",
      "Total loss: 0.008738242089748383; that's 0.005747538525611162 task and 0.0022668761666864157 recon and 3.6191399097442627 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.008715893202461302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_batches = 10000*100#6250*32\n",
    "\n",
    "for b in range(total_batches):\n",
    "    triplet, ind = rb.random_draw()\n",
    "    func, opt, batch_size = triplet\n",
    "    \n",
    "    batch_num = batches[ind]\n",
    "    batches[ind] += 1\n",
    "\n",
    "    #reset_model = True #default option; only transfer memory within the task files\n",
    "    reset_model = (b % 3 == 2)\n",
    "\n",
    "    printing = ((batch_num % 100) == 99)\n",
    "    full_results = func(batch_size, brain, optimizer=opt, batch_num=batch_num, compute_grad=True, random_order=True, model_eval=False, reset_model=reset_model, printing=printing, training=True)\n",
    "    L = full_results[0] # no need to look into the detailed loss report\n",
    "    total_losses[ind] += L\n",
    "\n",
    "    if printing: # if this is a significant batch\n",
    "        avg_loss = total_losses[ind] / 100\n",
    "        total_losses[ind] = 0\n",
    "        print(f\"Average total loss for task {ind}, last 100 batches: {avg_loss}\\n\")\n",
    "        \n",
    "        if avg_loss < curr_mins[ind]:\n",
    "            curr_mins[ind] = avg_loss\n",
    "            torch.save(brain.state_dict(), f\"brain_checkpoints/enhanced_brain_first_training_v2_batch{b + 1}.pth\")\n",
    "            \n",
    "    if b < 10:\n",
    "        print(f\"batch {b}, task {ind}, task batch_num {batch_num}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a9094-8dec-4a9c-92c2-4f7342e7345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: not even close on the results. Need several days (basically seems to be relearning task1; taskQA basically\n",
    "# completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0519dcb-f815-45e6-a46f-621620263fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerunning on top of the last results, with many more batches (so several days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb7c96-0ce6-4e96-99a6-0a2cddfd5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates: add sampling weights; add batch_num to print statement; split these two optimizers and optimize them separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa482e-91be-4bae-ac3c-f75ae99e23c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
