{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f5bd94-74fb-4588-b47b-273035eb2345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from control_framework import *\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "from mem_canvas_use_framework import *\n",
    "\n",
    "from temp_recorder import *\n",
    "\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "#device = torch.device('cuda:0')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6823f8c1-608a-4865-aeca-1458b0610761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4335c011-7512-4fde-bf66-16bdb5591fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9d6021b3b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4245931c-72c7-470f-9e6e-2f6de6e1c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_display(torch_img):\n",
    "    clean = torch_img.detach().cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c25d90-1bdd-46b4-ae86-a6e8170070d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = EnhancedAgentBrain()\n",
    "brain.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_batch10000.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_v2_batch160799.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v1_batch16600.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v2_batch55900.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v1_batch1199.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v2_batch24800.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v3_batch155466.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v4_batch399.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v5_batch133.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_v1_batch14250.pth'\n",
    "fname = 'brain_checkpoints/enhanced_brain_canvas_use_v2_batch29398.pth'\n",
    "\n",
    "# A little extra code to avoid weird error\n",
    "#brain.memory.remember(torch.randn(16, 1, 768).to(device))\n",
    "brain.memory.remember(torch.randn(8, 1, 768).to(device))\n",
    "\n",
    "brain.load_state_dict(torch.load(fname, weights_only=True, map_location=device))\n",
    "brain.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6a4389-e113-4dc7-bf96-7538570644e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optimizer = optim.Adam(brain.parameters(), lr=0.00001, eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c522ad35-e749-4b70-a282-f4489bd4069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should possibly also include mem_enc? Should just be gen_optimizer? \n",
    "# ONLY use this in sessions where this is the only optimizer.\n",
    "# General optimizer gets messed up if this is used\n",
    "text_optimizer = optim.Adam(list(brain.text_enc.parameters()) + list(brain.text_dec.parameters()), lr=0.00001, eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dedeb05-aeef-4cc0-8c32-41e4c74f92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful to randomize the order in which the tasks are trained\n",
    "class ReusableBuffer:\n",
    "    def __init__(self, L, repetitions):\n",
    "        self.L = []\n",
    "        self.true_inds = []\n",
    "        for i in range(len(L)):\n",
    "            for j in range(repetitions[i]):\n",
    "                self.L.append(L[i])\n",
    "                self.true_inds.append(i)\n",
    "        self.inds = list(range(len(self.L))) # could be longer or shorter than input L\n",
    "\n",
    "    def draw(self, ind):\n",
    "        return self.L[ind]\n",
    "\n",
    "    def random_draw(self):\n",
    "        ind_ind = random.randint(0, len(self.inds)-1)\n",
    "        ind = self.inds[ind_ind]\n",
    "        if ind_ind == (len(self.inds) - 1):\n",
    "            self.inds = self.inds[:-1]\n",
    "        else:\n",
    "            self.inds = self.inds[:ind_ind] + self.inds[ind_ind + 1:]\n",
    "        if len(self.inds) == 0:\n",
    "            self.inds = list(range(len(self.L)))\n",
    "        return self.L[ind], ind, self.true_inds[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8113bf0-e27a-4964-b993-1511284e05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for first task (and really anywhere I want to not reset between tasks)\n",
    "# make sure the batch size matches\n",
    "# add further functions in the firs list, and add their repetition number to the second list\n",
    "rb = ReusableBuffer([(arrow_task_batch, gen_optimizer, 8), \\\n",
    "                     (qa_task_batch, gen_optimizer, 8), \\\n",
    "                     (control_batch, gen_optimizer, 8), \n",
    "                     (mem_canvas_batch, gen_optimizer, 8)], \\\n",
    "                    [1, 0, 1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d0bf3cd-1207-4726-8983-3708c97ba125",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fcade85-fe40-4a68-b137-4c94c737614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_mins = [1000.0, 1000.0, 1000.0, 1.0e6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea6fc04a-8056-41bd-85c0-7e60970a13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_losses = [0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88167a4b-dd8d-43e6-b4ae-8f77c51adaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e62f64af-1ff3-4f80-804b-17b8488af2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# I'll find the place that causes the 'non in-place resize later; for now, I don't want to clutter the results'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c1d1940-ba13-4da2-bb5f-b1af6d45d7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, task 2, task batch_num 0\n",
      "\n",
      "batch 1, task 3, task batch_num 0\n",
      "\n",
      "batch 2, task 3, task batch_num 1\n",
      "\n",
      "batch 3, task 0, task batch_num 0\n",
      "\n",
      "batch 4, task 3, task batch_num 2\n",
      "\n",
      "batch 5, task 3, task batch_num 3\n",
      "\n",
      "batch 6, task 3, task batch_num 4\n",
      "\n",
      "batch 7, task 3, task batch_num 5\n",
      "\n",
      "batch 8, task 3, task batch_num 6\n",
      "\n",
      "batch 9, task 2, task batch_num 1\n",
      "\n",
      "Total loss: 0.009699538350105286; that's 0.006230611819773912 for recalled reconstructions, 0.0002210933162132278 for normal images, and 3.247833490371704 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009769771252758802\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00852111354470253; that's 0.005644555203616619 for recalled reconstructions, 0.0002334164164494723 for normal images, and 2.643141984939575 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009067352712154388\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008631343953311443; that's 0.004861024674028158 for recalled reconstructions, 0.00021796564396936446 for normal images, and 3.5523533821105957 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008527821195311844\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0017892122268676758; that's 0.0009262810926884413 task and 0.00022157792409416288 recon and 3.20676589012146 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022925079660490156\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010562917217612267; that's 0.007514345459640026 for recalled reconstructions, 0.0002302006323589012 for normal images, and 2.8183705806732178 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009107831278815865\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0033908491022884846; that's 2.8163411617279053 text and 0.000574507808778435 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003995465352199972\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01078135147690773; that's 0.006229782477021217 for recalled reconstructions, 0.00022316156537272036 for normal images, and 4.3284077644348145 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009698352986015379\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.013719467446208; that's 0.009481062181293964 for recalled reconstructions, 0.00021649760310538113 for normal images, and 4.021906852722168 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009898790423758328\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012030329555273056; that's 0.0068603986874222755 for recalled reconstructions, 0.00022858860029373318 for normal images, and 4.941341876983643 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009598497522529215\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0016926132375374436; that's 0.0009498217841610312 task and 0.00023721650359220803 recon and 2.5278749465942383 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002230732886819169\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011270126327872276; that's 0.0070424857549369335 for recalled reconstructions, 0.00023228248755913228 for normal images, and 3.9953572750091553 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009952402291819453\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0027538579888641834; that's 2.2127506732940674 text and 0.0005411073798313737 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003506066103000194\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009954201988875866; that's 0.006074152886867523 for recalled reconstructions, 0.0002200187009293586 for normal images, and 3.6600303649902344 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00976834775879979\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007237064652144909; that's 0.003443037159740925 for recalled reconstructions, 0.00023057646467350423 for normal images, and 3.5634512901306152 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009672793024219573\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007983059622347355; that's 0.004110212903469801 for recalled reconstructions, 0.00021870895579922944 for normal images, and 3.654137372970581 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00969440930057317\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0018567077349871397; that's 0.0009418277768418193 task and 0.0002214238775195554 recon and 3.4672799110412598 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002171481732511893\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0034096157178282738; that's 2.9641358852386475 text and 0.00044547984725795686 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0030432977550663054\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007527656387537718; that's 0.004095727112144232 for recalled reconstructions, 0.00022168495343066752 for normal images, and 3.2102441787719727 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00959372748620808\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010735680349171162; that's 0.005600016564130783 for recalled reconstructions, 0.0002194161934312433 for normal images, and 4.916247367858887 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009506292836740614\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010267655365169048; that's 0.0054373973980546 for recalled reconstructions, 0.00023403481463901699 for normal images, and 4.596222877502441 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009458990329876541\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00864950381219387; that's 0.0047308881767094135 for recalled reconstructions, 0.0002148817147826776 for normal images, and 3.703733444213867 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009282914744690061\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.002934206509962678; that's 2.5286507606506348 text and 0.00040555562009103596 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0033119682292453946\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.001970236888155341; that's 0.0011495251674205065 task and 0.00022588309366255999 recon and 2.9741435050964355 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002191803295863792\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012430080212652683; that's 0.007660497445613146 for recalled reconstructions, 0.0002214830310549587 for normal images, and 4.548099517822266 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009664122606627643\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011008108034729958; that's 0.006876732688397169 for recalled reconstructions, 0.00022473545686807483 for normal images, and 3.9066390991210938 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009569031167775393\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012763370759785175; that's 0.007659191731363535 for recalled reconstructions, 0.00022086885292083025 for normal images, and 4.883309364318848 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.01005845760460943\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009120721369981766; that's 0.005250335671007633 for recalled reconstructions, 0.00022990266734268516 for normal images, and 3.6404829025268555 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009454270931892097\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002325453097000718; that's 0.0012742581311613321 task and 0.0002310217678314075 recon and 4.100865840911865 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002304261972894892\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004384666681289673; that's 3.804152727127075 text and 0.000580514024477452 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038889472768642006\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008731233887374401; that's 0.005641358904540539 for recalled reconstructions, 0.00022369460202753544 for normal images, and 2.866180181503296 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009090011725202202\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007667844183743; that's 0.0033259615302085876 for recalled reconstructions, 0.00021164986537769437 for normal images, and 4.130232334136963 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009565844349563122\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007721015717834234; that's 0.003444678382948041 for recalled reconstructions, 0.00022139435168355703 for normal images, and 4.054943084716797 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009585041222162544\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0141453817486763; that's 0.009645701386034489 for recalled reconstructions, 0.00022343431191984564 for normal images, and 4.2762451171875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009825171646662056\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002434445545077324; that's 0.0013916916213929653 task and 0.00023042851535137743 recon and 4.061627388000488 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002403228135081008\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004249390214681625; that's 3.6759567260742188 text and 0.0005734332371503115 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004217335255816579\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009896788746118546; that's 0.005619760137051344 for recalled reconstructions, 0.00022818426077719778 for normal images, and 4.048844814300537 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010145849245600403\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009210831485688686; that's 0.005439650267362595 for recalled reconstructions, 0.00022131660080049187 for normal images, and 3.5498642921447754 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009727403693832458\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008891891688108444; that's 0.004835869651287794 for recalled reconstructions, 0.00021409059991128743 for normal images, and 3.8419313430786133 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009512867582961916\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009520360268652439; that's 0.006061905063688755 for recalled reconstructions, 0.00021925097098574042 for normal images, and 3.239204168319702 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00944128489587456\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0024816819932311773; that's 0.001144082867540419 task and 0.00022343304590322077 recon and 5.570830821990967 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022816579276695847\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004996653646230698; that's 4.5118632316589355 text and 0.0004847901000175625 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004023977913893759\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007945055142045021; that's 0.00448623625561595 for recalled reconstructions, 0.00022010068641975522 for normal images, and 3.238718271255493 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009386918097734452\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007762865629047155; that's 0.003285033628344536 for recalled reconstructions, 0.00022440367320086807 for normal images, and 4.2534284591674805 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00934317693579942\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011843199841678143; that's 0.007619782816618681 for recalled reconstructions, 0.00021761505922768265 for normal images, and 4.005801677703857 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009197108144871891\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01052930485457182; that's 0.006049818824976683 for recalled reconstructions, 0.00021654271404258907 for normal images, and 4.262943267822266 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009589156908914447\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0022147323470562696; that's 0.0012334049679338932 task and 0.0002179990115109831 recon and 3.8166422843933105 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022985680750571193\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004033334087580442; that's 3.4297525882720947 text and 0.00060358113842085 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00426667626015842\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009039856493473053; that's 0.004837434273213148 for recalled reconstructions, 0.00021313804609235376 for normal images, and 3.989283561706543 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009198753805831074\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007647027261555195; that's 0.004079568199813366 for recalled reconstructions, 0.00021479881252162158 for normal images, and 3.3526599407196045 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009086593007668852\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009590720757842064; that's 0.005606830585747957 for recalled reconstructions, 0.0002136655675712973 for normal images, and 3.7702245712280273 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009483746476471424\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007554509211331606; that's 0.00326326722279191 for recalled reconstructions, 0.0002163513272535056 for normal images, and 4.074890613555908 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009853396750986575\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0038089854642748833; that's 3.304346799850464 text and 0.000504638534039259 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004128174183424562\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002079549478366971; that's 0.0011058381060138345 task and 0.00021174269204493612 recon and 3.8098435401916504 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023025614884681998\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007924476638436317; that's 0.004070209339261055 for recalled reconstructions, 0.00020504309213720262 for normal images, and 3.6492233276367188 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009744675923138857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009680517949163914; that's 0.005800334271043539 for recalled reconstructions, 0.00021221490169409662 for normal images, and 3.66796875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010040009836666286\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008217208087444305; that's 0.004245184827595949 for recalled reconstructions, 0.00022942111536394805 for normal images, and 3.7426018714904785 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009433223917149007\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009542499668896198; that's 0.005492616910487413 for recalled reconstructions, 0.00021985593775752932 for normal images, and 3.830026626586914 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00943329943343997\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004038501065224409; that's 3.32155179977417 text and 0.0007169489399529994 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00412233667448163\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0037708140444010496; that's 0.0027423440478742123 task and 0.00025745562743395567 recon and 3.8550710678100586 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023738439788576217\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01205468364059925; that's 0.0071281264536082745 for recalled reconstructions, 0.00026001344667747617 for normal images, and 4.666543006896973 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009764822055585683\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011899027973413467; that's 0.008173559792339802 for recalled reconstructions, 0.00021788560843560845 for normal images, and 3.507582664489746 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00967775508761406\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007673528976738453; that's 0.0038905960973352194 for recalled reconstructions, 0.00021523743635043502 for normal images, and 3.567695140838623 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009857994974590839\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007904820144176483; that's 0.0028255877550691366 for recalled reconstructions, 0.00023167047766037285 for normal images, and 4.847561836242676 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009884859616868198\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0022398540750145912; that's 0.0013073001755401492 task and 0.00022353636450134218 recon and 3.5450873374938965 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002318343655206263\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.00376207591034472; that's 3.212310552597046 text and 0.0005497653037309647 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004237307021394372\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008275030180811882; that's 0.004839744418859482 for recalled reconstructions, 0.0002275589940836653 for normal images, and 3.207726240158081 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009359232704155148\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011028864420950413; that's 0.00636731693521142 for recalled reconstructions, 0.0002330042771063745 for normal images, and 4.4285430908203125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009993500243872404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009765065275132656; that's 0.004885576199740171 for recalled reconstructions, 0.00022315770911518484 for normal images, and 4.6563310623168945 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.0102449832810089\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009233379736542702; that's 0.00677062850445509 for recalled reconstructions, 0.00021532866230700165 for normal images, and 2.247422695159912 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009631605623289942\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002366036409512162; that's 0.0015201852656900883 task and 0.00021741549426224083 recon and 3.142178535461426 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022222242434509097\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008221537806093693; that's 0.005395486950874329 for recalled reconstructions, 0.00021460960851982236 for normal images, and 2.611440658569336 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009323843237943948\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0031790700741112232; that's 2.7372868061065674 text and 0.00044178313692100346 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003955480540171265\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007006485480815172; that's 0.002665843116119504 for recalled reconstructions, 0.00022236976656131446 for normal images, and 4.118272304534912 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009177812957204878\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009552178904414177; that's 0.006212249863892794 for recalled reconstructions, 0.00022263955906964839 for normal images, and 3.1172897815704346 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009291459061205386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009674311615526676; that's 0.0046925414353609085 for recalled reconstructions, 0.00020993586804252118 for normal images, and 4.771833896636963 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00950684726703912\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004976177122443914; that's 4.487916946411133 text and 0.0004882596549578011 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003832865508738905\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0028577265329658985; that's 0.0016960263019427657 task and 0.00021490917424671352 recon and 4.733955383300781 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022491290234029292\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009473748505115509; that's 0.0054610916413366795 for recalled reconstructions, 0.0002229889068985358 for normal images, and 3.789668083190918 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009383248831145465\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.006607087329030037; that's 0.00282875495031476 for recalled reconstructions, 0.00021454371744766831 for normal images, and 3.563788414001465 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009441387644037603\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010247969999909401; that's 0.005484318360686302 for recalled reconstructions, 0.00021661956270691007 for normal images, and 4.547031879425049 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009695277917198836\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008762124925851822; that's 0.004030329175293446 for recalled reconstructions, 0.00021842983551323414 for normal images, and 4.513365268707275 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009409634065814316\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004820821341127157; that's 4.240572929382324 text and 0.0005802484811283648 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00386071655433625\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0022189924493432045; that's 0.0010706010507419705 task and 0.00021942764578852803 recon and 4.644818305969238 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022407493356149644\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012523660436272621; that's 0.007636465132236481 for recalled reconstructions, 0.00020798454352188855 for normal images, and 4.679210186004639 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00942004366312176\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00753371138125658; that's 0.004227181430906057 for recalled reconstructions, 0.0002188158978242427 for normal images, and 3.0877134799957275 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.01012983116786927\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00873197428882122; that's 0.004683779086917639 for recalled reconstructions, 0.0002250541147077456 for normal images, and 3.8231406211853027 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009735108357854188\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009340805001556873; that's 0.005008874926716089 for recalled reconstructions, 0.000230598307098262 for normal images, and 4.10133171081543 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00960038034711033\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.003933439496904612; that's 3.224761962890625 text and 0.0007086772238835692 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038777893176302316\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00227946974337101; that's 0.0013216751394793391 task and 0.0002145678736269474 recon and 3.7161335945129395 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022479176335036756\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008717980235815048; that's 0.004854781087487936 for recalled reconstructions, 0.0002127933403244242 for normal images, and 3.650405168533325 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009968285108916461\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008928129449486732; that's 0.004887247458100319 for recalled reconstructions, 0.00021112977992743254 for normal images, and 3.829751968383789 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00960161177907139\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007235642988234758; that's 0.004039192572236061 for recalled reconstructions, 0.00020584849698934704 for normal images, and 2.9906020164489746 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009807037729769945\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.005767497234046459; that's 0.0020410518627613783 for recalled reconstructions, 0.00021012146316934377 for normal images, and 3.5163238048553467 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009824996385723352\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0022261417470872402; that's 0.0010089559946209192 task and 0.0002282188506796956 recon and 4.944835186004639 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022982488363049924\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.006630866788327694; that's 0.0034464308992028236 for recalled reconstructions, 0.0002073889336315915 for normal images, and 2.9770469665527344 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009160931431688368\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004833723418414593; that's 4.081692218780518 text and 0.0007520311046391726 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0040038551646284755\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007208212278783321; that's 0.003915069624781609 for recalled reconstructions, 0.0002187701320508495 for normal images, and 3.0743725299835205 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008711870284751058\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008877543732523918; that's 0.005280232988297939 for recalled reconstructions, 0.00020680368470493704 for normal images, and 3.3905065059661865 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00893512819427997\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010839984752237797; that's 0.005604419391602278 for recalled reconstructions, 0.0002133438247255981 for normal images, and 5.022221565246582 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009567289422266185\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0019188851583749056; that's 0.0009232970187440515 task and 0.00022427889052778482 recon and 3.856546640396118 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023690374882426113\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.003918398171663284; that's 3.409641742706299 text and 0.0005087564350105822 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004073948627337814\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008075486868619919; that's 0.005019600503146648 for recalled reconstructions, 0.0002092774084303528 for normal images, and 2.846608877182007 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009885619478300214\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00785877462476492; that's 0.00425309780985117 for recalled reconstructions, 0.00022008619271218777 for normal images, and 3.3855903148651123 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009693757141940295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008962929248809814; that's 0.005013648886233568 for recalled reconstructions, 0.00022654929489362985 for normal images, and 3.7227306365966797 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009764974843710661\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009363336488604546; that's 0.004833883605897427 for recalled reconstructions, 0.00023646859335713089 for normal images, and 4.292984485626221 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.01001589729450643\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0030795468483120203; that's 0.001911020721308887 task and 0.0002182477037422359 recon and 4.751392841339111 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023595069779548793\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004971549846231937; that's 4.2564778327941895 text and 0.0007150715682655573 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004360899943858385\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011827656999230385; that's 0.007020953577011824 for recalled reconstructions, 0.00022888231615070254 for normal images, and 4.577820777893066 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009961274256929754\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01255993451923132; that's 0.008462104946374893 for recalled reconstructions, 0.0002175785630242899 for normal images, and 3.880251169204712 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009679910144768655\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007078094407916069; that's 0.003298614639788866 for recalled reconstructions, 0.00021341706451494247 for normal images, and 3.5660629272460938 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010319653269834816\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007610957138240337; that's 0.003441249020397663 for recalled reconstructions, 0.00021819579706061631 for normal images, and 3.951511859893799 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009557329388335346\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0029576655942946672; that's 0.0019653288181871176 task and 0.00023881082597654313 recon and 3.767629623413086 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002211404845584184\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008612225763499737; that's 0.004841570742428303 for recalled reconstructions, 0.0002167184866266325 for normal images, and 3.553936719894409 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009041630337014795\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004108061082661152; that's 3.233628511428833 text and 0.0008744323276914656 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00384958918672055\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008443072438240051; that's 0.005019427742809057 for recalled reconstructions, 0.00022761497530154884 for normal images, and 3.1960296630859375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00977698681410402\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008000107482075691; that's 0.004999102558940649 for recalled reconstructions, 0.00021621868654619902 for normal images, and 2.784785747528076 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009245655597187579\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011864138767123222; that's 0.007093206513673067 for recalled reconstructions, 0.0003044574405066669 for normal images, and 4.466475009918213 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009682324156165123\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0031054590363055468; that's 2.400390863418579 text and 0.0007050679996609688 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003443929215427488\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0070450035855174065; that's 0.0033137958962470293 for recalled reconstructions, 0.00022612993780057877 for normal images, and 3.505077600479126 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009538148907013237\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0019536279141902924; that's 0.0011316360905766487 task and 0.00022849708329886198 recon and 2.9674744606018066 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002230915966210887\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.006070476956665516; that's 0.0026674808468669653 for recalled reconstructions, 0.00021257894695736468 for normal images, and 3.1904170513153076 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009402753161266446\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012217853218317032; that's 0.008848566561937332 for recalled reconstructions, 0.00021398776152636856 for normal images, and 3.1552987098693848 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009089608769863844\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010415947064757347; that's 0.004872134421020746 for recalled reconstructions, 0.00022598243958782405 for normal images, and 5.3178300857543945 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009313941653817891\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004316320177167654; that's 3.638296365737915 text and 0.0006780233816243708 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004053322670515626\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0021858951076865196; that's 0.0011689037783071399 task and 0.00020977335225325078 recon and 4.036090850830078 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022803056123666464\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008617703802883625; that's 0.005640543065965176 for recalled reconstructions, 0.00020793302974198014 for normal images, and 2.7692275047302246 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009120970661751927\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01047211792320013; that's 0.006390531547367573 for recalled reconstructions, 0.00022575916955247521 for normal images, and 3.8558268547058105 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009202774167060852\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007687682285904884; that's 0.004403152037411928 for recalled reconstructions, 0.0002249735698569566 for normal images, and 3.059556722640991 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009387808693572879\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008046353235840797; that's 0.004855572711676359 for recalled reconstructions, 0.0002268425450893119 for normal images, and 2.9639382362365723 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008875378905795515\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004313814919441938; that's 3.767469644546509 text and 0.0005463449633680284 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004155435995198786\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008595738559961319; that's 0.004863467998802662 for recalled reconstructions, 0.00021936318080406636 for normal images, and 3.5129072666168213 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009041511160321534\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0020030508749186993; that's 0.0009129439713433385 task and 0.00021190600818954408 recon and 4.3910040855407715 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022636447357945143\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010151647962629795; that's 0.0067319790832698345 for recalled reconstructions, 0.00022237945813685656 for normal images, and 3.19728946685791 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00900230553932488\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009786909446120262; that's 0.006099422462284565 for recalled reconstructions, 0.0002218224253738299 for normal images, and 3.4656646251678467 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009130765455774964\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007082022726535797; that's 0.004088270012289286 for recalled reconstructions, 0.0002101352292811498 for normal images, and 2.7836172580718994 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008914614347741007\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004652814473956823; that's 4.04597806930542 text and 0.0006068362854421139 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004263772575650364\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0024322455283254385; that's 0.0010647744638845325 task and 0.00021977387950755656 recon and 5.738486289978027 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002273162717465311\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010655603371560574; that's 0.00684478972107172 for recalled reconstructions, 0.0002176187263103202 for normal images, and 3.5931942462921143 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008601728300563992\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00939345546066761; that's 0.006247615907341242 for recalled reconstructions, 0.0002247580123366788 for normal images, and 2.921081781387329 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008995632659643888\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00983104482293129; that's 0.0050063286907970905 for recalled reconstructions, 0.00021237261535134166 for normal images, and 4.612342834472656 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00924605920445174\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009736841544508934; that's 0.00685221329331398 for recalled reconstructions, 0.00022406633070204407 for normal images, and 2.6605615615844727 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009135923534631728\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.00435624411329627; that's 3.682828187942505 text and 0.0006734158960171044 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00430143230361864\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009793576784431934; that's 0.006889274809509516 for recalled reconstructions, 0.00022140948567539454 for normal images, and 2.6828925609588623 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008574035759083927\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002251445082947612; that's 0.0012104320339858532 task and 0.0002264711947645992 recon and 4.072709560394287 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023669796832837165\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.006323512177914381; that's 0.0034561529755592346 for recalled reconstructions, 0.0002133005327777937 for normal images, and 2.6540584564208984 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008839494502171873\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008286898955702782; that's 0.005448519252240658 for recalled reconstructions, 0.000225216630497016 for normal images, and 2.6131629943847656 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009113775542937219\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009521001018583775; that's 0.005656778812408447 for recalled reconstructions, 0.00021554646082222462 for normal images, and 3.6486756801605225 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009616572363302111\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0035891160368919373; that's 3.1593878269195557 text and 0.0004297281848266721 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004074770181905479\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0022729241754859686; that's 0.0013151217717677355 task and 0.00021333617041818798 recon and 3.7223310470581055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022602454631123693\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0101547259837389; that's 0.006251954939216375 for recalled reconstructions, 0.00020538373792078346 for normal images, and 3.697387456893921 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009818817642517387\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011086606420576572; that's 0.006824204698204994 for recalled reconstructions, 0.00021987146465107799 for normal images, and 4.042530059814453 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009404434543102979\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01295179408043623; that's 0.008877991698682308 for recalled reconstructions, 0.00021590337564703077 for normal images, and 3.8578991889953613 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009829380824230611\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009431464597582817; that's 0.004667262546718121 for recalled reconstructions, 0.00021200485934969038 for normal images, and 4.552196979522705 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009975299811922014\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0038921614177525043; that's 3.428865909576416 text and 0.00046329534961842 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003830525637604296\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011007946915924549; that's 0.006239116657525301 for recalled reconstructions, 0.0002159153955290094 for normal images, and 4.552914619445801 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00970691763330251\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0019176483619958162; that's 0.0009329686872661114 task and 0.00023191705986391753 recon and 3.7638134956359863 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002277518453774974\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.006930691190063953; that's 0.0028287023305892944 for recalled reconstructions, 0.00021193470456637442 for normal images, and 3.8900537490844727 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010286079552024603\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011931538581848145; that's 0.007626212202012539 for recalled reconstructions, 0.0002177291753469035 for normal images, and 4.087596416473389 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.01008602161426097\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.006758059374988079; that's 0.003460478503257036 for recalled reconstructions, 0.00021426804596558213 for normal images, and 3.083312749862671 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009792493064887822\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0033680922351777554; that's 2.8528568744659424 text and 0.0005152351222932339 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003797352788969874\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0021874611265957355; that's 0.001338109839707613 task and 0.0002195755805587396 recon and 3.148878812789917 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002127236588858068\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.013274924829602242; that's 0.007779535837471485 for recalled reconstructions, 0.00021306808048393577 for normal images, and 5.282321453094482 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010113412514328957\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010357772000133991; that's 0.006260094232857227 for recalled reconstructions, 0.00022296191309578717 for normal images, and 3.87471604347229 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010038465037941932\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009853100404143333; that's 0.005635782144963741 for recalled reconstructions, 0.00021080429723951966 for normal images, and 4.006514072418213 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009867378389462828\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008563259616494179; that's 0.004864385351538658 for recalled reconstructions, 0.00021169516548980027 for normal images, and 3.4871788024902344 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009975564596243203\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0021648164838552475; that's 0.0011933932546526194 task and 0.00024241000937763602 recon and 3.645066022872925 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022172181692440064\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.003076123306527734; that's 2.729409694671631 text and 0.0003467135247774422 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035818239022046327\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008818656206130981; that's 0.00347657548263669 for recalled reconstructions, 0.0002064607833744958 for normal images, and 5.1356201171875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009568052804097534\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00855001900345087; that's 0.004668472334742546 for recalled reconstructions, 0.0002135422982973978 for normal images, and 3.668004035949707 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009850423466414213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008914419449865818; that's 0.004049205221235752 for recalled reconstructions, 0.0002164270990760997 for normal images, and 4.648786544799805 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009989720904268324\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009650958701968193; that's 0.005003660451620817 for recalled reconstructions, 0.00021492672385647893 for normal images, and 4.432371139526367 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009947397178038955\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004058546852320433; that's 3.7562875747680664 text and 0.00030225919908843935 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037706416938453912\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002612045034766197; that's 0.0015946094645187259 task and 0.0002220137685071677 recon and 3.977109432220459 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002204862363869324\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01339245680719614; that's 0.008432023227214813 for recalled reconstructions, 0.00019905835506506264 for normal images, and 4.761375427246094 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010101383426226676\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01048446074128151; that's 0.006248773075640202 for recalled reconstructions, 0.0002169553772546351 for normal images, and 4.018731594085693 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009910160549916327\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011483214795589447; that's 0.006862920708954334 for recalled reconstructions, 0.0002212460240116343 for normal images, and 4.399047374725342 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010074976226314902\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008663617074489594; that's 0.004695862997323275 for recalled reconstructions, 0.0002127650659531355 for normal images, and 3.7549896240234375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010152773829177023\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0028261570259928703; that's 0.0017198816640302539 task and 0.00023163347213994712 recon and 4.373210430145264 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022492607776075603\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012046191841363907; that's 0.006886627990752459 for recalled reconstructions, 0.00022045776131562889 for normal images, and 4.93910551071167 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010036047198809683\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0038752295076847076; that's 3.463958263397217 text and 0.0004112710594199598 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003920911606401205\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008831728249788284; that's 0.005010261666029692 for recalled reconstructions, 0.00021052200463600457 for normal images, and 3.6109442710876465 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009251122553832829\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008641514927148819; that's 0.006210864055901766 for recalled reconstructions, 0.00021742421085946262 for normal images, and 2.213226795196533 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009008255680091679\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0090695321559906; that's 0.005486825946718454 for recalled reconstructions, 0.00022355026158038527 for normal images, and 3.3591561317443848 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008870325544849037\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004412579350173473; that's 3.7669365406036377 text and 0.0006456428673118353 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004028226677328348\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0024943086318671703; that's 0.001266866340301931 task and 0.00021844220464117825 recon and 5.04500150680542 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023372088163159787\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00876837782561779; that's 0.005475266370922327 for recalled reconstructions, 0.0002171396918129176 for normal images, and 3.0759711265563965 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009740386004559697\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011993242427706718; that's 0.008248920552432537 for recalled reconstructions, 0.00021626947273034602 for normal images, and 3.52805233001709 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009158780579455197\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01078847423195839; that's 0.006235531531274319 for recalled reconstructions, 0.0002122938894899562 for normal images, and 4.340649127960205 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009688884583301843\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010056200437247753; that's 0.0048510110937058926 for recalled reconstructions, 0.0002048328606178984 for normal images, and 5.000356197357178 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00900540966540575\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002015418838709593; that's 0.000969258660916239 task and 0.00021463971643242985 recon and 4.157602310180664 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002171150390058756\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004429315682500601; that's 3.7627880573272705 text and 0.0006665276596322656 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003590967361815274\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00866031739860773; that's 0.0047996933571994305 for recalled reconstructions, 0.00022058107424527407 for normal images, and 3.640043020248413 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009046940826810896\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010016830638051033; that's 0.006056046113371849 for recalled reconstructions, 0.00020283021149225533 for normal images, and 3.757953405380249 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009405014840885996\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.006245414726436138; that's 0.002837228588759899 for recalled reconstructions, 0.00021122033649589866 for normal images, and 3.196965456008911 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008899661106988787\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008898882195353508; that's 0.005623325705528259 for recalled reconstructions, 0.00021125712373759598 for normal images, and 3.0642995834350586 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008982096305117012\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0036840238608419895; that's 3.0774850845336914 text and 0.0006065386114642024 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0036101919482462107\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.001738914754241705; that's 0.000842559733428061 task and 0.00021557038417086005 recon and 3.403923511505127 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021992489730473606\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007294799666851759; that's 0.004683826584368944 for recalled reconstructions, 0.00022448580421041697 for normal images, and 2.3864870071411133 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009223400671035052\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008250151760876179; that's 0.004088720306754112 for recalled reconstructions, 0.0002304358349647373 for normal images, and 3.930995464324951 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009385585831478239\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010180672630667686; that's 0.006872260477393866 for recalled reconstructions, 0.00022354171960614622 for normal images, and 3.0848701000213623 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008841486391611397\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008756084367632866; that's 0.005645733326673508 for recalled reconstructions, 0.00021032207587268203 for normal images, and 2.900029420852661 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009143749950453639\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002750516403466463; that's 0.001766773872077465 task and 0.00021547578216996044 recon and 3.841334819793701 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022651704284362495\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009986110031604767; that's 0.006840835325419903 for recalled reconstructions, 0.00022048558457754552 for normal images, and 2.9247894287109375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009279143717139959\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0035499008372426033; that's 3.194464921951294 text and 0.0003554356808308512 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003889137164223939\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011072590947151184; that's 0.007667738478630781 for recalled reconstructions, 0.0002194670814787969 for normal images, and 3.1853854656219482 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009321338376030325\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009235676378011703; that's 0.006076181773096323 for recalled reconstructions, 0.00022287519823294133 for normal images, and 2.936619520187378 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008689354113303125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01066866610199213; that's 0.006414627190679312 for recalled reconstructions, 0.00022376996639650315 for normal images, and 4.030269145965576 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008887855410575867\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004240680485963821; that's 3.6228840351104736 text and 0.0006177963805384934 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004068391034379602\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0021743231918662786; that's 0.0011390286963433027 task and 0.0002196069253841415 recon and 4.078437805175781 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022772531153168528\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007534543983638287; that's 0.004696960095316172 for recalled reconstructions, 0.00021834211656823754 for normal images, and 2.619241952896118 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009081899356096983\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010881615802645683; that's 0.006864564027637243 for recalled reconstructions, 0.0002162119490094483 for normal images, and 3.800839424133301 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009023669948801398\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007029248401522636; that's 0.003606157610192895 for recalled reconstructions, 0.00020672105893027037 for normal images, and 3.216369867324829 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009194682855159043\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009080853313207626; that's 0.006085646338760853 for recalled reconstructions, 0.00021805537107866257 for normal images, and 2.777151346206665 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009066465189680456\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0036474743392318487; that's 3.0934274196624756 text and 0.0005540467682294548 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0039905472588725385\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0019989474676549435; that's 0.0010300937574356794 task and 0.00022129339049570262 recon and 3.7378015518188477 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00228929795906879\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010395321995019913; that's 0.006689903791993856 for recalled reconstructions, 0.00021041920990683138 for normal images, and 3.4949991703033447 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008939657015725971\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009143823757767677; that's 0.005475817713886499 for recalled reconstructions, 0.0002140754513675347 for normal images, and 3.453930377960205 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009146234206855296\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008168996311724186; that's 0.0036223274655640125 for recalled reconstructions, 0.0002176356065319851 for normal images, and 4.329032897949219 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009443544093519449\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007958702743053436; that's 0.0045218272134661674 for recalled reconstructions, 0.0001922737283166498 for normal images, and 3.244601011276245 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009523262260481715\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0037180876825004816; that's 3.1538712978363037 text and 0.0005642162286676466 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004131636994425207\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012989968992769718; that's 0.008905407041311264 for recalled reconstructions, 0.00021013662626501173 for normal images, and 3.8744256496429443 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00955847471486777\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.001656215637922287; that's 0.000737211259547621 task and 0.00021914843819104135 recon and 3.499279737472534 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002280864113708958\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011319931596517563; that's 0.007654080633074045 for recalled reconstructions, 0.0002050498587777838 for normal images, and 3.460801362991333 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008994468399323522\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008372245356440544; that's 0.004863604437559843 for recalled reconstructions, 0.00021529430523514748 for normal images, and 3.293346881866455 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009330712161026895\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0053393663838505745; that's 0.002057285513728857 for recalled reconstructions, 0.0001988671865547076 for normal images, and 3.0832133293151855 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009434771975502371\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004072824493050575; that's 3.3170289993286133 text and 0.0007557954522781074 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0039021905581466854\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0022128713317215443; that's 0.0012369632022455335 task and 0.00022220099344849586 recon and 3.7685351371765137 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002200354969827458\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00928182527422905; that's 0.006228570360690355 for recalled reconstructions, 0.00022778031416237354 for normal images, and 2.825474500656128 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00911299664992839\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011250050738453865; that's 0.008422786369919777 for recalled reconstructions, 0.0002216114371549338 for normal images, and 2.605653762817383 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00922153687570244\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008308721706271172; that's 0.004851402714848518 for recalled reconstructions, 0.00023224021424539387 for normal images, and 3.2250783443450928 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009094393705017864\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009920651093125343; that's 0.00582855986431241 for recalled reconstructions, 0.00021546112839132547 for normal images, and 3.8766303062438965 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009000036949291825\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007907798513770103; that's 0.004213348496705294 for recalled reconstructions, 0.00022340672148857266 for normal images, and 3.471043348312378 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008973905802704393\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0029071979224681854; that's 0.0019107586704194546 task and 0.00022251297195907682 recon and 3.869631052017212 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023451757489237933\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0037554397713392973; that's 3.321812391281128 text and 0.0004336272249929607 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003864220518153161\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010934378951787949; that's 0.007007145322859287 for recalled reconstructions, 0.00022330535284709185 for normal images, and 3.7039284706115723 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008954211338423192\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011051991954445839; that's 0.007478353101760149 for recalled reconstructions, 0.00022301518765743822 for normal images, and 3.350623369216919 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009153816266916692\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010135600343346596; that's 0.006048485636711121 for recalled reconstructions, 0.00021545178606174886 for normal images, and 3.8716626167297363 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009506795560009778\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0023021847009658813; that's 0.0011160112917423248 task and 0.0002232498227385804 recon and 4.814618110656738 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022139029810205103\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004767283797264099; that's 4.265050411224365 text and 0.0005022335681132972 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004055282084736973\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009098662063479424; that's 0.005642966367304325 for recalled reconstructions, 0.00020886017591692507 for normal images, and 3.246835708618164 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008925829511135817\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008238706737756729; that's 0.003472328884527087 for recalled reconstructions, 0.00020963771385140717 for normal images, and 4.556739807128906 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009609253904782235\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008610626682639122; that's 0.005418803077191114 for recalled reconstructions, 0.00021824901341460645 for normal images, and 2.973574161529541 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009765996504575014\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010803192853927612; that's 0.0066758450120687485 for recalled reconstructions, 0.00020863064855802804 for normal images, and 3.918717622756958 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009525691783055663\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002035666024312377; that's 0.0009173316648229957 task and 0.00021281224326230586 recon and 4.527610778808594 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002269806707045063\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0035888145212084055; that's 3.0749645233154297 text and 0.0005138497799634933 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004097973732277751\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009593483991920948; that's 0.004693772178143263 for recalled reconstructions, 0.00019760463328566402 for normal images, and 4.702106952667236 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009877831428311765\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01003322098404169; that's 0.0060482630506157875 for recalled reconstructions, 0.00020243781909812242 for normal images, and 3.782519817352295 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009385724668391049\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008430221118032932; that's 0.004024133086204529 for recalled reconstructions, 0.00022123591043055058 for normal images, and 4.184852123260498 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009791722800582648\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0108722485601902; that's 0.00670249667018652 for recalled reconstructions, 0.00020890109590254724 for normal images, and 3.960850715637207 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009194644512608647\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0035628038458526134; that's 3.093665599822998 text and 0.00046913811820559204 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0041012726374901835\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00896838866174221; that's 0.005318166222423315 for recalled reconstructions, 0.00021707954874727875 for normal images, and 3.4331421852111816 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009541566376574337\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0022099530324339867; that's 0.0012798438547179103 task and 0.0002206940989708528 recon and 3.5470759868621826 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002196361287496984\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008828849531710148; that's 0.004252033773809671 for recalled reconstructions, 0.0002142586454283446 for normal images, and 4.3625569343566895 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009454775243066251\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01174945943057537; that's 0.007805274333804846 for recalled reconstructions, 0.00021007988834753633 for normal images, and 3.7341055870056152 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009656831286847592\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011038854718208313; that's 0.00545478193089366 for recalled reconstructions, 0.00021916683181189 for normal images, and 5.364905834197998 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010560529050417244\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004973894916474819; that's 4.528763294219971 text and 0.0004451312415767461 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004113519927486777\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0022420734167099; that's 0.001035979250445962 task and 0.00021775104687549174 recon and 4.941715717315674 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002219346697675064\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.013411610387265682; that's 0.007836731150746346 for recalled reconstructions, 0.0002148280036635697 for normal images, and 5.360050678253174 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010775177502073347\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01010342501103878; that's 0.004536491818726063 for recalled reconstructions, 0.0002054583019344136 for normal images, and 5.361474514007568 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.011033241022378206\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009172133170068264; that's 0.004709314089268446 for recalled reconstructions, 0.0002216540597146377 for normal images, and 4.2411651611328125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010859146369621158\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008349133655428886; that's 0.004977660719305277 for recalled reconstructions, 0.00021826087322551757 for normal images, and 3.153212070465088 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009757592272944749\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0035878964699804783; that's 2.9186878204345703 text and 0.000669208588078618 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003971616544295103\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0022331643849611282; that's 0.001344832475297153 task and 0.00022042758064344525 recon and 3.339521646499634 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021758922026492654\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007271081209182739; that's 0.003443163586780429 for recalled reconstructions, 0.00020331531413830817 for normal images, and 3.6246020793914795 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00992361973039806\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.006560911890119314; that's 0.00266269501298666 for recalled reconstructions, 0.0002170928055420518 for normal images, and 3.681123971939087 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009978864630684257\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012153401970863342; that's 0.007033742032945156 for recalled reconstructions, 0.0002129867789335549 for normal images, and 4.906672477722168 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009684228920377791\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012060040608048439; that's 0.007573569659143686 for recalled reconstructions, 0.0001937717606779188 for normal images, and 4.292699337005615 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009737612162716687\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0028030171524733305; that's 0.0017272478435188532 task and 0.00019017988233827055 recon and 4.427947521209717 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023396817268803716\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00845508836209774; that's 0.0048441761173307896 for recalled reconstructions, 0.0002187848003813997 for normal images, and 3.3921267986297607 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.01006039595697075\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0047294143587350845; that's 4.129003047943115 text and 0.0006004113238304853 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004211635030806064\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009867780841886997; that's 0.006104514002799988 for recalled reconstructions, 0.00021094603289384395 for normal images, and 3.5523204803466797 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010080741667188704\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009135494008660316; that's 0.004409367218613625 for recalled reconstructions, 0.0002140882716048509 for normal images, and 4.512037754058838 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009714739336632193\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.013918928802013397; that's 0.009354639798402786 for recalled reconstructions, 0.00021227342949714512 for normal images, and 4.352014541625977 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009956922456622124\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010244227945804596; that's 0.006211021449416876 for recalled reconstructions, 0.00020477559883147478 for normal images, and 3.828430652618408 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009596273703500628\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002471199259161949; that's 0.0012696700869128108 task and 0.00022026551596354693 recon and 4.906318664550781 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002366240390110761\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004474376328289509; that's 3.988309860229492 text and 0.0004860663029830903 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004407235733233392\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012114575132727623; that's 0.0074702063575387 for recalled reconstructions, 0.00021095902775414288 for normal images, and 4.433409690856934 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009586742031387985\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011225000955164433; that's 0.007062791846692562 for recalled reconstructions, 0.00020122196292504668 for normal images, and 3.960986852645874 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009632104812189936\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009639322757720947; that's 0.0054329996928572655 for recalled reconstructions, 0.0002097855176543817 for normal images, and 3.99653697013855 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009602024974301458\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.002611656906083226; that's 2.1235623359680176 text and 0.0004880945780314505 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004046877436339855\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00241906032897532; that's 0.0017195382388308644 task and 0.0002254490100312978 recon and 2.370366096496582 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023351302510127426\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011368692852556705; that's 0.006416061893105507 for recalled reconstructions, 0.00022894961875863373 for normal images, and 4.7236809730529785 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009797870083712041\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012170087546110153; that's 0.0076061333529651165 for recalled reconstructions, 0.00022407628421206027 for normal images, and 4.339877128601074 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009573776815086603\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011217531748116016; that's 0.006232073064893484 for recalled reconstructions, 0.00022213502961676568 for normal images, and 4.763323783874512 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010109763913787902\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.006932753138244152; that's 0.0034516439773142338 for recalled reconstructions, 0.00019883009372279048 for normal images, and 3.2822787761688232 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.01017808511853218\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0017564601730555296; that's 0.0010866266675293446 task and 0.00019728107145056129 recon and 2.3627617359161377 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002301844039466232\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0027175317518413067; that's 2.122201442718506 text and 0.000595330260694027 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003929914622567594\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01123921386897564; that's 0.007009067572653294 for recalled reconstructions, 0.00020997600222472101 for normal images, and 4.020169734954834 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010145485773682595\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01401262916624546; that's 0.008250288665294647 for recalled reconstructions, 0.0002085194137180224 for normal images, and 5.553820610046387 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010525891799479723\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011250722222030163; that's 0.006072040181607008 for recalled reconstructions, 0.00021250147256068885 for normal images, and 4.966180324554443 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010519611714407802\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012112787924706936; that's 0.0072061438113451 for recalled reconstructions, 0.00022042871569283307 for normal images, and 4.686215400695801 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010429018312133848\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0042259483598172665; that's 3.6073668003082275 text and 0.0006185814272612333 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035582460649311544\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002713153138756752; that's 0.001762286527082324 task and 0.00020474049961194396 recon and 3.7306296825408936 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002183816571487114\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009709039703011513; that's 0.005259878467768431 for recalled reconstructions, 0.0001960334338946268 for normal images, and 4.253127574920654 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010080611449666321\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01301049068570137; that's 0.008284704759716988 for recalled reconstructions, 0.00021269265562295914 for normal images, and 4.5130934715271 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010051982421427965\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007421692367643118; that's 0.003438805928453803 for recalled reconstructions, 0.00021861358254682273 for normal images, and 3.764272689819336 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.01010009678080678\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00997978262603283; that's 0.005016637500375509 for recalled reconstructions, 0.00021116975403856486 for normal images, and 4.751975059509277 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010080581749789416\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0031194479670375586; that's 2.6667981147766113 text and 0.0004526498378254473 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035236455919221044\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0021095317788422108; that's 0.0012806974118575454 task and 0.00021746977290604264 recon and 3.056823253631592 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021751587837934494\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008378422819077969; that's 0.003846142441034317 for recalled reconstructions, 0.00020805226813536137 for normal images, and 4.324227809906006 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010355903371237218\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011450864374637604; that's 0.006424490828067064 for recalled reconstructions, 0.0002087044413201511 for normal images, and 4.817668914794922 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00980857021175325\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010185997933149338; that's 0.0053239730186760426 for recalled reconstructions, 0.00020836344629060477 for normal images, and 4.653661727905273 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010420326772145928\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.013127412647008896; that's 0.0076032946817576885 for recalled reconstructions, 0.00021862621360924095 for normal images, and 5.3054914474487305 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.01031955199316144\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004747400991618633; that's 4.311602592468262 text and 0.00043579781777225435 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0040130654931999745\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002249859506264329; that's 0.0011439226800575852 task and 0.00020927183504682034 recon and 4.483325004577637 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021927492192480714\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010466042906045914; that's 0.006050893105566502 for recalled reconstructions, 0.0002164754259865731 for normal images, and 4.198674201965332 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00977623503189534\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009832622483372688; that's 0.0056430622935295105 for recalled reconstructions, 0.00021250071586109698 for normal images, and 3.9770586490631104 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010449762870557606\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.005989065393805504; that's 0.0022340654395520687 for recalled reconstructions, 0.000219641748117283 for normal images, and 3.53535795211792 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010384149732999504\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.013848837465047836; that's 0.008259204216301441 for recalled reconstructions, 0.0002195772685809061 for normal images, and 5.370056629180908 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010918366722762585\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.003925499971956015; that's 3.329113245010376 text and 0.0005963865551166236 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003959629617165774\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002294548787176609; that's 0.0012966821668669581 task and 0.00021151808323338628 recon and 3.9317426681518555 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022590146108996123\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009173484519124031; that's 0.004838257096707821 for recalled reconstructions, 0.00020916422363370657 for normal images, and 4.126062393188477 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010401848861947656\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0059497300535440445; that's 0.002269777236506343 for recalled reconstructions, 0.0002037668600678444 for normal images, and 3.4761857986450195 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.0103314049821347\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010534107685089111; that's 0.0062829735688865185 for recalled reconstructions, 0.00021051763906143606 for normal images, and 4.040616035461426 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010266607054509222\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011628899723291397; that's 0.007628061342984438 for recalled reconstructions, 0.0002141644508810714 for normal images, and 3.786673069000244 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010345330159179867\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00222022389061749; that's 0.0013372889952734113 task and 0.00021915305114816874 recon and 3.3189098834991455 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022353036678396166\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0037860539741814137; that's 3.148709297180176 text and 0.0006373444339260459 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003976341316010803\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009946347214281559; that's 0.00564330630004406 for recalled reconstructions, 0.00023933633929118514 for normal images, and 4.063704490661621 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010010741441510618\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007139507681131363; that's 0.0028268727473914623 for recalled reconstructions, 0.00021314091281965375 for normal images, and 4.099493503570557 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009960821010172366\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007061773911118507; that's 0.002855850150808692 for recalled reconstructions, 0.00020969014440197498 for normal images, and 3.9962334632873535 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010370146171189844\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012514130212366581; that's 0.008274431340396404 for recalled reconstructions, 0.00022103525407146662 for normal images, and 4.01866340637207 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010399935739114881\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002307221293449402; that's 0.0011489647440612316 task and 0.00021656753960996866 recon and 4.708445072174072 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021891324513126165\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0047209421172738075; that's 4.122029781341553 text and 0.0005989122437313199 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0039792216918431225\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01071052998304367; that's 0.004819931462407112 for recalled reconstructions, 0.00021499779541045427 for normal images, and 5.675600528717041 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010584481693804264\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008768920786678791; that's 0.004214099608361721 for recalled reconstructions, 0.00021385795844253153 for normal images, and 4.340963363647461 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010134879178367555\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012965654022991657; that's 0.007736257743090391 for recalled reconstructions, 0.00021216283494140953 for normal images, and 5.017232894897461 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009935507238842546\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009238828904926777; that's 0.004854605067521334 for recalled reconstructions, 0.00020973644859623164 for normal images, and 4.174487113952637 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009871644382365048\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002365713706240058; that's 0.0012326331343501806 task and 0.00022207557049114257 recon and 4.55502462387085 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022956236964091657\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004346764180809259; that's 3.9155819416046143 text and 0.0004311816592235118 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004052615854889154\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007808545604348183; that's 0.003617645939812064 for recalled reconstructions, 0.00020836835028603673 for normal images, and 3.9825313091278076 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010161739159375429\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008686970919370651; that's 0.005478665232658386 for recalled reconstructions, 0.00021059585560578853 for normal images, and 2.9977099895477295 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009505297769792379\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011189520359039307; that's 0.007006586063653231 for recalled reconstructions, 0.00020585859601851553 for normal images, and 3.9770753383636475 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008677402534522117\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.006945185363292694; that's 0.003894040361046791 for recalled reconstructions, 0.00021576110157184303 for normal images, and 2.8353841304779053 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010013401550240815\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004401501268148422; that's 4.007417678833008 text and 0.0003940835886169225 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037972104642540216\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0018200294580310583; that's 0.0007254588417708874 task and 0.0002007945004152134 recon and 4.468881130218506 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002190456015523523\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007465927861630917; that's 0.003454040503129363 for recalled reconstructions, 0.000198472902411595 for normal images, and 3.8134140968322754 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00952261856291443\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009012006223201752; that's 0.0042123072780668736 for recalled reconstructions, 0.0001985524722840637 for normal images, and 4.601146697998047 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009963914970867335\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012715629301965237; that's 0.00763317896053195 for recalled reconstructions, 0.00021857679530512542 for normal images, and 4.86387300491333 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010180618092417716\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007545518688857555; that's 0.004044871777296066 for recalled reconstructions, 0.00020105599833186716 for normal images, and 3.299591064453125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009820910203270614\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002095048315823078; that's 0.0012530040694400668 task and 0.00022023114433977753 recon and 3.1090662479400635 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023451948701404034\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.003327013459056616; that's 2.835266351699829 text and 0.0004917469923384488 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0043802108173258605\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009098176844418049; that's 0.005024063400924206 for recalled reconstructions, 0.00020480909734033048 for normal images, and 3.8693041801452637 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009423735560849309\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0112799983471632; that's 0.005836556665599346 for recalled reconstructions, 0.00021129568631295115 for normal images, and 5.2321457862854 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009705238565802575\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009190891869366169; that's 0.004829419776797295 for recalled reconstructions, 0.00020150371710769832 for normal images, and 4.159968376159668 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010036328784190118\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009152725338935852; that's 0.0049998522736132145 for recalled reconstructions, 0.00021352247858885676 for normal images, and 3.939350128173828 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009772848640568554\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002050627488642931; that's 0.001122468151152134 task and 0.00021581533655989915 recon and 3.561720371246338 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022494716243818404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0039551337249577045; that's 3.426893949508667 text and 0.0005282397614791989 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004176383365411311\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00890797283500433; that's 0.005449547898024321 for recalled reconstructions, 0.00020031558233313262 for normal images, and 3.2581090927124023 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009860610938630998\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00861581414937973; that's 0.004979155492037535 for recalled reconstructions, 0.00021635669691022485 for normal images, and 3.4203014373779297 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009190461882390082\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.005983812268823385; that's 0.0020645451731979847 for recalled reconstructions, 0.00024568664957769215 for normal images, and 3.6735804080963135 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00860527437645942\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0062025608494877815; that's 0.0034531280398368835 for recalled reconstructions, 0.00021726118575315922 for normal images, and 2.5321717262268066 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008360504400916397\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004039822146296501; that's 3.649226188659668 text and 0.000390595814678818 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004092343773227185\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0020804584491997957; that's 0.0009658271446824074 task and 0.00020935684733558446 recon and 4.526371955871582 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023287730640731753\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010258251801133156; that's 0.006107507739216089 for recalled reconstructions, 0.00020421876979526132 for normal images, and 3.9465255737304688 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00902210053987801\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007088689133524895; that's 0.004221626557409763 for recalled reconstructions, 0.0002140708384104073 for normal images, and 2.652991533279419 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009204495083540678\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008025247603654861; that's 0.005433089565485716 for recalled reconstructions, 0.00020463978580664843 for normal images, and 2.3875181674957275 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008518768097274006\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009703783318400383; that's 0.006265757605433464 for recalled reconstructions, 0.00020577329269144684 for normal images, and 3.232252359390259 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.007910719644278287\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0037714126519858837; that's 3.1823456287384033 text and 0.0005890668835490942 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004521157569251954\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.013287127017974854; that's 0.009017816744744778 for recalled reconstructions, 0.00020986686286050826 for normal images, and 4.059442520141602 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009065135112032295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0029755409341305494; that's 0.0020215576514601707 task and 0.00021078069403301924 recon and 3.7160136699676514 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023571728041861207\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008290247060358524; that's 0.004622077569365501 for recalled reconstructions, 0.00020566147577483207 for normal images, and 3.462507724761963 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009592240685597062\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.006632104050368071; that's 0.002231524558737874 for recalled reconstructions, 0.00020788121037185192 for normal images, and 4.192698001861572 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009665273712016642\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009433927945792675; that's 0.005045980680733919 for recalled reconstructions, 0.00020033401960972697 for normal images, and 4.187613010406494 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009760956345126033\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0023866179399192333; that's 0.0012430092319846153 task and 0.0002109435445163399 recon and 4.663326740264893 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002225572784664109\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008053712546825409; that's 0.004600326996296644 for recalled reconstructions, 0.0002163635363103822 for normal images, and 3.2370223999023438 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009137001070193947\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004188105463981628; that's 3.4698598384857178 text and 0.0007182456902228296 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003958375256042927\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011711370199918747; that's 0.008500657044351101 for recalled reconstructions, 0.0002123410813510418 for normal images, and 2.9983720779418945 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009112578281201423\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009877934120595455; that's 0.007000219076871872 for recalled reconstructions, 0.00020497616787906736 for normal images, and 2.672738552093506 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008837536149658263\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010022377595305443; that's 0.005038860719650984 for recalled reconstructions, 0.00021617392485495657 for normal images, and 4.767342567443848 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008556031184270977\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.00349623360671103; that's 2.974024772644043 text and 0.00052220857469365 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004343985361047089\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.001832757261581719; that's 0.0009614423615857959 task and 0.00022093139705248177 recon and 3.251917600631714 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022876213979907334\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008553116582334042; that's 0.004882012959569693 for recalled reconstructions, 0.00021763629047200084 for normal images, and 3.4534671306610107 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.008947334792464972\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008925049565732479; that's 0.004881835076957941 for recalled reconstructions, 0.0002170483785448596 for normal images, and 3.8261656761169434 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009467459451407194\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0114972535520792; that's 0.006251396611332893 for recalled reconstructions, 0.00021788792219012976 for normal images, and 5.0279693603515625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00974088913295418\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009839963167905807; that's 0.00483218627050519 for recalled reconstructions, 0.00021229221601970494 for normal images, and 4.795485019683838 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009833901897072792\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0035203867591917515; that's 3.0931074619293213 text and 0.0004272792721167207 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004146075719036162\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010911190882325172; that's 0.005621735472232103 for recalled reconstructions, 0.0002047529851552099 for normal images, and 5.084702491760254 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009896332826465369\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002555683022364974; that's 0.0016259377589449286 task and 0.0002114391390932724 recon and 3.591531276702881 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002233314688783139\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007995356805622578; that's 0.0034684566780924797 for recalled reconstructions, 0.00020967588352505118 for normal images, and 4.317224025726318 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010054768742993474\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008237364701926708; that's 0.0028328686021268368 for recalled reconstructions, 0.000199390749912709 for normal images, and 5.205105304718018 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009431984559632837\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011262722313404083; that's 0.008311149664223194 for recalled reconstructions, 0.00020523928105831146 for normal images, and 2.746333360671997 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.0096872001234442\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0029448834247887135; that's 2.5342400074005127 text and 0.0004106433189008385 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035223545297048985\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0018209057161584496; that's 0.0010487250983715057 task and 0.00019835274724755436 recon and 2.8691394329071045 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002130305006867275\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008680520579218864; that's 0.003982684575021267 for recalled reconstructions, 0.00020945524738635868 for normal images, and 4.4883809089660645 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009786443770863115\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008418813347816467; that's 0.0035140258260071278 for recalled reconstructions, 0.00020357438188511878 for normal images, and 4.7012128829956055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009986947765573859\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00898872409015894; that's 0.0056099300272762775 for recalled reconstructions, 0.00021846035087946802 for normal images, and 3.1603336334228516 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010093176462687552\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00926002487540245; that's 0.005037414841353893 for recalled reconstructions, 0.00020298421441111714 for normal images, and 4.019625663757324 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009946334823034704\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.003434601239860058; that's 2.8511319160461426 text and 0.0005834691692143679 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0031469395500607787\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009831147268414497; that's 0.004640557337552309 for recalled reconstructions, 0.00020855286857113242 for normal images, and 4.982036113739014 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009917680989019573\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0017584763700142503; that's 0.0009265693952329457 task and 0.00020930796745233238 recon and 3.112995147705078 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020356378541328012\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011592254042625427; that's 0.006240464746952057 for recalled reconstructions, 0.00020669189689215273 for normal images, and 5.145096778869629 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009992202147841453\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009459429420530796; that's 0.005424773320555687 for recalled reconstructions, 0.00020284578204154968 for normal images, and 3.831810235977173 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010033053983934224\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009265013039112091; that's 0.005409968551248312 for recalled reconstructions, 0.00020986823074053973 for normal images, and 3.6451761722564697 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010135801425203681\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008233532309532166; that's 0.0041178688406944275 for recalled reconstructions, 0.00020832815789617598 for normal images, and 3.9073355197906494 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00953257702756673\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0022821156308054924; that's 0.00137850153259933 task and 0.00019875024736393243 recon and 3.5243191719055176 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002202742915833369\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.003600836731493473; that's 3.078150987625122 text and 0.0005226857610978186 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035199144924990835\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011474609375; that's 0.007845373824238777 for recalled reconstructions, 0.00023419156786985695 for normal images, and 3.3950436115264893 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009688563235104085\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009615961462259293; that's 0.004840437322854996 for recalled reconstructions, 0.00022074987646192312 for normal images, and 4.554774284362793 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00982558966614306\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.010026281699538231; that's 0.004625188186764717 for recalled reconstructions, 0.00021070073125883937 for normal images, and 5.190392971038818 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009943591984920204\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002595743630081415; that's 0.0013727942714467645 task and 0.00020689604571089149 recon and 5.080266952514648 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022634544607717543\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.005110905505716801; that's 4.587795257568359 text and 0.000523109920322895 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003989631042350084\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01386641152203083; that's 0.009222405962646008 for recalled reconstructions, 0.00020371584105305374 for normal images, and 4.440289497375488 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00999330950435251\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009832141920924187; that's 0.005181874614208937 for recalled reconstructions, 0.00020186057372484356 for normal images, and 4.448406219482422 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009909604638814927\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0075403666123747826; that's 0.003434608457610011 for recalled reconstructions, 0.0002027979353442788 for normal images, and 3.9029595851898193 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010138568291440607\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0066611869260668755; that's 0.0028855309356004 for recalled reconstructions, 0.000223515133257024 for normal images, and 3.552140951156616 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009787191050127148\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0018174450378865004; that's 0.001008756342343986 task and 0.00021333672339096665 recon and 2.976759433746338 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023718532477505507\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007196062244474888; that's 0.0034089938271790743 for recalled reconstructions, 0.00020548311294987798 for normal images, and 3.581585168838501 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010037189219146966\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0031801857985556126; that's 2.534633159637451 text and 0.0006455524708144367 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004399958446156233\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009870287030935287; that's 0.00472361920401454 for recalled reconstructions, 0.00021437651594169438 for normal images, and 4.932291507720947 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.0096037642005831\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011189436540007591; that's 0.005734079051762819 for recalled reconstructions, 0.00021430518245324492 for normal images, and 5.241052627563477 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009638515301048756\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007284538820385933; that's 0.004017950501292944 for recalled reconstructions, 0.00020874832989647985 for normal images, and 3.057839870452881 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009178195833228528\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002985425293445587; that's 0.002074152696877718 task and 0.0002054625074379146 recon and 3.529050827026367 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022669733071234077\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0037103507202118635; that's 3.054135799407959 text and 0.0006562148337252438 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004076738813892007\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009763607755303383; that's 0.005807457957416773 for recalled reconstructions, 0.00020873431640211493 for normal images, and 3.747415065765381 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009800291955471038\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009122331626713276; that's 0.005748262628912926 for recalled reconstructions, 0.00020959369430784136 for normal images, and 3.164475202560425 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009700005264021457\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009926654398441315; that's 0.005586543120443821 for recalled reconstructions, 0.0001972544996533543 for normal images, and 4.142857074737549 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010089319772087038\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009348844178020954; that's 0.006219064351171255 for recalled reconstructions, 0.00020789200789295137 for normal images, and 2.9218878746032715 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00969675433356315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002399487653747201; that's 0.0013588381698355079 task and 0.00022095524764154106 recon and 4.098471164703369 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022710486268624664\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0035884613171219826; that's 3.167062282562256 text and 0.00042139890138059855 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004259783080779016\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007566426880657673; that's 0.003405152354389429 for recalled reconstructions, 0.0002014150086324662 for normal images, and 3.9598588943481445 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009791993126273156\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00943436473608017; that's 0.005330032203346491 for recalled reconstructions, 0.0002152471715817228 for normal images, and 3.889085531234741 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009932454666122794\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012413352727890015; that's 0.006982737686485052 for recalled reconstructions, 0.0001961074594873935 for normal images, and 5.234506607055664 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010208269264549017\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008762870915234089; that's 0.005021532066166401 for recalled reconstructions, 0.00020386173855513334 for normal images, and 3.5374770164489746 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009648559894412757\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002275108825415373; that's 0.001180322957225144 task and 0.00020497231162153184 recon and 4.449067115783691 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022304967534728347\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.005216642748564482; that's 0.0014228001236915588 for recalled reconstructions, 0.00019570755830500275 for normal images, and 3.598134994506836 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009895970495417714\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004433781374245882; that's 3.9525651931762695 text and 0.00048121585859917104 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004105550949461758\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00818030908703804; that's 0.003248049644753337 for recalled reconstructions, 0.0002169575309380889 for normal images, and 4.715301513671875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009460723963566125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00815532635897398; that's 0.0038885031826794147 for recalled reconstructions, 0.00019603031978476793 for normal images, and 4.0707926750183105 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010094324802048504\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007677953224629164; that's 0.003441289998590946 for recalled reconstructions, 0.0002078739635180682 for normal images, and 4.028789043426514 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009529999364167452\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002078479155898094; that's 0.0008951626950874925 task and 0.00021528484649024904 recon and 4.840157985687256 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023279564129188657\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.012813413515686989; that's 0.00792023353278637 for recalled reconstructions, 0.00022008274390827864 for normal images, and 4.673097133636475 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.0103404161054641\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0049553182907402515; that's 4.354997634887695 text and 0.0006003202288411558 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004448044875171035\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.013485657051205635; that's 0.008716515265405178 for recalled reconstructions, 0.0002181563468184322 for normal images, and 4.550984859466553 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010116807026788592\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.01138274371623993; that's 0.006264649331569672 for recalled reconstructions, 0.0002044028224190697 for normal images, and 4.913690567016602 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009791982998140157\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.007937883958220482; that's 0.004378866404294968 for recalled reconstructions, 0.00020709521777462214 for normal images, and 3.351921796798706 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009230598211288452\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.004140788223594427; that's 3.3563435077667236 text and 0.0007844447391107678 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004191626894753426\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.001925152144394815; that's 0.0009509233641438186 task and 0.00021736031339969486 recon and 3.7843427658081055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00219690939062275\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.011224874295294285; that's 0.006213536951690912 for recalled reconstructions, 0.00021717707568313926 for normal images, and 4.79416036605835 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009383592186495662\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008689981885254383; that's 0.004216483794152737 for recalled reconstructions, 0.00020229131041560322 for normal images, and 4.271206855773926 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009515924691222609\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008093548938632011; that's 0.0046415794640779495 for recalled reconstructions, 0.00022470473777502775 for normal images, and 3.227264881134033 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009253564313985408\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0073569901287555695; that's 0.0034288272727280855 for recalled reconstructions, 0.0002034723584074527 for normal images, and 3.7246901988983154 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009746746085584164\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.00404547480866313; that's 3.400545597076416 text and 0.0006449290085583925 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00445487406803295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.002291216282173991; that's 0.0011362498626112938 task and 0.00021695585746783763 recon and 4.6900529861450195 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023256266803946346\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.00872714165598154; that's 0.005071242339909077 for recalled reconstructions, 0.0002030506293522194 for normal images, and 3.452848434448242 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.010018172208219767\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.009045466780662537; that's 0.0042134784162044525 for recalled reconstructions, 0.00020317977759987116 for normal images, and 4.628808498382568 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009384078551083802\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0067073628306388855; that's 0.0038877229671925306 for recalled reconstructions, 0.00021924171596765518 for normal images, and 2.600398063659668 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00981724246405065\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0064354557543993; that's 0.0036158638540655375 for recalled reconstructions, 0.00020549110195133835 for normal images, and 2.614100694656372 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.009319196562282741\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.0022697022650390863; that's 0.0011978771071881056 task and 0.0002125633618561551 recon and 4.296309471130371 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022169941826723515\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total recon loss: 0.0037815291434526443; that's 3.5120644569396973 text and 0.0002694643917493522 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003941307493951171\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total loss: 0.008987842127680779; that's 0.0032990111503750086 for recalled reconstructions, 0.00022906331287231296 for normal images, and 5.4597673416137695 total text\n",
      "\n",
      "\n",
      "Average total loss for task 3, last 100 batches: 0.00974605567753315\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f9ea00aaae0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/atbolsh/anaconda3/envs/player/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m reset_model \u001b[38;5;241m=\u001b[39m (b \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     17\u001b[0m printing \u001b[38;5;241m=\u001b[39m ((batch_num \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m99\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m full_results \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprinting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprinting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m L \u001b[38;5;241m=\u001b[39m full_results[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# no need to look into the detailed loss report\u001b[39;00m\n\u001b[1;32m     20\u001b[0m total_losses[ind] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m L\n",
      "File \u001b[0;32m~/Player/tutorial1_framework.py:107\u001b[0m, in \u001b[0;36marrow_task_batch\u001b[0;34m(batch_size, model, optimizer, batch_num, compute_grad, random_order, model_eval, reset_model, printing, training)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21marrow_task_batch\u001b[39m(batch_size, model, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, batch_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, compute_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reset_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, printing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compute_grad:\n\u001b[0;32m--> 107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_arrow_task_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprinting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m training:\n",
      "File \u001b[0;32m~/Player/tutorial1_framework.py:76\u001b[0m, in \u001b[0;36m_arrow_task_batch\u001b[0;34m(batch_size, model, optimizer, batch_num, random_order, model_eval, reset_model, printing, training)\u001b[0m\n\u001b[1;32m     72\u001b[0m     flip \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# do not need to set create_context; it's always true here, since we're return images\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     task_probs, task_recon \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mret_imgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     control_probs, control_recon \u001b[38;5;241m=\u001b[39m model(control_texts, inp, ret_imgs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Player/visual_transformer/enhanced_model.py:147\u001b[0m, in \u001b[0;36mEnhancedAgentBrain.forward\u001b[0;34m(self, text_batch, img_batch, ret_imgs, return_full, use_masks, create_context, ret_dopamine)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext \u001b[38;5;241m=\u001b[39m tensor_context\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# now that we have built the shared representation, we use it\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m text_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text_decoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_encoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_full\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mremember(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem_enc(text_encoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext)) \u001b[38;5;66;03m# always store it in memory; no step should be forgotten\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m create_context:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# For images and memory, the text_encoding can be added to context (in fact, *must* be)\u001b[39;00m\n",
      "File \u001b[0;32m~/Player/visual_transformer/enhanced_model.py:99\u001b[0m, in \u001b[0;36mEnhancedAgentBrain.get_text_decoding\u001b[0;34m(self, text_encoding, src_attention_mask, src_key_padding_mask, context, return_full)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_text_decoding\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_encoding, src_attention_mask, src_key_padding_mask, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_full\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_dec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_encoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_full\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Player/visual_transformer/model.py:205\u001b[0m, in \u001b[0;36mSentenceTransformerDecoder.forward\u001b[0;34m(self, x, context, return_full, tgt_mask, tgt_key_padding_mask, memory_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    203\u001b[0m     memory_mask \u001b[38;5;241m=\u001b[39m tgt_mask\n\u001b[1;32m    204\u001b[0m     memory_key_padding_mask \u001b[38;5;241m=\u001b[39m memory_key_padding_mask\n\u001b[0;32m--> 205\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_full:\n\u001b[1;32m    207\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/transformer.py:602\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    599\u001b[0m tgt_is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 602\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/transformer.py:1087\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m   1084\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x))\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1086\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[0;32m-> 1087\u001b[0m         x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1088\u001b[0m     )\n\u001b[1;32m   1089\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(\n\u001b[1;32m   1090\u001b[0m         x\n\u001b[1;32m   1091\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mha_block(\n\u001b[1;32m   1092\u001b[0m             x, memory, memory_mask, memory_key_padding_mask, memory_is_causal\n\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m     )\n\u001b[1;32m   1095\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/transformer.py:1107\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1102\u001b[0m     x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1107\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/modules/activation.py:1368\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1343\u001b[0m         query,\n\u001b[1;32m   1344\u001b[0m         key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/functional.py:6097\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[1;32m   6094\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   6095\u001b[0m         in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   6096\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6097\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6098\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6099\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   6100\u001b[0m         q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   6101\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/player/lib/python3.12/site-packages/torch/nn/functional.py:5501\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   5498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m v:\n\u001b[1;32m   5499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m q \u001b[38;5;129;01mis\u001b[39;00m k:\n\u001b[1;32m   5500\u001b[0m         \u001b[38;5;66;03m# self-attention\u001b[39;00m\n\u001b[0;32m-> 5501\u001b[0m         proj \u001b[38;5;241m=\u001b[39m \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5502\u001b[0m         \u001b[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[1;32m   5503\u001b[0m         proj \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   5504\u001b[0m             proj\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m3\u001b[39m, E))\n\u001b[1;32m   5505\u001b[0m             \u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5508\u001b[0m             \u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m   5509\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_batches = 10000*100#6250*32\n",
    "\n",
    "for b in range(total_batches):\n",
    "    secs_to_cool = monitor_stage(device)\n",
    "    if secs_to_cool > 0:\n",
    "        print(f\"Had to cool device for {secs_to_cool} seconds\\n\")\n",
    "        \n",
    "    triplet, _, ind = rb.random_draw()\n",
    "    func, opt, batch_size = triplet\n",
    "    \n",
    "    batch_num = batches[ind]\n",
    "    batches[ind] += 1\n",
    "\n",
    "    #reset_model = True #default option; only transfer memory within the task files\n",
    "    reset_model = (b % 3 == 2)\n",
    "\n",
    "    printing = ((batch_num % 100) == 99)\n",
    "    full_results = func(batch_size, brain, optimizer=opt, batch_num=batch_num, compute_grad=True, random_order=True, model_eval=False, reset_model=reset_model, printing=printing, training=True)\n",
    "    L = full_results[0] # no need to look into the detailed loss report\n",
    "    total_losses[ind] += L\n",
    "\n",
    "    if printing: # if this is a significant batch\n",
    "        avg_loss = total_losses[ind] / 100\n",
    "        total_losses[ind] = 0\n",
    "        print(f\"Average total loss for task {ind}, last 100 batches: {avg_loss}\\n\\n\\n\\n\")\n",
    "        \n",
    "        if avg_loss < curr_mins[ind]:\n",
    "            curr_mins[ind] = avg_loss\n",
    "            torch.save(brain.state_dict(), f\"brain_checkpoints/enhanced_brain_canvas_use_v3_batch{b + 1}.pth\")\n",
    "            \n",
    "    if b < 10:\n",
    "        print(f\"batch {b}, task {ind}, task batch_num {batch_num}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb7c96-0ce6-4e96-99a6-0a2cddfd5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates: add sampling weights; add batch_num to print statement; split these two optimizers and optimize them separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82cb545-7d75-492b-84a2-7cd0f532f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abcce85-d400-45bc-8aa1-2a36da0746e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
