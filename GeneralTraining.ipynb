{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f5bd94-74fb-4588-b47b-273035eb2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from control_framework import *\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "from mem_canvas_use_framework import *\n",
    "from mem_canvas_use_CHEAP_framework import *\n",
    "from blue_line_QA_framework import *\n",
    "\n",
    "from temp_recorder import *\n",
    "\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "#device = torch.device('cuda:0')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823f8c1-608a-4865-aeca-1458b0610761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335c011-7512-4fde-bf66-16bdb5591fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245931c-72c7-470f-9e6e-2f6de6e1c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_display(torch_img):\n",
    "    clean = torch_img.detach().cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c25d90-1bdd-46b4-ae86-a6e8170070d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = EnhancedAgentBrain()\n",
    "brain.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_batch10000.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_v2_batch160799.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v1_batch16600.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v2_batch55900.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v1_batch1199.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v2_batch24800.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v3_batch155466.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v4_batch399.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v5_batch133.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_v1_batch14250.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_v2_batch29398.pth'\n",
    "#fname = 'brain_checkpoints/super_brain_transferred_weights.pth'\n",
    "#fname = 'brain_checkpoints/super_brain_retraining_control_arrow_v1_batch33400.pth'\n",
    "#fname = 'brain_checkpoints/super_brain_retraining_control_arrow_RESTART_v1_batch31799.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_transferred.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_canvases_v1_batch33597.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_canvases_v2_batch25999.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_canvases_v3_batch19998.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v2_batch9996.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v6_batch10993.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v8_batch13196.pth'\n",
    "fname = 'brain_checkpoints/frankenstein_blueLineDirection_v1_batch34120.pth'\n",
    "\n",
    "# A little extra code to avoid weird error\n",
    "#brain.memory.remember(torch.randn(16, 1, 768).to(device))\n",
    "brain.memory.remember(torch.randn(8, 1, 768).to(device))\n",
    "\n",
    "brain.load_state_dict(torch.load(fname, weights_only=True, map_location=device))\n",
    "brain.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a4389-e113-4dc7-bf96-7538570644e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optimizer = optim.Adam(brain.parameters(), lr=0.00001, eps=1e-9)\n",
    "lo_lr_optimizer = optim.Adam(brain.parameters(), lr = 1e-6, eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522ad35-e749-4b70-a282-f4489bd4069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should possibly also include mem_enc? Should just be gen_optimizer? \n",
    "# ONLY use this in sessions where this is the only optimizer.\n",
    "# General optimizer gets messed up if this is used\n",
    "#text_optimizer = optim.Adam(list(brain.text_enc.parameters()) + list(brain.text_dec.parameters()), lr=0.00001, eps=1e-9)\n",
    "text_optimizer = optim.Adam(brain.text_dec.parameters(), lr=0.00001, eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dedeb05-aeef-4cc0-8c32-41e4c74f92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful to randomize the order in which the tasks are trained\n",
    "class ReusableBuffer:\n",
    "    def __init__(self, L, repetitions):\n",
    "        self.L = []\n",
    "        self.true_inds = []\n",
    "        for i in range(len(L)):\n",
    "            for j in range(repetitions[i]):\n",
    "                self.L.append(L[i])\n",
    "                self.true_inds.append(i)\n",
    "        self.inds = list(range(len(self.L))) # could be longer or shorter than input L\n",
    "\n",
    "    def draw(self, ind):\n",
    "        return self.L[ind]\n",
    "\n",
    "    def random_draw(self):\n",
    "        ind_ind = random.randint(0, len(self.inds)-1)\n",
    "        ind = self.inds[ind_ind]\n",
    "        if ind_ind == (len(self.inds) - 1):\n",
    "            self.inds = self.inds[:-1]\n",
    "        else:\n",
    "            self.inds = self.inds[:ind_ind] + self.inds[ind_ind + 1:]\n",
    "        if len(self.inds) == 0:\n",
    "            self.inds = list(range(len(self.L)))\n",
    "        return self.L[ind], ind, self.true_inds[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8113bf0-e27a-4964-b993-1511284e05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for first task (and really anywhere I want to not reset between tasks)\n",
    "# make sure the batch size matches\n",
    "# add further functions in the firs list, and add their repetition number to the second list\n",
    "#batch_size = 16\n",
    "global_batch_size = 8\n",
    "default_optimizer = lo_lr_optimizer\n",
    "rb = ReusableBuffer([(arrow_task_batch, default_optimizer, global_batch_size), \\\n",
    "                     (qa_task_batch, default_optimizer, global_batch_size), \\\n",
    "                     (qa_task_batch, text_optimizer, 2*global_batch_size), \\\n",
    "                     (control_batch, default_optimizer, global_batch_size), \\\n",
    "                     (mem_canvas_batch, default_optimizer, 6), \\\n",
    "                     (mem_canvas_CHEAP_batch, default_optimizer, global_batch_size),\n",
    "                     (blue_line_direction_batch, default_optimizer, global_batch_size)], \\\n",
    "                    [8, 4, 0, 4, 4, 4, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0bf3cd-1207-4726-8983-3708c97ba125",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcade85-fe40-4a68-b137-4c94c737614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_mins = [1000.0, 1000.0, 1000.0, 1000.0, 1.0e6, 1.0e6, 1.0e6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6fc04a-8056-41bd-85c0-7e60970a13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_losses = [0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88167a4b-dd8d-43e6-b4ae-8f77c51adaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f64af-1ff3-4f80-804b-17b8488af2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# I'll find the place that causes the 'non in-place resize later; for now, I don't want to clutter the results'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d1940-ba13-4da2-bb5f-b1af6d45d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batches = 10000*100#6250*32\n",
    "\n",
    "for b in range(total_batches):\n",
    "    secs_to_cool = monitor_stage(device)\n",
    "    if secs_to_cool > 0:\n",
    "        print(f\"Had to cool device for {secs_to_cool} seconds\\n\")\n",
    "        \n",
    "    triplet, _, ind = rb.random_draw()\n",
    "    func, opt, batch_size = triplet\n",
    "    \n",
    "    batch_num = batches[ind]\n",
    "    batches[ind] += 1\n",
    "\n",
    "    #reset_model = True #default option; only transfer memory within the task files\n",
    "    reset_model = (b % 3 == 2)\n",
    "    if batch_size != global_batch_size:\n",
    "        brain.reset() # prevents bad memory and canvas problems; do this before and after calling func\n",
    "\n",
    "    printing = ((batch_num % 100) == 99)\n",
    "    full_results = func(batch_size, brain, optimizer=opt, batch_num=batch_num, compute_grad=True, random_order=True, model_eval=False, reset_model=reset_model, printing=printing, training=True)\n",
    "    L = full_results[0] # no need to look into the detailed loss report\n",
    "    total_losses[ind] += L\n",
    "\n",
    "    if batch_size != global_batch_size:\n",
    "        brain.reset() # prevents bad memory and canvas problems\n",
    "    \n",
    "    if printing: # if this is a significant batch\n",
    "        avg_loss = total_losses[ind] / 100\n",
    "        total_losses[ind] = 0\n",
    "        print(f\"Average total loss for task {ind}, last 100 batches: {avg_loss}\\n=================================================\\n\\n\\n\")\n",
    "        \n",
    "        if avg_loss < curr_mins[ind]:\n",
    "            curr_mins[ind] = avg_loss\n",
    "            print(f\"Saving at batch {b + 1}\\n=======================================\\n\\n\\n\")\n",
    "            torch.save(brain.state_dict(), f\"brain_checkpoints/frankenstein_blueLineDirection_v2_batch{b + 1}.pth\")\n",
    "            \n",
    "    if b < 10:\n",
    "        print(f\"batch {b}, task {ind}, task batch_num {batch_num}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb7c96-0ce6-4e96-99a6-0a2cddfd5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates: add sampling weights; add batch_num to print statement; split these two optimizers and optimize them separately"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
