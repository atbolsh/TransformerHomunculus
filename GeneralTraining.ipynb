{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f5bd94-74fb-4588-b47b-273035eb2345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from control_framework import *\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "from temp_recorder import *\n",
    "\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "#device = torch.device('cuda:0')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6823f8c1-608a-4865-aeca-1458b0610761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4335c011-7512-4fde-bf66-16bdb5591fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fae2e8cf0e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4245931c-72c7-470f-9e6e-2f6de6e1c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_display(torch_img):\n",
    "    clean = torch_img.detach().cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c25d90-1bdd-46b4-ae86-a6e8170070d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain = EnhancedAgentBrain()\n",
    "brain.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_batch10000.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_v2_batch160799.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v1_batch16600.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v2_batch55900.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v1_batch1199.pth'\n",
    "fname = 'brain_checkpoints/enhanced_brain_arrow_task_v2_batch24800.pth'\n",
    "\n",
    "# A little extra code to avoid weird error\n",
    "brain.memory.remember(torch.randn(16, 1, 768).to(device))\n",
    "\n",
    "brain.load_state_dict(torch.load(fname, weights_only=True, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6a4389-e113-4dc7-bf96-7538570644e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optimizer = optim.Adam(brain.parameters(), lr=0.00001, eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c522ad35-e749-4b70-a282-f4489bd4069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should possibly also include mem_enc? Should just be gen_optimizer? \n",
    "# ONLY use this in sessions where this is the only optimizer.\n",
    "# General optimizer gets messed up if this is used\n",
    "text_optimizer = optim.Adam(list(brain.text_enc.parameters()) + list(brain.text_dec.parameters()), lr=0.00001, eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dedeb05-aeef-4cc0-8c32-41e4c74f92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful to randomize the order in which the tasks are trained\n",
    "class ReusableBuffer:\n",
    "    def __init__(self, L, repetitions):\n",
    "        self.L = []\n",
    "        self.true_inds = []\n",
    "        for i in range(len(L)):\n",
    "            for j in range(repetitions[i]):\n",
    "                self.L.append(L[i])\n",
    "                self.true_inds.append(i)\n",
    "        self.inds = list(range(len(self.L))) # could be longer or shorter than input L\n",
    "\n",
    "    def draw(self, ind):\n",
    "        return self.L[ind]\n",
    "\n",
    "    def random_draw(self):\n",
    "        ind_ind = random.randint(0, len(self.inds)-1)\n",
    "        ind = self.inds[ind_ind]\n",
    "        if ind_ind == (len(self.inds) - 1):\n",
    "            self.inds = self.inds[:-1]\n",
    "        else:\n",
    "            self.inds = self.inds[:ind_ind] + self.inds[ind_ind + 1:]\n",
    "        if len(self.inds) == 0:\n",
    "            self.inds = list(range(len(self.L)))\n",
    "        return self.L[ind], ind, self.true_inds[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8113bf0-e27a-4964-b993-1511284e05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for first task (and really anywhere I want to not reset between tasks)\n",
    "# make sure the batch size matches\n",
    "# add further functions in the firs list, and add their repetition number to the second list\n",
    "rb = ReusableBuffer([(arrow_task_batch, gen_optimizer, 16), \\\n",
    "                     (qa_task_batch, gen_optimizer, 16), \\\n",
    "                     (control_batch, gen_optimizer, 16)], \\\n",
    "                    [3, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d0bf3cd-1207-4726-8983-3708c97ba125",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fcade85-fe40-4a68-b137-4c94c737614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_mins = [1000.0, 1000.0, 1000.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea6fc04a-8056-41bd-85c0-7e60970a13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_losses = [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88167a4b-dd8d-43e6-b4ae-8f77c51adaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e62f64af-1ff3-4f80-804b-17b8488af2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# I'll find the place that causes the 'non in-place resize later; for now, I don't want to clutter the results'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c1d1940-ba13-4da2-bb5f-b1af6d45d7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, task 0, task batch_num 0\n",
      "\n",
      "batch 1, task 0, task batch_num 1\n",
      "\n",
      "batch 2, task 0, task batch_num 2\n",
      "\n",
      "batch 3, task 2, task batch_num 0\n",
      "\n",
      "batch 4, task 0, task batch_num 3\n",
      "\n",
      "batch 5, task 0, task batch_num 4\n",
      "\n",
      "batch 6, task 2, task batch_num 1\n",
      "\n",
      "batch 7, task 0, task batch_num 5\n",
      "\n",
      "batch 8, task 2, task batch_num 2\n",
      "\n",
      "batch 9, task 0, task batch_num 6\n",
      "\n",
      "Total loss: 0.004619971849024296; that's 0.0035834205336868763 task and 0.0004004405636806041 recon and 3.180553436279297 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004915425032377243\n",
      "\n",
      "Total loss: 0.00477561354637146; that's 0.0036068707704544067 task and 0.00041783705819398165 recon and 3.754530429840088 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004791974548716098\n",
      "\n",
      "Total recon loss: 0.0035838782787323; that's 2.7180943489074707 text and 0.0008657838916406035 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004668907541781664\n",
      "\n",
      "Total loss: 0.005890343338251114; that's 0.004409030079841614 task and 0.000421319215092808 recon and 5.299971103668213 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004993205426726491\n",
      "\n",
      "Total loss: 0.004234375432133675; that's 0.0028969866689294577 task and 0.0004129076551180333 recon and 4.622406005859375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004966374945361167\n",
      "\n",
      "Total loss: 0.005108792334794998; that's 0.0036885421723127365 task and 0.0003938496229238808 recon and 5.132003307342529 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004965654895640909\n",
      "\n",
      "Total loss: 0.005445440765470266; that's 0.004217054694890976 task and 0.0004066824330948293 recon and 4.108517646789551 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005045505731832236\n",
      "\n",
      "Total recon loss: 0.004039154388010502; that's 3.3162841796875 text and 0.0007228699396364391 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0041231536981649695\n",
      "\n",
      "Total loss: 0.005066983867436647; that's 0.0035744463093578815 task and 0.000447257625637576 recon and 5.226400375366211 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00498792267870158\n",
      "\n",
      "Total loss: 0.005391720682382584; that's 0.003908870741724968 task and 0.00040264628478325903 recon and 5.401018142700195 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004939528158865869\n",
      "\n",
      "Total loss: 0.005467860959470272; that's 0.003969921264797449 task and 0.0004023733490612358 recon and 5.477832317352295 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005050343009643256\n",
      "\n",
      "Total recon loss: 0.0053703621961176395; that's 4.692780494689941 text and 0.0006775813526473939 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005092644889373332\n",
      "\n",
      "Total loss: 0.005229289177805185; that's 0.004019744228571653 task and 0.0004014002624899149 recon and 4.0407233238220215 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004866425213404\n",
      "\n",
      "Total loss: 0.004023365676403046; that's 0.0026793864089995623 task and 0.0004022570210509002 recon and 4.7086100578308105 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004998421538621187\n",
      "\n",
      "Total recon loss: 0.004863436333835125; that's 4.164999008178711 text and 0.0006984368665143847 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005109530370682478\n",
      "\n",
      "Total loss: 0.005172692239284515; that's 0.0038149708416312933 task and 0.00039757831837050617 recon and 4.800717830657959 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.005052267936989665\n",
      "\n",
      "Total loss: 0.00554246548563242; that's 0.004260567016899586 task and 0.00038686851621605456 recon and 4.4751482009887695 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004902729135937989\n",
      "\n",
      "Total loss: 0.004625589586794376; that's 0.003394581377506256 task and 0.0003931787796318531 recon and 4.189146518707275 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004950155424885452\n",
      "\n",
      "Total recon loss: 0.00520533649250865; that's 4.4643683433532715 text and 0.0007409682148136199 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005077713574282825\n",
      "\n",
      "Total loss: 0.004741678014397621; that's 0.00347967934794724 task and 0.0003890542720910162 recon and 4.3647236824035645 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004885148017201572\n",
      "\n",
      "Total loss: 0.00483910646289587; that's 0.0035310841631144285 task and 0.00039474215009249747 recon and 4.566400051116943 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004832912820857019\n",
      "\n",
      "Total loss: 0.003738709492608905; that's 0.0024209367111325264 task and 0.00038851224235258996 recon and 4.646303176879883 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004862623361404985\n",
      "\n",
      "Total recon loss: 0.004266674164682627; that's 3.35494065284729 text and 0.0009117334266193211 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0050222486583516\n",
      "\n",
      "Total loss: 0.004389500245451927; that's 0.0031431373208761215 task and 0.0003798190737143159 recon and 4.332719802856445 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004933623117394746\n",
      "\n",
      "Total loss: 0.003756868187338114; that's 0.0024398949462920427 task and 0.0003913013788405806 recon and 4.628358840942383 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0049689080193638805\n",
      "\n",
      "Total loss: 0.005447314120829105; that's 0.004058129154145718 task and 0.0003863211895804852 recon and 5.014320373535156 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004925780990161002\n",
      "\n",
      "Total loss: 0.004894542973488569; that's 0.003648032434284687 task and 0.000386205647373572 recon and 4.301525115966797 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0049936034996062514\n",
      "\n",
      "Total recon loss: 0.005620453506708145; that's 4.929129600524902 text and 0.0006913237739354372 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004878667311277241\n",
      "\n",
      "Total loss: 0.004720072261989117; that's 0.0035698190331459045 task and 0.00037845943006686866 recon and 3.85896897315979 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004891499523073435\n",
      "\n",
      "Total loss: 0.004689609631896019; that's 0.0031812177039682865 task and 0.0003813036310020834 recon and 5.635441780090332 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004937816439196468\n",
      "\n",
      "Total recon loss: 0.005572620779275894; that's 4.941155433654785 text and 0.0006314651691354811 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004984640735201538\n",
      "\n",
      "Total loss: 0.004808097146451473; that's 0.003723820438608527 task and 0.0003854481619782746 recon and 3.49414324760437 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004899445176124573\n",
      "\n",
      "Total loss: 0.004709349945187569; that's 0.003605693345889449 task and 0.0003804680600296706 recon and 3.615943431854248 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004797462308779359\n",
      "\n",
      "Total loss: 0.004979787394404411; that's 0.003702311310917139 task and 0.00038835417944937944 recon and 4.445610523223877 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004810459185391664\n",
      "\n",
      "Total recon loss: 0.005632065236568451; that's 4.969008922576904 text and 0.0006630562129430473 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0052452673995867375\n",
      "\n",
      "Total loss: 0.005773384589701891; that's 0.004452456254512072 task and 0.0003858538984786719 recon and 4.675372123718262 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004940330004319549\n",
      "\n",
      "Total loss: 0.004811840131878853; that's 0.003327104961499572 task and 0.0003776009543798864 recon and 5.535670280456543 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004953336813487113\n",
      "\n",
      "Total loss: 0.004939185921102762; that's 0.0037155020982027054 task and 0.00038828252581879497 recon and 4.177006721496582 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0048751899786293506\n",
      "\n",
      "Total recon loss: 0.0043299077078700066; that's 3.548691511154175 text and 0.000781215843744576 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004546656357124448\n",
      "\n",
      "Total loss: 0.0056019555777311325; that's 0.0043306672014296055 task and 0.00040315010119229555 recon and 4.340691566467285 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004907565950416029\n",
      "\n",
      "Total loss: 0.004880282562226057; that's 0.0036459434777498245 task and 0.0003669045399874449 recon and 4.33717155456543 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004823488758411258\n",
      "\n",
      "Total loss: 0.004190781619399786; that's 0.0031226202845573425 task and 0.00038311700336635113 recon and 3.4252207279205322 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0048352224752306935\n",
      "\n",
      "Total recon loss: 0.005182175897061825; that's 4.345308780670166 text and 0.0008368671406060457 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005147888388019055\n",
      "\n",
      "Total loss: 0.004987041931599379; that's 0.003835542593151331 task and 0.0003785936569329351 recon and 3.864527463912964 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0046175933349877595\n",
      "\n",
      "Total loss: 0.004413096234202385; that's 0.0031246331054717302 task and 0.00038449096609838307 recon and 4.519862174987793 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0048111431230790916\n",
      "\n",
      "Total loss: 0.00427952129393816; that's 0.003060820046812296 task and 0.00036786386044695973 recon and 4.254188060760498 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004847546895034611\n",
      "\n",
      "Total recon loss: 0.004935900680720806; that's 4.292331218719482 text and 0.0006435691029764712 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005282148392871023\n",
      "\n",
      "Total loss: 0.005389031022787094; that's 0.0039034481160342693 task and 0.00038216906250454485 recon and 5.517067909240723 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004934858032502234\n",
      "\n",
      "Total loss: 0.004400423727929592; that's 0.003220659913495183 task and 0.0003663879178930074 recon and 4.066880226135254 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0049341775616630916\n",
      "\n",
      "Total loss: 0.004472116939723492; that's 0.00324849970638752 task and 0.0003650553117040545 recon and 4.292810440063477 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004722508452832699\n",
      "\n",
      "Total recon loss: 0.00485185207799077; that's 3.8390374183654785 text and 0.0010128144640475512 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00491937650134787\n",
      "\n",
      "Total loss: 0.004797760397195816; that's 0.003748029936105013 task and 0.00038191420026123524 recon and 3.3390815258026123 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004857969554141164\n",
      "\n",
      "Total loss: 0.004583549685776234; that's 0.003384736366569996 task and 0.0003720503009390086 recon and 4.133813858032227 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004763860492967069\n",
      "\n",
      "Total loss: 0.00427787471562624; that's 0.003109272103756666 task and 0.0003611414285842329 recon and 4.0373053550720215 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004737898912280798\n",
      "\n",
      "Total recon loss: 0.004077522549778223; that's 3.445305347442627 text and 0.0006322169792838395 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004647195436991752\n",
      "\n",
      "Total loss: 0.004167168866842985; that's 0.0030607411172240973 task and 0.000380255893105641 recon and 3.630859136581421 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004683356052264571\n",
      "\n",
      "Total loss: 0.005119691602885723; that's 0.00397845171391964 task and 0.00036859410465694964 recon and 3.863227605819702 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0046466379053890705\n",
      "\n",
      "Total loss: 0.004908371716737747; that's 0.0037278812378644943 task and 0.0003662350936792791 recon and 4.071277141571045 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004650313747115433\n",
      "\n",
      "Total recon loss: 0.0046949731186032295; that's 3.957836151123047 text and 0.0007371368119493127 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004774056151509285\n",
      "\n",
      "Total loss: 0.004061835817992687; that's 0.00290343863889575 task and 0.0003770668990910053 recon and 3.906651735305786 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004528538642916829\n",
      "\n",
      "Total loss: 0.004569117911159992; that's 0.0034314303193241358 task and 0.00037466632784344256 recon and 3.8151051998138428 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004563966242130846\n",
      "\n",
      "Total loss: 0.004933769814670086; that's 0.0036892059724777937 task and 0.0003675228508654982 recon and 4.385204315185547 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004526979697402567\n",
      "\n",
      "Total loss: 0.004656719509512186; that's 0.0036038144025951624 task and 0.00037524092476814985 recon and 3.388321876525879 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004497733120806515\n",
      "\n",
      "Total recon loss: 0.00472152978181839; that's 4.150050640106201 text and 0.0005714789149351418 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0047406566445715725\n",
      "\n",
      "Total loss: 0.004648515023291111; that's 0.003409041790291667 task and 0.0003828556218650192 recon and 4.283089637756348 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004559381841681897\n",
      "\n",
      "Total loss: 0.005296608433127403; that's 0.003921550698578358 task and 0.00036914783413521945 recon and 5.029548168182373 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004664481112267822\n",
      "\n",
      "Total recon loss: 0.0049014706164598465; that's 4.091724395751953 text and 0.0008097459212876856 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0046950913639739154\n",
      "\n",
      "Total loss: 0.005418802611529827; that's 0.0041236779652535915 task and 0.0003762712876778096 recon and 4.59426736831665 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0046353357052430514\n",
      "\n",
      "Total loss: 0.004986027721315622; that's 0.003704540431499481 task and 0.0003723208501469344 recon and 4.545831203460693 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004624032992869616\n",
      "\n",
      "Total loss: 0.0041957213543355465; that's 0.0029274593107402325 task and 0.00035855453461408615 recon and 4.5485382080078125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00465281852055341\n",
      "\n",
      "Total recon loss: 0.004345929715782404; that's 3.597238063812256 text and 0.0007486912654712796 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00495597611181438\n",
      "\n",
      "Total loss: 0.004161547869443893; that's 0.002537811640650034 task and 0.00037705665454268456 recon and 6.233398914337158 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004608298391103744\n",
      "\n",
      "Total loss: 0.005147736519575119; that's 0.003775650868192315 task and 0.0003658679488580674 recon and 5.031087398529053 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0045885878754779695\n",
      "\n",
      "Total loss: 0.005436678417026997; that's 0.004029721021652222 task and 0.00036429960164241493 recon and 5.213289260864258 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004563892129808665\n",
      "\n",
      "Total recon loss: 0.004650415387004614; that's 3.9846599102020264 text and 0.0006657554185949266 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004915832553524524\n",
      "\n",
      "Total loss: 0.0050834608264267445; that's 0.003685066709294915 task and 0.00035901134833693504 recon and 5.196913242340088 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004511708957143128\n",
      "\n",
      "Total loss: 0.005322203040122986; that's 0.0039061533752828836 task and 0.00036355183692649007 recon and 5.26248836517334 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004525864887982607\n",
      "\n",
      "Total loss: 0.004985154140740633; that's 0.003479632781818509 task and 0.00038277945714071393 recon and 5.613710403442383 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004531355956569314\n",
      "\n",
      "Total recon loss: 0.0052358428947627544; that's 4.549509048461914 text and 0.0006863336311653256 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004834873895160854\n",
      "\n",
      "Total loss: 0.004518802743405104; that's 0.003119417931884527 task and 0.000354459451045841 recon and 5.224626541137695 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004621914434246719\n",
      "\n",
      "Total loss: 0.004308175295591354; that's 0.0033055320382118225 task and 0.00037935844738967717 recon and 3.1164238452911377 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004270370078738778\n",
      "\n",
      "Total loss: 0.004221141338348389; that's 0.0030603406485170126 task and 0.00037508015520870686 recon and 3.928603410720825 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004315332781989128\n",
      "\n",
      "Total recon loss: 0.004603976383805275; that's 3.7813687324523926 text and 0.0008226076606661081 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004986644138116389\n",
      "\n",
      "Total loss: 0.004597880411893129; that's 0.0032457695342600346 task and 0.00037527704262174666 recon and 4.884169578552246 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004432546435855329\n",
      "\n",
      "Total loss: 0.003984036855399609; that's 0.002793246414512396 task and 0.0003725464048329741 recon and 4.091219425201416 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004339502048678696\n",
      "\n",
      "Total loss: 0.004359640181064606; that's 0.0032321985345333815 task and 0.000373671151464805 recon and 3.768853187561035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004207913083955645\n",
      "\n",
      "Total recon loss: 0.003909402526915073; that's 3.309950590133667 text and 0.000599451654125005 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004971066911239177\n",
      "\n",
      "Total loss: 0.0035802191123366356; that's 0.0025370153598487377 task and 0.000369646237231791 recon and 3.367788314819336 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004162489525042474\n",
      "\n",
      "Total loss: 0.0037687215954065323; that's 0.002642159117385745 task and 0.00038938329089432955 recon and 3.6858959197998047 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004177574731875211\n",
      "\n",
      "Total loss: 0.00403200788423419; that's 0.0029766298830509186 task and 0.00036128517240285873 recon and 3.4704651832580566 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0041753815137781205\n",
      "\n",
      "Total recon loss: 0.005894314032047987; that's 5.148484230041504 text and 0.0007458298350684345 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005227136444300413\n",
      "\n",
      "Total loss: 0.004364709369838238; that's 0.0032799537293612957 task and 0.00037582378718070686 recon and 3.544658899307251 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004028180399909615\n",
      "\n",
      "Total loss: 0.0039635710418224335; that's 0.0029328817036002874 task and 0.00035757850855588913 recon and 3.3655545711517334 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004122703936882317\n",
      "\n",
      "Total loss: 0.004137478768825531; that's 0.003009275533258915 task and 0.0003689549630507827 recon and 3.7962398529052734 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004132525259628892\n",
      "\n",
      "Total loss: 0.0043454766273498535; that's 0.0031087948009371758 task and 0.00036862929118797183 recon and 4.340263366699219 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004016066768672317\n",
      "\n",
      "Total recon loss: 0.003683340037241578; that's 3.0388851165771484 text and 0.0006444547907449305 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00491888452321291\n",
      "\n",
      "Total loss: 0.0037241734098643064; that's 0.0023444436956197023 task and 0.00037030995008535683 recon and 5.0470991134643555 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004013822239357978\n",
      "\n",
      "Total loss: 0.0038373786956071854; that's 0.002650923328474164 task and 0.00036671923589892685 recon and 4.0986809730529785 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004062944252509624\n",
      "\n",
      "Total recon loss: 0.003634215332567692; that's 2.983609676361084 text and 0.000650605361443013 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0043975507095456124\n",
      "\n",
      "Total loss: 0.00417654775083065; that's 0.0029794510919600725 task and 0.0003647995472420007 recon and 4.1614861488342285 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0040385516546666625\n",
      "\n",
      "Total loss: 0.0038183187134563923; that's 0.0026731216348707676 task and 0.00036061849095858634 recon and 3.9228925704956055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0040605078474618495\n",
      "\n",
      "Total loss: 0.004318447317928076; that's 0.0031468968372792006 task and 0.00037383922608569264 recon and 3.9885573387145996 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003903625188395381\n",
      "\n",
      "Total recon loss: 0.004793376196175814; that's 4.061314582824707 text and 0.0007320612785406411 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004835641826502979\n",
      "\n",
      "Total loss: 0.004303932189941406; that's 0.003188036847859621 task and 0.0003707949654199183 recon and 3.7255024909973145 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0038827871065586807\n",
      "\n",
      "Total loss: 0.004345862194895744; that's 0.0031736516393721104 task and 0.00036311609437689185 recon and 4.04547119140625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003897857896517962\n",
      "\n",
      "Total loss: 0.004425679799169302; that's 0.003291063942015171 task and 0.00037578842602670193 recon and 3.794138193130493 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003911567307077348\n",
      "\n",
      "Total recon loss: 0.0050005316734313965; that's 4.147438049316406 text and 0.0008530931081622839 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004789432450197637\n",
      "\n",
      "Total loss: 0.003638838417828083; that's 0.0025836951099336147 task and 0.00037058486486785114 recon and 3.4227921962738037 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004023581424262374\n",
      "\n",
      "Total loss: 0.004320050124078989; that's 0.0029022551607340574 task and 0.0003688572614919394 recon and 5.244688987731934 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.004034364898689091\n",
      "\n",
      "Total loss: 0.0040873014368116856; that's 0.0027523995377123356 task and 0.0003700937668327242 recon and 4.824039459228516 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003943261606618762\n",
      "\n",
      "Total recon loss: 0.005282313097268343; that's 4.6095099449157715 text and 0.0006728027947247028 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004777520417701453\n",
      "\n",
      "Total loss: 0.0031013917177915573; that's 0.0020042695105075836 task and 0.0003699912631418556 recon and 3.635655403137207 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003830105043016374\n",
      "\n",
      "Total loss: 0.0041900319047272205; that's 0.0029282316099852324 task and 0.00036811508471146226 recon and 4.468425750732422 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00392474360531196\n",
      "\n",
      "Total loss: 0.004153866786509752; that's 0.00265324953943491 task and 0.00036808158620260656 recon and 5.662678241729736 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00412724201567471\n",
      "\n",
      "Total recon loss: 0.0044417669996619225; that's 3.7212235927581787 text and 0.000720543204806745 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005140514897648245\n",
      "\n",
      "Total loss: 0.004256796557456255; that's 0.002903773682191968 task and 0.00037315397639758885 recon and 4.899345397949219 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0041833901172503825\n",
      "\n",
      "Total loss: 0.003946205135434866; that's 0.002659471705555916 task and 0.00037538178730756044 recon and 4.556759834289551 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00392665145220235\n",
      "\n",
      "Total loss: 0.0041878847405314445; that's 0.002678146818652749 task and 0.0003589155385270715 recon and 5.754110336303711 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003878785928245634\n",
      "\n",
      "Total recon loss: 0.004670191090553999; that's 3.820570707321167 text and 0.0008496202062815428 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005050760337617248\n",
      "\n",
      "Total loss: 0.004288128111511469; that's 0.003013772889971733 task and 0.0003648814745247364 recon and 4.54736852645874 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003952417310792953\n",
      "\n",
      "Total loss: 0.003838623408228159; that's 0.0025521174538880587 task and 0.00037012732354924083 recon and 4.581892490386963 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0038377273571677506\n",
      "\n",
      "Total loss: 0.0038001632783561945; that's 0.0025220580864697695 task and 0.00036747445119544864 recon and 4.5531535148620605 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0038448698143474756\n",
      "\n",
      "Total loss: 0.004063997883349657; that's 0.002859534230083227 task and 0.0003674580657389015 recon and 4.185029029846191 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0037883909116499127\n",
      "\n",
      "Total recon loss: 0.004265887662768364; that's 3.544428586959839 text and 0.0007214589859358966 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004935374467168003\n",
      "\n",
      "Total loss: 0.004303285386413336; that's 0.002894066274166107 task and 0.0003729467571247369 recon and 5.181362152099609 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003860318122897297\n",
      "\n",
      "Total loss: 0.004428305197507143; that's 0.003021277254447341 task and 0.0003594447625800967 recon and 5.237915992736816 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003828388263937086\n",
      "\n",
      "Total recon loss: 0.0037232846952974796; that's 3.020134210586548 text and 0.0007031504064798355 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004534500758163631\n",
      "\n",
      "Total loss: 0.003983061295002699; that's 0.0027051151264458895 task and 0.0003697718493640423 recon and 4.5408711433410645 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00387559117982164\n",
      "\n",
      "Total loss: 0.004167675040662289; that's 0.002781884279102087 task and 0.0003571224515326321 recon and 5.1433424949646 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003921359539963305\n",
      "\n",
      "Total loss: 0.003985355142503977; that's 0.0027134327683597803 task and 0.00038000824861228466 recon and 4.45957088470459 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003859114279039204\n",
      "\n",
      "Total recon loss: 0.004130182787775993; that's 3.4546923637390137 text and 0.0006754905334673822 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00406586887082085\n",
      "\n",
      "Total loss: 0.003780532628297806; that's 0.0025401741731911898 task and 0.00035138134262524545 recon and 4.444886684417725 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0038675069715827706\n",
      "\n",
      "Total loss: 0.003970752004534006; that's 0.0026354785077273846 task and 0.0003685987030621618 recon and 4.8333740234375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0037751693883910776\n",
      "\n",
      "Total loss: 0.003951151389628649; that's 0.0026378321927040815 task and 0.0003590242995414883 recon and 4.7714738845825195 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003799217096529901\n",
      "\n",
      "Total loss: 0.003909294959157705; that's 0.002627125708386302 task and 0.0003671969461720437 recon and 4.574861526489258 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003762479848228395\n",
      "\n",
      "Total recon loss: 0.004943283274769783; that's 4.032516956329346 text and 0.0009107658406719565 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005025904611684382\n",
      "\n",
      "Total loss: 0.0035564154386520386; that's 0.0023742143530398607 task and 0.00037326314486563206 recon and 4.044689178466797 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0037772208149544893\n",
      "\n",
      "Total loss: 0.0037009255029261112; that's 0.0024063833989202976 task and 0.00035649427445605397 recon and 4.690239429473877 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0038506099209189414\n",
      "\n",
      "Total recon loss: 0.004288516007363796; that's 3.73598575592041 text and 0.0005525302258320153 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00501950646750629\n",
      "\n",
      "Total loss: 0.003397353459149599; that's 0.002218523295596242 task and 0.0003526850196067244 recon and 4.130725860595703 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0037296592141501605\n",
      "\n",
      "Total loss: 0.0036222469061613083; that's 0.002337054582312703 task and 0.00036088679917156696 recon and 4.621528148651123 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003803257425315678\n",
      "\n",
      "Total loss: 0.00384454894810915; that's 0.002535496838390827 task and 0.0003576802264433354 recon and 4.756859302520752 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0037652175151742994\n",
      "\n",
      "Total recon loss: 0.0055877394042909145; that's 5.027087211608887 text and 0.0005606518243439496 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005147706007119268\n",
      "\n",
      "Total loss: 0.003996598068624735; that's 0.002648310037329793 task and 0.0003650769649539143 recon and 4.916055202484131 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0038278424949385226\n",
      "\n",
      "Total loss: 0.0030018144752830267; that's 0.001710125943645835 task and 0.0003537556913215667 recon and 4.689664363861084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0036842141789384187\n",
      "\n",
      "Total loss: 0.003919865470379591; that's 0.002664146712049842 task and 0.00036025879671797156 recon and 4.47730016708374 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0037331682606600225\n",
      "\n",
      "Total recon loss: 0.004247600678354502; that's 3.614412784576416 text and 0.0006331877666525543 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005153263849206269\n",
      "\n",
      "Total loss: 0.004477207083255053; that's 0.0031624361872673035 task and 0.0003459926228970289 recon and 4.843891620635986 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00355309150647372\n",
      "\n",
      "Total loss: 0.003138243919238448; that's 0.0019223244162276387 task and 0.0003692080790642649 recon and 4.23355770111084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0036462788726203143\n",
      "\n",
      "Total loss: 0.003945881966501474; that's 0.0025521053466945887 task and 0.0003569561813492328 recon and 5.1841020584106445 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0036597018549218772\n",
      "\n",
      "Total recon loss: 0.004527370911091566; that's 3.7932772636413574 text and 0.0007340933079831302 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004392758959438652\n",
      "\n",
      "Total loss: 0.0036937231197953224; that's 0.002598288469016552 task and 0.0003607587132137269 recon and 3.6733791828155518 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003612502289470285\n",
      "\n",
      "Total loss: 0.0035055612679570913; that's 0.0023097905796021223 task and 0.00035478666541166604 recon and 4.204920291900635 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003645224920473993\n",
      "\n",
      "Total loss: 0.004416929557919502; that's 0.003228941233828664 task and 0.0003619807248469442 recon and 4.130038261413574 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0035919215832836927\n",
      "\n",
      "Total loss: 0.0034876810386776924; that's 0.002310583833605051 task and 0.00036475242814049125 recon and 4.0617241859436035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0034008269151672723\n",
      "\n",
      "Total recon loss: 0.00400076899677515; that's 3.0305254459381104 text and 0.0009702435927465558 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004959873715415597\n",
      "\n",
      "Total loss: 0.0033657988533377647; that's 0.0021835947409272194 task and 0.00034837849671021104 recon and 4.169128894805908 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0033535769348964095\n",
      "\n",
      "Total loss: 0.0035777033772319555; that's 0.0026317022275179625 task and 0.0003609101986512542 recon and 2.9254555702209473 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0034255028748884798\n",
      "\n",
      "Total loss: 0.0033692389260977507; that's 0.0022539629135280848 task and 0.00037222891114652157 recon and 3.715235471725464 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003333803212735802\n",
      "\n",
      "Total recon loss: 0.004270078148692846; that's 3.5947492122650146 text and 0.0006753289490006864 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0047604923020116985\n",
      "\n",
      "Total loss: 0.003005536738783121; that's 0.0017886741552501917 task and 0.0003513092815410346 recon and 4.327765941619873 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003506978519726545\n",
      "\n",
      "Total loss: 0.003416013903915882; that's 0.0023420017678290606 task and 0.00033964094473049045 recon and 3.6718552112579346 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0034870575042441486\n",
      "\n",
      "Total recon loss: 0.004503837786614895; that's 3.4645838737487793 text and 0.0010392540134489536 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004532068716362119\n",
      "\n",
      "Total loss: 0.003380358684808016; that's 0.0023785310331732035 task and 0.0003504455089569092 recon and 3.2569103240966797 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0033828263427130877\n",
      "\n",
      "Total loss: 0.003412873949855566; that's 0.0024118637666106224 task and 0.00035169863258488476 recon and 3.2465577125549316 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003395494413562119\n",
      "\n",
      "Total loss: 0.004007363226264715; that's 0.0026197985280305147 task and 0.0003505665808916092 recon and 5.184990406036377 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003480015767272562\n",
      "\n",
      "Total loss: 0.0036672228015959263; that's 0.002221545670181513 task and 0.0003598713083192706 recon and 5.429028511047363 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0035245141759514807\n",
      "\n",
      "Total recon loss: 0.003933269064873457; that's 3.014281988143921 text and 0.0009189870324917138 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004445536788553\n",
      "\n",
      "Total loss: 0.0037180299405008554; that's 0.0023443906102329493 task and 0.00035975032369606197 recon and 5.0694451332092285 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003506936028134078\n",
      "\n",
      "Total loss: 0.003430458717048168; that's 0.0021654744632542133 task and 0.00035103820846416056 recon and 4.569730281829834 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0035026289476081727\n",
      "\n",
      "Total recon loss: 0.004099672194570303; that's 3.342097520828247 text and 0.0007575747440569103 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004426171833183616\n",
      "\n",
      "Total loss: 0.0034136527683585882; that's 0.002271974226459861 task and 0.0003558394673746079 recon and 3.9291951656341553 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003466747794300318\n",
      "\n",
      "Total loss: 0.0029091115575283766; that's 0.0015401121927425265 task and 0.00035616435343399644 recon and 5.064175128936768 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0034994049044325946\n",
      "\n",
      "Total loss: 0.002928437665104866; that's 0.00166359543800354 task and 0.0003535120631568134 recon and 4.556650638580322 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0034648981946520507\n",
      "\n",
      "Total recon loss: 0.004394576884806156; that's 3.5778205394744873 text and 0.00081675621913746 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004217595579102635\n",
      "\n",
      "Total loss: 0.0030615527648478746; that's 0.0018718825886026025 task and 0.00035193958319723606 recon and 4.188652515411377 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003468637294135988\n",
      "\n",
      "Total loss: 0.0038750777021050453; that's 0.002681252546608448 task and 0.00034794944804161787 recon and 4.229377746582031 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0034429656690917907\n",
      "\n",
      "Total loss: 0.003544073086231947; that's 0.0021435392554849386 task and 0.00035971272154711187 recon and 5.20410680770874 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003512822741176933\n",
      "\n",
      "Total recon loss: 0.004326488822698593; that's 3.4817676544189453 text and 0.000844721042085439 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004043580272700638\n",
      "\n",
      "Total loss: 0.0035422369837760925; that's 0.0023548228200525045 task and 0.0003490250965114683 recon and 4.191946029663086 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0035314537631347775\n",
      "\n",
      "Total loss: 0.003420763649046421; that's 0.002288953633978963 task and 0.00034845914342440665 recon and 3.9167535305023193 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0034559369436465205\n",
      "\n",
      "Total loss: 0.0037492578849196434; that's 0.0023365227971225977 task and 0.0003609820851124823 recon and 5.258764743804932 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0034115075040608645\n",
      "\n",
      "Total recon loss: 0.004281697329133749; that's 3.3589963912963867 text and 0.0009227009722962976 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004104898893274367\n",
      "\n",
      "Total loss: 0.003403285052627325; that's 0.001971017336472869 task and 0.0003503604675643146 recon and 5.409536361694336 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003458658952731639\n",
      "\n",
      "Total loss: 0.003211669623851776; that's 0.0020113657228648663 task and 0.00034850012161768973 recon and 4.259018421173096 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0034754799609072505\n",
      "\n",
      "Total loss: 0.003630725434049964; that's 0.002396809868514538 task and 0.00035024870885536075 recon and 4.418334007263184 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0033949498645961286\n",
      "\n",
      "Total loss: 0.003414110979065299; that's 0.001902407850138843 task and 0.0003450986696407199 recon and 5.833022594451904 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0034242959250696003\n",
      "\n",
      "Total recon loss: 0.004803982097655535; that's 3.983503818511963 text and 0.0008204778423532844 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004146615331992507\n",
      "\n",
      "Total loss: 0.00311806658282876; that's 0.0019749412313103676 task and 0.0003464989713393152 recon and 3.9831318855285645 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003363288016989827\n",
      "\n",
      "Total loss: 0.0035849702544510365; that's 0.0022631529718637466 task and 0.00036272755824029446 recon and 4.795448303222656 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0033927487139590084\n",
      "\n",
      "Total recon loss: 0.003423559246584773; that's 2.673626661300659 text and 0.0007499323692172766 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038335199700668455\n",
      "\n",
      "Total loss: 0.0035247341729700565; that's 0.002172901062294841 task and 0.0003456423874013126 recon and 5.0309529304504395 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003387712659314275\n",
      "\n",
      "Total loss: 0.003618788905441761; that's 0.002270670374855399 task and 0.0003601669450290501 recon and 4.939758777618408 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003391095898114145\n",
      "\n",
      "Total loss: 0.002925971057265997; that's 0.0016833650879561901 task and 0.0003424971073400229 recon and 4.500543594360352 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0033348333509638905\n",
      "\n",
      "Total recon loss: 0.004241708666086197; that's 3.4435250759124756 text and 0.0007981834933161736 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004245931068435311\n",
      "\n",
      "Total loss: 0.0034157985355705023; that's 0.002283495618030429 task and 0.000356313306838274 recon and 3.879948377609253 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0032881611003540458\n",
      "\n",
      "Total loss: 0.002988803433254361; that's 0.0018302029930055141 task and 0.00035005222889594734 recon and 4.042741298675537 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003481462886556983\n",
      "\n",
      "Total loss: 0.0030976601410657167; that's 0.0021387760061770678 task and 0.0003401069843675941 recon and 3.093886613845825 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003340547285042703\n",
      "\n",
      "Total recon loss: 0.005344161298125982; that's 4.556093692779541 text and 0.0007880675257183611 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0048345987638458605\n",
      "\n",
      "Total loss: 0.003256389405578375; that's 0.0018272630404680967 task and 0.00034104124642908573 recon and 5.440424919128418 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0032750107836909594\n",
      "\n",
      "Total loss: 0.003479116363450885; that's 0.002199314534664154 task and 0.00035069117438979447 recon and 4.645553112030029 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003386082537472248\n",
      "\n",
      "Total loss: 0.0034077251330018044; that's 0.0022583159152418375 task and 0.0003471980744507164 recon and 4.011056423187256 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0033459382061846554\n",
      "\n",
      "Total recon loss: 0.004756953101605177; that's 4.065254211425781 text and 0.0006916986894793808 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005032819951884449\n",
      "\n",
      "Total loss: 0.003734295256435871; that's 0.002517982153221965 task and 0.0003569373511709273 recon and 4.296879291534424 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003334301409777254\n",
      "\n",
      "Total loss: 0.0035963025875389576; that's 0.002584919799119234 task and 0.0003461771411821246 recon and 3.3260273933410645 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0032135790400207045\n",
      "\n",
      "Total loss: 0.003299369942396879; that's 0.002011619508266449 task and 0.00035753779229708016 recon and 4.651063919067383 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0032515812385827303\n",
      "\n",
      "Total recon loss: 0.004927645903080702; that's 4.220849514007568 text and 0.0007067961269058287 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005117365224286914\n",
      "\n",
      "Total loss: 0.0030678166076540947; that's 0.002013578312471509 task and 0.00036266824463382363 recon and 3.457850456237793 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003262786774430424\n",
      "\n",
      "Total loss: 0.003356311470270157; that's 0.0024635575246065855 task and 0.00035574473440647125 recon and 2.6850454807281494 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0031819937331601976\n",
      "\n",
      "Total loss: 0.002800275105983019; that's 0.0018367600860074162 task and 0.0003530470421537757 recon and 3.052339553833008 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003090931756887585\n",
      "\n",
      "Total recon loss: 0.004891702905297279; that's 4.0977253913879395 text and 0.0007939771749079227 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005117874497082084\n",
      "\n",
      "Total loss: 0.0031473126728087664; that's 0.002170391147956252 task and 0.0003459340368863195 recon and 3.154937982559204 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003115396921057254\n",
      "\n",
      "Total loss: 0.003337882226333022; that's 0.002121180761605501 task and 0.0003490382805466652 recon and 4.338315963745117 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003252551390323788\n",
      "\n",
      "Total loss: 0.003354010870680213; that's 0.002147867577150464 task and 0.00034080762998200953 recon and 4.3266777992248535 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003196118150372058\n",
      "\n",
      "Total recon loss: 0.006426742300391197; that's 5.624619007110596 text and 0.0008021232206374407 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005282208593562245\n",
      "\n",
      "Total loss: 0.0022936235181987286; that's 0.0014067240990698338 task and 0.0003454440739005804 recon and 2.7072768211364746 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030331289116293193\n",
      "\n",
      "Total loss: 0.0029267636127769947; that's 0.001765495864674449 task and 0.00036036991514265537 recon and 4.004489898681641 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003050186629407108\n",
      "\n",
      "Total loss: 0.003409328870475292; that's 0.0020962173584848642 task and 0.00035857525654137135 recon and 4.772681713104248 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003235844117589295\n",
      "\n",
      "Total loss: 0.003091220511123538; that's 0.0022115116007626057 task and 0.000349650887073949 recon and 2.6502907276153564 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0032317311549559234\n",
      "\n",
      "Total recon loss: 0.005392976570874453; that's 4.4835429191589355 text and 0.0009094331762753427 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005030446206219495\n",
      "\n",
      "Total loss: 0.0024509471841156483; that's 0.0016028749523684382 task and 0.0003396914107725024 recon and 2.5419037342071533 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029211683687753974\n",
      "\n",
      "Total loss: 0.0029764920473098755; that's 0.002055032877251506 task and 0.00034538115141913295 recon and 2.8803892135620117 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002979598743841052\n",
      "\n",
      "Total loss: 0.002556771971285343; that's 0.0017530330223962665 task and 0.0003389783960301429 recon and 2.3238017559051514 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0031004007323645055\n",
      "\n",
      "Total recon loss: 0.005609041079878807; that's 4.690804481506348 text and 0.0009182365029118955 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005133255473338067\n",
      "\n",
      "Total loss: 0.003099836176261306; that's 0.002101264428347349 task and 0.000350113317836076 recon and 3.242292881011963 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0031093822023831306\n",
      "\n",
      "Total loss: 0.0034872437827289104; that's 0.0022415188141167164 task and 0.0003515329153742641 recon and 4.47096061706543 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030874952906742694\n",
      "\n",
      "Total recon loss: 0.005561398342251778; that's 4.7119951248168945 text and 0.0008494027424603701 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0051278486521914605\n",
      "\n",
      "Total loss: 0.003455288242548704; that's 0.0021059787832200527 task and 0.0003343256248626858 recon and 5.074918746948242 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0031700465735048054\n",
      "\n",
      "Total loss: 0.0033508988562971354; that's 0.0021802238188683987 task and 0.00034059834433719516 recon and 4.150383472442627 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003279799686279148\n",
      "\n",
      "Total loss: 0.003259330987930298; that's 0.0019391742534935474 task and 0.0003459099680185318 recon and 4.87123441696167 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003224833933636546\n",
      "\n",
      "Total recon loss: 0.005456532351672649; that's 4.836561679840088 text and 0.0006199703202582896 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005140639250166714\n",
      "\n",
      "Total loss: 0.003096475498750806; that's 0.0019066468812525272 task and 0.0003441746230237186 recon and 4.228270053863525 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003294503358192742\n",
      "\n",
      "Total loss: 0.003233746625483036; that's 0.0018665126990526915 task and 0.0003510871611069888 recon and 5.0807342529296875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0032373578706756233\n",
      "\n",
      "Total loss: 0.0031081181950867176; that's 0.0020076779183000326 task and 0.0003380632842890918 recon and 3.811884641647339 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030521577736362816\n",
      "\n",
      "Total recon loss: 0.005930762737989426; that's 5.192869663238525 text and 0.000737892696633935 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005181488732341677\n",
      "\n",
      "Total loss: 0.002948493231087923; that's 0.0019745107274502516 task and 0.000355268974089995 recon and 3.093566656112671 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030485884845256805\n",
      "\n",
      "Total loss: 0.0030637485906481743; that's 0.0018779590027406812 task and 0.0003389658813830465 recon and 4.2341179847717285 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00312412578612566\n",
      "\n",
      "Total loss: 0.0028603815007954836; that's 0.0018670485587790608 task and 0.0003364032891113311 recon and 3.2846479415893555 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003039891803637147\n",
      "\n",
      "Total recon loss: 0.005870479624718428; that's 4.945168495178223 text and 0.0009253107127733529 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005364156914874911\n",
      "\n",
      "Total loss: 0.0032154819928109646; that's 0.0022270751651376486 task and 0.0003349960898049176 recon and 3.267054319381714 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00308652953710407\n",
      "\n",
      "Total loss: 0.002533440478146076; that's 0.001582881435751915 task and 0.0003432375087868422 recon and 3.0366079807281494 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030339787900447845\n",
      "\n",
      "Total loss: 0.0029889889992773533; that's 0.002036851132288575 task and 0.0003475025878287852 recon and 3.023176670074463 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003000063570216298\n",
      "\n",
      "Total loss: 0.0031554268207401037; that's 0.0019775961991399527 task and 0.0003389880002941936 recon and 4.1942138671875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003039957277942449\n",
      "\n",
      "Total recon loss: 0.003266851184889674; that's 2.5275750160217285 text and 0.0007392758852802217 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004482648686971516\n",
      "\n",
      "Total loss: 0.0029461614321917295; that's 0.0018162946216762066 task and 0.0003406691539566964 recon and 3.945988178253174 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003064289821777493\n",
      "\n",
      "Total loss: 0.002977511612698436; that's 0.001932755229063332 task and 0.0003415484097786248 recon and 3.5160396099090576 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0031922032847069206\n",
      "\n",
      "Total loss: 0.0029239344876259565; that's 0.0018792505143210292 task and 0.0003416081890463829 recon and 3.51537823677063 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003165343834552914\n",
      "\n",
      "Total recon loss: 0.004019623156636953; that's 3.305903196334839 text and 0.0007137198117561638 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004451816999353469\n",
      "\n",
      "Total loss: 0.002477667760103941; that's 0.0015909322537481785 task and 0.0003376203530933708 recon and 2.745575428009033 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003129273799713701\n",
      "\n",
      "Total loss: 0.0026675336994230747; that's 0.0017121074488386512 task and 0.0003327124286442995 recon and 3.113570213317871 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002945984397083521\n",
      "\n",
      "Total recon loss: 0.004858361091464758; that's 4.239241123199463 text and 0.0006191201391629875 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004716622005216778\n",
      "\n",
      "Total loss: 0.003302676137536764; that's 0.0022653478663414717 task and 0.00033832198823802173 recon and 3.4950318336486816 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029576156660914422\n",
      "\n",
      "Total loss: 0.0032773097045719624; that's 0.0021363848354667425 task and 0.0003429820644669235 recon and 3.989713668823242 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002968569197691977\n",
      "\n",
      "Total loss: 0.003508513793349266; that's 0.002286983886733651 task and 0.00035132651100866497 recon and 4.351016998291016 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003082908308133483\n",
      "\n",
      "Total recon loss: 0.004328868351876736; that's 3.642439365386963 text and 0.0006864286260679364 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004399162197951227\n",
      "\n",
      "Total loss: 0.0033713236916810274; that's 0.0019574433099478483 task and 0.0003420141292735934 recon and 5.359332084655762 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029867477295920253\n",
      "\n",
      "Total loss: 0.002572320168837905; that's 0.0016342559829354286 task and 0.00034770992351695895 recon and 2.951770782470703 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029778757435269653\n",
      "\n",
      "Total loss: 0.0027181976474821568; that's 0.001764762564562261 task and 0.00033383836853317916 recon and 3.0979840755462646 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0031617367221042515\n",
      "\n",
      "Total loss: 0.0023429282009601593; that's 0.0015366836450994015 task and 0.00033846290898509324 recon and 2.3389086723327637 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028716194839216768\n",
      "\n",
      "Total recon loss: 0.003954289946705103; that's 3.2678871154785156 text and 0.0006864026072435081 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0043018660740926865\n",
      "\n",
      "Total loss: 0.0033021920826286077; that's 0.0018483817111700773 task and 0.0003459064173512161 recon and 5.539519786834717 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028650929383002223\n",
      "\n",
      "Total loss: 0.0025916926097124815; that's 0.0017792793223634362 task and 0.0003426240000408143 recon and 2.3489465713500977 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029731570882722737\n",
      "\n",
      "Total loss: 0.0029567107558250427; that's 0.002058065729215741 task and 0.0003391011559870094 recon and 2.7977192401885986 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002968084537424147\n",
      "\n",
      "Total recon loss: 0.003766801208257675; that's 2.8235819339752197 text and 0.0009432191727682948 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004206509301438927\n",
      "\n",
      "Total loss: 0.0031876086723059416; that's 0.0017512626945972443 task and 0.00034189128200523555 recon and 5.472273349761963 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003017389723099768\n",
      "\n",
      "Total loss: 0.002824367955327034; that's 0.0019302819855511189 task and 0.0003387554897926748 recon and 2.7766520977020264 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029770767828449607\n",
      "\n",
      "Total loss: 0.0026573617942631245; that's 0.001409458927810192 task and 0.00033392832847312093 recon and 4.569873809814453 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0031369158090092243\n",
      "\n",
      "Total recon loss: 0.0038155806250870228; that's 3.002046585083008 text and 0.0008135339012369514 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0042587237269617615\n",
      "\n",
      "Total loss: 0.003158118110150099; that's 0.002265176037326455 task and 0.00032980277319438756 recon and 2.8156962394714355 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030748648499138655\n",
      "\n",
      "Total loss: 0.0027107459027320147; that's 0.0015700823860242963 task and 0.00034445649362169206 recon and 3.981034755706787 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030775974690914155\n",
      "\n",
      "Total recon loss: 0.0037575874011963606; that's 3.104679822921753 text and 0.0006529074744321406 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004362602019682527\n",
      "\n",
      "Total loss: 0.00332144764252007; that's 0.0019634070340543985 task and 0.0003430206561461091 recon and 5.075099468231201 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003108733610715717\n",
      "\n",
      "Total loss: 0.0028339081909507513; that's 0.0018061102600768209 task and 0.0003365790471434593 recon and 3.4560952186584473 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030582379479892553\n",
      "\n",
      "Total loss: 0.002511401195079088; that's 0.0016033672727644444 task and 0.00033147347858175635 recon and 2.8828015327453613 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002920945640653372\n",
      "\n",
      "Total recon loss: 0.0036457201931625605; that's 2.978641986846924 text and 0.0006670779548585415 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004001939361914992\n",
      "\n",
      "Total loss: 0.0027479215059429407; that's 0.0018749551381915808 task and 0.00033893343061208725 recon and 2.6701643466949463 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028570336452685297\n",
      "\n",
      "Total loss: 0.0026496676728129387; that's 0.0016286224126815796 task and 0.0003467617789283395 recon and 3.371417760848999 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028794610197655857\n",
      "\n",
      "Total loss: 0.0030712843872606754; that's 0.0019309576600790024 task and 0.00032799720065668225 recon and 4.061648368835449 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00283620314206928\n",
      "\n",
      "Total loss: 0.0033173351548612118; that's 0.002394419629126787 task and 0.0003946982615161687 recon and 2.6410868167877197 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029073552787303924\n",
      "\n",
      "Total recon loss: 0.003836659248918295; that's 2.847212791442871 text and 0.0009894464164972305 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004329287006985396\n",
      "\n",
      "Total loss: 0.003017239738255739; that's 0.002057028468698263 task and 0.0003380604030098766 recon and 3.110755205154419 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028749666293151678\n",
      "\n",
      "Total loss: 0.002330369781702757; that's 0.0014912172919139266 task and 0.0003422460868023336 recon and 2.4845330715179443 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028687236364930866\n",
      "\n",
      "Total recon loss: 0.004178002011030912; that's 3.326638698577881 text and 0.0008513633511029184 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004381583733484149\n",
      "\n",
      "Total loss: 0.003149067983031273; that's 0.0017711709951981902 task and 0.0003293696790933609 recon and 5.242636203765869 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029196247179061174\n",
      "\n",
      "Total loss: 0.0036092326045036316; that's 0.0023624994792044163 task and 0.0003341201809234917 recon and 4.563065528869629 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030735784722492098\n",
      "\n",
      "Total loss: 0.00348842004314065; that's 0.0021405185107141733 task and 0.00032521560206077993 recon and 5.113430023193359 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0031175936618819833\n",
      "\n",
      "Total recon loss: 0.004279701504856348; that's 3.5942413806915283 text and 0.0006854597595520318 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004245982745196671\n",
      "\n",
      "Total loss: 0.002769922837615013; that's 0.0017540535191074014 task and 0.00033561864984221756 recon and 3.4012534618377686 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030858001066371796\n",
      "\n",
      "Total loss: 0.0027674087323248386; that's 0.0017994585214182734 task and 0.00033587912912480533 recon and 3.160355806350708 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002906033149920404\n",
      "\n",
      "Total loss: 0.0029671741649508476; that's 0.002026202389970422 task and 0.0003454701218288392 recon and 2.977508068084717 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002883913260884583\n",
      "\n",
      "Total recon loss: 0.0056289928033947945; that's 4.641304969787598 text and 0.0009876874973997474 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004409257096704096\n",
      "\n",
      "Total loss: 0.0029559223912656307; that's 0.0019300216808915138 task and 0.0003351546183694154 recon and 3.453730821609497 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002856875825673342\n",
      "\n",
      "Total loss: 0.002920451806858182; that's 0.0018611600389704108 task and 0.0003312464104965329 recon and 3.6402266025543213 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028452793485485017\n",
      "\n",
      "Total loss: 0.0029311403632164; that's 0.0019300917629152536 task and 0.0003262836253270507 recon and 3.373825788497925 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002899836155120283\n",
      "\n",
      "Total loss: 0.0033961315639317036; that's 0.0019276229431852698 task and 0.0003419324930291623 recon and 5.6328816413879395 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002921782115008682\n",
      "\n",
      "Total recon loss: 0.004227741155773401; that's 3.553774356842041 text and 0.0006739667151123285 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004542683910112828\n",
      "\n",
      "Total loss: 0.0029424706008285284; that's 0.002041792031377554 task and 0.0003383320290595293 recon and 2.811732530593872 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003045985819771886\n",
      "\n",
      "Total loss: 0.0032763760536909103; that's 0.001814117655158043 task and 0.00033715119934640825 recon and 5.62553596496582 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030360041791573167\n",
      "\n",
      "Total recon loss: 0.004027434624731541; that's 3.1245248317718506 text and 0.0009029097855091095 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0043661437020637095\n",
      "\n",
      "Total loss: 0.003200145671144128; that's 0.0020170698408037424 task and 0.0003322757547721267 recon and 4.254000663757324 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003095070845447481\n",
      "\n",
      "Total loss: 0.0032167520839720964; that's 0.0023153743240982294 task and 0.0003312486514914781 recon and 2.8506455421447754 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029132589558139442\n",
      "\n",
      "Total loss: 0.002973320195451379; that's 0.001691267010755837 task and 0.0003346767043694854 recon and 4.736882209777832 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030803220602683722\n",
      "\n",
      "Total recon loss: 0.003842920996248722; that's 3.1214587688446045 text and 0.0007214619545266032 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00455200006486848\n",
      "\n",
      "Total loss: 0.0036141695454716682; that's 0.0024570743553340435 task and 0.00032919904333539307 recon and 4.139481067657471 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0031156172743067147\n",
      "\n",
      "Total loss: 0.0033276183530688286; that's 0.0020186216570436954 task and 0.00032898789504542947 recon and 4.9000444412231445 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003002651552669704\n",
      "\n",
      "Total loss: 0.003066614270210266; that's 0.0018956952262669802 task and 0.00033133942633867264 recon and 4.197898864746094 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0031431728112511336\n",
      "\n",
      "Total recon loss: 0.0042935446836054325; that's 3.5130231380462646 text and 0.0007805213681422174 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004200274485629052\n",
      "\n",
      "Total loss: 0.0029905373230576515; that's 0.0018587925005704165 task and 0.00033111716038547456 recon and 4.003138542175293 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030422543385066093\n",
      "\n",
      "Total loss: 0.0029056244529783726; that's 0.0015146383084356785 task and 0.0003315469657536596 recon and 5.2971954345703125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003019102718681097\n",
      "\n",
      "Total loss: 0.002838724059984088; that's 0.0018536809366196394 task and 0.0003354856453370303 recon and 3.2477872371673584 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0031107852794229982\n",
      "\n",
      "Total recon loss: 0.003760032821446657; that's 3.0413930416107178 text and 0.0007186398142948747 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004128928824793547\n",
      "\n",
      "Total loss: 0.0027572850231081247; that's 0.0017172695370391011 task and 0.0003268158179707825 recon and 3.5659985542297363 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003015650408342481\n",
      "\n",
      "Total loss: 0.0031656953506171703; that's 0.0019103839294984937 task and 0.0003355270891916007 recon and 4.598922252655029 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003140671798028052\n",
      "\n",
      "Total loss: 0.0030894670635461807; that's 0.001869186176918447 task and 0.00032206266769208014 recon and 4.491091728210449 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029483803873881697\n",
      "\n",
      "Total recon loss: 0.0043073371052742004; that's 3.6330180168151855 text and 0.0006743191042914987 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004121346028987318\n",
      "\n",
      "Total loss: 0.0026836274191737175; that's 0.0014932145131751895 task and 0.0003393088700249791 recon and 4.255519866943359 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002930174795910716\n",
      "\n",
      "Total loss: 0.002777682151645422; that's 0.0017402510857209563 task and 0.00033273675944656134 recon and 3.5234713554382324 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003085580915212631\n",
      "\n",
      "Total loss: 0.0025502473581582308; that's 0.001701597822830081 task and 0.0003279344236943871 recon and 2.603574752807617 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002779845690820366\n",
      "\n",
      "Total recon loss: 0.00395936006680131; that's 3.311897039413452 text and 0.0006474630208685994 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004176712881308049\n",
      "\n",
      "Total loss: 0.0030897180549800396; that's 0.0018086587078869343 task and 0.0003262950631324202 recon and 4.7738213539123535 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029891387303359806\n",
      "\n",
      "Total loss: 0.0029355264268815517; that's 0.001698054140433669 task and 0.00033759709913283587 recon and 4.499374866485596 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003007181012071669\n",
      "\n",
      "Total loss: 0.0025969254784286022; that's 0.0016128248535096645 task and 0.00032113815541379154 recon and 3.314812183380127 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00302353487117216\n",
      "\n",
      "Total loss: 0.0026872556190937757; that's 0.0015337892109528184 task and 0.00033892126521095634 recon and 4.072725772857666 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028228538250550626\n",
      "\n",
      "Total recon loss: 0.0034313956275582314; that's 2.7440357208251953 text and 0.0006873599486425519 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004843091166112572\n",
      "\n",
      "Total loss: 0.0033176098950207233; that's 0.0023353088181465864 task and 0.0003222336817998439 recon and 3.300337553024292 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028981922497041523\n",
      "\n",
      "Total loss: 0.0027934638783335686; that's 0.0016029059188440442 task and 0.0003333127242513001 recon and 4.286225318908691 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028148922184482216\n",
      "\n",
      "Total recon loss: 0.005514173302799463; that's 4.787789344787598 text and 0.0007263835286721587 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004797170588281005\n",
      "\n",
      "Total loss: 0.003125345567241311; that's 0.001984783448278904 task and 0.00033194126444868743 recon and 4.04310417175293 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029249669727869332\n",
      "\n",
      "Total loss: 0.003635136876255274; that's 0.0022698226384818554 task and 0.00034423350007273257 recon and 5.105402946472168 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030674294871278107\n",
      "\n",
      "Total loss: 0.0027889972552657127; that's 0.0016757040284574032 task and 0.0003255544288549572 recon and 3.9386937618255615 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00299800384324044\n",
      "\n",
      "Total recon loss: 0.005329353269189596; that's 4.378935813903809 text and 0.0009504170157015324 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00476137560326606\n",
      "\n",
      "Total loss: 0.003031117608770728; that's 0.001861005206592381 task and 0.0003347636084072292 recon and 4.17674446105957 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029607597715221347\n",
      "\n",
      "Total loss: 0.003376364940777421; that's 0.002121740486472845 task and 0.0003255013725720346 recon and 4.645615577697754 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028314185631461443\n",
      "\n",
      "Total loss: 0.003021867945790291; that's 0.0019172626780346036 task and 0.00032111199107021093 recon and 3.917466640472412 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003057492091320455\n",
      "\n",
      "Total recon loss: 0.004119591787457466; that's 3.1737515926361084 text and 0.0009458399144932628 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004635311239399016\n",
      "\n",
      "Total loss: 0.0027869120240211487; that's 0.001557250740006566 task and 0.00032293435651808977 recon and 4.533634185791016 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00302734833676368\n",
      "\n",
      "Total loss: 0.002806752920150757; that's 0.0016458227764815092 task and 0.0003255676128901541 recon and 4.176812648773193 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028511419659480453\n",
      "\n",
      "Total loss: 0.002887622220441699; that's 0.0018326506251469254 task and 0.0003173114382661879 recon and 3.688300848007202 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029039405938237907\n",
      "\n",
      "Total recon loss: 0.0046002245508134365; that's 4.026193141937256 text and 0.0005740312044508755 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005017920162063092\n",
      "\n",
      "Total loss: 0.0027204472571611404; that's 0.0017937745433300734 task and 0.0003097783192060888 recon and 3.084472417831421 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028811677917838095\n",
      "\n",
      "Total loss: 0.002587720053270459; that's 0.0016497097676619887 task and 0.00032289428054355085 recon and 3.07558012008667 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002828277135267854\n",
      "\n",
      "Total loss: 0.003055165521800518; that's 0.0016070218989625573 task and 0.00032793215359561145 recon and 5.601058006286621 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002898747208528221\n",
      "\n",
      "Total loss: 0.0026353972498327494; that's 0.0016573151806369424 task and 0.00032688360079191625 recon and 3.2559924125671387 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028520946996286514\n",
      "\n",
      "Total recon loss: 0.0060833413153886795; that's 5.300942420959473 text and 0.0007823983323760331 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005967304985970259\n",
      "\n",
      "Total loss: 0.0025936951860785484; that's 0.0017487290315330029 task and 0.00032778960303403437 recon and 2.5858817100524902 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028548615030013023\n",
      "\n",
      "Total loss: 0.0030183547642081976; that's 0.0020358944311738014 task and 0.0003262698301114142 recon and 3.2809524536132812 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002879489806946367\n",
      "\n",
      "Total recon loss: 0.005398726090788841; that's 4.506628513336182 text and 0.0008920975378714502 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.006011355458758772\n",
      "\n",
      "Total loss: 0.0026830011047422886; that's 0.0017200837610289454 task and 0.0003213733434677124 recon and 3.207719087600708 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002805072267074138\n",
      "\n",
      "Total loss: 0.002526596188545227; that's 0.0014992839423939586 task and 0.0003265871782787144 recon and 3.50362491607666 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026960553834214805\n",
      "\n",
      "Total loss: 0.0034021083265542984; that's 0.0023582049179822206 task and 0.0003312236804049462 recon and 3.563398599624634 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028414264344610272\n",
      "\n",
      "Total recon loss: 0.005162184126675129; that's 4.183690071105957 text and 0.0009784939466044307 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005088351448066532\n",
      "\n",
      "Total loss: 0.002515821484848857; that's 0.0016727406764402986 task and 0.0003248743887525052 recon and 2.5910325050354004 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026600092835724356\n",
      "\n",
      "Total loss: 0.0025039061438292265; that's 0.0016106023686006665 task and 0.0003321272088214755 recon and 2.8058829307556152 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002625046856701374\n",
      "\n",
      "Total loss: 0.0029367306269705296; that's 0.001718993647955358 task and 0.00032101006945595145 recon and 4.4836344718933105 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029011788358911873\n",
      "\n",
      "Total recon loss: 0.005949614103883505; that's 5.3958916664123535 text and 0.0005537220858968794 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004942200228106231\n",
      "\n",
      "Total loss: 0.002935852622613311; that's 0.0018051639199256897 task and 0.00033140560844913125 recon and 3.996415615081787 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002981303264386952\n",
      "\n",
      "Total loss: 0.0030155933927744627; that's 0.001829512999393046 task and 0.00033136605634354055 recon and 4.273571968078613 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030018632137216628\n",
      "\n",
      "Total loss: 0.0030446366872638464; that's 0.002128144958987832 task and 0.0003262716345489025 recon and 2.9511001110076904 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002867130213417113\n",
      "\n",
      "Total recon loss: 0.004864928778260946; that's 4.117311954498291 text and 0.0007476164028048515 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00521026092581451\n",
      "\n",
      "Total loss: 0.0025830527301877737; that's 0.0017097409581765532 task and 0.00031016365392133594 recon and 2.8157408237457275 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028515723021700977\n",
      "\n",
      "Total loss: 0.002470973879098892; that's 0.001575996051542461 task and 0.0003192475123796612 recon and 2.8786511421203613 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026607350003905596\n",
      "\n",
      "Total loss: 0.003265631152316928; that's 0.0021462601143866777 task and 0.0003242189122829586 recon and 3.9757604598999023 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029072649101726713\n",
      "\n",
      "Total loss: 0.002708012005314231; that's 0.00172622490208596 task and 0.0003208951384294778 recon and 3.304459810256958 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026613567769527436\n",
      "\n",
      "Total recon loss: 0.004742226097732782; that's 3.961606740951538 text and 0.0007806193316355348 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005059690205380321\n",
      "\n",
      "Total loss: 0.002798374043777585; that's 0.0017537915846332908 task and 0.00032398264738731086 recon and 3.602999687194824 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028219377156347035\n",
      "\n",
      "Total loss: 0.002898575272411108; that's 0.001861983328126371 task and 0.0003165972011629492 recon and 3.5999746322631836 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002821402105037123\n",
      "\n",
      "Total loss: 0.0027025153394788504; that's 0.0016702605644240975 task and 0.00032126260339282453 recon and 3.5549604892730713 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028232926991768183\n",
      "\n",
      "Total recon loss: 0.004971468821167946; that's 4.098337650299072 text and 0.0008731309790164232 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0046980560827068986\n",
      "\n",
      "Total loss: 0.002622070489451289; that's 0.001695695798844099 task and 0.00031843542819842696 recon and 3.039696455001831 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002828313265927136\n",
      "\n",
      "Total loss: 0.0027523678727447987; that's 0.0018703771056607366 task and 0.0003330871695652604 recon and 2.7445175647735596 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002788071820978075\n",
      "\n",
      "Total recon loss: 0.004613626282662153; that's 3.8701391220092773 text and 0.0007434868603013456 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004742659537587315\n",
      "\n",
      "Total loss: 0.003178493119776249; that's 0.0020947789307683706 task and 0.00032466655829921365 recon and 3.795238494873047 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002790242612827569\n",
      "\n",
      "Total loss: 0.0022439744789153337; that's 0.0013286744942888618 task and 0.0003218059428036213 recon and 2.967470169067383 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002638929521199316\n",
      "\n",
      "Total loss: 0.0022703325375914574; that's 0.001205509644933045 task and 0.00032221071887761354 recon and 3.7130613327026367 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002787455355282873\n",
      "\n",
      "Total loss: 0.0028883968479931355; that's 0.0017904472770169377 task and 0.00032010622089728713 recon and 3.889216661453247 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002718131574802101\n",
      "\n",
      "Total recon loss: 0.0057497271336615086; that's 4.846564292907715 text and 0.0009031626977957785 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004964480176568031\n",
      "\n",
      "Total loss: 0.0029249966610223055; that's 0.00193686259444803 task and 0.00032250359072349966 recon and 3.328152656555176 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027323154243640603\n",
      "\n",
      "Total loss: 0.0028062041383236647; that's 0.0017501236870884895 task and 0.00032286401255987585 recon and 3.6660828590393066 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002729203465860337\n",
      "\n",
      "Total loss: 0.002824333030730486; that's 0.0016365882474929094 task and 0.00032996616209857166 recon and 4.28889274597168 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029172598756849765\n",
      "\n",
      "Total recon loss: 0.005326598882675171; that's 4.753840923309326 text and 0.0005727579700760543 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005029749423265457\n",
      "\n",
      "Total loss: 0.003136835526674986; that's 0.002021521097049117 task and 0.00031744633452035487 recon and 3.989339590072632 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002863868239801377\n",
      "\n",
      "Total loss: 0.0025235596112906933; that's 0.001593526336364448 task and 0.00031967670656740665 recon and 3.0517830848693848 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029670377471484244\n",
      "\n",
      "Total recon loss: 0.004902047570794821; that's 4.165706157684326 text and 0.0007363414624705911 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005192497614771128\n",
      "\n",
      "Total loss: 0.0025328455958515406; that's 0.0015552864642813802 task and 0.0003202183870598674 recon and 3.286703586578369 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028285518963821234\n",
      "\n",
      "Total loss: 0.003040436888113618; that's 0.0019565674010664225 task and 0.0003197159094270319 recon and 3.820768356323242 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002898065249901265\n",
      "\n",
      "Total loss: 0.0025647329166531563; that's 0.0016227366868406534 task and 0.0003110925608780235 recon and 3.154517889022827 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00285550881177187\n",
      "\n",
      "Total loss: 0.0030088366474956274; that's 0.0017031864263117313 task and 0.00033764002728275955 recon and 4.840051174163818 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002762538264505565\n",
      "\n",
      "Total recon loss: 0.00546522019430995; that's 4.673576831817627 text and 0.0007916431059129536 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0053933666227385406\n",
      "\n",
      "Total loss: 0.0028756745159626007; that's 0.002005958463996649 task and 0.0003344350552652031 recon and 2.676405191421509 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002745577283203602\n",
      "\n",
      "Total loss: 0.002818649634718895; that's 0.0017575682140886784 task and 0.0003210581198800355 recon and 3.7001168727874756 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028302414435893296\n",
      "\n",
      "Total recon loss: 0.004644231405109167; that's 3.869121551513672 text and 0.0007751096854917705 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0052489088405855\n",
      "\n",
      "Total loss: 0.002808338962495327; that's 0.001791338319890201 task and 0.00031734464573673904 recon and 3.4982805252075195 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002879209122620523\n",
      "\n",
      "Total loss: 0.002547717420384288; that's 0.0013450916158035398 task and 0.0003163816872984171 recon and 4.431221008300781 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0029016812541522085\n",
      "\n",
      "Total loss: 0.0031220128294080496; that's 0.0016532251611351967 task and 0.0003304438723716885 recon and 5.691718578338623 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002903899585362524\n",
      "\n",
      "Total loss: 0.002760831266641617; that's 0.0018121750326827168 task and 0.00031938913161866367 recon and 3.146336078643799 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002775035675149411\n",
      "\n",
      "Total recon loss: 0.004948056768625975; that's 4.124373912811279 text and 0.0008236824651248753 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005189930964261294\n",
      "\n",
      "Total loss: 0.0027822484262287617; that's 0.0016758824931457639 task and 0.00032338936580345035 recon and 3.914883852005005 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027849130681715907\n",
      "\n",
      "Total loss: 0.0025062512140721083; that's 0.0013683631550520658 task and 0.0003286557039245963 recon and 4.046161651611328 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002751767202280462\n",
      "\n",
      "Total loss: 0.002531693782657385; that's 0.0016259625554084778 task and 0.0003228057757951319 recon and 2.91462779045105 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002778284486848861\n",
      "\n",
      "Total recon loss: 0.0050773317925632; that's 4.299163818359375 text and 0.0007781680324114859 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005137242330238223\n",
      "\n",
      "Total loss: 0.0024994153063744307; that's 0.0014448767760768533 task and 0.0003175818710587919 recon and 3.684783697128296 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002698344949167222\n",
      "\n",
      "Total loss: 0.002828439464792609; that's 0.001670804456807673 task and 0.0003211406583432108 recon and 4.182472229003906 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002707489419262856\n",
      "\n",
      "Total recon loss: 0.005101202987134457; that's 4.342040061950684 text and 0.0007591629400849342 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005120173776522279\n",
      "\n",
      "Total loss: 0.0026327974628657103; that's 0.0017188359051942825 task and 0.0003207559639122337 recon and 2.9660286903381348 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027214176882989706\n",
      "\n",
      "Total loss: 0.0026105556171387434; that's 0.0016319042770192027 task and 0.0003124501381535083 recon and 3.3310065269470215 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002619208861142397\n",
      "\n",
      "Total loss: 0.002201173920184374; that's 0.0013311929069459438 task and 0.00031364557798951864 recon and 2.78167724609375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002635010164231062\n",
      "\n",
      "Total loss: 0.003122188849374652; that's 0.002169006271287799 task and 0.000311096606310457 recon and 3.2104296684265137 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026643750234507024\n",
      "\n",
      "Total recon loss: 0.005204967688769102; that's 4.328006267547607 text and 0.0008769611013121903 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005014285158831626\n",
      "\n",
      "Total loss: 0.0029510140884667635; that's 0.0016662910347804427 task and 0.0003134567232336849 recon and 4.856331825256348 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028230893169529734\n",
      "\n",
      "Total loss: 0.002952264156192541; that's 0.0015923903556540608 task and 0.0003178963379468769 recon and 5.209887981414795 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002853365861810744\n",
      "\n",
      "Total recon loss: 0.004246372729539871; that's 3.6139121055603027 text and 0.0006324602290987968 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005326482444070279\n",
      "\n",
      "Total loss: 0.0023451969027519226; that's 0.0014603693271055818 task and 0.0003071454993914813 recon and 2.8884103298187256 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026629122300073503\n",
      "\n",
      "Total loss: 0.0031682713888585567; that's 0.0021655550226569176 task and 0.0003259790246374905 recon and 3.383687734603882 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002623220831155777\n",
      "\n",
      "Total loss: 0.0025945655070245266; that's 0.001634216052480042 task and 0.0003209339047316462 recon and 3.1970784664154053 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002630304438062012\n",
      "\n",
      "Total loss: 0.0030018300749361515; that's 0.0020142379216849804 task and 0.0003154026053380221 recon and 3.360947847366333 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002647501393221319\n",
      "\n",
      "Total recon loss: 0.005258411634713411; that's 4.281175136566162 text and 0.0009772361954674125 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0055380271188914774\n",
      "\n",
      "Total loss: 0.0021582383196800947; that's 0.0011992171639576554 task and 0.0003181966894771904 recon and 3.2041220664978027 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002612353479489684\n",
      "\n",
      "Total loss: 0.0028260599356144667; that's 0.001594716333784163 task and 0.0003196037432644516 recon and 4.558699607849121 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027176394127309323\n",
      "\n",
      "Total recon loss: 0.004475866444408894; that's 3.7746529579162598 text and 0.0007012131973169744 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004997248332947493\n",
      "\n",
      "Total loss: 0.002485237317159772; that's 0.0015359069220721722 task and 0.0003178075421601534 recon and 3.1576147079467773 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002865538496989757\n",
      "\n",
      "Total loss: 0.0023389896377921104; that's 0.0015233013546094298 task and 0.0003190489951521158 recon and 2.4831960201263428 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028551582898944617\n",
      "\n",
      "Total loss: 0.002448852639645338; that's 0.0016094670863822103 task and 0.0003087787772528827 recon and 2.653034210205078 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025406206375919284\n",
      "\n",
      "Total recon loss: 0.004883781541138887; that's 4.159458160400391 text and 0.0007243229192681611 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005316080704797059\n",
      "\n",
      "Total loss: 0.00220870110206306; that's 0.001496560638770461 task and 0.00032389062107540667 recon and 1.9412493705749512 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025185366184450686\n",
      "\n",
      "Total loss: 0.0022964871022850275; that's 0.001358343055471778 task and 0.0003170943818986416 recon and 3.1052486896514893 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025528981699608267\n",
      "\n",
      "Total loss: 0.0022999588400125504; that's 0.001433314522728324 task and 0.0003052879183087498 recon and 2.806781768798828 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002498785648494959\n",
      "\n",
      "Total loss: 0.002332763047888875; that's 0.0014005164848640561 task and 0.00031692872289568186 recon and 3.076589345932007 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025618163286708294\n",
      "\n",
      "Total recon loss: 0.004980059806257486; that's 4.229257106781006 text and 0.000750802515540272 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005192739777266979\n",
      "\n",
      "Total loss: 0.002520251553505659; that's 0.0016509685665369034 task and 0.0003180804487783462 recon and 2.756012439727783 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002527434811927378\n",
      "\n",
      "Total loss: 0.0028749213088303804; that's 0.0019809440709650517 task and 0.00030637963209301233 recon and 2.937988758087158 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025484871410299094\n",
      "\n",
      "Total recon loss: 0.005323054734617472; that's 4.613083839416504 text and 0.0007099703652784228 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005579680781811476\n",
      "\n",
      "Total loss: 0.0021469248458743095; that's 0.0013239338295534253 task and 0.0003130015393253416 recon and 2.549947500228882 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025134389055892826\n",
      "\n",
      "Total loss: 0.002271562349051237; that's 0.0014736870070919394 task and 0.0003080815076828003 recon and 2.4489686489105225 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002529614430386573\n",
      "\n",
      "Total loss: 0.002573905047029257; that's 0.0017067205626517534 task and 0.00031092125573195517 recon and 2.781315803527832 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002536012085620314\n",
      "\n",
      "Total loss: 0.0023255846463143826; that's 0.0014560144627466798 task and 0.00031645421404391527 recon and 2.765580177307129 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025144917715806516\n",
      "\n",
      "Total recon loss: 0.004838987719267607; that's 4.252964019775391 text and 0.0005860234959982336 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005075839811470359\n",
      "\n",
      "Total loss: 0.002905511064454913; that's 0.0017937121447175741 task and 0.00031183045939542353 recon and 3.9998416900634766 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026275043585337696\n",
      "\n",
      "Total loss: 0.0032070442102849483; that's 0.001858701929450035 task and 0.0003429788048379123 recon and 5.026817321777344 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002930040555074811\n",
      "\n",
      "Total loss: 0.002926367800682783; that's 0.00183370360173285 task and 0.00032319047022610903 recon and 3.8473682403564453 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030228317831642927\n",
      "\n",
      "Total recon loss: 0.005046043079346418; that's 4.152498245239258 text and 0.0008935443474911153 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0050971641391515735\n",
      "\n",
      "Total loss: 0.00311078317463398; that's 0.0019889455288648605 task and 0.0003084627678617835 recon and 4.066873550415039 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002846243695821613\n",
      "\n",
      "Total loss: 0.00256781792268157; that's 0.0017483258852735162 task and 0.0003089772362727672 recon and 2.5525741577148438 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002697902354411781\n",
      "\n",
      "Total recon loss: 0.005410252138972282; that's 4.5692830085754395 text and 0.0008409690926782787 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004181956611573696\n",
      "\n",
      "Total loss: 0.002032387303188443; that's 0.0010732690570876002 task and 0.0003065172932110727 recon and 3.263005256652832 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002610881815198809\n",
      "\n",
      "Total loss: 0.002439190400764346; that's 0.0015338270459324121 task and 0.00030683501972816885 recon and 2.9926416873931885 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025956960837356744\n",
      "\n",
      "Total loss: 0.002819062676280737; that's 0.001784660154953599 task and 0.0003164864028804004 recon and 3.5895802974700928 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002643655613064766\n",
      "\n",
      "Total recon loss: 0.00432931212708354; that's 3.620180606842041 text and 0.0007091312436386943 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004775717917364091\n",
      "\n",
      "Total loss: 0.0033366638235747814; that's 0.0022117847111076117 task and 0.0003194637829437852 recon and 4.027076721191406 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027968016103841363\n",
      "\n",
      "Total loss: 0.004140431061387062; that's 0.0025066141970455647 task and 0.0006319106905721128 recon and 5.009531497955322 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003505127269309014\n",
      "\n",
      "Total loss: 0.0030859552789479494; that's 0.0017677529249340296 task and 0.00035543739795684814 recon and 4.813824653625488 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0030215866514481603\n",
      "\n",
      "Total recon loss: 0.005373569205403328; that's 4.774062633514404 text and 0.0005995063693262637 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0053445304138585925\n",
      "\n",
      "Total loss: 0.0029043364338576794; that's 0.0015697022899985313 task and 0.00033467551111243665 recon and 4.999793529510498 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002891363569069654\n",
      "\n",
      "Total loss: 0.0025132414884865284; that's 0.001377510605379939 task and 0.0003326952282804996 recon and 4.01517915725708 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002898796387016773\n",
      "\n",
      "Total loss: 0.0026546188164502382; that's 0.0014026977587491274 task and 0.00032087857834994793 recon and 4.65521240234375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002840224814135581\n",
      "\n",
      "Total recon loss: 0.004174836911261082; that's 3.37119197845459 text and 0.0008036448271013796 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004574133213609457\n",
      "\n",
      "Total loss: 0.0031097475439310074; that's 0.0017088173190131783 task and 0.00032976537477225065 recon and 5.355824947357178 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002844220479018986\n",
      "\n",
      "Total loss: 0.002940681530162692; that's 0.0018030626233667135 task and 0.000325813889503479 recon and 4.059024810791016 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028912913845852016\n",
      "\n",
      "Total loss: 0.0026363753713667393; that's 0.0016308536287397146 task and 0.0003286312276031822 recon and 3.384453535079956 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028173749428242446\n",
      "\n",
      "Total loss: 0.002334756078198552; that's 0.0013585446868091822 task and 0.00030907915788702667 recon and 3.3356614112854004 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002660944575909525\n",
      "\n",
      "Total recon loss: 0.004484917502850294; that's 3.738515853881836 text and 0.0007464016089215875 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0047649057768285276\n",
      "\n",
      "Total loss: 0.00217710854485631; that's 0.0012017320841550827 task and 0.00030952057568356395 recon and 3.3292794227600098 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002759144869633019\n",
      "\n",
      "Total loss: 0.002969185821712017; that's 0.0019094556337222457 task and 0.0003209873684681952 recon and 3.693714141845703 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026466466765850782\n",
      "\n",
      "Total recon loss: 0.0038574908394366503; that's 3.210137128829956 text and 0.0006473534740507603 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004798129361588508\n",
      "\n",
      "Total loss: 0.0025123024825006723; that's 0.0015202920185402036 task and 0.00032536606886424124 recon and 3.333221912384033 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026958466321229933\n",
      "\n",
      "Total loss: 0.002980777993798256; that's 0.0018249214626848698 task and 0.00031985173700377345 recon and 4.180023193359375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027449709339998664\n",
      "\n",
      "Total loss: 0.003031876403838396; that's 0.0019268825417384505 task and 0.00032383817597292364 recon and 3.905777931213379 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002732066847383976\n",
      "\n",
      "Total loss: 0.0028892112895846367; that's 0.001657132408581674 task and 0.0003092522674705833 recon and 4.614132881164551 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002729459346737713\n",
      "\n",
      "Total recon loss: 0.004193887580186129; that's 3.5599899291992188 text and 0.0006338974344544113 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003716902188025415\n",
      "\n",
      "Total loss: 0.002818163949996233; that's 0.0014508208259940147 task and 0.0003170686250086874 recon and 5.251373291015625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028467473457567394\n",
      "\n",
      "Total loss: 0.0028130020946264267; that's 0.0014624444302171469 task and 0.0003182208747602999 recon and 5.161684513092041 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002848151195794344\n",
      "\n",
      "Total recon loss: 0.004510773811489344; that's 3.5356333255767822 text and 0.0009751403704285622 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0036734318477101625\n",
      "\n",
      "Total loss: 0.002477718750014901; that's 0.0014940431574359536 task and 0.0003164133813697845 recon and 3.336311101913452 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002636532064061612\n",
      "\n",
      "Total loss: 0.002613665536046028; that's 0.0015708118444308639 task and 0.0003166450187563896 recon and 3.6310434341430664 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00254458945710212\n",
      "\n",
      "Total loss: 0.0025678242091089487; that's 0.0016835706774145365 task and 0.00031896005384624004 recon and 2.826467275619507 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026174648478627205\n",
      "\n",
      "Total recon loss: 0.003291175002232194; that's 2.384510040283203 text and 0.0009066648781299591 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035969657776877286\n",
      "\n",
      "Total loss: 0.0030955011025071144; that's 0.0018003544537350535 task and 0.0003163461806252599 recon and 4.894002914428711 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027374814823269843\n",
      "\n",
      "Total loss: 0.0030128001235425472; that's 0.0019678878597915173 task and 0.00031804971513338387 recon and 3.634312629699707 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002771555830258876\n",
      "\n",
      "Total loss: 0.002852246630936861; that's 0.0016450234688818455 task and 0.0003330436593387276 recon and 4.370896816253662 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002740179079119116\n",
      "\n",
      "Total loss: 0.002745262812823057; that's 0.001507122302427888 task and 0.00032384911901317537 recon and 4.571456432342529 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027795296697877346\n",
      "\n",
      "Total recon loss: 0.004352503921836615; that's 3.425723075866699 text and 0.0009267808636650443 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035445489548146724\n",
      "\n",
      "Total loss: 0.002183473901823163; that's 0.0012402328429743648 task and 0.0003142970963381231 recon and 3.1447205543518066 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026623573596589265\n",
      "\n",
      "Total loss: 0.0026852821465581656; that's 0.001590033178217709 task and 0.0003118954482488334 recon and 3.9167680740356445 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027397270500659943\n",
      "\n",
      "Total recon loss: 0.00487031415104866; that's 3.9456686973571777 text and 0.0009246453992091119 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004656782438978553\n",
      "\n",
      "Total loss: 0.0024881106801331043; that's 0.0015075812116265297 task and 0.00034012392279691994 recon and 3.2020277976989746 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027395144547335804\n",
      "\n",
      "Total loss: 0.002619785023853183; that's 0.0016423329943791032 task and 0.0003103984345216304 recon and 3.335268497467041 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002677039729896933\n",
      "\n",
      "Total loss: 0.002757902257144451; that's 0.001664928044192493 task and 0.00030474597588181496 recon and 3.941140651702881 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026697664568200706\n",
      "\n",
      "Total recon loss: 0.0038006941322237253; that's 3.188551425933838 text and 0.0006121425540186465 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004478463339619338\n",
      "\n",
      "Total loss: 0.0022581382654607296; that's 0.0012214221060276031 task and 0.0003254918265156448 recon and 3.556121826171875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027758405543863774\n",
      "\n",
      "Total loss: 0.0025925496593117714; that's 0.0012526432983577251 task and 0.00031737113022245467 recon and 5.11267614364624 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00268137794919312\n",
      "\n",
      "Total loss: 0.0029079674277454615; that's 0.0017698175506666303 task and 0.0003148849355056882 recon and 4.1163249015808105 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027537121484056113\n",
      "\n",
      "Total recon loss: 0.003551758360117674; that's 2.8194820880889893 text and 0.0007322761230170727 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003849068584386259\n",
      "\n",
      "Total loss: 0.002987634390592575; that's 0.001771327923052013 task and 0.0003196265606675297 recon and 4.483400344848633 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027656935597769917\n",
      "\n",
      "Total loss: 0.0029325641226023436; that's 0.0016894309082999825 task and 0.0003159648331347853 recon and 4.6358418464660645 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027350816829130055\n",
      "\n",
      "Total loss: 0.0027209774125367403; that's 0.0017134664813056588 task and 0.00031345567549578846 recon and 3.4702768325805664 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002642090420704335\n",
      "\n",
      "Total recon loss: 0.003524811239913106; that's 2.79508638381958 text and 0.0007297247648239136 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037227164953947066\n",
      "\n",
      "Total loss: 0.003225579159334302; that's 0.0023685486521571875 task and 0.0003131398989353329 recon and 2.7194530963897705 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026252313633449375\n",
      "\n",
      "Total loss: 0.0022986161056905985; that's 0.0013947708066552877 task and 0.0003125843359157443 recon and 2.9563047885894775 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026167308469302953\n",
      "\n",
      "Total loss: 0.0024008722975850105; that's 0.001358791603706777 task and 0.00031686792499385774 recon and 3.626063823699951 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002631344178225845\n",
      "\n",
      "Total recon loss: 0.005668594967573881; that's 4.685354232788086 text and 0.0009832404321059585 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004641056463588029\n",
      "\n",
      "Total loss: 0.002706970786675811; that's 0.001787146320566535 task and 0.00034661777317523956 recon and 2.8660335540771484 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027991617727093398\n",
      "\n",
      "Total loss: 0.0032237418927252293; that's 0.0020303151104599237 task and 0.000318884733133018 recon and 4.372711181640625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002802072474732995\n",
      "\n",
      "Total loss: 0.002489157486706972; that's 0.0013947959523648024 task and 0.0003195141616743058 recon and 3.8742361068725586 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002738659451715648\n",
      "\n",
      "Total loss: 0.0026717674918472767; that's 0.0013566728448495269 task and 0.0003158286854159087 recon and 4.996330261230469 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027047803974710404\n",
      "\n",
      "Total recon loss: 0.005757596809417009; that's 4.996253967285156 text and 0.0007613428169861436 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004744155472144485\n",
      "\n",
      "Total loss: 0.002578440820798278; that's 0.0014915578067302704 task and 0.0003110510006081313 recon and 3.879160165786743 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002804429430980235\n",
      "\n",
      "Total loss: 0.0029609939083456993; that's 0.0016404534690082073 task and 0.00030926696490496397 recon and 5.056367874145508 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002773856311105192\n",
      "\n",
      "Total recon loss: 0.005357665941119194; that's 4.676278591156006 text and 0.0006813874933868647 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004537538492586464\n",
      "\n",
      "Total loss: 0.00265817204490304; that's 0.0017151909414678812 task and 0.0003229237045161426 recon and 3.100287437438965 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027780082798562946\n",
      "\n",
      "Total loss: 0.0026746131479740143; that's 0.0015586731024086475 task and 0.0003204728418495506 recon and 3.9773364067077637 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027103353245183826\n",
      "\n",
      "Total loss: 0.002918114885687828; that's 0.0016507491236552596 task and 0.0003202816878911108 recon and 4.735419750213623 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002658285270445049\n",
      "\n",
      "Total loss: 0.0024012478534132242; that's 0.0014631878584623337 task and 0.00031348085030913353 recon and 3.1228957176208496 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002599334947299212\n",
      "\n",
      "Total recon loss: 0.005132561549544334; that's 4.241831302642822 text and 0.0008907300652936101 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004747010834980756\n",
      "\n",
      "Total loss: 0.0028886012732982635; that's 0.0018869597697630525 task and 0.0003161670174449682 recon and 3.427372455596924 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002643661943729967\n",
      "\n",
      "Total loss: 0.0022026447113603354; that's 0.001339988666586578 task and 0.00030649497057311237 recon and 2.7808055877685547 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026311889197677372\n",
      "\n",
      "Total recon loss: 0.004011951386928558; that's 3.487586259841919 text and 0.0005243650521151721 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004720540584530681\n",
      "\n",
      "Total loss: 0.0028213514015078545; that's 0.0016556319314986467 task and 0.0003063030308112502 recon and 4.297083377838135 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00256119373254478\n",
      "\n",
      "Total loss: 0.0024908469058573246; that's 0.0016172243049368262 task and 0.0003121299378108233 recon and 2.8074636459350586 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026271385932341218\n",
      "\n",
      "Total loss: 0.0024217606987804174; that's 0.001393888145685196 task and 0.0003075016720686108 recon and 3.6018548011779785 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002659583429340273\n",
      "\n",
      "Total recon loss: 0.0052847350016236305; that's 4.570840358734131 text and 0.0007138948421925306 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004873325512744486\n",
      "\n",
      "Total loss: 0.002558238571509719; that's 0.001463306718505919 task and 0.00031431595562025905 recon and 3.9030799865722656 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00254483082331717\n",
      "\n",
      "Total loss: 0.0027627241797745228; that's 0.0015580832259729505 task and 0.00030682949000038207 recon and 4.4890570640563965 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002615388131234795\n",
      "\n",
      "Total loss: 0.002460819436237216; that's 0.0014441508101299405 task and 0.00030891195638105273 recon and 3.5387840270996094 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027288349042646587\n",
      "\n",
      "Total recon loss: 0.004853258840739727; that's 4.092806339263916 text and 0.0007604522397741675 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004875460765324533\n",
      "\n",
      "Total loss: 0.0025012874975800514; that's 0.0013880431652069092 task and 0.00030949560459703207 recon and 4.018743515014648 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027202911744825544\n",
      "\n",
      "Total loss: 0.0019038603641092777; that's 0.0008842878160066903 task and 0.00030496096587739885 recon and 3.5730581283569336 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026946545415557923\n",
      "\n",
      "Total loss: 0.002311309101060033; that's 0.0012347942683845758 task and 0.00031197030330076814 recon and 3.822723388671875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026908644987270235\n",
      "\n",
      "Total recon loss: 0.0046164835803210735; that's 3.7114522457122803 text and 0.0009050311055034399 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004940948779694736\n",
      "\n",
      "Total loss: 0.00254985224455595; that's 0.0014708635862916708 task and 0.00031889681122265756 recon and 3.800459623336792 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026351515762507915\n",
      "\n",
      "Total loss: 0.002547103213146329; that's 0.0015269211726263165 task and 0.00031183144892565906 recon and 3.541752815246582 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025814189575612545\n",
      "\n",
      "Total loss: 0.0028812442906200886; that's 0.0017411882290616632 task and 0.0003013982204720378 recon and 4.193289279937744 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002626196499913931\n",
      "\n",
      "Total recon loss: 0.004411828704178333; that's 3.689021587371826 text and 0.0007228070171549916 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004720789063721895\n",
      "\n",
      "Total loss: 0.0029000663198530674; that's 0.0017494765343144536 task and 0.00030952616361901164 recon and 4.205318927764893 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026140264747664334\n",
      "\n",
      "Total loss: 0.0028308085165917873; that's 0.0018014853121712804 task and 0.00031650441815145314 recon and 3.564093589782715 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026126146572642028\n",
      "\n",
      "Total loss: 0.002531125210225582; that's 0.0015050857327878475 task and 0.00031146695255301893 recon and 3.572861909866333 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026141854468733072\n",
      "\n",
      "Total recon loss: 0.0053027477115392685; that's 4.505990505218506 text and 0.0007967569981701672 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0049497251166030765\n",
      "\n",
      "Total loss: 0.003151229117065668; that's 0.0016543468227609992 task and 0.0003188272239640355 recon and 5.890275478363037 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026351405563764274\n",
      "\n",
      "Total loss: 0.002629348775371909; that's 0.0014888659352436662 task and 0.0003128718526568264 recon and 4.138054847717285 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002632136601023376\n",
      "\n",
      "Total loss: 0.0028222929686307907; that's 0.0018776529468595982 task and 0.00031528310501016676 recon and 3.146784782409668 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026871410920284687\n",
      "\n",
      "Total recon loss: 0.004194791428744793; that's 3.547006130218506 text and 0.0006477853166870773 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0048603590158745645\n",
      "\n",
      "Total loss: 0.0024884240701794624; that's 0.0016020971816033125 task and 0.00031126447720453143 recon and 2.875312328338623 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002593887853436172\n",
      "\n",
      "Total loss: 0.00256031914614141; that's 0.001529724569991231 task and 0.0003135872248094529 recon and 3.585036277770996 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026446465007029475\n",
      "\n",
      "Total loss: 0.0031398702412843704; that's 0.0021407566964626312 task and 0.00030830729519948363 recon and 3.4540317058563232 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026571986498311164\n",
      "\n",
      "Total loss: 0.0031146982219070196; that's 0.0018475051037967205 task and 0.00031193182803690434 recon and 4.776306629180908 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026913072494789956\n",
      "\n",
      "Total recon loss: 0.004261787515133619; that's 3.4710452556610107 text and 0.0007907419931143522 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004816956862341613\n",
      "\n",
      "Total loss: 0.0027961113955825567; that's 0.0019008646486327052 task and 0.00030128256184980273 recon and 2.9698212146759033 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025246549281291663\n",
      "\n",
      "Total loss: 0.0024542263709008694; that's 0.0015366898151114583 task and 0.00030814140336588025 recon and 3.0469751358032227 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002530437319073826\n",
      "\n",
      "Total recon loss: 0.005677341017872095; that's 4.908255577087402 text and 0.0007690850761719048 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004672318981029093\n",
      "\n",
      "Total loss: 0.002561237197369337; that's 0.0016264427686110139 task and 0.0003492538817226887 recon and 2.927704095840454 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002478375141508877\n",
      "\n",
      "Total loss: 0.0024413438513875008; that's 0.001462667598389089 task and 0.0003100848407484591 recon and 3.3429574966430664 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024675469449721276\n",
      "\n",
      "Total loss: 0.0026820937637239695; that's 0.0014403876848518848 task and 0.0003137155144941062 recon and 4.639952659606934 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025186459301039577\n",
      "\n",
      "Total recon loss: 0.005646086763590574; that's 4.888157844543457 text and 0.0007579282973892987 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004598722036462277\n",
      "\n",
      "Total loss: 0.0027967337518930435; that's 0.0015296998899430037 task and 0.0003069886297453195 recon and 4.80022668838501 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027639956725761293\n",
      "\n",
      "Total loss: 0.002417328767478466; that's 0.0014818619238212705 task and 0.00030730856815353036 recon and 3.140791893005371 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002737402175553143\n",
      "\n",
      "Total loss: 0.0026187084149569273; that's 0.0016940226778388023 task and 0.00032026664121076465 recon and 3.0220954418182373 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025445898924954234\n",
      "\n",
      "Total loss: 0.00232060719281435; that's 0.0014659633161500096 task and 0.00030782725661993027 recon and 2.7340824604034424 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024059465841855853\n",
      "\n",
      "Total recon loss: 0.004725640174001455; that's 3.882789373397827 text and 0.0008428507135249674 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004655806249938905\n",
      "\n",
      "Total loss: 0.0027852635830640793; that's 0.001759166014380753 task and 0.00032232666853815317 recon and 3.5188543796539307 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028584873001091184\n",
      "\n",
      "Total loss: 0.002512449398636818; that's 0.0015204526716843247 task and 0.0003214245371054858 recon and 3.3528614044189453 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002458683650474995\n",
      "\n",
      "Total loss: 0.002731958869844675; that's 0.0014850059524178505 task and 0.00031323207076638937 recon and 4.668603897094727 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026141845784150063\n",
      "\n",
      "Total recon loss: 0.004776348359882832; that's 3.9508285522460938 text and 0.0008255194406956434 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004668893984053284\n",
      "\n",
      "Total loss: 0.002611840143799782; that's 0.0011805478716269135 task and 0.0003135335573460907 recon and 5.588794231414795 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026785374875180424\n",
      "\n",
      "Total loss: 0.002843519439920783; that's 0.0017859296640381217 task and 0.0003133761347271502 recon and 3.7210676670074463 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002618577182292938\n",
      "\n",
      "Total recon loss: 0.006044091656804085; that's 5.433671474456787 text and 0.0006104197818785906 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004909863481298089\n",
      "\n",
      "Total loss: 0.002372336806729436; that's 0.0011837161146104336 task and 0.00030712393345311284 recon and 4.40748405456543 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026503477967344223\n",
      "\n",
      "Total loss: 0.0025774468667805195; that's 0.0013804465997964144 task and 0.00030743502429686487 recon and 4.447826862335205 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002720436176750809\n",
      "\n",
      "Total loss: 0.002938405144959688; that's 0.0015055901603773236 task and 0.00030958393472246826 recon and 5.616155624389648 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002714523538015783\n",
      "\n",
      "Total recon loss: 0.004267773125320673; that's 3.4324791431427 text and 0.0008352939039468765 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004644234897568822\n",
      "\n",
      "Total loss: 0.0027483957819640636; that's 0.0016714846715331078 task and 0.00030296234763227403 recon and 3.8697447776794434 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002625112230889499\n",
      "\n",
      "Total loss: 0.0028239418752491474; that's 0.0015705458354204893 task and 0.000301347958156839 recon and 4.7602410316467285 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025666255434043704\n",
      "\n",
      "Total loss: 0.0027506486512720585; that's 0.0019413343397900462 task and 0.00029525920399464667 recon and 2.57027530670166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025825165980495513\n",
      "\n",
      "Total recon loss: 0.005124468822032213; that's 4.199608325958252 text and 0.0009248603018932045 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004693408983293921\n",
      "\n",
      "Total loss: 0.0029429630376398563; that's 0.002091923961415887 task and 0.0003038001013919711 recon and 2.7361948490142822 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024893852858804168\n",
      "\n",
      "Total loss: 0.0026942130643874407; that's 0.001455879071727395 task and 0.000304509827401489 recon and 4.6691203117370605 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002486452885204926\n",
      "\n",
      "Total loss: 0.002395386341959238; that's 0.0015710131265223026 task and 0.00029965219437144697 recon and 2.623605728149414 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025276420637965202\n",
      "\n",
      "Total loss: 0.0021261251531541348; that's 0.001353027648292482 task and 0.0002983136218972504 recon and 2.3739192485809326 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024885265179909765\n",
      "\n",
      "Total recon loss: 0.004983473569154739; that's 4.332496166229248 text and 0.0006509771919809282 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00477082947269082\n",
      "\n",
      "Total loss: 0.0026482101529836655; that's 0.0015442775329574943 task and 0.0003047729260288179 recon and 3.9957995414733887 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025498673296533523\n",
      "\n",
      "Total loss: 0.0021390134934335947; that's 0.0013283102307468653 task and 0.00030208597308956087 recon and 2.543086290359497 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002571418520528823\n",
      "\n",
      "Total recon loss: 0.005382196046411991; that's 4.53112268447876 text and 0.0008510735351592302 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00466911997180432\n",
      "\n",
      "Total loss: 0.002101600170135498; that's 0.0013046368258073926 task and 0.000304330576909706 recon and 2.4631643295288086 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002486746006179601\n",
      "\n",
      "Total loss: 0.0020510393660515547; that's 0.001201139995828271 task and 0.00029971450567245483 recon and 2.750924587249756 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024964744574390353\n",
      "\n",
      "Total loss: 0.0025215577334165573; that's 0.0017073494382202625 task and 0.00029615149833261967 recon and 2.5902836322784424 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023562455317005515\n",
      "\n",
      "Total loss: 0.0022536232136189938; that's 0.0013620111858472228 task and 0.00030131012317724526 recon and 2.951509475708008 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022734466008841993\n",
      "\n",
      "Total recon loss: 0.004854441620409489; that's 4.126848220825195 text and 0.0007275936659425497 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00434417681535706\n",
      "\n",
      "Total loss: 0.002604396315291524; that's 0.001367066754028201 task and 0.0003092660044785589 recon and 4.640317440032959 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026174603262916207\n",
      "\n",
      "Total loss: 0.0028739753179252148; that's 0.0014244804624468088 task and 0.0003155447484459728 recon and 5.669750213623047 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027128052990883587\n",
      "\n",
      "Total recon loss: 0.0038777044974267483; that's 3.20637583732605 text and 0.0006713286275044084 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004376333432737738\n",
      "\n",
      "Total loss: 0.0025990400463342667; that's 0.0015818419633433223 task and 0.0003130500263068825 recon and 3.520739793777466 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0027330116392113267\n",
      "\n",
      "Total loss: 0.0028011403046548367; that's 0.0012951126554980874 task and 0.0002987002662848681 recon and 6.036637783050537 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028568259766325356\n",
      "\n",
      "Total loss: 0.0028841381426900625; that's 0.001961365109309554 task and 0.00030446622986346483 recon and 3.0915334224700928 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002584576812805608\n",
      "\n",
      "Total recon loss: 0.003900344716385007; that's 3.3593082427978516 text and 0.0005410361918620765 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004787361400667578\n",
      "\n",
      "Total loss: 0.002189991297200322; that's 0.001443912391550839 task and 0.000308605027385056 recon and 2.1873691082000732 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023366666107904168\n",
      "\n",
      "Total loss: 0.0022064666263759136; that's 0.0013575642369687557 task and 0.000297916674753651 recon and 2.7549290657043457 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002308594600763172\n",
      "\n",
      "Total loss: 0.002329157665371895; that's 0.0015447668265551329 task and 0.00029715278651565313 recon and 2.436190605163574 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00227373439935036\n",
      "\n",
      "Total loss: 0.002425003796815872; that's 0.001599362469278276 task and 0.0002963234146591276 recon and 2.646589756011963 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023218705446925014\n",
      "\n",
      "Total recon loss: 0.0033145251218229532; that's 2.5801327228546143 text and 0.0007343923789449036 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004501855119597167\n",
      "\n",
      "Total loss: 0.0022268176544457674; that's 0.0014631848316639662 task and 0.0003039723087567836 recon and 2.298302412033081 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023188917036168276\n",
      "\n",
      "Total loss: 0.002351175993680954; that's 0.0015573702985420823 task and 0.00030908884946256876 recon and 2.4235846996307373 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002239414795767516\n",
      "\n",
      "Total loss: 0.0023810158018022776; that's 0.0014884795527905226 task and 0.0003048499347642064 recon and 2.93843150138855 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022609280073083936\n",
      "\n",
      "Total recon loss: 0.005507334601134062; that's 4.8648457527160645 text and 0.0006424888852052391 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004358093815390021\n",
      "\n",
      "Total loss: 0.0026743197813630104; that's 0.0017451095627620816 task and 0.0003136451996397227 recon and 3.0778262615203857 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00235792315332219\n",
      "\n",
      "Total loss: 0.002061040373519063; that's 0.001293980865739286 task and 0.0003005733888130635 recon and 2.332430362701416 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023084864730481057\n",
      "\n",
      "Total loss: 0.002354125026613474; that's 0.0015863640001043677 task and 0.00029254500987008214 recon and 2.376079797744751 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002257605945924297\n",
      "\n",
      "Total recon loss: 0.0050221215933561325; that's 4.276069164276123 text and 0.0007460521883331239 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004539520614780485\n",
      "\n",
      "Total loss: 0.0024497194681316614; that's 0.0016174332704395056 task and 0.0003055265115108341 recon and 2.633798599243164 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022909283358603714\n",
      "\n",
      "Total loss: 0.0018985107308253646; that's 0.001136778388172388 task and 0.00031388833303935826 recon and 2.239220380783081 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023176914523355663\n",
      "\n",
      "Total recon loss: 0.004482259973883629; that's 3.797624111175537 text and 0.0006846355390734971 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004657502004411071\n",
      "\n",
      "Total loss: 0.002279271837323904; that's 0.001533777336589992 task and 0.00029886275297030807 recon and 2.233158826828003 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022981169691774993\n",
      "\n",
      "Total loss: 0.0019660822581499815; that's 0.0011020693928003311 task and 0.00031430000672116876 recon and 2.7485647201538086 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023564189905300736\n",
      "\n",
      "Total loss: 0.002081365790218115; that's 0.0012466548942029476 task and 0.0002931674534920603 recon and 2.7077174186706543 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023252263013273477\n",
      "\n",
      "Total recon loss: 0.004473397508263588; that's 3.873375177383423 text and 0.0006000219145789742 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004477456682361662\n",
      "\n",
      "Total loss: 0.00309610553085804; that's 0.002294264966621995 task and 0.0003029353101737797 recon and 2.4945266246795654 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022872155206277965\n",
      "\n",
      "Total loss: 0.002122271806001663; that's 0.0013425768120214343 task and 0.00030708752456121147 recon and 2.363037109375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023008999682497234\n",
      "\n",
      "Total loss: 0.0019258968532085419; that's 0.0011682830518111587 task and 0.00031310587655752897 recon and 2.2225396633148193 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002266183579340577\n",
      "\n",
      "Total recon loss: 0.0036928215995430946; that's 2.9392659664154053 text and 0.0007535554468631744 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004058565113227814\n",
      "\n",
      "Total loss: 0.0021979662124067545; that's 0.0014843599637970328 task and 0.0003065941564273089 recon and 2.035059928894043 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023215709486976268\n",
      "\n",
      "Total loss: 0.0018856448587030172; that's 0.0010938085615634918 task and 0.00029769743559882045 recon and 2.470693826675415 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002247116524958983\n",
      "\n",
      "Total loss: 0.00230430462397635; that's 0.0015044989995658398 task and 0.0003074641281273216 recon and 2.461707353591919 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002260899501852691\n",
      "\n",
      "Total recon loss: 0.0050634173676371574; that's 4.223106861114502 text and 0.0008403105312027037 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004296743201557547\n",
      "\n",
      "Total loss: 0.00240045553073287; that's 0.0016805405030027032 task and 0.00030709640122950077 recon and 2.0640928745269775 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022848528111353516\n",
      "\n",
      "Total loss: 0.0022319357376545668; that's 0.0014129735063761473 task and 0.00029590309713967144 recon and 2.615295886993408 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022420232649892568\n",
      "\n",
      "Total loss: 0.0024794619530439377; that's 0.0016018718015402555 task and 0.00029744755011051893 recon and 2.9007134437561035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023100529180373995\n",
      "\n",
      "Total recon loss: 0.003878198331221938; that's 3.0094544887542725 text and 0.0008687437511980534 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003916332260705531\n",
      "\n",
      "Total loss: 0.0020503674168139696; that's 0.0013407421065494418 task and 0.00029468306456692517 recon and 2.074711799621582 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002299704379402101\n",
      "\n",
      "Total loss: 0.002501687267795205; that's 0.0015918356366455555 task and 0.000308305025100708 recon and 3.007733106613159 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002308511121664196\n",
      "\n",
      "Total loss: 0.002179440576583147; that's 0.0013695901725441217 task and 0.00031064474023878574 recon and 2.496027946472168 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021884190815035253\n",
      "\n",
      "Total recon loss: 0.0027551837265491486; that's 2.1926968097686768 text and 0.000562486588023603 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038720080908387897\n",
      "\n",
      "Total loss: 0.002502148738130927; that's 0.0016498311888426542 task and 0.00030057551339268684 recon and 2.7587103843688965 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00223590642795898\n",
      "\n",
      "Total loss: 0.0038622007705271244; that's 0.0015160412294790149 task and 0.0003172878932673484 recon and 10.14435863494873 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026037034834735097\n",
      "\n",
      "Total loss: 0.003507590387016535; that's 0.0013793783728033304 task and 0.0003151796408928931 recon and 9.065162658691406 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0032945906976237895\n",
      "\n",
      "Total recon loss: 0.005617557559162378; that's 4.94120454788208 text and 0.000676353054586798 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004757363128010184\n",
      "\n",
      "Total loss: 0.0035104011185467243; that's 0.0015553361736238003 task and 0.0002947768953163177 recon and 8.301441192626953 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003141308624763042\n",
      "\n",
      "Total loss: 0.002628206741064787; that's 0.0017854232573881745 task and 0.00029764921055175364 recon and 2.7256712913513184 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025769242737442256\n",
      "\n",
      "Total loss: 0.00239113112911582; that's 0.0016197743825614452 task and 0.00030201030313037336 recon and 2.3467323780059814 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002291577187133953\n",
      "\n",
      "Total loss: 0.0023726385552436113; that's 0.001190996845252812 task and 0.000293630117084831 recon and 4.440058708190918 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002750684975180775\n",
      "\n",
      "Total recon loss: 0.0033671618439257145; that's 2.747213363647461 text and 0.0006199484341777861 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003959619228262454\n",
      "\n",
      "Total loss: 0.0027000175323337317; that's 0.0014530830085277557 task and 0.00030743269599042833 recon and 4.697508811950684 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002719473042525351\n",
      "\n",
      "Total loss: 0.002204617951065302; that's 0.0013900954509153962 task and 0.0002969517663586885 recon and 2.5878541469573975 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002608884871006012\n",
      "\n",
      "Total recon loss: 0.004747151397168636; that's 3.9985673427581787 text and 0.0007485842215828598 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004356727537233382\n",
      "\n",
      "Total loss: 0.0024993186816573143; that's 0.0016644119750708342 task and 0.0003068266960326582 recon and 2.6404001712799072 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002340906463796273\n",
      "\n",
      "Total loss: 0.002394519280642271; that's 0.0013850356917828321 task and 0.0003106477379333228 recon and 3.4941792488098145 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022083262330852447\n",
      "\n",
      "Total loss: 0.00282821012660861; that's 0.0019644778221845627 task and 0.0003073365078307688 recon and 2.7819790840148926 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022846484638284893\n",
      "\n",
      "Total recon loss: 0.007119528949260712; that's 6.3983988761901855 text and 0.0007211297051981091 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004614379666745663\n",
      "\n",
      "Total loss: 0.0035085808485746384; that's 0.001448125229217112 task and 0.0002944041043519974 recon and 8.8302583694458 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003127701664343476\n",
      "\n",
      "Total loss: 0.0035895234905183315; that's 0.0014615865657106042 task and 0.00030377518851310015 recon and 9.120808601379395 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003244731890736148\n",
      "\n",
      "Total loss: 0.0021800983231514692; that's 0.0014289311366155744 task and 0.0003103126073256135 recon and 2.204272985458374 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0031773979379795493\n",
      "\n",
      "Total recon loss: 0.00550705986097455; that's 4.864052772521973 text and 0.000643006875179708 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005216530784964562\n",
      "\n",
      "Total loss: 0.0039030935149639845; that's 0.0017486338037997484 task and 0.0002988800115417689 recon and 9.277898788452148 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0031612297799438237\n",
      "\n",
      "Total loss: 0.0036700598429888487; that's 0.0015913803363218904 task and 0.00030544758192263544 recon and 8.866159439086914 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0032036244752816855\n",
      "\n",
      "Total loss: 0.002445484511554241; that's 0.001413523219525814 task and 0.0002951589412987232 recon and 3.684011459350586 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026162601169198753\n",
      "\n",
      "Total recon loss: 0.004726499784737825; that's 3.844088077545166 text and 0.0008824114920571446 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004509342540986836\n",
      "\n",
      "Total loss: 0.002134140348061919; that's 0.0012306704884395003 task and 0.0003034277760889381 recon and 3.0002100467681885 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023950806038919837\n",
      "\n",
      "Total loss: 0.002345737535506487; that's 0.001477189245633781 task and 0.0003103952913079411 recon and 2.7907657623291016 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022932579030748457\n",
      "\n",
      "Total loss: 0.001839646021835506; that's 0.0011213318211957812 task and 0.0003003163728863001 recon and 2.089989185333252 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022621931415051223\n",
      "\n",
      "Total loss: 0.0019247622694820166; that's 0.0011964699951931834 task and 0.0003024245088454336 recon and 2.129338502883911 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002213534282054752\n",
      "\n",
      "Total recon loss: 0.005128657910972834; that's 4.438482761383057 text and 0.0006901746382936835 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004489330113865435\n",
      "\n",
      "Total loss: 0.0021409341134130955; that's 0.001392874401062727 task and 0.0002945297455880791 recon and 2.2676498889923096 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002256279363064095\n",
      "\n",
      "Total loss: 0.002613726072013378; that's 0.0013577936915680766 task and 0.0002997948613483459 recon and 4.7806878089904785 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002299818142782897\n",
      "\n",
      "Total recon loss: 0.002839311258867383; that's 2.102708101272583 text and 0.0007366029894910753 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0036107826745137572\n",
      "\n",
      "Total loss: 0.0027086231857538223; that's 0.0015601833583787084 task and 0.0003098786692135036 recon and 4.192806720733643 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002617011135444045\n",
      "\n",
      "Total loss: 0.0027733889874070883; that's 0.001689584576524794 task and 0.00031453100382350385 recon and 3.8463668823242188 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002592395965475589\n",
      "\n",
      "Total loss: 0.00242937752045691; that's 0.0015151132829487324 task and 0.00029388582333922386 recon and 3.1018924713134766 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025867840996943413\n",
      "\n",
      "Total recon loss: 0.0025361671578139067; that's 1.9909894466400146 text and 0.0005451775505207479 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00275347076356411\n",
      "\n",
      "Total loss: 0.002242129063233733; that's 0.0012941245222464204 task and 0.000301332154776901 recon and 3.2333619594573975 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025852026278153062\n",
      "\n",
      "Total loss: 0.0022116126492619514; that's 0.0012464200844988227 task and 0.0003047462669201195 recon and 3.3022310733795166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00224316306761466\n",
      "\n",
      "Total loss: 0.0019122571684420109; that's 0.0013019064208492637 task and 0.00029144639847800136 recon and 1.5945217609405518 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002232591473730281\n",
      "\n",
      "Total recon loss: 0.0034706853330135345; that's 2.6151480674743652 text and 0.0008555370732210577 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003346702428534627\n",
      "\n",
      "Total loss: 0.0024343072436749935; that's 0.001647314871661365 task and 0.0002952946815639734 recon and 2.458489179611206 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021859206026419997\n",
      "\n",
      "Total loss: 0.0023873194586485624; that's 0.0016952510923147202 task and 0.00030272884760051966 recon and 1.9466983079910278 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002202292567817494\n",
      "\n",
      "Total loss: 0.001766381086781621; that's 0.0009929134976118803 task and 0.00030309282010421157 recon and 2.3518736362457275 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021851334243547173\n",
      "\n",
      "Total recon loss: 0.0026062410324811935; that's 1.9245398044586182 text and 0.0006817011744715273 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035501239751465617\n",
      "\n",
      "Total loss: 0.0020802882499992847; that's 0.0013972456799820065 task and 0.00029644937603734434 recon and 1.9329664707183838 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002152364873327315\n",
      "\n",
      "Total loss: 0.001932119601406157; that's 0.0011926405131816864 task and 0.0002952114155050367 recon and 2.2213382720947266 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021742357907351107\n",
      "\n",
      "Total loss: 0.0024748314172029495; that's 0.0016797068528831005 task and 0.0003007817140314728 recon and 2.4717137813568115 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002160490942187607\n",
      "\n",
      "Total recon loss: 0.0032747273799031973; that's 2.6113808155059814 text and 0.00066334631992504 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00389636141480878\n",
      "\n",
      "Total loss: 0.002292392775416374; that's 0.0015283358516171575 task and 0.000283566681900993 recon and 2.402451992034912 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002147809852613136\n",
      "\n",
      "Total loss: 0.00214158627204597; that's 0.0013300020946189761 task and 0.000304393150145188 recon and 2.5359556674957275 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002233661764767021\n",
      "\n",
      "Total loss: 0.001933249644935131; that's 0.001254069386050105 task and 0.0002980295103043318 recon and 1.9057537317276 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022580431390088053\n",
      "\n",
      "Total recon loss: 0.004810748156160116; that's 4.161486625671387 text and 0.000649261346552521 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037770879175513983\n",
      "\n",
      "Total loss: 0.0019149275030940771; that's 0.0011048823362216353 task and 0.00029290307429619133 recon and 2.5857110023498535 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002191730060148984\n",
      "\n",
      "Total loss: 0.002062265295535326; that's 0.0012254888424649835 task and 0.0002994207898154855 recon and 2.6867787837982178 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002203883717302233\n",
      "\n",
      "Total loss: 0.0020695526618510485; that's 0.0013042265782132745 task and 0.0002970555506180972 recon and 2.3413524627685547 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002229465019190684\n",
      "\n",
      "Total recon loss: 0.005090883933007717; that's 4.49599552154541 text and 0.000594888289924711 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004311505209188909\n",
      "\n",
      "Total loss: 0.002335993805900216; that's 0.0013507698895409703 task and 0.0002994672395288944 recon and 3.4287831783294678 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00229533476755023\n",
      "\n",
      "Total loss: 0.002366740722209215; that's 0.0014776510652154684 task and 0.0003076675347983837 recon and 2.9071106910705566 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023276002425700426\n",
      "\n",
      "Total loss: 0.0021590832620859146; that's 0.0013189866440370679 task and 0.00028990136343054473 recon and 2.750976085662842 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002222547838464379\n",
      "\n",
      "Total recon loss: 0.0045735593885183334; that's 3.7683281898498535 text and 0.0008052309858612716 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004615864080842584\n",
      "\n",
      "Total loss: 0.002389599336311221; that's 0.0016092886216938496 task and 0.00030918302945792675 recon and 2.355638027191162 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022169966960791498\n",
      "\n",
      "Total loss: 0.002111193723976612; that's 0.0014333382714539766 task and 0.00029541479307226837 recon and 1.9122036695480347 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022231560153886678\n",
      "\n",
      "Total loss: 0.002189998049288988; that's 0.0012319739907979965 task and 0.0002877218066714704 recon and 3.3515114784240723 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002248547029448673\n",
      "\n",
      "Total recon loss: 0.005091359838843346; that's 4.483410358428955 text and 0.0006079490412957966 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004278122549876571\n",
      "\n",
      "Total loss: 0.0020740695763379335; that's 0.0011646599741652608 task and 0.000300445914035663 recon and 3.044818639755249 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002242220116313547\n",
      "\n",
      "Total loss: 0.002839981345459819; that's 0.001555974711664021 task and 0.0003104103961959481 recon and 4.867981433868408 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025127148488536476\n",
      "\n",
      "Total loss: 0.002394505310803652; that's 0.0012787847081199288 task and 0.0002932670176960528 recon and 4.112267971038818 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025600502104498445\n",
      "\n",
      "Total recon loss: 0.004663655534386635; that's 3.976471424102783 text and 0.0006871835794299841 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004892545829061418\n",
      "\n",
      "Total loss: 0.0025650514289736748; that's 0.0012608446413651109 task and 0.0003043196629732847 recon and 4.999436378479004 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002533646267838776\n",
      "\n",
      "Total loss: 0.0022762848529964685; that's 0.0014638901920989156 task and 0.0002915749792009592 recon and 2.6040985584259033 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022752363199833783\n",
      "\n",
      "Total loss: 0.0026656072586774826; that's 0.0018267874838784337 task and 0.0003060794260818511 recon and 2.663701295852661 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021372775046620517\n",
      "\n",
      "Total recon loss: 0.005366602446883917; that's 4.811341285705566 text and 0.0005552612128667533 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004584814934059977\n",
      "\n",
      "Total loss: 0.0022381870076060295; that's 0.0016631146427243948 task and 0.0002942450519185513 recon and 1.4041359424591064 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002126340636750683\n",
      "\n",
      "Total loss: 0.002280395943671465; that's 0.0015322071267291903 task and 0.000301507709082216 recon and 2.2334063053131104 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002166882585734129\n",
      "\n",
      "Total loss: 0.001882858807221055; that's 0.0012059081345796585 task and 0.0002959076955448836 recon and 1.9052150249481201 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021357723930850625\n",
      "\n",
      "Total recon loss: 0.007059324998408556; that's 6.374772548675537 text and 0.0006845525349490345 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004369294801726938\n",
      "\n",
      "Total loss: 0.0037359013222157955; that's 0.0014997839462012053 task and 0.0003041611926164478 recon and 9.659781455993652 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003249085828429088\n",
      "\n",
      "Total loss: 0.003461953718215227; that's 0.0012942985631525517 task and 0.0003033812972716987 recon and 9.321369171142578 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0033014044212177395\n",
      "\n",
      "Total loss: 0.0027326890267431736; that's 0.0013420183677226305 task and 0.0003024601610377431 recon and 5.44105339050293 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0032676974032074214\n",
      "\n",
      "Total recon loss: 0.00616940064355731; that's 5.4019904136657715 text and 0.0007674098596908152 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005448790353257209\n",
      "\n",
      "Total loss: 0.0033104699105024338; that's 0.0012208978878334165 task and 0.00032064798870123923 recon and 8.844619750976562 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0034095121175050733\n",
      "\n",
      "Total loss: 0.00346476212143898; that's 0.0012940737651661038 task and 0.0003195847966708243 recon and 9.25551700592041 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003310431158170104\n",
      "\n",
      "Total loss: 0.0028229018207639456; that's 0.0014436165802180767 task and 0.0003028961946256459 recon and 5.381945610046387 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.003224557200446725\n",
      "\n",
      "Total recon loss: 0.005089468788355589; that's 4.448642253875732 text and 0.0006408263579942286 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0053658952936530115\n",
      "\n",
      "Total loss: 0.0019096366595476866; that's 0.0011122318683192134 task and 0.00031230723834596574 recon and 2.425487995147705 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002260791405569762\n",
      "\n",
      "Total loss: 0.00223548524081707; that's 0.0014157212572172284 task and 0.0003062748583033681 recon and 2.567445993423462 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021761987172067166\n",
      "\n",
      "Total loss: 0.0018842564895749092; that's 0.0011476761428639293 task and 0.0002925781882368028 recon and 2.220010995864868 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020953641680534927\n",
      "\n",
      "Total loss: 0.0019972571171820164; that's 0.001267240266315639 task and 0.0002869007003027946 recon and 2.215580701828003 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002106065434636548\n",
      "\n",
      "Total recon loss: 0.0035386672243475914; that's 2.790682554244995 text and 0.0007479845662601292 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00361060579540208\n",
      "\n",
      "Total loss: 0.002214050618931651; that's 0.001484137144871056 task and 0.00030275603057816625 recon and 2.135787010192871 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020774813636671753\n",
      "\n",
      "Total loss: 0.0022434622514992952; that's 0.001546857412904501 task and 0.00029171627829782665 recon and 2.024442672729492 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002076526277232915\n",
      "\n",
      "Total recon loss: 0.0028105785604566336; that's 2.3067431449890137 text and 0.0005038352101109922 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00384823078289628\n",
      "\n",
      "Total loss: 0.0019099987111985683; that's 0.0010972615564242005 task and 0.00029597102547995746 recon and 2.5838305950164795 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002124309561913833\n",
      "\n",
      "Total loss: 0.0018711136654019356; that's 0.0011346874525770545 task and 0.00028803249006159604 recon and 2.241968870162964 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002098153373226523\n",
      "\n",
      "Total loss: 0.0021458722185343504; that's 0.0013367235660552979 task and 0.0002929154725279659 recon and 2.5811657905578613 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021595054655335843\n",
      "\n",
      "Total loss: 0.0019337015692144632; that's 0.0012857605470344424 task and 0.0003017823910340667 recon and 1.7307931184768677 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020850491244345905\n",
      "\n",
      "Total recon loss: 0.0031277346424758434; that's 2.555030345916748 text and 0.0005727041861973703 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037212084815837444\n",
      "\n",
      "Total loss: 0.0021742642857134342; that's 0.0012496012495830655 task and 0.00028584044775925577 recon and 3.1941134929656982 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022025750007014723\n",
      "\n",
      "Total loss: 0.0019315113313496113; that's 0.0011551782954484224 task and 0.0002948360051959753 recon and 2.407485246658325 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002263748162658885\n",
      "\n",
      "Total recon loss: 0.003767873626202345; that's 3.1498985290527344 text and 0.0006179750198498368 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0036156731401570143\n",
      "\n",
      "Total loss: 0.002306697890162468; that's 0.0015275651821866632 task and 0.00028472879785113037 recon and 2.472020149230957 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022291565546765924\n",
      "\n",
      "Total loss: 0.0025648358277976513; that's 0.0016997437924146652 task and 0.00028511512209661305 recon and 2.8998851776123047 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022437610744964333\n",
      "\n",
      "Total loss: 0.0023322992492467165; that's 0.0015136112924665213 task and 0.00030183730996213853 recon and 2.5842533111572266 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002235702492762357\n",
      "\n",
      "Total recon loss: 0.004811711143702269; that's 4.1872992515563965 text and 0.000624411622993648 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037383733154274525\n",
      "\n",
      "Total loss: 0.0024672469589859247; that's 0.0014139829436317086 task and 0.0002892988850362599 recon and 3.8198256492614746 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023089791811071337\n",
      "\n",
      "Total loss: 0.002448825631290674; that's 0.0012626011157408357 task and 0.0002991340297739953 recon and 4.435451984405518 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00256164045073092\n",
      "\n",
      "Total loss: 0.002445103833451867; that's 0.0012687096605077386 task and 0.0002991408109664917 recon and 4.386266708374023 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002564321747049689\n",
      "\n",
      "Total loss: 0.002815237268805504; that's 0.0016791984671726823 task and 0.0002927859022747725 recon and 4.216264724731445 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002577765097375959\n",
      "\n",
      "Total recon loss: 0.0043545314110815525; that's 3.5684478282928467 text and 0.0007860834011808038 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0041943052806891505\n",
      "\n",
      "Total loss: 0.0024378823582082987; that's 0.0012305009877309203 task and 0.00028991856379434466 recon and 4.587314128875732 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025424627074971794\n",
      "\n",
      "Total loss: 0.0027697659097611904; that's 0.0016229531029239297 task and 0.00028757061227224767 recon and 4.296210765838623 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002635289435274899\n",
      "\n",
      "Total loss: 0.0025590728037059307; that's 0.0012192674912512302 task and 0.0003042439348064363 recon and 5.177806854248047 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0028727394039742647\n",
      "\n",
      "Total recon loss: 0.00401492603123188; that's 3.1051175594329834 text and 0.0009098082082346082 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004495457513257861\n",
      "\n",
      "Total loss: 0.0028719757683575153; that's 0.0013844113564118743 task and 0.0003075737040489912 recon and 5.899954319000244 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002722670950461179\n",
      "\n",
      "Total loss: 0.0023843669332563877; that's 0.0014965723967179656 task and 0.00029025733238086104 recon and 2.9876859188079834 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0025610093609429894\n",
      "\n",
      "Total recon loss: 0.0039770095609128475; that's 3.2938857078552246 text and 0.0006831236532889307 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004377469997853041\n",
      "\n",
      "Total loss: 0.0020262275356799364; that's 0.001254699076525867 task and 0.0002969118067994714 recon and 2.3730838298797607 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021218307223170997\n",
      "\n",
      "Total loss: 0.0018066547345370054; that's 0.0011137754190713167 task and 0.00028522752108983696 recon and 2.0382587909698486 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001976871204096824\n",
      "\n",
      "Total loss: 0.0019791019149124622; that's 0.0012873891973868012 task and 0.0002966384345199913 recon and 1.9753711223602295 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019838898943271488\n",
      "\n",
      "Total recon loss: 0.0028874478302896023; that's 1.9848867654800415 text and 0.0009025608887895942 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004172189875971526\n",
      "\n",
      "Total loss: 0.0020117813255637884; that's 0.0014473686460405588 task and 0.0002920608676504344 recon and 1.3617594242095947 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002054922218667343\n",
      "\n",
      "Total loss: 0.002250978024676442; that's 0.0015678700292482972 task and 0.0002908982860390097 recon and 1.9610488414764404 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020647461828775704\n",
      "\n",
      "Total loss: 0.002295379526913166; that's 0.0013618406374007463 task and 0.0003023029421456158 recon and 3.1561806201934814 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002117649380816147\n",
      "\n",
      "Total recon loss: 0.0031532489228993654; that's 2.6288743019104004 text and 0.0005243744817562401 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0031102037732489408\n",
      "\n",
      "Total loss: 0.0023872775491327047; that's 0.0015530138043686748 task and 0.0002919657854363322 recon and 2.7114899158477783 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002226627063937485\n",
      "\n",
      "Total loss: 0.0022721001878380775; that's 0.001411469536833465 task and 0.00029405992245301604 recon and 2.8328535556793213 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022271453228313474\n",
      "\n",
      "Total loss: 0.0020921514369547367; that's 0.0012738120276480913 task and 0.0002859947853721678 recon and 2.6617238521575928 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002183567420579493\n",
      "\n",
      "Total recon loss: 0.0039010890759527683; that's 3.1975808143615723 text and 0.0007035079761408269 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0032709544920362533\n",
      "\n",
      "Total loss: 0.001864441903308034; that's 0.0010744576575234532 task and 0.0002872814948204905 recon and 2.5135138034820557 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002195727527141571\n",
      "\n",
      "Total loss: 0.002344807144254446; that's 0.0016046615783125162 task and 0.00029723081388510764 recon and 2.214573621749878 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002227605666266754\n",
      "\n",
      "Total loss: 0.002505282871425152; that's 0.0015638821059837937 task and 0.0003086077922489494 recon and 3.1639654636383057 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021842724934685977\n",
      "\n",
      "Total recon loss: 0.004128393717110157; that's 3.4991183280944824 text and 0.0006292752223089337 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003643942382186651\n",
      "\n",
      "Total loss: 0.0021999813616275787; that's 0.0013772344682365656 task and 0.0003051797393709421 recon and 2.5878353118896484 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002195512857288122\n",
      "\n",
      "Total loss: 0.002251095836982131; that's 0.0012597398599609733 task and 0.00029158202232792974 recon and 3.4988694190979004 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002315254892455414\n",
      "\n",
      "Total loss: 0.0023993155919015408; that's 0.001455299207009375 task and 0.00029572565108537674 recon and 3.2414534091949463 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002438019337132573\n",
      "\n",
      "Total recon loss: 0.00477013923227787; that's 3.7969212532043457 text and 0.0009732179460115731 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038720794417895377\n",
      "\n",
      "Total loss: 0.002447022357955575; that's 0.0012842423748224974 task and 0.0002922633138950914 recon and 4.352582931518555 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002363094133324921\n",
      "\n",
      "Total loss: 0.002398452255874872; that's 0.0012188717955723405 task and 0.00030312989838421345 recon and 4.3822526931762695 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002396866598865017\n",
      "\n",
      "Total loss: 0.0023160798009485006; that's 0.0013609240995720029 task and 0.00028632034081965685 recon and 3.344177007675171 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00246477619279176\n",
      "\n",
      "Total recon loss: 0.005815178621560335; that's 4.967921733856201 text and 0.0008472568588331342 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038063403754495084\n",
      "\n",
      "Total loss: 0.0023523555137217045; that's 0.001098220469430089 task and 0.0002924371510744095 recon and 4.808489799499512 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024508260376751422\n",
      "\n",
      "Total loss: 0.0027189450338482857; that's 0.0016151098534464836 task and 0.00029123941203579307 recon and 4.062979221343994 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002516544561367482\n",
      "\n",
      "Total loss: 0.002190784551203251; that's 0.001177484286017716 task and 0.0002954858646262437 recon and 3.5890722274780273 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023525118094403297\n",
      "\n",
      "Total recon loss: 0.002861082786694169; that's 2.1933014392852783 text and 0.0006677813362330198 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035589534952305255\n",
      "\n",
      "Total loss: 0.001952985767275095; that's 0.0012094317935407162 task and 0.0002984419115819037 recon and 2.225560426712036 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002350805054884404\n",
      "\n",
      "Total loss: 0.0019503084477037191; that's 0.001218506833538413 task and 0.0002974355884362012 recon and 2.171830177307129 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023367619258351626\n",
      "\n",
      "Total loss: 0.0025512445718050003; that's 0.001344813033938408 task and 0.00028708638274110854 recon and 4.5967254638671875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002374435248784721\n",
      "\n",
      "Total recon loss: 0.002976668067276478; that's 2.2586023807525635 text and 0.0007180655375123024 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004479901187587529\n",
      "\n",
      "Total loss: 0.002387493848800659; that's 0.001401973539032042 task and 0.0002903330896515399 recon and 3.4759364128112793 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023831978370435535\n",
      "\n",
      "Total loss: 0.002186419675126672; that's 0.0012805499136447906 task and 0.0002949591143988073 recon and 3.054553270339966 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023719924269244076\n",
      "\n",
      "Total loss: 0.0019813303370028734; that's 0.0011123106814920902 task and 0.0002972260699607432 recon and 2.858968496322632 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022686674585565923\n",
      "\n",
      "Total recon loss: 0.0027362373657524586; that's 2.143482208251953 text and 0.0005927551537752151 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.002906554606743157\n",
      "\n",
      "Total loss: 0.0028345631435513496; that's 0.0018674994353204966 task and 0.0002900070685427636 recon and 3.3852827548980713 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023390687466599046\n",
      "\n",
      "Total loss: 0.002317214384675026; that's 0.0012366172159090638 task and 0.0002851839817594737 recon and 3.9770665168762207 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023588380648288877\n",
      "\n",
      "Total loss: 0.002593285171315074; that's 0.0013456883607432246 task and 0.000292278709821403 recon and 4.776590824127197 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002298320702975616\n",
      "\n",
      "Total loss: 0.0028131986036896706; that's 0.0015023938613012433 task and 0.00029003212694078684 recon and 5.10386323928833 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024187744280789046\n",
      "\n",
      "Total recon loss: 0.005676736123859882; that's 5.026642799377441 text and 0.0006500930758193135 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0031608400610275565\n",
      "\n",
      "Total loss: 0.002055454533547163; that's 0.0011441124370321631 task and 0.0002932207135017961 recon and 3.0906074047088623 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002318943836726248\n",
      "\n",
      "Total loss: 0.0020667361095547676; that's 0.0012511126697063446 task and 0.0002883686393033713 recon and 2.636274576187134 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00241788491839543\n",
      "\n",
      "Total recon loss: 0.002630308037623763; that's 1.9706496000289917 text and 0.0006596583407372236 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003367610235000029\n",
      "\n",
      "Total loss: 0.0021276914048939943; that's 0.0013960468349978328 task and 0.00028112175641581416 recon and 2.2526142597198486 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022329694079235196\n",
      "\n",
      "Total loss: 0.0020361554343253374; that's 0.0012012689840048552 task and 0.00028732692589983344 recon and 2.737797260284424 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021300820738542827\n",
      "\n",
      "Total loss: 0.0022297403775155544; that's 0.0013166680000722408 task and 0.0003031413652934134 recon and 3.049654722213745 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002192829642444849\n",
      "\n",
      "Total loss: 0.0022022873163223267; that's 0.0013838683953508735 task and 0.0002969101769849658 recon and 2.6075439453125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023199336684774606\n",
      "\n",
      "Total recon loss: 0.002666960936039686; that's 1.8795980215072632 text and 0.0007873627473600209 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003256217116722837\n",
      "\n",
      "Total loss: 0.0022365357726812363; that's 0.0015345201827585697 task and 0.0002817380300257355 recon and 2.1013882160186768 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023938981734681875\n",
      "\n",
      "Total loss: 0.00230385665781796; that's 0.0016360466834157705 task and 0.00029255280969664454 recon and 1.8762860298156738 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020627281186170877\n",
      "\n",
      "Total recon loss: 0.005741072818636894; that's 5.124319076538086 text and 0.0006167532992549241 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003923819076735526\n",
      "\n",
      "Total loss: 0.0023015844635665417; that's 0.0014671128010377288 task and 0.000284845067653805 recon and 2.7481324672698975 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002353651609737426\n",
      "\n",
      "Total loss: 0.002606193535029888; that's 0.001141975517384708 task and 0.00028540613129734993 recon and 5.894059181213379 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00227182230562903\n",
      "\n",
      "Total loss: 0.0026607185136526823; that's 0.001622578245587647 task and 0.0002856990904547274 recon and 3.7622056007385254 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002359298673691228\n",
      "\n",
      "Total loss: 0.0021210345439612865; that's 0.001210440183058381 task and 0.0002929449547082186 recon and 3.088247537612915 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024085309240035714\n",
      "\n",
      "Total recon loss: 0.0030184858478605747; that's 2.3761744499206543 text and 0.0006423111772164702 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0032807753747329115\n",
      "\n",
      "Total loss: 0.0028636730276048183; that's 0.0013876027660444379 task and 0.00030383095145225525 recon and 5.861196994781494 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026177859760355203\n",
      "\n",
      "Total loss: 0.00228660530410707; that's 0.0010078103514388204 task and 0.0002791206643451005 recon and 4.998371601104736 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002551050817128271\n",
      "\n",
      "Total loss: 0.0025808813516050577; that's 0.0012494351249188185 task and 0.0002800482325255871 recon and 5.2569899559021 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0026225720648653805\n",
      "\n",
      "Total recon loss: 0.004869919270277023; that's 4.143831253051758 text and 0.0007260877755470574 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004333237714599818\n",
      "\n",
      "Total loss: 0.0022943145595490932; that's 0.0012778601376339793 task and 0.000300289539154619 recon and 3.580825090408325 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002549126783851534\n",
      "\n",
      "Total loss: 0.0029091760516166687; that's 0.0017603420419618487 task and 0.00029208732303231955 recon and 4.283732891082764 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002556132023455575\n",
      "\n",
      "Total recon loss: 0.002874771598726511; that's 2.1754822731018066 text and 0.0006992890266701579 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003949679229408503\n",
      "\n",
      "Total loss: 0.0023667304776608944; that's 0.0014928218442946672 task and 0.00028081072377972305 recon and 2.965489625930786 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002436269732424989\n",
      "\n",
      "Total loss: 0.0026789384428411722; that's 0.0017796678002923727 task and 0.0002908473543357104 recon and 3.042116165161133 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002187143898336217\n",
      "\n",
      "Total loss: 0.0018528748769313097; that's 0.0010236294474452734 task and 0.00028931329143233597 recon and 2.699660539627075 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002222677052486688\n",
      "\n",
      "Total loss: 0.00264252838678658; that's 0.001743439119309187 task and 0.000286553637124598 recon and 3.062678813934326 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022910142259206625\n",
      "\n",
      "Total recon loss: 0.004141237586736679; that's 3.5105719566345215 text and 0.0006306656869128346 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00449247460346669\n",
      "\n",
      "Total loss: 0.0024102882016450167; that's 0.0013970161089673638 task and 0.0002939396072179079 recon and 3.5966625213623047 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022836625576019287\n",
      "\n",
      "Total loss: 0.0021798901725560427; that's 0.001261293888092041 task and 0.0002842381363734603 recon and 3.1717910766601562 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002290612420765683\n",
      "\n",
      "Total recon loss: 0.0052176411263644695; that's 4.586888790130615 text and 0.0006307521252892911 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004626759777311236\n",
      "\n",
      "Total loss: 0.0022410389501601458; that's 0.0012342783156782389 task and 0.0002858280495274812 recon and 3.6046628952026367 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002301657384959981\n",
      "\n",
      "Total loss: 0.0022603804245591164; that's 0.0012190690031275153 task and 0.00028501998167485 recon and 3.781456708908081 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002248099531279877\n",
      "\n",
      "Total loss: 0.002222296316176653; that's 0.0013484726659953594 task and 0.0002881511172745377 recon and 2.9283626079559326 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002230878710979596\n",
      "\n",
      "Total recon loss: 0.0033534392714500427; that's 2.7471840381622314 text and 0.0006062551401555538 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00433839688077569\n",
      "\n",
      "Total loss: 0.0022160112857818604; that's 0.0012424611486494541 task and 0.0002985882165376097 recon and 3.374809980392456 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002233527924399823\n",
      "\n",
      "Total loss: 0.0016838816227391362; that's 0.0011197515996173024 task and 0.00028430912061594427 recon and 1.399104356765747 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002102766903117299\n",
      "\n",
      "Total loss: 0.002079997444525361; that's 0.0012405335437506437 task and 0.00027944098110310733 recon and 2.800114631652832 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022428504086565225\n",
      "\n",
      "Total recon loss: 0.003367388155311346; that's 2.406697988510132 text and 0.0009606900275684893 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0032980523747392\n",
      "\n",
      "Total loss: 0.002086712745949626; that's 0.0012341768015176058 task and 0.0002964356099255383 recon and 2.7805020809173584 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002174369002459571\n",
      "\n",
      "Total loss: 0.002038676291704178; that's 0.0013266671448946 task and 0.0002793817257042974 recon and 2.1631364822387695 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002080833521904424\n",
      "\n",
      "Total loss: 0.002495631342753768; that's 0.001756713492795825 task and 0.00029120739782229066 recon and 2.2385523319244385 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021576327632647006\n",
      "\n",
      "Total recon loss: 0.0028328688349574804; that's 2.1397550106048584 text and 0.0006931137177161872 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00318767131306231\n",
      "\n",
      "Total loss: 0.0021227665711194277; that's 0.001123232999816537 task and 0.0002929845068138093 recon and 3.532745122909546 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002092728419229388\n",
      "\n",
      "Total loss: 0.0023486714344471693; that's 0.0012678193161264062 task and 0.00028988681151531637 recon and 3.9548263549804688 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021222624264191836\n",
      "\n",
      "Total loss: 0.0023849569261074066; that's 0.001716077676974237 task and 0.00029090739553794265 recon and 1.8898600339889526 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002266090966295451\n",
      "\n",
      "Total recon loss: 0.0034274414647370577; that's 2.637209892272949 text and 0.0007902314537204802 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0031871172576211394\n",
      "\n",
      "Total loss: 0.0017855344340205193; that's 0.0011253650300204754 task and 0.00029423146042972803 recon and 1.8296899795532227 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019974705181084575\n",
      "\n",
      "Total loss: 0.00219597271643579; that's 0.0016002494376152754 task and 0.0002827659191098064 recon and 1.5647865533828735 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020037840493023398\n",
      "\n",
      "Total loss: 0.002012263284996152; that's 0.0014042588882148266 task and 0.0002907895250245929 recon and 1.5860743522644043 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020115864963736385\n",
      "\n",
      "Total recon loss: 0.003169106086716056; that's 2.4129607677459717 text and 0.0007561451639048755 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0030509597877971827\n",
      "\n",
      "Total loss: 0.0019314443925395608; that's 0.0011987051693722606 task and 0.00028526748064905405 recon and 2.237358808517456 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001997395973885432\n",
      "\n",
      "Total loss: 0.0023658338468521833; that's 0.0015534736448898911 task and 0.00028494952130131423 recon and 2.6370537281036377 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002057344594504684\n",
      "\n",
      "Total loss: 0.001996664796024561; that's 0.0013663762947544456 task and 0.00029006964177824557 recon and 1.701094388961792 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00206704372423701\n",
      "\n",
      "Total loss: 0.0021883202716708183; that's 0.0014837528578937054 task and 0.00028137778281234205 recon and 2.115947723388672 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019468795438297092\n",
      "\n",
      "Total recon loss: 0.00272079324349761; that's 2.07915997505188 text and 0.0006416331161744893 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0030653559183701873\n",
      "\n",
      "Total loss: 0.0019833268597722054; that's 0.0011886904248967767 task and 0.0002910697367042303 recon and 2.517833709716797 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002072394355200231\n",
      "\n",
      "Total loss: 0.0025837458670139313; that's 0.0015774467028677464 task and 0.0002909933973569423 recon and 3.576529026031494 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021423135546501724\n",
      "\n",
      "Total recon loss: 0.0029141546692699194; that's 2.3832616806030273 text and 0.0005308929830789566 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0031129494472406805\n",
      "\n",
      "Total loss: 0.0023010186851024628; that's 0.0014430235605686903 task and 0.0002910109469667077 recon and 2.834920644760132 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021507043519522996\n",
      "\n",
      "Total loss: 0.0026745828799903393; that's 0.0016708592884242535 task and 0.00028531672433018684 recon and 3.5920345783233643 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002230174092110246\n",
      "\n",
      "Total loss: 0.001965508097782731; that's 0.0012014503590762615 task and 0.0002900444087572396 recon and 2.3700666427612305 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021269107796251774\n",
      "\n",
      "Total recon loss: 0.002820889465510845; that's 2.2219982147216797 text and 0.0005988911143504083 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0030655203014612197\n",
      "\n",
      "Total loss: 0.002014312194660306; that's 0.0013239156687632203 task and 0.00028881500475108624 recon and 2.0079081058502197 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002119097012327984\n",
      "\n",
      "Total loss: 0.0024218717589974403; that's 0.0016326552722603083 task and 0.00028423761250451207 recon and 2.5248939990997314 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021509648149367422\n",
      "\n",
      "Total loss: 0.0026418522465974092; that's 0.0016240808181464672 task and 0.0002896430960390717 recon and 3.6406421661376953 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022134526388254017\n",
      "\n",
      "Total recon loss: 0.0057107554748654366; that's 4.759426593780518 text and 0.00095132872229442 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003573838376905769\n",
      "\n",
      "Total loss: 0.002380513586103916; that's 0.0014319259207695723 task and 0.00029241404263302684 recon and 3.2808685302734375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002276404018048197\n",
      "\n",
      "Total loss: 0.001740931416861713; that's 0.0011983573203906417 task and 0.00027870782651007175 recon and 1.319331169128418 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002050478297751397\n",
      "\n",
      "Total loss: 0.002095967996865511; that's 0.0014359792694449425 task and 0.0002762407239060849 recon and 1.9187393188476562 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021316391276195645\n",
      "\n",
      "Total recon loss: 0.004800355061888695; that's 4.10120964050293 text and 0.0006991452537477016 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004722672023344785\n",
      "\n",
      "Total loss: 0.002205710392445326; that's 0.0013285266468301415 task and 0.00028420158196240664 recon and 2.964911460876465 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021502674382645635\n",
      "\n",
      "Total loss: 0.002330089919269085; that's 0.0014730719849467278 task and 0.0002865148999262601 recon and 2.852515459060669 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00224398921825923\n",
      "\n",
      "Total loss: 0.0018029101192951202; that's 0.001130713731981814 task and 0.00026857067132368684 recon and 2.0181283950805664 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020210003515239803\n",
      "\n",
      "Total loss: 0.0023966110311448574; that's 0.001293542212806642 task and 0.0002751341962721199 recon and 4.139673233032227 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001983840422471985\n",
      "\n",
      "Total recon loss: 0.0052814665250480175; that's 4.723456859588623 text and 0.000558009254746139 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004659391746390611\n",
      "\n",
      "Total loss: 0.001948237419128418; that's 0.0012942077592015266 task and 0.000284453941276297 recon and 1.8478786945343018 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020632578898221255\n",
      "\n",
      "Total loss: 0.0020984853617846966; that's 0.001353633590042591 task and 0.0002751941210590303 recon and 2.3482885360717773 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019445927685592323\n",
      "\n",
      "Total recon loss: 0.0033424575813114643; that's 2.6400933265686035 text and 0.0007023641373962164 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004364242551382631\n",
      "\n",
      "Total loss: 0.0020217886194586754; that's 0.0010312794474884868 task and 0.00028370640939101577 recon and 3.5340144634246826 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020546107192058118\n",
      "\n",
      "Total loss: 0.0021368819288909435; that's 0.0012681963853538036 task and 0.00027681858045980334 recon and 2.9593346118927 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021197885007131845\n",
      "\n",
      "Total loss: 0.0023005204275250435; that's 0.001189152942970395 task and 0.000292242388240993 recon and 4.095624923706055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022862334467936307\n",
      "\n",
      "Total recon loss: 0.003184479894116521; that's 2.6896278858184814 text and 0.0004948520218022168 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0033768509817309676\n",
      "\n",
      "Total loss: 0.002254502149298787; that's 0.0012235086178407073 task and 0.0002827789285220206 recon and 3.741072654724121 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022411514818668366\n",
      "\n",
      "Total loss: 0.0021824301220476627; that's 0.001122775487601757 task and 0.000286421796772629 recon and 3.866163969039917 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022383972618263215\n",
      "\n",
      "Total loss: 0.002325656358152628; that's 0.0011740694753825665 task and 0.000281645538052544 recon and 4.349706649780273 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022762868832796814\n",
      "\n",
      "Total recon loss: 0.003167929593473673; that's 2.434382438659668 text and 0.000733547261916101 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003270933725871146\n",
      "\n",
      "Total loss: 0.0024875132367014885; that's 0.0014784696977585554 task and 0.0002863605332095176 recon and 3.6134157180786133 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002290869483258575\n",
      "\n",
      "Total loss: 0.0020959125831723213; that's 0.0011218144791200757 task and 0.00028319371631368995 recon and 3.454521894454956 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002248651613481343\n",
      "\n",
      "Total loss: 0.0019712408538907766; that's 0.0010979450307786465 task and 0.00028325794846750796 recon and 2.9501898288726807 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002222730650100857\n",
      "\n",
      "Total recon loss: 0.0035411943681538105; that's 2.935926914215088 text and 0.0006052671815268695 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0032488725706934928\n",
      "\n",
      "Total loss: 0.0020333509892225266; that's 0.001128140720538795 task and 0.0002820251102093607 recon and 3.1159262657165527 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022645518684294074\n",
      "\n",
      "Total loss: 0.0023418772034347057; that's 0.0012930311495438218 task and 0.0002838911022990942 recon and 3.8247742652893066 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002226020368980244\n",
      "\n",
      "Total loss: 0.002472229767590761; that's 0.0015253571327775717 task and 0.00028077352908439934 recon and 3.330495595932007 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002284078620141372\n",
      "\n",
      "Total recon loss: 0.0037910945247858763; that's 2.8978323936462402 text and 0.000893262040335685 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003174645977560431\n",
      "\n",
      "Total loss: 0.002250887220725417; that's 0.0012113208649680018 task and 0.00027931039221584797 recon and 3.8012795448303223 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002409013700671494\n",
      "\n",
      "Total loss: 0.0023509948514401913; that's 0.0013357228599488735 task and 0.0002816272899508476 recon and 3.6682238578796387 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023204972594976425\n",
      "\n",
      "Total loss: 0.0026837848126888275; that's 0.0015247506089508533 task and 0.0002804843825288117 recon and 4.392749309539795 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024269384937360885\n",
      "\n",
      "Total recon loss: 0.003342360956594348; that's 2.7585246562957764 text and 0.0005838360521011055 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0032067689299583434\n",
      "\n",
      "Total loss: 0.002455204725265503; that's 0.001611189218237996 task and 0.0002831452584359795 recon and 2.804352045059204 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002401557550765574\n",
      "\n",
      "Total loss: 0.0022971522994339466; that's 0.0014910566387698054 task and 0.0002820590161718428 recon and 2.620183229446411 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002065762606216595\n",
      "\n",
      "Total loss: 0.00216670916415751; that's 0.0014291934203356504 task and 0.00028539510094560683 recon and 2.260603189468384 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020880517980549486\n",
      "\n",
      "Total recon loss: 0.006016330327838659; that's 5.40667200088501 text and 0.0006096583674661815 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0034414022299461065\n",
      "\n",
      "Total loss: 0.0022090082056820393; that's 0.0013383770128712058 task and 0.0002757256443146616 recon and 2.9745285511016846 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00206297415192239\n",
      "\n",
      "Total loss: 0.0017488267039880157; that's 0.0010447936365380883 task and 0.00028055135044269264 recon and 2.117408275604248 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002039412873564288\n",
      "\n",
      "Total loss: 0.0023544891737401485; that's 0.00132524233777076 task and 0.00028153948369435966 recon and 3.7385363578796387 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002034724133554846\n",
      "\n",
      "Total recon loss: 0.0030916458927094936; that's 2.3205578327178955 text and 0.00077108817640692 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004406637935899198\n",
      "\n",
      "Total loss: 0.0021514729596674442; that's 0.0012611435959115624 task and 0.0002866119612008333 recon and 3.018587350845337 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002123919784789905\n",
      "\n",
      "Total loss: 0.002009991556406021; that's 0.0011570798233151436 task and 0.00027553841937333345 recon and 2.886867046356201 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002081118928035721\n",
      "\n",
      "Total loss: 0.0020282804034650326; that's 0.0011428659781813622 task and 0.0002878997474908829 recon and 2.9875738620758057 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021023378253448755\n",
      "\n",
      "Total recon loss: 0.005697920452803373; that's 5.04109525680542 text and 0.0006568248500116169 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004215998365543783\n",
      "\n",
      "Total loss: 0.0023498223163187504; that's 0.0014993429649621248 task and 0.00028341563302092254 recon and 2.8353190422058105 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021395417593885213\n",
      "\n",
      "Total loss: 0.0022659909445792437; that's 0.0014263808261603117 task and 0.00027825316647067666 recon and 2.8067851066589355 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021340258268173783\n",
      "\n",
      "Total loss: 0.0023026210255920887; that's 0.0015615903539583087 task and 0.00028531471616588533 recon and 2.2785799503326416 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021356311568524688\n",
      "\n",
      "Total loss: 0.0020712334662675858; that's 0.001238772994838655 task and 0.0002828955475706607 recon and 2.7478246688842773 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019943197898101062\n",
      "\n",
      "Total recon loss: 0.004579506814479828; that's 3.9052305221557617 text and 0.0006742762052454054 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004745886854361742\n",
      "\n",
      "Total loss: 0.0020418651401996613; that's 0.0012174869189038873 task and 0.000277395622106269 recon and 2.7349135875701904 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019662622339092196\n",
      "\n",
      "Total loss: 0.002017847029492259; that's 0.0013316577533259988 task and 0.00028128791018389165 recon and 2.0245070457458496 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001988352236803621\n",
      "\n",
      "Total recon loss: 0.0029445895925164223; that's 2.270030975341797 text and 0.0006745585706084967 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003592379551846534\n",
      "\n",
      "Total loss: 0.002024624031037092; that's 0.0013538718922063708 task and 0.0002799471840262413 recon and 1.9540241956710815 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019314306159503758\n",
      "\n",
      "Total loss: 0.0019468053942546248; that's 0.0012638112530112267 task and 0.00028241254040040076 recon and 2.0029079914093018 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019015597505494953\n",
      "\n",
      "Total loss: 0.0021967061329632998; that's 0.0015809842152521014 task and 0.0002714801812544465 recon and 1.7212083339691162 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019502435042522848\n",
      "\n",
      "Total recon loss: 0.005347354803234339; that's 4.416471004486084 text and 0.0009308835142292082 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004365207131486386\n",
      "\n",
      "Total loss: 0.0021470231004059315; that's 0.00144974107388407 task and 0.00028415402630344033 recon and 2.0656402111053467 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019407698255963623\n",
      "\n",
      "Total loss: 0.002040327060967684; that's 0.001287825871258974 task and 0.000278898689430207 recon and 2.3680126667022705 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018866831937339157\n",
      "\n",
      "Total loss: 0.0022689620964229107; that's 0.0013175506610423326 task and 0.00027634395519271493 recon and 3.375338315963745 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001961374410893768\n",
      "\n",
      "Total loss: 0.0019499718910083175; that's 0.001187451183795929 task and 0.00027954805409535766 recon and 2.414862871170044 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020674326398875563\n",
      "\n",
      "Total recon loss: 0.004589623771607876; that's 3.8174142837524414 text and 0.0007722096052020788 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004717335232999176\n",
      "\n",
      "Total loss: 0.00196796259842813; that's 0.001358315465040505 task and 0.00028644484700635076 recon and 1.6160109043121338 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020330934843514115\n",
      "\n",
      "Total loss: 0.0024299481883645058; that's 0.0013094155583530664 task and 0.00027484126621857285 recon and 4.228456497192383 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002435436707455665\n",
      "\n",
      "Total recon loss: 0.005017896182835102; that's 4.477418422698975 text and 0.00054047757294029 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004492777108680457\n",
      "\n",
      "Total loss: 0.0014769025146961212; that's 0.0009342318517155945 task and 0.0002839536755345762 recon and 1.2935847043991089 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018914634094107897\n",
      "\n",
      "Total loss: 0.0019431933760643005; that's 0.0013681059936061502 task and 0.0002803722454700619 recon and 1.4735760688781738 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001918680527014658\n",
      "\n",
      "Total loss: 0.0014896042412146926; that's 0.0009377014939673245 task and 0.0002759879862423986 recon and 1.3795740604400635 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018297104234807193\n",
      "\n",
      "Total loss: 0.0019376494456082582; that's 0.0011989008635282516 task and 0.00027382795815356076 recon and 2.32460355758667 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019358210102654993\n",
      "\n",
      "Total recon loss: 0.004355516284704208; that's 3.800304412841797 text and 0.0005552115035243332 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004880313794128597\n",
      "\n",
      "Total loss: 0.001614091219380498; that's 0.0010538892820477486 task and 0.0002823114627972245 recon and 1.389452338218689 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018460033729206771\n",
      "\n",
      "Total loss: 0.00250511197373271; that's 0.0013018669560551643 task and 0.00028369147912599146 recon and 4.5977678298950195 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022068564558867364\n",
      "\n",
      "Total recon loss: 0.0042215497232973576; that's 3.613015651702881 text and 0.000608534028287977 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004465919157955796\n",
      "\n",
      "Total loss: 0.0020483233965933323; that's 0.0013956342590972781 task and 0.0002804021060001105 recon and 1.8614351749420166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00201650676317513\n",
      "\n",
      "Total loss: 0.0018474734388291836; that's 0.0012885303003713489 task and 0.0002766378747764975 recon and 1.4115262031555176 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001975956473033875\n",
      "\n",
      "Total loss: 0.00201572198420763; that's 0.001281283563002944 task and 0.0002777141926344484 recon and 2.283621311187744 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002105991338612512\n",
      "\n",
      "Total recon loss: 0.005592869129031897; that's 4.7678070068359375 text and 0.0008250619866885245 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004660981339402497\n",
      "\n",
      "Total loss: 0.0020537027157843113; that's 0.001210004324093461 task and 0.00028714881045743823 recon and 2.782747507095337 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020279364800080656\n",
      "\n",
      "Total loss: 0.002418921794742346; that's 0.0013043306535109878 task and 0.00027798814699053764 recon and 4.1830153465271 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002302088981959969\n",
      "\n",
      "Total loss: 0.0023712918628007174; that's 0.0014477972872555256 task and 0.0002948208129964769 recon and 3.143368721008301 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021577032969798894\n",
      "\n",
      "Total loss: 0.0019153270404785872; that's 0.0011871460592374206 task and 0.00027973277610726655 recon and 2.2422409057617188 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020119614782743156\n",
      "\n",
      "Total recon loss: 0.0034350540954619646; that's 2.7569167613983154 text and 0.0006781371193937957 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004605479200836271\n",
      "\n",
      "Total loss: 0.0018972593825310469; that's 0.0011840183287858963 task and 0.00027299619978293777 recon and 2.201223850250244 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019058077840600164\n",
      "\n",
      "Total loss: 0.001389042939990759; that's 0.0008974832599051297 task and 0.00027550256345421076 recon and 1.0802850723266602 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001862510461360216\n",
      "\n",
      "Total loss: 0.001876756316050887; that's 0.0012572326231747866 task and 0.00027469571796245873 recon and 1.7241404056549072 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019002799061127007\n",
      "\n",
      "Total recon loss: 0.0036970998626202345; that's 2.72990345954895 text and 0.000967196247074753 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00428725264267996\n",
      "\n",
      "Total loss: 0.0022655127104371786; that's 0.0016921490896493196 task and 0.0002833942708093673 recon and 1.4498465061187744 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018638836417812854\n",
      "\n",
      "Total loss: 0.0017989389598369598; that's 0.0010320303263142705 task and 0.00028012500843033195 recon and 2.4339187145233154 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001918740269029513\n",
      "\n",
      "Total recon loss: 0.00503543671220541; that's 4.29152774810791 text and 0.0007439089240506291 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004735164539888501\n",
      "\n",
      "Total loss: 0.0017823935486376286; that's 0.001117277191951871 task and 0.00028208314324729145 recon and 1.915165662765503 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018945662234909832\n",
      "\n",
      "Total loss: 0.0022348235361278057; that's 0.001488984446041286 task and 0.00027767461142502725 recon and 2.340822219848633 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019518282567150891\n",
      "\n",
      "Total loss: 0.0019634361378848553; that's 0.0013092359295114875 task and 0.0002816350315697491 recon and 1.8628261089324951 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019327721267472953\n",
      "\n",
      "Total recon loss: 0.004961640574038029; that's 4.220239639282227 text and 0.0007414005813188851 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0039433675282634795\n",
      "\n",
      "Total loss: 0.001964666647836566; that's 0.0012102880282327533 task and 0.000279896252322942 recon and 2.3724119663238525 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019183776143472642\n",
      "\n",
      "Total loss: 0.0017087118467316031; that's 0.001066618598997593 task and 0.0002703811915125698 recon and 1.8585602045059204 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001933765795547515\n",
      "\n",
      "Total loss: 0.0016476578311994672; that's 0.000947631720919162 task and 0.0002787506382446736 recon and 2.106377363204956 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001928404257632792\n",
      "\n",
      "Total recon loss: 0.0045798420906066895; that's 3.9745991230010986 text and 0.0006052429671399295 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004007568387314677\n",
      "\n",
      "Total loss: 0.0019104512175545096; that's 0.001189183909446001 task and 0.00028123476658947766 recon and 2.2001631259918213 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002011689716018736\n",
      "\n",
      "Total loss: 0.0019201039103791118; that's 0.0010525912512093782 task and 0.0002770097053144127 recon and 2.952514886856079 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002185873900307342\n",
      "\n",
      "Total loss: 0.002314105164259672; that's 0.0014565218007192016 task and 0.0002717920287977904 recon and 2.928956985473633 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002158144130371511\n",
      "\n",
      "Total loss: 0.0020094725769013166; that's 0.0011942918645218015 task and 0.00027821335243061185 recon and 2.6848366260528564 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002042856850894168\n",
      "\n",
      "Total recon loss: 0.003520531114190817; that's 2.874873638153076 text and 0.0006456573610194027 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004550867113284767\n",
      "\n",
      "Total loss: 0.002029747236520052; that's 0.001248887157998979 task and 0.00026836938923224807 recon and 2.5624539852142334 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002009921969147399\n",
      "\n",
      "Total loss: 0.001833900110796094; that's 0.0010240867268294096 task and 0.0002671992697287351 recon and 2.7130706310272217 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020509034709539267\n",
      "\n",
      "Total recon loss: 0.0030342855025082827; that's 2.2513267993927 text and 0.0007829586393199861 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0032280271593481302\n",
      "\n",
      "Total loss: 0.0027098108548671007; that's 0.0012276042252779007 task and 0.0002809203288052231 recon and 6.006431579589844 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022599239309784025\n",
      "\n",
      "Total loss: 0.002242084126919508; that's 0.0010302660521119833 task and 0.00028188497526571155 recon and 4.649665832519531 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022881070000585167\n",
      "\n",
      "Total loss: 0.002415919676423073; that's 0.0013436494627967477 task and 0.0002750556159298867 recon and 3.9860730171203613 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023208738514222203\n",
      "\n",
      "Total recon loss: 0.005162592511624098; that's 4.442612648010254 text and 0.0007199799874797463 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004276364389806986\n",
      "\n",
      "Total loss: 0.0022840166930109262; that's 0.0013246992602944374 task and 0.00027942261658608913 recon and 3.3994743824005127 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021554876992013307\n",
      "\n",
      "Total loss: 0.0021791793406009674; that's 0.0013044808292761445 task and 0.00028397244750522077 recon and 2.953629732131958 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021823103341739626\n",
      "\n",
      "Total loss: 0.0020169911440461874; that's 0.0011986661702394485 task and 0.0002837941574398428 recon and 2.672654628753662 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002035305950557813\n",
      "\n",
      "Total recon loss: 0.004531404003500938; that's 4.068103790283203 text and 0.00046329974429681897 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004492729222401976\n",
      "\n",
      "Total loss: 0.0017214802792295814; that's 0.0009566107182763517 task and 0.00027825060533359647 recon and 2.4330947399139404 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020238816179335116\n",
      "\n",
      "Total loss: 0.0023091055918484926; that's 0.0011858806246891618 task and 0.00027065022732131183 recon and 4.262873649597168 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00233617294812575\n",
      "\n",
      "Total loss: 0.002749616513028741; that's 0.0013190980535000563 task and 0.0002768146514426917 recon and 5.768518924713135 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024635534430854024\n",
      "\n",
      "Total loss: 0.00222719251178205; that's 0.0011911870678886771 task and 0.00027652489370666444 recon and 3.797402858734131 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024030079715885223\n",
      "\n",
      "Total recon loss: 0.0036586178466677666; that's 3.0789010524749756 text and 0.0005797165213152766 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00459795996081084\n",
      "\n",
      "Total loss: 0.002447216073051095; that's 0.0011813165619969368 task and 0.0002747204271145165 recon and 4.955895900726318 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022880065278150143\n",
      "\n",
      "Total loss: 0.002475262153893709; that's 0.0010765275219455361 task and 0.00027454542578198016 recon and 5.620946884155273 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002332342902664095\n",
      "\n",
      "Total loss: 0.002208116464316845; that's 0.0010670664487406611 task and 0.0002757389738690108 recon and 4.326555252075195 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023790160566568375\n",
      "\n",
      "Total recon loss: 0.004323125351220369; that's 3.7137646675109863 text and 0.0006093603442423046 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003376518504228443\n",
      "\n",
      "Total loss: 0.0023821915965527296; that's 0.0012616340536624193 task and 0.0002651076065376401 recon and 4.277249813079834 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00237324854824692\n",
      "\n",
      "Total loss: 0.0024045018944889307; that's 0.0012553238775581121 task and 0.00027548230718821287 recon and 4.368478775024414 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023922576126642527\n",
      "\n",
      "Total recon loss: 0.0031776591204106808; that's 2.594390869140625 text and 0.0005832681199535728 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0033964204927906393\n",
      "\n",
      "Total loss: 0.002307259477674961; that's 0.0009520780295133591 task and 0.0002692553971428424 recon and 5.429630756378174 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002412467203103006\n",
      "\n",
      "Total loss: 0.002698472933843732; that's 0.0013338710414245725 task and 0.00027149252127856016 recon and 5.46554708480835 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024507620092481374\n",
      "\n",
      "Total loss: 0.0020419813226908445; that's 0.0009710324229672551 task and 0.0002746522659435868 recon and 3.9814836978912354 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002404829519800842\n",
      "\n",
      "Total recon loss: 0.0044250814244151115; that's 3.7477781772613525 text and 0.0006773032946512103 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0033957973425276576\n",
      "\n",
      "Total loss: 0.0023215049877762794; that's 0.0011228638468310237 task and 0.00027656753081828356 recon and 4.610368728637695 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023527188564185053\n",
      "\n",
      "Total loss: 0.0022591594606637955; that's 0.0010745445033535361 task and 0.0002782281080726534 recon and 4.531935214996338 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023358665488194675\n",
      "\n",
      "Total loss: 0.0021354062482714653; that's 0.0009714816696941853 task and 0.0002721187483984977 recon and 4.459028720855713 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002394223699811846\n",
      "\n",
      "Total recon loss: 0.004362315405160189; that's 3.745260715484619 text and 0.0006170544656924903 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003969957379158586\n",
      "\n",
      "Total loss: 0.001867774873971939; that's 0.0008686314686201513 task and 0.00027738040080294013 recon and 3.6088147163391113 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002309761275537312\n",
      "\n",
      "Total loss: 0.0022141491062939167; that's 0.0011303126811981201 task and 0.0002798110945150256 recon and 4.020127296447754 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022515950398519636\n",
      "\n",
      "Total loss: 0.0025738426484167576; that's 0.0015281254891306162 task and 0.0002762953517958522 recon and 3.847108840942383 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002213193466886878\n",
      "\n",
      "Total recon loss: 0.005281263962388039; that's 4.671352386474609 text and 0.0006099112797528505 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004602425971534103\n",
      "\n",
      "Total loss: 0.0020193615928292274; that's 0.001267606276087463 task and 0.0002715841110330075 recon and 2.4008564949035645 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00224300054484047\n",
      "\n",
      "Total loss: 0.0026888593565672636; that's 0.0017387793632224202 task and 0.00028280395781621337 recon and 3.33638072013855 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021903025987558065\n",
      "\n",
      "Total loss: 0.002168497070670128; that's 0.0009817362297326326 task and 0.0002812037128023803 recon and 4.527784824371338 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002307545867515728\n",
      "\n",
      "Total recon loss: 0.003950856626033783; that's 3.2850570678710938 text and 0.0006657995982095599 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0041989356698468325\n",
      "\n",
      "Total loss: 0.0021817563101649284; that's 0.001209008158184588 task and 0.00027317446074448526 recon and 3.497868537902832 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002279068083735183\n",
      "\n",
      "Total loss: 0.0022279967088252306; that's 0.0012103014159947634 task and 0.000276578008197248 recon and 3.7055869102478027 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022229296527802945\n",
      "\n",
      "Total loss: 0.0022616349160671234; that's 0.001142196706496179 task and 0.0002623672771733254 recon and 4.2853546142578125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022147684404626488\n",
      "\n",
      "Total recon loss: 0.0045695798471570015; that's 3.8277838230133057 text and 0.0007417958113364875 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0042843139497563245\n",
      "\n",
      "Total loss: 0.002394156064838171; that's 0.0013001544866710901 task and 0.00028366342303343117 recon and 4.051691055297852 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022394181368872524\n",
      "\n",
      "Total loss: 0.001977914944291115; that's 0.0010687146568670869 task and 0.0002620209415908903 recon and 3.2358973026275635 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002253269732464105\n",
      "\n",
      "Total loss: 0.0024112502578645945; that's 0.0013526573311537504 task and 0.00027585463249124587 recon and 3.913691759109497 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002183632330270484\n",
      "\n",
      "Total recon loss: 0.004707997664809227; that's 4.114107608795166 text and 0.0005938897957094014 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003539766832254827\n",
      "\n",
      "Total loss: 0.0025863545015454292; that's 0.0011773143196478486 task and 0.0002875704085454345 recon and 5.607349872589111 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022365909919608382\n",
      "\n",
      "Total loss: 0.0023802886717021465; that's 0.0014392349403351545 task and 0.0002787828561849892 recon and 3.3113551139831543 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022378361108712852\n",
      "\n",
      "Total loss: 0.002107175998389721; that's 0.0011574078816920519 task and 0.00027417766978032887 recon and 3.377953052520752 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022249945963267238\n",
      "\n",
      "Total recon loss: 0.004099735524505377; that's 3.573920249938965 text and 0.0005258150049485266 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004665678308811039\n",
      "\n",
      "Total loss: 0.0022796564735472202; that's 0.0011925743892788887 task and 0.0002717682800721377 recon and 4.076569557189941 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023759636015165597\n",
      "\n",
      "Total loss: 0.0025344162713736296; that's 0.0013256021775305271 task and 0.00027018049149774015 recon and 4.693167686462402 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023205854673869907\n",
      "\n",
      "Total loss: 0.002890330273658037; that's 0.0016439942410215735 task and 0.0002818091888912022 recon and 4.822634696960449 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023829877795651555\n",
      "\n",
      "Total recon loss: 0.004734604619443417; that's 4.140373229980469 text and 0.0005942311254329979 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004517919402569532\n",
      "\n",
      "Total loss: 0.002310985466465354; that's 0.0012016086839139462 task and 0.00027669244445860386 recon and 4.163422107696533 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002392511059297249\n",
      "\n",
      "Total loss: 0.0022265110164880753; that's 0.0011808788403868675 task and 0.00028417029534466565 recon and 3.807309150695801 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024013980326708408\n",
      "\n",
      "Total loss: 0.0029532555490732193; that's 0.0017484109848737717 task and 0.00027981025050394237 recon and 4.625171184539795 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023730193660594524\n",
      "\n",
      "Total recon loss: 0.004433826077729464; that's 3.800534725189209 text and 0.0006332912016659975 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004018946383148432\n",
      "\n",
      "Total loss: 0.0021822070702910423; that's 0.0013768072240054607 task and 0.0002750415587797761 recon and 2.6517908573150635 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022389235603623094\n",
      "\n",
      "Total loss: 0.002382774604484439; that's 0.001096020801924169 task and 0.0002864691778086126 recon and 5.001423358917236 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021396994625683874\n",
      "\n",
      "Total loss: 0.002434541704133153; that's 0.0014665762428194284 task and 0.0002693477727007121 recon and 3.4930880069732666 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002207133288029581\n",
      "\n",
      "Total recon loss: 0.003910663537681103; that's 3.2397594451904297 text and 0.00067090371157974 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004187596812844276\n",
      "\n",
      "Total loss: 0.0020426216069608927; that's 0.0010387414367869496 task and 0.0002834538172464818 recon and 3.6021320819854736 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022624594054650514\n",
      "\n",
      "Total loss: 0.0021540140733122826; that's 0.0011806924594566226 task and 0.0002762133372016251 recon and 3.4855406284332275 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022340132656972853\n",
      "\n",
      "Total loss: 0.0023052878677845; that's 0.0013659788528457284 task and 0.0002751643187366426 recon and 3.32072377204895 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022753618925344197\n",
      "\n",
      "Total recon loss: 0.0029896751511842012; that's 2.3883273601531982 text and 0.0006013477104716003 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00396547976648435\n",
      "\n",
      "Total loss: 0.0024782922118902206; that's 0.0012439924757927656 task and 0.0002715250011533499 recon and 4.813873291015625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022772397648077457\n",
      "\n",
      "Total loss: 0.00251980684697628; that's 0.0014994328375905752 task and 0.0002695524599403143 recon and 3.7541074752807617 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023636101186275483\n",
      "\n",
      "Total loss: 0.002032631542533636; that's 0.0010426861699670553 task and 0.000276434380793944 recon and 3.5675547122955322 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002275065506109968\n",
      "\n",
      "Total loss: 0.0023170236963778734; that's 0.0011704934295266867 task and 0.00027363179833628237 recon and 4.364492416381836 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022425206226762383\n",
      "\n",
      "Total recon loss: 0.0030801603570580482; that's 2.455918312072754 text and 0.0006242419476620853 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0034863684931769967\n",
      "\n",
      "Total loss: 0.002246402669698; that's 0.0012113673146814108 task and 0.0002757727634161711 recon and 3.7963123321533203 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002325142143527046\n",
      "\n",
      "Total loss: 0.002951720729470253; that's 0.0014753108844161034 task and 0.00026317156152799726 recon and 6.066191673278809 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00231629385962151\n",
      "\n",
      "Total loss: 0.002529990393668413; that's 0.0012235352769494057 task and 0.00027248956030234694 recon and 5.169826984405518 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002307593587320298\n",
      "\n",
      "Total recon loss: 0.005966818891465664; that's 5.146893501281738 text and 0.0008199253352358937 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004228159626945853\n",
      "\n",
      "Total loss: 0.0026588262990117073; that's 0.0012300796806812286 task and 0.0002726864768192172 recon and 5.780301570892334 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023166058550123125\n",
      "\n",
      "Total loss: 0.0025850613601505756; that's 0.0013465611264109612 task and 0.0002681585028767586 recon and 4.85170841217041 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022304198087658733\n",
      "\n",
      "Total recon loss: 0.0032927922438830137; that's 2.6042721271514893 text and 0.0006885200273245573 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037032050965353845\n",
      "\n",
      "Total loss: 0.00226949923671782; that's 0.0013285117456689477 task and 0.00027526202029548585 recon and 3.328626871109009 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022652850858867167\n",
      "\n",
      "Total loss: 0.002041557803750038; that's 0.0011751556303352118 task and 0.0002701418416108936 recon and 2.981301784515381 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002093419512966648\n",
      "\n",
      "Total loss: 0.0019958135671913624; that's 0.0010115705663338304 task and 0.00027429949841462076 recon and 3.549717664718628 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021536117943469434\n",
      "\n",
      "Total recon loss: 0.002728841034695506; that's 2.1409289836883545 text and 0.000587912043556571 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003660605943296105\n",
      "\n",
      "Total loss: 0.002034012461081147; that's 0.0011511076008901 task and 0.0002715991868171841 recon and 3.0565285682678223 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002209336447995156\n",
      "\n",
      "Total loss: 0.002273249439895153; that's 0.0011514081852510571 task and 0.0002724330988712609 recon and 4.247040271759033 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002184469503117725\n",
      "\n",
      "Total loss: 0.002067218767479062; that's 0.0012602517381310463 task and 0.00026917894138023257 recon and 2.6889405250549316 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002083164651412517\n",
      "\n",
      "Total recon loss: 0.0034919108729809523; that's 2.7452714443206787 text and 0.0007466392125934362 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037996907811611892\n",
      "\n",
      "Total loss: 0.002162606455385685; that's 0.0012878305278718472 task and 0.00027681695064529777 recon and 2.9897942543029785 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021505590528249742\n",
      "\n",
      "Total loss: 0.002277741674333811; that's 0.0013621121179312468 task and 0.00026608421467244625 recon and 3.2477269172668457 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020886890089605002\n",
      "\n",
      "Total loss: 0.0021912851370871067; that's 0.0011892301263287663 task and 0.0002647533256094903 recon and 3.6865081787109375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002172839401755482\n",
      "\n",
      "Total recon loss: 0.003135337959975004; that's 2.6646628379821777 text and 0.00047067514969967306 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035847796825692058\n",
      "\n",
      "Total loss: 0.0019583869725465775; that's 0.0009912123205140233 task and 0.00027761131059378386 recon and 3.4478163719177246 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021751435252372175\n",
      "\n",
      "Total loss: 0.0018665855750441551; that's 0.0010106817353516817 task and 0.00027272661100141704 recon and 2.9158856868743896 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022141962312161923\n",
      "\n",
      "Total loss: 0.0019725614693015814; that's 0.0009554950520396233 task and 0.00026585650630295277 recon and 3.756049394607544 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021995855926070364\n",
      "\n",
      "Total recon loss: 0.0038435019087046385; that's 3.1860580444335938 text and 0.0006574435974471271 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0031201040861196815\n",
      "\n",
      "Total loss: 0.0019525764510035515; that's 0.0009247215348295867 task and 0.0002706151863094419 recon and 3.786198854446411 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002153834981145337\n",
      "\n",
      "Total loss: 0.00257995817810297; that's 0.0015789145836606622 task and 0.00027154627605341375 recon and 3.647486448287964 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002203964184736833\n",
      "\n",
      "Total loss: 0.002590001793578267; that's 0.0015374557115137577 task and 0.0002776987385004759 recon and 3.874236822128296 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022061119752470404\n",
      "\n",
      "Total loss: 0.002267062198370695; that's 0.0009894842514768243 task and 0.00027302184025757015 recon and 5.022780895233154 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002219289819477126\n",
      "\n",
      "Total recon loss: 0.003470413852483034; that's 2.9677371978759766 text and 0.0005026764702051878 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035821220953948796\n",
      "\n",
      "Total loss: 0.0022125099785625935; that's 0.001283369492739439 task and 0.00027885069721378386 recon and 3.2514498233795166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002212024179752916\n",
      "\n",
      "Total loss: 0.002079818630591035; that's 0.0011202851310372353 task and 0.00026478825020603836 recon and 3.473726272583008 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022364073991775514\n",
      "\n",
      "Total recon loss: 0.002594525460153818; that's 2.0147249698638916 text and 0.000579800340346992 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0026761452085338534\n",
      "\n",
      "Total loss: 0.0023345723748207092; that's 0.0011851086746901274 task and 0.0002720864722505212 recon and 4.3868865966796875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002223478371743113\n",
      "\n",
      "Total loss: 0.0018341242102906108; that's 0.001030860934406519 task and 0.00027848672471009195 recon and 2.62388277053833 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002060675504617393\n",
      "\n",
      "Total loss: 0.0019901730120182037; that's 0.0011233707191422582 task and 0.0002762197400443256 recon and 2.952913761138916 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020083564287051558\n",
      "\n",
      "Total recon loss: 0.0026957045774906874; that's 2.136488437652588 text and 0.0005592161323875189 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.002767130380962044\n",
      "\n",
      "Total loss: 0.0018256362527608871; that's 0.0011104296427220106 task and 0.0002669864916242659 recon and 2.2411012649536133 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020425830956082793\n",
      "\n",
      "Total loss: 0.0020418581552803516; that's 0.0012001751456409693 task and 0.0002735898015089333 recon and 2.840466022491455 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023832464776933193\n",
      "\n",
      "Total loss: 0.0021316995844244957; that's 0.0011978365946561098 task and 0.00026584792067296803 recon and 3.3400754928588867 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020933798304758966\n",
      "\n",
      "Total recon loss: 0.0047725774347782135; that's 4.1759796142578125 text and 0.0005965977907180786 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0041537333605811\n",
      "\n",
      "Total loss: 0.0017999762203544378; that's 0.0009682964882813394 task and 0.0002725138037931174 recon and 2.7958297729492188 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002045097080990672\n",
      "\n",
      "Total loss: 0.0018774825148284435; that's 0.0009881401201710105 task and 0.0002565715694800019 recon and 3.1638545989990234 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019254466029815377\n",
      "\n",
      "Total loss: 0.0019142073579132557; that's 0.0011345372768118978 task and 0.0002735339221544564 recon and 2.5306808948516846 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002015827464638278\n",
      "\n",
      "Total recon loss: 0.004309465177357197; that's 3.678395986557007 text and 0.0006310689495876431 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004516194816678762\n",
      "\n",
      "Total loss: 0.0018718785140663385; that's 0.0011082685086876154 task and 0.0002715680457185954 recon and 2.460209846496582 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019871926831547173\n",
      "\n",
      "Total loss: 0.002240439411252737; that's 0.0014585029566660523 task and 0.0002669440000317991 recon and 2.5749621391296387 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020387061079964043\n",
      "\n",
      "Total loss: 0.0015247877454385161; that's 0.0009178405744023621 task and 0.0002775750763248652 recon and 1.6468605995178223 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0017582758190110325\n",
      "\n",
      "Total loss: 0.0018606893718242645; that's 0.001207812107168138 task and 0.00026259382138960063 recon and 1.9514174461364746 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001772384331561625\n",
      "\n",
      "Total recon loss: 0.004438778385519981; that's 3.843881368637085 text and 0.0005948964972048998 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004630451321136206\n",
      "\n",
      "Total loss: 0.0021100668236613274; that's 0.0014126022579148412 task and 0.000263488560449332 recon and 2.1698808670043945 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019989608426112682\n",
      "\n",
      "Total loss: 0.0022283000871539116; that's 0.0013671087799593806 task and 0.00027301383670419455 recon and 2.940886974334717 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020733147487044332\n",
      "\n",
      "Total recon loss: 0.003064753720536828; that's 2.3220224380493164 text and 0.000742731208447367 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038803363824263214\n",
      "\n",
      "Total loss: 0.002062309067696333; that's 0.001066680415533483 task and 0.00026611165958456695 recon and 3.6475846767425537 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002012804684927687\n",
      "\n",
      "Total loss: 0.002734588459134102; that's 0.001698995241895318 task and 0.00027075299294665456 recon and 3.8242013454437256 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002250593510689214\n",
      "\n",
      "Total loss: 0.0021631030831485987; that's 0.001184725435450673 task and 0.0002740937052294612 recon and 3.5214195251464844 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002351022735238075\n",
      "\n",
      "Total recon loss: 0.0026896351482719183; that's 2.0746326446533203 text and 0.000615002354606986 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003915183357894421\n",
      "\n",
      "Total loss: 0.0023362368810921907; that's 0.0013267637696117163 task and 0.0002735665475483984 recon and 3.679532527923584 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023087225330527873\n",
      "\n",
      "Total loss: 0.0020310007967054844; that's 0.0008585331379435956 task and 0.0002652085677254945 recon and 4.536295413970947 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022509690327569844\n",
      "\n",
      "Total loss: 0.0022236420772969723; that's 0.0010322973830625415 task and 0.00027239054907113314 recon and 4.594771385192871 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002269510584883392\n",
      "\n",
      "Total loss: 0.002332542557269335; that's 0.0011585685424506664 task and 0.00026382951182313263 recon and 4.550722599029541 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002297474432270974\n",
      "\n",
      "Total recon loss: 0.0029753141570836306; that's 2.4059691429138184 text and 0.0005693449056707323 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.002872742498293519\n",
      "\n",
      "Total loss: 0.0024598792660981417; that's 0.0013547654962167144 task and 0.0002731436979956925 recon and 4.159850120544434 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022445363423321397\n",
      "\n",
      "Total loss: 0.0020723864436149597; that's 0.0010909860720857978 task and 0.000263399095274508 recon and 3.5900070667266846 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023024207563139497\n",
      "\n",
      "Total recon loss: 0.004075492266565561; that's 3.4595065116882324 text and 0.0006159857730381191 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0039849030878394845\n",
      "\n",
      "Total loss: 0.002151518827304244; that's 0.0011669433442875743 task and 0.00026970362523570657 recon and 3.57435941696167 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023734850017353894\n",
      "\n",
      "Total loss: 0.0025332048535346985; that's 0.001240024110302329 task and 0.000272233912255615 recon and 5.104733943939209 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002340275675524026\n",
      "\n",
      "Total loss: 0.0027478758711367846; that's 0.0012323219561949372 task and 0.0002659881429281086 recon and 6.247828960418701 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002477296453434974\n",
      "\n",
      "Total loss: 0.002111142734065652; that's 0.0010120117804035544 task and 0.0002677921438589692 recon and 4.156693935394287 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024047765042632817\n",
      "\n",
      "Total recon loss: 0.003517222823575139; that's 2.9274768829345703 text and 0.000589745759498328 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0032062419573776423\n",
      "\n",
      "Total loss: 0.002454407513141632; that's 0.0010118978098034859 task and 0.00027405869332142174 recon and 5.842255592346191 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023650098452344536\n",
      "\n",
      "Total loss: 0.0024317544884979725; that's 0.0009293537586927414 task and 0.00026539992541074753 recon and 6.185003757476807 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0024768500472418962\n",
      "\n",
      "Total recon loss: 0.0037038419395685196; that's 3.1059324741363525 text and 0.000597909209318459 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003868515670765191\n",
      "\n",
      "Total loss: 0.00239606574177742; that's 0.0012824948644265532 task and 0.00026743629132397473 recon and 4.230673789978027 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002403879703488201\n",
      "\n",
      "Total loss: 0.0020393875893205404; that's 0.0009901353623718023 task and 0.00026502134278416634 recon and 3.921154737472534 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023601993871852755\n",
      "\n",
      "Total loss: 0.0022722629364579916; that's 0.0010275763925164938 task and 0.00026549160247668624 recon and 4.895974636077881 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023432220472022892\n",
      "\n",
      "Total recon loss: 0.003878041636198759; that's 3.1673853397369385 text and 0.0007106561097316444 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0036131582804955543\n",
      "\n",
      "Total loss: 0.0023121607955545187; that's 0.0011519031831994653 task and 0.00025660221581347287 recon and 4.518277645111084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0023417235538363457\n",
      "\n",
      "Total loss: 0.0022152848541736603; that's 0.0011741226771846414 task and 0.0002602213353384286 recon and 3.9047043323516846 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022824690211564304\n",
      "\n",
      "Total loss: 0.002618336584419012; that's 0.0013788044452667236 task and 0.0002691105182748288 recon and 4.852108001708984 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002280268333852291\n",
      "\n",
      "Total recon loss: 0.0038248624186962843; that's 3.2261040210723877 text and 0.0005987582844682038 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003989889158401638\n",
      "\n",
      "Total loss: 0.0022116180043667555; that's 0.001098400098271668 task and 0.00026506936410441995 recon and 4.2407426834106445 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002264995907898992\n",
      "\n",
      "Total loss: 0.002381168073043227; that's 0.001252491376362741 task and 0.0002738123876042664 recon and 4.274321556091309 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00230959115200676\n",
      "\n",
      "Total loss: 0.002174999099224806; that's 0.0011975412489846349 task and 0.0002684723003767431 recon and 3.5449278354644775 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021996325254440307\n",
      "\n",
      "Total recon loss: 0.003245687112212181; that's 2.64794921875 text and 0.0005977378459647298 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003777981838211417\n",
      "\n",
      "Total loss: 0.002266222843900323; that's 0.001210652058944106 task and 0.000258949730778113 recon and 3.9831058979034424 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002245873686624691\n",
      "\n",
      "Total loss: 0.002132786437869072; that's 0.0010484755039215088 task and 0.0002722265780903399 recon and 4.060422897338867 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002277165736304596\n",
      "\n",
      "Total loss: 0.0024072621017694473; that's 0.00123788567725569 task and 0.00026404441450722516 recon and 4.526659965515137 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021899982634931803\n",
      "\n",
      "Total loss: 0.0020560924895107746; that's 0.0008125536260195076 task and 0.0002740664640441537 recon and 4.847362518310547 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002232353227445856\n",
      "\n",
      "Total recon loss: 0.0029171498026698828; that's 2.2214348316192627 text and 0.0006957149016670883 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0034496380272321403\n",
      "\n",
      "Total loss: 0.0024395687505602837; that's 0.001004604622721672 task and 0.00026539491955190897 recon and 5.847846508026123 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002414502517785877\n",
      "\n",
      "Total loss: 0.0019190290477126837; that's 0.0010303817689418793 task and 0.0002629485970828682 recon and 3.128493309020996 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022241143707651644\n",
      "\n",
      "Total recon loss: 0.0032444330863654613; that's 2.754495620727539 text and 0.0004899374325759709 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00340567244682461\n",
      "\n",
      "Total loss: 0.002066732384264469; that's 0.0011018436634913087 task and 0.00027253245934844017 recon and 3.4617815017700195 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021279941825196147\n",
      "\n",
      "Total loss: 0.0021043361630290747; that's 0.0011773260775953531 task and 0.00026243829051963985 recon and 3.322859048843384 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021617223310749977\n",
      "\n",
      "Total loss: 0.0022588863503187895; that's 0.0011646859347820282 task and 0.00026805236120708287 recon and 4.130740165710449 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002159266823437065\n",
      "\n",
      "Total recon loss: 0.0028021386824548244; that's 2.1793155670166016 text and 0.0006228229030966759 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0027845379710197448\n",
      "\n",
      "Total loss: 0.0022838758304715157; that's 0.0014269209932535887 task and 0.00026054770569317043 recon and 2.9820356369018555 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022023048240225763\n",
      "\n",
      "Total loss: 0.002371331211179495; that's 0.0014178779674693942 task and 0.00026584730949252844 recon and 3.4380290508270264 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002176753180101514\n",
      "\n",
      "Total loss: 0.0022113421000540257; that's 0.0009666499681770802 task and 0.0002596047706902027 recon and 4.9254374504089355 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022506510815583167\n",
      "\n",
      "Total loss: 0.0016525201499462128; that's 0.0009334005881100893 task and 0.0002658648299984634 recon and 2.2662734985351562 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002161213248036802\n",
      "\n",
      "Total recon loss: 0.0035503199324011803; that's 2.931871175765991 text and 0.0006184486555866897 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035570406634360553\n",
      "\n",
      "Total loss: 0.002091164467856288; that's 0.0011667018989101052 task and 0.0002819694927893579 recon and 3.21246600151062 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021854093356523663\n",
      "\n",
      "Total loss: 0.0021960646845400333; that's 0.0011201553279533982 task and 0.00026932364562526345 recon and 4.032927989959717 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002264684266410768\n",
      "\n",
      "Total recon loss: 0.00417594239115715; that's 3.31010365486145 text and 0.0008658385486342013 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035110868397168816\n",
      "\n",
      "Total loss: 0.002391650341451168; that's 0.0012129786191508174 task and 0.00027894735103473067 recon and 4.498622894287109 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022077390796039252\n",
      "\n",
      "Total loss: 0.0021110549569129944; that's 0.0011697937734425068 task and 0.00026750843971967697 recon and 3.3687639236450195 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022294913337100298\n",
      "\n",
      "Total loss: 0.002251286059617996; that's 0.0012151782866567373 task and 0.0002691626432351768 recon and 3.8347251415252686 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002223415363114327\n",
      "\n",
      "Total recon loss: 0.003465409390628338; that's 2.822180986404419 text and 0.0006432281224988401 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0033214502409100533\n",
      "\n",
      "Total loss: 0.002204428892582655; that's 0.0013317818520590663 task and 0.0002736643946263939 recon and 2.9949135780334473 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022332134936004877\n",
      "\n",
      "Total loss: 0.00217372621409595; that's 0.0009942938340827823 task and 0.0002670956600923091 recon and 4.561683654785156 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022385902726091444\n",
      "\n",
      "Total loss: 0.0018067765049636364; that's 0.000924009655136615 task and 0.0002646595530677587 recon and 3.09053635597229 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022390147543046622\n",
      "\n",
      "Total recon loss: 0.003776772413402796; that's 3.1825826168060303 text and 0.0005941895651631057 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003458247669041157\n",
      "\n",
      "Total loss: 0.0019739768467843533; that's 0.0011148873018100858 task and 0.00026828685076907277 recon and 2.954012632369995 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021770956274122\n",
      "\n",
      "Total loss: 0.0024331179447472095; that's 0.0013450669357553124 task and 0.00025369683862663805 recon and 4.17177152633667 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002189235211117193\n",
      "\n",
      "Total loss: 0.0022943681105971336; that's 0.001227375934831798 task and 0.0002706061350181699 recon and 3.9819300174713135 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022748615010641515\n",
      "\n",
      "Total loss: 0.0020183096639811993; that's 0.0009175134473480284 task and 0.00027087132912129164 recon and 4.149624347686768 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022135785198770463\n",
      "\n",
      "Total recon loss: 0.004767030477523804; that's 3.9925997257232666 text and 0.0007744306931272149 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004437749851495028\n",
      "\n",
      "Total loss: 0.002166206017136574; that's 0.001094897510483861 task and 0.0002617673890199512 recon and 4.047706127166748 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002237784374738112\n",
      "\n",
      "Total loss: 0.0020950562320649624; that's 0.0010383381741121411 task and 0.0002653825213201344 recon and 3.9566776752471924 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022006975032854825\n",
      "\n",
      "Total recon loss: 0.004057849291712046; that's 3.5172224044799805 text and 0.0005406267591752112 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004159035948105156\n",
      "\n",
      "Total loss: 0.002028428250923753; that's 0.0009928183862939477 task and 0.0002682419726625085 recon and 3.8368399143218994 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002209044899791479\n",
      "\n",
      "Total loss: 0.0019126457627862692; that's 0.0009543279302306473 task and 0.0002670875401236117 recon and 3.4561517238616943 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022167385753709824\n",
      "\n",
      "Total loss: 0.0022887783125042915; that's 0.001143812551163137 task and 0.0002641778555698693 recon and 4.4039387702941895 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002217430279124528\n",
      "\n",
      "Total recon loss: 0.0031325272284448147; that's 2.649284601211548 text and 0.0004832425620406866 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004301976540591568\n",
      "\n",
      "Total loss: 0.00207587331533432; that's 0.0011337118921801448 task and 0.000264715839875862 recon and 3.3872272968292236 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022288884723093362\n",
      "\n",
      "Total loss: 0.002172641921788454; that's 0.0010497987968847156 task and 0.0002586699556559324 recon and 4.320865631103516 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002160431386437267\n",
      "\n",
      "Total loss: 0.0019410153618082404; that's 0.0009526209905743599 task and 0.0002678748860489577 recon and 3.602597236633301 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002114010603399947\n",
      "\n",
      "Total recon loss: 0.0033677886240184307; that's 2.7938811779022217 text and 0.0005739072803407907 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00406434505712241\n",
      "\n",
      "Total loss: 0.002260437235236168; that's 0.0011841203086078167 task and 0.0002706452214624733 recon and 4.0283589363098145 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022111873351968823\n",
      "\n",
      "Total loss: 0.002145699691027403; that's 0.0011439055670052767 task and 0.00026361862546764314 recon and 3.690877676010132 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022135119582526387\n",
      "\n",
      "Total loss: 0.0024801762774586678; that's 0.00138473033439368 task and 0.00026883254759013653 recon and 4.1330671310424805 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022028886119369417\n",
      "\n",
      "Total recon loss: 0.004031467251479626; that's 3.4182701110839844 text and 0.0006131970440037549 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004424421263393014\n",
      "\n",
      "Total loss: 0.0023088238667696714; that's 0.0011650394881144166 task and 0.0002748720289673656 recon and 4.34456205368042 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002231337383855134\n",
      "\n",
      "Total loss: 0.001976876985281706; that's 0.0008611524826847017 task and 0.0002761771029327065 recon and 4.197737216949463 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022055627510417252\n",
      "\n",
      "Total loss: 0.0021462999284267426; that's 0.0011574284872040153 task and 0.0002662586630322039 recon and 3.6130638122558594 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002254944869782776\n",
      "\n",
      "Total recon loss: 0.0032266410999000072; that's 2.725895404815674 text and 0.0005007456056773663 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004244965426623821\n",
      "\n",
      "Total loss: 0.0020706485956907272; that's 0.0009805986192077398 task and 0.0002649265225045383 recon and 4.125616550445557 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022220937395468353\n",
      "\n",
      "Total loss: 0.0021635594312101603; that's 0.001028561033308506 task and 0.0002664397470653057 recon and 4.3427934646606445 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002176845106296241\n",
      "\n",
      "Total loss: 0.002183105330914259; that's 0.0011018230579793453 task and 0.0002656639844644815 recon and 4.078091621398926 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022145832527894526\n",
      "\n",
      "Total recon loss: 0.004841803573071957; that's 4.271785259246826 text and 0.0005700183100998402 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038424875307828186\n",
      "\n",
      "Total loss: 0.002384323626756668; that's 0.0013347159838303924 task and 0.0002729962579905987 recon and 3.883056402206421 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022144598665181548\n",
      "\n",
      "Total loss: 0.0022947408724576235; that's 0.001171146403066814 task and 0.00026095836074091494 recon and 4.313180923461914 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002195448874263093\n",
      "\n",
      "Total loss: 0.0026248374488204718; that's 0.0014533797511830926 task and 0.0002542470465414226 recon and 4.586053371429443 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022156018042005596\n",
      "\n",
      "Total recon loss: 0.0027876957319676876; that's 2.1240899562835693 text and 0.0006636057514697313 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0032622170005925\n",
      "\n",
      "Total loss: 0.0023522803094238043; that's 0.0013418247690424323 task and 0.00026752977282740176 recon and 3.7146294116973877 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022220166167244313\n",
      "\n",
      "Total loss: 0.0024031696375459433; that's 0.0014394106110557914 task and 0.0002583949826657772 recon and 3.526820182800293 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002198334819404408\n",
      "\n",
      "Total loss: 0.002248878590762615; that's 0.0011194389080628753 task and 0.00026991701452061534 recon and 4.297614097595215 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002142049199901521\n",
      "\n",
      "Total recon loss: 0.004002549219876528; that's 3.290431261062622 text and 0.000712118053343147 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038623054791241886\n",
      "\n",
      "Total loss: 0.001867276499979198; that's 0.0009356090449728072 task and 0.00026892570895142853 recon and 3.313708543777466 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021807444759178907\n",
      "\n",
      "Total loss: 0.0023402604274451733; that's 0.0013580130180343986 task and 0.00026886985870078206 recon and 3.566887378692627 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002212132717249915\n",
      "\n",
      "Total loss: 0.0019359554862603545; that's 0.000996638904325664 task and 0.0002585288311820477 recon and 3.4039387702941895 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002235778470057994\n",
      "\n",
      "Total recon loss: 0.003701881505548954; that's 3.0218465328216553 text and 0.0006800348637625575 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004340675426647067\n",
      "\n",
      "Total loss: 0.002348897513002157; that's 0.0013895148877054453 task and 0.00025582080706954 recon and 3.5178096294403076 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022202037880197168\n",
      "\n",
      "Total loss: 0.002114915754646063; that's 0.001127839321270585 task and 0.00026275962591171265 recon and 3.62158465385437 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00215713624143973\n",
      "\n",
      "Total loss: 0.0019443487981334329; that's 0.0009386739693582058 task and 0.0002639804151840508 recon and 3.708472490310669 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021376168471761046\n",
      "\n",
      "Total recon loss: 0.004848640877753496; that's 4.095083713531494 text and 0.0007535566692240536 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004563793623819947\n",
      "\n",
      "Total loss: 0.0021312376484274864; that's 0.0011189040960744023 task and 0.0002727242826949805 recon and 3.6980462074279785 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021533604396972803\n",
      "\n",
      "Total loss: 0.0018701658118516207; that's 0.0008940343977883458 task and 0.00026336911832913756 recon and 3.563812255859375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002210737109417096\n",
      "\n",
      "Total loss: 0.0022724897135049105; that's 0.0012934202095493674 task and 0.000268940522801131 recon and 3.550644874572754 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021962729562073945\n",
      "\n",
      "Total recon loss: 0.006215345114469528; that's 5.442997932434082 text and 0.00077234668424353 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004627666322048754\n",
      "\n",
      "Total loss: 0.001951531390659511; that's 0.0009605465456843376 task and 0.00026047989376820624 recon and 3.652524948120117 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021634889859706162\n",
      "\n",
      "Total loss: 0.001966707408428192; that's 0.0010051443241536617 task and 0.00025894405553117394 recon and 3.5130960941314697 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00220473779598251\n",
      "\n",
      "Total loss: 0.0023244116455316544; that's 0.001069202902726829 task and 0.0002588011266198009 recon and 4.982038497924805 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00219688780605793\n",
      "\n",
      "Total recon loss: 0.003205020446330309; that's 2.6496450901031494 text and 0.0005553750088438392 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003954374787863344\n",
      "\n",
      "Total loss: 0.002352775540202856; that's 0.0013473775470629334 task and 0.0002619609877001494 recon and 3.7171854972839355 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002216306454502046\n",
      "\n",
      "Total loss: 0.0024258550256490707; that's 0.0013468050165101886 task and 0.0002724089426919818 recon and 4.033205032348633 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022410824231337756\n",
      "\n",
      "Total loss: 0.0021675850730389357; that's 0.0010913604637607932 task and 0.00026106793666258454 recon and 4.0757832527160645 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002164463975932449\n",
      "\n",
      "Total recon loss: 0.0037891995161771774; that's 3.2703959941864014 text and 0.0005188031354919076 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003801889510359615\n",
      "\n",
      "Total loss: 0.002026601927354932; that's 0.0010821096366271377 task and 0.000258941319771111 recon and 3.4277546405792236 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022350905078928917\n",
      "\n",
      "Total loss: 0.002042519859969616; that's 0.0010610047029331326 task and 0.00027080325526185334 recon and 3.5535593032836914 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002204864212544635\n",
      "\n",
      "Total loss: 0.0021196920424699783; that's 0.0011196850100532174 task and 0.0002682126360014081 recon and 3.6589715480804443 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022447656060103328\n",
      "\n",
      "Total recon loss: 0.0041775996796786785; that's 3.5610909461975098 text and 0.000616508477833122 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037227826775051653\n",
      "\n",
      "Total loss: 0.0018273236928507686; that's 0.0009081787429749966 task and 0.00026740197790786624 recon and 3.2587146759033203 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00219710125005804\n",
      "\n",
      "Total loss: 0.0019578752107918262; that's 0.001085012685507536 task and 0.00026244972832500935 recon and 3.0520639419555664 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022131635481491686\n",
      "\n",
      "Total loss: 0.0021707855630666018; that's 0.0013281510910019279 task and 0.0002594159450381994 recon and 2.9160923957824707 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020402345713227987\n",
      "\n",
      "Total recon loss: 0.003116446314379573; that's 2.544431209564209 text and 0.0005720150656998158 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003829554582480341\n",
      "\n",
      "Total loss: 0.002281628083437681; that's 0.001207530265673995 task and 0.00026134654763154685 recon and 4.063755989074707 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021192514686845243\n",
      "\n",
      "Total loss: 0.0020381833892315626; that's 0.001174081931822002 task and 0.00026757470914162695 recon and 2.9826340675354004 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00214727146551013\n",
      "\n",
      "Total loss: 0.002034961013123393; that's 0.0009241893421858549 task and 0.00025835607084445655 recon and 4.262078285217285 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002246616934426129\n",
      "\n",
      "Total recon loss: 0.003656413871794939; that's 3.0780746936798096 text and 0.0005783390370197594 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035353448404930534\n",
      "\n",
      "Total loss: 0.0023141964338719845; that's 0.0012741258833557367 task and 0.00025641650427132845 recon and 3.9182705879211426 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002207337432773784\n",
      "\n",
      "Total loss: 0.0024398425593972206; that's 0.0013277058023959398 task and 0.0002670699032023549 recon and 4.2253336906433105 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022361845127306878\n",
      "\n",
      "Total loss: 0.0020355451852083206; that's 0.001028356608003378 task and 0.00025396645651198924 recon and 3.76611065864563 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021837695583235475\n",
      "\n",
      "Total loss: 0.0023567115422338247; that's 0.0012224063975736499 task and 0.0002603560860734433 recon and 4.369745254516602 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002224897906417027\n",
      "\n",
      "Total recon loss: 0.0042317574843764305; that's 3.614156723022461 text and 0.0006176006863825023 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037169730314053594\n",
      "\n",
      "Total loss: 0.0023946978617459536; that's 0.0009496912243776023 task and 0.00027289841091260314 recon and 5.860541343688965 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021959240618161856\n",
      "\n",
      "Total loss: 0.002291829790920019; that's 0.0010071371216326952 task and 0.00025588972494006157 recon and 5.144014835357666 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002210096538765356\n",
      "\n",
      "Total recon loss: 0.0030482676811516285; that's 2.425449848175049 text and 0.0006228177226148546 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003475285016465932\n",
      "\n",
      "Total loss: 0.0021616530138999224; that's 0.0010574078187346458 task and 0.0002612399694044143 recon and 4.215026378631592 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002156283016083762\n",
      "\n",
      "Total loss: 0.002454911358654499; that's 0.0013238947140052915 task and 0.0002548321499489248 recon and 4.380922794342041 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022119046689476817\n",
      "\n",
      "Total loss: 0.0020444507244974375; that's 0.000909188122022897 task and 0.0002657348522916436 recon and 4.3476386070251465 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022465735860168934\n",
      "\n",
      "Total recon loss: 0.0032826741226017475; that's 2.766221284866333 text and 0.0005164525937289 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003226924065966159\n",
      "\n",
      "Total loss: 0.0023595779202878475; that's 0.0013072275323793292 task and 0.0002689122047740966 recon and 3.917191505432129 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002238313576672226\n",
      "\n",
      "Total loss: 0.0019928021356463432; that's 0.001012546243146062 task and 0.000266273389570415 recon and 3.569913148880005 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022146160516422243\n",
      "\n",
      "Total loss: 0.0017905684653669596; that's 0.0009780612308532 task and 0.00026192012592218816 recon and 2.7529354095458984 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002158231339417398\n",
      "\n",
      "Total recon loss: 0.003006539773195982; that's 2.3989288806915283 text and 0.0006076106219552457 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0031402521766722203\n",
      "\n",
      "Total loss: 0.00226964196190238; that's 0.0011345602106302977 task and 0.0002672105038072914 recon and 4.339356422424316 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021785461355466394\n",
      "\n",
      "Total loss: 0.001938045839779079; that's 0.0010117265628650784 task and 0.00026199890999123454 recon and 3.3216023445129395 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022034198022447527\n",
      "\n",
      "Total loss: 0.0021411406341940165; that's 0.0012658771593123674 task and 0.0002715099835768342 recon and 3.0187673568725586 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021005154959857462\n",
      "\n",
      "Total loss: 0.0021624304354190826; that's 0.0011192781385034323 task and 0.00026429787976667285 recon and 3.8942723274230957 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002138617120217532\n",
      "\n",
      "Total recon loss: 0.0032684151083230972; that's 2.629160165786743 text and 0.0006392550421878695 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0032013834291137757\n",
      "\n",
      "Total loss: 0.0018657678738236427; that's 0.0009110017563216388 task and 0.00026001426158472896 recon and 3.473759174346924 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002071427385089919\n",
      "\n",
      "Total loss: 0.0023418909404426813; that's 0.0012228380655869842 task and 0.00025079966871999204 recon and 4.341265678405762 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021370960643980652\n",
      "\n",
      "Total recon loss: 0.005161380395293236; that's 4.607603549957275 text and 0.0005537766264751554 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003922533737495542\n",
      "\n",
      "Total loss: 0.0023039160296320915; that's 0.0011678494047373533 task and 0.0002651216054800898 recon and 4.354725360870361 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021923848462756723\n",
      "\n",
      "Total loss: 0.0022172557655721903; that's 0.00112611660733819 task and 0.00025375644327141345 recon and 4.18691349029541 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022349609876982867\n",
      "\n",
      "Total loss: 0.0019494264852255583; that's 0.0009437292465008795 task and 0.000263962458120659 recon and 3.7086737155914307 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022547385923098774\n",
      "\n",
      "Total loss: 0.0020438767969608307; that's 0.001121237757615745 task and 0.0002505721931811422 recon and 3.3603339195251465 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022896344657056034\n",
      "\n",
      "Total recon loss: 0.005393380299210548; that's 4.802909851074219 text and 0.0005904703284613788 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004573717163875699\n",
      "\n",
      "Total loss: 0.0022193228360265493; that's 0.0013043949147686362 task and 0.0002577338891569525 recon and 3.285970687866211 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002247978928498924\n",
      "\n",
      "Total loss: 0.0022848777007311583; that's 0.0011453281622380018 task and 0.00026201075525023043 recon and 4.387694358825684 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022528498037718237\n",
      "\n",
      "Total loss: 0.00218906975351274; that's 0.0010732610244303942 task and 0.00026048533618450165 recon and 4.276617050170898 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002261899947188795\n",
      "\n",
      "Total recon loss: 0.0030877836979925632; that's 2.458503007888794 text and 0.0006292805192060769 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035069902753457425\n",
      "\n",
      "Total loss: 0.002279791748151183; that's 0.001282167504541576 task and 0.0002579790889285505 recon and 3.6982264518737793 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002208042013226077\n",
      "\n",
      "Total loss: 0.0022758885752409697; that's 0.0010321050649508834 task and 0.0002588718489278108 recon and 4.924558639526367 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002224992228439078\n",
      "\n",
      "Total recon loss: 0.003363001858815551; that's 2.831005334854126 text and 0.0005319963674992323 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0031763690779916943\n",
      "\n",
      "Total loss: 0.0025264895521104336; that's 0.0012647175462916493 task and 0.00025465121143497527 recon and 5.035604000091553 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022354189679026602\n",
      "\n",
      "Total loss: 0.0018344107083976269; that's 0.0009627558756619692 task and 0.00025336132966913283 recon and 3.09146785736084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021449586120434105\n",
      "\n",
      "Total loss: 0.0020912368781864643; that's 0.0010211390908807516 task and 0.0002662284532561898 recon and 4.019346237182617 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022050502826459705\n",
      "\n",
      "Total recon loss: 0.0033121337182819843; that's 2.6938509941101074 text and 0.0006182825891301036 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0033848509402014315\n",
      "\n",
      "Total loss: 0.002223541494458914; that's 0.0012661953223869205 task and 0.0002561704022809863 recon and 3.505878448486328 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002223205129848793\n",
      "\n",
      "Total loss: 0.002112428657710552; that's 0.001018710434436798 task and 0.0002659778983797878 recon and 4.138701915740967 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021711424458771946\n",
      "\n",
      "Total loss: 0.0024555297568440437; that's 0.001478156540542841 task and 0.0002711084089241922 recon and 3.5313236713409424 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022039961314294487\n",
      "\n",
      "Total recon loss: 0.0034570915158838034; that's 2.7636806964874268 text and 0.0006934106349945068 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003167905923910439\n",
      "\n",
      "Total loss: 0.00233846390619874; that's 0.0012641226639971137 task and 0.0002593951649032533 recon and 4.074731349945068 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002208873664494604\n",
      "\n",
      "Total loss: 0.0019317985279485583; that's 0.0009805688168853521 task and 0.000259348627878353 recon and 3.4594054222106934 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022246114385779947\n",
      "\n",
      "Total loss: 0.0023579695262014866; that's 0.0012769807362928987 task and 0.00025592962629161775 recon and 4.125295639038086 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002213583108969033\n",
      "\n",
      "Total recon loss: 0.0034485626965761185; that's 2.8249948024749756 text and 0.0006235676119104028 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0033691812958568336\n",
      "\n",
      "Total loss: 0.0024124206975102425; that's 0.0014222644967958331 task and 0.00025038697640411556 recon and 3.6988465785980225 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022539150959346443\n",
      "\n",
      "Total loss: 0.0022343380842357874; that's 0.001126232324168086 task and 0.00025133276358246803 recon and 4.283865451812744 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021360560914035886\n",
      "\n",
      "Total loss: 0.002107246546074748; that's 0.001195024698972702 task and 0.00025844600168056786 recon and 3.2688796520233154 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020994166436139492\n",
      "\n",
      "Total recon loss: 0.004854828119277954; that's 4.304589748382568 text and 0.0005502378335222602 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003553451211191714\n",
      "\n",
      "Total loss: 0.002579656196758151; that's 0.0014606219483539462 task and 0.0002663315390236676 recon and 4.263513088226318 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022042734117712825\n",
      "\n",
      "Total loss: 0.002193197375163436; that's 0.0009775039507076144 task and 0.00026291984249837697 recon and 4.76386833190918 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021125294698867945\n",
      "\n",
      "Total loss: 0.00213032029569149; that's 0.001113652135245502 task and 0.00025974310119636357 recon and 3.784626007080078 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020791231363546103\n",
      "\n",
      "Total recon loss: 0.0032550867181271315; that's 2.7227084636688232 text and 0.0005323782097548246 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004703315042424947\n",
      "\n",
      "Total loss: 0.001934450352564454; that's 0.0009436557302251458 task and 0.00025883360649459064 recon and 3.6598050594329834 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020871484780218452\n",
      "\n",
      "Total loss: 0.0018394554499536753; that's 0.0009290933376178145 task and 0.00025793802342377603 recon and 3.2621207237243652 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002091154573718086\n",
      "\n",
      "Total loss: 0.002305195201188326; that's 0.0011747966054826975 task and 0.0002628637012094259 recon and 4.337674617767334 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020743350288830696\n",
      "\n",
      "Total recon loss: 0.0025504715740680695; that's 1.919782042503357 text and 0.0006306893774308264 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004460561617743224\n",
      "\n",
      "Total loss: 0.002284560352563858; that's 0.0011338240001350641 task and 0.00025738435215316713 recon and 4.466760635375977 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021447985339909793\n",
      "\n",
      "Total loss: 0.002407833468168974; that's 0.001034421962685883 task and 0.0002618129947222769 recon and 5.557991981506348 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021831159526482223\n",
      "\n",
      "Total loss: 0.0021328728180378675; that's 0.0008927301969379187 task and 0.00025547301629558206 recon and 4.923348426818848 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002320224188733846\n",
      "\n",
      "Total recon loss: 0.0032022257801145315; that's 2.5854976177215576 text and 0.0006167280371300876 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.002524099671281874\n",
      "\n",
      "Total loss: 0.002639730926603079; that's 0.0013015911681577563 task and 0.00026770459953695536 recon and 5.352175235748291 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022639982879627497\n",
      "\n",
      "Total loss: 0.0022332179360091686; that's 0.001069441670551896 task and 0.00026084695127792656 recon and 4.514647483825684 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002197973888833076\n",
      "\n",
      "Total loss: 0.002369185211136937; that's 0.001198626821860671 task and 0.0002510926569812 recon and 4.597328186035156 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002214766191318631\n",
      "\n",
      "Total recon loss: 0.0020034387707710266; that's 1.3331797122955322 text and 0.0006702590035274625 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0025040455698035658\n",
      "\n",
      "Total loss: 0.002073948737233877; that's 0.0010995365446433425 task and 0.0002556509571149945 recon and 3.5938057899475098 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002247281998861581\n",
      "\n",
      "Total loss: 0.002403518185019493; that's 0.0012299707159399986 task and 0.0002643128391355276 recon and 4.546173095703125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002208214054116979\n",
      "\n",
      "Total loss: 0.0022148543503135443; that's 0.0009729298180900514 task and 0.0002597787824925035 recon and 4.910728931427002 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022242451016791166\n",
      "\n",
      "Total recon loss: 0.0025244527496397495; that's 1.9671963453292847 text and 0.0005572562804445624 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.002586747104069218\n",
      "\n",
      "Total loss: 0.0024065703619271517; that's 0.001290181651711464 task and 0.00025459384778514504 recon and 4.308974742889404 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021790259459521623\n",
      "\n",
      "Total loss: 0.0020796831231564283; that's 0.0010618397500365973 task and 0.0002550421340856701 recon and 3.8140065670013428 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022222566639538855\n",
      "\n",
      "Total loss: 0.0023021691013127565; that's 0.001195424236357212 task and 0.00026085387798957527 recon and 4.22945499420166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002221034357789904\n",
      "\n",
      "Total recon loss: 0.0027706907130777836; that's 2.0682075023651123 text and 0.0007024829974398017 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0026181963575072588\n",
      "\n",
      "Total loss: 0.002255671424791217; that's 0.001095233135856688 task and 0.0002565902250353247 recon and 4.519240379333496 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002178309173323214\n",
      "\n",
      "Total loss: 0.00206578616052866; that's 0.0009791315533220768 task and 0.00025594147155061364 recon and 4.153565883636475 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021960068866610527\n",
      "\n",
      "Total loss: 0.001944083604030311; that's 0.0008396548801101744 task and 0.00025579947396181524 recon and 4.2431464195251465 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021702882379759105\n",
      "\n",
      "Total loss: 0.002524807583540678; that's 0.0013618877856060863 task and 0.0002630123926792294 recon and 4.499537944793701 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022853877244051546\n",
      "\n",
      "Total recon loss: 0.003152767661958933; that's 2.592756986618042 text and 0.0005600106087513268 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0027541033760644495\n",
      "\n",
      "Total loss: 0.002121326047927141; that's 0.0009086221107281744 task and 0.00026917768991552293 recon and 4.717630863189697 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00219367524725385\n",
      "\n",
      "Total loss: 0.0022447016090154648; that's 0.000981174991466105 task and 0.00026257464196532965 recon and 5.004759788513184 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002206148700788617\n",
      "\n",
      "Total loss: 0.002575464081019163; that's 0.0013737048720940948 task and 0.0002598889113869518 recon and 4.709351539611816 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022051187057513743\n",
      "\n",
      "Total recon loss: 0.0027617949526757; that's 2.120067596435547 text and 0.0006417274125851691 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.002808043388649821\n",
      "\n",
      "Total loss: 0.002275619190186262; that's 0.0011682756012305617 task and 0.00025282561546191573 recon and 4.272589683532715 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002263408652506769\n",
      "\n",
      "Total loss: 0.0021454286761581898; that's 0.0010493856389075518 task and 0.00025036075385287404 recon and 4.22841215133667 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002200680252863094\n",
      "\n",
      "Total recon loss: 0.002959020435810089; that's 2.4830591678619385 text and 0.0004759613366331905 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0027475894545204937\n",
      "\n",
      "Total loss: 0.0023912163451313972; that's 0.001283040503039956 task and 0.00026512486510910094 recon and 4.215254783630371 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022480313305277377\n",
      "\n",
      "Total loss: 0.001995176775380969; that's 0.0010498040355741978 task and 0.000244450056925416 recon and 3.5046133995056152 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021048928389791398\n",
      "\n",
      "Total loss: 0.002433094196021557; that's 0.001184498076327145 task and 0.00026046697166748345 recon and 4.940645694732666 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022324097785167397\n",
      "\n",
      "Total loss: 0.002412429777905345; that's 0.0011124805314466357 task and 0.00026348736719228327 recon and 5.182309627532959 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002269489453174174\n",
      "\n",
      "Total recon loss: 0.0025430750101804733; that's 1.9639551639556885 text and 0.0005791197763755918 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0027121030259877445\n",
      "\n",
      "Total loss: 0.002231057733297348; that's 0.0012050955556333065 task and 0.0002615273406263441 recon and 3.822174549102783 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002202923416625708\n",
      "\n",
      "Total loss: 0.002422262914478779; that's 0.0011926796287298203 task and 0.0002557998232077807 recon and 4.868917942047119 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022432769916485994\n",
      "\n",
      "Total recon loss: 0.0027289167046546936; that's 2.1237926483154297 text and 0.0006051241070963442 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0026874759094789626\n",
      "\n",
      "Total loss: 0.002182631054893136; that's 0.0010990957962349057 task and 0.00025622485554777086 recon and 4.136551856994629 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002233866238966584\n",
      "\n",
      "Total loss: 0.002239860827103257; that's 0.0009186671231873333 task and 0.00025403074687346816 recon and 5.335814952850342 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022372905153315516\n",
      "\n",
      "Total loss: 0.002406778745353222; that's 0.001170340576209128 task and 0.0002477201051078737 recon and 4.9435906410217285 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002213823904749006\n",
      "\n",
      "Total recon loss: 0.003021262353286147; that's 2.2143378257751465 text and 0.0008069244213402271 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0028087903140112756\n",
      "\n",
      "Total loss: 0.002304634777829051; that's 0.0010430969996377826 task and 0.00025538046611472964 recon and 5.030786991119385 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022181963303592057\n",
      "\n",
      "Total loss: 0.0019185356795787811; that's 0.0009840173879638314 task and 0.0002537601685617119 recon and 3.4037911891937256 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021854447433724998\n",
      "\n",
      "Total loss: 0.0019339104183018208; that's 0.0009424052550457418 task and 0.00025190820451825857 recon and 3.6979851722717285 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002260255650617182\n",
      "\n",
      "Total recon loss: 0.0027987558860331774; that's 2.159250259399414 text and 0.0006395053933374584 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.002837725707795471\n",
      "\n",
      "Total loss: 0.0025736920069903135; that's 0.0013401295291259885 task and 0.0002457364462316036 recon and 4.9391303062438965 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021747234906069933\n",
      "\n",
      "Total loss: 0.00225669052451849; that's 0.0010885109659284353 task and 0.0002540996065363288 recon and 4.570400238037109 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002219601564574987\n",
      "\n",
      "Total loss: 0.0020500917453318834; that's 0.0010272964136675 task and 0.00026059290394186974 recon and 3.8110122680664062 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002202734232414514\n",
      "\n",
      "Total loss: 0.002133765257894993; that's 0.0010738945566117764 task and 0.0002650201495271176 recon and 3.974252939224243 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021634408948011698\n",
      "\n",
      "Total recon loss: 0.004128052853047848; that's 3.69064998626709 text and 0.00043740260298363864 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003361765677109361\n",
      "\n",
      "Total loss: 0.0022049888502806425; that's 0.001009834581054747 task and 0.00025240788818337023 recon and 4.7137322425842285 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002193799235392362\n",
      "\n",
      "Total loss: 0.002021947642788291; that's 0.000970455352216959 task and 0.0002588322095107287 recon and 3.9633002281188965 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021003358077723534\n",
      "\n",
      "Total recon loss: 0.005182622466236353; that's 4.633206844329834 text and 0.0005494157085195184 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0048287482419982555\n",
      "\n",
      "Total loss: 0.0022080508060753345; that's 0.0011284539941698313 task and 0.0002616404672153294 recon and 4.089781761169434 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021732946718111632\n",
      "\n",
      "Total loss: 0.002339553087949753; that's 0.001254511415027082 task and 0.00025766875478439033 recon and 4.136864185333252 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002174909330205992\n",
      "\n",
      "Total loss: 0.0025417625438421965; that's 0.0013450852129608393 task and 0.00025806971825659275 recon and 4.693038463592529 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021375494031235574\n",
      "\n",
      "Total recon loss: 0.004070928320288658; that's 3.5678534507751465 text and 0.0005030747270211577 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.005344120624940842\n",
      "\n",
      "Total loss: 0.002368031069636345; that's 0.0011359525378793478 task and 0.00026169445482082665 recon and 4.851921081542969 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00212924798252061\n",
      "\n",
      "Total loss: 0.0019930333364754915; that's 0.0009305989951826632 task and 0.0002550725475884974 recon and 4.03680944442749 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021565774676855654\n",
      "\n",
      "Total loss: 0.0022246986627578735; that's 0.0010188359301537275 task and 0.00025130657013505697 recon and 4.7727813720703125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002111433573300019\n",
      "\n",
      "Total recon loss: 0.004261601250618696; that's 3.524275302886963 text and 0.000737325637601316 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004476959251333028\n",
      "\n",
      "Total loss: 0.0021953904069960117; that's 0.0009712019236758351 task and 0.0002563645539339632 recon and 4.839118957519531 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021494710945989936\n",
      "\n",
      "Total loss: 0.0021566092036664486; that's 0.0010463213548064232 task and 0.00026483877445571125 recon and 4.227245330810547 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022933154355268925\n",
      "\n",
      "Total loss: 0.002462539356201887; that's 0.0011754692532122135 task and 0.00025191085296683013 recon and 5.175795555114746 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002191333482041955\n",
      "\n",
      "Total recon loss: 0.0026340181939303875; that's 2.0793440341949463 text and 0.0005546740139834583 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035521410196088254\n",
      "\n",
      "Total loss: 0.002424980513751507; that's 0.0010360630694776773 task and 0.00025244386051781476 recon and 5.682368278503418 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022560895304195583\n",
      "\n",
      "Total loss: 0.001912158215418458; that's 0.0008859090157784522 task and 0.0002496743109077215 recon and 3.8828747272491455 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002209993547294289\n",
      "\n",
      "Total loss: 0.0019709146581590176; that's 0.0007552900933660567 task and 0.0002573295496404171 recon and 4.79147481918335 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002281314852880314\n",
      "\n",
      "Total recon loss: 0.0035819339100271463; that's 2.8769876956939697 text and 0.0007049459381960332 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0031623478909023105\n",
      "\n",
      "Total loss: 0.002100590616464615; that's 0.0010807079961523414 task and 0.0002548009215388447 recon and 3.825409173965454 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021871004696004093\n",
      "\n",
      "Total loss: 0.002273793797940016; that's 0.0012508871732279658 task and 0.00024932020460255444 recon and 3.8679323196411133 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021921259933151303\n",
      "\n",
      "Total loss: 0.002016897313296795; that's 0.0011066070292145014 task and 0.00025266414741054177 recon and 3.2881317138671875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021554110513534396\n",
      "\n",
      "Total recon loss: 0.0028298748657107353; that's 2.339301109313965 text and 0.0004905738169327378 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0030780026502907278\n",
      "\n",
      "Total loss: 0.0018381169065833092; that's 0.0008690338581800461 task and 0.0002560651919338852 recon and 3.565089702606201 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002067944654263556\n",
      "\n",
      "Total loss: 0.0023392224684357643; that's 0.0011646370403468609 task and 0.00025204732082784176 recon and 4.612690448760986 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002236807495355606\n",
      "\n",
      "Total loss: 0.002059122547507286; that's 0.0009583969367668033 task and 0.0002528230252210051 recon and 4.239513874053955 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002232494670897722\n",
      "\n",
      "Total recon loss: 0.003522717859596014; that's 2.9218785762786865 text and 0.0006008391501381993 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003236752515658736\n",
      "\n",
      "Total loss: 0.002260425593703985; that's 0.0010741368168964982 task and 0.0002554478123784065 recon and 4.654205322265625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002240565597312525\n",
      "\n",
      "Total loss: 0.0020886906422674656; that's 0.0011355571914464235 task and 0.00025251356419175863 recon and 3.503098964691162 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021987488132435827\n",
      "\n",
      "Total loss: 0.0023782197386026382; that's 0.0011526934104040265 task and 0.0002487651363480836 recon and 4.8838067054748535 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002182252740021795\n",
      "\n",
      "Total loss: 0.002256062813103199; that's 0.001016163849271834 task and 0.0002471001062076539 recon and 4.963994026184082 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002187854101648554\n",
      "\n",
      "Total recon loss: 0.004112710244953632; that's 3.6006767749786377 text and 0.0005120334099046886 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004370808508247137\n",
      "\n",
      "Total loss: 0.0021282637026160955; that's 0.0009030182845890522 task and 0.00025730361812748015 recon and 4.839709281921387 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022276716097258033\n",
      "\n",
      "Total loss: 0.0019110641442239285; that's 0.0009510666131973267 task and 0.0002504358417354524 recon and 3.5478086471557617 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021111910708714278\n",
      "\n",
      "Total recon loss: 0.0052586146630346775; that's 4.623542785644531 text and 0.0006350714829750359 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004299175892956555\n",
      "\n",
      "Total loss: 0.001948162680491805; that's 0.000858535582665354 task and 0.00024453498190268874 recon and 4.225460529327393 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022015487228054555\n",
      "\n",
      "Total loss: 0.0021640080958604813; that's 0.001076403190381825 task and 0.0002535756502766162 recon and 4.170146465301514 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002202159020816907\n",
      "\n",
      "Total loss: 0.0022019725292921066; that's 0.001129957614466548 task and 0.0002471621264703572 recon and 4.124264240264893 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021739809308201075\n",
      "\n",
      "Total recon loss: 0.005201045889407396; that's 4.353575706481934 text and 0.0008474698988720775 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037597151612862945\n",
      "\n",
      "Total loss: 0.0019807389471679926; that's 0.001045724144205451 task and 0.00025185622507706285 recon and 3.4157931804656982 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021249874588102104\n",
      "\n",
      "Total loss: 0.0023725791834294796; that's 0.001329105463810265 task and 0.0002551089273765683 recon and 3.941824197769165 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002119146047625691\n",
      "\n",
      "Total loss: 0.002260087989270687; that's 0.0012024351162835956 task and 0.00024250899150501937 recon and 4.075719833374023 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021166347071994098\n",
      "\n",
      "Total recon loss: 0.005336614791303873; that's 4.633075714111328 text and 0.0007035388262011111 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004410110095050186\n",
      "\n",
      "Total loss: 0.0020933139603585005; that's 0.0009879443095996976 task and 0.0002481964766047895 recon and 4.2858662605285645 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002126032313099131\n",
      "\n",
      "Total loss: 0.0017933433409780264; that's 0.0008057357044890523 task and 0.0002511129423510283 recon and 3.682473659515381 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021889049652963877\n",
      "\n",
      "Total loss: 0.001952031278051436; that's 0.0008605965995229781 task and 0.0002540375862736255 recon and 4.186985492706299 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002146790020633489\n",
      "\n",
      "Total loss: 0.0022362780291587114; that's 0.0010465707164257765 task and 0.00025990529684349895 recon and 4.649009704589844 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002183694705599919\n",
      "\n",
      "Total recon loss: 0.004067497327923775; that's 3.5946338176727295 text and 0.00047286320477724075 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004779513061512261\n",
      "\n",
      "Total loss: 0.001999273430556059; that's 0.0009940573945641518 task and 0.00024436420062556863 recon and 3.8042593002319336 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021956289268564434\n",
      "\n",
      "Total loss: 0.0021541924215853214; that's 0.0012004164746031165 task and 0.00025100584025494754 recon and 3.513850450515747 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022083162888884545\n",
      "\n",
      "Total loss: 0.0022886875085532665; that's 0.001061492832377553 task and 0.00024346067220903933 recon and 4.918669700622559 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022696645185351374\n",
      "\n",
      "Total recon loss: 0.004800568334758282; that's 4.196625232696533 text and 0.0006039430154487491 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004675225799437612\n",
      "\n",
      "Total loss: 0.0021973683033138514; that's 0.0013291864888742566 task and 0.00024968813522718847 recon and 3.092468500137329 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021509663644246756\n",
      "\n",
      "Total loss: 0.0019050362752750516; that's 0.0009810269111767411 task and 0.0002512285718694329 recon and 3.3639039993286133 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021044848044402898\n",
      "\n",
      "Total recon loss: 0.00549253448843956; that's 4.9090166091918945 text and 0.0005835177144035697 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0044782207906246185\n",
      "\n",
      "Total loss: 0.002187071368098259; that's 0.0011255963472649455 task and 0.00025466817896813154 recon and 4.034034252166748 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021441126498393717\n",
      "\n",
      "Total loss: 0.0024423429276794195; that's 0.001341552473604679 task and 0.0002611373201943934 recon and 4.19826602935791 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021631847764365373\n",
      "\n",
      "Total loss: 0.002345771063119173; that's 0.001149184419773519 task and 0.0002540911373216659 recon and 4.712478160858154 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021540083235595375\n",
      "\n",
      "Total recon loss: 0.004444519989192486; that's 3.634046792984009 text and 0.0008104729349724948 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004918847228400409\n",
      "\n",
      "Total loss: 0.002148137427866459; that's 0.0011673723347485065 task and 0.0002555894898250699 recon and 3.6258788108825684 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022141184029169383\n",
      "\n",
      "Total loss: 0.0022180352825671434; that's 0.0011517227394506335 task and 0.0002539554552640766 recon and 4.0617852210998535 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002173342484747991\n",
      "\n",
      "Total loss: 0.001950566889718175; that's 0.0009964556666091084 task and 0.00024299252254422754 recon and 3.555593729019165 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021700073778629305\n",
      "\n",
      "Total recon loss: 0.003167013404890895; that's 2.7378146648406982 text and 0.00042919855332002044 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004366804002784192\n",
      "\n",
      "Total loss: 0.002010297030210495; that's 0.001158477389253676 task and 0.0002556422841735184 recon and 2.980886697769165 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020918448199518025\n",
      "\n",
      "Total loss: 0.001936239656060934; that's 0.0009723759721964598 task and 0.000254790618782863 recon and 3.545365333557129 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002080483896424994\n",
      "\n",
      "Total loss: 0.0019617825746536255; that's 0.0008803863311186433 task and 0.0002614825207274407 recon and 4.099567890167236 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002161228578770533\n",
      "\n",
      "Total loss: 0.0019624526612460613; that's 0.0009543334017507732 task and 0.00024238304467871785 recon and 3.828681707382202 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021692556503694503\n",
      "\n",
      "Total recon loss: 0.0034222304821014404; that's 2.7757174968719482 text and 0.0006465130136348307 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003744690825697035\n",
      "\n",
      "Total loss: 0.002568732714280486; that's 0.0013216872466728091 task and 0.0002428207517368719 recon and 5.021123886108398 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022181854478549212\n",
      "\n",
      "Total loss: 0.0019493689760565758; that's 0.0009276905329898 task and 0.00025401354650966823 recon and 3.8383240699768066 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022076569579076023\n",
      "\n",
      "Total recon loss: 0.003596237627789378; that's 2.921837329864502 text and 0.000674400245770812 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004176025376655162\n",
      "\n",
      "Total loss: 0.0018672219011932611; that's 0.0008656011195853353 task and 0.0002500850532669574 recon and 3.7576792240142822 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002091355981538072\n",
      "\n",
      "Total loss: 0.0019549918361008167; that's 0.0010931252036243677 task and 0.0002491238119546324 recon and 3.0637149810791016 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021596056199632585\n",
      "\n",
      "Total loss: 0.002068932168185711; that's 0.0010945756221190095 task and 0.00023973938368726522 recon and 3.6730856895446777 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002149016852490604\n",
      "\n",
      "Total recon loss: 0.003728906624019146; that's 3.1814258098602295 text and 0.000547480711247772 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003570910331327468\n",
      "\n",
      "Total loss: 0.0017993091605603695; that's 0.0008500644471496344 task and 0.00024002928694244474 recon and 3.546077251434326 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021047391043975947\n",
      "\n",
      "Total loss: 0.0021592413540929556; that's 0.0012860661372542381 task and 0.00025120412465184927 recon and 3.1098556518554688 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020570807217154654\n",
      "\n",
      "Total loss: 0.0023038468789309263; that's 0.001357253990136087 task and 0.000248065305640921 recon and 3.4926376342773438 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002102010493399575\n",
      "\n",
      "Total loss: 0.002056750003248453; that's 0.0010891557903960347 task and 0.00024599829339422286 recon and 3.6079800128936768 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020490482950117437\n",
      "\n",
      "Total recon loss: 0.003687228774651885; that's 2.9120097160339355 text and 0.0007752188830636442 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037388370628468693\n",
      "\n",
      "Total loss: 0.002062273910269141; that's 0.0011012909235432744 task and 0.00025001066387631 recon and 3.554861545562744 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002005920473020524\n",
      "\n",
      "Total loss: 0.001814933493733406; that's 0.0008777414332143962 task and 0.00024599279277026653 recon and 3.45599627494812 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002044709095498547\n",
      "\n",
      "Total recon loss: 0.004001189023256302; that's 3.4674508571624756 text and 0.0005337380571290851 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004054907909594476\n",
      "\n",
      "Total loss: 0.0023091821931302547; that's 0.001272099674679339 task and 0.0002554997045081109 recon and 3.907914638519287 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020208490395452828\n",
      "\n",
      "Total loss: 0.0019009097013622522; that's 0.0010497000766918063 task and 0.0002491102204658091 recon and 3.0104966163635254 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001957229833351448\n",
      "\n",
      "Total loss: 0.0021625026129186153; that's 0.0011596295516937971 task and 0.0002526055322960019 recon and 3.7513372898101807 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002048465168336406\n",
      "\n",
      "Total loss: 0.0021450775675475597; that's 0.0009809766197577119 task and 0.00024857057724148035 recon and 4.5776519775390625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002160291860345751\n",
      "\n",
      "Total recon loss: 0.004006458446383476; that's 3.3203446865081787 text and 0.0006861132569611073 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004208804522641003\n",
      "\n",
      "Total loss: 0.002254468621686101; that's 0.0011800024658441544 task and 0.0002399441145826131 recon and 4.172610282897949 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021679804683662953\n",
      "\n",
      "Total loss: 0.002195109613239765; that's 0.0011219895677641034 task and 0.00024745959672145545 recon and 4.128301620483398 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021556630870327356\n",
      "\n",
      "Total recon loss: 0.004823610652238131; that's 4.1683349609375 text and 0.0006552754784934223 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0039574746997095645\n",
      "\n",
      "Total loss: 0.0021352656185626984; that's 0.0010338048450648785 task and 0.0002566074545029551 recon and 4.224266529083252 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022208060219418256\n",
      "\n",
      "Total loss: 0.0027961349114775658; that's 0.0014303685165941715 task and 0.0002544701856095344 recon and 5.556481838226318 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022080694162286817\n",
      "\n",
      "Total loss: 0.002093360759317875; that's 0.0009398731053806841 task and 0.0002446641738060862 recon and 4.544117450714111 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002191238700179383\n",
      "\n",
      "Total recon loss: 0.005305606406182051; that's 4.856561660766602 text and 0.00044904445530846715 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004724682914093137\n",
      "\n",
      "Total loss: 0.00248233275488019; that's 0.0012562602059915662 task and 0.0002514957741368562 recon and 4.872884750366211 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021763982134871186\n",
      "\n",
      "Total loss: 0.002087421715259552; that's 0.0008874644991010427 task and 0.00024969439255073667 recon and 4.751314640045166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021845456887967882\n",
      "\n",
      "Total loss: 0.0022470620460808277; that's 0.0010347093921154737 task and 0.0002547719341237098 recon and 4.787903308868408 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002184462696313858\n",
      "\n",
      "Total recon loss: 0.004967915825545788; that's 4.574825286865234 text and 0.0003930904495064169 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004662966572213918\n",
      "\n",
      "Total loss: 0.002408259781077504; that's 0.0011330327251926064 task and 0.00024632056010887027 recon and 5.144533157348633 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022161430679261684\n",
      "\n",
      "Total loss: 0.002299476880580187; that's 0.0010608024895191193 task and 0.00026036324561573565 recon and 4.8915557861328125 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022354235709644856\n",
      "\n",
      "Total loss: 0.0018683631205931306; that's 0.0011066616280004382 task and 0.00024069887876976281 recon and 2.605012893676758 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002082826553378254\n",
      "\n",
      "Total loss: 0.0021166461519896984; that's 0.0011603288585320115 task and 0.00024743343237787485 recon and 3.544419527053833 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020976744196377693\n",
      "\n",
      "Total recon loss: 0.0033874136861413717; that's 2.748051404953003 text and 0.0006393622024916112 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003655586263630539\n",
      "\n",
      "Total loss: 0.0020530037581920624; that's 0.0009146991651505232 task and 0.0002468863094691187 recon and 4.457091808319092 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002126306239515543\n",
      "\n",
      "Total loss: 0.0020822593942284584; that's 0.001084071584045887 task and 0.0002494591462891549 recon and 3.743642568588257 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020386641984805466\n",
      "\n",
      "Total loss: 0.0021597323939204216; that's 0.0012330006575211883 task and 0.00024209629918914288 recon and 3.42317795753479 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020589136681519447\n",
      "\n",
      "Total recon loss: 0.0035202938597649336; that's 2.985504388809204 text and 0.000534789462108165 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00321059845155105\n",
      "\n",
      "Total loss: 0.0020445026457309723; that's 0.0011769747361540794 task and 0.0002511487400624901 recon and 3.0818963050842285 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020275863283313812\n",
      "\n",
      "Total loss: 0.001980339642614126; that's 0.0011149303754791617 task and 0.00024259829660877585 recon and 3.1140546798706055 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00201202773838304\n",
      "\n",
      "Total recon loss: 0.0026807012036442757; that's 2.1098878383636475 text and 0.0005708131357096136 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0031016844976693393\n",
      "\n",
      "Total loss: 0.0017804390517994761; that's 0.000894497032277286 task and 0.0002471818879712373 recon and 3.193800926208496 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002033924930728972\n",
      "\n",
      "Total loss: 0.002031071111559868; that's 0.0011323383077979088 task and 0.00024368742015212774 recon and 3.2752270698547363 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00197741427924484\n",
      "\n",
      "Total loss: 0.0023861988447606564; that's 0.001544502447359264 task and 0.0002381811646046117 recon and 3.01757550239563 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020538851292803886\n",
      "\n",
      "Total recon loss: 0.004939529579132795; that's 4.439432144165039 text and 0.0005000975797884166 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00424526194576174\n",
      "\n",
      "Total loss: 0.001694755395874381; that's 0.000769814767409116 task and 0.00024850148474797606 recon and 3.3821961879730225 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002028119077440351\n",
      "\n",
      "Total loss: 0.0020538303069770336; that's 0.0010529042920097709 task and 0.0002561765140853822 recon and 3.7237484455108643 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002009373581968248\n",
      "\n",
      "Total loss: 0.0025295617524534464; that's 0.0013539118226617575 task and 0.00024578467127867043 recon and 4.649326324462891 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020411661523394285\n",
      "\n",
      "Total recon loss: 0.003602118929848075; that's 3.1344027519226074 text and 0.00046771610504947603 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004307472463697195\n",
      "\n",
      "Total loss: 0.0021425681188702583; that's 0.0011857171775773168 task and 0.00024667923571541905 recon and 3.5508580207824707 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002094871521694586\n",
      "\n",
      "Total loss: 0.0020385582465678453; that's 0.0010942020453512669 task and 0.000250457291258499 recon and 3.469494342803955 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002044157318305224\n",
      "\n",
      "Total loss: 0.0018921804148703814; that's 0.0009964945493265986 task and 0.0002494915679562837 recon and 3.2309718132019043 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020842478121630846\n",
      "\n",
      "Total recon loss: 0.004793365020304918; that's 4.141292095184326 text and 0.0006520727765746415 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0042633597529493274\n",
      "\n",
      "Total loss: 0.0021009899210184813; that's 0.0011275014840066433 task and 0.00023947726003825665 recon and 3.670055866241455 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020333279902115466\n",
      "\n",
      "Total loss: 0.0018973317928612232; that's 0.001026034471578896 task and 0.00024687140830792487 recon and 3.1221301555633545 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002039794051088393\n",
      "\n",
      "Total loss: 0.0017556450329720974; that's 0.0007626050501130521 task and 0.00025403700419701636 recon and 3.6950149536132812 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019963829463813454\n",
      "\n",
      "Total recon loss: 0.004577539395540953; that's 4.14762020111084 text and 0.0004299190768506378 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004457908675540238\n",
      "\n",
      "Total loss: 0.002080620266497135; that's 0.0011766996467486024 task and 0.00024904668680392206 recon and 3.274369239807129 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019866999972146006\n",
      "\n",
      "Total loss: 0.0021895209793001413; that's 0.0013288487680256367 task and 0.00024254497839137912 recon and 3.0906357765197754 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021718006394803526\n",
      "\n",
      "Total loss: 0.0020593246445059776; that's 0.0008881600806489587 task and 0.000242739959503524 recon and 4.642123699188232 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002136881563346833\n",
      "\n",
      "Total recon loss: 0.0033831866458058357; that's 2.694404363632202 text and 0.0006887823110446334 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.00397559086792171\n",
      "\n",
      "Total loss: 0.0021410416811704636; that's 0.0010062088258564472 task and 0.0002498026588000357 recon and 4.4251508712768555 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021198236872442067\n",
      "\n",
      "Total loss: 0.0017788747791200876; that's 0.000880644132848829 task and 0.00024100659356918186 recon and 3.2861204147338867 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021241739357355984\n",
      "\n",
      "Total loss: 0.0021142465993762016; that's 0.0010656780796125531 task and 0.00024276682233903557 recon and 4.029008388519287 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021945581317413597\n",
      "\n",
      "Total loss: 0.0024210545234382153; that's 0.0011017527431249619 task and 0.00024884557933546603 recon and 5.352281093597412 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002344799309503287\n",
      "\n",
      "Total recon loss: 0.00379752810113132; that's 3.326249837875366 text and 0.00047127806465141475 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004074771690648049\n",
      "\n",
      "Total loss: 0.0022341732401400805; that's 0.0010954414028674364 task and 0.00023815569875296205 recon and 4.502881050109863 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002365054932888597\n",
      "\n",
      "Total loss: 0.0023043565452098846; that's 0.0012591491686180234 task and 0.00024768197908997536 recon and 3.9876275062561035 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021863638539798558\n",
      "\n",
      "Total loss: 0.0026080987881869078; that's 0.0013030992122367024 task and 0.00024252425646409392 recon and 5.312376976013184 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021364322025328873\n",
      "\n",
      "Total recon loss: 0.0033343425020575523; that's 2.791154146194458 text and 0.0005431881872937083 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004224431130569428\n",
      "\n",
      "Total loss: 0.0020209625363349915; that's 0.0009727299329824746 task and 0.0002479076792951673 recon and 4.001625061035156 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022194869432132693\n",
      "\n",
      "Total loss: 0.0020755031146109104; that's 0.00102144293487072 task and 0.00024826478329487145 recon and 4.028977394104004 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002156514290254563\n",
      "\n",
      "Total recon loss: 0.0032863570377230644; that's 2.6859898567199707 text and 0.0006003670860081911 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004004373080097139\n",
      "\n",
      "Total loss: 0.0021730316802859306; that's 0.0011347428662702441 task and 0.00024079976719804108 recon and 3.98744535446167 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002139913565479219\n",
      "\n",
      "Total loss: 0.0023315618745982647; that's 0.0013163797557353973 task and 0.0002358643978368491 recon and 3.8965890407562256 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002112712730886415\n",
      "\n",
      "Total loss: 0.00233180308714509; that's 0.0011239643208682537 task and 0.00024282908998429775 recon and 4.825048923492432 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021208027040120216\n",
      "\n",
      "Total recon loss: 0.004125204868614674; that's 3.4199788570404053 text and 0.0007052258006297052 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003862777464091778\n",
      "\n",
      "Total loss: 0.0024859136901795864; that's 0.0012997416779398918 task and 0.00024629078689031303 recon and 4.699406623840332 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021652846434153617\n",
      "\n",
      "Total loss: 0.002331488998606801; that's 0.001222606166265905 task and 0.00025209123850800097 recon and 4.2839579582214355 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022027571429498495\n",
      "\n",
      "Total loss: 0.002287047216668725; that's 0.0010934656020253897 task and 0.0002454806526657194 recon and 4.740504741668701 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021967518993187695\n",
      "\n",
      "Total recon loss: 0.0036103082820773125; that's 2.98187518119812 text and 0.0006284330156631768 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004316783943213522\n",
      "\n",
      "Total loss: 0.0021232187282294035; that's 0.0011061569675803185 task and 0.0002438604860799387 recon and 3.8660058975219727 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002198236547410488\n",
      "\n",
      "Total loss: 0.00209588510915637; that's 0.001030659768730402 task and 0.00024279570789076388 recon and 4.112147808074951 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002192603898001835\n",
      "\n",
      "Total loss: 0.0023580221459269524; that's 0.0011970816412940621 task and 0.00023962171690072864 recon and 4.606593608856201 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021688444749452173\n",
      "\n",
      "Total recon loss: 0.004902025684714317; that's 4.56265115737915 text and 0.0003393745864741504 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004021823129151016\n",
      "\n",
      "Total loss: 0.0023750471882522106; that's 0.00125597242731601 task and 0.0002462250704411417 recon and 4.364248752593994 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022648228565230965\n",
      "\n",
      "Total loss: 0.001987945754081011; that's 0.0008653971017338336 task and 0.0002501088019926101 recon and 4.362198829650879 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021661514230072497\n",
      "\n",
      "Total loss: 0.0018353306222707033; that's 0.0008481917902827263 task and 0.00024888612097129226 recon and 3.69126296043396 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002239449811168015\n",
      "\n",
      "Total recon loss: 0.0042576720006763935; that's 3.7424983978271484 text and 0.0005151733057573438 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004213522563222796\n",
      "\n",
      "Total loss: 0.0023029367439448833; that's 0.001192501513287425 task and 0.0002366667176829651 recon and 4.368843078613281 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002258824435994029\n",
      "\n",
      "Total loss: 0.002466183854267001; that's 0.001502337516285479 task and 0.00024087571364361793 recon and 3.6148526668548584 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002188293975777924\n",
      "\n",
      "Total loss: 0.002216637833043933; that's 0.0011078329989686608 task and 0.0002449019521009177 recon and 4.319514274597168 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002255265162093565\n",
      "\n",
      "Total recon loss: 0.004512148443609476; that's 3.9536914825439453 text and 0.0005584569880738854 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004162502356339246\n",
      "\n",
      "Total loss: 0.0022060172632336617; that's 0.001088269636966288 task and 0.0002548736520111561 recon and 4.3143696784973145 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0022225862368941305\n",
      "\n",
      "Total loss: 0.002195817418396473; that's 0.0010705358581617475 task and 0.0002374499454163015 recon and 4.439157962799072 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002279229291016236\n",
      "\n",
      "Total loss: 0.0018254787428304553; that's 0.000723443750757724 task and 0.00026064159465022385 recon and 4.206966876983643 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021858639211859553\n",
      "\n",
      "Total recon loss: 0.004702211357653141; that's 4.10694694519043 text and 0.0005952639039605856 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004127382969018072\n",
      "\n",
      "Total loss: 0.002030830830335617; that's 0.0009578024037182331 task and 0.0002481780247762799 recon and 4.124252796173096 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002191688067978248\n",
      "\n",
      "Total loss: 0.002023808192461729; that's 0.0008642837638035417 task and 0.00024832412600517273 recon and 4.556001663208008 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020242407824844124\n",
      "\n",
      "Total loss: 0.0019617797806859016; that's 0.0010087080299854279 task and 0.00024097939603962004 recon and 3.560462236404419 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021185333956964315\n",
      "\n",
      "Total recon loss: 0.0035068101715296507; that's 3.0355513095855713 text and 0.0004712587397079915 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037291196268051862\n",
      "\n",
      "Total loss: 0.002378488425165415; that's 0.001193965901620686 task and 0.00023989977489691228 recon and 4.723114013671875 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021961945458315313\n",
      "\n",
      "Total loss: 0.0018228236585855484; that's 0.0009087834623642266 task and 0.00023904518457129598 recon and 3.3749754428863525 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020732574840076267\n",
      "\n",
      "Total loss: 0.002125727478414774; that's 0.001090114121325314 task and 0.00024681389913894236 recon and 3.943998098373413 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002088106453884393\n",
      "\n",
      "Total loss: 0.0018671790603548288; that's 0.0008816429181024432 task and 0.00025768866180442274 recon and 3.6392369270324707 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002139631361933425\n",
      "\n",
      "Total recon loss: 0.0026394748128950596; that's 2.050899028778076 text and 0.0005885754944756627 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0034709115675650537\n",
      "\n",
      "Total loss: 0.0021352791227400303; that's 0.0011394214816391468 task and 0.00025062603526748717 recon and 3.726158380508423 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001992362473392859\n",
      "\n",
      "Total loss: 0.0018153857672587037; that's 0.0008577063563279808 task and 0.000231769256060943 recon and 3.6295509338378906 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018746636190917342\n",
      "\n",
      "Total recon loss: 0.003012902569025755; that's 2.478696823120117 text and 0.0005342058138921857 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0034986953320913015\n",
      "\n",
      "Total loss: 0.0017082435078918934; that's 0.0009621663484722376 task and 0.00024126211064867675 recon and 2.5240747928619385 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018790247524157167\n",
      "\n",
      "Total loss: 0.002061509992927313; that's 0.0011290591210126877 task and 0.0002425759012112394 recon and 3.4493749141693115 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018893155828118323\n",
      "\n",
      "Total loss: 0.001927035627886653; that's 0.0008930100593715906 task and 0.0002416615461697802 recon and 3.961820363998413 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002106261339504272\n",
      "\n",
      "Total recon loss: 0.003910222556442022; that's 3.346397876739502 text and 0.0005638243746943772 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0036586633627302945\n",
      "\n",
      "Total loss: 0.0016346219927072525; that's 0.0007486116955988109 task and 0.0002398415090283379 recon and 3.230844497680664 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020548623451031745\n",
      "\n",
      "Total loss: 0.001813806127756834; that's 0.0009848795598372817 task and 0.000235884974244982 recon and 2.96520733833313 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019116087129805238\n",
      "\n",
      "Total loss: 0.001891832915134728; that's 0.0010953006567433476 task and 0.00023843864619266242 recon and 2.790468454360962 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00191265519708395\n",
      "\n",
      "Total recon loss: 0.003036975162103772; that's 2.375870943069458 text and 0.0006611042772419751 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038035773881711066\n",
      "\n",
      "Total loss: 0.0021505909971892834; that's 0.0010025351075455546 task and 0.00023529166355729103 recon and 4.563821315765381 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002040902234148234\n",
      "\n",
      "Total loss: 0.0021650223061442375; that's 0.0009304293198511004 task and 0.00024212384596467018 recon and 4.96234655380249 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021076542732771488\n",
      "\n",
      "Total loss: 0.0020493101328611374; that's 0.0008894896018318832 task and 0.00023360902559943497 recon and 4.631056785583496 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002031619141343981\n",
      "\n",
      "Total loss: 0.002026042900979519; that's 0.0009557488956488669 task and 0.00023761422198731452 recon and 4.163398742675781 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002092160776956007\n",
      "\n",
      "Total recon loss: 0.004538637585937977; that's 4.017238616943359 text and 0.0005213988479226828 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004087741281837225\n",
      "\n",
      "Total loss: 0.002042983192950487; that's 0.001111073768697679 task and 0.0002448951418045908 recon and 3.4350712299346924 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020608410146087408\n",
      "\n",
      "Total loss: 0.0018960335291922092; that's 0.0007536420016549528 task and 0.00024327584833372384 recon and 4.495578289031982 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002125854865880683\n",
      "\n",
      "Total recon loss: 0.004018229898065329; that's 3.4169631004333496 text and 0.0006012666271999478 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004163088311906904\n",
      "\n",
      "Total loss: 0.002050560899078846; that's 0.000960698293056339 task and 0.00025125592947006226 recon and 4.193033218383789 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002134124595904723\n",
      "\n",
      "Total loss: 0.001844838261604309; that's 0.0008421477396041155 task and 0.0002553858794271946 recon and 3.736523151397705 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021316887985449286\n",
      "\n",
      "Total loss: 0.002031050156801939; that's 0.0010320558212697506 task and 0.0002508825855329633 recon and 3.7405588626861572 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002126463504973799\n",
      "\n",
      "Total loss: 0.0021522080060094595; that's 0.0009585876250639558 task and 0.00024732836754992604 recon and 4.731460094451904 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002122430256567895\n",
      "\n",
      "Total recon loss: 0.0049630808643996716; that's 4.510595798492432 text and 0.0004524851101450622 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004262898969464004\n",
      "\n",
      "Total loss: 0.002053470816463232; that's 0.0010727618355304003 task and 0.00023723971389699727 recon and 3.717346429824829 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020935963036026804\n",
      "\n",
      "Total loss: 0.0018040718277916312; that's 0.0008918555686250329 task and 0.0002275411388836801 recon and 3.4233760833740234 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002110673296265304\n",
      "\n",
      "Total recon loss: 0.004090629983693361; that's 3.4118528366088867 text and 0.0006787768797948956 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004817750796210021\n",
      "\n",
      "Total loss: 0.0021764340344816446; that's 0.0009629353298805654 task and 0.00023385511303786188 recon and 4.898217678070068 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002075939482310787\n",
      "\n",
      "Total loss: 0.0022248474415391684; that's 0.0009952840628102422 task and 0.0002459998650010675 recon and 4.91781759262085 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020971412234939636\n",
      "\n",
      "Total loss: 0.0022087099496275187; that's 0.0011737804161384702 task and 0.0002437475195620209 recon and 3.9559102058410645 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020853465655818583\n",
      "\n",
      "Total recon loss: 0.004928966518491507; that's 4.356165409088135 text and 0.0005728011601604521 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004427586735691875\n",
      "\n",
      "Total loss: 0.0018539952579885721; that's 0.0007998218643479049 task and 0.0002473302884027362 recon and 4.034215927124023 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020793836924713105\n",
      "\n",
      "Total loss: 0.0022941352799534798; that's 0.0009512440883554518 task and 0.0002393701724940911 recon and 5.517604827880859 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002138909862842411\n",
      "\n",
      "Total loss: 0.0019949409179389477; that's 0.0010745659237727523 task and 0.0002353267918806523 recon and 3.425240993499756 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002066533218603581\n",
      "\n",
      "Total recon loss: 0.0031462451443076134; that's 2.60441255569458 text and 0.0005418325308710337 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0042581960442475975\n",
      "\n",
      "Total loss: 0.0019365523476153612; that's 0.0008348713745363057 task and 0.00024199475592467934 recon and 4.298431396484375 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002095120180165395\n",
      "\n",
      "Total loss: 0.0022590183652937412; that's 0.0011626476189121604 task and 0.00024318334180861712 recon and 4.265936851501465 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020972631371114405\n",
      "\n",
      "Total loss: 0.0022354950197041035; that's 0.0010886804666370153 task and 0.00023564450384583324 recon and 4.555850505828857 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002102041153702885\n",
      "\n",
      "Total recon loss: 0.003934343345463276; that's 3.5175812244415283 text and 0.00041676172986626625 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004259267861489207\n",
      "\n",
      "Total loss: 0.002071818569675088; that's 0.0010162643156945705 task and 0.00024195760488510132 recon and 4.067983150482178 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020399726857431234\n",
      "\n",
      "Total loss: 0.0018701523076742887; that's 0.000919862650334835 task and 0.00023536216758657247 recon and 3.574636936187744 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020436121919192372\n",
      "\n",
      "Total loss: 0.002218839479610324; that's 0.0012373432982712984 task and 0.0002392083843005821 recon and 3.711439609527588 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0021233257942367347\n",
      "\n",
      "Total recon loss: 0.004749163053929806; that's 4.145633220672607 text and 0.000603529391810298 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004117533853277564\n",
      "\n",
      "Total loss: 0.0019069155678153038; that's 0.0011247702641412616 task and 0.0002467332815285772 recon and 2.6770598888397217 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00207993024145253\n",
      "\n",
      "Total loss: 0.0020947479642927647; that's 0.0008643228793516755 task and 0.00024645161465741694 recon and 4.919867515563965 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020425057772081347\n",
      "\n",
      "Total loss: 0.002238783985376358; that's 0.0011542027350515127 task and 0.0002397587668383494 recon and 4.224112033843994 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002043701052898541\n",
      "\n",
      "Total recon loss: 0.0031195671763271093; that's 2.6355676651000977 text and 0.00048399955267086625 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003620099106337875\n",
      "\n",
      "Total loss: 0.0019807019270956516; that's 0.000991497072391212 task and 0.00023255734413396567 recon and 3.783237934112549 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002088948420714587\n",
      "\n",
      "Total loss: 0.001875422545708716; that's 0.0008604549802839756 task and 0.00023419910576194525 recon and 3.9038424491882324 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020491609058808534\n",
      "\n",
      "Total loss: 0.0018992368131875992; that's 0.001050029182806611 task and 0.00024744501570239663 recon and 3.0088131427764893 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001957741315709427\n",
      "\n",
      "Total recon loss: 0.0033543717581778765; that's 2.8702642917633057 text and 0.00048410738236270845 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038093237392604353\n",
      "\n",
      "Total loss: 0.0023508272133767605; that's 0.0012930084485560656 task and 0.00024395115906372666 recon and 4.069337844848633 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002008851720020175\n",
      "\n",
      "Total loss: 0.002071491675451398; that's 0.0012303517432883382 task and 0.00023979014076758176 recon and 3.006748914718628 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019310447142925112\n",
      "\n",
      "Total loss: 0.001724499510601163; that's 0.0010378900915384293 task and 0.00023487296130042523 recon and 2.2586822509765625 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019367438135668635\n",
      "\n",
      "Total recon loss: 0.002783253090456128; that's 2.360088586807251 text and 0.00042316436883993447 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0036332968273200096\n",
      "\n",
      "Total loss: 0.0018909182399511337; that's 0.0010722378501668572 task and 0.00024394750653300434 recon and 2.873664379119873 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018923476187046617\n",
      "\n",
      "Total loss: 0.0018218301702290773; that's 0.001023322925902903 task and 0.0002408157306490466 recon and 2.7884578704833984 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018787125661037863\n",
      "\n",
      "Total loss: 0.0021807763259857893; that's 0.0011360527714714408 task and 0.00023578220861963928 recon and 4.044706344604492 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020197023858781905\n",
      "\n",
      "Total recon loss: 0.00446666032075882; that's 3.9328885078430176 text and 0.000533771759364754 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0036567281233146785\n",
      "\n",
      "Total loss: 0.0024789762683212757; that's 0.0014305156655609608 task and 0.00023902369139250368 recon and 4.047184944152832 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019751675694715232\n",
      "\n",
      "Total loss: 0.002062777755782008; that's 0.0013348720967769623 task and 0.00023901306849438697 recon and 2.444463014602661 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018423330946825444\n",
      "\n",
      "Total loss: 0.0019794448744505644; that's 0.0010195821523666382 task and 0.0002448967134114355 recon and 3.5748300552368164 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00192640921799466\n",
      "\n",
      "Total recon loss: 0.002982922364026308; that's 2.2884809970855713 text and 0.0006944412598386407 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003874599488917738\n",
      "\n",
      "Total loss: 0.0021804242860525846; that's 0.0010573097970336676 task and 0.00023706180218141526 recon and 4.430263996124268 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020555450266692785\n",
      "\n",
      "Total loss: 0.001840706099756062; that's 0.0011121969437226653 task and 0.0002404949045740068 recon and 2.4400715827941895 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019014639011584221\n",
      "\n",
      "Total loss: 0.0017212647944688797; that's 0.0010333521058782935 task and 0.00023858359782025218 recon and 2.246645927429199 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001707275890512392\n",
      "\n",
      "Total recon loss: 0.0036022888962179422; that's 3.04819655418396 text and 0.0005540921702049673 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038681451766751705\n",
      "\n",
      "Total loss: 0.001828939886763692; that's 0.0010812700493261218 task and 0.0002369652793277055 recon and 2.553523063659668 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018109119741711766\n",
      "\n",
      "Total loss: 0.001822272315621376; that's 0.0011889514280483127 task and 0.00023574351507704705 recon and 1.987886905670166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001892315821023658\n",
      "\n",
      "Total loss: 0.0018177402671426535; that's 0.0009790814947336912 task and 0.00024587931693531573 recon and 2.963897466659546 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019285993336234243\n",
      "\n",
      "Total recon loss: 0.004234414082020521; that's 3.7179768085479736 text and 0.0005164368194527924 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0035899797920137646\n",
      "\n",
      "Total loss: 0.0019713416695594788; that's 0.0009062701719813049 task and 0.0002526536409277469 recon and 4.062089920043945 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019131314055994154\n",
      "\n",
      "Total loss: 0.002070245798677206; that's 0.0009111242834478617 task and 0.0002292686840519309 recon and 4.649263858795166 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002014390246476978\n",
      "\n",
      "Total loss: 0.0022044354118406773; that's 0.0012270519509911537 task and 0.00024329214647877961 recon and 3.670457124710083 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020790680462960155\n",
      "\n",
      "Total recon loss: 0.004657479468733072; that's 4.060400485992432 text and 0.0005970787606202066 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038747740793041883\n",
      "\n",
      "Total loss: 0.002205764641985297; that's 0.0010837630834430456 task and 0.00024156959261745214 recon and 4.402160167694092 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020335590909235177\n",
      "\n",
      "Total loss: 0.0021639051847159863; that's 0.001138830091804266 task and 0.00023126213636714965 recon and 3.969064712524414 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002091193577507511\n",
      "\n",
      "Total loss: 0.0023021637462079525; that's 0.001101626199670136 task and 0.00024139235028997064 recon and 4.795725345611572 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020649233483709395\n",
      "\n",
      "Total recon loss: 0.0036279477644711733; that's 2.9769651889801025 text and 0.0006509824306704104 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004345868714153767\n",
      "\n",
      "Total loss: 0.002095831325277686; that's 0.0012109102681279182 task and 0.00022895634174346924 recon and 3.2798240184783936 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019295318215154112\n",
      "\n",
      "Total loss: 0.0018384517170488834; that's 0.001068726647645235 task and 0.0002391246525803581 recon and 2.6530020236968994 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018971769942436366\n",
      "\n",
      "Total loss: 0.0019311908399686217; that's 0.0009191682911477983 task and 0.0002368273417232558 recon and 3.875976085662842 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019559052551630885\n",
      "\n",
      "Total recon loss: 0.004138044081628323; that's 3.5635313987731934 text and 0.0005745124071836472 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004177457015030086\n",
      "\n",
      "Total loss: 0.0017355913296341896; that's 0.0009107139194384217 task and 0.00023022215464152396 recon and 2.973276138305664 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018739182781428098\n",
      "\n",
      "Total loss: 0.001805123407393694; that's 0.0009580488549545407 task and 0.00024839036632329226 recon and 2.9934208393096924 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019041756435763091\n",
      "\n",
      "Total loss: 0.0018252647714689374; that's 0.0010300417197868228 task and 0.00024157052394002676 recon and 2.7682626247406006 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019535116967745124\n",
      "\n",
      "Total recon loss: 0.0033837174996733665; that's 2.930271625518799 text and 0.0004534457693807781 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004213751286733895\n",
      "\n",
      "Total loss: 0.0018848234321922064; that's 0.0010942051885649562 task and 0.00023962283739820123 recon and 2.754976511001587 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001919163822894916\n",
      "\n",
      "Total loss: 0.0019666424486786127; that's 0.0010422630002722144 task and 0.0002435208298265934 recon and 3.4042935371398926 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019200294872280211\n",
      "\n",
      "Total loss: 0.0020752009004354477; that's 0.0011449105804786086 task and 0.00023881872766651213 recon and 3.4573585987091064 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001988284718245268\n",
      "\n",
      "Total recon loss: 0.0038311167154461145; that's 3.354954719543457 text and 0.00047616203664802015 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004018397750332952\n",
      "\n",
      "Total loss: 0.002058316022157669; that's 0.0011700151953846216 task and 0.00024130458768922836 recon and 3.234981060028076 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002028320365352556\n",
      "\n",
      "Total loss: 0.00196505943313241; that's 0.001053653541021049 task and 0.0002334294404136017 recon and 3.3898818492889404 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020221334416419268\n",
      "\n",
      "Total loss: 0.0018035087268799543; that's 0.001087797456420958 task and 0.0002414987829979509 recon and 2.3710622787475586 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019509217154700309\n",
      "\n",
      "Total recon loss: 0.0037606433033943176; that's 3.184185266494751 text and 0.000576457881834358 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004005205372814089\n",
      "\n",
      "Total loss: 0.0015696650370955467; that's 0.0007550772279500961 task and 0.00024458489497192204 recon and 2.8500146865844727 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018190926651004702\n",
      "\n",
      "Total loss: 0.00167678645811975; that's 0.000851460441481322 task and 0.00023833174782339483 recon and 2.934971332550049 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001812193860532716\n",
      "\n",
      "Total loss: 0.002096126088872552; that's 0.0011408122954890132 task and 0.00023628646158613265 recon and 3.5951366424560547 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018579331890214235\n",
      "\n",
      "Total recon loss: 0.0035729066003113985; that's 3.063843011856079 text and 0.0005090634804219007 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038257423997856677\n",
      "\n",
      "Total loss: 0.0018222325015813112; that's 0.0008245873614214361 task and 0.00024162387126125395 recon and 3.780106544494629 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019257858500350267\n",
      "\n",
      "Total loss: 0.0025196820497512817; that's 0.0012912284582853317 task and 0.00023067498113960028 recon and 4.988893508911133 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019304692198056728\n",
      "\n",
      "Total loss: 0.0017972689820453525; that's 0.0009942525066435337 task and 0.00025122196529991925 recon and 2.758972644805908 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018845846108160912\n",
      "\n",
      "Total recon loss: 0.004284264054149389; that's 3.704481601715088 text and 0.0005797822959721088 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0039196447446011\n",
      "\n",
      "Total loss: 0.0017188910860568285; that's 0.000998223666101694 task and 0.00024345651036128402 recon and 2.386054515838623 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020353522058576346\n",
      "\n",
      "Total loss: 0.001647316850721836; that's 0.00101289723534137 task and 0.0002308692055521533 recon and 2.0177526473999023 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0017284034157637506\n",
      "\n",
      "Total loss: 0.0022283652797341347; that's 0.0009441906586289406 task and 0.00024731349549256265 recon and 5.184305191040039 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018076838355045766\n",
      "\n",
      "Total loss: 0.001618093578144908; that's 0.0009576561278663576 task and 0.00023032577882986516 recon and 2.1505582332611084 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001861987056909129\n",
      "\n",
      "Total recon loss: 0.004203391261398792; that's 3.670117139816284 text and 0.0005332740256562829 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0038333921018056574\n",
      "\n",
      "Total loss: 0.002063677180558443; that's 0.0013351034140214324 task and 0.00024189718533307314 recon and 2.433382987976074 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001834412879543379\n",
      "\n",
      "Total loss: 0.0022987849079072475; that's 0.0010423976927995682 task and 0.00023312863777391613 recon and 5.116292476654053 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0019439147575758397\n",
      "\n",
      "Total recon loss: 0.003848082385957241; that's 3.3033230304718018 text and 0.0005447591538541019 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003881776814814657\n",
      "\n",
      "Total loss: 0.0017276076832786202; that's 0.0009778877720236778 task and 0.00023737539595458657 recon and 2.561722755432129 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001841768331360072\n",
      "\n",
      "Total loss: 0.002372270915657282; that's 0.0012910534860566258 task and 0.00023289094679057598 recon and 4.241631984710693 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020197726308833807\n",
      "\n",
      "Total loss: 0.0017862999811768532; that's 0.0010560160735622048 task and 0.00022904564684722573 recon and 2.5061912536621094 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001965476913610473\n",
      "\n",
      "Total recon loss: 0.0037520111072808504; that's 3.06044340133667 text and 0.0006915675476193428 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003769959923811257\n",
      "\n",
      "Total loss: 0.0019384750630706549; that's 0.0010061232605949044 task and 0.00023643529857508838 recon and 3.4795825481414795 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002005467624403536\n",
      "\n",
      "Total loss: 0.0021575838327407837; that's 0.0010075541213154793 task and 0.00023844093084335327 recon and 4.557944297790527 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020571492530871184\n",
      "\n",
      "Total loss: 0.0018446205649524927; that's 0.0010181168327108026 task and 0.00022618917864747345 recon and 3.001572847366333 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020476442424114793\n",
      "\n",
      "Total loss: 0.0014152927324175835; that's 0.0006657124031335115 task and 0.00022575940238311887 recon and 2.6191043853759766 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018322671519126743\n",
      "\n",
      "Total recon loss: 0.006028227508068085; that's 5.433235168457031 text and 0.0005949923070147634 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.0037740169279277323\n",
      "\n",
      "Total loss: 0.0017226369818672538; that's 0.001031894818879664 task and 0.00023615466488990933 recon and 2.272937536239624 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0017891127069015057\n",
      "\n",
      "Total loss: 0.0018959282897412777; that's 0.0010692442301660776 task and 0.00023750732361804694 recon and 2.9458842277526855 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0017965187306981534\n",
      "\n",
      "Total recon loss: 0.004117149859666824; that's 3.641479969024658 text and 0.00047566983266733587 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004134006991516798\n",
      "\n",
      "Total loss: 0.0018678545020520687; that's 0.0011140141868963838 task and 0.0002456542570143938 recon and 2.5409300327301025 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0017489107989240437\n",
      "\n",
      "Total loss: 0.00172247807495296; that's 0.001028695609420538 task and 0.00023962257546372712 recon and 2.270799398422241 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.00179279827978462\n",
      "\n",
      "Total loss: 0.0016489168629050255; that's 0.0008823044481687248 task and 0.000231668193009682 recon and 2.6747212409973145 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0017636667867191136\n",
      "\n",
      "Total loss: 0.0019134206231683493; that's 0.0012215832248330116 task and 0.00023474975023418665 recon and 2.285438299179077 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.001783904175972566\n",
      "\n",
      "Total recon loss: 0.0033106524497270584; that's 2.672851085662842 text and 0.0006378011894412339 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.004272727726493031\n",
      "\n",
      "Total loss: 0.002365219872444868; that's 0.0011693553533405066 task and 0.00023977342061698437 recon and 4.780456066131592 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018768853170331567\n",
      "\n",
      "Total loss: 0.0020651333034038544; that's 0.0010064676171168685 task and 0.00023658396094106138 recon and 4.110408782958984 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020929206151049586\n",
      "\n",
      "Total recon loss: 0.0029686912894248962; that's 2.459887981414795 text and 0.0005088032921776175 img\n",
      "\n",
      "\n",
      "Average total loss for task 2, last 100 batches: 0.003772578495554626\n",
      "\n",
      "Total loss: 0.0020358378533273935; that's 0.0008392274030484259 task and 0.0002357957127969712 recon and 4.804073810577393 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0020585389784537255\n",
      "\n",
      "Total loss: 0.0016675957012921572; that's 0.0008754440932534635 task and 0.00024139568267855793 recon and 2.753779172897339 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.002022034685360268\n",
      "\n",
      "Total loss: 0.0020014557521790266; that's 0.0011913188500329852 task and 0.00023608269111718982 recon and 2.8702707290649414 total text\n",
      "\n",
      "\n",
      "Average total loss for task 0, last 100 batches: 0.0018523620290216058\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m reset_model \u001b[38;5;241m=\u001b[39m (b \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     17\u001b[0m printing \u001b[38;5;241m=\u001b[39m ((batch_num \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m99\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m full_results \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprinting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprinting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m L \u001b[38;5;241m=\u001b[39m full_results[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# no need to look into the detailed loss report\u001b[39;00m\n\u001b[1;32m     20\u001b[0m total_losses[ind] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m L\n",
      "File \u001b[0;32m~/Player/control_framework.py:64\u001b[0m, in \u001b[0;36mcontrol_batch\u001b[0;34m(batch_size, model, optimizer, batch_num, compute_grad, random_order, model_eval, reset_model, printing, training)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_batch\u001b[39m(batch_size, model, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, batch_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, compute_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reset_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, printing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compute_grad:\n\u001b[0;32m---> 64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_control_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprinting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m training:\n",
      "File \u001b[0;32m~/Player/control_framework.py:58\u001b[0m, in \u001b[0;36m_control_batch\u001b[0;34m(batch_size, model, optimizer, batch_num, random_order, model_eval, reset_model, printing, training)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_model \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mtype\u001b[39m(model) \u001b[38;5;129;01mis\u001b[39;00m EnhancedAgentBrain):\n\u001b[1;32m     56\u001b[0m     model\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, text_loss\u001b[38;5;241m.\u001b[39mitem(), img_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_batches = 10000*100#6250*32\n",
    "\n",
    "for b in range(total_batches):\n",
    "    secs_to_cool = monitor_stage(device)\n",
    "    if secs_to_cool > 0:\n",
    "        print(f\"Had to cool device for {secs_to_cool} seconds\\n\")\n",
    "        \n",
    "    triplet, _, ind = rb.random_draw()\n",
    "    func, opt, batch_size = triplet\n",
    "    \n",
    "    batch_num = batches[ind]\n",
    "    batches[ind] += 1\n",
    "\n",
    "    #reset_model = True #default option; only transfer memory within the task files\n",
    "    reset_model = (b % 3 == 2)\n",
    "\n",
    "    printing = ((batch_num % 100) == 99)\n",
    "    full_results = func(batch_size, brain, optimizer=opt, batch_num=batch_num, compute_grad=True, random_order=True, model_eval=False, reset_model=reset_model, printing=printing, training=True)\n",
    "    L = full_results[0] # no need to look into the detailed loss report\n",
    "    total_losses[ind] += L\n",
    "\n",
    "    if printing: # if this is a significant batch\n",
    "        avg_loss = total_losses[ind] / 100\n",
    "        total_losses[ind] = 0\n",
    "        print(f\"Average total loss for task {ind}, last 100 batches: {avg_loss}\\n\")\n",
    "        \n",
    "        if avg_loss < curr_mins[ind]:\n",
    "            curr_mins[ind] = avg_loss\n",
    "            torch.save(brain.state_dict(), f\"brain_checkpoints/enhanced_brain_arrow_task_v3_batch{b + 1}.pth\")\n",
    "            \n",
    "    if b < 10:\n",
    "        print(f\"batch {b}, task {ind}, task batch_num {batch_num}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb7c96-0ce6-4e96-99a6-0a2cddfd5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates: add sampling weights; add batch_num to print statement; split these two optimizers and optimize them separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa482e-91be-4bae-ac3c-f75ae99e23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5913c4-87c5-4365-8376-3fddbef4efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_temps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82cb545-7d75-492b-84a2-7cd0f532f045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
