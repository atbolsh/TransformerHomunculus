{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc7a75c-b93b-4e05-8262-4ab31ab4bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model import *\n",
    "from agent_internals import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4669c268-33a4-4cce-afa6-a4c6963a51ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppo_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c26e1c5-c3d8-4fb3-9f6e-5a63e30e2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = DefaultAgentBrain(7).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd60716-ccea-459a-a29a-a99c256239c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will write a demo reward func\n",
    "# Reward func has to accept a batch of traces and the seed offset\n",
    "# Reward func must provide 0 for everything after termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ddf90d5-56c7-4559-afea-4d80539386af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def reward_func_full(traces, seed_offset, past_terminated, contexts=None):\n",
    "#    # ignore contexts for now\n",
    "#    with torch.no_grad():\n",
    "#        batches, trace_length = traces.size()\n",
    "#        reward_len = trace_length - seed_offset + 1 # includes reward for initial seed\n",
    "#        rewards = torch.zeros(batches, reward_len, device=traces.device)\n",
    "#        for i in range(reward_len):\n",
    "#            trace_index = i + seed_offset - 1 # includes reward for initial seed\n",
    "#            rewards[:, i] += torch.logical_and(\n",
    "#                             torch.logical_and((traces[:, trace_index] > 2),  \\\n",
    "#                                               (torch.logical_not(past_terminated[:, i]))), \\\n",
    "#                             (((traces[:, trace_index] - traces[:, trace_index-1]) % 4) == 1)) * 1.0\n",
    "#            rewards[:, i] += torch.logical_and((traces[:, trace_index] == 2),  \\\n",
    "#                                              (torch.logical_not(past_terminated[:, i]))) * 5.0 # teach it to finish early\n",
    "#    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8904b6c-4654-4adb-9430-3e257c51d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 4's get rewards; nothing else matters.\n",
    "def reward_func_stupid(traces, seed_offset, past_terminated, contexts=None):\n",
    "    # ignore contexts for now\n",
    "    with torch.no_grad():\n",
    "        batches, trace_length = traces.size()\n",
    "        reward_len = trace_length - seed_offset + 1 # includes reward for initial seed\n",
    "        rewards = torch.zeros(batches, reward_len, device=traces.device)\n",
    "        for i in range(reward_len):\n",
    "            trace_index = i + seed_offset - 1 # includes reward for initial seed\n",
    "            rewards[:, i] += torch.logical_and((traces[:, trace_index] == 4),  \\\n",
    "                                              (torch.logical_not(past_terminated[:, i]))) * 5.0 # teach it to finish early\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b340a538-1e1c-4479-abe7-7a9622c86ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 4's get rewards; nothing else matters.\n",
    "def reward_func_modular(traces, seed_offset, past_terminated, contexts=None):\n",
    "    # ignore contexts for now\n",
    "    with torch.no_grad():\n",
    "        batches, trace_length = traces.size()\n",
    "        reward_len = trace_length - seed_offset + 1 # includes reward for initial seed\n",
    "        rewards = torch.zeros(batches, reward_len, device=traces.device)\n",
    "        for i in range(reward_len):\n",
    "            trace_index = i + seed_offset - 1 # includes reward for initial seed\n",
    "            rewards[:, i] += torch.logical_and(\n",
    "                             torch.logical_and((traces[:, trace_index] > 2),  \\\n",
    "                                               (torch.logical_not(past_terminated[:, i]))), \\\n",
    "                             (((traces[:, trace_index] - traces[:, trace_index-1]) % 4) == 1)) * 1.0\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b7d066-e994-454b-8997-b0d1f62ef2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only a reward at the end\n",
    "def reward_func_final(traces, seed_offset, past_terminated, contexts=None):\n",
    "    # ignore contexts for now\n",
    "    with torch.no_grad():\n",
    "        batches, trace_length = traces.size()\n",
    "        reward_len = trace_length - seed_offset + 1 # includes reward for initial seed\n",
    "        rewards = torch.zeros(batches, reward_len, device=traces.device)\n",
    "        for i in range(reward_len):\n",
    "            trace_index = i + seed_offset - 1 # includes reward for initial seed\n",
    "            rewards[:, i] += torch.logical_and((traces[:, trace_index] == 2),  \\\n",
    "                                              (torch.logical_not(past_terminated[:, i]))) * 5.0 # teach it to finish early\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea0ec61-2a44-4a66-a623-8e38493dca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_func_full(traces, seed_offset, past_terminated, contexts=None):\n",
    "    return reward_func_modular(traces, seed_offset, past_terminated, contexts) + \\\n",
    "           reward_func_final(traces, seed_offset, past_terminated, contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49668e1-2af5-49eb-896c-81d53225df41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd0feb-b740-4ef2-8939-6479d9d0dbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96b3ee36-bbfa-4000-8961-ad9c157b421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_func = reward_func_modular #reward_func_stupid #reward_func_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91cf3f9c-a37d-46aa-bc81-e64e508cedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_value(x):\n",
    "#    with torch.no_grad():\n",
    "#        val = brain.dopamine(brain.text_enc(x))\n",
    "#    return val\n",
    "\n",
    "get_value = SolitaryValueFunc(7).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "084b864c-ade3-4004-8c8f-5745590aa262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the lunar lander demo code: gamma 0.99, tau 0.97.\n",
    "# Will maybe change later since the env is so different\n",
    "#                                        policy,  value,  gamma, tau, reward_func\n",
    "env_buffer = SentenceOutputSingleEpisode(brain, get_value, 0.99, 0.97, reward_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc2fab2c-2533-4499-abef-c6d486cad531",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = torch.randint(3, 7, (3, 10), device=brain.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa249a68-14ae-463d-9faa-28e767521be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9041],\n",
       "        [ 0.0858],\n",
       "        [ 2.5040]], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_value(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cf847b7-8bee-4e9e-b3a8-1063c8cabfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_buffer.fill(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6c57425-1e83-4f63-8a80-3cb3c3b9e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, that's tested, now let's test an actual full training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d3dfb2b-1772-4d72-a9d2-fb5850d07a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seeds(minVal=3, maxVal=7, lenSeeds=10, batchSize=16, device='cuda'):\n",
    "    return torch.randint(minVal, maxVal, (batchSize, lenSeeds), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c06daee4-2a09-43e4-947d-83e50026a2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24009999999999995"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87969ccd-dc0c-46ec-97a5-58a9646972be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "def get_bb(num_buffers=64):\n",
    "    buffer_buffer = []\n",
    "    for i in range(num_buffers):\n",
    "        print(i)\n",
    "        # Let's try to make this particular system simpler on the value func, \n",
    "        # make it focus on the here-and-now, more. Old vals: 0.99, 0.97\n",
    "        #                                                      0.7, 0.6\n",
    "        buffer = SentenceOutputSingleEpisode(brain, get_value, 0.0, 0.0, reward_func)\n",
    "        buffer.fill(get_seeds(batchSize=8))\n",
    "        buffer = buffer.to('cpu') # avoid eating VRAM\n",
    "        buffer_buffer.append(buffer)\n",
    "    return buffer_buffer\n",
    "num_buffers=64\n",
    "buffer_buffer = get_bb(num_buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90bc3944-9981-4794-8b4d-33084df0b7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda81d00>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6cce7bd490>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6cce5ba570>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6cced71d60>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6cce806ed0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6cce94ebd0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6dc0420f20>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6cce94d730>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6cce9023f0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccd936360>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccd934cb0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccd936000>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6cce5c8830>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccd9354f0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6cce9ca420>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccd9350a0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccd9350d0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccd9352e0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccd936660>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda821e0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda815b0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda824e0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda819d0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda81a60>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda81b50>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda825d0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82510>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82480>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda827b0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda829f0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6cce382ba0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82900>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda81940>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6cce8b2ff0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82db0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda80fe0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82cf0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6cce933170>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82ed0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82c60>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda81b80>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda828a0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82d20>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82e10>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82b70>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda83260>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda83350>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6cce5baea0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda81c70>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82840>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82690>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda832f0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda83230>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda834d0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82c30>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda83500>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda83860>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda83620>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda82cc0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda835c0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda836b0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda839e0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda83740>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f6ccda83800>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8589a79d-4a54-4bec-8b3f-4f6abdc32a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5f47d90-d5a2-486d-9178-ff2147860e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_optimizer = optim.Adam(get_value.parameters(), lr=0.0005, betas=(0.9, 0.98), eps=1e-9)\n",
    "val_epochs = 16 #16 # old is 80, but that's only sampling a few per turn; we're gonna go through the whole buffer-buffer\n",
    "# 16 was too much, let's go with 2 times through all 64 16-batch sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dec4efba-dc53-471c-a8b6-2002294cea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this training loop is just for 'burning in' to have an initial value func that corresponds to the policy;\n",
    "# the other one (later) will include clamping and is slightly more advanced\n",
    "# this is 8 Gb VRAM, by the way (at batchSize 16). Not *too* surprising, but I will need the bigger system right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bdfd38f-84c5-4784-bc69-b79a5260aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def train_val_func(val_optimizer, epochs, buffer_buffer):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"==========Epoch {epoch}=====================\")\n",
    "        get_value.train()\n",
    "        train_loss = 0\n",
    "        random.shuffle(buffer_buffer)\n",
    "        i = 0\n",
    "        for buffer in buffer_buffer:\n",
    "            i += 1\n",
    "            buffer = buffer.cuda()\n",
    "            val_optimizer.zero_grad()\n",
    "            new_vals = buffer.get_values(evaluation = False) # call value func correctly, with gradients\n",
    "            loss = mse_loss(new_vals, buffer.returns)\n",
    "            loss.backward()\n",
    "            val_optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            print(f\"episode {i}, val func loss {loss.item()}\\n\")\n",
    "            buffer = buffer.cpu()\n",
    "        val_optimizer.zero_grad()\n",
    "        print(f\"Val func train loss in epoch {epoch}:{train_loss / (len(buffer_buffer))}\")\n",
    "#train_val_func(val_optimizer, val_epochs, buffer_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a18ceb68-9b96-4ec3-b534-6b30102dad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's recalculate gaes after burn-in, to get any progress on the policy network at all\n",
    "def restore_coherence(buffer_buffer):\n",
    "    for buffer in buffer_buffer:\n",
    "        buffer=buffer.cuda()\n",
    "        buffer.values = buffer.get_values() # retrained val func\n",
    "        buffer.gaes = buffer.get_gaes()\n",
    "        buffer = buffer.cpu()\n",
    "    return buffer_buffer\n",
    "#buffer_buffer = restore_coherence(buffer_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430477c8-f4c7-458b-a184-fd241d00a370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd128d6d-108d-448f-8dee-fe8eff958162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77447829-a88f-42c7-9627-c85afbc6cdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64219914-608f-4794-b100-46b5ca3f97d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "319d3839-93f9-4777-b0c4-0acf482a6e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_optimizer = optim.Adam(brain.parameters(), lr=0.0003, betas=(0.9, 0.98), eps=1e-9)\n",
    "policy_epochs = 4\n",
    "epochs = policy_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f741a965-8e75-4dfb-a108-6773dfda70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_clip_range = 0.1 #0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08e06795-b9b7-4e60-8d2f-4b658502e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_loss_weight = 5e-2 #0.01 I think this is too high for the policy I'm trying to produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d60ae67-9029-481b-8a34-700d93923497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchsize 8 is the correct path. THis is like 7.5 gigs of VRAM\n",
    "# just barely enough to work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "159d38c7-4d36-4213-a9eb-67684ae1bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_policy(policy_optimizer, epochs, buffer_buffer, policy_clip_range=0.1, entropy_loss_weight=0.01):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"==========Epoch {epoch}=====================\")\n",
    "        brain.train()\n",
    "        train_loss = 0\n",
    "        random.shuffle(buffer_buffer)\n",
    "        i = 0\n",
    "        for buffer in buffer_buffer:\n",
    "            i += 1\n",
    "            buffer = buffer.cuda()\n",
    "            #seeds = buffer.traces[:, :buffer.seed_offset]\n",
    "            policy_optimizer.zero_grad()\n",
    "            # hopefully no torch.no_grad's in that generation func, huh\n",
    "            # NO, this is NOT the correct path. I need logpas that correspond to the traces, no others\n",
    "            # traces, logpas, entropies = brain.generate(seeds)\n",
    "            # THIS is the correct one. Can be accelerated by passing in masks, later.\n",
    "            logpas, entropies = brain.compute_probabilities(buffer.traces, buffer.seed_offset, buffer.contexts)\n",
    "            #print(logpas.size())\n",
    "            #print(buffer.logpas.size())\n",
    "            # Add constraints to kill logpas / entropis in past_terminated? Just to avoid confusion?\n",
    "            ratios = (logpas - buffer.logpas).exp()\n",
    "            pi_obj = buffer.gaes * ratios\n",
    "            pi_obj_clipped = buffer.gaes * ratios.clamp(1.0 - policy_clip_range,\n",
    "                                                       1.0 + policy_clip_range)\n",
    "            policy_loss = -torch.min(pi_obj, pi_obj_clipped).mean()\n",
    "            entropy_loss = -entropies.mean() * entropy_loss_weight\n",
    "            \n",
    "            loss = policy_loss + entropy_loss\n",
    "    \n",
    "            loss.backward()\n",
    "            policy_optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            print(f\"episode {i}, policy loss {loss.item()}\\n\")\n",
    "            buffer = buffer.cpu()\n",
    "        policy_optimizer.zero_grad()\n",
    "        print(f\"Policy train loss in epoch {epoch}:{train_loss / (len(buffer_buffer))}\")\n",
    "#train_policy(policy_optimizer, policy_epochs, buffer_buffer, policy_clip_range, entropy_loss_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f123b67b-f5af-4d31-abe6-5661a4cb35cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find some way of clearing all the nonesense from the VRAM, I don't need the training artefacts to persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cef9e3f5-5c11-4318-9fcb-92f132258674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1dc0ea2-3071-4f74-9686-d57d43f9666d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0912623405456543"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d452b720-00cf-41f4-a9a1-0711a6ff51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_return(bb):\n",
    "    \"\"\"The average return (at the end of the seeds alone) from a buffer-buffer\"\"\"\n",
    "    s = torch.zeros(bb[0].returns[:, 0].size(), device = bb[0].returns[:, 0].device)\n",
    "    for b in bb:\n",
    "        s += bb[0].returns[:, 0]\n",
    "    return torch.sum(s).item()/(len(bb) * bb[0].returns.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5e219e4-0fb3-4cfa-a71e-9d589769a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no policy optimization on first round, only subsequent\n",
    "def run_round(round_num, policy_optimizer, val_optimizer, num_buffers=64, policy_epochs=4, val_epochs=16, policy_clip_range=0.5, entropy_loss_weight=1e-3):\n",
    "    # First, get some samples\n",
    "    brain.eval()\n",
    "    get_value.eval()\n",
    "    buffer_buffer = get_bb(num_buffers) # run the inference side\n",
    "    print(f\"Return before training was {average_return(buffer_buffer)}\")\n",
    "    if round_num > 0:\n",
    "        train_policy(policy_optimizer, policy_epochs, buffer_buffer, policy_clip_range, entropy_loss_weight)\n",
    "    train_val_func(val_optimizer, val_epochs, buffer_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "585410f6-6e85-49e8-8d0d-e4a321b44082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************ROUND 0 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.2074644565582275\n",
      "\n",
      "episode 2, val func loss 2887.237548828125\n",
      "\n",
      "episode 3, val func loss 5445.869140625\n",
      "\n",
      "episode 4, val func loss 582.6539916992188\n",
      "\n",
      "episode 5, val func loss 6.276142597198486\n",
      "\n",
      "episode 6, val func loss 11.880847930908203\n",
      "\n",
      "episode 7, val func loss 32.920982360839844\n",
      "\n",
      "episode 8, val func loss 4.315114974975586\n",
      "\n",
      "episode 9, val func loss 9.506723403930664\n",
      "\n",
      "episode 10, val func loss 46.66351318359375\n",
      "\n",
      "episode 11, val func loss 7.770531177520752\n",
      "\n",
      "episode 12, val func loss 0.8253315091133118\n",
      "\n",
      "episode 13, val func loss 9.432865142822266\n",
      "\n",
      "episode 14, val func loss 9.06496524810791\n",
      "\n",
      "episode 15, val func loss 3.630314826965332\n",
      "\n",
      "episode 16, val func loss 0.13209176063537598\n",
      "\n",
      "Val func train loss in epoch 0:566.2742231078446\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 3.496873617172241\n",
      "\n",
      "episode 2, val func loss 8.393011093139648\n",
      "\n",
      "episode 3, val func loss 4.20756721496582\n",
      "\n",
      "episode 4, val func loss 0.383107990026474\n",
      "\n",
      "episode 5, val func loss 5.439445495605469\n",
      "\n",
      "episode 6, val func loss 6.706742286682129\n",
      "\n",
      "episode 7, val func loss 1.4436721801757812\n",
      "\n",
      "episode 8, val func loss 0.08219128102064133\n",
      "\n",
      "episode 9, val func loss 1.748181939125061\n",
      "\n",
      "episode 10, val func loss 3.471904754638672\n",
      "\n",
      "episode 11, val func loss 3.4292032718658447\n",
      "\n",
      "episode 12, val func loss 0.1008809357881546\n",
      "\n",
      "episode 13, val func loss 1.870739221572876\n",
      "\n",
      "episode 14, val func loss 7.9143385887146\n",
      "\n",
      "episode 15, val func loss 0.7602962255477905\n",
      "\n",
      "episode 16, val func loss 0.6851379871368408\n",
      "\n",
      "Val func train loss in epoch 1:3.1333308801986277\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 11.590311050415039\n",
      "\n",
      "episode 2, val func loss 2.4924135208129883\n",
      "\n",
      "episode 3, val func loss 0.09519348293542862\n",
      "\n",
      "episode 4, val func loss 1.8272771835327148\n",
      "\n",
      "episode 5, val func loss 6.173357963562012\n",
      "\n",
      "episode 6, val func loss 1.2589073181152344\n",
      "\n",
      "episode 7, val func loss 0.5485496520996094\n",
      "\n",
      "episode 8, val func loss 0.8771944046020508\n",
      "\n",
      "episode 9, val func loss 1.5520946979522705\n",
      "\n",
      "episode 10, val func loss 1.3112025260925293\n",
      "\n",
      "episode 11, val func loss 0.14865557849407196\n",
      "\n",
      "episode 12, val func loss 0.20919178426265717\n",
      "\n",
      "episode 13, val func loss 1.4612014293670654\n",
      "\n",
      "episode 14, val func loss 0.5454679727554321\n",
      "\n",
      "episode 15, val func loss 0.10849212855100632\n",
      "\n",
      "episode 16, val func loss 0.6552301645278931\n",
      "\n",
      "Val func train loss in epoch 2:1.9284213036298752\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.2613014876842499\n",
      "\n",
      "episode 2, val func loss 0.24649114906787872\n",
      "\n",
      "episode 3, val func loss 0.15505388379096985\n",
      "\n",
      "episode 4, val func loss 0.3638260066509247\n",
      "\n",
      "episode 5, val func loss 0.18439222872257233\n",
      "\n",
      "episode 6, val func loss 0.12791486084461212\n",
      "\n",
      "episode 7, val func loss 0.1378328651189804\n",
      "\n",
      "episode 8, val func loss 0.24903063476085663\n",
      "\n",
      "episode 9, val func loss 0.10288301855325699\n",
      "\n",
      "episode 10, val func loss 0.11535008996725082\n",
      "\n",
      "episode 11, val func loss 0.15137451887130737\n",
      "\n",
      "episode 12, val func loss 0.13667896389961243\n",
      "\n",
      "episode 13, val func loss 0.15780700743198395\n",
      "\n",
      "episode 14, val func loss 0.13305525481700897\n",
      "\n",
      "episode 15, val func loss 0.0766809955239296\n",
      "\n",
      "episode 16, val func loss 0.2168557196855545\n",
      "\n",
      "Val func train loss in epoch 3:0.17603304283693433\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.13105228543281555\n",
      "\n",
      "episode 2, val func loss 0.1998187005519867\n",
      "\n",
      "episode 3, val func loss 0.11283855885267258\n",
      "\n",
      "episode 4, val func loss 0.08179330080747604\n",
      "\n",
      "episode 5, val func loss 0.12190914154052734\n",
      "\n",
      "episode 6, val func loss 0.14015334844589233\n",
      "\n",
      "episode 7, val func loss 0.11284191906452179\n",
      "\n",
      "episode 8, val func loss 0.17784611880779266\n",
      "\n",
      "episode 9, val func loss 0.21317967772483826\n",
      "\n",
      "episode 10, val func loss 0.17683324217796326\n",
      "\n",
      "episode 11, val func loss 0.07347904145717621\n",
      "\n",
      "episode 12, val func loss 0.13256828486919403\n",
      "\n",
      "episode 13, val func loss 0.1454847753047943\n",
      "\n",
      "episode 14, val func loss 0.08688177913427353\n",
      "\n",
      "episode 15, val func loss 0.15309788286685944\n",
      "\n",
      "episode 16, val func loss 0.10985755920410156\n",
      "\n",
      "Val func train loss in epoch 4:0.13560222601518035\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.14288614690303802\n",
      "\n",
      "episode 2, val func loss 0.19577381014823914\n",
      "\n",
      "episode 3, val func loss 0.17631895840168\n",
      "\n",
      "episode 4, val func loss 0.10946692526340485\n",
      "\n",
      "episode 5, val func loss 0.16635482013225555\n",
      "\n",
      "episode 6, val func loss 0.1025509461760521\n",
      "\n",
      "episode 7, val func loss 0.188552588224411\n",
      "\n",
      "episode 8, val func loss 0.0736108347773552\n",
      "\n",
      "episode 9, val func loss 0.11459193378686905\n",
      "\n",
      "episode 10, val func loss 0.22207148373126984\n",
      "\n",
      "episode 11, val func loss 0.06830424815416336\n",
      "\n",
      "episode 12, val func loss 0.19840112328529358\n",
      "\n",
      "episode 13, val func loss 0.10481996089220047\n",
      "\n",
      "episode 14, val func loss 0.18557700514793396\n",
      "\n",
      "episode 15, val func loss 0.13940218091011047\n",
      "\n",
      "episode 16, val func loss 0.22681410610675812\n",
      "\n",
      "Val func train loss in epoch 5:0.15096856700256467\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.20268310606479645\n",
      "\n",
      "episode 2, val func loss 0.13235950469970703\n",
      "\n",
      "episode 3, val func loss 0.21752706170082092\n",
      "\n",
      "episode 4, val func loss 0.08305495232343674\n",
      "\n",
      "episode 5, val func loss 0.3228165805339813\n",
      "\n",
      "episode 6, val func loss 0.16628429293632507\n",
      "\n",
      "episode 7, val func loss 0.22933480143547058\n",
      "\n",
      "episode 8, val func loss 0.15240691602230072\n",
      "\n",
      "episode 9, val func loss 0.08769945800304413\n",
      "\n",
      "episode 10, val func loss 0.1996086686849594\n",
      "\n",
      "episode 11, val func loss 0.1445363461971283\n",
      "\n",
      "episode 12, val func loss 0.23828209936618805\n",
      "\n",
      "episode 13, val func loss 0.16702334582805634\n",
      "\n",
      "episode 14, val func loss 0.11676277220249176\n",
      "\n",
      "episode 15, val func loss 0.21849986910820007\n",
      "\n",
      "episode 16, val func loss 0.16423167288303375\n",
      "\n",
      "Val func train loss in epoch 6:0.1776944654993713\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.11630848050117493\n",
      "\n",
      "episode 2, val func loss 0.15808065235614777\n",
      "\n",
      "episode 3, val func loss 0.13456329703330994\n",
      "\n",
      "episode 4, val func loss 0.1350969523191452\n",
      "\n",
      "episode 5, val func loss 0.23994138836860657\n",
      "\n",
      "episode 6, val func loss 0.17754638195037842\n",
      "\n",
      "episode 7, val func loss 0.23849926888942719\n",
      "\n",
      "episode 8, val func loss 0.12488175928592682\n",
      "\n",
      "episode 9, val func loss 0.12329964339733124\n",
      "\n",
      "episode 10, val func loss 0.17864219844341278\n",
      "\n",
      "episode 11, val func loss 0.07875089347362518\n",
      "\n",
      "episode 12, val func loss 0.18897303938865662\n",
      "\n",
      "episode 13, val func loss 0.23419968783855438\n",
      "\n",
      "episode 14, val func loss 0.3195379972457886\n",
      "\n",
      "episode 15, val func loss 0.055268511176109314\n",
      "\n",
      "episode 16, val func loss 0.2072763442993164\n",
      "\n",
      "Val func train loss in epoch 7:0.16942915599793196\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16173170506954193\n",
      "\n",
      "episode 2, val func loss 0.09698454290628433\n",
      "\n",
      "episode 3, val func loss 0.20581166446208954\n",
      "\n",
      "episode 4, val func loss 0.13467174768447876\n",
      "\n",
      "episode 5, val func loss 0.08980432152748108\n",
      "\n",
      "episode 6, val func loss 0.19689247012138367\n",
      "\n",
      "episode 7, val func loss 0.18063625693321228\n",
      "\n",
      "episode 8, val func loss 0.4714373052120209\n",
      "\n",
      "episode 9, val func loss 0.16706259548664093\n",
      "\n",
      "episode 10, val func loss 0.16166074573993683\n",
      "\n",
      "episode 11, val func loss 0.16150054335594177\n",
      "\n",
      "episode 12, val func loss 0.1871805638074875\n",
      "\n",
      "episode 13, val func loss 0.22783765196800232\n",
      "\n",
      "episode 14, val func loss 0.45011988282203674\n",
      "\n",
      "episode 15, val func loss 0.31228962540626526\n",
      "\n",
      "episode 16, val func loss 0.14660893380641937\n",
      "\n",
      "Val func train loss in epoch 8:0.20951440976932645\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.2848248779773712\n",
      "\n",
      "episode 2, val func loss 0.13964879512786865\n",
      "\n",
      "episode 3, val func loss 0.11252391338348389\n",
      "\n",
      "episode 4, val func loss 0.21106019616127014\n",
      "\n",
      "episode 5, val func loss 0.18185287714004517\n",
      "\n",
      "episode 6, val func loss 0.39420315623283386\n",
      "\n",
      "episode 7, val func loss 0.18711447715759277\n",
      "\n",
      "episode 8, val func loss 0.47849324345588684\n",
      "\n",
      "episode 9, val func loss 0.16157454252243042\n",
      "\n",
      "episode 10, val func loss 0.4586651027202606\n",
      "\n",
      "episode 11, val func loss 0.5228170156478882\n",
      "\n",
      "episode 12, val func loss 0.08268482238054276\n",
      "\n",
      "episode 13, val func loss 0.33187738060951233\n",
      "\n",
      "episode 14, val func loss 0.08909787237644196\n",
      "\n",
      "episode 15, val func loss 0.2264467179775238\n",
      "\n",
      "episode 16, val func loss 0.13664661347866058\n",
      "\n",
      "Val func train loss in epoch 9:0.24997072527185082\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.40098634362220764\n",
      "\n",
      "episode 2, val func loss 0.11419449746608734\n",
      "\n",
      "episode 3, val func loss 0.3107755482196808\n",
      "\n",
      "episode 4, val func loss 0.2308797836303711\n",
      "\n",
      "episode 5, val func loss 0.6486285328865051\n",
      "\n",
      "episode 6, val func loss 0.43628087639808655\n",
      "\n",
      "episode 7, val func loss 0.43272408843040466\n",
      "\n",
      "episode 8, val func loss 0.32491037249565125\n",
      "\n",
      "episode 9, val func loss 0.29759931564331055\n",
      "\n",
      "episode 10, val func loss 0.2634686827659607\n",
      "\n",
      "episode 11, val func loss 0.10053744912147522\n",
      "\n",
      "episode 12, val func loss 0.19871492683887482\n",
      "\n",
      "episode 13, val func loss 0.08726180344820023\n",
      "\n",
      "episode 14, val func loss 0.06738822907209396\n",
      "\n",
      "episode 15, val func loss 0.13668140769004822\n",
      "\n",
      "episode 16, val func loss 0.1974470317363739\n",
      "\n",
      "Val func train loss in epoch 10:0.26552993059158325\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.09844718128442764\n",
      "\n",
      "episode 2, val func loss 0.11647406220436096\n",
      "\n",
      "episode 3, val func loss 0.08927424252033234\n",
      "\n",
      "episode 4, val func loss 0.17596006393432617\n",
      "\n",
      "episode 5, val func loss 0.07184407114982605\n",
      "\n",
      "episode 6, val func loss 0.28348472714424133\n",
      "\n",
      "episode 7, val func loss 0.2828519642353058\n",
      "\n",
      "episode 8, val func loss 0.20444992184638977\n",
      "\n",
      "episode 9, val func loss 0.6355867981910706\n",
      "\n",
      "episode 10, val func loss 0.1165439784526825\n",
      "\n",
      "episode 11, val func loss 0.5562525391578674\n",
      "\n",
      "episode 12, val func loss 0.3231744170188904\n",
      "\n",
      "episode 13, val func loss 0.07343385368585587\n",
      "\n",
      "episode 14, val func loss 0.24719296395778656\n",
      "\n",
      "episode 15, val func loss 0.17999792098999023\n",
      "\n",
      "episode 16, val func loss 0.2332020401954651\n",
      "\n",
      "Val func train loss in epoch 11:0.23051067162305117\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.09930255264043808\n",
      "\n",
      "episode 2, val func loss 0.3551437556743622\n",
      "\n",
      "episode 3, val func loss 0.47159650921821594\n",
      "\n",
      "episode 4, val func loss 0.4605086147785187\n",
      "\n",
      "episode 5, val func loss 3.165872097015381\n",
      "\n",
      "episode 6, val func loss 0.4449518024921417\n",
      "\n",
      "episode 7, val func loss 1.0245774984359741\n",
      "\n",
      "episode 8, val func loss 0.6137303709983826\n",
      "\n",
      "episode 9, val func loss 0.08995712548494339\n",
      "\n",
      "episode 10, val func loss 0.46298789978027344\n",
      "\n",
      "episode 11, val func loss 0.5702242851257324\n",
      "\n",
      "episode 12, val func loss 0.5374141335487366\n",
      "\n",
      "episode 13, val func loss 0.0721922367811203\n",
      "\n",
      "episode 14, val func loss 0.2156170755624771\n",
      "\n",
      "episode 15, val func loss 0.1830187290906906\n",
      "\n",
      "episode 16, val func loss 0.46882447600364685\n",
      "\n",
      "Val func train loss in epoch 12:0.5772449476644397\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.07270053029060364\n",
      "\n",
      "episode 2, val func loss 0.6183918714523315\n",
      "\n",
      "episode 3, val func loss 0.14905133843421936\n",
      "\n",
      "episode 4, val func loss 0.7933497428894043\n",
      "\n",
      "episode 5, val func loss 0.48999255895614624\n",
      "\n",
      "episode 6, val func loss 1.836458444595337\n",
      "\n",
      "episode 7, val func loss 13.29686164855957\n",
      "\n",
      "episode 8, val func loss 2.116563320159912\n",
      "\n",
      "episode 9, val func loss 15.35153579711914\n",
      "\n",
      "episode 10, val func loss 6.926240921020508\n",
      "\n",
      "episode 11, val func loss 9.397173881530762\n",
      "\n",
      "episode 12, val func loss 26.68910789489746\n",
      "\n",
      "episode 13, val func loss 1.3329280614852905\n",
      "\n",
      "episode 14, val func loss 14.99238109588623\n",
      "\n",
      "episode 15, val func loss 1.1735355854034424\n",
      "\n",
      "episode 16, val func loss 10.874573707580566\n",
      "\n",
      "Val func train loss in epoch 13:6.631927900016308\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.8884153366088867\n",
      "\n",
      "episode 2, val func loss 3.3078882694244385\n",
      "\n",
      "episode 3, val func loss 5.707156658172607\n",
      "\n",
      "episode 4, val func loss 0.5566056966781616\n",
      "\n",
      "episode 5, val func loss 3.7686336040496826\n",
      "\n",
      "episode 6, val func loss 0.6180483102798462\n",
      "\n",
      "episode 7, val func loss 0.1500009298324585\n",
      "\n",
      "episode 8, val func loss 0.5454356074333191\n",
      "\n",
      "episode 9, val func loss 1.7247920036315918\n",
      "\n",
      "episode 10, val func loss 0.19526971876621246\n",
      "\n",
      "episode 11, val func loss 0.6087930798530579\n",
      "\n",
      "episode 12, val func loss 2.3473575115203857\n",
      "\n",
      "episode 13, val func loss 0.27097877860069275\n",
      "\n",
      "episode 14, val func loss 2.5317299365997314\n",
      "\n",
      "episode 15, val func loss 0.3029822111129761\n",
      "\n",
      "episode 16, val func loss 0.28911587595939636\n",
      "\n",
      "Val func train loss in epoch 14:1.4883252205327153\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.2614831924438477\n",
      "\n",
      "episode 2, val func loss 0.26031166315078735\n",
      "\n",
      "episode 3, val func loss 0.7001384496688843\n",
      "\n",
      "episode 4, val func loss 0.5627142786979675\n",
      "\n",
      "episode 5, val func loss 0.9269922971725464\n",
      "\n",
      "episode 6, val func loss 0.8734179139137268\n",
      "\n",
      "episode 7, val func loss 1.9176914691925049\n",
      "\n",
      "episode 8, val func loss 0.21307481825351715\n",
      "\n",
      "episode 9, val func loss 0.9742225408554077\n",
      "\n",
      "episode 10, val func loss 0.9264211654663086\n",
      "\n",
      "episode 11, val func loss 0.4421263337135315\n",
      "\n",
      "episode 12, val func loss 0.6434662342071533\n",
      "\n",
      "episode 13, val func loss 2.742563247680664\n",
      "\n",
      "episode 14, val func loss 0.23253914713859558\n",
      "\n",
      "episode 15, val func loss 2.674180507659912\n",
      "\n",
      "episode 16, val func loss 3.161571502685547\n",
      "\n",
      "Val func train loss in epoch 15:1.1570571726188064\n",
      "***********************TIME WAS 5.131104691823324 min*****************************\n",
      "\n",
      "**********************ROUND 1 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.028223708271980286\n",
      "\n",
      "episode 2, policy loss 0.08688628673553467\n",
      "\n",
      "episode 3, policy loss 0.09761776030063629\n",
      "\n",
      "episode 4, policy loss 0.17035505175590515\n",
      "\n",
      "episode 5, policy loss 0.02903403341770172\n",
      "\n",
      "episode 6, policy loss 0.18904177844524384\n",
      "\n",
      "episode 7, policy loss 0.07544185221195221\n",
      "\n",
      "episode 8, policy loss 0.039993248879909515\n",
      "\n",
      "episode 9, policy loss 0.16648933291435242\n",
      "\n",
      "episode 10, policy loss 0.0787770003080368\n",
      "\n",
      "episode 11, policy loss 0.05572905391454697\n",
      "\n",
      "episode 12, policy loss 0.0421292707324028\n",
      "\n",
      "episode 13, policy loss 0.08446795493364334\n",
      "\n",
      "episode 14, policy loss 0.061641208827495575\n",
      "\n",
      "episode 15, policy loss -0.018066521733999252\n",
      "\n",
      "episode 16, policy loss 0.06015023961663246\n",
      "\n",
      "Policy train loss in epoch 0:0.07446649018675089\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.06263965368270874\n",
      "\n",
      "episode 2, policy loss 0.1187291145324707\n",
      "\n",
      "episode 3, policy loss 0.05591814965009689\n",
      "\n",
      "episode 4, policy loss -0.02949126809835434\n",
      "\n",
      "episode 5, policy loss 0.02470654994249344\n",
      "\n",
      "episode 6, policy loss 0.04818209260702133\n",
      "\n",
      "episode 7, policy loss 0.12393125891685486\n",
      "\n",
      "episode 8, policy loss 0.03889957815408707\n",
      "\n",
      "episode 9, policy loss 0.02537648379802704\n",
      "\n",
      "episode 10, policy loss 0.11057423800230026\n",
      "\n",
      "episode 11, policy loss -0.01569235324859619\n",
      "\n",
      "episode 12, policy loss 0.011605344712734222\n",
      "\n",
      "episode 13, policy loss 0.03797756880521774\n",
      "\n",
      "episode 14, policy loss 0.023529663681983948\n",
      "\n",
      "episode 15, policy loss 0.04603596031665802\n",
      "\n",
      "episode 16, policy loss 0.07061799615621567\n",
      "\n",
      "Policy train loss in epoch 1:0.04709625197574496\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.0349825918674469\n",
      "\n",
      "episode 2, policy loss 0.034062355756759644\n",
      "\n",
      "episode 3, policy loss 0.05690140277147293\n",
      "\n",
      "episode 4, policy loss 0.023111574351787567\n",
      "\n",
      "episode 5, policy loss 0.06489547342061996\n",
      "\n",
      "episode 6, policy loss 0.0504312589764595\n",
      "\n",
      "episode 7, policy loss 0.01336236298084259\n",
      "\n",
      "episode 8, policy loss -0.00766521692276001\n",
      "\n",
      "episode 9, policy loss 0.021781697869300842\n",
      "\n",
      "episode 10, policy loss 0.09341802448034286\n",
      "\n",
      "episode 11, policy loss 0.012393616139888763\n",
      "\n",
      "episode 12, policy loss -0.038926199078559875\n",
      "\n",
      "episode 13, policy loss -0.003949299454689026\n",
      "\n",
      "episode 14, policy loss 0.09589824825525284\n",
      "\n",
      "episode 15, policy loss -0.03442155569791794\n",
      "\n",
      "episode 16, policy loss 0.014015555381774902\n",
      "\n",
      "Policy train loss in epoch 2:0.026893243193626404\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.0020089298486709595\n",
      "\n",
      "episode 2, policy loss 0.013660810887813568\n",
      "\n",
      "episode 3, policy loss -0.04932684823870659\n",
      "\n",
      "episode 4, policy loss 0.008363932371139526\n",
      "\n",
      "episode 5, policy loss 0.02619081735610962\n",
      "\n",
      "episode 6, policy loss 0.08900373429059982\n",
      "\n",
      "episode 7, policy loss -0.050597671419382095\n",
      "\n",
      "episode 8, policy loss 0.03776177763938904\n",
      "\n",
      "episode 9, policy loss 0.03550564497709274\n",
      "\n",
      "episode 10, policy loss 0.027900606393814087\n",
      "\n",
      "episode 11, policy loss 0.025110073387622833\n",
      "\n",
      "episode 12, policy loss 0.07915908843278885\n",
      "\n",
      "episode 13, policy loss -0.022835329174995422\n",
      "\n",
      "episode 14, policy loss 0.09283912926912308\n",
      "\n",
      "episode 15, policy loss 0.000927068293094635\n",
      "\n",
      "episode 16, policy loss 0.0005019307136535645\n",
      "\n",
      "Policy train loss in epoch 3:0.019760855939239264\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.15167981386184692\n",
      "\n",
      "episode 2, val func loss 4.82339334487915\n",
      "\n",
      "episode 3, val func loss 0.7431547045707703\n",
      "\n",
      "episode 4, val func loss 3.7137279510498047\n",
      "\n",
      "episode 5, val func loss 2.265376329421997\n",
      "\n",
      "episode 6, val func loss 0.1735936552286148\n",
      "\n",
      "episode 7, val func loss 2.5350117683410645\n",
      "\n",
      "episode 8, val func loss 0.2865282893180847\n",
      "\n",
      "episode 9, val func loss 0.09101983904838562\n",
      "\n",
      "episode 10, val func loss 0.7170836329460144\n",
      "\n",
      "episode 11, val func loss 0.9904543161392212\n",
      "\n",
      "episode 12, val func loss 0.7863845825195312\n",
      "\n",
      "episode 13, val func loss 0.7580271363258362\n",
      "\n",
      "episode 14, val func loss 0.052374184131622314\n",
      "\n",
      "episode 15, val func loss 1.021680235862732\n",
      "\n",
      "episode 16, val func loss 0.06861530989408493\n",
      "\n",
      "Val func train loss in epoch 0:1.1986315683461726\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.5307903289794922\n",
      "\n",
      "episode 2, val func loss 0.32126352190971375\n",
      "\n",
      "episode 3, val func loss 0.465474009513855\n",
      "\n",
      "episode 4, val func loss 0.31920841336250305\n",
      "\n",
      "episode 5, val func loss 0.15437473356723785\n",
      "\n",
      "episode 6, val func loss 0.08332374691963196\n",
      "\n",
      "episode 7, val func loss 0.2564806640148163\n",
      "\n",
      "episode 8, val func loss 0.12338976562023163\n",
      "\n",
      "episode 9, val func loss 0.2607460618019104\n",
      "\n",
      "episode 10, val func loss 0.04856530576944351\n",
      "\n",
      "episode 11, val func loss 0.15774700045585632\n",
      "\n",
      "episode 12, val func loss 0.06405646353960037\n",
      "\n",
      "episode 13, val func loss 0.10065969079732895\n",
      "\n",
      "episode 14, val func loss 0.07019177079200745\n",
      "\n",
      "episode 15, val func loss 0.1176653727889061\n",
      "\n",
      "episode 16, val func loss 0.10036460310220718\n",
      "\n",
      "Val func train loss in epoch 1:0.19839384080842137\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.11811181157827377\n",
      "\n",
      "episode 2, val func loss 0.13699711859226227\n",
      "\n",
      "episode 3, val func loss 0.1424344778060913\n",
      "\n",
      "episode 4, val func loss 0.0698712170124054\n",
      "\n",
      "episode 5, val func loss 0.09489013999700546\n",
      "\n",
      "episode 6, val func loss 0.07900813221931458\n",
      "\n",
      "episode 7, val func loss 0.12628388404846191\n",
      "\n",
      "episode 8, val func loss 0.07687179744243622\n",
      "\n",
      "episode 9, val func loss 0.11936992406845093\n",
      "\n",
      "episode 10, val func loss 0.12839102745056152\n",
      "\n",
      "episode 11, val func loss 0.11704529076814651\n",
      "\n",
      "episode 12, val func loss 0.14896954596042633\n",
      "\n",
      "episode 13, val func loss 0.12188058346509933\n",
      "\n",
      "episode 14, val func loss 0.1101086363196373\n",
      "\n",
      "episode 15, val func loss 0.05879521369934082\n",
      "\n",
      "episode 16, val func loss 0.10025003552436829\n",
      "\n",
      "Val func train loss in epoch 2:0.10932992724701762\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.16081863641738892\n",
      "\n",
      "episode 2, val func loss 0.08385851979255676\n",
      "\n",
      "episode 3, val func loss 0.10170848667621613\n",
      "\n",
      "episode 4, val func loss 0.05804644525051117\n",
      "\n",
      "episode 5, val func loss 0.04933133348822594\n",
      "\n",
      "episode 6, val func loss 0.11091459542512894\n",
      "\n",
      "episode 7, val func loss 0.06428602337837219\n",
      "\n",
      "episode 8, val func loss 0.09151832014322281\n",
      "\n",
      "episode 9, val func loss 0.08854339271783829\n",
      "\n",
      "episode 10, val func loss 0.09999940544366837\n",
      "\n",
      "episode 11, val func loss 0.1298213005065918\n",
      "\n",
      "episode 12, val func loss 0.06119036301970482\n",
      "\n",
      "episode 13, val func loss 0.11812790483236313\n",
      "\n",
      "episode 14, val func loss 0.08271368592977524\n",
      "\n",
      "episode 15, val func loss 0.13664510846138\n",
      "\n",
      "episode 16, val func loss 0.18495188653469086\n",
      "\n",
      "Val func train loss in epoch 3:0.10140471300110221\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.13086651265621185\n",
      "\n",
      "episode 2, val func loss 0.06525465101003647\n",
      "\n",
      "episode 3, val func loss 0.31454282999038696\n",
      "\n",
      "episode 4, val func loss 0.11284560710191727\n",
      "\n",
      "episode 5, val func loss 0.2667471766471863\n",
      "\n",
      "episode 6, val func loss 0.12383842468261719\n",
      "\n",
      "episode 7, val func loss 0.38823986053466797\n",
      "\n",
      "episode 8, val func loss 0.051184821873903275\n",
      "\n",
      "episode 9, val func loss 0.7984561920166016\n",
      "\n",
      "episode 10, val func loss 0.8463973999023438\n",
      "\n",
      "episode 11, val func loss 0.11688414216041565\n",
      "\n",
      "episode 12, val func loss 0.6856331825256348\n",
      "\n",
      "episode 13, val func loss 0.2961869537830353\n",
      "\n",
      "episode 14, val func loss 0.15349867939949036\n",
      "\n",
      "episode 15, val func loss 0.16057263314723969\n",
      "\n",
      "episode 16, val func loss 0.06890334188938141\n",
      "\n",
      "Val func train loss in epoch 4:0.28625327558256686\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.08775518089532852\n",
      "\n",
      "episode 2, val func loss 0.12174886465072632\n",
      "\n",
      "episode 3, val func loss 0.17673587799072266\n",
      "\n",
      "episode 4, val func loss 0.05317573994398117\n",
      "\n",
      "episode 5, val func loss 0.2856241762638092\n",
      "\n",
      "episode 6, val func loss 0.3881351351737976\n",
      "\n",
      "episode 7, val func loss 0.12387584894895554\n",
      "\n",
      "episode 8, val func loss 0.25082701444625854\n",
      "\n",
      "episode 9, val func loss 0.1960928738117218\n",
      "\n",
      "episode 10, val func loss 1.1183289289474487\n",
      "\n",
      "episode 11, val func loss 1.2264163494110107\n",
      "\n",
      "episode 12, val func loss 0.061016689985990524\n",
      "\n",
      "episode 13, val func loss 0.7132237553596497\n",
      "\n",
      "episode 14, val func loss 0.12303389608860016\n",
      "\n",
      "episode 15, val func loss 0.31688711047172546\n",
      "\n",
      "episode 16, val func loss 1.4364376068115234\n",
      "\n",
      "Val func train loss in epoch 5:0.41745719057507813\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.887550950050354\n",
      "\n",
      "episode 2, val func loss 0.1146375760436058\n",
      "\n",
      "episode 3, val func loss 0.5997797846794128\n",
      "\n",
      "episode 4, val func loss 0.10566078126430511\n",
      "\n",
      "episode 5, val func loss 0.39826148748397827\n",
      "\n",
      "episode 6, val func loss 0.09795292466878891\n",
      "\n",
      "episode 7, val func loss 0.2247772067785263\n",
      "\n",
      "episode 8, val func loss 0.31381914019584656\n",
      "\n",
      "episode 9, val func loss 0.5927456021308899\n",
      "\n",
      "episode 10, val func loss 0.08751391619443893\n",
      "\n",
      "episode 11, val func loss 0.2303897589445114\n",
      "\n",
      "episode 12, val func loss 0.03566683083772659\n",
      "\n",
      "episode 13, val func loss 0.2534325420856476\n",
      "\n",
      "episode 14, val func loss 0.2728911340236664\n",
      "\n",
      "episode 15, val func loss 0.08976919949054718\n",
      "\n",
      "episode 16, val func loss 0.19447903335094452\n",
      "\n",
      "Val func train loss in epoch 6:0.2812079917639494\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.3482399582862854\n",
      "\n",
      "episode 2, val func loss 0.14483238756656647\n",
      "\n",
      "episode 3, val func loss 0.2316131293773651\n",
      "\n",
      "episode 4, val func loss 0.2800115942955017\n",
      "\n",
      "episode 5, val func loss 1.5561403036117554\n",
      "\n",
      "episode 6, val func loss 2.2259163856506348\n",
      "\n",
      "episode 7, val func loss 0.19275601208209991\n",
      "\n",
      "episode 8, val func loss 2.397721767425537\n",
      "\n",
      "episode 9, val func loss 0.2393234372138977\n",
      "\n",
      "episode 10, val func loss 2.6596107482910156\n",
      "\n",
      "episode 11, val func loss 0.06552382558584213\n",
      "\n",
      "episode 12, val func loss 3.855320930480957\n",
      "\n",
      "episode 13, val func loss 0.26378923654556274\n",
      "\n",
      "episode 14, val func loss 1.86233389377594\n",
      "\n",
      "episode 15, val func loss 0.23478616774082184\n",
      "\n",
      "episode 16, val func loss 1.4157929420471191\n",
      "\n",
      "Val func train loss in epoch 7:1.1233570449985564\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.4146846532821655\n",
      "\n",
      "episode 2, val func loss 1.2711093425750732\n",
      "\n",
      "episode 3, val func loss 2.7223331928253174\n",
      "\n",
      "episode 4, val func loss 5.291170597076416\n",
      "\n",
      "episode 5, val func loss 8.374940872192383\n",
      "\n",
      "episode 6, val func loss 21.694747924804688\n",
      "\n",
      "episode 7, val func loss 13.801742553710938\n",
      "\n",
      "episode 8, val func loss 5.186568737030029\n",
      "\n",
      "episode 9, val func loss 11.305203437805176\n",
      "\n",
      "episode 10, val func loss 1.6494916677474976\n",
      "\n",
      "episode 11, val func loss 15.707918167114258\n",
      "\n",
      "episode 12, val func loss 0.9476267099380493\n",
      "\n",
      "episode 13, val func loss 1.7326993942260742\n",
      "\n",
      "episode 14, val func loss 6.304439544677734\n",
      "\n",
      "episode 15, val func loss 3.4152958393096924\n",
      "\n",
      "episode 16, val func loss 1.3657612800598145\n",
      "\n",
      "Val func train loss in epoch 8:6.386608369648457\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 12.19015121459961\n",
      "\n",
      "episode 2, val func loss 1.2656292915344238\n",
      "\n",
      "episode 3, val func loss 3.230905055999756\n",
      "\n",
      "episode 4, val func loss 5.649306774139404\n",
      "\n",
      "episode 5, val func loss 2.205186605453491\n",
      "\n",
      "episode 6, val func loss 0.08286049216985703\n",
      "\n",
      "episode 7, val func loss 1.9460004568099976\n",
      "\n",
      "episode 8, val func loss 5.227715492248535\n",
      "\n",
      "episode 9, val func loss 0.35543107986450195\n",
      "\n",
      "episode 10, val func loss 0.5351397395133972\n",
      "\n",
      "episode 11, val func loss 3.55859375\n",
      "\n",
      "episode 12, val func loss 12.899884223937988\n",
      "\n",
      "episode 13, val func loss 0.17511162161827087\n",
      "\n",
      "episode 14, val func loss 4.757286548614502\n",
      "\n",
      "episode 15, val func loss 6.40670108795166\n",
      "\n",
      "episode 16, val func loss 6.088013648986816\n",
      "\n",
      "Val func train loss in epoch 9:4.160869817715138\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.8237913250923157\n",
      "\n",
      "episode 2, val func loss 3.6408493518829346\n",
      "\n",
      "episode 3, val func loss 6.67042875289917\n",
      "\n",
      "episode 4, val func loss 2.0942752361297607\n",
      "\n",
      "episode 5, val func loss 0.1328846961259842\n",
      "\n",
      "episode 6, val func loss 2.92824125289917\n",
      "\n",
      "episode 7, val func loss 2.1082682609558105\n",
      "\n",
      "episode 8, val func loss 0.9911565780639648\n",
      "\n",
      "episode 9, val func loss 1.2827346324920654\n",
      "\n",
      "episode 10, val func loss 0.10144509375095367\n",
      "\n",
      "episode 11, val func loss 1.231229543685913\n",
      "\n",
      "episode 12, val func loss 1.6465411186218262\n",
      "\n",
      "episode 13, val func loss 0.44541358947753906\n",
      "\n",
      "episode 14, val func loss 0.10994797199964523\n",
      "\n",
      "episode 15, val func loss 0.590327799320221\n",
      "\n",
      "episode 16, val func loss 1.0394152402877808\n",
      "\n",
      "Val func train loss in epoch 10:1.614809402730316\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9081816077232361\n",
      "\n",
      "episode 2, val func loss 0.09472793340682983\n",
      "\n",
      "episode 3, val func loss 0.5141814947128296\n",
      "\n",
      "episode 4, val func loss 0.3683726191520691\n",
      "\n",
      "episode 5, val func loss 1.6833542585372925\n",
      "\n",
      "episode 6, val func loss 0.48671191930770874\n",
      "\n",
      "episode 7, val func loss 0.5286150574684143\n",
      "\n",
      "episode 8, val func loss 1.0463945865631104\n",
      "\n",
      "episode 9, val func loss 0.8918871879577637\n",
      "\n",
      "episode 10, val func loss 0.11770812422037125\n",
      "\n",
      "episode 11, val func loss 0.07930418848991394\n",
      "\n",
      "episode 12, val func loss 0.5427653193473816\n",
      "\n",
      "episode 13, val func loss 0.5368219017982483\n",
      "\n",
      "episode 14, val func loss 0.12399283796548843\n",
      "\n",
      "episode 15, val func loss 0.13756446540355682\n",
      "\n",
      "episode 16, val func loss 0.3693544268608093\n",
      "\n",
      "Val func train loss in epoch 11:0.526871120557189\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.4840891659259796\n",
      "\n",
      "episode 2, val func loss 0.038329947739839554\n",
      "\n",
      "episode 3, val func loss 0.2785598039627075\n",
      "\n",
      "episode 4, val func loss 0.27712342143058777\n",
      "\n",
      "episode 5, val func loss 0.11222764849662781\n",
      "\n",
      "episode 6, val func loss 0.05790046975016594\n",
      "\n",
      "episode 7, val func loss 0.07393309473991394\n",
      "\n",
      "episode 8, val func loss 0.25739872455596924\n",
      "\n",
      "episode 9, val func loss 0.1588166356086731\n",
      "\n",
      "episode 10, val func loss 0.09507125616073608\n",
      "\n",
      "episode 11, val func loss 0.20039382576942444\n",
      "\n",
      "episode 12, val func loss 0.15700042247772217\n",
      "\n",
      "episode 13, val func loss 0.03850799426436424\n",
      "\n",
      "episode 14, val func loss 0.0904342383146286\n",
      "\n",
      "episode 15, val func loss 0.1069038063287735\n",
      "\n",
      "episode 16, val func loss 0.16321958601474762\n",
      "\n",
      "Val func train loss in epoch 12:0.16186937759630382\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.10227867215871811\n",
      "\n",
      "episode 2, val func loss 0.05963117629289627\n",
      "\n",
      "episode 3, val func loss 0.11690166592597961\n",
      "\n",
      "episode 4, val func loss 0.21895158290863037\n",
      "\n",
      "episode 5, val func loss 0.06383951008319855\n",
      "\n",
      "episode 6, val func loss 0.0981532484292984\n",
      "\n",
      "episode 7, val func loss 0.08830922842025757\n",
      "\n",
      "episode 8, val func loss 0.07450743764638901\n",
      "\n",
      "episode 9, val func loss 0.11902618408203125\n",
      "\n",
      "episode 10, val func loss 0.07682380080223083\n",
      "\n",
      "episode 11, val func loss 0.1534968614578247\n",
      "\n",
      "episode 12, val func loss 0.0877726823091507\n",
      "\n",
      "episode 13, val func loss 0.08588401228189468\n",
      "\n",
      "episode 14, val func loss 0.15106968581676483\n",
      "\n",
      "episode 15, val func loss 0.14717714488506317\n",
      "\n",
      "episode 16, val func loss 0.09302699565887451\n",
      "\n",
      "Val func train loss in epoch 13:0.10855311807245016\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.11481920629739761\n",
      "\n",
      "episode 2, val func loss 0.04350380226969719\n",
      "\n",
      "episode 3, val func loss 0.09978588670492172\n",
      "\n",
      "episode 4, val func loss 0.037352971732616425\n",
      "\n",
      "episode 5, val func loss 0.08660826086997986\n",
      "\n",
      "episode 6, val func loss 0.09589525312185287\n",
      "\n",
      "episode 7, val func loss 0.08263330161571503\n",
      "\n",
      "episode 8, val func loss 0.10439437627792358\n",
      "\n",
      "episode 9, val func loss 0.1300094723701477\n",
      "\n",
      "episode 10, val func loss 0.11452794075012207\n",
      "\n",
      "episode 11, val func loss 0.12015402317047119\n",
      "\n",
      "episode 12, val func loss 0.052386652678251266\n",
      "\n",
      "episode 13, val func loss 0.1119409054517746\n",
      "\n",
      "episode 14, val func loss 0.09072189778089523\n",
      "\n",
      "episode 15, val func loss 0.09599322080612183\n",
      "\n",
      "episode 16, val func loss 0.03615653142333031\n",
      "\n",
      "Val func train loss in epoch 14:0.08855523145757616\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.06759408861398697\n",
      "\n",
      "episode 2, val func loss 0.03982122242450714\n",
      "\n",
      "episode 3, val func loss 0.10618545860052109\n",
      "\n",
      "episode 4, val func loss 0.10417577624320984\n",
      "\n",
      "episode 5, val func loss 0.049803536385297775\n",
      "\n",
      "episode 6, val func loss 0.07640790939331055\n",
      "\n",
      "episode 7, val func loss 0.06169379502534866\n",
      "\n",
      "episode 8, val func loss 0.05476615950465202\n",
      "\n",
      "episode 9, val func loss 0.12006825953722\n",
      "\n",
      "episode 10, val func loss 0.06788603961467743\n",
      "\n",
      "episode 11, val func loss 0.08448726683855057\n",
      "\n",
      "episode 12, val func loss 0.0659916028380394\n",
      "\n",
      "episode 13, val func loss 0.07280036062002182\n",
      "\n",
      "episode 14, val func loss 0.059295713901519775\n",
      "\n",
      "episode 15, val func loss 0.10901986062526703\n",
      "\n",
      "episode 16, val func loss 0.04339377582073212\n",
      "\n",
      "Val func train loss in epoch 15:0.07396192662417889\n",
      "***********************TIME WAS 5.28435298204422 min*****************************\n",
      "\n",
      "**********************ROUND 2 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.09769994020462036\n",
      "\n",
      "episode 2, policy loss -0.08836023509502411\n",
      "\n",
      "episode 3, policy loss -0.06666995584964752\n",
      "\n",
      "episode 4, policy loss -0.0603366456925869\n",
      "\n",
      "episode 5, policy loss -0.08445421606302261\n",
      "\n",
      "episode 6, policy loss -0.07451669126749039\n",
      "\n",
      "episode 7, policy loss -0.05195675790309906\n",
      "\n",
      "episode 8, policy loss -0.06366151571273804\n",
      "\n",
      "episode 9, policy loss -0.06393218040466309\n",
      "\n",
      "episode 10, policy loss -0.05706644430756569\n",
      "\n",
      "episode 11, policy loss -0.06149055063724518\n",
      "\n",
      "episode 12, policy loss -0.0871221274137497\n",
      "\n",
      "episode 13, policy loss -0.07082860916852951\n",
      "\n",
      "episode 14, policy loss -0.06224452331662178\n",
      "\n",
      "episode 15, policy loss -0.0930294319987297\n",
      "\n",
      "episode 16, policy loss -0.07300736755132675\n",
      "\n",
      "Policy train loss in epoch 0:-0.07227357453666627\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.06955242156982422\n",
      "\n",
      "episode 2, policy loss -0.06810081005096436\n",
      "\n",
      "episode 3, policy loss -0.05849436670541763\n",
      "\n",
      "episode 4, policy loss -0.09690378606319427\n",
      "\n",
      "episode 5, policy loss -0.06829136610031128\n",
      "\n",
      "episode 6, policy loss -0.054452504962682724\n",
      "\n",
      "episode 7, policy loss -0.06503432244062424\n",
      "\n",
      "episode 8, policy loss -0.08766493201255798\n",
      "\n",
      "episode 9, policy loss -0.07339054346084595\n",
      "\n",
      "episode 10, policy loss -0.07885593920946121\n",
      "\n",
      "episode 11, policy loss -0.07124051451683044\n",
      "\n",
      "episode 12, policy loss -0.0760616883635521\n",
      "\n",
      "episode 13, policy loss -0.06687368452548981\n",
      "\n",
      "episode 14, policy loss -0.08717160671949387\n",
      "\n",
      "episode 15, policy loss -0.09290877729654312\n",
      "\n",
      "episode 16, policy loss -0.09631309658288956\n",
      "\n",
      "Policy train loss in epoch 1:-0.07570689753629267\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.09123441576957703\n",
      "\n",
      "episode 2, policy loss -0.09382633864879608\n",
      "\n",
      "episode 3, policy loss -0.0883517861366272\n",
      "\n",
      "episode 4, policy loss -0.06130947917699814\n",
      "\n",
      "episode 5, policy loss -0.0641404539346695\n",
      "\n",
      "episode 6, policy loss -0.07621784508228302\n",
      "\n",
      "episode 7, policy loss -0.07097373902797699\n",
      "\n",
      "episode 8, policy loss -0.06757313013076782\n",
      "\n",
      "episode 9, policy loss -0.07472474128007889\n",
      "\n",
      "episode 10, policy loss -0.07208013534545898\n",
      "\n",
      "episode 11, policy loss -0.06706969439983368\n",
      "\n",
      "episode 12, policy loss -0.06916557252407074\n",
      "\n",
      "episode 13, policy loss -0.077552430331707\n",
      "\n",
      "episode 14, policy loss -0.101765938103199\n",
      "\n",
      "episode 15, policy loss -0.05913308635354042\n",
      "\n",
      "episode 16, policy loss -0.09639222174882889\n",
      "\n",
      "Policy train loss in epoch 2:-0.07696943799965084\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.07136066257953644\n",
      "\n",
      "episode 2, policy loss -0.09162415564060211\n",
      "\n",
      "episode 3, policy loss -0.07014559209346771\n",
      "\n",
      "episode 4, policy loss -0.10042808949947357\n",
      "\n",
      "episode 5, policy loss -0.08867288380861282\n",
      "\n",
      "episode 6, policy loss -0.07894021272659302\n",
      "\n",
      "episode 7, policy loss -0.06936316192150116\n",
      "\n",
      "episode 8, policy loss -0.09522474557161331\n",
      "\n",
      "episode 9, policy loss -0.0665653645992279\n",
      "\n",
      "episode 10, policy loss -0.09284355491399765\n",
      "\n",
      "episode 11, policy loss -0.07998736202716827\n",
      "\n",
      "episode 12, policy loss -0.07480932027101517\n",
      "\n",
      "episode 13, policy loss -0.07728566974401474\n",
      "\n",
      "episode 14, policy loss -0.06890134513378143\n",
      "\n",
      "episode 15, policy loss -0.06441356241703033\n",
      "\n",
      "episode 16, policy loss -0.06021680310368538\n",
      "\n",
      "Policy train loss in epoch 3:-0.07817390537820756\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.03746749833226204\n",
      "\n",
      "episode 2, val func loss 0.04128032922744751\n",
      "\n",
      "episode 3, val func loss 0.049505721777677536\n",
      "\n",
      "episode 4, val func loss 0.059450745582580566\n",
      "\n",
      "episode 5, val func loss 0.09225192666053772\n",
      "\n",
      "episode 6, val func loss 0.03808332979679108\n",
      "\n",
      "episode 7, val func loss 0.09507886320352554\n",
      "\n",
      "episode 8, val func loss 0.05936335772275925\n",
      "\n",
      "episode 9, val func loss 0.1000993400812149\n",
      "\n",
      "episode 10, val func loss 0.10995975881814957\n",
      "\n",
      "episode 11, val func loss 0.1083901897072792\n",
      "\n",
      "episode 12, val func loss 0.037435952574014664\n",
      "\n",
      "episode 13, val func loss 0.03925975784659386\n",
      "\n",
      "episode 14, val func loss 0.03603382408618927\n",
      "\n",
      "episode 15, val func loss 0.05958320200443268\n",
      "\n",
      "episode 16, val func loss 0.0256661344319582\n",
      "\n",
      "Val func train loss in epoch 0:0.06180687074083835\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.15064097940921783\n",
      "\n",
      "episode 2, val func loss 0.09581110626459122\n",
      "\n",
      "episode 3, val func loss 0.1420907825231552\n",
      "\n",
      "episode 4, val func loss 0.11784476786851883\n",
      "\n",
      "episode 5, val func loss 0.07417823374271393\n",
      "\n",
      "episode 6, val func loss 0.043895017355680466\n",
      "\n",
      "episode 7, val func loss 0.03366000950336456\n",
      "\n",
      "episode 8, val func loss 0.08439049124717712\n",
      "\n",
      "episode 9, val func loss 0.033131666481494904\n",
      "\n",
      "episode 10, val func loss 0.09611857682466507\n",
      "\n",
      "episode 11, val func loss 0.046202484518289566\n",
      "\n",
      "episode 12, val func loss 0.0640735775232315\n",
      "\n",
      "episode 13, val func loss 0.06329452991485596\n",
      "\n",
      "episode 14, val func loss 0.03820653632283211\n",
      "\n",
      "episode 15, val func loss 0.07821008563041687\n",
      "\n",
      "episode 16, val func loss 0.06071676313877106\n",
      "\n",
      "Val func train loss in epoch 1:0.07640410051681101\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.05196808651089668\n",
      "\n",
      "episode 2, val func loss 0.04286642372608185\n",
      "\n",
      "episode 3, val func loss 0.05121200159192085\n",
      "\n",
      "episode 4, val func loss 0.10266206413507462\n",
      "\n",
      "episode 5, val func loss 0.0214921236038208\n",
      "\n",
      "episode 6, val func loss 0.054817646741867065\n",
      "\n",
      "episode 7, val func loss 0.037957560271024704\n",
      "\n",
      "episode 8, val func loss 0.04437994956970215\n",
      "\n",
      "episode 9, val func loss 0.03900746628642082\n",
      "\n",
      "episode 10, val func loss 0.06915853172540665\n",
      "\n",
      "episode 11, val func loss 0.09551894664764404\n",
      "\n",
      "episode 12, val func loss 0.05325772613286972\n",
      "\n",
      "episode 13, val func loss 0.041069358587265015\n",
      "\n",
      "episode 14, val func loss 0.024923335760831833\n",
      "\n",
      "episode 15, val func loss 0.09433950483798981\n",
      "\n",
      "episode 16, val func loss 0.0975966602563858\n",
      "\n",
      "Val func train loss in epoch 2:0.05763921164907515\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.04849732667207718\n",
      "\n",
      "episode 2, val func loss 0.057571861892938614\n",
      "\n",
      "episode 3, val func loss 0.021840546280145645\n",
      "\n",
      "episode 4, val func loss 0.04670996218919754\n",
      "\n",
      "episode 5, val func loss 0.046355560421943665\n",
      "\n",
      "episode 6, val func loss 0.09766092896461487\n",
      "\n",
      "episode 7, val func loss 0.051129329949617386\n",
      "\n",
      "episode 8, val func loss 0.10470660775899887\n",
      "\n",
      "episode 9, val func loss 0.08598796278238297\n",
      "\n",
      "episode 10, val func loss 0.12996716797351837\n",
      "\n",
      "episode 11, val func loss 0.07278386503458023\n",
      "\n",
      "episode 12, val func loss 0.08775429427623749\n",
      "\n",
      "episode 13, val func loss 0.05845668166875839\n",
      "\n",
      "episode 14, val func loss 0.11585511267185211\n",
      "\n",
      "episode 15, val func loss 0.08280124515295029\n",
      "\n",
      "episode 16, val func loss 0.17828258872032166\n",
      "\n",
      "Val func train loss in epoch 3:0.08039756515063345\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.03210626170039177\n",
      "\n",
      "episode 2, val func loss 0.1298580914735794\n",
      "\n",
      "episode 3, val func loss 0.08161123096942902\n",
      "\n",
      "episode 4, val func loss 0.08717323839664459\n",
      "\n",
      "episode 5, val func loss 0.05956492945551872\n",
      "\n",
      "episode 6, val func loss 0.17046856880187988\n",
      "\n",
      "episode 7, val func loss 0.12215881794691086\n",
      "\n",
      "episode 8, val func loss 0.04553980007767677\n",
      "\n",
      "episode 9, val func loss 0.062296755611896515\n",
      "\n",
      "episode 10, val func loss 0.029048820957541466\n",
      "\n",
      "episode 11, val func loss 0.047931771725416183\n",
      "\n",
      "episode 12, val func loss 0.04064610227942467\n",
      "\n",
      "episode 13, val func loss 0.03664189949631691\n",
      "\n",
      "episode 14, val func loss 0.0826888233423233\n",
      "\n",
      "episode 15, val func loss 0.1088901236653328\n",
      "\n",
      "episode 16, val func loss 0.048313770443201065\n",
      "\n",
      "Val func train loss in epoch 4:0.07405868789646775\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.043251097202301025\n",
      "\n",
      "episode 2, val func loss 0.06498081237077713\n",
      "\n",
      "episode 3, val func loss 0.09043963253498077\n",
      "\n",
      "episode 4, val func loss 0.02997790277004242\n",
      "\n",
      "episode 5, val func loss 0.03974834829568863\n",
      "\n",
      "episode 6, val func loss 0.025885993614792824\n",
      "\n",
      "episode 7, val func loss 0.04053378477692604\n",
      "\n",
      "episode 8, val func loss 0.06001419201493263\n",
      "\n",
      "episode 9, val func loss 0.10907270759344101\n",
      "\n",
      "episode 10, val func loss 0.05460398644208908\n",
      "\n",
      "episode 11, val func loss 0.06135892868041992\n",
      "\n",
      "episode 12, val func loss 0.037774547934532166\n",
      "\n",
      "episode 13, val func loss 0.05704336240887642\n",
      "\n",
      "episode 14, val func loss 0.14543023705482483\n",
      "\n",
      "episode 15, val func loss 0.22796602547168732\n",
      "\n",
      "episode 16, val func loss 0.18078894913196564\n",
      "\n",
      "Val func train loss in epoch 5:0.07930440676864237\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.0688337087631226\n",
      "\n",
      "episode 2, val func loss 1.2263368368148804\n",
      "\n",
      "episode 3, val func loss 0.2177094668149948\n",
      "\n",
      "episode 4, val func loss 0.2800845205783844\n",
      "\n",
      "episode 5, val func loss 0.2924540340900421\n",
      "\n",
      "episode 6, val func loss 0.170443594455719\n",
      "\n",
      "episode 7, val func loss 0.5100528001785278\n",
      "\n",
      "episode 8, val func loss 0.15617434680461884\n",
      "\n",
      "episode 9, val func loss 1.1486576795578003\n",
      "\n",
      "episode 10, val func loss 0.7200108766555786\n",
      "\n",
      "episode 11, val func loss 1.3945456743240356\n",
      "\n",
      "episode 12, val func loss 0.8895032405853271\n",
      "\n",
      "episode 13, val func loss 0.6623077392578125\n",
      "\n",
      "episode 14, val func loss 1.731418490409851\n",
      "\n",
      "episode 15, val func loss 1.607741355895996\n",
      "\n",
      "episode 16, val func loss 0.08565928041934967\n",
      "\n",
      "Val func train loss in epoch 6:0.7601208528503776\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 2.7105307579040527\n",
      "\n",
      "episode 2, val func loss 0.026918714866042137\n",
      "\n",
      "episode 3, val func loss 1.1076527833938599\n",
      "\n",
      "episode 4, val func loss 4.493293285369873\n",
      "\n",
      "episode 5, val func loss 1.309935212135315\n",
      "\n",
      "episode 6, val func loss 25.681699752807617\n",
      "\n",
      "episode 7, val func loss 0.48862507939338684\n",
      "\n",
      "episode 8, val func loss 15.966737747192383\n",
      "\n",
      "episode 9, val func loss 8.530623435974121\n",
      "\n",
      "episode 10, val func loss 0.21321210265159607\n",
      "\n",
      "episode 11, val func loss 3.861435890197754\n",
      "\n",
      "episode 12, val func loss 1.9429011344909668\n",
      "\n",
      "episode 13, val func loss 1.5483787059783936\n",
      "\n",
      "episode 14, val func loss 2.217710018157959\n",
      "\n",
      "episode 15, val func loss 0.18257278203964233\n",
      "\n",
      "episode 16, val func loss 2.164417028427124\n",
      "\n",
      "Val func train loss in epoch 7:4.527915276936255\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 3.6804940700531006\n",
      "\n",
      "episode 2, val func loss 1.1501774787902832\n",
      "\n",
      "episode 3, val func loss 1.5961592197418213\n",
      "\n",
      "episode 4, val func loss 2.8356423377990723\n",
      "\n",
      "episode 5, val func loss 2.0143377780914307\n",
      "\n",
      "episode 6, val func loss 0.03968026489019394\n",
      "\n",
      "episode 7, val func loss 0.688084602355957\n",
      "\n",
      "episode 8, val func loss 1.3850816488265991\n",
      "\n",
      "episode 9, val func loss 2.8679237365722656\n",
      "\n",
      "episode 10, val func loss 2.437330484390259\n",
      "\n",
      "episode 11, val func loss 0.13549228012561798\n",
      "\n",
      "episode 12, val func loss 3.714144468307495\n",
      "\n",
      "episode 13, val func loss 0.9991283416748047\n",
      "\n",
      "episode 14, val func loss 0.4927797317504883\n",
      "\n",
      "episode 15, val func loss 0.0558786503970623\n",
      "\n",
      "episode 16, val func loss 0.17765913903713226\n",
      "\n",
      "Val func train loss in epoch 8:1.516874639550224\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.5729348063468933\n",
      "\n",
      "episode 2, val func loss 0.4472011923789978\n",
      "\n",
      "episode 3, val func loss 0.04511803761124611\n",
      "\n",
      "episode 4, val func loss 0.172390878200531\n",
      "\n",
      "episode 5, val func loss 0.17249958217144012\n",
      "\n",
      "episode 6, val func loss 0.18212063610553741\n",
      "\n",
      "episode 7, val func loss 0.5065187811851501\n",
      "\n",
      "episode 8, val func loss 0.09398526698350906\n",
      "\n",
      "episode 9, val func loss 0.10283190757036209\n",
      "\n",
      "episode 10, val func loss 0.4876001179218292\n",
      "\n",
      "episode 11, val func loss 0.2950668931007385\n",
      "\n",
      "episode 12, val func loss 0.1569768190383911\n",
      "\n",
      "episode 13, val func loss 0.06282047927379608\n",
      "\n",
      "episode 14, val func loss 0.06427253037691116\n",
      "\n",
      "episode 15, val func loss 0.19063250720500946\n",
      "\n",
      "episode 16, val func loss 0.18231989443302155\n",
      "\n",
      "Val func train loss in epoch 9:0.23345564561896026\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.035651665180921555\n",
      "\n",
      "episode 2, val func loss 0.0732683390378952\n",
      "\n",
      "episode 3, val func loss 0.12715978920459747\n",
      "\n",
      "episode 4, val func loss 0.06551004946231842\n",
      "\n",
      "episode 5, val func loss 0.03596794232726097\n",
      "\n",
      "episode 6, val func loss 0.09004203230142593\n",
      "\n",
      "episode 7, val func loss 0.06989075988531113\n",
      "\n",
      "episode 8, val func loss 0.11465413868427277\n",
      "\n",
      "episode 9, val func loss 0.013942073099315166\n",
      "\n",
      "episode 10, val func loss 0.07261549681425095\n",
      "\n",
      "episode 11, val func loss 0.10883396863937378\n",
      "\n",
      "episode 12, val func loss 0.06876491755247116\n",
      "\n",
      "episode 13, val func loss 0.08025883883237839\n",
      "\n",
      "episode 14, val func loss 0.13563485443592072\n",
      "\n",
      "episode 15, val func loss 0.03904403746128082\n",
      "\n",
      "episode 16, val func loss 0.04031083360314369\n",
      "\n",
      "Val func train loss in epoch 10:0.07322185853263363\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.01406520139425993\n",
      "\n",
      "episode 2, val func loss 0.047071702778339386\n",
      "\n",
      "episode 3, val func loss 0.1214703693985939\n",
      "\n",
      "episode 4, val func loss 0.0811266154050827\n",
      "\n",
      "episode 5, val func loss 0.061463356018066406\n",
      "\n",
      "episode 6, val func loss 0.10962670296430588\n",
      "\n",
      "episode 7, val func loss 0.0277883131057024\n",
      "\n",
      "episode 8, val func loss 0.039242468774318695\n",
      "\n",
      "episode 9, val func loss 0.08133890479803085\n",
      "\n",
      "episode 10, val func loss 0.07022556662559509\n",
      "\n",
      "episode 11, val func loss 0.04413514584302902\n",
      "\n",
      "episode 12, val func loss 0.07671873271465302\n",
      "\n",
      "episode 13, val func loss 0.11459837853908539\n",
      "\n",
      "episode 14, val func loss 0.03189576789736748\n",
      "\n",
      "episode 15, val func loss 0.049148041754961014\n",
      "\n",
      "episode 16, val func loss 0.13856647908687592\n",
      "\n",
      "Val func train loss in epoch 11:0.06928010919364169\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.04191930964589119\n",
      "\n",
      "episode 2, val func loss 0.058558445423841476\n",
      "\n",
      "episode 3, val func loss 0.10330193489789963\n",
      "\n",
      "episode 4, val func loss 0.027918623760342598\n",
      "\n",
      "episode 5, val func loss 0.0530528724193573\n",
      "\n",
      "episode 6, val func loss 0.03644731640815735\n",
      "\n",
      "episode 7, val func loss 0.0481368713080883\n",
      "\n",
      "episode 8, val func loss 0.03786923363804817\n",
      "\n",
      "episode 9, val func loss 0.039743006229400635\n",
      "\n",
      "episode 10, val func loss 0.08006591349840164\n",
      "\n",
      "episode 11, val func loss 0.0774340108036995\n",
      "\n",
      "episode 12, val func loss 0.04111380875110626\n",
      "\n",
      "episode 13, val func loss 0.01458518672734499\n",
      "\n",
      "episode 14, val func loss 0.04550226032733917\n",
      "\n",
      "episode 15, val func loss 0.048345670104026794\n",
      "\n",
      "episode 16, val func loss 0.08092232793569565\n",
      "\n",
      "Val func train loss in epoch 12:0.05218229949241504\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.0310773104429245\n",
      "\n",
      "episode 2, val func loss 0.03451325744390488\n",
      "\n",
      "episode 3, val func loss 0.03821202740073204\n",
      "\n",
      "episode 4, val func loss 0.05041366070508957\n",
      "\n",
      "episode 5, val func loss 0.07858511060476303\n",
      "\n",
      "episode 6, val func loss 0.028935125097632408\n",
      "\n",
      "episode 7, val func loss 0.05356956645846367\n",
      "\n",
      "episode 8, val func loss 0.01921645551919937\n",
      "\n",
      "episode 9, val func loss 0.0392116978764534\n",
      "\n",
      "episode 10, val func loss 0.08073307573795319\n",
      "\n",
      "episode 11, val func loss 0.04910427704453468\n",
      "\n",
      "episode 12, val func loss 0.03704053908586502\n",
      "\n",
      "episode 13, val func loss 0.08562954515218735\n",
      "\n",
      "episode 14, val func loss 0.046529605984687805\n",
      "\n",
      "episode 15, val func loss 0.09257226437330246\n",
      "\n",
      "episode 16, val func loss 0.04213173687458038\n",
      "\n",
      "Val func train loss in epoch 13:0.05046720348764211\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.019218841567635536\n",
      "\n",
      "episode 2, val func loss 0.09377232939004898\n",
      "\n",
      "episode 3, val func loss 0.04779581353068352\n",
      "\n",
      "episode 4, val func loss 0.034389134496450424\n",
      "\n",
      "episode 5, val func loss 0.03942341357469559\n",
      "\n",
      "episode 6, val func loss 0.049164626747369766\n",
      "\n",
      "episode 7, val func loss 0.0759899839758873\n",
      "\n",
      "episode 8, val func loss 0.054643455892801285\n",
      "\n",
      "episode 9, val func loss 0.04701691120862961\n",
      "\n",
      "episode 10, val func loss 0.041819099336862564\n",
      "\n",
      "episode 11, val func loss 0.08828321099281311\n",
      "\n",
      "episode 12, val func loss 0.05457373335957527\n",
      "\n",
      "episode 13, val func loss 0.03392600640654564\n",
      "\n",
      "episode 14, val func loss 0.037851665169000626\n",
      "\n",
      "episode 15, val func loss 0.028618618845939636\n",
      "\n",
      "episode 16, val func loss 0.07062865793704987\n",
      "\n",
      "Val func train loss in epoch 14:0.051069718901999295\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.01735665462911129\n",
      "\n",
      "episode 2, val func loss 0.03306964039802551\n",
      "\n",
      "episode 3, val func loss 0.07870549708604813\n",
      "\n",
      "episode 4, val func loss 0.09117944538593292\n",
      "\n",
      "episode 5, val func loss 0.04550648480653763\n",
      "\n",
      "episode 6, val func loss 0.03536875545978546\n",
      "\n",
      "episode 7, val func loss 0.06690488755702972\n",
      "\n",
      "episode 8, val func loss 0.07251293212175369\n",
      "\n",
      "episode 9, val func loss 0.10958321392536163\n",
      "\n",
      "episode 10, val func loss 0.05002053081989288\n",
      "\n",
      "episode 11, val func loss 0.05929279327392578\n",
      "\n",
      "episode 12, val func loss 0.06868688762187958\n",
      "\n",
      "episode 13, val func loss 0.04140046611428261\n",
      "\n",
      "episode 14, val func loss 0.051025211811065674\n",
      "\n",
      "episode 15, val func loss 0.06771645694971085\n",
      "\n",
      "episode 16, val func loss 0.06605718284845352\n",
      "\n",
      "Val func train loss in epoch 15:0.059649190050549805\n",
      "***********************TIME WAS 5.15683974424998 min*****************************\n",
      "\n",
      "**********************ROUND 3 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.16785740852355957\n",
      "\n",
      "episode 2, policy loss -0.20262828469276428\n",
      "\n",
      "episode 3, policy loss -0.21050159633159637\n",
      "\n",
      "episode 4, policy loss -0.18135367333889008\n",
      "\n",
      "episode 5, policy loss -0.14713937044143677\n",
      "\n",
      "episode 6, policy loss -0.19947916269302368\n",
      "\n",
      "episode 7, policy loss -0.17376211285591125\n",
      "\n",
      "episode 8, policy loss -0.10825152695178986\n",
      "\n",
      "episode 9, policy loss -0.14861102402210236\n",
      "\n",
      "episode 10, policy loss -0.16673758625984192\n",
      "\n",
      "episode 11, policy loss -0.19370174407958984\n",
      "\n",
      "episode 12, policy loss -0.16258040070533752\n",
      "\n",
      "episode 13, policy loss -0.15512754023075104\n",
      "\n",
      "episode 14, policy loss -0.1648811250925064\n",
      "\n",
      "episode 15, policy loss -0.1393398940563202\n",
      "\n",
      "episode 16, policy loss -0.14318569004535675\n",
      "\n",
      "Policy train loss in epoch 0:-0.16657113377004862\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.14849784970283508\n",
      "\n",
      "episode 2, policy loss -0.19897566735744476\n",
      "\n",
      "episode 3, policy loss -0.16306430101394653\n",
      "\n",
      "episode 4, policy loss -0.14411360025405884\n",
      "\n",
      "episode 5, policy loss -0.10949519276618958\n",
      "\n",
      "episode 6, policy loss -0.16555440425872803\n",
      "\n",
      "episode 7, policy loss -0.1660444438457489\n",
      "\n",
      "episode 8, policy loss -0.13999207317829132\n",
      "\n",
      "episode 9, policy loss -0.15141619741916656\n",
      "\n",
      "episode 10, policy loss -0.16040495038032532\n",
      "\n",
      "episode 11, policy loss -0.20050066709518433\n",
      "\n",
      "episode 12, policy loss -0.16175223886966705\n",
      "\n",
      "episode 13, policy loss -0.17228563129901886\n",
      "\n",
      "episode 14, policy loss -0.1964980661869049\n",
      "\n",
      "episode 15, policy loss -0.20620757341384888\n",
      "\n",
      "episode 16, policy loss -0.18007569015026093\n",
      "\n",
      "Policy train loss in epoch 1:-0.16655490919947624\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.1511426419019699\n",
      "\n",
      "episode 2, policy loss -0.14874860644340515\n",
      "\n",
      "episode 3, policy loss -0.16094139218330383\n",
      "\n",
      "episode 4, policy loss -0.16751369833946228\n",
      "\n",
      "episode 5, policy loss -0.19779503345489502\n",
      "\n",
      "episode 6, policy loss -0.19915157556533813\n",
      "\n",
      "episode 7, policy loss -0.17072030901908875\n",
      "\n",
      "episode 8, policy loss -0.17705637216567993\n",
      "\n",
      "episode 9, policy loss -0.17563396692276\n",
      "\n",
      "episode 10, policy loss -0.1396224945783615\n",
      "\n",
      "episode 11, policy loss -0.13945841789245605\n",
      "\n",
      "episode 12, policy loss -0.1661723107099533\n",
      "\n",
      "episode 13, policy loss -0.16957104206085205\n",
      "\n",
      "episode 14, policy loss -0.20680734515190125\n",
      "\n",
      "episode 15, policy loss -0.11015023291110992\n",
      "\n",
      "episode 16, policy loss -0.2029171586036682\n",
      "\n",
      "Policy train loss in epoch 2:-0.16771266236901283\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.10963279753923416\n",
      "\n",
      "episode 2, policy loss -0.13947375118732452\n",
      "\n",
      "episode 3, policy loss -0.2009003460407257\n",
      "\n",
      "episode 4, policy loss -0.15170720219612122\n",
      "\n",
      "episode 5, policy loss -0.19794723391532898\n",
      "\n",
      "episode 6, policy loss -0.16632407903671265\n",
      "\n",
      "episode 7, policy loss -0.17893517017364502\n",
      "\n",
      "episode 8, policy loss -0.20998728275299072\n",
      "\n",
      "episode 9, policy loss -0.17029374837875366\n",
      "\n",
      "episode 10, policy loss -0.146048441529274\n",
      "\n",
      "episode 11, policy loss -0.194015234708786\n",
      "\n",
      "episode 12, policy loss -0.1396770179271698\n",
      "\n",
      "episode 13, policy loss -0.16184887290000916\n",
      "\n",
      "episode 14, policy loss -0.1670738160610199\n",
      "\n",
      "episode 15, policy loss -0.1693934202194214\n",
      "\n",
      "episode 16, policy loss -0.16356824338436127\n",
      "\n",
      "Policy train loss in epoch 3:-0.16667666612192988\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.08687017112970352\n",
      "\n",
      "episode 2, val func loss 0.1546575278043747\n",
      "\n",
      "episode 3, val func loss 0.058584410697221756\n",
      "\n",
      "episode 4, val func loss 0.348052978515625\n",
      "\n",
      "episode 5, val func loss 0.315356969833374\n",
      "\n",
      "episode 6, val func loss 0.19668738543987274\n",
      "\n",
      "episode 7, val func loss 0.09082184731960297\n",
      "\n",
      "episode 8, val func loss 0.1667056679725647\n",
      "\n",
      "episode 9, val func loss 0.24171113967895508\n",
      "\n",
      "episode 10, val func loss 0.0705757737159729\n",
      "\n",
      "episode 11, val func loss 0.3302226662635803\n",
      "\n",
      "episode 12, val func loss 0.044885486364364624\n",
      "\n",
      "episode 13, val func loss 0.2835228443145752\n",
      "\n",
      "episode 14, val func loss 0.04945899173617363\n",
      "\n",
      "episode 15, val func loss 0.06387890875339508\n",
      "\n",
      "episode 16, val func loss 0.0890996977686882\n",
      "\n",
      "Val func train loss in epoch 0:0.16194327920675278\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.058995164930820465\n",
      "\n",
      "episode 2, val func loss 0.06668892502784729\n",
      "\n",
      "episode 3, val func loss 0.06390958279371262\n",
      "\n",
      "episode 4, val func loss 0.05298774316906929\n",
      "\n",
      "episode 5, val func loss 0.050370052456855774\n",
      "\n",
      "episode 6, val func loss 0.08627209812402725\n",
      "\n",
      "episode 7, val func loss 0.06358478218317032\n",
      "\n",
      "episode 8, val func loss 0.04996195808053017\n",
      "\n",
      "episode 9, val func loss 0.07524549216032028\n",
      "\n",
      "episode 10, val func loss 0.040205392986536026\n",
      "\n",
      "episode 11, val func loss 0.13206955790519714\n",
      "\n",
      "episode 12, val func loss 0.07297108322381973\n",
      "\n",
      "episode 13, val func loss 0.25657951831817627\n",
      "\n",
      "episode 14, val func loss 0.20477575063705444\n",
      "\n",
      "episode 15, val func loss 0.03330367058515549\n",
      "\n",
      "episode 16, val func loss 0.05662699043750763\n",
      "\n",
      "Val func train loss in epoch 1:0.08528423518873751\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.043934889137744904\n",
      "\n",
      "episode 2, val func loss 0.08246159553527832\n",
      "\n",
      "episode 3, val func loss 0.11657322198152542\n",
      "\n",
      "episode 4, val func loss 0.1345701515674591\n",
      "\n",
      "episode 5, val func loss 0.15497593581676483\n",
      "\n",
      "episode 6, val func loss 0.09591034054756165\n",
      "\n",
      "episode 7, val func loss 0.4671185612678528\n",
      "\n",
      "episode 8, val func loss 0.12295225262641907\n",
      "\n",
      "episode 9, val func loss 0.3484899401664734\n",
      "\n",
      "episode 10, val func loss 0.16177809238433838\n",
      "\n",
      "episode 11, val func loss 0.1996634602546692\n",
      "\n",
      "episode 12, val func loss 0.01660027727484703\n",
      "\n",
      "episode 13, val func loss 0.09726613014936447\n",
      "\n",
      "episode 14, val func loss 0.043981630355119705\n",
      "\n",
      "episode 15, val func loss 0.06747075170278549\n",
      "\n",
      "episode 16, val func loss 0.06899967044591904\n",
      "\n",
      "Val func train loss in epoch 2:0.13892168132588267\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.0738230049610138\n",
      "\n",
      "episode 2, val func loss 0.04532038792967796\n",
      "\n",
      "episode 3, val func loss 0.08686234802007675\n",
      "\n",
      "episode 4, val func loss 0.06684959679841995\n",
      "\n",
      "episode 5, val func loss 0.08146754652261734\n",
      "\n",
      "episode 6, val func loss 0.07271256297826767\n",
      "\n",
      "episode 7, val func loss 0.11050031334161758\n",
      "\n",
      "episode 8, val func loss 0.010167866945266724\n",
      "\n",
      "episode 9, val func loss 0.11997503787279129\n",
      "\n",
      "episode 10, val func loss 0.15028829872608185\n",
      "\n",
      "episode 11, val func loss 0.16647225618362427\n",
      "\n",
      "episode 12, val func loss 0.33940792083740234\n",
      "\n",
      "episode 13, val func loss 0.04814992845058441\n",
      "\n",
      "episode 14, val func loss 0.14611858129501343\n",
      "\n",
      "episode 15, val func loss 0.279403418302536\n",
      "\n",
      "episode 16, val func loss 0.23939615488052368\n",
      "\n",
      "Val func train loss in epoch 3:0.1273072015028447\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.07602209597826004\n",
      "\n",
      "episode 2, val func loss 0.05562795698642731\n",
      "\n",
      "episode 3, val func loss 0.11460389196872711\n",
      "\n",
      "episode 4, val func loss 0.0561806857585907\n",
      "\n",
      "episode 5, val func loss 0.2457294911146164\n",
      "\n",
      "episode 6, val func loss 0.11498420685529709\n",
      "\n",
      "episode 7, val func loss 0.16959348320960999\n",
      "\n",
      "episode 8, val func loss 0.15692657232284546\n",
      "\n",
      "episode 9, val func loss 0.17975223064422607\n",
      "\n",
      "episode 10, val func loss 0.642604649066925\n",
      "\n",
      "episode 11, val func loss 0.006477707996964455\n",
      "\n",
      "episode 12, val func loss 1.0014350414276123\n",
      "\n",
      "episode 13, val func loss 0.06152290478348732\n",
      "\n",
      "episode 14, val func loss 0.9791719317436218\n",
      "\n",
      "episode 15, val func loss 0.08064845204353333\n",
      "\n",
      "episode 16, val func loss 0.7333844900131226\n",
      "\n",
      "Val func train loss in epoch 4:0.2921666119946167\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.07437562197446823\n",
      "\n",
      "episode 2, val func loss 0.6309029459953308\n",
      "\n",
      "episode 3, val func loss 0.0881940945982933\n",
      "\n",
      "episode 4, val func loss 0.330969899892807\n",
      "\n",
      "episode 5, val func loss 0.3529130816459656\n",
      "\n",
      "episode 6, val func loss 0.2846181094646454\n",
      "\n",
      "episode 7, val func loss 0.9240067601203918\n",
      "\n",
      "episode 8, val func loss 0.603304386138916\n",
      "\n",
      "episode 9, val func loss 0.30332306027412415\n",
      "\n",
      "episode 10, val func loss 1.0068408250808716\n",
      "\n",
      "episode 11, val func loss 0.9388963580131531\n",
      "\n",
      "episode 12, val func loss 0.19862167537212372\n",
      "\n",
      "episode 13, val func loss 1.1559027433395386\n",
      "\n",
      "episode 14, val func loss 1.9268649816513062\n",
      "\n",
      "episode 15, val func loss 0.03801264241337776\n",
      "\n",
      "episode 16, val func loss 1.3987714052200317\n",
      "\n",
      "Val func train loss in epoch 5:0.6410324119497091\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.2615841329097748\n",
      "\n",
      "episode 2, val func loss 0.18478885293006897\n",
      "\n",
      "episode 3, val func loss 0.11238478869199753\n",
      "\n",
      "episode 4, val func loss 0.12383826822042465\n",
      "\n",
      "episode 5, val func loss 0.2837366759777069\n",
      "\n",
      "episode 6, val func loss 0.05072511360049248\n",
      "\n",
      "episode 7, val func loss 0.3500573933124542\n",
      "\n",
      "episode 8, val func loss 0.04540008679032326\n",
      "\n",
      "episode 9, val func loss 0.09558586776256561\n",
      "\n",
      "episode 10, val func loss 0.24986092746257782\n",
      "\n",
      "episode 11, val func loss 0.055396631360054016\n",
      "\n",
      "episode 12, val func loss 0.1818246692419052\n",
      "\n",
      "episode 13, val func loss 0.11199784278869629\n",
      "\n",
      "episode 14, val func loss 0.04809960350394249\n",
      "\n",
      "episode 15, val func loss 0.17581786215305328\n",
      "\n",
      "episode 16, val func loss 0.24476951360702515\n",
      "\n",
      "Val func train loss in epoch 6:0.16099176439456642\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.03697727248072624\n",
      "\n",
      "episode 2, val func loss 0.34843626618385315\n",
      "\n",
      "episode 3, val func loss 0.08777839690446854\n",
      "\n",
      "episode 4, val func loss 0.03547917306423187\n",
      "\n",
      "episode 5, val func loss 0.18947219848632812\n",
      "\n",
      "episode 6, val func loss 0.01640479639172554\n",
      "\n",
      "episode 7, val func loss 0.045181334018707275\n",
      "\n",
      "episode 8, val func loss 0.08736145496368408\n",
      "\n",
      "episode 9, val func loss 0.10917321592569351\n",
      "\n",
      "episode 10, val func loss 0.05206768587231636\n",
      "\n",
      "episode 11, val func loss 0.20102864503860474\n",
      "\n",
      "episode 12, val func loss 0.05981844663619995\n",
      "\n",
      "episode 13, val func loss 0.24936410784721375\n",
      "\n",
      "episode 14, val func loss 0.060276687145233154\n",
      "\n",
      "episode 15, val func loss 0.06337843835353851\n",
      "\n",
      "episode 16, val func loss 0.21764600276947021\n",
      "\n",
      "Val func train loss in epoch 7:0.11624025763012469\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.0902017131447792\n",
      "\n",
      "episode 2, val func loss 0.05899368226528168\n",
      "\n",
      "episode 3, val func loss 0.050409961491823196\n",
      "\n",
      "episode 4, val func loss 0.44673681259155273\n",
      "\n",
      "episode 5, val func loss 0.056420836597681046\n",
      "\n",
      "episode 6, val func loss 0.3501060903072357\n",
      "\n",
      "episode 7, val func loss 0.7101531624794006\n",
      "\n",
      "episode 8, val func loss 0.1539253145456314\n",
      "\n",
      "episode 9, val func loss 0.5711454749107361\n",
      "\n",
      "episode 10, val func loss 0.08421177417039871\n",
      "\n",
      "episode 11, val func loss 0.11986270546913147\n",
      "\n",
      "episode 12, val func loss 0.30083370208740234\n",
      "\n",
      "episode 13, val func loss 0.07170417904853821\n",
      "\n",
      "episode 14, val func loss 0.1025373637676239\n",
      "\n",
      "episode 15, val func loss 0.2780366539955139\n",
      "\n",
      "episode 16, val func loss 0.06425244361162186\n",
      "\n",
      "Val func train loss in epoch 8:0.219345741905272\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.21921145915985107\n",
      "\n",
      "episode 2, val func loss 0.16711731255054474\n",
      "\n",
      "episode 3, val func loss 0.006291008088737726\n",
      "\n",
      "episode 4, val func loss 0.2876810133457184\n",
      "\n",
      "episode 5, val func loss 0.06307867169380188\n",
      "\n",
      "episode 6, val func loss 0.05900638550519943\n",
      "\n",
      "episode 7, val func loss 0.07565245032310486\n",
      "\n",
      "episode 8, val func loss 0.06886026263237\n",
      "\n",
      "episode 9, val func loss 0.10922084003686905\n",
      "\n",
      "episode 10, val func loss 0.11318953335285187\n",
      "\n",
      "episode 11, val func loss 0.3423815071582794\n",
      "\n",
      "episode 12, val func loss 0.04211897403001785\n",
      "\n",
      "episode 13, val func loss 0.3340860605239868\n",
      "\n",
      "episode 14, val func loss 0.06796097010374069\n",
      "\n",
      "episode 15, val func loss 0.07140976190567017\n",
      "\n",
      "episode 16, val func loss 0.13403652608394623\n",
      "\n",
      "Val func train loss in epoch 9:0.13508142103091814\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.05812160298228264\n",
      "\n",
      "episode 2, val func loss 0.04928728938102722\n",
      "\n",
      "episode 3, val func loss 0.0506695993244648\n",
      "\n",
      "episode 4, val func loss 0.0940593034029007\n",
      "\n",
      "episode 5, val func loss 0.037381723523139954\n",
      "\n",
      "episode 6, val func loss 0.08341073244810104\n",
      "\n",
      "episode 7, val func loss 0.09219836443662643\n",
      "\n",
      "episode 8, val func loss 0.0677996352314949\n",
      "\n",
      "episode 9, val func loss 0.025166498497128487\n",
      "\n",
      "episode 10, val func loss 0.11320240795612335\n",
      "\n",
      "episode 11, val func loss 0.039242420345544815\n",
      "\n",
      "episode 12, val func loss 0.07973714917898178\n",
      "\n",
      "episode 13, val func loss 0.10405395179986954\n",
      "\n",
      "episode 14, val func loss 0.06817769259214401\n",
      "\n",
      "episode 15, val func loss 0.05925498902797699\n",
      "\n",
      "episode 16, val func loss 0.11120110005140305\n",
      "\n",
      "Val func train loss in epoch 10:0.0708102787612006\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.04320063441991806\n",
      "\n",
      "episode 2, val func loss 0.12054184079170227\n",
      "\n",
      "episode 3, val func loss 0.03929224982857704\n",
      "\n",
      "episode 4, val func loss 0.07757937908172607\n",
      "\n",
      "episode 5, val func loss 0.010898616164922714\n",
      "\n",
      "episode 6, val func loss 0.0533127598464489\n",
      "\n",
      "episode 7, val func loss 0.05078864097595215\n",
      "\n",
      "episode 8, val func loss 0.0652211382985115\n",
      "\n",
      "episode 9, val func loss 0.05256852135062218\n",
      "\n",
      "episode 10, val func loss 0.05996435880661011\n",
      "\n",
      "episode 11, val func loss 0.0802726000547409\n",
      "\n",
      "episode 12, val func loss 0.05923556536436081\n",
      "\n",
      "episode 13, val func loss 0.03781713545322418\n",
      "\n",
      "episode 14, val func loss 0.04108374938368797\n",
      "\n",
      "episode 15, val func loss 0.03771596774458885\n",
      "\n",
      "episode 16, val func loss 0.05662042647600174\n",
      "\n",
      "Val func train loss in epoch 11:0.055382099002599716\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.052388206124305725\n",
      "\n",
      "episode 2, val func loss 0.058201782405376434\n",
      "\n",
      "episode 3, val func loss 0.06016627699136734\n",
      "\n",
      "episode 4, val func loss 0.07725218683481216\n",
      "\n",
      "episode 5, val func loss 0.06780479848384857\n",
      "\n",
      "episode 6, val func loss 0.039677903056144714\n",
      "\n",
      "episode 7, val func loss 0.0411037914454937\n",
      "\n",
      "episode 8, val func loss 0.059615980833768845\n",
      "\n",
      "episode 9, val func loss 0.07519923895597458\n",
      "\n",
      "episode 10, val func loss 0.049417346715927124\n",
      "\n",
      "episode 11, val func loss 0.04020614176988602\n",
      "\n",
      "episode 12, val func loss 0.03706960752606392\n",
      "\n",
      "episode 13, val func loss 0.009700384922325611\n",
      "\n",
      "episode 14, val func loss 0.058369558304548264\n",
      "\n",
      "episode 15, val func loss 0.06791404634714127\n",
      "\n",
      "episode 16, val func loss 0.0628470778465271\n",
      "\n",
      "Val func train loss in epoch 12:0.05355839553521946\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.05515100806951523\n",
      "\n",
      "episode 2, val func loss 0.046088721603155136\n",
      "\n",
      "episode 3, val func loss 0.06972253322601318\n",
      "\n",
      "episode 4, val func loss 0.041085414588451385\n",
      "\n",
      "episode 5, val func loss 0.05464264750480652\n",
      "\n",
      "episode 6, val func loss 0.0626140907406807\n",
      "\n",
      "episode 7, val func loss 0.0966988280415535\n",
      "\n",
      "episode 8, val func loss 0.04470696672797203\n",
      "\n",
      "episode 9, val func loss 0.055270832031965256\n",
      "\n",
      "episode 10, val func loss 0.11203180253505707\n",
      "\n",
      "episode 11, val func loss 0.04989486187696457\n",
      "\n",
      "episode 12, val func loss 0.1733742356300354\n",
      "\n",
      "episode 13, val func loss 0.0675661712884903\n",
      "\n",
      "episode 14, val func loss 0.081229068338871\n",
      "\n",
      "episode 15, val func loss 0.16161419451236725\n",
      "\n",
      "episode 16, val func loss 0.023883648216724396\n",
      "\n",
      "Val func train loss in epoch 13:0.07472343905828893\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.5862128138542175\n",
      "\n",
      "episode 2, val func loss 0.06281889230012894\n",
      "\n",
      "episode 3, val func loss 0.7897777557373047\n",
      "\n",
      "episode 4, val func loss 0.06788765639066696\n",
      "\n",
      "episode 5, val func loss 0.5883197784423828\n",
      "\n",
      "episode 6, val func loss 0.09851521998643875\n",
      "\n",
      "episode 7, val func loss 0.17101944983005524\n",
      "\n",
      "episode 8, val func loss 1.4711846113204956\n",
      "\n",
      "episode 9, val func loss 0.35141754150390625\n",
      "\n",
      "episode 10, val func loss 1.599112868309021\n",
      "\n",
      "episode 11, val func loss 2.272489547729492\n",
      "\n",
      "episode 12, val func loss 0.0607796348631382\n",
      "\n",
      "episode 13, val func loss 4.572229862213135\n",
      "\n",
      "episode 14, val func loss 0.2822103202342987\n",
      "\n",
      "episode 15, val func loss 0.357509046792984\n",
      "\n",
      "episode 16, val func loss 0.7950154542922974\n",
      "\n",
      "Val func train loss in epoch 14:0.8829062783624977\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.4664496183395386\n",
      "\n",
      "episode 2, val func loss 1.2657390832901\n",
      "\n",
      "episode 3, val func loss 0.7809874415397644\n",
      "\n",
      "episode 4, val func loss 0.03096078895032406\n",
      "\n",
      "episode 5, val func loss 0.4724631607532501\n",
      "\n",
      "episode 6, val func loss 0.09077827632427216\n",
      "\n",
      "episode 7, val func loss 0.1254810094833374\n",
      "\n",
      "episode 8, val func loss 0.072743259370327\n",
      "\n",
      "episode 9, val func loss 0.15739814937114716\n",
      "\n",
      "episode 10, val func loss 0.14576561748981476\n",
      "\n",
      "episode 11, val func loss 0.05926750227808952\n",
      "\n",
      "episode 12, val func loss 0.13850346207618713\n",
      "\n",
      "episode 13, val func loss 0.10449618101119995\n",
      "\n",
      "episode 14, val func loss 0.0457303486764431\n",
      "\n",
      "episode 15, val func loss 0.05296121910214424\n",
      "\n",
      "episode 16, val func loss 0.15363973379135132\n",
      "\n",
      "Val func train loss in epoch 15:0.3227103032404557\n",
      "***********************TIME WAS 4.896862824757894 min*****************************\n",
      "\n",
      "**********************ROUND 4 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.09357905387878418\n",
      "\n",
      "episode 2, policy loss -0.08330856263637543\n",
      "\n",
      "episode 3, policy loss -0.06765108555555344\n",
      "\n",
      "episode 4, policy loss -0.10568605363368988\n",
      "\n",
      "episode 5, policy loss -0.10034111887216568\n",
      "\n",
      "episode 6, policy loss -0.03671003505587578\n",
      "\n",
      "episode 7, policy loss -0.08198042213916779\n",
      "\n",
      "episode 8, policy loss -0.03423791751265526\n",
      "\n",
      "episode 9, policy loss -0.09996581822633743\n",
      "\n",
      "episode 10, policy loss -0.06539610773324966\n",
      "\n",
      "episode 11, policy loss -0.11188357323408127\n",
      "\n",
      "episode 12, policy loss -0.04616144672036171\n",
      "\n",
      "episode 13, policy loss -0.0895133689045906\n",
      "\n",
      "episode 14, policy loss -0.10683214664459229\n",
      "\n",
      "episode 15, policy loss -0.09154022485017776\n",
      "\n",
      "episode 16, policy loss -0.11466828733682632\n",
      "\n",
      "Policy train loss in epoch 0:-0.08309095143340528\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.0799165591597557\n",
      "\n",
      "episode 2, policy loss -0.10488717257976532\n",
      "\n",
      "episode 3, policy loss -0.11449508368968964\n",
      "\n",
      "episode 4, policy loss -0.07346422970294952\n",
      "\n",
      "episode 5, policy loss -0.08582092076539993\n",
      "\n",
      "episode 6, policy loss -0.03682506084442139\n",
      "\n",
      "episode 7, policy loss -0.10734139382839203\n",
      "\n",
      "episode 8, policy loss -0.11087650805711746\n",
      "\n",
      "episode 9, policy loss -0.08752661943435669\n",
      "\n",
      "episode 10, policy loss -0.05796681344509125\n",
      "\n",
      "episode 11, policy loss -0.09985551983118057\n",
      "\n",
      "episode 12, policy loss -0.04093169793486595\n",
      "\n",
      "episode 13, policy loss -0.06597813963890076\n",
      "\n",
      "episode 14, policy loss -0.09883485734462738\n",
      "\n",
      "episode 15, policy loss -0.09001582860946655\n",
      "\n",
      "episode 16, policy loss -0.08874605596065521\n",
      "\n",
      "Policy train loss in epoch 1:-0.08396765380166471\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.08135270327329636\n",
      "\n",
      "episode 2, policy loss -0.04973438382148743\n",
      "\n",
      "episode 3, policy loss -0.10986421257257462\n",
      "\n",
      "episode 4, policy loss -0.10156121850013733\n",
      "\n",
      "episode 5, policy loss -0.0758846253156662\n",
      "\n",
      "episode 6, policy loss -0.10157443583011627\n",
      "\n",
      "episode 7, policy loss -0.07063760608434677\n",
      "\n",
      "episode 8, policy loss -0.09140282869338989\n",
      "\n",
      "episode 9, policy loss -0.06256221234798431\n",
      "\n",
      "episode 10, policy loss -0.0883161649107933\n",
      "\n",
      "episode 11, policy loss -0.100953109562397\n",
      "\n",
      "episode 12, policy loss -0.03215288370847702\n",
      "\n",
      "episode 13, policy loss -0.03796723857522011\n",
      "\n",
      "episode 14, policy loss -0.11829283833503723\n",
      "\n",
      "episode 15, policy loss -0.0911109670996666\n",
      "\n",
      "episode 16, policy loss -0.1089078038930893\n",
      "\n",
      "Policy train loss in epoch 2:-0.08264220203272998\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.08873820304870605\n",
      "\n",
      "episode 2, policy loss -0.04824739694595337\n",
      "\n",
      "episode 3, policy loss -0.11254720389842987\n",
      "\n",
      "episode 4, policy loss -0.08126947283744812\n",
      "\n",
      "episode 5, policy loss -0.10317018628120422\n",
      "\n",
      "episode 6, policy loss -0.11105012893676758\n",
      "\n",
      "episode 7, policy loss -0.09435640275478363\n",
      "\n",
      "episode 8, policy loss -0.10173708945512772\n",
      "\n",
      "episode 9, policy loss -0.08432339876890182\n",
      "\n",
      "episode 10, policy loss -0.06359999626874924\n",
      "\n",
      "episode 11, policy loss -0.10410014539957047\n",
      "\n",
      "episode 12, policy loss -0.03936295583844185\n",
      "\n",
      "episode 13, policy loss -0.05866891145706177\n",
      "\n",
      "episode 14, policy loss -0.0930367261171341\n",
      "\n",
      "episode 15, policy loss -0.07416433095932007\n",
      "\n",
      "episode 16, policy loss -0.11164434254169464\n",
      "\n",
      "Policy train loss in epoch 3:-0.0856260557193309\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.06232688948512077\n",
      "\n",
      "episode 2, val func loss 0.07733707129955292\n",
      "\n",
      "episode 3, val func loss 0.11450428515672684\n",
      "\n",
      "episode 4, val func loss 0.07049944996833801\n",
      "\n",
      "episode 5, val func loss 0.08796815574169159\n",
      "\n",
      "episode 6, val func loss 0.08885537087917328\n",
      "\n",
      "episode 7, val func loss 0.11441272497177124\n",
      "\n",
      "episode 8, val func loss 0.18045227229595184\n",
      "\n",
      "episode 9, val func loss 0.07948203384876251\n",
      "\n",
      "episode 10, val func loss 0.05221503973007202\n",
      "\n",
      "episode 11, val func loss 0.06125335022807121\n",
      "\n",
      "episode 12, val func loss 0.05270720645785332\n",
      "\n",
      "episode 13, val func loss 0.0579252615571022\n",
      "\n",
      "episode 14, val func loss 0.13500839471817017\n",
      "\n",
      "episode 15, val func loss 0.18130265176296234\n",
      "\n",
      "episode 16, val func loss 0.2892380952835083\n",
      "\n",
      "Val func train loss in epoch 0:0.10659301583655179\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.12792128324508667\n",
      "\n",
      "episode 2, val func loss 0.30361422896385193\n",
      "\n",
      "episode 3, val func loss 0.10516911000013351\n",
      "\n",
      "episode 4, val func loss 0.06670916825532913\n",
      "\n",
      "episode 5, val func loss 0.10332497209310532\n",
      "\n",
      "episode 6, val func loss 0.2700504958629608\n",
      "\n",
      "episode 7, val func loss 0.04463949427008629\n",
      "\n",
      "episode 8, val func loss 0.23857200145721436\n",
      "\n",
      "episode 9, val func loss 0.38104352355003357\n",
      "\n",
      "episode 10, val func loss 0.041425030678510666\n",
      "\n",
      "episode 11, val func loss 0.23926329612731934\n",
      "\n",
      "episode 12, val func loss 0.1998281031847\n",
      "\n",
      "episode 13, val func loss 0.07583553344011307\n",
      "\n",
      "episode 14, val func loss 0.19239211082458496\n",
      "\n",
      "episode 15, val func loss 0.07488124072551727\n",
      "\n",
      "episode 16, val func loss 0.11955483257770538\n",
      "\n",
      "Val func train loss in epoch 1:0.16151402657851577\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.13256484270095825\n",
      "\n",
      "episode 2, val func loss 0.05807223170995712\n",
      "\n",
      "episode 3, val func loss 0.1563245952129364\n",
      "\n",
      "episode 4, val func loss 0.021332496777176857\n",
      "\n",
      "episode 5, val func loss 0.12385232001543045\n",
      "\n",
      "episode 6, val func loss 0.07075490057468414\n",
      "\n",
      "episode 7, val func loss 0.08299948275089264\n",
      "\n",
      "episode 8, val func loss 0.08455651998519897\n",
      "\n",
      "episode 9, val func loss 0.06803107261657715\n",
      "\n",
      "episode 10, val func loss 0.04361024871468544\n",
      "\n",
      "episode 11, val func loss 0.0931348204612732\n",
      "\n",
      "episode 12, val func loss 0.050967756658792496\n",
      "\n",
      "episode 13, val func loss 0.03242415934801102\n",
      "\n",
      "episode 14, val func loss 0.045530568808317184\n",
      "\n",
      "episode 15, val func loss 0.07180879265069962\n",
      "\n",
      "episode 16, val func loss 0.0938420295715332\n",
      "\n",
      "Val func train loss in epoch 2:0.07686292740982026\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.0798119455575943\n",
      "\n",
      "episode 2, val func loss 0.07140949368476868\n",
      "\n",
      "episode 3, val func loss 0.13617858290672302\n",
      "\n",
      "episode 4, val func loss 0.05530070140957832\n",
      "\n",
      "episode 5, val func loss 0.1253826916217804\n",
      "\n",
      "episode 6, val func loss 0.102986641228199\n",
      "\n",
      "episode 7, val func loss 0.06477569788694382\n",
      "\n",
      "episode 8, val func loss 0.1181415393948555\n",
      "\n",
      "episode 9, val func loss 0.07705259323120117\n",
      "\n",
      "episode 10, val func loss 0.020763926208019257\n",
      "\n",
      "episode 11, val func loss 0.12356115877628326\n",
      "\n",
      "episode 12, val func loss 0.07303053885698318\n",
      "\n",
      "episode 13, val func loss 0.04409383609890938\n",
      "\n",
      "episode 14, val func loss 0.1931772232055664\n",
      "\n",
      "episode 15, val func loss 0.04007986560463905\n",
      "\n",
      "episode 16, val func loss 0.27766382694244385\n",
      "\n",
      "Val func train loss in epoch 3:0.10021314141340554\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.07834561169147491\n",
      "\n",
      "episode 2, val func loss 0.09994684159755707\n",
      "\n",
      "episode 3, val func loss 0.1971866637468338\n",
      "\n",
      "episode 4, val func loss 0.11335955560207367\n",
      "\n",
      "episode 5, val func loss 0.025966059416532516\n",
      "\n",
      "episode 6, val func loss 0.4074755907058716\n",
      "\n",
      "episode 7, val func loss 0.10365813225507736\n",
      "\n",
      "episode 8, val func loss 0.10944368690252304\n",
      "\n",
      "episode 9, val func loss 0.4435708820819855\n",
      "\n",
      "episode 10, val func loss 0.5806892514228821\n",
      "\n",
      "episode 11, val func loss 0.5957106947898865\n",
      "\n",
      "episode 12, val func loss 0.8397466540336609\n",
      "\n",
      "episode 13, val func loss 0.32984358072280884\n",
      "\n",
      "episode 14, val func loss 0.06467336416244507\n",
      "\n",
      "episode 15, val func loss 0.8340643048286438\n",
      "\n",
      "episode 16, val func loss 2.2350010871887207\n",
      "\n",
      "Val func train loss in epoch 4:0.4411676225718111\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.35752588510513306\n",
      "\n",
      "episode 2, val func loss 1.0543780326843262\n",
      "\n",
      "episode 3, val func loss 1.4607915878295898\n",
      "\n",
      "episode 4, val func loss 0.5539751648902893\n",
      "\n",
      "episode 5, val func loss 0.059827905148267746\n",
      "\n",
      "episode 6, val func loss 0.8537220358848572\n",
      "\n",
      "episode 7, val func loss 2.856942892074585\n",
      "\n",
      "episode 8, val func loss 0.034378405660390854\n",
      "\n",
      "episode 9, val func loss 1.2011728286743164\n",
      "\n",
      "episode 10, val func loss 1.1550822257995605\n",
      "\n",
      "episode 11, val func loss 1.3201578855514526\n",
      "\n",
      "episode 12, val func loss 0.08047301322221756\n",
      "\n",
      "episode 13, val func loss 1.4370617866516113\n",
      "\n",
      "episode 14, val func loss 1.3528412580490112\n",
      "\n",
      "episode 15, val func loss 0.35134363174438477\n",
      "\n",
      "episode 16, val func loss 0.045368533581495285\n",
      "\n",
      "Val func train loss in epoch 5:0.885940192034468\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.4984753727912903\n",
      "\n",
      "episode 2, val func loss 0.48195749521255493\n",
      "\n",
      "episode 3, val func loss 0.42353731393814087\n",
      "\n",
      "episode 4, val func loss 0.08971566706895828\n",
      "\n",
      "episode 5, val func loss 0.119815893471241\n",
      "\n",
      "episode 6, val func loss 0.40002089738845825\n",
      "\n",
      "episode 7, val func loss 0.8996657729148865\n",
      "\n",
      "episode 8, val func loss 0.35291945934295654\n",
      "\n",
      "episode 9, val func loss 0.020783666521310806\n",
      "\n",
      "episode 10, val func loss 0.29736781120300293\n",
      "\n",
      "episode 11, val func loss 0.6394460797309875\n",
      "\n",
      "episode 12, val func loss 0.766089677810669\n",
      "\n",
      "episode 13, val func loss 0.08437366038560867\n",
      "\n",
      "episode 14, val func loss 0.26196280121803284\n",
      "\n",
      "episode 15, val func loss 1.7736401557922363\n",
      "\n",
      "episode 16, val func loss 0.17760640382766724\n",
      "\n",
      "Val func train loss in epoch 6:0.4554611330386251\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.07882452756166458\n",
      "\n",
      "episode 2, val func loss 0.3308718800544739\n",
      "\n",
      "episode 3, val func loss 0.203438863158226\n",
      "\n",
      "episode 4, val func loss 0.47170522809028625\n",
      "\n",
      "episode 5, val func loss 0.3793583810329437\n",
      "\n",
      "episode 6, val func loss 0.08512341231107712\n",
      "\n",
      "episode 7, val func loss 0.0709306001663208\n",
      "\n",
      "episode 8, val func loss 0.5557252168655396\n",
      "\n",
      "episode 9, val func loss 0.41092348098754883\n",
      "\n",
      "episode 10, val func loss 0.22635851800441742\n",
      "\n",
      "episode 11, val func loss 0.12587013840675354\n",
      "\n",
      "episode 12, val func loss 0.4997757375240326\n",
      "\n",
      "episode 13, val func loss 0.41005611419677734\n",
      "\n",
      "episode 14, val func loss 0.13835808634757996\n",
      "\n",
      "episode 15, val func loss 0.12710097432136536\n",
      "\n",
      "episode 16, val func loss 0.07608462870121002\n",
      "\n",
      "Val func train loss in epoch 7:0.26190661173313856\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.3023267984390259\n",
      "\n",
      "episode 2, val func loss 0.6493148803710938\n",
      "\n",
      "episode 3, val func loss 0.07155811041593552\n",
      "\n",
      "episode 4, val func loss 0.08666034787893295\n",
      "\n",
      "episode 5, val func loss 0.5585532784461975\n",
      "\n",
      "episode 6, val func loss 0.16754183173179626\n",
      "\n",
      "episode 7, val func loss 0.07572918385267258\n",
      "\n",
      "episode 8, val func loss 0.0437207967042923\n",
      "\n",
      "episode 9, val func loss 0.1675158590078354\n",
      "\n",
      "episode 10, val func loss 0.37647637724876404\n",
      "\n",
      "episode 11, val func loss 0.13321785628795624\n",
      "\n",
      "episode 12, val func loss 0.03598012775182724\n",
      "\n",
      "episode 13, val func loss 0.06891355663537979\n",
      "\n",
      "episode 14, val func loss 0.16359885036945343\n",
      "\n",
      "episode 15, val func loss 0.13313813507556915\n",
      "\n",
      "episode 16, val func loss 0.028852513059973717\n",
      "\n",
      "Val func train loss in epoch 8:0.1914436564547941\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.08218763023614883\n",
      "\n",
      "episode 2, val func loss 0.04336751252412796\n",
      "\n",
      "episode 3, val func loss 0.07778582721948624\n",
      "\n",
      "episode 4, val func loss 0.20218174159526825\n",
      "\n",
      "episode 5, val func loss 0.02406766451895237\n",
      "\n",
      "episode 6, val func loss 0.07124796509742737\n",
      "\n",
      "episode 7, val func loss 0.13741841912269592\n",
      "\n",
      "episode 8, val func loss 0.1489695906639099\n",
      "\n",
      "episode 9, val func loss 0.069525346159935\n",
      "\n",
      "episode 10, val func loss 0.06475678831338882\n",
      "\n",
      "episode 11, val func loss 0.056306447833776474\n",
      "\n",
      "episode 12, val func loss 0.11337558180093765\n",
      "\n",
      "episode 13, val func loss 0.11182980984449387\n",
      "\n",
      "episode 14, val func loss 0.0900711640715599\n",
      "\n",
      "episode 15, val func loss 0.06453411281108856\n",
      "\n",
      "episode 16, val func loss 0.11171681433916092\n",
      "\n",
      "Val func train loss in epoch 9:0.09183390100952238\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.09697470813989639\n",
      "\n",
      "episode 2, val func loss 0.06386030465364456\n",
      "\n",
      "episode 3, val func loss 0.07078105956315994\n",
      "\n",
      "episode 4, val func loss 0.06926427781581879\n",
      "\n",
      "episode 5, val func loss 0.16583526134490967\n",
      "\n",
      "episode 6, val func loss 0.08299412578344345\n",
      "\n",
      "episode 7, val func loss 0.05542387068271637\n",
      "\n",
      "episode 8, val func loss 0.09109771251678467\n",
      "\n",
      "episode 9, val func loss 0.11587102711200714\n",
      "\n",
      "episode 10, val func loss 0.028137728571891785\n",
      "\n",
      "episode 11, val func loss 0.07799314707517624\n",
      "\n",
      "episode 12, val func loss 0.08342662453651428\n",
      "\n",
      "episode 13, val func loss 0.07071632146835327\n",
      "\n",
      "episode 14, val func loss 0.10749098658561707\n",
      "\n",
      "episode 15, val func loss 0.03846873715519905\n",
      "\n",
      "episode 16, val func loss 0.043101973831653595\n",
      "\n",
      "Val func train loss in epoch 10:0.07883986667729914\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.03863096982240677\n",
      "\n",
      "episode 2, val func loss 0.08489027619361877\n",
      "\n",
      "episode 3, val func loss 0.08447609096765518\n",
      "\n",
      "episode 4, val func loss 0.08701962232589722\n",
      "\n",
      "episode 5, val func loss 0.033403899520635605\n",
      "\n",
      "episode 6, val func loss 0.08485652506351471\n",
      "\n",
      "episode 7, val func loss 0.09833834320306778\n",
      "\n",
      "episode 8, val func loss 0.0714099183678627\n",
      "\n",
      "episode 9, val func loss 0.11748041212558746\n",
      "\n",
      "episode 10, val func loss 0.05487643554806709\n",
      "\n",
      "episode 11, val func loss 0.06327641010284424\n",
      "\n",
      "episode 12, val func loss 0.06954912841320038\n",
      "\n",
      "episode 13, val func loss 0.06978974491357803\n",
      "\n",
      "episode 14, val func loss 0.07460951805114746\n",
      "\n",
      "episode 15, val func loss 0.028454257175326347\n",
      "\n",
      "episode 16, val func loss 0.06077507510781288\n",
      "\n",
      "Val func train loss in epoch 11:0.07011478918138891\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.08003629744052887\n",
      "\n",
      "episode 2, val func loss 0.056835975497961044\n",
      "\n",
      "episode 3, val func loss 0.09045897424221039\n",
      "\n",
      "episode 4, val func loss 0.040532294660806656\n",
      "\n",
      "episode 5, val func loss 0.06422765552997589\n",
      "\n",
      "episode 6, val func loss 0.029574062675237656\n",
      "\n",
      "episode 7, val func loss 0.07078077644109726\n",
      "\n",
      "episode 8, val func loss 0.042599376291036606\n",
      "\n",
      "episode 9, val func loss 0.06217736378312111\n",
      "\n",
      "episode 10, val func loss 0.06510290503501892\n",
      "\n",
      "episode 11, val func loss 0.07060834020376205\n",
      "\n",
      "episode 12, val func loss 0.06747831404209137\n",
      "\n",
      "episode 13, val func loss 0.06409673392772675\n",
      "\n",
      "episode 14, val func loss 0.0638052299618721\n",
      "\n",
      "episode 15, val func loss 0.10379862785339355\n",
      "\n",
      "episode 16, val func loss 0.033345382660627365\n",
      "\n",
      "Val func train loss in epoch 12:0.06284114439040422\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.02784462831914425\n",
      "\n",
      "episode 2, val func loss 0.18020766973495483\n",
      "\n",
      "episode 3, val func loss 0.0744042918086052\n",
      "\n",
      "episode 4, val func loss 0.06678073108196259\n",
      "\n",
      "episode 5, val func loss 0.2305687516927719\n",
      "\n",
      "episode 6, val func loss 0.06137519329786301\n",
      "\n",
      "episode 7, val func loss 0.14057914912700653\n",
      "\n",
      "episode 8, val func loss 0.08638913929462433\n",
      "\n",
      "episode 9, val func loss 0.050881873816251755\n",
      "\n",
      "episode 10, val func loss 0.04624874144792557\n",
      "\n",
      "episode 11, val func loss 0.13915576040744781\n",
      "\n",
      "episode 12, val func loss 0.04368418827652931\n",
      "\n",
      "episode 13, val func loss 0.06907312572002411\n",
      "\n",
      "episode 14, val func loss 0.03853316605091095\n",
      "\n",
      "episode 15, val func loss 0.08210252970457077\n",
      "\n",
      "episode 16, val func loss 0.0775245875120163\n",
      "\n",
      "Val func train loss in epoch 13:0.08845959545578808\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.0811738446354866\n",
      "\n",
      "episode 2, val func loss 0.07622980326414108\n",
      "\n",
      "episode 3, val func loss 0.042549632489681244\n",
      "\n",
      "episode 4, val func loss 0.0787566676735878\n",
      "\n",
      "episode 5, val func loss 0.07341939955949783\n",
      "\n",
      "episode 6, val func loss 0.07718043774366379\n",
      "\n",
      "episode 7, val func loss 0.1673489212989807\n",
      "\n",
      "episode 8, val func loss 0.06053861603140831\n",
      "\n",
      "episode 9, val func loss 0.07108931243419647\n",
      "\n",
      "episode 10, val func loss 0.03704392537474632\n",
      "\n",
      "episode 11, val func loss 0.07527217268943787\n",
      "\n",
      "episode 12, val func loss 0.06525633484125137\n",
      "\n",
      "episode 13, val func loss 0.037990670651197433\n",
      "\n",
      "episode 14, val func loss 0.0727817639708519\n",
      "\n",
      "episode 15, val func loss 0.07625754922628403\n",
      "\n",
      "episode 16, val func loss 0.06054265797138214\n",
      "\n",
      "Val func train loss in epoch 14:0.07208948186598718\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.042469482868909836\n",
      "\n",
      "episode 2, val func loss 0.1415957808494568\n",
      "\n",
      "episode 3, val func loss 0.08470942080020905\n",
      "\n",
      "episode 4, val func loss 0.059138551354408264\n",
      "\n",
      "episode 5, val func loss 0.11018623411655426\n",
      "\n",
      "episode 6, val func loss 0.08463963121175766\n",
      "\n",
      "episode 7, val func loss 0.08805271238088608\n",
      "\n",
      "episode 8, val func loss 0.0867561623454094\n",
      "\n",
      "episode 9, val func loss 0.043863438069820404\n",
      "\n",
      "episode 10, val func loss 0.06423751264810562\n",
      "\n",
      "episode 11, val func loss 0.07212245464324951\n",
      "\n",
      "episode 12, val func loss 0.061318397521972656\n",
      "\n",
      "episode 13, val func loss 0.06342250853776932\n",
      "\n",
      "episode 14, val func loss 0.028685791417956352\n",
      "\n",
      "episode 15, val func loss 0.0950949490070343\n",
      "\n",
      "episode 16, val func loss 0.08642536401748657\n",
      "\n",
      "Val func train loss in epoch 15:0.07579489948693663\n",
      "***********************TIME WAS 5.16274455388387 min*****************************\n",
      "\n",
      "**********************ROUND 5 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.18402740359306335\n",
      "\n",
      "episode 2, policy loss -0.2544090449810028\n",
      "\n",
      "episode 3, policy loss -0.13382378220558167\n",
      "\n",
      "episode 4, policy loss -0.18319223821163177\n",
      "\n",
      "episode 5, policy loss -0.17413005232810974\n",
      "\n",
      "episode 6, policy loss -0.11949769407510757\n",
      "\n",
      "episode 7, policy loss -0.22995376586914062\n",
      "\n",
      "episode 8, policy loss -0.15603378415107727\n",
      "\n",
      "episode 9, policy loss -0.1793515682220459\n",
      "\n",
      "episode 10, policy loss -0.20841176807880402\n",
      "\n",
      "episode 11, policy loss -0.2073521763086319\n",
      "\n",
      "episode 12, policy loss -0.24760109186172485\n",
      "\n",
      "episode 13, policy loss -0.13063177466392517\n",
      "\n",
      "episode 14, policy loss -0.1982688009738922\n",
      "\n",
      "episode 15, policy loss -0.1917944848537445\n",
      "\n",
      "episode 16, policy loss -0.12971843779087067\n",
      "\n",
      "Policy train loss in epoch 0:-0.18301236676052213\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.2084498107433319\n",
      "\n",
      "episode 2, policy loss -0.1836191713809967\n",
      "\n",
      "episode 3, policy loss -0.18236176669597626\n",
      "\n",
      "episode 4, policy loss -0.1223895400762558\n",
      "\n",
      "episode 5, policy loss -0.12883129715919495\n",
      "\n",
      "episode 6, policy loss -0.18388426303863525\n",
      "\n",
      "episode 7, policy loss -0.24580058455467224\n",
      "\n",
      "episode 8, policy loss -0.227443665266037\n",
      "\n",
      "episode 9, policy loss -0.12893496453762054\n",
      "\n",
      "episode 10, policy loss -0.18948310613632202\n",
      "\n",
      "episode 11, policy loss -0.12902016937732697\n",
      "\n",
      "episode 12, policy loss -0.16867265105247498\n",
      "\n",
      "episode 13, policy loss -0.20548495650291443\n",
      "\n",
      "episode 14, policy loss -0.2504134774208069\n",
      "\n",
      "episode 15, policy loss -0.18421083688735962\n",
      "\n",
      "episode 16, policy loss -0.15928399562835693\n",
      "\n",
      "Policy train loss in epoch 1:-0.18114276602864265\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.11579941213130951\n",
      "\n",
      "episode 2, policy loss -0.20506222546100616\n",
      "\n",
      "episode 3, policy loss -0.18188220262527466\n",
      "\n",
      "episode 4, policy loss -0.18605640530586243\n",
      "\n",
      "episode 5, policy loss -0.17559882998466492\n",
      "\n",
      "episode 6, policy loss -0.22152678668498993\n",
      "\n",
      "episode 7, policy loss -0.15823876857757568\n",
      "\n",
      "episode 8, policy loss -0.25215041637420654\n",
      "\n",
      "episode 9, policy loss -0.2595437169075012\n",
      "\n",
      "episode 10, policy loss -0.1261410266160965\n",
      "\n",
      "episode 11, policy loss -0.12401026487350464\n",
      "\n",
      "episode 12, policy loss -0.18384972214698792\n",
      "\n",
      "episode 13, policy loss -0.12817484140396118\n",
      "\n",
      "episode 14, policy loss -0.1929776966571808\n",
      "\n",
      "episode 15, policy loss -0.20575977861881256\n",
      "\n",
      "episode 16, policy loss -0.17236945033073425\n",
      "\n",
      "Policy train loss in epoch 2:-0.1805713465437293\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.2564130127429962\n",
      "\n",
      "episode 2, policy loss -0.1810407191514969\n",
      "\n",
      "episode 3, policy loss -0.2526986002922058\n",
      "\n",
      "episode 4, policy loss -0.13140565156936646\n",
      "\n",
      "episode 5, policy loss -0.20621998608112335\n",
      "\n",
      "episode 6, policy loss -0.1975741982460022\n",
      "\n",
      "episode 7, policy loss -0.17511151731014252\n",
      "\n",
      "episode 8, policy loss -0.19389793276786804\n",
      "\n",
      "episode 9, policy loss -0.22957608103752136\n",
      "\n",
      "episode 10, policy loss -0.12025795876979828\n",
      "\n",
      "episode 11, policy loss -0.1594410538673401\n",
      "\n",
      "episode 12, policy loss -0.18429872393608093\n",
      "\n",
      "episode 13, policy loss -0.21052400767803192\n",
      "\n",
      "episode 14, policy loss -0.18305754661560059\n",
      "\n",
      "episode 15, policy loss -0.13225802779197693\n",
      "\n",
      "episode 16, policy loss -0.130851149559021\n",
      "\n",
      "Policy train loss in epoch 3:-0.18403913546353579\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.08124658465385437\n",
      "\n",
      "episode 2, val func loss 0.07141803950071335\n",
      "\n",
      "episode 3, val func loss 0.023930063471198082\n",
      "\n",
      "episode 4, val func loss 0.10505858808755875\n",
      "\n",
      "episode 5, val func loss 0.0650632306933403\n",
      "\n",
      "episode 6, val func loss 0.04973473772406578\n",
      "\n",
      "episode 7, val func loss 0.04003811627626419\n",
      "\n",
      "episode 8, val func loss 0.039742980152368546\n",
      "\n",
      "episode 9, val func loss 0.12154868245124817\n",
      "\n",
      "episode 10, val func loss 0.05968202278017998\n",
      "\n",
      "episode 11, val func loss 0.10743464529514313\n",
      "\n",
      "episode 12, val func loss 0.13069595396518707\n",
      "\n",
      "episode 13, val func loss 0.06270266324281693\n",
      "\n",
      "episode 14, val func loss 0.052899569272994995\n",
      "\n",
      "episode 15, val func loss 0.08952941000461578\n",
      "\n",
      "episode 16, val func loss 0.02257293462753296\n",
      "\n",
      "Val func train loss in epoch 0:0.07020613888744265\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.024360382929444313\n",
      "\n",
      "episode 2, val func loss 0.061486080288887024\n",
      "\n",
      "episode 3, val func loss 0.028600426390767097\n",
      "\n",
      "episode 4, val func loss 0.07458310574293137\n",
      "\n",
      "episode 5, val func loss 0.038816649466753006\n",
      "\n",
      "episode 6, val func loss 0.09560930728912354\n",
      "\n",
      "episode 7, val func loss 0.0508221760392189\n",
      "\n",
      "episode 8, val func loss 0.021268516778945923\n",
      "\n",
      "episode 9, val func loss 0.058967333287000656\n",
      "\n",
      "episode 10, val func loss 0.054482169449329376\n",
      "\n",
      "episode 11, val func loss 0.051484622061252594\n",
      "\n",
      "episode 12, val func loss 0.09793779999017715\n",
      "\n",
      "episode 13, val func loss 0.06391596049070358\n",
      "\n",
      "episode 14, val func loss 0.08780843764543533\n",
      "\n",
      "episode 15, val func loss 0.049722082912921906\n",
      "\n",
      "episode 16, val func loss 0.034253209829330444\n",
      "\n",
      "Val func train loss in epoch 1:0.05588239128701389\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.022286703810095787\n",
      "\n",
      "episode 2, val func loss 0.06916927546262741\n",
      "\n",
      "episode 3, val func loss 0.051539625972509384\n",
      "\n",
      "episode 4, val func loss 0.08885785937309265\n",
      "\n",
      "episode 5, val func loss 0.06466781347990036\n",
      "\n",
      "episode 6, val func loss 0.08471393585205078\n",
      "\n",
      "episode 7, val func loss 0.07744622975587845\n",
      "\n",
      "episode 8, val func loss 0.04391380399465561\n",
      "\n",
      "episode 9, val func loss 0.06275966763496399\n",
      "\n",
      "episode 10, val func loss 0.0543568879365921\n",
      "\n",
      "episode 11, val func loss 0.05665185675024986\n",
      "\n",
      "episode 12, val func loss 0.024008776992559433\n",
      "\n",
      "episode 13, val func loss 0.037864699959754944\n",
      "\n",
      "episode 14, val func loss 0.07550915330648422\n",
      "\n",
      "episode 15, val func loss 0.03885279968380928\n",
      "\n",
      "episode 16, val func loss 0.024848930537700653\n",
      "\n",
      "Val func train loss in epoch 2:0.05484050128143281\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.03288986533880234\n",
      "\n",
      "episode 2, val func loss 0.02595815435051918\n",
      "\n",
      "episode 3, val func loss 0.023715496063232422\n",
      "\n",
      "episode 4, val func loss 0.03464191406965256\n",
      "\n",
      "episode 5, val func loss 0.10228492319583893\n",
      "\n",
      "episode 6, val func loss 0.06705036759376526\n",
      "\n",
      "episode 7, val func loss 0.06412234157323837\n",
      "\n",
      "episode 8, val func loss 0.05303744226694107\n",
      "\n",
      "episode 9, val func loss 0.050262317061424255\n",
      "\n",
      "episode 10, val func loss 0.08330118656158447\n",
      "\n",
      "episode 11, val func loss 0.06189420446753502\n",
      "\n",
      "episode 12, val func loss 0.10573051124811172\n",
      "\n",
      "episode 13, val func loss 0.08004767447710037\n",
      "\n",
      "episode 14, val func loss 0.05622178688645363\n",
      "\n",
      "episode 15, val func loss 0.05756102502346039\n",
      "\n",
      "episode 16, val func loss 0.10597194731235504\n",
      "\n",
      "Val func train loss in epoch 3:0.06279319734312594\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.031718652695417404\n",
      "\n",
      "episode 2, val func loss 0.12040069699287415\n",
      "\n",
      "episode 3, val func loss 0.11515834927558899\n",
      "\n",
      "episode 4, val func loss 0.14351853728294373\n",
      "\n",
      "episode 5, val func loss 0.06581314653158188\n",
      "\n",
      "episode 6, val func loss 0.04483042284846306\n",
      "\n",
      "episode 7, val func loss 0.04328153654932976\n",
      "\n",
      "episode 8, val func loss 0.09858378022909164\n",
      "\n",
      "episode 9, val func loss 0.05165634676814079\n",
      "\n",
      "episode 10, val func loss 0.09580004960298538\n",
      "\n",
      "episode 11, val func loss 0.0304872989654541\n",
      "\n",
      "episode 12, val func loss 0.05355178192257881\n",
      "\n",
      "episode 13, val func loss 0.028741760179400444\n",
      "\n",
      "episode 14, val func loss 0.07672517746686935\n",
      "\n",
      "episode 15, val func loss 0.06868661940097809\n",
      "\n",
      "episode 16, val func loss 0.10798642039299011\n",
      "\n",
      "Val func train loss in epoch 4:0.07355878606904298\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.04364972189068794\n",
      "\n",
      "episode 2, val func loss 0.06202328950166702\n",
      "\n",
      "episode 3, val func loss 0.04052690416574478\n",
      "\n",
      "episode 4, val func loss 0.054319269955158234\n",
      "\n",
      "episode 5, val func loss 0.04579666629433632\n",
      "\n",
      "episode 6, val func loss 0.09009838104248047\n",
      "\n",
      "episode 7, val func loss 0.024778835475444794\n",
      "\n",
      "episode 8, val func loss 0.03318927809596062\n",
      "\n",
      "episode 9, val func loss 0.06106332316994667\n",
      "\n",
      "episode 10, val func loss 0.08244303613901138\n",
      "\n",
      "episode 11, val func loss 0.02672649547457695\n",
      "\n",
      "episode 12, val func loss 0.088669553399086\n",
      "\n",
      "episode 13, val func loss 0.07213147729635239\n",
      "\n",
      "episode 14, val func loss 0.06141558662056923\n",
      "\n",
      "episode 15, val func loss 0.035753827542066574\n",
      "\n",
      "episode 16, val func loss 0.12484341114759445\n",
      "\n",
      "Val func train loss in epoch 5:0.05921431607566774\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.06094008684158325\n",
      "\n",
      "episode 2, val func loss 0.11928769201040268\n",
      "\n",
      "episode 3, val func loss 0.03712073341012001\n",
      "\n",
      "episode 4, val func loss 0.07325717061758041\n",
      "\n",
      "episode 5, val func loss 0.0660831555724144\n",
      "\n",
      "episode 6, val func loss 0.08353076875209808\n",
      "\n",
      "episode 7, val func loss 0.1364802122116089\n",
      "\n",
      "episode 8, val func loss 0.046938735991716385\n",
      "\n",
      "episode 9, val func loss 0.029332105070352554\n",
      "\n",
      "episode 10, val func loss 0.04923875629901886\n",
      "\n",
      "episode 11, val func loss 0.11463619768619537\n",
      "\n",
      "episode 12, val func loss 0.05217795819044113\n",
      "\n",
      "episode 13, val func loss 0.13103491067886353\n",
      "\n",
      "episode 14, val func loss 0.11296894401311874\n",
      "\n",
      "episode 15, val func loss 0.030378520488739014\n",
      "\n",
      "episode 16, val func loss 0.12131155282258987\n",
      "\n",
      "Val func train loss in epoch 6:0.0790448437910527\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1688043177127838\n",
      "\n",
      "episode 2, val func loss 0.09494437277317047\n",
      "\n",
      "episode 3, val func loss 0.22392983734607697\n",
      "\n",
      "episode 4, val func loss 0.040318723767995834\n",
      "\n",
      "episode 5, val func loss 0.1303577721118927\n",
      "\n",
      "episode 6, val func loss 0.1394026279449463\n",
      "\n",
      "episode 7, val func loss 0.04559829458594322\n",
      "\n",
      "episode 8, val func loss 0.12455359101295471\n",
      "\n",
      "episode 9, val func loss 0.10570255666971207\n",
      "\n",
      "episode 10, val func loss 0.05209628492593765\n",
      "\n",
      "episode 11, val func loss 0.16323243081569672\n",
      "\n",
      "episode 12, val func loss 0.024686157703399658\n",
      "\n",
      "episode 13, val func loss 0.02808196097612381\n",
      "\n",
      "episode 14, val func loss 0.04747345671057701\n",
      "\n",
      "episode 15, val func loss 0.0812811478972435\n",
      "\n",
      "episode 16, val func loss 0.02273530326783657\n",
      "\n",
      "Val func train loss in epoch 7:0.09332492726389319\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.03333499655127525\n",
      "\n",
      "episode 2, val func loss 0.1373215913772583\n",
      "\n",
      "episode 3, val func loss 0.10811550915241241\n",
      "\n",
      "episode 4, val func loss 0.11459404975175858\n",
      "\n",
      "episode 5, val func loss 0.1458745300769806\n",
      "\n",
      "episode 6, val func loss 0.03844258561730385\n",
      "\n",
      "episode 7, val func loss 0.09036129713058472\n",
      "\n",
      "episode 8, val func loss 0.02793540246784687\n",
      "\n",
      "episode 9, val func loss 0.11475986242294312\n",
      "\n",
      "episode 10, val func loss 0.05635310336947441\n",
      "\n",
      "episode 11, val func loss 0.10251673310995102\n",
      "\n",
      "episode 12, val func loss 0.05031207948923111\n",
      "\n",
      "episode 13, val func loss 0.051336620002985\n",
      "\n",
      "episode 14, val func loss 0.1648256480693817\n",
      "\n",
      "episode 15, val func loss 0.03852647915482521\n",
      "\n",
      "episode 16, val func loss 0.03941792622208595\n",
      "\n",
      "Val func train loss in epoch 8:0.08212677587289363\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.0717535987496376\n",
      "\n",
      "episode 2, val func loss 0.13072356581687927\n",
      "\n",
      "episode 3, val func loss 0.0915764644742012\n",
      "\n",
      "episode 4, val func loss 0.1658107489347458\n",
      "\n",
      "episode 5, val func loss 0.07363300025463104\n",
      "\n",
      "episode 6, val func loss 0.028609974309802055\n",
      "\n",
      "episode 7, val func loss 0.15395048260688782\n",
      "\n",
      "episode 8, val func loss 0.08815857023000717\n",
      "\n",
      "episode 9, val func loss 0.026305824518203735\n",
      "\n",
      "episode 10, val func loss 0.053867124021053314\n",
      "\n",
      "episode 11, val func loss 0.227480947971344\n",
      "\n",
      "episode 12, val func loss 0.0745619386434555\n",
      "\n",
      "episode 13, val func loss 0.10257190465927124\n",
      "\n",
      "episode 14, val func loss 0.10385730862617493\n",
      "\n",
      "episode 15, val func loss 0.10038133710622787\n",
      "\n",
      "episode 16, val func loss 0.04552421346306801\n",
      "\n",
      "Val func train loss in epoch 9:0.09617293777409941\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.09553292393684387\n",
      "\n",
      "episode 2, val func loss 0.13220857083797455\n",
      "\n",
      "episode 3, val func loss 0.05426076799631119\n",
      "\n",
      "episode 4, val func loss 0.11841591447591782\n",
      "\n",
      "episode 5, val func loss 0.09174521267414093\n",
      "\n",
      "episode 6, val func loss 0.05313262715935707\n",
      "\n",
      "episode 7, val func loss 0.07032288610935211\n",
      "\n",
      "episode 8, val func loss 0.04039020463824272\n",
      "\n",
      "episode 9, val func loss 0.03175872191786766\n",
      "\n",
      "episode 10, val func loss 0.10244900733232498\n",
      "\n",
      "episode 11, val func loss 0.08966786414384842\n",
      "\n",
      "episode 12, val func loss 0.054975271224975586\n",
      "\n",
      "episode 13, val func loss 0.05692261457443237\n",
      "\n",
      "episode 14, val func loss 0.05098237842321396\n",
      "\n",
      "episode 15, val func loss 0.051116399466991425\n",
      "\n",
      "episode 16, val func loss 0.08223303407430649\n",
      "\n",
      "Val func train loss in epoch 10:0.07350714993663132\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.0766015574336052\n",
      "\n",
      "episode 2, val func loss 0.0838920846581459\n",
      "\n",
      "episode 3, val func loss 0.06157952547073364\n",
      "\n",
      "episode 4, val func loss 0.08029010891914368\n",
      "\n",
      "episode 5, val func loss 0.022209012880921364\n",
      "\n",
      "episode 6, val func loss 0.02849612571299076\n",
      "\n",
      "episode 7, val func loss 0.10929952561855316\n",
      "\n",
      "episode 8, val func loss 0.10536433756351471\n",
      "\n",
      "episode 9, val func loss 0.09176868200302124\n",
      "\n",
      "episode 10, val func loss 0.06698831170797348\n",
      "\n",
      "episode 11, val func loss 0.10618821531534195\n",
      "\n",
      "episode 12, val func loss 0.020280681550502777\n",
      "\n",
      "episode 13, val func loss 0.1432333141565323\n",
      "\n",
      "episode 14, val func loss 0.07158395648002625\n",
      "\n",
      "episode 15, val func loss 0.062410350888967514\n",
      "\n",
      "episode 16, val func loss 0.09136239439249039\n",
      "\n",
      "Val func train loss in epoch 11:0.07634676154702902\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.07095803320407867\n",
      "\n",
      "episode 2, val func loss 0.08484897762537003\n",
      "\n",
      "episode 3, val func loss 0.045000165700912476\n",
      "\n",
      "episode 4, val func loss 0.10886546969413757\n",
      "\n",
      "episode 5, val func loss 0.07445146143436432\n",
      "\n",
      "episode 6, val func loss 0.04778991639614105\n",
      "\n",
      "episode 7, val func loss 0.04294427111744881\n",
      "\n",
      "episode 8, val func loss 0.02826300635933876\n",
      "\n",
      "episode 9, val func loss 0.024141430854797363\n",
      "\n",
      "episode 10, val func loss 0.051695313304662704\n",
      "\n",
      "episode 11, val func loss 0.04809587448835373\n",
      "\n",
      "episode 12, val func loss 0.07753638178110123\n",
      "\n",
      "episode 13, val func loss 0.050811946392059326\n",
      "\n",
      "episode 14, val func loss 0.06234127655625343\n",
      "\n",
      "episode 15, val func loss 0.024490730836987495\n",
      "\n",
      "episode 16, val func loss 0.06247932091355324\n",
      "\n",
      "Val func train loss in epoch 12:0.05654459854122251\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.07737411558628082\n",
      "\n",
      "episode 2, val func loss 0.056739699095487595\n",
      "\n",
      "episode 3, val func loss 0.06364615261554718\n",
      "\n",
      "episode 4, val func loss 0.08322066813707352\n",
      "\n",
      "episode 5, val func loss 0.044355351477861404\n",
      "\n",
      "episode 6, val func loss 0.0507127121090889\n",
      "\n",
      "episode 7, val func loss 0.09327932447195053\n",
      "\n",
      "episode 8, val func loss 0.04494727775454521\n",
      "\n",
      "episode 9, val func loss 0.061298780143260956\n",
      "\n",
      "episode 10, val func loss 0.025399522855877876\n",
      "\n",
      "episode 11, val func loss 0.025527741760015488\n",
      "\n",
      "episode 12, val func loss 0.05854906141757965\n",
      "\n",
      "episode 13, val func loss 0.033598192036151886\n",
      "\n",
      "episode 14, val func loss 0.022544970735907555\n",
      "\n",
      "episode 15, val func loss 0.07726451009511948\n",
      "\n",
      "episode 16, val func loss 0.053963154554367065\n",
      "\n",
      "Val func train loss in epoch 13:0.054526327177882195\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.056913744658231735\n",
      "\n",
      "episode 2, val func loss 0.04935663938522339\n",
      "\n",
      "episode 3, val func loss 0.07870111614465714\n",
      "\n",
      "episode 4, val func loss 0.024040259420871735\n",
      "\n",
      "episode 5, val func loss 0.036074765026569366\n",
      "\n",
      "episode 6, val func loss 0.08972520381212234\n",
      "\n",
      "episode 7, val func loss 0.07212340831756592\n",
      "\n",
      "episode 8, val func loss 0.04819193854928017\n",
      "\n",
      "episode 9, val func loss 0.09247048944234848\n",
      "\n",
      "episode 10, val func loss 0.07428165525197983\n",
      "\n",
      "episode 11, val func loss 0.09929738193750381\n",
      "\n",
      "episode 12, val func loss 0.10180839151144028\n",
      "\n",
      "episode 13, val func loss 0.02106812782585621\n",
      "\n",
      "episode 14, val func loss 0.06327001005411148\n",
      "\n",
      "episode 15, val func loss 0.08503804355859756\n",
      "\n",
      "episode 16, val func loss 0.051239013671875\n",
      "\n",
      "Val func train loss in epoch 14:0.06522501178551465\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.053872883319854736\n",
      "\n",
      "episode 2, val func loss 0.11049506813287735\n",
      "\n",
      "episode 3, val func loss 0.04616624861955643\n",
      "\n",
      "episode 4, val func loss 0.04075739160180092\n",
      "\n",
      "episode 5, val func loss 0.06574870645999908\n",
      "\n",
      "episode 6, val func loss 0.024539921432733536\n",
      "\n",
      "episode 7, val func loss 0.048487916588783264\n",
      "\n",
      "episode 8, val func loss 0.020868461579084396\n",
      "\n",
      "episode 9, val func loss 0.04703153669834137\n",
      "\n",
      "episode 10, val func loss 0.11138267070055008\n",
      "\n",
      "episode 11, val func loss 0.06599504500627518\n",
      "\n",
      "episode 12, val func loss 0.12424985319375992\n",
      "\n",
      "episode 13, val func loss 0.059089235961437225\n",
      "\n",
      "episode 14, val func loss 0.07713908702135086\n",
      "\n",
      "episode 15, val func loss 0.0781003087759018\n",
      "\n",
      "episode 16, val func loss 0.029666414484381676\n",
      "\n",
      "Val func train loss in epoch 15:0.06272442184854299\n",
      "***********************TIME WAS 5.268024178345998 min*****************************\n",
      "\n",
      "**********************ROUND 6 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.11071835458278656\n",
      "\n",
      "episode 2, policy loss -0.1264600306749344\n",
      "\n",
      "episode 3, policy loss -0.05898994207382202\n",
      "\n",
      "episode 4, policy loss -0.11300389468669891\n",
      "\n",
      "episode 5, policy loss -0.09648357331752777\n",
      "\n",
      "episode 6, policy loss -0.11935288459062576\n",
      "\n",
      "episode 7, policy loss -0.10151010006666183\n",
      "\n",
      "episode 8, policy loss -0.09116189926862717\n",
      "\n",
      "episode 9, policy loss -0.09502506256103516\n",
      "\n",
      "episode 10, policy loss -0.07954691350460052\n",
      "\n",
      "episode 11, policy loss -0.12542343139648438\n",
      "\n",
      "episode 12, policy loss -0.12579217553138733\n",
      "\n",
      "episode 13, policy loss -0.121608667075634\n",
      "\n",
      "episode 14, policy loss -0.0945645347237587\n",
      "\n",
      "episode 15, policy loss -0.08532692492008209\n",
      "\n",
      "episode 16, policy loss -0.09962264448404312\n",
      "\n",
      "Policy train loss in epoch 0:-0.10278693959116936\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.07978601008653641\n",
      "\n",
      "episode 2, policy loss -0.09786534309387207\n",
      "\n",
      "episode 3, policy loss -0.12708403170108795\n",
      "\n",
      "episode 4, policy loss -0.09702141582965851\n",
      "\n",
      "episode 5, policy loss -0.090617835521698\n",
      "\n",
      "episode 6, policy loss -0.12596428394317627\n",
      "\n",
      "episode 7, policy loss -0.12380344420671463\n",
      "\n",
      "episode 8, policy loss -0.09581179916858673\n",
      "\n",
      "episode 9, policy loss -0.08770108968019485\n",
      "\n",
      "episode 10, policy loss -0.11713965982198715\n",
      "\n",
      "episode 11, policy loss -0.1227533295750618\n",
      "\n",
      "episode 12, policy loss -0.10452038049697876\n",
      "\n",
      "episode 13, policy loss -0.05891003832221031\n",
      "\n",
      "episode 14, policy loss -0.0923033133149147\n",
      "\n",
      "episode 15, policy loss -0.1123199537396431\n",
      "\n",
      "episode 16, policy loss -0.11408396810293198\n",
      "\n",
      "Policy train loss in epoch 1:-0.10298036853782833\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.13142631947994232\n",
      "\n",
      "episode 2, policy loss -0.0863238051533699\n",
      "\n",
      "episode 3, policy loss -0.08901006728410721\n",
      "\n",
      "episode 4, policy loss -0.09226031601428986\n",
      "\n",
      "episode 5, policy loss -0.1120205968618393\n",
      "\n",
      "episode 6, policy loss -0.10081350803375244\n",
      "\n",
      "episode 7, policy loss -0.12153653800487518\n",
      "\n",
      "episode 8, policy loss -0.1042899638414383\n",
      "\n",
      "episode 9, policy loss -0.08047527819871902\n",
      "\n",
      "episode 10, policy loss -0.12762238085269928\n",
      "\n",
      "episode 11, policy loss -0.12303851544857025\n",
      "\n",
      "episode 12, policy loss -0.09768587350845337\n",
      "\n",
      "episode 13, policy loss -0.059882037341594696\n",
      "\n",
      "episode 14, policy loss -0.09701908379793167\n",
      "\n",
      "episode 15, policy loss -0.12287086248397827\n",
      "\n",
      "episode 16, policy loss -0.11414636671543121\n",
      "\n",
      "Policy train loss in epoch 2:-0.10377634456381202\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.10565800219774246\n",
      "\n",
      "episode 2, policy loss -0.09131990373134613\n",
      "\n",
      "episode 3, policy loss -0.0838850736618042\n",
      "\n",
      "episode 4, policy loss -0.11344669759273529\n",
      "\n",
      "episode 5, policy loss -0.12428728491067886\n",
      "\n",
      "episode 6, policy loss -0.06149331480264664\n",
      "\n",
      "episode 7, policy loss -0.11428418755531311\n",
      "\n",
      "episode 8, policy loss -0.12285692989826202\n",
      "\n",
      "episode 9, policy loss -0.09641929715871811\n",
      "\n",
      "episode 10, policy loss -0.10161574184894562\n",
      "\n",
      "episode 11, policy loss -0.12118548154830933\n",
      "\n",
      "episode 12, policy loss -0.07925485074520111\n",
      "\n",
      "episode 13, policy loss -0.12681016325950623\n",
      "\n",
      "episode 14, policy loss -0.12536656856536865\n",
      "\n",
      "episode 15, policy loss -0.0916975736618042\n",
      "\n",
      "episode 16, policy loss -0.09651730209589005\n",
      "\n",
      "Policy train loss in epoch 3:-0.103506148327142\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.08015863597393036\n",
      "\n",
      "episode 2, val func loss 0.06492701172828674\n",
      "\n",
      "episode 3, val func loss 0.2427690029144287\n",
      "\n",
      "episode 4, val func loss 0.17479422688484192\n",
      "\n",
      "episode 5, val func loss 0.2186039686203003\n",
      "\n",
      "episode 6, val func loss 0.03547339886426926\n",
      "\n",
      "episode 7, val func loss 0.10716398805379868\n",
      "\n",
      "episode 8, val func loss 0.13799943029880524\n",
      "\n",
      "episode 9, val func loss 0.07487979531288147\n",
      "\n",
      "episode 10, val func loss 0.11191891878843307\n",
      "\n",
      "episode 11, val func loss 0.06833244860172272\n",
      "\n",
      "episode 12, val func loss 0.052097685635089874\n",
      "\n",
      "episode 13, val func loss 0.07697451859712601\n",
      "\n",
      "episode 14, val func loss 0.05345733463764191\n",
      "\n",
      "episode 15, val func loss 0.06922818720340729\n",
      "\n",
      "episode 16, val func loss 0.11478050798177719\n",
      "\n",
      "Val func train loss in epoch 0:0.1052224412560463\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.07021304219961166\n",
      "\n",
      "episode 2, val func loss 0.10074897855520248\n",
      "\n",
      "episode 3, val func loss 0.07504064589738846\n",
      "\n",
      "episode 4, val func loss 0.0726044550538063\n",
      "\n",
      "episode 5, val func loss 0.09079129248857498\n",
      "\n",
      "episode 6, val func loss 0.0662945806980133\n",
      "\n",
      "episode 7, val func loss 0.079962819814682\n",
      "\n",
      "episode 8, val func loss 0.05332227423787117\n",
      "\n",
      "episode 9, val func loss 0.08309692144393921\n",
      "\n",
      "episode 10, val func loss 0.06461319327354431\n",
      "\n",
      "episode 11, val func loss 0.036863479763269424\n",
      "\n",
      "episode 12, val func loss 0.10008710622787476\n",
      "\n",
      "episode 13, val func loss 0.09716399013996124\n",
      "\n",
      "episode 14, val func loss 0.09526660293340683\n",
      "\n",
      "episode 15, val func loss 0.2008875608444214\n",
      "\n",
      "episode 16, val func loss 0.060585759580135345\n",
      "\n",
      "Val func train loss in epoch 1:0.08422141894698143\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.13080744445323944\n",
      "\n",
      "episode 2, val func loss 0.1381245106458664\n",
      "\n",
      "episode 3, val func loss 0.10761480033397675\n",
      "\n",
      "episode 4, val func loss 0.07345551252365112\n",
      "\n",
      "episode 5, val func loss 0.08872150629758835\n",
      "\n",
      "episode 6, val func loss 0.08178453892469406\n",
      "\n",
      "episode 7, val func loss 0.06587271392345428\n",
      "\n",
      "episode 8, val func loss 0.09462185949087143\n",
      "\n",
      "episode 9, val func loss 0.06738798320293427\n",
      "\n",
      "episode 10, val func loss 0.060165759176015854\n",
      "\n",
      "episode 11, val func loss 0.06041800230741501\n",
      "\n",
      "episode 12, val func loss 0.05368572846055031\n",
      "\n",
      "episode 13, val func loss 0.08024337887763977\n",
      "\n",
      "episode 14, val func loss 0.07856690883636475\n",
      "\n",
      "episode 15, val func loss 0.08780291676521301\n",
      "\n",
      "episode 16, val func loss 0.09934122860431671\n",
      "\n",
      "Val func train loss in epoch 2:0.08553842455148697\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.05371030792593956\n",
      "\n",
      "episode 2, val func loss 0.09791801124811172\n",
      "\n",
      "episode 3, val func loss 0.07107896357774734\n",
      "\n",
      "episode 4, val func loss 0.07339426875114441\n",
      "\n",
      "episode 5, val func loss 0.03647944703698158\n",
      "\n",
      "episode 6, val func loss 0.0902094841003418\n",
      "\n",
      "episode 7, val func loss 0.07062426209449768\n",
      "\n",
      "episode 8, val func loss 0.06929823011159897\n",
      "\n",
      "episode 9, val func loss 0.05923137441277504\n",
      "\n",
      "episode 10, val func loss 0.08796455711126328\n",
      "\n",
      "episode 11, val func loss 0.05620858073234558\n",
      "\n",
      "episode 12, val func loss 0.09317903965711594\n",
      "\n",
      "episode 13, val func loss 0.0596802644431591\n",
      "\n",
      "episode 14, val func loss 0.08376774936914444\n",
      "\n",
      "episode 15, val func loss 0.10811097174882889\n",
      "\n",
      "episode 16, val func loss 0.05735745653510094\n",
      "\n",
      "Val func train loss in epoch 3:0.07301331055350602\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.03406066820025444\n",
      "\n",
      "episode 2, val func loss 0.08790672570466995\n",
      "\n",
      "episode 3, val func loss 0.0915486067533493\n",
      "\n",
      "episode 4, val func loss 0.07664629817008972\n",
      "\n",
      "episode 5, val func loss 0.08422309905290604\n",
      "\n",
      "episode 6, val func loss 0.07045670598745346\n",
      "\n",
      "episode 7, val func loss 0.12476471066474915\n",
      "\n",
      "episode 8, val func loss 0.07910303771495819\n",
      "\n",
      "episode 9, val func loss 0.10207459330558777\n",
      "\n",
      "episode 10, val func loss 0.09243201464414597\n",
      "\n",
      "episode 11, val func loss 0.05401509255170822\n",
      "\n",
      "episode 12, val func loss 0.09751956909894943\n",
      "\n",
      "episode 13, val func loss 0.05134280025959015\n",
      "\n",
      "episode 14, val func loss 0.08988305926322937\n",
      "\n",
      "episode 15, val func loss 0.05905092880129814\n",
      "\n",
      "episode 16, val func loss 0.059940703213214874\n",
      "\n",
      "Val func train loss in epoch 4:0.07843553833663464\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.056175604462623596\n",
      "\n",
      "episode 2, val func loss 0.079327292740345\n",
      "\n",
      "episode 3, val func loss 0.059504251927137375\n",
      "\n",
      "episode 4, val func loss 0.05578635260462761\n",
      "\n",
      "episode 5, val func loss 0.08326096832752228\n",
      "\n",
      "episode 6, val func loss 0.0667816549539566\n",
      "\n",
      "episode 7, val func loss 0.06022604927420616\n",
      "\n",
      "episode 8, val func loss 0.03543895110487938\n",
      "\n",
      "episode 9, val func loss 0.09896767139434814\n",
      "\n",
      "episode 10, val func loss 0.0781511440873146\n",
      "\n",
      "episode 11, val func loss 0.06073068827390671\n",
      "\n",
      "episode 12, val func loss 0.056206993758678436\n",
      "\n",
      "episode 13, val func loss 0.07755938172340393\n",
      "\n",
      "episode 14, val func loss 0.07017625123262405\n",
      "\n",
      "episode 15, val func loss 0.09127065539360046\n",
      "\n",
      "episode 16, val func loss 0.09588410705327988\n",
      "\n",
      "Val func train loss in epoch 5:0.07034050114452839\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.06759107857942581\n",
      "\n",
      "episode 2, val func loss 0.06621534377336502\n",
      "\n",
      "episode 3, val func loss 0.05777831748127937\n",
      "\n",
      "episode 4, val func loss 0.0786634311079979\n",
      "\n",
      "episode 5, val func loss 0.055922918021678925\n",
      "\n",
      "episode 6, val func loss 0.06463895738124847\n",
      "\n",
      "episode 7, val func loss 0.09917112439870834\n",
      "\n",
      "episode 8, val func loss 0.05188683792948723\n",
      "\n",
      "episode 9, val func loss 0.07998645305633545\n",
      "\n",
      "episode 10, val func loss 0.06238827481865883\n",
      "\n",
      "episode 11, val func loss 0.05906737595796585\n",
      "\n",
      "episode 12, val func loss 0.08598557859659195\n",
      "\n",
      "episode 13, val func loss 0.03634705767035484\n",
      "\n",
      "episode 14, val func loss 0.07988505810499191\n",
      "\n",
      "episode 15, val func loss 0.09709183126688004\n",
      "\n",
      "episode 16, val func loss 0.0662241131067276\n",
      "\n",
      "Val func train loss in epoch 6:0.0693027344532311\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.055347781628370285\n",
      "\n",
      "episode 2, val func loss 0.0961286649107933\n",
      "\n",
      "episode 3, val func loss 0.05073625221848488\n",
      "\n",
      "episode 4, val func loss 0.14673283696174622\n",
      "\n",
      "episode 5, val func loss 0.0705559030175209\n",
      "\n",
      "episode 6, val func loss 0.1566345989704132\n",
      "\n",
      "episode 7, val func loss 0.08850989490747452\n",
      "\n",
      "episode 8, val func loss 0.09741676598787308\n",
      "\n",
      "episode 9, val func loss 0.15377193689346313\n",
      "\n",
      "episode 10, val func loss 0.057879626750946045\n",
      "\n",
      "episode 11, val func loss 0.06786802411079407\n",
      "\n",
      "episode 12, val func loss 0.0917353555560112\n",
      "\n",
      "episode 13, val func loss 0.03345272317528725\n",
      "\n",
      "episode 14, val func loss 0.05682746320962906\n",
      "\n",
      "episode 15, val func loss 0.08527719974517822\n",
      "\n",
      "episode 16, val func loss 0.09046658128499985\n",
      "\n",
      "Val func train loss in epoch 7:0.08745885058306158\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.0776367112994194\n",
      "\n",
      "episode 2, val func loss 0.09883683174848557\n",
      "\n",
      "episode 3, val func loss 0.1371268779039383\n",
      "\n",
      "episode 4, val func loss 0.06674613058567047\n",
      "\n",
      "episode 5, val func loss 0.10680095106363297\n",
      "\n",
      "episode 6, val func loss 0.051220159977674484\n",
      "\n",
      "episode 7, val func loss 0.05355711653828621\n",
      "\n",
      "episode 8, val func loss 0.0777917355298996\n",
      "\n",
      "episode 9, val func loss 0.10340011119842529\n",
      "\n",
      "episode 10, val func loss 0.05361071974039078\n",
      "\n",
      "episode 11, val func loss 0.03839005529880524\n",
      "\n",
      "episode 12, val func loss 0.0541246272623539\n",
      "\n",
      "episode 13, val func loss 0.056000273674726486\n",
      "\n",
      "episode 14, val func loss 0.06752106547355652\n",
      "\n",
      "episode 15, val func loss 0.10057827830314636\n",
      "\n",
      "episode 16, val func loss 0.0751553401350975\n",
      "\n",
      "Val func train loss in epoch 8:0.07615606160834432\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.05558067932724953\n",
      "\n",
      "episode 2, val func loss 0.05707269161939621\n",
      "\n",
      "episode 3, val func loss 0.07991743087768555\n",
      "\n",
      "episode 4, val func loss 0.07522913813591003\n",
      "\n",
      "episode 5, val func loss 0.08119743317365646\n",
      "\n",
      "episode 6, val func loss 0.08432457596063614\n",
      "\n",
      "episode 7, val func loss 0.06555147469043732\n",
      "\n",
      "episode 8, val func loss 0.052787549793720245\n",
      "\n",
      "episode 9, val func loss 0.050604548305273056\n",
      "\n",
      "episode 10, val func loss 0.09541868418455124\n",
      "\n",
      "episode 11, val func loss 0.03785288333892822\n",
      "\n",
      "episode 12, val func loss 0.09852377325296402\n",
      "\n",
      "episode 13, val func loss 0.06789588183164597\n",
      "\n",
      "episode 14, val func loss 0.08003992587327957\n",
      "\n",
      "episode 15, val func loss 0.06787069141864777\n",
      "\n",
      "episode 16, val func loss 0.10607010871171951\n",
      "\n",
      "Val func train loss in epoch 9:0.0722460919059813\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.0560099296271801\n",
      "\n",
      "episode 2, val func loss 0.1364731788635254\n",
      "\n",
      "episode 3, val func loss 0.0690830871462822\n",
      "\n",
      "episode 4, val func loss 0.0887383297085762\n",
      "\n",
      "episode 5, val func loss 0.052175771445035934\n",
      "\n",
      "episode 6, val func loss 0.10215535759925842\n",
      "\n",
      "episode 7, val func loss 0.08064182847738266\n",
      "\n",
      "episode 8, val func loss 0.10049451142549515\n",
      "\n",
      "episode 9, val func loss 0.05091511085629463\n",
      "\n",
      "episode 10, val func loss 0.0881001427769661\n",
      "\n",
      "episode 11, val func loss 0.08548539876937866\n",
      "\n",
      "episode 12, val func loss 0.058836501091718674\n",
      "\n",
      "episode 13, val func loss 0.05646038055419922\n",
      "\n",
      "episode 14, val func loss 0.14370018243789673\n",
      "\n",
      "episode 15, val func loss 0.08100296556949615\n",
      "\n",
      "episode 16, val func loss 0.09557855129241943\n",
      "\n",
      "Val func train loss in epoch 10:0.0841157017275691\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.12169771641492844\n",
      "\n",
      "episode 2, val func loss 0.0527576208114624\n",
      "\n",
      "episode 3, val func loss 0.10046510398387909\n",
      "\n",
      "episode 4, val func loss 0.10408753901720047\n",
      "\n",
      "episode 5, val func loss 0.057142291218042374\n",
      "\n",
      "episode 6, val func loss 0.06944488734006882\n",
      "\n",
      "episode 7, val func loss 0.03662976622581482\n",
      "\n",
      "episode 8, val func loss 0.0667417049407959\n",
      "\n",
      "episode 9, val func loss 0.051485709846019745\n",
      "\n",
      "episode 10, val func loss 0.0738716572523117\n",
      "\n",
      "episode 11, val func loss 0.11283084750175476\n",
      "\n",
      "episode 12, val func loss 0.08475681394338608\n",
      "\n",
      "episode 13, val func loss 0.1614208221435547\n",
      "\n",
      "episode 14, val func loss 0.13154631853103638\n",
      "\n",
      "episode 15, val func loss 0.09760215878486633\n",
      "\n",
      "episode 16, val func loss 0.21269512176513672\n",
      "\n",
      "Val func train loss in epoch 11:0.09594850498251617\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.07393952459096909\n",
      "\n",
      "episode 2, val func loss 0.14676573872566223\n",
      "\n",
      "episode 3, val func loss 0.15482553839683533\n",
      "\n",
      "episode 4, val func loss 0.0516493022441864\n",
      "\n",
      "episode 5, val func loss 0.11278512328863144\n",
      "\n",
      "episode 6, val func loss 0.09348789602518082\n",
      "\n",
      "episode 7, val func loss 0.033538591116666794\n",
      "\n",
      "episode 8, val func loss 0.13337543606758118\n",
      "\n",
      "episode 9, val func loss 0.052580736577510834\n",
      "\n",
      "episode 10, val func loss 0.06140143424272537\n",
      "\n",
      "episode 11, val func loss 0.06194404512643814\n",
      "\n",
      "episode 12, val func loss 0.1385870724916458\n",
      "\n",
      "episode 13, val func loss 0.0563373938202858\n",
      "\n",
      "episode 14, val func loss 0.12879274785518646\n",
      "\n",
      "episode 15, val func loss 0.09232138842344284\n",
      "\n",
      "episode 16, val func loss 0.06908480823040009\n",
      "\n",
      "Val func train loss in epoch 12:0.09133854857645929\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.10609608143568039\n",
      "\n",
      "episode 2, val func loss 0.054841943085193634\n",
      "\n",
      "episode 3, val func loss 0.09048327058553696\n",
      "\n",
      "episode 4, val func loss 0.08144260942935944\n",
      "\n",
      "episode 5, val func loss 0.0771375447511673\n",
      "\n",
      "episode 6, val func loss 0.05125628784298897\n",
      "\n",
      "episode 7, val func loss 0.07795771211385727\n",
      "\n",
      "episode 8, val func loss 0.05236457288265228\n",
      "\n",
      "episode 9, val func loss 0.06937244534492493\n",
      "\n",
      "episode 10, val func loss 0.10024482756853104\n",
      "\n",
      "episode 11, val func loss 0.05481072887778282\n",
      "\n",
      "episode 12, val func loss 0.06114538386464119\n",
      "\n",
      "episode 13, val func loss 0.06646209210157394\n",
      "\n",
      "episode 14, val func loss 0.06961531192064285\n",
      "\n",
      "episode 15, val func loss 0.03458850085735321\n",
      "\n",
      "episode 16, val func loss 0.10210820287466049\n",
      "\n",
      "Val func train loss in epoch 13:0.07187046972103417\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.059245917946100235\n",
      "\n",
      "episode 2, val func loss 0.08557480573654175\n",
      "\n",
      "episode 3, val func loss 0.08158649504184723\n",
      "\n",
      "episode 4, val func loss 0.06452871859073639\n",
      "\n",
      "episode 5, val func loss 0.05615910515189171\n",
      "\n",
      "episode 6, val func loss 0.056554436683654785\n",
      "\n",
      "episode 7, val func loss 0.053773727267980576\n",
      "\n",
      "episode 8, val func loss 0.13221082091331482\n",
      "\n",
      "episode 9, val func loss 0.06897123903036118\n",
      "\n",
      "episode 10, val func loss 0.08666452020406723\n",
      "\n",
      "episode 11, val func loss 0.03534833341836929\n",
      "\n",
      "episode 12, val func loss 0.05497695133090019\n",
      "\n",
      "episode 13, val func loss 0.07856978476047516\n",
      "\n",
      "episode 14, val func loss 0.07208326458930969\n",
      "\n",
      "episode 15, val func loss 0.10088954120874405\n",
      "\n",
      "episode 16, val func loss 0.08890340477228165\n",
      "\n",
      "Val func train loss in epoch 14:0.073502566665411\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.11444318294525146\n",
      "\n",
      "episode 2, val func loss 0.08528075367212296\n",
      "\n",
      "episode 3, val func loss 0.09621230512857437\n",
      "\n",
      "episode 4, val func loss 0.1135614737868309\n",
      "\n",
      "episode 5, val func loss 0.1226736456155777\n",
      "\n",
      "episode 6, val func loss 0.10230978578329086\n",
      "\n",
      "episode 7, val func loss 0.07023291289806366\n",
      "\n",
      "episode 8, val func loss 0.08382642269134521\n",
      "\n",
      "episode 9, val func loss 0.07726016640663147\n",
      "\n",
      "episode 10, val func loss 0.03925086557865143\n",
      "\n",
      "episode 11, val func loss 0.11685815453529358\n",
      "\n",
      "episode 12, val func loss 0.08419738709926605\n",
      "\n",
      "episode 13, val func loss 0.06398230791091919\n",
      "\n",
      "episode 14, val func loss 0.06797538697719574\n",
      "\n",
      "episode 15, val func loss 0.0761386975646019\n",
      "\n",
      "episode 16, val func loss 0.07772485911846161\n",
      "\n",
      "Val func train loss in epoch 15:0.08699551923200488\n",
      "***********************TIME WAS 5.26044579744339 min*****************************\n",
      "\n",
      "**********************ROUND 7 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.0524418018758297\n",
      "\n",
      "episode 2, policy loss -0.04108358174562454\n",
      "\n",
      "episode 3, policy loss -0.0662359818816185\n",
      "\n",
      "episode 4, policy loss -0.09985455125570297\n",
      "\n",
      "episode 5, policy loss -0.10704232007265091\n",
      "\n",
      "episode 6, policy loss -0.038376376032829285\n",
      "\n",
      "episode 7, policy loss -0.06814874708652496\n",
      "\n",
      "episode 8, policy loss -0.04392436891794205\n",
      "\n",
      "episode 9, policy loss -0.051482461392879486\n",
      "\n",
      "episode 10, policy loss -0.09658802300691605\n",
      "\n",
      "episode 11, policy loss -0.024894677102565765\n",
      "\n",
      "episode 12, policy loss -0.07993750274181366\n",
      "\n",
      "episode 13, policy loss -0.068034328520298\n",
      "\n",
      "episode 14, policy loss -0.08936179429292679\n",
      "\n",
      "episode 15, policy loss -0.04029122740030289\n",
      "\n",
      "episode 16, policy loss -0.023273691534996033\n",
      "\n",
      "Policy train loss in epoch 0:-0.06193571467883885\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.07719138264656067\n",
      "\n",
      "episode 2, policy loss -0.07040317356586456\n",
      "\n",
      "episode 3, policy loss -0.02496672421693802\n",
      "\n",
      "episode 4, policy loss -0.02364267408847809\n",
      "\n",
      "episode 5, policy loss -0.06979574263095856\n",
      "\n",
      "episode 6, policy loss -0.038828372955322266\n",
      "\n",
      "episode 7, policy loss -0.05602885037660599\n",
      "\n",
      "episode 8, policy loss -0.05649840831756592\n",
      "\n",
      "episode 9, policy loss -0.10002056509256363\n",
      "\n",
      "episode 10, policy loss -0.03960759565234184\n",
      "\n",
      "episode 11, policy loss -0.05096939206123352\n",
      "\n",
      "episode 12, policy loss -0.06780760735273361\n",
      "\n",
      "episode 13, policy loss -0.08721953630447388\n",
      "\n",
      "episode 14, policy loss -0.1082015112042427\n",
      "\n",
      "episode 15, policy loss -0.09730186313390732\n",
      "\n",
      "episode 16, policy loss -0.04073222354054451\n",
      "\n",
      "Policy train loss in epoch 1:-0.06307597644627094\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.06389971822500229\n",
      "\n",
      "episode 2, policy loss -0.07701339572668076\n",
      "\n",
      "episode 3, policy loss -0.09413938224315643\n",
      "\n",
      "episode 4, policy loss -0.03837863355875015\n",
      "\n",
      "episode 5, policy loss -0.1003376916050911\n",
      "\n",
      "episode 6, policy loss -0.026828404515981674\n",
      "\n",
      "episode 7, policy loss -0.02337506413459778\n",
      "\n",
      "episode 8, policy loss -0.06824658811092377\n",
      "\n",
      "episode 9, policy loss -0.08898072689771652\n",
      "\n",
      "episode 10, policy loss -0.04332759231328964\n",
      "\n",
      "episode 11, policy loss -0.10599352419376373\n",
      "\n",
      "episode 12, policy loss -0.052374664694070816\n",
      "\n",
      "episode 13, policy loss -0.06881996989250183\n",
      "\n",
      "episode 14, policy loss -0.04152300953865051\n",
      "\n",
      "episode 15, policy loss -0.04871964082121849\n",
      "\n",
      "episode 16, policy loss -0.05152411758899689\n",
      "\n",
      "Policy train loss in epoch 2:-0.062092632753774524\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.07750073075294495\n",
      "\n",
      "episode 2, policy loss -0.08833971619606018\n",
      "\n",
      "episode 3, policy loss -0.06534479558467865\n",
      "\n",
      "episode 4, policy loss -0.02440813183784485\n",
      "\n",
      "episode 5, policy loss -0.03840786591172218\n",
      "\n",
      "episode 6, policy loss -0.04048333689570427\n",
      "\n",
      "episode 7, policy loss -0.025483019649982452\n",
      "\n",
      "episode 8, policy loss -0.09594814479351044\n",
      "\n",
      "episode 9, policy loss -0.09574979543685913\n",
      "\n",
      "episode 10, policy loss -0.05012219399213791\n",
      "\n",
      "episode 11, policy loss -0.06764446198940277\n",
      "\n",
      "episode 12, policy loss -0.04700075089931488\n",
      "\n",
      "episode 13, policy loss -0.06901820003986359\n",
      "\n",
      "episode 14, policy loss -0.10102804005146027\n",
      "\n",
      "episode 15, policy loss -0.044973619282245636\n",
      "\n",
      "episode 16, policy loss -0.03694205358624458\n",
      "\n",
      "Policy train loss in epoch 3:-0.060524678556248546\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.06845872104167938\n",
      "\n",
      "episode 2, val func loss 0.13938511908054352\n",
      "\n",
      "episode 3, val func loss 0.11228416115045547\n",
      "\n",
      "episode 4, val func loss 0.08867674320936203\n",
      "\n",
      "episode 5, val func loss 0.11181656271219254\n",
      "\n",
      "episode 6, val func loss 0.06957840919494629\n",
      "\n",
      "episode 7, val func loss 0.06958790868520737\n",
      "\n",
      "episode 8, val func loss 0.16333499550819397\n",
      "\n",
      "episode 9, val func loss 0.07726592570543289\n",
      "\n",
      "episode 10, val func loss 0.05648982152342796\n",
      "\n",
      "episode 11, val func loss 0.1448230892419815\n",
      "\n",
      "episode 12, val func loss 0.08633975684642792\n",
      "\n",
      "episode 13, val func loss 0.08962922543287277\n",
      "\n",
      "episode 14, val func loss 0.10889870673418045\n",
      "\n",
      "episode 15, val func loss 0.09188959747552872\n",
      "\n",
      "episode 16, val func loss 0.13215984404087067\n",
      "\n",
      "Val func train loss in epoch 0:0.10066366172395647\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1312522441148758\n",
      "\n",
      "episode 2, val func loss 0.0731571689248085\n",
      "\n",
      "episode 3, val func loss 0.06792054325342178\n",
      "\n",
      "episode 4, val func loss 0.14019526541233063\n",
      "\n",
      "episode 5, val func loss 0.10112648457288742\n",
      "\n",
      "episode 6, val func loss 0.11824488639831543\n",
      "\n",
      "episode 7, val func loss 0.14390330016613007\n",
      "\n",
      "episode 8, val func loss 0.06142646446824074\n",
      "\n",
      "episode 9, val func loss 0.11080019921064377\n",
      "\n",
      "episode 10, val func loss 0.07989207655191422\n",
      "\n",
      "episode 11, val func loss 0.09230968356132507\n",
      "\n",
      "episode 12, val func loss 0.08035241812467575\n",
      "\n",
      "episode 13, val func loss 0.09009819477796555\n",
      "\n",
      "episode 14, val func loss 0.13507403433322906\n",
      "\n",
      "episode 15, val func loss 0.06886734068393707\n",
      "\n",
      "episode 16, val func loss 0.08409969508647919\n",
      "\n",
      "Val func train loss in epoch 1:0.09866999997757375\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.08557487279176712\n",
      "\n",
      "episode 2, val func loss 0.07001593708992004\n",
      "\n",
      "episode 3, val func loss 0.09654346108436584\n",
      "\n",
      "episode 4, val func loss 0.13833767175674438\n",
      "\n",
      "episode 5, val func loss 0.10637540370225906\n",
      "\n",
      "episode 6, val func loss 0.07057126611471176\n",
      "\n",
      "episode 7, val func loss 0.10287286341190338\n",
      "\n",
      "episode 8, val func loss 0.07305113971233368\n",
      "\n",
      "episode 9, val func loss 0.08271630853414536\n",
      "\n",
      "episode 10, val func loss 0.1251755803823471\n",
      "\n",
      "episode 11, val func loss 0.07816648483276367\n",
      "\n",
      "episode 12, val func loss 0.09236661344766617\n",
      "\n",
      "episode 13, val func loss 0.09658778458833694\n",
      "\n",
      "episode 14, val func loss 0.05676385760307312\n",
      "\n",
      "episode 15, val func loss 0.12887714803218842\n",
      "\n",
      "episode 16, val func loss 0.08063407987356186\n",
      "\n",
      "Val func train loss in epoch 2:0.0927894045598805\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.10257735848426819\n",
      "\n",
      "episode 2, val func loss 0.06872507929801941\n",
      "\n",
      "episode 3, val func loss 0.1249520480632782\n",
      "\n",
      "episode 4, val func loss 0.06627436727285385\n",
      "\n",
      "episode 5, val func loss 0.07377171516418457\n",
      "\n",
      "episode 6, val func loss 0.0885569229722023\n",
      "\n",
      "episode 7, val func loss 0.09479701519012451\n",
      "\n",
      "episode 8, val func loss 0.05493063107132912\n",
      "\n",
      "episode 9, val func loss 0.07594410330057144\n",
      "\n",
      "episode 10, val func loss 0.11717004328966141\n",
      "\n",
      "episode 11, val func loss 0.12442456185817719\n",
      "\n",
      "episode 12, val func loss 0.08359689265489578\n",
      "\n",
      "episode 13, val func loss 0.09361817687749863\n",
      "\n",
      "episode 14, val func loss 0.09061948955059052\n",
      "\n",
      "episode 15, val func loss 0.08341432362794876\n",
      "\n",
      "episode 16, val func loss 0.0714465007185936\n",
      "\n",
      "Val func train loss in epoch 3:0.08842620183713734\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.11131426692008972\n",
      "\n",
      "episode 2, val func loss 0.07263130694627762\n",
      "\n",
      "episode 3, val func loss 0.05404934659600258\n",
      "\n",
      "episode 4, val func loss 0.0771476998925209\n",
      "\n",
      "episode 5, val func loss 0.1226763054728508\n",
      "\n",
      "episode 6, val func loss 0.08023405075073242\n",
      "\n",
      "episode 7, val func loss 0.09454035013914108\n",
      "\n",
      "episode 8, val func loss 0.08681564033031464\n",
      "\n",
      "episode 9, val func loss 0.09063934534788132\n",
      "\n",
      "episode 10, val func loss 0.06789115816354752\n",
      "\n",
      "episode 11, val func loss 0.13294506072998047\n",
      "\n",
      "episode 12, val func loss 0.06482251733541489\n",
      "\n",
      "episode 13, val func loss 0.090175099670887\n",
      "\n",
      "episode 14, val func loss 0.10546188801527023\n",
      "\n",
      "episode 15, val func loss 0.0714181512594223\n",
      "\n",
      "episode 16, val func loss 0.1123223602771759\n",
      "\n",
      "Val func train loss in epoch 4:0.08969278424046934\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.11202333122491837\n",
      "\n",
      "episode 2, val func loss 0.0781923457980156\n",
      "\n",
      "episode 3, val func loss 0.07367953658103943\n",
      "\n",
      "episode 4, val func loss 0.11737194657325745\n",
      "\n",
      "episode 5, val func loss 0.12106373906135559\n",
      "\n",
      "episode 6, val func loss 0.15840506553649902\n",
      "\n",
      "episode 7, val func loss 0.0773819163441658\n",
      "\n",
      "episode 8, val func loss 0.10279260575771332\n",
      "\n",
      "episode 9, val func loss 0.08425044268369675\n",
      "\n",
      "episode 10, val func loss 0.07862255722284317\n",
      "\n",
      "episode 11, val func loss 0.07359208166599274\n",
      "\n",
      "episode 12, val func loss 0.06677520275115967\n",
      "\n",
      "episode 13, val func loss 0.12092669308185577\n",
      "\n",
      "episode 14, val func loss 0.12447632849216461\n",
      "\n",
      "episode 15, val func loss 0.10596219450235367\n",
      "\n",
      "episode 16, val func loss 0.058222584426403046\n",
      "\n",
      "Val func train loss in epoch 5:0.09710866073146462\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1395369917154312\n",
      "\n",
      "episode 2, val func loss 0.07576735317707062\n",
      "\n",
      "episode 3, val func loss 0.1162925511598587\n",
      "\n",
      "episode 4, val func loss 0.1373721808195114\n",
      "\n",
      "episode 5, val func loss 0.08384665846824646\n",
      "\n",
      "episode 6, val func loss 0.10713881999254227\n",
      "\n",
      "episode 7, val func loss 0.09200087934732437\n",
      "\n",
      "episode 8, val func loss 0.06027090176939964\n",
      "\n",
      "episode 9, val func loss 0.09466491639614105\n",
      "\n",
      "episode 10, val func loss 0.12269866466522217\n",
      "\n",
      "episode 11, val func loss 0.07732661813497543\n",
      "\n",
      "episode 12, val func loss 0.05728770047426224\n",
      "\n",
      "episode 13, val func loss 0.08635322004556656\n",
      "\n",
      "episode 14, val func loss 0.09687081724405289\n",
      "\n",
      "episode 15, val func loss 0.06805560737848282\n",
      "\n",
      "episode 16, val func loss 0.14024674892425537\n",
      "\n",
      "Val func train loss in epoch 6:0.09723316435702145\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.07156271487474442\n",
      "\n",
      "episode 2, val func loss 0.12444291263818741\n",
      "\n",
      "episode 3, val func loss 0.09826943278312683\n",
      "\n",
      "episode 4, val func loss 0.07239881902933121\n",
      "\n",
      "episode 5, val func loss 0.07675988227128983\n",
      "\n",
      "episode 6, val func loss 0.0804109275341034\n",
      "\n",
      "episode 7, val func loss 0.1110200509428978\n",
      "\n",
      "episode 8, val func loss 0.1356624811887741\n",
      "\n",
      "episode 9, val func loss 0.09765338897705078\n",
      "\n",
      "episode 10, val func loss 0.09159258008003235\n",
      "\n",
      "episode 11, val func loss 0.09234044700860977\n",
      "\n",
      "episode 12, val func loss 0.05343463644385338\n",
      "\n",
      "episode 13, val func loss 0.1441015601158142\n",
      "\n",
      "episode 14, val func loss 0.06943745166063309\n",
      "\n",
      "episode 15, val func loss 0.1133277416229248\n",
      "\n",
      "episode 16, val func loss 0.10563431680202484\n",
      "\n",
      "Val func train loss in epoch 7:0.09612808399833739\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.08190973103046417\n",
      "\n",
      "episode 2, val func loss 0.11927445232868195\n",
      "\n",
      "episode 3, val func loss 0.08026162534952164\n",
      "\n",
      "episode 4, val func loss 0.12015463411808014\n",
      "\n",
      "episode 5, val func loss 0.06760568916797638\n",
      "\n",
      "episode 6, val func loss 0.12289165705442429\n",
      "\n",
      "episode 7, val func loss 0.0697769969701767\n",
      "\n",
      "episode 8, val func loss 0.0528155118227005\n",
      "\n",
      "episode 9, val func loss 0.09526286274194717\n",
      "\n",
      "episode 10, val func loss 0.07240328937768936\n",
      "\n",
      "episode 11, val func loss 0.10236256569623947\n",
      "\n",
      "episode 12, val func loss 0.09276709705591202\n",
      "\n",
      "episode 13, val func loss 0.084021657705307\n",
      "\n",
      "episode 14, val func loss 0.08296807110309601\n",
      "\n",
      "episode 15, val func loss 0.12305878847837448\n",
      "\n",
      "episode 16, val func loss 0.062739796936512\n",
      "\n",
      "Val func train loss in epoch 8:0.08939215168356895\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.07808443903923035\n",
      "\n",
      "episode 2, val func loss 0.07408887147903442\n",
      "\n",
      "episode 3, val func loss 0.11282695084810257\n",
      "\n",
      "episode 4, val func loss 0.0953291803598404\n",
      "\n",
      "episode 5, val func loss 0.05998213589191437\n",
      "\n",
      "episode 6, val func loss 0.08732067048549652\n",
      "\n",
      "episode 7, val func loss 0.09207002818584442\n",
      "\n",
      "episode 8, val func loss 0.08825232833623886\n",
      "\n",
      "episode 9, val func loss 0.07033106684684753\n",
      "\n",
      "episode 10, val func loss 0.05267591029405594\n",
      "\n",
      "episode 11, val func loss 0.10482146590948105\n",
      "\n",
      "episode 12, val func loss 0.12574295699596405\n",
      "\n",
      "episode 13, val func loss 0.12269999086856842\n",
      "\n",
      "episode 14, val func loss 0.06763969361782074\n",
      "\n",
      "episode 15, val func loss 0.10258311033248901\n",
      "\n",
      "episode 16, val func loss 0.08345510810613632\n",
      "\n",
      "Val func train loss in epoch 9:0.08861899422481656\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.09719827771186829\n",
      "\n",
      "episode 2, val func loss 0.10085180401802063\n",
      "\n",
      "episode 3, val func loss 0.0858069434762001\n",
      "\n",
      "episode 4, val func loss 0.06915836036205292\n",
      "\n",
      "episode 5, val func loss 0.10270142555236816\n",
      "\n",
      "episode 6, val func loss 0.12587784230709076\n",
      "\n",
      "episode 7, val func loss 0.10353542864322662\n",
      "\n",
      "episode 8, val func loss 0.12804241478443146\n",
      "\n",
      "episode 9, val func loss 0.05978361517190933\n",
      "\n",
      "episode 10, val func loss 0.11794298887252808\n",
      "\n",
      "episode 11, val func loss 0.11662972718477249\n",
      "\n",
      "episode 12, val func loss 0.10200963914394379\n",
      "\n",
      "episode 13, val func loss 0.08955642580986023\n",
      "\n",
      "episode 14, val func loss 0.060989540070295334\n",
      "\n",
      "episode 15, val func loss 0.07184026390314102\n",
      "\n",
      "episode 16, val func loss 0.07803674042224884\n",
      "\n",
      "Val func train loss in epoch 10:0.09437258983962238\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.08008581399917603\n",
      "\n",
      "episode 2, val func loss 0.11546539515256882\n",
      "\n",
      "episode 3, val func loss 0.11374597996473312\n",
      "\n",
      "episode 4, val func loss 0.15851421654224396\n",
      "\n",
      "episode 5, val func loss 0.09176132827997208\n",
      "\n",
      "episode 6, val func loss 0.09802579879760742\n",
      "\n",
      "episode 7, val func loss 0.07784343510866165\n",
      "\n",
      "episode 8, val func loss 0.08856417238712311\n",
      "\n",
      "episode 9, val func loss 0.07685016095638275\n",
      "\n",
      "episode 10, val func loss 0.10173960775136948\n",
      "\n",
      "episode 11, val func loss 0.052676547318696976\n",
      "\n",
      "episode 12, val func loss 0.07264985144138336\n",
      "\n",
      "episode 13, val func loss 0.06600053608417511\n",
      "\n",
      "episode 14, val func loss 0.06904182583093643\n",
      "\n",
      "episode 15, val func loss 0.12100151181221008\n",
      "\n",
      "episode 16, val func loss 0.10187448561191559\n",
      "\n",
      "Val func train loss in epoch 11:0.09286504168994725\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.0722116008400917\n",
      "\n",
      "episode 2, val func loss 0.07273057103157043\n",
      "\n",
      "episode 3, val func loss 0.08629748225212097\n",
      "\n",
      "episode 4, val func loss 0.10189410299062729\n",
      "\n",
      "episode 5, val func loss 0.07755422592163086\n",
      "\n",
      "episode 6, val func loss 0.086813785135746\n",
      "\n",
      "episode 7, val func loss 0.07692095637321472\n",
      "\n",
      "episode 8, val func loss 0.06851837038993835\n",
      "\n",
      "episode 9, val func loss 0.07979554682970047\n",
      "\n",
      "episode 10, val func loss 0.05660597234964371\n",
      "\n",
      "episode 11, val func loss 0.13236691057682037\n",
      "\n",
      "episode 12, val func loss 0.12842515110969543\n",
      "\n",
      "episode 13, val func loss 0.0921495109796524\n",
      "\n",
      "episode 14, val func loss 0.0958905965089798\n",
      "\n",
      "episode 15, val func loss 0.12376917898654938\n",
      "\n",
      "episode 16, val func loss 0.09542303532361984\n",
      "\n",
      "Val func train loss in epoch 12:0.09046043734997511\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.08814888447523117\n",
      "\n",
      "episode 2, val func loss 0.10196841508150101\n",
      "\n",
      "episode 3, val func loss 0.054712794721126556\n",
      "\n",
      "episode 4, val func loss 0.11175303161144257\n",
      "\n",
      "episode 5, val func loss 0.12895266711711884\n",
      "\n",
      "episode 6, val func loss 0.11286499351263046\n",
      "\n",
      "episode 7, val func loss 0.10406914353370667\n",
      "\n",
      "episode 8, val func loss 0.09845646470785141\n",
      "\n",
      "episode 9, val func loss 0.07648234814405441\n",
      "\n",
      "episode 10, val func loss 0.09946194291114807\n",
      "\n",
      "episode 11, val func loss 0.06874585151672363\n",
      "\n",
      "episode 12, val func loss 0.12128442525863647\n",
      "\n",
      "episode 13, val func loss 0.08223456889390945\n",
      "\n",
      "episode 14, val func loss 0.06170680746436119\n",
      "\n",
      "episode 15, val func loss 0.08443773537874222\n",
      "\n",
      "episode 16, val func loss 0.07326098531484604\n",
      "\n",
      "Val func train loss in epoch 13:0.09178381622768939\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.12184025347232819\n",
      "\n",
      "episode 2, val func loss 0.11362393945455551\n",
      "\n",
      "episode 3, val func loss 0.06927624344825745\n",
      "\n",
      "episode 4, val func loss 0.05434912443161011\n",
      "\n",
      "episode 5, val func loss 0.07852904498577118\n",
      "\n",
      "episode 6, val func loss 0.07653329521417618\n",
      "\n",
      "episode 7, val func loss 0.07835903018712997\n",
      "\n",
      "episode 8, val func loss 0.07840146869421005\n",
      "\n",
      "episode 9, val func loss 0.1138356551527977\n",
      "\n",
      "episode 10, val func loss 0.06631966680288315\n",
      "\n",
      "episode 11, val func loss 0.07685136049985886\n",
      "\n",
      "episode 12, val func loss 0.1002604067325592\n",
      "\n",
      "episode 13, val func loss 0.0937083512544632\n",
      "\n",
      "episode 14, val func loss 0.12725864350795746\n",
      "\n",
      "episode 15, val func loss 0.09492219239473343\n",
      "\n",
      "episode 16, val func loss 0.08288884162902832\n",
      "\n",
      "Val func train loss in epoch 14:0.089184844866395\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.05378777161240578\n",
      "\n",
      "episode 2, val func loss 0.08207740634679794\n",
      "\n",
      "episode 3, val func loss 0.10534251481294632\n",
      "\n",
      "episode 4, val func loss 0.06359878927469254\n",
      "\n",
      "episode 5, val func loss 0.06775624305009842\n",
      "\n",
      "episode 6, val func loss 0.132960706949234\n",
      "\n",
      "episode 7, val func loss 0.12128784507513046\n",
      "\n",
      "episode 8, val func loss 0.09685587882995605\n",
      "\n",
      "episode 9, val func loss 0.08500798791646957\n",
      "\n",
      "episode 10, val func loss 0.09233839809894562\n",
      "\n",
      "episode 11, val func loss 0.08765656501054764\n",
      "\n",
      "episode 12, val func loss 0.07699740678071976\n",
      "\n",
      "episode 13, val func loss 0.09136953949928284\n",
      "\n",
      "episode 14, val func loss 0.11224815994501114\n",
      "\n",
      "episode 15, val func loss 0.07960586249828339\n",
      "\n",
      "episode 16, val func loss 0.07400631159543991\n",
      "\n",
      "Val func train loss in epoch 15:0.08893108670599759\n",
      "***********************TIME WAS 5.2950677394866945 min*****************************\n",
      "\n",
      "**********************ROUND 8 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.05696975067257881\n",
      "\n",
      "episode 2, policy loss -0.07282467931509018\n",
      "\n",
      "episode 3, policy loss -0.06330752372741699\n",
      "\n",
      "episode 4, policy loss -0.034350909292697906\n",
      "\n",
      "episode 5, policy loss -0.06435389816761017\n",
      "\n",
      "episode 6, policy loss -0.0980551689863205\n",
      "\n",
      "episode 7, policy loss -0.087100088596344\n",
      "\n",
      "episode 8, policy loss -0.028795145452022552\n",
      "\n",
      "episode 9, policy loss -0.030166596174240112\n",
      "\n",
      "episode 10, policy loss -0.07389373332262039\n",
      "\n",
      "episode 11, policy loss -0.07806272059679031\n",
      "\n",
      "episode 12, policy loss -0.020246081054210663\n",
      "\n",
      "episode 13, policy loss -0.0319574736058712\n",
      "\n",
      "episode 14, policy loss -0.03178564831614494\n",
      "\n",
      "episode 15, policy loss -0.06230805814266205\n",
      "\n",
      "episode 16, policy loss -0.07589289546012878\n",
      "\n",
      "Policy train loss in epoch 0:-0.05687939818017185\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.01850561797618866\n",
      "\n",
      "episode 2, policy loss -0.0632166862487793\n",
      "\n",
      "episode 3, policy loss -0.0763179287314415\n",
      "\n",
      "episode 4, policy loss -0.032673563808202744\n",
      "\n",
      "episode 5, policy loss -0.06506145745515823\n",
      "\n",
      "episode 6, policy loss -0.07865399867296219\n",
      "\n",
      "episode 7, policy loss -0.09770765900611877\n",
      "\n",
      "episode 8, policy loss -0.027211636304855347\n",
      "\n",
      "episode 9, policy loss -0.03025398775935173\n",
      "\n",
      "episode 10, policy loss -0.0874004065990448\n",
      "\n",
      "episode 11, policy loss -0.05257830023765564\n",
      "\n",
      "episode 12, policy loss -0.027739569544792175\n",
      "\n",
      "episode 13, policy loss -0.07668638974428177\n",
      "\n",
      "episode 14, policy loss -0.028678271919488907\n",
      "\n",
      "episode 15, policy loss -0.0708194300532341\n",
      "\n",
      "episode 16, policy loss -0.05950848013162613\n",
      "\n",
      "Policy train loss in epoch 1:-0.055813336512073874\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.05979054421186447\n",
      "\n",
      "episode 2, policy loss -0.08291185647249222\n",
      "\n",
      "episode 3, policy loss -0.025176584720611572\n",
      "\n",
      "episode 4, policy loss -0.03355449438095093\n",
      "\n",
      "episode 5, policy loss -0.07580506801605225\n",
      "\n",
      "episode 6, policy loss -0.05154499039053917\n",
      "\n",
      "episode 7, policy loss -0.0729571133852005\n",
      "\n",
      "episode 8, policy loss -0.0648895874619484\n",
      "\n",
      "episode 9, policy loss -0.03153485804796219\n",
      "\n",
      "episode 10, policy loss -0.03339722380042076\n",
      "\n",
      "episode 11, policy loss -0.07633000612258911\n",
      "\n",
      "episode 12, policy loss -0.014788538217544556\n",
      "\n",
      "episode 13, policy loss -0.0679330825805664\n",
      "\n",
      "episode 14, policy loss -0.09831719100475311\n",
      "\n",
      "episode 15, policy loss -0.07325121015310287\n",
      "\n",
      "episode 16, policy loss -0.028817258775234222\n",
      "\n",
      "Policy train loss in epoch 2:-0.055687475483864546\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.03173092007637024\n",
      "\n",
      "episode 2, policy loss -0.03056841343641281\n",
      "\n",
      "episode 3, policy loss -0.02287730574607849\n",
      "\n",
      "episode 4, policy loss -0.06547272205352783\n",
      "\n",
      "episode 5, policy loss -0.027039427310228348\n",
      "\n",
      "episode 6, policy loss -0.061062656342983246\n",
      "\n",
      "episode 7, policy loss -0.028212781995534897\n",
      "\n",
      "episode 8, policy loss -0.055843278765678406\n",
      "\n",
      "episode 9, policy loss -0.06939373165369034\n",
      "\n",
      "episode 10, policy loss -0.08557827025651932\n",
      "\n",
      "episode 11, policy loss -0.07236802577972412\n",
      "\n",
      "episode 12, policy loss -0.07752107083797455\n",
      "\n",
      "episode 13, policy loss -0.030697599053382874\n",
      "\n",
      "episode 14, policy loss -0.07447884231805801\n",
      "\n",
      "episode 15, policy loss -0.07871144264936447\n",
      "\n",
      "episode 16, policy loss -0.09679541736841202\n",
      "\n",
      "Policy train loss in epoch 3:-0.05677199410274625\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.04683495685458183\n",
      "\n",
      "episode 2, val func loss 0.14094054698944092\n",
      "\n",
      "episode 3, val func loss 0.10925069451332092\n",
      "\n",
      "episode 4, val func loss 0.07265415787696838\n",
      "\n",
      "episode 5, val func loss 0.05816518887877464\n",
      "\n",
      "episode 6, val func loss 0.06260524690151215\n",
      "\n",
      "episode 7, val func loss 0.0819670632481575\n",
      "\n",
      "episode 8, val func loss 0.04114420711994171\n",
      "\n",
      "episode 9, val func loss 0.06835223734378815\n",
      "\n",
      "episode 10, val func loss 0.1367185264825821\n",
      "\n",
      "episode 11, val func loss 0.12161397933959961\n",
      "\n",
      "episode 12, val func loss 0.09906508028507233\n",
      "\n",
      "episode 13, val func loss 0.09087838232517242\n",
      "\n",
      "episode 14, val func loss 0.11679588258266449\n",
      "\n",
      "episode 15, val func loss 0.10675186663866043\n",
      "\n",
      "episode 16, val func loss 0.04986703395843506\n",
      "\n",
      "Val func train loss in epoch 0:0.08772531570866704\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.15475377440452576\n",
      "\n",
      "episode 2, val func loss 0.06622340530157089\n",
      "\n",
      "episode 3, val func loss 0.05777590349316597\n",
      "\n",
      "episode 4, val func loss 0.09704320877790451\n",
      "\n",
      "episode 5, val func loss 0.07163611054420471\n",
      "\n",
      "episode 6, val func loss 0.11925097554922104\n",
      "\n",
      "episode 7, val func loss 0.0489162839949131\n",
      "\n",
      "episode 8, val func loss 0.11366825550794601\n",
      "\n",
      "episode 9, val func loss 0.07016847282648087\n",
      "\n",
      "episode 10, val func loss 0.10740790516138077\n",
      "\n",
      "episode 11, val func loss 0.03735457360744476\n",
      "\n",
      "episode 12, val func loss 0.07543247938156128\n",
      "\n",
      "episode 13, val func loss 0.0759613886475563\n",
      "\n",
      "episode 14, val func loss 0.06411541253328323\n",
      "\n",
      "episode 15, val func loss 0.12785840034484863\n",
      "\n",
      "episode 16, val func loss 0.10777749121189117\n",
      "\n",
      "Val func train loss in epoch 1:0.08720900258049369\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.11310194432735443\n",
      "\n",
      "episode 2, val func loss 0.06454844772815704\n",
      "\n",
      "episode 3, val func loss 0.061836984008550644\n",
      "\n",
      "episode 4, val func loss 0.054704368114471436\n",
      "\n",
      "episode 5, val func loss 0.12236303091049194\n",
      "\n",
      "episode 6, val func loss 0.10608511418104172\n",
      "\n",
      "episode 7, val func loss 0.09935752302408218\n",
      "\n",
      "episode 8, val func loss 0.08028921484947205\n",
      "\n",
      "episode 9, val func loss 0.065335214138031\n",
      "\n",
      "episode 10, val func loss 0.04280562698841095\n",
      "\n",
      "episode 11, val func loss 0.03638665750622749\n",
      "\n",
      "episode 12, val func loss 0.07282625138759613\n",
      "\n",
      "episode 13, val func loss 0.1007784903049469\n",
      "\n",
      "episode 14, val func loss 0.139100581407547\n",
      "\n",
      "episode 15, val func loss 0.05183372274041176\n",
      "\n",
      "episode 16, val func loss 0.18872445821762085\n",
      "\n",
      "Val func train loss in epoch 2:0.08750485186465085\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.10655125230550766\n",
      "\n",
      "episode 2, val func loss 0.08803614228963852\n",
      "\n",
      "episode 3, val func loss 0.13004523515701294\n",
      "\n",
      "episode 4, val func loss 0.042478788644075394\n",
      "\n",
      "episode 5, val func loss 0.038807567209005356\n",
      "\n",
      "episode 6, val func loss 0.2120598405599594\n",
      "\n",
      "episode 7, val func loss 0.0627426877617836\n",
      "\n",
      "episode 8, val func loss 0.11054809391498566\n",
      "\n",
      "episode 9, val func loss 0.20884083211421967\n",
      "\n",
      "episode 10, val func loss 0.06609942764043808\n",
      "\n",
      "episode 11, val func loss 0.09960205852985382\n",
      "\n",
      "episode 12, val func loss 0.09961631894111633\n",
      "\n",
      "episode 13, val func loss 0.12360129505395889\n",
      "\n",
      "episode 14, val func loss 0.058736108243465424\n",
      "\n",
      "episode 15, val func loss 0.22411666810512543\n",
      "\n",
      "episode 16, val func loss 0.10841146856546402\n",
      "\n",
      "Val func train loss in epoch 3:0.11126836156472564\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.14984118938446045\n",
      "\n",
      "episode 2, val func loss 0.04537735879421234\n",
      "\n",
      "episode 3, val func loss 0.0621056966483593\n",
      "\n",
      "episode 4, val func loss 0.17377807199954987\n",
      "\n",
      "episode 5, val func loss 0.06550098210573196\n",
      "\n",
      "episode 6, val func loss 0.14323796331882477\n",
      "\n",
      "episode 7, val func loss 0.0718998908996582\n",
      "\n",
      "episode 8, val func loss 0.12215954810380936\n",
      "\n",
      "episode 9, val func loss 0.08913245797157288\n",
      "\n",
      "episode 10, val func loss 0.11263590306043625\n",
      "\n",
      "episode 11, val func loss 0.03670072183012962\n",
      "\n",
      "episode 12, val func loss 0.16765964031219482\n",
      "\n",
      "episode 13, val func loss 0.06349913030862808\n",
      "\n",
      "episode 14, val func loss 0.06565801799297333\n",
      "\n",
      "episode 15, val func loss 0.11035150289535522\n",
      "\n",
      "episode 16, val func loss 0.06430451571941376\n",
      "\n",
      "Val func train loss in epoch 4:0.09649016195908189\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.0693553015589714\n",
      "\n",
      "episode 2, val func loss 0.036215439438819885\n",
      "\n",
      "episode 3, val func loss 0.15628208220005035\n",
      "\n",
      "episode 4, val func loss 0.04260362684726715\n",
      "\n",
      "episode 5, val func loss 0.06264016032218933\n",
      "\n",
      "episode 6, val func loss 0.09658028185367584\n",
      "\n",
      "episode 7, val func loss 0.1718379557132721\n",
      "\n",
      "episode 8, val func loss 0.09880299121141434\n",
      "\n",
      "episode 9, val func loss 0.07157625257968903\n",
      "\n",
      "episode 10, val func loss 0.07797836512327194\n",
      "\n",
      "episode 11, val func loss 0.05269273743033409\n",
      "\n",
      "episode 12, val func loss 0.06057340279221535\n",
      "\n",
      "episode 13, val func loss 0.06566198170185089\n",
      "\n",
      "episode 14, val func loss 0.1124325841665268\n",
      "\n",
      "episode 15, val func loss 0.10973592847585678\n",
      "\n",
      "episode 16, val func loss 0.11475475877523422\n",
      "\n",
      "Val func train loss in epoch 5:0.08748274063691497\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1071881428360939\n",
      "\n",
      "episode 2, val func loss 0.07131968438625336\n",
      "\n",
      "episode 3, val func loss 0.07226858288049698\n",
      "\n",
      "episode 4, val func loss 0.12167325615882874\n",
      "\n",
      "episode 5, val func loss 0.058071427047252655\n",
      "\n",
      "episode 6, val func loss 0.1235852763056755\n",
      "\n",
      "episode 7, val func loss 0.10097035020589828\n",
      "\n",
      "episode 8, val func loss 0.04286478832364082\n",
      "\n",
      "episode 9, val func loss 0.03612879291176796\n",
      "\n",
      "episode 10, val func loss 0.0710313469171524\n",
      "\n",
      "episode 11, val func loss 0.16369295120239258\n",
      "\n",
      "episode 12, val func loss 0.09752097725868225\n",
      "\n",
      "episode 13, val func loss 0.12152445316314697\n",
      "\n",
      "episode 14, val func loss 0.10477893799543381\n",
      "\n",
      "episode 15, val func loss 0.07311012595891953\n",
      "\n",
      "episode 16, val func loss 0.055703580379486084\n",
      "\n",
      "Val func train loss in epoch 6:0.08883954212069511\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.06758951395750046\n",
      "\n",
      "episode 2, val func loss 0.05225580930709839\n",
      "\n",
      "episode 3, val func loss 0.13779041171073914\n",
      "\n",
      "episode 4, val func loss 0.04265255481004715\n",
      "\n",
      "episode 5, val func loss 0.06670625507831573\n",
      "\n",
      "episode 6, val func loss 0.12946413457393646\n",
      "\n",
      "episode 7, val func loss 0.09446895122528076\n",
      "\n",
      "episode 8, val func loss 0.05513155087828636\n",
      "\n",
      "episode 9, val func loss 0.03798863664269447\n",
      "\n",
      "episode 10, val func loss 0.14393873512744904\n",
      "\n",
      "episode 11, val func loss 0.12426091730594635\n",
      "\n",
      "episode 12, val func loss 0.06253893673419952\n",
      "\n",
      "episode 13, val func loss 0.07382256537675858\n",
      "\n",
      "episode 14, val func loss 0.10660049319267273\n",
      "\n",
      "episode 15, val func loss 0.06475167721509933\n",
      "\n",
      "episode 16, val func loss 0.09968142211437225\n",
      "\n",
      "Val func train loss in epoch 7:0.0849776603281498\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.11415460705757141\n",
      "\n",
      "episode 2, val func loss 0.042831774801015854\n",
      "\n",
      "episode 3, val func loss 0.06464123725891113\n",
      "\n",
      "episode 4, val func loss 0.11092132329940796\n",
      "\n",
      "episode 5, val func loss 0.06274762749671936\n",
      "\n",
      "episode 6, val func loss 0.06408640742301941\n",
      "\n",
      "episode 7, val func loss 0.14152537286281586\n",
      "\n",
      "episode 8, val func loss 0.06457563489675522\n",
      "\n",
      "episode 9, val func loss 0.09664201736450195\n",
      "\n",
      "episode 10, val func loss 0.10656484216451645\n",
      "\n",
      "episode 11, val func loss 0.10201862454414368\n",
      "\n",
      "episode 12, val func loss 0.12054827809333801\n",
      "\n",
      "episode 13, val func loss 0.0384201854467392\n",
      "\n",
      "episode 14, val func loss 0.059836793690919876\n",
      "\n",
      "episode 15, val func loss 0.07047601789236069\n",
      "\n",
      "episode 16, val func loss 0.04894213750958443\n",
      "\n",
      "Val func train loss in epoch 8:0.08180830511264503\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1077716276049614\n",
      "\n",
      "episode 2, val func loss 0.09606263786554337\n",
      "\n",
      "episode 3, val func loss 0.049259647727012634\n",
      "\n",
      "episode 4, val func loss 0.05049889162182808\n",
      "\n",
      "episode 5, val func loss 0.11928127706050873\n",
      "\n",
      "episode 6, val func loss 0.12532375752925873\n",
      "\n",
      "episode 7, val func loss 0.0635378509759903\n",
      "\n",
      "episode 8, val func loss 0.15577936172485352\n",
      "\n",
      "episode 9, val func loss 0.06204769015312195\n",
      "\n",
      "episode 10, val func loss 0.0819726213812828\n",
      "\n",
      "episode 11, val func loss 0.06620020419359207\n",
      "\n",
      "episode 12, val func loss 0.0700896605849266\n",
      "\n",
      "episode 13, val func loss 0.10838288813829422\n",
      "\n",
      "episode 14, val func loss 0.05076588690280914\n",
      "\n",
      "episode 15, val func loss 0.1092999130487442\n",
      "\n",
      "episode 16, val func loss 0.06852515786886215\n",
      "\n",
      "Val func train loss in epoch 9:0.08654994214884937\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.06265515089035034\n",
      "\n",
      "episode 2, val func loss 0.11371387541294098\n",
      "\n",
      "episode 3, val func loss 0.062381844967603683\n",
      "\n",
      "episode 4, val func loss 0.09619877487421036\n",
      "\n",
      "episode 5, val func loss 0.10486578196287155\n",
      "\n",
      "episode 6, val func loss 0.09850861877202988\n",
      "\n",
      "episode 7, val func loss 0.06612222641706467\n",
      "\n",
      "episode 8, val func loss 0.06671123206615448\n",
      "\n",
      "episode 9, val func loss 0.059585314244031906\n",
      "\n",
      "episode 10, val func loss 0.04927726089954376\n",
      "\n",
      "episode 11, val func loss 0.06549783796072006\n",
      "\n",
      "episode 12, val func loss 0.042559582740068436\n",
      "\n",
      "episode 13, val func loss 0.1391601413488388\n",
      "\n",
      "episode 14, val func loss 0.12055300176143646\n",
      "\n",
      "episode 15, val func loss 0.1072065457701683\n",
      "\n",
      "episode 16, val func loss 0.04753154516220093\n",
      "\n",
      "Val func train loss in epoch 10:0.08140804595313966\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.06284818798303604\n",
      "\n",
      "episode 2, val func loss 0.06556370854377747\n",
      "\n",
      "episode 3, val func loss 0.06456129997968674\n",
      "\n",
      "episode 4, val func loss 0.10701581835746765\n",
      "\n",
      "episode 5, val func loss 0.035925887525081635\n",
      "\n",
      "episode 6, val func loss 0.04879599064588547\n",
      "\n",
      "episode 7, val func loss 0.10650581866502762\n",
      "\n",
      "episode 8, val func loss 0.09722695499658585\n",
      "\n",
      "episode 9, val func loss 0.05666910111904144\n",
      "\n",
      "episode 10, val func loss 0.19733940064907074\n",
      "\n",
      "episode 11, val func loss 0.10806984454393387\n",
      "\n",
      "episode 12, val func loss 0.06488300859928131\n",
      "\n",
      "episode 13, val func loss 0.16913418471813202\n",
      "\n",
      "episode 14, val func loss 0.07081416249275208\n",
      "\n",
      "episode 15, val func loss 0.042486369609832764\n",
      "\n",
      "episode 16, val func loss 0.11061185598373413\n",
      "\n",
      "Val func train loss in epoch 11:0.08802822465077043\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.06690452992916107\n",
      "\n",
      "episode 2, val func loss 0.16382427513599396\n",
      "\n",
      "episode 3, val func loss 0.042619489133358\n",
      "\n",
      "episode 4, val func loss 0.07337207347154617\n",
      "\n",
      "episode 5, val func loss 0.0784054771065712\n",
      "\n",
      "episode 6, val func loss 0.13999487459659576\n",
      "\n",
      "episode 7, val func loss 0.11747267842292786\n",
      "\n",
      "episode 8, val func loss 0.07182076573371887\n",
      "\n",
      "episode 9, val func loss 0.06292009353637695\n",
      "\n",
      "episode 10, val func loss 0.1399272233247757\n",
      "\n",
      "episode 11, val func loss 0.09424635022878647\n",
      "\n",
      "episode 12, val func loss 0.06303137540817261\n",
      "\n",
      "episode 13, val func loss 0.10954218357801437\n",
      "\n",
      "episode 14, val func loss 0.0604449063539505\n",
      "\n",
      "episode 15, val func loss 0.06632648408412933\n",
      "\n",
      "episode 16, val func loss 0.10971724987030029\n",
      "\n",
      "Val func train loss in epoch 12:0.0912856268696487\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.11998506635427475\n",
      "\n",
      "episode 2, val func loss 0.0625213012099266\n",
      "\n",
      "episode 3, val func loss 0.14122039079666138\n",
      "\n",
      "episode 4, val func loss 0.09781315177679062\n",
      "\n",
      "episode 5, val func loss 0.0986286923289299\n",
      "\n",
      "episode 6, val func loss 0.1092950776219368\n",
      "\n",
      "episode 7, val func loss 0.04459472373127937\n",
      "\n",
      "episode 8, val func loss 0.05490717664361\n",
      "\n",
      "episode 9, val func loss 0.1142931804060936\n",
      "\n",
      "episode 10, val func loss 0.051554545760154724\n",
      "\n",
      "episode 11, val func loss 0.11510342359542847\n",
      "\n",
      "episode 12, val func loss 0.06832083314657211\n",
      "\n",
      "episode 13, val func loss 0.06653779745101929\n",
      "\n",
      "episode 14, val func loss 0.037168994545936584\n",
      "\n",
      "episode 15, val func loss 0.06474730372428894\n",
      "\n",
      "episode 16, val func loss 0.06564948707818985\n",
      "\n",
      "Val func train loss in epoch 13:0.08202132163569331\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.062482550740242004\n",
      "\n",
      "episode 2, val func loss 0.05578647181391716\n",
      "\n",
      "episode 3, val func loss 0.06482796370983124\n",
      "\n",
      "episode 4, val func loss 0.11091934144496918\n",
      "\n",
      "episode 5, val func loss 0.09829237312078476\n",
      "\n",
      "episode 6, val func loss 0.06346428394317627\n",
      "\n",
      "episode 7, val func loss 0.14076700806617737\n",
      "\n",
      "episode 8, val func loss 0.12071359157562256\n",
      "\n",
      "episode 9, val func loss 0.06947865337133408\n",
      "\n",
      "episode 10, val func loss 0.10518532246351242\n",
      "\n",
      "episode 11, val func loss 0.04349236935377121\n",
      "\n",
      "episode 12, val func loss 0.09948480874300003\n",
      "\n",
      "episode 13, val func loss 0.06574448198080063\n",
      "\n",
      "episode 14, val func loss 0.10827916115522385\n",
      "\n",
      "episode 15, val func loss 0.04384537413716316\n",
      "\n",
      "episode 16, val func loss 0.05841769278049469\n",
      "\n",
      "Val func train loss in epoch 14:0.08194884052500129\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.06590873748064041\n",
      "\n",
      "episode 2, val func loss 0.12914396822452545\n",
      "\n",
      "episode 3, val func loss 0.04219967871904373\n",
      "\n",
      "episode 4, val func loss 0.06414314359426498\n",
      "\n",
      "episode 5, val func loss 0.10720784217119217\n",
      "\n",
      "episode 6, val func loss 0.10607372224330902\n",
      "\n",
      "episode 7, val func loss 0.11065474897623062\n",
      "\n",
      "episode 8, val func loss 0.0622427873313427\n",
      "\n",
      "episode 9, val func loss 0.14807796478271484\n",
      "\n",
      "episode 10, val func loss 0.054578132927417755\n",
      "\n",
      "episode 11, val func loss 0.06655486673116684\n",
      "\n",
      "episode 12, val func loss 0.12166944146156311\n",
      "\n",
      "episode 13, val func loss 0.06023745611310005\n",
      "\n",
      "episode 14, val func loss 0.039570488035678864\n",
      "\n",
      "episode 15, val func loss 0.06707116216421127\n",
      "\n",
      "episode 16, val func loss 0.1030665710568428\n",
      "\n",
      "Val func train loss in epoch 15:0.08427504450082779\n",
      "***********************TIME WAS 5.221416894594828 min*****************************\n",
      "\n",
      "**********************ROUND 9 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.06284977495670319\n",
      "\n",
      "episode 2, policy loss -0.06622808426618576\n",
      "\n",
      "episode 3, policy loss -0.09022051841020584\n",
      "\n",
      "episode 4, policy loss -0.0828721821308136\n",
      "\n",
      "episode 5, policy loss -0.08320938050746918\n",
      "\n",
      "episode 6, policy loss -0.05919183790683746\n",
      "\n",
      "episode 7, policy loss -0.07160606235265732\n",
      "\n",
      "episode 8, policy loss -0.06989941745996475\n",
      "\n",
      "episode 9, policy loss -0.098054438829422\n",
      "\n",
      "episode 10, policy loss -0.054031576961278915\n",
      "\n",
      "episode 11, policy loss -0.08646779507398605\n",
      "\n",
      "episode 12, policy loss -0.0942181795835495\n",
      "\n",
      "episode 13, policy loss -0.07586412131786346\n",
      "\n",
      "episode 14, policy loss -0.08125109225511551\n",
      "\n",
      "episode 15, policy loss -0.10176899284124374\n",
      "\n",
      "episode 16, policy loss -0.06302444636821747\n",
      "\n",
      "Policy train loss in epoch 0:-0.07754736882634461\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.1027357429265976\n",
      "\n",
      "episode 2, policy loss -0.060715798288583755\n",
      "\n",
      "episode 3, policy loss -0.08641967177391052\n",
      "\n",
      "episode 4, policy loss -0.09403299540281296\n",
      "\n",
      "episode 5, policy loss -0.08864354342222214\n",
      "\n",
      "episode 6, policy loss -0.06542465835809708\n",
      "\n",
      "episode 7, policy loss -0.08383084088563919\n",
      "\n",
      "episode 8, policy loss -0.087428517639637\n",
      "\n",
      "episode 9, policy loss -0.09479531645774841\n",
      "\n",
      "episode 10, policy loss -0.06307884305715561\n",
      "\n",
      "episode 11, policy loss -0.07962361723184586\n",
      "\n",
      "episode 12, policy loss -0.06649824976921082\n",
      "\n",
      "episode 13, policy loss -0.10457773506641388\n",
      "\n",
      "episode 14, policy loss -0.06320062279701233\n",
      "\n",
      "episode 15, policy loss -0.05927395075559616\n",
      "\n",
      "episode 16, policy loss -0.06664694845676422\n",
      "\n",
      "Policy train loss in epoch 1:-0.07918294076807797\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.06161247193813324\n",
      "\n",
      "episode 2, policy loss -0.05961648374795914\n",
      "\n",
      "episode 3, policy loss -0.0752180963754654\n",
      "\n",
      "episode 4, policy loss -0.09213866293430328\n",
      "\n",
      "episode 5, policy loss -0.08416753262281418\n",
      "\n",
      "episode 6, policy loss -0.06952323019504547\n",
      "\n",
      "episode 7, policy loss -0.08913031220436096\n",
      "\n",
      "episode 8, policy loss -0.053001854568719864\n",
      "\n",
      "episode 9, policy loss -0.101789191365242\n",
      "\n",
      "episode 10, policy loss -0.060952167958021164\n",
      "\n",
      "episode 11, policy loss -0.06728361546993256\n",
      "\n",
      "episode 12, policy loss -0.05649041384458542\n",
      "\n",
      "episode 13, policy loss -0.07169276475906372\n",
      "\n",
      "episode 14, policy loss -0.07358547300100327\n",
      "\n",
      "episode 15, policy loss -0.09378693997859955\n",
      "\n",
      "episode 16, policy loss -0.06448101997375488\n",
      "\n",
      "Policy train loss in epoch 2:-0.07340438943356276\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.057471536099910736\n",
      "\n",
      "episode 2, policy loss -0.09238657355308533\n",
      "\n",
      "episode 3, policy loss -0.054244477301836014\n",
      "\n",
      "episode 4, policy loss -0.09521401673555374\n",
      "\n",
      "episode 5, policy loss -0.060800082981586456\n",
      "\n",
      "episode 6, policy loss -0.0829753652215004\n",
      "\n",
      "episode 7, policy loss -0.07356320321559906\n",
      "\n",
      "episode 8, policy loss -0.08622776716947556\n",
      "\n",
      "episode 9, policy loss -0.08603359758853912\n",
      "\n",
      "episode 10, policy loss -0.1019594594836235\n",
      "\n",
      "episode 11, policy loss -0.08659690618515015\n",
      "\n",
      "episode 12, policy loss -0.07810325175523758\n",
      "\n",
      "episode 13, policy loss -0.07031183689832687\n",
      "\n",
      "episode 14, policy loss -0.08586999773979187\n",
      "\n",
      "episode 15, policy loss -0.06081056594848633\n",
      "\n",
      "episode 16, policy loss -0.061404675245285034\n",
      "\n",
      "Policy train loss in epoch 3:-0.07712333207018673\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.056773263961076736\n",
      "\n",
      "episode 2, val func loss 0.08089602738618851\n",
      "\n",
      "episode 3, val func loss 0.10608825832605362\n",
      "\n",
      "episode 4, val func loss 0.05718906223773956\n",
      "\n",
      "episode 5, val func loss 0.05320180580019951\n",
      "\n",
      "episode 6, val func loss 0.058874037116765976\n",
      "\n",
      "episode 7, val func loss 0.0817028135061264\n",
      "\n",
      "episode 8, val func loss 0.12114666402339935\n",
      "\n",
      "episode 9, val func loss 0.07222539931535721\n",
      "\n",
      "episode 10, val func loss 0.09343240410089493\n",
      "\n",
      "episode 11, val func loss 0.05791521817445755\n",
      "\n",
      "episode 12, val func loss 0.0930841937661171\n",
      "\n",
      "episode 13, val func loss 0.09398158639669418\n",
      "\n",
      "episode 14, val func loss 0.040484510362148285\n",
      "\n",
      "episode 15, val func loss 0.057210613042116165\n",
      "\n",
      "episode 16, val func loss 0.10538055747747421\n",
      "\n",
      "Val func train loss in epoch 0:0.07684915093705058\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.041609495878219604\n",
      "\n",
      "episode 2, val func loss 0.08192586898803711\n",
      "\n",
      "episode 3, val func loss 0.09387238323688507\n",
      "\n",
      "episode 4, val func loss 0.05751417204737663\n",
      "\n",
      "episode 5, val func loss 0.09382420033216476\n",
      "\n",
      "episode 6, val func loss 0.08102002739906311\n",
      "\n",
      "episode 7, val func loss 0.09660113602876663\n",
      "\n",
      "episode 8, val func loss 0.11801853775978088\n",
      "\n",
      "episode 9, val func loss 0.10431573539972305\n",
      "\n",
      "episode 10, val func loss 0.0577089786529541\n",
      "\n",
      "episode 11, val func loss 0.07609930634498596\n",
      "\n",
      "episode 12, val func loss 0.05911555141210556\n",
      "\n",
      "episode 13, val func loss 0.09349978715181351\n",
      "\n",
      "episode 14, val func loss 0.056391458958387375\n",
      "\n",
      "episode 15, val func loss 0.06017591804265976\n",
      "\n",
      "episode 16, val func loss 0.0540723018348217\n",
      "\n",
      "Val func train loss in epoch 1:0.07661030371673405\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.10920045524835587\n",
      "\n",
      "episode 2, val func loss 0.053799357265233994\n",
      "\n",
      "episode 3, val func loss 0.09309284389019012\n",
      "\n",
      "episode 4, val func loss 0.09573221206665039\n",
      "\n",
      "episode 5, val func loss 0.06055537983775139\n",
      "\n",
      "episode 6, val func loss 0.05916554108262062\n",
      "\n",
      "episode 7, val func loss 0.08181643486022949\n",
      "\n",
      "episode 8, val func loss 0.11696378141641617\n",
      "\n",
      "episode 9, val func loss 0.05780254304409027\n",
      "\n",
      "episode 10, val func loss 0.09319962561130524\n",
      "\n",
      "episode 11, val func loss 0.07420415431261063\n",
      "\n",
      "episode 12, val func loss 0.04287678003311157\n",
      "\n",
      "episode 13, val func loss 0.059971705079078674\n",
      "\n",
      "episode 14, val func loss 0.08251600712537766\n",
      "\n",
      "episode 15, val func loss 0.09478163719177246\n",
      "\n",
      "episode 16, val func loss 0.05687934532761574\n",
      "\n",
      "Val func train loss in epoch 2:0.07703486271202564\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.11748382449150085\n",
      "\n",
      "episode 2, val func loss 0.1058703288435936\n",
      "\n",
      "episode 3, val func loss 0.055248890072107315\n",
      "\n",
      "episode 4, val func loss 0.09307874739170074\n",
      "\n",
      "episode 5, val func loss 0.04258343577384949\n",
      "\n",
      "episode 6, val func loss 0.057363759726285934\n",
      "\n",
      "episode 7, val func loss 0.08839499950408936\n",
      "\n",
      "episode 8, val func loss 0.07573932409286499\n",
      "\n",
      "episode 9, val func loss 0.061258163303136826\n",
      "\n",
      "episode 10, val func loss 0.09289637953042984\n",
      "\n",
      "episode 11, val func loss 0.059124335646629333\n",
      "\n",
      "episode 12, val func loss 0.09609229117631912\n",
      "\n",
      "episode 13, val func loss 0.05734541639685631\n",
      "\n",
      "episode 14, val func loss 0.08061686903238297\n",
      "\n",
      "episode 15, val func loss 0.09325207024812698\n",
      "\n",
      "episode 16, val func loss 0.05360830947756767\n",
      "\n",
      "Val func train loss in epoch 3:0.07687232154421508\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.07541295140981674\n",
      "\n",
      "episode 2, val func loss 0.09170595556497574\n",
      "\n",
      "episode 3, val func loss 0.101104736328125\n",
      "\n",
      "episode 4, val func loss 0.04221560060977936\n",
      "\n",
      "episode 5, val func loss 0.05756859853863716\n",
      "\n",
      "episode 6, val func loss 0.09138191491365433\n",
      "\n",
      "episode 7, val func loss 0.058552782982587814\n",
      "\n",
      "episode 8, val func loss 0.09264618903398514\n",
      "\n",
      "episode 9, val func loss 0.061143238097429276\n",
      "\n",
      "episode 10, val func loss 0.12439772486686707\n",
      "\n",
      "episode 11, val func loss 0.09844321012496948\n",
      "\n",
      "episode 12, val func loss 0.06146196648478508\n",
      "\n",
      "episode 13, val func loss 0.1113726794719696\n",
      "\n",
      "episode 14, val func loss 0.05756771191954613\n",
      "\n",
      "episode 15, val func loss 0.0599806010723114\n",
      "\n",
      "episode 16, val func loss 0.08151591569185257\n",
      "\n",
      "Val func train loss in epoch 4:0.07915448606945574\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.09709193557500839\n",
      "\n",
      "episode 2, val func loss 0.09322931617498398\n",
      "\n",
      "episode 3, val func loss 0.057445257902145386\n",
      "\n",
      "episode 4, val func loss 0.03989848494529724\n",
      "\n",
      "episode 5, val func loss 0.12067876011133194\n",
      "\n",
      "episode 6, val func loss 0.058212779462337494\n",
      "\n",
      "episode 7, val func loss 0.08177748322486877\n",
      "\n",
      "episode 8, val func loss 0.09318797290325165\n",
      "\n",
      "episode 9, val func loss 0.07133359462022781\n",
      "\n",
      "episode 10, val func loss 0.06221543252468109\n",
      "\n",
      "episode 11, val func loss 0.053941257297992706\n",
      "\n",
      "episode 12, val func loss 0.05468065291643143\n",
      "\n",
      "episode 13, val func loss 0.11530909687280655\n",
      "\n",
      "episode 14, val func loss 0.09328502416610718\n",
      "\n",
      "episode 15, val func loss 0.06547533720731735\n",
      "\n",
      "episode 16, val func loss 0.09539677202701569\n",
      "\n",
      "Val func train loss in epoch 5:0.07832244737073779\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.05884435027837753\n",
      "\n",
      "episode 2, val func loss 0.061828453093767166\n",
      "\n",
      "episode 3, val func loss 0.10465686768293381\n",
      "\n",
      "episode 4, val func loss 0.05366284027695656\n",
      "\n",
      "episode 5, val func loss 0.06309977173805237\n",
      "\n",
      "episode 6, val func loss 0.07294415682554245\n",
      "\n",
      "episode 7, val func loss 0.057722993195056915\n",
      "\n",
      "episode 8, val func loss 0.09306389838457108\n",
      "\n",
      "episode 9, val func loss 0.096546970307827\n",
      "\n",
      "episode 10, val func loss 0.12233961373567581\n",
      "\n",
      "episode 11, val func loss 0.09884099662303925\n",
      "\n",
      "episode 12, val func loss 0.053507205098867416\n",
      "\n",
      "episode 13, val func loss 0.08125791698694229\n",
      "\n",
      "episode 14, val func loss 0.10488682240247726\n",
      "\n",
      "episode 15, val func loss 0.04206124320626259\n",
      "\n",
      "episode 16, val func loss 0.08279938250780106\n",
      "\n",
      "Val func train loss in epoch 6:0.07800396764650941\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.05753333121538162\n",
      "\n",
      "episode 2, val func loss 0.10462071746587753\n",
      "\n",
      "episode 3, val func loss 0.05865239351987839\n",
      "\n",
      "episode 4, val func loss 0.07309744507074356\n",
      "\n",
      "episode 5, val func loss 0.05738160014152527\n",
      "\n",
      "episode 6, val func loss 0.08186140656471252\n",
      "\n",
      "episode 7, val func loss 0.10234039276838303\n",
      "\n",
      "episode 8, val func loss 0.11583627015352249\n",
      "\n",
      "episode 9, val func loss 0.05906885862350464\n",
      "\n",
      "episode 10, val func loss 0.08141257613897324\n",
      "\n",
      "episode 11, val func loss 0.094388447701931\n",
      "\n",
      "episode 12, val func loss 0.0567028671503067\n",
      "\n",
      "episode 13, val func loss 0.10145137459039688\n",
      "\n",
      "episode 14, val func loss 0.05378223955631256\n",
      "\n",
      "episode 15, val func loss 0.09278887510299683\n",
      "\n",
      "episode 16, val func loss 0.04502232372760773\n",
      "\n",
      "Val func train loss in epoch 7:0.07724631996825337\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.05400906875729561\n",
      "\n",
      "episode 2, val func loss 0.05675642937421799\n",
      "\n",
      "episode 3, val func loss 0.06032192334532738\n",
      "\n",
      "episode 4, val func loss 0.08941523730754852\n",
      "\n",
      "episode 5, val func loss 0.05542982369661331\n",
      "\n",
      "episode 6, val func loss 0.09766966849565506\n",
      "\n",
      "episode 7, val func loss 0.09405076503753662\n",
      "\n",
      "episode 8, val func loss 0.05931797996163368\n",
      "\n",
      "episode 9, val func loss 0.1160350888967514\n",
      "\n",
      "episode 10, val func loss 0.0835714265704155\n",
      "\n",
      "episode 11, val func loss 0.05781077593564987\n",
      "\n",
      "episode 12, val func loss 0.09290136396884918\n",
      "\n",
      "episode 13, val func loss 0.0932217463850975\n",
      "\n",
      "episode 14, val func loss 0.10468463599681854\n",
      "\n",
      "episode 15, val func loss 0.07142109423875809\n",
      "\n",
      "episode 16, val func loss 0.04357019439339638\n",
      "\n",
      "Val func train loss in epoch 8:0.07688670139759779\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.05878319591283798\n",
      "\n",
      "episode 2, val func loss 0.05391938239336014\n",
      "\n",
      "episode 3, val func loss 0.05706991255283356\n",
      "\n",
      "episode 4, val func loss 0.039840880781412125\n",
      "\n",
      "episode 5, val func loss 0.09406020492315292\n",
      "\n",
      "episode 6, val func loss 0.05839435011148453\n",
      "\n",
      "episode 7, val func loss 0.08142311125993729\n",
      "\n",
      "episode 8, val func loss 0.09773841500282288\n",
      "\n",
      "episode 9, val func loss 0.07229217886924744\n",
      "\n",
      "episode 10, val func loss 0.09282607585191727\n",
      "\n",
      "episode 11, val func loss 0.09554729610681534\n",
      "\n",
      "episode 12, val func loss 0.10489847511053085\n",
      "\n",
      "episode 13, val func loss 0.05322284996509552\n",
      "\n",
      "episode 14, val func loss 0.05908098444342613\n",
      "\n",
      "episode 15, val func loss 0.08826229721307755\n",
      "\n",
      "episode 16, val func loss 0.11744363605976105\n",
      "\n",
      "Val func train loss in epoch 9:0.07655020290985703\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.06023235619068146\n",
      "\n",
      "episode 2, val func loss 0.04419633001089096\n",
      "\n",
      "episode 3, val func loss 0.10473401099443436\n",
      "\n",
      "episode 4, val func loss 0.08193457126617432\n",
      "\n",
      "episode 5, val func loss 0.0568866953253746\n",
      "\n",
      "episode 6, val func loss 0.09928332269191742\n",
      "\n",
      "episode 7, val func loss 0.11702365428209305\n",
      "\n",
      "episode 8, val func loss 0.05942288413643837\n",
      "\n",
      "episode 9, val func loss 0.05340636521577835\n",
      "\n",
      "episode 10, val func loss 0.0856778472661972\n",
      "\n",
      "episode 11, val func loss 0.09327990561723709\n",
      "\n",
      "episode 12, val func loss 0.05548471212387085\n",
      "\n",
      "episode 13, val func loss 0.05772186815738678\n",
      "\n",
      "episode 14, val func loss 0.09340520948171616\n",
      "\n",
      "episode 15, val func loss 0.07252918183803558\n",
      "\n",
      "episode 16, val func loss 0.09401185065507889\n",
      "\n",
      "Val func train loss in epoch 10:0.07682692282833159\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.08192016184329987\n",
      "\n",
      "episode 2, val func loss 0.08291881531476974\n",
      "\n",
      "episode 3, val func loss 0.04001881554722786\n",
      "\n",
      "episode 4, val func loss 0.05701213330030441\n",
      "\n",
      "episode 5, val func loss 0.11423531919717789\n",
      "\n",
      "episode 6, val func loss 0.05741794407367706\n",
      "\n",
      "episode 7, val func loss 0.0719841867685318\n",
      "\n",
      "episode 8, val func loss 0.07802475243806839\n",
      "\n",
      "episode 9, val func loss 0.0624997615814209\n",
      "\n",
      "episode 10, val func loss 0.05696805194020271\n",
      "\n",
      "episode 11, val func loss 0.07216904312372208\n",
      "\n",
      "episode 12, val func loss 0.11770309507846832\n",
      "\n",
      "episode 13, val func loss 0.09413109719753265\n",
      "\n",
      "episode 14, val func loss 0.12938354909420013\n",
      "\n",
      "episode 15, val func loss 0.09721701592206955\n",
      "\n",
      "episode 16, val func loss 0.10420575737953186\n",
      "\n",
      "Val func train loss in epoch 11:0.08236309373751283\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.05744043365120888\n",
      "\n",
      "episode 2, val func loss 0.06249069422483444\n",
      "\n",
      "episode 3, val func loss 0.10190577059984207\n",
      "\n",
      "episode 4, val func loss 0.04182954132556915\n",
      "\n",
      "episode 5, val func loss 0.05836283788084984\n",
      "\n",
      "episode 6, val func loss 0.09549291431903839\n",
      "\n",
      "episode 7, val func loss 0.11695105582475662\n",
      "\n",
      "episode 8, val func loss 0.08236927539110184\n",
      "\n",
      "episode 9, val func loss 0.09884987771511078\n",
      "\n",
      "episode 10, val func loss 0.0619579516351223\n",
      "\n",
      "episode 11, val func loss 0.07238806039094925\n",
      "\n",
      "episode 12, val func loss 0.08234711736440659\n",
      "\n",
      "episode 13, val func loss 0.0555400587618351\n",
      "\n",
      "episode 14, val func loss 0.10433704406023026\n",
      "\n",
      "episode 15, val func loss 0.09343396127223969\n",
      "\n",
      "episode 16, val func loss 0.05788465216755867\n",
      "\n",
      "Val func train loss in epoch 12:0.07772382791154087\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.059276800602674484\n",
      "\n",
      "episode 2, val func loss 0.05735084041953087\n",
      "\n",
      "episode 3, val func loss 0.1009640097618103\n",
      "\n",
      "episode 4, val func loss 0.04133225232362747\n",
      "\n",
      "episode 5, val func loss 0.11781472712755203\n",
      "\n",
      "episode 6, val func loss 0.05472675710916519\n",
      "\n",
      "episode 7, val func loss 0.08363290131092072\n",
      "\n",
      "episode 8, val func loss 0.09357994794845581\n",
      "\n",
      "episode 9, val func loss 0.09579923003911972\n",
      "\n",
      "episode 10, val func loss 0.06122840195894241\n",
      "\n",
      "episode 11, val func loss 0.071034274995327\n",
      "\n",
      "episode 12, val func loss 0.10492350161075592\n",
      "\n",
      "episode 13, val func loss 0.09347860515117645\n",
      "\n",
      "episode 14, val func loss 0.059062108397483826\n",
      "\n",
      "episode 15, val func loss 0.0860234722495079\n",
      "\n",
      "episode 16, val func loss 0.053840264678001404\n",
      "\n",
      "Val func train loss in epoch 13:0.07712925598025322\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.06040244176983833\n",
      "\n",
      "episode 2, val func loss 0.0952395349740982\n",
      "\n",
      "episode 3, val func loss 0.09518314898014069\n",
      "\n",
      "episode 4, val func loss 0.05355019122362137\n",
      "\n",
      "episode 5, val func loss 0.08457326889038086\n",
      "\n",
      "episode 6, val func loss 0.058148112148046494\n",
      "\n",
      "episode 7, val func loss 0.05382047966122627\n",
      "\n",
      "episode 8, val func loss 0.10570024698972702\n",
      "\n",
      "episode 9, val func loss 0.07261699438095093\n",
      "\n",
      "episode 10, val func loss 0.08594245463609695\n",
      "\n",
      "episode 11, val func loss 0.04240335151553154\n",
      "\n",
      "episode 12, val func loss 0.09784200042486191\n",
      "\n",
      "episode 13, val func loss 0.05710291862487793\n",
      "\n",
      "episode 14, val func loss 0.09430742263793945\n",
      "\n",
      "episode 15, val func loss 0.11688651144504547\n",
      "\n",
      "episode 16, val func loss 0.05909794569015503\n",
      "\n",
      "Val func train loss in epoch 14:0.07705106399953365\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.04173167794942856\n",
      "\n",
      "episode 2, val func loss 0.05684443190693855\n",
      "\n",
      "episode 3, val func loss 0.061854202300310135\n",
      "\n",
      "episode 4, val func loss 0.0981576144695282\n",
      "\n",
      "episode 5, val func loss 0.07236173003911972\n",
      "\n",
      "episode 6, val func loss 0.06593076884746552\n",
      "\n",
      "episode 7, val func loss 0.1071372777223587\n",
      "\n",
      "episode 8, val func loss 0.08146445453166962\n",
      "\n",
      "episode 9, val func loss 0.05555606633424759\n",
      "\n",
      "episode 10, val func loss 0.12232458591461182\n",
      "\n",
      "episode 11, val func loss 0.10218924283981323\n",
      "\n",
      "episode 12, val func loss 0.1273023933172226\n",
      "\n",
      "episode 13, val func loss 0.11159363389015198\n",
      "\n",
      "episode 14, val func loss 0.08134286105632782\n",
      "\n",
      "episode 15, val func loss 0.058453939855098724\n",
      "\n",
      "episode 16, val func loss 0.05464669689536095\n",
      "\n",
      "Val func train loss in epoch 15:0.08118072361685336\n",
      "***********************TIME WAS 5.249237600962321 min*****************************\n",
      "\n",
      "**********************ROUND 10 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.13543230295181274\n",
      "\n",
      "episode 2, policy loss -0.11455526947975159\n",
      "\n",
      "episode 3, policy loss -0.12806642055511475\n",
      "\n",
      "episode 4, policy loss -0.14093007147312164\n",
      "\n",
      "episode 5, policy loss -0.17870721220970154\n",
      "\n",
      "episode 6, policy loss -0.15175873041152954\n",
      "\n",
      "episode 7, policy loss -0.13557615876197815\n",
      "\n",
      "episode 8, policy loss -0.13916878402233124\n",
      "\n",
      "episode 9, policy loss -0.1532234251499176\n",
      "\n",
      "episode 10, policy loss -0.12399199604988098\n",
      "\n",
      "episode 11, policy loss -0.137574702501297\n",
      "\n",
      "episode 12, policy loss -0.16898632049560547\n",
      "\n",
      "episode 13, policy loss -0.09955518692731857\n",
      "\n",
      "episode 14, policy loss -0.14403820037841797\n",
      "\n",
      "episode 15, policy loss -0.14757874608039856\n",
      "\n",
      "episode 16, policy loss -0.17184025049209595\n",
      "\n",
      "Policy train loss in epoch 0:-0.14193648612126708\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.13461875915527344\n",
      "\n",
      "episode 2, policy loss -0.13643604516983032\n",
      "\n",
      "episode 3, policy loss -0.15642312169075012\n",
      "\n",
      "episode 4, policy loss -0.12385627627372742\n",
      "\n",
      "episode 5, policy loss -0.15394505858421326\n",
      "\n",
      "episode 6, policy loss -0.1380792260169983\n",
      "\n",
      "episode 7, policy loss -0.1466502696275711\n",
      "\n",
      "episode 8, policy loss -0.1126193255186081\n",
      "\n",
      "episode 9, policy loss -0.09891852736473083\n",
      "\n",
      "episode 10, policy loss -0.1658262312412262\n",
      "\n",
      "episode 11, policy loss -0.12759877741336823\n",
      "\n",
      "episode 12, policy loss -0.17185789346694946\n",
      "\n",
      "episode 13, policy loss -0.18596965074539185\n",
      "\n",
      "episode 14, policy loss -0.15293294191360474\n",
      "\n",
      "episode 15, policy loss -0.15158851444721222\n",
      "\n",
      "episode 16, policy loss -0.13694143295288086\n",
      "\n",
      "Policy train loss in epoch 1:-0.14339137822389603\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.1528613567352295\n",
      "\n",
      "episode 2, policy loss -0.1506788432598114\n",
      "\n",
      "episode 3, policy loss -0.13847991824150085\n",
      "\n",
      "episode 4, policy loss -0.19249790906906128\n",
      "\n",
      "episode 5, policy loss -0.14813663065433502\n",
      "\n",
      "episode 6, policy loss -0.12513840198516846\n",
      "\n",
      "episode 7, policy loss -0.09573785960674286\n",
      "\n",
      "episode 8, policy loss -0.13437721133232117\n",
      "\n",
      "episode 9, policy loss -0.13626515865325928\n",
      "\n",
      "episode 10, policy loss -0.1732209026813507\n",
      "\n",
      "episode 11, policy loss -0.1523720622062683\n",
      "\n",
      "episode 12, policy loss -0.13781124353408813\n",
      "\n",
      "episode 13, policy loss -0.16647300124168396\n",
      "\n",
      "episode 14, policy loss -0.15358884632587433\n",
      "\n",
      "episode 15, policy loss -0.11093738675117493\n",
      "\n",
      "episode 16, policy loss -0.12471512705087662\n",
      "\n",
      "Policy train loss in epoch 2:-0.14333074120804667\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.09868897497653961\n",
      "\n",
      "episode 2, policy loss -0.15388745069503784\n",
      "\n",
      "episode 3, policy loss -0.12100550532341003\n",
      "\n",
      "episode 4, policy loss -0.15190264582633972\n",
      "\n",
      "episode 5, policy loss -0.13389168679714203\n",
      "\n",
      "episode 6, policy loss -0.13656771183013916\n",
      "\n",
      "episode 7, policy loss -0.1752394139766693\n",
      "\n",
      "episode 8, policy loss -0.15464913845062256\n",
      "\n",
      "episode 9, policy loss -0.16739660501480103\n",
      "\n",
      "episode 10, policy loss -0.13254901766777039\n",
      "\n",
      "episode 11, policy loss -0.14590777456760406\n",
      "\n",
      "episode 12, policy loss -0.1856534481048584\n",
      "\n",
      "episode 13, policy loss -0.13592873513698578\n",
      "\n",
      "episode 14, policy loss -0.11013904958963394\n",
      "\n",
      "episode 15, policy loss -0.12367598712444305\n",
      "\n",
      "episode 16, policy loss -0.14812955260276794\n",
      "\n",
      "Policy train loss in epoch 3:-0.1422007936052978\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.13106290996074677\n",
      "\n",
      "episode 2, val func loss 0.08950188010931015\n",
      "\n",
      "episode 3, val func loss 0.08136051148176193\n",
      "\n",
      "episode 4, val func loss 0.11608055233955383\n",
      "\n",
      "episode 5, val func loss 0.11313425004482269\n",
      "\n",
      "episode 6, val func loss 0.09263316541910172\n",
      "\n",
      "episode 7, val func loss 0.08619391918182373\n",
      "\n",
      "episode 8, val func loss 0.0907975435256958\n",
      "\n",
      "episode 9, val func loss 0.07376527041196823\n",
      "\n",
      "episode 10, val func loss 0.04123479872941971\n",
      "\n",
      "episode 11, val func loss 0.07652375847101212\n",
      "\n",
      "episode 12, val func loss 0.0934329703450203\n",
      "\n",
      "episode 13, val func loss 0.11181772500276566\n",
      "\n",
      "episode 14, val func loss 0.13923616707324982\n",
      "\n",
      "episode 15, val func loss 0.06478077918291092\n",
      "\n",
      "episode 16, val func loss 0.08135509490966797\n",
      "\n",
      "Val func train loss in epoch 0:0.09268195601180196\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.10140010714530945\n",
      "\n",
      "episode 2, val func loss 0.11619089543819427\n",
      "\n",
      "episode 3, val func loss 0.09806886315345764\n",
      "\n",
      "episode 4, val func loss 0.08453790098428726\n",
      "\n",
      "episode 5, val func loss 0.10974158346652985\n",
      "\n",
      "episode 6, val func loss 0.10740038752555847\n",
      "\n",
      "episode 7, val func loss 0.09811202436685562\n",
      "\n",
      "episode 8, val func loss 0.04368941858410835\n",
      "\n",
      "episode 9, val func loss 0.12230496853590012\n",
      "\n",
      "episode 10, val func loss 0.07126907259225845\n",
      "\n",
      "episode 11, val func loss 0.07046355307102203\n",
      "\n",
      "episode 12, val func loss 0.1242486909031868\n",
      "\n",
      "episode 13, val func loss 0.09541623294353485\n",
      "\n",
      "episode 14, val func loss 0.11969831585884094\n",
      "\n",
      "episode 15, val func loss 0.08677610009908676\n",
      "\n",
      "episode 16, val func loss 0.06761544942855835\n",
      "\n",
      "Val func train loss in epoch 1:0.09480834775604308\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.04018879681825638\n",
      "\n",
      "episode 2, val func loss 0.11937006562948227\n",
      "\n",
      "episode 3, val func loss 0.09048358350992203\n",
      "\n",
      "episode 4, val func loss 0.13155989348888397\n",
      "\n",
      "episode 5, val func loss 0.08805336058139801\n",
      "\n",
      "episode 6, val func loss 0.09893985837697983\n",
      "\n",
      "episode 7, val func loss 0.07344552129507065\n",
      "\n",
      "episode 8, val func loss 0.10853111743927002\n",
      "\n",
      "episode 9, val func loss 0.09636155515909195\n",
      "\n",
      "episode 10, val func loss 0.11774955689907074\n",
      "\n",
      "episode 11, val func loss 0.0642625167965889\n",
      "\n",
      "episode 12, val func loss 0.08258035778999329\n",
      "\n",
      "episode 13, val func loss 0.08039958775043488\n",
      "\n",
      "episode 14, val func loss 0.06492270529270172\n",
      "\n",
      "episode 15, val func loss 0.06826376169919968\n",
      "\n",
      "episode 16, val func loss 0.11347758769989014\n",
      "\n",
      "Val func train loss in epoch 2:0.08991186413913965\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.11718439310789108\n",
      "\n",
      "episode 2, val func loss 0.06350155919790268\n",
      "\n",
      "episode 3, val func loss 0.10598815232515335\n",
      "\n",
      "episode 4, val func loss 0.08753259479999542\n",
      "\n",
      "episode 5, val func loss 0.04412633180618286\n",
      "\n",
      "episode 6, val func loss 0.09086424857378006\n",
      "\n",
      "episode 7, val func loss 0.10261540114879608\n",
      "\n",
      "episode 8, val func loss 0.13685296475887299\n",
      "\n",
      "episode 9, val func loss 0.10816390067338943\n",
      "\n",
      "episode 10, val func loss 0.06511096656322479\n",
      "\n",
      "episode 11, val func loss 0.08956830203533173\n",
      "\n",
      "episode 12, val func loss 0.08263739198446274\n",
      "\n",
      "episode 13, val func loss 0.06745579838752747\n",
      "\n",
      "episode 14, val func loss 0.09002476185560226\n",
      "\n",
      "episode 15, val func loss 0.11004693806171417\n",
      "\n",
      "episode 16, val func loss 0.11174329370260239\n",
      "\n",
      "Val func train loss in epoch 3:0.09208856243640184\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.06874898821115494\n",
      "\n",
      "episode 2, val func loss 0.09207822382450104\n",
      "\n",
      "episode 3, val func loss 0.09067121148109436\n",
      "\n",
      "episode 4, val func loss 0.06470084935426712\n",
      "\n",
      "episode 5, val func loss 0.11326915770769119\n",
      "\n",
      "episode 6, val func loss 0.11313290148973465\n",
      "\n",
      "episode 7, val func loss 0.10774890333414078\n",
      "\n",
      "episode 8, val func loss 0.11179094761610031\n",
      "\n",
      "episode 9, val func loss 0.08640314638614655\n",
      "\n",
      "episode 10, val func loss 0.0657087042927742\n",
      "\n",
      "episode 11, val func loss 0.0750105232000351\n",
      "\n",
      "episode 12, val func loss 0.11926811188459396\n",
      "\n",
      "episode 13, val func loss 0.09396331012248993\n",
      "\n",
      "episode 14, val func loss 0.04219173267483711\n",
      "\n",
      "episode 15, val func loss 0.08934438973665237\n",
      "\n",
      "episode 16, val func loss 0.06413593888282776\n",
      "\n",
      "Val func train loss in epoch 4:0.08738544001244009\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.07398896664381027\n",
      "\n",
      "episode 2, val func loss 0.09300978481769562\n",
      "\n",
      "episode 3, val func loss 0.04027072340250015\n",
      "\n",
      "episode 4, val func loss 0.1151592954993248\n",
      "\n",
      "episode 5, val func loss 0.08266657590866089\n",
      "\n",
      "episode 6, val func loss 0.12844325602054596\n",
      "\n",
      "episode 7, val func loss 0.0648750588297844\n",
      "\n",
      "episode 8, val func loss 0.06497757136821747\n",
      "\n",
      "episode 9, val func loss 0.09117189794778824\n",
      "\n",
      "episode 10, val func loss 0.09503144770860672\n",
      "\n",
      "episode 11, val func loss 0.12339501827955246\n",
      "\n",
      "episode 12, val func loss 0.09155625849962234\n",
      "\n",
      "episode 13, val func loss 0.06313112378120422\n",
      "\n",
      "episode 14, val func loss 0.13951176404953003\n",
      "\n",
      "episode 15, val func loss 0.07085634022951126\n",
      "\n",
      "episode 16, val func loss 0.1083599403500557\n",
      "\n",
      "Val func train loss in epoch 5:0.09040031395852566\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.0962156355381012\n",
      "\n",
      "episode 2, val func loss 0.12539716064929962\n",
      "\n",
      "episode 3, val func loss 0.13311447203159332\n",
      "\n",
      "episode 4, val func loss 0.04199797660112381\n",
      "\n",
      "episode 5, val func loss 0.0752890333533287\n",
      "\n",
      "episode 6, val func loss 0.09649477899074554\n",
      "\n",
      "episode 7, val func loss 0.08411078155040741\n",
      "\n",
      "episode 8, val func loss 0.09917253255844116\n",
      "\n",
      "episode 9, val func loss 0.06611423939466476\n",
      "\n",
      "episode 10, val func loss 0.0736721009016037\n",
      "\n",
      "episode 11, val func loss 0.10991879552602768\n",
      "\n",
      "episode 12, val func loss 0.125151127576828\n",
      "\n",
      "episode 13, val func loss 0.06520061194896698\n",
      "\n",
      "episode 14, val func loss 0.0893791988492012\n",
      "\n",
      "episode 15, val func loss 0.11161243915557861\n",
      "\n",
      "episode 16, val func loss 0.06454016268253326\n",
      "\n",
      "Val func train loss in epoch 6:0.09108631545677781\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.08235888928174973\n",
      "\n",
      "episode 2, val func loss 0.09030013531446457\n",
      "\n",
      "episode 3, val func loss 0.07503417879343033\n",
      "\n",
      "episode 4, val func loss 0.12026190012693405\n",
      "\n",
      "episode 5, val func loss 0.09267197549343109\n",
      "\n",
      "episode 6, val func loss 0.04074662923812866\n",
      "\n",
      "episode 7, val func loss 0.11042787879705429\n",
      "\n",
      "episode 8, val func loss 0.07117529958486557\n",
      "\n",
      "episode 9, val func loss 0.10960028320550919\n",
      "\n",
      "episode 10, val func loss 0.06490463763475418\n",
      "\n",
      "episode 11, val func loss 0.08927140384912491\n",
      "\n",
      "episode 12, val func loss 0.10898777097463608\n",
      "\n",
      "episode 13, val func loss 0.11226289719343185\n",
      "\n",
      "episode 14, val func loss 0.08829315751791\n",
      "\n",
      "episode 15, val func loss 0.06473856419324875\n",
      "\n",
      "episode 16, val func loss 0.06589654088020325\n",
      "\n",
      "Val func train loss in epoch 7:0.08668325887992978\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.11271672695875168\n",
      "\n",
      "episode 2, val func loss 0.06620094925165176\n",
      "\n",
      "episode 3, val func loss 0.08955799043178558\n",
      "\n",
      "episode 4, val func loss 0.08369657397270203\n",
      "\n",
      "episode 5, val func loss 0.04141758009791374\n",
      "\n",
      "episode 6, val func loss 0.08762919902801514\n",
      "\n",
      "episode 7, val func loss 0.07310013473033905\n",
      "\n",
      "episode 8, val func loss 0.08940831571817398\n",
      "\n",
      "episode 9, val func loss 0.10958454012870789\n",
      "\n",
      "episode 10, val func loss 0.12270842492580414\n",
      "\n",
      "episode 11, val func loss 0.10901795327663422\n",
      "\n",
      "episode 12, val func loss 0.06577716022729874\n",
      "\n",
      "episode 13, val func loss 0.06464444845914841\n",
      "\n",
      "episode 14, val func loss 0.11321478337049484\n",
      "\n",
      "episode 15, val func loss 0.09356224536895752\n",
      "\n",
      "episode 16, val func loss 0.07241924107074738\n",
      "\n",
      "Val func train loss in epoch 8:0.08716601668857038\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.06496141105890274\n",
      "\n",
      "episode 2, val func loss 0.10956133157014847\n",
      "\n",
      "episode 3, val func loss 0.08766385912895203\n",
      "\n",
      "episode 4, val func loss 0.06591112166643143\n",
      "\n",
      "episode 5, val func loss 0.06604272872209549\n",
      "\n",
      "episode 6, val func loss 0.11657679826021194\n",
      "\n",
      "episode 7, val func loss 0.11265308409929276\n",
      "\n",
      "episode 8, val func loss 0.08896387368440628\n",
      "\n",
      "episode 9, val func loss 0.07529787719249725\n",
      "\n",
      "episode 10, val func loss 0.09072086960077286\n",
      "\n",
      "episode 11, val func loss 0.12756097316741943\n",
      "\n",
      "episode 12, val func loss 0.04164918139576912\n",
      "\n",
      "episode 13, val func loss 0.0704142153263092\n",
      "\n",
      "episode 14, val func loss 0.11287042498588562\n",
      "\n",
      "episode 15, val func loss 0.09719671308994293\n",
      "\n",
      "episode 16, val func loss 0.08912255614995956\n",
      "\n",
      "Val func train loss in epoch 9:0.08857293869368732\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.10966388136148453\n",
      "\n",
      "episode 2, val func loss 0.07194294780492783\n",
      "\n",
      "episode 3, val func loss 0.1102810725569725\n",
      "\n",
      "episode 4, val func loss 0.09080144762992859\n",
      "\n",
      "episode 5, val func loss 0.07341530174016953\n",
      "\n",
      "episode 6, val func loss 0.06612852215766907\n",
      "\n",
      "episode 7, val func loss 0.10964009165763855\n",
      "\n",
      "episode 8, val func loss 0.08985312283039093\n",
      "\n",
      "episode 9, val func loss 0.08770635724067688\n",
      "\n",
      "episode 10, val func loss 0.0845159962773323\n",
      "\n",
      "episode 11, val func loss 0.06557443737983704\n",
      "\n",
      "episode 12, val func loss 0.11210080981254578\n",
      "\n",
      "episode 13, val func loss 0.044468674808740616\n",
      "\n",
      "episode 14, val func loss 0.11766135692596436\n",
      "\n",
      "episode 15, val func loss 0.0696786418557167\n",
      "\n",
      "episode 16, val func loss 0.09401920437812805\n",
      "\n",
      "Val func train loss in epoch 10:0.0873407416511327\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.07002424448728561\n",
      "\n",
      "episode 2, val func loss 0.07409852743148804\n",
      "\n",
      "episode 3, val func loss 0.040098365396261215\n",
      "\n",
      "episode 4, val func loss 0.09061697125434875\n",
      "\n",
      "episode 5, val func loss 0.11511606723070145\n",
      "\n",
      "episode 6, val func loss 0.06434550881385803\n",
      "\n",
      "episode 7, val func loss 0.11873853206634521\n",
      "\n",
      "episode 8, val func loss 0.10395949333906174\n",
      "\n",
      "episode 9, val func loss 0.12104390561580658\n",
      "\n",
      "episode 10, val func loss 0.08756358921527863\n",
      "\n",
      "episode 11, val func loss 0.09716331958770752\n",
      "\n",
      "episode 12, val func loss 0.07104728370904922\n",
      "\n",
      "episode 13, val func loss 0.09494833648204803\n",
      "\n",
      "episode 14, val func loss 0.0651092454791069\n",
      "\n",
      "episode 15, val func loss 0.10848158597946167\n",
      "\n",
      "episode 16, val func loss 0.11799947172403336\n",
      "\n",
      "Val func train loss in epoch 11:0.09002215298824012\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.06480054557323456\n",
      "\n",
      "episode 2, val func loss 0.08957856893539429\n",
      "\n",
      "episode 3, val func loss 0.12074025720357895\n",
      "\n",
      "episode 4, val func loss 0.11180978268384933\n",
      "\n",
      "episode 5, val func loss 0.08412129431962967\n",
      "\n",
      "episode 6, val func loss 0.09255244582891464\n",
      "\n",
      "episode 7, val func loss 0.06518585234880447\n",
      "\n",
      "episode 8, val func loss 0.08807990700006485\n",
      "\n",
      "episode 9, val func loss 0.04069618135690689\n",
      "\n",
      "episode 10, val func loss 0.08994223922491074\n",
      "\n",
      "episode 11, val func loss 0.06844314932823181\n",
      "\n",
      "episode 12, val func loss 0.1091705933213234\n",
      "\n",
      "episode 13, val func loss 0.11149456351995468\n",
      "\n",
      "episode 14, val func loss 0.06521975249052048\n",
      "\n",
      "episode 15, val func loss 0.07367316633462906\n",
      "\n",
      "episode 16, val func loss 0.11919349431991577\n",
      "\n",
      "Val func train loss in epoch 12:0.08716886211186647\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.11532391607761383\n",
      "\n",
      "episode 2, val func loss 0.1116611659526825\n",
      "\n",
      "episode 3, val func loss 0.06797569245100021\n",
      "\n",
      "episode 4, val func loss 0.08797637373209\n",
      "\n",
      "episode 5, val func loss 0.11890964955091476\n",
      "\n",
      "episode 6, val func loss 0.06533908098936081\n",
      "\n",
      "episode 7, val func loss 0.08925144374370575\n",
      "\n",
      "episode 8, val func loss 0.06577260047197342\n",
      "\n",
      "episode 9, val func loss 0.08365927636623383\n",
      "\n",
      "episode 10, val func loss 0.09400280565023422\n",
      "\n",
      "episode 11, val func loss 0.04256168752908707\n",
      "\n",
      "episode 12, val func loss 0.07386285811662674\n",
      "\n",
      "episode 13, val func loss 0.10961588472127914\n",
      "\n",
      "episode 14, val func loss 0.07134374231100082\n",
      "\n",
      "episode 15, val func loss 0.09071779251098633\n",
      "\n",
      "episode 16, val func loss 0.11073348671197891\n",
      "\n",
      "Val func train loss in epoch 13:0.08741921605542302\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.08930913358926773\n",
      "\n",
      "episode 2, val func loss 0.11018156260251999\n",
      "\n",
      "episode 3, val func loss 0.12056802213191986\n",
      "\n",
      "episode 4, val func loss 0.11001792550086975\n",
      "\n",
      "episode 5, val func loss 0.06590691953897476\n",
      "\n",
      "episode 6, val func loss 0.08408550918102264\n",
      "\n",
      "episode 7, val func loss 0.04061434790492058\n",
      "\n",
      "episode 8, val func loss 0.06781943887472153\n",
      "\n",
      "episode 9, val func loss 0.09245536476373672\n",
      "\n",
      "episode 10, val func loss 0.07391230762004852\n",
      "\n",
      "episode 11, val func loss 0.11348208039999008\n",
      "\n",
      "episode 12, val func loss 0.08902253210544586\n",
      "\n",
      "episode 13, val func loss 0.06708252429962158\n",
      "\n",
      "episode 14, val func loss 0.06490568071603775\n",
      "\n",
      "episode 15, val func loss 0.08832228928804398\n",
      "\n",
      "episode 16, val func loss 0.11131100356578827\n",
      "\n",
      "Val func train loss in epoch 14:0.0868122901301831\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.08915762603282928\n",
      "\n",
      "episode 2, val func loss 0.11077003180980682\n",
      "\n",
      "episode 3, val func loss 0.0672677606344223\n",
      "\n",
      "episode 4, val func loss 0.040763139724731445\n",
      "\n",
      "episode 5, val func loss 0.11528404802083969\n",
      "\n",
      "episode 6, val func loss 0.07390866428613663\n",
      "\n",
      "episode 7, val func loss 0.09020372480154037\n",
      "\n",
      "episode 8, val func loss 0.08664825558662415\n",
      "\n",
      "episode 9, val func loss 0.0684930756688118\n",
      "\n",
      "episode 10, val func loss 0.06647302955389023\n",
      "\n",
      "episode 11, val func loss 0.11196710914373398\n",
      "\n",
      "episode 12, val func loss 0.06924278289079666\n",
      "\n",
      "episode 13, val func loss 0.11481311917304993\n",
      "\n",
      "episode 14, val func loss 0.121873639523983\n",
      "\n",
      "episode 15, val func loss 0.093289315700531\n",
      "\n",
      "episode 16, val func loss 0.09043098986148834\n",
      "\n",
      "Val func train loss in epoch 15:0.08816164452582598\n",
      "***********************TIME WAS 5.284245947996776 min*****************************\n",
      "\n",
      "**********************ROUND 11 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.12919186055660248\n",
      "\n",
      "episode 2, policy loss -0.12195967882871628\n",
      "\n",
      "episode 3, policy loss -0.11183781176805496\n",
      "\n",
      "episode 4, policy loss -0.10494676232337952\n",
      "\n",
      "episode 5, policy loss -0.14080184698104858\n",
      "\n",
      "episode 6, policy loss -0.08708556741476059\n",
      "\n",
      "episode 7, policy loss -0.13560259342193604\n",
      "\n",
      "episode 8, policy loss -0.13850761950016022\n",
      "\n",
      "episode 9, policy loss -0.09988299012184143\n",
      "\n",
      "episode 10, policy loss -0.12695084512233734\n",
      "\n",
      "episode 11, policy loss -0.126743882894516\n",
      "\n",
      "episode 12, policy loss -0.09821943193674088\n",
      "\n",
      "episode 13, policy loss -0.17453844845294952\n",
      "\n",
      "episode 14, policy loss -0.11478067934513092\n",
      "\n",
      "episode 15, policy loss -0.08719304949045181\n",
      "\n",
      "episode 16, policy loss -0.10228793323040009\n",
      "\n",
      "Policy train loss in epoch 0:-0.11878318758681417\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.1451881229877472\n",
      "\n",
      "episode 2, policy loss -0.14207112789154053\n",
      "\n",
      "episode 3, policy loss -0.12441334128379822\n",
      "\n",
      "episode 4, policy loss -0.09525471925735474\n",
      "\n",
      "episode 5, policy loss -0.13158395886421204\n",
      "\n",
      "episode 6, policy loss -0.12582768499851227\n",
      "\n",
      "episode 7, policy loss -0.08641988039016724\n",
      "\n",
      "episode 8, policy loss -0.09139334410429001\n",
      "\n",
      "episode 9, policy loss -0.10778351873159409\n",
      "\n",
      "episode 10, policy loss -0.18604527413845062\n",
      "\n",
      "episode 11, policy loss -0.0970470979809761\n",
      "\n",
      "episode 12, policy loss -0.09828385710716248\n",
      "\n",
      "episode 13, policy loss -0.12948614358901978\n",
      "\n",
      "episode 14, policy loss -0.11847706139087677\n",
      "\n",
      "episode 15, policy loss -0.13755229115486145\n",
      "\n",
      "episode 16, policy loss -0.11060671508312225\n",
      "\n",
      "Policy train loss in epoch 1:-0.12046463368460536\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.12935450673103333\n",
      "\n",
      "episode 2, policy loss -0.0957770049571991\n",
      "\n",
      "episode 3, policy loss -0.18295617401599884\n",
      "\n",
      "episode 4, policy loss -0.13923300802707672\n",
      "\n",
      "episode 5, policy loss -0.13380485773086548\n",
      "\n",
      "episode 6, policy loss -0.1214497834444046\n",
      "\n",
      "episode 7, policy loss -0.1434677690267563\n",
      "\n",
      "episode 8, policy loss -0.10868781805038452\n",
      "\n",
      "episode 9, policy loss -0.09727464616298676\n",
      "\n",
      "episode 10, policy loss -0.1250775307416916\n",
      "\n",
      "episode 11, policy loss -0.0881272405385971\n",
      "\n",
      "episode 12, policy loss -0.11412841826677322\n",
      "\n",
      "episode 13, policy loss -0.11132167279720306\n",
      "\n",
      "episode 14, policy loss -0.09356361627578735\n",
      "\n",
      "episode 15, policy loss -0.08586564660072327\n",
      "\n",
      "episode 16, policy loss -0.12198328971862793\n",
      "\n",
      "Policy train loss in epoch 2:-0.11825456144288182\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.11253582686185837\n",
      "\n",
      "episode 2, policy loss -0.09702792763710022\n",
      "\n",
      "episode 3, policy loss -0.09605120122432709\n",
      "\n",
      "episode 4, policy loss -0.12539930641651154\n",
      "\n",
      "episode 5, policy loss -0.1344749480485916\n",
      "\n",
      "episode 6, policy loss -0.14299026131629944\n",
      "\n",
      "episode 7, policy loss -0.13993893563747406\n",
      "\n",
      "episode 8, policy loss -0.08835747838020325\n",
      "\n",
      "episode 9, policy loss -0.1172015517950058\n",
      "\n",
      "episode 10, policy loss -0.08790915459394455\n",
      "\n",
      "episode 11, policy loss -0.11437928676605225\n",
      "\n",
      "episode 12, policy loss -0.12452105432748795\n",
      "\n",
      "episode 13, policy loss -0.09687666594982147\n",
      "\n",
      "episode 14, policy loss -0.10716915130615234\n",
      "\n",
      "episode 15, policy loss -0.1856992393732071\n",
      "\n",
      "episode 16, policy loss -0.12471259385347366\n",
      "\n",
      "Policy train loss in epoch 3:-0.11845278646796942\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1331128031015396\n",
      "\n",
      "episode 2, val func loss 0.10645408183336258\n",
      "\n",
      "episode 3, val func loss 0.09205793589353561\n",
      "\n",
      "episode 4, val func loss 0.09618069976568222\n",
      "\n",
      "episode 5, val func loss 0.04457790032029152\n",
      "\n",
      "episode 6, val func loss 0.09644058346748352\n",
      "\n",
      "episode 7, val func loss 0.03637823462486267\n",
      "\n",
      "episode 8, val func loss 0.11079499870538712\n",
      "\n",
      "episode 9, val func loss 0.1161692664027214\n",
      "\n",
      "episode 10, val func loss 0.05886363983154297\n",
      "\n",
      "episode 11, val func loss 0.1631229668855667\n",
      "\n",
      "episode 12, val func loss 0.13435839116573334\n",
      "\n",
      "episode 13, val func loss 0.1044498160481453\n",
      "\n",
      "episode 14, val func loss 0.0923319086432457\n",
      "\n",
      "episode 15, val func loss 0.11590882390737534\n",
      "\n",
      "episode 16, val func loss 0.11697431653738022\n",
      "\n",
      "Val func train loss in epoch 0:0.10113602294586599\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.12367688119411469\n",
      "\n",
      "episode 2, val func loss 0.1643228828907013\n",
      "\n",
      "episode 3, val func loss 0.1296158730983734\n",
      "\n",
      "episode 4, val func loss 0.09200948476791382\n",
      "\n",
      "episode 5, val func loss 0.11121870577335358\n",
      "\n",
      "episode 6, val func loss 0.11039333790540695\n",
      "\n",
      "episode 7, val func loss 0.039615198969841\n",
      "\n",
      "episode 8, val func loss 0.05868421494960785\n",
      "\n",
      "episode 9, val func loss 0.08668909221887589\n",
      "\n",
      "episode 10, val func loss 0.0355500690639019\n",
      "\n",
      "episode 11, val func loss 0.1323813796043396\n",
      "\n",
      "episode 12, val func loss 0.09262166172266006\n",
      "\n",
      "episode 13, val func loss 0.098922960460186\n",
      "\n",
      "episode 14, val func loss 0.10671267658472061\n",
      "\n",
      "episode 15, val func loss 0.09952039271593094\n",
      "\n",
      "episode 16, val func loss 0.11625728756189346\n",
      "\n",
      "Val func train loss in epoch 1:0.09988700621761382\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.13267260789871216\n",
      "\n",
      "episode 2, val func loss 0.09603139758110046\n",
      "\n",
      "episode 3, val func loss 0.03747037798166275\n",
      "\n",
      "episode 4, val func loss 0.10310333967208862\n",
      "\n",
      "episode 5, val func loss 0.10767721384763718\n",
      "\n",
      "episode 6, val func loss 0.10165691375732422\n",
      "\n",
      "episode 7, val func loss 0.10561781376600266\n",
      "\n",
      "episode 8, val func loss 0.09579228609800339\n",
      "\n",
      "episode 9, val func loss 0.12378396093845367\n",
      "\n",
      "episode 10, val func loss 0.09665436297655106\n",
      "\n",
      "episode 11, val func loss 0.11684181541204453\n",
      "\n",
      "episode 12, val func loss 0.10621203482151031\n",
      "\n",
      "episode 13, val func loss 0.16771632432937622\n",
      "\n",
      "episode 14, val func loss 0.09318741410970688\n",
      "\n",
      "episode 15, val func loss 0.04454169049859047\n",
      "\n",
      "episode 16, val func loss 0.06004273146390915\n",
      "\n",
      "Val func train loss in epoch 2:0.09931264282204211\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.11242667585611343\n",
      "\n",
      "episode 2, val func loss 0.13426029682159424\n",
      "\n",
      "episode 3, val func loss 0.09583106637001038\n",
      "\n",
      "episode 4, val func loss 0.09250394254922867\n",
      "\n",
      "episode 5, val func loss 0.058957070112228394\n",
      "\n",
      "episode 6, val func loss 0.09486229717731476\n",
      "\n",
      "episode 7, val func loss 0.101948581635952\n",
      "\n",
      "episode 8, val func loss 0.08775711059570312\n",
      "\n",
      "episode 9, val func loss 0.16384382545948029\n",
      "\n",
      "episode 10, val func loss 0.0354517363011837\n",
      "\n",
      "episode 11, val func loss 0.11118654906749725\n",
      "\n",
      "episode 12, val func loss 0.10747003555297852\n",
      "\n",
      "episode 13, val func loss 0.12249866127967834\n",
      "\n",
      "episode 14, val func loss 0.10666422545909882\n",
      "\n",
      "episode 15, val func loss 0.04017717391252518\n",
      "\n",
      "episode 16, val func loss 0.09430010616779327\n",
      "\n",
      "Val func train loss in epoch 3:0.09750870964489877\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.11057153344154358\n",
      "\n",
      "episode 2, val func loss 0.11208312958478928\n",
      "\n",
      "episode 3, val func loss 0.1328689008951187\n",
      "\n",
      "episode 4, val func loss 0.058506861329078674\n",
      "\n",
      "episode 5, val func loss 0.08679071068763733\n",
      "\n",
      "episode 6, val func loss 0.10281646251678467\n",
      "\n",
      "episode 7, val func loss 0.0403728112578392\n",
      "\n",
      "episode 8, val func loss 0.1637183576822281\n",
      "\n",
      "episode 9, val func loss 0.10004792362451553\n",
      "\n",
      "episode 10, val func loss 0.10416214913129807\n",
      "\n",
      "episode 11, val func loss 0.106988325715065\n",
      "\n",
      "episode 12, val func loss 0.11404965817928314\n",
      "\n",
      "episode 13, val func loss 0.09231863915920258\n",
      "\n",
      "episode 14, val func loss 0.03557601198554039\n",
      "\n",
      "episode 15, val func loss 0.12259218096733093\n",
      "\n",
      "episode 16, val func loss 0.09397824853658676\n",
      "\n",
      "Val func train loss in epoch 4:0.09859011904336512\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.09919963032007217\n",
      "\n",
      "episode 2, val func loss 0.09246894717216492\n",
      "\n",
      "episode 3, val func loss 0.13629861176013947\n",
      "\n",
      "episode 4, val func loss 0.1641509234905243\n",
      "\n",
      "episode 5, val func loss 0.10769956558942795\n",
      "\n",
      "episode 6, val func loss 0.09537086635828018\n",
      "\n",
      "episode 7, val func loss 0.09516435116529465\n",
      "\n",
      "episode 8, val func loss 0.08785374462604523\n",
      "\n",
      "episode 9, val func loss 0.036544907838106155\n",
      "\n",
      "episode 10, val func loss 0.10615885257720947\n",
      "\n",
      "episode 11, val func loss 0.05827512964606285\n",
      "\n",
      "episode 12, val func loss 0.0943494662642479\n",
      "\n",
      "episode 13, val func loss 0.03983132168650627\n",
      "\n",
      "episode 14, val func loss 0.10720665752887726\n",
      "\n",
      "episode 15, val func loss 0.11309574544429779\n",
      "\n",
      "episode 16, val func loss 0.1325017213821411\n",
      "\n",
      "Val func train loss in epoch 5:0.09788565267808735\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.04108353704214096\n",
      "\n",
      "episode 2, val func loss 0.035387374460697174\n",
      "\n",
      "episode 3, val func loss 0.09991127997636795\n",
      "\n",
      "episode 4, val func loss 0.09555848687887192\n",
      "\n",
      "episode 5, val func loss 0.08603708446025848\n",
      "\n",
      "episode 6, val func loss 0.13317042589187622\n",
      "\n",
      "episode 7, val func loss 0.09283486753702164\n",
      "\n",
      "episode 8, val func loss 0.1677572876214981\n",
      "\n",
      "episode 9, val func loss 0.10890160501003265\n",
      "\n",
      "episode 10, val func loss 0.09655918180942535\n",
      "\n",
      "episode 11, val func loss 0.10399611294269562\n",
      "\n",
      "episode 12, val func loss 0.11348920315504074\n",
      "\n",
      "episode 13, val func loss 0.05864247307181358\n",
      "\n",
      "episode 14, val func loss 0.12244568020105362\n",
      "\n",
      "episode 15, val func loss 0.10353529453277588\n",
      "\n",
      "episode 16, val func loss 0.10791144520044327\n",
      "\n",
      "Val func train loss in epoch 6:0.09795133373700082\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.092891164124012\n",
      "\n",
      "episode 2, val func loss 0.06344124674797058\n",
      "\n",
      "episode 3, val func loss 0.1204427108168602\n",
      "\n",
      "episode 4, val func loss 0.08858585357666016\n",
      "\n",
      "episode 5, val func loss 0.10785575956106186\n",
      "\n",
      "episode 6, val func loss 0.12405546754598618\n",
      "\n",
      "episode 7, val func loss 0.09499983489513397\n",
      "\n",
      "episode 8, val func loss 0.10901204496622086\n",
      "\n",
      "episode 9, val func loss 0.16812461614608765\n",
      "\n",
      "episode 10, val func loss 0.09904619306325912\n",
      "\n",
      "episode 11, val func loss 0.14735952019691467\n",
      "\n",
      "episode 12, val func loss 0.10551314055919647\n",
      "\n",
      "episode 13, val func loss 0.035564497113227844\n",
      "\n",
      "episode 14, val func loss 0.03938344866037369\n",
      "\n",
      "episode 15, val func loss 0.11152461171150208\n",
      "\n",
      "episode 16, val func loss 0.09907420724630356\n",
      "\n",
      "Val func train loss in epoch 7:0.10042964480817318\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.0386740081012249\n",
      "\n",
      "episode 2, val func loss 0.10827284306287766\n",
      "\n",
      "episode 3, val func loss 0.0393502339720726\n",
      "\n",
      "episode 4, val func loss 0.11275722831487656\n",
      "\n",
      "episode 5, val func loss 0.058974143117666245\n",
      "\n",
      "episode 6, val func loss 0.16373316943645477\n",
      "\n",
      "episode 7, val func loss 0.08810325711965561\n",
      "\n",
      "episode 8, val func loss 0.09892110526561737\n",
      "\n",
      "episode 9, val func loss 0.09286510944366455\n",
      "\n",
      "episode 10, val func loss 0.13464142382144928\n",
      "\n",
      "episode 11, val func loss 0.09605912864208221\n",
      "\n",
      "episode 12, val func loss 0.0932057723402977\n",
      "\n",
      "episode 13, val func loss 0.10948243737220764\n",
      "\n",
      "episode 14, val func loss 0.12399762868881226\n",
      "\n",
      "episode 15, val func loss 0.0946672260761261\n",
      "\n",
      "episode 16, val func loss 0.10952342301607132\n",
      "\n",
      "Val func train loss in epoch 8:0.0977017586119473\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.09385354071855545\n",
      "\n",
      "episode 2, val func loss 0.05799154192209244\n",
      "\n",
      "episode 3, val func loss 0.035302840173244476\n",
      "\n",
      "episode 4, val func loss 0.10728343576192856\n",
      "\n",
      "episode 5, val func loss 0.09604914486408234\n",
      "\n",
      "episode 6, val func loss 0.08708985149860382\n",
      "\n",
      "episode 7, val func loss 0.09511798620223999\n",
      "\n",
      "episode 8, val func loss 0.10411956906318665\n",
      "\n",
      "episode 9, val func loss 0.10779208689928055\n",
      "\n",
      "episode 10, val func loss 0.12299183011054993\n",
      "\n",
      "episode 11, val func loss 0.1005338579416275\n",
      "\n",
      "episode 12, val func loss 0.11263503134250641\n",
      "\n",
      "episode 13, val func loss 0.09607827663421631\n",
      "\n",
      "episode 14, val func loss 0.16923631727695465\n",
      "\n",
      "episode 15, val func loss 0.0398651584982872\n",
      "\n",
      "episode 16, val func loss 0.13273541629314423\n",
      "\n",
      "Val func train loss in epoch 9:0.09741724282503128\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.09345392882823944\n",
      "\n",
      "episode 2, val func loss 0.035206690430641174\n",
      "\n",
      "episode 3, val func loss 0.041954174637794495\n",
      "\n",
      "episode 4, val func loss 0.09639007598161697\n",
      "\n",
      "episode 5, val func loss 0.058240052312612534\n",
      "\n",
      "episode 6, val func loss 0.1683298796415329\n",
      "\n",
      "episode 7, val func loss 0.11240420490503311\n",
      "\n",
      "episode 8, val func loss 0.10746036469936371\n",
      "\n",
      "episode 9, val func loss 0.13326165080070496\n",
      "\n",
      "episode 10, val func loss 0.10691263526678085\n",
      "\n",
      "episode 11, val func loss 0.08636930584907532\n",
      "\n",
      "episode 12, val func loss 0.09642361849546432\n",
      "\n",
      "episode 13, val func loss 0.10664872825145721\n",
      "\n",
      "episode 14, val func loss 0.1223745346069336\n",
      "\n",
      "episode 15, val func loss 0.10113602131605148\n",
      "\n",
      "episode 16, val func loss 0.09386467188596725\n",
      "\n",
      "Val func train loss in epoch 10:0.09752690861932933\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.12259534001350403\n",
      "\n",
      "episode 2, val func loss 0.09950187057256699\n",
      "\n",
      "episode 3, val func loss 0.09732947498559952\n",
      "\n",
      "episode 4, val func loss 0.1324605941772461\n",
      "\n",
      "episode 5, val func loss 0.10627306997776031\n",
      "\n",
      "episode 6, val func loss 0.10733739286661148\n",
      "\n",
      "episode 7, val func loss 0.036006901413202286\n",
      "\n",
      "episode 8, val func loss 0.10741422325372696\n",
      "\n",
      "episode 9, val func loss 0.05955963581800461\n",
      "\n",
      "episode 10, val func loss 0.0420418307185173\n",
      "\n",
      "episode 11, val func loss 0.11431685835123062\n",
      "\n",
      "episode 12, val func loss 0.08658982068300247\n",
      "\n",
      "episode 13, val func loss 0.16807179152965546\n",
      "\n",
      "episode 14, val func loss 0.09383956342935562\n",
      "\n",
      "episode 15, val func loss 0.09534616023302078\n",
      "\n",
      "episode 16, val func loss 0.09495621174573898\n",
      "\n",
      "Val func train loss in epoch 11:0.09772754623554647\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.09435997158288956\n",
      "\n",
      "episode 2, val func loss 0.10811661928892136\n",
      "\n",
      "episode 3, val func loss 0.09401316195726395\n",
      "\n",
      "episode 4, val func loss 0.16669796407222748\n",
      "\n",
      "episode 5, val func loss 0.09884915500879288\n",
      "\n",
      "episode 6, val func loss 0.10712013393640518\n",
      "\n",
      "episode 7, val func loss 0.10515451431274414\n",
      "\n",
      "episode 8, val func loss 0.12266131490468979\n",
      "\n",
      "episode 9, val func loss 0.035587117075920105\n",
      "\n",
      "episode 10, val func loss 0.08642760664224625\n",
      "\n",
      "episode 11, val func loss 0.13205912709236145\n",
      "\n",
      "episode 12, val func loss 0.11246849596500397\n",
      "\n",
      "episode 13, val func loss 0.09343493729829788\n",
      "\n",
      "episode 14, val func loss 0.04134010151028633\n",
      "\n",
      "episode 15, val func loss 0.09922628104686737\n",
      "\n",
      "episode 16, val func loss 0.059881918132305145\n",
      "\n",
      "Val func train loss in epoch 12:0.09733740123920143\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.09560795873403549\n",
      "\n",
      "episode 2, val func loss 0.10629349201917648\n",
      "\n",
      "episode 3, val func loss 0.12432081997394562\n",
      "\n",
      "episode 4, val func loss 0.13607348501682281\n",
      "\n",
      "episode 5, val func loss 0.08634138107299805\n",
      "\n",
      "episode 6, val func loss 0.09826286882162094\n",
      "\n",
      "episode 7, val func loss 0.10728595405817032\n",
      "\n",
      "episode 8, val func loss 0.11284729838371277\n",
      "\n",
      "episode 9, val func loss 0.03520793467760086\n",
      "\n",
      "episode 10, val func loss 0.10353712737560272\n",
      "\n",
      "episode 11, val func loss 0.041100215166807175\n",
      "\n",
      "episode 12, val func loss 0.09257271885871887\n",
      "\n",
      "episode 13, val func loss 0.09744302183389664\n",
      "\n",
      "episode 14, val func loss 0.16459788382053375\n",
      "\n",
      "episode 15, val func loss 0.099423848092556\n",
      "\n",
      "episode 16, val func loss 0.05894823744893074\n",
      "\n",
      "Val func train loss in epoch 13:0.09749151533469558\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.10669687390327454\n",
      "\n",
      "episode 2, val func loss 0.13357578217983246\n",
      "\n",
      "episode 3, val func loss 0.04038749262690544\n",
      "\n",
      "episode 4, val func loss 0.09448403865098953\n",
      "\n",
      "episode 5, val func loss 0.11517111212015152\n",
      "\n",
      "episode 6, val func loss 0.1058845967054367\n",
      "\n",
      "episode 7, val func loss 0.09579162299633026\n",
      "\n",
      "episode 8, val func loss 0.10429860651493073\n",
      "\n",
      "episode 9, val func loss 0.09889595955610275\n",
      "\n",
      "episode 10, val func loss 0.09393097460269928\n",
      "\n",
      "episode 11, val func loss 0.10208911448717117\n",
      "\n",
      "episode 12, val func loss 0.0356205515563488\n",
      "\n",
      "episode 13, val func loss 0.1748429387807846\n",
      "\n",
      "episode 14, val func loss 0.12278510630130768\n",
      "\n",
      "episode 15, val func loss 0.05834025517106056\n",
      "\n",
      "episode 16, val func loss 0.09712731838226318\n",
      "\n",
      "Val func train loss in epoch 14:0.09874514653347433\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.0935763493180275\n",
      "\n",
      "episode 2, val func loss 0.09534837305545807\n",
      "\n",
      "episode 3, val func loss 0.1012682318687439\n",
      "\n",
      "episode 4, val func loss 0.03610207512974739\n",
      "\n",
      "episode 5, val func loss 0.13302502036094666\n",
      "\n",
      "episode 6, val func loss 0.10651566833257675\n",
      "\n",
      "episode 7, val func loss 0.12860684096813202\n",
      "\n",
      "episode 8, val func loss 0.10892853885889053\n",
      "\n",
      "episode 9, val func loss 0.11279652267694473\n",
      "\n",
      "episode 10, val func loss 0.08745421469211578\n",
      "\n",
      "episode 11, val func loss 0.17248503863811493\n",
      "\n",
      "episode 12, val func loss 0.04002407565712929\n",
      "\n",
      "episode 13, val func loss 0.05907030776143074\n",
      "\n",
      "episode 14, val func loss 0.09863948822021484\n",
      "\n",
      "episode 15, val func loss 0.103350929915905\n",
      "\n",
      "episode 16, val func loss 0.09868878871202469\n",
      "\n",
      "Val func train loss in epoch 15:0.09849252901040018\n",
      "***********************TIME WAS 5.2161353866259255 min*****************************\n",
      "\n",
      "**********************ROUND 12 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.0630917102098465\n",
      "\n",
      "episode 2, policy loss -0.09635815024375916\n",
      "\n",
      "episode 3, policy loss -0.09743289649486542\n",
      "\n",
      "episode 4, policy loss -0.10525871813297272\n",
      "\n",
      "episode 5, policy loss -0.12360183894634247\n",
      "\n",
      "episode 6, policy loss -0.10164504498243332\n",
      "\n",
      "episode 7, policy loss -0.17017531394958496\n",
      "\n",
      "episode 8, policy loss -0.1051710918545723\n",
      "\n",
      "episode 9, policy loss -0.11168252676725388\n",
      "\n",
      "episode 10, policy loss -0.07574272155761719\n",
      "\n",
      "episode 11, policy loss -0.08077262341976166\n",
      "\n",
      "episode 12, policy loss -0.1450679898262024\n",
      "\n",
      "episode 13, policy loss -0.05778113007545471\n",
      "\n",
      "episode 14, policy loss -0.07171190530061722\n",
      "\n",
      "episode 15, policy loss -0.047267913818359375\n",
      "\n",
      "episode 16, policy loss -0.14394503831863403\n",
      "\n",
      "Policy train loss in epoch 0:-0.09979416336864233\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.06439539790153503\n",
      "\n",
      "episode 2, policy loss -0.07509002089500427\n",
      "\n",
      "episode 3, policy loss -0.14372771978378296\n",
      "\n",
      "episode 4, policy loss -0.13812194764614105\n",
      "\n",
      "episode 5, policy loss -0.1128217875957489\n",
      "\n",
      "episode 6, policy loss -0.047986507415771484\n",
      "\n",
      "episode 7, policy loss -0.16704919934272766\n",
      "\n",
      "episode 8, policy loss -0.07285195589065552\n",
      "\n",
      "episode 9, policy loss -0.10488506406545639\n",
      "\n",
      "episode 10, policy loss -0.10472714155912399\n",
      "\n",
      "episode 11, policy loss -0.07358275353908539\n",
      "\n",
      "episode 12, policy loss -0.09149664640426636\n",
      "\n",
      "episode 13, policy loss -0.10413167625665665\n",
      "\n",
      "episode 14, policy loss -0.05893023684620857\n",
      "\n",
      "episode 15, policy loss -0.09856495261192322\n",
      "\n",
      "episode 16, policy loss -0.12223239988088608\n",
      "\n",
      "Policy train loss in epoch 1:-0.09878721297718585\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.04617893695831299\n",
      "\n",
      "episode 2, policy loss -0.09895730018615723\n",
      "\n",
      "episode 3, policy loss -0.08149277418851852\n",
      "\n",
      "episode 4, policy loss -0.06490305811166763\n",
      "\n",
      "episode 5, policy loss -0.1448613703250885\n",
      "\n",
      "episode 6, policy loss -0.11475209146738052\n",
      "\n",
      "episode 7, policy loss -0.06047632545232773\n",
      "\n",
      "episode 8, policy loss -0.16779784858226776\n",
      "\n",
      "episode 9, policy loss -0.10901252180337906\n",
      "\n",
      "episode 10, policy loss -0.10509854555130005\n",
      "\n",
      "episode 11, policy loss -0.0776054784655571\n",
      "\n",
      "episode 12, policy loss -0.12459559738636017\n",
      "\n",
      "episode 13, policy loss -0.09777949750423431\n",
      "\n",
      "episode 14, policy loss -0.10592721402645111\n",
      "\n",
      "episode 15, policy loss -0.1436585783958435\n",
      "\n",
      "episode 16, policy loss -0.07904722541570663\n",
      "\n",
      "Policy train loss in epoch 2:-0.10138402273878455\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.04854901507496834\n",
      "\n",
      "episode 2, policy loss -0.09661370515823364\n",
      "\n",
      "episode 3, policy loss -0.10487121343612671\n",
      "\n",
      "episode 4, policy loss -0.0743480697274208\n",
      "\n",
      "episode 5, policy loss -0.12681028246879578\n",
      "\n",
      "episode 6, policy loss -0.10991498082876205\n",
      "\n",
      "episode 7, policy loss -0.14614206552505493\n",
      "\n",
      "episode 8, policy loss -0.14697101712226868\n",
      "\n",
      "episode 9, policy loss -0.07844467461109161\n",
      "\n",
      "episode 10, policy loss -0.08257567137479782\n",
      "\n",
      "episode 11, policy loss -0.09881101548671722\n",
      "\n",
      "episode 12, policy loss -0.057755403220653534\n",
      "\n",
      "episode 13, policy loss -0.11370740830898285\n",
      "\n",
      "episode 14, policy loss -0.1669495701789856\n",
      "\n",
      "episode 15, policy loss -0.06563369929790497\n",
      "\n",
      "episode 16, policy loss -0.10357043147087097\n",
      "\n",
      "Policy train loss in epoch 3:-0.10135426395572722\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.0602603480219841\n",
      "\n",
      "episode 2, val func loss 0.12894479930400848\n",
      "\n",
      "episode 3, val func loss 0.08447740972042084\n",
      "\n",
      "episode 4, val func loss 0.10744183510541916\n",
      "\n",
      "episode 5, val func loss 0.18627071380615234\n",
      "\n",
      "episode 6, val func loss 0.09834080189466476\n",
      "\n",
      "episode 7, val func loss 0.1322069615125656\n",
      "\n",
      "episode 8, val func loss 0.10899132490158081\n",
      "\n",
      "episode 9, val func loss 0.10910771042108536\n",
      "\n",
      "episode 10, val func loss 0.16542665660381317\n",
      "\n",
      "episode 11, val func loss 0.09664428234100342\n",
      "\n",
      "episode 12, val func loss 0.10912863165140152\n",
      "\n",
      "episode 13, val func loss 0.12544292211532593\n",
      "\n",
      "episode 14, val func loss 0.1228431984782219\n",
      "\n",
      "episode 15, val func loss 0.13856729865074158\n",
      "\n",
      "episode 16, val func loss 0.1339074820280075\n",
      "\n",
      "Val func train loss in epoch 0:0.11925014853477478\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.12358177453279495\n",
      "\n",
      "episode 2, val func loss 0.09151624888181686\n",
      "\n",
      "episode 3, val func loss 0.11003416031599045\n",
      "\n",
      "episode 4, val func loss 0.09735695272684097\n",
      "\n",
      "episode 5, val func loss 0.16095022857189178\n",
      "\n",
      "episode 6, val func loss 0.1196460872888565\n",
      "\n",
      "episode 7, val func loss 0.12704266607761383\n",
      "\n",
      "episode 8, val func loss 0.08603145182132721\n",
      "\n",
      "episode 9, val func loss 0.2185172289609909\n",
      "\n",
      "episode 10, val func loss 0.11051903665065765\n",
      "\n",
      "episode 11, val func loss 0.14094337821006775\n",
      "\n",
      "episode 12, val func loss 0.13633371889591217\n",
      "\n",
      "episode 13, val func loss 0.11046379059553146\n",
      "\n",
      "episode 14, val func loss 0.060794271528720856\n",
      "\n",
      "episode 15, val func loss 0.1242508590221405\n",
      "\n",
      "episode 16, val func loss 0.12616977095603943\n",
      "\n",
      "Val func train loss in epoch 1:0.12150947656482458\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.0978570431470871\n",
      "\n",
      "episode 2, val func loss 0.05916907638311386\n",
      "\n",
      "episode 3, val func loss 0.14811694622039795\n",
      "\n",
      "episode 4, val func loss 0.16711075603961945\n",
      "\n",
      "episode 5, val func loss 0.1399189978837967\n",
      "\n",
      "episode 6, val func loss 0.10758993029594421\n",
      "\n",
      "episode 7, val func loss 0.10715674608945847\n",
      "\n",
      "episode 8, val func loss 0.09715432673692703\n",
      "\n",
      "episode 9, val func loss 0.11065765470266342\n",
      "\n",
      "episode 10, val func loss 0.08735425770282745\n",
      "\n",
      "episode 11, val func loss 0.13110099732875824\n",
      "\n",
      "episode 12, val func loss 0.11093170940876007\n",
      "\n",
      "episode 13, val func loss 0.12731249630451202\n",
      "\n",
      "episode 14, val func loss 0.12665410339832306\n",
      "\n",
      "episode 15, val func loss 0.12670785188674927\n",
      "\n",
      "episode 16, val func loss 0.1945619434118271\n",
      "\n",
      "Val func train loss in epoch 2:0.12120967730879784\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.09481297433376312\n",
      "\n",
      "episode 2, val func loss 0.09692636132240295\n",
      "\n",
      "episode 3, val func loss 0.1335931271314621\n",
      "\n",
      "episode 4, val func loss 0.10747532546520233\n",
      "\n",
      "episode 5, val func loss 0.11060025542974472\n",
      "\n",
      "episode 6, val func loss 0.1214185506105423\n",
      "\n",
      "episode 7, val func loss 0.1643025130033493\n",
      "\n",
      "episode 8, val func loss 0.18242782354354858\n",
      "\n",
      "episode 9, val func loss 0.10856244713068008\n",
      "\n",
      "episode 10, val func loss 0.14525678753852844\n",
      "\n",
      "episode 11, val func loss 0.06290985643863678\n",
      "\n",
      "episode 12, val func loss 0.08491560071706772\n",
      "\n",
      "episode 13, val func loss 0.1427871435880661\n",
      "\n",
      "episode 14, val func loss 0.13736385107040405\n",
      "\n",
      "episode 15, val func loss 0.10884824395179749\n",
      "\n",
      "episode 16, val func loss 0.12226676940917969\n",
      "\n",
      "Val func train loss in epoch 3:0.12027922691777349\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.14794373512268066\n",
      "\n",
      "episode 2, val func loss 0.1492575854063034\n",
      "\n",
      "episode 3, val func loss 0.08936706185340881\n",
      "\n",
      "episode 4, val func loss 0.09903951734304428\n",
      "\n",
      "episode 5, val func loss 0.12484925985336304\n",
      "\n",
      "episode 6, val func loss 0.11914663761854172\n",
      "\n",
      "episode 7, val func loss 0.05821891501545906\n",
      "\n",
      "episode 8, val func loss 0.10815563797950745\n",
      "\n",
      "episode 9, val func loss 0.12465991079807281\n",
      "\n",
      "episode 10, val func loss 0.09961488842964172\n",
      "\n",
      "episode 11, val func loss 0.16203801333904266\n",
      "\n",
      "episode 12, val func loss 0.18425491452217102\n",
      "\n",
      "episode 13, val func loss 0.12639552354812622\n",
      "\n",
      "episode 14, val func loss 0.10880763828754425\n",
      "\n",
      "episode 15, val func loss 0.10593932867050171\n",
      "\n",
      "episode 16, val func loss 0.12443022429943085\n",
      "\n",
      "Val func train loss in epoch 4:0.12075742450542748\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.10984643548727036\n",
      "\n",
      "episode 2, val func loss 0.08389721065759659\n",
      "\n",
      "episode 3, val func loss 0.1298360675573349\n",
      "\n",
      "episode 4, val func loss 0.10867923498153687\n",
      "\n",
      "episode 5, val func loss 0.12237174063920975\n",
      "\n",
      "episode 6, val func loss 0.1088620200753212\n",
      "\n",
      "episode 7, val func loss 0.10947680473327637\n",
      "\n",
      "episode 8, val func loss 0.06315319240093231\n",
      "\n",
      "episode 9, val func loss 0.09664444625377655\n",
      "\n",
      "episode 10, val func loss 0.1321151852607727\n",
      "\n",
      "episode 11, val func loss 0.12177074700593948\n",
      "\n",
      "episode 12, val func loss 0.09178916364908218\n",
      "\n",
      "episode 13, val func loss 0.1768900603055954\n",
      "\n",
      "episode 14, val func loss 0.13462164998054504\n",
      "\n",
      "episode 15, val func loss 0.12425252050161362\n",
      "\n",
      "episode 16, val func loss 0.18275277316570282\n",
      "\n",
      "Val func train loss in epoch 5:0.11855995329096913\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.11248762905597687\n",
      "\n",
      "episode 2, val func loss 0.18667151033878326\n",
      "\n",
      "episode 3, val func loss 0.12115872651338577\n",
      "\n",
      "episode 4, val func loss 0.09840743988752365\n",
      "\n",
      "episode 5, val func loss 0.12874673306941986\n",
      "\n",
      "episode 6, val func loss 0.12246984243392944\n",
      "\n",
      "episode 7, val func loss 0.08534597605466843\n",
      "\n",
      "episode 8, val func loss 0.1141519844532013\n",
      "\n",
      "episode 9, val func loss 0.12228047847747803\n",
      "\n",
      "episode 10, val func loss 0.09216064214706421\n",
      "\n",
      "episode 11, val func loss 0.1309119611978531\n",
      "\n",
      "episode 12, val func loss 0.05974557623267174\n",
      "\n",
      "episode 13, val func loss 0.12569420039653778\n",
      "\n",
      "episode 14, val func loss 0.16256077587604523\n",
      "\n",
      "episode 15, val func loss 0.1364450454711914\n",
      "\n",
      "episode 16, val func loss 0.10885452479124069\n",
      "\n",
      "Val func train loss in epoch 6:0.11925581539981067\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.10874930024147034\n",
      "\n",
      "episode 2, val func loss 0.12239999324083328\n",
      "\n",
      "episode 3, val func loss 0.09732944518327713\n",
      "\n",
      "episode 4, val func loss 0.1350688487291336\n",
      "\n",
      "episode 5, val func loss 0.10819664597511292\n",
      "\n",
      "episode 6, val func loss 0.060258932411670685\n",
      "\n",
      "episode 7, val func loss 0.11175163835287094\n",
      "\n",
      "episode 8, val func loss 0.1885913610458374\n",
      "\n",
      "episode 9, val func loss 0.0881127268075943\n",
      "\n",
      "episode 10, val func loss 0.16192401945590973\n",
      "\n",
      "episode 11, val func loss 0.13620567321777344\n",
      "\n",
      "episode 12, val func loss 0.1261662095785141\n",
      "\n",
      "episode 13, val func loss 0.12289626896381378\n",
      "\n",
      "episode 14, val func loss 0.10838693380355835\n",
      "\n",
      "episode 15, val func loss 0.09191269427537918\n",
      "\n",
      "episode 16, val func loss 0.12244497239589691\n",
      "\n",
      "Val func train loss in epoch 7:0.11814972897991538\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.12300209701061249\n",
      "\n",
      "episode 2, val func loss 0.1329699009656906\n",
      "\n",
      "episode 3, val func loss 0.19211329519748688\n",
      "\n",
      "episode 4, val func loss 0.1346472054719925\n",
      "\n",
      "episode 5, val func loss 0.12804129719734192\n",
      "\n",
      "episode 6, val func loss 0.1075543537735939\n",
      "\n",
      "episode 7, val func loss 0.09995228797197342\n",
      "\n",
      "episode 8, val func loss 0.16221675276756287\n",
      "\n",
      "episode 9, val func loss 0.09660765528678894\n",
      "\n",
      "episode 10, val func loss 0.13327261805534363\n",
      "\n",
      "episode 11, val func loss 0.10942365974187851\n",
      "\n",
      "episode 12, val func loss 0.058810245245695114\n",
      "\n",
      "episode 13, val func loss 0.12750782072544098\n",
      "\n",
      "episode 14, val func loss 0.11227565258741379\n",
      "\n",
      "episode 15, val func loss 0.10776648670434952\n",
      "\n",
      "episode 16, val func loss 0.0864107683300972\n",
      "\n",
      "Val func train loss in epoch 8:0.11953575606457889\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.10815977305173874\n",
      "\n",
      "episode 2, val func loss 0.10873402655124664\n",
      "\n",
      "episode 3, val func loss 0.13584910333156586\n",
      "\n",
      "episode 4, val func loss 0.0972268283367157\n",
      "\n",
      "episode 5, val func loss 0.1086181178689003\n",
      "\n",
      "episode 6, val func loss 0.08553053438663483\n",
      "\n",
      "episode 7, val func loss 0.16503991186618805\n",
      "\n",
      "episode 8, val func loss 0.05892288312315941\n",
      "\n",
      "episode 9, val func loss 0.1271531730890274\n",
      "\n",
      "episode 10, val func loss 0.12234029918909073\n",
      "\n",
      "episode 11, val func loss 0.12210606038570404\n",
      "\n",
      "episode 12, val func loss 0.13051192462444305\n",
      "\n",
      "episode 13, val func loss 0.19101643562316895\n",
      "\n",
      "episode 14, val func loss 0.09417951852083206\n",
      "\n",
      "episode 15, val func loss 0.12223716825246811\n",
      "\n",
      "episode 16, val func loss 0.10651317238807678\n",
      "\n",
      "Val func train loss in epoch 9:0.11775868316181004\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1089579239487648\n",
      "\n",
      "episode 2, val func loss 0.09196729212999344\n",
      "\n",
      "episode 3, val func loss 0.06298747658729553\n",
      "\n",
      "episode 4, val func loss 0.1864389330148697\n",
      "\n",
      "episode 5, val func loss 0.12313064187765121\n",
      "\n",
      "episode 6, val func loss 0.11095231026411057\n",
      "\n",
      "episode 7, val func loss 0.13101498782634735\n",
      "\n",
      "episode 8, val func loss 0.12575645744800568\n",
      "\n",
      "episode 9, val func loss 0.1334795504808426\n",
      "\n",
      "episode 10, val func loss 0.12502500414848328\n",
      "\n",
      "episode 11, val func loss 0.12454783916473389\n",
      "\n",
      "episode 12, val func loss 0.0967109352350235\n",
      "\n",
      "episode 13, val func loss 0.16234096884727478\n",
      "\n",
      "episode 14, val func loss 0.10870561748743057\n",
      "\n",
      "episode 15, val func loss 0.10585714876651764\n",
      "\n",
      "episode 16, val func loss 0.09696552157402039\n",
      "\n",
      "Val func train loss in epoch 10:0.1184274130500853\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.13205839693546295\n",
      "\n",
      "episode 2, val func loss 0.13417848944664001\n",
      "\n",
      "episode 3, val func loss 0.09205678105354309\n",
      "\n",
      "episode 4, val func loss 0.11274957656860352\n",
      "\n",
      "episode 5, val func loss 0.17347639799118042\n",
      "\n",
      "episode 6, val func loss 0.11040814220905304\n",
      "\n",
      "episode 7, val func loss 0.09642256796360016\n",
      "\n",
      "episode 8, val func loss 0.09026281535625458\n",
      "\n",
      "episode 9, val func loss 0.0651831328868866\n",
      "\n",
      "episode 10, val func loss 0.1290067583322525\n",
      "\n",
      "episode 11, val func loss 0.10862547904253006\n",
      "\n",
      "episode 12, val func loss 0.11100625991821289\n",
      "\n",
      "episode 13, val func loss 0.1271480917930603\n",
      "\n",
      "episode 14, val func loss 0.12266319245100021\n",
      "\n",
      "episode 15, val func loss 0.12859417498111725\n",
      "\n",
      "episode 16, val func loss 0.1882161647081375\n",
      "\n",
      "Val func train loss in epoch 11:0.12012852635234594\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1261741816997528\n",
      "\n",
      "episode 2, val func loss 0.10777666419744492\n",
      "\n",
      "episode 3, val func loss 0.0686008408665657\n",
      "\n",
      "episode 4, val func loss 0.1414787620306015\n",
      "\n",
      "episode 5, val func loss 0.1614627242088318\n",
      "\n",
      "episode 6, val func loss 0.0970795676112175\n",
      "\n",
      "episode 7, val func loss 0.12313969433307648\n",
      "\n",
      "episode 8, val func loss 0.0927053689956665\n",
      "\n",
      "episode 9, val func loss 0.1999487727880478\n",
      "\n",
      "episode 10, val func loss 0.0850466936826706\n",
      "\n",
      "episode 11, val func loss 0.12248197197914124\n",
      "\n",
      "episode 12, val func loss 0.11037784069776535\n",
      "\n",
      "episode 13, val func loss 0.1095980703830719\n",
      "\n",
      "episode 14, val func loss 0.10895049571990967\n",
      "\n",
      "episode 15, val func loss 0.12106796354055405\n",
      "\n",
      "episode 16, val func loss 0.1421402245759964\n",
      "\n",
      "Val func train loss in epoch 12:0.11987686483189464\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.16184577345848083\n",
      "\n",
      "episode 2, val func loss 0.09012085944414139\n",
      "\n",
      "episode 3, val func loss 0.10802687704563141\n",
      "\n",
      "episode 4, val func loss 0.11090119183063507\n",
      "\n",
      "episode 5, val func loss 0.0922546535730362\n",
      "\n",
      "episode 6, val func loss 0.1286732405424118\n",
      "\n",
      "episode 7, val func loss 0.12324272096157074\n",
      "\n",
      "episode 8, val func loss 0.131846085190773\n",
      "\n",
      "episode 9, val func loss 0.05865222588181496\n",
      "\n",
      "episode 10, val func loss 0.09776870161294937\n",
      "\n",
      "episode 11, val func loss 0.12566524744033813\n",
      "\n",
      "episode 12, val func loss 0.1341148018836975\n",
      "\n",
      "episode 13, val func loss 0.18355457484722137\n",
      "\n",
      "episode 14, val func loss 0.10795796662569046\n",
      "\n",
      "episode 15, val func loss 0.133077472448349\n",
      "\n",
      "episode 16, val func loss 0.108242928981781\n",
      "\n",
      "Val func train loss in epoch 13:0.11849658261053264\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.09649093449115753\n",
      "\n",
      "episode 2, val func loss 0.18791721761226654\n",
      "\n",
      "episode 3, val func loss 0.13328656554222107\n",
      "\n",
      "episode 4, val func loss 0.05970194190740585\n",
      "\n",
      "episode 5, val func loss 0.1258438527584076\n",
      "\n",
      "episode 6, val func loss 0.10729701071977615\n",
      "\n",
      "episode 7, val func loss 0.16244347393512726\n",
      "\n",
      "episode 8, val func loss 0.0875045657157898\n",
      "\n",
      "episode 9, val func loss 0.1244647353887558\n",
      "\n",
      "episode 10, val func loss 0.10847282409667969\n",
      "\n",
      "episode 11, val func loss 0.09526610374450684\n",
      "\n",
      "episode 12, val func loss 0.12274402379989624\n",
      "\n",
      "episode 13, val func loss 0.10770633816719055\n",
      "\n",
      "episode 14, val func loss 0.13140591979026794\n",
      "\n",
      "episode 15, val func loss 0.11204888671636581\n",
      "\n",
      "episode 16, val func loss 0.1288701444864273\n",
      "\n",
      "Val func train loss in epoch 14:0.11821653367951512\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.12724906206130981\n",
      "\n",
      "episode 2, val func loss 0.10755471885204315\n",
      "\n",
      "episode 3, val func loss 0.12487209588289261\n",
      "\n",
      "episode 4, val func loss 0.12256541848182678\n",
      "\n",
      "episode 5, val func loss 0.1624099761247635\n",
      "\n",
      "episode 6, val func loss 0.09945084154605865\n",
      "\n",
      "episode 7, val func loss 0.1345270872116089\n",
      "\n",
      "episode 8, val func loss 0.13380222022533417\n",
      "\n",
      "episode 9, val func loss 0.10992471128702164\n",
      "\n",
      "episode 10, val func loss 0.1224626898765564\n",
      "\n",
      "episode 11, val func loss 0.08404876291751862\n",
      "\n",
      "episode 12, val func loss 0.19845446944236755\n",
      "\n",
      "episode 13, val func loss 0.09773945063352585\n",
      "\n",
      "episode 14, val func loss 0.10595564544200897\n",
      "\n",
      "episode 15, val func loss 0.06359096616506577\n",
      "\n",
      "episode 16, val func loss 0.10714178532361984\n",
      "\n",
      "Val func train loss in epoch 15:0.11885936884209514\n",
      "***********************TIME WAS 5.199730678399404 min*****************************\n",
      "\n",
      "**********************ROUND 13 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.07580484449863434\n",
      "\n",
      "episode 2, policy loss -0.05634551867842674\n",
      "\n",
      "episode 3, policy loss -0.053514014929533005\n",
      "\n",
      "episode 4, policy loss -0.05728133022785187\n",
      "\n",
      "episode 5, policy loss -0.08516229689121246\n",
      "\n",
      "episode 6, policy loss -0.035290710628032684\n",
      "\n",
      "episode 7, policy loss -0.06265917420387268\n",
      "\n",
      "episode 8, policy loss -0.02181168645620346\n",
      "\n",
      "episode 9, policy loss -0.047170307487249374\n",
      "\n",
      "episode 10, policy loss -0.08675270527601242\n",
      "\n",
      "episode 11, policy loss -0.04256067052483559\n",
      "\n",
      "episode 12, policy loss -0.11233358085155487\n",
      "\n",
      "episode 13, policy loss -0.0647493526339531\n",
      "\n",
      "episode 14, policy loss -0.04571661725640297\n",
      "\n",
      "episode 15, policy loss -0.05847638100385666\n",
      "\n",
      "episode 16, policy loss -0.059723518788814545\n",
      "\n",
      "Policy train loss in epoch 0:-0.06033454439602792\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.0765736848115921\n",
      "\n",
      "episode 2, policy loss -0.035684868693351746\n",
      "\n",
      "episode 3, policy loss -0.05553634464740753\n",
      "\n",
      "episode 4, policy loss -0.11956887692213058\n",
      "\n",
      "episode 5, policy loss -0.08535697311162949\n",
      "\n",
      "episode 6, policy loss -0.061576347798109055\n",
      "\n",
      "episode 7, policy loss -0.06211593747138977\n",
      "\n",
      "episode 8, policy loss -0.08889108896255493\n",
      "\n",
      "episode 9, policy loss -0.04680642858147621\n",
      "\n",
      "episode 10, policy loss -0.05400454252958298\n",
      "\n",
      "episode 11, policy loss -0.057209696620702744\n",
      "\n",
      "episode 12, policy loss -0.06398799270391464\n",
      "\n",
      "episode 13, policy loss -0.06151267886161804\n",
      "\n",
      "episode 14, policy loss -0.027426090091466904\n",
      "\n",
      "episode 15, policy loss -0.04338642209768295\n",
      "\n",
      "episode 16, policy loss -0.062482867389917374\n",
      "\n",
      "Policy train loss in epoch 1:-0.06263255258090794\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.09261634200811386\n",
      "\n",
      "episode 2, policy loss -0.059068769216537476\n",
      "\n",
      "episode 3, policy loss -0.07356464117765427\n",
      "\n",
      "episode 4, policy loss -0.03628704696893692\n",
      "\n",
      "episode 5, policy loss -0.05627776309847832\n",
      "\n",
      "episode 6, policy loss -0.08797940611839294\n",
      "\n",
      "episode 7, policy loss -0.04388704150915146\n",
      "\n",
      "episode 8, policy loss -0.028272833675146103\n",
      "\n",
      "episode 9, policy loss -0.050551947206258774\n",
      "\n",
      "episode 10, policy loss -0.056395769119262695\n",
      "\n",
      "episode 11, policy loss -0.05316706746816635\n",
      "\n",
      "episode 12, policy loss -0.05702894926071167\n",
      "\n",
      "episode 13, policy loss -0.05889483541250229\n",
      "\n",
      "episode 14, policy loss -0.11133991926908493\n",
      "\n",
      "episode 15, policy loss -0.06440731137990952\n",
      "\n",
      "episode 16, policy loss -0.061735086143016815\n",
      "\n",
      "Policy train loss in epoch 2:-0.061967170564457774\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.06688835471868515\n",
      "\n",
      "episode 2, policy loss -0.07332316786050797\n",
      "\n",
      "episode 3, policy loss -0.11783257126808167\n",
      "\n",
      "episode 4, policy loss -0.05847802013158798\n",
      "\n",
      "episode 5, policy loss -0.04342830926179886\n",
      "\n",
      "episode 6, policy loss -0.053369998931884766\n",
      "\n",
      "episode 7, policy loss -0.02024829387664795\n",
      "\n",
      "episode 8, policy loss -0.07981949299573898\n",
      "\n",
      "episode 9, policy loss -0.056721486151218414\n",
      "\n",
      "episode 10, policy loss -0.05354861542582512\n",
      "\n",
      "episode 11, policy loss -0.050634682178497314\n",
      "\n",
      "episode 12, policy loss -0.08584282547235489\n",
      "\n",
      "episode 13, policy loss -0.048816122114658356\n",
      "\n",
      "episode 14, policy loss -0.0677018091082573\n",
      "\n",
      "episode 15, policy loss -0.03395755961537361\n",
      "\n",
      "episode 16, policy loss -0.06099018454551697\n",
      "\n",
      "Policy train loss in epoch 3:-0.060725093353539705\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1370118409395218\n",
      "\n",
      "episode 2, val func loss 0.1411593109369278\n",
      "\n",
      "episode 3, val func loss 0.06550049781799316\n",
      "\n",
      "episode 4, val func loss 0.09955035150051117\n",
      "\n",
      "episode 5, val func loss 0.15599021315574646\n",
      "\n",
      "episode 6, val func loss 0.10480248928070068\n",
      "\n",
      "episode 7, val func loss 0.1471588909626007\n",
      "\n",
      "episode 8, val func loss 0.12640100717544556\n",
      "\n",
      "episode 9, val func loss 0.09253816306591034\n",
      "\n",
      "episode 10, val func loss 0.09112826734781265\n",
      "\n",
      "episode 11, val func loss 0.14779597520828247\n",
      "\n",
      "episode 12, val func loss 0.13871628046035767\n",
      "\n",
      "episode 13, val func loss 0.13356024026870728\n",
      "\n",
      "episode 14, val func loss 0.13741636276245117\n",
      "\n",
      "episode 15, val func loss 0.10947387665510178\n",
      "\n",
      "episode 16, val func loss 0.19699735939502716\n",
      "\n",
      "Val func train loss in epoch 0:0.12657507043331861\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.06600114703178406\n",
      "\n",
      "episode 2, val func loss 0.19388669729232788\n",
      "\n",
      "episode 3, val func loss 0.09569710493087769\n",
      "\n",
      "episode 4, val func loss 0.13619913160800934\n",
      "\n",
      "episode 5, val func loss 0.09322835505008698\n",
      "\n",
      "episode 6, val func loss 0.10477494448423386\n",
      "\n",
      "episode 7, val func loss 0.15273141860961914\n",
      "\n",
      "episode 8, val func loss 0.16499823331832886\n",
      "\n",
      "episode 9, val func loss 0.12702226638793945\n",
      "\n",
      "episode 10, val func loss 0.1093732938170433\n",
      "\n",
      "episode 11, val func loss 0.1390238106250763\n",
      "\n",
      "episode 12, val func loss 0.14824888110160828\n",
      "\n",
      "episode 13, val func loss 0.13397455215454102\n",
      "\n",
      "episode 14, val func loss 0.1000179648399353\n",
      "\n",
      "episode 15, val func loss 0.1490069031715393\n",
      "\n",
      "episode 16, val func loss 0.1387280374765396\n",
      "\n",
      "Val func train loss in epoch 1:0.12830704636871815\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.13764964044094086\n",
      "\n",
      "episode 2, val func loss 0.06541483849287033\n",
      "\n",
      "episode 3, val func loss 0.09057534486055374\n",
      "\n",
      "episode 4, val func loss 0.12585391104221344\n",
      "\n",
      "episode 5, val func loss 0.10465040802955627\n",
      "\n",
      "episode 6, val func loss 0.10988165438175201\n",
      "\n",
      "episode 7, val func loss 0.13283489644527435\n",
      "\n",
      "episode 8, val func loss 0.12596814334392548\n",
      "\n",
      "episode 9, val func loss 0.14866024255752563\n",
      "\n",
      "episode 10, val func loss 0.1474592238664627\n",
      "\n",
      "episode 11, val func loss 0.13829998672008514\n",
      "\n",
      "episode 12, val func loss 0.20201420783996582\n",
      "\n",
      "episode 13, val func loss 0.1553686559200287\n",
      "\n",
      "episode 14, val func loss 0.09844313561916351\n",
      "\n",
      "episode 15, val func loss 0.1468924731016159\n",
      "\n",
      "episode 16, val func loss 0.10109081864356995\n",
      "\n",
      "Val func train loss in epoch 2:0.126941098831594\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1403963416814804\n",
      "\n",
      "episode 2, val func loss 0.09991656243801117\n",
      "\n",
      "episode 3, val func loss 0.2004161775112152\n",
      "\n",
      "episode 4, val func loss 0.14852328598499298\n",
      "\n",
      "episode 5, val func loss 0.14720623195171356\n",
      "\n",
      "episode 6, val func loss 0.14414019882678986\n",
      "\n",
      "episode 7, val func loss 0.13280309736728668\n",
      "\n",
      "episode 8, val func loss 0.13917599618434906\n",
      "\n",
      "episode 9, val func loss 0.10411227494478226\n",
      "\n",
      "episode 10, val func loss 0.15635308623313904\n",
      "\n",
      "episode 11, val func loss 0.10946758091449738\n",
      "\n",
      "episode 12, val func loss 0.09110116213560104\n",
      "\n",
      "episode 13, val func loss 0.128205344080925\n",
      "\n",
      "episode 14, val func loss 0.09220043569803238\n",
      "\n",
      "episode 15, val func loss 0.12773725390434265\n",
      "\n",
      "episode 16, val func loss 0.06593754142522812\n",
      "\n",
      "Val func train loss in epoch 3:0.12673078570514917\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.15908999741077423\n",
      "\n",
      "episode 2, val func loss 0.09089832752943039\n",
      "\n",
      "episode 3, val func loss 0.1383480578660965\n",
      "\n",
      "episode 4, val func loss 0.1429547816514969\n",
      "\n",
      "episode 5, val func loss 0.13205428421497345\n",
      "\n",
      "episode 6, val func loss 0.14702700078487396\n",
      "\n",
      "episode 7, val func loss 0.06498898565769196\n",
      "\n",
      "episode 8, val func loss 0.13291865587234497\n",
      "\n",
      "episode 9, val func loss 0.1107402816414833\n",
      "\n",
      "episode 10, val func loss 0.10477864742279053\n",
      "\n",
      "episode 11, val func loss 0.20059065520763397\n",
      "\n",
      "episode 12, val func loss 0.1519501954317093\n",
      "\n",
      "episode 13, val func loss 0.12788701057434082\n",
      "\n",
      "episode 14, val func loss 0.1383833885192871\n",
      "\n",
      "episode 15, val func loss 0.10023067146539688\n",
      "\n",
      "episode 16, val func loss 0.09291307628154755\n",
      "\n",
      "Val func train loss in epoch 4:0.127234626095742\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.13278594613075256\n",
      "\n",
      "episode 2, val func loss 0.1043756976723671\n",
      "\n",
      "episode 3, val func loss 0.1467873752117157\n",
      "\n",
      "episode 4, val func loss 0.1257818639278412\n",
      "\n",
      "episode 5, val func loss 0.2051454484462738\n",
      "\n",
      "episode 6, val func loss 0.09096630662679672\n",
      "\n",
      "episode 7, val func loss 0.14266221225261688\n",
      "\n",
      "episode 8, val func loss 0.15638011693954468\n",
      "\n",
      "episode 9, val func loss 0.09854662418365479\n",
      "\n",
      "episode 10, val func loss 0.13072443008422852\n",
      "\n",
      "episode 11, val func loss 0.09436845779418945\n",
      "\n",
      "episode 12, val func loss 0.14795809984207153\n",
      "\n",
      "episode 13, val func loss 0.1429908573627472\n",
      "\n",
      "episode 14, val func loss 0.11191955953836441\n",
      "\n",
      "episode 15, val func loss 0.06529708951711655\n",
      "\n",
      "episode 16, val func loss 0.13897345960140228\n",
      "\n",
      "Val func train loss in epoch 5:0.1272289715707302\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1423184871673584\n",
      "\n",
      "episode 2, val func loss 0.15236999094486237\n",
      "\n",
      "episode 3, val func loss 0.1974479705095291\n",
      "\n",
      "episode 4, val func loss 0.14810648560523987\n",
      "\n",
      "episode 5, val func loss 0.1335224062204361\n",
      "\n",
      "episode 6, val func loss 0.15605434775352478\n",
      "\n",
      "episode 7, val func loss 0.10958914458751678\n",
      "\n",
      "episode 8, val func loss 0.09267301112413406\n",
      "\n",
      "episode 9, val func loss 0.13894931972026825\n",
      "\n",
      "episode 10, val func loss 0.10516536235809326\n",
      "\n",
      "episode 11, val func loss 0.12609019875526428\n",
      "\n",
      "episode 12, val func loss 0.1383471041917801\n",
      "\n",
      "episode 13, val func loss 0.06563521921634674\n",
      "\n",
      "episode 14, val func loss 0.09979694336652756\n",
      "\n",
      "episode 15, val func loss 0.09309861063957214\n",
      "\n",
      "episode 16, val func loss 0.12975147366523743\n",
      "\n",
      "Val func train loss in epoch 6:0.1268072547391057\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.13823510706424713\n",
      "\n",
      "episode 2, val func loss 0.13990259170532227\n",
      "\n",
      "episode 3, val func loss 0.10404136776924133\n",
      "\n",
      "episode 4, val func loss 0.13313764333724976\n",
      "\n",
      "episode 5, val func loss 0.06560968607664108\n",
      "\n",
      "episode 6, val func loss 0.11106324195861816\n",
      "\n",
      "episode 7, val func loss 0.1290273219347\n",
      "\n",
      "episode 8, val func loss 0.12627176940441132\n",
      "\n",
      "episode 9, val func loss 0.14837335050106049\n",
      "\n",
      "episode 10, val func loss 0.20885339379310608\n",
      "\n",
      "episode 11, val func loss 0.15660125017166138\n",
      "\n",
      "episode 12, val func loss 0.10596442222595215\n",
      "\n",
      "episode 13, val func loss 0.1415611207485199\n",
      "\n",
      "episode 14, val func loss 0.0940011516213417\n",
      "\n",
      "episode 15, val func loss 0.15049715340137482\n",
      "\n",
      "episode 16, val func loss 0.0921420231461525\n",
      "\n",
      "Val func train loss in epoch 7:0.127830162178725\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.06852752715349197\n",
      "\n",
      "episode 2, val func loss 0.1365186721086502\n",
      "\n",
      "episode 3, val func loss 0.147537961602211\n",
      "\n",
      "episode 4, val func loss 0.15500684082508087\n",
      "\n",
      "episode 5, val func loss 0.13468299806118011\n",
      "\n",
      "episode 6, val func loss 0.09144064038991928\n",
      "\n",
      "episode 7, val func loss 0.13865508139133453\n",
      "\n",
      "episode 8, val func loss 0.09201216697692871\n",
      "\n",
      "episode 9, val func loss 0.1466224491596222\n",
      "\n",
      "episode 10, val func loss 0.13826696574687958\n",
      "\n",
      "episode 11, val func loss 0.19641022384166718\n",
      "\n",
      "episode 12, val func loss 0.09823247045278549\n",
      "\n",
      "episode 13, val func loss 0.11926586925983429\n",
      "\n",
      "episode 14, val func loss 0.10714136064052582\n",
      "\n",
      "episode 15, val func loss 0.12542177736759186\n",
      "\n",
      "episode 16, val func loss 0.14885510504245758\n",
      "\n",
      "Val func train loss in epoch 8:0.12778738187626004\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.14023452997207642\n",
      "\n",
      "episode 2, val func loss 0.14757509529590607\n",
      "\n",
      "episode 3, val func loss 0.12640029191970825\n",
      "\n",
      "episode 4, val func loss 0.09189578145742416\n",
      "\n",
      "episode 5, val func loss 0.12690551578998566\n",
      "\n",
      "episode 6, val func loss 0.06576891988515854\n",
      "\n",
      "episode 7, val func loss 0.09944098442792892\n",
      "\n",
      "episode 8, val func loss 0.15645666420459747\n",
      "\n",
      "episode 9, val func loss 0.1509721577167511\n",
      "\n",
      "episode 10, val func loss 0.1093699261546135\n",
      "\n",
      "episode 11, val func loss 0.10527685284614563\n",
      "\n",
      "episode 12, val func loss 0.13363158702850342\n",
      "\n",
      "episode 13, val func loss 0.09209174662828445\n",
      "\n",
      "episode 14, val func loss 0.19984054565429688\n",
      "\n",
      "episode 15, val func loss 0.14186158776283264\n",
      "\n",
      "episode 16, val func loss 0.14599953591823578\n",
      "\n",
      "Val func train loss in epoch 9:0.12710760766640306\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.09862290322780609\n",
      "\n",
      "episode 2, val func loss 0.14886409044265747\n",
      "\n",
      "episode 3, val func loss 0.1386747658252716\n",
      "\n",
      "episode 4, val func loss 0.09269528090953827\n",
      "\n",
      "episode 5, val func loss 0.06638780236244202\n",
      "\n",
      "episode 6, val func loss 0.1468752771615982\n",
      "\n",
      "episode 7, val func loss 0.09124670922756195\n",
      "\n",
      "episode 8, val func loss 0.15299706161022186\n",
      "\n",
      "episode 9, val func loss 0.10508272051811218\n",
      "\n",
      "episode 10, val func loss 0.12705954909324646\n",
      "\n",
      "episode 11, val func loss 0.1329701840877533\n",
      "\n",
      "episode 12, val func loss 0.12588925659656525\n",
      "\n",
      "episode 13, val func loss 0.13854889571666718\n",
      "\n",
      "episode 14, val func loss 0.10916659235954285\n",
      "\n",
      "episode 15, val func loss 0.15564198791980743\n",
      "\n",
      "episode 16, val func loss 0.19338436424732208\n",
      "\n",
      "Val func train loss in epoch 10:0.12650671508163214\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.15096893906593323\n",
      "\n",
      "episode 2, val func loss 0.14388243854045868\n",
      "\n",
      "episode 3, val func loss 0.09105987101793289\n",
      "\n",
      "episode 4, val func loss 0.09353826195001602\n",
      "\n",
      "episode 5, val func loss 0.10949533432722092\n",
      "\n",
      "episode 6, val func loss 0.21478334069252014\n",
      "\n",
      "episode 7, val func loss 0.13217581808567047\n",
      "\n",
      "episode 8, val func loss 0.06605439633131027\n",
      "\n",
      "episode 9, val func loss 0.1101459413766861\n",
      "\n",
      "episode 10, val func loss 0.15750637650489807\n",
      "\n",
      "episode 11, val func loss 0.13878297805786133\n",
      "\n",
      "episode 12, val func loss 0.12610362470149994\n",
      "\n",
      "episode 13, val func loss 0.1489679515361786\n",
      "\n",
      "episode 14, val func loss 0.11033516377210617\n",
      "\n",
      "episode 15, val func loss 0.12531577050685883\n",
      "\n",
      "episode 16, val func loss 0.158356711268425\n",
      "\n",
      "Val func train loss in epoch 11:0.12984205735847354\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1370316594839096\n",
      "\n",
      "episode 2, val func loss 0.09867928177118301\n",
      "\n",
      "episode 3, val func loss 0.09448318928480148\n",
      "\n",
      "episode 4, val func loss 0.13344167172908783\n",
      "\n",
      "episode 5, val func loss 0.13765625655651093\n",
      "\n",
      "episode 6, val func loss 0.09289532154798508\n",
      "\n",
      "episode 7, val func loss 0.16551953554153442\n",
      "\n",
      "episode 8, val func loss 0.10567250847816467\n",
      "\n",
      "episode 9, val func loss 0.20073716342449188\n",
      "\n",
      "episode 10, val func loss 0.15346263349056244\n",
      "\n",
      "episode 11, val func loss 0.150147944688797\n",
      "\n",
      "episode 12, val func loss 0.06518959254026413\n",
      "\n",
      "episode 13, val func loss 0.12631362676620483\n",
      "\n",
      "episode 14, val func loss 0.11024103313684464\n",
      "\n",
      "episode 15, val func loss 0.1327054649591446\n",
      "\n",
      "episode 16, val func loss 0.1464018076658249\n",
      "\n",
      "Val func train loss in epoch 12:0.12816116819158196\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.10431967675685883\n",
      "\n",
      "episode 2, val func loss 0.12794902920722961\n",
      "\n",
      "episode 3, val func loss 0.13758738338947296\n",
      "\n",
      "episode 4, val func loss 0.12632900476455688\n",
      "\n",
      "episode 5, val func loss 0.06532458961009979\n",
      "\n",
      "episode 6, val func loss 0.09250592440366745\n",
      "\n",
      "episode 7, val func loss 0.13880516588687897\n",
      "\n",
      "episode 8, val func loss 0.20103749632835388\n",
      "\n",
      "episode 9, val func loss 0.14217551052570343\n",
      "\n",
      "episode 10, val func loss 0.15200485289096832\n",
      "\n",
      "episode 11, val func loss 0.1380557417869568\n",
      "\n",
      "episode 12, val func loss 0.0917520523071289\n",
      "\n",
      "episode 13, val func loss 0.14837214350700378\n",
      "\n",
      "episode 14, val func loss 0.16067393124103546\n",
      "\n",
      "episode 15, val func loss 0.1102772206068039\n",
      "\n",
      "episode 16, val func loss 0.10227309167385101\n",
      "\n",
      "Val func train loss in epoch 13:0.12746517593041062\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.14407266676425934\n",
      "\n",
      "episode 2, val func loss 0.15017107129096985\n",
      "\n",
      "episode 3, val func loss 0.13920257985591888\n",
      "\n",
      "episode 4, val func loss 0.1478341668844223\n",
      "\n",
      "episode 5, val func loss 0.13246046006679535\n",
      "\n",
      "episode 6, val func loss 0.12629003822803497\n",
      "\n",
      "episode 7, val func loss 0.13949750363826752\n",
      "\n",
      "episode 8, val func loss 0.16129156947135925\n",
      "\n",
      "episode 9, val func loss 0.10900335758924484\n",
      "\n",
      "episode 10, val func loss 0.10448955744504929\n",
      "\n",
      "episode 11, val func loss 0.09129966795444489\n",
      "\n",
      "episode 12, val func loss 0.1948355883359909\n",
      "\n",
      "episode 13, val func loss 0.09557712823152542\n",
      "\n",
      "episode 14, val func loss 0.09856889396905899\n",
      "\n",
      "episode 15, val func loss 0.12931901216506958\n",
      "\n",
      "episode 16, val func loss 0.06594879180192947\n",
      "\n",
      "Val func train loss in epoch 14:0.1268663783557713\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.14332975447177887\n",
      "\n",
      "episode 2, val func loss 0.13308672606945038\n",
      "\n",
      "episode 3, val func loss 0.10129234194755554\n",
      "\n",
      "episode 4, val func loss 0.09097299724817276\n",
      "\n",
      "episode 5, val func loss 0.13824190199375153\n",
      "\n",
      "episode 6, val func loss 0.10494831204414368\n",
      "\n",
      "episode 7, val func loss 0.09225134551525116\n",
      "\n",
      "episode 8, val func loss 0.1473395973443985\n",
      "\n",
      "episode 9, val func loss 0.1383676677942276\n",
      "\n",
      "episode 10, val func loss 0.2003701776266098\n",
      "\n",
      "episode 11, val func loss 0.12739211320877075\n",
      "\n",
      "episode 12, val func loss 0.15569137036800385\n",
      "\n",
      "episode 13, val func loss 0.15379424393177032\n",
      "\n",
      "episode 14, val func loss 0.13147255778312683\n",
      "\n",
      "episode 15, val func loss 0.0652279406785965\n",
      "\n",
      "episode 16, val func loss 0.1094294860959053\n",
      "\n",
      "Val func train loss in epoch 15:0.12707553338259459\n",
      "***********************TIME WAS 5.15708338022232 min*****************************\n",
      "\n",
      "**********************ROUND 14 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.15472698211669922\n",
      "\n",
      "episode 2, policy loss -0.12352060526609421\n",
      "\n",
      "episode 3, policy loss -0.12646746635437012\n",
      "\n",
      "episode 4, policy loss -0.11457918584346771\n",
      "\n",
      "episode 5, policy loss -0.11157931387424469\n",
      "\n",
      "episode 6, policy loss -0.12628021836280823\n",
      "\n",
      "episode 7, policy loss -0.12788555026054382\n",
      "\n",
      "episode 8, policy loss -0.10028401762247086\n",
      "\n",
      "episode 9, policy loss -0.10581091791391373\n",
      "\n",
      "episode 10, policy loss -0.10031838715076447\n",
      "\n",
      "episode 11, policy loss -0.10200826078653336\n",
      "\n",
      "episode 12, policy loss -0.14183087646961212\n",
      "\n",
      "episode 13, policy loss -0.10017087310552597\n",
      "\n",
      "episode 14, policy loss -0.09198498725891113\n",
      "\n",
      "episode 15, policy loss -0.09774887561798096\n",
      "\n",
      "episode 16, policy loss -0.12473192065954208\n",
      "\n",
      "Policy train loss in epoch 0:-0.11562052741646767\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.10622363537549973\n",
      "\n",
      "episode 2, policy loss -0.1581038385629654\n",
      "\n",
      "episode 3, policy loss -0.11309804022312164\n",
      "\n",
      "episode 4, policy loss -0.1286928653717041\n",
      "\n",
      "episode 5, policy loss -0.09488507360219955\n",
      "\n",
      "episode 6, policy loss -0.09232090413570404\n",
      "\n",
      "episode 7, policy loss -0.10143555700778961\n",
      "\n",
      "episode 8, policy loss -0.12262244522571564\n",
      "\n",
      "episode 9, policy loss -0.10194312781095505\n",
      "\n",
      "episode 10, policy loss -0.12694019079208374\n",
      "\n",
      "episode 11, policy loss -0.12439869344234467\n",
      "\n",
      "episode 12, policy loss -0.0974842756986618\n",
      "\n",
      "episode 13, policy loss -0.14316518604755402\n",
      "\n",
      "episode 14, policy loss -0.10149776935577393\n",
      "\n",
      "episode 15, policy loss -0.1277090311050415\n",
      "\n",
      "episode 16, policy loss -0.115877166390419\n",
      "\n",
      "Policy train loss in epoch 1:-0.11602486250922084\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.11368140578269958\n",
      "\n",
      "episode 2, policy loss -0.15708819031715393\n",
      "\n",
      "episode 3, policy loss -0.13167035579681396\n",
      "\n",
      "episode 4, policy loss -0.09795278310775757\n",
      "\n",
      "episode 5, policy loss -0.1007484570145607\n",
      "\n",
      "episode 6, policy loss -0.09782451391220093\n",
      "\n",
      "episode 7, policy loss -0.10428285598754883\n",
      "\n",
      "episode 8, policy loss -0.12410078942775726\n",
      "\n",
      "episode 9, policy loss -0.12779642641544342\n",
      "\n",
      "episode 10, policy loss -0.14565348625183105\n",
      "\n",
      "episode 11, policy loss -0.09991122037172318\n",
      "\n",
      "episode 12, policy loss -0.1237725168466568\n",
      "\n",
      "episode 13, policy loss -0.12623971700668335\n",
      "\n",
      "episode 14, policy loss -0.09923087060451508\n",
      "\n",
      "episode 15, policy loss -0.11067776381969452\n",
      "\n",
      "episode 16, policy loss -0.09071779251098633\n",
      "\n",
      "Policy train loss in epoch 2:-0.11570932157337666\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.1136833056807518\n",
      "\n",
      "episode 2, policy loss -0.09083419293165207\n",
      "\n",
      "episode 3, policy loss -0.12331156432628632\n",
      "\n",
      "episode 4, policy loss -0.09950795769691467\n",
      "\n",
      "episode 5, policy loss -0.12389437854290009\n",
      "\n",
      "episode 6, policy loss -0.15828579664230347\n",
      "\n",
      "episode 7, policy loss -0.14407016336917877\n",
      "\n",
      "episode 8, policy loss -0.09833387285470963\n",
      "\n",
      "episode 9, policy loss -0.11381671577692032\n",
      "\n",
      "episode 10, policy loss -0.1249966248869896\n",
      "\n",
      "episode 11, policy loss -0.10272882133722305\n",
      "\n",
      "episode 12, policy loss -0.10587794333696365\n",
      "\n",
      "episode 13, policy loss -0.10159233212471008\n",
      "\n",
      "episode 14, policy loss -0.1271430104970932\n",
      "\n",
      "episode 15, policy loss -0.0961282029747963\n",
      "\n",
      "episode 16, policy loss -0.12664802372455597\n",
      "\n",
      "Policy train loss in epoch 3:-0.11567830666899681\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.16193631291389465\n",
      "\n",
      "episode 2, val func loss 0.07952713966369629\n",
      "\n",
      "episode 3, val func loss 0.11136465519666672\n",
      "\n",
      "episode 4, val func loss 0.1417686492204666\n",
      "\n",
      "episode 5, val func loss 0.1119500920176506\n",
      "\n",
      "episode 6, val func loss 0.1178470104932785\n",
      "\n",
      "episode 7, val func loss 0.10671564191579819\n",
      "\n",
      "episode 8, val func loss 0.12334973365068436\n",
      "\n",
      "episode 9, val func loss 0.06874850392341614\n",
      "\n",
      "episode 10, val func loss 0.08930446952581406\n",
      "\n",
      "episode 11, val func loss 0.11355210840702057\n",
      "\n",
      "episode 12, val func loss 0.13504426181316376\n",
      "\n",
      "episode 13, val func loss 0.14016926288604736\n",
      "\n",
      "episode 14, val func loss 0.1459999978542328\n",
      "\n",
      "episode 15, val func loss 0.13954830169677734\n",
      "\n",
      "episode 16, val func loss 0.14454716444015503\n",
      "\n",
      "Val func train loss in epoch 0:0.12071083160117269\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.14418907463550568\n",
      "\n",
      "episode 2, val func loss 0.11301594227552414\n",
      "\n",
      "episode 3, val func loss 0.1353580802679062\n",
      "\n",
      "episode 4, val func loss 0.1451086550951004\n",
      "\n",
      "episode 5, val func loss 0.08928700536489487\n",
      "\n",
      "episode 6, val func loss 0.16112905740737915\n",
      "\n",
      "episode 7, val func loss 0.13948948681354523\n",
      "\n",
      "episode 8, val func loss 0.1105157732963562\n",
      "\n",
      "episode 9, val func loss 0.10792475193738937\n",
      "\n",
      "episode 10, val func loss 0.11798360198736191\n",
      "\n",
      "episode 11, val func loss 0.1411428451538086\n",
      "\n",
      "episode 12, val func loss 0.08057805150747299\n",
      "\n",
      "episode 13, val func loss 0.11271624267101288\n",
      "\n",
      "episode 14, val func loss 0.14009971916675568\n",
      "\n",
      "episode 15, val func loss 0.06911727786064148\n",
      "\n",
      "episode 16, val func loss 0.12070199847221375\n",
      "\n",
      "Val func train loss in epoch 1:0.12052234774455428\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.06858108192682266\n",
      "\n",
      "episode 2, val func loss 0.13951937854290009\n",
      "\n",
      "episode 3, val func loss 0.11319637298583984\n",
      "\n",
      "episode 4, val func loss 0.10696670413017273\n",
      "\n",
      "episode 5, val func loss 0.08002035319805145\n",
      "\n",
      "episode 6, val func loss 0.12206270545721054\n",
      "\n",
      "episode 7, val func loss 0.11759650707244873\n",
      "\n",
      "episode 8, val func loss 0.11288187652826309\n",
      "\n",
      "episode 9, val func loss 0.1345963329076767\n",
      "\n",
      "episode 10, val func loss 0.1444389373064041\n",
      "\n",
      "episode 11, val func loss 0.11057800054550171\n",
      "\n",
      "episode 12, val func loss 0.08907590061426163\n",
      "\n",
      "episode 13, val func loss 0.14024405181407928\n",
      "\n",
      "episode 14, val func loss 0.14054268598556519\n",
      "\n",
      "episode 15, val func loss 0.14438636600971222\n",
      "\n",
      "episode 16, val func loss 0.15975284576416016\n",
      "\n",
      "Val func train loss in epoch 2:0.12027750629931688\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.10672357678413391\n",
      "\n",
      "episode 2, val func loss 0.06851831823587418\n",
      "\n",
      "episode 3, val func loss 0.1355961710214615\n",
      "\n",
      "episode 4, val func loss 0.1612057387828827\n",
      "\n",
      "episode 5, val func loss 0.14032377302646637\n",
      "\n",
      "episode 6, val func loss 0.11702798306941986\n",
      "\n",
      "episode 7, val func loss 0.145264133810997\n",
      "\n",
      "episode 8, val func loss 0.11070194840431213\n",
      "\n",
      "episode 9, val func loss 0.08954514563083649\n",
      "\n",
      "episode 10, val func loss 0.08075039088726044\n",
      "\n",
      "episode 11, val func loss 0.11355110257863998\n",
      "\n",
      "episode 12, val func loss 0.11267422884702682\n",
      "\n",
      "episode 13, val func loss 0.14399860799312592\n",
      "\n",
      "episode 14, val func loss 0.14044612646102905\n",
      "\n",
      "episode 15, val func loss 0.12092667073011398\n",
      "\n",
      "episode 16, val func loss 0.139460027217865\n",
      "\n",
      "Val func train loss in epoch 3:0.12041962146759033\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.12059111148118973\n",
      "\n",
      "episode 2, val func loss 0.06875729560852051\n",
      "\n",
      "episode 3, val func loss 0.11852839589118958\n",
      "\n",
      "episode 4, val func loss 0.11326698958873749\n",
      "\n",
      "episode 5, val func loss 0.07978320121765137\n",
      "\n",
      "episode 6, val func loss 0.13991700112819672\n",
      "\n",
      "episode 7, val func loss 0.14414682984352112\n",
      "\n",
      "episode 8, val func loss 0.11267338693141937\n",
      "\n",
      "episode 9, val func loss 0.14018835127353668\n",
      "\n",
      "episode 10, val func loss 0.14004504680633545\n",
      "\n",
      "episode 11, val func loss 0.1602012664079666\n",
      "\n",
      "episode 12, val func loss 0.10717833787202835\n",
      "\n",
      "episode 13, val func loss 0.11046040058135986\n",
      "\n",
      "episode 14, val func loss 0.13628290593624115\n",
      "\n",
      "episode 15, val func loss 0.1449412852525711\n",
      "\n",
      "episode 16, val func loss 0.08921879529953003\n",
      "\n",
      "Val func train loss in epoch 4:0.1203862875699997\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.11132180690765381\n",
      "\n",
      "episode 2, val func loss 0.16257822513580322\n",
      "\n",
      "episode 3, val func loss 0.14497700333595276\n",
      "\n",
      "episode 4, val func loss 0.11412668228149414\n",
      "\n",
      "episode 5, val func loss 0.11699517071247101\n",
      "\n",
      "episode 6, val func loss 0.06979857385158539\n",
      "\n",
      "episode 7, val func loss 0.13638585805892944\n",
      "\n",
      "episode 8, val func loss 0.14457477629184723\n",
      "\n",
      "episode 9, val func loss 0.10722755640745163\n",
      "\n",
      "episode 10, val func loss 0.09055233001708984\n",
      "\n",
      "episode 11, val func loss 0.1150607243180275\n",
      "\n",
      "episode 12, val func loss 0.13960054516792297\n",
      "\n",
      "episode 13, val func loss 0.07976904511451721\n",
      "\n",
      "episode 14, val func loss 0.14012517035007477\n",
      "\n",
      "episode 15, val func loss 0.13943636417388916\n",
      "\n",
      "episode 16, val func loss 0.12175207585096359\n",
      "\n",
      "Val func train loss in epoch 5:0.1208926192484796\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.06890875846147537\n",
      "\n",
      "episode 2, val func loss 0.16019217669963837\n",
      "\n",
      "episode 3, val func loss 0.10622932761907578\n",
      "\n",
      "episode 4, val func loss 0.08026079088449478\n",
      "\n",
      "episode 5, val func loss 0.1446601301431656\n",
      "\n",
      "episode 6, val func loss 0.08936738222837448\n",
      "\n",
      "episode 7, val func loss 0.1109766885638237\n",
      "\n",
      "episode 8, val func loss 0.13916011154651642\n",
      "\n",
      "episode 9, val func loss 0.1396746188402176\n",
      "\n",
      "episode 10, val func loss 0.11292324960231781\n",
      "\n",
      "episode 11, val func loss 0.1208089143037796\n",
      "\n",
      "episode 12, val func loss 0.11761192977428436\n",
      "\n",
      "episode 13, val func loss 0.13496744632720947\n",
      "\n",
      "episode 14, val func loss 0.14025375247001648\n",
      "\n",
      "episode 15, val func loss 0.11201606690883636\n",
      "\n",
      "episode 16, val func loss 0.14527387917041779\n",
      "\n",
      "Val func train loss in epoch 6:0.12020532647147775\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.10747561603784561\n",
      "\n",
      "episode 2, val func loss 0.13643330335617065\n",
      "\n",
      "episode 3, val func loss 0.06844060122966766\n",
      "\n",
      "episode 4, val func loss 0.14405015110969543\n",
      "\n",
      "episode 5, val func loss 0.13976553082466125\n",
      "\n",
      "episode 6, val func loss 0.14730717241764069\n",
      "\n",
      "episode 7, val func loss 0.13967210054397583\n",
      "\n",
      "episode 8, val func loss 0.11748474091291428\n",
      "\n",
      "episode 9, val func loss 0.12124211341142654\n",
      "\n",
      "episode 10, val func loss 0.08918070793151855\n",
      "\n",
      "episode 11, val func loss 0.11042647063732147\n",
      "\n",
      "episode 12, val func loss 0.08071010559797287\n",
      "\n",
      "episode 13, val func loss 0.139569953083992\n",
      "\n",
      "episode 14, val func loss 0.11342643946409225\n",
      "\n",
      "episode 15, val func loss 0.1605377495288849\n",
      "\n",
      "episode 16, val func loss 0.1123746708035469\n",
      "\n",
      "Val func train loss in epoch 7:0.12050608918070793\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.13932915031909943\n",
      "\n",
      "episode 2, val func loss 0.11798042058944702\n",
      "\n",
      "episode 3, val func loss 0.08163749426603317\n",
      "\n",
      "episode 4, val func loss 0.1069667860865593\n",
      "\n",
      "episode 5, val func loss 0.13428840041160583\n",
      "\n",
      "episode 6, val func loss 0.14461110532283783\n",
      "\n",
      "episode 7, val func loss 0.11227360367774963\n",
      "\n",
      "episode 8, val func loss 0.14654618501663208\n",
      "\n",
      "episode 9, val func loss 0.14003504812717438\n",
      "\n",
      "episode 10, val func loss 0.12116445600986481\n",
      "\n",
      "episode 11, val func loss 0.13907091319561005\n",
      "\n",
      "episode 12, val func loss 0.08938184380531311\n",
      "\n",
      "episode 13, val func loss 0.0681014284491539\n",
      "\n",
      "episode 14, val func loss 0.11313875764608383\n",
      "\n",
      "episode 15, val func loss 0.11217658966779709\n",
      "\n",
      "episode 16, val func loss 0.1609601527452469\n",
      "\n",
      "Val func train loss in epoch 8:0.12047889595851302\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.12167845666408539\n",
      "\n",
      "episode 2, val func loss 0.0895838513970375\n",
      "\n",
      "episode 3, val func loss 0.15959948301315308\n",
      "\n",
      "episode 4, val func loss 0.0801895335316658\n",
      "\n",
      "episode 5, val func loss 0.11288616061210632\n",
      "\n",
      "episode 6, val func loss 0.1446615606546402\n",
      "\n",
      "episode 7, val func loss 0.10586751997470856\n",
      "\n",
      "episode 8, val func loss 0.1135694682598114\n",
      "\n",
      "episode 9, val func loss 0.14025788009166718\n",
      "\n",
      "episode 10, val func loss 0.06852792948484421\n",
      "\n",
      "episode 11, val func loss 0.1189596951007843\n",
      "\n",
      "episode 12, val func loss 0.11111990362405777\n",
      "\n",
      "episode 13, val func loss 0.1394384652376175\n",
      "\n",
      "episode 14, val func loss 0.13881132006645203\n",
      "\n",
      "episode 15, val func loss 0.13743701577186584\n",
      "\n",
      "episode 16, val func loss 0.14495563507080078\n",
      "\n",
      "Val func train loss in epoch 9:0.12047149240970612\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.10728558152914047\n",
      "\n",
      "episode 2, val func loss 0.13494372367858887\n",
      "\n",
      "episode 3, val func loss 0.11902448534965515\n",
      "\n",
      "episode 4, val func loss 0.14644965529441833\n",
      "\n",
      "episode 5, val func loss 0.12011037021875381\n",
      "\n",
      "episode 6, val func loss 0.11320243775844574\n",
      "\n",
      "episode 7, val func loss 0.14068017899990082\n",
      "\n",
      "episode 8, val func loss 0.11372197419404984\n",
      "\n",
      "episode 9, val func loss 0.14012685418128967\n",
      "\n",
      "episode 10, val func loss 0.11045970022678375\n",
      "\n",
      "episode 11, val func loss 0.08001838624477386\n",
      "\n",
      "episode 12, val func loss 0.08917386084794998\n",
      "\n",
      "episode 13, val func loss 0.06818043440580368\n",
      "\n",
      "episode 14, val func loss 0.1447475552558899\n",
      "\n",
      "episode 15, val func loss 0.14052948355674744\n",
      "\n",
      "episode 16, val func loss 0.16125746071338654\n",
      "\n",
      "Val func train loss in epoch 10:0.12061950890347362\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.08987697213888168\n",
      "\n",
      "episode 2, val func loss 0.0694098174571991\n",
      "\n",
      "episode 3, val func loss 0.14261752367019653\n",
      "\n",
      "episode 4, val func loss 0.11226915568113327\n",
      "\n",
      "episode 5, val func loss 0.1452282816171646\n",
      "\n",
      "episode 6, val func loss 0.1439628154039383\n",
      "\n",
      "episode 7, val func loss 0.12053973227739334\n",
      "\n",
      "episode 8, val func loss 0.11971734464168549\n",
      "\n",
      "episode 9, val func loss 0.07961861789226532\n",
      "\n",
      "episode 10, val func loss 0.10680058598518372\n",
      "\n",
      "episode 11, val func loss 0.16201402246952057\n",
      "\n",
      "episode 12, val func loss 0.13554589450359344\n",
      "\n",
      "episode 13, val func loss 0.13903023302555084\n",
      "\n",
      "episode 14, val func loss 0.11608991771936417\n",
      "\n",
      "episode 15, val func loss 0.1106153205037117\n",
      "\n",
      "episode 16, val func loss 0.14266280829906464\n",
      "\n",
      "Val func train loss in epoch 11:0.12099994020536542\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.089288130402565\n",
      "\n",
      "episode 2, val func loss 0.16264499723911285\n",
      "\n",
      "episode 3, val func loss 0.14043191075325012\n",
      "\n",
      "episode 4, val func loss 0.06854221224784851\n",
      "\n",
      "episode 5, val func loss 0.1061994656920433\n",
      "\n",
      "episode 6, val func loss 0.07979238033294678\n",
      "\n",
      "episode 7, val func loss 0.1124216690659523\n",
      "\n",
      "episode 8, val func loss 0.14586420357227325\n",
      "\n",
      "episode 9, val func loss 0.12188540399074554\n",
      "\n",
      "episode 10, val func loss 0.13943639397621155\n",
      "\n",
      "episode 11, val func loss 0.14412225782871246\n",
      "\n",
      "episode 12, val func loss 0.13515391945838928\n",
      "\n",
      "episode 13, val func loss 0.11141519993543625\n",
      "\n",
      "episode 14, val func loss 0.1175275593996048\n",
      "\n",
      "episode 15, val func loss 0.11383180320262909\n",
      "\n",
      "episode 16, val func loss 0.13915075361728668\n",
      "\n",
      "Val func train loss in epoch 12:0.12048176629468799\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.0809047520160675\n",
      "\n",
      "episode 2, val func loss 0.14552311599254608\n",
      "\n",
      "episode 3, val func loss 0.14035847783088684\n",
      "\n",
      "episode 4, val func loss 0.1180158481001854\n",
      "\n",
      "episode 5, val func loss 0.1359037607908249\n",
      "\n",
      "episode 6, val func loss 0.16247472167015076\n",
      "\n",
      "episode 7, val func loss 0.10632409155368805\n",
      "\n",
      "episode 8, val func loss 0.14036139845848083\n",
      "\n",
      "episode 9, val func loss 0.1106923371553421\n",
      "\n",
      "episode 10, val func loss 0.12303049862384796\n",
      "\n",
      "episode 11, val func loss 0.08930063247680664\n",
      "\n",
      "episode 12, val func loss 0.14460617303848267\n",
      "\n",
      "episode 13, val func loss 0.11326365172863007\n",
      "\n",
      "episode 14, val func loss 0.14125703275203705\n",
      "\n",
      "episode 15, val func loss 0.06862176209688187\n",
      "\n",
      "episode 16, val func loss 0.11204610019922256\n",
      "\n",
      "Val func train loss in epoch 13:0.12079277215525508\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1449650228023529\n",
      "\n",
      "episode 2, val func loss 0.15953069925308228\n",
      "\n",
      "episode 3, val func loss 0.08098798245191574\n",
      "\n",
      "episode 4, val func loss 0.10699713975191116\n",
      "\n",
      "episode 5, val func loss 0.06844601780176163\n",
      "\n",
      "episode 6, val func loss 0.11871860921382904\n",
      "\n",
      "episode 7, val func loss 0.13548468053340912\n",
      "\n",
      "episode 8, val func loss 0.1392827332019806\n",
      "\n",
      "episode 9, val func loss 0.14619490504264832\n",
      "\n",
      "episode 10, val func loss 0.11425086855888367\n",
      "\n",
      "episode 11, val func loss 0.12134341895580292\n",
      "\n",
      "episode 12, val func loss 0.1402226984500885\n",
      "\n",
      "episode 13, val func loss 0.1404017060995102\n",
      "\n",
      "episode 14, val func loss 0.0894462838768959\n",
      "\n",
      "episode 15, val func loss 0.11108917742967606\n",
      "\n",
      "episode 16, val func loss 0.11284343153238297\n",
      "\n",
      "Val func train loss in epoch 14:0.12063783593475819\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.08056752383708954\n",
      "\n",
      "episode 2, val func loss 0.08954055607318878\n",
      "\n",
      "episode 3, val func loss 0.14515334367752075\n",
      "\n",
      "episode 4, val func loss 0.1404816061258316\n",
      "\n",
      "episode 5, val func loss 0.1598910242319107\n",
      "\n",
      "episode 6, val func loss 0.14286817610263824\n",
      "\n",
      "episode 7, val func loss 0.11450570076704025\n",
      "\n",
      "episode 8, val func loss 0.12116849422454834\n",
      "\n",
      "episode 9, val func loss 0.13783884048461914\n",
      "\n",
      "episode 10, val func loss 0.11455871909856796\n",
      "\n",
      "episode 11, val func loss 0.06820622086524963\n",
      "\n",
      "episode 12, val func loss 0.11046401411294937\n",
      "\n",
      "episode 13, val func loss 0.11690003424882889\n",
      "\n",
      "episode 14, val func loss 0.14012907445430756\n",
      "\n",
      "episode 15, val func loss 0.14442095160484314\n",
      "\n",
      "episode 16, val func loss 0.10820356011390686\n",
      "\n",
      "Val func train loss in epoch 15:0.12093111500144005\n",
      "***********************TIME WAS 5.2444467663764955 min*****************************\n",
      "\n",
      "**********************ROUND 15 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.10633765161037445\n",
      "\n",
      "episode 2, policy loss -0.10344123840332031\n",
      "\n",
      "episode 3, policy loss -0.07958007603883743\n",
      "\n",
      "episode 4, policy loss -0.0351862907409668\n",
      "\n",
      "episode 5, policy loss -0.12658673524856567\n",
      "\n",
      "episode 6, policy loss -0.09557604044675827\n",
      "\n",
      "episode 7, policy loss -0.11293874680995941\n",
      "\n",
      "episode 8, policy loss -0.09511608630418777\n",
      "\n",
      "episode 9, policy loss -0.10394924879074097\n",
      "\n",
      "episode 10, policy loss -0.12217245995998383\n",
      "\n",
      "episode 11, policy loss -0.08190133422613144\n",
      "\n",
      "episode 12, policy loss -0.10423605889081955\n",
      "\n",
      "episode 13, policy loss -0.12415102124214172\n",
      "\n",
      "episode 14, policy loss -0.12940174341201782\n",
      "\n",
      "episode 15, policy loss -0.09431377053260803\n",
      "\n",
      "episode 16, policy loss -0.09112691879272461\n",
      "\n",
      "Policy train loss in epoch 0:-0.10037596384063363\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.10424104332923889\n",
      "\n",
      "episode 2, policy loss -0.09465188533067703\n",
      "\n",
      "episode 3, policy loss -0.10216650366783142\n",
      "\n",
      "episode 4, policy loss -0.08564009517431259\n",
      "\n",
      "episode 5, policy loss -0.1279689371585846\n",
      "\n",
      "episode 6, policy loss -0.09237399697303772\n",
      "\n",
      "episode 7, policy loss -0.12329672276973724\n",
      "\n",
      "episode 8, policy loss -0.11180858314037323\n",
      "\n",
      "episode 9, policy loss -0.03307675942778587\n",
      "\n",
      "episode 10, policy loss -0.08062232285737991\n",
      "\n",
      "episode 11, policy loss -0.10086306929588318\n",
      "\n",
      "episode 12, policy loss -0.12951543927192688\n",
      "\n",
      "episode 13, policy loss -0.09478951245546341\n",
      "\n",
      "episode 14, policy loss -0.12509772181510925\n",
      "\n",
      "episode 15, policy loss -0.10385287553071976\n",
      "\n",
      "episode 16, policy loss -0.09172705560922623\n",
      "\n",
      "Policy train loss in epoch 1:-0.10010578273795545\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.07848765701055527\n",
      "\n",
      "episode 2, policy loss -0.10370273143053055\n",
      "\n",
      "episode 3, policy loss -0.10420471429824829\n",
      "\n",
      "episode 4, policy loss -0.12151314318180084\n",
      "\n",
      "episode 5, policy loss -0.10709518194198608\n",
      "\n",
      "episode 6, policy loss -0.09266579151153564\n",
      "\n",
      "episode 7, policy loss -0.11386197060346603\n",
      "\n",
      "episode 8, policy loss -0.08293505012989044\n",
      "\n",
      "episode 9, policy loss -0.1279979646205902\n",
      "\n",
      "episode 10, policy loss -0.09421656280755997\n",
      "\n",
      "episode 11, policy loss -0.10450249910354614\n",
      "\n",
      "episode 12, policy loss -0.11897064745426178\n",
      "\n",
      "episode 13, policy loss -0.037427615374326706\n",
      "\n",
      "episode 14, policy loss -0.12899163365364075\n",
      "\n",
      "episode 15, policy loss -0.0964641273021698\n",
      "\n",
      "episode 16, policy loss -0.09374182671308517\n",
      "\n",
      "Policy train loss in epoch 2:-0.1004236948210746\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.09621300548315048\n",
      "\n",
      "episode 2, policy loss -0.09100025147199631\n",
      "\n",
      "episode 3, policy loss -0.1249842643737793\n",
      "\n",
      "episode 4, policy loss -0.10582855343818665\n",
      "\n",
      "episode 5, policy loss -0.10668928921222687\n",
      "\n",
      "episode 6, policy loss -0.03702609986066818\n",
      "\n",
      "episode 7, policy loss -0.08581002801656723\n",
      "\n",
      "episode 8, policy loss -0.1275947093963623\n",
      "\n",
      "episode 9, policy loss -0.1052507609128952\n",
      "\n",
      "episode 10, policy loss -0.07955051213502884\n",
      "\n",
      "episode 11, policy loss -0.10417324304580688\n",
      "\n",
      "episode 12, policy loss -0.1294117569923401\n",
      "\n",
      "episode 13, policy loss -0.0942039042711258\n",
      "\n",
      "episode 14, policy loss -0.0919080451130867\n",
      "\n",
      "episode 15, policy loss -0.1108783632516861\n",
      "\n",
      "episode 16, policy loss -0.12140017002820969\n",
      "\n",
      "Policy train loss in epoch 3:-0.10074518481269479\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.11630135029554367\n",
      "\n",
      "episode 2, val func loss 0.08644914627075195\n",
      "\n",
      "episode 3, val func loss 0.14074331521987915\n",
      "\n",
      "episode 4, val func loss 0.08076866716146469\n",
      "\n",
      "episode 5, val func loss 0.12039545178413391\n",
      "\n",
      "episode 6, val func loss 0.13441719114780426\n",
      "\n",
      "episode 7, val func loss 0.13921807706356049\n",
      "\n",
      "episode 8, val func loss 0.10002026706933975\n",
      "\n",
      "episode 9, val func loss 0.12228810787200928\n",
      "\n",
      "episode 10, val func loss 0.09149791300296783\n",
      "\n",
      "episode 11, val func loss 0.0671018660068512\n",
      "\n",
      "episode 12, val func loss 0.13933785259723663\n",
      "\n",
      "episode 13, val func loss 0.11875517666339874\n",
      "\n",
      "episode 14, val func loss 0.154422327876091\n",
      "\n",
      "episode 15, val func loss 0.1168343722820282\n",
      "\n",
      "episode 16, val func loss 0.09858467429876328\n",
      "\n",
      "Val func train loss in epoch 0:0.114195984788239\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.12197080999612808\n",
      "\n",
      "episode 2, val func loss 0.11855557560920715\n",
      "\n",
      "episode 3, val func loss 0.09907633811235428\n",
      "\n",
      "episode 4, val func loss 0.13780252635478973\n",
      "\n",
      "episode 5, val func loss 0.13984175026416779\n",
      "\n",
      "episode 6, val func loss 0.15562982857227325\n",
      "\n",
      "episode 7, val func loss 0.09863948822021484\n",
      "\n",
      "episode 8, val func loss 0.07290596514940262\n",
      "\n",
      "episode 9, val func loss 0.09691881388425827\n",
      "\n",
      "episode 10, val func loss 0.12260561436414719\n",
      "\n",
      "episode 11, val func loss 0.06775601953268051\n",
      "\n",
      "episode 12, val func loss 0.13258104026317596\n",
      "\n",
      "episode 13, val func loss 0.11387615650892258\n",
      "\n",
      "episode 14, val func loss 0.12090001255273819\n",
      "\n",
      "episode 15, val func loss 0.0901634469628334\n",
      "\n",
      "episode 16, val func loss 0.13572092354297638\n",
      "\n",
      "Val func train loss in epoch 1:0.11405901936814189\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.13251888751983643\n",
      "\n",
      "episode 2, val func loss 0.13468340039253235\n",
      "\n",
      "episode 3, val func loss 0.07115912437438965\n",
      "\n",
      "episode 4, val func loss 0.0938817709684372\n",
      "\n",
      "episode 5, val func loss 0.1006554663181305\n",
      "\n",
      "episode 6, val func loss 0.09934231638908386\n",
      "\n",
      "episode 7, val func loss 0.13750417530536652\n",
      "\n",
      "episode 8, val func loss 0.11441882699728012\n",
      "\n",
      "episode 9, val func loss 0.11816321313381195\n",
      "\n",
      "episode 10, val func loss 0.15493182837963104\n",
      "\n",
      "episode 11, val func loss 0.06805090606212616\n",
      "\n",
      "episode 12, val func loss 0.11996745318174362\n",
      "\n",
      "episode 13, val func loss 0.11857429146766663\n",
      "\n",
      "episode 14, val func loss 0.09025067836046219\n",
      "\n",
      "episode 15, val func loss 0.1400514543056488\n",
      "\n",
      "episode 16, val func loss 0.12277012318372726\n",
      "\n",
      "Val func train loss in epoch 2:0.11355774477124214\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.13402338325977325\n",
      "\n",
      "episode 2, val func loss 0.0676095113158226\n",
      "\n",
      "episode 3, val func loss 0.11954426765441895\n",
      "\n",
      "episode 4, val func loss 0.07414176315069199\n",
      "\n",
      "episode 5, val func loss 0.1386042684316635\n",
      "\n",
      "episode 6, val func loss 0.09885577857494354\n",
      "\n",
      "episode 7, val func loss 0.12132497876882553\n",
      "\n",
      "episode 8, val func loss 0.11840290576219559\n",
      "\n",
      "episode 9, val func loss 0.1545405387878418\n",
      "\n",
      "episode 10, val func loss 0.1349242925643921\n",
      "\n",
      "episode 11, val func loss 0.14148423075675964\n",
      "\n",
      "episode 12, val func loss 0.11939837783575058\n",
      "\n",
      "episode 13, val func loss 0.11484907567501068\n",
      "\n",
      "episode 14, val func loss 0.08731259405612946\n",
      "\n",
      "episode 15, val func loss 0.09931987524032593\n",
      "\n",
      "episode 16, val func loss 0.09029123187065125\n",
      "\n",
      "Val func train loss in epoch 3:0.11341419210657477\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1216709092259407\n",
      "\n",
      "episode 2, val func loss 0.10010207444429398\n",
      "\n",
      "episode 3, val func loss 0.11819213628768921\n",
      "\n",
      "episode 4, val func loss 0.11687508970499039\n",
      "\n",
      "episode 5, val func loss 0.11518721282482147\n",
      "\n",
      "episode 6, val func loss 0.08738136291503906\n",
      "\n",
      "episode 7, val func loss 0.09835362434387207\n",
      "\n",
      "episode 8, val func loss 0.12262112647294998\n",
      "\n",
      "episode 9, val func loss 0.06756255775690079\n",
      "\n",
      "episode 10, val func loss 0.13922618329524994\n",
      "\n",
      "episode 11, val func loss 0.13272275030612946\n",
      "\n",
      "episode 12, val func loss 0.07484980672597885\n",
      "\n",
      "episode 13, val func loss 0.1418483555316925\n",
      "\n",
      "episode 14, val func loss 0.13591346144676208\n",
      "\n",
      "episode 15, val func loss 0.09508132189512253\n",
      "\n",
      "episode 16, val func loss 0.15241988003253937\n",
      "\n",
      "Val func train loss in epoch 4:0.11375049082562327\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.15342459082603455\n",
      "\n",
      "episode 2, val func loss 0.13211609423160553\n",
      "\n",
      "episode 3, val func loss 0.113829106092453\n",
      "\n",
      "episode 4, val func loss 0.06703541427850723\n",
      "\n",
      "episode 5, val func loss 0.09830658882856369\n",
      "\n",
      "episode 6, val func loss 0.07792080193758011\n",
      "\n",
      "episode 7, val func loss 0.09230986982584\n",
      "\n",
      "episode 8, val func loss 0.13753046095371246\n",
      "\n",
      "episode 9, val func loss 0.14061041176319122\n",
      "\n",
      "episode 10, val func loss 0.11923298984766006\n",
      "\n",
      "episode 11, val func loss 0.13451845943927765\n",
      "\n",
      "episode 12, val func loss 0.09917549788951874\n",
      "\n",
      "episode 13, val func loss 0.12062882632017136\n",
      "\n",
      "episode 14, val func loss 0.08795187622308731\n",
      "\n",
      "episode 15, val func loss 0.11754127591848373\n",
      "\n",
      "episode 16, val func loss 0.11569274961948395\n",
      "\n",
      "Val func train loss in epoch 5:0.11298906337469816\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.0781380832195282\n",
      "\n",
      "episode 2, val func loss 0.13923878967761993\n",
      "\n",
      "episode 3, val func loss 0.13206402957439423\n",
      "\n",
      "episode 4, val func loss 0.09910710901021957\n",
      "\n",
      "episode 5, val func loss 0.13354666531085968\n",
      "\n",
      "episode 6, val func loss 0.06760650128126144\n",
      "\n",
      "episode 7, val func loss 0.11899719387292862\n",
      "\n",
      "episode 8, val func loss 0.121646948158741\n",
      "\n",
      "episode 9, val func loss 0.11510027945041656\n",
      "\n",
      "episode 10, val func loss 0.0913735181093216\n",
      "\n",
      "episode 11, val func loss 0.12010186910629272\n",
      "\n",
      "episode 12, val func loss 0.15603789687156677\n",
      "\n",
      "episode 13, val func loss 0.11554622650146484\n",
      "\n",
      "episode 14, val func loss 0.09912289679050446\n",
      "\n",
      "episode 15, val func loss 0.1372535526752472\n",
      "\n",
      "episode 16, val func loss 0.08734790235757828\n",
      "\n",
      "Val func train loss in epoch 6:0.11326434137299657\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.11506146192550659\n",
      "\n",
      "episode 2, val func loss 0.09867999702692032\n",
      "\n",
      "episode 3, val func loss 0.09855712950229645\n",
      "\n",
      "episode 4, val func loss 0.0869385302066803\n",
      "\n",
      "episode 5, val func loss 0.12177064269781113\n",
      "\n",
      "episode 6, val func loss 0.07866484671831131\n",
      "\n",
      "episode 7, val func loss 0.1326150894165039\n",
      "\n",
      "episode 8, val func loss 0.1407998651266098\n",
      "\n",
      "episode 9, val func loss 0.11687206476926804\n",
      "\n",
      "episode 10, val func loss 0.1525171399116516\n",
      "\n",
      "episode 11, val func loss 0.06752260029315948\n",
      "\n",
      "episode 12, val func loss 0.13764773309230804\n",
      "\n",
      "episode 13, val func loss 0.11882998049259186\n",
      "\n",
      "episode 14, val func loss 0.09099131077528\n",
      "\n",
      "episode 15, val func loss 0.11900186538696289\n",
      "\n",
      "episode 16, val func loss 0.13681775331497192\n",
      "\n",
      "Val func train loss in epoch 7:0.1133305006660521\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1391444057226181\n",
      "\n",
      "episode 2, val func loss 0.09033362567424774\n",
      "\n",
      "episode 3, val func loss 0.1315511167049408\n",
      "\n",
      "episode 4, val func loss 0.11893942207098007\n",
      "\n",
      "episode 5, val func loss 0.12145910412073135\n",
      "\n",
      "episode 6, val func loss 0.11820289492607117\n",
      "\n",
      "episode 7, val func loss 0.09838882833719254\n",
      "\n",
      "episode 8, val func loss 0.07383285462856293\n",
      "\n",
      "episode 9, val func loss 0.11618716269731522\n",
      "\n",
      "episode 10, val func loss 0.06794757395982742\n",
      "\n",
      "episode 11, val func loss 0.08897285908460617\n",
      "\n",
      "episode 12, val func loss 0.11631371080875397\n",
      "\n",
      "episode 13, val func loss 0.09874095022678375\n",
      "\n",
      "episode 14, val func loss 0.13509602844715118\n",
      "\n",
      "episode 15, val func loss 0.1367330402135849\n",
      "\n",
      "episode 16, val func loss 0.15448230504989624\n",
      "\n",
      "Val func train loss in epoch 8:0.11289536766707897\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.13817241787910461\n",
      "\n",
      "episode 2, val func loss 0.12191491574048996\n",
      "\n",
      "episode 3, val func loss 0.11744149774312973\n",
      "\n",
      "episode 4, val func loss 0.07592593133449554\n",
      "\n",
      "episode 5, val func loss 0.11598512530326843\n",
      "\n",
      "episode 6, val func loss 0.13455553352832794\n",
      "\n",
      "episode 7, val func loss 0.11816783994436264\n",
      "\n",
      "episode 8, val func loss 0.06811974197626114\n",
      "\n",
      "episode 9, val func loss 0.1527893841266632\n",
      "\n",
      "episode 10, val func loss 0.11912580579519272\n",
      "\n",
      "episode 11, val func loss 0.09905621409416199\n",
      "\n",
      "episode 12, val func loss 0.13727228343486786\n",
      "\n",
      "episode 13, val func loss 0.09093686938285828\n",
      "\n",
      "episode 14, val func loss 0.13293056190013885\n",
      "\n",
      "episode 15, val func loss 0.0866420716047287\n",
      "\n",
      "episode 16, val func loss 0.0993088111281395\n",
      "\n",
      "Val func train loss in epoch 9:0.11302156280726194\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.09954529255628586\n",
      "\n",
      "episode 2, val func loss 0.15472620725631714\n",
      "\n",
      "episode 3, val func loss 0.11467453092336655\n",
      "\n",
      "episode 4, val func loss 0.06733543425798416\n",
      "\n",
      "episode 5, val func loss 0.12186842411756516\n",
      "\n",
      "episode 6, val func loss 0.11710185557603836\n",
      "\n",
      "episode 7, val func loss 0.09210523217916489\n",
      "\n",
      "episode 8, val func loss 0.11787525564432144\n",
      "\n",
      "episode 9, val func loss 0.08710934221744537\n",
      "\n",
      "episode 10, val func loss 0.12037698179483414\n",
      "\n",
      "episode 11, val func loss 0.13816407322883606\n",
      "\n",
      "episode 12, val func loss 0.13447441160678864\n",
      "\n",
      "episode 13, val func loss 0.13937562704086304\n",
      "\n",
      "episode 14, val func loss 0.13515274226665497\n",
      "\n",
      "episode 15, val func loss 0.07407712191343307\n",
      "\n",
      "episode 16, val func loss 0.100034199655056\n",
      "\n",
      "Val func train loss in epoch 10:0.11337479576468468\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.14257782697677612\n",
      "\n",
      "episode 2, val func loss 0.1227220892906189\n",
      "\n",
      "episode 3, val func loss 0.12139210850000381\n",
      "\n",
      "episode 4, val func loss 0.12271159142255783\n",
      "\n",
      "episode 5, val func loss 0.06713080406188965\n",
      "\n",
      "episode 6, val func loss 0.09022659063339233\n",
      "\n",
      "episode 7, val func loss 0.08533458411693573\n",
      "\n",
      "episode 8, val func loss 0.10416696220636368\n",
      "\n",
      "episode 9, val func loss 0.09447168558835983\n",
      "\n",
      "episode 10, val func loss 0.14117272198200226\n",
      "\n",
      "episode 11, val func loss 0.13307280838489532\n",
      "\n",
      "episode 12, val func loss 0.15243645012378693\n",
      "\n",
      "episode 13, val func loss 0.14634886384010315\n",
      "\n",
      "episode 14, val func loss 0.12389195710420609\n",
      "\n",
      "episode 15, val func loss 0.11864285171031952\n",
      "\n",
      "episode 16, val func loss 0.09834855049848557\n",
      "\n",
      "Val func train loss in epoch 11:0.11654052790254354\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.12396217882633209\n",
      "\n",
      "episode 2, val func loss 0.11754229664802551\n",
      "\n",
      "episode 3, val func loss 0.08762231469154358\n",
      "\n",
      "episode 4, val func loss 0.13945654034614563\n",
      "\n",
      "episode 5, val func loss 0.09050461649894714\n",
      "\n",
      "episode 6, val func loss 0.08409392833709717\n",
      "\n",
      "episode 7, val func loss 0.1194736585021019\n",
      "\n",
      "episode 8, val func loss 0.09983900189399719\n",
      "\n",
      "episode 9, val func loss 0.13369448482990265\n",
      "\n",
      "episode 10, val func loss 0.13412432372570038\n",
      "\n",
      "episode 11, val func loss 0.09905786067247391\n",
      "\n",
      "episode 12, val func loss 0.06683825701475143\n",
      "\n",
      "episode 13, val func loss 0.14018085598945618\n",
      "\n",
      "episode 14, val func loss 0.11563771963119507\n",
      "\n",
      "episode 15, val func loss 0.15276692807674408\n",
      "\n",
      "episode 16, val func loss 0.11731795966625214\n",
      "\n",
      "Val func train loss in epoch 12:0.11388205783441663\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.07105014473199844\n",
      "\n",
      "episode 2, val func loss 0.1393943727016449\n",
      "\n",
      "episode 3, val func loss 0.09935399889945984\n",
      "\n",
      "episode 4, val func loss 0.13393118977546692\n",
      "\n",
      "episode 5, val func loss 0.06719901412725449\n",
      "\n",
      "episode 6, val func loss 0.12031641602516174\n",
      "\n",
      "episode 7, val func loss 0.13913725316524506\n",
      "\n",
      "episode 8, val func loss 0.09870441257953644\n",
      "\n",
      "episode 9, val func loss 0.11595644056797028\n",
      "\n",
      "episode 10, val func loss 0.11471705138683319\n",
      "\n",
      "episode 11, val func loss 0.09084723144769669\n",
      "\n",
      "episode 12, val func loss 0.15649504959583282\n",
      "\n",
      "episode 13, val func loss 0.11793560534715652\n",
      "\n",
      "episode 14, val func loss 0.1318933218717575\n",
      "\n",
      "episode 15, val func loss 0.08829280734062195\n",
      "\n",
      "episode 16, val func loss 0.12205918878316879\n",
      "\n",
      "Val func train loss in epoch 13:0.11295521864667535\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1213611513376236\n",
      "\n",
      "episode 2, val func loss 0.11879588663578033\n",
      "\n",
      "episode 3, val func loss 0.11958066374063492\n",
      "\n",
      "episode 4, val func loss 0.09132551401853561\n",
      "\n",
      "episode 5, val func loss 0.15460814535617828\n",
      "\n",
      "episode 6, val func loss 0.1375035047531128\n",
      "\n",
      "episode 7, val func loss 0.09878756105899811\n",
      "\n",
      "episode 8, val func loss 0.11553084850311279\n",
      "\n",
      "episode 9, val func loss 0.06706605851650238\n",
      "\n",
      "episode 10, val func loss 0.13898636400699615\n",
      "\n",
      "episode 11, val func loss 0.08679203689098358\n",
      "\n",
      "episode 12, val func loss 0.11627212911844254\n",
      "\n",
      "episode 13, val func loss 0.13660652935504913\n",
      "\n",
      "episode 14, val func loss 0.08015317469835281\n",
      "\n",
      "episode 15, val func loss 0.1342748999595642\n",
      "\n",
      "episode 16, val func loss 0.09923207759857178\n",
      "\n",
      "Val func train loss in epoch 14:0.11355478409677744\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.14122982323169708\n",
      "\n",
      "episode 2, val func loss 0.10185511410236359\n",
      "\n",
      "episode 3, val func loss 0.1221272423863411\n",
      "\n",
      "episode 4, val func loss 0.06825342774391174\n",
      "\n",
      "episode 5, val func loss 0.13961757719516754\n",
      "\n",
      "episode 6, val func loss 0.12262966483831406\n",
      "\n",
      "episode 7, val func loss 0.09078366309404373\n",
      "\n",
      "episode 8, val func loss 0.11752259731292725\n",
      "\n",
      "episode 9, val func loss 0.11448244750499725\n",
      "\n",
      "episode 10, val func loss 0.12122637778520584\n",
      "\n",
      "episode 11, val func loss 0.09937667846679688\n",
      "\n",
      "episode 12, val func loss 0.08721734583377838\n",
      "\n",
      "episode 13, val func loss 0.15241044759750366\n",
      "\n",
      "episode 14, val func loss 0.07329785078763962\n",
      "\n",
      "episode 15, val func loss 0.1349978744983673\n",
      "\n",
      "episode 16, val func loss 0.1333085298538208\n",
      "\n",
      "Val func train loss in epoch 15:0.11377104138955474\n",
      "***********************TIME WAS 5.210951864719391 min*****************************\n",
      "\n",
      "**********************ROUND 16 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.18970662355422974\n",
      "\n",
      "episode 2, policy loss -0.1338280737400055\n",
      "\n",
      "episode 3, policy loss -0.14051386713981628\n",
      "\n",
      "episode 4, policy loss -0.14461097121238708\n",
      "\n",
      "episode 5, policy loss -0.1687197983264923\n",
      "\n",
      "episode 6, policy loss -0.15099897980690002\n",
      "\n",
      "episode 7, policy loss -0.15170639753341675\n",
      "\n",
      "episode 8, policy loss -0.11699064075946808\n",
      "\n",
      "episode 9, policy loss -0.1483943909406662\n",
      "\n",
      "episode 10, policy loss -0.14815270900726318\n",
      "\n",
      "episode 11, policy loss -0.14258816838264465\n",
      "\n",
      "episode 12, policy loss -0.13938841223716736\n",
      "\n",
      "episode 13, policy loss -0.14276310801506042\n",
      "\n",
      "episode 14, policy loss -0.15371966361999512\n",
      "\n",
      "episode 15, policy loss -0.13305388391017914\n",
      "\n",
      "episode 16, policy loss -0.15137022733688354\n",
      "\n",
      "Policy train loss in epoch 0:-0.14728161972016096\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.15246188640594482\n",
      "\n",
      "episode 2, policy loss -0.13228654861450195\n",
      "\n",
      "episode 3, policy loss -0.1499396562576294\n",
      "\n",
      "episode 4, policy loss -0.14199814200401306\n",
      "\n",
      "episode 5, policy loss -0.14160862565040588\n",
      "\n",
      "episode 6, policy loss -0.15501004457473755\n",
      "\n",
      "episode 7, policy loss -0.19110481441020966\n",
      "\n",
      "episode 8, policy loss -0.1665794849395752\n",
      "\n",
      "episode 9, policy loss -0.14950336515903473\n",
      "\n",
      "episode 10, policy loss -0.14864256978034973\n",
      "\n",
      "episode 11, policy loss -0.1525101214647293\n",
      "\n",
      "episode 12, policy loss -0.13860473036766052\n",
      "\n",
      "episode 13, policy loss -0.152095764875412\n",
      "\n",
      "episode 14, policy loss -0.13470926880836487\n",
      "\n",
      "episode 15, policy loss -0.1186446100473404\n",
      "\n",
      "episode 16, policy loss -0.1381804347038269\n",
      "\n",
      "Policy train loss in epoch 1:-0.1477425042539835\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.15497417747974396\n",
      "\n",
      "episode 2, policy loss -0.1441662609577179\n",
      "\n",
      "episode 3, policy loss -0.13487151265144348\n",
      "\n",
      "episode 4, policy loss -0.1525471806526184\n",
      "\n",
      "episode 5, policy loss -0.14798195660114288\n",
      "\n",
      "episode 6, policy loss -0.19237905740737915\n",
      "\n",
      "episode 7, policy loss -0.13398580253124237\n",
      "\n",
      "episode 8, policy loss -0.14613312482833862\n",
      "\n",
      "episode 9, policy loss -0.15423572063446045\n",
      "\n",
      "episode 10, policy loss -0.1691405326128006\n",
      "\n",
      "episode 11, policy loss -0.11795185506343842\n",
      "\n",
      "episode 12, policy loss -0.13863155245780945\n",
      "\n",
      "episode 13, policy loss -0.14818677306175232\n",
      "\n",
      "episode 14, policy loss -0.15572643280029297\n",
      "\n",
      "episode 15, policy loss -0.1407698541879654\n",
      "\n",
      "episode 16, policy loss -0.14881837368011475\n",
      "\n",
      "Policy train loss in epoch 2:-0.14878126047551632\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.15255358815193176\n",
      "\n",
      "episode 2, policy loss -0.15157172083854675\n",
      "\n",
      "episode 3, policy loss -0.1508246660232544\n",
      "\n",
      "episode 4, policy loss -0.11599155515432358\n",
      "\n",
      "episode 5, policy loss -0.14702962338924408\n",
      "\n",
      "episode 6, policy loss -0.14147056639194489\n",
      "\n",
      "episode 7, policy loss -0.19074416160583496\n",
      "\n",
      "episode 8, policy loss -0.1667470484972\n",
      "\n",
      "episode 9, policy loss -0.15028780698776245\n",
      "\n",
      "episode 10, policy loss -0.15345969796180725\n",
      "\n",
      "episode 11, policy loss -0.14392885565757751\n",
      "\n",
      "episode 12, policy loss -0.14196328818798065\n",
      "\n",
      "episode 13, policy loss -0.14485979080200195\n",
      "\n",
      "episode 14, policy loss -0.138274148106575\n",
      "\n",
      "episode 15, policy loss -0.13294486701488495\n",
      "\n",
      "episode 16, policy loss -0.13559526205062866\n",
      "\n",
      "Policy train loss in epoch 3:-0.14739041542634368\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.11124038696289062\n",
      "\n",
      "episode 2, val func loss 0.10984497517347336\n",
      "\n",
      "episode 3, val func loss 0.08867670595645905\n",
      "\n",
      "episode 4, val func loss 0.12620599567890167\n",
      "\n",
      "episode 5, val func loss 0.1309254765510559\n",
      "\n",
      "episode 6, val func loss 0.14666078984737396\n",
      "\n",
      "episode 7, val func loss 0.14472880959510803\n",
      "\n",
      "episode 8, val func loss 0.13994035124778748\n",
      "\n",
      "episode 9, val func loss 0.11872052401304245\n",
      "\n",
      "episode 10, val func loss 0.11599796265363693\n",
      "\n",
      "episode 11, val func loss 0.15285687148571014\n",
      "\n",
      "episode 12, val func loss 0.13808299601078033\n",
      "\n",
      "episode 13, val func loss 0.1403180956840515\n",
      "\n",
      "episode 14, val func loss 0.14560569822788239\n",
      "\n",
      "episode 15, val func loss 0.11309584230184555\n",
      "\n",
      "episode 16, val func loss 0.1111980751156807\n",
      "\n",
      "Val func train loss in epoch 0:0.127131222281605\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.11953724920749664\n",
      "\n",
      "episode 2, val func loss 0.12958957254886627\n",
      "\n",
      "episode 3, val func loss 0.13964232802391052\n",
      "\n",
      "episode 4, val func loss 0.112005814909935\n",
      "\n",
      "episode 5, val func loss 0.11682019382715225\n",
      "\n",
      "episode 6, val func loss 0.1432105153799057\n",
      "\n",
      "episode 7, val func loss 0.12615768611431122\n",
      "\n",
      "episode 8, val func loss 0.1531231552362442\n",
      "\n",
      "episode 9, val func loss 0.13860969245433807\n",
      "\n",
      "episode 10, val func loss 0.10586006939411163\n",
      "\n",
      "episode 11, val func loss 0.11040734499692917\n",
      "\n",
      "episode 12, val func loss 0.11060091853141785\n",
      "\n",
      "episode 13, val func loss 0.08467985689640045\n",
      "\n",
      "episode 14, val func loss 0.13972681760787964\n",
      "\n",
      "episode 15, val func loss 0.1449839174747467\n",
      "\n",
      "episode 16, val func loss 0.14629097282886505\n",
      "\n",
      "Val func train loss in epoch 1:0.1263278815895319\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.13404031097888947\n",
      "\n",
      "episode 2, val func loss 0.10530498623847961\n",
      "\n",
      "episode 3, val func loss 0.08368754386901855\n",
      "\n",
      "episode 4, val func loss 0.14696404337882996\n",
      "\n",
      "episode 5, val func loss 0.11337878555059433\n",
      "\n",
      "episode 6, val func loss 0.13101747632026672\n",
      "\n",
      "episode 7, val func loss 0.14447472989559174\n",
      "\n",
      "episode 8, val func loss 0.11231037229299545\n",
      "\n",
      "episode 9, val func loss 0.1427176147699356\n",
      "\n",
      "episode 10, val func loss 0.12606626749038696\n",
      "\n",
      "episode 11, val func loss 0.11915837228298187\n",
      "\n",
      "episode 12, val func loss 0.11079319566488266\n",
      "\n",
      "episode 13, val func loss 0.15304245054721832\n",
      "\n",
      "episode 14, val func loss 0.1399896740913391\n",
      "\n",
      "episode 15, val func loss 0.11703671514987946\n",
      "\n",
      "episode 16, val func loss 0.14018814265727997\n",
      "\n",
      "Val func train loss in epoch 2:0.1262606675736606\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1302097588777542\n",
      "\n",
      "episode 2, val func loss 0.13417430222034454\n",
      "\n",
      "episode 3, val func loss 0.11892469227313995\n",
      "\n",
      "episode 4, val func loss 0.11233893781900406\n",
      "\n",
      "episode 5, val func loss 0.1396435648202896\n",
      "\n",
      "episode 6, val func loss 0.14400257170200348\n",
      "\n",
      "episode 7, val func loss 0.12639696896076202\n",
      "\n",
      "episode 8, val func loss 0.1434422880411148\n",
      "\n",
      "episode 9, val func loss 0.1486952006816864\n",
      "\n",
      "episode 10, val func loss 0.10679398477077484\n",
      "\n",
      "episode 11, val func loss 0.13976310193538666\n",
      "\n",
      "episode 12, val func loss 0.11147888749837875\n",
      "\n",
      "episode 13, val func loss 0.08483947813510895\n",
      "\n",
      "episode 14, val func loss 0.1706864982843399\n",
      "\n",
      "episode 15, val func loss 0.12120217829942703\n",
      "\n",
      "episode 16, val func loss 0.11063943058252335\n",
      "\n",
      "Val func train loss in epoch 3:0.1277019903063774\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.10991019010543823\n",
      "\n",
      "episode 2, val func loss 0.15489192306995392\n",
      "\n",
      "episode 3, val func loss 0.1471996307373047\n",
      "\n",
      "episode 4, val func loss 0.1324061155319214\n",
      "\n",
      "episode 5, val func loss 0.1281282603740692\n",
      "\n",
      "episode 6, val func loss 0.11895913630723953\n",
      "\n",
      "episode 7, val func loss 0.11660696566104889\n",
      "\n",
      "episode 8, val func loss 0.11012222617864609\n",
      "\n",
      "episode 9, val func loss 0.08715891093015671\n",
      "\n",
      "episode 10, val func loss 0.13580617308616638\n",
      "\n",
      "episode 11, val func loss 0.14723339676856995\n",
      "\n",
      "episode 12, val func loss 0.11124163120985031\n",
      "\n",
      "episode 13, val func loss 0.1398458033800125\n",
      "\n",
      "episode 14, val func loss 0.14658749103546143\n",
      "\n",
      "episode 15, val func loss 0.10617878288030624\n",
      "\n",
      "episode 16, val func loss 0.1431073099374771\n",
      "\n",
      "Val func train loss in epoch 4:0.1272114966996014\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.11861845850944519\n",
      "\n",
      "episode 2, val func loss 0.10979331284761429\n",
      "\n",
      "episode 3, val func loss 0.11369960755109787\n",
      "\n",
      "episode 4, val func loss 0.14317946135997772\n",
      "\n",
      "episode 5, val func loss 0.1303967982530594\n",
      "\n",
      "episode 6, val func loss 0.11644869297742844\n",
      "\n",
      "episode 7, val func loss 0.1364564299583435\n",
      "\n",
      "episode 8, val func loss 0.14562152326107025\n",
      "\n",
      "episode 9, val func loss 0.1400599628686905\n",
      "\n",
      "episode 10, val func loss 0.14586499333381653\n",
      "\n",
      "episode 11, val func loss 0.11008171737194061\n",
      "\n",
      "episode 12, val func loss 0.1264503300189972\n",
      "\n",
      "episode 13, val func loss 0.1528964638710022\n",
      "\n",
      "episode 14, val func loss 0.08722532540559769\n",
      "\n",
      "episode 15, val func loss 0.10674327611923218\n",
      "\n",
      "episode 16, val func loss 0.14036867022514343\n",
      "\n",
      "Val func train loss in epoch 5:0.12649406399577856\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.13944515585899353\n",
      "\n",
      "episode 2, val func loss 0.08447304368019104\n",
      "\n",
      "episode 3, val func loss 0.11160904914140701\n",
      "\n",
      "episode 4, val func loss 0.11670492589473724\n",
      "\n",
      "episode 5, val func loss 0.11205241829156876\n",
      "\n",
      "episode 6, val func loss 0.11668866127729416\n",
      "\n",
      "episode 7, val func loss 0.152814120054245\n",
      "\n",
      "episode 8, val func loss 0.1276690810918808\n",
      "\n",
      "episode 9, val func loss 0.1343945562839508\n",
      "\n",
      "episode 10, val func loss 0.1458863765001297\n",
      "\n",
      "episode 11, val func loss 0.1426604688167572\n",
      "\n",
      "episode 12, val func loss 0.1340455859899521\n",
      "\n",
      "episode 13, val func loss 0.10756126046180725\n",
      "\n",
      "episode 14, val func loss 0.149896040558815\n",
      "\n",
      "episode 15, val func loss 0.14176565408706665\n",
      "\n",
      "episode 16, val func loss 0.11918172985315323\n",
      "\n",
      "Val func train loss in epoch 6:0.12730300799012184\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.11570897698402405\n",
      "\n",
      "episode 2, val func loss 0.11938311159610748\n",
      "\n",
      "episode 3, val func loss 0.14132678508758545\n",
      "\n",
      "episode 4, val func loss 0.1261490434408188\n",
      "\n",
      "episode 5, val func loss 0.11027780920267105\n",
      "\n",
      "episode 6, val func loss 0.14360062777996063\n",
      "\n",
      "episode 7, val func loss 0.1528283804655075\n",
      "\n",
      "episode 8, val func loss 0.11363139748573303\n",
      "\n",
      "episode 9, val func loss 0.11020652204751968\n",
      "\n",
      "episode 10, val func loss 0.1468215435743332\n",
      "\n",
      "episode 11, val func loss 0.13990364968776703\n",
      "\n",
      "episode 12, val func loss 0.14526237547397614\n",
      "\n",
      "episode 13, val func loss 0.13966257870197296\n",
      "\n",
      "episode 14, val func loss 0.08541779220104218\n",
      "\n",
      "episode 15, val func loss 0.10524500906467438\n",
      "\n",
      "episode 16, val func loss 0.13019953668117523\n",
      "\n",
      "Val func train loss in epoch 7:0.1266015712171793\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1394323855638504\n",
      "\n",
      "episode 2, val func loss 0.11100900918245316\n",
      "\n",
      "episode 3, val func loss 0.1398654729127884\n",
      "\n",
      "episode 4, val func loss 0.1532720923423767\n",
      "\n",
      "episode 5, val func loss 0.11867175996303558\n",
      "\n",
      "episode 6, val func loss 0.11004625260829926\n",
      "\n",
      "episode 7, val func loss 0.14292553067207336\n",
      "\n",
      "episode 8, val func loss 0.125895157456398\n",
      "\n",
      "episode 9, val func loss 0.08594118058681488\n",
      "\n",
      "episode 10, val func loss 0.13040174543857574\n",
      "\n",
      "episode 11, val func loss 0.14511971175670624\n",
      "\n",
      "episode 12, val func loss 0.13386109471321106\n",
      "\n",
      "episode 13, val func loss 0.1467152237892151\n",
      "\n",
      "episode 14, val func loss 0.11133971810340881\n",
      "\n",
      "episode 15, val func loss 0.11992686986923218\n",
      "\n",
      "episode 16, val func loss 0.10508639365434647\n",
      "\n",
      "Val func train loss in epoch 8:0.12621934991329908\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1400250792503357\n",
      "\n",
      "episode 2, val func loss 0.11226361989974976\n",
      "\n",
      "episode 3, val func loss 0.1410299390554428\n",
      "\n",
      "episode 4, val func loss 0.143034428358078\n",
      "\n",
      "episode 5, val func loss 0.14415095746517181\n",
      "\n",
      "episode 6, val func loss 0.11837375909090042\n",
      "\n",
      "episode 7, val func loss 0.1254052370786667\n",
      "\n",
      "episode 8, val func loss 0.08646167069673538\n",
      "\n",
      "episode 9, val func loss 0.13053616881370544\n",
      "\n",
      "episode 10, val func loss 0.1097523495554924\n",
      "\n",
      "episode 11, val func loss 0.10544676333665848\n",
      "\n",
      "episode 12, val func loss 0.1465841680765152\n",
      "\n",
      "episode 13, val func loss 0.11132257431745529\n",
      "\n",
      "episode 14, val func loss 0.15537238121032715\n",
      "\n",
      "episode 15, val func loss 0.11645764112472534\n",
      "\n",
      "episode 16, val func loss 0.13832959532737732\n",
      "\n",
      "Val func train loss in epoch 9:0.12653414579108357\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.13782407343387604\n",
      "\n",
      "episode 2, val func loss 0.14697568118572235\n",
      "\n",
      "episode 3, val func loss 0.11162950843572617\n",
      "\n",
      "episode 4, val func loss 0.15772300958633423\n",
      "\n",
      "episode 5, val func loss 0.11157239973545074\n",
      "\n",
      "episode 6, val func loss 0.13071414828300476\n",
      "\n",
      "episode 7, val func loss 0.13923335075378418\n",
      "\n",
      "episode 8, val func loss 0.1406729519367218\n",
      "\n",
      "episode 9, val func loss 0.12661540508270264\n",
      "\n",
      "episode 10, val func loss 0.1100853756070137\n",
      "\n",
      "episode 11, val func loss 0.14329122006893158\n",
      "\n",
      "episode 12, val func loss 0.11905668675899506\n",
      "\n",
      "episode 13, val func loss 0.0873003825545311\n",
      "\n",
      "episode 14, val func loss 0.11587783694267273\n",
      "\n",
      "episode 15, val func loss 0.10590756684541702\n",
      "\n",
      "episode 16, val func loss 0.1446814090013504\n",
      "\n",
      "Val func train loss in epoch 10:0.12682256288826466\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.12606094777584076\n",
      "\n",
      "episode 2, val func loss 0.11224165558815002\n",
      "\n",
      "episode 3, val func loss 0.14623849093914032\n",
      "\n",
      "episode 4, val func loss 0.10566062480211258\n",
      "\n",
      "episode 5, val func loss 0.12012135982513428\n",
      "\n",
      "episode 6, val func loss 0.08458001911640167\n",
      "\n",
      "episode 7, val func loss 0.1407112330198288\n",
      "\n",
      "episode 8, val func loss 0.11122637242078781\n",
      "\n",
      "episode 9, val func loss 0.1539585441350937\n",
      "\n",
      "episode 10, val func loss 0.11026453226804733\n",
      "\n",
      "episode 11, val func loss 0.14449112117290497\n",
      "\n",
      "episode 12, val func loss 0.14249634742736816\n",
      "\n",
      "episode 13, val func loss 0.11643669009208679\n",
      "\n",
      "episode 14, val func loss 0.1438882201910019\n",
      "\n",
      "episode 15, val func loss 0.13907642662525177\n",
      "\n",
      "episode 16, val func loss 0.1298753172159195\n",
      "\n",
      "Val func train loss in epoch 11:0.1267079939134419\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.11106333881616592\n",
      "\n",
      "episode 2, val func loss 0.08428224176168442\n",
      "\n",
      "episode 3, val func loss 0.10619738698005676\n",
      "\n",
      "episode 4, val func loss 0.1600593477487564\n",
      "\n",
      "episode 5, val func loss 0.11855529248714447\n",
      "\n",
      "episode 6, val func loss 0.13346506655216217\n",
      "\n",
      "episode 7, val func loss 0.1461154818534851\n",
      "\n",
      "episode 8, val func loss 0.1395568698644638\n",
      "\n",
      "episode 9, val func loss 0.1435924470424652\n",
      "\n",
      "episode 10, val func loss 0.13912293314933777\n",
      "\n",
      "episode 11, val func loss 0.14433959126472473\n",
      "\n",
      "episode 12, val func loss 0.13087932765483856\n",
      "\n",
      "episode 13, val func loss 0.12621933221817017\n",
      "\n",
      "episode 14, val func loss 0.10999911278486252\n",
      "\n",
      "episode 15, val func loss 0.11342956870794296\n",
      "\n",
      "episode 16, val func loss 0.11927476525306702\n",
      "\n",
      "Val func train loss in epoch 12:0.126634506508708\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1449057012796402\n",
      "\n",
      "episode 2, val func loss 0.13931754231452942\n",
      "\n",
      "episode 3, val func loss 0.11682883650064468\n",
      "\n",
      "episode 4, val func loss 0.11192973703145981\n",
      "\n",
      "episode 5, val func loss 0.11048583686351776\n",
      "\n",
      "episode 6, val func loss 0.11076458543539047\n",
      "\n",
      "episode 7, val func loss 0.13520775735378265\n",
      "\n",
      "episode 8, val func loss 0.10548407584428787\n",
      "\n",
      "episode 9, val func loss 0.13957399129867554\n",
      "\n",
      "episode 10, val func loss 0.08482930809259415\n",
      "\n",
      "episode 11, val func loss 0.14665646851062775\n",
      "\n",
      "episode 12, val func loss 0.1566653847694397\n",
      "\n",
      "episode 13, val func loss 0.12660612165927887\n",
      "\n",
      "episode 14, val func loss 0.13042786717414856\n",
      "\n",
      "episode 15, val func loss 0.14280347526073456\n",
      "\n",
      "episode 16, val func loss 0.1187153309583664\n",
      "\n",
      "Val func train loss in epoch 13:0.1263251262716949\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.14525438845157623\n",
      "\n",
      "episode 2, val func loss 0.14327144622802734\n",
      "\n",
      "episode 3, val func loss 0.13948270678520203\n",
      "\n",
      "episode 4, val func loss 0.1186019703745842\n",
      "\n",
      "episode 5, val func loss 0.10542569309473038\n",
      "\n",
      "episode 6, val func loss 0.11201924085617065\n",
      "\n",
      "episode 7, val func loss 0.13137587904930115\n",
      "\n",
      "episode 8, val func loss 0.11930745095014572\n",
      "\n",
      "episode 9, val func loss 0.12892726063728333\n",
      "\n",
      "episode 10, val func loss 0.14611734449863434\n",
      "\n",
      "episode 11, val func loss 0.11105284839868546\n",
      "\n",
      "episode 12, val func loss 0.11040353029966354\n",
      "\n",
      "episode 13, val func loss 0.14020340144634247\n",
      "\n",
      "episode 14, val func loss 0.14059136807918549\n",
      "\n",
      "episode 15, val func loss 0.15274199843406677\n",
      "\n",
      "episode 16, val func loss 0.08719303458929062\n",
      "\n",
      "Val func train loss in epoch 14:0.1269980976358056\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.11020196974277496\n",
      "\n",
      "episode 2, val func loss 0.1096978485584259\n",
      "\n",
      "episode 3, val func loss 0.13082477450370789\n",
      "\n",
      "episode 4, val func loss 0.08579874038696289\n",
      "\n",
      "episode 5, val func loss 0.11703305691480637\n",
      "\n",
      "episode 6, val func loss 0.134806290268898\n",
      "\n",
      "episode 7, val func loss 0.14015823602676392\n",
      "\n",
      "episode 8, val func loss 0.11984175443649292\n",
      "\n",
      "episode 9, val func loss 0.11138464510440826\n",
      "\n",
      "episode 10, val func loss 0.14606672525405884\n",
      "\n",
      "episode 11, val func loss 0.1561455875635147\n",
      "\n",
      "episode 12, val func loss 0.1393808126449585\n",
      "\n",
      "episode 13, val func loss 0.12588806450366974\n",
      "\n",
      "episode 14, val func loss 0.10703721642494202\n",
      "\n",
      "episode 15, val func loss 0.14327526092529297\n",
      "\n",
      "episode 16, val func loss 0.14832986891269684\n",
      "\n",
      "Val func train loss in epoch 15:0.12661692826077342\n",
      "***********************TIME WAS 5.1579758803049724 min*****************************\n",
      "\n",
      "**********************ROUND 17 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.08097726851701736\n",
      "\n",
      "episode 2, policy loss -0.11497844755649567\n",
      "\n",
      "episode 3, policy loss -0.14903920888900757\n",
      "\n",
      "episode 4, policy loss -0.10259684920310974\n",
      "\n",
      "episode 5, policy loss -0.09928605705499649\n",
      "\n",
      "episode 6, policy loss -0.14363789558410645\n",
      "\n",
      "episode 7, policy loss -0.18206346035003662\n",
      "\n",
      "episode 8, policy loss -0.08829387277364731\n",
      "\n",
      "episode 9, policy loss -0.11652634292840958\n",
      "\n",
      "episode 10, policy loss -0.0747271254658699\n",
      "\n",
      "episode 11, policy loss -0.10949533432722092\n",
      "\n",
      "episode 12, policy loss -0.13806946575641632\n",
      "\n",
      "episode 13, policy loss -0.10367314517498016\n",
      "\n",
      "episode 14, policy loss -0.10015793144702911\n",
      "\n",
      "episode 15, policy loss -0.09408210217952728\n",
      "\n",
      "episode 16, policy loss -0.08319145441055298\n",
      "\n",
      "Policy train loss in epoch 0:-0.11129974760115147\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.0976630374789238\n",
      "\n",
      "episode 2, policy loss -0.14144457876682281\n",
      "\n",
      "episode 3, policy loss -0.14419624209403992\n",
      "\n",
      "episode 4, policy loss -0.10950499773025513\n",
      "\n",
      "episode 5, policy loss -0.08969227224588394\n",
      "\n",
      "episode 6, policy loss -0.10575249046087265\n",
      "\n",
      "episode 7, policy loss -0.10437528789043427\n",
      "\n",
      "episode 8, policy loss -0.08041594922542572\n",
      "\n",
      "episode 9, policy loss -0.10271982103586197\n",
      "\n",
      "episode 10, policy loss -0.11494162678718567\n",
      "\n",
      "episode 11, policy loss -0.13696807622909546\n",
      "\n",
      "episode 12, policy loss -0.0783156082034111\n",
      "\n",
      "episode 13, policy loss -0.11880524456501007\n",
      "\n",
      "episode 14, policy loss -0.18075186014175415\n",
      "\n",
      "episode 15, policy loss -0.07893245667219162\n",
      "\n",
      "episode 16, policy loss -0.10460518300533295\n",
      "\n",
      "Policy train loss in epoch 1:-0.11181779578328133\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.10343372076749802\n",
      "\n",
      "episode 2, policy loss -0.14244744181632996\n",
      "\n",
      "episode 3, policy loss -0.09231392294168472\n",
      "\n",
      "episode 4, policy loss -0.13643698394298553\n",
      "\n",
      "episode 5, policy loss -0.10160370171070099\n",
      "\n",
      "episode 6, policy loss -0.1172424852848053\n",
      "\n",
      "episode 7, policy loss -0.0821664035320282\n",
      "\n",
      "episode 8, policy loss -0.10112091153860092\n",
      "\n",
      "episode 9, policy loss -0.17985907196998596\n",
      "\n",
      "episode 10, policy loss -0.10141035914421082\n",
      "\n",
      "episode 11, policy loss -0.08242015540599823\n",
      "\n",
      "episode 12, policy loss -0.1155739352107048\n",
      "\n",
      "episode 13, policy loss -0.07828714698553085\n",
      "\n",
      "episode 14, policy loss -0.09781612455844879\n",
      "\n",
      "episode 15, policy loss -0.13699206709861755\n",
      "\n",
      "episode 16, policy loss -0.11097250133752823\n",
      "\n",
      "Policy train loss in epoch 2:-0.11125605832785368\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.11583787202835083\n",
      "\n",
      "episode 2, policy loss -0.07738789916038513\n",
      "\n",
      "episode 3, policy loss -0.08150035887956619\n",
      "\n",
      "episode 4, policy loss -0.13813036680221558\n",
      "\n",
      "episode 5, policy loss -0.09846171736717224\n",
      "\n",
      "episode 6, policy loss -0.08024745434522629\n",
      "\n",
      "episode 7, policy loss -0.11806188523769379\n",
      "\n",
      "episode 8, policy loss -0.08760146796703339\n",
      "\n",
      "episode 9, policy loss -0.09575062245130539\n",
      "\n",
      "episode 10, policy loss -0.1818976104259491\n",
      "\n",
      "episode 11, policy loss -0.10369382798671722\n",
      "\n",
      "episode 12, policy loss -0.098142609000206\n",
      "\n",
      "episode 13, policy loss -0.13985277712345123\n",
      "\n",
      "episode 14, policy loss -0.1067027747631073\n",
      "\n",
      "episode 15, policy loss -0.11510159820318222\n",
      "\n",
      "episode 16, policy loss -0.14911232888698578\n",
      "\n",
      "Policy train loss in epoch 3:-0.11171769816428423\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17870119214057922\n",
      "\n",
      "episode 2, val func loss 0.1529271900653839\n",
      "\n",
      "episode 3, val func loss 0.12584415078163147\n",
      "\n",
      "episode 4, val func loss 0.10423238575458527\n",
      "\n",
      "episode 5, val func loss 0.11256253719329834\n",
      "\n",
      "episode 6, val func loss 0.12860248982906342\n",
      "\n",
      "episode 7, val func loss 0.13174384832382202\n",
      "\n",
      "episode 8, val func loss 0.08046752959489822\n",
      "\n",
      "episode 9, val func loss 0.12378968298435211\n",
      "\n",
      "episode 10, val func loss 0.12515553832054138\n",
      "\n",
      "episode 11, val func loss 0.08778256922960281\n",
      "\n",
      "episode 12, val func loss 0.14230546355247498\n",
      "\n",
      "episode 13, val func loss 0.1781320869922638\n",
      "\n",
      "episode 14, val func loss 0.12633146345615387\n",
      "\n",
      "episode 15, val func loss 0.10981089621782303\n",
      "\n",
      "episode 16, val func loss 0.16002385318279266\n",
      "\n",
      "Val func train loss in epoch 0:0.12927580485120416\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.12614043056964874\n",
      "\n",
      "episode 2, val func loss 0.17613612115383148\n",
      "\n",
      "episode 3, val func loss 0.12291879206895828\n",
      "\n",
      "episode 4, val func loss 0.1418662667274475\n",
      "\n",
      "episode 5, val func loss 0.1343761384487152\n",
      "\n",
      "episode 6, val func loss 0.10947436839342117\n",
      "\n",
      "episode 7, val func loss 0.1536538302898407\n",
      "\n",
      "episode 8, val func loss 0.12567153573036194\n",
      "\n",
      "episode 9, val func loss 0.08968675881624222\n",
      "\n",
      "episode 10, val func loss 0.10274051874876022\n",
      "\n",
      "episode 11, val func loss 0.13071706891059875\n",
      "\n",
      "episode 12, val func loss 0.13099795579910278\n",
      "\n",
      "episode 13, val func loss 0.11169195175170898\n",
      "\n",
      "episode 14, val func loss 0.17554712295532227\n",
      "\n",
      "episode 15, val func loss 0.08324103057384491\n",
      "\n",
      "episode 16, val func loss 0.16027912497520447\n",
      "\n",
      "Val func train loss in epoch 1:0.1296961884945631\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.10394513607025146\n",
      "\n",
      "episode 2, val func loss 0.08206772804260254\n",
      "\n",
      "episode 3, val func loss 0.14217329025268555\n",
      "\n",
      "episode 4, val func loss 0.1251664012670517\n",
      "\n",
      "episode 5, val func loss 0.11180606484413147\n",
      "\n",
      "episode 6, val func loss 0.12458302080631256\n",
      "\n",
      "episode 7, val func loss 0.15994907915592194\n",
      "\n",
      "episode 8, val func loss 0.1322803795337677\n",
      "\n",
      "episode 9, val func loss 0.11004086583852768\n",
      "\n",
      "episode 10, val func loss 0.1773875504732132\n",
      "\n",
      "episode 11, val func loss 0.12485255300998688\n",
      "\n",
      "episode 12, val func loss 0.12379047274589539\n",
      "\n",
      "episode 13, val func loss 0.17596201598644257\n",
      "\n",
      "episode 14, val func loss 0.12910319864749908\n",
      "\n",
      "episode 15, val func loss 0.09036559611558914\n",
      "\n",
      "episode 16, val func loss 0.15312930941581726\n",
      "\n",
      "Val func train loss in epoch 2:0.129162666387856\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.13058659434318542\n",
      "\n",
      "episode 2, val func loss 0.10277347266674042\n",
      "\n",
      "episode 3, val func loss 0.12936364114284515\n",
      "\n",
      "episode 4, val func loss 0.15920226275920868\n",
      "\n",
      "episode 5, val func loss 0.13360542058944702\n",
      "\n",
      "episode 6, val func loss 0.11078497022390366\n",
      "\n",
      "episode 7, val func loss 0.08821837604045868\n",
      "\n",
      "episode 8, val func loss 0.12523159384727478\n",
      "\n",
      "episode 9, val func loss 0.15393897891044617\n",
      "\n",
      "episode 10, val func loss 0.11153163015842438\n",
      "\n",
      "episode 11, val func loss 0.12544922530651093\n",
      "\n",
      "episode 12, val func loss 0.08185748755931854\n",
      "\n",
      "episode 13, val func loss 0.14279745519161224\n",
      "\n",
      "episode 14, val func loss 0.18291975557804108\n",
      "\n",
      "episode 15, val func loss 0.12421384453773499\n",
      "\n",
      "episode 16, val func loss 0.17658597230911255\n",
      "\n",
      "Val func train loss in epoch 3:0.12994129257276654\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.14426469802856445\n",
      "\n",
      "episode 2, val func loss 0.1324993073940277\n",
      "\n",
      "episode 3, val func loss 0.10271663218736649\n",
      "\n",
      "episode 4, val func loss 0.18392223119735718\n",
      "\n",
      "episode 5, val func loss 0.17755264043807983\n",
      "\n",
      "episode 6, val func loss 0.12401437759399414\n",
      "\n",
      "episode 7, val func loss 0.12416242808103561\n",
      "\n",
      "episode 8, val func loss 0.15773358941078186\n",
      "\n",
      "episode 9, val func loss 0.12597733736038208\n",
      "\n",
      "episode 10, val func loss 0.16434399783611298\n",
      "\n",
      "episode 11, val func loss 0.08178353309631348\n",
      "\n",
      "episode 12, val func loss 0.11139177531003952\n",
      "\n",
      "episode 13, val func loss 0.12919564545154572\n",
      "\n",
      "episode 14, val func loss 0.08904608339071274\n",
      "\n",
      "episode 15, val func loss 0.1229819655418396\n",
      "\n",
      "episode 16, val func loss 0.11077040433883667\n",
      "\n",
      "Val func train loss in epoch 4:0.13014729041606188\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1525694578886032\n",
      "\n",
      "episode 2, val func loss 0.12943118810653687\n",
      "\n",
      "episode 3, val func loss 0.16043011844158173\n",
      "\n",
      "episode 4, val func loss 0.11180496215820312\n",
      "\n",
      "episode 5, val func loss 0.1740485280752182\n",
      "\n",
      "episode 6, val func loss 0.1122865080833435\n",
      "\n",
      "episode 7, val func loss 0.12753956019878387\n",
      "\n",
      "episode 8, val func loss 0.09108174592256546\n",
      "\n",
      "episode 9, val func loss 0.10275176167488098\n",
      "\n",
      "episode 10, val func loss 0.12725882232189178\n",
      "\n",
      "episode 11, val func loss 0.14261111617088318\n",
      "\n",
      "episode 12, val func loss 0.12698781490325928\n",
      "\n",
      "episode 13, val func loss 0.12264005094766617\n",
      "\n",
      "episode 14, val func loss 0.08173588663339615\n",
      "\n",
      "episode 15, val func loss 0.17622160911560059\n",
      "\n",
      "episode 16, val func loss 0.13207188248634338\n",
      "\n",
      "Val func train loss in epoch 5:0.12946693832054734\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1755412220954895\n",
      "\n",
      "episode 2, val func loss 0.11216505616903305\n",
      "\n",
      "episode 3, val func loss 0.10410269349813461\n",
      "\n",
      "episode 4, val func loss 0.11015009135007858\n",
      "\n",
      "episode 5, val func loss 0.08127445727586746\n",
      "\n",
      "episode 6, val func loss 0.13028991222381592\n",
      "\n",
      "episode 7, val func loss 0.12735125422477722\n",
      "\n",
      "episode 8, val func loss 0.16072978079319\n",
      "\n",
      "episode 9, val func loss 0.12422577291727066\n",
      "\n",
      "episode 10, val func loss 0.13232380151748657\n",
      "\n",
      "episode 11, val func loss 0.17572957277297974\n",
      "\n",
      "episode 12, val func loss 0.12184064835309982\n",
      "\n",
      "episode 13, val func loss 0.08979111164808273\n",
      "\n",
      "episode 14, val func loss 0.12440314888954163\n",
      "\n",
      "episode 15, val func loss 0.1428488940000534\n",
      "\n",
      "episode 16, val func loss 0.15304450690746307\n",
      "\n",
      "Val func train loss in epoch 6:0.12911324528977275\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.12781061232089996\n",
      "\n",
      "episode 2, val func loss 0.08862096816301346\n",
      "\n",
      "episode 3, val func loss 0.11018842458724976\n",
      "\n",
      "episode 4, val func loss 0.1530287265777588\n",
      "\n",
      "episode 5, val func loss 0.17779342830181122\n",
      "\n",
      "episode 6, val func loss 0.17649024724960327\n",
      "\n",
      "episode 7, val func loss 0.10437572002410889\n",
      "\n",
      "episode 8, val func loss 0.1124848946928978\n",
      "\n",
      "episode 9, val func loss 0.1258348822593689\n",
      "\n",
      "episode 10, val func loss 0.1294049769639969\n",
      "\n",
      "episode 11, val func loss 0.08188647776842117\n",
      "\n",
      "episode 12, val func loss 0.12177684158086777\n",
      "\n",
      "episode 13, val func loss 0.12568432092666626\n",
      "\n",
      "episode 14, val func loss 0.14216731488704681\n",
      "\n",
      "episode 15, val func loss 0.16201338171958923\n",
      "\n",
      "episode 16, val func loss 0.13093717396259308\n",
      "\n",
      "Val func train loss in epoch 7:0.12940614949911833\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.12212363630533218\n",
      "\n",
      "episode 2, val func loss 0.1103479340672493\n",
      "\n",
      "episode 3, val func loss 0.12470478564500809\n",
      "\n",
      "episode 4, val func loss 0.1290108561515808\n",
      "\n",
      "episode 5, val func loss 0.1528969705104828\n",
      "\n",
      "episode 6, val func loss 0.12633059918880463\n",
      "\n",
      "episode 7, val func loss 0.11116573214530945\n",
      "\n",
      "episode 8, val func loss 0.08914761245250702\n",
      "\n",
      "episode 9, val func loss 0.1769137978553772\n",
      "\n",
      "episode 10, val func loss 0.13126593828201294\n",
      "\n",
      "episode 11, val func loss 0.1031005010008812\n",
      "\n",
      "episode 12, val func loss 0.12503479421138763\n",
      "\n",
      "episode 13, val func loss 0.08073914796113968\n",
      "\n",
      "episode 14, val func loss 0.1422818899154663\n",
      "\n",
      "episode 15, val func loss 0.16334153711795807\n",
      "\n",
      "episode 16, val func loss 0.1804363876581192\n",
      "\n",
      "Val func train loss in epoch 8:0.12930263252928853\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1099383756518364\n",
      "\n",
      "episode 2, val func loss 0.175805926322937\n",
      "\n",
      "episode 3, val func loss 0.08387413620948792\n",
      "\n",
      "episode 4, val func loss 0.09292451292276382\n",
      "\n",
      "episode 5, val func loss 0.14498600363731384\n",
      "\n",
      "episode 6, val func loss 0.12481345236301422\n",
      "\n",
      "episode 7, val func loss 0.12926237285137177\n",
      "\n",
      "episode 8, val func loss 0.1791667491197586\n",
      "\n",
      "episode 9, val func loss 0.16052629053592682\n",
      "\n",
      "episode 10, val func loss 0.12443314492702484\n",
      "\n",
      "episode 11, val func loss 0.1027129739522934\n",
      "\n",
      "episode 12, val func loss 0.12179111689329147\n",
      "\n",
      "episode 13, val func loss 0.1119365468621254\n",
      "\n",
      "episode 14, val func loss 0.12639835476875305\n",
      "\n",
      "episode 15, val func loss 0.1313091367483139\n",
      "\n",
      "episode 16, val func loss 0.15389667451381683\n",
      "\n",
      "Val func train loss in epoch 9:0.12961098551750183\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.11118902266025543\n",
      "\n",
      "episode 2, val func loss 0.1771325320005417\n",
      "\n",
      "episode 3, val func loss 0.08891050517559052\n",
      "\n",
      "episode 4, val func loss 0.12927837669849396\n",
      "\n",
      "episode 5, val func loss 0.12538371980190277\n",
      "\n",
      "episode 6, val func loss 0.12157750129699707\n",
      "\n",
      "episode 7, val func loss 0.17781728506088257\n",
      "\n",
      "episode 8, val func loss 0.0812014639377594\n",
      "\n",
      "episode 9, val func loss 0.10329587012529373\n",
      "\n",
      "episode 10, val func loss 0.12516553699970245\n",
      "\n",
      "episode 11, val func loss 0.15382711589336395\n",
      "\n",
      "episode 12, val func loss 0.15956296026706696\n",
      "\n",
      "episode 13, val func loss 0.14372068643569946\n",
      "\n",
      "episode 14, val func loss 0.1321074515581131\n",
      "\n",
      "episode 15, val func loss 0.11007767170667648\n",
      "\n",
      "episode 16, val func loss 0.12344355136156082\n",
      "\n",
      "Val func train loss in epoch 10:0.12898070318624377\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.14206714928150177\n",
      "\n",
      "episode 2, val func loss 0.08061439543962479\n",
      "\n",
      "episode 3, val func loss 0.13132251799106598\n",
      "\n",
      "episode 4, val func loss 0.12279840558767319\n",
      "\n",
      "episode 5, val func loss 0.180372953414917\n",
      "\n",
      "episode 6, val func loss 0.12770657241344452\n",
      "\n",
      "episode 7, val func loss 0.1288978010416031\n",
      "\n",
      "episode 8, val func loss 0.15941062569618225\n",
      "\n",
      "episode 9, val func loss 0.17249280214309692\n",
      "\n",
      "episode 10, val func loss 0.10780351608991623\n",
      "\n",
      "episode 11, val func loss 0.16168099641799927\n",
      "\n",
      "episode 12, val func loss 0.0968097597360611\n",
      "\n",
      "episode 13, val func loss 0.11234018951654434\n",
      "\n",
      "episode 14, val func loss 0.12498234212398529\n",
      "\n",
      "episode 15, val func loss 0.12476199865341187\n",
      "\n",
      "episode 16, val func loss 0.11225733906030655\n",
      "\n",
      "Val func train loss in epoch 11:0.13039496028795838\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.11331269145011902\n",
      "\n",
      "episode 2, val func loss 0.12562865018844604\n",
      "\n",
      "episode 3, val func loss 0.12717193365097046\n",
      "\n",
      "episode 4, val func loss 0.13356108963489532\n",
      "\n",
      "episode 5, val func loss 0.12426119297742844\n",
      "\n",
      "episode 6, val func loss 0.11018537729978561\n",
      "\n",
      "episode 7, val func loss 0.08932370692491531\n",
      "\n",
      "episode 8, val func loss 0.1325315237045288\n",
      "\n",
      "episode 9, val func loss 0.17569704353809357\n",
      "\n",
      "episode 10, val func loss 0.12488365173339844\n",
      "\n",
      "episode 11, val func loss 0.16012799739837646\n",
      "\n",
      "episode 12, val func loss 0.14631377160549164\n",
      "\n",
      "episode 13, val func loss 0.15575936436653137\n",
      "\n",
      "episode 14, val func loss 0.10435662418603897\n",
      "\n",
      "episode 15, val func loss 0.17603148519992828\n",
      "\n",
      "episode 16, val func loss 0.0809314027428627\n",
      "\n",
      "Val func train loss in epoch 12:0.13000484416261315\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1029171273112297\n",
      "\n",
      "episode 2, val func loss 0.12271066755056381\n",
      "\n",
      "episode 3, val func loss 0.13116756081581116\n",
      "\n",
      "episode 4, val func loss 0.14203859865665436\n",
      "\n",
      "episode 5, val func loss 0.11022206395864487\n",
      "\n",
      "episode 6, val func loss 0.12384004145860672\n",
      "\n",
      "episode 7, val func loss 0.08051765710115433\n",
      "\n",
      "episode 8, val func loss 0.17792801558971405\n",
      "\n",
      "episode 9, val func loss 0.1524725705385208\n",
      "\n",
      "episode 10, val func loss 0.17719128727912903\n",
      "\n",
      "episode 11, val func loss 0.1325174868106842\n",
      "\n",
      "episode 12, val func loss 0.11190078407526016\n",
      "\n",
      "episode 13, val func loss 0.12623350322246552\n",
      "\n",
      "episode 14, val func loss 0.1597176194190979\n",
      "\n",
      "episode 15, val func loss 0.09121651202440262\n",
      "\n",
      "episode 16, val func loss 0.12438061088323593\n",
      "\n",
      "Val func train loss in epoch 13:0.12918575666844845\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1251472383737564\n",
      "\n",
      "episode 2, val func loss 0.124615877866745\n",
      "\n",
      "episode 3, val func loss 0.17644648253917694\n",
      "\n",
      "episode 4, val func loss 0.1429685801267624\n",
      "\n",
      "episode 5, val func loss 0.1317395567893982\n",
      "\n",
      "episode 6, val func loss 0.17842404544353485\n",
      "\n",
      "episode 7, val func loss 0.12928004562854767\n",
      "\n",
      "episode 8, val func loss 0.1122259721159935\n",
      "\n",
      "episode 9, val func loss 0.08207378536462784\n",
      "\n",
      "episode 10, val func loss 0.12461303174495697\n",
      "\n",
      "episode 11, val func loss 0.08953581005334854\n",
      "\n",
      "episode 12, val func loss 0.10978591442108154\n",
      "\n",
      "episode 13, val func loss 0.16197113692760468\n",
      "\n",
      "episode 14, val func loss 0.152598038315773\n",
      "\n",
      "episode 15, val func loss 0.12255223095417023\n",
      "\n",
      "episode 16, val func loss 0.10306082665920258\n",
      "\n",
      "Val func train loss in epoch 14:0.12918991083279252\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.08035681396722794\n",
      "\n",
      "episode 2, val func loss 0.15218354761600494\n",
      "\n",
      "episode 3, val func loss 0.18076197803020477\n",
      "\n",
      "episode 4, val func loss 0.13096465170383453\n",
      "\n",
      "episode 5, val func loss 0.1224558874964714\n",
      "\n",
      "episode 6, val func loss 0.12497308105230331\n",
      "\n",
      "episode 7, val func loss 0.11025340110063553\n",
      "\n",
      "episode 8, val func loss 0.14340345561504364\n",
      "\n",
      "episode 9, val func loss 0.10291856527328491\n",
      "\n",
      "episode 10, val func loss 0.15983808040618896\n",
      "\n",
      "episode 11, val func loss 0.08901803195476532\n",
      "\n",
      "episode 12, val func loss 0.12649016082286835\n",
      "\n",
      "episode 13, val func loss 0.12986528873443604\n",
      "\n",
      "episode 14, val func loss 0.11202511936426163\n",
      "\n",
      "episode 15, val func loss 0.17724697291851044\n",
      "\n",
      "episode 16, val func loss 0.12451467663049698\n",
      "\n",
      "Val func train loss in epoch 15:0.12920435704290867\n",
      "***********************TIME WAS 5.207891452312469 min*****************************\n",
      "\n",
      "**********************ROUND 18 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.06999699771404266\n",
      "\n",
      "episode 2, policy loss -0.13810524344444275\n",
      "\n",
      "episode 3, policy loss -0.1036490648984909\n",
      "\n",
      "episode 4, policy loss -0.09549083560705185\n",
      "\n",
      "episode 5, policy loss -0.0790071040391922\n",
      "\n",
      "episode 6, policy loss -0.11031533777713776\n",
      "\n",
      "episode 7, policy loss -0.13464829325675964\n",
      "\n",
      "episode 8, policy loss -0.12445902824401855\n",
      "\n",
      "episode 9, policy loss -0.07202724367380142\n",
      "\n",
      "episode 10, policy loss -0.0985843688249588\n",
      "\n",
      "episode 11, policy loss -0.11350296437740326\n",
      "\n",
      "episode 12, policy loss -0.11322010308504105\n",
      "\n",
      "episode 13, policy loss -0.09056617319583893\n",
      "\n",
      "episode 14, policy loss -0.10479629039764404\n",
      "\n",
      "episode 15, policy loss -0.08052435517311096\n",
      "\n",
      "episode 16, policy loss -0.15830138325691223\n",
      "\n",
      "Policy train loss in epoch 0:-0.10544967418536544\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.1252516359090805\n",
      "\n",
      "episode 2, policy loss -0.09874647110700607\n",
      "\n",
      "episode 3, policy loss -0.1381782442331314\n",
      "\n",
      "episode 4, policy loss -0.06855450570583344\n",
      "\n",
      "episode 5, policy loss -0.07815111428499222\n",
      "\n",
      "episode 6, policy loss -0.09138711541891098\n",
      "\n",
      "episode 7, policy loss -0.10966745764017105\n",
      "\n",
      "episode 8, policy loss -0.07146334648132324\n",
      "\n",
      "episode 9, policy loss -0.15861186385154724\n",
      "\n",
      "episode 10, policy loss -0.13665500283241272\n",
      "\n",
      "episode 11, policy loss -0.11257725954055786\n",
      "\n",
      "episode 12, policy loss -0.11311355233192444\n",
      "\n",
      "episode 13, policy loss -0.11041007190942764\n",
      "\n",
      "episode 14, policy loss -0.09977219998836517\n",
      "\n",
      "episode 15, policy loss -0.081343874335289\n",
      "\n",
      "episode 16, policy loss -0.1132078468799591\n",
      "\n",
      "Policy train loss in epoch 1:-0.10669322265312076\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.07903475314378738\n",
      "\n",
      "episode 2, policy loss -0.1312446892261505\n",
      "\n",
      "episode 3, policy loss -0.13972140848636627\n",
      "\n",
      "episode 4, policy loss -0.10018178820610046\n",
      "\n",
      "episode 5, policy loss -0.07419297099113464\n",
      "\n",
      "episode 6, policy loss -0.12682169675827026\n",
      "\n",
      "episode 7, policy loss -0.07296226918697357\n",
      "\n",
      "episode 8, policy loss -0.10990222543478012\n",
      "\n",
      "episode 9, policy loss -0.09818531572818756\n",
      "\n",
      "episode 10, policy loss -0.11424185335636139\n",
      "\n",
      "episode 11, policy loss -0.11316347122192383\n",
      "\n",
      "episode 12, policy loss -0.11837084591388702\n",
      "\n",
      "episode 13, policy loss -0.15798339247703552\n",
      "\n",
      "episode 14, policy loss -0.0826316773891449\n",
      "\n",
      "episode 15, policy loss -0.11138699948787689\n",
      "\n",
      "episode 16, policy loss -0.09132321923971176\n",
      "\n",
      "Policy train loss in epoch 2:-0.10758428601548076\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.13650211691856384\n",
      "\n",
      "episode 2, policy loss -0.07578974962234497\n",
      "\n",
      "episode 3, policy loss -0.09168706834316254\n",
      "\n",
      "episode 4, policy loss -0.11249815672636032\n",
      "\n",
      "episode 5, policy loss -0.06960555911064148\n",
      "\n",
      "episode 6, policy loss -0.10672662407159805\n",
      "\n",
      "episode 7, policy loss -0.11362344026565552\n",
      "\n",
      "episode 8, policy loss -0.1102353036403656\n",
      "\n",
      "episode 9, policy loss -0.14020630717277527\n",
      "\n",
      "episode 10, policy loss -0.10255032777786255\n",
      "\n",
      "episode 11, policy loss -0.14625829458236694\n",
      "\n",
      "episode 12, policy loss -0.08100507408380508\n",
      "\n",
      "episode 13, policy loss -0.10875476896762848\n",
      "\n",
      "episode 14, policy loss -0.09735094755887985\n",
      "\n",
      "episode 15, policy loss -0.06901995092630386\n",
      "\n",
      "episode 16, policy loss -0.12109158933162689\n",
      "\n",
      "Policy train loss in epoch 3:-0.10518157994374633\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17178204655647278\n",
      "\n",
      "episode 2, val func loss 0.15134653449058533\n",
      "\n",
      "episode 3, val func loss 0.16320806741714478\n",
      "\n",
      "episode 4, val func loss 0.1492285579442978\n",
      "\n",
      "episode 5, val func loss 0.1199580579996109\n",
      "\n",
      "episode 6, val func loss 0.2019231617450714\n",
      "\n",
      "episode 7, val func loss 0.15347208082675934\n",
      "\n",
      "episode 8, val func loss 0.13946880400180817\n",
      "\n",
      "episode 9, val func loss 0.15066830813884735\n",
      "\n",
      "episode 10, val func loss 0.1507214605808258\n",
      "\n",
      "episode 11, val func loss 0.12725743651390076\n",
      "\n",
      "episode 12, val func loss 0.08848806470632553\n",
      "\n",
      "episode 13, val func loss 0.14119456708431244\n",
      "\n",
      "episode 14, val func loss 0.179077610373497\n",
      "\n",
      "episode 15, val func loss 0.1209755688905716\n",
      "\n",
      "episode 16, val func loss 0.09096480906009674\n",
      "\n",
      "Val func train loss in epoch 0:0.14373344602063298\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.14916905760765076\n",
      "\n",
      "episode 2, val func loss 0.09158508479595184\n",
      "\n",
      "episode 3, val func loss 0.12103231996297836\n",
      "\n",
      "episode 4, val func loss 0.15664801001548767\n",
      "\n",
      "episode 5, val func loss 0.17071914672851562\n",
      "\n",
      "episode 6, val func loss 0.12050514668226242\n",
      "\n",
      "episode 7, val func loss 0.20083552598953247\n",
      "\n",
      "episode 8, val func loss 0.092059426009655\n",
      "\n",
      "episode 9, val func loss 0.16406986117362976\n",
      "\n",
      "episode 10, val func loss 0.18191516399383545\n",
      "\n",
      "episode 11, val func loss 0.15137943625450134\n",
      "\n",
      "episode 12, val func loss 0.14873795211315155\n",
      "\n",
      "episode 13, val func loss 0.14073801040649414\n",
      "\n",
      "episode 14, val func loss 0.15064387023448944\n",
      "\n",
      "episode 15, val func loss 0.1455821990966797\n",
      "\n",
      "episode 16, val func loss 0.12118375301361084\n",
      "\n",
      "Val func train loss in epoch 1:0.14417524775490165\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.14682064950466156\n",
      "\n",
      "episode 2, val func loss 0.09164232015609741\n",
      "\n",
      "episode 3, val func loss 0.20316699147224426\n",
      "\n",
      "episode 4, val func loss 0.1212795302271843\n",
      "\n",
      "episode 5, val func loss 0.16166067123413086\n",
      "\n",
      "episode 6, val func loss 0.1251354068517685\n",
      "\n",
      "episode 7, val func loss 0.08848822861909866\n",
      "\n",
      "episode 8, val func loss 0.11767211556434631\n",
      "\n",
      "episode 9, val func loss 0.15287619829177856\n",
      "\n",
      "episode 10, val func loss 0.1500411331653595\n",
      "\n",
      "episode 11, val func loss 0.1547098606824875\n",
      "\n",
      "episode 12, val func loss 0.17861685156822205\n",
      "\n",
      "episode 13, val func loss 0.14152386784553528\n",
      "\n",
      "episode 14, val func loss 0.17138387262821198\n",
      "\n",
      "episode 15, val func loss 0.14152087271213531\n",
      "\n",
      "episode 16, val func loss 0.1477501094341278\n",
      "\n",
      "Val func train loss in epoch 2:0.14339304249733686\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20229433476924896\n",
      "\n",
      "episode 2, val func loss 0.12237714976072311\n",
      "\n",
      "episode 3, val func loss 0.16253432631492615\n",
      "\n",
      "episode 4, val func loss 0.1410226970911026\n",
      "\n",
      "episode 5, val func loss 0.0910123661160469\n",
      "\n",
      "episode 6, val func loss 0.14753814041614532\n",
      "\n",
      "episode 7, val func loss 0.1501142829656601\n",
      "\n",
      "episode 8, val func loss 0.17196357250213623\n",
      "\n",
      "episode 9, val func loss 0.14284777641296387\n",
      "\n",
      "episode 10, val func loss 0.14957065880298615\n",
      "\n",
      "episode 11, val func loss 0.1472940444946289\n",
      "\n",
      "episode 12, val func loss 0.08951161056756973\n",
      "\n",
      "episode 13, val func loss 0.15300780534744263\n",
      "\n",
      "episode 14, val func loss 0.11839302629232407\n",
      "\n",
      "episode 15, val func loss 0.18177592754364014\n",
      "\n",
      "episode 16, val func loss 0.11995436996221542\n",
      "\n",
      "Val func train loss in epoch 3:0.14320075558498502\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.12668700516223907\n",
      "\n",
      "episode 2, val func loss 0.17942357063293457\n",
      "\n",
      "episode 3, val func loss 0.17142179608345032\n",
      "\n",
      "episode 4, val func loss 0.12302069365978241\n",
      "\n",
      "episode 5, val func loss 0.14919248223304749\n",
      "\n",
      "episode 6, val func loss 0.2026786208152771\n",
      "\n",
      "episode 7, val func loss 0.1417623609304428\n",
      "\n",
      "episode 8, val func loss 0.146946519613266\n",
      "\n",
      "episode 9, val func loss 0.08914943784475327\n",
      "\n",
      "episode 10, val func loss 0.14130908250808716\n",
      "\n",
      "episode 11, val func loss 0.1529703438282013\n",
      "\n",
      "episode 12, val func loss 0.14956146478652954\n",
      "\n",
      "episode 13, val func loss 0.16260714828968048\n",
      "\n",
      "episode 14, val func loss 0.09190341085195541\n",
      "\n",
      "episode 15, val func loss 0.14842908084392548\n",
      "\n",
      "episode 16, val func loss 0.12150074541568756\n",
      "\n",
      "Val func train loss in epoch 4:0.14366023521870375\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.15583695471286774\n",
      "\n",
      "episode 2, val func loss 0.1494644582271576\n",
      "\n",
      "episode 3, val func loss 0.1206299364566803\n",
      "\n",
      "episode 4, val func loss 0.13820867240428925\n",
      "\n",
      "episode 5, val func loss 0.16297948360443115\n",
      "\n",
      "episode 6, val func loss 0.17240943014621735\n",
      "\n",
      "episode 7, val func loss 0.09141115844249725\n",
      "\n",
      "episode 8, val func loss 0.14101742208003998\n",
      "\n",
      "episode 9, val func loss 0.1494572013616562\n",
      "\n",
      "episode 10, val func loss 0.15049636363983154\n",
      "\n",
      "episode 11, val func loss 0.09020637720823288\n",
      "\n",
      "episode 12, val func loss 0.14647811651229858\n",
      "\n",
      "episode 13, val func loss 0.12279941886663437\n",
      "\n",
      "episode 14, val func loss 0.17860251665115356\n",
      "\n",
      "episode 15, val func loss 0.20249277353286743\n",
      "\n",
      "episode 16, val func loss 0.11926247179508209\n",
      "\n",
      "Val func train loss in epoch 5:0.14323454722762108\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.14984668791294098\n",
      "\n",
      "episode 2, val func loss 0.17983967065811157\n",
      "\n",
      "episode 3, val func loss 0.1533486694097519\n",
      "\n",
      "episode 4, val func loss 0.13855955004692078\n",
      "\n",
      "episode 5, val func loss 0.12085460871458054\n",
      "\n",
      "episode 6, val func loss 0.09281289577484131\n",
      "\n",
      "episode 7, val func loss 0.15211224555969238\n",
      "\n",
      "episode 8, val func loss 0.15388447046279907\n",
      "\n",
      "episode 9, val func loss 0.1232798621058464\n",
      "\n",
      "episode 10, val func loss 0.14803943037986755\n",
      "\n",
      "episode 11, val func loss 0.1255570352077484\n",
      "\n",
      "episode 12, val func loss 0.20699530839920044\n",
      "\n",
      "episode 13, val func loss 0.09114076942205429\n",
      "\n",
      "episode 14, val func loss 0.14099740982055664\n",
      "\n",
      "episode 15, val func loss 0.1626933068037033\n",
      "\n",
      "episode 16, val func loss 0.17324011027812958\n",
      "\n",
      "Val func train loss in epoch 6:0.14457512693479657\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.12578168511390686\n",
      "\n",
      "episode 2, val func loss 0.16191677749156952\n",
      "\n",
      "episode 3, val func loss 0.1537102460861206\n",
      "\n",
      "episode 4, val func loss 0.09108491986989975\n",
      "\n",
      "episode 5, val func loss 0.08902141451835632\n",
      "\n",
      "episode 6, val func loss 0.17890119552612305\n",
      "\n",
      "episode 7, val func loss 0.1714213788509369\n",
      "\n",
      "episode 8, val func loss 0.14143967628479004\n",
      "\n",
      "episode 9, val func loss 0.20210954546928406\n",
      "\n",
      "episode 10, val func loss 0.1476767659187317\n",
      "\n",
      "episode 11, val func loss 0.14714033901691437\n",
      "\n",
      "episode 12, val func loss 0.14181619882583618\n",
      "\n",
      "episode 13, val func loss 0.12070541083812714\n",
      "\n",
      "episode 14, val func loss 0.1510045826435089\n",
      "\n",
      "episode 15, val func loss 0.1492249220609665\n",
      "\n",
      "episode 16, val func loss 0.11901267617940903\n",
      "\n",
      "Val func train loss in epoch 7:0.14324798341840506\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.08920387923717499\n",
      "\n",
      "episode 2, val func loss 0.20096564292907715\n",
      "\n",
      "episode 3, val func loss 0.17181801795959473\n",
      "\n",
      "episode 4, val func loss 0.1252552568912506\n",
      "\n",
      "episode 5, val func loss 0.15297307074069977\n",
      "\n",
      "episode 6, val func loss 0.09193643182516098\n",
      "\n",
      "episode 7, val func loss 0.17904359102249146\n",
      "\n",
      "episode 8, val func loss 0.11823205649852753\n",
      "\n",
      "episode 9, val func loss 0.14704765379428864\n",
      "\n",
      "episode 10, val func loss 0.1627160757780075\n",
      "\n",
      "episode 11, val func loss 0.14627130329608917\n",
      "\n",
      "episode 12, val func loss 0.1499636471271515\n",
      "\n",
      "episode 13, val func loss 0.14077402651309967\n",
      "\n",
      "episode 14, val func loss 0.14168734848499298\n",
      "\n",
      "episode 15, val func loss 0.1507348269224167\n",
      "\n",
      "episode 16, val func loss 0.121025949716568\n",
      "\n",
      "Val func train loss in epoch 8:0.14310304867103696\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.12307213246822357\n",
      "\n",
      "episode 2, val func loss 0.09096667170524597\n",
      "\n",
      "episode 3, val func loss 0.15452592074871063\n",
      "\n",
      "episode 4, val func loss 0.14011678099632263\n",
      "\n",
      "episode 5, val func loss 0.20118756592273712\n",
      "\n",
      "episode 6, val func loss 0.14801588654518127\n",
      "\n",
      "episode 7, val func loss 0.1525120735168457\n",
      "\n",
      "episode 8, val func loss 0.14173990488052368\n",
      "\n",
      "episode 9, val func loss 0.1476992815732956\n",
      "\n",
      "episode 10, val func loss 0.14969204366207123\n",
      "\n",
      "episode 11, val func loss 0.17113716900348663\n",
      "\n",
      "episode 12, val func loss 0.1637524664402008\n",
      "\n",
      "episode 13, val func loss 0.1220390647649765\n",
      "\n",
      "episode 14, val func loss 0.17932970821857452\n",
      "\n",
      "episode 15, val func loss 0.11899473518133163\n",
      "\n",
      "episode 16, val func loss 0.08924201130867004\n",
      "\n",
      "Val func train loss in epoch 9:0.14337646355852485\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.12064345180988312\n",
      "\n",
      "episode 2, val func loss 0.1728120893239975\n",
      "\n",
      "episode 3, val func loss 0.1507350504398346\n",
      "\n",
      "episode 4, val func loss 0.18084371089935303\n",
      "\n",
      "episode 5, val func loss 0.1179841011762619\n",
      "\n",
      "episode 6, val func loss 0.15200814604759216\n",
      "\n",
      "episode 7, val func loss 0.15388181805610657\n",
      "\n",
      "episode 8, val func loss 0.14637263119220734\n",
      "\n",
      "episode 9, val func loss 0.1413004994392395\n",
      "\n",
      "episode 10, val func loss 0.09088589251041412\n",
      "\n",
      "episode 11, val func loss 0.09197565913200378\n",
      "\n",
      "episode 12, val func loss 0.14349836111068726\n",
      "\n",
      "episode 13, val func loss 0.12170536071062088\n",
      "\n",
      "episode 14, val func loss 0.20220637321472168\n",
      "\n",
      "episode 15, val func loss 0.1481594443321228\n",
      "\n",
      "episode 16, val func loss 0.16278696060180664\n",
      "\n",
      "Val func train loss in epoch 10:0.1436124718748033\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.12444742023944855\n",
      "\n",
      "episode 2, val func loss 0.20083321630954742\n",
      "\n",
      "episode 3, val func loss 0.09142521023750305\n",
      "\n",
      "episode 4, val func loss 0.17886357009410858\n",
      "\n",
      "episode 5, val func loss 0.1513693481683731\n",
      "\n",
      "episode 6, val func loss 0.16354332864284515\n",
      "\n",
      "episode 7, val func loss 0.1554979532957077\n",
      "\n",
      "episode 8, val func loss 0.09046196937561035\n",
      "\n",
      "episode 9, val func loss 0.14044469594955444\n",
      "\n",
      "episode 10, val func loss 0.14739757776260376\n",
      "\n",
      "episode 11, val func loss 0.14042921364307404\n",
      "\n",
      "episode 12, val func loss 0.1499483287334442\n",
      "\n",
      "episode 13, val func loss 0.12065396457910538\n",
      "\n",
      "episode 14, val func loss 0.11744339764118195\n",
      "\n",
      "episode 15, val func loss 0.17177200317382812\n",
      "\n",
      "episode 16, val func loss 0.14937081933021545\n",
      "\n",
      "Val func train loss in epoch 11:0.14336887607350945\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.14156538248062134\n",
      "\n",
      "episode 2, val func loss 0.15092837810516357\n",
      "\n",
      "episode 3, val func loss 0.1633347123861313\n",
      "\n",
      "episode 4, val func loss 0.12212546169757843\n",
      "\n",
      "episode 5, val func loss 0.20395933091640472\n",
      "\n",
      "episode 6, val func loss 0.11886590719223022\n",
      "\n",
      "episode 7, val func loss 0.14992426335811615\n",
      "\n",
      "episode 8, val func loss 0.14727914333343506\n",
      "\n",
      "episode 9, val func loss 0.08902562409639359\n",
      "\n",
      "episode 10, val func loss 0.14894738793373108\n",
      "\n",
      "episode 11, val func loss 0.09172036498785019\n",
      "\n",
      "episode 12, val func loss 0.1717327982187271\n",
      "\n",
      "episode 13, val func loss 0.13932952284812927\n",
      "\n",
      "episode 14, val func loss 0.12483131885528564\n",
      "\n",
      "episode 15, val func loss 0.17908205091953278\n",
      "\n",
      "episode 16, val func loss 0.15496401488780975\n",
      "\n",
      "Val func train loss in epoch 12:0.14360097888857126\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.0903908908367157\n",
      "\n",
      "episode 2, val func loss 0.14995430409908295\n",
      "\n",
      "episode 3, val func loss 0.15378600358963013\n",
      "\n",
      "episode 4, val func loss 0.1239575743675232\n",
      "\n",
      "episode 5, val func loss 0.17137615382671356\n",
      "\n",
      "episode 6, val func loss 0.14722763001918793\n",
      "\n",
      "episode 7, val func loss 0.09158666431903839\n",
      "\n",
      "episode 8, val func loss 0.14103949069976807\n",
      "\n",
      "episode 9, val func loss 0.14086583256721497\n",
      "\n",
      "episode 10, val func loss 0.17896339297294617\n",
      "\n",
      "episode 11, val func loss 0.1621517390012741\n",
      "\n",
      "episode 12, val func loss 0.14839813113212585\n",
      "\n",
      "episode 13, val func loss 0.1509397178888321\n",
      "\n",
      "episode 14, val func loss 0.20215970277786255\n",
      "\n",
      "episode 15, val func loss 0.12095209956169128\n",
      "\n",
      "episode 16, val func loss 0.11865099519491196\n",
      "\n",
      "Val func train loss in epoch 13:0.14327502017840743\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1510431319475174\n",
      "\n",
      "episode 2, val func loss 0.14140532910823822\n",
      "\n",
      "episode 3, val func loss 0.14028500020503998\n",
      "\n",
      "episode 4, val func loss 0.14823384582996368\n",
      "\n",
      "episode 5, val func loss 0.17120198905467987\n",
      "\n",
      "episode 6, val func loss 0.12274941056966782\n",
      "\n",
      "episode 7, val func loss 0.17914210259914398\n",
      "\n",
      "episode 8, val func loss 0.1552674025297165\n",
      "\n",
      "episode 9, val func loss 0.12064080685377121\n",
      "\n",
      "episode 10, val func loss 0.14645597338676453\n",
      "\n",
      "episode 11, val func loss 0.11809735000133514\n",
      "\n",
      "episode 12, val func loss 0.16191354393959045\n",
      "\n",
      "episode 13, val func loss 0.15022224187850952\n",
      "\n",
      "episode 14, val func loss 0.09153805673122406\n",
      "\n",
      "episode 15, val func loss 0.08869197964668274\n",
      "\n",
      "episode 16, val func loss 0.2002657800912857\n",
      "\n",
      "Val func train loss in epoch 14:0.14294712152332067\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.14972907304763794\n",
      "\n",
      "episode 2, val func loss 0.1420530080795288\n",
      "\n",
      "episode 3, val func loss 0.1486157774925232\n",
      "\n",
      "episode 4, val func loss 0.17962311208248138\n",
      "\n",
      "episode 5, val func loss 0.15041156113147736\n",
      "\n",
      "episode 6, val func loss 0.14669683575630188\n",
      "\n",
      "episode 7, val func loss 0.12374807894229889\n",
      "\n",
      "episode 8, val func loss 0.20559123158454895\n",
      "\n",
      "episode 9, val func loss 0.12093154340982437\n",
      "\n",
      "episode 10, val func loss 0.14093051850795746\n",
      "\n",
      "episode 11, val func loss 0.17069749534130096\n",
      "\n",
      "episode 12, val func loss 0.16346688568592072\n",
      "\n",
      "episode 13, val func loss 0.15241463482379913\n",
      "\n",
      "episode 14, val func loss 0.08821548521518707\n",
      "\n",
      "episode 15, val func loss 0.09415505081415176\n",
      "\n",
      "episode 16, val func loss 0.13122795522212982\n",
      "\n",
      "Val func train loss in epoch 15:0.14428176544606686\n",
      "***********************TIME WAS 5.233153450489044 min*****************************\n",
      "\n",
      "**********************ROUND 19 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.19886982440948486\n",
      "\n",
      "episode 2, policy loss -0.15781858563423157\n",
      "\n",
      "episode 3, policy loss -0.16063903272151947\n",
      "\n",
      "episode 4, policy loss -0.1121722161769867\n",
      "\n",
      "episode 5, policy loss -0.14632344245910645\n",
      "\n",
      "episode 6, policy loss -0.14948560297489166\n",
      "\n",
      "episode 7, policy loss -0.16365785896778107\n",
      "\n",
      "episode 8, policy loss -0.18121543526649475\n",
      "\n",
      "episode 9, policy loss -0.09912377595901489\n",
      "\n",
      "episode 10, policy loss -0.19362029433250427\n",
      "\n",
      "episode 11, policy loss -0.1271045207977295\n",
      "\n",
      "episode 12, policy loss -0.10395392775535583\n",
      "\n",
      "episode 13, policy loss -0.13404841721057892\n",
      "\n",
      "episode 14, policy loss -0.11028173565864563\n",
      "\n",
      "episode 15, policy loss -0.11900599300861359\n",
      "\n",
      "episode 16, policy loss -0.1317029893398285\n",
      "\n",
      "Policy train loss in epoch 0:-0.14306397829204798\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.136127769947052\n",
      "\n",
      "episode 2, policy loss -0.1924339383840561\n",
      "\n",
      "episode 3, policy loss -0.16220825910568237\n",
      "\n",
      "episode 4, policy loss -0.15010452270507812\n",
      "\n",
      "episode 5, policy loss -0.1829938292503357\n",
      "\n",
      "episode 6, policy loss -0.0981394425034523\n",
      "\n",
      "episode 7, policy loss -0.2041875422000885\n",
      "\n",
      "episode 8, policy loss -0.11804566532373428\n",
      "\n",
      "episode 9, policy loss -0.11419541388750076\n",
      "\n",
      "episode 10, policy loss -0.12622717022895813\n",
      "\n",
      "episode 11, policy loss -0.13695719838142395\n",
      "\n",
      "episode 12, policy loss -0.10392394661903381\n",
      "\n",
      "episode 13, policy loss -0.12741564214229584\n",
      "\n",
      "episode 14, policy loss -0.15952518582344055\n",
      "\n",
      "episode 15, policy loss -0.15782541036605835\n",
      "\n",
      "episode 16, policy loss -0.16598278284072876\n",
      "\n",
      "Policy train loss in epoch 1:-0.14601835748180747\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.13682809472084045\n",
      "\n",
      "episode 2, policy loss -0.11677022278308868\n",
      "\n",
      "episode 3, policy loss -0.12655214965343475\n",
      "\n",
      "episode 4, policy loss -0.1135464757680893\n",
      "\n",
      "episode 5, policy loss -0.18876108527183533\n",
      "\n",
      "episode 6, policy loss -0.2056211233139038\n",
      "\n",
      "episode 7, policy loss -0.15850599110126495\n",
      "\n",
      "episode 8, policy loss -0.10541749000549316\n",
      "\n",
      "episode 9, policy loss -0.1281834989786148\n",
      "\n",
      "episode 10, policy loss -0.15869556367397308\n",
      "\n",
      "episode 11, policy loss -0.15771685540676117\n",
      "\n",
      "episode 12, policy loss -0.13382075726985931\n",
      "\n",
      "episode 13, policy loss -0.16292741894721985\n",
      "\n",
      "episode 14, policy loss -0.15148618817329407\n",
      "\n",
      "episode 15, policy loss -0.18009483814239502\n",
      "\n",
      "episode 16, policy loss -0.10010002553462982\n",
      "\n",
      "Policy train loss in epoch 2:-0.1453142361715436\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.15947791934013367\n",
      "\n",
      "episode 2, policy loss -0.13584685325622559\n",
      "\n",
      "episode 3, policy loss -0.15785130858421326\n",
      "\n",
      "episode 4, policy loss -0.1146385595202446\n",
      "\n",
      "episode 5, policy loss -0.20278963446617126\n",
      "\n",
      "episode 6, policy loss -0.14808344841003418\n",
      "\n",
      "episode 7, policy loss -0.10236231982707977\n",
      "\n",
      "episode 8, policy loss -0.13529396057128906\n",
      "\n",
      "episode 9, policy loss -0.0981697365641594\n",
      "\n",
      "episode 10, policy loss -0.1811128854751587\n",
      "\n",
      "episode 11, policy loss -0.11452944576740265\n",
      "\n",
      "episode 12, policy loss -0.15559394657611847\n",
      "\n",
      "episode 13, policy loss -0.18925422430038452\n",
      "\n",
      "episode 14, policy loss -0.12787123024463654\n",
      "\n",
      "episode 15, policy loss -0.12490945309400558\n",
      "\n",
      "episode 16, policy loss -0.16316848993301392\n",
      "\n",
      "Policy train loss in epoch 3:-0.14443458849564195\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.11138663440942764\n",
      "\n",
      "episode 2, val func loss 0.12773220241069794\n",
      "\n",
      "episode 3, val func loss 0.13959723711013794\n",
      "\n",
      "episode 4, val func loss 0.11284349113702774\n",
      "\n",
      "episode 5, val func loss 0.1591794490814209\n",
      "\n",
      "episode 6, val func loss 0.17113077640533447\n",
      "\n",
      "episode 7, val func loss 0.15730831027030945\n",
      "\n",
      "episode 8, val func loss 0.11536163091659546\n",
      "\n",
      "episode 9, val func loss 0.12443658709526062\n",
      "\n",
      "episode 10, val func loss 0.15136368572711945\n",
      "\n",
      "episode 11, val func loss 0.1420217901468277\n",
      "\n",
      "episode 12, val func loss 0.14134426414966583\n",
      "\n",
      "episode 13, val func loss 0.18631446361541748\n",
      "\n",
      "episode 14, val func loss 0.17520257830619812\n",
      "\n",
      "episode 15, val func loss 0.1350545436143875\n",
      "\n",
      "episode 16, val func loss 0.1078888475894928\n",
      "\n",
      "Val func train loss in epoch 0:0.14113540574908257\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1136222556233406\n",
      "\n",
      "episode 2, val func loss 0.10764004290103912\n",
      "\n",
      "episode 3, val func loss 0.12372424453496933\n",
      "\n",
      "episode 4, val func loss 0.1864153891801834\n",
      "\n",
      "episode 5, val func loss 0.1436990648508072\n",
      "\n",
      "episode 6, val func loss 0.18038193881511688\n",
      "\n",
      "episode 7, val func loss 0.11513853073120117\n",
      "\n",
      "episode 8, val func loss 0.11612743884325027\n",
      "\n",
      "episode 9, val func loss 0.17222753167152405\n",
      "\n",
      "episode 10, val func loss 0.1358899474143982\n",
      "\n",
      "episode 11, val func loss 0.13387198746204376\n",
      "\n",
      "episode 12, val func loss 0.12254343926906586\n",
      "\n",
      "episode 13, val func loss 0.16474637389183044\n",
      "\n",
      "episode 14, val func loss 0.15737052261829376\n",
      "\n",
      "episode 15, val func loss 0.1519196331501007\n",
      "\n",
      "episode 16, val func loss 0.14030636847019196\n",
      "\n",
      "Val func train loss in epoch 1:0.1416015443392098\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.13959044218063354\n",
      "\n",
      "episode 2, val func loss 0.13549943268299103\n",
      "\n",
      "episode 3, val func loss 0.11227098107337952\n",
      "\n",
      "episode 4, val func loss 0.14594247937202454\n",
      "\n",
      "episode 5, val func loss 0.11476324498653412\n",
      "\n",
      "episode 6, val func loss 0.1797083616256714\n",
      "\n",
      "episode 7, val func loss 0.11164692044258118\n",
      "\n",
      "episode 8, val func loss 0.1724551022052765\n",
      "\n",
      "episode 9, val func loss 0.13973930478096008\n",
      "\n",
      "episode 10, val func loss 0.15139687061309814\n",
      "\n",
      "episode 11, val func loss 0.15611062943935394\n",
      "\n",
      "episode 12, val func loss 0.1555825173854828\n",
      "\n",
      "episode 13, val func loss 0.12440592795610428\n",
      "\n",
      "episode 14, val func loss 0.12190470844507217\n",
      "\n",
      "episode 15, val func loss 0.1755654364824295\n",
      "\n",
      "episode 16, val func loss 0.10906526446342468\n",
      "\n",
      "Val func train loss in epoch 2:0.1403529765084386\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.12203234434127808\n",
      "\n",
      "episode 2, val func loss 0.11323454231023788\n",
      "\n",
      "episode 3, val func loss 0.15141403675079346\n",
      "\n",
      "episode 4, val func loss 0.17469331622123718\n",
      "\n",
      "episode 5, val func loss 0.15620025992393494\n",
      "\n",
      "episode 6, val func loss 0.13925309479236603\n",
      "\n",
      "episode 7, val func loss 0.1449679285287857\n",
      "\n",
      "episode 8, val func loss 0.11483994126319885\n",
      "\n",
      "episode 9, val func loss 0.13527502119541168\n",
      "\n",
      "episode 10, val func loss 0.17221438884735107\n",
      "\n",
      "episode 11, val func loss 0.1809147745370865\n",
      "\n",
      "episode 12, val func loss 0.11154557764530182\n",
      "\n",
      "episode 13, val func loss 0.12293555587530136\n",
      "\n",
      "episode 14, val func loss 0.15742063522338867\n",
      "\n",
      "episode 15, val func loss 0.10742142051458359\n",
      "\n",
      "episode 16, val func loss 0.13359037041664124\n",
      "\n",
      "Val func train loss in epoch 3:0.13987207552418113\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.12385712563991547\n",
      "\n",
      "episode 2, val func loss 0.1398051381111145\n",
      "\n",
      "episode 3, val func loss 0.1726432889699936\n",
      "\n",
      "episode 4, val func loss 0.11321385204792023\n",
      "\n",
      "episode 5, val func loss 0.1527528166770935\n",
      "\n",
      "episode 6, val func loss 0.15121912956237793\n",
      "\n",
      "episode 7, val func loss 0.18243750929832458\n",
      "\n",
      "episode 8, val func loss 0.15641821920871735\n",
      "\n",
      "episode 9, val func loss 0.1734633594751358\n",
      "\n",
      "episode 10, val func loss 0.14354899525642395\n",
      "\n",
      "episode 11, val func loss 0.12314430624246597\n",
      "\n",
      "episode 12, val func loss 0.1338060349225998\n",
      "\n",
      "episode 13, val func loss 0.11510871350765228\n",
      "\n",
      "episode 14, val func loss 0.11355645209550858\n",
      "\n",
      "episode 15, val func loss 0.1365588754415512\n",
      "\n",
      "episode 16, val func loss 0.10779736191034317\n",
      "\n",
      "Val func train loss in epoch 4:0.13995819864794612\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18067368865013123\n",
      "\n",
      "episode 2, val func loss 0.17109808325767517\n",
      "\n",
      "episode 3, val func loss 0.11533021181821823\n",
      "\n",
      "episode 4, val func loss 0.11300638318061829\n",
      "\n",
      "episode 5, val func loss 0.1119917631149292\n",
      "\n",
      "episode 6, val func loss 0.15645663440227509\n",
      "\n",
      "episode 7, val func loss 0.13908429443836212\n",
      "\n",
      "episode 8, val func loss 0.1251814216375351\n",
      "\n",
      "episode 9, val func loss 0.13592590391635895\n",
      "\n",
      "episode 10, val func loss 0.10831756144762039\n",
      "\n",
      "episode 11, val func loss 0.15140150487422943\n",
      "\n",
      "episode 12, val func loss 0.12401722371578217\n",
      "\n",
      "episode 13, val func loss 0.13511531054973602\n",
      "\n",
      "episode 14, val func loss 0.17213930189609528\n",
      "\n",
      "episode 15, val func loss 0.1548692137002945\n",
      "\n",
      "episode 16, val func loss 0.14432159066200256\n",
      "\n",
      "Val func train loss in epoch 5:0.13993313070386648\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.12223417311906815\n",
      "\n",
      "episode 2, val func loss 0.11327758431434631\n",
      "\n",
      "episode 3, val func loss 0.11551172286272049\n",
      "\n",
      "episode 4, val func loss 0.15214557945728302\n",
      "\n",
      "episode 5, val func loss 0.13935159146785736\n",
      "\n",
      "episode 6, val func loss 0.1357181817293167\n",
      "\n",
      "episode 7, val func loss 0.17524637281894684\n",
      "\n",
      "episode 8, val func loss 0.11123312264680862\n",
      "\n",
      "episode 9, val func loss 0.14378628134727478\n",
      "\n",
      "episode 10, val func loss 0.17035701870918274\n",
      "\n",
      "episode 11, val func loss 0.12250500172376633\n",
      "\n",
      "episode 12, val func loss 0.1413058638572693\n",
      "\n",
      "episode 13, val func loss 0.10744699090719223\n",
      "\n",
      "episode 14, val func loss 0.16188181936740875\n",
      "\n",
      "episode 15, val func loss 0.18032366037368774\n",
      "\n",
      "episode 16, val func loss 0.1570976972579956\n",
      "\n",
      "Val func train loss in epoch 6:0.1405889163725078\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1517704427242279\n",
      "\n",
      "episode 2, val func loss 0.11467313021421432\n",
      "\n",
      "episode 3, val func loss 0.13554242253303528\n",
      "\n",
      "episode 4, val func loss 0.12119407206773758\n",
      "\n",
      "episode 5, val func loss 0.11084535717964172\n",
      "\n",
      "episode 6, val func loss 0.17712081968784332\n",
      "\n",
      "episode 7, val func loss 0.1847401112318039\n",
      "\n",
      "episode 8, val func loss 0.17551380395889282\n",
      "\n",
      "episode 9, val func loss 0.1353876143693924\n",
      "\n",
      "episode 10, val func loss 0.1394355446100235\n",
      "\n",
      "episode 11, val func loss 0.15851767361164093\n",
      "\n",
      "episode 12, val func loss 0.11298337578773499\n",
      "\n",
      "episode 13, val func loss 0.14641013741493225\n",
      "\n",
      "episode 14, val func loss 0.1564217507839203\n",
      "\n",
      "episode 15, val func loss 0.1234058141708374\n",
      "\n",
      "episode 16, val func loss 0.1073450967669487\n",
      "\n",
      "Val func train loss in epoch 7:0.1407066979445517\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1344708502292633\n",
      "\n",
      "episode 2, val func loss 0.17386111617088318\n",
      "\n",
      "episode 3, val func loss 0.10786834359169006\n",
      "\n",
      "episode 4, val func loss 0.15462659299373627\n",
      "\n",
      "episode 5, val func loss 0.15641865134239197\n",
      "\n",
      "episode 6, val func loss 0.18031150102615356\n",
      "\n",
      "episode 7, val func loss 0.11245955526828766\n",
      "\n",
      "episode 8, val func loss 0.11483245342969894\n",
      "\n",
      "episode 9, val func loss 0.15111935138702393\n",
      "\n",
      "episode 10, val func loss 0.13948954641819\n",
      "\n",
      "episode 11, val func loss 0.12328507006168365\n",
      "\n",
      "episode 12, val func loss 0.12322023510932922\n",
      "\n",
      "episode 13, val func loss 0.1349780410528183\n",
      "\n",
      "episode 14, val func loss 0.11158227920532227\n",
      "\n",
      "episode 15, val func loss 0.14427298307418823\n",
      "\n",
      "episode 16, val func loss 0.17380695044994354\n",
      "\n",
      "Val func train loss in epoch 8:0.13978772005066276\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.15167343616485596\n",
      "\n",
      "episode 2, val func loss 0.15396468341350555\n",
      "\n",
      "episode 3, val func loss 0.17482559382915497\n",
      "\n",
      "episode 4, val func loss 0.10805190354585648\n",
      "\n",
      "episode 5, val func loss 0.13919250667095184\n",
      "\n",
      "episode 6, val func loss 0.1722763627767563\n",
      "\n",
      "episode 7, val func loss 0.11116846650838852\n",
      "\n",
      "episode 8, val func loss 0.14518418908119202\n",
      "\n",
      "episode 9, val func loss 0.12327349931001663\n",
      "\n",
      "episode 10, val func loss 0.1563422828912735\n",
      "\n",
      "episode 11, val func loss 0.13417614996433258\n",
      "\n",
      "episode 12, val func loss 0.11333350837230682\n",
      "\n",
      "episode 13, val func loss 0.11496707797050476\n",
      "\n",
      "episode 14, val func loss 0.13542570173740387\n",
      "\n",
      "episode 15, val func loss 0.18113300204277039\n",
      "\n",
      "episode 16, val func loss 0.12377674877643585\n",
      "\n",
      "Val func train loss in epoch 9:0.13992281956598163\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.15131857991218567\n",
      "\n",
      "episode 2, val func loss 0.12427960336208344\n",
      "\n",
      "episode 3, val func loss 0.18186764419078827\n",
      "\n",
      "episode 4, val func loss 0.13510899245738983\n",
      "\n",
      "episode 5, val func loss 0.15435940027236938\n",
      "\n",
      "episode 6, val func loss 0.13829532265663147\n",
      "\n",
      "episode 7, val func loss 0.12169655412435532\n",
      "\n",
      "episode 8, val func loss 0.17626163363456726\n",
      "\n",
      "episode 9, val func loss 0.14182355999946594\n",
      "\n",
      "episode 10, val func loss 0.13719040155410767\n",
      "\n",
      "episode 11, val func loss 0.10820747911930084\n",
      "\n",
      "episode 12, val func loss 0.11493194103240967\n",
      "\n",
      "episode 13, val func loss 0.11262696981430054\n",
      "\n",
      "episode 14, val func loss 0.11090964078903198\n",
      "\n",
      "episode 15, val func loss 0.17135918140411377\n",
      "\n",
      "episode 16, val func loss 0.15644654631614685\n",
      "\n",
      "Val func train loss in epoch 10:0.139792715664953\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.135527566075325\n",
      "\n",
      "episode 2, val func loss 0.13398391008377075\n",
      "\n",
      "episode 3, val func loss 0.11546093970537186\n",
      "\n",
      "episode 4, val func loss 0.11302450299263\n",
      "\n",
      "episode 5, val func loss 0.14582586288452148\n",
      "\n",
      "episode 6, val func loss 0.12424688786268234\n",
      "\n",
      "episode 7, val func loss 0.18232789635658264\n",
      "\n",
      "episode 8, val func loss 0.1515239179134369\n",
      "\n",
      "episode 9, val func loss 0.17581117153167725\n",
      "\n",
      "episode 10, val func loss 0.15649773180484772\n",
      "\n",
      "episode 11, val func loss 0.15230076014995575\n",
      "\n",
      "episode 12, val func loss 0.12492449581623077\n",
      "\n",
      "episode 13, val func loss 0.13908526301383972\n",
      "\n",
      "episode 14, val func loss 0.17288798093795776\n",
      "\n",
      "episode 15, val func loss 0.11194787919521332\n",
      "\n",
      "episode 16, val func loss 0.10744883120059967\n",
      "\n",
      "Val func train loss in epoch 11:0.14017659984529018\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.14597053825855255\n",
      "\n",
      "episode 2, val func loss 0.151785746216774\n",
      "\n",
      "episode 3, val func loss 0.10765472054481506\n",
      "\n",
      "episode 4, val func loss 0.12382872402667999\n",
      "\n",
      "episode 5, val func loss 0.11152835935354233\n",
      "\n",
      "episode 6, val func loss 0.13512389361858368\n",
      "\n",
      "episode 7, val func loss 0.11501434445381165\n",
      "\n",
      "episode 8, val func loss 0.1388261467218399\n",
      "\n",
      "episode 9, val func loss 0.11276832967996597\n",
      "\n",
      "episode 10, val func loss 0.1567150354385376\n",
      "\n",
      "episode 11, val func loss 0.1727224439382553\n",
      "\n",
      "episode 12, val func loss 0.13504596054553986\n",
      "\n",
      "episode 13, val func loss 0.12431703507900238\n",
      "\n",
      "episode 14, val func loss 0.1712600290775299\n",
      "\n",
      "episode 15, val func loss 0.1558678299188614\n",
      "\n",
      "episode 16, val func loss 0.18100672960281372\n",
      "\n",
      "Val func train loss in epoch 12:0.13996474165469408\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.13848017156124115\n",
      "\n",
      "episode 2, val func loss 0.14313939213752747\n",
      "\n",
      "episode 3, val func loss 0.1524457037448883\n",
      "\n",
      "episode 4, val func loss 0.1845327764749527\n",
      "\n",
      "episode 5, val func loss 0.11398140341043472\n",
      "\n",
      "episode 6, val func loss 0.15195629000663757\n",
      "\n",
      "episode 7, val func loss 0.13745743036270142\n",
      "\n",
      "episode 8, val func loss 0.17453326284885406\n",
      "\n",
      "episode 9, val func loss 0.11074211448431015\n",
      "\n",
      "episode 10, val func loss 0.10750879347324371\n",
      "\n",
      "episode 11, val func loss 0.16963155567646027\n",
      "\n",
      "episode 12, val func loss 0.1370585858821869\n",
      "\n",
      "episode 13, val func loss 0.15906064212322235\n",
      "\n",
      "episode 14, val func loss 0.12246950715780258\n",
      "\n",
      "episode 15, val func loss 0.13140639662742615\n",
      "\n",
      "episode 16, val func loss 0.11640707403421402\n",
      "\n",
      "Val func train loss in epoch 13:0.14067569375038147\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1396060585975647\n",
      "\n",
      "episode 2, val func loss 0.11089789867401123\n",
      "\n",
      "episode 3, val func loss 0.13759751617908478\n",
      "\n",
      "episode 4, val func loss 0.1153082475066185\n",
      "\n",
      "episode 5, val func loss 0.15246789157390594\n",
      "\n",
      "episode 6, val func loss 0.10791873931884766\n",
      "\n",
      "episode 7, val func loss 0.12442418932914734\n",
      "\n",
      "episode 8, val func loss 0.12383975088596344\n",
      "\n",
      "episode 9, val func loss 0.1341288983821869\n",
      "\n",
      "episode 10, val func loss 0.15702256560325623\n",
      "\n",
      "episode 11, val func loss 0.11493989825248718\n",
      "\n",
      "episode 12, val func loss 0.1707535684108734\n",
      "\n",
      "episode 13, val func loss 0.15751811861991882\n",
      "\n",
      "episode 14, val func loss 0.14566200971603394\n",
      "\n",
      "episode 15, val func loss 0.18089181184768677\n",
      "\n",
      "episode 16, val func loss 0.17249064147472382\n",
      "\n",
      "Val func train loss in epoch 14:0.14034173777326941\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1810855120420456\n",
      "\n",
      "episode 2, val func loss 0.10769879817962646\n",
      "\n",
      "episode 3, val func loss 0.17150606215000153\n",
      "\n",
      "episode 4, val func loss 0.14541257917881012\n",
      "\n",
      "episode 5, val func loss 0.11248064041137695\n",
      "\n",
      "episode 6, val func loss 0.11536536365747452\n",
      "\n",
      "episode 7, val func loss 0.15552574396133423\n",
      "\n",
      "episode 8, val func loss 0.1750706434249878\n",
      "\n",
      "episode 9, val func loss 0.1242407038807869\n",
      "\n",
      "episode 10, val func loss 0.15620118379592896\n",
      "\n",
      "episode 11, val func loss 0.13563326001167297\n",
      "\n",
      "episode 12, val func loss 0.139659121632576\n",
      "\n",
      "episode 13, val func loss 0.12337356060743332\n",
      "\n",
      "episode 14, val func loss 0.1105085238814354\n",
      "\n",
      "episode 15, val func loss 0.14061343669891357\n",
      "\n",
      "episode 16, val func loss 0.1522260308265686\n",
      "\n",
      "Val func train loss in epoch 15:0.1404125727713108\n",
      "***********************TIME WAS 5.209028851985932 min*****************************\n",
      "\n",
      "**********************ROUND 20 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.11986339092254639\n",
      "\n",
      "episode 2, policy loss -0.10803833603858948\n",
      "\n",
      "episode 3, policy loss -0.09733232855796814\n",
      "\n",
      "episode 4, policy loss -0.10073485225439072\n",
      "\n",
      "episode 5, policy loss -0.12052251398563385\n",
      "\n",
      "episode 6, policy loss -0.12120604515075684\n",
      "\n",
      "episode 7, policy loss -0.14663979411125183\n",
      "\n",
      "episode 8, policy loss -0.07273395359516144\n",
      "\n",
      "episode 9, policy loss -0.05965924263000488\n",
      "\n",
      "episode 10, policy loss -0.08681540191173553\n",
      "\n",
      "episode 11, policy loss -0.1165972352027893\n",
      "\n",
      "episode 12, policy loss -0.12213899940252304\n",
      "\n",
      "episode 13, policy loss -0.08925215899944305\n",
      "\n",
      "episode 14, policy loss -0.1244695708155632\n",
      "\n",
      "episode 15, policy loss -0.1282767653465271\n",
      "\n",
      "episode 16, policy loss -0.10778594017028809\n",
      "\n",
      "Policy train loss in epoch 0:-0.1076291580684483\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.12700146436691284\n",
      "\n",
      "episode 2, policy loss -0.10096045583486557\n",
      "\n",
      "episode 3, policy loss -0.07693419605493546\n",
      "\n",
      "episode 4, policy loss -0.06905359029769897\n",
      "\n",
      "episode 5, policy loss -0.12309034168720245\n",
      "\n",
      "episode 6, policy loss -0.11655940115451813\n",
      "\n",
      "episode 7, policy loss -0.10971487313508987\n",
      "\n",
      "episode 8, policy loss -0.0564727857708931\n",
      "\n",
      "episode 9, policy loss -0.120367132127285\n",
      "\n",
      "episode 10, policy loss -0.10064582526683807\n",
      "\n",
      "episode 11, policy loss -0.1284189373254776\n",
      "\n",
      "episode 12, policy loss -0.11061349511146545\n",
      "\n",
      "episode 13, policy loss -0.147248774766922\n",
      "\n",
      "episode 14, policy loss -0.10984564572572708\n",
      "\n",
      "episode 15, policy loss -0.08912189304828644\n",
      "\n",
      "episode 16, policy loss -0.1238403171300888\n",
      "\n",
      "Policy train loss in epoch 1:-0.10686807055026293\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.08389508724212646\n",
      "\n",
      "episode 2, policy loss -0.09505333006381989\n",
      "\n",
      "episode 3, policy loss -0.11794436722993851\n",
      "\n",
      "episode 4, policy loss -0.11798730492591858\n",
      "\n",
      "episode 5, policy loss -0.12101764976978302\n",
      "\n",
      "episode 6, policy loss -0.12081562727689743\n",
      "\n",
      "episode 7, policy loss -0.10632404685020447\n",
      "\n",
      "episode 8, policy loss -0.0703047588467598\n",
      "\n",
      "episode 9, policy loss -0.0856800228357315\n",
      "\n",
      "episode 10, policy loss -0.12171461433172226\n",
      "\n",
      "episode 11, policy loss -0.05926184356212616\n",
      "\n",
      "episode 12, policy loss -0.10820308327674866\n",
      "\n",
      "episode 13, policy loss -0.14306050539016724\n",
      "\n",
      "episode 14, policy loss -0.09568943083286285\n",
      "\n",
      "episode 15, policy loss -0.12694494426250458\n",
      "\n",
      "episode 16, policy loss -0.12494815140962601\n",
      "\n",
      "Policy train loss in epoch 2:-0.10617779800668359\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.10616062581539154\n",
      "\n",
      "episode 2, policy loss -0.08366286754608154\n",
      "\n",
      "episode 3, policy loss -0.1286705732345581\n",
      "\n",
      "episode 4, policy loss -0.12118829786777496\n",
      "\n",
      "episode 5, policy loss -0.08547074347734451\n",
      "\n",
      "episode 6, policy loss -0.0726904422044754\n",
      "\n",
      "episode 7, policy loss -0.11630414426326752\n",
      "\n",
      "episode 8, policy loss -0.11221612989902496\n",
      "\n",
      "episode 9, policy loss -0.09601424634456635\n",
      "\n",
      "episode 10, policy loss -0.12450238317251205\n",
      "\n",
      "episode 11, policy loss -0.12319228053092957\n",
      "\n",
      "episode 12, policy loss -0.14498037099838257\n",
      "\n",
      "episode 13, policy loss -0.11501490324735641\n",
      "\n",
      "episode 14, policy loss -0.10392452031373978\n",
      "\n",
      "episode 15, policy loss -0.0964956283569336\n",
      "\n",
      "episode 16, policy loss -0.0602722093462944\n",
      "\n",
      "Policy train loss in epoch 3:-0.10567252291366458\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1269901841878891\n",
      "\n",
      "episode 2, val func loss 0.18996210396289825\n",
      "\n",
      "episode 3, val func loss 0.11065993458032608\n",
      "\n",
      "episode 4, val func loss 0.15423965454101562\n",
      "\n",
      "episode 5, val func loss 0.20295408368110657\n",
      "\n",
      "episode 6, val func loss 0.1061195433139801\n",
      "\n",
      "episode 7, val func loss 0.14451245963573456\n",
      "\n",
      "episode 8, val func loss 0.1309089958667755\n",
      "\n",
      "episode 9, val func loss 0.17579062283039093\n",
      "\n",
      "episode 10, val func loss 0.17224733531475067\n",
      "\n",
      "episode 11, val func loss 0.13365982472896576\n",
      "\n",
      "episode 12, val func loss 0.1406085044145584\n",
      "\n",
      "episode 13, val func loss 0.1617521345615387\n",
      "\n",
      "episode 14, val func loss 0.17236687242984772\n",
      "\n",
      "episode 15, val func loss 0.13532055914402008\n",
      "\n",
      "episode 16, val func loss 0.16635878384113312\n",
      "\n",
      "Val func train loss in epoch 0:0.1515282248146832\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.16871623694896698\n",
      "\n",
      "episode 2, val func loss 0.15472926199436188\n",
      "\n",
      "episode 3, val func loss 0.189643993973732\n",
      "\n",
      "episode 4, val func loss 0.1648803949356079\n",
      "\n",
      "episode 5, val func loss 0.12725399434566498\n",
      "\n",
      "episode 6, val func loss 0.20456218719482422\n",
      "\n",
      "episode 7, val func loss 0.17568433284759521\n",
      "\n",
      "episode 8, val func loss 0.14453859627246857\n",
      "\n",
      "episode 9, val func loss 0.11148712038993835\n",
      "\n",
      "episode 10, val func loss 0.16151832044124603\n",
      "\n",
      "episode 11, val func loss 0.10482922196388245\n",
      "\n",
      "episode 12, val func loss 0.13723474740982056\n",
      "\n",
      "episode 13, val func loss 0.13357865810394287\n",
      "\n",
      "episode 14, val func loss 0.17317523062229156\n",
      "\n",
      "episode 15, val func loss 0.1349799931049347\n",
      "\n",
      "episode 16, val func loss 0.14659000933170319\n",
      "\n",
      "Val func train loss in epoch 1:0.15208764374256134\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.14547738432884216\n",
      "\n",
      "episode 2, val func loss 0.1645701378583908\n",
      "\n",
      "episode 3, val func loss 0.1354830116033554\n",
      "\n",
      "episode 4, val func loss 0.1909528225660324\n",
      "\n",
      "episode 5, val func loss 0.1770426481962204\n",
      "\n",
      "episode 6, val func loss 0.15463203191757202\n",
      "\n",
      "episode 7, val func loss 0.16865143179893494\n",
      "\n",
      "episode 8, val func loss 0.10648562014102936\n",
      "\n",
      "episode 9, val func loss 0.13572153449058533\n",
      "\n",
      "episode 10, val func loss 0.16003747284412384\n",
      "\n",
      "episode 11, val func loss 0.11118760704994202\n",
      "\n",
      "episode 12, val func loss 0.12723113596439362\n",
      "\n",
      "episode 13, val func loss 0.17213687300682068\n",
      "\n",
      "episode 14, val func loss 0.20389100909233093\n",
      "\n",
      "episode 15, val func loss 0.1305832415819168\n",
      "\n",
      "episode 16, val func loss 0.14483751356601715\n",
      "\n",
      "Val func train loss in epoch 2:0.15180759225040674\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.10675938427448273\n",
      "\n",
      "episode 2, val func loss 0.1343659609556198\n",
      "\n",
      "episode 3, val func loss 0.17277784645557404\n",
      "\n",
      "episode 4, val func loss 0.18921808898448944\n",
      "\n",
      "episode 5, val func loss 0.16935160756111145\n",
      "\n",
      "episode 6, val func loss 0.1594560295343399\n",
      "\n",
      "episode 7, val func loss 0.13539420068264008\n",
      "\n",
      "episode 8, val func loss 0.14414151012897491\n",
      "\n",
      "episode 9, val func loss 0.20226126909255981\n",
      "\n",
      "episode 10, val func loss 0.12807036936283112\n",
      "\n",
      "episode 11, val func loss 0.15455161035060883\n",
      "\n",
      "episode 12, val func loss 0.1467529982328415\n",
      "\n",
      "episode 13, val func loss 0.11081283539533615\n",
      "\n",
      "episode 14, val func loss 0.1306290179491043\n",
      "\n",
      "episode 15, val func loss 0.17658746242523193\n",
      "\n",
      "episode 16, val func loss 0.16472941637039185\n",
      "\n",
      "Val func train loss in epoch 3:0.15161622548475862\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1414434164762497\n",
      "\n",
      "episode 2, val func loss 0.13353152573108673\n",
      "\n",
      "episode 3, val func loss 0.15874095261096954\n",
      "\n",
      "episode 4, val func loss 0.17055583000183105\n",
      "\n",
      "episode 5, val func loss 0.13103851675987244\n",
      "\n",
      "episode 6, val func loss 0.17656870186328888\n",
      "\n",
      "episode 7, val func loss 0.2035978138446808\n",
      "\n",
      "episode 8, val func loss 0.16638299822807312\n",
      "\n",
      "episode 9, val func loss 0.13509906828403473\n",
      "\n",
      "episode 10, val func loss 0.154832661151886\n",
      "\n",
      "episode 11, val func loss 0.12801626324653625\n",
      "\n",
      "episode 12, val func loss 0.11072160303592682\n",
      "\n",
      "episode 13, val func loss 0.14402954280376434\n",
      "\n",
      "episode 14, val func loss 0.10627790540456772\n",
      "\n",
      "episode 15, val func loss 0.1890782117843628\n",
      "\n",
      "episode 16, val func loss 0.17284393310546875\n",
      "\n",
      "Val func train loss in epoch 4:0.15142243402078748\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.10372916609048843\n",
      "\n",
      "episode 2, val func loss 0.13529753684997559\n",
      "\n",
      "episode 3, val func loss 0.15960735082626343\n",
      "\n",
      "episode 4, val func loss 0.17883706092834473\n",
      "\n",
      "episode 5, val func loss 0.1702435314655304\n",
      "\n",
      "episode 6, val func loss 0.1351758986711502\n",
      "\n",
      "episode 7, val func loss 0.15463887155056\n",
      "\n",
      "episode 8, val func loss 0.12938308715820312\n",
      "\n",
      "episode 9, val func loss 0.17468419671058655\n",
      "\n",
      "episode 10, val func loss 0.20232346653938293\n",
      "\n",
      "episode 11, val func loss 0.1108219102025032\n",
      "\n",
      "episode 12, val func loss 0.14402149617671967\n",
      "\n",
      "episode 13, val func loss 0.1459261029958725\n",
      "\n",
      "episode 14, val func loss 0.18954181671142578\n",
      "\n",
      "episode 15, val func loss 0.16485275328159332\n",
      "\n",
      "episode 16, val func loss 0.13160568475723267\n",
      "\n",
      "Val func train loss in epoch 5:0.15191812068223953\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.13421498239040375\n",
      "\n",
      "episode 2, val func loss 0.15684375166893005\n",
      "\n",
      "episode 3, val func loss 0.13768412172794342\n",
      "\n",
      "episode 4, val func loss 0.14106853306293488\n",
      "\n",
      "episode 5, val func loss 0.17290806770324707\n",
      "\n",
      "episode 6, val func loss 0.1763487458229065\n",
      "\n",
      "episode 7, val func loss 0.15879489481449127\n",
      "\n",
      "episode 8, val func loss 0.18869298696517944\n",
      "\n",
      "episode 9, val func loss 0.1645362377166748\n",
      "\n",
      "episode 10, val func loss 0.10562451183795929\n",
      "\n",
      "episode 11, val func loss 0.1687861979007721\n",
      "\n",
      "episode 12, val func loss 0.2026614099740982\n",
      "\n",
      "episode 13, val func loss 0.11049092561006546\n",
      "\n",
      "episode 14, val func loss 0.12739254534244537\n",
      "\n",
      "episode 15, val func loss 0.13061648607254028\n",
      "\n",
      "episode 16, val func loss 0.14451195299625397\n",
      "\n",
      "Val func train loss in epoch 6:0.15132352197542787\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.13478152453899384\n",
      "\n",
      "episode 2, val func loss 0.1271490901708603\n",
      "\n",
      "episode 3, val func loss 0.17563557624816895\n",
      "\n",
      "episode 4, val func loss 0.17318561673164368\n",
      "\n",
      "episode 5, val func loss 0.1450243443250656\n",
      "\n",
      "episode 6, val func loss 0.1548967808485031\n",
      "\n",
      "episode 7, val func loss 0.20332081615924835\n",
      "\n",
      "episode 8, val func loss 0.13073696196079254\n",
      "\n",
      "episode 9, val func loss 0.10623317211866379\n",
      "\n",
      "episode 10, val func loss 0.14387696981430054\n",
      "\n",
      "episode 11, val func loss 0.16936784982681274\n",
      "\n",
      "episode 12, val func loss 0.19018670916557312\n",
      "\n",
      "episode 13, val func loss 0.1369999796152115\n",
      "\n",
      "episode 14, val func loss 0.16422143578529358\n",
      "\n",
      "episode 15, val func loss 0.15858295559883118\n",
      "\n",
      "episode 16, val func loss 0.11101854592561722\n",
      "\n",
      "Val func train loss in epoch 7:0.15157614555209875\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16444794833660126\n",
      "\n",
      "episode 2, val func loss 0.12681034207344055\n",
      "\n",
      "episode 3, val func loss 0.14483192563056946\n",
      "\n",
      "episode 4, val func loss 0.15452878177165985\n",
      "\n",
      "episode 5, val func loss 0.16825473308563232\n",
      "\n",
      "episode 6, val func loss 0.13158026337623596\n",
      "\n",
      "episode 7, val func loss 0.2021280825138092\n",
      "\n",
      "episode 8, val func loss 0.17486031353473663\n",
      "\n",
      "episode 9, val func loss 0.16130582988262177\n",
      "\n",
      "episode 10, val func loss 0.13442127406597137\n",
      "\n",
      "episode 11, val func loss 0.17249040305614471\n",
      "\n",
      "episode 12, val func loss 0.110988087952137\n",
      "\n",
      "episode 13, val func loss 0.10340169072151184\n",
      "\n",
      "episode 14, val func loss 0.14001835882663727\n",
      "\n",
      "episode 15, val func loss 0.19300755858421326\n",
      "\n",
      "episode 16, val func loss 0.13939280807971954\n",
      "\n",
      "Val func train loss in epoch 8:0.15140427509322762\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.14063870906829834\n",
      "\n",
      "episode 2, val func loss 0.14747518301010132\n",
      "\n",
      "episode 3, val func loss 0.1314602494239807\n",
      "\n",
      "episode 4, val func loss 0.15405341982841492\n",
      "\n",
      "episode 5, val func loss 0.17567089200019836\n",
      "\n",
      "episode 6, val func loss 0.1915777027606964\n",
      "\n",
      "episode 7, val func loss 0.13517682254314423\n",
      "\n",
      "episode 8, val func loss 0.20199154317378998\n",
      "\n",
      "episode 9, val func loss 0.10829334706068039\n",
      "\n",
      "episode 10, val func loss 0.1655009537935257\n",
      "\n",
      "episode 11, val func loss 0.1730474978685379\n",
      "\n",
      "episode 12, val func loss 0.12752428650856018\n",
      "\n",
      "episode 13, val func loss 0.13429757952690125\n",
      "\n",
      "episode 14, val func loss 0.11175226420164108\n",
      "\n",
      "episode 15, val func loss 0.17221051454544067\n",
      "\n",
      "episode 16, val func loss 0.15881240367889404\n",
      "\n",
      "Val func train loss in epoch 9:0.15184271056205034\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.13095521926879883\n",
      "\n",
      "episode 2, val func loss 0.16435226798057556\n",
      "\n",
      "episode 3, val func loss 0.11076511442661285\n",
      "\n",
      "episode 4, val func loss 0.16746197640895844\n",
      "\n",
      "episode 5, val func loss 0.17333994805812836\n",
      "\n",
      "episode 6, val func loss 0.18990065157413483\n",
      "\n",
      "episode 7, val func loss 0.2015928477048874\n",
      "\n",
      "episode 8, val func loss 0.10512351244688034\n",
      "\n",
      "episode 9, val func loss 0.14549008011817932\n",
      "\n",
      "episode 10, val func loss 0.159023717045784\n",
      "\n",
      "episode 11, val func loss 0.17591999471187592\n",
      "\n",
      "episode 12, val func loss 0.13361622393131256\n",
      "\n",
      "episode 13, val func loss 0.15440236032009125\n",
      "\n",
      "episode 14, val func loss 0.1271931231021881\n",
      "\n",
      "episode 15, val func loss 0.13550303876399994\n",
      "\n",
      "episode 16, val func loss 0.14433583617210388\n",
      "\n",
      "Val func train loss in epoch 10:0.15118599450215697\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1901008039712906\n",
      "\n",
      "episode 2, val func loss 0.20343148708343506\n",
      "\n",
      "episode 3, val func loss 0.11083899438381195\n",
      "\n",
      "episode 4, val func loss 0.12759877741336823\n",
      "\n",
      "episode 5, val func loss 0.13486330211162567\n",
      "\n",
      "episode 6, val func loss 0.1592458039522171\n",
      "\n",
      "episode 7, val func loss 0.1419873684644699\n",
      "\n",
      "episode 8, val func loss 0.13142147660255432\n",
      "\n",
      "episode 9, val func loss 0.17077511548995972\n",
      "\n",
      "episode 10, val func loss 0.1035381630063057\n",
      "\n",
      "episode 11, val func loss 0.13691195845603943\n",
      "\n",
      "episode 12, val func loss 0.17653009295463562\n",
      "\n",
      "episode 13, val func loss 0.17159733176231384\n",
      "\n",
      "episode 14, val func loss 0.14441262185573578\n",
      "\n",
      "episode 15, val func loss 0.1686454713344574\n",
      "\n",
      "episode 16, val func loss 0.15501931309700012\n",
      "\n",
      "Val func train loss in epoch 11:0.15168238012120128\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.14462728798389435\n",
      "\n",
      "episode 2, val func loss 0.16437561810016632\n",
      "\n",
      "episode 3, val func loss 0.1314946711063385\n",
      "\n",
      "episode 4, val func loss 0.15472380816936493\n",
      "\n",
      "episode 5, val func loss 0.1692502647638321\n",
      "\n",
      "episode 6, val func loss 0.1597415655851364\n",
      "\n",
      "episode 7, val func loss 0.13663750886917114\n",
      "\n",
      "episode 8, val func loss 0.1896190047264099\n",
      "\n",
      "episode 9, val func loss 0.20270459353923798\n",
      "\n",
      "episode 10, val func loss 0.1458873599767685\n",
      "\n",
      "episode 11, val func loss 0.11069117486476898\n",
      "\n",
      "episode 12, val func loss 0.10405788570642471\n",
      "\n",
      "episode 13, val func loss 0.1760716438293457\n",
      "\n",
      "episode 14, val func loss 0.12708352506160736\n",
      "\n",
      "episode 15, val func loss 0.13427218794822693\n",
      "\n",
      "episode 16, val func loss 0.17255482077598572\n",
      "\n",
      "Val func train loss in epoch 12:0.15148705756291747\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1270008534193039\n",
      "\n",
      "episode 2, val func loss 0.14544041454792023\n",
      "\n",
      "episode 3, val func loss 0.17278963327407837\n",
      "\n",
      "episode 4, val func loss 0.16871502995491028\n",
      "\n",
      "episode 5, val func loss 0.18967802822589874\n",
      "\n",
      "episode 6, val func loss 0.1432419717311859\n",
      "\n",
      "episode 7, val func loss 0.16419216990470886\n",
      "\n",
      "episode 8, val func loss 0.10279898345470428\n",
      "\n",
      "episode 9, val func loss 0.13200272619724274\n",
      "\n",
      "episode 10, val func loss 0.13889937102794647\n",
      "\n",
      "episode 11, val func loss 0.17707012593746185\n",
      "\n",
      "episode 12, val func loss 0.15452168881893158\n",
      "\n",
      "episode 13, val func loss 0.11228536814451218\n",
      "\n",
      "episode 14, val func loss 0.1640883833169937\n",
      "\n",
      "episode 15, val func loss 0.13422201573848724\n",
      "\n",
      "episode 16, val func loss 0.20354200899600983\n",
      "\n",
      "Val func train loss in epoch 13:0.1519055482931435\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.13151852786540985\n",
      "\n",
      "episode 2, val func loss 0.20264601707458496\n",
      "\n",
      "episode 3, val func loss 0.16560512781143188\n",
      "\n",
      "episode 4, val func loss 0.16834713518619537\n",
      "\n",
      "episode 5, val func loss 0.12747417390346527\n",
      "\n",
      "episode 6, val func loss 0.13542211055755615\n",
      "\n",
      "episode 7, val func loss 0.16056016087532043\n",
      "\n",
      "episode 8, val func loss 0.17527064681053162\n",
      "\n",
      "episode 9, val func loss 0.1337500363588333\n",
      "\n",
      "episode 10, val func loss 0.1548328995704651\n",
      "\n",
      "episode 11, val func loss 0.1717921942472458\n",
      "\n",
      "episode 12, val func loss 0.1438794732093811\n",
      "\n",
      "episode 13, val func loss 0.18949712812900543\n",
      "\n",
      "episode 14, val func loss 0.10333861410617828\n",
      "\n",
      "episode 15, val func loss 0.14700643718242645\n",
      "\n",
      "episode 16, val func loss 0.11153624206781387\n",
      "\n",
      "Val func train loss in epoch 14:0.1514048078097403\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1336170881986618\n",
      "\n",
      "episode 2, val func loss 0.13134989142417908\n",
      "\n",
      "episode 3, val func loss 0.12782610952854156\n",
      "\n",
      "episode 4, val func loss 0.16019517183303833\n",
      "\n",
      "episode 5, val func loss 0.13556982576847076\n",
      "\n",
      "episode 6, val func loss 0.14446203410625458\n",
      "\n",
      "episode 7, val func loss 0.11077432334423065\n",
      "\n",
      "episode 8, val func loss 0.1899237036705017\n",
      "\n",
      "episode 9, val func loss 0.14450190961360931\n",
      "\n",
      "episode 10, val func loss 0.17519769072532654\n",
      "\n",
      "episode 11, val func loss 0.16868914663791656\n",
      "\n",
      "episode 12, val func loss 0.15493318438529968\n",
      "\n",
      "episode 13, val func loss 0.16458836197853088\n",
      "\n",
      "episode 14, val func loss 0.17232421040534973\n",
      "\n",
      "episode 15, val func loss 0.10463288426399231\n",
      "\n",
      "episode 16, val func loss 0.20422053337097168\n",
      "\n",
      "Val func train loss in epoch 15:0.1514253793284297\n",
      "***********************TIME WAS 5.168882834911346 min*****************************\n",
      "\n",
      "**********************ROUND 21 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.09402821958065033\n",
      "\n",
      "episode 2, policy loss -0.15049369633197784\n",
      "\n",
      "episode 3, policy loss -0.11393052339553833\n",
      "\n",
      "episode 4, policy loss -0.12473590672016144\n",
      "\n",
      "episode 5, policy loss -0.08897309005260468\n",
      "\n",
      "episode 6, policy loss -0.11090252548456192\n",
      "\n",
      "episode 7, policy loss -0.0749761313199997\n",
      "\n",
      "episode 8, policy loss -0.06992969661951065\n",
      "\n",
      "episode 9, policy loss -0.1278451681137085\n",
      "\n",
      "episode 10, policy loss -0.08485491573810577\n",
      "\n",
      "episode 11, policy loss -0.08502699434757233\n",
      "\n",
      "episode 12, policy loss -0.12823891639709473\n",
      "\n",
      "episode 13, policy loss -0.0737658441066742\n",
      "\n",
      "episode 14, policy loss -0.15353545546531677\n",
      "\n",
      "episode 15, policy loss -0.14090456068515778\n",
      "\n",
      "episode 16, policy loss -0.14062413573265076\n",
      "\n",
      "Policy train loss in epoch 0:-0.11017286125570536\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.11966121196746826\n",
      "\n",
      "episode 2, policy loss -0.0741596519947052\n",
      "\n",
      "episode 3, policy loss -0.06909335404634476\n",
      "\n",
      "episode 4, policy loss -0.07922361046075821\n",
      "\n",
      "episode 5, policy loss -0.15443116426467896\n",
      "\n",
      "episode 6, policy loss -0.13930952548980713\n",
      "\n",
      "episode 7, policy loss -0.08221214264631271\n",
      "\n",
      "episode 8, policy loss -0.1276957094669342\n",
      "\n",
      "episode 9, policy loss -0.07859113067388535\n",
      "\n",
      "episode 10, policy loss -0.08905848860740662\n",
      "\n",
      "episode 11, policy loss -0.12450816482305527\n",
      "\n",
      "episode 12, policy loss -0.09033437818288803\n",
      "\n",
      "episode 13, policy loss -0.1365889012813568\n",
      "\n",
      "episode 14, policy loss -0.15307152271270752\n",
      "\n",
      "episode 15, policy loss -0.11432438343763351\n",
      "\n",
      "episode 16, policy loss -0.13211342692375183\n",
      "\n",
      "Policy train loss in epoch 1:-0.1102735479362309\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.1174391433596611\n",
      "\n",
      "episode 2, policy loss -0.13815715909004211\n",
      "\n",
      "episode 3, policy loss -0.1267920434474945\n",
      "\n",
      "episode 4, policy loss -0.07082648575305939\n",
      "\n",
      "episode 5, policy loss -0.12049411237239838\n",
      "\n",
      "episode 6, policy loss -0.15337756276130676\n",
      "\n",
      "episode 7, policy loss -0.11624124646186829\n",
      "\n",
      "episode 8, policy loss -0.12765458226203918\n",
      "\n",
      "episode 9, policy loss -0.07737444341182709\n",
      "\n",
      "episode 10, policy loss -0.07035975903272629\n",
      "\n",
      "episode 11, policy loss -0.08502021431922913\n",
      "\n",
      "episode 12, policy loss -0.08497260510921478\n",
      "\n",
      "episode 13, policy loss -0.09295149892568588\n",
      "\n",
      "episode 14, policy loss -0.1417524516582489\n",
      "\n",
      "episode 15, policy loss -0.09072547405958176\n",
      "\n",
      "episode 16, policy loss -0.15088801085948944\n",
      "\n",
      "Policy train loss in epoch 2:-0.11031417455524206\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.11315715312957764\n",
      "\n",
      "episode 2, policy loss -0.12578091025352478\n",
      "\n",
      "episode 3, policy loss -0.14315497875213623\n",
      "\n",
      "episode 4, policy loss -0.08129676431417465\n",
      "\n",
      "episode 5, policy loss -0.1537039577960968\n",
      "\n",
      "episode 6, policy loss -0.15213945508003235\n",
      "\n",
      "episode 7, policy loss -0.09349068254232407\n",
      "\n",
      "episode 8, policy loss -0.08250933140516281\n",
      "\n",
      "episode 9, policy loss -0.12482388317584991\n",
      "\n",
      "episode 10, policy loss -0.07773207873106003\n",
      "\n",
      "episode 11, policy loss -0.09002445638179779\n",
      "\n",
      "episode 12, policy loss -0.11395376920700073\n",
      "\n",
      "episode 13, policy loss -0.07112108170986176\n",
      "\n",
      "episode 14, policy loss -0.07062174379825592\n",
      "\n",
      "episode 15, policy loss -0.137552410364151\n",
      "\n",
      "episode 16, policy loss -0.1169077605009079\n",
      "\n",
      "Policy train loss in epoch 3:-0.10924815107136965\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1449659764766693\n",
      "\n",
      "episode 2, val func loss 0.15242761373519897\n",
      "\n",
      "episode 3, val func loss 0.1816176325082779\n",
      "\n",
      "episode 4, val func loss 0.1405549943447113\n",
      "\n",
      "episode 5, val func loss 0.1806521862745285\n",
      "\n",
      "episode 6, val func loss 0.15005670487880707\n",
      "\n",
      "episode 7, val func loss 0.14348778128623962\n",
      "\n",
      "episode 8, val func loss 0.13282130658626556\n",
      "\n",
      "episode 9, val func loss 0.1576962172985077\n",
      "\n",
      "episode 10, val func loss 0.1505250185728073\n",
      "\n",
      "episode 11, val func loss 0.14903755486011505\n",
      "\n",
      "episode 12, val func loss 0.17728613317012787\n",
      "\n",
      "episode 13, val func loss 0.14111296832561493\n",
      "\n",
      "episode 14, val func loss 0.19473378360271454\n",
      "\n",
      "episode 15, val func loss 0.14276517927646637\n",
      "\n",
      "episode 16, val func loss 0.1587904393672943\n",
      "\n",
      "Val func train loss in epoch 0:0.15615821816027164\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1416071355342865\n",
      "\n",
      "episode 2, val func loss 0.18444588780403137\n",
      "\n",
      "episode 3, val func loss 0.14928485453128815\n",
      "\n",
      "episode 4, val func loss 0.15168693661689758\n",
      "\n",
      "episode 5, val func loss 0.16296014189720154\n",
      "\n",
      "episode 6, val func loss 0.18043646216392517\n",
      "\n",
      "episode 7, val func loss 0.13301484286785126\n",
      "\n",
      "episode 8, val func loss 0.15181602537631989\n",
      "\n",
      "episode 9, val func loss 0.14242084324359894\n",
      "\n",
      "episode 10, val func loss 0.1482456475496292\n",
      "\n",
      "episode 11, val func loss 0.15198247134685516\n",
      "\n",
      "episode 12, val func loss 0.17319276928901672\n",
      "\n",
      "episode 13, val func loss 0.15566332638263702\n",
      "\n",
      "episode 14, val func loss 0.19885972142219543\n",
      "\n",
      "episode 15, val func loss 0.1412297636270523\n",
      "\n",
      "episode 16, val func loss 0.1674942523241043\n",
      "\n",
      "Val func train loss in epoch 1:0.15839631762355566\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.15708908438682556\n",
      "\n",
      "episode 2, val func loss 0.18353547155857086\n",
      "\n",
      "episode 3, val func loss 0.1327078938484192\n",
      "\n",
      "episode 4, val func loss 0.14427079260349274\n",
      "\n",
      "episode 5, val func loss 0.14323821663856506\n",
      "\n",
      "episode 6, val func loss 0.1756512075662613\n",
      "\n",
      "episode 7, val func loss 0.18183016777038574\n",
      "\n",
      "episode 8, val func loss 0.194585382938385\n",
      "\n",
      "episode 9, val func loss 0.14101210236549377\n",
      "\n",
      "episode 10, val func loss 0.15958507359027863\n",
      "\n",
      "episode 11, val func loss 0.1448853760957718\n",
      "\n",
      "episode 12, val func loss 0.14184655249118805\n",
      "\n",
      "episode 13, val func loss 0.14627483487129211\n",
      "\n",
      "episode 14, val func loss 0.1638539433479309\n",
      "\n",
      "episode 15, val func loss 0.15461286902427673\n",
      "\n",
      "episode 16, val func loss 0.15115788578987122\n",
      "\n",
      "Val func train loss in epoch 2:0.15725855343043804\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.14139658212661743\n",
      "\n",
      "episode 2, val func loss 0.15206009149551392\n",
      "\n",
      "episode 3, val func loss 0.1466168761253357\n",
      "\n",
      "episode 4, val func loss 0.14880244433879852\n",
      "\n",
      "episode 5, val func loss 0.14816972613334656\n",
      "\n",
      "episode 6, val func loss 0.15096238255500793\n",
      "\n",
      "episode 7, val func loss 0.13456721603870392\n",
      "\n",
      "episode 8, val func loss 0.1796586513519287\n",
      "\n",
      "episode 9, val func loss 0.14533138275146484\n",
      "\n",
      "episode 10, val func loss 0.15903908014297485\n",
      "\n",
      "episode 11, val func loss 0.1508668065071106\n",
      "\n",
      "episode 12, val func loss 0.1398516744375229\n",
      "\n",
      "episode 13, val func loss 0.18160173296928406\n",
      "\n",
      "episode 14, val func loss 0.1961289346218109\n",
      "\n",
      "episode 15, val func loss 0.16187094151973724\n",
      "\n",
      "episode 16, val func loss 0.17304161190986633\n",
      "\n",
      "Val func train loss in epoch 3:0.15687288343906403\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17010757327079773\n",
      "\n",
      "episode 2, val func loss 0.14188390970230103\n",
      "\n",
      "episode 3, val func loss 0.15050366520881653\n",
      "\n",
      "episode 4, val func loss 0.1318972259759903\n",
      "\n",
      "episode 5, val func loss 0.14893701672554016\n",
      "\n",
      "episode 6, val func loss 0.15212735533714294\n",
      "\n",
      "episode 7, val func loss 0.14420178532600403\n",
      "\n",
      "episode 8, val func loss 0.20063109695911407\n",
      "\n",
      "episode 9, val func loss 0.17298173904418945\n",
      "\n",
      "episode 10, val func loss 0.18082669377326965\n",
      "\n",
      "episode 11, val func loss 0.14346691966056824\n",
      "\n",
      "episode 12, val func loss 0.14435681700706482\n",
      "\n",
      "episode 13, val func loss 0.1801629364490509\n",
      "\n",
      "episode 14, val func loss 0.140804722905159\n",
      "\n",
      "episode 15, val func loss 0.16188420355319977\n",
      "\n",
      "episode 16, val func loss 0.1522347778081894\n",
      "\n",
      "Val func train loss in epoch 4:0.15731302741914988\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.14175434410572052\n",
      "\n",
      "episode 2, val func loss 0.1513243168592453\n",
      "\n",
      "episode 3, val func loss 0.18062135577201843\n",
      "\n",
      "episode 4, val func loss 0.1413598656654358\n",
      "\n",
      "episode 5, val func loss 0.19586552679538727\n",
      "\n",
      "episode 6, val func loss 0.1508592814207077\n",
      "\n",
      "episode 7, val func loss 0.1580868363380432\n",
      "\n",
      "episode 8, val func loss 0.16195917129516602\n",
      "\n",
      "episode 9, val func loss 0.18159817159175873\n",
      "\n",
      "episode 10, val func loss 0.14946213364601135\n",
      "\n",
      "episode 11, val func loss 0.1411166787147522\n",
      "\n",
      "episode 12, val func loss 0.15205338597297668\n",
      "\n",
      "episode 13, val func loss 0.1730610579252243\n",
      "\n",
      "episode 14, val func loss 0.1461019068956375\n",
      "\n",
      "episode 15, val func loss 0.14455117285251617\n",
      "\n",
      "episode 16, val func loss 0.13228094577789307\n",
      "\n",
      "Val func train loss in epoch 5:0.1563785094767809\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.15170082449913025\n",
      "\n",
      "episode 2, val func loss 0.18228697776794434\n",
      "\n",
      "episode 3, val func loss 0.15773823857307434\n",
      "\n",
      "episode 4, val func loss 0.19547128677368164\n",
      "\n",
      "episode 5, val func loss 0.14039508998394012\n",
      "\n",
      "episode 6, val func loss 0.15041333436965942\n",
      "\n",
      "episode 7, val func loss 0.14433541893959045\n",
      "\n",
      "episode 8, val func loss 0.14398840069770813\n",
      "\n",
      "episode 9, val func loss 0.17357276380062103\n",
      "\n",
      "episode 10, val func loss 0.1806565821170807\n",
      "\n",
      "episode 11, val func loss 0.15017753839492798\n",
      "\n",
      "episode 12, val func loss 0.1330764889717102\n",
      "\n",
      "episode 13, val func loss 0.14215561747550964\n",
      "\n",
      "episode 14, val func loss 0.1611226350069046\n",
      "\n",
      "episode 15, val func loss 0.14536158740520477\n",
      "\n",
      "episode 16, val func loss 0.14637130498886108\n",
      "\n",
      "Val func train loss in epoch 6:0.1561765056103468\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.14960245788097382\n",
      "\n",
      "episode 2, val func loss 0.14248277246952057\n",
      "\n",
      "episode 3, val func loss 0.1362924724817276\n",
      "\n",
      "episode 4, val func loss 0.15321677923202515\n",
      "\n",
      "episode 5, val func loss 0.14578670263290405\n",
      "\n",
      "episode 6, val func loss 0.1953900009393692\n",
      "\n",
      "episode 7, val func loss 0.15853986144065857\n",
      "\n",
      "episode 8, val func loss 0.17602303624153137\n",
      "\n",
      "episode 9, val func loss 0.1418498307466507\n",
      "\n",
      "episode 10, val func loss 0.16261205077171326\n",
      "\n",
      "episode 11, val func loss 0.18254798650741577\n",
      "\n",
      "episode 12, val func loss 0.1417674571275711\n",
      "\n",
      "episode 13, val func loss 0.15212009847164154\n",
      "\n",
      "episode 14, val func loss 0.13996419310569763\n",
      "\n",
      "episode 15, val func loss 0.18071235716342926\n",
      "\n",
      "episode 16, val func loss 0.1446758210659027\n",
      "\n",
      "Val func train loss in epoch 7:0.15647399239242077\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.15025842189788818\n",
      "\n",
      "episode 2, val func loss 0.14051096141338348\n",
      "\n",
      "episode 3, val func loss 0.15269242227077484\n",
      "\n",
      "episode 4, val func loss 0.14519080519676208\n",
      "\n",
      "episode 5, val func loss 0.1464768350124359\n",
      "\n",
      "episode 6, val func loss 0.15863734483718872\n",
      "\n",
      "episode 7, val func loss 0.17994831502437592\n",
      "\n",
      "episode 8, val func loss 0.1505175530910492\n",
      "\n",
      "episode 9, val func loss 0.14454998075962067\n",
      "\n",
      "episode 10, val func loss 0.1415824294090271\n",
      "\n",
      "episode 11, val func loss 0.14211784303188324\n",
      "\n",
      "episode 12, val func loss 0.17453543841838837\n",
      "\n",
      "episode 13, val func loss 0.18113161623477936\n",
      "\n",
      "episode 14, val func loss 0.19481578469276428\n",
      "\n",
      "episode 15, val func loss 0.15994569659233093\n",
      "\n",
      "episode 16, val func loss 0.1340436339378357\n",
      "\n",
      "Val func train loss in epoch 8:0.1560596926137805\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.14216773211956024\n",
      "\n",
      "episode 2, val func loss 0.13457205891609192\n",
      "\n",
      "episode 3, val func loss 0.14534889161586761\n",
      "\n",
      "episode 4, val func loss 0.17314159870147705\n",
      "\n",
      "episode 5, val func loss 0.16093984246253967\n",
      "\n",
      "episode 6, val func loss 0.15981587767601013\n",
      "\n",
      "episode 7, val func loss 0.19571106135845184\n",
      "\n",
      "episode 8, val func loss 0.14143571257591248\n",
      "\n",
      "episode 9, val func loss 0.15166963636875153\n",
      "\n",
      "episode 10, val func loss 0.18238791823387146\n",
      "\n",
      "episode 11, val func loss 0.14779771864414215\n",
      "\n",
      "episode 12, val func loss 0.14034521579742432\n",
      "\n",
      "episode 13, val func loss 0.14040730893611908\n",
      "\n",
      "episode 14, val func loss 0.15094657242298126\n",
      "\n",
      "episode 15, val func loss 0.18058300018310547\n",
      "\n",
      "episode 16, val func loss 0.15052123367786407\n",
      "\n",
      "Val func train loss in epoch 9:0.15611196123063564\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18090564012527466\n",
      "\n",
      "episode 2, val func loss 0.1955375224351883\n",
      "\n",
      "episode 3, val func loss 0.14174358546733856\n",
      "\n",
      "episode 4, val func loss 0.14611752331256866\n",
      "\n",
      "episode 5, val func loss 0.1591910570859909\n",
      "\n",
      "episode 6, val func loss 0.16030314564704895\n",
      "\n",
      "episode 7, val func loss 0.173383429646492\n",
      "\n",
      "episode 8, val func loss 0.15058231353759766\n",
      "\n",
      "episode 9, val func loss 0.18030452728271484\n",
      "\n",
      "episode 10, val func loss 0.14211371541023254\n",
      "\n",
      "episode 11, val func loss 0.13227905333042145\n",
      "\n",
      "episode 12, val func loss 0.1518515646457672\n",
      "\n",
      "episode 13, val func loss 0.14637300372123718\n",
      "\n",
      "episode 14, val func loss 0.15176503360271454\n",
      "\n",
      "episode 15, val func loss 0.14113228023052216\n",
      "\n",
      "episode 16, val func loss 0.1464037448167801\n",
      "\n",
      "Val func train loss in epoch 10:0.1562491962686181\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.13255517184734344\n",
      "\n",
      "episode 2, val func loss 0.14468637108802795\n",
      "\n",
      "episode 3, val func loss 0.14382542669773102\n",
      "\n",
      "episode 4, val func loss 0.14243806898593903\n",
      "\n",
      "episode 5, val func loss 0.1953451931476593\n",
      "\n",
      "episode 6, val func loss 0.14591482281684875\n",
      "\n",
      "episode 7, val func loss 0.16099318861961365\n",
      "\n",
      "episode 8, val func loss 0.1591961830854416\n",
      "\n",
      "episode 9, val func loss 0.15007628500461578\n",
      "\n",
      "episode 10, val func loss 0.14106522500514984\n",
      "\n",
      "episode 11, val func loss 0.1810901165008545\n",
      "\n",
      "episode 12, val func loss 0.1506638526916504\n",
      "\n",
      "episode 13, val func loss 0.17335979640483856\n",
      "\n",
      "episode 14, val func loss 0.18059270083904266\n",
      "\n",
      "episode 15, val func loss 0.1532154083251953\n",
      "\n",
      "episode 16, val func loss 0.14216020703315735\n",
      "\n",
      "Val func train loss in epoch 11:0.15607362613081932\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18118464946746826\n",
      "\n",
      "episode 2, val func loss 0.14159905910491943\n",
      "\n",
      "episode 3, val func loss 0.16118259727954865\n",
      "\n",
      "episode 4, val func loss 0.19496457278728485\n",
      "\n",
      "episode 5, val func loss 0.17481033504009247\n",
      "\n",
      "episode 6, val func loss 0.14661800861358643\n",
      "\n",
      "episode 7, val func loss 0.15142208337783813\n",
      "\n",
      "episode 8, val func loss 0.14519885182380676\n",
      "\n",
      "episode 9, val func loss 0.14137504994869232\n",
      "\n",
      "episode 10, val func loss 0.14373955130577087\n",
      "\n",
      "episode 11, val func loss 0.1804514229297638\n",
      "\n",
      "episode 12, val func loss 0.15011216700077057\n",
      "\n",
      "episode 13, val func loss 0.14414162933826447\n",
      "\n",
      "episode 14, val func loss 0.13295792043209076\n",
      "\n",
      "episode 15, val func loss 0.15873652696609497\n",
      "\n",
      "episode 16, val func loss 0.15213145315647125\n",
      "\n",
      "Val func train loss in epoch 12:0.156289117410779\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.150956392288208\n",
      "\n",
      "episode 2, val func loss 0.14804671704769135\n",
      "\n",
      "episode 3, val func loss 0.1457729935646057\n",
      "\n",
      "episode 4, val func loss 0.14534765481948853\n",
      "\n",
      "episode 5, val func loss 0.1403401792049408\n",
      "\n",
      "episode 6, val func loss 0.13302339613437653\n",
      "\n",
      "episode 7, val func loss 0.14263492822647095\n",
      "\n",
      "episode 8, val func loss 0.15970011055469513\n",
      "\n",
      "episode 9, val func loss 0.1942431479692459\n",
      "\n",
      "episode 10, val func loss 0.18068255484104156\n",
      "\n",
      "episode 11, val func loss 0.18235497176647186\n",
      "\n",
      "episode 12, val func loss 0.16150398552417755\n",
      "\n",
      "episode 13, val func loss 0.15270914137363434\n",
      "\n",
      "episode 14, val func loss 0.17406536638736725\n",
      "\n",
      "episode 15, val func loss 0.14973223209381104\n",
      "\n",
      "episode 16, val func loss 0.1447528749704361\n",
      "\n",
      "Val func train loss in epoch 13:0.1566166654229164\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1799682080745697\n",
      "\n",
      "episode 2, val func loss 0.18080058693885803\n",
      "\n",
      "episode 3, val func loss 0.13376697897911072\n",
      "\n",
      "episode 4, val func loss 0.1504431664943695\n",
      "\n",
      "episode 5, val func loss 0.15065373480319977\n",
      "\n",
      "episode 6, val func loss 0.1420191079378128\n",
      "\n",
      "episode 7, val func loss 0.16138747334480286\n",
      "\n",
      "episode 8, val func loss 0.14663101732730865\n",
      "\n",
      "episode 9, val func loss 0.15191304683685303\n",
      "\n",
      "episode 10, val func loss 0.15859492123126984\n",
      "\n",
      "episode 11, val func loss 0.17479851841926575\n",
      "\n",
      "episode 12, val func loss 0.14027844369411469\n",
      "\n",
      "episode 13, val func loss 0.19450743496418\n",
      "\n",
      "episode 14, val func loss 0.1413034200668335\n",
      "\n",
      "episode 15, val func loss 0.14481458067893982\n",
      "\n",
      "episode 16, val func loss 0.14448854327201843\n",
      "\n",
      "Val func train loss in epoch 14:0.1560230739414692\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.17406445741653442\n",
      "\n",
      "episode 2, val func loss 0.16016808152198792\n",
      "\n",
      "episode 3, val func loss 0.15328267216682434\n",
      "\n",
      "episode 4, val func loss 0.18046262860298157\n",
      "\n",
      "episode 5, val func loss 0.14243094623088837\n",
      "\n",
      "episode 6, val func loss 0.141755610704422\n",
      "\n",
      "episode 7, val func loss 0.14010536670684814\n",
      "\n",
      "episode 8, val func loss 0.19626402854919434\n",
      "\n",
      "episode 9, val func loss 0.1842438280582428\n",
      "\n",
      "episode 10, val func loss 0.1512141227722168\n",
      "\n",
      "episode 11, val func loss 0.16275568306446075\n",
      "\n",
      "episode 12, val func loss 0.1463092714548111\n",
      "\n",
      "episode 13, val func loss 0.13308140635490417\n",
      "\n",
      "episode 14, val func loss 0.14192841947078705\n",
      "\n",
      "episode 15, val func loss 0.1509249359369278\n",
      "\n",
      "episode 16, val func loss 0.14610756933689117\n",
      "\n",
      "Val func train loss in epoch 15:0.15656868927180767\n",
      "***********************TIME WAS 5.167177208264669 min*****************************\n",
      "\n",
      "**********************ROUND 22 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.028414595872163773\n",
      "\n",
      "episode 2, policy loss -0.056348808109760284\n",
      "\n",
      "episode 3, policy loss -0.0892052873969078\n",
      "\n",
      "episode 4, policy loss -0.0398220494389534\n",
      "\n",
      "episode 5, policy loss -0.03215199336409569\n",
      "\n",
      "episode 6, policy loss -0.03476719558238983\n",
      "\n",
      "episode 7, policy loss 0.006335824728012085\n",
      "\n",
      "episode 8, policy loss -0.04719938337802887\n",
      "\n",
      "episode 9, policy loss 0.002197831869125366\n",
      "\n",
      "episode 10, policy loss -0.0569906160235405\n",
      "\n",
      "episode 11, policy loss -0.01747361198067665\n",
      "\n",
      "episode 12, policy loss -0.05913468450307846\n",
      "\n",
      "episode 13, policy loss -0.01038806140422821\n",
      "\n",
      "episode 14, policy loss -0.05148767679929733\n",
      "\n",
      "episode 15, policy loss 0.008122265338897705\n",
      "\n",
      "episode 16, policy loss -0.07587897032499313\n",
      "\n",
      "Policy train loss in epoch 0:-0.036412938265129924\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.05642178654670715\n",
      "\n",
      "episode 2, policy loss -0.07493487000465393\n",
      "\n",
      "episode 3, policy loss -0.030630551278591156\n",
      "\n",
      "episode 4, policy loss 0.005671612918376923\n",
      "\n",
      "episode 5, policy loss -0.05544373393058777\n",
      "\n",
      "episode 6, policy loss -0.019992083311080933\n",
      "\n",
      "episode 7, policy loss -0.04968490079045296\n",
      "\n",
      "episode 8, policy loss -0.061468370258808136\n",
      "\n",
      "episode 9, policy loss -0.029444199055433273\n",
      "\n",
      "episode 10, policy loss -0.04761911556124687\n",
      "\n",
      "episode 11, policy loss 0.006681427359580994\n",
      "\n",
      "episode 12, policy loss -0.018338333815336227\n",
      "\n",
      "episode 13, policy loss -0.05887841433286667\n",
      "\n",
      "episode 14, policy loss -0.03232942521572113\n",
      "\n",
      "episode 15, policy loss -0.09685438126325607\n",
      "\n",
      "episode 16, policy loss -0.0027970299124717712\n",
      "\n",
      "Policy train loss in epoch 1:-0.03890525968745351\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.05678762495517731\n",
      "\n",
      "episode 2, policy loss -0.0361802875995636\n",
      "\n",
      "episode 3, policy loss 0.003503657877445221\n",
      "\n",
      "episode 4, policy loss -0.06046367064118385\n",
      "\n",
      "episode 5, policy loss -0.05678519606590271\n",
      "\n",
      "episode 6, policy loss -0.03447806090116501\n",
      "\n",
      "episode 7, policy loss -0.01837608590722084\n",
      "\n",
      "episode 8, policy loss 0.0012505725026130676\n",
      "\n",
      "episode 9, policy loss -0.06157784163951874\n",
      "\n",
      "episode 10, policy loss -0.02802756056189537\n",
      "\n",
      "episode 11, policy loss -0.051095008850097656\n",
      "\n",
      "episode 12, policy loss -0.019625358283519745\n",
      "\n",
      "episode 13, policy loss -0.004001304507255554\n",
      "\n",
      "episode 14, policy loss -0.0985439196228981\n",
      "\n",
      "episode 15, policy loss -0.07577735930681229\n",
      "\n",
      "episode 16, policy loss -0.059141453355550766\n",
      "\n",
      "Policy train loss in epoch 2:-0.04100665636360645\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.05273452401161194\n",
      "\n",
      "episode 2, policy loss -0.07663699239492416\n",
      "\n",
      "episode 3, policy loss -0.019026774913072586\n",
      "\n",
      "episode 4, policy loss -0.05874141305685043\n",
      "\n",
      "episode 5, policy loss -0.057804349809885025\n",
      "\n",
      "episode 6, policy loss -0.0019782185554504395\n",
      "\n",
      "episode 7, policy loss -0.01667993888258934\n",
      "\n",
      "episode 8, policy loss -0.03613220155239105\n",
      "\n",
      "episode 9, policy loss -0.027939800173044205\n",
      "\n",
      "episode 10, policy loss -0.09752912819385529\n",
      "\n",
      "episode 11, policy loss -0.059246908873319626\n",
      "\n",
      "episode 12, policy loss -0.05767469108104706\n",
      "\n",
      "episode 13, policy loss -0.04821719974279404\n",
      "\n",
      "episode 14, policy loss -0.031204041093587875\n",
      "\n",
      "episode 15, policy loss 0.005513086915016174\n",
      "\n",
      "episode 16, policy loss 0.006795898079872131\n",
      "\n",
      "Policy train loss in epoch 3:-0.03932732483372092\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.15281978249549866\n",
      "\n",
      "episode 2, val func loss 0.14694012701511383\n",
      "\n",
      "episode 3, val func loss 0.21106480062007904\n",
      "\n",
      "episode 4, val func loss 0.16361965239048004\n",
      "\n",
      "episode 5, val func loss 0.15884001553058624\n",
      "\n",
      "episode 6, val func loss 0.1551222801208496\n",
      "\n",
      "episode 7, val func loss 0.14281292259693146\n",
      "\n",
      "episode 8, val func loss 0.1291324496269226\n",
      "\n",
      "episode 9, val func loss 0.13010235130786896\n",
      "\n",
      "episode 10, val func loss 0.12244553118944168\n",
      "\n",
      "episode 11, val func loss 0.1584610939025879\n",
      "\n",
      "episode 12, val func loss 0.1163225993514061\n",
      "\n",
      "episode 13, val func loss 0.15397590398788452\n",
      "\n",
      "episode 14, val func loss 0.1323125660419464\n",
      "\n",
      "episode 15, val func loss 0.15497468411922455\n",
      "\n",
      "episode 16, val func loss 0.15485414862632751\n",
      "\n",
      "Val func train loss in epoch 0:0.14898755680769682\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.16474634408950806\n",
      "\n",
      "episode 2, val func loss 0.1620764285326004\n",
      "\n",
      "episode 3, val func loss 0.1235751286149025\n",
      "\n",
      "episode 4, val func loss 0.15807239711284637\n",
      "\n",
      "episode 5, val func loss 0.14413267374038696\n",
      "\n",
      "episode 6, val func loss 0.15630538761615753\n",
      "\n",
      "episode 7, val func loss 0.15563425421714783\n",
      "\n",
      "episode 8, val func loss 0.13043585419654846\n",
      "\n",
      "episode 9, val func loss 0.12976746261119843\n",
      "\n",
      "episode 10, val func loss 0.14203019440174103\n",
      "\n",
      "episode 11, val func loss 0.12411310523748398\n",
      "\n",
      "episode 12, val func loss 0.21817117929458618\n",
      "\n",
      "episode 13, val func loss 0.1438564658164978\n",
      "\n",
      "episode 14, val func loss 0.12882037460803986\n",
      "\n",
      "episode 15, val func loss 0.1537158340215683\n",
      "\n",
      "episode 16, val func loss 0.15052907168865204\n",
      "\n",
      "Val func train loss in epoch 1:0.1491238847374916\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.11791994422674179\n",
      "\n",
      "episode 2, val func loss 0.12676852941513062\n",
      "\n",
      "episode 3, val func loss 0.15385551750659943\n",
      "\n",
      "episode 4, val func loss 0.12917132675647736\n",
      "\n",
      "episode 5, val func loss 0.15533028542995453\n",
      "\n",
      "episode 6, val func loss 0.15687298774719238\n",
      "\n",
      "episode 7, val func loss 0.21386978030204773\n",
      "\n",
      "episode 8, val func loss 0.1431942880153656\n",
      "\n",
      "episode 9, val func loss 0.14491423964500427\n",
      "\n",
      "episode 10, val func loss 0.13297022879123688\n",
      "\n",
      "episode 11, val func loss 0.15023264288902283\n",
      "\n",
      "episode 12, val func loss 0.15946932137012482\n",
      "\n",
      "episode 13, val func loss 0.12969762086868286\n",
      "\n",
      "episode 14, val func loss 0.14231553673744202\n",
      "\n",
      "episode 15, val func loss 0.16313816606998444\n",
      "\n",
      "episode 16, val func loss 0.15594890713691711\n",
      "\n",
      "Val func train loss in epoch 2:0.1484793326817453\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.15516799688339233\n",
      "\n",
      "episode 2, val func loss 0.15432170033454895\n",
      "\n",
      "episode 3, val func loss 0.11718425899744034\n",
      "\n",
      "episode 4, val func loss 0.14197532832622528\n",
      "\n",
      "episode 5, val func loss 0.1437298208475113\n",
      "\n",
      "episode 6, val func loss 0.12888334691524506\n",
      "\n",
      "episode 7, val func loss 0.15570871531963348\n",
      "\n",
      "episode 8, val func loss 0.1290392279624939\n",
      "\n",
      "episode 9, val func loss 0.1235826313495636\n",
      "\n",
      "episode 10, val func loss 0.1452663242816925\n",
      "\n",
      "episode 11, val func loss 0.16008256375789642\n",
      "\n",
      "episode 12, val func loss 0.15311037003993988\n",
      "\n",
      "episode 13, val func loss 0.21605463325977325\n",
      "\n",
      "episode 14, val func loss 0.1629505604505539\n",
      "\n",
      "episode 15, val func loss 0.15490782260894775\n",
      "\n",
      "episode 16, val func loss 0.12997034192085266\n",
      "\n",
      "Val func train loss in epoch 3:0.1482459777034819\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.16311220824718475\n",
      "\n",
      "episode 2, val func loss 0.16623196005821228\n",
      "\n",
      "episode 3, val func loss 0.15388120710849762\n",
      "\n",
      "episode 4, val func loss 0.1292675882577896\n",
      "\n",
      "episode 5, val func loss 0.2289734184741974\n",
      "\n",
      "episode 6, val func loss 0.1552502065896988\n",
      "\n",
      "episode 7, val func loss 0.1479272097349167\n",
      "\n",
      "episode 8, val func loss 0.1302163153886795\n",
      "\n",
      "episode 9, val func loss 0.15445126593112946\n",
      "\n",
      "episode 10, val func loss 0.14655371010303497\n",
      "\n",
      "episode 11, val func loss 0.1430440992116928\n",
      "\n",
      "episode 12, val func loss 0.11717170476913452\n",
      "\n",
      "episode 13, val func loss 0.15652450919151306\n",
      "\n",
      "episode 14, val func loss 0.12921957671642303\n",
      "\n",
      "episode 15, val func loss 0.12304511666297913\n",
      "\n",
      "episode 16, val func loss 0.15683242678642273\n",
      "\n",
      "Val func train loss in epoch 4:0.15010640770196915\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.15235723555088043\n",
      "\n",
      "episode 2, val func loss 0.14278602600097656\n",
      "\n",
      "episode 3, val func loss 0.12592115998268127\n",
      "\n",
      "episode 4, val func loss 0.213006392121315\n",
      "\n",
      "episode 5, val func loss 0.12956158816814423\n",
      "\n",
      "episode 6, val func loss 0.15389832854270935\n",
      "\n",
      "episode 7, val func loss 0.1545756459236145\n",
      "\n",
      "episode 8, val func loss 0.1548406034708023\n",
      "\n",
      "episode 9, val func loss 0.14556536078453064\n",
      "\n",
      "episode 10, val func loss 0.1571035385131836\n",
      "\n",
      "episode 11, val func loss 0.12965384125709534\n",
      "\n",
      "episode 12, val func loss 0.15887275338172913\n",
      "\n",
      "episode 13, val func loss 0.1634920984506607\n",
      "\n",
      "episode 14, val func loss 0.11672051250934601\n",
      "\n",
      "episode 15, val func loss 0.1295730471611023\n",
      "\n",
      "episode 16, val func loss 0.14537885785102844\n",
      "\n",
      "Val func train loss in epoch 5:0.1483316868543625\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.15285372734069824\n",
      "\n",
      "episode 2, val func loss 0.16411249339580536\n",
      "\n",
      "episode 3, val func loss 0.1590193659067154\n",
      "\n",
      "episode 4, val func loss 0.14389611780643463\n",
      "\n",
      "episode 5, val func loss 0.15475112199783325\n",
      "\n",
      "episode 6, val func loss 0.15405184030532837\n",
      "\n",
      "episode 7, val func loss 0.14560657739639282\n",
      "\n",
      "episode 8, val func loss 0.2119583934545517\n",
      "\n",
      "episode 9, val func loss 0.15703606605529785\n",
      "\n",
      "episode 10, val func loss 0.14263956248760223\n",
      "\n",
      "episode 11, val func loss 0.1189805269241333\n",
      "\n",
      "episode 12, val func loss 0.12958501279354095\n",
      "\n",
      "episode 13, val func loss 0.13067249953746796\n",
      "\n",
      "episode 14, val func loss 0.12334759533405304\n",
      "\n",
      "episode 15, val func loss 0.15948936343193054\n",
      "\n",
      "episode 16, val func loss 0.1291399449110031\n",
      "\n",
      "Val func train loss in epoch 6:0.1485712630674243\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.15867044031620026\n",
      "\n",
      "episode 2, val func loss 0.13061848282814026\n",
      "\n",
      "episode 3, val func loss 0.14315295219421387\n",
      "\n",
      "episode 4, val func loss 0.15561114251613617\n",
      "\n",
      "episode 5, val func loss 0.2131844460964203\n",
      "\n",
      "episode 6, val func loss 0.15480881929397583\n",
      "\n",
      "episode 7, val func loss 0.1294376701116562\n",
      "\n",
      "episode 8, val func loss 0.13388827443122864\n",
      "\n",
      "episode 9, val func loss 0.16258515417575836\n",
      "\n",
      "episode 10, val func loss 0.12896676361560822\n",
      "\n",
      "episode 11, val func loss 0.1425020545721054\n",
      "\n",
      "episode 12, val func loss 0.14444482326507568\n",
      "\n",
      "episode 13, val func loss 0.1159517914056778\n",
      "\n",
      "episode 14, val func loss 0.15216870605945587\n",
      "\n",
      "episode 15, val func loss 0.15970280766487122\n",
      "\n",
      "episode 16, val func loss 0.1548452377319336\n",
      "\n",
      "Val func train loss in epoch 7:0.1487837228924036\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.15374308824539185\n",
      "\n",
      "episode 2, val func loss 0.11751154065132141\n",
      "\n",
      "episode 3, val func loss 0.14210209250450134\n",
      "\n",
      "episode 4, val func loss 0.1321573704481125\n",
      "\n",
      "episode 5, val func loss 0.16303354501724243\n",
      "\n",
      "episode 6, val func loss 0.1446790248155594\n",
      "\n",
      "episode 7, val func loss 0.158988356590271\n",
      "\n",
      "episode 8, val func loss 0.1563260704278946\n",
      "\n",
      "episode 9, val func loss 0.1572716385126114\n",
      "\n",
      "episode 10, val func loss 0.12456846237182617\n",
      "\n",
      "episode 11, val func loss 0.15164585411548615\n",
      "\n",
      "episode 12, val func loss 0.1438812017440796\n",
      "\n",
      "episode 13, val func loss 0.2153676599264145\n",
      "\n",
      "episode 14, val func loss 0.12963469326496124\n",
      "\n",
      "episode 15, val func loss 0.154745414853096\n",
      "\n",
      "episode 16, val func loss 0.12929917871952057\n",
      "\n",
      "Val func train loss in epoch 8:0.14843469951301813\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.14699065685272217\n",
      "\n",
      "episode 2, val func loss 0.13456493616104126\n",
      "\n",
      "episode 3, val func loss 0.15508770942687988\n",
      "\n",
      "episode 4, val func loss 0.15397785604000092\n",
      "\n",
      "episode 5, val func loss 0.14385849237442017\n",
      "\n",
      "episode 6, val func loss 0.15686683356761932\n",
      "\n",
      "episode 7, val func loss 0.15582332015037537\n",
      "\n",
      "episode 8, val func loss 0.12956549227237701\n",
      "\n",
      "episode 9, val func loss 0.12483881413936615\n",
      "\n",
      "episode 10, val func loss 0.21602340042591095\n",
      "\n",
      "episode 11, val func loss 0.1590789258480072\n",
      "\n",
      "episode 12, val func loss 0.14174240827560425\n",
      "\n",
      "episode 13, val func loss 0.16319452226161957\n",
      "\n",
      "episode 14, val func loss 0.1296837031841278\n",
      "\n",
      "episode 15, val func loss 0.15055444836616516\n",
      "\n",
      "episode 16, val func loss 0.11900528520345688\n",
      "\n",
      "Val func train loss in epoch 9:0.14880355028435588\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1597396284341812\n",
      "\n",
      "episode 2, val func loss 0.15057100355625153\n",
      "\n",
      "episode 3, val func loss 0.1433815211057663\n",
      "\n",
      "episode 4, val func loss 0.12917013466358185\n",
      "\n",
      "episode 5, val func loss 0.16336791217327118\n",
      "\n",
      "episode 6, val func loss 0.2149553894996643\n",
      "\n",
      "episode 7, val func loss 0.15434958040714264\n",
      "\n",
      "episode 8, val func loss 0.12621665000915527\n",
      "\n",
      "episode 9, val func loss 0.15375928580760956\n",
      "\n",
      "episode 10, val func loss 0.15573915839195251\n",
      "\n",
      "episode 11, val func loss 0.13172318041324615\n",
      "\n",
      "episode 12, val func loss 0.141804039478302\n",
      "\n",
      "episode 13, val func loss 0.1297052949666977\n",
      "\n",
      "episode 14, val func loss 0.15664976835250854\n",
      "\n",
      "episode 15, val func loss 0.14394311606884003\n",
      "\n",
      "episode 16, val func loss 0.11632078140974045\n",
      "\n",
      "Val func train loss in epoch 10:0.14821227779611945\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.15625157952308655\n",
      "\n",
      "episode 2, val func loss 0.15594211220741272\n",
      "\n",
      "episode 3, val func loss 0.1442069262266159\n",
      "\n",
      "episode 4, val func loss 0.1439044326543808\n",
      "\n",
      "episode 5, val func loss 0.11665304750204086\n",
      "\n",
      "episode 6, val func loss 0.14245791733264923\n",
      "\n",
      "episode 7, val func loss 0.21644136309623718\n",
      "\n",
      "episode 8, val func loss 0.13099615275859833\n",
      "\n",
      "episode 9, val func loss 0.1296646147966385\n",
      "\n",
      "episode 10, val func loss 0.1553477942943573\n",
      "\n",
      "episode 11, val func loss 0.16023553907871246\n",
      "\n",
      "episode 12, val func loss 0.16409185528755188\n",
      "\n",
      "episode 13, val func loss 0.15330283343791962\n",
      "\n",
      "episode 14, val func loss 0.13057930767536163\n",
      "\n",
      "episode 15, val func loss 0.12825047969818115\n",
      "\n",
      "episode 16, val func loss 0.15094420313835144\n",
      "\n",
      "Val func train loss in epoch 11:0.14870438491925597\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.14368833601474762\n",
      "\n",
      "episode 2, val func loss 0.15950728952884674\n",
      "\n",
      "episode 3, val func loss 0.14302565157413483\n",
      "\n",
      "episode 4, val func loss 0.15641480684280396\n",
      "\n",
      "episode 5, val func loss 0.13143156468868256\n",
      "\n",
      "episode 6, val func loss 0.12370260059833527\n",
      "\n",
      "episode 7, val func loss 0.12842413783073425\n",
      "\n",
      "episode 8, val func loss 0.21467837691307068\n",
      "\n",
      "episode 9, val func loss 0.15617765486240387\n",
      "\n",
      "episode 10, val func loss 0.1551135927438736\n",
      "\n",
      "episode 11, val func loss 0.15006303787231445\n",
      "\n",
      "episode 12, val func loss 0.15473517775535583\n",
      "\n",
      "episode 13, val func loss 0.14445964992046356\n",
      "\n",
      "episode 14, val func loss 0.1353427916765213\n",
      "\n",
      "episode 15, val func loss 0.1636754721403122\n",
      "\n",
      "episode 16, val func loss 0.11809538304805756\n",
      "\n",
      "Val func train loss in epoch 12:0.14865847025066614\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1517631560564041\n",
      "\n",
      "episode 2, val func loss 0.1433604210615158\n",
      "\n",
      "episode 3, val func loss 0.15985693037509918\n",
      "\n",
      "episode 4, val func loss 0.13186199963092804\n",
      "\n",
      "episode 5, val func loss 0.12890289723873138\n",
      "\n",
      "episode 6, val func loss 0.1544984132051468\n",
      "\n",
      "episode 7, val func loss 0.21435226500034332\n",
      "\n",
      "episode 8, val func loss 0.1566845327615738\n",
      "\n",
      "episode 9, val func loss 0.14461587369441986\n",
      "\n",
      "episode 10, val func loss 0.15611468255519867\n",
      "\n",
      "episode 11, val func loss 0.13586673140525818\n",
      "\n",
      "episode 12, val func loss 0.12895454466342926\n",
      "\n",
      "episode 13, val func loss 0.1417107880115509\n",
      "\n",
      "episode 14, val func loss 0.15948720276355743\n",
      "\n",
      "episode 15, val func loss 0.16484948992729187\n",
      "\n",
      "episode 16, val func loss 0.11641274392604828\n",
      "\n",
      "Val func train loss in epoch 13:0.14933079201728106\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.15351136028766632\n",
      "\n",
      "episode 2, val func loss 0.12948907911777496\n",
      "\n",
      "episode 3, val func loss 0.14385905861854553\n",
      "\n",
      "episode 4, val func loss 0.21610894799232483\n",
      "\n",
      "episode 5, val func loss 0.15578225255012512\n",
      "\n",
      "episode 6, val func loss 0.1551171839237213\n",
      "\n",
      "episode 7, val func loss 0.14304207265377045\n",
      "\n",
      "episode 8, val func loss 0.134189173579216\n",
      "\n",
      "episode 9, val func loss 0.1287899911403656\n",
      "\n",
      "episode 10, val func loss 0.15894177556037903\n",
      "\n",
      "episode 11, val func loss 0.15764345228672028\n",
      "\n",
      "episode 12, val func loss 0.1307198852300644\n",
      "\n",
      "episode 13, val func loss 0.14373351633548737\n",
      "\n",
      "episode 14, val func loss 0.15408864617347717\n",
      "\n",
      "episode 15, val func loss 0.11673707515001297\n",
      "\n",
      "episode 16, val func loss 0.1635642647743225\n",
      "\n",
      "Val func train loss in epoch 14:0.14908235846087337\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.15671759843826294\n",
      "\n",
      "episode 2, val func loss 0.15099331736564636\n",
      "\n",
      "episode 3, val func loss 0.13030210137367249\n",
      "\n",
      "episode 4, val func loss 0.14392508566379547\n",
      "\n",
      "episode 5, val func loss 0.15680217742919922\n",
      "\n",
      "episode 6, val func loss 0.16310667991638184\n",
      "\n",
      "episode 7, val func loss 0.1298140436410904\n",
      "\n",
      "episode 8, val func loss 0.21298114955425262\n",
      "\n",
      "episode 9, val func loss 0.11960506439208984\n",
      "\n",
      "episode 10, val func loss 0.12856131792068481\n",
      "\n",
      "episode 11, val func loss 0.1547643393278122\n",
      "\n",
      "episode 12, val func loss 0.15930582582950592\n",
      "\n",
      "episode 13, val func loss 0.1545371115207672\n",
      "\n",
      "episode 14, val func loss 0.14383262395858765\n",
      "\n",
      "episode 15, val func loss 0.1291401982307434\n",
      "\n",
      "episode 16, val func loss 0.1416897028684616\n",
      "\n",
      "Val func train loss in epoch 15:0.14850489608943462\n",
      "***********************TIME WAS 5.1652748862902325 min*****************************\n",
      "\n",
      "**********************ROUND 23 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.19975745677947998\n",
      "\n",
      "episode 2, policy loss -0.1496506929397583\n",
      "\n",
      "episode 3, policy loss -0.09782055765390396\n",
      "\n",
      "episode 4, policy loss -0.11681537330150604\n",
      "\n",
      "episode 5, policy loss -0.177566260099411\n",
      "\n",
      "episode 6, policy loss -0.12325745820999146\n",
      "\n",
      "episode 7, policy loss -0.1724088191986084\n",
      "\n",
      "episode 8, policy loss -0.06602759659290314\n",
      "\n",
      "episode 9, policy loss -0.11761834472417831\n",
      "\n",
      "episode 10, policy loss -0.11475008726119995\n",
      "\n",
      "episode 11, policy loss -0.0887703225016594\n",
      "\n",
      "episode 12, policy loss -0.09940044581890106\n",
      "\n",
      "episode 13, policy loss -0.07940247654914856\n",
      "\n",
      "episode 14, policy loss -0.17368119955062866\n",
      "\n",
      "episode 15, policy loss -0.10250608623027802\n",
      "\n",
      "episode 16, policy loss -0.15042369067668915\n",
      "\n",
      "Policy train loss in epoch 0:-0.12686605425551534\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.1501295566558838\n",
      "\n",
      "episode 2, policy loss -0.08090370893478394\n",
      "\n",
      "episode 3, policy loss -0.11353009939193726\n",
      "\n",
      "episode 4, policy loss -0.0668199360370636\n",
      "\n",
      "episode 5, policy loss -0.19526302814483643\n",
      "\n",
      "episode 6, policy loss -0.12099523842334747\n",
      "\n",
      "episode 7, policy loss -0.17978446185588837\n",
      "\n",
      "episode 8, policy loss -0.15195614099502563\n",
      "\n",
      "episode 9, policy loss -0.08739057183265686\n",
      "\n",
      "episode 10, policy loss -0.1705068200826645\n",
      "\n",
      "episode 11, policy loss -0.17488053441047668\n",
      "\n",
      "episode 12, policy loss -0.0996650904417038\n",
      "\n",
      "episode 13, policy loss -0.1023922860622406\n",
      "\n",
      "episode 14, policy loss -0.10538965463638306\n",
      "\n",
      "episode 15, policy loss -0.11792868375778198\n",
      "\n",
      "episode 16, policy loss -0.11659793555736542\n",
      "\n",
      "Policy train loss in epoch 1:-0.12713335920125246\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.20217764377593994\n",
      "\n",
      "episode 2, policy loss -0.15054292976856232\n",
      "\n",
      "episode 3, policy loss -0.08634389936923981\n",
      "\n",
      "episode 4, policy loss -0.07680481672286987\n",
      "\n",
      "episode 5, policy loss -0.1199023649096489\n",
      "\n",
      "episode 6, policy loss -0.16898728907108307\n",
      "\n",
      "episode 7, policy loss -0.11593349277973175\n",
      "\n",
      "episode 8, policy loss -0.11601991951465607\n",
      "\n",
      "episode 9, policy loss -0.12060199677944183\n",
      "\n",
      "episode 10, policy loss -0.10066700726747513\n",
      "\n",
      "episode 11, policy loss -0.09899140149354935\n",
      "\n",
      "episode 12, policy loss -0.10364539921283722\n",
      "\n",
      "episode 13, policy loss -0.06992097198963165\n",
      "\n",
      "episode 14, policy loss -0.17575764656066895\n",
      "\n",
      "episode 15, policy loss -0.15273389220237732\n",
      "\n",
      "episode 16, policy loss -0.17572206258773804\n",
      "\n",
      "Policy train loss in epoch 2:-0.1271720458753407\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.06950447708368301\n",
      "\n",
      "episode 2, policy loss -0.15219667553901672\n",
      "\n",
      "episode 3, policy loss -0.17401060461997986\n",
      "\n",
      "episode 4, policy loss -0.178521066904068\n",
      "\n",
      "episode 5, policy loss -0.10127446055412292\n",
      "\n",
      "episode 6, policy loss -0.11865638196468353\n",
      "\n",
      "episode 7, policy loss -0.12028175592422485\n",
      "\n",
      "episode 8, policy loss -0.2020978331565857\n",
      "\n",
      "episode 9, policy loss -0.11245789378881454\n",
      "\n",
      "episode 10, policy loss -0.08161767572164536\n",
      "\n",
      "episode 11, policy loss -0.15468184649944305\n",
      "\n",
      "episode 12, policy loss -0.17426076531410217\n",
      "\n",
      "episode 13, policy loss -0.10085748136043549\n",
      "\n",
      "episode 14, policy loss -0.12494371086359024\n",
      "\n",
      "episode 15, policy loss -0.08805563300848007\n",
      "\n",
      "episode 16, policy loss -0.10405748337507248\n",
      "\n",
      "Policy train loss in epoch 3:-0.12859223410487175\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.2252025455236435\n",
      "\n",
      "episode 2, val func loss 0.1615123152732849\n",
      "\n",
      "episode 3, val func loss 0.1293436735868454\n",
      "\n",
      "episode 4, val func loss 0.17317743599414825\n",
      "\n",
      "episode 5, val func loss 0.16724905371665955\n",
      "\n",
      "episode 6, val func loss 0.19608347117900848\n",
      "\n",
      "episode 7, val func loss 0.12447554618120193\n",
      "\n",
      "episode 8, val func loss 0.1187947615981102\n",
      "\n",
      "episode 9, val func loss 0.16319513320922852\n",
      "\n",
      "episode 10, val func loss 0.16544091701507568\n",
      "\n",
      "episode 11, val func loss 0.17726759612560272\n",
      "\n",
      "episode 12, val func loss 0.20045624673366547\n",
      "\n",
      "episode 13, val func loss 0.20180833339691162\n",
      "\n",
      "episode 14, val func loss 0.149817556142807\n",
      "\n",
      "episode 15, val func loss 0.16426333785057068\n",
      "\n",
      "episode 16, val func loss 0.16798636317253113\n",
      "\n",
      "Val func train loss in epoch 0:0.16787964291870594\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.12762987613677979\n",
      "\n",
      "episode 2, val func loss 0.21723204851150513\n",
      "\n",
      "episode 3, val func loss 0.11971316486597061\n",
      "\n",
      "episode 4, val func loss 0.19590842723846436\n",
      "\n",
      "episode 5, val func loss 0.16396214067935944\n",
      "\n",
      "episode 6, val func loss 0.16088667511940002\n",
      "\n",
      "episode 7, val func loss 0.165329709649086\n",
      "\n",
      "episode 8, val func loss 0.16642245650291443\n",
      "\n",
      "episode 9, val func loss 0.18083083629608154\n",
      "\n",
      "episode 10, val func loss 0.13267067074775696\n",
      "\n",
      "episode 11, val func loss 0.16269271075725555\n",
      "\n",
      "episode 12, val func loss 0.20116499066352844\n",
      "\n",
      "episode 13, val func loss 0.1765415370464325\n",
      "\n",
      "episode 14, val func loss 0.18503452837467194\n",
      "\n",
      "episode 15, val func loss 0.16942620277404785\n",
      "\n",
      "episode 16, val func loss 0.1677665412425995\n",
      "\n",
      "Val func train loss in epoch 1:0.16832578228786588\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.169476717710495\n",
      "\n",
      "episode 2, val func loss 0.12306877970695496\n",
      "\n",
      "episode 3, val func loss 0.16389229893684387\n",
      "\n",
      "episode 4, val func loss 0.18055857717990875\n",
      "\n",
      "episode 5, val func loss 0.12796974182128906\n",
      "\n",
      "episode 6, val func loss 0.11853981018066406\n",
      "\n",
      "episode 7, val func loss 0.16162210702896118\n",
      "\n",
      "episode 8, val func loss 0.17703981697559357\n",
      "\n",
      "episode 9, val func loss 0.15349099040031433\n",
      "\n",
      "episode 10, val func loss 0.16613039374351501\n",
      "\n",
      "episode 11, val func loss 0.19764940440654755\n",
      "\n",
      "episode 12, val func loss 0.20010069012641907\n",
      "\n",
      "episode 13, val func loss 0.21957746148109436\n",
      "\n",
      "episode 14, val func loss 0.16351944208145142\n",
      "\n",
      "episode 15, val func loss 0.16735175251960754\n",
      "\n",
      "episode 16, val func loss 0.18371614813804626\n",
      "\n",
      "Val func train loss in epoch 2:0.16710650827735662\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.14519093930721283\n",
      "\n",
      "episode 2, val func loss 0.17569631338119507\n",
      "\n",
      "episode 3, val func loss 0.19933174550533295\n",
      "\n",
      "episode 4, val func loss 0.18374717235565186\n",
      "\n",
      "episode 5, val func loss 0.21734192967414856\n",
      "\n",
      "episode 6, val func loss 0.16770921647548676\n",
      "\n",
      "episode 7, val func loss 0.16948574781417847\n",
      "\n",
      "episode 8, val func loss 0.16417184472084045\n",
      "\n",
      "episode 9, val func loss 0.11863858252763748\n",
      "\n",
      "episode 10, val func loss 0.12164241820573807\n",
      "\n",
      "episode 11, val func loss 0.18641994893550873\n",
      "\n",
      "episode 12, val func loss 0.17663323879241943\n",
      "\n",
      "episode 13, val func loss 0.1631542146205902\n",
      "\n",
      "episode 14, val func loss 0.1968516856431961\n",
      "\n",
      "episode 15, val func loss 0.1621035784482956\n",
      "\n",
      "episode 16, val func loss 0.13005441427230835\n",
      "\n",
      "Val func train loss in epoch 3:0.1673858119174838\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.16788384318351746\n",
      "\n",
      "episode 2, val func loss 0.16203901171684265\n",
      "\n",
      "episode 3, val func loss 0.11890091001987457\n",
      "\n",
      "episode 4, val func loss 0.16337789595127106\n",
      "\n",
      "episode 5, val func loss 0.1946890503168106\n",
      "\n",
      "episode 6, val func loss 0.22502870857715607\n",
      "\n",
      "episode 7, val func loss 0.16287758946418762\n",
      "\n",
      "episode 8, val func loss 0.1803242713212967\n",
      "\n",
      "episode 9, val func loss 0.12467578053474426\n",
      "\n",
      "episode 10, val func loss 0.1651015281677246\n",
      "\n",
      "episode 11, val func loss 0.17390042543411255\n",
      "\n",
      "episode 12, val func loss 0.1665773242712021\n",
      "\n",
      "episode 13, val func loss 0.13120895624160767\n",
      "\n",
      "episode 14, val func loss 0.19622161984443665\n",
      "\n",
      "episode 15, val func loss 0.19876745343208313\n",
      "\n",
      "episode 16, val func loss 0.14855147898197174\n",
      "\n",
      "Val func train loss in epoch 4:0.16750786546617746\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1309526562690735\n",
      "\n",
      "episode 2, val func loss 0.16299863159656525\n",
      "\n",
      "episode 3, val func loss 0.16312739253044128\n",
      "\n",
      "episode 4, val func loss 0.1777283102273941\n",
      "\n",
      "episode 5, val func loss 0.12148904800415039\n",
      "\n",
      "episode 6, val func loss 0.11821094155311584\n",
      "\n",
      "episode 7, val func loss 0.17753328382968903\n",
      "\n",
      "episode 8, val func loss 0.2000289261341095\n",
      "\n",
      "episode 9, val func loss 0.1673235446214676\n",
      "\n",
      "episode 10, val func loss 0.14940541982650757\n",
      "\n",
      "episode 11, val func loss 0.1964753270149231\n",
      "\n",
      "episode 12, val func loss 0.16924524307250977\n",
      "\n",
      "episode 13, val func loss 0.16476477682590485\n",
      "\n",
      "episode 14, val func loss 0.16852331161499023\n",
      "\n",
      "episode 15, val func loss 0.2203701287508011\n",
      "\n",
      "episode 16, val func loss 0.1848895102739334\n",
      "\n",
      "Val func train loss in epoch 5:0.16706665325909853\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18463930487632751\n",
      "\n",
      "episode 2, val func loss 0.2172974795103073\n",
      "\n",
      "episode 3, val func loss 0.1664048582315445\n",
      "\n",
      "episode 4, val func loss 0.16840794682502747\n",
      "\n",
      "episode 5, val func loss 0.16685552895069122\n",
      "\n",
      "episode 6, val func loss 0.1838110387325287\n",
      "\n",
      "episode 7, val func loss 0.11895762383937836\n",
      "\n",
      "episode 8, val func loss 0.19764003157615662\n",
      "\n",
      "episode 9, val func loss 0.12203145027160645\n",
      "\n",
      "episode 10, val func loss 0.12727974355220795\n",
      "\n",
      "episode 11, val func loss 0.16819033026695251\n",
      "\n",
      "episode 12, val func loss 0.1571352779865265\n",
      "\n",
      "episode 13, val func loss 0.1614157110452652\n",
      "\n",
      "episode 14, val func loss 0.16412878036499023\n",
      "\n",
      "episode 15, val func loss 0.17668600380420685\n",
      "\n",
      "episode 16, val func loss 0.19934578239917755\n",
      "\n",
      "Val func train loss in epoch 6:0.16751418076455593\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.16401778161525726\n",
      "\n",
      "episode 2, val func loss 0.119095079600811\n",
      "\n",
      "episode 3, val func loss 0.1991174966096878\n",
      "\n",
      "episode 4, val func loss 0.13172125816345215\n",
      "\n",
      "episode 5, val func loss 0.16422100365161896\n",
      "\n",
      "episode 6, val func loss 0.16271832585334778\n",
      "\n",
      "episode 7, val func loss 0.12292752414941788\n",
      "\n",
      "episode 8, val func loss 0.22559630870819092\n",
      "\n",
      "episode 9, val func loss 0.17679107189178467\n",
      "\n",
      "episode 10, val func loss 0.16771012544631958\n",
      "\n",
      "episode 11, val func loss 0.17842689156532288\n",
      "\n",
      "episode 12, val func loss 0.1859598606824875\n",
      "\n",
      "episode 13, val func loss 0.19620901346206665\n",
      "\n",
      "episode 14, val func loss 0.16651691496372223\n",
      "\n",
      "episode 15, val func loss 0.1695191115140915\n",
      "\n",
      "episode 16, val func loss 0.1469033658504486\n",
      "\n",
      "Val func train loss in epoch 7:0.1673406958580017\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16949601471424103\n",
      "\n",
      "episode 2, val func loss 0.14762648940086365\n",
      "\n",
      "episode 3, val func loss 0.16676847636699677\n",
      "\n",
      "episode 4, val func loss 0.21928240358829498\n",
      "\n",
      "episode 5, val func loss 0.1300942748785019\n",
      "\n",
      "episode 6, val func loss 0.16802464425563812\n",
      "\n",
      "episode 7, val func loss 0.17829042673110962\n",
      "\n",
      "episode 8, val func loss 0.17381231486797333\n",
      "\n",
      "episode 9, val func loss 0.11912178248167038\n",
      "\n",
      "episode 10, val func loss 0.19742876291275024\n",
      "\n",
      "episode 11, val func loss 0.12230819463729858\n",
      "\n",
      "episode 12, val func loss 0.18681399524211884\n",
      "\n",
      "episode 13, val func loss 0.19893915951251984\n",
      "\n",
      "episode 14, val func loss 0.1629924327135086\n",
      "\n",
      "episode 15, val func loss 0.16274240612983704\n",
      "\n",
      "episode 16, val func loss 0.16460435092449188\n",
      "\n",
      "Val func train loss in epoch 8:0.16677163308486342\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.11879788339138031\n",
      "\n",
      "episode 2, val func loss 0.19955146312713623\n",
      "\n",
      "episode 3, val func loss 0.16330035030841827\n",
      "\n",
      "episode 4, val func loss 0.16197919845581055\n",
      "\n",
      "episode 5, val func loss 0.16769488155841827\n",
      "\n",
      "episode 6, val func loss 0.1669115275144577\n",
      "\n",
      "episode 7, val func loss 0.12213460355997086\n",
      "\n",
      "episode 8, val func loss 0.19937345385551453\n",
      "\n",
      "episode 9, val func loss 0.22362858057022095\n",
      "\n",
      "episode 10, val func loss 0.16171321272850037\n",
      "\n",
      "episode 11, val func loss 0.17786750197410583\n",
      "\n",
      "episode 12, val func loss 0.18521155416965485\n",
      "\n",
      "episode 13, val func loss 0.13087914884090424\n",
      "\n",
      "episode 14, val func loss 0.147063747048378\n",
      "\n",
      "episode 15, val func loss 0.1689484715461731\n",
      "\n",
      "episode 16, val func loss 0.1714806705713272\n",
      "\n",
      "Val func train loss in epoch 9:0.1666585155762732\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.16691380739212036\n",
      "\n",
      "episode 2, val func loss 0.1805199831724167\n",
      "\n",
      "episode 3, val func loss 0.19604629278182983\n",
      "\n",
      "episode 4, val func loss 0.11921953409910202\n",
      "\n",
      "episode 5, val func loss 0.19840097427368164\n",
      "\n",
      "episode 6, val func loss 0.16226254403591156\n",
      "\n",
      "episode 7, val func loss 0.1492125391960144\n",
      "\n",
      "episode 8, val func loss 0.18685200810432434\n",
      "\n",
      "episode 9, val func loss 0.16651447117328644\n",
      "\n",
      "episode 10, val func loss 0.12959104776382446\n",
      "\n",
      "episode 11, val func loss 0.17327634990215302\n",
      "\n",
      "episode 12, val func loss 0.21996937692165375\n",
      "\n",
      "episode 13, val func loss 0.16401806473731995\n",
      "\n",
      "episode 14, val func loss 0.1685481071472168\n",
      "\n",
      "episode 15, val func loss 0.16346648335456848\n",
      "\n",
      "episode 16, val func loss 0.12397579848766327\n",
      "\n",
      "Val func train loss in epoch 10:0.16679921140894294\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19605623185634613\n",
      "\n",
      "episode 2, val func loss 0.22008344531059265\n",
      "\n",
      "episode 3, val func loss 0.17208418250083923\n",
      "\n",
      "episode 4, val func loss 0.1794956475496292\n",
      "\n",
      "episode 5, val func loss 0.16382023692131042\n",
      "\n",
      "episode 6, val func loss 0.1476971060037613\n",
      "\n",
      "episode 7, val func loss 0.16402238607406616\n",
      "\n",
      "episode 8, val func loss 0.1311214119195938\n",
      "\n",
      "episode 9, val func loss 0.11880098283290863\n",
      "\n",
      "episode 10, val func loss 0.1620228886604309\n",
      "\n",
      "episode 11, val func loss 0.16636990010738373\n",
      "\n",
      "episode 12, val func loss 0.16436272859573364\n",
      "\n",
      "episode 13, val func loss 0.19093546271324158\n",
      "\n",
      "episode 14, val func loss 0.20198382437229156\n",
      "\n",
      "episode 15, val func loss 0.12191424518823624\n",
      "\n",
      "episode 16, val func loss 0.16871614754199982\n",
      "\n",
      "Val func train loss in epoch 11:0.1668429267592728\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1190178245306015\n",
      "\n",
      "episode 2, val func loss 0.16680492460727692\n",
      "\n",
      "episode 3, val func loss 0.16375838220119476\n",
      "\n",
      "episode 4, val func loss 0.16670414805412292\n",
      "\n",
      "episode 5, val func loss 0.17823824286460876\n",
      "\n",
      "episode 6, val func loss 0.19854307174682617\n",
      "\n",
      "episode 7, val func loss 0.19530101120471954\n",
      "\n",
      "episode 8, val func loss 0.16265267133712769\n",
      "\n",
      "episode 9, val func loss 0.17232076823711395\n",
      "\n",
      "episode 10, val func loss 0.1226741150021553\n",
      "\n",
      "episode 11, val func loss 0.13098149001598358\n",
      "\n",
      "episode 12, val func loss 0.16199319064617157\n",
      "\n",
      "episode 13, val func loss 0.18663007020950317\n",
      "\n",
      "episode 14, val func loss 0.220333993434906\n",
      "\n",
      "episode 15, val func loss 0.16710223257541656\n",
      "\n",
      "episode 16, val func loss 0.14862942695617676\n",
      "\n",
      "Val func train loss in epoch 12:0.16635534772649407\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1850062757730484\n",
      "\n",
      "episode 2, val func loss 0.14704084396362305\n",
      "\n",
      "episode 3, val func loss 0.19913308322429657\n",
      "\n",
      "episode 4, val func loss 0.11983166635036469\n",
      "\n",
      "episode 5, val func loss 0.17412471771240234\n",
      "\n",
      "episode 6, val func loss 0.13448014855384827\n",
      "\n",
      "episode 7, val func loss 0.19610007107257843\n",
      "\n",
      "episode 8, val func loss 0.16457849740982056\n",
      "\n",
      "episode 9, val func loss 0.22129523754119873\n",
      "\n",
      "episode 10, val func loss 0.16721998155117035\n",
      "\n",
      "episode 11, val func loss 0.16733555495738983\n",
      "\n",
      "episode 12, val func loss 0.1763351708650589\n",
      "\n",
      "episode 13, val func loss 0.1621856987476349\n",
      "\n",
      "episode 14, val func loss 0.16129422187805176\n",
      "\n",
      "episode 15, val func loss 0.12274853140115738\n",
      "\n",
      "episode 16, val func loss 0.1773403286933899\n",
      "\n",
      "Val func train loss in epoch 13:0.16725312685593963\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19748108088970184\n",
      "\n",
      "episode 2, val func loss 0.1641700565814972\n",
      "\n",
      "episode 3, val func loss 0.12223592400550842\n",
      "\n",
      "episode 4, val func loss 0.17437434196472168\n",
      "\n",
      "episode 5, val func loss 0.17784322798252106\n",
      "\n",
      "episode 6, val func loss 0.1996108442544937\n",
      "\n",
      "episode 7, val func loss 0.1484384536743164\n",
      "\n",
      "episode 8, val func loss 0.11891934275627136\n",
      "\n",
      "episode 9, val func loss 0.1834416389465332\n",
      "\n",
      "episode 10, val func loss 0.16741223633289337\n",
      "\n",
      "episode 11, val func loss 0.1720958799123764\n",
      "\n",
      "episode 12, val func loss 0.1690291166305542\n",
      "\n",
      "episode 13, val func loss 0.13142067193984985\n",
      "\n",
      "episode 14, val func loss 0.1622018814086914\n",
      "\n",
      "episode 15, val func loss 0.22191724181175232\n",
      "\n",
      "episode 16, val func loss 0.16159097850322723\n",
      "\n",
      "Val func train loss in epoch 14:0.16701143234968185\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.15218888223171234\n",
      "\n",
      "episode 2, val func loss 0.19784051179885864\n",
      "\n",
      "episode 3, val func loss 0.1757710874080658\n",
      "\n",
      "episode 4, val func loss 0.16626466810703278\n",
      "\n",
      "episode 5, val func loss 0.16208568215370178\n",
      "\n",
      "episode 6, val func loss 0.16394755244255066\n",
      "\n",
      "episode 7, val func loss 0.11762729287147522\n",
      "\n",
      "episode 8, val func loss 0.13069401681423187\n",
      "\n",
      "episode 9, val func loss 0.22021012008190155\n",
      "\n",
      "episode 10, val func loss 0.16669058799743652\n",
      "\n",
      "episode 11, val func loss 0.16374439001083374\n",
      "\n",
      "episode 12, val func loss 0.17805388569831848\n",
      "\n",
      "episode 13, val func loss 0.16715659201145172\n",
      "\n",
      "episode 14, val func loss 0.12233659625053406\n",
      "\n",
      "episode 15, val func loss 0.18862035870552063\n",
      "\n",
      "episode 16, val func loss 0.2004329264163971\n",
      "\n",
      "Val func train loss in epoch 15:0.16710407193750143\n",
      "***********************TIME WAS 5.191760679086049 min*****************************\n",
      "\n",
      "**********************ROUND 24 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.11712270975112915\n",
      "\n",
      "episode 2, policy loss -0.09077445417642593\n",
      "\n",
      "episode 3, policy loss -0.12396278977394104\n",
      "\n",
      "episode 4, policy loss -0.09516963362693787\n",
      "\n",
      "episode 5, policy loss -0.12428736686706543\n",
      "\n",
      "episode 6, policy loss -0.14121554791927338\n",
      "\n",
      "episode 7, policy loss -0.10226777195930481\n",
      "\n",
      "episode 8, policy loss -0.10640466958284378\n",
      "\n",
      "episode 9, policy loss -0.12047381699085236\n",
      "\n",
      "episode 10, policy loss -0.09046998620033264\n",
      "\n",
      "episode 11, policy loss -0.13319218158721924\n",
      "\n",
      "episode 12, policy loss -0.07715016603469849\n",
      "\n",
      "episode 13, policy loss -0.12817463278770447\n",
      "\n",
      "episode 14, policy loss -0.14094121754169464\n",
      "\n",
      "episode 15, policy loss -0.07377494126558304\n",
      "\n",
      "episode 16, policy loss -0.07445251941680908\n",
      "\n",
      "Policy train loss in epoch 0:-0.10873965034261346\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.10167950391769409\n",
      "\n",
      "episode 2, policy loss -0.10659214854240417\n",
      "\n",
      "episode 3, policy loss -0.08099699020385742\n",
      "\n",
      "episode 4, policy loss -0.0898827537894249\n",
      "\n",
      "episode 5, policy loss -0.13444676995277405\n",
      "\n",
      "episode 6, policy loss -0.10482446104288101\n",
      "\n",
      "episode 7, policy loss -0.07111500203609467\n",
      "\n",
      "episode 8, policy loss -0.1220998764038086\n",
      "\n",
      "episode 9, policy loss -0.12627550959587097\n",
      "\n",
      "episode 10, policy loss -0.1362724006175995\n",
      "\n",
      "episode 11, policy loss -0.13822641968727112\n",
      "\n",
      "episode 12, policy loss -0.11537817120552063\n",
      "\n",
      "episode 13, policy loss -0.09436910599470139\n",
      "\n",
      "episode 14, policy loss -0.07086852192878723\n",
      "\n",
      "episode 15, policy loss -0.12704822421073914\n",
      "\n",
      "episode 16, policy loss -0.11971166729927063\n",
      "\n",
      "Policy train loss in epoch 1:-0.10873672040179372\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.14457497000694275\n",
      "\n",
      "episode 2, policy loss -0.07926791906356812\n",
      "\n",
      "episode 3, policy loss -0.12093903869390488\n",
      "\n",
      "episode 4, policy loss -0.08785273879766464\n",
      "\n",
      "episode 5, policy loss -0.09426572173833847\n",
      "\n",
      "episode 6, policy loss -0.14044877886772156\n",
      "\n",
      "episode 7, policy loss -0.08215179294347763\n",
      "\n",
      "episode 8, policy loss -0.10538402199745178\n",
      "\n",
      "episode 9, policy loss -0.13642045855522156\n",
      "\n",
      "episode 10, policy loss -0.12384025007486343\n",
      "\n",
      "episode 11, policy loss -0.10637451708316803\n",
      "\n",
      "episode 12, policy loss -0.12658481299877167\n",
      "\n",
      "episode 13, policy loss -0.09052346646785736\n",
      "\n",
      "episode 14, policy loss -0.1269022673368454\n",
      "\n",
      "episode 15, policy loss -0.07282830029726028\n",
      "\n",
      "episode 16, policy loss -0.12082204222679138\n",
      "\n",
      "Policy train loss in epoch 2:-0.10994881857186556\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.07615616917610168\n",
      "\n",
      "episode 2, policy loss -0.10584983229637146\n",
      "\n",
      "episode 3, policy loss -0.10026829689741135\n",
      "\n",
      "episode 4, policy loss -0.07778234779834747\n",
      "\n",
      "episode 5, policy loss -0.14531126618385315\n",
      "\n",
      "episode 6, policy loss -0.11882489919662476\n",
      "\n",
      "episode 7, policy loss -0.13735643029212952\n",
      "\n",
      "episode 8, policy loss -0.14464862644672394\n",
      "\n",
      "episode 9, policy loss -0.12746179103851318\n",
      "\n",
      "episode 10, policy loss -0.09532954543828964\n",
      "\n",
      "episode 11, policy loss -0.12292739748954773\n",
      "\n",
      "episode 12, policy loss -0.08610078692436218\n",
      "\n",
      "episode 13, policy loss -0.10457435250282288\n",
      "\n",
      "episode 14, policy loss -0.07529214769601822\n",
      "\n",
      "episode 15, policy loss -0.1264415681362152\n",
      "\n",
      "episode 16, policy loss -0.12218979001045227\n",
      "\n",
      "Policy train loss in epoch 3:-0.11040720297023654\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1849973201751709\n",
      "\n",
      "episode 2, val func loss 0.17071136832237244\n",
      "\n",
      "episode 3, val func loss 0.18356752395629883\n",
      "\n",
      "episode 4, val func loss 0.16356930136680603\n",
      "\n",
      "episode 5, val func loss 0.12234891206026077\n",
      "\n",
      "episode 6, val func loss 0.1623140424489975\n",
      "\n",
      "episode 7, val func loss 0.1919974684715271\n",
      "\n",
      "episode 8, val func loss 0.1537109762430191\n",
      "\n",
      "episode 9, val func loss 0.16521748900413513\n",
      "\n",
      "episode 10, val func loss 0.17098276317119598\n",
      "\n",
      "episode 11, val func loss 0.1554465889930725\n",
      "\n",
      "episode 12, val func loss 0.1536862999200821\n",
      "\n",
      "episode 13, val func loss 0.17076757550239563\n",
      "\n",
      "episode 14, val func loss 0.13431191444396973\n",
      "\n",
      "episode 15, val func loss 0.19194814562797546\n",
      "\n",
      "episode 16, val func loss 0.18191756308078766\n",
      "\n",
      "Val func train loss in epoch 0:0.16609345329925418\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.15783098340034485\n",
      "\n",
      "episode 2, val func loss 0.1942318081855774\n",
      "\n",
      "episode 3, val func loss 0.17054049670696259\n",
      "\n",
      "episode 4, val func loss 0.1697586327791214\n",
      "\n",
      "episode 5, val func loss 0.1841305047273636\n",
      "\n",
      "episode 6, val func loss 0.18894411623477936\n",
      "\n",
      "episode 7, val func loss 0.17878828942775726\n",
      "\n",
      "episode 8, val func loss 0.1391310840845108\n",
      "\n",
      "episode 9, val func loss 0.1554407924413681\n",
      "\n",
      "episode 10, val func loss 0.15366311371326447\n",
      "\n",
      "episode 11, val func loss 0.1220916286110878\n",
      "\n",
      "episode 12, val func loss 0.16302283108234406\n",
      "\n",
      "episode 13, val func loss 0.16505074501037598\n",
      "\n",
      "episode 14, val func loss 0.184229776263237\n",
      "\n",
      "episode 15, val func loss 0.16408377885818481\n",
      "\n",
      "episode 16, val func loss 0.1682089865207672\n",
      "\n",
      "Val func train loss in epoch 1:0.16619672300294042\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.16465410590171814\n",
      "\n",
      "episode 2, val func loss 0.19493460655212402\n",
      "\n",
      "episode 3, val func loss 0.15361885726451874\n",
      "\n",
      "episode 4, val func loss 0.1694198101758957\n",
      "\n",
      "episode 5, val func loss 0.18378125131130219\n",
      "\n",
      "episode 6, val func loss 0.1783709079027176\n",
      "\n",
      "episode 7, val func loss 0.1904754638671875\n",
      "\n",
      "episode 8, val func loss 0.1536531001329422\n",
      "\n",
      "episode 9, val func loss 0.13848909735679626\n",
      "\n",
      "episode 10, val func loss 0.16330093145370483\n",
      "\n",
      "episode 11, val func loss 0.12173625081777573\n",
      "\n",
      "episode 12, val func loss 0.16368664801120758\n",
      "\n",
      "episode 13, val func loss 0.16940903663635254\n",
      "\n",
      "episode 14, val func loss 0.1850142925977707\n",
      "\n",
      "episode 15, val func loss 0.16755399107933044\n",
      "\n",
      "episode 16, val func loss 0.15846695005893707\n",
      "\n",
      "Val func train loss in epoch 2:0.16603533132001758\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1908203661441803\n",
      "\n",
      "episode 2, val func loss 0.15401741862297058\n",
      "\n",
      "episode 3, val func loss 0.18339532613754272\n",
      "\n",
      "episode 4, val func loss 0.15516531467437744\n",
      "\n",
      "episode 5, val func loss 0.1562347710132599\n",
      "\n",
      "episode 6, val func loss 0.18530499935150146\n",
      "\n",
      "episode 7, val func loss 0.17081259191036224\n",
      "\n",
      "episode 8, val func loss 0.1217123344540596\n",
      "\n",
      "episode 9, val func loss 0.16259975731372833\n",
      "\n",
      "episode 10, val func loss 0.18495331704616547\n",
      "\n",
      "episode 11, val func loss 0.141696035861969\n",
      "\n",
      "episode 12, val func loss 0.17811080813407898\n",
      "\n",
      "episode 13, val func loss 0.169620543718338\n",
      "\n",
      "episode 14, val func loss 0.16286230087280273\n",
      "\n",
      "episode 15, val func loss 0.16573520004749298\n",
      "\n",
      "episode 16, val func loss 0.19633838534355164\n",
      "\n",
      "Val func train loss in epoch 3:0.16746121691539884\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.16440585255622864\n",
      "\n",
      "episode 2, val func loss 0.17885370552539825\n",
      "\n",
      "episode 3, val func loss 0.1534721404314041\n",
      "\n",
      "episode 4, val func loss 0.1265888512134552\n",
      "\n",
      "episode 5, val func loss 0.1765366941690445\n",
      "\n",
      "episode 6, val func loss 0.18978764116764069\n",
      "\n",
      "episode 7, val func loss 0.18470147252082825\n",
      "\n",
      "episode 8, val func loss 0.1535395383834839\n",
      "\n",
      "episode 9, val func loss 0.1624625027179718\n",
      "\n",
      "episode 10, val func loss 0.17050422728061676\n",
      "\n",
      "episode 11, val func loss 0.19358426332473755\n",
      "\n",
      "episode 12, val func loss 0.15569870173931122\n",
      "\n",
      "episode 13, val func loss 0.14087948203086853\n",
      "\n",
      "episode 14, val func loss 0.16542412340641022\n",
      "\n",
      "episode 15, val func loss 0.18480284512043\n",
      "\n",
      "episode 16, val func loss 0.16759321093559265\n",
      "\n",
      "Val func train loss in epoch 4:0.1668022032827139\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.15738701820373535\n",
      "\n",
      "episode 2, val func loss 0.1340997964143753\n",
      "\n",
      "episode 3, val func loss 0.15380141139030457\n",
      "\n",
      "episode 4, val func loss 0.16916319727897644\n",
      "\n",
      "episode 5, val func loss 0.1954677253961563\n",
      "\n",
      "episode 6, val func loss 0.167457714676857\n",
      "\n",
      "episode 7, val func loss 0.16197295486927032\n",
      "\n",
      "episode 8, val func loss 0.17061369121074677\n",
      "\n",
      "episode 9, val func loss 0.12204064428806305\n",
      "\n",
      "episode 10, val func loss 0.18404975533485413\n",
      "\n",
      "episode 11, val func loss 0.18515674769878387\n",
      "\n",
      "episode 12, val func loss 0.18965423107147217\n",
      "\n",
      "episode 13, val func loss 0.15421999990940094\n",
      "\n",
      "episode 14, val func loss 0.16273412108421326\n",
      "\n",
      "episode 15, val func loss 0.17922963201999664\n",
      "\n",
      "episode 16, val func loss 0.16610820591449738\n",
      "\n",
      "Val func train loss in epoch 5:0.16582230292260647\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.16233544051647186\n",
      "\n",
      "episode 2, val func loss 0.15373735129833221\n",
      "\n",
      "episode 3, val func loss 0.16439706087112427\n",
      "\n",
      "episode 4, val func loss 0.18421567976474762\n",
      "\n",
      "episode 5, val func loss 0.15699614584445953\n",
      "\n",
      "episode 6, val func loss 0.13381654024124146\n",
      "\n",
      "episode 7, val func loss 0.19380006194114685\n",
      "\n",
      "episode 8, val func loss 0.18444865942001343\n",
      "\n",
      "episode 9, val func loss 0.1701786071062088\n",
      "\n",
      "episode 10, val func loss 0.1898966282606125\n",
      "\n",
      "episode 11, val func loss 0.12284447252750397\n",
      "\n",
      "episode 12, val func loss 0.16272954642772675\n",
      "\n",
      "episode 13, val func loss 0.17895595729351044\n",
      "\n",
      "episode 14, val func loss 0.15386202931404114\n",
      "\n",
      "episode 15, val func loss 0.17091265320777893\n",
      "\n",
      "episode 16, val func loss 0.17173457145690918\n",
      "\n",
      "Val func train loss in epoch 6:0.1659288378432393\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.16367840766906738\n",
      "\n",
      "episode 2, val func loss 0.1535681039094925\n",
      "\n",
      "episode 3, val func loss 0.12198267132043839\n",
      "\n",
      "episode 4, val func loss 0.16782769560813904\n",
      "\n",
      "episode 5, val func loss 0.18871064484119415\n",
      "\n",
      "episode 6, val func loss 0.15844941139221191\n",
      "\n",
      "episode 7, val func loss 0.18077382445335388\n",
      "\n",
      "episode 8, val func loss 0.16267859935760498\n",
      "\n",
      "episode 9, val func loss 0.1893414705991745\n",
      "\n",
      "episode 10, val func loss 0.15376846492290497\n",
      "\n",
      "episode 11, val func loss 0.191242516040802\n",
      "\n",
      "episode 12, val func loss 0.17850375175476074\n",
      "\n",
      "episode 13, val func loss 0.1853027641773224\n",
      "\n",
      "episode 14, val func loss 0.13745282590389252\n",
      "\n",
      "episode 15, val func loss 0.16545598208904266\n",
      "\n",
      "episode 16, val func loss 0.1698138266801834\n",
      "\n",
      "Val func train loss in epoch 7:0.1667844350449741\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.15801061689853668\n",
      "\n",
      "episode 2, val func loss 0.18604198098182678\n",
      "\n",
      "episode 3, val func loss 0.1824043095111847\n",
      "\n",
      "episode 4, val func loss 0.15420152246952057\n",
      "\n",
      "episode 5, val func loss 0.19101890921592712\n",
      "\n",
      "episode 6, val func loss 0.16484574973583221\n",
      "\n",
      "episode 7, val func loss 0.1913841962814331\n",
      "\n",
      "episode 8, val func loss 0.13803857564926147\n",
      "\n",
      "episode 9, val func loss 0.1538284718990326\n",
      "\n",
      "episode 10, val func loss 0.16257856786251068\n",
      "\n",
      "episode 11, val func loss 0.17378844320774078\n",
      "\n",
      "episode 12, val func loss 0.17062526941299438\n",
      "\n",
      "episode 13, val func loss 0.18418920040130615\n",
      "\n",
      "episode 14, val func loss 0.16775770485401154\n",
      "\n",
      "episode 15, val func loss 0.16223621368408203\n",
      "\n",
      "episode 16, val func loss 0.12198065221309662\n",
      "\n",
      "Val func train loss in epoch 8:0.1664331490173936\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.15386246144771576\n",
      "\n",
      "episode 2, val func loss 0.18790581822395325\n",
      "\n",
      "episode 3, val func loss 0.19108012318611145\n",
      "\n",
      "episode 4, val func loss 0.17043961584568024\n",
      "\n",
      "episode 5, val func loss 0.12217001616954803\n",
      "\n",
      "episode 6, val func loss 0.1701316386461258\n",
      "\n",
      "episode 7, val func loss 0.1648896038532257\n",
      "\n",
      "episode 8, val func loss 0.19249580800533295\n",
      "\n",
      "episode 9, val func loss 0.183684304356575\n",
      "\n",
      "episode 10, val func loss 0.13610118627548218\n",
      "\n",
      "episode 11, val func loss 0.1692861020565033\n",
      "\n",
      "episode 12, val func loss 0.17896324396133423\n",
      "\n",
      "episode 13, val func loss 0.16225489974021912\n",
      "\n",
      "episode 14, val func loss 0.1630164533853531\n",
      "\n",
      "episode 15, val func loss 0.15659993886947632\n",
      "\n",
      "episode 16, val func loss 0.15443947911262512\n",
      "\n",
      "Val func train loss in epoch 9:0.16608254332095385\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1559717059135437\n",
      "\n",
      "episode 2, val func loss 0.19221942126750946\n",
      "\n",
      "episode 3, val func loss 0.16636422276496887\n",
      "\n",
      "episode 4, val func loss 0.17847663164138794\n",
      "\n",
      "episode 5, val func loss 0.1703300178050995\n",
      "\n",
      "episode 6, val func loss 0.1559162735939026\n",
      "\n",
      "episode 7, val func loss 0.1637362390756607\n",
      "\n",
      "episode 8, val func loss 0.1626029908657074\n",
      "\n",
      "episode 9, val func loss 0.1712794303894043\n",
      "\n",
      "episode 10, val func loss 0.1335313469171524\n",
      "\n",
      "episode 11, val func loss 0.15600639581680298\n",
      "\n",
      "episode 12, val func loss 0.18910498917102814\n",
      "\n",
      "episode 13, val func loss 0.1927894800901413\n",
      "\n",
      "episode 14, val func loss 0.185099259018898\n",
      "\n",
      "episode 15, val func loss 0.16820693016052246\n",
      "\n",
      "episode 16, val func loss 0.12156518548727036\n",
      "\n",
      "Val func train loss in epoch 10:0.1664500324986875\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16545920073986053\n",
      "\n",
      "episode 2, val func loss 0.17297643423080444\n",
      "\n",
      "episode 3, val func loss 0.15383930504322052\n",
      "\n",
      "episode 4, val func loss 0.1787288784980774\n",
      "\n",
      "episode 5, val func loss 0.1844322830438614\n",
      "\n",
      "episode 6, val func loss 0.1365194469690323\n",
      "\n",
      "episode 7, val func loss 0.15554076433181763\n",
      "\n",
      "episode 8, val func loss 0.18925312161445618\n",
      "\n",
      "episode 9, val func loss 0.12184283137321472\n",
      "\n",
      "episode 10, val func loss 0.1693141758441925\n",
      "\n",
      "episode 11, val func loss 0.16299757361412048\n",
      "\n",
      "episode 12, val func loss 0.15397070348262787\n",
      "\n",
      "episode 13, val func loss 0.16268381476402283\n",
      "\n",
      "episode 14, val func loss 0.1836252063512802\n",
      "\n",
      "episode 15, val func loss 0.16887180507183075\n",
      "\n",
      "episode 16, val func loss 0.19382309913635254\n",
      "\n",
      "Val func train loss in epoch 11:0.16586741525679827\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17979638278484344\n",
      "\n",
      "episode 2, val func loss 0.17005470395088196\n",
      "\n",
      "episode 3, val func loss 0.15406185388565063\n",
      "\n",
      "episode 4, val func loss 0.18412308394908905\n",
      "\n",
      "episode 5, val func loss 0.18974153697490692\n",
      "\n",
      "episode 6, val func loss 0.15575848519802094\n",
      "\n",
      "episode 7, val func loss 0.17443032562732697\n",
      "\n",
      "episode 8, val func loss 0.16998586058616638\n",
      "\n",
      "episode 9, val func loss 0.15396012365818024\n",
      "\n",
      "episode 10, val func loss 0.13468298316001892\n",
      "\n",
      "episode 11, val func loss 0.12228601425886154\n",
      "\n",
      "episode 12, val func loss 0.1630917340517044\n",
      "\n",
      "episode 13, val func loss 0.1656631976366043\n",
      "\n",
      "episode 14, val func loss 0.16622386872768402\n",
      "\n",
      "episode 15, val func loss 0.19669494032859802\n",
      "\n",
      "episode 16, val func loss 0.18445181846618652\n",
      "\n",
      "Val func train loss in epoch 12:0.16656293207779527\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1627558171749115\n",
      "\n",
      "episode 2, val func loss 0.17856574058532715\n",
      "\n",
      "episode 3, val func loss 0.14010949432849884\n",
      "\n",
      "episode 4, val func loss 0.12354467809200287\n",
      "\n",
      "episode 5, val func loss 0.19158633053302765\n",
      "\n",
      "episode 6, val func loss 0.17462502419948578\n",
      "\n",
      "episode 7, val func loss 0.15408772230148315\n",
      "\n",
      "episode 8, val func loss 0.169525146484375\n",
      "\n",
      "episode 9, val func loss 0.19063949584960938\n",
      "\n",
      "episode 10, val func loss 0.16748525202274323\n",
      "\n",
      "episode 11, val func loss 0.16528445482254028\n",
      "\n",
      "episode 12, val func loss 0.15698552131652832\n",
      "\n",
      "episode 13, val func loss 0.18605858087539673\n",
      "\n",
      "episode 14, val func loss 0.15711678564548492\n",
      "\n",
      "episode 15, val func loss 0.1841043382883072\n",
      "\n",
      "episode 16, val func loss 0.16509032249450684\n",
      "\n",
      "Val func train loss in epoch 13:0.1667227940633893\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.15572471916675568\n",
      "\n",
      "episode 2, val func loss 0.1705065220594406\n",
      "\n",
      "episode 3, val func loss 0.16502158343791962\n",
      "\n",
      "episode 4, val func loss 0.12212122231721878\n",
      "\n",
      "episode 5, val func loss 0.18439853191375732\n",
      "\n",
      "episode 6, val func loss 0.16231341660022736\n",
      "\n",
      "episode 7, val func loss 0.15624672174453735\n",
      "\n",
      "episode 8, val func loss 0.1344369500875473\n",
      "\n",
      "episode 9, val func loss 0.19366198778152466\n",
      "\n",
      "episode 10, val func loss 0.18959595263004303\n",
      "\n",
      "episode 11, val func loss 0.1788945198059082\n",
      "\n",
      "episode 12, val func loss 0.15674273669719696\n",
      "\n",
      "episode 13, val func loss 0.1712697446346283\n",
      "\n",
      "episode 14, val func loss 0.18477249145507812\n",
      "\n",
      "episode 15, val func loss 0.17083363234996796\n",
      "\n",
      "episode 16, val func loss 0.1631895899772644\n",
      "\n",
      "Val func train loss in epoch 14:0.16623314516618848\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18602412939071655\n",
      "\n",
      "episode 2, val func loss 0.1702520251274109\n",
      "\n",
      "episode 3, val func loss 0.16958454251289368\n",
      "\n",
      "episode 4, val func loss 0.17056001722812653\n",
      "\n",
      "episode 5, val func loss 0.13348431885242462\n",
      "\n",
      "episode 6, val func loss 0.16538062691688538\n",
      "\n",
      "episode 7, val func loss 0.18628740310668945\n",
      "\n",
      "episode 8, val func loss 0.19462838768959045\n",
      "\n",
      "episode 9, val func loss 0.15603694319725037\n",
      "\n",
      "episode 10, val func loss 0.12603451311588287\n",
      "\n",
      "episode 11, val func loss 0.1553560495376587\n",
      "\n",
      "episode 12, val func loss 0.16223140060901642\n",
      "\n",
      "episode 13, val func loss 0.18068762123584747\n",
      "\n",
      "episode 14, val func loss 0.16356118023395538\n",
      "\n",
      "episode 15, val func loss 0.15408316254615784\n",
      "\n",
      "episode 16, val func loss 0.19028663635253906\n",
      "\n",
      "Val func train loss in epoch 15:0.16652993485331535\n",
      "***********************TIME WAS 5.2258472561836244 min*****************************\n",
      "\n",
      "**********************ROUND 25 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.10200168192386627\n",
      "\n",
      "episode 2, policy loss -0.051563262939453125\n",
      "\n",
      "episode 3, policy loss -0.09937610477209091\n",
      "\n",
      "episode 4, policy loss -0.08154579997062683\n",
      "\n",
      "episode 5, policy loss -0.08610005676746368\n",
      "\n",
      "episode 6, policy loss -0.09040901064872742\n",
      "\n",
      "episode 7, policy loss -0.04111604392528534\n",
      "\n",
      "episode 8, policy loss -0.09750419110059738\n",
      "\n",
      "episode 9, policy loss -0.10324284434318542\n",
      "\n",
      "episode 10, policy loss -0.11847317218780518\n",
      "\n",
      "episode 11, policy loss -0.0826558917760849\n",
      "\n",
      "episode 12, policy loss -0.06554628908634186\n",
      "\n",
      "episode 13, policy loss -0.09731719642877579\n",
      "\n",
      "episode 14, policy loss -0.10829485952854156\n",
      "\n",
      "episode 15, policy loss -0.09285192936658859\n",
      "\n",
      "episode 16, policy loss -0.06392732262611389\n",
      "\n",
      "Policy train loss in epoch 0:-0.08637035358697176\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.09851427376270294\n",
      "\n",
      "episode 2, policy loss -0.04132147133350372\n",
      "\n",
      "episode 3, policy loss -0.12009068578481674\n",
      "\n",
      "episode 4, policy loss -0.07999672740697861\n",
      "\n",
      "episode 5, policy loss -0.09287421405315399\n",
      "\n",
      "episode 6, policy loss -0.09952202439308167\n",
      "\n",
      "episode 7, policy loss -0.06307236850261688\n",
      "\n",
      "episode 8, policy loss -0.0867224931716919\n",
      "\n",
      "episode 9, policy loss -0.0871957466006279\n",
      "\n",
      "episode 10, policy loss -0.0664910078048706\n",
      "\n",
      "episode 11, policy loss -0.09304799884557724\n",
      "\n",
      "episode 12, policy loss -0.10349207371473312\n",
      "\n",
      "episode 13, policy loss -0.11009591817855835\n",
      "\n",
      "episode 14, policy loss -0.08435975760221481\n",
      "\n",
      "episode 15, policy loss -0.05070256441831589\n",
      "\n",
      "episode 16, policy loss -0.10403874516487122\n",
      "\n",
      "Policy train loss in epoch 1:-0.08634612942114472\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.10797646641731262\n",
      "\n",
      "episode 2, policy loss -0.06588313728570938\n",
      "\n",
      "episode 3, policy loss -0.0813838317990303\n",
      "\n",
      "episode 4, policy loss -0.10261854529380798\n",
      "\n",
      "episode 5, policy loss -0.062285229563713074\n",
      "\n",
      "episode 6, policy loss -0.05054423213005066\n",
      "\n",
      "episode 7, policy loss -0.094813272356987\n",
      "\n",
      "episode 8, policy loss -0.09699953347444534\n",
      "\n",
      "episode 9, policy loss -0.08373512327671051\n",
      "\n",
      "episode 10, policy loss -0.1108342856168747\n",
      "\n",
      "episode 11, policy loss -0.09751810133457184\n",
      "\n",
      "episode 12, policy loss -0.09744282811880112\n",
      "\n",
      "episode 13, policy loss -0.1002947986125946\n",
      "\n",
      "episode 14, policy loss -0.1237640380859375\n",
      "\n",
      "episode 15, policy loss -0.08558665215969086\n",
      "\n",
      "episode 16, policy loss -0.04213634878396988\n",
      "\n",
      "Policy train loss in epoch 2:-0.08773852651938796\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.08583441376686096\n",
      "\n",
      "episode 2, policy loss -0.12140966951847076\n",
      "\n",
      "episode 3, policy loss -0.10939197242259979\n",
      "\n",
      "episode 4, policy loss -0.0508401058614254\n",
      "\n",
      "episode 5, policy loss -0.09716277569532394\n",
      "\n",
      "episode 6, policy loss -0.08372477442026138\n",
      "\n",
      "episode 7, policy loss -0.03992509841918945\n",
      "\n",
      "episode 8, policy loss -0.0930466502904892\n",
      "\n",
      "episode 9, policy loss -0.10376997292041779\n",
      "\n",
      "episode 10, policy loss -0.10616735368967056\n",
      "\n",
      "episode 11, policy loss -0.0995456725358963\n",
      "\n",
      "episode 12, policy loss -0.06418026983737946\n",
      "\n",
      "episode 13, policy loss -0.08735370635986328\n",
      "\n",
      "episode 14, policy loss -0.06208030879497528\n",
      "\n",
      "episode 15, policy loss -0.09425806999206543\n",
      "\n",
      "episode 16, policy loss -0.09735624492168427\n",
      "\n",
      "Policy train loss in epoch 3:-0.08725294121541083\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1619446575641632\n",
      "\n",
      "episode 2, val func loss 0.19474759697914124\n",
      "\n",
      "episode 3, val func loss 0.20580536127090454\n",
      "\n",
      "episode 4, val func loss 0.15277411043643951\n",
      "\n",
      "episode 5, val func loss 0.15113045275211334\n",
      "\n",
      "episode 6, val func loss 0.18936190009117126\n",
      "\n",
      "episode 7, val func loss 0.17246955633163452\n",
      "\n",
      "episode 8, val func loss 0.19019675254821777\n",
      "\n",
      "episode 9, val func loss 0.13912400603294373\n",
      "\n",
      "episode 10, val func loss 0.1600187122821808\n",
      "\n",
      "episode 11, val func loss 0.1846126914024353\n",
      "\n",
      "episode 12, val func loss 0.18785662949085236\n",
      "\n",
      "episode 13, val func loss 0.13975343108177185\n",
      "\n",
      "episode 14, val func loss 0.17441579699516296\n",
      "\n",
      "episode 15, val func loss 0.1950373649597168\n",
      "\n",
      "episode 16, val func loss 0.17940260469913483\n",
      "\n",
      "Val func train loss in epoch 0:0.173665726557374\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1618318408727646\n",
      "\n",
      "episode 2, val func loss 0.173369899392128\n",
      "\n",
      "episode 3, val func loss 0.17932046949863434\n",
      "\n",
      "episode 4, val func loss 0.18969842791557312\n",
      "\n",
      "episode 5, val func loss 0.19416213035583496\n",
      "\n",
      "episode 6, val func loss 0.18980799615383148\n",
      "\n",
      "episode 7, val func loss 0.20572814345359802\n",
      "\n",
      "episode 8, val func loss 0.1524929255247116\n",
      "\n",
      "episode 9, val func loss 0.15032920241355896\n",
      "\n",
      "episode 10, val func loss 0.18651226162910461\n",
      "\n",
      "episode 11, val func loss 0.17313998937606812\n",
      "\n",
      "episode 12, val func loss 0.18521487712860107\n",
      "\n",
      "episode 13, val func loss 0.13828352093696594\n",
      "\n",
      "episode 14, val func loss 0.1392143815755844\n",
      "\n",
      "episode 15, val func loss 0.16036026179790497\n",
      "\n",
      "episode 16, val func loss 0.1946018934249878\n",
      "\n",
      "Val func train loss in epoch 1:0.17337926384061575\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1793077290058136\n",
      "\n",
      "episode 2, val func loss 0.17246508598327637\n",
      "\n",
      "episode 3, val func loss 0.18543878197669983\n",
      "\n",
      "episode 4, val func loss 0.19483667612075806\n",
      "\n",
      "episode 5, val func loss 0.18978175520896912\n",
      "\n",
      "episode 6, val func loss 0.16025806963443756\n",
      "\n",
      "episode 7, val func loss 0.1902981698513031\n",
      "\n",
      "episode 8, val func loss 0.19510987401008606\n",
      "\n",
      "episode 9, val func loss 0.15311378240585327\n",
      "\n",
      "episode 10, val func loss 0.15109673142433167\n",
      "\n",
      "episode 11, val func loss 0.2063618153333664\n",
      "\n",
      "episode 12, val func loss 0.17560121417045593\n",
      "\n",
      "episode 13, val func loss 0.1383257508277893\n",
      "\n",
      "episode 14, val func loss 0.1610681563615799\n",
      "\n",
      "episode 15, val func loss 0.1857210248708725\n",
      "\n",
      "episode 16, val func loss 0.13967005908489227\n",
      "\n",
      "Val func train loss in epoch 2:0.1736534172669053\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19435934722423553\n",
      "\n",
      "episode 2, val func loss 0.13893014192581177\n",
      "\n",
      "episode 3, val func loss 0.1394997239112854\n",
      "\n",
      "episode 4, val func loss 0.16110923886299133\n",
      "\n",
      "episode 5, val func loss 0.19463613629341125\n",
      "\n",
      "episode 6, val func loss 0.17319759726524353\n",
      "\n",
      "episode 7, val func loss 0.18950514495372772\n",
      "\n",
      "episode 8, val func loss 0.20639735460281372\n",
      "\n",
      "episode 9, val func loss 0.1503409892320633\n",
      "\n",
      "episode 10, val func loss 0.1741066575050354\n",
      "\n",
      "episode 11, val func loss 0.18451043963432312\n",
      "\n",
      "episode 12, val func loss 0.18486209213733673\n",
      "\n",
      "episode 13, val func loss 0.15914443135261536\n",
      "\n",
      "episode 14, val func loss 0.18977460265159607\n",
      "\n",
      "episode 15, val func loss 0.17907612025737762\n",
      "\n",
      "episode 16, val func loss 0.15330387651920319\n",
      "\n",
      "Val func train loss in epoch 3:0.17329711839556694\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18941769003868103\n",
      "\n",
      "episode 2, val func loss 0.14966091513633728\n",
      "\n",
      "episode 3, val func loss 0.17621776461601257\n",
      "\n",
      "episode 4, val func loss 0.1960046887397766\n",
      "\n",
      "episode 5, val func loss 0.18018431961536407\n",
      "\n",
      "episode 6, val func loss 0.13806268572807312\n",
      "\n",
      "episode 7, val func loss 0.17250820994377136\n",
      "\n",
      "episode 8, val func loss 0.1946602314710617\n",
      "\n",
      "episode 9, val func loss 0.1400495022535324\n",
      "\n",
      "episode 10, val func loss 0.15912023186683655\n",
      "\n",
      "episode 11, val func loss 0.18552350997924805\n",
      "\n",
      "episode 12, val func loss 0.19013361632823944\n",
      "\n",
      "episode 13, val func loss 0.20553337037563324\n",
      "\n",
      "episode 14, val func loss 0.1847555786371231\n",
      "\n",
      "episode 15, val func loss 0.161559596657753\n",
      "\n",
      "episode 16, val func loss 0.15313851833343506\n",
      "\n",
      "Val func train loss in epoch 4:0.1735331518575549\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1946171373128891\n",
      "\n",
      "episode 2, val func loss 0.1499994546175003\n",
      "\n",
      "episode 3, val func loss 0.1383582204580307\n",
      "\n",
      "episode 4, val func loss 0.19703568518161774\n",
      "\n",
      "episode 5, val func loss 0.17333826422691345\n",
      "\n",
      "episode 6, val func loss 0.1858813762664795\n",
      "\n",
      "episode 7, val func loss 0.1873399168252945\n",
      "\n",
      "episode 8, val func loss 0.19029536843299866\n",
      "\n",
      "episode 9, val func loss 0.15940512716770172\n",
      "\n",
      "episode 10, val func loss 0.1408270001411438\n",
      "\n",
      "episode 11, val func loss 0.17973804473876953\n",
      "\n",
      "episode 12, val func loss 0.16195718944072723\n",
      "\n",
      "episode 13, val func loss 0.17274053394794464\n",
      "\n",
      "episode 14, val func loss 0.19005349278450012\n",
      "\n",
      "episode 15, val func loss 0.2047886699438095\n",
      "\n",
      "episode 16, val func loss 0.15306200087070465\n",
      "\n",
      "Val func train loss in epoch 5:0.17371484264731407\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.20509518682956696\n",
      "\n",
      "episode 2, val func loss 0.13915686309337616\n",
      "\n",
      "episode 3, val func loss 0.1735098958015442\n",
      "\n",
      "episode 4, val func loss 0.1723199337720871\n",
      "\n",
      "episode 5, val func loss 0.18560169637203217\n",
      "\n",
      "episode 6, val func loss 0.18492358922958374\n",
      "\n",
      "episode 7, val func loss 0.1597919762134552\n",
      "\n",
      "episode 8, val func loss 0.19431628286838531\n",
      "\n",
      "episode 9, val func loss 0.16212810575962067\n",
      "\n",
      "episode 10, val func loss 0.19019003212451935\n",
      "\n",
      "episode 11, val func loss 0.19471575319766998\n",
      "\n",
      "episode 12, val func loss 0.15182913839817047\n",
      "\n",
      "episode 13, val func loss 0.19036810100078583\n",
      "\n",
      "episode 14, val func loss 0.14934280514717102\n",
      "\n",
      "episode 15, val func loss 0.1798979789018631\n",
      "\n",
      "episode 16, val func loss 0.13964532315731049\n",
      "\n",
      "Val func train loss in epoch 6:0.17330204136669636\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18977414071559906\n",
      "\n",
      "episode 2, val func loss 0.14824533462524414\n",
      "\n",
      "episode 3, val func loss 0.19162414968013763\n",
      "\n",
      "episode 4, val func loss 0.207757830619812\n",
      "\n",
      "episode 5, val func loss 0.15184490382671356\n",
      "\n",
      "episode 6, val func loss 0.1592850685119629\n",
      "\n",
      "episode 7, val func loss 0.1860640048980713\n",
      "\n",
      "episode 8, val func loss 0.1736675649881363\n",
      "\n",
      "episode 9, val func loss 0.1624838411808014\n",
      "\n",
      "episode 10, val func loss 0.17221395671367645\n",
      "\n",
      "episode 11, val func loss 0.17923413217067719\n",
      "\n",
      "episode 12, val func loss 0.1396891474723816\n",
      "\n",
      "episode 13, val func loss 0.1389557421207428\n",
      "\n",
      "episode 14, val func loss 0.19585983455181122\n",
      "\n",
      "episode 15, val func loss 0.1863127201795578\n",
      "\n",
      "episode 16, val func loss 0.19585062563419342\n",
      "\n",
      "Val func train loss in epoch 7:0.17367893736809492\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16042877733707428\n",
      "\n",
      "episode 2, val func loss 0.17278669774532318\n",
      "\n",
      "episode 3, val func loss 0.14007169008255005\n",
      "\n",
      "episode 4, val func loss 0.19023670256137848\n",
      "\n",
      "episode 5, val func loss 0.15165109932422638\n",
      "\n",
      "episode 6, val func loss 0.19531896710395813\n",
      "\n",
      "episode 7, val func loss 0.18572579324245453\n",
      "\n",
      "episode 8, val func loss 0.13793011009693146\n",
      "\n",
      "episode 9, val func loss 0.17522358894348145\n",
      "\n",
      "episode 10, val func loss 0.1527012288570404\n",
      "\n",
      "episode 11, val func loss 0.160734161734581\n",
      "\n",
      "episode 12, val func loss 0.19041888415813446\n",
      "\n",
      "episode 13, val func loss 0.18438947200775146\n",
      "\n",
      "episode 14, val func loss 0.20510829985141754\n",
      "\n",
      "episode 15, val func loss 0.19440141320228577\n",
      "\n",
      "episode 16, val func loss 0.1795889437198639\n",
      "\n",
      "Val func train loss in epoch 8:0.17354473937302828\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.19490043818950653\n",
      "\n",
      "episode 2, val func loss 0.16199161112308502\n",
      "\n",
      "episode 3, val func loss 0.18943656980991364\n",
      "\n",
      "episode 4, val func loss 0.1597578525543213\n",
      "\n",
      "episode 5, val func loss 0.19451485574245453\n",
      "\n",
      "episode 6, val func loss 0.15219978988170624\n",
      "\n",
      "episode 7, val func loss 0.1392689049243927\n",
      "\n",
      "episode 8, val func loss 0.18509046733379364\n",
      "\n",
      "episode 9, val func loss 0.20735405385494232\n",
      "\n",
      "episode 10, val func loss 0.13853143155574799\n",
      "\n",
      "episode 11, val func loss 0.18949301540851593\n",
      "\n",
      "episode 12, val func loss 0.17323748767375946\n",
      "\n",
      "episode 13, val func loss 0.17904295027256012\n",
      "\n",
      "episode 14, val func loss 0.18477122485637665\n",
      "\n",
      "episode 15, val func loss 0.15113721787929535\n",
      "\n",
      "episode 16, val func loss 0.17325711250305176\n",
      "\n",
      "Val func train loss in epoch 9:0.17337406147271395\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.17355769872665405\n",
      "\n",
      "episode 2, val func loss 0.15259066224098206\n",
      "\n",
      "episode 3, val func loss 0.13985952734947205\n",
      "\n",
      "episode 4, val func loss 0.17255425453186035\n",
      "\n",
      "episode 5, val func loss 0.20577426254749298\n",
      "\n",
      "episode 6, val func loss 0.19453445076942444\n",
      "\n",
      "episode 7, val func loss 0.1858617216348648\n",
      "\n",
      "episode 8, val func loss 0.18938270211219788\n",
      "\n",
      "episode 9, val func loss 0.1902950406074524\n",
      "\n",
      "episode 10, val func loss 0.17939753830432892\n",
      "\n",
      "episode 11, val func loss 0.1946324110031128\n",
      "\n",
      "episode 12, val func loss 0.1508321911096573\n",
      "\n",
      "episode 13, val func loss 0.18501894176006317\n",
      "\n",
      "episode 14, val func loss 0.1379053294658661\n",
      "\n",
      "episode 15, val func loss 0.16195666790008545\n",
      "\n",
      "episode 16, val func loss 0.1628713309764862\n",
      "\n",
      "Val func train loss in epoch 10:0.17356404569000006\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1614847183227539\n",
      "\n",
      "episode 2, val func loss 0.190027117729187\n",
      "\n",
      "episode 3, val func loss 0.1854812055826187\n",
      "\n",
      "episode 4, val func loss 0.19493712484836578\n",
      "\n",
      "episode 5, val func loss 0.19605451822280884\n",
      "\n",
      "episode 6, val func loss 0.17212709784507751\n",
      "\n",
      "episode 7, val func loss 0.18117494881153107\n",
      "\n",
      "episode 8, val func loss 0.15535703301429749\n",
      "\n",
      "episode 9, val func loss 0.16136561334133148\n",
      "\n",
      "episode 10, val func loss 0.20805910229682922\n",
      "\n",
      "episode 11, val func loss 0.17283225059509277\n",
      "\n",
      "episode 12, val func loss 0.14918829500675201\n",
      "\n",
      "episode 13, val func loss 0.13883696496486664\n",
      "\n",
      "episode 14, val func loss 0.13830989599227905\n",
      "\n",
      "episode 15, val func loss 0.19016709923744202\n",
      "\n",
      "episode 16, val func loss 0.18576541543006897\n",
      "\n",
      "Val func train loss in epoch 11:0.1738230250775814\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19603219628334045\n",
      "\n",
      "episode 2, val func loss 0.13891777396202087\n",
      "\n",
      "episode 3, val func loss 0.17899486422538757\n",
      "\n",
      "episode 4, val func loss 0.18564468622207642\n",
      "\n",
      "episode 5, val func loss 0.15151822566986084\n",
      "\n",
      "episode 6, val func loss 0.18982510268688202\n",
      "\n",
      "episode 7, val func loss 0.15247522294521332\n",
      "\n",
      "episode 8, val func loss 0.20734456181526184\n",
      "\n",
      "episode 9, val func loss 0.16105931997299194\n",
      "\n",
      "episode 10, val func loss 0.1604105830192566\n",
      "\n",
      "episode 11, val func loss 0.19024738669395447\n",
      "\n",
      "episode 12, val func loss 0.1741122454404831\n",
      "\n",
      "episode 13, val func loss 0.1944585144519806\n",
      "\n",
      "episode 14, val func loss 0.17293046414852142\n",
      "\n",
      "episode 15, val func loss 0.13992585241794586\n",
      "\n",
      "episode 16, val func loss 0.18486106395721436\n",
      "\n",
      "Val func train loss in epoch 12:0.17367237899452448\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.16010922193527222\n",
      "\n",
      "episode 2, val func loss 0.194294273853302\n",
      "\n",
      "episode 3, val func loss 0.18547599017620087\n",
      "\n",
      "episode 4, val func loss 0.17958985269069672\n",
      "\n",
      "episode 5, val func loss 0.16143307089805603\n",
      "\n",
      "episode 6, val func loss 0.19008539617061615\n",
      "\n",
      "episode 7, val func loss 0.19474516808986664\n",
      "\n",
      "episode 8, val func loss 0.15243320167064667\n",
      "\n",
      "episode 9, val func loss 0.17435146868228912\n",
      "\n",
      "episode 10, val func loss 0.18494457006454468\n",
      "\n",
      "episode 11, val func loss 0.17308132350444794\n",
      "\n",
      "episode 12, val func loss 0.19034521281719208\n",
      "\n",
      "episode 13, val func loss 0.20520628988742828\n",
      "\n",
      "episode 14, val func loss 0.15106572210788727\n",
      "\n",
      "episode 15, val func loss 0.13873931765556335\n",
      "\n",
      "episode 16, val func loss 0.13983801007270813\n",
      "\n",
      "Val func train loss in epoch 13:0.17348363064229488\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19053764641284943\n",
      "\n",
      "episode 2, val func loss 0.18847204744815826\n",
      "\n",
      "episode 3, val func loss 0.19610659778118134\n",
      "\n",
      "episode 4, val func loss 0.1516817957162857\n",
      "\n",
      "episode 5, val func loss 0.1383213847875595\n",
      "\n",
      "episode 6, val func loss 0.17297539114952087\n",
      "\n",
      "episode 7, val func loss 0.15206314623355865\n",
      "\n",
      "episode 8, val func loss 0.13930530846118927\n",
      "\n",
      "episode 9, val func loss 0.20718033611774445\n",
      "\n",
      "episode 10, val func loss 0.1610066145658493\n",
      "\n",
      "episode 11, val func loss 0.19473187625408173\n",
      "\n",
      "episode 12, val func loss 0.1787271797657013\n",
      "\n",
      "episode 13, val func loss 0.19000327587127686\n",
      "\n",
      "episode 14, val func loss 0.172386035323143\n",
      "\n",
      "episode 15, val func loss 0.16175919771194458\n",
      "\n",
      "episode 16, val func loss 0.18565663695335388\n",
      "\n",
      "Val func train loss in epoch 14:0.17380715440958738\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.15324439108371735\n",
      "\n",
      "episode 2, val func loss 0.2067260593175888\n",
      "\n",
      "episode 3, val func loss 0.1393367350101471\n",
      "\n",
      "episode 4, val func loss 0.17420080304145813\n",
      "\n",
      "episode 5, val func loss 0.13912591338157654\n",
      "\n",
      "episode 6, val func loss 0.18441499769687653\n",
      "\n",
      "episode 7, val func loss 0.15948182344436646\n",
      "\n",
      "episode 8, val func loss 0.1904010772705078\n",
      "\n",
      "episode 9, val func loss 0.1940470188856125\n",
      "\n",
      "episode 10, val func loss 0.19516855478286743\n",
      "\n",
      "episode 11, val func loss 0.172714501619339\n",
      "\n",
      "episode 12, val func loss 0.17943830788135529\n",
      "\n",
      "episode 13, val func loss 0.18995152413845062\n",
      "\n",
      "episode 14, val func loss 0.15044528245925903\n",
      "\n",
      "episode 15, val func loss 0.18538470566272736\n",
      "\n",
      "episode 16, val func loss 0.16163530945777893\n",
      "\n",
      "Val func train loss in epoch 15:0.1734823128208518\n",
      "***********************TIME WAS 5.176242113113403 min*****************************\n",
      "\n",
      "**********************ROUND 26 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.12531700730323792\n",
      "\n",
      "episode 2, policy loss -0.11580663919448853\n",
      "\n",
      "episode 3, policy loss -0.1576438546180725\n",
      "\n",
      "episode 4, policy loss -0.12795083224773407\n",
      "\n",
      "episode 5, policy loss -0.08554995059967041\n",
      "\n",
      "episode 6, policy loss -0.0911802351474762\n",
      "\n",
      "episode 7, policy loss -0.16751828789710999\n",
      "\n",
      "episode 8, policy loss -0.11835574358701706\n",
      "\n",
      "episode 9, policy loss -0.10184712707996368\n",
      "\n",
      "episode 10, policy loss -0.152240589261055\n",
      "\n",
      "episode 11, policy loss -0.1413297802209854\n",
      "\n",
      "episode 12, policy loss -0.16013415157794952\n",
      "\n",
      "episode 13, policy loss -0.1070844829082489\n",
      "\n",
      "episode 14, policy loss -0.08364218473434448\n",
      "\n",
      "episode 15, policy loss -0.09361163526773453\n",
      "\n",
      "episode 16, policy loss -0.12271595001220703\n",
      "\n",
      "Policy train loss in epoch 0:-0.12199552822858095\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.12416781485080719\n",
      "\n",
      "episode 2, policy loss -0.12379958480596542\n",
      "\n",
      "episode 3, policy loss -0.08245878666639328\n",
      "\n",
      "episode 4, policy loss -0.17177537083625793\n",
      "\n",
      "episode 5, policy loss -0.14561277627944946\n",
      "\n",
      "episode 6, policy loss -0.10398201644420624\n",
      "\n",
      "episode 7, policy loss -0.11738892644643784\n",
      "\n",
      "episode 8, policy loss -0.15996190905570984\n",
      "\n",
      "episode 9, policy loss -0.1553976982831955\n",
      "\n",
      "episode 10, policy loss -0.13037103414535522\n",
      "\n",
      "episode 11, policy loss -0.08856630325317383\n",
      "\n",
      "episode 12, policy loss -0.15366646647453308\n",
      "\n",
      "episode 13, policy loss -0.1045684963464737\n",
      "\n",
      "episode 14, policy loss -0.09088478982448578\n",
      "\n",
      "episode 15, policy loss -0.11286019533872604\n",
      "\n",
      "episode 16, policy loss -0.0942838117480278\n",
      "\n",
      "Policy train loss in epoch 1:-0.12248412379994988\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.10563088208436966\n",
      "\n",
      "episode 2, policy loss -0.0934300422668457\n",
      "\n",
      "episode 3, policy loss -0.07785004377365112\n",
      "\n",
      "episode 4, policy loss -0.11599265038967133\n",
      "\n",
      "episode 5, policy loss -0.08848930895328522\n",
      "\n",
      "episode 6, policy loss -0.11625321209430695\n",
      "\n",
      "episode 7, policy loss -0.10120303928852081\n",
      "\n",
      "episode 8, policy loss -0.1257784515619278\n",
      "\n",
      "episode 9, policy loss -0.15775765478610992\n",
      "\n",
      "episode 10, policy loss -0.09473951160907745\n",
      "\n",
      "episode 11, policy loss -0.1613454967737198\n",
      "\n",
      "episode 12, policy loss -0.16865898668766022\n",
      "\n",
      "episode 13, policy loss -0.15510347485542297\n",
      "\n",
      "episode 14, policy loss -0.12586282193660736\n",
      "\n",
      "episode 15, policy loss -0.12591148912906647\n",
      "\n",
      "episode 16, policy loss -0.1443871557712555\n",
      "\n",
      "Policy train loss in epoch 2:-0.12239963887259364\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.14482459425926208\n",
      "\n",
      "episode 2, policy loss -0.1263037919998169\n",
      "\n",
      "episode 3, policy loss -0.09889160096645355\n",
      "\n",
      "episode 4, policy loss -0.11793018877506256\n",
      "\n",
      "episode 5, policy loss -0.15459106862545013\n",
      "\n",
      "episode 6, policy loss -0.10592000186443329\n",
      "\n",
      "episode 7, policy loss -0.155935138463974\n",
      "\n",
      "episode 8, policy loss -0.16172170639038086\n",
      "\n",
      "episode 9, policy loss -0.11845201253890991\n",
      "\n",
      "episode 10, policy loss -0.12948501110076904\n",
      "\n",
      "episode 11, policy loss -0.1221919059753418\n",
      "\n",
      "episode 12, policy loss -0.08691725134849548\n",
      "\n",
      "episode 13, policy loss -0.09203964471817017\n",
      "\n",
      "episode 14, policy loss -0.09374456107616425\n",
      "\n",
      "episode 15, policy loss -0.1693882942199707\n",
      "\n",
      "episode 16, policy loss -0.08071645349264145\n",
      "\n",
      "Policy train loss in epoch 3:-0.12244082661345601\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17313644289970398\n",
      "\n",
      "episode 2, val func loss 0.15047651529312134\n",
      "\n",
      "episode 3, val func loss 0.18348412215709686\n",
      "\n",
      "episode 4, val func loss 0.14034713804721832\n",
      "\n",
      "episode 5, val func loss 0.16790910065174103\n",
      "\n",
      "episode 6, val func loss 0.15775920450687408\n",
      "\n",
      "episode 7, val func loss 0.20749805867671967\n",
      "\n",
      "episode 8, val func loss 0.15676158666610718\n",
      "\n",
      "episode 9, val func loss 0.14440777897834778\n",
      "\n",
      "episode 10, val func loss 0.12427842617034912\n",
      "\n",
      "episode 11, val func loss 0.1252877116203308\n",
      "\n",
      "episode 12, val func loss 0.14111857116222382\n",
      "\n",
      "episode 13, val func loss 0.15592394769191742\n",
      "\n",
      "episode 14, val func loss 0.19435998797416687\n",
      "\n",
      "episode 15, val func loss 0.19051504135131836\n",
      "\n",
      "episode 16, val func loss 0.1311364769935608\n",
      "\n",
      "Val func train loss in epoch 0:0.15902500692754984\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.12522058188915253\n",
      "\n",
      "episode 2, val func loss 0.1314489096403122\n",
      "\n",
      "episode 3, val func loss 0.1803794503211975\n",
      "\n",
      "episode 4, val func loss 0.15829789638519287\n",
      "\n",
      "episode 5, val func loss 0.2084067016839981\n",
      "\n",
      "episode 6, val func loss 0.18779334425926208\n",
      "\n",
      "episode 7, val func loss 0.14026153087615967\n",
      "\n",
      "episode 8, val func loss 0.18948300182819366\n",
      "\n",
      "episode 9, val func loss 0.14228233695030212\n",
      "\n",
      "episode 10, val func loss 0.1723998785018921\n",
      "\n",
      "episode 11, val func loss 0.15566422045230865\n",
      "\n",
      "episode 12, val func loss 0.1401984989643097\n",
      "\n",
      "episode 13, val func loss 0.1256536990404129\n",
      "\n",
      "episode 14, val func loss 0.15835891664028168\n",
      "\n",
      "episode 15, val func loss 0.17236046493053436\n",
      "\n",
      "episode 16, val func loss 0.15062759816646576\n",
      "\n",
      "Val func train loss in epoch 1:0.1586773144081235\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.12486790120601654\n",
      "\n",
      "episode 2, val func loss 0.18858295679092407\n",
      "\n",
      "episode 3, val func loss 0.14390739798545837\n",
      "\n",
      "episode 4, val func loss 0.1898023784160614\n",
      "\n",
      "episode 5, val func loss 0.20775078237056732\n",
      "\n",
      "episode 6, val func loss 0.13150152564048767\n",
      "\n",
      "episode 7, val func loss 0.18083877861499786\n",
      "\n",
      "episode 8, val func loss 0.14013412594795227\n",
      "\n",
      "episode 9, val func loss 0.15443409979343414\n",
      "\n",
      "episode 10, val func loss 0.1709008514881134\n",
      "\n",
      "episode 11, val func loss 0.16825953125953674\n",
      "\n",
      "episode 12, val func loss 0.15727096796035767\n",
      "\n",
      "episode 13, val func loss 0.1264737844467163\n",
      "\n",
      "episode 14, val func loss 0.1558259129524231\n",
      "\n",
      "episode 15, val func loss 0.15013734996318817\n",
      "\n",
      "episode 16, val func loss 0.1409386396408081\n",
      "\n",
      "Val func train loss in epoch 2:0.1582266865298152\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1509847640991211\n",
      "\n",
      "episode 2, val func loss 0.16062577068805695\n",
      "\n",
      "episode 3, val func loss 0.14172299206256866\n",
      "\n",
      "episode 4, val func loss 0.13957394659519196\n",
      "\n",
      "episode 5, val func loss 0.16942067444324493\n",
      "\n",
      "episode 6, val func loss 0.2079702913761139\n",
      "\n",
      "episode 7, val func loss 0.18996432423591614\n",
      "\n",
      "episode 8, val func loss 0.12533611059188843\n",
      "\n",
      "episode 9, val func loss 0.13045959174633026\n",
      "\n",
      "episode 10, val func loss 0.18702301383018494\n",
      "\n",
      "episode 11, val func loss 0.1437710076570511\n",
      "\n",
      "episode 12, val func loss 0.15875433385372162\n",
      "\n",
      "episode 13, val func loss 0.17118920385837555\n",
      "\n",
      "episode 14, val func loss 0.15402351319789886\n",
      "\n",
      "episode 15, val func loss 0.18345212936401367\n",
      "\n",
      "episode 16, val func loss 0.12478727102279663\n",
      "\n",
      "Val func train loss in epoch 3:0.15869118366390467\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1554768979549408\n",
      "\n",
      "episode 2, val func loss 0.17090091109275818\n",
      "\n",
      "episode 3, val func loss 0.1725970208644867\n",
      "\n",
      "episode 4, val func loss 0.14214909076690674\n",
      "\n",
      "episode 5, val func loss 0.13968470692634583\n",
      "\n",
      "episode 6, val func loss 0.13179561495780945\n",
      "\n",
      "episode 7, val func loss 0.12464983016252518\n",
      "\n",
      "episode 8, val func loss 0.18071691691875458\n",
      "\n",
      "episode 9, val func loss 0.18701976537704468\n",
      "\n",
      "episode 10, val func loss 0.1292983740568161\n",
      "\n",
      "episode 11, val func loss 0.15320442616939545\n",
      "\n",
      "episode 12, val func loss 0.1547115445137024\n",
      "\n",
      "episode 13, val func loss 0.14087584614753723\n",
      "\n",
      "episode 14, val func loss 0.19002801179885864\n",
      "\n",
      "episode 15, val func loss 0.20944102108478546\n",
      "\n",
      "episode 16, val func loss 0.1586567610502243\n",
      "\n",
      "Val func train loss in epoch 4:0.15882542124018073\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.14022992551326752\n",
      "\n",
      "episode 2, val func loss 0.12475185841321945\n",
      "\n",
      "episode 3, val func loss 0.19002319872379303\n",
      "\n",
      "episode 4, val func loss 0.15360906720161438\n",
      "\n",
      "episode 5, val func loss 0.15715153515338898\n",
      "\n",
      "episode 6, val func loss 0.15261676907539368\n",
      "\n",
      "episode 7, val func loss 0.12807363271713257\n",
      "\n",
      "episode 8, val func loss 0.13961967825889587\n",
      "\n",
      "episode 9, val func loss 0.1690426468849182\n",
      "\n",
      "episode 10, val func loss 0.14256551861763\n",
      "\n",
      "episode 11, val func loss 0.2089584469795227\n",
      "\n",
      "episode 12, val func loss 0.19060103595256805\n",
      "\n",
      "episode 13, val func loss 0.18298862874507904\n",
      "\n",
      "episode 14, val func loss 0.17181266844272614\n",
      "\n",
      "episode 15, val func loss 0.13133437931537628\n",
      "\n",
      "episode 16, val func loss 0.15799789130687714\n",
      "\n",
      "Val func train loss in epoch 5:0.1588360550813377\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.12559856474399567\n",
      "\n",
      "episode 2, val func loss 0.1286468207836151\n",
      "\n",
      "episode 3, val func loss 0.1525266319513321\n",
      "\n",
      "episode 4, val func loss 0.14085380733013153\n",
      "\n",
      "episode 5, val func loss 0.14176279306411743\n",
      "\n",
      "episode 6, val func loss 0.1569281965494156\n",
      "\n",
      "episode 7, val func loss 0.19866827130317688\n",
      "\n",
      "episode 8, val func loss 0.1927465945482254\n",
      "\n",
      "episode 9, val func loss 0.13957928121089935\n",
      "\n",
      "episode 10, val func loss 0.16915760934352875\n",
      "\n",
      "episode 11, val func loss 0.15420439839363098\n",
      "\n",
      "episode 12, val func loss 0.2067415714263916\n",
      "\n",
      "episode 13, val func loss 0.17142035067081451\n",
      "\n",
      "episode 14, val func loss 0.1804560124874115\n",
      "\n",
      "episode 15, val func loss 0.13096004724502563\n",
      "\n",
      "episode 16, val func loss 0.15868335962295532\n",
      "\n",
      "Val func train loss in epoch 6:0.1593083944171667\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17144615948200226\n",
      "\n",
      "episode 2, val func loss 0.18962271511554718\n",
      "\n",
      "episode 3, val func loss 0.1541234403848648\n",
      "\n",
      "episode 4, val func loss 0.12422645837068558\n",
      "\n",
      "episode 5, val func loss 0.14265844225883484\n",
      "\n",
      "episode 6, val func loss 0.14064458012580872\n",
      "\n",
      "episode 7, val func loss 0.1505480855703354\n",
      "\n",
      "episode 8, val func loss 0.13116712868213654\n",
      "\n",
      "episode 9, val func loss 0.18738627433776855\n",
      "\n",
      "episode 10, val func loss 0.20841656625270844\n",
      "\n",
      "episode 11, val func loss 0.12666162848472595\n",
      "\n",
      "episode 12, val func loss 0.18010129034519196\n",
      "\n",
      "episode 13, val func loss 0.15783289074897766\n",
      "\n",
      "episode 14, val func loss 0.15729765594005585\n",
      "\n",
      "episode 15, val func loss 0.1699516773223877\n",
      "\n",
      "episode 16, val func loss 0.14090992510318756\n",
      "\n",
      "Val func train loss in epoch 7:0.15831218240782619\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.15350434184074402\n",
      "\n",
      "episode 2, val func loss 0.19225436449050903\n",
      "\n",
      "episode 3, val func loss 0.1507847160100937\n",
      "\n",
      "episode 4, val func loss 0.13965961337089539\n",
      "\n",
      "episode 5, val func loss 0.1897992044687271\n",
      "\n",
      "episode 6, val func loss 0.15671108663082123\n",
      "\n",
      "episode 7, val func loss 0.16897766292095184\n",
      "\n",
      "episode 8, val func loss 0.12427021563053131\n",
      "\n",
      "episode 9, val func loss 0.14257292449474335\n",
      "\n",
      "episode 10, val func loss 0.13297094404697418\n",
      "\n",
      "episode 11, val func loss 0.15793901681900024\n",
      "\n",
      "episode 12, val func loss 0.17206251621246338\n",
      "\n",
      "episode 13, val func loss 0.20727020502090454\n",
      "\n",
      "episode 14, val func loss 0.1413615643978119\n",
      "\n",
      "episode 15, val func loss 0.12764118611812592\n",
      "\n",
      "episode 16, val func loss 0.1808658242225647\n",
      "\n",
      "Val func train loss in epoch 8:0.15866533666849136\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.15752072632312775\n",
      "\n",
      "episode 2, val func loss 0.18822196125984192\n",
      "\n",
      "episode 3, val func loss 0.12709107995033264\n",
      "\n",
      "episode 4, val func loss 0.15170277655124664\n",
      "\n",
      "episode 5, val func loss 0.18145890533924103\n",
      "\n",
      "episode 6, val func loss 0.15581999719142914\n",
      "\n",
      "episode 7, val func loss 0.2080668807029724\n",
      "\n",
      "episode 8, val func loss 0.14229664206504822\n",
      "\n",
      "episode 9, val func loss 0.1402990221977234\n",
      "\n",
      "episode 10, val func loss 0.12451696395874023\n",
      "\n",
      "episode 11, val func loss 0.13983848690986633\n",
      "\n",
      "episode 12, val func loss 0.17314092814922333\n",
      "\n",
      "episode 13, val func loss 0.19021357595920563\n",
      "\n",
      "episode 14, val func loss 0.15332165360450745\n",
      "\n",
      "episode 15, val func loss 0.13186682760715485\n",
      "\n",
      "episode 16, val func loss 0.16801898181438446\n",
      "\n",
      "Val func train loss in epoch 9:0.15833721309900284\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.12524399161338806\n",
      "\n",
      "episode 2, val func loss 0.141286239027977\n",
      "\n",
      "episode 3, val func loss 0.13094748556613922\n",
      "\n",
      "episode 4, val func loss 0.19023819267749786\n",
      "\n",
      "episode 5, val func loss 0.16780449450016022\n",
      "\n",
      "episode 6, val func loss 0.1539340615272522\n",
      "\n",
      "episode 7, val func loss 0.15734048187732697\n",
      "\n",
      "episode 8, val func loss 0.18129733204841614\n",
      "\n",
      "episode 9, val func loss 0.14093530178070068\n",
      "\n",
      "episode 10, val func loss 0.15700602531433105\n",
      "\n",
      "episode 11, val func loss 0.2082015722990036\n",
      "\n",
      "episode 12, val func loss 0.14294952154159546\n",
      "\n",
      "episode 13, val func loss 0.12500090897083282\n",
      "\n",
      "episode 14, val func loss 0.19315490126609802\n",
      "\n",
      "episode 15, val func loss 0.17297494411468506\n",
      "\n",
      "episode 16, val func loss 0.15066678822040558\n",
      "\n",
      "Val func train loss in epoch 10:0.15868639014661312\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1562895029783249\n",
      "\n",
      "episode 2, val func loss 0.1883435845375061\n",
      "\n",
      "episode 3, val func loss 0.157534658908844\n",
      "\n",
      "episode 4, val func loss 0.20709319412708282\n",
      "\n",
      "episode 5, val func loss 0.13120169937610626\n",
      "\n",
      "episode 6, val func loss 0.14672431349754333\n",
      "\n",
      "episode 7, val func loss 0.1525273621082306\n",
      "\n",
      "episode 8, val func loss 0.14055997133255005\n",
      "\n",
      "episode 9, val func loss 0.19302654266357422\n",
      "\n",
      "episode 10, val func loss 0.15527360141277313\n",
      "\n",
      "episode 11, val func loss 0.1252247393131256\n",
      "\n",
      "episode 12, val func loss 0.12513944506645203\n",
      "\n",
      "episode 13, val func loss 0.13957111537456512\n",
      "\n",
      "episode 14, val func loss 0.18271471560001373\n",
      "\n",
      "episode 15, val func loss 0.170939639210701\n",
      "\n",
      "episode 16, val func loss 0.1674860715866089\n",
      "\n",
      "Val func train loss in epoch 11:0.1587281348183751\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.16766156256198883\n",
      "\n",
      "episode 2, val func loss 0.14705301821231842\n",
      "\n",
      "episode 3, val func loss 0.1579219251871109\n",
      "\n",
      "episode 4, val func loss 0.15377654135227203\n",
      "\n",
      "episode 5, val func loss 0.13967610895633698\n",
      "\n",
      "episode 6, val func loss 0.19287176430225372\n",
      "\n",
      "episode 7, val func loss 0.1500203162431717\n",
      "\n",
      "episode 8, val func loss 0.15577606856822968\n",
      "\n",
      "episode 9, val func loss 0.1245223805308342\n",
      "\n",
      "episode 10, val func loss 0.13192254304885864\n",
      "\n",
      "episode 11, val func loss 0.17076943814754486\n",
      "\n",
      "episode 12, val func loss 0.18049174547195435\n",
      "\n",
      "episode 13, val func loss 0.1869322806596756\n",
      "\n",
      "episode 14, val func loss 0.1426667869091034\n",
      "\n",
      "episode 15, val func loss 0.12966345250606537\n",
      "\n",
      "episode 16, val func loss 0.20699483156204224\n",
      "\n",
      "Val func train loss in epoch 12:0.15867004776373506\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18944300711154938\n",
      "\n",
      "episode 2, val func loss 0.14257332682609558\n",
      "\n",
      "episode 3, val func loss 0.16021162271499634\n",
      "\n",
      "episode 4, val func loss 0.1700168401002884\n",
      "\n",
      "episode 5, val func loss 0.14079341292381287\n",
      "\n",
      "episode 6, val func loss 0.20720899105072021\n",
      "\n",
      "episode 7, val func loss 0.17136526107788086\n",
      "\n",
      "episode 8, val func loss 0.12574031949043274\n",
      "\n",
      "episode 9, val func loss 0.18774853646755219\n",
      "\n",
      "episode 10, val func loss 0.152647003531456\n",
      "\n",
      "episode 11, val func loss 0.18050368130207062\n",
      "\n",
      "episode 12, val func loss 0.1545923352241516\n",
      "\n",
      "episode 13, val func loss 0.12628385424613953\n",
      "\n",
      "episode 14, val func loss 0.15581072866916656\n",
      "\n",
      "episode 15, val func loss 0.13665901124477386\n",
      "\n",
      "episode 16, val func loss 0.13959082961082458\n",
      "\n",
      "Val func train loss in epoch 13:0.15882429759949446\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.12612250447273254\n",
      "\n",
      "episode 2, val func loss 0.1883072853088379\n",
      "\n",
      "episode 3, val func loss 0.1564624011516571\n",
      "\n",
      "episode 4, val func loss 0.1315588802099228\n",
      "\n",
      "episode 5, val func loss 0.14122791588306427\n",
      "\n",
      "episode 6, val func loss 0.18119311332702637\n",
      "\n",
      "episode 7, val func loss 0.18937961757183075\n",
      "\n",
      "episode 8, val func loss 0.12493741512298584\n",
      "\n",
      "episode 9, val func loss 0.15629814565181732\n",
      "\n",
      "episode 10, val func loss 0.151645690202713\n",
      "\n",
      "episode 11, val func loss 0.15393638610839844\n",
      "\n",
      "episode 12, val func loss 0.20916317403316498\n",
      "\n",
      "episode 13, val func loss 0.1426677405834198\n",
      "\n",
      "episode 14, val func loss 0.17166270315647125\n",
      "\n",
      "episode 15, val func loss 0.1678411215543747\n",
      "\n",
      "episode 16, val func loss 0.14012181758880615\n",
      "\n",
      "Val func train loss in epoch 14:0.15828286949545145\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.15191347897052765\n",
      "\n",
      "episode 2, val func loss 0.12670467793941498\n",
      "\n",
      "episode 3, val func loss 0.14176295697689056\n",
      "\n",
      "episode 4, val func loss 0.12732169032096863\n",
      "\n",
      "episode 5, val func loss 0.19731469452381134\n",
      "\n",
      "episode 6, val func loss 0.13943934440612793\n",
      "\n",
      "episode 7, val func loss 0.16840782761573792\n",
      "\n",
      "episode 8, val func loss 0.1575801819562912\n",
      "\n",
      "episode 9, val func loss 0.1427379995584488\n",
      "\n",
      "episode 10, val func loss 0.171061709523201\n",
      "\n",
      "episode 11, val func loss 0.13080660998821259\n",
      "\n",
      "episode 12, val func loss 0.19030041992664337\n",
      "\n",
      "episode 13, val func loss 0.2074347585439682\n",
      "\n",
      "episode 14, val func loss 0.18129391968250275\n",
      "\n",
      "episode 15, val func loss 0.15454131364822388\n",
      "\n",
      "episode 16, val func loss 0.1578439176082611\n",
      "\n",
      "Val func train loss in epoch 15:0.159154093824327\n",
      "***********************TIME WAS 5.176767571767171 min*****************************\n",
      "\n",
      "**********************ROUND 27 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.06807784736156464\n",
      "\n",
      "episode 2, policy loss -0.10035073012113571\n",
      "\n",
      "episode 3, policy loss -0.08021356910467148\n",
      "\n",
      "episode 4, policy loss -0.0760808140039444\n",
      "\n",
      "episode 5, policy loss -0.08447972685098648\n",
      "\n",
      "episode 6, policy loss -0.07524367421865463\n",
      "\n",
      "episode 7, policy loss -0.12057258188724518\n",
      "\n",
      "episode 8, policy loss -0.09200555086135864\n",
      "\n",
      "episode 9, policy loss -0.1261451095342636\n",
      "\n",
      "episode 10, policy loss -0.1018107533454895\n",
      "\n",
      "episode 11, policy loss -0.10484876483678818\n",
      "\n",
      "episode 12, policy loss -0.08902381360530853\n",
      "\n",
      "episode 13, policy loss -0.07088249921798706\n",
      "\n",
      "episode 14, policy loss -0.08199667930603027\n",
      "\n",
      "episode 15, policy loss -0.05621841549873352\n",
      "\n",
      "episode 16, policy loss -0.09228810667991638\n",
      "\n",
      "Policy train loss in epoch 0:-0.08876491477712989\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.09477069973945618\n",
      "\n",
      "episode 2, policy loss -0.08020508289337158\n",
      "\n",
      "episode 3, policy loss -0.07537256926298141\n",
      "\n",
      "episode 4, policy loss -0.09167937189340591\n",
      "\n",
      "episode 5, policy loss -0.10600973665714264\n",
      "\n",
      "episode 6, policy loss -0.07376600056886673\n",
      "\n",
      "episode 7, policy loss -0.09350113570690155\n",
      "\n",
      "episode 8, policy loss -0.1057138741016388\n",
      "\n",
      "episode 9, policy loss -0.0719660297036171\n",
      "\n",
      "episode 10, policy loss -0.06719202548265457\n",
      "\n",
      "episode 11, policy loss -0.12048735469579697\n",
      "\n",
      "episode 12, policy loss -0.08736010640859604\n",
      "\n",
      "episode 13, policy loss -0.07916010916233063\n",
      "\n",
      "episode 14, policy loss -0.12496855854988098\n",
      "\n",
      "episode 15, policy loss -0.08853674679994583\n",
      "\n",
      "episode 16, policy loss -0.05452669784426689\n",
      "\n",
      "Policy train loss in epoch 1:-0.08845100621692836\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.08521382510662079\n",
      "\n",
      "episode 2, policy loss -0.09280002862215042\n",
      "\n",
      "episode 3, policy loss -0.06952641159296036\n",
      "\n",
      "episode 4, policy loss -0.06626254320144653\n",
      "\n",
      "episode 5, policy loss -0.08061904460191727\n",
      "\n",
      "episode 6, policy loss -0.09174466133117676\n",
      "\n",
      "episode 7, policy loss -0.11981326341629028\n",
      "\n",
      "episode 8, policy loss -0.09730210900306702\n",
      "\n",
      "episode 9, policy loss -0.1253904402256012\n",
      "\n",
      "episode 10, policy loss -0.09057721495628357\n",
      "\n",
      "episode 11, policy loss -0.10292515903711319\n",
      "\n",
      "episode 12, policy loss -0.0722198411822319\n",
      "\n",
      "episode 13, policy loss -0.05462414771318436\n",
      "\n",
      "episode 14, policy loss -0.10373936593532562\n",
      "\n",
      "episode 15, policy loss -0.07538393139839172\n",
      "\n",
      "episode 16, policy loss -0.07768064737319946\n",
      "\n",
      "Policy train loss in epoch 2:-0.08786391466856003\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.07851657271385193\n",
      "\n",
      "episode 2, policy loss -0.08520655333995819\n",
      "\n",
      "episode 3, policy loss -0.06590764224529266\n",
      "\n",
      "episode 4, policy loss -0.10213931649923325\n",
      "\n",
      "episode 5, policy loss -0.06679663807153702\n",
      "\n",
      "episode 6, policy loss -0.1226603239774704\n",
      "\n",
      "episode 7, policy loss -0.05484578013420105\n",
      "\n",
      "episode 8, policy loss -0.09960169345140457\n",
      "\n",
      "episode 9, policy loss -0.10506879538297653\n",
      "\n",
      "episode 10, policy loss -0.09156101942062378\n",
      "\n",
      "episode 11, policy loss -0.08894628286361694\n",
      "\n",
      "episode 12, policy loss -0.12102041393518448\n",
      "\n",
      "episode 13, policy loss -0.07087942212820053\n",
      "\n",
      "episode 14, policy loss -0.07624314725399017\n",
      "\n",
      "episode 15, policy loss -0.08557837456464767\n",
      "\n",
      "episode 16, policy loss -0.07417149096727371\n",
      "\n",
      "Policy train loss in epoch 3:-0.08682146668434143\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.14436958730220795\n",
      "\n",
      "episode 2, val func loss 0.16182836890220642\n",
      "\n",
      "episode 3, val func loss 0.12195616215467453\n",
      "\n",
      "episode 4, val func loss 0.20367087423801422\n",
      "\n",
      "episode 5, val func loss 0.14455337822437286\n",
      "\n",
      "episode 6, val func loss 0.16906771063804626\n",
      "\n",
      "episode 7, val func loss 0.18183578550815582\n",
      "\n",
      "episode 8, val func loss 0.16705511510372162\n",
      "\n",
      "episode 9, val func loss 0.11393364518880844\n",
      "\n",
      "episode 10, val func loss 0.17685852944850922\n",
      "\n",
      "episode 11, val func loss 0.1499655842781067\n",
      "\n",
      "episode 12, val func loss 0.13069546222686768\n",
      "\n",
      "episode 13, val func loss 0.20087294280529022\n",
      "\n",
      "episode 14, val func loss 0.16801489889621735\n",
      "\n",
      "episode 15, val func loss 0.16572162508964539\n",
      "\n",
      "episode 16, val func loss 0.07362839579582214\n",
      "\n",
      "Val func train loss in epoch 0:0.15462675411254168\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.11616025120019913\n",
      "\n",
      "episode 2, val func loss 0.16747236251831055\n",
      "\n",
      "episode 3, val func loss 0.16566102206707\n",
      "\n",
      "episode 4, val func loss 0.11449746787548065\n",
      "\n",
      "episode 5, val func loss 0.15020963549613953\n",
      "\n",
      "episode 6, val func loss 0.13020090758800507\n",
      "\n",
      "episode 7, val func loss 0.1452215611934662\n",
      "\n",
      "episode 8, val func loss 0.20144523680210114\n",
      "\n",
      "episode 9, val func loss 0.20086415112018585\n",
      "\n",
      "episode 10, val func loss 0.14668051898479462\n",
      "\n",
      "episode 11, val func loss 0.18210186064243317\n",
      "\n",
      "episode 12, val func loss 0.07416971772909164\n",
      "\n",
      "episode 13, val func loss 0.16776122152805328\n",
      "\n",
      "episode 14, val func loss 0.16229410469532013\n",
      "\n",
      "episode 15, val func loss 0.16859585046768188\n",
      "\n",
      "episode 16, val func loss 0.17672474682331085\n",
      "\n",
      "Val func train loss in epoch 1:0.15437878854572773\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.07261299341917038\n",
      "\n",
      "episode 2, val func loss 0.2016073763370514\n",
      "\n",
      "episode 3, val func loss 0.11574188619852066\n",
      "\n",
      "episode 4, val func loss 0.20006437599658966\n",
      "\n",
      "episode 5, val func loss 0.13144604861736298\n",
      "\n",
      "episode 6, val func loss 0.17758585512638092\n",
      "\n",
      "episode 7, val func loss 0.165147602558136\n",
      "\n",
      "episode 8, val func loss 0.1672201305627823\n",
      "\n",
      "episode 9, val func loss 0.1675700545310974\n",
      "\n",
      "episode 10, val func loss 0.18190303444862366\n",
      "\n",
      "episode 11, val func loss 0.14489220082759857\n",
      "\n",
      "episode 12, val func loss 0.14290092885494232\n",
      "\n",
      "episode 13, val func loss 0.1670282781124115\n",
      "\n",
      "episode 14, val func loss 0.16600628197193146\n",
      "\n",
      "episode 15, val func loss 0.15032845735549927\n",
      "\n",
      "episode 16, val func loss 0.11430014669895172\n",
      "\n",
      "Val func train loss in epoch 2:0.15414722822606564\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.07316001504659653\n",
      "\n",
      "episode 2, val func loss 0.18143266439437866\n",
      "\n",
      "episode 3, val func loss 0.11576609313488007\n",
      "\n",
      "episode 4, val func loss 0.14339688420295715\n",
      "\n",
      "episode 5, val func loss 0.1676349937915802\n",
      "\n",
      "episode 6, val func loss 0.16723331809043884\n",
      "\n",
      "episode 7, val func loss 0.14419473707675934\n",
      "\n",
      "episode 8, val func loss 0.1499582976102829\n",
      "\n",
      "episode 9, val func loss 0.16667208075523376\n",
      "\n",
      "episode 10, val func loss 0.1655769944190979\n",
      "\n",
      "episode 11, val func loss 0.17652258276939392\n",
      "\n",
      "episode 12, val func loss 0.11465736478567123\n",
      "\n",
      "episode 13, val func loss 0.13025040924549103\n",
      "\n",
      "episode 14, val func loss 0.16243718564510345\n",
      "\n",
      "episode 15, val func loss 0.2015436440706253\n",
      "\n",
      "episode 16, val func loss 0.2027469128370285\n",
      "\n",
      "Val func train loss in epoch 3:0.15394901111721992\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18173933029174805\n",
      "\n",
      "episode 2, val func loss 0.11585254222154617\n",
      "\n",
      "episode 3, val func loss 0.07428266108036041\n",
      "\n",
      "episode 4, val func loss 0.20164212584495544\n",
      "\n",
      "episode 5, val func loss 0.16662868857383728\n",
      "\n",
      "episode 6, val func loss 0.15135863423347473\n",
      "\n",
      "episode 7, val func loss 0.11432436108589172\n",
      "\n",
      "episode 8, val func loss 0.14348585903644562\n",
      "\n",
      "episode 9, val func loss 0.20187722146511078\n",
      "\n",
      "episode 10, val func loss 0.16805975139141083\n",
      "\n",
      "episode 11, val func loss 0.17677666246891022\n",
      "\n",
      "episode 12, val func loss 0.16679249703884125\n",
      "\n",
      "episode 13, val func loss 0.13081522285938263\n",
      "\n",
      "episode 14, val func loss 0.1627681851387024\n",
      "\n",
      "episode 15, val func loss 0.1438407301902771\n",
      "\n",
      "episode 16, val func loss 0.167133167386055\n",
      "\n",
      "Val func train loss in epoch 4:0.15421110251918435\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1624111384153366\n",
      "\n",
      "episode 2, val func loss 0.20151424407958984\n",
      "\n",
      "episode 3, val func loss 0.16565611958503723\n",
      "\n",
      "episode 4, val func loss 0.11456920951604843\n",
      "\n",
      "episode 5, val func loss 0.1673734188079834\n",
      "\n",
      "episode 6, val func loss 0.1306265890598297\n",
      "\n",
      "episode 7, val func loss 0.16722996532917023\n",
      "\n",
      "episode 8, val func loss 0.17654472589492798\n",
      "\n",
      "episode 9, val func loss 0.1430862545967102\n",
      "\n",
      "episode 10, val func loss 0.2012745589017868\n",
      "\n",
      "episode 11, val func loss 0.18198473751544952\n",
      "\n",
      "episode 12, val func loss 0.1158343032002449\n",
      "\n",
      "episode 13, val func loss 0.1443677395582199\n",
      "\n",
      "episode 14, val func loss 0.16678203642368317\n",
      "\n",
      "episode 15, val func loss 0.0745982751250267\n",
      "\n",
      "episode 16, val func loss 0.15153305232524872\n",
      "\n",
      "Val func train loss in epoch 5:0.15408664802089334\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1642565280199051\n",
      "\n",
      "episode 2, val func loss 0.14310729503631592\n",
      "\n",
      "episode 3, val func loss 0.17645753920078278\n",
      "\n",
      "episode 4, val func loss 0.16853304207324982\n",
      "\n",
      "episode 5, val func loss 0.16838577389717102\n",
      "\n",
      "episode 6, val func loss 0.1668017953634262\n",
      "\n",
      "episode 7, val func loss 0.14588044583797455\n",
      "\n",
      "episode 8, val func loss 0.07268741726875305\n",
      "\n",
      "episode 9, val func loss 0.16808247566223145\n",
      "\n",
      "episode 10, val func loss 0.1501687467098236\n",
      "\n",
      "episode 11, val func loss 0.11561466753482819\n",
      "\n",
      "episode 12, val func loss 0.1317160725593567\n",
      "\n",
      "episode 13, val func loss 0.181662917137146\n",
      "\n",
      "episode 14, val func loss 0.2011096179485321\n",
      "\n",
      "episode 15, val func loss 0.19933290779590607\n",
      "\n",
      "episode 16, val func loss 0.11483597755432129\n",
      "\n",
      "Val func train loss in epoch 6:0.15428957622498274\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.16802829504013062\n",
      "\n",
      "episode 2, val func loss 0.13122068345546722\n",
      "\n",
      "episode 3, val func loss 0.16742268204689026\n",
      "\n",
      "episode 4, val func loss 0.14503581821918488\n",
      "\n",
      "episode 5, val func loss 0.17634867131710052\n",
      "\n",
      "episode 6, val func loss 0.11388634145259857\n",
      "\n",
      "episode 7, val func loss 0.20219579339027405\n",
      "\n",
      "episode 8, val func loss 0.20019571483135223\n",
      "\n",
      "episode 9, val func loss 0.1500554382801056\n",
      "\n",
      "episode 10, val func loss 0.1638309210538864\n",
      "\n",
      "episode 11, val func loss 0.1816752552986145\n",
      "\n",
      "episode 12, val func loss 0.07394351065158844\n",
      "\n",
      "episode 13, val func loss 0.16543467342853546\n",
      "\n",
      "episode 14, val func loss 0.1433418095111847\n",
      "\n",
      "episode 15, val func loss 0.16733086109161377\n",
      "\n",
      "episode 16, val func loss 0.11681743711233139\n",
      "\n",
      "Val func train loss in epoch 7:0.15417274413630366\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16737349331378937\n",
      "\n",
      "episode 2, val func loss 0.16728508472442627\n",
      "\n",
      "episode 3, val func loss 0.13060767948627472\n",
      "\n",
      "episode 4, val func loss 0.16777031123638153\n",
      "\n",
      "episode 5, val func loss 0.14475300908088684\n",
      "\n",
      "episode 6, val func loss 0.11492124944925308\n",
      "\n",
      "episode 7, val func loss 0.16617438197135925\n",
      "\n",
      "episode 8, val func loss 0.19879038631916046\n",
      "\n",
      "episode 9, val func loss 0.16575182974338531\n",
      "\n",
      "episode 10, val func loss 0.200907900929451\n",
      "\n",
      "episode 11, val func loss 0.18122512102127075\n",
      "\n",
      "episode 12, val func loss 0.14318931102752686\n",
      "\n",
      "episode 13, val func loss 0.17634329199790955\n",
      "\n",
      "episode 14, val func loss 0.07233960926532745\n",
      "\n",
      "episode 15, val func loss 0.11526211351156235\n",
      "\n",
      "episode 16, val func loss 0.15159133076667786\n",
      "\n",
      "Val func train loss in epoch 8:0.15401788149029016\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1695995032787323\n",
      "\n",
      "episode 2, val func loss 0.1615597903728485\n",
      "\n",
      "episode 3, val func loss 0.14480994641780853\n",
      "\n",
      "episode 4, val func loss 0.1660967916250229\n",
      "\n",
      "episode 5, val func loss 0.16770286858081818\n",
      "\n",
      "episode 6, val func loss 0.13237498700618744\n",
      "\n",
      "episode 7, val func loss 0.16880027949810028\n",
      "\n",
      "episode 8, val func loss 0.15136227011680603\n",
      "\n",
      "episode 9, val func loss 0.2007865309715271\n",
      "\n",
      "episode 10, val func loss 0.11422884464263916\n",
      "\n",
      "episode 11, val func loss 0.11584394425153732\n",
      "\n",
      "episode 12, val func loss 0.07304530590772629\n",
      "\n",
      "episode 13, val func loss 0.14208388328552246\n",
      "\n",
      "episode 14, val func loss 0.177401602268219\n",
      "\n",
      "episode 15, val func loss 0.20429617166519165\n",
      "\n",
      "episode 16, val func loss 0.18299950659275055\n",
      "\n",
      "Val func train loss in epoch 9:0.15456201415508986\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1668623834848404\n",
      "\n",
      "episode 2, val func loss 0.1635543406009674\n",
      "\n",
      "episode 3, val func loss 0.14469203352928162\n",
      "\n",
      "episode 4, val func loss 0.18137989938259125\n",
      "\n",
      "episode 5, val func loss 0.1318185180425644\n",
      "\n",
      "episode 6, val func loss 0.17684151232242584\n",
      "\n",
      "episode 7, val func loss 0.16799350082874298\n",
      "\n",
      "episode 8, val func loss 0.16688749194145203\n",
      "\n",
      "episode 9, val func loss 0.2011474221944809\n",
      "\n",
      "episode 10, val func loss 0.16572217643260956\n",
      "\n",
      "episode 11, val func loss 0.20075443387031555\n",
      "\n",
      "episode 12, val func loss 0.07288298010826111\n",
      "\n",
      "episode 13, val func loss 0.1434856802225113\n",
      "\n",
      "episode 14, val func loss 0.1504739671945572\n",
      "\n",
      "episode 15, val func loss 0.11472027748823166\n",
      "\n",
      "episode 16, val func loss 0.11640432476997375\n",
      "\n",
      "Val func train loss in epoch 10:0.15410130890086293\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1622580885887146\n",
      "\n",
      "episode 2, val func loss 0.20110736787319183\n",
      "\n",
      "episode 3, val func loss 0.1674719750881195\n",
      "\n",
      "episode 4, val func loss 0.11611796915531158\n",
      "\n",
      "episode 5, val func loss 0.17689523100852966\n",
      "\n",
      "episode 6, val func loss 0.1815001517534256\n",
      "\n",
      "episode 7, val func loss 0.16781318187713623\n",
      "\n",
      "episode 8, val func loss 0.1667601615190506\n",
      "\n",
      "episode 9, val func loss 0.15018227696418762\n",
      "\n",
      "episode 10, val func loss 0.1657983958721161\n",
      "\n",
      "episode 11, val func loss 0.11443032324314117\n",
      "\n",
      "episode 12, val func loss 0.13084284961223602\n",
      "\n",
      "episode 13, val func loss 0.145120307803154\n",
      "\n",
      "episode 14, val func loss 0.1420326828956604\n",
      "\n",
      "episode 15, val func loss 0.20238402485847473\n",
      "\n",
      "episode 16, val func loss 0.07237111777067184\n",
      "\n",
      "Val func train loss in epoch 11:0.1539428816176951\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.07253696024417877\n",
      "\n",
      "episode 2, val func loss 0.11416701972484589\n",
      "\n",
      "episode 3, val func loss 0.15006974339485168\n",
      "\n",
      "episode 4, val func loss 0.16560819745063782\n",
      "\n",
      "episode 5, val func loss 0.14298959076404572\n",
      "\n",
      "episode 6, val func loss 0.11645740270614624\n",
      "\n",
      "episode 7, val func loss 0.1815996617078781\n",
      "\n",
      "episode 8, val func loss 0.16380852460861206\n",
      "\n",
      "episode 9, val func loss 0.20060957968235016\n",
      "\n",
      "episode 10, val func loss 0.16752099990844727\n",
      "\n",
      "episode 11, val func loss 0.17639023065567017\n",
      "\n",
      "episode 12, val func loss 0.20074190199375153\n",
      "\n",
      "episode 13, val func loss 0.16807211935520172\n",
      "\n",
      "episode 14, val func loss 0.13033798336982727\n",
      "\n",
      "episode 15, val func loss 0.14452554285526276\n",
      "\n",
      "episode 16, val func loss 0.1670694500207901\n",
      "\n",
      "Val func train loss in epoch 12:0.15390655677765608\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1425122618675232\n",
      "\n",
      "episode 2, val func loss 0.20146246254444122\n",
      "\n",
      "episode 3, val func loss 0.14459146559238434\n",
      "\n",
      "episode 4, val func loss 0.13055923581123352\n",
      "\n",
      "episode 5, val func loss 0.0733402818441391\n",
      "\n",
      "episode 6, val func loss 0.17641447484493256\n",
      "\n",
      "episode 7, val func loss 0.16697372496128082\n",
      "\n",
      "episode 8, val func loss 0.16577042639255524\n",
      "\n",
      "episode 9, val func loss 0.11423124372959137\n",
      "\n",
      "episode 10, val func loss 0.166628897190094\n",
      "\n",
      "episode 11, val func loss 0.1681109070777893\n",
      "\n",
      "episode 12, val func loss 0.16249017417430878\n",
      "\n",
      "episode 13, val func loss 0.18136480450630188\n",
      "\n",
      "episode 14, val func loss 0.15024088323116302\n",
      "\n",
      "episode 15, val func loss 0.11593903601169586\n",
      "\n",
      "episode 16, val func loss 0.20099841058254242\n",
      "\n",
      "Val func train loss in epoch 13:0.15385179314762354\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1438734531402588\n",
      "\n",
      "episode 2, val func loss 0.16554972529411316\n",
      "\n",
      "episode 3, val func loss 0.11481540650129318\n",
      "\n",
      "episode 4, val func loss 0.16755835711956024\n",
      "\n",
      "episode 5, val func loss 0.20053730905056\n",
      "\n",
      "episode 6, val func loss 0.20041640102863312\n",
      "\n",
      "episode 7, val func loss 0.07299450039863586\n",
      "\n",
      "episode 8, val func loss 0.18119414150714874\n",
      "\n",
      "episode 9, val func loss 0.14991123974323273\n",
      "\n",
      "episode 10, val func loss 0.17675001919269562\n",
      "\n",
      "episode 11, val func loss 0.16734866797924042\n",
      "\n",
      "episode 12, val func loss 0.1428706794977188\n",
      "\n",
      "episode 13, val func loss 0.16231794655323029\n",
      "\n",
      "episode 14, val func loss 0.1305377185344696\n",
      "\n",
      "episode 15, val func loss 0.11745386570692062\n",
      "\n",
      "episode 16, val func loss 0.16912060976028442\n",
      "\n",
      "Val func train loss in epoch 14:0.15395312756299973\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1419599950313568\n",
      "\n",
      "episode 2, val func loss 0.11433184146881104\n",
      "\n",
      "episode 3, val func loss 0.1672915369272232\n",
      "\n",
      "episode 4, val func loss 0.17659887671470642\n",
      "\n",
      "episode 5, val func loss 0.18148547410964966\n",
      "\n",
      "episode 6, val func loss 0.20007583498954773\n",
      "\n",
      "episode 7, val func loss 0.14498968422412872\n",
      "\n",
      "episode 8, val func loss 0.07459674775600433\n",
      "\n",
      "episode 9, val func loss 0.15064622461795807\n",
      "\n",
      "episode 10, val func loss 0.11553610116243362\n",
      "\n",
      "episode 11, val func loss 0.16701020300388336\n",
      "\n",
      "episode 12, val func loss 0.13037022948265076\n",
      "\n",
      "episode 13, val func loss 0.20121246576309204\n",
      "\n",
      "episode 14, val func loss 0.16591329872608185\n",
      "\n",
      "episode 15, val func loss 0.1621532291173935\n",
      "\n",
      "episode 16, val func loss 0.1687946617603302\n",
      "\n",
      "Val func train loss in epoch 15:0.1539354003034532\n",
      "***********************TIME WAS 5.171599253018697 min*****************************\n",
      "\n",
      "**********************ROUND 28 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.11736278980970383\n",
      "\n",
      "episode 2, policy loss -0.17233452200889587\n",
      "\n",
      "episode 3, policy loss -0.1269860565662384\n",
      "\n",
      "episode 4, policy loss -0.13614247739315033\n",
      "\n",
      "episode 5, policy loss -0.11640489101409912\n",
      "\n",
      "episode 6, policy loss -0.11220589280128479\n",
      "\n",
      "episode 7, policy loss -0.17916902899742126\n",
      "\n",
      "episode 8, policy loss -0.11083291471004486\n",
      "\n",
      "episode 9, policy loss -0.15144072473049164\n",
      "\n",
      "episode 10, policy loss -0.09587924182415009\n",
      "\n",
      "episode 11, policy loss -0.11491361260414124\n",
      "\n",
      "episode 12, policy loss -0.16714245080947876\n",
      "\n",
      "episode 13, policy loss -0.12164387106895447\n",
      "\n",
      "episode 14, policy loss -0.14396996796131134\n",
      "\n",
      "episode 15, policy loss -0.11564086377620697\n",
      "\n",
      "episode 16, policy loss -0.08910474926233292\n",
      "\n",
      "Policy train loss in epoch 0:-0.12944837845861912\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.11544942855834961\n",
      "\n",
      "episode 2, policy loss -0.11995478719472885\n",
      "\n",
      "episode 3, policy loss -0.11324293911457062\n",
      "\n",
      "episode 4, policy loss -0.17889341711997986\n",
      "\n",
      "episode 5, policy loss -0.11575566232204437\n",
      "\n",
      "episode 6, policy loss -0.1504783034324646\n",
      "\n",
      "episode 7, policy loss -0.11950661242008209\n",
      "\n",
      "episode 8, policy loss -0.09088921546936035\n",
      "\n",
      "episode 9, policy loss -0.0946008488535881\n",
      "\n",
      "episode 10, policy loss -0.13130086660385132\n",
      "\n",
      "episode 11, policy loss -0.17213565111160278\n",
      "\n",
      "episode 12, policy loss -0.1230069100856781\n",
      "\n",
      "episode 13, policy loss -0.1346529871225357\n",
      "\n",
      "episode 14, policy loss -0.1438320130109787\n",
      "\n",
      "episode 15, policy loss -0.1470300853252411\n",
      "\n",
      "episode 16, policy loss -0.1689443737268448\n",
      "\n",
      "Policy train loss in epoch 1:-0.1324796313419938\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.11966739594936371\n",
      "\n",
      "episode 2, policy loss -0.09558002650737762\n",
      "\n",
      "episode 3, policy loss -0.09239710122346878\n",
      "\n",
      "episode 4, policy loss -0.15019023418426514\n",
      "\n",
      "episode 5, policy loss -0.11919163912534714\n",
      "\n",
      "episode 6, policy loss -0.11487317085266113\n",
      "\n",
      "episode 7, policy loss -0.12082509696483612\n",
      "\n",
      "episode 8, policy loss -0.12122247368097305\n",
      "\n",
      "episode 9, policy loss -0.15725453197956085\n",
      "\n",
      "episode 10, policy loss -0.16867244243621826\n",
      "\n",
      "episode 11, policy loss -0.13516880571842194\n",
      "\n",
      "episode 12, policy loss -0.18511119484901428\n",
      "\n",
      "episode 13, policy loss -0.11369501054286957\n",
      "\n",
      "episode 14, policy loss -0.17218685150146484\n",
      "\n",
      "episode 15, policy loss -0.14529269933700562\n",
      "\n",
      "episode 16, policy loss -0.13010507822036743\n",
      "\n",
      "Policy train loss in epoch 2:-0.13383960956707597\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.12893781065940857\n",
      "\n",
      "episode 2, policy loss -0.12208442389965057\n",
      "\n",
      "episode 3, policy loss -0.09300125390291214\n",
      "\n",
      "episode 4, policy loss -0.11622138321399689\n",
      "\n",
      "episode 5, policy loss -0.14727312326431274\n",
      "\n",
      "episode 6, policy loss -0.09603682160377502\n",
      "\n",
      "episode 7, policy loss -0.17453770339488983\n",
      "\n",
      "episode 8, policy loss -0.17006617784500122\n",
      "\n",
      "episode 9, policy loss -0.15562716126441956\n",
      "\n",
      "episode 10, policy loss -0.1159818023443222\n",
      "\n",
      "episode 11, policy loss -0.18451112508773804\n",
      "\n",
      "episode 12, policy loss -0.1184535026550293\n",
      "\n",
      "episode 13, policy loss -0.13294722139835358\n",
      "\n",
      "episode 14, policy loss -0.11671291291713715\n",
      "\n",
      "episode 15, policy loss -0.11449916660785675\n",
      "\n",
      "episode 16, policy loss -0.14373913407325745\n",
      "\n",
      "Policy train loss in epoch 3:-0.1331644202582538\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1131633073091507\n",
      "\n",
      "episode 2, val func loss 0.19767479598522186\n",
      "\n",
      "episode 3, val func loss 0.16546598076820374\n",
      "\n",
      "episode 4, val func loss 0.17909087240695953\n",
      "\n",
      "episode 5, val func loss 0.19190610945224762\n",
      "\n",
      "episode 6, val func loss 0.18592695891857147\n",
      "\n",
      "episode 7, val func loss 0.17681248486042023\n",
      "\n",
      "episode 8, val func loss 0.18891359865665436\n",
      "\n",
      "episode 9, val func loss 0.1488453596830368\n",
      "\n",
      "episode 10, val func loss 0.19157691299915314\n",
      "\n",
      "episode 11, val func loss 0.17360760271549225\n",
      "\n",
      "episode 12, val func loss 0.13854540884494781\n",
      "\n",
      "episode 13, val func loss 0.18957503139972687\n",
      "\n",
      "episode 14, val func loss 0.1854913979768753\n",
      "\n",
      "episode 15, val func loss 0.13192257285118103\n",
      "\n",
      "episode 16, val func loss 0.21371565759181976\n",
      "\n",
      "Val func train loss in epoch 0:0.1732646282762289\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.15018372237682343\n",
      "\n",
      "episode 2, val func loss 0.18682774901390076\n",
      "\n",
      "episode 3, val func loss 0.18158403038978577\n",
      "\n",
      "episode 4, val func loss 0.19184428453445435\n",
      "\n",
      "episode 5, val func loss 0.2116398811340332\n",
      "\n",
      "episode 6, val func loss 0.1897755265235901\n",
      "\n",
      "episode 7, val func loss 0.17903020977973938\n",
      "\n",
      "episode 8, val func loss 0.1406734138727188\n",
      "\n",
      "episode 9, val func loss 0.16483654081821442\n",
      "\n",
      "episode 10, val func loss 0.19182226061820984\n",
      "\n",
      "episode 11, val func loss 0.11358895897865295\n",
      "\n",
      "episode 12, val func loss 0.1319686472415924\n",
      "\n",
      "episode 13, val func loss 0.17336347699165344\n",
      "\n",
      "episode 14, val func loss 0.18097981810569763\n",
      "\n",
      "episode 15, val func loss 0.19834555685520172\n",
      "\n",
      "episode 16, val func loss 0.17563945055007935\n",
      "\n",
      "Val func train loss in epoch 1:0.17263147048652172\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.13455449044704437\n",
      "\n",
      "episode 2, val func loss 0.18226875364780426\n",
      "\n",
      "episode 3, val func loss 0.1754717081785202\n",
      "\n",
      "episode 4, val func loss 0.19017750024795532\n",
      "\n",
      "episode 5, val func loss 0.18108202517032623\n",
      "\n",
      "episode 6, val func loss 0.14896784722805023\n",
      "\n",
      "episode 7, val func loss 0.19659487903118134\n",
      "\n",
      "episode 8, val func loss 0.1811172217130661\n",
      "\n",
      "episode 9, val func loss 0.17050053179264069\n",
      "\n",
      "episode 10, val func loss 0.14197438955307007\n",
      "\n",
      "episode 11, val func loss 0.11156998574733734\n",
      "\n",
      "episode 12, val func loss 0.17347431182861328\n",
      "\n",
      "episode 13, val func loss 0.19246041774749756\n",
      "\n",
      "episode 14, val func loss 0.19207444787025452\n",
      "\n",
      "episode 15, val func loss 0.1870555281639099\n",
      "\n",
      "episode 16, val func loss 0.21528835594654083\n",
      "\n",
      "Val func train loss in epoch 2:0.17341452464461327\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.11157136410474777\n",
      "\n",
      "episode 2, val func loss 0.1828709989786148\n",
      "\n",
      "episode 3, val func loss 0.18813392519950867\n",
      "\n",
      "episode 4, val func loss 0.19026973843574524\n",
      "\n",
      "episode 5, val func loss 0.21277756989002228\n",
      "\n",
      "episode 6, val func loss 0.17388403415679932\n",
      "\n",
      "episode 7, val func loss 0.13290616869926453\n",
      "\n",
      "episode 8, val func loss 0.17631873488426208\n",
      "\n",
      "episode 9, val func loss 0.14888544380664825\n",
      "\n",
      "episode 10, val func loss 0.1647651344537735\n",
      "\n",
      "episode 11, val func loss 0.17992575466632843\n",
      "\n",
      "episode 12, val func loss 0.19209016859531403\n",
      "\n",
      "episode 13, val func loss 0.13876552879810333\n",
      "\n",
      "episode 14, val func loss 0.1986323744058609\n",
      "\n",
      "episode 15, val func loss 0.19000877439975739\n",
      "\n",
      "episode 16, val func loss 0.1823132038116455\n",
      "\n",
      "Val func train loss in epoch 3:0.17275743233039975\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17603851854801178\n",
      "\n",
      "episode 2, val func loss 0.17907153069972992\n",
      "\n",
      "episode 3, val func loss 0.18515825271606445\n",
      "\n",
      "episode 4, val func loss 0.17454899847507477\n",
      "\n",
      "episode 5, val func loss 0.1819194257259369\n",
      "\n",
      "episode 6, val func loss 0.1655690222978592\n",
      "\n",
      "episode 7, val func loss 0.14870776236057281\n",
      "\n",
      "episode 8, val func loss 0.19136379659175873\n",
      "\n",
      "episode 9, val func loss 0.1896839588880539\n",
      "\n",
      "episode 10, val func loss 0.19789376854896545\n",
      "\n",
      "episode 11, val func loss 0.1391604244709015\n",
      "\n",
      "episode 12, val func loss 0.13294699788093567\n",
      "\n",
      "episode 13, val func loss 0.21388810873031616\n",
      "\n",
      "episode 14, val func loss 0.11152470856904984\n",
      "\n",
      "episode 15, val func loss 0.18992355465888977\n",
      "\n",
      "episode 16, val func loss 0.18310095369815826\n",
      "\n",
      "Val func train loss in epoch 4:0.17253123642876744\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1760980784893036\n",
      "\n",
      "episode 2, val func loss 0.13928832113742828\n",
      "\n",
      "episode 3, val func loss 0.179068461060524\n",
      "\n",
      "episode 4, val func loss 0.17317569255828857\n",
      "\n",
      "episode 5, val func loss 0.18348360061645508\n",
      "\n",
      "episode 6, val func loss 0.14938783645629883\n",
      "\n",
      "episode 7, val func loss 0.19846104085445404\n",
      "\n",
      "episode 8, val func loss 0.1921844780445099\n",
      "\n",
      "episode 9, val func loss 0.111258365213871\n",
      "\n",
      "episode 10, val func loss 0.19033601880073547\n",
      "\n",
      "episode 11, val func loss 0.13391298055648804\n",
      "\n",
      "episode 12, val func loss 0.18942046165466309\n",
      "\n",
      "episode 13, val func loss 0.16599392890930176\n",
      "\n",
      "episode 14, val func loss 0.1851048320531845\n",
      "\n",
      "episode 15, val func loss 0.18204551935195923\n",
      "\n",
      "episode 16, val func loss 0.2142147272825241\n",
      "\n",
      "Val func train loss in epoch 5:0.17271464643999934\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.21551063656806946\n",
      "\n",
      "episode 2, val func loss 0.17913129925727844\n",
      "\n",
      "episode 3, val func loss 0.19293586909770966\n",
      "\n",
      "episode 4, val func loss 0.1491132229566574\n",
      "\n",
      "episode 5, val func loss 0.11149615794420242\n",
      "\n",
      "episode 6, val func loss 0.16557420790195465\n",
      "\n",
      "episode 7, val func loss 0.19055570662021637\n",
      "\n",
      "episode 8, val func loss 0.1749790459871292\n",
      "\n",
      "episode 9, val func loss 0.18940038979053497\n",
      "\n",
      "episode 10, val func loss 0.13211651146411896\n",
      "\n",
      "episode 11, val func loss 0.18089734017848969\n",
      "\n",
      "episode 12, val func loss 0.1383175104856491\n",
      "\n",
      "episode 13, val func loss 0.20035377144813538\n",
      "\n",
      "episode 14, val func loss 0.17319627106189728\n",
      "\n",
      "episode 15, val func loss 0.18597425520420074\n",
      "\n",
      "episode 16, val func loss 0.18299616873264313\n",
      "\n",
      "Val func train loss in epoch 6:0.17265927279368043\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17394228279590607\n",
      "\n",
      "episode 2, val func loss 0.1402919441461563\n",
      "\n",
      "episode 3, val func loss 0.18191474676132202\n",
      "\n",
      "episode 4, val func loss 0.1852191686630249\n",
      "\n",
      "episode 5, val func loss 0.19645090401172638\n",
      "\n",
      "episode 6, val func loss 0.19208678603172302\n",
      "\n",
      "episode 7, val func loss 0.13202831149101257\n",
      "\n",
      "episode 8, val func loss 0.14883054792881012\n",
      "\n",
      "episode 9, val func loss 0.21508412063121796\n",
      "\n",
      "episode 10, val func loss 0.19006364047527313\n",
      "\n",
      "episode 11, val func loss 0.1897590458393097\n",
      "\n",
      "episode 12, val func loss 0.18137389421463013\n",
      "\n",
      "episode 13, val func loss 0.17900285124778748\n",
      "\n",
      "episode 14, val func loss 0.16737112402915955\n",
      "\n",
      "episode 15, val func loss 0.17532920837402344\n",
      "\n",
      "episode 16, val func loss 0.1111832931637764\n",
      "\n",
      "Val func train loss in epoch 7:0.1724957418628037\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.18043257296085358\n",
      "\n",
      "episode 2, val func loss 0.21314698457717896\n",
      "\n",
      "episode 3, val func loss 0.19287531077861786\n",
      "\n",
      "episode 4, val func loss 0.19022388756275177\n",
      "\n",
      "episode 5, val func loss 0.18195240199565887\n",
      "\n",
      "episode 6, val func loss 0.18947413563728333\n",
      "\n",
      "episode 7, val func loss 0.11171042919158936\n",
      "\n",
      "episode 8, val func loss 0.1973545104265213\n",
      "\n",
      "episode 9, val func loss 0.173249751329422\n",
      "\n",
      "episode 10, val func loss 0.17558911442756653\n",
      "\n",
      "episode 11, val func loss 0.13243632018566132\n",
      "\n",
      "episode 12, val func loss 0.1798924207687378\n",
      "\n",
      "episode 13, val func loss 0.13915644586086273\n",
      "\n",
      "episode 14, val func loss 0.16558313369750977\n",
      "\n",
      "episode 15, val func loss 0.14850690960884094\n",
      "\n",
      "episode 16, val func loss 0.18574242293834686\n",
      "\n",
      "Val func train loss in epoch 8:0.17233292199671268\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18604643642902374\n",
      "\n",
      "episode 2, val func loss 0.18135452270507812\n",
      "\n",
      "episode 3, val func loss 0.1794501692056656\n",
      "\n",
      "episode 4, val func loss 0.18158307671546936\n",
      "\n",
      "episode 5, val func loss 0.1663534939289093\n",
      "\n",
      "episode 6, val func loss 0.14908970892429352\n",
      "\n",
      "episode 7, val func loss 0.1760566234588623\n",
      "\n",
      "episode 8, val func loss 0.21288087964057922\n",
      "\n",
      "episode 9, val func loss 0.18994058668613434\n",
      "\n",
      "episode 10, val func loss 0.1757008284330368\n",
      "\n",
      "episode 11, val func loss 0.19332990050315857\n",
      "\n",
      "episode 12, val func loss 0.11106874793767929\n",
      "\n",
      "episode 13, val func loss 0.1967127025127411\n",
      "\n",
      "episode 14, val func loss 0.13181079924106598\n",
      "\n",
      "episode 15, val func loss 0.13890036940574646\n",
      "\n",
      "episode 16, val func loss 0.18986403942108154\n",
      "\n",
      "Val func train loss in epoch 9:0.17250893032178283\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1980302631855011\n",
      "\n",
      "episode 2, val func loss 0.1320222169160843\n",
      "\n",
      "episode 3, val func loss 0.13948047161102295\n",
      "\n",
      "episode 4, val func loss 0.18951213359832764\n",
      "\n",
      "episode 5, val func loss 0.1897767335176468\n",
      "\n",
      "episode 6, val func loss 0.19204005599021912\n",
      "\n",
      "episode 7, val func loss 0.17335858941078186\n",
      "\n",
      "episode 8, val func loss 0.18071067333221436\n",
      "\n",
      "episode 9, val func loss 0.21477681398391724\n",
      "\n",
      "episode 10, val func loss 0.18207375705242157\n",
      "\n",
      "episode 11, val func loss 0.17926494777202606\n",
      "\n",
      "episode 12, val func loss 0.1112142950296402\n",
      "\n",
      "episode 13, val func loss 0.18534229695796967\n",
      "\n",
      "episode 14, val func loss 0.1675533652305603\n",
      "\n",
      "episode 15, val func loss 0.14988499879837036\n",
      "\n",
      "episode 16, val func loss 0.17617711424827576\n",
      "\n",
      "Val func train loss in epoch 10:0.1725761704146862\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.17948000133037567\n",
      "\n",
      "episode 2, val func loss 0.11098749935626984\n",
      "\n",
      "episode 3, val func loss 0.18963086605072021\n",
      "\n",
      "episode 4, val func loss 0.19268494844436646\n",
      "\n",
      "episode 5, val func loss 0.21523168683052063\n",
      "\n",
      "episode 6, val func loss 0.18167686462402344\n",
      "\n",
      "episode 7, val func loss 0.16591142117977142\n",
      "\n",
      "episode 8, val func loss 0.19532038271427155\n",
      "\n",
      "episode 9, val func loss 0.17542657256126404\n",
      "\n",
      "episode 10, val func loss 0.13386811316013336\n",
      "\n",
      "episode 11, val func loss 0.18298152089118958\n",
      "\n",
      "episode 12, val func loss 0.14861221611499786\n",
      "\n",
      "episode 13, val func loss 0.1908891499042511\n",
      "\n",
      "episode 14, val func loss 0.13852424919605255\n",
      "\n",
      "episode 15, val func loss 0.18623559176921844\n",
      "\n",
      "episode 16, val func loss 0.17331242561340332\n",
      "\n",
      "Val func train loss in epoch 11:0.17254834435880184\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19042342901229858\n",
      "\n",
      "episode 2, val func loss 0.18599161505699158\n",
      "\n",
      "episode 3, val func loss 0.1824696958065033\n",
      "\n",
      "episode 4, val func loss 0.1395689994096756\n",
      "\n",
      "episode 5, val func loss 0.13333268463611603\n",
      "\n",
      "episode 6, val func loss 0.17916539311408997\n",
      "\n",
      "episode 7, val func loss 0.19061346352100372\n",
      "\n",
      "episode 8, val func loss 0.182749941945076\n",
      "\n",
      "episode 9, val func loss 0.16587607562541962\n",
      "\n",
      "episode 10, val func loss 0.1741085648536682\n",
      "\n",
      "episode 11, val func loss 0.19834385812282562\n",
      "\n",
      "episode 12, val func loss 0.17576861381530762\n",
      "\n",
      "episode 13, val func loss 0.21568091213703156\n",
      "\n",
      "episode 14, val func loss 0.19280897080898285\n",
      "\n",
      "episode 15, val func loss 0.11107946932315826\n",
      "\n",
      "episode 16, val func loss 0.1489211767911911\n",
      "\n",
      "Val func train loss in epoch 12:0.17293142899870872\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.11130125820636749\n",
      "\n",
      "episode 2, val func loss 0.17643864452838898\n",
      "\n",
      "episode 3, val func loss 0.18544666469097137\n",
      "\n",
      "episode 4, val func loss 0.17953987419605255\n",
      "\n",
      "episode 5, val func loss 0.1825980544090271\n",
      "\n",
      "episode 6, val func loss 0.19627660512924194\n",
      "\n",
      "episode 7, val func loss 0.13210031390190125\n",
      "\n",
      "episode 8, val func loss 0.21456199884414673\n",
      "\n",
      "episode 9, val func loss 0.14947004616260529\n",
      "\n",
      "episode 10, val func loss 0.17371977865695953\n",
      "\n",
      "episode 11, val func loss 0.13911767303943634\n",
      "\n",
      "episode 12, val func loss 0.19224520027637482\n",
      "\n",
      "episode 13, val func loss 0.16556169092655182\n",
      "\n",
      "episode 14, val func loss 0.19047990441322327\n",
      "\n",
      "episode 15, val func loss 0.18346162140369415\n",
      "\n",
      "episode 16, val func loss 0.19083885848522186\n",
      "\n",
      "Val func train loss in epoch 13:0.17269738670438528\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1758260279893875\n",
      "\n",
      "episode 2, val func loss 0.17907825112342834\n",
      "\n",
      "episode 3, val func loss 0.16706475615501404\n",
      "\n",
      "episode 4, val func loss 0.1898493617773056\n",
      "\n",
      "episode 5, val func loss 0.1941521167755127\n",
      "\n",
      "episode 6, val func loss 0.18589727580547333\n",
      "\n",
      "episode 7, val func loss 0.18209712207317352\n",
      "\n",
      "episode 8, val func loss 0.11114189028739929\n",
      "\n",
      "episode 9, val func loss 0.13878493010997772\n",
      "\n",
      "episode 10, val func loss 0.19033776223659515\n",
      "\n",
      "episode 11, val func loss 0.2149418741464615\n",
      "\n",
      "episode 12, val func loss 0.13233856856822968\n",
      "\n",
      "episode 13, val func loss 0.1961084008216858\n",
      "\n",
      "episode 14, val func loss 0.174578458070755\n",
      "\n",
      "episode 15, val func loss 0.14894971251487732\n",
      "\n",
      "episode 16, val func loss 0.18223758041858673\n",
      "\n",
      "Val func train loss in epoch 14:0.17271150555461645\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1736813187599182\n",
      "\n",
      "episode 2, val func loss 0.1321154534816742\n",
      "\n",
      "episode 3, val func loss 0.16614024341106415\n",
      "\n",
      "episode 4, val func loss 0.21934226155281067\n",
      "\n",
      "episode 5, val func loss 0.13779538869857788\n",
      "\n",
      "episode 6, val func loss 0.18631549179553986\n",
      "\n",
      "episode 7, val func loss 0.181064635515213\n",
      "\n",
      "episode 8, val func loss 0.19087250530719757\n",
      "\n",
      "episode 9, val func loss 0.1963866800069809\n",
      "\n",
      "episode 10, val func loss 0.17889417707920074\n",
      "\n",
      "episode 11, val func loss 0.1498335599899292\n",
      "\n",
      "episode 12, val func loss 0.18131449818611145\n",
      "\n",
      "episode 13, val func loss 0.11085154116153717\n",
      "\n",
      "episode 14, val func loss 0.19482851028442383\n",
      "\n",
      "episode 15, val func loss 0.1755131483078003\n",
      "\n",
      "episode 16, val func loss 0.19065934419631958\n",
      "\n",
      "Val func train loss in epoch 15:0.17285054735839367\n",
      "***********************TIME WAS 5.169432747364044 min*****************************\n",
      "\n",
      "**********************ROUND 29 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.07823833078145981\n",
      "\n",
      "episode 2, policy loss -0.09201748669147491\n",
      "\n",
      "episode 3, policy loss -0.10383149236440659\n",
      "\n",
      "episode 4, policy loss -0.12813282012939453\n",
      "\n",
      "episode 5, policy loss -0.1274867057800293\n",
      "\n",
      "episode 6, policy loss -0.11458884179592133\n",
      "\n",
      "episode 7, policy loss -0.06545226275920868\n",
      "\n",
      "episode 8, policy loss -0.1127924770116806\n",
      "\n",
      "episode 9, policy loss -0.09874574095010757\n",
      "\n",
      "episode 10, policy loss -0.09851394593715668\n",
      "\n",
      "episode 11, policy loss -0.09509456157684326\n",
      "\n",
      "episode 12, policy loss -0.14501553773880005\n",
      "\n",
      "episode 13, policy loss -0.1757311075925827\n",
      "\n",
      "episode 14, policy loss -0.07906125485897064\n",
      "\n",
      "episode 15, policy loss -0.07754865288734436\n",
      "\n",
      "episode 16, policy loss -0.07819531112909317\n",
      "\n",
      "Policy train loss in epoch 0:-0.10440290812402964\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.07860062271356583\n",
      "\n",
      "episode 2, policy loss -0.06745631247758865\n",
      "\n",
      "episode 3, policy loss -0.13127000629901886\n",
      "\n",
      "episode 4, policy loss -0.1772192418575287\n",
      "\n",
      "episode 5, policy loss -0.12543882429599762\n",
      "\n",
      "episode 6, policy loss -0.14514076709747314\n",
      "\n",
      "episode 7, policy loss -0.09859462082386017\n",
      "\n",
      "episode 8, policy loss -0.0756351500749588\n",
      "\n",
      "episode 9, policy loss -0.10707753896713257\n",
      "\n",
      "episode 10, policy loss -0.09061914682388306\n",
      "\n",
      "episode 11, policy loss -0.07698662579059601\n",
      "\n",
      "episode 12, policy loss -0.07799680531024933\n",
      "\n",
      "episode 13, policy loss -0.09667303413152695\n",
      "\n",
      "episode 14, policy loss -0.11463947594165802\n",
      "\n",
      "episode 15, policy loss -0.09782345592975616\n",
      "\n",
      "episode 16, policy loss -0.11339707672595978\n",
      "\n",
      "Policy train loss in epoch 1:-0.1046605440787971\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.06701124459505081\n",
      "\n",
      "episode 2, policy loss -0.10503342747688293\n",
      "\n",
      "episode 3, policy loss -0.11512821912765503\n",
      "\n",
      "episode 4, policy loss -0.12690138816833496\n",
      "\n",
      "episode 5, policy loss -0.09930139780044556\n",
      "\n",
      "episode 6, policy loss -0.07645796239376068\n",
      "\n",
      "episode 7, policy loss -0.09621243178844452\n",
      "\n",
      "episode 8, policy loss -0.1325049251317978\n",
      "\n",
      "episode 9, policy loss -0.08001801371574402\n",
      "\n",
      "episode 10, policy loss -0.1144801452755928\n",
      "\n",
      "episode 11, policy loss -0.17545762658119202\n",
      "\n",
      "episode 12, policy loss -0.09066692739725113\n",
      "\n",
      "episode 13, policy loss -0.14625775814056396\n",
      "\n",
      "episode 14, policy loss -0.077581986784935\n",
      "\n",
      "episode 15, policy loss -0.09139526635408401\n",
      "\n",
      "episode 16, policy loss -0.07447212934494019\n",
      "\n",
      "Policy train loss in epoch 2:-0.10430505312979221\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.07776559889316559\n",
      "\n",
      "episode 2, policy loss -0.11799229681491852\n",
      "\n",
      "episode 3, policy loss -0.17786294221878052\n",
      "\n",
      "episode 4, policy loss -0.07991386204957962\n",
      "\n",
      "episode 5, policy loss -0.07836978137493134\n",
      "\n",
      "episode 6, policy loss -0.12149795889854431\n",
      "\n",
      "episode 7, policy loss -0.08910642564296722\n",
      "\n",
      "episode 8, policy loss -0.10488398373126984\n",
      "\n",
      "episode 9, policy loss -0.13351179659366608\n",
      "\n",
      "episode 10, policy loss -0.07593019306659698\n",
      "\n",
      "episode 11, policy loss -0.14709198474884033\n",
      "\n",
      "episode 12, policy loss -0.11565208435058594\n",
      "\n",
      "episode 13, policy loss -0.06626708805561066\n",
      "\n",
      "episode 14, policy loss -0.0926050990819931\n",
      "\n",
      "episode 15, policy loss -0.09724169969558716\n",
      "\n",
      "episode 16, policy loss -0.09849964827299118\n",
      "\n",
      "Policy train loss in epoch 3:-0.10463702771812677\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.13785909116268158\n",
      "\n",
      "episode 2, val func loss 0.19285809993743896\n",
      "\n",
      "episode 3, val func loss 0.17331184446811676\n",
      "\n",
      "episode 4, val func loss 0.16375766694545746\n",
      "\n",
      "episode 5, val func loss 0.13512098789215088\n",
      "\n",
      "episode 6, val func loss 0.18425025045871735\n",
      "\n",
      "episode 7, val func loss 0.18860244750976562\n",
      "\n",
      "episode 8, val func loss 0.13505913317203522\n",
      "\n",
      "episode 9, val func loss 0.16138316690921783\n",
      "\n",
      "episode 10, val func loss 0.1341589093208313\n",
      "\n",
      "episode 11, val func loss 0.14883510768413544\n",
      "\n",
      "episode 12, val func loss 0.15664872527122498\n",
      "\n",
      "episode 13, val func loss 0.13804134726524353\n",
      "\n",
      "episode 14, val func loss 0.16095584630966187\n",
      "\n",
      "episode 15, val func loss 0.21530494093894958\n",
      "\n",
      "episode 16, val func loss 0.16643688082695007\n",
      "\n",
      "Val func train loss in epoch 0:0.16203652787953615\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.16722631454467773\n",
      "\n",
      "episode 2, val func loss 0.16053293645381927\n",
      "\n",
      "episode 3, val func loss 0.14957307279109955\n",
      "\n",
      "episode 4, val func loss 0.1928217113018036\n",
      "\n",
      "episode 5, val func loss 0.1853669285774231\n",
      "\n",
      "episode 6, val func loss 0.1643252670764923\n",
      "\n",
      "episode 7, val func loss 0.13442553579807281\n",
      "\n",
      "episode 8, val func loss 0.1588854342699051\n",
      "\n",
      "episode 9, val func loss 0.19009166955947876\n",
      "\n",
      "episode 10, val func loss 0.1384924352169037\n",
      "\n",
      "episode 11, val func loss 0.17393116652965546\n",
      "\n",
      "episode 12, val func loss 0.13759899139404297\n",
      "\n",
      "episode 13, val func loss 0.13383285701274872\n",
      "\n",
      "episode 14, val func loss 0.21216757595539093\n",
      "\n",
      "episode 15, val func loss 0.1335802674293518\n",
      "\n",
      "episode 16, val func loss 0.16106611490249634\n",
      "\n",
      "Val func train loss in epoch 1:0.16211989242583513\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.13849857449531555\n",
      "\n",
      "episode 2, val func loss 0.13713274896144867\n",
      "\n",
      "episode 3, val func loss 0.13307397067546844\n",
      "\n",
      "episode 4, val func loss 0.18657498061656952\n",
      "\n",
      "episode 5, val func loss 0.17422740161418915\n",
      "\n",
      "episode 6, val func loss 0.14904625713825226\n",
      "\n",
      "episode 7, val func loss 0.16663265228271484\n",
      "\n",
      "episode 8, val func loss 0.2113863080739975\n",
      "\n",
      "episode 9, val func loss 0.15907439589500427\n",
      "\n",
      "episode 10, val func loss 0.16004958748817444\n",
      "\n",
      "episode 11, val func loss 0.19274605810642242\n",
      "\n",
      "episode 12, val func loss 0.13411845266819\n",
      "\n",
      "episode 13, val func loss 0.1340620368719101\n",
      "\n",
      "episode 14, val func loss 0.1596469134092331\n",
      "\n",
      "episode 15, val func loss 0.16712144017219543\n",
      "\n",
      "episode 16, val func loss 0.19349849224090576\n",
      "\n",
      "Val func train loss in epoch 2:0.16230564191937447\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.13336367905139923\n",
      "\n",
      "episode 2, val func loss 0.16451197862625122\n",
      "\n",
      "episode 3, val func loss 0.13400091230869293\n",
      "\n",
      "episode 4, val func loss 0.13465027511119843\n",
      "\n",
      "episode 5, val func loss 0.13942119479179382\n",
      "\n",
      "episode 6, val func loss 0.16536538302898407\n",
      "\n",
      "episode 7, val func loss 0.21664252877235413\n",
      "\n",
      "episode 8, val func loss 0.13711866736412048\n",
      "\n",
      "episode 9, val func loss 0.18542976677417755\n",
      "\n",
      "episode 10, val func loss 0.16110365092754364\n",
      "\n",
      "episode 11, val func loss 0.1594076007604599\n",
      "\n",
      "episode 12, val func loss 0.19208286702632904\n",
      "\n",
      "episode 13, val func loss 0.159893199801445\n",
      "\n",
      "episode 14, val func loss 0.19181060791015625\n",
      "\n",
      "episode 15, val func loss 0.17220540344715118\n",
      "\n",
      "episode 16, val func loss 0.1494043618440628\n",
      "\n",
      "Val func train loss in epoch 3:0.16227575484663248\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.13441799581050873\n",
      "\n",
      "episode 2, val func loss 0.18852731585502625\n",
      "\n",
      "episode 3, val func loss 0.15026220679283142\n",
      "\n",
      "episode 4, val func loss 0.19276653230190277\n",
      "\n",
      "episode 5, val func loss 0.13809989392757416\n",
      "\n",
      "episode 6, val func loss 0.16453160345554352\n",
      "\n",
      "episode 7, val func loss 0.21098436415195465\n",
      "\n",
      "episode 8, val func loss 0.13501830399036407\n",
      "\n",
      "episode 9, val func loss 0.13495726883411407\n",
      "\n",
      "episode 10, val func loss 0.13935799896717072\n",
      "\n",
      "episode 11, val func loss 0.15827913582324982\n",
      "\n",
      "episode 12, val func loss 0.159540593624115\n",
      "\n",
      "episode 13, val func loss 0.16147105395793915\n",
      "\n",
      "episode 14, val func loss 0.16515441238880157\n",
      "\n",
      "episode 15, val func loss 0.1762460470199585\n",
      "\n",
      "episode 16, val func loss 0.18683147430419922\n",
      "\n",
      "Val func train loss in epoch 4:0.16227788757532835\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.13325780630111694\n",
      "\n",
      "episode 2, val func loss 0.211796373128891\n",
      "\n",
      "episode 3, val func loss 0.14996196329593658\n",
      "\n",
      "episode 4, val func loss 0.19260892271995544\n",
      "\n",
      "episode 5, val func loss 0.13698825240135193\n",
      "\n",
      "episode 6, val func loss 0.17293314635753632\n",
      "\n",
      "episode 7, val func loss 0.16396689414978027\n",
      "\n",
      "episode 8, val func loss 0.15979652106761932\n",
      "\n",
      "episode 9, val func loss 0.15859897434711456\n",
      "\n",
      "episode 10, val func loss 0.13246628642082214\n",
      "\n",
      "episode 11, val func loss 0.1391502022743225\n",
      "\n",
      "episode 12, val func loss 0.13877585530281067\n",
      "\n",
      "episode 13, val func loss 0.19464455544948578\n",
      "\n",
      "episode 14, val func loss 0.1657084971666336\n",
      "\n",
      "episode 15, val func loss 0.18486350774765015\n",
      "\n",
      "episode 16, val func loss 0.16095933318138123\n",
      "\n",
      "Val func train loss in epoch 5:0.16227981820702553\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1642596423625946\n",
      "\n",
      "episode 2, val func loss 0.1501813679933548\n",
      "\n",
      "episode 3, val func loss 0.18439878523349762\n",
      "\n",
      "episode 4, val func loss 0.15910212695598602\n",
      "\n",
      "episode 5, val func loss 0.18960484862327576\n",
      "\n",
      "episode 6, val func loss 0.1601857990026474\n",
      "\n",
      "episode 7, val func loss 0.13843466341495514\n",
      "\n",
      "episode 8, val func loss 0.1333601176738739\n",
      "\n",
      "episode 9, val func loss 0.1648096740245819\n",
      "\n",
      "episode 10, val func loss 0.13374073803424835\n",
      "\n",
      "episode 11, val func loss 0.17754463851451874\n",
      "\n",
      "episode 12, val func loss 0.13789206743240356\n",
      "\n",
      "episode 13, val func loss 0.19365401566028595\n",
      "\n",
      "episode 14, val func loss 0.13348335027694702\n",
      "\n",
      "episode 15, val func loss 0.21015411615371704\n",
      "\n",
      "episode 16, val func loss 0.16059817373752594\n",
      "\n",
      "Val func train loss in epoch 6:0.16196275781840086\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1847994029521942\n",
      "\n",
      "episode 2, val func loss 0.1637497842311859\n",
      "\n",
      "episode 3, val func loss 0.1382375955581665\n",
      "\n",
      "episode 4, val func loss 0.16397395730018616\n",
      "\n",
      "episode 5, val func loss 0.13428747653961182\n",
      "\n",
      "episode 6, val func loss 0.17460478842258453\n",
      "\n",
      "episode 7, val func loss 0.16515977680683136\n",
      "\n",
      "episode 8, val func loss 0.1495613157749176\n",
      "\n",
      "episode 9, val func loss 0.13313192129135132\n",
      "\n",
      "episode 10, val func loss 0.19353120028972626\n",
      "\n",
      "episode 11, val func loss 0.19313468039035797\n",
      "\n",
      "episode 12, val func loss 0.13448219001293182\n",
      "\n",
      "episode 13, val func loss 0.15877965092658997\n",
      "\n",
      "episode 14, val func loss 0.13871446251869202\n",
      "\n",
      "episode 15, val func loss 0.2113751620054245\n",
      "\n",
      "episode 16, val func loss 0.15996848046779633\n",
      "\n",
      "Val func train loss in epoch 7:0.16234324034303427\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16775888204574585\n",
      "\n",
      "episode 2, val func loss 0.17291414737701416\n",
      "\n",
      "episode 3, val func loss 0.19258899986743927\n",
      "\n",
      "episode 4, val func loss 0.1378650963306427\n",
      "\n",
      "episode 5, val func loss 0.13326109945774078\n",
      "\n",
      "episode 6, val func loss 0.149549201130867\n",
      "\n",
      "episode 7, val func loss 0.13290174305438995\n",
      "\n",
      "episode 8, val func loss 0.15957514941692352\n",
      "\n",
      "episode 9, val func loss 0.13744351267814636\n",
      "\n",
      "episode 10, val func loss 0.16046561300754547\n",
      "\n",
      "episode 11, val func loss 0.13275708258152008\n",
      "\n",
      "episode 12, val func loss 0.15647056698799133\n",
      "\n",
      "episode 13, val func loss 0.18678170442581177\n",
      "\n",
      "episode 14, val func loss 0.1912371665239334\n",
      "\n",
      "episode 15, val func loss 0.16423168778419495\n",
      "\n",
      "episode 16, val func loss 0.20944969356060028\n",
      "\n",
      "Val func train loss in epoch 8:0.16157820913940668\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.16529984772205353\n",
      "\n",
      "episode 2, val func loss 0.13939639925956726\n",
      "\n",
      "episode 3, val func loss 0.16401103138923645\n",
      "\n",
      "episode 4, val func loss 0.1747545450925827\n",
      "\n",
      "episode 5, val func loss 0.17044349014759064\n",
      "\n",
      "episode 6, val func loss 0.16097959876060486\n",
      "\n",
      "episode 7, val func loss 0.14888326823711395\n",
      "\n",
      "episode 8, val func loss 0.19611579179763794\n",
      "\n",
      "episode 9, val func loss 0.22199082374572754\n",
      "\n",
      "episode 10, val func loss 0.13844241201877594\n",
      "\n",
      "episode 11, val func loss 0.13272148370742798\n",
      "\n",
      "episode 12, val func loss 0.19237910211086273\n",
      "\n",
      "episode 13, val func loss 0.18507659435272217\n",
      "\n",
      "episode 14, val func loss 0.13801653683185577\n",
      "\n",
      "episode 15, val func loss 0.1616317331790924\n",
      "\n",
      "episode 16, val func loss 0.13649414479732513\n",
      "\n",
      "Val func train loss in epoch 9:0.16416480019688606\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.13845929503440857\n",
      "\n",
      "episode 2, val func loss 0.18900148570537567\n",
      "\n",
      "episode 3, val func loss 0.21062996983528137\n",
      "\n",
      "episode 4, val func loss 0.17278353869915009\n",
      "\n",
      "episode 5, val func loss 0.13540825247764587\n",
      "\n",
      "episode 6, val func loss 0.16386905312538147\n",
      "\n",
      "episode 7, val func loss 0.15921713411808014\n",
      "\n",
      "episode 8, val func loss 0.13370275497436523\n",
      "\n",
      "episode 9, val func loss 0.16031286120414734\n",
      "\n",
      "episode 10, val func loss 0.13806600868701935\n",
      "\n",
      "episode 11, val func loss 0.13324744999408722\n",
      "\n",
      "episode 12, val func loss 0.16531270742416382\n",
      "\n",
      "episode 13, val func loss 0.16081933677196503\n",
      "\n",
      "episode 14, val func loss 0.19554167985916138\n",
      "\n",
      "episode 15, val func loss 0.187240868806839\n",
      "\n",
      "episode 16, val func loss 0.14908480644226074\n",
      "\n",
      "Val func train loss in epoch 10:0.16204357519745827\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16017068922519684\n",
      "\n",
      "episode 2, val func loss 0.16478681564331055\n",
      "\n",
      "episode 3, val func loss 0.18806420266628265\n",
      "\n",
      "episode 4, val func loss 0.16524243354797363\n",
      "\n",
      "episode 5, val func loss 0.1517334282398224\n",
      "\n",
      "episode 6, val func loss 0.18414416909217834\n",
      "\n",
      "episode 7, val func loss 0.13479368388652802\n",
      "\n",
      "episode 8, val func loss 0.16565191745758057\n",
      "\n",
      "episode 9, val func loss 0.1752452701330185\n",
      "\n",
      "episode 10, val func loss 0.1573866456747055\n",
      "\n",
      "episode 11, val func loss 0.2185993194580078\n",
      "\n",
      "episode 12, val func loss 0.13340935111045837\n",
      "\n",
      "episode 13, val func loss 0.1379275768995285\n",
      "\n",
      "episode 14, val func loss 0.13714483380317688\n",
      "\n",
      "episode 15, val func loss 0.13452810049057007\n",
      "\n",
      "episode 16, val func loss 0.1931338608264923\n",
      "\n",
      "Val func train loss in epoch 11:0.16262264363467693\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1586686372756958\n",
      "\n",
      "episode 2, val func loss 0.1893974393606186\n",
      "\n",
      "episode 3, val func loss 0.17280563712120056\n",
      "\n",
      "episode 4, val func loss 0.16071636974811554\n",
      "\n",
      "episode 5, val func loss 0.15995262563228607\n",
      "\n",
      "episode 6, val func loss 0.21132223308086395\n",
      "\n",
      "episode 7, val func loss 0.13501308858394623\n",
      "\n",
      "episode 8, val func loss 0.16386762261390686\n",
      "\n",
      "episode 9, val func loss 0.19230195879936218\n",
      "\n",
      "episode 10, val func loss 0.13447153568267822\n",
      "\n",
      "episode 11, val func loss 0.1843067854642868\n",
      "\n",
      "episode 12, val func loss 0.16707853972911835\n",
      "\n",
      "episode 13, val func loss 0.13388347625732422\n",
      "\n",
      "episode 14, val func loss 0.14925096929073334\n",
      "\n",
      "episode 15, val func loss 0.1386321783065796\n",
      "\n",
      "episode 16, val func loss 0.13805502653121948\n",
      "\n",
      "Val func train loss in epoch 12:0.161857757717371\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.16465145349502563\n",
      "\n",
      "episode 2, val func loss 0.1382548063993454\n",
      "\n",
      "episode 3, val func loss 0.15738414227962494\n",
      "\n",
      "episode 4, val func loss 0.19490009546279907\n",
      "\n",
      "episode 5, val func loss 0.13282465934753418\n",
      "\n",
      "episode 6, val func loss 0.16516375541687012\n",
      "\n",
      "episode 7, val func loss 0.14889688789844513\n",
      "\n",
      "episode 8, val func loss 0.1606697291135788\n",
      "\n",
      "episode 9, val func loss 0.1892285794019699\n",
      "\n",
      "episode 10, val func loss 0.13438020646572113\n",
      "\n",
      "episode 11, val func loss 0.1732344627380371\n",
      "\n",
      "episode 12, val func loss 0.13756100833415985\n",
      "\n",
      "episode 13, val func loss 0.16018253564834595\n",
      "\n",
      "episode 14, val func loss 0.21018879115581512\n",
      "\n",
      "episode 15, val func loss 0.13512080907821655\n",
      "\n",
      "episode 16, val func loss 0.18454605340957642\n",
      "\n",
      "Val func train loss in epoch 13:0.16169924847781658\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.16057008504867554\n",
      "\n",
      "episode 2, val func loss 0.18472856283187866\n",
      "\n",
      "episode 3, val func loss 0.13884274661540985\n",
      "\n",
      "episode 4, val func loss 0.1490487903356552\n",
      "\n",
      "episode 5, val func loss 0.13369479775428772\n",
      "\n",
      "episode 6, val func loss 0.1331375390291214\n",
      "\n",
      "episode 7, val func loss 0.1746845543384552\n",
      "\n",
      "episode 8, val func loss 0.16454888880252838\n",
      "\n",
      "episode 9, val func loss 0.1328810602426529\n",
      "\n",
      "episode 10, val func loss 0.21689100563526154\n",
      "\n",
      "episode 11, val func loss 0.19300265610218048\n",
      "\n",
      "episode 12, val func loss 0.15833495557308197\n",
      "\n",
      "episode 13, val func loss 0.1639125496149063\n",
      "\n",
      "episode 14, val func loss 0.18772979080677032\n",
      "\n",
      "episode 15, val func loss 0.1387312263250351\n",
      "\n",
      "episode 16, val func loss 0.16229495406150818\n",
      "\n",
      "Val func train loss in epoch 14:0.16206463519483805\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19307507574558258\n",
      "\n",
      "episode 2, val func loss 0.16144655644893646\n",
      "\n",
      "episode 3, val func loss 0.16396112740039825\n",
      "\n",
      "episode 4, val func loss 0.21039347350597382\n",
      "\n",
      "episode 5, val func loss 0.17364855110645294\n",
      "\n",
      "episode 6, val func loss 0.14931729435920715\n",
      "\n",
      "episode 7, val func loss 0.13333743810653687\n",
      "\n",
      "episode 8, val func loss 0.1909155696630478\n",
      "\n",
      "episode 9, val func loss 0.13743436336517334\n",
      "\n",
      "episode 10, val func loss 0.13865917921066284\n",
      "\n",
      "episode 11, val func loss 0.185309037566185\n",
      "\n",
      "episode 12, val func loss 0.16049543023109436\n",
      "\n",
      "episode 13, val func loss 0.13468138873577118\n",
      "\n",
      "episode 14, val func loss 0.16655148565769196\n",
      "\n",
      "episode 15, val func loss 0.1598249077796936\n",
      "\n",
      "episode 16, val func loss 0.13317130506038666\n",
      "\n",
      "Val func train loss in epoch 15:0.16201388649642467\n",
      "***********************TIME WAS 5.171836392084757 min*****************************\n",
      "\n",
      "**********************ROUND 30 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.1020117849111557\n",
      "\n",
      "episode 2, policy loss -0.16024941205978394\n",
      "\n",
      "episode 3, policy loss -0.14135867357254028\n",
      "\n",
      "episode 4, policy loss -0.12159715592861176\n",
      "\n",
      "episode 5, policy loss -0.11379913240671158\n",
      "\n",
      "episode 6, policy loss -0.14585691690444946\n",
      "\n",
      "episode 7, policy loss -0.09828667342662811\n",
      "\n",
      "episode 8, policy loss -0.18177980184555054\n",
      "\n",
      "episode 9, policy loss -0.1469670683145523\n",
      "\n",
      "episode 10, policy loss -0.14223045110702515\n",
      "\n",
      "episode 11, policy loss -0.21057173609733582\n",
      "\n",
      "episode 12, policy loss -0.11129105091094971\n",
      "\n",
      "episode 13, policy loss -0.1630232036113739\n",
      "\n",
      "episode 14, policy loss -0.09784261137247086\n",
      "\n",
      "episode 15, policy loss -0.11326658725738525\n",
      "\n",
      "episode 16, policy loss -0.10453059524297714\n",
      "\n",
      "Policy train loss in epoch 0:-0.13466642843559384\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.11499793827533722\n",
      "\n",
      "episode 2, policy loss -0.16124749183654785\n",
      "\n",
      "episode 3, policy loss -0.14160732924938202\n",
      "\n",
      "episode 4, policy loss -0.11154992878437042\n",
      "\n",
      "episode 5, policy loss -0.14865979552268982\n",
      "\n",
      "episode 6, policy loss -0.10681743919849396\n",
      "\n",
      "episode 7, policy loss -0.09601853787899017\n",
      "\n",
      "episode 8, policy loss -0.15943947434425354\n",
      "\n",
      "episode 9, policy loss -0.18464231491088867\n",
      "\n",
      "episode 10, policy loss -0.2103656828403473\n",
      "\n",
      "episode 11, policy loss -0.13617275655269623\n",
      "\n",
      "episode 12, policy loss -0.11081460863351822\n",
      "\n",
      "episode 13, policy loss -0.1433487981557846\n",
      "\n",
      "episode 14, policy loss -0.10013571381568909\n",
      "\n",
      "episode 15, policy loss -0.11954602599143982\n",
      "\n",
      "episode 16, policy loss -0.10295502841472626\n",
      "\n",
      "Policy train loss in epoch 1:-0.1342699290253222\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.09530999511480331\n",
      "\n",
      "episode 2, policy loss -0.13667845726013184\n",
      "\n",
      "episode 3, policy loss -0.13700982928276062\n",
      "\n",
      "episode 4, policy loss -0.20327439904212952\n",
      "\n",
      "episode 5, policy loss -0.11460022628307343\n",
      "\n",
      "episode 6, policy loss -0.15949824452400208\n",
      "\n",
      "episode 7, policy loss -0.11006653308868408\n",
      "\n",
      "episode 8, policy loss -0.18240028619766235\n",
      "\n",
      "episode 9, policy loss -0.1096569150686264\n",
      "\n",
      "episode 10, policy loss -0.1633717119693756\n",
      "\n",
      "episode 11, policy loss -0.14338286221027374\n",
      "\n",
      "episode 12, policy loss -0.09944341331720352\n",
      "\n",
      "episode 13, policy loss -0.14436709880828857\n",
      "\n",
      "episode 14, policy loss -0.10551832616329193\n",
      "\n",
      "episode 15, policy loss -0.10273902118206024\n",
      "\n",
      "episode 16, policy loss -0.12248986959457397\n",
      "\n",
      "Policy train loss in epoch 2:-0.13311294931918383\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.09447924047708511\n",
      "\n",
      "episode 2, policy loss -0.11692208051681519\n",
      "\n",
      "episode 3, policy loss -0.14587578177452087\n",
      "\n",
      "episode 4, policy loss -0.13689245283603668\n",
      "\n",
      "episode 5, policy loss -0.17907968163490295\n",
      "\n",
      "episode 6, policy loss -0.10024969279766083\n",
      "\n",
      "episode 7, policy loss -0.10462422668933868\n",
      "\n",
      "episode 8, policy loss -0.21074452996253967\n",
      "\n",
      "episode 9, policy loss -0.16124749183654785\n",
      "\n",
      "episode 10, policy loss -0.14472979307174683\n",
      "\n",
      "episode 11, policy loss -0.15392005443572998\n",
      "\n",
      "episode 12, policy loss -0.13825033605098724\n",
      "\n",
      "episode 13, policy loss -0.09889501333236694\n",
      "\n",
      "episode 14, policy loss -0.11213155835866928\n",
      "\n",
      "episode 15, policy loss -0.11515249311923981\n",
      "\n",
      "episode 16, policy loss -0.12282407283782959\n",
      "\n",
      "Policy train loss in epoch 3:-0.1335011562332511\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.18795329332351685\n",
      "\n",
      "episode 2, val func loss 0.21634560823440552\n",
      "\n",
      "episode 3, val func loss 0.1681283414363861\n",
      "\n",
      "episode 4, val func loss 0.16282814741134644\n",
      "\n",
      "episode 5, val func loss 0.23185995221138\n",
      "\n",
      "episode 6, val func loss 0.1981484591960907\n",
      "\n",
      "episode 7, val func loss 0.1407800316810608\n",
      "\n",
      "episode 8, val func loss 0.14836834371089935\n",
      "\n",
      "episode 9, val func loss 0.16945762932300568\n",
      "\n",
      "episode 10, val func loss 0.16050580143928528\n",
      "\n",
      "episode 11, val func loss 0.17364588379859924\n",
      "\n",
      "episode 12, val func loss 0.16104482114315033\n",
      "\n",
      "episode 13, val func loss 0.14054356515407562\n",
      "\n",
      "episode 14, val func loss 0.127247154712677\n",
      "\n",
      "episode 15, val func loss 0.20142585039138794\n",
      "\n",
      "episode 16, val func loss 0.15514834225177765\n",
      "\n",
      "Val func train loss in epoch 0:0.17146445158869028\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17040400207042694\n",
      "\n",
      "episode 2, val func loss 0.1889529824256897\n",
      "\n",
      "episode 3, val func loss 0.19835279881954193\n",
      "\n",
      "episode 4, val func loss 0.13856208324432373\n",
      "\n",
      "episode 5, val func loss 0.14585469663143158\n",
      "\n",
      "episode 6, val func loss 0.16477520763874054\n",
      "\n",
      "episode 7, val func loss 0.16244232654571533\n",
      "\n",
      "episode 8, val func loss 0.12853850424289703\n",
      "\n",
      "episode 9, val func loss 0.14401669800281525\n",
      "\n",
      "episode 10, val func loss 0.14804965257644653\n",
      "\n",
      "episode 11, val func loss 0.19864054024219513\n",
      "\n",
      "episode 12, val func loss 0.1590733677148819\n",
      "\n",
      "episode 13, val func loss 0.16334232687950134\n",
      "\n",
      "episode 14, val func loss 0.21424414217472076\n",
      "\n",
      "episode 15, val func loss 0.2317296713590622\n",
      "\n",
      "episode 16, val func loss 0.16344666481018066\n",
      "\n",
      "Val func train loss in epoch 1:0.17002660408616066\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.14492858946323395\n",
      "\n",
      "episode 2, val func loss 0.13948483765125275\n",
      "\n",
      "episode 3, val func loss 0.16534265875816345\n",
      "\n",
      "episode 4, val func loss 0.1971377283334732\n",
      "\n",
      "episode 5, val func loss 0.1274377852678299\n",
      "\n",
      "episode 6, val func loss 0.19815905392169952\n",
      "\n",
      "episode 7, val func loss 0.14876917004585266\n",
      "\n",
      "episode 8, val func loss 0.16600292921066284\n",
      "\n",
      "episode 9, val func loss 0.21271741390228271\n",
      "\n",
      "episode 10, val func loss 0.17258572578430176\n",
      "\n",
      "episode 11, val func loss 0.22850993275642395\n",
      "\n",
      "episode 12, val func loss 0.1641252189874649\n",
      "\n",
      "episode 13, val func loss 0.14117377996444702\n",
      "\n",
      "episode 14, val func loss 0.1586209237575531\n",
      "\n",
      "episode 15, val func loss 0.1610468029975891\n",
      "\n",
      "episode 16, val func loss 0.18634863197803497\n",
      "\n",
      "Val func train loss in epoch 2:0.1695244489237666\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1389555186033249\n",
      "\n",
      "episode 2, val func loss 0.1985819935798645\n",
      "\n",
      "episode 3, val func loss 0.16160912811756134\n",
      "\n",
      "episode 4, val func loss 0.12728101015090942\n",
      "\n",
      "episode 5, val func loss 0.14496681094169617\n",
      "\n",
      "episode 6, val func loss 0.16312769055366516\n",
      "\n",
      "episode 7, val func loss 0.16387362778186798\n",
      "\n",
      "episode 8, val func loss 0.150034561753273\n",
      "\n",
      "episode 9, val func loss 0.17047759890556335\n",
      "\n",
      "episode 10, val func loss 0.2341768890619278\n",
      "\n",
      "episode 11, val func loss 0.16621613502502441\n",
      "\n",
      "episode 12, val func loss 0.15895752608776093\n",
      "\n",
      "episode 13, val func loss 0.18668507039546967\n",
      "\n",
      "episode 14, val func loss 0.21292516589164734\n",
      "\n",
      "episode 15, val func loss 0.14476844668388367\n",
      "\n",
      "episode 16, val func loss 0.19848056137561798\n",
      "\n",
      "Val func train loss in epoch 3:0.1700698584318161\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1486169844865799\n",
      "\n",
      "episode 2, val func loss 0.21270492672920227\n",
      "\n",
      "episode 3, val func loss 0.16461603343486786\n",
      "\n",
      "episode 4, val func loss 0.16139067709445953\n",
      "\n",
      "episode 5, val func loss 0.1397523283958435\n",
      "\n",
      "episode 6, val func loss 0.1639215648174286\n",
      "\n",
      "episode 7, val func loss 0.15929099917411804\n",
      "\n",
      "episode 8, val func loss 0.18645639717578888\n",
      "\n",
      "episode 9, val func loss 0.14499028027057648\n",
      "\n",
      "episode 10, val func loss 0.13928507268428802\n",
      "\n",
      "episode 11, val func loss 0.16191589832305908\n",
      "\n",
      "episode 12, val func loss 0.23863324522972107\n",
      "\n",
      "episode 13, val func loss 0.20064674317836761\n",
      "\n",
      "episode 14, val func loss 0.17159073054790497\n",
      "\n",
      "episode 15, val func loss 0.1962166428565979\n",
      "\n",
      "episode 16, val func loss 0.12800092995166779\n",
      "\n",
      "Val func train loss in epoch 4:0.16987684089690447\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1439485400915146\n",
      "\n",
      "episode 2, val func loss 0.1613280177116394\n",
      "\n",
      "episode 3, val func loss 0.13953529298305511\n",
      "\n",
      "episode 4, val func loss 0.1492442637681961\n",
      "\n",
      "episode 5, val func loss 0.15858595073223114\n",
      "\n",
      "episode 6, val func loss 0.21391475200653076\n",
      "\n",
      "episode 7, val func loss 0.1631118208169937\n",
      "\n",
      "episode 8, val func loss 0.16315051913261414\n",
      "\n",
      "episode 9, val func loss 0.18701262772083282\n",
      "\n",
      "episode 10, val func loss 0.19818240404129028\n",
      "\n",
      "episode 11, val func loss 0.23345793783664703\n",
      "\n",
      "episode 12, val func loss 0.19862504303455353\n",
      "\n",
      "episode 13, val func loss 0.17551501095294952\n",
      "\n",
      "episode 14, val func loss 0.16447234153747559\n",
      "\n",
      "episode 15, val func loss 0.12760645151138306\n",
      "\n",
      "episode 16, val func loss 0.14661702513694763\n",
      "\n",
      "Val func train loss in epoch 5:0.1702692499384284\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1466667205095291\n",
      "\n",
      "episode 2, val func loss 0.15909984707832336\n",
      "\n",
      "episode 3, val func loss 0.16391751170158386\n",
      "\n",
      "episode 4, val func loss 0.16536326706409454\n",
      "\n",
      "episode 5, val func loss 0.15073689818382263\n",
      "\n",
      "episode 6, val func loss 0.2004123032093048\n",
      "\n",
      "episode 7, val func loss 0.14076954126358032\n",
      "\n",
      "episode 8, val func loss 0.21421732008457184\n",
      "\n",
      "episode 9, val func loss 0.1390058845281601\n",
      "\n",
      "episode 10, val func loss 0.1635780930519104\n",
      "\n",
      "episode 11, val func loss 0.12719160318374634\n",
      "\n",
      "episode 12, val func loss 0.19763855636119843\n",
      "\n",
      "episode 13, val func loss 0.23067262768745422\n",
      "\n",
      "episode 14, val func loss 0.18688136339187622\n",
      "\n",
      "episode 15, val func loss 0.1743512600660324\n",
      "\n",
      "episode 16, val func loss 0.16176322102546692\n",
      "\n",
      "Val func train loss in epoch 6:0.17014162614941597\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.12753690779209137\n",
      "\n",
      "episode 2, val func loss 0.1867935210466385\n",
      "\n",
      "episode 3, val func loss 0.1715795248746872\n",
      "\n",
      "episode 4, val func loss 0.23085445165634155\n",
      "\n",
      "episode 5, val func loss 0.16439686715602875\n",
      "\n",
      "episode 6, val func loss 0.14558102190494537\n",
      "\n",
      "episode 7, val func loss 0.16096650063991547\n",
      "\n",
      "episode 8, val func loss 0.16611886024475098\n",
      "\n",
      "episode 9, val func loss 0.1588449478149414\n",
      "\n",
      "episode 10, val func loss 0.2135927826166153\n",
      "\n",
      "episode 11, val func loss 0.19675423204898834\n",
      "\n",
      "episode 12, val func loss 0.14141513407230377\n",
      "\n",
      "episode 13, val func loss 0.14801913499832153\n",
      "\n",
      "episode 14, val func loss 0.19837872684001923\n",
      "\n",
      "episode 15, val func loss 0.14201605319976807\n",
      "\n",
      "episode 16, val func loss 0.1639377623796463\n",
      "\n",
      "Val func train loss in epoch 7:0.1697991518303752\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.13821999728679657\n",
      "\n",
      "episode 2, val func loss 0.12710607051849365\n",
      "\n",
      "episode 3, val func loss 0.15980151295661926\n",
      "\n",
      "episode 4, val func loss 0.2013951987028122\n",
      "\n",
      "episode 5, val func loss 0.16995975375175476\n",
      "\n",
      "episode 6, val func loss 0.14011935889720917\n",
      "\n",
      "episode 7, val func loss 0.14484663307666779\n",
      "\n",
      "episode 8, val func loss 0.15010978281497955\n",
      "\n",
      "episode 9, val func loss 0.16615718603134155\n",
      "\n",
      "episode 10, val func loss 0.21293671429157257\n",
      "\n",
      "episode 11, val func loss 0.1643792688846588\n",
      "\n",
      "episode 12, val func loss 0.16747760772705078\n",
      "\n",
      "episode 13, val func loss 0.16387569904327393\n",
      "\n",
      "episode 14, val func loss 0.19730372726917267\n",
      "\n",
      "episode 15, val func loss 0.23372074961662292\n",
      "\n",
      "episode 16, val func loss 0.18594294786453247\n",
      "\n",
      "Val func train loss in epoch 8:0.17020951304584742\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1719854474067688\n",
      "\n",
      "episode 2, val func loss 0.14132119715213776\n",
      "\n",
      "episode 3, val func loss 0.21345031261444092\n",
      "\n",
      "episode 4, val func loss 0.1992541253566742\n",
      "\n",
      "episode 5, val func loss 0.16125138103961945\n",
      "\n",
      "episode 6, val func loss 0.15930059552192688\n",
      "\n",
      "episode 7, val func loss 0.16393567621707916\n",
      "\n",
      "episode 8, val func loss 0.23010919988155365\n",
      "\n",
      "episode 9, val func loss 0.16394349932670593\n",
      "\n",
      "episode 10, val func loss 0.1863989681005478\n",
      "\n",
      "episode 11, val func loss 0.14541222155094147\n",
      "\n",
      "episode 12, val func loss 0.19712692499160767\n",
      "\n",
      "episode 13, val func loss 0.13905476033687592\n",
      "\n",
      "episode 14, val func loss 0.16549338400363922\n",
      "\n",
      "episode 15, val func loss 0.14924223721027374\n",
      "\n",
      "episode 16, val func loss 0.12708143889904022\n",
      "\n",
      "Val func train loss in epoch 9:0.16964758560061455\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1652139276266098\n",
      "\n",
      "episode 2, val func loss 0.17198050022125244\n",
      "\n",
      "episode 3, val func loss 0.23145733773708344\n",
      "\n",
      "episode 4, val func loss 0.1654866635799408\n",
      "\n",
      "episode 5, val func loss 0.1861903965473175\n",
      "\n",
      "episode 6, val func loss 0.15948931872844696\n",
      "\n",
      "episode 7, val func loss 0.14246885478496552\n",
      "\n",
      "episode 8, val func loss 0.16137467324733734\n",
      "\n",
      "episode 9, val func loss 0.19798994064331055\n",
      "\n",
      "episode 10, val func loss 0.19752515852451324\n",
      "\n",
      "episode 11, val func loss 0.14914266765117645\n",
      "\n",
      "episode 12, val func loss 0.12714646756649017\n",
      "\n",
      "episode 13, val func loss 0.21308161318302155\n",
      "\n",
      "episode 14, val func loss 0.14545707404613495\n",
      "\n",
      "episode 15, val func loss 0.16389010846614838\n",
      "\n",
      "episode 16, val func loss 0.13932159543037415\n",
      "\n",
      "Val func train loss in epoch 10:0.1698260186240077\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16270418465137482\n",
      "\n",
      "episode 2, val func loss 0.13985544443130493\n",
      "\n",
      "episode 3, val func loss 0.14595764875411987\n",
      "\n",
      "episode 4, val func loss 0.13897362351417542\n",
      "\n",
      "episode 5, val func loss 0.16241592168807983\n",
      "\n",
      "episode 6, val func loss 0.20132994651794434\n",
      "\n",
      "episode 7, val func loss 0.21603837609291077\n",
      "\n",
      "episode 8, val func loss 0.18687987327575684\n",
      "\n",
      "episode 9, val func loss 0.16439947485923767\n",
      "\n",
      "episode 10, val func loss 0.15886318683624268\n",
      "\n",
      "episode 11, val func loss 0.17475825548171997\n",
      "\n",
      "episode 12, val func loss 0.1644282341003418\n",
      "\n",
      "episode 13, val func loss 0.22671450674533844\n",
      "\n",
      "episode 14, val func loss 0.12844428420066833\n",
      "\n",
      "episode 15, val func loss 0.14849036931991577\n",
      "\n",
      "episode 16, val func loss 0.19858938455581665\n",
      "\n",
      "Val func train loss in epoch 11:0.16992766968905926\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1281183660030365\n",
      "\n",
      "episode 2, val func loss 0.16468104720115662\n",
      "\n",
      "episode 3, val func loss 0.14633306860923767\n",
      "\n",
      "episode 4, val func loss 0.21255642175674438\n",
      "\n",
      "episode 5, val func loss 0.1641348898410797\n",
      "\n",
      "episode 6, val func loss 0.15870358049869537\n",
      "\n",
      "episode 7, val func loss 0.1705005168914795\n",
      "\n",
      "episode 8, val func loss 0.2380136102437973\n",
      "\n",
      "episode 9, val func loss 0.16243532299995422\n",
      "\n",
      "episode 10, val func loss 0.1504245549440384\n",
      "\n",
      "episode 11, val func loss 0.19946418702602386\n",
      "\n",
      "episode 12, val func loss 0.19657845795154572\n",
      "\n",
      "episode 13, val func loss 0.16214360296726227\n",
      "\n",
      "episode 14, val func loss 0.1864095777273178\n",
      "\n",
      "episode 15, val func loss 0.14129266142845154\n",
      "\n",
      "episode 16, val func loss 0.14441543817520142\n",
      "\n",
      "Val func train loss in epoch 12:0.1703878315165639\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.16433969140052795\n",
      "\n",
      "episode 2, val func loss 0.19737985730171204\n",
      "\n",
      "episode 3, val func loss 0.14593732357025146\n",
      "\n",
      "episode 4, val func loss 0.21355363726615906\n",
      "\n",
      "episode 5, val func loss 0.16065561771392822\n",
      "\n",
      "episode 6, val func loss 0.1709347367286682\n",
      "\n",
      "episode 7, val func loss 0.1625106930732727\n",
      "\n",
      "episode 8, val func loss 0.15952429175376892\n",
      "\n",
      "episode 9, val func loss 0.200600728392601\n",
      "\n",
      "episode 10, val func loss 0.13862115144729614\n",
      "\n",
      "episode 11, val func loss 0.2339911311864853\n",
      "\n",
      "episode 12, val func loss 0.1495642215013504\n",
      "\n",
      "episode 13, val func loss 0.1272413581609726\n",
      "\n",
      "episode 14, val func loss 0.1444634348154068\n",
      "\n",
      "episode 15, val func loss 0.18682347238063812\n",
      "\n",
      "episode 16, val func loss 0.16767650842666626\n",
      "\n",
      "Val func train loss in epoch 13:0.17023861594498158\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1439436674118042\n",
      "\n",
      "episode 2, val func loss 0.16484598815441132\n",
      "\n",
      "episode 3, val func loss 0.15036189556121826\n",
      "\n",
      "episode 4, val func loss 0.19820301234722137\n",
      "\n",
      "episode 5, val func loss 0.20132558047771454\n",
      "\n",
      "episode 6, val func loss 0.16734211146831512\n",
      "\n",
      "episode 7, val func loss 0.21546493470668793\n",
      "\n",
      "episode 8, val func loss 0.16270571947097778\n",
      "\n",
      "episode 9, val func loss 0.12757328152656555\n",
      "\n",
      "episode 10, val func loss 0.22910131514072418\n",
      "\n",
      "episode 11, val func loss 0.16205234825611115\n",
      "\n",
      "episode 12, val func loss 0.18649563193321228\n",
      "\n",
      "episode 13, val func loss 0.17505253851413727\n",
      "\n",
      "episode 14, val func loss 0.14676788449287415\n",
      "\n",
      "episode 15, val func loss 0.14003793895244598\n",
      "\n",
      "episode 16, val func loss 0.1590331792831421\n",
      "\n",
      "Val func train loss in epoch 14:0.1706441892310977\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.14061589539051056\n",
      "\n",
      "episode 2, val func loss 0.14536893367767334\n",
      "\n",
      "episode 3, val func loss 0.16172201931476593\n",
      "\n",
      "episode 4, val func loss 0.18999303877353668\n",
      "\n",
      "episode 5, val func loss 0.21833327412605286\n",
      "\n",
      "episode 6, val func loss 0.1390773355960846\n",
      "\n",
      "episode 7, val func loss 0.12694193422794342\n",
      "\n",
      "episode 8, val func loss 0.23208044469356537\n",
      "\n",
      "episode 9, val func loss 0.14828899502754211\n",
      "\n",
      "episode 10, val func loss 0.16757705807685852\n",
      "\n",
      "episode 11, val func loss 0.16076497733592987\n",
      "\n",
      "episode 12, val func loss 0.19910910725593567\n",
      "\n",
      "episode 13, val func loss 0.19747865200042725\n",
      "\n",
      "episode 14, val func loss 0.16268688440322876\n",
      "\n",
      "episode 15, val func loss 0.17291899025440216\n",
      "\n",
      "episode 16, val func loss 0.1666642725467682\n",
      "\n",
      "Val func train loss in epoch 15:0.17060136329382658\n",
      "***********************TIME WAS 5.184093177318573 min*****************************\n",
      "\n",
      "**********************ROUND 31 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.11388637125492096\n",
      "\n",
      "episode 2, policy loss -0.07164657115936279\n",
      "\n",
      "episode 3, policy loss -0.11396847665309906\n",
      "\n",
      "episode 4, policy loss -0.14538094401359558\n",
      "\n",
      "episode 5, policy loss -0.09173569828271866\n",
      "\n",
      "episode 6, policy loss -0.05425238981842995\n",
      "\n",
      "episode 7, policy loss -0.14664527773857117\n",
      "\n",
      "episode 8, policy loss -0.11721529066562653\n",
      "\n",
      "episode 9, policy loss -0.08187443763017654\n",
      "\n",
      "episode 10, policy loss -0.10307085514068604\n",
      "\n",
      "episode 11, policy loss -0.08362790942192078\n",
      "\n",
      "episode 12, policy loss -0.1438440978527069\n",
      "\n",
      "episode 13, policy loss -0.09374041855335236\n",
      "\n",
      "episode 14, policy loss -0.09419005364179611\n",
      "\n",
      "episode 15, policy loss -0.0891760066151619\n",
      "\n",
      "episode 16, policy loss -0.11684711277484894\n",
      "\n",
      "Policy train loss in epoch 0:-0.10381886945106089\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.09167592227458954\n",
      "\n",
      "episode 2, policy loss -0.09622472524642944\n",
      "\n",
      "episode 3, policy loss -0.10836894065141678\n",
      "\n",
      "episode 4, policy loss -0.14821475744247437\n",
      "\n",
      "episode 5, policy loss -0.1453295350074768\n",
      "\n",
      "episode 6, policy loss -0.07460471987724304\n",
      "\n",
      "episode 7, policy loss -0.11649076640605927\n",
      "\n",
      "episode 8, policy loss -0.14524853229522705\n",
      "\n",
      "episode 9, policy loss -0.09348353743553162\n",
      "\n",
      "episode 10, policy loss -0.11324094980955124\n",
      "\n",
      "episode 11, policy loss -0.10332663357257843\n",
      "\n",
      "episode 12, policy loss -0.08368540555238724\n",
      "\n",
      "episode 13, policy loss -0.05466160923242569\n",
      "\n",
      "episode 14, policy loss -0.08056803047657013\n",
      "\n",
      "episode 15, policy loss -0.09670324623584747\n",
      "\n",
      "episode 16, policy loss -0.11719437688589096\n",
      "\n",
      "Policy train loss in epoch 1:-0.10431385552510619\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.11655272543430328\n",
      "\n",
      "episode 2, policy loss -0.11260104924440384\n",
      "\n",
      "episode 3, policy loss -0.09864629060029984\n",
      "\n",
      "episode 4, policy loss -0.11539347469806671\n",
      "\n",
      "episode 5, policy loss -0.10383492708206177\n",
      "\n",
      "episode 6, policy loss -0.09819349646568298\n",
      "\n",
      "episode 7, policy loss -0.07640715688467026\n",
      "\n",
      "episode 8, policy loss -0.09334741532802582\n",
      "\n",
      "episode 9, policy loss -0.08295309543609619\n",
      "\n",
      "episode 10, policy loss -0.1487240195274353\n",
      "\n",
      "episode 11, policy loss -0.14613105356693268\n",
      "\n",
      "episode 12, policy loss -0.07910238951444626\n",
      "\n",
      "episode 13, policy loss -0.09785939007997513\n",
      "\n",
      "episode 14, policy loss -0.058263733983039856\n",
      "\n",
      "episode 15, policy loss -0.11796543002128601\n",
      "\n",
      "episode 16, policy loss -0.14743080735206604\n",
      "\n",
      "Policy train loss in epoch 2:-0.1058379034511745\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.11572932451963425\n",
      "\n",
      "episode 2, policy loss -0.07487472891807556\n",
      "\n",
      "episode 3, policy loss -0.0984976589679718\n",
      "\n",
      "episode 4, policy loss -0.11584779620170593\n",
      "\n",
      "episode 5, policy loss -0.11453191936016083\n",
      "\n",
      "episode 6, policy loss -0.05476755648851395\n",
      "\n",
      "episode 7, policy loss -0.15483763813972473\n",
      "\n",
      "episode 8, policy loss -0.10156387835741043\n",
      "\n",
      "episode 9, policy loss -0.09835392236709595\n",
      "\n",
      "episode 10, policy loss -0.09751543402671814\n",
      "\n",
      "episode 11, policy loss -0.08337562531232834\n",
      "\n",
      "episode 12, policy loss -0.09196479618549347\n",
      "\n",
      "episode 13, policy loss -0.11549003422260284\n",
      "\n",
      "episode 14, policy loss -0.15205208957195282\n",
      "\n",
      "episode 15, policy loss -0.08136588335037231\n",
      "\n",
      "episode 16, policy loss -0.1468285620212555\n",
      "\n",
      "Policy train loss in epoch 3:-0.10609980300068855\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.12433099001646042\n",
      "\n",
      "episode 2, val func loss 0.17293962836265564\n",
      "\n",
      "episode 3, val func loss 0.14454568922519684\n",
      "\n",
      "episode 4, val func loss 0.17952516674995422\n",
      "\n",
      "episode 5, val func loss 0.15038801729679108\n",
      "\n",
      "episode 6, val func loss 0.16911134123802185\n",
      "\n",
      "episode 7, val func loss 0.14987467229366302\n",
      "\n",
      "episode 8, val func loss 0.15962134301662445\n",
      "\n",
      "episode 9, val func loss 0.20801997184753418\n",
      "\n",
      "episode 10, val func loss 0.12664398550987244\n",
      "\n",
      "episode 11, val func loss 0.15517406165599823\n",
      "\n",
      "episode 12, val func loss 0.13579367101192474\n",
      "\n",
      "episode 13, val func loss 0.17848989367485046\n",
      "\n",
      "episode 14, val func loss 0.16450971364974976\n",
      "\n",
      "episode 15, val func loss 0.1920594424009323\n",
      "\n",
      "episode 16, val func loss 0.14893567562103271\n",
      "\n",
      "Val func train loss in epoch 0:0.1599977039732039\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.12508486211299896\n",
      "\n",
      "episode 2, val func loss 0.16578978300094604\n",
      "\n",
      "episode 3, val func loss 0.1268995702266693\n",
      "\n",
      "episode 4, val func loss 0.15537580847740173\n",
      "\n",
      "episode 5, val func loss 0.15560732781887054\n",
      "\n",
      "episode 6, val func loss 0.16150860488414764\n",
      "\n",
      "episode 7, val func loss 0.14418651163578033\n",
      "\n",
      "episode 8, val func loss 0.2104763239622116\n",
      "\n",
      "episode 9, val func loss 0.16997754573822021\n",
      "\n",
      "episode 10, val func loss 0.17353291809558868\n",
      "\n",
      "episode 11, val func loss 0.14946381747722626\n",
      "\n",
      "episode 12, val func loss 0.15022000670433044\n",
      "\n",
      "episode 13, val func loss 0.19150029122829437\n",
      "\n",
      "episode 14, val func loss 0.1380998194217682\n",
      "\n",
      "episode 15, val func loss 0.18090437352657318\n",
      "\n",
      "episode 16, val func loss 0.17724809050559998\n",
      "\n",
      "Val func train loss in epoch 1:0.16099222842603922\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.14954620599746704\n",
      "\n",
      "episode 2, val func loss 0.15653786063194275\n",
      "\n",
      "episode 3, val func loss 0.2053232192993164\n",
      "\n",
      "episode 4, val func loss 0.15445183217525482\n",
      "\n",
      "episode 5, val func loss 0.1818789392709732\n",
      "\n",
      "episode 6, val func loss 0.12569250166416168\n",
      "\n",
      "episode 7, val func loss 0.19470880925655365\n",
      "\n",
      "episode 8, val func loss 0.12609991431236267\n",
      "\n",
      "episode 9, val func loss 0.13763251900672913\n",
      "\n",
      "episode 10, val func loss 0.15853822231292725\n",
      "\n",
      "episode 11, val func loss 0.14785191416740417\n",
      "\n",
      "episode 12, val func loss 0.17311297357082367\n",
      "\n",
      "episode 13, val func loss 0.17952761054039001\n",
      "\n",
      "episode 14, val func loss 0.15132620930671692\n",
      "\n",
      "episode 15, val func loss 0.16908255219459534\n",
      "\n",
      "episode 16, val func loss 0.1646633744239807\n",
      "\n",
      "Val func train loss in epoch 2:0.16099841613322496\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.14459680020809174\n",
      "\n",
      "episode 2, val func loss 0.13586418330669403\n",
      "\n",
      "episode 3, val func loss 0.12495945394039154\n",
      "\n",
      "episode 4, val func loss 0.16474242508411407\n",
      "\n",
      "episode 5, val func loss 0.15099605917930603\n",
      "\n",
      "episode 6, val func loss 0.19471505284309387\n",
      "\n",
      "episode 7, val func loss 0.16936516761779785\n",
      "\n",
      "episode 8, val func loss 0.15342538058757782\n",
      "\n",
      "episode 9, val func loss 0.1583806723356247\n",
      "\n",
      "episode 10, val func loss 0.15635989606380463\n",
      "\n",
      "episode 11, val func loss 0.17868179082870483\n",
      "\n",
      "episode 12, val func loss 0.14918582141399384\n",
      "\n",
      "episode 13, val func loss 0.1261909455060959\n",
      "\n",
      "episode 14, val func loss 0.17224998772144318\n",
      "\n",
      "episode 15, val func loss 0.17980729043483734\n",
      "\n",
      "episode 16, val func loss 0.20552237331867218\n",
      "\n",
      "Val func train loss in epoch 3:0.16031520627439022\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.15195871889591217\n",
      "\n",
      "episode 2, val func loss 0.13577201962471008\n",
      "\n",
      "episode 3, val func loss 0.14435650408267975\n",
      "\n",
      "episode 4, val func loss 0.173101007938385\n",
      "\n",
      "episode 5, val func loss 0.16487422585487366\n",
      "\n",
      "episode 6, val func loss 0.126778706908226\n",
      "\n",
      "episode 7, val func loss 0.16902770102024078\n",
      "\n",
      "episode 8, val func loss 0.12527887523174286\n",
      "\n",
      "episode 9, val func loss 0.15412786602973938\n",
      "\n",
      "episode 10, val func loss 0.15913966298103333\n",
      "\n",
      "episode 11, val func loss 0.1944797784090042\n",
      "\n",
      "episode 12, val func loss 0.14939971268177032\n",
      "\n",
      "episode 13, val func loss 0.17746253311634064\n",
      "\n",
      "episode 14, val func loss 0.1802479773759842\n",
      "\n",
      "episode 15, val func loss 0.15132740139961243\n",
      "\n",
      "episode 16, val func loss 0.2043616771697998\n",
      "\n",
      "Val func train loss in epoch 4:0.16010589804500341\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.2041032314300537\n",
      "\n",
      "episode 2, val func loss 0.1776358038187027\n",
      "\n",
      "episode 3, val func loss 0.15944327414035797\n",
      "\n",
      "episode 4, val func loss 0.1548713892698288\n",
      "\n",
      "episode 5, val func loss 0.16899506747722626\n",
      "\n",
      "episode 6, val func loss 0.15050241351127625\n",
      "\n",
      "episode 7, val func loss 0.19943690299987793\n",
      "\n",
      "episode 8, val func loss 0.16109175980091095\n",
      "\n",
      "episode 9, val func loss 0.1807217001914978\n",
      "\n",
      "episode 10, val func loss 0.16480781137943268\n",
      "\n",
      "episode 11, val func loss 0.17271777987480164\n",
      "\n",
      "episode 12, val func loss 0.15043199062347412\n",
      "\n",
      "episode 13, val func loss 0.13694803416728973\n",
      "\n",
      "episode 14, val func loss 0.14666086435317993\n",
      "\n",
      "episode 15, val func loss 0.12654924392700195\n",
      "\n",
      "episode 16, val func loss 0.12487386912107468\n",
      "\n",
      "Val func train loss in epoch 5:0.1612369460053742\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.14914372563362122\n",
      "\n",
      "episode 2, val func loss 0.1801932156085968\n",
      "\n",
      "episode 3, val func loss 0.15573501586914062\n",
      "\n",
      "episode 4, val func loss 0.15000878274440765\n",
      "\n",
      "episode 5, val func loss 0.15195044875144958\n",
      "\n",
      "episode 6, val func loss 0.1258898377418518\n",
      "\n",
      "episode 7, val func loss 0.18338267505168915\n",
      "\n",
      "episode 8, val func loss 0.19903628528118134\n",
      "\n",
      "episode 9, val func loss 0.16496317088603973\n",
      "\n",
      "episode 10, val func loss 0.204985573887825\n",
      "\n",
      "episode 11, val func loss 0.17253440618515015\n",
      "\n",
      "episode 12, val func loss 0.15835362672805786\n",
      "\n",
      "episode 13, val func loss 0.12712636590003967\n",
      "\n",
      "episode 14, val func loss 0.17348408699035645\n",
      "\n",
      "episode 15, val func loss 0.15036430954933167\n",
      "\n",
      "episode 16, val func loss 0.13796038925647736\n",
      "\n",
      "Val func train loss in epoch 6:0.161569494754076\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.15724624693393707\n",
      "\n",
      "episode 2, val func loss 0.14931648969650269\n",
      "\n",
      "episode 3, val func loss 0.16399124264717102\n",
      "\n",
      "episode 4, val func loss 0.12919948995113373\n",
      "\n",
      "episode 5, val func loss 0.18840424716472626\n",
      "\n",
      "episode 6, val func loss 0.1822972148656845\n",
      "\n",
      "episode 7, val func loss 0.16507454216480255\n",
      "\n",
      "episode 8, val func loss 0.15099526941776276\n",
      "\n",
      "episode 9, val func loss 0.16933926939964294\n",
      "\n",
      "episode 10, val func loss 0.14914461970329285\n",
      "\n",
      "episode 11, val func loss 0.17202992737293243\n",
      "\n",
      "episode 12, val func loss 0.20413847267627716\n",
      "\n",
      "episode 13, val func loss 0.19065511226654053\n",
      "\n",
      "episode 14, val func loss 0.1274714469909668\n",
      "\n",
      "episode 15, val func loss 0.13906031847000122\n",
      "\n",
      "episode 16, val func loss 0.1491992324590683\n",
      "\n",
      "Val func train loss in epoch 7:0.16172269638627768\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.14610598981380463\n",
      "\n",
      "episode 2, val func loss 0.2109839916229248\n",
      "\n",
      "episode 3, val func loss 0.17967398464679718\n",
      "\n",
      "episode 4, val func loss 0.15072619915008545\n",
      "\n",
      "episode 5, val func loss 0.17228686809539795\n",
      "\n",
      "episode 6, val func loss 0.15581904351711273\n",
      "\n",
      "episode 7, val func loss 0.1650247722864151\n",
      "\n",
      "episode 8, val func loss 0.13591711223125458\n",
      "\n",
      "episode 9, val func loss 0.1619095802307129\n",
      "\n",
      "episode 10, val func loss 0.15397386252880096\n",
      "\n",
      "episode 11, val func loss 0.12507595121860504\n",
      "\n",
      "episode 12, val func loss 0.1690267026424408\n",
      "\n",
      "episode 13, val func loss 0.12616336345672607\n",
      "\n",
      "episode 14, val func loss 0.19505250453948975\n",
      "\n",
      "episode 15, val func loss 0.14922744035720825\n",
      "\n",
      "episode 16, val func loss 0.17990021407604218\n",
      "\n",
      "Val func train loss in epoch 8:0.16105422377586365\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.16514693200588226\n",
      "\n",
      "episode 2, val func loss 0.15690045058727264\n",
      "\n",
      "episode 3, val func loss 0.1369241625070572\n",
      "\n",
      "episode 4, val func loss 0.14908497035503387\n",
      "\n",
      "episode 5, val func loss 0.2056506723165512\n",
      "\n",
      "episode 6, val func loss 0.16884399950504303\n",
      "\n",
      "episode 7, val func loss 0.19267107546329498\n",
      "\n",
      "episode 8, val func loss 0.1263580620288849\n",
      "\n",
      "episode 9, val func loss 0.14992655813694\n",
      "\n",
      "episode 10, val func loss 0.18013548851013184\n",
      "\n",
      "episode 11, val func loss 0.1466348022222519\n",
      "\n",
      "episode 12, val func loss 0.15857262909412384\n",
      "\n",
      "episode 13, val func loss 0.1524934470653534\n",
      "\n",
      "episode 14, val func loss 0.17896437644958496\n",
      "\n",
      "episode 15, val func loss 0.125061497092247\n",
      "\n",
      "episode 16, val func loss 0.17322508990764618\n",
      "\n",
      "Val func train loss in epoch 9:0.1604121383279562\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.12550722062587738\n",
      "\n",
      "episode 2, val func loss 0.1728924959897995\n",
      "\n",
      "episode 3, val func loss 0.17943422496318817\n",
      "\n",
      "episode 4, val func loss 0.2046748846769333\n",
      "\n",
      "episode 5, val func loss 0.17999649047851562\n",
      "\n",
      "episode 6, val func loss 0.1647314727306366\n",
      "\n",
      "episode 7, val func loss 0.15879224240779877\n",
      "\n",
      "episode 8, val func loss 0.16942241787910461\n",
      "\n",
      "episode 9, val func loss 0.1509045511484146\n",
      "\n",
      "episode 10, val func loss 0.1259717494249344\n",
      "\n",
      "episode 11, val func loss 0.1447182595729828\n",
      "\n",
      "episode 12, val func loss 0.13556163012981415\n",
      "\n",
      "episode 13, val func loss 0.19669626653194427\n",
      "\n",
      "episode 14, val func loss 0.14888103306293488\n",
      "\n",
      "episode 15, val func loss 0.15005271136760712\n",
      "\n",
      "episode 16, val func loss 0.1601826399564743\n",
      "\n",
      "Val func train loss in epoch 10:0.16052626818418503\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.14862553775310516\n",
      "\n",
      "episode 2, val func loss 0.17335836589336395\n",
      "\n",
      "episode 3, val func loss 0.19560204446315765\n",
      "\n",
      "episode 4, val func loss 0.1788620799779892\n",
      "\n",
      "episode 5, val func loss 0.1259516477584839\n",
      "\n",
      "episode 6, val func loss 0.1254272311925888\n",
      "\n",
      "episode 7, val func loss 0.15859265625476837\n",
      "\n",
      "episode 8, val func loss 0.1383114755153656\n",
      "\n",
      "episode 9, val func loss 0.14998455345630646\n",
      "\n",
      "episode 10, val func loss 0.17202939093112946\n",
      "\n",
      "episode 11, val func loss 0.15917102992534637\n",
      "\n",
      "episode 12, val func loss 0.14606258273124695\n",
      "\n",
      "episode 13, val func loss 0.20542843639850616\n",
      "\n",
      "episode 14, val func loss 0.16522398591041565\n",
      "\n",
      "episode 15, val func loss 0.151652529835701\n",
      "\n",
      "episode 16, val func loss 0.18062417209148407\n",
      "\n",
      "Val func train loss in epoch 11:0.16093173250555992\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18146589398384094\n",
      "\n",
      "episode 2, val func loss 0.19657808542251587\n",
      "\n",
      "episode 3, val func loss 0.1639450192451477\n",
      "\n",
      "episode 4, val func loss 0.17937104403972626\n",
      "\n",
      "episode 5, val func loss 0.13670819997787476\n",
      "\n",
      "episode 6, val func loss 0.15120652318000793\n",
      "\n",
      "episode 7, val func loss 0.15747672319412231\n",
      "\n",
      "episode 8, val func loss 0.17237290740013123\n",
      "\n",
      "episode 9, val func loss 0.14623142778873444\n",
      "\n",
      "episode 10, val func loss 0.1694761961698532\n",
      "\n",
      "episode 11, val func loss 0.20624922215938568\n",
      "\n",
      "episode 12, val func loss 0.12694315612316132\n",
      "\n",
      "episode 13, val func loss 0.15958355367183685\n",
      "\n",
      "episode 14, val func loss 0.1496044248342514\n",
      "\n",
      "episode 15, val func loss 0.15404357016086578\n",
      "\n",
      "episode 16, val func loss 0.12546393275260925\n",
      "\n",
      "Val func train loss in epoch 12:0.16104499250650406\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.15002085268497467\n",
      "\n",
      "episode 2, val func loss 0.1250474900007248\n",
      "\n",
      "episode 3, val func loss 0.15455137193202972\n",
      "\n",
      "episode 4, val func loss 0.16494812071323395\n",
      "\n",
      "episode 5, val func loss 0.15129245817661285\n",
      "\n",
      "episode 6, val func loss 0.15972678363323212\n",
      "\n",
      "episode 7, val func loss 0.12626002728939056\n",
      "\n",
      "episode 8, val func loss 0.1794171929359436\n",
      "\n",
      "episode 9, val func loss 0.14417664706707\n",
      "\n",
      "episode 10, val func loss 0.1946505755186081\n",
      "\n",
      "episode 11, val func loss 0.17953290045261383\n",
      "\n",
      "episode 12, val func loss 0.1701747626066208\n",
      "\n",
      "episode 13, val func loss 0.17221218347549438\n",
      "\n",
      "episode 14, val func loss 0.2034742385149002\n",
      "\n",
      "episode 15, val func loss 0.13759858906269073\n",
      "\n",
      "episode 16, val func loss 0.15132075548171997\n",
      "\n",
      "Val func train loss in epoch 13:0.16027530934661627\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.20378494262695312\n",
      "\n",
      "episode 2, val func loss 0.12688906490802765\n",
      "\n",
      "episode 3, val func loss 0.1906539350748062\n",
      "\n",
      "episode 4, val func loss 0.15535151958465576\n",
      "\n",
      "episode 5, val func loss 0.17711009085178375\n",
      "\n",
      "episode 6, val func loss 0.16459934413433075\n",
      "\n",
      "episode 7, val func loss 0.14931374788284302\n",
      "\n",
      "episode 8, val func loss 0.15064650774002075\n",
      "\n",
      "episode 9, val func loss 0.16893324255943298\n",
      "\n",
      "episode 10, val func loss 0.13605651259422302\n",
      "\n",
      "episode 11, val func loss 0.1594383418560028\n",
      "\n",
      "episode 12, val func loss 0.14462238550186157\n",
      "\n",
      "episode 13, val func loss 0.18052630126476288\n",
      "\n",
      "episode 14, val func loss 0.1250835359096527\n",
      "\n",
      "episode 15, val func loss 0.15423691272735596\n",
      "\n",
      "episode 16, val func loss 0.1731622964143753\n",
      "\n",
      "Val func train loss in epoch 14:0.16002554260194302\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.14983054995536804\n",
      "\n",
      "episode 2, val func loss 0.15053625404834747\n",
      "\n",
      "episode 3, val func loss 0.15866592526435852\n",
      "\n",
      "episode 4, val func loss 0.16483095288276672\n",
      "\n",
      "episode 5, val func loss 0.1248345822095871\n",
      "\n",
      "episode 6, val func loss 0.12607426941394806\n",
      "\n",
      "episode 7, val func loss 0.17265790700912476\n",
      "\n",
      "episode 8, val func loss 0.17788065969944\n",
      "\n",
      "episode 9, val func loss 0.15586556494235992\n",
      "\n",
      "episode 10, val func loss 0.15080522000789642\n",
      "\n",
      "episode 11, val func loss 0.16902929544448853\n",
      "\n",
      "episode 12, val func loss 0.1360861361026764\n",
      "\n",
      "episode 13, val func loss 0.17928725481033325\n",
      "\n",
      "episode 14, val func loss 0.20526725053787231\n",
      "\n",
      "episode 15, val func loss 0.193350687623024\n",
      "\n",
      "episode 16, val func loss 0.14570866525173187\n",
      "\n",
      "Val func train loss in epoch 15:0.1600444484502077\n",
      "***********************TIME WAS 5.062061325709025 min*****************************\n",
      "\n",
      "**********************ROUND 32 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.04662034660577774\n",
      "\n",
      "episode 2, policy loss -0.11128369718790054\n",
      "\n",
      "episode 3, policy loss -0.10549069941043854\n",
      "\n",
      "episode 4, policy loss -0.11928531527519226\n",
      "\n",
      "episode 5, policy loss -0.08646519482135773\n",
      "\n",
      "episode 6, policy loss -0.10203350335359573\n",
      "\n",
      "episode 7, policy loss -0.18549035489559174\n",
      "\n",
      "episode 8, policy loss -0.08254963904619217\n",
      "\n",
      "episode 9, policy loss -0.12296897172927856\n",
      "\n",
      "episode 10, policy loss -0.08755318075418472\n",
      "\n",
      "episode 11, policy loss -0.08960279077291489\n",
      "\n",
      "episode 12, policy loss -0.0935421884059906\n",
      "\n",
      "episode 13, policy loss -0.10952368378639221\n",
      "\n",
      "episode 14, policy loss -0.10471168160438538\n",
      "\n",
      "episode 15, policy loss -0.09292487800121307\n",
      "\n",
      "episode 16, policy loss -0.05378134548664093\n",
      "\n",
      "Policy train loss in epoch 0:-0.09961421694606543\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.09207802265882492\n",
      "\n",
      "episode 2, policy loss -0.10269618034362793\n",
      "\n",
      "episode 3, policy loss -0.18355706334114075\n",
      "\n",
      "episode 4, policy loss -0.11107081174850464\n",
      "\n",
      "episode 5, policy loss -0.1031872108578682\n",
      "\n",
      "episode 6, policy loss -0.09009765833616257\n",
      "\n",
      "episode 7, policy loss -0.0473255030810833\n",
      "\n",
      "episode 8, policy loss -0.09191885590553284\n",
      "\n",
      "episode 9, policy loss -0.1050240620970726\n",
      "\n",
      "episode 10, policy loss -0.12391991913318634\n",
      "\n",
      "episode 11, policy loss -0.0844632089138031\n",
      "\n",
      "episode 12, policy loss -0.12128773331642151\n",
      "\n",
      "episode 13, policy loss -0.09372878074645996\n",
      "\n",
      "episode 14, policy loss -0.11106652021408081\n",
      "\n",
      "episode 15, policy loss -0.09023253619670868\n",
      "\n",
      "episode 16, policy loss -0.05462122708559036\n",
      "\n",
      "Policy train loss in epoch 1:-0.10039220587350428\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.05516481399536133\n",
      "\n",
      "episode 2, policy loss -0.09231064468622208\n",
      "\n",
      "episode 3, policy loss -0.11015114933252335\n",
      "\n",
      "episode 4, policy loss -0.09343837201595306\n",
      "\n",
      "episode 5, policy loss -0.10673948377370834\n",
      "\n",
      "episode 6, policy loss -0.08944208174943924\n",
      "\n",
      "episode 7, policy loss -0.09093757718801498\n",
      "\n",
      "episode 8, policy loss -0.09426359832286835\n",
      "\n",
      "episode 9, policy loss -0.08325895667076111\n",
      "\n",
      "episode 10, policy loss -0.18704622983932495\n",
      "\n",
      "episode 11, policy loss -0.12241486459970474\n",
      "\n",
      "episode 12, policy loss -0.1027686595916748\n",
      "\n",
      "episode 13, policy loss -0.11064474284648895\n",
      "\n",
      "episode 14, policy loss -0.1076086089015007\n",
      "\n",
      "episode 15, policy loss -0.05247919261455536\n",
      "\n",
      "episode 16, policy loss -0.12281977385282516\n",
      "\n",
      "Policy train loss in epoch 2:-0.10134304687380791\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.05357655510306358\n",
      "\n",
      "episode 2, policy loss -0.11246980726718903\n",
      "\n",
      "episode 3, policy loss -0.09518902748823166\n",
      "\n",
      "episode 4, policy loss -0.05384305864572525\n",
      "\n",
      "episode 5, policy loss -0.09132462739944458\n",
      "\n",
      "episode 6, policy loss -0.10610386729240417\n",
      "\n",
      "episode 7, policy loss -0.080815888941288\n",
      "\n",
      "episode 8, policy loss -0.12102782726287842\n",
      "\n",
      "episode 9, policy loss -0.1222330778837204\n",
      "\n",
      "episode 10, policy loss -0.09158438444137573\n",
      "\n",
      "episode 11, policy loss -0.10960333049297333\n",
      "\n",
      "episode 12, policy loss -0.10235267877578735\n",
      "\n",
      "episode 13, policy loss -0.08806467801332474\n",
      "\n",
      "episode 14, policy loss -0.10684403032064438\n",
      "\n",
      "episode 15, policy loss -0.09200286865234375\n",
      "\n",
      "episode 16, policy loss -0.18836423754692078\n",
      "\n",
      "Policy train loss in epoch 3:-0.1009624965954572\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.14484427869319916\n",
      "\n",
      "episode 2, val func loss 0.1564146727323532\n",
      "\n",
      "episode 3, val func loss 0.15348297357559204\n",
      "\n",
      "episode 4, val func loss 0.13589459657669067\n",
      "\n",
      "episode 5, val func loss 0.23238791525363922\n",
      "\n",
      "episode 6, val func loss 0.14074257016181946\n",
      "\n",
      "episode 7, val func loss 0.14226849377155304\n",
      "\n",
      "episode 8, val func loss 0.17179039120674133\n",
      "\n",
      "episode 9, val func loss 0.15927791595458984\n",
      "\n",
      "episode 10, val func loss 0.15429948270320892\n",
      "\n",
      "episode 11, val func loss 0.1557644009590149\n",
      "\n",
      "episode 12, val func loss 0.14838923513889313\n",
      "\n",
      "episode 13, val func loss 0.11937074363231659\n",
      "\n",
      "episode 14, val func loss 0.14997482299804688\n",
      "\n",
      "episode 15, val func loss 0.14005032181739807\n",
      "\n",
      "episode 16, val func loss 0.15552127361297607\n",
      "\n",
      "Val func train loss in epoch 0:0.15377963054925203\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17340514063835144\n",
      "\n",
      "episode 2, val func loss 0.15710072219371796\n",
      "\n",
      "episode 3, val func loss 0.11974991858005524\n",
      "\n",
      "episode 4, val func loss 0.15685530006885529\n",
      "\n",
      "episode 5, val func loss 0.15762411057949066\n",
      "\n",
      "episode 6, val func loss 0.1548820286989212\n",
      "\n",
      "episode 7, val func loss 0.14492860436439514\n",
      "\n",
      "episode 8, val func loss 0.15533196926116943\n",
      "\n",
      "episode 9, val func loss 0.13656574487686157\n",
      "\n",
      "episode 10, val func loss 0.1417084038257599\n",
      "\n",
      "episode 11, val func loss 0.14990240335464478\n",
      "\n",
      "episode 12, val func loss 0.14026281237602234\n",
      "\n",
      "episode 13, val func loss 0.14797978103160858\n",
      "\n",
      "episode 14, val func loss 0.13923192024230957\n",
      "\n",
      "episode 15, val func loss 0.23164895176887512\n",
      "\n",
      "episode 16, val func loss 0.15824104845523834\n",
      "\n",
      "Val func train loss in epoch 1:0.15408867876976728\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.15586258471012115\n",
      "\n",
      "episode 2, val func loss 0.1417447030544281\n",
      "\n",
      "episode 3, val func loss 0.17190343141555786\n",
      "\n",
      "episode 4, val func loss 0.14004327356815338\n",
      "\n",
      "episode 5, val func loss 0.15437553822994232\n",
      "\n",
      "episode 6, val func loss 0.15817540884017944\n",
      "\n",
      "episode 7, val func loss 0.1190720945596695\n",
      "\n",
      "episode 8, val func loss 0.15457190573215485\n",
      "\n",
      "episode 9, val func loss 0.15677063167095184\n",
      "\n",
      "episode 10, val func loss 0.23771683871746063\n",
      "\n",
      "episode 11, val func loss 0.14897041022777557\n",
      "\n",
      "episode 12, val func loss 0.15028831362724304\n",
      "\n",
      "episode 13, val func loss 0.15420715510845184\n",
      "\n",
      "episode 14, val func loss 0.13743966817855835\n",
      "\n",
      "episode 15, val func loss 0.14039447903633118\n",
      "\n",
      "episode 16, val func loss 0.14423415064811707\n",
      "\n",
      "Val func train loss in epoch 2:0.1541106617078185\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.22952179610729218\n",
      "\n",
      "episode 2, val func loss 0.11974900215864182\n",
      "\n",
      "episode 3, val func loss 0.1495937705039978\n",
      "\n",
      "episode 4, val func loss 0.17199474573135376\n",
      "\n",
      "episode 5, val func loss 0.16025634109973907\n",
      "\n",
      "episode 6, val func loss 0.14056561887264252\n",
      "\n",
      "episode 7, val func loss 0.15846754610538483\n",
      "\n",
      "episode 8, val func loss 0.1438448131084442\n",
      "\n",
      "episode 9, val func loss 0.1394944190979004\n",
      "\n",
      "episode 10, val func loss 0.14942443370819092\n",
      "\n",
      "episode 11, val func loss 0.1329488307237625\n",
      "\n",
      "episode 12, val func loss 0.1568262279033661\n",
      "\n",
      "episode 13, val func loss 0.15771135687828064\n",
      "\n",
      "episode 14, val func loss 0.14419209957122803\n",
      "\n",
      "episode 15, val func loss 0.1562769114971161\n",
      "\n",
      "episode 16, val func loss 0.15728220343589783\n",
      "\n",
      "Val func train loss in epoch 3:0.15425938228145242\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1373971402645111\n",
      "\n",
      "episode 2, val func loss 0.15562543272972107\n",
      "\n",
      "episode 3, val func loss 0.13978146016597748\n",
      "\n",
      "episode 4, val func loss 0.15493901073932648\n",
      "\n",
      "episode 5, val func loss 0.15639857947826385\n",
      "\n",
      "episode 6, val func loss 0.23740942776203156\n",
      "\n",
      "episode 7, val func loss 0.14837636053562164\n",
      "\n",
      "episode 8, val func loss 0.15934771299362183\n",
      "\n",
      "episode 9, val func loss 0.15471552312374115\n",
      "\n",
      "episode 10, val func loss 0.14457638561725616\n",
      "\n",
      "episode 11, val func loss 0.12038123607635498\n",
      "\n",
      "episode 12, val func loss 0.14994095265865326\n",
      "\n",
      "episode 13, val func loss 0.1556946337223053\n",
      "\n",
      "episode 14, val func loss 0.1416151076555252\n",
      "\n",
      "episode 15, val func loss 0.17235110700130463\n",
      "\n",
      "episode 16, val func loss 0.1405945122241974\n",
      "\n",
      "Val func train loss in epoch 4:0.15432153642177582\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17209254205226898\n",
      "\n",
      "episode 2, val func loss 0.14158114790916443\n",
      "\n",
      "episode 3, val func loss 0.15349110960960388\n",
      "\n",
      "episode 4, val func loss 0.1572856456041336\n",
      "\n",
      "episode 5, val func loss 0.1403828114271164\n",
      "\n",
      "episode 6, val func loss 0.14454436302185059\n",
      "\n",
      "episode 7, val func loss 0.15498678386211395\n",
      "\n",
      "episode 8, val func loss 0.15559543669223785\n",
      "\n",
      "episode 9, val func loss 0.1486738622188568\n",
      "\n",
      "episode 10, val func loss 0.15827426314353943\n",
      "\n",
      "episode 11, val func loss 0.15602748095989227\n",
      "\n",
      "episode 12, val func loss 0.23530519008636475\n",
      "\n",
      "episode 13, val func loss 0.11950219422578812\n",
      "\n",
      "episode 14, val func loss 0.14021146297454834\n",
      "\n",
      "episode 15, val func loss 0.14060519635677338\n",
      "\n",
      "episode 16, val func loss 0.15020014345645905\n",
      "\n",
      "Val func train loss in epoch 5:0.1542974771000445\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.15740379691123962\n",
      "\n",
      "episode 2, val func loss 0.1538769155740738\n",
      "\n",
      "episode 3, val func loss 0.17304489016532898\n",
      "\n",
      "episode 4, val func loss 0.14823663234710693\n",
      "\n",
      "episode 5, val func loss 0.12018569558858871\n",
      "\n",
      "episode 6, val func loss 0.1556384116411209\n",
      "\n",
      "episode 7, val func loss 0.1447460949420929\n",
      "\n",
      "episode 8, val func loss 0.14209531247615814\n",
      "\n",
      "episode 9, val func loss 0.14944519102573395\n",
      "\n",
      "episode 10, val func loss 0.15801385045051575\n",
      "\n",
      "episode 11, val func loss 0.2334901988506317\n",
      "\n",
      "episode 12, val func loss 0.15488247573375702\n",
      "\n",
      "episode 13, val func loss 0.1402147263288498\n",
      "\n",
      "episode 14, val func loss 0.13644526898860931\n",
      "\n",
      "episode 15, val func loss 0.1400347203016281\n",
      "\n",
      "episode 16, val func loss 0.1581614911556244\n",
      "\n",
      "Val func train loss in epoch 6:0.15411972953006625\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.15399785339832306\n",
      "\n",
      "episode 2, val func loss 0.1505919247865677\n",
      "\n",
      "episode 3, val func loss 0.13425499200820923\n",
      "\n",
      "episode 4, val func loss 0.14145249128341675\n",
      "\n",
      "episode 5, val func loss 0.11935769021511078\n",
      "\n",
      "episode 6, val func loss 0.14952348172664642\n",
      "\n",
      "episode 7, val func loss 0.1559891253709793\n",
      "\n",
      "episode 8, val func loss 0.15711741149425507\n",
      "\n",
      "episode 9, val func loss 0.14255675673484802\n",
      "\n",
      "episode 10, val func loss 0.17201313376426697\n",
      "\n",
      "episode 11, val func loss 0.15822260081768036\n",
      "\n",
      "episode 12, val func loss 0.23197002708911896\n",
      "\n",
      "episode 13, val func loss 0.1394401490688324\n",
      "\n",
      "episode 14, val func loss 0.15860332548618317\n",
      "\n",
      "episode 15, val func loss 0.15487059950828552\n",
      "\n",
      "episode 16, val func loss 0.14426176249980927\n",
      "\n",
      "Val func train loss in epoch 7:0.1540139578282833\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.11934669315814972\n",
      "\n",
      "episode 2, val func loss 0.1724134385585785\n",
      "\n",
      "episode 3, val func loss 0.1400662362575531\n",
      "\n",
      "episode 4, val func loss 0.14032325148582458\n",
      "\n",
      "episode 5, val func loss 0.13673517107963562\n",
      "\n",
      "episode 6, val func loss 0.15878891944885254\n",
      "\n",
      "episode 7, val func loss 0.15666691958904266\n",
      "\n",
      "episode 8, val func loss 0.14933422207832336\n",
      "\n",
      "episode 9, val func loss 0.1520971655845642\n",
      "\n",
      "episode 10, val func loss 0.15690305829048157\n",
      "\n",
      "episode 11, val func loss 0.15556736290454865\n",
      "\n",
      "episode 12, val func loss 0.23920302093029022\n",
      "\n",
      "episode 13, val func loss 0.15588964521884918\n",
      "\n",
      "episode 14, val func loss 0.1446211189031601\n",
      "\n",
      "episode 15, val func loss 0.1495555341243744\n",
      "\n",
      "episode 16, val func loss 0.1431163251399994\n",
      "\n",
      "Val func train loss in epoch 8:0.15441425517201424\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1546153426170349\n",
      "\n",
      "episode 2, val func loss 0.14343281090259552\n",
      "\n",
      "episode 3, val func loss 0.2277291864156723\n",
      "\n",
      "episode 4, val func loss 0.1409822404384613\n",
      "\n",
      "episode 5, val func loss 0.15025588870048523\n",
      "\n",
      "episode 6, val func loss 0.1445377618074417\n",
      "\n",
      "episode 7, val func loss 0.14748507738113403\n",
      "\n",
      "episode 8, val func loss 0.17227080464363098\n",
      "\n",
      "episode 9, val func loss 0.1583084613084793\n",
      "\n",
      "episode 10, val func loss 0.14046698808670044\n",
      "\n",
      "episode 11, val func loss 0.15673360228538513\n",
      "\n",
      "episode 12, val func loss 0.1553507000207901\n",
      "\n",
      "episode 13, val func loss 0.15539389848709106\n",
      "\n",
      "episode 14, val func loss 0.1421765685081482\n",
      "\n",
      "episode 15, val func loss 0.11944341659545898\n",
      "\n",
      "episode 16, val func loss 0.15642918646335602\n",
      "\n",
      "Val func train loss in epoch 9:0.15410074591636658\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.14193223416805267\n",
      "\n",
      "episode 2, val func loss 0.15844984352588654\n",
      "\n",
      "episode 3, val func loss 0.23684924840927124\n",
      "\n",
      "episode 4, val func loss 0.14046968519687653\n",
      "\n",
      "episode 5, val func loss 0.1555090993642807\n",
      "\n",
      "episode 6, val func loss 0.15444889664649963\n",
      "\n",
      "episode 7, val func loss 0.1359294354915619\n",
      "\n",
      "episode 8, val func loss 0.15399955213069916\n",
      "\n",
      "episode 9, val func loss 0.14819665253162384\n",
      "\n",
      "episode 10, val func loss 0.14494343101978302\n",
      "\n",
      "episode 11, val func loss 0.17194192111492157\n",
      "\n",
      "episode 12, val func loss 0.15662434697151184\n",
      "\n",
      "episode 13, val func loss 0.15506352484226227\n",
      "\n",
      "episode 14, val func loss 0.14002925157546997\n",
      "\n",
      "episode 15, val func loss 0.1504966765642166\n",
      "\n",
      "episode 16, val func loss 0.11961611360311508\n",
      "\n",
      "Val func train loss in epoch 10:0.15403124457225204\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.14978179335594177\n",
      "\n",
      "episode 2, val func loss 0.1718224734067917\n",
      "\n",
      "episode 3, val func loss 0.23001977801322937\n",
      "\n",
      "episode 4, val func loss 0.16027215123176575\n",
      "\n",
      "episode 5, val func loss 0.14501884579658508\n",
      "\n",
      "episode 6, val func loss 0.1204453706741333\n",
      "\n",
      "episode 7, val func loss 0.15859593451023102\n",
      "\n",
      "episode 8, val func loss 0.15832144021987915\n",
      "\n",
      "episode 9, val func loss 0.1540243923664093\n",
      "\n",
      "episode 10, val func loss 0.14882545173168182\n",
      "\n",
      "episode 11, val func loss 0.13981203734874725\n",
      "\n",
      "episode 12, val func loss 0.1425340473651886\n",
      "\n",
      "episode 13, val func loss 0.15742745995521545\n",
      "\n",
      "episode 14, val func loss 0.14347140491008759\n",
      "\n",
      "episode 15, val func loss 0.13407202064990997\n",
      "\n",
      "episode 16, val func loss 0.15568111836910248\n",
      "\n",
      "Val func train loss in epoch 11:0.15438285749405622\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.15621261298656464\n",
      "\n",
      "episode 2, val func loss 0.14085234701633453\n",
      "\n",
      "episode 3, val func loss 0.1552361398935318\n",
      "\n",
      "episode 4, val func loss 0.15848210453987122\n",
      "\n",
      "episode 5, val func loss 0.15629062056541443\n",
      "\n",
      "episode 6, val func loss 0.13998177647590637\n",
      "\n",
      "episode 7, val func loss 0.1194007396697998\n",
      "\n",
      "episode 8, val func loss 0.17275111377239227\n",
      "\n",
      "episode 9, val func loss 0.23623263835906982\n",
      "\n",
      "episode 10, val func loss 0.15489162504673004\n",
      "\n",
      "episode 11, val func loss 0.14814729988574982\n",
      "\n",
      "episode 12, val func loss 0.1544157713651657\n",
      "\n",
      "episode 13, val func loss 0.14291836321353912\n",
      "\n",
      "episode 14, val func loss 0.14532604813575745\n",
      "\n",
      "episode 15, val func loss 0.15049418807029724\n",
      "\n",
      "episode 16, val func loss 0.14118359982967377\n",
      "\n",
      "Val func train loss in epoch 12:0.15455106180161238\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.15912701189517975\n",
      "\n",
      "episode 2, val func loss 0.11955451220273972\n",
      "\n",
      "episode 3, val func loss 0.1548675298690796\n",
      "\n",
      "episode 4, val func loss 0.1428164392709732\n",
      "\n",
      "episode 5, val func loss 0.14709343016147614\n",
      "\n",
      "episode 6, val func loss 0.15271812677383423\n",
      "\n",
      "episode 7, val func loss 0.1569489687681198\n",
      "\n",
      "episode 8, val func loss 0.1400274783372879\n",
      "\n",
      "episode 9, val func loss 0.14837057888507843\n",
      "\n",
      "episode 10, val func loss 0.22903256118297577\n",
      "\n",
      "episode 11, val func loss 0.15834257006645203\n",
      "\n",
      "episode 12, val func loss 0.1447189748287201\n",
      "\n",
      "episode 13, val func loss 0.17334280908107758\n",
      "\n",
      "episode 14, val func loss 0.16044683754444122\n",
      "\n",
      "episode 15, val func loss 0.16016288101673126\n",
      "\n",
      "episode 16, val func loss 0.13689716160297394\n",
      "\n",
      "Val func train loss in epoch 13:0.1552792419679463\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.15474022924900055\n",
      "\n",
      "episode 2, val func loss 0.17458634078502655\n",
      "\n",
      "episode 3, val func loss 0.14365597069263458\n",
      "\n",
      "episode 4, val func loss 0.1457240879535675\n",
      "\n",
      "episode 5, val func loss 0.1532740741968155\n",
      "\n",
      "episode 6, val func loss 0.1565711498260498\n",
      "\n",
      "episode 7, val func loss 0.15153370797634125\n",
      "\n",
      "episode 8, val func loss 0.11945094168186188\n",
      "\n",
      "episode 9, val func loss 0.1579001247882843\n",
      "\n",
      "episode 10, val func loss 0.2318313866853714\n",
      "\n",
      "episode 11, val func loss 0.15558068454265594\n",
      "\n",
      "episode 12, val func loss 0.14749105274677277\n",
      "\n",
      "episode 13, val func loss 0.14096473157405853\n",
      "\n",
      "episode 14, val func loss 0.13983815908432007\n",
      "\n",
      "episode 15, val func loss 0.14809203147888184\n",
      "\n",
      "episode 16, val func loss 0.15584233403205872\n",
      "\n",
      "Val func train loss in epoch 14:0.15481731295585632\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.13358275592327118\n",
      "\n",
      "episode 2, val func loss 0.1568196564912796\n",
      "\n",
      "episode 3, val func loss 0.23886005580425262\n",
      "\n",
      "episode 4, val func loss 0.14472341537475586\n",
      "\n",
      "episode 5, val func loss 0.15385417640209198\n",
      "\n",
      "episode 6, val func loss 0.14826029539108276\n",
      "\n",
      "episode 7, val func loss 0.17202377319335938\n",
      "\n",
      "episode 8, val func loss 0.149921715259552\n",
      "\n",
      "episode 9, val func loss 0.154295414686203\n",
      "\n",
      "episode 10, val func loss 0.1595563441514969\n",
      "\n",
      "episode 11, val func loss 0.1416475623846054\n",
      "\n",
      "episode 12, val func loss 0.11972519755363464\n",
      "\n",
      "episode 13, val func loss 0.1562454253435135\n",
      "\n",
      "episode 14, val func loss 0.14111538231372833\n",
      "\n",
      "episode 15, val func loss 0.15683020651340485\n",
      "\n",
      "episode 16, val func loss 0.14063963294029236\n",
      "\n",
      "Val func train loss in epoch 15:0.15425631310790777\n",
      "***********************TIME WAS 4.895150828361511 min*****************************\n",
      "\n",
      "**********************ROUND 33 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.1010650098323822\n",
      "\n",
      "episode 2, policy loss -0.09752797335386276\n",
      "\n",
      "episode 3, policy loss -0.12282240390777588\n",
      "\n",
      "episode 4, policy loss -0.15647433698177338\n",
      "\n",
      "episode 5, policy loss -0.10017120093107224\n",
      "\n",
      "episode 6, policy loss -0.14912769198417664\n",
      "\n",
      "episode 7, policy loss -0.15695993602275848\n",
      "\n",
      "episode 8, policy loss -0.13042008876800537\n",
      "\n",
      "episode 9, policy loss -0.12563472986221313\n",
      "\n",
      "episode 10, policy loss -0.11663085222244263\n",
      "\n",
      "episode 11, policy loss -0.1833653748035431\n",
      "\n",
      "episode 12, policy loss -0.1597074270248413\n",
      "\n",
      "episode 13, policy loss -0.15978848934173584\n",
      "\n",
      "episode 14, policy loss -0.15291106700897217\n",
      "\n",
      "episode 15, policy loss -0.15988048911094666\n",
      "\n",
      "episode 16, policy loss -0.12679612636566162\n",
      "\n",
      "Policy train loss in epoch 0:-0.1374551998451352\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.1614515781402588\n",
      "\n",
      "episode 2, policy loss -0.1289055198431015\n",
      "\n",
      "episode 3, policy loss -0.10392968356609344\n",
      "\n",
      "episode 4, policy loss -0.15538901090621948\n",
      "\n",
      "episode 5, policy loss -0.14538054168224335\n",
      "\n",
      "episode 6, policy loss -0.15921255946159363\n",
      "\n",
      "episode 7, policy loss -0.12433956563472748\n",
      "\n",
      "episode 8, policy loss -0.11751999706029892\n",
      "\n",
      "episode 9, policy loss -0.15348592400550842\n",
      "\n",
      "episode 10, policy loss -0.1628570258617401\n",
      "\n",
      "episode 11, policy loss -0.10352823138237\n",
      "\n",
      "episode 12, policy loss -0.1287277489900589\n",
      "\n",
      "episode 13, policy loss -0.18517747521400452\n",
      "\n",
      "episode 14, policy loss -0.16101506352424622\n",
      "\n",
      "episode 15, policy loss -0.1271909475326538\n",
      "\n",
      "episode 16, policy loss -0.09852933138608932\n",
      "\n",
      "Policy train loss in epoch 1:-0.1385400127619505\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.14520367980003357\n",
      "\n",
      "episode 2, policy loss -0.10303276777267456\n",
      "\n",
      "episode 3, policy loss -0.15889906883239746\n",
      "\n",
      "episode 4, policy loss -0.16039738059043884\n",
      "\n",
      "episode 5, policy loss -0.1267213374376297\n",
      "\n",
      "episode 6, policy loss -0.10309930145740509\n",
      "\n",
      "episode 7, policy loss -0.15246565639972687\n",
      "\n",
      "episode 8, policy loss -0.09736957401037216\n",
      "\n",
      "episode 9, policy loss -0.11719724535942078\n",
      "\n",
      "episode 10, policy loss -0.12496712803840637\n",
      "\n",
      "episode 11, policy loss -0.16509029269218445\n",
      "\n",
      "episode 12, policy loss -0.1588655412197113\n",
      "\n",
      "episode 13, policy loss -0.15298821032047272\n",
      "\n",
      "episode 14, policy loss -0.11965034902095795\n",
      "\n",
      "episode 15, policy loss -0.18383829295635223\n",
      "\n",
      "episode 16, policy loss -0.1314481496810913\n",
      "\n",
      "Policy train loss in epoch 2:-0.1375771234743297\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.12643952667713165\n",
      "\n",
      "episode 2, policy loss -0.1246698796749115\n",
      "\n",
      "episode 3, policy loss -0.1438233107328415\n",
      "\n",
      "episode 4, policy loss -0.12932199239730835\n",
      "\n",
      "episode 5, policy loss -0.15111544728279114\n",
      "\n",
      "episode 6, policy loss -0.11667969822883606\n",
      "\n",
      "episode 7, policy loss -0.10157044231891632\n",
      "\n",
      "episode 8, policy loss -0.16412889957427979\n",
      "\n",
      "episode 9, policy loss -0.15403738617897034\n",
      "\n",
      "episode 10, policy loss -0.10036013275384903\n",
      "\n",
      "episode 11, policy loss -0.15820127725601196\n",
      "\n",
      "episode 12, policy loss -0.12984555959701538\n",
      "\n",
      "episode 13, policy loss -0.15974856913089752\n",
      "\n",
      "episode 14, policy loss -0.18448486924171448\n",
      "\n",
      "episode 15, policy loss -0.16262497007846832\n",
      "\n",
      "episode 16, policy loss -0.09615061432123184\n",
      "\n",
      "Policy train loss in epoch 3:-0.13770016096532345\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.12459933757781982\n",
      "\n",
      "episode 2, val func loss 0.16341806948184967\n",
      "\n",
      "episode 3, val func loss 0.15669839084148407\n",
      "\n",
      "episode 4, val func loss 0.1551934778690338\n",
      "\n",
      "episode 5, val func loss 0.1555849015712738\n",
      "\n",
      "episode 6, val func loss 0.15848460793495178\n",
      "\n",
      "episode 7, val func loss 0.1448923498392105\n",
      "\n",
      "episode 8, val func loss 0.15630985796451569\n",
      "\n",
      "episode 9, val func loss 0.19423310458660126\n",
      "\n",
      "episode 10, val func loss 0.1761697232723236\n",
      "\n",
      "episode 11, val func loss 0.18176013231277466\n",
      "\n",
      "episode 12, val func loss 0.1812669187784195\n",
      "\n",
      "episode 13, val func loss 0.1814875453710556\n",
      "\n",
      "episode 14, val func loss 0.17535939812660217\n",
      "\n",
      "episode 15, val func loss 0.16173569858074188\n",
      "\n",
      "episode 16, val func loss 0.1704326570034027\n",
      "\n",
      "Val func train loss in epoch 0:0.16485163569450378\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19398576021194458\n",
      "\n",
      "episode 2, val func loss 0.180882066488266\n",
      "\n",
      "episode 3, val func loss 0.12406372278928757\n",
      "\n",
      "episode 4, val func loss 0.15934619307518005\n",
      "\n",
      "episode 5, val func loss 0.15512709319591522\n",
      "\n",
      "episode 6, val func loss 0.15626826882362366\n",
      "\n",
      "episode 7, val func loss 0.16273747384548187\n",
      "\n",
      "episode 8, val func loss 0.18248990178108215\n",
      "\n",
      "episode 9, val func loss 0.17123189568519592\n",
      "\n",
      "episode 10, val func loss 0.15581060945987701\n",
      "\n",
      "episode 11, val func loss 0.1791684776544571\n",
      "\n",
      "episode 12, val func loss 0.15845689177513123\n",
      "\n",
      "episode 13, val func loss 0.1597232222557068\n",
      "\n",
      "episode 14, val func loss 0.17667065560817719\n",
      "\n",
      "episode 15, val func loss 0.14618274569511414\n",
      "\n",
      "episode 16, val func loss 0.1758069545030594\n",
      "\n",
      "Val func train loss in epoch 1:0.16487199580296874\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17571131885051727\n",
      "\n",
      "episode 2, val func loss 0.15642069280147552\n",
      "\n",
      "episode 3, val func loss 0.18189749121665955\n",
      "\n",
      "episode 4, val func loss 0.18044434487819672\n",
      "\n",
      "episode 5, val func loss 0.15908502042293549\n",
      "\n",
      "episode 6, val func loss 0.19445323944091797\n",
      "\n",
      "episode 7, val func loss 0.1564532220363617\n",
      "\n",
      "episode 8, val func loss 0.15933677554130554\n",
      "\n",
      "episode 9, val func loss 0.12366393208503723\n",
      "\n",
      "episode 10, val func loss 0.17891784012317657\n",
      "\n",
      "episode 11, val func loss 0.14369381964206696\n",
      "\n",
      "episode 12, val func loss 0.18111085891723633\n",
      "\n",
      "episode 13, val func loss 0.17425751686096191\n",
      "\n",
      "episode 14, val func loss 0.16067422926425934\n",
      "\n",
      "episode 15, val func loss 0.1632005125284195\n",
      "\n",
      "episode 16, val func loss 0.15801924467086792\n",
      "\n",
      "Val func train loss in epoch 2:0.16545875370502472\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18132172524929047\n",
      "\n",
      "episode 2, val func loss 0.15797355771064758\n",
      "\n",
      "episode 3, val func loss 0.1833290010690689\n",
      "\n",
      "episode 4, val func loss 0.16542693972587585\n",
      "\n",
      "episode 5, val func loss 0.16285556554794312\n",
      "\n",
      "episode 6, val func loss 0.14875584840774536\n",
      "\n",
      "episode 7, val func loss 0.12464600056409836\n",
      "\n",
      "episode 8, val func loss 0.1558922678232193\n",
      "\n",
      "episode 9, val func loss 0.15828783810138702\n",
      "\n",
      "episode 10, val func loss 0.18284448981285095\n",
      "\n",
      "episode 11, val func loss 0.18535512685775757\n",
      "\n",
      "episode 12, val func loss 0.17349372804164886\n",
      "\n",
      "episode 13, val func loss 0.1785825490951538\n",
      "\n",
      "episode 14, val func loss 0.1625421792268753\n",
      "\n",
      "episode 15, val func loss 0.15569162368774414\n",
      "\n",
      "episode 16, val func loss 0.19412226974964142\n",
      "\n",
      "Val func train loss in epoch 3:0.16694504441693425\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.157363161444664\n",
      "\n",
      "episode 2, val func loss 0.1609119027853012\n",
      "\n",
      "episode 3, val func loss 0.1705814003944397\n",
      "\n",
      "episode 4, val func loss 0.12603668868541718\n",
      "\n",
      "episode 5, val func loss 0.17515866458415985\n",
      "\n",
      "episode 6, val func loss 0.18221578001976013\n",
      "\n",
      "episode 7, val func loss 0.15663960576057434\n",
      "\n",
      "episode 8, val func loss 0.18140989542007446\n",
      "\n",
      "episode 9, val func loss 0.1760110855102539\n",
      "\n",
      "episode 10, val func loss 0.1796070635318756\n",
      "\n",
      "episode 11, val func loss 0.14584659039974213\n",
      "\n",
      "episode 12, val func loss 0.1571170836687088\n",
      "\n",
      "episode 13, val func loss 0.16070477664470673\n",
      "\n",
      "episode 14, val func loss 0.15488086640834808\n",
      "\n",
      "episode 15, val func loss 0.19793079793453217\n",
      "\n",
      "episode 16, val func loss 0.15820789337158203\n",
      "\n",
      "Val func train loss in epoch 4:0.16503895353525877\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17788860201835632\n",
      "\n",
      "episode 2, val func loss 0.1453687995672226\n",
      "\n",
      "episode 3, val func loss 0.1607951670885086\n",
      "\n",
      "episode 4, val func loss 0.16021405160427094\n",
      "\n",
      "episode 5, val func loss 0.18026956915855408\n",
      "\n",
      "episode 6, val func loss 0.15755069255828857\n",
      "\n",
      "episode 7, val func loss 0.1943902224302292\n",
      "\n",
      "episode 8, val func loss 0.18105363845825195\n",
      "\n",
      "episode 9, val func loss 0.15734750032424927\n",
      "\n",
      "episode 10, val func loss 0.12384022027254105\n",
      "\n",
      "episode 11, val func loss 0.1557418555021286\n",
      "\n",
      "episode 12, val func loss 0.1578620821237564\n",
      "\n",
      "episode 13, val func loss 0.15613913536071777\n",
      "\n",
      "episode 14, val func loss 0.18147903680801392\n",
      "\n",
      "episode 15, val func loss 0.18269415199756622\n",
      "\n",
      "episode 16, val func loss 0.17030034959316254\n",
      "\n",
      "Val func train loss in epoch 5:0.16518344217911363\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17022036015987396\n",
      "\n",
      "episode 2, val func loss 0.17454521358013153\n",
      "\n",
      "episode 3, val func loss 0.15761560201644897\n",
      "\n",
      "episode 4, val func loss 0.18057659268379211\n",
      "\n",
      "episode 5, val func loss 0.1833922415971756\n",
      "\n",
      "episode 6, val func loss 0.17641878128051758\n",
      "\n",
      "episode 7, val func loss 0.1611708253622055\n",
      "\n",
      "episode 8, val func loss 0.1791549026966095\n",
      "\n",
      "episode 9, val func loss 0.15772069990634918\n",
      "\n",
      "episode 10, val func loss 0.14341755211353302\n",
      "\n",
      "episode 11, val func loss 0.15571758151054382\n",
      "\n",
      "episode 12, val func loss 0.1569175273180008\n",
      "\n",
      "episode 13, val func loss 0.16054606437683105\n",
      "\n",
      "episode 14, val func loss 0.1959102898836136\n",
      "\n",
      "episode 15, val func loss 0.12430895864963531\n",
      "\n",
      "episode 16, val func loss 0.1567373126745224\n",
      "\n",
      "Val func train loss in epoch 6:0.1646481566131115\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1751932054758072\n",
      "\n",
      "episode 2, val func loss 0.16082289814949036\n",
      "\n",
      "episode 3, val func loss 0.15730604529380798\n",
      "\n",
      "episode 4, val func loss 0.18370167911052704\n",
      "\n",
      "episode 5, val func loss 0.1948140263557434\n",
      "\n",
      "episode 6, val func loss 0.15652728080749512\n",
      "\n",
      "episode 7, val func loss 0.18301472067832947\n",
      "\n",
      "episode 8, val func loss 0.17168286442756653\n",
      "\n",
      "episode 9, val func loss 0.15834634006023407\n",
      "\n",
      "episode 10, val func loss 0.12425824999809265\n",
      "\n",
      "episode 11, val func loss 0.1767641007900238\n",
      "\n",
      "episode 12, val func loss 0.1562047302722931\n",
      "\n",
      "episode 13, val func loss 0.17093069851398468\n",
      "\n",
      "episode 14, val func loss 0.18182186782360077\n",
      "\n",
      "episode 15, val func loss 0.1563243269920349\n",
      "\n",
      "episode 16, val func loss 0.1463632583618164\n",
      "\n",
      "Val func train loss in epoch 7:0.16587976831942797\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.12394865602254868\n",
      "\n",
      "episode 2, val func loss 0.18175108730793\n",
      "\n",
      "episode 3, val func loss 0.17701774835586548\n",
      "\n",
      "episode 4, val func loss 0.17963078618049622\n",
      "\n",
      "episode 5, val func loss 0.15657779574394226\n",
      "\n",
      "episode 6, val func loss 0.15784740447998047\n",
      "\n",
      "episode 7, val func loss 0.16971296072006226\n",
      "\n",
      "episode 8, val func loss 0.15630249679088593\n",
      "\n",
      "episode 9, val func loss 0.15934467315673828\n",
      "\n",
      "episode 10, val func loss 0.16169574856758118\n",
      "\n",
      "episode 11, val func loss 0.19484849274158478\n",
      "\n",
      "episode 12, val func loss 0.18156835436820984\n",
      "\n",
      "episode 13, val func loss 0.14452937245368958\n",
      "\n",
      "episode 14, val func loss 0.15571704506874084\n",
      "\n",
      "episode 15, val func loss 0.17786341905593872\n",
      "\n",
      "episode 16, val func loss 0.16000890731811523\n",
      "\n",
      "Val func train loss in epoch 8:0.16489780927076936\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.15965917706489563\n",
      "\n",
      "episode 2, val func loss 0.19491654634475708\n",
      "\n",
      "episode 3, val func loss 0.1820141226053238\n",
      "\n",
      "episode 4, val func loss 0.18212559819221497\n",
      "\n",
      "episode 5, val func loss 0.15662741661071777\n",
      "\n",
      "episode 6, val func loss 0.16102759540081024\n",
      "\n",
      "episode 7, val func loss 0.17643186450004578\n",
      "\n",
      "episode 8, val func loss 0.17470985651016235\n",
      "\n",
      "episode 9, val func loss 0.12706759572029114\n",
      "\n",
      "episode 10, val func loss 0.16500137746334076\n",
      "\n",
      "episode 11, val func loss 0.18168339133262634\n",
      "\n",
      "episode 12, val func loss 0.15705493092536926\n",
      "\n",
      "episode 13, val func loss 0.15552836656570435\n",
      "\n",
      "episode 14, val func loss 0.1741321086883545\n",
      "\n",
      "episode 15, val func loss 0.14430448412895203\n",
      "\n",
      "episode 16, val func loss 0.16028058528900146\n",
      "\n",
      "Val func train loss in epoch 9:0.16578531358391047\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19048435986042023\n",
      "\n",
      "episode 2, val func loss 0.12420404702425003\n",
      "\n",
      "episode 3, val func loss 0.17880327999591827\n",
      "\n",
      "episode 4, val func loss 0.15831272304058075\n",
      "\n",
      "episode 5, val func loss 0.15591612458229065\n",
      "\n",
      "episode 6, val func loss 0.16114920377731323\n",
      "\n",
      "episode 7, val func loss 0.15852150321006775\n",
      "\n",
      "episode 8, val func loss 0.16628441214561462\n",
      "\n",
      "episode 9, val func loss 0.18291929364204407\n",
      "\n",
      "episode 10, val func loss 0.1806785762310028\n",
      "\n",
      "episode 11, val func loss 0.16066421568393707\n",
      "\n",
      "episode 12, val func loss 0.14503933489322662\n",
      "\n",
      "episode 13, val func loss 0.18014435470104218\n",
      "\n",
      "episode 14, val func loss 0.15487705171108246\n",
      "\n",
      "episode 15, val func loss 0.19760985672473907\n",
      "\n",
      "episode 16, val func loss 0.1733478307723999\n",
      "\n",
      "Val func train loss in epoch 10:0.1668097604997456\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19609171152114868\n",
      "\n",
      "episode 2, val func loss 0.15551947057247162\n",
      "\n",
      "episode 3, val func loss 0.15692216157913208\n",
      "\n",
      "episode 4, val func loss 0.16118301451206207\n",
      "\n",
      "episode 5, val func loss 0.17983391880989075\n",
      "\n",
      "episode 6, val func loss 0.15791316330432892\n",
      "\n",
      "episode 7, val func loss 0.18090561032295227\n",
      "\n",
      "episode 8, val func loss 0.16199806332588196\n",
      "\n",
      "episode 9, val func loss 0.17647486925125122\n",
      "\n",
      "episode 10, val func loss 0.16936835646629333\n",
      "\n",
      "episode 11, val func loss 0.18162433803081512\n",
      "\n",
      "episode 12, val func loss 0.17635037004947662\n",
      "\n",
      "episode 13, val func loss 0.14661671221256256\n",
      "\n",
      "episode 14, val func loss 0.16035853326320648\n",
      "\n",
      "episode 15, val func loss 0.15641210973262787\n",
      "\n",
      "episode 16, val func loss 0.12367843091487885\n",
      "\n",
      "Val func train loss in epoch 11:0.16507817711681128\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17958199977874756\n",
      "\n",
      "episode 2, val func loss 0.19564129412174225\n",
      "\n",
      "episode 3, val func loss 0.15893299877643585\n",
      "\n",
      "episode 4, val func loss 0.1616808921098709\n",
      "\n",
      "episode 5, val func loss 0.1564190685749054\n",
      "\n",
      "episode 6, val func loss 0.15618841350078583\n",
      "\n",
      "episode 7, val func loss 0.1250145584344864\n",
      "\n",
      "episode 8, val func loss 0.17006848752498627\n",
      "\n",
      "episode 9, val func loss 0.14740769565105438\n",
      "\n",
      "episode 10, val func loss 0.18157511949539185\n",
      "\n",
      "episode 11, val func loss 0.1818540394306183\n",
      "\n",
      "episode 12, val func loss 0.15982657670974731\n",
      "\n",
      "episode 13, val func loss 0.15839719772338867\n",
      "\n",
      "episode 14, val func loss 0.17713689804077148\n",
      "\n",
      "episode 15, val func loss 0.15529684722423553\n",
      "\n",
      "episode 16, val func loss 0.17921939492225647\n",
      "\n",
      "Val func train loss in epoch 12:0.16526509262621403\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.15554243326187134\n",
      "\n",
      "episode 2, val func loss 0.14426779747009277\n",
      "\n",
      "episode 3, val func loss 0.12419257313013077\n",
      "\n",
      "episode 4, val func loss 0.16021816432476044\n",
      "\n",
      "episode 5, val func loss 0.18244805932044983\n",
      "\n",
      "episode 6, val func loss 0.15815754234790802\n",
      "\n",
      "episode 7, val func loss 0.1566062867641449\n",
      "\n",
      "episode 8, val func loss 0.17059452831745148\n",
      "\n",
      "episode 9, val func loss 0.18120846152305603\n",
      "\n",
      "episode 10, val func loss 0.1603541523218155\n",
      "\n",
      "episode 11, val func loss 0.1808387190103531\n",
      "\n",
      "episode 12, val func loss 0.15801045298576355\n",
      "\n",
      "episode 13, val func loss 0.1940588802099228\n",
      "\n",
      "episode 14, val func loss 0.17666269838809967\n",
      "\n",
      "episode 15, val func loss 0.16149121522903442\n",
      "\n",
      "episode 16, val func loss 0.17634063959121704\n",
      "\n",
      "Val func train loss in epoch 13:0.16506203776225448\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1609160155057907\n",
      "\n",
      "episode 2, val func loss 0.17015211284160614\n",
      "\n",
      "episode 3, val func loss 0.16102971136569977\n",
      "\n",
      "episode 4, val func loss 0.19419895112514496\n",
      "\n",
      "episode 5, val func loss 0.1754344403743744\n",
      "\n",
      "episode 6, val func loss 0.1763322651386261\n",
      "\n",
      "episode 7, val func loss 0.1813928633928299\n",
      "\n",
      "episode 8, val func loss 0.15648473799228668\n",
      "\n",
      "episode 9, val func loss 0.18160851299762726\n",
      "\n",
      "episode 10, val func loss 0.1460452377796173\n",
      "\n",
      "episode 11, val func loss 0.15555350482463837\n",
      "\n",
      "episode 12, val func loss 0.15773393213748932\n",
      "\n",
      "episode 13, val func loss 0.16110415756702423\n",
      "\n",
      "episode 14, val func loss 0.18600128591060638\n",
      "\n",
      "episode 15, val func loss 0.12429064512252808\n",
      "\n",
      "episode 16, val func loss 0.1576569676399231\n",
      "\n",
      "Val func train loss in epoch 14:0.1653709588572383\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.145395889878273\n",
      "\n",
      "episode 2, val func loss 0.15986378490924835\n",
      "\n",
      "episode 3, val func loss 0.15789486467838287\n",
      "\n",
      "episode 4, val func loss 0.1570785790681839\n",
      "\n",
      "episode 5, val func loss 0.12397844344377518\n",
      "\n",
      "episode 6, val func loss 0.18455812335014343\n",
      "\n",
      "episode 7, val func loss 0.1778738647699356\n",
      "\n",
      "episode 8, val func loss 0.15516695380210876\n",
      "\n",
      "episode 9, val func loss 0.17001058161258698\n",
      "\n",
      "episode 10, val func loss 0.1577518880367279\n",
      "\n",
      "episode 11, val func loss 0.1821860671043396\n",
      "\n",
      "episode 12, val func loss 0.1748751848936081\n",
      "\n",
      "episode 13, val func loss 0.18248578906059265\n",
      "\n",
      "episode 14, val func loss 0.16148865222930908\n",
      "\n",
      "episode 15, val func loss 0.15867485105991364\n",
      "\n",
      "episode 16, val func loss 0.19422954320907593\n",
      "\n",
      "Val func train loss in epoch 15:0.1652195663191378\n",
      "***********************TIME WAS 4.893790137767792 min*****************************\n",
      "\n",
      "**********************ROUND 34 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.08567032217979431\n",
      "\n",
      "episode 2, policy loss -0.10670217871665955\n",
      "\n",
      "episode 3, policy loss -0.05659278482198715\n",
      "\n",
      "episode 4, policy loss -0.1015356183052063\n",
      "\n",
      "episode 5, policy loss -0.08209625631570816\n",
      "\n",
      "episode 6, policy loss -0.11606548726558685\n",
      "\n",
      "episode 7, policy loss -0.11668525636196136\n",
      "\n",
      "episode 8, policy loss -0.09266968816518784\n",
      "\n",
      "episode 9, policy loss -0.145152747631073\n",
      "\n",
      "episode 10, policy loss -0.09001431614160538\n",
      "\n",
      "episode 11, policy loss -0.08332415670156479\n",
      "\n",
      "episode 12, policy loss -0.13342487812042236\n",
      "\n",
      "episode 13, policy loss -0.11962065100669861\n",
      "\n",
      "episode 14, policy loss -0.10011408478021622\n",
      "\n",
      "episode 15, policy loss -0.12375938892364502\n",
      "\n",
      "episode 16, policy loss -0.16770920157432556\n",
      "\n",
      "Policy train loss in epoch 0:-0.10757106356322765\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.08925606310367584\n",
      "\n",
      "episode 2, policy loss -0.12281445413827896\n",
      "\n",
      "episode 3, policy loss -0.08605325222015381\n",
      "\n",
      "episode 4, policy loss -0.1029600277543068\n",
      "\n",
      "episode 5, policy loss -0.1406179666519165\n",
      "\n",
      "episode 6, policy loss -0.10546905547380447\n",
      "\n",
      "episode 7, policy loss -0.13229621946811676\n",
      "\n",
      "episode 8, policy loss -0.08862065523862839\n",
      "\n",
      "episode 9, policy loss -0.11653976142406464\n",
      "\n",
      "episode 10, policy loss -0.09503825753927231\n",
      "\n",
      "episode 11, policy loss -0.11967051029205322\n",
      "\n",
      "episode 12, policy loss -0.0898984745144844\n",
      "\n",
      "episode 13, policy loss -0.11904625594615936\n",
      "\n",
      "episode 14, policy loss -0.1612159013748169\n",
      "\n",
      "episode 15, policy loss -0.08412937819957733\n",
      "\n",
      "episode 16, policy loss -0.056987129151821136\n",
      "\n",
      "Policy train loss in epoch 1:-0.10691333515569568\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.08574122190475464\n",
      "\n",
      "episode 2, policy loss -0.08693873882293701\n",
      "\n",
      "episode 3, policy loss -0.10218483954668045\n",
      "\n",
      "episode 4, policy loss -0.08368648588657379\n",
      "\n",
      "episode 5, policy loss -0.09073401242494583\n",
      "\n",
      "episode 6, policy loss -0.1209753155708313\n",
      "\n",
      "episode 7, policy loss -0.08659183233976364\n",
      "\n",
      "episode 8, policy loss -0.09845088422298431\n",
      "\n",
      "episode 9, policy loss -0.15769968926906586\n",
      "\n",
      "episode 10, policy loss -0.05383637174963951\n",
      "\n",
      "episode 11, policy loss -0.10077957063913345\n",
      "\n",
      "episode 12, policy loss -0.12320470809936523\n",
      "\n",
      "episode 13, policy loss -0.13336221873760223\n",
      "\n",
      "episode 14, policy loss -0.11953771859407425\n",
      "\n",
      "episode 15, policy loss -0.1232156902551651\n",
      "\n",
      "episode 16, policy loss -0.13077577948570251\n",
      "\n",
      "Policy train loss in epoch 2:-0.1061071923468262\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.10155463963747025\n",
      "\n",
      "episode 2, policy loss -0.08956653624773026\n",
      "\n",
      "episode 3, policy loss -0.16603177785873413\n",
      "\n",
      "episode 4, policy loss -0.1407676339149475\n",
      "\n",
      "episode 5, policy loss -0.1172628104686737\n",
      "\n",
      "episode 6, policy loss -0.1097768098115921\n",
      "\n",
      "episode 7, policy loss -0.08583270758390427\n",
      "\n",
      "episode 8, policy loss -0.05580880492925644\n",
      "\n",
      "episode 9, policy loss -0.09816646575927734\n",
      "\n",
      "episode 10, policy loss -0.12887760996818542\n",
      "\n",
      "episode 11, policy loss -0.08509130775928497\n",
      "\n",
      "episode 12, policy loss -0.09808598458766937\n",
      "\n",
      "episode 13, policy loss -0.08418713510036469\n",
      "\n",
      "episode 14, policy loss -0.12165671586990356\n",
      "\n",
      "episode 15, policy loss -0.12080889940261841\n",
      "\n",
      "episode 16, policy loss -0.09021136164665222\n",
      "\n",
      "Policy train loss in epoch 3:-0.10585545003414154\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.15486058592796326\n",
      "\n",
      "episode 2, val func loss 0.15063489973545074\n",
      "\n",
      "episode 3, val func loss 0.18764309585094452\n",
      "\n",
      "episode 4, val func loss 0.16514068841934204\n",
      "\n",
      "episode 5, val func loss 0.1795044243335724\n",
      "\n",
      "episode 6, val func loss 0.15745510160923004\n",
      "\n",
      "episode 7, val func loss 0.1607358455657959\n",
      "\n",
      "episode 8, val func loss 0.20241259038448334\n",
      "\n",
      "episode 9, val func loss 0.16228102147579193\n",
      "\n",
      "episode 10, val func loss 0.14547106623649597\n",
      "\n",
      "episode 11, val func loss 0.1481366753578186\n",
      "\n",
      "episode 12, val func loss 0.14340446889400482\n",
      "\n",
      "episode 13, val func loss 0.19461117684841156\n",
      "\n",
      "episode 14, val func loss 0.1354202777147293\n",
      "\n",
      "episode 15, val func loss 0.13006292283535004\n",
      "\n",
      "episode 16, val func loss 0.15249577164649963\n",
      "\n",
      "Val func train loss in epoch 0:0.16064191330224276\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.16492435336112976\n",
      "\n",
      "episode 2, val func loss 0.15326836705207825\n",
      "\n",
      "episode 3, val func loss 0.18435806035995483\n",
      "\n",
      "episode 4, val func loss 0.20247511565685272\n",
      "\n",
      "episode 5, val func loss 0.1360601782798767\n",
      "\n",
      "episode 6, val func loss 0.15884296596050262\n",
      "\n",
      "episode 7, val func loss 0.14764808118343353\n",
      "\n",
      "episode 8, val func loss 0.193459615111351\n",
      "\n",
      "episode 9, val func loss 0.14708200097084045\n",
      "\n",
      "episode 10, val func loss 0.1428976207971573\n",
      "\n",
      "episode 11, val func loss 0.1578799933195114\n",
      "\n",
      "episode 12, val func loss 0.16028785705566406\n",
      "\n",
      "episode 13, val func loss 0.17764492332935333\n",
      "\n",
      "episode 14, val func loss 0.14599046111106873\n",
      "\n",
      "episode 15, val func loss 0.13032571971416473\n",
      "\n",
      "episode 16, val func loss 0.16188298165798187\n",
      "\n",
      "Val func train loss in epoch 1:0.16031426843255758\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.181028351187706\n",
      "\n",
      "episode 2, val func loss 0.16190029680728912\n",
      "\n",
      "episode 3, val func loss 0.19281499087810516\n",
      "\n",
      "episode 4, val func loss 0.16535742580890656\n",
      "\n",
      "episode 5, val func loss 0.13000386953353882\n",
      "\n",
      "episode 6, val func loss 0.14611032605171204\n",
      "\n",
      "episode 7, val func loss 0.14280858635902405\n",
      "\n",
      "episode 8, val func loss 0.17804178595542908\n",
      "\n",
      "episode 9, val func loss 0.14712844789028168\n",
      "\n",
      "episode 10, val func loss 0.14775043725967407\n",
      "\n",
      "episode 11, val func loss 0.20236730575561523\n",
      "\n",
      "episode 12, val func loss 0.16095462441444397\n",
      "\n",
      "episode 13, val func loss 0.15318575501441956\n",
      "\n",
      "episode 14, val func loss 0.15782049298286438\n",
      "\n",
      "episode 15, val func loss 0.15777696669101715\n",
      "\n",
      "episode 16, val func loss 0.1339021474123001\n",
      "\n",
      "Val func train loss in epoch 2:0.15993448812514544\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18590348958969116\n",
      "\n",
      "episode 2, val func loss 0.14976277947425842\n",
      "\n",
      "episode 3, val func loss 0.1434100866317749\n",
      "\n",
      "episode 4, val func loss 0.20350444316864014\n",
      "\n",
      "episode 5, val func loss 0.18176087737083435\n",
      "\n",
      "episode 6, val func loss 0.16223393380641937\n",
      "\n",
      "episode 7, val func loss 0.13143390417099\n",
      "\n",
      "episode 8, val func loss 0.1673973798751831\n",
      "\n",
      "episode 9, val func loss 0.19297507405281067\n",
      "\n",
      "episode 10, val func loss 0.16036659479141235\n",
      "\n",
      "episode 11, val func loss 0.1473545879125595\n",
      "\n",
      "episode 12, val func loss 0.15494082868099213\n",
      "\n",
      "episode 13, val func loss 0.13399678468704224\n",
      "\n",
      "episode 14, val func loss 0.1510436236858368\n",
      "\n",
      "episode 15, val func loss 0.1536387801170349\n",
      "\n",
      "episode 16, val func loss 0.15728040039539337\n",
      "\n",
      "Val func train loss in epoch 3:0.1610627230256796\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18279291689395905\n",
      "\n",
      "episode 2, val func loss 0.12986187636852264\n",
      "\n",
      "episode 3, val func loss 0.16203272342681885\n",
      "\n",
      "episode 4, val func loss 0.14828439056873322\n",
      "\n",
      "episode 5, val func loss 0.1456955224275589\n",
      "\n",
      "episode 6, val func loss 0.15297527611255646\n",
      "\n",
      "episode 7, val func loss 0.14671605825424194\n",
      "\n",
      "episode 8, val func loss 0.1432516872882843\n",
      "\n",
      "episode 9, val func loss 0.15526488423347473\n",
      "\n",
      "episode 10, val func loss 0.2053733766078949\n",
      "\n",
      "episode 11, val func loss 0.16461364924907684\n",
      "\n",
      "episode 12, val func loss 0.1606549471616745\n",
      "\n",
      "episode 13, val func loss 0.1574939489364624\n",
      "\n",
      "episode 14, val func loss 0.19368219375610352\n",
      "\n",
      "episode 15, val func loss 0.13477419316768646\n",
      "\n",
      "episode 16, val func loss 0.17683245241641998\n",
      "\n",
      "Val func train loss in epoch 4:0.1600187560543418\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.13110679388046265\n",
      "\n",
      "episode 2, val func loss 0.1534637063741684\n",
      "\n",
      "episode 3, val func loss 0.16586971282958984\n",
      "\n",
      "episode 4, val func loss 0.17615704238414764\n",
      "\n",
      "episode 5, val func loss 0.20315773785114288\n",
      "\n",
      "episode 6, val func loss 0.161916583776474\n",
      "\n",
      "episode 7, val func loss 0.14792297780513763\n",
      "\n",
      "episode 8, val func loss 0.13531677424907684\n",
      "\n",
      "episode 9, val func loss 0.15374310314655304\n",
      "\n",
      "episode 10, val func loss 0.18521267175674438\n",
      "\n",
      "episode 11, val func loss 0.19614870846271515\n",
      "\n",
      "episode 12, val func loss 0.14309535920619965\n",
      "\n",
      "episode 13, val func loss 0.14757442474365234\n",
      "\n",
      "episode 14, val func loss 0.15957051515579224\n",
      "\n",
      "episode 15, val func loss 0.15808741748332977\n",
      "\n",
      "episode 16, val func loss 0.14570917189121246\n",
      "\n",
      "Val func train loss in epoch 5:0.16025329381227493\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1435689479112625\n",
      "\n",
      "episode 2, val func loss 0.13588230311870575\n",
      "\n",
      "episode 3, val func loss 0.1925751268863678\n",
      "\n",
      "episode 4, val func loss 0.1296965330839157\n",
      "\n",
      "episode 5, val func loss 0.14560075104236603\n",
      "\n",
      "episode 6, val func loss 0.18286854028701782\n",
      "\n",
      "episode 7, val func loss 0.148011714220047\n",
      "\n",
      "episode 8, val func loss 0.15882784128189087\n",
      "\n",
      "episode 9, val func loss 0.14713674783706665\n",
      "\n",
      "episode 10, val func loss 0.15970875322818756\n",
      "\n",
      "episode 11, val func loss 0.16579578816890717\n",
      "\n",
      "episode 12, val func loss 0.20323963463306427\n",
      "\n",
      "episode 13, val func loss 0.1558827906847\n",
      "\n",
      "episode 14, val func loss 0.1526256948709488\n",
      "\n",
      "episode 15, val func loss 0.1804436892271042\n",
      "\n",
      "episode 16, val func loss 0.1617201715707779\n",
      "\n",
      "Val func train loss in epoch 6:0.16022406425327063\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.12884294986724854\n",
      "\n",
      "episode 2, val func loss 0.17852053046226501\n",
      "\n",
      "episode 3, val func loss 0.15778721868991852\n",
      "\n",
      "episode 4, val func loss 0.19270020723342896\n",
      "\n",
      "episode 5, val func loss 0.18128611147403717\n",
      "\n",
      "episode 6, val func loss 0.14395150542259216\n",
      "\n",
      "episode 7, val func loss 0.16009493172168732\n",
      "\n",
      "episode 8, val func loss 0.16586650907993317\n",
      "\n",
      "episode 9, val func loss 0.1463877409696579\n",
      "\n",
      "episode 10, val func loss 0.16046161949634552\n",
      "\n",
      "episode 11, val func loss 0.13411609828472137\n",
      "\n",
      "episode 12, val func loss 0.14859740436077118\n",
      "\n",
      "episode 13, val func loss 0.14901883900165558\n",
      "\n",
      "episode 14, val func loss 0.1609925627708435\n",
      "\n",
      "episode 15, val func loss 0.15271234512329102\n",
      "\n",
      "episode 16, val func loss 0.20355573296546936\n",
      "\n",
      "Val func train loss in epoch 7:0.16030576918274164\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.15444669127464294\n",
      "\n",
      "episode 2, val func loss 0.1433815211057663\n",
      "\n",
      "episode 3, val func loss 0.1650819182395935\n",
      "\n",
      "episode 4, val func loss 0.19368739426136017\n",
      "\n",
      "episode 5, val func loss 0.14825400710105896\n",
      "\n",
      "episode 6, val func loss 0.16112403571605682\n",
      "\n",
      "episode 7, val func loss 0.1818433403968811\n",
      "\n",
      "episode 8, val func loss 0.13041502237319946\n",
      "\n",
      "episode 9, val func loss 0.17643488943576813\n",
      "\n",
      "episode 10, val func loss 0.14676433801651\n",
      "\n",
      "episode 11, val func loss 0.15401576459407806\n",
      "\n",
      "episode 12, val func loss 0.14568279683589935\n",
      "\n",
      "episode 13, val func loss 0.2024836540222168\n",
      "\n",
      "episode 14, val func loss 0.1602870672941208\n",
      "\n",
      "episode 15, val func loss 0.15884308516979218\n",
      "\n",
      "episode 16, val func loss 0.1352163404226303\n",
      "\n",
      "Val func train loss in epoch 8:0.15987261664122343\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.14306868612766266\n",
      "\n",
      "episode 2, val func loss 0.14829476177692413\n",
      "\n",
      "episode 3, val func loss 0.15221285820007324\n",
      "\n",
      "episode 4, val func loss 0.16171321272850037\n",
      "\n",
      "episode 5, val func loss 0.20658867061138153\n",
      "\n",
      "episode 6, val func loss 0.1483401507139206\n",
      "\n",
      "episode 7, val func loss 0.19497349858283997\n",
      "\n",
      "episode 8, val func loss 0.1301725059747696\n",
      "\n",
      "episode 9, val func loss 0.15818192064762115\n",
      "\n",
      "episode 10, val func loss 0.13608522713184357\n",
      "\n",
      "episode 11, val func loss 0.1814735233783722\n",
      "\n",
      "episode 12, val func loss 0.1663825809955597\n",
      "\n",
      "episode 13, val func loss 0.16168780624866486\n",
      "\n",
      "episode 14, val func loss 0.15263263881206512\n",
      "\n",
      "episode 15, val func loss 0.14760462939739227\n",
      "\n",
      "episode 16, val func loss 0.17763374745845795\n",
      "\n",
      "Val func train loss in epoch 9:0.16044040117412806\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.15981385111808777\n",
      "\n",
      "episode 2, val func loss 0.15308715403079987\n",
      "\n",
      "episode 3, val func loss 0.16505174338817596\n",
      "\n",
      "episode 4, val func loss 0.15779653191566467\n",
      "\n",
      "episode 5, val func loss 0.1484081745147705\n",
      "\n",
      "episode 6, val func loss 0.18275414407253265\n",
      "\n",
      "episode 7, val func loss 0.1616791933774948\n",
      "\n",
      "episode 8, val func loss 0.1461457461118698\n",
      "\n",
      "episode 9, val func loss 0.14410170912742615\n",
      "\n",
      "episode 10, val func loss 0.20317919552326202\n",
      "\n",
      "episode 11, val func loss 0.1300429105758667\n",
      "\n",
      "episode 12, val func loss 0.15593427419662476\n",
      "\n",
      "episode 13, val func loss 0.1470307856798172\n",
      "\n",
      "episode 14, val func loss 0.13442450761795044\n",
      "\n",
      "episode 15, val func loss 0.18038353323936462\n",
      "\n",
      "episode 16, val func loss 0.19534528255462646\n",
      "\n",
      "Val func train loss in epoch 10:0.1603236710652709\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.15357749164104462\n",
      "\n",
      "episode 2, val func loss 0.1294894814491272\n",
      "\n",
      "episode 3, val func loss 0.20387707650661469\n",
      "\n",
      "episode 4, val func loss 0.1430206447839737\n",
      "\n",
      "episode 5, val func loss 0.1834200620651245\n",
      "\n",
      "episode 6, val func loss 0.15252336859703064\n",
      "\n",
      "episode 7, val func loss 0.13495270907878876\n",
      "\n",
      "episode 8, val func loss 0.148262158036232\n",
      "\n",
      "episode 9, val func loss 0.1922658532857895\n",
      "\n",
      "episode 10, val func loss 0.16157624125480652\n",
      "\n",
      "episode 11, val func loss 0.15846854448318481\n",
      "\n",
      "episode 12, val func loss 0.14584435522556305\n",
      "\n",
      "episode 13, val func loss 0.1656181514263153\n",
      "\n",
      "episode 14, val func loss 0.17710623145103455\n",
      "\n",
      "episode 15, val func loss 0.15972957015037537\n",
      "\n",
      "episode 16, val func loss 0.1471128910779953\n",
      "\n",
      "Val func train loss in epoch 11:0.15980280190706253\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.13050955533981323\n",
      "\n",
      "episode 2, val func loss 0.15674631297588348\n",
      "\n",
      "episode 3, val func loss 0.15814624726772308\n",
      "\n",
      "episode 4, val func loss 0.20374178886413574\n",
      "\n",
      "episode 5, val func loss 0.15245001018047333\n",
      "\n",
      "episode 6, val func loss 0.19565342366695404\n",
      "\n",
      "episode 7, val func loss 0.1615593433380127\n",
      "\n",
      "episode 8, val func loss 0.14332690834999084\n",
      "\n",
      "episode 9, val func loss 0.178835928440094\n",
      "\n",
      "episode 10, val func loss 0.1815558820962906\n",
      "\n",
      "episode 11, val func loss 0.16081981360912323\n",
      "\n",
      "episode 12, val func loss 0.14822377264499664\n",
      "\n",
      "episode 13, val func loss 0.16783614456653595\n",
      "\n",
      "episode 14, val func loss 0.1466560661792755\n",
      "\n",
      "episode 15, val func loss 0.14588741958141327\n",
      "\n",
      "episode 16, val func loss 0.13714206218719482\n",
      "\n",
      "Val func train loss in epoch 12:0.1605681674554944\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1535412073135376\n",
      "\n",
      "episode 2, val func loss 0.16548879444599152\n",
      "\n",
      "episode 3, val func loss 0.20371432602405548\n",
      "\n",
      "episode 4, val func loss 0.18021227419376373\n",
      "\n",
      "episode 5, val func loss 0.1830916702747345\n",
      "\n",
      "episode 6, val func loss 0.1460076868534088\n",
      "\n",
      "episode 7, val func loss 0.1432380974292755\n",
      "\n",
      "episode 8, val func loss 0.1484392136335373\n",
      "\n",
      "episode 9, val func loss 0.14660097658634186\n",
      "\n",
      "episode 10, val func loss 0.16063398122787476\n",
      "\n",
      "episode 11, val func loss 0.16258090734481812\n",
      "\n",
      "episode 12, val func loss 0.13702794909477234\n",
      "\n",
      "episode 13, val func loss 0.1305769979953766\n",
      "\n",
      "episode 14, val func loss 0.15775257349014282\n",
      "\n",
      "episode 15, val func loss 0.15437786281108856\n",
      "\n",
      "episode 16, val func loss 0.19591665267944336\n",
      "\n",
      "Val func train loss in epoch 13:0.16057507321238518\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1507461667060852\n",
      "\n",
      "episode 2, val func loss 0.14376726746559143\n",
      "\n",
      "episode 3, val func loss 0.20552057027816772\n",
      "\n",
      "episode 4, val func loss 0.16441620886325836\n",
      "\n",
      "episode 5, val func loss 0.183465376496315\n",
      "\n",
      "episode 6, val func loss 0.1569339483976364\n",
      "\n",
      "episode 7, val func loss 0.16009899973869324\n",
      "\n",
      "episode 8, val func loss 0.19287224113941193\n",
      "\n",
      "episode 9, val func loss 0.17671340703964233\n",
      "\n",
      "episode 10, val func loss 0.1314447671175003\n",
      "\n",
      "episode 11, val func loss 0.163055419921875\n",
      "\n",
      "episode 12, val func loss 0.14686232805252075\n",
      "\n",
      "episode 13, val func loss 0.15323330461978912\n",
      "\n",
      "episode 14, val func loss 0.14530310034751892\n",
      "\n",
      "episode 15, val func loss 0.1351797729730606\n",
      "\n",
      "episode 16, val func loss 0.15791888535022736\n",
      "\n",
      "Val func train loss in epoch 14:0.16047073528170586\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.15768909454345703\n",
      "\n",
      "episode 2, val func loss 0.18398417532444\n",
      "\n",
      "episode 3, val func loss 0.1530166119337082\n",
      "\n",
      "episode 4, val func loss 0.16477757692337036\n",
      "\n",
      "episode 5, val func loss 0.16049809753894806\n",
      "\n",
      "episode 6, val func loss 0.13482895493507385\n",
      "\n",
      "episode 7, val func loss 0.19394342601299286\n",
      "\n",
      "episode 8, val func loss 0.177456334233284\n",
      "\n",
      "episode 9, val func loss 0.13086621463298798\n",
      "\n",
      "episode 10, val func loss 0.1465912014245987\n",
      "\n",
      "episode 11, val func loss 0.15996408462524414\n",
      "\n",
      "episode 12, val func loss 0.14735159277915955\n",
      "\n",
      "episode 13, val func loss 0.2026185244321823\n",
      "\n",
      "episode 14, val func loss 0.1433078795671463\n",
      "\n",
      "episode 15, val func loss 0.16112609207630157\n",
      "\n",
      "episode 16, val func loss 0.14661440253257751\n",
      "\n",
      "Val func train loss in epoch 15:0.16028964146971703\n",
      "***********************TIME WAS 4.898531989256541 min*****************************\n",
      "\n",
      "**********************ROUND 35 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.10657860338687897\n",
      "\n",
      "episode 2, policy loss -0.058258820325136185\n",
      "\n",
      "episode 3, policy loss -0.10050638020038605\n",
      "\n",
      "episode 4, policy loss -0.14474955201148987\n",
      "\n",
      "episode 5, policy loss -0.16098766028881073\n",
      "\n",
      "episode 6, policy loss -0.1022544577717781\n",
      "\n",
      "episode 7, policy loss -0.11488133668899536\n",
      "\n",
      "episode 8, policy loss -0.07735614478588104\n",
      "\n",
      "episode 9, policy loss -0.10574065148830414\n",
      "\n",
      "episode 10, policy loss -0.19351385533809662\n",
      "\n",
      "episode 11, policy loss -0.15739741921424866\n",
      "\n",
      "episode 12, policy loss -0.09659995138645172\n",
      "\n",
      "episode 13, policy loss -0.10316690802574158\n",
      "\n",
      "episode 14, policy loss -0.13951854407787323\n",
      "\n",
      "episode 15, policy loss -0.18117184937000275\n",
      "\n",
      "episode 16, policy loss -0.07958260923624039\n",
      "\n",
      "Policy train loss in epoch 0:-0.12014154647476971\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.0763113796710968\n",
      "\n",
      "episode 2, policy loss -0.15336856245994568\n",
      "\n",
      "episode 3, policy loss -0.16360031068325043\n",
      "\n",
      "episode 4, policy loss -0.10963185131549835\n",
      "\n",
      "episode 5, policy loss -0.08184970915317535\n",
      "\n",
      "episode 6, policy loss -0.09587247669696808\n",
      "\n",
      "episode 7, policy loss -0.18263909220695496\n",
      "\n",
      "episode 8, policy loss -0.11318999528884888\n",
      "\n",
      "episode 9, policy loss -0.10477743297815323\n",
      "\n",
      "episode 10, policy loss -0.19215446710586548\n",
      "\n",
      "episode 11, policy loss -0.05595383420586586\n",
      "\n",
      "episode 12, policy loss -0.1456725299358368\n",
      "\n",
      "episode 13, policy loss -0.10183332860469818\n",
      "\n",
      "episode 14, policy loss -0.1034994125366211\n",
      "\n",
      "episode 15, policy loss -0.13907480239868164\n",
      "\n",
      "episode 16, policy loss -0.10078589618206024\n",
      "\n",
      "Policy train loss in epoch 1:-0.12001344258897007\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.08039004355669022\n",
      "\n",
      "episode 2, policy loss -0.18999196588993073\n",
      "\n",
      "episode 3, policy loss -0.09675493836402893\n",
      "\n",
      "episode 4, policy loss -0.055799879133701324\n",
      "\n",
      "episode 5, policy loss -0.1487383246421814\n",
      "\n",
      "episode 6, policy loss -0.10451208055019379\n",
      "\n",
      "episode 7, policy loss -0.07769598066806793\n",
      "\n",
      "episode 8, policy loss -0.16467861831188202\n",
      "\n",
      "episode 9, policy loss -0.18638066947460175\n",
      "\n",
      "episode 10, policy loss -0.15611498057842255\n",
      "\n",
      "episode 11, policy loss -0.10249509662389755\n",
      "\n",
      "episode 12, policy loss -0.11019542813301086\n",
      "\n",
      "episode 13, policy loss -0.10942834615707397\n",
      "\n",
      "episode 14, policy loss -0.10040988773107529\n",
      "\n",
      "episode 15, policy loss -0.14338326454162598\n",
      "\n",
      "episode 16, policy loss -0.10509174317121506\n",
      "\n",
      "Policy train loss in epoch 2:-0.12075382797047496\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.08098024874925613\n",
      "\n",
      "episode 2, policy loss -0.19220398366451263\n",
      "\n",
      "episode 3, policy loss -0.1618194580078125\n",
      "\n",
      "episode 4, policy loss -0.1038295179605484\n",
      "\n",
      "episode 5, policy loss -0.10275162756443024\n",
      "\n",
      "episode 6, policy loss -0.115575410425663\n",
      "\n",
      "episode 7, policy loss -0.15471619367599487\n",
      "\n",
      "episode 8, policy loss -0.1481957584619522\n",
      "\n",
      "episode 9, policy loss -0.18768718838691711\n",
      "\n",
      "episode 10, policy loss -0.07681766152381897\n",
      "\n",
      "episode 11, policy loss -0.11005593836307526\n",
      "\n",
      "episode 12, policy loss -0.10464734584093094\n",
      "\n",
      "episode 13, policy loss -0.05710568279027939\n",
      "\n",
      "episode 14, policy loss -0.09424368292093277\n",
      "\n",
      "episode 15, policy loss -0.10381871461868286\n",
      "\n",
      "episode 16, policy loss -0.1393319070339203\n",
      "\n",
      "Policy train loss in epoch 3:-0.12086126999929547\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.16618582606315613\n",
      "\n",
      "episode 2, val func loss 0.22973446547985077\n",
      "\n",
      "episode 3, val func loss 0.17989321053028107\n",
      "\n",
      "episode 4, val func loss 0.19753725826740265\n",
      "\n",
      "episode 5, val func loss 0.1861170083284378\n",
      "\n",
      "episode 6, val func loss 0.1662888526916504\n",
      "\n",
      "episode 7, val func loss 0.12658239901065826\n",
      "\n",
      "episode 8, val func loss 0.1521029770374298\n",
      "\n",
      "episode 9, val func loss 0.11948668956756592\n",
      "\n",
      "episode 10, val func loss 0.18409790098667145\n",
      "\n",
      "episode 11, val func loss 0.13791535794734955\n",
      "\n",
      "episode 12, val func loss 0.15828630328178406\n",
      "\n",
      "episode 13, val func loss 0.18806511163711548\n",
      "\n",
      "episode 14, val func loss 0.17791719734668732\n",
      "\n",
      "episode 15, val func loss 0.13277021050453186\n",
      "\n",
      "episode 16, val func loss 0.10743183642625809\n",
      "\n",
      "Val func train loss in epoch 0:0.1631507878191769\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1875375509262085\n",
      "\n",
      "episode 2, val func loss 0.10689752548933029\n",
      "\n",
      "episode 3, val func loss 0.19969691336154938\n",
      "\n",
      "episode 4, val func loss 0.11955441534519196\n",
      "\n",
      "episode 5, val func loss 0.2273717224597931\n",
      "\n",
      "episode 6, val func loss 0.1387120485305786\n",
      "\n",
      "episode 7, val func loss 0.1663198173046112\n",
      "\n",
      "episode 8, val func loss 0.17591938376426697\n",
      "\n",
      "episode 9, val func loss 0.1670277714729309\n",
      "\n",
      "episode 10, val func loss 0.18263454735279083\n",
      "\n",
      "episode 11, val func loss 0.15909156203269958\n",
      "\n",
      "episode 12, val func loss 0.1845542937517166\n",
      "\n",
      "episode 13, val func loss 0.1514042764902115\n",
      "\n",
      "episode 14, val func loss 0.133254274725914\n",
      "\n",
      "episode 15, val func loss 0.18984295427799225\n",
      "\n",
      "episode 16, val func loss 0.12170501798391342\n",
      "\n",
      "Val func train loss in epoch 1:0.1632202547043562\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.12152040004730225\n",
      "\n",
      "episode 2, val func loss 0.17780068516731262\n",
      "\n",
      "episode 3, val func loss 0.20177924633026123\n",
      "\n",
      "episode 4, val func loss 0.1376299411058426\n",
      "\n",
      "episode 5, val func loss 0.1328279674053192\n",
      "\n",
      "episode 6, val func loss 0.22803929448127747\n",
      "\n",
      "episode 7, val func loss 0.15948745608329773\n",
      "\n",
      "episode 8, val func loss 0.175941601395607\n",
      "\n",
      "episode 9, val func loss 0.12002412229776382\n",
      "\n",
      "episode 10, val func loss 0.18327045440673828\n",
      "\n",
      "episode 11, val func loss 0.16675950586795807\n",
      "\n",
      "episode 12, val func loss 0.11080043762922287\n",
      "\n",
      "episode 13, val func loss 0.187295064330101\n",
      "\n",
      "episode 14, val func loss 0.18628738820552826\n",
      "\n",
      "episode 15, val func loss 0.15138179063796997\n",
      "\n",
      "episode 16, val func loss 0.1656157523393631\n",
      "\n",
      "Val func train loss in epoch 2:0.1629038192331791\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18411080539226532\n",
      "\n",
      "episode 2, val func loss 0.22804296016693115\n",
      "\n",
      "episode 3, val func loss 0.16512002050876617\n",
      "\n",
      "episode 4, val func loss 0.11979850381612778\n",
      "\n",
      "episode 5, val func loss 0.12456458806991577\n",
      "\n",
      "episode 6, val func loss 0.19694755971431732\n",
      "\n",
      "episode 7, val func loss 0.13341327011585236\n",
      "\n",
      "episode 8, val func loss 0.1602577269077301\n",
      "\n",
      "episode 9, val func loss 0.1765846163034439\n",
      "\n",
      "episode 10, val func loss 0.10826189070940018\n",
      "\n",
      "episode 11, val func loss 0.187445268034935\n",
      "\n",
      "episode 12, val func loss 0.16663306951522827\n",
      "\n",
      "episode 13, val func loss 0.13813675940036774\n",
      "\n",
      "episode 14, val func loss 0.18819107115268707\n",
      "\n",
      "episode 15, val func loss 0.17922301590442657\n",
      "\n",
      "episode 16, val func loss 0.15133625268936157\n",
      "\n",
      "Val func train loss in epoch 3:0.16300421115010977\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.16660445928573608\n",
      "\n",
      "episode 2, val func loss 0.19999369978904724\n",
      "\n",
      "episode 3, val func loss 0.1513022929430008\n",
      "\n",
      "episode 4, val func loss 0.10740240663290024\n",
      "\n",
      "episode 5, val func loss 0.1654440462589264\n",
      "\n",
      "episode 6, val func loss 0.1837981641292572\n",
      "\n",
      "episode 7, val func loss 0.1331399530172348\n",
      "\n",
      "episode 8, val func loss 0.1585281491279602\n",
      "\n",
      "episode 9, val func loss 0.1787538081407547\n",
      "\n",
      "episode 10, val func loss 0.12138892710208893\n",
      "\n",
      "episode 11, val func loss 0.23070542514324188\n",
      "\n",
      "episode 12, val func loss 0.1890491247177124\n",
      "\n",
      "episode 13, val func loss 0.12012436240911484\n",
      "\n",
      "episode 14, val func loss 0.1869860142469406\n",
      "\n",
      "episode 15, val func loss 0.13862115144729614\n",
      "\n",
      "episode 16, val func loss 0.1757166087627411\n",
      "\n",
      "Val func train loss in epoch 4:0.1629724120721221\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1668979376554489\n",
      "\n",
      "episode 2, val func loss 0.18516312539577484\n",
      "\n",
      "episode 3, val func loss 0.13357295095920563\n",
      "\n",
      "episode 4, val func loss 0.1195002868771553\n",
      "\n",
      "episode 5, val func loss 0.1657792329788208\n",
      "\n",
      "episode 6, val func loss 0.1513451635837555\n",
      "\n",
      "episode 7, val func loss 0.18642264604568481\n",
      "\n",
      "episode 8, val func loss 0.18948836624622345\n",
      "\n",
      "episode 9, val func loss 0.10659537464380264\n",
      "\n",
      "episode 10, val func loss 0.17708978056907654\n",
      "\n",
      "episode 11, val func loss 0.19837670028209686\n",
      "\n",
      "episode 12, val func loss 0.1599704772233963\n",
      "\n",
      "episode 13, val func loss 0.1868530660867691\n",
      "\n",
      "episode 14, val func loss 0.12467438727617264\n",
      "\n",
      "episode 15, val func loss 0.1389247626066208\n",
      "\n",
      "episode 16, val func loss 0.22629414498806\n",
      "\n",
      "Val func train loss in epoch 5:0.163559275213629\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.13791267573833466\n",
      "\n",
      "episode 2, val func loss 0.12244478613138199\n",
      "\n",
      "episode 3, val func loss 0.18707019090652466\n",
      "\n",
      "episode 4, val func loss 0.1191791445016861\n",
      "\n",
      "episode 5, val func loss 0.16617783904075623\n",
      "\n",
      "episode 6, val func loss 0.18724794685840607\n",
      "\n",
      "episode 7, val func loss 0.18073591589927673\n",
      "\n",
      "episode 8, val func loss 0.19879913330078125\n",
      "\n",
      "episode 9, val func loss 0.22748494148254395\n",
      "\n",
      "episode 10, val func loss 0.10820787400007248\n",
      "\n",
      "episode 11, val func loss 0.16532886028289795\n",
      "\n",
      "episode 12, val func loss 0.17596282064914703\n",
      "\n",
      "episode 13, val func loss 0.15876367688179016\n",
      "\n",
      "episode 14, val func loss 0.15122932195663452\n",
      "\n",
      "episode 15, val func loss 0.13328620791435242\n",
      "\n",
      "episode 16, val func loss 0.1845814287662506\n",
      "\n",
      "Val func train loss in epoch 6:0.1627757977694273\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18492391705513\n",
      "\n",
      "episode 2, val func loss 0.1805162876844406\n",
      "\n",
      "episode 3, val func loss 0.18743407726287842\n",
      "\n",
      "episode 4, val func loss 0.10684335231781006\n",
      "\n",
      "episode 5, val func loss 0.13743934035301208\n",
      "\n",
      "episode 6, val func loss 0.12154096364974976\n",
      "\n",
      "episode 7, val func loss 0.12091360986232758\n",
      "\n",
      "episode 8, val func loss 0.1660126894712448\n",
      "\n",
      "episode 9, val func loss 0.1579074263572693\n",
      "\n",
      "episode 10, val func loss 0.15139712393283844\n",
      "\n",
      "episode 11, val func loss 0.1658993363380432\n",
      "\n",
      "episode 12, val func loss 0.1328001618385315\n",
      "\n",
      "episode 13, val func loss 0.2276209145784378\n",
      "\n",
      "episode 14, val func loss 0.18521614372730255\n",
      "\n",
      "episode 15, val func loss 0.19606143236160278\n",
      "\n",
      "episode 16, val func loss 0.18001988530158997\n",
      "\n",
      "Val func train loss in epoch 7:0.16265916638076305\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1781209111213684\n",
      "\n",
      "episode 2, val func loss 0.18558719754219055\n",
      "\n",
      "episode 3, val func loss 0.13325509428977966\n",
      "\n",
      "episode 4, val func loss 0.20188824832439423\n",
      "\n",
      "episode 5, val func loss 0.16688698530197144\n",
      "\n",
      "episode 6, val func loss 0.12164313346147537\n",
      "\n",
      "episode 7, val func loss 0.1382095366716385\n",
      "\n",
      "episode 8, val func loss 0.1579608917236328\n",
      "\n",
      "episode 9, val func loss 0.1515023410320282\n",
      "\n",
      "episode 10, val func loss 0.1076975092291832\n",
      "\n",
      "episode 11, val func loss 0.18558992445468903\n",
      "\n",
      "episode 12, val func loss 0.18834543228149414\n",
      "\n",
      "episode 13, val func loss 0.22739093005657196\n",
      "\n",
      "episode 14, val func loss 0.12069886922836304\n",
      "\n",
      "episode 15, val func loss 0.1705189347267151\n",
      "\n",
      "episode 16, val func loss 0.18497098982334137\n",
      "\n",
      "Val func train loss in epoch 8:0.1637666830793023\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.15216854214668274\n",
      "\n",
      "episode 2, val func loss 0.22640644013881683\n",
      "\n",
      "episode 3, val func loss 0.15873846411705017\n",
      "\n",
      "episode 4, val func loss 0.13331463932991028\n",
      "\n",
      "episode 5, val func loss 0.17706291377544403\n",
      "\n",
      "episode 6, val func loss 0.16521719098091125\n",
      "\n",
      "episode 7, val func loss 0.12217748910188675\n",
      "\n",
      "episode 8, val func loss 0.13825421035289764\n",
      "\n",
      "episode 9, val func loss 0.12009213864803314\n",
      "\n",
      "episode 10, val func loss 0.16662921011447906\n",
      "\n",
      "episode 11, val func loss 0.18479521572589874\n",
      "\n",
      "episode 12, val func loss 0.18781974911689758\n",
      "\n",
      "episode 13, val func loss 0.18472178280353546\n",
      "\n",
      "episode 14, val func loss 0.19154109060764313\n",
      "\n",
      "episode 15, val func loss 0.11150243878364563\n",
      "\n",
      "episode 16, val func loss 0.19804494082927704\n",
      "\n",
      "Val func train loss in epoch 9:0.1636554035358131\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.11992491781711578\n",
      "\n",
      "episode 2, val func loss 0.13308538496494293\n",
      "\n",
      "episode 3, val func loss 0.2008960247039795\n",
      "\n",
      "episode 4, val func loss 0.1062707006931305\n",
      "\n",
      "episode 5, val func loss 0.1847553849220276\n",
      "\n",
      "episode 6, val func loss 0.15126851201057434\n",
      "\n",
      "episode 7, val func loss 0.18024437129497528\n",
      "\n",
      "episode 8, val func loss 0.22816163301467896\n",
      "\n",
      "episode 9, val func loss 0.1858559548854828\n",
      "\n",
      "episode 10, val func loss 0.13885463774204254\n",
      "\n",
      "episode 11, val func loss 0.1243516057729721\n",
      "\n",
      "episode 12, val func loss 0.1663895845413208\n",
      "\n",
      "episode 13, val func loss 0.17657367885112762\n",
      "\n",
      "episode 14, val func loss 0.16548503935337067\n",
      "\n",
      "episode 15, val func loss 0.18659073114395142\n",
      "\n",
      "episode 16, val func loss 0.15877774357795715\n",
      "\n",
      "Val func train loss in epoch 10:0.16296786908060312\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.17969045042991638\n",
      "\n",
      "episode 2, val func loss 0.18531116843223572\n",
      "\n",
      "episode 3, val func loss 0.1885586827993393\n",
      "\n",
      "episode 4, val func loss 0.12015190720558167\n",
      "\n",
      "episode 5, val func loss 0.13319413363933563\n",
      "\n",
      "episode 6, val func loss 0.13794372975826263\n",
      "\n",
      "episode 7, val func loss 0.1650591343641281\n",
      "\n",
      "episode 8, val func loss 0.15838533639907837\n",
      "\n",
      "episode 9, val func loss 0.19863329827785492\n",
      "\n",
      "episode 10, val func loss 0.22773297131061554\n",
      "\n",
      "episode 11, val func loss 0.15142276883125305\n",
      "\n",
      "episode 12, val func loss 0.124212346971035\n",
      "\n",
      "episode 13, val func loss 0.16682106256484985\n",
      "\n",
      "episode 14, val func loss 0.18704631924629211\n",
      "\n",
      "episode 15, val func loss 0.10842902213335037\n",
      "\n",
      "episode 16, val func loss 0.17733250558376312\n",
      "\n",
      "Val func train loss in epoch 11:0.16312030237168074\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.11998344957828522\n",
      "\n",
      "episode 2, val func loss 0.12224938720464706\n",
      "\n",
      "episode 3, val func loss 0.17827245593070984\n",
      "\n",
      "episode 4, val func loss 0.18614035844802856\n",
      "\n",
      "episode 5, val func loss 0.18903899192810059\n",
      "\n",
      "episode 6, val func loss 0.10554349422454834\n",
      "\n",
      "episode 7, val func loss 0.13283061981201172\n",
      "\n",
      "episode 8, val func loss 0.18903620541095734\n",
      "\n",
      "episode 9, val func loss 0.15120719373226166\n",
      "\n",
      "episode 10, val func loss 0.1663181334733963\n",
      "\n",
      "episode 11, val func loss 0.1652412861585617\n",
      "\n",
      "episode 12, val func loss 0.1763203740119934\n",
      "\n",
      "episode 13, val func loss 0.19657330214977264\n",
      "\n",
      "episode 14, val func loss 0.16190995275974274\n",
      "\n",
      "episode 15, val func loss 0.22511979937553406\n",
      "\n",
      "episode 16, val func loss 0.1403283327817917\n",
      "\n",
      "Val func train loss in epoch 12:0.16288208356127143\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18493874371051788\n",
      "\n",
      "episode 2, val func loss 0.15276393294334412\n",
      "\n",
      "episode 3, val func loss 0.18257559835910797\n",
      "\n",
      "episode 4, val func loss 0.13346154987812042\n",
      "\n",
      "episode 5, val func loss 0.22845563292503357\n",
      "\n",
      "episode 6, val func loss 0.12192494422197342\n",
      "\n",
      "episode 7, val func loss 0.15757763385772705\n",
      "\n",
      "episode 8, val func loss 0.189569354057312\n",
      "\n",
      "episode 9, val func loss 0.18696540594100952\n",
      "\n",
      "episode 10, val func loss 0.1654379814863205\n",
      "\n",
      "episode 11, val func loss 0.1199168786406517\n",
      "\n",
      "episode 12, val func loss 0.13786451518535614\n",
      "\n",
      "episode 13, val func loss 0.19804105162620544\n",
      "\n",
      "episode 14, val func loss 0.10962360352277756\n",
      "\n",
      "episode 15, val func loss 0.1760215014219284\n",
      "\n",
      "episode 16, val func loss 0.166788250207901\n",
      "\n",
      "Val func train loss in epoch 13:0.16324541112408042\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17609377205371857\n",
      "\n",
      "episode 2, val func loss 0.18696266412734985\n",
      "\n",
      "episode 3, val func loss 0.11985955387353897\n",
      "\n",
      "episode 4, val func loss 0.1855672001838684\n",
      "\n",
      "episode 5, val func loss 0.13368642330169678\n",
      "\n",
      "episode 6, val func loss 0.13874414563179016\n",
      "\n",
      "episode 7, val func loss 0.1811840534210205\n",
      "\n",
      "episode 8, val func loss 0.22797837853431702\n",
      "\n",
      "episode 9, val func loss 0.15837500989437103\n",
      "\n",
      "episode 10, val func loss 0.19960714876651764\n",
      "\n",
      "episode 11, val func loss 0.1663823276758194\n",
      "\n",
      "episode 12, val func loss 0.18446607887744904\n",
      "\n",
      "episode 13, val func loss 0.10769005864858627\n",
      "\n",
      "episode 14, val func loss 0.15081098675727844\n",
      "\n",
      "episode 15, val func loss 0.16543243825435638\n",
      "\n",
      "episode 16, val func loss 0.12224676460027695\n",
      "\n",
      "Val func train loss in epoch 14:0.1628179377876222\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1662350296974182\n",
      "\n",
      "episode 2, val func loss 0.12155807018280029\n",
      "\n",
      "episode 3, val func loss 0.23022665083408356\n",
      "\n",
      "episode 4, val func loss 0.1852256804704666\n",
      "\n",
      "episode 5, val func loss 0.18645530939102173\n",
      "\n",
      "episode 6, val func loss 0.18066808581352234\n",
      "\n",
      "episode 7, val func loss 0.1597534418106079\n",
      "\n",
      "episode 8, val func loss 0.11963608115911484\n",
      "\n",
      "episode 9, val func loss 0.18635596334934235\n",
      "\n",
      "episode 10, val func loss 0.17626115679740906\n",
      "\n",
      "episode 11, val func loss 0.13377699255943298\n",
      "\n",
      "episode 12, val func loss 0.19794803857803345\n",
      "\n",
      "episode 13, val func loss 0.10923323780298233\n",
      "\n",
      "episode 14, val func loss 0.16541464626789093\n",
      "\n",
      "episode 15, val func loss 0.137916699051857\n",
      "\n",
      "episode 16, val func loss 0.15109983086585999\n",
      "\n",
      "Val func train loss in epoch 15:0.16298530716449022\n",
      "***********************TIME WAS 4.896786125500997 min*****************************\n",
      "\n",
      "**********************ROUND 36 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.11756078898906708\n",
      "\n",
      "episode 2, policy loss -0.16851139068603516\n",
      "\n",
      "episode 3, policy loss -0.08658268302679062\n",
      "\n",
      "episode 4, policy loss -0.09420577436685562\n",
      "\n",
      "episode 5, policy loss -0.10734862089157104\n",
      "\n",
      "episode 6, policy loss -0.12060851603746414\n",
      "\n",
      "episode 7, policy loss -0.11092352867126465\n",
      "\n",
      "episode 8, policy loss -0.08856601268053055\n",
      "\n",
      "episode 9, policy loss -0.10270815342664719\n",
      "\n",
      "episode 10, policy loss -0.09612887352705002\n",
      "\n",
      "episode 11, policy loss -0.1389990746974945\n",
      "\n",
      "episode 12, policy loss -0.0861140638589859\n",
      "\n",
      "episode 13, policy loss -0.07758390158414841\n",
      "\n",
      "episode 14, policy loss -0.13917496800422668\n",
      "\n",
      "episode 15, policy loss -0.07688915729522705\n",
      "\n",
      "episode 16, policy loss -0.11879407614469528\n",
      "\n",
      "Policy train loss in epoch 0:-0.10816872399300337\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.1363726556301117\n",
      "\n",
      "episode 2, policy loss -0.09369979053735733\n",
      "\n",
      "episode 3, policy loss -0.07791652530431747\n",
      "\n",
      "episode 4, policy loss -0.12261870503425598\n",
      "\n",
      "episode 5, policy loss -0.1466318666934967\n",
      "\n",
      "episode 6, policy loss -0.09938371926546097\n",
      "\n",
      "episode 7, policy loss -0.07503396272659302\n",
      "\n",
      "episode 8, policy loss -0.08332282304763794\n",
      "\n",
      "episode 9, policy loss -0.0854235291481018\n",
      "\n",
      "episode 10, policy loss -0.09278631955385208\n",
      "\n",
      "episode 11, policy loss -0.1698630452156067\n",
      "\n",
      "episode 12, policy loss -0.12074826657772064\n",
      "\n",
      "episode 13, policy loss -0.11890673637390137\n",
      "\n",
      "episode 14, policy loss -0.11390931904315948\n",
      "\n",
      "episode 15, policy loss -0.08555793017148972\n",
      "\n",
      "episode 16, policy loss -0.10744966566562653\n",
      "\n",
      "Policy train loss in epoch 1:-0.10810155374929309\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.1720774918794632\n",
      "\n",
      "episode 2, policy loss -0.09620087593793869\n",
      "\n",
      "episode 3, policy loss -0.13602638244628906\n",
      "\n",
      "episode 4, policy loss -0.08561761677265167\n",
      "\n",
      "episode 5, policy loss -0.07696406543254852\n",
      "\n",
      "episode 6, policy loss -0.11564598977565765\n",
      "\n",
      "episode 7, policy loss -0.14428195357322693\n",
      "\n",
      "episode 8, policy loss -0.10211262106895447\n",
      "\n",
      "episode 9, policy loss -0.08660194277763367\n",
      "\n",
      "episode 10, policy loss -0.12048983573913574\n",
      "\n",
      "episode 11, policy loss -0.08807972073554993\n",
      "\n",
      "episode 12, policy loss -0.11050105839967728\n",
      "\n",
      "episode 13, policy loss -0.12169072031974792\n",
      "\n",
      "episode 14, policy loss -0.09504611790180206\n",
      "\n",
      "episode 15, policy loss -0.07852590084075928\n",
      "\n",
      "episode 16, policy loss -0.12126190960407257\n",
      "\n",
      "Policy train loss in epoch 2:-0.10944526270031929\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.10254179686307907\n",
      "\n",
      "episode 2, policy loss -0.11546413600444794\n",
      "\n",
      "episode 3, policy loss -0.16964483261108398\n",
      "\n",
      "episode 4, policy loss -0.11199283599853516\n",
      "\n",
      "episode 5, policy loss -0.08767669647932053\n",
      "\n",
      "episode 6, policy loss -0.07809314876794815\n",
      "\n",
      "episode 7, policy loss -0.1222110167145729\n",
      "\n",
      "episode 8, policy loss -0.09674236178398132\n",
      "\n",
      "episode 9, policy loss -0.07790976762771606\n",
      "\n",
      "episode 10, policy loss -0.12075656652450562\n",
      "\n",
      "episode 11, policy loss -0.14666008949279785\n",
      "\n",
      "episode 12, policy loss -0.0873628780245781\n",
      "\n",
      "episode 13, policy loss -0.0847930833697319\n",
      "\n",
      "episode 14, policy loss -0.09749393165111542\n",
      "\n",
      "episode 15, policy loss -0.138386532664299\n",
      "\n",
      "episode 16, policy loss -0.12250524759292603\n",
      "\n",
      "Policy train loss in epoch 3:-0.11001468263566494\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.12503904104232788\n",
      "\n",
      "episode 2, val func loss 0.18363036215305328\n",
      "\n",
      "episode 3, val func loss 0.15821810066699982\n",
      "\n",
      "episode 4, val func loss 0.1821422129869461\n",
      "\n",
      "episode 5, val func loss 0.1782522201538086\n",
      "\n",
      "episode 6, val func loss 0.17468442022800446\n",
      "\n",
      "episode 7, val func loss 0.19646093249320984\n",
      "\n",
      "episode 8, val func loss 0.1171007826924324\n",
      "\n",
      "episode 9, val func loss 0.1562785655260086\n",
      "\n",
      "episode 10, val func loss 0.17907072603702545\n",
      "\n",
      "episode 11, val func loss 0.22322729229927063\n",
      "\n",
      "episode 12, val func loss 0.16155332326889038\n",
      "\n",
      "episode 13, val func loss 0.14056305587291718\n",
      "\n",
      "episode 14, val func loss 0.18250975012779236\n",
      "\n",
      "episode 15, val func loss 0.14352166652679443\n",
      "\n",
      "episode 16, val func loss 0.17038552463054657\n",
      "\n",
      "Val func train loss in epoch 0:0.16703987354412675\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17020992934703827\n",
      "\n",
      "episode 2, val func loss 0.1433812826871872\n",
      "\n",
      "episode 3, val func loss 0.11832531541585922\n",
      "\n",
      "episode 4, val func loss 0.17642958462238312\n",
      "\n",
      "episode 5, val func loss 0.17673513293266296\n",
      "\n",
      "episode 6, val func loss 0.1831253319978714\n",
      "\n",
      "episode 7, val func loss 0.18325532972812653\n",
      "\n",
      "episode 8, val func loss 0.17858903110027313\n",
      "\n",
      "episode 9, val func loss 0.12496670335531235\n",
      "\n",
      "episode 10, val func loss 0.15559731423854828\n",
      "\n",
      "episode 11, val func loss 0.19635972380638123\n",
      "\n",
      "episode 12, val func loss 0.16225476562976837\n",
      "\n",
      "episode 13, val func loss 0.22271928191184998\n",
      "\n",
      "episode 14, val func loss 0.1853216588497162\n",
      "\n",
      "episode 15, val func loss 0.1559750735759735\n",
      "\n",
      "episode 16, val func loss 0.1401444673538208\n",
      "\n",
      "Val func train loss in epoch 1:0.16708687040954828\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.22540690004825592\n",
      "\n",
      "episode 2, val func loss 0.1769849956035614\n",
      "\n",
      "episode 3, val func loss 0.1836249977350235\n",
      "\n",
      "episode 4, val func loss 0.18280310928821564\n",
      "\n",
      "episode 5, val func loss 0.17055071890354156\n",
      "\n",
      "episode 6, val func loss 0.1180725246667862\n",
      "\n",
      "episode 7, val func loss 0.1747966706752777\n",
      "\n",
      "episode 8, val func loss 0.13917578756809235\n",
      "\n",
      "episode 9, val func loss 0.1608181893825531\n",
      "\n",
      "episode 10, val func loss 0.17864389717578888\n",
      "\n",
      "episode 11, val func loss 0.15522587299346924\n",
      "\n",
      "episode 12, val func loss 0.15621830523014069\n",
      "\n",
      "episode 13, val func loss 0.1442125141620636\n",
      "\n",
      "episode 14, val func loss 0.18299521505832672\n",
      "\n",
      "episode 15, val func loss 0.19634337723255157\n",
      "\n",
      "episode 16, val func loss 0.12510688602924347\n",
      "\n",
      "Val func train loss in epoch 2:0.16693624760955572\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.17405186593532562\n",
      "\n",
      "episode 2, val func loss 0.11693163961172104\n",
      "\n",
      "episode 3, val func loss 0.18300050497055054\n",
      "\n",
      "episode 4, val func loss 0.1440054029226303\n",
      "\n",
      "episode 5, val func loss 0.1780785471200943\n",
      "\n",
      "episode 6, val func loss 0.13943763077259064\n",
      "\n",
      "episode 7, val func loss 0.15979112684726715\n",
      "\n",
      "episode 8, val func loss 0.15591906011104584\n",
      "\n",
      "episode 9, val func loss 0.16113153100013733\n",
      "\n",
      "episode 10, val func loss 0.18554829061031342\n",
      "\n",
      "episode 11, val func loss 0.22771574556827545\n",
      "\n",
      "episode 12, val func loss 0.12522834539413452\n",
      "\n",
      "episode 13, val func loss 0.17900726199150085\n",
      "\n",
      "episode 14, val func loss 0.1971845030784607\n",
      "\n",
      "episode 15, val func loss 0.1850241869688034\n",
      "\n",
      "episode 16, val func loss 0.17085124552249908\n",
      "\n",
      "Val func train loss in epoch 3:0.1676816805265844\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1819600611925125\n",
      "\n",
      "episode 2, val func loss 0.1838403046131134\n",
      "\n",
      "episode 3, val func loss 0.1733265519142151\n",
      "\n",
      "episode 4, val func loss 0.2254878431558609\n",
      "\n",
      "episode 5, val func loss 0.12524938583374023\n",
      "\n",
      "episode 6, val func loss 0.17821931838989258\n",
      "\n",
      "episode 7, val func loss 0.17036403715610504\n",
      "\n",
      "episode 8, val func loss 0.15555529296398163\n",
      "\n",
      "episode 9, val func loss 0.16031163930892944\n",
      "\n",
      "episode 10, val func loss 0.18227581679821014\n",
      "\n",
      "episode 11, val func loss 0.11770428717136383\n",
      "\n",
      "episode 12, val func loss 0.182895228266716\n",
      "\n",
      "episode 13, val func loss 0.19624052941799164\n",
      "\n",
      "episode 14, val func loss 0.13894425332546234\n",
      "\n",
      "episode 15, val func loss 0.14346162974834442\n",
      "\n",
      "episode 16, val func loss 0.15721310675144196\n",
      "\n",
      "Val func train loss in epoch 4:0.16706558037549257\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.22523875534534454\n",
      "\n",
      "episode 2, val func loss 0.17872421443462372\n",
      "\n",
      "episode 3, val func loss 0.15513886511325836\n",
      "\n",
      "episode 4, val func loss 0.18213748931884766\n",
      "\n",
      "episode 5, val func loss 0.1475515216588974\n",
      "\n",
      "episode 6, val func loss 0.11646204441785812\n",
      "\n",
      "episode 7, val func loss 0.1967712938785553\n",
      "\n",
      "episode 8, val func loss 0.17988522350788116\n",
      "\n",
      "episode 9, val func loss 0.14049668610095978\n",
      "\n",
      "episode 10, val func loss 0.16000114381313324\n",
      "\n",
      "episode 11, val func loss 0.17181266844272614\n",
      "\n",
      "episode 12, val func loss 0.18244963884353638\n",
      "\n",
      "episode 13, val func loss 0.1264403611421585\n",
      "\n",
      "episode 14, val func loss 0.15674199163913727\n",
      "\n",
      "episode 15, val func loss 0.18377487361431122\n",
      "\n",
      "episode 16, val func loss 0.17599503695964813\n",
      "\n",
      "Val func train loss in epoch 5:0.1674763630144298\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18274454772472382\n",
      "\n",
      "episode 2, val func loss 0.19630134105682373\n",
      "\n",
      "episode 3, val func loss 0.14538054168224335\n",
      "\n",
      "episode 4, val func loss 0.15670807659626007\n",
      "\n",
      "episode 5, val func loss 0.17281021177768707\n",
      "\n",
      "episode 6, val func loss 0.18307945132255554\n",
      "\n",
      "episode 7, val func loss 0.11697039753198624\n",
      "\n",
      "episode 8, val func loss 0.14110837876796722\n",
      "\n",
      "episode 9, val func loss 0.17878231406211853\n",
      "\n",
      "episode 10, val func loss 0.12522579729557037\n",
      "\n",
      "episode 11, val func loss 0.18230925500392914\n",
      "\n",
      "episode 12, val func loss 0.1600705087184906\n",
      "\n",
      "episode 13, val func loss 0.1713581681251526\n",
      "\n",
      "episode 14, val func loss 0.15853695571422577\n",
      "\n",
      "episode 15, val func loss 0.22516076266765594\n",
      "\n",
      "episode 16, val func loss 0.1792249232530594\n",
      "\n",
      "Val func train loss in epoch 6:0.16723572695627809\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.182147815823555\n",
      "\n",
      "episode 2, val func loss 0.18549923598766327\n",
      "\n",
      "episode 3, val func loss 0.1260022521018982\n",
      "\n",
      "episode 4, val func loss 0.11708071082830429\n",
      "\n",
      "episode 5, val func loss 0.18310795724391937\n",
      "\n",
      "episode 6, val func loss 0.15552248060703278\n",
      "\n",
      "episode 7, val func loss 0.22642961144447327\n",
      "\n",
      "episode 8, val func loss 0.144464373588562\n",
      "\n",
      "episode 9, val func loss 0.17921209335327148\n",
      "\n",
      "episode 10, val func loss 0.1401147097349167\n",
      "\n",
      "episode 11, val func loss 0.19697409868240356\n",
      "\n",
      "episode 12, val func loss 0.160017192363739\n",
      "\n",
      "episode 13, val func loss 0.16087119281291962\n",
      "\n",
      "episode 14, val func loss 0.17517371475696564\n",
      "\n",
      "episode 15, val func loss 0.1696126013994217\n",
      "\n",
      "episode 16, val func loss 0.1788235753774643\n",
      "\n",
      "Val func train loss in epoch 7:0.16756585100665689\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17238831520080566\n",
      "\n",
      "episode 2, val func loss 0.141547292470932\n",
      "\n",
      "episode 3, val func loss 0.1833767294883728\n",
      "\n",
      "episode 4, val func loss 0.19610343873500824\n",
      "\n",
      "episode 5, val func loss 0.17749646306037903\n",
      "\n",
      "episode 6, val func loss 0.12600839138031006\n",
      "\n",
      "episode 7, val func loss 0.23087191581726074\n",
      "\n",
      "episode 8, val func loss 0.17829810082912445\n",
      "\n",
      "episode 9, val func loss 0.18313002586364746\n",
      "\n",
      "episode 10, val func loss 0.15525676310062408\n",
      "\n",
      "episode 11, val func loss 0.17100602388381958\n",
      "\n",
      "episode 12, val func loss 0.16347342729568481\n",
      "\n",
      "episode 13, val func loss 0.14677132666110992\n",
      "\n",
      "episode 14, val func loss 0.18376381695270538\n",
      "\n",
      "episode 15, val func loss 0.11796547472476959\n",
      "\n",
      "episode 16, val func loss 0.1554541438817978\n",
      "\n",
      "Val func train loss in epoch 8:0.16768197808414698\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.14226345717906952\n",
      "\n",
      "episode 2, val func loss 0.1975603550672531\n",
      "\n",
      "episode 3, val func loss 0.13783085346221924\n",
      "\n",
      "episode 4, val func loss 0.18430162966251373\n",
      "\n",
      "episode 5, val func loss 0.2277349829673767\n",
      "\n",
      "episode 6, val func loss 0.12560446560382843\n",
      "\n",
      "episode 7, val func loss 0.15583078563213348\n",
      "\n",
      "episode 8, val func loss 0.18513652682304382\n",
      "\n",
      "episode 9, val func loss 0.11673858761787415\n",
      "\n",
      "episode 10, val func loss 0.18065933883190155\n",
      "\n",
      "episode 11, val func loss 0.18383362889289856\n",
      "\n",
      "episode 12, val func loss 0.1723238080739975\n",
      "\n",
      "episode 13, val func loss 0.1701650321483612\n",
      "\n",
      "episode 14, val func loss 0.16144408285617828\n",
      "\n",
      "episode 15, val func loss 0.1554005891084671\n",
      "\n",
      "episode 16, val func loss 0.17685110867023468\n",
      "\n",
      "Val func train loss in epoch 9:0.16710495203733444\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.23391897976398468\n",
      "\n",
      "episode 2, val func loss 0.15934132039546967\n",
      "\n",
      "episode 3, val func loss 0.18231342732906342\n",
      "\n",
      "episode 4, val func loss 0.19626134634017944\n",
      "\n",
      "episode 5, val func loss 0.1575244665145874\n",
      "\n",
      "episode 6, val func loss 0.14341574907302856\n",
      "\n",
      "episode 7, val func loss 0.17950570583343506\n",
      "\n",
      "episode 8, val func loss 0.14364953339099884\n",
      "\n",
      "episode 9, val func loss 0.17238792777061462\n",
      "\n",
      "episode 10, val func loss 0.17653831839561462\n",
      "\n",
      "episode 11, val func loss 0.1823253184556961\n",
      "\n",
      "episode 12, val func loss 0.11826207488775253\n",
      "\n",
      "episode 13, val func loss 0.1601259857416153\n",
      "\n",
      "episode 14, val func loss 0.18283860385417938\n",
      "\n",
      "episode 15, val func loss 0.12499286234378815\n",
      "\n",
      "episode 16, val func loss 0.17372852563858032\n",
      "\n",
      "Val func train loss in epoch 10:0.16794563410803676\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.15545013546943665\n",
      "\n",
      "episode 2, val func loss 0.1393786370754242\n",
      "\n",
      "episode 3, val func loss 0.18279239535331726\n",
      "\n",
      "episode 4, val func loss 0.1786172091960907\n",
      "\n",
      "episode 5, val func loss 0.1779886931180954\n",
      "\n",
      "episode 6, val func loss 0.15883144736289978\n",
      "\n",
      "episode 7, val func loss 0.17450834810733795\n",
      "\n",
      "episode 8, val func loss 0.22492623329162598\n",
      "\n",
      "episode 9, val func loss 0.1166834831237793\n",
      "\n",
      "episode 10, val func loss 0.19680114090442657\n",
      "\n",
      "episode 11, val func loss 0.17045409977436066\n",
      "\n",
      "episode 12, val func loss 0.1477012187242508\n",
      "\n",
      "episode 13, val func loss 0.18384885787963867\n",
      "\n",
      "episode 14, val func loss 0.16079679131507874\n",
      "\n",
      "episode 15, val func loss 0.18233181536197662\n",
      "\n",
      "episode 16, val func loss 0.1272350251674652\n",
      "\n",
      "Val func train loss in epoch 11:0.16739659570157528\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18537458777427673\n",
      "\n",
      "episode 2, val func loss 0.1716299057006836\n",
      "\n",
      "episode 3, val func loss 0.18291516602039337\n",
      "\n",
      "episode 4, val func loss 0.17288227379322052\n",
      "\n",
      "episode 5, val func loss 0.14488829672336578\n",
      "\n",
      "episode 6, val func loss 0.1969316005706787\n",
      "\n",
      "episode 7, val func loss 0.18396848440170288\n",
      "\n",
      "episode 8, val func loss 0.22390924394130707\n",
      "\n",
      "episode 9, val func loss 0.12502720952033997\n",
      "\n",
      "episode 10, val func loss 0.1556200236082077\n",
      "\n",
      "episode 11, val func loss 0.11723947525024414\n",
      "\n",
      "episode 12, val func loss 0.1805250644683838\n",
      "\n",
      "episode 13, val func loss 0.1622881144285202\n",
      "\n",
      "episode 14, val func loss 0.17886634171009064\n",
      "\n",
      "episode 15, val func loss 0.138461634516716\n",
      "\n",
      "episode 16, val func loss 0.15780998766422272\n",
      "\n",
      "Val func train loss in epoch 12:0.1673960881307721\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18297505378723145\n",
      "\n",
      "episode 2, val func loss 0.19771160185337067\n",
      "\n",
      "episode 3, val func loss 0.1389617621898651\n",
      "\n",
      "episode 4, val func loss 0.17704375088214874\n",
      "\n",
      "episode 5, val func loss 0.18345102667808533\n",
      "\n",
      "episode 6, val func loss 0.14298073947429657\n",
      "\n",
      "episode 7, val func loss 0.12492410093545914\n",
      "\n",
      "episode 8, val func loss 0.1780828833580017\n",
      "\n",
      "episode 9, val func loss 0.11780271679162979\n",
      "\n",
      "episode 10, val func loss 0.1744534969329834\n",
      "\n",
      "episode 11, val func loss 0.16087982058525085\n",
      "\n",
      "episode 12, val func loss 0.1695692390203476\n",
      "\n",
      "episode 13, val func loss 0.22363662719726562\n",
      "\n",
      "episode 14, val func loss 0.15516889095306396\n",
      "\n",
      "episode 15, val func loss 0.18277454376220703\n",
      "\n",
      "episode 16, val func loss 0.15850600600242615\n",
      "\n",
      "Val func train loss in epoch 13:0.16680764127522707\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18525929749011993\n",
      "\n",
      "episode 2, val func loss 0.2221079170703888\n",
      "\n",
      "episode 3, val func loss 0.11673863977193832\n",
      "\n",
      "episode 4, val func loss 0.18454261124134064\n",
      "\n",
      "episode 5, val func loss 0.19634604454040527\n",
      "\n",
      "episode 6, val func loss 0.17825201153755188\n",
      "\n",
      "episode 7, val func loss 0.18344633281230927\n",
      "\n",
      "episode 8, val func loss 0.1252593845129013\n",
      "\n",
      "episode 9, val func loss 0.1699443757534027\n",
      "\n",
      "episode 10, val func loss 0.15501582622528076\n",
      "\n",
      "episode 11, val func loss 0.15703193843364716\n",
      "\n",
      "episode 12, val func loss 0.17809005081653595\n",
      "\n",
      "episode 13, val func loss 0.14444500207901\n",
      "\n",
      "episode 14, val func loss 0.16026976704597473\n",
      "\n",
      "episode 15, val func loss 0.1391691118478775\n",
      "\n",
      "episode 16, val func loss 0.17553570866584778\n",
      "\n",
      "Val func train loss in epoch 14:0.16696587624028325\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.11834186315536499\n",
      "\n",
      "episode 2, val func loss 0.1831154227256775\n",
      "\n",
      "episode 3, val func loss 0.1828942894935608\n",
      "\n",
      "episode 4, val func loss 0.17763876914978027\n",
      "\n",
      "episode 5, val func loss 0.19646674394607544\n",
      "\n",
      "episode 6, val func loss 0.17022903263568878\n",
      "\n",
      "episode 7, val func loss 0.17839393019676208\n",
      "\n",
      "episode 8, val func loss 0.18300947546958923\n",
      "\n",
      "episode 9, val func loss 0.1393352448940277\n",
      "\n",
      "episode 10, val func loss 0.17585498094558716\n",
      "\n",
      "episode 11, val func loss 0.14242470264434814\n",
      "\n",
      "episode 12, val func loss 0.2282918095588684\n",
      "\n",
      "episode 13, val func loss 0.1246270015835762\n",
      "\n",
      "episode 14, val func loss 0.15607692301273346\n",
      "\n",
      "episode 15, val func loss 0.16202813386917114\n",
      "\n",
      "episode 16, val func loss 0.1566653698682785\n",
      "\n",
      "Val func train loss in epoch 15:0.1672121058218181\n",
      "***********************TIME WAS 4.8978614966074625 min*****************************\n",
      "\n",
      "**********************ROUND 37 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.05321325361728668\n",
      "\n",
      "episode 2, policy loss -0.0996282547712326\n",
      "\n",
      "episode 3, policy loss -0.14123645424842834\n",
      "\n",
      "episode 4, policy loss -0.0635947659611702\n",
      "\n",
      "episode 5, policy loss -0.06912928819656372\n",
      "\n",
      "episode 6, policy loss -0.12357904016971588\n",
      "\n",
      "episode 7, policy loss -0.14365020394325256\n",
      "\n",
      "episode 8, policy loss -0.11282661557197571\n",
      "\n",
      "episode 9, policy loss -0.07250489294528961\n",
      "\n",
      "episode 10, policy loss -0.06178596243262291\n",
      "\n",
      "episode 11, policy loss -0.02246808633208275\n",
      "\n",
      "episode 12, policy loss -0.09795266389846802\n",
      "\n",
      "episode 13, policy loss -0.08914517611265182\n",
      "\n",
      "episode 14, policy loss -0.08484219759702682\n",
      "\n",
      "episode 15, policy loss -0.0895383432507515\n",
      "\n",
      "episode 16, policy loss -0.10224556177854538\n",
      "\n",
      "Policy train loss in epoch 0:-0.08920879755169153\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.10142915695905685\n",
      "\n",
      "episode 2, policy loss -0.1222369521856308\n",
      "\n",
      "episode 3, policy loss -0.14128001034259796\n",
      "\n",
      "episode 4, policy loss -0.09249621629714966\n",
      "\n",
      "episode 5, policy loss -0.07547874003648758\n",
      "\n",
      "episode 6, policy loss -0.08795522898435593\n",
      "\n",
      "episode 7, policy loss -0.061634741723537445\n",
      "\n",
      "episode 8, policy loss -0.07275357842445374\n",
      "\n",
      "episode 9, policy loss -0.08941593021154404\n",
      "\n",
      "episode 10, policy loss -0.11310441792011261\n",
      "\n",
      "episode 11, policy loss -0.14378775656223297\n",
      "\n",
      "episode 12, policy loss -0.05771767348051071\n",
      "\n",
      "episode 13, policy loss -0.06677540391683578\n",
      "\n",
      "episode 14, policy loss -0.09884460270404816\n",
      "\n",
      "episode 15, policy loss -0.021593529731035233\n",
      "\n",
      "episode 16, policy loss -0.10336753726005554\n",
      "\n",
      "Policy train loss in epoch 1:-0.09061696729622781\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.09265760332345963\n",
      "\n",
      "episode 2, policy loss -0.05825551226735115\n",
      "\n",
      "episode 3, policy loss -0.07494115829467773\n",
      "\n",
      "episode 4, policy loss -0.06868073344230652\n",
      "\n",
      "episode 5, policy loss -0.12319524586200714\n",
      "\n",
      "episode 6, policy loss -0.1039615347981453\n",
      "\n",
      "episode 7, policy loss -0.146484836935997\n",
      "\n",
      "episode 8, policy loss -0.10093589127063751\n",
      "\n",
      "episode 9, policy loss -0.1155824065208435\n",
      "\n",
      "episode 10, policy loss -0.022363081574440002\n",
      "\n",
      "episode 11, policy loss -0.09996689856052399\n",
      "\n",
      "episode 12, policy loss -0.06247992441058159\n",
      "\n",
      "episode 13, policy loss -0.09263493865728378\n",
      "\n",
      "episode 14, policy loss -0.08721653372049332\n",
      "\n",
      "episode 15, policy loss -0.14095038175582886\n",
      "\n",
      "episode 16, policy loss -0.07057755440473557\n",
      "\n",
      "Policy train loss in epoch 2:-0.09130526473745704\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.1064499020576477\n",
      "\n",
      "episode 2, policy loss -0.056387271732091904\n",
      "\n",
      "episode 3, policy loss -0.1456560492515564\n",
      "\n",
      "episode 4, policy loss -0.1143966093659401\n",
      "\n",
      "episode 5, policy loss -0.09111558645963669\n",
      "\n",
      "episode 6, policy loss -0.10271082818508148\n",
      "\n",
      "episode 7, policy loss -0.14170272648334503\n",
      "\n",
      "episode 8, policy loss -0.07189685106277466\n",
      "\n",
      "episode 9, policy loss -0.12268790602684021\n",
      "\n",
      "episode 10, policy loss -0.09197667241096497\n",
      "\n",
      "episode 11, policy loss -0.09535855054855347\n",
      "\n",
      "episode 12, policy loss -0.021793395280838013\n",
      "\n",
      "episode 13, policy loss -0.07511105388402939\n",
      "\n",
      "episode 14, policy loss -0.08770100027322769\n",
      "\n",
      "episode 15, policy loss -0.061402738094329834\n",
      "\n",
      "episode 16, policy loss -0.06518072634935379\n",
      "\n",
      "Policy train loss in epoch 3:-0.09072049171663821\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17766965925693512\n",
      "\n",
      "episode 2, val func loss 0.18658103048801422\n",
      "\n",
      "episode 3, val func loss 0.19140517711639404\n",
      "\n",
      "episode 4, val func loss 0.16587932407855988\n",
      "\n",
      "episode 5, val func loss 0.15991854667663574\n",
      "\n",
      "episode 6, val func loss 0.17469251155853271\n",
      "\n",
      "episode 7, val func loss 0.1844351589679718\n",
      "\n",
      "episode 8, val func loss 0.1728537231683731\n",
      "\n",
      "episode 9, val func loss 0.1966671347618103\n",
      "\n",
      "episode 10, val func loss 0.15590618550777435\n",
      "\n",
      "episode 11, val func loss 0.1459999978542328\n",
      "\n",
      "episode 12, val func loss 0.16843539476394653\n",
      "\n",
      "episode 13, val func loss 0.13987313210964203\n",
      "\n",
      "episode 14, val func loss 0.22195258736610413\n",
      "\n",
      "episode 15, val func loss 0.14864641427993774\n",
      "\n",
      "episode 16, val func loss 0.17653383314609528\n",
      "\n",
      "Val func train loss in epoch 0:0.17296561319380999\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17704269289970398\n",
      "\n",
      "episode 2, val func loss 0.1670050173997879\n",
      "\n",
      "episode 3, val func loss 0.1820138841867447\n",
      "\n",
      "episode 4, val func loss 0.22159314155578613\n",
      "\n",
      "episode 5, val func loss 0.15956346690654755\n",
      "\n",
      "episode 6, val func loss 0.17733821272850037\n",
      "\n",
      "episode 7, val func loss 0.16101697087287903\n",
      "\n",
      "episode 8, val func loss 0.19241681694984436\n",
      "\n",
      "episode 9, val func loss 0.1690789759159088\n",
      "\n",
      "episode 10, val func loss 0.17396019399166107\n",
      "\n",
      "episode 11, val func loss 0.13986626267433167\n",
      "\n",
      "episode 12, val func loss 0.19855229556560516\n",
      "\n",
      "episode 13, val func loss 0.14514683187007904\n",
      "\n",
      "episode 14, val func loss 0.15035955607891083\n",
      "\n",
      "episode 15, val func loss 0.17123903334140778\n",
      "\n",
      "episode 16, val func loss 0.1864757537841797\n",
      "\n",
      "Val func train loss in epoch 1:0.17329181917011738\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17797346413135529\n",
      "\n",
      "episode 2, val func loss 0.14699749648571014\n",
      "\n",
      "episode 3, val func loss 0.14030598104000092\n",
      "\n",
      "episode 4, val func loss 0.15743136405944824\n",
      "\n",
      "episode 5, val func loss 0.22285978496074677\n",
      "\n",
      "episode 6, val func loss 0.14842696487903595\n",
      "\n",
      "episode 7, val func loss 0.17494794726371765\n",
      "\n",
      "episode 8, val func loss 0.165008544921875\n",
      "\n",
      "episode 9, val func loss 0.18573085963726044\n",
      "\n",
      "episode 10, val func loss 0.17809569835662842\n",
      "\n",
      "episode 11, val func loss 0.17180244624614716\n",
      "\n",
      "episode 12, val func loss 0.194645494222641\n",
      "\n",
      "episode 13, val func loss 0.16853173077106476\n",
      "\n",
      "episode 14, val func loss 0.16110825538635254\n",
      "\n",
      "episode 15, val func loss 0.1917908787727356\n",
      "\n",
      "episode 16, val func loss 0.1824726015329361\n",
      "\n",
      "Val func train loss in epoch 2:0.1730080945417285\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1874426156282425\n",
      "\n",
      "episode 2, val func loss 0.1701393723487854\n",
      "\n",
      "episode 3, val func loss 0.22114378213882446\n",
      "\n",
      "episode 4, val func loss 0.1484650820493698\n",
      "\n",
      "episode 5, val func loss 0.15924113988876343\n",
      "\n",
      "episode 6, val func loss 0.177850142121315\n",
      "\n",
      "episode 7, val func loss 0.13981083035469055\n",
      "\n",
      "episode 8, val func loss 0.17745041847229004\n",
      "\n",
      "episode 9, val func loss 0.16824156045913696\n",
      "\n",
      "episode 10, val func loss 0.14479202032089233\n",
      "\n",
      "episode 11, val func loss 0.1849614530801773\n",
      "\n",
      "episode 12, val func loss 0.17436517775058746\n",
      "\n",
      "episode 13, val func loss 0.19672690331935883\n",
      "\n",
      "episode 14, val func loss 0.15976880490779877\n",
      "\n",
      "episode 15, val func loss 0.1647900491952896\n",
      "\n",
      "episode 16, val func loss 0.19195932149887085\n",
      "\n",
      "Val func train loss in epoch 3:0.17294679209589958\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1409255415201187\n",
      "\n",
      "episode 2, val func loss 0.22211726009845734\n",
      "\n",
      "episode 3, val func loss 0.17732834815979004\n",
      "\n",
      "episode 4, val func loss 0.17662310600280762\n",
      "\n",
      "episode 5, val func loss 0.14815451204776764\n",
      "\n",
      "episode 6, val func loss 0.1591171771287918\n",
      "\n",
      "episode 7, val func loss 0.1467532068490982\n",
      "\n",
      "episode 8, val func loss 0.19360780715942383\n",
      "\n",
      "episode 9, val func loss 0.1715899258852005\n",
      "\n",
      "episode 10, val func loss 0.1915307641029358\n",
      "\n",
      "episode 11, val func loss 0.16088652610778809\n",
      "\n",
      "episode 12, val func loss 0.16819939017295837\n",
      "\n",
      "episode 13, val func loss 0.1862216293811798\n",
      "\n",
      "episode 14, val func loss 0.17762044072151184\n",
      "\n",
      "episode 15, val func loss 0.18345870077610016\n",
      "\n",
      "episode 16, val func loss 0.16527345776557922\n",
      "\n",
      "Val func train loss in epoch 4:0.1730879871174693\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1941445916891098\n",
      "\n",
      "episode 2, val func loss 0.1747635304927826\n",
      "\n",
      "episode 3, val func loss 0.1699095517396927\n",
      "\n",
      "episode 4, val func loss 0.1654338389635086\n",
      "\n",
      "episode 5, val func loss 0.1688847690820694\n",
      "\n",
      "episode 6, val func loss 0.1767057329416275\n",
      "\n",
      "episode 7, val func loss 0.22195249795913696\n",
      "\n",
      "episode 8, val func loss 0.17734551429748535\n",
      "\n",
      "episode 9, val func loss 0.1586235910654068\n",
      "\n",
      "episode 10, val func loss 0.19127382338047028\n",
      "\n",
      "episode 11, val func loss 0.16041409969329834\n",
      "\n",
      "episode 12, val func loss 0.14587511122226715\n",
      "\n",
      "episode 13, val func loss 0.15004707872867584\n",
      "\n",
      "episode 14, val func loss 0.18455229699611664\n",
      "\n",
      "episode 15, val func loss 0.18568557500839233\n",
      "\n",
      "episode 16, val func loss 0.13982918858528137\n",
      "\n",
      "Val func train loss in epoch 5:0.1728400494903326\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1719711571931839\n",
      "\n",
      "episode 2, val func loss 0.17736588418483734\n",
      "\n",
      "episode 3, val func loss 0.19188182055950165\n",
      "\n",
      "episode 4, val func loss 0.18617667257785797\n",
      "\n",
      "episode 5, val func loss 0.19269196689128876\n",
      "\n",
      "episode 6, val func loss 0.16652968525886536\n",
      "\n",
      "episode 7, val func loss 0.22104187309741974\n",
      "\n",
      "episode 8, val func loss 0.14859622716903687\n",
      "\n",
      "episode 9, val func loss 0.14804880321025848\n",
      "\n",
      "episode 10, val func loss 0.17615841329097748\n",
      "\n",
      "episode 11, val func loss 0.14152799546718597\n",
      "\n",
      "episode 12, val func loss 0.15790672600269318\n",
      "\n",
      "episode 13, val func loss 0.17485083639621735\n",
      "\n",
      "episode 14, val func loss 0.1599445790052414\n",
      "\n",
      "episode 15, val func loss 0.16980969905853271\n",
      "\n",
      "episode 16, val func loss 0.18784411251544952\n",
      "\n",
      "Val func train loss in epoch 6:0.17327165324240923\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17536383867263794\n",
      "\n",
      "episode 2, val func loss 0.1953398734331131\n",
      "\n",
      "episode 3, val func loss 0.16474199295043945\n",
      "\n",
      "episode 4, val func loss 0.1780780553817749\n",
      "\n",
      "episode 5, val func loss 0.14874909818172455\n",
      "\n",
      "episode 6, val func loss 0.1496524214744568\n",
      "\n",
      "episode 7, val func loss 0.16450917720794678\n",
      "\n",
      "episode 8, val func loss 0.16057968139648438\n",
      "\n",
      "episode 9, val func loss 0.1770946979522705\n",
      "\n",
      "episode 10, val func loss 0.16771982610225677\n",
      "\n",
      "episode 11, val func loss 0.18577447533607483\n",
      "\n",
      "episode 12, val func loss 0.13918611407279968\n",
      "\n",
      "episode 13, val func loss 0.19861793518066406\n",
      "\n",
      "episode 14, val func loss 0.1747967153787613\n",
      "\n",
      "episode 15, val func loss 0.22475828230381012\n",
      "\n",
      "episode 16, val func loss 0.18208612501621246\n",
      "\n",
      "Val func train loss in epoch 7:0.17419051937758923\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17318376898765564\n",
      "\n",
      "episode 2, val func loss 0.16532117128372192\n",
      "\n",
      "episode 3, val func loss 0.1921202689409256\n",
      "\n",
      "episode 4, val func loss 0.223650723695755\n",
      "\n",
      "episode 5, val func loss 0.14553454518318176\n",
      "\n",
      "episode 6, val func loss 0.15512271225452423\n",
      "\n",
      "episode 7, val func loss 0.1496211588382721\n",
      "\n",
      "episode 8, val func loss 0.13937672972679138\n",
      "\n",
      "episode 9, val func loss 0.18360617756843567\n",
      "\n",
      "episode 10, val func loss 0.18554463982582092\n",
      "\n",
      "episode 11, val func loss 0.17785616219043732\n",
      "\n",
      "episode 12, val func loss 0.17729966342449188\n",
      "\n",
      "episode 13, val func loss 0.17599016427993774\n",
      "\n",
      "episode 14, val func loss 0.192236989736557\n",
      "\n",
      "episode 15, val func loss 0.17050164937973022\n",
      "\n",
      "episode 16, val func loss 0.16666676104068756\n",
      "\n",
      "Val func train loss in epoch 8:0.17335208039730787\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17703300714492798\n",
      "\n",
      "episode 2, val func loss 0.14607009291648865\n",
      "\n",
      "episode 3, val func loss 0.15600278973579407\n",
      "\n",
      "episode 4, val func loss 0.1774800568819046\n",
      "\n",
      "episode 5, val func loss 0.19681282341480255\n",
      "\n",
      "episode 6, val func loss 0.13985081017017365\n",
      "\n",
      "episode 7, val func loss 0.22611472010612488\n",
      "\n",
      "episode 8, val func loss 0.17155620455741882\n",
      "\n",
      "episode 9, val func loss 0.16943958401679993\n",
      "\n",
      "episode 10, val func loss 0.1917872279882431\n",
      "\n",
      "episode 11, val func loss 0.18830431997776031\n",
      "\n",
      "episode 12, val func loss 0.17688807845115662\n",
      "\n",
      "episode 13, val func loss 0.1823044866323471\n",
      "\n",
      "episode 14, val func loss 0.16202686727046967\n",
      "\n",
      "episode 15, val func loss 0.14815565943717957\n",
      "\n",
      "episode 16, val func loss 0.1657547950744629\n",
      "\n",
      "Val func train loss in epoch 9:0.1734738452360034\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.14009860157966614\n",
      "\n",
      "episode 2, val func loss 0.1947697252035141\n",
      "\n",
      "episode 3, val func loss 0.14526335895061493\n",
      "\n",
      "episode 4, val func loss 0.14895020425319672\n",
      "\n",
      "episode 5, val func loss 0.1776188164949417\n",
      "\n",
      "episode 6, val func loss 0.18572424352169037\n",
      "\n",
      "episode 7, val func loss 0.1686387062072754\n",
      "\n",
      "episode 8, val func loss 0.19192616641521454\n",
      "\n",
      "episode 9, val func loss 0.17725248634815216\n",
      "\n",
      "episode 10, val func loss 0.2224707156419754\n",
      "\n",
      "episode 11, val func loss 0.15848970413208008\n",
      "\n",
      "episode 12, val func loss 0.16081690788269043\n",
      "\n",
      "episode 13, val func loss 0.17044484615325928\n",
      "\n",
      "episode 14, val func loss 0.16516034305095673\n",
      "\n",
      "episode 15, val func loss 0.17479391396045685\n",
      "\n",
      "episode 16, val func loss 0.18303543329238892\n",
      "\n",
      "Val func train loss in epoch 10:0.1728408858180046\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1778479665517807\n",
      "\n",
      "episode 2, val func loss 0.14985181391239166\n",
      "\n",
      "episode 3, val func loss 0.19412554800510406\n",
      "\n",
      "episode 4, val func loss 0.15731729567050934\n",
      "\n",
      "episode 5, val func loss 0.1915668249130249\n",
      "\n",
      "episode 6, val func loss 0.18696045875549316\n",
      "\n",
      "episode 7, val func loss 0.17082346975803375\n",
      "\n",
      "episode 8, val func loss 0.1612578183412552\n",
      "\n",
      "episode 9, val func loss 0.16849510371685028\n",
      "\n",
      "episode 10, val func loss 0.1827506572008133\n",
      "\n",
      "episode 11, val func loss 0.1777893602848053\n",
      "\n",
      "episode 12, val func loss 0.17479370534420013\n",
      "\n",
      "episode 13, val func loss 0.1455426812171936\n",
      "\n",
      "episode 14, val func loss 0.16453076899051666\n",
      "\n",
      "episode 15, val func loss 0.2259923666715622\n",
      "\n",
      "episode 16, val func loss 0.14001362025737762\n",
      "\n",
      "Val func train loss in epoch 11:0.173103716224432\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17447371780872345\n",
      "\n",
      "episode 2, val func loss 0.17745690047740936\n",
      "\n",
      "episode 3, val func loss 0.16546371579170227\n",
      "\n",
      "episode 4, val func loss 0.1776622086763382\n",
      "\n",
      "episode 5, val func loss 0.18204951286315918\n",
      "\n",
      "episode 6, val func loss 0.14860667288303375\n",
      "\n",
      "episode 7, val func loss 0.2213219553232193\n",
      "\n",
      "episode 8, val func loss 0.1916184425354004\n",
      "\n",
      "episode 9, val func loss 0.1700284779071808\n",
      "\n",
      "episode 10, val func loss 0.14177069067955017\n",
      "\n",
      "episode 11, val func loss 0.14830288290977478\n",
      "\n",
      "episode 12, val func loss 0.15811128914356232\n",
      "\n",
      "episode 13, val func loss 0.18638905882835388\n",
      "\n",
      "episode 14, val func loss 0.19746708869934082\n",
      "\n",
      "episode 15, val func loss 0.1598915308713913\n",
      "\n",
      "episode 16, val func loss 0.17348536849021912\n",
      "\n",
      "Val func train loss in epoch 12:0.17338121961802244\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.14528585970401764\n",
      "\n",
      "episode 2, val func loss 0.1542484313249588\n",
      "\n",
      "episode 3, val func loss 0.1939174383878708\n",
      "\n",
      "episode 4, val func loss 0.1740650087594986\n",
      "\n",
      "episode 5, val func loss 0.1688266545534134\n",
      "\n",
      "episode 6, val func loss 0.15980321168899536\n",
      "\n",
      "episode 7, val func loss 0.1496906280517578\n",
      "\n",
      "episode 8, val func loss 0.22285529971122742\n",
      "\n",
      "episode 9, val func loss 0.1768498420715332\n",
      "\n",
      "episode 10, val func loss 0.1904679834842682\n",
      "\n",
      "episode 11, val func loss 0.18093432486057281\n",
      "\n",
      "episode 12, val func loss 0.1712765395641327\n",
      "\n",
      "episode 13, val func loss 0.1426294445991516\n",
      "\n",
      "episode 14, val func loss 0.18809916079044342\n",
      "\n",
      "episode 15, val func loss 0.17113184928894043\n",
      "\n",
      "episode 16, val func loss 0.18363706767559052\n",
      "\n",
      "Val func train loss in epoch 13:0.1733574215322733\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.16836564242839813\n",
      "\n",
      "episode 2, val func loss 0.17444556951522827\n",
      "\n",
      "episode 3, val func loss 0.17846551537513733\n",
      "\n",
      "episode 4, val func loss 0.17214317619800568\n",
      "\n",
      "episode 5, val func loss 0.19201384484767914\n",
      "\n",
      "episode 6, val func loss 0.18868765234947205\n",
      "\n",
      "episode 7, val func loss 0.14009545743465424\n",
      "\n",
      "episode 8, val func loss 0.19398488104343414\n",
      "\n",
      "episode 9, val func loss 0.14857275784015656\n",
      "\n",
      "episode 10, val func loss 0.18235959112644196\n",
      "\n",
      "episode 11, val func loss 0.14773163199424744\n",
      "\n",
      "episode 12, val func loss 0.1584954708814621\n",
      "\n",
      "episode 13, val func loss 0.16048641502857208\n",
      "\n",
      "episode 14, val func loss 0.16492696106433868\n",
      "\n",
      "episode 15, val func loss 0.1782456338405609\n",
      "\n",
      "episode 16, val func loss 0.22792528569698334\n",
      "\n",
      "Val func train loss in epoch 14:0.17355909291654825\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1444253921508789\n",
      "\n",
      "episode 2, val func loss 0.1590915322303772\n",
      "\n",
      "episode 3, val func loss 0.22383704781532288\n",
      "\n",
      "episode 4, val func loss 0.17568866908550262\n",
      "\n",
      "episode 5, val func loss 0.19184286892414093\n",
      "\n",
      "episode 6, val func loss 0.17057445645332336\n",
      "\n",
      "episode 7, val func loss 0.18727396428585052\n",
      "\n",
      "episode 8, val func loss 0.16853976249694824\n",
      "\n",
      "episode 9, val func loss 0.1482531875371933\n",
      "\n",
      "episode 10, val func loss 0.1823919117450714\n",
      "\n",
      "episode 11, val func loss 0.19327570497989655\n",
      "\n",
      "episode 12, val func loss 0.14078067243099213\n",
      "\n",
      "episode 13, val func loss 0.16605153679847717\n",
      "\n",
      "episode 14, val func loss 0.17675615847110748\n",
      "\n",
      "episode 15, val func loss 0.15774548053741455\n",
      "\n",
      "episode 16, val func loss 0.177645742893219\n",
      "\n",
      "Val func train loss in epoch 15:0.17276088055223227\n",
      "***********************TIME WAS 4.899080574512482 min*****************************\n",
      "\n",
      "**********************ROUND 38 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.132285013794899\n",
      "\n",
      "episode 2, policy loss -0.06747113168239594\n",
      "\n",
      "episode 3, policy loss -0.09876775741577148\n",
      "\n",
      "episode 4, policy loss -0.07003973424434662\n",
      "\n",
      "episode 5, policy loss -0.11230561882257462\n",
      "\n",
      "episode 6, policy loss -0.056980498135089874\n",
      "\n",
      "episode 7, policy loss -0.11211793124675751\n",
      "\n",
      "episode 8, policy loss -0.10953279584646225\n",
      "\n",
      "episode 9, policy loss -0.09119531512260437\n",
      "\n",
      "episode 10, policy loss -0.06073593720793724\n",
      "\n",
      "episode 11, policy loss -0.080884650349617\n",
      "\n",
      "episode 12, policy loss -0.14633679389953613\n",
      "\n",
      "episode 13, policy loss -0.14436599612236023\n",
      "\n",
      "episode 14, policy loss -0.1250605285167694\n",
      "\n",
      "episode 15, policy loss -0.13700971007347107\n",
      "\n",
      "episode 16, policy loss -0.14388839900493622\n",
      "\n",
      "Policy train loss in epoch 0:-0.10556111321784556\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.0610516220331192\n",
      "\n",
      "episode 2, policy loss -0.09903421998023987\n",
      "\n",
      "episode 3, policy loss -0.11378688365221024\n",
      "\n",
      "episode 4, policy loss -0.13685539364814758\n",
      "\n",
      "episode 5, policy loss -0.07135052978992462\n",
      "\n",
      "episode 6, policy loss -0.06357019394636154\n",
      "\n",
      "episode 7, policy loss -0.108027383685112\n",
      "\n",
      "episode 8, policy loss -0.11607423424720764\n",
      "\n",
      "episode 9, policy loss -0.13558275997638702\n",
      "\n",
      "episode 10, policy loss -0.14399448037147522\n",
      "\n",
      "episode 11, policy loss -0.14608293771743774\n",
      "\n",
      "episode 12, policy loss -0.14220066368579865\n",
      "\n",
      "episode 13, policy loss -0.08107390999794006\n",
      "\n",
      "episode 14, policy loss -0.06695425510406494\n",
      "\n",
      "episode 15, policy loss -0.0917375385761261\n",
      "\n",
      "episode 16, policy loss -0.1253405511379242\n",
      "\n",
      "Policy train loss in epoch 1:-0.10641984734684229\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.1480804681777954\n",
      "\n",
      "episode 2, policy loss -0.11364088952541351\n",
      "\n",
      "episode 3, policy loss -0.0674246996641159\n",
      "\n",
      "episode 4, policy loss -0.14174804091453552\n",
      "\n",
      "episode 5, policy loss -0.13639682531356812\n",
      "\n",
      "episode 6, policy loss -0.11630304157733917\n",
      "\n",
      "episode 7, policy loss -0.14153695106506348\n",
      "\n",
      "episode 8, policy loss -0.1339968591928482\n",
      "\n",
      "episode 9, policy loss -0.06259947270154953\n",
      "\n",
      "episode 10, policy loss -0.09145917743444443\n",
      "\n",
      "episode 11, policy loss -0.10636343061923981\n",
      "\n",
      "episode 12, policy loss -0.12223938852548599\n",
      "\n",
      "episode 13, policy loss -0.05836043506860733\n",
      "\n",
      "episode 14, policy loss -0.06943415850400925\n",
      "\n",
      "episode 15, policy loss -0.09692844748497009\n",
      "\n",
      "episode 16, policy loss -0.07515634596347809\n",
      "\n",
      "Policy train loss in epoch 2:-0.10510428948327899\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.08811009675264359\n",
      "\n",
      "episode 2, policy loss -0.09947983920574188\n",
      "\n",
      "episode 3, policy loss -0.10760115087032318\n",
      "\n",
      "episode 4, policy loss -0.12433847784996033\n",
      "\n",
      "episode 5, policy loss -0.07062533497810364\n",
      "\n",
      "episode 6, policy loss -0.144663006067276\n",
      "\n",
      "episode 7, policy loss -0.06755994260311127\n",
      "\n",
      "episode 8, policy loss -0.08110292255878448\n",
      "\n",
      "episode 9, policy loss -0.06854791194200516\n",
      "\n",
      "episode 10, policy loss -0.14328359067440033\n",
      "\n",
      "episode 11, policy loss -0.1410178393125534\n",
      "\n",
      "episode 12, policy loss -0.13432082533836365\n",
      "\n",
      "episode 13, policy loss -0.11514967679977417\n",
      "\n",
      "episode 14, policy loss -0.06325703114271164\n",
      "\n",
      "episode 15, policy loss -0.1336870789527893\n",
      "\n",
      "episode 16, policy loss -0.11586353927850723\n",
      "\n",
      "Policy train loss in epoch 3:-0.10616301652044058\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.13227590918540955\n",
      "\n",
      "episode 2, val func loss 0.16527192294597626\n",
      "\n",
      "episode 3, val func loss 0.17573560774326324\n",
      "\n",
      "episode 4, val func loss 0.18306227028369904\n",
      "\n",
      "episode 5, val func loss 0.16289056837558746\n",
      "\n",
      "episode 6, val func loss 0.21346737444400787\n",
      "\n",
      "episode 7, val func loss 0.15586228668689728\n",
      "\n",
      "episode 8, val func loss 0.16443495452404022\n",
      "\n",
      "episode 9, val func loss 0.20045915246009827\n",
      "\n",
      "episode 10, val func loss 0.18271782994270325\n",
      "\n",
      "episode 11, val func loss 0.1684517115354538\n",
      "\n",
      "episode 12, val func loss 0.16287705302238464\n",
      "\n",
      "episode 13, val func loss 0.17347025871276855\n",
      "\n",
      "episode 14, val func loss 0.12249244004487991\n",
      "\n",
      "episode 15, val func loss 0.18509343266487122\n",
      "\n",
      "episode 16, val func loss 0.14057087898254395\n",
      "\n",
      "Val func train loss in epoch 0:0.16807085322216153\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18395152688026428\n",
      "\n",
      "episode 2, val func loss 0.13975022733211517\n",
      "\n",
      "episode 3, val func loss 0.1535698026418686\n",
      "\n",
      "episode 4, val func loss 0.17543645203113556\n",
      "\n",
      "episode 5, val func loss 0.20360919833183289\n",
      "\n",
      "episode 6, val func loss 0.15469154715538025\n",
      "\n",
      "episode 7, val func loss 0.13078729808330536\n",
      "\n",
      "episode 8, val func loss 0.18373256921768188\n",
      "\n",
      "episode 9, val func loss 0.21333682537078857\n",
      "\n",
      "episode 10, val func loss 0.18570338189601898\n",
      "\n",
      "episode 11, val func loss 0.16941873729228973\n",
      "\n",
      "episode 12, val func loss 0.16108942031860352\n",
      "\n",
      "episode 13, val func loss 0.17346599698066711\n",
      "\n",
      "episode 14, val func loss 0.12648819386959076\n",
      "\n",
      "episode 15, val func loss 0.16837112605571747\n",
      "\n",
      "episode 16, val func loss 0.16264677047729492\n",
      "\n",
      "Val func train loss in epoch 1:0.1678780671209097\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18143007159233093\n",
      "\n",
      "episode 2, val func loss 0.11869816482067108\n",
      "\n",
      "episode 3, val func loss 0.15651807188987732\n",
      "\n",
      "episode 4, val func loss 0.18554778397083282\n",
      "\n",
      "episode 5, val func loss 0.17484425008296967\n",
      "\n",
      "episode 6, val func loss 0.13032735884189606\n",
      "\n",
      "episode 7, val func loss 0.1394740790128708\n",
      "\n",
      "episode 8, val func loss 0.17438261210918427\n",
      "\n",
      "episode 9, val func loss 0.1648600697517395\n",
      "\n",
      "episode 10, val func loss 0.1653345227241516\n",
      "\n",
      "episode 11, val func loss 0.1756332665681839\n",
      "\n",
      "episode 12, val func loss 0.18719889223575592\n",
      "\n",
      "episode 13, val func loss 0.20244835317134857\n",
      "\n",
      "episode 14, val func loss 0.21234086155891418\n",
      "\n",
      "episode 15, val func loss 0.15630082786083221\n",
      "\n",
      "episode 16, val func loss 0.16052861511707306\n",
      "\n",
      "Val func train loss in epoch 2:0.1678667375817895\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.17066164314746857\n",
      "\n",
      "episode 2, val func loss 0.17504939436912537\n",
      "\n",
      "episode 3, val func loss 0.11758922785520554\n",
      "\n",
      "episode 4, val func loss 0.21232138574123383\n",
      "\n",
      "episode 5, val func loss 0.17878076434135437\n",
      "\n",
      "episode 6, val func loss 0.1559617817401886\n",
      "\n",
      "episode 7, val func loss 0.1844969242811203\n",
      "\n",
      "episode 8, val func loss 0.1400831788778305\n",
      "\n",
      "episode 9, val func loss 0.18492312729358673\n",
      "\n",
      "episode 10, val func loss 0.16540326178073883\n",
      "\n",
      "episode 11, val func loss 0.2002909928560257\n",
      "\n",
      "episode 12, val func loss 0.16028141975402832\n",
      "\n",
      "episode 13, val func loss 0.18093250691890717\n",
      "\n",
      "episode 14, val func loss 0.15626835823059082\n",
      "\n",
      "episode 15, val func loss 0.1633228212594986\n",
      "\n",
      "episode 16, val func loss 0.1339959353208542\n",
      "\n",
      "Val func train loss in epoch 3:0.16752267023548484\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.16403204202651978\n",
      "\n",
      "episode 2, val func loss 0.1601913869380951\n",
      "\n",
      "episode 3, val func loss 0.11773333698511124\n",
      "\n",
      "episode 4, val func loss 0.17103475332260132\n",
      "\n",
      "episode 5, val func loss 0.1561821550130844\n",
      "\n",
      "episode 6, val func loss 0.15338049829006195\n",
      "\n",
      "episode 7, val func loss 0.17854897677898407\n",
      "\n",
      "episode 8, val func loss 0.18515637516975403\n",
      "\n",
      "episode 9, val func loss 0.1811620146036148\n",
      "\n",
      "episode 10, val func loss 0.2114112377166748\n",
      "\n",
      "episode 11, val func loss 0.14155302941799164\n",
      "\n",
      "episode 12, val func loss 0.13606005907058716\n",
      "\n",
      "episode 13, val func loss 0.17644712328910828\n",
      "\n",
      "episode 14, val func loss 0.2013510912656784\n",
      "\n",
      "episode 15, val func loss 0.16410960257053375\n",
      "\n",
      "episode 16, val func loss 0.18557429313659668\n",
      "\n",
      "Val func train loss in epoch 4:0.16774549847468734\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.20184512436389923\n",
      "\n",
      "episode 2, val func loss 0.15643872320652008\n",
      "\n",
      "episode 3, val func loss 0.18456962704658508\n",
      "\n",
      "episode 4, val func loss 0.1646757572889328\n",
      "\n",
      "episode 5, val func loss 0.17486423254013062\n",
      "\n",
      "episode 6, val func loss 0.15415243804454803\n",
      "\n",
      "episode 7, val func loss 0.1605747491121292\n",
      "\n",
      "episode 8, val func loss 0.1646450012922287\n",
      "\n",
      "episode 9, val func loss 0.17713412642478943\n",
      "\n",
      "episode 10, val func loss 0.13448432087898254\n",
      "\n",
      "episode 11, val func loss 0.13995249569416046\n",
      "\n",
      "episode 12, val func loss 0.11902298033237457\n",
      "\n",
      "episode 13, val func loss 0.18486037850379944\n",
      "\n",
      "episode 14, val func loss 0.1706235706806183\n",
      "\n",
      "episode 15, val func loss 0.21106252074241638\n",
      "\n",
      "episode 16, val func loss 0.18134772777557373\n",
      "\n",
      "Val func train loss in epoch 5:0.16751586087048054\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17542627453804016\n",
      "\n",
      "episode 2, val func loss 0.15442851185798645\n",
      "\n",
      "episode 3, val func loss 0.16546864807605743\n",
      "\n",
      "episode 4, val func loss 0.13957631587982178\n",
      "\n",
      "episode 5, val func loss 0.17852282524108887\n",
      "\n",
      "episode 6, val func loss 0.15608593821525574\n",
      "\n",
      "episode 7, val func loss 0.1853528618812561\n",
      "\n",
      "episode 8, val func loss 0.20173698663711548\n",
      "\n",
      "episode 9, val func loss 0.17020893096923828\n",
      "\n",
      "episode 10, val func loss 0.13316598534584045\n",
      "\n",
      "episode 11, val func loss 0.18037323653697968\n",
      "\n",
      "episode 12, val func loss 0.18306593596935272\n",
      "\n",
      "episode 13, val func loss 0.16033732891082764\n",
      "\n",
      "episode 14, val func loss 0.12023717910051346\n",
      "\n",
      "episode 15, val func loss 0.16248148679733276\n",
      "\n",
      "episode 16, val func loss 0.21142573654651642\n",
      "\n",
      "Val func train loss in epoch 6:0.16736838640645146\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.21049049496650696\n",
      "\n",
      "episode 2, val func loss 0.1627359390258789\n",
      "\n",
      "episode 3, val func loss 0.16579757630825043\n",
      "\n",
      "episode 4, val func loss 0.20080624520778656\n",
      "\n",
      "episode 5, val func loss 0.17464031279087067\n",
      "\n",
      "episode 6, val func loss 0.18311664462089539\n",
      "\n",
      "episode 7, val func loss 0.1204797551035881\n",
      "\n",
      "episode 8, val func loss 0.16893871128559113\n",
      "\n",
      "episode 9, val func loss 0.17663955688476562\n",
      "\n",
      "episode 10, val func loss 0.15965549647808075\n",
      "\n",
      "episode 11, val func loss 0.1842968761920929\n",
      "\n",
      "episode 12, val func loss 0.18126180768013\n",
      "\n",
      "episode 13, val func loss 0.15447717905044556\n",
      "\n",
      "episode 14, val func loss 0.13186007738113403\n",
      "\n",
      "episode 15, val func loss 0.1393718719482422\n",
      "\n",
      "episode 16, val func loss 0.15499751269817352\n",
      "\n",
      "Val func train loss in epoch 7:0.16684787860140204\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16394396126270294\n",
      "\n",
      "episode 2, val func loss 0.15517261624336243\n",
      "\n",
      "episode 3, val func loss 0.12977449595928192\n",
      "\n",
      "episode 4, val func loss 0.21573659777641296\n",
      "\n",
      "episode 5, val func loss 0.16564631462097168\n",
      "\n",
      "episode 6, val func loss 0.18668067455291748\n",
      "\n",
      "episode 7, val func loss 0.1703646183013916\n",
      "\n",
      "episode 8, val func loss 0.12008655071258545\n",
      "\n",
      "episode 9, val func loss 0.18146179616451263\n",
      "\n",
      "episode 10, val func loss 0.1734963059425354\n",
      "\n",
      "episode 11, val func loss 0.16010302305221558\n",
      "\n",
      "episode 12, val func loss 0.20101550221443176\n",
      "\n",
      "episode 13, val func loss 0.16215848922729492\n",
      "\n",
      "episode 14, val func loss 0.18493741750717163\n",
      "\n",
      "episode 15, val func loss 0.1404201239347458\n",
      "\n",
      "episode 16, val func loss 0.17637300491333008\n",
      "\n",
      "Val func train loss in epoch 8:0.16796071827411652\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.15368162095546722\n",
      "\n",
      "episode 2, val func loss 0.1753207892179489\n",
      "\n",
      "episode 3, val func loss 0.18891647458076477\n",
      "\n",
      "episode 4, val func loss 0.18258850276470184\n",
      "\n",
      "episode 5, val func loss 0.1649142950773239\n",
      "\n",
      "episode 6, val func loss 0.16085189580917358\n",
      "\n",
      "episode 7, val func loss 0.11866234242916107\n",
      "\n",
      "episode 8, val func loss 0.1686156690120697\n",
      "\n",
      "episode 9, val func loss 0.16044795513153076\n",
      "\n",
      "episode 10, val func loss 0.1812611073255539\n",
      "\n",
      "episode 11, val func loss 0.13470011949539185\n",
      "\n",
      "episode 12, val func loss 0.1850939244031906\n",
      "\n",
      "episode 13, val func loss 0.13979867100715637\n",
      "\n",
      "episode 14, val func loss 0.166211798787117\n",
      "\n",
      "episode 15, val func loss 0.21236351132392883\n",
      "\n",
      "episode 16, val func loss 0.20149236917495728\n",
      "\n",
      "Val func train loss in epoch 9:0.16843256540596485\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1812027394771576\n",
      "\n",
      "episode 2, val func loss 0.1828787922859192\n",
      "\n",
      "episode 3, val func loss 0.1649964600801468\n",
      "\n",
      "episode 4, val func loss 0.12081228196620941\n",
      "\n",
      "episode 5, val func loss 0.17384369671344757\n",
      "\n",
      "episode 6, val func loss 0.1685522198677063\n",
      "\n",
      "episode 7, val func loss 0.15667152404785156\n",
      "\n",
      "episode 8, val func loss 0.15993937849998474\n",
      "\n",
      "episode 9, val func loss 0.20071864128112793\n",
      "\n",
      "episode 10, val func loss 0.18532869219779968\n",
      "\n",
      "episode 11, val func loss 0.1650014966726303\n",
      "\n",
      "episode 12, val func loss 0.13186869025230408\n",
      "\n",
      "episode 13, val func loss 0.17514510452747345\n",
      "\n",
      "episode 14, val func loss 0.13948136568069458\n",
      "\n",
      "episode 15, val func loss 0.16149947047233582\n",
      "\n",
      "episode 16, val func loss 0.21247772872447968\n",
      "\n",
      "Val func train loss in epoch 10:0.1675261426717043\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1652170568704605\n",
      "\n",
      "episode 2, val func loss 0.17746515572071075\n",
      "\n",
      "episode 3, val func loss 0.16952766478061676\n",
      "\n",
      "episode 4, val func loss 0.16695177555084229\n",
      "\n",
      "episode 5, val func loss 0.16368946433067322\n",
      "\n",
      "episode 6, val func loss 0.1817040741443634\n",
      "\n",
      "episode 7, val func loss 0.20091627538204193\n",
      "\n",
      "episode 8, val func loss 0.15558071434497833\n",
      "\n",
      "episode 9, val func loss 0.21126411855220795\n",
      "\n",
      "episode 10, val func loss 0.11762510240077972\n",
      "\n",
      "episode 11, val func loss 0.18617720901966095\n",
      "\n",
      "episode 12, val func loss 0.13098007440567017\n",
      "\n",
      "episode 13, val func loss 0.13947267830371857\n",
      "\n",
      "episode 14, val func loss 0.16287510097026825\n",
      "\n",
      "episode 15, val func loss 0.17576433718204498\n",
      "\n",
      "episode 16, val func loss 0.18741944432258606\n",
      "\n",
      "Val func train loss in epoch 11:0.1682893903926015\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18234586715698242\n",
      "\n",
      "episode 2, val func loss 0.20096778869628906\n",
      "\n",
      "episode 3, val func loss 0.18451246619224548\n",
      "\n",
      "episode 4, val func loss 0.1382724791765213\n",
      "\n",
      "episode 5, val func loss 0.16232502460479736\n",
      "\n",
      "episode 6, val func loss 0.168370321393013\n",
      "\n",
      "episode 7, val func loss 0.15798020362854004\n",
      "\n",
      "episode 8, val func loss 0.16582998633384705\n",
      "\n",
      "episode 9, val func loss 0.1586097627878189\n",
      "\n",
      "episode 10, val func loss 0.1755545735359192\n",
      "\n",
      "episode 11, val func loss 0.13956905901432037\n",
      "\n",
      "episode 12, val func loss 0.19100835919380188\n",
      "\n",
      "episode 13, val func loss 0.16302895545959473\n",
      "\n",
      "episode 14, val func loss 0.21225669980049133\n",
      "\n",
      "episode 15, val func loss 0.1178385391831398\n",
      "\n",
      "episode 16, val func loss 0.17647254467010498\n",
      "\n",
      "Val func train loss in epoch 12:0.16843391442671418\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.17503580451011658\n",
      "\n",
      "episode 2, val func loss 0.21143144369125366\n",
      "\n",
      "episode 3, val func loss 0.1585797369480133\n",
      "\n",
      "episode 4, val func loss 0.18490071594715118\n",
      "\n",
      "episode 5, val func loss 0.166123166680336\n",
      "\n",
      "episode 6, val func loss 0.15865090489387512\n",
      "\n",
      "episode 7, val func loss 0.1616336554288864\n",
      "\n",
      "episode 8, val func loss 0.13920968770980835\n",
      "\n",
      "episode 9, val func loss 0.18378432095050812\n",
      "\n",
      "episode 10, val func loss 0.1752999722957611\n",
      "\n",
      "episode 11, val func loss 0.13186225295066833\n",
      "\n",
      "episode 12, val func loss 0.11732932925224304\n",
      "\n",
      "episode 13, val func loss 0.1653815656900406\n",
      "\n",
      "episode 14, val func loss 0.20142091810703278\n",
      "\n",
      "episode 15, val func loss 0.18383856117725372\n",
      "\n",
      "episode 16, val func loss 0.16971451044082642\n",
      "\n",
      "Val func train loss in epoch 13:0.16776228416711092\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.20046678185462952\n",
      "\n",
      "episode 2, val func loss 0.1743471622467041\n",
      "\n",
      "episode 3, val func loss 0.16113528609275818\n",
      "\n",
      "episode 4, val func loss 0.18610776960849762\n",
      "\n",
      "episode 5, val func loss 0.14009493589401245\n",
      "\n",
      "episode 6, val func loss 0.1424705535173416\n",
      "\n",
      "episode 7, val func loss 0.18293645977973938\n",
      "\n",
      "episode 8, val func loss 0.17569948732852936\n",
      "\n",
      "episode 9, val func loss 0.17174965143203735\n",
      "\n",
      "episode 10, val func loss 0.11734569072723389\n",
      "\n",
      "episode 11, val func loss 0.1656152606010437\n",
      "\n",
      "episode 12, val func loss 0.15365204215049744\n",
      "\n",
      "episode 13, val func loss 0.16445186734199524\n",
      "\n",
      "episode 14, val func loss 0.18205758929252625\n",
      "\n",
      "episode 15, val func loss 0.21184220910072327\n",
      "\n",
      "episode 16, val func loss 0.15647952258586884\n",
      "\n",
      "Val func train loss in epoch 14:0.16790326684713364\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1700621247291565\n",
      "\n",
      "episode 2, val func loss 0.11797552555799484\n",
      "\n",
      "episode 3, val func loss 0.1813862919807434\n",
      "\n",
      "episode 4, val func loss 0.15691514313220978\n",
      "\n",
      "episode 5, val func loss 0.15341322124004364\n",
      "\n",
      "episode 6, val func loss 0.16487576067447662\n",
      "\n",
      "episode 7, val func loss 0.16633519530296326\n",
      "\n",
      "episode 8, val func loss 0.21270449459552765\n",
      "\n",
      "episode 9, val func loss 0.1780988872051239\n",
      "\n",
      "episode 10, val func loss 0.17541755735874176\n",
      "\n",
      "episode 11, val func loss 0.13355830311775208\n",
      "\n",
      "episode 12, val func loss 0.18468596041202545\n",
      "\n",
      "episode 13, val func loss 0.14064887166023254\n",
      "\n",
      "episode 14, val func loss 0.2013215273618698\n",
      "\n",
      "episode 15, val func loss 0.18267275393009186\n",
      "\n",
      "episode 16, val func loss 0.16028939187526703\n",
      "\n",
      "Val func train loss in epoch 15:0.16752256313338876\n",
      "***********************TIME WAS 4.904253856341044 min*****************************\n",
      "\n",
      "**********************ROUND 39 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.09005618095397949\n",
      "\n",
      "episode 2, policy loss -0.05866637080907822\n",
      "\n",
      "episode 3, policy loss -0.050690215080976486\n",
      "\n",
      "episode 4, policy loss -0.0385826900601387\n",
      "\n",
      "episode 5, policy loss -0.07916811108589172\n",
      "\n",
      "episode 6, policy loss -0.026290249079465866\n",
      "\n",
      "episode 7, policy loss -0.029884736984968185\n",
      "\n",
      "episode 8, policy loss -0.08633943647146225\n",
      "\n",
      "episode 9, policy loss -0.08281614631414413\n",
      "\n",
      "episode 10, policy loss -0.08619163185358047\n",
      "\n",
      "episode 11, policy loss -0.1315038502216339\n",
      "\n",
      "episode 12, policy loss -0.10025864094495773\n",
      "\n",
      "episode 13, policy loss -0.14614266157150269\n",
      "\n",
      "episode 14, policy loss -0.12139667570590973\n",
      "\n",
      "episode 15, policy loss -0.02891988679766655\n",
      "\n",
      "episode 16, policy loss -0.09066886454820633\n",
      "\n",
      "Policy train loss in epoch 0:-0.07797352178022265\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.09020555764436722\n",
      "\n",
      "episode 2, policy loss -0.0548626184463501\n",
      "\n",
      "episode 3, policy loss -0.04944069683551788\n",
      "\n",
      "episode 4, policy loss -0.03674573078751564\n",
      "\n",
      "episode 5, policy loss -0.09145055711269379\n",
      "\n",
      "episode 6, policy loss -0.08678865432739258\n",
      "\n",
      "episode 7, policy loss -0.11892207711935043\n",
      "\n",
      "episode 8, policy loss -0.023023594170808792\n",
      "\n",
      "episode 9, policy loss -0.14654695987701416\n",
      "\n",
      "episode 10, policy loss -0.03244689106941223\n",
      "\n",
      "episode 11, policy loss -0.13364577293395996\n",
      "\n",
      "episode 12, policy loss -0.09989280253648758\n",
      "\n",
      "episode 13, policy loss -0.08822032064199448\n",
      "\n",
      "episode 14, policy loss -0.02686382457613945\n",
      "\n",
      "episode 15, policy loss -0.091873899102211\n",
      "\n",
      "episode 16, policy loss -0.07780111581087112\n",
      "\n",
      "Policy train loss in epoch 1:-0.0780456920620054\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.06017986685037613\n",
      "\n",
      "episode 2, policy loss -0.08920547366142273\n",
      "\n",
      "episode 3, policy loss -0.07931707054376602\n",
      "\n",
      "episode 4, policy loss -0.09034192562103271\n",
      "\n",
      "episode 5, policy loss -0.11643444001674652\n",
      "\n",
      "episode 6, policy loss -0.027769003063440323\n",
      "\n",
      "episode 7, policy loss -0.09892570972442627\n",
      "\n",
      "episode 8, policy loss -0.08882292360067368\n",
      "\n",
      "episode 9, policy loss -0.1457662582397461\n",
      "\n",
      "episode 10, policy loss -0.13546207547187805\n",
      "\n",
      "episode 11, policy loss -0.09154179692268372\n",
      "\n",
      "episode 12, policy loss -0.051731325685977936\n",
      "\n",
      "episode 13, policy loss -0.028603408485651016\n",
      "\n",
      "episode 14, policy loss -0.08515249937772751\n",
      "\n",
      "episode 15, policy loss -0.04035063087940216\n",
      "\n",
      "episode 16, policy loss -0.02514002099633217\n",
      "\n",
      "Policy train loss in epoch 2:-0.07842152682133019\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.028781719505786896\n",
      "\n",
      "episode 2, policy loss -0.10074955970048904\n",
      "\n",
      "episode 3, policy loss -0.09398643672466278\n",
      "\n",
      "episode 4, policy loss -0.08872667700052261\n",
      "\n",
      "episode 5, policy loss -0.040373124182224274\n",
      "\n",
      "episode 6, policy loss -0.11869914829730988\n",
      "\n",
      "episode 7, policy loss -0.13244536519050598\n",
      "\n",
      "episode 8, policy loss -0.03239075839519501\n",
      "\n",
      "episode 9, policy loss -0.08030441403388977\n",
      "\n",
      "episode 10, policy loss -0.05147065222263336\n",
      "\n",
      "episode 11, policy loss -0.05997695401310921\n",
      "\n",
      "episode 12, policy loss -0.1468379944562912\n",
      "\n",
      "episode 13, policy loss -0.09142589569091797\n",
      "\n",
      "episode 14, policy loss -0.08923698216676712\n",
      "\n",
      "episode 15, policy loss -0.026346173137426376\n",
      "\n",
      "episode 16, policy loss -0.08827737718820572\n",
      "\n",
      "Policy train loss in epoch 3:-0.07937682699412107\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1989138424396515\n",
      "\n",
      "episode 2, val func loss 0.18726572394371033\n",
      "\n",
      "episode 3, val func loss 0.13650600612163544\n",
      "\n",
      "episode 4, val func loss 0.12842078506946564\n",
      "\n",
      "episode 5, val func loss 0.1576215773820877\n",
      "\n",
      "episode 6, val func loss 0.1583351343870163\n",
      "\n",
      "episode 7, val func loss 0.164953351020813\n",
      "\n",
      "episode 8, val func loss 0.184202179312706\n",
      "\n",
      "episode 9, val func loss 0.17453981935977936\n",
      "\n",
      "episode 10, val func loss 0.19907721877098083\n",
      "\n",
      "episode 11, val func loss 0.2160462886095047\n",
      "\n",
      "episode 12, val func loss 0.13308367133140564\n",
      "\n",
      "episode 13, val func loss 0.12131854891777039\n",
      "\n",
      "episode 14, val func loss 0.16535250842571259\n",
      "\n",
      "episode 15, val func loss 0.16276179254055023\n",
      "\n",
      "episode 16, val func loss 0.16733820736408234\n",
      "\n",
      "Val func train loss in epoch 0:0.1659835409373045\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.12907058000564575\n",
      "\n",
      "episode 2, val func loss 0.18671606481075287\n",
      "\n",
      "episode 3, val func loss 0.18231773376464844\n",
      "\n",
      "episode 4, val func loss 0.1382128745317459\n",
      "\n",
      "episode 5, val func loss 0.1658371388912201\n",
      "\n",
      "episode 6, val func loss 0.2095104306936264\n",
      "\n",
      "episode 7, val func loss 0.1985601931810379\n",
      "\n",
      "episode 8, val func loss 0.16758599877357483\n",
      "\n",
      "episode 9, val func loss 0.16895908117294312\n",
      "\n",
      "episode 10, val func loss 0.15862314403057098\n",
      "\n",
      "episode 11, val func loss 0.15574482083320618\n",
      "\n",
      "episode 12, val func loss 0.17259013652801514\n",
      "\n",
      "episode 13, val func loss 0.1625450849533081\n",
      "\n",
      "episode 14, val func loss 0.13254450261592865\n",
      "\n",
      "episode 15, val func loss 0.11928269267082214\n",
      "\n",
      "episode 16, val func loss 0.19870634377002716\n",
      "\n",
      "Val func train loss in epoch 1:0.1654254263266921\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17396464943885803\n",
      "\n",
      "episode 2, val func loss 0.13148534297943115\n",
      "\n",
      "episode 3, val func loss 0.18259423971176147\n",
      "\n",
      "episode 4, val func loss 0.17107240855693817\n",
      "\n",
      "episode 5, val func loss 0.18719720840454102\n",
      "\n",
      "episode 6, val func loss 0.1961948573589325\n",
      "\n",
      "episode 7, val func loss 0.17144301533699036\n",
      "\n",
      "episode 8, val func loss 0.2000804990530014\n",
      "\n",
      "episode 9, val func loss 0.12728315591812134\n",
      "\n",
      "episode 10, val func loss 0.1382298767566681\n",
      "\n",
      "episode 11, val func loss 0.1649305820465088\n",
      "\n",
      "episode 12, val func loss 0.1560106873512268\n",
      "\n",
      "episode 13, val func loss 0.1593625843524933\n",
      "\n",
      "episode 14, val func loss 0.1318124681711197\n",
      "\n",
      "episode 15, val func loss 0.1669439822435379\n",
      "\n",
      "episode 16, val func loss 0.22286149859428406\n",
      "\n",
      "Val func train loss in epoch 2:0.16759169101715088\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1189582496881485\n",
      "\n",
      "episode 2, val func loss 0.13186167180538177\n",
      "\n",
      "episode 3, val func loss 0.20098522305488586\n",
      "\n",
      "episode 4, val func loss 0.1713957041501999\n",
      "\n",
      "episode 5, val func loss 0.18129245936870575\n",
      "\n",
      "episode 6, val func loss 0.1587468683719635\n",
      "\n",
      "episode 7, val func loss 0.2092730551958084\n",
      "\n",
      "episode 8, val func loss 0.16699852049350739\n",
      "\n",
      "episode 9, val func loss 0.1658046543598175\n",
      "\n",
      "episode 10, val func loss 0.13899259269237518\n",
      "\n",
      "episode 11, val func loss 0.1723286658525467\n",
      "\n",
      "episode 12, val func loss 0.18929842114448547\n",
      "\n",
      "episode 13, val func loss 0.19815343618392944\n",
      "\n",
      "episode 14, val func loss 0.13233976066112518\n",
      "\n",
      "episode 15, val func loss 0.16518506407737732\n",
      "\n",
      "episode 16, val func loss 0.1662665605545044\n",
      "\n",
      "Val func train loss in epoch 3:0.16674255672842264\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17161345481872559\n",
      "\n",
      "episode 2, val func loss 0.12912331521511078\n",
      "\n",
      "episode 3, val func loss 0.18160131573677063\n",
      "\n",
      "episode 4, val func loss 0.12308546155691147\n",
      "\n",
      "episode 5, val func loss 0.17299427092075348\n",
      "\n",
      "episode 6, val func loss 0.13499000668525696\n",
      "\n",
      "episode 7, val func loss 0.1952858418226242\n",
      "\n",
      "episode 8, val func loss 0.13295339047908783\n",
      "\n",
      "episode 9, val func loss 0.18899644911289215\n",
      "\n",
      "episode 10, val func loss 0.20046918094158173\n",
      "\n",
      "episode 11, val func loss 0.16265100240707397\n",
      "\n",
      "episode 12, val func loss 0.16573597490787506\n",
      "\n",
      "episode 13, val func loss 0.15624397993087769\n",
      "\n",
      "episode 14, val func loss 0.2122201919555664\n",
      "\n",
      "episode 15, val func loss 0.1661190539598465\n",
      "\n",
      "episode 16, val func loss 0.15852531790733337\n",
      "\n",
      "Val func train loss in epoch 4:0.165788013022393\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18202972412109375\n",
      "\n",
      "episode 2, val func loss 0.12931236624717712\n",
      "\n",
      "episode 3, val func loss 0.19616392254829407\n",
      "\n",
      "episode 4, val func loss 0.16303369402885437\n",
      "\n",
      "episode 5, val func loss 0.1986905038356781\n",
      "\n",
      "episode 6, val func loss 0.16763770580291748\n",
      "\n",
      "episode 7, val func loss 0.16847139596939087\n",
      "\n",
      "episode 8, val func loss 0.1588498055934906\n",
      "\n",
      "episode 9, val func loss 0.16493754088878632\n",
      "\n",
      "episode 10, val func loss 0.20995251834392548\n",
      "\n",
      "episode 11, val func loss 0.15978150069713593\n",
      "\n",
      "episode 12, val func loss 0.13556812703609467\n",
      "\n",
      "episode 13, val func loss 0.13332675397396088\n",
      "\n",
      "episode 14, val func loss 0.17254117131233215\n",
      "\n",
      "episode 15, val func loss 0.19052572548389435\n",
      "\n",
      "episode 16, val func loss 0.11905696988105774\n",
      "\n",
      "Val func train loss in epoch 5:0.16561746411025524\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.13218581676483154\n",
      "\n",
      "episode 2, val func loss 0.18492227792739868\n",
      "\n",
      "episode 3, val func loss 0.2177049070596695\n",
      "\n",
      "episode 4, val func loss 0.1633545607328415\n",
      "\n",
      "episode 5, val func loss 0.165657177567482\n",
      "\n",
      "episode 6, val func loss 0.19592994451522827\n",
      "\n",
      "episode 7, val func loss 0.12210884690284729\n",
      "\n",
      "episode 8, val func loss 0.1729726344347\n",
      "\n",
      "episode 9, val func loss 0.16740389168262482\n",
      "\n",
      "episode 10, val func loss 0.16504918038845062\n",
      "\n",
      "episode 11, val func loss 0.1983829140663147\n",
      "\n",
      "episode 12, val func loss 0.12888015806674957\n",
      "\n",
      "episode 13, val func loss 0.1626342535018921\n",
      "\n",
      "episode 14, val func loss 0.18703481554985046\n",
      "\n",
      "episode 15, val func loss 0.13515369594097137\n",
      "\n",
      "episode 16, val func loss 0.15857072174549103\n",
      "\n",
      "Val func train loss in epoch 6:0.16612161230295897\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.11955863982439041\n",
      "\n",
      "episode 2, val func loss 0.2201482504606247\n",
      "\n",
      "episode 3, val func loss 0.20310087502002716\n",
      "\n",
      "episode 4, val func loss 0.1666988581418991\n",
      "\n",
      "episode 5, val func loss 0.18155135214328766\n",
      "\n",
      "episode 6, val func loss 0.13389787077903748\n",
      "\n",
      "episode 7, val func loss 0.186727836728096\n",
      "\n",
      "episode 8, val func loss 0.15811415016651154\n",
      "\n",
      "episode 9, val func loss 0.13500747084617615\n",
      "\n",
      "episode 10, val func loss 0.16662925481796265\n",
      "\n",
      "episode 11, val func loss 0.1726638823747635\n",
      "\n",
      "episode 12, val func loss 0.15582416951656342\n",
      "\n",
      "episode 13, val func loss 0.1962665468454361\n",
      "\n",
      "episode 14, val func loss 0.17271392047405243\n",
      "\n",
      "episode 15, val func loss 0.12962239980697632\n",
      "\n",
      "episode 16, val func loss 0.1625266671180725\n",
      "\n",
      "Val func train loss in epoch 7:0.16631575906649232\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.15823641419410706\n",
      "\n",
      "episode 2, val func loss 0.21146801114082336\n",
      "\n",
      "episode 3, val func loss 0.1674797534942627\n",
      "\n",
      "episode 4, val func loss 0.12369109690189362\n",
      "\n",
      "episode 5, val func loss 0.1368306428194046\n",
      "\n",
      "episode 6, val func loss 0.19532842934131622\n",
      "\n",
      "episode 7, val func loss 0.18705135583877563\n",
      "\n",
      "episode 8, val func loss 0.13427601754665375\n",
      "\n",
      "episode 9, val func loss 0.17244784533977509\n",
      "\n",
      "episode 10, val func loss 0.1663820445537567\n",
      "\n",
      "episode 11, val func loss 0.16310831904411316\n",
      "\n",
      "episode 12, val func loss 0.15458105504512787\n",
      "\n",
      "episode 13, val func loss 0.18288351595401764\n",
      "\n",
      "episode 14, val func loss 0.13003109395503998\n",
      "\n",
      "episode 15, val func loss 0.19961778819561005\n",
      "\n",
      "episode 16, val func loss 0.165701225399971\n",
      "\n",
      "Val func train loss in epoch 8:0.16556966304779053\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1326296031475067\n",
      "\n",
      "episode 2, val func loss 0.19581401348114014\n",
      "\n",
      "episode 3, val func loss 0.18182308971881866\n",
      "\n",
      "episode 4, val func loss 0.1698073297739029\n",
      "\n",
      "episode 5, val func loss 0.1667736917734146\n",
      "\n",
      "episode 6, val func loss 0.17202885448932648\n",
      "\n",
      "episode 7, val func loss 0.1870325356721878\n",
      "\n",
      "episode 8, val func loss 0.15854065120220184\n",
      "\n",
      "episode 9, val func loss 0.19854867458343506\n",
      "\n",
      "episode 10, val func loss 0.12883800268173218\n",
      "\n",
      "episode 11, val func loss 0.13542988896369934\n",
      "\n",
      "episode 12, val func loss 0.12226565927267075\n",
      "\n",
      "episode 13, val func loss 0.21204343438148499\n",
      "\n",
      "episode 14, val func loss 0.16246798634529114\n",
      "\n",
      "episode 15, val func loss 0.1661529690027237\n",
      "\n",
      "episode 16, val func loss 0.15555769205093384\n",
      "\n",
      "Val func train loss in epoch 9:0.16535962978377938\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18189598619937897\n",
      "\n",
      "episode 2, val func loss 0.15882553160190582\n",
      "\n",
      "episode 3, val func loss 0.11984209716320038\n",
      "\n",
      "episode 4, val func loss 0.16278865933418274\n",
      "\n",
      "episode 5, val func loss 0.16694389283657074\n",
      "\n",
      "episode 6, val func loss 0.1726607233285904\n",
      "\n",
      "episode 7, val func loss 0.1653337925672531\n",
      "\n",
      "episode 8, val func loss 0.1319308876991272\n",
      "\n",
      "episode 9, val func loss 0.196557879447937\n",
      "\n",
      "episode 10, val func loss 0.1328388750553131\n",
      "\n",
      "episode 11, val func loss 0.129679337143898\n",
      "\n",
      "episode 12, val func loss 0.21277062594890594\n",
      "\n",
      "episode 13, val func loss 0.19895727932453156\n",
      "\n",
      "episode 14, val func loss 0.15773460268974304\n",
      "\n",
      "episode 15, val func loss 0.18690034747123718\n",
      "\n",
      "episode 16, val func loss 0.16722124814987183\n",
      "\n",
      "Val func train loss in epoch 10:0.16518011037260294\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16839921474456787\n",
      "\n",
      "episode 2, val func loss 0.19874586164951324\n",
      "\n",
      "episode 3, val func loss 0.1286747008562088\n",
      "\n",
      "episode 4, val func loss 0.16318845748901367\n",
      "\n",
      "episode 5, val func loss 0.17305298149585724\n",
      "\n",
      "episode 6, val func loss 0.16713480651378632\n",
      "\n",
      "episode 7, val func loss 0.21050727367401123\n",
      "\n",
      "episode 8, val func loss 0.18171824514865875\n",
      "\n",
      "episode 9, val func loss 0.12456513941287994\n",
      "\n",
      "episode 10, val func loss 0.19519740343093872\n",
      "\n",
      "episode 11, val func loss 0.16524304449558258\n",
      "\n",
      "episode 12, val func loss 0.186838299036026\n",
      "\n",
      "episode 13, val func loss 0.1344568282365799\n",
      "\n",
      "episode 14, val func loss 0.15694290399551392\n",
      "\n",
      "episode 15, val func loss 0.15872931480407715\n",
      "\n",
      "episode 16, val func loss 0.13124366104602814\n",
      "\n",
      "Val func train loss in epoch 11:0.16528988350182772\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.16450746357440948\n",
      "\n",
      "episode 2, val func loss 0.1525886058807373\n",
      "\n",
      "episode 3, val func loss 0.11854978650808334\n",
      "\n",
      "episode 4, val func loss 0.16588693857192993\n",
      "\n",
      "episode 5, val func loss 0.13133613765239716\n",
      "\n",
      "episode 6, val func loss 0.17650264501571655\n",
      "\n",
      "episode 7, val func loss 0.17895035445690155\n",
      "\n",
      "episode 8, val func loss 0.13135595619678497\n",
      "\n",
      "episode 9, val func loss 0.1890679895877838\n",
      "\n",
      "episode 10, val func loss 0.1660550981760025\n",
      "\n",
      "episode 11, val func loss 0.1984410136938095\n",
      "\n",
      "episode 12, val func loss 0.18202388286590576\n",
      "\n",
      "episode 13, val func loss 0.20907987654209137\n",
      "\n",
      "episode 14, val func loss 0.1301141083240509\n",
      "\n",
      "episode 15, val func loss 0.16181039810180664\n",
      "\n",
      "episode 16, val func loss 0.19738668203353882\n",
      "\n",
      "Val func train loss in epoch 12:0.16585355857387185\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1665215939283371\n",
      "\n",
      "episode 2, val func loss 0.18188099563121796\n",
      "\n",
      "episode 3, val func loss 0.16777433454990387\n",
      "\n",
      "episode 4, val func loss 0.12145306169986725\n",
      "\n",
      "episode 5, val func loss 0.16515983641147614\n",
      "\n",
      "episode 6, val func loss 0.21652182936668396\n",
      "\n",
      "episode 7, val func loss 0.15972058475017548\n",
      "\n",
      "episode 8, val func loss 0.2021781951189041\n",
      "\n",
      "episode 9, val func loss 0.19796475768089294\n",
      "\n",
      "episode 10, val func loss 0.13206693530082703\n",
      "\n",
      "episode 11, val func loss 0.13217252492904663\n",
      "\n",
      "episode 12, val func loss 0.18818145990371704\n",
      "\n",
      "episode 13, val func loss 0.1627817153930664\n",
      "\n",
      "episode 14, val func loss 0.16457083821296692\n",
      "\n",
      "episode 15, val func loss 0.12873774766921997\n",
      "\n",
      "episode 16, val func loss 0.17342153191566467\n",
      "\n",
      "Val func train loss in epoch 13:0.16631924640387297\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.13575886189937592\n",
      "\n",
      "episode 2, val func loss 0.15881237387657166\n",
      "\n",
      "episode 3, val func loss 0.16761420667171478\n",
      "\n",
      "episode 4, val func loss 0.1956692785024643\n",
      "\n",
      "episode 5, val func loss 0.13247832655906677\n",
      "\n",
      "episode 6, val func loss 0.18196211755275726\n",
      "\n",
      "episode 7, val func loss 0.18884845077991486\n",
      "\n",
      "episode 8, val func loss 0.1196027472615242\n",
      "\n",
      "episode 9, val func loss 0.20133787393569946\n",
      "\n",
      "episode 10, val func loss 0.1302962750196457\n",
      "\n",
      "episode 11, val func loss 0.15449859201908112\n",
      "\n",
      "episode 12, val func loss 0.16257475316524506\n",
      "\n",
      "episode 13, val func loss 0.16686274111270905\n",
      "\n",
      "episode 14, val func loss 0.21240921318531036\n",
      "\n",
      "episode 15, val func loss 0.17260615527629852\n",
      "\n",
      "episode 16, val func loss 0.16737662255764008\n",
      "\n",
      "Val func train loss in epoch 14:0.1655442868359387\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18136994540691376\n",
      "\n",
      "episode 2, val func loss 0.13863204419612885\n",
      "\n",
      "episode 3, val func loss 0.20960766077041626\n",
      "\n",
      "episode 4, val func loss 0.17122343182563782\n",
      "\n",
      "episode 5, val func loss 0.1954004466533661\n",
      "\n",
      "episode 6, val func loss 0.16367869079113007\n",
      "\n",
      "episode 7, val func loss 0.15875114500522614\n",
      "\n",
      "episode 8, val func loss 0.12087702006101608\n",
      "\n",
      "episode 9, val func loss 0.13197502493858337\n",
      "\n",
      "episode 10, val func loss 0.19155597686767578\n",
      "\n",
      "episode 11, val func loss 0.17492231726646423\n",
      "\n",
      "episode 12, val func loss 0.1526724249124527\n",
      "\n",
      "episode 13, val func loss 0.1688312590122223\n",
      "\n",
      "episode 14, val func loss 0.20160646736621857\n",
      "\n",
      "episode 15, val func loss 0.13048715889453888\n",
      "\n",
      "episode 16, val func loss 0.16951972246170044\n",
      "\n",
      "Val func train loss in epoch 15:0.1663194210268557\n",
      "***********************TIME WAS 4.905289471149445 min*****************************\n",
      "\n",
      "**********************ROUND 40 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.0565955713391304\n",
      "\n",
      "episode 2, policy loss -0.11966221034526825\n",
      "\n",
      "episode 3, policy loss -0.09903635084629059\n",
      "\n",
      "episode 4, policy loss -0.09851738065481186\n",
      "\n",
      "episode 5, policy loss -0.08863198757171631\n",
      "\n",
      "episode 6, policy loss -0.06058123707771301\n",
      "\n",
      "episode 7, policy loss -0.11920386552810669\n",
      "\n",
      "episode 8, policy loss -0.10135498642921448\n",
      "\n",
      "episode 9, policy loss -0.05129718780517578\n",
      "\n",
      "episode 10, policy loss -0.0924341082572937\n",
      "\n",
      "episode 11, policy loss -0.07717093080282211\n",
      "\n",
      "episode 12, policy loss -0.07290982455015182\n",
      "\n",
      "episode 13, policy loss -0.10420210659503937\n",
      "\n",
      "episode 14, policy loss -0.11978578567504883\n",
      "\n",
      "episode 15, policy loss -0.05625002086162567\n",
      "\n",
      "episode 16, policy loss -0.024690400809049606\n",
      "\n",
      "Policy train loss in epoch 0:-0.08389524719677866\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.09759020060300827\n",
      "\n",
      "episode 2, policy loss -0.11483140289783478\n",
      "\n",
      "episode 3, policy loss -0.02499452605843544\n",
      "\n",
      "episode 4, policy loss -0.1025538519024849\n",
      "\n",
      "episode 5, policy loss -0.07494796812534332\n",
      "\n",
      "episode 6, policy loss -0.057956911623477936\n",
      "\n",
      "episode 7, policy loss -0.05844941735267639\n",
      "\n",
      "episode 8, policy loss -0.07600793987512589\n",
      "\n",
      "episode 9, policy loss -0.10217026621103287\n",
      "\n",
      "episode 10, policy loss -0.05925335735082626\n",
      "\n",
      "episode 11, policy loss -0.11580225825309753\n",
      "\n",
      "episode 12, policy loss -0.12072721123695374\n",
      "\n",
      "episode 13, policy loss -0.09091459214687347\n",
      "\n",
      "episode 14, policy loss -0.10342968255281448\n",
      "\n",
      "episode 15, policy loss -0.09407562017440796\n",
      "\n",
      "episode 16, policy loss -0.05283864587545395\n",
      "\n",
      "Policy train loss in epoch 1:-0.08415899076499045\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.1184292584657669\n",
      "\n",
      "episode 2, policy loss -0.07481686025857925\n",
      "\n",
      "episode 3, policy loss -0.08910506218671799\n",
      "\n",
      "episode 4, policy loss -0.05371762812137604\n",
      "\n",
      "episode 5, policy loss -0.09777890890836716\n",
      "\n",
      "episode 6, policy loss -0.11706642806529999\n",
      "\n",
      "episode 7, policy loss -0.02319856360554695\n",
      "\n",
      "episode 8, policy loss -0.09885537624359131\n",
      "\n",
      "episode 9, policy loss -0.11649157106876373\n",
      "\n",
      "episode 10, policy loss -0.05983215197920799\n",
      "\n",
      "episode 11, policy loss -0.058385416865348816\n",
      "\n",
      "episode 12, policy loss -0.09600004553794861\n",
      "\n",
      "episode 13, policy loss -0.10509628057479858\n",
      "\n",
      "episode 14, policy loss -0.10082528740167618\n",
      "\n",
      "episode 15, policy loss -0.07045231759548187\n",
      "\n",
      "episode 16, policy loss -0.054452408105134964\n",
      "\n",
      "Policy train loss in epoch 2:-0.0834064728114754\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.0710071325302124\n",
      "\n",
      "episode 2, policy loss -0.09630662202835083\n",
      "\n",
      "episode 3, policy loss -0.05476881191134453\n",
      "\n",
      "episode 4, policy loss -0.0588991716504097\n",
      "\n",
      "episode 5, policy loss -0.11860279738903046\n",
      "\n",
      "episode 6, policy loss -0.06026264280080795\n",
      "\n",
      "episode 7, policy loss -0.05647630989551544\n",
      "\n",
      "episode 8, policy loss -0.0980510488152504\n",
      "\n",
      "episode 9, policy loss -0.021616771817207336\n",
      "\n",
      "episode 10, policy loss -0.07418360561132431\n",
      "\n",
      "episode 11, policy loss -0.10407346487045288\n",
      "\n",
      "episode 12, policy loss -0.11809466779232025\n",
      "\n",
      "episode 13, policy loss -0.11879044771194458\n",
      "\n",
      "episode 14, policy loss -0.10202338546514511\n",
      "\n",
      "episode 15, policy loss -0.0890401229262352\n",
      "\n",
      "episode 16, policy loss -0.10078231990337372\n",
      "\n",
      "Policy train loss in epoch 3:-0.08393620769493282\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1988520473241806\n",
      "\n",
      "episode 2, val func loss 0.20591555535793304\n",
      "\n",
      "episode 3, val func loss 0.16189700365066528\n",
      "\n",
      "episode 4, val func loss 0.18845948576927185\n",
      "\n",
      "episode 5, val func loss 0.18001055717468262\n",
      "\n",
      "episode 6, val func loss 0.1648780256509781\n",
      "\n",
      "episode 7, val func loss 0.16112980246543884\n",
      "\n",
      "episode 8, val func loss 0.19685018062591553\n",
      "\n",
      "episode 9, val func loss 0.16169318556785583\n",
      "\n",
      "episode 10, val func loss 0.16113035380840302\n",
      "\n",
      "episode 11, val func loss 0.15743213891983032\n",
      "\n",
      "episode 12, val func loss 0.15269823372364044\n",
      "\n",
      "episode 13, val func loss 0.15294088423252106\n",
      "\n",
      "episode 14, val func loss 0.16897182166576385\n",
      "\n",
      "episode 15, val func loss 0.12489885091781616\n",
      "\n",
      "episode 16, val func loss 0.1804487407207489\n",
      "\n",
      "Val func train loss in epoch 0:0.16988792922347784\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.20172372460365295\n",
      "\n",
      "episode 2, val func loss 0.19633981585502625\n",
      "\n",
      "episode 3, val func loss 0.16103853285312653\n",
      "\n",
      "episode 4, val func loss 0.1642797887325287\n",
      "\n",
      "episode 5, val func loss 0.15633875131607056\n",
      "\n",
      "episode 6, val func loss 0.16745124757289886\n",
      "\n",
      "episode 7, val func loss 0.17575682699680328\n",
      "\n",
      "episode 8, val func loss 0.15836338698863983\n",
      "\n",
      "episode 9, val func loss 0.20727989077568054\n",
      "\n",
      "episode 10, val func loss 0.153812438249588\n",
      "\n",
      "episode 11, val func loss 0.1614983081817627\n",
      "\n",
      "episode 12, val func loss 0.12521147727966309\n",
      "\n",
      "episode 13, val func loss 0.1510981321334839\n",
      "\n",
      "episode 14, val func loss 0.18023857474327087\n",
      "\n",
      "episode 15, val func loss 0.18699482083320618\n",
      "\n",
      "episode 16, val func loss 0.161478191614151\n",
      "\n",
      "Val func train loss in epoch 1:0.16930649429559708\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1605205535888672\n",
      "\n",
      "episode 2, val func loss 0.16233153641223907\n",
      "\n",
      "episode 3, val func loss 0.12447576969861984\n",
      "\n",
      "episode 4, val func loss 0.1514458954334259\n",
      "\n",
      "episode 5, val func loss 0.15318644046783447\n",
      "\n",
      "episode 6, val func loss 0.15462496876716614\n",
      "\n",
      "episode 7, val func loss 0.1686336100101471\n",
      "\n",
      "episode 8, val func loss 0.197160005569458\n",
      "\n",
      "episode 9, val func loss 0.20726169645786285\n",
      "\n",
      "episode 10, val func loss 0.1605530083179474\n",
      "\n",
      "episode 11, val func loss 0.18079756200313568\n",
      "\n",
      "episode 12, val func loss 0.1984098255634308\n",
      "\n",
      "episode 13, val func loss 0.16624745726585388\n",
      "\n",
      "episode 14, val func loss 0.18594281375408173\n",
      "\n",
      "episode 15, val func loss 0.17664135992527008\n",
      "\n",
      "episode 16, val func loss 0.15904398262500763\n",
      "\n",
      "Val func train loss in epoch 2:0.16920478036627173\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.16366788744926453\n",
      "\n",
      "episode 2, val func loss 0.19614800810813904\n",
      "\n",
      "episode 3, val func loss 0.16244730353355408\n",
      "\n",
      "episode 4, val func loss 0.12402123957872391\n",
      "\n",
      "episode 5, val func loss 0.1526806801557541\n",
      "\n",
      "episode 6, val func loss 0.15355461835861206\n",
      "\n",
      "episode 7, val func loss 0.16333742439746857\n",
      "\n",
      "episode 8, val func loss 0.18044713139533997\n",
      "\n",
      "episode 9, val func loss 0.1742183417081833\n",
      "\n",
      "episode 10, val func loss 0.1550559550523758\n",
      "\n",
      "episode 11, val func loss 0.18599775433540344\n",
      "\n",
      "episode 12, val func loss 0.2064785361289978\n",
      "\n",
      "episode 13, val func loss 0.1985759288072586\n",
      "\n",
      "episode 14, val func loss 0.16597719490528107\n",
      "\n",
      "episode 15, val func loss 0.1679118424654007\n",
      "\n",
      "episode 16, val func loss 0.1597217470407486\n",
      "\n",
      "Val func train loss in epoch 3:0.1693900995887816\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17962008714675903\n",
      "\n",
      "episode 2, val func loss 0.15073759853839874\n",
      "\n",
      "episode 3, val func loss 0.15355941653251648\n",
      "\n",
      "episode 4, val func loss 0.1615907996892929\n",
      "\n",
      "episode 5, val func loss 0.12440478801727295\n",
      "\n",
      "episode 6, val func loss 0.15683193504810333\n",
      "\n",
      "episode 7, val func loss 0.19794298708438873\n",
      "\n",
      "episode 8, val func loss 0.21005211770534515\n",
      "\n",
      "episode 9, val func loss 0.1869926005601883\n",
      "\n",
      "episode 10, val func loss 0.1683914214372635\n",
      "\n",
      "episode 11, val func loss 0.16108310222625732\n",
      "\n",
      "episode 12, val func loss 0.17575114965438843\n",
      "\n",
      "episode 13, val func loss 0.1994108110666275\n",
      "\n",
      "episode 14, val func loss 0.16443496942520142\n",
      "\n",
      "episode 15, val func loss 0.15818190574645996\n",
      "\n",
      "episode 16, val func loss 0.1635645180940628\n",
      "\n",
      "Val func train loss in epoch 4:0.1695343879982829\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.15426141023635864\n",
      "\n",
      "episode 2, val func loss 0.2072063833475113\n",
      "\n",
      "episode 3, val func loss 0.15987947583198547\n",
      "\n",
      "episode 4, val func loss 0.2016814947128296\n",
      "\n",
      "episode 5, val func loss 0.16223834455013275\n",
      "\n",
      "episode 6, val func loss 0.16389502584934235\n",
      "\n",
      "episode 7, val func loss 0.151036337018013\n",
      "\n",
      "episode 8, val func loss 0.15732188522815704\n",
      "\n",
      "episode 9, val func loss 0.18571095168590546\n",
      "\n",
      "episode 10, val func loss 0.18001790344715118\n",
      "\n",
      "episode 11, val func loss 0.17506666481494904\n",
      "\n",
      "episode 12, val func loss 0.1558355838060379\n",
      "\n",
      "episode 13, val func loss 0.1609799563884735\n",
      "\n",
      "episode 14, val func loss 0.12690483033657074\n",
      "\n",
      "episode 15, val func loss 0.1962946504354477\n",
      "\n",
      "episode 16, val func loss 0.16830776631832123\n",
      "\n",
      "Val func train loss in epoch 5:0.16916491650044918\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.15716834366321564\n",
      "\n",
      "episode 2, val func loss 0.1549452245235443\n",
      "\n",
      "episode 3, val func loss 0.20846393704414368\n",
      "\n",
      "episode 4, val func loss 0.15304507315158844\n",
      "\n",
      "episode 5, val func loss 0.15094245970249176\n",
      "\n",
      "episode 6, val func loss 0.1994379311800003\n",
      "\n",
      "episode 7, val func loss 0.16747719049453735\n",
      "\n",
      "episode 8, val func loss 0.18617653846740723\n",
      "\n",
      "episode 9, val func loss 0.16106969118118286\n",
      "\n",
      "episode 10, val func loss 0.16565434634685516\n",
      "\n",
      "episode 11, val func loss 0.1811327189207077\n",
      "\n",
      "episode 12, val func loss 0.16054576635360718\n",
      "\n",
      "episode 13, val func loss 0.1636291891336441\n",
      "\n",
      "episode 14, val func loss 0.12737031280994415\n",
      "\n",
      "episode 15, val func loss 0.17400911450386047\n",
      "\n",
      "episode 16, val func loss 0.198220893740654\n",
      "\n",
      "Val func train loss in epoch 6:0.16933054570108652\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17499126493930817\n",
      "\n",
      "episode 2, val func loss 0.18286660313606262\n",
      "\n",
      "episode 3, val func loss 0.15987823903560638\n",
      "\n",
      "episode 4, val func loss 0.16442151367664337\n",
      "\n",
      "episode 5, val func loss 0.1533697545528412\n",
      "\n",
      "episode 6, val func loss 0.12411355972290039\n",
      "\n",
      "episode 7, val func loss 0.16416491568088531\n",
      "\n",
      "episode 8, val func loss 0.1864536553621292\n",
      "\n",
      "episode 9, val func loss 0.1621282994747162\n",
      "\n",
      "episode 10, val func loss 0.20627093315124512\n",
      "\n",
      "episode 11, val func loss 0.15927325189113617\n",
      "\n",
      "episode 12, val func loss 0.15620282292366028\n",
      "\n",
      "episode 13, val func loss 0.16744616627693176\n",
      "\n",
      "episode 14, val func loss 0.19896835088729858\n",
      "\n",
      "episode 15, val func loss 0.149557426571846\n",
      "\n",
      "episode 16, val func loss 0.19590091705322266\n",
      "\n",
      "Val func train loss in epoch 7:0.1691254796460271\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.19913822412490845\n",
      "\n",
      "episode 2, val func loss 0.1597229391336441\n",
      "\n",
      "episode 3, val func loss 0.1798793226480484\n",
      "\n",
      "episode 4, val func loss 0.19525595009326935\n",
      "\n",
      "episode 5, val func loss 0.16046935319900513\n",
      "\n",
      "episode 6, val func loss 0.16352479159832\n",
      "\n",
      "episode 7, val func loss 0.161093607544899\n",
      "\n",
      "episode 8, val func loss 0.16811701655387878\n",
      "\n",
      "episode 9, val func loss 0.18638794124126434\n",
      "\n",
      "episode 10, val func loss 0.12600602209568024\n",
      "\n",
      "episode 11, val func loss 0.16132232546806335\n",
      "\n",
      "episode 12, val func loss 0.20786543190479279\n",
      "\n",
      "episode 13, val func loss 0.1518033891916275\n",
      "\n",
      "episode 14, val func loss 0.155079647898674\n",
      "\n",
      "episode 15, val func loss 0.17413340508937836\n",
      "\n",
      "episode 16, val func loss 0.1536252647638321\n",
      "\n",
      "Val func train loss in epoch 8:0.16896403953433037\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1868019998073578\n",
      "\n",
      "episode 2, val func loss 0.1570836454629898\n",
      "\n",
      "episode 3, val func loss 0.15122215449810028\n",
      "\n",
      "episode 4, val func loss 0.19976916909217834\n",
      "\n",
      "episode 5, val func loss 0.153619647026062\n",
      "\n",
      "episode 6, val func loss 0.1612660139799118\n",
      "\n",
      "episode 7, val func loss 0.12832136452198029\n",
      "\n",
      "episode 8, val func loss 0.15589256584644318\n",
      "\n",
      "episode 9, val func loss 0.20676887035369873\n",
      "\n",
      "episode 10, val func loss 0.16343480348587036\n",
      "\n",
      "episode 11, val func loss 0.1800927072763443\n",
      "\n",
      "episode 12, val func loss 0.16107866168022156\n",
      "\n",
      "episode 13, val func loss 0.16193409264087677\n",
      "\n",
      "episode 14, val func loss 0.1677047461271286\n",
      "\n",
      "episode 15, val func loss 0.1742912381887436\n",
      "\n",
      "episode 16, val func loss 0.19646452367305756\n",
      "\n",
      "Val func train loss in epoch 9:0.1691091377288103\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1965014487504959\n",
      "\n",
      "episode 2, val func loss 0.16104406118392944\n",
      "\n",
      "episode 3, val func loss 0.1755957007408142\n",
      "\n",
      "episode 4, val func loss 0.20534169673919678\n",
      "\n",
      "episode 5, val func loss 0.16420377790927887\n",
      "\n",
      "episode 6, val func loss 0.15645167231559753\n",
      "\n",
      "episode 7, val func loss 0.16087810695171356\n",
      "\n",
      "episode 8, val func loss 0.17975391447544098\n",
      "\n",
      "episode 9, val func loss 0.1860204041004181\n",
      "\n",
      "episode 10, val func loss 0.1615050584077835\n",
      "\n",
      "episode 11, val func loss 0.15354396402835846\n",
      "\n",
      "episode 12, val func loss 0.1569843292236328\n",
      "\n",
      "episode 13, val func loss 0.15321069955825806\n",
      "\n",
      "episode 14, val func loss 0.20381712913513184\n",
      "\n",
      "episode 15, val func loss 0.12328857183456421\n",
      "\n",
      "episode 16, val func loss 0.1695401817560196\n",
      "\n",
      "Val func train loss in epoch 10:0.16923004481941462\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.15179091691970825\n",
      "\n",
      "episode 2, val func loss 0.16786783933639526\n",
      "\n",
      "episode 3, val func loss 0.16393741965293884\n",
      "\n",
      "episode 4, val func loss 0.12849146127700806\n",
      "\n",
      "episode 5, val func loss 0.2055136263370514\n",
      "\n",
      "episode 6, val func loss 0.15608660876750946\n",
      "\n",
      "episode 7, val func loss 0.1580527424812317\n",
      "\n",
      "episode 8, val func loss 0.15378440916538239\n",
      "\n",
      "episode 9, val func loss 0.20109322667121887\n",
      "\n",
      "episode 10, val func loss 0.1965024769306183\n",
      "\n",
      "episode 11, val func loss 0.1806361824274063\n",
      "\n",
      "episode 12, val func loss 0.16165542602539062\n",
      "\n",
      "episode 13, val func loss 0.18624426424503326\n",
      "\n",
      "episode 14, val func loss 0.1610395461320877\n",
      "\n",
      "episode 15, val func loss 0.1751653403043747\n",
      "\n",
      "episode 16, val func loss 0.1626582145690918\n",
      "\n",
      "Val func train loss in epoch 11:0.16940748132765293\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1750946342945099\n",
      "\n",
      "episode 2, val func loss 0.15731893479824066\n",
      "\n",
      "episode 3, val func loss 0.15065594017505646\n",
      "\n",
      "episode 4, val func loss 0.2084445208311081\n",
      "\n",
      "episode 5, val func loss 0.1556994467973709\n",
      "\n",
      "episode 6, val func loss 0.1533801257610321\n",
      "\n",
      "episode 7, val func loss 0.16209757328033447\n",
      "\n",
      "episode 8, val func loss 0.16857650876045227\n",
      "\n",
      "episode 9, val func loss 0.19629812240600586\n",
      "\n",
      "episode 10, val func loss 0.16272637248039246\n",
      "\n",
      "episode 11, val func loss 0.1605876088142395\n",
      "\n",
      "episode 12, val func loss 0.12795250117778778\n",
      "\n",
      "episode 13, val func loss 0.17989401519298553\n",
      "\n",
      "episode 14, val func loss 0.18622100353240967\n",
      "\n",
      "episode 15, val func loss 0.20005019009113312\n",
      "\n",
      "episode 16, val func loss 0.16301120817661285\n",
      "\n",
      "Val func train loss in epoch 12:0.16925054416060448\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.20687808096408844\n",
      "\n",
      "episode 2, val func loss 0.15568426251411438\n",
      "\n",
      "episode 3, val func loss 0.15752002596855164\n",
      "\n",
      "episode 4, val func loss 0.14993901550769806\n",
      "\n",
      "episode 5, val func loss 0.16753269731998444\n",
      "\n",
      "episode 6, val func loss 0.18611447513103485\n",
      "\n",
      "episode 7, val func loss 0.19902047514915466\n",
      "\n",
      "episode 8, val func loss 0.17593169212341309\n",
      "\n",
      "episode 9, val func loss 0.16005422174930573\n",
      "\n",
      "episode 10, val func loss 0.1611015498638153\n",
      "\n",
      "episode 11, val func loss 0.16457468271255493\n",
      "\n",
      "episode 12, val func loss 0.17972104251384735\n",
      "\n",
      "episode 13, val func loss 0.1271624118089676\n",
      "\n",
      "episode 14, val func loss 0.19610244035720825\n",
      "\n",
      "episode 15, val func loss 0.15323305130004883\n",
      "\n",
      "episode 16, val func loss 0.1598755568265915\n",
      "\n",
      "Val func train loss in epoch 13:0.1687778551131487\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.16419366002082825\n",
      "\n",
      "episode 2, val func loss 0.1818428337574005\n",
      "\n",
      "episode 3, val func loss 0.16317196190357208\n",
      "\n",
      "episode 4, val func loss 0.20757193863391876\n",
      "\n",
      "episode 5, val func loss 0.15417754650115967\n",
      "\n",
      "episode 6, val func loss 0.195889413356781\n",
      "\n",
      "episode 7, val func loss 0.1569371223449707\n",
      "\n",
      "episode 8, val func loss 0.1677931547164917\n",
      "\n",
      "episode 9, val func loss 0.16403046250343323\n",
      "\n",
      "episode 10, val func loss 0.1858353465795517\n",
      "\n",
      "episode 11, val func loss 0.15006734430789948\n",
      "\n",
      "episode 12, val func loss 0.1569717675447464\n",
      "\n",
      "episode 13, val func loss 0.12540513277053833\n",
      "\n",
      "episode 14, val func loss 0.1742851436138153\n",
      "\n",
      "episode 15, val func loss 0.16478943824768066\n",
      "\n",
      "episode 16, val func loss 0.20527590811252594\n",
      "\n",
      "Val func train loss in epoch 14:0.1698898859322071\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20313309133052826\n",
      "\n",
      "episode 2, val func loss 0.1613813042640686\n",
      "\n",
      "episode 3, val func loss 0.19549942016601562\n",
      "\n",
      "episode 4, val func loss 0.15759073197841644\n",
      "\n",
      "episode 5, val func loss 0.1771550178527832\n",
      "\n",
      "episode 6, val func loss 0.1571592390537262\n",
      "\n",
      "episode 7, val func loss 0.15002290904521942\n",
      "\n",
      "episode 8, val func loss 0.16756688058376312\n",
      "\n",
      "episode 9, val func loss 0.1798701137304306\n",
      "\n",
      "episode 10, val func loss 0.12715093791484833\n",
      "\n",
      "episode 11, val func loss 0.18638592958450317\n",
      "\n",
      "episode 12, val func loss 0.20891828835010529\n",
      "\n",
      "episode 13, val func loss 0.16083665192127228\n",
      "\n",
      "episode 14, val func loss 0.15739229321479797\n",
      "\n",
      "episode 15, val func loss 0.1635119765996933\n",
      "\n",
      "episode 16, val func loss 0.16261625289916992\n",
      "\n",
      "Val func train loss in epoch 15:0.16976193990558386\n",
      "***********************TIME WAS 4.91310654481252 min*****************************\n",
      "\n",
      "**********************ROUND 41 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.14312227070331573\n",
      "\n",
      "episode 2, policy loss -0.0408388115465641\n",
      "\n",
      "episode 3, policy loss -0.05200006067752838\n",
      "\n",
      "episode 4, policy loss -0.11483436822891235\n",
      "\n",
      "episode 5, policy loss -0.0855104997754097\n",
      "\n",
      "episode 6, policy loss -0.09179559350013733\n",
      "\n",
      "episode 7, policy loss -0.10510607063770294\n",
      "\n",
      "episode 8, policy loss -0.09177395701408386\n",
      "\n",
      "episode 9, policy loss -0.08181031048297882\n",
      "\n",
      "episode 10, policy loss -0.09176185727119446\n",
      "\n",
      "episode 11, policy loss -0.10935163497924805\n",
      "\n",
      "episode 12, policy loss -0.15649068355560303\n",
      "\n",
      "episode 13, policy loss -0.13147005438804626\n",
      "\n",
      "episode 14, policy loss -0.11141948401927948\n",
      "\n",
      "episode 15, policy loss -0.07243113219738007\n",
      "\n",
      "episode 16, policy loss -0.16167283058166504\n",
      "\n",
      "Policy train loss in epoch 0:-0.1025868512224406\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.07299983501434326\n",
      "\n",
      "episode 2, policy loss -0.08717641979455948\n",
      "\n",
      "episode 3, policy loss -0.08256612718105316\n",
      "\n",
      "episode 4, policy loss -0.13221275806427002\n",
      "\n",
      "episode 5, policy loss -0.09282134473323822\n",
      "\n",
      "episode 6, policy loss -0.09481421113014221\n",
      "\n",
      "episode 7, policy loss -0.10890346020460129\n",
      "\n",
      "episode 8, policy loss -0.11412281543016434\n",
      "\n",
      "episode 9, policy loss -0.11045674234628677\n",
      "\n",
      "episode 10, policy loss -0.16040144860744476\n",
      "\n",
      "episode 11, policy loss -0.042370449751615524\n",
      "\n",
      "episode 12, policy loss -0.051637113094329834\n",
      "\n",
      "episode 13, policy loss -0.16212762892246246\n",
      "\n",
      "episode 14, policy loss -0.09054677188396454\n",
      "\n",
      "episode 15, policy loss -0.14877456426620483\n",
      "\n",
      "episode 16, policy loss -0.11763136088848114\n",
      "\n",
      "Policy train loss in epoch 1:-0.10434769070707262\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.11591879278421402\n",
      "\n",
      "episode 2, policy loss -0.0840011015534401\n",
      "\n",
      "episode 3, policy loss -0.09723746031522751\n",
      "\n",
      "episode 4, policy loss -0.15996354818344116\n",
      "\n",
      "episode 5, policy loss -0.15001332759857178\n",
      "\n",
      "episode 6, policy loss -0.08994363993406296\n",
      "\n",
      "episode 7, policy loss -0.11148953437805176\n",
      "\n",
      "episode 8, policy loss -0.09321223944425583\n",
      "\n",
      "episode 9, policy loss -0.0396636426448822\n",
      "\n",
      "episode 10, policy loss -0.13184615969657898\n",
      "\n",
      "episode 11, policy loss -0.0923762246966362\n",
      "\n",
      "episode 12, policy loss -0.07046223431825638\n",
      "\n",
      "episode 13, policy loss -0.15885645151138306\n",
      "\n",
      "episode 14, policy loss -0.11718669533729553\n",
      "\n",
      "episode 15, policy loss -0.05164105445146561\n",
      "\n",
      "episode 16, policy loss -0.11093680560588837\n",
      "\n",
      "Policy train loss in epoch 2:-0.10467180702835321\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.15944954752922058\n",
      "\n",
      "episode 2, policy loss -0.11815561354160309\n",
      "\n",
      "episode 3, policy loss -0.0419936329126358\n",
      "\n",
      "episode 4, policy loss -0.14820443093776703\n",
      "\n",
      "episode 5, policy loss -0.11495611071586609\n",
      "\n",
      "episode 6, policy loss -0.10738515853881836\n",
      "\n",
      "episode 7, policy loss -0.1595839560031891\n",
      "\n",
      "episode 8, policy loss -0.09285430610179901\n",
      "\n",
      "episode 9, policy loss -0.09002966433763504\n",
      "\n",
      "episode 10, policy loss -0.13190054893493652\n",
      "\n",
      "episode 11, policy loss -0.08255341649055481\n",
      "\n",
      "episode 12, policy loss -0.0513698011636734\n",
      "\n",
      "episode 13, policy loss -0.10788565874099731\n",
      "\n",
      "episode 14, policy loss -0.08886312693357468\n",
      "\n",
      "episode 15, policy loss -0.07050728797912598\n",
      "\n",
      "episode 16, policy loss -0.09070046246051788\n",
      "\n",
      "Policy train loss in epoch 3:-0.10352454520761967\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1281968504190445\n",
      "\n",
      "episode 2, val func loss 0.17511160671710968\n",
      "\n",
      "episode 3, val func loss 0.14123956859111786\n",
      "\n",
      "episode 4, val func loss 0.1832505315542221\n",
      "\n",
      "episode 5, val func loss 0.21622587740421295\n",
      "\n",
      "episode 6, val func loss 0.1474105268716812\n",
      "\n",
      "episode 7, val func loss 0.17001120746135712\n",
      "\n",
      "episode 8, val func loss 0.15659093856811523\n",
      "\n",
      "episode 9, val func loss 0.1763775646686554\n",
      "\n",
      "episode 10, val func loss 0.17453008890151978\n",
      "\n",
      "episode 11, val func loss 0.17335425317287445\n",
      "\n",
      "episode 12, val func loss 0.17702384293079376\n",
      "\n",
      "episode 13, val func loss 0.1469661295413971\n",
      "\n",
      "episode 14, val func loss 0.15946519374847412\n",
      "\n",
      "episode 15, val func loss 0.1815102994441986\n",
      "\n",
      "episode 16, val func loss 0.13003598153591156\n",
      "\n",
      "Val func train loss in epoch 0:0.16483127884566784\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1769474744796753\n",
      "\n",
      "episode 2, val func loss 0.128409281373024\n",
      "\n",
      "episode 3, val func loss 0.17488335072994232\n",
      "\n",
      "episode 4, val func loss 0.1698240488767624\n",
      "\n",
      "episode 5, val func loss 0.15606030821800232\n",
      "\n",
      "episode 6, val func loss 0.17405655980110168\n",
      "\n",
      "episode 7, val func loss 0.18310926854610443\n",
      "\n",
      "episode 8, val func loss 0.1748359501361847\n",
      "\n",
      "episode 9, val func loss 0.15878696739673615\n",
      "\n",
      "episode 10, val func loss 0.21543283760547638\n",
      "\n",
      "episode 11, val func loss 0.17543554306030273\n",
      "\n",
      "episode 12, val func loss 0.15024413168430328\n",
      "\n",
      "episode 13, val func loss 0.1284991353750229\n",
      "\n",
      "episode 14, val func loss 0.18132621049880981\n",
      "\n",
      "episode 15, val func loss 0.1418597549200058\n",
      "\n",
      "episode 16, val func loss 0.14702707529067993\n",
      "\n",
      "Val func train loss in epoch 1:0.16479611862450838\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1298295110464096\n",
      "\n",
      "episode 2, val func loss 0.15855762362480164\n",
      "\n",
      "episode 3, val func loss 0.17477092146873474\n",
      "\n",
      "episode 4, val func loss 0.17844942212104797\n",
      "\n",
      "episode 5, val func loss 0.21990127861499786\n",
      "\n",
      "episode 6, val func loss 0.1750495433807373\n",
      "\n",
      "episode 7, val func loss 0.14400994777679443\n",
      "\n",
      "episode 8, val func loss 0.17803706228733063\n",
      "\n",
      "episode 9, val func loss 0.12807787954807281\n",
      "\n",
      "episode 10, val func loss 0.15683992207050323\n",
      "\n",
      "episode 11, val func loss 0.1726180762052536\n",
      "\n",
      "episode 12, val func loss 0.14187534153461456\n",
      "\n",
      "episode 13, val func loss 0.15305127203464508\n",
      "\n",
      "episode 14, val func loss 0.16939298808574677\n",
      "\n",
      "episode 15, val func loss 0.18167175352573395\n",
      "\n",
      "episode 16, val func loss 0.1822984218597412\n",
      "\n",
      "Val func train loss in epoch 2:0.16527693532407284\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1572790890932083\n",
      "\n",
      "episode 2, val func loss 0.17375127971172333\n",
      "\n",
      "episode 3, val func loss 0.17535509169101715\n",
      "\n",
      "episode 4, val func loss 0.12827947735786438\n",
      "\n",
      "episode 5, val func loss 0.16959775984287262\n",
      "\n",
      "episode 6, val func loss 0.17723917961120605\n",
      "\n",
      "episode 7, val func loss 0.14135342836380005\n",
      "\n",
      "episode 8, val func loss 0.1747860312461853\n",
      "\n",
      "episode 9, val func loss 0.18164025247097015\n",
      "\n",
      "episode 10, val func loss 0.13006357848644257\n",
      "\n",
      "episode 11, val func loss 0.21407973766326904\n",
      "\n",
      "episode 12, val func loss 0.14580920338630676\n",
      "\n",
      "episode 13, val func loss 0.15863236784934998\n",
      "\n",
      "episode 14, val func loss 0.17533764243125916\n",
      "\n",
      "episode 15, val func loss 0.18345582485198975\n",
      "\n",
      "episode 16, val func loss 0.14398930966854095\n",
      "\n",
      "Val func train loss in epoch 3:0.16441557835787535\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.14273755252361298\n",
      "\n",
      "episode 2, val func loss 0.17964546382427216\n",
      "\n",
      "episode 3, val func loss 0.18622291088104248\n",
      "\n",
      "episode 4, val func loss 0.12976345419883728\n",
      "\n",
      "episode 5, val func loss 0.2217310518026352\n",
      "\n",
      "episode 6, val func loss 0.12616270780563354\n",
      "\n",
      "episode 7, val func loss 0.16999946534633636\n",
      "\n",
      "episode 8, val func loss 0.14578261971473694\n",
      "\n",
      "episode 9, val func loss 0.17467010021209717\n",
      "\n",
      "episode 10, val func loss 0.18121010065078735\n",
      "\n",
      "episode 11, val func loss 0.15939468145370483\n",
      "\n",
      "episode 12, val func loss 0.15846653282642365\n",
      "\n",
      "episode 13, val func loss 0.17812113463878632\n",
      "\n",
      "episode 14, val func loss 0.1418752819299698\n",
      "\n",
      "episode 15, val func loss 0.17377407848834991\n",
      "\n",
      "episode 16, val func loss 0.17719727754592896\n",
      "\n",
      "Val func train loss in epoch 4:0.16542215086519718\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1772925853729248\n",
      "\n",
      "episode 2, val func loss 0.17572656273841858\n",
      "\n",
      "episode 3, val func loss 0.12812207639217377\n",
      "\n",
      "episode 4, val func loss 0.17823095619678497\n",
      "\n",
      "episode 5, val func loss 0.14168380200862885\n",
      "\n",
      "episode 6, val func loss 0.1866535097360611\n",
      "\n",
      "episode 7, val func loss 0.21717648208141327\n",
      "\n",
      "episode 8, val func loss 0.17440764605998993\n",
      "\n",
      "episode 9, val func loss 0.12821587920188904\n",
      "\n",
      "episode 10, val func loss 0.1580152064561844\n",
      "\n",
      "episode 11, val func loss 0.15927168726921082\n",
      "\n",
      "episode 12, val func loss 0.1727810800075531\n",
      "\n",
      "episode 13, val func loss 0.1829645186662674\n",
      "\n",
      "episode 14, val func loss 0.16996781527996063\n",
      "\n",
      "episode 15, val func loss 0.15162409842014313\n",
      "\n",
      "episode 16, val func loss 0.1459539532661438\n",
      "\n",
      "Val func train loss in epoch 5:0.16550549119710922\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1281091719865799\n",
      "\n",
      "episode 2, val func loss 0.17451506853103638\n",
      "\n",
      "episode 3, val func loss 0.18198585510253906\n",
      "\n",
      "episode 4, val func loss 0.14453774690628052\n",
      "\n",
      "episode 5, val func loss 0.1258845180273056\n",
      "\n",
      "episode 6, val func loss 0.15757890045642853\n",
      "\n",
      "episode 7, val func loss 0.1719178408384323\n",
      "\n",
      "episode 8, val func loss 0.187604621052742\n",
      "\n",
      "episode 9, val func loss 0.15866561233997345\n",
      "\n",
      "episode 10, val func loss 0.14613260328769684\n",
      "\n",
      "episode 11, val func loss 0.14143404364585876\n",
      "\n",
      "episode 12, val func loss 0.1741723269224167\n",
      "\n",
      "episode 13, val func loss 0.17678576707839966\n",
      "\n",
      "episode 14, val func loss 0.17309898138046265\n",
      "\n",
      "episode 15, val func loss 0.18250039219856262\n",
      "\n",
      "episode 16, val func loss 0.21364299952983856\n",
      "\n",
      "Val func train loss in epoch 6:0.1649104030802846\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1506807804107666\n",
      "\n",
      "episode 2, val func loss 0.158973827958107\n",
      "\n",
      "episode 3, val func loss 0.14102540910243988\n",
      "\n",
      "episode 4, val func loss 0.1289406418800354\n",
      "\n",
      "episode 5, val func loss 0.16982731223106384\n",
      "\n",
      "episode 6, val func loss 0.1787014603614807\n",
      "\n",
      "episode 7, val func loss 0.17506836354732513\n",
      "\n",
      "episode 8, val func loss 0.1751699000597\n",
      "\n",
      "episode 9, val func loss 0.1840752810239792\n",
      "\n",
      "episode 10, val func loss 0.15707822144031525\n",
      "\n",
      "episode 11, val func loss 0.12859384715557098\n",
      "\n",
      "episode 12, val func loss 0.17783692479133606\n",
      "\n",
      "episode 13, val func loss 0.2137361615896225\n",
      "\n",
      "episode 14, val func loss 0.1827220469713211\n",
      "\n",
      "episode 15, val func loss 0.17583975195884705\n",
      "\n",
      "episode 16, val func loss 0.14803652465343475\n",
      "\n",
      "Val func train loss in epoch 7:0.1653941534459591\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.14692071080207825\n",
      "\n",
      "episode 2, val func loss 0.1589764952659607\n",
      "\n",
      "episode 3, val func loss 0.17795541882514954\n",
      "\n",
      "episode 4, val func loss 0.17486882209777832\n",
      "\n",
      "episode 5, val func loss 0.1565544307231903\n",
      "\n",
      "episode 6, val func loss 0.17035625874996185\n",
      "\n",
      "episode 7, val func loss 0.17587433755397797\n",
      "\n",
      "episode 8, val func loss 0.17492517828941345\n",
      "\n",
      "episode 9, val func loss 0.18318404257297516\n",
      "\n",
      "episode 10, val func loss 0.18292754888534546\n",
      "\n",
      "episode 11, val func loss 0.15060658752918243\n",
      "\n",
      "episode 12, val func loss 0.1283893585205078\n",
      "\n",
      "episode 13, val func loss 0.12865695357322693\n",
      "\n",
      "episode 14, val func loss 0.1769958883523941\n",
      "\n",
      "episode 15, val func loss 0.1414489597082138\n",
      "\n",
      "episode 16, val func loss 0.21612246334552765\n",
      "\n",
      "Val func train loss in epoch 8:0.16529771592468023\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17333078384399414\n",
      "\n",
      "episode 2, val func loss 0.17726334929466248\n",
      "\n",
      "episode 3, val func loss 0.15859851241111755\n",
      "\n",
      "episode 4, val func loss 0.14958806335926056\n",
      "\n",
      "episode 5, val func loss 0.16971167922019958\n",
      "\n",
      "episode 6, val func loss 0.17634257674217224\n",
      "\n",
      "episode 7, val func loss 0.1586190164089203\n",
      "\n",
      "episode 8, val func loss 0.141092911362648\n",
      "\n",
      "episode 9, val func loss 0.17542974650859833\n",
      "\n",
      "episode 10, val func loss 0.17464497685432434\n",
      "\n",
      "episode 11, val func loss 0.21620473265647888\n",
      "\n",
      "episode 12, val func loss 0.18277417123317719\n",
      "\n",
      "episode 13, val func loss 0.1287020891904831\n",
      "\n",
      "episode 14, val func loss 0.1832144409418106\n",
      "\n",
      "episode 15, val func loss 0.14761146903038025\n",
      "\n",
      "episode 16, val func loss 0.13011805713176727\n",
      "\n",
      "Val func train loss in epoch 9:0.16520291101187468\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.14683164656162262\n",
      "\n",
      "episode 2, val func loss 0.17457722127437592\n",
      "\n",
      "episode 3, val func loss 0.18356063961982727\n",
      "\n",
      "episode 4, val func loss 0.1444779485464096\n",
      "\n",
      "episode 5, val func loss 0.12901224195957184\n",
      "\n",
      "episode 6, val func loss 0.1838397979736328\n",
      "\n",
      "episode 7, val func loss 0.17569467425346375\n",
      "\n",
      "episode 8, val func loss 0.15853117406368256\n",
      "\n",
      "episode 9, val func loss 0.17528189718723297\n",
      "\n",
      "episode 10, val func loss 0.1778280884027481\n",
      "\n",
      "episode 11, val func loss 0.21344560384750366\n",
      "\n",
      "episode 12, val func loss 0.18101811408996582\n",
      "\n",
      "episode 13, val func loss 0.15952421724796295\n",
      "\n",
      "episode 14, val func loss 0.13329894840717316\n",
      "\n",
      "episode 15, val func loss 0.14172984659671783\n",
      "\n",
      "episode 16, val func loss 0.1695072203874588\n",
      "\n",
      "Val func train loss in epoch 10:0.16550995502620935\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1282864212989807\n",
      "\n",
      "episode 2, val func loss 0.17756354808807373\n",
      "\n",
      "episode 3, val func loss 0.15830105543136597\n",
      "\n",
      "episode 4, val func loss 0.17440049350261688\n",
      "\n",
      "episode 5, val func loss 0.14143873751163483\n",
      "\n",
      "episode 6, val func loss 0.17607936263084412\n",
      "\n",
      "episode 7, val func loss 0.18345226347446442\n",
      "\n",
      "episode 8, val func loss 0.14542829990386963\n",
      "\n",
      "episode 9, val func loss 0.1767728328704834\n",
      "\n",
      "episode 10, val func loss 0.1459435224533081\n",
      "\n",
      "episode 11, val func loss 0.15707527101039886\n",
      "\n",
      "episode 12, val func loss 0.1268865317106247\n",
      "\n",
      "episode 13, val func loss 0.18383219838142395\n",
      "\n",
      "episode 14, val func loss 0.22108666598796844\n",
      "\n",
      "episode 15, val func loss 0.1709769368171692\n",
      "\n",
      "episode 16, val func loss 0.175214484333992\n",
      "\n",
      "Val func train loss in epoch 11:0.16517116408795118\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.14125509560108185\n",
      "\n",
      "episode 2, val func loss 0.17706091701984406\n",
      "\n",
      "episode 3, val func loss 0.16949738562107086\n",
      "\n",
      "episode 4, val func loss 0.14876750111579895\n",
      "\n",
      "episode 5, val func loss 0.1719120442867279\n",
      "\n",
      "episode 6, val func loss 0.12881332635879517\n",
      "\n",
      "episode 7, val func loss 0.17364028096199036\n",
      "\n",
      "episode 8, val func loss 0.13193954527378082\n",
      "\n",
      "episode 9, val func loss 0.15073417127132416\n",
      "\n",
      "episode 10, val func loss 0.15845179557800293\n",
      "\n",
      "episode 11, val func loss 0.15702365338802338\n",
      "\n",
      "episode 12, val func loss 0.1745702177286148\n",
      "\n",
      "episode 13, val func loss 0.18526165187358856\n",
      "\n",
      "episode 14, val func loss 0.2218971699476242\n",
      "\n",
      "episode 15, val func loss 0.1883968561887741\n",
      "\n",
      "episode 16, val func loss 0.17467838525772095\n",
      "\n",
      "Val func train loss in epoch 12:0.1658687498420477\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.15867458283901215\n",
      "\n",
      "episode 2, val func loss 0.18207144737243652\n",
      "\n",
      "episode 3, val func loss 0.17736020684242249\n",
      "\n",
      "episode 4, val func loss 0.18032173812389374\n",
      "\n",
      "episode 5, val func loss 0.159263014793396\n",
      "\n",
      "episode 6, val func loss 0.14989207684993744\n",
      "\n",
      "episode 7, val func loss 0.14278644323349\n",
      "\n",
      "episode 8, val func loss 0.1531362533569336\n",
      "\n",
      "episode 9, val func loss 0.1740460842847824\n",
      "\n",
      "episode 10, val func loss 0.16928794980049133\n",
      "\n",
      "episode 11, val func loss 0.12776410579681396\n",
      "\n",
      "episode 12, val func loss 0.12838442623615265\n",
      "\n",
      "episode 13, val func loss 0.17499969899654388\n",
      "\n",
      "episode 14, val func loss 0.22040694952011108\n",
      "\n",
      "episode 15, val func loss 0.1746111810207367\n",
      "\n",
      "episode 16, val func loss 0.17662407457828522\n",
      "\n",
      "Val func train loss in epoch 13:0.16560188960283995\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.14423339068889618\n",
      "\n",
      "episode 2, val func loss 0.18398438394069672\n",
      "\n",
      "episode 3, val func loss 0.1828632354736328\n",
      "\n",
      "episode 4, val func loss 0.17411983013153076\n",
      "\n",
      "episode 5, val func loss 0.15940327942371368\n",
      "\n",
      "episode 6, val func loss 0.17607328295707703\n",
      "\n",
      "episode 7, val func loss 0.1428402215242386\n",
      "\n",
      "episode 8, val func loss 0.2128565013408661\n",
      "\n",
      "episode 9, val func loss 0.17814864218235016\n",
      "\n",
      "episode 10, val func loss 0.15433433651924133\n",
      "\n",
      "episode 11, val func loss 0.1778172254562378\n",
      "\n",
      "episode 12, val func loss 0.17330898344516754\n",
      "\n",
      "episode 13, val func loss 0.12818090617656708\n",
      "\n",
      "episode 14, val func loss 0.15725204348564148\n",
      "\n",
      "episode 15, val func loss 0.17118805646896362\n",
      "\n",
      "episode 16, val func loss 0.12604956328868866\n",
      "\n",
      "Val func train loss in epoch 14:0.16516586765646935\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1754971444606781\n",
      "\n",
      "episode 2, val func loss 0.18212111294269562\n",
      "\n",
      "episode 3, val func loss 0.1420566886663437\n",
      "\n",
      "episode 4, val func loss 0.14432784914970398\n",
      "\n",
      "episode 5, val func loss 0.15691113471984863\n",
      "\n",
      "episode 6, val func loss 0.14525634050369263\n",
      "\n",
      "episode 7, val func loss 0.12768606841564178\n",
      "\n",
      "episode 8, val func loss 0.16962748765945435\n",
      "\n",
      "episode 9, val func loss 0.18339240550994873\n",
      "\n",
      "episode 10, val func loss 0.17474541068077087\n",
      "\n",
      "episode 11, val func loss 0.15834401547908783\n",
      "\n",
      "episode 12, val func loss 0.21643948554992676\n",
      "\n",
      "episode 13, val func loss 0.18351294100284576\n",
      "\n",
      "episode 14, val func loss 0.17774899303913116\n",
      "\n",
      "episode 15, val func loss 0.1726948767900467\n",
      "\n",
      "episode 16, val func loss 0.12871690094470978\n",
      "\n",
      "Val func train loss in epoch 15:0.1649424284696579\n",
      "***********************TIME WAS 4.910353235403696 min*****************************\n",
      "\n",
      "**********************ROUND 42 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.03311161696910858\n",
      "\n",
      "episode 2, policy loss 0.007432777434587479\n",
      "\n",
      "episode 3, policy loss -0.08128632605075836\n",
      "\n",
      "episode 4, policy loss -0.05492626130580902\n",
      "\n",
      "episode 5, policy loss -0.02164366841316223\n",
      "\n",
      "episode 6, policy loss -0.07825794070959091\n",
      "\n",
      "episode 7, policy loss -0.03296507149934769\n",
      "\n",
      "episode 8, policy loss -0.07296401262283325\n",
      "\n",
      "episode 9, policy loss -0.07830855250358582\n",
      "\n",
      "episode 10, policy loss -0.037433281540870667\n",
      "\n",
      "episode 11, policy loss -0.04810851439833641\n",
      "\n",
      "episode 12, policy loss -0.043559618294239044\n",
      "\n",
      "episode 13, policy loss -0.05297689139842987\n",
      "\n",
      "episode 14, policy loss -0.013691084459424019\n",
      "\n",
      "episode 15, policy loss -0.07689444720745087\n",
      "\n",
      "episode 16, policy loss -0.059419095516204834\n",
      "\n",
      "Policy train loss in epoch 0:-0.048632100340910256\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.0805375725030899\n",
      "\n",
      "episode 2, policy loss -0.07690626382827759\n",
      "\n",
      "episode 3, policy loss -0.03937102481722832\n",
      "\n",
      "episode 4, policy loss -0.08412058651447296\n",
      "\n",
      "episode 5, policy loss -0.04170337691903114\n",
      "\n",
      "episode 6, policy loss -0.014052269980311394\n",
      "\n",
      "episode 7, policy loss -0.05562724173069\n",
      "\n",
      "episode 8, policy loss -0.058902353048324585\n",
      "\n",
      "episode 9, policy loss -0.05346505343914032\n",
      "\n",
      "episode 10, policy loss -0.07390902936458588\n",
      "\n",
      "episode 11, policy loss -0.03519696369767189\n",
      "\n",
      "episode 12, policy loss -0.02187146246433258\n",
      "\n",
      "episode 13, policy loss -0.07536071538925171\n",
      "\n",
      "episode 14, policy loss 0.010654628276824951\n",
      "\n",
      "episode 15, policy loss -0.051591984927654266\n",
      "\n",
      "episode 16, policy loss -0.03234398365020752\n",
      "\n",
      "Policy train loss in epoch 1:-0.04901907837484032\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.03705567866563797\n",
      "\n",
      "episode 2, policy loss -0.03298678994178772\n",
      "\n",
      "episode 3, policy loss -0.05512470752000809\n",
      "\n",
      "episode 4, policy loss -0.019799886271357536\n",
      "\n",
      "episode 5, policy loss -0.08452421426773071\n",
      "\n",
      "episode 6, policy loss -0.07768264412879944\n",
      "\n",
      "episode 7, policy loss 0.007288884371519089\n",
      "\n",
      "episode 8, policy loss -0.05090118572115898\n",
      "\n",
      "episode 9, policy loss -0.03263888880610466\n",
      "\n",
      "episode 10, policy loss -0.051118943840265274\n",
      "\n",
      "episode 11, policy loss -0.07914799451828003\n",
      "\n",
      "episode 12, policy loss -0.04031191021203995\n",
      "\n",
      "episode 13, policy loss -0.05795535072684288\n",
      "\n",
      "episode 14, policy loss -0.07674835622310638\n",
      "\n",
      "episode 15, policy loss -0.01185525767505169\n",
      "\n",
      "episode 16, policy loss -0.07370206713676453\n",
      "\n",
      "Policy train loss in epoch 2:-0.04839156195521355\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.07861832529306412\n",
      "\n",
      "episode 2, policy loss 0.010194789618253708\n",
      "\n",
      "episode 3, policy loss -0.05636666715145111\n",
      "\n",
      "episode 4, policy loss -0.03645654767751694\n",
      "\n",
      "episode 5, policy loss -0.05453813076019287\n",
      "\n",
      "episode 6, policy loss -0.07649314403533936\n",
      "\n",
      "episode 7, policy loss -0.03688584268093109\n",
      "\n",
      "episode 8, policy loss -0.04959286004304886\n",
      "\n",
      "episode 9, policy loss -0.03676304221153259\n",
      "\n",
      "episode 10, policy loss -0.07769301533699036\n",
      "\n",
      "episode 11, policy loss -0.02035588026046753\n",
      "\n",
      "episode 12, policy loss -0.051699817180633545\n",
      "\n",
      "episode 13, policy loss -0.07050620019435883\n",
      "\n",
      "episode 14, policy loss -0.07869675010442734\n",
      "\n",
      "episode 15, policy loss -0.03058535046875477\n",
      "\n",
      "episode 16, policy loss -0.010933931916952133\n",
      "\n",
      "Policy train loss in epoch 3:-0.04724941973108798\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1894732564687729\n",
      "\n",
      "episode 2, val func loss 0.19121132791042328\n",
      "\n",
      "episode 3, val func loss 0.20761694014072418\n",
      "\n",
      "episode 4, val func loss 0.1688823103904724\n",
      "\n",
      "episode 5, val func loss 0.18294906616210938\n",
      "\n",
      "episode 6, val func loss 0.16264939308166504\n",
      "\n",
      "episode 7, val func loss 0.17268604040145874\n",
      "\n",
      "episode 8, val func loss 0.16403059661388397\n",
      "\n",
      "episode 9, val func loss 0.16970759630203247\n",
      "\n",
      "episode 10, val func loss 0.18527930974960327\n",
      "\n",
      "episode 11, val func loss 0.19179792702198029\n",
      "\n",
      "episode 12, val func loss 0.17846006155014038\n",
      "\n",
      "episode 13, val func loss 0.2006584256887436\n",
      "\n",
      "episode 14, val func loss 0.17656755447387695\n",
      "\n",
      "episode 15, val func loss 0.18554188311100006\n",
      "\n",
      "episode 16, val func loss 0.20614926517009735\n",
      "\n",
      "Val func train loss in epoch 0:0.18335380963981152\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1812196671962738\n",
      "\n",
      "episode 2, val func loss 0.18646447360515594\n",
      "\n",
      "episode 3, val func loss 0.20319418609142303\n",
      "\n",
      "episode 4, val func loss 0.1910562962293625\n",
      "\n",
      "episode 5, val func loss 0.1808699518442154\n",
      "\n",
      "episode 6, val func loss 0.18599486351013184\n",
      "\n",
      "episode 7, val func loss 0.1852773129940033\n",
      "\n",
      "episode 8, val func loss 0.16997019946575165\n",
      "\n",
      "episode 9, val func loss 0.1736346334218979\n",
      "\n",
      "episode 10, val func loss 0.16313433647155762\n",
      "\n",
      "episode 11, val func loss 0.16313208639621735\n",
      "\n",
      "episode 12, val func loss 0.16987045109272003\n",
      "\n",
      "episode 13, val func loss 0.21119239926338196\n",
      "\n",
      "episode 14, val func loss 0.1997416764497757\n",
      "\n",
      "episode 15, val func loss 0.17634031176567078\n",
      "\n",
      "episode 16, val func loss 0.19059377908706665\n",
      "\n",
      "Val func train loss in epoch 1:0.18323041405528784\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.16528013348579407\n",
      "\n",
      "episode 2, val func loss 0.17606383562088013\n",
      "\n",
      "episode 3, val func loss 0.20910997688770294\n",
      "\n",
      "episode 4, val func loss 0.17817412316799164\n",
      "\n",
      "episode 5, val func loss 0.1637081652879715\n",
      "\n",
      "episode 6, val func loss 0.19092676043510437\n",
      "\n",
      "episode 7, val func loss 0.18124330043792725\n",
      "\n",
      "episode 8, val func loss 0.1637546271085739\n",
      "\n",
      "episode 9, val func loss 0.20365099608898163\n",
      "\n",
      "episode 10, val func loss 0.16946038603782654\n",
      "\n",
      "episode 11, val func loss 0.1892845183610916\n",
      "\n",
      "episode 12, val func loss 0.18671298027038574\n",
      "\n",
      "episode 13, val func loss 0.18104524910449982\n",
      "\n",
      "episode 14, val func loss 0.1888584941625595\n",
      "\n",
      "episode 15, val func loss 0.19834697246551514\n",
      "\n",
      "episode 16, val func loss 0.17009465396404266\n",
      "\n",
      "Val func train loss in epoch 2:0.18223219830542803\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18201997876167297\n",
      "\n",
      "episode 2, val func loss 0.18797847628593445\n",
      "\n",
      "episode 3, val func loss 0.19756455719470978\n",
      "\n",
      "episode 4, val func loss 0.18999719619750977\n",
      "\n",
      "episode 5, val func loss 0.20443497598171234\n",
      "\n",
      "episode 6, val func loss 0.17679917812347412\n",
      "\n",
      "episode 7, val func loss 0.1688995510339737\n",
      "\n",
      "episode 8, val func loss 0.1642385572195053\n",
      "\n",
      "episode 9, val func loss 0.1633845418691635\n",
      "\n",
      "episode 10, val func loss 0.16914361715316772\n",
      "\n",
      "episode 11, val func loss 0.16978897154331207\n",
      "\n",
      "episode 12, val func loss 0.19098904728889465\n",
      "\n",
      "episode 13, val func loss 0.17839664220809937\n",
      "\n",
      "episode 14, val func loss 0.18548667430877686\n",
      "\n",
      "episode 15, val func loss 0.1856081187725067\n",
      "\n",
      "episode 16, val func loss 0.21044671535491943\n",
      "\n",
      "Val func train loss in epoch 3:0.1828235499560833\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19076795876026154\n",
      "\n",
      "episode 2, val func loss 0.16974492371082306\n",
      "\n",
      "episode 3, val func loss 0.18688851594924927\n",
      "\n",
      "episode 4, val func loss 0.1814327836036682\n",
      "\n",
      "episode 5, val func loss 0.1829749494791031\n",
      "\n",
      "episode 6, val func loss 0.16395223140716553\n",
      "\n",
      "episode 7, val func loss 0.17667339742183685\n",
      "\n",
      "episode 8, val func loss 0.19826002418994904\n",
      "\n",
      "episode 9, val func loss 0.16487517952919006\n",
      "\n",
      "episode 10, val func loss 0.17572227120399475\n",
      "\n",
      "episode 11, val func loss 0.21068428456783295\n",
      "\n",
      "episode 12, val func loss 0.17032243311405182\n",
      "\n",
      "episode 13, val func loss 0.1777445524930954\n",
      "\n",
      "episode 14, val func loss 0.19257020950317383\n",
      "\n",
      "episode 15, val func loss 0.2065298706293106\n",
      "\n",
      "episode 16, val func loss 0.18541400134563446\n",
      "\n",
      "Val func train loss in epoch 4:0.18340984918177128\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17628096044063568\n",
      "\n",
      "episode 2, val func loss 0.18983304500579834\n",
      "\n",
      "episode 3, val func loss 0.16340655088424683\n",
      "\n",
      "episode 4, val func loss 0.1979149430990219\n",
      "\n",
      "episode 5, val func loss 0.16507205367088318\n",
      "\n",
      "episode 6, val func loss 0.1815081536769867\n",
      "\n",
      "episode 7, val func loss 0.18070892989635468\n",
      "\n",
      "episode 8, val func loss 0.20376232266426086\n",
      "\n",
      "episode 9, val func loss 0.1693912148475647\n",
      "\n",
      "episode 10, val func loss 0.1692156046628952\n",
      "\n",
      "episode 11, val func loss 0.20856310427188873\n",
      "\n",
      "episode 12, val func loss 0.1691814810037613\n",
      "\n",
      "episode 13, val func loss 0.19161435961723328\n",
      "\n",
      "episode 14, val func loss 0.18605756759643555\n",
      "\n",
      "episode 15, val func loss 0.1879042536020279\n",
      "\n",
      "episode 16, val func loss 0.18094515800476074\n",
      "\n",
      "Val func train loss in epoch 5:0.18258498143404722\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1905992031097412\n",
      "\n",
      "episode 2, val func loss 0.20428413152694702\n",
      "\n",
      "episode 3, val func loss 0.1868266612291336\n",
      "\n",
      "episode 4, val func loss 0.17099356651306152\n",
      "\n",
      "episode 5, val func loss 0.1628149151802063\n",
      "\n",
      "episode 6, val func loss 0.18213239312171936\n",
      "\n",
      "episode 7, val func loss 0.18155090510845184\n",
      "\n",
      "episode 8, val func loss 0.1689150482416153\n",
      "\n",
      "episode 9, val func loss 0.16739940643310547\n",
      "\n",
      "episode 10, val func loss 0.18616297841072083\n",
      "\n",
      "episode 11, val func loss 0.21064721047878265\n",
      "\n",
      "episode 12, val func loss 0.1989915370941162\n",
      "\n",
      "episode 13, val func loss 0.18613047897815704\n",
      "\n",
      "episode 14, val func loss 0.17585201561450958\n",
      "\n",
      "episode 15, val func loss 0.16386385262012482\n",
      "\n",
      "episode 16, val func loss 0.19010813534259796\n",
      "\n",
      "Val func train loss in epoch 6:0.18295452743768692\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17626476287841797\n",
      "\n",
      "episode 2, val func loss 0.19746960699558258\n",
      "\n",
      "episode 3, val func loss 0.19102555513381958\n",
      "\n",
      "episode 4, val func loss 0.18679389357566833\n",
      "\n",
      "episode 5, val func loss 0.16971199214458466\n",
      "\n",
      "episode 6, val func loss 0.18082892894744873\n",
      "\n",
      "episode 7, val func loss 0.18108923733234406\n",
      "\n",
      "episode 8, val func loss 0.16897732019424438\n",
      "\n",
      "episode 9, val func loss 0.2076622098684311\n",
      "\n",
      "episode 10, val func loss 0.18689356744289398\n",
      "\n",
      "episode 11, val func loss 0.1673361361026764\n",
      "\n",
      "episode 12, val func loss 0.19181965291500092\n",
      "\n",
      "episode 13, val func loss 0.20891080796718597\n",
      "\n",
      "episode 14, val func loss 0.1814069151878357\n",
      "\n",
      "episode 15, val func loss 0.163694828748703\n",
      "\n",
      "episode 16, val func loss 0.16288511455059052\n",
      "\n",
      "Val func train loss in epoch 7:0.18267315812408924\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16341806948184967\n",
      "\n",
      "episode 2, val func loss 0.18003115057945251\n",
      "\n",
      "episode 3, val func loss 0.181366965174675\n",
      "\n",
      "episode 4, val func loss 0.1690891683101654\n",
      "\n",
      "episode 5, val func loss 0.1901445835828781\n",
      "\n",
      "episode 6, val func loss 0.19779343903064728\n",
      "\n",
      "episode 7, val func loss 0.1644374579191208\n",
      "\n",
      "episode 8, val func loss 0.16972720623016357\n",
      "\n",
      "episode 9, val func loss 0.1665143072605133\n",
      "\n",
      "episode 10, val func loss 0.194338858127594\n",
      "\n",
      "episode 11, val func loss 0.17621032893657684\n",
      "\n",
      "episode 12, val func loss 0.18169793486595154\n",
      "\n",
      "episode 13, val func loss 0.18539196252822876\n",
      "\n",
      "episode 14, val func loss 0.20840631425380707\n",
      "\n",
      "episode 15, val func loss 0.1873304545879364\n",
      "\n",
      "episode 16, val func loss 0.20371149480342865\n",
      "\n",
      "Val func train loss in epoch 8:0.1824756059795618\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.2026994824409485\n",
      "\n",
      "episode 2, val func loss 0.17041686177253723\n",
      "\n",
      "episode 3, val func loss 0.18520456552505493\n",
      "\n",
      "episode 4, val func loss 0.1723613739013672\n",
      "\n",
      "episode 5, val func loss 0.1978335678577423\n",
      "\n",
      "episode 6, val func loss 0.1808871477842331\n",
      "\n",
      "episode 7, val func loss 0.20974917709827423\n",
      "\n",
      "episode 8, val func loss 0.19244377315044403\n",
      "\n",
      "episode 9, val func loss 0.16393491625785828\n",
      "\n",
      "episode 10, val func loss 0.18965144455432892\n",
      "\n",
      "episode 11, val func loss 0.17596112191677094\n",
      "\n",
      "episode 12, val func loss 0.1822274625301361\n",
      "\n",
      "episode 13, val func loss 0.18724699318408966\n",
      "\n",
      "episode 14, val func loss 0.16419249773025513\n",
      "\n",
      "episode 15, val func loss 0.18729130923748016\n",
      "\n",
      "episode 16, val func loss 0.1686418652534485\n",
      "\n",
      "Val func train loss in epoch 9:0.18317147251218557\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18117867410182953\n",
      "\n",
      "episode 2, val func loss 0.16603383421897888\n",
      "\n",
      "episode 3, val func loss 0.18794678151607513\n",
      "\n",
      "episode 4, val func loss 0.20032167434692383\n",
      "\n",
      "episode 5, val func loss 0.1762552261352539\n",
      "\n",
      "episode 6, val func loss 0.20627345144748688\n",
      "\n",
      "episode 7, val func loss 0.16397060453891754\n",
      "\n",
      "episode 8, val func loss 0.16403958201408386\n",
      "\n",
      "episode 9, val func loss 0.1699409931898117\n",
      "\n",
      "episode 10, val func loss 0.16920514404773712\n",
      "\n",
      "episode 11, val func loss 0.18708926439285278\n",
      "\n",
      "episode 12, val func loss 0.1893802285194397\n",
      "\n",
      "episode 13, val func loss 0.17886027693748474\n",
      "\n",
      "episode 14, val func loss 0.19014914333820343\n",
      "\n",
      "episode 15, val func loss 0.20892333984375\n",
      "\n",
      "episode 16, val func loss 0.19131486117839813\n",
      "\n",
      "Val func train loss in epoch 10:0.1831801924854517\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.20747648179531097\n",
      "\n",
      "episode 2, val func loss 0.1810155212879181\n",
      "\n",
      "episode 3, val func loss 0.1710873395204544\n",
      "\n",
      "episode 4, val func loss 0.16865688562393188\n",
      "\n",
      "episode 5, val func loss 0.18390722572803497\n",
      "\n",
      "episode 6, val func loss 0.1808198243379593\n",
      "\n",
      "episode 7, val func loss 0.20648135244846344\n",
      "\n",
      "episode 8, val func loss 0.16357757151126862\n",
      "\n",
      "episode 9, val func loss 0.18654781579971313\n",
      "\n",
      "episode 10, val func loss 0.1762804388999939\n",
      "\n",
      "episode 11, val func loss 0.18736928701400757\n",
      "\n",
      "episode 12, val func loss 0.16417722404003143\n",
      "\n",
      "episode 13, val func loss 0.19112317264080048\n",
      "\n",
      "episode 14, val func loss 0.19760586321353912\n",
      "\n",
      "episode 15, val func loss 0.1688215732574463\n",
      "\n",
      "episode 16, val func loss 0.18964162468910217\n",
      "\n",
      "Val func train loss in epoch 11:0.18278682511299849\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.20384876430034637\n",
      "\n",
      "episode 2, val func loss 0.1703069508075714\n",
      "\n",
      "episode 3, val func loss 0.18677201867103577\n",
      "\n",
      "episode 4, val func loss 0.16541989147663116\n",
      "\n",
      "episode 5, val func loss 0.18084682524204254\n",
      "\n",
      "episode 6, val func loss 0.19781987369060516\n",
      "\n",
      "episode 7, val func loss 0.18299812078475952\n",
      "\n",
      "episode 8, val func loss 0.19002272188663483\n",
      "\n",
      "episode 9, val func loss 0.20771221816539764\n",
      "\n",
      "episode 10, val func loss 0.17545820772647858\n",
      "\n",
      "episode 11, val func loss 0.1862308233976364\n",
      "\n",
      "episode 12, val func loss 0.19084668159484863\n",
      "\n",
      "episode 13, val func loss 0.1815672218799591\n",
      "\n",
      "episode 14, val func loss 0.16342288255691528\n",
      "\n",
      "episode 15, val func loss 0.1695917844772339\n",
      "\n",
      "episode 16, val func loss 0.16830624639987946\n",
      "\n",
      "Val func train loss in epoch 12:0.18257320206612349\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18572790920734406\n",
      "\n",
      "episode 2, val func loss 0.20622113347053528\n",
      "\n",
      "episode 3, val func loss 0.1805802285671234\n",
      "\n",
      "episode 4, val func loss 0.19799667596817017\n",
      "\n",
      "episode 5, val func loss 0.16909159719944\n",
      "\n",
      "episode 6, val func loss 0.16347789764404297\n",
      "\n",
      "episode 7, val func loss 0.17833386361598969\n",
      "\n",
      "episode 8, val func loss 0.18787427246570587\n",
      "\n",
      "episode 9, val func loss 0.20820917189121246\n",
      "\n",
      "episode 10, val func loss 0.1818106770515442\n",
      "\n",
      "episode 11, val func loss 0.17039217054843903\n",
      "\n",
      "episode 12, val func loss 0.16300193965435028\n",
      "\n",
      "episode 13, val func loss 0.17187288403511047\n",
      "\n",
      "episode 14, val func loss 0.18867163360118866\n",
      "\n",
      "episode 15, val func loss 0.1916116327047348\n",
      "\n",
      "episode 16, val func loss 0.176579087972641\n",
      "\n",
      "Val func train loss in epoch 13:0.18259079847484827\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1668328195810318\n",
      "\n",
      "episode 2, val func loss 0.1923239380121231\n",
      "\n",
      "episode 3, val func loss 0.20820669829845428\n",
      "\n",
      "episode 4, val func loss 0.18537238240242004\n",
      "\n",
      "episode 5, val func loss 0.17824575304985046\n",
      "\n",
      "episode 6, val func loss 0.1894042044878006\n",
      "\n",
      "episode 7, val func loss 0.16977687180042267\n",
      "\n",
      "episode 8, val func loss 0.18081246316432953\n",
      "\n",
      "episode 9, val func loss 0.18196599185466766\n",
      "\n",
      "episode 10, val func loss 0.19834119081497192\n",
      "\n",
      "episode 11, val func loss 0.20785987377166748\n",
      "\n",
      "episode 12, val func loss 0.16314813494682312\n",
      "\n",
      "episode 13, val func loss 0.17781299352645874\n",
      "\n",
      "episode 14, val func loss 0.19018036127090454\n",
      "\n",
      "episode 15, val func loss 0.16594305634498596\n",
      "\n",
      "episode 16, val func loss 0.16880066692829132\n",
      "\n",
      "Val func train loss in epoch 14:0.1828142125159502\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20432434976100922\n",
      "\n",
      "episode 2, val func loss 0.16386477649211884\n",
      "\n",
      "episode 3, val func loss 0.18939872086048126\n",
      "\n",
      "episode 4, val func loss 0.18286535143852234\n",
      "\n",
      "episode 5, val func loss 0.16900987923145294\n",
      "\n",
      "episode 6, val func loss 0.18056075274944305\n",
      "\n",
      "episode 7, val func loss 0.20791158080101013\n",
      "\n",
      "episode 8, val func loss 0.16810749471187592\n",
      "\n",
      "episode 9, val func loss 0.17535558342933655\n",
      "\n",
      "episode 10, val func loss 0.18584589660167694\n",
      "\n",
      "episode 11, val func loss 0.16968847811222076\n",
      "\n",
      "episode 12, val func loss 0.19155962765216827\n",
      "\n",
      "episode 13, val func loss 0.16434675455093384\n",
      "\n",
      "episode 14, val func loss 0.19830967485904694\n",
      "\n",
      "episode 15, val func loss 0.17842473089694977\n",
      "\n",
      "episode 16, val func loss 0.1880539208650589\n",
      "\n",
      "Val func train loss in epoch 15:0.1823517233133316\n",
      "***********************TIME WAS 4.907179633776347 min*****************************\n",
      "\n",
      "**********************ROUND 43 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.02472662925720215\n",
      "\n",
      "episode 2, policy loss -0.0795927345752716\n",
      "\n",
      "episode 3, policy loss -0.011390475556254387\n",
      "\n",
      "episode 4, policy loss -0.032795500010252\n",
      "\n",
      "episode 5, policy loss -0.05075205862522125\n",
      "\n",
      "episode 6, policy loss -0.046829722821712494\n",
      "\n",
      "episode 7, policy loss 0.005732422694563866\n",
      "\n",
      "episode 8, policy loss -0.019399387761950493\n",
      "\n",
      "episode 9, policy loss -0.000814361497759819\n",
      "\n",
      "episode 10, policy loss -0.04928202927112579\n",
      "\n",
      "episode 11, policy loss -0.03890298306941986\n",
      "\n",
      "episode 12, policy loss -0.04463758319616318\n",
      "\n",
      "episode 13, policy loss -0.053926751017570496\n",
      "\n",
      "episode 14, policy loss -0.003851276822388172\n",
      "\n",
      "episode 15, policy loss -0.03930173069238663\n",
      "\n",
      "episode 16, policy loss -0.04830646514892578\n",
      "\n",
      "Policy train loss in epoch 0:-0.033673579164315015\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.041994206607341766\n",
      "\n",
      "episode 2, policy loss 0.005419151857495308\n",
      "\n",
      "episode 3, policy loss -0.00725918635725975\n",
      "\n",
      "episode 4, policy loss -0.0017102602869272232\n",
      "\n",
      "episode 5, policy loss -0.012683581560850143\n",
      "\n",
      "episode 6, policy loss -0.036073051393032074\n",
      "\n",
      "episode 7, policy loss -0.05036478489637375\n",
      "\n",
      "episode 8, policy loss -0.04827699437737465\n",
      "\n",
      "episode 9, policy loss -0.052721403539180756\n",
      "\n",
      "episode 10, policy loss -0.0445232130587101\n",
      "\n",
      "episode 11, policy loss -0.02697775512933731\n",
      "\n",
      "episode 12, policy loss -0.04494800418615341\n",
      "\n",
      "episode 13, policy loss -0.02182249166071415\n",
      "\n",
      "episode 14, policy loss -0.03242906555533409\n",
      "\n",
      "episode 15, policy loss -0.08074437081813812\n",
      "\n",
      "episode 16, policy loss -0.05948922783136368\n",
      "\n",
      "Policy train loss in epoch 1:-0.03478740283753723\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.04383133351802826\n",
      "\n",
      "episode 2, policy loss -0.07962637394666672\n",
      "\n",
      "episode 3, policy loss -0.011758211068809032\n",
      "\n",
      "episode 4, policy loss -0.03834889456629753\n",
      "\n",
      "episode 5, policy loss -0.049720294773578644\n",
      "\n",
      "episode 6, policy loss -0.022451329976320267\n",
      "\n",
      "episode 7, policy loss -0.054264020174741745\n",
      "\n",
      "episode 8, policy loss 0.0020097270607948303\n",
      "\n",
      "episode 9, policy loss -0.05240762233734131\n",
      "\n",
      "episode 10, policy loss -0.024034623056650162\n",
      "\n",
      "episode 11, policy loss -0.0342705175280571\n",
      "\n",
      "episode 12, policy loss -0.044798098504543304\n",
      "\n",
      "episode 13, policy loss -0.05745998024940491\n",
      "\n",
      "episode 14, policy loss -0.0034014424309134483\n",
      "\n",
      "episode 15, policy loss -0.006011516787111759\n",
      "\n",
      "episode 16, policy loss -0.04221806675195694\n",
      "\n",
      "Policy train loss in epoch 2:-0.03516203741310164\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.00046729855239391327\n",
      "\n",
      "episode 2, policy loss -0.08063000440597534\n",
      "\n",
      "episode 3, policy loss -0.00565306656062603\n",
      "\n",
      "episode 4, policy loss -0.01307731308043003\n",
      "\n",
      "episode 5, policy loss -0.033856019377708435\n",
      "\n",
      "episode 6, policy loss -0.05038885772228241\n",
      "\n",
      "episode 7, policy loss -0.019920727238059044\n",
      "\n",
      "episode 8, policy loss -0.05402813106775284\n",
      "\n",
      "episode 9, policy loss -0.04580026492476463\n",
      "\n",
      "episode 10, policy loss -0.04228693246841431\n",
      "\n",
      "episode 11, policy loss -0.022517535835504532\n",
      "\n",
      "episode 12, policy loss -0.004908130504190922\n",
      "\n",
      "episode 13, policy loss -0.039083294570446014\n",
      "\n",
      "episode 14, policy loss -0.04979987069964409\n",
      "\n",
      "episode 15, policy loss -0.04570864140987396\n",
      "\n",
      "episode 16, policy loss -0.058585040271282196\n",
      "\n",
      "Policy train loss in epoch 3:-0.035419445543084294\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1617104709148407\n",
      "\n",
      "episode 2, val func loss 0.17765991389751434\n",
      "\n",
      "episode 3, val func loss 0.19643007218837738\n",
      "\n",
      "episode 4, val func loss 0.13896559178829193\n",
      "\n",
      "episode 5, val func loss 0.19570448994636536\n",
      "\n",
      "episode 6, val func loss 0.17855066061019897\n",
      "\n",
      "episode 7, val func loss 0.13294224441051483\n",
      "\n",
      "episode 8, val func loss 0.1554281860589981\n",
      "\n",
      "episode 9, val func loss 0.18619319796562195\n",
      "\n",
      "episode 10, val func loss 0.1403612643480301\n",
      "\n",
      "episode 11, val func loss 0.16948753595352173\n",
      "\n",
      "episode 12, val func loss 0.15440687537193298\n",
      "\n",
      "episode 13, val func loss 0.16152599453926086\n",
      "\n",
      "episode 14, val func loss 0.18252620100975037\n",
      "\n",
      "episode 15, val func loss 0.16713693737983704\n",
      "\n",
      "episode 16, val func loss 0.15064746141433716\n",
      "\n",
      "Val func train loss in epoch 0:0.1656048186123371\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1508391946554184\n",
      "\n",
      "episode 2, val func loss 0.1410205215215683\n",
      "\n",
      "episode 3, val func loss 0.18245048820972443\n",
      "\n",
      "episode 4, val func loss 0.1949721723794937\n",
      "\n",
      "episode 5, val func loss 0.16107459366321564\n",
      "\n",
      "episode 6, val func loss 0.1362771838903427\n",
      "\n",
      "episode 7, val func loss 0.18091440200805664\n",
      "\n",
      "episode 8, val func loss 0.13297699391841888\n",
      "\n",
      "episode 9, val func loss 0.16004705429077148\n",
      "\n",
      "episode 10, val func loss 0.16679923236370087\n",
      "\n",
      "episode 11, val func loss 0.15377691388130188\n",
      "\n",
      "episode 12, val func loss 0.1790255308151245\n",
      "\n",
      "episode 13, val func loss 0.157310351729393\n",
      "\n",
      "episode 14, val func loss 0.19526973366737366\n",
      "\n",
      "episode 15, val func loss 0.18562951683998108\n",
      "\n",
      "episode 16, val func loss 0.17072758078575134\n",
      "\n",
      "Val func train loss in epoch 1:0.16556946653872728\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18216684460639954\n",
      "\n",
      "episode 2, val func loss 0.1796412467956543\n",
      "\n",
      "episode 3, val func loss 0.18559391796588898\n",
      "\n",
      "episode 4, val func loss 0.16667719185352325\n",
      "\n",
      "episode 5, val func loss 0.19542022049427032\n",
      "\n",
      "episode 6, val func loss 0.1949499249458313\n",
      "\n",
      "episode 7, val func loss 0.13295258581638336\n",
      "\n",
      "episode 8, val func loss 0.1715513914823532\n",
      "\n",
      "episode 9, val func loss 0.14167802035808563\n",
      "\n",
      "episode 10, val func loss 0.15574471652507782\n",
      "\n",
      "episode 11, val func loss 0.15411588549613953\n",
      "\n",
      "episode 12, val func loss 0.16049666702747345\n",
      "\n",
      "episode 13, val func loss 0.17923687398433685\n",
      "\n",
      "episode 14, val func loss 0.15043173730373383\n",
      "\n",
      "episode 15, val func loss 0.16217640042304993\n",
      "\n",
      "episode 16, val func loss 0.1347283571958542\n",
      "\n",
      "Val func train loss in epoch 2:0.16547262389212847\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.14029011130332947\n",
      "\n",
      "episode 2, val func loss 0.16067299246788025\n",
      "\n",
      "episode 3, val func loss 0.15085765719413757\n",
      "\n",
      "episode 4, val func loss 0.16113168001174927\n",
      "\n",
      "episode 5, val func loss 0.1329462230205536\n",
      "\n",
      "episode 6, val func loss 0.13706037402153015\n",
      "\n",
      "episode 7, val func loss 0.15373824536800385\n",
      "\n",
      "episode 8, val func loss 0.18527033925056458\n",
      "\n",
      "episode 9, val func loss 0.17065007984638214\n",
      "\n",
      "episode 10, val func loss 0.17897017300128937\n",
      "\n",
      "episode 11, val func loss 0.18237607181072235\n",
      "\n",
      "episode 12, val func loss 0.1549154669046402\n",
      "\n",
      "episode 13, val func loss 0.18152818083763123\n",
      "\n",
      "episode 14, val func loss 0.19590751826763153\n",
      "\n",
      "episode 15, val func loss 0.16690945625305176\n",
      "\n",
      "episode 16, val func loss 0.1961950659751892\n",
      "\n",
      "Val func train loss in epoch 3:0.1655887272208929\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17871925234794617\n",
      "\n",
      "episode 2, val func loss 0.14147047698497772\n",
      "\n",
      "episode 3, val func loss 0.18556839227676392\n",
      "\n",
      "episode 4, val func loss 0.15370525419712067\n",
      "\n",
      "episode 5, val func loss 0.1975078582763672\n",
      "\n",
      "episode 6, val func loss 0.18349801003932953\n",
      "\n",
      "episode 7, val func loss 0.1954309642314911\n",
      "\n",
      "episode 8, val func loss 0.17087213695049286\n",
      "\n",
      "episode 9, val func loss 0.16685232520103455\n",
      "\n",
      "episode 10, val func loss 0.1331254541873932\n",
      "\n",
      "episode 11, val func loss 0.1503763645887375\n",
      "\n",
      "episode 12, val func loss 0.1546274721622467\n",
      "\n",
      "episode 13, val func loss 0.16037966310977936\n",
      "\n",
      "episode 14, val func loss 0.13460145890712738\n",
      "\n",
      "episode 15, val func loss 0.16373085975646973\n",
      "\n",
      "episode 16, val func loss 0.18009142577648163\n",
      "\n",
      "Val func train loss in epoch 4:0.16565983556210995\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17901286482810974\n",
      "\n",
      "episode 2, val func loss 0.1950812190771103\n",
      "\n",
      "episode 3, val func loss 0.15867628157138824\n",
      "\n",
      "episode 4, val func loss 0.14226190745830536\n",
      "\n",
      "episode 5, val func loss 0.18357053399085999\n",
      "\n",
      "episode 6, val func loss 0.1771537959575653\n",
      "\n",
      "episode 7, val func loss 0.1599757969379425\n",
      "\n",
      "episode 8, val func loss 0.19593098759651184\n",
      "\n",
      "episode 9, val func loss 0.17091256380081177\n",
      "\n",
      "episode 10, val func loss 0.13302987813949585\n",
      "\n",
      "episode 11, val func loss 0.13527138531208038\n",
      "\n",
      "episode 12, val func loss 0.16816267371177673\n",
      "\n",
      "episode 13, val func loss 0.15561716258525848\n",
      "\n",
      "episode 14, val func loss 0.15042483806610107\n",
      "\n",
      "episode 15, val func loss 0.16023282706737518\n",
      "\n",
      "episode 16, val func loss 0.18737570941448212\n",
      "\n",
      "Val func train loss in epoch 5:0.16579315159469843\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1360241323709488\n",
      "\n",
      "episode 2, val func loss 0.1592615842819214\n",
      "\n",
      "episode 3, val func loss 0.177744522690773\n",
      "\n",
      "episode 4, val func loss 0.152740940451622\n",
      "\n",
      "episode 5, val func loss 0.16029928624629974\n",
      "\n",
      "episode 6, val func loss 0.17853890359401703\n",
      "\n",
      "episode 7, val func loss 0.18563324213027954\n",
      "\n",
      "episode 8, val func loss 0.18232953548431396\n",
      "\n",
      "episode 9, val func loss 0.13371242582798004\n",
      "\n",
      "episode 10, val func loss 0.16064453125\n",
      "\n",
      "episode 11, val func loss 0.16933195292949677\n",
      "\n",
      "episode 12, val func loss 0.19586947560310364\n",
      "\n",
      "episode 13, val func loss 0.14057952165603638\n",
      "\n",
      "episode 14, val func loss 0.1671811193227768\n",
      "\n",
      "episode 15, val func loss 0.1952665150165558\n",
      "\n",
      "episode 16, val func loss 0.15416502952575684\n",
      "\n",
      "Val func train loss in epoch 6:0.1655826698988676\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.15432241559028625\n",
      "\n",
      "episode 2, val func loss 0.18269427120685577\n",
      "\n",
      "episode 3, val func loss 0.1668802946805954\n",
      "\n",
      "episode 4, val func loss 0.154873788356781\n",
      "\n",
      "episode 5, val func loss 0.16081301867961884\n",
      "\n",
      "episode 6, val func loss 0.16951113939285278\n",
      "\n",
      "episode 7, val func loss 0.17957007884979248\n",
      "\n",
      "episode 8, val func loss 0.14012998342514038\n",
      "\n",
      "episode 9, val func loss 0.15033785998821259\n",
      "\n",
      "episode 10, val func loss 0.15917882323265076\n",
      "\n",
      "episode 11, val func loss 0.17757906019687653\n",
      "\n",
      "episode 12, val func loss 0.14632363617420197\n",
      "\n",
      "episode 13, val func loss 0.1963994801044464\n",
      "\n",
      "episode 14, val func loss 0.19571350514888763\n",
      "\n",
      "episode 15, val func loss 0.13306109607219696\n",
      "\n",
      "episode 16, val func loss 0.18735206127166748\n",
      "\n",
      "Val func train loss in epoch 7:0.16592128202319145\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.19755347073078156\n",
      "\n",
      "episode 2, val func loss 0.16064795851707458\n",
      "\n",
      "episode 3, val func loss 0.1812366247177124\n",
      "\n",
      "episode 4, val func loss 0.18202872574329376\n",
      "\n",
      "episode 5, val func loss 0.15378032624721527\n",
      "\n",
      "episode 6, val func loss 0.13329850137233734\n",
      "\n",
      "episode 7, val func loss 0.16758690774440765\n",
      "\n",
      "episode 8, val func loss 0.1962767094373703\n",
      "\n",
      "episode 9, val func loss 0.1577828824520111\n",
      "\n",
      "episode 10, val func loss 0.17003211379051208\n",
      "\n",
      "episode 11, val func loss 0.14029330015182495\n",
      "\n",
      "episode 12, val func loss 0.18779624998569489\n",
      "\n",
      "episode 13, val func loss 0.16305692493915558\n",
      "\n",
      "episode 14, val func loss 0.15049153566360474\n",
      "\n",
      "episode 15, val func loss 0.17951616644859314\n",
      "\n",
      "episode 16, val func loss 0.13519054651260376\n",
      "\n",
      "Val func train loss in epoch 8:0.16603555902838707\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.16951707005500793\n",
      "\n",
      "episode 2, val func loss 0.17870821058750153\n",
      "\n",
      "episode 3, val func loss 0.1607304960489273\n",
      "\n",
      "episode 4, val func loss 0.13553503155708313\n",
      "\n",
      "episode 5, val func loss 0.154184028506279\n",
      "\n",
      "episode 6, val func loss 0.19520722329616547\n",
      "\n",
      "episode 7, val func loss 0.18063902854919434\n",
      "\n",
      "episode 8, val func loss 0.15034623444080353\n",
      "\n",
      "episode 9, val func loss 0.14078421890735626\n",
      "\n",
      "episode 10, val func loss 0.13267213106155396\n",
      "\n",
      "episode 11, val func loss 0.18493905663490295\n",
      "\n",
      "episode 12, val func loss 0.18242239952087402\n",
      "\n",
      "episode 13, val func loss 0.19620025157928467\n",
      "\n",
      "episode 14, val func loss 0.15751203894615173\n",
      "\n",
      "episode 15, val func loss 0.1665746420621872\n",
      "\n",
      "episode 16, val func loss 0.15910249948501587\n",
      "\n",
      "Val func train loss in epoch 9:0.16531716007739305\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.13292858004570007\n",
      "\n",
      "episode 2, val func loss 0.13615670800209045\n",
      "\n",
      "episode 3, val func loss 0.17856183648109436\n",
      "\n",
      "episode 4, val func loss 0.16683030128479004\n",
      "\n",
      "episode 5, val func loss 0.1509539633989334\n",
      "\n",
      "episode 6, val func loss 0.18025106191635132\n",
      "\n",
      "episode 7, val func loss 0.16012264788150787\n",
      "\n",
      "episode 8, val func loss 0.1854712963104248\n",
      "\n",
      "episode 9, val func loss 0.16233354806900024\n",
      "\n",
      "episode 10, val func loss 0.1960694044828415\n",
      "\n",
      "episode 11, val func loss 0.1539389044046402\n",
      "\n",
      "episode 12, val func loss 0.15786346793174744\n",
      "\n",
      "episode 13, val func loss 0.19501586258411407\n",
      "\n",
      "episode 14, val func loss 0.1820247322320938\n",
      "\n",
      "episode 15, val func loss 0.1410212367773056\n",
      "\n",
      "episode 16, val func loss 0.1693357229232788\n",
      "\n",
      "Val func train loss in epoch 10:0.16555495467036963\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18276967108249664\n",
      "\n",
      "episode 2, val func loss 0.1619899570941925\n",
      "\n",
      "episode 3, val func loss 0.1694038212299347\n",
      "\n",
      "episode 4, val func loss 0.15439140796661377\n",
      "\n",
      "episode 5, val func loss 0.18748551607131958\n",
      "\n",
      "episode 6, val func loss 0.16038399934768677\n",
      "\n",
      "episode 7, val func loss 0.17830896377563477\n",
      "\n",
      "episode 8, val func loss 0.17908211052417755\n",
      "\n",
      "episode 9, val func loss 0.16675634682178497\n",
      "\n",
      "episode 10, val func loss 0.19615305960178375\n",
      "\n",
      "episode 11, val func loss 0.13293711841106415\n",
      "\n",
      "episode 12, val func loss 0.15210634469985962\n",
      "\n",
      "episode 13, val func loss 0.14219193160533905\n",
      "\n",
      "episode 14, val func loss 0.1537589430809021\n",
      "\n",
      "episode 15, val func loss 0.19576585292816162\n",
      "\n",
      "episode 16, val func loss 0.1363936811685562\n",
      "\n",
      "Val func train loss in epoch 11:0.16561742033809423\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.16660760343074799\n",
      "\n",
      "episode 2, val func loss 0.14040227234363556\n",
      "\n",
      "episode 3, val func loss 0.1613718569278717\n",
      "\n",
      "episode 4, val func loss 0.15467621386051178\n",
      "\n",
      "episode 5, val func loss 0.18238399922847748\n",
      "\n",
      "episode 6, val func loss 0.1612033247947693\n",
      "\n",
      "episode 7, val func loss 0.1786755472421646\n",
      "\n",
      "episode 8, val func loss 0.1362096220254898\n",
      "\n",
      "episode 9, val func loss 0.1326671838760376\n",
      "\n",
      "episode 10, val func loss 0.19522656500339508\n",
      "\n",
      "episode 11, val func loss 0.1699189990758896\n",
      "\n",
      "episode 12, val func loss 0.19506877660751343\n",
      "\n",
      "episode 13, val func loss 0.1540321707725525\n",
      "\n",
      "episode 14, val func loss 0.18626168370246887\n",
      "\n",
      "episode 15, val func loss 0.1503899246454239\n",
      "\n",
      "episode 16, val func loss 0.18165414035320282\n",
      "\n",
      "Val func train loss in epoch 12:0.1654218677431345\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.15595100820064545\n",
      "\n",
      "episode 2, val func loss 0.1591900736093521\n",
      "\n",
      "episode 3, val func loss 0.16097696125507355\n",
      "\n",
      "episode 4, val func loss 0.15004278719425201\n",
      "\n",
      "episode 5, val func loss 0.16910851001739502\n",
      "\n",
      "episode 6, val func loss 0.19657674431800842\n",
      "\n",
      "episode 7, val func loss 0.18203569948673248\n",
      "\n",
      "episode 8, val func loss 0.18081583082675934\n",
      "\n",
      "episode 9, val func loss 0.1782608926296234\n",
      "\n",
      "episode 10, val func loss 0.13274358212947845\n",
      "\n",
      "episode 11, val func loss 0.15403656661510468\n",
      "\n",
      "episode 12, val func loss 0.13913603127002716\n",
      "\n",
      "episode 13, val func loss 0.19611607491970062\n",
      "\n",
      "episode 14, val func loss 0.1415005624294281\n",
      "\n",
      "episode 15, val func loss 0.1853657215833664\n",
      "\n",
      "episode 16, val func loss 0.16683711111545563\n",
      "\n",
      "Val func train loss in epoch 13:0.16554338485002518\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.13602811098098755\n",
      "\n",
      "episode 2, val func loss 0.15483276546001434\n",
      "\n",
      "episode 3, val func loss 0.19594036042690277\n",
      "\n",
      "episode 4, val func loss 0.1624649167060852\n",
      "\n",
      "episode 5, val func loss 0.18271251022815704\n",
      "\n",
      "episode 6, val func loss 0.16091366112232208\n",
      "\n",
      "episode 7, val func loss 0.1860695332288742\n",
      "\n",
      "episode 8, val func loss 0.14071938395500183\n",
      "\n",
      "episode 9, val func loss 0.13234072923660278\n",
      "\n",
      "episode 10, val func loss 0.1950446516275406\n",
      "\n",
      "episode 11, val func loss 0.16630859673023224\n",
      "\n",
      "episode 12, val func loss 0.1725596785545349\n",
      "\n",
      "episode 13, val func loss 0.17769600450992584\n",
      "\n",
      "episode 14, val func loss 0.1539018303155899\n",
      "\n",
      "episode 15, val func loss 0.15119971334934235\n",
      "\n",
      "episode 16, val func loss 0.17871873080730438\n",
      "\n",
      "Val func train loss in epoch 14:0.16546569857746363\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.15354612469673157\n",
      "\n",
      "episode 2, val func loss 0.1818537712097168\n",
      "\n",
      "episode 3, val func loss 0.16737601161003113\n",
      "\n",
      "episode 4, val func loss 0.13572794198989868\n",
      "\n",
      "episode 5, val func loss 0.1331072896718979\n",
      "\n",
      "episode 6, val func loss 0.15048258006572723\n",
      "\n",
      "episode 7, val func loss 0.1970912516117096\n",
      "\n",
      "episode 8, val func loss 0.18104171752929688\n",
      "\n",
      "episode 9, val func loss 0.15929098427295685\n",
      "\n",
      "episode 10, val func loss 0.16230721771717072\n",
      "\n",
      "episode 11, val func loss 0.14188025891780853\n",
      "\n",
      "episode 12, val func loss 0.1797323226928711\n",
      "\n",
      "episode 13, val func loss 0.1723136603832245\n",
      "\n",
      "episode 14, val func loss 0.19547513127326965\n",
      "\n",
      "episode 15, val func loss 0.1557452380657196\n",
      "\n",
      "episode 16, val func loss 0.18627838790416718\n",
      "\n",
      "Val func train loss in epoch 15:0.16582811810076237\n",
      "***********************TIME WAS 4.909960293769837 min*****************************\n",
      "\n",
      "**********************ROUND 44 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.044502098113298416\n",
      "\n",
      "episode 2, policy loss -0.1077650785446167\n",
      "\n",
      "episode 3, policy loss -0.0694131851196289\n",
      "\n",
      "episode 4, policy loss -0.07968705892562866\n",
      "\n",
      "episode 5, policy loss -0.03876567631959915\n",
      "\n",
      "episode 6, policy loss -0.05929247662425041\n",
      "\n",
      "episode 7, policy loss -0.04993009939789772\n",
      "\n",
      "episode 8, policy loss -0.06530071794986725\n",
      "\n",
      "episode 9, policy loss -0.009900009259581566\n",
      "\n",
      "episode 10, policy loss -0.11807304620742798\n",
      "\n",
      "episode 11, policy loss -0.04666643217206001\n",
      "\n",
      "episode 12, policy loss -0.0014611324295401573\n",
      "\n",
      "episode 13, policy loss -0.03216308355331421\n",
      "\n",
      "episode 14, policy loss -0.06684596836566925\n",
      "\n",
      "episode 15, policy loss -0.05813083052635193\n",
      "\n",
      "episode 16, policy loss -0.08753041177988052\n",
      "\n",
      "Policy train loss in epoch 0:-0.0584642065805383\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.044445618987083435\n",
      "\n",
      "episode 2, policy loss -0.05967520922422409\n",
      "\n",
      "episode 3, policy loss -0.06826411187648773\n",
      "\n",
      "episode 4, policy loss -0.07458821684122086\n",
      "\n",
      "episode 5, policy loss -0.11397869139909744\n",
      "\n",
      "episode 6, policy loss -0.0358286015689373\n",
      "\n",
      "episode 7, policy loss -0.06480702012777328\n",
      "\n",
      "episode 8, policy loss -0.042933203279972076\n",
      "\n",
      "episode 9, policy loss -0.061270035803318024\n",
      "\n",
      "episode 10, policy loss -0.0493110716342926\n",
      "\n",
      "episode 11, policy loss -0.08533766865730286\n",
      "\n",
      "episode 12, policy loss -0.08263645321130753\n",
      "\n",
      "episode 13, policy loss -0.1156870648264885\n",
      "\n",
      "episode 14, policy loss -0.049814511090517044\n",
      "\n",
      "episode 15, policy loss -0.011361462064087391\n",
      "\n",
      "episode 16, policy loss -0.0009105037897825241\n",
      "\n",
      "Policy train loss in epoch 1:-0.06005309027386829\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.11726539582014084\n",
      "\n",
      "episode 2, policy loss -0.03509131073951721\n",
      "\n",
      "episode 3, policy loss -0.04537934064865112\n",
      "\n",
      "episode 4, policy loss -0.08658783882856369\n",
      "\n",
      "episode 5, policy loss -0.060126837342977524\n",
      "\n",
      "episode 6, policy loss -0.058369964361190796\n",
      "\n",
      "episode 7, policy loss -0.039740219712257385\n",
      "\n",
      "episode 8, policy loss -0.050622619688510895\n",
      "\n",
      "episode 9, policy loss -0.06474228948354721\n",
      "\n",
      "episode 10, policy loss -0.08375116437673569\n",
      "\n",
      "episode 11, policy loss -0.07214240729808807\n",
      "\n",
      "episode 12, policy loss -0.045277189463377\n",
      "\n",
      "episode 13, policy loss -0.10863250494003296\n",
      "\n",
      "episode 14, policy loss -0.06356239318847656\n",
      "\n",
      "episode 15, policy loss -0.010226104408502579\n",
      "\n",
      "episode 16, policy loss 0.001536427065730095\n",
      "\n",
      "Policy train loss in epoch 2:-0.058748822077177465\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.08188634365797043\n",
      "\n",
      "episode 2, policy loss -0.04363236203789711\n",
      "\n",
      "episode 3, policy loss -0.11489436030387878\n",
      "\n",
      "episode 4, policy loss -0.05069228261709213\n",
      "\n",
      "episode 5, policy loss -0.0337604321539402\n",
      "\n",
      "episode 6, policy loss -0.047262586653232574\n",
      "\n",
      "episode 7, policy loss 0.00032176822423934937\n",
      "\n",
      "episode 8, policy loss -0.05739564448595047\n",
      "\n",
      "episode 9, policy loss -0.059331294149160385\n",
      "\n",
      "episode 10, policy loss -0.06627010554075241\n",
      "\n",
      "episode 11, policy loss -0.06980574876070023\n",
      "\n",
      "episode 12, policy loss -0.11765063554048538\n",
      "\n",
      "episode 13, policy loss -0.07676916569471359\n",
      "\n",
      "episode 14, policy loss -0.009293190203607082\n",
      "\n",
      "episode 15, policy loss -0.081505186855793\n",
      "\n",
      "episode 16, policy loss -0.042175162583589554\n",
      "\n",
      "Policy train loss in epoch 3:-0.05950017081340775\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17975832521915436\n",
      "\n",
      "episode 2, val func loss 0.159420907497406\n",
      "\n",
      "episode 3, val func loss 0.1967465579509735\n",
      "\n",
      "episode 4, val func loss 0.2050534188747406\n",
      "\n",
      "episode 5, val func loss 0.22391080856323242\n",
      "\n",
      "episode 6, val func loss 0.19820843636989594\n",
      "\n",
      "episode 7, val func loss 0.17730198800563812\n",
      "\n",
      "episode 8, val func loss 0.18419159948825836\n",
      "\n",
      "episode 9, val func loss 0.20701932907104492\n",
      "\n",
      "episode 10, val func loss 0.17244917154312134\n",
      "\n",
      "episode 11, val func loss 0.2009081393480301\n",
      "\n",
      "episode 12, val func loss 0.15138599276542664\n",
      "\n",
      "episode 13, val func loss 0.1647048443555832\n",
      "\n",
      "episode 14, val func loss 0.18576845526695251\n",
      "\n",
      "episode 15, val func loss 0.19521495699882507\n",
      "\n",
      "episode 16, val func loss 0.22283042967319489\n",
      "\n",
      "Val func train loss in epoch 0:0.18905458506196737\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.2062358856201172\n",
      "\n",
      "episode 2, val func loss 0.17178653180599213\n",
      "\n",
      "episode 3, val func loss 0.1854480654001236\n",
      "\n",
      "episode 4, val func loss 0.22250328958034515\n",
      "\n",
      "episode 5, val func loss 0.20259591937065125\n",
      "\n",
      "episode 6, val func loss 0.1828191876411438\n",
      "\n",
      "episode 7, val func loss 0.20484308898448944\n",
      "\n",
      "episode 8, val func loss 0.2179078608751297\n",
      "\n",
      "episode 9, val func loss 0.16065827012062073\n",
      "\n",
      "episode 10, val func loss 0.17739363014698029\n",
      "\n",
      "episode 11, val func loss 0.1947527378797531\n",
      "\n",
      "episode 12, val func loss 0.19728845357894897\n",
      "\n",
      "episode 13, val func loss 0.1535577028989792\n",
      "\n",
      "episode 14, val func loss 0.17926204204559326\n",
      "\n",
      "episode 15, val func loss 0.1960136592388153\n",
      "\n",
      "episode 16, val func loss 0.16444182395935059\n",
      "\n",
      "Val func train loss in epoch 1:0.1885942593216896\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.2234940528869629\n",
      "\n",
      "episode 2, val func loss 0.1601097136735916\n",
      "\n",
      "episode 3, val func loss 0.1964230090379715\n",
      "\n",
      "episode 4, val func loss 0.19856341183185577\n",
      "\n",
      "episode 5, val func loss 0.21872329711914062\n",
      "\n",
      "episode 6, val func loss 0.18598710000514984\n",
      "\n",
      "episode 7, val func loss 0.15761734545230865\n",
      "\n",
      "episode 8, val func loss 0.17747920751571655\n",
      "\n",
      "episode 9, val func loss 0.20552141964435577\n",
      "\n",
      "episode 10, val func loss 0.16927184164524078\n",
      "\n",
      "episode 11, val func loss 0.20426033437252045\n",
      "\n",
      "episode 12, val func loss 0.17907226085662842\n",
      "\n",
      "episode 13, val func loss 0.16513963043689728\n",
      "\n",
      "episode 14, val func loss 0.18293584883213043\n",
      "\n",
      "episode 15, val func loss 0.2057388573884964\n",
      "\n",
      "episode 16, val func loss 0.1940324306488037\n",
      "\n",
      "Val func train loss in epoch 2:0.18902311008423567\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1601244956254959\n",
      "\n",
      "episode 2, val func loss 0.19500289857387543\n",
      "\n",
      "episode 3, val func loss 0.20595601201057434\n",
      "\n",
      "episode 4, val func loss 0.20121636986732483\n",
      "\n",
      "episode 5, val func loss 0.17113377153873444\n",
      "\n",
      "episode 6, val func loss 0.1963501274585724\n",
      "\n",
      "episode 7, val func loss 0.18452075123786926\n",
      "\n",
      "episode 8, val func loss 0.17966501414775848\n",
      "\n",
      "episode 9, val func loss 0.17809459567070007\n",
      "\n",
      "episode 10, val func loss 0.22293518483638763\n",
      "\n",
      "episode 11, val func loss 0.15101125836372375\n",
      "\n",
      "episode 12, val func loss 0.18186154961585999\n",
      "\n",
      "episode 13, val func loss 0.1986505687236786\n",
      "\n",
      "episode 14, val func loss 0.22103571891784668\n",
      "\n",
      "episode 15, val func loss 0.16431783139705658\n",
      "\n",
      "episode 16, val func loss 0.20465028285980225\n",
      "\n",
      "Val func train loss in epoch 3:0.1885329019278288\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19612346589565277\n",
      "\n",
      "episode 2, val func loss 0.20620529353618622\n",
      "\n",
      "episode 3, val func loss 0.21756130456924438\n",
      "\n",
      "episode 4, val func loss 0.1969284862279892\n",
      "\n",
      "episode 5, val func loss 0.19996871054172516\n",
      "\n",
      "episode 6, val func loss 0.16591458022594452\n",
      "\n",
      "episode 7, val func loss 0.18440599739551544\n",
      "\n",
      "episode 8, val func loss 0.1724109649658203\n",
      "\n",
      "episode 9, val func loss 0.22178834676742554\n",
      "\n",
      "episode 10, val func loss 0.17824380099773407\n",
      "\n",
      "episode 11, val func loss 0.1855061799287796\n",
      "\n",
      "episode 12, val func loss 0.17906467616558075\n",
      "\n",
      "episode 13, val func loss 0.19455470144748688\n",
      "\n",
      "episode 14, val func loss 0.2048625946044922\n",
      "\n",
      "episode 15, val func loss 0.14987236261367798\n",
      "\n",
      "episode 16, val func loss 0.16002157330513\n",
      "\n",
      "Val func train loss in epoch 4:0.18833956494927406\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1951252520084381\n",
      "\n",
      "episode 2, val func loss 0.18646784126758575\n",
      "\n",
      "episode 3, val func loss 0.18207068741321564\n",
      "\n",
      "episode 4, val func loss 0.19800953567028046\n",
      "\n",
      "episode 5, val func loss 0.19602084159851074\n",
      "\n",
      "episode 6, val func loss 0.17783750593662262\n",
      "\n",
      "episode 7, val func loss 0.16605862975120544\n",
      "\n",
      "episode 8, val func loss 0.15625542402267456\n",
      "\n",
      "episode 9, val func loss 0.160627081990242\n",
      "\n",
      "episode 10, val func loss 0.20601245760917664\n",
      "\n",
      "episode 11, val func loss 0.2209796905517578\n",
      "\n",
      "episode 12, val func loss 0.1795307844877243\n",
      "\n",
      "episode 13, val func loss 0.16727909445762634\n",
      "\n",
      "episode 14, val func loss 0.20396050810813904\n",
      "\n",
      "episode 15, val func loss 0.22304464876651764\n",
      "\n",
      "episode 16, val func loss 0.20400945842266083\n",
      "\n",
      "Val func train loss in epoch 5:0.18895559012889862\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18259596824645996\n",
      "\n",
      "episode 2, val func loss 0.19666950404644012\n",
      "\n",
      "episode 3, val func loss 0.17771016061306\n",
      "\n",
      "episode 4, val func loss 0.2223387211561203\n",
      "\n",
      "episode 5, val func loss 0.18656304478645325\n",
      "\n",
      "episode 6, val func loss 0.20028243958950043\n",
      "\n",
      "episode 7, val func loss 0.21730725467205048\n",
      "\n",
      "episode 8, val func loss 0.19655755162239075\n",
      "\n",
      "episode 9, val func loss 0.16511063277721405\n",
      "\n",
      "episode 10, val func loss 0.1608828753232956\n",
      "\n",
      "episode 11, val func loss 0.20571933686733246\n",
      "\n",
      "episode 12, val func loss 0.17929509282112122\n",
      "\n",
      "episode 13, val func loss 0.1676616668701172\n",
      "\n",
      "episode 14, val func loss 0.20590579509735107\n",
      "\n",
      "episode 15, val func loss 0.14816369116306305\n",
      "\n",
      "episode 16, val func loss 0.1989319622516632\n",
      "\n",
      "Val func train loss in epoch 6:0.18823098111897707\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.20155061781406403\n",
      "\n",
      "episode 2, val func loss 0.1822057068347931\n",
      "\n",
      "episode 3, val func loss 0.1854097545146942\n",
      "\n",
      "episode 4, val func loss 0.16053155064582825\n",
      "\n",
      "episode 5, val func loss 0.20042778551578522\n",
      "\n",
      "episode 6, val func loss 0.20709100365638733\n",
      "\n",
      "episode 7, val func loss 0.20599500834941864\n",
      "\n",
      "episode 8, val func loss 0.19555139541625977\n",
      "\n",
      "episode 9, val func loss 0.19601836800575256\n",
      "\n",
      "episode 10, val func loss 0.15154145658016205\n",
      "\n",
      "episode 11, val func loss 0.16499797999858856\n",
      "\n",
      "episode 12, val func loss 0.18131235241889954\n",
      "\n",
      "episode 13, val func loss 0.223283588886261\n",
      "\n",
      "episode 14, val func loss 0.1789552867412567\n",
      "\n",
      "episode 15, val func loss 0.1691490113735199\n",
      "\n",
      "episode 16, val func loss 0.22247350215911865\n",
      "\n",
      "Val func train loss in epoch 7:0.18915589805692434\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.22193393111228943\n",
      "\n",
      "episode 2, val func loss 0.17784346640110016\n",
      "\n",
      "episode 3, val func loss 0.20580758154392242\n",
      "\n",
      "episode 4, val func loss 0.1952877640724182\n",
      "\n",
      "episode 5, val func loss 0.20482507348060608\n",
      "\n",
      "episode 6, val func loss 0.2021723836660385\n",
      "\n",
      "episode 7, val func loss 0.17943885922431946\n",
      "\n",
      "episode 8, val func loss 0.16995006799697876\n",
      "\n",
      "episode 9, val func loss 0.1856675148010254\n",
      "\n",
      "episode 10, val func loss 0.15051129460334778\n",
      "\n",
      "episode 11, val func loss 0.1648925393819809\n",
      "\n",
      "episode 12, val func loss 0.19793619215488434\n",
      "\n",
      "episode 13, val func loss 0.20011618733406067\n",
      "\n",
      "episode 14, val func loss 0.22222121059894562\n",
      "\n",
      "episode 15, val func loss 0.1596156507730484\n",
      "\n",
      "episode 16, val func loss 0.18199841678142548\n",
      "\n",
      "Val func train loss in epoch 8:0.18876363337039948\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18565279245376587\n",
      "\n",
      "episode 2, val func loss 0.19999374449253082\n",
      "\n",
      "episode 3, val func loss 0.16167159378528595\n",
      "\n",
      "episode 4, val func loss 0.20556651055812836\n",
      "\n",
      "episode 5, val func loss 0.1719139963388443\n",
      "\n",
      "episode 6, val func loss 0.19442811608314514\n",
      "\n",
      "episode 7, val func loss 0.22352562844753265\n",
      "\n",
      "episode 8, val func loss 0.16466361284255981\n",
      "\n",
      "episode 9, val func loss 0.18253204226493835\n",
      "\n",
      "episode 10, val func loss 0.19628745317459106\n",
      "\n",
      "episode 11, val func loss 0.17884407937526703\n",
      "\n",
      "episode 12, val func loss 0.20618696510791779\n",
      "\n",
      "episode 13, val func loss 0.15153451263904572\n",
      "\n",
      "episode 14, val func loss 0.2199610024690628\n",
      "\n",
      "episode 15, val func loss 0.19792476296424866\n",
      "\n",
      "episode 16, val func loss 0.17804694175720215\n",
      "\n",
      "Val func train loss in epoch 9:0.18867085967212915\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.15285703539848328\n",
      "\n",
      "episode 2, val func loss 0.18508882820606232\n",
      "\n",
      "episode 3, val func loss 0.2183079570531845\n",
      "\n",
      "episode 4, val func loss 0.16426420211791992\n",
      "\n",
      "episode 5, val func loss 0.17785602807998657\n",
      "\n",
      "episode 6, val func loss 0.16028672456741333\n",
      "\n",
      "episode 7, val func loss 0.17947594821453094\n",
      "\n",
      "episode 8, val func loss 0.20100252330303192\n",
      "\n",
      "episode 9, val func loss 0.19569405913352966\n",
      "\n",
      "episode 10, val func loss 0.20460382103919983\n",
      "\n",
      "episode 11, val func loss 0.16985206305980682\n",
      "\n",
      "episode 12, val func loss 0.18212705850601196\n",
      "\n",
      "episode 13, val func loss 0.19424600899219513\n",
      "\n",
      "episode 14, val func loss 0.199082151055336\n",
      "\n",
      "episode 15, val func loss 0.2235746681690216\n",
      "\n",
      "episode 16, val func loss 0.2056093066930771\n",
      "\n",
      "Val func train loss in epoch 10:0.18837052397429943\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18224266171455383\n",
      "\n",
      "episode 2, val func loss 0.16485311090946198\n",
      "\n",
      "episode 3, val func loss 0.20110055804252625\n",
      "\n",
      "episode 4, val func loss 0.20545636117458344\n",
      "\n",
      "episode 5, val func loss 0.17750173807144165\n",
      "\n",
      "episode 6, val func loss 0.16175620257854462\n",
      "\n",
      "episode 7, val func loss 0.18083597719669342\n",
      "\n",
      "episode 8, val func loss 0.15460807085037231\n",
      "\n",
      "episode 9, val func loss 0.18501773476600647\n",
      "\n",
      "episode 10, val func loss 0.22304721176624298\n",
      "\n",
      "episode 11, val func loss 0.1960802972316742\n",
      "\n",
      "episode 12, val func loss 0.221521258354187\n",
      "\n",
      "episode 13, val func loss 0.16756251454353333\n",
      "\n",
      "episode 14, val func loss 0.19464963674545288\n",
      "\n",
      "episode 15, val func loss 0.1986263543367386\n",
      "\n",
      "episode 16, val func loss 0.20401494204998016\n",
      "\n",
      "Val func train loss in epoch 11:0.18867966439574957\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17926974594593048\n",
      "\n",
      "episode 2, val func loss 0.1597924679517746\n",
      "\n",
      "episode 3, val func loss 0.196981742978096\n",
      "\n",
      "episode 4, val func loss 0.16508176922798157\n",
      "\n",
      "episode 5, val func loss 0.18228217959403992\n",
      "\n",
      "episode 6, val func loss 0.1530446857213974\n",
      "\n",
      "episode 7, val func loss 0.16888761520385742\n",
      "\n",
      "episode 8, val func loss 0.2236316204071045\n",
      "\n",
      "episode 9, val func loss 0.17963138222694397\n",
      "\n",
      "episode 10, val func loss 0.20520123839378357\n",
      "\n",
      "episode 11, val func loss 0.1969163715839386\n",
      "\n",
      "episode 12, val func loss 0.20370690524578094\n",
      "\n",
      "episode 13, val func loss 0.19431720674037933\n",
      "\n",
      "episode 14, val func loss 0.20576398074626923\n",
      "\n",
      "episode 15, val func loss 0.18574661016464233\n",
      "\n",
      "episode 16, val func loss 0.21731692552566528\n",
      "\n",
      "Val func train loss in epoch 12:0.18859827797859907\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19663110375404358\n",
      "\n",
      "episode 2, val func loss 0.2057548612356186\n",
      "\n",
      "episode 3, val func loss 0.16548599302768707\n",
      "\n",
      "episode 4, val func loss 0.15520338714122772\n",
      "\n",
      "episode 5, val func loss 0.22228498756885529\n",
      "\n",
      "episode 6, val func loss 0.19808772206306458\n",
      "\n",
      "episode 7, val func loss 0.17955440282821655\n",
      "\n",
      "episode 8, val func loss 0.22136448323726654\n",
      "\n",
      "episode 9, val func loss 0.1945887953042984\n",
      "\n",
      "episode 10, val func loss 0.17865222692489624\n",
      "\n",
      "episode 11, val func loss 0.20573420822620392\n",
      "\n",
      "episode 12, val func loss 0.182036355137825\n",
      "\n",
      "episode 13, val func loss 0.1851598173379898\n",
      "\n",
      "episode 14, val func loss 0.17055702209472656\n",
      "\n",
      "episode 15, val func loss 0.1604597568511963\n",
      "\n",
      "episode 16, val func loss 0.20166613161563873\n",
      "\n",
      "Val func train loss in epoch 13:0.18895132839679718\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.16022831201553345\n",
      "\n",
      "episode 2, val func loss 0.17838603258132935\n",
      "\n",
      "episode 3, val func loss 0.20186862349510193\n",
      "\n",
      "episode 4, val func loss 0.1519828736782074\n",
      "\n",
      "episode 5, val func loss 0.21809121966362\n",
      "\n",
      "episode 6, val func loss 0.19555789232254028\n",
      "\n",
      "episode 7, val func loss 0.204545795917511\n",
      "\n",
      "episode 8, val func loss 0.19498346745967865\n",
      "\n",
      "episode 9, val func loss 0.1696837693452835\n",
      "\n",
      "episode 10, val func loss 0.17945939302444458\n",
      "\n",
      "episode 11, val func loss 0.16446588933467865\n",
      "\n",
      "episode 12, val func loss 0.20625680685043335\n",
      "\n",
      "episode 13, val func loss 0.18265044689178467\n",
      "\n",
      "episode 14, val func loss 0.22305990755558014\n",
      "\n",
      "episode 15, val func loss 0.1985989511013031\n",
      "\n",
      "episode 16, val func loss 0.1857653707265854\n",
      "\n",
      "Val func train loss in epoch 14:0.18847404699772596\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.21849989891052246\n",
      "\n",
      "episode 2, val func loss 0.19748124480247498\n",
      "\n",
      "episode 3, val func loss 0.2072230875492096\n",
      "\n",
      "episode 4, val func loss 0.2070288509130478\n",
      "\n",
      "episode 5, val func loss 0.19998298585414886\n",
      "\n",
      "episode 6, val func loss 0.18180832266807556\n",
      "\n",
      "episode 7, val func loss 0.1832684725522995\n",
      "\n",
      "episode 8, val func loss 0.19467295706272125\n",
      "\n",
      "episode 9, val func loss 0.15951652824878693\n",
      "\n",
      "episode 10, val func loss 0.1982952058315277\n",
      "\n",
      "episode 11, val func loss 0.148992121219635\n",
      "\n",
      "episode 12, val func loss 0.18050837516784668\n",
      "\n",
      "episode 13, val func loss 0.16711905598640442\n",
      "\n",
      "episode 14, val func loss 0.18568827211856842\n",
      "\n",
      "episode 15, val func loss 0.22317811846733093\n",
      "\n",
      "episode 16, val func loss 0.16463592648506165\n",
      "\n",
      "Val func train loss in epoch 15:0.18861871398985386\n",
      "***********************TIME WAS 4.907780492305756 min*****************************\n",
      "\n",
      "**********************ROUND 45 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.03295896202325821\n",
      "\n",
      "episode 2, policy loss -0.056198470294475555\n",
      "\n",
      "episode 3, policy loss -0.029889410361647606\n",
      "\n",
      "episode 4, policy loss -0.06654603034257889\n",
      "\n",
      "episode 5, policy loss -0.07148998230695724\n",
      "\n",
      "episode 6, policy loss 0.019781148061156273\n",
      "\n",
      "episode 7, policy loss -0.02372458204627037\n",
      "\n",
      "episode 8, policy loss -0.021683476865291595\n",
      "\n",
      "episode 9, policy loss -0.03467384725809097\n",
      "\n",
      "episode 10, policy loss -0.02418389916419983\n",
      "\n",
      "episode 11, policy loss -0.06161375716328621\n",
      "\n",
      "episode 12, policy loss -0.007200460880994797\n",
      "\n",
      "episode 13, policy loss -0.09217603504657745\n",
      "\n",
      "episode 14, policy loss -0.047636132687330246\n",
      "\n",
      "episode 15, policy loss 0.012865006923675537\n",
      "\n",
      "episode 16, policy loss -0.012585215270519257\n",
      "\n",
      "Policy train loss in epoch 0:-0.0343696316704154\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.0258196871727705\n",
      "\n",
      "episode 2, policy loss 0.013245662674307823\n",
      "\n",
      "episode 3, policy loss -0.05574620142579079\n",
      "\n",
      "episode 4, policy loss -0.016497613862156868\n",
      "\n",
      "episode 5, policy loss -0.03537048399448395\n",
      "\n",
      "episode 6, policy loss -0.01655237376689911\n",
      "\n",
      "episode 7, policy loss -0.06188853457570076\n",
      "\n",
      "episode 8, policy loss -0.011282002553343773\n",
      "\n",
      "episode 9, policy loss -0.07124194502830505\n",
      "\n",
      "episode 10, policy loss -0.037042513489723206\n",
      "\n",
      "episode 11, policy loss -0.01054639182984829\n",
      "\n",
      "episode 12, policy loss -0.09698749333620071\n",
      "\n",
      "episode 13, policy loss -0.057783789932727814\n",
      "\n",
      "episode 14, policy loss -0.0673767626285553\n",
      "\n",
      "episode 15, policy loss 0.020582038909196854\n",
      "\n",
      "episode 16, policy loss -0.03147177770733833\n",
      "\n",
      "Policy train loss in epoch 1:-0.035111241857521236\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.012822874821722507\n",
      "\n",
      "episode 2, policy loss -0.03334088623523712\n",
      "\n",
      "episode 3, policy loss -0.0684119388461113\n",
      "\n",
      "episode 4, policy loss 0.015735434368252754\n",
      "\n",
      "episode 5, policy loss -0.055851053446531296\n",
      "\n",
      "episode 6, policy loss -0.02338993176817894\n",
      "\n",
      "episode 7, policy loss -0.05605199933052063\n",
      "\n",
      "episode 8, policy loss -0.06128718703985214\n",
      "\n",
      "episode 9, policy loss 0.020257387310266495\n",
      "\n",
      "episode 10, policy loss -0.019536610692739487\n",
      "\n",
      "episode 11, policy loss -0.09933841228485107\n",
      "\n",
      "episode 12, policy loss -0.035380683839321136\n",
      "\n",
      "episode 13, policy loss -0.036629773676395416\n",
      "\n",
      "episode 14, policy loss -0.0219784677028656\n",
      "\n",
      "episode 15, policy loss -0.008834595791995525\n",
      "\n",
      "episode 16, policy loss -0.06948844343423843\n",
      "\n",
      "Policy train loss in epoch 2:-0.035396877327002585\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.06713014841079712\n",
      "\n",
      "episode 2, policy loss -0.023565780371427536\n",
      "\n",
      "episode 3, policy loss 0.01208559051156044\n",
      "\n",
      "episode 4, policy loss -0.026998277753591537\n",
      "\n",
      "episode 5, policy loss -0.049882322549819946\n",
      "\n",
      "episode 6, policy loss -0.01072411797940731\n",
      "\n",
      "episode 7, policy loss -0.061579130589962006\n",
      "\n",
      "episode 8, policy loss -0.021433426067233086\n",
      "\n",
      "episode 9, policy loss 0.02036205120384693\n",
      "\n",
      "episode 10, policy loss -0.03731917217373848\n",
      "\n",
      "episode 11, policy loss -0.09925369173288345\n",
      "\n",
      "episode 12, policy loss -0.03456154838204384\n",
      "\n",
      "episode 13, policy loss -0.03469075635075569\n",
      "\n",
      "episode 14, policy loss -0.06778937578201294\n",
      "\n",
      "episode 15, policy loss -0.012921882793307304\n",
      "\n",
      "episode 16, policy loss -0.05665012449026108\n",
      "\n",
      "Policy train loss in epoch 3:-0.03575325710698962\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1877785176038742\n",
      "\n",
      "episode 2, val func loss 0.1701856106519699\n",
      "\n",
      "episode 3, val func loss 0.1796502321958542\n",
      "\n",
      "episode 4, val func loss 0.1857086718082428\n",
      "\n",
      "episode 5, val func loss 0.1908619999885559\n",
      "\n",
      "episode 6, val func loss 0.22314578294754028\n",
      "\n",
      "episode 7, val func loss 0.1373753398656845\n",
      "\n",
      "episode 8, val func loss 0.18445496261119843\n",
      "\n",
      "episode 9, val func loss 0.20200258493423462\n",
      "\n",
      "episode 10, val func loss 0.18056052923202515\n",
      "\n",
      "episode 11, val func loss 0.1659667193889618\n",
      "\n",
      "episode 12, val func loss 0.18431276082992554\n",
      "\n",
      "episode 13, val func loss 0.1852564811706543\n",
      "\n",
      "episode 14, val func loss 0.19538888335227966\n",
      "\n",
      "episode 15, val func loss 0.17313824594020844\n",
      "\n",
      "episode 16, val func loss 0.21528418362140656\n",
      "\n",
      "Val func train loss in epoch 0:0.18506696913391352\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1914920061826706\n",
      "\n",
      "episode 2, val func loss 0.18541334569454193\n",
      "\n",
      "episode 3, val func loss 0.20216220617294312\n",
      "\n",
      "episode 4, val func loss 0.21354907751083374\n",
      "\n",
      "episode 5, val func loss 0.1876223236322403\n",
      "\n",
      "episode 6, val func loss 0.1930658519268036\n",
      "\n",
      "episode 7, val func loss 0.18654455244541168\n",
      "\n",
      "episode 8, val func loss 0.18642064929008484\n",
      "\n",
      "episode 9, val func loss 0.1380583792924881\n",
      "\n",
      "episode 10, val func loss 0.17013923823833466\n",
      "\n",
      "episode 11, val func loss 0.18300141394138336\n",
      "\n",
      "episode 12, val func loss 0.17915385961532593\n",
      "\n",
      "episode 13, val func loss 0.1825588494539261\n",
      "\n",
      "episode 14, val func loss 0.16598768532276154\n",
      "\n",
      "episode 15, val func loss 0.1734347939491272\n",
      "\n",
      "episode 16, val func loss 0.22670456767082214\n",
      "\n",
      "Val func train loss in epoch 1:0.18533180002123117\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.22483982145786285\n",
      "\n",
      "episode 2, val func loss 0.18741993606090546\n",
      "\n",
      "episode 3, val func loss 0.17845460772514343\n",
      "\n",
      "episode 4, val func loss 0.1858387440443039\n",
      "\n",
      "episode 5, val func loss 0.18109247088432312\n",
      "\n",
      "episode 6, val func loss 0.1857934594154358\n",
      "\n",
      "episode 7, val func loss 0.16612586379051208\n",
      "\n",
      "episode 8, val func loss 0.19326843321323395\n",
      "\n",
      "episode 9, val func loss 0.18765883147716522\n",
      "\n",
      "episode 10, val func loss 0.17074355483055115\n",
      "\n",
      "episode 11, val func loss 0.19369183480739594\n",
      "\n",
      "episode 12, val func loss 0.21437068283557892\n",
      "\n",
      "episode 13, val func loss 0.17993491888046265\n",
      "\n",
      "episode 14, val func loss 0.18463283777236938\n",
      "\n",
      "episode 15, val func loss 0.20122569799423218\n",
      "\n",
      "episode 16, val func loss 0.1388469636440277\n",
      "\n",
      "Val func train loss in epoch 2:0.18587116617709398\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1911909580230713\n",
      "\n",
      "episode 2, val func loss 0.2254883348941803\n",
      "\n",
      "episode 3, val func loss 0.20171566307544708\n",
      "\n",
      "episode 4, val func loss 0.18605659902095795\n",
      "\n",
      "episode 5, val func loss 0.1810537427663803\n",
      "\n",
      "episode 6, val func loss 0.18608562648296356\n",
      "\n",
      "episode 7, val func loss 0.16993020474910736\n",
      "\n",
      "episode 8, val func loss 0.17312733829021454\n",
      "\n",
      "episode 9, val func loss 0.22163304686546326\n",
      "\n",
      "episode 10, val func loss 0.18341684341430664\n",
      "\n",
      "episode 11, val func loss 0.13470108807086945\n",
      "\n",
      "episode 12, val func loss 0.19406673312187195\n",
      "\n",
      "episode 13, val func loss 0.1838224083185196\n",
      "\n",
      "episode 14, val func loss 0.166129007935524\n",
      "\n",
      "episode 15, val func loss 0.18069356679916382\n",
      "\n",
      "episode 16, val func loss 0.1881580799818039\n",
      "\n",
      "Val func train loss in epoch 3:0.1854543276131153\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.22254633903503418\n",
      "\n",
      "episode 2, val func loss 0.20111146569252014\n",
      "\n",
      "episode 3, val func loss 0.17103834450244904\n",
      "\n",
      "episode 4, val func loss 0.1878029853105545\n",
      "\n",
      "episode 5, val func loss 0.19340351223945618\n",
      "\n",
      "episode 6, val func loss 0.18055874109268188\n",
      "\n",
      "episode 7, val func loss 0.21367491781711578\n",
      "\n",
      "episode 8, val func loss 0.17620187997817993\n",
      "\n",
      "episode 9, val func loss 0.1657886952161789\n",
      "\n",
      "episode 10, val func loss 0.18354548513889313\n",
      "\n",
      "episode 11, val func loss 0.13351242244243622\n",
      "\n",
      "episode 12, val func loss 0.1978251039981842\n",
      "\n",
      "episode 13, val func loss 0.1908392310142517\n",
      "\n",
      "episode 14, val func loss 0.18315382301807404\n",
      "\n",
      "episode 15, val func loss 0.18583376705646515\n",
      "\n",
      "episode 16, val func loss 0.18000023066997528\n",
      "\n",
      "Val func train loss in epoch 4:0.18542730901390314\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1381504088640213\n",
      "\n",
      "episode 2, val func loss 0.20181243121623993\n",
      "\n",
      "episode 3, val func loss 0.18654172122478485\n",
      "\n",
      "episode 4, val func loss 0.1875171959400177\n",
      "\n",
      "episode 5, val func loss 0.17519818246364594\n",
      "\n",
      "episode 6, val func loss 0.18282116949558258\n",
      "\n",
      "episode 7, val func loss 0.16646476089954376\n",
      "\n",
      "episode 8, val func loss 0.21740582585334778\n",
      "\n",
      "episode 9, val func loss 0.19251155853271484\n",
      "\n",
      "episode 10, val func loss 0.17882366478443146\n",
      "\n",
      "episode 11, val func loss 0.18504182994365692\n",
      "\n",
      "episode 12, val func loss 0.18352173268795013\n",
      "\n",
      "episode 13, val func loss 0.19420844316482544\n",
      "\n",
      "episode 14, val func loss 0.1802385151386261\n",
      "\n",
      "episode 15, val func loss 0.17085936665534973\n",
      "\n",
      "episode 16, val func loss 0.2224317193031311\n",
      "\n",
      "Val func train loss in epoch 5:0.18522178288549185\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19372127950191498\n",
      "\n",
      "episode 2, val func loss 0.2202354073524475\n",
      "\n",
      "episode 3, val func loss 0.14162318408489227\n",
      "\n",
      "episode 4, val func loss 0.18854756653308868\n",
      "\n",
      "episode 5, val func loss 0.18601569533348083\n",
      "\n",
      "episode 6, val func loss 0.16614188253879547\n",
      "\n",
      "episode 7, val func loss 0.1785057932138443\n",
      "\n",
      "episode 8, val func loss 0.18724408745765686\n",
      "\n",
      "episode 9, val func loss 0.19338537752628326\n",
      "\n",
      "episode 10, val func loss 0.2165195196866989\n",
      "\n",
      "episode 11, val func loss 0.17056280374526978\n",
      "\n",
      "episode 12, val func loss 0.18354064226150513\n",
      "\n",
      "episode 13, val func loss 0.18095169961452484\n",
      "\n",
      "episode 14, val func loss 0.20231342315673828\n",
      "\n",
      "episode 15, val func loss 0.18719811737537384\n",
      "\n",
      "episode 16, val func loss 0.17797914147377014\n",
      "\n",
      "Val func train loss in epoch 6:0.18590535130351782\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.2129230797290802\n",
      "\n",
      "episode 2, val func loss 0.22137965261936188\n",
      "\n",
      "episode 3, val func loss 0.20178981125354767\n",
      "\n",
      "episode 4, val func loss 0.18066740036010742\n",
      "\n",
      "episode 5, val func loss 0.16760699450969696\n",
      "\n",
      "episode 6, val func loss 0.19335071742534637\n",
      "\n",
      "episode 7, val func loss 0.17068815231323242\n",
      "\n",
      "episode 8, val func loss 0.18591338396072388\n",
      "\n",
      "episode 9, val func loss 0.17956498265266418\n",
      "\n",
      "episode 10, val func loss 0.1885032057762146\n",
      "\n",
      "episode 11, val func loss 0.1342048943042755\n",
      "\n",
      "episode 12, val func loss 0.18289460241794586\n",
      "\n",
      "episode 13, val func loss 0.19348180294036865\n",
      "\n",
      "episode 14, val func loss 0.171843484044075\n",
      "\n",
      "episode 15, val func loss 0.1832866668701172\n",
      "\n",
      "episode 16, val func loss 0.1850055605173111\n",
      "\n",
      "Val func train loss in epoch 7:0.1845690244808793\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16634388267993927\n",
      "\n",
      "episode 2, val func loss 0.19516822695732117\n",
      "\n",
      "episode 3, val func loss 0.22473235428333282\n",
      "\n",
      "episode 4, val func loss 0.179950550198555\n",
      "\n",
      "episode 5, val func loss 0.1851586550474167\n",
      "\n",
      "episode 6, val func loss 0.18709318339824677\n",
      "\n",
      "episode 7, val func loss 0.18034811317920685\n",
      "\n",
      "episode 8, val func loss 0.18579496443271637\n",
      "\n",
      "episode 9, val func loss 0.17024299502372742\n",
      "\n",
      "episode 10, val func loss 0.2138253152370453\n",
      "\n",
      "episode 11, val func loss 0.1882937103509903\n",
      "\n",
      "episode 12, val func loss 0.18585897982120514\n",
      "\n",
      "episode 13, val func loss 0.13484714925289154\n",
      "\n",
      "episode 14, val func loss 0.17373234033584595\n",
      "\n",
      "episode 15, val func loss 0.20434235036373138\n",
      "\n",
      "episode 16, val func loss 0.19158533215522766\n",
      "\n",
      "Val func train loss in epoch 8:0.18545738141983747\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.21556663513183594\n",
      "\n",
      "episode 2, val func loss 0.20341651141643524\n",
      "\n",
      "episode 3, val func loss 0.1830172836780548\n",
      "\n",
      "episode 4, val func loss 0.17917832732200623\n",
      "\n",
      "episode 5, val func loss 0.19113613665103912\n",
      "\n",
      "episode 6, val func loss 0.18639203906059265\n",
      "\n",
      "episode 7, val func loss 0.1765812188386917\n",
      "\n",
      "episode 8, val func loss 0.16595928370952606\n",
      "\n",
      "episode 9, val func loss 0.18799790740013123\n",
      "\n",
      "episode 10, val func loss 0.17016713321208954\n",
      "\n",
      "episode 11, val func loss 0.18207421898841858\n",
      "\n",
      "episode 12, val func loss 0.19498395919799805\n",
      "\n",
      "episode 13, val func loss 0.1861695647239685\n",
      "\n",
      "episode 14, val func loss 0.13577374815940857\n",
      "\n",
      "episode 15, val func loss 0.22382798790931702\n",
      "\n",
      "episode 16, val func loss 0.18339094519615173\n",
      "\n",
      "Val func train loss in epoch 9:0.18535205628722906\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.16667646169662476\n",
      "\n",
      "episode 2, val func loss 0.17992766201496124\n",
      "\n",
      "episode 3, val func loss 0.21330498158931732\n",
      "\n",
      "episode 4, val func loss 0.19348682463169098\n",
      "\n",
      "episode 5, val func loss 0.18640463054180145\n",
      "\n",
      "episode 6, val func loss 0.22090762853622437\n",
      "\n",
      "episode 7, val func loss 0.17835652828216553\n",
      "\n",
      "episode 8, val func loss 0.1874583661556244\n",
      "\n",
      "episode 9, val func loss 0.1803455799818039\n",
      "\n",
      "episode 10, val func loss 0.18378117680549622\n",
      "\n",
      "episode 11, val func loss 0.19152763485908508\n",
      "\n",
      "episode 12, val func loss 0.17042399942874908\n",
      "\n",
      "episode 13, val func loss 0.18287122249603271\n",
      "\n",
      "episode 14, val func loss 0.20444662868976593\n",
      "\n",
      "episode 15, val func loss 0.1847960501909256\n",
      "\n",
      "episode 16, val func loss 0.1341177523136139\n",
      "\n",
      "Val func train loss in epoch 10:0.18492707051336765\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18262577056884766\n",
      "\n",
      "episode 2, val func loss 0.13392195105552673\n",
      "\n",
      "episode 3, val func loss 0.1792840212583542\n",
      "\n",
      "episode 4, val func loss 0.18321634829044342\n",
      "\n",
      "episode 5, val func loss 0.19601953029632568\n",
      "\n",
      "episode 6, val func loss 0.21561303734779358\n",
      "\n",
      "episode 7, val func loss 0.18502923846244812\n",
      "\n",
      "episode 8, val func loss 0.20243193209171295\n",
      "\n",
      "episode 9, val func loss 0.17013968527317047\n",
      "\n",
      "episode 10, val func loss 0.18679727613925934\n",
      "\n",
      "episode 11, val func loss 0.1802457720041275\n",
      "\n",
      "episode 12, val func loss 0.1926310658454895\n",
      "\n",
      "episode 13, val func loss 0.2195461094379425\n",
      "\n",
      "episode 14, val func loss 0.18073774874210358\n",
      "\n",
      "episode 15, val func loss 0.16757528483867645\n",
      "\n",
      "episode 16, val func loss 0.1875745952129364\n",
      "\n",
      "Val func train loss in epoch 11:0.18521183542907238\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1829153597354889\n",
      "\n",
      "episode 2, val func loss 0.2030874788761139\n",
      "\n",
      "episode 3, val func loss 0.19208961725234985\n",
      "\n",
      "episode 4, val func loss 0.13401466608047485\n",
      "\n",
      "episode 5, val func loss 0.2286364734172821\n",
      "\n",
      "episode 6, val func loss 0.16613145172595978\n",
      "\n",
      "episode 7, val func loss 0.18653297424316406\n",
      "\n",
      "episode 8, val func loss 0.18064317107200623\n",
      "\n",
      "episode 9, val func loss 0.17087891697883606\n",
      "\n",
      "episode 10, val func loss 0.19360004365444183\n",
      "\n",
      "episode 11, val func loss 0.1778741180896759\n",
      "\n",
      "episode 12, val func loss 0.18658050894737244\n",
      "\n",
      "episode 13, val func loss 0.17978042364120483\n",
      "\n",
      "episode 14, val func loss 0.2132747918367386\n",
      "\n",
      "episode 15, val func loss 0.18803700804710388\n",
      "\n",
      "episode 16, val func loss 0.18305513262748718\n",
      "\n",
      "Val func train loss in epoch 12:0.18544575851410627\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.17054931819438934\n",
      "\n",
      "episode 2, val func loss 0.22491967678070068\n",
      "\n",
      "episode 3, val func loss 0.20315448939800262\n",
      "\n",
      "episode 4, val func loss 0.17483286559581757\n",
      "\n",
      "episode 5, val func loss 0.1849440336227417\n",
      "\n",
      "episode 6, val func loss 0.17945115268230438\n",
      "\n",
      "episode 7, val func loss 0.16599678993225098\n",
      "\n",
      "episode 8, val func loss 0.18592822551727295\n",
      "\n",
      "episode 9, val func loss 0.13513849675655365\n",
      "\n",
      "episode 10, val func loss 0.18337573111057281\n",
      "\n",
      "episode 11, val func loss 0.18238863348960876\n",
      "\n",
      "episode 12, val func loss 0.1888839453458786\n",
      "\n",
      "episode 13, val func loss 0.21504847705364227\n",
      "\n",
      "episode 14, val func loss 0.19437411427497864\n",
      "\n",
      "episode 15, val func loss 0.1838027536869049\n",
      "\n",
      "episode 16, val func loss 0.19165831804275513\n",
      "\n",
      "Val func train loss in epoch 13:0.18527793884277344\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1759921759366989\n",
      "\n",
      "episode 2, val func loss 0.18578392267227173\n",
      "\n",
      "episode 3, val func loss 0.16993089020252228\n",
      "\n",
      "episode 4, val func loss 0.1858690083026886\n",
      "\n",
      "episode 5, val func loss 0.19084610044956207\n",
      "\n",
      "episode 6, val func loss 0.1807398647069931\n",
      "\n",
      "episode 7, val func loss 0.18795424699783325\n",
      "\n",
      "episode 8, val func loss 0.16623204946517944\n",
      "\n",
      "episode 9, val func loss 0.1833736151456833\n",
      "\n",
      "episode 10, val func loss 0.18292738497257233\n",
      "\n",
      "episode 11, val func loss 0.20244893431663513\n",
      "\n",
      "episode 12, val func loss 0.1795891523361206\n",
      "\n",
      "episode 13, val func loss 0.21435944736003876\n",
      "\n",
      "episode 14, val func loss 0.19373637437820435\n",
      "\n",
      "episode 15, val func loss 0.22250217199325562\n",
      "\n",
      "episode 16, val func loss 0.13786765933036804\n",
      "\n",
      "Val func train loss in epoch 14:0.18500956241041422\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.22137466073036194\n",
      "\n",
      "episode 2, val func loss 0.18768484890460968\n",
      "\n",
      "episode 3, val func loss 0.16838288307189941\n",
      "\n",
      "episode 4, val func loss 0.1877458244562149\n",
      "\n",
      "episode 5, val func loss 0.21317067742347717\n",
      "\n",
      "episode 6, val func loss 0.1704859584569931\n",
      "\n",
      "episode 7, val func loss 0.13685564696788788\n",
      "\n",
      "episode 8, val func loss 0.18053415417671204\n",
      "\n",
      "episode 9, val func loss 0.17907439172267914\n",
      "\n",
      "episode 10, val func loss 0.18298417329788208\n",
      "\n",
      "episode 11, val func loss 0.1718096286058426\n",
      "\n",
      "episode 12, val func loss 0.18880748748779297\n",
      "\n",
      "episode 13, val func loss 0.1939670294523239\n",
      "\n",
      "episode 14, val func loss 0.18268869817256927\n",
      "\n",
      "episode 15, val func loss 0.20517998933792114\n",
      "\n",
      "episode 16, val func loss 0.19534678757190704\n",
      "\n",
      "Val func train loss in epoch 15:0.18538080248981714\n",
      "***********************TIME WAS 4.907264745235443 min*****************************\n",
      "\n",
      "**********************ROUND 46 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.02829284593462944\n",
      "\n",
      "episode 2, policy loss -0.012040365487337112\n",
      "\n",
      "episode 3, policy loss 0.005228408612310886\n",
      "\n",
      "episode 4, policy loss -0.10277090966701508\n",
      "\n",
      "episode 5, policy loss -0.040527839213609695\n",
      "\n",
      "episode 6, policy loss 0.009189865551888943\n",
      "\n",
      "episode 7, policy loss -0.07447095215320587\n",
      "\n",
      "episode 8, policy loss -0.017632028087973595\n",
      "\n",
      "episode 9, policy loss -0.026006029918789864\n",
      "\n",
      "episode 10, policy loss -0.07001267373561859\n",
      "\n",
      "episode 11, policy loss -0.044538531452417374\n",
      "\n",
      "episode 12, policy loss -0.0517413504421711\n",
      "\n",
      "episode 13, policy loss -0.01367916725575924\n",
      "\n",
      "episode 14, policy loss -0.04177895560860634\n",
      "\n",
      "episode 15, policy loss -0.07786878198385239\n",
      "\n",
      "episode 16, policy loss -0.05310911685228348\n",
      "\n",
      "Policy train loss in epoch 0:-0.04000320460181683\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.05429805815219879\n",
      "\n",
      "episode 2, policy loss -0.026365183293819427\n",
      "\n",
      "episode 3, policy loss -0.10356910526752472\n",
      "\n",
      "episode 4, policy loss -0.010260520502924919\n",
      "\n",
      "episode 5, policy loss -0.052768051624298096\n",
      "\n",
      "episode 6, policy loss -0.03981073200702667\n",
      "\n",
      "episode 7, policy loss 0.0110631687566638\n",
      "\n",
      "episode 8, policy loss -0.06699085980653763\n",
      "\n",
      "episode 9, policy loss -0.07395794987678528\n",
      "\n",
      "episode 10, policy loss -0.03888336196541786\n",
      "\n",
      "episode 11, policy loss -0.07897544652223587\n",
      "\n",
      "episode 12, policy loss -0.014898445457220078\n",
      "\n",
      "episode 13, policy loss -0.04455329850316048\n",
      "\n",
      "episode 14, policy loss -0.017775464802980423\n",
      "\n",
      "episode 15, policy loss 0.00466119172051549\n",
      "\n",
      "episode 16, policy loss -0.042175255715847015\n",
      "\n",
      "Policy train loss in epoch 1:-0.04059733581379987\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.06603825837373734\n",
      "\n",
      "episode 2, policy loss -0.045318830758333206\n",
      "\n",
      "episode 3, policy loss -0.02371755801141262\n",
      "\n",
      "episode 4, policy loss -0.031713470816612244\n",
      "\n",
      "episode 5, policy loss -0.012409405782818794\n",
      "\n",
      "episode 6, policy loss 0.005787299945950508\n",
      "\n",
      "episode 7, policy loss -0.10349266976118088\n",
      "\n",
      "episode 8, policy loss -0.0137654272839427\n",
      "\n",
      "episode 9, policy loss -0.07247953861951828\n",
      "\n",
      "episode 10, policy loss -0.04219759255647659\n",
      "\n",
      "episode 11, policy loss -0.07803534716367722\n",
      "\n",
      "episode 12, policy loss -0.016446510329842567\n",
      "\n",
      "episode 13, policy loss -0.04324156418442726\n",
      "\n",
      "episode 14, policy loss -0.050987303256988525\n",
      "\n",
      "episode 15, policy loss -0.053083449602127075\n",
      "\n",
      "episode 16, policy loss 0.012541772797703743\n",
      "\n",
      "Policy train loss in epoch 2:-0.039662365859840065\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.012489277869462967\n",
      "\n",
      "episode 2, policy loss -0.04176267236471176\n",
      "\n",
      "episode 3, policy loss -0.10253484547138214\n",
      "\n",
      "episode 4, policy loss -0.05365696921944618\n",
      "\n",
      "episode 5, policy loss -0.07229368388652802\n",
      "\n",
      "episode 6, policy loss -0.07045021653175354\n",
      "\n",
      "episode 7, policy loss 0.005329578649252653\n",
      "\n",
      "episode 8, policy loss -0.030142374336719513\n",
      "\n",
      "episode 9, policy loss -0.07839877903461456\n",
      "\n",
      "episode 10, policy loss -0.03689024969935417\n",
      "\n",
      "episode 11, policy loss -0.01099756546318531\n",
      "\n",
      "episode 12, policy loss -0.04471147060394287\n",
      "\n",
      "episode 13, policy loss -0.02288707159459591\n",
      "\n",
      "episode 14, policy loss -0.04698477312922478\n",
      "\n",
      "episode 15, policy loss -0.011206584051251411\n",
      "\n",
      "episode 16, policy loss -0.018522311002016068\n",
      "\n",
      "Policy train loss in epoch 3:-0.03897629436687566\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17749622464179993\n",
      "\n",
      "episode 2, val func loss 0.23801596462726593\n",
      "\n",
      "episode 3, val func loss 0.20835159718990326\n",
      "\n",
      "episode 4, val func loss 0.1850910186767578\n",
      "\n",
      "episode 5, val func loss 0.194809228181839\n",
      "\n",
      "episode 6, val func loss 0.19596290588378906\n",
      "\n",
      "episode 7, val func loss 0.2011338174343109\n",
      "\n",
      "episode 8, val func loss 0.1905876249074936\n",
      "\n",
      "episode 9, val func loss 0.18993376195430756\n",
      "\n",
      "episode 10, val func loss 0.20266371965408325\n",
      "\n",
      "episode 11, val func loss 0.21553434431552887\n",
      "\n",
      "episode 12, val func loss 0.21151596307754517\n",
      "\n",
      "episode 13, val func loss 0.19121459126472473\n",
      "\n",
      "episode 14, val func loss 0.16772347688674927\n",
      "\n",
      "episode 15, val func loss 0.18515023589134216\n",
      "\n",
      "episode 16, val func loss 0.18713092803955078\n",
      "\n",
      "Val func train loss in epoch 0:0.19639471266418695\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17596392333507538\n",
      "\n",
      "episode 2, val func loss 0.20356839895248413\n",
      "\n",
      "episode 3, val func loss 0.1932930201292038\n",
      "\n",
      "episode 4, val func loss 0.2175000011920929\n",
      "\n",
      "episode 5, val func loss 0.19490675628185272\n",
      "\n",
      "episode 6, val func loss 0.1905144453048706\n",
      "\n",
      "episode 7, val func loss 0.19347915053367615\n",
      "\n",
      "episode 8, val func loss 0.23672699928283691\n",
      "\n",
      "episode 9, val func loss 0.19672706723213196\n",
      "\n",
      "episode 10, val func loss 0.1875787079334259\n",
      "\n",
      "episode 11, val func loss 0.18361631035804749\n",
      "\n",
      "episode 12, val func loss 0.18724721670150757\n",
      "\n",
      "episode 13, val func loss 0.2082226574420929\n",
      "\n",
      "episode 14, val func loss 0.2130117416381836\n",
      "\n",
      "episode 15, val func loss 0.19868989288806915\n",
      "\n",
      "episode 16, val func loss 0.16259697079658508\n",
      "\n",
      "Val func train loss in epoch 1:0.19647770375013351\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19403943419456482\n",
      "\n",
      "episode 2, val func loss 0.21464118361473083\n",
      "\n",
      "episode 3, val func loss 0.18029184639453888\n",
      "\n",
      "episode 4, val func loss 0.19502921402454376\n",
      "\n",
      "episode 5, val func loss 0.18889130651950836\n",
      "\n",
      "episode 6, val func loss 0.2370012104511261\n",
      "\n",
      "episode 7, val func loss 0.2174677699804306\n",
      "\n",
      "episode 8, val func loss 0.19114461541175842\n",
      "\n",
      "episode 9, val func loss 0.20830312371253967\n",
      "\n",
      "episode 10, val func loss 0.1914081871509552\n",
      "\n",
      "episode 11, val func loss 0.1980379819869995\n",
      "\n",
      "episode 12, val func loss 0.1754171997308731\n",
      "\n",
      "episode 13, val func loss 0.19759559631347656\n",
      "\n",
      "episode 14, val func loss 0.18866336345672607\n",
      "\n",
      "episode 15, val func loss 0.20471353828907013\n",
      "\n",
      "episode 16, val func loss 0.16393885016441345\n",
      "\n",
      "Val func train loss in epoch 2:0.19666152633726597\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1953481286764145\n",
      "\n",
      "episode 2, val func loss 0.21276085078716278\n",
      "\n",
      "episode 3, val func loss 0.18568414449691772\n",
      "\n",
      "episode 4, val func loss 0.17905351519584656\n",
      "\n",
      "episode 5, val func loss 0.18774370849132538\n",
      "\n",
      "episode 6, val func loss 0.19063009321689606\n",
      "\n",
      "episode 7, val func loss 0.19467474520206451\n",
      "\n",
      "episode 8, val func loss 0.20776280760765076\n",
      "\n",
      "episode 9, val func loss 0.19195501506328583\n",
      "\n",
      "episode 10, val func loss 0.19950252771377563\n",
      "\n",
      "episode 11, val func loss 0.19022224843502045\n",
      "\n",
      "episode 12, val func loss 0.16513654589653015\n",
      "\n",
      "episode 13, val func loss 0.2026844471693039\n",
      "\n",
      "episode 14, val func loss 0.23935438692569733\n",
      "\n",
      "episode 15, val func loss 0.18113507330417633\n",
      "\n",
      "episode 16, val func loss 0.2158871293067932\n",
      "\n",
      "Val func train loss in epoch 3:0.19622096046805382\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.2116476148366928\n",
      "\n",
      "episode 2, val func loss 0.2017216980457306\n",
      "\n",
      "episode 3, val func loss 0.18834014236927032\n",
      "\n",
      "episode 4, val func loss 0.20151615142822266\n",
      "\n",
      "episode 5, val func loss 0.19027157127857208\n",
      "\n",
      "episode 6, val func loss 0.19441750645637512\n",
      "\n",
      "episode 7, val func loss 0.1909724622964859\n",
      "\n",
      "episode 8, val func loss 0.19437827169895172\n",
      "\n",
      "episode 9, val func loss 0.17682376503944397\n",
      "\n",
      "episode 10, val func loss 0.24070902168750763\n",
      "\n",
      "episode 11, val func loss 0.21647383272647858\n",
      "\n",
      "episode 12, val func loss 0.19077396392822266\n",
      "\n",
      "episode 13, val func loss 0.20827756822109222\n",
      "\n",
      "episode 14, val func loss 0.1674312949180603\n",
      "\n",
      "episode 15, val func loss 0.18270841240882874\n",
      "\n",
      "episode 16, val func loss 0.18526843190193176\n",
      "\n",
      "Val func train loss in epoch 4:0.1963582318276167\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.16507096588611603\n",
      "\n",
      "episode 2, val func loss 0.21706897020339966\n",
      "\n",
      "episode 3, val func loss 0.1958780586719513\n",
      "\n",
      "episode 4, val func loss 0.18514679372310638\n",
      "\n",
      "episode 5, val func loss 0.17608022689819336\n",
      "\n",
      "episode 6, val func loss 0.198527529835701\n",
      "\n",
      "episode 7, val func loss 0.208674356341362\n",
      "\n",
      "episode 8, val func loss 0.2134781926870346\n",
      "\n",
      "episode 9, val func loss 0.1805456429719925\n",
      "\n",
      "episode 10, val func loss 0.19204571843147278\n",
      "\n",
      "episode 11, val func loss 0.20286846160888672\n",
      "\n",
      "episode 12, val func loss 0.1880006045103073\n",
      "\n",
      "episode 13, val func loss 0.18813838064670563\n",
      "\n",
      "episode 14, val func loss 0.19566227495670319\n",
      "\n",
      "episode 15, val func loss 0.19401982426643372\n",
      "\n",
      "episode 16, val func loss 0.23672614991664886\n",
      "\n",
      "Val func train loss in epoch 5:0.19612075947225094\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18806222081184387\n",
      "\n",
      "episode 2, val func loss 0.18837253749370575\n",
      "\n",
      "episode 3, val func loss 0.20228666067123413\n",
      "\n",
      "episode 4, val func loss 0.16802610456943512\n",
      "\n",
      "episode 5, val func loss 0.20761871337890625\n",
      "\n",
      "episode 6, val func loss 0.1945560723543167\n",
      "\n",
      "episode 7, val func loss 0.19119200110435486\n",
      "\n",
      "episode 8, val func loss 0.19826576113700867\n",
      "\n",
      "episode 9, val func loss 0.19543005526065826\n",
      "\n",
      "episode 10, val func loss 0.17569328844547272\n",
      "\n",
      "episode 11, val func loss 0.18059231340885162\n",
      "\n",
      "episode 12, val func loss 0.19406750798225403\n",
      "\n",
      "episode 13, val func loss 0.21845419704914093\n",
      "\n",
      "episode 14, val func loss 0.18504346907138824\n",
      "\n",
      "episode 15, val func loss 0.23792052268981934\n",
      "\n",
      "episode 16, val func loss 0.21143317222595215\n",
      "\n",
      "Val func train loss in epoch 6:0.19606341235339642\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.2151695191860199\n",
      "\n",
      "episode 2, val func loss 0.20636776089668274\n",
      "\n",
      "episode 3, val func loss 0.18988348543643951\n",
      "\n",
      "episode 4, val func loss 0.18462365865707397\n",
      "\n",
      "episode 5, val func loss 0.19144988059997559\n",
      "\n",
      "episode 6, val func loss 0.19137616455554962\n",
      "\n",
      "episode 7, val func loss 0.1923225224018097\n",
      "\n",
      "episode 8, val func loss 0.20398065447807312\n",
      "\n",
      "episode 9, val func loss 0.19517551362514496\n",
      "\n",
      "episode 10, val func loss 0.17602120339870453\n",
      "\n",
      "episode 11, val func loss 0.1879683881998062\n",
      "\n",
      "episode 12, val func loss 0.23978720605373383\n",
      "\n",
      "episode 13, val func loss 0.19453062117099762\n",
      "\n",
      "episode 14, val func loss 0.21205678582191467\n",
      "\n",
      "episode 15, val func loss 0.20853693783283234\n",
      "\n",
      "episode 16, val func loss 0.1692388504743576\n",
      "\n",
      "Val func train loss in epoch 7:0.19740557204931974\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.20223091542720795\n",
      "\n",
      "episode 2, val func loss 0.23740254342556\n",
      "\n",
      "episode 3, val func loss 0.20795072615146637\n",
      "\n",
      "episode 4, val func loss 0.1882309764623642\n",
      "\n",
      "episode 5, val func loss 0.211396723985672\n",
      "\n",
      "episode 6, val func loss 0.21568062901496887\n",
      "\n",
      "episode 7, val func loss 0.1857326328754425\n",
      "\n",
      "episode 8, val func loss 0.1999233067035675\n",
      "\n",
      "episode 9, val func loss 0.18970122933387756\n",
      "\n",
      "episode 10, val func loss 0.19394853711128235\n",
      "\n",
      "episode 11, val func loss 0.1945580691099167\n",
      "\n",
      "episode 12, val func loss 0.17851392924785614\n",
      "\n",
      "episode 13, val func loss 0.190891832113266\n",
      "\n",
      "episode 14, val func loss 0.1646372526884079\n",
      "\n",
      "episode 15, val func loss 0.19075748324394226\n",
      "\n",
      "episode 16, val func loss 0.1806076169013977\n",
      "\n",
      "Val func train loss in epoch 8:0.19576027523726225\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20898230373859406\n",
      "\n",
      "episode 2, val func loss 0.24219369888305664\n",
      "\n",
      "episode 3, val func loss 0.19536685943603516\n",
      "\n",
      "episode 4, val func loss 0.21712547540664673\n",
      "\n",
      "episode 5, val func loss 0.1988716423511505\n",
      "\n",
      "episode 6, val func loss 0.21171769499778748\n",
      "\n",
      "episode 7, val func loss 0.17889297008514404\n",
      "\n",
      "episode 8, val func loss 0.18983601033687592\n",
      "\n",
      "episode 9, val func loss 0.1937812715768814\n",
      "\n",
      "episode 10, val func loss 0.1827719360589981\n",
      "\n",
      "episode 11, val func loss 0.19143803417682648\n",
      "\n",
      "episode 12, val func loss 0.20245493948459625\n",
      "\n",
      "episode 13, val func loss 0.16520696878433228\n",
      "\n",
      "episode 14, val func loss 0.18722745776176453\n",
      "\n",
      "episode 15, val func loss 0.19294758141040802\n",
      "\n",
      "episode 16, val func loss 0.18522022664546967\n",
      "\n",
      "Val func train loss in epoch 9:0.19650219194591045\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.209058478474617\n",
      "\n",
      "episode 2, val func loss 0.17647376656532288\n",
      "\n",
      "episode 3, val func loss 0.16326908767223358\n",
      "\n",
      "episode 4, val func loss 0.19843068718910217\n",
      "\n",
      "episode 5, val func loss 0.19318336248397827\n",
      "\n",
      "episode 6, val func loss 0.21351823210716248\n",
      "\n",
      "episode 7, val func loss 0.23985734581947327\n",
      "\n",
      "episode 8, val func loss 0.19465534389019012\n",
      "\n",
      "episode 9, val func loss 0.2021171599626541\n",
      "\n",
      "episode 10, val func loss 0.1935398280620575\n",
      "\n",
      "episode 11, val func loss 0.21476563811302185\n",
      "\n",
      "episode 12, val func loss 0.18525007367134094\n",
      "\n",
      "episode 13, val func loss 0.18846306204795837\n",
      "\n",
      "episode 14, val func loss 0.1865837723016739\n",
      "\n",
      "episode 15, val func loss 0.19056206941604614\n",
      "\n",
      "episode 16, val func loss 0.19431853294372559\n",
      "\n",
      "Val func train loss in epoch 10:0.19650290254503489\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19922061264514923\n",
      "\n",
      "episode 2, val func loss 0.20838089287281036\n",
      "\n",
      "episode 3, val func loss 0.2406253069639206\n",
      "\n",
      "episode 4, val func loss 0.19493499398231506\n",
      "\n",
      "episode 5, val func loss 0.19095584750175476\n",
      "\n",
      "episode 6, val func loss 0.18476611375808716\n",
      "\n",
      "episode 7, val func loss 0.19135421514511108\n",
      "\n",
      "episode 8, val func loss 0.1940898895263672\n",
      "\n",
      "episode 9, val func loss 0.16673198342323303\n",
      "\n",
      "episode 10, val func loss 0.2148788720369339\n",
      "\n",
      "episode 11, val func loss 0.20259948074817657\n",
      "\n",
      "episode 12, val func loss 0.2117958515882492\n",
      "\n",
      "episode 13, val func loss 0.17834006249904633\n",
      "\n",
      "episode 14, val func loss 0.1899264007806778\n",
      "\n",
      "episode 15, val func loss 0.1812557578086853\n",
      "\n",
      "episode 16, val func loss 0.18768742680549622\n",
      "\n",
      "Val func train loss in epoch 11:0.19609648175537586\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18527497351169586\n",
      "\n",
      "episode 2, val func loss 0.20832745730876923\n",
      "\n",
      "episode 3, val func loss 0.191566601395607\n",
      "\n",
      "episode 4, val func loss 0.18726305663585663\n",
      "\n",
      "episode 5, val func loss 0.20236144959926605\n",
      "\n",
      "episode 6, val func loss 0.19478844106197357\n",
      "\n",
      "episode 7, val func loss 0.19952498376369476\n",
      "\n",
      "episode 8, val func loss 0.18979044258594513\n",
      "\n",
      "episode 9, val func loss 0.2381736934185028\n",
      "\n",
      "episode 10, val func loss 0.1681334674358368\n",
      "\n",
      "episode 11, val func loss 0.21492618322372437\n",
      "\n",
      "episode 12, val func loss 0.21145352721214294\n",
      "\n",
      "episode 13, val func loss 0.19241271913051605\n",
      "\n",
      "episode 14, val func loss 0.1784037947654724\n",
      "\n",
      "episode 15, val func loss 0.19441771507263184\n",
      "\n",
      "episode 16, val func loss 0.1809663325548172\n",
      "\n",
      "Val func train loss in epoch 12:0.1961115524172783\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.16330458223819733\n",
      "\n",
      "episode 2, val func loss 0.2136688530445099\n",
      "\n",
      "episode 3, val func loss 0.1965610235929489\n",
      "\n",
      "episode 4, val func loss 0.19425511360168457\n",
      "\n",
      "episode 5, val func loss 0.21844904124736786\n",
      "\n",
      "episode 6, val func loss 0.19055867195129395\n",
      "\n",
      "episode 7, val func loss 0.17752371728420258\n",
      "\n",
      "episode 8, val func loss 0.19020168483257294\n",
      "\n",
      "episode 9, val func loss 0.20207490026950836\n",
      "\n",
      "episode 10, val func loss 0.1881975531578064\n",
      "\n",
      "episode 11, val func loss 0.1946568340063095\n",
      "\n",
      "episode 12, val func loss 0.18662871420383453\n",
      "\n",
      "episode 13, val func loss 0.20110583305358887\n",
      "\n",
      "episode 14, val func loss 0.18197333812713623\n",
      "\n",
      "episode 15, val func loss 0.23912911117076874\n",
      "\n",
      "episode 16, val func loss 0.2084895819425583\n",
      "\n",
      "Val func train loss in epoch 13:0.19667365960776806\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19126790761947632\n",
      "\n",
      "episode 2, val func loss 0.1952989399433136\n",
      "\n",
      "episode 3, val func loss 0.2159750610589981\n",
      "\n",
      "episode 4, val func loss 0.1948389858007431\n",
      "\n",
      "episode 5, val func loss 0.2020537555217743\n",
      "\n",
      "episode 6, val func loss 0.1916273832321167\n",
      "\n",
      "episode 7, val func loss 0.18947215378284454\n",
      "\n",
      "episode 8, val func loss 0.23693884909152985\n",
      "\n",
      "episode 9, val func loss 0.18091541528701782\n",
      "\n",
      "episode 10, val func loss 0.18829931318759918\n",
      "\n",
      "episode 11, val func loss 0.20121580362319946\n",
      "\n",
      "episode 12, val func loss 0.16605067253112793\n",
      "\n",
      "episode 13, val func loss 0.2078220397233963\n",
      "\n",
      "episode 14, val func loss 0.18057934939861298\n",
      "\n",
      "episode 15, val func loss 0.1868593394756317\n",
      "\n",
      "episode 16, val func loss 0.2168418914079666\n",
      "\n",
      "Val func train loss in epoch 14:0.19662855379283428\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1762126088142395\n",
      "\n",
      "episode 2, val func loss 0.19869017601013184\n",
      "\n",
      "episode 3, val func loss 0.20485492050647736\n",
      "\n",
      "episode 4, val func loss 0.24137656390666962\n",
      "\n",
      "episode 5, val func loss 0.1908971220254898\n",
      "\n",
      "episode 6, val func loss 0.207833930850029\n",
      "\n",
      "episode 7, val func loss 0.19493621587753296\n",
      "\n",
      "episode 8, val func loss 0.21475155651569366\n",
      "\n",
      "episode 9, val func loss 0.18913067877292633\n",
      "\n",
      "episode 10, val func loss 0.18786385655403137\n",
      "\n",
      "episode 11, val func loss 0.1956806182861328\n",
      "\n",
      "episode 12, val func loss 0.18343611061573029\n",
      "\n",
      "episode 13, val func loss 0.1943141669034958\n",
      "\n",
      "episode 14, val func loss 0.21172523498535156\n",
      "\n",
      "episode 15, val func loss 0.16419905424118042\n",
      "\n",
      "episode 16, val func loss 0.1874874383211136\n",
      "\n",
      "Val func train loss in epoch 15:0.19646189082413912\n",
      "***********************TIME WAS 4.911269664764404 min*****************************\n",
      "\n",
      "**********************ROUND 47 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.0012953034602105618\n",
      "\n",
      "episode 2, policy loss -0.10939503461122513\n",
      "\n",
      "episode 3, policy loss -0.02038039080798626\n",
      "\n",
      "episode 4, policy loss -0.11370356380939484\n",
      "\n",
      "episode 5, policy loss -0.014070456847548485\n",
      "\n",
      "episode 6, policy loss -0.044470641762018204\n",
      "\n",
      "episode 7, policy loss -0.05429510027170181\n",
      "\n",
      "episode 8, policy loss -0.07606567442417145\n",
      "\n",
      "episode 9, policy loss -0.07227111607789993\n",
      "\n",
      "episode 10, policy loss -0.08758344501256943\n",
      "\n",
      "episode 11, policy loss -0.054027117788791656\n",
      "\n",
      "episode 12, policy loss -0.05381757393479347\n",
      "\n",
      "episode 13, policy loss -0.028552278876304626\n",
      "\n",
      "episode 14, policy loss -0.009081115946173668\n",
      "\n",
      "episode 15, policy loss -0.03545356169342995\n",
      "\n",
      "episode 16, policy loss -0.01805037632584572\n",
      "\n",
      "Policy train loss in epoch 0:-0.049532046978129074\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.08743460476398468\n",
      "\n",
      "episode 2, policy loss -0.037151359021663666\n",
      "\n",
      "episode 3, policy loss -0.020108431577682495\n",
      "\n",
      "episode 4, policy loss -0.1141669973731041\n",
      "\n",
      "episode 5, policy loss -0.04277866706252098\n",
      "\n",
      "episode 6, policy loss -0.07206524908542633\n",
      "\n",
      "episode 7, policy loss -0.019119132310152054\n",
      "\n",
      "episode 8, policy loss -0.05413205176591873\n",
      "\n",
      "episode 9, policy loss -0.11369152367115021\n",
      "\n",
      "episode 10, policy loss -0.03173954412341118\n",
      "\n",
      "episode 11, policy loss -0.05223415419459343\n",
      "\n",
      "episode 12, policy loss -0.07619735598564148\n",
      "\n",
      "episode 13, policy loss -0.009353367611765862\n",
      "\n",
      "episode 14, policy loss -0.05219379439949989\n",
      "\n",
      "episode 15, policy loss -0.0024489532224833965\n",
      "\n",
      "episode 16, policy loss -0.011581148020923138\n",
      "\n",
      "Policy train loss in epoch 1:-0.0497747708868701\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.04806067422032356\n",
      "\n",
      "episode 2, policy loss -0.07616712898015976\n",
      "\n",
      "episode 3, policy loss -0.02183292619884014\n",
      "\n",
      "episode 4, policy loss -0.014058968052268028\n",
      "\n",
      "episode 5, policy loss -0.00323763070628047\n",
      "\n",
      "episode 6, policy loss -0.00989488884806633\n",
      "\n",
      "episode 7, policy loss -0.056947071105241776\n",
      "\n",
      "episode 8, policy loss -0.05178903415799141\n",
      "\n",
      "episode 9, policy loss -0.0876651257276535\n",
      "\n",
      "episode 10, policy loss -0.11631415039300919\n",
      "\n",
      "episode 11, policy loss -0.027899065986275673\n",
      "\n",
      "episode 12, policy loss -0.018017327412962914\n",
      "\n",
      "episode 13, policy loss -0.11198501288890839\n",
      "\n",
      "episode 14, policy loss -0.0728093683719635\n",
      "\n",
      "episode 15, policy loss -0.03413970023393631\n",
      "\n",
      "episode 16, policy loss -0.054430440068244934\n",
      "\n",
      "Policy train loss in epoch 2:-0.05032803208450787\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.05587311089038849\n",
      "\n",
      "episode 2, policy loss -0.024483175948262215\n",
      "\n",
      "episode 3, policy loss -0.0167794618755579\n",
      "\n",
      "episode 4, policy loss -0.003835455747321248\n",
      "\n",
      "episode 5, policy loss -0.01695130206644535\n",
      "\n",
      "episode 6, policy loss -0.05408439040184021\n",
      "\n",
      "episode 7, policy loss -0.07610916346311569\n",
      "\n",
      "episode 8, policy loss -0.008926372043788433\n",
      "\n",
      "episode 9, policy loss -0.11555195599794388\n",
      "\n",
      "episode 10, policy loss -0.08569352328777313\n",
      "\n",
      "episode 11, policy loss -0.11485721170902252\n",
      "\n",
      "episode 12, policy loss -0.04060402885079384\n",
      "\n",
      "episode 13, policy loss -0.020814646035432816\n",
      "\n",
      "episode 14, policy loss -0.07503129541873932\n",
      "\n",
      "episode 15, policy loss -0.054152682423591614\n",
      "\n",
      "episode 16, policy loss -0.03661655634641647\n",
      "\n",
      "Policy train loss in epoch 3:-0.05002277078165207\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17517752945423126\n",
      "\n",
      "episode 2, val func loss 0.20815561711788177\n",
      "\n",
      "episode 3, val func loss 0.20563797652721405\n",
      "\n",
      "episode 4, val func loss 0.20650899410247803\n",
      "\n",
      "episode 5, val func loss 0.20729854702949524\n",
      "\n",
      "episode 6, val func loss 0.1949942409992218\n",
      "\n",
      "episode 7, val func loss 0.21771185100078583\n",
      "\n",
      "episode 8, val func loss 0.18016253411769867\n",
      "\n",
      "episode 9, val func loss 0.18583664298057556\n",
      "\n",
      "episode 10, val func loss 0.16375266015529633\n",
      "\n",
      "episode 11, val func loss 0.1774836927652359\n",
      "\n",
      "episode 12, val func loss 0.17311689257621765\n",
      "\n",
      "episode 13, val func loss 0.19923986494541168\n",
      "\n",
      "episode 14, val func loss 0.15213918685913086\n",
      "\n",
      "episode 15, val func loss 0.19031120836734772\n",
      "\n",
      "episode 16, val func loss 0.1727880984544754\n",
      "\n",
      "Val func train loss in epoch 0:0.1881447210907936\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.22160795331001282\n",
      "\n",
      "episode 2, val func loss 0.20526061952114105\n",
      "\n",
      "episode 3, val func loss 0.20644134283065796\n",
      "\n",
      "episode 4, val func loss 0.20383943617343903\n",
      "\n",
      "episode 5, val func loss 0.15535064041614532\n",
      "\n",
      "episode 6, val func loss 0.1729131042957306\n",
      "\n",
      "episode 7, val func loss 0.16476063430309296\n",
      "\n",
      "episode 8, val func loss 0.2093423455953598\n",
      "\n",
      "episode 9, val func loss 0.19867224991321564\n",
      "\n",
      "episode 10, val func loss 0.18604819476604462\n",
      "\n",
      "episode 11, val func loss 0.1968868523836136\n",
      "\n",
      "episode 12, val func loss 0.20700518786907196\n",
      "\n",
      "episode 13, val func loss 0.1769295185804367\n",
      "\n",
      "episode 14, val func loss 0.17479003965854645\n",
      "\n",
      "episode 15, val func loss 0.17192474007606506\n",
      "\n",
      "episode 16, val func loss 0.17746353149414062\n",
      "\n",
      "Val func train loss in epoch 1:0.18932727444916964\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17271246016025543\n",
      "\n",
      "episode 2, val func loss 0.2089400589466095\n",
      "\n",
      "episode 3, val func loss 0.2128799557685852\n",
      "\n",
      "episode 4, val func loss 0.17278771102428436\n",
      "\n",
      "episode 5, val func loss 0.17417222261428833\n",
      "\n",
      "episode 6, val func loss 0.16407135128974915\n",
      "\n",
      "episode 7, val func loss 0.1771000176668167\n",
      "\n",
      "episode 8, val func loss 0.18892425298690796\n",
      "\n",
      "episode 9, val func loss 0.17497427761554718\n",
      "\n",
      "episode 10, val func loss 0.20634344220161438\n",
      "\n",
      "episode 11, val func loss 0.2204265594482422\n",
      "\n",
      "episode 12, val func loss 0.19316941499710083\n",
      "\n",
      "episode 13, val func loss 0.18636523187160492\n",
      "\n",
      "episode 14, val func loss 0.20685525238513947\n",
      "\n",
      "episode 15, val func loss 0.19746871292591095\n",
      "\n",
      "episode 16, val func loss 0.15548409521579742\n",
      "\n",
      "Val func train loss in epoch 2:0.18829218856990337\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20572273433208466\n",
      "\n",
      "episode 2, val func loss 0.188836932182312\n",
      "\n",
      "episode 3, val func loss 0.1629771590232849\n",
      "\n",
      "episode 4, val func loss 0.17219285666942596\n",
      "\n",
      "episode 5, val func loss 0.19386132061481476\n",
      "\n",
      "episode 6, val func loss 0.1747269481420517\n",
      "\n",
      "episode 7, val func loss 0.17204391956329346\n",
      "\n",
      "episode 8, val func loss 0.19784045219421387\n",
      "\n",
      "episode 9, val func loss 0.15255741775035858\n",
      "\n",
      "episode 10, val func loss 0.2227454036474228\n",
      "\n",
      "episode 11, val func loss 0.20973773300647736\n",
      "\n",
      "episode 12, val func loss 0.17534784972667694\n",
      "\n",
      "episode 13, val func loss 0.17765823006629944\n",
      "\n",
      "episode 14, val func loss 0.20492835342884064\n",
      "\n",
      "episode 15, val func loss 0.20639121532440186\n",
      "\n",
      "episode 16, val func loss 0.18539030849933624\n",
      "\n",
      "Val func train loss in epoch 3:0.18768492713570595\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.2065705806016922\n",
      "\n",
      "episode 2, val func loss 0.19369278848171234\n",
      "\n",
      "episode 3, val func loss 0.15708503127098083\n",
      "\n",
      "episode 4, val func loss 0.1785716861486435\n",
      "\n",
      "episode 5, val func loss 0.16412284970283508\n",
      "\n",
      "episode 6, val func loss 0.1727144867181778\n",
      "\n",
      "episode 7, val func loss 0.2067936509847641\n",
      "\n",
      "episode 8, val func loss 0.17494100332260132\n",
      "\n",
      "episode 9, val func loss 0.1849285215139389\n",
      "\n",
      "episode 10, val func loss 0.17228470742702484\n",
      "\n",
      "episode 11, val func loss 0.20884492993354797\n",
      "\n",
      "episode 12, val func loss 0.2059311717748642\n",
      "\n",
      "episode 13, val func loss 0.1734464317560196\n",
      "\n",
      "episode 14, val func loss 0.18940992653369904\n",
      "\n",
      "episode 15, val func loss 0.19725501537322998\n",
      "\n",
      "episode 16, val func loss 0.21958206593990326\n",
      "\n",
      "Val func train loss in epoch 4:0.18788592796772718\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.2197449803352356\n",
      "\n",
      "episode 2, val func loss 0.18585814535617828\n",
      "\n",
      "episode 3, val func loss 0.17674894630908966\n",
      "\n",
      "episode 4, val func loss 0.19037409126758575\n",
      "\n",
      "episode 5, val func loss 0.20390792191028595\n",
      "\n",
      "episode 6, val func loss 0.17815715074539185\n",
      "\n",
      "episode 7, val func loss 0.20525267720222473\n",
      "\n",
      "episode 8, val func loss 0.2054099291563034\n",
      "\n",
      "episode 9, val func loss 0.1967228651046753\n",
      "\n",
      "episode 10, val func loss 0.16376575827598572\n",
      "\n",
      "episode 11, val func loss 0.15304189920425415\n",
      "\n",
      "episode 12, val func loss 0.21301113069057465\n",
      "\n",
      "episode 13, val func loss 0.17786487936973572\n",
      "\n",
      "episode 14, val func loss 0.19439274072647095\n",
      "\n",
      "episode 15, val func loss 0.1724776178598404\n",
      "\n",
      "episode 16, val func loss 0.1721896231174469\n",
      "\n",
      "Val func train loss in epoch 5:0.18805752228945494\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.20603571832180023\n",
      "\n",
      "episode 2, val func loss 0.17469589412212372\n",
      "\n",
      "episode 3, val func loss 0.21965520083904266\n",
      "\n",
      "episode 4, val func loss 0.1554352194070816\n",
      "\n",
      "episode 5, val func loss 0.1931765228509903\n",
      "\n",
      "episode 6, val func loss 0.1746632158756256\n",
      "\n",
      "episode 7, val func loss 0.20638278126716614\n",
      "\n",
      "episode 8, val func loss 0.18517915904521942\n",
      "\n",
      "episode 9, val func loss 0.16406677663326263\n",
      "\n",
      "episode 10, val func loss 0.20560240745544434\n",
      "\n",
      "episode 11, val func loss 0.17731675505638123\n",
      "\n",
      "episode 12, val func loss 0.17289194464683533\n",
      "\n",
      "episode 13, val func loss 0.18924251198768616\n",
      "\n",
      "episode 14, val func loss 0.20701980590820312\n",
      "\n",
      "episode 15, val func loss 0.17296232283115387\n",
      "\n",
      "episode 16, val func loss 0.19769196212291718\n",
      "\n",
      "Val func train loss in epoch 6:0.18762613739818335\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18949422240257263\n",
      "\n",
      "episode 2, val func loss 0.17197030782699585\n",
      "\n",
      "episode 3, val func loss 0.1726902425289154\n",
      "\n",
      "episode 4, val func loss 0.20761919021606445\n",
      "\n",
      "episode 5, val func loss 0.17732149362564087\n",
      "\n",
      "episode 6, val func loss 0.18480336666107178\n",
      "\n",
      "episode 7, val func loss 0.20681433379650116\n",
      "\n",
      "episode 8, val func loss 0.16306930780410767\n",
      "\n",
      "episode 9, val func loss 0.2056940197944641\n",
      "\n",
      "episode 10, val func loss 0.1555701047182083\n",
      "\n",
      "episode 11, val func loss 0.20705413818359375\n",
      "\n",
      "episode 12, val func loss 0.19260114431381226\n",
      "\n",
      "episode 13, val func loss 0.17389258742332458\n",
      "\n",
      "episode 14, val func loss 0.17550717294216156\n",
      "\n",
      "episode 15, val func loss 0.21932479739189148\n",
      "\n",
      "episode 16, val func loss 0.19734477996826172\n",
      "\n",
      "Val func train loss in epoch 7:0.18754820059984922\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17445971071720123\n",
      "\n",
      "episode 2, val func loss 0.17723406851291656\n",
      "\n",
      "episode 3, val func loss 0.18942487239837646\n",
      "\n",
      "episode 4, val func loss 0.17270001769065857\n",
      "\n",
      "episode 5, val func loss 0.17471936345100403\n",
      "\n",
      "episode 6, val func loss 0.22336068749427795\n",
      "\n",
      "episode 7, val func loss 0.2067834436893463\n",
      "\n",
      "episode 8, val func loss 0.2102266401052475\n",
      "\n",
      "episode 9, val func loss 0.19288061559200287\n",
      "\n",
      "episode 10, val func loss 0.1563688963651657\n",
      "\n",
      "episode 11, val func loss 0.16536547243595123\n",
      "\n",
      "episode 12, val func loss 0.1770368218421936\n",
      "\n",
      "episode 13, val func loss 0.20598886907100677\n",
      "\n",
      "episode 14, val func loss 0.1852823942899704\n",
      "\n",
      "episode 15, val func loss 0.19744563102722168\n",
      "\n",
      "episode 16, val func loss 0.2060461938381195\n",
      "\n",
      "Val func train loss in epoch 8:0.18845773115754128\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20602060854434967\n",
      "\n",
      "episode 2, val func loss 0.17414669692516327\n",
      "\n",
      "episode 3, val func loss 0.17239442467689514\n",
      "\n",
      "episode 4, val func loss 0.19731710851192474\n",
      "\n",
      "episode 5, val func loss 0.20567946135997772\n",
      "\n",
      "episode 6, val func loss 0.22056053578853607\n",
      "\n",
      "episode 7, val func loss 0.2088574320077896\n",
      "\n",
      "episode 8, val func loss 0.1739954799413681\n",
      "\n",
      "episode 9, val func loss 0.19270065426826477\n",
      "\n",
      "episode 10, val func loss 0.1567571759223938\n",
      "\n",
      "episode 11, val func loss 0.17810064554214478\n",
      "\n",
      "episode 12, val func loss 0.1750737875699997\n",
      "\n",
      "episode 13, val func loss 0.16332575678825378\n",
      "\n",
      "episode 14, val func loss 0.2059161216020584\n",
      "\n",
      "episode 15, val func loss 0.18487657606601715\n",
      "\n",
      "episode 16, val func loss 0.18929266929626465\n",
      "\n",
      "Val func train loss in epoch 9:0.18781344592571259\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18513505160808563\n",
      "\n",
      "episode 2, val func loss 0.19367848336696625\n",
      "\n",
      "episode 3, val func loss 0.17491593956947327\n",
      "\n",
      "episode 4, val func loss 0.17238028347492218\n",
      "\n",
      "episode 5, val func loss 0.22073687613010406\n",
      "\n",
      "episode 6, val func loss 0.15414325892925262\n",
      "\n",
      "episode 7, val func loss 0.2057780623435974\n",
      "\n",
      "episode 8, val func loss 0.16402192413806915\n",
      "\n",
      "episode 9, val func loss 0.18895983695983887\n",
      "\n",
      "episode 10, val func loss 0.1971500962972641\n",
      "\n",
      "episode 11, val func loss 0.20737509429454803\n",
      "\n",
      "episode 12, val func loss 0.20565076172351837\n",
      "\n",
      "episode 13, val func loss 0.1743854433298111\n",
      "\n",
      "episode 14, val func loss 0.20489764213562012\n",
      "\n",
      "episode 15, val func loss 0.17803224921226501\n",
      "\n",
      "episode 16, val func loss 0.17558732628822327\n",
      "\n",
      "Val func train loss in epoch 10:0.18767677061259747\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1750689148902893\n",
      "\n",
      "episode 2, val func loss 0.18919509649276733\n",
      "\n",
      "episode 3, val func loss 0.22215327620506287\n",
      "\n",
      "episode 4, val func loss 0.20548638701438904\n",
      "\n",
      "episode 5, val func loss 0.1934032440185547\n",
      "\n",
      "episode 6, val func loss 0.1771761029958725\n",
      "\n",
      "episode 7, val func loss 0.18387363851070404\n",
      "\n",
      "episode 8, val func loss 0.19691747426986694\n",
      "\n",
      "episode 9, val func loss 0.154371440410614\n",
      "\n",
      "episode 10, val func loss 0.17296239733695984\n",
      "\n",
      "episode 11, val func loss 0.17268948256969452\n",
      "\n",
      "episode 12, val func loss 0.206137016415596\n",
      "\n",
      "episode 13, val func loss 0.17338064312934875\n",
      "\n",
      "episode 14, val func loss 0.2117595225572586\n",
      "\n",
      "episode 15, val func loss 0.1631574183702469\n",
      "\n",
      "episode 16, val func loss 0.20685932040214539\n",
      "\n",
      "Val func train loss in epoch 11:0.18778696097433567\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17249105870723724\n",
      "\n",
      "episode 2, val func loss 0.16356375813484192\n",
      "\n",
      "episode 3, val func loss 0.17509664595127106\n",
      "\n",
      "episode 4, val func loss 0.2075103372335434\n",
      "\n",
      "episode 5, val func loss 0.1762915551662445\n",
      "\n",
      "episode 6, val func loss 0.20584173500537872\n",
      "\n",
      "episode 7, val func loss 0.1848164051771164\n",
      "\n",
      "episode 8, val func loss 0.19766508042812347\n",
      "\n",
      "episode 9, val func loss 0.1728895604610443\n",
      "\n",
      "episode 10, val func loss 0.2062562108039856\n",
      "\n",
      "episode 11, val func loss 0.17715272307395935\n",
      "\n",
      "episode 12, val func loss 0.18885372579097748\n",
      "\n",
      "episode 13, val func loss 0.15381795167922974\n",
      "\n",
      "episode 14, val func loss 0.2212069183588028\n",
      "\n",
      "episode 15, val func loss 0.20591415464878082\n",
      "\n",
      "episode 16, val func loss 0.19320470094680786\n",
      "\n",
      "Val func train loss in epoch 12:0.18766078259795904\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18392397463321686\n",
      "\n",
      "episode 2, val func loss 0.20640137791633606\n",
      "\n",
      "episode 3, val func loss 0.19021673500537872\n",
      "\n",
      "episode 4, val func loss 0.17563502490520477\n",
      "\n",
      "episode 5, val func loss 0.2045200914144516\n",
      "\n",
      "episode 6, val func loss 0.16482506692409515\n",
      "\n",
      "episode 7, val func loss 0.21867719292640686\n",
      "\n",
      "episode 8, val func loss 0.1755990982055664\n",
      "\n",
      "episode 9, val func loss 0.1935226172208786\n",
      "\n",
      "episode 10, val func loss 0.15465177595615387\n",
      "\n",
      "episode 11, val func loss 0.17819716036319733\n",
      "\n",
      "episode 12, val func loss 0.1719152331352234\n",
      "\n",
      "episode 13, val func loss 0.17280104756355286\n",
      "\n",
      "episode 14, val func loss 0.2099841684103012\n",
      "\n",
      "episode 15, val func loss 0.19934308528900146\n",
      "\n",
      "episode 16, val func loss 0.20634759962558746\n",
      "\n",
      "Val func train loss in epoch 13:0.18791007809340954\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1980080008506775\n",
      "\n",
      "episode 2, val func loss 0.17214837670326233\n",
      "\n",
      "episode 3, val func loss 0.19262948632240295\n",
      "\n",
      "episode 4, val func loss 0.21905501186847687\n",
      "\n",
      "episode 5, val func loss 0.18532533943653107\n",
      "\n",
      "episode 6, val func loss 0.20528064668178558\n",
      "\n",
      "episode 7, val func loss 0.1666518896818161\n",
      "\n",
      "episode 8, val func loss 0.17766544222831726\n",
      "\n",
      "episode 9, val func loss 0.20641347765922546\n",
      "\n",
      "episode 10, val func loss 0.18953444063663483\n",
      "\n",
      "episode 11, val func loss 0.20716194808483124\n",
      "\n",
      "episode 12, val func loss 0.1773889660835266\n",
      "\n",
      "episode 13, val func loss 0.17395319044589996\n",
      "\n",
      "episode 14, val func loss 0.20759831368923187\n",
      "\n",
      "episode 15, val func loss 0.15329046547412872\n",
      "\n",
      "episode 16, val func loss 0.17185823619365692\n",
      "\n",
      "Val func train loss in epoch 14:0.18774770200252533\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.177007257938385\n",
      "\n",
      "episode 2, val func loss 0.19783221185207367\n",
      "\n",
      "episode 3, val func loss 0.17210833728313446\n",
      "\n",
      "episode 4, val func loss 0.18997414410114288\n",
      "\n",
      "episode 5, val func loss 0.18504853546619415\n",
      "\n",
      "episode 6, val func loss 0.163222998380661\n",
      "\n",
      "episode 7, val func loss 0.1540578007698059\n",
      "\n",
      "episode 8, val func loss 0.17166714370250702\n",
      "\n",
      "episode 9, val func loss 0.19370268285274506\n",
      "\n",
      "episode 10, val func loss 0.17517085373401642\n",
      "\n",
      "episode 11, val func loss 0.2068619728088379\n",
      "\n",
      "episode 12, val func loss 0.2097240835428238\n",
      "\n",
      "episode 13, val func loss 0.17538703978061676\n",
      "\n",
      "episode 14, val func loss 0.20385295152664185\n",
      "\n",
      "episode 15, val func loss 0.2056964784860611\n",
      "\n",
      "episode 16, val func loss 0.2182038128376007\n",
      "\n",
      "Val func train loss in epoch 15:0.18746989406645298\n",
      "***********************TIME WAS 4.912652254104614 min*****************************\n",
      "\n",
      "**********************ROUND 48 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.027476973831653595\n",
      "\n",
      "episode 2, policy loss -0.030431989580392838\n",
      "\n",
      "episode 3, policy loss -0.009166985750198364\n",
      "\n",
      "episode 4, policy loss -0.023371711373329163\n",
      "\n",
      "episode 5, policy loss 0.006328499410301447\n",
      "\n",
      "episode 6, policy loss 0.025994418188929558\n",
      "\n",
      "episode 7, policy loss 0.008731203153729439\n",
      "\n",
      "episode 8, policy loss 0.03346097469329834\n",
      "\n",
      "episode 9, policy loss 0.022164026275277138\n",
      "\n",
      "episode 10, policy loss -0.007167533505707979\n",
      "\n",
      "episode 11, policy loss 0.019503645598888397\n",
      "\n",
      "episode 12, policy loss -0.002807455603033304\n",
      "\n",
      "episode 13, policy loss 0.044041894376277924\n",
      "\n",
      "episode 14, policy loss 0.001152992364950478\n",
      "\n",
      "episode 15, policy loss 0.0236428901553154\n",
      "\n",
      "episode 16, policy loss 0.016314182430505753\n",
      "\n",
      "Policy train loss in epoch 0:0.009741626541654114\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.015004643239080906\n",
      "\n",
      "episode 2, policy loss 0.010824484750628471\n",
      "\n",
      "episode 3, policy loss -0.031751055270433426\n",
      "\n",
      "episode 4, policy loss 0.04191237688064575\n",
      "\n",
      "episode 5, policy loss 0.004661439917981625\n",
      "\n",
      "episode 6, policy loss 0.02603268064558506\n",
      "\n",
      "episode 7, policy loss 0.019681518897414207\n",
      "\n",
      "episode 8, policy loss -0.008236423134803772\n",
      "\n",
      "episode 9, policy loss 0.017956458032131195\n",
      "\n",
      "episode 10, policy loss 0.02721814438700676\n",
      "\n",
      "episode 11, policy loss 0.02368701621890068\n",
      "\n",
      "episode 12, policy loss 0.03531869500875473\n",
      "\n",
      "episode 13, policy loss -0.022332536056637764\n",
      "\n",
      "episode 14, policy loss 0.001667555421590805\n",
      "\n",
      "episode 15, policy loss -0.010599606670439243\n",
      "\n",
      "episode 16, policy loss 0.0028943729121237993\n",
      "\n",
      "Policy train loss in epoch 1:0.009621235323720612\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.0031661216635257006\n",
      "\n",
      "episode 2, policy loss 0.020589174702763557\n",
      "\n",
      "episode 3, policy loss -0.032485030591487885\n",
      "\n",
      "episode 4, policy loss 0.017894670367240906\n",
      "\n",
      "episode 5, policy loss 0.03605611249804497\n",
      "\n",
      "episode 6, policy loss -0.025038843974471092\n",
      "\n",
      "episode 7, policy loss 0.01261676661670208\n",
      "\n",
      "episode 8, policy loss 0.018209675326943398\n",
      "\n",
      "episode 9, policy loss -0.00930134765803814\n",
      "\n",
      "episode 10, policy loss 0.007275435142219067\n",
      "\n",
      "episode 11, policy loss 0.0017440584488213062\n",
      "\n",
      "episode 12, policy loss 0.023091169074177742\n",
      "\n",
      "episode 13, policy loss 0.02545507252216339\n",
      "\n",
      "episode 14, policy loss 0.03983447700738907\n",
      "\n",
      "episode 15, policy loss -0.012062817811965942\n",
      "\n",
      "episode 16, policy loss 0.0006374536897055805\n",
      "\n",
      "Policy train loss in epoch 2:0.007980134188983357\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.019940005615353584\n",
      "\n",
      "episode 2, policy loss 0.00692834472283721\n",
      "\n",
      "episode 3, policy loss -0.03269930183887482\n",
      "\n",
      "episode 4, policy loss 0.023078665137290955\n",
      "\n",
      "episode 5, policy loss 0.003139443462714553\n",
      "\n",
      "episode 6, policy loss 0.03463323041796684\n",
      "\n",
      "episode 7, policy loss 0.017819806933403015\n",
      "\n",
      "episode 8, policy loss 0.03934156894683838\n",
      "\n",
      "episode 9, policy loss -8.088609320111573e-05\n",
      "\n",
      "episode 10, policy loss 0.0010092176962643862\n",
      "\n",
      "episode 11, policy loss 0.01837381348013878\n",
      "\n",
      "episode 12, policy loss -0.012288253754377365\n",
      "\n",
      "episode 13, policy loss -0.026594461873173714\n",
      "\n",
      "episode 14, policy loss 0.02605120837688446\n",
      "\n",
      "episode 15, policy loss -0.010266294702887535\n",
      "\n",
      "episode 16, policy loss 0.009890645742416382\n",
      "\n",
      "Policy train loss in epoch 3:0.007392297016849625\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17713136970996857\n",
      "\n",
      "episode 2, val func loss 0.18994547426700592\n",
      "\n",
      "episode 3, val func loss 0.21455509960651398\n",
      "\n",
      "episode 4, val func loss 0.1980091631412506\n",
      "\n",
      "episode 5, val func loss 0.1981186419725418\n",
      "\n",
      "episode 6, val func loss 0.19028878211975098\n",
      "\n",
      "episode 7, val func loss 0.18095430731773376\n",
      "\n",
      "episode 8, val func loss 0.16912418603897095\n",
      "\n",
      "episode 9, val func loss 0.20164047181606293\n",
      "\n",
      "episode 10, val func loss 0.17837922275066376\n",
      "\n",
      "episode 11, val func loss 0.17177537083625793\n",
      "\n",
      "episode 12, val func loss 0.17505498230457306\n",
      "\n",
      "episode 13, val func loss 0.1827780157327652\n",
      "\n",
      "episode 14, val func loss 0.18677057325839996\n",
      "\n",
      "episode 15, val func loss 0.1710001677274704\n",
      "\n",
      "episode 16, val func loss 0.22163888812065125\n",
      "\n",
      "Val func train loss in epoch 0:0.18794779479503632\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1982695609331131\n",
      "\n",
      "episode 2, val func loss 0.1655598282814026\n",
      "\n",
      "episode 3, val func loss 0.21867673099040985\n",
      "\n",
      "episode 4, val func loss 0.17100867629051208\n",
      "\n",
      "episode 5, val func loss 0.176227405667305\n",
      "\n",
      "episode 6, val func loss 0.17884714901447296\n",
      "\n",
      "episode 7, val func loss 0.19197238981723785\n",
      "\n",
      "episode 8, val func loss 0.18751920759677887\n",
      "\n",
      "episode 9, val func loss 0.2009473443031311\n",
      "\n",
      "episode 10, val func loss 0.17101508378982544\n",
      "\n",
      "episode 11, val func loss 0.17496855556964874\n",
      "\n",
      "episode 12, val func loss 0.1863185614347458\n",
      "\n",
      "episode 13, val func loss 0.1976257711648941\n",
      "\n",
      "episode 14, val func loss 0.18028943240642548\n",
      "\n",
      "episode 15, val func loss 0.18060694634914398\n",
      "\n",
      "episode 16, val func loss 0.21873174607753754\n",
      "\n",
      "Val func train loss in epoch 1:0.18741152435541153\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17892995476722717\n",
      "\n",
      "episode 2, val func loss 0.17153628170490265\n",
      "\n",
      "episode 3, val func loss 0.19742190837860107\n",
      "\n",
      "episode 4, val func loss 0.17035597562789917\n",
      "\n",
      "episode 5, val func loss 0.18742084503173828\n",
      "\n",
      "episode 6, val func loss 0.16539473831653595\n",
      "\n",
      "episode 7, val func loss 0.181258887052536\n",
      "\n",
      "episode 8, val func loss 0.17540501058101654\n",
      "\n",
      "episode 9, val func loss 0.1745690554380417\n",
      "\n",
      "episode 10, val func loss 0.18045111000537872\n",
      "\n",
      "episode 11, val func loss 0.220435231924057\n",
      "\n",
      "episode 12, val func loss 0.19072644412517548\n",
      "\n",
      "episode 13, val func loss 0.18664799630641937\n",
      "\n",
      "episode 14, val func loss 0.21687622368335724\n",
      "\n",
      "episode 15, val func loss 0.19973987340927124\n",
      "\n",
      "episode 16, val func loss 0.1979604810476303\n",
      "\n",
      "Val func train loss in epoch 2:0.18719562608748674\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1809253990650177\n",
      "\n",
      "episode 2, val func loss 0.21853357553482056\n",
      "\n",
      "episode 3, val func loss 0.18151582777500153\n",
      "\n",
      "episode 4, val func loss 0.21609190106391907\n",
      "\n",
      "episode 5, val func loss 0.191484272480011\n",
      "\n",
      "episode 6, val func loss 0.1751224547624588\n",
      "\n",
      "episode 7, val func loss 0.18737979233264923\n",
      "\n",
      "episode 8, val func loss 0.171238511800766\n",
      "\n",
      "episode 9, val func loss 0.19749470055103302\n",
      "\n",
      "episode 10, val func loss 0.1671435385942459\n",
      "\n",
      "episode 11, val func loss 0.18639612197875977\n",
      "\n",
      "episode 12, val func loss 0.20048294961452484\n",
      "\n",
      "episode 13, val func loss 0.17069223523139954\n",
      "\n",
      "episode 14, val func loss 0.1978803277015686\n",
      "\n",
      "episode 15, val func loss 0.1785847246646881\n",
      "\n",
      "episode 16, val func loss 0.17506925761699677\n",
      "\n",
      "Val func train loss in epoch 3:0.18725222442299128\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18730147182941437\n",
      "\n",
      "episode 2, val func loss 0.17841008305549622\n",
      "\n",
      "episode 3, val func loss 0.1753440499305725\n",
      "\n",
      "episode 4, val func loss 0.21955591440200806\n",
      "\n",
      "episode 5, val func loss 0.2002740353345871\n",
      "\n",
      "episode 6, val func loss 0.1914035975933075\n",
      "\n",
      "episode 7, val func loss 0.17055539786815643\n",
      "\n",
      "episode 8, val func loss 0.18678520619869232\n",
      "\n",
      "episode 9, val func loss 0.1804192215204239\n",
      "\n",
      "episode 10, val func loss 0.18022695183753967\n",
      "\n",
      "episode 11, val func loss 0.17608468234539032\n",
      "\n",
      "episode 12, val func loss 0.1975090652704239\n",
      "\n",
      "episode 13, val func loss 0.16689945757389069\n",
      "\n",
      "episode 14, val func loss 0.17046590149402618\n",
      "\n",
      "episode 15, val func loss 0.19767950475215912\n",
      "\n",
      "episode 16, val func loss 0.21621595323085785\n",
      "\n",
      "Val func train loss in epoch 4:0.18719565588980913\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18118999898433685\n",
      "\n",
      "episode 2, val func loss 0.19843509793281555\n",
      "\n",
      "episode 3, val func loss 0.16495051980018616\n",
      "\n",
      "episode 4, val func loss 0.1920691579580307\n",
      "\n",
      "episode 5, val func loss 0.1877935528755188\n",
      "\n",
      "episode 6, val func loss 0.17029044032096863\n",
      "\n",
      "episode 7, val func loss 0.17964763939380646\n",
      "\n",
      "episode 8, val func loss 0.19913221895694733\n",
      "\n",
      "episode 9, val func loss 0.17533591389656067\n",
      "\n",
      "episode 10, val func loss 0.18081045150756836\n",
      "\n",
      "episode 11, val func loss 0.18677502870559692\n",
      "\n",
      "episode 12, val func loss 0.17534327507019043\n",
      "\n",
      "episode 13, val func loss 0.17061223089694977\n",
      "\n",
      "episode 14, val func loss 0.21649661660194397\n",
      "\n",
      "episode 15, val func loss 0.21875490248203278\n",
      "\n",
      "episode 16, val func loss 0.19980327785015106\n",
      "\n",
      "Val func train loss in epoch 5:0.18734002020210028\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17624394595623016\n",
      "\n",
      "episode 2, val func loss 0.17386619746685028\n",
      "\n",
      "episode 3, val func loss 0.17875827848911285\n",
      "\n",
      "episode 4, val func loss 0.18177731335163116\n",
      "\n",
      "episode 5, val func loss 0.18949627876281738\n",
      "\n",
      "episode 6, val func loss 0.20069943368434906\n",
      "\n",
      "episode 7, val func loss 0.19801069796085358\n",
      "\n",
      "episode 8, val func loss 0.1677909940481186\n",
      "\n",
      "episode 9, val func loss 0.21808172762393951\n",
      "\n",
      "episode 10, val func loss 0.17031577229499817\n",
      "\n",
      "episode 11, val func loss 0.19925682246685028\n",
      "\n",
      "episode 12, val func loss 0.18205557763576508\n",
      "\n",
      "episode 13, val func loss 0.1751885712146759\n",
      "\n",
      "episode 14, val func loss 0.1875128298997879\n",
      "\n",
      "episode 15, val func loss 0.18717604875564575\n",
      "\n",
      "episode 16, val func loss 0.22196435928344727\n",
      "\n",
      "Val func train loss in epoch 6:0.18801217805594206\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17838764190673828\n",
      "\n",
      "episode 2, val func loss 0.1651618480682373\n",
      "\n",
      "episode 3, val func loss 0.17302317917346954\n",
      "\n",
      "episode 4, val func loss 0.175359308719635\n",
      "\n",
      "episode 5, val func loss 0.18712827563285828\n",
      "\n",
      "episode 6, val func loss 0.22090713679790497\n",
      "\n",
      "episode 7, val func loss 0.18110105395317078\n",
      "\n",
      "episode 8, val func loss 0.19804702699184418\n",
      "\n",
      "episode 9, val func loss 0.18722999095916748\n",
      "\n",
      "episode 10, val func loss 0.21743746101856232\n",
      "\n",
      "episode 11, val func loss 0.1802961826324463\n",
      "\n",
      "episode 12, val func loss 0.17484831809997559\n",
      "\n",
      "episode 13, val func loss 0.1974387764930725\n",
      "\n",
      "episode 14, val func loss 0.19097813963890076\n",
      "\n",
      "episode 15, val func loss 0.19935382902622223\n",
      "\n",
      "episode 16, val func loss 0.17002935707569122\n",
      "\n",
      "Val func train loss in epoch 7:0.18729547038674355\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17043879628181458\n",
      "\n",
      "episode 2, val func loss 0.21924901008605957\n",
      "\n",
      "episode 3, val func loss 0.17546144127845764\n",
      "\n",
      "episode 4, val func loss 0.19154615700244904\n",
      "\n",
      "episode 5, val func loss 0.1746744066476822\n",
      "\n",
      "episode 6, val func loss 0.1997040957212448\n",
      "\n",
      "episode 7, val func loss 0.16439706087112427\n",
      "\n",
      "episode 8, val func loss 0.1718641221523285\n",
      "\n",
      "episode 9, val func loss 0.21620315313339233\n",
      "\n",
      "episode 10, val func loss 0.1979673206806183\n",
      "\n",
      "episode 11, val func loss 0.18674913048744202\n",
      "\n",
      "episode 12, val func loss 0.18747751414775848\n",
      "\n",
      "episode 13, val func loss 0.17843109369277954\n",
      "\n",
      "episode 14, val func loss 0.19697099924087524\n",
      "\n",
      "episode 15, val func loss 0.18043920397758484\n",
      "\n",
      "episode 16, val func loss 0.18065717816352844\n",
      "\n",
      "Val func train loss in epoch 8:0.18701441772282124\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18064656853675842\n",
      "\n",
      "episode 2, val func loss 0.17938214540481567\n",
      "\n",
      "episode 3, val func loss 0.1907610446214676\n",
      "\n",
      "episode 4, val func loss 0.17193172872066498\n",
      "\n",
      "episode 5, val func loss 0.21754974126815796\n",
      "\n",
      "episode 6, val func loss 0.18717101216316223\n",
      "\n",
      "episode 7, val func loss 0.1646668016910553\n",
      "\n",
      "episode 8, val func loss 0.17085981369018555\n",
      "\n",
      "episode 9, val func loss 0.19973741471767426\n",
      "\n",
      "episode 10, val func loss 0.1980101764202118\n",
      "\n",
      "episode 11, val func loss 0.19787099957466125\n",
      "\n",
      "episode 12, val func loss 0.1814538985490799\n",
      "\n",
      "episode 13, val func loss 0.18604488670825958\n",
      "\n",
      "episode 14, val func loss 0.22074927389621735\n",
      "\n",
      "episode 15, val func loss 0.17599715292453766\n",
      "\n",
      "episode 16, val func loss 0.17471909523010254\n",
      "\n",
      "Val func train loss in epoch 9:0.18734698463231325\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.2170977145433426\n",
      "\n",
      "episode 2, val func loss 0.19760532677173615\n",
      "\n",
      "episode 3, val func loss 0.17555157840251923\n",
      "\n",
      "episode 4, val func loss 0.16439288854599\n",
      "\n",
      "episode 5, val func loss 0.17463335394859314\n",
      "\n",
      "episode 6, val func loss 0.17912650108337402\n",
      "\n",
      "episode 7, val func loss 0.18084561824798584\n",
      "\n",
      "episode 8, val func loss 0.1969505399465561\n",
      "\n",
      "episode 9, val func loss 0.19016297161579132\n",
      "\n",
      "episode 10, val func loss 0.18807685375213623\n",
      "\n",
      "episode 11, val func loss 0.18912410736083984\n",
      "\n",
      "episode 12, val func loss 0.20128561556339264\n",
      "\n",
      "episode 13, val func loss 0.18060734868049622\n",
      "\n",
      "episode 14, val func loss 0.17087820172309875\n",
      "\n",
      "episode 15, val func loss 0.21803860366344452\n",
      "\n",
      "episode 16, val func loss 0.17568397521972656\n",
      "\n",
      "Val func train loss in epoch 10:0.18750382494181395\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1885942816734314\n",
      "\n",
      "episode 2, val func loss 0.18337880074977875\n",
      "\n",
      "episode 3, val func loss 0.19829484820365906\n",
      "\n",
      "episode 4, val func loss 0.1870890110731125\n",
      "\n",
      "episode 5, val func loss 0.175001859664917\n",
      "\n",
      "episode 6, val func loss 0.19707579910755157\n",
      "\n",
      "episode 7, val func loss 0.2218572199344635\n",
      "\n",
      "episode 8, val func loss 0.21842636168003082\n",
      "\n",
      "episode 9, val func loss 0.17857725918293\n",
      "\n",
      "episode 10, val func loss 0.17115625739097595\n",
      "\n",
      "episode 11, val func loss 0.1645401120185852\n",
      "\n",
      "episode 12, val func loss 0.18226972222328186\n",
      "\n",
      "episode 13, val func loss 0.17384767532348633\n",
      "\n",
      "episode 14, val func loss 0.19144174456596375\n",
      "\n",
      "episode 15, val func loss 0.20067016780376434\n",
      "\n",
      "episode 16, val func loss 0.17611873149871826\n",
      "\n",
      "Val func train loss in epoch 11:0.18802124075591564\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17490074038505554\n",
      "\n",
      "episode 2, val func loss 0.17570219933986664\n",
      "\n",
      "episode 3, val func loss 0.1974787563085556\n",
      "\n",
      "episode 4, val func loss 0.19829143583774567\n",
      "\n",
      "episode 5, val func loss 0.1653135120868683\n",
      "\n",
      "episode 6, val func loss 0.1714869737625122\n",
      "\n",
      "episode 7, val func loss 0.21544386446475983\n",
      "\n",
      "episode 8, val func loss 0.18089964985847473\n",
      "\n",
      "episode 9, val func loss 0.20015273988246918\n",
      "\n",
      "episode 10, val func loss 0.1709507703781128\n",
      "\n",
      "episode 11, val func loss 0.18073458969593048\n",
      "\n",
      "episode 12, val func loss 0.18612389266490936\n",
      "\n",
      "episode 13, val func loss 0.18797451257705688\n",
      "\n",
      "episode 14, val func loss 0.22170846164226532\n",
      "\n",
      "episode 15, val func loss 0.19029869139194489\n",
      "\n",
      "episode 16, val func loss 0.1781284511089325\n",
      "\n",
      "Val func train loss in epoch 12:0.18722432758659124\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.21624091267585754\n",
      "\n",
      "episode 2, val func loss 0.1760479062795639\n",
      "\n",
      "episode 3, val func loss 0.16481085121631622\n",
      "\n",
      "episode 4, val func loss 0.18197859823703766\n",
      "\n",
      "episode 5, val func loss 0.1820208728313446\n",
      "\n",
      "episode 6, val func loss 0.17080357670783997\n",
      "\n",
      "episode 7, val func loss 0.18720971047878265\n",
      "\n",
      "episode 8, val func loss 0.1880217045545578\n",
      "\n",
      "episode 9, val func loss 0.19060006737709045\n",
      "\n",
      "episode 10, val func loss 0.21953105926513672\n",
      "\n",
      "episode 11, val func loss 0.19831052422523499\n",
      "\n",
      "episode 12, val func loss 0.19768574833869934\n",
      "\n",
      "episode 13, val func loss 0.17249000072479248\n",
      "\n",
      "episode 14, val func loss 0.19940677285194397\n",
      "\n",
      "episode 15, val func loss 0.1785481870174408\n",
      "\n",
      "episode 16, val func loss 0.17430700361728668\n",
      "\n",
      "Val func train loss in epoch 13:0.18737584352493286\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.21730861067771912\n",
      "\n",
      "episode 2, val func loss 0.1808249056339264\n",
      "\n",
      "episode 3, val func loss 0.18675367534160614\n",
      "\n",
      "episode 4, val func loss 0.17189042270183563\n",
      "\n",
      "episode 5, val func loss 0.19726122915744781\n",
      "\n",
      "episode 6, val func loss 0.1885308027267456\n",
      "\n",
      "episode 7, val func loss 0.1672568917274475\n",
      "\n",
      "episode 8, val func loss 0.17563849687576294\n",
      "\n",
      "episode 9, val func loss 0.19976840913295746\n",
      "\n",
      "episode 10, val func loss 0.1716204732656479\n",
      "\n",
      "episode 11, val func loss 0.21740281581878662\n",
      "\n",
      "episode 12, val func loss 0.19819582998752594\n",
      "\n",
      "episode 13, val func loss 0.1750880628824234\n",
      "\n",
      "episode 14, val func loss 0.18064799904823303\n",
      "\n",
      "episode 15, val func loss 0.18110507726669312\n",
      "\n",
      "episode 16, val func loss 0.19001001119613647\n",
      "\n",
      "Val func train loss in epoch 14:0.18745648209005594\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.21937836706638336\n",
      "\n",
      "episode 2, val func loss 0.17439398169517517\n",
      "\n",
      "episode 3, val func loss 0.20012764632701874\n",
      "\n",
      "episode 4, val func loss 0.19921141862869263\n",
      "\n",
      "episode 5, val func loss 0.16544145345687866\n",
      "\n",
      "episode 6, val func loss 0.18071602284908295\n",
      "\n",
      "episode 7, val func loss 0.17039215564727783\n",
      "\n",
      "episode 8, val func loss 0.1909150332212448\n",
      "\n",
      "episode 9, val func loss 0.17993126809597015\n",
      "\n",
      "episode 10, val func loss 0.17055049538612366\n",
      "\n",
      "episode 11, val func loss 0.19125953316688538\n",
      "\n",
      "episode 12, val func loss 0.19791661202907562\n",
      "\n",
      "episode 13, val func loss 0.21518588066101074\n",
      "\n",
      "episode 14, val func loss 0.18779492378234863\n",
      "\n",
      "episode 15, val func loss 0.18133704364299774\n",
      "\n",
      "episode 16, val func loss 0.17571397125720978\n",
      "\n",
      "Val func train loss in epoch 15:0.187516612932086\n",
      "***********************TIME WAS 4.91353745063146 min*****************************\n",
      "\n",
      "**********************ROUND 49 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.022731488570570946\n",
      "\n",
      "episode 2, policy loss -0.1258241981267929\n",
      "\n",
      "episode 3, policy loss -0.06458631902933121\n",
      "\n",
      "episode 4, policy loss -0.06864891946315765\n",
      "\n",
      "episode 5, policy loss 0.0159359909594059\n",
      "\n",
      "episode 6, policy loss -0.06503235548734665\n",
      "\n",
      "episode 7, policy loss -0.036719389259815216\n",
      "\n",
      "episode 8, policy loss -0.06387588381767273\n",
      "\n",
      "episode 9, policy loss -0.06509722024202347\n",
      "\n",
      "episode 10, policy loss -0.04675104469060898\n",
      "\n",
      "episode 11, policy loss -0.017721660435199738\n",
      "\n",
      "episode 12, policy loss -0.007558587472885847\n",
      "\n",
      "episode 13, policy loss -0.08420920372009277\n",
      "\n",
      "episode 14, policy loss -0.03976571559906006\n",
      "\n",
      "episode 15, policy loss -0.06848955154418945\n",
      "\n",
      "episode 16, policy loss -0.0836850255727768\n",
      "\n",
      "Policy train loss in epoch 0:-0.05279753575450741\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.08490291237831116\n",
      "\n",
      "episode 2, policy loss -0.04527776688337326\n",
      "\n",
      "episode 3, policy loss -0.07727731019258499\n",
      "\n",
      "episode 4, policy loss -0.0328766405582428\n",
      "\n",
      "episode 5, policy loss -0.024051671847701073\n",
      "\n",
      "episode 6, policy loss -0.016833849251270294\n",
      "\n",
      "episode 7, policy loss -0.06935141235589981\n",
      "\n",
      "episode 8, policy loss -0.035506609827280045\n",
      "\n",
      "episode 9, policy loss -0.06318606436252594\n",
      "\n",
      "episode 10, policy loss -0.06933178752660751\n",
      "\n",
      "episode 11, policy loss -0.06558571010828018\n",
      "\n",
      "episode 12, policy loss -0.06835442781448364\n",
      "\n",
      "episode 13, policy loss -0.1277547925710678\n",
      "\n",
      "episode 14, policy loss 0.010878666304051876\n",
      "\n",
      "episode 15, policy loss -0.010755490511655807\n",
      "\n",
      "episode 16, policy loss -0.06231877580285072\n",
      "\n",
      "Policy train loss in epoch 1:-0.0526554097305052\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.02199135161936283\n",
      "\n",
      "episode 2, policy loss -0.01688692905008793\n",
      "\n",
      "episode 3, policy loss -0.0658770427107811\n",
      "\n",
      "episode 4, policy loss -0.03873620182275772\n",
      "\n",
      "episode 5, policy loss -0.046975210309028625\n",
      "\n",
      "episode 6, policy loss -0.07366154342889786\n",
      "\n",
      "episode 7, policy loss -0.08371476829051971\n",
      "\n",
      "episode 8, policy loss -0.009763898327946663\n",
      "\n",
      "episode 9, policy loss -0.06437575072050095\n",
      "\n",
      "episode 10, policy loss -0.08474741876125336\n",
      "\n",
      "episode 11, policy loss -0.03657796233892441\n",
      "\n",
      "episode 12, policy loss -0.06986618041992188\n",
      "\n",
      "episode 13, policy loss -0.12660010159015656\n",
      "\n",
      "episode 14, policy loss 0.014025505632162094\n",
      "\n",
      "episode 15, policy loss -0.07356815785169601\n",
      "\n",
      "episode 16, policy loss -0.06792193651199341\n",
      "\n",
      "Policy train loss in epoch 2:-0.05420243425760418\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.06628524512052536\n",
      "\n",
      "episode 2, policy loss -0.06478863209486008\n",
      "\n",
      "episode 3, policy loss -0.012097638100385666\n",
      "\n",
      "episode 4, policy loss -0.12708529829978943\n",
      "\n",
      "episode 5, policy loss -0.08267561346292496\n",
      "\n",
      "episode 6, policy loss -0.08834914118051529\n",
      "\n",
      "episode 7, policy loss -0.06735317409038544\n",
      "\n",
      "episode 8, policy loss -0.035740192979574203\n",
      "\n",
      "episode 9, policy loss -0.047768864780664444\n",
      "\n",
      "episode 10, policy loss 0.013132233172655106\n",
      "\n",
      "episode 11, policy loss -0.03528797626495361\n",
      "\n",
      "episode 12, policy loss -0.07165417075157166\n",
      "\n",
      "episode 13, policy loss -0.06909138709306717\n",
      "\n",
      "episode 14, policy loss -0.01650836132466793\n",
      "\n",
      "episode 15, policy loss -0.07374536246061325\n",
      "\n",
      "episode 16, policy loss -0.023313244804739952\n",
      "\n",
      "Policy train loss in epoch 3:-0.05428825435228646\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1760845184326172\n",
      "\n",
      "episode 2, val func loss 0.15610700845718384\n",
      "\n",
      "episode 3, val func loss 0.18195828795433044\n",
      "\n",
      "episode 4, val func loss 0.20238667726516724\n",
      "\n",
      "episode 5, val func loss 0.19738616049289703\n",
      "\n",
      "episode 6, val func loss 0.1883961707353592\n",
      "\n",
      "episode 7, val func loss 0.20823360979557037\n",
      "\n",
      "episode 8, val func loss 0.19136762619018555\n",
      "\n",
      "episode 9, val func loss 0.2097572535276413\n",
      "\n",
      "episode 10, val func loss 0.1816258281469345\n",
      "\n",
      "episode 11, val func loss 0.19384881854057312\n",
      "\n",
      "episode 12, val func loss 0.2065267413854599\n",
      "\n",
      "episode 13, val func loss 0.18552574515342712\n",
      "\n",
      "episode 14, val func loss 0.2276056557893753\n",
      "\n",
      "episode 15, val func loss 0.18990297615528107\n",
      "\n",
      "episode 16, val func loss 0.17634856700897217\n",
      "\n",
      "Val func train loss in epoch 0:0.19206635281443596\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1762477606534958\n",
      "\n",
      "episode 2, val func loss 0.18579308688640594\n",
      "\n",
      "episode 3, val func loss 0.15702341496944427\n",
      "\n",
      "episode 4, val func loss 0.2104341685771942\n",
      "\n",
      "episode 5, val func loss 0.17121641337871552\n",
      "\n",
      "episode 6, val func loss 0.17556318640708923\n",
      "\n",
      "episode 7, val func loss 0.1951819360256195\n",
      "\n",
      "episode 8, val func loss 0.19685214757919312\n",
      "\n",
      "episode 9, val func loss 0.23204372823238373\n",
      "\n",
      "episode 10, val func loss 0.19086720049381256\n",
      "\n",
      "episode 11, val func loss 0.2079879194498062\n",
      "\n",
      "episode 12, val func loss 0.20957939326763153\n",
      "\n",
      "episode 13, val func loss 0.19084399938583374\n",
      "\n",
      "episode 14, val func loss 0.18754801154136658\n",
      "\n",
      "episode 15, val func loss 0.19560764729976654\n",
      "\n",
      "episode 16, val func loss 0.19081427156925201\n",
      "\n",
      "Val func train loss in epoch 1:0.19210026785731316\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18642611801624298\n",
      "\n",
      "episode 2, val func loss 0.22615723311901093\n",
      "\n",
      "episode 3, val func loss 0.19841401278972626\n",
      "\n",
      "episode 4, val func loss 0.17557111382484436\n",
      "\n",
      "episode 5, val func loss 0.20683859288692474\n",
      "\n",
      "episode 6, val func loss 0.17645452916622162\n",
      "\n",
      "episode 7, val func loss 0.1859852820634842\n",
      "\n",
      "episode 8, val func loss 0.20926308631896973\n",
      "\n",
      "episode 9, val func loss 0.20826074481010437\n",
      "\n",
      "episode 10, val func loss 0.15888471901416779\n",
      "\n",
      "episode 11, val func loss 0.17284688353538513\n",
      "\n",
      "episode 12, val func loss 0.19367636740207672\n",
      "\n",
      "episode 13, val func loss 0.19304220378398895\n",
      "\n",
      "episode 14, val func loss 0.19156311452388763\n",
      "\n",
      "episode 15, val func loss 0.1829184889793396\n",
      "\n",
      "episode 16, val func loss 0.19583971798419952\n",
      "\n",
      "Val func train loss in epoch 2:0.1913838880136609\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20884978771209717\n",
      "\n",
      "episode 2, val func loss 0.17369075119495392\n",
      "\n",
      "episode 3, val func loss 0.19294510781764984\n",
      "\n",
      "episode 4, val func loss 0.17646194994449615\n",
      "\n",
      "episode 5, val func loss 0.20886898040771484\n",
      "\n",
      "episode 6, val func loss 0.2087937295436859\n",
      "\n",
      "episode 7, val func loss 0.18542633950710297\n",
      "\n",
      "episode 8, val func loss 0.19163642823696136\n",
      "\n",
      "episode 9, val func loss 0.17599545419216156\n",
      "\n",
      "episode 10, val func loss 0.1609654724597931\n",
      "\n",
      "episode 11, val func loss 0.1956995725631714\n",
      "\n",
      "episode 12, val func loss 0.2284107506275177\n",
      "\n",
      "episode 13, val func loss 0.18964752554893494\n",
      "\n",
      "episode 14, val func loss 0.18460020422935486\n",
      "\n",
      "episode 15, val func loss 0.19671587646007538\n",
      "\n",
      "episode 16, val func loss 0.18691015243530273\n",
      "\n",
      "Val func train loss in epoch 3:0.19160113018006086\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1760450005531311\n",
      "\n",
      "episode 2, val func loss 0.1836245208978653\n",
      "\n",
      "episode 3, val func loss 0.15602941811084747\n",
      "\n",
      "episode 4, val func loss 0.18871954083442688\n",
      "\n",
      "episode 5, val func loss 0.189813032746315\n",
      "\n",
      "episode 6, val func loss 0.1954072266817093\n",
      "\n",
      "episode 7, val func loss 0.17130210995674133\n",
      "\n",
      "episode 8, val func loss 0.1972530484199524\n",
      "\n",
      "episode 9, val func loss 0.1963304877281189\n",
      "\n",
      "episode 10, val func loss 0.21020984649658203\n",
      "\n",
      "episode 11, val func loss 0.20735765993595123\n",
      "\n",
      "episode 12, val func loss 0.17560110986232758\n",
      "\n",
      "episode 13, val func loss 0.19160693883895874\n",
      "\n",
      "episode 14, val func loss 0.19039715826511383\n",
      "\n",
      "episode 15, val func loss 0.22469180822372437\n",
      "\n",
      "episode 16, val func loss 0.2103784680366516\n",
      "\n",
      "Val func train loss in epoch 4:0.19154796097427607\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19249776005744934\n",
      "\n",
      "episode 2, val func loss 0.20152547955513\n",
      "\n",
      "episode 3, val func loss 0.22548535466194153\n",
      "\n",
      "episode 4, val func loss 0.19012351334095\n",
      "\n",
      "episode 5, val func loss 0.1857369840145111\n",
      "\n",
      "episode 6, val func loss 0.17362478375434875\n",
      "\n",
      "episode 7, val func loss 0.19615377485752106\n",
      "\n",
      "episode 8, val func loss 0.19388167560100555\n",
      "\n",
      "episode 9, val func loss 0.19485610723495483\n",
      "\n",
      "episode 10, val func loss 0.21066787838935852\n",
      "\n",
      "episode 11, val func loss 0.1759123057126999\n",
      "\n",
      "episode 12, val func loss 0.1754324585199356\n",
      "\n",
      "episode 13, val func loss 0.18756896257400513\n",
      "\n",
      "episode 14, val func loss 0.2080886960029602\n",
      "\n",
      "episode 15, val func loss 0.2062976360321045\n",
      "\n",
      "episode 16, val func loss 0.16295915842056274\n",
      "\n",
      "Val func train loss in epoch 5:0.19255078304558992\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1898467242717743\n",
      "\n",
      "episode 2, val func loss 0.1764155775308609\n",
      "\n",
      "episode 3, val func loss 0.19160784780979156\n",
      "\n",
      "episode 4, val func loss 0.1603580117225647\n",
      "\n",
      "episode 5, val func loss 0.18406443297863007\n",
      "\n",
      "episode 6, val func loss 0.1967296451330185\n",
      "\n",
      "episode 7, val func loss 0.1757093369960785\n",
      "\n",
      "episode 8, val func loss 0.21377481520175934\n",
      "\n",
      "episode 9, val func loss 0.19129233062267303\n",
      "\n",
      "episode 10, val func loss 0.23485086858272552\n",
      "\n",
      "episode 11, val func loss 0.1942550390958786\n",
      "\n",
      "episode 12, val func loss 0.20789316296577454\n",
      "\n",
      "episode 13, val func loss 0.19541771709918976\n",
      "\n",
      "episode 14, val func loss 0.2083914577960968\n",
      "\n",
      "episode 15, val func loss 0.18697266280651093\n",
      "\n",
      "episode 16, val func loss 0.18367792665958405\n",
      "\n",
      "Val func train loss in epoch 6:0.19320359732955694\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18757236003875732\n",
      "\n",
      "episode 2, val func loss 0.2093915492296219\n",
      "\n",
      "episode 3, val func loss 0.22533993422985077\n",
      "\n",
      "episode 4, val func loss 0.1950298696756363\n",
      "\n",
      "episode 5, val func loss 0.19883446395397186\n",
      "\n",
      "episode 6, val func loss 0.17422814667224884\n",
      "\n",
      "episode 7, val func loss 0.2088639885187149\n",
      "\n",
      "episode 8, val func loss 0.19080813229084015\n",
      "\n",
      "episode 9, val func loss 0.17611591517925262\n",
      "\n",
      "episode 10, val func loss 0.15508638322353363\n",
      "\n",
      "episode 11, val func loss 0.19486495852470398\n",
      "\n",
      "episode 12, val func loss 0.1771281361579895\n",
      "\n",
      "episode 13, val func loss 0.19539161026477814\n",
      "\n",
      "episode 14, val func loss 0.18732091784477234\n",
      "\n",
      "episode 15, val func loss 0.18336105346679688\n",
      "\n",
      "episode 16, val func loss 0.2080964595079422\n",
      "\n",
      "Val func train loss in epoch 7:0.1917146174237132\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.18699699640274048\n",
      "\n",
      "episode 2, val func loss 0.19297301769256592\n",
      "\n",
      "episode 3, val func loss 0.19538459181785583\n",
      "\n",
      "episode 4, val func loss 0.18901610374450684\n",
      "\n",
      "episode 5, val func loss 0.17937639355659485\n",
      "\n",
      "episode 6, val func loss 0.2080737054347992\n",
      "\n",
      "episode 7, val func loss 0.1908576637506485\n",
      "\n",
      "episode 8, val func loss 0.22715817391872406\n",
      "\n",
      "episode 9, val func loss 0.18584074079990387\n",
      "\n",
      "episode 10, val func loss 0.19776225090026855\n",
      "\n",
      "episode 11, val func loss 0.19021527469158173\n",
      "\n",
      "episode 12, val func loss 0.17419587075710297\n",
      "\n",
      "episode 13, val func loss 0.15824919939041138\n",
      "\n",
      "episode 14, val func loss 0.20854677259922028\n",
      "\n",
      "episode 15, val func loss 0.1756310760974884\n",
      "\n",
      "episode 16, val func loss 0.20974980294704437\n",
      "\n",
      "Val func train loss in epoch 8:0.19187672715634108\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1934974193572998\n",
      "\n",
      "episode 2, val func loss 0.1965257078409195\n",
      "\n",
      "episode 3, val func loss 0.18390655517578125\n",
      "\n",
      "episode 4, val func loss 0.19037355482578278\n",
      "\n",
      "episode 5, val func loss 0.22790850698947906\n",
      "\n",
      "episode 6, val func loss 0.18612703680992126\n",
      "\n",
      "episode 7, val func loss 0.18650546669960022\n",
      "\n",
      "episode 8, val func loss 0.17989248037338257\n",
      "\n",
      "episode 9, val func loss 0.20767071843147278\n",
      "\n",
      "episode 10, val func loss 0.1775946468114853\n",
      "\n",
      "episode 11, val func loss 0.2054833620786667\n",
      "\n",
      "episode 12, val func loss 0.19333267211914062\n",
      "\n",
      "episode 13, val func loss 0.19899998605251312\n",
      "\n",
      "episode 14, val func loss 0.20889419317245483\n",
      "\n",
      "episode 15, val func loss 0.17476345598697662\n",
      "\n",
      "episode 16, val func loss 0.15719233453273773\n",
      "\n",
      "Val func train loss in epoch 9:0.19179175607860088\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.191968634724617\n",
      "\n",
      "episode 2, val func loss 0.23447518050670624\n",
      "\n",
      "episode 3, val func loss 0.21107248961925507\n",
      "\n",
      "episode 4, val func loss 0.17711420357227325\n",
      "\n",
      "episode 5, val func loss 0.18837402760982513\n",
      "\n",
      "episode 6, val func loss 0.19231016933918\n",
      "\n",
      "episode 7, val func loss 0.17522430419921875\n",
      "\n",
      "episode 8, val func loss 0.16071061789989471\n",
      "\n",
      "episode 9, val func loss 0.1982354372739792\n",
      "\n",
      "episode 10, val func loss 0.18452627956867218\n",
      "\n",
      "episode 11, val func loss 0.17603488266468048\n",
      "\n",
      "episode 12, val func loss 0.1866825968027115\n",
      "\n",
      "episode 13, val func loss 0.21135811507701874\n",
      "\n",
      "episode 14, val func loss 0.1942078322172165\n",
      "\n",
      "episode 15, val func loss 0.1960790455341339\n",
      "\n",
      "episode 16, val func loss 0.20731744170188904\n",
      "\n",
      "Val func train loss in epoch 10:0.19285570364445448\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.22507286071777344\n",
      "\n",
      "episode 2, val func loss 0.19028054177761078\n",
      "\n",
      "episode 3, val func loss 0.20690825581550598\n",
      "\n",
      "episode 4, val func loss 0.19398146867752075\n",
      "\n",
      "episode 5, val func loss 0.19492805004119873\n",
      "\n",
      "episode 6, val func loss 0.17371100187301636\n",
      "\n",
      "episode 7, val func loss 0.15577499568462372\n",
      "\n",
      "episode 8, val func loss 0.17683833837509155\n",
      "\n",
      "episode 9, val func loss 0.19333700835704803\n",
      "\n",
      "episode 10, val func loss 0.18259401619434357\n",
      "\n",
      "episode 11, val func loss 0.19600246846675873\n",
      "\n",
      "episode 12, val func loss 0.17588192224502563\n",
      "\n",
      "episode 13, val func loss 0.18722675740718842\n",
      "\n",
      "episode 14, val func loss 0.2063569575548172\n",
      "\n",
      "episode 15, val func loss 0.21389207243919373\n",
      "\n",
      "episode 16, val func loss 0.2075725942850113\n",
      "\n",
      "Val func train loss in epoch 11:0.192522456869483\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17562998831272125\n",
      "\n",
      "episode 2, val func loss 0.21044820547103882\n",
      "\n",
      "episode 3, val func loss 0.1966153085231781\n",
      "\n",
      "episode 4, val func loss 0.1923937052488327\n",
      "\n",
      "episode 5, val func loss 0.18944770097732544\n",
      "\n",
      "episode 6, val func loss 0.19349993765354156\n",
      "\n",
      "episode 7, val func loss 0.2248416543006897\n",
      "\n",
      "episode 8, val func loss 0.16827663779258728\n",
      "\n",
      "episode 9, val func loss 0.18628144264221191\n",
      "\n",
      "episode 10, val func loss 0.18553806841373444\n",
      "\n",
      "episode 11, val func loss 0.2077963501214981\n",
      "\n",
      "episode 12, val func loss 0.20897376537322998\n",
      "\n",
      "episode 13, val func loss 0.18395210802555084\n",
      "\n",
      "episode 14, val func loss 0.17237785458564758\n",
      "\n",
      "episode 15, val func loss 0.19640101492404938\n",
      "\n",
      "episode 16, val func loss 0.17591062188148499\n",
      "\n",
      "Val func train loss in epoch 12:0.19177402276545763\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19711042940616608\n",
      "\n",
      "episode 2, val func loss 0.1900060474872589\n",
      "\n",
      "episode 3, val func loss 0.2105744630098343\n",
      "\n",
      "episode 4, val func loss 0.21048903465270996\n",
      "\n",
      "episode 5, val func loss 0.19381318986415863\n",
      "\n",
      "episode 6, val func loss 0.19146758317947388\n",
      "\n",
      "episode 7, val func loss 0.207415372133255\n",
      "\n",
      "episode 8, val func loss 0.22370396554470062\n",
      "\n",
      "episode 9, val func loss 0.1993718147277832\n",
      "\n",
      "episode 10, val func loss 0.17194399237632751\n",
      "\n",
      "episode 11, val func loss 0.17969314754009247\n",
      "\n",
      "episode 12, val func loss 0.17558233439922333\n",
      "\n",
      "episode 13, val func loss 0.18582157790660858\n",
      "\n",
      "episode 14, val func loss 0.1910712718963623\n",
      "\n",
      "episode 15, val func loss 0.17095674574375153\n",
      "\n",
      "episode 16, val func loss 0.18240392208099365\n",
      "\n",
      "Val func train loss in epoch 13:0.19258905574679375\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18259629607200623\n",
      "\n",
      "episode 2, val func loss 0.15365417301654816\n",
      "\n",
      "episode 3, val func loss 0.19791394472122192\n",
      "\n",
      "episode 4, val func loss 0.19842082262039185\n",
      "\n",
      "episode 5, val func loss 0.23815345764160156\n",
      "\n",
      "episode 6, val func loss 0.197418674826622\n",
      "\n",
      "episode 7, val func loss 0.1737007349729538\n",
      "\n",
      "episode 8, val func loss 0.20815028250217438\n",
      "\n",
      "episode 9, val func loss 0.18583178520202637\n",
      "\n",
      "episode 10, val func loss 0.19045135378837585\n",
      "\n",
      "episode 11, val func loss 0.19144290685653687\n",
      "\n",
      "episode 12, val func loss 0.20605137944221497\n",
      "\n",
      "episode 13, val func loss 0.17698752880096436\n",
      "\n",
      "episode 14, val func loss 0.2088245302438736\n",
      "\n",
      "episode 15, val func loss 0.18616652488708496\n",
      "\n",
      "episode 16, val func loss 0.17733031511306763\n",
      "\n",
      "Val func train loss in epoch 14:0.19206841941922903\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19017471373081207\n",
      "\n",
      "episode 2, val func loss 0.1839941143989563\n",
      "\n",
      "episode 3, val func loss 0.17266711592674255\n",
      "\n",
      "episode 4, val func loss 0.18867453932762146\n",
      "\n",
      "episode 5, val func loss 0.1967909038066864\n",
      "\n",
      "episode 6, val func loss 0.17669475078582764\n",
      "\n",
      "episode 7, val func loss 0.19473223388195038\n",
      "\n",
      "episode 8, val func loss 0.21229997277259827\n",
      "\n",
      "episode 9, val func loss 0.19656965136528015\n",
      "\n",
      "episode 10, val func loss 0.20803223550319672\n",
      "\n",
      "episode 11, val func loss 0.16038130223751068\n",
      "\n",
      "episode 12, val func loss 0.22584475576877594\n",
      "\n",
      "episode 13, val func loss 0.20858873426914215\n",
      "\n",
      "episode 14, val func loss 0.1905752271413803\n",
      "\n",
      "episode 15, val func loss 0.1860274225473404\n",
      "\n",
      "episode 16, val func loss 0.17941002547740936\n",
      "\n",
      "Val func train loss in epoch 15:0.19196610618382692\n",
      "***********************TIME WAS 4.912533656756083 min*****************************\n",
      "\n",
      "**********************ROUND 50 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.018019402399659157\n",
      "\n",
      "episode 2, policy loss 0.03350631520152092\n",
      "\n",
      "episode 3, policy loss -0.0015343445120379329\n",
      "\n",
      "episode 4, policy loss 0.026614200323820114\n",
      "\n",
      "episode 5, policy loss -0.0612449087202549\n",
      "\n",
      "episode 6, policy loss -0.00031885987846180797\n",
      "\n",
      "episode 7, policy loss 0.03285670652985573\n",
      "\n",
      "episode 8, policy loss -0.025187695398926735\n",
      "\n",
      "episode 9, policy loss 0.027248384431004524\n",
      "\n",
      "episode 10, policy loss 0.03118632547557354\n",
      "\n",
      "episode 11, policy loss 0.030569812282919884\n",
      "\n",
      "episode 12, policy loss -0.051126737147569656\n",
      "\n",
      "episode 13, policy loss -0.031361281871795654\n",
      "\n",
      "episode 14, policy loss -0.001007094862870872\n",
      "\n",
      "episode 15, policy loss -0.028424251824617386\n",
      "\n",
      "episode 16, policy loss 0.04669136181473732\n",
      "\n",
      "Policy train loss in epoch 0:0.0006530330902023707\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.0017394957831129432\n",
      "\n",
      "episode 2, policy loss 0.03343040496110916\n",
      "\n",
      "episode 3, policy loss -0.04957776516675949\n",
      "\n",
      "episode 4, policy loss 0.025364277884364128\n",
      "\n",
      "episode 5, policy loss -0.004459760617464781\n",
      "\n",
      "episode 6, policy loss 0.04370860010385513\n",
      "\n",
      "episode 7, policy loss -0.015686793252825737\n",
      "\n",
      "episode 8, policy loss -0.026515545323491096\n",
      "\n",
      "episode 9, policy loss 0.03212728723883629\n",
      "\n",
      "episode 10, policy loss -0.020251229405403137\n",
      "\n",
      "episode 11, policy loss -0.031041748821735382\n",
      "\n",
      "episode 12, policy loss 0.03668277710676193\n",
      "\n",
      "episode 13, policy loss -0.06810316443443298\n",
      "\n",
      "episode 14, policy loss 0.03188520297408104\n",
      "\n",
      "episode 15, policy loss -0.0029773360583931208\n",
      "\n",
      "episode 16, policy loss 0.022901412099599838\n",
      "\n",
      "Policy train loss in epoch 1:0.000576632191950921\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.004097578581422567\n",
      "\n",
      "episode 2, policy loss -0.029667163267731667\n",
      "\n",
      "episode 3, policy loss -0.06986290216445923\n",
      "\n",
      "episode 4, policy loss 0.00370777933858335\n",
      "\n",
      "episode 5, policy loss 0.030227860435843468\n",
      "\n",
      "episode 6, policy loss 0.02456294372677803\n",
      "\n",
      "episode 7, policy loss -0.028946761041879654\n",
      "\n",
      "episode 8, policy loss -0.051178742200136185\n",
      "\n",
      "episode 9, policy loss -0.03195696696639061\n",
      "\n",
      "episode 10, policy loss 0.02776341140270233\n",
      "\n",
      "episode 11, policy loss 0.032006438821554184\n",
      "\n",
      "episode 12, policy loss 0.003024771809577942\n",
      "\n",
      "episode 13, policy loss -0.019264880567789078\n",
      "\n",
      "episode 14, policy loss 0.029384486377239227\n",
      "\n",
      "episode 15, policy loss 0.04257308691740036\n",
      "\n",
      "episode 16, policy loss 0.03321230039000511\n",
      "\n",
      "Policy train loss in epoch 2:-0.0005319947231328115\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.03138072416186333\n",
      "\n",
      "episode 2, policy loss -0.01726706512272358\n",
      "\n",
      "episode 3, policy loss -0.005046829115599394\n",
      "\n",
      "episode 4, policy loss 0.0318765714764595\n",
      "\n",
      "episode 5, policy loss 0.025762012228369713\n",
      "\n",
      "episode 6, policy loss -0.06386759877204895\n",
      "\n",
      "episode 7, policy loss -0.025975774973630905\n",
      "\n",
      "episode 8, policy loss -0.0018814064096659422\n",
      "\n",
      "episode 9, policy loss -0.02144315466284752\n",
      "\n",
      "episode 10, policy loss 0.0014568761689588428\n",
      "\n",
      "episode 11, policy loss 0.03407206013798714\n",
      "\n",
      "episode 12, policy loss 0.0322597399353981\n",
      "\n",
      "episode 13, policy loss 0.03136307746171951\n",
      "\n",
      "episode 14, policy loss 0.02433053031563759\n",
      "\n",
      "episode 15, policy loss -0.052310217171907425\n",
      "\n",
      "episode 16, policy loss 0.041657496243715286\n",
      "\n",
      "Policy train loss in epoch 3:0.00022534959862241521\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17307059466838837\n",
      "\n",
      "episode 2, val func loss 0.20142047107219696\n",
      "\n",
      "episode 3, val func loss 0.20763975381851196\n",
      "\n",
      "episode 4, val func loss 0.2079983651638031\n",
      "\n",
      "episode 5, val func loss 0.21620427072048187\n",
      "\n",
      "episode 6, val func loss 0.1631586104631424\n",
      "\n",
      "episode 7, val func loss 0.18570177257061005\n",
      "\n",
      "episode 8, val func loss 0.18598471581935883\n",
      "\n",
      "episode 9, val func loss 0.16700734198093414\n",
      "\n",
      "episode 10, val func loss 0.17296822369098663\n",
      "\n",
      "episode 11, val func loss 0.2171747386455536\n",
      "\n",
      "episode 12, val func loss 0.18892429769039154\n",
      "\n",
      "episode 13, val func loss 0.2128438800573349\n",
      "\n",
      "episode 14, val func loss 0.1600698083639145\n",
      "\n",
      "episode 15, val func loss 0.18337635695934296\n",
      "\n",
      "episode 16, val func loss 0.1839779019355774\n",
      "\n",
      "Val func train loss in epoch 0:0.18922006897628307\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.20746372640132904\n",
      "\n",
      "episode 2, val func loss 0.2014683037996292\n",
      "\n",
      "episode 3, val func loss 0.16933780908584595\n",
      "\n",
      "episode 4, val func loss 0.18575963377952576\n",
      "\n",
      "episode 5, val func loss 0.2153683602809906\n",
      "\n",
      "episode 6, val func loss 0.17507663369178772\n",
      "\n",
      "episode 7, val func loss 0.16851456463336945\n",
      "\n",
      "episode 8, val func loss 0.16415388882160187\n",
      "\n",
      "episode 9, val func loss 0.1839197874069214\n",
      "\n",
      "episode 10, val func loss 0.18809598684310913\n",
      "\n",
      "episode 11, val func loss 0.15988652408123016\n",
      "\n",
      "episode 12, val func loss 0.18298450112342834\n",
      "\n",
      "episode 13, val func loss 0.2135707288980484\n",
      "\n",
      "episode 14, val func loss 0.2107689529657364\n",
      "\n",
      "episode 15, val func loss 0.18570920825004578\n",
      "\n",
      "episode 16, val func loss 0.21668268740177155\n",
      "\n",
      "Val func train loss in epoch 1:0.18929758109152317\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.15988200902938843\n",
      "\n",
      "episode 2, val func loss 0.18333573639392853\n",
      "\n",
      "episode 3, val func loss 0.21290026605129242\n",
      "\n",
      "episode 4, val func loss 0.20199543237686157\n",
      "\n",
      "episode 5, val func loss 0.1882413774728775\n",
      "\n",
      "episode 6, val func loss 0.17899559438228607\n",
      "\n",
      "episode 7, val func loss 0.17060397565364838\n",
      "\n",
      "episode 8, val func loss 0.21417377889156342\n",
      "\n",
      "episode 9, val func loss 0.21147260069847107\n",
      "\n",
      "episode 10, val func loss 0.16959549486637115\n",
      "\n",
      "episode 11, val func loss 0.2085006982088089\n",
      "\n",
      "episode 12, val func loss 0.18599145114421844\n",
      "\n",
      "episode 13, val func loss 0.1848202347755432\n",
      "\n",
      "episode 14, val func loss 0.1618710309267044\n",
      "\n",
      "episode 15, val func loss 0.20976902544498444\n",
      "\n",
      "episode 16, val func loss 0.1889730989933014\n",
      "\n",
      "Val func train loss in epoch 2:0.18944511283189058\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1830219030380249\n",
      "\n",
      "episode 2, val func loss 0.1863871067762375\n",
      "\n",
      "episode 3, val func loss 0.16823621094226837\n",
      "\n",
      "episode 4, val func loss 0.17312346398830414\n",
      "\n",
      "episode 5, val func loss 0.1842307448387146\n",
      "\n",
      "episode 6, val func loss 0.20849773287773132\n",
      "\n",
      "episode 7, val func loss 0.2082235962152481\n",
      "\n",
      "episode 8, val func loss 0.2134154587984085\n",
      "\n",
      "episode 9, val func loss 0.16227197647094727\n",
      "\n",
      "episode 10, val func loss 0.18857748806476593\n",
      "\n",
      "episode 11, val func loss 0.16714408993721008\n",
      "\n",
      "episode 12, val func loss 0.21144512295722961\n",
      "\n",
      "episode 13, val func loss 0.21491749584674835\n",
      "\n",
      "episode 14, val func loss 0.167843297123909\n",
      "\n",
      "episode 15, val func loss 0.1888791173696518\n",
      "\n",
      "episode 16, val func loss 0.20215986669063568\n",
      "\n",
      "Val func train loss in epoch 3:0.1892734169960022\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.20823943614959717\n",
      "\n",
      "episode 2, val func loss 0.18364031612873077\n",
      "\n",
      "episode 3, val func loss 0.21157336235046387\n",
      "\n",
      "episode 4, val func loss 0.18629810214042664\n",
      "\n",
      "episode 5, val func loss 0.16864421963691711\n",
      "\n",
      "episode 6, val func loss 0.2172127366065979\n",
      "\n",
      "episode 7, val func loss 0.17346742749214172\n",
      "\n",
      "episode 8, val func loss 0.18397898972034454\n",
      "\n",
      "episode 9, val func loss 0.21377356350421906\n",
      "\n",
      "episode 10, val func loss 0.18527618050575256\n",
      "\n",
      "episode 11, val func loss 0.1887752264738083\n",
      "\n",
      "episode 12, val func loss 0.20223340392112732\n",
      "\n",
      "episode 13, val func loss 0.16610932350158691\n",
      "\n",
      "episode 14, val func loss 0.2077876478433609\n",
      "\n",
      "episode 15, val func loss 0.16883344948291779\n",
      "\n",
      "episode 16, val func loss 0.16121074557304382\n",
      "\n",
      "Val func train loss in epoch 4:0.18919088318943977\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.16258443892002106\n",
      "\n",
      "episode 2, val func loss 0.1727597862482071\n",
      "\n",
      "episode 3, val func loss 0.21121081709861755\n",
      "\n",
      "episode 4, val func loss 0.22025859355926514\n",
      "\n",
      "episode 5, val func loss 0.18950113654136658\n",
      "\n",
      "episode 6, val func loss 0.18548865616321564\n",
      "\n",
      "episode 7, val func loss 0.18386590480804443\n",
      "\n",
      "episode 8, val func loss 0.18554601073265076\n",
      "\n",
      "episode 9, val func loss 0.16989149153232574\n",
      "\n",
      "episode 10, val func loss 0.20747137069702148\n",
      "\n",
      "episode 11, val func loss 0.21150095760822296\n",
      "\n",
      "episode 12, val func loss 0.18552984297275543\n",
      "\n",
      "episode 13, val func loss 0.16173338890075684\n",
      "\n",
      "episode 14, val func loss 0.2152329981327057\n",
      "\n",
      "episode 15, val func loss 0.16753393411636353\n",
      "\n",
      "episode 16, val func loss 0.20165739953517914\n",
      "\n",
      "Val func train loss in epoch 5:0.18948542047291994\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18638892471790314\n",
      "\n",
      "episode 2, val func loss 0.21412837505340576\n",
      "\n",
      "episode 3, val func loss 0.183692067861557\n",
      "\n",
      "episode 4, val func loss 0.18842245638370514\n",
      "\n",
      "episode 5, val func loss 0.20758633315563202\n",
      "\n",
      "episode 6, val func loss 0.17022790014743805\n",
      "\n",
      "episode 7, val func loss 0.20808763802051544\n",
      "\n",
      "episode 8, val func loss 0.1860807090997696\n",
      "\n",
      "episode 9, val func loss 0.21546617150306702\n",
      "\n",
      "episode 10, val func loss 0.18433420360088348\n",
      "\n",
      "episode 11, val func loss 0.16757337749004364\n",
      "\n",
      "episode 12, val func loss 0.17479778826236725\n",
      "\n",
      "episode 13, val func loss 0.2117328643798828\n",
      "\n",
      "episode 14, val func loss 0.16026614606380463\n",
      "\n",
      "episode 15, val func loss 0.20317970216274261\n",
      "\n",
      "episode 16, val func loss 0.16223396360874176\n",
      "\n",
      "Val func train loss in epoch 6:0.1890124138444662\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18400059640407562\n",
      "\n",
      "episode 2, val func loss 0.20392516255378723\n",
      "\n",
      "episode 3, val func loss 0.2164304554462433\n",
      "\n",
      "episode 4, val func loss 0.20787064731121063\n",
      "\n",
      "episode 5, val func loss 0.17069213092327118\n",
      "\n",
      "episode 6, val func loss 0.20742981135845184\n",
      "\n",
      "episode 7, val func loss 0.18622121214866638\n",
      "\n",
      "episode 8, val func loss 0.18921680748462677\n",
      "\n",
      "episode 9, val func loss 0.18816065788269043\n",
      "\n",
      "episode 10, val func loss 0.16558578610420227\n",
      "\n",
      "episode 11, val func loss 0.21170206367969513\n",
      "\n",
      "episode 12, val func loss 0.18356220424175262\n",
      "\n",
      "episode 13, val func loss 0.16656190156936646\n",
      "\n",
      "episode 14, val func loss 0.15953412652015686\n",
      "\n",
      "episode 15, val func loss 0.17310789227485657\n",
      "\n",
      "episode 16, val func loss 0.22397130727767944\n",
      "\n",
      "Val func train loss in epoch 7:0.1898732976987958\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.2154647260904312\n",
      "\n",
      "episode 2, val func loss 0.21016423404216766\n",
      "\n",
      "episode 3, val func loss 0.20848432183265686\n",
      "\n",
      "episode 4, val func loss 0.2156325876712799\n",
      "\n",
      "episode 5, val func loss 0.19022606313228607\n",
      "\n",
      "episode 6, val func loss 0.18999537825584412\n",
      "\n",
      "episode 7, val func loss 0.17963552474975586\n",
      "\n",
      "episode 8, val func loss 0.18954232335090637\n",
      "\n",
      "episode 9, val func loss 0.18354421854019165\n",
      "\n",
      "episode 10, val func loss 0.1642102748155594\n",
      "\n",
      "episode 11, val func loss 0.1598157435655594\n",
      "\n",
      "episode 12, val func loss 0.16832013428211212\n",
      "\n",
      "episode 13, val func loss 0.1878969669342041\n",
      "\n",
      "episode 14, val func loss 0.16711178421974182\n",
      "\n",
      "episode 15, val func loss 0.20746512711048126\n",
      "\n",
      "episode 16, val func loss 0.21933278441429138\n",
      "\n",
      "Val func train loss in epoch 8:0.19105263706296682\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.2117392122745514\n",
      "\n",
      "episode 2, val func loss 0.18114495277404785\n",
      "\n",
      "episode 3, val func loss 0.2082018256187439\n",
      "\n",
      "episode 4, val func loss 0.2160285860300064\n",
      "\n",
      "episode 5, val func loss 0.21492592990398407\n",
      "\n",
      "episode 6, val func loss 0.16360145807266235\n",
      "\n",
      "episode 7, val func loss 0.1838606297969818\n",
      "\n",
      "episode 8, val func loss 0.18801555037498474\n",
      "\n",
      "episode 9, val func loss 0.17412598431110382\n",
      "\n",
      "episode 10, val func loss 0.2075609415769577\n",
      "\n",
      "episode 11, val func loss 0.20183324813842773\n",
      "\n",
      "episode 12, val func loss 0.16765563189983368\n",
      "\n",
      "episode 13, val func loss 0.16022706031799316\n",
      "\n",
      "episode 14, val func loss 0.18536557257175446\n",
      "\n",
      "episode 15, val func loss 0.1833726465702057\n",
      "\n",
      "episode 16, val func loss 0.18591128289699554\n",
      "\n",
      "Val func train loss in epoch 9:0.18959815707057714\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20849888026714325\n",
      "\n",
      "episode 2, val func loss 0.18874475359916687\n",
      "\n",
      "episode 3, val func loss 0.1625104397535324\n",
      "\n",
      "episode 4, val func loss 0.21290768682956696\n",
      "\n",
      "episode 5, val func loss 0.16886062920093536\n",
      "\n",
      "episode 6, val func loss 0.20884883403778076\n",
      "\n",
      "episode 7, val func loss 0.16679371893405914\n",
      "\n",
      "episode 8, val func loss 0.18587100505828857\n",
      "\n",
      "episode 9, val func loss 0.15948258340358734\n",
      "\n",
      "episode 10, val func loss 0.20235823094844818\n",
      "\n",
      "episode 11, val func loss 0.1734461933374405\n",
      "\n",
      "episode 12, val func loss 0.1838274896144867\n",
      "\n",
      "episode 13, val func loss 0.21475961804389954\n",
      "\n",
      "episode 14, val func loss 0.2154565453529358\n",
      "\n",
      "episode 15, val func loss 0.18507061898708344\n",
      "\n",
      "episode 16, val func loss 0.18640819191932678\n",
      "\n",
      "Val func train loss in epoch 10:0.1889903387054801\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.21166187524795532\n",
      "\n",
      "episode 2, val func loss 0.1665641963481903\n",
      "\n",
      "episode 3, val func loss 0.18927164375782013\n",
      "\n",
      "episode 4, val func loss 0.1680651605129242\n",
      "\n",
      "episode 5, val func loss 0.21402059495449066\n",
      "\n",
      "episode 6, val func loss 0.16026543080806732\n",
      "\n",
      "episode 7, val func loss 0.183942049741745\n",
      "\n",
      "episode 8, val func loss 0.18581382930278778\n",
      "\n",
      "episode 9, val func loss 0.18491822481155396\n",
      "\n",
      "episode 10, val func loss 0.17224423587322235\n",
      "\n",
      "episode 11, val func loss 0.1873261034488678\n",
      "\n",
      "episode 12, val func loss 0.22035108506679535\n",
      "\n",
      "episode 13, val func loss 0.2092028111219406\n",
      "\n",
      "episode 14, val func loss 0.20175768435001373\n",
      "\n",
      "episode 15, val func loss 0.20768149197101593\n",
      "\n",
      "episode 16, val func loss 0.17284761369228363\n",
      "\n",
      "Val func train loss in epoch 11:0.18974587693810463\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.20152002573013306\n",
      "\n",
      "episode 2, val func loss 0.18428492546081543\n",
      "\n",
      "episode 3, val func loss 0.21340914070606232\n",
      "\n",
      "episode 4, val func loss 0.21216270327568054\n",
      "\n",
      "episode 5, val func loss 0.16326536238193512\n",
      "\n",
      "episode 6, val func loss 0.18621481955051422\n",
      "\n",
      "episode 7, val func loss 0.21196593344211578\n",
      "\n",
      "episode 8, val func loss 0.2074645608663559\n",
      "\n",
      "episode 9, val func loss 0.2077607363462448\n",
      "\n",
      "episode 10, val func loss 0.1670631319284439\n",
      "\n",
      "episode 11, val func loss 0.1694895178079605\n",
      "\n",
      "episode 12, val func loss 0.18643654882907867\n",
      "\n",
      "episode 13, val func loss 0.17315641045570374\n",
      "\n",
      "episode 14, val func loss 0.1855241358280182\n",
      "\n",
      "episode 15, val func loss 0.16203874349594116\n",
      "\n",
      "episode 16, val func loss 0.18951353430747986\n",
      "\n",
      "Val func train loss in epoch 12:0.1888293894007802\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1873074620962143\n",
      "\n",
      "episode 2, val func loss 0.21103501319885254\n",
      "\n",
      "episode 3, val func loss 0.2043505609035492\n",
      "\n",
      "episode 4, val func loss 0.21518836915493011\n",
      "\n",
      "episode 5, val func loss 0.2115732729434967\n",
      "\n",
      "episode 6, val func loss 0.18671250343322754\n",
      "\n",
      "episode 7, val func loss 0.184326633810997\n",
      "\n",
      "episode 8, val func loss 0.21340863406658173\n",
      "\n",
      "episode 9, val func loss 0.17081603407859802\n",
      "\n",
      "episode 10, val func loss 0.20904093980789185\n",
      "\n",
      "episode 11, val func loss 0.16320785880088806\n",
      "\n",
      "episode 12, val func loss 0.1872718632221222\n",
      "\n",
      "episode 13, val func loss 0.16949672996997833\n",
      "\n",
      "episode 14, val func loss 0.17321130633354187\n",
      "\n",
      "episode 15, val func loss 0.16711094975471497\n",
      "\n",
      "episode 16, val func loss 0.19208180904388428\n",
      "\n",
      "Val func train loss in epoch 13:0.1903837462887168\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18408145010471344\n",
      "\n",
      "episode 2, val func loss 0.16904820501804352\n",
      "\n",
      "episode 3, val func loss 0.1601586639881134\n",
      "\n",
      "episode 4, val func loss 0.21129539608955383\n",
      "\n",
      "episode 5, val func loss 0.1889733076095581\n",
      "\n",
      "episode 6, val func loss 0.20888866484165192\n",
      "\n",
      "episode 7, val func loss 0.20154105126857758\n",
      "\n",
      "episode 8, val func loss 0.2113322764635086\n",
      "\n",
      "episode 9, val func loss 0.19191914796829224\n",
      "\n",
      "episode 10, val func loss 0.19532017409801483\n",
      "\n",
      "episode 11, val func loss 0.1860925853252411\n",
      "\n",
      "episode 12, val func loss 0.16978415846824646\n",
      "\n",
      "episode 13, val func loss 0.21156293153762817\n",
      "\n",
      "episode 14, val func loss 0.16253270208835602\n",
      "\n",
      "episode 15, val func loss 0.22192895412445068\n",
      "\n",
      "episode 16, val func loss 0.17299240827560425\n",
      "\n",
      "Val func train loss in epoch 14:0.19046575482934713\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20514804124832153\n",
      "\n",
      "episode 2, val func loss 0.20914676785469055\n",
      "\n",
      "episode 3, val func loss 0.17426051199436188\n",
      "\n",
      "episode 4, val func loss 0.16709280014038086\n",
      "\n",
      "episode 5, val func loss 0.2154759168624878\n",
      "\n",
      "episode 6, val func loss 0.1687413454055786\n",
      "\n",
      "episode 7, val func loss 0.18875867128372192\n",
      "\n",
      "episode 8, val func loss 0.2117222547531128\n",
      "\n",
      "episode 9, val func loss 0.16100279986858368\n",
      "\n",
      "episode 10, val func loss 0.18577530980110168\n",
      "\n",
      "episode 11, val func loss 0.21558178961277008\n",
      "\n",
      "episode 12, val func loss 0.1833217442035675\n",
      "\n",
      "episode 13, val func loss 0.16529498994350433\n",
      "\n",
      "episode 14, val func loss 0.18431028723716736\n",
      "\n",
      "episode 15, val func loss 0.20704466104507446\n",
      "\n",
      "episode 16, val func loss 0.18609203398227692\n",
      "\n",
      "Val func train loss in epoch 15:0.18929812032729387\n",
      "***********************TIME WAS 4.912560975551605 min*****************************\n",
      "\n",
      "**********************ROUND 51 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.05447525531053543\n",
      "\n",
      "episode 2, policy loss -0.044617049396038055\n",
      "\n",
      "episode 3, policy loss -0.04057161509990692\n",
      "\n",
      "episode 4, policy loss -0.04143952950835228\n",
      "\n",
      "episode 5, policy loss -0.054470546543598175\n",
      "\n",
      "episode 6, policy loss -0.0182022862136364\n",
      "\n",
      "episode 7, policy loss -0.015639137476682663\n",
      "\n",
      "episode 8, policy loss -0.039468295872211456\n",
      "\n",
      "episode 9, policy loss -0.07289434224367142\n",
      "\n",
      "episode 10, policy loss -0.0008556704851798713\n",
      "\n",
      "episode 11, policy loss -0.05840793624520302\n",
      "\n",
      "episode 12, policy loss -0.01400192640721798\n",
      "\n",
      "episode 13, policy loss 0.0038008911069482565\n",
      "\n",
      "episode 14, policy loss -0.08115168660879135\n",
      "\n",
      "episode 15, policy loss -0.10075059533119202\n",
      "\n",
      "episode 16, policy loss -0.0806407779455185\n",
      "\n",
      "Policy train loss in epoch 0:-0.044611609973799204\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.04742753878235817\n",
      "\n",
      "episode 2, policy loss -0.05995427072048187\n",
      "\n",
      "episode 3, policy loss -0.09780629724264145\n",
      "\n",
      "episode 4, policy loss -0.039654262363910675\n",
      "\n",
      "episode 5, policy loss -0.06484583020210266\n",
      "\n",
      "episode 6, policy loss -0.04270488768815994\n",
      "\n",
      "episode 7, policy loss 0.006264238152652979\n",
      "\n",
      "episode 8, policy loss -0.010748670436441898\n",
      "\n",
      "episode 9, policy loss -0.07151809334754944\n",
      "\n",
      "episode 10, policy loss -0.08213178813457489\n",
      "\n",
      "episode 11, policy loss -0.08136418461799622\n",
      "\n",
      "episode 12, policy loss -0.0008656831923872232\n",
      "\n",
      "episode 13, policy loss -0.059879254549741745\n",
      "\n",
      "episode 14, policy loss -0.019559603184461594\n",
      "\n",
      "episode 15, policy loss -0.014675733633339405\n",
      "\n",
      "episode 16, policy loss -0.039168667048215866\n",
      "\n",
      "Policy train loss in epoch 1:-0.04537753293698188\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.04453640803694725\n",
      "\n",
      "episode 2, policy loss -0.021661939099431038\n",
      "\n",
      "episode 3, policy loss -0.09931875765323639\n",
      "\n",
      "episode 4, policy loss -0.06472937762737274\n",
      "\n",
      "episode 5, policy loss -0.08091998100280762\n",
      "\n",
      "episode 6, policy loss -0.04628743976354599\n",
      "\n",
      "episode 7, policy loss -0.07273247092962265\n",
      "\n",
      "episode 8, policy loss -0.013403384946286678\n",
      "\n",
      "episode 9, policy loss -0.08219806849956512\n",
      "\n",
      "episode 10, policy loss -0.0017816207837313414\n",
      "\n",
      "episode 11, policy loss -0.017145957797765732\n",
      "\n",
      "episode 12, policy loss -0.059182170778512955\n",
      "\n",
      "episode 13, policy loss -0.06670013815164566\n",
      "\n",
      "episode 14, policy loss -0.039759472012519836\n",
      "\n",
      "episode 15, policy loss -0.038826048374176025\n",
      "\n",
      "episode 16, policy loss 0.004928052891045809\n",
      "\n",
      "Policy train loss in epoch 2:-0.046515948910382576\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.04287245497107506\n",
      "\n",
      "episode 2, policy loss 0.003939483780413866\n",
      "\n",
      "episode 3, policy loss -0.014858822338283062\n",
      "\n",
      "episode 4, policy loss -0.06335936486721039\n",
      "\n",
      "episode 5, policy loss -0.0006547869415953755\n",
      "\n",
      "episode 6, policy loss -0.014571649953722954\n",
      "\n",
      "episode 7, policy loss -0.07152548432350159\n",
      "\n",
      "episode 8, policy loss -0.0795690193772316\n",
      "\n",
      "episode 9, policy loss -0.02137940563261509\n",
      "\n",
      "episode 10, policy loss -0.10171625018119812\n",
      "\n",
      "episode 11, policy loss -0.05639348179101944\n",
      "\n",
      "episode 12, policy loss -0.08301474899053574\n",
      "\n",
      "episode 13, policy loss -0.03959709778428078\n",
      "\n",
      "episode 14, policy loss -0.04760447144508362\n",
      "\n",
      "episode 15, policy loss -0.06390762329101562\n",
      "\n",
      "episode 16, policy loss -0.03844758868217468\n",
      "\n",
      "Policy train loss in epoch 3:-0.04597079792438308\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.20209772884845734\n",
      "\n",
      "episode 2, val func loss 0.1932353973388672\n",
      "\n",
      "episode 3, val func loss 0.20136383175849915\n",
      "\n",
      "episode 4, val func loss 0.16736766695976257\n",
      "\n",
      "episode 5, val func loss 0.17247703671455383\n",
      "\n",
      "episode 6, val func loss 0.19238725304603577\n",
      "\n",
      "episode 7, val func loss 0.17363262176513672\n",
      "\n",
      "episode 8, val func loss 0.17468959093093872\n",
      "\n",
      "episode 9, val func loss 0.2035542130470276\n",
      "\n",
      "episode 10, val func loss 0.23731862008571625\n",
      "\n",
      "episode 11, val func loss 0.19818833470344543\n",
      "\n",
      "episode 12, val func loss 0.17435546219348907\n",
      "\n",
      "episode 13, val func loss 0.20790518820285797\n",
      "\n",
      "episode 14, val func loss 0.18574200570583344\n",
      "\n",
      "episode 15, val func loss 0.2026611715555191\n",
      "\n",
      "episode 16, val func loss 0.22280417382717133\n",
      "\n",
      "Val func train loss in epoch 0:0.19436126854270697\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18775969743728638\n",
      "\n",
      "episode 2, val func loss 0.17588497698307037\n",
      "\n",
      "episode 3, val func loss 0.19415593147277832\n",
      "\n",
      "episode 4, val func loss 0.20702910423278809\n",
      "\n",
      "episode 5, val func loss 0.17532071471214294\n",
      "\n",
      "episode 6, val func loss 0.19266726076602936\n",
      "\n",
      "episode 7, val func loss 0.16719508171081543\n",
      "\n",
      "episode 8, val func loss 0.20284457504749298\n",
      "\n",
      "episode 9, val func loss 0.2024887353181839\n",
      "\n",
      "episode 10, val func loss 0.20295177400112152\n",
      "\n",
      "episode 11, val func loss 0.23758648335933685\n",
      "\n",
      "episode 12, val func loss 0.2034902125597\n",
      "\n",
      "episode 13, val func loss 0.19708915054798126\n",
      "\n",
      "episode 14, val func loss 0.22220569849014282\n",
      "\n",
      "episode 15, val func loss 0.1775340586900711\n",
      "\n",
      "episode 16, val func loss 0.1772836148738861\n",
      "\n",
      "Val func train loss in epoch 1:0.19521794188767672\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1771979182958603\n",
      "\n",
      "episode 2, val func loss 0.17427131533622742\n",
      "\n",
      "episode 3, val func loss 0.20111528038978577\n",
      "\n",
      "episode 4, val func loss 0.17458924651145935\n",
      "\n",
      "episode 5, val func loss 0.19246821105480194\n",
      "\n",
      "episode 6, val func loss 0.22900870442390442\n",
      "\n",
      "episode 7, val func loss 0.20365957915782928\n",
      "\n",
      "episode 8, val func loss 0.1866038739681244\n",
      "\n",
      "episode 9, val func loss 0.20850366353988647\n",
      "\n",
      "episode 10, val func loss 0.16732731461524963\n",
      "\n",
      "episode 11, val func loss 0.17482122778892517\n",
      "\n",
      "episode 12, val func loss 0.19938993453979492\n",
      "\n",
      "episode 13, val func loss 0.20436780154705048\n",
      "\n",
      "episode 14, val func loss 0.1935478150844574\n",
      "\n",
      "episode 15, val func loss 0.19771257042884827\n",
      "\n",
      "episode 16, val func loss 0.2364589124917984\n",
      "\n",
      "Val func train loss in epoch 2:0.19506521057337523\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.17454543709754944\n",
      "\n",
      "episode 2, val func loss 0.20339275896549225\n",
      "\n",
      "episode 3, val func loss 0.1665692925453186\n",
      "\n",
      "episode 4, val func loss 0.20430026948451996\n",
      "\n",
      "episode 5, val func loss 0.20964054763317108\n",
      "\n",
      "episode 6, val func loss 0.22512316703796387\n",
      "\n",
      "episode 7, val func loss 0.1992928683757782\n",
      "\n",
      "episode 8, val func loss 0.1773948222398758\n",
      "\n",
      "episode 9, val func loss 0.19528721272945404\n",
      "\n",
      "episode 10, val func loss 0.19750095903873444\n",
      "\n",
      "episode 11, val func loss 0.17733106017112732\n",
      "\n",
      "episode 12, val func loss 0.18696445226669312\n",
      "\n",
      "episode 13, val func loss 0.23777785897254944\n",
      "\n",
      "episode 14, val func loss 0.193115234375\n",
      "\n",
      "episode 15, val func loss 0.17472940683364868\n",
      "\n",
      "episode 16, val func loss 0.2018374353647232\n",
      "\n",
      "Val func train loss in epoch 3:0.19530017394572496\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17438459396362305\n",
      "\n",
      "episode 2, val func loss 0.19285202026367188\n",
      "\n",
      "episode 3, val func loss 0.2076883763074875\n",
      "\n",
      "episode 4, val func loss 0.19693399965763092\n",
      "\n",
      "episode 5, val func loss 0.18682262301445007\n",
      "\n",
      "episode 6, val func loss 0.20429754257202148\n",
      "\n",
      "episode 7, val func loss 0.22281476855278015\n",
      "\n",
      "episode 8, val func loss 0.17403197288513184\n",
      "\n",
      "episode 9, val func loss 0.2357787936925888\n",
      "\n",
      "episode 10, val func loss 0.2006959319114685\n",
      "\n",
      "episode 11, val func loss 0.16836635768413544\n",
      "\n",
      "episode 12, val func loss 0.19271379709243774\n",
      "\n",
      "episode 13, val func loss 0.20090855658054352\n",
      "\n",
      "episode 14, val func loss 0.17502938210964203\n",
      "\n",
      "episode 15, val func loss 0.20230455696582794\n",
      "\n",
      "episode 16, val func loss 0.17432530224323273\n",
      "\n",
      "Val func train loss in epoch 4:0.1943717859685421\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17177538573741913\n",
      "\n",
      "episode 2, val func loss 0.19271531701087952\n",
      "\n",
      "episode 3, val func loss 0.20352494716644287\n",
      "\n",
      "episode 4, val func loss 0.2022005021572113\n",
      "\n",
      "episode 5, val func loss 0.17442390322685242\n",
      "\n",
      "episode 6, val func loss 0.1924859583377838\n",
      "\n",
      "episode 7, val func loss 0.20423634350299835\n",
      "\n",
      "episode 8, val func loss 0.22322097420692444\n",
      "\n",
      "episode 9, val func loss 0.20657232403755188\n",
      "\n",
      "episode 10, val func loss 0.2021532952785492\n",
      "\n",
      "episode 11, val func loss 0.19722822308540344\n",
      "\n",
      "episode 12, val func loss 0.2363591492176056\n",
      "\n",
      "episode 13, val func loss 0.17027106881141663\n",
      "\n",
      "episode 14, val func loss 0.18696337938308716\n",
      "\n",
      "episode 15, val func loss 0.17620371282100677\n",
      "\n",
      "episode 16, val func loss 0.17300963401794434\n",
      "\n",
      "Val func train loss in epoch 5:0.1945840073749423\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.24075740575790405\n",
      "\n",
      "episode 2, val func loss 0.20148466527462006\n",
      "\n",
      "episode 3, val func loss 0.19335858523845673\n",
      "\n",
      "episode 4, val func loss 0.2017788290977478\n",
      "\n",
      "episode 5, val func loss 0.20168209075927734\n",
      "\n",
      "episode 6, val func loss 0.22238965332508087\n",
      "\n",
      "episode 7, val func loss 0.1945592314004898\n",
      "\n",
      "episode 8, val func loss 0.2064685821533203\n",
      "\n",
      "episode 9, val func loss 0.202043354511261\n",
      "\n",
      "episode 10, val func loss 0.1893782913684845\n",
      "\n",
      "episode 11, val func loss 0.1773492991924286\n",
      "\n",
      "episode 12, val func loss 0.17480552196502686\n",
      "\n",
      "episode 13, val func loss 0.16837194561958313\n",
      "\n",
      "episode 14, val func loss 0.17171788215637207\n",
      "\n",
      "episode 15, val func loss 0.20425668358802795\n",
      "\n",
      "episode 16, val func loss 0.17342764139175415\n",
      "\n",
      "Val func train loss in epoch 6:0.1952393539249897\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.20385871827602386\n",
      "\n",
      "episode 2, val func loss 0.1750214844942093\n",
      "\n",
      "episode 3, val func loss 0.22523196041584015\n",
      "\n",
      "episode 4, val func loss 0.2011406570672989\n",
      "\n",
      "episode 5, val func loss 0.20650115609169006\n",
      "\n",
      "episode 6, val func loss 0.17700627446174622\n",
      "\n",
      "episode 7, val func loss 0.19374358654022217\n",
      "\n",
      "episode 8, val func loss 0.19925980269908905\n",
      "\n",
      "episode 9, val func loss 0.1868578940629959\n",
      "\n",
      "episode 10, val func loss 0.19329942762851715\n",
      "\n",
      "episode 11, val func loss 0.19727873802185059\n",
      "\n",
      "episode 12, val func loss 0.16762188076972961\n",
      "\n",
      "episode 13, val func loss 0.2369755357503891\n",
      "\n",
      "episode 14, val func loss 0.1740567684173584\n",
      "\n",
      "episode 15, val func loss 0.17132404446601868\n",
      "\n",
      "episode 16, val func loss 0.20299884676933289\n",
      "\n",
      "Val func train loss in epoch 7:0.1945110484957695\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.22636938095092773\n",
      "\n",
      "episode 2, val func loss 0.17433059215545654\n",
      "\n",
      "episode 3, val func loss 0.23605632781982422\n",
      "\n",
      "episode 4, val func loss 0.19894731044769287\n",
      "\n",
      "episode 5, val func loss 0.1972755342721939\n",
      "\n",
      "episode 6, val func loss 0.16995443403720856\n",
      "\n",
      "episode 7, val func loss 0.18778793513774872\n",
      "\n",
      "episode 8, val func loss 0.1751849353313446\n",
      "\n",
      "episode 9, val func loss 0.2010958343744278\n",
      "\n",
      "episode 10, val func loss 0.20206932723522186\n",
      "\n",
      "episode 11, val func loss 0.17499583959579468\n",
      "\n",
      "episode 12, val func loss 0.204071044921875\n",
      "\n",
      "episode 13, val func loss 0.19314609467983246\n",
      "\n",
      "episode 14, val func loss 0.21012765169143677\n",
      "\n",
      "episode 15, val func loss 0.17303206026554108\n",
      "\n",
      "episode 16, val func loss 0.19284306466579437\n",
      "\n",
      "Val func train loss in epoch 8:0.19483046047389507\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.2010156363248825\n",
      "\n",
      "episode 2, val func loss 0.2239338904619217\n",
      "\n",
      "episode 3, val func loss 0.18690329790115356\n",
      "\n",
      "episode 4, val func loss 0.17629018425941467\n",
      "\n",
      "episode 5, val func loss 0.20103219151496887\n",
      "\n",
      "episode 6, val func loss 0.1768665313720703\n",
      "\n",
      "episode 7, val func loss 0.19287697970867157\n",
      "\n",
      "episode 8, val func loss 0.20386984944343567\n",
      "\n",
      "episode 9, val func loss 0.23631995916366577\n",
      "\n",
      "episode 10, val func loss 0.16710981726646423\n",
      "\n",
      "episode 11, val func loss 0.19819073379039764\n",
      "\n",
      "episode 12, val func loss 0.17427538335323334\n",
      "\n",
      "episode 13, val func loss 0.20307657122612\n",
      "\n",
      "episode 14, val func loss 0.20914140343666077\n",
      "\n",
      "episode 15, val func loss 0.193113312125206\n",
      "\n",
      "episode 16, val func loss 0.17235782742500305\n",
      "\n",
      "Val func train loss in epoch 9:0.19477334804832935\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.17241652309894562\n",
      "\n",
      "episode 2, val func loss 0.20784515142440796\n",
      "\n",
      "episode 3, val func loss 0.17394937574863434\n",
      "\n",
      "episode 4, val func loss 0.203944131731987\n",
      "\n",
      "episode 5, val func loss 0.2019944041967392\n",
      "\n",
      "episode 6, val func loss 0.17490947246551514\n",
      "\n",
      "episode 7, val func loss 0.20113015174865723\n",
      "\n",
      "episode 8, val func loss 0.19285444915294647\n",
      "\n",
      "episode 9, val func loss 0.20164942741394043\n",
      "\n",
      "episode 10, val func loss 0.22270244359970093\n",
      "\n",
      "episode 11, val func loss 0.1973174810409546\n",
      "\n",
      "episode 12, val func loss 0.17027990520000458\n",
      "\n",
      "episode 13, val func loss 0.17863602936267853\n",
      "\n",
      "episode 14, val func loss 0.19398300349712372\n",
      "\n",
      "episode 15, val func loss 0.18679699301719666\n",
      "\n",
      "episode 16, val func loss 0.2367936670780182\n",
      "\n",
      "Val func train loss in epoch 10:0.19482516311109066\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.2035083770751953\n",
      "\n",
      "episode 2, val func loss 0.1730668991804123\n",
      "\n",
      "episode 3, val func loss 0.23783442378044128\n",
      "\n",
      "episode 4, val func loss 0.1865813285112381\n",
      "\n",
      "episode 5, val func loss 0.17086154222488403\n",
      "\n",
      "episode 6, val func loss 0.20362792909145355\n",
      "\n",
      "episode 7, val func loss 0.20344780385494232\n",
      "\n",
      "episode 8, val func loss 0.16704131662845612\n",
      "\n",
      "episode 9, val func loss 0.2240581065416336\n",
      "\n",
      "episode 10, val func loss 0.19255304336547852\n",
      "\n",
      "episode 11, val func loss 0.20045410096645355\n",
      "\n",
      "episode 12, val func loss 0.19730497896671295\n",
      "\n",
      "episode 13, val func loss 0.20647238194942474\n",
      "\n",
      "episode 14, val func loss 0.19549013674259186\n",
      "\n",
      "episode 15, val func loss 0.17842857539653778\n",
      "\n",
      "episode 16, val func loss 0.17650385200977325\n",
      "\n",
      "Val func train loss in epoch 11:0.19482717476785183\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17300079762935638\n",
      "\n",
      "episode 2, val func loss 0.17441314458847046\n",
      "\n",
      "episode 3, val func loss 0.20052219927310944\n",
      "\n",
      "episode 4, val func loss 0.18799526989459991\n",
      "\n",
      "episode 5, val func loss 0.17568475008010864\n",
      "\n",
      "episode 6, val func loss 0.20576530694961548\n",
      "\n",
      "episode 7, val func loss 0.20952966809272766\n",
      "\n",
      "episode 8, val func loss 0.2017841935157776\n",
      "\n",
      "episode 9, val func loss 0.20417454838752747\n",
      "\n",
      "episode 10, val func loss 0.17657391726970673\n",
      "\n",
      "episode 11, val func loss 0.19414938986301422\n",
      "\n",
      "episode 12, val func loss 0.22180503606796265\n",
      "\n",
      "episode 13, val func loss 0.2031000852584839\n",
      "\n",
      "episode 14, val func loss 0.169727623462677\n",
      "\n",
      "episode 15, val func loss 0.23595577478408813\n",
      "\n",
      "episode 16, val func loss 0.192339688539505\n",
      "\n",
      "Val func train loss in epoch 12:0.19540758710354567\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.16701707243919373\n",
      "\n",
      "episode 2, val func loss 0.20623493194580078\n",
      "\n",
      "episode 3, val func loss 0.174502432346344\n",
      "\n",
      "episode 4, val func loss 0.1868661344051361\n",
      "\n",
      "episode 5, val func loss 0.17228172719478607\n",
      "\n",
      "episode 6, val func loss 0.20427025854587555\n",
      "\n",
      "episode 7, val func loss 0.19741497933864594\n",
      "\n",
      "episode 8, val func loss 0.17527498304843903\n",
      "\n",
      "episode 9, val func loss 0.23649147152900696\n",
      "\n",
      "episode 10, val func loss 0.20033670961856842\n",
      "\n",
      "episode 11, val func loss 0.20761336386203766\n",
      "\n",
      "episode 12, val func loss 0.1753501445055008\n",
      "\n",
      "episode 13, val func loss 0.20110125839710236\n",
      "\n",
      "episode 14, val func loss 0.19277270138263702\n",
      "\n",
      "episode 15, val func loss 0.22209793329238892\n",
      "\n",
      "episode 16, val func loss 0.19333148002624512\n",
      "\n",
      "Val func train loss in epoch 13:0.19455984886735678\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.20138877630233765\n",
      "\n",
      "episode 2, val func loss 0.23623454570770264\n",
      "\n",
      "episode 3, val func loss 0.20669971406459808\n",
      "\n",
      "episode 4, val func loss 0.1988700032234192\n",
      "\n",
      "episode 5, val func loss 0.19335055351257324\n",
      "\n",
      "episode 6, val func loss 0.1934054046869278\n",
      "\n",
      "episode 7, val func loss 0.18679459393024445\n",
      "\n",
      "episode 8, val func loss 0.20213808119297028\n",
      "\n",
      "episode 9, val func loss 0.17212241888046265\n",
      "\n",
      "episode 10, val func loss 0.16627593338489532\n",
      "\n",
      "episode 11, val func loss 0.23007498681545258\n",
      "\n",
      "episode 12, val func loss 0.17480477690696716\n",
      "\n",
      "episode 13, val func loss 0.17389772832393646\n",
      "\n",
      "episode 14, val func loss 0.19772869348526\n",
      "\n",
      "episode 15, val func loss 0.20419585704803467\n",
      "\n",
      "episode 16, val func loss 0.17534984648227692\n",
      "\n",
      "Val func train loss in epoch 14:0.1945832446217537\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1753561645746231\n",
      "\n",
      "episode 2, val func loss 0.1674642562866211\n",
      "\n",
      "episode 3, val func loss 0.17282576858997345\n",
      "\n",
      "episode 4, val func loss 0.23299874365329742\n",
      "\n",
      "episode 5, val func loss 0.19343215227127075\n",
      "\n",
      "episode 6, val func loss 0.19730837643146515\n",
      "\n",
      "episode 7, val func loss 0.17293334007263184\n",
      "\n",
      "episode 8, val func loss 0.2021520435810089\n",
      "\n",
      "episode 9, val func loss 0.1928143948316574\n",
      "\n",
      "episode 10, val func loss 0.20682057738304138\n",
      "\n",
      "episode 11, val func loss 0.19933509826660156\n",
      "\n",
      "episode 12, val func loss 0.2047213912010193\n",
      "\n",
      "episode 13, val func loss 0.17643219232559204\n",
      "\n",
      "episode 14, val func loss 0.2011856883764267\n",
      "\n",
      "episode 15, val func loss 0.186732217669487\n",
      "\n",
      "episode 16, val func loss 0.23666684329509735\n",
      "\n",
      "Val func train loss in epoch 15:0.1949487030506134\n",
      "***********************TIME WAS 4.922277569770813 min*****************************\n",
      "\n",
      "**********************ROUND 52 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.006042384542524815\n",
      "\n",
      "episode 2, policy loss 0.010644020512700081\n",
      "\n",
      "episode 3, policy loss -0.0482577420771122\n",
      "\n",
      "episode 4, policy loss -0.027259021997451782\n",
      "\n",
      "episode 5, policy loss 0.008186738938093185\n",
      "\n",
      "episode 6, policy loss -0.016574036329984665\n",
      "\n",
      "episode 7, policy loss -0.044702932238578796\n",
      "\n",
      "episode 8, policy loss -0.0170897226780653\n",
      "\n",
      "episode 9, policy loss 0.031906940042972565\n",
      "\n",
      "episode 10, policy loss -0.043638888746500015\n",
      "\n",
      "episode 11, policy loss -0.026961104944348335\n",
      "\n",
      "episode 12, policy loss -0.045298971235752106\n",
      "\n",
      "episode 13, policy loss -0.03558887168765068\n",
      "\n",
      "episode 14, policy loss -0.029528595507144928\n",
      "\n",
      "episode 15, policy loss -0.05187723785638809\n",
      "\n",
      "episode 16, policy loss -0.04353724420070648\n",
      "\n",
      "Policy train loss in epoch 0:-0.024101190909277648\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.04320978745818138\n",
      "\n",
      "episode 2, policy loss 0.006032336037606001\n",
      "\n",
      "episode 3, policy loss 0.030948497354984283\n",
      "\n",
      "episode 4, policy loss -0.05008745566010475\n",
      "\n",
      "episode 5, policy loss -0.027906108647584915\n",
      "\n",
      "episode 6, policy loss -0.01802966371178627\n",
      "\n",
      "episode 7, policy loss -0.012363369576632977\n",
      "\n",
      "episode 8, policy loss -0.020205333828926086\n",
      "\n",
      "episode 9, policy loss -0.038095999509096146\n",
      "\n",
      "episode 10, policy loss 0.0027160532772541046\n",
      "\n",
      "episode 11, policy loss -0.041780877858400345\n",
      "\n",
      "episode 12, policy loss -0.030727744102478027\n",
      "\n",
      "episode 13, policy loss -0.025173453614115715\n",
      "\n",
      "episode 14, policy loss -0.05193042382597923\n",
      "\n",
      "episode 15, policy loss -0.042779311537742615\n",
      "\n",
      "episode 16, policy loss -0.0463416762650013\n",
      "\n",
      "Policy train loss in epoch 1:-0.025558394932886586\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.024089094251394272\n",
      "\n",
      "episode 2, policy loss -0.04318869486451149\n",
      "\n",
      "episode 3, policy loss -0.025708099827170372\n",
      "\n",
      "episode 4, policy loss 0.0016202847473323345\n",
      "\n",
      "episode 5, policy loss 0.032211750745773315\n",
      "\n",
      "episode 6, policy loss -0.050552986562252045\n",
      "\n",
      "episode 7, policy loss 0.007039375137537718\n",
      "\n",
      "episode 8, policy loss -0.029640400782227516\n",
      "\n",
      "episode 9, policy loss -0.04825499653816223\n",
      "\n",
      "episode 10, policy loss -0.012671606615185738\n",
      "\n",
      "episode 11, policy loss -0.04359297826886177\n",
      "\n",
      "episode 12, policy loss -0.020237283781170845\n",
      "\n",
      "episode 13, policy loss -0.029197009280323982\n",
      "\n",
      "episode 14, policy loss -0.043014369904994965\n",
      "\n",
      "episode 15, policy loss -0.03840291500091553\n",
      "\n",
      "episode 16, policy loss -0.045221660286188126\n",
      "\n",
      "Policy train loss in epoch 2:-0.02580629283329472\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.012110135518014431\n",
      "\n",
      "episode 2, policy loss -0.043944064527750015\n",
      "\n",
      "episode 3, policy loss 0.00027406198205426335\n",
      "\n",
      "episode 4, policy loss -0.050141386687755585\n",
      "\n",
      "episode 5, policy loss -0.05286020785570145\n",
      "\n",
      "episode 6, policy loss -0.02831043303012848\n",
      "\n",
      "episode 7, policy loss -0.03187643736600876\n",
      "\n",
      "episode 8, policy loss -0.024348774924874306\n",
      "\n",
      "episode 9, policy loss 0.029774785041809082\n",
      "\n",
      "episode 10, policy loss -0.04364844039082527\n",
      "\n",
      "episode 11, policy loss -0.021402528509497643\n",
      "\n",
      "episode 12, policy loss -0.029692543670535088\n",
      "\n",
      "episode 13, policy loss -0.03844553977251053\n",
      "\n",
      "episode 14, policy loss 0.006865187548100948\n",
      "\n",
      "episode 15, policy loss -0.04496745765209198\n",
      "\n",
      "episode 16, policy loss -0.04903305321931839\n",
      "\n",
      "Policy train loss in epoch 3:-0.027116685534565477\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1898483783006668\n",
      "\n",
      "episode 2, val func loss 0.1989031434059143\n",
      "\n",
      "episode 3, val func loss 0.20146174728870392\n",
      "\n",
      "episode 4, val func loss 0.18387889862060547\n",
      "\n",
      "episode 5, val func loss 0.1937859207391739\n",
      "\n",
      "episode 6, val func loss 0.16774433851242065\n",
      "\n",
      "episode 7, val func loss 0.1803160160779953\n",
      "\n",
      "episode 8, val func loss 0.1927785873413086\n",
      "\n",
      "episode 9, val func loss 0.15300430357456207\n",
      "\n",
      "episode 10, val func loss 0.1729077696800232\n",
      "\n",
      "episode 11, val func loss 0.19581957161426544\n",
      "\n",
      "episode 12, val func loss 0.1806735247373581\n",
      "\n",
      "episode 13, val func loss 0.18789437413215637\n",
      "\n",
      "episode 14, val func loss 0.19940124452114105\n",
      "\n",
      "episode 15, val func loss 0.1881905198097229\n",
      "\n",
      "episode 16, val func loss 0.2058698832988739\n",
      "\n",
      "Val func train loss in epoch 0:0.18702988885343075\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17303769290447235\n",
      "\n",
      "episode 2, val func loss 0.1933794617652893\n",
      "\n",
      "episode 3, val func loss 0.1926947981119156\n",
      "\n",
      "episode 4, val func loss 0.18028146028518677\n",
      "\n",
      "episode 5, val func loss 0.18711380660533905\n",
      "\n",
      "episode 6, val func loss 0.19916969537734985\n",
      "\n",
      "episode 7, val func loss 0.16713035106658936\n",
      "\n",
      "episode 8, val func loss 0.19250816106796265\n",
      "\n",
      "episode 9, val func loss 0.1526055783033371\n",
      "\n",
      "episode 10, val func loss 0.18760409951210022\n",
      "\n",
      "episode 11, val func loss 0.20157578587532043\n",
      "\n",
      "episode 12, val func loss 0.1905480921268463\n",
      "\n",
      "episode 13, val func loss 0.1990618109703064\n",
      "\n",
      "episode 14, val func loss 0.18060651421546936\n",
      "\n",
      "episode 15, val func loss 0.18378938734531403\n",
      "\n",
      "episode 16, val func loss 0.20584647357463837\n",
      "\n",
      "Val func train loss in epoch 1:0.18668457306921482\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19996564090251923\n",
      "\n",
      "episode 2, val func loss 0.1811164766550064\n",
      "\n",
      "episode 3, val func loss 0.19380690157413483\n",
      "\n",
      "episode 4, val func loss 0.200078547000885\n",
      "\n",
      "episode 5, val func loss 0.18008166551589966\n",
      "\n",
      "episode 6, val func loss 0.18393519520759583\n",
      "\n",
      "episode 7, val func loss 0.18719348311424255\n",
      "\n",
      "episode 8, val func loss 0.1678602695465088\n",
      "\n",
      "episode 9, val func loss 0.20599967241287231\n",
      "\n",
      "episode 10, val func loss 0.18961811065673828\n",
      "\n",
      "episode 11, val func loss 0.19251467287540436\n",
      "\n",
      "episode 12, val func loss 0.18789762258529663\n",
      "\n",
      "episode 13, val func loss 0.17317086458206177\n",
      "\n",
      "episode 14, val func loss 0.15396074950695038\n",
      "\n",
      "episode 15, val func loss 0.19112108647823334\n",
      "\n",
      "episode 16, val func loss 0.1992151439189911\n",
      "\n",
      "Val func train loss in epoch 2:0.18672100640833378\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1834092140197754\n",
      "\n",
      "episode 2, val func loss 0.1994507908821106\n",
      "\n",
      "episode 3, val func loss 0.19007088243961334\n",
      "\n",
      "episode 4, val func loss 0.19918036460876465\n",
      "\n",
      "episode 5, val func loss 0.1528525948524475\n",
      "\n",
      "episode 6, val func loss 0.20546261966228485\n",
      "\n",
      "episode 7, val func loss 0.19393807649612427\n",
      "\n",
      "episode 8, val func loss 0.18687434494495392\n",
      "\n",
      "episode 9, val func loss 0.20080861449241638\n",
      "\n",
      "episode 10, val func loss 0.1807083934545517\n",
      "\n",
      "episode 11, val func loss 0.17372751235961914\n",
      "\n",
      "episode 12, val func loss 0.19072414934635162\n",
      "\n",
      "episode 13, val func loss 0.1932888627052307\n",
      "\n",
      "episode 14, val func loss 0.16816332936286926\n",
      "\n",
      "episode 15, val func loss 0.18799437582492828\n",
      "\n",
      "episode 16, val func loss 0.18376068770885468\n",
      "\n",
      "Val func train loss in epoch 3:0.18690092582255602\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19994188845157623\n",
      "\n",
      "episode 2, val func loss 0.16697897017002106\n",
      "\n",
      "episode 3, val func loss 0.18381483852863312\n",
      "\n",
      "episode 4, val func loss 0.18754389882087708\n",
      "\n",
      "episode 5, val func loss 0.1994202733039856\n",
      "\n",
      "episode 6, val func loss 0.18030418455600739\n",
      "\n",
      "episode 7, val func loss 0.19267381727695465\n",
      "\n",
      "episode 8, val func loss 0.19005164504051208\n",
      "\n",
      "episode 9, val func loss 0.17991387844085693\n",
      "\n",
      "episode 10, val func loss 0.20019349455833435\n",
      "\n",
      "episode 11, val func loss 0.19586730003356934\n",
      "\n",
      "episode 12, val func loss 0.1746910810470581\n",
      "\n",
      "episode 13, val func loss 0.1558489352464676\n",
      "\n",
      "episode 14, val func loss 0.18636544048786163\n",
      "\n",
      "episode 15, val func loss 0.19389952719211578\n",
      "\n",
      "episode 16, val func loss 0.20638884603977203\n",
      "\n",
      "Val func train loss in epoch 4:0.18711862619966269\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18772345781326294\n",
      "\n",
      "episode 2, val func loss 0.19045564532279968\n",
      "\n",
      "episode 3, val func loss 0.18071389198303223\n",
      "\n",
      "episode 4, val func loss 0.1670040339231491\n",
      "\n",
      "episode 5, val func loss 0.20260952413082123\n",
      "\n",
      "episode 6, val func loss 0.18121881783008575\n",
      "\n",
      "episode 7, val func loss 0.18412430584430695\n",
      "\n",
      "episode 8, val func loss 0.19083599746227264\n",
      "\n",
      "episode 9, val func loss 0.17549413442611694\n",
      "\n",
      "episode 10, val func loss 0.18967919051647186\n",
      "\n",
      "episode 11, val func loss 0.1915617436170578\n",
      "\n",
      "episode 12, val func loss 0.2055339366197586\n",
      "\n",
      "episode 13, val func loss 0.2005351185798645\n",
      "\n",
      "episode 14, val func loss 0.1940607875585556\n",
      "\n",
      "episode 15, val func loss 0.15193769335746765\n",
      "\n",
      "episode 16, val func loss 0.1997273564338684\n",
      "\n",
      "Val func train loss in epoch 5:0.18707597721368074\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17312413454055786\n",
      "\n",
      "episode 2, val func loss 0.1966797560453415\n",
      "\n",
      "episode 3, val func loss 0.1675741970539093\n",
      "\n",
      "episode 4, val func loss 0.19904182851314545\n",
      "\n",
      "episode 5, val func loss 0.20597854256629944\n",
      "\n",
      "episode 6, val func loss 0.1878042221069336\n",
      "\n",
      "episode 7, val func loss 0.19818717241287231\n",
      "\n",
      "episode 8, val func loss 0.2001950740814209\n",
      "\n",
      "episode 9, val func loss 0.18280935287475586\n",
      "\n",
      "episode 10, val func loss 0.1958019882440567\n",
      "\n",
      "episode 11, val func loss 0.15534965693950653\n",
      "\n",
      "episode 12, val func loss 0.19008556008338928\n",
      "\n",
      "episode 13, val func loss 0.1842302829027176\n",
      "\n",
      "episode 14, val func loss 0.18505175411701202\n",
      "\n",
      "episode 15, val func loss 0.19612905383110046\n",
      "\n",
      "episode 16, val func loss 0.18847079575061798\n",
      "\n",
      "Val func train loss in epoch 6:0.1879070857539773\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18648429214954376\n",
      "\n",
      "episode 2, val func loss 0.19031989574432373\n",
      "\n",
      "episode 3, val func loss 0.1758110672235489\n",
      "\n",
      "episode 4, val func loss 0.19556663930416107\n",
      "\n",
      "episode 5, val func loss 0.20088934898376465\n",
      "\n",
      "episode 6, val func loss 0.19013774394989014\n",
      "\n",
      "episode 7, val func loss 0.1908329427242279\n",
      "\n",
      "episode 8, val func loss 0.2000897228717804\n",
      "\n",
      "episode 9, val func loss 0.17276354134082794\n",
      "\n",
      "episode 10, val func loss 0.1503896266222\n",
      "\n",
      "episode 11, val func loss 0.18437108397483826\n",
      "\n",
      "episode 12, val func loss 0.20720618963241577\n",
      "\n",
      "episode 13, val func loss 0.20267465710639954\n",
      "\n",
      "episode 14, val func loss 0.17985761165618896\n",
      "\n",
      "episode 15, val func loss 0.18736355006694794\n",
      "\n",
      "episode 16, val func loss 0.19025085866451263\n",
      "\n",
      "Val func train loss in epoch 7:0.18781304825097322\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.2003917694091797\n",
      "\n",
      "episode 2, val func loss 0.2017425149679184\n",
      "\n",
      "episode 3, val func loss 0.18744447827339172\n",
      "\n",
      "episode 4, val func loss 0.20603898167610168\n",
      "\n",
      "episode 5, val func loss 0.1935139149427414\n",
      "\n",
      "episode 6, val func loss 0.17989963293075562\n",
      "\n",
      "episode 7, val func loss 0.19142715632915497\n",
      "\n",
      "episode 8, val func loss 0.20071856677532196\n",
      "\n",
      "episode 9, val func loss 0.16949525475502014\n",
      "\n",
      "episode 10, val func loss 0.18743252754211426\n",
      "\n",
      "episode 11, val func loss 0.17983278632164001\n",
      "\n",
      "episode 12, val func loss 0.18955625593662262\n",
      "\n",
      "episode 13, val func loss 0.15105792880058289\n",
      "\n",
      "episode 14, val func loss 0.18407388031482697\n",
      "\n",
      "episode 15, val func loss 0.19070248305797577\n",
      "\n",
      "episode 16, val func loss 0.17318211495876312\n",
      "\n",
      "Val func train loss in epoch 8:0.18665689043700695\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1881209909915924\n",
      "\n",
      "episode 2, val func loss 0.19427604973316193\n",
      "\n",
      "episode 3, val func loss 0.1679239273071289\n",
      "\n",
      "episode 4, val func loss 0.17973947525024414\n",
      "\n",
      "episode 5, val func loss 0.1751345843076706\n",
      "\n",
      "episode 6, val func loss 0.18801482021808624\n",
      "\n",
      "episode 7, val func loss 0.18019817769527435\n",
      "\n",
      "episode 8, val func loss 0.1914537250995636\n",
      "\n",
      "episode 9, val func loss 0.20197251439094543\n",
      "\n",
      "episode 10, val func loss 0.18390415608882904\n",
      "\n",
      "episode 11, val func loss 0.1995544284582138\n",
      "\n",
      "episode 12, val func loss 0.19279326498508453\n",
      "\n",
      "episode 13, val func loss 0.19973468780517578\n",
      "\n",
      "episode 14, val func loss 0.15455269813537598\n",
      "\n",
      "episode 15, val func loss 0.19001047313213348\n",
      "\n",
      "episode 16, val func loss 0.20494113862514496\n",
      "\n",
      "Val func train loss in epoch 9:0.18702031951397657\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20099607110023499\n",
      "\n",
      "episode 2, val func loss 0.19895048439502716\n",
      "\n",
      "episode 3, val func loss 0.18050526082515717\n",
      "\n",
      "episode 4, val func loss 0.18618451058864594\n",
      "\n",
      "episode 5, val func loss 0.16892586648464203\n",
      "\n",
      "episode 6, val func loss 0.19095873832702637\n",
      "\n",
      "episode 7, val func loss 0.15637552738189697\n",
      "\n",
      "episode 8, val func loss 0.18758545815944672\n",
      "\n",
      "episode 9, val func loss 0.17320950329303741\n",
      "\n",
      "episode 10, val func loss 0.19939970970153809\n",
      "\n",
      "episode 11, val func loss 0.18382491171360016\n",
      "\n",
      "episode 12, val func loss 0.19030293822288513\n",
      "\n",
      "episode 13, val func loss 0.18061842024326324\n",
      "\n",
      "episode 14, val func loss 0.1906956434249878\n",
      "\n",
      "episode 15, val func loss 0.20664916932582855\n",
      "\n",
      "episode 16, val func loss 0.19487597048282623\n",
      "\n",
      "Val func train loss in epoch 10:0.18687863647937775\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19912126660346985\n",
      "\n",
      "episode 2, val func loss 0.1808922439813614\n",
      "\n",
      "episode 3, val func loss 0.18672989308834076\n",
      "\n",
      "episode 4, val func loss 0.2000506967306137\n",
      "\n",
      "episode 5, val func loss 0.19607383012771606\n",
      "\n",
      "episode 6, val func loss 0.20751339197158813\n",
      "\n",
      "episode 7, val func loss 0.18528328835964203\n",
      "\n",
      "episode 8, val func loss 0.19095000624656677\n",
      "\n",
      "episode 9, val func loss 0.1900884062051773\n",
      "\n",
      "episode 10, val func loss 0.15305034816265106\n",
      "\n",
      "episode 11, val func loss 0.19150759279727936\n",
      "\n",
      "episode 12, val func loss 0.1992468237876892\n",
      "\n",
      "episode 13, val func loss 0.16811327636241913\n",
      "\n",
      "episode 14, val func loss 0.18976719677448273\n",
      "\n",
      "episode 15, val func loss 0.17360658943653107\n",
      "\n",
      "episode 16, val func loss 0.18169233202934265\n",
      "\n",
      "Val func train loss in epoch 11:0.18710544891655445\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19572626054286957\n",
      "\n",
      "episode 2, val func loss 0.19924193620681763\n",
      "\n",
      "episode 3, val func loss 0.20560434460639954\n",
      "\n",
      "episode 4, val func loss 0.18478922545909882\n",
      "\n",
      "episode 5, val func loss 0.19188229739665985\n",
      "\n",
      "episode 6, val func loss 0.1700507253408432\n",
      "\n",
      "episode 7, val func loss 0.15720272064208984\n",
      "\n",
      "episode 8, val func loss 0.18635685741901398\n",
      "\n",
      "episode 9, val func loss 0.201423779129982\n",
      "\n",
      "episode 10, val func loss 0.187198668718338\n",
      "\n",
      "episode 11, val func loss 0.18217749893665314\n",
      "\n",
      "episode 12, val func loss 0.19102677702903748\n",
      "\n",
      "episode 13, val func loss 0.19415050745010376\n",
      "\n",
      "episode 14, val func loss 0.19944912195205688\n",
      "\n",
      "episode 15, val func loss 0.1727677285671234\n",
      "\n",
      "episode 16, val func loss 0.1804758757352829\n",
      "\n",
      "Val func train loss in epoch 12:0.18747027032077312\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18776315450668335\n",
      "\n",
      "episode 2, val func loss 0.1989482045173645\n",
      "\n",
      "episode 3, val func loss 0.20125050842761993\n",
      "\n",
      "episode 4, val func loss 0.19214800000190735\n",
      "\n",
      "episode 5, val func loss 0.18935458362102509\n",
      "\n",
      "episode 6, val func loss 0.20521019399166107\n",
      "\n",
      "episode 7, val func loss 0.18408235907554626\n",
      "\n",
      "episode 8, val func loss 0.16791842877864838\n",
      "\n",
      "episode 9, val func loss 0.17252621054649353\n",
      "\n",
      "episode 10, val func loss 0.1519850492477417\n",
      "\n",
      "episode 11, val func loss 0.1873795986175537\n",
      "\n",
      "episode 12, val func loss 0.18289831280708313\n",
      "\n",
      "episode 13, val func loss 0.194678395986557\n",
      "\n",
      "episode 14, val func loss 0.1989879161119461\n",
      "\n",
      "episode 15, val func loss 0.19218619167804718\n",
      "\n",
      "episode 16, val func loss 0.18079312145709991\n",
      "\n",
      "Val func train loss in epoch 13:0.18675688933581114\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18777009844779968\n",
      "\n",
      "episode 2, val func loss 0.19050274789333344\n",
      "\n",
      "episode 3, val func loss 0.16912977397441864\n",
      "\n",
      "episode 4, val func loss 0.178925022482872\n",
      "\n",
      "episode 5, val func loss 0.19102197885513306\n",
      "\n",
      "episode 6, val func loss 0.19374577701091766\n",
      "\n",
      "episode 7, val func loss 0.1986062228679657\n",
      "\n",
      "episode 8, val func loss 0.19293726980686188\n",
      "\n",
      "episode 9, val func loss 0.17243832349777222\n",
      "\n",
      "episode 10, val func loss 0.19918254017829895\n",
      "\n",
      "episode 11, val func loss 0.20328675210475922\n",
      "\n",
      "episode 12, val func loss 0.1505061537027359\n",
      "\n",
      "episode 13, val func loss 0.18477967381477356\n",
      "\n",
      "episode 14, val func loss 0.1806260049343109\n",
      "\n",
      "episode 15, val func loss 0.1882951557636261\n",
      "\n",
      "episode 16, val func loss 0.2065926492214203\n",
      "\n",
      "Val func train loss in epoch 14:0.18677163403481245\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20563024282455444\n",
      "\n",
      "episode 2, val func loss 0.19001036882400513\n",
      "\n",
      "episode 3, val func loss 0.18426962196826935\n",
      "\n",
      "episode 4, val func loss 0.1881990283727646\n",
      "\n",
      "episode 5, val func loss 0.19870488345623016\n",
      "\n",
      "episode 6, val func loss 0.1685590296983719\n",
      "\n",
      "episode 7, val func loss 0.19982844591140747\n",
      "\n",
      "episode 8, val func loss 0.19114138185977936\n",
      "\n",
      "episode 9, val func loss 0.1928771585226059\n",
      "\n",
      "episode 10, val func loss 0.20016421377658844\n",
      "\n",
      "episode 11, val func loss 0.186371847987175\n",
      "\n",
      "episode 12, val func loss 0.18009598553180695\n",
      "\n",
      "episode 13, val func loss 0.1941998153924942\n",
      "\n",
      "episode 14, val func loss 0.1517637073993683\n",
      "\n",
      "episode 15, val func loss 0.17262794077396393\n",
      "\n",
      "episode 16, val func loss 0.1834620237350464\n",
      "\n",
      "Val func train loss in epoch 15:0.18674410600215197\n",
      "***********************TIME WAS 4.915628838539123 min*****************************\n",
      "\n",
      "**********************ROUND 53 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.06606175750494003\n",
      "\n",
      "episode 2, policy loss -0.08367534726858139\n",
      "\n",
      "episode 3, policy loss -0.06963935494422913\n",
      "\n",
      "episode 4, policy loss -0.1010732650756836\n",
      "\n",
      "episode 5, policy loss -0.00881133507937193\n",
      "\n",
      "episode 6, policy loss -0.05051890388131142\n",
      "\n",
      "episode 7, policy loss -0.020292164757847786\n",
      "\n",
      "episode 8, policy loss -0.07761961966753006\n",
      "\n",
      "episode 9, policy loss -0.056984078139066696\n",
      "\n",
      "episode 10, policy loss -0.06127004697918892\n",
      "\n",
      "episode 11, policy loss -0.07438642531633377\n",
      "\n",
      "episode 12, policy loss -0.040280960500240326\n",
      "\n",
      "episode 13, policy loss -0.02493731863796711\n",
      "\n",
      "episode 14, policy loss -0.07319635152816772\n",
      "\n",
      "episode 15, policy loss -0.09697960317134857\n",
      "\n",
      "episode 16, policy loss -0.06728904694318771\n",
      "\n",
      "Policy train loss in epoch 0:-0.06081347371218726\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.05171326547861099\n",
      "\n",
      "episode 2, policy loss -0.10219808667898178\n",
      "\n",
      "episode 3, policy loss -0.07530590891838074\n",
      "\n",
      "episode 4, policy loss -0.05989999696612358\n",
      "\n",
      "episode 5, policy loss -0.061619244515895844\n",
      "\n",
      "episode 6, policy loss -0.09531719982624054\n",
      "\n",
      "episode 7, policy loss -0.07226797193288803\n",
      "\n",
      "episode 8, policy loss -0.07915350049734116\n",
      "\n",
      "episode 9, policy loss -0.03658024221658707\n",
      "\n",
      "episode 10, policy loss -0.08890858292579651\n",
      "\n",
      "episode 11, policy loss -0.06816315650939941\n",
      "\n",
      "episode 12, policy loss -0.02214827574789524\n",
      "\n",
      "episode 13, policy loss -0.07740236073732376\n",
      "\n",
      "episode 14, policy loss -0.009276497177779675\n",
      "\n",
      "episode 15, policy loss -0.0757853239774704\n",
      "\n",
      "episode 16, policy loss -0.020915435627102852\n",
      "\n",
      "Policy train loss in epoch 1:-0.0622909406083636\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.06832222640514374\n",
      "\n",
      "episode 2, policy loss -0.03754384443163872\n",
      "\n",
      "episode 3, policy loss -0.09817629307508469\n",
      "\n",
      "episode 4, policy loss -0.07317344099283218\n",
      "\n",
      "episode 5, policy loss -0.07613543421030045\n",
      "\n",
      "episode 6, policy loss -0.05226995423436165\n",
      "\n",
      "episode 7, policy loss -0.008047463372349739\n",
      "\n",
      "episode 8, policy loss -0.07523772865533829\n",
      "\n",
      "episode 9, policy loss -0.08085483312606812\n",
      "\n",
      "episode 10, policy loss -0.09047329425811768\n",
      "\n",
      "episode 11, policy loss -0.10437019914388657\n",
      "\n",
      "episode 12, policy loss -0.05956444889307022\n",
      "\n",
      "episode 13, policy loss -0.05923554301261902\n",
      "\n",
      "episode 14, policy loss -0.07534316182136536\n",
      "\n",
      "episode 15, policy loss -0.022817501798272133\n",
      "\n",
      "episode 16, policy loss -0.023192888125777245\n",
      "\n",
      "Policy train loss in epoch 2:-0.06279739097226411\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.09889896959066391\n",
      "\n",
      "episode 2, policy loss -0.06993413716554642\n",
      "\n",
      "episode 3, policy loss -0.09071068465709686\n",
      "\n",
      "episode 4, policy loss -0.060755472630262375\n",
      "\n",
      "episode 5, policy loss -0.1030774861574173\n",
      "\n",
      "episode 6, policy loss -0.07977309077978134\n",
      "\n",
      "episode 7, policy loss -0.07680140435695648\n",
      "\n",
      "episode 8, policy loss -0.05200841650366783\n",
      "\n",
      "episode 9, policy loss -0.07375206798315048\n",
      "\n",
      "episode 10, policy loss -0.08262109011411667\n",
      "\n",
      "episode 11, policy loss -0.05988467112183571\n",
      "\n",
      "episode 12, policy loss -0.009308342821896076\n",
      "\n",
      "episode 13, policy loss -0.025193952023983\n",
      "\n",
      "episode 14, policy loss -0.040115781128406525\n",
      "\n",
      "episode 15, policy loss -0.0722212865948677\n",
      "\n",
      "episode 16, policy loss -0.02257535420358181\n",
      "\n",
      "Policy train loss in epoch 3:-0.0636020129895769\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.21202166378498077\n",
      "\n",
      "episode 2, val func loss 0.20326219499111176\n",
      "\n",
      "episode 3, val func loss 0.1756831556558609\n",
      "\n",
      "episode 4, val func loss 0.20013032853603363\n",
      "\n",
      "episode 5, val func loss 0.20332379639148712\n",
      "\n",
      "episode 6, val func loss 0.16782256960868835\n",
      "\n",
      "episode 7, val func loss 0.1952378898859024\n",
      "\n",
      "episode 8, val func loss 0.18215882778167725\n",
      "\n",
      "episode 9, val func loss 0.20280461013317108\n",
      "\n",
      "episode 10, val func loss 0.1892242282629013\n",
      "\n",
      "episode 11, val func loss 0.21283605694770813\n",
      "\n",
      "episode 12, val func loss 0.19253893196582794\n",
      "\n",
      "episode 13, val func loss 0.18102969229221344\n",
      "\n",
      "episode 14, val func loss 0.1825072467327118\n",
      "\n",
      "episode 15, val func loss 0.16697849333286285\n",
      "\n",
      "episode 16, val func loss 0.20256024599075317\n",
      "\n",
      "Val func train loss in epoch 0:0.19188249576836824\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18241669237613678\n",
      "\n",
      "episode 2, val func loss 0.2028215229511261\n",
      "\n",
      "episode 3, val func loss 0.20052458345890045\n",
      "\n",
      "episode 4, val func loss 0.19345718622207642\n",
      "\n",
      "episode 5, val func loss 0.20947319269180298\n",
      "\n",
      "episode 6, val func loss 0.18272143602371216\n",
      "\n",
      "episode 7, val func loss 0.20330752432346344\n",
      "\n",
      "episode 8, val func loss 0.21125003695487976\n",
      "\n",
      "episode 9, val func loss 0.16670182347297668\n",
      "\n",
      "episode 10, val func loss 0.16950739920139313\n",
      "\n",
      "episode 11, val func loss 0.2027852088212967\n",
      "\n",
      "episode 12, val func loss 0.20309193432331085\n",
      "\n",
      "episode 13, val func loss 0.18104350566864014\n",
      "\n",
      "episode 14, val func loss 0.19558194279670715\n",
      "\n",
      "episode 15, val func loss 0.18930406868457794\n",
      "\n",
      "episode 16, val func loss 0.17514869570732117\n",
      "\n",
      "Val func train loss in epoch 1:0.19182104710489511\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18121369183063507\n",
      "\n",
      "episode 2, val func loss 0.205407977104187\n",
      "\n",
      "episode 3, val func loss 0.17275084555149078\n",
      "\n",
      "episode 4, val func loss 0.206782266497612\n",
      "\n",
      "episode 5, val func loss 0.16572454571723938\n",
      "\n",
      "episode 6, val func loss 0.19529393315315247\n",
      "\n",
      "episode 7, val func loss 0.2040167897939682\n",
      "\n",
      "episode 8, val func loss 0.18156126141548157\n",
      "\n",
      "episode 9, val func loss 0.1954570859670639\n",
      "\n",
      "episode 10, val func loss 0.19014514982700348\n",
      "\n",
      "episode 11, val func loss 0.21056798100471497\n",
      "\n",
      "episode 12, val func loss 0.18279774487018585\n",
      "\n",
      "episode 13, val func loss 0.16841383278369904\n",
      "\n",
      "episode 14, val func loss 0.20271603763103485\n",
      "\n",
      "episode 15, val func loss 0.20174121856689453\n",
      "\n",
      "episode 16, val func loss 0.20746801793575287\n",
      "\n",
      "Val func train loss in epoch 2:0.19200364872813225\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18246063590049744\n",
      "\n",
      "episode 2, val func loss 0.2031000405550003\n",
      "\n",
      "episode 3, val func loss 0.1667008101940155\n",
      "\n",
      "episode 4, val func loss 0.18913844227790833\n",
      "\n",
      "episode 5, val func loss 0.18021464347839355\n",
      "\n",
      "episode 6, val func loss 0.21493469178676605\n",
      "\n",
      "episode 7, val func loss 0.1736472249031067\n",
      "\n",
      "episode 8, val func loss 0.21030858159065247\n",
      "\n",
      "episode 9, val func loss 0.19335998594760895\n",
      "\n",
      "episode 10, val func loss 0.18222928047180176\n",
      "\n",
      "episode 11, val func loss 0.195307657122612\n",
      "\n",
      "episode 12, val func loss 0.20349162817001343\n",
      "\n",
      "episode 13, val func loss 0.20286162197589874\n",
      "\n",
      "episode 14, val func loss 0.2040298730134964\n",
      "\n",
      "episode 15, val func loss 0.20302335917949677\n",
      "\n",
      "episode 16, val func loss 0.16669058799743652\n",
      "\n",
      "Val func train loss in epoch 3:0.19196869153529406\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.20295046269893646\n",
      "\n",
      "episode 2, val func loss 0.18952405452728271\n",
      "\n",
      "episode 3, val func loss 0.17310965061187744\n",
      "\n",
      "episode 4, val func loss 0.18266309797763824\n",
      "\n",
      "episode 5, val func loss 0.19907967746257782\n",
      "\n",
      "episode 6, val func loss 0.20644578337669373\n",
      "\n",
      "episode 7, val func loss 0.1839754730463028\n",
      "\n",
      "episode 8, val func loss 0.16483330726623535\n",
      "\n",
      "episode 9, val func loss 0.20821364223957062\n",
      "\n",
      "episode 10, val func loss 0.1698625385761261\n",
      "\n",
      "episode 11, val func loss 0.20200717449188232\n",
      "\n",
      "episode 12, val func loss 0.2103351503610611\n",
      "\n",
      "episode 13, val func loss 0.18073248863220215\n",
      "\n",
      "episode 14, val func loss 0.20290353894233704\n",
      "\n",
      "episode 15, val func loss 0.19489113986492157\n",
      "\n",
      "episode 16, val func loss 0.20316624641418457\n",
      "\n",
      "Val func train loss in epoch 4:0.19216833915561438\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.21131980419158936\n",
      "\n",
      "episode 2, val func loss 0.19034916162490845\n",
      "\n",
      "episode 3, val func loss 0.20259246230125427\n",
      "\n",
      "episode 4, val func loss 0.2032780945301056\n",
      "\n",
      "episode 5, val func loss 0.16619622707366943\n",
      "\n",
      "episode 6, val func loss 0.19599537551403046\n",
      "\n",
      "episode 7, val func loss 0.20968027412891388\n",
      "\n",
      "episode 8, val func loss 0.18195554614067078\n",
      "\n",
      "episode 9, val func loss 0.20022889971733093\n",
      "\n",
      "episode 10, val func loss 0.1755666583776474\n",
      "\n",
      "episode 11, val func loss 0.18412016332149506\n",
      "\n",
      "episode 12, val func loss 0.20414000749588013\n",
      "\n",
      "episode 13, val func loss 0.1662718504667282\n",
      "\n",
      "episode 14, val func loss 0.19494473934173584\n",
      "\n",
      "episode 15, val func loss 0.204300656914711\n",
      "\n",
      "episode 16, val func loss 0.18028952181339264\n",
      "\n",
      "Val func train loss in epoch 5:0.19195184018462896\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.16795992851257324\n",
      "\n",
      "episode 2, val func loss 0.1818712055683136\n",
      "\n",
      "episode 3, val func loss 0.19174125790596008\n",
      "\n",
      "episode 4, val func loss 0.18294282257556915\n",
      "\n",
      "episode 5, val func loss 0.1901751458644867\n",
      "\n",
      "episode 6, val func loss 0.1804303377866745\n",
      "\n",
      "episode 7, val func loss 0.175748810172081\n",
      "\n",
      "episode 8, val func loss 0.20374862849712372\n",
      "\n",
      "episode 9, val func loss 0.20497839152812958\n",
      "\n",
      "episode 10, val func loss 0.19600291550159454\n",
      "\n",
      "episode 11, val func loss 0.16455475986003876\n",
      "\n",
      "episode 12, val func loss 0.2044472098350525\n",
      "\n",
      "episode 13, val func loss 0.21280686557292938\n",
      "\n",
      "episode 14, val func loss 0.20052753388881683\n",
      "\n",
      "episode 15, val func loss 0.2072383016347885\n",
      "\n",
      "episode 16, val func loss 0.20360155403614044\n",
      "\n",
      "Val func train loss in epoch 6:0.19179847929626703\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.16966935992240906\n",
      "\n",
      "episode 2, val func loss 0.20256200432777405\n",
      "\n",
      "episode 3, val func loss 0.1957329362630844\n",
      "\n",
      "episode 4, val func loss 0.16579939424991608\n",
      "\n",
      "episode 5, val func loss 0.20845618844032288\n",
      "\n",
      "episode 6, val func loss 0.1921740174293518\n",
      "\n",
      "episode 7, val func loss 0.20349352061748505\n",
      "\n",
      "episode 8, val func loss 0.1823485791683197\n",
      "\n",
      "episode 9, val func loss 0.2107781022787094\n",
      "\n",
      "episode 10, val func loss 0.20258133113384247\n",
      "\n",
      "episode 11, val func loss 0.19113850593566895\n",
      "\n",
      "episode 12, val func loss 0.2022189050912857\n",
      "\n",
      "episode 13, val func loss 0.18301033973693848\n",
      "\n",
      "episode 14, val func loss 0.20362748205661774\n",
      "\n",
      "episode 15, val func loss 0.17553843557834625\n",
      "\n",
      "episode 16, val func loss 0.18076175451278687\n",
      "\n",
      "Val func train loss in epoch 7:0.19186817854642868\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.20611771941184998\n",
      "\n",
      "episode 2, val func loss 0.1960989087820053\n",
      "\n",
      "episode 3, val func loss 0.21219402551651\n",
      "\n",
      "episode 4, val func loss 0.2038380354642868\n",
      "\n",
      "episode 5, val func loss 0.21165193617343903\n",
      "\n",
      "episode 6, val func loss 0.18299657106399536\n",
      "\n",
      "episode 7, val func loss 0.16774584352970123\n",
      "\n",
      "episode 8, val func loss 0.18196885287761688\n",
      "\n",
      "episode 9, val func loss 0.19601917266845703\n",
      "\n",
      "episode 10, val func loss 0.1908169686794281\n",
      "\n",
      "episode 11, val func loss 0.20295587182044983\n",
      "\n",
      "episode 12, val func loss 0.1670735776424408\n",
      "\n",
      "episode 13, val func loss 0.19997459650039673\n",
      "\n",
      "episode 14, val func loss 0.18630944192409515\n",
      "\n",
      "episode 15, val func loss 0.20511677861213684\n",
      "\n",
      "episode 16, val func loss 0.17340584099292755\n",
      "\n",
      "Val func train loss in epoch 8:0.19276775885373354\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18940135836601257\n",
      "\n",
      "episode 2, val func loss 0.19944556057453156\n",
      "\n",
      "episode 3, val func loss 0.19371022284030914\n",
      "\n",
      "episode 4, val func loss 0.19572597742080688\n",
      "\n",
      "episode 5, val func loss 0.18021290004253387\n",
      "\n",
      "episode 6, val func loss 0.1823444664478302\n",
      "\n",
      "episode 7, val func loss 0.2027495950460434\n",
      "\n",
      "episode 8, val func loss 0.20296569168567657\n",
      "\n",
      "episode 9, val func loss 0.20299820601940155\n",
      "\n",
      "episode 10, val func loss 0.1695060282945633\n",
      "\n",
      "episode 11, val func loss 0.1667092740535736\n",
      "\n",
      "episode 12, val func loss 0.1764681488275528\n",
      "\n",
      "episode 13, val func loss 0.21493062376976013\n",
      "\n",
      "episode 14, val func loss 0.21237117052078247\n",
      "\n",
      "episode 15, val func loss 0.2043767273426056\n",
      "\n",
      "episode 16, val func loss 0.18172450363636017\n",
      "\n",
      "Val func train loss in epoch 9:0.1922275284305215\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20281757414340973\n",
      "\n",
      "episode 2, val func loss 0.21222351491451263\n",
      "\n",
      "episode 3, val func loss 0.20294785499572754\n",
      "\n",
      "episode 4, val func loss 0.1828620433807373\n",
      "\n",
      "episode 5, val func loss 0.2020212560892105\n",
      "\n",
      "episode 6, val func loss 0.19164249300956726\n",
      "\n",
      "episode 7, val func loss 0.16883304715156555\n",
      "\n",
      "episode 8, val func loss 0.18061472475528717\n",
      "\n",
      "episode 9, val func loss 0.20390833914279938\n",
      "\n",
      "episode 10, val func loss 0.2036350518465042\n",
      "\n",
      "episode 11, val func loss 0.20946210622787476\n",
      "\n",
      "episode 12, val func loss 0.165034681558609\n",
      "\n",
      "episode 13, val func loss 0.1954493373632431\n",
      "\n",
      "episode 14, val func loss 0.17686006426811218\n",
      "\n",
      "episode 15, val func loss 0.1826893389225006\n",
      "\n",
      "episode 16, val func loss 0.18909426033496857\n",
      "\n",
      "Val func train loss in epoch 10:0.19188098050653934\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16440929472446442\n",
      "\n",
      "episode 2, val func loss 0.19395385682582855\n",
      "\n",
      "episode 3, val func loss 0.1963014155626297\n",
      "\n",
      "episode 4, val func loss 0.18295206129550934\n",
      "\n",
      "episode 5, val func loss 0.20316214859485626\n",
      "\n",
      "episode 6, val func loss 0.1763564795255661\n",
      "\n",
      "episode 7, val func loss 0.18213169276714325\n",
      "\n",
      "episode 8, val func loss 0.18022233247756958\n",
      "\n",
      "episode 9, val func loss 0.18910439312458038\n",
      "\n",
      "episode 10, val func loss 0.1662329137325287\n",
      "\n",
      "episode 11, val func loss 0.21121187508106232\n",
      "\n",
      "episode 12, val func loss 0.20468610525131226\n",
      "\n",
      "episode 13, val func loss 0.20004749298095703\n",
      "\n",
      "episode 14, val func loss 0.20319843292236328\n",
      "\n",
      "episode 15, val func loss 0.20269927382469177\n",
      "\n",
      "episode 16, val func loss 0.21099525690078735\n",
      "\n",
      "Val func train loss in epoch 11:0.19172906409949064\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.16943523287773132\n",
      "\n",
      "episode 2, val func loss 0.16727198660373688\n",
      "\n",
      "episode 3, val func loss 0.1916077733039856\n",
      "\n",
      "episode 4, val func loss 0.2111581414937973\n",
      "\n",
      "episode 5, val func loss 0.20300070941448212\n",
      "\n",
      "episode 6, val func loss 0.18211545050144196\n",
      "\n",
      "episode 7, val func loss 0.20738011598587036\n",
      "\n",
      "episode 8, val func loss 0.20262156426906586\n",
      "\n",
      "episode 9, val func loss 0.18312565982341766\n",
      "\n",
      "episode 10, val func loss 0.20106574892997742\n",
      "\n",
      "episode 11, val func loss 0.20357681810855865\n",
      "\n",
      "episode 12, val func loss 0.17609146237373352\n",
      "\n",
      "episode 13, val func loss 0.196244478225708\n",
      "\n",
      "episode 14, val func loss 0.1893298178911209\n",
      "\n",
      "episode 15, val func loss 0.2045602798461914\n",
      "\n",
      "episode 16, val func loss 0.18137861788272858\n",
      "\n",
      "Val func train loss in epoch 12:0.19187274109572172\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.20570045709609985\n",
      "\n",
      "episode 2, val func loss 0.20379620790481567\n",
      "\n",
      "episode 3, val func loss 0.2086021602153778\n",
      "\n",
      "episode 4, val func loss 0.18091851472854614\n",
      "\n",
      "episode 5, val func loss 0.18240493535995483\n",
      "\n",
      "episode 6, val func loss 0.20398461818695068\n",
      "\n",
      "episode 7, val func loss 0.18512555956840515\n",
      "\n",
      "episode 8, val func loss 0.20298708975315094\n",
      "\n",
      "episode 9, val func loss 0.19130845367908478\n",
      "\n",
      "episode 10, val func loss 0.21057768166065216\n",
      "\n",
      "episode 11, val func loss 0.16929665207862854\n",
      "\n",
      "episode 12, val func loss 0.17761164903640747\n",
      "\n",
      "episode 13, val func loss 0.1996946781873703\n",
      "\n",
      "episode 14, val func loss 0.19721746444702148\n",
      "\n",
      "episode 15, val func loss 0.1900642216205597\n",
      "\n",
      "episode 16, val func loss 0.1643694043159485\n",
      "\n",
      "Val func train loss in epoch 13:0.19210373423993587\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.2065742015838623\n",
      "\n",
      "episode 2, val func loss 0.19703376293182373\n",
      "\n",
      "episode 3, val func loss 0.203725203871727\n",
      "\n",
      "episode 4, val func loss 0.18214420974254608\n",
      "\n",
      "episode 5, val func loss 0.1825440526008606\n",
      "\n",
      "episode 6, val func loss 0.20766755938529968\n",
      "\n",
      "episode 7, val func loss 0.20312997698783875\n",
      "\n",
      "episode 8, val func loss 0.19189050793647766\n",
      "\n",
      "episode 9, val func loss 0.20407506823539734\n",
      "\n",
      "episode 10, val func loss 0.18340058624744415\n",
      "\n",
      "episode 11, val func loss 0.16811436414718628\n",
      "\n",
      "episode 12, val func loss 0.16696932911872864\n",
      "\n",
      "episode 13, val func loss 0.18178923428058624\n",
      "\n",
      "episode 14, val func loss 0.19070371985435486\n",
      "\n",
      "episode 15, val func loss 0.20055371522903442\n",
      "\n",
      "episode 16, val func loss 0.21778497099876404\n",
      "\n",
      "Val func train loss in epoch 14:0.19300627894699574\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.2116108387708664\n",
      "\n",
      "episode 2, val func loss 0.1924007683992386\n",
      "\n",
      "episode 3, val func loss 0.18059951066970825\n",
      "\n",
      "episode 4, val func loss 0.2026565819978714\n",
      "\n",
      "episode 5, val func loss 0.2035844475030899\n",
      "\n",
      "episode 6, val func loss 0.18426455557346344\n",
      "\n",
      "episode 7, val func loss 0.20320071280002594\n",
      "\n",
      "episode 8, val func loss 0.21186423301696777\n",
      "\n",
      "episode 9, val func loss 0.16632044315338135\n",
      "\n",
      "episode 10, val func loss 0.19521594047546387\n",
      "\n",
      "episode 11, val func loss 0.18232810497283936\n",
      "\n",
      "episode 12, val func loss 0.20308727025985718\n",
      "\n",
      "episode 13, val func loss 0.1891528069972992\n",
      "\n",
      "episode 14, val func loss 0.16656291484832764\n",
      "\n",
      "episode 15, val func loss 0.17399197816848755\n",
      "\n",
      "episode 16, val func loss 0.2100665122270584\n",
      "\n",
      "Val func train loss in epoch 15:0.19230672623962164\n",
      "***********************TIME WAS 4.923009435335795 min*****************************\n",
      "\n",
      "**********************ROUND 54 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.03348170593380928\n",
      "\n",
      "episode 2, policy loss -0.1594722419977188\n",
      "\n",
      "episode 3, policy loss -0.14830872416496277\n",
      "\n",
      "episode 4, policy loss -0.08374045789241791\n",
      "\n",
      "episode 5, policy loss -0.08669403940439224\n",
      "\n",
      "episode 6, policy loss -0.03529612720012665\n",
      "\n",
      "episode 7, policy loss -0.0823083221912384\n",
      "\n",
      "episode 8, policy loss -0.060974400490522385\n",
      "\n",
      "episode 9, policy loss -0.08587821573019028\n",
      "\n",
      "episode 10, policy loss -0.03559866175055504\n",
      "\n",
      "episode 11, policy loss -0.11862342804670334\n",
      "\n",
      "episode 12, policy loss -0.09725937247276306\n",
      "\n",
      "episode 13, policy loss -0.07804200053215027\n",
      "\n",
      "episode 14, policy loss -0.024363044649362564\n",
      "\n",
      "episode 15, policy loss -0.041833337396383286\n",
      "\n",
      "episode 16, policy loss -0.0566878579556942\n",
      "\n",
      "Policy train loss in epoch 0:-0.0767851211130619\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.05769976228475571\n",
      "\n",
      "episode 2, policy loss -0.024030903354287148\n",
      "\n",
      "episode 3, policy loss -0.15867222845554352\n",
      "\n",
      "episode 4, policy loss -0.08475467562675476\n",
      "\n",
      "episode 5, policy loss -0.03507201373577118\n",
      "\n",
      "episode 6, policy loss -0.084824338555336\n",
      "\n",
      "episode 7, policy loss -0.08580337464809418\n",
      "\n",
      "episode 8, policy loss -0.03510567918419838\n",
      "\n",
      "episode 9, policy loss -0.07566841691732407\n",
      "\n",
      "episode 10, policy loss -0.09632322192192078\n",
      "\n",
      "episode 11, policy loss -0.11948931217193604\n",
      "\n",
      "episode 12, policy loss -0.14762476086616516\n",
      "\n",
      "episode 13, policy loss -0.042448557913303375\n",
      "\n",
      "episode 14, policy loss -0.06291792541742325\n",
      "\n",
      "episode 15, policy loss -0.0807863250374794\n",
      "\n",
      "episode 16, policy loss -0.037963446229696274\n",
      "\n",
      "Policy train loss in epoch 1:-0.07682405889499933\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.08139663189649582\n",
      "\n",
      "episode 2, policy loss -0.09408707171678543\n",
      "\n",
      "episode 3, policy loss -0.02270493470132351\n",
      "\n",
      "episode 4, policy loss -0.036673277616500854\n",
      "\n",
      "episode 5, policy loss -0.08262746036052704\n",
      "\n",
      "episode 6, policy loss -0.036910124123096466\n",
      "\n",
      "episode 7, policy loss -0.15795980393886566\n",
      "\n",
      "episode 8, policy loss -0.14401806890964508\n",
      "\n",
      "episode 9, policy loss -0.03239349275827408\n",
      "\n",
      "episode 10, policy loss -0.12121333181858063\n",
      "\n",
      "episode 11, policy loss -0.03978210687637329\n",
      "\n",
      "episode 12, policy loss -0.059418223798274994\n",
      "\n",
      "episode 13, policy loss -0.08023123443126678\n",
      "\n",
      "episode 14, policy loss -0.062128059566020966\n",
      "\n",
      "episode 15, policy loss -0.08546502888202667\n",
      "\n",
      "episode 16, policy loss -0.07696764171123505\n",
      "\n",
      "Policy train loss in epoch 2:-0.07587353081908077\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.060575731098651886\n",
      "\n",
      "episode 2, policy loss -0.04211646690964699\n",
      "\n",
      "episode 3, policy loss -0.15737079083919525\n",
      "\n",
      "episode 4, policy loss -0.03336816281080246\n",
      "\n",
      "episode 5, policy loss -0.08613269776105881\n",
      "\n",
      "episode 6, policy loss -0.14864705502986908\n",
      "\n",
      "episode 7, policy loss -0.08903907239437103\n",
      "\n",
      "episode 8, policy loss -0.08023160696029663\n",
      "\n",
      "episode 9, policy loss -0.11530504375696182\n",
      "\n",
      "episode 10, policy loss -0.034480784088373184\n",
      "\n",
      "episode 11, policy loss -0.03704962879419327\n",
      "\n",
      "episode 12, policy loss -0.024006741121411324\n",
      "\n",
      "episode 13, policy loss -0.0978614017367363\n",
      "\n",
      "episode 14, policy loss -0.08243488520383835\n",
      "\n",
      "episode 15, policy loss -0.05959711968898773\n",
      "\n",
      "episode 16, policy loss -0.0798228532075882\n",
      "\n",
      "Policy train loss in epoch 3:-0.0767525025876239\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.2204422503709793\n",
      "\n",
      "episode 2, val func loss 0.18755340576171875\n",
      "\n",
      "episode 3, val func loss 0.17728205025196075\n",
      "\n",
      "episode 4, val func loss 0.1960153430700302\n",
      "\n",
      "episode 5, val func loss 0.2101822793483734\n",
      "\n",
      "episode 6, val func loss 0.22511716187000275\n",
      "\n",
      "episode 7, val func loss 0.19415389001369476\n",
      "\n",
      "episode 8, val func loss 0.1739858090877533\n",
      "\n",
      "episode 9, val func loss 0.17293159663677216\n",
      "\n",
      "episode 10, val func loss 0.18797773122787476\n",
      "\n",
      "episode 11, val func loss 0.16761000454425812\n",
      "\n",
      "episode 12, val func loss 0.18981213867664337\n",
      "\n",
      "episode 13, val func loss 0.19142991304397583\n",
      "\n",
      "episode 14, val func loss 0.1703837513923645\n",
      "\n",
      "episode 15, val func loss 0.1531764566898346\n",
      "\n",
      "episode 16, val func loss 0.2293509840965271\n",
      "\n",
      "Val func train loss in epoch 0:0.19046279788017273\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.15349645912647247\n",
      "\n",
      "episode 2, val func loss 0.18763574957847595\n",
      "\n",
      "episode 3, val func loss 0.1771223545074463\n",
      "\n",
      "episode 4, val func loss 0.18768112361431122\n",
      "\n",
      "episode 5, val func loss 0.17089703679084778\n",
      "\n",
      "episode 6, val func loss 0.1674433946609497\n",
      "\n",
      "episode 7, val func loss 0.19534288346767426\n",
      "\n",
      "episode 8, val func loss 0.21683669090270996\n",
      "\n",
      "episode 9, val func loss 0.18820185959339142\n",
      "\n",
      "episode 10, val func loss 0.22679302096366882\n",
      "\n",
      "episode 11, val func loss 0.22876960039138794\n",
      "\n",
      "episode 12, val func loss 0.16887901723384857\n",
      "\n",
      "episode 13, val func loss 0.21025194227695465\n",
      "\n",
      "episode 14, val func loss 0.19315733015537262\n",
      "\n",
      "episode 15, val func loss 0.18876175582408905\n",
      "\n",
      "episode 16, val func loss 0.17426076531410217\n",
      "\n",
      "Val func train loss in epoch 1:0.18972068652510643\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18773390352725983\n",
      "\n",
      "episode 2, val func loss 0.17115747928619385\n",
      "\n",
      "episode 3, val func loss 0.16925564408302307\n",
      "\n",
      "episode 4, val func loss 0.21263116598129272\n",
      "\n",
      "episode 5, val func loss 0.16581636667251587\n",
      "\n",
      "episode 6, val func loss 0.2314388006925583\n",
      "\n",
      "episode 7, val func loss 0.2352657914161682\n",
      "\n",
      "episode 8, val func loss 0.17007191479206085\n",
      "\n",
      "episode 9, val func loss 0.19476306438446045\n",
      "\n",
      "episode 10, val func loss 0.21617045998573303\n",
      "\n",
      "episode 11, val func loss 0.15730169415473938\n",
      "\n",
      "episode 12, val func loss 0.18799933791160583\n",
      "\n",
      "episode 13, val func loss 0.187427818775177\n",
      "\n",
      "episode 14, val func loss 0.18982286751270294\n",
      "\n",
      "episode 15, val func loss 0.17742745578289032\n",
      "\n",
      "episode 16, val func loss 0.19523243606090546\n",
      "\n",
      "Val func train loss in epoch 2:0.19059476256370544\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.22647236287593842\n",
      "\n",
      "episode 2, val func loss 0.18817515671253204\n",
      "\n",
      "episode 3, val func loss 0.2115946263074875\n",
      "\n",
      "episode 4, val func loss 0.17159104347229004\n",
      "\n",
      "episode 5, val func loss 0.1952752321958542\n",
      "\n",
      "episode 6, val func loss 0.18765242397785187\n",
      "\n",
      "episode 7, val func loss 0.16849373281002045\n",
      "\n",
      "episode 8, val func loss 0.21671855449676514\n",
      "\n",
      "episode 9, val func loss 0.16644024848937988\n",
      "\n",
      "episode 10, val func loss 0.1889258325099945\n",
      "\n",
      "episode 11, val func loss 0.16591200232505798\n",
      "\n",
      "episode 12, val func loss 0.2344353199005127\n",
      "\n",
      "episode 13, val func loss 0.19534073770046234\n",
      "\n",
      "episode 14, val func loss 0.15507635474205017\n",
      "\n",
      "episode 15, val func loss 0.1868147850036621\n",
      "\n",
      "episode 16, val func loss 0.17720259726047516\n",
      "\n",
      "Val func train loss in epoch 3:0.1897575631737709\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.22836971282958984\n",
      "\n",
      "episode 2, val func loss 0.17822369933128357\n",
      "\n",
      "episode 3, val func loss 0.16950124502182007\n",
      "\n",
      "episode 4, val func loss 0.18710781633853912\n",
      "\n",
      "episode 5, val func loss 0.18894502520561218\n",
      "\n",
      "episode 6, val func loss 0.16761428117752075\n",
      "\n",
      "episode 7, val func loss 0.1880711019039154\n",
      "\n",
      "episode 8, val func loss 0.1954401135444641\n",
      "\n",
      "episode 9, val func loss 0.2174835056066513\n",
      "\n",
      "episode 10, val func loss 0.16706779599189758\n",
      "\n",
      "episode 11, val func loss 0.21317890286445618\n",
      "\n",
      "episode 12, val func loss 0.2266327440738678\n",
      "\n",
      "episode 13, val func loss 0.15565332770347595\n",
      "\n",
      "episode 14, val func loss 0.17148643732070923\n",
      "\n",
      "episode 15, val func loss 0.18732531368732452\n",
      "\n",
      "episode 16, val func loss 0.19427239894866943\n",
      "\n",
      "Val func train loss in epoch 4:0.18977333884686232\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.15726059675216675\n",
      "\n",
      "episode 2, val func loss 0.17786872386932373\n",
      "\n",
      "episode 3, val func loss 0.1942887157201767\n",
      "\n",
      "episode 4, val func loss 0.1951492577791214\n",
      "\n",
      "episode 5, val func loss 0.18780653178691864\n",
      "\n",
      "episode 6, val func loss 0.18728619813919067\n",
      "\n",
      "episode 7, val func loss 0.1883634328842163\n",
      "\n",
      "episode 8, val func loss 0.16673997044563293\n",
      "\n",
      "episode 9, val func loss 0.18791303038597107\n",
      "\n",
      "episode 10, val func loss 0.1678103655576706\n",
      "\n",
      "episode 11, val func loss 0.21706809103488922\n",
      "\n",
      "episode 12, val func loss 0.23140789568424225\n",
      "\n",
      "episode 13, val func loss 0.17061537504196167\n",
      "\n",
      "episode 14, val func loss 0.22383947670459747\n",
      "\n",
      "episode 15, val func loss 0.1687861979007721\n",
      "\n",
      "episode 16, val func loss 0.21017883718013763\n",
      "\n",
      "Val func train loss in epoch 5:0.18952391855418682\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19658134877681732\n",
      "\n",
      "episode 2, val func loss 0.19027739763259888\n",
      "\n",
      "episode 3, val func loss 0.17890901863574982\n",
      "\n",
      "episode 4, val func loss 0.21678388118743896\n",
      "\n",
      "episode 5, val func loss 0.17189428210258484\n",
      "\n",
      "episode 6, val func loss 0.16805990040302277\n",
      "\n",
      "episode 7, val func loss 0.2318643480539322\n",
      "\n",
      "episode 8, val func loss 0.21246829628944397\n",
      "\n",
      "episode 9, val func loss 0.1663573533296585\n",
      "\n",
      "episode 10, val func loss 0.18825960159301758\n",
      "\n",
      "episode 11, val func loss 0.1875879466533661\n",
      "\n",
      "episode 12, val func loss 0.186958447098732\n",
      "\n",
      "episode 13, val func loss 0.16701403260231018\n",
      "\n",
      "episode 14, val func loss 0.15563878417015076\n",
      "\n",
      "episode 15, val func loss 0.22522783279418945\n",
      "\n",
      "episode 16, val func loss 0.19401036202907562\n",
      "\n",
      "Val func train loss in epoch 6:0.18986830208450556\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.2241300344467163\n",
      "\n",
      "episode 2, val func loss 0.1956932246685028\n",
      "\n",
      "episode 3, val func loss 0.22548505663871765\n",
      "\n",
      "episode 4, val func loss 0.16091731190681458\n",
      "\n",
      "episode 5, val func loss 0.1887064427137375\n",
      "\n",
      "episode 6, val func loss 0.1716972291469574\n",
      "\n",
      "episode 7, val func loss 0.21711061894893646\n",
      "\n",
      "episode 8, val func loss 0.187198668718338\n",
      "\n",
      "episode 9, val func loss 0.18859747052192688\n",
      "\n",
      "episode 10, val func loss 0.18751364946365356\n",
      "\n",
      "episode 11, val func loss 0.17153269052505493\n",
      "\n",
      "episode 12, val func loss 0.1661030650138855\n",
      "\n",
      "episode 13, val func loss 0.19622845947742462\n",
      "\n",
      "episode 14, val func loss 0.165719136595726\n",
      "\n",
      "episode 15, val func loss 0.21554923057556152\n",
      "\n",
      "episode 16, val func loss 0.17735034227371216\n",
      "\n",
      "Val func train loss in epoch 7:0.18997078947722912\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17671802639961243\n",
      "\n",
      "episode 2, val func loss 0.2178640365600586\n",
      "\n",
      "episode 3, val func loss 0.19578751921653748\n",
      "\n",
      "episode 4, val func loss 0.22965598106384277\n",
      "\n",
      "episode 5, val func loss 0.2227592021226883\n",
      "\n",
      "episode 6, val func loss 0.19518396258354187\n",
      "\n",
      "episode 7, val func loss 0.1909770518541336\n",
      "\n",
      "episode 8, val func loss 0.17796607315540314\n",
      "\n",
      "episode 9, val func loss 0.21236048638820648\n",
      "\n",
      "episode 10, val func loss 0.17464718222618103\n",
      "\n",
      "episode 11, val func loss 0.18983294069766998\n",
      "\n",
      "episode 12, val func loss 0.16803745925426483\n",
      "\n",
      "episode 13, val func loss 0.1541948914527893\n",
      "\n",
      "episode 14, val func loss 0.1703815758228302\n",
      "\n",
      "episode 15, val func loss 0.19251373410224915\n",
      "\n",
      "episode 16, val func loss 0.1925426423549652\n",
      "\n",
      "Val func train loss in epoch 8:0.1913389228284359\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.19087590277194977\n",
      "\n",
      "episode 2, val func loss 0.19708152115345\n",
      "\n",
      "episode 3, val func loss 0.17056894302368164\n",
      "\n",
      "episode 4, val func loss 0.16865745186805725\n",
      "\n",
      "episode 5, val func loss 0.23170238733291626\n",
      "\n",
      "episode 6, val func loss 0.19564177095890045\n",
      "\n",
      "episode 7, val func loss 0.2164415717124939\n",
      "\n",
      "episode 8, val func loss 0.17876972258090973\n",
      "\n",
      "episode 9, val func loss 0.1717648059129715\n",
      "\n",
      "episode 10, val func loss 0.2117532640695572\n",
      "\n",
      "episode 11, val func loss 0.1545606404542923\n",
      "\n",
      "episode 12, val func loss 0.16523244976997375\n",
      "\n",
      "episode 13, val func loss 0.19060474634170532\n",
      "\n",
      "episode 14, val func loss 0.1909836232662201\n",
      "\n",
      "episode 15, val func loss 0.18894904851913452\n",
      "\n",
      "episode 16, val func loss 0.22824311256408691\n",
      "\n",
      "Val func train loss in epoch 9:0.1907394351437688\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.216003879904747\n",
      "\n",
      "episode 2, val func loss 0.1810564398765564\n",
      "\n",
      "episode 3, val func loss 0.17430438101291656\n",
      "\n",
      "episode 4, val func loss 0.21021181344985962\n",
      "\n",
      "episode 5, val func loss 0.18761447072029114\n",
      "\n",
      "episode 6, val func loss 0.16782507300376892\n",
      "\n",
      "episode 7, val func loss 0.22605349123477936\n",
      "\n",
      "episode 8, val func loss 0.1951162964105606\n",
      "\n",
      "episode 9, val func loss 0.18781304359436035\n",
      "\n",
      "episode 10, val func loss 0.15447558462619781\n",
      "\n",
      "episode 11, val func loss 0.1882297247648239\n",
      "\n",
      "episode 12, val func loss 0.19527725875377655\n",
      "\n",
      "episode 13, val func loss 0.1881902813911438\n",
      "\n",
      "episode 14, val func loss 0.17099450528621674\n",
      "\n",
      "episode 15, val func loss 0.22947007417678833\n",
      "\n",
      "episode 16, val func loss 0.16849157214164734\n",
      "\n",
      "Val func train loss in epoch 10:0.19007049314677715\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19395442306995392\n",
      "\n",
      "episode 2, val func loss 0.19553454220294952\n",
      "\n",
      "episode 3, val func loss 0.2107604295015335\n",
      "\n",
      "episode 4, val func loss 0.173289492726326\n",
      "\n",
      "episode 5, val func loss 0.2270440310239792\n",
      "\n",
      "episode 6, val func loss 0.21614626049995422\n",
      "\n",
      "episode 7, val func loss 0.1697191298007965\n",
      "\n",
      "episode 8, val func loss 0.1783750057220459\n",
      "\n",
      "episode 9, val func loss 0.1692388355731964\n",
      "\n",
      "episode 10, val func loss 0.18913018703460693\n",
      "\n",
      "episode 11, val func loss 0.22617164254188538\n",
      "\n",
      "episode 12, val func loss 0.16629979014396667\n",
      "\n",
      "episode 13, val func loss 0.18872307240962982\n",
      "\n",
      "episode 14, val func loss 0.18815816938877106\n",
      "\n",
      "episode 15, val func loss 0.18830087780952454\n",
      "\n",
      "episode 16, val func loss 0.15350422263145447\n",
      "\n",
      "Val func train loss in epoch 11:0.18964688200503588\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18856003880500793\n",
      "\n",
      "episode 2, val func loss 0.166204035282135\n",
      "\n",
      "episode 3, val func loss 0.22730796039104462\n",
      "\n",
      "episode 4, val func loss 0.17085711658000946\n",
      "\n",
      "episode 5, val func loss 0.17672783136367798\n",
      "\n",
      "episode 6, val func loss 0.19460931420326233\n",
      "\n",
      "episode 7, val func loss 0.2168837934732437\n",
      "\n",
      "episode 8, val func loss 0.16898950934410095\n",
      "\n",
      "episode 9, val func loss 0.21093615889549255\n",
      "\n",
      "episode 10, val func loss 0.18707555532455444\n",
      "\n",
      "episode 11, val func loss 0.1890401840209961\n",
      "\n",
      "episode 12, val func loss 0.1568925827741623\n",
      "\n",
      "episode 13, val func loss 0.22809122502803802\n",
      "\n",
      "episode 14, val func loss 0.19492946565151215\n",
      "\n",
      "episode 15, val func loss 0.1876204013824463\n",
      "\n",
      "episode 16, val func loss 0.16756586730480194\n",
      "\n",
      "Val func train loss in epoch 12:0.18951818998903036\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18891699612140656\n",
      "\n",
      "episode 2, val func loss 0.166632279753685\n",
      "\n",
      "episode 3, val func loss 0.16749364137649536\n",
      "\n",
      "episode 4, val func loss 0.2178049087524414\n",
      "\n",
      "episode 5, val func loss 0.1533159762620926\n",
      "\n",
      "episode 6, val func loss 0.1650811731815338\n",
      "\n",
      "episode 7, val func loss 0.23752430081367493\n",
      "\n",
      "episode 8, val func loss 0.19625332951545715\n",
      "\n",
      "episode 9, val func loss 0.18826012313365936\n",
      "\n",
      "episode 10, val func loss 0.18798977136611938\n",
      "\n",
      "episode 11, val func loss 0.18843957781791687\n",
      "\n",
      "episode 12, val func loss 0.1777239292860031\n",
      "\n",
      "episode 13, val func loss 0.19406169652938843\n",
      "\n",
      "episode 14, val func loss 0.17397058010101318\n",
      "\n",
      "episode 15, val func loss 0.21005988121032715\n",
      "\n",
      "episode 16, val func loss 0.22081279754638672\n",
      "\n",
      "Val func train loss in epoch 13:0.18964631017297506\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18796294927597046\n",
      "\n",
      "episode 2, val func loss 0.1728687882423401\n",
      "\n",
      "episode 3, val func loss 0.17093977332115173\n",
      "\n",
      "episode 4, val func loss 0.16940197348594666\n",
      "\n",
      "episode 5, val func loss 0.15591368079185486\n",
      "\n",
      "episode 6, val func loss 0.1770629733800888\n",
      "\n",
      "episode 7, val func loss 0.18897700309753418\n",
      "\n",
      "episode 8, val func loss 0.1703096479177475\n",
      "\n",
      "episode 9, val func loss 0.24171489477157593\n",
      "\n",
      "episode 10, val func loss 0.23600441217422485\n",
      "\n",
      "episode 11, val func loss 0.1891395002603531\n",
      "\n",
      "episode 12, val func loss 0.1883668452501297\n",
      "\n",
      "episode 13, val func loss 0.195443257689476\n",
      "\n",
      "episode 14, val func loss 0.1938406527042389\n",
      "\n",
      "episode 15, val func loss 0.21050171554088593\n",
      "\n",
      "episode 16, val func loss 0.21976371109485626\n",
      "\n",
      "Val func train loss in epoch 14:0.19176323618739843\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.21124239265918732\n",
      "\n",
      "episode 2, val func loss 0.17494168877601624\n",
      "\n",
      "episode 3, val func loss 0.1752798706293106\n",
      "\n",
      "episode 4, val func loss 0.17900100350379944\n",
      "\n",
      "episode 5, val func loss 0.1868370771408081\n",
      "\n",
      "episode 6, val func loss 0.18848340213298798\n",
      "\n",
      "episode 7, val func loss 0.15450963377952576\n",
      "\n",
      "episode 8, val func loss 0.18823489546775818\n",
      "\n",
      "episode 9, val func loss 0.19716648757457733\n",
      "\n",
      "episode 10, val func loss 0.2192797213792801\n",
      "\n",
      "episode 11, val func loss 0.17097418010234833\n",
      "\n",
      "episode 12, val func loss 0.19098809361457825\n",
      "\n",
      "episode 13, val func loss 0.19689790904521942\n",
      "\n",
      "episode 14, val func loss 0.2247815728187561\n",
      "\n",
      "episode 15, val func loss 0.1734766811132431\n",
      "\n",
      "episode 16, val func loss 0.22435611486434937\n",
      "\n",
      "Val func train loss in epoch 15:0.1910281702876091\n",
      "***********************TIME WAS 4.918191738923391 min*****************************\n",
      "\n",
      "**********************ROUND 55 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.011730169877409935\n",
      "\n",
      "episode 2, policy loss 0.057312771677970886\n",
      "\n",
      "episode 3, policy loss -0.016619529575109482\n",
      "\n",
      "episode 4, policy loss 0.05543406680226326\n",
      "\n",
      "episode 5, policy loss 0.0343424491584301\n",
      "\n",
      "episode 6, policy loss 0.007626844570040703\n",
      "\n",
      "episode 7, policy loss 0.01795083098113537\n",
      "\n",
      "episode 8, policy loss 0.05866894870996475\n",
      "\n",
      "episode 9, policy loss -0.024569230154156685\n",
      "\n",
      "episode 10, policy loss -0.020253457129001617\n",
      "\n",
      "episode 11, policy loss 0.028005044907331467\n",
      "\n",
      "episode 12, policy loss 0.04352140054106712\n",
      "\n",
      "episode 13, policy loss 0.025406548753380775\n",
      "\n",
      "episode 14, policy loss 0.052937425673007965\n",
      "\n",
      "episode 15, policy loss 0.04023878648877144\n",
      "\n",
      "episode 16, policy loss 0.029740722849965096\n",
      "\n",
      "Policy train loss in epoch 0:0.025092112133279443\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.053264036774635315\n",
      "\n",
      "episode 2, policy loss 0.039832375943660736\n",
      "\n",
      "episode 3, policy loss 0.054637644439935684\n",
      "\n",
      "episode 4, policy loss 0.009584320709109306\n",
      "\n",
      "episode 5, policy loss -0.026132242754101753\n",
      "\n",
      "episode 6, policy loss 0.05129595100879669\n",
      "\n",
      "episode 7, policy loss 0.04330863803625107\n",
      "\n",
      "episode 8, policy loss 0.025042589753866196\n",
      "\n",
      "episode 9, policy loss 0.03336343541741371\n",
      "\n",
      "episode 10, policy loss -0.021123019978404045\n",
      "\n",
      "episode 11, policy loss 0.054969217628240585\n",
      "\n",
      "episode 12, policy loss 0.007394194137305021\n",
      "\n",
      "episode 13, policy loss 0.017036940902471542\n",
      "\n",
      "episode 14, policy loss 0.02922969125211239\n",
      "\n",
      "episode 15, policy loss 0.029687700793147087\n",
      "\n",
      "episode 16, policy loss -0.017987865954637527\n",
      "\n",
      "Policy train loss in epoch 1:0.023962725506862625\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.05587834119796753\n",
      "\n",
      "episode 2, policy loss 0.05178031697869301\n",
      "\n",
      "episode 3, policy loss 0.009124409407377243\n",
      "\n",
      "episode 4, policy loss 0.02962232567369938\n",
      "\n",
      "episode 5, policy loss 0.055584777146577835\n",
      "\n",
      "episode 6, policy loss -0.026567872613668442\n",
      "\n",
      "episode 7, policy loss 0.03861566632986069\n",
      "\n",
      "episode 8, policy loss 0.024523736909031868\n",
      "\n",
      "episode 9, policy loss 0.016585959121584892\n",
      "\n",
      "episode 10, policy loss 0.05235646665096283\n",
      "\n",
      "episode 11, policy loss 0.0078659076243639\n",
      "\n",
      "episode 12, policy loss 0.04228084906935692\n",
      "\n",
      "episode 13, policy loss -0.020917175337672234\n",
      "\n",
      "episode 14, policy loss 0.02884889952838421\n",
      "\n",
      "episode 15, policy loss 0.03449702262878418\n",
      "\n",
      "episode 16, policy loss -0.018932808190584183\n",
      "\n",
      "Policy train loss in epoch 2:0.023821676382794976\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.03844289109110832\n",
      "\n",
      "episode 2, policy loss 0.05205834284424782\n",
      "\n",
      "episode 3, policy loss 0.04402106627821922\n",
      "\n",
      "episode 4, policy loss 0.028953950852155685\n",
      "\n",
      "episode 5, policy loss 0.052642736583948135\n",
      "\n",
      "episode 6, policy loss -0.021161526441574097\n",
      "\n",
      "episode 7, policy loss -0.020601538941264153\n",
      "\n",
      "episode 8, policy loss 0.008514951914548874\n",
      "\n",
      "episode 9, policy loss 0.024373924359679222\n",
      "\n",
      "episode 10, policy loss -0.027054738253355026\n",
      "\n",
      "episode 11, policy loss 0.054208431392908096\n",
      "\n",
      "episode 12, policy loss 0.0077291266061365604\n",
      "\n",
      "episode 13, policy loss 0.017081748694181442\n",
      "\n",
      "episode 14, policy loss 0.05569447949528694\n",
      "\n",
      "episode 15, policy loss 0.034038763493299484\n",
      "\n",
      "episode 16, policy loss 0.029532525688409805\n",
      "\n",
      "Policy train loss in epoch 3:0.02365469597862102\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1872635781764984\n",
      "\n",
      "episode 2, val func loss 0.17574037611484528\n",
      "\n",
      "episode 3, val func loss 0.1990603804588318\n",
      "\n",
      "episode 4, val func loss 0.21055267751216888\n",
      "\n",
      "episode 5, val func loss 0.1799623668193817\n",
      "\n",
      "episode 6, val func loss 0.18143479526042938\n",
      "\n",
      "episode 7, val func loss 0.18796266615390778\n",
      "\n",
      "episode 8, val func loss 0.21052925288677216\n",
      "\n",
      "episode 9, val func loss 0.17998769879341125\n",
      "\n",
      "episode 10, val func loss 0.17555157840251923\n",
      "\n",
      "episode 11, val func loss 0.1821860820055008\n",
      "\n",
      "episode 12, val func loss 0.20172476768493652\n",
      "\n",
      "episode 13, val func loss 0.17669802904129028\n",
      "\n",
      "episode 14, val func loss 0.23256826400756836\n",
      "\n",
      "episode 15, val func loss 0.16678974032402039\n",
      "\n",
      "episode 16, val func loss 0.19455766677856445\n",
      "\n",
      "Val func train loss in epoch 0:0.19016062002629042\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1814122051000595\n",
      "\n",
      "episode 2, val func loss 0.23055493831634521\n",
      "\n",
      "episode 3, val func loss 0.19857463240623474\n",
      "\n",
      "episode 4, val func loss 0.1836451292037964\n",
      "\n",
      "episode 5, val func loss 0.17048758268356323\n",
      "\n",
      "episode 6, val func loss 0.17663002014160156\n",
      "\n",
      "episode 7, val func loss 0.16648751497268677\n",
      "\n",
      "episode 8, val func loss 0.19553618133068085\n",
      "\n",
      "episode 9, val func loss 0.18772096931934357\n",
      "\n",
      "episode 10, val func loss 0.2132793813943863\n",
      "\n",
      "episode 11, val func loss 0.18307901918888092\n",
      "\n",
      "episode 12, val func loss 0.17975649237632751\n",
      "\n",
      "episode 13, val func loss 0.2017436921596527\n",
      "\n",
      "episode 14, val func loss 0.20680266618728638\n",
      "\n",
      "episode 15, val func loss 0.18507695198059082\n",
      "\n",
      "episode 16, val func loss 0.17784836888313293\n",
      "\n",
      "Val func train loss in epoch 1:0.1899147341027856\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18151333928108215\n",
      "\n",
      "episode 2, val func loss 0.1831532120704651\n",
      "\n",
      "episode 3, val func loss 0.1818256676197052\n",
      "\n",
      "episode 4, val func loss 0.1956377476453781\n",
      "\n",
      "episode 5, val func loss 0.16647417843341827\n",
      "\n",
      "episode 6, val func loss 0.17627015709877014\n",
      "\n",
      "episode 7, val func loss 0.17711208760738373\n",
      "\n",
      "episode 8, val func loss 0.19886519014835358\n",
      "\n",
      "episode 9, val func loss 0.18809667229652405\n",
      "\n",
      "episode 10, val func loss 0.16940385103225708\n",
      "\n",
      "episode 11, val func loss 0.20194211602210999\n",
      "\n",
      "episode 12, val func loss 0.2320312112569809\n",
      "\n",
      "episode 13, val func loss 0.20673426985740662\n",
      "\n",
      "episode 14, val func loss 0.18171298503875732\n",
      "\n",
      "episode 15, val func loss 0.1878541111946106\n",
      "\n",
      "episode 16, val func loss 0.2097192406654358\n",
      "\n",
      "Val func train loss in epoch 2:0.1898966273292899\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.22997865080833435\n",
      "\n",
      "episode 2, val func loss 0.20964553952217102\n",
      "\n",
      "episode 3, val func loss 0.20101849734783173\n",
      "\n",
      "episode 4, val func loss 0.17224140465259552\n",
      "\n",
      "episode 5, val func loss 0.18386542797088623\n",
      "\n",
      "episode 6, val func loss 0.1762308031320572\n",
      "\n",
      "episode 7, val func loss 0.20807068049907684\n",
      "\n",
      "episode 8, val func loss 0.17929388582706451\n",
      "\n",
      "episode 9, val func loss 0.17642216384410858\n",
      "\n",
      "episode 10, val func loss 0.1810106486082077\n",
      "\n",
      "episode 11, val func loss 0.16609515249729156\n",
      "\n",
      "episode 12, val func loss 0.18736320734024048\n",
      "\n",
      "episode 13, val func loss 0.1956537961959839\n",
      "\n",
      "episode 14, val func loss 0.19840414822101593\n",
      "\n",
      "episode 15, val func loss 0.18166661262512207\n",
      "\n",
      "episode 16, val func loss 0.18012386560440063\n",
      "\n",
      "Val func train loss in epoch 3:0.18919278029352427\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.198017418384552\n",
      "\n",
      "episode 2, val func loss 0.16972948610782623\n",
      "\n",
      "episode 3, val func loss 0.19531475007534027\n",
      "\n",
      "episode 4, val func loss 0.1810869425535202\n",
      "\n",
      "episode 5, val func loss 0.20931151509284973\n",
      "\n",
      "episode 6, val func loss 0.18710188567638397\n",
      "\n",
      "episode 7, val func loss 0.1834639459848404\n",
      "\n",
      "episode 8, val func loss 0.21130143105983734\n",
      "\n",
      "episode 9, val func loss 0.17757980525493622\n",
      "\n",
      "episode 10, val func loss 0.17646093666553497\n",
      "\n",
      "episode 11, val func loss 0.16701912879943848\n",
      "\n",
      "episode 12, val func loss 0.18147607147693634\n",
      "\n",
      "episode 13, val func loss 0.20083247125148773\n",
      "\n",
      "episode 14, val func loss 0.1819573938846588\n",
      "\n",
      "episode 15, val func loss 0.17952309548854828\n",
      "\n",
      "episode 16, val func loss 0.2336466908454895\n",
      "\n",
      "Val func train loss in epoch 4:0.18961393553763628\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17583951354026794\n",
      "\n",
      "episode 2, val func loss 0.21177035570144653\n",
      "\n",
      "episode 3, val func loss 0.2013607621192932\n",
      "\n",
      "episode 4, val func loss 0.20718292891979218\n",
      "\n",
      "episode 5, val func loss 0.18362517654895782\n",
      "\n",
      "episode 6, val func loss 0.18037372827529907\n",
      "\n",
      "episode 7, val func loss 0.1730467677116394\n",
      "\n",
      "episode 8, val func loss 0.16796080768108368\n",
      "\n",
      "episode 9, val func loss 0.18070141971111298\n",
      "\n",
      "episode 10, val func loss 0.19784227013587952\n",
      "\n",
      "episode 11, val func loss 0.1817343384027481\n",
      "\n",
      "episode 12, val func loss 0.19630268216133118\n",
      "\n",
      "episode 13, val func loss 0.23614512383937836\n",
      "\n",
      "episode 14, val func loss 0.18031340837478638\n",
      "\n",
      "episode 15, val func loss 0.17700114846229553\n",
      "\n",
      "episode 16, val func loss 0.1877204328775406\n",
      "\n",
      "Val func train loss in epoch 5:0.18993255402892828\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17951086163520813\n",
      "\n",
      "episode 2, val func loss 0.1802874505519867\n",
      "\n",
      "episode 3, val func loss 0.18688488006591797\n",
      "\n",
      "episode 4, val func loss 0.198177769780159\n",
      "\n",
      "episode 5, val func loss 0.1826433539390564\n",
      "\n",
      "episode 6, val func loss 0.20190377533435822\n",
      "\n",
      "episode 7, val func loss 0.17077602446079254\n",
      "\n",
      "episode 8, val func loss 0.1818360835313797\n",
      "\n",
      "episode 9, val func loss 0.1949598342180252\n",
      "\n",
      "episode 10, val func loss 0.23349452018737793\n",
      "\n",
      "episode 11, val func loss 0.1663023680448532\n",
      "\n",
      "episode 12, val func loss 0.21197274327278137\n",
      "\n",
      "episode 13, val func loss 0.17559383809566498\n",
      "\n",
      "episode 14, val func loss 0.17685644328594208\n",
      "\n",
      "episode 15, val func loss 0.20684093236923218\n",
      "\n",
      "episode 16, val func loss 0.182822123169899\n",
      "\n",
      "Val func train loss in epoch 6:0.18942893762141466\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.23111696541309357\n",
      "\n",
      "episode 2, val func loss 0.21033629775047302\n",
      "\n",
      "episode 3, val func loss 0.1839745193719864\n",
      "\n",
      "episode 4, val func loss 0.1843937188386917\n",
      "\n",
      "episode 5, val func loss 0.2066122442483902\n",
      "\n",
      "episode 6, val func loss 0.18668602406978607\n",
      "\n",
      "episode 7, val func loss 0.17134588956832886\n",
      "\n",
      "episode 8, val func loss 0.18075506389141083\n",
      "\n",
      "episode 9, val func loss 0.17987176775932312\n",
      "\n",
      "episode 10, val func loss 0.20161212980747223\n",
      "\n",
      "episode 11, val func loss 0.196417436003685\n",
      "\n",
      "episode 12, val func loss 0.16644296050071716\n",
      "\n",
      "episode 13, val func loss 0.18085803091526031\n",
      "\n",
      "episode 14, val func loss 0.19859109818935394\n",
      "\n",
      "episode 15, val func loss 0.17579619586467743\n",
      "\n",
      "episode 16, val func loss 0.17640933394432068\n",
      "\n",
      "Val func train loss in epoch 7:0.18945122975856066\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.23380622267723083\n",
      "\n",
      "episode 2, val func loss 0.18035802245140076\n",
      "\n",
      "episode 3, val func loss 0.2105027288198471\n",
      "\n",
      "episode 4, val func loss 0.1840732842683792\n",
      "\n",
      "episode 5, val func loss 0.17966195940971375\n",
      "\n",
      "episode 6, val func loss 0.19447685778141022\n",
      "\n",
      "episode 7, val func loss 0.17631830275058746\n",
      "\n",
      "episode 8, val func loss 0.17707976698875427\n",
      "\n",
      "episode 9, val func loss 0.18299277126789093\n",
      "\n",
      "episode 10, val func loss 0.18727679550647736\n",
      "\n",
      "episode 11, val func loss 0.19796445965766907\n",
      "\n",
      "episode 12, val func loss 0.1663282811641693\n",
      "\n",
      "episode 13, val func loss 0.18184974789619446\n",
      "\n",
      "episode 14, val func loss 0.16886450350284576\n",
      "\n",
      "episode 15, val func loss 0.20301970839500427\n",
      "\n",
      "episode 16, val func loss 0.21053583920001984\n",
      "\n",
      "Val func train loss in epoch 8:0.18969432823359966\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1831514984369278\n",
      "\n",
      "episode 2, val func loss 0.20195451378822327\n",
      "\n",
      "episode 3, val func loss 0.18095949292182922\n",
      "\n",
      "episode 4, val func loss 0.16760416328907013\n",
      "\n",
      "episode 5, val func loss 0.17591649293899536\n",
      "\n",
      "episode 6, val func loss 0.18224084377288818\n",
      "\n",
      "episode 7, val func loss 0.18186748027801514\n",
      "\n",
      "episode 8, val func loss 0.23347258567810059\n",
      "\n",
      "episode 9, val func loss 0.18001481890678406\n",
      "\n",
      "episode 10, val func loss 0.19845713675022125\n",
      "\n",
      "episode 11, val func loss 0.20885705947875977\n",
      "\n",
      "episode 12, val func loss 0.19501255452632904\n",
      "\n",
      "episode 13, val func loss 0.18665006756782532\n",
      "\n",
      "episode 14, val func loss 0.20969001948833466\n",
      "\n",
      "episode 15, val func loss 0.1795646697282791\n",
      "\n",
      "episode 16, val func loss 0.1740962713956833\n",
      "\n",
      "Val func train loss in epoch 9:0.18996935430914164\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.17217427492141724\n",
      "\n",
      "episode 2, val func loss 0.18665176630020142\n",
      "\n",
      "episode 3, val func loss 0.19835972785949707\n",
      "\n",
      "episode 4, val func loss 0.21318069100379944\n",
      "\n",
      "episode 5, val func loss 0.23423495888710022\n",
      "\n",
      "episode 6, val func loss 0.19562192261219025\n",
      "\n",
      "episode 7, val func loss 0.20098252594470978\n",
      "\n",
      "episode 8, val func loss 0.20675696432590485\n",
      "\n",
      "episode 9, val func loss 0.18846119940280914\n",
      "\n",
      "episode 10, val func loss 0.18393222987651825\n",
      "\n",
      "episode 11, val func loss 0.17931482195854187\n",
      "\n",
      "episode 12, val func loss 0.1798120141029358\n",
      "\n",
      "episode 13, val func loss 0.16559986770153046\n",
      "\n",
      "episode 14, val func loss 0.17676660418510437\n",
      "\n",
      "episode 15, val func loss 0.18369753658771515\n",
      "\n",
      "episode 16, val func loss 0.1758507490158081\n",
      "\n",
      "Val func train loss in epoch 10:0.19008736591786146\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18651632964611053\n",
      "\n",
      "episode 2, val func loss 0.1811756044626236\n",
      "\n",
      "episode 3, val func loss 0.23182524740695953\n",
      "\n",
      "episode 4, val func loss 0.17110244929790497\n",
      "\n",
      "episode 5, val func loss 0.17976681888103485\n",
      "\n",
      "episode 6, val func loss 0.17583739757537842\n",
      "\n",
      "episode 7, val func loss 0.2127315253019333\n",
      "\n",
      "episode 8, val func loss 0.17619048058986664\n",
      "\n",
      "episode 9, val func loss 0.18312734365463257\n",
      "\n",
      "episode 10, val func loss 0.18331515789031982\n",
      "\n",
      "episode 11, val func loss 0.19495649635791779\n",
      "\n",
      "episode 12, val func loss 0.19808238744735718\n",
      "\n",
      "episode 13, val func loss 0.16632422804832458\n",
      "\n",
      "episode 14, val func loss 0.18100659549236298\n",
      "\n",
      "episode 15, val func loss 0.21282412111759186\n",
      "\n",
      "episode 16, val func loss 0.2020866870880127\n",
      "\n",
      "Val func train loss in epoch 11:0.1898043043911457\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.20809701085090637\n",
      "\n",
      "episode 2, val func loss 0.1800992786884308\n",
      "\n",
      "episode 3, val func loss 0.17358604073524475\n",
      "\n",
      "episode 4, val func loss 0.21008753776550293\n",
      "\n",
      "episode 5, val func loss 0.18285402655601501\n",
      "\n",
      "episode 6, val func loss 0.1827777773141861\n",
      "\n",
      "episode 7, val func loss 0.18668486177921295\n",
      "\n",
      "episode 8, val func loss 0.1981544941663742\n",
      "\n",
      "episode 9, val func loss 0.17995208501815796\n",
      "\n",
      "episode 10, val func loss 0.19609397649765015\n",
      "\n",
      "episode 11, val func loss 0.18120986223220825\n",
      "\n",
      "episode 12, val func loss 0.2021074742078781\n",
      "\n",
      "episode 13, val func loss 0.2333887666463852\n",
      "\n",
      "episode 14, val func loss 0.17697878181934357\n",
      "\n",
      "episode 15, val func loss 0.16746827960014343\n",
      "\n",
      "episode 16, val func loss 0.17684750258922577\n",
      "\n",
      "Val func train loss in epoch 12:0.1897742347791791\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.17962656915187836\n",
      "\n",
      "episode 2, val func loss 0.1830078661441803\n",
      "\n",
      "episode 3, val func loss 0.18698643147945404\n",
      "\n",
      "episode 4, val func loss 0.1953190565109253\n",
      "\n",
      "episode 5, val func loss 0.18212196230888367\n",
      "\n",
      "episode 6, val func loss 0.17960436642169952\n",
      "\n",
      "episode 7, val func loss 0.1812281459569931\n",
      "\n",
      "episode 8, val func loss 0.21047383546829224\n",
      "\n",
      "episode 9, val func loss 0.20234046876430511\n",
      "\n",
      "episode 10, val func loss 0.23319274187088013\n",
      "\n",
      "episode 11, val func loss 0.1985478699207306\n",
      "\n",
      "episode 12, val func loss 0.1720360666513443\n",
      "\n",
      "episode 13, val func loss 0.1767847090959549\n",
      "\n",
      "episode 14, val func loss 0.17729000747203827\n",
      "\n",
      "episode 15, val func loss 0.21050801873207092\n",
      "\n",
      "episode 16, val func loss 0.16675955057144165\n",
      "\n",
      "Val func train loss in epoch 13:0.18973922915756702\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.21118777990341187\n",
      "\n",
      "episode 2, val func loss 0.1756533980369568\n",
      "\n",
      "episode 3, val func loss 0.18083585798740387\n",
      "\n",
      "episode 4, val func loss 0.18678070604801178\n",
      "\n",
      "episode 5, val func loss 0.17645014822483063\n",
      "\n",
      "episode 6, val func loss 0.18164262175559998\n",
      "\n",
      "episode 7, val func loss 0.1687941551208496\n",
      "\n",
      "episode 8, val func loss 0.19581811130046844\n",
      "\n",
      "episode 9, val func loss 0.19877703487873077\n",
      "\n",
      "episode 10, val func loss 0.17988935112953186\n",
      "\n",
      "episode 11, val func loss 0.18094521760940552\n",
      "\n",
      "episode 12, val func loss 0.2335464209318161\n",
      "\n",
      "episode 13, val func loss 0.16616131365299225\n",
      "\n",
      "episode 14, val func loss 0.20137330889701843\n",
      "\n",
      "episode 15, val func loss 0.1833532154560089\n",
      "\n",
      "episode 16, val func loss 0.2069811224937439\n",
      "\n",
      "Val func train loss in epoch 14:0.1892618602141738\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20980125665664673\n",
      "\n",
      "episode 2, val func loss 0.1804913431406021\n",
      "\n",
      "episode 3, val func loss 0.18559424579143524\n",
      "\n",
      "episode 4, val func loss 0.1790899634361267\n",
      "\n",
      "episode 5, val func loss 0.1763361692428589\n",
      "\n",
      "episode 6, val func loss 0.1805610954761505\n",
      "\n",
      "episode 7, val func loss 0.2333536595106125\n",
      "\n",
      "episode 8, val func loss 0.19638414680957794\n",
      "\n",
      "episode 9, val func loss 0.18101352453231812\n",
      "\n",
      "episode 10, val func loss 0.20230886340141296\n",
      "\n",
      "episode 11, val func loss 0.16868707537651062\n",
      "\n",
      "episode 12, val func loss 0.19833223521709442\n",
      "\n",
      "episode 13, val func loss 0.20953606069087982\n",
      "\n",
      "episode 14, val func loss 0.1661706566810608\n",
      "\n",
      "episode 15, val func loss 0.1872251033782959\n",
      "\n",
      "episode 16, val func loss 0.18263478577136993\n",
      "\n",
      "Val func train loss in epoch 15:0.18984501156955957\n",
      "***********************TIME WAS 4.919833238919576 min*****************************\n",
      "\n",
      "**********************ROUND 56 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.014088278636336327\n",
      "\n",
      "episode 2, policy loss 0.020494811236858368\n",
      "\n",
      "episode 3, policy loss 0.006821401417255402\n",
      "\n",
      "episode 4, policy loss -0.03732380270957947\n",
      "\n",
      "episode 5, policy loss -0.002579391933977604\n",
      "\n",
      "episode 6, policy loss -0.05377268046140671\n",
      "\n",
      "episode 7, policy loss -0.0033278174232691526\n",
      "\n",
      "episode 8, policy loss 0.02380291186273098\n",
      "\n",
      "episode 9, policy loss -0.007154695689678192\n",
      "\n",
      "episode 10, policy loss -0.0014595574466511607\n",
      "\n",
      "episode 11, policy loss -0.044291261583566666\n",
      "\n",
      "episode 12, policy loss -0.044172678142786026\n",
      "\n",
      "episode 13, policy loss -0.03808408975601196\n",
      "\n",
      "episode 14, policy loss -0.03877299278974533\n",
      "\n",
      "episode 15, policy loss -0.017644822597503662\n",
      "\n",
      "episode 16, policy loss -0.008442859165370464\n",
      "\n",
      "Policy train loss in epoch 0:-0.016249737738689873\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.043914638459682465\n",
      "\n",
      "episode 2, policy loss -0.03992301598191261\n",
      "\n",
      "episode 3, policy loss 0.016080347821116447\n",
      "\n",
      "episode 4, policy loss -0.039420612156391144\n",
      "\n",
      "episode 5, policy loss -0.0025800077710300684\n",
      "\n",
      "episode 6, policy loss -0.039173565804958344\n",
      "\n",
      "episode 7, policy loss 0.020360268652439117\n",
      "\n",
      "episode 8, policy loss -0.054097980260849\n",
      "\n",
      "episode 9, policy loss -0.006083821412175894\n",
      "\n",
      "episode 10, policy loss -0.01161025557667017\n",
      "\n",
      "episode 11, policy loss -0.004659151192754507\n",
      "\n",
      "episode 12, policy loss -0.04242563620209694\n",
      "\n",
      "episode 13, policy loss -0.016403036192059517\n",
      "\n",
      "episode 14, policy loss -0.01757226325571537\n",
      "\n",
      "episode 15, policy loss -0.0069872597232460976\n",
      "\n",
      "episode 16, policy loss 0.0016893765423446894\n",
      "\n",
      "Policy train loss in epoch 1:-0.017920078185852617\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.0059446049854159355\n",
      "\n",
      "episode 2, policy loss -0.011302486062049866\n",
      "\n",
      "episode 3, policy loss -0.0034949863329529762\n",
      "\n",
      "episode 4, policy loss -0.004331002477556467\n",
      "\n",
      "episode 5, policy loss -0.007566029205918312\n",
      "\n",
      "episode 6, policy loss 0.0014202563324943185\n",
      "\n",
      "episode 7, policy loss -0.021915674209594727\n",
      "\n",
      "episode 8, policy loss -0.04190614074468613\n",
      "\n",
      "episode 9, policy loss 0.018316684290766716\n",
      "\n",
      "episode 10, policy loss -0.03694172203540802\n",
      "\n",
      "episode 11, policy loss -0.04423961043357849\n",
      "\n",
      "episode 12, policy loss -0.042458001524209976\n",
      "\n",
      "episode 13, policy loss -0.04372570291161537\n",
      "\n",
      "episode 14, policy loss -0.019390739500522614\n",
      "\n",
      "episode 15, policy loss -0.05422759801149368\n",
      "\n",
      "episode 16, policy loss 0.019690141081809998\n",
      "\n",
      "Policy train loss in epoch 2:-0.01862607604562072\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.018429772928357124\n",
      "\n",
      "episode 2, policy loss 0.018728068098425865\n",
      "\n",
      "episode 3, policy loss -0.007745898794382811\n",
      "\n",
      "episode 4, policy loss 0.016367264091968536\n",
      "\n",
      "episode 5, policy loss -0.005211586598306894\n",
      "\n",
      "episode 6, policy loss -0.02221476286649704\n",
      "\n",
      "episode 7, policy loss -0.0025399615988135338\n",
      "\n",
      "episode 8, policy loss -0.008779301308095455\n",
      "\n",
      "episode 9, policy loss -0.04237201809883118\n",
      "\n",
      "episode 10, policy loss -0.03935917466878891\n",
      "\n",
      "episode 11, policy loss -0.05631367489695549\n",
      "\n",
      "episode 12, policy loss -0.004098332021385431\n",
      "\n",
      "episode 13, policy loss -0.045711640268564224\n",
      "\n",
      "episode 14, policy loss -0.04310806468129158\n",
      "\n",
      "episode 15, policy loss -0.04329825937747955\n",
      "\n",
      "episode 16, policy loss 0.000497810251545161\n",
      "\n",
      "Policy train loss in epoch 3:-0.018974331604113104\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.18614917993545532\n",
      "\n",
      "episode 2, val func loss 0.19669976830482483\n",
      "\n",
      "episode 3, val func loss 0.17711469531059265\n",
      "\n",
      "episode 4, val func loss 0.2018485963344574\n",
      "\n",
      "episode 5, val func loss 0.17976658046245575\n",
      "\n",
      "episode 6, val func loss 0.17615380883216858\n",
      "\n",
      "episode 7, val func loss 0.19001594185829163\n",
      "\n",
      "episode 8, val func loss 0.16561636328697205\n",
      "\n",
      "episode 9, val func loss 0.16637377440929413\n",
      "\n",
      "episode 10, val func loss 0.188436359167099\n",
      "\n",
      "episode 11, val func loss 0.1647716462612152\n",
      "\n",
      "episode 12, val func loss 0.18582704663276672\n",
      "\n",
      "episode 13, val func loss 0.20166905224323273\n",
      "\n",
      "episode 14, val func loss 0.18328073620796204\n",
      "\n",
      "episode 15, val func loss 0.20129573345184326\n",
      "\n",
      "episode 16, val func loss 0.20493081212043762\n",
      "\n",
      "Val func train loss in epoch 0:0.1856218809261918\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.20042245090007782\n",
      "\n",
      "episode 2, val func loss 0.18955549597740173\n",
      "\n",
      "episode 3, val func loss 0.18823988735675812\n",
      "\n",
      "episode 4, val func loss 0.18515416979789734\n",
      "\n",
      "episode 5, val func loss 0.19998915493488312\n",
      "\n",
      "episode 6, val func loss 0.19603650271892548\n",
      "\n",
      "episode 7, val func loss 0.1663222461938858\n",
      "\n",
      "episode 8, val func loss 0.20482300221920013\n",
      "\n",
      "episode 9, val func loss 0.1803547441959381\n",
      "\n",
      "episode 10, val func loss 0.17612051963806152\n",
      "\n",
      "episode 11, val func loss 0.16485027968883514\n",
      "\n",
      "episode 12, val func loss 0.2021922618150711\n",
      "\n",
      "episode 13, val func loss 0.16595491766929626\n",
      "\n",
      "episode 14, val func loss 0.17615658044815063\n",
      "\n",
      "episode 15, val func loss 0.18659447133541107\n",
      "\n",
      "episode 16, val func loss 0.18480218946933746\n",
      "\n",
      "Val func train loss in epoch 1:0.18547305464744568\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17664983868598938\n",
      "\n",
      "episode 2, val func loss 0.20165908336639404\n",
      "\n",
      "episode 3, val func loss 0.1665574312210083\n",
      "\n",
      "episode 4, val func loss 0.19764193892478943\n",
      "\n",
      "episode 5, val func loss 0.18365931510925293\n",
      "\n",
      "episode 6, val func loss 0.200934037566185\n",
      "\n",
      "episode 7, val func loss 0.18085208535194397\n",
      "\n",
      "episode 8, val func loss 0.20462071895599365\n",
      "\n",
      "episode 9, val func loss 0.20022191107273102\n",
      "\n",
      "episode 10, val func loss 0.16681303083896637\n",
      "\n",
      "episode 11, val func loss 0.18830499053001404\n",
      "\n",
      "episode 12, val func loss 0.18538203835487366\n",
      "\n",
      "episode 13, val func loss 0.1770470291376114\n",
      "\n",
      "episode 14, val func loss 0.1851731240749359\n",
      "\n",
      "episode 15, val func loss 0.188413605093956\n",
      "\n",
      "episode 16, val func loss 0.16621221601963043\n",
      "\n",
      "Val func train loss in epoch 2:0.18563389964401722\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20161539316177368\n",
      "\n",
      "episode 2, val func loss 0.1659611165523529\n",
      "\n",
      "episode 3, val func loss 0.20662768185138702\n",
      "\n",
      "episode 4, val func loss 0.18313291668891907\n",
      "\n",
      "episode 5, val func loss 0.16423633694648743\n",
      "\n",
      "episode 6, val func loss 0.19766344130039215\n",
      "\n",
      "episode 7, val func loss 0.1797725111246109\n",
      "\n",
      "episode 8, val func loss 0.2010745257139206\n",
      "\n",
      "episode 9, val func loss 0.186340793967247\n",
      "\n",
      "episode 10, val func loss 0.20058350265026093\n",
      "\n",
      "episode 11, val func loss 0.1885027289390564\n",
      "\n",
      "episode 12, val func loss 0.16633087396621704\n",
      "\n",
      "episode 13, val func loss 0.18858088552951813\n",
      "\n",
      "episode 14, val func loss 0.17709560692310333\n",
      "\n",
      "episode 15, val func loss 0.17661194503307343\n",
      "\n",
      "episode 16, val func loss 0.1858060657978058\n",
      "\n",
      "Val func train loss in epoch 3:0.18562102038413286\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18927089869976044\n",
      "\n",
      "episode 2, val func loss 0.16661010682582855\n",
      "\n",
      "episode 3, val func loss 0.16481797397136688\n",
      "\n",
      "episode 4, val func loss 0.18361115455627441\n",
      "\n",
      "episode 5, val func loss 0.16626358032226562\n",
      "\n",
      "episode 6, val func loss 0.19832147657871246\n",
      "\n",
      "episode 7, val func loss 0.20211149752140045\n",
      "\n",
      "episode 8, val func loss 0.18803928792476654\n",
      "\n",
      "episode 9, val func loss 0.20508986711502075\n",
      "\n",
      "episode 10, val func loss 0.17815007269382477\n",
      "\n",
      "episode 11, val func loss 0.18653567135334015\n",
      "\n",
      "episode 12, val func loss 0.20084796845912933\n",
      "\n",
      "episode 13, val func loss 0.201633021235466\n",
      "\n",
      "episode 14, val func loss 0.17766793072223663\n",
      "\n",
      "episode 15, val func loss 0.18013358116149902\n",
      "\n",
      "episode 16, val func loss 0.18449248373508453\n",
      "\n",
      "Val func train loss in epoch 4:0.18584978580474854\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.2035311907529831\n",
      "\n",
      "episode 2, val func loss 0.1656332165002823\n",
      "\n",
      "episode 3, val func loss 0.1895112842321396\n",
      "\n",
      "episode 4, val func loss 0.17651240527629852\n",
      "\n",
      "episode 5, val func loss 0.2018645852804184\n",
      "\n",
      "episode 6, val func loss 0.18593452870845795\n",
      "\n",
      "episode 7, val func loss 0.1656988561153412\n",
      "\n",
      "episode 8, val func loss 0.18401473760604858\n",
      "\n",
      "episode 9, val func loss 0.19657117128372192\n",
      "\n",
      "episode 10, val func loss 0.18048153817653656\n",
      "\n",
      "episode 11, val func loss 0.18846125900745392\n",
      "\n",
      "episode 12, val func loss 0.20495466887950897\n",
      "\n",
      "episode 13, val func loss 0.20021438598632812\n",
      "\n",
      "episode 14, val func loss 0.16731005907058716\n",
      "\n",
      "episode 15, val func loss 0.17728279531002045\n",
      "\n",
      "episode 16, val func loss 0.18505685031414032\n",
      "\n",
      "Val func train loss in epoch 5:0.1858145957812667\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1849175989627838\n",
      "\n",
      "episode 2, val func loss 0.18776309490203857\n",
      "\n",
      "episode 3, val func loss 0.20609155297279358\n",
      "\n",
      "episode 4, val func loss 0.20403634011745453\n",
      "\n",
      "episode 5, val func loss 0.20115531980991364\n",
      "\n",
      "episode 6, val func loss 0.1967398226261139\n",
      "\n",
      "episode 7, val func loss 0.1882820576429367\n",
      "\n",
      "episode 8, val func loss 0.18481260538101196\n",
      "\n",
      "episode 9, val func loss 0.17086581885814667\n",
      "\n",
      "episode 10, val func loss 0.1883877068758011\n",
      "\n",
      "episode 11, val func loss 0.20460332930088043\n",
      "\n",
      "episode 12, val func loss 0.16519798338413239\n",
      "\n",
      "episode 13, val func loss 0.1658548265695572\n",
      "\n",
      "episode 14, val func loss 0.1762576550245285\n",
      "\n",
      "episode 15, val func loss 0.18005026876926422\n",
      "\n",
      "episode 16, val func loss 0.17637522518634796\n",
      "\n",
      "Val func train loss in epoch 6:0.18633695039898157\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18795453011989594\n",
      "\n",
      "episode 2, val func loss 0.16528043150901794\n",
      "\n",
      "episode 3, val func loss 0.20093078911304474\n",
      "\n",
      "episode 4, val func loss 0.20112572610378265\n",
      "\n",
      "episode 5, val func loss 0.18365027010440826\n",
      "\n",
      "episode 6, val func loss 0.2048131376504898\n",
      "\n",
      "episode 7, val func loss 0.16643701493740082\n",
      "\n",
      "episode 8, val func loss 0.168424591422081\n",
      "\n",
      "episode 9, val func loss 0.19702932238578796\n",
      "\n",
      "episode 10, val func loss 0.20115773379802704\n",
      "\n",
      "episode 11, val func loss 0.18951964378356934\n",
      "\n",
      "episode 12, val func loss 0.17675557732582092\n",
      "\n",
      "episode 13, val func loss 0.17650488018989563\n",
      "\n",
      "episode 14, val func loss 0.1854408085346222\n",
      "\n",
      "episode 15, val func loss 0.18484622240066528\n",
      "\n",
      "episode 16, val func loss 0.17953504621982574\n",
      "\n",
      "Val func train loss in epoch 7:0.18558785784989595\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17674899101257324\n",
      "\n",
      "episode 2, val func loss 0.18421795964241028\n",
      "\n",
      "episode 3, val func loss 0.20269593596458435\n",
      "\n",
      "episode 4, val func loss 0.1653640866279602\n",
      "\n",
      "episode 5, val func loss 0.20571115612983704\n",
      "\n",
      "episode 6, val func loss 0.18599779903888702\n",
      "\n",
      "episode 7, val func loss 0.18677271902561188\n",
      "\n",
      "episode 8, val func loss 0.18838684260845184\n",
      "\n",
      "episode 9, val func loss 0.2007666975259781\n",
      "\n",
      "episode 10, val func loss 0.18037742376327515\n",
      "\n",
      "episode 11, val func loss 0.17667517066001892\n",
      "\n",
      "episode 12, val func loss 0.1975170075893402\n",
      "\n",
      "episode 13, val func loss 0.16493329405784607\n",
      "\n",
      "episode 14, val func loss 0.18976406753063202\n",
      "\n",
      "episode 15, val func loss 0.20136339962482452\n",
      "\n",
      "episode 16, val func loss 0.1667952984571457\n",
      "\n",
      "Val func train loss in epoch 8:0.18588049057871103\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17603443562984467\n",
      "\n",
      "episode 2, val func loss 0.1883888691663742\n",
      "\n",
      "episode 3, val func loss 0.17655105888843536\n",
      "\n",
      "episode 4, val func loss 0.20146696269512177\n",
      "\n",
      "episode 5, val func loss 0.18483711779117584\n",
      "\n",
      "episode 6, val func loss 0.20232026278972626\n",
      "\n",
      "episode 7, val func loss 0.166970893740654\n",
      "\n",
      "episode 8, val func loss 0.18318666517734528\n",
      "\n",
      "episode 9, val func loss 0.2020515352487564\n",
      "\n",
      "episode 10, val func loss 0.2052631676197052\n",
      "\n",
      "episode 11, val func loss 0.18564827740192413\n",
      "\n",
      "episode 12, val func loss 0.1966714709997177\n",
      "\n",
      "episode 13, val func loss 0.1662265807390213\n",
      "\n",
      "episode 14, val func loss 0.16722409427165985\n",
      "\n",
      "episode 15, val func loss 0.18074770271778107\n",
      "\n",
      "episode 16, val func loss 0.1883857250213623\n",
      "\n",
      "Val func train loss in epoch 9:0.18574842624366283\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20536218583583832\n",
      "\n",
      "episode 2, val func loss 0.1763845980167389\n",
      "\n",
      "episode 3, val func loss 0.1666613519191742\n",
      "\n",
      "episode 4, val func loss 0.16460523009300232\n",
      "\n",
      "episode 5, val func loss 0.20274348556995392\n",
      "\n",
      "episode 6, val func loss 0.18614964187145233\n",
      "\n",
      "episode 7, val func loss 0.16615451872348785\n",
      "\n",
      "episode 8, val func loss 0.18852873146533966\n",
      "\n",
      "episode 9, val func loss 0.1837398111820221\n",
      "\n",
      "episode 10, val func loss 0.1886923611164093\n",
      "\n",
      "episode 11, val func loss 0.18616324663162231\n",
      "\n",
      "episode 12, val func loss 0.1967097669839859\n",
      "\n",
      "episode 13, val func loss 0.18096007406711578\n",
      "\n",
      "episode 14, val func loss 0.20101767778396606\n",
      "\n",
      "episode 15, val func loss 0.2011220008134842\n",
      "\n",
      "episode 16, val func loss 0.17762060463428497\n",
      "\n",
      "Val func train loss in epoch 10:0.18578845541924238\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18568269908428192\n",
      "\n",
      "episode 2, val func loss 0.17681576311588287\n",
      "\n",
      "episode 3, val func loss 0.19832338392734528\n",
      "\n",
      "episode 4, val func loss 0.2014639526605606\n",
      "\n",
      "episode 5, val func loss 0.2013772577047348\n",
      "\n",
      "episode 6, val func loss 0.18028834462165833\n",
      "\n",
      "episode 7, val func loss 0.17720188200473785\n",
      "\n",
      "episode 8, val func loss 0.20517294108867645\n",
      "\n",
      "episode 9, val func loss 0.20084163546562195\n",
      "\n",
      "episode 10, val func loss 0.18792621791362762\n",
      "\n",
      "episode 11, val func loss 0.18684951961040497\n",
      "\n",
      "episode 12, val func loss 0.16687645018100739\n",
      "\n",
      "episode 13, val func loss 0.16619528830051422\n",
      "\n",
      "episode 14, val func loss 0.1838179975748062\n",
      "\n",
      "episode 15, val func loss 0.16601936519145966\n",
      "\n",
      "episode 16, val func loss 0.1900615692138672\n",
      "\n",
      "Val func train loss in epoch 11:0.1859321417286992\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.20040547847747803\n",
      "\n",
      "episode 2, val func loss 0.18418285250663757\n",
      "\n",
      "episode 3, val func loss 0.20186010003089905\n",
      "\n",
      "episode 4, val func loss 0.18540439009666443\n",
      "\n",
      "episode 5, val func loss 0.18033944070339203\n",
      "\n",
      "episode 6, val func loss 0.20492225885391235\n",
      "\n",
      "episode 7, val func loss 0.18826022744178772\n",
      "\n",
      "episode 8, val func loss 0.16896399855613708\n",
      "\n",
      "episode 9, val func loss 0.20095252990722656\n",
      "\n",
      "episode 10, val func loss 0.1771557629108429\n",
      "\n",
      "episode 11, val func loss 0.18582670390605927\n",
      "\n",
      "episode 12, val func loss 0.16593070328235626\n",
      "\n",
      "episode 13, val func loss 0.2017371952533722\n",
      "\n",
      "episode 14, val func loss 0.164567768573761\n",
      "\n",
      "episode 15, val func loss 0.17675404250621796\n",
      "\n",
      "episode 16, val func loss 0.18907858431339264\n",
      "\n",
      "Val func train loss in epoch 12:0.18602137733250856\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.197766974568367\n",
      "\n",
      "episode 2, val func loss 0.18008220195770264\n",
      "\n",
      "episode 3, val func loss 0.1857006698846817\n",
      "\n",
      "episode 4, val func loss 0.20489375293254852\n",
      "\n",
      "episode 5, val func loss 0.1838804930448532\n",
      "\n",
      "episode 6, val func loss 0.18813718855381012\n",
      "\n",
      "episode 7, val func loss 0.20184075832366943\n",
      "\n",
      "episode 8, val func loss 0.1886642575263977\n",
      "\n",
      "episode 9, val func loss 0.17702186107635498\n",
      "\n",
      "episode 10, val func loss 0.16583813726902008\n",
      "\n",
      "episode 11, val func loss 0.16566424071788788\n",
      "\n",
      "episode 12, val func loss 0.2025587111711502\n",
      "\n",
      "episode 13, val func loss 0.17657940089702606\n",
      "\n",
      "episode 14, val func loss 0.1664825975894928\n",
      "\n",
      "episode 15, val func loss 0.18507225811481476\n",
      "\n",
      "episode 16, val func loss 0.20345336198806763\n",
      "\n",
      "Val func train loss in epoch 13:0.1858523041009903\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17635656893253326\n",
      "\n",
      "episode 2, val func loss 0.1836385726928711\n",
      "\n",
      "episode 3, val func loss 0.18787647783756256\n",
      "\n",
      "episode 4, val func loss 0.20143426954746246\n",
      "\n",
      "episode 5, val func loss 0.1658996194601059\n",
      "\n",
      "episode 6, val func loss 0.19708935916423798\n",
      "\n",
      "episode 7, val func loss 0.1770932674407959\n",
      "\n",
      "episode 8, val func loss 0.17990393936634064\n",
      "\n",
      "episode 9, val func loss 0.2019856572151184\n",
      "\n",
      "episode 10, val func loss 0.18579035997390747\n",
      "\n",
      "episode 11, val func loss 0.16555051505565643\n",
      "\n",
      "episode 12, val func loss 0.2014303207397461\n",
      "\n",
      "episode 13, val func loss 0.18821588158607483\n",
      "\n",
      "episode 14, val func loss 0.18611611425876617\n",
      "\n",
      "episode 15, val func loss 0.20543676614761353\n",
      "\n",
      "episode 16, val func loss 0.1683562844991684\n",
      "\n",
      "Val func train loss in epoch 14:0.18576087336987257\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1768198013305664\n",
      "\n",
      "episode 2, val func loss 0.2023945450782776\n",
      "\n",
      "episode 3, val func loss 0.1894695907831192\n",
      "\n",
      "episode 4, val func loss 0.16655735671520233\n",
      "\n",
      "episode 5, val func loss 0.19768238067626953\n",
      "\n",
      "episode 6, val func loss 0.18816085159778595\n",
      "\n",
      "episode 7, val func loss 0.16570264101028442\n",
      "\n",
      "episode 8, val func loss 0.18055196106433868\n",
      "\n",
      "episode 9, val func loss 0.20601476728916168\n",
      "\n",
      "episode 10, val func loss 0.1835176944732666\n",
      "\n",
      "episode 11, val func loss 0.16609960794448853\n",
      "\n",
      "episode 12, val func loss 0.20095685124397278\n",
      "\n",
      "episode 13, val func loss 0.18529070913791656\n",
      "\n",
      "episode 14, val func loss 0.20160874724388123\n",
      "\n",
      "episode 15, val func loss 0.18528048694133759\n",
      "\n",
      "episode 16, val func loss 0.17670296132564545\n",
      "\n",
      "Val func train loss in epoch 15:0.18580068461596966\n",
      "***********************TIME WAS 4.925625900427501 min*****************************\n",
      "\n",
      "**********************ROUND 57 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.013250342570245266\n",
      "\n",
      "episode 2, policy loss -0.01975187472999096\n",
      "\n",
      "episode 3, policy loss -0.06358310580253601\n",
      "\n",
      "episode 4, policy loss -0.033824481070041656\n",
      "\n",
      "episode 5, policy loss -0.013122900389134884\n",
      "\n",
      "episode 6, policy loss -0.0708203911781311\n",
      "\n",
      "episode 7, policy loss -0.09216268360614777\n",
      "\n",
      "episode 8, policy loss 0.023960603401064873\n",
      "\n",
      "episode 9, policy loss -0.03937884792685509\n",
      "\n",
      "episode 10, policy loss -0.07142133265733719\n",
      "\n",
      "episode 11, policy loss -0.04399484023451805\n",
      "\n",
      "episode 12, policy loss -0.08723779767751694\n",
      "\n",
      "episode 13, policy loss -0.05574171245098114\n",
      "\n",
      "episode 14, policy loss -0.06973455101251602\n",
      "\n",
      "episode 15, policy loss -0.01228619646281004\n",
      "\n",
      "episode 16, policy loss -0.09753959625959396\n",
      "\n",
      "Policy train loss in epoch 0:-0.0474931281642057\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.024401100352406502\n",
      "\n",
      "episode 2, policy loss -0.054926130920648575\n",
      "\n",
      "episode 3, policy loss -0.04567438364028931\n",
      "\n",
      "episode 4, policy loss -0.016946496441960335\n",
      "\n",
      "episode 5, policy loss -0.07454801350831985\n",
      "\n",
      "episode 6, policy loss -0.039024487137794495\n",
      "\n",
      "episode 7, policy loss -0.09916269034147263\n",
      "\n",
      "episode 8, policy loss -0.09362512826919556\n",
      "\n",
      "episode 9, policy loss -0.016191130504012108\n",
      "\n",
      "episode 10, policy loss -0.013952064327895641\n",
      "\n",
      "episode 11, policy loss -0.032577890902757645\n",
      "\n",
      "episode 12, policy loss -0.08993913233280182\n",
      "\n",
      "episode 13, policy loss -0.06490375846624374\n",
      "\n",
      "episode 14, policy loss -0.0721467062830925\n",
      "\n",
      "episode 15, policy loss -0.027954772114753723\n",
      "\n",
      "episode 16, policy loss -0.07127663493156433\n",
      "\n",
      "Policy train loss in epoch 1:-0.049278019985649735\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.02814176119863987\n",
      "\n",
      "episode 2, policy loss -0.01633346639573574\n",
      "\n",
      "episode 3, policy loss -0.07318225502967834\n",
      "\n",
      "episode 4, policy loss -0.09344974160194397\n",
      "\n",
      "episode 5, policy loss -0.036793917417526245\n",
      "\n",
      "episode 6, policy loss -0.04615074396133423\n",
      "\n",
      "episode 7, policy loss -0.07022342830896378\n",
      "\n",
      "episode 8, policy loss -0.06463053077459335\n",
      "\n",
      "episode 9, policy loss -0.07542930543422699\n",
      "\n",
      "episode 10, policy loss 0.023177290335297585\n",
      "\n",
      "episode 11, policy loss -0.016162913292646408\n",
      "\n",
      "episode 12, policy loss -0.09199241548776627\n",
      "\n",
      "episode 13, policy loss -0.031944453716278076\n",
      "\n",
      "episode 14, policy loss -0.012660713866353035\n",
      "\n",
      "episode 15, policy loss -0.09795007109642029\n",
      "\n",
      "episode 16, policy loss -0.05606995150446892\n",
      "\n",
      "Policy train loss in epoch 2:-0.04924614867195487\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.0887560173869133\n",
      "\n",
      "episode 2, policy loss -0.06401891261339188\n",
      "\n",
      "episode 3, policy loss -0.0702664777636528\n",
      "\n",
      "episode 4, policy loss -0.055449120700359344\n",
      "\n",
      "episode 5, policy loss -0.03821170702576637\n",
      "\n",
      "episode 6, policy loss -0.031353700906038284\n",
      "\n",
      "episode 7, policy loss -0.016463985666632652\n",
      "\n",
      "episode 8, policy loss -0.04474765062332153\n",
      "\n",
      "episode 9, policy loss -0.09848765283823013\n",
      "\n",
      "episode 10, policy loss -0.07479371130466461\n",
      "\n",
      "episode 11, policy loss -0.028993401676416397\n",
      "\n",
      "episode 12, policy loss -0.01277642697095871\n",
      "\n",
      "episode 13, policy loss -0.06973180919885635\n",
      "\n",
      "episode 14, policy loss -0.01724787801504135\n",
      "\n",
      "episode 15, policy loss 0.023014966398477554\n",
      "\n",
      "episode 16, policy loss -0.09424223750829697\n",
      "\n",
      "Policy train loss in epoch 3:-0.048907857737503946\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1649986207485199\n",
      "\n",
      "episode 2, val func loss 0.23107902705669403\n",
      "\n",
      "episode 3, val func loss 0.21600157022476196\n",
      "\n",
      "episode 4, val func loss 0.17151659727096558\n",
      "\n",
      "episode 5, val func loss 0.21311286091804504\n",
      "\n",
      "episode 6, val func loss 0.17379651963710785\n",
      "\n",
      "episode 7, val func loss 0.1653192937374115\n",
      "\n",
      "episode 8, val func loss 0.17769792675971985\n",
      "\n",
      "episode 9, val func loss 0.19528897106647491\n",
      "\n",
      "episode 10, val func loss 0.18407873809337616\n",
      "\n",
      "episode 11, val func loss 0.20826737582683563\n",
      "\n",
      "episode 12, val func loss 0.1866505742073059\n",
      "\n",
      "episode 13, val func loss 0.21285036206245422\n",
      "\n",
      "episode 14, val func loss 0.17668113112449646\n",
      "\n",
      "episode 15, val func loss 0.2049947828054428\n",
      "\n",
      "episode 16, val func loss 0.17420022189617157\n",
      "\n",
      "Val func train loss in epoch 0:0.19103341083973646\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.2131824791431427\n",
      "\n",
      "episode 2, val func loss 0.17742563784122467\n",
      "\n",
      "episode 3, val func loss 0.17205460369586945\n",
      "\n",
      "episode 4, val func loss 0.20496228337287903\n",
      "\n",
      "episode 5, val func loss 0.18518510460853577\n",
      "\n",
      "episode 6, val func loss 0.19506008923053741\n",
      "\n",
      "episode 7, val func loss 0.16102439165115356\n",
      "\n",
      "episode 8, val func loss 0.18673084676265717\n",
      "\n",
      "episode 9, val func loss 0.17343807220458984\n",
      "\n",
      "episode 10, val func loss 0.21503351628780365\n",
      "\n",
      "episode 11, val func loss 0.1756943017244339\n",
      "\n",
      "episode 12, val func loss 0.23316021263599396\n",
      "\n",
      "episode 13, val func loss 0.21587905287742615\n",
      "\n",
      "episode 14, val func loss 0.20454120635986328\n",
      "\n",
      "episode 15, val func loss 0.16597528755664825\n",
      "\n",
      "episode 16, val func loss 0.18162287771701813\n",
      "\n",
      "Val func train loss in epoch 1:0.19131062272936106\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1813122183084488\n",
      "\n",
      "episode 2, val func loss 0.1874208003282547\n",
      "\n",
      "episode 3, val func loss 0.17250138521194458\n",
      "\n",
      "episode 4, val func loss 0.1979440301656723\n",
      "\n",
      "episode 5, val func loss 0.1812431514263153\n",
      "\n",
      "episode 6, val func loss 0.17408350110054016\n",
      "\n",
      "episode 7, val func loss 0.2051314115524292\n",
      "\n",
      "episode 8, val func loss 0.21192020177841187\n",
      "\n",
      "episode 9, val func loss 0.21256890892982483\n",
      "\n",
      "episode 10, val func loss 0.16823667287826538\n",
      "\n",
      "episode 11, val func loss 0.20498943328857422\n",
      "\n",
      "episode 12, val func loss 0.18501105904579163\n",
      "\n",
      "episode 13, val func loss 0.23213209211826324\n",
      "\n",
      "episode 14, val func loss 0.21372243762016296\n",
      "\n",
      "episode 15, val func loss 0.16474604606628418\n",
      "\n",
      "episode 16, val func loss 0.16980299353599548\n",
      "\n",
      "Val func train loss in epoch 2:0.19142289645969868\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.2064458578824997\n",
      "\n",
      "episode 2, val func loss 0.1842479258775711\n",
      "\n",
      "episode 3, val func loss 0.21562717854976654\n",
      "\n",
      "episode 4, val func loss 0.18658217787742615\n",
      "\n",
      "episode 5, val func loss 0.16481004655361176\n",
      "\n",
      "episode 6, val func loss 0.174480602145195\n",
      "\n",
      "episode 7, val func loss 0.20435830950737\n",
      "\n",
      "episode 8, val func loss 0.17733584344387054\n",
      "\n",
      "episode 9, val func loss 0.17811319231987\n",
      "\n",
      "episode 10, val func loss 0.17097751796245575\n",
      "\n",
      "episode 11, val func loss 0.21183422207832336\n",
      "\n",
      "episode 12, val func loss 0.21365323662757874\n",
      "\n",
      "episode 13, val func loss 0.23018930852413177\n",
      "\n",
      "episode 14, val func loss 0.16128046810626984\n",
      "\n",
      "episode 15, val func loss 0.17248451709747314\n",
      "\n",
      "episode 16, val func loss 0.19537383317947388\n",
      "\n",
      "Val func train loss in epoch 3:0.19048713985830545\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.21654106676578522\n",
      "\n",
      "episode 2, val func loss 0.17274653911590576\n",
      "\n",
      "episode 3, val func loss 0.1780211478471756\n",
      "\n",
      "episode 4, val func loss 0.16454431414604187\n",
      "\n",
      "episode 5, val func loss 0.16305746138095856\n",
      "\n",
      "episode 6, val func loss 0.19554030895233154\n",
      "\n",
      "episode 7, val func loss 0.1770942211151123\n",
      "\n",
      "episode 8, val func loss 0.21322420239448547\n",
      "\n",
      "episode 9, val func loss 0.18685434758663177\n",
      "\n",
      "episode 10, val func loss 0.20716692507266998\n",
      "\n",
      "episode 11, val func loss 0.18400134146213531\n",
      "\n",
      "episode 12, val func loss 0.17447753250598907\n",
      "\n",
      "episode 13, val func loss 0.20461907982826233\n",
      "\n",
      "episode 14, val func loss 0.21183814108371735\n",
      "\n",
      "episode 15, val func loss 0.17007258534431458\n",
      "\n",
      "episode 16, val func loss 0.22876028716564178\n",
      "\n",
      "Val func train loss in epoch 4:0.1905349688604474\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.2124241590499878\n",
      "\n",
      "episode 2, val func loss 0.1866326779127121\n",
      "\n",
      "episode 3, val func loss 0.1853632777929306\n",
      "\n",
      "episode 4, val func loss 0.1652241051197052\n",
      "\n",
      "episode 5, val func loss 0.17117337882518768\n",
      "\n",
      "episode 6, val func loss 0.1745966374874115\n",
      "\n",
      "episode 7, val func loss 0.1956101804971695\n",
      "\n",
      "episode 8, val func loss 0.17966973781585693\n",
      "\n",
      "episode 9, val func loss 0.21760787069797516\n",
      "\n",
      "episode 10, val func loss 0.16008761525154114\n",
      "\n",
      "episode 11, val func loss 0.1766257882118225\n",
      "\n",
      "episode 12, val func loss 0.21228674054145813\n",
      "\n",
      "episode 13, val func loss 0.2301190197467804\n",
      "\n",
      "episode 14, val func loss 0.2055843025445938\n",
      "\n",
      "episode 15, val func loss 0.17358878254890442\n",
      "\n",
      "episode 16, val func loss 0.20461173355579376\n",
      "\n",
      "Val func train loss in epoch 5:0.19070037547498941\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18681654334068298\n",
      "\n",
      "episode 2, val func loss 0.19605238735675812\n",
      "\n",
      "episode 3, val func loss 0.22733724117279053\n",
      "\n",
      "episode 4, val func loss 0.17437832057476044\n",
      "\n",
      "episode 5, val func loss 0.16476735472679138\n",
      "\n",
      "episode 6, val func loss 0.1774010956287384\n",
      "\n",
      "episode 7, val func loss 0.1727181077003479\n",
      "\n",
      "episode 8, val func loss 0.21339960396289825\n",
      "\n",
      "episode 9, val func loss 0.1763787865638733\n",
      "\n",
      "episode 10, val func loss 0.16871127486228943\n",
      "\n",
      "episode 11, val func loss 0.2187075912952423\n",
      "\n",
      "episode 12, val func loss 0.20848357677459717\n",
      "\n",
      "episode 13, val func loss 0.21265113353729248\n",
      "\n",
      "episode 14, val func loss 0.18633437156677246\n",
      "\n",
      "episode 15, val func loss 0.2043527513742447\n",
      "\n",
      "episode 16, val func loss 0.16488568484783173\n",
      "\n",
      "Val func train loss in epoch 6:0.19083598908036947\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.20408640801906586\n",
      "\n",
      "episode 2, val func loss 0.1736162304878235\n",
      "\n",
      "episode 3, val func loss 0.19588810205459595\n",
      "\n",
      "episode 4, val func loss 0.1863800585269928\n",
      "\n",
      "episode 5, val func loss 0.21309508383274078\n",
      "\n",
      "episode 6, val func loss 0.20589672029018402\n",
      "\n",
      "episode 7, val func loss 0.21232353150844574\n",
      "\n",
      "episode 8, val func loss 0.23033902049064636\n",
      "\n",
      "episode 9, val func loss 0.16422724723815918\n",
      "\n",
      "episode 10, val func loss 0.21453700959682465\n",
      "\n",
      "episode 11, val func loss 0.1629447489976883\n",
      "\n",
      "episode 12, val func loss 0.17322714626789093\n",
      "\n",
      "episode 13, val func loss 0.1745227724313736\n",
      "\n",
      "episode 14, val func loss 0.17723973095417023\n",
      "\n",
      "episode 15, val func loss 0.1863822489976883\n",
      "\n",
      "episode 16, val func loss 0.1788528710603714\n",
      "\n",
      "Val func train loss in epoch 7:0.19084743317216635\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.21235507726669312\n",
      "\n",
      "episode 2, val func loss 0.20507261157035828\n",
      "\n",
      "episode 3, val func loss 0.17273962497711182\n",
      "\n",
      "episode 4, val func loss 0.17694023251533508\n",
      "\n",
      "episode 5, val func loss 0.22969020903110504\n",
      "\n",
      "episode 6, val func loss 0.17758242785930634\n",
      "\n",
      "episode 7, val func loss 0.1864423155784607\n",
      "\n",
      "episode 8, val func loss 0.16446363925933838\n",
      "\n",
      "episode 9, val func loss 0.21311669051647186\n",
      "\n",
      "episode 10, val func loss 0.1956731379032135\n",
      "\n",
      "episode 11, val func loss 0.1647198647260666\n",
      "\n",
      "episode 12, val func loss 0.18432916700839996\n",
      "\n",
      "episode 13, val func loss 0.17512035369873047\n",
      "\n",
      "episode 14, val func loss 0.20816098153591156\n",
      "\n",
      "episode 15, val func loss 0.16913045942783356\n",
      "\n",
      "episode 16, val func loss 0.21683718264102936\n",
      "\n",
      "Val func train loss in epoch 8:0.19077337346971035\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.19552244246006012\n",
      "\n",
      "episode 2, val func loss 0.21293523907661438\n",
      "\n",
      "episode 3, val func loss 0.16992808878421783\n",
      "\n",
      "episode 4, val func loss 0.20478877425193787\n",
      "\n",
      "episode 5, val func loss 0.1729782372713089\n",
      "\n",
      "episode 6, val func loss 0.20527641475200653\n",
      "\n",
      "episode 7, val func loss 0.17833630740642548\n",
      "\n",
      "episode 8, val func loss 0.16487561166286469\n",
      "\n",
      "episode 9, val func loss 0.21253760159015656\n",
      "\n",
      "episode 10, val func loss 0.17760434746742249\n",
      "\n",
      "episode 11, val func loss 0.1631174087524414\n",
      "\n",
      "episode 12, val func loss 0.21469731628894806\n",
      "\n",
      "episode 13, val func loss 0.2295084446668625\n",
      "\n",
      "episode 14, val func loss 0.18424175679683685\n",
      "\n",
      "episode 15, val func loss 0.1858881711959839\n",
      "\n",
      "episode 16, val func loss 0.174516499042511\n",
      "\n",
      "Val func train loss in epoch 9:0.1904220413416624\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.16162721812725067\n",
      "\n",
      "episode 2, val func loss 0.17305009067058563\n",
      "\n",
      "episode 3, val func loss 0.2064453810453415\n",
      "\n",
      "episode 4, val func loss 0.20552243292331696\n",
      "\n",
      "episode 5, val func loss 0.16439484059810638\n",
      "\n",
      "episode 6, val func loss 0.19515739381313324\n",
      "\n",
      "episode 7, val func loss 0.1741011142730713\n",
      "\n",
      "episode 8, val func loss 0.18414518237113953\n",
      "\n",
      "episode 9, val func loss 0.2297852635383606\n",
      "\n",
      "episode 10, val func loss 0.18625704944133759\n",
      "\n",
      "episode 11, val func loss 0.17767882347106934\n",
      "\n",
      "episode 12, val func loss 0.21213121712207794\n",
      "\n",
      "episode 13, val func loss 0.17718461155891418\n",
      "\n",
      "episode 14, val func loss 0.2141420841217041\n",
      "\n",
      "episode 15, val func loss 0.17286835610866547\n",
      "\n",
      "episode 16, val func loss 0.2126867026090622\n",
      "\n",
      "Val func train loss in epoch 10:0.19044861011207104\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.21364983916282654\n",
      "\n",
      "episode 2, val func loss 0.19578681886196136\n",
      "\n",
      "episode 3, val func loss 0.17718584835529327\n",
      "\n",
      "episode 4, val func loss 0.1784869134426117\n",
      "\n",
      "episode 5, val func loss 0.21162070333957672\n",
      "\n",
      "episode 6, val func loss 0.20491456985473633\n",
      "\n",
      "episode 7, val func loss 0.17253568768501282\n",
      "\n",
      "episode 8, val func loss 0.18648596107959747\n",
      "\n",
      "episode 9, val func loss 0.2292584627866745\n",
      "\n",
      "episode 10, val func loss 0.1743762493133545\n",
      "\n",
      "episode 11, val func loss 0.20596301555633545\n",
      "\n",
      "episode 12, val func loss 0.17079982161521912\n",
      "\n",
      "episode 13, val func loss 0.16463282704353333\n",
      "\n",
      "episode 14, val func loss 0.18491263687610626\n",
      "\n",
      "episode 15, val func loss 0.16168487071990967\n",
      "\n",
      "episode 16, val func loss 0.21353918313980103\n",
      "\n",
      "Val func train loss in epoch 11:0.19036458805203438\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.16892102360725403\n",
      "\n",
      "episode 2, val func loss 0.1580345630645752\n",
      "\n",
      "episode 3, val func loss 0.17739643156528473\n",
      "\n",
      "episode 4, val func loss 0.23898638784885406\n",
      "\n",
      "episode 5, val func loss 0.1746024638414383\n",
      "\n",
      "episode 6, val func loss 0.18413205444812775\n",
      "\n",
      "episode 7, val func loss 0.20612582564353943\n",
      "\n",
      "episode 8, val func loss 0.21362777054309845\n",
      "\n",
      "episode 9, val func loss 0.20600078999996185\n",
      "\n",
      "episode 10, val func loss 0.19595475494861603\n",
      "\n",
      "episode 11, val func loss 0.17503365874290466\n",
      "\n",
      "episode 12, val func loss 0.1881372183561325\n",
      "\n",
      "episode 13, val func loss 0.21198047697544098\n",
      "\n",
      "episode 14, val func loss 0.1661316603422165\n",
      "\n",
      "episode 15, val func loss 0.17722541093826294\n",
      "\n",
      "episode 16, val func loss 0.21254709362983704\n",
      "\n",
      "Val func train loss in epoch 12:0.19092734903097153\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1850423663854599\n",
      "\n",
      "episode 2, val func loss 0.21212391555309296\n",
      "\n",
      "episode 3, val func loss 0.17466585338115692\n",
      "\n",
      "episode 4, val func loss 0.20793737471103668\n",
      "\n",
      "episode 5, val func loss 0.16034582257270813\n",
      "\n",
      "episode 6, val func loss 0.17684394121170044\n",
      "\n",
      "episode 7, val func loss 0.20536574721336365\n",
      "\n",
      "episode 8, val func loss 0.1648399531841278\n",
      "\n",
      "episode 9, val func loss 0.17890839278697968\n",
      "\n",
      "episode 10, val func loss 0.2292936146259308\n",
      "\n",
      "episode 11, val func loss 0.19513453543186188\n",
      "\n",
      "episode 12, val func loss 0.172488734126091\n",
      "\n",
      "episode 13, val func loss 0.21390239894390106\n",
      "\n",
      "episode 14, val func loss 0.2132837474346161\n",
      "\n",
      "episode 15, val func loss 0.17405033111572266\n",
      "\n",
      "episode 16, val func loss 0.18729181587696075\n",
      "\n",
      "Val func train loss in epoch 13:0.1907199090346694\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.21197324991226196\n",
      "\n",
      "episode 2, val func loss 0.20452965795993805\n",
      "\n",
      "episode 3, val func loss 0.17440292239189148\n",
      "\n",
      "episode 4, val func loss 0.21337996423244476\n",
      "\n",
      "episode 5, val func loss 0.17255322635173798\n",
      "\n",
      "episode 6, val func loss 0.1602509766817093\n",
      "\n",
      "episode 7, val func loss 0.16494539380073547\n",
      "\n",
      "episode 8, val func loss 0.21906135976314545\n",
      "\n",
      "episode 9, val func loss 0.18668444454669952\n",
      "\n",
      "episode 10, val func loss 0.2072152942419052\n",
      "\n",
      "episode 11, val func loss 0.2289307713508606\n",
      "\n",
      "episode 12, val func loss 0.17154818773269653\n",
      "\n",
      "episode 13, val func loss 0.1962341070175171\n",
      "\n",
      "episode 14, val func loss 0.17920811474323273\n",
      "\n",
      "episode 15, val func loss 0.18685561418533325\n",
      "\n",
      "episode 16, val func loss 0.17716555297374725\n",
      "\n",
      "Val func train loss in epoch 14:0.19093367736786604\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20504511892795563\n",
      "\n",
      "episode 2, val func loss 0.22839215397834778\n",
      "\n",
      "episode 3, val func loss 0.16347536444664001\n",
      "\n",
      "episode 4, val func loss 0.2143988013267517\n",
      "\n",
      "episode 5, val func loss 0.1863902360200882\n",
      "\n",
      "episode 6, val func loss 0.1951148509979248\n",
      "\n",
      "episode 7, val func loss 0.17856670916080475\n",
      "\n",
      "episode 8, val func loss 0.21179845929145813\n",
      "\n",
      "episode 9, val func loss 0.17458629608154297\n",
      "\n",
      "episode 10, val func loss 0.1644524484872818\n",
      "\n",
      "episode 11, val func loss 0.18440553545951843\n",
      "\n",
      "episode 12, val func loss 0.17301353812217712\n",
      "\n",
      "episode 13, val func loss 0.20514170825481415\n",
      "\n",
      "episode 14, val func loss 0.2132362723350525\n",
      "\n",
      "episode 15, val func loss 0.17707303166389465\n",
      "\n",
      "episode 16, val func loss 0.16963988542556763\n",
      "\n",
      "Val func train loss in epoch 15:0.19029565062373877\n",
      "***********************TIME WAS 4.934127362569173 min*****************************\n",
      "\n",
      "**********************ROUND 58 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.004490648861974478\n",
      "\n",
      "episode 2, policy loss -0.0359516404569149\n",
      "\n",
      "episode 3, policy loss -0.04161448031663895\n",
      "\n",
      "episode 4, policy loss -0.07240539789199829\n",
      "\n",
      "episode 5, policy loss -0.028736546635627747\n",
      "\n",
      "episode 6, policy loss -0.012064546346664429\n",
      "\n",
      "episode 7, policy loss -0.05778149887919426\n",
      "\n",
      "episode 8, policy loss 0.004931317642331123\n",
      "\n",
      "episode 9, policy loss 0.057639095932245255\n",
      "\n",
      "episode 10, policy loss -0.08827638626098633\n",
      "\n",
      "episode 11, policy loss 0.015178932808339596\n",
      "\n",
      "episode 12, policy loss -0.0439329668879509\n",
      "\n",
      "episode 13, policy loss -0.06712864339351654\n",
      "\n",
      "episode 14, policy loss -0.06754793226718903\n",
      "\n",
      "episode 15, policy loss -0.02439926750957966\n",
      "\n",
      "episode 16, policy loss -0.04342027008533478\n",
      "\n",
      "Policy train loss in epoch 0:-0.031313723855419084\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.05343925952911377\n",
      "\n",
      "episode 2, policy loss -0.02651139162480831\n",
      "\n",
      "episode 3, policy loss -0.04397107660770416\n",
      "\n",
      "episode 4, policy loss -0.04625120759010315\n",
      "\n",
      "episode 5, policy loss -0.058123767375946045\n",
      "\n",
      "episode 6, policy loss -0.06544478237628937\n",
      "\n",
      "episode 7, policy loss -0.07430127263069153\n",
      "\n",
      "episode 8, policy loss -0.032883331179618835\n",
      "\n",
      "episode 9, policy loss 0.013784220442175865\n",
      "\n",
      "episode 10, policy loss -0.044246017932891846\n",
      "\n",
      "episode 11, policy loss -0.06857308745384216\n",
      "\n",
      "episode 12, policy loss 0.002990458160638809\n",
      "\n",
      "episode 13, policy loss -0.08515702933073044\n",
      "\n",
      "episode 14, policy loss -0.012537142261862755\n",
      "\n",
      "episode 15, policy loss -0.039216917008161545\n",
      "\n",
      "episode 16, policy loss 0.003399480367079377\n",
      "\n",
      "Policy train loss in epoch 1:-0.032725225304602645\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.05606765300035477\n",
      "\n",
      "episode 2, policy loss -0.028733162209391594\n",
      "\n",
      "episode 3, policy loss -0.0747428834438324\n",
      "\n",
      "episode 4, policy loss -0.0673646554350853\n",
      "\n",
      "episode 5, policy loss 0.001343999756500125\n",
      "\n",
      "episode 6, policy loss -0.03933839127421379\n",
      "\n",
      "episode 7, policy loss -0.032126687467098236\n",
      "\n",
      "episode 8, policy loss -0.060102593153715134\n",
      "\n",
      "episode 9, policy loss -0.09158991277217865\n",
      "\n",
      "episode 10, policy loss -0.014662635512650013\n",
      "\n",
      "episode 11, policy loss -0.06637760251760483\n",
      "\n",
      "episode 12, policy loss 0.01566305197775364\n",
      "\n",
      "episode 13, policy loss 0.0022377606946974993\n",
      "\n",
      "episode 14, policy loss -0.044595781713724136\n",
      "\n",
      "episode 15, policy loss -0.04282756522297859\n",
      "\n",
      "episode 16, policy loss -0.044478777796030045\n",
      "\n",
      "Policy train loss in epoch 2:-0.03322676144307479\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.043529096990823746\n",
      "\n",
      "episode 2, policy loss -0.06567786633968353\n",
      "\n",
      "episode 3, policy loss -0.05892745405435562\n",
      "\n",
      "episode 4, policy loss -0.08189734816551208\n",
      "\n",
      "episode 5, policy loss -0.0442020520567894\n",
      "\n",
      "episode 6, policy loss 0.003080650232732296\n",
      "\n",
      "episode 7, policy loss -0.044140443205833435\n",
      "\n",
      "episode 8, policy loss 0.012923462316393852\n",
      "\n",
      "episode 9, policy loss -0.07195203006267548\n",
      "\n",
      "episode 10, policy loss -0.013542653061449528\n",
      "\n",
      "episode 11, policy loss 0.055709853768348694\n",
      "\n",
      "episode 12, policy loss -0.03129609301686287\n",
      "\n",
      "episode 13, policy loss -0.039125945419073105\n",
      "\n",
      "episode 14, policy loss -0.029852749779820442\n",
      "\n",
      "episode 15, policy loss 0.0007946563418954611\n",
      "\n",
      "episode 16, policy loss -0.0751347467303276\n",
      "\n",
      "Policy train loss in epoch 3:-0.032923116013989784\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17272287607192993\n",
      "\n",
      "episode 2, val func loss 0.13873876631259918\n",
      "\n",
      "episode 3, val func loss 0.1703435629606247\n",
      "\n",
      "episode 4, val func loss 0.18800310790538788\n",
      "\n",
      "episode 5, val func loss 0.20317484438419342\n",
      "\n",
      "episode 6, val func loss 0.17215925455093384\n",
      "\n",
      "episode 7, val func loss 0.19824610650539398\n",
      "\n",
      "episode 8, val func loss 0.1887962818145752\n",
      "\n",
      "episode 9, val func loss 0.20187516510486603\n",
      "\n",
      "episode 10, val func loss 0.2107003927230835\n",
      "\n",
      "episode 11, val func loss 0.1842515766620636\n",
      "\n",
      "episode 12, val func loss 0.1559562385082245\n",
      "\n",
      "episode 13, val func loss 0.20464569330215454\n",
      "\n",
      "episode 14, val func loss 0.21396411955356598\n",
      "\n",
      "episode 15, val func loss 0.17794501781463623\n",
      "\n",
      "episode 16, val func loss 0.16893020272254944\n",
      "\n",
      "Val func train loss in epoch 0:0.18440332543104887\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.20437133312225342\n",
      "\n",
      "episode 2, val func loss 0.18894343078136444\n",
      "\n",
      "episode 3, val func loss 0.2020186334848404\n",
      "\n",
      "episode 4, val func loss 0.17299804091453552\n",
      "\n",
      "episode 5, val func loss 0.17649102210998535\n",
      "\n",
      "episode 6, val func loss 0.2099461555480957\n",
      "\n",
      "episode 7, val func loss 0.19577117264270782\n",
      "\n",
      "episode 8, val func loss 0.17595158517360687\n",
      "\n",
      "episode 9, val func loss 0.2141033262014389\n",
      "\n",
      "episode 10, val func loss 0.18403783440589905\n",
      "\n",
      "episode 11, val func loss 0.153738334774971\n",
      "\n",
      "episode 12, val func loss 0.20184244215488434\n",
      "\n",
      "episode 13, val func loss 0.18682050704956055\n",
      "\n",
      "episode 14, val func loss 0.13728460669517517\n",
      "\n",
      "episode 15, val func loss 0.1701839566230774\n",
      "\n",
      "episode 16, val func loss 0.16816984117031097\n",
      "\n",
      "Val func train loss in epoch 1:0.18391701392829418\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17658163607120514\n",
      "\n",
      "episode 2, val func loss 0.18894575536251068\n",
      "\n",
      "episode 3, val func loss 0.196785107254982\n",
      "\n",
      "episode 4, val func loss 0.17308710515499115\n",
      "\n",
      "episode 5, val func loss 0.1416323333978653\n",
      "\n",
      "episode 6, val func loss 0.1661798357963562\n",
      "\n",
      "episode 7, val func loss 0.20653675496578217\n",
      "\n",
      "episode 8, val func loss 0.15072233974933624\n",
      "\n",
      "episode 9, val func loss 0.17791752517223358\n",
      "\n",
      "episode 10, val func loss 0.20206868648529053\n",
      "\n",
      "episode 11, val func loss 0.21591468155384064\n",
      "\n",
      "episode 12, val func loss 0.20136721432209015\n",
      "\n",
      "episode 13, val func loss 0.18371590971946716\n",
      "\n",
      "episode 14, val func loss 0.18539194762706757\n",
      "\n",
      "episode 15, val func loss 0.20812392234802246\n",
      "\n",
      "episode 16, val func loss 0.1756124049425125\n",
      "\n",
      "Val func train loss in epoch 2:0.1844114474952221\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19618789851665497\n",
      "\n",
      "episode 2, val func loss 0.17465882003307343\n",
      "\n",
      "episode 3, val func loss 0.1998913288116455\n",
      "\n",
      "episode 4, val func loss 0.17499202489852905\n",
      "\n",
      "episode 5, val func loss 0.13988403975963593\n",
      "\n",
      "episode 6, val func loss 0.17381152510643005\n",
      "\n",
      "episode 7, val func loss 0.18910709023475647\n",
      "\n",
      "episode 8, val func loss 0.16706493496894836\n",
      "\n",
      "episode 9, val func loss 0.18926401436328888\n",
      "\n",
      "episode 10, val func loss 0.18740299344062805\n",
      "\n",
      "episode 11, val func loss 0.17794539034366608\n",
      "\n",
      "episode 12, val func loss 0.21133410930633545\n",
      "\n",
      "episode 13, val func loss 0.15539085865020752\n",
      "\n",
      "episode 14, val func loss 0.20502620935440063\n",
      "\n",
      "episode 15, val func loss 0.20265907049179077\n",
      "\n",
      "episode 16, val func loss 0.21461787819862366\n",
      "\n",
      "Val func train loss in epoch 3:0.18495238665491343\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1719406247138977\n",
      "\n",
      "episode 2, val func loss 0.19612036645412445\n",
      "\n",
      "episode 3, val func loss 0.20243580639362335\n",
      "\n",
      "episode 4, val func loss 0.1898052990436554\n",
      "\n",
      "episode 5, val func loss 0.21500736474990845\n",
      "\n",
      "episode 6, val func loss 0.20526906847953796\n",
      "\n",
      "episode 7, val func loss 0.20012283325195312\n",
      "\n",
      "episode 8, val func loss 0.18589359521865845\n",
      "\n",
      "episode 9, val func loss 0.14256101846694946\n",
      "\n",
      "episode 10, val func loss 0.1738499104976654\n",
      "\n",
      "episode 11, val func loss 0.17740216851234436\n",
      "\n",
      "episode 12, val func loss 0.17058147490024567\n",
      "\n",
      "episode 13, val func loss 0.1854463517665863\n",
      "\n",
      "episode 14, val func loss 0.1498214453458786\n",
      "\n",
      "episode 15, val func loss 0.16656649112701416\n",
      "\n",
      "episode 16, val func loss 0.2163473516702652\n",
      "\n",
      "Val func train loss in epoch 4:0.18432319816201925\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1360819935798645\n",
      "\n",
      "episode 2, val func loss 0.17346830666065216\n",
      "\n",
      "episode 3, val func loss 0.20686478912830353\n",
      "\n",
      "episode 4, val func loss 0.18868979811668396\n",
      "\n",
      "episode 5, val func loss 0.17065906524658203\n",
      "\n",
      "episode 6, val func loss 0.19636672735214233\n",
      "\n",
      "episode 7, val func loss 0.2150096446275711\n",
      "\n",
      "episode 8, val func loss 0.20928560197353363\n",
      "\n",
      "episode 9, val func loss 0.17680960893630981\n",
      "\n",
      "episode 10, val func loss 0.17833130061626434\n",
      "\n",
      "episode 11, val func loss 0.1554550975561142\n",
      "\n",
      "episode 12, val func loss 0.1679317206144333\n",
      "\n",
      "episode 13, val func loss 0.18513227999210358\n",
      "\n",
      "episode 14, val func loss 0.18442551791667938\n",
      "\n",
      "episode 15, val func loss 0.20076175034046173\n",
      "\n",
      "episode 16, val func loss 0.20162130892276764\n",
      "\n",
      "Val func train loss in epoch 5:0.1841809069737792\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18568074703216553\n",
      "\n",
      "episode 2, val func loss 0.1382187306880951\n",
      "\n",
      "episode 3, val func loss 0.14994177222251892\n",
      "\n",
      "episode 4, val func loss 0.18574148416519165\n",
      "\n",
      "episode 5, val func loss 0.17215877771377563\n",
      "\n",
      "episode 6, val func loss 0.17880034446716309\n",
      "\n",
      "episode 7, val func loss 0.17463062703609467\n",
      "\n",
      "episode 8, val func loss 0.20292916893959045\n",
      "\n",
      "episode 9, val func loss 0.16629314422607422\n",
      "\n",
      "episode 10, val func loss 0.20162858068943024\n",
      "\n",
      "episode 11, val func loss 0.1714996099472046\n",
      "\n",
      "episode 12, val func loss 0.18949440121650696\n",
      "\n",
      "episode 13, val func loss 0.20536008477210999\n",
      "\n",
      "episode 14, val func loss 0.21397624909877777\n",
      "\n",
      "episode 15, val func loss 0.20919924974441528\n",
      "\n",
      "episode 16, val func loss 0.19541777670383453\n",
      "\n",
      "Val func train loss in epoch 6:0.1838106717914343\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17412543296813965\n",
      "\n",
      "episode 2, val func loss 0.176688551902771\n",
      "\n",
      "episode 3, val func loss 0.20868492126464844\n",
      "\n",
      "episode 4, val func loss 0.19598081707954407\n",
      "\n",
      "episode 5, val func loss 0.1540619432926178\n",
      "\n",
      "episode 6, val func loss 0.17753584682941437\n",
      "\n",
      "episode 7, val func loss 0.20010964572429657\n",
      "\n",
      "episode 8, val func loss 0.18387064337730408\n",
      "\n",
      "episode 9, val func loss 0.20137177407741547\n",
      "\n",
      "episode 10, val func loss 0.20557014644145966\n",
      "\n",
      "episode 11, val func loss 0.18608298897743225\n",
      "\n",
      "episode 12, val func loss 0.1721065640449524\n",
      "\n",
      "episode 13, val func loss 0.14092393219470978\n",
      "\n",
      "episode 14, val func loss 0.18867358565330505\n",
      "\n",
      "episode 15, val func loss 0.1667468249797821\n",
      "\n",
      "episode 16, val func loss 0.21606644988059998\n",
      "\n",
      "Val func train loss in epoch 7:0.18428750429302454\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.18504580855369568\n",
      "\n",
      "episode 2, val func loss 0.17268289625644684\n",
      "\n",
      "episode 3, val func loss 0.17067649960517883\n",
      "\n",
      "episode 4, val func loss 0.17282557487487793\n",
      "\n",
      "episode 5, val func loss 0.20133739709854126\n",
      "\n",
      "episode 6, val func loss 0.1772148311138153\n",
      "\n",
      "episode 7, val func loss 0.201167032122612\n",
      "\n",
      "episode 8, val func loss 0.14223475754261017\n",
      "\n",
      "episode 9, val func loss 0.15219718217849731\n",
      "\n",
      "episode 10, val func loss 0.20620417594909668\n",
      "\n",
      "episode 11, val func loss 0.18876656889915466\n",
      "\n",
      "episode 12, val func loss 0.18590380251407623\n",
      "\n",
      "episode 13, val func loss 0.21399712562561035\n",
      "\n",
      "episode 14, val func loss 0.2157217115163803\n",
      "\n",
      "episode 15, val func loss 0.1955944448709488\n",
      "\n",
      "episode 16, val func loss 0.1676652878522873\n",
      "\n",
      "Val func train loss in epoch 8:0.18432719353586435\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17236673831939697\n",
      "\n",
      "episode 2, val func loss 0.19990423321723938\n",
      "\n",
      "episode 3, val func loss 0.20492865145206451\n",
      "\n",
      "episode 4, val func loss 0.17613622546195984\n",
      "\n",
      "episode 5, val func loss 0.18973976373672485\n",
      "\n",
      "episode 6, val func loss 0.18396176397800446\n",
      "\n",
      "episode 7, val func loss 0.15205620229244232\n",
      "\n",
      "episode 8, val func loss 0.18575653433799744\n",
      "\n",
      "episode 9, val func loss 0.16648586094379425\n",
      "\n",
      "episode 10, val func loss 0.20217271149158478\n",
      "\n",
      "episode 11, val func loss 0.21694199740886688\n",
      "\n",
      "episode 12, val func loss 0.17358726263046265\n",
      "\n",
      "episode 13, val func loss 0.17707864940166473\n",
      "\n",
      "episode 14, val func loss 0.1964956372976303\n",
      "\n",
      "episode 15, val func loss 0.1428471952676773\n",
      "\n",
      "episode 16, val func loss 0.2101738601922989\n",
      "\n",
      "Val func train loss in epoch 9:0.1844145804643631\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20059871673583984\n",
      "\n",
      "episode 2, val func loss 0.1717703491449356\n",
      "\n",
      "episode 3, val func loss 0.18528036773204803\n",
      "\n",
      "episode 4, val func loss 0.2094995677471161\n",
      "\n",
      "episode 5, val func loss 0.21376323699951172\n",
      "\n",
      "episode 6, val func loss 0.15427599847316742\n",
      "\n",
      "episode 7, val func loss 0.16771183907985687\n",
      "\n",
      "episode 8, val func loss 0.18927524983882904\n",
      "\n",
      "episode 9, val func loss 0.1960572749376297\n",
      "\n",
      "episode 10, val func loss 0.20586609840393066\n",
      "\n",
      "episode 11, val func loss 0.17710553109645844\n",
      "\n",
      "episode 12, val func loss 0.13943937420845032\n",
      "\n",
      "episode 13, val func loss 0.17256778478622437\n",
      "\n",
      "episode 14, val func loss 0.20176970958709717\n",
      "\n",
      "episode 15, val func loss 0.1743691861629486\n",
      "\n",
      "episode 16, val func loss 0.18623024225234985\n",
      "\n",
      "Val func train loss in epoch 10:0.1840987829491496\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.21560238301753998\n",
      "\n",
      "episode 2, val func loss 0.20672324299812317\n",
      "\n",
      "episode 3, val func loss 0.1670270562171936\n",
      "\n",
      "episode 4, val func loss 0.1955530345439911\n",
      "\n",
      "episode 5, val func loss 0.18592308461666107\n",
      "\n",
      "episode 6, val func loss 0.20299120247364044\n",
      "\n",
      "episode 7, val func loss 0.1781548708677292\n",
      "\n",
      "episode 8, val func loss 0.15568062663078308\n",
      "\n",
      "episode 9, val func loss 0.1753878891468048\n",
      "\n",
      "episode 10, val func loss 0.21451419591903687\n",
      "\n",
      "episode 11, val func loss 0.17204666137695312\n",
      "\n",
      "episode 12, val func loss 0.13938207924365997\n",
      "\n",
      "episode 13, val func loss 0.17042981088161469\n",
      "\n",
      "episode 14, val func loss 0.18675078451633453\n",
      "\n",
      "episode 15, val func loss 0.1887756735086441\n",
      "\n",
      "episode 16, val func loss 0.20581477880477905\n",
      "\n",
      "Val func train loss in epoch 11:0.18504733592271805\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.21892085671424866\n",
      "\n",
      "episode 2, val func loss 0.18666458129882812\n",
      "\n",
      "episode 3, val func loss 0.1665060818195343\n",
      "\n",
      "episode 4, val func loss 0.20536687970161438\n",
      "\n",
      "episode 5, val func loss 0.20019063353538513\n",
      "\n",
      "episode 6, val func loss 0.15122279524803162\n",
      "\n",
      "episode 7, val func loss 0.19094085693359375\n",
      "\n",
      "episode 8, val func loss 0.17127655446529388\n",
      "\n",
      "episode 9, val func loss 0.173733189702034\n",
      "\n",
      "episode 10, val func loss 0.21266067028045654\n",
      "\n",
      "episode 11, val func loss 0.19696538150310516\n",
      "\n",
      "episode 12, val func loss 0.20137107372283936\n",
      "\n",
      "episode 13, val func loss 0.15159748494625092\n",
      "\n",
      "episode 14, val func loss 0.1843777298927307\n",
      "\n",
      "episode 15, val func loss 0.1707063466310501\n",
      "\n",
      "episode 16, val func loss 0.17800919711589813\n",
      "\n",
      "Val func train loss in epoch 12:0.18503189459443092\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18868446350097656\n",
      "\n",
      "episode 2, val func loss 0.13837020099163055\n",
      "\n",
      "episode 3, val func loss 0.17323265969753265\n",
      "\n",
      "episode 4, val func loss 0.2144443243741989\n",
      "\n",
      "episode 5, val func loss 0.1975231170654297\n",
      "\n",
      "episode 6, val func loss 0.15045157074928284\n",
      "\n",
      "episode 7, val func loss 0.16601690649986267\n",
      "\n",
      "episode 8, val func loss 0.2013067752122879\n",
      "\n",
      "episode 9, val func loss 0.20152615010738373\n",
      "\n",
      "episode 10, val func loss 0.17722323536872864\n",
      "\n",
      "episode 11, val func loss 0.18396250903606415\n",
      "\n",
      "episode 12, val func loss 0.17484727501869202\n",
      "\n",
      "episode 13, val func loss 0.1719038337469101\n",
      "\n",
      "episode 14, val func loss 0.21421504020690918\n",
      "\n",
      "episode 15, val func loss 0.1859673708677292\n",
      "\n",
      "episode 16, val func loss 0.2050175964832306\n",
      "\n",
      "Val func train loss in epoch 13:0.18404331430792809\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17149342596530914\n",
      "\n",
      "episode 2, val func loss 0.17719431221485138\n",
      "\n",
      "episode 3, val func loss 0.18910744786262512\n",
      "\n",
      "episode 4, val func loss 0.1962587535381317\n",
      "\n",
      "episode 5, val func loss 0.13954755663871765\n",
      "\n",
      "episode 6, val func loss 0.1860843002796173\n",
      "\n",
      "episode 7, val func loss 0.15036936104297638\n",
      "\n",
      "episode 8, val func loss 0.1660495400428772\n",
      "\n",
      "episode 9, val func loss 0.21852241456508636\n",
      "\n",
      "episode 10, val func loss 0.17209407687187195\n",
      "\n",
      "episode 11, val func loss 0.2155478149652481\n",
      "\n",
      "episode 12, val func loss 0.20218706130981445\n",
      "\n",
      "episode 13, val func loss 0.18418103456497192\n",
      "\n",
      "episode 14, val func loss 0.1717255860567093\n",
      "\n",
      "episode 15, val func loss 0.20343239605426788\n",
      "\n",
      "episode 16, val func loss 0.2050316035747528\n",
      "\n",
      "Val func train loss in epoch 14:0.1843016678467393\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18524667620658875\n",
      "\n",
      "episode 2, val func loss 0.15668199956417084\n",
      "\n",
      "episode 3, val func loss 0.18568536639213562\n",
      "\n",
      "episode 4, val func loss 0.17240960896015167\n",
      "\n",
      "episode 5, val func loss 0.18858130276203156\n",
      "\n",
      "episode 6, val func loss 0.21511134505271912\n",
      "\n",
      "episode 7, val func loss 0.17353089153766632\n",
      "\n",
      "episode 8, val func loss 0.20202873647212982\n",
      "\n",
      "episode 9, val func loss 0.2076306939125061\n",
      "\n",
      "episode 10, val func loss 0.17271876335144043\n",
      "\n",
      "episode 11, val func loss 0.21233218908309937\n",
      "\n",
      "episode 12, val func loss 0.17705491185188293\n",
      "\n",
      "episode 13, val func loss 0.19592057168483734\n",
      "\n",
      "episode 14, val func loss 0.14971765875816345\n",
      "\n",
      "episode 15, val func loss 0.19991837441921234\n",
      "\n",
      "episode 16, val func loss 0.16697163879871368\n",
      "\n",
      "Val func train loss in epoch 15:0.18509629555046558\n",
      "***********************TIME WAS 4.938335780302683 min*****************************\n",
      "\n",
      "**********************ROUND 59 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.06625184416770935\n",
      "\n",
      "episode 2, policy loss -0.07367036491632462\n",
      "\n",
      "episode 3, policy loss -0.028966857120394707\n",
      "\n",
      "episode 4, policy loss -0.04528204724192619\n",
      "\n",
      "episode 5, policy loss -0.030083797872066498\n",
      "\n",
      "episode 6, policy loss -0.04118682071566582\n",
      "\n",
      "episode 7, policy loss -0.08158775418996811\n",
      "\n",
      "episode 8, policy loss -0.04021914675831795\n",
      "\n",
      "episode 9, policy loss -0.060452599078416824\n",
      "\n",
      "episode 10, policy loss -0.012889857403934002\n",
      "\n",
      "episode 11, policy loss -0.03577367216348648\n",
      "\n",
      "episode 12, policy loss -0.027773849666118622\n",
      "\n",
      "episode 13, policy loss 0.004689670633524656\n",
      "\n",
      "episode 14, policy loss -0.009510448202490807\n",
      "\n",
      "episode 15, policy loss -0.03440408408641815\n",
      "\n",
      "episode 16, policy loss -0.042293157428503036\n",
      "\n",
      "Policy train loss in epoch 0:-0.03910353939863853\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.023698410019278526\n",
      "\n",
      "episode 2, policy loss -0.04660767689347267\n",
      "\n",
      "episode 3, policy loss -0.014314591884613037\n",
      "\n",
      "episode 4, policy loss -0.01071239449083805\n",
      "\n",
      "episode 5, policy loss -0.07765500992536545\n",
      "\n",
      "episode 6, policy loss -0.036441560834646225\n",
      "\n",
      "episode 7, policy loss -0.04376564174890518\n",
      "\n",
      "episode 8, policy loss -0.08051040023565292\n",
      "\n",
      "episode 9, policy loss -0.04418448358774185\n",
      "\n",
      "episode 10, policy loss 0.005354007240384817\n",
      "\n",
      "episode 11, policy loss -0.03407399356365204\n",
      "\n",
      "episode 12, policy loss -0.029556576162576675\n",
      "\n",
      "episode 13, policy loss -0.06138935685157776\n",
      "\n",
      "episode 14, policy loss -0.07101251184940338\n",
      "\n",
      "episode 15, policy loss -0.04522639513015747\n",
      "\n",
      "episode 16, policy loss -0.030367834493517876\n",
      "\n",
      "Policy train loss in epoch 1:-0.040260176901938394\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.07933063060045242\n",
      "\n",
      "episode 2, policy loss -0.03478064388036728\n",
      "\n",
      "episode 3, policy loss -0.031319357454776764\n",
      "\n",
      "episode 4, policy loss -0.0821644589304924\n",
      "\n",
      "episode 5, policy loss -0.014836623333394527\n",
      "\n",
      "episode 6, policy loss -0.04562610760331154\n",
      "\n",
      "episode 7, policy loss -0.07026626914739609\n",
      "\n",
      "episode 8, policy loss -0.02677256427705288\n",
      "\n",
      "episode 9, policy loss -0.04772508144378662\n",
      "\n",
      "episode 10, policy loss -0.04407398775219917\n",
      "\n",
      "episode 11, policy loss -0.03170589730143547\n",
      "\n",
      "episode 12, policy loss -0.061621248722076416\n",
      "\n",
      "episode 13, policy loss -0.044214341789484024\n",
      "\n",
      "episode 14, policy loss 0.005844095256179571\n",
      "\n",
      "episode 15, policy loss -0.03711279481649399\n",
      "\n",
      "episode 16, policy loss -0.012491831555962563\n",
      "\n",
      "Policy train loss in epoch 2:-0.04113735895953141\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.011939573101699352\n",
      "\n",
      "episode 2, policy loss -0.06025521457195282\n",
      "\n",
      "episode 3, policy loss -0.04302256926894188\n",
      "\n",
      "episode 4, policy loss -0.036343786865472794\n",
      "\n",
      "episode 5, policy loss -0.02836436964571476\n",
      "\n",
      "episode 6, policy loss -0.04686582460999489\n",
      "\n",
      "episode 7, policy loss -0.07297592610120773\n",
      "\n",
      "episode 8, policy loss 0.0056852735579013824\n",
      "\n",
      "episode 9, policy loss -0.04427797719836235\n",
      "\n",
      "episode 10, policy loss -0.07940158993005753\n",
      "\n",
      "episode 11, policy loss -0.03113085776567459\n",
      "\n",
      "episode 12, policy loss -0.035666707903146744\n",
      "\n",
      "episode 13, policy loss -0.015383915975689888\n",
      "\n",
      "episode 14, policy loss -0.08274108916521072\n",
      "\n",
      "episode 15, policy loss -0.03040933422744274\n",
      "\n",
      "episode 16, policy loss -0.045981794595718384\n",
      "\n",
      "Policy train loss in epoch 3:-0.04119220358552411\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17775724828243256\n",
      "\n",
      "episode 2, val func loss 0.16584515571594238\n",
      "\n",
      "episode 3, val func loss 0.1771874874830246\n",
      "\n",
      "episode 4, val func loss 0.21016879379749298\n",
      "\n",
      "episode 5, val func loss 0.18613572418689728\n",
      "\n",
      "episode 6, val func loss 0.1850704550743103\n",
      "\n",
      "episode 7, val func loss 0.194443017244339\n",
      "\n",
      "episode 8, val func loss 0.21888446807861328\n",
      "\n",
      "episode 9, val func loss 0.18198028206825256\n",
      "\n",
      "episode 10, val func loss 0.19853200018405914\n",
      "\n",
      "episode 11, val func loss 0.1969856172800064\n",
      "\n",
      "episode 12, val func loss 0.1954018622636795\n",
      "\n",
      "episode 13, val func loss 0.2101125717163086\n",
      "\n",
      "episode 14, val func loss 0.2030191868543625\n",
      "\n",
      "episode 15, val func loss 0.18597213923931122\n",
      "\n",
      "episode 16, val func loss 0.17715421319007874\n",
      "\n",
      "Val func train loss in epoch 0:0.19154063891619444\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18204481899738312\n",
      "\n",
      "episode 2, val func loss 0.1935323029756546\n",
      "\n",
      "episode 3, val func loss 0.20365813374519348\n",
      "\n",
      "episode 4, val func loss 0.16553115844726562\n",
      "\n",
      "episode 5, val func loss 0.22190526127815247\n",
      "\n",
      "episode 6, val func loss 0.1741728037595749\n",
      "\n",
      "episode 7, val func loss 0.18579305708408356\n",
      "\n",
      "episode 8, val func loss 0.19625291228294373\n",
      "\n",
      "episode 9, val func loss 0.19692721962928772\n",
      "\n",
      "episode 10, val func loss 0.1775195598602295\n",
      "\n",
      "episode 11, val func loss 0.20927877724170685\n",
      "\n",
      "episode 12, val func loss 0.20737452805042267\n",
      "\n",
      "episode 13, val func loss 0.17811281979084015\n",
      "\n",
      "episode 14, val func loss 0.1993691623210907\n",
      "\n",
      "episode 15, val func loss 0.18430417776107788\n",
      "\n",
      "episode 16, val func loss 0.18541012704372406\n",
      "\n",
      "Val func train loss in epoch 1:0.19132417626678944\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18488013744354248\n",
      "\n",
      "episode 2, val func loss 0.20380337536334991\n",
      "\n",
      "episode 3, val func loss 0.19268491864204407\n",
      "\n",
      "episode 4, val func loss 0.18192344903945923\n",
      "\n",
      "episode 5, val func loss 0.20893917977809906\n",
      "\n",
      "episode 6, val func loss 0.16611279547214508\n",
      "\n",
      "episode 7, val func loss 0.1983967125415802\n",
      "\n",
      "episode 8, val func loss 0.19709093868732452\n",
      "\n",
      "episode 9, val func loss 0.210471510887146\n",
      "\n",
      "episode 10, val func loss 0.1759219765663147\n",
      "\n",
      "episode 11, val func loss 0.18547558784484863\n",
      "\n",
      "episode 12, val func loss 0.21882840991020203\n",
      "\n",
      "episode 13, val func loss 0.17775848507881165\n",
      "\n",
      "episode 14, val func loss 0.17584414780139923\n",
      "\n",
      "episode 15, val func loss 0.19560043513774872\n",
      "\n",
      "episode 16, val func loss 0.18423455953598022\n",
      "\n",
      "Val func train loss in epoch 2:0.19112291373312473\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18431887030601501\n",
      "\n",
      "episode 2, val func loss 0.18597683310508728\n",
      "\n",
      "episode 3, val func loss 0.20719705522060394\n",
      "\n",
      "episode 4, val func loss 0.20973607897758484\n",
      "\n",
      "episode 5, val func loss 0.19469784200191498\n",
      "\n",
      "episode 6, val func loss 0.17630720138549805\n",
      "\n",
      "episode 7, val func loss 0.21859799325466156\n",
      "\n",
      "episode 8, val func loss 0.20277823507785797\n",
      "\n",
      "episode 9, val func loss 0.18530282378196716\n",
      "\n",
      "episode 10, val func loss 0.16748404502868652\n",
      "\n",
      "episode 11, val func loss 0.19708847999572754\n",
      "\n",
      "episode 12, val func loss 0.17509226500988007\n",
      "\n",
      "episode 13, val func loss 0.17783090472221375\n",
      "\n",
      "episode 14, val func loss 0.19627822935581207\n",
      "\n",
      "episode 15, val func loss 0.1984824687242508\n",
      "\n",
      "episode 16, val func loss 0.18235550820827484\n",
      "\n",
      "Val func train loss in epoch 3:0.19122030213475227\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19612157344818115\n",
      "\n",
      "episode 2, val func loss 0.19745318591594696\n",
      "\n",
      "episode 3, val func loss 0.1782742440700531\n",
      "\n",
      "episode 4, val func loss 0.20328760147094727\n",
      "\n",
      "episode 5, val func loss 0.21791811287403107\n",
      "\n",
      "episode 6, val func loss 0.20735497772693634\n",
      "\n",
      "episode 7, val func loss 0.20070822536945343\n",
      "\n",
      "episode 8, val func loss 0.1845705658197403\n",
      "\n",
      "episode 9, val func loss 0.18443870544433594\n",
      "\n",
      "episode 10, val func loss 0.17025481164455414\n",
      "\n",
      "episode 11, val func loss 0.20954108238220215\n",
      "\n",
      "episode 12, val func loss 0.19333474338054657\n",
      "\n",
      "episode 13, val func loss 0.17611387372016907\n",
      "\n",
      "episode 14, val func loss 0.1745181679725647\n",
      "\n",
      "episode 15, val func loss 0.18615776300430298\n",
      "\n",
      "episode 16, val func loss 0.18663173913955688\n",
      "\n",
      "Val func train loss in epoch 4:0.19166746083647013\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17967964708805084\n",
      "\n",
      "episode 2, val func loss 0.1988442987203598\n",
      "\n",
      "episode 3, val func loss 0.21084673702716827\n",
      "\n",
      "episode 4, val func loss 0.17500442266464233\n",
      "\n",
      "episode 5, val func loss 0.18526187539100647\n",
      "\n",
      "episode 6, val func loss 0.17621447145938873\n",
      "\n",
      "episode 7, val func loss 0.18495972454547882\n",
      "\n",
      "episode 8, val func loss 0.2093104124069214\n",
      "\n",
      "episode 9, val func loss 0.16963420808315277\n",
      "\n",
      "episode 10, val func loss 0.19495746493339539\n",
      "\n",
      "episode 11, val func loss 0.2179718017578125\n",
      "\n",
      "episode 12, val func loss 0.184186190366745\n",
      "\n",
      "episode 13, val func loss 0.1957150399684906\n",
      "\n",
      "episode 14, val func loss 0.19696763157844543\n",
      "\n",
      "episode 15, val func loss 0.18164630234241486\n",
      "\n",
      "episode 16, val func loss 0.20318152010440826\n",
      "\n",
      "Val func train loss in epoch 5:0.1915238592773676\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18488633632659912\n",
      "\n",
      "episode 2, val func loss 0.1978563666343689\n",
      "\n",
      "episode 3, val func loss 0.1854766607284546\n",
      "\n",
      "episode 4, val func loss 0.21029867231845856\n",
      "\n",
      "episode 5, val func loss 0.1761617660522461\n",
      "\n",
      "episode 6, val func loss 0.1956053376197815\n",
      "\n",
      "episode 7, val func loss 0.20287416875362396\n",
      "\n",
      "episode 8, val func loss 0.1777927577495575\n",
      "\n",
      "episode 9, val func loss 0.16813072562217712\n",
      "\n",
      "episode 10, val func loss 0.1934618353843689\n",
      "\n",
      "episode 11, val func loss 0.18162256479263306\n",
      "\n",
      "episode 12, val func loss 0.19711875915527344\n",
      "\n",
      "episode 13, val func loss 0.1861848086118698\n",
      "\n",
      "episode 14, val func loss 0.22358322143554688\n",
      "\n",
      "episode 15, val func loss 0.17848600447177887\n",
      "\n",
      "episode 16, val func loss 0.20973454415798187\n",
      "\n",
      "Val func train loss in epoch 6:0.19182965811342\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1752510964870453\n",
      "\n",
      "episode 2, val func loss 0.20274341106414795\n",
      "\n",
      "episode 3, val func loss 0.1857060194015503\n",
      "\n",
      "episode 4, val func loss 0.2071085274219513\n",
      "\n",
      "episode 5, val func loss 0.19946643710136414\n",
      "\n",
      "episode 6, val func loss 0.17057864367961884\n",
      "\n",
      "episode 7, val func loss 0.21733997762203217\n",
      "\n",
      "episode 8, val func loss 0.186079740524292\n",
      "\n",
      "episode 9, val func loss 0.17796537280082703\n",
      "\n",
      "episode 10, val func loss 0.19350405037403107\n",
      "\n",
      "episode 11, val func loss 0.19616790115833282\n",
      "\n",
      "episode 12, val func loss 0.19690757989883423\n",
      "\n",
      "episode 13, val func loss 0.18582630157470703\n",
      "\n",
      "episode 14, val func loss 0.17647556960582733\n",
      "\n",
      "episode 15, val func loss 0.2118144929409027\n",
      "\n",
      "episode 16, val func loss 0.18234030902385712\n",
      "\n",
      "Val func train loss in epoch 7:0.19157971441745758\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16650524735450745\n",
      "\n",
      "episode 2, val func loss 0.17592687904834747\n",
      "\n",
      "episode 3, val func loss 0.21056334674358368\n",
      "\n",
      "episode 4, val func loss 0.1952826976776123\n",
      "\n",
      "episode 5, val func loss 0.19371120631694794\n",
      "\n",
      "episode 6, val func loss 0.21893686056137085\n",
      "\n",
      "episode 7, val func loss 0.1822320520877838\n",
      "\n",
      "episode 8, val func loss 0.1966291069984436\n",
      "\n",
      "episode 9, val func loss 0.19829049706459045\n",
      "\n",
      "episode 10, val func loss 0.18451553583145142\n",
      "\n",
      "episode 11, val func loss 0.17755873501300812\n",
      "\n",
      "episode 12, val func loss 0.1757832020521164\n",
      "\n",
      "episode 13, val func loss 0.207729771733284\n",
      "\n",
      "episode 14, val func loss 0.18536311388015747\n",
      "\n",
      "episode 15, val func loss 0.1852603256702423\n",
      "\n",
      "episode 16, val func loss 0.20259664952754974\n",
      "\n",
      "Val func train loss in epoch 8:0.1910553267225623\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17775456607341766\n",
      "\n",
      "episode 2, val func loss 0.1841283142566681\n",
      "\n",
      "episode 3, val func loss 0.1852620393037796\n",
      "\n",
      "episode 4, val func loss 0.1953941434621811\n",
      "\n",
      "episode 5, val func loss 0.20248259603977203\n",
      "\n",
      "episode 6, val func loss 0.20922425389289856\n",
      "\n",
      "episode 7, val func loss 0.20743656158447266\n",
      "\n",
      "episode 8, val func loss 0.1687985509634018\n",
      "\n",
      "episode 9, val func loss 0.1759883314371109\n",
      "\n",
      "episode 10, val func loss 0.17718252539634705\n",
      "\n",
      "episode 11, val func loss 0.18550506234169006\n",
      "\n",
      "episode 12, val func loss 0.19694426655769348\n",
      "\n",
      "episode 13, val func loss 0.22060610353946686\n",
      "\n",
      "episode 14, val func loss 0.18174970149993896\n",
      "\n",
      "episode 15, val func loss 0.19807328283786774\n",
      "\n",
      "episode 16, val func loss 0.19247180223464966\n",
      "\n",
      "Val func train loss in epoch 9:0.19118763133883476\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18213118612766266\n",
      "\n",
      "episode 2, val func loss 0.1926880180835724\n",
      "\n",
      "episode 3, val func loss 0.18507321178913116\n",
      "\n",
      "episode 4, val func loss 0.2032938450574875\n",
      "\n",
      "episode 5, val func loss 0.17453305423259735\n",
      "\n",
      "episode 6, val func loss 0.2111521065235138\n",
      "\n",
      "episode 7, val func loss 0.18567442893981934\n",
      "\n",
      "episode 8, val func loss 0.1673908233642578\n",
      "\n",
      "episode 9, val func loss 0.18470259010791779\n",
      "\n",
      "episode 10, val func loss 0.17722810804843903\n",
      "\n",
      "episode 11, val func loss 0.21884597837924957\n",
      "\n",
      "episode 12, val func loss 0.1758614033460617\n",
      "\n",
      "episode 13, val func loss 0.19713014364242554\n",
      "\n",
      "episode 14, val func loss 0.20746244490146637\n",
      "\n",
      "episode 15, val func loss 0.19562190771102905\n",
      "\n",
      "episode 16, val func loss 0.1986657828092575\n",
      "\n",
      "Val func train loss in epoch 10:0.19109093956649303\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19557391107082367\n",
      "\n",
      "episode 2, val func loss 0.1776685267686844\n",
      "\n",
      "episode 3, val func loss 0.18420298397541046\n",
      "\n",
      "episode 4, val func loss 0.18215277791023254\n",
      "\n",
      "episode 5, val func loss 0.20762775838375092\n",
      "\n",
      "episode 6, val func loss 0.17563019692897797\n",
      "\n",
      "episode 7, val func loss 0.18526014685630798\n",
      "\n",
      "episode 8, val func loss 0.19280552864074707\n",
      "\n",
      "episode 9, val func loss 0.2041858434677124\n",
      "\n",
      "episode 10, val func loss 0.16519147157669067\n",
      "\n",
      "episode 11, val func loss 0.21258047223091125\n",
      "\n",
      "episode 12, val func loss 0.18552571535110474\n",
      "\n",
      "episode 13, val func loss 0.17632447183132172\n",
      "\n",
      "episode 14, val func loss 0.21918660402297974\n",
      "\n",
      "episode 15, val func loss 0.19878756999969482\n",
      "\n",
      "episode 16, val func loss 0.19787338376045227\n",
      "\n",
      "Val func train loss in epoch 11:0.19128608517348766\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.21708689630031586\n",
      "\n",
      "episode 2, val func loss 0.20719356834888458\n",
      "\n",
      "episode 3, val func loss 0.1721300333738327\n",
      "\n",
      "episode 4, val func loss 0.17946481704711914\n",
      "\n",
      "episode 5, val func loss 0.18535125255584717\n",
      "\n",
      "episode 6, val func loss 0.21069180965423584\n",
      "\n",
      "episode 7, val func loss 0.19804735481739044\n",
      "\n",
      "episode 8, val func loss 0.1786881536245346\n",
      "\n",
      "episode 9, val func loss 0.19644372165203094\n",
      "\n",
      "episode 10, val func loss 0.18268275260925293\n",
      "\n",
      "episode 11, val func loss 0.17636217176914215\n",
      "\n",
      "episode 12, val func loss 0.19671398401260376\n",
      "\n",
      "episode 13, val func loss 0.1930025815963745\n",
      "\n",
      "episode 14, val func loss 0.20312781631946564\n",
      "\n",
      "episode 15, val func loss 0.18454016745090485\n",
      "\n",
      "episode 16, val func loss 0.18494297564029694\n",
      "\n",
      "Val func train loss in epoch 12:0.1916543785482645\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18591001629829407\n",
      "\n",
      "episode 2, val func loss 0.20329637825489044\n",
      "\n",
      "episode 3, val func loss 0.18575125932693481\n",
      "\n",
      "episode 4, val func loss 0.19683295488357544\n",
      "\n",
      "episode 5, val func loss 0.1755598783493042\n",
      "\n",
      "episode 6, val func loss 0.20851151645183563\n",
      "\n",
      "episode 7, val func loss 0.19546236097812653\n",
      "\n",
      "episode 8, val func loss 0.17769941687583923\n",
      "\n",
      "episode 9, val func loss 0.19441746175289154\n",
      "\n",
      "episode 10, val func loss 0.18212322890758514\n",
      "\n",
      "episode 11, val func loss 0.2193392515182495\n",
      "\n",
      "episode 12, val func loss 0.17553292214870453\n",
      "\n",
      "episode 13, val func loss 0.1842859983444214\n",
      "\n",
      "episode 14, val func loss 0.1981324702501297\n",
      "\n",
      "episode 15, val func loss 0.16638091206550598\n",
      "\n",
      "episode 16, val func loss 0.21192723512649536\n",
      "\n",
      "Val func train loss in epoch 13:0.19132270384579897\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18541781604290009\n",
      "\n",
      "episode 2, val func loss 0.1776810735464096\n",
      "\n",
      "episode 3, val func loss 0.18516172468662262\n",
      "\n",
      "episode 4, val func loss 0.19389961659908295\n",
      "\n",
      "episode 5, val func loss 0.20762592554092407\n",
      "\n",
      "episode 6, val func loss 0.19710104167461395\n",
      "\n",
      "episode 7, val func loss 0.1952962428331375\n",
      "\n",
      "episode 8, val func loss 0.20999747514724731\n",
      "\n",
      "episode 9, val func loss 0.17582187056541443\n",
      "\n",
      "episode 10, val func loss 0.17772895097732544\n",
      "\n",
      "episode 11, val func loss 0.21794791519641876\n",
      "\n",
      "episode 12, val func loss 0.19875556230545044\n",
      "\n",
      "episode 13, val func loss 0.16724085807800293\n",
      "\n",
      "episode 14, val func loss 0.18514007329940796\n",
      "\n",
      "episode 15, val func loss 0.18183086812496185\n",
      "\n",
      "episode 16, val func loss 0.20422811806201935\n",
      "\n",
      "Val func train loss in epoch 14:0.1913046957924962\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1862102895975113\n",
      "\n",
      "episode 2, val func loss 0.17472971975803375\n",
      "\n",
      "episode 3, val func loss 0.18547585606575012\n",
      "\n",
      "episode 4, val func loss 0.1818857192993164\n",
      "\n",
      "episode 5, val func loss 0.17770253121852875\n",
      "\n",
      "episode 6, val func loss 0.21959632635116577\n",
      "\n",
      "episode 7, val func loss 0.19844743609428406\n",
      "\n",
      "episode 8, val func loss 0.17613080143928528\n",
      "\n",
      "episode 9, val func loss 0.19471736252307892\n",
      "\n",
      "episode 10, val func loss 0.20917564630508423\n",
      "\n",
      "episode 11, val func loss 0.18596512079238892\n",
      "\n",
      "episode 12, val func loss 0.16820693016052246\n",
      "\n",
      "episode 13, val func loss 0.1969221830368042\n",
      "\n",
      "episode 14, val func loss 0.19595329463481903\n",
      "\n",
      "episode 15, val func loss 0.2098110318183899\n",
      "\n",
      "episode 16, val func loss 0.2033773809671402\n",
      "\n",
      "Val func train loss in epoch 15:0.19151922687888145\n",
      "***********************TIME WAS 4.936812766393026 min*****************************\n",
      "\n",
      "**********************ROUND 60 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.06391625106334686\n",
      "\n",
      "episode 2, policy loss -0.05976491421461105\n",
      "\n",
      "episode 3, policy loss -0.0889737457036972\n",
      "\n",
      "episode 4, policy loss -0.05069712921977043\n",
      "\n",
      "episode 5, policy loss -0.03241639956831932\n",
      "\n",
      "episode 6, policy loss -0.03820356726646423\n",
      "\n",
      "episode 7, policy loss -0.10286912322044373\n",
      "\n",
      "episode 8, policy loss -0.037177979946136475\n",
      "\n",
      "episode 9, policy loss -0.010734443552792072\n",
      "\n",
      "episode 10, policy loss -0.07002529501914978\n",
      "\n",
      "episode 11, policy loss -0.058584313839673996\n",
      "\n",
      "episode 12, policy loss -0.045109666883945465\n",
      "\n",
      "episode 13, policy loss -0.0482122004032135\n",
      "\n",
      "episode 14, policy loss -0.03663317486643791\n",
      "\n",
      "episode 15, policy loss -0.008402767591178417\n",
      "\n",
      "episode 16, policy loss 0.008057162165641785\n",
      "\n",
      "Policy train loss in epoch 0:-0.04647898813709617\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.008028971962630749\n",
      "\n",
      "episode 2, policy loss -0.046451158821582794\n",
      "\n",
      "episode 3, policy loss -0.06774879992008209\n",
      "\n",
      "episode 4, policy loss -0.10795996338129044\n",
      "\n",
      "episode 5, policy loss -0.05684632062911987\n",
      "\n",
      "episode 6, policy loss 0.004622568376362324\n",
      "\n",
      "episode 7, policy loss -0.03507820889353752\n",
      "\n",
      "episode 8, policy loss -0.06530902534723282\n",
      "\n",
      "episode 9, policy loss -0.015057044103741646\n",
      "\n",
      "episode 10, policy loss -0.05054273083806038\n",
      "\n",
      "episode 11, policy loss -0.04152075946331024\n",
      "\n",
      "episode 12, policy loss -0.034031640738248825\n",
      "\n",
      "episode 13, policy loss -0.05062235891819\n",
      "\n",
      "episode 14, policy loss -0.04023203253746033\n",
      "\n",
      "episode 15, policy loss -0.07153935730457306\n",
      "\n",
      "episode 16, policy loss -0.08974162489175797\n",
      "\n",
      "Policy train loss in epoch 1:-0.048505464335903525\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.04025416448712349\n",
      "\n",
      "episode 2, policy loss -0.014783800579607487\n",
      "\n",
      "episode 3, policy loss -0.06689813733100891\n",
      "\n",
      "episode 4, policy loss -0.034325532615184784\n",
      "\n",
      "episode 5, policy loss -0.090038001537323\n",
      "\n",
      "episode 6, policy loss -0.039879392832517624\n",
      "\n",
      "episode 7, policy loss -0.03679066523909569\n",
      "\n",
      "episode 8, policy loss -0.04962056502699852\n",
      "\n",
      "episode 9, policy loss -0.07101712375879288\n",
      "\n",
      "episode 10, policy loss -0.056775350123643875\n",
      "\n",
      "episode 11, policy loss -0.00925997830927372\n",
      "\n",
      "episode 12, policy loss -0.050377752631902695\n",
      "\n",
      "episode 13, policy loss -0.06749855726957321\n",
      "\n",
      "episode 14, policy loss -0.10899247229099274\n",
      "\n",
      "episode 15, policy loss -0.04792972654104233\n",
      "\n",
      "episode 16, policy loss 0.0048491209745407104\n",
      "\n",
      "Policy train loss in epoch 2:-0.048724506224971265\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.06814191490411758\n",
      "\n",
      "episode 2, policy loss -0.10887549072504044\n",
      "\n",
      "episode 3, policy loss -0.04010230675339699\n",
      "\n",
      "episode 4, policy loss -0.04090870916843414\n",
      "\n",
      "episode 5, policy loss -0.05727541446685791\n",
      "\n",
      "episode 6, policy loss -0.015177951194345951\n",
      "\n",
      "episode 7, policy loss -0.03516991063952446\n",
      "\n",
      "episode 8, policy loss -0.0906219333410263\n",
      "\n",
      "episode 9, policy loss -0.05158708989620209\n",
      "\n",
      "episode 10, policy loss -0.032970353960990906\n",
      "\n",
      "episode 11, policy loss -0.04733369126915932\n",
      "\n",
      "episode 12, policy loss -0.07262396067380905\n",
      "\n",
      "episode 13, policy loss -0.05008246749639511\n",
      "\n",
      "episode 14, policy loss -0.006980590987950563\n",
      "\n",
      "episode 15, policy loss 0.002559379441663623\n",
      "\n",
      "episode 16, policy loss -0.06466420739889145\n",
      "\n",
      "Policy train loss in epoch 3:-0.048747288339654915\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19271892309188843\n",
      "\n",
      "episode 2, val func loss 0.19729608297348022\n",
      "\n",
      "episode 3, val func loss 0.20226725935935974\n",
      "\n",
      "episode 4, val func loss 0.20233938097953796\n",
      "\n",
      "episode 5, val func loss 0.19313791394233704\n",
      "\n",
      "episode 6, val func loss 0.17506560683250427\n",
      "\n",
      "episode 7, val func loss 0.18858633935451508\n",
      "\n",
      "episode 8, val func loss 0.19991721212863922\n",
      "\n",
      "episode 9, val func loss 0.21110527217388153\n",
      "\n",
      "episode 10, val func loss 0.1748942881822586\n",
      "\n",
      "episode 11, val func loss 0.19347576797008514\n",
      "\n",
      "episode 12, val func loss 0.20783449709415436\n",
      "\n",
      "episode 13, val func loss 0.23700907826423645\n",
      "\n",
      "episode 14, val func loss 0.16907478868961334\n",
      "\n",
      "episode 15, val func loss 0.21170325577259064\n",
      "\n",
      "episode 16, val func loss 0.19469410181045532\n",
      "\n",
      "Val func train loss in epoch 0:0.19694498553872108\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19707085192203522\n",
      "\n",
      "episode 2, val func loss 0.17711420357227325\n",
      "\n",
      "episode 3, val func loss 0.20814186334609985\n",
      "\n",
      "episode 4, val func loss 0.19917196035385132\n",
      "\n",
      "episode 5, val func loss 0.21287038922309875\n",
      "\n",
      "episode 6, val func loss 0.16952206194400787\n",
      "\n",
      "episode 7, val func loss 0.23581936955451965\n",
      "\n",
      "episode 8, val func loss 0.19372542202472687\n",
      "\n",
      "episode 9, val func loss 0.17243918776512146\n",
      "\n",
      "episode 10, val func loss 0.20078906416893005\n",
      "\n",
      "episode 11, val func loss 0.20810045301914215\n",
      "\n",
      "episode 12, val func loss 0.19224318861961365\n",
      "\n",
      "episode 13, val func loss 0.20439739525318146\n",
      "\n",
      "episode 14, val func loss 0.188447043299675\n",
      "\n",
      "episode 15, val func loss 0.19473499059677124\n",
      "\n",
      "episode 16, val func loss 0.19258971512317657\n",
      "\n",
      "Val func train loss in epoch 1:0.19669857248663902\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.2361215204000473\n",
      "\n",
      "episode 2, val func loss 0.19533663988113403\n",
      "\n",
      "episode 3, val func loss 0.2117173671722412\n",
      "\n",
      "episode 4, val func loss 0.19505858421325684\n",
      "\n",
      "episode 5, val func loss 0.20834222435951233\n",
      "\n",
      "episode 6, val func loss 0.1780744045972824\n",
      "\n",
      "episode 7, val func loss 0.20110975205898285\n",
      "\n",
      "episode 8, val func loss 0.16926614940166473\n",
      "\n",
      "episode 9, val func loss 0.20755687355995178\n",
      "\n",
      "episode 10, val func loss 0.20032194256782532\n",
      "\n",
      "episode 11, val func loss 0.16941335797309875\n",
      "\n",
      "episode 12, val func loss 0.18776176869869232\n",
      "\n",
      "episode 13, val func loss 0.19330962002277374\n",
      "\n",
      "episode 14, val func loss 0.19190983474254608\n",
      "\n",
      "episode 15, val func loss 0.1976851224899292\n",
      "\n",
      "episode 16, val func loss 0.20865292847156525\n",
      "\n",
      "Val func train loss in epoch 2:0.1969773806631565\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19168953597545624\n",
      "\n",
      "episode 2, val func loss 0.19925826787948608\n",
      "\n",
      "episode 3, val func loss 0.20689617097377777\n",
      "\n",
      "episode 4, val func loss 0.21172618865966797\n",
      "\n",
      "episode 5, val func loss 0.1707180291414261\n",
      "\n",
      "episode 6, val func loss 0.20149654150009155\n",
      "\n",
      "episode 7, val func loss 0.23573875427246094\n",
      "\n",
      "episode 8, val func loss 0.20897451043128967\n",
      "\n",
      "episode 9, val func loss 0.17638172209262848\n",
      "\n",
      "episode 10, val func loss 0.1977829784154892\n",
      "\n",
      "episode 11, val func loss 0.17112502455711365\n",
      "\n",
      "episode 12, val func loss 0.19343525171279907\n",
      "\n",
      "episode 13, val func loss 0.20415496826171875\n",
      "\n",
      "episode 14, val func loss 0.18813186883926392\n",
      "\n",
      "episode 15, val func loss 0.19481462240219116\n",
      "\n",
      "episode 16, val func loss 0.1928393840789795\n",
      "\n",
      "Val func train loss in epoch 3:0.196572738699615\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1754196584224701\n",
      "\n",
      "episode 2, val func loss 0.1933242827653885\n",
      "\n",
      "episode 3, val func loss 0.21331621706485748\n",
      "\n",
      "episode 4, val func loss 0.1973366141319275\n",
      "\n",
      "episode 5, val func loss 0.2082008719444275\n",
      "\n",
      "episode 6, val func loss 0.17069844901561737\n",
      "\n",
      "episode 7, val func loss 0.1732795238494873\n",
      "\n",
      "episode 8, val func loss 0.1919190138578415\n",
      "\n",
      "episode 9, val func loss 0.1925191879272461\n",
      "\n",
      "episode 10, val func loss 0.20781196653842926\n",
      "\n",
      "episode 11, val func loss 0.20353856682777405\n",
      "\n",
      "episode 12, val func loss 0.20045062899589539\n",
      "\n",
      "episode 13, val func loss 0.1881016492843628\n",
      "\n",
      "episode 14, val func loss 0.23675227165222168\n",
      "\n",
      "episode 15, val func loss 0.19481860101222992\n",
      "\n",
      "episode 16, val func loss 0.19955486059188843\n",
      "\n",
      "Val func train loss in epoch 4:0.19669014774262905\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19509339332580566\n",
      "\n",
      "episode 2, val func loss 0.18911489844322205\n",
      "\n",
      "episode 3, val func loss 0.2116432636976242\n",
      "\n",
      "episode 4, val func loss 0.19215093553066254\n",
      "\n",
      "episode 5, val func loss 0.1764516830444336\n",
      "\n",
      "episode 6, val func loss 0.20083579421043396\n",
      "\n",
      "episode 7, val func loss 0.19737115502357483\n",
      "\n",
      "episode 8, val func loss 0.19934022426605225\n",
      "\n",
      "episode 9, val func loss 0.23735401034355164\n",
      "\n",
      "episode 10, val func loss 0.17115145921707153\n",
      "\n",
      "episode 11, val func loss 0.16906847059726715\n",
      "\n",
      "episode 12, val func loss 0.2093115746974945\n",
      "\n",
      "episode 13, val func loss 0.1930859237909317\n",
      "\n",
      "episode 14, val func loss 0.19377760589122772\n",
      "\n",
      "episode 15, val func loss 0.2080654352903366\n",
      "\n",
      "episode 16, val func loss 0.20323589444160461\n",
      "\n",
      "Val func train loss in epoch 5:0.1966907326132059\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1978161334991455\n",
      "\n",
      "episode 2, val func loss 0.2353856861591339\n",
      "\n",
      "episode 3, val func loss 0.2078690379858017\n",
      "\n",
      "episode 4, val func loss 0.1932549923658371\n",
      "\n",
      "episode 5, val func loss 0.19562853872776031\n",
      "\n",
      "episode 6, val func loss 0.1918533593416214\n",
      "\n",
      "episode 7, val func loss 0.2117096483707428\n",
      "\n",
      "episode 8, val func loss 0.19942054152488708\n",
      "\n",
      "episode 9, val func loss 0.188869908452034\n",
      "\n",
      "episode 10, val func loss 0.17540062963962555\n",
      "\n",
      "episode 11, val func loss 0.2003154158592224\n",
      "\n",
      "episode 12, val func loss 0.16863837838172913\n",
      "\n",
      "episode 13, val func loss 0.1955614537000656\n",
      "\n",
      "episode 14, val func loss 0.20944106578826904\n",
      "\n",
      "episode 15, val func loss 0.21156664192676544\n",
      "\n",
      "episode 16, val func loss 0.16882957518100739\n",
      "\n",
      "Val func train loss in epoch 6:0.19697256293147802\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19916240870952606\n",
      "\n",
      "episode 2, val func loss 0.20132392644882202\n",
      "\n",
      "episode 3, val func loss 0.1892537623643875\n",
      "\n",
      "episode 4, val func loss 0.23549920320510864\n",
      "\n",
      "episode 5, val func loss 0.1933402568101883\n",
      "\n",
      "episode 6, val func loss 0.2080746591091156\n",
      "\n",
      "episode 7, val func loss 0.1942264288663864\n",
      "\n",
      "episode 8, val func loss 0.17571520805358887\n",
      "\n",
      "episode 9, val func loss 0.2098332941532135\n",
      "\n",
      "episode 10, val func loss 0.19290488958358765\n",
      "\n",
      "episode 11, val func loss 0.19793301820755005\n",
      "\n",
      "episode 12, val func loss 0.20306310057640076\n",
      "\n",
      "episode 13, val func loss 0.17229628562927246\n",
      "\n",
      "episode 14, val func loss 0.19452831149101257\n",
      "\n",
      "episode 15, val func loss 0.2122257947921753\n",
      "\n",
      "episode 16, val func loss 0.17010490596294403\n",
      "\n",
      "Val func train loss in epoch 7:0.19684284087270498\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.2086428999900818\n",
      "\n",
      "episode 2, val func loss 0.20095157623291016\n",
      "\n",
      "episode 3, val func loss 0.16883733868598938\n",
      "\n",
      "episode 4, val func loss 0.20784813165664673\n",
      "\n",
      "episode 5, val func loss 0.19937843084335327\n",
      "\n",
      "episode 6, val func loss 0.1938445270061493\n",
      "\n",
      "episode 7, val func loss 0.23736265301704407\n",
      "\n",
      "episode 8, val func loss 0.19728060066699982\n",
      "\n",
      "episode 9, val func loss 0.19203662872314453\n",
      "\n",
      "episode 10, val func loss 0.20263582468032837\n",
      "\n",
      "episode 11, val func loss 0.2115865796804428\n",
      "\n",
      "episode 12, val func loss 0.19591832160949707\n",
      "\n",
      "episode 13, val func loss 0.19209779798984528\n",
      "\n",
      "episode 14, val func loss 0.1908736675977707\n",
      "\n",
      "episode 15, val func loss 0.17433762550354004\n",
      "\n",
      "episode 16, val func loss 0.17515642940998077\n",
      "\n",
      "Val func train loss in epoch 8:0.19679931458085775\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.16904772818088531\n",
      "\n",
      "episode 2, val func loss 0.19021718204021454\n",
      "\n",
      "episode 3, val func loss 0.1953364461660385\n",
      "\n",
      "episode 4, val func loss 0.20172898471355438\n",
      "\n",
      "episode 5, val func loss 0.1945306807756424\n",
      "\n",
      "episode 6, val func loss 0.1752132624387741\n",
      "\n",
      "episode 7, val func loss 0.1944519579410553\n",
      "\n",
      "episode 8, val func loss 0.20770537853240967\n",
      "\n",
      "episode 9, val func loss 0.19699810445308685\n",
      "\n",
      "episode 10, val func loss 0.21182100474834442\n",
      "\n",
      "episode 11, val func loss 0.23471948504447937\n",
      "\n",
      "episode 12, val func loss 0.20361502468585968\n",
      "\n",
      "episode 13, val func loss 0.17679837346076965\n",
      "\n",
      "episode 14, val func loss 0.1943344622850418\n",
      "\n",
      "episode 15, val func loss 0.2046438306570053\n",
      "\n",
      "episode 16, val func loss 0.20897027850151062\n",
      "\n",
      "Val func train loss in epoch 9:0.197508261539042\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19756215810775757\n",
      "\n",
      "episode 2, val func loss 0.17101912200450897\n",
      "\n",
      "episode 3, val func loss 0.19159351289272308\n",
      "\n",
      "episode 4, val func loss 0.19340625405311584\n",
      "\n",
      "episode 5, val func loss 0.2080218493938446\n",
      "\n",
      "episode 6, val func loss 0.1991891860961914\n",
      "\n",
      "episode 7, val func loss 0.20089656114578247\n",
      "\n",
      "episode 8, val func loss 0.1945360004901886\n",
      "\n",
      "episode 9, val func loss 0.236561119556427\n",
      "\n",
      "episode 10, val func loss 0.18869929015636444\n",
      "\n",
      "episode 11, val func loss 0.16976004838943481\n",
      "\n",
      "episode 12, val func loss 0.19223104417324066\n",
      "\n",
      "episode 13, val func loss 0.21235010027885437\n",
      "\n",
      "episode 14, val func loss 0.20802025496959686\n",
      "\n",
      "episode 15, val func loss 0.17700760066509247\n",
      "\n",
      "episode 16, val func loss 0.2022450566291809\n",
      "\n",
      "Val func train loss in epoch 10:0.196443697437644\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18933014571666718\n",
      "\n",
      "episode 2, val func loss 0.1995181292295456\n",
      "\n",
      "episode 3, val func loss 0.17564688622951508\n",
      "\n",
      "episode 4, val func loss 0.20960132777690887\n",
      "\n",
      "episode 5, val func loss 0.19259575009346008\n",
      "\n",
      "episode 6, val func loss 0.20061509311199188\n",
      "\n",
      "episode 7, val func loss 0.21332918107509613\n",
      "\n",
      "episode 8, val func loss 0.19737736880779266\n",
      "\n",
      "episode 9, val func loss 0.20784790813922882\n",
      "\n",
      "episode 10, val func loss 0.19416444003582\n",
      "\n",
      "episode 11, val func loss 0.23496893048286438\n",
      "\n",
      "episode 12, val func loss 0.1954369992017746\n",
      "\n",
      "episode 13, val func loss 0.17205440998077393\n",
      "\n",
      "episode 14, val func loss 0.1727128028869629\n",
      "\n",
      "episode 15, val func loss 0.2028244286775589\n",
      "\n",
      "episode 16, val func loss 0.19332154095172882\n",
      "\n",
      "Val func train loss in epoch 11:0.1969590838998556\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19332581758499146\n",
      "\n",
      "episode 2, val func loss 0.16900961101055145\n",
      "\n",
      "episode 3, val func loss 0.21007584035396576\n",
      "\n",
      "episode 4, val func loss 0.169691801071167\n",
      "\n",
      "episode 5, val func loss 0.20457488298416138\n",
      "\n",
      "episode 6, val func loss 0.20067563652992249\n",
      "\n",
      "episode 7, val func loss 0.1933414191007614\n",
      "\n",
      "episode 8, val func loss 0.1920207142829895\n",
      "\n",
      "episode 9, val func loss 0.1756221503019333\n",
      "\n",
      "episode 10, val func loss 0.19471417367458344\n",
      "\n",
      "episode 11, val func loss 0.23664626479148865\n",
      "\n",
      "episode 12, val func loss 0.19928893446922302\n",
      "\n",
      "episode 13, val func loss 0.21086981892585754\n",
      "\n",
      "episode 14, val func loss 0.2074098438024521\n",
      "\n",
      "episode 15, val func loss 0.19023476541042328\n",
      "\n",
      "episode 16, val func loss 0.19728849828243256\n",
      "\n",
      "Val func train loss in epoch 12:0.19654938578605652\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18976010382175446\n",
      "\n",
      "episode 2, val func loss 0.17612433433532715\n",
      "\n",
      "episode 3, val func loss 0.20744110643863678\n",
      "\n",
      "episode 4, val func loss 0.19208556413650513\n",
      "\n",
      "episode 5, val func loss 0.19382581114768982\n",
      "\n",
      "episode 6, val func loss 0.2156321108341217\n",
      "\n",
      "episode 7, val func loss 0.16919530928134918\n",
      "\n",
      "episode 8, val func loss 0.1982528418302536\n",
      "\n",
      "episode 9, val func loss 0.20948858559131622\n",
      "\n",
      "episode 10, val func loss 0.23623540997505188\n",
      "\n",
      "episode 11, val func loss 0.2026984691619873\n",
      "\n",
      "episode 12, val func loss 0.19554661214351654\n",
      "\n",
      "episode 13, val func loss 0.2030484825372696\n",
      "\n",
      "episode 14, val func loss 0.19259439408779144\n",
      "\n",
      "episode 15, val func loss 0.19986851513385773\n",
      "\n",
      "episode 16, val func loss 0.17123718559741974\n",
      "\n",
      "Val func train loss in epoch 13:0.19706467725336552\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.20806115865707397\n",
      "\n",
      "episode 2, val func loss 0.17104393243789673\n",
      "\n",
      "episode 3, val func loss 0.19452834129333496\n",
      "\n",
      "episode 4, val func loss 0.20856104791164398\n",
      "\n",
      "episode 5, val func loss 0.19238393008708954\n",
      "\n",
      "episode 6, val func loss 0.1943041980266571\n",
      "\n",
      "episode 7, val func loss 0.21656161546707153\n",
      "\n",
      "episode 8, val func loss 0.18773046135902405\n",
      "\n",
      "episode 9, val func loss 0.19820795953273773\n",
      "\n",
      "episode 10, val func loss 0.20103925466537476\n",
      "\n",
      "episode 11, val func loss 0.2026401162147522\n",
      "\n",
      "episode 12, val func loss 0.19940418004989624\n",
      "\n",
      "episode 13, val func loss 0.192147359251976\n",
      "\n",
      "episode 14, val func loss 0.23554721474647522\n",
      "\n",
      "episode 15, val func loss 0.17909573018550873\n",
      "\n",
      "episode 16, val func loss 0.1721632182598114\n",
      "\n",
      "Val func train loss in epoch 14:0.19708873238414526\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18930332362651825\n",
      "\n",
      "episode 2, val func loss 0.17481502890586853\n",
      "\n",
      "episode 3, val func loss 0.20063064992427826\n",
      "\n",
      "episode 4, val func loss 0.21048647165298462\n",
      "\n",
      "episode 5, val func loss 0.168373242020607\n",
      "\n",
      "episode 6, val func loss 0.19666269421577454\n",
      "\n",
      "episode 7, val func loss 0.20041805505752563\n",
      "\n",
      "episode 8, val func loss 0.16858495771884918\n",
      "\n",
      "episode 9, val func loss 0.23830460011959076\n",
      "\n",
      "episode 10, val func loss 0.20779919624328613\n",
      "\n",
      "episode 11, val func loss 0.2114659696817398\n",
      "\n",
      "episode 12, val func loss 0.20252257585525513\n",
      "\n",
      "episode 13, val func loss 0.19783248007297516\n",
      "\n",
      "episode 14, val func loss 0.1963738203048706\n",
      "\n",
      "episode 15, val func loss 0.19250375032424927\n",
      "\n",
      "episode 16, val func loss 0.2022571861743927\n",
      "\n",
      "Val func train loss in epoch 15:0.19739587511867285\n",
      "***********************TIME WAS 4.926081911722819 min*****************************\n",
      "\n",
      "**********************ROUND 61 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.08146505802869797\n",
      "\n",
      "episode 2, policy loss -0.06678936630487442\n",
      "\n",
      "episode 3, policy loss -0.012959517538547516\n",
      "\n",
      "episode 4, policy loss -0.03640765696763992\n",
      "\n",
      "episode 5, policy loss -0.08303482085466385\n",
      "\n",
      "episode 6, policy loss -0.037859175354242325\n",
      "\n",
      "episode 7, policy loss -0.045271776616573334\n",
      "\n",
      "episode 8, policy loss -0.09266446530818939\n",
      "\n",
      "episode 9, policy loss -0.059374820441007614\n",
      "\n",
      "episode 10, policy loss 0.011656916700303555\n",
      "\n",
      "episode 11, policy loss -0.02058134786784649\n",
      "\n",
      "episode 12, policy loss 0.018053313717246056\n",
      "\n",
      "episode 13, policy loss -0.04216217249631882\n",
      "\n",
      "episode 14, policy loss -0.02686210907995701\n",
      "\n",
      "episode 15, policy loss -0.07262977212667465\n",
      "\n",
      "episode 16, policy loss -0.07833027094602585\n",
      "\n",
      "Policy train loss in epoch 0:-0.04541763121960685\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.08010267466306686\n",
      "\n",
      "episode 2, policy loss -0.03755325824022293\n",
      "\n",
      "episode 3, policy loss 0.019266299903392792\n",
      "\n",
      "episode 4, policy loss -0.014804046601057053\n",
      "\n",
      "episode 5, policy loss -0.03884227201342583\n",
      "\n",
      "episode 6, policy loss -0.09023284912109375\n",
      "\n",
      "episode 7, policy loss -0.08335258066654205\n",
      "\n",
      "episode 8, policy loss -0.07229547202587128\n",
      "\n",
      "episode 9, policy loss -0.06200938671827316\n",
      "\n",
      "episode 10, policy loss -0.030518794432282448\n",
      "\n",
      "episode 11, policy loss -0.04653381556272507\n",
      "\n",
      "episode 12, policy loss -0.021494455635547638\n",
      "\n",
      "episode 13, policy loss -0.09972836822271347\n",
      "\n",
      "episode 14, policy loss -0.07721059024333954\n",
      "\n",
      "episode 15, policy loss -0.042763177305459976\n",
      "\n",
      "episode 16, policy loss 0.010957184247672558\n",
      "\n",
      "Policy train loss in epoch 1:-0.04795114108128473\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.021931959316134453\n",
      "\n",
      "episode 2, policy loss -0.08618749678134918\n",
      "\n",
      "episode 3, policy loss -0.03923671692609787\n",
      "\n",
      "episode 4, policy loss -0.043299928307533264\n",
      "\n",
      "episode 5, policy loss -0.012479935772716999\n",
      "\n",
      "episode 6, policy loss -0.05979571118950844\n",
      "\n",
      "episode 7, policy loss 0.009394371882081032\n",
      "\n",
      "episode 8, policy loss -0.03734486550092697\n",
      "\n",
      "episode 9, policy loss -0.08244981616735458\n",
      "\n",
      "episode 10, policy loss -0.0845213383436203\n",
      "\n",
      "episode 11, policy loss -0.07619325816631317\n",
      "\n",
      "episode 12, policy loss -0.03067617118358612\n",
      "\n",
      "episode 13, policy loss -0.04729852080345154\n",
      "\n",
      "episode 14, policy loss -0.07197660207748413\n",
      "\n",
      "episode 15, policy loss -0.09809839725494385\n",
      "\n",
      "episode 16, policy loss 0.017375510185956955\n",
      "\n",
      "Policy train loss in epoch 2:-0.04779505223268643\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.0827183723449707\n",
      "\n",
      "episode 2, policy loss -0.08997482061386108\n",
      "\n",
      "episode 3, policy loss -0.0616743266582489\n",
      "\n",
      "episode 4, policy loss -0.030683519318699837\n",
      "\n",
      "episode 5, policy loss 0.009540063329041004\n",
      "\n",
      "episode 6, policy loss -0.08686317503452301\n",
      "\n",
      "episode 7, policy loss -0.07274968922138214\n",
      "\n",
      "episode 8, policy loss -0.03752376511693001\n",
      "\n",
      "episode 9, policy loss -0.04093480855226517\n",
      "\n",
      "episode 10, policy loss -0.01576823741197586\n",
      "\n",
      "episode 11, policy loss -0.07709338515996933\n",
      "\n",
      "episode 12, policy loss -0.04514634236693382\n",
      "\n",
      "episode 13, policy loss -0.09965542703866959\n",
      "\n",
      "episode 14, policy loss 0.018532399088144302\n",
      "\n",
      "episode 15, policy loss -0.018566953018307686\n",
      "\n",
      "episode 16, policy loss -0.04595230519771576\n",
      "\n",
      "Policy train loss in epoch 3:-0.048577041539829224\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1986747831106186\n",
      "\n",
      "episode 2, val func loss 0.1797059327363968\n",
      "\n",
      "episode 3, val func loss 0.22200895845890045\n",
      "\n",
      "episode 4, val func loss 0.19895996153354645\n",
      "\n",
      "episode 5, val func loss 0.22530782222747803\n",
      "\n",
      "episode 6, val func loss 0.2050374299287796\n",
      "\n",
      "episode 7, val func loss 0.1930534839630127\n",
      "\n",
      "episode 8, val func loss 0.2307700365781784\n",
      "\n",
      "episode 9, val func loss 0.21943020820617676\n",
      "\n",
      "episode 10, val func loss 0.19218839704990387\n",
      "\n",
      "episode 11, val func loss 0.2074245810508728\n",
      "\n",
      "episode 12, val func loss 0.17088130116462708\n",
      "\n",
      "episode 13, val func loss 0.19189980626106262\n",
      "\n",
      "episode 14, val func loss 0.17241798341274261\n",
      "\n",
      "episode 15, val func loss 0.21163739264011383\n",
      "\n",
      "episode 16, val func loss 0.20837374031543732\n",
      "\n",
      "Val func train loss in epoch 0:0.2017357386648655\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.20700277388095856\n",
      "\n",
      "episode 2, val func loss 0.19942165911197662\n",
      "\n",
      "episode 3, val func loss 0.16784337162971497\n",
      "\n",
      "episode 4, val func loss 0.19195450842380524\n",
      "\n",
      "episode 5, val func loss 0.20725329220294952\n",
      "\n",
      "episode 6, val func loss 0.17213279008865356\n",
      "\n",
      "episode 7, val func loss 0.17965492606163025\n",
      "\n",
      "episode 8, val func loss 0.22091460227966309\n",
      "\n",
      "episode 9, val func loss 0.23390106856822968\n",
      "\n",
      "episode 10, val func loss 0.22385160624980927\n",
      "\n",
      "episode 11, val func loss 0.2067003846168518\n",
      "\n",
      "episode 12, val func loss 0.2081906944513321\n",
      "\n",
      "episode 13, val func loss 0.1957237869501114\n",
      "\n",
      "episode 14, val func loss 0.1977401077747345\n",
      "\n",
      "episode 15, val func loss 0.19875597953796387\n",
      "\n",
      "episode 16, val func loss 0.2195460945367813\n",
      "\n",
      "Val func train loss in epoch 1:0.20191172789782286\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19058911502361298\n",
      "\n",
      "episode 2, val func loss 0.22072413563728333\n",
      "\n",
      "episode 3, val func loss 0.22035491466522217\n",
      "\n",
      "episode 4, val func loss 0.20604519546031952\n",
      "\n",
      "episode 5, val func loss 0.19832931458950043\n",
      "\n",
      "episode 6, val func loss 0.18067418038845062\n",
      "\n",
      "episode 7, val func loss 0.22400985658168793\n",
      "\n",
      "episode 8, val func loss 0.1698693484067917\n",
      "\n",
      "episode 9, val func loss 0.2321082055568695\n",
      "\n",
      "episode 10, val func loss 0.17447911202907562\n",
      "\n",
      "episode 11, val func loss 0.2084542214870453\n",
      "\n",
      "episode 12, val func loss 0.19982171058654785\n",
      "\n",
      "episode 13, val func loss 0.20766320824623108\n",
      "\n",
      "episode 14, val func loss 0.20515792071819305\n",
      "\n",
      "episode 15, val func loss 0.19189026951789856\n",
      "\n",
      "episode 16, val func loss 0.1922248750925064\n",
      "\n",
      "Val func train loss in epoch 2:0.20139972399920225\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1800553798675537\n",
      "\n",
      "episode 2, val func loss 0.20937882363796234\n",
      "\n",
      "episode 3, val func loss 0.19081920385360718\n",
      "\n",
      "episode 4, val func loss 0.20628346502780914\n",
      "\n",
      "episode 5, val func loss 0.21995262801647186\n",
      "\n",
      "episode 6, val func loss 0.17524456977844238\n",
      "\n",
      "episode 7, val func loss 0.1924675703048706\n",
      "\n",
      "episode 8, val func loss 0.19848954677581787\n",
      "\n",
      "episode 9, val func loss 0.20547287166118622\n",
      "\n",
      "episode 10, val func loss 0.22461339831352234\n",
      "\n",
      "episode 11, val func loss 0.1685894876718521\n",
      "\n",
      "episode 12, val func loss 0.1996055543422699\n",
      "\n",
      "episode 13, val func loss 0.19144703447818756\n",
      "\n",
      "episode 14, val func loss 0.2085038125514984\n",
      "\n",
      "episode 15, val func loss 0.22165502607822418\n",
      "\n",
      "episode 16, val func loss 0.2337639033794403\n",
      "\n",
      "Val func train loss in epoch 3:0.20164639223366976\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18015435338020325\n",
      "\n",
      "episode 2, val func loss 0.2062670737504959\n",
      "\n",
      "episode 3, val func loss 0.22276829183101654\n",
      "\n",
      "episode 4, val func loss 0.20724628865718842\n",
      "\n",
      "episode 5, val func loss 0.19311828911304474\n",
      "\n",
      "episode 6, val func loss 0.2307823896408081\n",
      "\n",
      "episode 7, val func loss 0.20763860642910004\n",
      "\n",
      "episode 8, val func loss 0.21786226332187653\n",
      "\n",
      "episode 9, val func loss 0.18010002374649048\n",
      "\n",
      "episode 10, val func loss 0.1937270164489746\n",
      "\n",
      "episode 11, val func loss 0.19335539638996124\n",
      "\n",
      "episode 12, val func loss 0.19778428971767426\n",
      "\n",
      "episode 13, val func loss 0.2207673192024231\n",
      "\n",
      "episode 14, val func loss 0.1672486513853073\n",
      "\n",
      "episode 15, val func loss 0.19954748451709747\n",
      "\n",
      "episode 16, val func loss 0.20845550298690796\n",
      "\n",
      "Val func train loss in epoch 4:0.20167645253241062\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.20009303092956543\n",
      "\n",
      "episode 2, val func loss 0.20027068257331848\n",
      "\n",
      "episode 3, val func loss 0.20885007083415985\n",
      "\n",
      "episode 4, val func loss 0.23573678731918335\n",
      "\n",
      "episode 5, val func loss 0.16968846321105957\n",
      "\n",
      "episode 6, val func loss 0.20783157646656036\n",
      "\n",
      "episode 7, val func loss 0.20601283013820648\n",
      "\n",
      "episode 8, val func loss 0.19439636170864105\n",
      "\n",
      "episode 9, val func loss 0.19264978170394897\n",
      "\n",
      "episode 10, val func loss 0.218317449092865\n",
      "\n",
      "episode 11, val func loss 0.17616307735443115\n",
      "\n",
      "episode 12, val func loss 0.21996237337589264\n",
      "\n",
      "episode 13, val func loss 0.19186314940452576\n",
      "\n",
      "episode 14, val func loss 0.17943382263183594\n",
      "\n",
      "episode 15, val func loss 0.22677907347679138\n",
      "\n",
      "episode 16, val func loss 0.20869740843772888\n",
      "\n",
      "Val func train loss in epoch 5:0.20229662116616964\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1797025501728058\n",
      "\n",
      "episode 2, val func loss 0.1911775767803192\n",
      "\n",
      "episode 3, val func loss 0.23441244661808014\n",
      "\n",
      "episode 4, val func loss 0.2096697837114334\n",
      "\n",
      "episode 5, val func loss 0.1695627123117447\n",
      "\n",
      "episode 6, val func loss 0.19191376864910126\n",
      "\n",
      "episode 7, val func loss 0.20572082698345184\n",
      "\n",
      "episode 8, val func loss 0.17506477236747742\n",
      "\n",
      "episode 9, val func loss 0.20574821531772614\n",
      "\n",
      "episode 10, val func loss 0.19062991440296173\n",
      "\n",
      "episode 11, val func loss 0.22001099586486816\n",
      "\n",
      "episode 12, val func loss 0.2075255960226059\n",
      "\n",
      "episode 13, val func loss 0.2201469987630844\n",
      "\n",
      "episode 14, val func loss 0.19845175743103027\n",
      "\n",
      "episode 15, val func loss 0.2230750173330307\n",
      "\n",
      "episode 16, val func loss 0.2021019607782364\n",
      "\n",
      "Val func train loss in epoch 6:0.20155718084424734\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19214512407779694\n",
      "\n",
      "episode 2, val func loss 0.17615766823291779\n",
      "\n",
      "episode 3, val func loss 0.21971331536769867\n",
      "\n",
      "episode 4, val func loss 0.19181591272354126\n",
      "\n",
      "episode 5, val func loss 0.22475570440292358\n",
      "\n",
      "episode 6, val func loss 0.20633482933044434\n",
      "\n",
      "episode 7, val func loss 0.17945225536823273\n",
      "\n",
      "episode 8, val func loss 0.20757527649402618\n",
      "\n",
      "episode 9, val func loss 0.19232045114040375\n",
      "\n",
      "episode 10, val func loss 0.20892193913459778\n",
      "\n",
      "episode 11, val func loss 0.20060008764266968\n",
      "\n",
      "episode 12, val func loss 0.21974138915538788\n",
      "\n",
      "episode 13, val func loss 0.19810859858989716\n",
      "\n",
      "episode 14, val func loss 0.23220306634902954\n",
      "\n",
      "episode 15, val func loss 0.1717952936887741\n",
      "\n",
      "episode 16, val func loss 0.20537783205509186\n",
      "\n",
      "Val func train loss in epoch 7:0.20168867148458958\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.21893469989299774\n",
      "\n",
      "episode 2, val func loss 0.2196921706199646\n",
      "\n",
      "episode 3, val func loss 0.18094375729560852\n",
      "\n",
      "episode 4, val func loss 0.1752742975950241\n",
      "\n",
      "episode 5, val func loss 0.16941484808921814\n",
      "\n",
      "episode 6, val func loss 0.19175094366073608\n",
      "\n",
      "episode 7, val func loss 0.23582811653614044\n",
      "\n",
      "episode 8, val func loss 0.19110365211963654\n",
      "\n",
      "episode 9, val func loss 0.20985794067382812\n",
      "\n",
      "episode 10, val func loss 0.1990615576505661\n",
      "\n",
      "episode 11, val func loss 0.2067556232213974\n",
      "\n",
      "episode 12, val func loss 0.20930825173854828\n",
      "\n",
      "episode 13, val func loss 0.19250790774822235\n",
      "\n",
      "episode 14, val func loss 0.20477332174777985\n",
      "\n",
      "episode 15, val func loss 0.22263303399085999\n",
      "\n",
      "episode 16, val func loss 0.1986750364303589\n",
      "\n",
      "Val func train loss in epoch 8:0.20165719743818045\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.23098646104335785\n",
      "\n",
      "episode 2, val func loss 0.19924207031726837\n",
      "\n",
      "episode 3, val func loss 0.19410867989063263\n",
      "\n",
      "episode 4, val func loss 0.19226543605327606\n",
      "\n",
      "episode 5, val func loss 0.2079031616449356\n",
      "\n",
      "episode 6, val func loss 0.2192223072052002\n",
      "\n",
      "episode 7, val func loss 0.20554614067077637\n",
      "\n",
      "episode 8, val func loss 0.2229136824607849\n",
      "\n",
      "episode 9, val func loss 0.2049652636051178\n",
      "\n",
      "episode 10, val func loss 0.21880826354026794\n",
      "\n",
      "episode 11, val func loss 0.19394735991954803\n",
      "\n",
      "episode 12, val func loss 0.20158760249614716\n",
      "\n",
      "episode 13, val func loss 0.1698005348443985\n",
      "\n",
      "episode 14, val func loss 0.17333561182022095\n",
      "\n",
      "episode 15, val func loss 0.1792963296175003\n",
      "\n",
      "episode 16, val func loss 0.2102251499891281\n",
      "\n",
      "Val func train loss in epoch 9:0.20150962844491005\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19953955709934235\n",
      "\n",
      "episode 2, val func loss 0.1928856521844864\n",
      "\n",
      "episode 3, val func loss 0.2383953183889389\n",
      "\n",
      "episode 4, val func loss 0.19120772182941437\n",
      "\n",
      "episode 5, val func loss 0.19161489605903625\n",
      "\n",
      "episode 6, val func loss 0.20566414296627045\n",
      "\n",
      "episode 7, val func loss 0.2192186713218689\n",
      "\n",
      "episode 8, val func loss 0.172123521566391\n",
      "\n",
      "episode 9, val func loss 0.2083481103181839\n",
      "\n",
      "episode 10, val func loss 0.18085265159606934\n",
      "\n",
      "episode 11, val func loss 0.19844704866409302\n",
      "\n",
      "episode 12, val func loss 0.17410027980804443\n",
      "\n",
      "episode 13, val func loss 0.22136905789375305\n",
      "\n",
      "episode 14, val func loss 0.2256373167037964\n",
      "\n",
      "episode 15, val func loss 0.20791518688201904\n",
      "\n",
      "episode 16, val func loss 0.20602355897426605\n",
      "\n",
      "Val func train loss in epoch 10:0.20208391826599836\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19132311642169952\n",
      "\n",
      "episode 2, val func loss 0.21852965652942657\n",
      "\n",
      "episode 3, val func loss 0.1726101189851761\n",
      "\n",
      "episode 4, val func loss 0.1927734762430191\n",
      "\n",
      "episode 5, val func loss 0.20719753205776215\n",
      "\n",
      "episode 6, val func loss 0.22402606904506683\n",
      "\n",
      "episode 7, val func loss 0.18004395067691803\n",
      "\n",
      "episode 8, val func loss 0.20023590326309204\n",
      "\n",
      "episode 9, val func loss 0.2201751321554184\n",
      "\n",
      "episode 10, val func loss 0.2321401685476303\n",
      "\n",
      "episode 11, val func loss 0.20867542922496796\n",
      "\n",
      "episode 12, val func loss 0.20589224994182587\n",
      "\n",
      "episode 13, val func loss 0.1990070790052414\n",
      "\n",
      "episode 14, val func loss 0.19388531148433685\n",
      "\n",
      "episode 15, val func loss 0.20578551292419434\n",
      "\n",
      "episode 16, val func loss 0.1752825826406479\n",
      "\n",
      "Val func train loss in epoch 11:0.20172395557165146\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17933478951454163\n",
      "\n",
      "episode 2, val func loss 0.19913671910762787\n",
      "\n",
      "episode 3, val func loss 0.19100293517112732\n",
      "\n",
      "episode 4, val func loss 0.2259618192911148\n",
      "\n",
      "episode 5, val func loss 0.21183866262435913\n",
      "\n",
      "episode 6, val func loss 0.20659059286117554\n",
      "\n",
      "episode 7, val func loss 0.23396314680576324\n",
      "\n",
      "episode 8, val func loss 0.19271790981292725\n",
      "\n",
      "episode 9, val func loss 0.20558267831802368\n",
      "\n",
      "episode 10, val func loss 0.20817118883132935\n",
      "\n",
      "episode 11, val func loss 0.22228902578353882\n",
      "\n",
      "episode 12, val func loss 0.17700029909610748\n",
      "\n",
      "episode 13, val func loss 0.1786399483680725\n",
      "\n",
      "episode 14, val func loss 0.21975748240947723\n",
      "\n",
      "episode 15, val func loss 0.19840900599956512\n",
      "\n",
      "episode 16, val func loss 0.19096799194812775\n",
      "\n",
      "Val func train loss in epoch 12:0.20258526224642992\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19111637771129608\n",
      "\n",
      "episode 2, val func loss 0.19083485007286072\n",
      "\n",
      "episode 3, val func loss 0.22756126523017883\n",
      "\n",
      "episode 4, val func loss 0.1993146538734436\n",
      "\n",
      "episode 5, val func loss 0.17969927191734314\n",
      "\n",
      "episode 6, val func loss 0.22083084285259247\n",
      "\n",
      "episode 7, val func loss 0.19838735461235046\n",
      "\n",
      "episode 8, val func loss 0.1725401133298874\n",
      "\n",
      "episode 9, val func loss 0.2321111261844635\n",
      "\n",
      "episode 10, val func loss 0.17364831268787384\n",
      "\n",
      "episode 11, val func loss 0.20657750964164734\n",
      "\n",
      "episode 12, val func loss 0.22078758478164673\n",
      "\n",
      "episode 13, val func loss 0.2082756757736206\n",
      "\n",
      "episode 14, val func loss 0.20529183745384216\n",
      "\n",
      "episode 15, val func loss 0.19238369166851044\n",
      "\n",
      "episode 16, val func loss 0.2082054316997528\n",
      "\n",
      "Val func train loss in epoch 13:0.20172286871820688\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19189755618572235\n",
      "\n",
      "episode 2, val func loss 0.19231563806533813\n",
      "\n",
      "episode 3, val func loss 0.21937420964241028\n",
      "\n",
      "episode 4, val func loss 0.19220556318759918\n",
      "\n",
      "episode 5, val func loss 0.17961739003658295\n",
      "\n",
      "episode 6, val func loss 0.20591188967227936\n",
      "\n",
      "episode 7, val func loss 0.2217913568019867\n",
      "\n",
      "episode 8, val func loss 0.17265962064266205\n",
      "\n",
      "episode 9, val func loss 0.19863349199295044\n",
      "\n",
      "episode 10, val func loss 0.20860153436660767\n",
      "\n",
      "episode 11, val func loss 0.1685268133878708\n",
      "\n",
      "episode 12, val func loss 0.2096933126449585\n",
      "\n",
      "episode 13, val func loss 0.2247372567653656\n",
      "\n",
      "episode 14, val func loss 0.20609654486179352\n",
      "\n",
      "episode 15, val func loss 0.23170824348926544\n",
      "\n",
      "episode 16, val func loss 0.2030818611383438\n",
      "\n",
      "Val func train loss in epoch 14:0.20167826768010855\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20792248845100403\n",
      "\n",
      "episode 2, val func loss 0.20700092613697052\n",
      "\n",
      "episode 3, val func loss 0.2026260644197464\n",
      "\n",
      "episode 4, val func loss 0.19262637197971344\n",
      "\n",
      "episode 5, val func loss 0.20556993782520294\n",
      "\n",
      "episode 6, val func loss 0.23221246898174286\n",
      "\n",
      "episode 7, val func loss 0.18012823164463043\n",
      "\n",
      "episode 8, val func loss 0.19061486423015594\n",
      "\n",
      "episode 9, val func loss 0.17291361093521118\n",
      "\n",
      "episode 10, val func loss 0.22645674645900726\n",
      "\n",
      "episode 11, val func loss 0.19074995815753937\n",
      "\n",
      "episode 12, val func loss 0.22294577956199646\n",
      "\n",
      "episode 13, val func loss 0.206917867064476\n",
      "\n",
      "episode 14, val func loss 0.19807417690753937\n",
      "\n",
      "episode 15, val func loss 0.2201298028230667\n",
      "\n",
      "episode 16, val func loss 0.1713840514421463\n",
      "\n",
      "Val func train loss in epoch 15:0.20176708418875933\n",
      "***********************TIME WAS 4.928376158078511 min*****************************\n",
      "\n",
      "**********************ROUND 62 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.007599786389619112\n",
      "\n",
      "episode 2, policy loss 0.0634702816605568\n",
      "\n",
      "episode 3, policy loss 0.02675561234354973\n",
      "\n",
      "episode 4, policy loss -0.016452064737677574\n",
      "\n",
      "episode 5, policy loss 0.05862647294998169\n",
      "\n",
      "episode 6, policy loss -0.036394134163856506\n",
      "\n",
      "episode 7, policy loss 0.002220987807959318\n",
      "\n",
      "episode 8, policy loss -0.014987705275416374\n",
      "\n",
      "episode 9, policy loss 0.009082292206585407\n",
      "\n",
      "episode 10, policy loss -0.03276583179831505\n",
      "\n",
      "episode 11, policy loss 0.011634194292128086\n",
      "\n",
      "episode 12, policy loss 0.06012389063835144\n",
      "\n",
      "episode 13, policy loss -0.024220265448093414\n",
      "\n",
      "episode 14, policy loss -0.007415241561830044\n",
      "\n",
      "episode 15, policy loss 0.013894173316657543\n",
      "\n",
      "episode 16, policy loss 0.0021779153030365705\n",
      "\n",
      "Policy train loss in epoch 0:0.0077093977452022955\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.01442138385027647\n",
      "\n",
      "episode 2, policy loss 0.057802557945251465\n",
      "\n",
      "episode 3, policy loss 0.023348640650510788\n",
      "\n",
      "episode 4, policy loss 0.0609910674393177\n",
      "\n",
      "episode 5, policy loss -0.023663396015763283\n",
      "\n",
      "episode 6, policy loss 0.004921379499137402\n",
      "\n",
      "episode 7, policy loss 0.008562934584915638\n",
      "\n",
      "episode 8, policy loss 0.060926273465156555\n",
      "\n",
      "episode 9, policy loss 0.011602837592363358\n",
      "\n",
      "episode 10, policy loss 0.013132249005138874\n",
      "\n",
      "episode 11, policy loss -0.03251802921295166\n",
      "\n",
      "episode 12, policy loss -0.0005452481564134359\n",
      "\n",
      "episode 13, policy loss -0.037845611572265625\n",
      "\n",
      "episode 14, policy loss -0.0021848329342901707\n",
      "\n",
      "episode 15, policy loss -0.016382388770580292\n",
      "\n",
      "episode 16, policy loss -0.008828913792967796\n",
      "\n",
      "Policy train loss in epoch 1:0.006556133492267691\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.00665828725323081\n",
      "\n",
      "episode 2, policy loss -0.001224599895067513\n",
      "\n",
      "episode 3, policy loss 0.05773790180683136\n",
      "\n",
      "episode 4, policy loss -0.03717774897813797\n",
      "\n",
      "episode 5, policy loss 0.023260867223143578\n",
      "\n",
      "episode 6, policy loss 0.002733068075031042\n",
      "\n",
      "episode 7, policy loss 0.013949975371360779\n",
      "\n",
      "episode 8, policy loss -0.001016164431348443\n",
      "\n",
      "episode 9, policy loss -0.03301798924803734\n",
      "\n",
      "episode 10, policy loss -0.025665510445833206\n",
      "\n",
      "episode 11, policy loss 0.05951306223869324\n",
      "\n",
      "episode 12, policy loss 0.060692206025123596\n",
      "\n",
      "episode 13, policy loss -0.015663832426071167\n",
      "\n",
      "episode 14, policy loss 0.01137132104486227\n",
      "\n",
      "episode 15, policy loss -0.008942585438489914\n",
      "\n",
      "episode 16, policy loss -0.01252052653580904\n",
      "\n",
      "Policy train loss in epoch 2:0.00629298322746763\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.03756466507911682\n",
      "\n",
      "episode 2, policy loss 0.05937805771827698\n",
      "\n",
      "episode 3, policy loss 0.0033208546228706837\n",
      "\n",
      "episode 4, policy loss -0.0010520932264626026\n",
      "\n",
      "episode 5, policy loss 0.006820335518568754\n",
      "\n",
      "episode 6, policy loss 0.02350950986146927\n",
      "\n",
      "episode 7, policy loss -0.033439505845308304\n",
      "\n",
      "episode 8, policy loss -0.0028460242319852114\n",
      "\n",
      "episode 9, policy loss 0.010668275877833366\n",
      "\n",
      "episode 10, policy loss -0.016956893727183342\n",
      "\n",
      "episode 11, policy loss 0.05643166974186897\n",
      "\n",
      "episode 12, policy loss -0.01527959480881691\n",
      "\n",
      "episode 13, policy loss -0.008936108089983463\n",
      "\n",
      "episode 14, policy loss 0.05980969965457916\n",
      "\n",
      "episode 15, policy loss 0.011774161830544472\n",
      "\n",
      "episode 16, policy loss -0.024800458922982216\n",
      "\n",
      "Policy train loss in epoch 3:0.005677326305885799\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1958092898130417\n",
      "\n",
      "episode 2, val func loss 0.18736176192760468\n",
      "\n",
      "episode 3, val func loss 0.1781509667634964\n",
      "\n",
      "episode 4, val func loss 0.15935161709785461\n",
      "\n",
      "episode 5, val func loss 0.18586474657058716\n",
      "\n",
      "episode 6, val func loss 0.19856853783130646\n",
      "\n",
      "episode 7, val func loss 0.17202423512935638\n",
      "\n",
      "episode 8, val func loss 0.17393116652965546\n",
      "\n",
      "episode 9, val func loss 0.14354504644870758\n",
      "\n",
      "episode 10, val func loss 0.21980194747447968\n",
      "\n",
      "episode 11, val func loss 0.19953778386116028\n",
      "\n",
      "episode 12, val func loss 0.2055818736553192\n",
      "\n",
      "episode 13, val func loss 0.17999711632728577\n",
      "\n",
      "episode 14, val func loss 0.1667143851518631\n",
      "\n",
      "episode 15, val func loss 0.1887507289648056\n",
      "\n",
      "episode 16, val func loss 0.1765730082988739\n",
      "\n",
      "Val func train loss in epoch 0:0.18322276324033737\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19659267365932465\n",
      "\n",
      "episode 2, val func loss 0.17767508327960968\n",
      "\n",
      "episode 3, val func loss 0.1949641853570938\n",
      "\n",
      "episode 4, val func loss 0.1798635572195053\n",
      "\n",
      "episode 5, val func loss 0.14640022814273834\n",
      "\n",
      "episode 6, val func loss 0.17700058221817017\n",
      "\n",
      "episode 7, val func loss 0.2163790464401245\n",
      "\n",
      "episode 8, val func loss 0.18687649071216583\n",
      "\n",
      "episode 9, val func loss 0.18820860981941223\n",
      "\n",
      "episode 10, val func loss 0.1757100522518158\n",
      "\n",
      "episode 11, val func loss 0.18624965846538544\n",
      "\n",
      "episode 12, val func loss 0.19830967485904694\n",
      "\n",
      "episode 13, val func loss 0.20304934680461884\n",
      "\n",
      "episode 14, val func loss 0.15835733711719513\n",
      "\n",
      "episode 15, val func loss 0.17253334820270538\n",
      "\n",
      "episode 16, val func loss 0.16735145449638367\n",
      "\n",
      "Val func train loss in epoch 1:0.18284508306533098\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1761174499988556\n",
      "\n",
      "episode 2, val func loss 0.17710232734680176\n",
      "\n",
      "episode 3, val func loss 0.18015161156654358\n",
      "\n",
      "episode 4, val func loss 0.17370449006557465\n",
      "\n",
      "episode 5, val func loss 0.19607305526733398\n",
      "\n",
      "episode 6, val func loss 0.17342229187488556\n",
      "\n",
      "episode 7, val func loss 0.19792889058589935\n",
      "\n",
      "episode 8, val func loss 0.15622584521770477\n",
      "\n",
      "episode 9, val func loss 0.21661731600761414\n",
      "\n",
      "episode 10, val func loss 0.187994584441185\n",
      "\n",
      "episode 11, val func loss 0.1984844207763672\n",
      "\n",
      "episode 12, val func loss 0.16707617044448853\n",
      "\n",
      "episode 13, val func loss 0.14655937254428864\n",
      "\n",
      "episode 14, val func loss 0.18619723618030548\n",
      "\n",
      "episode 15, val func loss 0.20266520977020264\n",
      "\n",
      "episode 16, val func loss 0.18597237765789032\n",
      "\n",
      "Val func train loss in epoch 2:0.18264329060912132\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.15764141082763672\n",
      "\n",
      "episode 2, val func loss 0.14654241502285004\n",
      "\n",
      "episode 3, val func loss 0.18786217272281647\n",
      "\n",
      "episode 4, val func loss 0.1969674974679947\n",
      "\n",
      "episode 5, val func loss 0.17396973073482513\n",
      "\n",
      "episode 6, val func loss 0.19914086163043976\n",
      "\n",
      "episode 7, val func loss 0.17603999376296997\n",
      "\n",
      "episode 8, val func loss 0.17253582179546356\n",
      "\n",
      "episode 9, val func loss 0.19629503786563873\n",
      "\n",
      "episode 10, val func loss 0.1664191633462906\n",
      "\n",
      "episode 11, val func loss 0.1799764186143875\n",
      "\n",
      "episode 12, val func loss 0.1861587017774582\n",
      "\n",
      "episode 13, val func loss 0.2024921327829361\n",
      "\n",
      "episode 14, val func loss 0.17756079137325287\n",
      "\n",
      "episode 15, val func loss 0.21400783956050873\n",
      "\n",
      "episode 16, val func loss 0.18703262507915497\n",
      "\n",
      "Val func train loss in epoch 3:0.182540163397789\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18714496493339539\n",
      "\n",
      "episode 2, val func loss 0.19590705633163452\n",
      "\n",
      "episode 3, val func loss 0.17701169848442078\n",
      "\n",
      "episode 4, val func loss 0.17641893029212952\n",
      "\n",
      "episode 5, val func loss 0.18819452822208405\n",
      "\n",
      "episode 6, val func loss 0.18652306497097015\n",
      "\n",
      "episode 7, val func loss 0.15484842658042908\n",
      "\n",
      "episode 8, val func loss 0.14325879514217377\n",
      "\n",
      "episode 9, val func loss 0.1781550794839859\n",
      "\n",
      "episode 10, val func loss 0.18455109000205994\n",
      "\n",
      "episode 11, val func loss 0.20115475356578827\n",
      "\n",
      "episode 12, val func loss 0.2000325471162796\n",
      "\n",
      "episode 13, val func loss 0.17733673751354218\n",
      "\n",
      "episode 14, val func loss 0.16744384169578552\n",
      "\n",
      "episode 15, val func loss 0.20171451568603516\n",
      "\n",
      "episode 16, val func loss 0.21406687796115875\n",
      "\n",
      "Val func train loss in epoch 4:0.18336018174886703\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17069384455680847\n",
      "\n",
      "episode 2, val func loss 0.15394733846187592\n",
      "\n",
      "episode 3, val func loss 0.1967487335205078\n",
      "\n",
      "episode 4, val func loss 0.1862214207649231\n",
      "\n",
      "episode 5, val func loss 0.17378219962120056\n",
      "\n",
      "episode 6, val func loss 0.15514978766441345\n",
      "\n",
      "episode 7, val func loss 0.21802742779254913\n",
      "\n",
      "episode 8, val func loss 0.19588255882263184\n",
      "\n",
      "episode 9, val func loss 0.17579782009124756\n",
      "\n",
      "episode 10, val func loss 0.2020498812198639\n",
      "\n",
      "episode 11, val func loss 0.18057945370674133\n",
      "\n",
      "episode 12, val func loss 0.17776812613010406\n",
      "\n",
      "episode 13, val func loss 0.19641275703907013\n",
      "\n",
      "episode 14, val func loss 0.17733415961265564\n",
      "\n",
      "episode 15, val func loss 0.18727588653564453\n",
      "\n",
      "episode 16, val func loss 0.18715792894363403\n",
      "\n",
      "Val func train loss in epoch 5:0.18342683278024197\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.197480708360672\n",
      "\n",
      "episode 2, val func loss 0.15680469572544098\n",
      "\n",
      "episode 3, val func loss 0.1980333924293518\n",
      "\n",
      "episode 4, val func loss 0.1801213026046753\n",
      "\n",
      "episode 5, val func loss 0.14597351849079132\n",
      "\n",
      "episode 6, val func loss 0.21492460370063782\n",
      "\n",
      "episode 7, val func loss 0.20300330221652985\n",
      "\n",
      "episode 8, val func loss 0.17259344458580017\n",
      "\n",
      "episode 9, val func loss 0.17502401769161224\n",
      "\n",
      "episode 10, val func loss 0.16734591126441956\n",
      "\n",
      "episode 11, val func loss 0.18625815212726593\n",
      "\n",
      "episode 12, val func loss 0.18859055638313293\n",
      "\n",
      "episode 13, val func loss 0.17539381980895996\n",
      "\n",
      "episode 14, val func loss 0.1865028738975525\n",
      "\n",
      "episode 15, val func loss 0.196641206741333\n",
      "\n",
      "episode 16, val func loss 0.1773274540901184\n",
      "\n",
      "Val func train loss in epoch 6:0.18262618500739336\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1772090345621109\n",
      "\n",
      "episode 2, val func loss 0.19750657677650452\n",
      "\n",
      "episode 3, val func loss 0.19508907198905945\n",
      "\n",
      "episode 4, val func loss 0.17579969763755798\n",
      "\n",
      "episode 5, val func loss 0.2019992172718048\n",
      "\n",
      "episode 6, val func loss 0.21354055404663086\n",
      "\n",
      "episode 7, val func loss 0.16178059577941895\n",
      "\n",
      "episode 8, val func loss 0.18037179112434387\n",
      "\n",
      "episode 9, val func loss 0.1486583948135376\n",
      "\n",
      "episode 10, val func loss 0.19685479998588562\n",
      "\n",
      "episode 11, val func loss 0.1728203296661377\n",
      "\n",
      "episode 12, val func loss 0.1870616227388382\n",
      "\n",
      "episode 13, val func loss 0.18782541155815125\n",
      "\n",
      "episode 14, val func loss 0.16653887927532196\n",
      "\n",
      "episode 15, val func loss 0.186747208237648\n",
      "\n",
      "episode 16, val func loss 0.17191992700099945\n",
      "\n",
      "Val func train loss in epoch 7:0.18260769452899694\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1995517760515213\n",
      "\n",
      "episode 2, val func loss 0.144658625125885\n",
      "\n",
      "episode 3, val func loss 0.19745004177093506\n",
      "\n",
      "episode 4, val func loss 0.1778324395418167\n",
      "\n",
      "episode 5, val func loss 0.21625664830207825\n",
      "\n",
      "episode 6, val func loss 0.16628557443618774\n",
      "\n",
      "episode 7, val func loss 0.1581699103116989\n",
      "\n",
      "episode 8, val func loss 0.18840867280960083\n",
      "\n",
      "episode 9, val func loss 0.17251205444335938\n",
      "\n",
      "episode 10, val func loss 0.2027505785226822\n",
      "\n",
      "episode 11, val func loss 0.19493494927883148\n",
      "\n",
      "episode 12, val func loss 0.186192125082016\n",
      "\n",
      "episode 13, val func loss 0.18618281185626984\n",
      "\n",
      "episode 14, val func loss 0.1797538846731186\n",
      "\n",
      "episode 15, val func loss 0.17614680528640747\n",
      "\n",
      "episode 16, val func loss 0.17551134526729584\n",
      "\n",
      "Val func train loss in epoch 8:0.18266239017248154\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1864086538553238\n",
      "\n",
      "episode 2, val func loss 0.15657959878444672\n",
      "\n",
      "episode 3, val func loss 0.1868368536233902\n",
      "\n",
      "episode 4, val func loss 0.1977134644985199\n",
      "\n",
      "episode 5, val func loss 0.20042867958545685\n",
      "\n",
      "episode 6, val func loss 0.18792182207107544\n",
      "\n",
      "episode 7, val func loss 0.17222359776496887\n",
      "\n",
      "episode 8, val func loss 0.20438574254512787\n",
      "\n",
      "episode 9, val func loss 0.16684536635875702\n",
      "\n",
      "episode 10, val func loss 0.17737600207328796\n",
      "\n",
      "episode 11, val func loss 0.21448935568332672\n",
      "\n",
      "episode 12, val func loss 0.19657976925373077\n",
      "\n",
      "episode 13, val func loss 0.14886093139648438\n",
      "\n",
      "episode 14, val func loss 0.17300622165203094\n",
      "\n",
      "episode 15, val func loss 0.1802138090133667\n",
      "\n",
      "episode 16, val func loss 0.17625917494297028\n",
      "\n",
      "Val func train loss in epoch 9:0.18288306519389153\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19701384007930756\n",
      "\n",
      "episode 2, val func loss 0.19499492645263672\n",
      "\n",
      "episode 3, val func loss 0.16683655977249146\n",
      "\n",
      "episode 4, val func loss 0.18598820269107819\n",
      "\n",
      "episode 5, val func loss 0.18826045095920563\n",
      "\n",
      "episode 6, val func loss 0.1733918935060501\n",
      "\n",
      "episode 7, val func loss 0.18632028996944427\n",
      "\n",
      "episode 8, val func loss 0.1756252646446228\n",
      "\n",
      "episode 9, val func loss 0.19774892926216125\n",
      "\n",
      "episode 10, val func loss 0.1739128977060318\n",
      "\n",
      "episode 11, val func loss 0.21526847779750824\n",
      "\n",
      "episode 12, val func loss 0.20265327394008636\n",
      "\n",
      "episode 13, val func loss 0.1580197811126709\n",
      "\n",
      "episode 14, val func loss 0.17987792193889618\n",
      "\n",
      "episode 15, val func loss 0.17742128670215607\n",
      "\n",
      "episode 16, val func loss 0.1465005874633789\n",
      "\n",
      "Val func train loss in epoch 10:0.1824896614998579\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18848766386508942\n",
      "\n",
      "episode 2, val func loss 0.18010780215263367\n",
      "\n",
      "episode 3, val func loss 0.17740456759929657\n",
      "\n",
      "episode 4, val func loss 0.17366629838943481\n",
      "\n",
      "episode 5, val func loss 0.1444460153579712\n",
      "\n",
      "episode 6, val func loss 0.17555353045463562\n",
      "\n",
      "episode 7, val func loss 0.19892515242099762\n",
      "\n",
      "episode 8, val func loss 0.19695478677749634\n",
      "\n",
      "episode 9, val func loss 0.2033660113811493\n",
      "\n",
      "episode 10, val func loss 0.158186674118042\n",
      "\n",
      "episode 11, val func loss 0.18659359216690063\n",
      "\n",
      "episode 12, val func loss 0.16771134734153748\n",
      "\n",
      "episode 13, val func loss 0.17531803250312805\n",
      "\n",
      "episode 14, val func loss 0.18586620688438416\n",
      "\n",
      "episode 15, val func loss 0.19736823439598083\n",
      "\n",
      "episode 16, val func loss 0.21512767672538757\n",
      "\n",
      "Val func train loss in epoch 11:0.18281772453337908\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.20365288853645325\n",
      "\n",
      "episode 2, val func loss 0.18642371892929077\n",
      "\n",
      "episode 3, val func loss 0.19519507884979248\n",
      "\n",
      "episode 4, val func loss 0.1674257069826126\n",
      "\n",
      "episode 5, val func loss 0.14801113307476044\n",
      "\n",
      "episode 6, val func loss 0.17732538282871246\n",
      "\n",
      "episode 7, val func loss 0.1968434900045395\n",
      "\n",
      "episode 8, val func loss 0.19727805256843567\n",
      "\n",
      "episode 9, val func loss 0.17307166755199432\n",
      "\n",
      "episode 10, val func loss 0.18007780611515045\n",
      "\n",
      "episode 11, val func loss 0.17398038506507874\n",
      "\n",
      "episode 12, val func loss 0.17540857195854187\n",
      "\n",
      "episode 13, val func loss 0.18785162270069122\n",
      "\n",
      "episode 14, val func loss 0.18657757341861725\n",
      "\n",
      "episode 15, val func loss 0.21632501482963562\n",
      "\n",
      "episode 16, val func loss 0.15611112117767334\n",
      "\n",
      "Val func train loss in epoch 12:0.18259745091199875\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18616610765457153\n",
      "\n",
      "episode 2, val func loss 0.18821650743484497\n",
      "\n",
      "episode 3, val func loss 0.17572709918022156\n",
      "\n",
      "episode 4, val func loss 0.16662797331809998\n",
      "\n",
      "episode 5, val func loss 0.19698534905910492\n",
      "\n",
      "episode 6, val func loss 0.18034113943576813\n",
      "\n",
      "episode 7, val func loss 0.157205730676651\n",
      "\n",
      "episode 8, val func loss 0.14600206911563873\n",
      "\n",
      "episode 9, val func loss 0.17737816274166107\n",
      "\n",
      "episode 10, val func loss 0.2163715809583664\n",
      "\n",
      "episode 11, val func loss 0.19640901684761047\n",
      "\n",
      "episode 12, val func loss 0.18644633889198303\n",
      "\n",
      "episode 13, val func loss 0.17336109280586243\n",
      "\n",
      "episode 14, val func loss 0.19746075570583344\n",
      "\n",
      "episode 15, val func loss 0.2028161734342575\n",
      "\n",
      "episode 16, val func loss 0.17289072275161743\n",
      "\n",
      "Val func train loss in epoch 13:0.1825253637507558\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18632781505584717\n",
      "\n",
      "episode 2, val func loss 0.16732893884181976\n",
      "\n",
      "episode 3, val func loss 0.18899710476398468\n",
      "\n",
      "episode 4, val func loss 0.19616156816482544\n",
      "\n",
      "episode 5, val func loss 0.17319563031196594\n",
      "\n",
      "episode 6, val func loss 0.14670494198799133\n",
      "\n",
      "episode 7, val func loss 0.17733412981033325\n",
      "\n",
      "episode 8, val func loss 0.20442113280296326\n",
      "\n",
      "episode 9, val func loss 0.17230713367462158\n",
      "\n",
      "episode 10, val func loss 0.19676341116428375\n",
      "\n",
      "episode 11, val func loss 0.17998573184013367\n",
      "\n",
      "episode 12, val func loss 0.1754215508699417\n",
      "\n",
      "episode 13, val func loss 0.19830924272537231\n",
      "\n",
      "episode 14, val func loss 0.214582160115242\n",
      "\n",
      "episode 15, val func loss 0.1865350902080536\n",
      "\n",
      "episode 16, val func loss 0.1604967713356018\n",
      "\n",
      "Val func train loss in epoch 14:0.18280452210456133\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18923190236091614\n",
      "\n",
      "episode 2, val func loss 0.15947966277599335\n",
      "\n",
      "episode 3, val func loss 0.1859733760356903\n",
      "\n",
      "episode 4, val func loss 0.1758582890033722\n",
      "\n",
      "episode 5, val func loss 0.1777597963809967\n",
      "\n",
      "episode 6, val func loss 0.1668710559606552\n",
      "\n",
      "episode 7, val func loss 0.17129680514335632\n",
      "\n",
      "episode 8, val func loss 0.20702266693115234\n",
      "\n",
      "episode 9, val func loss 0.1977871060371399\n",
      "\n",
      "episode 10, val func loss 0.14447139203548431\n",
      "\n",
      "episode 11, val func loss 0.21578402817249298\n",
      "\n",
      "episode 12, val func loss 0.19711780548095703\n",
      "\n",
      "episode 13, val func loss 0.1729641854763031\n",
      "\n",
      "episode 14, val func loss 0.1865062564611435\n",
      "\n",
      "episode 15, val func loss 0.19682677090168\n",
      "\n",
      "episode 16, val func loss 0.1807248592376709\n",
      "\n",
      "Val func train loss in epoch 15:0.18285474739968777\n",
      "***********************TIME WAS 4.934728348255158 min*****************************\n",
      "\n",
      "**********************ROUND 63 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.017282409593462944\n",
      "\n",
      "episode 2, policy loss 0.010349806398153305\n",
      "\n",
      "episode 3, policy loss -0.018493453040719032\n",
      "\n",
      "episode 4, policy loss -0.01886955462396145\n",
      "\n",
      "episode 5, policy loss -0.045234937220811844\n",
      "\n",
      "episode 6, policy loss -0.009401398710906506\n",
      "\n",
      "episode 7, policy loss -0.02057701162993908\n",
      "\n",
      "episode 8, policy loss -0.032542720437049866\n",
      "\n",
      "episode 9, policy loss 0.03584872931241989\n",
      "\n",
      "episode 10, policy loss 0.03753184899687767\n",
      "\n",
      "episode 11, policy loss -0.012157182209193707\n",
      "\n",
      "episode 12, policy loss -0.019678113982081413\n",
      "\n",
      "episode 13, policy loss -0.05070158839225769\n",
      "\n",
      "episode 14, policy loss -0.026162713766098022\n",
      "\n",
      "episode 15, policy loss -0.02290947735309601\n",
      "\n",
      "episode 16, policy loss -0.04962059482932091\n",
      "\n",
      "Policy train loss in epoch 0:-0.016243798192590475\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.027866607531905174\n",
      "\n",
      "episode 2, policy loss -0.022138837724924088\n",
      "\n",
      "episode 3, policy loss -0.0204324908554554\n",
      "\n",
      "episode 4, policy loss -0.013290425762534142\n",
      "\n",
      "episode 5, policy loss -0.023881198838353157\n",
      "\n",
      "episode 6, policy loss -0.05069863423705101\n",
      "\n",
      "episode 7, policy loss 0.006212035659700632\n",
      "\n",
      "episode 8, policy loss -0.02506602182984352\n",
      "\n",
      "episode 9, policy loss -0.009999175556004047\n",
      "\n",
      "episode 10, policy loss -0.02188575454056263\n",
      "\n",
      "episode 11, policy loss -0.05176321789622307\n",
      "\n",
      "episode 12, policy loss -0.03439586982131004\n",
      "\n",
      "episode 13, policy loss 0.036061447113752365\n",
      "\n",
      "episode 14, policy loss -0.042639125138521194\n",
      "\n",
      "episode 15, policy loss 0.039823099970817566\n",
      "\n",
      "episode 16, policy loss -0.019609665498137474\n",
      "\n",
      "Policy train loss in epoch 1:-0.01759815265540965\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.03268690034747124\n",
      "\n",
      "episode 2, policy loss -0.02187691628932953\n",
      "\n",
      "episode 3, policy loss -0.05010081082582474\n",
      "\n",
      "episode 4, policy loss -0.02377242222428322\n",
      "\n",
      "episode 5, policy loss -0.021731209009885788\n",
      "\n",
      "episode 6, policy loss -0.050847701728343964\n",
      "\n",
      "episode 7, policy loss -0.014530664309859276\n",
      "\n",
      "episode 8, policy loss 0.03501782938838005\n",
      "\n",
      "episode 9, policy loss -0.010688475333154202\n",
      "\n",
      "episode 10, policy loss -0.02640102617442608\n",
      "\n",
      "episode 11, policy loss 0.03773777559399605\n",
      "\n",
      "episode 12, policy loss -0.02169857732951641\n",
      "\n",
      "episode 13, policy loss 0.006734211463481188\n",
      "\n",
      "episode 14, policy loss -0.023038821294903755\n",
      "\n",
      "episode 15, policy loss -0.023913267999887466\n",
      "\n",
      "episode 16, policy loss -0.0459509938955307\n",
      "\n",
      "Policy train loss in epoch 2:-0.017984248144784942\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.023531556129455566\n",
      "\n",
      "episode 2, policy loss -0.02724064141511917\n",
      "\n",
      "episode 3, policy loss 0.035366035997867584\n",
      "\n",
      "episode 4, policy loss -0.05190267786383629\n",
      "\n",
      "episode 5, policy loss -0.024484330788254738\n",
      "\n",
      "episode 6, policy loss -0.0343276672065258\n",
      "\n",
      "episode 7, policy loss 0.006637731567025185\n",
      "\n",
      "episode 8, policy loss -0.046096500009298325\n",
      "\n",
      "episode 9, policy loss -0.011412559077143669\n",
      "\n",
      "episode 10, policy loss -0.021053263917565346\n",
      "\n",
      "episode 11, policy loss 0.03619690239429474\n",
      "\n",
      "episode 12, policy loss -0.048318199813365936\n",
      "\n",
      "episode 13, policy loss -0.024294080212712288\n",
      "\n",
      "episode 14, policy loss -0.023304585367441177\n",
      "\n",
      "episode 15, policy loss -0.014967386610805988\n",
      "\n",
      "episode 16, policy loss -0.02295859344303608\n",
      "\n",
      "Policy train loss in epoch 3:-0.018480710743460804\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.18934740126132965\n",
      "\n",
      "episode 2, val func loss 0.1947130709886551\n",
      "\n",
      "episode 3, val func loss 0.20246605575084686\n",
      "\n",
      "episode 4, val func loss 0.19423621892929077\n",
      "\n",
      "episode 5, val func loss 0.1949489712715149\n",
      "\n",
      "episode 6, val func loss 0.18538591265678406\n",
      "\n",
      "episode 7, val func loss 0.16532939672470093\n",
      "\n",
      "episode 8, val func loss 0.19934917986392975\n",
      "\n",
      "episode 9, val func loss 0.1722884327173233\n",
      "\n",
      "episode 10, val func loss 0.1995656043291092\n",
      "\n",
      "episode 11, val func loss 0.1932418942451477\n",
      "\n",
      "episode 12, val func loss 0.17487291991710663\n",
      "\n",
      "episode 13, val func loss 0.18831481039524078\n",
      "\n",
      "episode 14, val func loss 0.1633821278810501\n",
      "\n",
      "episode 15, val func loss 0.18488174676895142\n",
      "\n",
      "episode 16, val func loss 0.18441888689994812\n",
      "\n",
      "Val func train loss in epoch 0:0.18667141441255808\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.20006582140922546\n",
      "\n",
      "episode 2, val func loss 0.1991393119096756\n",
      "\n",
      "episode 3, val func loss 0.16692957282066345\n",
      "\n",
      "episode 4, val func loss 0.19461549818515778\n",
      "\n",
      "episode 5, val func loss 0.1842111498117447\n",
      "\n",
      "episode 6, val func loss 0.18988074362277985\n",
      "\n",
      "episode 7, val func loss 0.18542315065860748\n",
      "\n",
      "episode 8, val func loss 0.16856250166893005\n",
      "\n",
      "episode 9, val func loss 0.18841229379177094\n",
      "\n",
      "episode 10, val func loss 0.193933367729187\n",
      "\n",
      "episode 11, val func loss 0.19910679757595062\n",
      "\n",
      "episode 12, val func loss 0.20334666967391968\n",
      "\n",
      "episode 13, val func loss 0.16497880220413208\n",
      "\n",
      "episode 14, val func loss 0.1946963220834732\n",
      "\n",
      "episode 15, val func loss 0.1842270791530609\n",
      "\n",
      "episode 16, val func loss 0.17401108145713806\n",
      "\n",
      "Val func train loss in epoch 1:0.18697126023471355\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1934838742017746\n",
      "\n",
      "episode 2, val func loss 0.1900368332862854\n",
      "\n",
      "episode 3, val func loss 0.2017679214477539\n",
      "\n",
      "episode 4, val func loss 0.16515813767910004\n",
      "\n",
      "episode 5, val func loss 0.18487976491451263\n",
      "\n",
      "episode 6, val func loss 0.20033086836338043\n",
      "\n",
      "episode 7, val func loss 0.18357034027576447\n",
      "\n",
      "episode 8, val func loss 0.1856834590435028\n",
      "\n",
      "episode 9, val func loss 0.19518554210662842\n",
      "\n",
      "episode 10, val func loss 0.16653171181678772\n",
      "\n",
      "episode 11, val func loss 0.19474467635154724\n",
      "\n",
      "episode 12, val func loss 0.1731504201889038\n",
      "\n",
      "episode 13, val func loss 0.1900961995124817\n",
      "\n",
      "episode 14, val func loss 0.19959506392478943\n",
      "\n",
      "episode 15, val func loss 0.16850879788398743\n",
      "\n",
      "episode 16, val func loss 0.19970984756946564\n",
      "\n",
      "Val func train loss in epoch 2:0.1870270911604166\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.17446394264698029\n",
      "\n",
      "episode 2, val func loss 0.1857975721359253\n",
      "\n",
      "episode 3, val func loss 0.19896960258483887\n",
      "\n",
      "episode 4, val func loss 0.202284574508667\n",
      "\n",
      "episode 5, val func loss 0.18954211473464966\n",
      "\n",
      "episode 6, val func loss 0.19451050460338593\n",
      "\n",
      "episode 7, val func loss 0.19297194480895996\n",
      "\n",
      "episode 8, val func loss 0.17316603660583496\n",
      "\n",
      "episode 9, val func loss 0.16524548828601837\n",
      "\n",
      "episode 10, val func loss 0.1999610811471939\n",
      "\n",
      "episode 11, val func loss 0.19462604820728302\n",
      "\n",
      "episode 12, val func loss 0.1889548897743225\n",
      "\n",
      "episode 13, val func loss 0.16412700712680817\n",
      "\n",
      "episode 14, val func loss 0.19938622415065765\n",
      "\n",
      "episode 15, val func loss 0.18516959249973297\n",
      "\n",
      "episode 16, val func loss 0.18383347988128662\n",
      "\n",
      "Val func train loss in epoch 3:0.18706313148140907\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.20273154973983765\n",
      "\n",
      "episode 2, val func loss 0.183693990111351\n",
      "\n",
      "episode 3, val func loss 0.1990695297718048\n",
      "\n",
      "episode 4, val func loss 0.18378347158432007\n",
      "\n",
      "episode 5, val func loss 0.19393278658390045\n",
      "\n",
      "episode 6, val func loss 0.1947319656610489\n",
      "\n",
      "episode 7, val func loss 0.18996095657348633\n",
      "\n",
      "episode 8, val func loss 0.1737840473651886\n",
      "\n",
      "episode 9, val func loss 0.1646347939968109\n",
      "\n",
      "episode 10, val func loss 0.20038928091526031\n",
      "\n",
      "episode 11, val func loss 0.18630319833755493\n",
      "\n",
      "episode 12, val func loss 0.16448509693145752\n",
      "\n",
      "episode 13, val func loss 0.19449827075004578\n",
      "\n",
      "episode 14, val func loss 0.19112014770507812\n",
      "\n",
      "episode 15, val func loss 0.1707751750946045\n",
      "\n",
      "episode 16, val func loss 0.1987876445055008\n",
      "\n",
      "Val func train loss in epoch 4:0.18704261910170317\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18568505346775055\n",
      "\n",
      "episode 2, val func loss 0.18857595324516296\n",
      "\n",
      "episode 3, val func loss 0.20392794907093048\n",
      "\n",
      "episode 4, val func loss 0.19534814357757568\n",
      "\n",
      "episode 5, val func loss 0.17010588943958282\n",
      "\n",
      "episode 6, val func loss 0.18391422927379608\n",
      "\n",
      "episode 7, val func loss 0.1735924780368805\n",
      "\n",
      "episode 8, val func loss 0.19040361046791077\n",
      "\n",
      "episode 9, val func loss 0.1644400805234909\n",
      "\n",
      "episode 10, val func loss 0.18551577627658844\n",
      "\n",
      "episode 11, val func loss 0.2018607258796692\n",
      "\n",
      "episode 12, val func loss 0.19728043675422668\n",
      "\n",
      "episode 13, val func loss 0.19188964366912842\n",
      "\n",
      "episode 14, val func loss 0.19923844933509827\n",
      "\n",
      "episode 15, val func loss 0.16527636349201202\n",
      "\n",
      "episode 16, val func loss 0.19444996118545532\n",
      "\n",
      "Val func train loss in epoch 5:0.1869690464809537\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.20187239348888397\n",
      "\n",
      "episode 2, val func loss 0.19209827482700348\n",
      "\n",
      "episode 3, val func loss 0.19960545003414154\n",
      "\n",
      "episode 4, val func loss 0.1839781254529953\n",
      "\n",
      "episode 5, val func loss 0.1884385645389557\n",
      "\n",
      "episode 6, val func loss 0.1949479579925537\n",
      "\n",
      "episode 7, val func loss 0.19489887356758118\n",
      "\n",
      "episode 8, val func loss 0.17305761575698853\n",
      "\n",
      "episode 9, val func loss 0.1650700718164444\n",
      "\n",
      "episode 10, val func loss 0.18575112521648407\n",
      "\n",
      "episode 11, val func loss 0.16653405129909515\n",
      "\n",
      "episode 12, val func loss 0.18395376205444336\n",
      "\n",
      "episode 13, val func loss 0.19818417727947235\n",
      "\n",
      "episode 14, val func loss 0.16924306750297546\n",
      "\n",
      "episode 15, val func loss 0.20003877580165863\n",
      "\n",
      "episode 16, val func loss 0.18938860297203064\n",
      "\n",
      "Val func train loss in epoch 6:0.18669130560010672\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18586024641990662\n",
      "\n",
      "episode 2, val func loss 0.1960906982421875\n",
      "\n",
      "episode 3, val func loss 0.1651051938533783\n",
      "\n",
      "episode 4, val func loss 0.19938956201076508\n",
      "\n",
      "episode 5, val func loss 0.2024555653333664\n",
      "\n",
      "episode 6, val func loss 0.1947130560874939\n",
      "\n",
      "episode 7, val func loss 0.1839517503976822\n",
      "\n",
      "episode 8, val func loss 0.19242623448371887\n",
      "\n",
      "episode 9, val func loss 0.18356657028198242\n",
      "\n",
      "episode 10, val func loss 0.17374615371227264\n",
      "\n",
      "episode 11, val func loss 0.19916044175624847\n",
      "\n",
      "episode 12, val func loss 0.18901708722114563\n",
      "\n",
      "episode 13, val func loss 0.16885791718959808\n",
      "\n",
      "episode 14, val func loss 0.163343608379364\n",
      "\n",
      "episode 15, val func loss 0.1888817995786667\n",
      "\n",
      "episode 16, val func loss 0.20200945436954498\n",
      "\n",
      "Val func train loss in epoch 7:0.1867859587073326\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1939125955104828\n",
      "\n",
      "episode 2, val func loss 0.1963876634836197\n",
      "\n",
      "episode 3, val func loss 0.18377657234668732\n",
      "\n",
      "episode 4, val func loss 0.17410461604595184\n",
      "\n",
      "episode 5, val func loss 0.17898398637771606\n",
      "\n",
      "episode 6, val func loss 0.19681653380393982\n",
      "\n",
      "episode 7, val func loss 0.18390098214149475\n",
      "\n",
      "episode 8, val func loss 0.1990402787923813\n",
      "\n",
      "episode 9, val func loss 0.20279937982559204\n",
      "\n",
      "episode 10, val func loss 0.16332358121871948\n",
      "\n",
      "episode 11, val func loss 0.20560550689697266\n",
      "\n",
      "episode 12, val func loss 0.19609880447387695\n",
      "\n",
      "episode 13, val func loss 0.19497165083885193\n",
      "\n",
      "episode 14, val func loss 0.16463322937488556\n",
      "\n",
      "episode 15, val func loss 0.18891561031341553\n",
      "\n",
      "episode 16, val func loss 0.18499495089054108\n",
      "\n",
      "Val func train loss in epoch 8:0.18801662139594555\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18505722284317017\n",
      "\n",
      "episode 2, val func loss 0.16569405794143677\n",
      "\n",
      "episode 3, val func loss 0.19990284740924835\n",
      "\n",
      "episode 4, val func loss 0.19245798885822296\n",
      "\n",
      "episode 5, val func loss 0.18801766633987427\n",
      "\n",
      "episode 6, val func loss 0.195261612534523\n",
      "\n",
      "episode 7, val func loss 0.18410898745059967\n",
      "\n",
      "episode 8, val func loss 0.1711915284395218\n",
      "\n",
      "episode 9, val func loss 0.20258726179599762\n",
      "\n",
      "episode 10, val func loss 0.1648031324148178\n",
      "\n",
      "episode 11, val func loss 0.19441555440425873\n",
      "\n",
      "episode 12, val func loss 0.17347246408462524\n",
      "\n",
      "episode 13, val func loss 0.19511210918426514\n",
      "\n",
      "episode 14, val func loss 0.19923119246959686\n",
      "\n",
      "episode 15, val func loss 0.19096636772155762\n",
      "\n",
      "episode 16, val func loss 0.18389680981636047\n",
      "\n",
      "Val func train loss in epoch 9:0.18663605023175478\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.17036767303943634\n",
      "\n",
      "episode 2, val func loss 0.1967807114124298\n",
      "\n",
      "episode 3, val func loss 0.18935033679008484\n",
      "\n",
      "episode 4, val func loss 0.18459217250347137\n",
      "\n",
      "episode 5, val func loss 0.19980455935001373\n",
      "\n",
      "episode 6, val func loss 0.1740356832742691\n",
      "\n",
      "episode 7, val func loss 0.20045296847820282\n",
      "\n",
      "episode 8, val func loss 0.18503358960151672\n",
      "\n",
      "episode 9, val func loss 0.19195672869682312\n",
      "\n",
      "episode 10, val func loss 0.1892670840024948\n",
      "\n",
      "episode 11, val func loss 0.16503667831420898\n",
      "\n",
      "episode 12, val func loss 0.18384245038032532\n",
      "\n",
      "episode 13, val func loss 0.20199905335903168\n",
      "\n",
      "episode 14, val func loss 0.1951073259115219\n",
      "\n",
      "episode 15, val func loss 0.16725723445415497\n",
      "\n",
      "episode 16, val func loss 0.19423091411590576\n",
      "\n",
      "Val func train loss in epoch 10:0.1868196977302432\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.20232857763767242\n",
      "\n",
      "episode 2, val func loss 0.18551093339920044\n",
      "\n",
      "episode 3, val func loss 0.19534258544445038\n",
      "\n",
      "episode 4, val func loss 0.17286130785942078\n",
      "\n",
      "episode 5, val func loss 0.18866582214832306\n",
      "\n",
      "episode 6, val func loss 0.19943414628505707\n",
      "\n",
      "episode 7, val func loss 0.19885365664958954\n",
      "\n",
      "episode 8, val func loss 0.19123542308807373\n",
      "\n",
      "episode 9, val func loss 0.19446028769016266\n",
      "\n",
      "episode 10, val func loss 0.18362832069396973\n",
      "\n",
      "episode 11, val func loss 0.19209346175193787\n",
      "\n",
      "episode 12, val func loss 0.19464772939682007\n",
      "\n",
      "episode 13, val func loss 0.16493681073188782\n",
      "\n",
      "episode 14, val func loss 0.16905422508716583\n",
      "\n",
      "episode 15, val func loss 0.1846352070569992\n",
      "\n",
      "episode 16, val func loss 0.16488595306873322\n",
      "\n",
      "Val func train loss in epoch 11:0.1864109029993415\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.16497531533241272\n",
      "\n",
      "episode 2, val func loss 0.1964966505765915\n",
      "\n",
      "episode 3, val func loss 0.204217791557312\n",
      "\n",
      "episode 4, val func loss 0.183978870511055\n",
      "\n",
      "episode 5, val func loss 0.19920150935649872\n",
      "\n",
      "episode 6, val func loss 0.1724596619606018\n",
      "\n",
      "episode 7, val func loss 0.1926187425851822\n",
      "\n",
      "episode 8, val func loss 0.16771353781223297\n",
      "\n",
      "episode 9, val func loss 0.19518886506557465\n",
      "\n",
      "episode 10, val func loss 0.18554025888442993\n",
      "\n",
      "episode 11, val func loss 0.19230829179286957\n",
      "\n",
      "episode 12, val func loss 0.19444267451763153\n",
      "\n",
      "episode 13, val func loss 0.19975866377353668\n",
      "\n",
      "episode 14, val func loss 0.1880321353673935\n",
      "\n",
      "episode 15, val func loss 0.17343126237392426\n",
      "\n",
      "episode 16, val func loss 0.18401950597763062\n",
      "\n",
      "Val func train loss in epoch 12:0.18714898359030485\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18966567516326904\n",
      "\n",
      "episode 2, val func loss 0.18370899558067322\n",
      "\n",
      "episode 3, val func loss 0.1838594526052475\n",
      "\n",
      "episode 4, val func loss 0.16483671963214874\n",
      "\n",
      "episode 5, val func loss 0.19201141595840454\n",
      "\n",
      "episode 6, val func loss 0.19929292798042297\n",
      "\n",
      "episode 7, val func loss 0.1948336511850357\n",
      "\n",
      "episode 8, val func loss 0.20197884738445282\n",
      "\n",
      "episode 9, val func loss 0.18927080929279327\n",
      "\n",
      "episode 10, val func loss 0.19427581131458282\n",
      "\n",
      "episode 11, val func loss 0.19931267201900482\n",
      "\n",
      "episode 12, val func loss 0.17119251191616058\n",
      "\n",
      "episode 13, val func loss 0.1956922709941864\n",
      "\n",
      "episode 14, val func loss 0.17340314388275146\n",
      "\n",
      "episode 15, val func loss 0.16517440974712372\n",
      "\n",
      "episode 16, val func loss 0.18563418090343475\n",
      "\n",
      "Val func train loss in epoch 13:0.18650896847248077\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19780820608139038\n",
      "\n",
      "episode 2, val func loss 0.1643475443124771\n",
      "\n",
      "episode 3, val func loss 0.1841064840555191\n",
      "\n",
      "episode 4, val func loss 0.17385424673557281\n",
      "\n",
      "episode 5, val func loss 0.20289874076843262\n",
      "\n",
      "episode 6, val func loss 0.19890211522579193\n",
      "\n",
      "episode 7, val func loss 0.19105753302574158\n",
      "\n",
      "episode 8, val func loss 0.19471468031406403\n",
      "\n",
      "episode 9, val func loss 0.17024113237857819\n",
      "\n",
      "episode 10, val func loss 0.19528712332248688\n",
      "\n",
      "episode 11, val func loss 0.1883968710899353\n",
      "\n",
      "episode 12, val func loss 0.18369393050670624\n",
      "\n",
      "episode 13, val func loss 0.1864612102508545\n",
      "\n",
      "episode 14, val func loss 0.19199195504188538\n",
      "\n",
      "episode 15, val func loss 0.16417822241783142\n",
      "\n",
      "episode 16, val func loss 0.19894173741340637\n",
      "\n",
      "Val func train loss in epoch 14:0.18668010830879211\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19553561508655548\n",
      "\n",
      "episode 2, val func loss 0.2014928162097931\n",
      "\n",
      "episode 3, val func loss 0.16520510613918304\n",
      "\n",
      "episode 4, val func loss 0.16800737380981445\n",
      "\n",
      "episode 5, val func loss 0.19915539026260376\n",
      "\n",
      "episode 6, val func loss 0.1843080073595047\n",
      "\n",
      "episode 7, val func loss 0.19515599310398102\n",
      "\n",
      "episode 8, val func loss 0.19943396747112274\n",
      "\n",
      "episode 9, val func loss 0.1719682365655899\n",
      "\n",
      "episode 10, val func loss 0.18698589503765106\n",
      "\n",
      "episode 11, val func loss 0.18604643642902374\n",
      "\n",
      "episode 12, val func loss 0.19210846722126007\n",
      "\n",
      "episode 13, val func loss 0.16948601603507996\n",
      "\n",
      "episode 14, val func loss 0.18704049289226532\n",
      "\n",
      "episode 15, val func loss 0.18398639559745789\n",
      "\n",
      "episode 16, val func loss 0.19730448722839355\n",
      "\n",
      "Val func train loss in epoch 15:0.18645129352808\n",
      "***********************TIME WAS 4.933214569091797 min*****************************\n",
      "\n",
      "**********************ROUND 64 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.029744962230324745\n",
      "\n",
      "episode 2, policy loss -0.02119476906955242\n",
      "\n",
      "episode 3, policy loss 0.0300019308924675\n",
      "\n",
      "episode 4, policy loss 0.02468857541680336\n",
      "\n",
      "episode 5, policy loss 0.0804060623049736\n",
      "\n",
      "episode 6, policy loss 0.062324367463588715\n",
      "\n",
      "episode 7, policy loss 0.05080975219607353\n",
      "\n",
      "episode 8, policy loss 0.061140138655900955\n",
      "\n",
      "episode 9, policy loss 0.006285009905695915\n",
      "\n",
      "episode 10, policy loss 0.03232365846633911\n",
      "\n",
      "episode 11, policy loss -0.008772696368396282\n",
      "\n",
      "episode 12, policy loss 0.00046681740786880255\n",
      "\n",
      "episode 13, policy loss 0.0724811926484108\n",
      "\n",
      "episode 14, policy loss 0.009500671178102493\n",
      "\n",
      "episode 15, policy loss 0.05418510362505913\n",
      "\n",
      "episode 16, policy loss 0.004134008660912514\n",
      "\n",
      "Policy train loss in epoch 0:0.03053279910091078\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.028595292940735817\n",
      "\n",
      "episode 2, policy loss 0.05587786063551903\n",
      "\n",
      "episode 3, policy loss 0.030242282897233963\n",
      "\n",
      "episode 4, policy loss 0.0003288843436166644\n",
      "\n",
      "episode 5, policy loss 0.006989885121583939\n",
      "\n",
      "episode 6, policy loss 0.018013516440987587\n",
      "\n",
      "episode 7, policy loss 0.0015841620042920113\n",
      "\n",
      "episode 8, policy loss 0.06239612028002739\n",
      "\n",
      "episode 9, policy loss -0.007745774462819099\n",
      "\n",
      "episode 10, policy loss 0.025865644216537476\n",
      "\n",
      "episode 11, policy loss 0.05334228649735451\n",
      "\n",
      "episode 12, policy loss 0.07874579727649689\n",
      "\n",
      "episode 13, policy loss 0.0021427026949822903\n",
      "\n",
      "episode 14, policy loss 0.029711494222283363\n",
      "\n",
      "episode 15, policy loss 0.07134352624416351\n",
      "\n",
      "episode 16, policy loss 0.04746270552277565\n",
      "\n",
      "Policy train loss in epoch 1:0.02798161256214371\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.02542399801313877\n",
      "\n",
      "episode 2, policy loss 0.0024904722813516855\n",
      "\n",
      "episode 3, policy loss 0.0606391467154026\n",
      "\n",
      "episode 4, policy loss -0.00172964867670089\n",
      "\n",
      "episode 5, policy loss -0.008028857409954071\n",
      "\n",
      "episode 6, policy loss -0.031159106642007828\n",
      "\n",
      "episode 7, policy loss 0.05370552837848663\n",
      "\n",
      "episode 8, policy loss 0.0021246839314699173\n",
      "\n",
      "episode 9, policy loss 0.006846352480351925\n",
      "\n",
      "episode 10, policy loss 0.027406511828303337\n",
      "\n",
      "episode 11, policy loss 0.055353473871946335\n",
      "\n",
      "episode 12, policy loss 0.07825259864330292\n",
      "\n",
      "episode 13, policy loss 0.01856049709022045\n",
      "\n",
      "episode 14, policy loss 0.07278665900230408\n",
      "\n",
      "episode 15, policy loss 0.028826002031564713\n",
      "\n",
      "episode 16, policy loss 0.046458736062049866\n",
      "\n",
      "Policy train loss in epoch 2:0.027372315475076903\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.05661826953291893\n",
      "\n",
      "episode 2, policy loss -0.0012250116560608149\n",
      "\n",
      "episode 3, policy loss 0.029731348156929016\n",
      "\n",
      "episode 4, policy loss 0.0017583691515028477\n",
      "\n",
      "episode 5, policy loss 0.06222622096538544\n",
      "\n",
      "episode 6, policy loss 0.0025409692898392677\n",
      "\n",
      "episode 7, policy loss 0.005467335227876902\n",
      "\n",
      "episode 8, policy loss 0.07849515974521637\n",
      "\n",
      "episode 9, policy loss 0.04690127819776535\n",
      "\n",
      "episode 10, policy loss 0.05501222237944603\n",
      "\n",
      "episode 11, policy loss 0.01888744719326496\n",
      "\n",
      "episode 12, policy loss -0.008933638222515583\n",
      "\n",
      "episode 13, policy loss -0.03190896660089493\n",
      "\n",
      "episode 14, policy loss 0.024424605071544647\n",
      "\n",
      "episode 15, policy loss 0.0713965967297554\n",
      "\n",
      "episode 16, policy loss 0.02842959761619568\n",
      "\n",
      "Policy train loss in epoch 3:0.027488862673635595\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.21663865447044373\n",
      "\n",
      "episode 2, val func loss 0.14756397902965546\n",
      "\n",
      "episode 3, val func loss 0.19928418099880219\n",
      "\n",
      "episode 4, val func loss 0.20735608041286469\n",
      "\n",
      "episode 5, val func loss 0.19301657378673553\n",
      "\n",
      "episode 6, val func loss 0.164576455950737\n",
      "\n",
      "episode 7, val func loss 0.1799962818622589\n",
      "\n",
      "episode 8, val func loss 0.20673219859600067\n",
      "\n",
      "episode 9, val func loss 0.19035029411315918\n",
      "\n",
      "episode 10, val func loss 0.18133988976478577\n",
      "\n",
      "episode 11, val func loss 0.17786820232868195\n",
      "\n",
      "episode 12, val func loss 0.19563095271587372\n",
      "\n",
      "episode 13, val func loss 0.2118954211473465\n",
      "\n",
      "episode 14, val func loss 0.17557650804519653\n",
      "\n",
      "episode 15, val func loss 0.17144158482551575\n",
      "\n",
      "episode 16, val func loss 0.18935707211494446\n",
      "\n",
      "Val func train loss in epoch 0:0.18803902063518763\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1956188827753067\n",
      "\n",
      "episode 2, val func loss 0.20719146728515625\n",
      "\n",
      "episode 3, val func loss 0.2209443300962448\n",
      "\n",
      "episode 4, val func loss 0.19199147820472717\n",
      "\n",
      "episode 5, val func loss 0.21358619630336761\n",
      "\n",
      "episode 6, val func loss 0.1884416788816452\n",
      "\n",
      "episode 7, val func loss 0.16860201954841614\n",
      "\n",
      "episode 8, val func loss 0.20093593001365662\n",
      "\n",
      "episode 9, val func loss 0.17667090892791748\n",
      "\n",
      "episode 10, val func loss 0.17621546983718872\n",
      "\n",
      "episode 11, val func loss 0.20282675325870514\n",
      "\n",
      "episode 12, val func loss 0.17935404181480408\n",
      "\n",
      "episode 13, val func loss 0.14672623574733734\n",
      "\n",
      "episode 14, val func loss 0.17511264979839325\n",
      "\n",
      "episode 15, val func loss 0.15970639884471893\n",
      "\n",
      "episode 16, val func loss 0.19501736760139465\n",
      "\n",
      "Val func train loss in epoch 1:0.18743386305868626\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.20340114831924438\n",
      "\n",
      "episode 2, val func loss 0.21266373991966248\n",
      "\n",
      "episode 3, val func loss 0.17590098083019257\n",
      "\n",
      "episode 4, val func loss 0.19019989669322968\n",
      "\n",
      "episode 5, val func loss 0.21371234953403473\n",
      "\n",
      "episode 6, val func loss 0.18874651193618774\n",
      "\n",
      "episode 7, val func loss 0.14722390472888947\n",
      "\n",
      "episode 8, val func loss 0.19772681593894958\n",
      "\n",
      "episode 9, val func loss 0.20010539889335632\n",
      "\n",
      "episode 10, val func loss 0.20653121173381805\n",
      "\n",
      "episode 11, val func loss 0.17859886586666107\n",
      "\n",
      "episode 12, val func loss 0.16665631532669067\n",
      "\n",
      "episode 13, val func loss 0.17688490450382233\n",
      "\n",
      "episode 14, val func loss 0.17644156515598297\n",
      "\n",
      "episode 15, val func loss 0.1583285629749298\n",
      "\n",
      "episode 16, val func loss 0.19937731325626373\n",
      "\n",
      "Val func train loss in epoch 2:0.18703121785074472\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.2053077518939972\n",
      "\n",
      "episode 2, val func loss 0.21693839132785797\n",
      "\n",
      "episode 3, val func loss 0.17636673152446747\n",
      "\n",
      "episode 4, val func loss 0.2046533226966858\n",
      "\n",
      "episode 5, val func loss 0.19203761219978333\n",
      "\n",
      "episode 6, val func loss 0.18384984135627747\n",
      "\n",
      "episode 7, val func loss 0.19107143580913544\n",
      "\n",
      "episode 8, val func loss 0.16826467216014862\n",
      "\n",
      "episode 9, val func loss 0.19552446901798248\n",
      "\n",
      "episode 10, val func loss 0.17595042288303375\n",
      "\n",
      "episode 11, val func loss 0.20669905841350555\n",
      "\n",
      "episode 12, val func loss 0.17706991732120514\n",
      "\n",
      "episode 13, val func loss 0.14549578726291656\n",
      "\n",
      "episode 14, val func loss 0.2139623910188675\n",
      "\n",
      "episode 15, val func loss 0.2012629359960556\n",
      "\n",
      "episode 16, val func loss 0.16140049695968628\n",
      "\n",
      "Val func train loss in epoch 3:0.18849095236510038\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1969238817691803\n",
      "\n",
      "episode 2, val func loss 0.17588545382022858\n",
      "\n",
      "episode 3, val func loss 0.15901976823806763\n",
      "\n",
      "episode 4, val func loss 0.2184222936630249\n",
      "\n",
      "episode 5, val func loss 0.20549903810024261\n",
      "\n",
      "episode 6, val func loss 0.16736815869808197\n",
      "\n",
      "episode 7, val func loss 0.20568592846393585\n",
      "\n",
      "episode 8, val func loss 0.21309848129749298\n",
      "\n",
      "episode 9, val func loss 0.18927931785583496\n",
      "\n",
      "episode 10, val func loss 0.14927658438682556\n",
      "\n",
      "episode 11, val func loss 0.19172120094299316\n",
      "\n",
      "episode 12, val func loss 0.17651255428791046\n",
      "\n",
      "episode 13, val func loss 0.20021195709705353\n",
      "\n",
      "episode 14, val func loss 0.19510264694690704\n",
      "\n",
      "episode 15, val func loss 0.17940260469913483\n",
      "\n",
      "episode 16, val func loss 0.17507801949977875\n",
      "\n",
      "Val func train loss in epoch 4:0.18740549311041832\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19539104402065277\n",
      "\n",
      "episode 2, val func loss 0.2153521031141281\n",
      "\n",
      "episode 3, val func loss 0.14697955548763275\n",
      "\n",
      "episode 4, val func loss 0.2025483399629593\n",
      "\n",
      "episode 5, val func loss 0.20116890966892242\n",
      "\n",
      "episode 6, val func loss 0.1918322741985321\n",
      "\n",
      "episode 7, val func loss 0.2131601721048355\n",
      "\n",
      "episode 8, val func loss 0.1676049828529358\n",
      "\n",
      "episode 9, val func loss 0.19578051567077637\n",
      "\n",
      "episode 10, val func loss 0.17855983972549438\n",
      "\n",
      "episode 11, val func loss 0.180032417178154\n",
      "\n",
      "episode 12, val func loss 0.17670515179634094\n",
      "\n",
      "episode 13, val func loss 0.2075636088848114\n",
      "\n",
      "episode 14, val func loss 0.17720067501068115\n",
      "\n",
      "episode 15, val func loss 0.19002610445022583\n",
      "\n",
      "episode 16, val func loss 0.1597500443458557\n",
      "\n",
      "Val func train loss in epoch 5:0.18747848365455866\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.14598579704761505\n",
      "\n",
      "episode 2, val func loss 0.160085529088974\n",
      "\n",
      "episode 3, val func loss 0.20077639818191528\n",
      "\n",
      "episode 4, val func loss 0.1948259025812149\n",
      "\n",
      "episode 5, val func loss 0.20677413046360016\n",
      "\n",
      "episode 6, val func loss 0.16789035499095917\n",
      "\n",
      "episode 7, val func loss 0.20289665460586548\n",
      "\n",
      "episode 8, val func loss 0.18919913470745087\n",
      "\n",
      "episode 9, val func loss 0.17573833465576172\n",
      "\n",
      "episode 10, val func loss 0.1757252812385559\n",
      "\n",
      "episode 11, val func loss 0.21444718539714813\n",
      "\n",
      "episode 12, val func loss 0.19238029420375824\n",
      "\n",
      "episode 13, val func loss 0.1755465865135193\n",
      "\n",
      "episode 14, val func loss 0.2119825929403305\n",
      "\n",
      "episode 15, val func loss 0.18024994432926178\n",
      "\n",
      "episode 16, val func loss 0.1943444013595581\n",
      "\n",
      "Val func train loss in epoch 6:0.18680303264409304\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17770402133464813\n",
      "\n",
      "episode 2, val func loss 0.1656016856431961\n",
      "\n",
      "episode 3, val func loss 0.2095673680305481\n",
      "\n",
      "episode 4, val func loss 0.2169274538755417\n",
      "\n",
      "episode 5, val func loss 0.20197713375091553\n",
      "\n",
      "episode 6, val func loss 0.21729043126106262\n",
      "\n",
      "episode 7, val func loss 0.19358305633068085\n",
      "\n",
      "episode 8, val func loss 0.20706860721111298\n",
      "\n",
      "episode 9, val func loss 0.18970340490341187\n",
      "\n",
      "episode 10, val func loss 0.17685025930404663\n",
      "\n",
      "episode 11, val func loss 0.1955811083316803\n",
      "\n",
      "episode 12, val func loss 0.16232332587242126\n",
      "\n",
      "episode 13, val func loss 0.17841297388076782\n",
      "\n",
      "episode 14, val func loss 0.19640111923217773\n",
      "\n",
      "episode 15, val func loss 0.14586126804351807\n",
      "\n",
      "episode 16, val func loss 0.17943646013736725\n",
      "\n",
      "Val func train loss in epoch 7:0.18839310482144356\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1771133542060852\n",
      "\n",
      "episode 2, val func loss 0.17813095450401306\n",
      "\n",
      "episode 3, val func loss 0.14566797018051147\n",
      "\n",
      "episode 4, val func loss 0.17690998315811157\n",
      "\n",
      "episode 5, val func loss 0.19585508108139038\n",
      "\n",
      "episode 6, val func loss 0.21762189269065857\n",
      "\n",
      "episode 7, val func loss 0.15960372984409332\n",
      "\n",
      "episode 8, val func loss 0.19499273598194122\n",
      "\n",
      "episode 9, val func loss 0.207693949341774\n",
      "\n",
      "episode 10, val func loss 0.21327143907546997\n",
      "\n",
      "episode 11, val func loss 0.17534463107585907\n",
      "\n",
      "episode 12, val func loss 0.18888191878795624\n",
      "\n",
      "episode 13, val func loss 0.19072695076465607\n",
      "\n",
      "episode 14, val func loss 0.20044204592704773\n",
      "\n",
      "episode 15, val func loss 0.16745726764202118\n",
      "\n",
      "episode 16, val func loss 0.20496726036071777\n",
      "\n",
      "Val func train loss in epoch 8:0.18716757278889418\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20241229236125946\n",
      "\n",
      "episode 2, val func loss 0.19733433425426483\n",
      "\n",
      "episode 3, val func loss 0.20430874824523926\n",
      "\n",
      "episode 4, val func loss 0.17554022371768951\n",
      "\n",
      "episode 5, val func loss 0.189444437623024\n",
      "\n",
      "episode 6, val func loss 0.18595953285694122\n",
      "\n",
      "episode 7, val func loss 0.20986440777778625\n",
      "\n",
      "episode 8, val func loss 0.1761091947555542\n",
      "\n",
      "episode 9, val func loss 0.21271295845508575\n",
      "\n",
      "episode 10, val func loss 0.1677250862121582\n",
      "\n",
      "episode 11, val func loss 0.19532158970832825\n",
      "\n",
      "episode 12, val func loss 0.2194947451353073\n",
      "\n",
      "episode 13, val func loss 0.17720232903957367\n",
      "\n",
      "episode 14, val func loss 0.18670302629470825\n",
      "\n",
      "episode 15, val func loss 0.1589682400226593\n",
      "\n",
      "episode 16, val func loss 0.1454285979270935\n",
      "\n",
      "Val func train loss in epoch 9:0.18778310902416706\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1458573341369629\n",
      "\n",
      "episode 2, val func loss 0.15888385474681854\n",
      "\n",
      "episode 3, val func loss 0.1768333613872528\n",
      "\n",
      "episode 4, val func loss 0.19557587802410126\n",
      "\n",
      "episode 5, val func loss 0.20806284248828888\n",
      "\n",
      "episode 6, val func loss 0.19064897298812866\n",
      "\n",
      "episode 7, val func loss 0.21471551060676575\n",
      "\n",
      "episode 8, val func loss 0.18945103883743286\n",
      "\n",
      "episode 9, val func loss 0.1691831648349762\n",
      "\n",
      "episode 10, val func loss 0.20241443812847137\n",
      "\n",
      "episode 11, val func loss 0.17956365644931793\n",
      "\n",
      "episode 12, val func loss 0.17627720534801483\n",
      "\n",
      "episode 13, val func loss 0.17563550174236298\n",
      "\n",
      "episode 14, val func loss 0.20062698423862457\n",
      "\n",
      "episode 15, val func loss 0.19654971361160278\n",
      "\n",
      "episode 16, val func loss 0.21198898553848267\n",
      "\n",
      "Val func train loss in epoch 10:0.1870167776942253\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.2028556764125824\n",
      "\n",
      "episode 2, val func loss 0.15880349278450012\n",
      "\n",
      "episode 3, val func loss 0.17702791094779968\n",
      "\n",
      "episode 4, val func loss 0.17549896240234375\n",
      "\n",
      "episode 5, val func loss 0.21302704513072968\n",
      "\n",
      "episode 6, val func loss 0.1763932853937149\n",
      "\n",
      "episode 7, val func loss 0.1897689253091812\n",
      "\n",
      "episode 8, val func loss 0.19376429915428162\n",
      "\n",
      "episode 9, val func loss 0.19482207298278809\n",
      "\n",
      "episode 10, val func loss 0.21569429337978363\n",
      "\n",
      "episode 11, val func loss 0.20678052306175232\n",
      "\n",
      "episode 12, val func loss 0.19999660551548004\n",
      "\n",
      "episode 13, val func loss 0.17881876230239868\n",
      "\n",
      "episode 14, val func loss 0.18989355862140656\n",
      "\n",
      "episode 15, val func loss 0.16527743637561798\n",
      "\n",
      "episode 16, val func loss 0.14765098690986633\n",
      "\n",
      "Val func train loss in epoch 11:0.1866296147927642\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.2055921107530594\n",
      "\n",
      "episode 2, val func loss 0.1880275458097458\n",
      "\n",
      "episode 3, val func loss 0.21594595909118652\n",
      "\n",
      "episode 4, val func loss 0.20071019232273102\n",
      "\n",
      "episode 5, val func loss 0.15886588394641876\n",
      "\n",
      "episode 6, val func loss 0.20623746514320374\n",
      "\n",
      "episode 7, val func loss 0.17921791970729828\n",
      "\n",
      "episode 8, val func loss 0.16557028889656067\n",
      "\n",
      "episode 9, val func loss 0.14661522209644318\n",
      "\n",
      "episode 10, val func loss 0.21766206622123718\n",
      "\n",
      "episode 11, val func loss 0.1768961399793625\n",
      "\n",
      "episode 12, val func loss 0.17876297235488892\n",
      "\n",
      "episode 13, val func loss 0.17714600265026093\n",
      "\n",
      "episode 14, val func loss 0.1941221058368683\n",
      "\n",
      "episode 15, val func loss 0.19848503172397614\n",
      "\n",
      "episode 16, val func loss 0.1892075389623642\n",
      "\n",
      "Val func train loss in epoch 12:0.18744152784347534\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.17433182895183563\n",
      "\n",
      "episode 2, val func loss 0.1747254580259323\n",
      "\n",
      "episode 3, val func loss 0.17750877141952515\n",
      "\n",
      "episode 4, val func loss 0.21267297863960266\n",
      "\n",
      "episode 5, val func loss 0.14655432105064392\n",
      "\n",
      "episode 6, val func loss 0.15849995613098145\n",
      "\n",
      "episode 7, val func loss 0.18758432567119598\n",
      "\n",
      "episode 8, val func loss 0.19059067964553833\n",
      "\n",
      "episode 9, val func loss 0.20261503756046295\n",
      "\n",
      "episode 10, val func loss 0.19681134819984436\n",
      "\n",
      "episode 11, val func loss 0.21744944155216217\n",
      "\n",
      "episode 12, val func loss 0.2027190923690796\n",
      "\n",
      "episode 13, val func loss 0.1985141932964325\n",
      "\n",
      "episode 14, val func loss 0.17133529484272003\n",
      "\n",
      "episode 15, val func loss 0.2080395370721817\n",
      "\n",
      "episode 16, val func loss 0.18089817464351654\n",
      "\n",
      "Val func train loss in epoch 13:0.18755315244197845\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.16831764578819275\n",
      "\n",
      "episode 2, val func loss 0.20628519356250763\n",
      "\n",
      "episode 3, val func loss 0.20223920047283173\n",
      "\n",
      "episode 4, val func loss 0.2213374674320221\n",
      "\n",
      "episode 5, val func loss 0.21531155705451965\n",
      "\n",
      "episode 6, val func loss 0.1588386744260788\n",
      "\n",
      "episode 7, val func loss 0.19567319750785828\n",
      "\n",
      "episode 8, val func loss 0.18778616189956665\n",
      "\n",
      "episode 9, val func loss 0.17524267733097076\n",
      "\n",
      "episode 10, val func loss 0.1788148432970047\n",
      "\n",
      "episode 11, val func loss 0.1771186739206314\n",
      "\n",
      "episode 12, val func loss 0.17696592211723328\n",
      "\n",
      "episode 13, val func loss 0.14562760293483734\n",
      "\n",
      "episode 14, val func loss 0.20351600646972656\n",
      "\n",
      "episode 15, val func loss 0.18961724638938904\n",
      "\n",
      "episode 16, val func loss 0.19403627514839172\n",
      "\n",
      "Val func train loss in epoch 14:0.18729552160948515\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.16205866634845734\n",
      "\n",
      "episode 2, val func loss 0.17479801177978516\n",
      "\n",
      "episode 3, val func loss 0.2025931179523468\n",
      "\n",
      "episode 4, val func loss 0.17869704961776733\n",
      "\n",
      "episode 5, val func loss 0.1759682148694992\n",
      "\n",
      "episode 6, val func loss 0.14720796048641205\n",
      "\n",
      "episode 7, val func loss 0.18901343643665314\n",
      "\n",
      "episode 8, val func loss 0.16679523885250092\n",
      "\n",
      "episode 9, val func loss 0.17834684252738953\n",
      "\n",
      "episode 10, val func loss 0.20724916458129883\n",
      "\n",
      "episode 11, val func loss 0.19674597680568695\n",
      "\n",
      "episode 12, val func loss 0.20422421395778656\n",
      "\n",
      "episode 13, val func loss 0.1935281753540039\n",
      "\n",
      "episode 14, val func loss 0.21546530723571777\n",
      "\n",
      "episode 15, val func loss 0.21819140017032623\n",
      "\n",
      "episode 16, val func loss 0.19429200887680054\n",
      "\n",
      "Val func train loss in epoch 15:0.18782342411577702\n",
      "***********************TIME WAS 4.9297996163368225 min*****************************\n",
      "\n",
      "**********************ROUND 65 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.028870178386569023\n",
      "\n",
      "episode 2, policy loss -0.00722578726708889\n",
      "\n",
      "episode 3, policy loss -0.02477196417748928\n",
      "\n",
      "episode 4, policy loss 0.020246336236596107\n",
      "\n",
      "episode 5, policy loss 0.008836419321596622\n",
      "\n",
      "episode 6, policy loss -0.014126606285572052\n",
      "\n",
      "episode 7, policy loss -0.008746624924242496\n",
      "\n",
      "episode 8, policy loss 0.05542900040745735\n",
      "\n",
      "episode 9, policy loss 0.1056690365076065\n",
      "\n",
      "episode 10, policy loss 0.031548891216516495\n",
      "\n",
      "episode 11, policy loss -0.038264334201812744\n",
      "\n",
      "episode 12, policy loss 0.01641993597149849\n",
      "\n",
      "episode 13, policy loss -0.02259485423564911\n",
      "\n",
      "episode 14, policy loss 0.012210256420075893\n",
      "\n",
      "episode 15, policy loss 0.006901322863996029\n",
      "\n",
      "episode 16, policy loss 0.055813245475292206\n",
      "\n",
      "Policy train loss in epoch 0:0.014138403232209384\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.012366809882223606\n",
      "\n",
      "episode 2, policy loss -0.013819381594657898\n",
      "\n",
      "episode 3, policy loss 0.01995907723903656\n",
      "\n",
      "episode 4, policy loss 0.053265463560819626\n",
      "\n",
      "episode 5, policy loss -0.02806353196501732\n",
      "\n",
      "episode 6, policy loss -0.016734950244426727\n",
      "\n",
      "episode 7, policy loss -0.02520296908915043\n",
      "\n",
      "episode 8, policy loss 0.015163429081439972\n",
      "\n",
      "episode 9, policy loss -0.010524362325668335\n",
      "\n",
      "episode 10, policy loss 0.008375808596611023\n",
      "\n",
      "episode 11, policy loss 0.006504034623503685\n",
      "\n",
      "episode 12, policy loss -0.038819827139377594\n",
      "\n",
      "episode 13, policy loss 0.10546773672103882\n",
      "\n",
      "episode 14, policy loss 0.02910994365811348\n",
      "\n",
      "episode 15, policy loss 0.05383157357573509\n",
      "\n",
      "episode 16, policy loss 0.020347988232970238\n",
      "\n",
      "Policy train loss in epoch 1:0.011951677675824612\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.1030888706445694\n",
      "\n",
      "episode 2, policy loss -0.016238439828157425\n",
      "\n",
      "episode 3, policy loss 0.012930355966091156\n",
      "\n",
      "episode 4, policy loss -0.021197905763983727\n",
      "\n",
      "episode 5, policy loss 0.05630817636847496\n",
      "\n",
      "episode 6, policy loss 0.015769636258482933\n",
      "\n",
      "episode 7, policy loss 0.020154990255832672\n",
      "\n",
      "episode 8, policy loss -0.010792925953865051\n",
      "\n",
      "episode 9, policy loss 0.006870201788842678\n",
      "\n",
      "episode 10, policy loss -0.027022710070014\n",
      "\n",
      "episode 11, policy loss 0.03086782619357109\n",
      "\n",
      "episode 12, policy loss 0.05312687158584595\n",
      "\n",
      "episode 13, policy loss -0.018063899129629135\n",
      "\n",
      "episode 14, policy loss 0.019077841192483902\n",
      "\n",
      "episode 15, policy loss 0.004973375704139471\n",
      "\n",
      "episode 16, policy loss -0.03987794741988182\n",
      "\n",
      "Policy train loss in epoch 2:0.01187339486205019\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.053318802267313004\n",
      "\n",
      "episode 2, policy loss 0.10342220962047577\n",
      "\n",
      "episode 3, policy loss -0.016452506184577942\n",
      "\n",
      "episode 4, policy loss 0.02876780927181244\n",
      "\n",
      "episode 5, policy loss 0.019099611788988113\n",
      "\n",
      "episode 6, policy loss -0.011292612180113792\n",
      "\n",
      "episode 7, policy loss -0.028695808723568916\n",
      "\n",
      "episode 8, policy loss 0.014317755587399006\n",
      "\n",
      "episode 9, policy loss 0.004838257096707821\n",
      "\n",
      "episode 10, policy loss 0.010229486040771008\n",
      "\n",
      "episode 11, policy loss -0.02526715025305748\n",
      "\n",
      "episode 12, policy loss -0.017999401316046715\n",
      "\n",
      "episode 13, policy loss 0.004252906423062086\n",
      "\n",
      "episode 14, policy loss -0.04148370027542114\n",
      "\n",
      "episode 15, policy loss 0.019036728888750076\n",
      "\n",
      "episode 16, policy loss 0.05380159988999367\n",
      "\n",
      "Policy train loss in epoch 3:0.010618374246405438\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.14689131081104279\n",
      "\n",
      "episode 2, val func loss 0.20515874028205872\n",
      "\n",
      "episode 3, val func loss 0.19031493365764618\n",
      "\n",
      "episode 4, val func loss 0.21517625451087952\n",
      "\n",
      "episode 5, val func loss 0.21062226593494415\n",
      "\n",
      "episode 6, val func loss 0.16265615820884705\n",
      "\n",
      "episode 7, val func loss 0.20040851831436157\n",
      "\n",
      "episode 8, val func loss 0.18670865893363953\n",
      "\n",
      "episode 9, val func loss 0.1632901132106781\n",
      "\n",
      "episode 10, val func loss 0.16768336296081543\n",
      "\n",
      "episode 11, val func loss 0.21530781686306\n",
      "\n",
      "episode 12, val func loss 0.19053861498832703\n",
      "\n",
      "episode 13, val func loss 0.14036162197589874\n",
      "\n",
      "episode 14, val func loss 0.18458324670791626\n",
      "\n",
      "episode 15, val func loss 0.19607314467430115\n",
      "\n",
      "episode 16, val func loss 0.17997783422470093\n",
      "\n",
      "Val func train loss in epoch 0:0.18473453726619482\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.16151629388332367\n",
      "\n",
      "episode 2, val func loss 0.1643866002559662\n",
      "\n",
      "episode 3, val func loss 0.21445399522781372\n",
      "\n",
      "episode 4, val func loss 0.21283291280269623\n",
      "\n",
      "episode 5, val func loss 0.18640564382076263\n",
      "\n",
      "episode 6, val func loss 0.18999460339546204\n",
      "\n",
      "episode 7, val func loss 0.18431514501571655\n",
      "\n",
      "episode 8, val func loss 0.16832514107227325\n",
      "\n",
      "episode 9, val func loss 0.21338720619678497\n",
      "\n",
      "episode 10, val func loss 0.20496779680252075\n",
      "\n",
      "episode 11, val func loss 0.1937873661518097\n",
      "\n",
      "episode 12, val func loss 0.14260625839233398\n",
      "\n",
      "episode 13, val func loss 0.1799018383026123\n",
      "\n",
      "episode 14, val func loss 0.1420585662126541\n",
      "\n",
      "episode 15, val func loss 0.18970908224582672\n",
      "\n",
      "episode 16, val func loss 0.2014535814523697\n",
      "\n",
      "Val func train loss in epoch 1:0.1843813769519329\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18464818596839905\n",
      "\n",
      "episode 2, val func loss 0.18591037392616272\n",
      "\n",
      "episode 3, val func loss 0.21424467861652374\n",
      "\n",
      "episode 4, val func loss 0.21452860534191132\n",
      "\n",
      "episode 5, val func loss 0.20079684257507324\n",
      "\n",
      "episode 6, val func loss 0.16917762160301208\n",
      "\n",
      "episode 7, val func loss 0.1890941709280014\n",
      "\n",
      "episode 8, val func loss 0.14150767028331757\n",
      "\n",
      "episode 9, val func loss 0.21256005764007568\n",
      "\n",
      "episode 10, val func loss 0.17999298870563507\n",
      "\n",
      "episode 11, val func loss 0.2054102122783661\n",
      "\n",
      "episode 12, val func loss 0.1635291874408722\n",
      "\n",
      "episode 13, val func loss 0.14062243700027466\n",
      "\n",
      "episode 14, val func loss 0.1964005082845688\n",
      "\n",
      "episode 15, val func loss 0.15975649654865265\n",
      "\n",
      "episode 16, val func loss 0.19036118686199188\n",
      "\n",
      "Val func train loss in epoch 2:0.18428382650017738\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.2137618362903595\n",
      "\n",
      "episode 2, val func loss 0.19442036747932434\n",
      "\n",
      "episode 3, val func loss 0.1688116192817688\n",
      "\n",
      "episode 4, val func loss 0.21245214343070984\n",
      "\n",
      "episode 5, val func loss 0.1852473020553589\n",
      "\n",
      "episode 6, val func loss 0.19145281612873077\n",
      "\n",
      "episode 7, val func loss 0.14278045296669006\n",
      "\n",
      "episode 8, val func loss 0.201112300157547\n",
      "\n",
      "episode 9, val func loss 0.17944389581680298\n",
      "\n",
      "episode 10, val func loss 0.18619202077388763\n",
      "\n",
      "episode 11, val func loss 0.15937800705432892\n",
      "\n",
      "episode 12, val func loss 0.19062794744968414\n",
      "\n",
      "episode 13, val func loss 0.20720751583576202\n",
      "\n",
      "episode 14, val func loss 0.14024992287158966\n",
      "\n",
      "episode 15, val func loss 0.16316255927085876\n",
      "\n",
      "episode 16, val func loss 0.21491141617298126\n",
      "\n",
      "Val func train loss in epoch 3:0.18445075768977404\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18050368130207062\n",
      "\n",
      "episode 2, val func loss 0.18434138596057892\n",
      "\n",
      "episode 3, val func loss 0.19328708946704865\n",
      "\n",
      "episode 4, val func loss 0.1707446575164795\n",
      "\n",
      "episode 5, val func loss 0.21506117284297943\n",
      "\n",
      "episode 6, val func loss 0.18898428976535797\n",
      "\n",
      "episode 7, val func loss 0.16481435298919678\n",
      "\n",
      "episode 8, val func loss 0.1857701689004898\n",
      "\n",
      "episode 9, val func loss 0.14036431908607483\n",
      "\n",
      "episode 10, val func loss 0.13384610414505005\n",
      "\n",
      "episode 11, val func loss 0.21902026236057281\n",
      "\n",
      "episode 12, val func loss 0.20992161333560944\n",
      "\n",
      "episode 13, val func loss 0.21797901391983032\n",
      "\n",
      "episode 14, val func loss 0.19058232009410858\n",
      "\n",
      "episode 15, val func loss 0.15975242853164673\n",
      "\n",
      "episode 16, val func loss 0.20076076686382294\n",
      "\n",
      "Val func train loss in epoch 4:0.18473335169255733\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17982932925224304\n",
      "\n",
      "episode 2, val func loss 0.2045678347349167\n",
      "\n",
      "episode 3, val func loss 0.2155308574438095\n",
      "\n",
      "episode 4, val func loss 0.16319584846496582\n",
      "\n",
      "episode 5, val func loss 0.1933499276638031\n",
      "\n",
      "episode 6, val func loss 0.16911378502845764\n",
      "\n",
      "episode 7, val func loss 0.1643751859664917\n",
      "\n",
      "episode 8, val func loss 0.18981249630451202\n",
      "\n",
      "episode 9, val func loss 0.2152673900127411\n",
      "\n",
      "episode 10, val func loss 0.185553640127182\n",
      "\n",
      "episode 11, val func loss 0.21283869445323944\n",
      "\n",
      "episode 12, val func loss 0.1846177577972412\n",
      "\n",
      "episode 13, val func loss 0.1896379292011261\n",
      "\n",
      "episode 14, val func loss 0.14428697526454926\n",
      "\n",
      "episode 15, val func loss 0.14105908572673798\n",
      "\n",
      "episode 16, val func loss 0.20147904753684998\n",
      "\n",
      "Val func train loss in epoch 5:0.18465723656117916\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1896672546863556\n",
      "\n",
      "episode 2, val func loss 0.13425862789154053\n",
      "\n",
      "episode 3, val func loss 0.20918282866477966\n",
      "\n",
      "episode 4, val func loss 0.21617990732192993\n",
      "\n",
      "episode 5, val func loss 0.1682686060667038\n",
      "\n",
      "episode 6, val func loss 0.14041964709758759\n",
      "\n",
      "episode 7, val func loss 0.1599537432193756\n",
      "\n",
      "episode 8, val func loss 0.21312668919563293\n",
      "\n",
      "episode 9, val func loss 0.21272610127925873\n",
      "\n",
      "episode 10, val func loss 0.17970708012580872\n",
      "\n",
      "episode 11, val func loss 0.18407735228538513\n",
      "\n",
      "episode 12, val func loss 0.1933659166097641\n",
      "\n",
      "episode 13, val func loss 0.2007034868001938\n",
      "\n",
      "episode 14, val func loss 0.16676634550094604\n",
      "\n",
      "episode 15, val func loss 0.19100061058998108\n",
      "\n",
      "episode 16, val func loss 0.18759341537952423\n",
      "\n",
      "Val func train loss in epoch 6:0.18418735079467297\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.14174674451351166\n",
      "\n",
      "episode 2, val func loss 0.17963705956935883\n",
      "\n",
      "episode 3, val func loss 0.16831938922405243\n",
      "\n",
      "episode 4, val func loss 0.2076585292816162\n",
      "\n",
      "episode 5, val func loss 0.2156609743833542\n",
      "\n",
      "episode 6, val func loss 0.19555138051509857\n",
      "\n",
      "episode 7, val func loss 0.1897595077753067\n",
      "\n",
      "episode 8, val func loss 0.214193657040596\n",
      "\n",
      "episode 9, val func loss 0.1417803019285202\n",
      "\n",
      "episode 10, val func loss 0.16212362051010132\n",
      "\n",
      "episode 11, val func loss 0.18695321679115295\n",
      "\n",
      "episode 12, val func loss 0.200959250330925\n",
      "\n",
      "episode 13, val func loss 0.18424786627292633\n",
      "\n",
      "episode 14, val func loss 0.1897175908088684\n",
      "\n",
      "episode 15, val func loss 0.1631721407175064\n",
      "\n",
      "episode 16, val func loss 0.21458700299263\n",
      "\n",
      "Val func train loss in epoch 7:0.18475426454097033\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.21442797780036926\n",
      "\n",
      "episode 2, val func loss 0.1600826382637024\n",
      "\n",
      "episode 3, val func loss 0.18627308309078217\n",
      "\n",
      "episode 4, val func loss 0.20455676317214966\n",
      "\n",
      "episode 5, val func loss 0.21373744308948517\n",
      "\n",
      "episode 6, val func loss 0.1642393320798874\n",
      "\n",
      "episode 7, val func loss 0.18397626280784607\n",
      "\n",
      "episode 8, val func loss 0.18016120791435242\n",
      "\n",
      "episode 9, val func loss 0.1951398402452469\n",
      "\n",
      "episode 10, val func loss 0.18849313259124756\n",
      "\n",
      "episode 11, val func loss 0.16851451992988586\n",
      "\n",
      "episode 12, val func loss 0.1904781460762024\n",
      "\n",
      "episode 13, val func loss 0.20092807710170746\n",
      "\n",
      "episode 14, val func loss 0.2105252742767334\n",
      "\n",
      "episode 15, val func loss 0.1420082151889801\n",
      "\n",
      "episode 16, val func loss 0.13824425637722015\n",
      "\n",
      "Val func train loss in epoch 8:0.1838616356253624\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1337938755750656\n",
      "\n",
      "episode 2, val func loss 0.16592161357402802\n",
      "\n",
      "episode 3, val func loss 0.16292442381381989\n",
      "\n",
      "episode 4, val func loss 0.22626985609531403\n",
      "\n",
      "episode 5, val func loss 0.20330238342285156\n",
      "\n",
      "episode 6, val func loss 0.18609635531902313\n",
      "\n",
      "episode 7, val func loss 0.1890978068113327\n",
      "\n",
      "episode 8, val func loss 0.19304455816745758\n",
      "\n",
      "episode 9, val func loss 0.14698821306228638\n",
      "\n",
      "episode 10, val func loss 0.19268125295639038\n",
      "\n",
      "episode 11, val func loss 0.18041743338108063\n",
      "\n",
      "episode 12, val func loss 0.18409398198127747\n",
      "\n",
      "episode 13, val func loss 0.21369092166423798\n",
      "\n",
      "episode 14, val func loss 0.20535880327224731\n",
      "\n",
      "episode 15, val func loss 0.16855129599571228\n",
      "\n",
      "episode 16, val func loss 0.21417845785617828\n",
      "\n",
      "Val func train loss in epoch 9:0.18540070205926895\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.213014155626297\n",
      "\n",
      "episode 2, val func loss 0.14263968169689178\n",
      "\n",
      "episode 3, val func loss 0.1645120531320572\n",
      "\n",
      "episode 4, val func loss 0.18448124825954437\n",
      "\n",
      "episode 5, val func loss 0.21413668990135193\n",
      "\n",
      "episode 6, val func loss 0.1680743545293808\n",
      "\n",
      "episode 7, val func loss 0.20088481903076172\n",
      "\n",
      "episode 8, val func loss 0.19020900130271912\n",
      "\n",
      "episode 9, val func loss 0.17953947186470032\n",
      "\n",
      "episode 10, val func loss 0.14046384394168854\n",
      "\n",
      "episode 11, val func loss 0.15996018052101135\n",
      "\n",
      "episode 12, val func loss 0.18973618745803833\n",
      "\n",
      "episode 13, val func loss 0.20630989968776703\n",
      "\n",
      "episode 14, val func loss 0.18591685593128204\n",
      "\n",
      "episode 15, val func loss 0.21479906141757965\n",
      "\n",
      "episode 16, val func loss 0.19596420228481293\n",
      "\n",
      "Val func train loss in epoch 10:0.18441510666161776\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1360962986946106\n",
      "\n",
      "episode 2, val func loss 0.19550088047981262\n",
      "\n",
      "episode 3, val func loss 0.1863977164030075\n",
      "\n",
      "episode 4, val func loss 0.18414008617401123\n",
      "\n",
      "episode 5, val func loss 0.21400271356105804\n",
      "\n",
      "episode 6, val func loss 0.17957177758216858\n",
      "\n",
      "episode 7, val func loss 0.21234041452407837\n",
      "\n",
      "episode 8, val func loss 0.161654993891716\n",
      "\n",
      "episode 9, val func loss 0.21205540001392365\n",
      "\n",
      "episode 10, val func loss 0.1890840083360672\n",
      "\n",
      "episode 11, val func loss 0.16865678131580353\n",
      "\n",
      "episode 12, val func loss 0.1642516404390335\n",
      "\n",
      "episode 13, val func loss 0.20099377632141113\n",
      "\n",
      "episode 14, val func loss 0.14172114431858063\n",
      "\n",
      "episode 15, val func loss 0.18958912789821625\n",
      "\n",
      "episode 16, val func loss 0.20600846409797668\n",
      "\n",
      "Val func train loss in epoch 11:0.18387907650321722\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1680235117673874\n",
      "\n",
      "episode 2, val func loss 0.16299951076507568\n",
      "\n",
      "episode 3, val func loss 0.19005842506885529\n",
      "\n",
      "episode 4, val func loss 0.1856682449579239\n",
      "\n",
      "episode 5, val func loss 0.14063778519630432\n",
      "\n",
      "episode 6, val func loss 0.21451133489608765\n",
      "\n",
      "episode 7, val func loss 0.18948516249656677\n",
      "\n",
      "episode 8, val func loss 0.21452265977859497\n",
      "\n",
      "episode 9, val func loss 0.20460523664951324\n",
      "\n",
      "episode 10, val func loss 0.18393850326538086\n",
      "\n",
      "episode 11, val func loss 0.21123164892196655\n",
      "\n",
      "episode 12, val func loss 0.20011462271213531\n",
      "\n",
      "episode 13, val func loss 0.18042108416557312\n",
      "\n",
      "episode 14, val func loss 0.16450341045856476\n",
      "\n",
      "episode 15, val func loss 0.14229975640773773\n",
      "\n",
      "episode 16, val func loss 0.19435708224773407\n",
      "\n",
      "Val func train loss in epoch 12:0.1842111237347126\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.15963119268417358\n",
      "\n",
      "episode 2, val func loss 0.19074013829231262\n",
      "\n",
      "episode 3, val func loss 0.19156374037265778\n",
      "\n",
      "episode 4, val func loss 0.18616920709609985\n",
      "\n",
      "episode 5, val func loss 0.1333138793706894\n",
      "\n",
      "episode 6, val func loss 0.1399257481098175\n",
      "\n",
      "episode 7, val func loss 0.21859252452850342\n",
      "\n",
      "episode 8, val func loss 0.20789918303489685\n",
      "\n",
      "episode 9, val func loss 0.18092627823352814\n",
      "\n",
      "episode 10, val func loss 0.21390920877456665\n",
      "\n",
      "episode 11, val func loss 0.21250025928020477\n",
      "\n",
      "episode 12, val func loss 0.1693275421857834\n",
      "\n",
      "episode 13, val func loss 0.19282318651676178\n",
      "\n",
      "episode 14, val func loss 0.16809892654418945\n",
      "\n",
      "episode 15, val func loss 0.18615329265594482\n",
      "\n",
      "episode 16, val func loss 0.20106403529644012\n",
      "\n",
      "Val func train loss in epoch 13:0.18453989643603563\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18548725545406342\n",
      "\n",
      "episode 2, val func loss 0.16531457006931305\n",
      "\n",
      "episode 3, val func loss 0.13841499388217926\n",
      "\n",
      "episode 4, val func loss 0.14011746644973755\n",
      "\n",
      "episode 5, val func loss 0.17120608687400818\n",
      "\n",
      "episode 6, val func loss 0.19534406065940857\n",
      "\n",
      "episode 7, val func loss 0.1879987269639969\n",
      "\n",
      "episode 8, val func loss 0.21739476919174194\n",
      "\n",
      "episode 9, val func loss 0.19798870384693146\n",
      "\n",
      "episode 10, val func loss 0.21388313174247742\n",
      "\n",
      "episode 11, val func loss 0.17993545532226562\n",
      "\n",
      "episode 12, val func loss 0.21125653386116028\n",
      "\n",
      "episode 13, val func loss 0.19115975499153137\n",
      "\n",
      "episode 14, val func loss 0.16603997349739075\n",
      "\n",
      "episode 15, val func loss 0.20096956193447113\n",
      "\n",
      "episode 16, val func loss 0.2049642652273178\n",
      "\n",
      "Val func train loss in epoch 14:0.18546720687299967\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20470523834228516\n",
      "\n",
      "episode 2, val func loss 0.20073434710502625\n",
      "\n",
      "episode 3, val func loss 0.16841088235378265\n",
      "\n",
      "episode 4, val func loss 0.13586653769016266\n",
      "\n",
      "episode 5, val func loss 0.13940779864788055\n",
      "\n",
      "episode 6, val func loss 0.2232767641544342\n",
      "\n",
      "episode 7, val func loss 0.18749015033245087\n",
      "\n",
      "episode 8, val func loss 0.21518413722515106\n",
      "\n",
      "episode 9, val func loss 0.16307714581489563\n",
      "\n",
      "episode 10, val func loss 0.21460185945034027\n",
      "\n",
      "episode 11, val func loss 0.19366227090358734\n",
      "\n",
      "episode 12, val func loss 0.19048643112182617\n",
      "\n",
      "episode 13, val func loss 0.18037149310112\n",
      "\n",
      "episode 14, val func loss 0.19036948680877686\n",
      "\n",
      "episode 15, val func loss 0.16074953973293304\n",
      "\n",
      "episode 16, val func loss 0.1864372342824936\n",
      "\n",
      "Val func train loss in epoch 15:0.18467695731669664\n",
      "***********************TIME WAS 4.935330764452616 min*****************************\n",
      "\n",
      "**********************ROUND 66 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.03464040532708168\n",
      "\n",
      "episode 2, policy loss -0.06502140313386917\n",
      "\n",
      "episode 3, policy loss -0.013235528022050858\n",
      "\n",
      "episode 4, policy loss -0.06355506926774979\n",
      "\n",
      "episode 5, policy loss -0.05705614387989044\n",
      "\n",
      "episode 6, policy loss -0.0876094400882721\n",
      "\n",
      "episode 7, policy loss -0.06458202004432678\n",
      "\n",
      "episode 8, policy loss -0.0049010757356882095\n",
      "\n",
      "episode 9, policy loss -0.12740711867809296\n",
      "\n",
      "episode 10, policy loss -0.008473528549075127\n",
      "\n",
      "episode 11, policy loss -0.06736592203378677\n",
      "\n",
      "episode 12, policy loss -0.07558119297027588\n",
      "\n",
      "episode 13, policy loss -0.027368919923901558\n",
      "\n",
      "episode 14, policy loss -0.07331191003322601\n",
      "\n",
      "episode 15, policy loss -0.10554223507642746\n",
      "\n",
      "episode 16, policy loss -0.08207599073648453\n",
      "\n",
      "Policy train loss in epoch 0:-0.05985799396876246\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.02724749967455864\n",
      "\n",
      "episode 2, policy loss -0.07145657390356064\n",
      "\n",
      "episode 3, policy loss -0.0632898136973381\n",
      "\n",
      "episode 4, policy loss -0.08001170307397842\n",
      "\n",
      "episode 5, policy loss -0.06900126487016678\n",
      "\n",
      "episode 6, policy loss -0.10666725039482117\n",
      "\n",
      "episode 7, policy loss -0.08810080587863922\n",
      "\n",
      "episode 8, policy loss -0.015296468511223793\n",
      "\n",
      "episode 9, policy loss -0.06645048409700394\n",
      "\n",
      "episode 10, policy loss -0.0751899778842926\n",
      "\n",
      "episode 11, policy loss -0.12804915010929108\n",
      "\n",
      "episode 12, policy loss -0.07759679108858109\n",
      "\n",
      "episode 13, policy loss -0.012131021358072758\n",
      "\n",
      "episode 14, policy loss -0.006929975468665361\n",
      "\n",
      "episode 15, policy loss -0.0432727076113224\n",
      "\n",
      "episode 16, policy loss -0.057348962873220444\n",
      "\n",
      "Policy train loss in epoch 1:-0.06175252815592103\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.028088880702853203\n",
      "\n",
      "episode 2, policy loss -0.07368620485067368\n",
      "\n",
      "episode 3, policy loss -0.06576148420572281\n",
      "\n",
      "episode 4, policy loss -0.1284855753183365\n",
      "\n",
      "episode 5, policy loss -0.08097982406616211\n",
      "\n",
      "episode 6, policy loss -0.05662757530808449\n",
      "\n",
      "episode 7, policy loss -0.0735001340508461\n",
      "\n",
      "episode 8, policy loss -0.012154126539826393\n",
      "\n",
      "episode 9, policy loss -0.016118638217449188\n",
      "\n",
      "episode 10, policy loss -0.08924967795610428\n",
      "\n",
      "episode 11, policy loss -0.07024998962879181\n",
      "\n",
      "episode 12, policy loss -0.06727446615695953\n",
      "\n",
      "episode 13, policy loss -0.08263063430786133\n",
      "\n",
      "episode 14, policy loss -0.008271468803286552\n",
      "\n",
      "episode 15, policy loss -0.10775001347064972\n",
      "\n",
      "episode 16, policy loss -0.04467792063951492\n",
      "\n",
      "Policy train loss in epoch 2:-0.06284416338894516\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.0077173444442451\n",
      "\n",
      "episode 2, policy loss -0.012458090670406818\n",
      "\n",
      "episode 3, policy loss -0.01649896614253521\n",
      "\n",
      "episode 4, policy loss -0.08935409039258957\n",
      "\n",
      "episode 5, policy loss -0.07639691978693008\n",
      "\n",
      "episode 6, policy loss -0.06803055107593536\n",
      "\n",
      "episode 7, policy loss -0.029149457812309265\n",
      "\n",
      "episode 8, policy loss -0.056906238198280334\n",
      "\n",
      "episode 9, policy loss -0.07986541837453842\n",
      "\n",
      "episode 10, policy loss -0.07338888943195343\n",
      "\n",
      "episode 11, policy loss -0.04443957656621933\n",
      "\n",
      "episode 12, policy loss -0.07050648331642151\n",
      "\n",
      "episode 13, policy loss -0.12916512787342072\n",
      "\n",
      "episode 14, policy loss -0.08102347701787949\n",
      "\n",
      "episode 15, policy loss -0.1074918657541275\n",
      "\n",
      "episode 16, policy loss -0.0685868039727211\n",
      "\n",
      "Policy train loss in epoch 3:-0.06318620630190708\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17162559926509857\n",
      "\n",
      "episode 2, val func loss 0.20153245329856873\n",
      "\n",
      "episode 3, val func loss 0.2120378315448761\n",
      "\n",
      "episode 4, val func loss 0.1995069980621338\n",
      "\n",
      "episode 5, val func loss 0.19358815252780914\n",
      "\n",
      "episode 6, val func loss 0.18930181860923767\n",
      "\n",
      "episode 7, val func loss 0.1656983196735382\n",
      "\n",
      "episode 8, val func loss 0.1953783929347992\n",
      "\n",
      "episode 9, val func loss 0.16042453050613403\n",
      "\n",
      "episode 10, val func loss 0.19991609454154968\n",
      "\n",
      "episode 11, val func loss 0.22336462140083313\n",
      "\n",
      "episode 12, val func loss 0.19392208755016327\n",
      "\n",
      "episode 13, val func loss 0.2185095101594925\n",
      "\n",
      "episode 14, val func loss 0.1646924465894699\n",
      "\n",
      "episode 15, val func loss 0.17508791387081146\n",
      "\n",
      "episode 16, val func loss 0.16568708419799805\n",
      "\n",
      "Val func train loss in epoch 0:0.1893921159207821\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19277064502239227\n",
      "\n",
      "episode 2, val func loss 0.1632971167564392\n",
      "\n",
      "episode 3, val func loss 0.19900274276733398\n",
      "\n",
      "episode 4, val func loss 0.17183691263198853\n",
      "\n",
      "episode 5, val func loss 0.16159974038600922\n",
      "\n",
      "episode 6, val func loss 0.20108628273010254\n",
      "\n",
      "episode 7, val func loss 0.2149639129638672\n",
      "\n",
      "episode 8, val func loss 0.22125524282455444\n",
      "\n",
      "episode 9, val func loss 0.19256539642810822\n",
      "\n",
      "episode 10, val func loss 0.19142255187034607\n",
      "\n",
      "episode 11, val func loss 0.1902972161769867\n",
      "\n",
      "episode 12, val func loss 0.1647520661354065\n",
      "\n",
      "episode 13, val func loss 0.21815906465053558\n",
      "\n",
      "episode 14, val func loss 0.16474004089832306\n",
      "\n",
      "episode 15, val func loss 0.1992848664522171\n",
      "\n",
      "episode 16, val func loss 0.17240087687969208\n",
      "\n",
      "Val func train loss in epoch 1:0.18871466722339392\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19079571962356567\n",
      "\n",
      "episode 2, val func loss 0.20074795186519623\n",
      "\n",
      "episode 3, val func loss 0.17156921327114105\n",
      "\n",
      "episode 4, val func loss 0.17159831523895264\n",
      "\n",
      "episode 5, val func loss 0.19186526536941528\n",
      "\n",
      "episode 6, val func loss 0.16226400434970856\n",
      "\n",
      "episode 7, val func loss 0.22147834300994873\n",
      "\n",
      "episode 8, val func loss 0.1602003127336502\n",
      "\n",
      "episode 9, val func loss 0.1908130943775177\n",
      "\n",
      "episode 10, val func loss 0.1622556895017624\n",
      "\n",
      "episode 11, val func loss 0.19890408217906952\n",
      "\n",
      "episode 12, val func loss 0.220148965716362\n",
      "\n",
      "episode 13, val func loss 0.1991594135761261\n",
      "\n",
      "episode 14, val func loss 0.16386538743972778\n",
      "\n",
      "episode 15, val func loss 0.21264787018299103\n",
      "\n",
      "episode 16, val func loss 0.1930791288614273\n",
      "\n",
      "Val func train loss in epoch 2:0.18821204733103514\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19293420016765594\n",
      "\n",
      "episode 2, val func loss 0.21781808137893677\n",
      "\n",
      "episode 3, val func loss 0.20024961233139038\n",
      "\n",
      "episode 4, val func loss 0.16320806741714478\n",
      "\n",
      "episode 5, val func loss 0.2120484560728073\n",
      "\n",
      "episode 6, val func loss 0.16472958028316498\n",
      "\n",
      "episode 7, val func loss 0.21981143951416016\n",
      "\n",
      "episode 8, val func loss 0.19099371135234833\n",
      "\n",
      "episode 9, val func loss 0.1921989619731903\n",
      "\n",
      "episode 10, val func loss 0.1724020093679428\n",
      "\n",
      "episode 11, val func loss 0.19906015694141388\n",
      "\n",
      "episode 12, val func loss 0.17219726741313934\n",
      "\n",
      "episode 13, val func loss 0.16159138083457947\n",
      "\n",
      "episode 14, val func loss 0.19848275184631348\n",
      "\n",
      "episode 15, val func loss 0.19141043722629547\n",
      "\n",
      "episode 16, val func loss 0.1597110778093338\n",
      "\n",
      "Val func train loss in epoch 3:0.18805294949561357\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1624249964952469\n",
      "\n",
      "episode 2, val func loss 0.1714099794626236\n",
      "\n",
      "episode 3, val func loss 0.20295201241970062\n",
      "\n",
      "episode 4, val func loss 0.15953953564167023\n",
      "\n",
      "episode 5, val func loss 0.17195425927639008\n",
      "\n",
      "episode 6, val func loss 0.22069866955280304\n",
      "\n",
      "episode 7, val func loss 0.1913299411535263\n",
      "\n",
      "episode 8, val func loss 0.1643260419368744\n",
      "\n",
      "episode 9, val func loss 0.192339688539505\n",
      "\n",
      "episode 10, val func loss 0.19353578984737396\n",
      "\n",
      "episode 11, val func loss 0.20028255879878998\n",
      "\n",
      "episode 12, val func loss 0.2122068852186203\n",
      "\n",
      "episode 13, val func loss 0.21855798363685608\n",
      "\n",
      "episode 14, val func loss 0.1633884161710739\n",
      "\n",
      "episode 15, val func loss 0.19169878959655762\n",
      "\n",
      "episode 16, val func loss 0.19805341958999634\n",
      "\n",
      "Val func train loss in epoch 4:0.18841868545860052\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.16091664135456085\n",
      "\n",
      "episode 2, val func loss 0.21955199539661407\n",
      "\n",
      "episode 3, val func loss 0.16291183233261108\n",
      "\n",
      "episode 4, val func loss 0.19853368401527405\n",
      "\n",
      "episode 5, val func loss 0.1937209814786911\n",
      "\n",
      "episode 6, val func loss 0.16196347773075104\n",
      "\n",
      "episode 7, val func loss 0.17162087559700012\n",
      "\n",
      "episode 8, val func loss 0.199545755982399\n",
      "\n",
      "episode 9, val func loss 0.19113588333129883\n",
      "\n",
      "episode 10, val func loss 0.22251377999782562\n",
      "\n",
      "episode 11, val func loss 0.19219763576984406\n",
      "\n",
      "episode 12, val func loss 0.2012457698583603\n",
      "\n",
      "episode 13, val func loss 0.21195727586746216\n",
      "\n",
      "episode 14, val func loss 0.19032080471515656\n",
      "\n",
      "episode 15, val func loss 0.17388346791267395\n",
      "\n",
      "episode 16, val func loss 0.16642582416534424\n",
      "\n",
      "Val func train loss in epoch 5:0.1886528553441167\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19929738342761993\n",
      "\n",
      "episode 2, val func loss 0.19267654418945312\n",
      "\n",
      "episode 3, val func loss 0.19061878323554993\n",
      "\n",
      "episode 4, val func loss 0.16288481652736664\n",
      "\n",
      "episode 5, val func loss 0.19272910058498383\n",
      "\n",
      "episode 6, val func loss 0.20157046616077423\n",
      "\n",
      "episode 7, val func loss 0.1718410700559616\n",
      "\n",
      "episode 8, val func loss 0.19095416367053986\n",
      "\n",
      "episode 9, val func loss 0.16165268421173096\n",
      "\n",
      "episode 10, val func loss 0.19878408312797546\n",
      "\n",
      "episode 11, val func loss 0.1618659645318985\n",
      "\n",
      "episode 12, val func loss 0.2207578867673874\n",
      "\n",
      "episode 13, val func loss 0.1714559942483902\n",
      "\n",
      "episode 14, val func loss 0.2203301340341568\n",
      "\n",
      "episode 15, val func loss 0.16400925815105438\n",
      "\n",
      "episode 16, val func loss 0.21037858724594116\n",
      "\n",
      "Val func train loss in epoch 6:0.188237932510674\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.21566425263881683\n",
      "\n",
      "episode 2, val func loss 0.20134882628917694\n",
      "\n",
      "episode 3, val func loss 0.19404134154319763\n",
      "\n",
      "episode 4, val func loss 0.1669096201658249\n",
      "\n",
      "episode 5, val func loss 0.17461760342121124\n",
      "\n",
      "episode 6, val func loss 0.2116176187992096\n",
      "\n",
      "episode 7, val func loss 0.16168586909770966\n",
      "\n",
      "episode 8, val func loss 0.1617746353149414\n",
      "\n",
      "episode 9, val func loss 0.22472535073757172\n",
      "\n",
      "episode 10, val func loss 0.1724293828010559\n",
      "\n",
      "episode 11, val func loss 0.19767947494983673\n",
      "\n",
      "episode 12, val func loss 0.19290310144424438\n",
      "\n",
      "episode 13, val func loss 0.1903100311756134\n",
      "\n",
      "episode 14, val func loss 0.19809839129447937\n",
      "\n",
      "episode 15, val func loss 0.19368955492973328\n",
      "\n",
      "episode 16, val func loss 0.1624833047389984\n",
      "\n",
      "Val func train loss in epoch 7:0.18874864745885134\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17230185866355896\n",
      "\n",
      "episode 2, val func loss 0.19768540561199188\n",
      "\n",
      "episode 3, val func loss 0.17232707142829895\n",
      "\n",
      "episode 4, val func loss 0.1923360824584961\n",
      "\n",
      "episode 5, val func loss 0.19320957362651825\n",
      "\n",
      "episode 6, val func loss 0.16217195987701416\n",
      "\n",
      "episode 7, val func loss 0.19978664815425873\n",
      "\n",
      "episode 8, val func loss 0.22073663771152496\n",
      "\n",
      "episode 9, val func loss 0.19051577150821686\n",
      "\n",
      "episode 10, val func loss 0.19979655742645264\n",
      "\n",
      "episode 11, val func loss 0.2112499326467514\n",
      "\n",
      "episode 12, val func loss 0.1659308820962906\n",
      "\n",
      "episode 13, val func loss 0.19386596977710724\n",
      "\n",
      "episode 14, val func loss 0.2160913646221161\n",
      "\n",
      "episode 15, val func loss 0.16484692692756653\n",
      "\n",
      "episode 16, val func loss 0.1620001345872879\n",
      "\n",
      "Val func train loss in epoch 8:0.1884282985702157\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.19935008883476257\n",
      "\n",
      "episode 2, val func loss 0.16263075172901154\n",
      "\n",
      "episode 3, val func loss 0.19228358566761017\n",
      "\n",
      "episode 4, val func loss 0.1939036101102829\n",
      "\n",
      "episode 5, val func loss 0.19203588366508484\n",
      "\n",
      "episode 6, val func loss 0.21363110840320587\n",
      "\n",
      "episode 7, val func loss 0.22037626802921295\n",
      "\n",
      "episode 8, val func loss 0.2193748950958252\n",
      "\n",
      "episode 9, val func loss 0.2004820853471756\n",
      "\n",
      "episode 10, val func loss 0.19365713000297546\n",
      "\n",
      "episode 11, val func loss 0.17405365407466888\n",
      "\n",
      "episode 12, val func loss 0.16648413240909576\n",
      "\n",
      "episode 13, val func loss 0.1671886444091797\n",
      "\n",
      "episode 14, val func loss 0.19944718480110168\n",
      "\n",
      "episode 15, val func loss 0.17223140597343445\n",
      "\n",
      "episode 16, val func loss 0.16091986000537872\n",
      "\n",
      "Val func train loss in epoch 9:0.1892531430348754\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1617669016122818\n",
      "\n",
      "episode 2, val func loss 0.19608630239963531\n",
      "\n",
      "episode 3, val func loss 0.19429625570774078\n",
      "\n",
      "episode 4, val func loss 0.20087051391601562\n",
      "\n",
      "episode 5, val func loss 0.19424062967300415\n",
      "\n",
      "episode 6, val func loss 0.21423493325710297\n",
      "\n",
      "episode 7, val func loss 0.16043171286582947\n",
      "\n",
      "episode 8, val func loss 0.1985778659582138\n",
      "\n",
      "episode 9, val func loss 0.17220619320869446\n",
      "\n",
      "episode 10, val func loss 0.16423296928405762\n",
      "\n",
      "episode 11, val func loss 0.1633382886648178\n",
      "\n",
      "episode 12, val func loss 0.21801337599754333\n",
      "\n",
      "episode 13, val func loss 0.20061300694942474\n",
      "\n",
      "episode 14, val func loss 0.218793585896492\n",
      "\n",
      "episode 15, val func loss 0.1731654703617096\n",
      "\n",
      "episode 16, val func loss 0.1924898326396942\n",
      "\n",
      "Val func train loss in epoch 10:0.1889598648995161\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16338998079299927\n",
      "\n",
      "episode 2, val func loss 0.17245303094387054\n",
      "\n",
      "episode 3, val func loss 0.19793465733528137\n",
      "\n",
      "episode 4, val func loss 0.1627190262079239\n",
      "\n",
      "episode 5, val func loss 0.19220928847789764\n",
      "\n",
      "episode 6, val func loss 0.1717570424079895\n",
      "\n",
      "episode 7, val func loss 0.19199238717556\n",
      "\n",
      "episode 8, val func loss 0.19201324880123138\n",
      "\n",
      "episode 9, val func loss 0.19276167452335358\n",
      "\n",
      "episode 10, val func loss 0.21060031652450562\n",
      "\n",
      "episode 11, val func loss 0.16333265602588654\n",
      "\n",
      "episode 12, val func loss 0.2004069685935974\n",
      "\n",
      "episode 13, val func loss 0.2177320122718811\n",
      "\n",
      "episode 14, val func loss 0.19894731044769287\n",
      "\n",
      "episode 15, val func loss 0.21716274321079254\n",
      "\n",
      "episode 16, val func loss 0.16561253368854523\n",
      "\n",
      "Val func train loss in epoch 11:0.18818905483931303\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.20016175508499146\n",
      "\n",
      "episode 2, val func loss 0.19719916582107544\n",
      "\n",
      "episode 3, val func loss 0.1605062037706375\n",
      "\n",
      "episode 4, val func loss 0.16258423030376434\n",
      "\n",
      "episode 5, val func loss 0.15926270186901093\n",
      "\n",
      "episode 6, val func loss 0.1720380336046219\n",
      "\n",
      "episode 7, val func loss 0.21546152234077454\n",
      "\n",
      "episode 8, val func loss 0.1731141209602356\n",
      "\n",
      "episode 9, val func loss 0.15856370329856873\n",
      "\n",
      "episode 10, val func loss 0.19215784966945648\n",
      "\n",
      "episode 11, val func loss 0.20247912406921387\n",
      "\n",
      "episode 12, val func loss 0.19126896560192108\n",
      "\n",
      "episode 13, val func loss 0.21585845947265625\n",
      "\n",
      "episode 14, val func loss 0.1966525763273239\n",
      "\n",
      "episode 15, val func loss 0.19196735322475433\n",
      "\n",
      "episode 16, val func loss 0.2194080352783203\n",
      "\n",
      "Val func train loss in epoch 12:0.18804273754358292\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.2174907773733139\n",
      "\n",
      "episode 2, val func loss 0.19476518034934998\n",
      "\n",
      "episode 3, val func loss 0.19050972163677216\n",
      "\n",
      "episode 4, val func loss 0.2009585201740265\n",
      "\n",
      "episode 5, val func loss 0.16218645870685577\n",
      "\n",
      "episode 6, val func loss 0.1630438268184662\n",
      "\n",
      "episode 7, val func loss 0.2204013466835022\n",
      "\n",
      "episode 8, val func loss 0.17054957151412964\n",
      "\n",
      "episode 9, val func loss 0.19223779439926147\n",
      "\n",
      "episode 10, val func loss 0.19890756905078888\n",
      "\n",
      "episode 11, val func loss 0.17299284040927887\n",
      "\n",
      "episode 12, val func loss 0.19940219819545746\n",
      "\n",
      "episode 13, val func loss 0.16047896444797516\n",
      "\n",
      "episode 14, val func loss 0.16245722770690918\n",
      "\n",
      "episode 15, val func loss 0.21295931935310364\n",
      "\n",
      "episode 16, val func loss 0.19087651371955872\n",
      "\n",
      "Val func train loss in epoch 13:0.18813861440867186\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.16020675003528595\n",
      "\n",
      "episode 2, val func loss 0.17173756659030914\n",
      "\n",
      "episode 3, val func loss 0.201315775513649\n",
      "\n",
      "episode 4, val func loss 0.19316764175891876\n",
      "\n",
      "episode 5, val func loss 0.16238991916179657\n",
      "\n",
      "episode 6, val func loss 0.21953164041042328\n",
      "\n",
      "episode 7, val func loss 0.19759593904018402\n",
      "\n",
      "episode 8, val func loss 0.19148100912570953\n",
      "\n",
      "episode 9, val func loss 0.16563434898853302\n",
      "\n",
      "episode 10, val func loss 0.192207470536232\n",
      "\n",
      "episode 11, val func loss 0.21742789447307587\n",
      "\n",
      "episode 12, val func loss 0.17171138525009155\n",
      "\n",
      "episode 13, val func loss 0.19857224822044373\n",
      "\n",
      "episode 14, val func loss 0.2125539779663086\n",
      "\n",
      "episode 15, val func loss 0.1627749353647232\n",
      "\n",
      "episode 16, val func loss 0.1914694905281067\n",
      "\n",
      "Val func train loss in epoch 14:0.18811112456023693\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19035041332244873\n",
      "\n",
      "episode 2, val func loss 0.21326152980327606\n",
      "\n",
      "episode 3, val func loss 0.20254464447498322\n",
      "\n",
      "episode 4, val func loss 0.19185970723628998\n",
      "\n",
      "episode 5, val func loss 0.19021469354629517\n",
      "\n",
      "episode 6, val func loss 0.19907246530056\n",
      "\n",
      "episode 7, val func loss 0.2145663946866989\n",
      "\n",
      "episode 8, val func loss 0.1918972283601761\n",
      "\n",
      "episode 9, val func loss 0.16589213907718658\n",
      "\n",
      "episode 10, val func loss 0.17260682582855225\n",
      "\n",
      "episode 11, val func loss 0.17154672741889954\n",
      "\n",
      "episode 12, val func loss 0.1623246669769287\n",
      "\n",
      "episode 13, val func loss 0.19596906006336212\n",
      "\n",
      "episode 14, val func loss 0.16164889931678772\n",
      "\n",
      "episode 15, val func loss 0.22614532709121704\n",
      "\n",
      "episode 16, val func loss 0.15936274826526642\n",
      "\n",
      "Val func train loss in epoch 15:0.18807896692305803\n",
      "***********************TIME WAS 4.934133005142212 min*****************************\n",
      "\n",
      "**********************ROUND 67 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.06576685607433319\n",
      "\n",
      "episode 2, policy loss 0.02393621765077114\n",
      "\n",
      "episode 3, policy loss -0.02212996780872345\n",
      "\n",
      "episode 4, policy loss -0.07122548669576645\n",
      "\n",
      "episode 5, policy loss -0.010059257037937641\n",
      "\n",
      "episode 6, policy loss -0.004312033765017986\n",
      "\n",
      "episode 7, policy loss 0.011241014115512371\n",
      "\n",
      "episode 8, policy loss -0.028767673298716545\n",
      "\n",
      "episode 9, policy loss 0.009911766275763512\n",
      "\n",
      "episode 10, policy loss -0.024955997243523598\n",
      "\n",
      "episode 11, policy loss -0.03905731067061424\n",
      "\n",
      "episode 12, policy loss -0.020713701844215393\n",
      "\n",
      "episode 13, policy loss -0.013963366858661175\n",
      "\n",
      "episode 14, policy loss -0.04053542762994766\n",
      "\n",
      "episode 15, policy loss -0.08020636439323425\n",
      "\n",
      "episode 16, policy loss -0.00911008846014738\n",
      "\n",
      "Policy train loss in epoch 0:-0.024107158358674496\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.023680590093135834\n",
      "\n",
      "episode 2, policy loss -0.01973799616098404\n",
      "\n",
      "episode 3, policy loss -0.0060317181050777435\n",
      "\n",
      "episode 4, policy loss 0.009673994965851307\n",
      "\n",
      "episode 5, policy loss -0.07207538187503815\n",
      "\n",
      "episode 6, policy loss -0.042419418692588806\n",
      "\n",
      "episode 7, policy loss 0.008282812312245369\n",
      "\n",
      "episode 8, policy loss -0.08146538585424423\n",
      "\n",
      "episode 9, policy loss -0.014561628922820091\n",
      "\n",
      "episode 10, policy loss -0.03196223825216293\n",
      "\n",
      "episode 11, policy loss -0.0266309455037117\n",
      "\n",
      "episode 12, policy loss -0.010169636458158493\n",
      "\n",
      "episode 13, policy loss 0.01961132511496544\n",
      "\n",
      "episode 14, policy loss -0.009372258558869362\n",
      "\n",
      "episode 15, policy loss -0.0390113890171051\n",
      "\n",
      "episode 16, policy loss -0.07303114235401154\n",
      "\n",
      "Policy train loss in epoch 1:-0.02578634984092787\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.042052529752254486\n",
      "\n",
      "episode 2, policy loss 0.007482458371669054\n",
      "\n",
      "episode 3, policy loss -0.08207112550735474\n",
      "\n",
      "episode 4, policy loss -0.03887366130948067\n",
      "\n",
      "episode 5, policy loss -0.020982913672924042\n",
      "\n",
      "episode 6, policy loss -0.008422988466918468\n",
      "\n",
      "episode 7, policy loss -0.024299710988998413\n",
      "\n",
      "episode 8, policy loss -0.07296574860811234\n",
      "\n",
      "episode 9, policy loss -0.03168084844946861\n",
      "\n",
      "episode 10, policy loss -0.011268781498074532\n",
      "\n",
      "episode 11, policy loss 0.018999334424734116\n",
      "\n",
      "episode 12, policy loss 0.0082709277048707\n",
      "\n",
      "episode 13, policy loss -0.009715073741972446\n",
      "\n",
      "episode 14, policy loss -0.02587888017296791\n",
      "\n",
      "episode 15, policy loss -0.015552714467048645\n",
      "\n",
      "episode 16, policy loss -0.0733800157904625\n",
      "\n",
      "Policy train loss in epoch 2:-0.026399516995297745\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.03182048350572586\n",
      "\n",
      "episode 2, policy loss -0.02435959130525589\n",
      "\n",
      "episode 3, policy loss -0.03968210518360138\n",
      "\n",
      "episode 4, policy loss -0.04218868538737297\n",
      "\n",
      "episode 5, policy loss -0.021401599049568176\n",
      "\n",
      "episode 6, policy loss -0.010668440721929073\n",
      "\n",
      "episode 7, policy loss -0.08198835700750351\n",
      "\n",
      "episode 8, policy loss -0.025942742824554443\n",
      "\n",
      "episode 9, policy loss -0.008998761884868145\n",
      "\n",
      "episode 10, policy loss -0.015824446454644203\n",
      "\n",
      "episode 11, policy loss -0.07275762408971786\n",
      "\n",
      "episode 12, policy loss 0.01989528350532055\n",
      "\n",
      "episode 13, policy loss 0.00965789146721363\n",
      "\n",
      "episode 14, policy loss -0.005276992917060852\n",
      "\n",
      "episode 15, policy loss 0.008997490629553795\n",
      "\n",
      "episode 16, policy loss -0.07164867222309113\n",
      "\n",
      "Policy train loss in epoch 3:-0.025875489809550345\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19148121774196625\n",
      "\n",
      "episode 2, val func loss 0.1648615598678589\n",
      "\n",
      "episode 3, val func loss 0.180993914604187\n",
      "\n",
      "episode 4, val func loss 0.19177445769309998\n",
      "\n",
      "episode 5, val func loss 0.19438481330871582\n",
      "\n",
      "episode 6, val func loss 0.20144234597682953\n",
      "\n",
      "episode 7, val func loss 0.18045291304588318\n",
      "\n",
      "episode 8, val func loss 0.19427287578582764\n",
      "\n",
      "episode 9, val func loss 0.19371114671230316\n",
      "\n",
      "episode 10, val func loss 0.18351134657859802\n",
      "\n",
      "episode 11, val func loss 0.19715791940689087\n",
      "\n",
      "episode 12, val func loss 0.22258149087429047\n",
      "\n",
      "episode 13, val func loss 0.2305222600698471\n",
      "\n",
      "episode 14, val func loss 0.20501655340194702\n",
      "\n",
      "episode 15, val func loss 0.19665442407131195\n",
      "\n",
      "episode 16, val func loss 0.19777439534664154\n",
      "\n",
      "Val func train loss in epoch 0:0.1954121021553874\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19760704040527344\n",
      "\n",
      "episode 2, val func loss 0.1940794438123703\n",
      "\n",
      "episode 3, val func loss 0.20565444231033325\n",
      "\n",
      "episode 4, val func loss 0.20304079353809357\n",
      "\n",
      "episode 5, val func loss 0.20046016573905945\n",
      "\n",
      "episode 6, val func loss 0.18751126527786255\n",
      "\n",
      "episode 7, val func loss 0.1846574991941452\n",
      "\n",
      "episode 8, val func loss 0.18472695350646973\n",
      "\n",
      "episode 9, val func loss 0.19706963002681732\n",
      "\n",
      "episode 10, val func loss 0.19796226918697357\n",
      "\n",
      "episode 11, val func loss 0.2254054695367813\n",
      "\n",
      "episode 12, val func loss 0.2317487895488739\n",
      "\n",
      "episode 13, val func loss 0.20192807912826538\n",
      "\n",
      "episode 14, val func loss 0.1666908860206604\n",
      "\n",
      "episode 15, val func loss 0.1765519082546234\n",
      "\n",
      "episode 16, val func loss 0.18900622427463531\n",
      "\n",
      "Val func train loss in epoch 1:0.19650630373507738\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18227362632751465\n",
      "\n",
      "episode 2, val func loss 0.20533306896686554\n",
      "\n",
      "episode 3, val func loss 0.16541017591953278\n",
      "\n",
      "episode 4, val func loss 0.20391832292079926\n",
      "\n",
      "episode 5, val func loss 0.23145686089992523\n",
      "\n",
      "episode 6, val func loss 0.19644853472709656\n",
      "\n",
      "episode 7, val func loss 0.19814056158065796\n",
      "\n",
      "episode 8, val func loss 0.19249194860458374\n",
      "\n",
      "episode 9, val func loss 0.2235921025276184\n",
      "\n",
      "episode 10, val func loss 0.18766893446445465\n",
      "\n",
      "episode 11, val func loss 0.186313658952713\n",
      "\n",
      "episode 12, val func loss 0.18560633063316345\n",
      "\n",
      "episode 13, val func loss 0.17895209789276123\n",
      "\n",
      "episode 14, val func loss 0.19617652893066406\n",
      "\n",
      "episode 15, val func loss 0.2017681747674942\n",
      "\n",
      "episode 16, val func loss 0.20157785713672638\n",
      "\n",
      "Val func train loss in epoch 2:0.1960705490782857\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.2261892855167389\n",
      "\n",
      "episode 2, val func loss 0.19755616784095764\n",
      "\n",
      "episode 3, val func loss 0.19814907014369965\n",
      "\n",
      "episode 4, val func loss 0.20178347826004028\n",
      "\n",
      "episode 5, val func loss 0.23003284633159637\n",
      "\n",
      "episode 6, val func loss 0.1985616236925125\n",
      "\n",
      "episode 7, val func loss 0.18465055525302887\n",
      "\n",
      "episode 8, val func loss 0.18282225728034973\n",
      "\n",
      "episode 9, val func loss 0.2024349570274353\n",
      "\n",
      "episode 10, val func loss 0.1977706402540207\n",
      "\n",
      "episode 11, val func loss 0.19281022250652313\n",
      "\n",
      "episode 12, val func loss 0.17578546702861786\n",
      "\n",
      "episode 13, val func loss 0.20525400340557098\n",
      "\n",
      "episode 14, val func loss 0.1893022358417511\n",
      "\n",
      "episode 15, val func loss 0.16557636857032776\n",
      "\n",
      "episode 16, val func loss 0.18960775434970856\n",
      "\n",
      "Val func train loss in epoch 3:0.19614293333142996\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19228069484233856\n",
      "\n",
      "episode 2, val func loss 0.1817864179611206\n",
      "\n",
      "episode 3, val func loss 0.1978578120470047\n",
      "\n",
      "episode 4, val func loss 0.1656966507434845\n",
      "\n",
      "episode 5, val func loss 0.1873958855867386\n",
      "\n",
      "episode 6, val func loss 0.20336399972438812\n",
      "\n",
      "episode 7, val func loss 0.20139344036579132\n",
      "\n",
      "episode 8, val func loss 0.17794294655323029\n",
      "\n",
      "episode 9, val func loss 0.20381633937358856\n",
      "\n",
      "episode 10, val func loss 0.18915455043315887\n",
      "\n",
      "episode 11, val func loss 0.19637790322303772\n",
      "\n",
      "episode 12, val func loss 0.23242859542369843\n",
      "\n",
      "episode 13, val func loss 0.22539159655570984\n",
      "\n",
      "episode 14, val func loss 0.18412204086780548\n",
      "\n",
      "episode 15, val func loss 0.1959693729877472\n",
      "\n",
      "episode 16, val func loss 0.1975366175174713\n",
      "\n",
      "Val func train loss in epoch 4:0.19578217901289463\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.20506395399570465\n",
      "\n",
      "episode 2, val func loss 0.18967750668525696\n",
      "\n",
      "episode 3, val func loss 0.19725646078586578\n",
      "\n",
      "episode 4, val func loss 0.178057461977005\n",
      "\n",
      "episode 5, val func loss 0.22572870552539825\n",
      "\n",
      "episode 6, val func loss 0.19191639125347137\n",
      "\n",
      "episode 7, val func loss 0.20176199078559875\n",
      "\n",
      "episode 8, val func loss 0.20510615408420563\n",
      "\n",
      "episode 9, val func loss 0.20000188052654266\n",
      "\n",
      "episode 10, val func loss 0.18264275789260864\n",
      "\n",
      "episode 11, val func loss 0.18140909075737\n",
      "\n",
      "episode 12, val func loss 0.1668393611907959\n",
      "\n",
      "episode 13, val func loss 0.22896724939346313\n",
      "\n",
      "episode 14, val func loss 0.19770652055740356\n",
      "\n",
      "episode 15, val func loss 0.19648820161819458\n",
      "\n",
      "episode 16, val func loss 0.18707846105098724\n",
      "\n",
      "Val func train loss in epoch 5:0.195981384254992\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19083386659622192\n",
      "\n",
      "episode 2, val func loss 0.18072862923145294\n",
      "\n",
      "episode 3, val func loss 0.1970786303281784\n",
      "\n",
      "episode 4, val func loss 0.2055223137140274\n",
      "\n",
      "episode 5, val func loss 0.2295691967010498\n",
      "\n",
      "episode 6, val func loss 0.1738271266222\n",
      "\n",
      "episode 7, val func loss 0.22640585899353027\n",
      "\n",
      "episode 8, val func loss 0.18107058107852936\n",
      "\n",
      "episode 9, val func loss 0.1899215131998062\n",
      "\n",
      "episode 10, val func loss 0.2052992582321167\n",
      "\n",
      "episode 11, val func loss 0.1951601207256317\n",
      "\n",
      "episode 12, val func loss 0.19956433773040771\n",
      "\n",
      "episode 13, val func loss 0.19698837399482727\n",
      "\n",
      "episode 14, val func loss 0.16779428720474243\n",
      "\n",
      "episode 15, val func loss 0.2037249505519867\n",
      "\n",
      "episode 16, val func loss 0.18418638408184052\n",
      "\n",
      "Val func train loss in epoch 6:0.19547971431165934\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17938952147960663\n",
      "\n",
      "episode 2, val func loss 0.187234029173851\n",
      "\n",
      "episode 3, val func loss 0.1933080106973648\n",
      "\n",
      "episode 4, val func loss 0.1958821415901184\n",
      "\n",
      "episode 5, val func loss 0.22800470888614655\n",
      "\n",
      "episode 6, val func loss 0.20194365084171295\n",
      "\n",
      "episode 7, val func loss 0.1999141126871109\n",
      "\n",
      "episode 8, val func loss 0.16632665693759918\n",
      "\n",
      "episode 9, val func loss 0.2035714089870453\n",
      "\n",
      "episode 10, val func loss 0.19863536953926086\n",
      "\n",
      "episode 11, val func loss 0.2047661542892456\n",
      "\n",
      "episode 12, val func loss 0.18910212814807892\n",
      "\n",
      "episode 13, val func loss 0.18494722247123718\n",
      "\n",
      "episode 14, val func loss 0.23117467761039734\n",
      "\n",
      "episode 15, val func loss 0.19754524528980255\n",
      "\n",
      "episode 16, val func loss 0.1824534833431244\n",
      "\n",
      "Val func train loss in epoch 7:0.1965124076232314\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.2262158989906311\n",
      "\n",
      "episode 2, val func loss 0.17675122618675232\n",
      "\n",
      "episode 3, val func loss 0.23266567289829254\n",
      "\n",
      "episode 4, val func loss 0.18230372667312622\n",
      "\n",
      "episode 5, val func loss 0.20276828110218048\n",
      "\n",
      "episode 6, val func loss 0.19633173942565918\n",
      "\n",
      "episode 7, val func loss 0.19646058976650238\n",
      "\n",
      "episode 8, val func loss 0.1659003347158432\n",
      "\n",
      "episode 9, val func loss 0.18753081560134888\n",
      "\n",
      "episode 10, val func loss 0.19783300161361694\n",
      "\n",
      "episode 11, val func loss 0.18204089999198914\n",
      "\n",
      "episode 12, val func loss 0.19856694340705872\n",
      "\n",
      "episode 13, val func loss 0.20403356850147247\n",
      "\n",
      "episode 14, val func loss 0.1891031712293625\n",
      "\n",
      "episode 15, val func loss 0.19389799237251282\n",
      "\n",
      "episode 16, val func loss 0.2031472772359848\n",
      "\n",
      "Val func train loss in epoch 8:0.19597194623202085\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20010919868946075\n",
      "\n",
      "episode 2, val func loss 0.22478240728378296\n",
      "\n",
      "episode 3, val func loss 0.19771292805671692\n",
      "\n",
      "episode 4, val func loss 0.18684810400009155\n",
      "\n",
      "episode 5, val func loss 0.19329869747161865\n",
      "\n",
      "episode 6, val func loss 0.20431236922740936\n",
      "\n",
      "episode 7, val func loss 0.20241045951843262\n",
      "\n",
      "episode 8, val func loss 0.20468582212924957\n",
      "\n",
      "episode 9, val func loss 0.16569963097572327\n",
      "\n",
      "episode 10, val func loss 0.19643796980381012\n",
      "\n",
      "episode 11, val func loss 0.18955540657043457\n",
      "\n",
      "episode 12, val func loss 0.18209853768348694\n",
      "\n",
      "episode 13, val func loss 0.18234670162200928\n",
      "\n",
      "episode 14, val func loss 0.1988816112279892\n",
      "\n",
      "episode 15, val func loss 0.1772359311580658\n",
      "\n",
      "episode 16, val func loss 0.23174814879894257\n",
      "\n",
      "Val func train loss in epoch 9:0.1961352452635765\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18315079808235168\n",
      "\n",
      "episode 2, val func loss 0.20254471898078918\n",
      "\n",
      "episode 3, val func loss 0.1865014284849167\n",
      "\n",
      "episode 4, val func loss 0.2312314510345459\n",
      "\n",
      "episode 5, val func loss 0.1666116863489151\n",
      "\n",
      "episode 6, val func loss 0.18247880041599274\n",
      "\n",
      "episode 7, val func loss 0.22539806365966797\n",
      "\n",
      "episode 8, val func loss 0.19686448574066162\n",
      "\n",
      "episode 9, val func loss 0.19777095317840576\n",
      "\n",
      "episode 10, val func loss 0.20463970303535461\n",
      "\n",
      "episode 11, val func loss 0.17630286514759064\n",
      "\n",
      "episode 12, val func loss 0.18881358206272125\n",
      "\n",
      "episode 13, val func loss 0.2049504965543747\n",
      "\n",
      "episode 14, val func loss 0.20068210363388062\n",
      "\n",
      "episode 15, val func loss 0.19730520248413086\n",
      "\n",
      "episode 16, val func loss 0.19157661497592926\n",
      "\n",
      "Val func train loss in epoch 10:0.19605143461376429\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16758346557617188\n",
      "\n",
      "episode 2, val func loss 0.23094043135643005\n",
      "\n",
      "episode 3, val func loss 0.19911988079547882\n",
      "\n",
      "episode 4, val func loss 0.20422928035259247\n",
      "\n",
      "episode 5, val func loss 0.19752100110054016\n",
      "\n",
      "episode 6, val func loss 0.19892410933971405\n",
      "\n",
      "episode 7, val func loss 0.1825779229402542\n",
      "\n",
      "episode 8, val func loss 0.18870574235916138\n",
      "\n",
      "episode 9, val func loss 0.2020643949508667\n",
      "\n",
      "episode 10, val func loss 0.17669272422790527\n",
      "\n",
      "episode 11, val func loss 0.20520073175430298\n",
      "\n",
      "episode 12, val func loss 0.18186527490615845\n",
      "\n",
      "episode 13, val func loss 0.1964973360300064\n",
      "\n",
      "episode 14, val func loss 0.19271427392959595\n",
      "\n",
      "episode 15, val func loss 0.18757189810276031\n",
      "\n",
      "episode 16, val func loss 0.2265317738056183\n",
      "\n",
      "Val func train loss in epoch 11:0.19617126509547234\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19663619995117188\n",
      "\n",
      "episode 2, val func loss 0.20243464410305023\n",
      "\n",
      "episode 3, val func loss 0.1886235624551773\n",
      "\n",
      "episode 4, val func loss 0.18330365419387817\n",
      "\n",
      "episode 5, val func loss 0.1869470775127411\n",
      "\n",
      "episode 6, val func loss 0.1825455129146576\n",
      "\n",
      "episode 7, val func loss 0.1987004578113556\n",
      "\n",
      "episode 8, val func loss 0.22576971352100372\n",
      "\n",
      "episode 9, val func loss 0.20407035946846008\n",
      "\n",
      "episode 10, val func loss 0.17760378122329712\n",
      "\n",
      "episode 11, val func loss 0.19777335226535797\n",
      "\n",
      "episode 12, val func loss 0.16630205512046814\n",
      "\n",
      "episode 13, val func loss 0.20432767271995544\n",
      "\n",
      "episode 14, val func loss 0.19721052050590515\n",
      "\n",
      "episode 15, val func loss 0.23190940916538239\n",
      "\n",
      "episode 16, val func loss 0.19312241673469543\n",
      "\n",
      "Val func train loss in epoch 12:0.19608002435415983\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.20245599746704102\n",
      "\n",
      "episode 2, val func loss 0.19655437767505646\n",
      "\n",
      "episode 3, val func loss 0.1926141083240509\n",
      "\n",
      "episode 4, val func loss 0.1982964277267456\n",
      "\n",
      "episode 5, val func loss 0.20477385818958282\n",
      "\n",
      "episode 6, val func loss 0.22719185054302216\n",
      "\n",
      "episode 7, val func loss 0.1762135624885559\n",
      "\n",
      "episode 8, val func loss 0.20467236638069153\n",
      "\n",
      "episode 9, val func loss 0.18264319002628326\n",
      "\n",
      "episode 10, val func loss 0.1967327892780304\n",
      "\n",
      "episode 11, val func loss 0.18830257654190063\n",
      "\n",
      "episode 12, val func loss 0.23139588534832\n",
      "\n",
      "episode 13, val func loss 0.1973414421081543\n",
      "\n",
      "episode 14, val func loss 0.18687140941619873\n",
      "\n",
      "episode 15, val func loss 0.18380196392536163\n",
      "\n",
      "episode 16, val func loss 0.16845668852329254\n",
      "\n",
      "Val func train loss in epoch 13:0.196144905872643\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.20321325957775116\n",
      "\n",
      "episode 2, val func loss 0.19342246651649475\n",
      "\n",
      "episode 3, val func loss 0.19680701196193695\n",
      "\n",
      "episode 4, val func loss 0.2262275516986847\n",
      "\n",
      "episode 5, val func loss 0.19645829498767853\n",
      "\n",
      "episode 6, val func loss 0.1755879521369934\n",
      "\n",
      "episode 7, val func loss 0.19055794179439545\n",
      "\n",
      "episode 8, val func loss 0.20253653824329376\n",
      "\n",
      "episode 9, val func loss 0.19807355105876923\n",
      "\n",
      "episode 10, val func loss 0.18224187195301056\n",
      "\n",
      "episode 11, val func loss 0.23185908794403076\n",
      "\n",
      "episode 12, val func loss 0.20376716554164886\n",
      "\n",
      "episode 13, val func loss 0.16874337196350098\n",
      "\n",
      "episode 14, val func loss 0.2052823156118393\n",
      "\n",
      "episode 15, val func loss 0.18699641525745392\n",
      "\n",
      "episode 16, val func loss 0.18392783403396606\n",
      "\n",
      "Val func train loss in epoch 14:0.19660641439259052\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19706270098686218\n",
      "\n",
      "episode 2, val func loss 0.19652141630649567\n",
      "\n",
      "episode 3, val func loss 0.18231819570064545\n",
      "\n",
      "episode 4, val func loss 0.1996840238571167\n",
      "\n",
      "episode 5, val func loss 0.17489875853061676\n",
      "\n",
      "episode 6, val func loss 0.19160401821136475\n",
      "\n",
      "episode 7, val func loss 0.20230376720428467\n",
      "\n",
      "episode 8, val func loss 0.2270965278148651\n",
      "\n",
      "episode 9, val func loss 0.1829996556043625\n",
      "\n",
      "episode 10, val func loss 0.2039097547531128\n",
      "\n",
      "episode 11, val func loss 0.16858729720115662\n",
      "\n",
      "episode 12, val func loss 0.20450665056705475\n",
      "\n",
      "episode 13, val func loss 0.19304831326007843\n",
      "\n",
      "episode 14, val func loss 0.1870945692062378\n",
      "\n",
      "episode 15, val func loss 0.23166823387145996\n",
      "\n",
      "episode 16, val func loss 0.19774827361106873\n",
      "\n",
      "Val func train loss in epoch 15:0.19631575979292393\n",
      "***********************TIME WAS 4.941734496752421 min*****************************\n",
      "\n",
      "**********************ROUND 68 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.013655856251716614\n",
      "\n",
      "episode 2, policy loss -0.043298523873090744\n",
      "\n",
      "episode 3, policy loss 0.034621354192495346\n",
      "\n",
      "episode 4, policy loss 0.019544538110494614\n",
      "\n",
      "episode 5, policy loss 0.007594279944896698\n",
      "\n",
      "episode 6, policy loss -0.025893403217196465\n",
      "\n",
      "episode 7, policy loss 0.004562137648463249\n",
      "\n",
      "episode 8, policy loss -0.015453825704753399\n",
      "\n",
      "episode 9, policy loss 0.006715333554893732\n",
      "\n",
      "episode 10, policy loss -0.04427207633852959\n",
      "\n",
      "episode 11, policy loss -0.02250596322119236\n",
      "\n",
      "episode 12, policy loss -0.045731596648693085\n",
      "\n",
      "episode 13, policy loss -0.003585435915738344\n",
      "\n",
      "episode 14, policy loss 0.03657899424433708\n",
      "\n",
      "episode 15, policy loss 0.01216813549399376\n",
      "\n",
      "episode 16, policy loss -0.04153855890035629\n",
      "\n",
      "Policy train loss in epoch 0:-0.006677422148641199\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.04305535927414894\n",
      "\n",
      "episode 2, policy loss 0.018356073647737503\n",
      "\n",
      "episode 3, policy loss -0.042005520313978195\n",
      "\n",
      "episode 4, policy loss -0.02702924609184265\n",
      "\n",
      "episode 5, policy loss 0.003086859593167901\n",
      "\n",
      "episode 6, policy loss 0.004933068994432688\n",
      "\n",
      "episode 7, policy loss 0.03628300130367279\n",
      "\n",
      "episode 8, policy loss -0.04876675084233284\n",
      "\n",
      "episode 9, policy loss 0.014544001780450344\n",
      "\n",
      "episode 10, policy loss -0.04702575504779816\n",
      "\n",
      "episode 11, policy loss -0.026968924328684807\n",
      "\n",
      "episode 12, policy loss -0.004334829282015562\n",
      "\n",
      "episode 13, policy loss 0.006837863940745592\n",
      "\n",
      "episode 14, policy loss -0.020318301394581795\n",
      "\n",
      "episode 15, policy loss 0.009359431453049183\n",
      "\n",
      "episode 16, policy loss 0.030805271118879318\n",
      "\n",
      "Policy train loss in epoch 1:-0.008456194671452977\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.009093712083995342\n",
      "\n",
      "episode 2, policy loss 0.002382449107244611\n",
      "\n",
      "episode 3, policy loss -0.030223025009036064\n",
      "\n",
      "episode 4, policy loss 0.008401411585509777\n",
      "\n",
      "episode 5, policy loss -0.021837729960680008\n",
      "\n",
      "episode 6, policy loss -0.0030528968200087547\n",
      "\n",
      "episode 7, policy loss -0.04964154213666916\n",
      "\n",
      "episode 8, policy loss 0.019255252555012703\n",
      "\n",
      "episode 9, policy loss 0.009127778932452202\n",
      "\n",
      "episode 10, policy loss -0.04453960806131363\n",
      "\n",
      "episode 11, policy loss 0.03753636032342911\n",
      "\n",
      "episode 12, policy loss -0.0446755476295948\n",
      "\n",
      "episode 13, policy loss 0.029155908152461052\n",
      "\n",
      "episode 14, policy loss -0.024622488766908646\n",
      "\n",
      "episode 15, policy loss -0.04732384532690048\n",
      "\n",
      "episode 16, policy loss 0.005093507468700409\n",
      "\n",
      "Policy train loss in epoch 2:-0.009116893968894146\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.020823318511247635\n",
      "\n",
      "episode 2, policy loss 0.0064591593109071255\n",
      "\n",
      "episode 3, policy loss -0.046285904943943024\n",
      "\n",
      "episode 4, policy loss 0.011073091998696327\n",
      "\n",
      "episode 5, policy loss -0.04428096115589142\n",
      "\n",
      "episode 6, policy loss -0.004492748528718948\n",
      "\n",
      "episode 7, policy loss 0.036471541970968246\n",
      "\n",
      "episode 8, policy loss 0.03030385822057724\n",
      "\n",
      "episode 9, policy loss 0.0017920266836881638\n",
      "\n",
      "episode 10, policy loss -0.04794609919190407\n",
      "\n",
      "episode 11, policy loss -0.026067091152071953\n",
      "\n",
      "episode 12, policy loss 0.017156964167952538\n",
      "\n",
      "episode 13, policy loss 0.004993819631636143\n",
      "\n",
      "episode 14, policy loss -0.049257565289735794\n",
      "\n",
      "episode 15, policy loss 0.008691301569342613\n",
      "\n",
      "episode 16, policy loss -0.02711491473019123\n",
      "\n",
      "Policy train loss in epoch 3:-0.00933292749687098\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.16509167850017548\n",
      "\n",
      "episode 2, val func loss 0.16060951352119446\n",
      "\n",
      "episode 3, val func loss 0.1866021752357483\n",
      "\n",
      "episode 4, val func loss 0.1787501722574234\n",
      "\n",
      "episode 5, val func loss 0.19990994036197662\n",
      "\n",
      "episode 6, val func loss 0.1651453971862793\n",
      "\n",
      "episode 7, val func loss 0.17343251407146454\n",
      "\n",
      "episode 8, val func loss 0.1934630125761032\n",
      "\n",
      "episode 9, val func loss 0.19195307791233063\n",
      "\n",
      "episode 10, val func loss 0.19553110003471375\n",
      "\n",
      "episode 11, val func loss 0.17568136751651764\n",
      "\n",
      "episode 12, val func loss 0.18722310662269592\n",
      "\n",
      "episode 13, val func loss 0.21520324051380157\n",
      "\n",
      "episode 14, val func loss 0.19367755949497223\n",
      "\n",
      "episode 15, val func loss 0.20498347282409668\n",
      "\n",
      "episode 16, val func loss 0.18910416960716248\n",
      "\n",
      "Val func train loss in epoch 0:0.186022593639791\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.20266172289848328\n",
      "\n",
      "episode 2, val func loss 0.18936705589294434\n",
      "\n",
      "episode 3, val func loss 0.16323956847190857\n",
      "\n",
      "episode 4, val func loss 0.1951802372932434\n",
      "\n",
      "episode 5, val func loss 0.1736346334218979\n",
      "\n",
      "episode 6, val func loss 0.2172657698392868\n",
      "\n",
      "episode 7, val func loss 0.1652645319700241\n",
      "\n",
      "episode 8, val func loss 0.19879090785980225\n",
      "\n",
      "episode 9, val func loss 0.17563362419605255\n",
      "\n",
      "episode 10, val func loss 0.1946890950202942\n",
      "\n",
      "episode 11, val func loss 0.1867804080247879\n",
      "\n",
      "episode 12, val func loss 0.18796221911907196\n",
      "\n",
      "episode 13, val func loss 0.19574233889579773\n",
      "\n",
      "episode 14, val func loss 0.16646796464920044\n",
      "\n",
      "episode 15, val func loss 0.19394397735595703\n",
      "\n",
      "episode 16, val func loss 0.17920701205730438\n",
      "\n",
      "Val func train loss in epoch 1:0.18661444168537855\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18729433417320251\n",
      "\n",
      "episode 2, val func loss 0.18541975319385529\n",
      "\n",
      "episode 3, val func loss 0.1996515542268753\n",
      "\n",
      "episode 4, val func loss 0.1652459353208542\n",
      "\n",
      "episode 5, val func loss 0.1614210307598114\n",
      "\n",
      "episode 6, val func loss 0.19353348016738892\n",
      "\n",
      "episode 7, val func loss 0.1756504327058792\n",
      "\n",
      "episode 8, val func loss 0.19660036265850067\n",
      "\n",
      "episode 9, val func loss 0.17823489010334015\n",
      "\n",
      "episode 10, val func loss 0.19381427764892578\n",
      "\n",
      "episode 11, val func loss 0.1869773119688034\n",
      "\n",
      "episode 12, val func loss 0.16033484041690826\n",
      "\n",
      "episode 13, val func loss 0.1929207146167755\n",
      "\n",
      "episode 14, val func loss 0.17360110580921173\n",
      "\n",
      "episode 15, val func loss 0.20518742501735687\n",
      "\n",
      "episode 16, val func loss 0.21375247836112976\n",
      "\n",
      "Val func train loss in epoch 2:0.18560249544680119\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.16287554800510406\n",
      "\n",
      "episode 2, val func loss 0.19782821834087372\n",
      "\n",
      "episode 3, val func loss 0.20311732590198517\n",
      "\n",
      "episode 4, val func loss 0.18752293288707733\n",
      "\n",
      "episode 5, val func loss 0.16029180586338043\n",
      "\n",
      "episode 6, val func loss 0.19343194365501404\n",
      "\n",
      "episode 7, val func loss 0.19360105693340302\n",
      "\n",
      "episode 8, val func loss 0.1879921406507492\n",
      "\n",
      "episode 9, val func loss 0.2118806391954422\n",
      "\n",
      "episode 10, val func loss 0.19355137646198273\n",
      "\n",
      "episode 11, val func loss 0.16532941162586212\n",
      "\n",
      "episode 12, val func loss 0.19300979375839233\n",
      "\n",
      "episode 13, val func loss 0.17430393397808075\n",
      "\n",
      "episode 14, val func loss 0.1777360439300537\n",
      "\n",
      "episode 15, val func loss 0.17543384432792664\n",
      "\n",
      "episode 16, val func loss 0.18609720468521118\n",
      "\n",
      "Val func train loss in epoch 3:0.18525020126253366\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1843220293521881\n",
      "\n",
      "episode 2, val func loss 0.17645788192749023\n",
      "\n",
      "episode 3, val func loss 0.218418151140213\n",
      "\n",
      "episode 4, val func loss 0.19271208345890045\n",
      "\n",
      "episode 5, val func loss 0.1936274617910385\n",
      "\n",
      "episode 6, val func loss 0.1806744933128357\n",
      "\n",
      "episode 7, val func loss 0.187627375125885\n",
      "\n",
      "episode 8, val func loss 0.18712832033634186\n",
      "\n",
      "episode 9, val func loss 0.19518958032131195\n",
      "\n",
      "episode 10, val func loss 0.17261256277561188\n",
      "\n",
      "episode 11, val func loss 0.16476240754127502\n",
      "\n",
      "episode 12, val func loss 0.16038969159126282\n",
      "\n",
      "episode 13, val func loss 0.19649368524551392\n",
      "\n",
      "episode 14, val func loss 0.15730446577072144\n",
      "\n",
      "episode 15, val func loss 0.2058507651090622\n",
      "\n",
      "episode 16, val func loss 0.19776864349842072\n",
      "\n",
      "Val func train loss in epoch 4:0.18570872489362955\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18661150336265564\n",
      "\n",
      "episode 2, val func loss 0.1972392350435257\n",
      "\n",
      "episode 3, val func loss 0.20214441418647766\n",
      "\n",
      "episode 4, val func loss 0.19483056664466858\n",
      "\n",
      "episode 5, val func loss 0.18611463904380798\n",
      "\n",
      "episode 6, val func loss 0.19842399656772614\n",
      "\n",
      "episode 7, val func loss 0.1652487963438034\n",
      "\n",
      "episode 8, val func loss 0.19510331749916077\n",
      "\n",
      "episode 9, val func loss 0.17329733073711395\n",
      "\n",
      "episode 10, val func loss 0.1970817744731903\n",
      "\n",
      "episode 11, val func loss 0.17803992331027985\n",
      "\n",
      "episode 12, val func loss 0.21331515908241272\n",
      "\n",
      "episode 13, val func loss 0.18658578395843506\n",
      "\n",
      "episode 14, val func loss 0.16535845398902893\n",
      "\n",
      "episode 15, val func loss 0.15970627963542938\n",
      "\n",
      "episode 16, val func loss 0.17411983013153076\n",
      "\n",
      "Val func train loss in epoch 5:0.18582631275057793\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.15698793530464172\n",
      "\n",
      "episode 2, val func loss 0.2145046591758728\n",
      "\n",
      "episode 3, val func loss 0.16023898124694824\n",
      "\n",
      "episode 4, val func loss 0.19484268128871918\n",
      "\n",
      "episode 5, val func loss 0.19272130727767944\n",
      "\n",
      "episode 6, val func loss 0.16695262491703033\n",
      "\n",
      "episode 7, val func loss 0.17941643297672272\n",
      "\n",
      "episode 8, val func loss 0.1875646412372589\n",
      "\n",
      "episode 9, val func loss 0.17400799691677094\n",
      "\n",
      "episode 10, val func loss 0.2125568687915802\n",
      "\n",
      "episode 11, val func loss 0.18712492287158966\n",
      "\n",
      "episode 12, val func loss 0.1983896791934967\n",
      "\n",
      "episode 13, val func loss 0.19365356862545013\n",
      "\n",
      "episode 14, val func loss 0.18606872856616974\n",
      "\n",
      "episode 15, val func loss 0.17573970556259155\n",
      "\n",
      "episode 16, val func loss 0.1938530057668686\n",
      "\n",
      "Val func train loss in epoch 6:0.18591398373246193\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18806242942810059\n",
      "\n",
      "episode 2, val func loss 0.1942036747932434\n",
      "\n",
      "episode 3, val func loss 0.18422095477581024\n",
      "\n",
      "episode 4, val func loss 0.19270090758800507\n",
      "\n",
      "episode 5, val func loss 0.1748523712158203\n",
      "\n",
      "episode 6, val func loss 0.1989695131778717\n",
      "\n",
      "episode 7, val func loss 0.1768999546766281\n",
      "\n",
      "episode 8, val func loss 0.2025889754295349\n",
      "\n",
      "episode 9, val func loss 0.1658090502023697\n",
      "\n",
      "episode 10, val func loss 0.19344185292720795\n",
      "\n",
      "episode 11, val func loss 0.16117656230926514\n",
      "\n",
      "episode 12, val func loss 0.17898701131343842\n",
      "\n",
      "episode 13, val func loss 0.18662287294864655\n",
      "\n",
      "episode 14, val func loss 0.2140076458454132\n",
      "\n",
      "episode 15, val func loss 0.1940843015909195\n",
      "\n",
      "episode 16, val func loss 0.16174478828907013\n",
      "\n",
      "Val func train loss in epoch 7:0.18552330415695906\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.15797847509384155\n",
      "\n",
      "episode 2, val func loss 0.18640688061714172\n",
      "\n",
      "episode 3, val func loss 0.21710267663002014\n",
      "\n",
      "episode 4, val func loss 0.20827381312847137\n",
      "\n",
      "episode 5, val func loss 0.19332090020179749\n",
      "\n",
      "episode 6, val func loss 0.1937141716480255\n",
      "\n",
      "episode 7, val func loss 0.16757753491401672\n",
      "\n",
      "episode 8, val func loss 0.1652941256761551\n",
      "\n",
      "episode 9, val func loss 0.1753867268562317\n",
      "\n",
      "episode 10, val func loss 0.18827809393405914\n",
      "\n",
      "episode 11, val func loss 0.17828013002872467\n",
      "\n",
      "episode 12, val func loss 0.19793245196342468\n",
      "\n",
      "episode 13, val func loss 0.17519988119602203\n",
      "\n",
      "episode 14, val func loss 0.19385893642902374\n",
      "\n",
      "episode 15, val func loss 0.19562077522277832\n",
      "\n",
      "episode 16, val func loss 0.18438509106636047\n",
      "\n",
      "Val func train loss in epoch 8:0.1861631665378809\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20510555803775787\n",
      "\n",
      "episode 2, val func loss 0.1858319491147995\n",
      "\n",
      "episode 3, val func loss 0.18696168065071106\n",
      "\n",
      "episode 4, val func loss 0.17558053135871887\n",
      "\n",
      "episode 5, val func loss 0.19441567361354828\n",
      "\n",
      "episode 6, val func loss 0.19353008270263672\n",
      "\n",
      "episode 7, val func loss 0.21386776864528656\n",
      "\n",
      "episode 8, val func loss 0.17856363952159882\n",
      "\n",
      "episode 9, val func loss 0.1737738996744156\n",
      "\n",
      "episode 10, val func loss 0.1945398598909378\n",
      "\n",
      "episode 11, val func loss 0.18653005361557007\n",
      "\n",
      "episode 12, val func loss 0.16541056334972382\n",
      "\n",
      "episode 13, val func loss 0.1979266107082367\n",
      "\n",
      "episode 14, val func loss 0.19544266164302826\n",
      "\n",
      "episode 15, val func loss 0.15904299914836884\n",
      "\n",
      "episode 16, val func loss 0.1625705510377884\n",
      "\n",
      "Val func train loss in epoch 9:0.18556838016957045\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18621951341629028\n",
      "\n",
      "episode 2, val func loss 0.1946914941072464\n",
      "\n",
      "episode 3, val func loss 0.19270722568035126\n",
      "\n",
      "episode 4, val func loss 0.19831697642803192\n",
      "\n",
      "episode 5, val func loss 0.19359762966632843\n",
      "\n",
      "episode 6, val func loss 0.1628115177154541\n",
      "\n",
      "episode 7, val func loss 0.15952326357364655\n",
      "\n",
      "episode 8, val func loss 0.20343370735645294\n",
      "\n",
      "episode 9, val func loss 0.1748790591955185\n",
      "\n",
      "episode 10, val func loss 0.18650737404823303\n",
      "\n",
      "episode 11, val func loss 0.1875603348016739\n",
      "\n",
      "episode 12, val func loss 0.19372020661830902\n",
      "\n",
      "episode 13, val func loss 0.17313764989376068\n",
      "\n",
      "episode 14, val func loss 0.17830997705459595\n",
      "\n",
      "episode 15, val func loss 0.16679254174232483\n",
      "\n",
      "episode 16, val func loss 0.21653525531291962\n",
      "\n",
      "Val func train loss in epoch 10:0.1855464829131961\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19334548711776733\n",
      "\n",
      "episode 2, val func loss 0.1574738770723343\n",
      "\n",
      "episode 3, val func loss 0.21407409012317657\n",
      "\n",
      "episode 4, val func loss 0.19481335580348969\n",
      "\n",
      "episode 5, val func loss 0.18561002612113953\n",
      "\n",
      "episode 6, val func loss 0.1905158907175064\n",
      "\n",
      "episode 7, val func loss 0.19708551466464996\n",
      "\n",
      "episode 8, val func loss 0.17589430510997772\n",
      "\n",
      "episode 9, val func loss 0.1825408786535263\n",
      "\n",
      "episode 10, val func loss 0.167864590883255\n",
      "\n",
      "episode 11, val func loss 0.17452694475650787\n",
      "\n",
      "episode 12, val func loss 0.1938265711069107\n",
      "\n",
      "episode 13, val func loss 0.20802909135818481\n",
      "\n",
      "episode 14, val func loss 0.1606772541999817\n",
      "\n",
      "episode 15, val func loss 0.18536332249641418\n",
      "\n",
      "episode 16, val func loss 0.18903006613254547\n",
      "\n",
      "Val func train loss in epoch 11:0.18566695414483547\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1848030537366867\n",
      "\n",
      "episode 2, val func loss 0.17845629155635834\n",
      "\n",
      "episode 3, val func loss 0.19342629611492157\n",
      "\n",
      "episode 4, val func loss 0.18611980974674225\n",
      "\n",
      "episode 5, val func loss 0.2134711742401123\n",
      "\n",
      "episode 6, val func loss 0.19388848543167114\n",
      "\n",
      "episode 7, val func loss 0.19443204998970032\n",
      "\n",
      "episode 8, val func loss 0.17628495395183563\n",
      "\n",
      "episode 9, val func loss 0.1678125411272049\n",
      "\n",
      "episode 10, val func loss 0.1961737722158432\n",
      "\n",
      "episode 11, val func loss 0.18722963333129883\n",
      "\n",
      "episode 12, val func loss 0.17293967306613922\n",
      "\n",
      "episode 13, val func loss 0.1574563831090927\n",
      "\n",
      "episode 14, val func loss 0.2070637196302414\n",
      "\n",
      "episode 15, val func loss 0.16240336000919342\n",
      "\n",
      "episode 16, val func loss 0.19380821287631989\n",
      "\n",
      "Val func train loss in epoch 12:0.1853605881333351\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.2056736797094345\n",
      "\n",
      "episode 2, val func loss 0.19423674046993256\n",
      "\n",
      "episode 3, val func loss 0.19504514336585999\n",
      "\n",
      "episode 4, val func loss 0.16564495861530304\n",
      "\n",
      "episode 5, val func loss 0.19327332079410553\n",
      "\n",
      "episode 6, val func loss 0.19691202044487\n",
      "\n",
      "episode 7, val func loss 0.1611655354499817\n",
      "\n",
      "episode 8, val func loss 0.18839015066623688\n",
      "\n",
      "episode 9, val func loss 0.193154439330101\n",
      "\n",
      "episode 10, val func loss 0.16557317972183228\n",
      "\n",
      "episode 11, val func loss 0.18581631779670715\n",
      "\n",
      "episode 12, val func loss 0.18667283654212952\n",
      "\n",
      "episode 13, val func loss 0.216898575425148\n",
      "\n",
      "episode 14, val func loss 0.17596672475337982\n",
      "\n",
      "episode 15, val func loss 0.17817352712154388\n",
      "\n",
      "episode 16, val func loss 0.17363829910755157\n",
      "\n",
      "Val func train loss in epoch 13:0.18601471558213234\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18472984433174133\n",
      "\n",
      "episode 2, val func loss 0.1940660923719406\n",
      "\n",
      "episode 3, val func loss 0.21474851667881012\n",
      "\n",
      "episode 4, val func loss 0.20458446443080902\n",
      "\n",
      "episode 5, val func loss 0.19361944496631622\n",
      "\n",
      "episode 6, val func loss 0.16108575463294983\n",
      "\n",
      "episode 7, val func loss 0.19391852617263794\n",
      "\n",
      "episode 8, val func loss 0.16617120802402496\n",
      "\n",
      "episode 9, val func loss 0.1878991723060608\n",
      "\n",
      "episode 10, val func loss 0.19700129330158234\n",
      "\n",
      "episode 11, val func loss 0.194540873169899\n",
      "\n",
      "episode 12, val func loss 0.18736149370670319\n",
      "\n",
      "episode 13, val func loss 0.16557106375694275\n",
      "\n",
      "episode 14, val func loss 0.17312157154083252\n",
      "\n",
      "episode 15, val func loss 0.1751926690340042\n",
      "\n",
      "episode 16, val func loss 0.17739081382751465\n",
      "\n",
      "Val func train loss in epoch 14:0.1856876751407981\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19920571148395538\n",
      "\n",
      "episode 2, val func loss 0.19435305893421173\n",
      "\n",
      "episode 3, val func loss 0.1762944608926773\n",
      "\n",
      "episode 4, val func loss 0.18531866371631622\n",
      "\n",
      "episode 5, val func loss 0.19381403923034668\n",
      "\n",
      "episode 6, val func loss 0.18621961772441864\n",
      "\n",
      "episode 7, val func loss 0.15709495544433594\n",
      "\n",
      "episode 8, val func loss 0.19406592845916748\n",
      "\n",
      "episode 9, val func loss 0.2078189104795456\n",
      "\n",
      "episode 10, val func loss 0.16052407026290894\n",
      "\n",
      "episode 11, val func loss 0.16619732975959778\n",
      "\n",
      "episode 12, val func loss 0.17475078999996185\n",
      "\n",
      "episode 13, val func loss 0.19380557537078857\n",
      "\n",
      "episode 14, val func loss 0.21400053799152374\n",
      "\n",
      "episode 15, val func loss 0.17728453874588013\n",
      "\n",
      "episode 16, val func loss 0.18793264031410217\n",
      "\n",
      "Val func train loss in epoch 15:0.18554255180060863\n",
      "***********************TIME WAS 4.939043513933817 min*****************************\n",
      "\n",
      "**********************ROUND 69 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.004082081839442253\n",
      "\n",
      "episode 2, policy loss 0.003126773051917553\n",
      "\n",
      "episode 3, policy loss -0.00806067418307066\n",
      "\n",
      "episode 4, policy loss -0.04437779635190964\n",
      "\n",
      "episode 5, policy loss -0.05185246467590332\n",
      "\n",
      "episode 6, policy loss -0.012935975566506386\n",
      "\n",
      "episode 7, policy loss -0.03157510608434677\n",
      "\n",
      "episode 8, policy loss -0.01167471893131733\n",
      "\n",
      "episode 9, policy loss -0.036535151302814484\n",
      "\n",
      "episode 10, policy loss 0.01436214242130518\n",
      "\n",
      "episode 11, policy loss -0.04016542062163353\n",
      "\n",
      "episode 12, policy loss -0.07133219391107559\n",
      "\n",
      "episode 13, policy loss -0.016864076256752014\n",
      "\n",
      "episode 14, policy loss -0.01964796893298626\n",
      "\n",
      "episode 15, policy loss -0.0480799563229084\n",
      "\n",
      "episode 16, policy loss 0.007114598993211985\n",
      "\n",
      "Policy train loss in epoch 0:-0.022775994177209213\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.05078142136335373\n",
      "\n",
      "episode 2, policy loss -0.01073911041021347\n",
      "\n",
      "episode 3, policy loss -0.0017089667962864041\n",
      "\n",
      "episode 4, policy loss -0.018433138728141785\n",
      "\n",
      "episode 5, policy loss -0.013899768702685833\n",
      "\n",
      "episode 6, policy loss 0.004352277610450983\n",
      "\n",
      "episode 7, policy loss -0.03396986424922943\n",
      "\n",
      "episode 8, policy loss -0.0018789961468428373\n",
      "\n",
      "episode 9, policy loss -0.041814401745796204\n",
      "\n",
      "episode 10, policy loss -0.015843741595745087\n",
      "\n",
      "episode 11, policy loss -0.07245272397994995\n",
      "\n",
      "episode 12, policy loss 0.013466285541653633\n",
      "\n",
      "episode 13, policy loss -0.046812593936920166\n",
      "\n",
      "episode 14, policy loss -0.04808353632688522\n",
      "\n",
      "episode 15, policy loss -0.016393762081861496\n",
      "\n",
      "episode 16, policy loss -0.04004285857081413\n",
      "\n",
      "Policy train loss in epoch 1:-0.02468977009266382\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.018758248537778854\n",
      "\n",
      "episode 2, policy loss -0.013170541264116764\n",
      "\n",
      "episode 3, policy loss -0.04646758735179901\n",
      "\n",
      "episode 4, policy loss -0.04979618638753891\n",
      "\n",
      "episode 5, policy loss -0.0015403430443257093\n",
      "\n",
      "episode 6, policy loss -0.03258544206619263\n",
      "\n",
      "episode 7, policy loss -0.0019019896863028407\n",
      "\n",
      "episode 8, policy loss -0.01419109757989645\n",
      "\n",
      "episode 9, policy loss -0.05114543437957764\n",
      "\n",
      "episode 10, policy loss -0.0726156011223793\n",
      "\n",
      "episode 11, policy loss -0.010520975105464458\n",
      "\n",
      "episode 12, policy loss 0.014936581254005432\n",
      "\n",
      "episode 13, policy loss -0.041828930377960205\n",
      "\n",
      "episode 14, policy loss -0.03780924156308174\n",
      "\n",
      "episode 15, policy loss 0.005200854502618313\n",
      "\n",
      "episode 16, policy loss -0.015899894759058952\n",
      "\n",
      "Policy train loss in epoch 2:-0.024255879841803107\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.03363396227359772\n",
      "\n",
      "episode 2, policy loss -0.007898532785475254\n",
      "\n",
      "episode 3, policy loss 0.004895927384495735\n",
      "\n",
      "episode 4, policy loss -0.0402224026620388\n",
      "\n",
      "episode 5, policy loss -0.07221261411905289\n",
      "\n",
      "episode 6, policy loss -0.002678754273802042\n",
      "\n",
      "episode 7, policy loss -0.04438383877277374\n",
      "\n",
      "episode 8, policy loss 0.014940696768462658\n",
      "\n",
      "episode 9, policy loss -0.00145330757368356\n",
      "\n",
      "episode 10, policy loss -0.016079524531960487\n",
      "\n",
      "episode 11, policy loss -0.018255487084388733\n",
      "\n",
      "episode 12, policy loss -0.051634371280670166\n",
      "\n",
      "episode 13, policy loss -0.04800894483923912\n",
      "\n",
      "episode 14, policy loss -0.012489144690334797\n",
      "\n",
      "episode 15, policy loss -0.04132343456149101\n",
      "\n",
      "episode 16, policy loss -0.017266809940338135\n",
      "\n",
      "Policy train loss in epoch 3:-0.024231531577243004\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1929555982351303\n",
      "\n",
      "episode 2, val func loss 0.15816211700439453\n",
      "\n",
      "episode 3, val func loss 0.19341199100017548\n",
      "\n",
      "episode 4, val func loss 0.16205278038978577\n",
      "\n",
      "episode 5, val func loss 0.16616679728031158\n",
      "\n",
      "episode 6, val func loss 0.17353101074695587\n",
      "\n",
      "episode 7, val func loss 0.20498120784759521\n",
      "\n",
      "episode 8, val func loss 0.18739819526672363\n",
      "\n",
      "episode 9, val func loss 0.17303019762039185\n",
      "\n",
      "episode 10, val func loss 0.19531433284282684\n",
      "\n",
      "episode 11, val func loss 0.1708001345396042\n",
      "\n",
      "episode 12, val func loss 0.20796142518520355\n",
      "\n",
      "episode 13, val func loss 0.18923935294151306\n",
      "\n",
      "episode 14, val func loss 0.17703495919704437\n",
      "\n",
      "episode 15, val func loss 0.1710229367017746\n",
      "\n",
      "episode 16, val func loss 0.1973951905965805\n",
      "\n",
      "Val func train loss in epoch 0:0.1825286392122507\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1963491439819336\n",
      "\n",
      "episode 2, val func loss 0.20404189825057983\n",
      "\n",
      "episode 3, val func loss 0.1945653259754181\n",
      "\n",
      "episode 4, val func loss 0.16455894708633423\n",
      "\n",
      "episode 5, val func loss 0.17321504652500153\n",
      "\n",
      "episode 6, val func loss 0.1681472361087799\n",
      "\n",
      "episode 7, val func loss 0.18605674803256989\n",
      "\n",
      "episode 8, val func loss 0.17000961303710938\n",
      "\n",
      "episode 9, val func loss 0.1901390254497528\n",
      "\n",
      "episode 10, val func loss 0.17799624800682068\n",
      "\n",
      "episode 11, val func loss 0.17581017315387726\n",
      "\n",
      "episode 12, val func loss 0.17265275120735168\n",
      "\n",
      "episode 13, val func loss 0.1539885401725769\n",
      "\n",
      "episode 14, val func loss 0.2100016176700592\n",
      "\n",
      "episode 15, val func loss 0.19610834121704102\n",
      "\n",
      "episode 16, val func loss 0.1938486546278\n",
      "\n",
      "Val func train loss in epoch 1:0.18296808190643787\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1870841532945633\n",
      "\n",
      "episode 2, val func loss 0.16808399558067322\n",
      "\n",
      "episode 3, val func loss 0.19554296135902405\n",
      "\n",
      "episode 4, val func loss 0.20486952364444733\n",
      "\n",
      "episode 5, val func loss 0.1917858123779297\n",
      "\n",
      "episode 6, val func loss 0.19360211491584778\n",
      "\n",
      "episode 7, val func loss 0.15725669264793396\n",
      "\n",
      "episode 8, val func loss 0.206848606467247\n",
      "\n",
      "episode 9, val func loss 0.19037765264511108\n",
      "\n",
      "episode 10, val func loss 0.17311234772205353\n",
      "\n",
      "episode 11, val func loss 0.1764381229877472\n",
      "\n",
      "episode 12, val func loss 0.17032752931118011\n",
      "\n",
      "episode 13, val func loss 0.17283253371715546\n",
      "\n",
      "episode 14, val func loss 0.1628381907939911\n",
      "\n",
      "episode 15, val func loss 0.19616936147212982\n",
      "\n",
      "episode 16, val func loss 0.17392787337303162\n",
      "\n",
      "Val func train loss in epoch 2:0.18256859201937914\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1735469549894333\n",
      "\n",
      "episode 2, val func loss 0.19533565640449524\n",
      "\n",
      "episode 3, val func loss 0.204912930727005\n",
      "\n",
      "episode 4, val func loss 0.1639954000711441\n",
      "\n",
      "episode 5, val func loss 0.17493659257888794\n",
      "\n",
      "episode 6, val func loss 0.1931280940771103\n",
      "\n",
      "episode 7, val func loss 0.19481177628040314\n",
      "\n",
      "episode 8, val func loss 0.16810490190982819\n",
      "\n",
      "episode 9, val func loss 0.15606170892715454\n",
      "\n",
      "episode 10, val func loss 0.17597022652626038\n",
      "\n",
      "episode 11, val func loss 0.17273063957691193\n",
      "\n",
      "episode 12, val func loss 0.19533321261405945\n",
      "\n",
      "episode 13, val func loss 0.2089652270078659\n",
      "\n",
      "episode 14, val func loss 0.18971295654773712\n",
      "\n",
      "episode 15, val func loss 0.18633855879306793\n",
      "\n",
      "episode 16, val func loss 0.16996628046035767\n",
      "\n",
      "Val func train loss in epoch 3:0.18274069484323263\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18665604293346405\n",
      "\n",
      "episode 2, val func loss 0.16971422731876373\n",
      "\n",
      "episode 3, val func loss 0.15560190379619598\n",
      "\n",
      "episode 4, val func loss 0.16379131376743317\n",
      "\n",
      "episode 5, val func loss 0.174765944480896\n",
      "\n",
      "episode 6, val func loss 0.19585010409355164\n",
      "\n",
      "episode 7, val func loss 0.2074141502380371\n",
      "\n",
      "episode 8, val func loss 0.1725441813468933\n",
      "\n",
      "episode 9, val func loss 0.19455695152282715\n",
      "\n",
      "episode 10, val func loss 0.19164985418319702\n",
      "\n",
      "episode 11, val func loss 0.17529068887233734\n",
      "\n",
      "episode 12, val func loss 0.19283510744571686\n",
      "\n",
      "episode 13, val func loss 0.16718390583992004\n",
      "\n",
      "episode 14, val func loss 0.20433911681175232\n",
      "\n",
      "episode 15, val func loss 0.17599625885486603\n",
      "\n",
      "episode 16, val func loss 0.1952870488166809\n",
      "\n",
      "Val func train loss in epoch 4:0.1827173000201583\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.194069042801857\n",
      "\n",
      "episode 2, val func loss 0.19476036727428436\n",
      "\n",
      "episode 3, val func loss 0.17326444387435913\n",
      "\n",
      "episode 4, val func loss 0.18636703491210938\n",
      "\n",
      "episode 5, val func loss 0.20460952818393707\n",
      "\n",
      "episode 6, val func loss 0.17464716732501984\n",
      "\n",
      "episode 7, val func loss 0.20671790838241577\n",
      "\n",
      "episode 8, val func loss 0.15579746663570404\n",
      "\n",
      "episode 9, val func loss 0.1735825538635254\n",
      "\n",
      "episode 10, val func loss 0.17645761370658875\n",
      "\n",
      "episode 11, val func loss 0.1954590529203415\n",
      "\n",
      "episode 12, val func loss 0.1897028386592865\n",
      "\n",
      "episode 13, val func loss 0.1697663962841034\n",
      "\n",
      "episode 14, val func loss 0.19548048079013824\n",
      "\n",
      "episode 15, val func loss 0.16316528618335724\n",
      "\n",
      "episode 16, val func loss 0.1672378033399582\n",
      "\n",
      "Val func train loss in epoch 5:0.1825678115710616\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17554649710655212\n",
      "\n",
      "episode 2, val func loss 0.2067544013261795\n",
      "\n",
      "episode 3, val func loss 0.1948404759168625\n",
      "\n",
      "episode 4, val func loss 0.1734037697315216\n",
      "\n",
      "episode 5, val func loss 0.1686144918203354\n",
      "\n",
      "episode 6, val func loss 0.20438408851623535\n",
      "\n",
      "episode 7, val func loss 0.17449712753295898\n",
      "\n",
      "episode 8, val func loss 0.192712664604187\n",
      "\n",
      "episode 9, val func loss 0.16355538368225098\n",
      "\n",
      "episode 10, val func loss 0.16698727011680603\n",
      "\n",
      "episode 11, val func loss 0.15499438345432281\n",
      "\n",
      "episode 12, val func loss 0.18660607933998108\n",
      "\n",
      "episode 13, val func loss 0.17196790874004364\n",
      "\n",
      "episode 14, val func loss 0.19926345348358154\n",
      "\n",
      "episode 15, val func loss 0.18990521132946014\n",
      "\n",
      "episode 16, val func loss 0.19767050445079803\n",
      "\n",
      "Val func train loss in epoch 6:0.1826064819470048\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18552768230438232\n",
      "\n",
      "episode 2, val func loss 0.15549339354038239\n",
      "\n",
      "episode 3, val func loss 0.20739272236824036\n",
      "\n",
      "episode 4, val func loss 0.16344128549098969\n",
      "\n",
      "episode 5, val func loss 0.17445701360702515\n",
      "\n",
      "episode 6, val func loss 0.19574306905269623\n",
      "\n",
      "episode 7, val func loss 0.1943131387233734\n",
      "\n",
      "episode 8, val func loss 0.19135645031929016\n",
      "\n",
      "episode 9, val func loss 0.1678926646709442\n",
      "\n",
      "episode 10, val func loss 0.19462789595127106\n",
      "\n",
      "episode 11, val func loss 0.17418424785137177\n",
      "\n",
      "episode 12, val func loss 0.1728714406490326\n",
      "\n",
      "episode 13, val func loss 0.17564311623573303\n",
      "\n",
      "episode 14, val func loss 0.19017484784126282\n",
      "\n",
      "episode 15, val func loss 0.1701003909111023\n",
      "\n",
      "episode 16, val func loss 0.20618629455566406\n",
      "\n",
      "Val func train loss in epoch 7:0.1824628533795476\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.19764089584350586\n",
      "\n",
      "episode 2, val func loss 0.17538966238498688\n",
      "\n",
      "episode 3, val func loss 0.1741577833890915\n",
      "\n",
      "episode 4, val func loss 0.19308795034885406\n",
      "\n",
      "episode 5, val func loss 0.15745173394680023\n",
      "\n",
      "episode 6, val func loss 0.20683716237545013\n",
      "\n",
      "episode 7, val func loss 0.1738065481185913\n",
      "\n",
      "episode 8, val func loss 0.16639083623886108\n",
      "\n",
      "episode 9, val func loss 0.18595562875270844\n",
      "\n",
      "episode 10, val func loss 0.19552668929100037\n",
      "\n",
      "episode 11, val func loss 0.16994206607341766\n",
      "\n",
      "episode 12, val func loss 0.19449976086616516\n",
      "\n",
      "episode 13, val func loss 0.19009436666965485\n",
      "\n",
      "episode 14, val func loss 0.20336225628852844\n",
      "\n",
      "episode 15, val func loss 0.16435424983501434\n",
      "\n",
      "episode 16, val func loss 0.17347308993339539\n",
      "\n",
      "Val func train loss in epoch 8:0.1826231675222516\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.19498665630817413\n",
      "\n",
      "episode 2, val func loss 0.18686872720718384\n",
      "\n",
      "episode 3, val func loss 0.1749902218580246\n",
      "\n",
      "episode 4, val func loss 0.16385462880134583\n",
      "\n",
      "episode 5, val func loss 0.20803821086883545\n",
      "\n",
      "episode 6, val func loss 0.1940271556377411\n",
      "\n",
      "episode 7, val func loss 0.16853652894496918\n",
      "\n",
      "episode 8, val func loss 0.20492815971374512\n",
      "\n",
      "episode 9, val func loss 0.19501930475234985\n",
      "\n",
      "episode 10, val func loss 0.19233094155788422\n",
      "\n",
      "episode 11, val func loss 0.17664648592472076\n",
      "\n",
      "episode 12, val func loss 0.17554697394371033\n",
      "\n",
      "episode 13, val func loss 0.1929844170808792\n",
      "\n",
      "episode 14, val func loss 0.16789184510707855\n",
      "\n",
      "episode 15, val func loss 0.15518712997436523\n",
      "\n",
      "episode 16, val func loss 0.17321714758872986\n",
      "\n",
      "Val func train loss in epoch 9:0.18281590845435858\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.21253438293933868\n",
      "\n",
      "episode 2, val func loss 0.17335918545722961\n",
      "\n",
      "episode 3, val func loss 0.16417890787124634\n",
      "\n",
      "episode 4, val func loss 0.1773570328950882\n",
      "\n",
      "episode 5, val func loss 0.1895042061805725\n",
      "\n",
      "episode 6, val func loss 0.17364658415317535\n",
      "\n",
      "episode 7, val func loss 0.17447598278522491\n",
      "\n",
      "episode 8, val func loss 0.19442245364189148\n",
      "\n",
      "episode 9, val func loss 0.19452844560146332\n",
      "\n",
      "episode 10, val func loss 0.16844794154167175\n",
      "\n",
      "episode 11, val func loss 0.1869603842496872\n",
      "\n",
      "episode 12, val func loss 0.20445440709590912\n",
      "\n",
      "episode 13, val func loss 0.19198475778102875\n",
      "\n",
      "episode 14, val func loss 0.19373489916324615\n",
      "\n",
      "episode 15, val func loss 0.1689986288547516\n",
      "\n",
      "episode 16, val func loss 0.15674759447574615\n",
      "\n",
      "Val func train loss in epoch 10:0.18283348716795444\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19496223330497742\n",
      "\n",
      "episode 2, val func loss 0.19572097063064575\n",
      "\n",
      "episode 3, val func loss 0.1547004133462906\n",
      "\n",
      "episode 4, val func loss 0.1895264983177185\n",
      "\n",
      "episode 5, val func loss 0.17358604073524475\n",
      "\n",
      "episode 6, val func loss 0.16994161903858185\n",
      "\n",
      "episode 7, val func loss 0.17312481999397278\n",
      "\n",
      "episode 8, val func loss 0.17697736620903015\n",
      "\n",
      "episode 9, val func loss 0.17497479915618896\n",
      "\n",
      "episode 10, val func loss 0.19342082738876343\n",
      "\n",
      "episode 11, val func loss 0.16722677648067474\n",
      "\n",
      "episode 12, val func loss 0.19505880773067474\n",
      "\n",
      "episode 13, val func loss 0.2047099471092224\n",
      "\n",
      "episode 14, val func loss 0.206938698887825\n",
      "\n",
      "episode 15, val func loss 0.18678636848926544\n",
      "\n",
      "episode 16, val func loss 0.16471807658672333\n",
      "\n",
      "Val func train loss in epoch 11:0.1826483914628625\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19478559494018555\n",
      "\n",
      "episode 2, val func loss 0.19408395886421204\n",
      "\n",
      "episode 3, val func loss 0.2067638784646988\n",
      "\n",
      "episode 4, val func loss 0.16348864138126373\n",
      "\n",
      "episode 5, val func loss 0.194683238863945\n",
      "\n",
      "episode 6, val func loss 0.20498761534690857\n",
      "\n",
      "episode 7, val func loss 0.19221949577331543\n",
      "\n",
      "episode 8, val func loss 0.1759243905544281\n",
      "\n",
      "episode 9, val func loss 0.15697313845157623\n",
      "\n",
      "episode 10, val func loss 0.17347849905490875\n",
      "\n",
      "episode 11, val func loss 0.1864556074142456\n",
      "\n",
      "episode 12, val func loss 0.19018451869487762\n",
      "\n",
      "episode 13, val func loss 0.17020803689956665\n",
      "\n",
      "episode 14, val func loss 0.1757098138332367\n",
      "\n",
      "episode 15, val func loss 0.1715959757566452\n",
      "\n",
      "episode 16, val func loss 0.16555321216583252\n",
      "\n",
      "Val func train loss in epoch 12:0.1823184760287404\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18732328712940216\n",
      "\n",
      "episode 2, val func loss 0.2084432989358902\n",
      "\n",
      "episode 3, val func loss 0.19518183171749115\n",
      "\n",
      "episode 4, val func loss 0.1681225299835205\n",
      "\n",
      "episode 5, val func loss 0.19207978248596191\n",
      "\n",
      "episode 6, val func loss 0.17364542186260223\n",
      "\n",
      "episode 7, val func loss 0.1755867451429367\n",
      "\n",
      "episode 8, val func loss 0.16494297981262207\n",
      "\n",
      "episode 9, val func loss 0.1679268479347229\n",
      "\n",
      "episode 10, val func loss 0.1876561939716339\n",
      "\n",
      "episode 11, val func loss 0.17507430911064148\n",
      "\n",
      "episode 12, val func loss 0.15513338148593903\n",
      "\n",
      "episode 13, val func loss 0.1712637096643448\n",
      "\n",
      "episode 14, val func loss 0.19841007888317108\n",
      "\n",
      "episode 15, val func loss 0.20639625191688538\n",
      "\n",
      "episode 16, val func loss 0.19641076028347015\n",
      "\n",
      "Val func train loss in epoch 13:0.18272483814507723\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19466042518615723\n",
      "\n",
      "episode 2, val func loss 0.1887226551771164\n",
      "\n",
      "episode 3, val func loss 0.1923723667860031\n",
      "\n",
      "episode 4, val func loss 0.16815602779388428\n",
      "\n",
      "episode 5, val func loss 0.16305960714817047\n",
      "\n",
      "episode 6, val func loss 0.19222800433635712\n",
      "\n",
      "episode 7, val func loss 0.1685628890991211\n",
      "\n",
      "episode 8, val func loss 0.1746755987405777\n",
      "\n",
      "episode 9, val func loss 0.15638108551502228\n",
      "\n",
      "episode 10, val func loss 0.20699357986450195\n",
      "\n",
      "episode 11, val func loss 0.1732514500617981\n",
      "\n",
      "episode 12, val func loss 0.20832708477973938\n",
      "\n",
      "episode 13, val func loss 0.17767585813999176\n",
      "\n",
      "episode 14, val func loss 0.1938115507364273\n",
      "\n",
      "episode 15, val func loss 0.1724088191986084\n",
      "\n",
      "episode 16, val func loss 0.19566121697425842\n",
      "\n",
      "Val func train loss in epoch 14:0.18293426372110844\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20537069439888\n",
      "\n",
      "episode 2, val func loss 0.1673983484506607\n",
      "\n",
      "episode 3, val func loss 0.20495979487895966\n",
      "\n",
      "episode 4, val func loss 0.16829559206962585\n",
      "\n",
      "episode 5, val func loss 0.17713692784309387\n",
      "\n",
      "episode 6, val func loss 0.17380650341510773\n",
      "\n",
      "episode 7, val func loss 0.17245571315288544\n",
      "\n",
      "episode 8, val func loss 0.17539244890213013\n",
      "\n",
      "episode 9, val func loss 0.16425180435180664\n",
      "\n",
      "episode 10, val func loss 0.19579273462295532\n",
      "\n",
      "episode 11, val func loss 0.19566349685192108\n",
      "\n",
      "episode 12, val func loss 0.19271226227283478\n",
      "\n",
      "episode 13, val func loss 0.18725347518920898\n",
      "\n",
      "episode 14, val func loss 0.19414906203746796\n",
      "\n",
      "episode 15, val func loss 0.19291824102401733\n",
      "\n",
      "episode 16, val func loss 0.158487930893898\n",
      "\n",
      "Val func train loss in epoch 15:0.18287781439721584\n",
      "***********************TIME WAS 4.93969273964564 min*****************************\n",
      "\n",
      "**********************ROUND 70 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.0277871061116457\n",
      "\n",
      "episode 2, policy loss -0.017618786543607712\n",
      "\n",
      "episode 3, policy loss 0.004441851284354925\n",
      "\n",
      "episode 4, policy loss -0.008692723698914051\n",
      "\n",
      "episode 5, policy loss 0.016406117007136345\n",
      "\n",
      "episode 6, policy loss -0.06085178256034851\n",
      "\n",
      "episode 7, policy loss -0.048285774886608124\n",
      "\n",
      "episode 8, policy loss -0.03797442466020584\n",
      "\n",
      "episode 9, policy loss -0.03195749968290329\n",
      "\n",
      "episode 10, policy loss 0.04455845430493355\n",
      "\n",
      "episode 11, policy loss -0.08721111714839935\n",
      "\n",
      "episode 12, policy loss -0.07643667608499527\n",
      "\n",
      "episode 13, policy loss -0.01167477946728468\n",
      "\n",
      "episode 14, policy loss -0.06373363733291626\n",
      "\n",
      "episode 15, policy loss 0.02423606812953949\n",
      "\n",
      "episode 16, policy loss -0.056292202323675156\n",
      "\n",
      "Policy train loss in epoch 0:-0.023956237972015515\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.06273362040519714\n",
      "\n",
      "episode 2, policy loss -0.03526507318019867\n",
      "\n",
      "episode 3, policy loss 0.024368437007069588\n",
      "\n",
      "episode 4, policy loss -0.027347147464752197\n",
      "\n",
      "episode 5, policy loss -0.09277600795030594\n",
      "\n",
      "episode 6, policy loss -0.04280427098274231\n",
      "\n",
      "episode 7, policy loss 0.043183572590351105\n",
      "\n",
      "episode 8, policy loss 0.013283509761095047\n",
      "\n",
      "episode 9, policy loss -0.07763011753559113\n",
      "\n",
      "episode 10, policy loss 0.0006451978115364909\n",
      "\n",
      "episode 11, policy loss -0.01050473004579544\n",
      "\n",
      "episode 12, policy loss 0.018215864896774292\n",
      "\n",
      "episode 13, policy loss -0.062454793602228165\n",
      "\n",
      "episode 14, policy loss -0.016185186803340912\n",
      "\n",
      "episode 15, policy loss -0.055150967091321945\n",
      "\n",
      "episode 16, policy loss -0.04920379817485809\n",
      "\n",
      "Policy train loss in epoch 1:-0.02702244569809409\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.09162864834070206\n",
      "\n",
      "episode 2, policy loss -0.06184300035238266\n",
      "\n",
      "episode 3, policy loss -0.04975340887904167\n",
      "\n",
      "episode 4, policy loss -0.0005566997569985688\n",
      "\n",
      "episode 5, policy loss -0.011279476806521416\n",
      "\n",
      "episode 6, policy loss 0.013808853924274445\n",
      "\n",
      "episode 7, policy loss 0.0426735021173954\n",
      "\n",
      "episode 8, policy loss 0.02431699074804783\n",
      "\n",
      "episode 9, policy loss -0.05507764220237732\n",
      "\n",
      "episode 10, policy loss 0.018790630623698235\n",
      "\n",
      "episode 11, policy loss -0.07788421958684921\n",
      "\n",
      "episode 12, policy loss -0.0138322114944458\n",
      "\n",
      "episode 13, policy loss -0.041332829743623734\n",
      "\n",
      "episode 14, policy loss -0.026330046355724335\n",
      "\n",
      "episode 15, policy loss -0.03789140656590462\n",
      "\n",
      "episode 16, policy loss -0.06475349515676498\n",
      "\n",
      "Policy train loss in epoch 2:-0.02703581923924503\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.04959150031208992\n",
      "\n",
      "episode 2, policy loss 0.01396144274622202\n",
      "\n",
      "episode 3, policy loss -0.036807507276535034\n",
      "\n",
      "episode 4, policy loss -9.584045619703829e-05\n",
      "\n",
      "episode 5, policy loss -0.02706807292997837\n",
      "\n",
      "episode 6, policy loss -0.07771532982587814\n",
      "\n",
      "episode 7, policy loss -0.061498645693063736\n",
      "\n",
      "episode 8, policy loss 0.018344003707170486\n",
      "\n",
      "episode 9, policy loss -0.06445470452308655\n",
      "\n",
      "episode 10, policy loss 0.02441876381635666\n",
      "\n",
      "episode 11, policy loss -0.01587774232029915\n",
      "\n",
      "episode 12, policy loss -0.04300040379166603\n",
      "\n",
      "episode 13, policy loss -0.055816423147916794\n",
      "\n",
      "episode 14, policy loss -0.011961008422076702\n",
      "\n",
      "episode 15, policy loss 0.042972665280103683\n",
      "\n",
      "episode 16, policy loss -0.09250890463590622\n",
      "\n",
      "Policy train loss in epoch 3:-0.027293700486552552\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.18334656953811646\n",
      "\n",
      "episode 2, val func loss 0.22664353251457214\n",
      "\n",
      "episode 3, val func loss 0.16343705356121063\n",
      "\n",
      "episode 4, val func loss 0.18171526491641998\n",
      "\n",
      "episode 5, val func loss 0.19266657531261444\n",
      "\n",
      "episode 6, val func loss 0.18947461247444153\n",
      "\n",
      "episode 7, val func loss 0.14806653559207916\n",
      "\n",
      "episode 8, val func loss 0.21982283890247345\n",
      "\n",
      "episode 9, val func loss 0.14156970381736755\n",
      "\n",
      "episode 10, val func loss 0.20126231014728546\n",
      "\n",
      "episode 11, val func loss 0.20846889913082123\n",
      "\n",
      "episode 12, val func loss 0.20529411733150482\n",
      "\n",
      "episode 13, val func loss 0.19632430374622345\n",
      "\n",
      "episode 14, val func loss 0.14635254442691803\n",
      "\n",
      "episode 15, val func loss 0.1784353256225586\n",
      "\n",
      "episode 16, val func loss 0.1677384376525879\n",
      "\n",
      "Val func train loss in epoch 0:0.18441366404294968\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1470153033733368\n",
      "\n",
      "episode 2, val func loss 0.22158530354499817\n",
      "\n",
      "episode 3, val func loss 0.1830904185771942\n",
      "\n",
      "episode 4, val func loss 0.17645937204360962\n",
      "\n",
      "episode 5, val func loss 0.22770896553993225\n",
      "\n",
      "episode 6, val func loss 0.1416388750076294\n",
      "\n",
      "episode 7, val func loss 0.16320915520191193\n",
      "\n",
      "episode 8, val func loss 0.18004266917705536\n",
      "\n",
      "episode 9, val func loss 0.1960197538137436\n",
      "\n",
      "episode 10, val func loss 0.13993427157402039\n",
      "\n",
      "episode 11, val func loss 0.20660313963890076\n",
      "\n",
      "episode 12, val func loss 0.1914196014404297\n",
      "\n",
      "episode 13, val func loss 0.16646592319011688\n",
      "\n",
      "episode 14, val func loss 0.20061111450195312\n",
      "\n",
      "episode 15, val func loss 0.19189982116222382\n",
      "\n",
      "episode 16, val func loss 0.20798376202583313\n",
      "\n",
      "Val func train loss in epoch 1:0.18385546561330557\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.20807354152202606\n",
      "\n",
      "episode 2, val func loss 0.1476898491382599\n",
      "\n",
      "episode 3, val func loss 0.1488107144832611\n",
      "\n",
      "episode 4, val func loss 0.16281920671463013\n",
      "\n",
      "episode 5, val func loss 0.1392158716917038\n",
      "\n",
      "episode 6, val func loss 0.23336993157863617\n",
      "\n",
      "episode 7, val func loss 0.18526530265808105\n",
      "\n",
      "episode 8, val func loss 0.22484207153320312\n",
      "\n",
      "episode 9, val func loss 0.19011013209819794\n",
      "\n",
      "episode 10, val func loss 0.16882391273975372\n",
      "\n",
      "episode 11, val func loss 0.17830424010753632\n",
      "\n",
      "episode 12, val func loss 0.18396875262260437\n",
      "\n",
      "episode 13, val func loss 0.1894749402999878\n",
      "\n",
      "episode 14, val func loss 0.2016248255968094\n",
      "\n",
      "episode 15, val func loss 0.2047148197889328\n",
      "\n",
      "episode 16, val func loss 0.1965837925672531\n",
      "\n",
      "Val func train loss in epoch 2:0.1852307440713048\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.152177631855011\n",
      "\n",
      "episode 2, val func loss 0.17932844161987305\n",
      "\n",
      "episode 3, val func loss 0.1902172714471817\n",
      "\n",
      "episode 4, val func loss 0.1839892864227295\n",
      "\n",
      "episode 5, val func loss 0.22022904455661774\n",
      "\n",
      "episode 6, val func loss 0.20716506242752075\n",
      "\n",
      "episode 7, val func loss 0.20165452361106873\n",
      "\n",
      "episode 8, val func loss 0.16766245663166046\n",
      "\n",
      "episode 9, val func loss 0.1447882205247879\n",
      "\n",
      "episode 10, val func loss 0.16527025401592255\n",
      "\n",
      "episode 11, val func loss 0.14058248698711395\n",
      "\n",
      "episode 12, val func loss 0.18967172503471375\n",
      "\n",
      "episode 13, val func loss 0.19750648736953735\n",
      "\n",
      "episode 14, val func loss 0.22828291356563568\n",
      "\n",
      "episode 15, val func loss 0.18168969452381134\n",
      "\n",
      "episode 16, val func loss 0.21011091768741608\n",
      "\n",
      "Val func train loss in epoch 3:0.1850204011425376\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18913596868515015\n",
      "\n",
      "episode 2, val func loss 0.18003959953784943\n",
      "\n",
      "episode 3, val func loss 0.22246642410755157\n",
      "\n",
      "episode 4, val func loss 0.15265050530433655\n",
      "\n",
      "episode 5, val func loss 0.18541856110095978\n",
      "\n",
      "episode 6, val func loss 0.20511971414089203\n",
      "\n",
      "episode 7, val func loss 0.14332512021064758\n",
      "\n",
      "episode 8, val func loss 0.1450890451669693\n",
      "\n",
      "episode 9, val func loss 0.20890437066555023\n",
      "\n",
      "episode 10, val func loss 0.19638314843177795\n",
      "\n",
      "episode 11, val func loss 0.20232680439949036\n",
      "\n",
      "episode 12, val func loss 0.17642050981521606\n",
      "\n",
      "episode 13, val func loss 0.2219126969575882\n",
      "\n",
      "episode 14, val func loss 0.19331105053424835\n",
      "\n",
      "episode 15, val func loss 0.16802482306957245\n",
      "\n",
      "episode 16, val func loss 0.16529960930347443\n",
      "\n",
      "Val func train loss in epoch 4:0.18473924696445465\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.14125129580497742\n",
      "\n",
      "episode 2, val func loss 0.18018126487731934\n",
      "\n",
      "episode 3, val func loss 0.201937735080719\n",
      "\n",
      "episode 4, val func loss 0.18359282612800598\n",
      "\n",
      "episode 5, val func loss 0.17800982296466827\n",
      "\n",
      "episode 6, val func loss 0.20929129421710968\n",
      "\n",
      "episode 7, val func loss 0.16443867981433868\n",
      "\n",
      "episode 8, val func loss 0.19141732156276703\n",
      "\n",
      "episode 9, val func loss 0.1957998275756836\n",
      "\n",
      "episode 10, val func loss 0.1478527933359146\n",
      "\n",
      "episode 11, val func loss 0.22035475075244904\n",
      "\n",
      "episode 12, val func loss 0.14215897023677826\n",
      "\n",
      "episode 13, val func loss 0.18905924260616302\n",
      "\n",
      "episode 14, val func loss 0.22602027654647827\n",
      "\n",
      "episode 15, val func loss 0.16787637770175934\n",
      "\n",
      "episode 16, val func loss 0.20658043026924133\n",
      "\n",
      "Val func train loss in epoch 5:0.1841139318421483\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19018913805484772\n",
      "\n",
      "episode 2, val func loss 0.17974990606307983\n",
      "\n",
      "episode 3, val func loss 0.19123166799545288\n",
      "\n",
      "episode 4, val func loss 0.15356889367103577\n",
      "\n",
      "episode 5, val func loss 0.22198930382728577\n",
      "\n",
      "episode 6, val func loss 0.20851771533489227\n",
      "\n",
      "episode 7, val func loss 0.2049390971660614\n",
      "\n",
      "episode 8, val func loss 0.18459950387477875\n",
      "\n",
      "episode 9, val func loss 0.16640138626098633\n",
      "\n",
      "episode 10, val func loss 0.1411665380001068\n",
      "\n",
      "episode 11, val func loss 0.22037597000598907\n",
      "\n",
      "episode 12, val func loss 0.14105728268623352\n",
      "\n",
      "episode 13, val func loss 0.19672748446464539\n",
      "\n",
      "episode 14, val func loss 0.17674989998340607\n",
      "\n",
      "episode 15, val func loss 0.20447930693626404\n",
      "\n",
      "episode 16, val func loss 0.1693301647901535\n",
      "\n",
      "Val func train loss in epoch 6:0.1844420786947012\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1816110610961914\n",
      "\n",
      "episode 2, val func loss 0.1916431337594986\n",
      "\n",
      "episode 3, val func loss 0.1963571459054947\n",
      "\n",
      "episode 4, val func loss 0.14516812562942505\n",
      "\n",
      "episode 5, val func loss 0.2181328982114792\n",
      "\n",
      "episode 6, val func loss 0.17934712767601013\n",
      "\n",
      "episode 7, val func loss 0.20857633650302887\n",
      "\n",
      "episode 8, val func loss 0.1452975869178772\n",
      "\n",
      "episode 9, val func loss 0.18946422636508942\n",
      "\n",
      "episode 10, val func loss 0.16348592936992645\n",
      "\n",
      "episode 11, val func loss 0.22694024443626404\n",
      "\n",
      "episode 12, val func loss 0.16918672621250153\n",
      "\n",
      "episode 13, val func loss 0.20334331691265106\n",
      "\n",
      "episode 14, val func loss 0.18334351480007172\n",
      "\n",
      "episode 15, val func loss 0.2079368233680725\n",
      "\n",
      "episode 16, val func loss 0.14863009750843048\n",
      "\n",
      "Val func train loss in epoch 7:0.18490401841700077\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1959407478570938\n",
      "\n",
      "episode 2, val func loss 0.2233363837003708\n",
      "\n",
      "episode 3, val func loss 0.17770373821258545\n",
      "\n",
      "episode 4, val func loss 0.17879857122898102\n",
      "\n",
      "episode 5, val func loss 0.2171805500984192\n",
      "\n",
      "episode 6, val func loss 0.15232059359550476\n",
      "\n",
      "episode 7, val func loss 0.18865938484668732\n",
      "\n",
      "episode 8, val func loss 0.20232756435871124\n",
      "\n",
      "episode 9, val func loss 0.1696513593196869\n",
      "\n",
      "episode 10, val func loss 0.183697909116745\n",
      "\n",
      "episode 11, val func loss 0.14034180343151093\n",
      "\n",
      "episode 12, val func loss 0.18995442986488342\n",
      "\n",
      "episode 13, val func loss 0.14183948934078217\n",
      "\n",
      "episode 14, val func loss 0.20870356261730194\n",
      "\n",
      "episode 15, val func loss 0.21070292592048645\n",
      "\n",
      "episode 16, val func loss 0.16362428665161133\n",
      "\n",
      "Val func train loss in epoch 8:0.1840489562600851\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.14114300906658173\n",
      "\n",
      "episode 2, val func loss 0.16294483840465546\n",
      "\n",
      "episode 3, val func loss 0.18316718935966492\n",
      "\n",
      "episode 4, val func loss 0.182113915681839\n",
      "\n",
      "episode 5, val func loss 0.1688801348209381\n",
      "\n",
      "episode 6, val func loss 0.19606752693653107\n",
      "\n",
      "episode 7, val func loss 0.20942570269107819\n",
      "\n",
      "episode 8, val func loss 0.20569287240505219\n",
      "\n",
      "episode 9, val func loss 0.2186180055141449\n",
      "\n",
      "episode 10, val func loss 0.20197319984436035\n",
      "\n",
      "episode 11, val func loss 0.14880789816379547\n",
      "\n",
      "episode 12, val func loss 0.18097861111164093\n",
      "\n",
      "episode 13, val func loss 0.15093103051185608\n",
      "\n",
      "episode 14, val func loss 0.18940918147563934\n",
      "\n",
      "episode 15, val func loss 0.18870320916175842\n",
      "\n",
      "episode 16, val func loss 0.2254747897386551\n",
      "\n",
      "Val func train loss in epoch 9:0.18464569468051195\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.22512619197368622\n",
      "\n",
      "episode 2, val func loss 0.19664497673511505\n",
      "\n",
      "episode 3, val func loss 0.20645757019519806\n",
      "\n",
      "episode 4, val func loss 0.18387630581855774\n",
      "\n",
      "episode 5, val func loss 0.2045111507177353\n",
      "\n",
      "episode 6, val func loss 0.2178371101617813\n",
      "\n",
      "episode 7, val func loss 0.14643603563308716\n",
      "\n",
      "episode 8, val func loss 0.1523486226797104\n",
      "\n",
      "episode 9, val func loss 0.1771969199180603\n",
      "\n",
      "episode 10, val func loss 0.1631099283695221\n",
      "\n",
      "episode 11, val func loss 0.19221094250679016\n",
      "\n",
      "episode 12, val func loss 0.13890431821346283\n",
      "\n",
      "episode 13, val func loss 0.20090599358081818\n",
      "\n",
      "episode 14, val func loss 0.171411395072937\n",
      "\n",
      "episode 15, val func loss 0.20322273671627045\n",
      "\n",
      "episode 16, val func loss 0.1803073137998581\n",
      "\n",
      "Val func train loss in epoch 10:0.1850317195057869\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.2098241150379181\n",
      "\n",
      "episode 2, val func loss 0.14879105985164642\n",
      "\n",
      "episode 3, val func loss 0.2225431352853775\n",
      "\n",
      "episode 4, val func loss 0.19022394716739655\n",
      "\n",
      "episode 5, val func loss 0.20592167973518372\n",
      "\n",
      "episode 6, val func loss 0.2191055566072464\n",
      "\n",
      "episode 7, val func loss 0.18386921286582947\n",
      "\n",
      "episode 8, val func loss 0.16823309659957886\n",
      "\n",
      "episode 9, val func loss 0.14978663623332977\n",
      "\n",
      "episode 10, val func loss 0.18005608022212982\n",
      "\n",
      "episode 11, val func loss 0.16421523690223694\n",
      "\n",
      "episode 12, val func loss 0.17646117508411407\n",
      "\n",
      "episode 13, val func loss 0.19703683257102966\n",
      "\n",
      "episode 14, val func loss 0.19390977919101715\n",
      "\n",
      "episode 15, val func loss 0.14068670570850372\n",
      "\n",
      "episode 16, val func loss 0.20304980874061584\n",
      "\n",
      "Val func train loss in epoch 11:0.18460712861269712\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.2089775651693344\n",
      "\n",
      "episode 2, val func loss 0.18081903457641602\n",
      "\n",
      "episode 3, val func loss 0.1891942024230957\n",
      "\n",
      "episode 4, val func loss 0.16818755865097046\n",
      "\n",
      "episode 5, val func loss 0.1849435269832611\n",
      "\n",
      "episode 6, val func loss 0.16683854162693024\n",
      "\n",
      "episode 7, val func loss 0.20861037075519562\n",
      "\n",
      "episode 8, val func loss 0.21919995546340942\n",
      "\n",
      "episode 9, val func loss 0.17827992141246796\n",
      "\n",
      "episode 10, val func loss 0.19043400883674622\n",
      "\n",
      "episode 11, val func loss 0.14121754467487335\n",
      "\n",
      "episode 12, val func loss 0.14317463338375092\n",
      "\n",
      "episode 13, val func loss 0.14689385890960693\n",
      "\n",
      "episode 14, val func loss 0.19707246124744415\n",
      "\n",
      "episode 15, val func loss 0.20364981889724731\n",
      "\n",
      "episode 16, val func loss 0.2288428395986557\n",
      "\n",
      "Val func train loss in epoch 12:0.18477099016308784\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18210247159004211\n",
      "\n",
      "episode 2, val func loss 0.16320575773715973\n",
      "\n",
      "episode 3, val func loss 0.20938268303871155\n",
      "\n",
      "episode 4, val func loss 0.16847586631774902\n",
      "\n",
      "episode 5, val func loss 0.20183555781841278\n",
      "\n",
      "episode 6, val func loss 0.14513498544692993\n",
      "\n",
      "episode 7, val func loss 0.18423673510551453\n",
      "\n",
      "episode 8, val func loss 0.17873777449131012\n",
      "\n",
      "episode 9, val func loss 0.21959413588047028\n",
      "\n",
      "episode 10, val func loss 0.22368018329143524\n",
      "\n",
      "episode 11, val func loss 0.20620404183864594\n",
      "\n",
      "episode 12, val func loss 0.19608904421329498\n",
      "\n",
      "episode 13, val func loss 0.18962378799915314\n",
      "\n",
      "episode 14, val func loss 0.14306755363941193\n",
      "\n",
      "episode 15, val func loss 0.1897697001695633\n",
      "\n",
      "episode 16, val func loss 0.15015730261802673\n",
      "\n",
      "Val func train loss in epoch 13:0.18445609882473946\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.20847292244434357\n",
      "\n",
      "episode 2, val func loss 0.1651875376701355\n",
      "\n",
      "episode 3, val func loss 0.19136148691177368\n",
      "\n",
      "episode 4, val func loss 0.20720958709716797\n",
      "\n",
      "episode 5, val func loss 0.1403854787349701\n",
      "\n",
      "episode 6, val func loss 0.14172396063804626\n",
      "\n",
      "episode 7, val func loss 0.1768389642238617\n",
      "\n",
      "episode 8, val func loss 0.22724013030529022\n",
      "\n",
      "episode 9, val func loss 0.19661526381969452\n",
      "\n",
      "episode 10, val func loss 0.18324902653694153\n",
      "\n",
      "episode 11, val func loss 0.2020873874425888\n",
      "\n",
      "episode 12, val func loss 0.16857199370861053\n",
      "\n",
      "episode 13, val func loss 0.1898050755262375\n",
      "\n",
      "episode 14, val func loss 0.1489497870206833\n",
      "\n",
      "episode 15, val func loss 0.21871666610240936\n",
      "\n",
      "episode 16, val func loss 0.1798257678747177\n",
      "\n",
      "Val func train loss in epoch 14:0.18414006475359201\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.14464923739433289\n",
      "\n",
      "episode 2, val func loss 0.14899058640003204\n",
      "\n",
      "episode 3, val func loss 0.20179308950901031\n",
      "\n",
      "episode 4, val func loss 0.1681322455406189\n",
      "\n",
      "episode 5, val func loss 0.1766933649778366\n",
      "\n",
      "episode 6, val func loss 0.21013092994689941\n",
      "\n",
      "episode 7, val func loss 0.18965788185596466\n",
      "\n",
      "episode 8, val func loss 0.2082339972257614\n",
      "\n",
      "episode 9, val func loss 0.16315393149852753\n",
      "\n",
      "episode 10, val func loss 0.18040889501571655\n",
      "\n",
      "episode 11, val func loss 0.14068837463855743\n",
      "\n",
      "episode 12, val func loss 0.2243080735206604\n",
      "\n",
      "episode 13, val func loss 0.21848122775554657\n",
      "\n",
      "episode 14, val func loss 0.19053049385547638\n",
      "\n",
      "episode 15, val func loss 0.18394479155540466\n",
      "\n",
      "episode 16, val func loss 0.1963050663471222\n",
      "\n",
      "Val func train loss in epoch 15:0.18413138668984175\n",
      "***********************TIME WAS 4.940379778544108 min*****************************\n",
      "\n",
      "**********************ROUND 71 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.018025681376457214\n",
      "\n",
      "episode 2, policy loss 0.04026523977518082\n",
      "\n",
      "episode 3, policy loss -0.006093695759773254\n",
      "\n",
      "episode 4, policy loss -0.014878310263156891\n",
      "\n",
      "episode 5, policy loss -0.019557660445570946\n",
      "\n",
      "episode 6, policy loss -0.03833214193582535\n",
      "\n",
      "episode 7, policy loss 0.022135380655527115\n",
      "\n",
      "episode 8, policy loss -0.017270531505346298\n",
      "\n",
      "episode 9, policy loss -0.028239313513040543\n",
      "\n",
      "episode 10, policy loss -0.0006940191960893571\n",
      "\n",
      "episode 11, policy loss -0.007777565624564886\n",
      "\n",
      "episode 12, policy loss 0.05344610661268234\n",
      "\n",
      "episode 13, policy loss -0.005633391439914703\n",
      "\n",
      "episode 14, policy loss -0.03967029228806496\n",
      "\n",
      "episode 15, policy loss 0.004255610052496195\n",
      "\n",
      "episode 16, policy loss 0.03984120115637779\n",
      "\n",
      "Policy train loss in epoch 0:-1.1106396414106712e-05\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.033316921442747116\n",
      "\n",
      "episode 2, policy loss -0.03288211300969124\n",
      "\n",
      "episode 3, policy loss -0.0207962766289711\n",
      "\n",
      "episode 4, policy loss 0.053011711686849594\n",
      "\n",
      "episode 5, policy loss -0.018188711255788803\n",
      "\n",
      "episode 6, policy loss 0.0358394980430603\n",
      "\n",
      "episode 7, policy loss -0.012087632901966572\n",
      "\n",
      "episode 8, policy loss -0.016319358721375465\n",
      "\n",
      "episode 9, policy loss -0.005208917893469334\n",
      "\n",
      "episode 10, policy loss -0.03848525509238243\n",
      "\n",
      "episode 11, policy loss -0.03771296143531799\n",
      "\n",
      "episode 12, policy loss -0.0022620081435889006\n",
      "\n",
      "episode 13, policy loss -0.00653996504843235\n",
      "\n",
      "episode 14, policy loss 0.01840955950319767\n",
      "\n",
      "episode 15, policy loss 0.009285730309784412\n",
      "\n",
      "episode 16, policy loss 0.0028256087098270655\n",
      "\n",
      "Policy train loss in epoch 1:-0.0023621356522198766\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.03672490641474724\n",
      "\n",
      "episode 2, policy loss 0.05295783653855324\n",
      "\n",
      "episode 3, policy loss 0.0043531847186386585\n",
      "\n",
      "episode 4, policy loss -0.03782707080245018\n",
      "\n",
      "episode 5, policy loss -0.0033364281989634037\n",
      "\n",
      "episode 6, policy loss -0.0032765809446573257\n",
      "\n",
      "episode 7, policy loss -0.03370882570743561\n",
      "\n",
      "episode 8, policy loss -0.018562061712145805\n",
      "\n",
      "episode 9, policy loss 0.020032735541462898\n",
      "\n",
      "episode 10, policy loss -0.017223909497261047\n",
      "\n",
      "episode 11, policy loss -0.009586119093000889\n",
      "\n",
      "episode 12, policy loss -0.04148811101913452\n",
      "\n",
      "episode 13, policy loss -0.020585978403687477\n",
      "\n",
      "episode 14, policy loss 0.03077824041247368\n",
      "\n",
      "episode 15, policy loss 0.008011669851839542\n",
      "\n",
      "episode 16, policy loss -0.010887796990573406\n",
      "\n",
      "Policy train loss in epoch 2:-0.0027265193057246506\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.011722451075911522\n",
      "\n",
      "episode 2, policy loss 0.018984606489539146\n",
      "\n",
      "episode 3, policy loss -0.03394325077533722\n",
      "\n",
      "episode 4, policy loss 0.008675682358443737\n",
      "\n",
      "episode 5, policy loss -0.04071139171719551\n",
      "\n",
      "episode 6, policy loss -0.02150162123143673\n",
      "\n",
      "episode 7, policy loss -0.004036108497530222\n",
      "\n",
      "episode 8, policy loss -0.019735652953386307\n",
      "\n",
      "episode 9, policy loss 0.0352303571999073\n",
      "\n",
      "episode 10, policy loss 0.0026540968101471663\n",
      "\n",
      "episode 11, policy loss -0.040492456406354904\n",
      "\n",
      "episode 12, policy loss -0.01822124794125557\n",
      "\n",
      "episode 13, policy loss -0.004454719368368387\n",
      "\n",
      "episode 14, policy loss -0.009627621620893478\n",
      "\n",
      "episode 15, policy loss 0.051273491233587265\n",
      "\n",
      "episode 16, policy loss 0.03069981560111046\n",
      "\n",
      "Policy train loss in epoch 3:-0.0035580294934334233\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.18959538638591766\n",
      "\n",
      "episode 2, val func loss 0.18976521492004395\n",
      "\n",
      "episode 3, val func loss 0.2060106098651886\n",
      "\n",
      "episode 4, val func loss 0.18132901191711426\n",
      "\n",
      "episode 5, val func loss 0.18176910281181335\n",
      "\n",
      "episode 6, val func loss 0.20454639196395874\n",
      "\n",
      "episode 7, val func loss 0.19172705709934235\n",
      "\n",
      "episode 8, val func loss 0.18169832229614258\n",
      "\n",
      "episode 9, val func loss 0.18943336606025696\n",
      "\n",
      "episode 10, val func loss 0.2276555448770523\n",
      "\n",
      "episode 11, val func loss 0.1954464465379715\n",
      "\n",
      "episode 12, val func loss 0.18475358188152313\n",
      "\n",
      "episode 13, val func loss 0.16090048849582672\n",
      "\n",
      "episode 14, val func loss 0.16248096525669098\n",
      "\n",
      "episode 15, val func loss 0.20973116159439087\n",
      "\n",
      "episode 16, val func loss 0.1929216831922531\n",
      "\n",
      "Val func train loss in epoch 0:0.19061027094721794\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18783988058567047\n",
      "\n",
      "episode 2, val func loss 0.16833573579788208\n",
      "\n",
      "episode 3, val func loss 0.1982259303331375\n",
      "\n",
      "episode 4, val func loss 0.19025668501853943\n",
      "\n",
      "episode 5, val func loss 0.18734243512153625\n",
      "\n",
      "episode 6, val func loss 0.19469775259494781\n",
      "\n",
      "episode 7, val func loss 0.21247921884059906\n",
      "\n",
      "episode 8, val func loss 0.18867959082126617\n",
      "\n",
      "episode 9, val func loss 0.18265709280967712\n",
      "\n",
      "episode 10, val func loss 0.2054581642150879\n",
      "\n",
      "episode 11, val func loss 0.18971054255962372\n",
      "\n",
      "episode 12, val func loss 0.16428722441196442\n",
      "\n",
      "episode 13, val func loss 0.19046807289123535\n",
      "\n",
      "episode 14, val func loss 0.18377287685871124\n",
      "\n",
      "episode 15, val func loss 0.20705021917819977\n",
      "\n",
      "episode 16, val func loss 0.22554516792297363\n",
      "\n",
      "Val func train loss in epoch 1:0.19230041187256575\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.2103336602449417\n",
      "\n",
      "episode 2, val func loss 0.1626608669757843\n",
      "\n",
      "episode 3, val func loss 0.1908450722694397\n",
      "\n",
      "episode 4, val func loss 0.1841670125722885\n",
      "\n",
      "episode 5, val func loss 0.1944681704044342\n",
      "\n",
      "episode 6, val func loss 0.19266997277736664\n",
      "\n",
      "episode 7, val func loss 0.18219152092933655\n",
      "\n",
      "episode 8, val func loss 0.16514524817466736\n",
      "\n",
      "episode 9, val func loss 0.19536837935447693\n",
      "\n",
      "episode 10, val func loss 0.1865392029285431\n",
      "\n",
      "episode 11, val func loss 0.22539763152599335\n",
      "\n",
      "episode 12, val func loss 0.18999549746513367\n",
      "\n",
      "episode 13, val func loss 0.20641016960144043\n",
      "\n",
      "episode 14, val func loss 0.19007745385169983\n",
      "\n",
      "episode 15, val func loss 0.18137431144714355\n",
      "\n",
      "episode 16, val func loss 0.20572927594184875\n",
      "\n",
      "Val func train loss in epoch 2:0.19146084040403366\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.21072062849998474\n",
      "\n",
      "episode 2, val func loss 0.19119781255722046\n",
      "\n",
      "episode 3, val func loss 0.19289250671863556\n",
      "\n",
      "episode 4, val func loss 0.1941308230161667\n",
      "\n",
      "episode 5, val func loss 0.1952558010816574\n",
      "\n",
      "episode 6, val func loss 0.18515333533287048\n",
      "\n",
      "episode 7, val func loss 0.2064095139503479\n",
      "\n",
      "episode 8, val func loss 0.20603406429290771\n",
      "\n",
      "episode 9, val func loss 0.1666829138994217\n",
      "\n",
      "episode 10, val func loss 0.18954716622829437\n",
      "\n",
      "episode 11, val func loss 0.1817774772644043\n",
      "\n",
      "episode 12, val func loss 0.1802065521478653\n",
      "\n",
      "episode 13, val func loss 0.22404421865940094\n",
      "\n",
      "episode 14, val func loss 0.19011282920837402\n",
      "\n",
      "episode 15, val func loss 0.18585428595542908\n",
      "\n",
      "episode 16, val func loss 0.162367582321167\n",
      "\n",
      "Val func train loss in epoch 3:0.19139921944588423\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18273349106311798\n",
      "\n",
      "episode 2, val func loss 0.22558455169200897\n",
      "\n",
      "episode 3, val func loss 0.185988187789917\n",
      "\n",
      "episode 4, val func loss 0.1913587599992752\n",
      "\n",
      "episode 5, val func loss 0.1903453916311264\n",
      "\n",
      "episode 6, val func loss 0.20649676024913788\n",
      "\n",
      "episode 7, val func loss 0.1928095668554306\n",
      "\n",
      "episode 8, val func loss 0.1948556900024414\n",
      "\n",
      "episode 9, val func loss 0.1830236166715622\n",
      "\n",
      "episode 10, val func loss 0.2105170637369156\n",
      "\n",
      "episode 11, val func loss 0.16560666263103485\n",
      "\n",
      "episode 12, val func loss 0.18510450422763824\n",
      "\n",
      "episode 13, val func loss 0.19110853970050812\n",
      "\n",
      "episode 14, val func loss 0.20878992974758148\n",
      "\n",
      "episode 15, val func loss 0.1624114215373993\n",
      "\n",
      "episode 16, val func loss 0.19632619619369507\n",
      "\n",
      "Val func train loss in epoch 4:0.1920662708580494\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19285371899604797\n",
      "\n",
      "episode 2, val func loss 0.18384608626365662\n",
      "\n",
      "episode 3, val func loss 0.2064099907875061\n",
      "\n",
      "episode 4, val func loss 0.16590982675552368\n",
      "\n",
      "episode 5, val func loss 0.19461941719055176\n",
      "\n",
      "episode 6, val func loss 0.2050427943468094\n",
      "\n",
      "episode 7, val func loss 0.188080832362175\n",
      "\n",
      "episode 8, val func loss 0.16495415568351746\n",
      "\n",
      "episode 9, val func loss 0.19489768147468567\n",
      "\n",
      "episode 10, val func loss 0.18170307576656342\n",
      "\n",
      "episode 11, val func loss 0.1895463466644287\n",
      "\n",
      "episode 12, val func loss 0.19067613780498505\n",
      "\n",
      "episode 13, val func loss 0.21171176433563232\n",
      "\n",
      "episode 14, val func loss 0.19132418930530548\n",
      "\n",
      "episode 15, val func loss 0.18308213353157043\n",
      "\n",
      "episode 16, val func loss 0.22548960149288177\n",
      "\n",
      "Val func train loss in epoch 5:0.19188423454761505\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18137693405151367\n",
      "\n",
      "episode 2, val func loss 0.2063436359167099\n",
      "\n",
      "episode 3, val func loss 0.19176144897937775\n",
      "\n",
      "episode 4, val func loss 0.19057580828666687\n",
      "\n",
      "episode 5, val func loss 0.1673479527235031\n",
      "\n",
      "episode 6, val func loss 0.21019993722438812\n",
      "\n",
      "episode 7, val func loss 0.1885565221309662\n",
      "\n",
      "episode 8, val func loss 0.1900823414325714\n",
      "\n",
      "episode 9, val func loss 0.20683002471923828\n",
      "\n",
      "episode 10, val func loss 0.19259685277938843\n",
      "\n",
      "episode 11, val func loss 0.22515836358070374\n",
      "\n",
      "episode 12, val func loss 0.17899677157402039\n",
      "\n",
      "episode 13, val func loss 0.16354675590991974\n",
      "\n",
      "episode 14, val func loss 0.1963758021593094\n",
      "\n",
      "episode 15, val func loss 0.1829380989074707\n",
      "\n",
      "episode 16, val func loss 0.19639845192432404\n",
      "\n",
      "Val func train loss in epoch 6:0.19181785639375448\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.2113667130470276\n",
      "\n",
      "episode 2, val func loss 0.19113221764564514\n",
      "\n",
      "episode 3, val func loss 0.20577885210514069\n",
      "\n",
      "episode 4, val func loss 0.18650799989700317\n",
      "\n",
      "episode 5, val func loss 0.16738642752170563\n",
      "\n",
      "episode 6, val func loss 0.1930830180644989\n",
      "\n",
      "episode 7, val func loss 0.1865464597940445\n",
      "\n",
      "episode 8, val func loss 0.1884898990392685\n",
      "\n",
      "episode 9, val func loss 0.192372664809227\n",
      "\n",
      "episode 10, val func loss 0.1773276925086975\n",
      "\n",
      "episode 11, val func loss 0.22634625434875488\n",
      "\n",
      "episode 12, val func loss 0.1930929720401764\n",
      "\n",
      "episode 13, val func loss 0.16372427344322205\n",
      "\n",
      "episode 14, val func loss 0.2068348526954651\n",
      "\n",
      "episode 15, val func loss 0.183929443359375\n",
      "\n",
      "episode 16, val func loss 0.19145816564559937\n",
      "\n",
      "Val func train loss in epoch 7:0.1915861191228032\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.20187002420425415\n",
      "\n",
      "episode 2, val func loss 0.1884518265724182\n",
      "\n",
      "episode 3, val func loss 0.2199142575263977\n",
      "\n",
      "episode 4, val func loss 0.18893387913703918\n",
      "\n",
      "episode 5, val func loss 0.16884179413318634\n",
      "\n",
      "episode 6, val func loss 0.20987121760845184\n",
      "\n",
      "episode 7, val func loss 0.18878349661827087\n",
      "\n",
      "episode 8, val func loss 0.1641472578048706\n",
      "\n",
      "episode 9, val func loss 0.2098541557788849\n",
      "\n",
      "episode 10, val func loss 0.18232600390911102\n",
      "\n",
      "episode 11, val func loss 0.18532612919807434\n",
      "\n",
      "episode 12, val func loss 0.1852620244026184\n",
      "\n",
      "episode 13, val func loss 0.19326721131801605\n",
      "\n",
      "episode 14, val func loss 0.17853981256484985\n",
      "\n",
      "episode 15, val func loss 0.19711679220199585\n",
      "\n",
      "episode 16, val func loss 0.19426828622817993\n",
      "\n",
      "Val func train loss in epoch 8:0.1910483855754137\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.19563594460487366\n",
      "\n",
      "episode 2, val func loss 0.21049274504184723\n",
      "\n",
      "episode 3, val func loss 0.18306471407413483\n",
      "\n",
      "episode 4, val func loss 0.1889791041612625\n",
      "\n",
      "episode 5, val func loss 0.18264377117156982\n",
      "\n",
      "episode 6, val func loss 0.1896859109401703\n",
      "\n",
      "episode 7, val func loss 0.16380572319030762\n",
      "\n",
      "episode 8, val func loss 0.18690963089466095\n",
      "\n",
      "episode 9, val func loss 0.16155126690864563\n",
      "\n",
      "episode 10, val func loss 0.19975852966308594\n",
      "\n",
      "episode 11, val func loss 0.22762365639209747\n",
      "\n",
      "episode 12, val func loss 0.18191935122013092\n",
      "\n",
      "episode 13, val func loss 0.2061205804347992\n",
      "\n",
      "episode 14, val func loss 0.19228453934192657\n",
      "\n",
      "episode 15, val func loss 0.2033325880765915\n",
      "\n",
      "episode 16, val func loss 0.1901770532131195\n",
      "\n",
      "Val func train loss in epoch 9:0.19149906933307648\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.22199299931526184\n",
      "\n",
      "episode 2, val func loss 0.18663085997104645\n",
      "\n",
      "episode 3, val func loss 0.19555599987506866\n",
      "\n",
      "episode 4, val func loss 0.19066601991653442\n",
      "\n",
      "episode 5, val func loss 0.1887841820716858\n",
      "\n",
      "episode 6, val func loss 0.16201046109199524\n",
      "\n",
      "episode 7, val func loss 0.1930748075246811\n",
      "\n",
      "episode 8, val func loss 0.21195043623447418\n",
      "\n",
      "episode 9, val func loss 0.19353988766670227\n",
      "\n",
      "episode 10, val func loss 0.1626901626586914\n",
      "\n",
      "episode 11, val func loss 0.20744481682777405\n",
      "\n",
      "episode 12, val func loss 0.1822875440120697\n",
      "\n",
      "episode 13, val func loss 0.18716445565223694\n",
      "\n",
      "episode 14, val func loss 0.19407245516777039\n",
      "\n",
      "episode 15, val func loss 0.19438129663467407\n",
      "\n",
      "episode 16, val func loss 0.21001020073890686\n",
      "\n",
      "Val func train loss in epoch 10:0.19264103658497334\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18453995883464813\n",
      "\n",
      "episode 2, val func loss 0.18174511194229126\n",
      "\n",
      "episode 3, val func loss 0.20546680688858032\n",
      "\n",
      "episode 4, val func loss 0.1941177397966385\n",
      "\n",
      "episode 5, val func loss 0.20427438616752625\n",
      "\n",
      "episode 6, val func loss 0.19266219437122345\n",
      "\n",
      "episode 7, val func loss 0.19341054558753967\n",
      "\n",
      "episode 8, val func loss 0.22120948135852814\n",
      "\n",
      "episode 9, val func loss 0.16632713377475739\n",
      "\n",
      "episode 10, val func loss 0.2083761990070343\n",
      "\n",
      "episode 11, val func loss 0.17918337881565094\n",
      "\n",
      "episode 12, val func loss 0.18377617001533508\n",
      "\n",
      "episode 13, val func loss 0.1977023035287857\n",
      "\n",
      "episode 14, val func loss 0.16423150897026062\n",
      "\n",
      "episode 15, val func loss 0.19014711678028107\n",
      "\n",
      "episode 16, val func loss 0.19106699526309967\n",
      "\n",
      "Val func train loss in epoch 11:0.19113981444388628\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18529170751571655\n",
      "\n",
      "episode 2, val func loss 0.18957437574863434\n",
      "\n",
      "episode 3, val func loss 0.16346429288387299\n",
      "\n",
      "episode 4, val func loss 0.16101974248886108\n",
      "\n",
      "episode 5, val func loss 0.19325818121433258\n",
      "\n",
      "episode 6, val func loss 0.22256192564964294\n",
      "\n",
      "episode 7, val func loss 0.20630167424678802\n",
      "\n",
      "episode 8, val func loss 0.18124859035015106\n",
      "\n",
      "episode 9, val func loss 0.192237988114357\n",
      "\n",
      "episode 10, val func loss 0.2150232046842575\n",
      "\n",
      "episode 11, val func loss 0.20477692782878876\n",
      "\n",
      "episode 12, val func loss 0.19757144153118134\n",
      "\n",
      "episode 13, val func loss 0.1910506635904312\n",
      "\n",
      "episode 14, val func loss 0.1897696703672409\n",
      "\n",
      "episode 15, val func loss 0.18139943480491638\n",
      "\n",
      "episode 16, val func loss 0.1816069632768631\n",
      "\n",
      "Val func train loss in epoch 12:0.19100979901850224\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.20656295120716095\n",
      "\n",
      "episode 2, val func loss 0.19253461062908173\n",
      "\n",
      "episode 3, val func loss 0.17988252639770508\n",
      "\n",
      "episode 4, val func loss 0.20732909440994263\n",
      "\n",
      "episode 5, val func loss 0.18430443108081818\n",
      "\n",
      "episode 6, val func loss 0.18221451342105865\n",
      "\n",
      "episode 7, val func loss 0.2098296880722046\n",
      "\n",
      "episode 8, val func loss 0.1959095448255539\n",
      "\n",
      "episode 9, val func loss 0.16555103659629822\n",
      "\n",
      "episode 10, val func loss 0.19036757946014404\n",
      "\n",
      "episode 11, val func loss 0.19083701074123383\n",
      "\n",
      "episode 12, val func loss 0.18618330359458923\n",
      "\n",
      "episode 13, val func loss 0.19564929604530334\n",
      "\n",
      "episode 14, val func loss 0.16378936171531677\n",
      "\n",
      "episode 15, val func loss 0.18975910544395447\n",
      "\n",
      "episode 16, val func loss 0.2239583134651184\n",
      "\n",
      "Val func train loss in epoch 13:0.19154139794409275\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.20795196294784546\n",
      "\n",
      "episode 2, val func loss 0.16421636939048767\n",
      "\n",
      "episode 3, val func loss 0.16623730957508087\n",
      "\n",
      "episode 4, val func loss 0.19130052626132965\n",
      "\n",
      "episode 5, val func loss 0.2060730755329132\n",
      "\n",
      "episode 6, val func loss 0.19538797438144684\n",
      "\n",
      "episode 7, val func loss 0.1932748556137085\n",
      "\n",
      "episode 8, val func loss 0.18471133708953857\n",
      "\n",
      "episode 9, val func loss 0.1794155240058899\n",
      "\n",
      "episode 10, val func loss 0.18950094282627106\n",
      "\n",
      "episode 11, val func loss 0.21181610226631165\n",
      "\n",
      "episode 12, val func loss 0.19071917235851288\n",
      "\n",
      "episode 13, val func loss 0.22554874420166016\n",
      "\n",
      "episode 14, val func loss 0.1899566948413849\n",
      "\n",
      "episode 15, val func loss 0.187594935297966\n",
      "\n",
      "episode 16, val func loss 0.18254736065864563\n",
      "\n",
      "Val func train loss in epoch 14:0.19164080545306206\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18913806974887848\n",
      "\n",
      "episode 2, val func loss 0.1835443526506424\n",
      "\n",
      "episode 3, val func loss 0.1810036152601242\n",
      "\n",
      "episode 4, val func loss 0.20983177423477173\n",
      "\n",
      "episode 5, val func loss 0.16352079808712006\n",
      "\n",
      "episode 6, val func loss 0.1886613368988037\n",
      "\n",
      "episode 7, val func loss 0.18711231648921967\n",
      "\n",
      "episode 8, val func loss 0.2072676420211792\n",
      "\n",
      "episode 9, val func loss 0.19482210278511047\n",
      "\n",
      "episode 10, val func loss 0.19171765446662903\n",
      "\n",
      "episode 11, val func loss 0.16622142493724823\n",
      "\n",
      "episode 12, val func loss 0.17972597479820251\n",
      "\n",
      "episode 13, val func loss 0.22526873648166656\n",
      "\n",
      "episode 14, val func loss 0.2064386010169983\n",
      "\n",
      "episode 15, val func loss 0.18995556235313416\n",
      "\n",
      "episode 16, val func loss 0.19463913142681122\n",
      "\n",
      "Val func train loss in epoch 15:0.19117931835353374\n",
      "***********************TIME WAS 4.946601537863414 min*****************************\n",
      "\n",
      "**********************ROUND 72 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.07529646903276443\n",
      "\n",
      "episode 2, policy loss -0.02517259679734707\n",
      "\n",
      "episode 3, policy loss -0.020762065425515175\n",
      "\n",
      "episode 4, policy loss 0.02687723934650421\n",
      "\n",
      "episode 5, policy loss 0.04297918081283569\n",
      "\n",
      "episode 6, policy loss -0.059761811047792435\n",
      "\n",
      "episode 7, policy loss 0.005579634569585323\n",
      "\n",
      "episode 8, policy loss -0.03211803734302521\n",
      "\n",
      "episode 9, policy loss -0.04599541053175926\n",
      "\n",
      "episode 10, policy loss -0.029810309410095215\n",
      "\n",
      "episode 11, policy loss 0.08909260481595993\n",
      "\n",
      "episode 12, policy loss 0.011504477821290493\n",
      "\n",
      "episode 13, policy loss 0.054068226367235184\n",
      "\n",
      "episode 14, policy loss 0.01329757459461689\n",
      "\n",
      "episode 15, policy loss 0.05642661452293396\n",
      "\n",
      "episode 16, policy loss 0.01610104739665985\n",
      "\n",
      "Policy train loss in epoch 0:0.0016881187912076712\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.012539796531200409\n",
      "\n",
      "episode 2, policy loss -0.033597514033317566\n",
      "\n",
      "episode 3, policy loss 0.040999606251716614\n",
      "\n",
      "episode 4, policy loss -0.0350133441388607\n",
      "\n",
      "episode 5, policy loss 0.05620155483484268\n",
      "\n",
      "episode 6, policy loss 0.023519467562437057\n",
      "\n",
      "episode 7, policy loss 0.05441609025001526\n",
      "\n",
      "episode 8, policy loss -0.08685114234685898\n",
      "\n",
      "episode 9, policy loss 0.014920363202691078\n",
      "\n",
      "episode 10, policy loss -0.023602843284606934\n",
      "\n",
      "episode 11, policy loss 0.0037038095761090517\n",
      "\n",
      "episode 12, policy loss -0.028540654107928276\n",
      "\n",
      "episode 13, policy loss -0.04879674315452576\n",
      "\n",
      "episode 14, policy loss -0.061717692762613297\n",
      "\n",
      "episode 15, policy loss 0.08852160722017288\n",
      "\n",
      "episode 16, policy loss 0.01067537534981966\n",
      "\n",
      "Policy train loss in epoch 1:-0.000788891440606676\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.02739022672176361\n",
      "\n",
      "episode 2, policy loss 0.01473669521510601\n",
      "\n",
      "episode 3, policy loss -0.08750816434621811\n",
      "\n",
      "episode 4, policy loss -0.06095441058278084\n",
      "\n",
      "episode 5, policy loss -0.033733222633600235\n",
      "\n",
      "episode 6, policy loss 0.08850249648094177\n",
      "\n",
      "episode 7, policy loss 0.05439468100667\n",
      "\n",
      "episode 8, policy loss 0.0096867885440588\n",
      "\n",
      "episode 9, policy loss 0.03972608596086502\n",
      "\n",
      "episode 10, policy loss -0.050052013248205185\n",
      "\n",
      "episode 11, policy loss 0.002941540442407131\n",
      "\n",
      "episode 12, policy loss -0.025400616228580475\n",
      "\n",
      "episode 13, policy loss 0.011087239719927311\n",
      "\n",
      "episode 14, policy loss 0.052660584449768066\n",
      "\n",
      "episode 15, policy loss 0.02178756520152092\n",
      "\n",
      "episode 16, policy loss -0.03592439740896225\n",
      "\n",
      "Policy train loss in epoch 2:-0.0015899608843028545\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.08818396180868149\n",
      "\n",
      "episode 2, policy loss -0.06257206946611404\n",
      "\n",
      "episode 3, policy loss -0.03340202197432518\n",
      "\n",
      "episode 4, policy loss 0.08830804377794266\n",
      "\n",
      "episode 5, policy loss 0.05385180190205574\n",
      "\n",
      "episode 6, policy loss 0.013507033698260784\n",
      "\n",
      "episode 7, policy loss 0.009309487417340279\n",
      "\n",
      "episode 8, policy loss 0.022026004269719124\n",
      "\n",
      "episode 9, policy loss 0.03971097990870476\n",
      "\n",
      "episode 10, policy loss -0.03662331402301788\n",
      "\n",
      "episode 11, policy loss -0.025431716814637184\n",
      "\n",
      "episode 12, policy loss 0.05385783687233925\n",
      "\n",
      "episode 13, policy loss -0.049051683396101\n",
      "\n",
      "episode 14, policy loss 0.011071681044995785\n",
      "\n",
      "episode 15, policy loss -0.028379147872328758\n",
      "\n",
      "episode 16, policy loss 0.0023391826543956995\n",
      "\n",
      "Policy train loss in epoch 3:-0.0018538664880907163\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.21468032896518707\n",
      "\n",
      "episode 2, val func loss 0.1650499850511551\n",
      "\n",
      "episode 3, val func loss 0.20910844206809998\n",
      "\n",
      "episode 4, val func loss 0.18144679069519043\n",
      "\n",
      "episode 5, val func loss 0.20980095863342285\n",
      "\n",
      "episode 6, val func loss 0.2019294649362564\n",
      "\n",
      "episode 7, val func loss 0.20609769225120544\n",
      "\n",
      "episode 8, val func loss 0.1580047905445099\n",
      "\n",
      "episode 9, val func loss 0.16784024238586426\n",
      "\n",
      "episode 10, val func loss 0.21994324028491974\n",
      "\n",
      "episode 11, val func loss 0.18909813463687897\n",
      "\n",
      "episode 12, val func loss 0.1771707981824875\n",
      "\n",
      "episode 13, val func loss 0.2431248277425766\n",
      "\n",
      "episode 14, val func loss 0.19166171550750732\n",
      "\n",
      "episode 15, val func loss 0.177100270986557\n",
      "\n",
      "episode 16, val func loss 0.19035221636295319\n",
      "\n",
      "Val func train loss in epoch 0:0.19390061870217323\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.162599116563797\n",
      "\n",
      "episode 2, val func loss 0.17922616004943848\n",
      "\n",
      "episode 3, val func loss 0.18882416188716888\n",
      "\n",
      "episode 4, val func loss 0.18706415593624115\n",
      "\n",
      "episode 5, val func loss 0.2283352017402649\n",
      "\n",
      "episode 6, val func loss 0.20895634591579437\n",
      "\n",
      "episode 7, val func loss 0.1928742527961731\n",
      "\n",
      "episode 8, val func loss 0.24121226370334625\n",
      "\n",
      "episode 9, val func loss 0.17752519249916077\n",
      "\n",
      "episode 10, val func loss 0.1591642051935196\n",
      "\n",
      "episode 11, val func loss 0.20803174376487732\n",
      "\n",
      "episode 12, val func loss 0.16906535625457764\n",
      "\n",
      "episode 13, val func loss 0.18071629106998444\n",
      "\n",
      "episode 14, val func loss 0.2129932940006256\n",
      "\n",
      "episode 15, val func loss 0.2124253660440445\n",
      "\n",
      "episode 16, val func loss 0.21248668432235718\n",
      "\n",
      "Val func train loss in epoch 1:0.1950937369838357\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.2101476490497589\n",
      "\n",
      "episode 2, val func loss 0.19129902124404907\n",
      "\n",
      "episode 3, val func loss 0.1519727259874344\n",
      "\n",
      "episode 4, val func loss 0.19397349655628204\n",
      "\n",
      "episode 5, val func loss 0.17682985961437225\n",
      "\n",
      "episode 6, val func loss 0.24517899751663208\n",
      "\n",
      "episode 7, val func loss 0.18923979997634888\n",
      "\n",
      "episode 8, val func loss 0.1803717464208603\n",
      "\n",
      "episode 9, val func loss 0.21217885613441467\n",
      "\n",
      "episode 10, val func loss 0.20790638029575348\n",
      "\n",
      "episode 11, val func loss 0.16419918835163116\n",
      "\n",
      "episode 12, val func loss 0.2197360247373581\n",
      "\n",
      "episode 13, val func loss 0.16539768874645233\n",
      "\n",
      "episode 14, val func loss 0.1776585876941681\n",
      "\n",
      "episode 15, val func loss 0.21134713292121887\n",
      "\n",
      "episode 16, val func loss 0.20936091244220734\n",
      "\n",
      "Val func train loss in epoch 2:0.19417487923055887\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.16995152831077576\n",
      "\n",
      "episode 2, val func loss 0.19052068889141083\n",
      "\n",
      "episode 3, val func loss 0.15577618777751923\n",
      "\n",
      "episode 4, val func loss 0.2083708494901657\n",
      "\n",
      "episode 5, val func loss 0.16312292218208313\n",
      "\n",
      "episode 6, val func loss 0.20979680120944977\n",
      "\n",
      "episode 7, val func loss 0.21526771783828735\n",
      "\n",
      "episode 8, val func loss 0.24634258449077606\n",
      "\n",
      "episode 9, val func loss 0.17718347907066345\n",
      "\n",
      "episode 10, val func loss 0.21740391850471497\n",
      "\n",
      "episode 11, val func loss 0.20961754024028778\n",
      "\n",
      "episode 12, val func loss 0.21269018948078156\n",
      "\n",
      "episode 13, val func loss 0.17879897356033325\n",
      "\n",
      "episode 14, val func loss 0.20077626407146454\n",
      "\n",
      "episode 15, val func loss 0.1994483470916748\n",
      "\n",
      "episode 16, val func loss 0.1853259950876236\n",
      "\n",
      "Val func train loss in epoch 3:0.19627462420612574\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.21223381161689758\n",
      "\n",
      "episode 2, val func loss 0.19177241623401642\n",
      "\n",
      "episode 3, val func loss 0.20946930348873138\n",
      "\n",
      "episode 4, val func loss 0.17811979353427887\n",
      "\n",
      "episode 5, val func loss 0.18128140270709991\n",
      "\n",
      "episode 6, val func loss 0.1924181580543518\n",
      "\n",
      "episode 7, val func loss 0.18877863883972168\n",
      "\n",
      "episode 8, val func loss 0.21174409985542297\n",
      "\n",
      "episode 9, val func loss 0.1634744107723236\n",
      "\n",
      "episode 10, val func loss 0.2440711110830307\n",
      "\n",
      "episode 11, val func loss 0.21229933202266693\n",
      "\n",
      "episode 12, val func loss 0.1665739119052887\n",
      "\n",
      "episode 13, val func loss 0.17924566566944122\n",
      "\n",
      "episode 14, val func loss 0.15478146076202393\n",
      "\n",
      "episode 15, val func loss 0.21790891885757446\n",
      "\n",
      "episode 16, val func loss 0.21209557354450226\n",
      "\n",
      "Val func train loss in epoch 4:0.19476675055921078\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.16434474289417267\n",
      "\n",
      "episode 2, val func loss 0.24071624875068665\n",
      "\n",
      "episode 3, val func loss 0.21375809609889984\n",
      "\n",
      "episode 4, val func loss 0.20824827253818512\n",
      "\n",
      "episode 5, val func loss 0.19523051381111145\n",
      "\n",
      "episode 6, val func loss 0.2107767015695572\n",
      "\n",
      "episode 7, val func loss 0.1805143654346466\n",
      "\n",
      "episode 8, val func loss 0.17750968039035797\n",
      "\n",
      "episode 9, val func loss 0.21304993331432343\n",
      "\n",
      "episode 10, val func loss 0.19029070436954498\n",
      "\n",
      "episode 11, val func loss 0.1803869605064392\n",
      "\n",
      "episode 12, val func loss 0.18976157903671265\n",
      "\n",
      "episode 13, val func loss 0.16328608989715576\n",
      "\n",
      "episode 14, val func loss 0.21738608181476593\n",
      "\n",
      "episode 15, val func loss 0.22967222332954407\n",
      "\n",
      "episode 16, val func loss 0.14975737035274506\n",
      "\n",
      "Val func train loss in epoch 5:0.19529309775680304\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17702993750572205\n",
      "\n",
      "episode 2, val func loss 0.2052803933620453\n",
      "\n",
      "episode 3, val func loss 0.2165660411119461\n",
      "\n",
      "episode 4, val func loss 0.16729067265987396\n",
      "\n",
      "episode 5, val func loss 0.21085114777088165\n",
      "\n",
      "episode 6, val func loss 0.15947306156158447\n",
      "\n",
      "episode 7, val func loss 0.23831383883953094\n",
      "\n",
      "episode 8, val func loss 0.20684151351451874\n",
      "\n",
      "episode 9, val func loss 0.21336469054222107\n",
      "\n",
      "episode 10, val func loss 0.17990697920322418\n",
      "\n",
      "episode 11, val func loss 0.1913103610277176\n",
      "\n",
      "episode 12, val func loss 0.21168746054172516\n",
      "\n",
      "episode 13, val func loss 0.19186750054359436\n",
      "\n",
      "episode 14, val func loss 0.18067634105682373\n",
      "\n",
      "episode 15, val func loss 0.16324397921562195\n",
      "\n",
      "episode 16, val func loss 0.19226358830928802\n",
      "\n",
      "Val func train loss in epoch 6:0.19412296917289495\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1763918101787567\n",
      "\n",
      "episode 2, val func loss 0.14550895988941193\n",
      "\n",
      "episode 3, val func loss 0.1623295396566391\n",
      "\n",
      "episode 4, val func loss 0.2228422611951828\n",
      "\n",
      "episode 5, val func loss 0.2541164755821228\n",
      "\n",
      "episode 6, val func loss 0.21660825610160828\n",
      "\n",
      "episode 7, val func loss 0.21374936401844025\n",
      "\n",
      "episode 8, val func loss 0.19338442385196686\n",
      "\n",
      "episode 9, val func loss 0.17757585644721985\n",
      "\n",
      "episode 10, val func loss 0.20500972867012024\n",
      "\n",
      "episode 11, val func loss 0.19448263943195343\n",
      "\n",
      "episode 12, val func loss 0.1830769181251526\n",
      "\n",
      "episode 13, val func loss 0.19767872989177704\n",
      "\n",
      "episode 14, val func loss 0.16865341365337372\n",
      "\n",
      "episode 15, val func loss 0.21679282188415527\n",
      "\n",
      "episode 16, val func loss 0.2137545794248581\n",
      "\n",
      "Val func train loss in epoch 7:0.19637223612517118\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.18956118822097778\n",
      "\n",
      "episode 2, val func loss 0.19221824407577515\n",
      "\n",
      "episode 3, val func loss 0.21343186497688293\n",
      "\n",
      "episode 4, val func loss 0.16398613154888153\n",
      "\n",
      "episode 5, val func loss 0.16278328001499176\n",
      "\n",
      "episode 6, val func loss 0.21605992317199707\n",
      "\n",
      "episode 7, val func loss 0.18022370338439941\n",
      "\n",
      "episode 8, val func loss 0.18826045095920563\n",
      "\n",
      "episode 9, val func loss 0.17603778839111328\n",
      "\n",
      "episode 10, val func loss 0.22541674971580505\n",
      "\n",
      "episode 11, val func loss 0.14861072599887848\n",
      "\n",
      "episode 12, val func loss 0.2450055330991745\n",
      "\n",
      "episode 13, val func loss 0.2064710110425949\n",
      "\n",
      "episode 14, val func loss 0.2081335186958313\n",
      "\n",
      "episode 15, val func loss 0.2102058082818985\n",
      "\n",
      "episode 16, val func loss 0.1788267344236374\n",
      "\n",
      "Val func train loss in epoch 8:0.1940770410001278\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1930248886346817\n",
      "\n",
      "episode 2, val func loss 0.20518720149993896\n",
      "\n",
      "episode 3, val func loss 0.21010422706604004\n",
      "\n",
      "episode 4, val func loss 0.17161506414413452\n",
      "\n",
      "episode 5, val func loss 0.23870842158794403\n",
      "\n",
      "episode 6, val func loss 0.21500808000564575\n",
      "\n",
      "episode 7, val func loss 0.21042853593826294\n",
      "\n",
      "episode 8, val func loss 0.16879312694072723\n",
      "\n",
      "episode 9, val func loss 0.2137957513332367\n",
      "\n",
      "episode 10, val func loss 0.1936054676771164\n",
      "\n",
      "episode 11, val func loss 0.1781987100839615\n",
      "\n",
      "episode 12, val func loss 0.17738761007785797\n",
      "\n",
      "episode 13, val func loss 0.14682833850383759\n",
      "\n",
      "episode 14, val func loss 0.1944710910320282\n",
      "\n",
      "episode 15, val func loss 0.2217647135257721\n",
      "\n",
      "episode 16, val func loss 0.1835104376077652\n",
      "\n",
      "Val func train loss in epoch 9:0.19515197910368443\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.17876608669757843\n",
      "\n",
      "episode 2, val func loss 0.17636625468730927\n",
      "\n",
      "episode 3, val func loss 0.21461103856563568\n",
      "\n",
      "episode 4, val func loss 0.1799587607383728\n",
      "\n",
      "episode 5, val func loss 0.1918947845697403\n",
      "\n",
      "episode 6, val func loss 0.21137872338294983\n",
      "\n",
      "episode 7, val func loss 0.1542934775352478\n",
      "\n",
      "episode 8, val func loss 0.1654955893754959\n",
      "\n",
      "episode 9, val func loss 0.20976673066616058\n",
      "\n",
      "episode 10, val func loss 0.16384939849376678\n",
      "\n",
      "episode 11, val func loss 0.20682957768440247\n",
      "\n",
      "episode 12, val func loss 0.1925223469734192\n",
      "\n",
      "episode 13, val func loss 0.21290142834186554\n",
      "\n",
      "episode 14, val func loss 0.24360798299312592\n",
      "\n",
      "episode 15, val func loss 0.18928366899490356\n",
      "\n",
      "episode 16, val func loss 0.21755939722061157\n",
      "\n",
      "Val func train loss in epoch 10:0.1943178279325366\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.21391093730926514\n",
      "\n",
      "episode 2, val func loss 0.16858358681201935\n",
      "\n",
      "episode 3, val func loss 0.1672143191099167\n",
      "\n",
      "episode 4, val func loss 0.20474807918071747\n",
      "\n",
      "episode 5, val func loss 0.1778678447008133\n",
      "\n",
      "episode 6, val func loss 0.19083645939826965\n",
      "\n",
      "episode 7, val func loss 0.1786351501941681\n",
      "\n",
      "episode 8, val func loss 0.2206258326768875\n",
      "\n",
      "episode 9, val func loss 0.24241749942302704\n",
      "\n",
      "episode 10, val func loss 0.19139091670513153\n",
      "\n",
      "episode 11, val func loss 0.15262654423713684\n",
      "\n",
      "episode 12, val func loss 0.21242083609104156\n",
      "\n",
      "episode 13, val func loss 0.21289442479610443\n",
      "\n",
      "episode 14, val func loss 0.19257865846157074\n",
      "\n",
      "episode 15, val func loss 0.209125354886055\n",
      "\n",
      "episode 16, val func loss 0.18030250072479248\n",
      "\n",
      "Val func train loss in epoch 11:0.1947611840441823\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.20545682311058044\n",
      "\n",
      "episode 2, val func loss 0.17868484556674957\n",
      "\n",
      "episode 3, val func loss 0.1657218337059021\n",
      "\n",
      "episode 4, val func loss 0.18040922284126282\n",
      "\n",
      "episode 5, val func loss 0.1905573606491089\n",
      "\n",
      "episode 6, val func loss 0.149523064494133\n",
      "\n",
      "episode 7, val func loss 0.21388275921344757\n",
      "\n",
      "episode 8, val func loss 0.21616150438785553\n",
      "\n",
      "episode 9, val func loss 0.18860870599746704\n",
      "\n",
      "episode 10, val func loss 0.1627621203660965\n",
      "\n",
      "episode 11, val func loss 0.1771984100341797\n",
      "\n",
      "episode 12, val func loss 0.21481837332248688\n",
      "\n",
      "episode 13, val func loss 0.19263549149036407\n",
      "\n",
      "episode 14, val func loss 0.21200881898403168\n",
      "\n",
      "episode 15, val func loss 0.2414969652891159\n",
      "\n",
      "episode 16, val func loss 0.21720783412456512\n",
      "\n",
      "Val func train loss in epoch 12:0.19419588334858418\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.21031051874160767\n",
      "\n",
      "episode 2, val func loss 0.19848890602588654\n",
      "\n",
      "episode 3, val func loss 0.2373877912759781\n",
      "\n",
      "episode 4, val func loss 0.205610990524292\n",
      "\n",
      "episode 5, val func loss 0.18439309298992157\n",
      "\n",
      "episode 6, val func loss 0.2159722000360489\n",
      "\n",
      "episode 7, val func loss 0.21415948867797852\n",
      "\n",
      "episode 8, val func loss 0.21087443828582764\n",
      "\n",
      "episode 9, val func loss 0.1938742846250534\n",
      "\n",
      "episode 10, val func loss 0.16714465618133545\n",
      "\n",
      "episode 11, val func loss 0.18896955251693726\n",
      "\n",
      "episode 12, val func loss 0.21234263479709625\n",
      "\n",
      "episode 13, val func loss 0.1777254045009613\n",
      "\n",
      "episode 14, val func loss 0.16231192648410797\n",
      "\n",
      "episode 15, val func loss 0.18129971623420715\n",
      "\n",
      "episode 16, val func loss 0.14802692830562592\n",
      "\n",
      "Val func train loss in epoch 13:0.1943057831376791\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19208145141601562\n",
      "\n",
      "episode 2, val func loss 0.22560156881809235\n",
      "\n",
      "episode 3, val func loss 0.18119150400161743\n",
      "\n",
      "episode 4, val func loss 0.21488815546035767\n",
      "\n",
      "episode 5, val func loss 0.2120026797056198\n",
      "\n",
      "episode 6, val func loss 0.20510278642177582\n",
      "\n",
      "episode 7, val func loss 0.17862680554389954\n",
      "\n",
      "episode 8, val func loss 0.21072541177272797\n",
      "\n",
      "episode 9, val func loss 0.18447096645832062\n",
      "\n",
      "episode 10, val func loss 0.1955002099275589\n",
      "\n",
      "episode 11, val func loss 0.16203168034553528\n",
      "\n",
      "episode 12, val func loss 0.2072312831878662\n",
      "\n",
      "episode 13, val func loss 0.24087534844875336\n",
      "\n",
      "episode 14, val func loss 0.1653166115283966\n",
      "\n",
      "episode 15, val func loss 0.1899830400943756\n",
      "\n",
      "episode 16, val func loss 0.16264285147190094\n",
      "\n",
      "Val func train loss in epoch 14:0.19551702216267586\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.17613638937473297\n",
      "\n",
      "episode 2, val func loss 0.2210664004087448\n",
      "\n",
      "episode 3, val func loss 0.18038085103034973\n",
      "\n",
      "episode 4, val func loss 0.18988938629627228\n",
      "\n",
      "episode 5, val func loss 0.18176348507404327\n",
      "\n",
      "episode 6, val func loss 0.2170368731021881\n",
      "\n",
      "episode 7, val func loss 0.24559630453586578\n",
      "\n",
      "episode 8, val func loss 0.2086731344461441\n",
      "\n",
      "episode 9, val func loss 0.20498916506767273\n",
      "\n",
      "episode 10, val func loss 0.21400105953216553\n",
      "\n",
      "episode 11, val func loss 0.17726388573646545\n",
      "\n",
      "episode 12, val func loss 0.17611297965049744\n",
      "\n",
      "episode 13, val func loss 0.2108769416809082\n",
      "\n",
      "episode 14, val func loss 0.2010428011417389\n",
      "\n",
      "episode 15, val func loss 0.1616179496049881\n",
      "\n",
      "episode 16, val func loss 0.19383805990219116\n",
      "\n",
      "Val func train loss in epoch 15:0.19751785416156054\n",
      "***********************TIME WAS 4.942952497800191 min*****************************\n",
      "\n",
      "**********************ROUND 73 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.08123979717493057\n",
      "\n",
      "episode 2, policy loss -0.03585493564605713\n",
      "\n",
      "episode 3, policy loss -0.07056691497564316\n",
      "\n",
      "episode 4, policy loss -0.03727022558450699\n",
      "\n",
      "episode 5, policy loss 0.002199306385591626\n",
      "\n",
      "episode 6, policy loss -0.036213357001543045\n",
      "\n",
      "episode 7, policy loss -0.009614459238946438\n",
      "\n",
      "episode 8, policy loss -0.050409428775310516\n",
      "\n",
      "episode 9, policy loss -0.06537245959043503\n",
      "\n",
      "episode 10, policy loss -0.07613803446292877\n",
      "\n",
      "episode 11, policy loss -0.07079114764928818\n",
      "\n",
      "episode 12, policy loss -0.0964014008641243\n",
      "\n",
      "episode 13, policy loss -0.019943969324231148\n",
      "\n",
      "episode 14, policy loss -0.010966463014483452\n",
      "\n",
      "episode 15, policy loss -0.06528396904468536\n",
      "\n",
      "episode 16, policy loss -0.043065350502729416\n",
      "\n",
      "Policy train loss in epoch 0:-0.04793328790401574\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.010357484221458435\n",
      "\n",
      "episode 2, policy loss -0.010144374333322048\n",
      "\n",
      "episode 3, policy loss -0.09734094142913818\n",
      "\n",
      "episode 4, policy loss -0.043703965842723846\n",
      "\n",
      "episode 5, policy loss -0.04004289209842682\n",
      "\n",
      "episode 6, policy loss -0.06677453219890594\n",
      "\n",
      "episode 7, policy loss -0.02030794881284237\n",
      "\n",
      "episode 8, policy loss 0.0004476570466067642\n",
      "\n",
      "episode 9, policy loss -0.07766842842102051\n",
      "\n",
      "episode 10, policy loss -0.04128401353955269\n",
      "\n",
      "episode 11, policy loss -0.05160922184586525\n",
      "\n",
      "episode 12, policy loss -0.0662035271525383\n",
      "\n",
      "episode 13, policy loss -0.08863525092601776\n",
      "\n",
      "episode 14, policy loss -0.07824713736772537\n",
      "\n",
      "episode 15, policy loss -0.0738600343465805\n",
      "\n",
      "episode 16, policy loss -0.037939563393592834\n",
      "\n",
      "Policy train loss in epoch 1:-0.050229478680194006\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.010270566679537296\n",
      "\n",
      "episode 2, policy loss -0.06756481528282166\n",
      "\n",
      "episode 3, policy loss -0.0751161053776741\n",
      "\n",
      "episode 4, policy loss -0.07931086421012878\n",
      "\n",
      "episode 5, policy loss -0.05124928429722786\n",
      "\n",
      "episode 6, policy loss -0.03755853325128555\n",
      "\n",
      "episode 7, policy loss -0.010653425939381123\n",
      "\n",
      "episode 8, policy loss -0.07894168794155121\n",
      "\n",
      "episode 9, policy loss -0.040925659239292145\n",
      "\n",
      "episode 10, policy loss -0.10078784823417664\n",
      "\n",
      "episode 11, policy loss -0.0889510065317154\n",
      "\n",
      "episode 12, policy loss -0.0409519262611866\n",
      "\n",
      "episode 13, policy loss -0.0008949129260145128\n",
      "\n",
      "episode 14, policy loss -0.04140627384185791\n",
      "\n",
      "episode 15, policy loss -0.020271386951208115\n",
      "\n",
      "episode 16, policy loss -0.0664791688323021\n",
      "\n",
      "Policy train loss in epoch 2:-0.05070834161233506\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.07791460305452347\n",
      "\n",
      "episode 2, policy loss -0.08982933312654495\n",
      "\n",
      "episode 3, policy loss -0.010696010664105415\n",
      "\n",
      "episode 4, policy loss -0.03795083984732628\n",
      "\n",
      "episode 5, policy loss -0.08006169646978378\n",
      "\n",
      "episode 6, policy loss -0.04225882515311241\n",
      "\n",
      "episode 7, policy loss -0.02101876772940159\n",
      "\n",
      "episode 8, policy loss -0.09932279586791992\n",
      "\n",
      "episode 9, policy loss -0.04083435609936714\n",
      "\n",
      "episode 10, policy loss -0.06688810139894485\n",
      "\n",
      "episode 11, policy loss -0.05141711235046387\n",
      "\n",
      "episode 12, policy loss -0.07354721426963806\n",
      "\n",
      "episode 13, policy loss -0.0012810244224965572\n",
      "\n",
      "episode 14, policy loss -0.010862314142286777\n",
      "\n",
      "episode 15, policy loss -0.04451649636030197\n",
      "\n",
      "episode 16, policy loss -0.06764048337936401\n",
      "\n",
      "Policy train loss in epoch 3:-0.051002498395973817\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.191804438829422\n",
      "\n",
      "episode 2, val func loss 0.1822115033864975\n",
      "\n",
      "episode 3, val func loss 0.23264166712760925\n",
      "\n",
      "episode 4, val func loss 0.19920098781585693\n",
      "\n",
      "episode 5, val func loss 0.16476266086101532\n",
      "\n",
      "episode 6, val func loss 0.18747831881046295\n",
      "\n",
      "episode 7, val func loss 0.17216528952121735\n",
      "\n",
      "episode 8, val func loss 0.2261837273836136\n",
      "\n",
      "episode 9, val func loss 0.21047775447368622\n",
      "\n",
      "episode 10, val func loss 0.20222795009613037\n",
      "\n",
      "episode 11, val func loss 0.21135956048965454\n",
      "\n",
      "episode 12, val func loss 0.19890186190605164\n",
      "\n",
      "episode 13, val func loss 0.19501018524169922\n",
      "\n",
      "episode 14, val func loss 0.1811130791902542\n",
      "\n",
      "episode 15, val func loss 0.19313086569309235\n",
      "\n",
      "episode 16, val func loss 0.19144207239151\n",
      "\n",
      "Val func train loss in epoch 0:0.19625699520111084\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1659165322780609\n",
      "\n",
      "episode 2, val func loss 0.22549162805080414\n",
      "\n",
      "episode 3, val func loss 0.17715954780578613\n",
      "\n",
      "episode 4, val func loss 0.19560781121253967\n",
      "\n",
      "episode 5, val func loss 0.19712626934051514\n",
      "\n",
      "episode 6, val func loss 0.1915365755558014\n",
      "\n",
      "episode 7, val func loss 0.20964659750461578\n",
      "\n",
      "episode 8, val func loss 0.19426260888576508\n",
      "\n",
      "episode 9, val func loss 0.2124415785074234\n",
      "\n",
      "episode 10, val func loss 0.1862761229276657\n",
      "\n",
      "episode 11, val func loss 0.20462581515312195\n",
      "\n",
      "episode 12, val func loss 0.19017024338245392\n",
      "\n",
      "episode 13, val func loss 0.18629813194274902\n",
      "\n",
      "episode 14, val func loss 0.2182401865720749\n",
      "\n",
      "episode 15, val func loss 0.19302190840244293\n",
      "\n",
      "episode 16, val func loss 0.1733117699623108\n",
      "\n",
      "Val func train loss in epoch 1:0.19507083296775818\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18197894096374512\n",
      "\n",
      "episode 2, val func loss 0.1968955248594284\n",
      "\n",
      "episode 3, val func loss 0.1788957118988037\n",
      "\n",
      "episode 4, val func loss 0.20014454424381256\n",
      "\n",
      "episode 5, val func loss 0.21946750581264496\n",
      "\n",
      "episode 6, val func loss 0.22697564959526062\n",
      "\n",
      "episode 7, val func loss 0.213111013174057\n",
      "\n",
      "episode 8, val func loss 0.1897643357515335\n",
      "\n",
      "episode 9, val func loss 0.20953232049942017\n",
      "\n",
      "episode 10, val func loss 0.19540716707706451\n",
      "\n",
      "episode 11, val func loss 0.19448471069335938\n",
      "\n",
      "episode 12, val func loss 0.19222132861614227\n",
      "\n",
      "episode 13, val func loss 0.17626386880874634\n",
      "\n",
      "episode 14, val func loss 0.16614653170108795\n",
      "\n",
      "episode 15, val func loss 0.20214056968688965\n",
      "\n",
      "episode 16, val func loss 0.18716654181480408\n",
      "\n",
      "Val func train loss in epoch 2:0.19566226657480001\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19289986789226532\n",
      "\n",
      "episode 2, val func loss 0.19277788698673248\n",
      "\n",
      "episode 3, val func loss 0.18722745776176453\n",
      "\n",
      "episode 4, val func loss 0.22087271511554718\n",
      "\n",
      "episode 5, val func loss 0.2136608213186264\n",
      "\n",
      "episode 6, val func loss 0.16486991941928864\n",
      "\n",
      "episode 7, val func loss 0.2104116976261139\n",
      "\n",
      "episode 8, val func loss 0.1790715605020523\n",
      "\n",
      "episode 9, val func loss 0.19516974687576294\n",
      "\n",
      "episode 10, val func loss 0.1761578917503357\n",
      "\n",
      "episode 11, val func loss 0.19888655841350555\n",
      "\n",
      "episode 12, val func loss 0.19181209802627563\n",
      "\n",
      "episode 13, val func loss 0.22571130096912384\n",
      "\n",
      "episode 14, val func loss 0.20318332314491272\n",
      "\n",
      "episode 15, val func loss 0.18446607887744904\n",
      "\n",
      "episode 16, val func loss 0.191905215382576\n",
      "\n",
      "Val func train loss in epoch 3:0.19556775875389576\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.202164888381958\n",
      "\n",
      "episode 2, val func loss 0.22724951803684235\n",
      "\n",
      "episode 3, val func loss 0.19310615956783295\n",
      "\n",
      "episode 4, val func loss 0.1715783029794693\n",
      "\n",
      "episode 5, val func loss 0.18718566000461578\n",
      "\n",
      "episode 6, val func loss 0.19948554039001465\n",
      "\n",
      "episode 7, val func loss 0.19234126806259155\n",
      "\n",
      "episode 8, val func loss 0.19869348406791687\n",
      "\n",
      "episode 9, val func loss 0.20998406410217285\n",
      "\n",
      "episode 10, val func loss 0.19217543303966522\n",
      "\n",
      "episode 11, val func loss 0.21030060946941376\n",
      "\n",
      "episode 12, val func loss 0.1965504139661789\n",
      "\n",
      "episode 13, val func loss 0.17050687968730927\n",
      "\n",
      "episode 14, val func loss 0.21728557348251343\n",
      "\n",
      "episode 15, val func loss 0.1807185709476471\n",
      "\n",
      "episode 16, val func loss 0.18650129437446594\n",
      "\n",
      "Val func train loss in epoch 4:0.195989228785038\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19874121248722076\n",
      "\n",
      "episode 2, val func loss 0.1650649607181549\n",
      "\n",
      "episode 3, val func loss 0.18243242800235748\n",
      "\n",
      "episode 4, val func loss 0.1992463618516922\n",
      "\n",
      "episode 5, val func loss 0.21301241219043732\n",
      "\n",
      "episode 6, val func loss 0.19399394094944\n",
      "\n",
      "episode 7, val func loss 0.22817355394363403\n",
      "\n",
      "episode 8, val func loss 0.19145731627941132\n",
      "\n",
      "episode 9, val func loss 0.17174606025218964\n",
      "\n",
      "episode 10, val func loss 0.19307152926921844\n",
      "\n",
      "episode 11, val func loss 0.2024436593055725\n",
      "\n",
      "episode 12, val func loss 0.18682612478733063\n",
      "\n",
      "episode 13, val func loss 0.19252102077007294\n",
      "\n",
      "episode 14, val func loss 0.17882870137691498\n",
      "\n",
      "episode 15, val func loss 0.2111237347126007\n",
      "\n",
      "episode 16, val func loss 0.21788783371448517\n",
      "\n",
      "Val func train loss in epoch 5:0.19541067816317081\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1852378398180008\n",
      "\n",
      "episode 2, val func loss 0.19286219775676727\n",
      "\n",
      "episode 3, val func loss 0.16543631255626678\n",
      "\n",
      "episode 4, val func loss 0.2114427238702774\n",
      "\n",
      "episode 5, val func loss 0.21873050928115845\n",
      "\n",
      "episode 6, val func loss 0.18688729405403137\n",
      "\n",
      "episode 7, val func loss 0.2253342568874359\n",
      "\n",
      "episode 8, val func loss 0.19209302961826324\n",
      "\n",
      "episode 9, val func loss 0.1904568076133728\n",
      "\n",
      "episode 10, val func loss 0.17536097764968872\n",
      "\n",
      "episode 11, val func loss 0.17925997078418732\n",
      "\n",
      "episode 12, val func loss 0.20308136940002441\n",
      "\n",
      "episode 13, val func loss 0.21017497777938843\n",
      "\n",
      "episode 14, val func loss 0.19634051620960236\n",
      "\n",
      "episode 15, val func loss 0.19204726815223694\n",
      "\n",
      "episode 16, val func loss 0.1984054148197174\n",
      "\n",
      "Val func train loss in epoch 6:0.19519696664065123\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18375135958194733\n",
      "\n",
      "episode 2, val func loss 0.21036341786384583\n",
      "\n",
      "episode 3, val func loss 0.1917741894721985\n",
      "\n",
      "episode 4, val func loss 0.20155927538871765\n",
      "\n",
      "episode 5, val func loss 0.19285143911838531\n",
      "\n",
      "episode 6, val func loss 0.22005143761634827\n",
      "\n",
      "episode 7, val func loss 0.19114159047603607\n",
      "\n",
      "episode 8, val func loss 0.21245001256465912\n",
      "\n",
      "episode 9, val func loss 0.16537971794605255\n",
      "\n",
      "episode 10, val func loss 0.18695136904716492\n",
      "\n",
      "episode 11, val func loss 0.1802968829870224\n",
      "\n",
      "episode 12, val func loss 0.22551630437374115\n",
      "\n",
      "episode 13, val func loss 0.17422108352184296\n",
      "\n",
      "episode 14, val func loss 0.19535693526268005\n",
      "\n",
      "episode 15, val func loss 0.19832271337509155\n",
      "\n",
      "episode 16, val func loss 0.19193795323371887\n",
      "\n",
      "Val func train loss in epoch 7:0.19512035511434078\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.178435280919075\n",
      "\n",
      "episode 2, val func loss 0.17244456708431244\n",
      "\n",
      "episode 3, val func loss 0.22586587071418762\n",
      "\n",
      "episode 4, val func loss 0.19797661900520325\n",
      "\n",
      "episode 5, val func loss 0.1925133317708969\n",
      "\n",
      "episode 6, val func loss 0.18292643129825592\n",
      "\n",
      "episode 7, val func loss 0.19464974105358124\n",
      "\n",
      "episode 8, val func loss 0.19734586775302887\n",
      "\n",
      "episode 9, val func loss 0.19165529310703278\n",
      "\n",
      "episode 10, val func loss 0.16493695974349976\n",
      "\n",
      "episode 11, val func loss 0.20983614027500153\n",
      "\n",
      "episode 12, val func loss 0.21805058419704437\n",
      "\n",
      "episode 13, val func loss 0.1865803301334381\n",
      "\n",
      "episode 14, val func loss 0.20337142050266266\n",
      "\n",
      "episode 15, val func loss 0.19020043313503265\n",
      "\n",
      "episode 16, val func loss 0.210797518491745\n",
      "\n",
      "Val func train loss in epoch 8:0.19484914932399988\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.21738484501838684\n",
      "\n",
      "episode 2, val func loss 0.19018733501434326\n",
      "\n",
      "episode 3, val func loss 0.21037328243255615\n",
      "\n",
      "episode 4, val func loss 0.20554837584495544\n",
      "\n",
      "episode 5, val func loss 0.2095765918493271\n",
      "\n",
      "episode 6, val func loss 0.1761208176612854\n",
      "\n",
      "episode 7, val func loss 0.18527966737747192\n",
      "\n",
      "episode 8, val func loss 0.19589681923389435\n",
      "\n",
      "episode 9, val func loss 0.19233438372612\n",
      "\n",
      "episode 10, val func loss 0.19421373307704926\n",
      "\n",
      "episode 11, val func loss 0.18653370440006256\n",
      "\n",
      "episode 12, val func loss 0.17772629857063293\n",
      "\n",
      "episode 13, val func loss 0.22688232362270355\n",
      "\n",
      "episode 14, val func loss 0.1648828685283661\n",
      "\n",
      "episode 15, val func loss 0.1987585872411728\n",
      "\n",
      "episode 16, val func loss 0.19192837178707123\n",
      "\n",
      "Val func train loss in epoch 9:0.19522675033658743\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19603753089904785\n",
      "\n",
      "episode 2, val func loss 0.1787494421005249\n",
      "\n",
      "episode 3, val func loss 0.1920696198940277\n",
      "\n",
      "episode 4, val func loss 0.19888335466384888\n",
      "\n",
      "episode 5, val func loss 0.1839756816625595\n",
      "\n",
      "episode 6, val func loss 0.2019379734992981\n",
      "\n",
      "episode 7, val func loss 0.18746668100357056\n",
      "\n",
      "episode 8, val func loss 0.19267632067203522\n",
      "\n",
      "episode 9, val func loss 0.22062285244464874\n",
      "\n",
      "episode 10, val func loss 0.1722445785999298\n",
      "\n",
      "episode 11, val func loss 0.19144704937934875\n",
      "\n",
      "episode 12, val func loss 0.21275508403778076\n",
      "\n",
      "episode 13, val func loss 0.19234666228294373\n",
      "\n",
      "episode 14, val func loss 0.2259802669286728\n",
      "\n",
      "episode 15, val func loss 0.2097381204366684\n",
      "\n",
      "episode 16, val func loss 0.169041246175766\n",
      "\n",
      "Val func train loss in epoch 10:0.19537327904254198\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19164729118347168\n",
      "\n",
      "episode 2, val func loss 0.176572784781456\n",
      "\n",
      "episode 3, val func loss 0.19022220373153687\n",
      "\n",
      "episode 4, val func loss 0.20994244515895844\n",
      "\n",
      "episode 5, val func loss 0.20278532803058624\n",
      "\n",
      "episode 6, val func loss 0.1980259120464325\n",
      "\n",
      "episode 7, val func loss 0.19166192412376404\n",
      "\n",
      "episode 8, val func loss 0.18179313838481903\n",
      "\n",
      "episode 9, val func loss 0.22840000689029694\n",
      "\n",
      "episode 10, val func loss 0.1782534271478653\n",
      "\n",
      "episode 11, val func loss 0.1876295804977417\n",
      "\n",
      "episode 12, val func loss 0.1989385038614273\n",
      "\n",
      "episode 13, val func loss 0.16492891311645508\n",
      "\n",
      "episode 14, val func loss 0.19256587326526642\n",
      "\n",
      "episode 15, val func loss 0.21748881042003632\n",
      "\n",
      "episode 16, val func loss 0.20978429913520813\n",
      "\n",
      "Val func train loss in epoch 11:0.19504002761095762\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17223328351974487\n",
      "\n",
      "episode 2, val func loss 0.22684192657470703\n",
      "\n",
      "episode 3, val func loss 0.21041668951511383\n",
      "\n",
      "episode 4, val func loss 0.17999595403671265\n",
      "\n",
      "episode 5, val func loss 0.19262370467185974\n",
      "\n",
      "episode 6, val func loss 0.19081439077854156\n",
      "\n",
      "episode 7, val func loss 0.21983511745929718\n",
      "\n",
      "episode 8, val func loss 0.19186626374721527\n",
      "\n",
      "episode 9, val func loss 0.18639378249645233\n",
      "\n",
      "episode 10, val func loss 0.2130308598279953\n",
      "\n",
      "episode 11, val func loss 0.18357546627521515\n",
      "\n",
      "episode 12, val func loss 0.20257742702960968\n",
      "\n",
      "episode 13, val func loss 0.1985546052455902\n",
      "\n",
      "episode 14, val func loss 0.19289915263652802\n",
      "\n",
      "episode 15, val func loss 0.1726437509059906\n",
      "\n",
      "episode 16, val func loss 0.19630388915538788\n",
      "\n",
      "Val func train loss in epoch 12:0.19566289149224758\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.21241603791713715\n",
      "\n",
      "episode 2, val func loss 0.1868179589509964\n",
      "\n",
      "episode 3, val func loss 0.17488665878772736\n",
      "\n",
      "episode 4, val func loss 0.1986292600631714\n",
      "\n",
      "episode 5, val func loss 0.20267100632190704\n",
      "\n",
      "episode 6, val func loss 0.1924120932817459\n",
      "\n",
      "episode 7, val func loss 0.1963634341955185\n",
      "\n",
      "episode 8, val func loss 0.19097639620304108\n",
      "\n",
      "episode 9, val func loss 0.16546432673931122\n",
      "\n",
      "episode 10, val func loss 0.218397855758667\n",
      "\n",
      "episode 11, val func loss 0.19287632405757904\n",
      "\n",
      "episode 12, val func loss 0.17926913499832153\n",
      "\n",
      "episode 13, val func loss 0.22534941136837006\n",
      "\n",
      "episode 14, val func loss 0.2097400575876236\n",
      "\n",
      "episode 15, val func loss 0.19328545033931732\n",
      "\n",
      "episode 16, val func loss 0.18503603339195251\n",
      "\n",
      "Val func train loss in epoch 13:0.1952869649976492\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17326503992080688\n",
      "\n",
      "episode 2, val func loss 0.16467241942882538\n",
      "\n",
      "episode 3, val func loss 0.19090017676353455\n",
      "\n",
      "episode 4, val func loss 0.18811392784118652\n",
      "\n",
      "episode 5, val func loss 0.19797265529632568\n",
      "\n",
      "episode 6, val func loss 0.1784733533859253\n",
      "\n",
      "episode 7, val func loss 0.2127062827348709\n",
      "\n",
      "episode 8, val func loss 0.21404922008514404\n",
      "\n",
      "episode 9, val func loss 0.19290409982204437\n",
      "\n",
      "episode 10, val func loss 0.2000861018896103\n",
      "\n",
      "episode 11, val func loss 0.22568145394325256\n",
      "\n",
      "episode 12, val func loss 0.19017870724201202\n",
      "\n",
      "episode 13, val func loss 0.1889137178659439\n",
      "\n",
      "episode 14, val func loss 0.20453818142414093\n",
      "\n",
      "episode 15, val func loss 0.217838853597641\n",
      "\n",
      "episode 16, val func loss 0.19568563997745514\n",
      "\n",
      "Val func train loss in epoch 14:0.19599873945116997\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20288613438606262\n",
      "\n",
      "episode 2, val func loss 0.22579261660575867\n",
      "\n",
      "episode 3, val func loss 0.18355295062065125\n",
      "\n",
      "episode 4, val func loss 0.19360892474651337\n",
      "\n",
      "episode 5, val func loss 0.19706279039382935\n",
      "\n",
      "episode 6, val func loss 0.1724122166633606\n",
      "\n",
      "episode 7, val func loss 0.16477563977241516\n",
      "\n",
      "episode 8, val func loss 0.19110259413719177\n",
      "\n",
      "episode 9, val func loss 0.2124137282371521\n",
      "\n",
      "episode 10, val func loss 0.19868765771389008\n",
      "\n",
      "episode 11, val func loss 0.20988161861896515\n",
      "\n",
      "episode 12, val func loss 0.18674257397651672\n",
      "\n",
      "episode 13, val func loss 0.17955154180526733\n",
      "\n",
      "episode 14, val func loss 0.19288495182991028\n",
      "\n",
      "episode 15, val func loss 0.2175265997648239\n",
      "\n",
      "episode 16, val func loss 0.19260650873184204\n",
      "\n",
      "Val func train loss in epoch 15:0.1950930655002594\n",
      "***********************TIME WAS 4.946454000473023 min*****************************\n",
      "\n",
      "**********************ROUND 74 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.0027232433203607798\n",
      "\n",
      "episode 2, policy loss -0.08363005518913269\n",
      "\n",
      "episode 3, policy loss -0.08115161210298538\n",
      "\n",
      "episode 4, policy loss -0.1362394094467163\n",
      "\n",
      "episode 5, policy loss -0.047335781157016754\n",
      "\n",
      "episode 6, policy loss 0.0034467994701117277\n",
      "\n",
      "episode 7, policy loss 0.01702941209077835\n",
      "\n",
      "episode 8, policy loss -0.006887907162308693\n",
      "\n",
      "episode 9, policy loss -0.04499227553606033\n",
      "\n",
      "episode 10, policy loss -0.07936429977416992\n",
      "\n",
      "episode 11, policy loss -0.07735399156808853\n",
      "\n",
      "episode 12, policy loss -0.05737652629613876\n",
      "\n",
      "episode 13, policy loss -0.015228597447276115\n",
      "\n",
      "episode 14, policy loss -0.08101733028888702\n",
      "\n",
      "episode 15, policy loss -0.02119266428053379\n",
      "\n",
      "episode 16, policy loss -0.03820674121379852\n",
      "\n",
      "Policy train loss in epoch 0:-0.04701401395141147\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.0920560285449028\n",
      "\n",
      "episode 2, policy loss -0.07629526406526566\n",
      "\n",
      "episode 3, policy loss -0.049531131982803345\n",
      "\n",
      "episode 4, policy loss 0.013383296318352222\n",
      "\n",
      "episode 5, policy loss -0.010633198544383049\n",
      "\n",
      "episode 6, policy loss -0.02101617492735386\n",
      "\n",
      "episode 7, policy loss -0.01387703511863947\n",
      "\n",
      "episode 8, policy loss -0.041128870099782944\n",
      "\n",
      "episode 9, policy loss -0.1416448950767517\n",
      "\n",
      "episode 10, policy loss -0.08411981910467148\n",
      "\n",
      "episode 11, policy loss -0.04976580664515495\n",
      "\n",
      "episode 12, policy loss -0.05736933648586273\n",
      "\n",
      "episode 13, policy loss 0.0003831683425232768\n",
      "\n",
      "episode 14, policy loss -0.08198782056570053\n",
      "\n",
      "episode 15, policy loss -0.08716945350170135\n",
      "\n",
      "episode 16, policy loss -0.009632947854697704\n",
      "\n",
      "Policy train loss in epoch 1:-0.050153832366049755\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.013916303403675556\n",
      "\n",
      "episode 2, policy loss -0.14275333285331726\n",
      "\n",
      "episode 3, policy loss -0.078919917345047\n",
      "\n",
      "episode 4, policy loss -0.08259887993335724\n",
      "\n",
      "episode 5, policy loss -0.050614092499017715\n",
      "\n",
      "episode 6, policy loss -0.04072029888629913\n",
      "\n",
      "episode 7, policy loss -0.021887844428420067\n",
      "\n",
      "episode 8, policy loss -0.014746122993528843\n",
      "\n",
      "episode 9, policy loss -0.010670502670109272\n",
      "\n",
      "episode 10, policy loss 2.1757237846031785e-05\n",
      "\n",
      "episode 11, policy loss -0.08753730356693268\n",
      "\n",
      "episode 12, policy loss -0.09410414844751358\n",
      "\n",
      "episode 13, policy loss -0.08250218629837036\n",
      "\n",
      "episode 14, policy loss -0.05762849003076553\n",
      "\n",
      "episode 15, policy loss -0.04900291562080383\n",
      "\n",
      "episode 16, policy loss -0.009760984219610691\n",
      "\n",
      "Policy train loss in epoch 2:-0.050594309946973226\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.04105503857135773\n",
      "\n",
      "episode 2, policy loss -0.08275870978832245\n",
      "\n",
      "episode 3, policy loss -0.05098453536629677\n",
      "\n",
      "episode 4, policy loss -0.009556051343679428\n",
      "\n",
      "episode 5, policy loss -0.010611401870846748\n",
      "\n",
      "episode 6, policy loss -0.057484984397888184\n",
      "\n",
      "episode 7, policy loss 0.012427115812897682\n",
      "\n",
      "episode 8, policy loss 0.000560009153559804\n",
      "\n",
      "episode 9, policy loss -0.07733245193958282\n",
      "\n",
      "episode 10, policy loss -0.08707081526517868\n",
      "\n",
      "episode 11, policy loss -0.09479912370443344\n",
      "\n",
      "episode 12, policy loss -0.02215736173093319\n",
      "\n",
      "episode 13, policy loss -0.14293891191482544\n",
      "\n",
      "episode 14, policy loss -0.04809936136007309\n",
      "\n",
      "episode 15, policy loss -0.08225832134485245\n",
      "\n",
      "episode 16, policy loss -0.014345897361636162\n",
      "\n",
      "Policy train loss in epoch 3:-0.05052911506209057\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19503195583820343\n",
      "\n",
      "episode 2, val func loss 0.19694915413856506\n",
      "\n",
      "episode 3, val func loss 0.25262925028800964\n",
      "\n",
      "episode 4, val func loss 0.18073143064975739\n",
      "\n",
      "episode 5, val func loss 0.18140701949596405\n",
      "\n",
      "episode 6, val func loss 0.17460636794567108\n",
      "\n",
      "episode 7, val func loss 0.17175951600074768\n",
      "\n",
      "episode 8, val func loss 0.2249000072479248\n",
      "\n",
      "episode 9, val func loss 0.1990009844303131\n",
      "\n",
      "episode 10, val func loss 0.2123783677816391\n",
      "\n",
      "episode 11, val func loss 0.17508162558078766\n",
      "\n",
      "episode 12, val func loss 0.21542035043239594\n",
      "\n",
      "episode 13, val func loss 0.20622208714485168\n",
      "\n",
      "episode 14, val func loss 0.21462130546569824\n",
      "\n",
      "episode 15, val func loss 0.20174077153205872\n",
      "\n",
      "episode 16, val func loss 0.17374689877033234\n",
      "\n",
      "Val func train loss in epoch 0:0.1985141932964325\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.20327647030353546\n",
      "\n",
      "episode 2, val func loss 0.17436467111110687\n",
      "\n",
      "episode 3, val func loss 0.21280673146247864\n",
      "\n",
      "episode 4, val func loss 0.2139039933681488\n",
      "\n",
      "episode 5, val func loss 0.18381908535957336\n",
      "\n",
      "episode 6, val func loss 0.24816332757472992\n",
      "\n",
      "episode 7, val func loss 0.22337661683559418\n",
      "\n",
      "episode 8, val func loss 0.17946036159992218\n",
      "\n",
      "episode 9, val func loss 0.20154930651187897\n",
      "\n",
      "episode 10, val func loss 0.2112000286579132\n",
      "\n",
      "episode 11, val func loss 0.17236092686653137\n",
      "\n",
      "episode 12, val func loss 0.19614887237548828\n",
      "\n",
      "episode 13, val func loss 0.19608645141124725\n",
      "\n",
      "episode 14, val func loss 0.19937682151794434\n",
      "\n",
      "episode 15, val func loss 0.17363223433494568\n",
      "\n",
      "episode 16, val func loss 0.17925558984279633\n",
      "\n",
      "Val func train loss in epoch 1:0.19804884307086468\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17932799458503723\n",
      "\n",
      "episode 2, val func loss 0.17391298711299896\n",
      "\n",
      "episode 3, val func loss 0.25930526852607727\n",
      "\n",
      "episode 4, val func loss 0.20225338637828827\n",
      "\n",
      "episode 5, val func loss 0.19717718660831451\n",
      "\n",
      "episode 6, val func loss 0.18070299923419952\n",
      "\n",
      "episode 7, val func loss 0.1740541011095047\n",
      "\n",
      "episode 8, val func loss 0.21095912158489227\n",
      "\n",
      "episode 9, val func loss 0.21460950374603271\n",
      "\n",
      "episode 10, val func loss 0.19574709236621857\n",
      "\n",
      "episode 11, val func loss 0.20374412834644318\n",
      "\n",
      "episode 12, val func loss 0.21236123144626617\n",
      "\n",
      "episode 13, val func loss 0.223353311419487\n",
      "\n",
      "episode 14, val func loss 0.17970673739910126\n",
      "\n",
      "episode 15, val func loss 0.1753872036933899\n",
      "\n",
      "episode 16, val func loss 0.19963115453720093\n",
      "\n",
      "Val func train loss in epoch 2:0.19888958800584078\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.2046474814414978\n",
      "\n",
      "episode 2, val func loss 0.2514464259147644\n",
      "\n",
      "episode 3, val func loss 0.19648736715316772\n",
      "\n",
      "episode 4, val func loss 0.2147233486175537\n",
      "\n",
      "episode 5, val func loss 0.19536855816841125\n",
      "\n",
      "episode 6, val func loss 0.2232658565044403\n",
      "\n",
      "episode 7, val func loss 0.18180988729000092\n",
      "\n",
      "episode 8, val func loss 0.17323637008666992\n",
      "\n",
      "episode 9, val func loss 0.17290854454040527\n",
      "\n",
      "episode 10, val func loss 0.1811378002166748\n",
      "\n",
      "episode 11, val func loss 0.201395183801651\n",
      "\n",
      "episode 12, val func loss 0.2133854180574417\n",
      "\n",
      "episode 13, val func loss 0.217034712433815\n",
      "\n",
      "episode 14, val func loss 0.19859297573566437\n",
      "\n",
      "episode 15, val func loss 0.17530134320259094\n",
      "\n",
      "episode 16, val func loss 0.17354637384414673\n",
      "\n",
      "Val func train loss in epoch 3:0.198392977938056\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.21554219722747803\n",
      "\n",
      "episode 2, val func loss 0.17351031303405762\n",
      "\n",
      "episode 3, val func loss 0.2510870695114136\n",
      "\n",
      "episode 4, val func loss 0.2112298607826233\n",
      "\n",
      "episode 5, val func loss 0.19614511728286743\n",
      "\n",
      "episode 6, val func loss 0.1838696151971817\n",
      "\n",
      "episode 7, val func loss 0.17424438893795013\n",
      "\n",
      "episode 8, val func loss 0.20206716656684875\n",
      "\n",
      "episode 9, val func loss 0.1744682937860489\n",
      "\n",
      "episode 10, val func loss 0.18172712624073029\n",
      "\n",
      "episode 11, val func loss 0.22479045391082764\n",
      "\n",
      "episode 12, val func loss 0.21590974926948547\n",
      "\n",
      "episode 13, val func loss 0.20837485790252686\n",
      "\n",
      "episode 14, val func loss 0.1972353160381317\n",
      "\n",
      "episode 15, val func loss 0.1988697052001953\n",
      "\n",
      "episode 16, val func loss 0.1752847582101822\n",
      "\n",
      "Val func train loss in epoch 4:0.1990222493186593\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17331695556640625\n",
      "\n",
      "episode 2, val func loss 0.1753002554178238\n",
      "\n",
      "episode 3, val func loss 0.2152249813079834\n",
      "\n",
      "episode 4, val func loss 0.2014252096414566\n",
      "\n",
      "episode 5, val func loss 0.25296708941459656\n",
      "\n",
      "episode 6, val func loss 0.19633567333221436\n",
      "\n",
      "episode 7, val func loss 0.19931383430957794\n",
      "\n",
      "episode 8, val func loss 0.18236622214317322\n",
      "\n",
      "episode 9, val func loss 0.17266003787517548\n",
      "\n",
      "episode 10, val func loss 0.22318707406520844\n",
      "\n",
      "episode 11, val func loss 0.17350329458713531\n",
      "\n",
      "episode 12, val func loss 0.1813507378101349\n",
      "\n",
      "episode 13, val func loss 0.21125781536102295\n",
      "\n",
      "episode 14, val func loss 0.21560806035995483\n",
      "\n",
      "episode 15, val func loss 0.20621050894260406\n",
      "\n",
      "episode 16, val func loss 0.19572311639785767\n",
      "\n",
      "Val func train loss in epoch 5:0.19848442915827036\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17214107513427734\n",
      "\n",
      "episode 2, val func loss 0.21468299627304077\n",
      "\n",
      "episode 3, val func loss 0.17685317993164062\n",
      "\n",
      "episode 4, val func loss 0.20467284321784973\n",
      "\n",
      "episode 5, val func loss 0.22370868921279907\n",
      "\n",
      "episode 6, val func loss 0.1822005659341812\n",
      "\n",
      "episode 7, val func loss 0.17418670654296875\n",
      "\n",
      "episode 8, val func loss 0.1951913684606552\n",
      "\n",
      "episode 9, val func loss 0.17384357750415802\n",
      "\n",
      "episode 10, val func loss 0.1807277351617813\n",
      "\n",
      "episode 11, val func loss 0.19906245172023773\n",
      "\n",
      "episode 12, val func loss 0.21431446075439453\n",
      "\n",
      "episode 13, val func loss 0.2572714686393738\n",
      "\n",
      "episode 14, val func loss 0.20188473165035248\n",
      "\n",
      "episode 15, val func loss 0.19704478979110718\n",
      "\n",
      "episode 16, val func loss 0.2144748717546463\n",
      "\n",
      "Val func train loss in epoch 6:0.1988913444802165\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19573116302490234\n",
      "\n",
      "episode 2, val func loss 0.19722215831279755\n",
      "\n",
      "episode 3, val func loss 0.199591726064682\n",
      "\n",
      "episode 4, val func loss 0.18372423946857452\n",
      "\n",
      "episode 5, val func loss 0.17891092598438263\n",
      "\n",
      "episode 6, val func loss 0.17306195199489594\n",
      "\n",
      "episode 7, val func loss 0.25169992446899414\n",
      "\n",
      "episode 8, val func loss 0.2145102322101593\n",
      "\n",
      "episode 9, val func loss 0.17382118105888367\n",
      "\n",
      "episode 10, val func loss 0.2115238457918167\n",
      "\n",
      "episode 11, val func loss 0.21481119096279144\n",
      "\n",
      "episode 12, val func loss 0.17293992638587952\n",
      "\n",
      "episode 13, val func loss 0.20111513137817383\n",
      "\n",
      "episode 14, val func loss 0.18110843002796173\n",
      "\n",
      "episode 15, val func loss 0.20541146397590637\n",
      "\n",
      "episode 16, val func loss 0.22403472661972046\n",
      "\n",
      "Val func train loss in epoch 7:0.19870113860815763\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1738973706960678\n",
      "\n",
      "episode 2, val func loss 0.18115070462226868\n",
      "\n",
      "episode 3, val func loss 0.19900208711624146\n",
      "\n",
      "episode 4, val func loss 0.19729545712471008\n",
      "\n",
      "episode 5, val func loss 0.2246062308549881\n",
      "\n",
      "episode 6, val func loss 0.21477757394313812\n",
      "\n",
      "episode 7, val func loss 0.21533437073230743\n",
      "\n",
      "episode 8, val func loss 0.17222857475280762\n",
      "\n",
      "episode 9, val func loss 0.19546903669834137\n",
      "\n",
      "episode 10, val func loss 0.21037738025188446\n",
      "\n",
      "episode 11, val func loss 0.20435358583927155\n",
      "\n",
      "episode 12, val func loss 0.18313869833946228\n",
      "\n",
      "episode 13, val func loss 0.20281100273132324\n",
      "\n",
      "episode 14, val func loss 0.2481251358985901\n",
      "\n",
      "episode 15, val func loss 0.17578141391277313\n",
      "\n",
      "episode 16, val func loss 0.17898419499397278\n",
      "\n",
      "Val func train loss in epoch 8:0.19858330115675926\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.2143450826406479\n",
      "\n",
      "episode 2, val func loss 0.19683779776096344\n",
      "\n",
      "episode 3, val func loss 0.17385713756084442\n",
      "\n",
      "episode 4, val func loss 0.2533511221408844\n",
      "\n",
      "episode 5, val func loss 0.21515685319900513\n",
      "\n",
      "episode 6, val func loss 0.20635445415973663\n",
      "\n",
      "episode 7, val func loss 0.1812478005886078\n",
      "\n",
      "episode 8, val func loss 0.19888225197792053\n",
      "\n",
      "episode 9, val func loss 0.17277652025222778\n",
      "\n",
      "episode 10, val func loss 0.21066834032535553\n",
      "\n",
      "episode 11, val func loss 0.1819010078907013\n",
      "\n",
      "episode 12, val func loss 0.22386614978313446\n",
      "\n",
      "episode 13, val func loss 0.17337752878665924\n",
      "\n",
      "episode 14, val func loss 0.2010825276374817\n",
      "\n",
      "episode 15, val func loss 0.19517451524734497\n",
      "\n",
      "episode 16, val func loss 0.1749933511018753\n",
      "\n",
      "Val func train loss in epoch 9:0.1983670275658369\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18058690428733826\n",
      "\n",
      "episode 2, val func loss 0.16968680918216705\n",
      "\n",
      "episode 3, val func loss 0.20438887178897858\n",
      "\n",
      "episode 4, val func loss 0.26144930720329285\n",
      "\n",
      "episode 5, val func loss 0.19951236248016357\n",
      "\n",
      "episode 6, val func loss 0.20766209065914154\n",
      "\n",
      "episode 7, val func loss 0.17416450381278992\n",
      "\n",
      "episode 8, val func loss 0.22346067428588867\n",
      "\n",
      "episode 9, val func loss 0.1964891105890274\n",
      "\n",
      "episode 10, val func loss 0.17497718334197998\n",
      "\n",
      "episode 11, val func loss 0.21059852838516235\n",
      "\n",
      "episode 12, val func loss 0.19811707735061646\n",
      "\n",
      "episode 13, val func loss 0.18246513605117798\n",
      "\n",
      "episode 14, val func loss 0.17488156259059906\n",
      "\n",
      "episode 15, val func loss 0.2269415706396103\n",
      "\n",
      "episode 16, val func loss 0.2199995219707489\n",
      "\n",
      "Val func train loss in epoch 10:0.20033632591366768\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19553913176059723\n",
      "\n",
      "episode 2, val func loss 0.2025865912437439\n",
      "\n",
      "episode 3, val func loss 0.22361178696155548\n",
      "\n",
      "episode 4, val func loss 0.18661540746688843\n",
      "\n",
      "episode 5, val func loss 0.17831876873970032\n",
      "\n",
      "episode 6, val func loss 0.19814491271972656\n",
      "\n",
      "episode 7, val func loss 0.19933658838272095\n",
      "\n",
      "episode 8, val func loss 0.2141885757446289\n",
      "\n",
      "episode 9, val func loss 0.25495463609695435\n",
      "\n",
      "episode 10, val func loss 0.1723063737154007\n",
      "\n",
      "episode 11, val func loss 0.1812303066253662\n",
      "\n",
      "episode 12, val func loss 0.21337705850601196\n",
      "\n",
      "episode 13, val func loss 0.17725859582424164\n",
      "\n",
      "episode 14, val func loss 0.17282216250896454\n",
      "\n",
      "episode 15, val func loss 0.20530767738819122\n",
      "\n",
      "episode 16, val func loss 0.21531279385089874\n",
      "\n",
      "Val func train loss in epoch 11:0.19943196047097445\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17362083494663239\n",
      "\n",
      "episode 2, val func loss 0.20597778260707855\n",
      "\n",
      "episode 3, val func loss 0.1722908765077591\n",
      "\n",
      "episode 4, val func loss 0.21495421230793\n",
      "\n",
      "episode 5, val func loss 0.2113635092973709\n",
      "\n",
      "episode 6, val func loss 0.17376752197742462\n",
      "\n",
      "episode 7, val func loss 0.1821039468050003\n",
      "\n",
      "episode 8, val func loss 0.22400008141994476\n",
      "\n",
      "episode 9, val func loss 0.17685268819332123\n",
      "\n",
      "episode 10, val func loss 0.19910117983818054\n",
      "\n",
      "episode 11, val func loss 0.19706204533576965\n",
      "\n",
      "episode 12, val func loss 0.252497136592865\n",
      "\n",
      "episode 13, val func loss 0.201593279838562\n",
      "\n",
      "episode 14, val func loss 0.18044734001159668\n",
      "\n",
      "episode 15, val func loss 0.2147628217935562\n",
      "\n",
      "episode 16, val func loss 0.19528403878211975\n",
      "\n",
      "Val func train loss in epoch 12:0.19847995601594448\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1764693558216095\n",
      "\n",
      "episode 2, val func loss 0.20199733972549438\n",
      "\n",
      "episode 3, val func loss 0.17372137308120728\n",
      "\n",
      "episode 4, val func loss 0.25120195746421814\n",
      "\n",
      "episode 5, val func loss 0.21142339706420898\n",
      "\n",
      "episode 6, val func loss 0.17281922698020935\n",
      "\n",
      "episode 7, val func loss 0.21392083168029785\n",
      "\n",
      "episode 8, val func loss 0.19642196595668793\n",
      "\n",
      "episode 9, val func loss 0.22352264821529388\n",
      "\n",
      "episode 10, val func loss 0.1728595644235611\n",
      "\n",
      "episode 11, val func loss 0.19578194618225098\n",
      "\n",
      "episode 12, val func loss 0.20456111431121826\n",
      "\n",
      "episode 13, val func loss 0.21292288601398468\n",
      "\n",
      "episode 14, val func loss 0.18224602937698364\n",
      "\n",
      "episode 15, val func loss 0.1996176838874817\n",
      "\n",
      "episode 16, val func loss 0.18172010779380798\n",
      "\n",
      "Val func train loss in epoch 13:0.19820046424865723\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.21340078115463257\n",
      "\n",
      "episode 2, val func loss 0.19516991078853607\n",
      "\n",
      "episode 3, val func loss 0.2055407464504242\n",
      "\n",
      "episode 4, val func loss 0.1806281954050064\n",
      "\n",
      "episode 5, val func loss 0.19874408841133118\n",
      "\n",
      "episode 6, val func loss 0.19666887819766998\n",
      "\n",
      "episode 7, val func loss 0.2519585192203522\n",
      "\n",
      "episode 8, val func loss 0.22442299127578735\n",
      "\n",
      "episode 9, val func loss 0.17262859642505646\n",
      "\n",
      "episode 10, val func loss 0.21162307262420654\n",
      "\n",
      "episode 11, val func loss 0.17254875600337982\n",
      "\n",
      "episode 12, val func loss 0.18171758949756622\n",
      "\n",
      "episode 13, val func loss 0.20185586810112\n",
      "\n",
      "episode 14, val func loss 0.17400147020816803\n",
      "\n",
      "episode 15, val func loss 0.1756007969379425\n",
      "\n",
      "episode 16, val func loss 0.2155488133430481\n",
      "\n",
      "Val func train loss in epoch 14:0.19825369212776423\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.2126394361257553\n",
      "\n",
      "episode 2, val func loss 0.1795603334903717\n",
      "\n",
      "episode 3, val func loss 0.1957390308380127\n",
      "\n",
      "episode 4, val func loss 0.2530488073825836\n",
      "\n",
      "episode 5, val func loss 0.2150544673204422\n",
      "\n",
      "episode 6, val func loss 0.2143605500459671\n",
      "\n",
      "episode 7, val func loss 0.201703280210495\n",
      "\n",
      "episode 8, val func loss 0.17635764181613922\n",
      "\n",
      "episode 9, val func loss 0.18381336331367493\n",
      "\n",
      "episode 10, val func loss 0.18025673925876617\n",
      "\n",
      "episode 11, val func loss 0.2035171091556549\n",
      "\n",
      "episode 12, val func loss 0.2233114242553711\n",
      "\n",
      "episode 13, val func loss 0.17295792698860168\n",
      "\n",
      "episode 14, val func loss 0.19722607731819153\n",
      "\n",
      "episode 15, val func loss 0.172611266374588\n",
      "\n",
      "episode 16, val func loss 0.19904012978076935\n",
      "\n",
      "Val func train loss in epoch 15:0.19882484897971153\n",
      "***********************TIME WAS 4.948806981245677 min*****************************\n",
      "\n",
      "**********************ROUND 75 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.08278796076774597\n",
      "\n",
      "episode 2, policy loss -0.036872174590826035\n",
      "\n",
      "episode 3, policy loss -0.02601434662938118\n",
      "\n",
      "episode 4, policy loss -0.07785492390394211\n",
      "\n",
      "episode 5, policy loss 0.011671161279082298\n",
      "\n",
      "episode 6, policy loss -0.0406302735209465\n",
      "\n",
      "episode 7, policy loss -0.03192621096968651\n",
      "\n",
      "episode 8, policy loss -0.04419512301683426\n",
      "\n",
      "episode 9, policy loss -0.026832645758986473\n",
      "\n",
      "episode 10, policy loss -0.040403738617897034\n",
      "\n",
      "episode 11, policy loss 0.015229112468659878\n",
      "\n",
      "episode 12, policy loss -0.09858354181051254\n",
      "\n",
      "episode 13, policy loss -0.014474965631961823\n",
      "\n",
      "episode 14, policy loss -0.0624646320939064\n",
      "\n",
      "episode 15, policy loss -0.0672726258635521\n",
      "\n",
      "episode 16, policy loss -0.014623126946389675\n",
      "\n",
      "Policy train loss in epoch 0:-0.03987725102342665\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.04184357076883316\n",
      "\n",
      "episode 2, policy loss -0.08504194021224976\n",
      "\n",
      "episode 3, policy loss -0.030282221734523773\n",
      "\n",
      "episode 4, policy loss -0.027000294998288155\n",
      "\n",
      "episode 5, policy loss -0.043358299881219864\n",
      "\n",
      "episode 6, policy loss -0.06050450727343559\n",
      "\n",
      "episode 7, policy loss -0.017168954014778137\n",
      "\n",
      "episode 8, policy loss -0.027147963643074036\n",
      "\n",
      "episode 9, policy loss -0.01063441950827837\n",
      "\n",
      "episode 10, policy loss -0.08784805238246918\n",
      "\n",
      "episode 11, policy loss -0.04423615336418152\n",
      "\n",
      "episode 12, policy loss -0.068611279129982\n",
      "\n",
      "episode 13, policy loss 0.007832770235836506\n",
      "\n",
      "episode 14, policy loss -0.04130474478006363\n",
      "\n",
      "episode 15, policy loss 0.012993254698812962\n",
      "\n",
      "episode 16, policy loss -0.09985534846782684\n",
      "\n",
      "Policy train loss in epoch 1:-0.04150073282653466\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.013182378374040127\n",
      "\n",
      "episode 2, policy loss -0.040143754333257675\n",
      "\n",
      "episode 3, policy loss -0.014645490795373917\n",
      "\n",
      "episode 4, policy loss -0.026038354262709618\n",
      "\n",
      "episode 5, policy loss -0.061686500906944275\n",
      "\n",
      "episode 6, policy loss 0.008241383358836174\n",
      "\n",
      "episode 7, policy loss -0.04412569850683212\n",
      "\n",
      "episode 8, policy loss -0.09931263327598572\n",
      "\n",
      "episode 9, policy loss -0.03354690968990326\n",
      "\n",
      "episode 10, policy loss -0.06992224603891373\n",
      "\n",
      "episode 11, policy loss -0.08725066483020782\n",
      "\n",
      "episode 12, policy loss -0.08554773777723312\n",
      "\n",
      "episode 13, policy loss -0.031063875183463097\n",
      "\n",
      "episode 14, policy loss -0.045486390590667725\n",
      "\n",
      "episode 15, policy loss -0.014310430735349655\n",
      "\n",
      "episode 16, policy loss -0.04241278022527695\n",
      "\n",
      "Policy train loss in epoch 2:-0.04212935658870265\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.07041442394256592\n",
      "\n",
      "episode 2, policy loss -0.08517344295978546\n",
      "\n",
      "episode 3, policy loss -0.08661133795976639\n",
      "\n",
      "episode 4, policy loss -0.06162666156888008\n",
      "\n",
      "episode 5, policy loss 0.011333043687045574\n",
      "\n",
      "episode 6, policy loss -0.014173280447721481\n",
      "\n",
      "episode 7, policy loss 0.008643709123134613\n",
      "\n",
      "episode 8, policy loss -0.09680192917585373\n",
      "\n",
      "episode 9, policy loss -0.027233131229877472\n",
      "\n",
      "episode 10, policy loss -0.030234219506382942\n",
      "\n",
      "episode 11, policy loss -0.012619208544492722\n",
      "\n",
      "episode 12, policy loss -0.04125095158815384\n",
      "\n",
      "episode 13, policy loss -0.040718015283346176\n",
      "\n",
      "episode 14, policy loss -0.04614977911114693\n",
      "\n",
      "episode 15, policy loss -0.04521007463335991\n",
      "\n",
      "episode 16, policy loss -0.03371836617588997\n",
      "\n",
      "Policy train loss in epoch 3:-0.04199737933231518\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.20539212226867676\n",
      "\n",
      "episode 2, val func loss 0.2077096700668335\n",
      "\n",
      "episode 3, val func loss 0.20941303670406342\n",
      "\n",
      "episode 4, val func loss 0.1692393273115158\n",
      "\n",
      "episode 5, val func loss 0.20473115146160126\n",
      "\n",
      "episode 6, val func loss 0.18505540490150452\n",
      "\n",
      "episode 7, val func loss 0.18194891512393951\n",
      "\n",
      "episode 8, val func loss 0.16398993134498596\n",
      "\n",
      "episode 9, val func loss 0.18919534981250763\n",
      "\n",
      "episode 10, val func loss 0.18550819158554077\n",
      "\n",
      "episode 11, val func loss 0.17359749972820282\n",
      "\n",
      "episode 12, val func loss 0.19278451800346375\n",
      "\n",
      "episode 13, val func loss 0.17142298817634583\n",
      "\n",
      "episode 14, val func loss 0.18002228438854218\n",
      "\n",
      "episode 15, val func loss 0.22500544786453247\n",
      "\n",
      "episode 16, val func loss 0.19402927160263062\n",
      "\n",
      "Val func train loss in epoch 0:0.18994031939655542\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17067080736160278\n",
      "\n",
      "episode 2, val func loss 0.1882738620042801\n",
      "\n",
      "episode 3, val func loss 0.20690226554870605\n",
      "\n",
      "episode 4, val func loss 0.2095910608768463\n",
      "\n",
      "episode 5, val func loss 0.17998476326465607\n",
      "\n",
      "episode 6, val func loss 0.16917558014392853\n",
      "\n",
      "episode 7, val func loss 0.19462206959724426\n",
      "\n",
      "episode 8, val func loss 0.17368333041667938\n",
      "\n",
      "episode 9, val func loss 0.2046617865562439\n",
      "\n",
      "episode 10, val func loss 0.1933259516954422\n",
      "\n",
      "episode 11, val func loss 0.22029225528240204\n",
      "\n",
      "episode 12, val func loss 0.18542194366455078\n",
      "\n",
      "episode 13, val func loss 0.20540685951709747\n",
      "\n",
      "episode 14, val func loss 0.16475261747837067\n",
      "\n",
      "episode 15, val func loss 0.18131043016910553\n",
      "\n",
      "episode 16, val func loss 0.18493416905403137\n",
      "\n",
      "Val func train loss in epoch 1:0.18956310953944921\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19421079754829407\n",
      "\n",
      "episode 2, val func loss 0.2050010859966278\n",
      "\n",
      "episode 3, val func loss 0.1732597053050995\n",
      "\n",
      "episode 4, val func loss 0.18443986773490906\n",
      "\n",
      "episode 5, val func loss 0.19442667067050934\n",
      "\n",
      "episode 6, val func loss 0.16947464644908905\n",
      "\n",
      "episode 7, val func loss 0.1855079084634781\n",
      "\n",
      "episode 8, val func loss 0.22224749624729156\n",
      "\n",
      "episode 9, val func loss 0.2094748169183731\n",
      "\n",
      "episode 10, val func loss 0.20606186985969543\n",
      "\n",
      "episode 11, val func loss 0.1739855408668518\n",
      "\n",
      "episode 12, val func loss 0.1888764500617981\n",
      "\n",
      "episode 13, val func loss 0.1641903817653656\n",
      "\n",
      "episode 14, val func loss 0.18132305145263672\n",
      "\n",
      "episode 15, val func loss 0.18020333349704742\n",
      "\n",
      "episode 16, val func loss 0.20458628237247467\n",
      "\n",
      "Val func train loss in epoch 2:0.18982936907559633\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18833038210868835\n",
      "\n",
      "episode 2, val func loss 0.20541837811470032\n",
      "\n",
      "episode 3, val func loss 0.17220650613307953\n",
      "\n",
      "episode 4, val func loss 0.1801701933145523\n",
      "\n",
      "episode 5, val func loss 0.16906489431858063\n",
      "\n",
      "episode 6, val func loss 0.22202813625335693\n",
      "\n",
      "episode 7, val func loss 0.2092723399400711\n",
      "\n",
      "episode 8, val func loss 0.1855124682188034\n",
      "\n",
      "episode 9, val func loss 0.17330029606819153\n",
      "\n",
      "episode 10, val func loss 0.19509519636631012\n",
      "\n",
      "episode 11, val func loss 0.18486852943897247\n",
      "\n",
      "episode 12, val func loss 0.1933964043855667\n",
      "\n",
      "episode 13, val func loss 0.20473982393741608\n",
      "\n",
      "episode 14, val func loss 0.2066980004310608\n",
      "\n",
      "episode 15, val func loss 0.16397909820079803\n",
      "\n",
      "episode 16, val func loss 0.18119116127490997\n",
      "\n",
      "Val func train loss in epoch 3:0.18970448803156614\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.22039125859737396\n",
      "\n",
      "episode 2, val func loss 0.180413618683815\n",
      "\n",
      "episode 3, val func loss 0.19399122893810272\n",
      "\n",
      "episode 4, val func loss 0.18551163375377655\n",
      "\n",
      "episode 5, val func loss 0.18100561201572418\n",
      "\n",
      "episode 6, val func loss 0.18932215869426727\n",
      "\n",
      "episode 7, val func loss 0.17381396889686584\n",
      "\n",
      "episode 8, val func loss 0.1690952032804489\n",
      "\n",
      "episode 9, val func loss 0.20533862709999084\n",
      "\n",
      "episode 10, val func loss 0.1854170560836792\n",
      "\n",
      "episode 11, val func loss 0.1620776206254959\n",
      "\n",
      "episode 12, val func loss 0.19398990273475647\n",
      "\n",
      "episode 13, val func loss 0.2100084125995636\n",
      "\n",
      "episode 14, val func loss 0.17074652016162872\n",
      "\n",
      "episode 15, val func loss 0.21004526317119598\n",
      "\n",
      "episode 16, val func loss 0.20620796084403992\n",
      "\n",
      "Val func train loss in epoch 4:0.18983600288629532\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17221134901046753\n",
      "\n",
      "episode 2, val func loss 0.1699998378753662\n",
      "\n",
      "episode 3, val func loss 0.1846596747636795\n",
      "\n",
      "episode 4, val func loss 0.20451636612415314\n",
      "\n",
      "episode 5, val func loss 0.21916069090366364\n",
      "\n",
      "episode 6, val func loss 0.20342522859573364\n",
      "\n",
      "episode 7, val func loss 0.18765559792518616\n",
      "\n",
      "episode 8, val func loss 0.20427152514457703\n",
      "\n",
      "episode 9, val func loss 0.18224138021469116\n",
      "\n",
      "episode 10, val func loss 0.176690936088562\n",
      "\n",
      "episode 11, val func loss 0.19100873172283173\n",
      "\n",
      "episode 12, val func loss 0.18138550221920013\n",
      "\n",
      "episode 13, val func loss 0.1941617876291275\n",
      "\n",
      "episode 14, val func loss 0.16235455870628357\n",
      "\n",
      "episode 15, val func loss 0.21094174683094025\n",
      "\n",
      "episode 16, val func loss 0.19260776042938232\n",
      "\n",
      "Val func train loss in epoch 5:0.18983079213649035\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18184031546115875\n",
      "\n",
      "episode 2, val func loss 0.21047526597976685\n",
      "\n",
      "episode 3, val func loss 0.17305824160575867\n",
      "\n",
      "episode 4, val func loss 0.22250233590602875\n",
      "\n",
      "episode 5, val func loss 0.18667113780975342\n",
      "\n",
      "episode 6, val func loss 0.17301113903522491\n",
      "\n",
      "episode 7, val func loss 0.1906241625547409\n",
      "\n",
      "episode 8, val func loss 0.19489452242851257\n",
      "\n",
      "episode 9, val func loss 0.17112240195274353\n",
      "\n",
      "episode 10, val func loss 0.20634450018405914\n",
      "\n",
      "episode 11, val func loss 0.21058212220668793\n",
      "\n",
      "episode 12, val func loss 0.21115994453430176\n",
      "\n",
      "episode 13, val func loss 0.18503887951374054\n",
      "\n",
      "episode 14, val func loss 0.181229829788208\n",
      "\n",
      "episode 15, val func loss 0.1687333881855011\n",
      "\n",
      "episode 16, val func loss 0.1952989399433136\n",
      "\n",
      "Val func train loss in epoch 6:0.19141169544309378\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.16384468972682953\n",
      "\n",
      "episode 2, val func loss 0.18029093742370605\n",
      "\n",
      "episode 3, val func loss 0.17144113779067993\n",
      "\n",
      "episode 4, val func loss 0.2061651349067688\n",
      "\n",
      "episode 5, val func loss 0.18598875403404236\n",
      "\n",
      "episode 6, val func loss 0.21031782031059265\n",
      "\n",
      "episode 7, val func loss 0.18216514587402344\n",
      "\n",
      "episode 8, val func loss 0.16973991692066193\n",
      "\n",
      "episode 9, val func loss 0.19446060061454773\n",
      "\n",
      "episode 10, val func loss 0.2055288851261139\n",
      "\n",
      "episode 11, val func loss 0.22080813348293304\n",
      "\n",
      "episode 12, val func loss 0.18979859352111816\n",
      "\n",
      "episode 13, val func loss 0.17465738952159882\n",
      "\n",
      "episode 14, val func loss 0.20440250635147095\n",
      "\n",
      "episode 15, val func loss 0.1864657700061798\n",
      "\n",
      "episode 16, val func loss 0.19471406936645508\n",
      "\n",
      "Val func train loss in epoch 7:0.19004934281110764\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1731872856616974\n",
      "\n",
      "episode 2, val func loss 0.20473425090312958\n",
      "\n",
      "episode 3, val func loss 0.1844678521156311\n",
      "\n",
      "episode 4, val func loss 0.1816120445728302\n",
      "\n",
      "episode 5, val func loss 0.20776790380477905\n",
      "\n",
      "episode 6, val func loss 0.16913777589797974\n",
      "\n",
      "episode 7, val func loss 0.20924067497253418\n",
      "\n",
      "episode 8, val func loss 0.20468921959400177\n",
      "\n",
      "episode 9, val func loss 0.18593639135360718\n",
      "\n",
      "episode 10, val func loss 0.18991084396839142\n",
      "\n",
      "episode 11, val func loss 0.1742449700832367\n",
      "\n",
      "episode 12, val func loss 0.19388684630393982\n",
      "\n",
      "episode 13, val func loss 0.16386015713214874\n",
      "\n",
      "episode 14, val func loss 0.22174054384231567\n",
      "\n",
      "episode 15, val func loss 0.17969733476638794\n",
      "\n",
      "episode 16, val func loss 0.19420002400875092\n",
      "\n",
      "Val func train loss in epoch 8:0.1898946324363351\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20547987520694733\n",
      "\n",
      "episode 2, val func loss 0.17324934899806976\n",
      "\n",
      "episode 3, val func loss 0.2099156230688095\n",
      "\n",
      "episode 4, val func loss 0.18169556558132172\n",
      "\n",
      "episode 5, val func loss 0.16898363828659058\n",
      "\n",
      "episode 6, val func loss 0.19425220787525177\n",
      "\n",
      "episode 7, val func loss 0.17222221195697784\n",
      "\n",
      "episode 8, val func loss 0.20560969412326813\n",
      "\n",
      "episode 9, val func loss 0.1889074593782425\n",
      "\n",
      "episode 10, val func loss 0.18449659645557404\n",
      "\n",
      "episode 11, val func loss 0.20717372000217438\n",
      "\n",
      "episode 12, val func loss 0.18045932054519653\n",
      "\n",
      "episode 13, val func loss 0.19343756139278412\n",
      "\n",
      "episode 14, val func loss 0.2195211499929428\n",
      "\n",
      "episode 15, val func loss 0.1862325519323349\n",
      "\n",
      "episode 16, val func loss 0.16529341042041779\n",
      "\n",
      "Val func train loss in epoch 9:0.18980812095105648\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.21908479928970337\n",
      "\n",
      "episode 2, val func loss 0.16495148837566376\n",
      "\n",
      "episode 3, val func loss 0.17297041416168213\n",
      "\n",
      "episode 4, val func loss 0.18559883534908295\n",
      "\n",
      "episode 5, val func loss 0.20647920668125153\n",
      "\n",
      "episode 6, val func loss 0.18479503691196442\n",
      "\n",
      "episode 7, val func loss 0.1820315271615982\n",
      "\n",
      "episode 8, val func loss 0.20880189538002014\n",
      "\n",
      "episode 9, val func loss 0.20895299315452576\n",
      "\n",
      "episode 10, val func loss 0.17371049523353577\n",
      "\n",
      "episode 11, val func loss 0.19490276277065277\n",
      "\n",
      "episode 12, val func loss 0.2042246311903\n",
      "\n",
      "episode 13, val func loss 0.19008667767047882\n",
      "\n",
      "episode 14, val func loss 0.19452114403247833\n",
      "\n",
      "episode 15, val func loss 0.1808994710445404\n",
      "\n",
      "episode 16, val func loss 0.16986866295337677\n",
      "\n",
      "Val func train loss in epoch 10:0.19011750258505344\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16950692236423492\n",
      "\n",
      "episode 2, val func loss 0.16257071495056152\n",
      "\n",
      "episode 3, val func loss 0.1882905513048172\n",
      "\n",
      "episode 4, val func loss 0.1927168071269989\n",
      "\n",
      "episode 5, val func loss 0.21191257238388062\n",
      "\n",
      "episode 6, val func loss 0.1736542135477066\n",
      "\n",
      "episode 7, val func loss 0.21385043859481812\n",
      "\n",
      "episode 8, val func loss 0.19436649978160858\n",
      "\n",
      "episode 9, val func loss 0.1850420981645584\n",
      "\n",
      "episode 10, val func loss 0.17167606949806213\n",
      "\n",
      "episode 11, val func loss 0.22014199197292328\n",
      "\n",
      "episode 12, val func loss 0.18107488751411438\n",
      "\n",
      "episode 13, val func loss 0.20424038171768188\n",
      "\n",
      "episode 14, val func loss 0.18736182153224945\n",
      "\n",
      "episode 15, val func loss 0.2043885737657547\n",
      "\n",
      "episode 16, val func loss 0.18194153904914856\n",
      "\n",
      "Val func train loss in epoch 11:0.19017100520431995\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.2178870141506195\n",
      "\n",
      "episode 2, val func loss 0.20442616939544678\n",
      "\n",
      "episode 3, val func loss 0.17598536610603333\n",
      "\n",
      "episode 4, val func loss 0.17552338540554047\n",
      "\n",
      "episode 5, val func loss 0.18140356242656708\n",
      "\n",
      "episode 6, val func loss 0.18891264498233795\n",
      "\n",
      "episode 7, val func loss 0.2079661637544632\n",
      "\n",
      "episode 8, val func loss 0.16926951706409454\n",
      "\n",
      "episode 9, val func loss 0.2099374383687973\n",
      "\n",
      "episode 10, val func loss 0.18483605980873108\n",
      "\n",
      "episode 11, val func loss 0.18535485863685608\n",
      "\n",
      "episode 12, val func loss 0.20657876133918762\n",
      "\n",
      "episode 13, val func loss 0.19367894530296326\n",
      "\n",
      "episode 14, val func loss 0.1927526295185089\n",
      "\n",
      "episode 15, val func loss 0.1801874339580536\n",
      "\n",
      "episode 16, val func loss 0.16354185342788696\n",
      "\n",
      "Val func train loss in epoch 12:0.18989011272788048\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18137283623218536\n",
      "\n",
      "episode 2, val func loss 0.18025439977645874\n",
      "\n",
      "episode 3, val func loss 0.16895689070224762\n",
      "\n",
      "episode 4, val func loss 0.1711304634809494\n",
      "\n",
      "episode 5, val func loss 0.19276967644691467\n",
      "\n",
      "episode 6, val func loss 0.18593730032444\n",
      "\n",
      "episode 7, val func loss 0.1617327332496643\n",
      "\n",
      "episode 8, val func loss 0.21115975081920624\n",
      "\n",
      "episode 9, val func loss 0.18881654739379883\n",
      "\n",
      "episode 10, val func loss 0.2079382836818695\n",
      "\n",
      "episode 11, val func loss 0.2242269515991211\n",
      "\n",
      "episode 12, val func loss 0.1736982762813568\n",
      "\n",
      "episode 13, val func loss 0.20485107600688934\n",
      "\n",
      "episode 14, val func loss 0.19566117227077484\n",
      "\n",
      "episode 15, val func loss 0.18621988594532013\n",
      "\n",
      "episode 16, val func loss 0.20521622896194458\n",
      "\n",
      "Val func train loss in epoch 13:0.18999640457332134\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.21712656319141388\n",
      "\n",
      "episode 2, val func loss 0.18874375522136688\n",
      "\n",
      "episode 3, val func loss 0.16925343871116638\n",
      "\n",
      "episode 4, val func loss 0.1759284883737564\n",
      "\n",
      "episode 5, val func loss 0.16984274983406067\n",
      "\n",
      "episode 6, val func loss 0.20712058246135712\n",
      "\n",
      "episode 7, val func loss 0.1818459928035736\n",
      "\n",
      "episode 8, val func loss 0.21031071245670319\n",
      "\n",
      "episode 9, val func loss 0.1732088178396225\n",
      "\n",
      "episode 10, val func loss 0.18844115734100342\n",
      "\n",
      "episode 11, val func loss 0.1851876676082611\n",
      "\n",
      "episode 12, val func loss 0.1926141381263733\n",
      "\n",
      "episode 13, val func loss 0.1937572956085205\n",
      "\n",
      "episode 14, val func loss 0.2062864750623703\n",
      "\n",
      "episode 15, val func loss 0.2052690088748932\n",
      "\n",
      "episode 16, val func loss 0.18034367263317108\n",
      "\n",
      "Val func train loss in epoch 14:0.19033003225922585\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.21884508430957794\n",
      "\n",
      "episode 2, val func loss 0.16719123721122742\n",
      "\n",
      "episode 3, val func loss 0.20960302650928497\n",
      "\n",
      "episode 4, val func loss 0.18144354224205017\n",
      "\n",
      "episode 5, val func loss 0.1730940043926239\n",
      "\n",
      "episode 6, val func loss 0.19432877004146576\n",
      "\n",
      "episode 7, val func loss 0.18008220195770264\n",
      "\n",
      "episode 8, val func loss 0.18820612132549286\n",
      "\n",
      "episode 9, val func loss 0.21049608290195465\n",
      "\n",
      "episode 10, val func loss 0.17337532341480255\n",
      "\n",
      "episode 11, val func loss 0.2068473994731903\n",
      "\n",
      "episode 12, val func loss 0.20435719192028046\n",
      "\n",
      "episode 13, val func loss 0.18764632940292358\n",
      "\n",
      "episode 14, val func loss 0.1853187084197998\n",
      "\n",
      "episode 15, val func loss 0.19424289464950562\n",
      "\n",
      "episode 16, val func loss 0.16947226226329803\n",
      "\n",
      "Val func train loss in epoch 15:0.1902843862771988\n",
      "***********************TIME WAS 4.949149696032206 min*****************************\n",
      "\n",
      "**********************ROUND 76 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.048624079674482346\n",
      "\n",
      "episode 2, policy loss -0.014793123118579388\n",
      "\n",
      "episode 3, policy loss -0.04975735396146774\n",
      "\n",
      "episode 4, policy loss -0.048147052526474\n",
      "\n",
      "episode 5, policy loss -0.059480808675289154\n",
      "\n",
      "episode 6, policy loss -0.0056981537491083145\n",
      "\n",
      "episode 7, policy loss -0.047873642295598984\n",
      "\n",
      "episode 8, policy loss -0.03138844296336174\n",
      "\n",
      "episode 9, policy loss -0.05555763840675354\n",
      "\n",
      "episode 10, policy loss 0.023989222943782806\n",
      "\n",
      "episode 11, policy loss -0.06416816264390945\n",
      "\n",
      "episode 12, policy loss -0.05921439453959465\n",
      "\n",
      "episode 13, policy loss -0.025425899773836136\n",
      "\n",
      "episode 14, policy loss -0.04978998377919197\n",
      "\n",
      "episode 15, policy loss -0.079142265021801\n",
      "\n",
      "episode 16, policy loss -0.018717313185334206\n",
      "\n",
      "Policy train loss in epoch 0:-0.03961181821068749\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.055917125195264816\n",
      "\n",
      "episode 2, policy loss -0.04977075383067131\n",
      "\n",
      "episode 3, policy loss -0.0543360561132431\n",
      "\n",
      "episode 4, policy loss -0.05514482781291008\n",
      "\n",
      "episode 5, policy loss -0.0284818634390831\n",
      "\n",
      "episode 6, policy loss -0.05658969655632973\n",
      "\n",
      "episode 7, policy loss -0.033174023032188416\n",
      "\n",
      "episode 8, policy loss -0.018442904576659203\n",
      "\n",
      "episode 9, policy loss -0.052424024790525436\n",
      "\n",
      "episode 10, policy loss -0.0649026557803154\n",
      "\n",
      "episode 11, policy loss -0.022359434515237808\n",
      "\n",
      "episode 12, policy loss -0.008051312528550625\n",
      "\n",
      "episode 13, policy loss 0.019474919885396957\n",
      "\n",
      "episode 14, policy loss -0.06443997472524643\n",
      "\n",
      "episode 15, policy loss -0.06466422230005264\n",
      "\n",
      "episode 16, policy loss -0.0788893848657608\n",
      "\n",
      "Policy train loss in epoch 1:-0.04300708376104012\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.05557745322585106\n",
      "\n",
      "episode 2, policy loss -0.06458673626184464\n",
      "\n",
      "episode 3, policy loss -0.008856038562953472\n",
      "\n",
      "episode 4, policy loss -0.022508347406983376\n",
      "\n",
      "episode 5, policy loss -0.05514727160334587\n",
      "\n",
      "episode 6, policy loss -0.06443735212087631\n",
      "\n",
      "episode 7, policy loss -0.06461414694786072\n",
      "\n",
      "episode 8, policy loss -0.058030690997838974\n",
      "\n",
      "episode 9, policy loss -0.033831559121608734\n",
      "\n",
      "episode 10, policy loss -0.019361453130841255\n",
      "\n",
      "episode 11, policy loss -0.07945962995290756\n",
      "\n",
      "episode 12, policy loss 0.019294647499918938\n",
      "\n",
      "episode 13, policy loss -0.057696837931871414\n",
      "\n",
      "episode 14, policy loss -0.027856716886162758\n",
      "\n",
      "episode 15, policy loss -0.05023903027176857\n",
      "\n",
      "episode 16, policy loss -0.05031277611851692\n",
      "\n",
      "Policy train loss in epoch 2:-0.04332633706508204\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.033502500504255295\n",
      "\n",
      "episode 2, policy loss -0.0554891861975193\n",
      "\n",
      "episode 3, policy loss -0.0516490712761879\n",
      "\n",
      "episode 4, policy loss -0.028670044615864754\n",
      "\n",
      "episode 5, policy loss -0.05551031231880188\n",
      "\n",
      "episode 6, policy loss -0.06434637308120728\n",
      "\n",
      "episode 7, policy loss -0.07810688018798828\n",
      "\n",
      "episode 8, policy loss 0.020845266059041023\n",
      "\n",
      "episode 9, policy loss -0.02104692906141281\n",
      "\n",
      "episode 10, policy loss -0.050981052219867706\n",
      "\n",
      "episode 11, policy loss -0.05580520257353783\n",
      "\n",
      "episode 12, policy loss -0.008554567582905293\n",
      "\n",
      "episode 13, policy loss -0.06384006142616272\n",
      "\n",
      "episode 14, policy loss -0.06483350694179535\n",
      "\n",
      "episode 15, policy loss -0.05861121043562889\n",
      "\n",
      "episode 16, policy loss -0.019687525928020477\n",
      "\n",
      "Policy train loss in epoch 3:-0.04311182239325717\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19866633415222168\n",
      "\n",
      "episode 2, val func loss 0.19961002469062805\n",
      "\n",
      "episode 3, val func loss 0.195846825838089\n",
      "\n",
      "episode 4, val func loss 0.20550031960010529\n",
      "\n",
      "episode 5, val func loss 0.1799604594707489\n",
      "\n",
      "episode 6, val func loss 0.17770390212535858\n",
      "\n",
      "episode 7, val func loss 0.1977846920490265\n",
      "\n",
      "episode 8, val func loss 0.19982337951660156\n",
      "\n",
      "episode 9, val func loss 0.21065711975097656\n",
      "\n",
      "episode 10, val func loss 0.2027081996202469\n",
      "\n",
      "episode 11, val func loss 0.17983201146125793\n",
      "\n",
      "episode 12, val func loss 0.18502169847488403\n",
      "\n",
      "episode 13, val func loss 0.18459393084049225\n",
      "\n",
      "episode 14, val func loss 0.21126258373260498\n",
      "\n",
      "episode 15, val func loss 0.15907572209835052\n",
      "\n",
      "episode 16, val func loss 0.1841346174478531\n",
      "\n",
      "Val func train loss in epoch 0:0.19201136380434036\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19745956361293793\n",
      "\n",
      "episode 2, val func loss 0.21219702064990997\n",
      "\n",
      "episode 3, val func loss 0.20701485872268677\n",
      "\n",
      "episode 4, val func loss 0.2036716639995575\n",
      "\n",
      "episode 5, val func loss 0.19877511262893677\n",
      "\n",
      "episode 6, val func loss 0.19997097551822662\n",
      "\n",
      "episode 7, val func loss 0.18868117034435272\n",
      "\n",
      "episode 8, val func loss 0.17986127734184265\n",
      "\n",
      "episode 9, val func loss 0.19868455827236176\n",
      "\n",
      "episode 10, val func loss 0.15980319678783417\n",
      "\n",
      "episode 11, val func loss 0.19798289239406586\n",
      "\n",
      "episode 12, val func loss 0.1831045001745224\n",
      "\n",
      "episode 13, val func loss 0.21200358867645264\n",
      "\n",
      "episode 14, val func loss 0.18400725722312927\n",
      "\n",
      "episode 15, val func loss 0.17673666775226593\n",
      "\n",
      "episode 16, val func loss 0.17839856445789337\n",
      "\n",
      "Val func train loss in epoch 1:0.19239705428481102\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.2062123566865921\n",
      "\n",
      "episode 2, val func loss 0.198882058262825\n",
      "\n",
      "episode 3, val func loss 0.20305919647216797\n",
      "\n",
      "episode 4, val func loss 0.19907811284065247\n",
      "\n",
      "episode 5, val func loss 0.17941293120384216\n",
      "\n",
      "episode 6, val func loss 0.2105264663696289\n",
      "\n",
      "episode 7, val func loss 0.16137728095054626\n",
      "\n",
      "episode 8, val func loss 0.21151307225227356\n",
      "\n",
      "episode 9, val func loss 0.18431110680103302\n",
      "\n",
      "episode 10, val func loss 0.20122769474983215\n",
      "\n",
      "episode 11, val func loss 0.17719799280166626\n",
      "\n",
      "episode 12, val func loss 0.18401005864143372\n",
      "\n",
      "episode 13, val func loss 0.17892497777938843\n",
      "\n",
      "episode 14, val func loss 0.1834787279367447\n",
      "\n",
      "episode 15, val func loss 0.19620604813098907\n",
      "\n",
      "episode 16, val func loss 0.1981663703918457\n",
      "\n",
      "Val func train loss in epoch 2:0.19209902826696634\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.16032782196998596\n",
      "\n",
      "episode 2, val func loss 0.2000858038663864\n",
      "\n",
      "episode 3, val func loss 0.18384020030498505\n",
      "\n",
      "episode 4, val func loss 0.20280879735946655\n",
      "\n",
      "episode 5, val func loss 0.21017670631408691\n",
      "\n",
      "episode 6, val func loss 0.17689312994480133\n",
      "\n",
      "episode 7, val func loss 0.18461909890174866\n",
      "\n",
      "episode 8, val func loss 0.1958787441253662\n",
      "\n",
      "episode 9, val func loss 0.2114231288433075\n",
      "\n",
      "episode 10, val func loss 0.1981712430715561\n",
      "\n",
      "episode 11, val func loss 0.18323417007923126\n",
      "\n",
      "episode 12, val func loss 0.17870160937309265\n",
      "\n",
      "episode 13, val func loss 0.20567989349365234\n",
      "\n",
      "episode 14, val func loss 0.19862794876098633\n",
      "\n",
      "episode 15, val func loss 0.18006674945354462\n",
      "\n",
      "episode 16, val func loss 0.1989179253578186\n",
      "\n",
      "Val func train loss in epoch 3:0.19184081070125103\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19960464537143707\n",
      "\n",
      "episode 2, val func loss 0.21043793857097626\n",
      "\n",
      "episode 3, val func loss 0.211958646774292\n",
      "\n",
      "episode 4, val func loss 0.17910592257976532\n",
      "\n",
      "episode 5, val func loss 0.1840859353542328\n",
      "\n",
      "episode 6, val func loss 0.18378542363643646\n",
      "\n",
      "episode 7, val func loss 0.1998206526041031\n",
      "\n",
      "episode 8, val func loss 0.1966666579246521\n",
      "\n",
      "episode 9, val func loss 0.17862296104431152\n",
      "\n",
      "episode 10, val func loss 0.20659425854682922\n",
      "\n",
      "episode 11, val func loss 0.2034412920475006\n",
      "\n",
      "episode 12, val func loss 0.19761180877685547\n",
      "\n",
      "episode 13, val func loss 0.1596660614013672\n",
      "\n",
      "episode 14, val func loss 0.19867561757564545\n",
      "\n",
      "episode 15, val func loss 0.17971166968345642\n",
      "\n",
      "episode 16, val func loss 0.18528778851032257\n",
      "\n",
      "Val func train loss in epoch 4:0.19219233002513647\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19861674308776855\n",
      "\n",
      "episode 2, val func loss 0.202708438038826\n",
      "\n",
      "episode 3, val func loss 0.19921572506427765\n",
      "\n",
      "episode 4, val func loss 0.2054109126329422\n",
      "\n",
      "episode 5, val func loss 0.1594776064157486\n",
      "\n",
      "episode 6, val func loss 0.17915476858615875\n",
      "\n",
      "episode 7, val func loss 0.200180783867836\n",
      "\n",
      "episode 8, val func loss 0.1767829805612564\n",
      "\n",
      "episode 9, val func loss 0.184194415807724\n",
      "\n",
      "episode 10, val func loss 0.19623221457004547\n",
      "\n",
      "episode 11, val func loss 0.21115991473197937\n",
      "\n",
      "episode 12, val func loss 0.19807231426239014\n",
      "\n",
      "episode 13, val func loss 0.21148885786533356\n",
      "\n",
      "episode 14, val func loss 0.18043839931488037\n",
      "\n",
      "episode 15, val func loss 0.18399931490421295\n",
      "\n",
      "episode 16, val func loss 0.1843818575143814\n",
      "\n",
      "Val func train loss in epoch 5:0.1919697029516101\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18623462319374084\n",
      "\n",
      "episode 2, val func loss 0.18013016879558563\n",
      "\n",
      "episode 3, val func loss 0.2048691362142563\n",
      "\n",
      "episode 4, val func loss 0.20017552375793457\n",
      "\n",
      "episode 5, val func loss 0.18341417610645294\n",
      "\n",
      "episode 6, val func loss 0.2099165916442871\n",
      "\n",
      "episode 7, val func loss 0.18353359401226044\n",
      "\n",
      "episode 8, val func loss 0.21132531762123108\n",
      "\n",
      "episode 9, val func loss 0.19792123138904572\n",
      "\n",
      "episode 10, val func loss 0.19522851705551147\n",
      "\n",
      "episode 11, val func loss 0.1989203840494156\n",
      "\n",
      "episode 12, val func loss 0.20298531651496887\n",
      "\n",
      "episode 13, val func loss 0.16029377281665802\n",
      "\n",
      "episode 14, val func loss 0.17903125286102295\n",
      "\n",
      "episode 15, val func loss 0.1986486166715622\n",
      "\n",
      "episode 16, val func loss 0.17659346759319305\n",
      "\n",
      "Val func train loss in epoch 6:0.19182635564357042\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.2033776044845581\n",
      "\n",
      "episode 2, val func loss 0.1577088087797165\n",
      "\n",
      "episode 3, val func loss 0.18370647728443146\n",
      "\n",
      "episode 4, val func loss 0.21251660585403442\n",
      "\n",
      "episode 5, val func loss 0.21250994503498077\n",
      "\n",
      "episode 6, val func loss 0.1990298181772232\n",
      "\n",
      "episode 7, val func loss 0.19984567165374756\n",
      "\n",
      "episode 8, val func loss 0.1956077218055725\n",
      "\n",
      "episode 9, val func loss 0.18458391726016998\n",
      "\n",
      "episode 10, val func loss 0.17966842651367188\n",
      "\n",
      "episode 11, val func loss 0.18481199443340302\n",
      "\n",
      "episode 12, val func loss 0.1996077448129654\n",
      "\n",
      "episode 13, val func loss 0.1988173872232437\n",
      "\n",
      "episode 14, val func loss 0.1782868206501007\n",
      "\n",
      "episode 15, val func loss 0.20452715456485748\n",
      "\n",
      "episode 16, val func loss 0.1794023960828781\n",
      "\n",
      "Val func train loss in epoch 7:0.19212553091347218\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1584741473197937\n",
      "\n",
      "episode 2, val func loss 0.19695454835891724\n",
      "\n",
      "episode 3, val func loss 0.18233801424503326\n",
      "\n",
      "episode 4, val func loss 0.20008018612861633\n",
      "\n",
      "episode 5, val func loss 0.20730482041835785\n",
      "\n",
      "episode 6, val func loss 0.1997005045413971\n",
      "\n",
      "episode 7, val func loss 0.1978662759065628\n",
      "\n",
      "episode 8, val func loss 0.203388050198555\n",
      "\n",
      "episode 9, val func loss 0.2102707177400589\n",
      "\n",
      "episode 10, val func loss 0.18184417486190796\n",
      "\n",
      "episode 11, val func loss 0.21185041964054108\n",
      "\n",
      "episode 12, val func loss 0.17885258793830872\n",
      "\n",
      "episode 13, val func loss 0.1841767132282257\n",
      "\n",
      "episode 14, val func loss 0.18318022787570953\n",
      "\n",
      "episode 15, val func loss 0.1833839863538742\n",
      "\n",
      "episode 16, val func loss 0.20440006256103516\n",
      "\n",
      "Val func train loss in epoch 8:0.1927540898323059\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18382081389427185\n",
      "\n",
      "episode 2, val func loss 0.17909249663352966\n",
      "\n",
      "episode 3, val func loss 0.2116096317768097\n",
      "\n",
      "episode 4, val func loss 0.18411806225776672\n",
      "\n",
      "episode 5, val func loss 0.19845786690711975\n",
      "\n",
      "episode 6, val func loss 0.15918660163879395\n",
      "\n",
      "episode 7, val func loss 0.18006879091262817\n",
      "\n",
      "episode 8, val func loss 0.2027060091495514\n",
      "\n",
      "episode 9, val func loss 0.197388157248497\n",
      "\n",
      "episode 10, val func loss 0.21141017973423004\n",
      "\n",
      "episode 11, val func loss 0.17779836058616638\n",
      "\n",
      "episode 12, val func loss 0.1837732344865799\n",
      "\n",
      "episode 13, val func loss 0.19924500584602356\n",
      "\n",
      "episode 14, val func loss 0.1957537680864334\n",
      "\n",
      "episode 15, val func loss 0.1997995376586914\n",
      "\n",
      "episode 16, val func loss 0.2049209177494049\n",
      "\n",
      "Val func train loss in epoch 9:0.1918218396604061\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19871583580970764\n",
      "\n",
      "episode 2, val func loss 0.19715487957000732\n",
      "\n",
      "episode 3, val func loss 0.19550064206123352\n",
      "\n",
      "episode 4, val func loss 0.1853124052286148\n",
      "\n",
      "episode 5, val func loss 0.1600922793149948\n",
      "\n",
      "episode 6, val func loss 0.19919447600841522\n",
      "\n",
      "episode 7, val func loss 0.17881573736667633\n",
      "\n",
      "episode 8, val func loss 0.21205922961235046\n",
      "\n",
      "episode 9, val func loss 0.1835983544588089\n",
      "\n",
      "episode 10, val func loss 0.20121341943740845\n",
      "\n",
      "episode 11, val func loss 0.20579718053340912\n",
      "\n",
      "episode 12, val func loss 0.17729514837265015\n",
      "\n",
      "episode 13, val func loss 0.17952081561088562\n",
      "\n",
      "episode 14, val func loss 0.21147429943084717\n",
      "\n",
      "episode 15, val func loss 0.18723168969154358\n",
      "\n",
      "episode 16, val func loss 0.20320811867713928\n",
      "\n",
      "Val func train loss in epoch 10:0.19226153194904327\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19553524255752563\n",
      "\n",
      "episode 2, val func loss 0.1792401522397995\n",
      "\n",
      "episode 3, val func loss 0.19931256771087646\n",
      "\n",
      "episode 4, val func loss 0.18344050645828247\n",
      "\n",
      "episode 5, val func loss 0.176948681473732\n",
      "\n",
      "episode 6, val func loss 0.19807057082653046\n",
      "\n",
      "episode 7, val func loss 0.18114073574543\n",
      "\n",
      "episode 8, val func loss 0.21049873530864716\n",
      "\n",
      "episode 9, val func loss 0.15976835787296295\n",
      "\n",
      "episode 10, val func loss 0.18487334251403809\n",
      "\n",
      "episode 11, val func loss 0.20260053873062134\n",
      "\n",
      "episode 12, val func loss 0.19986304640769958\n",
      "\n",
      "episode 13, val func loss 0.18315328657627106\n",
      "\n",
      "episode 14, val func loss 0.21136358380317688\n",
      "\n",
      "episode 15, val func loss 0.19852086901664734\n",
      "\n",
      "episode 16, val func loss 0.20581361651420593\n",
      "\n",
      "Val func train loss in epoch 11:0.19188398960977793\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.15903037786483765\n",
      "\n",
      "episode 2, val func loss 0.18339936435222626\n",
      "\n",
      "episode 3, val func loss 0.19893501698970795\n",
      "\n",
      "episode 4, val func loss 0.20318065583705902\n",
      "\n",
      "episode 5, val func loss 0.20005790889263153\n",
      "\n",
      "episode 6, val func loss 0.21133755147457123\n",
      "\n",
      "episode 7, val func loss 0.1989944726228714\n",
      "\n",
      "episode 8, val func loss 0.17973241209983826\n",
      "\n",
      "episode 9, val func loss 0.19767893850803375\n",
      "\n",
      "episode 10, val func loss 0.18418116867542267\n",
      "\n",
      "episode 11, val func loss 0.20446118712425232\n",
      "\n",
      "episode 12, val func loss 0.17868168652057648\n",
      "\n",
      "episode 13, val func loss 0.2102668583393097\n",
      "\n",
      "episode 14, val func loss 0.19568581879138947\n",
      "\n",
      "episode 15, val func loss 0.1785542070865631\n",
      "\n",
      "episode 16, val func loss 0.18422751128673553\n",
      "\n",
      "Val func train loss in epoch 12:0.19177532102912664\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.20708739757537842\n",
      "\n",
      "episode 2, val func loss 0.17851082980632782\n",
      "\n",
      "episode 3, val func loss 0.18374145030975342\n",
      "\n",
      "episode 4, val func loss 0.21107587218284607\n",
      "\n",
      "episode 5, val func loss 0.18300776183605194\n",
      "\n",
      "episode 6, val func loss 0.19793175160884857\n",
      "\n",
      "episode 7, val func loss 0.1771940141916275\n",
      "\n",
      "episode 8, val func loss 0.19897137582302094\n",
      "\n",
      "episode 9, val func loss 0.19826263189315796\n",
      "\n",
      "episode 10, val func loss 0.16050298511981964\n",
      "\n",
      "episode 11, val func loss 0.21086430549621582\n",
      "\n",
      "episode 12, val func loss 0.18511353433132172\n",
      "\n",
      "episode 13, val func loss 0.2033136636018753\n",
      "\n",
      "episode 14, val func loss 0.19624492526054382\n",
      "\n",
      "episode 15, val func loss 0.18134354054927826\n",
      "\n",
      "episode 16, val func loss 0.20026469230651855\n",
      "\n",
      "Val func train loss in epoch 13:0.1920894207432866\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.2056214064359665\n",
      "\n",
      "episode 2, val func loss 0.20282787084579468\n",
      "\n",
      "episode 3, val func loss 0.18487903475761414\n",
      "\n",
      "episode 4, val func loss 0.18080587685108185\n",
      "\n",
      "episode 5, val func loss 0.19878271222114563\n",
      "\n",
      "episode 6, val func loss 0.2106485366821289\n",
      "\n",
      "episode 7, val func loss 0.16002734005451202\n",
      "\n",
      "episode 8, val func loss 0.21195843815803528\n",
      "\n",
      "episode 9, val func loss 0.17709185183048248\n",
      "\n",
      "episode 10, val func loss 0.19723404943943024\n",
      "\n",
      "episode 11, val func loss 0.18341375887393951\n",
      "\n",
      "episode 12, val func loss 0.20137202739715576\n",
      "\n",
      "episode 13, val func loss 0.1985652595758438\n",
      "\n",
      "episode 14, val func loss 0.18089966475963593\n",
      "\n",
      "episode 15, val func loss 0.19927334785461426\n",
      "\n",
      "episode 16, val func loss 0.1840125471353531\n",
      "\n",
      "Val func train loss in epoch 14:0.19233835767954588\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19904087483882904\n",
      "\n",
      "episode 2, val func loss 0.1854473203420639\n",
      "\n",
      "episode 3, val func loss 0.2033458799123764\n",
      "\n",
      "episode 4, val func loss 0.19604365527629852\n",
      "\n",
      "episode 5, val func loss 0.17800459265708923\n",
      "\n",
      "episode 6, val func loss 0.19973663985729218\n",
      "\n",
      "episode 7, val func loss 0.19962210953235626\n",
      "\n",
      "episode 8, val func loss 0.17869777977466583\n",
      "\n",
      "episode 9, val func loss 0.21054209768772125\n",
      "\n",
      "episode 10, val func loss 0.2111852765083313\n",
      "\n",
      "episode 11, val func loss 0.20564167201519012\n",
      "\n",
      "episode 12, val func loss 0.1849755495786667\n",
      "\n",
      "episode 13, val func loss 0.19767345488071442\n",
      "\n",
      "episode 14, val func loss 0.18352055549621582\n",
      "\n",
      "episode 15, val func loss 0.15926332771778107\n",
      "\n",
      "episode 16, val func loss 0.18038654327392578\n",
      "\n",
      "Val func train loss in epoch 15:0.19207045808434486\n",
      "***********************TIME WAS 4.952243864536285 min*****************************\n",
      "\n",
      "**********************ROUND 77 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.051309261471033096\n",
      "\n",
      "episode 2, policy loss -0.040675316005945206\n",
      "\n",
      "episode 3, policy loss -0.03513893112540245\n",
      "\n",
      "episode 4, policy loss -0.012529250234365463\n",
      "\n",
      "episode 5, policy loss -0.022488011047244072\n",
      "\n",
      "episode 6, policy loss -0.08234291523694992\n",
      "\n",
      "episode 7, policy loss -0.008814089931547642\n",
      "\n",
      "episode 8, policy loss -0.08114831149578094\n",
      "\n",
      "episode 9, policy loss -0.07004092633724213\n",
      "\n",
      "episode 10, policy loss -0.10686811059713364\n",
      "\n",
      "episode 11, policy loss -0.07099681347608566\n",
      "\n",
      "episode 12, policy loss -0.052543751895427704\n",
      "\n",
      "episode 13, policy loss -0.03221765533089638\n",
      "\n",
      "episode 14, policy loss -0.07988651841878891\n",
      "\n",
      "episode 15, policy loss -0.058687563985586166\n",
      "\n",
      "episode 16, policy loss -0.06934802979230881\n",
      "\n",
      "Policy train loss in epoch 0:-0.05468971602385864\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.0570160336792469\n",
      "\n",
      "episode 2, policy loss -0.07351449877023697\n",
      "\n",
      "episode 3, policy loss -0.03319977968931198\n",
      "\n",
      "episode 4, policy loss -0.05824492499232292\n",
      "\n",
      "episode 5, policy loss -0.011938243173062801\n",
      "\n",
      "episode 6, policy loss -0.08260026574134827\n",
      "\n",
      "episode 7, policy loss -0.011713401414453983\n",
      "\n",
      "episode 8, policy loss -0.02216535247862339\n",
      "\n",
      "episode 9, policy loss -0.04828885570168495\n",
      "\n",
      "episode 10, policy loss -0.03582540154457092\n",
      "\n",
      "episode 11, policy loss -0.07544410973787308\n",
      "\n",
      "episode 12, policy loss -0.07156385481357574\n",
      "\n",
      "episode 13, policy loss -0.05756120756268501\n",
      "\n",
      "episode 14, policy loss -0.08332913368940353\n",
      "\n",
      "episode 15, policy loss -0.11198887974023819\n",
      "\n",
      "episode 16, policy loss -0.08264969289302826\n",
      "\n",
      "Policy train loss in epoch 1:-0.05731522722635418\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.07506410032510757\n",
      "\n",
      "episode 2, policy loss -0.07167398184537888\n",
      "\n",
      "episode 3, policy loss -0.02424849383533001\n",
      "\n",
      "episode 4, policy loss -0.07996265590190887\n",
      "\n",
      "episode 5, policy loss -0.01331289578229189\n",
      "\n",
      "episode 6, policy loss -0.08407475799322128\n",
      "\n",
      "episode 7, policy loss -0.07518617808818817\n",
      "\n",
      "episode 8, policy loss -0.05749990791082382\n",
      "\n",
      "episode 9, policy loss -0.048601604998111725\n",
      "\n",
      "episode 10, policy loss -0.03491358086466789\n",
      "\n",
      "episode 11, policy loss -0.1123504564166069\n",
      "\n",
      "episode 12, policy loss -0.0359560064971447\n",
      "\n",
      "episode 13, policy loss -0.08127781003713608\n",
      "\n",
      "episode 14, policy loss -0.05849349498748779\n",
      "\n",
      "episode 15, policy loss -0.05755433067679405\n",
      "\n",
      "episode 16, policy loss -0.011953058652579784\n",
      "\n",
      "Policy train loss in epoch 2:-0.057632707175798714\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.07564044743776321\n",
      "\n",
      "episode 2, policy loss -0.07427912205457687\n",
      "\n",
      "episode 3, policy loss -0.021787215024232864\n",
      "\n",
      "episode 4, policy loss -0.0801062360405922\n",
      "\n",
      "episode 5, policy loss -0.07068835198879242\n",
      "\n",
      "episode 6, policy loss -0.05876639857888222\n",
      "\n",
      "episode 7, policy loss -0.08237998932600021\n",
      "\n",
      "episode 8, policy loss -0.05766695365309715\n",
      "\n",
      "episode 9, policy loss -0.04837946966290474\n",
      "\n",
      "episode 10, policy loss -0.014279342256486416\n",
      "\n",
      "episode 11, policy loss -0.03422258421778679\n",
      "\n",
      "episode 12, policy loss -0.05941566452383995\n",
      "\n",
      "episode 13, policy loss -0.035134218633174896\n",
      "\n",
      "episode 14, policy loss -0.08495119214057922\n",
      "\n",
      "episode 15, policy loss -0.011791029945015907\n",
      "\n",
      "episode 16, policy loss -0.11486142873764038\n",
      "\n",
      "Policy train loss in epoch 3:-0.05777185276383534\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.20492206513881683\n",
      "\n",
      "episode 2, val func loss 0.22163711488246918\n",
      "\n",
      "episode 3, val func loss 0.1773187816143036\n",
      "\n",
      "episode 4, val func loss 0.20192638039588928\n",
      "\n",
      "episode 5, val func loss 0.19957402348518372\n",
      "\n",
      "episode 6, val func loss 0.213406503200531\n",
      "\n",
      "episode 7, val func loss 0.1889844387769699\n",
      "\n",
      "episode 8, val func loss 0.19408193230628967\n",
      "\n",
      "episode 9, val func loss 0.19926877319812775\n",
      "\n",
      "episode 10, val func loss 0.1746392846107483\n",
      "\n",
      "episode 11, val func loss 0.2146204710006714\n",
      "\n",
      "episode 12, val func loss 0.20340277254581451\n",
      "\n",
      "episode 13, val func loss 0.20071597397327423\n",
      "\n",
      "episode 14, val func loss 0.1742365062236786\n",
      "\n",
      "episode 15, val func loss 0.18811404705047607\n",
      "\n",
      "episode 16, val func loss 0.21500654518604279\n",
      "\n",
      "Val func train loss in epoch 0:0.19824097584933043\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.2225274294614792\n",
      "\n",
      "episode 2, val func loss 0.1999409794807434\n",
      "\n",
      "episode 3, val func loss 0.1992461234331131\n",
      "\n",
      "episode 4, val func loss 0.17711055278778076\n",
      "\n",
      "episode 5, val func loss 0.21328343451023102\n",
      "\n",
      "episode 6, val func loss 0.18948547542095184\n",
      "\n",
      "episode 7, val func loss 0.21076597273349762\n",
      "\n",
      "episode 8, val func loss 0.19324694573879242\n",
      "\n",
      "episode 9, val func loss 0.20425233244895935\n",
      "\n",
      "episode 10, val func loss 0.20176547765731812\n",
      "\n",
      "episode 11, val func loss 0.20408374071121216\n",
      "\n",
      "episode 12, val func loss 0.1881093531847\n",
      "\n",
      "episode 13, val func loss 0.17836184799671173\n",
      "\n",
      "episode 14, val func loss 0.2151843011379242\n",
      "\n",
      "episode 15, val func loss 0.2015056610107422\n",
      "\n",
      "episode 16, val func loss 0.1724354475736618\n",
      "\n",
      "Val func train loss in epoch 1:0.19820656720548868\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.20318835973739624\n",
      "\n",
      "episode 2, val func loss 0.2125435322523117\n",
      "\n",
      "episode 3, val func loss 0.2003801017999649\n",
      "\n",
      "episode 4, val func loss 0.19933456182479858\n",
      "\n",
      "episode 5, val func loss 0.2041890174150467\n",
      "\n",
      "episode 6, val func loss 0.21477010846138\n",
      "\n",
      "episode 7, val func loss 0.19976840913295746\n",
      "\n",
      "episode 8, val func loss 0.17487692832946777\n",
      "\n",
      "episode 9, val func loss 0.21824777126312256\n",
      "\n",
      "episode 10, val func loss 0.17926639318466187\n",
      "\n",
      "episode 11, val func loss 0.1877492368221283\n",
      "\n",
      "episode 12, val func loss 0.2154340147972107\n",
      "\n",
      "episode 13, val func loss 0.2040805071592331\n",
      "\n",
      "episode 14, val func loss 0.17352856695652008\n",
      "\n",
      "episode 15, val func loss 0.18925151228904724\n",
      "\n",
      "episode 16, val func loss 0.19049763679504395\n",
      "\n",
      "Val func train loss in epoch 2:0.1979441661387682\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20393095910549164\n",
      "\n",
      "episode 2, val func loss 0.21528805792331696\n",
      "\n",
      "episode 3, val func loss 0.2044239044189453\n",
      "\n",
      "episode 4, val func loss 0.21163368225097656\n",
      "\n",
      "episode 5, val func loss 0.19924728572368622\n",
      "\n",
      "episode 6, val func loss 0.19249050319194794\n",
      "\n",
      "episode 7, val func loss 0.18891139328479767\n",
      "\n",
      "episode 8, val func loss 0.19968874752521515\n",
      "\n",
      "episode 9, val func loss 0.2134101390838623\n",
      "\n",
      "episode 10, val func loss 0.1886335015296936\n",
      "\n",
      "episode 11, val func loss 0.20046621561050415\n",
      "\n",
      "episode 12, val func loss 0.1996692270040512\n",
      "\n",
      "episode 13, val func loss 0.1796153485774994\n",
      "\n",
      "episode 14, val func loss 0.17304368317127228\n",
      "\n",
      "episode 15, val func loss 0.2211470901966095\n",
      "\n",
      "episode 16, val func loss 0.1738939881324768\n",
      "\n",
      "Val func train loss in epoch 3:0.19784335792064667\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.20055679976940155\n",
      "\n",
      "episode 2, val func loss 0.2043047547340393\n",
      "\n",
      "episode 3, val func loss 0.177155539393425\n",
      "\n",
      "episode 4, val func loss 0.19046902656555176\n",
      "\n",
      "episode 5, val func loss 0.17345893383026123\n",
      "\n",
      "episode 6, val func loss 0.20451252162456512\n",
      "\n",
      "episode 7, val func loss 0.1879541128873825\n",
      "\n",
      "episode 8, val func loss 0.21510280668735504\n",
      "\n",
      "episode 9, val func loss 0.18937110900878906\n",
      "\n",
      "episode 10, val func loss 0.2139110565185547\n",
      "\n",
      "episode 11, val func loss 0.2035055160522461\n",
      "\n",
      "episode 12, val func loss 0.17462743818759918\n",
      "\n",
      "episode 13, val func loss 0.2113814651966095\n",
      "\n",
      "episode 14, val func loss 0.2007262408733368\n",
      "\n",
      "episode 15, val func loss 0.21664908528327942\n",
      "\n",
      "episode 16, val func loss 0.19972540438175201\n",
      "\n",
      "Val func train loss in epoch 4:0.19771323818713427\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1939745396375656\n",
      "\n",
      "episode 2, val func loss 0.2000633180141449\n",
      "\n",
      "episode 3, val func loss 0.1889295130968094\n",
      "\n",
      "episode 4, val func loss 0.1792902797460556\n",
      "\n",
      "episode 5, val func loss 0.20430096983909607\n",
      "\n",
      "episode 6, val func loss 0.1879531294107437\n",
      "\n",
      "episode 7, val func loss 0.2226109802722931\n",
      "\n",
      "episode 8, val func loss 0.20052412152290344\n",
      "\n",
      "episode 9, val func loss 0.1995818316936493\n",
      "\n",
      "episode 10, val func loss 0.20361410081386566\n",
      "\n",
      "episode 11, val func loss 0.21169550716876984\n",
      "\n",
      "episode 12, val func loss 0.17443238198757172\n",
      "\n",
      "episode 13, val func loss 0.1763136088848114\n",
      "\n",
      "episode 14, val func loss 0.21329867839813232\n",
      "\n",
      "episode 15, val func loss 0.20021070539951324\n",
      "\n",
      "episode 16, val func loss 0.21477890014648438\n",
      "\n",
      "Val func train loss in epoch 5:0.1982232853770256\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.21460379660129547\n",
      "\n",
      "episode 2, val func loss 0.188148632645607\n",
      "\n",
      "episode 3, val func loss 0.19957327842712402\n",
      "\n",
      "episode 4, val func loss 0.18886491656303406\n",
      "\n",
      "episode 5, val func loss 0.20058608055114746\n",
      "\n",
      "episode 6, val func loss 0.21929232776165009\n",
      "\n",
      "episode 7, val func loss 0.17895470559597015\n",
      "\n",
      "episode 8, val func loss 0.17328518629074097\n",
      "\n",
      "episode 9, val func loss 0.17527489364147186\n",
      "\n",
      "episode 10, val func loss 0.20014344155788422\n",
      "\n",
      "episode 11, val func loss 0.20376473665237427\n",
      "\n",
      "episode 12, val func loss 0.21290867030620575\n",
      "\n",
      "episode 13, val func loss 0.21520380675792694\n",
      "\n",
      "episode 14, val func loss 0.20181797444820404\n",
      "\n",
      "episode 15, val func loss 0.20374171435832977\n",
      "\n",
      "episode 16, val func loss 0.19251158833503723\n",
      "\n",
      "Val func train loss in epoch 6:0.1980422344058752\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17691662907600403\n",
      "\n",
      "episode 2, val func loss 0.19942738115787506\n",
      "\n",
      "episode 3, val func loss 0.19206009805202484\n",
      "\n",
      "episode 4, val func loss 0.17256467044353485\n",
      "\n",
      "episode 5, val func loss 0.22341381013393402\n",
      "\n",
      "episode 6, val func loss 0.2156389057636261\n",
      "\n",
      "episode 7, val func loss 0.20216670632362366\n",
      "\n",
      "episode 8, val func loss 0.19928857684135437\n",
      "\n",
      "episode 9, val func loss 0.1883293092250824\n",
      "\n",
      "episode 10, val func loss 0.20412063598632812\n",
      "\n",
      "episode 11, val func loss 0.1888270378112793\n",
      "\n",
      "episode 12, val func loss 0.20078116655349731\n",
      "\n",
      "episode 13, val func loss 0.2036406695842743\n",
      "\n",
      "episode 14, val func loss 0.1772684007883072\n",
      "\n",
      "episode 15, val func loss 0.21859411895275116\n",
      "\n",
      "episode 16, val func loss 0.21405106782913208\n",
      "\n",
      "Val func train loss in epoch 7:0.1985680740326643\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.21894317865371704\n",
      "\n",
      "episode 2, val func loss 0.20000238716602325\n",
      "\n",
      "episode 3, val func loss 0.21390700340270996\n",
      "\n",
      "episode 4, val func loss 0.19913826882839203\n",
      "\n",
      "episode 5, val func loss 0.17961065471172333\n",
      "\n",
      "episode 6, val func loss 0.1908332258462906\n",
      "\n",
      "episode 7, val func loss 0.2035215198993683\n",
      "\n",
      "episode 8, val func loss 0.20703493058681488\n",
      "\n",
      "episode 9, val func loss 0.17565815150737762\n",
      "\n",
      "episode 10, val func loss 0.21465563774108887\n",
      "\n",
      "episode 11, val func loss 0.1734708696603775\n",
      "\n",
      "episode 12, val func loss 0.20044590532779694\n",
      "\n",
      "episode 13, val func loss 0.19932958483695984\n",
      "\n",
      "episode 14, val func loss 0.21506324410438538\n",
      "\n",
      "episode 15, val func loss 0.18888378143310547\n",
      "\n",
      "episode 16, val func loss 0.20087330043315887\n",
      "\n",
      "Val func train loss in epoch 8:0.19883572775870562\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1991683542728424\n",
      "\n",
      "episode 2, val func loss 0.2134607881307602\n",
      "\n",
      "episode 3, val func loss 0.20052644610404968\n",
      "\n",
      "episode 4, val func loss 0.18918375670909882\n",
      "\n",
      "episode 5, val func loss 0.19954229891300201\n",
      "\n",
      "episode 6, val func loss 0.1817200779914856\n",
      "\n",
      "episode 7, val func loss 0.216964989900589\n",
      "\n",
      "episode 8, val func loss 0.18914136290550232\n",
      "\n",
      "episode 9, val func loss 0.20361050963401794\n",
      "\n",
      "episode 10, val func loss 0.20046906173229218\n",
      "\n",
      "episode 11, val func loss 0.2044352889060974\n",
      "\n",
      "episode 12, val func loss 0.21533817052841187\n",
      "\n",
      "episode 13, val func loss 0.2121933251619339\n",
      "\n",
      "episode 14, val func loss 0.17481771111488342\n",
      "\n",
      "episode 15, val func loss 0.17304246127605438\n",
      "\n",
      "episode 16, val func loss 0.1905745267868042\n",
      "\n",
      "Val func train loss in epoch 9:0.19776182062923908\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1765395700931549\n",
      "\n",
      "episode 2, val func loss 0.21620377898216248\n",
      "\n",
      "episode 3, val func loss 0.20562610030174255\n",
      "\n",
      "episode 4, val func loss 0.2013082504272461\n",
      "\n",
      "episode 5, val func loss 0.20361635088920593\n",
      "\n",
      "episode 6, val func loss 0.21220393478870392\n",
      "\n",
      "episode 7, val func loss 0.19174373149871826\n",
      "\n",
      "episode 8, val func loss 0.19960780441761017\n",
      "\n",
      "episode 9, val func loss 0.20369522273540497\n",
      "\n",
      "episode 10, val func loss 0.17713582515716553\n",
      "\n",
      "episode 11, val func loss 0.19914884865283966\n",
      "\n",
      "episode 12, val func loss 0.21813814342021942\n",
      "\n",
      "episode 13, val func loss 0.17409977316856384\n",
      "\n",
      "episode 14, val func loss 0.18840503692626953\n",
      "\n",
      "episode 15, val func loss 0.2138059139251709\n",
      "\n",
      "episode 16, val func loss 0.18889419734477997\n",
      "\n",
      "Val func train loss in epoch 10:0.19813578017055988\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1751180738210678\n",
      "\n",
      "episode 2, val func loss 0.19074025750160217\n",
      "\n",
      "episode 3, val func loss 0.19982507824897766\n",
      "\n",
      "episode 4, val func loss 0.20536670088768005\n",
      "\n",
      "episode 5, val func loss 0.1764717996120453\n",
      "\n",
      "episode 6, val func loss 0.20117011666297913\n",
      "\n",
      "episode 7, val func loss 0.2041359841823578\n",
      "\n",
      "episode 8, val func loss 0.1721264272928238\n",
      "\n",
      "episode 9, val func loss 0.22062884271144867\n",
      "\n",
      "episode 10, val func loss 0.19958806037902832\n",
      "\n",
      "episode 11, val func loss 0.2137639820575714\n",
      "\n",
      "episode 12, val func loss 0.2147776186466217\n",
      "\n",
      "episode 13, val func loss 0.20480363070964813\n",
      "\n",
      "episode 14, val func loss 0.2111966758966446\n",
      "\n",
      "episode 15, val func loss 0.19127613306045532\n",
      "\n",
      "episode 16, val func loss 0.19000287353992462\n",
      "\n",
      "Val func train loss in epoch 11:0.19818701595067978\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17847700417041779\n",
      "\n",
      "episode 2, val func loss 0.18037369847297668\n",
      "\n",
      "episode 3, val func loss 0.2137550264596939\n",
      "\n",
      "episode 4, val func loss 0.204306498169899\n",
      "\n",
      "episode 5, val func loss 0.17207954823970795\n",
      "\n",
      "episode 6, val func loss 0.19094038009643555\n",
      "\n",
      "episode 7, val func loss 0.2022169828414917\n",
      "\n",
      "episode 8, val func loss 0.19019094109535217\n",
      "\n",
      "episode 9, val func loss 0.20232316851615906\n",
      "\n",
      "episode 10, val func loss 0.20378726720809937\n",
      "\n",
      "episode 11, val func loss 0.19921079277992249\n",
      "\n",
      "episode 12, val func loss 0.21173354983329773\n",
      "\n",
      "episode 13, val func loss 0.2147432267665863\n",
      "\n",
      "episode 14, val func loss 0.1903277337551117\n",
      "\n",
      "episode 15, val func loss 0.21601547300815582\n",
      "\n",
      "episode 16, val func loss 0.20589177310466766\n",
      "\n",
      "Val func train loss in epoch 12:0.19852331653237343\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.20050036907196045\n",
      "\n",
      "episode 2, val func loss 0.20563453435897827\n",
      "\n",
      "episode 3, val func loss 0.2005520761013031\n",
      "\n",
      "episode 4, val func loss 0.18908724188804626\n",
      "\n",
      "episode 5, val func loss 0.21285156905651093\n",
      "\n",
      "episode 6, val func loss 0.17528720200061798\n",
      "\n",
      "episode 7, val func loss 0.2193462997674942\n",
      "\n",
      "episode 8, val func loss 0.20196419954299927\n",
      "\n",
      "episode 9, val func loss 0.19069507718086243\n",
      "\n",
      "episode 10, val func loss 0.2145722508430481\n",
      "\n",
      "episode 11, val func loss 0.1878935843706131\n",
      "\n",
      "episode 12, val func loss 0.20104748010635376\n",
      "\n",
      "episode 13, val func loss 0.17742501199245453\n",
      "\n",
      "episode 14, val func loss 0.20394611358642578\n",
      "\n",
      "episode 15, val func loss 0.2129252552986145\n",
      "\n",
      "episode 16, val func loss 0.172719806432724\n",
      "\n",
      "Val func train loss in epoch 13:0.19790300447493792\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1997145414352417\n",
      "\n",
      "episode 2, val func loss 0.2041657269001007\n",
      "\n",
      "episode 3, val func loss 0.2002488225698471\n",
      "\n",
      "episode 4, val func loss 0.1749776154756546\n",
      "\n",
      "episode 5, val func loss 0.1890682578086853\n",
      "\n",
      "episode 6, val func loss 0.18823321163654327\n",
      "\n",
      "episode 7, val func loss 0.17806239426136017\n",
      "\n",
      "episode 8, val func loss 0.22027413547039032\n",
      "\n",
      "episode 9, val func loss 0.2148098349571228\n",
      "\n",
      "episode 10, val func loss 0.2016075998544693\n",
      "\n",
      "episode 11, val func loss 0.17362457513809204\n",
      "\n",
      "episode 12, val func loss 0.2141789197921753\n",
      "\n",
      "episode 13, val func loss 0.19918407499790192\n",
      "\n",
      "episode 14, val func loss 0.19269803166389465\n",
      "\n",
      "episode 15, val func loss 0.2111636847257614\n",
      "\n",
      "episode 16, val func loss 0.2034202665090561\n",
      "\n",
      "Val func train loss in epoch 14:0.19783948082476854\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.2140980362892151\n",
      "\n",
      "episode 2, val func loss 0.19183267652988434\n",
      "\n",
      "episode 3, val func loss 0.18822450935840607\n",
      "\n",
      "episode 4, val func loss 0.17282505333423615\n",
      "\n",
      "episode 5, val func loss 0.1768890768289566\n",
      "\n",
      "episode 6, val func loss 0.17316456139087677\n",
      "\n",
      "episode 7, val func loss 0.21983329951763153\n",
      "\n",
      "episode 8, val func loss 0.20386646687984467\n",
      "\n",
      "episode 9, val func loss 0.21562060713768005\n",
      "\n",
      "episode 10, val func loss 0.2042839229106903\n",
      "\n",
      "episode 11, val func loss 0.20414049923419952\n",
      "\n",
      "episode 12, val func loss 0.2029380202293396\n",
      "\n",
      "episode 13, val func loss 0.18912369012832642\n",
      "\n",
      "episode 14, val func loss 0.21628622710704803\n",
      "\n",
      "episode 15, val func loss 0.20103713870048523\n",
      "\n",
      "episode 16, val func loss 0.2026033252477646\n",
      "\n",
      "Val func train loss in epoch 15:0.19854794442653656\n",
      "***********************TIME WAS 4.9484353025754295 min*****************************\n",
      "\n",
      "**********************ROUND 78 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.02391539141535759\n",
      "\n",
      "episode 2, policy loss 0.02258775569498539\n",
      "\n",
      "episode 3, policy loss -0.019594937562942505\n",
      "\n",
      "episode 4, policy loss 0.031015243381261826\n",
      "\n",
      "episode 5, policy loss 0.01932392455637455\n",
      "\n",
      "episode 6, policy loss 0.010397573933005333\n",
      "\n",
      "episode 7, policy loss -0.05368099361658096\n",
      "\n",
      "episode 8, policy loss 0.06420497596263885\n",
      "\n",
      "episode 9, policy loss 0.03378955274820328\n",
      "\n",
      "episode 10, policy loss -0.018278926610946655\n",
      "\n",
      "episode 11, policy loss 0.03807540982961655\n",
      "\n",
      "episode 12, policy loss 0.024125145748257637\n",
      "\n",
      "episode 13, policy loss -0.026256460696458817\n",
      "\n",
      "episode 14, policy loss 0.02427620254456997\n",
      "\n",
      "episode 15, policy loss 0.013601173646748066\n",
      "\n",
      "episode 16, policy loss 0.021168701350688934\n",
      "\n",
      "Policy train loss in epoch 0:0.01304185827029869\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.01750335283577442\n",
      "\n",
      "episode 2, policy loss 0.009343396872282028\n",
      "\n",
      "episode 3, policy loss 0.023373467847704887\n",
      "\n",
      "episode 4, policy loss -0.02535705268383026\n",
      "\n",
      "episode 5, policy loss -0.055814504623413086\n",
      "\n",
      "episode 6, policy loss 0.06180490180850029\n",
      "\n",
      "episode 7, policy loss 0.02863246202468872\n",
      "\n",
      "episode 8, policy loss 0.017918838188052177\n",
      "\n",
      "episode 9, policy loss 0.036832038313150406\n",
      "\n",
      "episode 10, policy loss 0.022930778563022614\n",
      "\n",
      "episode 11, policy loss 0.006046336144208908\n",
      "\n",
      "episode 12, policy loss 0.01858329027891159\n",
      "\n",
      "episode 13, policy loss 0.018241293728351593\n",
      "\n",
      "episode 14, policy loss -0.023024775087833405\n",
      "\n",
      "episode 15, policy loss 0.031776174902915955\n",
      "\n",
      "episode 16, policy loss -0.020490285009145737\n",
      "\n",
      "Policy train loss in epoch 1:0.010518732131458819\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.008828854188323021\n",
      "\n",
      "episode 2, policy loss 0.018716292455792427\n",
      "\n",
      "episode 3, policy loss -0.02031346596777439\n",
      "\n",
      "episode 4, policy loss 0.016669543460011482\n",
      "\n",
      "episode 5, policy loss 0.03672903776168823\n",
      "\n",
      "episode 6, policy loss 0.01643330045044422\n",
      "\n",
      "episode 7, policy loss -0.024106906726956367\n",
      "\n",
      "episode 8, policy loss 0.028323940932750702\n",
      "\n",
      "episode 9, policy loss -0.05791670083999634\n",
      "\n",
      "episode 10, policy loss 0.015635069459676743\n",
      "\n",
      "episode 11, policy loss 0.021888889372348785\n",
      "\n",
      "episode 12, policy loss -0.02823069877922535\n",
      "\n",
      "episode 13, policy loss 0.03158627450466156\n",
      "\n",
      "episode 14, policy loss 0.05782924219965935\n",
      "\n",
      "episode 15, policy loss 0.005168968345969915\n",
      "\n",
      "episode 16, policy loss 0.02323795109987259\n",
      "\n",
      "Policy train loss in epoch 2:0.009404974494827911\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.027878589928150177\n",
      "\n",
      "episode 2, policy loss 0.005294709000736475\n",
      "\n",
      "episode 3, policy loss 0.057635217905044556\n",
      "\n",
      "episode 4, policy loss 0.021658966317772865\n",
      "\n",
      "episode 5, policy loss 0.03103066422045231\n",
      "\n",
      "episode 6, policy loss 0.00814291276037693\n",
      "\n",
      "episode 7, policy loss 0.01562950387597084\n",
      "\n",
      "episode 8, policy loss -0.020751338452100754\n",
      "\n",
      "episode 9, policy loss 0.016157343983650208\n",
      "\n",
      "episode 10, policy loss 0.023181084543466568\n",
      "\n",
      "episode 11, policy loss -0.024549247696995735\n",
      "\n",
      "episode 12, policy loss 0.015925217419862747\n",
      "\n",
      "episode 13, policy loss 0.03488004580140114\n",
      "\n",
      "episode 14, policy loss -0.058912619948387146\n",
      "\n",
      "episode 15, policy loss 0.02648910880088806\n",
      "\n",
      "episode 16, policy loss 0.017281223088502884\n",
      "\n",
      "Policy train loss in epoch 3:0.008825887605780736\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19028767943382263\n",
      "\n",
      "episode 2, val func loss 0.19309459626674652\n",
      "\n",
      "episode 3, val func loss 0.1792265921831131\n",
      "\n",
      "episode 4, val func loss 0.20687270164489746\n",
      "\n",
      "episode 5, val func loss 0.21171118319034576\n",
      "\n",
      "episode 6, val func loss 0.19857491552829742\n",
      "\n",
      "episode 7, val func loss 0.2251707762479782\n",
      "\n",
      "episode 8, val func loss 0.1851942092180252\n",
      "\n",
      "episode 9, val func loss 0.17928878962993622\n",
      "\n",
      "episode 10, val func loss 0.18674352765083313\n",
      "\n",
      "episode 11, val func loss 0.19778726994991302\n",
      "\n",
      "episode 12, val func loss 0.21820691227912903\n",
      "\n",
      "episode 13, val func loss 0.18839310109615326\n",
      "\n",
      "episode 14, val func loss 0.20438922941684723\n",
      "\n",
      "episode 15, val func loss 0.19226281344890594\n",
      "\n",
      "episode 16, val func loss 0.21234658360481262\n",
      "\n",
      "Val func train loss in epoch 0:0.1980969300493598\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1894952356815338\n",
      "\n",
      "episode 2, val func loss 0.18698610365390778\n",
      "\n",
      "episode 3, val func loss 0.21507565677165985\n",
      "\n",
      "episode 4, val func loss 0.2211035043001175\n",
      "\n",
      "episode 5, val func loss 0.18386240303516388\n",
      "\n",
      "episode 6, val func loss 0.18395668268203735\n",
      "\n",
      "episode 7, val func loss 0.21211732923984528\n",
      "\n",
      "episode 8, val func loss 0.19270147383213043\n",
      "\n",
      "episode 9, val func loss 0.1924401819705963\n",
      "\n",
      "episode 10, val func loss 0.20626139640808105\n",
      "\n",
      "episode 11, val func loss 0.20379538834095\n",
      "\n",
      "episode 12, val func loss 0.17770539224147797\n",
      "\n",
      "episode 13, val func loss 0.21159853041172028\n",
      "\n",
      "episode 14, val func loss 0.18640394508838654\n",
      "\n",
      "episode 15, val func loss 0.19932158291339874\n",
      "\n",
      "episode 16, val func loss 0.19738969206809998\n",
      "\n",
      "Val func train loss in epoch 1:0.19751340616494417\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1781294047832489\n",
      "\n",
      "episode 2, val func loss 0.1925904005765915\n",
      "\n",
      "episode 3, val func loss 0.21714961528778076\n",
      "\n",
      "episode 4, val func loss 0.2111583650112152\n",
      "\n",
      "episode 5, val func loss 0.18386968970298767\n",
      "\n",
      "episode 6, val func loss 0.19417265057563782\n",
      "\n",
      "episode 7, val func loss 0.2051716297864914\n",
      "\n",
      "episode 8, val func loss 0.20766356587409973\n",
      "\n",
      "episode 9, val func loss 0.18747419118881226\n",
      "\n",
      "episode 10, val func loss 0.19747456908226013\n",
      "\n",
      "episode 11, val func loss 0.18749681115150452\n",
      "\n",
      "episode 12, val func loss 0.22351492941379547\n",
      "\n",
      "episode 13, val func loss 0.21666954457759857\n",
      "\n",
      "episode 14, val func loss 0.1788521260023117\n",
      "\n",
      "episode 15, val func loss 0.19876517355442047\n",
      "\n",
      "episode 16, val func loss 0.1868267059326172\n",
      "\n",
      "Val func train loss in epoch 2:0.19793621078133583\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.22346480190753937\n",
      "\n",
      "episode 2, val func loss 0.17860724031925201\n",
      "\n",
      "episode 3, val func loss 0.18798118829727173\n",
      "\n",
      "episode 4, val func loss 0.1926640272140503\n",
      "\n",
      "episode 5, val func loss 0.19919823110103607\n",
      "\n",
      "episode 6, val func loss 0.1818370372056961\n",
      "\n",
      "episode 7, val func loss 0.19807268679141998\n",
      "\n",
      "episode 8, val func loss 0.18660157918930054\n",
      "\n",
      "episode 9, val func loss 0.20379282534122467\n",
      "\n",
      "episode 10, val func loss 0.18678255379199982\n",
      "\n",
      "episode 11, val func loss 0.2054973542690277\n",
      "\n",
      "episode 12, val func loss 0.19392544031143188\n",
      "\n",
      "episode 13, val func loss 0.21209466457366943\n",
      "\n",
      "episode 14, val func loss 0.21563635766506195\n",
      "\n",
      "episode 15, val func loss 0.21110349893569946\n",
      "\n",
      "episode 16, val func loss 0.18748217821121216\n",
      "\n",
      "Val func train loss in epoch 3:0.19779635407030582\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.21476787328720093\n",
      "\n",
      "episode 2, val func loss 0.19070042669773102\n",
      "\n",
      "episode 3, val func loss 0.2003786712884903\n",
      "\n",
      "episode 4, val func loss 0.18157672882080078\n",
      "\n",
      "episode 5, val func loss 0.21268214285373688\n",
      "\n",
      "episode 6, val func loss 0.19531093537807465\n",
      "\n",
      "episode 7, val func loss 0.22417506575584412\n",
      "\n",
      "episode 8, val func loss 0.17945902049541473\n",
      "\n",
      "episode 9, val func loss 0.21473105251789093\n",
      "\n",
      "episode 10, val func loss 0.1835830956697464\n",
      "\n",
      "episode 11, val func loss 0.19779258966445923\n",
      "\n",
      "episode 12, val func loss 0.19250546395778656\n",
      "\n",
      "episode 13, val func loss 0.2208976000547409\n",
      "\n",
      "episode 14, val func loss 0.18576663732528687\n",
      "\n",
      "episode 15, val func loss 0.20402249693870544\n",
      "\n",
      "episode 16, val func loss 0.1980799436569214\n",
      "\n",
      "Val func train loss in epoch 4:0.19977685902267694\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.21830902993679047\n",
      "\n",
      "episode 2, val func loss 0.19239442050457\n",
      "\n",
      "episode 3, val func loss 0.20651158690452576\n",
      "\n",
      "episode 4, val func loss 0.2111188918352127\n",
      "\n",
      "episode 5, val func loss 0.20404332876205444\n",
      "\n",
      "episode 6, val func loss 0.19257964193820953\n",
      "\n",
      "episode 7, val func loss 0.21255289018154144\n",
      "\n",
      "episode 8, val func loss 0.19787515699863434\n",
      "\n",
      "episode 9, val func loss 0.1845879852771759\n",
      "\n",
      "episode 10, val func loss 0.1867792308330536\n",
      "\n",
      "episode 11, val func loss 0.2220693975687027\n",
      "\n",
      "episode 12, val func loss 0.18361589312553406\n",
      "\n",
      "episode 13, val func loss 0.1783229410648346\n",
      "\n",
      "episode 14, val func loss 0.18599598109722137\n",
      "\n",
      "episode 15, val func loss 0.1987375169992447\n",
      "\n",
      "episode 16, val func loss 0.1878213733434677\n",
      "\n",
      "Val func train loss in epoch 5:0.19770720414817333\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19775134325027466\n",
      "\n",
      "episode 2, val func loss 0.22276245057582855\n",
      "\n",
      "episode 3, val func loss 0.21460144221782684\n",
      "\n",
      "episode 4, val func loss 0.17822133004665375\n",
      "\n",
      "episode 5, val func loss 0.1922963708639145\n",
      "\n",
      "episode 6, val func loss 0.1925567388534546\n",
      "\n",
      "episode 7, val func loss 0.20022085309028625\n",
      "\n",
      "episode 8, val func loss 0.18369878828525543\n",
      "\n",
      "episode 9, val func loss 0.20635931193828583\n",
      "\n",
      "episode 10, val func loss 0.18904557824134827\n",
      "\n",
      "episode 11, val func loss 0.21654605865478516\n",
      "\n",
      "episode 12, val func loss 0.1857638955116272\n",
      "\n",
      "episode 13, val func loss 0.1866643726825714\n",
      "\n",
      "episode 14, val func loss 0.21144506335258484\n",
      "\n",
      "episode 15, val func loss 0.1819608509540558\n",
      "\n",
      "episode 16, val func loss 0.20372740924358368\n",
      "\n",
      "Val func train loss in epoch 6:0.19772636611014605\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.21474038064479828\n",
      "\n",
      "episode 2, val func loss 0.19334225356578827\n",
      "\n",
      "episode 3, val func loss 0.1783316731452942\n",
      "\n",
      "episode 4, val func loss 0.21117138862609863\n",
      "\n",
      "episode 5, val func loss 0.1983727663755417\n",
      "\n",
      "episode 6, val func loss 0.2064201384782791\n",
      "\n",
      "episode 7, val func loss 0.20426547527313232\n",
      "\n",
      "episode 8, val func loss 0.1994890570640564\n",
      "\n",
      "episode 9, val func loss 0.21631500124931335\n",
      "\n",
      "episode 10, val func loss 0.22168630361557007\n",
      "\n",
      "episode 11, val func loss 0.18929487466812134\n",
      "\n",
      "episode 12, val func loss 0.19273069500923157\n",
      "\n",
      "episode 13, val func loss 0.18685181438922882\n",
      "\n",
      "episode 14, val func loss 0.183843195438385\n",
      "\n",
      "episode 15, val func loss 0.18142598867416382\n",
      "\n",
      "episode 16, val func loss 0.18619808554649353\n",
      "\n",
      "Val func train loss in epoch 7:0.19777994323521852\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.21915742754936218\n",
      "\n",
      "episode 2, val func loss 0.18018154799938202\n",
      "\n",
      "episode 3, val func loss 0.20538857579231262\n",
      "\n",
      "episode 4, val func loss 0.21602846682071686\n",
      "\n",
      "episode 5, val func loss 0.1936551034450531\n",
      "\n",
      "episode 6, val func loss 0.21208994090557098\n",
      "\n",
      "episode 7, val func loss 0.19775165617465973\n",
      "\n",
      "episode 8, val func loss 0.22167232632637024\n",
      "\n",
      "episode 9, val func loss 0.20010368525981903\n",
      "\n",
      "episode 10, val func loss 0.1901337057352066\n",
      "\n",
      "episode 11, val func loss 0.20400254428386688\n",
      "\n",
      "episode 12, val func loss 0.18721404671669006\n",
      "\n",
      "episode 13, val func loss 0.19288799166679382\n",
      "\n",
      "episode 14, val func loss 0.17810295522212982\n",
      "\n",
      "episode 15, val func loss 0.1840265691280365\n",
      "\n",
      "episode 16, val func loss 0.18627002835273743\n",
      "\n",
      "Val func train loss in epoch 8:0.19804166071116924\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20527160167694092\n",
      "\n",
      "episode 2, val func loss 0.19797344505786896\n",
      "\n",
      "episode 3, val func loss 0.1841321885585785\n",
      "\n",
      "episode 4, val func loss 0.19897453486919403\n",
      "\n",
      "episode 5, val func loss 0.21204161643981934\n",
      "\n",
      "episode 6, val func loss 0.17841263115406036\n",
      "\n",
      "episode 7, val func loss 0.19258323311805725\n",
      "\n",
      "episode 8, val func loss 0.18842452764511108\n",
      "\n",
      "episode 9, val func loss 0.19219067692756653\n",
      "\n",
      "episode 10, val func loss 0.18626171350479126\n",
      "\n",
      "episode 11, val func loss 0.18579471111297607\n",
      "\n",
      "episode 12, val func loss 0.18123047053813934\n",
      "\n",
      "episode 13, val func loss 0.2181750237941742\n",
      "\n",
      "episode 14, val func loss 0.20362383127212524\n",
      "\n",
      "episode 15, val func loss 0.21479865908622742\n",
      "\n",
      "episode 16, val func loss 0.22215543687343597\n",
      "\n",
      "Val func train loss in epoch 9:0.19762776885181665\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1890396624803543\n",
      "\n",
      "episode 2, val func loss 0.2063390463590622\n",
      "\n",
      "episode 3, val func loss 0.21220244467258453\n",
      "\n",
      "episode 4, val func loss 0.19247028231620789\n",
      "\n",
      "episode 5, val func loss 0.19854320585727692\n",
      "\n",
      "episode 6, val func loss 0.2039480209350586\n",
      "\n",
      "episode 7, val func loss 0.1844070702791214\n",
      "\n",
      "episode 8, val func loss 0.22162188589572906\n",
      "\n",
      "episode 9, val func loss 0.2117096483707428\n",
      "\n",
      "episode 10, val func loss 0.2168678641319275\n",
      "\n",
      "episode 11, val func loss 0.18357525765895844\n",
      "\n",
      "episode 12, val func loss 0.19203397631645203\n",
      "\n",
      "episode 13, val func loss 0.19940686225891113\n",
      "\n",
      "episode 14, val func loss 0.18691973388195038\n",
      "\n",
      "episode 15, val func loss 0.17795275151729584\n",
      "\n",
      "episode 16, val func loss 0.18612469732761383\n",
      "\n",
      "Val func train loss in epoch 10:0.19769765064120293\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19931723177433014\n",
      "\n",
      "episode 2, val func loss 0.187909796833992\n",
      "\n",
      "episode 3, val func loss 0.205459862947464\n",
      "\n",
      "episode 4, val func loss 0.17930862307548523\n",
      "\n",
      "episode 5, val func loss 0.19849315285682678\n",
      "\n",
      "episode 6, val func loss 0.19247275590896606\n",
      "\n",
      "episode 7, val func loss 0.22643670439720154\n",
      "\n",
      "episode 8, val func loss 0.22267717123031616\n",
      "\n",
      "episode 9, val func loss 0.2038934826850891\n",
      "\n",
      "episode 10, val func loss 0.18648295104503632\n",
      "\n",
      "episode 11, val func loss 0.21096573770046234\n",
      "\n",
      "episode 12, val func loss 0.18778270483016968\n",
      "\n",
      "episode 13, val func loss 0.19251203536987305\n",
      "\n",
      "episode 14, val func loss 0.211481511592865\n",
      "\n",
      "episode 15, val func loss 0.18447422981262207\n",
      "\n",
      "episode 16, val func loss 0.18007367849349976\n",
      "\n",
      "Val func train loss in epoch 11:0.19810885190963745\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.22061149775981903\n",
      "\n",
      "episode 2, val func loss 0.20935958623886108\n",
      "\n",
      "episode 3, val func loss 0.18849243223667145\n",
      "\n",
      "episode 4, val func loss 0.20027492940425873\n",
      "\n",
      "episode 5, val func loss 0.2115585058927536\n",
      "\n",
      "episode 6, val func loss 0.21446964144706726\n",
      "\n",
      "episode 7, val func loss 0.1786159873008728\n",
      "\n",
      "episode 8, val func loss 0.17985108494758606\n",
      "\n",
      "episode 9, val func loss 0.22029893100261688\n",
      "\n",
      "episode 10, val func loss 0.1939225047826767\n",
      "\n",
      "episode 11, val func loss 0.1871514767408371\n",
      "\n",
      "episode 12, val func loss 0.1976773887872696\n",
      "\n",
      "episode 13, val func loss 0.18623530864715576\n",
      "\n",
      "episode 14, val func loss 0.18369737267494202\n",
      "\n",
      "episode 15, val func loss 0.20384688675403595\n",
      "\n",
      "episode 16, val func loss 0.19265130162239075\n",
      "\n",
      "Val func train loss in epoch 12:0.19804467726498842\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.2124256044626236\n",
      "\n",
      "episode 2, val func loss 0.2043124884366989\n",
      "\n",
      "episode 3, val func loss 0.18338753283023834\n",
      "\n",
      "episode 4, val func loss 0.1987473964691162\n",
      "\n",
      "episode 5, val func loss 0.19322553277015686\n",
      "\n",
      "episode 6, val func loss 0.1890856772661209\n",
      "\n",
      "episode 7, val func loss 0.21598322689533234\n",
      "\n",
      "episode 8, val func loss 0.1781853437423706\n",
      "\n",
      "episode 9, val func loss 0.18660400807857513\n",
      "\n",
      "episode 10, val func loss 0.19317859411239624\n",
      "\n",
      "episode 11, val func loss 0.18590310215950012\n",
      "\n",
      "episode 12, val func loss 0.19921667873859406\n",
      "\n",
      "episode 13, val func loss 0.20556317269802094\n",
      "\n",
      "episode 14, val func loss 0.18079964816570282\n",
      "\n",
      "episode 15, val func loss 0.2121148407459259\n",
      "\n",
      "episode 16, val func loss 0.22388572990894318\n",
      "\n",
      "Val func train loss in epoch 13:0.19766366109251976\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18658924102783203\n",
      "\n",
      "episode 2, val func loss 0.2188205122947693\n",
      "\n",
      "episode 3, val func loss 0.1993398666381836\n",
      "\n",
      "episode 4, val func loss 0.19268709421157837\n",
      "\n",
      "episode 5, val func loss 0.1858234852552414\n",
      "\n",
      "episode 6, val func loss 0.20454879105091095\n",
      "\n",
      "episode 7, val func loss 0.2117689698934555\n",
      "\n",
      "episode 8, val func loss 0.18601563572883606\n",
      "\n",
      "episode 9, val func loss 0.1833895891904831\n",
      "\n",
      "episode 10, val func loss 0.2068348377943039\n",
      "\n",
      "episode 11, val func loss 0.21150502562522888\n",
      "\n",
      "episode 12, val func loss 0.17793171107769012\n",
      "\n",
      "episode 13, val func loss 0.19209128618240356\n",
      "\n",
      "episode 14, val func loss 0.1977982372045517\n",
      "\n",
      "episode 15, val func loss 0.2237711399793625\n",
      "\n",
      "episode 16, val func loss 0.1867476850748062\n",
      "\n",
      "Val func train loss in epoch 14:0.19785394426435232\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18426215648651123\n",
      "\n",
      "episode 2, val func loss 0.18714627623558044\n",
      "\n",
      "episode 3, val func loss 0.20361755788326263\n",
      "\n",
      "episode 4, val func loss 0.21959532797336578\n",
      "\n",
      "episode 5, val func loss 0.2120632529258728\n",
      "\n",
      "episode 6, val func loss 0.22227221727371216\n",
      "\n",
      "episode 7, val func loss 0.18596340715885162\n",
      "\n",
      "episode 8, val func loss 0.19922468066215515\n",
      "\n",
      "episode 9, val func loss 0.1887306571006775\n",
      "\n",
      "episode 10, val func loss 0.19429364800453186\n",
      "\n",
      "episode 11, val func loss 0.19240373373031616\n",
      "\n",
      "episode 12, val func loss 0.20727171003818512\n",
      "\n",
      "episode 13, val func loss 0.1826307475566864\n",
      "\n",
      "episode 14, val func loss 0.21433871984481812\n",
      "\n",
      "episode 15, val func loss 0.1785152554512024\n",
      "\n",
      "episode 16, val func loss 0.19911493360996246\n",
      "\n",
      "Val func train loss in epoch 15:0.19821526762098074\n",
      "***********************TIME WAS 4.9587024291356405 min*****************************\n",
      "\n",
      "**********************ROUND 79 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.03353966027498245\n",
      "\n",
      "episode 2, policy loss -0.0849495530128479\n",
      "\n",
      "episode 3, policy loss -0.0682540237903595\n",
      "\n",
      "episode 4, policy loss -0.06385490298271179\n",
      "\n",
      "episode 5, policy loss -0.00902894139289856\n",
      "\n",
      "episode 6, policy loss -0.062048688530921936\n",
      "\n",
      "episode 7, policy loss -0.08837608247995377\n",
      "\n",
      "episode 8, policy loss -0.059012770652770996\n",
      "\n",
      "episode 9, policy loss -0.02781706489622593\n",
      "\n",
      "episode 10, policy loss -0.07847099751234055\n",
      "\n",
      "episode 11, policy loss -0.0026445244438946247\n",
      "\n",
      "episode 12, policy loss -0.07917387038469315\n",
      "\n",
      "episode 13, policy loss -0.04927995428442955\n",
      "\n",
      "episode 14, policy loss -0.048522256314754486\n",
      "\n",
      "episode 15, policy loss -0.024122247472405434\n",
      "\n",
      "episode 16, policy loss -0.08918652683496475\n",
      "\n",
      "Policy train loss in epoch 0:-0.05426762907882221\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.04073657467961311\n",
      "\n",
      "episode 2, policy loss -0.05075611546635628\n",
      "\n",
      "episode 3, policy loss -0.011366606689989567\n",
      "\n",
      "episode 4, policy loss -0.005255415104329586\n",
      "\n",
      "episode 5, policy loss -0.024361466988921165\n",
      "\n",
      "episode 6, policy loss -0.059760939329862595\n",
      "\n",
      "episode 7, policy loss -0.08949217200279236\n",
      "\n",
      "episode 8, policy loss -0.028839239850640297\n",
      "\n",
      "episode 9, policy loss -0.07167860120534897\n",
      "\n",
      "episode 10, policy loss -0.07949650287628174\n",
      "\n",
      "episode 11, policy loss -0.080818310379982\n",
      "\n",
      "episode 12, policy loss -0.04883532226085663\n",
      "\n",
      "episode 13, policy loss -0.06477047502994537\n",
      "\n",
      "episode 14, policy loss -0.0700957179069519\n",
      "\n",
      "episode 15, policy loss -0.09762818366289139\n",
      "\n",
      "episode 16, policy loss -0.0891660675406456\n",
      "\n",
      "Policy train loss in epoch 1:-0.057066106935963035\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.07143153995275497\n",
      "\n",
      "episode 2, policy loss -0.08827628195285797\n",
      "\n",
      "episode 3, policy loss -0.09616141021251678\n",
      "\n",
      "episode 4, policy loss -0.06532015651464462\n",
      "\n",
      "episode 5, policy loss -0.07991684228181839\n",
      "\n",
      "episode 6, policy loss -0.01028189342468977\n",
      "\n",
      "episode 7, policy loss -0.04856065660715103\n",
      "\n",
      "episode 8, policy loss -0.07049844413995743\n",
      "\n",
      "episode 9, policy loss -0.08885501325130463\n",
      "\n",
      "episode 10, policy loss -0.02429795451462269\n",
      "\n",
      "episode 11, policy loss -0.04958716034889221\n",
      "\n",
      "episode 12, policy loss -0.06004033610224724\n",
      "\n",
      "episode 13, policy loss -0.08061857521533966\n",
      "\n",
      "episode 14, policy loss -0.028422055765986443\n",
      "\n",
      "episode 15, policy loss -0.0036877901293337345\n",
      "\n",
      "episode 16, policy loss -0.04047517850995064\n",
      "\n",
      "Policy train loss in epoch 2:-0.05665195555775426\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.08620910346508026\n",
      "\n",
      "episode 2, policy loss -0.004007861949503422\n",
      "\n",
      "episode 3, policy loss -0.024244144558906555\n",
      "\n",
      "episode 4, policy loss -0.060478877276182175\n",
      "\n",
      "episode 5, policy loss -0.07108235359191895\n",
      "\n",
      "episode 6, policy loss -0.049089670181274414\n",
      "\n",
      "episode 7, policy loss -0.0876535177230835\n",
      "\n",
      "episode 8, policy loss -0.009704936295747757\n",
      "\n",
      "episode 9, policy loss -0.0793602243065834\n",
      "\n",
      "episode 10, policy loss -0.08037631213665009\n",
      "\n",
      "episode 11, policy loss -0.040708061307668686\n",
      "\n",
      "episode 12, policy loss -0.09569531679153442\n",
      "\n",
      "episode 13, policy loss -0.06876346468925476\n",
      "\n",
      "episode 14, policy loss -0.06265145540237427\n",
      "\n",
      "episode 15, policy loss -0.02837725542485714\n",
      "\n",
      "episode 16, policy loss -0.04951774328947067\n",
      "\n",
      "Policy train loss in epoch 3:-0.056120018649380654\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.2092992514371872\n",
      "\n",
      "episode 2, val func loss 0.1943168193101883\n",
      "\n",
      "episode 3, val func loss 0.21454879641532898\n",
      "\n",
      "episode 4, val func loss 0.16236737370491028\n",
      "\n",
      "episode 5, val func loss 0.1919751763343811\n",
      "\n",
      "episode 6, val func loss 0.2124805897474289\n",
      "\n",
      "episode 7, val func loss 0.2007182240486145\n",
      "\n",
      "episode 8, val func loss 0.2205961048603058\n",
      "\n",
      "episode 9, val func loss 0.18106728792190552\n",
      "\n",
      "episode 10, val func loss 0.19333940744400024\n",
      "\n",
      "episode 11, val func loss 0.191346675157547\n",
      "\n",
      "episode 12, val func loss 0.20298391580581665\n",
      "\n",
      "episode 13, val func loss 0.2004677802324295\n",
      "\n",
      "episode 14, val func loss 0.16801144182682037\n",
      "\n",
      "episode 15, val func loss 0.202344611287117\n",
      "\n",
      "episode 16, val func loss 0.18265125155448914\n",
      "\n",
      "Val func train loss in epoch 0:0.1955321691930294\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.20350593328475952\n",
      "\n",
      "episode 2, val func loss 0.21359792351722717\n",
      "\n",
      "episode 3, val func loss 0.1707446128129959\n",
      "\n",
      "episode 4, val func loss 0.22203557193279266\n",
      "\n",
      "episode 5, val func loss 0.1626768261194229\n",
      "\n",
      "episode 6, val func loss 0.19168709218502045\n",
      "\n",
      "episode 7, val func loss 0.20250244438648224\n",
      "\n",
      "episode 8, val func loss 0.21426908671855927\n",
      "\n",
      "episode 9, val func loss 0.1945040374994278\n",
      "\n",
      "episode 10, val func loss 0.18361137807369232\n",
      "\n",
      "episode 11, val func loss 0.16965092718601227\n",
      "\n",
      "episode 12, val func loss 0.19274921715259552\n",
      "\n",
      "episode 13, val func loss 0.20960451662540436\n",
      "\n",
      "episode 14, val func loss 0.20370541512966156\n",
      "\n",
      "episode 15, val func loss 0.20008017122745514\n",
      "\n",
      "episode 16, val func loss 0.1916113793849945\n",
      "\n",
      "Val func train loss in epoch 1:0.19540853332728148\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1969156116247177\n",
      "\n",
      "episode 2, val func loss 0.20067638158798218\n",
      "\n",
      "episode 3, val func loss 0.21223051846027374\n",
      "\n",
      "episode 4, val func loss 0.1721019297838211\n",
      "\n",
      "episode 5, val func loss 0.22059321403503418\n",
      "\n",
      "episode 6, val func loss 0.20280088484287262\n",
      "\n",
      "episode 7, val func loss 0.19201809167861938\n",
      "\n",
      "episode 8, val func loss 0.1917843222618103\n",
      "\n",
      "episode 9, val func loss 0.21380721032619476\n",
      "\n",
      "episode 10, val func loss 0.20251086354255676\n",
      "\n",
      "episode 11, val func loss 0.17110970616340637\n",
      "\n",
      "episode 12, val func loss 0.20833627879619598\n",
      "\n",
      "episode 13, val func loss 0.19175009429454803\n",
      "\n",
      "episode 14, val func loss 0.1828993707895279\n",
      "\n",
      "episode 15, val func loss 0.16182148456573486\n",
      "\n",
      "episode 16, val func loss 0.20003406703472137\n",
      "\n",
      "Val func train loss in epoch 2:0.19508687686175108\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18344980478286743\n",
      "\n",
      "episode 2, val func loss 0.20258024334907532\n",
      "\n",
      "episode 3, val func loss 0.1623937338590622\n",
      "\n",
      "episode 4, val func loss 0.20213857293128967\n",
      "\n",
      "episode 5, val func loss 0.22134548425674438\n",
      "\n",
      "episode 6, val func loss 0.17325477302074432\n",
      "\n",
      "episode 7, val func loss 0.20287871360778809\n",
      "\n",
      "episode 8, val func loss 0.1921636313199997\n",
      "\n",
      "episode 9, val func loss 0.20782135426998138\n",
      "\n",
      "episode 10, val func loss 0.19198866188526154\n",
      "\n",
      "episode 11, val func loss 0.21301569044589996\n",
      "\n",
      "episode 12, val func loss 0.1696593463420868\n",
      "\n",
      "episode 13, val func loss 0.19146966934204102\n",
      "\n",
      "episode 14, val func loss 0.1995031088590622\n",
      "\n",
      "episode 15, val func loss 0.19492830336093903\n",
      "\n",
      "episode 16, val func loss 0.213959738612175\n",
      "\n",
      "Val func train loss in epoch 3:0.19515942689031363\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.21408423781394958\n",
      "\n",
      "episode 2, val func loss 0.1832343488931656\n",
      "\n",
      "episode 3, val func loss 0.20756804943084717\n",
      "\n",
      "episode 4, val func loss 0.19171977043151855\n",
      "\n",
      "episode 5, val func loss 0.17017216980457306\n",
      "\n",
      "episode 6, val func loss 0.1717875599861145\n",
      "\n",
      "episode 7, val func loss 0.19438859820365906\n",
      "\n",
      "episode 8, val func loss 0.19149480760097504\n",
      "\n",
      "episode 9, val func loss 0.2008245289325714\n",
      "\n",
      "episode 10, val func loss 0.16152390837669373\n",
      "\n",
      "episode 11, val func loss 0.2022402435541153\n",
      "\n",
      "episode 12, val func loss 0.1930791586637497\n",
      "\n",
      "episode 13, val func loss 0.20352774858474731\n",
      "\n",
      "episode 14, val func loss 0.21370024979114532\n",
      "\n",
      "episode 15, val func loss 0.22257116436958313\n",
      "\n",
      "episode 16, val func loss 0.20101016759872437\n",
      "\n",
      "Val func train loss in epoch 4:0.1951829195022583\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18494261801242828\n",
      "\n",
      "episode 2, val func loss 0.1649862676858902\n",
      "\n",
      "episode 3, val func loss 0.20108498632907867\n",
      "\n",
      "episode 4, val func loss 0.20466597378253937\n",
      "\n",
      "episode 5, val func loss 0.2061856985092163\n",
      "\n",
      "episode 6, val func loss 0.21216195821762085\n",
      "\n",
      "episode 7, val func loss 0.19134259223937988\n",
      "\n",
      "episode 8, val func loss 0.17329467833042145\n",
      "\n",
      "episode 9, val func loss 0.19942276179790497\n",
      "\n",
      "episode 10, val func loss 0.20246949791908264\n",
      "\n",
      "episode 11, val func loss 0.2230328768491745\n",
      "\n",
      "episode 12, val func loss 0.1914196014404297\n",
      "\n",
      "episode 13, val func loss 0.16849136352539062\n",
      "\n",
      "episode 14, val func loss 0.19254949688911438\n",
      "\n",
      "episode 15, val func loss 0.19475378096103668\n",
      "\n",
      "episode 16, val func loss 0.2145228236913681\n",
      "\n",
      "Val func train loss in epoch 5:0.1953329360112548\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.20823974907398224\n",
      "\n",
      "episode 2, val func loss 0.19485875964164734\n",
      "\n",
      "episode 3, val func loss 0.16280505061149597\n",
      "\n",
      "episode 4, val func loss 0.20258012413978577\n",
      "\n",
      "episode 5, val func loss 0.18360835313796997\n",
      "\n",
      "episode 6, val func loss 0.1915704905986786\n",
      "\n",
      "episode 7, val func loss 0.1923636645078659\n",
      "\n",
      "episode 8, val func loss 0.2023487687110901\n",
      "\n",
      "episode 9, val func loss 0.1690368950366974\n",
      "\n",
      "episode 10, val func loss 0.20198433101177216\n",
      "\n",
      "episode 11, val func loss 0.19247092306613922\n",
      "\n",
      "episode 12, val func loss 0.1699533462524414\n",
      "\n",
      "episode 13, val func loss 0.22230571508407593\n",
      "\n",
      "episode 14, val func loss 0.1997985690832138\n",
      "\n",
      "episode 15, val func loss 0.2128412276506424\n",
      "\n",
      "episode 16, val func loss 0.21352587640285492\n",
      "\n",
      "Val func train loss in epoch 6:0.19501824025064707\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19205181300640106\n",
      "\n",
      "episode 2, val func loss 0.20322094857692719\n",
      "\n",
      "episode 3, val func loss 0.22050224244594574\n",
      "\n",
      "episode 4, val func loss 0.19988706707954407\n",
      "\n",
      "episode 5, val func loss 0.21348333358764648\n",
      "\n",
      "episode 6, val func loss 0.21244174242019653\n",
      "\n",
      "episode 7, val func loss 0.20644287765026093\n",
      "\n",
      "episode 8, val func loss 0.19285599887371063\n",
      "\n",
      "episode 9, val func loss 0.19571644067764282\n",
      "\n",
      "episode 10, val func loss 0.17004235088825226\n",
      "\n",
      "episode 11, val func loss 0.20222193002700806\n",
      "\n",
      "episode 12, val func loss 0.16940538585186005\n",
      "\n",
      "episode 13, val func loss 0.18324024975299835\n",
      "\n",
      "episode 14, val func loss 0.19416488707065582\n",
      "\n",
      "episode 15, val func loss 0.16266438364982605\n",
      "\n",
      "episode 16, val func loss 0.20739780366420746\n",
      "\n",
      "Val func train loss in epoch 7:0.19535871595144272\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1939518004655838\n",
      "\n",
      "episode 2, val func loss 0.20404312014579773\n",
      "\n",
      "episode 3, val func loss 0.1922769844532013\n",
      "\n",
      "episode 4, val func loss 0.17316606640815735\n",
      "\n",
      "episode 5, val func loss 0.2063622772693634\n",
      "\n",
      "episode 6, val func loss 0.19925519824028015\n",
      "\n",
      "episode 7, val func loss 0.18615113198757172\n",
      "\n",
      "episode 8, val func loss 0.21330343186855316\n",
      "\n",
      "episode 9, val func loss 0.19221679866313934\n",
      "\n",
      "episode 10, val func loss 0.16324037313461304\n",
      "\n",
      "episode 11, val func loss 0.16859664022922516\n",
      "\n",
      "episode 12, val func loss 0.20533974468708038\n",
      "\n",
      "episode 13, val func loss 0.22652864456176758\n",
      "\n",
      "episode 14, val func loss 0.21382907032966614\n",
      "\n",
      "episode 15, val func loss 0.20229613780975342\n",
      "\n",
      "episode 16, val func loss 0.1956777125597\n",
      "\n",
      "Val func train loss in epoch 8:0.19601469580084085\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20652879774570465\n",
      "\n",
      "episode 2, val func loss 0.19652001559734344\n",
      "\n",
      "episode 3, val func loss 0.21222516894340515\n",
      "\n",
      "episode 4, val func loss 0.1924409419298172\n",
      "\n",
      "episode 5, val func loss 0.2023112028837204\n",
      "\n",
      "episode 6, val func loss 0.19250546395778656\n",
      "\n",
      "episode 7, val func loss 0.20146365463733673\n",
      "\n",
      "episode 8, val func loss 0.220462366938591\n",
      "\n",
      "episode 9, val func loss 0.20460809767246246\n",
      "\n",
      "episode 10, val func loss 0.1928528994321823\n",
      "\n",
      "episode 11, val func loss 0.1640584021806717\n",
      "\n",
      "episode 12, val func loss 0.21361292898654938\n",
      "\n",
      "episode 13, val func loss 0.17135967314243317\n",
      "\n",
      "episode 14, val func loss 0.182964488863945\n",
      "\n",
      "episode 15, val func loss 0.20299379527568817\n",
      "\n",
      "episode 16, val func loss 0.16798387467861176\n",
      "\n",
      "Val func train loss in epoch 9:0.19530573580414057\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.2050231248140335\n",
      "\n",
      "episode 2, val func loss 0.18305878341197968\n",
      "\n",
      "episode 3, val func loss 0.16973167657852173\n",
      "\n",
      "episode 4, val func loss 0.19991418719291687\n",
      "\n",
      "episode 5, val func loss 0.2132342904806137\n",
      "\n",
      "episode 6, val func loss 0.20778478682041168\n",
      "\n",
      "episode 7, val func loss 0.19175858795642853\n",
      "\n",
      "episode 8, val func loss 0.22133769094944\n",
      "\n",
      "episode 9, val func loss 0.19289278984069824\n",
      "\n",
      "episode 10, val func loss 0.19156530499458313\n",
      "\n",
      "episode 11, val func loss 0.19664731621742249\n",
      "\n",
      "episode 12, val func loss 0.21370811760425568\n",
      "\n",
      "episode 13, val func loss 0.16365639865398407\n",
      "\n",
      "episode 14, val func loss 0.2021789848804474\n",
      "\n",
      "episode 15, val func loss 0.20230717957019806\n",
      "\n",
      "episode 16, val func loss 0.16823506355285645\n",
      "\n",
      "Val func train loss in epoch 10:0.19518964271992445\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19634997844696045\n",
      "\n",
      "episode 2, val func loss 0.21131229400634766\n",
      "\n",
      "episode 3, val func loss 0.22254100441932678\n",
      "\n",
      "episode 4, val func loss 0.19535504281520844\n",
      "\n",
      "episode 5, val func loss 0.20099735260009766\n",
      "\n",
      "episode 6, val func loss 0.16491195559501648\n",
      "\n",
      "episode 7, val func loss 0.21422137320041656\n",
      "\n",
      "episode 8, val func loss 0.19939124584197998\n",
      "\n",
      "episode 9, val func loss 0.19313007593154907\n",
      "\n",
      "episode 10, val func loss 0.19193531572818756\n",
      "\n",
      "episode 11, val func loss 0.20263905823230743\n",
      "\n",
      "episode 12, val func loss 0.21364030241966248\n",
      "\n",
      "episode 13, val func loss 0.16872844099998474\n",
      "\n",
      "episode 14, val func loss 0.18292228877544403\n",
      "\n",
      "episode 15, val func loss 0.202544167637825\n",
      "\n",
      "episode 16, val func loss 0.1690952032804489\n",
      "\n",
      "Val func train loss in epoch 11:0.1956071937456727\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.2167271375656128\n",
      "\n",
      "episode 2, val func loss 0.2108835130929947\n",
      "\n",
      "episode 3, val func loss 0.20322458446025848\n",
      "\n",
      "episode 4, val func loss 0.1714061051607132\n",
      "\n",
      "episode 5, val func loss 0.21231728792190552\n",
      "\n",
      "episode 6, val func loss 0.20245343446731567\n",
      "\n",
      "episode 7, val func loss 0.19947142899036407\n",
      "\n",
      "episode 8, val func loss 0.17072877287864685\n",
      "\n",
      "episode 9, val func loss 0.22070516645908356\n",
      "\n",
      "episode 10, val func loss 0.1631830930709839\n",
      "\n",
      "episode 11, val func loss 0.19227036833763123\n",
      "\n",
      "episode 12, val func loss 0.20226600766181946\n",
      "\n",
      "episode 13, val func loss 0.19146564602851868\n",
      "\n",
      "episode 14, val func loss 0.194670632481575\n",
      "\n",
      "episode 15, val func loss 0.19347289204597473\n",
      "\n",
      "episode 16, val func loss 0.18281179666519165\n",
      "\n",
      "Val func train loss in epoch 12:0.19550361670553684\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1943081170320511\n",
      "\n",
      "episode 2, val func loss 0.1924700289964676\n",
      "\n",
      "episode 3, val func loss 0.19177605211734772\n",
      "\n",
      "episode 4, val func loss 0.2016793191432953\n",
      "\n",
      "episode 5, val func loss 0.1729063242673874\n",
      "\n",
      "episode 6, val func loss 0.2019263207912445\n",
      "\n",
      "episode 7, val func loss 0.18357858061790466\n",
      "\n",
      "episode 8, val func loss 0.2137000858783722\n",
      "\n",
      "episode 9, val func loss 0.19971860945224762\n",
      "\n",
      "episode 10, val func loss 0.16226895153522491\n",
      "\n",
      "episode 11, val func loss 0.16903671622276306\n",
      "\n",
      "episode 12, val func loss 0.22242869436740875\n",
      "\n",
      "episode 13, val func loss 0.20246148109436035\n",
      "\n",
      "episode 14, val func loss 0.1916755586862564\n",
      "\n",
      "episode 15, val func loss 0.21322959661483765\n",
      "\n",
      "episode 16, val func loss 0.20736238360404968\n",
      "\n",
      "Val func train loss in epoch 13:0.19503292627632618\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19157841801643372\n",
      "\n",
      "episode 2, val func loss 0.1926397830247879\n",
      "\n",
      "episode 3, val func loss 0.18495620787143707\n",
      "\n",
      "episode 4, val func loss 0.21338923275470734\n",
      "\n",
      "episode 5, val func loss 0.20340000092983246\n",
      "\n",
      "episode 6, val func loss 0.19927361607551575\n",
      "\n",
      "episode 7, val func loss 0.20125043392181396\n",
      "\n",
      "episode 8, val func loss 0.20718500018119812\n",
      "\n",
      "episode 9, val func loss 0.22076043486595154\n",
      "\n",
      "episode 10, val func loss 0.17075160145759583\n",
      "\n",
      "episode 11, val func loss 0.20192065834999084\n",
      "\n",
      "episode 12, val func loss 0.19197824597358704\n",
      "\n",
      "episode 13, val func loss 0.1716248244047165\n",
      "\n",
      "episode 14, val func loss 0.1620878279209137\n",
      "\n",
      "episode 15, val func loss 0.19413042068481445\n",
      "\n",
      "episode 16, val func loss 0.21596921980381012\n",
      "\n",
      "Val func train loss in epoch 14:0.19518099538981915\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.2056833952665329\n",
      "\n",
      "episode 2, val func loss 0.2243705838918686\n",
      "\n",
      "episode 3, val func loss 0.20810233056545258\n",
      "\n",
      "episode 4, val func loss 0.16254857182502747\n",
      "\n",
      "episode 5, val func loss 0.17433203756809235\n",
      "\n",
      "episode 6, val func loss 0.21196013689041138\n",
      "\n",
      "episode 7, val func loss 0.19624535739421844\n",
      "\n",
      "episode 8, val func loss 0.1924002319574356\n",
      "\n",
      "episode 9, val func loss 0.19921711087226868\n",
      "\n",
      "episode 10, val func loss 0.21339160203933716\n",
      "\n",
      "episode 11, val func loss 0.18336988985538483\n",
      "\n",
      "episode 12, val func loss 0.1920991986989975\n",
      "\n",
      "episode 13, val func loss 0.16892917454242706\n",
      "\n",
      "episode 14, val func loss 0.19151167571544647\n",
      "\n",
      "episode 15, val func loss 0.20232008397579193\n",
      "\n",
      "episode 16, val func loss 0.20346787571907043\n",
      "\n",
      "Val func train loss in epoch 15:0.1956218285486102\n",
      "***********************TIME WAS 4.955294175942739 min*****************************\n",
      "\n",
      "**********************ROUND 80 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.017947696149349213\n",
      "\n",
      "episode 2, policy loss -0.004290258977562189\n",
      "\n",
      "episode 3, policy loss -0.07271268218755722\n",
      "\n",
      "episode 4, policy loss -0.0667397528886795\n",
      "\n",
      "episode 5, policy loss -0.04012695327401161\n",
      "\n",
      "episode 6, policy loss -0.06489282101392746\n",
      "\n",
      "episode 7, policy loss -0.019680127501487732\n",
      "\n",
      "episode 8, policy loss -0.08150820434093475\n",
      "\n",
      "episode 9, policy loss -0.03825743496417999\n",
      "\n",
      "episode 10, policy loss -0.01602252386510372\n",
      "\n",
      "episode 11, policy loss -0.019483698531985283\n",
      "\n",
      "episode 12, policy loss -0.06160430237650871\n",
      "\n",
      "episode 13, policy loss -0.02401180937886238\n",
      "\n",
      "episode 14, policy loss -0.058531541377305984\n",
      "\n",
      "episode 15, policy loss -0.027146006003022194\n",
      "\n",
      "episode 16, policy loss -0.04527784138917923\n",
      "\n",
      "Policy train loss in epoch 0:-0.041139603388728574\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.028754137456417084\n",
      "\n",
      "episode 2, policy loss -0.05860176309943199\n",
      "\n",
      "episode 3, policy loss -0.08152482658624649\n",
      "\n",
      "episode 4, policy loss -0.04576031118631363\n",
      "\n",
      "episode 5, policy loss -0.016078289598226547\n",
      "\n",
      "episode 6, policy loss -0.025260303169488907\n",
      "\n",
      "episode 7, policy loss -0.024686571210622787\n",
      "\n",
      "episode 8, policy loss -0.011763064190745354\n",
      "\n",
      "episode 9, policy loss -0.07416511327028275\n",
      "\n",
      "episode 10, policy loss -0.06977998465299606\n",
      "\n",
      "episode 11, policy loss -0.022259749472141266\n",
      "\n",
      "episode 12, policy loss -0.06426042318344116\n",
      "\n",
      "episode 13, policy loss -0.0392015166580677\n",
      "\n",
      "episode 14, policy loss -0.02708151564002037\n",
      "\n",
      "episode 15, policy loss -0.08490578830242157\n",
      "\n",
      "episode 16, policy loss -0.04897389933466911\n",
      "\n",
      "Policy train loss in epoch 1:-0.0451910785632208\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.026163605973124504\n",
      "\n",
      "episode 2, policy loss -0.07448044419288635\n",
      "\n",
      "episode 3, policy loss -0.06513672322034836\n",
      "\n",
      "episode 4, policy loss -0.016091585159301758\n",
      "\n",
      "episode 5, policy loss -0.049943629652261734\n",
      "\n",
      "episode 6, policy loss -0.020852185785770416\n",
      "\n",
      "episode 7, policy loss -0.0692768320441246\n",
      "\n",
      "episode 8, policy loss -0.024688834324479103\n",
      "\n",
      "episode 9, policy loss -0.08453702926635742\n",
      "\n",
      "episode 10, policy loss -0.027324091643095016\n",
      "\n",
      "episode 11, policy loss -0.012187652289867401\n",
      "\n",
      "episode 12, policy loss -0.03917337581515312\n",
      "\n",
      "episode 13, policy loss -0.08195924758911133\n",
      "\n",
      "episode 14, policy loss -0.05976247787475586\n",
      "\n",
      "episode 15, policy loss -0.027931200340390205\n",
      "\n",
      "episode 16, policy loss -0.04613587260246277\n",
      "\n",
      "Policy train loss in epoch 2:-0.04535279923584312\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.02497757039964199\n",
      "\n",
      "episode 2, policy loss -0.03902338072657585\n",
      "\n",
      "episode 3, policy loss -0.04953799396753311\n",
      "\n",
      "episode 4, policy loss -0.04573926329612732\n",
      "\n",
      "episode 5, policy loss -0.08370500802993774\n",
      "\n",
      "episode 6, policy loss -0.06529803574085236\n",
      "\n",
      "episode 7, policy loss -0.028726600110530853\n",
      "\n",
      "episode 8, policy loss -0.059957824647426605\n",
      "\n",
      "episode 9, policy loss -0.011472661979496479\n",
      "\n",
      "episode 10, policy loss -0.021380946040153503\n",
      "\n",
      "episode 11, policy loss -0.02693789452314377\n",
      "\n",
      "episode 12, policy loss -0.07395046204328537\n",
      "\n",
      "episode 13, policy loss -0.02576194889843464\n",
      "\n",
      "episode 14, policy loss -0.0695929005742073\n",
      "\n",
      "episode 15, policy loss -0.08175893872976303\n",
      "\n",
      "episode 16, policy loss -0.016617368906736374\n",
      "\n",
      "Policy train loss in epoch 3:-0.045277424913365394\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19389520585536957\n",
      "\n",
      "episode 2, val func loss 0.19777001440525055\n",
      "\n",
      "episode 3, val func loss 0.20910535752773285\n",
      "\n",
      "episode 4, val func loss 0.20138368010520935\n",
      "\n",
      "episode 5, val func loss 0.1779535561800003\n",
      "\n",
      "episode 6, val func loss 0.1928449273109436\n",
      "\n",
      "episode 7, val func loss 0.1788206398487091\n",
      "\n",
      "episode 8, val func loss 0.19204936921596527\n",
      "\n",
      "episode 9, val func loss 0.2102552056312561\n",
      "\n",
      "episode 10, val func loss 0.17311231791973114\n",
      "\n",
      "episode 11, val func loss 0.18552593886852264\n",
      "\n",
      "episode 12, val func loss 0.15068115293979645\n",
      "\n",
      "episode 13, val func loss 0.18665456771850586\n",
      "\n",
      "episode 14, val func loss 0.17996416985988617\n",
      "\n",
      "episode 15, val func loss 0.1911981850862503\n",
      "\n",
      "episode 16, val func loss 0.20297451317310333\n",
      "\n",
      "Val func train loss in epoch 0:0.18901180010288954\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19442839920520782\n",
      "\n",
      "episode 2, val func loss 0.1777513027191162\n",
      "\n",
      "episode 3, val func loss 0.17267383635044098\n",
      "\n",
      "episode 4, val func loss 0.17750446498394012\n",
      "\n",
      "episode 5, val func loss 0.15158484876155853\n",
      "\n",
      "episode 6, val func loss 0.19241955876350403\n",
      "\n",
      "episode 7, val func loss 0.1855318695306778\n",
      "\n",
      "episode 8, val func loss 0.21147815883159637\n",
      "\n",
      "episode 9, val func loss 0.18022744357585907\n",
      "\n",
      "episode 10, val func loss 0.20989353954792023\n",
      "\n",
      "episode 11, val func loss 0.19004052877426147\n",
      "\n",
      "episode 12, val func loss 0.1945865899324417\n",
      "\n",
      "episode 13, val func loss 0.19934000074863434\n",
      "\n",
      "episode 14, val func loss 0.18781358003616333\n",
      "\n",
      "episode 15, val func loss 0.2010480910539627\n",
      "\n",
      "episode 16, val func loss 0.19756829738616943\n",
      "\n",
      "Val func train loss in epoch 1:0.18899315688759089\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18238863348960876\n",
      "\n",
      "episode 2, val func loss 0.19317656755447388\n",
      "\n",
      "episode 3, val func loss 0.186379536986351\n",
      "\n",
      "episode 4, val func loss 0.20914536714553833\n",
      "\n",
      "episode 5, val func loss 0.1999630481004715\n",
      "\n",
      "episode 6, val func loss 0.19191840291023254\n",
      "\n",
      "episode 7, val func loss 0.19229495525360107\n",
      "\n",
      "episode 8, val func loss 0.2014199197292328\n",
      "\n",
      "episode 9, val func loss 0.17907509207725525\n",
      "\n",
      "episode 10, val func loss 0.18940819799900055\n",
      "\n",
      "episode 11, val func loss 0.1513332724571228\n",
      "\n",
      "episode 12, val func loss 0.1766495555639267\n",
      "\n",
      "episode 13, val func loss 0.18671314418315887\n",
      "\n",
      "episode 14, val func loss 0.21552681922912598\n",
      "\n",
      "episode 15, val func loss 0.17307345569133759\n",
      "\n",
      "episode 16, val func loss 0.19897525012493134\n",
      "\n",
      "Val func train loss in epoch 2:0.18921507615596056\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20183062553405762\n",
      "\n",
      "episode 2, val func loss 0.2091299146413803\n",
      "\n",
      "episode 3, val func loss 0.1935647875070572\n",
      "\n",
      "episode 4, val func loss 0.19341415166854858\n",
      "\n",
      "episode 5, val func loss 0.18314266204833984\n",
      "\n",
      "episode 6, val func loss 0.1976989358663559\n",
      "\n",
      "episode 7, val func loss 0.19160395860671997\n",
      "\n",
      "episode 8, val func loss 0.18719615042209625\n",
      "\n",
      "episode 9, val func loss 0.1772935390472412\n",
      "\n",
      "episode 10, val func loss 0.18678562343120575\n",
      "\n",
      "episode 11, val func loss 0.17761674523353577\n",
      "\n",
      "episode 12, val func loss 0.2027706652879715\n",
      "\n",
      "episode 13, val func loss 0.15077756345272064\n",
      "\n",
      "episode 14, val func loss 0.17285317182540894\n",
      "\n",
      "episode 15, val func loss 0.19000481069087982\n",
      "\n",
      "episode 16, val func loss 0.21102778613567352\n",
      "\n",
      "Val func train loss in epoch 3:0.18916944321244955\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1918930858373642\n",
      "\n",
      "episode 2, val func loss 0.18767394125461578\n",
      "\n",
      "episode 3, val func loss 0.2010204941034317\n",
      "\n",
      "episode 4, val func loss 0.19361861050128937\n",
      "\n",
      "episode 5, val func loss 0.1935122311115265\n",
      "\n",
      "episode 6, val func loss 0.17378465831279755\n",
      "\n",
      "episode 7, val func loss 0.19779802858829498\n",
      "\n",
      "episode 8, val func loss 0.18067273497581482\n",
      "\n",
      "episode 9, val func loss 0.2108832746744156\n",
      "\n",
      "episode 10, val func loss 0.18651574850082397\n",
      "\n",
      "episode 11, val func loss 0.17610831558704376\n",
      "\n",
      "episode 12, val func loss 0.21241912245750427\n",
      "\n",
      "episode 13, val func loss 0.18984811007976532\n",
      "\n",
      "episode 14, val func loss 0.19914080202579498\n",
      "\n",
      "episode 15, val func loss 0.17923517525196075\n",
      "\n",
      "episode 16, val func loss 0.1522965282201767\n",
      "\n",
      "Val func train loss in epoch 4:0.18915130384266376\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1936763972043991\n",
      "\n",
      "episode 2, val func loss 0.2097787857055664\n",
      "\n",
      "episode 3, val func loss 0.1899270862340927\n",
      "\n",
      "episode 4, val func loss 0.19803570210933685\n",
      "\n",
      "episode 5, val func loss 0.15195457637310028\n",
      "\n",
      "episode 6, val func loss 0.1772516518831253\n",
      "\n",
      "episode 7, val func loss 0.1915998011827469\n",
      "\n",
      "episode 8, val func loss 0.19227276742458344\n",
      "\n",
      "episode 9, val func loss 0.18070606887340546\n",
      "\n",
      "episode 10, val func loss 0.1986227035522461\n",
      "\n",
      "episode 11, val func loss 0.18434885144233704\n",
      "\n",
      "episode 12, val func loss 0.1775786131620407\n",
      "\n",
      "episode 13, val func loss 0.18588405847549438\n",
      "\n",
      "episode 14, val func loss 0.1729651838541031\n",
      "\n",
      "episode 15, val func loss 0.2045743763446808\n",
      "\n",
      "episode 16, val func loss 0.21123020350933075\n",
      "\n",
      "Val func train loss in epoch 5:0.18877542670816183\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19297143816947937\n",
      "\n",
      "episode 2, val func loss 0.18118087947368622\n",
      "\n",
      "episode 3, val func loss 0.19748003780841827\n",
      "\n",
      "episode 4, val func loss 0.17967233061790466\n",
      "\n",
      "episode 5, val func loss 0.1777062714099884\n",
      "\n",
      "episode 6, val func loss 0.1895195096731186\n",
      "\n",
      "episode 7, val func loss 0.20109935104846954\n",
      "\n",
      "episode 8, val func loss 0.17353090643882751\n",
      "\n",
      "episode 9, val func loss 0.18489164113998413\n",
      "\n",
      "episode 10, val func loss 0.19168411195278168\n",
      "\n",
      "episode 11, val func loss 0.19558048248291016\n",
      "\n",
      "episode 12, val func loss 0.1510191708803177\n",
      "\n",
      "episode 13, val func loss 0.2017010599374771\n",
      "\n",
      "episode 14, val func loss 0.18630658090114594\n",
      "\n",
      "episode 15, val func loss 0.2113538235425949\n",
      "\n",
      "episode 16, val func loss 0.2092878818511963\n",
      "\n",
      "Val func train loss in epoch 6:0.18906159233301878\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.15222661197185516\n",
      "\n",
      "episode 2, val func loss 0.1887194812297821\n",
      "\n",
      "episode 3, val func loss 0.17401118576526642\n",
      "\n",
      "episode 4, val func loss 0.18193349242210388\n",
      "\n",
      "episode 5, val func loss 0.2091303914785385\n",
      "\n",
      "episode 6, val func loss 0.21078632771968842\n",
      "\n",
      "episode 7, val func loss 0.19840000569820404\n",
      "\n",
      "episode 8, val func loss 0.19241400063037872\n",
      "\n",
      "episode 9, val func loss 0.18956486880779266\n",
      "\n",
      "episode 10, val func loss 0.19312946498394012\n",
      "\n",
      "episode 11, val func loss 0.17752814292907715\n",
      "\n",
      "episode 12, val func loss 0.20103685557842255\n",
      "\n",
      "episode 13, val func loss 0.19282031059265137\n",
      "\n",
      "episode 14, val func loss 0.17865973711013794\n",
      "\n",
      "episode 15, val func loss 0.19846829771995544\n",
      "\n",
      "episode 16, val func loss 0.18513816595077515\n",
      "\n",
      "Val func train loss in epoch 7:0.1889979587867856\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.21102969348430634\n",
      "\n",
      "episode 2, val func loss 0.2018289417028427\n",
      "\n",
      "episode 3, val func loss 0.18081557750701904\n",
      "\n",
      "episode 4, val func loss 0.19404055178165436\n",
      "\n",
      "episode 5, val func loss 0.19869783520698547\n",
      "\n",
      "episode 6, val func loss 0.1977393925189972\n",
      "\n",
      "episode 7, val func loss 0.1916995644569397\n",
      "\n",
      "episode 8, val func loss 0.17975878715515137\n",
      "\n",
      "episode 9, val func loss 0.20890770852565765\n",
      "\n",
      "episode 10, val func loss 0.19362841546535492\n",
      "\n",
      "episode 11, val func loss 0.18893006443977356\n",
      "\n",
      "episode 12, val func loss 0.17726314067840576\n",
      "\n",
      "episode 13, val func loss 0.15069754421710968\n",
      "\n",
      "episode 14, val func loss 0.17289236187934875\n",
      "\n",
      "episode 15, val func loss 0.1905640959739685\n",
      "\n",
      "episode 16, val func loss 0.18316924571990967\n",
      "\n",
      "Val func train loss in epoch 8:0.18885393254458904\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1959734857082367\n",
      "\n",
      "episode 2, val func loss 0.1866869330406189\n",
      "\n",
      "episode 3, val func loss 0.21149010956287384\n",
      "\n",
      "episode 4, val func loss 0.17812594771385193\n",
      "\n",
      "episode 5, val func loss 0.2019731104373932\n",
      "\n",
      "episode 6, val func loss 0.2101120799779892\n",
      "\n",
      "episode 7, val func loss 0.1757906675338745\n",
      "\n",
      "episode 8, val func loss 0.17962639033794403\n",
      "\n",
      "episode 9, val func loss 0.1945047378540039\n",
      "\n",
      "episode 10, val func loss 0.1976555436849594\n",
      "\n",
      "episode 11, val func loss 0.18633496761322021\n",
      "\n",
      "episode 12, val func loss 0.18020211160182953\n",
      "\n",
      "episode 13, val func loss 0.20051616430282593\n",
      "\n",
      "episode 14, val func loss 0.19520148634910583\n",
      "\n",
      "episode 15, val func loss 0.15060676634311676\n",
      "\n",
      "episode 16, val func loss 0.18949760496616364\n",
      "\n",
      "Val func train loss in epoch 9:0.18964363168925047\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.21024948358535767\n",
      "\n",
      "episode 2, val func loss 0.15112975239753723\n",
      "\n",
      "episode 3, val func loss 0.18750262260437012\n",
      "\n",
      "episode 4, val func loss 0.19194601476192474\n",
      "\n",
      "episode 5, val func loss 0.18536211550235748\n",
      "\n",
      "episode 6, val func loss 0.21059007942676544\n",
      "\n",
      "episode 7, val func loss 0.17661899328231812\n",
      "\n",
      "episode 8, val func loss 0.1728726625442505\n",
      "\n",
      "episode 9, val func loss 0.1775810718536377\n",
      "\n",
      "episode 10, val func loss 0.1921701431274414\n",
      "\n",
      "episode 11, val func loss 0.19444946944713593\n",
      "\n",
      "episode 12, val func loss 0.1987481564283371\n",
      "\n",
      "episode 13, val func loss 0.18033869564533234\n",
      "\n",
      "episode 14, val func loss 0.20259860157966614\n",
      "\n",
      "episode 15, val func loss 0.19922995567321777\n",
      "\n",
      "episode 16, val func loss 0.18984422087669373\n",
      "\n",
      "Val func train loss in epoch 10:0.18882700242102146\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1884593516588211\n",
      "\n",
      "episode 2, val func loss 0.19000232219696045\n",
      "\n",
      "episode 3, val func loss 0.18220648169517517\n",
      "\n",
      "episode 4, val func loss 0.1858643740415573\n",
      "\n",
      "episode 5, val func loss 0.19825853407382965\n",
      "\n",
      "episode 6, val func loss 0.20001626014709473\n",
      "\n",
      "episode 7, val func loss 0.1729796677827835\n",
      "\n",
      "episode 8, val func loss 0.19155289232730865\n",
      "\n",
      "episode 9, val func loss 0.19424165785312653\n",
      "\n",
      "episode 10, val func loss 0.1779753863811493\n",
      "\n",
      "episode 11, val func loss 0.20990528166294098\n",
      "\n",
      "episode 12, val func loss 0.1510838270187378\n",
      "\n",
      "episode 13, val func loss 0.192569762468338\n",
      "\n",
      "episode 14, val func loss 0.17699553072452545\n",
      "\n",
      "episode 15, val func loss 0.21010169386863708\n",
      "\n",
      "episode 16, val func loss 0.20137198269367218\n",
      "\n",
      "Val func train loss in epoch 11:0.18897406291216612\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1887735277414322\n",
      "\n",
      "episode 2, val func loss 0.19767268002033234\n",
      "\n",
      "episode 3, val func loss 0.18237143754959106\n",
      "\n",
      "episode 4, val func loss 0.1517227590084076\n",
      "\n",
      "episode 5, val func loss 0.176834836602211\n",
      "\n",
      "episode 6, val func loss 0.1899254471063614\n",
      "\n",
      "episode 7, val func loss 0.19204632937908173\n",
      "\n",
      "episode 8, val func loss 0.2106941044330597\n",
      "\n",
      "episode 9, val func loss 0.2034658044576645\n",
      "\n",
      "episode 10, val func loss 0.17293834686279297\n",
      "\n",
      "episode 11, val func loss 0.1946278214454651\n",
      "\n",
      "episode 12, val func loss 0.1845078319311142\n",
      "\n",
      "episode 13, val func loss 0.19912798702716827\n",
      "\n",
      "episode 14, val func loss 0.17798535525798798\n",
      "\n",
      "episode 15, val func loss 0.1914350539445877\n",
      "\n",
      "episode 16, val func loss 0.20945538580417633\n",
      "\n",
      "Val func train loss in epoch 12:0.18897404428571463\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.20919039845466614\n",
      "\n",
      "episode 2, val func loss 0.2088683694601059\n",
      "\n",
      "episode 3, val func loss 0.1912076473236084\n",
      "\n",
      "episode 4, val func loss 0.19455793499946594\n",
      "\n",
      "episode 5, val func loss 0.18584106862545013\n",
      "\n",
      "episode 6, val func loss 0.18932509422302246\n",
      "\n",
      "episode 7, val func loss 0.17957432568073273\n",
      "\n",
      "episode 8, val func loss 0.1873895823955536\n",
      "\n",
      "episode 9, val func loss 0.20122748613357544\n",
      "\n",
      "episode 10, val func loss 0.17635048925876617\n",
      "\n",
      "episode 11, val func loss 0.20549528300762177\n",
      "\n",
      "episode 12, val func loss 0.20120036602020264\n",
      "\n",
      "episode 13, val func loss 0.19122286140918732\n",
      "\n",
      "episode 14, val func loss 0.1919039487838745\n",
      "\n",
      "episode 15, val func loss 0.17269372940063477\n",
      "\n",
      "episode 16, val func loss 0.15088610351085663\n",
      "\n",
      "Val func train loss in epoch 13:0.18980841804295778\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.2017807513475418\n",
      "\n",
      "episode 2, val func loss 0.19397179782390594\n",
      "\n",
      "episode 3, val func loss 0.20921488106250763\n",
      "\n",
      "episode 4, val func loss 0.19742773473262787\n",
      "\n",
      "episode 5, val func loss 0.19437338411808014\n",
      "\n",
      "episode 6, val func loss 0.20970912277698517\n",
      "\n",
      "episode 7, val func loss 0.17991219460964203\n",
      "\n",
      "episode 8, val func loss 0.1912253201007843\n",
      "\n",
      "episode 9, val func loss 0.1899099349975586\n",
      "\n",
      "episode 10, val func loss 0.15107868611812592\n",
      "\n",
      "episode 11, val func loss 0.1805368959903717\n",
      "\n",
      "episode 12, val func loss 0.18633587658405304\n",
      "\n",
      "episode 13, val func loss 0.20167915523052216\n",
      "\n",
      "episode 14, val func loss 0.1761315017938614\n",
      "\n",
      "episode 15, val func loss 0.184030219912529\n",
      "\n",
      "episode 16, val func loss 0.1726560890674591\n",
      "\n",
      "Val func train loss in epoch 14:0.18874834664165974\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.191636860370636\n",
      "\n",
      "episode 2, val func loss 0.15060822665691376\n",
      "\n",
      "episode 3, val func loss 0.2011108249425888\n",
      "\n",
      "episode 4, val func loss 0.19273459911346436\n",
      "\n",
      "episode 5, val func loss 0.17749203741550446\n",
      "\n",
      "episode 6, val func loss 0.1932971477508545\n",
      "\n",
      "episode 7, val func loss 0.18828852474689484\n",
      "\n",
      "episode 8, val func loss 0.2093306928873062\n",
      "\n",
      "episode 9, val func loss 0.1975124627351761\n",
      "\n",
      "episode 10, val func loss 0.18990284204483032\n",
      "\n",
      "episode 11, val func loss 0.20165777206420898\n",
      "\n",
      "episode 12, val func loss 0.1783764511346817\n",
      "\n",
      "episode 13, val func loss 0.20966127514839172\n",
      "\n",
      "episode 14, val func loss 0.1809549331665039\n",
      "\n",
      "episode 15, val func loss 0.1729220151901245\n",
      "\n",
      "episode 16, val func loss 0.18650096654891968\n",
      "\n",
      "Val func train loss in epoch 15:0.1888742269948125\n",
      "***********************TIME WAS 4.955423367023468 min*****************************\n",
      "\n",
      "**********************ROUND 81 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.055689722299575806\n",
      "\n",
      "episode 2, policy loss -0.016210099682211876\n",
      "\n",
      "episode 3, policy loss -0.11361866444349289\n",
      "\n",
      "episode 4, policy loss -0.06916450709104538\n",
      "\n",
      "episode 5, policy loss -0.053723111748695374\n",
      "\n",
      "episode 6, policy loss -0.06480484455823898\n",
      "\n",
      "episode 7, policy loss -0.1051706001162529\n",
      "\n",
      "episode 8, policy loss -0.05770598724484444\n",
      "\n",
      "episode 9, policy loss -0.11803258955478668\n",
      "\n",
      "episode 10, policy loss -0.04593326523900032\n",
      "\n",
      "episode 11, policy loss -0.011176800355315208\n",
      "\n",
      "episode 12, policy loss -0.09074397385120392\n",
      "\n",
      "episode 13, policy loss -0.07594547420740128\n",
      "\n",
      "episode 14, policy loss -0.05613967776298523\n",
      "\n",
      "episode 15, policy loss -0.058872174471616745\n",
      "\n",
      "episode 16, policy loss -0.040268365293741226\n",
      "\n",
      "Policy train loss in epoch 0:-0.06457499112002552\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.05899191275238991\n",
      "\n",
      "episode 2, policy loss -0.12040702253580093\n",
      "\n",
      "episode 3, policy loss -0.03963952884078026\n",
      "\n",
      "episode 4, policy loss -0.10646415501832962\n",
      "\n",
      "episode 5, policy loss -0.05876757949590683\n",
      "\n",
      "episode 6, policy loss -0.07534968107938766\n",
      "\n",
      "episode 7, policy loss -0.021059809252619743\n",
      "\n",
      "episode 8, policy loss -0.06718158721923828\n",
      "\n",
      "episode 9, policy loss -0.06503238528966904\n",
      "\n",
      "episode 10, policy loss -0.07325813919305801\n",
      "\n",
      "episode 11, policy loss -0.05794641748070717\n",
      "\n",
      "episode 12, policy loss -0.12231285125017166\n",
      "\n",
      "episode 13, policy loss -0.015584403648972511\n",
      "\n",
      "episode 14, policy loss -0.057397883385419846\n",
      "\n",
      "episode 15, policy loss -0.04761507734656334\n",
      "\n",
      "episode 16, policy loss -0.09041634202003479\n",
      "\n",
      "Policy train loss in epoch 1:-0.0673390484880656\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.07680346071720123\n",
      "\n",
      "episode 2, policy loss -0.015180359594523907\n",
      "\n",
      "episode 3, policy loss -0.057222213596105576\n",
      "\n",
      "episode 4, policy loss -0.05839826166629791\n",
      "\n",
      "episode 5, policy loss -0.06602997332811356\n",
      "\n",
      "episode 6, policy loss -0.041519202291965485\n",
      "\n",
      "episode 7, policy loss -0.0608142651617527\n",
      "\n",
      "episode 8, policy loss -0.059435367584228516\n",
      "\n",
      "episode 9, policy loss -0.12310530245304108\n",
      "\n",
      "episode 10, policy loss -0.10684331506490707\n",
      "\n",
      "episode 11, policy loss -0.09322500228881836\n",
      "\n",
      "episode 12, policy loss -0.12240859866142273\n",
      "\n",
      "episode 13, policy loss -0.04847713187336922\n",
      "\n",
      "episode 14, policy loss -0.07483220100402832\n",
      "\n",
      "episode 15, policy loss -0.06761813908815384\n",
      "\n",
      "episode 16, policy loss -0.02245318330824375\n",
      "\n",
      "Policy train loss in epoch 2:-0.06839787360513583\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.07409115135669708\n",
      "\n",
      "episode 2, policy loss -0.06039879843592644\n",
      "\n",
      "episode 3, policy loss -0.022739555686712265\n",
      "\n",
      "episode 4, policy loss -0.09308797121047974\n",
      "\n",
      "episode 5, policy loss -0.01489125844091177\n",
      "\n",
      "episode 6, policy loss -0.07691607624292374\n",
      "\n",
      "episode 7, policy loss -0.04820745810866356\n",
      "\n",
      "episode 8, policy loss -0.04155118390917778\n",
      "\n",
      "episode 9, policy loss -0.12248450517654419\n",
      "\n",
      "episode 10, policy loss -0.06658422946929932\n",
      "\n",
      "episode 11, policy loss -0.05959013104438782\n",
      "\n",
      "episode 12, policy loss -0.06705544888973236\n",
      "\n",
      "episode 13, policy loss -0.059598978608846664\n",
      "\n",
      "episode 14, policy loss -0.058060113340616226\n",
      "\n",
      "episode 15, policy loss -0.10714582353830338\n",
      "\n",
      "episode 16, policy loss -0.12296681851148605\n",
      "\n",
      "Policy train loss in epoch 3:-0.06846059387316927\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.20893250405788422\n",
      "\n",
      "episode 2, val func loss 0.20117010176181793\n",
      "\n",
      "episode 3, val func loss 0.22991281747817993\n",
      "\n",
      "episode 4, val func loss 0.17844104766845703\n",
      "\n",
      "episode 5, val func loss 0.1935747265815735\n",
      "\n",
      "episode 6, val func loss 0.20796334743499756\n",
      "\n",
      "episode 7, val func loss 0.23105698823928833\n",
      "\n",
      "episode 8, val func loss 0.18960390985012054\n",
      "\n",
      "episode 9, val func loss 0.18565066158771515\n",
      "\n",
      "episode 10, val func loss 0.20139412581920624\n",
      "\n",
      "episode 11, val func loss 0.18659096956253052\n",
      "\n",
      "episode 12, val func loss 0.18282262980937958\n",
      "\n",
      "episode 13, val func loss 0.21194379031658173\n",
      "\n",
      "episode 14, val func loss 0.21921756863594055\n",
      "\n",
      "episode 15, val func loss 0.17598894238471985\n",
      "\n",
      "episode 16, val func loss 0.16695012152194977\n",
      "\n",
      "Val func train loss in epoch 0:0.1982008907943964\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1945973038673401\n",
      "\n",
      "episode 2, val func loss 0.1782078742980957\n",
      "\n",
      "episode 3, val func loss 0.1755484789609909\n",
      "\n",
      "episode 4, val func loss 0.1861109584569931\n",
      "\n",
      "episode 5, val func loss 0.20717725157737732\n",
      "\n",
      "episode 6, val func loss 0.1827797293663025\n",
      "\n",
      "episode 7, val func loss 0.2332880198955536\n",
      "\n",
      "episode 8, val func loss 0.2269313633441925\n",
      "\n",
      "episode 9, val func loss 0.1685446798801422\n",
      "\n",
      "episode 10, val func loss 0.20005479454994202\n",
      "\n",
      "episode 11, val func loss 0.21596066653728485\n",
      "\n",
      "episode 12, val func loss 0.20075993239879608\n",
      "\n",
      "episode 13, val func loss 0.21116378903388977\n",
      "\n",
      "episode 14, val func loss 0.18535341322422028\n",
      "\n",
      "episode 15, val func loss 0.20796054601669312\n",
      "\n",
      "episode 16, val func loss 0.18713612854480743\n",
      "\n",
      "Val func train loss in epoch 1:0.19759843312203884\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.20017728209495544\n",
      "\n",
      "episode 2, val func loss 0.2069159597158432\n",
      "\n",
      "episode 3, val func loss 0.17603518068790436\n",
      "\n",
      "episode 4, val func loss 0.20072701573371887\n",
      "\n",
      "episode 5, val func loss 0.18353131413459778\n",
      "\n",
      "episode 6, val func loss 0.17900115251541138\n",
      "\n",
      "episode 7, val func loss 0.23469530045986176\n",
      "\n",
      "episode 8, val func loss 0.22855965793132782\n",
      "\n",
      "episode 9, val func loss 0.20805436372756958\n",
      "\n",
      "episode 10, val func loss 0.1940145045518875\n",
      "\n",
      "episode 11, val func loss 0.18884603679180145\n",
      "\n",
      "episode 12, val func loss 0.1836589276790619\n",
      "\n",
      "episode 13, val func loss 0.2116447538137436\n",
      "\n",
      "episode 14, val func loss 0.21593596041202545\n",
      "\n",
      "episode 15, val func loss 0.1705087274312973\n",
      "\n",
      "episode 16, val func loss 0.1852499544620514\n",
      "\n",
      "Val func train loss in epoch 2:0.19797225575894117\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.22632275521755219\n",
      "\n",
      "episode 2, val func loss 0.18225929141044617\n",
      "\n",
      "episode 3, val func loss 0.18708834052085876\n",
      "\n",
      "episode 4, val func loss 0.1849864423274994\n",
      "\n",
      "episode 5, val func loss 0.23302465677261353\n",
      "\n",
      "episode 6, val func loss 0.20691722631454468\n",
      "\n",
      "episode 7, val func loss 0.1760861575603485\n",
      "\n",
      "episode 8, val func loss 0.2168930172920227\n",
      "\n",
      "episode 9, val func loss 0.17774897813796997\n",
      "\n",
      "episode 10, val func loss 0.1938447207212448\n",
      "\n",
      "episode 11, val func loss 0.20848457515239716\n",
      "\n",
      "episode 12, val func loss 0.19996722042560577\n",
      "\n",
      "episode 13, val func loss 0.1700826734304428\n",
      "\n",
      "episode 14, val func loss 0.20004212856292725\n",
      "\n",
      "episode 15, val func loss 0.21159307658672333\n",
      "\n",
      "episode 16, val func loss 0.18399932980537415\n",
      "\n",
      "Val func train loss in epoch 3:0.1974587868899107\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.2087043672800064\n",
      "\n",
      "episode 2, val func loss 0.2013515830039978\n",
      "\n",
      "episode 3, val func loss 0.18328671157360077\n",
      "\n",
      "episode 4, val func loss 0.1666652113199234\n",
      "\n",
      "episode 5, val func loss 0.19994989037513733\n",
      "\n",
      "episode 6, val func loss 0.2129031866788864\n",
      "\n",
      "episode 7, val func loss 0.1853901892900467\n",
      "\n",
      "episode 8, val func loss 0.1860055774450302\n",
      "\n",
      "episode 9, val func loss 0.22676600515842438\n",
      "\n",
      "episode 10, val func loss 0.17681464552879333\n",
      "\n",
      "episode 11, val func loss 0.23121915757656097\n",
      "\n",
      "episode 12, val func loss 0.21549884974956512\n",
      "\n",
      "episode 13, val func loss 0.20928426086902618\n",
      "\n",
      "episode 14, val func loss 0.18370239436626434\n",
      "\n",
      "episode 15, val func loss 0.17775709927082062\n",
      "\n",
      "episode 16, val func loss 0.19361655414104462\n",
      "\n",
      "Val func train loss in epoch 4:0.19743223022669554\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19989892840385437\n",
      "\n",
      "episode 2, val func loss 0.18442709743976593\n",
      "\n",
      "episode 3, val func loss 0.18525026738643646\n",
      "\n",
      "episode 4, val func loss 0.1999812126159668\n",
      "\n",
      "episode 5, val func loss 0.16698618233203888\n",
      "\n",
      "episode 6, val func loss 0.18374915421009064\n",
      "\n",
      "episode 7, val func loss 0.20929129421710968\n",
      "\n",
      "episode 8, val func loss 0.17614111304283142\n",
      "\n",
      "episode 9, val func loss 0.22737640142440796\n",
      "\n",
      "episode 10, val func loss 0.17779022455215454\n",
      "\n",
      "episode 11, val func loss 0.21216927468776703\n",
      "\n",
      "episode 12, val func loss 0.23094619810581207\n",
      "\n",
      "episode 13, val func loss 0.21611325442790985\n",
      "\n",
      "episode 14, val func loss 0.19483500719070435\n",
      "\n",
      "episode 15, val func loss 0.18873915076255798\n",
      "\n",
      "episode 16, val func loss 0.20735830068588257\n",
      "\n",
      "Val func train loss in epoch 5:0.19756581634283066\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1995159536600113\n",
      "\n",
      "episode 2, val func loss 0.23338598012924194\n",
      "\n",
      "episode 3, val func loss 0.21739666163921356\n",
      "\n",
      "episode 4, val func loss 0.22696992754936218\n",
      "\n",
      "episode 5, val func loss 0.1875055432319641\n",
      "\n",
      "episode 6, val func loss 0.17784161865711212\n",
      "\n",
      "episode 7, val func loss 0.18591131269931793\n",
      "\n",
      "episode 8, val func loss 0.1766432225704193\n",
      "\n",
      "episode 9, val func loss 0.1693076491355896\n",
      "\n",
      "episode 10, val func loss 0.19367752969264984\n",
      "\n",
      "episode 11, val func loss 0.18249817192554474\n",
      "\n",
      "episode 12, val func loss 0.20836114883422852\n",
      "\n",
      "episode 13, val func loss 0.18395888805389404\n",
      "\n",
      "episode 14, val func loss 0.20733195543289185\n",
      "\n",
      "episode 15, val func loss 0.2002396583557129\n",
      "\n",
      "episode 16, val func loss 0.2122660130262375\n",
      "\n",
      "Val func train loss in epoch 6:0.19767570216208696\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.20090505480766296\n",
      "\n",
      "episode 2, val func loss 0.1996493935585022\n",
      "\n",
      "episode 3, val func loss 0.18677571415901184\n",
      "\n",
      "episode 4, val func loss 0.2324518859386444\n",
      "\n",
      "episode 5, val func loss 0.17800955474376678\n",
      "\n",
      "episode 6, val func loss 0.20810480415821075\n",
      "\n",
      "episode 7, val func loss 0.1772245317697525\n",
      "\n",
      "episode 8, val func loss 0.2253624051809311\n",
      "\n",
      "episode 9, val func loss 0.19360990822315216\n",
      "\n",
      "episode 10, val func loss 0.21105897426605225\n",
      "\n",
      "episode 11, val func loss 0.16968269646167755\n",
      "\n",
      "episode 12, val func loss 0.2164885699748993\n",
      "\n",
      "episode 13, val func loss 0.18514326214790344\n",
      "\n",
      "episode 14, val func loss 0.184983029961586\n",
      "\n",
      "episode 15, val func loss 0.1830451488494873\n",
      "\n",
      "episode 16, val func loss 0.20745235681533813\n",
      "\n",
      "Val func train loss in epoch 7:0.19749670568853617\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.22947144508361816\n",
      "\n",
      "episode 2, val func loss 0.18671023845672607\n",
      "\n",
      "episode 3, val func loss 0.19433975219726562\n",
      "\n",
      "episode 4, val func loss 0.21132013201713562\n",
      "\n",
      "episode 5, val func loss 0.18295510113239288\n",
      "\n",
      "episode 6, val func loss 0.2079133242368698\n",
      "\n",
      "episode 7, val func loss 0.17816723883152008\n",
      "\n",
      "episode 8, val func loss 0.18779325485229492\n",
      "\n",
      "episode 9, val func loss 0.20015323162078857\n",
      "\n",
      "episode 10, val func loss 0.2067200094461441\n",
      "\n",
      "episode 11, val func loss 0.2002282589673996\n",
      "\n",
      "episode 12, val func loss 0.23350602388381958\n",
      "\n",
      "episode 13, val func loss 0.1675100326538086\n",
      "\n",
      "episode 14, val func loss 0.1760949045419693\n",
      "\n",
      "episode 15, val func loss 0.18520790338516235\n",
      "\n",
      "episode 16, val func loss 0.21762710809707642\n",
      "\n",
      "Val func train loss in epoch 8:0.19785737246274948\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.21710452437400818\n",
      "\n",
      "episode 2, val func loss 0.1933276206254959\n",
      "\n",
      "episode 3, val func loss 0.18616443872451782\n",
      "\n",
      "episode 4, val func loss 0.23092231154441833\n",
      "\n",
      "episode 5, val func loss 0.1898101270198822\n",
      "\n",
      "episode 6, val func loss 0.20801886916160583\n",
      "\n",
      "episode 7, val func loss 0.21105897426605225\n",
      "\n",
      "episode 8, val func loss 0.18679560720920563\n",
      "\n",
      "episode 9, val func loss 0.22754323482513428\n",
      "\n",
      "episode 10, val func loss 0.18293094635009766\n",
      "\n",
      "episode 11, val func loss 0.20773498713970184\n",
      "\n",
      "episode 12, val func loss 0.17830181121826172\n",
      "\n",
      "episode 13, val func loss 0.1999427229166031\n",
      "\n",
      "episode 14, val func loss 0.1686246544122696\n",
      "\n",
      "episode 15, val func loss 0.17599566280841827\n",
      "\n",
      "episode 16, val func loss 0.19996918737888336\n",
      "\n",
      "Val func train loss in epoch 9:0.19776535499840975\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.2003004252910614\n",
      "\n",
      "episode 2, val func loss 0.23275935649871826\n",
      "\n",
      "episode 3, val func loss 0.211131289601326\n",
      "\n",
      "episode 4, val func loss 0.20773813128471375\n",
      "\n",
      "episode 5, val func loss 0.2253912091255188\n",
      "\n",
      "episode 6, val func loss 0.21594704687595367\n",
      "\n",
      "episode 7, val func loss 0.18418379127979279\n",
      "\n",
      "episode 8, val func loss 0.1723378598690033\n",
      "\n",
      "episode 9, val func loss 0.19383807480335236\n",
      "\n",
      "episode 10, val func loss 0.20797626674175262\n",
      "\n",
      "episode 11, val func loss 0.18668504059314728\n",
      "\n",
      "episode 12, val func loss 0.17572021484375\n",
      "\n",
      "episode 13, val func loss 0.18554706871509552\n",
      "\n",
      "episode 14, val func loss 0.17933176457881927\n",
      "\n",
      "episode 15, val func loss 0.20012031495571136\n",
      "\n",
      "episode 16, val func loss 0.1841890960931778\n",
      "\n",
      "Val func train loss in epoch 10:0.19769980944693089\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.17641325294971466\n",
      "\n",
      "episode 2, val func loss 0.19453074038028717\n",
      "\n",
      "episode 3, val func loss 0.20009750127792358\n",
      "\n",
      "episode 4, val func loss 0.182613804936409\n",
      "\n",
      "episode 5, val func loss 0.1877269595861435\n",
      "\n",
      "episode 6, val func loss 0.16887541115283966\n",
      "\n",
      "episode 7, val func loss 0.20785702764987946\n",
      "\n",
      "episode 8, val func loss 0.2115832418203354\n",
      "\n",
      "episode 9, val func loss 0.19975444674491882\n",
      "\n",
      "episode 10, val func loss 0.1786143034696579\n",
      "\n",
      "episode 11, val func loss 0.18446578085422516\n",
      "\n",
      "episode 12, val func loss 0.18505844473838806\n",
      "\n",
      "episode 13, val func loss 0.21810343861579895\n",
      "\n",
      "episode 14, val func loss 0.20728401839733124\n",
      "\n",
      "episode 15, val func loss 0.22668439149856567\n",
      "\n",
      "episode 16, val func loss 0.23124073445796967\n",
      "\n",
      "Val func train loss in epoch 11:0.19755646865814924\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17372161149978638\n",
      "\n",
      "episode 2, val func loss 0.19407688081264496\n",
      "\n",
      "episode 3, val func loss 0.1780608594417572\n",
      "\n",
      "episode 4, val func loss 0.17638029158115387\n",
      "\n",
      "episode 5, val func loss 0.1996874362230301\n",
      "\n",
      "episode 6, val func loss 0.2071094810962677\n",
      "\n",
      "episode 7, val func loss 0.21748214960098267\n",
      "\n",
      "episode 8, val func loss 0.18653085827827454\n",
      "\n",
      "episode 9, val func loss 0.2116672694683075\n",
      "\n",
      "episode 10, val func loss 0.18285119533538818\n",
      "\n",
      "episode 11, val func loss 0.18532367050647736\n",
      "\n",
      "episode 12, val func loss 0.18558025360107422\n",
      "\n",
      "episode 13, val func loss 0.22687752544879913\n",
      "\n",
      "episode 14, val func loss 0.19988806545734406\n",
      "\n",
      "episode 15, val func loss 0.2082129865884781\n",
      "\n",
      "episode 16, val func loss 0.2322542667388916\n",
      "\n",
      "Val func train loss in epoch 12:0.1978565501049161\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1867746263742447\n",
      "\n",
      "episode 2, val func loss 0.21143007278442383\n",
      "\n",
      "episode 3, val func loss 0.1757650375366211\n",
      "\n",
      "episode 4, val func loss 0.23179657757282257\n",
      "\n",
      "episode 5, val func loss 0.2081814408302307\n",
      "\n",
      "episode 6, val func loss 0.20755045115947723\n",
      "\n",
      "episode 7, val func loss 0.19951903820037842\n",
      "\n",
      "episode 8, val func loss 0.19347481429576874\n",
      "\n",
      "episode 9, val func loss 0.1854918897151947\n",
      "\n",
      "episode 10, val func loss 0.21622301638126373\n",
      "\n",
      "episode 11, val func loss 0.16851674020290375\n",
      "\n",
      "episode 12, val func loss 0.2264990210533142\n",
      "\n",
      "episode 13, val func loss 0.19987629354000092\n",
      "\n",
      "episode 14, val func loss 0.1781110316514969\n",
      "\n",
      "episode 15, val func loss 0.18275563418865204\n",
      "\n",
      "episode 16, val func loss 0.18544724583625793\n",
      "\n",
      "Val func train loss in epoch 13:0.19733830820769072\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19388172030448914\n",
      "\n",
      "episode 2, val func loss 0.17592036724090576\n",
      "\n",
      "episode 3, val func loss 0.18286846578121185\n",
      "\n",
      "episode 4, val func loss 0.18631711602210999\n",
      "\n",
      "episode 5, val func loss 0.22843438386917114\n",
      "\n",
      "episode 6, val func loss 0.1844768077135086\n",
      "\n",
      "episode 7, val func loss 0.20829495787620544\n",
      "\n",
      "episode 8, val func loss 0.2171603888273239\n",
      "\n",
      "episode 9, val func loss 0.2325098216533661\n",
      "\n",
      "episode 10, val func loss 0.1778893917798996\n",
      "\n",
      "episode 11, val func loss 0.2113932967185974\n",
      "\n",
      "episode 12, val func loss 0.2013833075761795\n",
      "\n",
      "episode 13, val func loss 0.17081378400325775\n",
      "\n",
      "episode 14, val func loss 0.1856350302696228\n",
      "\n",
      "episode 15, val func loss 0.20008309185504913\n",
      "\n",
      "episode 16, val func loss 0.20691142976284027\n",
      "\n",
      "Val func train loss in epoch 14:0.19774833507835865\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1670360118150711\n",
      "\n",
      "episode 2, val func loss 0.22945880889892578\n",
      "\n",
      "episode 3, val func loss 0.20732514560222626\n",
      "\n",
      "episode 4, val func loss 0.23445966839790344\n",
      "\n",
      "episode 5, val func loss 0.21774202585220337\n",
      "\n",
      "episode 6, val func loss 0.19946277141571045\n",
      "\n",
      "episode 7, val func loss 0.20041076838970184\n",
      "\n",
      "episode 8, val func loss 0.1781991869211197\n",
      "\n",
      "episode 9, val func loss 0.2089841514825821\n",
      "\n",
      "episode 10, val func loss 0.1773087978363037\n",
      "\n",
      "episode 11, val func loss 0.1862344741821289\n",
      "\n",
      "episode 12, val func loss 0.18808187544345856\n",
      "\n",
      "episode 13, val func loss 0.18233370780944824\n",
      "\n",
      "episode 14, val func loss 0.19391348958015442\n",
      "\n",
      "episode 15, val func loss 0.18444325029850006\n",
      "\n",
      "episode 16, val func loss 0.2126735895872116\n",
      "\n",
      "Val func train loss in epoch 15:0.1980042327195406\n",
      "***********************TIME WAS 4.955658419926961 min*****************************\n",
      "\n",
      "**********************ROUND 82 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.021445954218506813\n",
      "\n",
      "episode 2, policy loss -0.022927410900592804\n",
      "\n",
      "episode 3, policy loss -0.05928952991962433\n",
      "\n",
      "episode 4, policy loss -0.010035895742475986\n",
      "\n",
      "episode 5, policy loss -0.0937616229057312\n",
      "\n",
      "episode 6, policy loss -0.0747629851102829\n",
      "\n",
      "episode 7, policy loss -0.0811009556055069\n",
      "\n",
      "episode 8, policy loss -0.10589444637298584\n",
      "\n",
      "episode 9, policy loss -0.04064398631453514\n",
      "\n",
      "episode 10, policy loss -0.052465178072452545\n",
      "\n",
      "episode 11, policy loss -0.00685786921530962\n",
      "\n",
      "episode 12, policy loss -0.03440787270665169\n",
      "\n",
      "episode 13, policy loss -0.07272021472454071\n",
      "\n",
      "episode 14, policy loss -0.06987733393907547\n",
      "\n",
      "episode 15, policy loss -0.0069336192682385445\n",
      "\n",
      "episode 16, policy loss -0.07424359023571014\n",
      "\n",
      "Policy train loss in epoch 0:-0.05171052907826379\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.011906487867236137\n",
      "\n",
      "episode 2, policy loss -0.00837119109928608\n",
      "\n",
      "episode 3, policy loss -0.07154743373394012\n",
      "\n",
      "episode 4, policy loss -0.0308663509786129\n",
      "\n",
      "episode 5, policy loss -0.029820963740348816\n",
      "\n",
      "episode 6, policy loss -0.07293376326560974\n",
      "\n",
      "episode 7, policy loss -0.06537792086601257\n",
      "\n",
      "episode 8, policy loss -0.09515439718961716\n",
      "\n",
      "episode 9, policy loss -0.10836923122406006\n",
      "\n",
      "episode 10, policy loss -0.05606444552540779\n",
      "\n",
      "episode 11, policy loss -0.036402370780706406\n",
      "\n",
      "episode 12, policy loss -0.04116445034742355\n",
      "\n",
      "episode 13, policy loss -0.0739998146891594\n",
      "\n",
      "episode 14, policy loss -0.007585519924759865\n",
      "\n",
      "episode 15, policy loss -0.08228665590286255\n",
      "\n",
      "episode 16, policy loss -0.07927051186561584\n",
      "\n",
      "Policy train loss in epoch 1:-0.05444509431254119\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.08259125798940659\n",
      "\n",
      "episode 2, policy loss -0.03738458827137947\n",
      "\n",
      "episode 3, policy loss -0.013683086261153221\n",
      "\n",
      "episode 4, policy loss -0.030679946765303612\n",
      "\n",
      "episode 5, policy loss -0.04029842093586922\n",
      "\n",
      "episode 6, policy loss -0.07550787180662155\n",
      "\n",
      "episode 7, policy loss -0.10755616426467896\n",
      "\n",
      "episode 8, policy loss -0.09565726667642593\n",
      "\n",
      "episode 9, policy loss -0.03216416388750076\n",
      "\n",
      "episode 10, policy loss -0.07172293961048126\n",
      "\n",
      "episode 11, policy loss -0.06490034610033035\n",
      "\n",
      "episode 12, policy loss -0.07310733199119568\n",
      "\n",
      "episode 13, policy loss -0.05445319786667824\n",
      "\n",
      "episode 14, policy loss -0.008611231110990047\n",
      "\n",
      "episode 15, policy loss -0.007720137946307659\n",
      "\n",
      "episode 16, policy loss -0.0783725306391716\n",
      "\n",
      "Policy train loss in epoch 2:-0.054650655132718384\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.07323374599218369\n",
      "\n",
      "episode 2, policy loss -0.07871148735284805\n",
      "\n",
      "episode 3, policy loss -0.008426923304796219\n",
      "\n",
      "episode 4, policy loss -0.03592991456389427\n",
      "\n",
      "episode 5, policy loss -0.008344778791069984\n",
      "\n",
      "episode 6, policy loss -0.07489287853240967\n",
      "\n",
      "episode 7, policy loss -0.06489183753728867\n",
      "\n",
      "episode 8, policy loss -0.07440771162509918\n",
      "\n",
      "episode 9, policy loss -0.032280340790748596\n",
      "\n",
      "episode 10, policy loss -0.09592051059007645\n",
      "\n",
      "episode 11, policy loss -0.013888061977922916\n",
      "\n",
      "episode 12, policy loss -0.055481210350990295\n",
      "\n",
      "episode 13, policy loss -0.04168109595775604\n",
      "\n",
      "episode 14, policy loss -0.08289303630590439\n",
      "\n",
      "episode 15, policy loss -0.1081252172589302\n",
      "\n",
      "episode 16, policy loss -0.031199945136904716\n",
      "\n",
      "Policy train loss in epoch 3:-0.05501929350430146\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1909627467393875\n",
      "\n",
      "episode 2, val func loss 0.15942129492759705\n",
      "\n",
      "episode 3, val func loss 0.17440402507781982\n",
      "\n",
      "episode 4, val func loss 0.18140946328639984\n",
      "\n",
      "episode 5, val func loss 0.21045534312725067\n",
      "\n",
      "episode 6, val func loss 0.1913495659828186\n",
      "\n",
      "episode 7, val func loss 0.2018701285123825\n",
      "\n",
      "episode 8, val func loss 0.21695619821548462\n",
      "\n",
      "episode 9, val func loss 0.17308850586414337\n",
      "\n",
      "episode 10, val func loss 0.16829849779605865\n",
      "\n",
      "episode 11, val func loss 0.1597161740064621\n",
      "\n",
      "episode 12, val func loss 0.1965898871421814\n",
      "\n",
      "episode 13, val func loss 0.1609911471605301\n",
      "\n",
      "episode 14, val func loss 0.19864733517169952\n",
      "\n",
      "episode 15, val func loss 0.193898543715477\n",
      "\n",
      "episode 16, val func loss 0.1881544589996338\n",
      "\n",
      "Val func train loss in epoch 0:0.1853883322328329\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.21678893268108368\n",
      "\n",
      "episode 2, val func loss 0.17221888899803162\n",
      "\n",
      "episode 3, val func loss 0.18874326348304749\n",
      "\n",
      "episode 4, val func loss 0.1986040323972702\n",
      "\n",
      "episode 5, val func loss 0.2054990530014038\n",
      "\n",
      "episode 6, val func loss 0.18767715990543365\n",
      "\n",
      "episode 7, val func loss 0.1592092514038086\n",
      "\n",
      "episode 8, val func loss 0.1933744251728058\n",
      "\n",
      "episode 9, val func loss 0.160834401845932\n",
      "\n",
      "episode 10, val func loss 0.19737859070301056\n",
      "\n",
      "episode 11, val func loss 0.16635483503341675\n",
      "\n",
      "episode 12, val func loss 0.18210120499134064\n",
      "\n",
      "episode 13, val func loss 0.19079773128032684\n",
      "\n",
      "episode 14, val func loss 0.20281705260276794\n",
      "\n",
      "episode 15, val func loss 0.17450955510139465\n",
      "\n",
      "episode 16, val func loss 0.15931810438632965\n",
      "\n",
      "Val func train loss in epoch 1:0.18476415518671274\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19122926890850067\n",
      "\n",
      "episode 2, val func loss 0.1566120684146881\n",
      "\n",
      "episode 3, val func loss 0.15972870588302612\n",
      "\n",
      "episode 4, val func loss 0.15897293388843536\n",
      "\n",
      "episode 5, val func loss 0.2029036283493042\n",
      "\n",
      "episode 6, val func loss 0.17201343178749084\n",
      "\n",
      "episode 7, val func loss 0.21880075335502625\n",
      "\n",
      "episode 8, val func loss 0.19897660613059998\n",
      "\n",
      "episode 9, val func loss 0.18874968588352203\n",
      "\n",
      "episode 10, val func loss 0.17826151847839355\n",
      "\n",
      "episode 11, val func loss 0.1691434383392334\n",
      "\n",
      "episode 12, val func loss 0.18379521369934082\n",
      "\n",
      "episode 13, val func loss 0.19352979958057404\n",
      "\n",
      "episode 14, val func loss 0.18787284195423126\n",
      "\n",
      "episode 15, val func loss 0.19744761288166046\n",
      "\n",
      "episode 16, val func loss 0.20612388849258423\n",
      "\n",
      "Val func train loss in epoch 2:0.1852600872516632\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.16065232455730438\n",
      "\n",
      "episode 2, val func loss 0.15772216022014618\n",
      "\n",
      "episode 3, val func loss 0.18855445086956024\n",
      "\n",
      "episode 4, val func loss 0.16456031799316406\n",
      "\n",
      "episode 5, val func loss 0.19068506360054016\n",
      "\n",
      "episode 6, val func loss 0.19994018971920013\n",
      "\n",
      "episode 7, val func loss 0.17469759285449982\n",
      "\n",
      "episode 8, val func loss 0.20226441323757172\n",
      "\n",
      "episode 9, val func loss 0.1904618740081787\n",
      "\n",
      "episode 10, val func loss 0.19882600009441376\n",
      "\n",
      "episode 11, val func loss 0.1817644238471985\n",
      "\n",
      "episode 12, val func loss 0.19450001418590546\n",
      "\n",
      "episode 13, val func loss 0.2163197100162506\n",
      "\n",
      "episode 14, val func loss 0.16183675825595856\n",
      "\n",
      "episode 15, val func loss 0.1736110895872116\n",
      "\n",
      "episode 16, val func loss 0.20516833662986755\n",
      "\n",
      "Val func train loss in epoch 3:0.18509779497981071\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17860110104084015\n",
      "\n",
      "episode 2, val func loss 0.18350839614868164\n",
      "\n",
      "episode 3, val func loss 0.20121608674526215\n",
      "\n",
      "episode 4, val func loss 0.15973269939422607\n",
      "\n",
      "episode 5, val func loss 0.20045524835586548\n",
      "\n",
      "episode 6, val func loss 0.19718503952026367\n",
      "\n",
      "episode 7, val func loss 0.15942418575286865\n",
      "\n",
      "episode 8, val func loss 0.21815167367458344\n",
      "\n",
      "episode 9, val func loss 0.19076547026634216\n",
      "\n",
      "episode 10, val func loss 0.18894560635089874\n",
      "\n",
      "episode 11, val func loss 0.2061854898929596\n",
      "\n",
      "episode 12, val func loss 0.158655047416687\n",
      "\n",
      "episode 13, val func loss 0.1968885064125061\n",
      "\n",
      "episode 14, val func loss 0.18773771822452545\n",
      "\n",
      "episode 15, val func loss 0.1680096834897995\n",
      "\n",
      "episode 16, val func loss 0.1726200431585312\n",
      "\n",
      "Val func train loss in epoch 4:0.18550512474030256\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18179532885551453\n",
      "\n",
      "episode 2, val func loss 0.1723330169916153\n",
      "\n",
      "episode 3, val func loss 0.1626666784286499\n",
      "\n",
      "episode 4, val func loss 0.22376972436904907\n",
      "\n",
      "episode 5, val func loss 0.19069528579711914\n",
      "\n",
      "episode 6, val func loss 0.18920207023620605\n",
      "\n",
      "episode 7, val func loss 0.20592254400253296\n",
      "\n",
      "episode 8, val func loss 0.16287276148796082\n",
      "\n",
      "episode 9, val func loss 0.20145048201084137\n",
      "\n",
      "episode 10, val func loss 0.1934104561805725\n",
      "\n",
      "episode 11, val func loss 0.1599033623933792\n",
      "\n",
      "episode 12, val func loss 0.16131439805030823\n",
      "\n",
      "episode 13, val func loss 0.1910822093486786\n",
      "\n",
      "episode 14, val func loss 0.17469733953475952\n",
      "\n",
      "episode 15, val func loss 0.2046525776386261\n",
      "\n",
      "episode 16, val func loss 0.20078524947166443\n",
      "\n",
      "Val func train loss in epoch 5:0.18603459279984236\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.16485852003097534\n",
      "\n",
      "episode 2, val func loss 0.1820206195116043\n",
      "\n",
      "episode 3, val func loss 0.2158905416727066\n",
      "\n",
      "episode 4, val func loss 0.19338670372962952\n",
      "\n",
      "episode 5, val func loss 0.19227616488933563\n",
      "\n",
      "episode 6, val func loss 0.20152175426483154\n",
      "\n",
      "episode 7, val func loss 0.19837814569473267\n",
      "\n",
      "episode 8, val func loss 0.1614774763584137\n",
      "\n",
      "episode 9, val func loss 0.18827451765537262\n",
      "\n",
      "episode 10, val func loss 0.1725606471300125\n",
      "\n",
      "episode 11, val func loss 0.15970438718795776\n",
      "\n",
      "episode 12, val func loss 0.19050660729408264\n",
      "\n",
      "episode 13, val func loss 0.15673238039016724\n",
      "\n",
      "episode 14, val func loss 0.1746094971895218\n",
      "\n",
      "episode 15, val func loss 0.2079627513885498\n",
      "\n",
      "episode 16, val func loss 0.1987779140472412\n",
      "\n",
      "Val func train loss in epoch 6:0.18493366427719593\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.2012433558702469\n",
      "\n",
      "episode 2, val func loss 0.16081839799880981\n",
      "\n",
      "episode 3, val func loss 0.16009461879730225\n",
      "\n",
      "episode 4, val func loss 0.1574791818857193\n",
      "\n",
      "episode 5, val func loss 0.2166067212820053\n",
      "\n",
      "episode 6, val func loss 0.18856418132781982\n",
      "\n",
      "episode 7, val func loss 0.1973119080066681\n",
      "\n",
      "episode 8, val func loss 0.17254433035850525\n",
      "\n",
      "episode 9, val func loss 0.17677316069602966\n",
      "\n",
      "episode 10, val func loss 0.18256817758083344\n",
      "\n",
      "episode 11, val func loss 0.19139020144939423\n",
      "\n",
      "episode 12, val func loss 0.20697268843650818\n",
      "\n",
      "episode 13, val func loss 0.19941605627536774\n",
      "\n",
      "episode 14, val func loss 0.16440387070178986\n",
      "\n",
      "episode 15, val func loss 0.19001592695713043\n",
      "\n",
      "episode 16, val func loss 0.19569015502929688\n",
      "\n",
      "Val func train loss in epoch 7:0.1851183082908392\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.20715481042861938\n",
      "\n",
      "episode 2, val func loss 0.1601572334766388\n",
      "\n",
      "episode 3, val func loss 0.16533900797367096\n",
      "\n",
      "episode 4, val func loss 0.1972830444574356\n",
      "\n",
      "episode 5, val func loss 0.1989949345588684\n",
      "\n",
      "episode 6, val func loss 0.18214151263237\n",
      "\n",
      "episode 7, val func loss 0.19147811830043793\n",
      "\n",
      "episode 8, val func loss 0.17217031121253967\n",
      "\n",
      "episode 9, val func loss 0.18896688520908356\n",
      "\n",
      "episode 10, val func loss 0.15638023614883423\n",
      "\n",
      "episode 11, val func loss 0.19527746737003326\n",
      "\n",
      "episode 12, val func loss 0.21765436232089996\n",
      "\n",
      "episode 13, val func loss 0.20139598846435547\n",
      "\n",
      "episode 14, val func loss 0.16012825071811676\n",
      "\n",
      "episode 15, val func loss 0.17639799416065216\n",
      "\n",
      "episode 16, val func loss 0.18878161907196045\n",
      "\n",
      "Val func train loss in epoch 8:0.1849813610315323\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18216344714164734\n",
      "\n",
      "episode 2, val func loss 0.1881972998380661\n",
      "\n",
      "episode 3, val func loss 0.19707541167736053\n",
      "\n",
      "episode 4, val func loss 0.1758928894996643\n",
      "\n",
      "episode 5, val func loss 0.19429230690002441\n",
      "\n",
      "episode 6, val func loss 0.21659210324287415\n",
      "\n",
      "episode 7, val func loss 0.1914530247449875\n",
      "\n",
      "episode 8, val func loss 0.20595210790634155\n",
      "\n",
      "episode 9, val func loss 0.18883295357227325\n",
      "\n",
      "episode 10, val func loss 0.20088127255439758\n",
      "\n",
      "episode 11, val func loss 0.16747520864009857\n",
      "\n",
      "episode 12, val func loss 0.1612364947795868\n",
      "\n",
      "episode 13, val func loss 0.15703745186328888\n",
      "\n",
      "episode 14, val func loss 0.15934568643569946\n",
      "\n",
      "episode 15, val func loss 0.2015807330608368\n",
      "\n",
      "episode 16, val func loss 0.17274096608161926\n",
      "\n",
      "Val func train loss in epoch 9:0.1850468348711729\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1916845589876175\n",
      "\n",
      "episode 2, val func loss 0.2194540649652481\n",
      "\n",
      "episode 3, val func loss 0.20689284801483154\n",
      "\n",
      "episode 4, val func loss 0.18793711066246033\n",
      "\n",
      "episode 5, val func loss 0.1630469411611557\n",
      "\n",
      "episode 6, val func loss 0.1929631233215332\n",
      "\n",
      "episode 7, val func loss 0.1603817492723465\n",
      "\n",
      "episode 8, val func loss 0.1735522449016571\n",
      "\n",
      "episode 9, val func loss 0.18314146995544434\n",
      "\n",
      "episode 10, val func loss 0.16489771008491516\n",
      "\n",
      "episode 11, val func loss 0.15985314548015594\n",
      "\n",
      "episode 12, val func loss 0.2044154852628708\n",
      "\n",
      "episode 13, val func loss 0.20313067734241486\n",
      "\n",
      "episode 14, val func loss 0.17439179122447968\n",
      "\n",
      "episode 15, val func loss 0.19777995347976685\n",
      "\n",
      "episode 16, val func loss 0.19896018505096436\n",
      "\n",
      "Val func train loss in epoch 10:0.18640519119799137\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.21726079285144806\n",
      "\n",
      "episode 2, val func loss 0.1988135427236557\n",
      "\n",
      "episode 3, val func loss 0.16807793080806732\n",
      "\n",
      "episode 4, val func loss 0.18905633687973022\n",
      "\n",
      "episode 5, val func loss 0.1847173124551773\n",
      "\n",
      "episode 6, val func loss 0.1739068627357483\n",
      "\n",
      "episode 7, val func loss 0.1768142282962799\n",
      "\n",
      "episode 8, val func loss 0.19795919954776764\n",
      "\n",
      "episode 9, val func loss 0.207206591963768\n",
      "\n",
      "episode 10, val func loss 0.1909743994474411\n",
      "\n",
      "episode 11, val func loss 0.15964075922966003\n",
      "\n",
      "episode 12, val func loss 0.18891732394695282\n",
      "\n",
      "episode 13, val func loss 0.15987400710582733\n",
      "\n",
      "episode 14, val func loss 0.156416654586792\n",
      "\n",
      "episode 15, val func loss 0.19532513618469238\n",
      "\n",
      "episode 16, val func loss 0.20170174539089203\n",
      "\n",
      "Val func train loss in epoch 11:0.18541642650961876\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17199896275997162\n",
      "\n",
      "episode 2, val func loss 0.18879052996635437\n",
      "\n",
      "episode 3, val func loss 0.18176352977752686\n",
      "\n",
      "episode 4, val func loss 0.19696392118930817\n",
      "\n",
      "episode 5, val func loss 0.19843445718288422\n",
      "\n",
      "episode 6, val func loss 0.2013583779335022\n",
      "\n",
      "episode 7, val func loss 0.1887352615594864\n",
      "\n",
      "episode 8, val func loss 0.19200578331947327\n",
      "\n",
      "episode 9, val func loss 0.21532079577445984\n",
      "\n",
      "episode 10, val func loss 0.17693085968494415\n",
      "\n",
      "episode 11, val func loss 0.19332075119018555\n",
      "\n",
      "episode 12, val func loss 0.15772928297519684\n",
      "\n",
      "episode 13, val func loss 0.16523480415344238\n",
      "\n",
      "episode 14, val func loss 0.1599864959716797\n",
      "\n",
      "episode 15, val func loss 0.20991981029510498\n",
      "\n",
      "episode 16, val func loss 0.15977288782596588\n",
      "\n",
      "Val func train loss in epoch 12:0.1848916569724679\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1562638282775879\n",
      "\n",
      "episode 2, val func loss 0.18193700909614563\n",
      "\n",
      "episode 3, val func loss 0.19080494344234467\n",
      "\n",
      "episode 4, val func loss 0.20856314897537231\n",
      "\n",
      "episode 5, val func loss 0.20197367668151855\n",
      "\n",
      "episode 6, val func loss 0.18860481679439545\n",
      "\n",
      "episode 7, val func loss 0.16525982320308685\n",
      "\n",
      "episode 8, val func loss 0.19697421789169312\n",
      "\n",
      "episode 9, val func loss 0.2155061662197113\n",
      "\n",
      "episode 10, val func loss 0.19331613183021545\n",
      "\n",
      "episode 11, val func loss 0.1742154061794281\n",
      "\n",
      "episode 12, val func loss 0.1624714881181717\n",
      "\n",
      "episode 13, val func loss 0.18857033550739288\n",
      "\n",
      "episode 14, val func loss 0.16267625987529755\n",
      "\n",
      "episode 15, val func loss 0.19887521862983704\n",
      "\n",
      "episode 16, val func loss 0.17532671988010406\n",
      "\n",
      "Val func train loss in epoch 13:0.1850836994126439\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.20183256268501282\n",
      "\n",
      "episode 2, val func loss 0.18124133348464966\n",
      "\n",
      "episode 3, val func loss 0.19115909934043884\n",
      "\n",
      "episode 4, val func loss 0.15953631699085236\n",
      "\n",
      "episode 5, val func loss 0.2006254643201828\n",
      "\n",
      "episode 6, val func loss 0.21953031420707703\n",
      "\n",
      "episode 7, val func loss 0.18968941271305084\n",
      "\n",
      "episode 8, val func loss 0.20605754852294922\n",
      "\n",
      "episode 9, val func loss 0.19881047308444977\n",
      "\n",
      "episode 10, val func loss 0.16974982619285583\n",
      "\n",
      "episode 11, val func loss 0.18843834102153778\n",
      "\n",
      "episode 12, val func loss 0.17979198694229126\n",
      "\n",
      "episode 13, val func loss 0.19350558519363403\n",
      "\n",
      "episode 14, val func loss 0.15880529582500458\n",
      "\n",
      "episode 15, val func loss 0.1610070914030075\n",
      "\n",
      "episode 16, val func loss 0.17221902310848236\n",
      "\n",
      "Val func train loss in epoch 14:0.1857499796897173\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.15962103009223938\n",
      "\n",
      "episode 2, val func loss 0.19188864529132843\n",
      "\n",
      "episode 3, val func loss 0.1564863622188568\n",
      "\n",
      "episode 4, val func loss 0.19230090081691742\n",
      "\n",
      "episode 5, val func loss 0.17498686909675598\n",
      "\n",
      "episode 6, val func loss 0.15924429893493652\n",
      "\n",
      "episode 7, val func loss 0.1723058521747589\n",
      "\n",
      "episode 8, val func loss 0.1820274442434311\n",
      "\n",
      "episode 9, val func loss 0.20751433074474335\n",
      "\n",
      "episode 10, val func loss 0.21787399053573608\n",
      "\n",
      "episode 11, val func loss 0.16544106602668762\n",
      "\n",
      "episode 12, val func loss 0.18765611946582794\n",
      "\n",
      "episode 13, val func loss 0.1972200572490692\n",
      "\n",
      "episode 14, val func loss 0.2013959139585495\n",
      "\n",
      "episode 15, val func loss 0.19346792995929718\n",
      "\n",
      "episode 16, val func loss 0.1992654800415039\n",
      "\n",
      "Val func train loss in epoch 15:0.18491851817816496\n",
      "***********************TIME WAS 4.965613126754761 min*****************************\n",
      "\n",
      "**********************ROUND 83 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.027920516207814217\n",
      "\n",
      "episode 2, policy loss -0.06741714477539062\n",
      "\n",
      "episode 3, policy loss 0.011338086798787117\n",
      "\n",
      "episode 4, policy loss -0.000852766796015203\n",
      "\n",
      "episode 5, policy loss 0.03193698450922966\n",
      "\n",
      "episode 6, policy loss -0.0026406655088067055\n",
      "\n",
      "episode 7, policy loss -0.01324387826025486\n",
      "\n",
      "episode 8, policy loss 0.005942516960203648\n",
      "\n",
      "episode 9, policy loss -0.04032270237803459\n",
      "\n",
      "episode 10, policy loss 0.01674645207822323\n",
      "\n",
      "episode 11, policy loss 0.041777353733778\n",
      "\n",
      "episode 12, policy loss 0.037305861711502075\n",
      "\n",
      "episode 13, policy loss -0.03973480686545372\n",
      "\n",
      "episode 14, policy loss -0.010788566432893276\n",
      "\n",
      "episode 15, policy loss -0.03487350046634674\n",
      "\n",
      "episode 16, policy loss -0.04178709536790848\n",
      "\n",
      "Policy train loss in epoch 0:-0.008408399204199668\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.03484581410884857\n",
      "\n",
      "episode 2, policy loss 0.040125682950019836\n",
      "\n",
      "episode 3, policy loss 0.004615711979568005\n",
      "\n",
      "episode 4, policy loss -0.03180362656712532\n",
      "\n",
      "episode 5, policy loss -0.043270908296108246\n",
      "\n",
      "episode 6, policy loss -0.012344506569206715\n",
      "\n",
      "episode 7, policy loss -0.0383467897772789\n",
      "\n",
      "episode 8, policy loss -0.005157449282705784\n",
      "\n",
      "episode 9, policy loss 0.03213881701231003\n",
      "\n",
      "episode 10, policy loss -0.04099185764789581\n",
      "\n",
      "episode 11, policy loss 0.0061969151720404625\n",
      "\n",
      "episode 12, policy loss -0.01328975334763527\n",
      "\n",
      "episode 13, policy loss -0.0048033930361270905\n",
      "\n",
      "episode 14, policy loss -0.0425698347389698\n",
      "\n",
      "episode 15, policy loss 0.016404276713728905\n",
      "\n",
      "episode 16, policy loss -0.07614512741565704\n",
      "\n",
      "Policy train loss in epoch 1:-0.010899751796387136\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.042129289358854294\n",
      "\n",
      "episode 2, policy loss -0.01288997009396553\n",
      "\n",
      "episode 3, policy loss 0.015690168365836143\n",
      "\n",
      "episode 4, policy loss -0.0305409524589777\n",
      "\n",
      "episode 5, policy loss 0.005886082071810961\n",
      "\n",
      "episode 6, policy loss 0.03117481991648674\n",
      "\n",
      "episode 7, policy loss 0.03958389535546303\n",
      "\n",
      "episode 8, policy loss -0.04176659882068634\n",
      "\n",
      "episode 9, policy loss 0.03328714519739151\n",
      "\n",
      "episode 10, policy loss -0.03856406733393669\n",
      "\n",
      "episode 11, policy loss -0.04392607510089874\n",
      "\n",
      "episode 12, policy loss -0.0071734413504600525\n",
      "\n",
      "episode 13, policy loss -0.015576999634504318\n",
      "\n",
      "episode 14, policy loss -0.07812747359275818\n",
      "\n",
      "episode 15, policy loss -0.004658302757889032\n",
      "\n",
      "episode 16, policy loss 0.0063986037857830524\n",
      "\n",
      "Policy train loss in epoch 2:-0.011458278488134965\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.04268456995487213\n",
      "\n",
      "episode 2, policy loss -0.015703609213232994\n",
      "\n",
      "episode 3, policy loss -0.01335338968783617\n",
      "\n",
      "episode 4, policy loss 0.03961008042097092\n",
      "\n",
      "episode 5, policy loss 0.0324305035173893\n",
      "\n",
      "episode 6, policy loss 0.004328285809606314\n",
      "\n",
      "episode 7, policy loss 0.01537112332880497\n",
      "\n",
      "episode 8, policy loss 0.030326133593916893\n",
      "\n",
      "episode 9, policy loss -0.005221100524067879\n",
      "\n",
      "episode 10, policy loss -0.042245008051395416\n",
      "\n",
      "episode 11, policy loss -0.043643053621053696\n",
      "\n",
      "episode 12, policy loss 0.005724336951971054\n",
      "\n",
      "episode 13, policy loss -0.03233013302087784\n",
      "\n",
      "episode 14, policy loss -0.03966126963496208\n",
      "\n",
      "episode 15, policy loss -0.007016930729150772\n",
      "\n",
      "episode 16, policy loss -0.07814410328865051\n",
      "\n",
      "Policy train loss in epoch 3:-0.012013294006465003\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1854100525379181\n",
      "\n",
      "episode 2, val func loss 0.17104697227478027\n",
      "\n",
      "episode 3, val func loss 0.21666599810123444\n",
      "\n",
      "episode 4, val func loss 0.16866278648376465\n",
      "\n",
      "episode 5, val func loss 0.19103923439979553\n",
      "\n",
      "episode 6, val func loss 0.21083618700504303\n",
      "\n",
      "episode 7, val func loss 0.18312259018421173\n",
      "\n",
      "episode 8, val func loss 0.19195133447647095\n",
      "\n",
      "episode 9, val func loss 0.1953859180212021\n",
      "\n",
      "episode 10, val func loss 0.17281219363212585\n",
      "\n",
      "episode 11, val func loss 0.20169523358345032\n",
      "\n",
      "episode 12, val func loss 0.20812545716762543\n",
      "\n",
      "episode 13, val func loss 0.16075439751148224\n",
      "\n",
      "episode 14, val func loss 0.19857457280158997\n",
      "\n",
      "episode 15, val func loss 0.18669427931308746\n",
      "\n",
      "episode 16, val func loss 0.17607153952121735\n",
      "\n",
      "Val func train loss in epoch 0:0.18867804668843746\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1956905871629715\n",
      "\n",
      "episode 2, val func loss 0.19942855834960938\n",
      "\n",
      "episode 3, val func loss 0.19103403389453888\n",
      "\n",
      "episode 4, val func loss 0.18637417256832123\n",
      "\n",
      "episode 5, val func loss 0.18469180166721344\n",
      "\n",
      "episode 6, val func loss 0.16819921135902405\n",
      "\n",
      "episode 7, val func loss 0.16947714984416962\n",
      "\n",
      "episode 8, val func loss 0.21824580430984497\n",
      "\n",
      "episode 9, val func loss 0.17257188260555267\n",
      "\n",
      "episode 10, val func loss 0.21053314208984375\n",
      "\n",
      "episode 11, val func loss 0.18262681365013123\n",
      "\n",
      "episode 12, val func loss 0.19269980490207672\n",
      "\n",
      "episode 13, val func loss 0.2079957127571106\n",
      "\n",
      "episode 14, val func loss 0.17592836916446686\n",
      "\n",
      "episode 15, val func loss 0.16080443561077118\n",
      "\n",
      "episode 16, val func loss 0.20186080038547516\n",
      "\n",
      "Val func train loss in epoch 1:0.18863514252007008\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.20810984075069427\n",
      "\n",
      "episode 2, val func loss 0.1752759963274002\n",
      "\n",
      "episode 3, val func loss 0.21039722859859467\n",
      "\n",
      "episode 4, val func loss 0.19156622886657715\n",
      "\n",
      "episode 5, val func loss 0.19203725457191467\n",
      "\n",
      "episode 6, val func loss 0.17263026535511017\n",
      "\n",
      "episode 7, val func loss 0.20122557878494263\n",
      "\n",
      "episode 8, val func loss 0.18495966494083405\n",
      "\n",
      "episode 9, val func loss 0.19579504430294037\n",
      "\n",
      "episode 10, val func loss 0.1979917734861374\n",
      "\n",
      "episode 11, val func loss 0.17044949531555176\n",
      "\n",
      "episode 12, val func loss 0.16925914585590363\n",
      "\n",
      "episode 13, val func loss 0.1868065595626831\n",
      "\n",
      "episode 14, val func loss 0.15966998040676117\n",
      "\n",
      "episode 15, val func loss 0.1830017864704132\n",
      "\n",
      "episode 16, val func loss 0.22540536522865295\n",
      "\n",
      "Val func train loss in epoch 2:0.18903632555156946\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.21320316195487976\n",
      "\n",
      "episode 2, val func loss 0.16553163528442383\n",
      "\n",
      "episode 3, val func loss 0.17311660945415497\n",
      "\n",
      "episode 4, val func loss 0.1755303293466568\n",
      "\n",
      "episode 5, val func loss 0.1826508641242981\n",
      "\n",
      "episode 6, val func loss 0.16040542721748352\n",
      "\n",
      "episode 7, val func loss 0.21831388771533966\n",
      "\n",
      "episode 8, val func loss 0.20121188461780548\n",
      "\n",
      "episode 9, val func loss 0.19218645989894867\n",
      "\n",
      "episode 10, val func loss 0.18689176440238953\n",
      "\n",
      "episode 11, val func loss 0.20800034701824188\n",
      "\n",
      "episode 12, val func loss 0.1980263888835907\n",
      "\n",
      "episode 13, val func loss 0.17126575112342834\n",
      "\n",
      "episode 14, val func loss 0.19055457413196564\n",
      "\n",
      "episode 15, val func loss 0.18496982753276825\n",
      "\n",
      "episode 16, val func loss 0.19556355476379395\n",
      "\n",
      "Val func train loss in epoch 3:0.18858890421688557\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.20179687440395355\n",
      "\n",
      "episode 2, val func loss 0.18304255604743958\n",
      "\n",
      "episode 3, val func loss 0.19912905991077423\n",
      "\n",
      "episode 4, val func loss 0.1691482961177826\n",
      "\n",
      "episode 5, val func loss 0.16712726652622223\n",
      "\n",
      "episode 6, val func loss 0.18664860725402832\n",
      "\n",
      "episode 7, val func loss 0.19486357271671295\n",
      "\n",
      "episode 8, val func loss 0.2204851657152176\n",
      "\n",
      "episode 9, val func loss 0.17272725701332092\n",
      "\n",
      "episode 10, val func loss 0.176636204123497\n",
      "\n",
      "episode 11, val func loss 0.19203849136829376\n",
      "\n",
      "episode 12, val func loss 0.16145457327365875\n",
      "\n",
      "episode 13, val func loss 0.21018940210342407\n",
      "\n",
      "episode 14, val func loss 0.1910925805568695\n",
      "\n",
      "episode 15, val func loss 0.1845463067293167\n",
      "\n",
      "episode 16, val func loss 0.2083260715007782\n",
      "\n",
      "Val func train loss in epoch 4:0.18870326783508062\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.16734221577644348\n",
      "\n",
      "episode 2, val func loss 0.17616111040115356\n",
      "\n",
      "episode 3, val func loss 0.18451397120952606\n",
      "\n",
      "episode 4, val func loss 0.18730168044567108\n",
      "\n",
      "episode 5, val func loss 0.2205916941165924\n",
      "\n",
      "episode 6, val func loss 0.18262597918510437\n",
      "\n",
      "episode 7, val func loss 0.20846255123615265\n",
      "\n",
      "episode 8, val func loss 0.19120587408542633\n",
      "\n",
      "episode 9, val func loss 0.19217538833618164\n",
      "\n",
      "episode 10, val func loss 0.1954859495162964\n",
      "\n",
      "episode 11, val func loss 0.19787999987602234\n",
      "\n",
      "episode 12, val func loss 0.2002171128988266\n",
      "\n",
      "episode 13, val func loss 0.16445036232471466\n",
      "\n",
      "episode 14, val func loss 0.1715822070837021\n",
      "\n",
      "episode 15, val func loss 0.17300935089588165\n",
      "\n",
      "episode 16, val func loss 0.2103664129972458\n",
      "\n",
      "Val func train loss in epoch 5:0.18896074127405882\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17576827108860016\n",
      "\n",
      "episode 2, val func loss 0.18712857365608215\n",
      "\n",
      "episode 3, val func loss 0.18263965845108032\n",
      "\n",
      "episode 4, val func loss 0.16770531237125397\n",
      "\n",
      "episode 5, val func loss 0.20998702943325043\n",
      "\n",
      "episode 6, val func loss 0.20358557999134064\n",
      "\n",
      "episode 7, val func loss 0.19218315184116364\n",
      "\n",
      "episode 8, val func loss 0.1947166472673416\n",
      "\n",
      "episode 9, val func loss 0.17287683486938477\n",
      "\n",
      "episode 10, val func loss 0.18530325591564178\n",
      "\n",
      "episode 11, val func loss 0.16297034919261932\n",
      "\n",
      "episode 12, val func loss 0.20986461639404297\n",
      "\n",
      "episode 13, val func loss 0.1981385350227356\n",
      "\n",
      "episode 14, val func loss 0.21652834117412567\n",
      "\n",
      "episode 15, val func loss 0.16839072108268738\n",
      "\n",
      "episode 16, val func loss 0.1920909881591797\n",
      "\n",
      "Val func train loss in epoch 6:0.18874236661940813\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.16964927315711975\n",
      "\n",
      "episode 2, val func loss 0.1949833184480667\n",
      "\n",
      "episode 3, val func loss 0.20137175917625427\n",
      "\n",
      "episode 4, val func loss 0.19165536761283875\n",
      "\n",
      "episode 5, val func loss 0.15950465202331543\n",
      "\n",
      "episode 6, val func loss 0.18276764452457428\n",
      "\n",
      "episode 7, val func loss 0.20858731865882874\n",
      "\n",
      "episode 8, val func loss 0.22031459212303162\n",
      "\n",
      "episode 9, val func loss 0.16649092733860016\n",
      "\n",
      "episode 10, val func loss 0.18703585863113403\n",
      "\n",
      "episode 11, val func loss 0.1841621845960617\n",
      "\n",
      "episode 12, val func loss 0.19216780364513397\n",
      "\n",
      "episode 13, val func loss 0.17613345384597778\n",
      "\n",
      "episode 14, val func loss 0.2099675089120865\n",
      "\n",
      "episode 15, val func loss 0.19900266826152802\n",
      "\n",
      "episode 16, val func loss 0.17256218194961548\n",
      "\n",
      "Val func train loss in epoch 7:0.18852228205651045\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1917431652545929\n",
      "\n",
      "episode 2, val func loss 0.1955636888742447\n",
      "\n",
      "episode 3, val func loss 0.20820485055446625\n",
      "\n",
      "episode 4, val func loss 0.17269502580165863\n",
      "\n",
      "episode 5, val func loss 0.16121938824653625\n",
      "\n",
      "episode 6, val func loss 0.16891111433506012\n",
      "\n",
      "episode 7, val func loss 0.219266876578331\n",
      "\n",
      "episode 8, val func loss 0.17518408596515656\n",
      "\n",
      "episode 9, val func loss 0.1999409943819046\n",
      "\n",
      "episode 10, val func loss 0.21076256036758423\n",
      "\n",
      "episode 11, val func loss 0.16685041785240173\n",
      "\n",
      "episode 12, val func loss 0.20157192647457123\n",
      "\n",
      "episode 13, val func loss 0.18645668029785156\n",
      "\n",
      "episode 14, val func loss 0.18461795151233673\n",
      "\n",
      "episode 15, val func loss 0.19108782708644867\n",
      "\n",
      "episode 16, val func loss 0.18325656652450562\n",
      "\n",
      "Val func train loss in epoch 8:0.18858332000672817\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17655795812606812\n",
      "\n",
      "episode 2, val func loss 0.19062507152557373\n",
      "\n",
      "episode 3, val func loss 0.19237373769283295\n",
      "\n",
      "episode 4, val func loss 0.19508466124534607\n",
      "\n",
      "episode 5, val func loss 0.21027332544326782\n",
      "\n",
      "episode 6, val func loss 0.18277716636657715\n",
      "\n",
      "episode 7, val func loss 0.16709575057029724\n",
      "\n",
      "episode 8, val func loss 0.15946656465530396\n",
      "\n",
      "episode 9, val func loss 0.1846131533384323\n",
      "\n",
      "episode 10, val func loss 0.20985835790634155\n",
      "\n",
      "episode 11, val func loss 0.16784179210662842\n",
      "\n",
      "episode 12, val func loss 0.2039809674024582\n",
      "\n",
      "episode 13, val func loss 0.18724748492240906\n",
      "\n",
      "episode 14, val func loss 0.17301791906356812\n",
      "\n",
      "episode 15, val func loss 0.21816855669021606\n",
      "\n",
      "episode 16, val func loss 0.19804127514362335\n",
      "\n",
      "Val func train loss in epoch 9:0.188563983887434\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18589051067829132\n",
      "\n",
      "episode 2, val func loss 0.1666441261768341\n",
      "\n",
      "episode 3, val func loss 0.2006726711988449\n",
      "\n",
      "episode 4, val func loss 0.1854562759399414\n",
      "\n",
      "episode 5, val func loss 0.1977376937866211\n",
      "\n",
      "episode 6, val func loss 0.19062818586826324\n",
      "\n",
      "episode 7, val func loss 0.17702266573905945\n",
      "\n",
      "episode 8, val func loss 0.2098698914051056\n",
      "\n",
      "episode 9, val func loss 0.19167262315750122\n",
      "\n",
      "episode 10, val func loss 0.2189687043428421\n",
      "\n",
      "episode 11, val func loss 0.1950025111436844\n",
      "\n",
      "episode 12, val func loss 0.17264659702777863\n",
      "\n",
      "episode 13, val func loss 0.1676684319972992\n",
      "\n",
      "episode 14, val func loss 0.1865808665752411\n",
      "\n",
      "episode 15, val func loss 0.20801813900470734\n",
      "\n",
      "episode 16, val func loss 0.16883216798305511\n",
      "\n",
      "Val func train loss in epoch 10:0.1889570038765669\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19476318359375\n",
      "\n",
      "episode 2, val func loss 0.19170647859573364\n",
      "\n",
      "episode 3, val func loss 0.16667123138904572\n",
      "\n",
      "episode 4, val func loss 0.20222322642803192\n",
      "\n",
      "episode 5, val func loss 0.1681784838438034\n",
      "\n",
      "episode 6, val func loss 0.21927346289157867\n",
      "\n",
      "episode 7, val func loss 0.17572477459907532\n",
      "\n",
      "episode 8, val func loss 0.16067810356616974\n",
      "\n",
      "episode 9, val func loss 0.18685662746429443\n",
      "\n",
      "episode 10, val func loss 0.18391431868076324\n",
      "\n",
      "episode 11, val func loss 0.20816121995449066\n",
      "\n",
      "episode 12, val func loss 0.19193635880947113\n",
      "\n",
      "episode 13, val func loss 0.1987069845199585\n",
      "\n",
      "episode 14, val func loss 0.1827917993068695\n",
      "\n",
      "episode 15, val func loss 0.1726093590259552\n",
      "\n",
      "episode 16, val func loss 0.21022002398967743\n",
      "\n",
      "Val func train loss in epoch 11:0.18840097729116678\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.16934457421302795\n",
      "\n",
      "episode 2, val func loss 0.21705254912376404\n",
      "\n",
      "episode 3, val func loss 0.18471208214759827\n",
      "\n",
      "episode 4, val func loss 0.16183879971504211\n",
      "\n",
      "episode 5, val func loss 0.19534321129322052\n",
      "\n",
      "episode 6, val func loss 0.1829986423254013\n",
      "\n",
      "episode 7, val func loss 0.1725744605064392\n",
      "\n",
      "episode 8, val func loss 0.1661176234483719\n",
      "\n",
      "episode 9, val func loss 0.20304423570632935\n",
      "\n",
      "episode 10, val func loss 0.20117603242397308\n",
      "\n",
      "episode 11, val func loss 0.18725579977035522\n",
      "\n",
      "episode 12, val func loss 0.21062196791172028\n",
      "\n",
      "episode 13, val func loss 0.19073118269443512\n",
      "\n",
      "episode 14, val func loss 0.17689251899719238\n",
      "\n",
      "episode 15, val func loss 0.19257497787475586\n",
      "\n",
      "episode 16, val func loss 0.2082665115594864\n",
      "\n",
      "Val func train loss in epoch 12:0.18878407310694456\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1839991956949234\n",
      "\n",
      "episode 2, val func loss 0.18467459082603455\n",
      "\n",
      "episode 3, val func loss 0.17280952632427216\n",
      "\n",
      "episode 4, val func loss 0.16742636263370514\n",
      "\n",
      "episode 5, val func loss 0.16831523180007935\n",
      "\n",
      "episode 6, val func loss 0.19515196979045868\n",
      "\n",
      "episode 7, val func loss 0.2123456448316574\n",
      "\n",
      "episode 8, val func loss 0.1877150982618332\n",
      "\n",
      "episode 9, val func loss 0.1933177262544632\n",
      "\n",
      "episode 10, val func loss 0.19230856001377106\n",
      "\n",
      "episode 11, val func loss 0.17586103081703186\n",
      "\n",
      "episode 12, val func loss 0.20796430110931396\n",
      "\n",
      "episode 13, val func loss 0.19854231178760529\n",
      "\n",
      "episode 14, val func loss 0.20082175731658936\n",
      "\n",
      "episode 15, val func loss 0.21420715749263763\n",
      "\n",
      "episode 16, val func loss 0.1714501827955246\n",
      "\n",
      "Val func train loss in epoch 13:0.1891819154843688\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1678033471107483\n",
      "\n",
      "episode 2, val func loss 0.20803986489772797\n",
      "\n",
      "episode 3, val func loss 0.18683454394340515\n",
      "\n",
      "episode 4, val func loss 0.16653111577033997\n",
      "\n",
      "episode 5, val func loss 0.20237313210964203\n",
      "\n",
      "episode 6, val func loss 0.19378173351287842\n",
      "\n",
      "episode 7, val func loss 0.17475847899913788\n",
      "\n",
      "episode 8, val func loss 0.19590552151203156\n",
      "\n",
      "episode 9, val func loss 0.17497804760932922\n",
      "\n",
      "episode 10, val func loss 0.18441489338874817\n",
      "\n",
      "episode 11, val func loss 0.21723943948745728\n",
      "\n",
      "episode 12, val func loss 0.19043448567390442\n",
      "\n",
      "episode 13, val func loss 0.1880733221769333\n",
      "\n",
      "episode 14, val func loss 0.2012672871351242\n",
      "\n",
      "episode 15, val func loss 0.17241941392421722\n",
      "\n",
      "episode 16, val func loss 0.21010378003120422\n",
      "\n",
      "Val func train loss in epoch 14:0.18968490045517683\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20160023868083954\n",
      "\n",
      "episode 2, val func loss 0.15947970747947693\n",
      "\n",
      "episode 3, val func loss 0.2088126689195633\n",
      "\n",
      "episode 4, val func loss 0.2009262889623642\n",
      "\n",
      "episode 5, val func loss 0.16577860713005066\n",
      "\n",
      "episode 6, val func loss 0.18706417083740234\n",
      "\n",
      "episode 7, val func loss 0.17550978064537048\n",
      "\n",
      "episode 8, val func loss 0.21116895973682404\n",
      "\n",
      "episode 9, val func loss 0.1683037281036377\n",
      "\n",
      "episode 10, val func loss 0.17272241413593292\n",
      "\n",
      "episode 11, val func loss 0.18467435240745544\n",
      "\n",
      "episode 12, val func loss 0.21811671555042267\n",
      "\n",
      "episode 13, val func loss 0.19164042174816132\n",
      "\n",
      "episode 14, val func loss 0.183832049369812\n",
      "\n",
      "episode 15, val func loss 0.1901213377714157\n",
      "\n",
      "episode 16, val func loss 0.19608506560325623\n",
      "\n",
      "Val func train loss in epoch 15:0.1884897816926241\n",
      "***********************TIME WAS 4.967708837985993 min*****************************\n",
      "\n",
      "**********************ROUND 84 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.013442104682326317\n",
      "\n",
      "episode 2, policy loss 0.014062258414924145\n",
      "\n",
      "episode 3, policy loss -0.008954411372542381\n",
      "\n",
      "episode 4, policy loss -0.03356786444783211\n",
      "\n",
      "episode 5, policy loss -0.03306436911225319\n",
      "\n",
      "episode 6, policy loss -0.0391128771007061\n",
      "\n",
      "episode 7, policy loss -0.016562577337026596\n",
      "\n",
      "episode 8, policy loss 0.00835988949984312\n",
      "\n",
      "episode 9, policy loss 0.03702297434210777\n",
      "\n",
      "episode 10, policy loss -0.01368872169405222\n",
      "\n",
      "episode 11, policy loss -0.063472680747509\n",
      "\n",
      "episode 12, policy loss -0.04693172499537468\n",
      "\n",
      "episode 13, policy loss 0.004050608724355698\n",
      "\n",
      "episode 14, policy loss 0.0032714763656258583\n",
      "\n",
      "episode 15, policy loss -0.008535496890544891\n",
      "\n",
      "episode 16, policy loss -0.0648268535733223\n",
      "\n",
      "Policy train loss in epoch 0:-0.017212029662914574\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.002749257255345583\n",
      "\n",
      "episode 2, policy loss -0.04728960990905762\n",
      "\n",
      "episode 3, policy loss -0.033995404839515686\n",
      "\n",
      "episode 4, policy loss -0.03849709779024124\n",
      "\n",
      "episode 5, policy loss 0.03417358919978142\n",
      "\n",
      "episode 6, policy loss 0.004698492120951414\n",
      "\n",
      "episode 7, policy loss -0.021669985726475716\n",
      "\n",
      "episode 8, policy loss 0.011946696788072586\n",
      "\n",
      "episode 9, policy loss -0.01698862574994564\n",
      "\n",
      "episode 10, policy loss -0.06411983072757721\n",
      "\n",
      "episode 11, policy loss -0.06368981301784515\n",
      "\n",
      "episode 12, policy loss -0.006760548800230026\n",
      "\n",
      "episode 13, policy loss -0.03223983570933342\n",
      "\n",
      "episode 14, policy loss 0.007637835573405027\n",
      "\n",
      "episode 15, policy loss -0.00998478103429079\n",
      "\n",
      "episode 16, policy loss -0.015993697568774223\n",
      "\n",
      "Policy train loss in epoch 1:-0.01812645999598317\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.011458436027169228\n",
      "\n",
      "episode 2, policy loss -0.00581321120262146\n",
      "\n",
      "episode 3, policy loss -0.01618007943034172\n",
      "\n",
      "episode 4, policy loss -0.06467223912477493\n",
      "\n",
      "episode 5, policy loss 0.007323050871491432\n",
      "\n",
      "episode 6, policy loss 0.0019140038639307022\n",
      "\n",
      "episode 7, policy loss 0.005692170932888985\n",
      "\n",
      "episode 8, policy loss 0.03570912405848503\n",
      "\n",
      "episode 9, policy loss -0.0386282317340374\n",
      "\n",
      "episode 10, policy loss -0.04797196015715599\n",
      "\n",
      "episode 11, policy loss -0.03269485384225845\n",
      "\n",
      "episode 12, policy loss -0.022400211542844772\n",
      "\n",
      "episode 13, policy loss -0.06664956361055374\n",
      "\n",
      "episode 14, policy loss -0.017103329300880432\n",
      "\n",
      "episode 15, policy loss -0.03499278053641319\n",
      "\n",
      "episode 16, policy loss -0.01116752065718174\n",
      "\n",
      "Policy train loss in epoch 2:-0.018511074711568654\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.020574361085891724\n",
      "\n",
      "episode 2, policy loss -0.06508320569992065\n",
      "\n",
      "episode 3, policy loss -0.016987236216664314\n",
      "\n",
      "episode 4, policy loss 0.011255213990807533\n",
      "\n",
      "episode 5, policy loss 0.03468741476535797\n",
      "\n",
      "episode 6, policy loss -0.019066615030169487\n",
      "\n",
      "episode 7, policy loss -0.06644328683614731\n",
      "\n",
      "episode 8, policy loss 0.004443905781954527\n",
      "\n",
      "episode 9, policy loss 0.006318530533462763\n",
      "\n",
      "episode 10, policy loss -0.008390199393033981\n",
      "\n",
      "episode 11, policy loss 0.004208945669233799\n",
      "\n",
      "episode 12, policy loss -0.03393740579485893\n",
      "\n",
      "episode 13, policy loss -0.03290688246488571\n",
      "\n",
      "episode 14, policy loss -0.04743711277842522\n",
      "\n",
      "episode 15, policy loss -0.038683727383613586\n",
      "\n",
      "episode 16, policy loss -0.009892861358821392\n",
      "\n",
      "Policy train loss in epoch 3:-0.018655555206350982\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17576077580451965\n",
      "\n",
      "episode 2, val func loss 0.1969180703163147\n",
      "\n",
      "episode 3, val func loss 0.1885242462158203\n",
      "\n",
      "episode 4, val func loss 0.16494399309158325\n",
      "\n",
      "episode 5, val func loss 0.1797817498445511\n",
      "\n",
      "episode 6, val func loss 0.16574330627918243\n",
      "\n",
      "episode 7, val func loss 0.207044318318367\n",
      "\n",
      "episode 8, val func loss 0.18837477266788483\n",
      "\n",
      "episode 9, val func loss 0.21470427513122559\n",
      "\n",
      "episode 10, val func loss 0.19875073432922363\n",
      "\n",
      "episode 11, val func loss 0.18498516082763672\n",
      "\n",
      "episode 12, val func loss 0.19163808226585388\n",
      "\n",
      "episode 13, val func loss 0.21750620007514954\n",
      "\n",
      "episode 14, val func loss 0.19932419061660767\n",
      "\n",
      "episode 15, val func loss 0.18504486978054047\n",
      "\n",
      "episode 16, val func loss 0.2115589678287506\n",
      "\n",
      "Val func train loss in epoch 0:0.1919127320870757\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18918746709823608\n",
      "\n",
      "episode 2, val func loss 0.20914502441883087\n",
      "\n",
      "episode 3, val func loss 0.16726377606391907\n",
      "\n",
      "episode 4, val func loss 0.18677076697349548\n",
      "\n",
      "episode 5, val func loss 0.1982738971710205\n",
      "\n",
      "episode 6, val func loss 0.21782316267490387\n",
      "\n",
      "episode 7, val func loss 0.21208888292312622\n",
      "\n",
      "episode 8, val func loss 0.1880866140127182\n",
      "\n",
      "episode 9, val func loss 0.16643185913562775\n",
      "\n",
      "episode 10, val func loss 0.19837920367717743\n",
      "\n",
      "episode 11, val func loss 0.19282123446464539\n",
      "\n",
      "episode 12, val func loss 0.17940367758274078\n",
      "\n",
      "episode 13, val func loss 0.1739339381456375\n",
      "\n",
      "episode 14, val func loss 0.2062353640794754\n",
      "\n",
      "episode 15, val func loss 0.19778741896152496\n",
      "\n",
      "episode 16, val func loss 0.18495060503482819\n",
      "\n",
      "Val func train loss in epoch 1:0.19178643077611923\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18882453441619873\n",
      "\n",
      "episode 2, val func loss 0.18047261238098145\n",
      "\n",
      "episode 3, val func loss 0.21776336431503296\n",
      "\n",
      "episode 4, val func loss 0.18476004898548126\n",
      "\n",
      "episode 5, val func loss 0.18774253129959106\n",
      "\n",
      "episode 6, val func loss 0.18649138510227203\n",
      "\n",
      "episode 7, val func loss 0.2100144326686859\n",
      "\n",
      "episode 8, val func loss 0.17524829506874084\n",
      "\n",
      "episode 9, val func loss 0.21111446619033813\n",
      "\n",
      "episode 10, val func loss 0.16797517240047455\n",
      "\n",
      "episode 11, val func loss 0.1646428108215332\n",
      "\n",
      "episode 12, val func loss 0.205549955368042\n",
      "\n",
      "episode 13, val func loss 0.19834381341934204\n",
      "\n",
      "episode 14, val func loss 0.19840744137763977\n",
      "\n",
      "episode 15, val func loss 0.19303716719150543\n",
      "\n",
      "episode 16, val func loss 0.19722416996955872\n",
      "\n",
      "Val func train loss in epoch 2:0.19172576256096363\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1971202939748764\n",
      "\n",
      "episode 2, val func loss 0.18889696896076202\n",
      "\n",
      "episode 3, val func loss 0.1805712729692459\n",
      "\n",
      "episode 4, val func loss 0.19896988570690155\n",
      "\n",
      "episode 5, val func loss 0.20476718246936798\n",
      "\n",
      "episode 6, val func loss 0.1655554175376892\n",
      "\n",
      "episode 7, val func loss 0.21056008338928223\n",
      "\n",
      "episode 8, val func loss 0.18580351769924164\n",
      "\n",
      "episode 9, val func loss 0.1678062081336975\n",
      "\n",
      "episode 10, val func loss 0.18749801814556122\n",
      "\n",
      "episode 11, val func loss 0.19200566411018372\n",
      "\n",
      "episode 12, val func loss 0.21292787790298462\n",
      "\n",
      "episode 13, val func loss 0.1985628753900528\n",
      "\n",
      "episode 14, val func loss 0.1740378886461258\n",
      "\n",
      "episode 15, val func loss 0.21864467859268188\n",
      "\n",
      "episode 16, val func loss 0.18461152911186218\n",
      "\n",
      "Val func train loss in epoch 3:0.1917712101712823\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17460913956165314\n",
      "\n",
      "episode 2, val func loss 0.18733319640159607\n",
      "\n",
      "episode 3, val func loss 0.1985236257314682\n",
      "\n",
      "episode 4, val func loss 0.18443116545677185\n",
      "\n",
      "episode 5, val func loss 0.167804554104805\n",
      "\n",
      "episode 6, val func loss 0.19878806173801422\n",
      "\n",
      "episode 7, val func loss 0.1794997900724411\n",
      "\n",
      "episode 8, val func loss 0.19739478826522827\n",
      "\n",
      "episode 9, val func loss 0.2203647792339325\n",
      "\n",
      "episode 10, val func loss 0.1847812384366989\n",
      "\n",
      "episode 11, val func loss 0.20633293688297272\n",
      "\n",
      "episode 12, val func loss 0.19219247996807098\n",
      "\n",
      "episode 13, val func loss 0.18842917680740356\n",
      "\n",
      "episode 14, val func loss 0.16541394591331482\n",
      "\n",
      "episode 15, val func loss 0.21067744493484497\n",
      "\n",
      "episode 16, val func loss 0.20957745611667633\n",
      "\n",
      "Val func train loss in epoch 4:0.1916346112266183\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18209515511989594\n",
      "\n",
      "episode 2, val func loss 0.16766759753227234\n",
      "\n",
      "episode 3, val func loss 0.19985711574554443\n",
      "\n",
      "episode 4, val func loss 0.21787959337234497\n",
      "\n",
      "episode 5, val func loss 0.16871050000190735\n",
      "\n",
      "episode 6, val func loss 0.1968870759010315\n",
      "\n",
      "episode 7, val func loss 0.184785395860672\n",
      "\n",
      "episode 8, val func loss 0.1988133043050766\n",
      "\n",
      "episode 9, val func loss 0.21420185267925262\n",
      "\n",
      "episode 10, val func loss 0.18470408022403717\n",
      "\n",
      "episode 11, val func loss 0.21351981163024902\n",
      "\n",
      "episode 12, val func loss 0.18760691583156586\n",
      "\n",
      "episode 13, val func loss 0.17437681555747986\n",
      "\n",
      "episode 14, val func loss 0.2051064521074295\n",
      "\n",
      "episode 15, val func loss 0.18908993899822235\n",
      "\n",
      "episode 16, val func loss 0.1908774971961975\n",
      "\n",
      "Val func train loss in epoch 5:0.1922611938789487\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.20005564391613007\n",
      "\n",
      "episode 2, val func loss 0.2097410410642624\n",
      "\n",
      "episode 3, val func loss 0.1704082041978836\n",
      "\n",
      "episode 4, val func loss 0.19861598312854767\n",
      "\n",
      "episode 5, val func loss 0.18450075387954712\n",
      "\n",
      "episode 6, val func loss 0.21189317107200623\n",
      "\n",
      "episode 7, val func loss 0.17965149879455566\n",
      "\n",
      "episode 8, val func loss 0.2188560515642166\n",
      "\n",
      "episode 9, val func loss 0.18786513805389404\n",
      "\n",
      "episode 10, val func loss 0.19220061600208282\n",
      "\n",
      "episode 11, val func loss 0.16430987417697906\n",
      "\n",
      "episode 12, val func loss 0.1744520366191864\n",
      "\n",
      "episode 13, val func loss 0.18521277606487274\n",
      "\n",
      "episode 14, val func loss 0.20555542409420013\n",
      "\n",
      "episode 15, val func loss 0.19691957533359528\n",
      "\n",
      "episode 16, val func loss 0.18881851434707642\n",
      "\n",
      "Val func train loss in epoch 6:0.19181601889431477\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1797092854976654\n",
      "\n",
      "episode 2, val func loss 0.21149730682373047\n",
      "\n",
      "episode 3, val func loss 0.18541303277015686\n",
      "\n",
      "episode 4, val func loss 0.16490133106708527\n",
      "\n",
      "episode 5, val func loss 0.20509470999240875\n",
      "\n",
      "episode 6, val func loss 0.21116524934768677\n",
      "\n",
      "episode 7, val func loss 0.18870176374912262\n",
      "\n",
      "episode 8, val func loss 0.1982852667570114\n",
      "\n",
      "episode 9, val func loss 0.19097058475017548\n",
      "\n",
      "episode 10, val func loss 0.16960832476615906\n",
      "\n",
      "episode 11, val func loss 0.21769855916500092\n",
      "\n",
      "episode 12, val func loss 0.19870920479297638\n",
      "\n",
      "episode 13, val func loss 0.17443670332431793\n",
      "\n",
      "episode 14, val func loss 0.18430954217910767\n",
      "\n",
      "episode 15, val func loss 0.18805354833602905\n",
      "\n",
      "episode 16, val func loss 0.19698680937290192\n",
      "\n",
      "Val func train loss in epoch 7:0.191596326418221\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1971973031759262\n",
      "\n",
      "episode 2, val func loss 0.18791939318180084\n",
      "\n",
      "episode 3, val func loss 0.17432741820812225\n",
      "\n",
      "episode 4, val func loss 0.16597504913806915\n",
      "\n",
      "episode 5, val func loss 0.1851082295179367\n",
      "\n",
      "episode 6, val func loss 0.21263885498046875\n",
      "\n",
      "episode 7, val func loss 0.17976166307926178\n",
      "\n",
      "episode 8, val func loss 0.2053198218345642\n",
      "\n",
      "episode 9, val func loss 0.18866845965385437\n",
      "\n",
      "episode 10, val func loss 0.2114400416612625\n",
      "\n",
      "episode 11, val func loss 0.19936572015285492\n",
      "\n",
      "episode 12, val func loss 0.1908147633075714\n",
      "\n",
      "episode 13, val func loss 0.21712738275527954\n",
      "\n",
      "episode 14, val func loss 0.18711142241954803\n",
      "\n",
      "episode 15, val func loss 0.16610413789749146\n",
      "\n",
      "episode 16, val func loss 0.19815421104431152\n",
      "\n",
      "Val func train loss in epoch 8:0.19168961700052023\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18783517181873322\n",
      "\n",
      "episode 2, val func loss 0.20547282695770264\n",
      "\n",
      "episode 3, val func loss 0.21280743181705475\n",
      "\n",
      "episode 4, val func loss 0.19840052723884583\n",
      "\n",
      "episode 5, val func loss 0.19841967523097992\n",
      "\n",
      "episode 6, val func loss 0.17967890202999115\n",
      "\n",
      "episode 7, val func loss 0.1848638653755188\n",
      "\n",
      "episode 8, val func loss 0.2122015357017517\n",
      "\n",
      "episode 9, val func loss 0.184369757771492\n",
      "\n",
      "episode 10, val func loss 0.1973084956407547\n",
      "\n",
      "episode 11, val func loss 0.16487587988376617\n",
      "\n",
      "episode 12, val func loss 0.19117486476898193\n",
      "\n",
      "episode 13, val func loss 0.17504721879959106\n",
      "\n",
      "episode 14, val func loss 0.21738409996032715\n",
      "\n",
      "episode 15, val func loss 0.18868423998355865\n",
      "\n",
      "episode 16, val func loss 0.16855058073997498\n",
      "\n",
      "Val func train loss in epoch 9:0.19169219210743904\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.21096663177013397\n",
      "\n",
      "episode 2, val func loss 0.18536809086799622\n",
      "\n",
      "episode 3, val func loss 0.19822640717029572\n",
      "\n",
      "episode 4, val func loss 0.18889464437961578\n",
      "\n",
      "episode 5, val func loss 0.16435258090496063\n",
      "\n",
      "episode 6, val func loss 0.17983436584472656\n",
      "\n",
      "episode 7, val func loss 0.19269831478595734\n",
      "\n",
      "episode 8, val func loss 0.18767566978931427\n",
      "\n",
      "episode 9, val func loss 0.21249175071716309\n",
      "\n",
      "episode 10, val func loss 0.16800951957702637\n",
      "\n",
      "episode 11, val func loss 0.2047692835330963\n",
      "\n",
      "episode 12, val func loss 0.21833984553813934\n",
      "\n",
      "episode 13, val func loss 0.19864077866077423\n",
      "\n",
      "episode 14, val func loss 0.1747501790523529\n",
      "\n",
      "episode 15, val func loss 0.18444150686264038\n",
      "\n",
      "episode 16, val func loss 0.1968083381652832\n",
      "\n",
      "Val func train loss in epoch 10:0.19164174422621727\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.20484641194343567\n",
      "\n",
      "episode 2, val func loss 0.1648295819759369\n",
      "\n",
      "episode 3, val func loss 0.2122131884098053\n",
      "\n",
      "episode 4, val func loss 0.16706648468971252\n",
      "\n",
      "episode 5, val func loss 0.17977730929851532\n",
      "\n",
      "episode 6, val func loss 0.18458393216133118\n",
      "\n",
      "episode 7, val func loss 0.19724585115909576\n",
      "\n",
      "episode 8, val func loss 0.19836902618408203\n",
      "\n",
      "episode 9, val func loss 0.184759721159935\n",
      "\n",
      "episode 10, val func loss 0.19864754378795624\n",
      "\n",
      "episode 11, val func loss 0.18914858996868134\n",
      "\n",
      "episode 12, val func loss 0.21183361113071442\n",
      "\n",
      "episode 13, val func loss 0.1750367283821106\n",
      "\n",
      "episode 14, val func loss 0.1880611777305603\n",
      "\n",
      "episode 15, val func loss 0.190857395529747\n",
      "\n",
      "episode 16, val func loss 0.21757648885250092\n",
      "\n",
      "Val func train loss in epoch 11:0.19155331514775753\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17620688676834106\n",
      "\n",
      "episode 2, val func loss 0.19852058589458466\n",
      "\n",
      "episode 3, val func loss 0.18457670509815216\n",
      "\n",
      "episode 4, val func loss 0.18574538826942444\n",
      "\n",
      "episode 5, val func loss 0.21182818710803986\n",
      "\n",
      "episode 6, val func loss 0.21237659454345703\n",
      "\n",
      "episode 7, val func loss 0.1916310340166092\n",
      "\n",
      "episode 8, val func loss 0.19853384792804718\n",
      "\n",
      "episode 9, val func loss 0.16838951408863068\n",
      "\n",
      "episode 10, val func loss 0.16526241600513458\n",
      "\n",
      "episode 11, val func loss 0.18011432886123657\n",
      "\n",
      "episode 12, val func loss 0.21930748224258423\n",
      "\n",
      "episode 13, val func loss 0.1893770843744278\n",
      "\n",
      "episode 14, val func loss 0.19720761477947235\n",
      "\n",
      "episode 15, val func loss 0.20560871064662933\n",
      "\n",
      "episode 16, val func loss 0.1877695769071579\n",
      "\n",
      "Val func train loss in epoch 12:0.19202849734574556\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19103842973709106\n",
      "\n",
      "episode 2, val func loss 0.17128853499889374\n",
      "\n",
      "episode 3, val func loss 0.21105633676052094\n",
      "\n",
      "episode 4, val func loss 0.18021419644355774\n",
      "\n",
      "episode 5, val func loss 0.18484920263290405\n",
      "\n",
      "episode 6, val func loss 0.21902188658714294\n",
      "\n",
      "episode 7, val func loss 0.16402693092823029\n",
      "\n",
      "episode 8, val func loss 0.18488755822181702\n",
      "\n",
      "episode 9, val func loss 0.19815458357334137\n",
      "\n",
      "episode 10, val func loss 0.19841057062149048\n",
      "\n",
      "episode 11, val func loss 0.18876436352729797\n",
      "\n",
      "episode 12, val func loss 0.20463894307613373\n",
      "\n",
      "episode 13, val func loss 0.1965813934803009\n",
      "\n",
      "episode 14, val func loss 0.18832631409168243\n",
      "\n",
      "episode 15, val func loss 0.17503918707370758\n",
      "\n",
      "episode 16, val func loss 0.21092179417610168\n",
      "\n",
      "Val func train loss in epoch 13:0.19170126412063837\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18776774406433105\n",
      "\n",
      "episode 2, val func loss 0.17460621893405914\n",
      "\n",
      "episode 3, val func loss 0.18457627296447754\n",
      "\n",
      "episode 4, val func loss 0.2117805778980255\n",
      "\n",
      "episode 5, val func loss 0.19113993644714355\n",
      "\n",
      "episode 6, val func loss 0.18104471266269684\n",
      "\n",
      "episode 7, val func loss 0.21140193939208984\n",
      "\n",
      "episode 8, val func loss 0.18643999099731445\n",
      "\n",
      "episode 9, val func loss 0.1983603984117508\n",
      "\n",
      "episode 10, val func loss 0.16838929057121277\n",
      "\n",
      "episode 11, val func loss 0.1644245982170105\n",
      "\n",
      "episode 12, val func loss 0.21930824220180511\n",
      "\n",
      "episode 13, val func loss 0.2063961923122406\n",
      "\n",
      "episode 14, val func loss 0.19839705526828766\n",
      "\n",
      "episode 15, val func loss 0.19706639647483826\n",
      "\n",
      "episode 16, val func loss 0.18912991881370544\n",
      "\n",
      "Val func train loss in epoch 14:0.19188934285193682\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1743149757385254\n",
      "\n",
      "episode 2, val func loss 0.1799824833869934\n",
      "\n",
      "episode 3, val func loss 0.18877780437469482\n",
      "\n",
      "episode 4, val func loss 0.1842663586139679\n",
      "\n",
      "episode 5, val func loss 0.18535248935222626\n",
      "\n",
      "episode 6, val func loss 0.16734875738620758\n",
      "\n",
      "episode 7, val func loss 0.16419623792171478\n",
      "\n",
      "episode 8, val func loss 0.20627735555171967\n",
      "\n",
      "episode 9, val func loss 0.21377675235271454\n",
      "\n",
      "episode 10, val func loss 0.1881110966205597\n",
      "\n",
      "episode 11, val func loss 0.19213886559009552\n",
      "\n",
      "episode 12, val func loss 0.19690082967281342\n",
      "\n",
      "episode 13, val func loss 0.19953610002994537\n",
      "\n",
      "episode 14, val func loss 0.2174278348684311\n",
      "\n",
      "episode 15, val func loss 0.20983032882213593\n",
      "\n",
      "episode 16, val func loss 0.19914095103740692\n",
      "\n",
      "Val func train loss in epoch 15:0.19171120133250952\n",
      "***********************TIME WAS 4.96431698401769 min*****************************\n",
      "\n",
      "**********************ROUND 85 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.05058752000331879\n",
      "\n",
      "episode 2, policy loss 0.004562011919915676\n",
      "\n",
      "episode 3, policy loss -0.04142455756664276\n",
      "\n",
      "episode 4, policy loss 0.041809484362602234\n",
      "\n",
      "episode 5, policy loss -0.0072358096949756145\n",
      "\n",
      "episode 6, policy loss -0.019339509308338165\n",
      "\n",
      "episode 7, policy loss -0.0010594406630843878\n",
      "\n",
      "episode 8, policy loss -0.05877881124615669\n",
      "\n",
      "episode 9, policy loss 0.004933485761284828\n",
      "\n",
      "episode 10, policy loss -0.028799884021282196\n",
      "\n",
      "episode 11, policy loss -0.006580966990441084\n",
      "\n",
      "episode 12, policy loss 0.021967237815260887\n",
      "\n",
      "episode 13, policy loss -0.034341517835855484\n",
      "\n",
      "episode 14, policy loss -0.06732465326786041\n",
      "\n",
      "episode 15, policy loss -0.0017680900637060404\n",
      "\n",
      "episode 16, policy loss -0.03183374181389809\n",
      "\n",
      "Policy train loss in epoch 0:-0.010914202663116157\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.005152286496013403\n",
      "\n",
      "episode 2, policy loss -0.019851040095090866\n",
      "\n",
      "episode 3, policy loss -0.030550353229045868\n",
      "\n",
      "episode 4, policy loss -0.0011133317602798343\n",
      "\n",
      "episode 5, policy loss -0.008629708550870419\n",
      "\n",
      "episode 6, policy loss 0.03773825615644455\n",
      "\n",
      "episode 7, policy loss -0.008653129450976849\n",
      "\n",
      "episode 8, policy loss -0.06882745027542114\n",
      "\n",
      "episode 9, policy loss -0.03405241295695305\n",
      "\n",
      "episode 10, policy loss 0.0030180392786860466\n",
      "\n",
      "episode 11, policy loss -0.059737976640462875\n",
      "\n",
      "episode 12, policy loss 0.01917068101465702\n",
      "\n",
      "episode 13, policy loss -0.046981725841760635\n",
      "\n",
      "episode 14, policy loss -0.035840630531311035\n",
      "\n",
      "episode 15, policy loss -0.001769687863998115\n",
      "\n",
      "episode 16, policy loss 0.04050709679722786\n",
      "\n",
      "Policy train loss in epoch 1:-0.013795353777823038\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.0029806361999362707\n",
      "\n",
      "episode 2, policy loss -0.02068621851503849\n",
      "\n",
      "episode 3, policy loss -0.008725238032639027\n",
      "\n",
      "episode 4, policy loss 0.041365087032318115\n",
      "\n",
      "episode 5, policy loss -0.0014239667216315866\n",
      "\n",
      "episode 6, policy loss -0.031751424074172974\n",
      "\n",
      "episode 7, policy loss -0.07069851458072662\n",
      "\n",
      "episode 8, policy loss -0.03452074155211449\n",
      "\n",
      "episode 9, policy loss 0.0027060804422944784\n",
      "\n",
      "episode 10, policy loss -0.03688604384660721\n",
      "\n",
      "episode 11, policy loss 0.019244849681854248\n",
      "\n",
      "episode 12, policy loss -0.005949478130787611\n",
      "\n",
      "episode 13, policy loss -0.04641959071159363\n",
      "\n",
      "episode 14, policy loss 0.03666325658559799\n",
      "\n",
      "episode 15, policy loss -0.009868666529655457\n",
      "\n",
      "episode 16, policy loss -0.06167629361152649\n",
      "\n",
      "Policy train loss in epoch 2:-0.014475471172772814\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.036834098398685455\n",
      "\n",
      "episode 2, policy loss 0.003257429925724864\n",
      "\n",
      "episode 3, policy loss 0.019594842568039894\n",
      "\n",
      "episode 4, policy loss -0.036924343556165695\n",
      "\n",
      "episode 5, policy loss -0.0017988410545513034\n",
      "\n",
      "episode 6, policy loss -0.003024918958544731\n",
      "\n",
      "episode 7, policy loss -0.03391481935977936\n",
      "\n",
      "episode 8, policy loss -0.01953352428972721\n",
      "\n",
      "episode 9, policy loss 0.04187692329287529\n",
      "\n",
      "episode 10, policy loss -0.005208836402744055\n",
      "\n",
      "episode 11, policy loss -0.047155722975730896\n",
      "\n",
      "episode 12, policy loss -0.03062126226723194\n",
      "\n",
      "episode 13, policy loss -0.006451971363276243\n",
      "\n",
      "episode 14, policy loss -0.0696883425116539\n",
      "\n",
      "episode 15, policy loss -0.05980802699923515\n",
      "\n",
      "episode 16, policy loss -0.008693883195519447\n",
      "\n",
      "Policy train loss in epoch 3:-0.013828824921802152\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1806405931711197\n",
      "\n",
      "episode 2, val func loss 0.212989941239357\n",
      "\n",
      "episode 3, val func loss 0.1558387577533722\n",
      "\n",
      "episode 4, val func loss 0.2098160684108734\n",
      "\n",
      "episode 5, val func loss 0.20476283133029938\n",
      "\n",
      "episode 6, val func loss 0.16720688343048096\n",
      "\n",
      "episode 7, val func loss 0.18829689919948578\n",
      "\n",
      "episode 8, val func loss 0.1966889500617981\n",
      "\n",
      "episode 9, val func loss 0.1966482698917389\n",
      "\n",
      "episode 10, val func loss 0.18677349388599396\n",
      "\n",
      "episode 11, val func loss 0.18270543217658997\n",
      "\n",
      "episode 12, val func loss 0.15334555506706238\n",
      "\n",
      "episode 13, val func loss 0.21720965206623077\n",
      "\n",
      "episode 14, val func loss 0.1746789962053299\n",
      "\n",
      "episode 15, val func loss 0.18967390060424805\n",
      "\n",
      "episode 16, val func loss 0.19692695140838623\n",
      "\n",
      "Val func train loss in epoch 0:0.18838769849389791\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.188685342669487\n",
      "\n",
      "episode 2, val func loss 0.20484033226966858\n",
      "\n",
      "episode 3, val func loss 0.17941375076770782\n",
      "\n",
      "episode 4, val func loss 0.16737286746501923\n",
      "\n",
      "episode 5, val func loss 0.15361288189888\n",
      "\n",
      "episode 6, val func loss 0.21193364262580872\n",
      "\n",
      "episode 7, val func loss 0.1970037817955017\n",
      "\n",
      "episode 8, val func loss 0.18618491291999817\n",
      "\n",
      "episode 9, val func loss 0.1749412566423416\n",
      "\n",
      "episode 10, val func loss 0.21402575075626373\n",
      "\n",
      "episode 11, val func loss 0.1904831975698471\n",
      "\n",
      "episode 12, val func loss 0.1962120234966278\n",
      "\n",
      "episode 13, val func loss 0.1824854165315628\n",
      "\n",
      "episode 14, val func loss 0.19688908755779266\n",
      "\n",
      "episode 15, val func loss 0.2147318422794342\n",
      "\n",
      "episode 16, val func loss 0.15703874826431274\n",
      "\n",
      "Val func train loss in epoch 1:0.18849092721939087\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19637589156627655\n",
      "\n",
      "episode 2, val func loss 0.21455901861190796\n",
      "\n",
      "episode 3, val func loss 0.17995484173297882\n",
      "\n",
      "episode 4, val func loss 0.1555706411600113\n",
      "\n",
      "episode 5, val func loss 0.2050071805715561\n",
      "\n",
      "episode 6, val func loss 0.19671837985515594\n",
      "\n",
      "episode 7, val func loss 0.1748899668455124\n",
      "\n",
      "episode 8, val func loss 0.19657035171985626\n",
      "\n",
      "episode 9, val func loss 0.1868475377559662\n",
      "\n",
      "episode 10, val func loss 0.1528371125459671\n",
      "\n",
      "episode 11, val func loss 0.21261166036128998\n",
      "\n",
      "episode 12, val func loss 0.2143545150756836\n",
      "\n",
      "episode 13, val func loss 0.1900210827589035\n",
      "\n",
      "episode 14, val func loss 0.18915686011314392\n",
      "\n",
      "episode 15, val func loss 0.16741953790187836\n",
      "\n",
      "episode 16, val func loss 0.1825498789548874\n",
      "\n",
      "Val func train loss in epoch 2:0.18846527859568596\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18906651437282562\n",
      "\n",
      "episode 2, val func loss 0.16712255775928497\n",
      "\n",
      "episode 3, val func loss 0.15298953652381897\n",
      "\n",
      "episode 4, val func loss 0.21889522671699524\n",
      "\n",
      "episode 5, val func loss 0.18966026604175568\n",
      "\n",
      "episode 6, val func loss 0.21440361440181732\n",
      "\n",
      "episode 7, val func loss 0.18343865871429443\n",
      "\n",
      "episode 8, val func loss 0.19638611376285553\n",
      "\n",
      "episode 9, val func loss 0.21405595541000366\n",
      "\n",
      "episode 10, val func loss 0.18602728843688965\n",
      "\n",
      "episode 11, val func loss 0.20473362505435944\n",
      "\n",
      "episode 12, val func loss 0.1970697045326233\n",
      "\n",
      "episode 13, val func loss 0.17794010043144226\n",
      "\n",
      "episode 14, val func loss 0.1596386730670929\n",
      "\n",
      "episode 15, val func loss 0.19636589288711548\n",
      "\n",
      "episode 16, val func loss 0.17973199486732483\n",
      "\n",
      "Val func train loss in epoch 3:0.1892203576862812\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.20607148110866547\n",
      "\n",
      "episode 2, val func loss 0.1829545497894287\n",
      "\n",
      "episode 3, val func loss 0.17508681118488312\n",
      "\n",
      "episode 4, val func loss 0.15316584706306458\n",
      "\n",
      "episode 5, val func loss 0.21185202896595\n",
      "\n",
      "episode 6, val func loss 0.1526743471622467\n",
      "\n",
      "episode 7, val func loss 0.19639740884304047\n",
      "\n",
      "episode 8, val func loss 0.21485276520252228\n",
      "\n",
      "episode 9, val func loss 0.18839307129383087\n",
      "\n",
      "episode 10, val func loss 0.19729283452033997\n",
      "\n",
      "episode 11, val func loss 0.21616625785827637\n",
      "\n",
      "episode 12, val func loss 0.1858147829771042\n",
      "\n",
      "episode 13, val func loss 0.17980532348155975\n",
      "\n",
      "episode 14, val func loss 0.19689378142356873\n",
      "\n",
      "episode 15, val func loss 0.19157041609287262\n",
      "\n",
      "episode 16, val func loss 0.16884127259254456\n",
      "\n",
      "Val func train loss in epoch 4:0.18861456122249365\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1857563555240631\n",
      "\n",
      "episode 2, val func loss 0.2165420800447464\n",
      "\n",
      "episode 3, val func loss 0.1542845070362091\n",
      "\n",
      "episode 4, val func loss 0.1897796094417572\n",
      "\n",
      "episode 5, val func loss 0.20561324059963226\n",
      "\n",
      "episode 6, val func loss 0.1793479323387146\n",
      "\n",
      "episode 7, val func loss 0.1519462764263153\n",
      "\n",
      "episode 8, val func loss 0.19691388309001923\n",
      "\n",
      "episode 9, val func loss 0.18765363097190857\n",
      "\n",
      "episode 10, val func loss 0.21451519429683685\n",
      "\n",
      "episode 11, val func loss 0.19720108807086945\n",
      "\n",
      "episode 12, val func loss 0.19773735105991364\n",
      "\n",
      "episode 13, val func loss 0.17524337768554688\n",
      "\n",
      "episode 14, val func loss 0.21296194195747375\n",
      "\n",
      "episode 15, val func loss 0.16951079666614532\n",
      "\n",
      "episode 16, val func loss 0.1827944964170456\n",
      "\n",
      "Val func train loss in epoch 5:0.18861261010169983\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19072325527668\n",
      "\n",
      "episode 2, val func loss 0.15641619265079498\n",
      "\n",
      "episode 3, val func loss 0.17545822262763977\n",
      "\n",
      "episode 4, val func loss 0.18953630328178406\n",
      "\n",
      "episode 5, val func loss 0.18565122783184052\n",
      "\n",
      "episode 6, val func loss 0.21660751104354858\n",
      "\n",
      "episode 7, val func loss 0.2156190723180771\n",
      "\n",
      "episode 8, val func loss 0.16685904562473297\n",
      "\n",
      "episode 9, val func loss 0.1796221137046814\n",
      "\n",
      "episode 10, val func loss 0.2150125801563263\n",
      "\n",
      "episode 11, val func loss 0.19623902440071106\n",
      "\n",
      "episode 12, val func loss 0.15747444331645966\n",
      "\n",
      "episode 13, val func loss 0.19716234505176544\n",
      "\n",
      "episode 14, val func loss 0.2048792690038681\n",
      "\n",
      "episode 15, val func loss 0.18581661581993103\n",
      "\n",
      "episode 16, val func loss 0.1970454901456833\n",
      "\n",
      "Val func train loss in epoch 6:0.18938266951590776\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.21303890645503998\n",
      "\n",
      "episode 2, val func loss 0.2091357707977295\n",
      "\n",
      "episode 3, val func loss 0.204720601439476\n",
      "\n",
      "episode 4, val func loss 0.1572536826133728\n",
      "\n",
      "episode 5, val func loss 0.1858065277338028\n",
      "\n",
      "episode 6, val func loss 0.1965779811143875\n",
      "\n",
      "episode 7, val func loss 0.18922294676303864\n",
      "\n",
      "episode 8, val func loss 0.19618971645832062\n",
      "\n",
      "episode 9, val func loss 0.16626998782157898\n",
      "\n",
      "episode 10, val func loss 0.1753402054309845\n",
      "\n",
      "episode 11, val func loss 0.18947964906692505\n",
      "\n",
      "episode 12, val func loss 0.15113943815231323\n",
      "\n",
      "episode 13, val func loss 0.22133104503154755\n",
      "\n",
      "episode 14, val func loss 0.1840038150548935\n",
      "\n",
      "episode 15, val func loss 0.1796797513961792\n",
      "\n",
      "episode 16, val func loss 0.1976141780614853\n",
      "\n",
      "Val func train loss in epoch 7:0.1885502627119422\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.2045954018831253\n",
      "\n",
      "episode 2, val func loss 0.19665628671646118\n",
      "\n",
      "episode 3, val func loss 0.18228769302368164\n",
      "\n",
      "episode 4, val func loss 0.18056371808052063\n",
      "\n",
      "episode 5, val func loss 0.1695096790790558\n",
      "\n",
      "episode 6, val func loss 0.19113805890083313\n",
      "\n",
      "episode 7, val func loss 0.19692951440811157\n",
      "\n",
      "episode 8, val func loss 0.2161760777235031\n",
      "\n",
      "episode 9, val func loss 0.1538008600473404\n",
      "\n",
      "episode 10, val func loss 0.17504800856113434\n",
      "\n",
      "episode 11, val func loss 0.18630626797676086\n",
      "\n",
      "episode 12, val func loss 0.15216872096061707\n",
      "\n",
      "episode 13, val func loss 0.21600967645645142\n",
      "\n",
      "episode 14, val func loss 0.21310363709926605\n",
      "\n",
      "episode 15, val func loss 0.19675153493881226\n",
      "\n",
      "episode 16, val func loss 0.18879914283752441\n",
      "\n",
      "Val func train loss in epoch 8:0.18874026741832495\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17569085955619812\n",
      "\n",
      "episode 2, val func loss 0.18558987975120544\n",
      "\n",
      "episode 3, val func loss 0.20439457893371582\n",
      "\n",
      "episode 4, val func loss 0.20884762704372406\n",
      "\n",
      "episode 5, val func loss 0.15705713629722595\n",
      "\n",
      "episode 6, val func loss 0.18192365765571594\n",
      "\n",
      "episode 7, val func loss 0.1909300982952118\n",
      "\n",
      "episode 8, val func loss 0.17950887978076935\n",
      "\n",
      "episode 9, val func loss 0.19666580855846405\n",
      "\n",
      "episode 10, val func loss 0.15305106341838837\n",
      "\n",
      "episode 11, val func loss 0.21823324263095856\n",
      "\n",
      "episode 12, val func loss 0.215708926320076\n",
      "\n",
      "episode 13, val func loss 0.18820905685424805\n",
      "\n",
      "episode 14, val func loss 0.19644878804683685\n",
      "\n",
      "episode 15, val func loss 0.16651636362075806\n",
      "\n",
      "episode 16, val func loss 0.197266086935997\n",
      "\n",
      "Val func train loss in epoch 9:0.18850262835621834\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18869876861572266\n",
      "\n",
      "episode 2, val func loss 0.19016025960445404\n",
      "\n",
      "episode 3, val func loss 0.1824597865343094\n",
      "\n",
      "episode 4, val func loss 0.1792406588792801\n",
      "\n",
      "episode 5, val func loss 0.20515494048595428\n",
      "\n",
      "episode 6, val func loss 0.15360592305660248\n",
      "\n",
      "episode 7, val func loss 0.19621387124061584\n",
      "\n",
      "episode 8, val func loss 0.1969231814146042\n",
      "\n",
      "episode 9, val func loss 0.19722996652126312\n",
      "\n",
      "episode 10, val func loss 0.16719494760036469\n",
      "\n",
      "episode 11, val func loss 0.21376901865005493\n",
      "\n",
      "episode 12, val func loss 0.18590392172336578\n",
      "\n",
      "episode 13, val func loss 0.20926669239997864\n",
      "\n",
      "episode 14, val func loss 0.1763370782136917\n",
      "\n",
      "episode 15, val func loss 0.21464431285858154\n",
      "\n",
      "episode 16, val func loss 0.15836875140666962\n",
      "\n",
      "Val func train loss in epoch 10:0.18844825495034456\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18076519668102264\n",
      "\n",
      "episode 2, val func loss 0.21259376406669617\n",
      "\n",
      "episode 3, val func loss 0.196767196059227\n",
      "\n",
      "episode 4, val func loss 0.18952617049217224\n",
      "\n",
      "episode 5, val func loss 0.20981577038764954\n",
      "\n",
      "episode 6, val func loss 0.1822512298822403\n",
      "\n",
      "episode 7, val func loss 0.17522218823432922\n",
      "\n",
      "episode 8, val func loss 0.1665857583284378\n",
      "\n",
      "episode 9, val func loss 0.15331067144870758\n",
      "\n",
      "episode 10, val func loss 0.2175281047821045\n",
      "\n",
      "episode 11, val func loss 0.1521502435207367\n",
      "\n",
      "episode 12, val func loss 0.1970386505126953\n",
      "\n",
      "episode 13, val func loss 0.18718045949935913\n",
      "\n",
      "episode 14, val func loss 0.18956632912158966\n",
      "\n",
      "episode 15, val func loss 0.19764572381973267\n",
      "\n",
      "episode 16, val func loss 0.20599497854709625\n",
      "\n",
      "Val func train loss in epoch 11:0.1883714022114873\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.15250784158706665\n",
      "\n",
      "episode 2, val func loss 0.19645479321479797\n",
      "\n",
      "episode 3, val func loss 0.19629372656345367\n",
      "\n",
      "episode 4, val func loss 0.1792752742767334\n",
      "\n",
      "episode 5, val func loss 0.2100086659193039\n",
      "\n",
      "episode 6, val func loss 0.19063487648963928\n",
      "\n",
      "episode 7, val func loss 0.18955472111701965\n",
      "\n",
      "episode 8, val func loss 0.1859968900680542\n",
      "\n",
      "episode 9, val func loss 0.16769051551818848\n",
      "\n",
      "episode 10, val func loss 0.18214330077171326\n",
      "\n",
      "episode 11, val func loss 0.1538148820400238\n",
      "\n",
      "episode 12, val func loss 0.19793152809143066\n",
      "\n",
      "episode 13, val func loss 0.21769118309020996\n",
      "\n",
      "episode 14, val func loss 0.17512790858745575\n",
      "\n",
      "episode 15, val func loss 0.2142503559589386\n",
      "\n",
      "episode 16, val func loss 0.20491953194141388\n",
      "\n",
      "Val func train loss in epoch 12:0.1883934997022152\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.16710641980171204\n",
      "\n",
      "episode 2, val func loss 0.19035781919956207\n",
      "\n",
      "episode 3, val func loss 0.204498291015625\n",
      "\n",
      "episode 4, val func loss 0.17539027333259583\n",
      "\n",
      "episode 5, val func loss 0.17956861853599548\n",
      "\n",
      "episode 6, val func loss 0.19642797112464905\n",
      "\n",
      "episode 7, val func loss 0.19642573595046997\n",
      "\n",
      "episode 8, val func loss 0.21370966732501984\n",
      "\n",
      "episode 9, val func loss 0.18929243087768555\n",
      "\n",
      "episode 10, val func loss 0.18576447665691376\n",
      "\n",
      "episode 11, val func loss 0.21541647613048553\n",
      "\n",
      "episode 12, val func loss 0.1963716447353363\n",
      "\n",
      "episode 13, val func loss 0.15566816926002502\n",
      "\n",
      "episode 14, val func loss 0.15540316700935364\n",
      "\n",
      "episode 15, val func loss 0.21001678705215454\n",
      "\n",
      "episode 16, val func loss 0.18233145773410797\n",
      "\n",
      "Val func train loss in epoch 13:0.18835933785885572\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1664738804101944\n",
      "\n",
      "episode 2, val func loss 0.19695116579532623\n",
      "\n",
      "episode 3, val func loss 0.1862626075744629\n",
      "\n",
      "episode 4, val func loss 0.1792847216129303\n",
      "\n",
      "episode 5, val func loss 0.2115795612335205\n",
      "\n",
      "episode 6, val func loss 0.15395838022232056\n",
      "\n",
      "episode 7, val func loss 0.20487482845783234\n",
      "\n",
      "episode 8, val func loss 0.19654150307178497\n",
      "\n",
      "episode 9, val func loss 0.18219514191150665\n",
      "\n",
      "episode 10, val func loss 0.19040584564208984\n",
      "\n",
      "episode 11, val func loss 0.1892162412405014\n",
      "\n",
      "episode 12, val func loss 0.15470269322395325\n",
      "\n",
      "episode 13, val func loss 0.19742876291275024\n",
      "\n",
      "episode 14, val func loss 0.21500539779663086\n",
      "\n",
      "episode 15, val func loss 0.17489081621170044\n",
      "\n",
      "episode 16, val func loss 0.21738380193710327\n",
      "\n",
      "Val func train loss in epoch 14:0.188572209328413\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1824212670326233\n",
      "\n",
      "episode 2, val func loss 0.1962743103504181\n",
      "\n",
      "episode 3, val func loss 0.17530620098114014\n",
      "\n",
      "episode 4, val func loss 0.15517209470272064\n",
      "\n",
      "episode 5, val func loss 0.1855470836162567\n",
      "\n",
      "episode 6, val func loss 0.19602642953395844\n",
      "\n",
      "episode 7, val func loss 0.21608950197696686\n",
      "\n",
      "episode 8, val func loss 0.209579735994339\n",
      "\n",
      "episode 9, val func loss 0.20437033474445343\n",
      "\n",
      "episode 10, val func loss 0.19056017696857452\n",
      "\n",
      "episode 11, val func loss 0.16851991415023804\n",
      "\n",
      "episode 12, val func loss 0.19131235778331757\n",
      "\n",
      "episode 13, val func loss 0.15518899261951447\n",
      "\n",
      "episode 14, val func loss 0.17958565056324005\n",
      "\n",
      "episode 15, val func loss 0.1981659233570099\n",
      "\n",
      "episode 16, val func loss 0.21576762199401855\n",
      "\n",
      "Val func train loss in epoch 15:0.18874297477304935\n",
      "***********************TIME WAS 4.963820898532868 min*****************************\n",
      "\n",
      "**********************ROUND 86 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.0066880593076348305\n",
      "\n",
      "episode 2, policy loss -0.07137946039438248\n",
      "\n",
      "episode 3, policy loss -0.09517212212085724\n",
      "\n",
      "episode 4, policy loss -0.08285317569971085\n",
      "\n",
      "episode 5, policy loss -0.11673582345247269\n",
      "\n",
      "episode 6, policy loss -0.09033721685409546\n",
      "\n",
      "episode 7, policy loss -0.03995826467871666\n",
      "\n",
      "episode 8, policy loss -0.05520663037896156\n",
      "\n",
      "episode 9, policy loss -0.0622740276157856\n",
      "\n",
      "episode 10, policy loss -0.09326884150505066\n",
      "\n",
      "episode 11, policy loss -0.09179188311100006\n",
      "\n",
      "episode 12, policy loss 0.006841071881353855\n",
      "\n",
      "episode 13, policy loss -0.07258336246013641\n",
      "\n",
      "episode 14, policy loss -0.09650958329439163\n",
      "\n",
      "episode 15, policy loss -0.030463041737675667\n",
      "\n",
      "episode 16, policy loss -0.040707673877477646\n",
      "\n",
      "Policy train loss in epoch 0:-0.06494300591293722\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.10079555213451385\n",
      "\n",
      "episode 2, policy loss -0.09479168057441711\n",
      "\n",
      "episode 3, policy loss -0.09507938474416733\n",
      "\n",
      "episode 4, policy loss -0.11739887297153473\n",
      "\n",
      "episode 5, policy loss -0.030533509328961372\n",
      "\n",
      "episode 6, policy loss -0.09357056766748428\n",
      "\n",
      "episode 7, policy loss -0.07959190011024475\n",
      "\n",
      "episode 8, policy loss -0.07639004290103912\n",
      "\n",
      "episode 9, policy loss -0.06436306238174438\n",
      "\n",
      "episode 10, policy loss -0.09943129122257233\n",
      "\n",
      "episode 11, policy loss 0.005150798708200455\n",
      "\n",
      "episode 12, policy loss -0.0846128761768341\n",
      "\n",
      "episode 13, policy loss -0.017070623114705086\n",
      "\n",
      "episode 14, policy loss -0.05761044844985008\n",
      "\n",
      "episode 15, policy loss -0.042373716831207275\n",
      "\n",
      "episode 16, policy loss -0.04217758774757385\n",
      "\n",
      "Policy train loss in epoch 1:-0.06816501985304058\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.042645413428545\n",
      "\n",
      "episode 2, policy loss -0.10200215131044388\n",
      "\n",
      "episode 3, policy loss -0.09408354014158249\n",
      "\n",
      "episode 4, policy loss 0.0050040483474731445\n",
      "\n",
      "episode 5, policy loss -0.11835556477308273\n",
      "\n",
      "episode 6, policy loss -0.031060954555869102\n",
      "\n",
      "episode 7, policy loss -0.042695581912994385\n",
      "\n",
      "episode 8, policy loss -0.07915513962507248\n",
      "\n",
      "episode 9, policy loss -0.0858859270811081\n",
      "\n",
      "episode 10, policy loss -0.07757198065519333\n",
      "\n",
      "episode 11, policy loss -0.016971228644251823\n",
      "\n",
      "episode 12, policy loss -0.05735282599925995\n",
      "\n",
      "episode 13, policy loss -0.09599456191062927\n",
      "\n",
      "episode 14, policy loss -0.1003146693110466\n",
      "\n",
      "episode 15, policy loss -0.06644754111766815\n",
      "\n",
      "episode 16, policy loss -0.09626816213130951\n",
      "\n",
      "Policy train loss in epoch 2:-0.06886257464066148\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.01658523455262184\n",
      "\n",
      "episode 2, policy loss -0.10184571892023087\n",
      "\n",
      "episode 3, policy loss -0.057649705559015274\n",
      "\n",
      "episode 4, policy loss -0.04275909438729286\n",
      "\n",
      "episode 5, policy loss -0.07699602097272873\n",
      "\n",
      "episode 6, policy loss -0.0959385335445404\n",
      "\n",
      "episode 7, policy loss 0.00473702372983098\n",
      "\n",
      "episode 8, policy loss -0.11918020248413086\n",
      "\n",
      "episode 9, policy loss -0.09655877947807312\n",
      "\n",
      "episode 10, policy loss -0.10089722275733948\n",
      "\n",
      "episode 11, policy loss -0.0791236013174057\n",
      "\n",
      "episode 12, policy loss -0.06614208966493607\n",
      "\n",
      "episode 13, policy loss -0.04268498718738556\n",
      "\n",
      "episode 14, policy loss -0.09354928880929947\n",
      "\n",
      "episode 15, policy loss -0.03113715536892414\n",
      "\n",
      "episode 16, policy loss -0.08476719260215759\n",
      "\n",
      "Policy train loss in epoch 3:-0.06881736274226569\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.21440669894218445\n",
      "\n",
      "episode 2, val func loss 0.20074516534805298\n",
      "\n",
      "episode 3, val func loss 0.19780853390693665\n",
      "\n",
      "episode 4, val func loss 0.20821845531463623\n",
      "\n",
      "episode 5, val func loss 0.1948879510164261\n",
      "\n",
      "episode 6, val func loss 0.15867511928081512\n",
      "\n",
      "episode 7, val func loss 0.19022709131240845\n",
      "\n",
      "episode 8, val func loss 0.17979466915130615\n",
      "\n",
      "episode 9, val func loss 0.20016372203826904\n",
      "\n",
      "episode 10, val func loss 0.22911250591278076\n",
      "\n",
      "episode 11, val func loss 0.18400327861309052\n",
      "\n",
      "episode 12, val func loss 0.19528403878211975\n",
      "\n",
      "episode 13, val func loss 0.18435879051685333\n",
      "\n",
      "episode 14, val func loss 0.17177291214466095\n",
      "\n",
      "episode 15, val func loss 0.19463983178138733\n",
      "\n",
      "episode 16, val func loss 0.20563602447509766\n",
      "\n",
      "Val func train loss in epoch 0:0.1943584242835641\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19478006660938263\n",
      "\n",
      "episode 2, val func loss 0.1997712254524231\n",
      "\n",
      "episode 3, val func loss 0.2042691856622696\n",
      "\n",
      "episode 4, val func loss 0.1974509358406067\n",
      "\n",
      "episode 5, val func loss 0.195990189909935\n",
      "\n",
      "episode 6, val func loss 0.15749618411064148\n",
      "\n",
      "episode 7, val func loss 0.22931770980358124\n",
      "\n",
      "episode 8, val func loss 0.18809671700000763\n",
      "\n",
      "episode 9, val func loss 0.19450964033603668\n",
      "\n",
      "episode 10, val func loss 0.18451529741287231\n",
      "\n",
      "episode 11, val func loss 0.19836202263832092\n",
      "\n",
      "episode 12, val func loss 0.18529033660888672\n",
      "\n",
      "episode 13, val func loss 0.2117486298084259\n",
      "\n",
      "episode 14, val func loss 0.17652204632759094\n",
      "\n",
      "episode 15, val func loss 0.20846106112003326\n",
      "\n",
      "episode 16, val func loss 0.17264507710933685\n",
      "\n",
      "Val func train loss in epoch 1:0.19370164535939693\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18469412624835968\n",
      "\n",
      "episode 2, val func loss 0.2120285928249359\n",
      "\n",
      "episode 3, val func loss 0.19732019305229187\n",
      "\n",
      "episode 4, val func loss 0.2033349722623825\n",
      "\n",
      "episode 5, val func loss 0.1535651981830597\n",
      "\n",
      "episode 6, val func loss 0.1968657225370407\n",
      "\n",
      "episode 7, val func loss 0.19934789836406708\n",
      "\n",
      "episode 8, val func loss 0.19353996217250824\n",
      "\n",
      "episode 9, val func loss 0.19793859124183655\n",
      "\n",
      "episode 10, val func loss 0.19437533617019653\n",
      "\n",
      "episode 11, val func loss 0.18365320563316345\n",
      "\n",
      "episode 12, val func loss 0.17475074529647827\n",
      "\n",
      "episode 13, val func loss 0.2293483167886734\n",
      "\n",
      "episode 14, val func loss 0.20745733380317688\n",
      "\n",
      "episode 15, val func loss 0.1766122579574585\n",
      "\n",
      "episode 16, val func loss 0.1864890605211258\n",
      "\n",
      "Val func train loss in epoch 2:0.1932075945660472\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.17588894069194794\n",
      "\n",
      "episode 2, val func loss 0.23069092631340027\n",
      "\n",
      "episode 3, val func loss 0.18439483642578125\n",
      "\n",
      "episode 4, val func loss 0.1981816589832306\n",
      "\n",
      "episode 5, val func loss 0.20001091063022614\n",
      "\n",
      "episode 6, val func loss 0.18588797748088837\n",
      "\n",
      "episode 7, val func loss 0.2120138704776764\n",
      "\n",
      "episode 8, val func loss 0.15412279963493347\n",
      "\n",
      "episode 9, val func loss 0.1734112948179245\n",
      "\n",
      "episode 10, val func loss 0.20301532745361328\n",
      "\n",
      "episode 11, val func loss 0.20850561559200287\n",
      "\n",
      "episode 12, val func loss 0.1967647224664688\n",
      "\n",
      "episode 13, val func loss 0.19915452599525452\n",
      "\n",
      "episode 14, val func loss 0.19362708926200867\n",
      "\n",
      "episode 15, val func loss 0.19439199566841125\n",
      "\n",
      "episode 16, val func loss 0.18435542285442352\n",
      "\n",
      "Val func train loss in epoch 3:0.193401119671762\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.15503385663032532\n",
      "\n",
      "episode 2, val func loss 0.19567684829235077\n",
      "\n",
      "episode 3, val func loss 0.19916225969791412\n",
      "\n",
      "episode 4, val func loss 0.19394941627979279\n",
      "\n",
      "episode 5, val func loss 0.20341342687606812\n",
      "\n",
      "episode 6, val func loss 0.18605364859104156\n",
      "\n",
      "episode 7, val func loss 0.19530516862869263\n",
      "\n",
      "episode 8, val func loss 0.20854564011096954\n",
      "\n",
      "episode 9, val func loss 0.23018454015254974\n",
      "\n",
      "episode 10, val func loss 0.17642807960510254\n",
      "\n",
      "episode 11, val func loss 0.1854574829339981\n",
      "\n",
      "episode 12, val func loss 0.21104224026203156\n",
      "\n",
      "episode 13, val func loss 0.17381082475185394\n",
      "\n",
      "episode 14, val func loss 0.19848206639289856\n",
      "\n",
      "episode 15, val func loss 0.1964838057756424\n",
      "\n",
      "episode 16, val func loss 0.1838950514793396\n",
      "\n",
      "Val func train loss in epoch 4:0.1933077722787857\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1850227266550064\n",
      "\n",
      "episode 2, val func loss 0.19639907777309418\n",
      "\n",
      "episode 3, val func loss 0.1995551586151123\n",
      "\n",
      "episode 4, val func loss 0.20330990850925446\n",
      "\n",
      "episode 5, val func loss 0.21153640747070312\n",
      "\n",
      "episode 6, val func loss 0.1543143093585968\n",
      "\n",
      "episode 7, val func loss 0.22978176176548004\n",
      "\n",
      "episode 8, val func loss 0.19341525435447693\n",
      "\n",
      "episode 9, val func loss 0.2077588587999344\n",
      "\n",
      "episode 10, val func loss 0.19443035125732422\n",
      "\n",
      "episode 11, val func loss 0.19817715883255005\n",
      "\n",
      "episode 12, val func loss 0.19594039022922516\n",
      "\n",
      "episode 13, val func loss 0.18797962367534637\n",
      "\n",
      "episode 14, val func loss 0.1778292953968048\n",
      "\n",
      "episode 15, val func loss 0.1846805214881897\n",
      "\n",
      "episode 16, val func loss 0.17392563819885254\n",
      "\n",
      "Val func train loss in epoch 5:0.19337852764874697\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18355055153369904\n",
      "\n",
      "episode 2, val func loss 0.17595267295837402\n",
      "\n",
      "episode 3, val func loss 0.1997666209936142\n",
      "\n",
      "episode 4, val func loss 0.18436594307422638\n",
      "\n",
      "episode 5, val func loss 0.2331908494234085\n",
      "\n",
      "episode 6, val func loss 0.15144431591033936\n",
      "\n",
      "episode 7, val func loss 0.20144815742969513\n",
      "\n",
      "episode 8, val func loss 0.2134448140859604\n",
      "\n",
      "episode 9, val func loss 0.19898022711277008\n",
      "\n",
      "episode 10, val func loss 0.2079005241394043\n",
      "\n",
      "episode 11, val func loss 0.2030104398727417\n",
      "\n",
      "episode 12, val func loss 0.1948135942220688\n",
      "\n",
      "episode 13, val func loss 0.19600234925746918\n",
      "\n",
      "episode 14, val func loss 0.19627322256565094\n",
      "\n",
      "episode 15, val func loss 0.17979654669761658\n",
      "\n",
      "episode 16, val func loss 0.18967299163341522\n",
      "\n",
      "Val func train loss in epoch 6:0.19435086380690336\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19442301988601685\n",
      "\n",
      "episode 2, val func loss 0.18503184616565704\n",
      "\n",
      "episode 3, val func loss 0.19846244156360626\n",
      "\n",
      "episode 4, val func loss 0.19945096969604492\n",
      "\n",
      "episode 5, val func loss 0.19651079177856445\n",
      "\n",
      "episode 6, val func loss 0.17134436964988708\n",
      "\n",
      "episode 7, val func loss 0.21315383911132812\n",
      "\n",
      "episode 8, val func loss 0.2038835883140564\n",
      "\n",
      "episode 9, val func loss 0.18336990475654602\n",
      "\n",
      "episode 10, val func loss 0.19840848445892334\n",
      "\n",
      "episode 11, val func loss 0.17732878029346466\n",
      "\n",
      "episode 12, val func loss 0.15535783767700195\n",
      "\n",
      "episode 13, val func loss 0.20778022706508636\n",
      "\n",
      "episode 14, val func loss 0.18686246871948242\n",
      "\n",
      "episode 15, val func loss 0.2299039512872696\n",
      "\n",
      "episode 16, val func loss 0.19911393523216248\n",
      "\n",
      "Val func train loss in epoch 7:0.19377415347844362\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17630355060100555\n",
      "\n",
      "episode 2, val func loss 0.19510717689990997\n",
      "\n",
      "episode 3, val func loss 0.21205036342144012\n",
      "\n",
      "episode 4, val func loss 0.18610000610351562\n",
      "\n",
      "episode 5, val func loss 0.20822608470916748\n",
      "\n",
      "episode 6, val func loss 0.15358535945415497\n",
      "\n",
      "episode 7, val func loss 0.1732463836669922\n",
      "\n",
      "episode 8, val func loss 0.19711272418498993\n",
      "\n",
      "episode 9, val func loss 0.1940532773733139\n",
      "\n",
      "episode 10, val func loss 0.19925624132156372\n",
      "\n",
      "episode 11, val func loss 0.1998111754655838\n",
      "\n",
      "episode 12, val func loss 0.1831188201904297\n",
      "\n",
      "episode 13, val func loss 0.20337963104248047\n",
      "\n",
      "episode 14, val func loss 0.22945058345794678\n",
      "\n",
      "episode 15, val func loss 0.19471219182014465\n",
      "\n",
      "episode 16, val func loss 0.1896848976612091\n",
      "\n",
      "Val func train loss in epoch 8:0.1934499042108655\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.15856613218784332\n",
      "\n",
      "episode 2, val func loss 0.183878093957901\n",
      "\n",
      "episode 3, val func loss 0.20347462594509125\n",
      "\n",
      "episode 4, val func loss 0.17175722122192383\n",
      "\n",
      "episode 5, val func loss 0.2011740803718567\n",
      "\n",
      "episode 6, val func loss 0.1761217713356018\n",
      "\n",
      "episode 7, val func loss 0.21159805357456207\n",
      "\n",
      "episode 8, val func loss 0.19952599704265594\n",
      "\n",
      "episode 9, val func loss 0.212326779961586\n",
      "\n",
      "episode 10, val func loss 0.19400273263454437\n",
      "\n",
      "episode 11, val func loss 0.18891650438308716\n",
      "\n",
      "episode 12, val func loss 0.18631775677204132\n",
      "\n",
      "episode 13, val func loss 0.1947266161441803\n",
      "\n",
      "episode 14, val func loss 0.23031650483608246\n",
      "\n",
      "episode 15, val func loss 0.19729183614253998\n",
      "\n",
      "episode 16, val func loss 0.19671069085597992\n",
      "\n",
      "Val func train loss in epoch 9:0.19416908733546734\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18698722124099731\n",
      "\n",
      "episode 2, val func loss 0.20329156517982483\n",
      "\n",
      "episode 3, val func loss 0.19824936985969543\n",
      "\n",
      "episode 4, val func loss 0.19518744945526123\n",
      "\n",
      "episode 5, val func loss 0.1943097561597824\n",
      "\n",
      "episode 6, val func loss 0.21086278557777405\n",
      "\n",
      "episode 7, val func loss 0.17937520146369934\n",
      "\n",
      "episode 8, val func loss 0.15784794092178345\n",
      "\n",
      "episode 9, val func loss 0.19561699032783508\n",
      "\n",
      "episode 10, val func loss 0.19915373623371124\n",
      "\n",
      "episode 11, val func loss 0.2076711654663086\n",
      "\n",
      "episode 12, val func loss 0.17264091968536377\n",
      "\n",
      "episode 13, val func loss 0.19372500479221344\n",
      "\n",
      "episode 14, val func loss 0.23070530593395233\n",
      "\n",
      "episode 15, val func loss 0.1833060383796692\n",
      "\n",
      "episode 16, val func loss 0.18432505428791046\n",
      "\n",
      "Val func train loss in epoch 10:0.19332846906036139\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19424396753311157\n",
      "\n",
      "episode 2, val func loss 0.18357181549072266\n",
      "\n",
      "episode 3, val func loss 0.23093630373477936\n",
      "\n",
      "episode 4, val func loss 0.1994277685880661\n",
      "\n",
      "episode 5, val func loss 0.19479042291641235\n",
      "\n",
      "episode 6, val func loss 0.1780458390712738\n",
      "\n",
      "episode 7, val func loss 0.15658822655677795\n",
      "\n",
      "episode 8, val func loss 0.19948385655879974\n",
      "\n",
      "episode 9, val func loss 0.17355838418006897\n",
      "\n",
      "episode 10, val func loss 0.1970382183790207\n",
      "\n",
      "episode 11, val func loss 0.212759867310524\n",
      "\n",
      "episode 12, val func loss 0.20379038155078888\n",
      "\n",
      "episode 13, val func loss 0.19723154604434967\n",
      "\n",
      "episode 14, val func loss 0.18533603847026825\n",
      "\n",
      "episode 15, val func loss 0.208232119679451\n",
      "\n",
      "episode 16, val func loss 0.18659628927707672\n",
      "\n",
      "Val func train loss in epoch 11:0.19385194033384323\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1945902407169342\n",
      "\n",
      "episode 2, val func loss 0.20318204164505005\n",
      "\n",
      "episode 3, val func loss 0.176843523979187\n",
      "\n",
      "episode 4, val func loss 0.18708424270153046\n",
      "\n",
      "episode 5, val func loss 0.2080957144498825\n",
      "\n",
      "episode 6, val func loss 0.19917188584804535\n",
      "\n",
      "episode 7, val func loss 0.22974097728729248\n",
      "\n",
      "episode 8, val func loss 0.17326392233371735\n",
      "\n",
      "episode 9, val func loss 0.21209290623664856\n",
      "\n",
      "episode 10, val func loss 0.15303590893745422\n",
      "\n",
      "episode 11, val func loss 0.19909949600696564\n",
      "\n",
      "episode 12, val func loss 0.1832246035337448\n",
      "\n",
      "episode 13, val func loss 0.1972641795873642\n",
      "\n",
      "episode 14, val func loss 0.19689907133579254\n",
      "\n",
      "episode 15, val func loss 0.18560583889484406\n",
      "\n",
      "episode 16, val func loss 0.19379308819770813\n",
      "\n",
      "Val func train loss in epoch 12:0.1933117276057601\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.2078608274459839\n",
      "\n",
      "episode 2, val func loss 0.19386523962020874\n",
      "\n",
      "episode 3, val func loss 0.19981741905212402\n",
      "\n",
      "episode 4, val func loss 0.1945204734802246\n",
      "\n",
      "episode 5, val func loss 0.1862591654062271\n",
      "\n",
      "episode 6, val func loss 0.1840192973613739\n",
      "\n",
      "episode 7, val func loss 0.19808419048786163\n",
      "\n",
      "episode 8, val func loss 0.21125157177448273\n",
      "\n",
      "episode 9, val func loss 0.19623322784900665\n",
      "\n",
      "episode 10, val func loss 0.196017786860466\n",
      "\n",
      "episode 11, val func loss 0.17708024382591248\n",
      "\n",
      "episode 12, val func loss 0.18693526089191437\n",
      "\n",
      "episode 13, val func loss 0.2292974293231964\n",
      "\n",
      "episode 14, val func loss 0.2030201256275177\n",
      "\n",
      "episode 15, val func loss 0.15457317233085632\n",
      "\n",
      "episode 16, val func loss 0.17317840456962585\n",
      "\n",
      "Val func train loss in epoch 13:0.1932508647441864\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.195536807179451\n",
      "\n",
      "episode 2, val func loss 0.15181918442249298\n",
      "\n",
      "episode 3, val func loss 0.19986878335475922\n",
      "\n",
      "episode 4, val func loss 0.21230390667915344\n",
      "\n",
      "episode 5, val func loss 0.19963522255420685\n",
      "\n",
      "episode 6, val func loss 0.1940261274576187\n",
      "\n",
      "episode 7, val func loss 0.1981838494539261\n",
      "\n",
      "episode 8, val func loss 0.2032289355993271\n",
      "\n",
      "episode 9, val func loss 0.19817961752414703\n",
      "\n",
      "episode 10, val func loss 0.18528953194618225\n",
      "\n",
      "episode 11, val func loss 0.17839854955673218\n",
      "\n",
      "episode 12, val func loss 0.18831443786621094\n",
      "\n",
      "episode 13, val func loss 0.17855776846408844\n",
      "\n",
      "episode 14, val func loss 0.2106884866952896\n",
      "\n",
      "episode 15, val func loss 0.18646059930324554\n",
      "\n",
      "episode 16, val func loss 0.23033295571804047\n",
      "\n",
      "Val func train loss in epoch 14:0.1944265477359295\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19927166402339935\n",
      "\n",
      "episode 2, val func loss 0.1853514164686203\n",
      "\n",
      "episode 3, val func loss 0.21334508061408997\n",
      "\n",
      "episode 4, val func loss 0.1945616900920868\n",
      "\n",
      "episode 5, val func loss 0.2315686047077179\n",
      "\n",
      "episode 6, val func loss 0.20949865877628326\n",
      "\n",
      "episode 7, val func loss 0.20291484892368317\n",
      "\n",
      "episode 8, val func loss 0.18546241521835327\n",
      "\n",
      "episode 9, val func loss 0.1947900503873825\n",
      "\n",
      "episode 10, val func loss 0.1956692636013031\n",
      "\n",
      "episode 11, val func loss 0.1576678305864334\n",
      "\n",
      "episode 12, val func loss 0.17655816674232483\n",
      "\n",
      "episode 13, val func loss 0.1774967610836029\n",
      "\n",
      "episode 14, val func loss 0.19823066890239716\n",
      "\n",
      "episode 15, val func loss 0.19697870314121246\n",
      "\n",
      "episode 16, val func loss 0.18339803814888\n",
      "\n",
      "Val func train loss in epoch 15:0.19392274133861065\n",
      "***********************TIME WAS 4.961293896039327 min*****************************\n",
      "\n",
      "**********************ROUND 87 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.01567884348332882\n",
      "\n",
      "episode 2, policy loss 0.012502039782702923\n",
      "\n",
      "episode 3, policy loss -0.06732127815485\n",
      "\n",
      "episode 4, policy loss -0.05858637019991875\n",
      "\n",
      "episode 5, policy loss -0.10230719298124313\n",
      "\n",
      "episode 6, policy loss -0.0314803272485733\n",
      "\n",
      "episode 7, policy loss 0.02416715770959854\n",
      "\n",
      "episode 8, policy loss 0.03642488643527031\n",
      "\n",
      "episode 9, policy loss -0.09907953441143036\n",
      "\n",
      "episode 10, policy loss -0.023577315732836723\n",
      "\n",
      "episode 11, policy loss -0.03746465593576431\n",
      "\n",
      "episode 12, policy loss -0.07220058888196945\n",
      "\n",
      "episode 13, policy loss -0.06454898416996002\n",
      "\n",
      "episode 14, policy loss -0.09120909124612808\n",
      "\n",
      "episode 15, policy loss -0.07495580613613129\n",
      "\n",
      "episode 16, policy loss -0.04216597229242325\n",
      "\n",
      "Policy train loss in epoch 0:-0.04421761730918661\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.1071525290608406\n",
      "\n",
      "episode 2, policy loss -0.06976649165153503\n",
      "\n",
      "episode 3, policy loss -0.02314833551645279\n",
      "\n",
      "episode 4, policy loss -0.028515709564089775\n",
      "\n",
      "episode 5, policy loss -0.06405114382505417\n",
      "\n",
      "episode 6, policy loss -0.07414523512125015\n",
      "\n",
      "episode 7, policy loss 0.003379895118996501\n",
      "\n",
      "episode 8, policy loss 0.024089844897389412\n",
      "\n",
      "episode 9, policy loss -0.02935878559947014\n",
      "\n",
      "episode 10, policy loss -0.07691677659749985\n",
      "\n",
      "episode 11, policy loss -0.040785420686006546\n",
      "\n",
      "episode 12, policy loss -0.07477671653032303\n",
      "\n",
      "episode 13, policy loss -0.1009654775261879\n",
      "\n",
      "episode 14, policy loss 0.036489348858594894\n",
      "\n",
      "episode 15, policy loss -0.042931437492370605\n",
      "\n",
      "episode 16, policy loss -0.09316375851631165\n",
      "\n",
      "Policy train loss in epoch 1:-0.047607420550775714\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.003486379748210311\n",
      "\n",
      "episode 2, policy loss -0.10260818153619766\n",
      "\n",
      "episode 3, policy loss -0.03126758337020874\n",
      "\n",
      "episode 4, policy loss -0.07571887224912643\n",
      "\n",
      "episode 5, policy loss 0.02406427264213562\n",
      "\n",
      "episode 6, policy loss -0.10651812702417374\n",
      "\n",
      "episode 7, policy loss -0.043219443410634995\n",
      "\n",
      "episode 8, policy loss -0.023596394807100296\n",
      "\n",
      "episode 9, policy loss 0.03675113618373871\n",
      "\n",
      "episode 10, policy loss -0.06930498778820038\n",
      "\n",
      "episode 11, policy loss -0.06528718769550323\n",
      "\n",
      "episode 12, policy loss -0.02896525338292122\n",
      "\n",
      "episode 13, policy loss -0.076445572078228\n",
      "\n",
      "episode 14, policy loss -0.09343407303094864\n",
      "\n",
      "episode 15, policy loss -0.04379281401634216\n",
      "\n",
      "episode 16, policy loss -0.07671859860420227\n",
      "\n",
      "Policy train loss in epoch 2:-0.048285956276231445\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.10736875236034393\n",
      "\n",
      "episode 2, policy loss -0.07672598958015442\n",
      "\n",
      "episode 3, policy loss 0.0031327595934271812\n",
      "\n",
      "episode 4, policy loss 0.03727494552731514\n",
      "\n",
      "episode 5, policy loss -0.04423360899090767\n",
      "\n",
      "episode 6, policy loss -0.06961476802825928\n",
      "\n",
      "episode 7, policy loss -0.030906468629837036\n",
      "\n",
      "episode 8, policy loss -0.07668472826480865\n",
      "\n",
      "episode 9, policy loss -0.10343276709318161\n",
      "\n",
      "episode 10, policy loss -0.02409285120666027\n",
      "\n",
      "episode 11, policy loss -0.06503769755363464\n",
      "\n",
      "episode 12, policy loss 0.024020027369260788\n",
      "\n",
      "episode 13, policy loss -0.02918544039130211\n",
      "\n",
      "episode 14, policy loss -0.0933581069111824\n",
      "\n",
      "episode 15, policy loss -0.07620002329349518\n",
      "\n",
      "episode 16, policy loss -0.04338853061199188\n",
      "\n",
      "Policy train loss in epoch 3:-0.04848762502660975\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19346219301223755\n",
      "\n",
      "episode 2, val func loss 0.21198773384094238\n",
      "\n",
      "episode 3, val func loss 0.1911875158548355\n",
      "\n",
      "episode 4, val func loss 0.21899837255477905\n",
      "\n",
      "episode 5, val func loss 0.23290088772773743\n",
      "\n",
      "episode 6, val func loss 0.22590890526771545\n",
      "\n",
      "episode 7, val func loss 0.14003337919712067\n",
      "\n",
      "episode 8, val func loss 0.21497179567813873\n",
      "\n",
      "episode 9, val func loss 0.21398621797561646\n",
      "\n",
      "episode 10, val func loss 0.20666779577732086\n",
      "\n",
      "episode 11, val func loss 0.17230457067489624\n",
      "\n",
      "episode 12, val func loss 0.17765286564826965\n",
      "\n",
      "episode 13, val func loss 0.19025085866451263\n",
      "\n",
      "episode 14, val func loss 0.1807178407907486\n",
      "\n",
      "episode 15, val func loss 0.15825049579143524\n",
      "\n",
      "episode 16, val func loss 0.20255661010742188\n",
      "\n",
      "Val func train loss in epoch 0:0.19573987741023302\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.22042308747768402\n",
      "\n",
      "episode 2, val func loss 0.1931302547454834\n",
      "\n",
      "episode 3, val func loss 0.16795745491981506\n",
      "\n",
      "episode 4, val func loss 0.21576865017414093\n",
      "\n",
      "episode 5, val func loss 0.1577504426240921\n",
      "\n",
      "episode 6, val func loss 0.1360391527414322\n",
      "\n",
      "episode 7, val func loss 0.22808927297592163\n",
      "\n",
      "episode 8, val func loss 0.23394805192947388\n",
      "\n",
      "episode 9, val func loss 0.19127745926380157\n",
      "\n",
      "episode 10, val func loss 0.211903914809227\n",
      "\n",
      "episode 11, val func loss 0.20107978582382202\n",
      "\n",
      "episode 12, val func loss 0.21569876372814178\n",
      "\n",
      "episode 13, val func loss 0.18152929842472076\n",
      "\n",
      "episode 14, val func loss 0.17825360596179962\n",
      "\n",
      "episode 15, val func loss 0.20666655898094177\n",
      "\n",
      "episode 16, val func loss 0.19001802802085876\n",
      "\n",
      "Val func train loss in epoch 1:0.19559586141258478\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18178875744342804\n",
      "\n",
      "episode 2, val func loss 0.22563084959983826\n",
      "\n",
      "episode 3, val func loss 0.16077451407909393\n",
      "\n",
      "episode 4, val func loss 0.20607177913188934\n",
      "\n",
      "episode 5, val func loss 0.13706420361995697\n",
      "\n",
      "episode 6, val func loss 0.2021082490682602\n",
      "\n",
      "episode 7, val func loss 0.19351167976856232\n",
      "\n",
      "episode 8, val func loss 0.16766084730625153\n",
      "\n",
      "episode 9, val func loss 0.21900558471679688\n",
      "\n",
      "episode 10, val func loss 0.2149004340171814\n",
      "\n",
      "episode 11, val func loss 0.17614704370498657\n",
      "\n",
      "episode 12, val func loss 0.1907968819141388\n",
      "\n",
      "episode 13, val func loss 0.21816428005695343\n",
      "\n",
      "episode 14, val func loss 0.2146398276090622\n",
      "\n",
      "episode 15, val func loss 0.23055437207221985\n",
      "\n",
      "episode 16, val func loss 0.19007882475852966\n",
      "\n",
      "Val func train loss in epoch 2:0.19555613305419683\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.21358604729175568\n",
      "\n",
      "episode 2, val func loss 0.2158021181821823\n",
      "\n",
      "episode 3, val func loss 0.20791690051555634\n",
      "\n",
      "episode 4, val func loss 0.19610165059566498\n",
      "\n",
      "episode 5, val func loss 0.17866529524326324\n",
      "\n",
      "episode 6, val func loss 0.1937684565782547\n",
      "\n",
      "episode 7, val func loss 0.2370750606060028\n",
      "\n",
      "episode 8, val func loss 0.16767284274101257\n",
      "\n",
      "episode 9, val func loss 0.21330174803733826\n",
      "\n",
      "episode 10, val func loss 0.2012583315372467\n",
      "\n",
      "episode 11, val func loss 0.1598174273967743\n",
      "\n",
      "episode 12, val func loss 0.1810843050479889\n",
      "\n",
      "episode 13, val func loss 0.1382172852754593\n",
      "\n",
      "episode 14, val func loss 0.2182113379240036\n",
      "\n",
      "episode 15, val func loss 0.1904841810464859\n",
      "\n",
      "episode 16, val func loss 0.22771209478378296\n",
      "\n",
      "Val func train loss in epoch 3:0.19629219267517328\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19049112498760223\n",
      "\n",
      "episode 2, val func loss 0.2111373245716095\n",
      "\n",
      "episode 3, val func loss 0.17038790881633759\n",
      "\n",
      "episode 4, val func loss 0.21636123955249786\n",
      "\n",
      "episode 5, val func loss 0.18152788281440735\n",
      "\n",
      "episode 6, val func loss 0.16070377826690674\n",
      "\n",
      "episode 7, val func loss 0.20668788254261017\n",
      "\n",
      "episode 8, val func loss 0.23183952271938324\n",
      "\n",
      "episode 9, val func loss 0.2147188037633896\n",
      "\n",
      "episode 10, val func loss 0.2008189558982849\n",
      "\n",
      "episode 11, val func loss 0.13886889815330505\n",
      "\n",
      "episode 12, val func loss 0.1766432225704193\n",
      "\n",
      "episode 13, val func loss 0.21605300903320312\n",
      "\n",
      "episode 14, val func loss 0.22706566751003265\n",
      "\n",
      "episode 15, val func loss 0.1931506097316742\n",
      "\n",
      "episode 16, val func loss 0.19109655916690826\n",
      "\n",
      "Val func train loss in epoch 4:0.19547202438116074\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.23245882987976074\n",
      "\n",
      "episode 2, val func loss 0.13743312656879425\n",
      "\n",
      "episode 3, val func loss 0.15852242708206177\n",
      "\n",
      "episode 4, val func loss 0.22765006124973297\n",
      "\n",
      "episode 5, val func loss 0.20677624642848969\n",
      "\n",
      "episode 6, val func loss 0.2164946049451828\n",
      "\n",
      "episode 7, val func loss 0.17579667270183563\n",
      "\n",
      "episode 8, val func loss 0.21175861358642578\n",
      "\n",
      "episode 9, val func loss 0.20078982412815094\n",
      "\n",
      "episode 10, val func loss 0.21413472294807434\n",
      "\n",
      "episode 11, val func loss 0.17144039273262024\n",
      "\n",
      "episode 12, val func loss 0.21624159812927246\n",
      "\n",
      "episode 13, val func loss 0.19312793016433716\n",
      "\n",
      "episode 14, val func loss 0.18175861239433289\n",
      "\n",
      "episode 15, val func loss 0.19368070363998413\n",
      "\n",
      "episode 16, val func loss 0.18972264230251312\n",
      "\n",
      "Val func train loss in epoch 5:0.19548668805509806\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17671817541122437\n",
      "\n",
      "episode 2, val func loss 0.13724973797798157\n",
      "\n",
      "episode 3, val func loss 0.20696306228637695\n",
      "\n",
      "episode 4, val func loss 0.22023093700408936\n",
      "\n",
      "episode 5, val func loss 0.21701154112815857\n",
      "\n",
      "episode 6, val func loss 0.21331103146076202\n",
      "\n",
      "episode 7, val func loss 0.157809317111969\n",
      "\n",
      "episode 8, val func loss 0.19124674797058105\n",
      "\n",
      "episode 9, val func loss 0.19082511961460114\n",
      "\n",
      "episode 10, val func loss 0.18123646080493927\n",
      "\n",
      "episode 11, val func loss 0.2323216199874878\n",
      "\n",
      "episode 12, val func loss 0.16989268362522125\n",
      "\n",
      "episode 13, val func loss 0.20076702535152435\n",
      "\n",
      "episode 14, val func loss 0.21528740227222443\n",
      "\n",
      "episode 15, val func loss 0.19370225071907043\n",
      "\n",
      "episode 16, val func loss 0.2253897786140442\n",
      "\n",
      "Val func train loss in epoch 6:0.19562268070876598\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.14058169722557068\n",
      "\n",
      "episode 2, val func loss 0.19344356656074524\n",
      "\n",
      "episode 3, val func loss 0.15975479781627655\n",
      "\n",
      "episode 4, val func loss 0.19000624120235443\n",
      "\n",
      "episode 5, val func loss 0.17638026177883148\n",
      "\n",
      "episode 6, val func loss 0.2071402221918106\n",
      "\n",
      "episode 7, val func loss 0.2136976718902588\n",
      "\n",
      "episode 8, val func loss 0.19101926684379578\n",
      "\n",
      "episode 9, val func loss 0.21612758934497833\n",
      "\n",
      "episode 10, val func loss 0.2169872373342514\n",
      "\n",
      "episode 11, val func loss 0.22744262218475342\n",
      "\n",
      "episode 12, val func loss 0.21753224730491638\n",
      "\n",
      "episode 13, val func loss 0.20028822124004364\n",
      "\n",
      "episode 14, val func loss 0.22992147505283356\n",
      "\n",
      "episode 15, val func loss 0.17714254558086395\n",
      "\n",
      "episode 16, val func loss 0.18406665325164795\n",
      "\n",
      "Val func train loss in epoch 7:0.19634576980024576\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.21558547019958496\n",
      "\n",
      "episode 2, val func loss 0.1796966940164566\n",
      "\n",
      "episode 3, val func loss 0.19431261718273163\n",
      "\n",
      "episode 4, val func loss 0.20629647374153137\n",
      "\n",
      "episode 5, val func loss 0.21479834616184235\n",
      "\n",
      "episode 6, val func loss 0.22697830200195312\n",
      "\n",
      "episode 7, val func loss 0.16863128542900085\n",
      "\n",
      "episode 8, val func loss 0.13576240837574005\n",
      "\n",
      "episode 9, val func loss 0.20281535387039185\n",
      "\n",
      "episode 10, val func loss 0.23567615449428558\n",
      "\n",
      "episode 11, val func loss 0.19316565990447998\n",
      "\n",
      "episode 12, val func loss 0.19162404537200928\n",
      "\n",
      "episode 13, val func loss 0.21286576986312866\n",
      "\n",
      "episode 14, val func loss 0.215957373380661\n",
      "\n",
      "episode 15, val func loss 0.18125870823860168\n",
      "\n",
      "episode 16, val func loss 0.1616353988647461\n",
      "\n",
      "Val func train loss in epoch 8:0.19606625381857157\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.2254170924425125\n",
      "\n",
      "episode 2, val func loss 0.1776435524225235\n",
      "\n",
      "episode 3, val func loss 0.23029494285583496\n",
      "\n",
      "episode 4, val func loss 0.2161250114440918\n",
      "\n",
      "episode 5, val func loss 0.19001007080078125\n",
      "\n",
      "episode 6, val func loss 0.21381519734859467\n",
      "\n",
      "episode 7, val func loss 0.20059563219547272\n",
      "\n",
      "episode 8, val func loss 0.19389615952968597\n",
      "\n",
      "episode 9, val func loss 0.21508823335170746\n",
      "\n",
      "episode 10, val func loss 0.18134385347366333\n",
      "\n",
      "episode 11, val func loss 0.19331830739974976\n",
      "\n",
      "episode 12, val func loss 0.2126881629228592\n",
      "\n",
      "episode 13, val func loss 0.16877129673957825\n",
      "\n",
      "episode 14, val func loss 0.13534919917583466\n",
      "\n",
      "episode 15, val func loss 0.1568039059638977\n",
      "\n",
      "episode 16, val func loss 0.21095432341098785\n",
      "\n",
      "Val func train loss in epoch 9:0.19513218384236097\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20669808983802795\n",
      "\n",
      "episode 2, val func loss 0.21936437487602234\n",
      "\n",
      "episode 3, val func loss 0.21575115621089935\n",
      "\n",
      "episode 4, val func loss 0.19006499648094177\n",
      "\n",
      "episode 5, val func loss 0.17144402861595154\n",
      "\n",
      "episode 6, val func loss 0.14150036871433258\n",
      "\n",
      "episode 7, val func loss 0.17813459038734436\n",
      "\n",
      "episode 8, val func loss 0.21739301085472107\n",
      "\n",
      "episode 9, val func loss 0.20637676119804382\n",
      "\n",
      "episode 10, val func loss 0.21068651974201202\n",
      "\n",
      "episode 11, val func loss 0.15962184965610504\n",
      "\n",
      "episode 12, val func loss 0.1809684932231903\n",
      "\n",
      "episode 13, val func loss 0.22692129015922546\n",
      "\n",
      "episode 14, val func loss 0.19122314453125\n",
      "\n",
      "episode 15, val func loss 0.23261244595050812\n",
      "\n",
      "episode 16, val func loss 0.19326750934123993\n",
      "\n",
      "Val func train loss in epoch 10:0.19637678936123848\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.21146361529827118\n",
      "\n",
      "episode 2, val func loss 0.2064647227525711\n",
      "\n",
      "episode 3, val func loss 0.1811610758304596\n",
      "\n",
      "episode 4, val func loss 0.13907432556152344\n",
      "\n",
      "episode 5, val func loss 0.21731488406658173\n",
      "\n",
      "episode 6, val func loss 0.22575192153453827\n",
      "\n",
      "episode 7, val func loss 0.2142970860004425\n",
      "\n",
      "episode 8, val func loss 0.17700481414794922\n",
      "\n",
      "episode 9, val func loss 0.19345517456531525\n",
      "\n",
      "episode 10, val func loss 0.17050138115882874\n",
      "\n",
      "episode 11, val func loss 0.19212882220745087\n",
      "\n",
      "episode 12, val func loss 0.21628828346729279\n",
      "\n",
      "episode 13, val func loss 0.2331089824438095\n",
      "\n",
      "episode 14, val func loss 0.1583695411682129\n",
      "\n",
      "episode 15, val func loss 0.20162898302078247\n",
      "\n",
      "episode 16, val func loss 0.19076716899871826\n",
      "\n",
      "Val func train loss in epoch 11:0.19554879888892174\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.21614311635494232\n",
      "\n",
      "episode 2, val func loss 0.168675035238266\n",
      "\n",
      "episode 3, val func loss 0.22679921984672546\n",
      "\n",
      "episode 4, val func loss 0.13731186091899872\n",
      "\n",
      "episode 5, val func loss 0.1931266188621521\n",
      "\n",
      "episode 6, val func loss 0.20626987516880035\n",
      "\n",
      "episode 7, val func loss 0.1905355453491211\n",
      "\n",
      "episode 8, val func loss 0.20082582533359528\n",
      "\n",
      "episode 9, val func loss 0.1811361163854599\n",
      "\n",
      "episode 10, val func loss 0.1590072065591812\n",
      "\n",
      "episode 11, val func loss 0.19097183644771576\n",
      "\n",
      "episode 12, val func loss 0.21875597536563873\n",
      "\n",
      "episode 13, val func loss 0.2118152230978012\n",
      "\n",
      "episode 14, val func loss 0.17607370018959045\n",
      "\n",
      "episode 15, val func loss 0.23218250274658203\n",
      "\n",
      "episode 16, val func loss 0.2141505926847458\n",
      "\n",
      "Val func train loss in epoch 12:0.19523626565933228\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18988680839538574\n",
      "\n",
      "episode 2, val func loss 0.2156452089548111\n",
      "\n",
      "episode 3, val func loss 0.18239501118659973\n",
      "\n",
      "episode 4, val func loss 0.17359955608844757\n",
      "\n",
      "episode 5, val func loss 0.20081551373004913\n",
      "\n",
      "episode 6, val func loss 0.14201682806015015\n",
      "\n",
      "episode 7, val func loss 0.2253819853067398\n",
      "\n",
      "episode 8, val func loss 0.21415148675441742\n",
      "\n",
      "episode 9, val func loss 0.19152821600437164\n",
      "\n",
      "episode 10, val func loss 0.20632880926132202\n",
      "\n",
      "episode 11, val func loss 0.21652533113956451\n",
      "\n",
      "episode 12, val func loss 0.17621663212776184\n",
      "\n",
      "episode 13, val func loss 0.19313430786132812\n",
      "\n",
      "episode 14, val func loss 0.21266399323940277\n",
      "\n",
      "episode 15, val func loss 0.23339174687862396\n",
      "\n",
      "episode 16, val func loss 0.15858584642410278\n",
      "\n",
      "Val func train loss in epoch 13:0.1957667050883174\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18992729485034943\n",
      "\n",
      "episode 2, val func loss 0.23197977244853973\n",
      "\n",
      "episode 3, val func loss 0.19348250329494476\n",
      "\n",
      "episode 4, val func loss 0.21402597427368164\n",
      "\n",
      "episode 5, val func loss 0.17190898954868317\n",
      "\n",
      "episode 6, val func loss 0.20090273022651672\n",
      "\n",
      "episode 7, val func loss 0.16155801713466644\n",
      "\n",
      "episode 8, val func loss 0.1813744306564331\n",
      "\n",
      "episode 9, val func loss 0.22554829716682434\n",
      "\n",
      "episode 10, val func loss 0.20656880736351013\n",
      "\n",
      "episode 11, val func loss 0.19123321771621704\n",
      "\n",
      "episode 12, val func loss 0.21852105855941772\n",
      "\n",
      "episode 13, val func loss 0.216184601187706\n",
      "\n",
      "episode 14, val func loss 0.2118167132139206\n",
      "\n",
      "episode 15, val func loss 0.176741361618042\n",
      "\n",
      "episode 16, val func loss 0.13839083909988403\n",
      "\n",
      "Val func train loss in epoch 14:0.19563528802245855\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.23192466795444489\n",
      "\n",
      "episode 2, val func loss 0.21420039236545563\n",
      "\n",
      "episode 3, val func loss 0.16970938444137573\n",
      "\n",
      "episode 4, val func loss 0.15938976407051086\n",
      "\n",
      "episode 5, val func loss 0.22681403160095215\n",
      "\n",
      "episode 6, val func loss 0.18099051713943481\n",
      "\n",
      "episode 7, val func loss 0.21829195320606232\n",
      "\n",
      "episode 8, val func loss 0.1929371953010559\n",
      "\n",
      "episode 9, val func loss 0.17643672227859497\n",
      "\n",
      "episode 10, val func loss 0.21596257388591766\n",
      "\n",
      "episode 11, val func loss 0.19162654876708984\n",
      "\n",
      "episode 12, val func loss 0.20090366899967194\n",
      "\n",
      "episode 13, val func loss 0.21123896539211273\n",
      "\n",
      "episode 14, val func loss 0.19003602862358093\n",
      "\n",
      "episode 15, val func loss 0.13958071172237396\n",
      "\n",
      "episode 16, val func loss 0.20640331506729126\n",
      "\n",
      "Val func train loss in epoch 15:0.19540290255099535\n",
      "***********************TIME WAS 4.966905264059703 min*****************************\n",
      "\n",
      "**********************ROUND 88 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.05005113407969475\n",
      "\n",
      "episode 2, policy loss -0.06275556981563568\n",
      "\n",
      "episode 3, policy loss -0.034302785992622375\n",
      "\n",
      "episode 4, policy loss -0.04704594239592552\n",
      "\n",
      "episode 5, policy loss -0.007794585544615984\n",
      "\n",
      "episode 6, policy loss -0.019429821521043777\n",
      "\n",
      "episode 7, policy loss -0.0432894192636013\n",
      "\n",
      "episode 8, policy loss 0.011300877667963505\n",
      "\n",
      "episode 9, policy loss -0.05276995524764061\n",
      "\n",
      "episode 10, policy loss -0.029518062248826027\n",
      "\n",
      "episode 11, policy loss -0.040839508175849915\n",
      "\n",
      "episode 12, policy loss -0.024197285994887352\n",
      "\n",
      "episode 13, policy loss -0.0016666718292981386\n",
      "\n",
      "episode 14, policy loss -0.013437536545097828\n",
      "\n",
      "episode 15, policy loss -0.006753814406692982\n",
      "\n",
      "episode 16, policy loss -0.0506332628428936\n",
      "\n",
      "Policy train loss in epoch 0:-0.029574029889772646\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.009811628609895706\n",
      "\n",
      "episode 2, policy loss -0.037742454558610916\n",
      "\n",
      "episode 3, policy loss -0.05149492621421814\n",
      "\n",
      "episode 4, policy loss -0.00761419115588069\n",
      "\n",
      "episode 5, policy loss -0.06324570626020432\n",
      "\n",
      "episode 6, policy loss -0.01919453777372837\n",
      "\n",
      "episode 7, policy loss -0.0029438859783113003\n",
      "\n",
      "episode 8, policy loss -0.04305968061089516\n",
      "\n",
      "episode 9, policy loss -0.008430920541286469\n",
      "\n",
      "episode 10, policy loss -0.033170152455568314\n",
      "\n",
      "episode 11, policy loss -0.04400341585278511\n",
      "\n",
      "episode 12, policy loss -0.07551620900630951\n",
      "\n",
      "episode 13, policy loss -0.024471959099173546\n",
      "\n",
      "episode 14, policy loss -0.04937945306301117\n",
      "\n",
      "episode 15, policy loss -0.016465552151203156\n",
      "\n",
      "episode 16, policy loss -0.05549747869372368\n",
      "\n",
      "Policy train loss in epoch 1:-0.03265118092531338\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.016408296301960945\n",
      "\n",
      "episode 2, policy loss -0.03697327524423599\n",
      "\n",
      "episode 3, policy loss -0.05009274184703827\n",
      "\n",
      "episode 4, policy loss -0.05526277795433998\n",
      "\n",
      "episode 5, policy loss -0.003966282121837139\n",
      "\n",
      "episode 6, policy loss -0.02641485072672367\n",
      "\n",
      "episode 7, policy loss -0.07507068663835526\n",
      "\n",
      "episode 8, policy loss -0.01942206174135208\n",
      "\n",
      "episode 9, policy loss 0.009484388865530491\n",
      "\n",
      "episode 10, policy loss -0.05219780281186104\n",
      "\n",
      "episode 11, policy loss -0.00881341751664877\n",
      "\n",
      "episode 12, policy loss -0.033606257289648056\n",
      "\n",
      "episode 13, policy loss -0.007685037795454264\n",
      "\n",
      "episode 14, policy loss -0.04342205822467804\n",
      "\n",
      "episode 15, policy loss -0.0427880696952343\n",
      "\n",
      "episode 16, policy loss -0.06314292550086975\n",
      "\n",
      "Policy train loss in epoch 2:-0.03286138453404419\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.05191446468234062\n",
      "\n",
      "episode 2, policy loss -0.04466964304447174\n",
      "\n",
      "episode 3, policy loss -0.025969207286834717\n",
      "\n",
      "episode 4, policy loss -0.006888031493872404\n",
      "\n",
      "episode 5, policy loss -0.0542505644261837\n",
      "\n",
      "episode 6, policy loss 0.00970440823584795\n",
      "\n",
      "episode 7, policy loss -0.050659533590078354\n",
      "\n",
      "episode 8, policy loss -0.038060322403907776\n",
      "\n",
      "episode 9, policy loss -0.008872882463037968\n",
      "\n",
      "episode 10, policy loss -0.07423945516347885\n",
      "\n",
      "episode 11, policy loss -0.0336361899971962\n",
      "\n",
      "episode 12, policy loss -0.043087366968393326\n",
      "\n",
      "episode 13, policy loss -0.019267339259386063\n",
      "\n",
      "episode 14, policy loss -0.06312690675258636\n",
      "\n",
      "episode 15, policy loss -0.0033213524147868156\n",
      "\n",
      "episode 16, policy loss -0.016159377992153168\n",
      "\n",
      "Policy train loss in epoch 3:-0.03277613935642876\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19075627624988556\n",
      "\n",
      "episode 2, val func loss 0.1987488865852356\n",
      "\n",
      "episode 3, val func loss 0.2026093602180481\n",
      "\n",
      "episode 4, val func loss 0.18170274794101715\n",
      "\n",
      "episode 5, val func loss 0.19907043874263763\n",
      "\n",
      "episode 6, val func loss 0.17861774563789368\n",
      "\n",
      "episode 7, val func loss 0.18159891664981842\n",
      "\n",
      "episode 8, val func loss 0.20838090777397156\n",
      "\n",
      "episode 9, val func loss 0.19490644335746765\n",
      "\n",
      "episode 10, val func loss 0.19640682637691498\n",
      "\n",
      "episode 11, val func loss 0.18662336468696594\n",
      "\n",
      "episode 12, val func loss 0.19749434292316437\n",
      "\n",
      "episode 13, val func loss 0.1761315017938614\n",
      "\n",
      "episode 14, val func loss 0.20640049874782562\n",
      "\n",
      "episode 15, val func loss 0.19866184890270233\n",
      "\n",
      "episode 16, val func loss 0.20101980865001678\n",
      "\n",
      "Val func train loss in epoch 0:0.19369561970233917\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1870104819536209\n",
      "\n",
      "episode 2, val func loss 0.18206743896007538\n",
      "\n",
      "episode 3, val func loss 0.19835332036018372\n",
      "\n",
      "episode 4, val func loss 0.2029077261686325\n",
      "\n",
      "episode 5, val func loss 0.19912095367908478\n",
      "\n",
      "episode 6, val func loss 0.17654301226139069\n",
      "\n",
      "episode 7, val func loss 0.19797269999980927\n",
      "\n",
      "episode 8, val func loss 0.17874950170516968\n",
      "\n",
      "episode 9, val func loss 0.19159772992134094\n",
      "\n",
      "episode 10, val func loss 0.19837267696857452\n",
      "\n",
      "episode 11, val func loss 0.18133781850337982\n",
      "\n",
      "episode 12, val func loss 0.19663836061954498\n",
      "\n",
      "episode 13, val func loss 0.20189502835273743\n",
      "\n",
      "episode 14, val func loss 0.19489526748657227\n",
      "\n",
      "episode 15, val func loss 0.20582108199596405\n",
      "\n",
      "episode 16, val func loss 0.20711278915405273\n",
      "\n",
      "Val func train loss in epoch 1:0.19377474300563335\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19974781572818756\n",
      "\n",
      "episode 2, val func loss 0.1841665357351303\n",
      "\n",
      "episode 3, val func loss 0.19113053381443024\n",
      "\n",
      "episode 4, val func loss 0.19625991582870483\n",
      "\n",
      "episode 5, val func loss 0.19904224574565887\n",
      "\n",
      "episode 6, val func loss 0.19466662406921387\n",
      "\n",
      "episode 7, val func loss 0.20696277916431427\n",
      "\n",
      "episode 8, val func loss 0.18757443130016327\n",
      "\n",
      "episode 9, val func loss 0.19923724234104156\n",
      "\n",
      "episode 10, val func loss 0.19914261996746063\n",
      "\n",
      "episode 11, val func loss 0.17539845407009125\n",
      "\n",
      "episode 12, val func loss 0.20767894387245178\n",
      "\n",
      "episode 13, val func loss 0.1810704618692398\n",
      "\n",
      "episode 14, val func loss 0.20337359607219696\n",
      "\n",
      "episode 15, val func loss 0.17878299951553345\n",
      "\n",
      "episode 16, val func loss 0.19849056005477905\n",
      "\n",
      "Val func train loss in epoch 2:0.19392035994678736\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18656380474567413\n",
      "\n",
      "episode 2, val func loss 0.1964579075574875\n",
      "\n",
      "episode 3, val func loss 0.18171334266662598\n",
      "\n",
      "episode 4, val func loss 0.20276236534118652\n",
      "\n",
      "episode 5, val func loss 0.19760537147521973\n",
      "\n",
      "episode 6, val func loss 0.19479264318943024\n",
      "\n",
      "episode 7, val func loss 0.19102303683757782\n",
      "\n",
      "episode 8, val func loss 0.19888703525066376\n",
      "\n",
      "episode 9, val func loss 0.20501115918159485\n",
      "\n",
      "episode 10, val func loss 0.1788778156042099\n",
      "\n",
      "episode 11, val func loss 0.18311451375484467\n",
      "\n",
      "episode 12, val func loss 0.19905318319797516\n",
      "\n",
      "episode 13, val func loss 0.19888849556446075\n",
      "\n",
      "episode 14, val func loss 0.20221184194087982\n",
      "\n",
      "episode 15, val func loss 0.20854254066944122\n",
      "\n",
      "episode 16, val func loss 0.17889076471328735\n",
      "\n",
      "Val func train loss in epoch 3:0.19402473885565996\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18125605583190918\n",
      "\n",
      "episode 2, val func loss 0.20829768478870392\n",
      "\n",
      "episode 3, val func loss 0.20129208266735077\n",
      "\n",
      "episode 4, val func loss 0.17895649373531342\n",
      "\n",
      "episode 5, val func loss 0.1992574781179428\n",
      "\n",
      "episode 6, val func loss 0.1990027278661728\n",
      "\n",
      "episode 7, val func loss 0.176690936088562\n",
      "\n",
      "episode 8, val func loss 0.19796323776245117\n",
      "\n",
      "episode 9, val func loss 0.1912749707698822\n",
      "\n",
      "episode 10, val func loss 0.20650982856750488\n",
      "\n",
      "episode 11, val func loss 0.19556882977485657\n",
      "\n",
      "episode 12, val func loss 0.1812044233083725\n",
      "\n",
      "episode 13, val func loss 0.19435136020183563\n",
      "\n",
      "episode 14, val func loss 0.20279215276241302\n",
      "\n",
      "episode 15, val func loss 0.19858798384666443\n",
      "\n",
      "episode 16, val func loss 0.18742448091506958\n",
      "\n",
      "Val func train loss in epoch 4:0.1937769204378128\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19858136773109436\n",
      "\n",
      "episode 2, val func loss 0.17914755642414093\n",
      "\n",
      "episode 3, val func loss 0.19089019298553467\n",
      "\n",
      "episode 4, val func loss 0.2028060257434845\n",
      "\n",
      "episode 5, val func loss 0.19897326827049255\n",
      "\n",
      "episode 6, val func loss 0.2006550133228302\n",
      "\n",
      "episode 7, val func loss 0.19544917345046997\n",
      "\n",
      "episode 8, val func loss 0.17744077742099762\n",
      "\n",
      "episode 9, val func loss 0.1946403980255127\n",
      "\n",
      "episode 10, val func loss 0.20508363842964172\n",
      "\n",
      "episode 11, val func loss 0.18267059326171875\n",
      "\n",
      "episode 12, val func loss 0.18733470141887665\n",
      "\n",
      "episode 13, val func loss 0.18123412132263184\n",
      "\n",
      "episode 14, val func loss 0.20803295075893402\n",
      "\n",
      "episode 15, val func loss 0.19876806437969208\n",
      "\n",
      "episode 16, val func loss 0.1981704980134964\n",
      "\n",
      "Val func train loss in epoch 5:0.1937423963099718\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18092197179794312\n",
      "\n",
      "episode 2, val func loss 0.19735684990882874\n",
      "\n",
      "episode 3, val func loss 0.20862127840518951\n",
      "\n",
      "episode 4, val func loss 0.17826665937900543\n",
      "\n",
      "episode 5, val func loss 0.19855128228664398\n",
      "\n",
      "episode 6, val func loss 0.19909946620464325\n",
      "\n",
      "episode 7, val func loss 0.19059538841247559\n",
      "\n",
      "episode 8, val func loss 0.17909564077854156\n",
      "\n",
      "episode 9, val func loss 0.19472099840641022\n",
      "\n",
      "episode 10, val func loss 0.20559324324131012\n",
      "\n",
      "episode 11, val func loss 0.19948068261146545\n",
      "\n",
      "episode 12, val func loss 0.19794796407222748\n",
      "\n",
      "episode 13, val func loss 0.18647626042366028\n",
      "\n",
      "episode 14, val func loss 0.2019033282995224\n",
      "\n",
      "episode 15, val func loss 0.18111227452754974\n",
      "\n",
      "episode 16, val func loss 0.20289212465286255\n",
      "\n",
      "Val func train loss in epoch 6:0.19391471333801746\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18119733035564423\n",
      "\n",
      "episode 2, val func loss 0.19517973065376282\n",
      "\n",
      "episode 3, val func loss 0.17884628474712372\n",
      "\n",
      "episode 4, val func loss 0.17523758113384247\n",
      "\n",
      "episode 5, val func loss 0.19842804968357086\n",
      "\n",
      "episode 6, val func loss 0.20328006148338318\n",
      "\n",
      "episode 7, val func loss 0.19782930612564087\n",
      "\n",
      "episode 8, val func loss 0.2024039775133133\n",
      "\n",
      "episode 9, val func loss 0.2077833116054535\n",
      "\n",
      "episode 10, val func loss 0.19925127923488617\n",
      "\n",
      "episode 11, val func loss 0.20530498027801514\n",
      "\n",
      "episode 12, val func loss 0.18391628563404083\n",
      "\n",
      "episode 13, val func loss 0.18975920975208282\n",
      "\n",
      "episode 14, val func loss 0.19064393639564514\n",
      "\n",
      "episode 15, val func loss 0.19845308363437653\n",
      "\n",
      "episode 16, val func loss 0.19502946734428406\n",
      "\n",
      "Val func train loss in epoch 7:0.1939089922234416\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.19113260507583618\n",
      "\n",
      "episode 2, val func loss 0.18239310383796692\n",
      "\n",
      "episode 3, val func loss 0.18179182708263397\n",
      "\n",
      "episode 4, val func loss 0.19924518465995789\n",
      "\n",
      "episode 5, val func loss 0.20721335709095\n",
      "\n",
      "episode 6, val func loss 0.1867583990097046\n",
      "\n",
      "episode 7, val func loss 0.1992671638727188\n",
      "\n",
      "episode 8, val func loss 0.20122306048870087\n",
      "\n",
      "episode 9, val func loss 0.20747512578964233\n",
      "\n",
      "episode 10, val func loss 0.17867237329483032\n",
      "\n",
      "episode 11, val func loss 0.19974036514759064\n",
      "\n",
      "episode 12, val func loss 0.19482670724391937\n",
      "\n",
      "episode 13, val func loss 0.1980358213186264\n",
      "\n",
      "episode 14, val func loss 0.20291858911514282\n",
      "\n",
      "episode 15, val func loss 0.17876677215099335\n",
      "\n",
      "episode 16, val func loss 0.19456516206264496\n",
      "\n",
      "Val func train loss in epoch 8:0.19400160107761621\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1813828945159912\n",
      "\n",
      "episode 2, val func loss 0.20729221403598785\n",
      "\n",
      "episode 3, val func loss 0.1950843334197998\n",
      "\n",
      "episode 4, val func loss 0.19159597158432007\n",
      "\n",
      "episode 5, val func loss 0.20683355629444122\n",
      "\n",
      "episode 6, val func loss 0.19487597048282623\n",
      "\n",
      "episode 7, val func loss 0.18158701062202454\n",
      "\n",
      "episode 8, val func loss 0.18286249041557312\n",
      "\n",
      "episode 9, val func loss 0.19932371377944946\n",
      "\n",
      "episode 10, val func loss 0.178894504904747\n",
      "\n",
      "episode 11, val func loss 0.19825178384780884\n",
      "\n",
      "episode 12, val func loss 0.20030687749385834\n",
      "\n",
      "episode 13, val func loss 0.20450665056705475\n",
      "\n",
      "episode 14, val func loss 0.18682458996772766\n",
      "\n",
      "episode 15, val func loss 0.1990465670824051\n",
      "\n",
      "episode 16, val func loss 0.19964005053043365\n",
      "\n",
      "Val func train loss in epoch 9:0.19426932372152805\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20181892812252045\n",
      "\n",
      "episode 2, val func loss 0.19154930114746094\n",
      "\n",
      "episode 3, val func loss 0.1945922076702118\n",
      "\n",
      "episode 4, val func loss 0.1988113969564438\n",
      "\n",
      "episode 5, val func loss 0.19930800795555115\n",
      "\n",
      "episode 6, val func loss 0.2037842869758606\n",
      "\n",
      "episode 7, val func loss 0.20879071950912476\n",
      "\n",
      "episode 8, val func loss 0.1813930869102478\n",
      "\n",
      "episode 9, val func loss 0.18672417104244232\n",
      "\n",
      "episode 10, val func loss 0.20141655206680298\n",
      "\n",
      "episode 11, val func loss 0.17886392772197723\n",
      "\n",
      "episode 12, val func loss 0.17662912607192993\n",
      "\n",
      "episode 13, val func loss 0.19757570326328278\n",
      "\n",
      "episode 14, val func loss 0.20618616044521332\n",
      "\n",
      "episode 15, val func loss 0.18161731958389282\n",
      "\n",
      "episode 16, val func loss 0.19476482272148132\n",
      "\n",
      "Val func train loss in epoch 10:0.19398910738527775\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.20109823346138\n",
      "\n",
      "episode 2, val func loss 0.17882180213928223\n",
      "\n",
      "episode 3, val func loss 0.1984788477420807\n",
      "\n",
      "episode 4, val func loss 0.177405446767807\n",
      "\n",
      "episode 5, val func loss 0.18234629929065704\n",
      "\n",
      "episode 6, val func loss 0.18164479732513428\n",
      "\n",
      "episode 7, val func loss 0.1981571912765503\n",
      "\n",
      "episode 8, val func loss 0.20894622802734375\n",
      "\n",
      "episode 9, val func loss 0.20806308090686798\n",
      "\n",
      "episode 10, val func loss 0.1981102079153061\n",
      "\n",
      "episode 11, val func loss 0.1947484314441681\n",
      "\n",
      "episode 12, val func loss 0.19091536104679108\n",
      "\n",
      "episode 13, val func loss 0.20331726968288422\n",
      "\n",
      "episode 14, val func loss 0.19911152124404907\n",
      "\n",
      "episode 15, val func loss 0.19446435570716858\n",
      "\n",
      "episode 16, val func loss 0.1887461394071579\n",
      "\n",
      "Val func train loss in epoch 11:0.19402345083653927\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1945154368877411\n",
      "\n",
      "episode 2, val func loss 0.18814948201179504\n",
      "\n",
      "episode 3, val func loss 0.19101788103580475\n",
      "\n",
      "episode 4, val func loss 0.19866342842578888\n",
      "\n",
      "episode 5, val func loss 0.2079138606786728\n",
      "\n",
      "episode 6, val func loss 0.19448745250701904\n",
      "\n",
      "episode 7, val func loss 0.18161259591579437\n",
      "\n",
      "episode 8, val func loss 0.20303167402744293\n",
      "\n",
      "episode 9, val func loss 0.1989944726228714\n",
      "\n",
      "episode 10, val func loss 0.1813087910413742\n",
      "\n",
      "episode 11, val func loss 0.2067212015390396\n",
      "\n",
      "episode 12, val func loss 0.20123793184757233\n",
      "\n",
      "episode 13, val func loss 0.19899021089076996\n",
      "\n",
      "episode 14, val func loss 0.17924794554710388\n",
      "\n",
      "episode 15, val func loss 0.17627830803394318\n",
      "\n",
      "episode 16, val func loss 0.1975029706954956\n",
      "\n",
      "Val func train loss in epoch 12:0.19372960273176432\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1988065540790558\n",
      "\n",
      "episode 2, val func loss 0.19773901998996735\n",
      "\n",
      "episode 3, val func loss 0.17476695775985718\n",
      "\n",
      "episode 4, val func loss 0.1865828037261963\n",
      "\n",
      "episode 5, val func loss 0.20430710911750793\n",
      "\n",
      "episode 6, val func loss 0.19546423852443695\n",
      "\n",
      "episode 7, val func loss 0.18132981657981873\n",
      "\n",
      "episode 8, val func loss 0.1785513013601303\n",
      "\n",
      "episode 9, val func loss 0.19637688994407654\n",
      "\n",
      "episode 10, val func loss 0.20666508376598358\n",
      "\n",
      "episode 11, val func loss 0.19829048216342926\n",
      "\n",
      "episode 12, val func loss 0.19068589806556702\n",
      "\n",
      "episode 13, val func loss 0.18572382628917694\n",
      "\n",
      "episode 14, val func loss 0.20767855644226074\n",
      "\n",
      "episode 15, val func loss 0.19935038685798645\n",
      "\n",
      "episode 16, val func loss 0.19982698559761047\n",
      "\n",
      "Val func train loss in epoch 13:0.19388411939144135\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19980525970458984\n",
      "\n",
      "episode 2, val func loss 0.18250083923339844\n",
      "\n",
      "episode 3, val func loss 0.2012198120355606\n",
      "\n",
      "episode 4, val func loss 0.19182512164115906\n",
      "\n",
      "episode 5, val func loss 0.1976197361946106\n",
      "\n",
      "episode 6, val func loss 0.19627733528614044\n",
      "\n",
      "episode 7, val func loss 0.19939617812633514\n",
      "\n",
      "episode 8, val func loss 0.1758037656545639\n",
      "\n",
      "episode 9, val func loss 0.18145263195037842\n",
      "\n",
      "episode 10, val func loss 0.17859500646591187\n",
      "\n",
      "episode 11, val func loss 0.1982421875\n",
      "\n",
      "episode 12, val func loss 0.18692339956760406\n",
      "\n",
      "episode 13, val func loss 0.20347322523593903\n",
      "\n",
      "episode 14, val func loss 0.20745070278644562\n",
      "\n",
      "episode 15, val func loss 0.19506984949111938\n",
      "\n",
      "episode 16, val func loss 0.20806366205215454\n",
      "\n",
      "Val func train loss in epoch 14:0.19398241955786943\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19873476028442383\n",
      "\n",
      "episode 2, val func loss 0.19873279333114624\n",
      "\n",
      "episode 3, val func loss 0.20027194917201996\n",
      "\n",
      "episode 4, val func loss 0.17845915257930756\n",
      "\n",
      "episode 5, val func loss 0.19815295934677124\n",
      "\n",
      "episode 6, val func loss 0.20766480267047882\n",
      "\n",
      "episode 7, val func loss 0.18146613240242004\n",
      "\n",
      "episode 8, val func loss 0.1865517646074295\n",
      "\n",
      "episode 9, val func loss 0.20396266877651215\n",
      "\n",
      "episode 10, val func loss 0.20873995125293732\n",
      "\n",
      "episode 11, val func loss 0.19254237413406372\n",
      "\n",
      "episode 12, val func loss 0.1951649785041809\n",
      "\n",
      "episode 13, val func loss 0.17868933081626892\n",
      "\n",
      "episode 14, val func loss 0.20063112676143646\n",
      "\n",
      "episode 15, val func loss 0.19497162103652954\n",
      "\n",
      "episode 16, val func loss 0.1837446391582489\n",
      "\n",
      "Val func train loss in epoch 15:0.19428006280213594\n",
      "***********************TIME WAS 4.970680809020996 min*****************************\n",
      "\n",
      "**********************ROUND 89 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.0049544889479875565\n",
      "\n",
      "episode 2, policy loss -0.005440116859972477\n",
      "\n",
      "episode 3, policy loss -0.0063814809545874596\n",
      "\n",
      "episode 4, policy loss 0.038077764213085175\n",
      "\n",
      "episode 5, policy loss -0.04491226002573967\n",
      "\n",
      "episode 6, policy loss 0.010293830186128616\n",
      "\n",
      "episode 7, policy loss -0.016600187867879868\n",
      "\n",
      "episode 8, policy loss 0.003311818465590477\n",
      "\n",
      "episode 9, policy loss 0.01596338488161564\n",
      "\n",
      "episode 10, policy loss -0.07395419478416443\n",
      "\n",
      "episode 11, policy loss -0.018071144819259644\n",
      "\n",
      "episode 12, policy loss -0.05885479971766472\n",
      "\n",
      "episode 13, policy loss -0.003937209490686655\n",
      "\n",
      "episode 14, policy loss 0.033236194401979446\n",
      "\n",
      "episode 15, policy loss 0.002837789012119174\n",
      "\n",
      "episode 16, policy loss -0.017247222363948822\n",
      "\n",
      "Policy train loss in epoch 0:-0.009164520291960798\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.01072071772068739\n",
      "\n",
      "episode 2, policy loss -0.010392189025878906\n",
      "\n",
      "episode 3, policy loss 0.01298476941883564\n",
      "\n",
      "episode 4, policy loss -0.06179678812623024\n",
      "\n",
      "episode 5, policy loss -0.047950223088264465\n",
      "\n",
      "episode 6, policy loss -0.020469151437282562\n",
      "\n",
      "episode 7, policy loss -0.003525066887959838\n",
      "\n",
      "episode 8, policy loss 0.0052958461456000805\n",
      "\n",
      "episode 9, policy loss -0.015987850725650787\n",
      "\n",
      "episode 10, policy loss 0.008361456915736198\n",
      "\n",
      "episode 11, policy loss 0.03396013751626015\n",
      "\n",
      "episode 12, policy loss -0.07967306673526764\n",
      "\n",
      "episode 13, policy loss 0.03598974645137787\n",
      "\n",
      "episode 14, policy loss -0.018522189930081367\n",
      "\n",
      "episode 15, policy loss 0.0039881193079054356\n",
      "\n",
      "episode 16, policy loss -0.020177725702524185\n",
      "\n",
      "Policy train loss in epoch 1:-0.011789680851507\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.020674094557762146\n",
      "\n",
      "episode 2, policy loss -0.012975363060832024\n",
      "\n",
      "episode 3, policy loss -0.07646060734987259\n",
      "\n",
      "episode 4, policy loss 0.013032651506364346\n",
      "\n",
      "episode 5, policy loss 0.03548178821802139\n",
      "\n",
      "episode 6, policy loss 0.03232703357934952\n",
      "\n",
      "episode 7, policy loss -0.012774444185197353\n",
      "\n",
      "episode 8, policy loss 0.008364812470972538\n",
      "\n",
      "episode 9, policy loss -0.01948443241417408\n",
      "\n",
      "episode 10, policy loss 0.0043245358392596245\n",
      "\n",
      "episode 11, policy loss 0.0025295522063970566\n",
      "\n",
      "episode 12, policy loss -0.04717057943344116\n",
      "\n",
      "episode 13, policy loss -0.021001527085900307\n",
      "\n",
      "episode 14, policy loss -0.00514140073210001\n",
      "\n",
      "episode 15, policy loss -0.06218057870864868\n",
      "\n",
      "episode 16, policy loss -0.016351228579878807\n",
      "\n",
      "Policy train loss in epoch 2:-0.012384617642965168\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.005269819870591164\n",
      "\n",
      "episode 2, policy loss -0.020637013018131256\n",
      "\n",
      "episode 3, policy loss 0.032397352159023285\n",
      "\n",
      "episode 4, policy loss -0.013434355147182941\n",
      "\n",
      "episode 5, policy loss 0.008252286352217197\n",
      "\n",
      "episode 6, policy loss -0.016971401870250702\n",
      "\n",
      "episode 7, policy loss -0.07871714979410172\n",
      "\n",
      "episode 8, policy loss -0.04832051321864128\n",
      "\n",
      "episode 9, policy loss 0.011549440212547779\n",
      "\n",
      "episode 10, policy loss -0.0622200071811676\n",
      "\n",
      "episode 11, policy loss -0.02089563012123108\n",
      "\n",
      "episode 12, policy loss -0.012901576235890388\n",
      "\n",
      "episode 13, policy loss 0.002830749610438943\n",
      "\n",
      "episode 14, policy loss 0.035606689751148224\n",
      "\n",
      "episode 15, policy loss 0.003967221360653639\n",
      "\n",
      "episode 16, policy loss -0.020443255081772804\n",
      "\n",
      "Policy train loss in epoch 3:-0.012825436380808242\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.221962109208107\n",
      "\n",
      "episode 2, val func loss 0.20257556438446045\n",
      "\n",
      "episode 3, val func loss 0.1784963607788086\n",
      "\n",
      "episode 4, val func loss 0.19035615026950836\n",
      "\n",
      "episode 5, val func loss 0.18292464315891266\n",
      "\n",
      "episode 6, val func loss 0.215219646692276\n",
      "\n",
      "episode 7, val func loss 0.1886359602212906\n",
      "\n",
      "episode 8, val func loss 0.22662542760372162\n",
      "\n",
      "episode 9, val func loss 0.18099793791770935\n",
      "\n",
      "episode 10, val func loss 0.16669276356697083\n",
      "\n",
      "episode 11, val func loss 0.19452767074108124\n",
      "\n",
      "episode 12, val func loss 0.20029988884925842\n",
      "\n",
      "episode 13, val func loss 0.18795548379421234\n",
      "\n",
      "episode 14, val func loss 0.18565896153450012\n",
      "\n",
      "episode 15, val func loss 0.17614644765853882\n",
      "\n",
      "episode 16, val func loss 0.18161365389823914\n",
      "\n",
      "Val func train loss in epoch 0:0.19254304189234972\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19987629354000092\n",
      "\n",
      "episode 2, val func loss 0.1877346932888031\n",
      "\n",
      "episode 3, val func loss 0.18084466457366943\n",
      "\n",
      "episode 4, val func loss 0.2165864109992981\n",
      "\n",
      "episode 5, val func loss 0.22616897523403168\n",
      "\n",
      "episode 6, val func loss 0.18482479453086853\n",
      "\n",
      "episode 7, val func loss 0.17857655882835388\n",
      "\n",
      "episode 8, val func loss 0.18248356878757477\n",
      "\n",
      "episode 9, val func loss 0.20126496255397797\n",
      "\n",
      "episode 10, val func loss 0.22368291020393372\n",
      "\n",
      "episode 11, val func loss 0.18909147381782532\n",
      "\n",
      "episode 12, val func loss 0.1836773008108139\n",
      "\n",
      "episode 13, val func loss 0.16895931959152222\n",
      "\n",
      "episode 14, val func loss 0.1884850263595581\n",
      "\n",
      "episode 15, val func loss 0.19427312910556793\n",
      "\n",
      "episode 16, val func loss 0.1758306920528412\n",
      "\n",
      "Val func train loss in epoch 1:0.19264754839241505\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19013722240924835\n",
      "\n",
      "episode 2, val func loss 0.20167827606201172\n",
      "\n",
      "episode 3, val func loss 0.1892976611852646\n",
      "\n",
      "episode 4, val func loss 0.1806480586528778\n",
      "\n",
      "episode 5, val func loss 0.1854950338602066\n",
      "\n",
      "episode 6, val func loss 0.17575502395629883\n",
      "\n",
      "episode 7, val func loss 0.18753650784492493\n",
      "\n",
      "episode 8, val func loss 0.2261282503604889\n",
      "\n",
      "episode 9, val func loss 0.17745287716388702\n",
      "\n",
      "episode 10, val func loss 0.20064479112625122\n",
      "\n",
      "episode 11, val func loss 0.18176957964897156\n",
      "\n",
      "episode 12, val func loss 0.19355544447898865\n",
      "\n",
      "episode 13, val func loss 0.1809452325105667\n",
      "\n",
      "episode 14, val func loss 0.22581805288791656\n",
      "\n",
      "episode 15, val func loss 0.21566012501716614\n",
      "\n",
      "episode 16, val func loss 0.1691536158323288\n",
      "\n",
      "Val func train loss in epoch 2:0.1926047345623374\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.22564318776130676\n",
      "\n",
      "episode 2, val func loss 0.1809096336364746\n",
      "\n",
      "episode 3, val func loss 0.2006591558456421\n",
      "\n",
      "episode 4, val func loss 0.16859304904937744\n",
      "\n",
      "episode 5, val func loss 0.18466028571128845\n",
      "\n",
      "episode 6, val func loss 0.18131667375564575\n",
      "\n",
      "episode 7, val func loss 0.19478623569011688\n",
      "\n",
      "episode 8, val func loss 0.1763659119606018\n",
      "\n",
      "episode 9, val func loss 0.2022118866443634\n",
      "\n",
      "episode 10, val func loss 0.1906525045633316\n",
      "\n",
      "episode 11, val func loss 0.22982166707515717\n",
      "\n",
      "episode 12, val func loss 0.18918690085411072\n",
      "\n",
      "episode 13, val func loss 0.17629727721214294\n",
      "\n",
      "episode 14, val func loss 0.21518196165561676\n",
      "\n",
      "episode 15, val func loss 0.18749362230300903\n",
      "\n",
      "episode 16, val func loss 0.18403056263923645\n",
      "\n",
      "Val func train loss in epoch 3:0.19298815727233887\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.22199296951293945\n",
      "\n",
      "episode 2, val func loss 0.18634863197803497\n",
      "\n",
      "episode 3, val func loss 0.1903849095106125\n",
      "\n",
      "episode 4, val func loss 0.1943456083536148\n",
      "\n",
      "episode 5, val func loss 0.1774241179227829\n",
      "\n",
      "episode 6, val func loss 0.1857924461364746\n",
      "\n",
      "episode 7, val func loss 0.18119406700134277\n",
      "\n",
      "episode 8, val func loss 0.18990956246852875\n",
      "\n",
      "episode 9, val func loss 0.18150636553764343\n",
      "\n",
      "episode 10, val func loss 0.17569254338741302\n",
      "\n",
      "episode 11, val func loss 0.2165071964263916\n",
      "\n",
      "episode 12, val func loss 0.19973941147327423\n",
      "\n",
      "episode 13, val func loss 0.18722845613956451\n",
      "\n",
      "episode 14, val func loss 0.2254185527563095\n",
      "\n",
      "episode 15, val func loss 0.16895027458667755\n",
      "\n",
      "episode 16, val func loss 0.20074409246444702\n",
      "\n",
      "Val func train loss in epoch 4:0.19269870035350323\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18110856413841248\n",
      "\n",
      "episode 2, val func loss 0.18137383460998535\n",
      "\n",
      "episode 3, val func loss 0.17608216404914856\n",
      "\n",
      "episode 4, val func loss 0.17649564146995544\n",
      "\n",
      "episode 5, val func loss 0.16565082967281342\n",
      "\n",
      "episode 6, val func loss 0.22969436645507812\n",
      "\n",
      "episode 7, val func loss 0.22880437970161438\n",
      "\n",
      "episode 8, val func loss 0.18955017626285553\n",
      "\n",
      "episode 9, val func loss 0.18918085098266602\n",
      "\n",
      "episode 10, val func loss 0.20204345881938934\n",
      "\n",
      "episode 11, val func loss 0.1855691373348236\n",
      "\n",
      "episode 12, val func loss 0.18745045363903046\n",
      "\n",
      "episode 13, val func loss 0.18502625823020935\n",
      "\n",
      "episode 14, val func loss 0.2007230669260025\n",
      "\n",
      "episode 15, val func loss 0.1942705661058426\n",
      "\n",
      "episode 16, val func loss 0.2158159464597702\n",
      "\n",
      "Val func train loss in epoch 5:0.19305248092859983\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18962648510932922\n",
      "\n",
      "episode 2, val func loss 0.17816266417503357\n",
      "\n",
      "episode 3, val func loss 0.20116201043128967\n",
      "\n",
      "episode 4, val func loss 0.19419479370117188\n",
      "\n",
      "episode 5, val func loss 0.1998576521873474\n",
      "\n",
      "episode 6, val func loss 0.21687543392181396\n",
      "\n",
      "episode 7, val func loss 0.17625261843204498\n",
      "\n",
      "episode 8, val func loss 0.16791865229606628\n",
      "\n",
      "episode 9, val func loss 0.18868620693683624\n",
      "\n",
      "episode 10, val func loss 0.18141156435012817\n",
      "\n",
      "episode 11, val func loss 0.18508853018283844\n",
      "\n",
      "episode 12, val func loss 0.18110227584838867\n",
      "\n",
      "episode 13, val func loss 0.18095621466636658\n",
      "\n",
      "episode 14, val func loss 0.18773455917835236\n",
      "\n",
      "episode 15, val func loss 0.22724249958992004\n",
      "\n",
      "episode 16, val func loss 0.22606006264686584\n",
      "\n",
      "Val func train loss in epoch 6:0.19264576397836208\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.20108826458454132\n",
      "\n",
      "episode 2, val func loss 0.18296638131141663\n",
      "\n",
      "episode 3, val func loss 0.19458609819412231\n",
      "\n",
      "episode 4, val func loss 0.18473517894744873\n",
      "\n",
      "episode 5, val func loss 0.18979401886463165\n",
      "\n",
      "episode 6, val func loss 0.1815345287322998\n",
      "\n",
      "episode 7, val func loss 0.2153315395116806\n",
      "\n",
      "episode 8, val func loss 0.17713026702404022\n",
      "\n",
      "episode 9, val func loss 0.2010827362537384\n",
      "\n",
      "episode 10, val func loss 0.1891666054725647\n",
      "\n",
      "episode 11, val func loss 0.22750145196914673\n",
      "\n",
      "episode 12, val func loss 0.16735579073429108\n",
      "\n",
      "episode 13, val func loss 0.17614701390266418\n",
      "\n",
      "episode 14, val func loss 0.182083860039711\n",
      "\n",
      "episode 15, val func loss 0.18763382732868195\n",
      "\n",
      "episode 16, val func loss 0.2267446219921112\n",
      "\n",
      "Val func train loss in epoch 7:0.19280513655394316\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.21606209874153137\n",
      "\n",
      "episode 2, val func loss 0.18465116620063782\n",
      "\n",
      "episode 3, val func loss 0.19404909014701843\n",
      "\n",
      "episode 4, val func loss 0.1887819916009903\n",
      "\n",
      "episode 5, val func loss 0.18739041686058044\n",
      "\n",
      "episode 6, val func loss 0.2011006474494934\n",
      "\n",
      "episode 7, val func loss 0.22538624703884125\n",
      "\n",
      "episode 8, val func loss 0.2015000879764557\n",
      "\n",
      "episode 9, val func loss 0.18930618464946747\n",
      "\n",
      "episode 10, val func loss 0.16892488300800323\n",
      "\n",
      "episode 11, val func loss 0.18152029812335968\n",
      "\n",
      "episode 12, val func loss 0.18114633858203888\n",
      "\n",
      "episode 13, val func loss 0.17625099420547485\n",
      "\n",
      "episode 14, val func loss 0.18302279710769653\n",
      "\n",
      "episode 15, val func loss 0.2346198707818985\n",
      "\n",
      "episode 16, val func loss 0.17648012936115265\n",
      "\n",
      "Val func train loss in epoch 8:0.19313707761466503\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20165438950061798\n",
      "\n",
      "episode 2, val func loss 0.176175057888031\n",
      "\n",
      "episode 3, val func loss 0.22556208074092865\n",
      "\n",
      "episode 4, val func loss 0.20119519531726837\n",
      "\n",
      "episode 5, val func loss 0.22252003848552704\n",
      "\n",
      "episode 6, val func loss 0.1837720274925232\n",
      "\n",
      "episode 7, val func loss 0.19532854855060577\n",
      "\n",
      "episode 8, val func loss 0.18987208604812622\n",
      "\n",
      "episode 9, val func loss 0.18512125313282013\n",
      "\n",
      "episode 10, val func loss 0.17896826565265656\n",
      "\n",
      "episode 11, val func loss 0.18932795524597168\n",
      "\n",
      "episode 12, val func loss 0.18128706514835358\n",
      "\n",
      "episode 13, val func loss 0.1659277230501175\n",
      "\n",
      "episode 14, val func loss 0.22058744728565216\n",
      "\n",
      "episode 15, val func loss 0.18043692409992218\n",
      "\n",
      "episode 16, val func loss 0.1892225444316864\n",
      "\n",
      "Val func train loss in epoch 9:0.19293491262942553\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20177362859249115\n",
      "\n",
      "episode 2, val func loss 0.17632456123828888\n",
      "\n",
      "episode 3, val func loss 0.17604374885559082\n",
      "\n",
      "episode 4, val func loss 0.18079981207847595\n",
      "\n",
      "episode 5, val func loss 0.20009580254554749\n",
      "\n",
      "episode 6, val func loss 0.181112602353096\n",
      "\n",
      "episode 7, val func loss 0.22613798081874847\n",
      "\n",
      "episode 8, val func loss 0.1682852953672409\n",
      "\n",
      "episode 9, val func loss 0.18951860070228577\n",
      "\n",
      "episode 10, val func loss 0.19423821568489075\n",
      "\n",
      "episode 11, val func loss 0.2157091498374939\n",
      "\n",
      "episode 12, val func loss 0.18302810192108154\n",
      "\n",
      "episode 13, val func loss 0.18757015466690063\n",
      "\n",
      "episode 14, val func loss 0.18476125597953796\n",
      "\n",
      "episode 15, val func loss 0.2260206937789917\n",
      "\n",
      "episode 16, val func loss 0.18863292038440704\n",
      "\n",
      "Val func train loss in epoch 10:0.1925032828003168\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18478456139564514\n",
      "\n",
      "episode 2, val func loss 0.22552485764026642\n",
      "\n",
      "episode 3, val func loss 0.17679040133953094\n",
      "\n",
      "episode 4, val func loss 0.22367875277996063\n",
      "\n",
      "episode 5, val func loss 0.16959655284881592\n",
      "\n",
      "episode 6, val func loss 0.1889854520559311\n",
      "\n",
      "episode 7, val func loss 0.2009059637784958\n",
      "\n",
      "episode 8, val func loss 0.18917734920978546\n",
      "\n",
      "episode 9, val func loss 0.18112750351428986\n",
      "\n",
      "episode 10, val func loss 0.17662861943244934\n",
      "\n",
      "episode 11, val func loss 0.19467227160930634\n",
      "\n",
      "episode 12, val func loss 0.18760427832603455\n",
      "\n",
      "episode 13, val func loss 0.18128053843975067\n",
      "\n",
      "episode 14, val func loss 0.21708355844020844\n",
      "\n",
      "episode 15, val func loss 0.18089593946933746\n",
      "\n",
      "episode 16, val func loss 0.20118087530136108\n",
      "\n",
      "Val func train loss in epoch 11:0.19249484222382307\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17649513483047485\n",
      "\n",
      "episode 2, val func loss 0.18057477474212646\n",
      "\n",
      "episode 3, val func loss 0.1669212281703949\n",
      "\n",
      "episode 4, val func loss 0.17569610476493835\n",
      "\n",
      "episode 5, val func loss 0.18763551115989685\n",
      "\n",
      "episode 6, val func loss 0.1894994080066681\n",
      "\n",
      "episode 7, val func loss 0.1812669187784195\n",
      "\n",
      "episode 8, val func loss 0.1808393895626068\n",
      "\n",
      "episode 9, val func loss 0.18919286131858826\n",
      "\n",
      "episode 10, val func loss 0.20183037221431732\n",
      "\n",
      "episode 11, val func loss 0.20035123825073242\n",
      "\n",
      "episode 12, val func loss 0.18504731357097626\n",
      "\n",
      "episode 13, val func loss 0.2161547690629959\n",
      "\n",
      "episode 14, val func loss 0.22443535923957825\n",
      "\n",
      "episode 15, val func loss 0.19432426989078522\n",
      "\n",
      "episode 16, val func loss 0.22498643398284912\n",
      "\n",
      "Val func train loss in epoch 12:0.19220319297164679\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.22506263852119446\n",
      "\n",
      "episode 2, val func loss 0.2156810313463211\n",
      "\n",
      "episode 3, val func loss 0.19065071642398834\n",
      "\n",
      "episode 4, val func loss 0.18345795571804047\n",
      "\n",
      "episode 5, val func loss 0.2030116468667984\n",
      "\n",
      "episode 6, val func loss 0.17096368968486786\n",
      "\n",
      "episode 7, val func loss 0.18267624080181122\n",
      "\n",
      "episode 8, val func loss 0.18772581219673157\n",
      "\n",
      "episode 9, val func loss 0.1760704666376114\n",
      "\n",
      "episode 10, val func loss 0.19205307960510254\n",
      "\n",
      "episode 11, val func loss 0.2019854038953781\n",
      "\n",
      "episode 12, val func loss 0.1828153133392334\n",
      "\n",
      "episode 13, val func loss 0.177499920129776\n",
      "\n",
      "episode 14, val func loss 0.19631236791610718\n",
      "\n",
      "episode 15, val func loss 0.230861634016037\n",
      "\n",
      "episode 16, val func loss 0.18485692143440247\n",
      "\n",
      "Val func train loss in epoch 13:0.1938553024083376\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18389393389225006\n",
      "\n",
      "episode 2, val func loss 0.2226506620645523\n",
      "\n",
      "episode 3, val func loss 0.22527280449867249\n",
      "\n",
      "episode 4, val func loss 0.20461364090442657\n",
      "\n",
      "episode 5, val func loss 0.18680009245872498\n",
      "\n",
      "episode 6, val func loss 0.18633915483951569\n",
      "\n",
      "episode 7, val func loss 0.20324371755123138\n",
      "\n",
      "episode 8, val func loss 0.18219438195228577\n",
      "\n",
      "episode 9, val func loss 0.1871645599603653\n",
      "\n",
      "episode 10, val func loss 0.1899094432592392\n",
      "\n",
      "episode 11, val func loss 0.1944648176431656\n",
      "\n",
      "episode 12, val func loss 0.1663341224193573\n",
      "\n",
      "episode 13, val func loss 0.1901482790708542\n",
      "\n",
      "episode 14, val func loss 0.21918006241321564\n",
      "\n",
      "episode 15, val func loss 0.1761934906244278\n",
      "\n",
      "episode 16, val func loss 0.1761537492275238\n",
      "\n",
      "Val func train loss in epoch 14:0.193409807048738\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.22744125127792358\n",
      "\n",
      "episode 2, val func loss 0.1885005384683609\n",
      "\n",
      "episode 3, val func loss 0.22545796632766724\n",
      "\n",
      "episode 4, val func loss 0.19115684926509857\n",
      "\n",
      "episode 5, val func loss 0.21545743942260742\n",
      "\n",
      "episode 6, val func loss 0.18517063558101654\n",
      "\n",
      "episode 7, val func loss 0.2016175389289856\n",
      "\n",
      "episode 8, val func loss 0.187459796667099\n",
      "\n",
      "episode 9, val func loss 0.17716413736343384\n",
      "\n",
      "episode 10, val func loss 0.16737690567970276\n",
      "\n",
      "episode 11, val func loss 0.20127516984939575\n",
      "\n",
      "episode 12, val func loss 0.18168427050113678\n",
      "\n",
      "episode 13, val func loss 0.19544580578804016\n",
      "\n",
      "episode 14, val func loss 0.18111783266067505\n",
      "\n",
      "episode 15, val func loss 0.18085747957229614\n",
      "\n",
      "episode 16, val func loss 0.17599114775657654\n",
      "\n",
      "Val func train loss in epoch 15:0.192698422819376\n",
      "***********************TIME WAS 4.990842759609222 min*****************************\n",
      "\n",
      "**********************ROUND 90 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.05347426235675812\n",
      "\n",
      "episode 2, policy loss -0.08744737505912781\n",
      "\n",
      "episode 3, policy loss -0.0788353905081749\n",
      "\n",
      "episode 4, policy loss -0.027639921754598618\n",
      "\n",
      "episode 5, policy loss -0.08637240529060364\n",
      "\n",
      "episode 6, policy loss -0.053826309740543365\n",
      "\n",
      "episode 7, policy loss -0.016252797096967697\n",
      "\n",
      "episode 8, policy loss -0.07272939383983612\n",
      "\n",
      "episode 9, policy loss -0.06320087611675262\n",
      "\n",
      "episode 10, policy loss -0.11953185498714447\n",
      "\n",
      "episode 11, policy loss -0.07374565303325653\n",
      "\n",
      "episode 12, policy loss -0.0074442969635128975\n",
      "\n",
      "episode 13, policy loss -0.11936292052268982\n",
      "\n",
      "episode 14, policy loss -0.10005819797515869\n",
      "\n",
      "episode 15, policy loss -0.07900732755661011\n",
      "\n",
      "episode 16, policy loss -0.051983948796987534\n",
      "\n",
      "Policy train loss in epoch 0:-0.06818205822492018\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.010525856167078018\n",
      "\n",
      "episode 2, policy loss -0.05444267764687538\n",
      "\n",
      "episode 3, policy loss -0.10155300796031952\n",
      "\n",
      "episode 4, policy loss -0.06506755948066711\n",
      "\n",
      "episode 5, policy loss -0.05043400451540947\n",
      "\n",
      "episode 6, policy loss -0.12038840353488922\n",
      "\n",
      "episode 7, policy loss -0.0166766420006752\n",
      "\n",
      "episode 8, policy loss -0.0790262371301651\n",
      "\n",
      "episode 9, policy loss -0.12269576638936996\n",
      "\n",
      "episode 10, policy loss -0.06382088363170624\n",
      "\n",
      "episode 11, policy loss -0.07631364464759827\n",
      "\n",
      "episode 12, policy loss -0.09185748547315598\n",
      "\n",
      "episode 13, policy loss -0.09244316071271896\n",
      "\n",
      "episode 14, policy loss -0.07336792349815369\n",
      "\n",
      "episode 15, policy loss -0.08394484966993332\n",
      "\n",
      "episode 16, policy loss -0.03327794373035431\n",
      "\n",
      "Policy train loss in epoch 1:-0.07098975288681686\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.07400313019752502\n",
      "\n",
      "episode 2, policy loss -0.12162957340478897\n",
      "\n",
      "episode 3, policy loss -0.1227521225810051\n",
      "\n",
      "episode 4, policy loss -0.09468775242567062\n",
      "\n",
      "episode 5, policy loss -0.09295564144849777\n",
      "\n",
      "episode 6, policy loss -0.07905890047550201\n",
      "\n",
      "episode 7, policy loss -0.01802201196551323\n",
      "\n",
      "episode 8, policy loss -0.0836891457438469\n",
      "\n",
      "episode 9, policy loss -0.10290263593196869\n",
      "\n",
      "episode 10, policy loss -0.0641682967543602\n",
      "\n",
      "episode 11, policy loss -0.07750584185123444\n",
      "\n",
      "episode 12, policy loss -0.010716673918068409\n",
      "\n",
      "episode 13, policy loss -0.0527481772005558\n",
      "\n",
      "episode 14, policy loss -0.06741973757743835\n",
      "\n",
      "episode 15, policy loss -0.03351999819278717\n",
      "\n",
      "episode 16, policy loss -0.05621340125799179\n",
      "\n",
      "Policy train loss in epoch 2:-0.07199956505792215\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.09394132345914841\n",
      "\n",
      "episode 2, policy loss -0.017771316692233086\n",
      "\n",
      "episode 3, policy loss -0.07441059499979019\n",
      "\n",
      "episode 4, policy loss -0.033410631120204926\n",
      "\n",
      "episode 5, policy loss -0.06750929355621338\n",
      "\n",
      "episode 6, policy loss -0.09474606066942215\n",
      "\n",
      "episode 7, policy loss -0.01044479850679636\n",
      "\n",
      "episode 8, policy loss -0.052402738481760025\n",
      "\n",
      "episode 9, policy loss -0.08418813347816467\n",
      "\n",
      "episode 10, policy loss -0.12372690439224243\n",
      "\n",
      "episode 11, policy loss -0.12241984903812408\n",
      "\n",
      "episode 12, policy loss -0.07943514734506607\n",
      "\n",
      "episode 13, policy loss -0.07756197452545166\n",
      "\n",
      "episode 14, policy loss -0.06521205604076385\n",
      "\n",
      "episode 15, policy loss -0.10300346463918686\n",
      "\n",
      "episode 16, policy loss -0.0560789592564106\n",
      "\n",
      "Policy train loss in epoch 3:-0.07226645288756117\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1753576397895813\n",
      "\n",
      "episode 2, val func loss 0.19234366714954376\n",
      "\n",
      "episode 3, val func loss 0.14918643236160278\n",
      "\n",
      "episode 4, val func loss 0.19522227346897125\n",
      "\n",
      "episode 5, val func loss 0.19613191485404968\n",
      "\n",
      "episode 6, val func loss 0.1829155832529068\n",
      "\n",
      "episode 7, val func loss 0.1922668218612671\n",
      "\n",
      "episode 8, val func loss 0.2198750078678131\n",
      "\n",
      "episode 9, val func loss 0.18736588954925537\n",
      "\n",
      "episode 10, val func loss 0.22919949889183044\n",
      "\n",
      "episode 11, val func loss 0.19143494963645935\n",
      "\n",
      "episode 12, val func loss 0.1820726841688156\n",
      "\n",
      "episode 13, val func loss 0.20358146727085114\n",
      "\n",
      "episode 14, val func loss 0.17116720974445343\n",
      "\n",
      "episode 15, val func loss 0.19334639608860016\n",
      "\n",
      "episode 16, val func loss 0.22437067329883575\n",
      "\n",
      "Val func train loss in epoch 0:0.19286488182842731\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19579006731510162\n",
      "\n",
      "episode 2, val func loss 0.22069351375102997\n",
      "\n",
      "episode 3, val func loss 0.18642577528953552\n",
      "\n",
      "episode 4, val func loss 0.19133074581623077\n",
      "\n",
      "episode 5, val func loss 0.15144628286361694\n",
      "\n",
      "episode 6, val func loss 0.1729295402765274\n",
      "\n",
      "episode 7, val func loss 0.19142569601535797\n",
      "\n",
      "episode 8, val func loss 0.1749531328678131\n",
      "\n",
      "episode 9, val func loss 0.19559800624847412\n",
      "\n",
      "episode 10, val func loss 0.18338236212730408\n",
      "\n",
      "episode 11, val func loss 0.205286905169487\n",
      "\n",
      "episode 12, val func loss 0.18036895990371704\n",
      "\n",
      "episode 13, val func loss 0.19317150115966797\n",
      "\n",
      "episode 14, val func loss 0.22387197613716125\n",
      "\n",
      "episode 15, val func loss 0.1916312426328659\n",
      "\n",
      "episode 16, val func loss 0.22896981239318848\n",
      "\n",
      "Val func train loss in epoch 1:0.19295471999794245\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18423962593078613\n",
      "\n",
      "episode 2, val func loss 0.1932474672794342\n",
      "\n",
      "episode 3, val func loss 0.20284076035022736\n",
      "\n",
      "episode 4, val func loss 0.19568607211112976\n",
      "\n",
      "episode 5, val func loss 0.19550970196723938\n",
      "\n",
      "episode 6, val func loss 0.2285802662372589\n",
      "\n",
      "episode 7, val func loss 0.17569351196289062\n",
      "\n",
      "episode 8, val func loss 0.1870129406452179\n",
      "\n",
      "episode 9, val func loss 0.172324538230896\n",
      "\n",
      "episode 10, val func loss 0.1832684874534607\n",
      "\n",
      "episode 11, val func loss 0.1917380839586258\n",
      "\n",
      "episode 12, val func loss 0.1476946920156479\n",
      "\n",
      "episode 13, val func loss 0.19211873412132263\n",
      "\n",
      "episode 14, val func loss 0.2266591191291809\n",
      "\n",
      "episode 15, val func loss 0.19389764964580536\n",
      "\n",
      "episode 16, val func loss 0.22170162200927734\n",
      "\n",
      "Val func train loss in epoch 2:0.19326332956552505\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1925393044948578\n",
      "\n",
      "episode 2, val func loss 0.19547131657600403\n",
      "\n",
      "episode 3, val func loss 0.18775837123394012\n",
      "\n",
      "episode 4, val func loss 0.22003485262393951\n",
      "\n",
      "episode 5, val func loss 0.19190050661563873\n",
      "\n",
      "episode 6, val func loss 0.19295282661914825\n",
      "\n",
      "episode 7, val func loss 0.1955607533454895\n",
      "\n",
      "episode 8, val func loss 0.15258853137493134\n",
      "\n",
      "episode 9, val func loss 0.1729331612586975\n",
      "\n",
      "episode 10, val func loss 0.2301783412694931\n",
      "\n",
      "episode 11, val func loss 0.1927562654018402\n",
      "\n",
      "episode 12, val func loss 0.17484275996685028\n",
      "\n",
      "episode 13, val func loss 0.1838439404964447\n",
      "\n",
      "episode 14, val func loss 0.17995212972164154\n",
      "\n",
      "episode 15, val func loss 0.20568479597568512\n",
      "\n",
      "episode 16, val func loss 0.22187019884586334\n",
      "\n",
      "Val func train loss in epoch 3:0.19317925348877907\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1705458015203476\n",
      "\n",
      "episode 2, val func loss 0.1837436407804489\n",
      "\n",
      "episode 3, val func loss 0.22290998697280884\n",
      "\n",
      "episode 4, val func loss 0.14941661059856415\n",
      "\n",
      "episode 5, val func loss 0.19117069244384766\n",
      "\n",
      "episode 6, val func loss 0.22006919980049133\n",
      "\n",
      "episode 7, val func loss 0.19180573523044586\n",
      "\n",
      "episode 8, val func loss 0.17513927817344666\n",
      "\n",
      "episode 9, val func loss 0.20311614871025085\n",
      "\n",
      "episode 10, val func loss 0.1924498826265335\n",
      "\n",
      "episode 11, val func loss 0.22857637703418732\n",
      "\n",
      "episode 12, val func loss 0.19557563960552216\n",
      "\n",
      "episode 13, val func loss 0.19254571199417114\n",
      "\n",
      "episode 14, val func loss 0.1951128989458084\n",
      "\n",
      "episode 15, val func loss 0.18702703714370728\n",
      "\n",
      "episode 16, val func loss 0.18206605315208435\n",
      "\n",
      "Val func train loss in epoch 4:0.19257941842079163\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19175173342227936\n",
      "\n",
      "episode 2, val func loss 0.18305304646492004\n",
      "\n",
      "episode 3, val func loss 0.221438467502594\n",
      "\n",
      "episode 4, val func loss 0.19217585027217865\n",
      "\n",
      "episode 5, val func loss 0.14874471724033356\n",
      "\n",
      "episode 6, val func loss 0.17521516978740692\n",
      "\n",
      "episode 7, val func loss 0.19202247262001038\n",
      "\n",
      "episode 8, val func loss 0.1797439008951187\n",
      "\n",
      "episode 9, val func loss 0.19636084139347076\n",
      "\n",
      "episode 10, val func loss 0.19552665948867798\n",
      "\n",
      "episode 11, val func loss 0.2311794012784958\n",
      "\n",
      "episode 12, val func loss 0.18605057895183563\n",
      "\n",
      "episode 13, val func loss 0.20303207635879517\n",
      "\n",
      "episode 14, val func loss 0.1739286631345749\n",
      "\n",
      "episode 15, val func loss 0.1924217939376831\n",
      "\n",
      "episode 16, val func loss 0.22024084627628326\n",
      "\n",
      "Val func train loss in epoch 5:0.19268038868904114\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19244568049907684\n",
      "\n",
      "episode 2, val func loss 0.19224530458450317\n",
      "\n",
      "episode 3, val func loss 0.19529828429222107\n",
      "\n",
      "episode 4, val func loss 0.18703077733516693\n",
      "\n",
      "episode 5, val func loss 0.1919393390417099\n",
      "\n",
      "episode 6, val func loss 0.18340365588665009\n",
      "\n",
      "episode 7, val func loss 0.17482402920722961\n",
      "\n",
      "episode 8, val func loss 0.22070635855197906\n",
      "\n",
      "episode 9, val func loss 0.17052912712097168\n",
      "\n",
      "episode 10, val func loss 0.1953297257423401\n",
      "\n",
      "episode 11, val func loss 0.23245853185653687\n",
      "\n",
      "episode 12, val func loss 0.18021729588508606\n",
      "\n",
      "episode 13, val func loss 0.20439331233501434\n",
      "\n",
      "episode 14, val func loss 0.1912080943584442\n",
      "\n",
      "episode 15, val func loss 0.14950068295001984\n",
      "\n",
      "episode 16, val func loss 0.22218813002109528\n",
      "\n",
      "Val func train loss in epoch 6:0.19273239560425282\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.22139599919319153\n",
      "\n",
      "episode 2, val func loss 0.19135966897010803\n",
      "\n",
      "episode 3, val func loss 0.18262793123722076\n",
      "\n",
      "episode 4, val func loss 0.19589082896709442\n",
      "\n",
      "episode 5, val func loss 0.19288316369056702\n",
      "\n",
      "episode 6, val func loss 0.17557932436466217\n",
      "\n",
      "episode 7, val func loss 0.1835803985595703\n",
      "\n",
      "episode 8, val func loss 0.15021958947181702\n",
      "\n",
      "episode 9, val func loss 0.23086228966712952\n",
      "\n",
      "episode 10, val func loss 0.1958281695842743\n",
      "\n",
      "episode 11, val func loss 0.17028994858264923\n",
      "\n",
      "episode 12, val func loss 0.2211235761642456\n",
      "\n",
      "episode 13, val func loss 0.20493465662002563\n",
      "\n",
      "episode 14, val func loss 0.1930561512708664\n",
      "\n",
      "episode 15, val func loss 0.1915421038866043\n",
      "\n",
      "episode 16, val func loss 0.1862127035856247\n",
      "\n",
      "Val func train loss in epoch 7:0.19296165648847818\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1952943056821823\n",
      "\n",
      "episode 2, val func loss 0.19142822921276093\n",
      "\n",
      "episode 3, val func loss 0.1835862696170807\n",
      "\n",
      "episode 4, val func loss 0.1727094054222107\n",
      "\n",
      "episode 5, val func loss 0.21989619731903076\n",
      "\n",
      "episode 6, val func loss 0.1924339383840561\n",
      "\n",
      "episode 7, val func loss 0.22206872701644897\n",
      "\n",
      "episode 8, val func loss 0.1915474385023117\n",
      "\n",
      "episode 9, val func loss 0.22942444682121277\n",
      "\n",
      "episode 10, val func loss 0.18204985558986664\n",
      "\n",
      "episode 11, val func loss 0.18654818832874298\n",
      "\n",
      "episode 12, val func loss 0.1754664182662964\n",
      "\n",
      "episode 13, val func loss 0.19501706957817078\n",
      "\n",
      "episode 14, val func loss 0.19243407249450684\n",
      "\n",
      "episode 15, val func loss 0.1493421196937561\n",
      "\n",
      "episode 16, val func loss 0.20438215136528015\n",
      "\n",
      "Val func train loss in epoch 8:0.19272680208086967\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1837187260389328\n",
      "\n",
      "episode 2, val func loss 0.20479397475719452\n",
      "\n",
      "episode 3, val func loss 0.1924474984407425\n",
      "\n",
      "episode 4, val func loss 0.17495910823345184\n",
      "\n",
      "episode 5, val func loss 0.1951664686203003\n",
      "\n",
      "episode 6, val func loss 0.18578943610191345\n",
      "\n",
      "episode 7, val func loss 0.2295890897512436\n",
      "\n",
      "episode 8, val func loss 0.1947498321533203\n",
      "\n",
      "episode 9, val func loss 0.22027182579040527\n",
      "\n",
      "episode 10, val func loss 0.19319987297058105\n",
      "\n",
      "episode 11, val func loss 0.17701587080955505\n",
      "\n",
      "episode 12, val func loss 0.21990473568439484\n",
      "\n",
      "episode 13, val func loss 0.18325300514698029\n",
      "\n",
      "episode 14, val func loss 0.19134584069252014\n",
      "\n",
      "episode 15, val func loss 0.19123952090740204\n",
      "\n",
      "episode 16, val func loss 0.14864382147789001\n",
      "\n",
      "Val func train loss in epoch 9:0.19288053922355175\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.22176316380500793\n",
      "\n",
      "episode 2, val func loss 0.19275923073291779\n",
      "\n",
      "episode 3, val func loss 0.1476898491382599\n",
      "\n",
      "episode 4, val func loss 0.1926933377981186\n",
      "\n",
      "episode 5, val func loss 0.1961340755224228\n",
      "\n",
      "episode 6, val func loss 0.19302526116371155\n",
      "\n",
      "episode 7, val func loss 0.19529558718204498\n",
      "\n",
      "episode 8, val func loss 0.17924721539020538\n",
      "\n",
      "episode 9, val func loss 0.19258084893226624\n",
      "\n",
      "episode 10, val func loss 0.2040894776582718\n",
      "\n",
      "episode 11, val func loss 0.23156486451625824\n",
      "\n",
      "episode 12, val func loss 0.18356609344482422\n",
      "\n",
      "episode 13, val func loss 0.17515653371810913\n",
      "\n",
      "episode 14, val func loss 0.1856050044298172\n",
      "\n",
      "episode 15, val func loss 0.22208715975284576\n",
      "\n",
      "episode 16, val func loss 0.18141651153564453\n",
      "\n",
      "Val func train loss in epoch 10:0.19341713842004538\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19209957122802734\n",
      "\n",
      "episode 2, val func loss 0.1503176987171173\n",
      "\n",
      "episode 3, val func loss 0.22155579924583435\n",
      "\n",
      "episode 4, val func loss 0.195815771818161\n",
      "\n",
      "episode 5, val func loss 0.19187390804290771\n",
      "\n",
      "episode 6, val func loss 0.18108807504177094\n",
      "\n",
      "episode 7, val func loss 0.19139324128627777\n",
      "\n",
      "episode 8, val func loss 0.1716916263103485\n",
      "\n",
      "episode 9, val func loss 0.2042478770017624\n",
      "\n",
      "episode 10, val func loss 0.22064340114593506\n",
      "\n",
      "episode 11, val func loss 0.23070381581783295\n",
      "\n",
      "episode 12, val func loss 0.17492949962615967\n",
      "\n",
      "episode 13, val func loss 0.1862955540418625\n",
      "\n",
      "episode 14, val func loss 0.19517461955547333\n",
      "\n",
      "episode 15, val func loss 0.1926742047071457\n",
      "\n",
      "episode 16, val func loss 0.18330685794353485\n",
      "\n",
      "Val func train loss in epoch 11:0.19273822009563446\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.2294807881116867\n",
      "\n",
      "episode 2, val func loss 0.22052694857120514\n",
      "\n",
      "episode 3, val func loss 0.2034512162208557\n",
      "\n",
      "episode 4, val func loss 0.1882675439119339\n",
      "\n",
      "episode 5, val func loss 0.153595969080925\n",
      "\n",
      "episode 6, val func loss 0.18286460638046265\n",
      "\n",
      "episode 7, val func loss 0.17234185338020325\n",
      "\n",
      "episode 8, val func loss 0.17519080638885498\n",
      "\n",
      "episode 9, val func loss 0.19203045964241028\n",
      "\n",
      "episode 10, val func loss 0.1935841143131256\n",
      "\n",
      "episode 11, val func loss 0.19837597012519836\n",
      "\n",
      "episode 12, val func loss 0.19469618797302246\n",
      "\n",
      "episode 13, val func loss 0.1968681961297989\n",
      "\n",
      "episode 14, val func loss 0.22157736122608185\n",
      "\n",
      "episode 15, val func loss 0.1834861785173416\n",
      "\n",
      "episode 16, val func loss 0.19199419021606445\n",
      "\n",
      "Val func train loss in epoch 12:0.19364577438682318\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.22012025117874146\n",
      "\n",
      "episode 2, val func loss 0.19533804059028625\n",
      "\n",
      "episode 3, val func loss 0.19270965456962585\n",
      "\n",
      "episode 4, val func loss 0.15395592153072357\n",
      "\n",
      "episode 5, val func loss 0.1956384927034378\n",
      "\n",
      "episode 6, val func loss 0.2200896441936493\n",
      "\n",
      "episode 7, val func loss 0.17339876294136047\n",
      "\n",
      "episode 8, val func loss 0.18363632261753082\n",
      "\n",
      "episode 9, val func loss 0.1919993907213211\n",
      "\n",
      "episode 10, val func loss 0.2040107548236847\n",
      "\n",
      "episode 11, val func loss 0.18017873167991638\n",
      "\n",
      "episode 12, val func loss 0.19171643257141113\n",
      "\n",
      "episode 13, val func loss 0.23200923204421997\n",
      "\n",
      "episode 14, val func loss 0.1745162308216095\n",
      "\n",
      "episode 15, val func loss 0.19123435020446777\n",
      "\n",
      "episode 16, val func loss 0.18589575588703156\n",
      "\n",
      "Val func train loss in epoch 13:0.1929029980674386\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19087794423103333\n",
      "\n",
      "episode 2, val func loss 0.1922004371881485\n",
      "\n",
      "episode 3, val func loss 0.2293437272310257\n",
      "\n",
      "episode 4, val func loss 0.22072218358516693\n",
      "\n",
      "episode 5, val func loss 0.18738071620464325\n",
      "\n",
      "episode 6, val func loss 0.15280139446258545\n",
      "\n",
      "episode 7, val func loss 0.2199801653623581\n",
      "\n",
      "episode 8, val func loss 0.1733492612838745\n",
      "\n",
      "episode 9, val func loss 0.18341894447803497\n",
      "\n",
      "episode 10, val func loss 0.17447608709335327\n",
      "\n",
      "episode 11, val func loss 0.1914231777191162\n",
      "\n",
      "episode 12, val func loss 0.20523959398269653\n",
      "\n",
      "episode 13, val func loss 0.1968904435634613\n",
      "\n",
      "episode 14, val func loss 0.19565513730049133\n",
      "\n",
      "episode 15, val func loss 0.17989154160022736\n",
      "\n",
      "episode 16, val func loss 0.19290314614772797\n",
      "\n",
      "Val func train loss in epoch 14:0.19290961883962154\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.22052064538002014\n",
      "\n",
      "episode 2, val func loss 0.1750723421573639\n",
      "\n",
      "episode 3, val func loss 0.1946454495191574\n",
      "\n",
      "episode 4, val func loss 0.17267879843711853\n",
      "\n",
      "episode 5, val func loss 0.1500125527381897\n",
      "\n",
      "episode 6, val func loss 0.19129455089569092\n",
      "\n",
      "episode 7, val func loss 0.19274239242076874\n",
      "\n",
      "episode 8, val func loss 0.22311703860759735\n",
      "\n",
      "episode 9, val func loss 0.23112501204013824\n",
      "\n",
      "episode 10, val func loss 0.195561021566391\n",
      "\n",
      "episode 11, val func loss 0.19217607378959656\n",
      "\n",
      "episode 12, val func loss 0.19200365245342255\n",
      "\n",
      "episode 13, val func loss 0.1874886006116867\n",
      "\n",
      "episode 14, val func loss 0.2030341625213623\n",
      "\n",
      "episode 15, val func loss 0.18281006813049316\n",
      "\n",
      "episode 16, val func loss 0.18393181264400482\n",
      "\n",
      "Val func train loss in epoch 15:0.19301338586956263\n",
      "***********************TIME WAS 4.968855635325114 min*****************************\n",
      "\n",
      "**********************ROUND 91 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.02105807699263096\n",
      "\n",
      "episode 2, policy loss -0.015463189221918583\n",
      "\n",
      "episode 3, policy loss 0.0292276032269001\n",
      "\n",
      "episode 4, policy loss -0.02319965325295925\n",
      "\n",
      "episode 5, policy loss 0.004328838083893061\n",
      "\n",
      "episode 6, policy loss -0.06297188997268677\n",
      "\n",
      "episode 7, policy loss 0.01892140693962574\n",
      "\n",
      "episode 8, policy loss 0.006372757721692324\n",
      "\n",
      "episode 9, policy loss -0.04457613825798035\n",
      "\n",
      "episode 10, policy loss 0.02598828636109829\n",
      "\n",
      "episode 11, policy loss -0.07421749085187912\n",
      "\n",
      "episode 12, policy loss -0.0025393094401806593\n",
      "\n",
      "episode 13, policy loss -0.006101380567997694\n",
      "\n",
      "episode 14, policy loss -0.06212659925222397\n",
      "\n",
      "episode 15, policy loss -0.024125758558511734\n",
      "\n",
      "episode 16, policy loss -0.0009737086365930736\n",
      "\n",
      "Policy train loss in epoch 0:-0.01578214391702204\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.005074060522019863\n",
      "\n",
      "episode 2, policy loss -0.0001740352454362437\n",
      "\n",
      "episode 3, policy loss 0.02292165346443653\n",
      "\n",
      "episode 4, policy loss -0.0311487577855587\n",
      "\n",
      "episode 5, policy loss -0.06170394644141197\n",
      "\n",
      "episode 6, policy loss -0.009125795215368271\n",
      "\n",
      "episode 7, policy loss 0.023316888138651848\n",
      "\n",
      "episode 8, policy loss -0.04478047788143158\n",
      "\n",
      "episode 9, policy loss -0.028267808258533478\n",
      "\n",
      "episode 10, policy loss -0.02467001974582672\n",
      "\n",
      "episode 11, policy loss 0.0011500383261591196\n",
      "\n",
      "episode 12, policy loss -0.06648662686347961\n",
      "\n",
      "episode 13, policy loss -0.006674949545413256\n",
      "\n",
      "episode 14, policy loss -0.02154325507581234\n",
      "\n",
      "episode 15, policy loss -0.07811284810304642\n",
      "\n",
      "episode 16, policy loss 0.01877608336508274\n",
      "\n",
      "Policy train loss in epoch 1:-0.01884061227156053\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.07765495777130127\n",
      "\n",
      "episode 2, policy loss -0.04615573212504387\n",
      "\n",
      "episode 3, policy loss 0.000997306895442307\n",
      "\n",
      "episode 4, policy loss -0.028653472661972046\n",
      "\n",
      "episode 5, policy loss -0.0012444324092939496\n",
      "\n",
      "episode 6, policy loss -0.062490180134773254\n",
      "\n",
      "episode 7, policy loss 0.022612910717725754\n",
      "\n",
      "episode 8, policy loss -0.06673584133386612\n",
      "\n",
      "episode 9, policy loss 0.004511289298534393\n",
      "\n",
      "episode 10, policy loss -0.009480595588684082\n",
      "\n",
      "episode 11, policy loss 0.02244851179420948\n",
      "\n",
      "episode 12, policy loss -0.03164222091436386\n",
      "\n",
      "episode 13, policy loss 0.01855643279850483\n",
      "\n",
      "episode 14, policy loss -0.019948797300457954\n",
      "\n",
      "episode 15, policy loss -0.02389461174607277\n",
      "\n",
      "episode 16, policy loss -0.006036908831447363\n",
      "\n",
      "Policy train loss in epoch 2:-0.019050706207053736\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.009367735125124454\n",
      "\n",
      "episode 2, policy loss 0.023066820576786995\n",
      "\n",
      "episode 3, policy loss -0.0013338506687432528\n",
      "\n",
      "episode 4, policy loss 0.0013047491665929556\n",
      "\n",
      "episode 5, policy loss 0.0044999998062849045\n",
      "\n",
      "episode 6, policy loss -0.06249891221523285\n",
      "\n",
      "episode 7, policy loss -0.07839270681142807\n",
      "\n",
      "episode 8, policy loss -0.02885257825255394\n",
      "\n",
      "episode 9, policy loss 0.018767768517136574\n",
      "\n",
      "episode 10, policy loss -0.06680884212255478\n",
      "\n",
      "episode 11, policy loss -0.02530796080827713\n",
      "\n",
      "episode 12, policy loss -0.005221093073487282\n",
      "\n",
      "episode 13, policy loss -0.03135436773300171\n",
      "\n",
      "episode 14, policy loss -0.02091037668287754\n",
      "\n",
      "episode 15, policy loss 0.022870078682899475\n",
      "\n",
      "episode 16, policy loss -0.046184785664081573\n",
      "\n",
      "Policy train loss in epoch 3:-0.019107737025478855\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.22227196395397186\n",
      "\n",
      "episode 2, val func loss 0.18182477355003357\n",
      "\n",
      "episode 3, val func loss 0.1786833256483078\n",
      "\n",
      "episode 4, val func loss 0.17465853691101074\n",
      "\n",
      "episode 5, val func loss 0.18585284054279327\n",
      "\n",
      "episode 6, val func loss 0.19310712814331055\n",
      "\n",
      "episode 7, val func loss 0.19775710999965668\n",
      "\n",
      "episode 8, val func loss 0.17764605581760406\n",
      "\n",
      "episode 9, val func loss 0.18844805657863617\n",
      "\n",
      "episode 10, val func loss 0.19782282412052155\n",
      "\n",
      "episode 11, val func loss 0.16254325211048126\n",
      "\n",
      "episode 12, val func loss 0.17601986229419708\n",
      "\n",
      "episode 13, val func loss 0.15976940095424652\n",
      "\n",
      "episode 14, val func loss 0.21750082075595856\n",
      "\n",
      "episode 15, val func loss 0.20577816665172577\n",
      "\n",
      "episode 16, val func loss 0.19132353365421295\n",
      "\n",
      "Val func train loss in epoch 0:0.18818797823041677\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19329240918159485\n",
      "\n",
      "episode 2, val func loss 0.1861777901649475\n",
      "\n",
      "episode 3, val func loss 0.2045859545469284\n",
      "\n",
      "episode 4, val func loss 0.17842164635658264\n",
      "\n",
      "episode 5, val func loss 0.17647534608840942\n",
      "\n",
      "episode 6, val func loss 0.22293692827224731\n",
      "\n",
      "episode 7, val func loss 0.19769228994846344\n",
      "\n",
      "episode 8, val func loss 0.1958189308643341\n",
      "\n",
      "episode 9, val func loss 0.17722734808921814\n",
      "\n",
      "episode 10, val func loss 0.16155697405338287\n",
      "\n",
      "episode 11, val func loss 0.21550501883029938\n",
      "\n",
      "episode 12, val func loss 0.1916242092847824\n",
      "\n",
      "episode 13, val func loss 0.16272442042827606\n",
      "\n",
      "episode 14, val func loss 0.18780310451984406\n",
      "\n",
      "episode 15, val func loss 0.17568227648735046\n",
      "\n",
      "episode 16, val func loss 0.18172088265419006\n",
      "\n",
      "Val func train loss in epoch 1:0.1880778456106782\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.22580723464488983\n",
      "\n",
      "episode 2, val func loss 0.19062188267707825\n",
      "\n",
      "episode 3, val func loss 0.1929381936788559\n",
      "\n",
      "episode 4, val func loss 0.1979006677865982\n",
      "\n",
      "episode 5, val func loss 0.17595449090003967\n",
      "\n",
      "episode 6, val func loss 0.16011810302734375\n",
      "\n",
      "episode 7, val func loss 0.21672320365905762\n",
      "\n",
      "episode 8, val func loss 0.17483451962471008\n",
      "\n",
      "episode 9, val func loss 0.1779649257659912\n",
      "\n",
      "episode 10, val func loss 0.1879521906375885\n",
      "\n",
      "episode 11, val func loss 0.1816156655550003\n",
      "\n",
      "episode 12, val func loss 0.18588943779468536\n",
      "\n",
      "episode 13, val func loss 0.17650724947452545\n",
      "\n",
      "episode 14, val func loss 0.20454585552215576\n",
      "\n",
      "episode 15, val func loss 0.16305021941661835\n",
      "\n",
      "episode 16, val func loss 0.1959007978439331\n",
      "\n",
      "Val func train loss in epoch 2:0.18802028987556696\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18600976467132568\n",
      "\n",
      "episode 2, val func loss 0.1974550187587738\n",
      "\n",
      "episode 3, val func loss 0.17446739971637726\n",
      "\n",
      "episode 4, val func loss 0.18777135014533997\n",
      "\n",
      "episode 5, val func loss 0.19281594455242157\n",
      "\n",
      "episode 6, val func loss 0.21649158000946045\n",
      "\n",
      "episode 7, val func loss 0.16001299023628235\n",
      "\n",
      "episode 8, val func loss 0.19609478116035461\n",
      "\n",
      "episode 9, val func loss 0.1782146543264389\n",
      "\n",
      "episode 10, val func loss 0.17628641426563263\n",
      "\n",
      "episode 11, val func loss 0.1761554628610611\n",
      "\n",
      "episode 12, val func loss 0.22356493771076202\n",
      "\n",
      "episode 13, val func loss 0.1814914345741272\n",
      "\n",
      "episode 14, val func loss 0.16264452040195465\n",
      "\n",
      "episode 15, val func loss 0.19118642807006836\n",
      "\n",
      "episode 16, val func loss 0.2058837115764618\n",
      "\n",
      "Val func train loss in epoch 3:0.18790914956480265\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19807720184326172\n",
      "\n",
      "episode 2, val func loss 0.1909707486629486\n",
      "\n",
      "episode 3, val func loss 0.17677050828933716\n",
      "\n",
      "episode 4, val func loss 0.1778896152973175\n",
      "\n",
      "episode 5, val func loss 0.17569221556186676\n",
      "\n",
      "episode 6, val func loss 0.15968038141727448\n",
      "\n",
      "episode 7, val func loss 0.17543348670005798\n",
      "\n",
      "episode 8, val func loss 0.1621289998292923\n",
      "\n",
      "episode 9, val func loss 0.19328831136226654\n",
      "\n",
      "episode 10, val func loss 0.1856003701686859\n",
      "\n",
      "episode 11, val func loss 0.2268630415201187\n",
      "\n",
      "episode 12, val func loss 0.2070702314376831\n",
      "\n",
      "episode 13, val func loss 0.21724635362625122\n",
      "\n",
      "episode 14, val func loss 0.1876383274793625\n",
      "\n",
      "episode 15, val func loss 0.18218377232551575\n",
      "\n",
      "episode 16, val func loss 0.19612018764019012\n",
      "\n",
      "Val func train loss in epoch 4:0.1882908595725894\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1836463063955307\n",
      "\n",
      "episode 2, val func loss 0.19723345339298248\n",
      "\n",
      "episode 3, val func loss 0.18932458758354187\n",
      "\n",
      "episode 4, val func loss 0.18708603084087372\n",
      "\n",
      "episode 5, val func loss 0.22334223985671997\n",
      "\n",
      "episode 6, val func loss 0.17666195333003998\n",
      "\n",
      "episode 7, val func loss 0.19777630269527435\n",
      "\n",
      "episode 8, val func loss 0.2055695354938507\n",
      "\n",
      "episode 9, val func loss 0.21624638140201569\n",
      "\n",
      "episode 10, val func loss 0.16090713441371918\n",
      "\n",
      "episode 11, val func loss 0.1774318516254425\n",
      "\n",
      "episode 12, val func loss 0.17841406166553497\n",
      "\n",
      "episode 13, val func loss 0.17512358725070953\n",
      "\n",
      "episode 14, val func loss 0.19659215211868286\n",
      "\n",
      "episode 15, val func loss 0.16263549029827118\n",
      "\n",
      "episode 16, val func loss 0.19273744523525238\n",
      "\n",
      "Val func train loss in epoch 5:0.18879553209990263\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17727141082286835\n",
      "\n",
      "episode 2, val func loss 0.20701806247234344\n",
      "\n",
      "episode 3, val func loss 0.19112753868103027\n",
      "\n",
      "episode 4, val func loss 0.18550749123096466\n",
      "\n",
      "episode 5, val func loss 0.17540624737739563\n",
      "\n",
      "episode 6, val func loss 0.19722594320774078\n",
      "\n",
      "episode 7, val func loss 0.1877303421497345\n",
      "\n",
      "episode 8, val func loss 0.16048844158649445\n",
      "\n",
      "episode 9, val func loss 0.18144893646240234\n",
      "\n",
      "episode 10, val func loss 0.17758961021900177\n",
      "\n",
      "episode 11, val func loss 0.19696149230003357\n",
      "\n",
      "episode 12, val func loss 0.1931631714105606\n",
      "\n",
      "episode 13, val func loss 0.16209720075130463\n",
      "\n",
      "episode 14, val func loss 0.2249283641576767\n",
      "\n",
      "episode 15, val func loss 0.17581366002559662\n",
      "\n",
      "episode 16, val func loss 0.2171417623758316\n",
      "\n",
      "Val func train loss in epoch 6:0.18818247970193624\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17593245208263397\n",
      "\n",
      "episode 2, val func loss 0.19310307502746582\n",
      "\n",
      "episode 3, val func loss 0.18591290712356567\n",
      "\n",
      "episode 4, val func loss 0.19151878356933594\n",
      "\n",
      "episode 5, val func loss 0.16214023530483246\n",
      "\n",
      "episode 6, val func loss 0.19714131951332092\n",
      "\n",
      "episode 7, val func loss 0.17733228206634521\n",
      "\n",
      "episode 8, val func loss 0.22533906996250153\n",
      "\n",
      "episode 9, val func loss 0.18781496584415436\n",
      "\n",
      "episode 10, val func loss 0.17810676991939545\n",
      "\n",
      "episode 11, val func loss 0.16057685017585754\n",
      "\n",
      "episode 12, val func loss 0.18140892684459686\n",
      "\n",
      "episode 13, val func loss 0.19728530943393707\n",
      "\n",
      "episode 14, val func loss 0.20492468774318695\n",
      "\n",
      "episode 15, val func loss 0.1747242957353592\n",
      "\n",
      "episode 16, val func loss 0.21452265977859497\n",
      "\n",
      "Val func train loss in epoch 7:0.18798653688281775\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17538653314113617\n",
      "\n",
      "episode 2, val func loss 0.19643381237983704\n",
      "\n",
      "episode 3, val func loss 0.2027793973684311\n",
      "\n",
      "episode 4, val func loss 0.22179661691188812\n",
      "\n",
      "episode 5, val func loss 0.17742252349853516\n",
      "\n",
      "episode 6, val func loss 0.18995559215545654\n",
      "\n",
      "episode 7, val func loss 0.17976631224155426\n",
      "\n",
      "episode 8, val func loss 0.1814912110567093\n",
      "\n",
      "episode 9, val func loss 0.16040267050266266\n",
      "\n",
      "episode 10, val func loss 0.17749732732772827\n",
      "\n",
      "episode 11, val func loss 0.22193896770477295\n",
      "\n",
      "episode 12, val func loss 0.1610625684261322\n",
      "\n",
      "episode 13, val func loss 0.1992604285478592\n",
      "\n",
      "episode 14, val func loss 0.19045855104923248\n",
      "\n",
      "episode 15, val func loss 0.1858617514371872\n",
      "\n",
      "episode 16, val func loss 0.193499356508255\n",
      "\n",
      "Val func train loss in epoch 8:0.1884383512660861\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1768696904182434\n",
      "\n",
      "episode 2, val func loss 0.17801761627197266\n",
      "\n",
      "episode 3, val func loss 0.17620617151260376\n",
      "\n",
      "episode 4, val func loss 0.19291017949581146\n",
      "\n",
      "episode 5, val func loss 0.1879177987575531\n",
      "\n",
      "episode 6, val func loss 0.19082631170749664\n",
      "\n",
      "episode 7, val func loss 0.19760434329509735\n",
      "\n",
      "episode 8, val func loss 0.15917399525642395\n",
      "\n",
      "episode 9, val func loss 0.18193112313747406\n",
      "\n",
      "episode 10, val func loss 0.1853075623512268\n",
      "\n",
      "episode 11, val func loss 0.16204670071601868\n",
      "\n",
      "episode 12, val func loss 0.19735440611839294\n",
      "\n",
      "episode 13, val func loss 0.2252187728881836\n",
      "\n",
      "episode 14, val func loss 0.20554769039154053\n",
      "\n",
      "episode 15, val func loss 0.17493796348571777\n",
      "\n",
      "episode 16, val func loss 0.21341493725776672\n",
      "\n",
      "Val func train loss in epoch 9:0.18783032894134521\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20304854214191437\n",
      "\n",
      "episode 2, val func loss 0.20331285893917084\n",
      "\n",
      "episode 3, val func loss 0.1919010728597641\n",
      "\n",
      "episode 4, val func loss 0.21326175332069397\n",
      "\n",
      "episode 5, val func loss 0.18150641024112701\n",
      "\n",
      "episode 6, val func loss 0.1816089153289795\n",
      "\n",
      "episode 7, val func loss 0.16346849501132965\n",
      "\n",
      "episode 8, val func loss 0.1929340809583664\n",
      "\n",
      "episode 9, val func loss 0.17738336324691772\n",
      "\n",
      "episode 10, val func loss 0.19034722447395325\n",
      "\n",
      "episode 11, val func loss 0.17512184381484985\n",
      "\n",
      "episode 12, val func loss 0.18586893379688263\n",
      "\n",
      "episode 13, val func loss 0.19970305263996124\n",
      "\n",
      "episode 14, val func loss 0.17695599794387817\n",
      "\n",
      "episode 15, val func loss 0.15911531448364258\n",
      "\n",
      "episode 16, val func loss 0.22423267364501953\n",
      "\n",
      "Val func train loss in epoch 10:0.18873565830290318\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.22186221182346344\n",
      "\n",
      "episode 2, val func loss 0.1984063684940338\n",
      "\n",
      "episode 3, val func loss 0.18950995802879333\n",
      "\n",
      "episode 4, val func loss 0.19788895547389984\n",
      "\n",
      "episode 5, val func loss 0.17469438910484314\n",
      "\n",
      "episode 6, val func loss 0.21750682592391968\n",
      "\n",
      "episode 7, val func loss 0.20550037920475006\n",
      "\n",
      "episode 8, val func loss 0.18137669563293457\n",
      "\n",
      "episode 9, val func loss 0.17585033178329468\n",
      "\n",
      "episode 10, val func loss 0.16261808574199677\n",
      "\n",
      "episode 11, val func loss 0.18673424422740936\n",
      "\n",
      "episode 12, val func loss 0.17820528149604797\n",
      "\n",
      "episode 13, val func loss 0.1626223772764206\n",
      "\n",
      "episode 14, val func loss 0.17515982687473297\n",
      "\n",
      "episode 15, val func loss 0.19357867538928986\n",
      "\n",
      "episode 16, val func loss 0.19864808022975922\n",
      "\n",
      "Val func train loss in epoch 11:0.18876016791909933\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17483073472976685\n",
      "\n",
      "episode 2, val func loss 0.198613703250885\n",
      "\n",
      "episode 3, val func loss 0.16139091551303864\n",
      "\n",
      "episode 4, val func loss 0.22642050683498383\n",
      "\n",
      "episode 5, val func loss 0.18129655718803406\n",
      "\n",
      "episode 6, val func loss 0.20443087816238403\n",
      "\n",
      "episode 7, val func loss 0.1950998157262802\n",
      "\n",
      "episode 8, val func loss 0.21323749423027039\n",
      "\n",
      "episode 9, val func loss 0.1959356665611267\n",
      "\n",
      "episode 10, val func loss 0.16369467973709106\n",
      "\n",
      "episode 11, val func loss 0.18722422420978546\n",
      "\n",
      "episode 12, val func loss 0.18791542947292328\n",
      "\n",
      "episode 13, val func loss 0.17680171132087708\n",
      "\n",
      "episode 14, val func loss 0.17504563927650452\n",
      "\n",
      "episode 15, val func loss 0.19808033108711243\n",
      "\n",
      "episode 16, val func loss 0.17746669054031372\n",
      "\n",
      "Val func train loss in epoch 12:0.18859281111508608\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.21837158501148224\n",
      "\n",
      "episode 2, val func loss 0.19152094423770905\n",
      "\n",
      "episode 3, val func loss 0.18143177032470703\n",
      "\n",
      "episode 4, val func loss 0.20468445122241974\n",
      "\n",
      "episode 5, val func loss 0.22199009358882904\n",
      "\n",
      "episode 6, val func loss 0.19077597558498383\n",
      "\n",
      "episode 7, val func loss 0.18271604180335999\n",
      "\n",
      "episode 8, val func loss 0.1763116866350174\n",
      "\n",
      "episode 9, val func loss 0.16097204387187958\n",
      "\n",
      "episode 10, val func loss 0.1622702181339264\n",
      "\n",
      "episode 11, val func loss 0.19738100469112396\n",
      "\n",
      "episode 12, val func loss 0.17582544684410095\n",
      "\n",
      "episode 13, val func loss 0.198252335190773\n",
      "\n",
      "episode 14, val func loss 0.19297157227993011\n",
      "\n",
      "episode 15, val func loss 0.18505719304084778\n",
      "\n",
      "episode 16, val func loss 0.17563343048095703\n",
      "\n",
      "Val func train loss in epoch 13:0.18851036205887794\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.15949967503547668\n",
      "\n",
      "episode 2, val func loss 0.22582387924194336\n",
      "\n",
      "episode 3, val func loss 0.1905617117881775\n",
      "\n",
      "episode 4, val func loss 0.1878611296415329\n",
      "\n",
      "episode 5, val func loss 0.1767292469739914\n",
      "\n",
      "episode 6, val func loss 0.21524593234062195\n",
      "\n",
      "episode 7, val func loss 0.19855768978595734\n",
      "\n",
      "episode 8, val func loss 0.18326303362846375\n",
      "\n",
      "episode 9, val func loss 0.19509711861610413\n",
      "\n",
      "episode 10, val func loss 0.1782415807247162\n",
      "\n",
      "episode 11, val func loss 0.20513418316841125\n",
      "\n",
      "episode 12, val func loss 0.17753954231739044\n",
      "\n",
      "episode 13, val func loss 0.1972174197435379\n",
      "\n",
      "episode 14, val func loss 0.1754358559846878\n",
      "\n",
      "episode 15, val func loss 0.1854235678911209\n",
      "\n",
      "episode 16, val func loss 0.1624041497707367\n",
      "\n",
      "Val func train loss in epoch 14:0.1883772322908044\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.17703202366828918\n",
      "\n",
      "episode 2, val func loss 0.18819209933280945\n",
      "\n",
      "episode 3, val func loss 0.16127438843250275\n",
      "\n",
      "episode 4, val func loss 0.2078155130147934\n",
      "\n",
      "episode 5, val func loss 0.15951292216777802\n",
      "\n",
      "episode 6, val func loss 0.1767062395811081\n",
      "\n",
      "episode 7, val func loss 0.19640213251113892\n",
      "\n",
      "episode 8, val func loss 0.22261424362659454\n",
      "\n",
      "episode 9, val func loss 0.18006089329719543\n",
      "\n",
      "episode 10, val func loss 0.19472724199295044\n",
      "\n",
      "episode 11, val func loss 0.19295383989810944\n",
      "\n",
      "episode 12, val func loss 0.17486132681369781\n",
      "\n",
      "episode 13, val func loss 0.19773860275745392\n",
      "\n",
      "episode 14, val func loss 0.18226505815982819\n",
      "\n",
      "episode 15, val func loss 0.18576106429100037\n",
      "\n",
      "episode 16, val func loss 0.21846432983875275\n",
      "\n",
      "Val func train loss in epoch 15:0.18852386996150017\n",
      "***********************TIME WAS 4.972175451119741 min*****************************\n",
      "\n",
      "**********************ROUND 92 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.09056397527456284\n",
      "\n",
      "episode 2, policy loss -0.0672350600361824\n",
      "\n",
      "episode 3, policy loss -0.028076190501451492\n",
      "\n",
      "episode 4, policy loss -0.02388303168118\n",
      "\n",
      "episode 5, policy loss -0.06530534476041794\n",
      "\n",
      "episode 6, policy loss -0.050289154052734375\n",
      "\n",
      "episode 7, policy loss -0.04175374656915665\n",
      "\n",
      "episode 8, policy loss -0.04869740083813667\n",
      "\n",
      "episode 9, policy loss -0.013349324464797974\n",
      "\n",
      "episode 10, policy loss -0.05527873709797859\n",
      "\n",
      "episode 11, policy loss -0.03757640719413757\n",
      "\n",
      "episode 12, policy loss 0.03149349242448807\n",
      "\n",
      "episode 13, policy loss -0.028052056208252907\n",
      "\n",
      "episode 14, policy loss -0.054100628942251205\n",
      "\n",
      "episode 15, policy loss -0.1045025885105133\n",
      "\n",
      "episode 16, policy loss -0.07133027166128159\n",
      "\n",
      "Policy train loss in epoch 0:-0.046781276585534215\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.08034534007310867\n",
      "\n",
      "episode 2, policy loss -0.07110791653394699\n",
      "\n",
      "episode 3, policy loss -0.04828653857111931\n",
      "\n",
      "episode 4, policy loss -0.05295873060822487\n",
      "\n",
      "episode 5, policy loss -0.10469911992549896\n",
      "\n",
      "episode 6, policy loss -0.03971823677420616\n",
      "\n",
      "episode 7, policy loss -0.05206557735800743\n",
      "\n",
      "episode 8, policy loss -0.03644724190235138\n",
      "\n",
      "episode 9, policy loss -0.025894181802868843\n",
      "\n",
      "episode 10, policy loss -0.05787966772913933\n",
      "\n",
      "episode 11, policy loss 0.029263945296406746\n",
      "\n",
      "episode 12, policy loss -0.0960441306233406\n",
      "\n",
      "episode 13, policy loss -0.04437321424484253\n",
      "\n",
      "episode 14, policy loss -0.06983856111764908\n",
      "\n",
      "episode 15, policy loss -0.01547887735068798\n",
      "\n",
      "episode 16, policy loss -0.029508301988244057\n",
      "\n",
      "Policy train loss in epoch 1:-0.04971135570667684\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.0953497365117073\n",
      "\n",
      "episode 2, policy loss -0.052523110061883926\n",
      "\n",
      "episode 3, policy loss -0.01568836346268654\n",
      "\n",
      "episode 4, policy loss -0.056572962552309036\n",
      "\n",
      "episode 5, policy loss -0.02925959974527359\n",
      "\n",
      "episode 6, policy loss -0.10494939982891083\n",
      "\n",
      "episode 7, policy loss -0.03562552481889725\n",
      "\n",
      "episode 8, policy loss -0.07095978409051895\n",
      "\n",
      "episode 9, policy loss -0.07027249038219452\n",
      "\n",
      "episode 10, policy loss -0.046047668904066086\n",
      "\n",
      "episode 11, policy loss -0.08078740537166595\n",
      "\n",
      "episode 12, policy loss 0.03082461841404438\n",
      "\n",
      "episode 13, policy loss -0.05254126340150833\n",
      "\n",
      "episode 14, policy loss -0.048525016754865646\n",
      "\n",
      "episode 15, policy loss -0.03947088494896889\n",
      "\n",
      "episode 16, policy loss -0.025502633303403854\n",
      "\n",
      "Policy train loss in epoch 2:-0.04957820160780102\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.04940496012568474\n",
      "\n",
      "episode 2, policy loss -0.09558994323015213\n",
      "\n",
      "episode 3, policy loss -0.028727415949106216\n",
      "\n",
      "episode 4, policy loss -0.0689699798822403\n",
      "\n",
      "episode 5, policy loss -0.03465099260210991\n",
      "\n",
      "episode 6, policy loss -0.07001204043626785\n",
      "\n",
      "episode 7, policy loss -0.026560019701719284\n",
      "\n",
      "episode 8, policy loss -0.07924382388591766\n",
      "\n",
      "episode 9, policy loss -0.05229319632053375\n",
      "\n",
      "episode 10, policy loss -0.10522229969501495\n",
      "\n",
      "episode 11, policy loss -0.046441901475191116\n",
      "\n",
      "episode 12, policy loss -0.03741208091378212\n",
      "\n",
      "episode 13, policy loss 0.03104938194155693\n",
      "\n",
      "episode 14, policy loss -0.05304790288209915\n",
      "\n",
      "episode 15, policy loss -0.014777245931327343\n",
      "\n",
      "episode 16, policy loss -0.05712609365582466\n",
      "\n",
      "Policy train loss in epoch 3:-0.04927690717158839\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.15712706744670868\n",
      "\n",
      "episode 2, val func loss 0.20771794021129608\n",
      "\n",
      "episode 3, val func loss 0.17376305162906647\n",
      "\n",
      "episode 4, val func loss 0.1730676293373108\n",
      "\n",
      "episode 5, val func loss 0.22367550432682037\n",
      "\n",
      "episode 6, val func loss 0.20621415972709656\n",
      "\n",
      "episode 7, val func loss 0.18600663542747498\n",
      "\n",
      "episode 8, val func loss 0.187185138463974\n",
      "\n",
      "episode 9, val func loss 0.2005518674850464\n",
      "\n",
      "episode 10, val func loss 0.17514322698116302\n",
      "\n",
      "episode 11, val func loss 0.19107350707054138\n",
      "\n",
      "episode 12, val func loss 0.20047540962696075\n",
      "\n",
      "episode 13, val func loss 0.18449360132217407\n",
      "\n",
      "episode 14, val func loss 0.1783987581729889\n",
      "\n",
      "episode 15, val func loss 0.21685826778411865\n",
      "\n",
      "episode 16, val func loss 0.18529142439365387\n",
      "\n",
      "Val func train loss in epoch 0:0.19044019933789968\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1753608137369156\n",
      "\n",
      "episode 2, val func loss 0.20011354982852936\n",
      "\n",
      "episode 3, val func loss 0.18570120632648468\n",
      "\n",
      "episode 4, val func loss 0.20611922442913055\n",
      "\n",
      "episode 5, val func loss 0.17934314906597137\n",
      "\n",
      "episode 6, val func loss 0.17372295260429382\n",
      "\n",
      "episode 7, val func loss 0.21642370522022247\n",
      "\n",
      "episode 8, val func loss 0.1911710649728775\n",
      "\n",
      "episode 9, val func loss 0.18507619202136993\n",
      "\n",
      "episode 10, val func loss 0.1849365085363388\n",
      "\n",
      "episode 11, val func loss 0.17347683012485504\n",
      "\n",
      "episode 12, val func loss 0.22522905468940735\n",
      "\n",
      "episode 13, val func loss 0.1571856588125229\n",
      "\n",
      "episode 14, val func loss 0.20799143612384796\n",
      "\n",
      "episode 15, val func loss 0.18530771136283875\n",
      "\n",
      "episode 16, val func loss 0.19899483025074005\n",
      "\n",
      "Val func train loss in epoch 1:0.19038461800664663\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17807286977767944\n",
      "\n",
      "episode 2, val func loss 0.1910676509141922\n",
      "\n",
      "episode 3, val func loss 0.21574321389198303\n",
      "\n",
      "episode 4, val func loss 0.1844695806503296\n",
      "\n",
      "episode 5, val func loss 0.22140465676784515\n",
      "\n",
      "episode 6, val func loss 0.17490169405937195\n",
      "\n",
      "episode 7, val func loss 0.18580850958824158\n",
      "\n",
      "episode 8, val func loss 0.20541507005691528\n",
      "\n",
      "episode 9, val func loss 0.1846230924129486\n",
      "\n",
      "episode 10, val func loss 0.17433340847492218\n",
      "\n",
      "episode 11, val func loss 0.17356109619140625\n",
      "\n",
      "episode 12, val func loss 0.19921404123306274\n",
      "\n",
      "episode 13, val func loss 0.18350794911384583\n",
      "\n",
      "episode 14, val func loss 0.15577417612075806\n",
      "\n",
      "episode 15, val func loss 0.2145652025938034\n",
      "\n",
      "episode 16, val func loss 0.2036294937133789\n",
      "\n",
      "Val func train loss in epoch 2:0.19038073159754276\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.21808210015296936\n",
      "\n",
      "episode 2, val func loss 0.1843642145395279\n",
      "\n",
      "episode 3, val func loss 0.17175857722759247\n",
      "\n",
      "episode 4, val func loss 0.177509605884552\n",
      "\n",
      "episode 5, val func loss 0.19836783409118652\n",
      "\n",
      "episode 6, val func loss 0.2189302295446396\n",
      "\n",
      "episode 7, val func loss 0.1974470615386963\n",
      "\n",
      "episode 8, val func loss 0.1946331411600113\n",
      "\n",
      "episode 9, val func loss 0.17951683700084686\n",
      "\n",
      "episode 10, val func loss 0.17612017691135406\n",
      "\n",
      "episode 11, val func loss 0.18520613014698029\n",
      "\n",
      "episode 12, val func loss 0.1842903345823288\n",
      "\n",
      "episode 13, val func loss 0.20635497570037842\n",
      "\n",
      "episode 14, val func loss 0.15800660848617554\n",
      "\n",
      "episode 15, val func loss 0.20625148713588715\n",
      "\n",
      "episode 16, val func loss 0.1855861097574234\n",
      "\n",
      "Val func train loss in epoch 3:0.19015158899128437\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.22315405309200287\n",
      "\n",
      "episode 2, val func loss 0.19115647673606873\n",
      "\n",
      "episode 3, val func loss 0.19817887246608734\n",
      "\n",
      "episode 4, val func loss 0.18538060784339905\n",
      "\n",
      "episode 5, val func loss 0.18638892471790314\n",
      "\n",
      "episode 6, val func loss 0.1740597039461136\n",
      "\n",
      "episode 7, val func loss 0.15669283270835876\n",
      "\n",
      "episode 8, val func loss 0.17925047874450684\n",
      "\n",
      "episode 9, val func loss 0.2075037807226181\n",
      "\n",
      "episode 10, val func loss 0.17267192900180817\n",
      "\n",
      "episode 11, val func loss 0.21952472627162933\n",
      "\n",
      "episode 12, val func loss 0.18295028805732727\n",
      "\n",
      "episode 13, val func loss 0.2075367420911789\n",
      "\n",
      "episode 14, val func loss 0.18412244319915771\n",
      "\n",
      "episode 15, val func loss 0.18127897381782532\n",
      "\n",
      "episode 16, val func loss 0.19911156594753265\n",
      "\n",
      "Val func train loss in epoch 4:0.19056014996021986\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.2011205106973648\n",
      "\n",
      "episode 2, val func loss 0.2162325084209442\n",
      "\n",
      "episode 3, val func loss 0.18763016164302826\n",
      "\n",
      "episode 4, val func loss 0.22119398415088654\n",
      "\n",
      "episode 5, val func loss 0.17734649777412415\n",
      "\n",
      "episode 6, val func loss 0.2053397297859192\n",
      "\n",
      "episode 7, val func loss 0.18420572578907013\n",
      "\n",
      "episode 8, val func loss 0.20639710128307343\n",
      "\n",
      "episode 9, val func loss 0.20015949010849\n",
      "\n",
      "episode 10, val func loss 0.19170570373535156\n",
      "\n",
      "episode 11, val func loss 0.18587476015090942\n",
      "\n",
      "episode 12, val func loss 0.17575500905513763\n",
      "\n",
      "episode 13, val func loss 0.15748576819896698\n",
      "\n",
      "episode 14, val func loss 0.1855262666940689\n",
      "\n",
      "episode 15, val func loss 0.17225748300552368\n",
      "\n",
      "episode 16, val func loss 0.1792602390050888\n",
      "\n",
      "Val func train loss in epoch 5:0.19046818371862173\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1555577516555786\n",
      "\n",
      "episode 2, val func loss 0.18609976768493652\n",
      "\n",
      "episode 3, val func loss 0.20304112136363983\n",
      "\n",
      "episode 4, val func loss 0.19191353023052216\n",
      "\n",
      "episode 5, val func loss 0.1735863834619522\n",
      "\n",
      "episode 6, val func loss 0.20695681869983673\n",
      "\n",
      "episode 7, val func loss 0.21586310863494873\n",
      "\n",
      "episode 8, val func loss 0.20054100453853607\n",
      "\n",
      "episode 9, val func loss 0.18805193901062012\n",
      "\n",
      "episode 10, val func loss 0.178900346159935\n",
      "\n",
      "episode 11, val func loss 0.175131693482399\n",
      "\n",
      "episode 12, val func loss 0.18558603525161743\n",
      "\n",
      "episode 13, val func loss 0.17573468387126923\n",
      "\n",
      "episode 14, val func loss 0.20799840986728668\n",
      "\n",
      "episode 15, val func loss 0.22395528852939606\n",
      "\n",
      "episode 16, val func loss 0.18568091094493866\n",
      "\n",
      "Val func train loss in epoch 6:0.19091242458671331\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17343486845493317\n",
      "\n",
      "episode 2, val func loss 0.18558992445468903\n",
      "\n",
      "episode 3, val func loss 0.15890046954154968\n",
      "\n",
      "episode 4, val func loss 0.18528975546360016\n",
      "\n",
      "episode 5, val func loss 0.208515003323555\n",
      "\n",
      "episode 6, val func loss 0.18514567613601685\n",
      "\n",
      "episode 7, val func loss 0.1787341982126236\n",
      "\n",
      "episode 8, val func loss 0.19140678644180298\n",
      "\n",
      "episode 9, val func loss 0.2241673767566681\n",
      "\n",
      "episode 10, val func loss 0.2009585052728653\n",
      "\n",
      "episode 11, val func loss 0.2150598019361496\n",
      "\n",
      "episode 12, val func loss 0.17557330429553986\n",
      "\n",
      "episode 13, val func loss 0.2024865448474884\n",
      "\n",
      "episode 14, val func loss 0.17784006893634796\n",
      "\n",
      "episode 15, val func loss 0.18690615892410278\n",
      "\n",
      "episode 16, val func loss 0.20592398941516876\n",
      "\n",
      "Val func train loss in epoch 7:0.19099577702581882\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.20021076500415802\n",
      "\n",
      "episode 2, val func loss 0.17334721982479095\n",
      "\n",
      "episode 3, val func loss 0.17826992273330688\n",
      "\n",
      "episode 4, val func loss 0.18425580859184265\n",
      "\n",
      "episode 5, val func loss 0.20360581576824188\n",
      "\n",
      "episode 6, val func loss 0.2100791484117508\n",
      "\n",
      "episode 7, val func loss 0.2191539853811264\n",
      "\n",
      "episode 8, val func loss 0.1852571666240692\n",
      "\n",
      "episode 9, val func loss 0.22256267070770264\n",
      "\n",
      "episode 10, val func loss 0.17614804208278656\n",
      "\n",
      "episode 11, val func loss 0.19168025255203247\n",
      "\n",
      "episode 12, val func loss 0.16531184315681458\n",
      "\n",
      "episode 13, val func loss 0.20523765683174133\n",
      "\n",
      "episode 14, val func loss 0.1835714727640152\n",
      "\n",
      "episode 15, val func loss 0.1734512597322464\n",
      "\n",
      "episode 16, val func loss 0.18467944860458374\n",
      "\n",
      "Val func train loss in epoch 8:0.1910514049232006\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18343929946422577\n",
      "\n",
      "episode 2, val func loss 0.20881761610507965\n",
      "\n",
      "episode 3, val func loss 0.18738137185573578\n",
      "\n",
      "episode 4, val func loss 0.21913781762123108\n",
      "\n",
      "episode 5, val func loss 0.17436976730823517\n",
      "\n",
      "episode 6, val func loss 0.22134578227996826\n",
      "\n",
      "episode 7, val func loss 0.1765786111354828\n",
      "\n",
      "episode 8, val func loss 0.17966921627521515\n",
      "\n",
      "episode 9, val func loss 0.19145487248897552\n",
      "\n",
      "episode 10, val func loss 0.19945518672466278\n",
      "\n",
      "episode 11, val func loss 0.18504458665847778\n",
      "\n",
      "episode 12, val func loss 0.21002106368541718\n",
      "\n",
      "episode 13, val func loss 0.20734082162380219\n",
      "\n",
      "episode 14, val func loss 0.18496230244636536\n",
      "\n",
      "episode 15, val func loss 0.17578022181987762\n",
      "\n",
      "episode 16, val func loss 0.163117453455925\n",
      "\n",
      "Val func train loss in epoch 9:0.19174474943429232\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.17971497774124146\n",
      "\n",
      "episode 2, val func loss 0.18648815155029297\n",
      "\n",
      "episode 3, val func loss 0.18474000692367554\n",
      "\n",
      "episode 4, val func loss 0.1735549420118332\n",
      "\n",
      "episode 5, val func loss 0.18432356417179108\n",
      "\n",
      "episode 6, val func loss 0.19923417270183563\n",
      "\n",
      "episode 7, val func loss 0.17767836153507233\n",
      "\n",
      "episode 8, val func loss 0.21877537667751312\n",
      "\n",
      "episode 9, val func loss 0.1731434464454651\n",
      "\n",
      "episode 10, val func loss 0.15982317924499512\n",
      "\n",
      "episode 11, val func loss 0.18430867791175842\n",
      "\n",
      "episode 12, val func loss 0.1988183706998825\n",
      "\n",
      "episode 13, val func loss 0.20575390756130219\n",
      "\n",
      "episode 14, val func loss 0.19186389446258545\n",
      "\n",
      "episode 15, val func loss 0.20646941661834717\n",
      "\n",
      "episode 16, val func loss 0.22171595692634583\n",
      "\n",
      "Val func train loss in epoch 10:0.19040040019899607\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18335790932178497\n",
      "\n",
      "episode 2, val func loss 0.17669329047203064\n",
      "\n",
      "episode 3, val func loss 0.1863943189382553\n",
      "\n",
      "episode 4, val func loss 0.19929984211921692\n",
      "\n",
      "episode 5, val func loss 0.2046583741903305\n",
      "\n",
      "episode 6, val func loss 0.22151242196559906\n",
      "\n",
      "episode 7, val func loss 0.17521540820598602\n",
      "\n",
      "episode 8, val func loss 0.1758817881345749\n",
      "\n",
      "episode 9, val func loss 0.19959142804145813\n",
      "\n",
      "episode 10, val func loss 0.15898779034614563\n",
      "\n",
      "episode 11, val func loss 0.1837923526763916\n",
      "\n",
      "episode 12, val func loss 0.1949775367975235\n",
      "\n",
      "episode 13, val func loss 0.22480201721191406\n",
      "\n",
      "episode 14, val func loss 0.21362298727035522\n",
      "\n",
      "episode 15, val func loss 0.1792822778224945\n",
      "\n",
      "episode 16, val func loss 0.18465784192085266\n",
      "\n",
      "Val func train loss in epoch 11:0.1914204740896821\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17815929651260376\n",
      "\n",
      "episode 2, val func loss 0.19058039784431458\n",
      "\n",
      "episode 3, val func loss 0.1750057488679886\n",
      "\n",
      "episode 4, val func loss 0.1863369196653366\n",
      "\n",
      "episode 5, val func loss 0.17570999264717102\n",
      "\n",
      "episode 6, val func loss 0.20516294240951538\n",
      "\n",
      "episode 7, val func loss 0.1844625025987625\n",
      "\n",
      "episode 8, val func loss 0.18743403255939484\n",
      "\n",
      "episode 9, val func loss 0.1856212019920349\n",
      "\n",
      "episode 10, val func loss 0.17350411415100098\n",
      "\n",
      "episode 11, val func loss 0.20634174346923828\n",
      "\n",
      "episode 12, val func loss 0.2255835086107254\n",
      "\n",
      "episode 13, val func loss 0.20002666115760803\n",
      "\n",
      "episode 14, val func loss 0.21674981713294983\n",
      "\n",
      "episode 15, val func loss 0.15885059535503387\n",
      "\n",
      "episode 16, val func loss 0.1983030140399933\n",
      "\n",
      "Val func train loss in epoch 12:0.1904895305633545\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19129852950572968\n",
      "\n",
      "episode 2, val func loss 0.15852732956409454\n",
      "\n",
      "episode 3, val func loss 0.17524178326129913\n",
      "\n",
      "episode 4, val func loss 0.1744755506515503\n",
      "\n",
      "episode 5, val func loss 0.2071181684732437\n",
      "\n",
      "episode 6, val func loss 0.2080683559179306\n",
      "\n",
      "episode 7, val func loss 0.22584708034992218\n",
      "\n",
      "episode 8, val func loss 0.1735345870256424\n",
      "\n",
      "episode 9, val func loss 0.2158106118440628\n",
      "\n",
      "episode 10, val func loss 0.1781143695116043\n",
      "\n",
      "episode 11, val func loss 0.18525269627571106\n",
      "\n",
      "episode 12, val func loss 0.199159175157547\n",
      "\n",
      "episode 13, val func loss 0.1834772378206253\n",
      "\n",
      "episode 14, val func loss 0.18618878722190857\n",
      "\n",
      "episode 15, val func loss 0.18677306175231934\n",
      "\n",
      "episode 16, val func loss 0.20030739903450012\n",
      "\n",
      "Val func train loss in epoch 13:0.1905746702104807\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17233997583389282\n",
      "\n",
      "episode 2, val func loss 0.2014341652393341\n",
      "\n",
      "episode 3, val func loss 0.19247575104236603\n",
      "\n",
      "episode 4, val func loss 0.17703093588352203\n",
      "\n",
      "episode 5, val func loss 0.22573889791965485\n",
      "\n",
      "episode 6, val func loss 0.20616105198860168\n",
      "\n",
      "episode 7, val func loss 0.18607550859451294\n",
      "\n",
      "episode 8, val func loss 0.17759311199188232\n",
      "\n",
      "episode 9, val func loss 0.15776120126247406\n",
      "\n",
      "episode 10, val func loss 0.1988772600889206\n",
      "\n",
      "episode 11, val func loss 0.17456653714179993\n",
      "\n",
      "episode 12, val func loss 0.18376228213310242\n",
      "\n",
      "episode 13, val func loss 0.21684104204177856\n",
      "\n",
      "episode 14, val func loss 0.1854439377784729\n",
      "\n",
      "episode 15, val func loss 0.20800606906414032\n",
      "\n",
      "episode 16, val func loss 0.18504315614700317\n",
      "\n",
      "Val func train loss in epoch 14:0.19057193025946617\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.21761813759803772\n",
      "\n",
      "episode 2, val func loss 0.2045438587665558\n",
      "\n",
      "episode 3, val func loss 0.1845940500497818\n",
      "\n",
      "episode 4, val func loss 0.17977866530418396\n",
      "\n",
      "episode 5, val func loss 0.18792256712913513\n",
      "\n",
      "episode 6, val func loss 0.18282952904701233\n",
      "\n",
      "episode 7, val func loss 0.1862424612045288\n",
      "\n",
      "episode 8, val func loss 0.22170208394527435\n",
      "\n",
      "episode 9, val func loss 0.20487499237060547\n",
      "\n",
      "episode 10, val func loss 0.19043049216270447\n",
      "\n",
      "episode 11, val func loss 0.17447318136692047\n",
      "\n",
      "episode 12, val func loss 0.1780284345149994\n",
      "\n",
      "episode 13, val func loss 0.20023535192012787\n",
      "\n",
      "episode 14, val func loss 0.17466816306114197\n",
      "\n",
      "episode 15, val func loss 0.198739156126976\n",
      "\n",
      "episode 16, val func loss 0.1577417403459549\n",
      "\n",
      "Val func train loss in epoch 15:0.19027642905712128\n",
      "***********************TIME WAS 4.971834051609039 min*****************************\n",
      "\n",
      "**********************ROUND 93 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.007799389772117138\n",
      "\n",
      "episode 2, policy loss -0.05370742455124855\n",
      "\n",
      "episode 3, policy loss 0.014418326318264008\n",
      "\n",
      "episode 4, policy loss -0.009742878377437592\n",
      "\n",
      "episode 5, policy loss -0.012611600570380688\n",
      "\n",
      "episode 6, policy loss -0.06430473178625107\n",
      "\n",
      "episode 7, policy loss -0.0548539012670517\n",
      "\n",
      "episode 8, policy loss -0.039946526288986206\n",
      "\n",
      "episode 9, policy loss -0.02186420187354088\n",
      "\n",
      "episode 10, policy loss -0.06676559150218964\n",
      "\n",
      "episode 11, policy loss -0.053355079144239426\n",
      "\n",
      "episode 12, policy loss -0.06375547498464584\n",
      "\n",
      "episode 13, policy loss -0.054723285138607025\n",
      "\n",
      "episode 14, policy loss -0.030308282002806664\n",
      "\n",
      "episode 15, policy loss -0.052691638469696045\n",
      "\n",
      "episode 16, policy loss -0.026581905782222748\n",
      "\n",
      "Policy train loss in epoch 0:-0.037412099074572325\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.01839650236070156\n",
      "\n",
      "episode 2, policy loss -0.014629406854510307\n",
      "\n",
      "episode 3, policy loss -0.05467893183231354\n",
      "\n",
      "episode 4, policy loss -0.062086280435323715\n",
      "\n",
      "episode 5, policy loss 0.010127907618880272\n",
      "\n",
      "episode 6, policy loss -0.06477122753858566\n",
      "\n",
      "episode 7, policy loss -0.06962954998016357\n",
      "\n",
      "episode 8, policy loss -0.057550594210624695\n",
      "\n",
      "episode 9, policy loss -0.055583398789167404\n",
      "\n",
      "episode 10, policy loss -0.038500744849443436\n",
      "\n",
      "episode 11, policy loss -0.0698743462562561\n",
      "\n",
      "episode 12, policy loss -0.016171468421816826\n",
      "\n",
      "episode 13, policy loss -0.02505607157945633\n",
      "\n",
      "episode 14, policy loss -0.01261071301996708\n",
      "\n",
      "episode 15, policy loss -0.05072588101029396\n",
      "\n",
      "episode 16, policy loss -0.03927784413099289\n",
      "\n",
      "Policy train loss in epoch 1:-0.03996344085317105\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.05564909800887108\n",
      "\n",
      "episode 2, policy loss -0.014821633696556091\n",
      "\n",
      "episode 3, policy loss -0.0630018413066864\n",
      "\n",
      "episode 4, policy loss -0.03982635959982872\n",
      "\n",
      "episode 5, policy loss -0.025312654674053192\n",
      "\n",
      "episode 6, policy loss 0.013630308210849762\n",
      "\n",
      "episode 7, policy loss -0.01874290034174919\n",
      "\n",
      "episode 8, policy loss -0.023032793775200844\n",
      "\n",
      "episode 9, policy loss -0.05329109728336334\n",
      "\n",
      "episode 10, policy loss -0.05522553622722626\n",
      "\n",
      "episode 11, policy loss -0.03208447992801666\n",
      "\n",
      "episode 12, policy loss -0.06855792552232742\n",
      "\n",
      "episode 13, policy loss -0.06496518105268478\n",
      "\n",
      "episode 14, policy loss -0.05702681839466095\n",
      "\n",
      "episode 15, policy loss -0.014221574179828167\n",
      "\n",
      "episode 16, policy loss -0.06803188472986221\n",
      "\n",
      "Policy train loss in epoch 2:-0.0400100919068791\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.01994858868420124\n",
      "\n",
      "episode 2, policy loss 0.00943360198289156\n",
      "\n",
      "episode 3, policy loss -0.06099472939968109\n",
      "\n",
      "episode 4, policy loss -0.06965316087007523\n",
      "\n",
      "episode 5, policy loss -0.03747265413403511\n",
      "\n",
      "episode 6, policy loss -0.025732513517141342\n",
      "\n",
      "episode 7, policy loss -0.0692526325583458\n",
      "\n",
      "episode 8, policy loss -0.015083747915923595\n",
      "\n",
      "episode 9, policy loss -0.057253431528806686\n",
      "\n",
      "episode 10, policy loss -0.05537369102239609\n",
      "\n",
      "episode 11, policy loss -0.014951796270906925\n",
      "\n",
      "episode 12, policy loss -0.05475085228681564\n",
      "\n",
      "episode 13, policy loss -0.06527402251958847\n",
      "\n",
      "episode 14, policy loss -0.03785496577620506\n",
      "\n",
      "episode 15, policy loss -0.052245933562517166\n",
      "\n",
      "episode 16, policy loss -0.01776760257780552\n",
      "\n",
      "Policy train loss in epoch 3:-0.04026104504009709\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1925896406173706\n",
      "\n",
      "episode 2, val func loss 0.17729339003562927\n",
      "\n",
      "episode 3, val func loss 0.20118854939937592\n",
      "\n",
      "episode 4, val func loss 0.1823270320892334\n",
      "\n",
      "episode 5, val func loss 0.17675001919269562\n",
      "\n",
      "episode 6, val func loss 0.17842599749565125\n",
      "\n",
      "episode 7, val func loss 0.16872292757034302\n",
      "\n",
      "episode 8, val func loss 0.17398002743721008\n",
      "\n",
      "episode 9, val func loss 0.20342445373535156\n",
      "\n",
      "episode 10, val func loss 0.18755441904067993\n",
      "\n",
      "episode 11, val func loss 0.1940656155347824\n",
      "\n",
      "episode 12, val func loss 0.18913957476615906\n",
      "\n",
      "episode 13, val func loss 0.19420257210731506\n",
      "\n",
      "episode 14, val func loss 0.20017093420028687\n",
      "\n",
      "episode 15, val func loss 0.18341870605945587\n",
      "\n",
      "episode 16, val func loss 0.19953304529190063\n",
      "\n",
      "Val func train loss in epoch 0:0.18767418153584003\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19199496507644653\n",
      "\n",
      "episode 2, val func loss 0.1857011467218399\n",
      "\n",
      "episode 3, val func loss 0.19426244497299194\n",
      "\n",
      "episode 4, val func loss 0.19698749482631683\n",
      "\n",
      "episode 5, val func loss 0.17113010585308075\n",
      "\n",
      "episode 6, val func loss 0.1722172647714615\n",
      "\n",
      "episode 7, val func loss 0.177594393491745\n",
      "\n",
      "episode 8, val func loss 0.1995074301958084\n",
      "\n",
      "episode 9, val func loss 0.19841589033603668\n",
      "\n",
      "episode 10, val func loss 0.17898572981357574\n",
      "\n",
      "episode 11, val func loss 0.19948440790176392\n",
      "\n",
      "episode 12, val func loss 0.18842585384845734\n",
      "\n",
      "episode 13, val func loss 0.1824180781841278\n",
      "\n",
      "episode 14, val func loss 0.20163236558437347\n",
      "\n",
      "episode 15, val func loss 0.19166097044944763\n",
      "\n",
      "episode 16, val func loss 0.18257151544094086\n",
      "\n",
      "Val func train loss in epoch 1:0.1883118785917759\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1828332245349884\n",
      "\n",
      "episode 2, val func loss 0.19986410439014435\n",
      "\n",
      "episode 3, val func loss 0.1780083179473877\n",
      "\n",
      "episode 4, val func loss 0.19306257367134094\n",
      "\n",
      "episode 5, val func loss 0.17221684753894806\n",
      "\n",
      "episode 6, val func loss 0.1919211894273758\n",
      "\n",
      "episode 7, val func loss 0.18911609053611755\n",
      "\n",
      "episode 8, val func loss 0.1779535561800003\n",
      "\n",
      "episode 9, val func loss 0.19865243136882782\n",
      "\n",
      "episode 10, val func loss 0.18203561007976532\n",
      "\n",
      "episode 11, val func loss 0.17803190648555756\n",
      "\n",
      "episode 12, val func loss 0.18872196972370148\n",
      "\n",
      "episode 13, val func loss 0.20301303267478943\n",
      "\n",
      "episode 14, val func loss 0.17716211080551147\n",
      "\n",
      "episode 15, val func loss 0.19731156527996063\n",
      "\n",
      "episode 16, val func loss 0.19701120257377625\n",
      "\n",
      "Val func train loss in epoch 2:0.18793223332613707\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1959492415189743\n",
      "\n",
      "episode 2, val func loss 0.19878605008125305\n",
      "\n",
      "episode 3, val func loss 0.20123746991157532\n",
      "\n",
      "episode 4, val func loss 0.1917140632867813\n",
      "\n",
      "episode 5, val func loss 0.18489302694797516\n",
      "\n",
      "episode 6, val func loss 0.18273833394050598\n",
      "\n",
      "episode 7, val func loss 0.17878976464271545\n",
      "\n",
      "episode 8, val func loss 0.18447375297546387\n",
      "\n",
      "episode 9, val func loss 0.19566306471824646\n",
      "\n",
      "episode 10, val func loss 0.18949498236179352\n",
      "\n",
      "episode 11, val func loss 0.1722702533006668\n",
      "\n",
      "episode 12, val func loss 0.17797274887561798\n",
      "\n",
      "episode 13, val func loss 0.19000127911567688\n",
      "\n",
      "episode 14, val func loss 0.18696726858615875\n",
      "\n",
      "episode 15, val func loss 0.17039887607097626\n",
      "\n",
      "episode 16, val func loss 0.19853301346302032\n",
      "\n",
      "Val func train loss in epoch 3:0.1874926993623376\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.20108933746814728\n",
      "\n",
      "episode 2, val func loss 0.19680923223495483\n",
      "\n",
      "episode 3, val func loss 0.17150776088237762\n",
      "\n",
      "episode 4, val func loss 0.1804789900779724\n",
      "\n",
      "episode 5, val func loss 0.19551673531532288\n",
      "\n",
      "episode 6, val func loss 0.18518763780593872\n",
      "\n",
      "episode 7, val func loss 0.17796394228935242\n",
      "\n",
      "episode 8, val func loss 0.20021072030067444\n",
      "\n",
      "episode 9, val func loss 0.1888403296470642\n",
      "\n",
      "episode 10, val func loss 0.1740952879190445\n",
      "\n",
      "episode 11, val func loss 0.18597158789634705\n",
      "\n",
      "episode 12, val func loss 0.19620588421821594\n",
      "\n",
      "episode 13, val func loss 0.19158720970153809\n",
      "\n",
      "episode 14, val func loss 0.1970217227935791\n",
      "\n",
      "episode 15, val func loss 0.17987442016601562\n",
      "\n",
      "episode 16, val func loss 0.1775522232055664\n",
      "\n",
      "Val func train loss in epoch 4:0.18749456387013197\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18856596946716309\n",
      "\n",
      "episode 2, val func loss 0.18023046851158142\n",
      "\n",
      "episode 3, val func loss 0.1984385997056961\n",
      "\n",
      "episode 4, val func loss 0.20406974852085114\n",
      "\n",
      "episode 5, val func loss 0.19085173308849335\n",
      "\n",
      "episode 6, val func loss 0.19941280782222748\n",
      "\n",
      "episode 7, val func loss 0.17079836130142212\n",
      "\n",
      "episode 8, val func loss 0.1975310891866684\n",
      "\n",
      "episode 9, val func loss 0.1932700276374817\n",
      "\n",
      "episode 10, val func loss 0.18934237957000732\n",
      "\n",
      "episode 11, val func loss 0.1797228902578354\n",
      "\n",
      "episode 12, val func loss 0.18456771969795227\n",
      "\n",
      "episode 13, val func loss 0.19642622768878937\n",
      "\n",
      "episode 14, val func loss 0.17359007894992828\n",
      "\n",
      "episode 15, val func loss 0.18340125679969788\n",
      "\n",
      "episode 16, val func loss 0.1776822805404663\n",
      "\n",
      "Val func train loss in epoch 5:0.18799385242164135\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19190803170204163\n",
      "\n",
      "episode 2, val func loss 0.1701546609401703\n",
      "\n",
      "episode 3, val func loss 0.19598832726478577\n",
      "\n",
      "episode 4, val func loss 0.19763346016407013\n",
      "\n",
      "episode 5, val func loss 0.17235659062862396\n",
      "\n",
      "episode 6, val func loss 0.20331279933452606\n",
      "\n",
      "episode 7, val func loss 0.17766690254211426\n",
      "\n",
      "episode 8, val func loss 0.1771668642759323\n",
      "\n",
      "episode 9, val func loss 0.1867576688528061\n",
      "\n",
      "episode 10, val func loss 0.18300750851631165\n",
      "\n",
      "episode 11, val func loss 0.18151088058948517\n",
      "\n",
      "episode 12, val func loss 0.18272018432617188\n",
      "\n",
      "episode 13, val func loss 0.1985100358724594\n",
      "\n",
      "episode 14, val func loss 0.19862788915634155\n",
      "\n",
      "episode 15, val func loss 0.1968802660703659\n",
      "\n",
      "episode 16, val func loss 0.18775956332683563\n",
      "\n",
      "Val func train loss in epoch 6:0.1876226020976901\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17772190272808075\n",
      "\n",
      "episode 2, val func loss 0.19823680818080902\n",
      "\n",
      "episode 3, val func loss 0.17989635467529297\n",
      "\n",
      "episode 4, val func loss 0.18366485834121704\n",
      "\n",
      "episode 5, val func loss 0.19717220962047577\n",
      "\n",
      "episode 6, val func loss 0.18263112008571625\n",
      "\n",
      "episode 7, val func loss 0.1711307168006897\n",
      "\n",
      "episode 8, val func loss 0.1944602131843567\n",
      "\n",
      "episode 9, val func loss 0.17341507971286774\n",
      "\n",
      "episode 10, val func loss 0.1877307891845703\n",
      "\n",
      "episode 11, val func loss 0.1865629106760025\n",
      "\n",
      "episode 12, val func loss 0.19858132302761078\n",
      "\n",
      "episode 13, val func loss 0.17750056087970734\n",
      "\n",
      "episode 14, val func loss 0.20191752910614014\n",
      "\n",
      "episode 15, val func loss 0.19067540764808655\n",
      "\n",
      "episode 16, val func loss 0.19495506584644318\n",
      "\n",
      "Val func train loss in epoch 7:0.18726580310612917\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17240798473358154\n",
      "\n",
      "episode 2, val func loss 0.19651633501052856\n",
      "\n",
      "episode 3, val func loss 0.19607071578502655\n",
      "\n",
      "episode 4, val func loss 0.19979329407215118\n",
      "\n",
      "episode 5, val func loss 0.18052560091018677\n",
      "\n",
      "episode 6, val func loss 0.19727648794651031\n",
      "\n",
      "episode 7, val func loss 0.17800024151802063\n",
      "\n",
      "episode 8, val func loss 0.19082090258598328\n",
      "\n",
      "episode 9, val func loss 0.18513885140419006\n",
      "\n",
      "episode 10, val func loss 0.18654923141002655\n",
      "\n",
      "episode 11, val func loss 0.18722273409366608\n",
      "\n",
      "episode 12, val func loss 0.18024535477161407\n",
      "\n",
      "episode 13, val func loss 0.18098348379135132\n",
      "\n",
      "episode 14, val func loss 0.1944161355495453\n",
      "\n",
      "episode 15, val func loss 0.17107485234737396\n",
      "\n",
      "episode 16, val func loss 0.19776900112628937\n",
      "\n",
      "Val func train loss in epoch 8:0.18717570044100285\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18901357054710388\n",
      "\n",
      "episode 2, val func loss 0.20052337646484375\n",
      "\n",
      "episode 3, val func loss 0.17980049550533295\n",
      "\n",
      "episode 4, val func loss 0.17195652425289154\n",
      "\n",
      "episode 5, val func loss 0.17845329642295837\n",
      "\n",
      "episode 6, val func loss 0.18837693333625793\n",
      "\n",
      "episode 7, val func loss 0.196338951587677\n",
      "\n",
      "episode 8, val func loss 0.1809602826833725\n",
      "\n",
      "episode 9, val func loss 0.18952682614326477\n",
      "\n",
      "episode 10, val func loss 0.18374493718147278\n",
      "\n",
      "episode 11, val func loss 0.1771399974822998\n",
      "\n",
      "episode 12, val func loss 0.20021380484104156\n",
      "\n",
      "episode 13, val func loss 0.19459891319274902\n",
      "\n",
      "episode 14, val func loss 0.19577349722385406\n",
      "\n",
      "episode 15, val func loss 0.20101070404052734\n",
      "\n",
      "episode 16, val func loss 0.17229078710079193\n",
      "\n",
      "Val func train loss in epoch 9:0.18748268112540245\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19108635187149048\n",
      "\n",
      "episode 2, val func loss 0.19804681837558746\n",
      "\n",
      "episode 3, val func loss 0.1752379834651947\n",
      "\n",
      "episode 4, val func loss 0.1879483312368393\n",
      "\n",
      "episode 5, val func loss 0.18507343530654907\n",
      "\n",
      "episode 6, val func loss 0.17770840227603912\n",
      "\n",
      "episode 7, val func loss 0.18947315216064453\n",
      "\n",
      "episode 8, val func loss 0.19455961883068085\n",
      "\n",
      "episode 9, val func loss 0.1715974658727646\n",
      "\n",
      "episode 10, val func loss 0.196345254778862\n",
      "\n",
      "episode 11, val func loss 0.19559700787067413\n",
      "\n",
      "episode 12, val func loss 0.17022880911827087\n",
      "\n",
      "episode 13, val func loss 0.1986302137374878\n",
      "\n",
      "episode 14, val func loss 0.18204481899738312\n",
      "\n",
      "episode 15, val func loss 0.1819552779197693\n",
      "\n",
      "episode 16, val func loss 0.2012406289577484\n",
      "\n",
      "Val func train loss in epoch 10:0.1872983481734991\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19660960137844086\n",
      "\n",
      "episode 2, val func loss 0.1949910968542099\n",
      "\n",
      "episode 3, val func loss 0.1976647675037384\n",
      "\n",
      "episode 4, val func loss 0.20119762420654297\n",
      "\n",
      "episode 5, val func loss 0.1819339096546173\n",
      "\n",
      "episode 6, val func loss 0.1706816852092743\n",
      "\n",
      "episode 7, val func loss 0.1879235804080963\n",
      "\n",
      "episode 8, val func loss 0.19596876204013824\n",
      "\n",
      "episode 9, val func loss 0.19844095408916473\n",
      "\n",
      "episode 10, val func loss 0.17741653323173523\n",
      "\n",
      "episode 11, val func loss 0.18680015206336975\n",
      "\n",
      "episode 12, val func loss 0.17034508287906647\n",
      "\n",
      "episode 13, val func loss 0.17768937349319458\n",
      "\n",
      "episode 14, val func loss 0.1917310208082199\n",
      "\n",
      "episode 15, val func loss 0.18719936907291412\n",
      "\n",
      "episode 16, val func loss 0.18132902681827545\n",
      "\n",
      "Val func train loss in epoch 11:0.1873701587319374\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1956658959388733\n",
      "\n",
      "episode 2, val func loss 0.1813184916973114\n",
      "\n",
      "episode 3, val func loss 0.1842281073331833\n",
      "\n",
      "episode 4, val func loss 0.19932551681995392\n",
      "\n",
      "episode 5, val func loss 0.19710956513881683\n",
      "\n",
      "episode 6, val func loss 0.19115601480007172\n",
      "\n",
      "episode 7, val func loss 0.171807661652565\n",
      "\n",
      "episode 8, val func loss 0.17563454806804657\n",
      "\n",
      "episode 9, val func loss 0.19989129900932312\n",
      "\n",
      "episode 10, val func loss 0.17972376942634583\n",
      "\n",
      "episode 11, val func loss 0.18886862695217133\n",
      "\n",
      "episode 12, val func loss 0.2055015116930008\n",
      "\n",
      "episode 13, val func loss 0.17675180733203888\n",
      "\n",
      "episode 14, val func loss 0.19707439839839935\n",
      "\n",
      "episode 15, val func loss 0.19162553548812866\n",
      "\n",
      "episode 16, val func loss 0.17740805447101593\n",
      "\n",
      "Val func train loss in epoch 12:0.18831817526370287\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.17806792259216309\n",
      "\n",
      "episode 2, val func loss 0.17112840712070465\n",
      "\n",
      "episode 3, val func loss 0.18752267956733704\n",
      "\n",
      "episode 4, val func loss 0.18108251690864563\n",
      "\n",
      "episode 5, val func loss 0.18160198628902435\n",
      "\n",
      "episode 6, val func loss 0.19879277050495148\n",
      "\n",
      "episode 7, val func loss 0.17127537727355957\n",
      "\n",
      "episode 8, val func loss 0.1970374882221222\n",
      "\n",
      "episode 9, val func loss 0.1975206732749939\n",
      "\n",
      "episode 10, val func loss 0.1902521252632141\n",
      "\n",
      "episode 11, val func loss 0.19344577193260193\n",
      "\n",
      "episode 12, val func loss 0.17510804533958435\n",
      "\n",
      "episode 13, val func loss 0.1942371279001236\n",
      "\n",
      "episode 14, val func loss 0.1813725382089615\n",
      "\n",
      "episode 15, val func loss 0.18855047225952148\n",
      "\n",
      "episode 16, val func loss 0.2006426453590393\n",
      "\n",
      "Val func train loss in epoch 13:0.18672740925103426\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18659040331840515\n",
      "\n",
      "episode 2, val func loss 0.19115054607391357\n",
      "\n",
      "episode 3, val func loss 0.197401762008667\n",
      "\n",
      "episode 4, val func loss 0.17173446714878082\n",
      "\n",
      "episode 5, val func loss 0.17687346041202545\n",
      "\n",
      "episode 6, val func loss 0.1941148191690445\n",
      "\n",
      "episode 7, val func loss 0.1966298669576645\n",
      "\n",
      "episode 8, val func loss 0.19838909804821014\n",
      "\n",
      "episode 9, val func loss 0.19040726125240326\n",
      "\n",
      "episode 10, val func loss 0.17596115171909332\n",
      "\n",
      "episode 11, val func loss 0.19911861419677734\n",
      "\n",
      "episode 12, val func loss 0.1855359673500061\n",
      "\n",
      "episode 13, val func loss 0.17947867512702942\n",
      "\n",
      "episode 14, val func loss 0.18091681599617004\n",
      "\n",
      "episode 15, val func loss 0.16935914754867554\n",
      "\n",
      "episode 16, val func loss 0.2028885781764984\n",
      "\n",
      "Val func train loss in epoch 14:0.18728441465646029\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1705314815044403\n",
      "\n",
      "episode 2, val func loss 0.18154463171958923\n",
      "\n",
      "episode 3, val func loss 0.17054101824760437\n",
      "\n",
      "episode 4, val func loss 0.18610885739326477\n",
      "\n",
      "episode 5, val func loss 0.19890311360359192\n",
      "\n",
      "episode 6, val func loss 0.19672361016273499\n",
      "\n",
      "episode 7, val func loss 0.1959846317768097\n",
      "\n",
      "episode 8, val func loss 0.17944017052650452\n",
      "\n",
      "episode 9, val func loss 0.19043469429016113\n",
      "\n",
      "episode 10, val func loss 0.19016921520233154\n",
      "\n",
      "episode 11, val func loss 0.1789887249469757\n",
      "\n",
      "episode 12, val func loss 0.19387324154376984\n",
      "\n",
      "episode 13, val func loss 0.18787351250648499\n",
      "\n",
      "episode 14, val func loss 0.17882922291755676\n",
      "\n",
      "episode 15, val func loss 0.19741149246692657\n",
      "\n",
      "episode 16, val func loss 0.2014017552137375\n",
      "\n",
      "Val func train loss in epoch 15:0.18742246087640524\n",
      "***********************TIME WAS 4.9745442271232605 min*****************************\n",
      "\n",
      "**********************ROUND 94 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.10459598898887634\n",
      "\n",
      "episode 2, policy loss 0.12812574207782745\n",
      "\n",
      "episode 3, policy loss 0.16105790436267853\n",
      "\n",
      "episode 4, policy loss 0.10715130716562271\n",
      "\n",
      "episode 5, policy loss 0.038243379443883896\n",
      "\n",
      "episode 6, policy loss 0.08328329771757126\n",
      "\n",
      "episode 7, policy loss 0.11725311726331711\n",
      "\n",
      "episode 8, policy loss 0.09066496044397354\n",
      "\n",
      "episode 9, policy loss 0.07521062344312668\n",
      "\n",
      "episode 10, policy loss 0.061215609312057495\n",
      "\n",
      "episode 11, policy loss 0.0672890767455101\n",
      "\n",
      "episode 12, policy loss 0.08403890579938889\n",
      "\n",
      "episode 13, policy loss 0.08525307476520538\n",
      "\n",
      "episode 14, policy loss 0.1137252077460289\n",
      "\n",
      "episode 15, policy loss 0.020336559042334557\n",
      "\n",
      "episode 16, policy loss 0.11427677422761917\n",
      "\n",
      "Policy train loss in epoch 0:0.09073259553406388\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.06278844177722931\n",
      "\n",
      "episode 2, policy loss 0.05808299034833908\n",
      "\n",
      "episode 3, policy loss 0.15690039098262787\n",
      "\n",
      "episode 4, policy loss 0.07156407088041306\n",
      "\n",
      "episode 5, policy loss 0.019964534789323807\n",
      "\n",
      "episode 6, policy loss 0.08463085442781448\n",
      "\n",
      "episode 7, policy loss 0.10665023326873779\n",
      "\n",
      "episode 8, policy loss 0.12094210833311081\n",
      "\n",
      "episode 9, policy loss 0.11517034471035004\n",
      "\n",
      "episode 10, policy loss 0.11572746187448502\n",
      "\n",
      "episode 11, policy loss 0.09015800058841705\n",
      "\n",
      "episode 12, policy loss 0.08176232129335403\n",
      "\n",
      "episode 13, policy loss 0.08469641208648682\n",
      "\n",
      "episode 14, policy loss 0.03392504155635834\n",
      "\n",
      "episode 15, policy loss 0.11389598250389099\n",
      "\n",
      "episode 16, policy loss 0.092844657599926\n",
      "\n",
      "Policy train loss in epoch 1:0.08810649043880403\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.07448794692754745\n",
      "\n",
      "episode 2, policy loss 0.11940017342567444\n",
      "\n",
      "episode 3, policy loss 0.03382278233766556\n",
      "\n",
      "episode 4, policy loss 0.15713493525981903\n",
      "\n",
      "episode 5, policy loss 0.08130533993244171\n",
      "\n",
      "episode 6, policy loss 0.08183638751506805\n",
      "\n",
      "episode 7, policy loss 0.06035861372947693\n",
      "\n",
      "episode 8, policy loss 0.12107865512371063\n",
      "\n",
      "episode 9, policy loss 0.10436254739761353\n",
      "\n",
      "episode 10, policy loss 0.08489508926868439\n",
      "\n",
      "episode 11, policy loss 0.11383218318223953\n",
      "\n",
      "episode 12, policy loss 0.11562813073396683\n",
      "\n",
      "episode 13, policy loss 0.0991106852889061\n",
      "\n",
      "episode 14, policy loss 0.016845325008034706\n",
      "\n",
      "episode 15, policy loss 0.0659409612417221\n",
      "\n",
      "episode 16, policy loss 0.08876800537109375\n",
      "\n",
      "Policy train loss in epoch 2:0.08867548510897905\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.0660260021686554\n",
      "\n",
      "episode 2, policy loss 0.08147237449884415\n",
      "\n",
      "episode 3, policy loss 0.09544594585895538\n",
      "\n",
      "episode 4, policy loss 0.11691801995038986\n",
      "\n",
      "episode 5, policy loss 0.07324901968240738\n",
      "\n",
      "episode 6, policy loss 0.015178970992565155\n",
      "\n",
      "episode 7, policy loss 0.10169511288404465\n",
      "\n",
      "episode 8, policy loss 0.08122669160366058\n",
      "\n",
      "episode 9, policy loss 0.15694254636764526\n",
      "\n",
      "episode 10, policy loss 0.08164655417203903\n",
      "\n",
      "episode 11, policy loss 0.11366631090641022\n",
      "\n",
      "episode 12, policy loss 0.035075780004262924\n",
      "\n",
      "episode 13, policy loss 0.06020114943385124\n",
      "\n",
      "episode 14, policy loss 0.12067393213510513\n",
      "\n",
      "episode 15, policy loss 0.08862278610467911\n",
      "\n",
      "episode 16, policy loss 0.11511217057704926\n",
      "\n",
      "Policy train loss in epoch 3:0.0876970854587853\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1884462535381317\n",
      "\n",
      "episode 2, val func loss 0.16955403983592987\n",
      "\n",
      "episode 3, val func loss 0.16105696558952332\n",
      "\n",
      "episode 4, val func loss 0.16781921684741974\n",
      "\n",
      "episode 5, val func loss 0.2013014405965805\n",
      "\n",
      "episode 6, val func loss 0.2210075855255127\n",
      "\n",
      "episode 7, val func loss 0.207417830824852\n",
      "\n",
      "episode 8, val func loss 0.18399062752723694\n",
      "\n",
      "episode 9, val func loss 0.1688942313194275\n",
      "\n",
      "episode 10, val func loss 0.19252640008926392\n",
      "\n",
      "episode 11, val func loss 0.18260230123996735\n",
      "\n",
      "episode 12, val func loss 0.19394397735595703\n",
      "\n",
      "episode 13, val func loss 0.17044049501419067\n",
      "\n",
      "episode 14, val func loss 0.19680458307266235\n",
      "\n",
      "episode 15, val func loss 0.17168834805488586\n",
      "\n",
      "episode 16, val func loss 0.2152213305234909\n",
      "\n",
      "Val func train loss in epoch 0:0.18704472668468952\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18753914535045624\n",
      "\n",
      "episode 2, val func loss 0.1932966411113739\n",
      "\n",
      "episode 3, val func loss 0.17158618569374084\n",
      "\n",
      "episode 4, val func loss 0.213831827044487\n",
      "\n",
      "episode 5, val func loss 0.2137911021709442\n",
      "\n",
      "episode 6, val func loss 0.17233824729919434\n",
      "\n",
      "episode 7, val func loss 0.20179229974746704\n",
      "\n",
      "episode 8, val func loss 0.20029598474502563\n",
      "\n",
      "episode 9, val func loss 0.17161649465560913\n",
      "\n",
      "episode 10, val func loss 0.1909717470407486\n",
      "\n",
      "episode 11, val func loss 0.1847398579120636\n",
      "\n",
      "episode 12, val func loss 0.1845635622739792\n",
      "\n",
      "episode 13, val func loss 0.1681721806526184\n",
      "\n",
      "episode 14, val func loss 0.16942685842514038\n",
      "\n",
      "episode 15, val func loss 0.2011125385761261\n",
      "\n",
      "episode 16, val func loss 0.1589636504650116\n",
      "\n",
      "Val func train loss in epoch 1:0.18650239519774914\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.16903957724571228\n",
      "\n",
      "episode 2, val func loss 0.1807853877544403\n",
      "\n",
      "episode 3, val func loss 0.21417061984539032\n",
      "\n",
      "episode 4, val func loss 0.1733885258436203\n",
      "\n",
      "episode 5, val func loss 0.2156306654214859\n",
      "\n",
      "episode 6, val func loss 0.16938412189483643\n",
      "\n",
      "episode 7, val func loss 0.1621835082769394\n",
      "\n",
      "episode 8, val func loss 0.1890382021665573\n",
      "\n",
      "episode 9, val func loss 0.19784845411777496\n",
      "\n",
      "episode 10, val func loss 0.19492462277412415\n",
      "\n",
      "episode 11, val func loss 0.1878557652235031\n",
      "\n",
      "episode 12, val func loss 0.19787023961544037\n",
      "\n",
      "episode 13, val func loss 0.16618525981903076\n",
      "\n",
      "episode 14, val func loss 0.20083008706569672\n",
      "\n",
      "episode 15, val func loss 0.16830088198184967\n",
      "\n",
      "episode 16, val func loss 0.1984788328409195\n",
      "\n",
      "Val func train loss in epoch 2:0.1866196719929576\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20416231453418732\n",
      "\n",
      "episode 2, val func loss 0.21403183043003082\n",
      "\n",
      "episode 3, val func loss 0.18241877853870392\n",
      "\n",
      "episode 4, val func loss 0.19300439953804016\n",
      "\n",
      "episode 5, val func loss 0.20195095241069794\n",
      "\n",
      "episode 6, val func loss 0.1766413003206253\n",
      "\n",
      "episode 7, val func loss 0.1658790409564972\n",
      "\n",
      "episode 8, val func loss 0.19983792304992676\n",
      "\n",
      "episode 9, val func loss 0.21715761721134186\n",
      "\n",
      "episode 10, val func loss 0.18066829442977905\n",
      "\n",
      "episode 11, val func loss 0.19909824430942535\n",
      "\n",
      "episode 12, val func loss 0.16866685450077057\n",
      "\n",
      "episode 13, val func loss 0.18648384511470795\n",
      "\n",
      "episode 14, val func loss 0.16528946161270142\n",
      "\n",
      "episode 15, val func loss 0.1712743043899536\n",
      "\n",
      "episode 16, val func loss 0.1688491404056549\n",
      "\n",
      "Val func train loss in epoch 3:0.18721339385956526\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1876252442598343\n",
      "\n",
      "episode 2, val func loss 0.20100979506969452\n",
      "\n",
      "episode 3, val func loss 0.18202871084213257\n",
      "\n",
      "episode 4, val func loss 0.1965712159872055\n",
      "\n",
      "episode 5, val func loss 0.17171801626682281\n",
      "\n",
      "episode 6, val func loss 0.2153363823890686\n",
      "\n",
      "episode 7, val func loss 0.19873353838920593\n",
      "\n",
      "episode 8, val func loss 0.16794133186340332\n",
      "\n",
      "episode 9, val func loss 0.16788429021835327\n",
      "\n",
      "episode 10, val func loss 0.21221259236335754\n",
      "\n",
      "episode 11, val func loss 0.1979505568742752\n",
      "\n",
      "episode 12, val func loss 0.16821424663066864\n",
      "\n",
      "episode 13, val func loss 0.16515886783599854\n",
      "\n",
      "episode 14, val func loss 0.1729901134967804\n",
      "\n",
      "episode 15, val func loss 0.18352040648460388\n",
      "\n",
      "episode 16, val func loss 0.19411303102970123\n",
      "\n",
      "Val func train loss in epoch 4:0.18643802125006914\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1840103566646576\n",
      "\n",
      "episode 2, val func loss 0.18957729637622833\n",
      "\n",
      "episode 3, val func loss 0.2158527821302414\n",
      "\n",
      "episode 4, val func loss 0.1754608154296875\n",
      "\n",
      "episode 5, val func loss 0.16700860857963562\n",
      "\n",
      "episode 6, val func loss 0.19923833012580872\n",
      "\n",
      "episode 7, val func loss 0.18775881826877594\n",
      "\n",
      "episode 8, val func loss 0.19571441411972046\n",
      "\n",
      "episode 9, val func loss 0.16895684599876404\n",
      "\n",
      "episode 10, val func loss 0.1688181310892105\n",
      "\n",
      "episode 11, val func loss 0.1829022914171219\n",
      "\n",
      "episode 12, val func loss 0.1656665802001953\n",
      "\n",
      "episode 13, val func loss 0.200286865234375\n",
      "\n",
      "episode 14, val func loss 0.16875208914279938\n",
      "\n",
      "episode 15, val func loss 0.20573711395263672\n",
      "\n",
      "episode 16, val func loss 0.22006814181804657\n",
      "\n",
      "Val func train loss in epoch 5:0.18723809253424406\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.16780810058116913\n",
      "\n",
      "episode 2, val func loss 0.20026464760303497\n",
      "\n",
      "episode 3, val func loss 0.1878604143857956\n",
      "\n",
      "episode 4, val func loss 0.16983427107334137\n",
      "\n",
      "episode 5, val func loss 0.170079305768013\n",
      "\n",
      "episode 6, val func loss 0.18261350691318512\n",
      "\n",
      "episode 7, val func loss 0.21709197759628296\n",
      "\n",
      "episode 8, val func loss 0.16299022734165192\n",
      "\n",
      "episode 9, val func loss 0.17006787657737732\n",
      "\n",
      "episode 10, val func loss 0.19483354687690735\n",
      "\n",
      "episode 11, val func loss 0.17100173234939575\n",
      "\n",
      "episode 12, val func loss 0.2167632281780243\n",
      "\n",
      "episode 13, val func loss 0.20141372084617615\n",
      "\n",
      "episode 14, val func loss 0.18344782292842865\n",
      "\n",
      "episode 15, val func loss 0.2012348473072052\n",
      "\n",
      "episode 16, val func loss 0.19396400451660156\n",
      "\n",
      "Val func train loss in epoch 6:0.1869543269276619\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.21579618752002716\n",
      "\n",
      "episode 2, val func loss 0.1715821772813797\n",
      "\n",
      "episode 3, val func loss 0.20178304612636566\n",
      "\n",
      "episode 4, val func loss 0.1725231409072876\n",
      "\n",
      "episode 5, val func loss 0.16976794600486755\n",
      "\n",
      "episode 6, val func loss 0.19350019097328186\n",
      "\n",
      "episode 7, val func loss 0.195020392537117\n",
      "\n",
      "episode 8, val func loss 0.18281814455986023\n",
      "\n",
      "episode 9, val func loss 0.2012774497270584\n",
      "\n",
      "episode 10, val func loss 0.16773203015327454\n",
      "\n",
      "episode 11, val func loss 0.18179716169834137\n",
      "\n",
      "episode 12, val func loss 0.18596720695495605\n",
      "\n",
      "episode 13, val func loss 0.1581360101699829\n",
      "\n",
      "episode 14, val func loss 0.16618697345256805\n",
      "\n",
      "episode 15, val func loss 0.20218248665332794\n",
      "\n",
      "episode 16, val func loss 0.22381484508514404\n",
      "\n",
      "Val func train loss in epoch 7:0.1868678368628025\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17307861149311066\n",
      "\n",
      "episode 2, val func loss 0.16717278957366943\n",
      "\n",
      "episode 3, val func loss 0.18471382558345795\n",
      "\n",
      "episode 4, val func loss 0.21732838451862335\n",
      "\n",
      "episode 5, val func loss 0.17268387973308563\n",
      "\n",
      "episode 6, val func loss 0.19997812807559967\n",
      "\n",
      "episode 7, val func loss 0.19697432219982147\n",
      "\n",
      "episode 8, val func loss 0.1861431896686554\n",
      "\n",
      "episode 9, val func loss 0.1985253542661667\n",
      "\n",
      "episode 10, val func loss 0.2197405844926834\n",
      "\n",
      "episode 11, val func loss 0.18226295709609985\n",
      "\n",
      "episode 12, val func loss 0.19565311074256897\n",
      "\n",
      "episode 13, val func loss 0.16943074762821198\n",
      "\n",
      "episode 14, val func loss 0.2045372575521469\n",
      "\n",
      "episode 15, val func loss 0.16022497415542603\n",
      "\n",
      "episode 16, val func loss 0.17239433526992798\n",
      "\n",
      "Val func train loss in epoch 8:0.18755265325307846\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.16869394481182098\n",
      "\n",
      "episode 2, val func loss 0.20422737300395966\n",
      "\n",
      "episode 3, val func loss 0.15987609326839447\n",
      "\n",
      "episode 4, val func loss 0.1880543828010559\n",
      "\n",
      "episode 5, val func loss 0.19333864748477936\n",
      "\n",
      "episode 6, val func loss 0.21584145724773407\n",
      "\n",
      "episode 7, val func loss 0.18416042625904083\n",
      "\n",
      "episode 8, val func loss 0.16854949295520782\n",
      "\n",
      "episode 9, val func loss 0.19945964217185974\n",
      "\n",
      "episode 10, val func loss 0.17035210132598877\n",
      "\n",
      "episode 11, val func loss 0.16841065883636475\n",
      "\n",
      "episode 12, val func loss 0.19315075874328613\n",
      "\n",
      "episode 13, val func loss 0.1703476905822754\n",
      "\n",
      "episode 14, val func loss 0.2199830263853073\n",
      "\n",
      "episode 15, val func loss 0.19909630715847015\n",
      "\n",
      "episode 16, val func loss 0.18207691609859467\n",
      "\n",
      "Val func train loss in epoch 9:0.18660118244588375\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1713550090789795\n",
      "\n",
      "episode 2, val func loss 0.17104800045490265\n",
      "\n",
      "episode 3, val func loss 0.1982550024986267\n",
      "\n",
      "episode 4, val func loss 0.19253697991371155\n",
      "\n",
      "episode 5, val func loss 0.1842299848794937\n",
      "\n",
      "episode 6, val func loss 0.16973882913589478\n",
      "\n",
      "episode 7, val func loss 0.1712634563446045\n",
      "\n",
      "episode 8, val func loss 0.2172449678182602\n",
      "\n",
      "episode 9, val func loss 0.2174757719039917\n",
      "\n",
      "episode 10, val func loss 0.16981366276741028\n",
      "\n",
      "episode 11, val func loss 0.2000644952058792\n",
      "\n",
      "episode 12, val func loss 0.19902218878269196\n",
      "\n",
      "episode 13, val func loss 0.1895279437303543\n",
      "\n",
      "episode 14, val func loss 0.18357926607131958\n",
      "\n",
      "episode 15, val func loss 0.19455845654010773\n",
      "\n",
      "episode 16, val func loss 0.16107548773288727\n",
      "\n",
      "Val func train loss in epoch 10:0.18692434392869473\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.15899255871772766\n",
      "\n",
      "episode 2, val func loss 0.1872556507587433\n",
      "\n",
      "episode 3, val func loss 0.16669295728206635\n",
      "\n",
      "episode 4, val func loss 0.1944127380847931\n",
      "\n",
      "episode 5, val func loss 0.20600396394729614\n",
      "\n",
      "episode 6, val func loss 0.20006819069385529\n",
      "\n",
      "episode 7, val func loss 0.16990341246128082\n",
      "\n",
      "episode 8, val func loss 0.21643462777137756\n",
      "\n",
      "episode 9, val func loss 0.16686102747917175\n",
      "\n",
      "episode 10, val func loss 0.21706008911132812\n",
      "\n",
      "episode 11, val func loss 0.18486155569553375\n",
      "\n",
      "episode 12, val func loss 0.17197710275650024\n",
      "\n",
      "episode 13, val func loss 0.19444690644741058\n",
      "\n",
      "episode 14, val func loss 0.20030666887760162\n",
      "\n",
      "episode 15, val func loss 0.17479687929153442\n",
      "\n",
      "episode 16, val func loss 0.18668311834335327\n",
      "\n",
      "Val func train loss in epoch 11:0.18729734048247337\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.2002190351486206\n",
      "\n",
      "episode 2, val func loss 0.18424426019191742\n",
      "\n",
      "episode 3, val func loss 0.17073644697666168\n",
      "\n",
      "episode 4, val func loss 0.20186132192611694\n",
      "\n",
      "episode 5, val func loss 0.15886738896369934\n",
      "\n",
      "episode 6, val func loss 0.19298134744167328\n",
      "\n",
      "episode 7, val func loss 0.20054519176483154\n",
      "\n",
      "episode 8, val func loss 0.18799754977226257\n",
      "\n",
      "episode 9, val func loss 0.16708938777446747\n",
      "\n",
      "episode 10, val func loss 0.1693064123392105\n",
      "\n",
      "episode 11, val func loss 0.19399075210094452\n",
      "\n",
      "episode 12, val func loss 0.2156885862350464\n",
      "\n",
      "episode 13, val func loss 0.18341666460037231\n",
      "\n",
      "episode 14, val func loss 0.21544772386550903\n",
      "\n",
      "episode 15, val func loss 0.17185045778751373\n",
      "\n",
      "episode 16, val func loss 0.17680849134922028\n",
      "\n",
      "Val func train loss in epoch 12:0.18694068863987923\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18916615843772888\n",
      "\n",
      "episode 2, val func loss 0.21349270641803741\n",
      "\n",
      "episode 3, val func loss 0.16080157458782196\n",
      "\n",
      "episode 4, val func loss 0.194009467959404\n",
      "\n",
      "episode 5, val func loss 0.17123453319072723\n",
      "\n",
      "episode 6, val func loss 0.16703028976917267\n",
      "\n",
      "episode 7, val func loss 0.21775184571743011\n",
      "\n",
      "episode 8, val func loss 0.20341989398002625\n",
      "\n",
      "episode 9, val func loss 0.18394941091537476\n",
      "\n",
      "episode 10, val func loss 0.1703723669052124\n",
      "\n",
      "episode 11, val func loss 0.2017877697944641\n",
      "\n",
      "episode 12, val func loss 0.16988807916641235\n",
      "\n",
      "episode 13, val func loss 0.20006203651428223\n",
      "\n",
      "episode 14, val func loss 0.19479596614837646\n",
      "\n",
      "episode 15, val func loss 0.16900552809238434\n",
      "\n",
      "episode 16, val func loss 0.18415683507919312\n",
      "\n",
      "Val func train loss in epoch 13:0.18693277891725302\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1851954460144043\n",
      "\n",
      "episode 2, val func loss 0.15852822363376617\n",
      "\n",
      "episode 3, val func loss 0.17042423784732819\n",
      "\n",
      "episode 4, val func loss 0.22094140946865082\n",
      "\n",
      "episode 5, val func loss 0.20167620480060577\n",
      "\n",
      "episode 6, val func loss 0.19265879690647125\n",
      "\n",
      "episode 7, val func loss 0.19244034588336945\n",
      "\n",
      "episode 8, val func loss 0.18700271844863892\n",
      "\n",
      "episode 9, val func loss 0.16819629073143005\n",
      "\n",
      "episode 10, val func loss 0.2136499434709549\n",
      "\n",
      "episode 11, val func loss 0.20199334621429443\n",
      "\n",
      "episode 12, val func loss 0.18260599672794342\n",
      "\n",
      "episode 13, val func loss 0.1685638725757599\n",
      "\n",
      "episode 14, val func loss 0.20297938585281372\n",
      "\n",
      "episode 15, val func loss 0.1697433739900589\n",
      "\n",
      "episode 16, val func loss 0.1659698784351349\n",
      "\n",
      "Val func train loss in epoch 14:0.18641059193760157\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.21785089373588562\n",
      "\n",
      "episode 2, val func loss 0.16865161061286926\n",
      "\n",
      "episode 3, val func loss 0.1727110892534256\n",
      "\n",
      "episode 4, val func loss 0.16759464144706726\n",
      "\n",
      "episode 5, val func loss 0.1833428591489792\n",
      "\n",
      "episode 6, val func loss 0.1941003054380417\n",
      "\n",
      "episode 7, val func loss 0.198711559176445\n",
      "\n",
      "episode 8, val func loss 0.214385986328125\n",
      "\n",
      "episode 9, val func loss 0.19498446583747864\n",
      "\n",
      "episode 10, val func loss 0.18347972631454468\n",
      "\n",
      "episode 11, val func loss 0.17167715728282928\n",
      "\n",
      "episode 12, val func loss 0.199599027633667\n",
      "\n",
      "episode 13, val func loss 0.16165435314178467\n",
      "\n",
      "episode 14, val func loss 0.18789763748645782\n",
      "\n",
      "episode 15, val func loss 0.20117850601673126\n",
      "\n",
      "episode 16, val func loss 0.17133939266204834\n",
      "\n",
      "Val func train loss in epoch 15:0.18682245071977377\n",
      "***********************TIME WAS 4.97315503358841 min*****************************\n",
      "\n",
      "**********************ROUND 95 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.07506050914525986\n",
      "\n",
      "episode 2, policy loss 0.06267096102237701\n",
      "\n",
      "episode 3, policy loss 0.12256840616464615\n",
      "\n",
      "episode 4, policy loss 0.13040390610694885\n",
      "\n",
      "episode 5, policy loss 0.09287427365779877\n",
      "\n",
      "episode 6, policy loss 0.11135165393352509\n",
      "\n",
      "episode 7, policy loss 0.017057234421372414\n",
      "\n",
      "episode 8, policy loss 0.08645640313625336\n",
      "\n",
      "episode 9, policy loss 0.09967728704214096\n",
      "\n",
      "episode 10, policy loss 0.07689407467842102\n",
      "\n",
      "episode 11, policy loss 0.09883143752813339\n",
      "\n",
      "episode 12, policy loss 0.1314776986837387\n",
      "\n",
      "episode 13, policy loss 0.07893332093954086\n",
      "\n",
      "episode 14, policy loss 0.10201554000377655\n",
      "\n",
      "episode 15, policy loss 0.09378622472286224\n",
      "\n",
      "episode 16, policy loss 0.09114700555801392\n",
      "\n",
      "Policy train loss in epoch 0:0.09195037104655057\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.11728651821613312\n",
      "\n",
      "episode 2, policy loss 0.1262296736240387\n",
      "\n",
      "episode 3, policy loss 0.01579156517982483\n",
      "\n",
      "episode 4, policy loss 0.11128479242324829\n",
      "\n",
      "episode 5, policy loss 0.08417411148548126\n",
      "\n",
      "episode 6, policy loss 0.08880637586116791\n",
      "\n",
      "episode 7, policy loss 0.07541073858737946\n",
      "\n",
      "episode 8, policy loss 0.09317846596240997\n",
      "\n",
      "episode 9, policy loss 0.09228111803531647\n",
      "\n",
      "episode 10, policy loss 0.09122135490179062\n",
      "\n",
      "episode 11, policy loss 0.0976688489317894\n",
      "\n",
      "episode 12, policy loss 0.05924548953771591\n",
      "\n",
      "episode 13, policy loss 0.13233372569084167\n",
      "\n",
      "episode 14, policy loss 0.0760367140173912\n",
      "\n",
      "episode 15, policy loss 0.06923986971378326\n",
      "\n",
      "episode 16, policy loss 0.10101043432950974\n",
      "\n",
      "Policy train loss in epoch 1:0.08944998728111386\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.11114035546779633\n",
      "\n",
      "episode 2, policy loss 0.10075116902589798\n",
      "\n",
      "episode 3, policy loss 0.11698734015226364\n",
      "\n",
      "episode 4, policy loss 0.07439999282360077\n",
      "\n",
      "episode 5, policy loss 0.08919116854667664\n",
      "\n",
      "episode 6, policy loss 0.09039074182510376\n",
      "\n",
      "episode 7, policy loss 0.05836954340338707\n",
      "\n",
      "episode 8, policy loss 0.08297538757324219\n",
      "\n",
      "episode 9, policy loss 0.06718171387910843\n",
      "\n",
      "episode 10, policy loss 0.016924303025007248\n",
      "\n",
      "episode 11, policy loss 0.07483374327421188\n",
      "\n",
      "episode 12, policy loss 0.1335209161043167\n",
      "\n",
      "episode 13, policy loss 0.09739471971988678\n",
      "\n",
      "episode 14, policy loss 0.09235386550426483\n",
      "\n",
      "episode 15, policy loss 0.09239383786916733\n",
      "\n",
      "episode 16, policy loss 0.12558409571647644\n",
      "\n",
      "Policy train loss in epoch 2:0.0890245558694005\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.13171978294849396\n",
      "\n",
      "episode 2, policy loss 0.06881873309612274\n",
      "\n",
      "episode 3, policy loss 0.09216439723968506\n",
      "\n",
      "episode 4, policy loss 0.1171722263097763\n",
      "\n",
      "episode 5, policy loss 0.09199612587690353\n",
      "\n",
      "episode 6, policy loss 0.11012370884418488\n",
      "\n",
      "episode 7, policy loss 0.05974921956658363\n",
      "\n",
      "episode 8, policy loss 0.016025757417082787\n",
      "\n",
      "episode 9, policy loss 0.09712657332420349\n",
      "\n",
      "episode 10, policy loss 0.09085004776716232\n",
      "\n",
      "episode 11, policy loss 0.0747290849685669\n",
      "\n",
      "episode 12, policy loss 0.1238291934132576\n",
      "\n",
      "episode 13, policy loss 0.09844958782196045\n",
      "\n",
      "episode 14, policy loss 0.08160655945539474\n",
      "\n",
      "episode 15, policy loss 0.09048092365264893\n",
      "\n",
      "episode 16, policy loss 0.07184556871652603\n",
      "\n",
      "Policy train loss in epoch 3:0.08854296815115958\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1996040791273117\n",
      "\n",
      "episode 2, val func loss 0.20891448855400085\n",
      "\n",
      "episode 3, val func loss 0.20297983288764954\n",
      "\n",
      "episode 4, val func loss 0.1767105907201767\n",
      "\n",
      "episode 5, val func loss 0.17566294968128204\n",
      "\n",
      "episode 6, val func loss 0.21592994034290314\n",
      "\n",
      "episode 7, val func loss 0.18920525908470154\n",
      "\n",
      "episode 8, val func loss 0.1881464421749115\n",
      "\n",
      "episode 9, val func loss 0.19899092614650726\n",
      "\n",
      "episode 10, val func loss 0.185516357421875\n",
      "\n",
      "episode 11, val func loss 0.18545590341091156\n",
      "\n",
      "episode 12, val func loss 0.19118458032608032\n",
      "\n",
      "episode 13, val func loss 0.2315761148929596\n",
      "\n",
      "episode 14, val func loss 0.17898119986057281\n",
      "\n",
      "episode 15, val func loss 0.2092045545578003\n",
      "\n",
      "episode 16, val func loss 0.1773746758699417\n",
      "\n",
      "Val func train loss in epoch 0:0.1947148684412241\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18572844564914703\n",
      "\n",
      "episode 2, val func loss 0.17854608595371246\n",
      "\n",
      "episode 3, val func loss 0.17452692985534668\n",
      "\n",
      "episode 4, val func loss 0.18791596591472626\n",
      "\n",
      "episode 5, val func loss 0.17510837316513062\n",
      "\n",
      "episode 6, val func loss 0.19657781720161438\n",
      "\n",
      "episode 7, val func loss 0.20419539511203766\n",
      "\n",
      "episode 8, val func loss 0.1914711892604828\n",
      "\n",
      "episode 9, val func loss 0.1840638369321823\n",
      "\n",
      "episode 10, val func loss 0.1757783442735672\n",
      "\n",
      "episode 11, val func loss 0.2313237190246582\n",
      "\n",
      "episode 12, val func loss 0.2128124237060547\n",
      "\n",
      "episode 13, val func loss 0.20058991014957428\n",
      "\n",
      "episode 14, val func loss 0.20763084292411804\n",
      "\n",
      "episode 15, val func loss 0.1857949197292328\n",
      "\n",
      "episode 16, val func loss 0.20603366196155548\n",
      "\n",
      "Val func train loss in epoch 1:0.1936311163008213\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.22901952266693115\n",
      "\n",
      "episode 2, val func loss 0.18219010531902313\n",
      "\n",
      "episode 3, val func loss 0.1757579743862152\n",
      "\n",
      "episode 4, val func loss 0.19846485555171967\n",
      "\n",
      "episode 5, val func loss 0.19248776137828827\n",
      "\n",
      "episode 6, val func loss 0.17754711210727692\n",
      "\n",
      "episode 7, val func loss 0.18225732445716858\n",
      "\n",
      "episode 8, val func loss 0.21510128676891327\n",
      "\n",
      "episode 9, val func loss 0.18566086888313293\n",
      "\n",
      "episode 10, val func loss 0.1783457249403\n",
      "\n",
      "episode 11, val func loss 0.208623468875885\n",
      "\n",
      "episode 12, val func loss 0.20977693796157837\n",
      "\n",
      "episode 13, val func loss 0.19358757138252258\n",
      "\n",
      "episode 14, val func loss 0.19990044832229614\n",
      "\n",
      "episode 15, val func loss 0.190418541431427\n",
      "\n",
      "episode 16, val func loss 0.18379999697208405\n",
      "\n",
      "Val func train loss in epoch 2:0.19393371883779764\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20471681654453278\n",
      "\n",
      "episode 2, val func loss 0.21424880623817444\n",
      "\n",
      "episode 3, val func loss 0.19853973388671875\n",
      "\n",
      "episode 4, val func loss 0.17779329419136047\n",
      "\n",
      "episode 5, val func loss 0.1918811798095703\n",
      "\n",
      "episode 6, val func loss 0.17645807564258575\n",
      "\n",
      "episode 7, val func loss 0.17375870048999786\n",
      "\n",
      "episode 8, val func loss 0.23369115591049194\n",
      "\n",
      "episode 9, val func loss 0.19805382192134857\n",
      "\n",
      "episode 10, val func loss 0.20596228539943695\n",
      "\n",
      "episode 11, val func loss 0.18345364928245544\n",
      "\n",
      "episode 12, val func loss 0.1869518905878067\n",
      "\n",
      "episode 13, val func loss 0.2066541314125061\n",
      "\n",
      "episode 14, val func loss 0.18331564962863922\n",
      "\n",
      "episode 15, val func loss 0.19507941603660583\n",
      "\n",
      "episode 16, val func loss 0.1786554455757141\n",
      "\n",
      "Val func train loss in epoch 3:0.19432587828487158\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1801966428756714\n",
      "\n",
      "episode 2, val func loss 0.19089576601982117\n",
      "\n",
      "episode 3, val func loss 0.18634192645549774\n",
      "\n",
      "episode 4, val func loss 0.20795534551143646\n",
      "\n",
      "episode 5, val func loss 0.17784690856933594\n",
      "\n",
      "episode 6, val func loss 0.1856074184179306\n",
      "\n",
      "episode 7, val func loss 0.2086763232946396\n",
      "\n",
      "episode 8, val func loss 0.23185957968235016\n",
      "\n",
      "episode 9, val func loss 0.19549527764320374\n",
      "\n",
      "episode 10, val func loss 0.19571180641651154\n",
      "\n",
      "episode 11, val func loss 0.1903832107782364\n",
      "\n",
      "episode 12, val func loss 0.187549889087677\n",
      "\n",
      "episode 13, val func loss 0.21490462124347687\n",
      "\n",
      "episode 14, val func loss 0.17903174459934235\n",
      "\n",
      "episode 15, val func loss 0.20210279524326324\n",
      "\n",
      "episode 16, val func loss 0.1772288829088211\n",
      "\n",
      "Val func train loss in epoch 4:0.19448675867170095\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17874790728092194\n",
      "\n",
      "episode 2, val func loss 0.20932164788246155\n",
      "\n",
      "episode 3, val func loss 0.17501221597194672\n",
      "\n",
      "episode 4, val func loss 0.19366951286792755\n",
      "\n",
      "episode 5, val func loss 0.20482337474822998\n",
      "\n",
      "episode 6, val func loss 0.19688959419727325\n",
      "\n",
      "episode 7, val func loss 0.17753908038139343\n",
      "\n",
      "episode 8, val func loss 0.18360035121440887\n",
      "\n",
      "episode 9, val func loss 0.19125109910964966\n",
      "\n",
      "episode 10, val func loss 0.1780126690864563\n",
      "\n",
      "episode 11, val func loss 0.19745370745658875\n",
      "\n",
      "episode 12, val func loss 0.2295692265033722\n",
      "\n",
      "episode 13, val func loss 0.20910674333572388\n",
      "\n",
      "episode 14, val func loss 0.2158048301935196\n",
      "\n",
      "episode 15, val func loss 0.18865111470222473\n",
      "\n",
      "episode 16, val func loss 0.18505360186100006\n",
      "\n",
      "Val func train loss in epoch 5:0.19465666729956865\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1862291544675827\n",
      "\n",
      "episode 2, val func loss 0.17853710055351257\n",
      "\n",
      "episode 3, val func loss 0.1841280162334442\n",
      "\n",
      "episode 4, val func loss 0.18761394917964935\n",
      "\n",
      "episode 5, val func loss 0.23361662030220032\n",
      "\n",
      "episode 6, val func loss 0.2107134908437729\n",
      "\n",
      "episode 7, val func loss 0.20218269526958466\n",
      "\n",
      "episode 8, val func loss 0.20489060878753662\n",
      "\n",
      "episode 9, val func loss 0.1801186203956604\n",
      "\n",
      "episode 10, val func loss 0.21343255043029785\n",
      "\n",
      "episode 11, val func loss 0.17768968641757965\n",
      "\n",
      "episode 12, val func loss 0.19246530532836914\n",
      "\n",
      "episode 13, val func loss 0.19640003144741058\n",
      "\n",
      "episode 14, val func loss 0.18564186990261078\n",
      "\n",
      "episode 15, val func loss 0.19804896414279938\n",
      "\n",
      "episode 16, val func loss 0.18025529384613037\n",
      "\n",
      "Val func train loss in epoch 6:0.19449774734675884\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.2113957703113556\n",
      "\n",
      "episode 2, val func loss 0.17948435246944427\n",
      "\n",
      "episode 3, val func loss 0.22998186945915222\n",
      "\n",
      "episode 4, val func loss 0.19241447746753693\n",
      "\n",
      "episode 5, val func loss 0.21464824676513672\n",
      "\n",
      "episode 6, val func loss 0.19917359948158264\n",
      "\n",
      "episode 7, val func loss 0.177289679646492\n",
      "\n",
      "episode 8, val func loss 0.17862112820148468\n",
      "\n",
      "episode 9, val func loss 0.18367315828800201\n",
      "\n",
      "episode 10, val func loss 0.20295614004135132\n",
      "\n",
      "episode 11, val func loss 0.1776614487171173\n",
      "\n",
      "episode 12, val func loss 0.19064059853553772\n",
      "\n",
      "episode 13, val func loss 0.20443369448184967\n",
      "\n",
      "episode 14, val func loss 0.19598282873630524\n",
      "\n",
      "episode 15, val func loss 0.1863485872745514\n",
      "\n",
      "episode 16, val func loss 0.1855219602584839\n",
      "\n",
      "Val func train loss in epoch 7:0.19438922125846148\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.216192826628685\n",
      "\n",
      "episode 2, val func loss 0.18354059755802155\n",
      "\n",
      "episode 3, val func loss 0.19554543495178223\n",
      "\n",
      "episode 4, val func loss 0.18014366924762726\n",
      "\n",
      "episode 5, val func loss 0.2062043994665146\n",
      "\n",
      "episode 6, val func loss 0.2083883136510849\n",
      "\n",
      "episode 7, val func loss 0.1751093715429306\n",
      "\n",
      "episode 8, val func loss 0.1882365345954895\n",
      "\n",
      "episode 9, val func loss 0.19037821888923645\n",
      "\n",
      "episode 10, val func loss 0.1870226263999939\n",
      "\n",
      "episode 11, val func loss 0.1989119052886963\n",
      "\n",
      "episode 12, val func loss 0.1921004056930542\n",
      "\n",
      "episode 13, val func loss 0.20562632381916046\n",
      "\n",
      "episode 14, val func loss 0.23559612035751343\n",
      "\n",
      "episode 15, val func loss 0.18081355094909668\n",
      "\n",
      "episode 16, val func loss 0.17969872057437897\n",
      "\n",
      "Val func train loss in epoch 8:0.19521931372582912\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.186710923910141\n",
      "\n",
      "episode 2, val func loss 0.17770987749099731\n",
      "\n",
      "episode 3, val func loss 0.20234759151935577\n",
      "\n",
      "episode 4, val func loss 0.1769622564315796\n",
      "\n",
      "episode 5, val func loss 0.2074051797389984\n",
      "\n",
      "episode 6, val func loss 0.1780274212360382\n",
      "\n",
      "episode 7, val func loss 0.1835503876209259\n",
      "\n",
      "episode 8, val func loss 0.2169698029756546\n",
      "\n",
      "episode 9, val func loss 0.19209875166416168\n",
      "\n",
      "episode 10, val func loss 0.18583542108535767\n",
      "\n",
      "episode 11, val func loss 0.2289126068353653\n",
      "\n",
      "episode 12, val func loss 0.1955912709236145\n",
      "\n",
      "episode 13, val func loss 0.19723361730575562\n",
      "\n",
      "episode 14, val func loss 0.1796102374792099\n",
      "\n",
      "episode 15, val func loss 0.1885453760623932\n",
      "\n",
      "episode 16, val func loss 0.20941270887851715\n",
      "\n",
      "Val func train loss in epoch 9:0.1941827144473791\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.2095191776752472\n",
      "\n",
      "episode 2, val func loss 0.1754637211561203\n",
      "\n",
      "episode 3, val func loss 0.17811931669712067\n",
      "\n",
      "episode 4, val func loss 0.19606547057628632\n",
      "\n",
      "episode 5, val func loss 0.19065412878990173\n",
      "\n",
      "episode 6, val func loss 0.1786479949951172\n",
      "\n",
      "episode 7, val func loss 0.18559905886650085\n",
      "\n",
      "episode 8, val func loss 0.18299317359924316\n",
      "\n",
      "episode 9, val func loss 0.19442220032215118\n",
      "\n",
      "episode 10, val func loss 0.20394906401634216\n",
      "\n",
      "episode 11, val func loss 0.17758023738861084\n",
      "\n",
      "episode 12, val func loss 0.19708144664764404\n",
      "\n",
      "episode 13, val func loss 0.21434466540813446\n",
      "\n",
      "episode 14, val func loss 0.18610168993473053\n",
      "\n",
      "episode 15, val func loss 0.2261260747909546\n",
      "\n",
      "episode 16, val func loss 0.20599523186683655\n",
      "\n",
      "Val func train loss in epoch 10:0.19391641579568386\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1809709221124649\n",
      "\n",
      "episode 2, val func loss 0.18206559121608734\n",
      "\n",
      "episode 3, val func loss 0.17853492498397827\n",
      "\n",
      "episode 4, val func loss 0.1851935237646103\n",
      "\n",
      "episode 5, val func loss 0.20998181402683258\n",
      "\n",
      "episode 6, val func loss 0.23042774200439453\n",
      "\n",
      "episode 7, val func loss 0.18672305345535278\n",
      "\n",
      "episode 8, val func loss 0.18525515496730804\n",
      "\n",
      "episode 9, val func loss 0.2061726599931717\n",
      "\n",
      "episode 10, val func loss 0.19665776193141937\n",
      "\n",
      "episode 11, val func loss 0.20145834982395172\n",
      "\n",
      "episode 12, val func loss 0.197275310754776\n",
      "\n",
      "episode 13, val func loss 0.17708513140678406\n",
      "\n",
      "episode 14, val func loss 0.2153097689151764\n",
      "\n",
      "episode 15, val func loss 0.19122818112373352\n",
      "\n",
      "episode 16, val func loss 0.19343289732933044\n",
      "\n",
      "Val func train loss in epoch 11:0.19486079923808575\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.20624276995658875\n",
      "\n",
      "episode 2, val func loss 0.19952517747879028\n",
      "\n",
      "episode 3, val func loss 0.22681228816509247\n",
      "\n",
      "episode 4, val func loss 0.19798544049263\n",
      "\n",
      "episode 5, val func loss 0.17900089919567108\n",
      "\n",
      "episode 6, val func loss 0.19321641325950623\n",
      "\n",
      "episode 7, val func loss 0.18739522993564606\n",
      "\n",
      "episode 8, val func loss 0.1847819834947586\n",
      "\n",
      "episode 9, val func loss 0.17922957241535187\n",
      "\n",
      "episode 10, val func loss 0.18867969512939453\n",
      "\n",
      "episode 11, val func loss 0.21832428872585297\n",
      "\n",
      "episode 12, val func loss 0.20952627062797546\n",
      "\n",
      "episode 13, val func loss 0.19774150848388672\n",
      "\n",
      "episode 14, val func loss 0.1839001476764679\n",
      "\n",
      "episode 15, val func loss 0.17441430687904358\n",
      "\n",
      "episode 16, val func loss 0.17781509459018707\n",
      "\n",
      "Val func train loss in epoch 12:0.19403694290667772\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.2337716966867447\n",
      "\n",
      "episode 2, val func loss 0.17486953735351562\n",
      "\n",
      "episode 3, val func loss 0.17997318506240845\n",
      "\n",
      "episode 4, val func loss 0.19818523526191711\n",
      "\n",
      "episode 5, val func loss 0.1862974464893341\n",
      "\n",
      "episode 6, val func loss 0.21606387197971344\n",
      "\n",
      "episode 7, val func loss 0.19156238436698914\n",
      "\n",
      "episode 8, val func loss 0.17932409048080444\n",
      "\n",
      "episode 9, val func loss 0.1801324188709259\n",
      "\n",
      "episode 10, val func loss 0.21002040803432465\n",
      "\n",
      "episode 11, val func loss 0.20693165063858032\n",
      "\n",
      "episode 12, val func loss 0.19815988838672638\n",
      "\n",
      "episode 13, val func loss 0.20146992802619934\n",
      "\n",
      "episode 14, val func loss 0.1842353343963623\n",
      "\n",
      "episode 15, val func loss 0.18930286169052124\n",
      "\n",
      "episode 16, val func loss 0.18563933670520782\n",
      "\n",
      "Val func train loss in epoch 13:0.19474620465189219\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1975194662809372\n",
      "\n",
      "episode 2, val func loss 0.20899976789951324\n",
      "\n",
      "episode 3, val func loss 0.1992070972919464\n",
      "\n",
      "episode 4, val func loss 0.22942966222763062\n",
      "\n",
      "episode 5, val func loss 0.1770572066307068\n",
      "\n",
      "episode 6, val func loss 0.18393023312091827\n",
      "\n",
      "episode 7, val func loss 0.1853221207857132\n",
      "\n",
      "episode 8, val func loss 0.17824028432369232\n",
      "\n",
      "episode 9, val func loss 0.21677419543266296\n",
      "\n",
      "episode 10, val func loss 0.19134776294231415\n",
      "\n",
      "episode 11, val func loss 0.17810013890266418\n",
      "\n",
      "episode 12, val func loss 0.17723171412944794\n",
      "\n",
      "episode 13, val func loss 0.20591963827610016\n",
      "\n",
      "episode 14, val func loss 0.18810434639453888\n",
      "\n",
      "episode 15, val func loss 0.1984844207763672\n",
      "\n",
      "episode 16, val func loss 0.18883933126926422\n",
      "\n",
      "Val func train loss in epoch 14:0.1940317116677761\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.17595110833644867\n",
      "\n",
      "episode 2, val func loss 0.19352515041828156\n",
      "\n",
      "episode 3, val func loss 0.17697462439537048\n",
      "\n",
      "episode 4, val func loss 0.21159155666828156\n",
      "\n",
      "episode 5, val func loss 0.20908406376838684\n",
      "\n",
      "episode 6, val func loss 0.187146857380867\n",
      "\n",
      "episode 7, val func loss 0.18588559329509735\n",
      "\n",
      "episode 8, val func loss 0.20453567802906036\n",
      "\n",
      "episode 9, val func loss 0.19674056768417358\n",
      "\n",
      "episode 10, val func loss 0.18842525780200958\n",
      "\n",
      "episode 11, val func loss 0.23055683076381683\n",
      "\n",
      "episode 12, val func loss 0.18405260145664215\n",
      "\n",
      "episode 13, val func loss 0.21743646264076233\n",
      "\n",
      "episode 14, val func loss 0.19703027606010437\n",
      "\n",
      "episode 15, val func loss 0.17970061302185059\n",
      "\n",
      "episode 16, val func loss 0.1802118718624115\n",
      "\n",
      "Val func train loss in epoch 15:0.1949280695989728\n",
      "***********************TIME WAS 4.972383411725362 min*****************************\n",
      "\n",
      "**********************ROUND 96 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.04724036529660225\n",
      "\n",
      "episode 2, policy loss 0.1073436364531517\n",
      "\n",
      "episode 3, policy loss 0.02078467607498169\n",
      "\n",
      "episode 4, policy loss 0.08875741809606552\n",
      "\n",
      "episode 5, policy loss 0.05631817504763603\n",
      "\n",
      "episode 6, policy loss 0.04128183424472809\n",
      "\n",
      "episode 7, policy loss 0.05893154814839363\n",
      "\n",
      "episode 8, policy loss 0.03606138750910759\n",
      "\n",
      "episode 9, policy loss 0.02309713326394558\n",
      "\n",
      "episode 10, policy loss 0.011327172629535198\n",
      "\n",
      "episode 11, policy loss 0.09433919936418533\n",
      "\n",
      "episode 12, policy loss 0.012057777494192123\n",
      "\n",
      "episode 13, policy loss -0.012942383997142315\n",
      "\n",
      "episode 14, policy loss 0.0006553624989464879\n",
      "\n",
      "episode 15, policy loss 0.021016931161284447\n",
      "\n",
      "episode 16, policy loss 0.03631571680307388\n",
      "\n",
      "Policy train loss in epoch 0:0.04016162188054295\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.03969534859061241\n",
      "\n",
      "episode 2, policy loss -0.0150228813290596\n",
      "\n",
      "episode 3, policy loss 0.0945969894528389\n",
      "\n",
      "episode 4, policy loss 0.03919615224003792\n",
      "\n",
      "episode 5, policy loss 0.101570263504982\n",
      "\n",
      "episode 6, policy loss 0.037206001579761505\n",
      "\n",
      "episode 7, policy loss 0.0831424668431282\n",
      "\n",
      "episode 8, policy loss 0.052310407161712646\n",
      "\n",
      "episode 9, policy loss 0.014795142225921154\n",
      "\n",
      "episode 10, policy loss 0.009551739320158958\n",
      "\n",
      "episode 11, policy loss 0.022172922268509865\n",
      "\n",
      "episode 12, policy loss 0.009672763757407665\n",
      "\n",
      "episode 13, policy loss 0.05861464515328407\n",
      "\n",
      "episode 14, policy loss 0.0007500008214265108\n",
      "\n",
      "episode 15, policy loss 0.019269844517111778\n",
      "\n",
      "episode 16, policy loss 0.03854568675160408\n",
      "\n",
      "Policy train loss in epoch 1:0.03787921830371488\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.039633702486753464\n",
      "\n",
      "episode 2, policy loss 0.02007690630853176\n",
      "\n",
      "episode 3, policy loss 0.05272926017642021\n",
      "\n",
      "episode 4, policy loss 0.03912780433893204\n",
      "\n",
      "episode 5, policy loss 0.008711389265954494\n",
      "\n",
      "episode 6, policy loss 0.03778781741857529\n",
      "\n",
      "episode 7, policy loss 0.08363761007785797\n",
      "\n",
      "episode 8, policy loss 0.014236236922442913\n",
      "\n",
      "episode 9, policy loss 0.038943640887737274\n",
      "\n",
      "episode 10, policy loss 0.021380072459578514\n",
      "\n",
      "episode 11, policy loss 0.009291031397879124\n",
      "\n",
      "episode 12, policy loss 0.10213766247034073\n",
      "\n",
      "episode 13, policy loss 0.05771731585264206\n",
      "\n",
      "episode 14, policy loss 0.09449818730354309\n",
      "\n",
      "episode 15, policy loss -0.01729774661362171\n",
      "\n",
      "episode 16, policy loss -0.001044667325913906\n",
      "\n",
      "Policy train loss in epoch 2:0.03759788896422833\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.05812041088938713\n",
      "\n",
      "episode 2, policy loss 0.05161064863204956\n",
      "\n",
      "episode 3, policy loss 0.04017059504985809\n",
      "\n",
      "episode 4, policy loss 0.008784038946032524\n",
      "\n",
      "episode 5, policy loss -0.0009864408057183027\n",
      "\n",
      "episode 6, policy loss 0.020745033398270607\n",
      "\n",
      "episode 7, policy loss 0.0939318984746933\n",
      "\n",
      "episode 8, policy loss 0.03881743177771568\n",
      "\n",
      "episode 9, policy loss 0.00843102764338255\n",
      "\n",
      "episode 10, policy loss 0.037672217935323715\n",
      "\n",
      "episode 11, policy loss 0.01945681869983673\n",
      "\n",
      "episode 12, policy loss 0.10155201703310013\n",
      "\n",
      "episode 13, policy loss 0.036211445927619934\n",
      "\n",
      "episode 14, policy loss 0.08172071725130081\n",
      "\n",
      "episode 15, policy loss -0.0169250275939703\n",
      "\n",
      "episode 16, policy loss 0.013998213224112988\n",
      "\n",
      "Policy train loss in epoch 3:0.0370819404051872\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1532641053199768\n",
      "\n",
      "episode 2, val func loss 0.22499126195907593\n",
      "\n",
      "episode 3, val func loss 0.1607406586408615\n",
      "\n",
      "episode 4, val func loss 0.16947977244853973\n",
      "\n",
      "episode 5, val func loss 0.16009943187236786\n",
      "\n",
      "episode 6, val func loss 0.1861484944820404\n",
      "\n",
      "episode 7, val func loss 0.1463935226202011\n",
      "\n",
      "episode 8, val func loss 0.19632379710674286\n",
      "\n",
      "episode 9, val func loss 0.14674906432628632\n",
      "\n",
      "episode 10, val func loss 0.18009984493255615\n",
      "\n",
      "episode 11, val func loss 0.06301616877317429\n",
      "\n",
      "episode 12, val func loss 0.15070098638534546\n",
      "\n",
      "episode 13, val func loss 0.20490919053554535\n",
      "\n",
      "episode 14, val func loss 0.17080052196979523\n",
      "\n",
      "episode 15, val func loss 0.15509872138500214\n",
      "\n",
      "episode 16, val func loss 0.17509715259075165\n",
      "\n",
      "Val func train loss in epoch 0:0.16524454345926642\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.06651745736598969\n",
      "\n",
      "episode 2, val func loss 0.1509905457496643\n",
      "\n",
      "episode 3, val func loss 0.17361141741275787\n",
      "\n",
      "episode 4, val func loss 0.17747963964939117\n",
      "\n",
      "episode 5, val func loss 0.17777827382087708\n",
      "\n",
      "episode 6, val func loss 0.14739210903644562\n",
      "\n",
      "episode 7, val func loss 0.17155052721500397\n",
      "\n",
      "episode 8, val func loss 0.16171734035015106\n",
      "\n",
      "episode 9, val func loss 0.1511693298816681\n",
      "\n",
      "episode 10, val func loss 0.20600873231887817\n",
      "\n",
      "episode 11, val func loss 0.22658099234104156\n",
      "\n",
      "episode 12, val func loss 0.14507485926151276\n",
      "\n",
      "episode 13, val func loss 0.18479223549365997\n",
      "\n",
      "episode 14, val func loss 0.15463393926620483\n",
      "\n",
      "episode 15, val func loss 0.20005379617214203\n",
      "\n",
      "episode 16, val func loss 0.1627514660358429\n",
      "\n",
      "Val func train loss in epoch 1:0.16613141633570194\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1874438226222992\n",
      "\n",
      "episode 2, val func loss 0.22321689128875732\n",
      "\n",
      "episode 3, val func loss 0.14788596332073212\n",
      "\n",
      "episode 4, val func loss 0.15406575798988342\n",
      "\n",
      "episode 5, val func loss 0.15149512887001038\n",
      "\n",
      "episode 6, val func loss 0.2110314667224884\n",
      "\n",
      "episode 7, val func loss 0.16383081674575806\n",
      "\n",
      "episode 8, val func loss 0.17237825691699982\n",
      "\n",
      "episode 9, val func loss 0.17766591906547546\n",
      "\n",
      "episode 10, val func loss 0.20162513852119446\n",
      "\n",
      "episode 11, val func loss 0.06456473469734192\n",
      "\n",
      "episode 12, val func loss 0.17319424450397491\n",
      "\n",
      "episode 13, val func loss 0.16137389838695526\n",
      "\n",
      "episode 14, val func loss 0.14539003372192383\n",
      "\n",
      "episode 15, val func loss 0.17436960339546204\n",
      "\n",
      "episode 16, val func loss 0.1559826284646988\n",
      "\n",
      "Val func train loss in epoch 2:0.1665946440771222\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.14416344463825226\n",
      "\n",
      "episode 2, val func loss 0.1683230847120285\n",
      "\n",
      "episode 3, val func loss 0.15724022686481476\n",
      "\n",
      "episode 4, val func loss 0.06360690295696259\n",
      "\n",
      "episode 5, val func loss 0.15080131590366364\n",
      "\n",
      "episode 6, val func loss 0.17851309478282928\n",
      "\n",
      "episode 7, val func loss 0.16250796616077423\n",
      "\n",
      "episode 8, val func loss 0.16989083588123322\n",
      "\n",
      "episode 9, val func loss 0.1793263703584671\n",
      "\n",
      "episode 10, val func loss 0.16090041399002075\n",
      "\n",
      "episode 11, val func loss 0.19954977929592133\n",
      "\n",
      "episode 12, val func loss 0.20320585370063782\n",
      "\n",
      "episode 13, val func loss 0.14954312145709991\n",
      "\n",
      "episode 14, val func loss 0.1870572566986084\n",
      "\n",
      "episode 15, val func loss 0.22398795187473297\n",
      "\n",
      "episode 16, val func loss 0.15426546335220337\n",
      "\n",
      "Val func train loss in epoch 3:0.16580519266426563\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.15177474915981293\n",
      "\n",
      "episode 2, val func loss 0.15755371749401093\n",
      "\n",
      "episode 3, val func loss 0.15382826328277588\n",
      "\n",
      "episode 4, val func loss 0.14778220653533936\n",
      "\n",
      "episode 5, val func loss 0.20083415508270264\n",
      "\n",
      "episode 6, val func loss 0.17409858107566833\n",
      "\n",
      "episode 7, val func loss 0.14513035118579865\n",
      "\n",
      "episode 8, val func loss 0.1846126765012741\n",
      "\n",
      "episode 9, val func loss 0.06545054167509079\n",
      "\n",
      "episode 10, val func loss 0.2042863965034485\n",
      "\n",
      "episode 11, val func loss 0.18229034543037415\n",
      "\n",
      "episode 12, val func loss 0.17127232253551483\n",
      "\n",
      "episode 13, val func loss 0.16131561994552612\n",
      "\n",
      "episode 14, val func loss 0.15835455060005188\n",
      "\n",
      "episode 15, val func loss 0.22537049651145935\n",
      "\n",
      "episode 16, val func loss 0.16817642748355865\n",
      "\n",
      "Val func train loss in epoch 4:0.16575821256265044\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.0636959820985794\n",
      "\n",
      "episode 2, val func loss 0.19889964163303375\n",
      "\n",
      "episode 3, val func loss 0.18672509491443634\n",
      "\n",
      "episode 4, val func loss 0.16114327311515808\n",
      "\n",
      "episode 5, val func loss 0.1794966459274292\n",
      "\n",
      "episode 6, val func loss 0.2271931916475296\n",
      "\n",
      "episode 7, val func loss 0.15279783308506012\n",
      "\n",
      "episode 8, val func loss 0.1521492600440979\n",
      "\n",
      "episode 9, val func loss 0.17047858238220215\n",
      "\n",
      "episode 10, val func loss 0.14622728526592255\n",
      "\n",
      "episode 11, val func loss 0.16176192462444305\n",
      "\n",
      "episode 12, val func loss 0.1474991887807846\n",
      "\n",
      "episode 13, val func loss 0.17404800653457642\n",
      "\n",
      "episode 14, val func loss 0.20547880232334137\n",
      "\n",
      "episode 15, val func loss 0.1577828824520111\n",
      "\n",
      "episode 16, val func loss 0.170087531208992\n",
      "\n",
      "Val func train loss in epoch 5:0.16596657037734985\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1866232007741928\n",
      "\n",
      "episode 2, val func loss 0.15554097294807434\n",
      "\n",
      "episode 3, val func loss 0.1742677241563797\n",
      "\n",
      "episode 4, val func loss 0.14649134874343872\n",
      "\n",
      "episode 5, val func loss 0.15121951699256897\n",
      "\n",
      "episode 6, val func loss 0.1783413290977478\n",
      "\n",
      "episode 7, val func loss 0.17320869863033295\n",
      "\n",
      "episode 8, val func loss 0.20096911489963531\n",
      "\n",
      "episode 9, val func loss 0.17180491983890533\n",
      "\n",
      "episode 10, val func loss 0.15230989456176758\n",
      "\n",
      "episode 11, val func loss 0.14706048369407654\n",
      "\n",
      "episode 12, val func loss 0.06414328515529633\n",
      "\n",
      "episode 13, val func loss 0.16072283685207367\n",
      "\n",
      "episode 14, val func loss 0.20376703143119812\n",
      "\n",
      "episode 15, val func loss 0.16001220047473907\n",
      "\n",
      "episode 16, val func loss 0.2255270630121231\n",
      "\n",
      "Val func train loss in epoch 6:0.1657506013289094\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1603090912103653\n",
      "\n",
      "episode 2, val func loss 0.14496047794818878\n",
      "\n",
      "episode 3, val func loss 0.1878805160522461\n",
      "\n",
      "episode 4, val func loss 0.162642702460289\n",
      "\n",
      "episode 5, val func loss 0.15519805252552032\n",
      "\n",
      "episode 6, val func loss 0.20386652648448944\n",
      "\n",
      "episode 7, val func loss 0.19852298498153687\n",
      "\n",
      "episode 8, val func loss 0.15162360668182373\n",
      "\n",
      "episode 9, val func loss 0.17052848637104034\n",
      "\n",
      "episode 10, val func loss 0.16274915635585785\n",
      "\n",
      "episode 11, val func loss 0.1778894066810608\n",
      "\n",
      "episode 12, val func loss 0.17983967065811157\n",
      "\n",
      "episode 13, val func loss 0.06379365921020508\n",
      "\n",
      "episode 14, val func loss 0.22715316712856293\n",
      "\n",
      "episode 15, val func loss 0.17155328392982483\n",
      "\n",
      "episode 16, val func loss 0.14657503366470337\n",
      "\n",
      "Val func train loss in epoch 7:0.16656786389648914\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1617426723241806\n",
      "\n",
      "episode 2, val func loss 0.17444922029972076\n",
      "\n",
      "episode 3, val func loss 0.17259961366653442\n",
      "\n",
      "episode 4, val func loss 0.15745998919010162\n",
      "\n",
      "episode 5, val func loss 0.06522811204195023\n",
      "\n",
      "episode 6, val func loss 0.14393368363380432\n",
      "\n",
      "episode 7, val func loss 0.18068906664848328\n",
      "\n",
      "episode 8, val func loss 0.17047902941703796\n",
      "\n",
      "episode 9, val func loss 0.20735231041908264\n",
      "\n",
      "episode 10, val func loss 0.16116398572921753\n",
      "\n",
      "episode 11, val func loss 0.1984691172838211\n",
      "\n",
      "episode 12, val func loss 0.22508053481578827\n",
      "\n",
      "episode 13, val func loss 0.15263590216636658\n",
      "\n",
      "episode 14, val func loss 0.15325258672237396\n",
      "\n",
      "episode 15, val func loss 0.18511955440044403\n",
      "\n",
      "episode 16, val func loss 0.14719213545322418\n",
      "\n",
      "Val func train loss in epoch 8:0.16605296963825822\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.15292784571647644\n",
      "\n",
      "episode 2, val func loss 0.16126810014247894\n",
      "\n",
      "episode 3, val func loss 0.2272508442401886\n",
      "\n",
      "episode 4, val func loss 0.1709597110748291\n",
      "\n",
      "episode 5, val func loss 0.19929052889347076\n",
      "\n",
      "episode 6, val func loss 0.16995930671691895\n",
      "\n",
      "episode 7, val func loss 0.18039177358150482\n",
      "\n",
      "episode 8, val func loss 0.1448039561510086\n",
      "\n",
      "episode 9, val func loss 0.1731606274843216\n",
      "\n",
      "episode 10, val func loss 0.16171352565288544\n",
      "\n",
      "episode 11, val func loss 0.18475016951560974\n",
      "\n",
      "episode 12, val func loss 0.1558692902326584\n",
      "\n",
      "episode 13, val func loss 0.15339067578315735\n",
      "\n",
      "episode 14, val func loss 0.20580798387527466\n",
      "\n",
      "episode 15, val func loss 0.06500911712646484\n",
      "\n",
      "episode 16, val func loss 0.1471007615327835\n",
      "\n",
      "Val func train loss in epoch 9:0.16585338860750198\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.2068393975496292\n",
      "\n",
      "episode 2, val func loss 0.15079744160175323\n",
      "\n",
      "episode 3, val func loss 0.16070428490638733\n",
      "\n",
      "episode 4, val func loss 0.15279901027679443\n",
      "\n",
      "episode 5, val func loss 0.22440247237682343\n",
      "\n",
      "episode 6, val func loss 0.1742660254240036\n",
      "\n",
      "episode 7, val func loss 0.06593422591686249\n",
      "\n",
      "episode 8, val func loss 0.1742757111787796\n",
      "\n",
      "episode 9, val func loss 0.1993190497159958\n",
      "\n",
      "episode 10, val func loss 0.17163176834583282\n",
      "\n",
      "episode 11, val func loss 0.14536818861961365\n",
      "\n",
      "episode 12, val func loss 0.18641836941242218\n",
      "\n",
      "episode 13, val func loss 0.18154557049274445\n",
      "\n",
      "episode 14, val func loss 0.14810365438461304\n",
      "\n",
      "episode 15, val func loss 0.15403471887111664\n",
      "\n",
      "episode 16, val func loss 0.16117125749588013\n",
      "\n",
      "Val func train loss in epoch 10:0.16610069666057825\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18416720628738403\n",
      "\n",
      "episode 2, val func loss 0.15325137972831726\n",
      "\n",
      "episode 3, val func loss 0.17847812175750732\n",
      "\n",
      "episode 4, val func loss 0.16294290125370026\n",
      "\n",
      "episode 5, val func loss 0.14473608136177063\n",
      "\n",
      "episode 6, val func loss 0.22862917184829712\n",
      "\n",
      "episode 7, val func loss 0.14796647429466248\n",
      "\n",
      "episode 8, val func loss 0.06368429213762283\n",
      "\n",
      "episode 9, val func loss 0.16942819952964783\n",
      "\n",
      "episode 10, val func loss 0.19884803891181946\n",
      "\n",
      "episode 11, val func loss 0.17379051446914673\n",
      "\n",
      "episode 12, val func loss 0.20452375710010529\n",
      "\n",
      "episode 13, val func loss 0.17343264818191528\n",
      "\n",
      "episode 14, val func loss 0.1562577337026596\n",
      "\n",
      "episode 15, val func loss 0.15561345219612122\n",
      "\n",
      "episode 16, val func loss 0.15968731045722961\n",
      "\n",
      "Val func train loss in epoch 11:0.16596483020111918\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.15506711602210999\n",
      "\n",
      "episode 2, val func loss 0.17130668461322784\n",
      "\n",
      "episode 3, val func loss 0.22559230029582977\n",
      "\n",
      "episode 4, val func loss 0.1525985300540924\n",
      "\n",
      "episode 5, val func loss 0.14566144347190857\n",
      "\n",
      "episode 6, val func loss 0.17000460624694824\n",
      "\n",
      "episode 7, val func loss 0.19955746829509735\n",
      "\n",
      "episode 8, val func loss 0.16309328377246857\n",
      "\n",
      "episode 9, val func loss 0.15407392382621765\n",
      "\n",
      "episode 10, val func loss 0.1753632128238678\n",
      "\n",
      "episode 11, val func loss 0.06483416259288788\n",
      "\n",
      "episode 12, val func loss 0.1804971694946289\n",
      "\n",
      "episode 13, val func loss 0.16150549054145813\n",
      "\n",
      "episode 14, val func loss 0.18442656099796295\n",
      "\n",
      "episode 15, val func loss 0.14686092734336853\n",
      "\n",
      "episode 16, val func loss 0.20810692012310028\n",
      "\n",
      "Val func train loss in epoch 12:0.16615936253219843\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18442565202713013\n",
      "\n",
      "episode 2, val func loss 0.15418760478496552\n",
      "\n",
      "episode 3, val func loss 0.1475445181131363\n",
      "\n",
      "episode 4, val func loss 0.20583701133728027\n",
      "\n",
      "episode 5, val func loss 0.1992441713809967\n",
      "\n",
      "episode 6, val func loss 0.16958290338516235\n",
      "\n",
      "episode 7, val func loss 0.16098222136497498\n",
      "\n",
      "episode 8, val func loss 0.22549304366111755\n",
      "\n",
      "episode 9, val func loss 0.16188843548297882\n",
      "\n",
      "episode 10, val func loss 0.06480590254068375\n",
      "\n",
      "episode 11, val func loss 0.14501893520355225\n",
      "\n",
      "episode 12, val func loss 0.15307478606700897\n",
      "\n",
      "episode 13, val func loss 0.18104276061058044\n",
      "\n",
      "episode 14, val func loss 0.1738978922367096\n",
      "\n",
      "episode 15, val func loss 0.15437397360801697\n",
      "\n",
      "episode 16, val func loss 0.1702890247106552\n",
      "\n",
      "Val func train loss in epoch 13:0.16573055228218436\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17423410713672638\n",
      "\n",
      "episode 2, val func loss 0.2001158893108368\n",
      "\n",
      "episode 3, val func loss 0.17093752324581146\n",
      "\n",
      "episode 4, val func loss 0.14728781580924988\n",
      "\n",
      "episode 5, val func loss 0.18025928735733032\n",
      "\n",
      "episode 6, val func loss 0.20690974593162537\n",
      "\n",
      "episode 7, val func loss 0.1605508029460907\n",
      "\n",
      "episode 8, val func loss 0.15460418164730072\n",
      "\n",
      "episode 9, val func loss 0.18472112715244293\n",
      "\n",
      "episode 10, val func loss 0.17161676287651062\n",
      "\n",
      "episode 11, val func loss 0.15512146055698395\n",
      "\n",
      "episode 12, val func loss 0.15260660648345947\n",
      "\n",
      "episode 13, val func loss 0.14809852838516235\n",
      "\n",
      "episode 14, val func loss 0.22506843507289886\n",
      "\n",
      "episode 15, val func loss 0.06378469616174698\n",
      "\n",
      "episode 16, val func loss 0.16225719451904297\n",
      "\n",
      "Val func train loss in epoch 14:0.16613588528707623\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1462078094482422\n",
      "\n",
      "episode 2, val func loss 0.17138296365737915\n",
      "\n",
      "episode 3, val func loss 0.15159142017364502\n",
      "\n",
      "episode 4, val func loss 0.1746569126844406\n",
      "\n",
      "episode 5, val func loss 0.20653092861175537\n",
      "\n",
      "episode 6, val func loss 0.1455114334821701\n",
      "\n",
      "episode 7, val func loss 0.16102547943592072\n",
      "\n",
      "episode 8, val func loss 0.18775513768196106\n",
      "\n",
      "episode 9, val func loss 0.22344672679901123\n",
      "\n",
      "episode 10, val func loss 0.16203196346759796\n",
      "\n",
      "episode 11, val func loss 0.15995128452777863\n",
      "\n",
      "episode 12, val func loss 0.19988052546977997\n",
      "\n",
      "episode 13, val func loss 0.15434464812278748\n",
      "\n",
      "episode 14, val func loss 0.17861217260360718\n",
      "\n",
      "episode 15, val func loss 0.0649222731590271\n",
      "\n",
      "episode 16, val func loss 0.1719369739294052\n",
      "\n",
      "Val func train loss in epoch 15:0.1662367908284068\n",
      "***********************TIME WAS 4.982669540246328 min*****************************\n",
      "\n",
      "**********************ROUND 97 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.03292727470397949\n",
      "\n",
      "episode 2, policy loss -0.0650656446814537\n",
      "\n",
      "episode 3, policy loss -0.038910139352083206\n",
      "\n",
      "episode 4, policy loss -0.030549632385373116\n",
      "\n",
      "episode 5, policy loss -0.0269178319722414\n",
      "\n",
      "episode 6, policy loss -0.06243544816970825\n",
      "\n",
      "episode 7, policy loss -0.019520025700330734\n",
      "\n",
      "episode 8, policy loss 0.019518142566084862\n",
      "\n",
      "episode 9, policy loss -0.018884100019931793\n",
      "\n",
      "episode 10, policy loss -0.005263430532068014\n",
      "\n",
      "episode 11, policy loss -0.06140923500061035\n",
      "\n",
      "episode 12, policy loss -0.01528895366936922\n",
      "\n",
      "episode 13, policy loss -0.016449803486466408\n",
      "\n",
      "episode 14, policy loss 0.020285040140151978\n",
      "\n",
      "episode 15, policy loss -0.13223525881767273\n",
      "\n",
      "episode 16, policy loss -0.03972792625427246\n",
      "\n",
      "Policy train loss in epoch 0:-0.03286134512745775\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.06214873865246773\n",
      "\n",
      "episode 2, policy loss -0.04092250391840935\n",
      "\n",
      "episode 3, policy loss -0.005997245199978352\n",
      "\n",
      "episode 4, policy loss -0.06386175006628036\n",
      "\n",
      "episode 5, policy loss -0.13237051665782928\n",
      "\n",
      "episode 6, policy loss -0.017033182084560394\n",
      "\n",
      "episode 7, policy loss -0.017794746905565262\n",
      "\n",
      "episode 8, policy loss -0.035086143761873245\n",
      "\n",
      "episode 9, policy loss -0.043366312980651855\n",
      "\n",
      "episode 10, policy loss 0.01951933465898037\n",
      "\n",
      "episode 11, policy loss -0.03043484315276146\n",
      "\n",
      "episode 12, policy loss -0.016364216804504395\n",
      "\n",
      "episode 13, policy loss -0.043666381388902664\n",
      "\n",
      "episode 14, policy loss -0.07512036710977554\n",
      "\n",
      "episode 15, policy loss 0.018467118963599205\n",
      "\n",
      "episode 16, policy loss -0.020573114976286888\n",
      "\n",
      "Policy train loss in epoch 1:-0.0354221006273292\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.0612337552011013\n",
      "\n",
      "episode 2, policy loss -0.04038752615451813\n",
      "\n",
      "episode 3, policy loss -0.01807868666946888\n",
      "\n",
      "episode 4, policy loss -0.02198011800646782\n",
      "\n",
      "episode 5, policy loss 0.017548654228448868\n",
      "\n",
      "episode 6, policy loss -0.04267029091715813\n",
      "\n",
      "episode 7, policy loss -0.005591583903878927\n",
      "\n",
      "episode 8, policy loss -0.03406538441777229\n",
      "\n",
      "episode 9, policy loss -0.13367824256420135\n",
      "\n",
      "episode 10, policy loss -0.044376667588949203\n",
      "\n",
      "episode 11, policy loss -0.07578805834054947\n",
      "\n",
      "episode 12, policy loss -0.0177364032715559\n",
      "\n",
      "episode 13, policy loss -0.06317142397165298\n",
      "\n",
      "episode 14, policy loss -0.030946126207709312\n",
      "\n",
      "episode 15, policy loss 0.019884847104549408\n",
      "\n",
      "episode 16, policy loss -0.016919806599617004\n",
      "\n",
      "Policy train loss in epoch 2:-0.03557441078010015\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.015315310098230839\n",
      "\n",
      "episode 2, policy loss -0.032932646572589874\n",
      "\n",
      "episode 3, policy loss -0.0306180901825428\n",
      "\n",
      "episode 4, policy loss -0.04288183152675629\n",
      "\n",
      "episode 5, policy loss -0.019945744425058365\n",
      "\n",
      "episode 6, policy loss -0.06143500655889511\n",
      "\n",
      "episode 7, policy loss -0.04419197142124176\n",
      "\n",
      "episode 8, policy loss -0.018701843917369843\n",
      "\n",
      "episode 9, policy loss -0.04139556363224983\n",
      "\n",
      "episode 10, policy loss -0.13469800353050232\n",
      "\n",
      "episode 11, policy loss -0.006415348034352064\n",
      "\n",
      "episode 12, policy loss 0.016702895984053612\n",
      "\n",
      "episode 13, policy loss -0.07461941987276077\n",
      "\n",
      "episode 14, policy loss -0.06652911007404327\n",
      "\n",
      "episode 15, policy loss 0.017936984077095985\n",
      "\n",
      "episode 16, policy loss -0.017943786457180977\n",
      "\n",
      "Policy train loss in epoch 3:-0.03581148726516403\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1583375483751297\n",
      "\n",
      "episode 2, val func loss 0.15411049127578735\n",
      "\n",
      "episode 3, val func loss 0.19708016514778137\n",
      "\n",
      "episode 4, val func loss 0.08687673509120941\n",
      "\n",
      "episode 5, val func loss 0.1828763782978058\n",
      "\n",
      "episode 6, val func loss 0.1738385111093521\n",
      "\n",
      "episode 7, val func loss 0.138383686542511\n",
      "\n",
      "episode 8, val func loss 0.1866823136806488\n",
      "\n",
      "episode 9, val func loss 0.14866606891155243\n",
      "\n",
      "episode 10, val func loss 0.13563740253448486\n",
      "\n",
      "episode 11, val func loss 0.11462650448083878\n",
      "\n",
      "episode 12, val func loss 0.11449494957923889\n",
      "\n",
      "episode 13, val func loss 0.20398551225662231\n",
      "\n",
      "episode 14, val func loss 0.24562188982963562\n",
      "\n",
      "episode 15, val func loss 0.13655321300029755\n",
      "\n",
      "episode 16, val func loss 0.16113191843032837\n",
      "\n",
      "Val func train loss in epoch 0:0.15868145553395152\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.14308755099773407\n",
      "\n",
      "episode 2, val func loss 0.20093242824077606\n",
      "\n",
      "episode 3, val func loss 0.1350795328617096\n",
      "\n",
      "episode 4, val func loss 0.11754871904850006\n",
      "\n",
      "episode 5, val func loss 0.2351503074169159\n",
      "\n",
      "episode 6, val func loss 0.08740460872650146\n",
      "\n",
      "episode 7, val func loss 0.18188416957855225\n",
      "\n",
      "episode 8, val func loss 0.13625571131706238\n",
      "\n",
      "episode 9, val func loss 0.11471874266862869\n",
      "\n",
      "episode 10, val func loss 0.156714528799057\n",
      "\n",
      "episode 11, val func loss 0.1556638479232788\n",
      "\n",
      "episode 12, val func loss 0.16116444766521454\n",
      "\n",
      "episode 13, val func loss 0.1927080750465393\n",
      "\n",
      "episode 14, val func loss 0.17275960743427277\n",
      "\n",
      "episode 15, val func loss 0.13940274715423584\n",
      "\n",
      "episode 16, val func loss 0.18286912143230438\n",
      "\n",
      "Val func train loss in epoch 1:0.1570840091444552\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.11742138117551804\n",
      "\n",
      "episode 2, val func loss 0.23410961031913757\n",
      "\n",
      "episode 3, val func loss 0.15473629534244537\n",
      "\n",
      "episode 4, val func loss 0.14011073112487793\n",
      "\n",
      "episode 5, val func loss 0.19348593056201935\n",
      "\n",
      "episode 6, val func loss 0.11398174613714218\n",
      "\n",
      "episode 7, val func loss 0.14315573871135712\n",
      "\n",
      "episode 8, val func loss 0.15757600963115692\n",
      "\n",
      "episode 9, val func loss 0.1609210968017578\n",
      "\n",
      "episode 10, val func loss 0.1722436398267746\n",
      "\n",
      "episode 11, val func loss 0.18206609785556793\n",
      "\n",
      "episode 12, val func loss 0.1368517279624939\n",
      "\n",
      "episode 13, val func loss 0.13345329463481903\n",
      "\n",
      "episode 14, val func loss 0.20182271301746368\n",
      "\n",
      "episode 15, val func loss 0.08711984753608704\n",
      "\n",
      "episode 16, val func loss 0.18076977133750916\n",
      "\n",
      "Val func train loss in epoch 2:0.15686410199850798\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18135058879852295\n",
      "\n",
      "episode 2, val func loss 0.15718722343444824\n",
      "\n",
      "episode 3, val func loss 0.14012038707733154\n",
      "\n",
      "episode 4, val func loss 0.15437187254428864\n",
      "\n",
      "episode 5, val func loss 0.23576310276985168\n",
      "\n",
      "episode 6, val func loss 0.1346634328365326\n",
      "\n",
      "episode 7, val func loss 0.14478233456611633\n",
      "\n",
      "episode 8, val func loss 0.0868212953209877\n",
      "\n",
      "episode 9, val func loss 0.16096945106983185\n",
      "\n",
      "episode 10, val func loss 0.2022123783826828\n",
      "\n",
      "episode 11, val func loss 0.13762448728084564\n",
      "\n",
      "episode 12, val func loss 0.17199373245239258\n",
      "\n",
      "episode 13, val func loss 0.1165846660733223\n",
      "\n",
      "episode 14, val func loss 0.11334537714719772\n",
      "\n",
      "episode 15, val func loss 0.1934216022491455\n",
      "\n",
      "episode 16, val func loss 0.18181376159191132\n",
      "\n",
      "Val func train loss in epoch 3:0.1570641058497131\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18218739330768585\n",
      "\n",
      "episode 2, val func loss 0.20297881960868835\n",
      "\n",
      "episode 3, val func loss 0.18083937466144562\n",
      "\n",
      "episode 4, val func loss 0.16161637008190155\n",
      "\n",
      "episode 5, val func loss 0.13708549737930298\n",
      "\n",
      "episode 6, val func loss 0.14259885251522064\n",
      "\n",
      "episode 7, val func loss 0.15611328184604645\n",
      "\n",
      "episode 8, val func loss 0.08641907572746277\n",
      "\n",
      "episode 9, val func loss 0.17269127070903778\n",
      "\n",
      "episode 10, val func loss 0.11393236368894577\n",
      "\n",
      "episode 11, val func loss 0.2365577220916748\n",
      "\n",
      "episode 12, val func loss 0.13492004573345184\n",
      "\n",
      "episode 13, val func loss 0.15496395528316498\n",
      "\n",
      "episode 14, val func loss 0.19188354909420013\n",
      "\n",
      "episode 15, val func loss 0.1380460411310196\n",
      "\n",
      "episode 16, val func loss 0.11818959563970566\n",
      "\n",
      "Val func train loss in epoch 4:0.15693895053118467\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.20177485048770905\n",
      "\n",
      "episode 2, val func loss 0.184632807970047\n",
      "\n",
      "episode 3, val func loss 0.1910862773656845\n",
      "\n",
      "episode 4, val func loss 0.08815161883831024\n",
      "\n",
      "episode 5, val func loss 0.11328937113285065\n",
      "\n",
      "episode 6, val func loss 0.17975392937660217\n",
      "\n",
      "episode 7, val func loss 0.16163912415504456\n",
      "\n",
      "episode 8, val func loss 0.1732456088066101\n",
      "\n",
      "episode 9, val func loss 0.13419006764888763\n",
      "\n",
      "episode 10, val func loss 0.13768388330936432\n",
      "\n",
      "episode 11, val func loss 0.1390051692724228\n",
      "\n",
      "episode 12, val func loss 0.1141863614320755\n",
      "\n",
      "episode 13, val func loss 0.15747547149658203\n",
      "\n",
      "episode 14, val func loss 0.1411704570055008\n",
      "\n",
      "episode 15, val func loss 0.2394854575395584\n",
      "\n",
      "episode 16, val func loss 0.15439441800117493\n",
      "\n",
      "Val func train loss in epoch 5:0.15694780461490154\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1555003821849823\n",
      "\n",
      "episode 2, val func loss 0.11524077504873276\n",
      "\n",
      "episode 3, val func loss 0.08674252033233643\n",
      "\n",
      "episode 4, val func loss 0.23626860976219177\n",
      "\n",
      "episode 5, val func loss 0.20158782601356506\n",
      "\n",
      "episode 6, val func loss 0.16092689335346222\n",
      "\n",
      "episode 7, val func loss 0.1457490175962448\n",
      "\n",
      "episode 8, val func loss 0.13838040828704834\n",
      "\n",
      "episode 9, val func loss 0.13378597795963287\n",
      "\n",
      "episode 10, val func loss 0.18292368948459625\n",
      "\n",
      "episode 11, val func loss 0.13971202075481415\n",
      "\n",
      "episode 12, val func loss 0.1732470989227295\n",
      "\n",
      "episode 13, val func loss 0.18182283639907837\n",
      "\n",
      "episode 14, val func loss 0.15433067083358765\n",
      "\n",
      "episode 15, val func loss 0.1129222884774208\n",
      "\n",
      "episode 16, val func loss 0.1949448138475418\n",
      "\n",
      "Val func train loss in epoch 6:0.15713036432862282\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1415739357471466\n",
      "\n",
      "episode 2, val func loss 0.11497798562049866\n",
      "\n",
      "episode 3, val func loss 0.18070152401924133\n",
      "\n",
      "episode 4, val func loss 0.17377601563930511\n",
      "\n",
      "episode 5, val func loss 0.1618514358997345\n",
      "\n",
      "episode 6, val func loss 0.13746434450149536\n",
      "\n",
      "episode 7, val func loss 0.11280304938554764\n",
      "\n",
      "episode 8, val func loss 0.20307502150535583\n",
      "\n",
      "episode 9, val func loss 0.13477863371372223\n",
      "\n",
      "episode 10, val func loss 0.19234740734100342\n",
      "\n",
      "episode 11, val func loss 0.08618942648172379\n",
      "\n",
      "episode 12, val func loss 0.1548338234424591\n",
      "\n",
      "episode 13, val func loss 0.13889005780220032\n",
      "\n",
      "episode 14, val func loss 0.15783171355724335\n",
      "\n",
      "episode 15, val func loss 0.23514588177204132\n",
      "\n",
      "episode 16, val func loss 0.18255090713500977\n",
      "\n",
      "Val func train loss in epoch 7:0.15679944772273302\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.13494807481765747\n",
      "\n",
      "episode 2, val func loss 0.161590576171875\n",
      "\n",
      "episode 3, val func loss 0.181704580783844\n",
      "\n",
      "episode 4, val func loss 0.14303800463676453\n",
      "\n",
      "episode 5, val func loss 0.08632384985685349\n",
      "\n",
      "episode 6, val func loss 0.2364245504140854\n",
      "\n",
      "episode 7, val func loss 0.11393863707780838\n",
      "\n",
      "episode 8, val func loss 0.1737053543329239\n",
      "\n",
      "episode 9, val func loss 0.11217057704925537\n",
      "\n",
      "episode 10, val func loss 0.19435277581214905\n",
      "\n",
      "episode 11, val func loss 0.15423281490802765\n",
      "\n",
      "episode 12, val func loss 0.13717135787010193\n",
      "\n",
      "episode 13, val func loss 0.15551747381687164\n",
      "\n",
      "episode 14, val func loss 0.1803140938282013\n",
      "\n",
      "episode 15, val func loss 0.1388295292854309\n",
      "\n",
      "episode 16, val func loss 0.19893042743206024\n",
      "\n",
      "Val func train loss in epoch 8:0.1564495423808694\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1595936417579651\n",
      "\n",
      "episode 2, val func loss 0.15615639090538025\n",
      "\n",
      "episode 3, val func loss 0.1796044558286667\n",
      "\n",
      "episode 4, val func loss 0.13764864206314087\n",
      "\n",
      "episode 5, val func loss 0.14216580986976624\n",
      "\n",
      "episode 6, val func loss 0.08912570029497147\n",
      "\n",
      "episode 7, val func loss 0.1747828871011734\n",
      "\n",
      "episode 8, val func loss 0.1822771430015564\n",
      "\n",
      "episode 9, val func loss 0.13405729830265045\n",
      "\n",
      "episode 10, val func loss 0.23489594459533691\n",
      "\n",
      "episode 11, val func loss 0.20238752663135529\n",
      "\n",
      "episode 12, val func loss 0.11642183363437653\n",
      "\n",
      "episode 13, val func loss 0.15586280822753906\n",
      "\n",
      "episode 14, val func loss 0.14220094680786133\n",
      "\n",
      "episode 15, val func loss 0.19149279594421387\n",
      "\n",
      "episode 16, val func loss 0.11420691013336182\n",
      "\n",
      "Val func train loss in epoch 9:0.15705504594370723\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.13903719186782837\n",
      "\n",
      "episode 2, val func loss 0.08593317866325378\n",
      "\n",
      "episode 3, val func loss 0.15684352815151215\n",
      "\n",
      "episode 4, val func loss 0.1610625684261322\n",
      "\n",
      "episode 5, val func loss 0.14116324484348297\n",
      "\n",
      "episode 6, val func loss 0.15352395176887512\n",
      "\n",
      "episode 7, val func loss 0.11301185190677643\n",
      "\n",
      "episode 8, val func loss 0.20142777264118195\n",
      "\n",
      "episode 9, val func loss 0.19172658026218414\n",
      "\n",
      "episode 10, val func loss 0.1789086014032364\n",
      "\n",
      "episode 11, val func loss 0.23317860066890717\n",
      "\n",
      "episode 12, val func loss 0.17011134326457977\n",
      "\n",
      "episode 13, val func loss 0.12528668344020844\n",
      "\n",
      "episode 14, val func loss 0.1383378803730011\n",
      "\n",
      "episode 15, val func loss 0.13641493022441864\n",
      "\n",
      "episode 16, val func loss 0.18229129910469055\n",
      "\n",
      "Val func train loss in epoch 10:0.15676620043814182\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.17941226065158844\n",
      "\n",
      "episode 2, val func loss 0.13171686232089996\n",
      "\n",
      "episode 3, val func loss 0.08857210725545883\n",
      "\n",
      "episode 4, val func loss 0.18368057906627655\n",
      "\n",
      "episode 5, val func loss 0.11387143284082413\n",
      "\n",
      "episode 6, val func loss 0.13830916583538055\n",
      "\n",
      "episode 7, val func loss 0.11142902821302414\n",
      "\n",
      "episode 8, val func loss 0.14176368713378906\n",
      "\n",
      "episode 9, val func loss 0.24863840639591217\n",
      "\n",
      "episode 10, val func loss 0.16097980737686157\n",
      "\n",
      "episode 11, val func loss 0.19435173273086548\n",
      "\n",
      "episode 12, val func loss 0.15557359158992767\n",
      "\n",
      "episode 13, val func loss 0.20390726625919342\n",
      "\n",
      "episode 14, val func loss 0.17121997475624084\n",
      "\n",
      "episode 15, val func loss 0.15830405056476593\n",
      "\n",
      "episode 16, val func loss 0.1481378674507141\n",
      "\n",
      "Val func train loss in epoch 11:0.15811673877760768\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.16069787740707397\n",
      "\n",
      "episode 2, val func loss 0.1906878501176834\n",
      "\n",
      "episode 3, val func loss 0.13816824555397034\n",
      "\n",
      "episode 4, val func loss 0.23805008828639984\n",
      "\n",
      "episode 5, val func loss 0.15771302580833435\n",
      "\n",
      "episode 6, val func loss 0.11790864914655685\n",
      "\n",
      "episode 7, val func loss 0.20104089379310608\n",
      "\n",
      "episode 8, val func loss 0.11401795595884323\n",
      "\n",
      "episode 9, val func loss 0.18130970001220703\n",
      "\n",
      "episode 10, val func loss 0.18199600279331207\n",
      "\n",
      "episode 11, val func loss 0.14221785962581635\n",
      "\n",
      "episode 12, val func loss 0.17379865050315857\n",
      "\n",
      "episode 13, val func loss 0.15382695198059082\n",
      "\n",
      "episode 14, val func loss 0.14016929268836975\n",
      "\n",
      "episode 15, val func loss 0.08663436025381088\n",
      "\n",
      "episode 16, val func loss 0.13399972021579742\n",
      "\n",
      "Val func train loss in epoch 12:0.15701482025906444\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.14139656722545624\n",
      "\n",
      "episode 2, val func loss 0.11355522274971008\n",
      "\n",
      "episode 3, val func loss 0.1380448341369629\n",
      "\n",
      "episode 4, val func loss 0.08691326528787613\n",
      "\n",
      "episode 5, val func loss 0.1411629021167755\n",
      "\n",
      "episode 6, val func loss 0.2031949907541275\n",
      "\n",
      "episode 7, val func loss 0.18130925297737122\n",
      "\n",
      "episode 8, val func loss 0.16018515825271606\n",
      "\n",
      "episode 9, val func loss 0.17258520424365997\n",
      "\n",
      "episode 10, val func loss 0.1345914751291275\n",
      "\n",
      "episode 11, val func loss 0.19184540212154388\n",
      "\n",
      "episode 12, val func loss 0.15574723482131958\n",
      "\n",
      "episode 13, val func loss 0.118053138256073\n",
      "\n",
      "episode 14, val func loss 0.18038521707057953\n",
      "\n",
      "episode 15, val func loss 0.15691807866096497\n",
      "\n",
      "episode 16, val func loss 0.235322505235672\n",
      "\n",
      "Val func train loss in epoch 13:0.156950653064996\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.11369030922651291\n",
      "\n",
      "episode 2, val func loss 0.1368863433599472\n",
      "\n",
      "episode 3, val func loss 0.08562950789928436\n",
      "\n",
      "episode 4, val func loss 0.15431183576583862\n",
      "\n",
      "episode 5, val func loss 0.15901994705200195\n",
      "\n",
      "episode 6, val func loss 0.19154225289821625\n",
      "\n",
      "episode 7, val func loss 0.13346336781978607\n",
      "\n",
      "episode 8, val func loss 0.20331971347332\n",
      "\n",
      "episode 9, val func loss 0.14509163796901703\n",
      "\n",
      "episode 10, val func loss 0.1566300392150879\n",
      "\n",
      "episode 11, val func loss 0.11562139540910721\n",
      "\n",
      "episode 12, val func loss 0.18204697966575623\n",
      "\n",
      "episode 13, val func loss 0.2399550974369049\n",
      "\n",
      "episode 14, val func loss 0.17389872670173645\n",
      "\n",
      "episode 15, val func loss 0.1395587921142578\n",
      "\n",
      "episode 16, val func loss 0.18070755898952484\n",
      "\n",
      "Val func train loss in epoch 14:0.15696084406226873\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18286794424057007\n",
      "\n",
      "episode 2, val func loss 0.13958996534347534\n",
      "\n",
      "episode 3, val func loss 0.17250744998455048\n",
      "\n",
      "episode 4, val func loss 0.18197521567344666\n",
      "\n",
      "episode 5, val func loss 0.19153885543346405\n",
      "\n",
      "episode 6, val func loss 0.14633230865001678\n",
      "\n",
      "episode 7, val func loss 0.20135286450386047\n",
      "\n",
      "episode 8, val func loss 0.16239209473133087\n",
      "\n",
      "episode 9, val func loss 0.13452038168907166\n",
      "\n",
      "episode 10, val func loss 0.23507890105247498\n",
      "\n",
      "episode 11, val func loss 0.08724945783615112\n",
      "\n",
      "episode 12, val func loss 0.1557883322238922\n",
      "\n",
      "episode 13, val func loss 0.1142968013882637\n",
      "\n",
      "episode 14, val func loss 0.15634404122829437\n",
      "\n",
      "episode 15, val func loss 0.1157878115773201\n",
      "\n",
      "episode 16, val func loss 0.1374337524175644\n",
      "\n",
      "Val func train loss in epoch 15:0.1571910111233592\n",
      "***********************TIME WAS 4.981271620591482 min*****************************\n",
      "\n",
      "**********************ROUND 98 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.003861114149913192\n",
      "\n",
      "episode 2, policy loss -0.03008919022977352\n",
      "\n",
      "episode 3, policy loss -0.03290639445185661\n",
      "\n",
      "episode 4, policy loss 0.002325017936527729\n",
      "\n",
      "episode 5, policy loss 0.04218938946723938\n",
      "\n",
      "episode 6, policy loss 0.026439115405082703\n",
      "\n",
      "episode 7, policy loss -0.001047821599058807\n",
      "\n",
      "episode 8, policy loss -0.003424464724957943\n",
      "\n",
      "episode 9, policy loss 0.021802498027682304\n",
      "\n",
      "episode 10, policy loss 0.01917990669608116\n",
      "\n",
      "episode 11, policy loss 0.01850523240864277\n",
      "\n",
      "episode 12, policy loss 0.04354396462440491\n",
      "\n",
      "episode 13, policy loss -0.0001034417437040247\n",
      "\n",
      "episode 14, policy loss -0.0012630034470930696\n",
      "\n",
      "episode 15, policy loss -0.05051853135228157\n",
      "\n",
      "episode 16, policy loss -0.03430468589067459\n",
      "\n",
      "Policy train loss in epoch 0:0.0015117940797608753\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.039627231657505035\n",
      "\n",
      "episode 2, policy loss 0.016853513196110725\n",
      "\n",
      "episode 3, policy loss -0.05085613951086998\n",
      "\n",
      "episode 4, policy loss -0.001993518089875579\n",
      "\n",
      "episode 5, policy loss -0.0006924399058334529\n",
      "\n",
      "episode 6, policy loss 0.018599826842546463\n",
      "\n",
      "episode 7, policy loss -0.0007747000781819224\n",
      "\n",
      "episode 8, policy loss 7.477978942915797e-05\n",
      "\n",
      "episode 9, policy loss -0.004840938374400139\n",
      "\n",
      "episode 10, policy loss 0.041053906083106995\n",
      "\n",
      "episode 11, policy loss -0.034905821084976196\n",
      "\n",
      "episode 12, policy loss 0.02505003847181797\n",
      "\n",
      "episode 13, policy loss -0.002313429955393076\n",
      "\n",
      "episode 14, policy loss -0.034866053611040115\n",
      "\n",
      "episode 15, policy loss 0.015248325653374195\n",
      "\n",
      "episode 16, policy loss 0.03682127967476845\n",
      "\n",
      "Policy train loss in epoch 1:-0.0010730376598075964\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.04163952171802521\n",
      "\n",
      "episode 2, policy loss -0.003835401963442564\n",
      "\n",
      "episode 3, policy loss 0.03613903000950813\n",
      "\n",
      "episode 4, policy loss 0.014195151627063751\n",
      "\n",
      "episode 5, policy loss 0.018230153247714043\n",
      "\n",
      "episode 6, policy loss 0.0006367915193550289\n",
      "\n",
      "episode 7, policy loss 0.01711920090019703\n",
      "\n",
      "episode 8, policy loss -8.778109622653574e-05\n",
      "\n",
      "episode 9, policy loss 0.024590391665697098\n",
      "\n",
      "episode 10, policy loss -0.03995322436094284\n",
      "\n",
      "episode 11, policy loss -0.034796591848134995\n",
      "\n",
      "episode 12, policy loss -0.050765614956617355\n",
      "\n",
      "episode 13, policy loss -0.000900349288713187\n",
      "\n",
      "episode 14, policy loss -0.002907600486651063\n",
      "\n",
      "episode 15, policy loss -0.003904173383489251\n",
      "\n",
      "episode 16, policy loss -0.034293342381715775\n",
      "\n",
      "Policy train loss in epoch 2:-0.0011808649423983297\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.015600074082612991\n",
      "\n",
      "episode 2, policy loss -0.0017640390433371067\n",
      "\n",
      "episode 3, policy loss 0.016428476199507713\n",
      "\n",
      "episode 4, policy loss -0.005359184928238392\n",
      "\n",
      "episode 5, policy loss 0.0187672208994627\n",
      "\n",
      "episode 6, policy loss -1.2241762306075543e-05\n",
      "\n",
      "episode 7, policy loss -0.003107271622866392\n",
      "\n",
      "episode 8, policy loss -0.003979955799877644\n",
      "\n",
      "episode 9, policy loss -0.04991870000958443\n",
      "\n",
      "episode 10, policy loss -0.04100189730525017\n",
      "\n",
      "episode 11, policy loss -0.03508062660694122\n",
      "\n",
      "episode 12, policy loss -0.03459491580724716\n",
      "\n",
      "episode 13, policy loss 0.024591706693172455\n",
      "\n",
      "episode 14, policy loss -0.0010172328911721706\n",
      "\n",
      "episode 15, policy loss 0.041063956916332245\n",
      "\n",
      "episode 16, policy loss 0.03671952337026596\n",
      "\n",
      "Policy train loss in epoch 3:-0.0014165692259666685\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.18584498763084412\n",
      "\n",
      "episode 2, val func loss 0.1480497121810913\n",
      "\n",
      "episode 3, val func loss 0.19115331768989563\n",
      "\n",
      "episode 4, val func loss 0.19166570901870728\n",
      "\n",
      "episode 5, val func loss 0.18643160164356232\n",
      "\n",
      "episode 6, val func loss 0.1325935423374176\n",
      "\n",
      "episode 7, val func loss 0.1252642422914505\n",
      "\n",
      "episode 8, val func loss 0.11263162642717361\n",
      "\n",
      "episode 9, val func loss 0.16620931029319763\n",
      "\n",
      "episode 10, val func loss 0.163093701004982\n",
      "\n",
      "episode 11, val func loss 0.13097332417964935\n",
      "\n",
      "episode 12, val func loss 0.1701938360929489\n",
      "\n",
      "episode 13, val func loss 0.12832936644554138\n",
      "\n",
      "episode 14, val func loss 0.1632360965013504\n",
      "\n",
      "episode 15, val func loss 0.18796412646770477\n",
      "\n",
      "episode 16, val func loss 0.1364891082048416\n",
      "\n",
      "Val func train loss in epoch 0:0.1575077255256474\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.16970965266227722\n",
      "\n",
      "episode 2, val func loss 0.13001500070095062\n",
      "\n",
      "episode 3, val func loss 0.1316993534564972\n",
      "\n",
      "episode 4, val func loss 0.11403200030326843\n",
      "\n",
      "episode 5, val func loss 0.18902771174907684\n",
      "\n",
      "episode 6, val func loss 0.19126145541667938\n",
      "\n",
      "episode 7, val func loss 0.14786066114902496\n",
      "\n",
      "episode 8, val func loss 0.1303606480360031\n",
      "\n",
      "episode 9, val func loss 0.13589872419834137\n",
      "\n",
      "episode 10, val func loss 0.12381190806627274\n",
      "\n",
      "episode 11, val func loss 0.16204553842544556\n",
      "\n",
      "episode 12, val func loss 0.19346125423908234\n",
      "\n",
      "episode 13, val func loss 0.16588906943798065\n",
      "\n",
      "episode 14, val func loss 0.18774227797985077\n",
      "\n",
      "episode 15, val func loss 0.16475024819374084\n",
      "\n",
      "episode 16, val func loss 0.18417420983314514\n",
      "\n",
      "Val func train loss in epoch 1:0.15760873211547732\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18743088841438293\n",
      "\n",
      "episode 2, val func loss 0.13164597749710083\n",
      "\n",
      "episode 3, val func loss 0.1831856220960617\n",
      "\n",
      "episode 4, val func loss 0.19450698792934418\n",
      "\n",
      "episode 5, val func loss 0.1389256715774536\n",
      "\n",
      "episode 6, val func loss 0.11663302034139633\n",
      "\n",
      "episode 7, val func loss 0.1709425449371338\n",
      "\n",
      "episode 8, val func loss 0.16261789202690125\n",
      "\n",
      "episode 9, val func loss 0.1295110285282135\n",
      "\n",
      "episode 10, val func loss 0.12336883693933487\n",
      "\n",
      "episode 11, val func loss 0.16684988141059875\n",
      "\n",
      "episode 12, val func loss 0.13155922293663025\n",
      "\n",
      "episode 13, val func loss 0.17090162634849548\n",
      "\n",
      "episode 14, val func loss 0.1922881305217743\n",
      "\n",
      "episode 15, val func loss 0.14761614799499512\n",
      "\n",
      "episode 16, val func loss 0.1904313564300537\n",
      "\n",
      "Val func train loss in epoch 2:0.1586509272456169\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1367948204278946\n",
      "\n",
      "episode 2, val func loss 0.1245444118976593\n",
      "\n",
      "episode 3, val func loss 0.131881982088089\n",
      "\n",
      "episode 4, val func loss 0.12827739119529724\n",
      "\n",
      "episode 5, val func loss 0.18800616264343262\n",
      "\n",
      "episode 6, val func loss 0.1145467758178711\n",
      "\n",
      "episode 7, val func loss 0.1662716418504715\n",
      "\n",
      "episode 8, val func loss 0.16318170726299286\n",
      "\n",
      "episode 9, val func loss 0.19334596395492554\n",
      "\n",
      "episode 10, val func loss 0.18938419222831726\n",
      "\n",
      "episode 11, val func loss 0.1851392686367035\n",
      "\n",
      "episode 12, val func loss 0.16254684329032898\n",
      "\n",
      "episode 13, val func loss 0.18683762848377228\n",
      "\n",
      "episode 14, val func loss 0.1505233198404312\n",
      "\n",
      "episode 15, val func loss 0.16955392062664032\n",
      "\n",
      "episode 16, val func loss 0.12941709160804749\n",
      "\n",
      "Val func train loss in epoch 3:0.15751582011580467\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19241422414779663\n",
      "\n",
      "episode 2, val func loss 0.14644135534763336\n",
      "\n",
      "episode 3, val func loss 0.12277930974960327\n",
      "\n",
      "episode 4, val func loss 0.18355295062065125\n",
      "\n",
      "episode 5, val func loss 0.16704872250556946\n",
      "\n",
      "episode 6, val func loss 0.18816956877708435\n",
      "\n",
      "episode 7, val func loss 0.13659094274044037\n",
      "\n",
      "episode 8, val func loss 0.18750517070293427\n",
      "\n",
      "episode 9, val func loss 0.18506349623203278\n",
      "\n",
      "episode 10, val func loss 0.16066046059131622\n",
      "\n",
      "episode 11, val func loss 0.11580150574445724\n",
      "\n",
      "episode 12, val func loss 0.1354081779718399\n",
      "\n",
      "episode 13, val func loss 0.1261233389377594\n",
      "\n",
      "episode 14, val func loss 0.17027324438095093\n",
      "\n",
      "episode 15, val func loss 0.13017000257968903\n",
      "\n",
      "episode 16, val func loss 0.16311630606651306\n",
      "\n",
      "Val func train loss in epoch 4:0.15694492356851697\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.13444995880126953\n",
      "\n",
      "episode 2, val func loss 0.1286100596189499\n",
      "\n",
      "episode 3, val func loss 0.18909677863121033\n",
      "\n",
      "episode 4, val func loss 0.12237101048231125\n",
      "\n",
      "episode 5, val func loss 0.1936892420053482\n",
      "\n",
      "episode 6, val func loss 0.15028779208660126\n",
      "\n",
      "episode 7, val func loss 0.1860007792711258\n",
      "\n",
      "episode 8, val func loss 0.16889598965644836\n",
      "\n",
      "episode 9, val func loss 0.16440682113170624\n",
      "\n",
      "episode 10, val func loss 0.1312100887298584\n",
      "\n",
      "episode 11, val func loss 0.13071058690547943\n",
      "\n",
      "episode 12, val func loss 0.18135614693164825\n",
      "\n",
      "episode 13, val func loss 0.18933740258216858\n",
      "\n",
      "episode 14, val func loss 0.16656465828418732\n",
      "\n",
      "episode 15, val func loss 0.1642543226480484\n",
      "\n",
      "episode 16, val func loss 0.11619064211845398\n",
      "\n",
      "Val func train loss in epoch 5:0.15733951749280095\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.16737717390060425\n",
      "\n",
      "episode 2, val func loss 0.16554372012615204\n",
      "\n",
      "episode 3, val func loss 0.18909400701522827\n",
      "\n",
      "episode 4, val func loss 0.1924268901348114\n",
      "\n",
      "episode 5, val func loss 0.12350080907344818\n",
      "\n",
      "episode 6, val func loss 0.11484720557928085\n",
      "\n",
      "episode 7, val func loss 0.13403786718845367\n",
      "\n",
      "episode 8, val func loss 0.1473497748374939\n",
      "\n",
      "episode 9, val func loss 0.16144022345542908\n",
      "\n",
      "episode 10, val func loss 0.12940706312656403\n",
      "\n",
      "episode 11, val func loss 0.16949912905693054\n",
      "\n",
      "episode 12, val func loss 0.19363684952259064\n",
      "\n",
      "episode 13, val func loss 0.13344042003154755\n",
      "\n",
      "episode 14, val func loss 0.18561318516731262\n",
      "\n",
      "episode 15, val func loss 0.18543507158756256\n",
      "\n",
      "episode 16, val func loss 0.13135550916194916\n",
      "\n",
      "Val func train loss in epoch 6:0.15775030618533492\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1942121535539627\n",
      "\n",
      "episode 2, val func loss 0.1292421817779541\n",
      "\n",
      "episode 3, val func loss 0.13349807262420654\n",
      "\n",
      "episode 4, val func loss 0.16435080766677856\n",
      "\n",
      "episode 5, val func loss 0.11483612656593323\n",
      "\n",
      "episode 6, val func loss 0.1359802931547165\n",
      "\n",
      "episode 7, val func loss 0.12414854764938354\n",
      "\n",
      "episode 8, val func loss 0.14824634790420532\n",
      "\n",
      "episode 9, val func loss 0.16932015120983124\n",
      "\n",
      "episode 10, val func loss 0.16889749467372894\n",
      "\n",
      "episode 11, val func loss 0.1911071538925171\n",
      "\n",
      "episode 12, val func loss 0.19139279425144196\n",
      "\n",
      "episode 13, val func loss 0.16854465007781982\n",
      "\n",
      "episode 14, val func loss 0.18990595638751984\n",
      "\n",
      "episode 15, val func loss 0.13187281787395477\n",
      "\n",
      "episode 16, val func loss 0.18685629963874817\n",
      "\n",
      "Val func train loss in epoch 7:0.1589007405564189\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.11296480149030685\n",
      "\n",
      "episode 2, val func loss 0.1660425066947937\n",
      "\n",
      "episode 3, val func loss 0.18813328444957733\n",
      "\n",
      "episode 4, val func loss 0.13281984627246857\n",
      "\n",
      "episode 5, val func loss 0.19023331999778748\n",
      "\n",
      "episode 6, val func loss 0.13651807606220245\n",
      "\n",
      "episode 7, val func loss 0.16456957161426544\n",
      "\n",
      "episode 8, val func loss 0.12755131721496582\n",
      "\n",
      "episode 9, val func loss 0.18544115126132965\n",
      "\n",
      "episode 10, val func loss 0.16252511739730835\n",
      "\n",
      "episode 11, val func loss 0.18723024427890778\n",
      "\n",
      "episode 12, val func loss 0.19300739467144012\n",
      "\n",
      "episode 13, val func loss 0.13091619312763214\n",
      "\n",
      "episode 14, val func loss 0.14944033324718475\n",
      "\n",
      "episode 15, val func loss 0.12254303693771362\n",
      "\n",
      "episode 16, val func loss 0.16871847212314606\n",
      "\n",
      "Val func train loss in epoch 8:0.15741591667756438\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.15971629321575165\n",
      "\n",
      "episode 2, val func loss 0.1879301518201828\n",
      "\n",
      "episode 3, val func loss 0.18605178594589233\n",
      "\n",
      "episode 4, val func loss 0.1319860816001892\n",
      "\n",
      "episode 5, val func loss 0.1849365532398224\n",
      "\n",
      "episode 6, val func loss 0.13396966457366943\n",
      "\n",
      "episode 7, val func loss 0.13110455870628357\n",
      "\n",
      "episode 8, val func loss 0.18940310180187225\n",
      "\n",
      "episode 9, val func loss 0.12983985245227814\n",
      "\n",
      "episode 10, val func loss 0.16658003628253937\n",
      "\n",
      "episode 11, val func loss 0.12695281207561493\n",
      "\n",
      "episode 12, val func loss 0.16697531938552856\n",
      "\n",
      "episode 13, val func loss 0.18751290440559387\n",
      "\n",
      "episode 14, val func loss 0.16801303625106812\n",
      "\n",
      "episode 15, val func loss 0.11568982899188995\n",
      "\n",
      "episode 16, val func loss 0.14665037393569946\n",
      "\n",
      "Val func train loss in epoch 9:0.15708202216774225\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18591445684432983\n",
      "\n",
      "episode 2, val func loss 0.16945180296897888\n",
      "\n",
      "episode 3, val func loss 0.16633065044879913\n",
      "\n",
      "episode 4, val func loss 0.19675175845623016\n",
      "\n",
      "episode 5, val func loss 0.14796718955039978\n",
      "\n",
      "episode 6, val func loss 0.18801985681056976\n",
      "\n",
      "episode 7, val func loss 0.11563599854707718\n",
      "\n",
      "episode 8, val func loss 0.18823331594467163\n",
      "\n",
      "episode 9, val func loss 0.13266804814338684\n",
      "\n",
      "episode 10, val func loss 0.18922337889671326\n",
      "\n",
      "episode 11, val func loss 0.13005034625530243\n",
      "\n",
      "episode 12, val func loss 0.16411569714546204\n",
      "\n",
      "episode 13, val func loss 0.1328764408826828\n",
      "\n",
      "episode 14, val func loss 0.1646042764186859\n",
      "\n",
      "episode 15, val func loss 0.12595532834529877\n",
      "\n",
      "episode 16, val func loss 0.1366291046142578\n",
      "\n",
      "Val func train loss in epoch 10:0.1584017281420529\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18772689998149872\n",
      "\n",
      "episode 2, val func loss 0.1685817986726761\n",
      "\n",
      "episode 3, val func loss 0.1287851631641388\n",
      "\n",
      "episode 4, val func loss 0.1496528834104538\n",
      "\n",
      "episode 5, val func loss 0.16109007596969604\n",
      "\n",
      "episode 6, val func loss 0.11412857472896576\n",
      "\n",
      "episode 7, val func loss 0.19209182262420654\n",
      "\n",
      "episode 8, val func loss 0.16540659964084625\n",
      "\n",
      "episode 9, val func loss 0.131320983171463\n",
      "\n",
      "episode 10, val func loss 0.13161596655845642\n",
      "\n",
      "episode 11, val func loss 0.1872572898864746\n",
      "\n",
      "episode 12, val func loss 0.1833757758140564\n",
      "\n",
      "episode 13, val func loss 0.12510013580322266\n",
      "\n",
      "episode 14, val func loss 0.19318106770515442\n",
      "\n",
      "episode 15, val func loss 0.1373327672481537\n",
      "\n",
      "episode 16, val func loss 0.17060601711273193\n",
      "\n",
      "Val func train loss in epoch 11:0.1579533638432622\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.13085705041885376\n",
      "\n",
      "episode 2, val func loss 0.14931851625442505\n",
      "\n",
      "episode 3, val func loss 0.1888633817434311\n",
      "\n",
      "episode 4, val func loss 0.12924370169639587\n",
      "\n",
      "episode 5, val func loss 0.1950795203447342\n",
      "\n",
      "episode 6, val func loss 0.11359746009111404\n",
      "\n",
      "episode 7, val func loss 0.18932348489761353\n",
      "\n",
      "episode 8, val func loss 0.16931463778018951\n",
      "\n",
      "episode 9, val func loss 0.16626840829849243\n",
      "\n",
      "episode 10, val func loss 0.16305693984031677\n",
      "\n",
      "episode 11, val func loss 0.19166694581508636\n",
      "\n",
      "episode 12, val func loss 0.1375807523727417\n",
      "\n",
      "episode 13, val func loss 0.1249857172369957\n",
      "\n",
      "episode 14, val func loss 0.13096444308757782\n",
      "\n",
      "episode 15, val func loss 0.18582500517368317\n",
      "\n",
      "episode 16, val func loss 0.16689372062683105\n",
      "\n",
      "Val func train loss in epoch 12:0.15830248035490513\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.13051621615886688\n",
      "\n",
      "episode 2, val func loss 0.1132970079779625\n",
      "\n",
      "episode 3, val func loss 0.16225343942642212\n",
      "\n",
      "episode 4, val func loss 0.16594170033931732\n",
      "\n",
      "episode 5, val func loss 0.18887461721897125\n",
      "\n",
      "episode 6, val func loss 0.12428583204746246\n",
      "\n",
      "episode 7, val func loss 0.16921643912792206\n",
      "\n",
      "episode 8, val func loss 0.14897723495960236\n",
      "\n",
      "episode 9, val func loss 0.1283482313156128\n",
      "\n",
      "episode 10, val func loss 0.13508962094783783\n",
      "\n",
      "episode 11, val func loss 0.18586252629756927\n",
      "\n",
      "episode 12, val func loss 0.16671663522720337\n",
      "\n",
      "episode 13, val func loss 0.19201166927814484\n",
      "\n",
      "episode 14, val func loss 0.12930899858474731\n",
      "\n",
      "episode 15, val func loss 0.19289560616016388\n",
      "\n",
      "episode 16, val func loss 0.18365277349948883\n",
      "\n",
      "Val func train loss in epoch 13:0.15732803428545594\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17202791571617126\n",
      "\n",
      "episode 2, val func loss 0.19427621364593506\n",
      "\n",
      "episode 3, val func loss 0.16834108531475067\n",
      "\n",
      "episode 4, val func loss 0.18448223173618317\n",
      "\n",
      "episode 5, val func loss 0.15229153633117676\n",
      "\n",
      "episode 6, val func loss 0.16579647362232208\n",
      "\n",
      "episode 7, val func loss 0.1861521452665329\n",
      "\n",
      "episode 8, val func loss 0.12369144707918167\n",
      "\n",
      "episode 9, val func loss 0.191181018948555\n",
      "\n",
      "episode 10, val func loss 0.16024599969387054\n",
      "\n",
      "episode 11, val func loss 0.1134183406829834\n",
      "\n",
      "episode 12, val func loss 0.12880340218544006\n",
      "\n",
      "episode 13, val func loss 0.1303148716688156\n",
      "\n",
      "episode 14, val func loss 0.13184259831905365\n",
      "\n",
      "episode 15, val func loss 0.1347436159849167\n",
      "\n",
      "episode 16, val func loss 0.18869495391845703\n",
      "\n",
      "Val func train loss in epoch 14:0.1578939906321466\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.14954668283462524\n",
      "\n",
      "episode 2, val func loss 0.12383108586072922\n",
      "\n",
      "episode 3, val func loss 0.13104501366615295\n",
      "\n",
      "episode 4, val func loss 0.12776653468608856\n",
      "\n",
      "episode 5, val func loss 0.18655671179294586\n",
      "\n",
      "episode 6, val func loss 0.13567467033863068\n",
      "\n",
      "episode 7, val func loss 0.15998080372810364\n",
      "\n",
      "episode 8, val func loss 0.16462352871894836\n",
      "\n",
      "episode 9, val func loss 0.18753644824028015\n",
      "\n",
      "episode 10, val func loss 0.17085745930671692\n",
      "\n",
      "episode 11, val func loss 0.1322081834077835\n",
      "\n",
      "episode 12, val func loss 0.1862771064043045\n",
      "\n",
      "episode 13, val func loss 0.19057416915893555\n",
      "\n",
      "episode 14, val func loss 0.19012318551540375\n",
      "\n",
      "episode 15, val func loss 0.11347472667694092\n",
      "\n",
      "episode 16, val func loss 0.1654277741909027\n",
      "\n",
      "Val func train loss in epoch 15:0.15721900528296828\n",
      "***********************TIME WAS 4.98424441019694 min*****************************\n",
      "\n",
      "**********************ROUND 99 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.042237620800733566\n",
      "\n",
      "episode 2, policy loss 0.06047140806913376\n",
      "\n",
      "episode 3, policy loss 0.06566420942544937\n",
      "\n",
      "episode 4, policy loss 0.09222263097763062\n",
      "\n",
      "episode 5, policy loss 0.030896609649062157\n",
      "\n",
      "episode 6, policy loss 0.10362179577350616\n",
      "\n",
      "episode 7, policy loss 0.026686465367674828\n",
      "\n",
      "episode 8, policy loss 0.03819065913558006\n",
      "\n",
      "episode 9, policy loss 0.06165960058569908\n",
      "\n",
      "episode 10, policy loss 0.002340246457606554\n",
      "\n",
      "episode 11, policy loss 0.07378072291612625\n",
      "\n",
      "episode 12, policy loss 0.08709920197725296\n",
      "\n",
      "episode 13, policy loss 0.055311765521764755\n",
      "\n",
      "episode 14, policy loss 0.040689948946237564\n",
      "\n",
      "episode 15, policy loss 0.03131614252924919\n",
      "\n",
      "episode 16, policy loss 0.07797025144100189\n",
      "\n",
      "Policy train loss in epoch 0:0.0556349549733568\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.05626366287469864\n",
      "\n",
      "episode 2, policy loss 0.03899238631129265\n",
      "\n",
      "episode 3, policy loss 0.08656854927539825\n",
      "\n",
      "episode 4, policy loss 0.039447151124477386\n",
      "\n",
      "episode 5, policy loss 0.07415217906236649\n",
      "\n",
      "episode 6, policy loss 0.10158033668994904\n",
      "\n",
      "episode 7, policy loss 0.03424280509352684\n",
      "\n",
      "episode 8, policy loss 0.002116740681231022\n",
      "\n",
      "episode 9, policy loss 0.059611327946186066\n",
      "\n",
      "episode 10, policy loss 0.05547252297401428\n",
      "\n",
      "episode 11, policy loss 0.07291160523891449\n",
      "\n",
      "episode 12, policy loss 0.024281036108732224\n",
      "\n",
      "episode 13, policy loss 0.06131201237440109\n",
      "\n",
      "episode 14, policy loss 0.0882260650396347\n",
      "\n",
      "episode 15, policy loss 0.02775859646499157\n",
      "\n",
      "episode 16, policy loss 0.02941235341131687\n",
      "\n",
      "Policy train loss in epoch 1:0.053271833166945726\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.02822105772793293\n",
      "\n",
      "episode 2, policy loss -0.00012584193609654903\n",
      "\n",
      "episode 3, policy loss 0.03606019914150238\n",
      "\n",
      "episode 4, policy loss 0.08713509142398834\n",
      "\n",
      "episode 5, policy loss 0.03894956409931183\n",
      "\n",
      "episode 6, policy loss 0.09931466728448868\n",
      "\n",
      "episode 7, policy loss 0.05522651597857475\n",
      "\n",
      "episode 8, policy loss 0.03303755819797516\n",
      "\n",
      "episode 9, policy loss 0.059434205293655396\n",
      "\n",
      "episode 10, policy loss 0.0728864073753357\n",
      "\n",
      "episode 11, policy loss 0.054091326892375946\n",
      "\n",
      "episode 12, policy loss 0.07053282111883163\n",
      "\n",
      "episode 13, policy loss 0.08470363169908524\n",
      "\n",
      "episode 14, policy loss 0.022335110232234\n",
      "\n",
      "episode 15, policy loss 0.05975567176938057\n",
      "\n",
      "episode 16, policy loss 0.027943462133407593\n",
      "\n",
      "Policy train loss in epoch 2:0.051843840526998974\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.09971775114536285\n",
      "\n",
      "episode 2, policy loss 0.03268294781446457\n",
      "\n",
      "episode 3, policy loss 0.05853364244103432\n",
      "\n",
      "episode 4, policy loss 0.055127788335084915\n",
      "\n",
      "episode 5, policy loss 0.03568108379840851\n",
      "\n",
      "episode 6, policy loss 0.02796485461294651\n",
      "\n",
      "episode 7, policy loss 0.05335482209920883\n",
      "\n",
      "episode 8, policy loss 0.02726704068481922\n",
      "\n",
      "episode 9, policy loss 0.08506349474191666\n",
      "\n",
      "episode 10, policy loss -0.0020056557841598988\n",
      "\n",
      "episode 11, policy loss 0.022017117589712143\n",
      "\n",
      "episode 12, policy loss 0.05938414856791496\n",
      "\n",
      "episode 13, policy loss 0.07154484838247299\n",
      "\n",
      "episode 14, policy loss 0.03803931176662445\n",
      "\n",
      "episode 15, policy loss 0.07054702937602997\n",
      "\n",
      "episode 16, policy loss 0.0864465981721878\n",
      "\n",
      "Policy train loss in epoch 3:0.0513354264840018\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.14286060631275177\n",
      "\n",
      "episode 2, val func loss 0.18045981228351593\n",
      "\n",
      "episode 3, val func loss 0.20286300778388977\n",
      "\n",
      "episode 4, val func loss 0.21636144816875458\n",
      "\n",
      "episode 5, val func loss 0.17922426760196686\n",
      "\n",
      "episode 6, val func loss 0.14908407628536224\n",
      "\n",
      "episode 7, val func loss 0.19628272950649261\n",
      "\n",
      "episode 8, val func loss 0.16198459267616272\n",
      "\n",
      "episode 9, val func loss 0.19999438524246216\n",
      "\n",
      "episode 10, val func loss 0.15075312554836273\n",
      "\n",
      "episode 11, val func loss 0.183258056640625\n",
      "\n",
      "episode 12, val func loss 0.20915602147579193\n",
      "\n",
      "episode 13, val func loss 0.15236303210258484\n",
      "\n",
      "episode 14, val func loss 0.16973307728767395\n",
      "\n",
      "episode 15, val func loss 0.20937281847000122\n",
      "\n",
      "episode 16, val func loss 0.19167204201221466\n",
      "\n",
      "Val func train loss in epoch 0:0.1809639437124133\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.20519737899303436\n",
      "\n",
      "episode 2, val func loss 0.19453854858875275\n",
      "\n",
      "episode 3, val func loss 0.17264136672019958\n",
      "\n",
      "episode 4, val func loss 0.21234014630317688\n",
      "\n",
      "episode 5, val func loss 0.21670013666152954\n",
      "\n",
      "episode 6, val func loss 0.18068911135196686\n",
      "\n",
      "episode 7, val func loss 0.15322250127792358\n",
      "\n",
      "episode 8, val func loss 0.1427043378353119\n",
      "\n",
      "episode 9, val func loss 0.20858536660671234\n",
      "\n",
      "episode 10, val func loss 0.1513257920742035\n",
      "\n",
      "episode 11, val func loss 0.20413969457149506\n",
      "\n",
      "episode 12, val func loss 0.18997062742710114\n",
      "\n",
      "episode 13, val func loss 0.18327642977237701\n",
      "\n",
      "episode 14, val func loss 0.14883685111999512\n",
      "\n",
      "episode 15, val func loss 0.16204975545406342\n",
      "\n",
      "episode 16, val func loss 0.16950573027133942\n",
      "\n",
      "Val func train loss in epoch 1:0.1809827359393239\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.15611165761947632\n",
      "\n",
      "episode 2, val func loss 0.20170879364013672\n",
      "\n",
      "episode 3, val func loss 0.2079349160194397\n",
      "\n",
      "episode 4, val func loss 0.189214289188385\n",
      "\n",
      "episode 5, val func loss 0.18267054855823517\n",
      "\n",
      "episode 6, val func loss 0.16997681558132172\n",
      "\n",
      "episode 7, val func loss 0.204487144947052\n",
      "\n",
      "episode 8, val func loss 0.15040323138237\n",
      "\n",
      "episode 9, val func loss 0.14883188903331757\n",
      "\n",
      "episode 10, val func loss 0.1972007006406784\n",
      "\n",
      "episode 11, val func loss 0.18097463250160217\n",
      "\n",
      "episode 12, val func loss 0.2171018123626709\n",
      "\n",
      "episode 13, val func loss 0.2111867219209671\n",
      "\n",
      "episode 14, val func loss 0.17662477493286133\n",
      "\n",
      "episode 15, val func loss 0.1428126096725464\n",
      "\n",
      "episode 16, val func loss 0.1618080586194992\n",
      "\n",
      "Val func train loss in epoch 2:0.18119053728878498\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19020001590251923\n",
      "\n",
      "episode 2, val func loss 0.21250256896018982\n",
      "\n",
      "episode 3, val func loss 0.16954123973846436\n",
      "\n",
      "episode 4, val func loss 0.19533364474773407\n",
      "\n",
      "episode 5, val func loss 0.14877615869045258\n",
      "\n",
      "episode 6, val func loss 0.21695883572101593\n",
      "\n",
      "episode 7, val func loss 0.14380967617034912\n",
      "\n",
      "episode 8, val func loss 0.15402434766292572\n",
      "\n",
      "episode 9, val func loss 0.1814817190170288\n",
      "\n",
      "episode 10, val func loss 0.20156583189964294\n",
      "\n",
      "episode 11, val func loss 0.16159223020076752\n",
      "\n",
      "episode 12, val func loss 0.2082182914018631\n",
      "\n",
      "episode 13, val func loss 0.20305617153644562\n",
      "\n",
      "episode 14, val func loss 0.15209712088108063\n",
      "\n",
      "episode 15, val func loss 0.1770409345626831\n",
      "\n",
      "episode 16, val func loss 0.1821976602077484\n",
      "\n",
      "Val func train loss in epoch 3:0.18114977795630693\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17402824759483337\n",
      "\n",
      "episode 2, val func loss 0.21295815706253052\n",
      "\n",
      "episode 3, val func loss 0.15132814645767212\n",
      "\n",
      "episode 4, val func loss 0.18261432647705078\n",
      "\n",
      "episode 5, val func loss 0.15052999556064606\n",
      "\n",
      "episode 6, val func loss 0.20917938649654388\n",
      "\n",
      "episode 7, val func loss 0.19622796773910522\n",
      "\n",
      "episode 8, val func loss 0.21678149700164795\n",
      "\n",
      "episode 9, val func loss 0.1429678499698639\n",
      "\n",
      "episode 10, val func loss 0.16217902302742004\n",
      "\n",
      "episode 11, val func loss 0.1883755624294281\n",
      "\n",
      "episode 12, val func loss 0.1691412776708603\n",
      "\n",
      "episode 13, val func loss 0.15609489381313324\n",
      "\n",
      "episode 14, val func loss 0.20118620991706848\n",
      "\n",
      "episode 15, val func loss 0.18074840307235718\n",
      "\n",
      "episode 16, val func loss 0.20304466784000397\n",
      "\n",
      "Val func train loss in epoch 4:0.18108660075813532\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.20110955834388733\n",
      "\n",
      "episode 2, val func loss 0.14823609590530396\n",
      "\n",
      "episode 3, val func loss 0.14199848473072052\n",
      "\n",
      "episode 4, val func loss 0.19131779670715332\n",
      "\n",
      "episode 5, val func loss 0.2059447467327118\n",
      "\n",
      "episode 6, val func loss 0.18475472927093506\n",
      "\n",
      "episode 7, val func loss 0.20402266085147858\n",
      "\n",
      "episode 8, val func loss 0.21350429952144623\n",
      "\n",
      "episode 9, val func loss 0.21414723992347717\n",
      "\n",
      "episode 10, val func loss 0.15670260787010193\n",
      "\n",
      "episode 11, val func loss 0.1521252989768982\n",
      "\n",
      "episode 12, val func loss 0.19482304155826569\n",
      "\n",
      "episode 13, val func loss 0.16926230490207672\n",
      "\n",
      "episode 14, val func loss 0.1814829409122467\n",
      "\n",
      "episode 15, val func loss 0.17028124630451202\n",
      "\n",
      "episode 16, val func loss 0.16302147507667542\n",
      "\n",
      "Val func train loss in epoch 5:0.18079590797424316\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1880420595407486\n",
      "\n",
      "episode 2, val func loss 0.19575436413288116\n",
      "\n",
      "episode 3, val func loss 0.15276634693145752\n",
      "\n",
      "episode 4, val func loss 0.20403356850147247\n",
      "\n",
      "episode 5, val func loss 0.21696127951145172\n",
      "\n",
      "episode 6, val func loss 0.14228130877017975\n",
      "\n",
      "episode 7, val func loss 0.18111833930015564\n",
      "\n",
      "episode 8, val func loss 0.1640947163105011\n",
      "\n",
      "episode 9, val func loss 0.15384186804294586\n",
      "\n",
      "episode 10, val func loss 0.21050827205181122\n",
      "\n",
      "episode 11, val func loss 0.19640137255191803\n",
      "\n",
      "episode 12, val func loss 0.1810082197189331\n",
      "\n",
      "episode 13, val func loss 0.14759257435798645\n",
      "\n",
      "episode 14, val func loss 0.2055836170911789\n",
      "\n",
      "episode 15, val func loss 0.16984465718269348\n",
      "\n",
      "episode 16, val func loss 0.1815592348575592\n",
      "\n",
      "Val func train loss in epoch 6:0.18071198742836714\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18277354538440704\n",
      "\n",
      "episode 2, val func loss 0.1903345286846161\n",
      "\n",
      "episode 3, val func loss 0.19693176448345184\n",
      "\n",
      "episode 4, val func loss 0.18183563649654388\n",
      "\n",
      "episode 5, val func loss 0.20564983785152435\n",
      "\n",
      "episode 6, val func loss 0.20388881862163544\n",
      "\n",
      "episode 7, val func loss 0.2154942899942398\n",
      "\n",
      "episode 8, val func loss 0.1541762799024582\n",
      "\n",
      "episode 9, val func loss 0.20426034927368164\n",
      "\n",
      "episode 10, val func loss 0.17419695854187012\n",
      "\n",
      "episode 11, val func loss 0.16968828439712524\n",
      "\n",
      "episode 12, val func loss 0.1508180946111679\n",
      "\n",
      "episode 13, val func loss 0.1438826471567154\n",
      "\n",
      "episode 14, val func loss 0.16230593621730804\n",
      "\n",
      "episode 15, val func loss 0.21253156661987305\n",
      "\n",
      "episode 16, val func loss 0.1493251919746399\n",
      "\n",
      "Val func train loss in epoch 7:0.18113085813820362\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.2157330960035324\n",
      "\n",
      "episode 2, val func loss 0.21042002737522125\n",
      "\n",
      "episode 3, val func loss 0.1426847279071808\n",
      "\n",
      "episode 4, val func loss 0.203340083360672\n",
      "\n",
      "episode 5, val func loss 0.19046609103679657\n",
      "\n",
      "episode 6, val func loss 0.19782134890556335\n",
      "\n",
      "episode 7, val func loss 0.17994920909404755\n",
      "\n",
      "episode 8, val func loss 0.20794682204723358\n",
      "\n",
      "episode 9, val func loss 0.18235094845294952\n",
      "\n",
      "episode 10, val func loss 0.1509324461221695\n",
      "\n",
      "episode 11, val func loss 0.14837045967578888\n",
      "\n",
      "episode 12, val func loss 0.20596446096897125\n",
      "\n",
      "episode 13, val func loss 0.16787609457969666\n",
      "\n",
      "episode 14, val func loss 0.17233878374099731\n",
      "\n",
      "episode 15, val func loss 0.15433067083358765\n",
      "\n",
      "episode 16, val func loss 0.16196128726005554\n",
      "\n",
      "Val func train loss in epoch 8:0.180780409835279\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.15211617946624756\n",
      "\n",
      "episode 2, val func loss 0.18737713992595673\n",
      "\n",
      "episode 3, val func loss 0.19472894072532654\n",
      "\n",
      "episode 4, val func loss 0.2108161449432373\n",
      "\n",
      "episode 5, val func loss 0.17015977203845978\n",
      "\n",
      "episode 6, val func loss 0.15081284940242767\n",
      "\n",
      "episode 7, val func loss 0.20149384438991547\n",
      "\n",
      "episode 8, val func loss 0.16143923997879028\n",
      "\n",
      "episode 9, val func loss 0.21175310015678406\n",
      "\n",
      "episode 10, val func loss 0.15089480578899384\n",
      "\n",
      "episode 11, val func loss 0.1811107099056244\n",
      "\n",
      "episode 12, val func loss 0.21601776778697968\n",
      "\n",
      "episode 13, val func loss 0.20403578877449036\n",
      "\n",
      "episode 14, val func loss 0.1812056452035904\n",
      "\n",
      "episode 15, val func loss 0.14458362758159637\n",
      "\n",
      "episode 16, val func loss 0.18067210912704468\n",
      "\n",
      "Val func train loss in epoch 9:0.18120110407471657\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.15348075330257416\n",
      "\n",
      "episode 2, val func loss 0.20380982756614685\n",
      "\n",
      "episode 3, val func loss 0.20670443773269653\n",
      "\n",
      "episode 4, val func loss 0.20173409581184387\n",
      "\n",
      "episode 5, val func loss 0.18056324124336243\n",
      "\n",
      "episode 6, val func loss 0.16184744238853455\n",
      "\n",
      "episode 7, val func loss 0.19697082042694092\n",
      "\n",
      "episode 8, val func loss 0.1697860062122345\n",
      "\n",
      "episode 9, val func loss 0.21525026857852936\n",
      "\n",
      "episode 10, val func loss 0.18265128135681152\n",
      "\n",
      "episode 11, val func loss 0.1422455608844757\n",
      "\n",
      "episode 12, val func loss 0.17438876628875732\n",
      "\n",
      "episode 13, val func loss 0.1500687599182129\n",
      "\n",
      "episode 14, val func loss 0.18887107074260712\n",
      "\n",
      "episode 15, val func loss 0.14756973087787628\n",
      "\n",
      "episode 16, val func loss 0.21586762368679047\n",
      "\n",
      "Val func train loss in epoch 10:0.18073810543864965\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16181130707263947\n",
      "\n",
      "episode 2, val func loss 0.2092650979757309\n",
      "\n",
      "episode 3, val func loss 0.15477555990219116\n",
      "\n",
      "episode 4, val func loss 0.15503396093845367\n",
      "\n",
      "episode 5, val func loss 0.17279958724975586\n",
      "\n",
      "episode 6, val func loss 0.21505886316299438\n",
      "\n",
      "episode 7, val func loss 0.14748874306678772\n",
      "\n",
      "episode 8, val func loss 0.14250008761882782\n",
      "\n",
      "episode 9, val func loss 0.1834501475095749\n",
      "\n",
      "episode 10, val func loss 0.2113719880580902\n",
      "\n",
      "episode 11, val func loss 0.1703910231590271\n",
      "\n",
      "episode 12, val func loss 0.18982462584972382\n",
      "\n",
      "episode 13, val func loss 0.2010672241449356\n",
      "\n",
      "episode 14, val func loss 0.17933039367198944\n",
      "\n",
      "episode 15, val func loss 0.1977716088294983\n",
      "\n",
      "episode 16, val func loss 0.20037715137004852\n",
      "\n",
      "Val func train loss in epoch 11:0.1807698355987668\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.2113112062215805\n",
      "\n",
      "episode 2, val func loss 0.16925522685050964\n",
      "\n",
      "episode 3, val func loss 0.19775067269802094\n",
      "\n",
      "episode 4, val func loss 0.19150996208190918\n",
      "\n",
      "episode 5, val func loss 0.14818048477172852\n",
      "\n",
      "episode 6, val func loss 0.1444893777370453\n",
      "\n",
      "episode 7, val func loss 0.20480239391326904\n",
      "\n",
      "episode 8, val func loss 0.18241877853870392\n",
      "\n",
      "episode 9, val func loss 0.15137453377246857\n",
      "\n",
      "episode 10, val func loss 0.21656131744384766\n",
      "\n",
      "episode 11, val func loss 0.16321581602096558\n",
      "\n",
      "episode 12, val func loss 0.1722734272480011\n",
      "\n",
      "episode 13, val func loss 0.15194493532180786\n",
      "\n",
      "episode 14, val func loss 0.20894880592823029\n",
      "\n",
      "episode 15, val func loss 0.18119290471076965\n",
      "\n",
      "episode 16, val func loss 0.20199471712112427\n",
      "\n",
      "Val func train loss in epoch 12:0.18107653502374887\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.16213183104991913\n",
      "\n",
      "episode 2, val func loss 0.14912286400794983\n",
      "\n",
      "episode 3, val func loss 0.15290521085262299\n",
      "\n",
      "episode 4, val func loss 0.15225201845169067\n",
      "\n",
      "episode 5, val func loss 0.1882585734128952\n",
      "\n",
      "episode 6, val func loss 0.16948634386062622\n",
      "\n",
      "episode 7, val func loss 0.14272695779800415\n",
      "\n",
      "episode 8, val func loss 0.21543067693710327\n",
      "\n",
      "episode 9, val func loss 0.20095157623291016\n",
      "\n",
      "episode 10, val func loss 0.20802834630012512\n",
      "\n",
      "episode 11, val func loss 0.20209641754627228\n",
      "\n",
      "episode 12, val func loss 0.17993871867656708\n",
      "\n",
      "episode 13, val func loss 0.183442160487175\n",
      "\n",
      "episode 14, val func loss 0.2090986967086792\n",
      "\n",
      "episode 15, val func loss 0.1998162865638733\n",
      "\n",
      "episode 16, val func loss 0.17811116576194763\n",
      "\n",
      "Val func train loss in epoch 13:0.18086236529052258\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.14229945838451385\n",
      "\n",
      "episode 2, val func loss 0.2125537395477295\n",
      "\n",
      "episode 3, val func loss 0.1692482829093933\n",
      "\n",
      "episode 4, val func loss 0.18120579421520233\n",
      "\n",
      "episode 5, val func loss 0.1999519020318985\n",
      "\n",
      "episode 6, val func loss 0.15087667107582092\n",
      "\n",
      "episode 7, val func loss 0.17455348372459412\n",
      "\n",
      "episode 8, val func loss 0.14979980885982513\n",
      "\n",
      "episode 9, val func loss 0.19390486180782318\n",
      "\n",
      "episode 10, val func loss 0.15954135358333588\n",
      "\n",
      "episode 11, val func loss 0.20968939363956451\n",
      "\n",
      "episode 12, val func loss 0.1874992549419403\n",
      "\n",
      "episode 13, val func loss 0.21497395634651184\n",
      "\n",
      "episode 14, val func loss 0.18431560695171356\n",
      "\n",
      "episode 15, val func loss 0.2044094353914261\n",
      "\n",
      "episode 16, val func loss 0.15341602265834808\n",
      "\n",
      "Val func train loss in epoch 14:0.18051493912935257\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19114112854003906\n",
      "\n",
      "episode 2, val func loss 0.1828354001045227\n",
      "\n",
      "episode 3, val func loss 0.20204192399978638\n",
      "\n",
      "episode 4, val func loss 0.2162092924118042\n",
      "\n",
      "episode 5, val func loss 0.14901547133922577\n",
      "\n",
      "episode 6, val func loss 0.17255346477031708\n",
      "\n",
      "episode 7, val func loss 0.15444697439670563\n",
      "\n",
      "episode 8, val func loss 0.19495359063148499\n",
      "\n",
      "episode 9, val func loss 0.18122640252113342\n",
      "\n",
      "episode 10, val func loss 0.21396711468696594\n",
      "\n",
      "episode 11, val func loss 0.20405970513820648\n",
      "\n",
      "episode 12, val func loss 0.14851883053779602\n",
      "\n",
      "episode 13, val func loss 0.16245689988136292\n",
      "\n",
      "episode 14, val func loss 0.16980142891407013\n",
      "\n",
      "episode 15, val func loss 0.14148488640785217\n",
      "\n",
      "episode 16, val func loss 0.2076476365327835\n",
      "\n",
      "Val func train loss in epoch 15:0.18077250942587852\n",
      "***********************TIME WAS 4.98213152885437 min*****************************\n",
      "\n",
      "**********************ROUND 100 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.28941118717193604\n",
      "\n",
      "episode 2, policy loss 0.3238081932067871\n",
      "\n",
      "episode 3, policy loss 0.26160386204719543\n",
      "\n",
      "episode 4, policy loss 0.23197299242019653\n",
      "\n",
      "episode 5, policy loss 0.38987594842910767\n",
      "\n",
      "episode 6, policy loss 0.3341616094112396\n",
      "\n",
      "episode 7, policy loss 0.17132744193077087\n",
      "\n",
      "episode 8, policy loss 0.2893877625465393\n",
      "\n",
      "episode 9, policy loss 0.3325207829475403\n",
      "\n",
      "episode 10, policy loss 0.2221495807170868\n",
      "\n",
      "episode 11, policy loss 0.2244473397731781\n",
      "\n",
      "episode 12, policy loss 0.3107343912124634\n",
      "\n",
      "episode 13, policy loss 0.3713778853416443\n",
      "\n",
      "episode 14, policy loss 0.34813064336776733\n",
      "\n",
      "episode 15, policy loss 0.3433384597301483\n",
      "\n",
      "episode 16, policy loss 0.3285643756389618\n",
      "\n",
      "Policy train loss in epoch 0:0.2983007784932852\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.39229080080986023\n",
      "\n",
      "episode 2, policy loss 0.29350027441978455\n",
      "\n",
      "episode 3, policy loss 0.26095277070999146\n",
      "\n",
      "episode 4, policy loss 0.22586682438850403\n",
      "\n",
      "episode 5, policy loss 0.3733372688293457\n",
      "\n",
      "episode 6, policy loss 0.17020054161548615\n",
      "\n",
      "episode 7, policy loss 0.3437855541706085\n",
      "\n",
      "episode 8, policy loss 0.33117809891700745\n",
      "\n",
      "episode 9, policy loss 0.33033865690231323\n",
      "\n",
      "episode 10, policy loss 0.2849433720111847\n",
      "\n",
      "episode 11, policy loss 0.3213658034801483\n",
      "\n",
      "episode 12, policy loss 0.22343014180660248\n",
      "\n",
      "episode 13, policy loss 0.34835389256477356\n",
      "\n",
      "episode 14, policy loss 0.3095053732395172\n",
      "\n",
      "episode 15, policy loss 0.21998651325702667\n",
      "\n",
      "episode 16, policy loss 0.32709822058677673\n",
      "\n",
      "Policy train loss in epoch 1:0.2972583817318082\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.3176512122154236\n",
      "\n",
      "episode 2, policy loss 0.26133260130882263\n",
      "\n",
      "episode 3, policy loss 0.37351468205451965\n",
      "\n",
      "episode 4, policy loss 0.22868911921977997\n",
      "\n",
      "episode 5, policy loss 0.33383920788764954\n",
      "\n",
      "episode 6, policy loss 0.22008450329303741\n",
      "\n",
      "episode 7, policy loss 0.2863263189792633\n",
      "\n",
      "episode 8, policy loss 0.34349697828292847\n",
      "\n",
      "episode 9, policy loss 0.29048869013786316\n",
      "\n",
      "episode 10, policy loss 0.30906301736831665\n",
      "\n",
      "episode 11, policy loss 0.16995401680469513\n",
      "\n",
      "episode 12, policy loss 0.3519775867462158\n",
      "\n",
      "episode 13, policy loss 0.3320371210575104\n",
      "\n",
      "episode 14, policy loss 0.22355565428733826\n",
      "\n",
      "episode 15, policy loss 0.38340356945991516\n",
      "\n",
      "episode 16, policy loss 0.3279324471950531\n",
      "\n",
      "Policy train loss in epoch 2:0.29708417039364576\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.21970123052597046\n",
      "\n",
      "episode 2, policy loss 0.3725139796733856\n",
      "\n",
      "episode 3, policy loss 0.22173592448234558\n",
      "\n",
      "episode 4, policy loss 0.32925549149513245\n",
      "\n",
      "episode 5, policy loss 0.3497883975505829\n",
      "\n",
      "episode 6, policy loss 0.22249023616313934\n",
      "\n",
      "episode 7, policy loss 0.31814417243003845\n",
      "\n",
      "episode 8, policy loss 0.16971905529499054\n",
      "\n",
      "episode 9, policy loss 0.25595417618751526\n",
      "\n",
      "episode 10, policy loss 0.38366326689720154\n",
      "\n",
      "episode 11, policy loss 0.2886403501033783\n",
      "\n",
      "episode 12, policy loss 0.3434640169143677\n",
      "\n",
      "episode 13, policy loss 0.3277663588523865\n",
      "\n",
      "episode 14, policy loss 0.3311261236667633\n",
      "\n",
      "episode 15, policy loss 0.310169517993927\n",
      "\n",
      "episode 16, policy loss 0.2832407057285309\n",
      "\n",
      "Policy train loss in epoch 3:0.2954608127474785\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.20711775124073029\n",
      "\n",
      "episode 2, val func loss 0.18367139995098114\n",
      "\n",
      "episode 3, val func loss 0.18763351440429688\n",
      "\n",
      "episode 4, val func loss 0.15519188344478607\n",
      "\n",
      "episode 5, val func loss 0.17246286571025848\n",
      "\n",
      "episode 6, val func loss 0.15428192913532257\n",
      "\n",
      "episode 7, val func loss 0.174348384141922\n",
      "\n",
      "episode 8, val func loss 0.16858015954494476\n",
      "\n",
      "episode 9, val func loss 0.16495855152606964\n",
      "\n",
      "episode 10, val func loss 0.1704898476600647\n",
      "\n",
      "episode 11, val func loss 0.15577642619609833\n",
      "\n",
      "episode 12, val func loss 0.18670378625392914\n",
      "\n",
      "episode 13, val func loss 0.1988128274679184\n",
      "\n",
      "episode 14, val func loss 0.15091021358966827\n",
      "\n",
      "episode 15, val func loss 0.14988653361797333\n",
      "\n",
      "episode 16, val func loss 0.16440574824810028\n",
      "\n",
      "Val func train loss in epoch 0:0.17157698888331652\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18252041935920715\n",
      "\n",
      "episode 2, val func loss 0.14997252821922302\n",
      "\n",
      "episode 3, val func loss 0.16584548354148865\n",
      "\n",
      "episode 4, val func loss 0.1458342969417572\n",
      "\n",
      "episode 5, val func loss 0.17102380096912384\n",
      "\n",
      "episode 6, val func loss 0.17202679812908173\n",
      "\n",
      "episode 7, val func loss 0.1749345362186432\n",
      "\n",
      "episode 8, val func loss 0.19700779020786285\n",
      "\n",
      "episode 9, val func loss 0.19694030284881592\n",
      "\n",
      "episode 10, val func loss 0.20888873934745789\n",
      "\n",
      "episode 11, val func loss 0.14965398609638214\n",
      "\n",
      "episode 12, val func loss 0.18505072593688965\n",
      "\n",
      "episode 13, val func loss 0.1489906907081604\n",
      "\n",
      "episode 14, val func loss 0.16629953682422638\n",
      "\n",
      "episode 15, val func loss 0.1755794882774353\n",
      "\n",
      "episode 16, val func loss 0.15187913179397583\n",
      "\n",
      "Val func train loss in epoch 1:0.1714030159637332\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.15166980028152466\n",
      "\n",
      "episode 2, val func loss 0.14987853169441223\n",
      "\n",
      "episode 3, val func loss 0.17071279883384705\n",
      "\n",
      "episode 4, val func loss 0.18409372866153717\n",
      "\n",
      "episode 5, val func loss 0.14907662570476532\n",
      "\n",
      "episode 6, val func loss 0.17456884682178497\n",
      "\n",
      "episode 7, val func loss 0.16581326723098755\n",
      "\n",
      "episode 8, val func loss 0.14817418158054352\n",
      "\n",
      "episode 9, val func loss 0.17055626213550568\n",
      "\n",
      "episode 10, val func loss 0.19561709463596344\n",
      "\n",
      "episode 11, val func loss 0.17560745775699615\n",
      "\n",
      "episode 12, val func loss 0.14893919229507446\n",
      "\n",
      "episode 13, val func loss 0.2045315057039261\n",
      "\n",
      "episode 14, val func loss 0.18501035869121552\n",
      "\n",
      "episode 15, val func loss 0.1679934412240982\n",
      "\n",
      "episode 16, val func loss 0.19084163010120392\n",
      "\n",
      "Val func train loss in epoch 2:0.17081779520958662\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.16528473794460297\n",
      "\n",
      "episode 2, val func loss 0.1804099678993225\n",
      "\n",
      "episode 3, val func loss 0.14859209954738617\n",
      "\n",
      "episode 4, val func loss 0.16541700065135956\n",
      "\n",
      "episode 5, val func loss 0.14781858026981354\n",
      "\n",
      "episode 6, val func loss 0.1988433450460434\n",
      "\n",
      "episode 7, val func loss 0.14741219580173492\n",
      "\n",
      "episode 8, val func loss 0.18009082973003387\n",
      "\n",
      "episode 9, val func loss 0.18396444618701935\n",
      "\n",
      "episode 10, val func loss 0.18466174602508545\n",
      "\n",
      "episode 11, val func loss 0.14784342050552368\n",
      "\n",
      "episode 12, val func loss 0.20873571932315826\n",
      "\n",
      "episode 13, val func loss 0.15253956615924835\n",
      "\n",
      "episode 14, val func loss 0.17487387359142303\n",
      "\n",
      "episode 15, val func loss 0.1716078221797943\n",
      "\n",
      "episode 16, val func loss 0.19537118077278137\n",
      "\n",
      "Val func train loss in epoch 3:0.17209165822714567\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.16453249752521515\n",
      "\n",
      "episode 2, val func loss 0.16910420358181\n",
      "\n",
      "episode 3, val func loss 0.19586364924907684\n",
      "\n",
      "episode 4, val func loss 0.1738213300704956\n",
      "\n",
      "episode 5, val func loss 0.14858940243721008\n",
      "\n",
      "episode 6, val func loss 0.15295501053333282\n",
      "\n",
      "episode 7, val func loss 0.14928679168224335\n",
      "\n",
      "episode 8, val func loss 0.1674705445766449\n",
      "\n",
      "episode 9, val func loss 0.17077626287937164\n",
      "\n",
      "episode 10, val func loss 0.1941247284412384\n",
      "\n",
      "episode 11, val func loss 0.18379740417003632\n",
      "\n",
      "episode 12, val func loss 0.17397719621658325\n",
      "\n",
      "episode 13, val func loss 0.1891442984342575\n",
      "\n",
      "episode 14, val func loss 0.15040859580039978\n",
      "\n",
      "episode 15, val func loss 0.20747123658657074\n",
      "\n",
      "episode 16, val func loss 0.15021590888500214\n",
      "\n",
      "Val func train loss in epoch 4:0.17134619131684303\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1815636157989502\n",
      "\n",
      "episode 2, val func loss 0.17378853261470795\n",
      "\n",
      "episode 3, val func loss 0.19632719457149506\n",
      "\n",
      "episode 4, val func loss 0.15229155123233795\n",
      "\n",
      "episode 5, val func loss 0.14849717915058136\n",
      "\n",
      "episode 6, val func loss 0.17408856749534607\n",
      "\n",
      "episode 7, val func loss 0.16781912744045258\n",
      "\n",
      "episode 8, val func loss 0.18477320671081543\n",
      "\n",
      "episode 9, val func loss 0.19692033529281616\n",
      "\n",
      "episode 10, val func loss 0.15298660099506378\n",
      "\n",
      "episode 11, val func loss 0.20945681631565094\n",
      "\n",
      "episode 12, val func loss 0.16973885893821716\n",
      "\n",
      "episode 13, val func loss 0.14814965426921844\n",
      "\n",
      "episode 14, val func loss 0.1633751094341278\n",
      "\n",
      "episode 15, val func loss 0.17051225900650024\n",
      "\n",
      "episode 16, val func loss 0.1471448391675949\n",
      "\n",
      "Val func train loss in epoch 5:0.17108959052711725\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18293598294258118\n",
      "\n",
      "episode 2, val func loss 0.19640105962753296\n",
      "\n",
      "episode 3, val func loss 0.1926693320274353\n",
      "\n",
      "episode 4, val func loss 0.14940068125724792\n",
      "\n",
      "episode 5, val func loss 0.15143531560897827\n",
      "\n",
      "episode 6, val func loss 0.17135575413703918\n",
      "\n",
      "episode 7, val func loss 0.17757652699947357\n",
      "\n",
      "episode 8, val func loss 0.20448502898216248\n",
      "\n",
      "episode 9, val func loss 0.17630311846733093\n",
      "\n",
      "episode 10, val func loss 0.16478364169597626\n",
      "\n",
      "episode 11, val func loss 0.18251003324985504\n",
      "\n",
      "episode 12, val func loss 0.17326878011226654\n",
      "\n",
      "episode 13, val func loss 0.14634756743907928\n",
      "\n",
      "episode 14, val func loss 0.14606210589408875\n",
      "\n",
      "episode 15, val func loss 0.16744494438171387\n",
      "\n",
      "episode 16, val func loss 0.14716283977031708\n",
      "\n",
      "Val func train loss in epoch 6:0.1706339195370674\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18474015593528748\n",
      "\n",
      "episode 2, val func loss 0.16507761180400848\n",
      "\n",
      "episode 3, val func loss 0.19536031782627106\n",
      "\n",
      "episode 4, val func loss 0.1457907110452652\n",
      "\n",
      "episode 5, val func loss 0.16797828674316406\n",
      "\n",
      "episode 6, val func loss 0.15620163083076477\n",
      "\n",
      "episode 7, val func loss 0.19547238945960999\n",
      "\n",
      "episode 8, val func loss 0.18319514393806458\n",
      "\n",
      "episode 9, val func loss 0.1488678753376007\n",
      "\n",
      "episode 10, val func loss 0.20432688295841217\n",
      "\n",
      "episode 11, val func loss 0.14786982536315918\n",
      "\n",
      "episode 12, val func loss 0.16997618973255157\n",
      "\n",
      "episode 13, val func loss 0.17501942813396454\n",
      "\n",
      "episode 14, val func loss 0.1540653258562088\n",
      "\n",
      "episode 15, val func loss 0.17332665622234344\n",
      "\n",
      "episode 16, val func loss 0.17963027954101562\n",
      "\n",
      "Val func train loss in epoch 7:0.17168116942048073\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.18213309347629547\n",
      "\n",
      "episode 2, val func loss 0.2072550356388092\n",
      "\n",
      "episode 3, val func loss 0.16874799132347107\n",
      "\n",
      "episode 4, val func loss 0.17658723890781403\n",
      "\n",
      "episode 5, val func loss 0.14840887486934662\n",
      "\n",
      "episode 6, val func loss 0.15252982079982758\n",
      "\n",
      "episode 7, val func loss 0.1969062238931656\n",
      "\n",
      "episode 8, val func loss 0.14794045686721802\n",
      "\n",
      "episode 9, val func loss 0.14667895436286926\n",
      "\n",
      "episode 10, val func loss 0.16431689262390137\n",
      "\n",
      "episode 11, val func loss 0.17130133509635925\n",
      "\n",
      "episode 12, val func loss 0.16703274846076965\n",
      "\n",
      "episode 13, val func loss 0.15052594244480133\n",
      "\n",
      "episode 14, val func loss 0.17599555850028992\n",
      "\n",
      "episode 15, val func loss 0.18531222641468048\n",
      "\n",
      "episode 16, val func loss 0.19641368091106415\n",
      "\n",
      "Val func train loss in epoch 8:0.1711303796619177\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17772012948989868\n",
      "\n",
      "episode 2, val func loss 0.14791102707386017\n",
      "\n",
      "episode 3, val func loss 0.1834903061389923\n",
      "\n",
      "episode 4, val func loss 0.1850431114435196\n",
      "\n",
      "episode 5, val func loss 0.16453158855438232\n",
      "\n",
      "episode 6, val func loss 0.14866776764392853\n",
      "\n",
      "episode 7, val func loss 0.20889942348003387\n",
      "\n",
      "episode 8, val func loss 0.16647952795028687\n",
      "\n",
      "episode 9, val func loss 0.1945396512746811\n",
      "\n",
      "episode 10, val func loss 0.14618007838726044\n",
      "\n",
      "episode 11, val func loss 0.15139493346214294\n",
      "\n",
      "episode 12, val func loss 0.15319187939167023\n",
      "\n",
      "episode 13, val func loss 0.17806662619113922\n",
      "\n",
      "episode 14, val func loss 0.1728285700082779\n",
      "\n",
      "episode 15, val func loss 0.19517946243286133\n",
      "\n",
      "episode 16, val func loss 0.17081567645072937\n",
      "\n",
      "Val func train loss in epoch 9:0.17155873496085405\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18400679528713226\n",
      "\n",
      "episode 2, val func loss 0.1467897742986679\n",
      "\n",
      "episode 3, val func loss 0.15580442547798157\n",
      "\n",
      "episode 4, val func loss 0.16605301201343536\n",
      "\n",
      "episode 5, val func loss 0.17409129440784454\n",
      "\n",
      "episode 6, val func loss 0.14775978028774261\n",
      "\n",
      "episode 7, val func loss 0.16918635368347168\n",
      "\n",
      "episode 8, val func loss 0.18541283905506134\n",
      "\n",
      "episode 9, val func loss 0.1951662003993988\n",
      "\n",
      "episode 10, val func loss 0.14549380540847778\n",
      "\n",
      "episode 11, val func loss 0.19639869034290314\n",
      "\n",
      "episode 12, val func loss 0.17400699853897095\n",
      "\n",
      "episode 13, val func loss 0.16705173254013062\n",
      "\n",
      "episode 14, val func loss 0.20933856070041656\n",
      "\n",
      "episode 15, val func loss 0.15289227664470673\n",
      "\n",
      "episode 16, val func loss 0.17358367145061493\n",
      "\n",
      "Val func train loss in epoch 10:0.1714397631585598\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.15297821164131165\n",
      "\n",
      "episode 2, val func loss 0.1520417034626007\n",
      "\n",
      "episode 3, val func loss 0.15445595979690552\n",
      "\n",
      "episode 4, val func loss 0.2092503160238266\n",
      "\n",
      "episode 5, val func loss 0.14832575619220734\n",
      "\n",
      "episode 6, val func loss 0.19469764828681946\n",
      "\n",
      "episode 7, val func loss 0.17141970992088318\n",
      "\n",
      "episode 8, val func loss 0.16988329589366913\n",
      "\n",
      "episode 9, val func loss 0.16434979438781738\n",
      "\n",
      "episode 10, val func loss 0.14917410910129547\n",
      "\n",
      "episode 11, val func loss 0.1847686767578125\n",
      "\n",
      "episode 12, val func loss 0.17551717162132263\n",
      "\n",
      "episode 13, val func loss 0.17507976293563843\n",
      "\n",
      "episode 14, val func loss 0.16706568002700806\n",
      "\n",
      "episode 15, val func loss 0.18612772226333618\n",
      "\n",
      "episode 16, val func loss 0.19472730159759521\n",
      "\n",
      "Val func train loss in epoch 11:0.1718664262443781\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.194912850856781\n",
      "\n",
      "episode 2, val func loss 0.14907434582710266\n",
      "\n",
      "episode 3, val func loss 0.2083640992641449\n",
      "\n",
      "episode 4, val func loss 0.1665252298116684\n",
      "\n",
      "episode 5, val func loss 0.171102374792099\n",
      "\n",
      "episode 6, val func loss 0.18567915260791779\n",
      "\n",
      "episode 7, val func loss 0.19567598402500153\n",
      "\n",
      "episode 8, val func loss 0.17520824074745178\n",
      "\n",
      "episode 9, val func loss 0.1846337914466858\n",
      "\n",
      "episode 10, val func loss 0.14819101989269257\n",
      "\n",
      "episode 11, val func loss 0.1708727478981018\n",
      "\n",
      "episode 12, val func loss 0.1454354226589203\n",
      "\n",
      "episode 13, val func loss 0.16469885408878326\n",
      "\n",
      "episode 14, val func loss 0.17484934628009796\n",
      "\n",
      "episode 15, val func loss 0.1500137895345688\n",
      "\n",
      "episode 16, val func loss 0.15177540481090546\n",
      "\n",
      "Val func train loss in epoch 12:0.17106329090893269\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.20812831819057465\n",
      "\n",
      "episode 2, val func loss 0.17125153541564941\n",
      "\n",
      "episode 3, val func loss 0.1487130969762802\n",
      "\n",
      "episode 4, val func loss 0.17500950396060944\n",
      "\n",
      "episode 5, val func loss 0.16480526328086853\n",
      "\n",
      "episode 6, val func loss 0.15093056857585907\n",
      "\n",
      "episode 7, val func loss 0.197163924574852\n",
      "\n",
      "episode 8, val func loss 0.1486513614654541\n",
      "\n",
      "episode 9, val func loss 0.1535654366016388\n",
      "\n",
      "episode 10, val func loss 0.14521999657154083\n",
      "\n",
      "episode 11, val func loss 0.1940430849790573\n",
      "\n",
      "episode 12, val func loss 0.18543322384357452\n",
      "\n",
      "episode 13, val func loss 0.17419582605361938\n",
      "\n",
      "episode 14, val func loss 0.16701360046863556\n",
      "\n",
      "episode 15, val func loss 0.1725223958492279\n",
      "\n",
      "episode 16, val func loss 0.18392036855220795\n",
      "\n",
      "Val func train loss in epoch 13:0.1712854690849781\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.16458462178707123\n",
      "\n",
      "episode 2, val func loss 0.19600729644298553\n",
      "\n",
      "episode 3, val func loss 0.17397035658359528\n",
      "\n",
      "episode 4, val func loss 0.19308951497077942\n",
      "\n",
      "episode 5, val func loss 0.15281961858272552\n",
      "\n",
      "episode 6, val func loss 0.1754641830921173\n",
      "\n",
      "episode 7, val func loss 0.20660197734832764\n",
      "\n",
      "episode 8, val func loss 0.1699046939611435\n",
      "\n",
      "episode 9, val func loss 0.15263168513774872\n",
      "\n",
      "episode 10, val func loss 0.18343324959278107\n",
      "\n",
      "episode 11, val func loss 0.1834382563829422\n",
      "\n",
      "episode 12, val func loss 0.14880236983299255\n",
      "\n",
      "episode 13, val func loss 0.17066402733325958\n",
      "\n",
      "episode 14, val func loss 0.1475386768579483\n",
      "\n",
      "episode 15, val func loss 0.1482265144586563\n",
      "\n",
      "episode 16, val func loss 0.16976960003376007\n",
      "\n",
      "Val func train loss in epoch 14:0.17105916514992714\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.21027278900146484\n",
      "\n",
      "episode 2, val func loss 0.19692854583263397\n",
      "\n",
      "episode 3, val func loss 0.19734051823616028\n",
      "\n",
      "episode 4, val func loss 0.17525038123130798\n",
      "\n",
      "episode 5, val func loss 0.14766934514045715\n",
      "\n",
      "episode 6, val func loss 0.15205951035022736\n",
      "\n",
      "episode 7, val func loss 0.15222050249576569\n",
      "\n",
      "episode 8, val func loss 0.1647457331418991\n",
      "\n",
      "episode 9, val func loss 0.16769081354141235\n",
      "\n",
      "episode 10, val func loss 0.17151682078838348\n",
      "\n",
      "episode 11, val func loss 0.14926809072494507\n",
      "\n",
      "episode 12, val func loss 0.1697462797164917\n",
      "\n",
      "episode 13, val func loss 0.17741890251636505\n",
      "\n",
      "episode 14, val func loss 0.14775404334068298\n",
      "\n",
      "episode 15, val func loss 0.18478737771511078\n",
      "\n",
      "episode 16, val func loss 0.18503685295581818\n",
      "\n",
      "Val func train loss in epoch 15:0.17185665667057037\n",
      "***********************TIME WAS 4.98524386882782 min*****************************\n",
      "\n",
      "**********************ROUND 101 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.054914217442274094\n",
      "\n",
      "episode 2, policy loss 0.057012662291526794\n",
      "\n",
      "episode 3, policy loss 0.04195907711982727\n",
      "\n",
      "episode 4, policy loss 0.034501660615205765\n",
      "\n",
      "episode 5, policy loss 0.02145441807806492\n",
      "\n",
      "episode 6, policy loss -0.015817444771528244\n",
      "\n",
      "episode 7, policy loss -0.00014271234977059066\n",
      "\n",
      "episode 8, policy loss 0.03783350810408592\n",
      "\n",
      "episode 9, policy loss 0.044179659336805344\n",
      "\n",
      "episode 10, policy loss 0.03150148689746857\n",
      "\n",
      "episode 11, policy loss 0.06091821938753128\n",
      "\n",
      "episode 12, policy loss 0.052946094423532486\n",
      "\n",
      "episode 13, policy loss 0.03641790896654129\n",
      "\n",
      "episode 14, policy loss 0.08090619742870331\n",
      "\n",
      "episode 15, policy loss 0.05378399044275284\n",
      "\n",
      "episode 16, policy loss 0.03636365383863449\n",
      "\n",
      "Policy train loss in epoch 0:0.03929578732822847\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.07801488786935806\n",
      "\n",
      "episode 2, policy loss 0.03668687492609024\n",
      "\n",
      "episode 3, policy loss 0.05643119290471077\n",
      "\n",
      "episode 4, policy loss 0.046858400106430054\n",
      "\n",
      "episode 5, policy loss 0.04049765318632126\n",
      "\n",
      "episode 6, policy loss 0.036355506628751755\n",
      "\n",
      "episode 7, policy loss 0.05369921028614044\n",
      "\n",
      "episode 8, policy loss 0.0479748398065567\n",
      "\n",
      "episode 9, policy loss 0.03479849547147751\n",
      "\n",
      "episode 10, policy loss 0.016010677441954613\n",
      "\n",
      "episode 11, policy loss 0.047642868012189865\n",
      "\n",
      "episode 12, policy loss 0.029197316616773605\n",
      "\n",
      "episode 13, policy loss -0.0010946692200377584\n",
      "\n",
      "episode 14, policy loss 0.030844954773783684\n",
      "\n",
      "episode 15, policy loss -0.02253671921789646\n",
      "\n",
      "episode 16, policy loss 0.048225440084934235\n",
      "\n",
      "Policy train loss in epoch 1:0.03622543310484616\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.03658926114439964\n",
      "\n",
      "episode 2, policy loss 0.07773410528898239\n",
      "\n",
      "episode 3, policy loss 0.03482696786522865\n",
      "\n",
      "episode 4, policy loss 0.04648352041840553\n",
      "\n",
      "episode 5, policy loss 0.04560064151883125\n",
      "\n",
      "episode 6, policy loss 0.031680457293987274\n",
      "\n",
      "episode 7, policy loss -0.0010298315901309252\n",
      "\n",
      "episode 8, policy loss 0.03837880864739418\n",
      "\n",
      "episode 9, policy loss 0.04567725211381912\n",
      "\n",
      "episode 10, policy loss 0.033308517187833786\n",
      "\n",
      "episode 11, policy loss 0.04350202530622482\n",
      "\n",
      "episode 12, policy loss 0.05563350394368172\n",
      "\n",
      "episode 13, policy loss 0.02857142686843872\n",
      "\n",
      "episode 14, policy loss 0.04994983226060867\n",
      "\n",
      "episode 15, policy loss 0.01509320829063654\n",
      "\n",
      "episode 16, policy loss -0.023564806208014488\n",
      "\n",
      "Policy train loss in epoch 2:0.03490218064689543\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.049770183861255646\n",
      "\n",
      "episode 2, policy loss 0.03506646305322647\n",
      "\n",
      "episode 3, policy loss 0.07722881436347961\n",
      "\n",
      "episode 4, policy loss 0.04467809945344925\n",
      "\n",
      "episode 5, policy loss 0.0457586795091629\n",
      "\n",
      "episode 6, policy loss 0.028039870783686638\n",
      "\n",
      "episode 7, policy loss 0.03132084757089615\n",
      "\n",
      "episode 8, policy loss 0.034040190279483795\n",
      "\n",
      "episode 9, policy loss 0.04575720056891441\n",
      "\n",
      "episode 10, policy loss -0.0017735218862071633\n",
      "\n",
      "episode 11, policy loss 0.014831461943686008\n",
      "\n",
      "episode 12, policy loss 0.04642798751592636\n",
      "\n",
      "episode 13, policy loss 0.05483270436525345\n",
      "\n",
      "episode 14, policy loss 0.03247978910803795\n",
      "\n",
      "episode 15, policy loss -0.023356758058071136\n",
      "\n",
      "episode 16, policy loss 0.03757331147789955\n",
      "\n",
      "Policy train loss in epoch 3:0.034542207744379994\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19182051718235016\n",
      "\n",
      "episode 2, val func loss 0.17739072442054749\n",
      "\n",
      "episode 3, val func loss 0.16911792755126953\n",
      "\n",
      "episode 4, val func loss 0.1646314263343811\n",
      "\n",
      "episode 5, val func loss 0.1632600873708725\n",
      "\n",
      "episode 6, val func loss 0.17802496254444122\n",
      "\n",
      "episode 7, val func loss 0.16241711378097534\n",
      "\n",
      "episode 8, val func loss 0.1649564951658249\n",
      "\n",
      "episode 9, val func loss 0.15844567120075226\n",
      "\n",
      "episode 10, val func loss 0.15088887512683868\n",
      "\n",
      "episode 11, val func loss 0.18016454577445984\n",
      "\n",
      "episode 12, val func loss 0.19542120397090912\n",
      "\n",
      "episode 13, val func loss 0.1594647765159607\n",
      "\n",
      "episode 14, val func loss 0.15942516922950745\n",
      "\n",
      "episode 15, val func loss 0.16183263063430786\n",
      "\n",
      "episode 16, val func loss 0.18315257132053375\n",
      "\n",
      "Val func train loss in epoch 0:0.17002591863274574\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18062977492809296\n",
      "\n",
      "episode 2, val func loss 0.1621350198984146\n",
      "\n",
      "episode 3, val func loss 0.17658503353595734\n",
      "\n",
      "episode 4, val func loss 0.17569991946220398\n",
      "\n",
      "episode 5, val func loss 0.15538711845874786\n",
      "\n",
      "episode 6, val func loss 0.18242962658405304\n",
      "\n",
      "episode 7, val func loss 0.15900138020515442\n",
      "\n",
      "episode 8, val func loss 0.16187435388565063\n",
      "\n",
      "episode 9, val func loss 0.19336162507534027\n",
      "\n",
      "episode 10, val func loss 0.1950034648180008\n",
      "\n",
      "episode 11, val func loss 0.1643379032611847\n",
      "\n",
      "episode 12, val func loss 0.15850865840911865\n",
      "\n",
      "episode 13, val func loss 0.1479441374540329\n",
      "\n",
      "episode 14, val func loss 0.16260366141796112\n",
      "\n",
      "episode 15, val func loss 0.16528601944446564\n",
      "\n",
      "episode 16, val func loss 0.16788889467716217\n",
      "\n",
      "Val func train loss in epoch 1:0.16929228696972132\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1592268943786621\n",
      "\n",
      "episode 2, val func loss 0.19440241158008575\n",
      "\n",
      "episode 3, val func loss 0.1630426049232483\n",
      "\n",
      "episode 4, val func loss 0.17983213067054749\n",
      "\n",
      "episode 5, val func loss 0.14870712161064148\n",
      "\n",
      "episode 6, val func loss 0.16850537061691284\n",
      "\n",
      "episode 7, val func loss 0.1735295206308365\n",
      "\n",
      "episode 8, val func loss 0.16268232464790344\n",
      "\n",
      "episode 9, val func loss 0.16363875567913055\n",
      "\n",
      "episode 10, val func loss 0.18049754202365875\n",
      "\n",
      "episode 11, val func loss 0.16178222000598907\n",
      "\n",
      "episode 12, val func loss 0.19690564274787903\n",
      "\n",
      "episode 13, val func loss 0.1650659292936325\n",
      "\n",
      "episode 14, val func loss 0.1783701628446579\n",
      "\n",
      "episode 15, val func loss 0.1587754637002945\n",
      "\n",
      "episode 16, val func loss 0.15871186554431915\n",
      "\n",
      "Val func train loss in epoch 2:0.16960474755614996\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.164034903049469\n",
      "\n",
      "episode 2, val func loss 0.16017092764377594\n",
      "\n",
      "episode 3, val func loss 0.17506253719329834\n",
      "\n",
      "episode 4, val func loss 0.18052329123020172\n",
      "\n",
      "episode 5, val func loss 0.18046869337558746\n",
      "\n",
      "episode 6, val func loss 0.16101665794849396\n",
      "\n",
      "episode 7, val func loss 0.15868200361728668\n",
      "\n",
      "episode 8, val func loss 0.16414637863636017\n",
      "\n",
      "episode 9, val func loss 0.16305066645145416\n",
      "\n",
      "episode 10, val func loss 0.16378210484981537\n",
      "\n",
      "episode 11, val func loss 0.19473975896835327\n",
      "\n",
      "episode 12, val func loss 0.15000298619270325\n",
      "\n",
      "episode 13, val func loss 0.17659446597099304\n",
      "\n",
      "episode 14, val func loss 0.19270215928554535\n",
      "\n",
      "episode 15, val func loss 0.15717509388923645\n",
      "\n",
      "episode 16, val func loss 0.1640707105398178\n",
      "\n",
      "Val func train loss in epoch 3:0.1691389586776495\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17559084296226501\n",
      "\n",
      "episode 2, val func loss 0.1500784307718277\n",
      "\n",
      "episode 3, val func loss 0.16098451614379883\n",
      "\n",
      "episode 4, val func loss 0.17879322171211243\n",
      "\n",
      "episode 5, val func loss 0.16462361812591553\n",
      "\n",
      "episode 6, val func loss 0.1864529550075531\n",
      "\n",
      "episode 7, val func loss 0.16474737226963043\n",
      "\n",
      "episode 8, val func loss 0.15920290350914001\n",
      "\n",
      "episode 9, val func loss 0.19699698686599731\n",
      "\n",
      "episode 10, val func loss 0.16302074491977692\n",
      "\n",
      "episode 11, val func loss 0.16237664222717285\n",
      "\n",
      "episode 12, val func loss 0.16580575704574585\n",
      "\n",
      "episode 13, val func loss 0.15545029938220978\n",
      "\n",
      "episode 14, val func loss 0.1744709461927414\n",
      "\n",
      "episode 15, val func loss 0.1592453122138977\n",
      "\n",
      "episode 16, val func loss 0.1942674070596695\n",
      "\n",
      "Val func train loss in epoch 4:0.1695067472755909\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.16145746409893036\n",
      "\n",
      "episode 2, val func loss 0.164740651845932\n",
      "\n",
      "episode 3, val func loss 0.15865260362625122\n",
      "\n",
      "episode 4, val func loss 0.17911426723003387\n",
      "\n",
      "episode 5, val func loss 0.16484692692756653\n",
      "\n",
      "episode 6, val func loss 0.16130679845809937\n",
      "\n",
      "episode 7, val func loss 0.17610423266887665\n",
      "\n",
      "episode 8, val func loss 0.18266110122203827\n",
      "\n",
      "episode 9, val func loss 0.15821504592895508\n",
      "\n",
      "episode 10, val func loss 0.16184276342391968\n",
      "\n",
      "episode 11, val func loss 0.15770448744297028\n",
      "\n",
      "episode 12, val func loss 0.18058808147907257\n",
      "\n",
      "episode 13, val func loss 0.16709274053573608\n",
      "\n",
      "episode 14, val func loss 0.1949574053287506\n",
      "\n",
      "episode 15, val func loss 0.19178707897663116\n",
      "\n",
      "episode 16, val func loss 0.14935514330863953\n",
      "\n",
      "Val func train loss in epoch 5:0.1694016745314002\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1625133603811264\n",
      "\n",
      "episode 2, val func loss 0.1754550188779831\n",
      "\n",
      "episode 3, val func loss 0.16315889358520508\n",
      "\n",
      "episode 4, val func loss 0.18342356383800507\n",
      "\n",
      "episode 5, val func loss 0.1644720435142517\n",
      "\n",
      "episode 6, val func loss 0.19473110139369965\n",
      "\n",
      "episode 7, val func loss 0.18013739585876465\n",
      "\n",
      "episode 8, val func loss 0.14972738921642303\n",
      "\n",
      "episode 9, val func loss 0.15877273678779602\n",
      "\n",
      "episode 10, val func loss 0.16718141734600067\n",
      "\n",
      "episode 11, val func loss 0.19304148852825165\n",
      "\n",
      "episode 12, val func loss 0.16251172125339508\n",
      "\n",
      "episode 13, val func loss 0.15715305507183075\n",
      "\n",
      "episode 14, val func loss 0.16360114514827728\n",
      "\n",
      "episode 15, val func loss 0.17616648972034454\n",
      "\n",
      "episode 16, val func loss 0.15958751738071442\n",
      "\n",
      "Val func train loss in epoch 6:0.16947714611887932\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.16179966926574707\n",
      "\n",
      "episode 2, val func loss 0.19557397067546844\n",
      "\n",
      "episode 3, val func loss 0.19248796999454498\n",
      "\n",
      "episode 4, val func loss 0.16713625192642212\n",
      "\n",
      "episode 5, val func loss 0.1596527397632599\n",
      "\n",
      "episode 6, val func loss 0.149855837225914\n",
      "\n",
      "episode 7, val func loss 0.1804591864347458\n",
      "\n",
      "episode 8, val func loss 0.16350680589675903\n",
      "\n",
      "episode 9, val func loss 0.17650753259658813\n",
      "\n",
      "episode 10, val func loss 0.1768425852060318\n",
      "\n",
      "episode 11, val func loss 0.16530705988407135\n",
      "\n",
      "episode 12, val func loss 0.15935122966766357\n",
      "\n",
      "episode 13, val func loss 0.1621975302696228\n",
      "\n",
      "episode 14, val func loss 0.18413907289505005\n",
      "\n",
      "episode 15, val func loss 0.163045734167099\n",
      "\n",
      "episode 16, val func loss 0.15859684348106384\n",
      "\n",
      "Val func train loss in epoch 7:0.16977875120937824\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16319672763347626\n",
      "\n",
      "episode 2, val func loss 0.1619240790605545\n",
      "\n",
      "episode 3, val func loss 0.16175492107868195\n",
      "\n",
      "episode 4, val func loss 0.19315914809703827\n",
      "\n",
      "episode 5, val func loss 0.17686520516872406\n",
      "\n",
      "episode 6, val func loss 0.19429142773151398\n",
      "\n",
      "episode 7, val func loss 0.16040323674678802\n",
      "\n",
      "episode 8, val func loss 0.14929205179214478\n",
      "\n",
      "episode 9, val func loss 0.18057172000408173\n",
      "\n",
      "episode 10, val func loss 0.1572810560464859\n",
      "\n",
      "episode 11, val func loss 0.1594599485397339\n",
      "\n",
      "episode 12, val func loss 0.18286091089248657\n",
      "\n",
      "episode 13, val func loss 0.16721245646476746\n",
      "\n",
      "episode 14, val func loss 0.16491739451885223\n",
      "\n",
      "episode 15, val func loss 0.1624819040298462\n",
      "\n",
      "episode 16, val func loss 0.17777124047279358\n",
      "\n",
      "Val func train loss in epoch 8:0.16959021426737309\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.15955357253551483\n",
      "\n",
      "episode 2, val func loss 0.16275708377361298\n",
      "\n",
      "episode 3, val func loss 0.15897251665592194\n",
      "\n",
      "episode 4, val func loss 0.1496814787387848\n",
      "\n",
      "episode 5, val func loss 0.1791301816701889\n",
      "\n",
      "episode 6, val func loss 0.1572108268737793\n",
      "\n",
      "episode 7, val func loss 0.17608265578746796\n",
      "\n",
      "episode 8, val func loss 0.1750531792640686\n",
      "\n",
      "episode 9, val func loss 0.16807760298252106\n",
      "\n",
      "episode 10, val func loss 0.18308685719966888\n",
      "\n",
      "episode 11, val func loss 0.16111350059509277\n",
      "\n",
      "episode 12, val func loss 0.19447949528694153\n",
      "\n",
      "episode 13, val func loss 0.1607704758644104\n",
      "\n",
      "episode 14, val func loss 0.16220176219940186\n",
      "\n",
      "episode 15, val func loss 0.19198451936244965\n",
      "\n",
      "episode 16, val func loss 0.15849170088768005\n",
      "\n",
      "Val func train loss in epoch 9:0.1686654631048441\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.16790008544921875\n",
      "\n",
      "episode 2, val func loss 0.18427716195583344\n",
      "\n",
      "episode 3, val func loss 0.15968897938728333\n",
      "\n",
      "episode 4, val func loss 0.17786914110183716\n",
      "\n",
      "episode 5, val func loss 0.15463700890541077\n",
      "\n",
      "episode 6, val func loss 0.16324187815189362\n",
      "\n",
      "episode 7, val func loss 0.16452693939208984\n",
      "\n",
      "episode 8, val func loss 0.17711615562438965\n",
      "\n",
      "episode 9, val func loss 0.19518983364105225\n",
      "\n",
      "episode 10, val func loss 0.18757124245166779\n",
      "\n",
      "episode 11, val func loss 0.16522829234600067\n",
      "\n",
      "episode 12, val func loss 0.15665486454963684\n",
      "\n",
      "episode 13, val func loss 0.1495538055896759\n",
      "\n",
      "episode 14, val func loss 0.16335570812225342\n",
      "\n",
      "episode 15, val func loss 0.1776725947856903\n",
      "\n",
      "episode 16, val func loss 0.16672717034816742\n",
      "\n",
      "Val func train loss in epoch 10:0.16945067886263132\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16313454508781433\n",
      "\n",
      "episode 2, val func loss 0.16134917736053467\n",
      "\n",
      "episode 3, val func loss 0.15001100301742554\n",
      "\n",
      "episode 4, val func loss 0.17691972851753235\n",
      "\n",
      "episode 5, val func loss 0.18268431723117828\n",
      "\n",
      "episode 6, val func loss 0.19401410222053528\n",
      "\n",
      "episode 7, val func loss 0.1601445972919464\n",
      "\n",
      "episode 8, val func loss 0.16930024325847626\n",
      "\n",
      "episode 9, val func loss 0.18298973143100739\n",
      "\n",
      "episode 10, val func loss 0.19330494105815887\n",
      "\n",
      "episode 11, val func loss 0.16366976499557495\n",
      "\n",
      "episode 12, val func loss 0.15854495763778687\n",
      "\n",
      "episode 13, val func loss 0.16285692155361176\n",
      "\n",
      "episode 14, val func loss 0.16710332036018372\n",
      "\n",
      "episode 15, val func loss 0.15901054441928864\n",
      "\n",
      "episode 16, val func loss 0.1764756143093109\n",
      "\n",
      "Val func train loss in epoch 11:0.1700945943593979\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17949707806110382\n",
      "\n",
      "episode 2, val func loss 0.16208197176456451\n",
      "\n",
      "episode 3, val func loss 0.17657408118247986\n",
      "\n",
      "episode 4, val func loss 0.16505390405654907\n",
      "\n",
      "episode 5, val func loss 0.16350820660591125\n",
      "\n",
      "episode 6, val func loss 0.167523592710495\n",
      "\n",
      "episode 7, val func loss 0.16324402391910553\n",
      "\n",
      "episode 8, val func loss 0.15886931121349335\n",
      "\n",
      "episode 9, val func loss 0.19388651847839355\n",
      "\n",
      "episode 10, val func loss 0.19591191411018372\n",
      "\n",
      "episode 11, val func loss 0.18262015283107758\n",
      "\n",
      "episode 12, val func loss 0.162770614027977\n",
      "\n",
      "episode 13, val func loss 0.14916345477104187\n",
      "\n",
      "episode 14, val func loss 0.15673492848873138\n",
      "\n",
      "episode 15, val func loss 0.1602434664964676\n",
      "\n",
      "episode 16, val func loss 0.18067215383052826\n",
      "\n",
      "Val func train loss in epoch 12:0.16989721078425646\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19447281956672668\n",
      "\n",
      "episode 2, val func loss 0.17577068507671356\n",
      "\n",
      "episode 3, val func loss 0.16276288032531738\n",
      "\n",
      "episode 4, val func loss 0.18150141835212708\n",
      "\n",
      "episode 5, val func loss 0.16318106651306152\n",
      "\n",
      "episode 6, val func loss 0.14977000653743744\n",
      "\n",
      "episode 7, val func loss 0.16246938705444336\n",
      "\n",
      "episode 8, val func loss 0.1628168225288391\n",
      "\n",
      "episode 9, val func loss 0.18033857643604279\n",
      "\n",
      "episode 10, val func loss 0.15862303972244263\n",
      "\n",
      "episode 11, val func loss 0.1946200132369995\n",
      "\n",
      "episode 12, val func loss 0.16678635776042938\n",
      "\n",
      "episode 13, val func loss 0.1651238352060318\n",
      "\n",
      "episode 14, val func loss 0.17644716799259186\n",
      "\n",
      "episode 15, val func loss 0.15951284766197205\n",
      "\n",
      "episode 16, val func loss 0.15772239863872528\n",
      "\n",
      "Val func train loss in epoch 13:0.16949495766311884\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17992158234119415\n",
      "\n",
      "episode 2, val func loss 0.19432660937309265\n",
      "\n",
      "episode 3, val func loss 0.16303198039531708\n",
      "\n",
      "episode 4, val func loss 0.17766925692558289\n",
      "\n",
      "episode 5, val func loss 0.19398610293865204\n",
      "\n",
      "episode 6, val func loss 0.1843341737985611\n",
      "\n",
      "episode 7, val func loss 0.15879039466381073\n",
      "\n",
      "episode 8, val func loss 0.17425917088985443\n",
      "\n",
      "episode 9, val func loss 0.15900862216949463\n",
      "\n",
      "episode 10, val func loss 0.1671064794063568\n",
      "\n",
      "episode 11, val func loss 0.1493530571460724\n",
      "\n",
      "episode 12, val func loss 0.16121678054332733\n",
      "\n",
      "episode 13, val func loss 0.1658419519662857\n",
      "\n",
      "episode 14, val func loss 0.1635517030954361\n",
      "\n",
      "episode 15, val func loss 0.15954843163490295\n",
      "\n",
      "episode 16, val func loss 0.15675558149814606\n",
      "\n",
      "Val func train loss in epoch 14:0.16929386742413044\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1663842499256134\n",
      "\n",
      "episode 2, val func loss 0.16347435116767883\n",
      "\n",
      "episode 3, val func loss 0.16403169929981232\n",
      "\n",
      "episode 4, val func loss 0.16378912329673767\n",
      "\n",
      "episode 5, val func loss 0.1771085560321808\n",
      "\n",
      "episode 6, val func loss 0.1583676040172577\n",
      "\n",
      "episode 7, val func loss 0.19538983702659607\n",
      "\n",
      "episode 8, val func loss 0.15808047354221344\n",
      "\n",
      "episode 9, val func loss 0.18187083303928375\n",
      "\n",
      "episode 10, val func loss 0.17965590953826904\n",
      "\n",
      "episode 11, val func loss 0.1491960883140564\n",
      "\n",
      "episode 12, val func loss 0.19360418617725372\n",
      "\n",
      "episode 13, val func loss 0.1597573310136795\n",
      "\n",
      "episode 14, val func loss 0.1768369972705841\n",
      "\n",
      "episode 15, val func loss 0.16340598464012146\n",
      "\n",
      "episode 16, val func loss 0.16668875515460968\n",
      "\n",
      "Val func train loss in epoch 15:0.16985262371599674\n",
      "***********************TIME WAS 4.989157382647196 min*****************************\n",
      "\n",
      "**********************ROUND 102 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.04808497801423073\n",
      "\n",
      "episode 2, policy loss 0.06619524955749512\n",
      "\n",
      "episode 3, policy loss 0.03965980187058449\n",
      "\n",
      "episode 4, policy loss 0.07761228084564209\n",
      "\n",
      "episode 5, policy loss 0.09362004697322845\n",
      "\n",
      "episode 6, policy loss 0.05231986194849014\n",
      "\n",
      "episode 7, policy loss 0.07696831226348877\n",
      "\n",
      "episode 8, policy loss 0.03147042915225029\n",
      "\n",
      "episode 9, policy loss 0.07320936769247055\n",
      "\n",
      "episode 10, policy loss 0.018567616119980812\n",
      "\n",
      "episode 11, policy loss 0.03300193324685097\n",
      "\n",
      "episode 12, policy loss 0.05343056470155716\n",
      "\n",
      "episode 13, policy loss 0.1116817370057106\n",
      "\n",
      "episode 14, policy loss 0.08283058553934097\n",
      "\n",
      "episode 15, policy loss 0.014694069512188435\n",
      "\n",
      "episode 16, policy loss 0.0635690987110138\n",
      "\n",
      "Policy train loss in epoch 0:0.05855724582215771\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.07795117795467377\n",
      "\n",
      "episode 2, policy loss 0.03126693144440651\n",
      "\n",
      "episode 3, policy loss 0.03210384026169777\n",
      "\n",
      "episode 4, policy loss 0.07461082935333252\n",
      "\n",
      "episode 5, policy loss 0.06357526779174805\n",
      "\n",
      "episode 6, policy loss 0.03287925571203232\n",
      "\n",
      "episode 7, policy loss 0.09218364208936691\n",
      "\n",
      "episode 8, policy loss 0.015051566995680332\n",
      "\n",
      "episode 9, policy loss 0.015835683792829514\n",
      "\n",
      "episode 10, policy loss 0.10679604858160019\n",
      "\n",
      "episode 11, policy loss 0.07898097485303879\n",
      "\n",
      "episode 12, policy loss 0.05785638466477394\n",
      "\n",
      "episode 13, policy loss 0.04144926369190216\n",
      "\n",
      "episode 14, policy loss 0.05219061300158501\n",
      "\n",
      "episode 15, policy loss 0.07060965895652771\n",
      "\n",
      "episode 16, policy loss 0.05115411803126335\n",
      "\n",
      "Policy train loss in epoch 1:0.05590595357352868\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.013347785919904709\n",
      "\n",
      "episode 2, policy loss 0.031010791659355164\n",
      "\n",
      "episode 3, policy loss 0.0510052852332592\n",
      "\n",
      "episode 4, policy loss 0.015315012075006962\n",
      "\n",
      "episode 5, policy loss 0.06131242960691452\n",
      "\n",
      "episode 6, policy loss 0.07661645859479904\n",
      "\n",
      "episode 7, policy loss 0.07456007599830627\n",
      "\n",
      "episode 8, policy loss 0.07038845121860504\n",
      "\n",
      "episode 9, policy loss 0.1064295694231987\n",
      "\n",
      "episode 10, policy loss 0.032101184129714966\n",
      "\n",
      "episode 11, policy loss 0.05189455300569534\n",
      "\n",
      "episode 12, policy loss 0.04094190523028374\n",
      "\n",
      "episode 13, policy loss 0.05747542157769203\n",
      "\n",
      "episode 14, policy loss 0.077914297580719\n",
      "\n",
      "episode 15, policy loss 0.03079693578183651\n",
      "\n",
      "episode 16, policy loss 0.09070197492837906\n",
      "\n",
      "Policy train loss in epoch 2:0.05511325824772939\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.07057353854179382\n",
      "\n",
      "episode 2, policy loss 0.05250014364719391\n",
      "\n",
      "episode 3, policy loss 0.10651689767837524\n",
      "\n",
      "episode 4, policy loss 0.06174815446138382\n",
      "\n",
      "episode 5, policy loss 0.07781662046909332\n",
      "\n",
      "episode 6, policy loss 0.015781095251441002\n",
      "\n",
      "episode 7, policy loss 0.0141474399715662\n",
      "\n",
      "episode 8, policy loss 0.05664391443133354\n",
      "\n",
      "episode 9, policy loss 0.030356302857398987\n",
      "\n",
      "episode 10, policy loss 0.07424600422382355\n",
      "\n",
      "episode 11, policy loss 0.04079490527510643\n",
      "\n",
      "episode 12, policy loss 0.09055633097887039\n",
      "\n",
      "episode 13, policy loss 0.031864233314991\n",
      "\n",
      "episode 14, policy loss 0.05116558447480202\n",
      "\n",
      "episode 15, policy loss 0.030513331294059753\n",
      "\n",
      "episode 16, policy loss 0.076272152364254\n",
      "\n",
      "Policy train loss in epoch 3:0.055093540577217937\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.2168663740158081\n",
      "\n",
      "episode 2, val func loss 0.19763337075710297\n",
      "\n",
      "episode 3, val func loss 0.1742812842130661\n",
      "\n",
      "episode 4, val func loss 0.1801571249961853\n",
      "\n",
      "episode 5, val func loss 0.13901372253894806\n",
      "\n",
      "episode 6, val func loss 0.19069518148899078\n",
      "\n",
      "episode 7, val func loss 0.1972309648990631\n",
      "\n",
      "episode 8, val func loss 0.18841364979743958\n",
      "\n",
      "episode 9, val func loss 0.20247553288936615\n",
      "\n",
      "episode 10, val func loss 0.159744992852211\n",
      "\n",
      "episode 11, val func loss 0.15039180219173431\n",
      "\n",
      "episode 12, val func loss 0.1726735383272171\n",
      "\n",
      "episode 13, val func loss 0.1435200721025467\n",
      "\n",
      "episode 14, val func loss 0.16996987164020538\n",
      "\n",
      "episode 15, val func loss 0.1875981092453003\n",
      "\n",
      "episode 16, val func loss 0.16253581643104553\n",
      "\n",
      "Val func train loss in epoch 0:0.1770750880241394\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19197824597358704\n",
      "\n",
      "episode 2, val func loss 0.18881866335868835\n",
      "\n",
      "episode 3, val func loss 0.1813250035047531\n",
      "\n",
      "episode 4, val func loss 0.19797514379024506\n",
      "\n",
      "episode 5, val func loss 0.17175062000751495\n",
      "\n",
      "episode 6, val func loss 0.1388804167509079\n",
      "\n",
      "episode 7, val func loss 0.19864754378795624\n",
      "\n",
      "episode 8, val func loss 0.21745429933071136\n",
      "\n",
      "episode 9, val func loss 0.15719544887542725\n",
      "\n",
      "episode 10, val func loss 0.1912454068660736\n",
      "\n",
      "episode 11, val func loss 0.20386704802513123\n",
      "\n",
      "episode 12, val func loss 0.17700476944446564\n",
      "\n",
      "episode 13, val func loss 0.15941496193408966\n",
      "\n",
      "episode 14, val func loss 0.15103529393672943\n",
      "\n",
      "episode 15, val func loss 0.14432035386562347\n",
      "\n",
      "episode 16, val func loss 0.17280343174934387\n",
      "\n",
      "Val func train loss in epoch 1:0.177732290700078\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.15973465144634247\n",
      "\n",
      "episode 2, val func loss 0.175556480884552\n",
      "\n",
      "episode 3, val func loss 0.14357194304466248\n",
      "\n",
      "episode 4, val func loss 0.15196765959262848\n",
      "\n",
      "episode 5, val func loss 0.13555116951465607\n",
      "\n",
      "episode 6, val func loss 0.15844622254371643\n",
      "\n",
      "episode 7, val func loss 0.19909930229187012\n",
      "\n",
      "episode 8, val func loss 0.1831589639186859\n",
      "\n",
      "episode 9, val func loss 0.18885056674480438\n",
      "\n",
      "episode 10, val func loss 0.2169676274061203\n",
      "\n",
      "episode 11, val func loss 0.19131331145763397\n",
      "\n",
      "episode 12, val func loss 0.19011883437633514\n",
      "\n",
      "episode 13, val func loss 0.19776760041713715\n",
      "\n",
      "episode 14, val func loss 0.17581911385059357\n",
      "\n",
      "episode 15, val func loss 0.17531295120716095\n",
      "\n",
      "episode 16, val func loss 0.20384474098682404\n",
      "\n",
      "Val func train loss in epoch 2:0.17794257123023272\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.17641621828079224\n",
      "\n",
      "episode 2, val func loss 0.20463091135025024\n",
      "\n",
      "episode 3, val func loss 0.1512335240840912\n",
      "\n",
      "episode 4, val func loss 0.19116941094398499\n",
      "\n",
      "episode 5, val func loss 0.19025029242038727\n",
      "\n",
      "episode 6, val func loss 0.13741356134414673\n",
      "\n",
      "episode 7, val func loss 0.15947653353214264\n",
      "\n",
      "episode 8, val func loss 0.21829576790332794\n",
      "\n",
      "episode 9, val func loss 0.17306028306484222\n",
      "\n",
      "episode 10, val func loss 0.19663836061954498\n",
      "\n",
      "episode 11, val func loss 0.171611949801445\n",
      "\n",
      "episode 12, val func loss 0.1979086995124817\n",
      "\n",
      "episode 13, val func loss 0.14431457221508026\n",
      "\n",
      "episode 14, val func loss 0.181531623005867\n",
      "\n",
      "episode 15, val func loss 0.1574399620294571\n",
      "\n",
      "episode 16, val func loss 0.18863628804683685\n",
      "\n",
      "Val func train loss in epoch 3:0.1775017473846674\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19361162185668945\n",
      "\n",
      "episode 2, val func loss 0.14476662874221802\n",
      "\n",
      "episode 3, val func loss 0.18165694177150726\n",
      "\n",
      "episode 4, val func loss 0.1977187693119049\n",
      "\n",
      "episode 5, val func loss 0.17374947667121887\n",
      "\n",
      "episode 6, val func loss 0.17364338040351868\n",
      "\n",
      "episode 7, val func loss 0.1882183849811554\n",
      "\n",
      "episode 8, val func loss 0.19029663503170013\n",
      "\n",
      "episode 9, val func loss 0.20555679500102997\n",
      "\n",
      "episode 10, val func loss 0.1509547233581543\n",
      "\n",
      "episode 11, val func loss 0.21791893243789673\n",
      "\n",
      "episode 12, val func loss 0.15914736688137054\n",
      "\n",
      "episode 13, val func loss 0.1574941873550415\n",
      "\n",
      "episode 14, val func loss 0.17634651064872742\n",
      "\n",
      "episode 15, val func loss 0.1389889270067215\n",
      "\n",
      "episode 16, val func loss 0.1911209374666214\n",
      "\n",
      "Val func train loss in epoch 4:0.17757438868284225\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.13795915246009827\n",
      "\n",
      "episode 2, val func loss 0.1595839262008667\n",
      "\n",
      "episode 3, val func loss 0.17616583406925201\n",
      "\n",
      "episode 4, val func loss 0.17045293748378754\n",
      "\n",
      "episode 5, val func loss 0.18345360457897186\n",
      "\n",
      "episode 6, val func loss 0.20821110904216766\n",
      "\n",
      "episode 7, val func loss 0.1920304298400879\n",
      "\n",
      "episode 8, val func loss 0.15713411569595337\n",
      "\n",
      "episode 9, val func loss 0.15121226012706757\n",
      "\n",
      "episode 10, val func loss 0.17403022944927216\n",
      "\n",
      "episode 11, val func loss 0.19748792052268982\n",
      "\n",
      "episode 12, val func loss 0.19074000418186188\n",
      "\n",
      "episode 13, val func loss 0.21674664318561554\n",
      "\n",
      "episode 14, val func loss 0.18901187181472778\n",
      "\n",
      "episode 15, val func loss 0.19304612278938293\n",
      "\n",
      "episode 16, val func loss 0.14548324048519135\n",
      "\n",
      "Val func train loss in epoch 5:0.17767183762043715\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18883541226387024\n",
      "\n",
      "episode 2, val func loss 0.17419421672821045\n",
      "\n",
      "episode 3, val func loss 0.17236508429050446\n",
      "\n",
      "episode 4, val func loss 0.1821879893541336\n",
      "\n",
      "episode 5, val func loss 0.19899630546569824\n",
      "\n",
      "episode 6, val func loss 0.1434929221868515\n",
      "\n",
      "episode 7, val func loss 0.15103311836719513\n",
      "\n",
      "episode 8, val func loss 0.20672599971294403\n",
      "\n",
      "episode 9, val func loss 0.15952971577644348\n",
      "\n",
      "episode 10, val func loss 0.17608949542045593\n",
      "\n",
      "episode 11, val func loss 0.19070540368556976\n",
      "\n",
      "episode 12, val func loss 0.19396759569644928\n",
      "\n",
      "episode 13, val func loss 0.19045738875865936\n",
      "\n",
      "episode 14, val func loss 0.15841813385486603\n",
      "\n",
      "episode 15, val func loss 0.14341656863689423\n",
      "\n",
      "episode 16, val func loss 0.21651117503643036\n",
      "\n",
      "Val func train loss in epoch 6:0.1779329078271985\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.15741071105003357\n",
      "\n",
      "episode 2, val func loss 0.14379499852657318\n",
      "\n",
      "episode 3, val func loss 0.19604326784610748\n",
      "\n",
      "episode 4, val func loss 0.13685251772403717\n",
      "\n",
      "episode 5, val func loss 0.15974217653274536\n",
      "\n",
      "episode 6, val func loss 0.17035545408725739\n",
      "\n",
      "episode 7, val func loss 0.2074696123600006\n",
      "\n",
      "episode 8, val func loss 0.1765320897102356\n",
      "\n",
      "episode 9, val func loss 0.19894017279148102\n",
      "\n",
      "episode 10, val func loss 0.21614935994148254\n",
      "\n",
      "episode 11, val func loss 0.1918410062789917\n",
      "\n",
      "episode 12, val func loss 0.1756468266248703\n",
      "\n",
      "episode 13, val func loss 0.19043973088264465\n",
      "\n",
      "episode 14, val func loss 0.15092498064041138\n",
      "\n",
      "episode 15, val func loss 0.1882774978876114\n",
      "\n",
      "episode 16, val func loss 0.18153056502342224\n",
      "\n",
      "Val func train loss in epoch 7:0.1776219354942441\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1897062212228775\n",
      "\n",
      "episode 2, val func loss 0.21678535640239716\n",
      "\n",
      "episode 3, val func loss 0.17412805557250977\n",
      "\n",
      "episode 4, val func loss 0.1977190375328064\n",
      "\n",
      "episode 5, val func loss 0.15925078094005585\n",
      "\n",
      "episode 6, val func loss 0.18084709346294403\n",
      "\n",
      "episode 7, val func loss 0.15794500708580017\n",
      "\n",
      "episode 8, val func loss 0.14048640429973602\n",
      "\n",
      "episode 9, val func loss 0.14387430250644684\n",
      "\n",
      "episode 10, val func loss 0.20351658761501312\n",
      "\n",
      "episode 11, val func loss 0.17437171936035156\n",
      "\n",
      "episode 12, val func loss 0.18732419610023499\n",
      "\n",
      "episode 13, val func loss 0.19535237550735474\n",
      "\n",
      "episode 14, val func loss 0.1905437856912613\n",
      "\n",
      "episode 15, val func loss 0.1520504355430603\n",
      "\n",
      "episode 16, val func loss 0.1777782440185547\n",
      "\n",
      "Val func train loss in epoch 8:0.17760497517883778\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1917884349822998\n",
      "\n",
      "episode 2, val func loss 0.18848846852779388\n",
      "\n",
      "episode 3, val func loss 0.19671630859375\n",
      "\n",
      "episode 4, val func loss 0.1458434909582138\n",
      "\n",
      "episode 5, val func loss 0.18892699480056763\n",
      "\n",
      "episode 6, val func loss 0.19326171278953552\n",
      "\n",
      "episode 7, val func loss 0.17541547119617462\n",
      "\n",
      "episode 8, val func loss 0.21712671220302582\n",
      "\n",
      "episode 9, val func loss 0.1715177297592163\n",
      "\n",
      "episode 10, val func loss 0.2058875560760498\n",
      "\n",
      "episode 11, val func loss 0.1597643792629242\n",
      "\n",
      "episode 12, val func loss 0.1512172967195511\n",
      "\n",
      "episode 13, val func loss 0.15687446296215057\n",
      "\n",
      "episode 14, val func loss 0.18184474110603333\n",
      "\n",
      "episode 15, val func loss 0.13950978219509125\n",
      "\n",
      "episode 16, val func loss 0.17323040962219238\n",
      "\n",
      "Val func train loss in epoch 9:0.17733837198466063\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1517806500196457\n",
      "\n",
      "episode 2, val func loss 0.1988898664712906\n",
      "\n",
      "episode 3, val func loss 0.1729196012020111\n",
      "\n",
      "episode 4, val func loss 0.13669925928115845\n",
      "\n",
      "episode 5, val func loss 0.1436731070280075\n",
      "\n",
      "episode 6, val func loss 0.2186659574508667\n",
      "\n",
      "episode 7, val func loss 0.16014878451824188\n",
      "\n",
      "episode 8, val func loss 0.19804790616035461\n",
      "\n",
      "episode 9, val func loss 0.19021238386631012\n",
      "\n",
      "episode 10, val func loss 0.15701931715011597\n",
      "\n",
      "episode 11, val func loss 0.18176311254501343\n",
      "\n",
      "episode 12, val func loss 0.20360827445983887\n",
      "\n",
      "episode 13, val func loss 0.1756499707698822\n",
      "\n",
      "episode 14, val func loss 0.19031421840190887\n",
      "\n",
      "episode 15, val func loss 0.17770518362522125\n",
      "\n",
      "episode 16, val func loss 0.18919309973716736\n",
      "\n",
      "Val func train loss in epoch 10:0.17789316829293966\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1446639895439148\n",
      "\n",
      "episode 2, val func loss 0.19835025072097778\n",
      "\n",
      "episode 3, val func loss 0.17102400958538055\n",
      "\n",
      "episode 4, val func loss 0.19753128290176392\n",
      "\n",
      "episode 5, val func loss 0.2060311883687973\n",
      "\n",
      "episode 6, val func loss 0.13689574599266052\n",
      "\n",
      "episode 7, val func loss 0.15104800462722778\n",
      "\n",
      "episode 8, val func loss 0.19053374230861664\n",
      "\n",
      "episode 9, val func loss 0.18846088647842407\n",
      "\n",
      "episode 10, val func loss 0.15718232095241547\n",
      "\n",
      "episode 11, val func loss 0.17353786528110504\n",
      "\n",
      "episode 12, val func loss 0.17653603851795197\n",
      "\n",
      "episode 13, val func loss 0.21728333830833435\n",
      "\n",
      "episode 14, val func loss 0.15931767225265503\n",
      "\n",
      "episode 15, val func loss 0.19139327108860016\n",
      "\n",
      "episode 16, val func loss 0.1821196973323822\n",
      "\n",
      "Val func train loss in epoch 11:0.17761933151632547\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1569802612066269\n",
      "\n",
      "episode 2, val func loss 0.20421800017356873\n",
      "\n",
      "episode 3, val func loss 0.18889279663562775\n",
      "\n",
      "episode 4, val func loss 0.19123394787311554\n",
      "\n",
      "episode 5, val func loss 0.1818905472755432\n",
      "\n",
      "episode 6, val func loss 0.17612963914871216\n",
      "\n",
      "episode 7, val func loss 0.14419275522232056\n",
      "\n",
      "episode 8, val func loss 0.21687299013137817\n",
      "\n",
      "episode 9, val func loss 0.18967154622077942\n",
      "\n",
      "episode 10, val func loss 0.13770785927772522\n",
      "\n",
      "episode 11, val func loss 0.17088763415813446\n",
      "\n",
      "episode 12, val func loss 0.1604103446006775\n",
      "\n",
      "episode 13, val func loss 0.20105735957622528\n",
      "\n",
      "episode 14, val func loss 0.15104839205741882\n",
      "\n",
      "episode 15, val func loss 0.1981225460767746\n",
      "\n",
      "episode 16, val func loss 0.1728755533695221\n",
      "\n",
      "Val func train loss in epoch 12:0.1776370108127594\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.20472964644432068\n",
      "\n",
      "episode 2, val func loss 0.19055694341659546\n",
      "\n",
      "episode 3, val func loss 0.1582978516817093\n",
      "\n",
      "episode 4, val func loss 0.18994712829589844\n",
      "\n",
      "episode 5, val func loss 0.14391444623470306\n",
      "\n",
      "episode 6, val func loss 0.1599179208278656\n",
      "\n",
      "episode 7, val func loss 0.19131837785243988\n",
      "\n",
      "episode 8, val func loss 0.17229916155338287\n",
      "\n",
      "episode 9, val func loss 0.1731681525707245\n",
      "\n",
      "episode 10, val func loss 0.218485489487648\n",
      "\n",
      "episode 11, val func loss 0.18332618474960327\n",
      "\n",
      "episode 12, val func loss 0.17669866979122162\n",
      "\n",
      "episode 13, val func loss 0.1519067883491516\n",
      "\n",
      "episode 14, val func loss 0.14351657032966614\n",
      "\n",
      "episode 15, val func loss 0.19685876369476318\n",
      "\n",
      "episode 16, val func loss 0.1978549212217331\n",
      "\n",
      "Val func train loss in epoch 13:0.17829981353133917\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.15717631578445435\n",
      "\n",
      "episode 2, val func loss 0.1896473467350006\n",
      "\n",
      "episode 3, val func loss 0.1750713437795639\n",
      "\n",
      "episode 4, val func loss 0.15980404615402222\n",
      "\n",
      "episode 5, val func loss 0.1513107717037201\n",
      "\n",
      "episode 6, val func loss 0.1392717957496643\n",
      "\n",
      "episode 7, val func loss 0.19489462673664093\n",
      "\n",
      "episode 8, val func loss 0.19850921630859375\n",
      "\n",
      "episode 9, val func loss 0.19050945341587067\n",
      "\n",
      "episode 10, val func loss 0.17592646181583405\n",
      "\n",
      "episode 11, val func loss 0.1710553765296936\n",
      "\n",
      "episode 12, val func loss 0.1435651034116745\n",
      "\n",
      "episode 13, val func loss 0.18195506930351257\n",
      "\n",
      "episode 14, val func loss 0.20545612275600433\n",
      "\n",
      "episode 15, val func loss 0.19118288159370422\n",
      "\n",
      "episode 16, val func loss 0.21692869067192078\n",
      "\n",
      "Val func train loss in epoch 14:0.17764153890311718\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1451375037431717\n",
      "\n",
      "episode 2, val func loss 0.17253084480762482\n",
      "\n",
      "episode 3, val func loss 0.1585141271352768\n",
      "\n",
      "episode 4, val func loss 0.18250688910484314\n",
      "\n",
      "episode 5, val func loss 0.19086016714572906\n",
      "\n",
      "episode 6, val func loss 0.15783809125423431\n",
      "\n",
      "episode 7, val func loss 0.19695942103862762\n",
      "\n",
      "episode 8, val func loss 0.19109205901622772\n",
      "\n",
      "episode 9, val func loss 0.19470344483852386\n",
      "\n",
      "episode 10, val func loss 0.190092071890831\n",
      "\n",
      "episode 11, val func loss 0.2027970254421234\n",
      "\n",
      "episode 12, val func loss 0.14330866932868958\n",
      "\n",
      "episode 13, val func loss 0.17286624014377594\n",
      "\n",
      "episode 14, val func loss 0.1514490842819214\n",
      "\n",
      "episode 15, val func loss 0.2174350470304489\n",
      "\n",
      "episode 16, val func loss 0.17635858058929443\n",
      "\n",
      "Val func train loss in epoch 15:0.17777807917445898\n",
      "***********************TIME WAS 4.992612250645956 min*****************************\n",
      "\n",
      "**********************ROUND 103 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.12740197777748108\n",
      "\n",
      "episode 2, policy loss 0.09624034911394119\n",
      "\n",
      "episode 3, policy loss 0.03254855051636696\n",
      "\n",
      "episode 4, policy loss 0.07946702092885971\n",
      "\n",
      "episode 5, policy loss 0.062046922743320465\n",
      "\n",
      "episode 6, policy loss 0.0395846925675869\n",
      "\n",
      "episode 7, policy loss 0.06957191228866577\n",
      "\n",
      "episode 8, policy loss 0.06989717483520508\n",
      "\n",
      "episode 9, policy loss 0.06300011277198792\n",
      "\n",
      "episode 10, policy loss 0.08385995775461197\n",
      "\n",
      "episode 11, policy loss 0.0351550430059433\n",
      "\n",
      "episode 12, policy loss 0.05295799672603607\n",
      "\n",
      "episode 13, policy loss 0.061656780540943146\n",
      "\n",
      "episode 14, policy loss 0.007126254495233297\n",
      "\n",
      "episode 15, policy loss 0.08799594640731812\n",
      "\n",
      "episode 16, policy loss 0.052861861884593964\n",
      "\n",
      "Policy train loss in epoch 0:0.06383578464738093\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.006734041031450033\n",
      "\n",
      "episode 2, policy loss 0.08385609835386276\n",
      "\n",
      "episode 3, policy loss 0.05132019519805908\n",
      "\n",
      "episode 4, policy loss 0.08825231343507767\n",
      "\n",
      "episode 5, policy loss 0.03810705244541168\n",
      "\n",
      "episode 6, policy loss 0.05932655185461044\n",
      "\n",
      "episode 7, policy loss 0.12225981801748276\n",
      "\n",
      "episode 8, policy loss 0.030405644327402115\n",
      "\n",
      "episode 9, policy loss 0.07113353908061981\n",
      "\n",
      "episode 10, policy loss 0.06200014799833298\n",
      "\n",
      "episode 11, policy loss 0.07026832550764084\n",
      "\n",
      "episode 12, policy loss 0.02529638446867466\n",
      "\n",
      "episode 13, policy loss 0.07206688821315765\n",
      "\n",
      "episode 14, policy loss 0.05798228457570076\n",
      "\n",
      "episode 15, policy loss 0.05256127938628197\n",
      "\n",
      "episode 16, policy loss 0.08778510242700577\n",
      "\n",
      "Policy train loss in epoch 1:0.061209729145048186\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.03938481956720352\n",
      "\n",
      "episode 2, policy loss 0.058881472796201706\n",
      "\n",
      "episode 3, policy loss 0.06124794855713844\n",
      "\n",
      "episode 4, policy loss 0.08357584476470947\n",
      "\n",
      "episode 5, policy loss 0.061923764646053314\n",
      "\n",
      "episode 6, policy loss 0.08927829563617706\n",
      "\n",
      "episode 7, policy loss 0.07244338095188141\n",
      "\n",
      "episode 8, policy loss 0.0306828822940588\n",
      "\n",
      "episode 9, policy loss 0.08763979375362396\n",
      "\n",
      "episode 10, policy loss 0.0022936651948839426\n",
      "\n",
      "episode 11, policy loss 0.05559169501066208\n",
      "\n",
      "episode 12, policy loss 0.04809090867638588\n",
      "\n",
      "episode 13, policy loss 0.12231748551130295\n",
      "\n",
      "episode 14, policy loss 0.024948541074991226\n",
      "\n",
      "episode 15, policy loss 0.06938107311725616\n",
      "\n",
      "episode 16, policy loss 0.06886162608861923\n",
      "\n",
      "Policy train loss in epoch 2:0.06103394985257182\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.0691971555352211\n",
      "\n",
      "episode 2, policy loss 0.031499747186899185\n",
      "\n",
      "episode 3, policy loss 0.04952229931950569\n",
      "\n",
      "episode 4, policy loss 0.03814832121133804\n",
      "\n",
      "episode 5, policy loss 0.06833066791296005\n",
      "\n",
      "episode 6, policy loss 0.08805742114782333\n",
      "\n",
      "episode 7, policy loss 0.02598140574991703\n",
      "\n",
      "episode 8, policy loss 0.05314118415117264\n",
      "\n",
      "episode 9, policy loss 0.05728209391236305\n",
      "\n",
      "episode 10, policy loss 0.08735864609479904\n",
      "\n",
      "episode 11, policy loss 0.08233429491519928\n",
      "\n",
      "episode 12, policy loss 0.06203353404998779\n",
      "\n",
      "episode 13, policy loss 0.1225753203034401\n",
      "\n",
      "episode 14, policy loss 0.05919146165251732\n",
      "\n",
      "episode 15, policy loss 0.07290196418762207\n",
      "\n",
      "episode 16, policy loss 0.002906756941229105\n",
      "\n",
      "Policy train loss in epoch 3:0.06065389214199968\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.18348754942417145\n",
      "\n",
      "episode 2, val func loss 0.21118029952049255\n",
      "\n",
      "episode 3, val func loss 0.20023444294929504\n",
      "\n",
      "episode 4, val func loss 0.15067742764949799\n",
      "\n",
      "episode 5, val func loss 0.1842748075723648\n",
      "\n",
      "episode 6, val func loss 0.18522633612155914\n",
      "\n",
      "episode 7, val func loss 0.18950095772743225\n",
      "\n",
      "episode 8, val func loss 0.18476544320583344\n",
      "\n",
      "episode 9, val func loss 0.18984316289424896\n",
      "\n",
      "episode 10, val func loss 0.17776599526405334\n",
      "\n",
      "episode 11, val func loss 0.1859232485294342\n",
      "\n",
      "episode 12, val func loss 0.23097984492778778\n",
      "\n",
      "episode 13, val func loss 0.1755092889070511\n",
      "\n",
      "episode 14, val func loss 0.1737663298845291\n",
      "\n",
      "episode 15, val func loss 0.1935521811246872\n",
      "\n",
      "episode 16, val func loss 0.17776519060134888\n",
      "\n",
      "Val func train loss in epoch 0:0.1871532816439867\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.20802269876003265\n",
      "\n",
      "episode 2, val func loss 0.18595343828201294\n",
      "\n",
      "episode 3, val func loss 0.17352914810180664\n",
      "\n",
      "episode 4, val func loss 0.20155343413352966\n",
      "\n",
      "episode 5, val func loss 0.18753983080387115\n",
      "\n",
      "episode 6, val func loss 0.18983903527259827\n",
      "\n",
      "episode 7, val func loss 0.1807723343372345\n",
      "\n",
      "episode 8, val func loss 0.23557555675506592\n",
      "\n",
      "episode 9, val func loss 0.1740499585866928\n",
      "\n",
      "episode 10, val func loss 0.15319737792015076\n",
      "\n",
      "episode 11, val func loss 0.1867288500070572\n",
      "\n",
      "episode 12, val func loss 0.17491793632507324\n",
      "\n",
      "episode 13, val func loss 0.19162225723266602\n",
      "\n",
      "episode 14, val func loss 0.18365110456943512\n",
      "\n",
      "episode 15, val func loss 0.18530964851379395\n",
      "\n",
      "episode 16, val func loss 0.17642930150032043\n",
      "\n",
      "Val func train loss in epoch 1:0.18679324444383383\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18997478485107422\n",
      "\n",
      "episode 2, val func loss 0.18526297807693481\n",
      "\n",
      "episode 3, val func loss 0.187683567404747\n",
      "\n",
      "episode 4, val func loss 0.17437325417995453\n",
      "\n",
      "episode 5, val func loss 0.18466639518737793\n",
      "\n",
      "episode 6, val func loss 0.15010036528110504\n",
      "\n",
      "episode 7, val func loss 0.19252939522266388\n",
      "\n",
      "episode 8, val func loss 0.17030848562717438\n",
      "\n",
      "episode 9, val func loss 0.23262621462345123\n",
      "\n",
      "episode 10, val func loss 0.1751299351453781\n",
      "\n",
      "episode 11, val func loss 0.1963062286376953\n",
      "\n",
      "episode 12, val func loss 0.20402587950229645\n",
      "\n",
      "episode 13, val func loss 0.18353839218616486\n",
      "\n",
      "episode 14, val func loss 0.1952776163816452\n",
      "\n",
      "episode 15, val func loss 0.18147887289524078\n",
      "\n",
      "episode 16, val func loss 0.17959736287593842\n",
      "\n",
      "Val func train loss in epoch 2:0.18642998300492764\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1536385864019394\n",
      "\n",
      "episode 2, val func loss 0.1738559752702713\n",
      "\n",
      "episode 3, val func loss 0.20058317482471466\n",
      "\n",
      "episode 4, val func loss 0.18799985945224762\n",
      "\n",
      "episode 5, val func loss 0.17565758526325226\n",
      "\n",
      "episode 6, val func loss 0.187723770737648\n",
      "\n",
      "episode 7, val func loss 0.17540882527828217\n",
      "\n",
      "episode 8, val func loss 0.18852832913398743\n",
      "\n",
      "episode 9, val func loss 0.18771541118621826\n",
      "\n",
      "episode 10, val func loss 0.17924754321575165\n",
      "\n",
      "episode 11, val func loss 0.18658886849880219\n",
      "\n",
      "episode 12, val func loss 0.1926582008600235\n",
      "\n",
      "episode 13, val func loss 0.1760323941707611\n",
      "\n",
      "episode 14, val func loss 0.19105862081050873\n",
      "\n",
      "episode 15, val func loss 0.20998382568359375\n",
      "\n",
      "episode 16, val func loss 0.23481348156929016\n",
      "\n",
      "Val func train loss in epoch 3:0.18759340327233076\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18063686788082123\n",
      "\n",
      "episode 2, val func loss 0.18659891188144684\n",
      "\n",
      "episode 3, val func loss 0.18769687414169312\n",
      "\n",
      "episode 4, val func loss 0.1746618002653122\n",
      "\n",
      "episode 5, val func loss 0.17524367570877075\n",
      "\n",
      "episode 6, val func loss 0.21027012169361115\n",
      "\n",
      "episode 7, val func loss 0.17300058901309967\n",
      "\n",
      "episode 8, val func loss 0.18738290667533875\n",
      "\n",
      "episode 9, val func loss 0.18459880352020264\n",
      "\n",
      "episode 10, val func loss 0.19110846519470215\n",
      "\n",
      "episode 11, val func loss 0.17592434585094452\n",
      "\n",
      "episode 12, val func loss 0.1518389880657196\n",
      "\n",
      "episode 13, val func loss 0.18652698397636414\n",
      "\n",
      "episode 14, val func loss 0.1930200308561325\n",
      "\n",
      "episode 15, val func loss 0.23620258271694183\n",
      "\n",
      "episode 16, val func loss 0.20165134966373444\n",
      "\n",
      "Val func train loss in epoch 4:0.18727270606905222\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1872531920671463\n",
      "\n",
      "episode 2, val func loss 0.17494994401931763\n",
      "\n",
      "episode 3, val func loss 0.2094586044549942\n",
      "\n",
      "episode 4, val func loss 0.23049569129943848\n",
      "\n",
      "episode 5, val func loss 0.17980986833572388\n",
      "\n",
      "episode 6, val func loss 0.1858745664358139\n",
      "\n",
      "episode 7, val func loss 0.18774741888046265\n",
      "\n",
      "episode 8, val func loss 0.1794746071100235\n",
      "\n",
      "episode 9, val func loss 0.20231056213378906\n",
      "\n",
      "episode 10, val func loss 0.18636614084243774\n",
      "\n",
      "episode 11, val func loss 0.15115700662136078\n",
      "\n",
      "episode 12, val func loss 0.17334777116775513\n",
      "\n",
      "episode 13, val func loss 0.17467382550239563\n",
      "\n",
      "episode 14, val func loss 0.18835760653018951\n",
      "\n",
      "episode 15, val func loss 0.19350023567676544\n",
      "\n",
      "episode 16, val func loss 0.19004714488983154\n",
      "\n",
      "Val func train loss in epoch 5:0.18717651162296534\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18455643951892853\n",
      "\n",
      "episode 2, val func loss 0.2099597007036209\n",
      "\n",
      "episode 3, val func loss 0.1910809725522995\n",
      "\n",
      "episode 4, val func loss 0.17332997918128967\n",
      "\n",
      "episode 5, val func loss 0.18578623235225677\n",
      "\n",
      "episode 6, val func loss 0.18651245534420013\n",
      "\n",
      "episode 7, val func loss 0.20205731689929962\n",
      "\n",
      "episode 8, val func loss 0.18663707375526428\n",
      "\n",
      "episode 9, val func loss 0.17526152729988098\n",
      "\n",
      "episode 10, val func loss 0.1813715398311615\n",
      "\n",
      "episode 11, val func loss 0.17348404228687286\n",
      "\n",
      "episode 12, val func loss 0.18822801113128662\n",
      "\n",
      "episode 13, val func loss 0.15392620861530304\n",
      "\n",
      "episode 14, val func loss 0.19202744960784912\n",
      "\n",
      "episode 15, val func loss 0.17431387305259705\n",
      "\n",
      "episode 16, val func loss 0.23427438735961914\n",
      "\n",
      "Val func train loss in epoch 6:0.1870504505932331\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19063891470432281\n",
      "\n",
      "episode 2, val func loss 0.20892848074436188\n",
      "\n",
      "episode 3, val func loss 0.17964914441108704\n",
      "\n",
      "episode 4, val func loss 0.2023789882659912\n",
      "\n",
      "episode 5, val func loss 0.1546398103237152\n",
      "\n",
      "episode 6, val func loss 0.19218897819519043\n",
      "\n",
      "episode 7, val func loss 0.17648108303546906\n",
      "\n",
      "episode 8, val func loss 0.18692581355571747\n",
      "\n",
      "episode 9, val func loss 0.17374397814273834\n",
      "\n",
      "episode 10, val func loss 0.18767502903938293\n",
      "\n",
      "episode 11, val func loss 0.17390674352645874\n",
      "\n",
      "episode 12, val func loss 0.18475088477134705\n",
      "\n",
      "episode 13, val func loss 0.1856294572353363\n",
      "\n",
      "episode 14, val func loss 0.17591655254364014\n",
      "\n",
      "episode 15, val func loss 0.18486762046813965\n",
      "\n",
      "episode 16, val func loss 0.23144610226154327\n",
      "\n",
      "Val func train loss in epoch 7:0.1868604738265276\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1923362761735916\n",
      "\n",
      "episode 2, val func loss 0.18533886969089508\n",
      "\n",
      "episode 3, val func loss 0.2101752758026123\n",
      "\n",
      "episode 4, val func loss 0.20281614363193512\n",
      "\n",
      "episode 5, val func loss 0.18433338403701782\n",
      "\n",
      "episode 6, val func loss 0.18629254400730133\n",
      "\n",
      "episode 7, val func loss 0.18650773167610168\n",
      "\n",
      "episode 8, val func loss 0.175337553024292\n",
      "\n",
      "episode 9, val func loss 0.18185916543006897\n",
      "\n",
      "episode 10, val func loss 0.18751414120197296\n",
      "\n",
      "episode 11, val func loss 0.18652789294719696\n",
      "\n",
      "episode 12, val func loss 0.23069405555725098\n",
      "\n",
      "episode 13, val func loss 0.17655450105667114\n",
      "\n",
      "episode 14, val func loss 0.1733069270849228\n",
      "\n",
      "episode 15, val func loss 0.14790640771389008\n",
      "\n",
      "episode 16, val func loss 0.17381152510643005\n",
      "\n",
      "Val func train loss in epoch 8:0.18633202463388443\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18810155987739563\n",
      "\n",
      "episode 2, val func loss 0.17671431601047516\n",
      "\n",
      "episode 3, val func loss 0.2016024887561798\n",
      "\n",
      "episode 4, val func loss 0.21342630684375763\n",
      "\n",
      "episode 5, val func loss 0.18503740429878235\n",
      "\n",
      "episode 6, val func loss 0.17617754638195038\n",
      "\n",
      "episode 7, val func loss 0.1869092583656311\n",
      "\n",
      "episode 8, val func loss 0.1736888438463211\n",
      "\n",
      "episode 9, val func loss 0.19068410992622375\n",
      "\n",
      "episode 10, val func loss 0.18628491461277008\n",
      "\n",
      "episode 11, val func loss 0.1844017654657364\n",
      "\n",
      "episode 12, val func loss 0.17374730110168457\n",
      "\n",
      "episode 13, val func loss 0.18211627006530762\n",
      "\n",
      "episode 14, val func loss 0.23188373446464539\n",
      "\n",
      "episode 15, val func loss 0.15528787672519684\n",
      "\n",
      "episode 16, val func loss 0.18726544082164764\n",
      "\n",
      "Val func train loss in epoch 9:0.1870830710977316\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.21039216220378876\n",
      "\n",
      "episode 2, val func loss 0.17399781942367554\n",
      "\n",
      "episode 3, val func loss 0.17273549735546112\n",
      "\n",
      "episode 4, val func loss 0.1846013367176056\n",
      "\n",
      "episode 5, val func loss 0.23316143453121185\n",
      "\n",
      "episode 6, val func loss 0.1899496167898178\n",
      "\n",
      "episode 7, val func loss 0.1775461584329605\n",
      "\n",
      "episode 8, val func loss 0.1900101602077484\n",
      "\n",
      "episode 9, val func loss 0.1840282380580902\n",
      "\n",
      "episode 10, val func loss 0.18330863118171692\n",
      "\n",
      "episode 11, val func loss 0.20364081859588623\n",
      "\n",
      "episode 12, val func loss 0.1528284102678299\n",
      "\n",
      "episode 13, val func loss 0.18466345965862274\n",
      "\n",
      "episode 14, val func loss 0.18444913625717163\n",
      "\n",
      "episode 15, val func loss 0.18152236938476562\n",
      "\n",
      "episode 16, val func loss 0.17011508345603943\n",
      "\n",
      "Val func train loss in epoch 10:0.18605939578264952\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.231391042470932\n",
      "\n",
      "episode 2, val func loss 0.1872515082359314\n",
      "\n",
      "episode 3, val func loss 0.186358243227005\n",
      "\n",
      "episode 4, val func loss 0.18004082143306732\n",
      "\n",
      "episode 5, val func loss 0.17865069210529327\n",
      "\n",
      "episode 6, val func loss 0.18842042982578278\n",
      "\n",
      "episode 7, val func loss 0.15626779198646545\n",
      "\n",
      "episode 8, val func loss 0.18869437277317047\n",
      "\n",
      "episode 9, val func loss 0.20983873307704926\n",
      "\n",
      "episode 10, val func loss 0.17430633306503296\n",
      "\n",
      "episode 11, val func loss 0.1734650582075119\n",
      "\n",
      "episode 12, val func loss 0.18480314314365387\n",
      "\n",
      "episode 13, val func loss 0.18614716827869415\n",
      "\n",
      "episode 14, val func loss 0.17269426584243774\n",
      "\n",
      "episode 15, val func loss 0.20148903131484985\n",
      "\n",
      "episode 16, val func loss 0.19273443520069122\n",
      "\n",
      "Val func train loss in epoch 11:0.18703456688672304\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19050940871238708\n",
      "\n",
      "episode 2, val func loss 0.17315499484539032\n",
      "\n",
      "episode 3, val func loss 0.20201285183429718\n",
      "\n",
      "episode 4, val func loss 0.18662799894809723\n",
      "\n",
      "episode 5, val func loss 0.23393666744232178\n",
      "\n",
      "episode 6, val func loss 0.18646356463432312\n",
      "\n",
      "episode 7, val func loss 0.17951126396656036\n",
      "\n",
      "episode 8, val func loss 0.19255542755126953\n",
      "\n",
      "episode 9, val func loss 0.185459703207016\n",
      "\n",
      "episode 10, val func loss 0.17950299382209778\n",
      "\n",
      "episode 11, val func loss 0.17568464577198029\n",
      "\n",
      "episode 12, val func loss 0.20920948684215546\n",
      "\n",
      "episode 13, val func loss 0.18708239495754242\n",
      "\n",
      "episode 14, val func loss 0.17491382360458374\n",
      "\n",
      "episode 15, val func loss 0.15093618631362915\n",
      "\n",
      "episode 16, val func loss 0.18765126168727875\n",
      "\n",
      "Val func train loss in epoch 12:0.18720079213380814\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18809036910533905\n",
      "\n",
      "episode 2, val func loss 0.19497458636760712\n",
      "\n",
      "episode 3, val func loss 0.1876995712518692\n",
      "\n",
      "episode 4, val func loss 0.21028369665145874\n",
      "\n",
      "episode 5, val func loss 0.18761135637760162\n",
      "\n",
      "episode 6, val func loss 0.1726001650094986\n",
      "\n",
      "episode 7, val func loss 0.23206594586372375\n",
      "\n",
      "episode 8, val func loss 0.19134573638439178\n",
      "\n",
      "episode 9, val func loss 0.17814427614212036\n",
      "\n",
      "episode 10, val func loss 0.18525144457817078\n",
      "\n",
      "episode 11, val func loss 0.18043598532676697\n",
      "\n",
      "episode 12, val func loss 0.15224367380142212\n",
      "\n",
      "episode 13, val func loss 0.18822699785232544\n",
      "\n",
      "episode 14, val func loss 0.1729550063610077\n",
      "\n",
      "episode 15, val func loss 0.1760556697845459\n",
      "\n",
      "episode 16, val func loss 0.20180769264698029\n",
      "\n",
      "Val func train loss in epoch 13:0.18748701084405184\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17532415688037872\n",
      "\n",
      "episode 2, val func loss 0.18174532055854797\n",
      "\n",
      "episode 3, val func loss 0.18757708370685577\n",
      "\n",
      "episode 4, val func loss 0.17285950481891632\n",
      "\n",
      "episode 5, val func loss 0.15153621137142181\n",
      "\n",
      "episode 6, val func loss 0.18688586354255676\n",
      "\n",
      "episode 7, val func loss 0.17382259666919708\n",
      "\n",
      "episode 8, val func loss 0.18525974452495575\n",
      "\n",
      "episode 9, val func loss 0.2100898176431656\n",
      "\n",
      "episode 10, val func loss 0.18540790677070618\n",
      "\n",
      "episode 11, val func loss 0.19213245809078217\n",
      "\n",
      "episode 12, val func loss 0.20178666710853577\n",
      "\n",
      "episode 13, val func loss 0.1913226991891861\n",
      "\n",
      "episode 14, val func loss 0.23361463844776154\n",
      "\n",
      "episode 15, val func loss 0.17529620230197906\n",
      "\n",
      "episode 16, val func loss 0.18711455166339874\n",
      "\n",
      "Val func train loss in epoch 14:0.18698596395552158\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.17421278357505798\n",
      "\n",
      "episode 2, val func loss 0.18836838006973267\n",
      "\n",
      "episode 3, val func loss 0.17613017559051514\n",
      "\n",
      "episode 4, val func loss 0.1912643164396286\n",
      "\n",
      "episode 5, val func loss 0.17283061146736145\n",
      "\n",
      "episode 6, val func loss 0.23489472270011902\n",
      "\n",
      "episode 7, val func loss 0.17473067343235016\n",
      "\n",
      "episode 8, val func loss 0.18784396350383759\n",
      "\n",
      "episode 9, val func loss 0.2028382420539856\n",
      "\n",
      "episode 10, val func loss 0.18733659386634827\n",
      "\n",
      "episode 11, val func loss 0.21008171141147614\n",
      "\n",
      "episode 12, val func loss 0.1798602193593979\n",
      "\n",
      "episode 13, val func loss 0.1921451836824417\n",
      "\n",
      "episode 14, val func loss 0.1863856166601181\n",
      "\n",
      "episode 15, val func loss 0.1545301079750061\n",
      "\n",
      "episode 16, val func loss 0.18457257747650146\n",
      "\n",
      "Val func train loss in epoch 15:0.18737661745399237\n",
      "***********************TIME WAS 4.991380707422892 min*****************************\n",
      "\n",
      "**********************ROUND 104 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.015340883284807205\n",
      "\n",
      "episode 2, policy loss 0.07250940054655075\n",
      "\n",
      "episode 3, policy loss 0.06380879878997803\n",
      "\n",
      "episode 4, policy loss -0.015784330666065216\n",
      "\n",
      "episode 5, policy loss -0.03657917305827141\n",
      "\n",
      "episode 6, policy loss 0.023027727380394936\n",
      "\n",
      "episode 7, policy loss -0.05918136239051819\n",
      "\n",
      "episode 8, policy loss -0.09529397636651993\n",
      "\n",
      "episode 9, policy loss -0.054905444383621216\n",
      "\n",
      "episode 10, policy loss -0.006496753077954054\n",
      "\n",
      "episode 11, policy loss -0.022079089656472206\n",
      "\n",
      "episode 12, policy loss 0.003534720279276371\n",
      "\n",
      "episode 13, policy loss -0.030419833958148956\n",
      "\n",
      "episode 14, policy loss -0.05234367027878761\n",
      "\n",
      "episode 15, policy loss -0.0047329687513411045\n",
      "\n",
      "episode 16, policy loss -0.037236571311950684\n",
      "\n",
      "Policy train loss in epoch 0:-0.014801977726165205\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.03657039999961853\n",
      "\n",
      "episode 2, policy loss -0.022231722250580788\n",
      "\n",
      "episode 3, policy loss -0.05936985835433006\n",
      "\n",
      "episode 4, policy loss 0.02202478237450123\n",
      "\n",
      "episode 5, policy loss -0.038113970309495926\n",
      "\n",
      "episode 6, policy loss 0.001118747633881867\n",
      "\n",
      "episode 7, policy loss -0.05572500452399254\n",
      "\n",
      "episode 8, policy loss -0.005724884569644928\n",
      "\n",
      "episode 9, policy loss -0.006744853686541319\n",
      "\n",
      "episode 10, policy loss -0.09693837910890579\n",
      "\n",
      "episode 11, policy loss 0.06046051159501076\n",
      "\n",
      "episode 12, policy loss 0.004769877530634403\n",
      "\n",
      "episode 13, policy loss -0.05298257991671562\n",
      "\n",
      "episode 14, policy loss -0.03181859105825424\n",
      "\n",
      "episode 15, policy loss 0.06743014603853226\n",
      "\n",
      "episode 16, policy loss -0.020933443680405617\n",
      "\n",
      "Policy train loss in epoch 1:-0.016959351392870303\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.00763707747682929\n",
      "\n",
      "episode 2, policy loss 0.0004908107803203166\n",
      "\n",
      "episode 3, policy loss -0.03239081799983978\n",
      "\n",
      "episode 4, policy loss -0.006910425610840321\n",
      "\n",
      "episode 5, policy loss -0.09694229066371918\n",
      "\n",
      "episode 6, policy loss 0.020716045051813126\n",
      "\n",
      "episode 7, policy loss -0.022424623370170593\n",
      "\n",
      "episode 8, policy loss -0.053284645080566406\n",
      "\n",
      "episode 9, policy loss -0.03836227208375931\n",
      "\n",
      "episode 10, policy loss -0.039048932492733\n",
      "\n",
      "episode 11, policy loss 0.06787946820259094\n",
      "\n",
      "episode 12, policy loss -0.060750506818294525\n",
      "\n",
      "episode 13, policy loss 0.06000567227602005\n",
      "\n",
      "episode 14, policy loss -0.02072824351489544\n",
      "\n",
      "episode 15, policy loss 0.004265790805220604\n",
      "\n",
      "episode 16, policy loss -0.05539292097091675\n",
      "\n",
      "Policy train loss in epoch 2:-0.017532185560412472\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.022086547687649727\n",
      "\n",
      "episode 2, policy loss -0.006975498981773853\n",
      "\n",
      "episode 3, policy loss 0.060957469046115875\n",
      "\n",
      "episode 4, policy loss 0.00036944373277947307\n",
      "\n",
      "episode 5, policy loss 0.06794843077659607\n",
      "\n",
      "episode 6, policy loss 0.020503457635641098\n",
      "\n",
      "episode 7, policy loss -0.021033508703112602\n",
      "\n",
      "episode 8, policy loss -0.06046024709939957\n",
      "\n",
      "episode 9, policy loss -0.05606023967266083\n",
      "\n",
      "episode 10, policy loss -0.03933567926287651\n",
      "\n",
      "episode 11, policy loss -0.006952587049454451\n",
      "\n",
      "episode 12, policy loss -0.09705045074224472\n",
      "\n",
      "episode 13, policy loss -0.05318811535835266\n",
      "\n",
      "episode 14, policy loss 0.004185216035693884\n",
      "\n",
      "episode 15, policy loss -0.0380302332341671\n",
      "\n",
      "episode 16, policy loss -0.03242075815796852\n",
      "\n",
      "Policy train loss in epoch 3:-0.017476865545177134\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.202580064535141\n",
      "\n",
      "episode 2, val func loss 0.17957115173339844\n",
      "\n",
      "episode 3, val func loss 0.1811433881521225\n",
      "\n",
      "episode 4, val func loss 0.15622209012508392\n",
      "\n",
      "episode 5, val func loss 0.14553645253181458\n",
      "\n",
      "episode 6, val func loss 0.1876964122056961\n",
      "\n",
      "episode 7, val func loss 0.19308878481388092\n",
      "\n",
      "episode 8, val func loss 0.2044275552034378\n",
      "\n",
      "episode 9, val func loss 0.15072154998779297\n",
      "\n",
      "episode 10, val func loss 0.17124445736408234\n",
      "\n",
      "episode 11, val func loss 0.135965496301651\n",
      "\n",
      "episode 12, val func loss 0.14352038502693176\n",
      "\n",
      "episode 13, val func loss 0.2131464183330536\n",
      "\n",
      "episode 14, val func loss 0.18245118856430054\n",
      "\n",
      "episode 15, val func loss 0.1453772932291031\n",
      "\n",
      "episode 16, val func loss 0.17675155401229858\n",
      "\n",
      "Val func train loss in epoch 0:0.17309026513248682\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17657674849033356\n",
      "\n",
      "episode 2, val func loss 0.1306333988904953\n",
      "\n",
      "episode 3, val func loss 0.14285336434841156\n",
      "\n",
      "episode 4, val func loss 0.20713545382022858\n",
      "\n",
      "episode 5, val func loss 0.19453836977481842\n",
      "\n",
      "episode 6, val func loss 0.22280253469944\n",
      "\n",
      "episode 7, val func loss 0.17422087490558624\n",
      "\n",
      "episode 8, val func loss 0.14540860056877136\n",
      "\n",
      "episode 9, val func loss 0.15607839822769165\n",
      "\n",
      "episode 10, val func loss 0.20171868801116943\n",
      "\n",
      "episode 11, val func loss 0.1827288120985031\n",
      "\n",
      "episode 12, val func loss 0.18241210281848907\n",
      "\n",
      "episode 13, val func loss 0.14654995501041412\n",
      "\n",
      "episode 14, val func loss 0.1828833520412445\n",
      "\n",
      "episode 15, val func loss 0.15108811855316162\n",
      "\n",
      "episode 16, val func loss 0.18199411034584045\n",
      "\n",
      "Val func train loss in epoch 1:0.17372643016278744\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.14546653628349304\n",
      "\n",
      "episode 2, val func loss 0.13389328122138977\n",
      "\n",
      "episode 3, val func loss 0.15793228149414062\n",
      "\n",
      "episode 4, val func loss 0.21194806694984436\n",
      "\n",
      "episode 5, val func loss 0.12757746875286102\n",
      "\n",
      "episode 6, val func loss 0.17791254818439484\n",
      "\n",
      "episode 7, val func loss 0.17296651005744934\n",
      "\n",
      "episode 8, val func loss 0.1911020278930664\n",
      "\n",
      "episode 9, val func loss 0.2137404978275299\n",
      "\n",
      "episode 10, val func loss 0.14752228558063507\n",
      "\n",
      "episode 11, val func loss 0.2001761943101883\n",
      "\n",
      "episode 12, val func loss 0.1821521669626236\n",
      "\n",
      "episode 13, val func loss 0.1787799745798111\n",
      "\n",
      "episode 14, val func loss 0.1834295690059662\n",
      "\n",
      "episode 15, val func loss 0.15830564498901367\n",
      "\n",
      "episode 16, val func loss 0.1826091706752777\n",
      "\n",
      "Val func train loss in epoch 2:0.1728446390479803\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1910100281238556\n",
      "\n",
      "episode 2, val func loss 0.13878858089447021\n",
      "\n",
      "episode 3, val func loss 0.17580433189868927\n",
      "\n",
      "episode 4, val func loss 0.17797942459583282\n",
      "\n",
      "episode 5, val func loss 0.17660851776599884\n",
      "\n",
      "episode 6, val func loss 0.20760545134544373\n",
      "\n",
      "episode 7, val func loss 0.12819428741931915\n",
      "\n",
      "episode 8, val func loss 0.18235594034194946\n",
      "\n",
      "episode 9, val func loss 0.20399409532546997\n",
      "\n",
      "episode 10, val func loss 0.18394988775253296\n",
      "\n",
      "episode 11, val func loss 0.2143760323524475\n",
      "\n",
      "episode 12, val func loss 0.1506376713514328\n",
      "\n",
      "episode 13, val func loss 0.1487588882446289\n",
      "\n",
      "episode 14, val func loss 0.14828331768512726\n",
      "\n",
      "episode 15, val func loss 0.18166567385196686\n",
      "\n",
      "episode 16, val func loss 0.1590198278427124\n",
      "\n",
      "Val func train loss in epoch 3:0.17306449729949236\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.15106774866580963\n",
      "\n",
      "episode 2, val func loss 0.1569659262895584\n",
      "\n",
      "episode 3, val func loss 0.1451493352651596\n",
      "\n",
      "episode 4, val func loss 0.18390917778015137\n",
      "\n",
      "episode 5, val func loss 0.17303158342838287\n",
      "\n",
      "episode 6, val func loss 0.20413446426391602\n",
      "\n",
      "episode 7, val func loss 0.18178802728652954\n",
      "\n",
      "episode 8, val func loss 0.20340119302272797\n",
      "\n",
      "episode 9, val func loss 0.19089248776435852\n",
      "\n",
      "episode 10, val func loss 0.1408662348985672\n",
      "\n",
      "episode 11, val func loss 0.14565235376358032\n",
      "\n",
      "episode 12, val func loss 0.17876793444156647\n",
      "\n",
      "episode 13, val func loss 0.1844058334827423\n",
      "\n",
      "episode 14, val func loss 0.13062602281570435\n",
      "\n",
      "episode 15, val func loss 0.21693886816501617\n",
      "\n",
      "episode 16, val func loss 0.17592890560626984\n",
      "\n",
      "Val func train loss in epoch 4:0.17272038105875254\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17222175002098083\n",
      "\n",
      "episode 2, val func loss 0.14418958127498627\n",
      "\n",
      "episode 3, val func loss 0.1835779994726181\n",
      "\n",
      "episode 4, val func loss 0.21545256674289703\n",
      "\n",
      "episode 5, val func loss 0.13327671587467194\n",
      "\n",
      "episode 6, val func loss 0.1509471982717514\n",
      "\n",
      "episode 7, val func loss 0.1791640669107437\n",
      "\n",
      "episode 8, val func loss 0.1760663539171219\n",
      "\n",
      "episode 9, val func loss 0.13866281509399414\n",
      "\n",
      "episode 10, val func loss 0.18158207833766937\n",
      "\n",
      "episode 11, val func loss 0.14457128942012787\n",
      "\n",
      "episode 12, val func loss 0.20547103881835938\n",
      "\n",
      "episode 13, val func loss 0.19303937256336212\n",
      "\n",
      "episode 14, val func loss 0.20423777401447296\n",
      "\n",
      "episode 15, val func loss 0.18466976284980774\n",
      "\n",
      "episode 16, val func loss 0.15621978044509888\n",
      "\n",
      "Val func train loss in epoch 5:0.17270938400179148\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.13968057930469513\n",
      "\n",
      "episode 2, val func loss 0.18217028677463531\n",
      "\n",
      "episode 3, val func loss 0.20243698358535767\n",
      "\n",
      "episode 4, val func loss 0.19213145971298218\n",
      "\n",
      "episode 5, val func loss 0.18028129637241364\n",
      "\n",
      "episode 6, val func loss 0.17739629745483398\n",
      "\n",
      "episode 7, val func loss 0.17051750421524048\n",
      "\n",
      "episode 8, val func loss 0.21449600160121918\n",
      "\n",
      "episode 9, val func loss 0.14502878487110138\n",
      "\n",
      "episode 10, val func loss 0.14509016275405884\n",
      "\n",
      "episode 11, val func loss 0.20301242172718048\n",
      "\n",
      "episode 12, val func loss 0.13292565941810608\n",
      "\n",
      "episode 13, val func loss 0.18405379354953766\n",
      "\n",
      "episode 14, val func loss 0.1839286983013153\n",
      "\n",
      "episode 15, val func loss 0.156516894698143\n",
      "\n",
      "episode 16, val func loss 0.1505064219236374\n",
      "\n",
      "Val func train loss in epoch 6:0.1725108278915286\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19105768203735352\n",
      "\n",
      "episode 2, val func loss 0.21516026556491852\n",
      "\n",
      "episode 3, val func loss 0.13942715525627136\n",
      "\n",
      "episode 4, val func loss 0.17174576222896576\n",
      "\n",
      "episode 5, val func loss 0.18182356655597687\n",
      "\n",
      "episode 6, val func loss 0.1793975830078125\n",
      "\n",
      "episode 7, val func loss 0.14552035927772522\n",
      "\n",
      "episode 8, val func loss 0.1839585155248642\n",
      "\n",
      "episode 9, val func loss 0.13186103105545044\n",
      "\n",
      "episode 10, val func loss 0.1765461415052414\n",
      "\n",
      "episode 11, val func loss 0.15117302536964417\n",
      "\n",
      "episode 12, val func loss 0.20434898138046265\n",
      "\n",
      "episode 13, val func loss 0.15607765316963196\n",
      "\n",
      "episode 14, val func loss 0.18444080650806427\n",
      "\n",
      "episode 15, val func loss 0.14526709914207458\n",
      "\n",
      "episode 16, val func loss 0.2040373831987381\n",
      "\n",
      "Val func train loss in epoch 7:0.17261518817394972\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1506338119506836\n",
      "\n",
      "episode 2, val func loss 0.13837173581123352\n",
      "\n",
      "episode 3, val func loss 0.14560402929782867\n",
      "\n",
      "episode 4, val func loss 0.15627607703208923\n",
      "\n",
      "episode 5, val func loss 0.18218128383159637\n",
      "\n",
      "episode 6, val func loss 0.20170831680297852\n",
      "\n",
      "episode 7, val func loss 0.17202292382717133\n",
      "\n",
      "episode 8, val func loss 0.14423736929893494\n",
      "\n",
      "episode 9, val func loss 0.20243136584758759\n",
      "\n",
      "episode 10, val func loss 0.21447263658046722\n",
      "\n",
      "episode 11, val func loss 0.17734520137310028\n",
      "\n",
      "episode 12, val func loss 0.18296882510185242\n",
      "\n",
      "episode 13, val func loss 0.19153039157390594\n",
      "\n",
      "episode 14, val func loss 0.1821828931570053\n",
      "\n",
      "episode 15, val func loss 0.13714025914669037\n",
      "\n",
      "episode 16, val func loss 0.18215855956077576\n",
      "\n",
      "Val func train loss in epoch 8:0.17257910501211882\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20218700170516968\n",
      "\n",
      "episode 2, val func loss 0.21394075453281403\n",
      "\n",
      "episode 3, val func loss 0.1405002772808075\n",
      "\n",
      "episode 4, val func loss 0.1438838243484497\n",
      "\n",
      "episode 5, val func loss 0.17751270532608032\n",
      "\n",
      "episode 6, val func loss 0.18498188257217407\n",
      "\n",
      "episode 7, val func loss 0.20426133275032043\n",
      "\n",
      "episode 8, val func loss 0.18372923135757446\n",
      "\n",
      "episode 9, val func loss 0.12862271070480347\n",
      "\n",
      "episode 10, val func loss 0.15720601379871368\n",
      "\n",
      "episode 11, val func loss 0.18146631121635437\n",
      "\n",
      "episode 12, val func loss 0.1465786248445511\n",
      "\n",
      "episode 13, val func loss 0.17310047149658203\n",
      "\n",
      "episode 14, val func loss 0.17642506957054138\n",
      "\n",
      "episode 15, val func loss 0.19185292720794678\n",
      "\n",
      "episode 16, val func loss 0.1506321281194687\n",
      "\n",
      "Val func train loss in epoch 9:0.17230507917702198\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.17833863198757172\n",
      "\n",
      "episode 2, val func loss 0.15535517036914825\n",
      "\n",
      "episode 3, val func loss 0.17186082899570465\n",
      "\n",
      "episode 4, val func loss 0.14448542892932892\n",
      "\n",
      "episode 5, val func loss 0.1406727284193039\n",
      "\n",
      "episode 6, val func loss 0.1453237533569336\n",
      "\n",
      "episode 7, val func loss 0.12967796623706818\n",
      "\n",
      "episode 8, val func loss 0.2044377624988556\n",
      "\n",
      "episode 9, val func loss 0.19309939444065094\n",
      "\n",
      "episode 10, val func loss 0.20730501413345337\n",
      "\n",
      "episode 11, val func loss 0.2215762436389923\n",
      "\n",
      "episode 12, val func loss 0.15083222091197968\n",
      "\n",
      "episode 13, val func loss 0.1755756139755249\n",
      "\n",
      "episode 14, val func loss 0.1839337795972824\n",
      "\n",
      "episode 15, val func loss 0.18199221789836884\n",
      "\n",
      "episode 16, val func loss 0.18240052461624146\n",
      "\n",
      "Val func train loss in epoch 10:0.17292920500040054\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.15121141076087952\n",
      "\n",
      "episode 2, val func loss 0.20176635682582855\n",
      "\n",
      "episode 3, val func loss 0.16055214405059814\n",
      "\n",
      "episode 4, val func loss 0.21339793503284454\n",
      "\n",
      "episode 5, val func loss 0.13937437534332275\n",
      "\n",
      "episode 6, val func loss 0.18351751565933228\n",
      "\n",
      "episode 7, val func loss 0.14641571044921875\n",
      "\n",
      "episode 8, val func loss 0.18272922933101654\n",
      "\n",
      "episode 9, val func loss 0.19215364754199982\n",
      "\n",
      "episode 10, val func loss 0.1437394767999649\n",
      "\n",
      "episode 11, val func loss 0.17475886642932892\n",
      "\n",
      "episode 12, val func loss 0.13554447889328003\n",
      "\n",
      "episode 13, val func loss 0.20709195733070374\n",
      "\n",
      "episode 14, val func loss 0.17784222960472107\n",
      "\n",
      "episode 15, val func loss 0.18466247618198395\n",
      "\n",
      "episode 16, val func loss 0.1760520488023758\n",
      "\n",
      "Val func train loss in epoch 11:0.17317561618983746\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17243605852127075\n",
      "\n",
      "episode 2, val func loss 0.18350501358509064\n",
      "\n",
      "episode 3, val func loss 0.15660756826400757\n",
      "\n",
      "episode 4, val func loss 0.14120794832706451\n",
      "\n",
      "episode 5, val func loss 0.14539502561092377\n",
      "\n",
      "episode 6, val func loss 0.20222598314285278\n",
      "\n",
      "episode 7, val func loss 0.1450047791004181\n",
      "\n",
      "episode 8, val func loss 0.20287452638149261\n",
      "\n",
      "episode 9, val func loss 0.17783604562282562\n",
      "\n",
      "episode 10, val func loss 0.17657026648521423\n",
      "\n",
      "episode 11, val func loss 0.19161701202392578\n",
      "\n",
      "episode 12, val func loss 0.15121500194072723\n",
      "\n",
      "episode 13, val func loss 0.13026434183120728\n",
      "\n",
      "episode 14, val func loss 0.18526029586791992\n",
      "\n",
      "episode 15, val func loss 0.18192316591739655\n",
      "\n",
      "episode 16, val func loss 0.21681630611419678\n",
      "\n",
      "Val func train loss in epoch 12:0.17254745867103338\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.145056813955307\n",
      "\n",
      "episode 2, val func loss 0.1819293051958084\n",
      "\n",
      "episode 3, val func loss 0.19135786592960358\n",
      "\n",
      "episode 4, val func loss 0.21328993141651154\n",
      "\n",
      "episode 5, val func loss 0.19966362416744232\n",
      "\n",
      "episode 6, val func loss 0.20248661935329437\n",
      "\n",
      "episode 7, val func loss 0.18488135933876038\n",
      "\n",
      "episode 8, val func loss 0.15084366500377655\n",
      "\n",
      "episode 9, val func loss 0.14633658528327942\n",
      "\n",
      "episode 10, val func loss 0.18180003762245178\n",
      "\n",
      "episode 11, val func loss 0.13410939276218414\n",
      "\n",
      "episode 12, val func loss 0.14980770647525787\n",
      "\n",
      "episode 13, val func loss 0.17308098077774048\n",
      "\n",
      "episode 14, val func loss 0.17721955478191376\n",
      "\n",
      "episode 15, val func loss 0.18368978798389435\n",
      "\n",
      "episode 16, val func loss 0.1565699279308319\n",
      "\n",
      "Val func train loss in epoch 13:0.17325769737362862\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17513437569141388\n",
      "\n",
      "episode 2, val func loss 0.14312849938869476\n",
      "\n",
      "episode 3, val func loss 0.17775556445121765\n",
      "\n",
      "episode 4, val func loss 0.18702936172485352\n",
      "\n",
      "episode 5, val func loss 0.20541167259216309\n",
      "\n",
      "episode 6, val func loss 0.14596857130527496\n",
      "\n",
      "episode 7, val func loss 0.1489388793706894\n",
      "\n",
      "episode 8, val func loss 0.17657285928726196\n",
      "\n",
      "episode 9, val func loss 0.15583163499832153\n",
      "\n",
      "episode 10, val func loss 0.18885090947151184\n",
      "\n",
      "episode 11, val func loss 0.13978345692157745\n",
      "\n",
      "episode 12, val func loss 0.19985663890838623\n",
      "\n",
      "episode 13, val func loss 0.1822834461927414\n",
      "\n",
      "episode 14, val func loss 0.21411538124084473\n",
      "\n",
      "episode 15, val func loss 0.18405331671237946\n",
      "\n",
      "episode 16, val func loss 0.13796788454055786\n",
      "\n",
      "Val func train loss in epoch 14:0.1726676532998681\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1819400042295456\n",
      "\n",
      "episode 2, val func loss 0.1833169013261795\n",
      "\n",
      "episode 3, val func loss 0.13790252804756165\n",
      "\n",
      "episode 4, val func loss 0.19171354174613953\n",
      "\n",
      "episode 5, val func loss 0.12961752712726593\n",
      "\n",
      "episode 6, val func loss 0.14745241403579712\n",
      "\n",
      "episode 7, val func loss 0.22212837636470795\n",
      "\n",
      "episode 8, val func loss 0.15283387899398804\n",
      "\n",
      "episode 9, val func loss 0.15569643676280975\n",
      "\n",
      "episode 10, val func loss 0.20467771589756012\n",
      "\n",
      "episode 11, val func loss 0.17802157998085022\n",
      "\n",
      "episode 12, val func loss 0.18491530418395996\n",
      "\n",
      "episode 13, val func loss 0.17674964666366577\n",
      "\n",
      "episode 14, val func loss 0.17152591049671173\n",
      "\n",
      "episode 15, val func loss 0.1999724954366684\n",
      "\n",
      "episode 16, val func loss 0.15042679011821747\n",
      "\n",
      "Val func train loss in epoch 15:0.1730556907132268\n",
      "***********************TIME WAS 4.994479346275329 min*****************************\n",
      "\n",
      "**********************ROUND 105 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.030617641285061836\n",
      "\n",
      "episode 2, policy loss 0.0259564109146595\n",
      "\n",
      "episode 3, policy loss -0.034846458584070206\n",
      "\n",
      "episode 4, policy loss 0.017307326197624207\n",
      "\n",
      "episode 5, policy loss 0.00738922692835331\n",
      "\n",
      "episode 6, policy loss -0.00805586762726307\n",
      "\n",
      "episode 7, policy loss -0.026566660031676292\n",
      "\n",
      "episode 8, policy loss 0.008041161112487316\n",
      "\n",
      "episode 9, policy loss -0.050341129302978516\n",
      "\n",
      "episode 10, policy loss -0.061675652861595154\n",
      "\n",
      "episode 11, policy loss 0.022969195619225502\n",
      "\n",
      "episode 12, policy loss -0.04630114510655403\n",
      "\n",
      "episode 13, policy loss -0.03386098891496658\n",
      "\n",
      "episode 14, policy loss 0.009422073140740395\n",
      "\n",
      "episode 15, policy loss 0.0244375579059124\n",
      "\n",
      "episode 16, policy loss -0.028969140723347664\n",
      "\n",
      "Policy train loss in epoch 0:-0.00902977812802419\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.03449874743819237\n",
      "\n",
      "episode 2, policy loss -0.051698170602321625\n",
      "\n",
      "episode 3, policy loss 0.02355671487748623\n",
      "\n",
      "episode 4, policy loss -0.06314385682344437\n",
      "\n",
      "episode 5, policy loss 0.007302552927285433\n",
      "\n",
      "episode 6, policy loss -0.02835001051425934\n",
      "\n",
      "episode 7, policy loss -0.03216949477791786\n",
      "\n",
      "episode 8, policy loss -0.009205128066241741\n",
      "\n",
      "episode 9, policy loss 0.007349500898271799\n",
      "\n",
      "episode 10, policy loss 0.020553182810544968\n",
      "\n",
      "episode 11, policy loss 0.022957919165492058\n",
      "\n",
      "episode 12, policy loss -0.04845630005002022\n",
      "\n",
      "episode 13, policy loss 0.014758095145225525\n",
      "\n",
      "episode 14, policy loss 0.0055010137148201466\n",
      "\n",
      "episode 15, policy loss 0.022496147081255913\n",
      "\n",
      "episode 16, policy loss -0.041217952966690063\n",
      "\n",
      "Policy train loss in epoch 1:-0.011516533413669094\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.02290675789117813\n",
      "\n",
      "episode 2, policy loss 0.008421490900218487\n",
      "\n",
      "episode 3, policy loss 0.007866747677326202\n",
      "\n",
      "episode 4, policy loss 0.022409718483686447\n",
      "\n",
      "episode 5, policy loss -0.009922315366566181\n",
      "\n",
      "episode 6, policy loss 0.02066987007856369\n",
      "\n",
      "episode 7, policy loss 0.014665923081338406\n",
      "\n",
      "episode 8, policy loss -0.041796982288360596\n",
      "\n",
      "episode 9, policy loss -0.02873326651751995\n",
      "\n",
      "episode 10, policy loss 0.005159835331141949\n",
      "\n",
      "episode 11, policy loss 0.021842634305357933\n",
      "\n",
      "episode 12, policy loss -0.03290007635951042\n",
      "\n",
      "episode 13, policy loss -0.06364323198795319\n",
      "\n",
      "episode 14, policy loss -0.0493272989988327\n",
      "\n",
      "episode 15, policy loss -0.038371652364730835\n",
      "\n",
      "episode 16, policy loss -0.053319305181503296\n",
      "\n",
      "Policy train loss in epoch 2:-0.01212944695726037\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.06393935531377792\n",
      "\n",
      "episode 2, policy loss -0.03823326528072357\n",
      "\n",
      "episode 3, policy loss 0.013284305110573769\n",
      "\n",
      "episode 4, policy loss -0.02804848551750183\n",
      "\n",
      "episode 5, policy loss -0.010534677654504776\n",
      "\n",
      "episode 6, policy loss 0.007529905065894127\n",
      "\n",
      "episode 7, policy loss -0.05370975658297539\n",
      "\n",
      "episode 8, policy loss -0.04081873968243599\n",
      "\n",
      "episode 9, policy loss 0.021837368607521057\n",
      "\n",
      "episode 10, policy loss 0.022946389392018318\n",
      "\n",
      "episode 11, policy loss 0.0206900667399168\n",
      "\n",
      "episode 12, policy loss 0.02225477620959282\n",
      "\n",
      "episode 13, policy loss -0.04928196966648102\n",
      "\n",
      "episode 14, policy loss -0.03273261711001396\n",
      "\n",
      "episode 15, policy loss 0.005183567758649588\n",
      "\n",
      "episode 16, policy loss 0.007879208773374557\n",
      "\n",
      "Policy train loss in epoch 3:-0.012230829946929589\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.20103515684604645\n",
      "\n",
      "episode 2, val func loss 0.1719793826341629\n",
      "\n",
      "episode 3, val func loss 0.16820156574249268\n",
      "\n",
      "episode 4, val func loss 0.21155685186386108\n",
      "\n",
      "episode 5, val func loss 0.2058390974998474\n",
      "\n",
      "episode 6, val func loss 0.18082237243652344\n",
      "\n",
      "episode 7, val func loss 0.20360027253627777\n",
      "\n",
      "episode 8, val func loss 0.20423319935798645\n",
      "\n",
      "episode 9, val func loss 0.20256872475147247\n",
      "\n",
      "episode 10, val func loss 0.18039724230766296\n",
      "\n",
      "episode 11, val func loss 0.1789126694202423\n",
      "\n",
      "episode 12, val func loss 0.1962691694498062\n",
      "\n",
      "episode 13, val func loss 0.18858428299427032\n",
      "\n",
      "episode 14, val func loss 0.1627965271472931\n",
      "\n",
      "episode 15, val func loss 0.1691306233406067\n",
      "\n",
      "episode 16, val func loss 0.17137253284454346\n",
      "\n",
      "Val func train loss in epoch 0:0.18733122944831848\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17272713780403137\n",
      "\n",
      "episode 2, val func loss 0.21337756514549255\n",
      "\n",
      "episode 3, val func loss 0.17899127304553986\n",
      "\n",
      "episode 4, val func loss 0.20505391061306\n",
      "\n",
      "episode 5, val func loss 0.20510682463645935\n",
      "\n",
      "episode 6, val func loss 0.16980624198913574\n",
      "\n",
      "episode 7, val func loss 0.17746491730213165\n",
      "\n",
      "episode 8, val func loss 0.20234809815883636\n",
      "\n",
      "episode 9, val func loss 0.17133694887161255\n",
      "\n",
      "episode 10, val func loss 0.20094360411167145\n",
      "\n",
      "episode 11, val func loss 0.19021350145339966\n",
      "\n",
      "episode 12, val func loss 0.16110070049762726\n",
      "\n",
      "episode 13, val func loss 0.2024005800485611\n",
      "\n",
      "episode 14, val func loss 0.19537845253944397\n",
      "\n",
      "episode 15, val func loss 0.18171437084674835\n",
      "\n",
      "episode 16, val func loss 0.1688748151063919\n",
      "\n",
      "Val func train loss in epoch 1:0.18730243388563395\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.16241729259490967\n",
      "\n",
      "episode 2, val func loss 0.1796843558549881\n",
      "\n",
      "episode 3, val func loss 0.19101087749004364\n",
      "\n",
      "episode 4, val func loss 0.17676421999931335\n",
      "\n",
      "episode 5, val func loss 0.20441743731498718\n",
      "\n",
      "episode 6, val func loss 0.21522165834903717\n",
      "\n",
      "episode 7, val func loss 0.19168689846992493\n",
      "\n",
      "episode 8, val func loss 0.18224044144153595\n",
      "\n",
      "episode 9, val func loss 0.20304356515407562\n",
      "\n",
      "episode 10, val func loss 0.17004625499248505\n",
      "\n",
      "episode 11, val func loss 0.16932597756385803\n",
      "\n",
      "episode 12, val func loss 0.20220118761062622\n",
      "\n",
      "episode 13, val func loss 0.2065458744764328\n",
      "\n",
      "episode 14, val func loss 0.17292392253875732\n",
      "\n",
      "episode 15, val func loss 0.1730094999074936\n",
      "\n",
      "episode 16, val func loss 0.20143409073352814\n",
      "\n",
      "Val func train loss in epoch 2:0.1876233471557498\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20941859483718872\n",
      "\n",
      "episode 2, val func loss 0.18771988153457642\n",
      "\n",
      "episode 3, val func loss 0.17710791528224945\n",
      "\n",
      "episode 4, val func loss 0.16117137670516968\n",
      "\n",
      "episode 5, val func loss 0.17089514434337616\n",
      "\n",
      "episode 6, val func loss 0.20676352083683014\n",
      "\n",
      "episode 7, val func loss 0.20238439738750458\n",
      "\n",
      "episode 8, val func loss 0.20270273089408875\n",
      "\n",
      "episode 9, val func loss 0.17252327501773834\n",
      "\n",
      "episode 10, val func loss 0.18225853145122528\n",
      "\n",
      "episode 11, val func loss 0.17828930914402008\n",
      "\n",
      "episode 12, val func loss 0.20428943634033203\n",
      "\n",
      "episode 13, val func loss 0.1951141655445099\n",
      "\n",
      "episode 14, val func loss 0.16937053203582764\n",
      "\n",
      "episode 15, val func loss 0.20092655718326569\n",
      "\n",
      "episode 16, val func loss 0.16989809274673462\n",
      "\n",
      "Val func train loss in epoch 3:0.18692709133028984\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1796044111251831\n",
      "\n",
      "episode 2, val func loss 0.20317679643630981\n",
      "\n",
      "episode 3, val func loss 0.17043675482273102\n",
      "\n",
      "episode 4, val func loss 0.21376635134220123\n",
      "\n",
      "episode 5, val func loss 0.20274046063423157\n",
      "\n",
      "episode 6, val func loss 0.19354797899723053\n",
      "\n",
      "episode 7, val func loss 0.1868273913860321\n",
      "\n",
      "episode 8, val func loss 0.20207177102565765\n",
      "\n",
      "episode 9, val func loss 0.17627322673797607\n",
      "\n",
      "episode 10, val func loss 0.200593501329422\n",
      "\n",
      "episode 11, val func loss 0.16604699194431305\n",
      "\n",
      "episode 12, val func loss 0.1797846108675003\n",
      "\n",
      "episode 13, val func loss 0.16809435188770294\n",
      "\n",
      "episode 14, val func loss 0.17242971062660217\n",
      "\n",
      "episode 15, val func loss 0.205350860953331\n",
      "\n",
      "episode 16, val func loss 0.16932593286037445\n",
      "\n",
      "Val func train loss in epoch 4:0.18687944393604994\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.20577330887317657\n",
      "\n",
      "episode 2, val func loss 0.17289777100086212\n",
      "\n",
      "episode 3, val func loss 0.2021235227584839\n",
      "\n",
      "episode 4, val func loss 0.16913773119449615\n",
      "\n",
      "episode 5, val func loss 0.20429933071136475\n",
      "\n",
      "episode 6, val func loss 0.2073981761932373\n",
      "\n",
      "episode 7, val func loss 0.2143746316432953\n",
      "\n",
      "episode 8, val func loss 0.17887066304683685\n",
      "\n",
      "episode 9, val func loss 0.18380366265773773\n",
      "\n",
      "episode 10, val func loss 0.20380114018917084\n",
      "\n",
      "episode 11, val func loss 0.18261799216270447\n",
      "\n",
      "episode 12, val func loss 0.17207872867584229\n",
      "\n",
      "episode 13, val func loss 0.162250816822052\n",
      "\n",
      "episode 14, val func loss 0.17116165161132812\n",
      "\n",
      "episode 15, val func loss 0.19048428535461426\n",
      "\n",
      "episode 16, val func loss 0.19465886056423187\n",
      "\n",
      "Val func train loss in epoch 5:0.18848326709121466\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.2050497680902481\n",
      "\n",
      "episode 2, val func loss 0.16895242035388947\n",
      "\n",
      "episode 3, val func loss 0.17096282541751862\n",
      "\n",
      "episode 4, val func loss 0.2068248838186264\n",
      "\n",
      "episode 5, val func loss 0.19380085170269012\n",
      "\n",
      "episode 6, val func loss 0.20377841591835022\n",
      "\n",
      "episode 7, val func loss 0.1809282749891281\n",
      "\n",
      "episode 8, val func loss 0.18883585929870605\n",
      "\n",
      "episode 9, val func loss 0.2086014300584793\n",
      "\n",
      "episode 10, val func loss 0.1725948452949524\n",
      "\n",
      "episode 11, val func loss 0.17872405052185059\n",
      "\n",
      "episode 12, val func loss 0.20406150817871094\n",
      "\n",
      "episode 13, val func loss 0.17136815190315247\n",
      "\n",
      "episode 14, val func loss 0.20122797787189484\n",
      "\n",
      "episode 15, val func loss 0.1632959395647049\n",
      "\n",
      "episode 16, val func loss 0.1820726990699768\n",
      "\n",
      "Val func train loss in epoch 6:0.18756749387830496\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18018803000450134\n",
      "\n",
      "episode 2, val func loss 0.20247045159339905\n",
      "\n",
      "episode 3, val func loss 0.18911483883857727\n",
      "\n",
      "episode 4, val func loss 0.16289980709552765\n",
      "\n",
      "episode 5, val func loss 0.1938754767179489\n",
      "\n",
      "episode 6, val func loss 0.20530164241790771\n",
      "\n",
      "episode 7, val func loss 0.20274876058101654\n",
      "\n",
      "episode 8, val func loss 0.1708824783563614\n",
      "\n",
      "episode 9, val func loss 0.20906567573547363\n",
      "\n",
      "episode 10, val func loss 0.17142321169376373\n",
      "\n",
      "episode 11, val func loss 0.18192635476589203\n",
      "\n",
      "episode 12, val func loss 0.20678570866584778\n",
      "\n",
      "episode 13, val func loss 0.20025116205215454\n",
      "\n",
      "episode 14, val func loss 0.17203547060489655\n",
      "\n",
      "episode 15, val func loss 0.16903282701969147\n",
      "\n",
      "episode 16, val func loss 0.1776362806558609\n",
      "\n",
      "Val func train loss in epoch 7:0.18722738604992628\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.2034108191728592\n",
      "\n",
      "episode 2, val func loss 0.17143265902996063\n",
      "\n",
      "episode 3, val func loss 0.1622869372367859\n",
      "\n",
      "episode 4, val func loss 0.17614060640335083\n",
      "\n",
      "episode 5, val func loss 0.18027183413505554\n",
      "\n",
      "episode 6, val func loss 0.1940792202949524\n",
      "\n",
      "episode 7, val func loss 0.2036198377609253\n",
      "\n",
      "episode 8, val func loss 0.21413929760456085\n",
      "\n",
      "episode 9, val func loss 0.1709885597229004\n",
      "\n",
      "episode 10, val func loss 0.17144696414470673\n",
      "\n",
      "episode 11, val func loss 0.20419780910015106\n",
      "\n",
      "episode 12, val func loss 0.18365120887756348\n",
      "\n",
      "episode 13, val func loss 0.16969947516918182\n",
      "\n",
      "episode 14, val func loss 0.20069999992847443\n",
      "\n",
      "episode 15, val func loss 0.19094730913639069\n",
      "\n",
      "episode 16, val func loss 0.20449265837669373\n",
      "\n",
      "Val func train loss in epoch 8:0.18759407475590706\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17085731029510498\n",
      "\n",
      "episode 2, val func loss 0.1697198897600174\n",
      "\n",
      "episode 3, val func loss 0.17712946236133575\n",
      "\n",
      "episode 4, val func loss 0.20768427848815918\n",
      "\n",
      "episode 5, val func loss 0.1889367401599884\n",
      "\n",
      "episode 6, val func loss 0.1798749566078186\n",
      "\n",
      "episode 7, val func loss 0.1807073950767517\n",
      "\n",
      "episode 8, val func loss 0.1697290539741516\n",
      "\n",
      "episode 9, val func loss 0.20530806481838226\n",
      "\n",
      "episode 10, val func loss 0.20497430860996246\n",
      "\n",
      "episode 11, val func loss 0.16979946196079254\n",
      "\n",
      "episode 12, val func loss 0.19371099770069122\n",
      "\n",
      "episode 13, val func loss 0.16379860043525696\n",
      "\n",
      "episode 14, val func loss 0.20173130929470062\n",
      "\n",
      "episode 15, val func loss 0.20996877551078796\n",
      "\n",
      "episode 16, val func loss 0.19954600930213928\n",
      "\n",
      "Val func train loss in epoch 9:0.18709228839725256\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18444643914699554\n",
      "\n",
      "episode 2, val func loss 0.1660223752260208\n",
      "\n",
      "episode 3, val func loss 0.1910281777381897\n",
      "\n",
      "episode 4, val func loss 0.1731870323419571\n",
      "\n",
      "episode 5, val func loss 0.16931702196598053\n",
      "\n",
      "episode 6, val func loss 0.20930346846580505\n",
      "\n",
      "episode 7, val func loss 0.2020971029996872\n",
      "\n",
      "episode 8, val func loss 0.17052437365055084\n",
      "\n",
      "episode 9, val func loss 0.18170465528964996\n",
      "\n",
      "episode 10, val func loss 0.20422737300395966\n",
      "\n",
      "episode 11, val func loss 0.175562784075737\n",
      "\n",
      "episode 12, val func loss 0.20272041857242584\n",
      "\n",
      "episode 13, val func loss 0.20749859511852264\n",
      "\n",
      "episode 14, val func loss 0.20356924831867218\n",
      "\n",
      "episode 15, val func loss 0.19356440007686615\n",
      "\n",
      "episode 16, val func loss 0.17187297344207764\n",
      "\n",
      "Val func train loss in epoch 10:0.18791540246456861\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.2101079672574997\n",
      "\n",
      "episode 2, val func loss 0.1695164144039154\n",
      "\n",
      "episode 3, val func loss 0.19756513833999634\n",
      "\n",
      "episode 4, val func loss 0.2013801485300064\n",
      "\n",
      "episode 5, val func loss 0.17378254234790802\n",
      "\n",
      "episode 6, val func loss 0.20162856578826904\n",
      "\n",
      "episode 7, val func loss 0.16293740272521973\n",
      "\n",
      "episode 8, val func loss 0.1773861050605774\n",
      "\n",
      "episode 9, val func loss 0.18965640664100647\n",
      "\n",
      "episode 10, val func loss 0.17052794992923737\n",
      "\n",
      "episode 11, val func loss 0.20365871489048004\n",
      "\n",
      "episode 12, val func loss 0.2070254236459732\n",
      "\n",
      "episode 13, val func loss 0.18029747903347015\n",
      "\n",
      "episode 14, val func loss 0.16854159533977509\n",
      "\n",
      "episode 15, val func loss 0.18013125658035278\n",
      "\n",
      "episode 16, val func loss 0.20304328203201294\n",
      "\n",
      "Val func train loss in epoch 11:0.18732414953410625\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1758534461259842\n",
      "\n",
      "episode 2, val func loss 0.1713830530643463\n",
      "\n",
      "episode 3, val func loss 0.18001991510391235\n",
      "\n",
      "episode 4, val func loss 0.16387447714805603\n",
      "\n",
      "episode 5, val func loss 0.16962511837482452\n",
      "\n",
      "episode 6, val func loss 0.18154242634773254\n",
      "\n",
      "episode 7, val func loss 0.1696435958147049\n",
      "\n",
      "episode 8, val func loss 0.2053864300251007\n",
      "\n",
      "episode 9, val func loss 0.20618683099746704\n",
      "\n",
      "episode 10, val func loss 0.20433640480041504\n",
      "\n",
      "episode 11, val func loss 0.1889069825410843\n",
      "\n",
      "episode 12, val func loss 0.17178693413734436\n",
      "\n",
      "episode 13, val func loss 0.20105530321598053\n",
      "\n",
      "episode 14, val func loss 0.21106743812561035\n",
      "\n",
      "episode 15, val func loss 0.20050720870494843\n",
      "\n",
      "episode 16, val func loss 0.1977674663066864\n",
      "\n",
      "Val func train loss in epoch 12:0.18743393942713737\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.20283173024654388\n",
      "\n",
      "episode 2, val func loss 0.19200222194194794\n",
      "\n",
      "episode 3, val func loss 0.2008318156003952\n",
      "\n",
      "episode 4, val func loss 0.17092189192771912\n",
      "\n",
      "episode 5, val func loss 0.18309035897254944\n",
      "\n",
      "episode 6, val func loss 0.17305032908916473\n",
      "\n",
      "episode 7, val func loss 0.20617493987083435\n",
      "\n",
      "episode 8, val func loss 0.17725227773189545\n",
      "\n",
      "episode 9, val func loss 0.16327963769435883\n",
      "\n",
      "episode 10, val func loss 0.20712871849536896\n",
      "\n",
      "episode 11, val func loss 0.17119328677654266\n",
      "\n",
      "episode 12, val func loss 0.20709919929504395\n",
      "\n",
      "episode 13, val func loss 0.18006542325019836\n",
      "\n",
      "episode 14, val func loss 0.19438084959983826\n",
      "\n",
      "episode 15, val func loss 0.21014492213726044\n",
      "\n",
      "episode 16, val func loss 0.1740463525056839\n",
      "\n",
      "Val func train loss in epoch 13:0.1883433721959591\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.16419006884098053\n",
      "\n",
      "episode 2, val func loss 0.20212309062480927\n",
      "\n",
      "episode 3, val func loss 0.18285100162029266\n",
      "\n",
      "episode 4, val func loss 0.20891687273979187\n",
      "\n",
      "episode 5, val func loss 0.17113983631134033\n",
      "\n",
      "episode 6, val func loss 0.18968002498149872\n",
      "\n",
      "episode 7, val func loss 0.20504775643348694\n",
      "\n",
      "episode 8, val func loss 0.20212659239768982\n",
      "\n",
      "episode 9, val func loss 0.1714380383491516\n",
      "\n",
      "episode 10, val func loss 0.204923614859581\n",
      "\n",
      "episode 11, val func loss 0.17080673575401306\n",
      "\n",
      "episode 12, val func loss 0.19508805871009827\n",
      "\n",
      "episode 13, val func loss 0.20240820944309235\n",
      "\n",
      "episode 14, val func loss 0.18082618713378906\n",
      "\n",
      "episode 15, val func loss 0.17644745111465454\n",
      "\n",
      "episode 16, val func loss 0.1691512018442154\n",
      "\n",
      "Val func train loss in epoch 14:0.18732279632240534\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.16246424615383148\n",
      "\n",
      "episode 2, val func loss 0.20258012413978577\n",
      "\n",
      "episode 3, val func loss 0.17594532668590546\n",
      "\n",
      "episode 4, val func loss 0.1943613439798355\n",
      "\n",
      "episode 5, val func loss 0.1691570281982422\n",
      "\n",
      "episode 6, val func loss 0.2068060040473938\n",
      "\n",
      "episode 7, val func loss 0.20268641412258148\n",
      "\n",
      "episode 8, val func loss 0.20182622969150543\n",
      "\n",
      "episode 9, val func loss 0.20377878844738007\n",
      "\n",
      "episode 10, val func loss 0.17386534810066223\n",
      "\n",
      "episode 11, val func loss 0.19010086357593536\n",
      "\n",
      "episode 12, val func loss 0.17050378024578094\n",
      "\n",
      "episode 13, val func loss 0.1720309853553772\n",
      "\n",
      "episode 14, val func loss 0.17884019017219543\n",
      "\n",
      "episode 15, val func loss 0.21331670880317688\n",
      "\n",
      "episode 16, val func loss 0.18233859539031982\n",
      "\n",
      "Val func train loss in epoch 15:0.18753762356936932\n",
      "***********************TIME WAS 4.9927809556325276 min*****************************\n",
      "\n",
      "**********************ROUND 106 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.02488952875137329\n",
      "\n",
      "episode 2, policy loss -0.004396798554807901\n",
      "\n",
      "episode 3, policy loss -0.014639660716056824\n",
      "\n",
      "episode 4, policy loss -0.006474586669355631\n",
      "\n",
      "episode 5, policy loss -0.07321039587259293\n",
      "\n",
      "episode 6, policy loss 0.0055026947520673275\n",
      "\n",
      "episode 7, policy loss -0.041836198419332504\n",
      "\n",
      "episode 8, policy loss -0.0323801264166832\n",
      "\n",
      "episode 9, policy loss -0.016638344153761864\n",
      "\n",
      "episode 10, policy loss -0.007854054681956768\n",
      "\n",
      "episode 11, policy loss 0.03084750287234783\n",
      "\n",
      "episode 12, policy loss -0.06154785677790642\n",
      "\n",
      "episode 13, policy loss -0.03770747408270836\n",
      "\n",
      "episode 14, policy loss -0.028227724134922028\n",
      "\n",
      "episode 15, policy loss -0.03224451467394829\n",
      "\n",
      "episode 16, policy loss -0.04763210937380791\n",
      "\n",
      "Policy train loss in epoch 0:-0.02458307347842492\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.03307930380105972\n",
      "\n",
      "episode 2, policy loss -0.03313719853758812\n",
      "\n",
      "episode 3, policy loss -0.009182158857584\n",
      "\n",
      "episode 4, policy loss -0.06235255300998688\n",
      "\n",
      "episode 5, policy loss -0.0755191296339035\n",
      "\n",
      "episode 6, policy loss -0.033128201961517334\n",
      "\n",
      "episode 7, policy loss 0.030422871932387352\n",
      "\n",
      "episode 8, policy loss -0.048697736114263535\n",
      "\n",
      "episode 9, policy loss -0.012388582341372967\n",
      "\n",
      "episode 10, policy loss 0.005137547384947538\n",
      "\n",
      "episode 11, policy loss -0.039226822555065155\n",
      "\n",
      "episode 12, policy loss -0.019073359668254852\n",
      "\n",
      "episode 13, policy loss -0.017523860558867455\n",
      "\n",
      "episode 14, policy loss -0.009694335050880909\n",
      "\n",
      "episode 15, policy loss -0.041297852993011475\n",
      "\n",
      "episode 16, policy loss -0.031170496717095375\n",
      "\n",
      "Policy train loss in epoch 1:-0.026869448280194774\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.03444033861160278\n",
      "\n",
      "episode 2, policy loss 0.030024787411093712\n",
      "\n",
      "episode 3, policy loss -0.06165660545229912\n",
      "\n",
      "episode 4, policy loss -0.009822797030210495\n",
      "\n",
      "episode 5, policy loss -0.019175725057721138\n",
      "\n",
      "episode 6, policy loss -0.04172815382480621\n",
      "\n",
      "episode 7, policy loss -0.07705283164978027\n",
      "\n",
      "episode 8, policy loss 0.004709712695330381\n",
      "\n",
      "episode 9, policy loss -0.01215306669473648\n",
      "\n",
      "episode 10, policy loss -0.017408503219485283\n",
      "\n",
      "episode 11, policy loss -0.049354441463947296\n",
      "\n",
      "episode 12, policy loss -0.03345475718379021\n",
      "\n",
      "episode 13, policy loss -0.03302307426929474\n",
      "\n",
      "episode 14, policy loss -0.009464702568948269\n",
      "\n",
      "episode 15, policy loss -0.04048417881131172\n",
      "\n",
      "episode 16, policy loss -0.03115740977227688\n",
      "\n",
      "Policy train loss in epoch 2:-0.027227630343986675\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.0038506377022713423\n",
      "\n",
      "episode 2, policy loss -0.04056176543235779\n",
      "\n",
      "episode 3, policy loss -0.03270386531949043\n",
      "\n",
      "episode 4, policy loss -0.034824758768081665\n",
      "\n",
      "episode 5, policy loss -0.019432036206126213\n",
      "\n",
      "episode 6, policy loss -0.04927881807088852\n",
      "\n",
      "episode 7, policy loss -0.01744190603494644\n",
      "\n",
      "episode 8, policy loss -0.0416620709002018\n",
      "\n",
      "episode 9, policy loss -0.06298673152923584\n",
      "\n",
      "episode 10, policy loss 0.030343730002641678\n",
      "\n",
      "episode 11, policy loss -0.010430724360048771\n",
      "\n",
      "episode 12, policy loss -0.012580079026520252\n",
      "\n",
      "episode 13, policy loss -0.010724658146500587\n",
      "\n",
      "episode 14, policy loss -0.032989904284477234\n",
      "\n",
      "episode 15, policy loss -0.07667339593172073\n",
      "\n",
      "episode 16, policy loss -0.030819036066532135\n",
      "\n",
      "Policy train loss in epoch 3:-0.027432211398263462\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.18896335363388062\n",
      "\n",
      "episode 2, val func loss 0.1416650116443634\n",
      "\n",
      "episode 3, val func loss 0.15330365300178528\n",
      "\n",
      "episode 4, val func loss 0.19673791527748108\n",
      "\n",
      "episode 5, val func loss 0.20330099761486053\n",
      "\n",
      "episode 6, val func loss 0.1710144579410553\n",
      "\n",
      "episode 7, val func loss 0.2167455404996872\n",
      "\n",
      "episode 8, val func loss 0.2014651596546173\n",
      "\n",
      "episode 9, val func loss 0.18583688139915466\n",
      "\n",
      "episode 10, val func loss 0.17875348031520844\n",
      "\n",
      "episode 11, val func loss 0.1653311550617218\n",
      "\n",
      "episode 12, val func loss 0.19715018570423126\n",
      "\n",
      "episode 13, val func loss 0.1904199719429016\n",
      "\n",
      "episode 14, val func loss 0.19377131760120392\n",
      "\n",
      "episode 15, val func loss 0.17588651180267334\n",
      "\n",
      "episode 16, val func loss 0.18535195291042328\n",
      "\n",
      "Val func train loss in epoch 0:0.18410609662532806\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.16507650911808014\n",
      "\n",
      "episode 2, val func loss 0.20356759428977966\n",
      "\n",
      "episode 3, val func loss 0.14240321516990662\n",
      "\n",
      "episode 4, val func loss 0.20217439532279968\n",
      "\n",
      "episode 5, val func loss 0.15372861921787262\n",
      "\n",
      "episode 6, val func loss 0.16989576816558838\n",
      "\n",
      "episode 7, val func loss 0.19582022726535797\n",
      "\n",
      "episode 8, val func loss 0.19177661836147308\n",
      "\n",
      "episode 9, val func loss 0.192930206656456\n",
      "\n",
      "episode 10, val func loss 0.18676237761974335\n",
      "\n",
      "episode 11, val func loss 0.21665416657924652\n",
      "\n",
      "episode 12, val func loss 0.18590255081653595\n",
      "\n",
      "episode 13, val func loss 0.17552480101585388\n",
      "\n",
      "episode 14, val func loss 0.19817768037319183\n",
      "\n",
      "episode 15, val func loss 0.17844580113887787\n",
      "\n",
      "episode 16, val func loss 0.18869543075561523\n",
      "\n",
      "Val func train loss in epoch 1:0.18422099761664867\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19300375878810883\n",
      "\n",
      "episode 2, val func loss 0.18469901382923126\n",
      "\n",
      "episode 3, val func loss 0.21797135472297668\n",
      "\n",
      "episode 4, val func loss 0.1661558449268341\n",
      "\n",
      "episode 5, val func loss 0.1799132376909256\n",
      "\n",
      "episode 6, val func loss 0.17120184004306793\n",
      "\n",
      "episode 7, val func loss 0.14271020889282227\n",
      "\n",
      "episode 8, val func loss 0.18696756660938263\n",
      "\n",
      "episode 9, val func loss 0.2011324018239975\n",
      "\n",
      "episode 10, val func loss 0.18880032002925873\n",
      "\n",
      "episode 11, val func loss 0.17523130774497986\n",
      "\n",
      "episode 12, val func loss 0.19125093519687653\n",
      "\n",
      "episode 13, val func loss 0.1926109492778778\n",
      "\n",
      "episode 14, val func loss 0.20311222970485687\n",
      "\n",
      "episode 15, val func loss 0.15255150198936462\n",
      "\n",
      "episode 16, val func loss 0.19697348773479462\n",
      "\n",
      "Val func train loss in epoch 2:0.18401787243783474\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.17187172174453735\n",
      "\n",
      "episode 2, val func loss 0.1783323884010315\n",
      "\n",
      "episode 3, val func loss 0.2007930427789688\n",
      "\n",
      "episode 4, val func loss 0.15241000056266785\n",
      "\n",
      "episode 5, val func loss 0.14211371541023254\n",
      "\n",
      "episode 6, val func loss 0.21823431551456451\n",
      "\n",
      "episode 7, val func loss 0.18732278048992157\n",
      "\n",
      "episode 8, val func loss 0.20416496694087982\n",
      "\n",
      "episode 9, val func loss 0.18449941277503967\n",
      "\n",
      "episode 10, val func loss 0.17500504851341248\n",
      "\n",
      "episode 11, val func loss 0.19098809361457825\n",
      "\n",
      "episode 12, val func loss 0.1887921839952469\n",
      "\n",
      "episode 13, val func loss 0.1933085024356842\n",
      "\n",
      "episode 14, val func loss 0.19607403874397278\n",
      "\n",
      "episode 15, val func loss 0.19476202130317688\n",
      "\n",
      "episode 16, val func loss 0.1659282147884369\n",
      "\n",
      "Val func train loss in epoch 3:0.184037528000772\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18449094891548157\n",
      "\n",
      "episode 2, val func loss 0.1934288889169693\n",
      "\n",
      "episode 3, val func loss 0.20289748907089233\n",
      "\n",
      "episode 4, val func loss 0.19417031109333038\n",
      "\n",
      "episode 5, val func loss 0.19144487380981445\n",
      "\n",
      "episode 6, val func loss 0.1656666100025177\n",
      "\n",
      "episode 7, val func loss 0.14154832065105438\n",
      "\n",
      "episode 8, val func loss 0.18734227120876312\n",
      "\n",
      "episode 9, val func loss 0.1861453503370285\n",
      "\n",
      "episode 10, val func loss 0.2167300134897232\n",
      "\n",
      "episode 11, val func loss 0.19465027749538422\n",
      "\n",
      "episode 12, val func loss 0.1546405702829361\n",
      "\n",
      "episode 13, val func loss 0.17334532737731934\n",
      "\n",
      "episode 14, val func loss 0.2033640593290329\n",
      "\n",
      "episode 15, val func loss 0.1787451058626175\n",
      "\n",
      "episode 16, val func loss 0.1755601018667221\n",
      "\n",
      "Val func train loss in epoch 4:0.1840106574818492\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.20295649766921997\n",
      "\n",
      "episode 2, val func loss 0.21431715786457062\n",
      "\n",
      "episode 3, val func loss 0.1857111155986786\n",
      "\n",
      "episode 4, val func loss 0.1898251473903656\n",
      "\n",
      "episode 5, val func loss 0.19439224898815155\n",
      "\n",
      "episode 6, val func loss 0.1777811497449875\n",
      "\n",
      "episode 7, val func loss 0.17488351464271545\n",
      "\n",
      "episode 8, val func loss 0.1843625009059906\n",
      "\n",
      "episode 9, val func loss 0.17270827293395996\n",
      "\n",
      "episode 10, val func loss 0.1544579416513443\n",
      "\n",
      "episode 11, val func loss 0.18885904550552368\n",
      "\n",
      "episode 12, val func loss 0.19465701282024384\n",
      "\n",
      "episode 13, val func loss 0.1412617415189743\n",
      "\n",
      "episode 14, val func loss 0.2013954073190689\n",
      "\n",
      "episode 15, val func loss 0.1670624166727066\n",
      "\n",
      "episode 16, val func loss 0.19182628393173218\n",
      "\n",
      "Val func train loss in epoch 5:0.1835285909473896\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19623294472694397\n",
      "\n",
      "episode 2, val func loss 0.17512470483779907\n",
      "\n",
      "episode 3, val func loss 0.18860773742198944\n",
      "\n",
      "episode 4, val func loss 0.17888525128364563\n",
      "\n",
      "episode 5, val func loss 0.16616933047771454\n",
      "\n",
      "episode 6, val func loss 0.20216962695121765\n",
      "\n",
      "episode 7, val func loss 0.20163770020008087\n",
      "\n",
      "episode 8, val func loss 0.19302357733249664\n",
      "\n",
      "episode 9, val func loss 0.14337457716464996\n",
      "\n",
      "episode 10, val func loss 0.21637564897537231\n",
      "\n",
      "episode 11, val func loss 0.17109087109565735\n",
      "\n",
      "episode 12, val func loss 0.18446564674377441\n",
      "\n",
      "episode 13, val func loss 0.18893469870090485\n",
      "\n",
      "episode 14, val func loss 0.1929585188627243\n",
      "\n",
      "episode 15, val func loss 0.15306152403354645\n",
      "\n",
      "episode 16, val func loss 0.19228748977184296\n",
      "\n",
      "Val func train loss in epoch 6:0.18402499053627253\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.15170259773731232\n",
      "\n",
      "episode 2, val func loss 0.1906321942806244\n",
      "\n",
      "episode 3, val func loss 0.19398607313632965\n",
      "\n",
      "episode 4, val func loss 0.21720004081726074\n",
      "\n",
      "episode 5, val func loss 0.17676638066768646\n",
      "\n",
      "episode 6, val func loss 0.1857893019914627\n",
      "\n",
      "episode 7, val func loss 0.17106026411056519\n",
      "\n",
      "episode 8, val func loss 0.19299541413784027\n",
      "\n",
      "episode 9, val func loss 0.14575998485088348\n",
      "\n",
      "episode 10, val func loss 0.1999412178993225\n",
      "\n",
      "episode 11, val func loss 0.165017768740654\n",
      "\n",
      "episode 12, val func loss 0.17592425644397736\n",
      "\n",
      "episode 13, val func loss 0.20518042147159576\n",
      "\n",
      "episode 14, val func loss 0.1869581937789917\n",
      "\n",
      "episode 15, val func loss 0.19261497259140015\n",
      "\n",
      "episode 16, val func loss 0.18844331800937653\n",
      "\n",
      "Val func train loss in epoch 7:0.1837482750415802\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.19297268986701965\n",
      "\n",
      "episode 2, val func loss 0.17899289727210999\n",
      "\n",
      "episode 3, val func loss 0.21706710755825043\n",
      "\n",
      "episode 4, val func loss 0.1901591718196869\n",
      "\n",
      "episode 5, val func loss 0.18844518065452576\n",
      "\n",
      "episode 6, val func loss 0.16648174822330475\n",
      "\n",
      "episode 7, val func loss 0.17437736690044403\n",
      "\n",
      "episode 8, val func loss 0.14547736942768097\n",
      "\n",
      "episode 9, val func loss 0.17223531007766724\n",
      "\n",
      "episode 10, val func loss 0.1512988656759262\n",
      "\n",
      "episode 11, val func loss 0.19523923099040985\n",
      "\n",
      "episode 12, val func loss 0.18202203512191772\n",
      "\n",
      "episode 13, val func loss 0.20244374871253967\n",
      "\n",
      "episode 14, val func loss 0.18806470930576324\n",
      "\n",
      "episode 15, val func loss 0.1956270933151245\n",
      "\n",
      "episode 16, val func loss 0.20136359333992004\n",
      "\n",
      "Val func train loss in epoch 8:0.18389175739139318\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1437406688928604\n",
      "\n",
      "episode 2, val func loss 0.1931605339050293\n",
      "\n",
      "episode 3, val func loss 0.19510306417942047\n",
      "\n",
      "episode 4, val func loss 0.1880173236131668\n",
      "\n",
      "episode 5, val func loss 0.21763144433498383\n",
      "\n",
      "episode 6, val func loss 0.17565356194972992\n",
      "\n",
      "episode 7, val func loss 0.20053519308567047\n",
      "\n",
      "episode 8, val func loss 0.16498789191246033\n",
      "\n",
      "episode 9, val func loss 0.18477904796600342\n",
      "\n",
      "episode 10, val func loss 0.1537826955318451\n",
      "\n",
      "episode 11, val func loss 0.17925865948200226\n",
      "\n",
      "episode 12, val func loss 0.18986277282238007\n",
      "\n",
      "episode 13, val func loss 0.1860014945268631\n",
      "\n",
      "episode 14, val func loss 0.19402417540550232\n",
      "\n",
      "episode 15, val func loss 0.16965913772583008\n",
      "\n",
      "episode 16, val func loss 0.2030189335346222\n",
      "\n",
      "Val func train loss in epoch 9:0.18370103742927313\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19395442306995392\n",
      "\n",
      "episode 2, val func loss 0.21790967881679535\n",
      "\n",
      "episode 3, val func loss 0.1897817701101303\n",
      "\n",
      "episode 4, val func loss 0.1660180240869522\n",
      "\n",
      "episode 5, val func loss 0.19164052605628967\n",
      "\n",
      "episode 6, val func loss 0.18387283384799957\n",
      "\n",
      "episode 7, val func loss 0.18545785546302795\n",
      "\n",
      "episode 8, val func loss 0.15386474132537842\n",
      "\n",
      "episode 9, val func loss 0.17242592573165894\n",
      "\n",
      "episode 10, val func loss 0.20046524703502655\n",
      "\n",
      "episode 11, val func loss 0.17563366889953613\n",
      "\n",
      "episode 12, val func loss 0.2026727795600891\n",
      "\n",
      "episode 13, val func loss 0.18011319637298584\n",
      "\n",
      "episode 14, val func loss 0.1420162469148636\n",
      "\n",
      "episode 15, val func loss 0.1923244297504425\n",
      "\n",
      "episode 16, val func loss 0.18854060769081116\n",
      "\n",
      "Val func train loss in epoch 10:0.18354324717074633\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18153364956378937\n",
      "\n",
      "episode 2, val func loss 0.1877080500125885\n",
      "\n",
      "episode 3, val func loss 0.1874653846025467\n",
      "\n",
      "episode 4, val func loss 0.1905083954334259\n",
      "\n",
      "episode 5, val func loss 0.16724391281604767\n",
      "\n",
      "episode 6, val func loss 0.2007812112569809\n",
      "\n",
      "episode 7, val func loss 0.14651519060134888\n",
      "\n",
      "episode 8, val func loss 0.18559148907661438\n",
      "\n",
      "episode 9, val func loss 0.15314927697181702\n",
      "\n",
      "episode 10, val func loss 0.20383252203464508\n",
      "\n",
      "episode 11, val func loss 0.19309364259243011\n",
      "\n",
      "episode 12, val func loss 0.17403022944927216\n",
      "\n",
      "episode 13, val func loss 0.2184804230928421\n",
      "\n",
      "episode 14, val func loss 0.19281211495399475\n",
      "\n",
      "episode 15, val func loss 0.17016032338142395\n",
      "\n",
      "episode 16, val func loss 0.19503143429756165\n",
      "\n",
      "Val func train loss in epoch 11:0.18424607813358307\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19500403106212616\n",
      "\n",
      "episode 2, val func loss 0.17808906733989716\n",
      "\n",
      "episode 3, val func loss 0.20128093659877777\n",
      "\n",
      "episode 4, val func loss 0.19106701016426086\n",
      "\n",
      "episode 5, val func loss 0.1978565752506256\n",
      "\n",
      "episode 6, val func loss 0.19189780950546265\n",
      "\n",
      "episode 7, val func loss 0.18333004415035248\n",
      "\n",
      "episode 8, val func loss 0.1677756905555725\n",
      "\n",
      "episode 9, val func loss 0.18897029757499695\n",
      "\n",
      "episode 10, val func loss 0.1996525526046753\n",
      "\n",
      "episode 11, val func loss 0.1415414810180664\n",
      "\n",
      "episode 12, val func loss 0.1662493348121643\n",
      "\n",
      "episode 13, val func loss 0.21669282019138336\n",
      "\n",
      "episode 14, val func loss 0.18764348328113556\n",
      "\n",
      "episode 15, val func loss 0.15268965065479279\n",
      "\n",
      "episode 16, val func loss 0.17612333595752716\n",
      "\n",
      "Val func train loss in epoch 12:0.18349150754511356\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18617267906665802\n",
      "\n",
      "episode 2, val func loss 0.19161751866340637\n",
      "\n",
      "episode 3, val func loss 0.16939738392829895\n",
      "\n",
      "episode 4, val func loss 0.19146694242954254\n",
      "\n",
      "episode 5, val func loss 0.20011843740940094\n",
      "\n",
      "episode 6, val func loss 0.1657174974679947\n",
      "\n",
      "episode 7, val func loss 0.20423756539821625\n",
      "\n",
      "episode 8, val func loss 0.19418425858020782\n",
      "\n",
      "episode 9, val func loss 0.1767369955778122\n",
      "\n",
      "episode 10, val func loss 0.17864522337913513\n",
      "\n",
      "episode 11, val func loss 0.1865995228290558\n",
      "\n",
      "episode 12, val func loss 0.2175084799528122\n",
      "\n",
      "episode 13, val func loss 0.18861500918865204\n",
      "\n",
      "episode 14, val func loss 0.1475352942943573\n",
      "\n",
      "episode 15, val func loss 0.18850409984588623\n",
      "\n",
      "episode 16, val func loss 0.1519446223974228\n",
      "\n",
      "Val func train loss in epoch 13:0.1836875956505537\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1813684105873108\n",
      "\n",
      "episode 2, val func loss 0.1677028089761734\n",
      "\n",
      "episode 3, val func loss 0.20321187376976013\n",
      "\n",
      "episode 4, val func loss 0.1923009306192398\n",
      "\n",
      "episode 5, val func loss 0.16849112510681152\n",
      "\n",
      "episode 6, val func loss 0.19359837472438812\n",
      "\n",
      "episode 7, val func loss 0.1890372633934021\n",
      "\n",
      "episode 8, val func loss 0.19431938230991364\n",
      "\n",
      "episode 9, val func loss 0.14287832379341125\n",
      "\n",
      "episode 10, val func loss 0.17516076564788818\n",
      "\n",
      "episode 11, val func loss 0.15218502283096313\n",
      "\n",
      "episode 12, val func loss 0.1861269623041153\n",
      "\n",
      "episode 13, val func loss 0.1791096329689026\n",
      "\n",
      "episode 14, val func loss 0.19451282918453217\n",
      "\n",
      "episode 15, val func loss 0.2038324624300003\n",
      "\n",
      "episode 16, val func loss 0.21651451289653778\n",
      "\n",
      "Val func train loss in epoch 14:0.1837719175964594\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.193940669298172\n",
      "\n",
      "episode 2, val func loss 0.15294037759304047\n",
      "\n",
      "episode 3, val func loss 0.16661085188388824\n",
      "\n",
      "episode 4, val func loss 0.17816759645938873\n",
      "\n",
      "episode 5, val func loss 0.17556968331336975\n",
      "\n",
      "episode 6, val func loss 0.18652014434337616\n",
      "\n",
      "episode 7, val func loss 0.18721787631511688\n",
      "\n",
      "episode 8, val func loss 0.20334641635417938\n",
      "\n",
      "episode 9, val func loss 0.14384016394615173\n",
      "\n",
      "episode 10, val func loss 0.18500608205795288\n",
      "\n",
      "episode 11, val func loss 0.16875211894512177\n",
      "\n",
      "episode 12, val func loss 0.21904277801513672\n",
      "\n",
      "episode 13, val func loss 0.20174776017665863\n",
      "\n",
      "episode 14, val func loss 0.1929907351732254\n",
      "\n",
      "episode 15, val func loss 0.19306112825870514\n",
      "\n",
      "episode 16, val func loss 0.19068631529808044\n",
      "\n",
      "Val func train loss in epoch 15:0.18371504358947277\n",
      "***********************TIME WAS 4.995871325333913 min*****************************\n",
      "\n",
      "**********************ROUND 107 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.003108155680820346\n",
      "\n",
      "episode 2, policy loss -0.003873300040140748\n",
      "\n",
      "episode 3, policy loss -0.032393086701631546\n",
      "\n",
      "episode 4, policy loss -0.0047271098010241985\n",
      "\n",
      "episode 5, policy loss -0.017440112307667732\n",
      "\n",
      "episode 6, policy loss -0.04518098756670952\n",
      "\n",
      "episode 7, policy loss -0.013856761157512665\n",
      "\n",
      "episode 8, policy loss -0.0423031784594059\n",
      "\n",
      "episode 9, policy loss -0.00507368054240942\n",
      "\n",
      "episode 10, policy loss -0.049218613654375076\n",
      "\n",
      "episode 11, policy loss -0.01961360312998295\n",
      "\n",
      "episode 12, policy loss -0.0074221547693014145\n",
      "\n",
      "episode 13, policy loss -0.022460320964455605\n",
      "\n",
      "episode 14, policy loss -0.014891279861330986\n",
      "\n",
      "episode 15, policy loss -0.002177034504711628\n",
      "\n",
      "episode 16, policy loss -0.009973973035812378\n",
      "\n",
      "Policy train loss in epoch 0:-0.017968565050978214\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.020556924864649773\n",
      "\n",
      "episode 2, policy loss -0.008509175851941109\n",
      "\n",
      "episode 3, policy loss -0.007619630545377731\n",
      "\n",
      "episode 4, policy loss -0.016204137355089188\n",
      "\n",
      "episode 5, policy loss -0.04814595729112625\n",
      "\n",
      "episode 6, policy loss -0.004932065960019827\n",
      "\n",
      "episode 7, policy loss -0.01636549085378647\n",
      "\n",
      "episode 8, policy loss -0.01154492050409317\n",
      "\n",
      "episode 9, policy loss -0.008394354023039341\n",
      "\n",
      "episode 10, policy loss -0.00858536921441555\n",
      "\n",
      "episode 11, policy loss -0.024019254371523857\n",
      "\n",
      "episode 12, policy loss -0.011897976510226727\n",
      "\n",
      "episode 13, policy loss -0.01969185657799244\n",
      "\n",
      "episode 14, policy loss -0.045165929943323135\n",
      "\n",
      "episode 15, policy loss -0.03481827303767204\n",
      "\n",
      "episode 16, policy loss -0.04817764088511467\n",
      "\n",
      "Policy train loss in epoch 1:-0.020914309861836955\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.04932155832648277\n",
      "\n",
      "episode 2, policy loss -0.048304181545972824\n",
      "\n",
      "episode 3, policy loss -0.009100177325308323\n",
      "\n",
      "episode 4, policy loss -0.04510640725493431\n",
      "\n",
      "episode 5, policy loss -0.015521746128797531\n",
      "\n",
      "episode 6, policy loss -0.005476150196045637\n",
      "\n",
      "episode 7, policy loss -0.00863575004041195\n",
      "\n",
      "episode 8, policy loss -0.035115525126457214\n",
      "\n",
      "episode 9, policy loss -0.008291531354188919\n",
      "\n",
      "episode 10, policy loss -0.016795001924037933\n",
      "\n",
      "episode 11, policy loss -0.02416500262916088\n",
      "\n",
      "episode 12, policy loss -0.01278605218976736\n",
      "\n",
      "episode 13, policy loss -0.021101946011185646\n",
      "\n",
      "episode 14, policy loss -0.021684929728507996\n",
      "\n",
      "episode 15, policy loss -0.01224400382488966\n",
      "\n",
      "episode 16, policy loss -0.007895780727267265\n",
      "\n",
      "Policy train loss in epoch 2:-0.021346609020838514\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.007069374434649944\n",
      "\n",
      "episode 2, policy loss -0.017280859872698784\n",
      "\n",
      "episode 3, policy loss -0.008193069137632847\n",
      "\n",
      "episode 4, policy loss -0.04761030152440071\n",
      "\n",
      "episode 5, policy loss -0.023001300171017647\n",
      "\n",
      "episode 6, policy loss -0.007819216698408127\n",
      "\n",
      "episode 7, policy loss -0.011074922978878021\n",
      "\n",
      "episode 8, policy loss -0.0035249264910817146\n",
      "\n",
      "episode 9, policy loss -0.050438810139894485\n",
      "\n",
      "episode 10, policy loss -0.04436162859201431\n",
      "\n",
      "episode 11, policy loss -0.01906261034309864\n",
      "\n",
      "episode 12, policy loss -0.011939640156924725\n",
      "\n",
      "episode 13, policy loss -0.020822638645768166\n",
      "\n",
      "episode 14, policy loss -0.016478156670928\n",
      "\n",
      "episode 15, policy loss -0.009027726016938686\n",
      "\n",
      "episode 16, policy loss -0.03630717471241951\n",
      "\n",
      "Policy train loss in epoch 3:-0.020875772286672145\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.2074686586856842\n",
      "\n",
      "episode 2, val func loss 0.19468344748020172\n",
      "\n",
      "episode 3, val func loss 0.19126659631729126\n",
      "\n",
      "episode 4, val func loss 0.19565585255622864\n",
      "\n",
      "episode 5, val func loss 0.1995217353105545\n",
      "\n",
      "episode 6, val func loss 0.1931454837322235\n",
      "\n",
      "episode 7, val func loss 0.20230960845947266\n",
      "\n",
      "episode 8, val func loss 0.20780424773693085\n",
      "\n",
      "episode 9, val func loss 0.17983372509479523\n",
      "\n",
      "episode 10, val func loss 0.21055544912815094\n",
      "\n",
      "episode 11, val func loss 0.16582021117210388\n",
      "\n",
      "episode 12, val func loss 0.18403546512126923\n",
      "\n",
      "episode 13, val func loss 0.20338855683803558\n",
      "\n",
      "episode 14, val func loss 0.1871224343776703\n",
      "\n",
      "episode 15, val func loss 0.17409047484397888\n",
      "\n",
      "episode 16, val func loss 0.20680341124534607\n",
      "\n",
      "Val func train loss in epoch 0:0.1939690848812461\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19068361818790436\n",
      "\n",
      "episode 2, val func loss 0.20089581608772278\n",
      "\n",
      "episode 3, val func loss 0.18737655878067017\n",
      "\n",
      "episode 4, val func loss 0.21075625717639923\n",
      "\n",
      "episode 5, val func loss 0.17458008229732513\n",
      "\n",
      "episode 6, val func loss 0.16702967882156372\n",
      "\n",
      "episode 7, val func loss 0.19577930867671967\n",
      "\n",
      "episode 8, val func loss 0.1961968094110489\n",
      "\n",
      "episode 9, val func loss 0.1801394671201706\n",
      "\n",
      "episode 10, val func loss 0.19293184578418732\n",
      "\n",
      "episode 11, val func loss 0.2067996710538864\n",
      "\n",
      "episode 12, val func loss 0.18395110964775085\n",
      "\n",
      "episode 13, val func loss 0.19875334203243256\n",
      "\n",
      "episode 14, val func loss 0.20231632888317108\n",
      "\n",
      "episode 15, val func loss 0.20735031366348267\n",
      "\n",
      "episode 16, val func loss 0.20713363587856293\n",
      "\n",
      "Val func train loss in epoch 1:0.1939171152189374\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.2100038379430771\n",
      "\n",
      "episode 2, val func loss 0.16631537675857544\n",
      "\n",
      "episode 3, val func loss 0.18001757562160492\n",
      "\n",
      "episode 4, val func loss 0.2015223503112793\n",
      "\n",
      "episode 5, val func loss 0.2025897204875946\n",
      "\n",
      "episode 6, val func loss 0.1871880739927292\n",
      "\n",
      "episode 7, val func loss 0.20599307119846344\n",
      "\n",
      "episode 8, val func loss 0.19039052724838257\n",
      "\n",
      "episode 9, val func loss 0.19294415414333344\n",
      "\n",
      "episode 10, val func loss 0.20733171701431274\n",
      "\n",
      "episode 11, val func loss 0.19537284970283508\n",
      "\n",
      "episode 12, val func loss 0.17466820776462555\n",
      "\n",
      "episode 13, val func loss 0.19961373507976532\n",
      "\n",
      "episode 14, val func loss 0.18433845043182373\n",
      "\n",
      "episode 15, val func loss 0.1956818699836731\n",
      "\n",
      "episode 16, val func loss 0.20679068565368652\n",
      "\n",
      "Val func train loss in epoch 2:0.19379763770848513\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.17513389885425568\n",
      "\n",
      "episode 2, val func loss 0.180355504155159\n",
      "\n",
      "episode 3, val func loss 0.19545766711235046\n",
      "\n",
      "episode 4, val func loss 0.21049192547798157\n",
      "\n",
      "episode 5, val func loss 0.1932389885187149\n",
      "\n",
      "episode 6, val func loss 0.18720737099647522\n",
      "\n",
      "episode 7, val func loss 0.1663677990436554\n",
      "\n",
      "episode 8, val func loss 0.19556139409542084\n",
      "\n",
      "episode 9, val func loss 0.20662614703178406\n",
      "\n",
      "episode 10, val func loss 0.19898547232151031\n",
      "\n",
      "episode 11, val func loss 0.20273572206497192\n",
      "\n",
      "episode 12, val func loss 0.18951749801635742\n",
      "\n",
      "episode 13, val func loss 0.18564189970493317\n",
      "\n",
      "episode 14, val func loss 0.20243199169635773\n",
      "\n",
      "episode 15, val func loss 0.2066771686077118\n",
      "\n",
      "episode 16, val func loss 0.2055392861366272\n",
      "\n",
      "Val func train loss in epoch 3:0.19387310836464167\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1994909644126892\n",
      "\n",
      "episode 2, val func loss 0.19395451247692108\n",
      "\n",
      "episode 3, val func loss 0.20121969282627106\n",
      "\n",
      "episode 4, val func loss 0.20669572055339813\n",
      "\n",
      "episode 5, val func loss 0.2069448083639145\n",
      "\n",
      "episode 6, val func loss 0.20554795861244202\n",
      "\n",
      "episode 7, val func loss 0.16592438519001007\n",
      "\n",
      "episode 8, val func loss 0.19595588743686676\n",
      "\n",
      "episode 9, val func loss 0.17479492723941803\n",
      "\n",
      "episode 10, val func loss 0.1843961477279663\n",
      "\n",
      "episode 11, val func loss 0.1959734410047531\n",
      "\n",
      "episode 12, val func loss 0.21066351234912872\n",
      "\n",
      "episode 13, val func loss 0.17967070639133453\n",
      "\n",
      "episode 14, val func loss 0.18700730800628662\n",
      "\n",
      "episode 15, val func loss 0.190121129155159\n",
      "\n",
      "episode 16, val func loss 0.20239569246768951\n",
      "\n",
      "Val func train loss in epoch 4:0.19379729963839054\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19028057157993317\n",
      "\n",
      "episode 2, val func loss 0.20736703276634216\n",
      "\n",
      "episode 3, val func loss 0.1800735741853714\n",
      "\n",
      "episode 4, val func loss 0.18444475531578064\n",
      "\n",
      "episode 5, val func loss 0.1961098164319992\n",
      "\n",
      "episode 6, val func loss 0.21052326261997223\n",
      "\n",
      "episode 7, val func loss 0.16549897193908691\n",
      "\n",
      "episode 8, val func loss 0.20102091133594513\n",
      "\n",
      "episode 9, val func loss 0.1959364414215088\n",
      "\n",
      "episode 10, val func loss 0.1748456209897995\n",
      "\n",
      "episode 11, val func loss 0.1991761475801468\n",
      "\n",
      "episode 12, val func loss 0.20277757942676544\n",
      "\n",
      "episode 13, val func loss 0.2071157544851303\n",
      "\n",
      "episode 14, val func loss 0.1925431191921234\n",
      "\n",
      "episode 15, val func loss 0.20662689208984375\n",
      "\n",
      "episode 16, val func loss 0.18720611929893494\n",
      "\n",
      "Val func train loss in epoch 5:0.19384666066616774\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17499308288097382\n",
      "\n",
      "episode 2, val func loss 0.1990448534488678\n",
      "\n",
      "episode 3, val func loss 0.20298267900943756\n",
      "\n",
      "episode 4, val func loss 0.18457654118537903\n",
      "\n",
      "episode 5, val func loss 0.2016085386276245\n",
      "\n",
      "episode 6, val func loss 0.19562317430973053\n",
      "\n",
      "episode 7, val func loss 0.206687331199646\n",
      "\n",
      "episode 8, val func loss 0.1656702309846878\n",
      "\n",
      "episode 9, val func loss 0.17959198355674744\n",
      "\n",
      "episode 10, val func loss 0.19006399810314178\n",
      "\n",
      "episode 11, val func loss 0.19262605905532837\n",
      "\n",
      "episode 12, val func loss 0.20763659477233887\n",
      "\n",
      "episode 13, val func loss 0.206461101770401\n",
      "\n",
      "episode 14, val func loss 0.18739186227321625\n",
      "\n",
      "episode 15, val func loss 0.19589370489120483\n",
      "\n",
      "episode 16, val func loss 0.21019913256168365\n",
      "\n",
      "Val func train loss in epoch 6:0.19381567928940058\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.20186196267604828\n",
      "\n",
      "episode 2, val func loss 0.20738019049167633\n",
      "\n",
      "episode 3, val func loss 0.19610673189163208\n",
      "\n",
      "episode 4, val func loss 0.17499159276485443\n",
      "\n",
      "episode 5, val func loss 0.20283930003643036\n",
      "\n",
      "episode 6, val func loss 0.19925443828105927\n",
      "\n",
      "episode 7, val func loss 0.2114427089691162\n",
      "\n",
      "episode 8, val func loss 0.16527503728866577\n",
      "\n",
      "episode 9, val func loss 0.19283710420131683\n",
      "\n",
      "episode 10, val func loss 0.19024658203125\n",
      "\n",
      "episode 11, val func loss 0.17999553680419922\n",
      "\n",
      "episode 12, val func loss 0.2072588950395584\n",
      "\n",
      "episode 13, val func loss 0.1844216287136078\n",
      "\n",
      "episode 14, val func loss 0.18741479516029358\n",
      "\n",
      "episode 15, val func loss 0.19590047001838684\n",
      "\n",
      "episode 16, val func loss 0.20526403188705444\n",
      "\n",
      "Val func train loss in epoch 7:0.19390568789094687\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.19545866549015045\n",
      "\n",
      "episode 2, val func loss 0.19976022839546204\n",
      "\n",
      "episode 3, val func loss 0.19597011804580688\n",
      "\n",
      "episode 4, val func loss 0.1932525932788849\n",
      "\n",
      "episode 5, val func loss 0.1745167225599289\n",
      "\n",
      "episode 6, val func loss 0.20197485387325287\n",
      "\n",
      "episode 7, val func loss 0.16515584290027618\n",
      "\n",
      "episode 8, val func loss 0.18735840916633606\n",
      "\n",
      "episode 9, val func loss 0.1901419311761856\n",
      "\n",
      "episode 10, val func loss 0.2108149528503418\n",
      "\n",
      "episode 11, val func loss 0.2071342021226883\n",
      "\n",
      "episode 12, val func loss 0.18447011709213257\n",
      "\n",
      "episode 13, val func loss 0.18006137013435364\n",
      "\n",
      "episode 14, val func loss 0.20472705364227295\n",
      "\n",
      "episode 15, val func loss 0.2031555473804474\n",
      "\n",
      "episode 16, val func loss 0.2073240876197815\n",
      "\n",
      "Val func train loss in epoch 8:0.19382979348301888\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20986756682395935\n",
      "\n",
      "episode 2, val func loss 0.20700989663600922\n",
      "\n",
      "episode 3, val func loss 0.20718976855278015\n",
      "\n",
      "episode 4, val func loss 0.17435969412326813\n",
      "\n",
      "episode 5, val func loss 0.20522181689739227\n",
      "\n",
      "episode 6, val func loss 0.19916725158691406\n",
      "\n",
      "episode 7, val func loss 0.18476785719394684\n",
      "\n",
      "episode 8, val func loss 0.1660045087337494\n",
      "\n",
      "episode 9, val func loss 0.1802784949541092\n",
      "\n",
      "episode 10, val func loss 0.18720047175884247\n",
      "\n",
      "episode 11, val func loss 0.19021408259868622\n",
      "\n",
      "episode 12, val func loss 0.1962950974702835\n",
      "\n",
      "episode 13, val func loss 0.19620676338672638\n",
      "\n",
      "episode 14, val func loss 0.20166955888271332\n",
      "\n",
      "episode 15, val func loss 0.20293180644512177\n",
      "\n",
      "episode 16, val func loss 0.19361786544322968\n",
      "\n",
      "Val func train loss in epoch 9:0.19387515634298325\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1995142251253128\n",
      "\n",
      "episode 2, val func loss 0.16568371653556824\n",
      "\n",
      "episode 3, val func loss 0.20713019371032715\n",
      "\n",
      "episode 4, val func loss 0.2074805200099945\n",
      "\n",
      "episode 5, val func loss 0.19312815368175507\n",
      "\n",
      "episode 6, val func loss 0.17500849068164825\n",
      "\n",
      "episode 7, val func loss 0.1958240419626236\n",
      "\n",
      "episode 8, val func loss 0.18994006514549255\n",
      "\n",
      "episode 9, val func loss 0.18728472292423248\n",
      "\n",
      "episode 10, val func loss 0.19588956236839294\n",
      "\n",
      "episode 11, val func loss 0.20259740948677063\n",
      "\n",
      "episode 12, val func loss 0.21032758057117462\n",
      "\n",
      "episode 13, val func loss 0.1847010999917984\n",
      "\n",
      "episode 14, val func loss 0.20148441195487976\n",
      "\n",
      "episode 15, val func loss 0.20496787130832672\n",
      "\n",
      "episode 16, val func loss 0.18033115565776825\n",
      "\n",
      "Val func train loss in epoch 10:0.19383082631975412\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.20716987550258636\n",
      "\n",
      "episode 2, val func loss 0.19052603840827942\n",
      "\n",
      "episode 3, val func loss 0.19578170776367188\n",
      "\n",
      "episode 4, val func loss 0.19279223680496216\n",
      "\n",
      "episode 5, val func loss 0.20630604028701782\n",
      "\n",
      "episode 6, val func loss 0.16532927751541138\n",
      "\n",
      "episode 7, val func loss 0.20724640786647797\n",
      "\n",
      "episode 8, val func loss 0.20250029861927032\n",
      "\n",
      "episode 9, val func loss 0.17990615963935852\n",
      "\n",
      "episode 10, val func loss 0.17457763850688934\n",
      "\n",
      "episode 11, val func loss 0.20176643133163452\n",
      "\n",
      "episode 12, val func loss 0.18473267555236816\n",
      "\n",
      "episode 13, val func loss 0.21039758622646332\n",
      "\n",
      "episode 14, val func loss 0.1957329660654068\n",
      "\n",
      "episode 15, val func loss 0.19969172775745392\n",
      "\n",
      "episode 16, val func loss 0.1872451901435852\n",
      "\n",
      "Val func train loss in epoch 11:0.19385639112442732\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1744144856929779\n",
      "\n",
      "episode 2, val func loss 0.2057434618473053\n",
      "\n",
      "episode 3, val func loss 0.19599944353103638\n",
      "\n",
      "episode 4, val func loss 0.1799444705247879\n",
      "\n",
      "episode 5, val func loss 0.19546978175640106\n",
      "\n",
      "episode 6, val func loss 0.16553330421447754\n",
      "\n",
      "episode 7, val func loss 0.1843636929988861\n",
      "\n",
      "episode 8, val func loss 0.1994263380765915\n",
      "\n",
      "episode 9, val func loss 0.1875627636909485\n",
      "\n",
      "episode 10, val func loss 0.19017651677131653\n",
      "\n",
      "episode 11, val func loss 0.20733895897865295\n",
      "\n",
      "episode 12, val func loss 0.19273553788661957\n",
      "\n",
      "episode 13, val func loss 0.20258556306362152\n",
      "\n",
      "episode 14, val func loss 0.20186424255371094\n",
      "\n",
      "episode 15, val func loss 0.21019798517227173\n",
      "\n",
      "episode 16, val func loss 0.2068547010421753\n",
      "\n",
      "Val func train loss in epoch 12:0.1937632029876113\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19967104494571686\n",
      "\n",
      "episode 2, val func loss 0.2012142390012741\n",
      "\n",
      "episode 3, val func loss 0.17519982159137726\n",
      "\n",
      "episode 4, val func loss 0.21016724407672882\n",
      "\n",
      "episode 5, val func loss 0.1935800164937973\n",
      "\n",
      "episode 6, val func loss 0.196025088429451\n",
      "\n",
      "episode 7, val func loss 0.2071746438741684\n",
      "\n",
      "episode 8, val func loss 0.1652466207742691\n",
      "\n",
      "episode 9, val func loss 0.18996164202690125\n",
      "\n",
      "episode 10, val func loss 0.20744623243808746\n",
      "\n",
      "episode 11, val func loss 0.20240575075149536\n",
      "\n",
      "episode 12, val func loss 0.17984722554683685\n",
      "\n",
      "episode 13, val func loss 0.1958085596561432\n",
      "\n",
      "episode 14, val func loss 0.18445336818695068\n",
      "\n",
      "episode 15, val func loss 0.1874176561832428\n",
      "\n",
      "episode 16, val func loss 0.20522117614746094\n",
      "\n",
      "Val func train loss in epoch 13:0.19380252063274384\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18490161001682281\n",
      "\n",
      "episode 2, val func loss 0.20993836224079132\n",
      "\n",
      "episode 3, val func loss 0.19378484785556793\n",
      "\n",
      "episode 4, val func loss 0.20515669882297516\n",
      "\n",
      "episode 5, val func loss 0.20142194628715515\n",
      "\n",
      "episode 6, val func loss 0.179971843957901\n",
      "\n",
      "episode 7, val func loss 0.17485447227954865\n",
      "\n",
      "episode 8, val func loss 0.1905193328857422\n",
      "\n",
      "episode 9, val func loss 0.1956605166196823\n",
      "\n",
      "episode 10, val func loss 0.19614021480083466\n",
      "\n",
      "episode 11, val func loss 0.2026980072259903\n",
      "\n",
      "episode 12, val func loss 0.18738004565238953\n",
      "\n",
      "episode 13, val func loss 0.19931107759475708\n",
      "\n",
      "episode 14, val func loss 0.2072322517633438\n",
      "\n",
      "episode 15, val func loss 0.16535000503063202\n",
      "\n",
      "episode 16, val func loss 0.20690037310123444\n",
      "\n",
      "Val func train loss in epoch 14:0.19382635038346052\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.2066131979227066\n",
      "\n",
      "episode 2, val func loss 0.17482969164848328\n",
      "\n",
      "episode 3, val func loss 0.2026084065437317\n",
      "\n",
      "episode 4, val func loss 0.20129834115505219\n",
      "\n",
      "episode 5, val func loss 0.20519515872001648\n",
      "\n",
      "episode 6, val func loss 0.18052217364311218\n",
      "\n",
      "episode 7, val func loss 0.21027761697769165\n",
      "\n",
      "episode 8, val func loss 0.20717880129814148\n",
      "\n",
      "episode 9, val func loss 0.19620384275913239\n",
      "\n",
      "episode 10, val func loss 0.1935221254825592\n",
      "\n",
      "episode 11, val func loss 0.1656787395477295\n",
      "\n",
      "episode 12, val func loss 0.1876572072505951\n",
      "\n",
      "episode 13, val func loss 0.18557986617088318\n",
      "\n",
      "episode 14, val func loss 0.2000037580728531\n",
      "\n",
      "episode 15, val func loss 0.1965329349040985\n",
      "\n",
      "episode 16, val func loss 0.1897851526737213\n",
      "\n",
      "Val func train loss in epoch 15:0.19396793842315674\n",
      "***********************TIME WAS 4.994813172022502 min*****************************\n",
      "\n",
      "**********************ROUND 108 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.02424648217856884\n",
      "\n",
      "episode 2, policy loss -0.022371822968125343\n",
      "\n",
      "episode 3, policy loss -0.007309635169804096\n",
      "\n",
      "episode 4, policy loss 0.011414602398872375\n",
      "\n",
      "episode 5, policy loss 0.03259950131177902\n",
      "\n",
      "episode 6, policy loss -0.0019823608454316854\n",
      "\n",
      "episode 7, policy loss -0.027843957766890526\n",
      "\n",
      "episode 8, policy loss -0.0019000417087227106\n",
      "\n",
      "episode 9, policy loss -0.03508789464831352\n",
      "\n",
      "episode 10, policy loss -0.038521431386470795\n",
      "\n",
      "episode 11, policy loss 0.0021673967130482197\n",
      "\n",
      "episode 12, policy loss 0.0263145100325346\n",
      "\n",
      "episode 13, policy loss -0.04324640333652496\n",
      "\n",
      "episode 14, policy loss 0.024918274953961372\n",
      "\n",
      "episode 15, policy loss -0.01878882758319378\n",
      "\n",
      "episode 16, policy loss -0.042980991303920746\n",
      "\n",
      "Policy train loss in epoch 0:-0.007398287445539609\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.019609622657299042\n",
      "\n",
      "episode 2, policy loss -0.003509955946356058\n",
      "\n",
      "episode 3, policy loss -0.03936038911342621\n",
      "\n",
      "episode 4, policy loss 0.014342806302011013\n",
      "\n",
      "episode 5, policy loss -0.04704923927783966\n",
      "\n",
      "episode 6, policy loss -0.04253881052136421\n",
      "\n",
      "episode 7, policy loss 0.03156652674078941\n",
      "\n",
      "episode 8, policy loss -0.03796205669641495\n",
      "\n",
      "episode 9, policy loss 0.024505993351340294\n",
      "\n",
      "episode 10, policy loss 0.0058669643476605415\n",
      "\n",
      "episode 11, policy loss -0.03631041571497917\n",
      "\n",
      "episode 12, policy loss -0.009423678740859032\n",
      "\n",
      "episode 13, policy loss 0.024936607107520103\n",
      "\n",
      "episode 14, policy loss -0.002342317719012499\n",
      "\n",
      "episode 15, policy loss -0.029279382899403572\n",
      "\n",
      "episode 16, policy loss -0.0015784741844981909\n",
      "\n",
      "Policy train loss in epoch 1:-0.010484090351383202\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.04041531682014465\n",
      "\n",
      "episode 2, policy loss -0.011117704212665558\n",
      "\n",
      "episode 3, policy loss 0.014629107899963856\n",
      "\n",
      "episode 4, policy loss -0.003381443675607443\n",
      "\n",
      "episode 5, policy loss 0.02530413493514061\n",
      "\n",
      "episode 6, policy loss 0.031781479716300964\n",
      "\n",
      "episode 7, policy loss -0.04679345712065697\n",
      "\n",
      "episode 8, policy loss 0.005870847962796688\n",
      "\n",
      "episode 9, policy loss -0.01913466490805149\n",
      "\n",
      "episode 10, policy loss -0.0028363075107336044\n",
      "\n",
      "episode 11, policy loss -0.036224182695150375\n",
      "\n",
      "episode 12, policy loss -0.028638524934649467\n",
      "\n",
      "episode 13, policy loss 0.025070028379559517\n",
      "\n",
      "episode 14, policy loss -0.0013230324257165194\n",
      "\n",
      "episode 15, policy loss -0.043097980320453644\n",
      "\n",
      "episode 16, policy loss -0.03805680200457573\n",
      "\n",
      "Policy train loss in epoch 2:-0.010522738608415239\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.024795999750494957\n",
      "\n",
      "episode 2, policy loss -0.03621213883161545\n",
      "\n",
      "episode 3, policy loss -0.04389195144176483\n",
      "\n",
      "episode 4, policy loss 0.031482480466365814\n",
      "\n",
      "episode 5, policy loss -0.03858671709895134\n",
      "\n",
      "episode 6, policy loss -0.04072537273168564\n",
      "\n",
      "episode 7, policy loss -0.0014497711090371013\n",
      "\n",
      "episode 8, policy loss 0.006141756195574999\n",
      "\n",
      "episode 9, policy loss -0.010940486565232277\n",
      "\n",
      "episode 10, policy loss -0.004675417672842741\n",
      "\n",
      "episode 11, policy loss -0.0039879982359707355\n",
      "\n",
      "episode 12, policy loss 0.014464503154158592\n",
      "\n",
      "episode 13, policy loss 0.024876249954104424\n",
      "\n",
      "episode 14, policy loss -0.01940542832016945\n",
      "\n",
      "episode 15, policy loss -0.04685916006565094\n",
      "\n",
      "episode 16, policy loss -0.031293924897909164\n",
      "\n",
      "Policy train loss in epoch 3:-0.01101671109063318\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19399425387382507\n",
      "\n",
      "episode 2, val func loss 0.16687290370464325\n",
      "\n",
      "episode 3, val func loss 0.17956344783306122\n",
      "\n",
      "episode 4, val func loss 0.20652079582214355\n",
      "\n",
      "episode 5, val func loss 0.17719654738903046\n",
      "\n",
      "episode 6, val func loss 0.17541088163852692\n",
      "\n",
      "episode 7, val func loss 0.20041601359844208\n",
      "\n",
      "episode 8, val func loss 0.19754256308078766\n",
      "\n",
      "episode 9, val func loss 0.1895158588886261\n",
      "\n",
      "episode 10, val func loss 0.17455287277698517\n",
      "\n",
      "episode 11, val func loss 0.16114863753318787\n",
      "\n",
      "episode 12, val func loss 0.20565274357795715\n",
      "\n",
      "episode 13, val func loss 0.16910681128501892\n",
      "\n",
      "episode 14, val func loss 0.16482894122600555\n",
      "\n",
      "episode 15, val func loss 0.21031147241592407\n",
      "\n",
      "episode 16, val func loss 0.18847332894802094\n",
      "\n",
      "Val func train loss in epoch 0:0.18506925459951162\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.16705328226089478\n",
      "\n",
      "episode 2, val func loss 0.18850310146808624\n",
      "\n",
      "episode 3, val func loss 0.20725959539413452\n",
      "\n",
      "episode 4, val func loss 0.19664672017097473\n",
      "\n",
      "episode 5, val func loss 0.17581132054328918\n",
      "\n",
      "episode 6, val func loss 0.17735788226127625\n",
      "\n",
      "episode 7, val func loss 0.1742745339870453\n",
      "\n",
      "episode 8, val func loss 0.2070205956697464\n",
      "\n",
      "episode 9, val func loss 0.1901250183582306\n",
      "\n",
      "episode 10, val func loss 0.16540159285068512\n",
      "\n",
      "episode 11, val func loss 0.16454721987247467\n",
      "\n",
      "episode 12, val func loss 0.19726043939590454\n",
      "\n",
      "episode 13, val func loss 0.16087199747562408\n",
      "\n",
      "episode 14, val func loss 0.1751321703195572\n",
      "\n",
      "episode 15, val func loss 0.2111128568649292\n",
      "\n",
      "episode 16, val func loss 0.19566281139850616\n",
      "\n",
      "Val func train loss in epoch 1:0.18462757114320993\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17758166790008545\n",
      "\n",
      "episode 2, val func loss 0.17675918340682983\n",
      "\n",
      "episode 3, val func loss 0.21047982573509216\n",
      "\n",
      "episode 4, val func loss 0.1884765923023224\n",
      "\n",
      "episode 5, val func loss 0.20692236721515656\n",
      "\n",
      "episode 6, val func loss 0.16460253298282623\n",
      "\n",
      "episode 7, val func loss 0.16138604283332825\n",
      "\n",
      "episode 8, val func loss 0.19706586003303528\n",
      "\n",
      "episode 9, val func loss 0.17403215169906616\n",
      "\n",
      "episode 10, val func loss 0.1649988293647766\n",
      "\n",
      "episode 11, val func loss 0.16746914386749268\n",
      "\n",
      "episode 12, val func loss 0.1955925077199936\n",
      "\n",
      "episode 13, val func loss 0.18958452343940735\n",
      "\n",
      "episode 14, val func loss 0.2063298225402832\n",
      "\n",
      "episode 15, val func loss 0.17549695074558258\n",
      "\n",
      "episode 16, val func loss 0.19573214650154114\n",
      "\n",
      "Val func train loss in epoch 2:0.18453188426792622\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19690439105033875\n",
      "\n",
      "episode 2, val func loss 0.18871571123600006\n",
      "\n",
      "episode 3, val func loss 0.16276757419109344\n",
      "\n",
      "episode 4, val func loss 0.1650880128145218\n",
      "\n",
      "episode 5, val func loss 0.18981444835662842\n",
      "\n",
      "episode 6, val func loss 0.20685328543186188\n",
      "\n",
      "episode 7, val func loss 0.17539967596530914\n",
      "\n",
      "episode 8, val func loss 0.2106696516275406\n",
      "\n",
      "episode 9, val func loss 0.16438394784927368\n",
      "\n",
      "episode 10, val func loss 0.1667230725288391\n",
      "\n",
      "episode 11, val func loss 0.19667068123817444\n",
      "\n",
      "episode 12, val func loss 0.2070005238056183\n",
      "\n",
      "episode 13, val func loss 0.1770748496055603\n",
      "\n",
      "episode 14, val func loss 0.19562268257141113\n",
      "\n",
      "episode 15, val func loss 0.1765880435705185\n",
      "\n",
      "episode 16, val func loss 0.17390434443950653\n",
      "\n",
      "Val func train loss in epoch 3:0.18463630601763725\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17757286131381989\n",
      "\n",
      "episode 2, val func loss 0.18992961943149567\n",
      "\n",
      "episode 3, val func loss 0.16856034100055695\n",
      "\n",
      "episode 4, val func loss 0.18829764425754547\n",
      "\n",
      "episode 5, val func loss 0.1952977031469345\n",
      "\n",
      "episode 6, val func loss 0.1958182007074356\n",
      "\n",
      "episode 7, val func loss 0.16404815018177032\n",
      "\n",
      "episode 8, val func loss 0.20715562999248505\n",
      "\n",
      "episode 9, val func loss 0.21007832884788513\n",
      "\n",
      "episode 10, val func loss 0.17533639073371887\n",
      "\n",
      "episode 11, val func loss 0.20551466941833496\n",
      "\n",
      "episode 12, val func loss 0.1620129495859146\n",
      "\n",
      "episode 13, val func loss 0.19644704461097717\n",
      "\n",
      "episode 14, val func loss 0.17761127650737762\n",
      "\n",
      "episode 15, val func loss 0.17356657981872559\n",
      "\n",
      "episode 16, val func loss 0.1650346964597702\n",
      "\n",
      "Val func train loss in epoch 4:0.18451763037592173\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17543908953666687\n",
      "\n",
      "episode 2, val func loss 0.16019487380981445\n",
      "\n",
      "episode 3, val func loss 0.18997225165367126\n",
      "\n",
      "episode 4, val func loss 0.17719261348247528\n",
      "\n",
      "episode 5, val func loss 0.16449721157550812\n",
      "\n",
      "episode 6, val func loss 0.19829586148262024\n",
      "\n",
      "episode 7, val func loss 0.21226628124713898\n",
      "\n",
      "episode 8, val func loss 0.20658132433891296\n",
      "\n",
      "episode 9, val func loss 0.17412003874778748\n",
      "\n",
      "episode 10, val func loss 0.16532403230667114\n",
      "\n",
      "episode 11, val func loss 0.19612427055835724\n",
      "\n",
      "episode 12, val func loss 0.2069542557001114\n",
      "\n",
      "episode 13, val func loss 0.17330703139305115\n",
      "\n",
      "episode 14, val func loss 0.1800401210784912\n",
      "\n",
      "episode 15, val func loss 0.18880058825016022\n",
      "\n",
      "episode 16, val func loss 0.19476018846035004\n",
      "\n",
      "Val func train loss in epoch 5:0.18524187710136175\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19586123526096344\n",
      "\n",
      "episode 2, val func loss 0.17601121962070465\n",
      "\n",
      "episode 3, val func loss 0.16010387241840363\n",
      "\n",
      "episode 4, val func loss 0.1639253795146942\n",
      "\n",
      "episode 5, val func loss 0.1762649118900299\n",
      "\n",
      "episode 6, val func loss 0.16440805792808533\n",
      "\n",
      "episode 7, val func loss 0.20787417888641357\n",
      "\n",
      "episode 8, val func loss 0.177192822098732\n",
      "\n",
      "episode 9, val func loss 0.2073691487312317\n",
      "\n",
      "episode 10, val func loss 0.18980512022972107\n",
      "\n",
      "episode 11, val func loss 0.20963270962238312\n",
      "\n",
      "episode 12, val func loss 0.19630247354507446\n",
      "\n",
      "episode 13, val func loss 0.17741569876670837\n",
      "\n",
      "episode 14, val func loss 0.1716633290052414\n",
      "\n",
      "episode 15, val func loss 0.1943361908197403\n",
      "\n",
      "episode 16, val func loss 0.18860875070095062\n",
      "\n",
      "Val func train loss in epoch 6:0.18479844368994236\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18967247009277344\n",
      "\n",
      "episode 2, val func loss 0.1980467289686203\n",
      "\n",
      "episode 3, val func loss 0.17533132433891296\n",
      "\n",
      "episode 4, val func loss 0.20606952905654907\n",
      "\n",
      "episode 5, val func loss 0.2066994160413742\n",
      "\n",
      "episode 6, val func loss 0.19493721425533295\n",
      "\n",
      "episode 7, val func loss 0.1940293312072754\n",
      "\n",
      "episode 8, val func loss 0.17404532432556152\n",
      "\n",
      "episode 9, val func loss 0.18028317391872406\n",
      "\n",
      "episode 10, val func loss 0.1888555884361267\n",
      "\n",
      "episode 11, val func loss 0.1644972264766693\n",
      "\n",
      "episode 12, val func loss 0.1664121448993683\n",
      "\n",
      "episode 13, val func loss 0.21228213608264923\n",
      "\n",
      "episode 14, val func loss 0.15944020450115204\n",
      "\n",
      "episode 15, val func loss 0.17512817680835724\n",
      "\n",
      "episode 16, val func loss 0.16474978625774384\n",
      "\n",
      "Val func train loss in epoch 7:0.1844049859791994\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16481085121631622\n",
      "\n",
      "episode 2, val func loss 0.20792633295059204\n",
      "\n",
      "episode 3, val func loss 0.2109903246164322\n",
      "\n",
      "episode 4, val func loss 0.16554699838161469\n",
      "\n",
      "episode 5, val func loss 0.19538766145706177\n",
      "\n",
      "episode 6, val func loss 0.19610118865966797\n",
      "\n",
      "episode 7, val func loss 0.20676970481872559\n",
      "\n",
      "episode 8, val func loss 0.19373001158237457\n",
      "\n",
      "episode 9, val func loss 0.17929692566394806\n",
      "\n",
      "episode 10, val func loss 0.18855613470077515\n",
      "\n",
      "episode 11, val func loss 0.16783881187438965\n",
      "\n",
      "episode 12, val func loss 0.17563243210315704\n",
      "\n",
      "episode 13, val func loss 0.17586970329284668\n",
      "\n",
      "episode 14, val func loss 0.17731013894081116\n",
      "\n",
      "episode 15, val func loss 0.15964828431606293\n",
      "\n",
      "episode 16, val func loss 0.19039469957351685\n",
      "\n",
      "Val func train loss in epoch 8:0.18473813775926828\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.16538582742214203\n",
      "\n",
      "episode 2, val func loss 0.19963882863521576\n",
      "\n",
      "episode 3, val func loss 0.20664557814598083\n",
      "\n",
      "episode 4, val func loss 0.20720942318439484\n",
      "\n",
      "episode 5, val func loss 0.19222943484783173\n",
      "\n",
      "episode 6, val func loss 0.19561095535755157\n",
      "\n",
      "episode 7, val func loss 0.17929019033908844\n",
      "\n",
      "episode 8, val func loss 0.1779298633337021\n",
      "\n",
      "episode 9, val func loss 0.21065272390842438\n",
      "\n",
      "episode 10, val func loss 0.16423673927783966\n",
      "\n",
      "episode 11, val func loss 0.19640342891216278\n",
      "\n",
      "episode 12, val func loss 0.15976780652999878\n",
      "\n",
      "episode 13, val func loss 0.1753387451171875\n",
      "\n",
      "episode 14, val func loss 0.17500631511211395\n",
      "\n",
      "episode 15, val func loss 0.1646898090839386\n",
      "\n",
      "episode 16, val func loss 0.1884782463312149\n",
      "\n",
      "Val func train loss in epoch 9:0.18490711972117424\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.16488538682460785\n",
      "\n",
      "episode 2, val func loss 0.20717206597328186\n",
      "\n",
      "episode 3, val func loss 0.2056998759508133\n",
      "\n",
      "episode 4, val func loss 0.18845264613628387\n",
      "\n",
      "episode 5, val func loss 0.16481198370456696\n",
      "\n",
      "episode 6, val func loss 0.19530309736728668\n",
      "\n",
      "episode 7, val func loss 0.16144607961177826\n",
      "\n",
      "episode 8, val func loss 0.17370523512363434\n",
      "\n",
      "episode 9, val func loss 0.19500499963760376\n",
      "\n",
      "episode 10, val func loss 0.20998014509677887\n",
      "\n",
      "episode 11, val func loss 0.19644981622695923\n",
      "\n",
      "episode 12, val func loss 0.17134685814380646\n",
      "\n",
      "episode 13, val func loss 0.19009636342525482\n",
      "\n",
      "episode 14, val func loss 0.17756566405296326\n",
      "\n",
      "episode 15, val func loss 0.17535461485385895\n",
      "\n",
      "episode 16, val func loss 0.17599661648273468\n",
      "\n",
      "Val func train loss in epoch 10:0.18457946553826332\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16565051674842834\n",
      "\n",
      "episode 2, val func loss 0.21305067837238312\n",
      "\n",
      "episode 3, val func loss 0.15994775295257568\n",
      "\n",
      "episode 4, val func loss 0.17502127587795258\n",
      "\n",
      "episode 5, val func loss 0.1988716423511505\n",
      "\n",
      "episode 6, val func loss 0.19952411949634552\n",
      "\n",
      "episode 7, val func loss 0.17419825494289398\n",
      "\n",
      "episode 8, val func loss 0.19543461501598358\n",
      "\n",
      "episode 9, val func loss 0.1695377081632614\n",
      "\n",
      "episode 10, val func loss 0.20606881380081177\n",
      "\n",
      "episode 11, val func loss 0.16719594597816467\n",
      "\n",
      "episode 12, val func loss 0.18852457404136658\n",
      "\n",
      "episode 13, val func loss 0.17540857195854187\n",
      "\n",
      "episode 14, val func loss 0.20724868774414062\n",
      "\n",
      "episode 15, val func loss 0.18967081606388092\n",
      "\n",
      "episode 16, val func loss 0.17683908343315125\n",
      "\n",
      "Val func train loss in epoch 11:0.18513706605881453\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17681947350502014\n",
      "\n",
      "episode 2, val func loss 0.15978898108005524\n",
      "\n",
      "episode 3, val func loss 0.16373024880886078\n",
      "\n",
      "episode 4, val func loss 0.17575068771839142\n",
      "\n",
      "episode 5, val func loss 0.2077087163925171\n",
      "\n",
      "episode 6, val func loss 0.17626342177391052\n",
      "\n",
      "episode 7, val func loss 0.207564115524292\n",
      "\n",
      "episode 8, val func loss 0.19729019701480865\n",
      "\n",
      "episode 9, val func loss 0.19036318361759186\n",
      "\n",
      "episode 10, val func loss 0.16601774096488953\n",
      "\n",
      "episode 11, val func loss 0.18871626257896423\n",
      "\n",
      "episode 12, val func loss 0.17370329797267914\n",
      "\n",
      "episode 13, val func loss 0.21069858968257904\n",
      "\n",
      "episode 14, val func loss 0.16725194454193115\n",
      "\n",
      "episode 15, val func loss 0.19559510052204132\n",
      "\n",
      "episode 16, val func loss 0.19585083425045013\n",
      "\n",
      "Val func train loss in epoch 12:0.1845695497468114\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1649261862039566\n",
      "\n",
      "episode 2, val func loss 0.20697654783725739\n",
      "\n",
      "episode 3, val func loss 0.19447380304336548\n",
      "\n",
      "episode 4, val func loss 0.1902814507484436\n",
      "\n",
      "episode 5, val func loss 0.17849259078502655\n",
      "\n",
      "episode 6, val func loss 0.17749223113059998\n",
      "\n",
      "episode 7, val func loss 0.16752836108207703\n",
      "\n",
      "episode 8, val func loss 0.1886267066001892\n",
      "\n",
      "episode 9, val func loss 0.21225833892822266\n",
      "\n",
      "episode 10, val func loss 0.19999371469020844\n",
      "\n",
      "episode 11, val func loss 0.15959101915359497\n",
      "\n",
      "episode 12, val func loss 0.16367745399475098\n",
      "\n",
      "episode 13, val func loss 0.17523986101150513\n",
      "\n",
      "episode 14, val func loss 0.1748085618019104\n",
      "\n",
      "episode 15, val func loss 0.20559753477573395\n",
      "\n",
      "episode 16, val func loss 0.19509357213974\n",
      "\n",
      "Val func train loss in epoch 13:0.1846911208704114\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1939898431301117\n",
      "\n",
      "episode 2, val func loss 0.18324026465415955\n",
      "\n",
      "episode 3, val func loss 0.19144868850708008\n",
      "\n",
      "episode 4, val func loss 0.17854583263397217\n",
      "\n",
      "episode 5, val func loss 0.17377793788909912\n",
      "\n",
      "episode 6, val func loss 0.17518483102321625\n",
      "\n",
      "episode 7, val func loss 0.20653633773326874\n",
      "\n",
      "episode 8, val func loss 0.16373233497142792\n",
      "\n",
      "episode 9, val func loss 0.15975092351436615\n",
      "\n",
      "episode 10, val func loss 0.1654890775680542\n",
      "\n",
      "episode 11, val func loss 0.1647578328847885\n",
      "\n",
      "episode 12, val func loss 0.20050032436847687\n",
      "\n",
      "episode 13, val func loss 0.1891704648733139\n",
      "\n",
      "episode 14, val func loss 0.21162915229797363\n",
      "\n",
      "episode 15, val func loss 0.20667396485805511\n",
      "\n",
      "episode 16, val func loss 0.19510605931282043\n",
      "\n",
      "Val func train loss in epoch 14:0.18497086688876152\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18069784343242645\n",
      "\n",
      "episode 2, val func loss 0.17801356315612793\n",
      "\n",
      "episode 3, val func loss 0.19602294266223907\n",
      "\n",
      "episode 4, val func loss 0.2052408903837204\n",
      "\n",
      "episode 5, val func loss 0.19430133700370789\n",
      "\n",
      "episode 6, val func loss 0.177313432097435\n",
      "\n",
      "episode 7, val func loss 0.16789424419403076\n",
      "\n",
      "episode 8, val func loss 0.1746014803647995\n",
      "\n",
      "episode 9, val func loss 0.1598581224679947\n",
      "\n",
      "episode 10, val func loss 0.18892674148082733\n",
      "\n",
      "episode 11, val func loss 0.20850783586502075\n",
      "\n",
      "episode 12, val func loss 0.21192389726638794\n",
      "\n",
      "episode 13, val func loss 0.16447384655475616\n",
      "\n",
      "episode 14, val func loss 0.1893940269947052\n",
      "\n",
      "episode 15, val func loss 0.19585445523262024\n",
      "\n",
      "episode 16, val func loss 0.1646040380001068\n",
      "\n",
      "Val func train loss in epoch 15:0.18485179357230663\n",
      "***********************TIME WAS 4.997952981789907 min*****************************\n",
      "\n",
      "**********************ROUND 109 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.03054852783679962\n",
      "\n",
      "episode 2, policy loss -0.03766409680247307\n",
      "\n",
      "episode 3, policy loss -0.06455820798873901\n",
      "\n",
      "episode 4, policy loss -0.049406662583351135\n",
      "\n",
      "episode 5, policy loss -0.06892486661672592\n",
      "\n",
      "episode 6, policy loss -0.07815875858068466\n",
      "\n",
      "episode 7, policy loss 0.0022119597997516394\n",
      "\n",
      "episode 8, policy loss -0.0730612576007843\n",
      "\n",
      "episode 9, policy loss -0.05234363302588463\n",
      "\n",
      "episode 10, policy loss -0.01251368597149849\n",
      "\n",
      "episode 11, policy loss -0.059230126440525055\n",
      "\n",
      "episode 12, policy loss -0.07612922042608261\n",
      "\n",
      "episode 13, policy loss -0.009819759987294674\n",
      "\n",
      "episode 14, policy loss -0.06533407419919968\n",
      "\n",
      "episode 15, policy loss -0.04043420031666756\n",
      "\n",
      "episode 16, policy loss -0.03473002836108208\n",
      "\n",
      "Policy train loss in epoch 0:-0.04691532168362755\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.017286410555243492\n",
      "\n",
      "episode 2, policy loss -0.0458608940243721\n",
      "\n",
      "episode 3, policy loss -0.039340049028396606\n",
      "\n",
      "episode 4, policy loss -0.03437820076942444\n",
      "\n",
      "episode 5, policy loss -0.07129884511232376\n",
      "\n",
      "episode 6, policy loss -0.05553314462304115\n",
      "\n",
      "episode 7, policy loss -0.0801340714097023\n",
      "\n",
      "episode 8, policy loss -0.06982962787151337\n",
      "\n",
      "episode 9, policy loss -0.07612669467926025\n",
      "\n",
      "episode 10, policy loss -0.07960429787635803\n",
      "\n",
      "episode 11, policy loss -0.08109758794307709\n",
      "\n",
      "episode 12, policy loss -0.013219899497926235\n",
      "\n",
      "episode 13, policy loss -0.0010047323303297162\n",
      "\n",
      "episode 14, policy loss -0.04207795858383179\n",
      "\n",
      "episode 15, policy loss -0.06562740355730057\n",
      "\n",
      "episode 16, policy loss -0.05913897976279259\n",
      "\n",
      "Policy train loss in epoch 1:-0.05197242485155584\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.08102819323539734\n",
      "\n",
      "episode 2, policy loss -0.05384160205721855\n",
      "\n",
      "episode 3, policy loss -0.08163505047559738\n",
      "\n",
      "episode 4, policy loss -0.07591358572244644\n",
      "\n",
      "episode 5, policy loss -0.04062793776392937\n",
      "\n",
      "episode 6, policy loss -0.013722027651965618\n",
      "\n",
      "episode 7, policy loss -0.0808342918753624\n",
      "\n",
      "episode 8, policy loss -0.017970100045204163\n",
      "\n",
      "episode 9, policy loss -0.07385169714689255\n",
      "\n",
      "episode 10, policy loss -0.06481796503067017\n",
      "\n",
      "episode 11, policy loss -0.0430588461458683\n",
      "\n",
      "episode 12, policy loss -0.06969496607780457\n",
      "\n",
      "episode 13, policy loss -0.0014894703635945916\n",
      "\n",
      "episode 14, policy loss -0.03661356121301651\n",
      "\n",
      "episode 15, policy loss -0.05918411165475845\n",
      "\n",
      "episode 16, policy loss -0.046655941754579544\n",
      "\n",
      "Policy train loss in epoch 2:-0.05255870926339412\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.05575387179851532\n",
      "\n",
      "episode 2, policy loss -0.08122403174638748\n",
      "\n",
      "episode 3, policy loss -0.07407568395137787\n",
      "\n",
      "episode 4, policy loss -0.001270734122954309\n",
      "\n",
      "episode 5, policy loss -0.018457768484950066\n",
      "\n",
      "episode 6, policy loss -0.08106280118227005\n",
      "\n",
      "episode 7, policy loss -0.046764422208070755\n",
      "\n",
      "episode 8, policy loss -0.04076100140810013\n",
      "\n",
      "episode 9, policy loss -0.04382699355483055\n",
      "\n",
      "episode 10, policy loss -0.06593206524848938\n",
      "\n",
      "episode 11, policy loss -0.08077696710824966\n",
      "\n",
      "episode 12, policy loss -0.012921955436468124\n",
      "\n",
      "episode 13, policy loss -0.07640405744314194\n",
      "\n",
      "episode 14, policy loss -0.05878803879022598\n",
      "\n",
      "episode 15, policy loss -0.07005009800195694\n",
      "\n",
      "episode 16, policy loss -0.036685943603515625\n",
      "\n",
      "Policy train loss in epoch 3:-0.05279727713059401\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19194860756397247\n",
      "\n",
      "episode 2, val func loss 0.20807868242263794\n",
      "\n",
      "episode 3, val func loss 0.18529614806175232\n",
      "\n",
      "episode 4, val func loss 0.22386963665485382\n",
      "\n",
      "episode 5, val func loss 0.20848995447158813\n",
      "\n",
      "episode 6, val func loss 0.20019793510437012\n",
      "\n",
      "episode 7, val func loss 0.20258203148841858\n",
      "\n",
      "episode 8, val func loss 0.18389888107776642\n",
      "\n",
      "episode 9, val func loss 0.21079863607883453\n",
      "\n",
      "episode 10, val func loss 0.18464623391628265\n",
      "\n",
      "episode 11, val func loss 0.2039828598499298\n",
      "\n",
      "episode 12, val func loss 0.20726542174816132\n",
      "\n",
      "episode 13, val func loss 0.19852760434150696\n",
      "\n",
      "episode 14, val func loss 0.17219096422195435\n",
      "\n",
      "episode 15, val func loss 0.19613759219646454\n",
      "\n",
      "episode 16, val func loss 0.2013382911682129\n",
      "\n",
      "Val func train loss in epoch 0:0.19870309252291918\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.20469573140144348\n",
      "\n",
      "episode 2, val func loss 0.20808833837509155\n",
      "\n",
      "episode 3, val func loss 0.20376786589622498\n",
      "\n",
      "episode 4, val func loss 0.18536096811294556\n",
      "\n",
      "episode 5, val func loss 0.18533413112163544\n",
      "\n",
      "episode 6, val func loss 0.20000354945659637\n",
      "\n",
      "episode 7, val func loss 0.20574848353862762\n",
      "\n",
      "episode 8, val func loss 0.20857878029346466\n",
      "\n",
      "episode 9, val func loss 0.1836644858121872\n",
      "\n",
      "episode 10, val func loss 0.20063775777816772\n",
      "\n",
      "episode 11, val func loss 0.20008805394172668\n",
      "\n",
      "episode 12, val func loss 0.1919013112783432\n",
      "\n",
      "episode 13, val func loss 0.1969074010848999\n",
      "\n",
      "episode 14, val func loss 0.22345195710659027\n",
      "\n",
      "episode 15, val func loss 0.2113647758960724\n",
      "\n",
      "episode 16, val func loss 0.17185720801353455\n",
      "\n",
      "Val func train loss in epoch 1:0.19884067494422197\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19997939467430115\n",
      "\n",
      "episode 2, val func loss 0.20864994823932648\n",
      "\n",
      "episode 3, val func loss 0.17242659628391266\n",
      "\n",
      "episode 4, val func loss 0.22397875785827637\n",
      "\n",
      "episode 5, val func loss 0.1869843602180481\n",
      "\n",
      "episode 6, val func loss 0.20399928092956543\n",
      "\n",
      "episode 7, val func loss 0.19936826825141907\n",
      "\n",
      "episode 8, val func loss 0.19164183735847473\n",
      "\n",
      "episode 9, val func loss 0.2110997587442398\n",
      "\n",
      "episode 10, val func loss 0.2082291692495346\n",
      "\n",
      "episode 11, val func loss 0.20284195244312286\n",
      "\n",
      "episode 12, val func loss 0.19998379051685333\n",
      "\n",
      "episode 13, val func loss 0.19789303839206696\n",
      "\n",
      "episode 14, val func loss 0.20840422809123993\n",
      "\n",
      "episode 15, val func loss 0.18285709619522095\n",
      "\n",
      "episode 16, val func loss 0.18403306603431702\n",
      "\n",
      "Val func train loss in epoch 2:0.19889815896749496\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1921716034412384\n",
      "\n",
      "episode 2, val func loss 0.19592484831809998\n",
      "\n",
      "episode 3, val func loss 0.18408454954624176\n",
      "\n",
      "episode 4, val func loss 0.2009170651435852\n",
      "\n",
      "episode 5, val func loss 0.21094393730163574\n",
      "\n",
      "episode 6, val func loss 0.18382054567337036\n",
      "\n",
      "episode 7, val func loss 0.2038230150938034\n",
      "\n",
      "episode 8, val func loss 0.20401372015476227\n",
      "\n",
      "episode 9, val func loss 0.18522140383720398\n",
      "\n",
      "episode 10, val func loss 0.17394712567329407\n",
      "\n",
      "episode 11, val func loss 0.206428661942482\n",
      "\n",
      "episode 12, val func loss 0.19938048720359802\n",
      "\n",
      "episode 13, val func loss 0.20050491392612457\n",
      "\n",
      "episode 14, val func loss 0.2076094150543213\n",
      "\n",
      "episode 15, val func loss 0.22369712591171265\n",
      "\n",
      "episode 16, val func loss 0.207980677485466\n",
      "\n",
      "Val func train loss in epoch 3:0.19877931848168373\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18393106758594513\n",
      "\n",
      "episode 2, val func loss 0.20677003264427185\n",
      "\n",
      "episode 3, val func loss 0.19087743759155273\n",
      "\n",
      "episode 4, val func loss 0.1728845238685608\n",
      "\n",
      "episode 5, val func loss 0.19922637939453125\n",
      "\n",
      "episode 6, val func loss 0.19949811697006226\n",
      "\n",
      "episode 7, val func loss 0.20999465882778168\n",
      "\n",
      "episode 8, val func loss 0.20084097981452942\n",
      "\n",
      "episode 9, val func loss 0.19939306378364563\n",
      "\n",
      "episode 10, val func loss 0.18443529307842255\n",
      "\n",
      "episode 11, val func loss 0.20457226037979126\n",
      "\n",
      "episode 12, val func loss 0.22444108128547668\n",
      "\n",
      "episode 13, val func loss 0.2064530849456787\n",
      "\n",
      "episode 14, val func loss 0.19616617262363434\n",
      "\n",
      "episode 15, val func loss 0.2100585550069809\n",
      "\n",
      "episode 16, val func loss 0.18563294410705566\n",
      "\n",
      "Val func train loss in epoch 4:0.19844847824424505\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.2000538408756256\n",
      "\n",
      "episode 2, val func loss 0.1845376044511795\n",
      "\n",
      "episode 3, val func loss 0.20011006295681\n",
      "\n",
      "episode 4, val func loss 0.19153992831707\n",
      "\n",
      "episode 5, val func loss 0.2216254621744156\n",
      "\n",
      "episode 6, val func loss 0.20511138439178467\n",
      "\n",
      "episode 7, val func loss 0.2114877551794052\n",
      "\n",
      "episode 8, val func loss 0.2104518562555313\n",
      "\n",
      "episode 9, val func loss 0.2062997817993164\n",
      "\n",
      "episode 10, val func loss 0.19711048901081085\n",
      "\n",
      "episode 11, val func loss 0.188406303524971\n",
      "\n",
      "episode 12, val func loss 0.2033866047859192\n",
      "\n",
      "episode 13, val func loss 0.18674272298812866\n",
      "\n",
      "episode 14, val func loss 0.20828968286514282\n",
      "\n",
      "episode 15, val func loss 0.172947496175766\n",
      "\n",
      "episode 16, val func loss 0.1991632580757141\n",
      "\n",
      "Val func train loss in epoch 5:0.19920401461422443\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.20859289169311523\n",
      "\n",
      "episode 2, val func loss 0.2031582146883011\n",
      "\n",
      "episode 3, val func loss 0.18497227132320404\n",
      "\n",
      "episode 4, val func loss 0.20257380604743958\n",
      "\n",
      "episode 5, val func loss 0.22252321243286133\n",
      "\n",
      "episode 6, val func loss 0.21151164174079895\n",
      "\n",
      "episode 7, val func loss 0.17236599326133728\n",
      "\n",
      "episode 8, val func loss 0.19859550893306732\n",
      "\n",
      "episode 9, val func loss 0.1994556188583374\n",
      "\n",
      "episode 10, val func loss 0.20576249063014984\n",
      "\n",
      "episode 11, val func loss 0.19549046456813812\n",
      "\n",
      "episode 12, val func loss 0.1897406429052353\n",
      "\n",
      "episode 13, val func loss 0.18538393080234528\n",
      "\n",
      "episode 14, val func loss 0.20555658638477325\n",
      "\n",
      "episode 15, val func loss 0.18577522039413452\n",
      "\n",
      "episode 16, val func loss 0.19934217631816864\n",
      "\n",
      "Val func train loss in epoch 6:0.19817504193633795\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19599886238574982\n",
      "\n",
      "episode 2, val func loss 0.22100453078746796\n",
      "\n",
      "episode 3, val func loss 0.18346986174583435\n",
      "\n",
      "episode 4, val func loss 0.20731030404567719\n",
      "\n",
      "episode 5, val func loss 0.1867162138223648\n",
      "\n",
      "episode 6, val func loss 0.1939087212085724\n",
      "\n",
      "episode 7, val func loss 0.2020881474018097\n",
      "\n",
      "episode 8, val func loss 0.2114458531141281\n",
      "\n",
      "episode 9, val func loss 0.19999843835830688\n",
      "\n",
      "episode 10, val func loss 0.17417797446250916\n",
      "\n",
      "episode 11, val func loss 0.20364506542682648\n",
      "\n",
      "episode 12, val func loss 0.20395547151565552\n",
      "\n",
      "episode 13, val func loss 0.18339970707893372\n",
      "\n",
      "episode 14, val func loss 0.19956740736961365\n",
      "\n",
      "episode 15, val func loss 0.20377029478549957\n",
      "\n",
      "episode 16, val func loss 0.20687070488929749\n",
      "\n",
      "Val func train loss in epoch 7:0.19858297239989042\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.20011429488658905\n",
      "\n",
      "episode 2, val func loss 0.21043987572193146\n",
      "\n",
      "episode 3, val func loss 0.19952215254306793\n",
      "\n",
      "episode 4, val func loss 0.20597229897975922\n",
      "\n",
      "episode 5, val func loss 0.18259459733963013\n",
      "\n",
      "episode 6, val func loss 0.20041459798812866\n",
      "\n",
      "episode 7, val func loss 0.22085396945476532\n",
      "\n",
      "episode 8, val func loss 0.17299677431583405\n",
      "\n",
      "episode 9, val func loss 0.20696745812892914\n",
      "\n",
      "episode 10, val func loss 0.19413931667804718\n",
      "\n",
      "episode 11, val func loss 0.20513427257537842\n",
      "\n",
      "episode 12, val func loss 0.2069326937198639\n",
      "\n",
      "episode 13, val func loss 0.18306565284729004\n",
      "\n",
      "episode 14, val func loss 0.2021150439977646\n",
      "\n",
      "episode 15, val func loss 0.18664397299289703\n",
      "\n",
      "episode 16, val func loss 0.18905428051948547\n",
      "\n",
      "Val func train loss in epoch 8:0.1979350782930851\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20158515870571136\n",
      "\n",
      "episode 2, val func loss 0.2000550776720047\n",
      "\n",
      "episode 3, val func loss 0.20921695232391357\n",
      "\n",
      "episode 4, val func loss 0.18568147718906403\n",
      "\n",
      "episode 5, val func loss 0.20523019134998322\n",
      "\n",
      "episode 6, val func loss 0.1713908165693283\n",
      "\n",
      "episode 7, val func loss 0.2077062726020813\n",
      "\n",
      "episode 8, val func loss 0.1941118687391281\n",
      "\n",
      "episode 9, val func loss 0.18745003640651703\n",
      "\n",
      "episode 10, val func loss 0.20182578265666962\n",
      "\n",
      "episode 11, val func loss 0.19497424364089966\n",
      "\n",
      "episode 12, val func loss 0.19912447035312653\n",
      "\n",
      "episode 13, val func loss 0.222320556640625\n",
      "\n",
      "episode 14, val func loss 0.18634791672229767\n",
      "\n",
      "episode 15, val func loss 0.19854749739170074\n",
      "\n",
      "episode 16, val func loss 0.20697307586669922\n",
      "\n",
      "Val func train loss in epoch 9:0.19828383717685938\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20948021113872528\n",
      "\n",
      "episode 2, val func loss 0.2057095617055893\n",
      "\n",
      "episode 3, val func loss 0.18431758880615234\n",
      "\n",
      "episode 4, val func loss 0.19898885488510132\n",
      "\n",
      "episode 5, val func loss 0.2054888904094696\n",
      "\n",
      "episode 6, val func loss 0.18450927734375\n",
      "\n",
      "episode 7, val func loss 0.19257427752017975\n",
      "\n",
      "episode 8, val func loss 0.18489673733711243\n",
      "\n",
      "episode 9, val func loss 0.22385427355766296\n",
      "\n",
      "episode 10, val func loss 0.20276685059070587\n",
      "\n",
      "episode 11, val func loss 0.20870478451251984\n",
      "\n",
      "episode 12, val func loss 0.2072761207818985\n",
      "\n",
      "episode 13, val func loss 0.1712302714586258\n",
      "\n",
      "episode 14, val func loss 0.19879303872585297\n",
      "\n",
      "episode 15, val func loss 0.19682542979717255\n",
      "\n",
      "episode 16, val func loss 0.19963771104812622\n",
      "\n",
      "Val func train loss in epoch 10:0.1984408674761653\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19934241473674774\n",
      "\n",
      "episode 2, val func loss 0.1854863166809082\n",
      "\n",
      "episode 3, val func loss 0.19925732910633087\n",
      "\n",
      "episode 4, val func loss 0.19504958391189575\n",
      "\n",
      "episode 5, val func loss 0.18498864769935608\n",
      "\n",
      "episode 6, val func loss 0.20749425888061523\n",
      "\n",
      "episode 7, val func loss 0.18271487951278687\n",
      "\n",
      "episode 8, val func loss 0.20225666463375092\n",
      "\n",
      "episode 9, val func loss 0.2098652571439743\n",
      "\n",
      "episode 10, val func loss 0.20867040753364563\n",
      "\n",
      "episode 11, val func loss 0.1988770067691803\n",
      "\n",
      "episode 12, val func loss 0.1715388149023056\n",
      "\n",
      "episode 13, val func loss 0.20239880681037903\n",
      "\n",
      "episode 14, val func loss 0.20631925761699677\n",
      "\n",
      "episode 15, val func loss 0.1910475492477417\n",
      "\n",
      "episode 16, val func loss 0.2228187918663025\n",
      "\n",
      "Val func train loss in epoch 11:0.19800787419080734\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.20698991417884827\n",
      "\n",
      "episode 2, val func loss 0.18961191177368164\n",
      "\n",
      "episode 3, val func loss 0.18255382776260376\n",
      "\n",
      "episode 4, val func loss 0.2079697996377945\n",
      "\n",
      "episode 5, val func loss 0.20894430577754974\n",
      "\n",
      "episode 6, val func loss 0.22089307010173798\n",
      "\n",
      "episode 7, val func loss 0.17207172513008118\n",
      "\n",
      "episode 8, val func loss 0.19875219464302063\n",
      "\n",
      "episode 9, val func loss 0.1828412413597107\n",
      "\n",
      "episode 10, val func loss 0.19891248643398285\n",
      "\n",
      "episode 11, val func loss 0.20664143562316895\n",
      "\n",
      "episode 12, val func loss 0.20095373690128326\n",
      "\n",
      "episode 13, val func loss 0.20712094008922577\n",
      "\n",
      "episode 14, val func loss 0.1854405403137207\n",
      "\n",
      "episode 15, val func loss 0.2040618658065796\n",
      "\n",
      "episode 16, val func loss 0.2098754495382309\n",
      "\n",
      "Val func train loss in epoch 12:0.19897715281695127\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1780724972486496\n",
      "\n",
      "episode 2, val func loss 0.18568769097328186\n",
      "\n",
      "episode 3, val func loss 0.20384958386421204\n",
      "\n",
      "episode 4, val func loss 0.18583226203918457\n",
      "\n",
      "episode 5, val func loss 0.20072203874588013\n",
      "\n",
      "episode 6, val func loss 0.2040865123271942\n",
      "\n",
      "episode 7, val func loss 0.1910039484500885\n",
      "\n",
      "episode 8, val func loss 0.20374096930027008\n",
      "\n",
      "episode 9, val func loss 0.20891173183918\n",
      "\n",
      "episode 10, val func loss 0.2222081571817398\n",
      "\n",
      "episode 11, val func loss 0.20724640786647797\n",
      "\n",
      "episode 12, val func loss 0.2110854536294937\n",
      "\n",
      "episode 13, val func loss 0.18283753097057343\n",
      "\n",
      "episode 14, val func loss 0.19992685317993164\n",
      "\n",
      "episode 15, val func loss 0.19691556692123413\n",
      "\n",
      "episode 16, val func loss 0.19995366036891937\n",
      "\n",
      "Val func train loss in epoch 13:0.19888005405664444\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17242193222045898\n",
      "\n",
      "episode 2, val func loss 0.18715800344944\n",
      "\n",
      "episode 3, val func loss 0.2100558876991272\n",
      "\n",
      "episode 4, val func loss 0.20822472870349884\n",
      "\n",
      "episode 5, val func loss 0.20421551167964935\n",
      "\n",
      "episode 6, val func loss 0.2240607738494873\n",
      "\n",
      "episode 7, val func loss 0.20236533880233765\n",
      "\n",
      "episode 8, val func loss 0.18444938957691193\n",
      "\n",
      "episode 9, val func loss 0.19943492114543915\n",
      "\n",
      "episode 10, val func loss 0.19615468382835388\n",
      "\n",
      "episode 11, val func loss 0.198490709066391\n",
      "\n",
      "episode 12, val func loss 0.20183037221431732\n",
      "\n",
      "episode 13, val func loss 0.18219122290611267\n",
      "\n",
      "episode 14, val func loss 0.1920904517173767\n",
      "\n",
      "episode 15, val func loss 0.2071930468082428\n",
      "\n",
      "episode 16, val func loss 0.20751792192459106\n",
      "\n",
      "Val func train loss in epoch 14:0.1986159309744835\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20697320997714996\n",
      "\n",
      "episode 2, val func loss 0.1864030659198761\n",
      "\n",
      "episode 3, val func loss 0.19820764660835266\n",
      "\n",
      "episode 4, val func loss 0.21184754371643066\n",
      "\n",
      "episode 5, val func loss 0.2055383324623108\n",
      "\n",
      "episode 6, val func loss 0.19966018199920654\n",
      "\n",
      "episode 7, val func loss 0.1841897815465927\n",
      "\n",
      "episode 8, val func loss 0.19831083714962006\n",
      "\n",
      "episode 9, val func loss 0.17206451296806335\n",
      "\n",
      "episode 10, val func loss 0.20225803554058075\n",
      "\n",
      "episode 11, val func loss 0.22439223527908325\n",
      "\n",
      "episode 12, val func loss 0.18336047232151031\n",
      "\n",
      "episode 13, val func loss 0.20834015309810638\n",
      "\n",
      "episode 14, val func loss 0.1927085965871811\n",
      "\n",
      "episode 15, val func loss 0.20709075033664703\n",
      "\n",
      "episode 16, val func loss 0.20322489738464355\n",
      "\n",
      "Val func train loss in epoch 15:0.1990356408059597\n",
      "***********************TIME WAS 4.99920627673467 min*****************************\n",
      "\n",
      "**********************ROUND 110 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.0037695299834012985\n",
      "\n",
      "episode 2, policy loss -0.005028767976909876\n",
      "\n",
      "episode 3, policy loss -0.02878742292523384\n",
      "\n",
      "episode 4, policy loss 0.019710244610905647\n",
      "\n",
      "episode 5, policy loss -0.04048551991581917\n",
      "\n",
      "episode 6, policy loss -0.08289122581481934\n",
      "\n",
      "episode 7, policy loss 0.01824790984392166\n",
      "\n",
      "episode 8, policy loss 0.08926452696323395\n",
      "\n",
      "episode 9, policy loss 0.04957415908575058\n",
      "\n",
      "episode 10, policy loss -0.031029535457491875\n",
      "\n",
      "episode 11, policy loss -0.05020584911108017\n",
      "\n",
      "episode 12, policy loss 0.020692018792033195\n",
      "\n",
      "episode 13, policy loss 0.031033221632242203\n",
      "\n",
      "episode 14, policy loss -0.01966376043856144\n",
      "\n",
      "episode 15, policy loss 0.005916999187320471\n",
      "\n",
      "episode 16, policy loss 0.03446074575185776\n",
      "\n",
      "Policy train loss in epoch 0:0.0004398883902467787\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.037870243191719055\n",
      "\n",
      "episode 2, policy loss -0.011167952790856361\n",
      "\n",
      "episode 3, policy loss -0.043042901903390884\n",
      "\n",
      "episode 4, policy loss 0.03683420270681381\n",
      "\n",
      "episode 5, policy loss -0.036320094019174576\n",
      "\n",
      "episode 6, policy loss -0.02169717848300934\n",
      "\n",
      "episode 7, policy loss -0.08507265150547028\n",
      "\n",
      "episode 8, policy loss -0.05280221998691559\n",
      "\n",
      "episode 9, policy loss 0.08785280585289001\n",
      "\n",
      "episode 10, policy loss -0.021492144092917442\n",
      "\n",
      "episode 11, policy loss 0.006860359106212854\n",
      "\n",
      "episode 12, policy loss 0.016160251572728157\n",
      "\n",
      "episode 13, policy loss 0.028504977002739906\n",
      "\n",
      "episode 14, policy loss 0.019154179841279984\n",
      "\n",
      "episode 15, policy loss 0.012289772741496563\n",
      "\n",
      "episode 16, policy loss 0.046040285378694534\n",
      "\n",
      "Policy train loss in epoch 1:-0.003485534485662356\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.0365803986787796\n",
      "\n",
      "episode 2, policy loss -0.012291355058550835\n",
      "\n",
      "episode 3, policy loss -0.08593155443668365\n",
      "\n",
      "episode 4, policy loss 0.026646830141544342\n",
      "\n",
      "episode 5, policy loss 0.08632118254899979\n",
      "\n",
      "episode 6, policy loss -0.03832344338297844\n",
      "\n",
      "episode 7, policy loss 0.01300222147256136\n",
      "\n",
      "episode 8, policy loss 0.01826999895274639\n",
      "\n",
      "episode 9, policy loss 0.04540208727121353\n",
      "\n",
      "episode 10, policy loss -0.044229887425899506\n",
      "\n",
      "episode 11, policy loss -0.05307278409600258\n",
      "\n",
      "episode 12, policy loss -0.021301619708538055\n",
      "\n",
      "episode 13, policy loss 0.034835800528526306\n",
      "\n",
      "episode 14, policy loss -0.021969294175505638\n",
      "\n",
      "episode 15, policy loss 0.014738494530320168\n",
      "\n",
      "episode 16, policy loss 0.005011127330362797\n",
      "\n",
      "Policy train loss in epoch 2:-0.004342037136666477\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.08672792464494705\n",
      "\n",
      "episode 2, policy loss -0.05356067046523094\n",
      "\n",
      "episode 3, policy loss 0.0457160659134388\n",
      "\n",
      "episode 4, policy loss 0.011805585585534573\n",
      "\n",
      "episode 5, policy loss -0.022913731634616852\n",
      "\n",
      "episode 6, policy loss 0.014664096757769585\n",
      "\n",
      "episode 7, policy loss -0.0220345426350832\n",
      "\n",
      "episode 8, policy loss 0.026803093031048775\n",
      "\n",
      "episode 9, policy loss -0.03679291903972626\n",
      "\n",
      "episode 10, policy loss 0.0348532609641552\n",
      "\n",
      "episode 11, policy loss -0.013413254171609879\n",
      "\n",
      "episode 12, policy loss 0.004964692052453756\n",
      "\n",
      "episode 13, policy loss -0.039427656680345535\n",
      "\n",
      "episode 14, policy loss 0.017345484346151352\n",
      "\n",
      "episode 15, policy loss -0.08589872717857361\n",
      "\n",
      "episode 16, policy loss -0.04582753777503967\n",
      "\n",
      "Policy train loss in epoch 3:-0.004811802267795429\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.21006137132644653\n",
      "\n",
      "episode 2, val func loss 0.17851483821868896\n",
      "\n",
      "episode 3, val func loss 0.1821926385164261\n",
      "\n",
      "episode 4, val func loss 0.1808646321296692\n",
      "\n",
      "episode 5, val func loss 0.23623882234096527\n",
      "\n",
      "episode 6, val func loss 0.20379050076007843\n",
      "\n",
      "episode 7, val func loss 0.17931170761585236\n",
      "\n",
      "episode 8, val func loss 0.22045789659023285\n",
      "\n",
      "episode 9, val func loss 0.21508640050888062\n",
      "\n",
      "episode 10, val func loss 0.21325212717056274\n",
      "\n",
      "episode 11, val func loss 0.21707448363304138\n",
      "\n",
      "episode 12, val func loss 0.1634368747472763\n",
      "\n",
      "episode 13, val func loss 0.1837167739868164\n",
      "\n",
      "episode 14, val func loss 0.19376617670059204\n",
      "\n",
      "episode 15, val func loss 0.19448082149028778\n",
      "\n",
      "episode 16, val func loss 0.17991866171360016\n",
      "\n",
      "Val func train loss in epoch 0:0.19701029546558857\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.16420914232730865\n",
      "\n",
      "episode 2, val func loss 0.1782054454088211\n",
      "\n",
      "episode 3, val func loss 0.1791856586933136\n",
      "\n",
      "episode 4, val func loss 0.21536307036876678\n",
      "\n",
      "episode 5, val func loss 0.2154369354248047\n",
      "\n",
      "episode 6, val func loss 0.16883431375026703\n",
      "\n",
      "episode 7, val func loss 0.21403329074382782\n",
      "\n",
      "episode 8, val func loss 0.20359288156032562\n",
      "\n",
      "episode 9, val func loss 0.23743054270744324\n",
      "\n",
      "episode 10, val func loss 0.21713081002235413\n",
      "\n",
      "episode 11, val func loss 0.18617410957813263\n",
      "\n",
      "episode 12, val func loss 0.1946483701467514\n",
      "\n",
      "episode 13, val func loss 0.17947186529636383\n",
      "\n",
      "episode 14, val func loss 0.1801784634590149\n",
      "\n",
      "episode 15, val func loss 0.21917758882045746\n",
      "\n",
      "episode 16, val func loss 0.19396723806858063\n",
      "\n",
      "Val func train loss in epoch 1:0.19668998289853334\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.16935664415359497\n",
      "\n",
      "episode 2, val func loss 0.16272777318954468\n",
      "\n",
      "episode 3, val func loss 0.216226264834404\n",
      "\n",
      "episode 4, val func loss 0.1787615716457367\n",
      "\n",
      "episode 5, val func loss 0.2211424559354782\n",
      "\n",
      "episode 6, val func loss 0.2171483337879181\n",
      "\n",
      "episode 7, val func loss 0.17939703166484833\n",
      "\n",
      "episode 8, val func loss 0.23524199426174164\n",
      "\n",
      "episode 9, val func loss 0.19196870923042297\n",
      "\n",
      "episode 10, val func loss 0.21300898492336273\n",
      "\n",
      "episode 11, val func loss 0.18882480263710022\n",
      "\n",
      "episode 12, val func loss 0.21733736991882324\n",
      "\n",
      "episode 13, val func loss 0.19658227264881134\n",
      "\n",
      "episode 14, val func loss 0.1819123476743698\n",
      "\n",
      "episode 15, val func loss 0.20353956520557404\n",
      "\n",
      "episode 16, val func loss 0.17882665991783142\n",
      "\n",
      "Val func train loss in epoch 2:0.19700017385184765\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.21856264770030975\n",
      "\n",
      "episode 2, val func loss 0.21994876861572266\n",
      "\n",
      "episode 3, val func loss 0.16771209239959717\n",
      "\n",
      "episode 4, val func loss 0.17777295410633087\n",
      "\n",
      "episode 5, val func loss 0.18020585179328918\n",
      "\n",
      "episode 6, val func loss 0.23894084990024567\n",
      "\n",
      "episode 7, val func loss 0.16425910592079163\n",
      "\n",
      "episode 8, val func loss 0.18151769042015076\n",
      "\n",
      "episode 9, val func loss 0.1975812315940857\n",
      "\n",
      "episode 10, val func loss 0.20625890791416168\n",
      "\n",
      "episode 11, val func loss 0.19515258073806763\n",
      "\n",
      "episode 12, val func loss 0.1781689077615738\n",
      "\n",
      "episode 13, val func loss 0.17925067245960236\n",
      "\n",
      "episode 14, val func loss 0.20990820229053497\n",
      "\n",
      "episode 15, val func loss 0.21332092583179474\n",
      "\n",
      "episode 16, val func loss 0.21323850750923157\n",
      "\n",
      "Val func train loss in epoch 3:0.19636249355971813\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.21923276782035828\n",
      "\n",
      "episode 2, val func loss 0.21334396302700043\n",
      "\n",
      "episode 3, val func loss 0.18251626193523407\n",
      "\n",
      "episode 4, val func loss 0.20763152837753296\n",
      "\n",
      "episode 5, val func loss 0.23988938331604004\n",
      "\n",
      "episode 6, val func loss 0.21215151250362396\n",
      "\n",
      "episode 7, val func loss 0.21200037002563477\n",
      "\n",
      "episode 8, val func loss 0.19476306438446045\n",
      "\n",
      "episode 9, val func loss 0.18371868133544922\n",
      "\n",
      "episode 10, val func loss 0.17936329543590546\n",
      "\n",
      "episode 11, val func loss 0.19547690451145172\n",
      "\n",
      "episode 12, val func loss 0.18065980076789856\n",
      "\n",
      "episode 13, val func loss 0.17792418599128723\n",
      "\n",
      "episode 14, val func loss 0.1673947274684906\n",
      "\n",
      "episode 15, val func loss 0.21590407192707062\n",
      "\n",
      "episode 16, val func loss 0.16303789615631104\n",
      "\n",
      "Val func train loss in epoch 4:0.19656302593648434\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.21554319560527802\n",
      "\n",
      "episode 2, val func loss 0.23811715841293335\n",
      "\n",
      "episode 3, val func loss 0.21510356664657593\n",
      "\n",
      "episode 4, val func loss 0.21400046348571777\n",
      "\n",
      "episode 5, val func loss 0.18378669023513794\n",
      "\n",
      "episode 6, val func loss 0.21674476563930511\n",
      "\n",
      "episode 7, val func loss 0.16594405472278595\n",
      "\n",
      "episode 8, val func loss 0.18173810839653015\n",
      "\n",
      "episode 9, val func loss 0.19162282347679138\n",
      "\n",
      "episode 10, val func loss 0.19654104113578796\n",
      "\n",
      "episode 11, val func loss 0.18052935600280762\n",
      "\n",
      "episode 12, val func loss 0.22114090621471405\n",
      "\n",
      "episode 13, val func loss 0.17819155752658844\n",
      "\n",
      "episode 14, val func loss 0.1796000599861145\n",
      "\n",
      "episode 15, val func loss 0.1648445576429367\n",
      "\n",
      "episode 16, val func loss 0.2112554907798767\n",
      "\n",
      "Val func train loss in epoch 5:0.1971689872443676\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.2406976819038391\n",
      "\n",
      "episode 2, val func loss 0.17897513508796692\n",
      "\n",
      "episode 3, val func loss 0.21937714517116547\n",
      "\n",
      "episode 4, val func loss 0.21405833959579468\n",
      "\n",
      "episode 5, val func loss 0.2114863395690918\n",
      "\n",
      "episode 6, val func loss 0.20972849428653717\n",
      "\n",
      "episode 7, val func loss 0.19782570004463196\n",
      "\n",
      "episode 8, val func loss 0.16804704070091248\n",
      "\n",
      "episode 9, val func loss 0.20301853120326996\n",
      "\n",
      "episode 10, val func loss 0.1831672191619873\n",
      "\n",
      "episode 11, val func loss 0.22208724915981293\n",
      "\n",
      "episode 12, val func loss 0.18582431972026825\n",
      "\n",
      "episode 13, val func loss 0.1807427704334259\n",
      "\n",
      "episode 14, val func loss 0.1944933384656906\n",
      "\n",
      "episode 15, val func loss 0.1648164689540863\n",
      "\n",
      "episode 16, val func loss 0.1763690710067749\n",
      "\n",
      "Val func train loss in epoch 6:0.19691967777907848\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1795065701007843\n",
      "\n",
      "episode 2, val func loss 0.18143029510974884\n",
      "\n",
      "episode 3, val func loss 0.17801012098789215\n",
      "\n",
      "episode 4, val func loss 0.2200477421283722\n",
      "\n",
      "episode 5, val func loss 0.18381360173225403\n",
      "\n",
      "episode 6, val func loss 0.19973880052566528\n",
      "\n",
      "episode 7, val func loss 0.19383971393108368\n",
      "\n",
      "episode 8, val func loss 0.20992210507392883\n",
      "\n",
      "episode 9, val func loss 0.1650753766298294\n",
      "\n",
      "episode 10, val func loss 0.23603415489196777\n",
      "\n",
      "episode 11, val func loss 0.21108640730381012\n",
      "\n",
      "episode 12, val func loss 0.21321554481983185\n",
      "\n",
      "episode 13, val func loss 0.17656446993350983\n",
      "\n",
      "episode 14, val func loss 0.2042870819568634\n",
      "\n",
      "episode 15, val func loss 0.21808746457099915\n",
      "\n",
      "episode 16, val func loss 0.1792767345905304\n",
      "\n",
      "Val func train loss in epoch 7:0.19687101151794195\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17831124365329742\n",
      "\n",
      "episode 2, val func loss 0.19718141853809357\n",
      "\n",
      "episode 3, val func loss 0.22260276973247528\n",
      "\n",
      "episode 4, val func loss 0.19458137452602386\n",
      "\n",
      "episode 5, val func loss 0.17878997325897217\n",
      "\n",
      "episode 6, val func loss 0.18250031769275665\n",
      "\n",
      "episode 7, val func loss 0.16374607384204865\n",
      "\n",
      "episode 8, val func loss 0.23629559576511383\n",
      "\n",
      "episode 9, val func loss 0.2038266658782959\n",
      "\n",
      "episode 10, val func loss 0.21363216638565063\n",
      "\n",
      "episode 11, val func loss 0.17920954525470734\n",
      "\n",
      "episode 12, val func loss 0.21797999739646912\n",
      "\n",
      "episode 13, val func loss 0.21471785008907318\n",
      "\n",
      "episode 14, val func loss 0.21303796768188477\n",
      "\n",
      "episode 15, val func loss 0.1758943647146225\n",
      "\n",
      "episode 16, val func loss 0.1816524714231491\n",
      "\n",
      "Val func train loss in epoch 8:0.19712248723953962\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.16396088898181915\n",
      "\n",
      "episode 2, val func loss 0.2040809541940689\n",
      "\n",
      "episode 3, val func loss 0.21184979379177094\n",
      "\n",
      "episode 4, val func loss 0.21335498988628387\n",
      "\n",
      "episode 5, val func loss 0.16892801225185394\n",
      "\n",
      "episode 6, val func loss 0.19417530298233032\n",
      "\n",
      "episode 7, val func loss 0.23619994521141052\n",
      "\n",
      "episode 8, val func loss 0.2198469340801239\n",
      "\n",
      "episode 9, val func loss 0.17752757668495178\n",
      "\n",
      "episode 10, val func loss 0.17922969162464142\n",
      "\n",
      "episode 11, val func loss 0.18241024017333984\n",
      "\n",
      "episode 12, val func loss 0.17888019979000092\n",
      "\n",
      "episode 13, val func loss 0.2130058854818344\n",
      "\n",
      "episode 14, val func loss 0.19457755982875824\n",
      "\n",
      "episode 15, val func loss 0.18058055639266968\n",
      "\n",
      "episode 16, val func loss 0.21916623413562775\n",
      "\n",
      "Val func train loss in epoch 9:0.19611092284321785\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1785828024148941\n",
      "\n",
      "episode 2, val func loss 0.2178606539964676\n",
      "\n",
      "episode 3, val func loss 0.217803955078125\n",
      "\n",
      "episode 4, val func loss 0.18078161776065826\n",
      "\n",
      "episode 5, val func loss 0.18007482588291168\n",
      "\n",
      "episode 6, val func loss 0.20622272789478302\n",
      "\n",
      "episode 7, val func loss 0.18163292109966278\n",
      "\n",
      "episode 8, val func loss 0.16343602538108826\n",
      "\n",
      "episode 9, val func loss 0.21255286037921906\n",
      "\n",
      "episode 10, val func loss 0.16290464997291565\n",
      "\n",
      "episode 11, val func loss 0.1975977122783661\n",
      "\n",
      "episode 12, val func loss 0.17939099669456482\n",
      "\n",
      "episode 13, val func loss 0.19632644951343536\n",
      "\n",
      "episode 14, val func loss 0.21592579782009125\n",
      "\n",
      "episode 15, val func loss 0.2330360859632492\n",
      "\n",
      "episode 16, val func loss 0.2145473062992096\n",
      "\n",
      "Val func train loss in epoch 10:0.1961673367768526\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19578620791435242\n",
      "\n",
      "episode 2, val func loss 0.1890093982219696\n",
      "\n",
      "episode 3, val func loss 0.2081279307603836\n",
      "\n",
      "episode 4, val func loss 0.18756552040576935\n",
      "\n",
      "episode 5, val func loss 0.22306601703166962\n",
      "\n",
      "episode 6, val func loss 0.17837226390838623\n",
      "\n",
      "episode 7, val func loss 0.1825120598077774\n",
      "\n",
      "episode 8, val func loss 0.16471172869205475\n",
      "\n",
      "episode 9, val func loss 0.23829041421413422\n",
      "\n",
      "episode 10, val func loss 0.17869292199611664\n",
      "\n",
      "episode 11, val func loss 0.22211983799934387\n",
      "\n",
      "episode 12, val func loss 0.21705307066440582\n",
      "\n",
      "episode 13, val func loss 0.21638409793376923\n",
      "\n",
      "episode 14, val func loss 0.16496062278747559\n",
      "\n",
      "episode 15, val func loss 0.2143130898475647\n",
      "\n",
      "episode 16, val func loss 0.1801653802394867\n",
      "\n",
      "Val func train loss in epoch 11:0.19757066015154123\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19519369304180145\n",
      "\n",
      "episode 2, val func loss 0.2032986581325531\n",
      "\n",
      "episode 3, val func loss 0.18780288100242615\n",
      "\n",
      "episode 4, val func loss 0.19177202880382538\n",
      "\n",
      "episode 5, val func loss 0.16579070687294006\n",
      "\n",
      "episode 6, val func loss 0.17599010467529297\n",
      "\n",
      "episode 7, val func loss 0.209262877702713\n",
      "\n",
      "episode 8, val func loss 0.21421289443969727\n",
      "\n",
      "episode 9, val func loss 0.23579518496990204\n",
      "\n",
      "episode 10, val func loss 0.21657970547676086\n",
      "\n",
      "episode 11, val func loss 0.21251942217350006\n",
      "\n",
      "episode 12, val func loss 0.2193552404642105\n",
      "\n",
      "episode 13, val func loss 0.17989963293075562\n",
      "\n",
      "episode 14, val func loss 0.1799059808254242\n",
      "\n",
      "episode 15, val func loss 0.17898228764533997\n",
      "\n",
      "episode 16, val func loss 0.17789626121520996\n",
      "\n",
      "Val func train loss in epoch 12:0.19651609752327204\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.2170078009366989\n",
      "\n",
      "episode 2, val func loss 0.2375594824552536\n",
      "\n",
      "episode 3, val func loss 0.18077349662780762\n",
      "\n",
      "episode 4, val func loss 0.17975890636444092\n",
      "\n",
      "episode 5, val func loss 0.17823882400989532\n",
      "\n",
      "episode 6, val func loss 0.21585385501384735\n",
      "\n",
      "episode 7, val func loss 0.21399788558483124\n",
      "\n",
      "episode 8, val func loss 0.16330760717391968\n",
      "\n",
      "episode 9, val func loss 0.19385983049869537\n",
      "\n",
      "episode 10, val func loss 0.2024884819984436\n",
      "\n",
      "episode 11, val func loss 0.1716414839029312\n",
      "\n",
      "episode 12, val func loss 0.19445228576660156\n",
      "\n",
      "episode 13, val func loss 0.21382591128349304\n",
      "\n",
      "episode 14, val func loss 0.22114263474941254\n",
      "\n",
      "episode 15, val func loss 0.17940612137317657\n",
      "\n",
      "episode 16, val func loss 0.18276596069335938\n",
      "\n",
      "Val func train loss in epoch 13:0.1966300355270505\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.21607419848442078\n",
      "\n",
      "episode 2, val func loss 0.19355517625808716\n",
      "\n",
      "episode 3, val func loss 0.1643478125333786\n",
      "\n",
      "episode 4, val func loss 0.20544105768203735\n",
      "\n",
      "episode 5, val func loss 0.23738190531730652\n",
      "\n",
      "episode 6, val func loss 0.18027372658252716\n",
      "\n",
      "episode 7, val func loss 0.17847007513046265\n",
      "\n",
      "episode 8, val func loss 0.21276994049549103\n",
      "\n",
      "episode 9, val func loss 0.21132129430770874\n",
      "\n",
      "episode 10, val func loss 0.17963245511054993\n",
      "\n",
      "episode 11, val func loss 0.18033133447170258\n",
      "\n",
      "episode 12, val func loss 0.2192784994840622\n",
      "\n",
      "episode 13, val func loss 0.21702438592910767\n",
      "\n",
      "episode 14, val func loss 0.19464050233364105\n",
      "\n",
      "episode 15, val func loss 0.1724207103252411\n",
      "\n",
      "episode 16, val func loss 0.18287375569343567\n",
      "\n",
      "Val func train loss in epoch 14:0.1966148018836975\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18284350633621216\n",
      "\n",
      "episode 2, val func loss 0.23861068487167358\n",
      "\n",
      "episode 3, val func loss 0.19585175812244415\n",
      "\n",
      "episode 4, val func loss 0.1796617954969406\n",
      "\n",
      "episode 5, val func loss 0.17714209854602814\n",
      "\n",
      "episode 6, val func loss 0.2145303338766098\n",
      "\n",
      "episode 7, val func loss 0.2186211347579956\n",
      "\n",
      "episode 8, val func loss 0.21373343467712402\n",
      "\n",
      "episode 9, val func loss 0.20572257041931152\n",
      "\n",
      "episode 10, val func loss 0.19461046159267426\n",
      "\n",
      "episode 11, val func loss 0.18766175210475922\n",
      "\n",
      "episode 12, val func loss 0.2144727259874344\n",
      "\n",
      "episode 13, val func loss 0.16901546716690063\n",
      "\n",
      "episode 14, val func loss 0.17948876321315765\n",
      "\n",
      "episode 15, val func loss 0.17088623344898224\n",
      "\n",
      "episode 16, val func loss 0.21574904024600983\n",
      "\n",
      "Val func train loss in epoch 15:0.1974126100540161\n",
      "***********************TIME WAS 5.0003119270006815 min*****************************\n",
      "\n",
      "**********************ROUND 111 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.022693663835525513\n",
      "\n",
      "episode 2, policy loss 0.03787333518266678\n",
      "\n",
      "episode 3, policy loss 0.04704941809177399\n",
      "\n",
      "episode 4, policy loss 0.08181919157505035\n",
      "\n",
      "episode 5, policy loss 0.04872794821858406\n",
      "\n",
      "episode 6, policy loss 0.050299081951379776\n",
      "\n",
      "episode 7, policy loss 0.08135777711868286\n",
      "\n",
      "episode 8, policy loss 0.07234188169240952\n",
      "\n",
      "episode 9, policy loss 0.03542318195104599\n",
      "\n",
      "episode 10, policy loss 0.09752290695905685\n",
      "\n",
      "episode 11, policy loss 0.07241156697273254\n",
      "\n",
      "episode 12, policy loss 0.04065137356519699\n",
      "\n",
      "episode 13, policy loss 0.002201199298724532\n",
      "\n",
      "episode 14, policy loss 0.05919697508215904\n",
      "\n",
      "episode 15, policy loss 0.041066769510507584\n",
      "\n",
      "episode 16, policy loss 0.04965952783823013\n",
      "\n",
      "Policy train loss in epoch 0:0.05251848742773291\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.03357793763279915\n",
      "\n",
      "episode 2, policy loss 0.0470600351691246\n",
      "\n",
      "episode 3, policy loss 0.03842560201883316\n",
      "\n",
      "episode 4, policy loss 0.0011926570441573858\n",
      "\n",
      "episode 5, policy loss 0.0372881218791008\n",
      "\n",
      "episode 6, policy loss 0.049206387251615524\n",
      "\n",
      "episode 7, policy loss 0.092317596077919\n",
      "\n",
      "episode 8, policy loss 0.06832683831453323\n",
      "\n",
      "episode 9, policy loss 0.027817653492093086\n",
      "\n",
      "episode 10, policy loss 0.07042409479618073\n",
      "\n",
      "episode 11, policy loss 0.0811861902475357\n",
      "\n",
      "episode 12, policy loss 0.07835181802511215\n",
      "\n",
      "episode 13, policy loss 0.04955165833234787\n",
      "\n",
      "episode 14, policy loss 0.007572888396680355\n",
      "\n",
      "episode 15, policy loss 0.038497790694236755\n",
      "\n",
      "episode 16, policy loss 0.05819891020655632\n",
      "\n",
      "Policy train loss in epoch 1:0.048687261223676614\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.035148393362760544\n",
      "\n",
      "episode 2, policy loss 0.03106464073061943\n",
      "\n",
      "episode 3, policy loss 0.0673009529709816\n",
      "\n",
      "episode 4, policy loss 0.04435637593269348\n",
      "\n",
      "episode 5, policy loss -0.0009582662605680525\n",
      "\n",
      "episode 6, policy loss 0.026300670579075813\n",
      "\n",
      "episode 7, policy loss 0.09094376116991043\n",
      "\n",
      "episode 8, policy loss 0.038406599313020706\n",
      "\n",
      "episode 9, policy loss 0.0076283784583210945\n",
      "\n",
      "episode 10, policy loss 0.08114100247621536\n",
      "\n",
      "episode 11, policy loss 0.05827346444129944\n",
      "\n",
      "episode 12, policy loss 0.07898464798927307\n",
      "\n",
      "episode 13, policy loss 0.07172763347625732\n",
      "\n",
      "episode 14, policy loss 0.03680039942264557\n",
      "\n",
      "episode 15, policy loss 0.0480511374771595\n",
      "\n",
      "episode 16, policy loss 0.04911823198199272\n",
      "\n",
      "Policy train loss in epoch 2:0.04776800147010363\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.03548732399940491\n",
      "\n",
      "episode 2, policy loss 0.06682667136192322\n",
      "\n",
      "episode 3, policy loss 0.08177632838487625\n",
      "\n",
      "episode 4, policy loss 0.04496866092085838\n",
      "\n",
      "episode 5, policy loss 0.058083675801754\n",
      "\n",
      "episode 6, policy loss 0.04941350221633911\n",
      "\n",
      "episode 7, policy loss 0.09318814426660538\n",
      "\n",
      "episode 8, policy loss 0.03873707726597786\n",
      "\n",
      "episode 9, policy loss 0.007964948192238808\n",
      "\n",
      "episode 10, policy loss 0.0324079804122448\n",
      "\n",
      "episode 11, policy loss -0.00020054633205290884\n",
      "\n",
      "episode 12, policy loss 0.02673456445336342\n",
      "\n",
      "episode 13, policy loss 0.04843364655971527\n",
      "\n",
      "episode 14, policy loss 0.03654101863503456\n",
      "\n",
      "episode 15, policy loss 0.07823611050844193\n",
      "\n",
      "episode 16, policy loss 0.07001928985118866\n",
      "\n",
      "Policy train loss in epoch 3:0.0480386497811196\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19874407351016998\n",
      "\n",
      "episode 2, val func loss 0.17261473834514618\n",
      "\n",
      "episode 3, val func loss 0.18019062280654907\n",
      "\n",
      "episode 4, val func loss 0.2043096274137497\n",
      "\n",
      "episode 5, val func loss 0.19045887887477875\n",
      "\n",
      "episode 6, val func loss 0.18329255282878876\n",
      "\n",
      "episode 7, val func loss 0.20921821892261505\n",
      "\n",
      "episode 8, val func loss 0.19177381694316864\n",
      "\n",
      "episode 9, val func loss 0.19601142406463623\n",
      "\n",
      "episode 10, val func loss 0.21557171642780304\n",
      "\n",
      "episode 11, val func loss 0.20971372723579407\n",
      "\n",
      "episode 12, val func loss 0.16617003083229065\n",
      "\n",
      "episode 13, val func loss 0.2002713978290558\n",
      "\n",
      "episode 14, val func loss 0.18372797966003418\n",
      "\n",
      "episode 15, val func loss 0.21222606301307678\n",
      "\n",
      "episode 16, val func loss 0.20076219737529755\n",
      "\n",
      "Val func train loss in epoch 0:0.19469106663018465\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1953914910554886\n",
      "\n",
      "episode 2, val func loss 0.17877508699893951\n",
      "\n",
      "episode 3, val func loss 0.1889060139656067\n",
      "\n",
      "episode 4, val func loss 0.2037629932165146\n",
      "\n",
      "episode 5, val func loss 0.19248425960540771\n",
      "\n",
      "episode 6, val func loss 0.1839718371629715\n",
      "\n",
      "episode 7, val func loss 0.2118445336818695\n",
      "\n",
      "episode 8, val func loss 0.2010394036769867\n",
      "\n",
      "episode 9, val func loss 0.20844347774982452\n",
      "\n",
      "episode 10, val func loss 0.16371528804302216\n",
      "\n",
      "episode 11, val func loss 0.19875741004943848\n",
      "\n",
      "episode 12, val func loss 0.2108377367258072\n",
      "\n",
      "episode 13, val func loss 0.18201330304145813\n",
      "\n",
      "episode 14, val func loss 0.21497471630573273\n",
      "\n",
      "episode 15, val func loss 0.20026427507400513\n",
      "\n",
      "episode 16, val func loss 0.17250338196754456\n",
      "\n",
      "Val func train loss in epoch 1:0.1942303255200386\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19478562474250793\n",
      "\n",
      "episode 2, val func loss 0.215656116604805\n",
      "\n",
      "episode 3, val func loss 0.1828426718711853\n",
      "\n",
      "episode 4, val func loss 0.20352044701576233\n",
      "\n",
      "episode 5, val func loss 0.16522063314914703\n",
      "\n",
      "episode 6, val func loss 0.1918136328458786\n",
      "\n",
      "episode 7, val func loss 0.21135881543159485\n",
      "\n",
      "episode 8, val func loss 0.20999965071678162\n",
      "\n",
      "episode 9, val func loss 0.18062186241149902\n",
      "\n",
      "episode 10, val func loss 0.20109516382217407\n",
      "\n",
      "episode 11, val func loss 0.1711687296628952\n",
      "\n",
      "episode 12, val func loss 0.20323483645915985\n",
      "\n",
      "episode 13, val func loss 0.19934575259685516\n",
      "\n",
      "episode 14, val func loss 0.18999259173870087\n",
      "\n",
      "episode 15, val func loss 0.17918193340301514\n",
      "\n",
      "episode 16, val func loss 0.21313738822937012\n",
      "\n",
      "Val func train loss in epoch 2:0.19456099066883326\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20327973365783691\n",
      "\n",
      "episode 2, val func loss 0.1722240447998047\n",
      "\n",
      "episode 3, val func loss 0.18350856006145477\n",
      "\n",
      "episode 4, val func loss 0.21478980779647827\n",
      "\n",
      "episode 5, val func loss 0.20018550753593445\n",
      "\n",
      "episode 6, val func loss 0.19880548119544983\n",
      "\n",
      "episode 7, val func loss 0.19435054063796997\n",
      "\n",
      "episode 8, val func loss 0.2137717753648758\n",
      "\n",
      "episode 9, val func loss 0.19053173065185547\n",
      "\n",
      "episode 10, val func loss 0.20117545127868652\n",
      "\n",
      "episode 11, val func loss 0.1863957792520523\n",
      "\n",
      "episode 12, val func loss 0.16323360800743103\n",
      "\n",
      "episode 13, val func loss 0.2096707820892334\n",
      "\n",
      "episode 14, val func loss 0.20799842476844788\n",
      "\n",
      "episode 15, val func loss 0.19098004698753357\n",
      "\n",
      "episode 16, val func loss 0.1783006489276886\n",
      "\n",
      "Val func train loss in epoch 3:0.19432512018829584\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1900017410516739\n",
      "\n",
      "episode 2, val func loss 0.17228370904922485\n",
      "\n",
      "episode 3, val func loss 0.2016162872314453\n",
      "\n",
      "episode 4, val func loss 0.19841352105140686\n",
      "\n",
      "episode 5, val func loss 0.1651626080274582\n",
      "\n",
      "episode 6, val func loss 0.1885455846786499\n",
      "\n",
      "episode 7, val func loss 0.21087783575057983\n",
      "\n",
      "episode 8, val func loss 0.2007937878370285\n",
      "\n",
      "episode 9, val func loss 0.17847077548503876\n",
      "\n",
      "episode 10, val func loss 0.210280179977417\n",
      "\n",
      "episode 11, val func loss 0.20964813232421875\n",
      "\n",
      "episode 12, val func loss 0.20261250436306\n",
      "\n",
      "episode 13, val func loss 0.1987769603729248\n",
      "\n",
      "episode 14, val func loss 0.21563279628753662\n",
      "\n",
      "episode 15, val func loss 0.18403057754039764\n",
      "\n",
      "episode 16, val func loss 0.18655797839164734\n",
      "\n",
      "Val func train loss in epoch 4:0.19460656121373177\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1710866242647171\n",
      "\n",
      "episode 2, val func loss 0.1620176136493683\n",
      "\n",
      "episode 3, val func loss 0.1895865947008133\n",
      "\n",
      "episode 4, val func loss 0.1837475299835205\n",
      "\n",
      "episode 5, val func loss 0.2063940316438675\n",
      "\n",
      "episode 6, val func loss 0.22096207737922668\n",
      "\n",
      "episode 7, val func loss 0.1983986794948578\n",
      "\n",
      "episode 8, val func loss 0.17897753417491913\n",
      "\n",
      "episode 9, val func loss 0.21151673793792725\n",
      "\n",
      "episode 10, val func loss 0.19939671456813812\n",
      "\n",
      "episode 11, val func loss 0.21210384368896484\n",
      "\n",
      "episode 12, val func loss 0.2048129290342331\n",
      "\n",
      "episode 13, val func loss 0.20335227251052856\n",
      "\n",
      "episode 14, val func loss 0.19458630681037903\n",
      "\n",
      "episode 15, val func loss 0.21038399636745453\n",
      "\n",
      "episode 16, val func loss 0.178915873169899\n",
      "\n",
      "Val func train loss in epoch 5:0.19538995996117592\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19600404798984528\n",
      "\n",
      "episode 2, val func loss 0.1710572987794876\n",
      "\n",
      "episode 3, val func loss 0.18987825512886047\n",
      "\n",
      "episode 4, val func loss 0.17869248986244202\n",
      "\n",
      "episode 5, val func loss 0.20856957137584686\n",
      "\n",
      "episode 6, val func loss 0.20267915725708008\n",
      "\n",
      "episode 7, val func loss 0.1757558137178421\n",
      "\n",
      "episode 8, val func loss 0.21026429533958435\n",
      "\n",
      "episode 9, val func loss 0.1828908920288086\n",
      "\n",
      "episode 10, val func loss 0.1995442658662796\n",
      "\n",
      "episode 11, val func loss 0.19544918835163116\n",
      "\n",
      "episode 12, val func loss 0.212116539478302\n",
      "\n",
      "episode 13, val func loss 0.2132912576198578\n",
      "\n",
      "episode 14, val func loss 0.16895011067390442\n",
      "\n",
      "episode 15, val func loss 0.19827167689800262\n",
      "\n",
      "episode 16, val func loss 0.19999948143959045\n",
      "\n",
      "Val func train loss in epoch 6:0.19396339636296034\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19457842409610748\n",
      "\n",
      "episode 2, val func loss 0.21113146841526031\n",
      "\n",
      "episode 3, val func loss 0.20017823576927185\n",
      "\n",
      "episode 4, val func loss 0.19534297287464142\n",
      "\n",
      "episode 5, val func loss 0.21424800157546997\n",
      "\n",
      "episode 6, val func loss 0.1855263113975525\n",
      "\n",
      "episode 7, val func loss 0.17117656767368317\n",
      "\n",
      "episode 8, val func loss 0.20741991698741913\n",
      "\n",
      "episode 9, val func loss 0.1633731871843338\n",
      "\n",
      "episode 10, val func loss 0.1905289590358734\n",
      "\n",
      "episode 11, val func loss 0.20230145752429962\n",
      "\n",
      "episode 12, val func loss 0.18034879863262177\n",
      "\n",
      "episode 13, val func loss 0.1894606351852417\n",
      "\n",
      "episode 14, val func loss 0.21778348088264465\n",
      "\n",
      "episode 15, val func loss 0.2038302719593048\n",
      "\n",
      "episode 16, val func loss 0.17809495329856873\n",
      "\n",
      "Val func train loss in epoch 7:0.1940827276557684\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.18399032950401306\n",
      "\n",
      "episode 2, val func loss 0.21134069561958313\n",
      "\n",
      "episode 3, val func loss 0.16167593002319336\n",
      "\n",
      "episode 4, val func loss 0.18988265097141266\n",
      "\n",
      "episode 5, val func loss 0.20117098093032837\n",
      "\n",
      "episode 6, val func loss 0.16935452818870544\n",
      "\n",
      "episode 7, val func loss 0.1798272579908371\n",
      "\n",
      "episode 8, val func loss 0.19231989979743958\n",
      "\n",
      "episode 9, val func loss 0.1800217181444168\n",
      "\n",
      "episode 10, val func loss 0.20201613008975983\n",
      "\n",
      "episode 11, val func loss 0.2177102118730545\n",
      "\n",
      "episode 12, val func loss 0.20115549862384796\n",
      "\n",
      "episode 13, val func loss 0.2076958268880844\n",
      "\n",
      "episode 14, val func loss 0.20207707583904266\n",
      "\n",
      "episode 15, val func loss 0.2110273540019989\n",
      "\n",
      "episode 16, val func loss 0.19492270052433014\n",
      "\n",
      "Val func train loss in epoch 8:0.194136799313128\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.19669462740421295\n",
      "\n",
      "episode 2, val func loss 0.20137912034988403\n",
      "\n",
      "episode 3, val func loss 0.1803523451089859\n",
      "\n",
      "episode 4, val func loss 0.20042259991168976\n",
      "\n",
      "episode 5, val func loss 0.2024439573287964\n",
      "\n",
      "episode 6, val func loss 0.16392740607261658\n",
      "\n",
      "episode 7, val func loss 0.20762087404727936\n",
      "\n",
      "episode 8, val func loss 0.19570425152778625\n",
      "\n",
      "episode 9, val func loss 0.18938471376895905\n",
      "\n",
      "episode 10, val func loss 0.21080929040908813\n",
      "\n",
      "episode 11, val func loss 0.1706913262605667\n",
      "\n",
      "episode 12, val func loss 0.19200092554092407\n",
      "\n",
      "episode 13, val func loss 0.21308857202529907\n",
      "\n",
      "episode 14, val func loss 0.17911475896835327\n",
      "\n",
      "episode 15, val func loss 0.18344292044639587\n",
      "\n",
      "episode 16, val func loss 0.2162291705608368\n",
      "\n",
      "Val func train loss in epoch 9:0.19395667873322964\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.16287121176719666\n",
      "\n",
      "episode 2, val func loss 0.17875395715236664\n",
      "\n",
      "episode 3, val func loss 0.17231076955795288\n",
      "\n",
      "episode 4, val func loss 0.1788153499364853\n",
      "\n",
      "episode 5, val func loss 0.20072489976882935\n",
      "\n",
      "episode 6, val func loss 0.2026614099740982\n",
      "\n",
      "episode 7, val func loss 0.21062727272510529\n",
      "\n",
      "episode 8, val func loss 0.20324794948101044\n",
      "\n",
      "episode 9, val func loss 0.18975946307182312\n",
      "\n",
      "episode 10, val func loss 0.21373701095581055\n",
      "\n",
      "episode 11, val func loss 0.21555423736572266\n",
      "\n",
      "episode 12, val func loss 0.20918866991996765\n",
      "\n",
      "episode 13, val func loss 0.19884267449378967\n",
      "\n",
      "episode 14, val func loss 0.19784389436244965\n",
      "\n",
      "episode 15, val func loss 0.19532744586467743\n",
      "\n",
      "episode 16, val func loss 0.18884451687335968\n",
      "\n",
      "Val func train loss in epoch 10:0.19494442082941532\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.201104998588562\n",
      "\n",
      "episode 2, val func loss 0.1769927740097046\n",
      "\n",
      "episode 3, val func loss 0.18373045325279236\n",
      "\n",
      "episode 4, val func loss 0.19025494158267975\n",
      "\n",
      "episode 5, val func loss 0.20132173597812653\n",
      "\n",
      "episode 6, val func loss 0.21794503927230835\n",
      "\n",
      "episode 7, val func loss 0.21056228876113892\n",
      "\n",
      "episode 8, val func loss 0.17016592621803284\n",
      "\n",
      "episode 9, val func loss 0.2008938044309616\n",
      "\n",
      "episode 10, val func loss 0.1638980507850647\n",
      "\n",
      "episode 11, val func loss 0.18072986602783203\n",
      "\n",
      "episode 12, val func loss 0.20889826118946075\n",
      "\n",
      "episode 13, val func loss 0.19449836015701294\n",
      "\n",
      "episode 14, val func loss 0.21606852114200592\n",
      "\n",
      "episode 15, val func loss 0.19030539691448212\n",
      "\n",
      "episode 16, val func loss 0.20020850002765656\n",
      "\n",
      "Val func train loss in epoch 11:0.19422368239611387\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19748136401176453\n",
      "\n",
      "episode 2, val func loss 0.20090854167938232\n",
      "\n",
      "episode 3, val func loss 0.17411008477210999\n",
      "\n",
      "episode 4, val func loss 0.1901175081729889\n",
      "\n",
      "episode 5, val func loss 0.21376106142997742\n",
      "\n",
      "episode 6, val func loss 0.1759667992591858\n",
      "\n",
      "episode 7, val func loss 0.20532406866550446\n",
      "\n",
      "episode 8, val func loss 0.18964894115924835\n",
      "\n",
      "episode 9, val func loss 0.21076157689094543\n",
      "\n",
      "episode 10, val func loss 0.1635759472846985\n",
      "\n",
      "episode 11, val func loss 0.21657776832580566\n",
      "\n",
      "episode 12, val func loss 0.18525514006614685\n",
      "\n",
      "episode 13, val func loss 0.19626784324645996\n",
      "\n",
      "episode 14, val func loss 0.17855221033096313\n",
      "\n",
      "episode 15, val func loss 0.2103816121816635\n",
      "\n",
      "episode 16, val func loss 0.20004186034202576\n",
      "\n",
      "Val func train loss in epoch 12:0.1942957704886794\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18303938210010529\n",
      "\n",
      "episode 2, val func loss 0.1841215044260025\n",
      "\n",
      "episode 3, val func loss 0.17177382111549377\n",
      "\n",
      "episode 4, val func loss 0.21010227501392365\n",
      "\n",
      "episode 5, val func loss 0.17972435057163239\n",
      "\n",
      "episode 6, val func loss 0.21687796711921692\n",
      "\n",
      "episode 7, val func loss 0.2024417221546173\n",
      "\n",
      "episode 8, val func loss 0.2008703052997589\n",
      "\n",
      "episode 9, val func loss 0.21004849672317505\n",
      "\n",
      "episode 10, val func loss 0.197658970952034\n",
      "\n",
      "episode 11, val func loss 0.1968231201171875\n",
      "\n",
      "episode 12, val func loss 0.19269959628582\n",
      "\n",
      "episode 13, val func loss 0.18995025753974915\n",
      "\n",
      "episode 14, val func loss 0.1662217378616333\n",
      "\n",
      "episode 15, val func loss 0.2026667445898056\n",
      "\n",
      "episode 16, val func loss 0.2146100401878357\n",
      "\n",
      "Val func train loss in epoch 13:0.19497689325362444\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18960073590278625\n",
      "\n",
      "episode 2, val func loss 0.20088134706020355\n",
      "\n",
      "episode 3, val func loss 0.20078302919864655\n",
      "\n",
      "episode 4, val func loss 0.19763894379138947\n",
      "\n",
      "episode 5, val func loss 0.2135353982448578\n",
      "\n",
      "episode 6, val func loss 0.17299845814704895\n",
      "\n",
      "episode 7, val func loss 0.21462173759937286\n",
      "\n",
      "episode 8, val func loss 0.2105802297592163\n",
      "\n",
      "episode 9, val func loss 0.18583650887012482\n",
      "\n",
      "episode 10, val func loss 0.19343668222427368\n",
      "\n",
      "episode 11, val func loss 0.20977787673473358\n",
      "\n",
      "episode 12, val func loss 0.2011696845293045\n",
      "\n",
      "episode 13, val func loss 0.1629149466753006\n",
      "\n",
      "episode 14, val func loss 0.2039051651954651\n",
      "\n",
      "episode 15, val func loss 0.17803701758384705\n",
      "\n",
      "episode 16, val func loss 0.17945797741413116\n",
      "\n",
      "Val func train loss in epoch 14:0.1946984836831689\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.2158786505460739\n",
      "\n",
      "episode 2, val func loss 0.20035037398338318\n",
      "\n",
      "episode 3, val func loss 0.19198919832706451\n",
      "\n",
      "episode 4, val func loss 0.19604924321174622\n",
      "\n",
      "episode 5, val func loss 0.20960313081741333\n",
      "\n",
      "episode 6, val func loss 0.21004441380500793\n",
      "\n",
      "episode 7, val func loss 0.1651143878698349\n",
      "\n",
      "episode 8, val func loss 0.2006177455186844\n",
      "\n",
      "episode 9, val func loss 0.20270098745822906\n",
      "\n",
      "episode 10, val func loss 0.1812116801738739\n",
      "\n",
      "episode 11, val func loss 0.2155878245830536\n",
      "\n",
      "episode 12, val func loss 0.1704869419336319\n",
      "\n",
      "episode 13, val func loss 0.18367062509059906\n",
      "\n",
      "episode 14, val func loss 0.20130856335163116\n",
      "\n",
      "episode 15, val func loss 0.19085247814655304\n",
      "\n",
      "episode 16, val func loss 0.17685742676258087\n",
      "\n",
      "Val func train loss in epoch 15:0.19452022947371006\n",
      "***********************TIME WAS 5.002367877960205 min*****************************\n",
      "\n",
      "**********************ROUND 112 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.022721223533153534\n",
      "\n",
      "episode 2, policy loss 0.00045971188228577375\n",
      "\n",
      "episode 3, policy loss 0.003273643786087632\n",
      "\n",
      "episode 4, policy loss 0.005523471161723137\n",
      "\n",
      "episode 5, policy loss 0.05239150673151016\n",
      "\n",
      "episode 6, policy loss 0.029533762484788895\n",
      "\n",
      "episode 7, policy loss 0.017767509445548058\n",
      "\n",
      "episode 8, policy loss 0.04204335808753967\n",
      "\n",
      "episode 9, policy loss 0.0374896265566349\n",
      "\n",
      "episode 10, policy loss 0.058693233877420425\n",
      "\n",
      "episode 11, policy loss 0.005949569400399923\n",
      "\n",
      "episode 12, policy loss -0.011047488078474998\n",
      "\n",
      "episode 13, policy loss 0.040228359401226044\n",
      "\n",
      "episode 14, policy loss 0.011197380721569061\n",
      "\n",
      "episode 15, policy loss 0.023341704159975052\n",
      "\n",
      "episode 16, policy loss -0.025284601375460625\n",
      "\n",
      "Policy train loss in epoch 0:0.019642623235995416\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.03778119385242462\n",
      "\n",
      "episode 2, policy loss 0.016013819724321365\n",
      "\n",
      "episode 3, policy loss 0.005277570337057114\n",
      "\n",
      "episode 4, policy loss 0.03493401035666466\n",
      "\n",
      "episode 5, policy loss 0.022495873272418976\n",
      "\n",
      "episode 6, policy loss 0.0017567235045135021\n",
      "\n",
      "episode 7, policy loss -0.02615991048514843\n",
      "\n",
      "episode 8, policy loss -0.006623248569667339\n",
      "\n",
      "episode 9, policy loss 0.058072809129953384\n",
      "\n",
      "episode 10, policy loss 0.046366896480321884\n",
      "\n",
      "episode 11, policy loss 0.04048415645956993\n",
      "\n",
      "episode 12, policy loss -0.008204814046621323\n",
      "\n",
      "episode 13, policy loss 0.009239866398274899\n",
      "\n",
      "episode 14, policy loss 0.0109407315030694\n",
      "\n",
      "episode 15, policy loss 0.026184728369116783\n",
      "\n",
      "episode 16, policy loss -0.012515602633357048\n",
      "\n",
      "Policy train loss in epoch 1:0.016002800228307024\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.008961954154074192\n",
      "\n",
      "episode 2, policy loss -0.00764795858412981\n",
      "\n",
      "episode 3, policy loss -0.013225250877439976\n",
      "\n",
      "episode 4, policy loss 0.022406334057450294\n",
      "\n",
      "episode 5, policy loss 0.025209123268723488\n",
      "\n",
      "episode 6, policy loss 0.03992762044072151\n",
      "\n",
      "episode 7, policy loss 0.014983853325247765\n",
      "\n",
      "episode 8, policy loss 0.057946763932704926\n",
      "\n",
      "episode 9, policy loss -0.026896463707089424\n",
      "\n",
      "episode 10, policy loss 0.034924574196338654\n",
      "\n",
      "episode 11, policy loss 0.00013509378186427057\n",
      "\n",
      "episode 12, policy loss -0.007152739446610212\n",
      "\n",
      "episode 13, policy loss 0.047624584287405014\n",
      "\n",
      "episode 14, policy loss 0.004474380519241095\n",
      "\n",
      "episode 15, policy loss 0.009145613759756088\n",
      "\n",
      "episode 16, policy loss 0.036937493830919266\n",
      "\n",
      "Policy train loss in epoch 2:0.015484686058698571\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.03682122007012367\n",
      "\n",
      "episode 2, policy loss 0.015243515372276306\n",
      "\n",
      "episode 3, policy loss 0.004863315727561712\n",
      "\n",
      "episode 4, policy loss 0.00013324074097909033\n",
      "\n",
      "episode 5, policy loss 0.009941465221345425\n",
      "\n",
      "episode 6, policy loss 0.03496120125055313\n",
      "\n",
      "episode 7, policy loss -0.013712535612285137\n",
      "\n",
      "episode 8, policy loss 0.02487003430724144\n",
      "\n",
      "episode 9, policy loss -0.027019839733839035\n",
      "\n",
      "episode 10, policy loss 0.009063041768968105\n",
      "\n",
      "episode 11, policy loss -0.007346296217292547\n",
      "\n",
      "episode 12, policy loss 0.04715316742658615\n",
      "\n",
      "episode 13, policy loss 0.058065496385097504\n",
      "\n",
      "episode 14, policy loss 0.021977797150611877\n",
      "\n",
      "episode 15, policy loss -0.008471434004604816\n",
      "\n",
      "episode 16, policy loss 0.04012095555663109\n",
      "\n",
      "Policy train loss in epoch 3:0.015416521588122123\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.18631014227867126\n",
      "\n",
      "episode 2, val func loss 0.18395374715328217\n",
      "\n",
      "episode 3, val func loss 0.20946963131427765\n",
      "\n",
      "episode 4, val func loss 0.1818828582763672\n",
      "\n",
      "episode 5, val func loss 0.20663084089756012\n",
      "\n",
      "episode 6, val func loss 0.1959666758775711\n",
      "\n",
      "episode 7, val func loss 0.15659426152706146\n",
      "\n",
      "episode 8, val func loss 0.17122574150562286\n",
      "\n",
      "episode 9, val func loss 0.1782175600528717\n",
      "\n",
      "episode 10, val func loss 0.2104206085205078\n",
      "\n",
      "episode 11, val func loss 0.19511619210243225\n",
      "\n",
      "episode 12, val func loss 0.20188382267951965\n",
      "\n",
      "episode 13, val func loss 0.1998734325170517\n",
      "\n",
      "episode 14, val func loss 0.207046240568161\n",
      "\n",
      "episode 15, val func loss 0.21495948731899261\n",
      "\n",
      "episode 16, val func loss 0.17664924263954163\n",
      "\n",
      "Val func train loss in epoch 0:0.19226253032684326\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19310474395751953\n",
      "\n",
      "episode 2, val func loss 0.15775741636753082\n",
      "\n",
      "episode 3, val func loss 0.1979028433561325\n",
      "\n",
      "episode 4, val func loss 0.16890360414981842\n",
      "\n",
      "episode 5, val func loss 0.20155322551727295\n",
      "\n",
      "episode 6, val func loss 0.18898464739322662\n",
      "\n",
      "episode 7, val func loss 0.1853685826063156\n",
      "\n",
      "episode 8, val func loss 0.20439152419567108\n",
      "\n",
      "episode 9, val func loss 0.17417965829372406\n",
      "\n",
      "episode 10, val func loss 0.17708787322044373\n",
      "\n",
      "episode 11, val func loss 0.18128854036331177\n",
      "\n",
      "episode 12, val func loss 0.19959089159965515\n",
      "\n",
      "episode 13, val func loss 0.21468113362789154\n",
      "\n",
      "episode 14, val func loss 0.21381378173828125\n",
      "\n",
      "episode 15, val func loss 0.20799584686756134\n",
      "\n",
      "episode 16, val func loss 0.20557242631912231\n",
      "\n",
      "Val func train loss in epoch 1:0.19201104622334242\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.20068798959255219\n",
      "\n",
      "episode 2, val func loss 0.19720590114593506\n",
      "\n",
      "episode 3, val func loss 0.17995676398277283\n",
      "\n",
      "episode 4, val func loss 0.17288954555988312\n",
      "\n",
      "episode 5, val func loss 0.20759998261928558\n",
      "\n",
      "episode 6, val func loss 0.15731875598430634\n",
      "\n",
      "episode 7, val func loss 0.18593361973762512\n",
      "\n",
      "episode 8, val func loss 0.19364529848098755\n",
      "\n",
      "episode 9, val func loss 0.19660741090774536\n",
      "\n",
      "episode 10, val func loss 0.1861511915922165\n",
      "\n",
      "episode 11, val func loss 0.21147601306438446\n",
      "\n",
      "episode 12, val func loss 0.21548233926296234\n",
      "\n",
      "episode 13, val func loss 0.20926165580749512\n",
      "\n",
      "episode 14, val func loss 0.1763269156217575\n",
      "\n",
      "episode 15, val func loss 0.1849273145198822\n",
      "\n",
      "episode 16, val func loss 0.20562325417995453\n",
      "\n",
      "Val func train loss in epoch 2:0.1925683720037341\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.2044520378112793\n",
      "\n",
      "episode 2, val func loss 0.15878421068191528\n",
      "\n",
      "episode 3, val func loss 0.20531584322452545\n",
      "\n",
      "episode 4, val func loss 0.2060401439666748\n",
      "\n",
      "episode 5, val func loss 0.2124944031238556\n",
      "\n",
      "episode 6, val func loss 0.1865306943655014\n",
      "\n",
      "episode 7, val func loss 0.18921072781085968\n",
      "\n",
      "episode 8, val func loss 0.1774173229932785\n",
      "\n",
      "episode 9, val func loss 0.18275441229343414\n",
      "\n",
      "episode 10, val func loss 0.1985827535390854\n",
      "\n",
      "episode 11, val func loss 0.2045271396636963\n",
      "\n",
      "episode 12, val func loss 0.17069858312606812\n",
      "\n",
      "episode 13, val func loss 0.19491533935070038\n",
      "\n",
      "episode 14, val func loss 0.17471078038215637\n",
      "\n",
      "episode 15, val func loss 0.1997087299823761\n",
      "\n",
      "episode 16, val func loss 0.20751352608203888\n",
      "\n",
      "Val func train loss in epoch 3:0.19210354052484035\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.20850110054016113\n",
      "\n",
      "episode 2, val func loss 0.17863766849040985\n",
      "\n",
      "episode 3, val func loss 0.1881934255361557\n",
      "\n",
      "episode 4, val func loss 0.1905623823404312\n",
      "\n",
      "episode 5, val func loss 0.17070087790489197\n",
      "\n",
      "episode 6, val func loss 0.20407836139202118\n",
      "\n",
      "episode 7, val func loss 0.20901812613010406\n",
      "\n",
      "episode 8, val func loss 0.17821051180362701\n",
      "\n",
      "episode 9, val func loss 0.19791968166828156\n",
      "\n",
      "episode 10, val func loss 0.20043997466564178\n",
      "\n",
      "episode 11, val func loss 0.20127691328525543\n",
      "\n",
      "episode 12, val func loss 0.21323063969612122\n",
      "\n",
      "episode 13, val func loss 0.15852615237236023\n",
      "\n",
      "episode 14, val func loss 0.18335707485675812\n",
      "\n",
      "episode 15, val func loss 0.20985177159309387\n",
      "\n",
      "episode 16, val func loss 0.19496138393878937\n",
      "\n",
      "Val func train loss in epoch 4:0.19296662788838148\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19464527070522308\n",
      "\n",
      "episode 2, val func loss 0.1587173193693161\n",
      "\n",
      "episode 3, val func loss 0.19760563969612122\n",
      "\n",
      "episode 4, val func loss 0.20089800655841827\n",
      "\n",
      "episode 5, val func loss 0.21267594397068024\n",
      "\n",
      "episode 6, val func loss 0.18883571028709412\n",
      "\n",
      "episode 7, val func loss 0.20943869650363922\n",
      "\n",
      "episode 8, val func loss 0.17637357115745544\n",
      "\n",
      "episode 9, val func loss 0.18556690216064453\n",
      "\n",
      "episode 10, val func loss 0.20905958116054535\n",
      "\n",
      "episode 11, val func loss 0.20524999499320984\n",
      "\n",
      "episode 12, val func loss 0.1986648589372635\n",
      "\n",
      "episode 13, val func loss 0.1697089821100235\n",
      "\n",
      "episode 14, val func loss 0.18350879848003387\n",
      "\n",
      "episode 15, val func loss 0.2085452675819397\n",
      "\n",
      "episode 16, val func loss 0.17767487466335297\n",
      "\n",
      "Val func train loss in epoch 5:0.19232308864593506\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1578052043914795\n",
      "\n",
      "episode 2, val func loss 0.20768065750598907\n",
      "\n",
      "episode 3, val func loss 0.20837680995464325\n",
      "\n",
      "episode 4, val func loss 0.18873745203018188\n",
      "\n",
      "episode 5, val func loss 0.21323847770690918\n",
      "\n",
      "episode 6, val func loss 0.17603501677513123\n",
      "\n",
      "episode 7, val func loss 0.17760640382766724\n",
      "\n",
      "episode 8, val func loss 0.1946631819009781\n",
      "\n",
      "episode 9, val func loss 0.19773012399673462\n",
      "\n",
      "episode 10, val func loss 0.18340082466602325\n",
      "\n",
      "episode 11, val func loss 0.20065082609653473\n",
      "\n",
      "episode 12, val func loss 0.19759923219680786\n",
      "\n",
      "episode 13, val func loss 0.2114071249961853\n",
      "\n",
      "episode 14, val func loss 0.16828139126300812\n",
      "\n",
      "episode 15, val func loss 0.20513638854026794\n",
      "\n",
      "episode 16, val func loss 0.18498727679252625\n",
      "\n",
      "Val func train loss in epoch 6:0.19208352454006672\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.20346476137638092\n",
      "\n",
      "episode 2, val func loss 0.21254988014698029\n",
      "\n",
      "episode 3, val func loss 0.19847168028354645\n",
      "\n",
      "episode 4, val func loss 0.1773374378681183\n",
      "\n",
      "episode 5, val func loss 0.18498583137989044\n",
      "\n",
      "episode 6, val func loss 0.20779618620872498\n",
      "\n",
      "episode 7, val func loss 0.18736852705478668\n",
      "\n",
      "episode 8, val func loss 0.18382786214351654\n",
      "\n",
      "episode 9, val func loss 0.19602298736572266\n",
      "\n",
      "episode 10, val func loss 0.2105282098054886\n",
      "\n",
      "episode 11, val func loss 0.19609178602695465\n",
      "\n",
      "episode 12, val func loss 0.21111121773719788\n",
      "\n",
      "episode 13, val func loss 0.1747429370880127\n",
      "\n",
      "episode 14, val func loss 0.15713444352149963\n",
      "\n",
      "episode 15, val func loss 0.20073090493679047\n",
      "\n",
      "episode 16, val func loss 0.16947056353092194\n",
      "\n",
      "Val func train loss in epoch 7:0.19197720102965832\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.18717044591903687\n",
      "\n",
      "episode 2, val func loss 0.17225824296474457\n",
      "\n",
      "episode 3, val func loss 0.17914104461669922\n",
      "\n",
      "episode 4, val func loss 0.20146235823631287\n",
      "\n",
      "episode 5, val func loss 0.19892586767673492\n",
      "\n",
      "episode 6, val func loss 0.1951315999031067\n",
      "\n",
      "episode 7, val func loss 0.186801478266716\n",
      "\n",
      "episode 8, val func loss 0.15897609293460846\n",
      "\n",
      "episode 9, val func loss 0.19865651428699493\n",
      "\n",
      "episode 10, val func loss 0.2116256058216095\n",
      "\n",
      "episode 11, val func loss 0.17472536861896515\n",
      "\n",
      "episode 12, val func loss 0.2077292650938034\n",
      "\n",
      "episode 13, val func loss 0.1848696917295456\n",
      "\n",
      "episode 14, val func loss 0.2052413374185562\n",
      "\n",
      "episode 15, val func loss 0.20803534984588623\n",
      "\n",
      "episode 16, val func loss 0.21229273080825806\n",
      "\n",
      "Val func train loss in epoch 8:0.19269018713384867\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1964893788099289\n",
      "\n",
      "episode 2, val func loss 0.15758979320526123\n",
      "\n",
      "episode 3, val func loss 0.18579158186912537\n",
      "\n",
      "episode 4, val func loss 0.17921344935894012\n",
      "\n",
      "episode 5, val func loss 0.20783057808876038\n",
      "\n",
      "episode 6, val func loss 0.20114339888095856\n",
      "\n",
      "episode 7, val func loss 0.2097207009792328\n",
      "\n",
      "episode 8, val func loss 0.1754893660545349\n",
      "\n",
      "episode 9, val func loss 0.1957961767911911\n",
      "\n",
      "episode 10, val func loss 0.1682226061820984\n",
      "\n",
      "episode 11, val func loss 0.2050589919090271\n",
      "\n",
      "episode 12, val func loss 0.1841362863779068\n",
      "\n",
      "episode 13, val func loss 0.2067856341600418\n",
      "\n",
      "episode 14, val func loss 0.1971205472946167\n",
      "\n",
      "episode 15, val func loss 0.21249543130397797\n",
      "\n",
      "episode 16, val func loss 0.18910300731658936\n",
      "\n",
      "Val func train loss in epoch 9:0.19199918303638697\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20013973116874695\n",
      "\n",
      "episode 2, val func loss 0.19804689288139343\n",
      "\n",
      "episode 3, val func loss 0.18294832110404968\n",
      "\n",
      "episode 4, val func loss 0.18271324038505554\n",
      "\n",
      "episode 5, val func loss 0.18670806288719177\n",
      "\n",
      "episode 6, val func loss 0.15848936140537262\n",
      "\n",
      "episode 7, val func loss 0.1986619532108307\n",
      "\n",
      "episode 8, val func loss 0.21078777313232422\n",
      "\n",
      "episode 9, val func loss 0.17690859735012054\n",
      "\n",
      "episode 10, val func loss 0.20884539186954498\n",
      "\n",
      "episode 11, val func loss 0.16740620136260986\n",
      "\n",
      "episode 12, val func loss 0.20785102248191833\n",
      "\n",
      "episode 13, val func loss 0.20323096215724945\n",
      "\n",
      "episode 14, val func loss 0.21032193303108215\n",
      "\n",
      "episode 15, val func loss 0.17884103953838348\n",
      "\n",
      "episode 16, val func loss 0.20274129509925842\n",
      "\n",
      "Val func train loss in epoch 10:0.19216511119157076\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18150553107261658\n",
      "\n",
      "episode 2, val func loss 0.2072567343711853\n",
      "\n",
      "episode 3, val func loss 0.20377972722053528\n",
      "\n",
      "episode 4, val func loss 0.19738493859767914\n",
      "\n",
      "episode 5, val func loss 0.21161113679409027\n",
      "\n",
      "episode 6, val func loss 0.20095650851726532\n",
      "\n",
      "episode 7, val func loss 0.20065365731716156\n",
      "\n",
      "episode 8, val func loss 0.21178635954856873\n",
      "\n",
      "episode 9, val func loss 0.1891893744468689\n",
      "\n",
      "episode 10, val func loss 0.17119894921779633\n",
      "\n",
      "episode 11, val func loss 0.20754197239875793\n",
      "\n",
      "episode 12, val func loss 0.1891791820526123\n",
      "\n",
      "episode 13, val func loss 0.1788216084241867\n",
      "\n",
      "episode 14, val func loss 0.21347717940807343\n",
      "\n",
      "episode 15, val func loss 0.18640640377998352\n",
      "\n",
      "episode 16, val func loss 0.15778550505638123\n",
      "\n",
      "Val func train loss in epoch 11:0.19428342301398516\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1982850879430771\n",
      "\n",
      "episode 2, val func loss 0.20934706926345825\n",
      "\n",
      "episode 3, val func loss 0.15838903188705444\n",
      "\n",
      "episode 4, val func loss 0.1843227595090866\n",
      "\n",
      "episode 5, val func loss 0.20086254179477692\n",
      "\n",
      "episode 6, val func loss 0.18785680830478668\n",
      "\n",
      "episode 7, val func loss 0.1700126975774765\n",
      "\n",
      "episode 8, val func loss 0.19517023861408234\n",
      "\n",
      "episode 9, val func loss 0.19867964088916779\n",
      "\n",
      "episode 10, val func loss 0.21082530915737152\n",
      "\n",
      "episode 11, val func loss 0.20788012444972992\n",
      "\n",
      "episode 12, val func loss 0.2054164707660675\n",
      "\n",
      "episode 13, val func loss 0.2137453258037567\n",
      "\n",
      "episode 14, val func loss 0.17780281603336334\n",
      "\n",
      "episode 15, val func loss 0.1797332763671875\n",
      "\n",
      "episode 16, val func loss 0.18499623239040375\n",
      "\n",
      "Val func train loss in epoch 12:0.19270783942192793\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.20792937278747559\n",
      "\n",
      "episode 2, val func loss 0.17749476432800293\n",
      "\n",
      "episode 3, val func loss 0.19508975744247437\n",
      "\n",
      "episode 4, val func loss 0.18244196474552155\n",
      "\n",
      "episode 5, val func loss 0.20644085109233856\n",
      "\n",
      "episode 6, val func loss 0.18759837746620178\n",
      "\n",
      "episode 7, val func loss 0.17519080638885498\n",
      "\n",
      "episode 8, val func loss 0.15896745026111603\n",
      "\n",
      "episode 9, val func loss 0.21042007207870483\n",
      "\n",
      "episode 10, val func loss 0.20124506950378418\n",
      "\n",
      "episode 11, val func loss 0.2132655531167984\n",
      "\n",
      "episode 12, val func loss 0.20765520632266998\n",
      "\n",
      "episode 13, val func loss 0.19946543872356415\n",
      "\n",
      "episode 14, val func loss 0.20244565606117249\n",
      "\n",
      "episode 15, val func loss 0.18972617387771606\n",
      "\n",
      "episode 16, val func loss 0.17010359466075897\n",
      "\n",
      "Val func train loss in epoch 13:0.19284250680357218\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19487221539020538\n",
      "\n",
      "episode 2, val func loss 0.21397869288921356\n",
      "\n",
      "episode 3, val func loss 0.15881888568401337\n",
      "\n",
      "episode 4, val func loss 0.1987527459859848\n",
      "\n",
      "episode 5, val func loss 0.2095293402671814\n",
      "\n",
      "episode 6, val func loss 0.2013072967529297\n",
      "\n",
      "episode 7, val func loss 0.17812475562095642\n",
      "\n",
      "episode 8, val func loss 0.20806363224983215\n",
      "\n",
      "episode 9, val func loss 0.1894558072090149\n",
      "\n",
      "episode 10, val func loss 0.20495769381523132\n",
      "\n",
      "episode 11, val func loss 0.18528231978416443\n",
      "\n",
      "episode 12, val func loss 0.1982598602771759\n",
      "\n",
      "episode 13, val func loss 0.18333132565021515\n",
      "\n",
      "episode 14, val func loss 0.21122050285339355\n",
      "\n",
      "episode 15, val func loss 0.170100137591362\n",
      "\n",
      "episode 16, val func loss 0.17515027523040771\n",
      "\n",
      "Val func train loss in epoch 14:0.1925753429532051\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1881749927997589\n",
      "\n",
      "episode 2, val func loss 0.15815424919128418\n",
      "\n",
      "episode 3, val func loss 0.2135457545518875\n",
      "\n",
      "episode 4, val func loss 0.1750352680683136\n",
      "\n",
      "episode 5, val func loss 0.20895171165466309\n",
      "\n",
      "episode 6, val func loss 0.17741815745830536\n",
      "\n",
      "episode 7, val func loss 0.20987258851528168\n",
      "\n",
      "episode 8, val func loss 0.1851249784231186\n",
      "\n",
      "episode 9, val func loss 0.20471221208572388\n",
      "\n",
      "episode 10, val func loss 0.18446142971515656\n",
      "\n",
      "episode 11, val func loss 0.16955699026584625\n",
      "\n",
      "episode 12, val func loss 0.2077060341835022\n",
      "\n",
      "episode 13, val func loss 0.1946539729833603\n",
      "\n",
      "episode 14, val func loss 0.1982819139957428\n",
      "\n",
      "episode 15, val func loss 0.20104040205478668\n",
      "\n",
      "episode 16, val func loss 0.19802403450012207\n",
      "\n",
      "Val func train loss in epoch 15:0.19216966815292835\n",
      "***********************TIME WAS 5.004350248972575 min*****************************\n",
      "\n",
      "**********************ROUND 113 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.0675453245639801\n",
      "\n",
      "episode 2, policy loss -0.005785451270639896\n",
      "\n",
      "episode 3, policy loss -0.028684601187705994\n",
      "\n",
      "episode 4, policy loss -0.06022932007908821\n",
      "\n",
      "episode 5, policy loss -0.03436795622110367\n",
      "\n",
      "episode 6, policy loss -0.05119725316762924\n",
      "\n",
      "episode 7, policy loss 0.007434628438204527\n",
      "\n",
      "episode 8, policy loss -0.01753374934196472\n",
      "\n",
      "episode 9, policy loss -0.08846555650234222\n",
      "\n",
      "episode 10, policy loss -0.011566503904759884\n",
      "\n",
      "episode 11, policy loss -0.0487741120159626\n",
      "\n",
      "episode 12, policy loss -0.012858920730650425\n",
      "\n",
      "episode 13, policy loss 0.02829657308757305\n",
      "\n",
      "episode 14, policy loss -0.039751868695020676\n",
      "\n",
      "episode 15, policy loss -0.1230190098285675\n",
      "\n",
      "episode 16, policy loss 0.021012311801314354\n",
      "\n",
      "Policy train loss in epoch 0:-0.0333147571363952\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.08138221502304077\n",
      "\n",
      "episode 2, policy loss 0.009698047302663326\n",
      "\n",
      "episode 3, policy loss -0.016048669815063477\n",
      "\n",
      "episode 4, policy loss -0.015299495309591293\n",
      "\n",
      "episode 5, policy loss -0.042176321148872375\n",
      "\n",
      "episode 6, policy loss 0.01930037885904312\n",
      "\n",
      "episode 7, policy loss -0.014565241523087025\n",
      "\n",
      "episode 8, policy loss -0.052139151841402054\n",
      "\n",
      "episode 9, policy loss -0.12451419979333878\n",
      "\n",
      "episode 10, policy loss -0.0893029198050499\n",
      "\n",
      "episode 11, policy loss -0.06514298915863037\n",
      "\n",
      "episode 12, policy loss 0.022848064079880714\n",
      "\n",
      "episode 13, policy loss -0.03818218782544136\n",
      "\n",
      "episode 14, policy loss -0.03681496903300285\n",
      "\n",
      "episode 15, policy loss -0.013702450320124626\n",
      "\n",
      "episode 16, policy loss -0.05054965987801552\n",
      "\n",
      "Policy train loss in epoch 1:-0.03674837376456708\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.017250685021281242\n",
      "\n",
      "episode 2, policy loss -0.013145978562533855\n",
      "\n",
      "episode 3, policy loss -0.04498763009905815\n",
      "\n",
      "episode 4, policy loss -0.01787933148443699\n",
      "\n",
      "episode 5, policy loss 0.024094300344586372\n",
      "\n",
      "episode 6, policy loss -0.03992718830704689\n",
      "\n",
      "episode 7, policy loss 0.006905488204210997\n",
      "\n",
      "episode 8, policy loss -0.03644184023141861\n",
      "\n",
      "episode 9, policy loss -0.06711713969707489\n",
      "\n",
      "episode 10, policy loss -0.014865351840853691\n",
      "\n",
      "episode 11, policy loss -0.051326457411050797\n",
      "\n",
      "episode 12, policy loss -0.0897756814956665\n",
      "\n",
      "episode 13, policy loss 0.018604569137096405\n",
      "\n",
      "episode 14, policy loss -0.12593458592891693\n",
      "\n",
      "episode 15, policy loss -0.05288831517100334\n",
      "\n",
      "episode 16, policy loss -0.08305930346250534\n",
      "\n",
      "Policy train loss in epoch 2:-0.03781219568918459\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.09023106098175049\n",
      "\n",
      "episode 2, policy loss -0.053032081574201584\n",
      "\n",
      "episode 3, policy loss 0.00661156140267849\n",
      "\n",
      "episode 4, policy loss -0.04471734166145325\n",
      "\n",
      "episode 5, policy loss -0.12664347887039185\n",
      "\n",
      "episode 6, policy loss 0.018545348197221756\n",
      "\n",
      "episode 7, policy loss -0.08285025507211685\n",
      "\n",
      "episode 8, policy loss -0.03687773272395134\n",
      "\n",
      "episode 9, policy loss 0.023224296048283577\n",
      "\n",
      "episode 10, policy loss -0.013327165506780148\n",
      "\n",
      "episode 11, policy loss -0.017653394490480423\n",
      "\n",
      "episode 12, policy loss -0.05178495869040489\n",
      "\n",
      "episode 13, policy loss -0.018217036500573158\n",
      "\n",
      "episode 14, policy loss -0.040434155613183975\n",
      "\n",
      "episode 15, policy loss -0.06740375608205795\n",
      "\n",
      "episode 16, policy loss -0.014832673594355583\n",
      "\n",
      "Policy train loss in epoch 3:-0.038101492857094854\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.200770303606987\n",
      "\n",
      "episode 2, val func loss 0.16729353368282318\n",
      "\n",
      "episode 3, val func loss 0.17531231045722961\n",
      "\n",
      "episode 4, val func loss 0.19493140280246735\n",
      "\n",
      "episode 5, val func loss 0.20356427133083344\n",
      "\n",
      "episode 6, val func loss 0.19134630262851715\n",
      "\n",
      "episode 7, val func loss 0.16195589303970337\n",
      "\n",
      "episode 8, val func loss 0.1756557822227478\n",
      "\n",
      "episode 9, val func loss 0.23294824361801147\n",
      "\n",
      "episode 10, val func loss 0.21104900538921356\n",
      "\n",
      "episode 11, val func loss 0.17812363803386688\n",
      "\n",
      "episode 12, val func loss 0.21985746920108795\n",
      "\n",
      "episode 13, val func loss 0.1903063803911209\n",
      "\n",
      "episode 14, val func loss 0.225061297416687\n",
      "\n",
      "episode 15, val func loss 0.1907622516155243\n",
      "\n",
      "episode 16, val func loss 0.22416308522224426\n",
      "\n",
      "Val func train loss in epoch 0:0.19644382316619158\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17958100140094757\n",
      "\n",
      "episode 2, val func loss 0.2026994526386261\n",
      "\n",
      "episode 3, val func loss 0.2095731943845749\n",
      "\n",
      "episode 4, val func loss 0.1951686292886734\n",
      "\n",
      "episode 5, val func loss 0.1899009793996811\n",
      "\n",
      "episode 6, val func loss 0.1622399091720581\n",
      "\n",
      "episode 7, val func loss 0.22024321556091309\n",
      "\n",
      "episode 8, val func loss 0.20191778242588043\n",
      "\n",
      "episode 9, val func loss 0.2319985330104828\n",
      "\n",
      "episode 10, val func loss 0.22480979561805725\n",
      "\n",
      "episode 11, val func loss 0.22489243745803833\n",
      "\n",
      "episode 12, val func loss 0.19113168120384216\n",
      "\n",
      "episode 13, val func loss 0.19159415364265442\n",
      "\n",
      "episode 14, val func loss 0.17829592525959015\n",
      "\n",
      "episode 15, val func loss 0.1762324720621109\n",
      "\n",
      "episode 16, val func loss 0.1693279892206192\n",
      "\n",
      "Val func train loss in epoch 1:0.19685044698417187\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19034717977046967\n",
      "\n",
      "episode 2, val func loss 0.19004756212234497\n",
      "\n",
      "episode 3, val func loss 0.21164193749427795\n",
      "\n",
      "episode 4, val func loss 0.20226553082466125\n",
      "\n",
      "episode 5, val func loss 0.22693155705928802\n",
      "\n",
      "episode 6, val func loss 0.22738105058670044\n",
      "\n",
      "episode 7, val func loss 0.17570596933364868\n",
      "\n",
      "episode 8, val func loss 0.16185888648033142\n",
      "\n",
      "episode 9, val func loss 0.17539086937904358\n",
      "\n",
      "episode 10, val func loss 0.16631951928138733\n",
      "\n",
      "episode 11, val func loss 0.19095823168754578\n",
      "\n",
      "episode 12, val func loss 0.19454962015151978\n",
      "\n",
      "episode 13, val func loss 0.21994340419769287\n",
      "\n",
      "episode 14, val func loss 0.2033509761095047\n",
      "\n",
      "episode 15, val func loss 0.17715702950954437\n",
      "\n",
      "episode 16, val func loss 0.23150157928466797\n",
      "\n",
      "Val func train loss in epoch 2:0.1965844314545393\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19479672610759735\n",
      "\n",
      "episode 2, val func loss 0.19034819304943085\n",
      "\n",
      "episode 3, val func loss 0.22000963985919952\n",
      "\n",
      "episode 4, val func loss 0.1913978010416031\n",
      "\n",
      "episode 5, val func loss 0.16658839583396912\n",
      "\n",
      "episode 6, val func loss 0.2256401628255844\n",
      "\n",
      "episode 7, val func loss 0.22492194175720215\n",
      "\n",
      "episode 8, val func loss 0.23000383377075195\n",
      "\n",
      "episode 9, val func loss 0.17692363262176514\n",
      "\n",
      "episode 10, val func loss 0.20120787620544434\n",
      "\n",
      "episode 11, val func loss 0.17573434114456177\n",
      "\n",
      "episode 12, val func loss 0.18106111884117126\n",
      "\n",
      "episode 13, val func loss 0.20879030227661133\n",
      "\n",
      "episode 14, val func loss 0.19072383642196655\n",
      "\n",
      "episode 15, val func loss 0.20295120775699615\n",
      "\n",
      "episode 16, val func loss 0.1621858775615692\n",
      "\n",
      "Val func train loss in epoch 3:0.196455305442214\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19458742439746857\n",
      "\n",
      "episode 2, val func loss 0.23244675993919373\n",
      "\n",
      "episode 3, val func loss 0.18965107202529907\n",
      "\n",
      "episode 4, val func loss 0.17521116137504578\n",
      "\n",
      "episode 5, val func loss 0.2032688409090042\n",
      "\n",
      "episode 6, val func loss 0.22622741758823395\n",
      "\n",
      "episode 7, val func loss 0.20124265551567078\n",
      "\n",
      "episode 8, val func loss 0.20926576852798462\n",
      "\n",
      "episode 9, val func loss 0.2239125370979309\n",
      "\n",
      "episode 10, val func loss 0.19140301644802094\n",
      "\n",
      "episode 11, val func loss 0.19179262220859528\n",
      "\n",
      "episode 12, val func loss 0.17140841484069824\n",
      "\n",
      "episode 13, val func loss 0.16453294456005096\n",
      "\n",
      "episode 14, val func loss 0.21960581839084625\n",
      "\n",
      "episode 15, val func loss 0.17883338034152985\n",
      "\n",
      "episode 16, val func loss 0.17567852139472961\n",
      "\n",
      "Val func train loss in epoch 4:0.19681677222251892\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19447650015354156\n",
      "\n",
      "episode 2, val func loss 0.19046618044376373\n",
      "\n",
      "episode 3, val func loss 0.20404572784900665\n",
      "\n",
      "episode 4, val func loss 0.23875631392002106\n",
      "\n",
      "episode 5, val func loss 0.2218153178691864\n",
      "\n",
      "episode 6, val func loss 0.17584386467933655\n",
      "\n",
      "episode 7, val func loss 0.1752742975950241\n",
      "\n",
      "episode 8, val func loss 0.20985569059848785\n",
      "\n",
      "episode 9, val func loss 0.2026325762271881\n",
      "\n",
      "episode 10, val func loss 0.17126329243183136\n",
      "\n",
      "episode 11, val func loss 0.1646784245967865\n",
      "\n",
      "episode 12, val func loss 0.19158175587654114\n",
      "\n",
      "episode 13, val func loss 0.17857010662555695\n",
      "\n",
      "episode 14, val func loss 0.22714665532112122\n",
      "\n",
      "episode 15, val func loss 0.18933135271072388\n",
      "\n",
      "episode 16, val func loss 0.22693954408168793\n",
      "\n",
      "Val func train loss in epoch 5:0.1976673500612378\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.2258371263742447\n",
      "\n",
      "episode 2, val func loss 0.21012447774410248\n",
      "\n",
      "episode 3, val func loss 0.22532092034816742\n",
      "\n",
      "episode 4, val func loss 0.17579568922519684\n",
      "\n",
      "episode 5, val func loss 0.1771513968706131\n",
      "\n",
      "episode 6, val func loss 0.19165225327014923\n",
      "\n",
      "episode 7, val func loss 0.1955375075340271\n",
      "\n",
      "episode 8, val func loss 0.1675054281949997\n",
      "\n",
      "episode 9, val func loss 0.2013198286294937\n",
      "\n",
      "episode 10, val func loss 0.2206691950559616\n",
      "\n",
      "episode 11, val func loss 0.16173996031284332\n",
      "\n",
      "episode 12, val func loss 0.17492371797561646\n",
      "\n",
      "episode 13, val func loss 0.18896490335464478\n",
      "\n",
      "episode 14, val func loss 0.23820409178733826\n",
      "\n",
      "episode 15, val func loss 0.19266127049922943\n",
      "\n",
      "episode 16, val func loss 0.20330624282360077\n",
      "\n",
      "Val func train loss in epoch 6:0.1969196256250143\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.22495241463184357\n",
      "\n",
      "episode 2, val func loss 0.2029450535774231\n",
      "\n",
      "episode 3, val func loss 0.2017238885164261\n",
      "\n",
      "episode 4, val func loss 0.19240427017211914\n",
      "\n",
      "episode 5, val func loss 0.19209223985671997\n",
      "\n",
      "episode 6, val func loss 0.22390694916248322\n",
      "\n",
      "episode 7, val func loss 0.1964508593082428\n",
      "\n",
      "episode 8, val func loss 0.16983504593372345\n",
      "\n",
      "episode 9, val func loss 0.22959904372692108\n",
      "\n",
      "episode 10, val func loss 0.16277119517326355\n",
      "\n",
      "episode 11, val func loss 0.21015198528766632\n",
      "\n",
      "episode 12, val func loss 0.18993772566318512\n",
      "\n",
      "episode 13, val func loss 0.17657698690891266\n",
      "\n",
      "episode 14, val func loss 0.1754172444343567\n",
      "\n",
      "episode 15, val func loss 0.17597472667694092\n",
      "\n",
      "episode 16, val func loss 0.2220144271850586\n",
      "\n",
      "Val func train loss in epoch 7:0.1966721285134554\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17517094314098358\n",
      "\n",
      "episode 2, val func loss 0.16404792666435242\n",
      "\n",
      "episode 3, val func loss 0.1941651701927185\n",
      "\n",
      "episode 4, val func loss 0.1912940889596939\n",
      "\n",
      "episode 5, val func loss 0.2049468606710434\n",
      "\n",
      "episode 6, val func loss 0.17556162178516388\n",
      "\n",
      "episode 7, val func loss 0.19019322097301483\n",
      "\n",
      "episode 8, val func loss 0.161337748169899\n",
      "\n",
      "episode 9, val func loss 0.20133070647716522\n",
      "\n",
      "episode 10, val func loss 0.22829659283161163\n",
      "\n",
      "episode 11, val func loss 0.22483088076114655\n",
      "\n",
      "episode 12, val func loss 0.2244468778371811\n",
      "\n",
      "episode 13, val func loss 0.18459278345108032\n",
      "\n",
      "episode 14, val func loss 0.21917569637298584\n",
      "\n",
      "episode 15, val func loss 0.19383642077445984\n",
      "\n",
      "episode 16, val func loss 0.20934666693210602\n",
      "\n",
      "Val func train loss in epoch 8:0.19641088787466288\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.23090790212154388\n",
      "\n",
      "episode 2, val func loss 0.1905554234981537\n",
      "\n",
      "episode 3, val func loss 0.2027818113565445\n",
      "\n",
      "episode 4, val func loss 0.16633297502994537\n",
      "\n",
      "episode 5, val func loss 0.17804192006587982\n",
      "\n",
      "episode 6, val func loss 0.2205396592617035\n",
      "\n",
      "episode 7, val func loss 0.19407853484153748\n",
      "\n",
      "episode 8, val func loss 0.175088569521904\n",
      "\n",
      "episode 9, val func loss 0.17595379054546356\n",
      "\n",
      "episode 10, val func loss 0.21412381529808044\n",
      "\n",
      "episode 11, val func loss 0.20246389508247375\n",
      "\n",
      "episode 12, val func loss 0.2271672934293747\n",
      "\n",
      "episode 13, val func loss 0.22531263530254364\n",
      "\n",
      "episode 14, val func loss 0.1899888515472412\n",
      "\n",
      "episode 15, val func loss 0.1632208228111267\n",
      "\n",
      "episode 16, val func loss 0.1920597106218338\n",
      "\n",
      "Val func train loss in epoch 9:0.19678860064595938\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19528838992118835\n",
      "\n",
      "episode 2, val func loss 0.18115434050559998\n",
      "\n",
      "episode 3, val func loss 0.22848190367221832\n",
      "\n",
      "episode 4, val func loss 0.2246101200580597\n",
      "\n",
      "episode 5, val func loss 0.19110634922981262\n",
      "\n",
      "episode 6, val func loss 0.17560698091983795\n",
      "\n",
      "episode 7, val func loss 0.20926156640052795\n",
      "\n",
      "episode 8, val func loss 0.20118755102157593\n",
      "\n",
      "episode 9, val func loss 0.19078665971755981\n",
      "\n",
      "episode 10, val func loss 0.16269047558307648\n",
      "\n",
      "episode 11, val func loss 0.21985042095184326\n",
      "\n",
      "episode 12, val func loss 0.20277820527553558\n",
      "\n",
      "episode 13, val func loss 0.1909487396478653\n",
      "\n",
      "episode 14, val func loss 0.22419506311416626\n",
      "\n",
      "episode 15, val func loss 0.17567846179008484\n",
      "\n",
      "episode 16, val func loss 0.16660743951797485\n",
      "\n",
      "Val func train loss in epoch 10:0.19626454170793295\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19506877660751343\n",
      "\n",
      "episode 2, val func loss 0.22505855560302734\n",
      "\n",
      "episode 3, val func loss 0.1755669265985489\n",
      "\n",
      "episode 4, val func loss 0.22543343901634216\n",
      "\n",
      "episode 5, val func loss 0.2028670608997345\n",
      "\n",
      "episode 6, val func loss 0.174781933426857\n",
      "\n",
      "episode 7, val func loss 0.1660572737455368\n",
      "\n",
      "episode 8, val func loss 0.23044273257255554\n",
      "\n",
      "episode 9, val func loss 0.19097889959812164\n",
      "\n",
      "episode 10, val func loss 0.21958401799201965\n",
      "\n",
      "episode 11, val func loss 0.20062409341335297\n",
      "\n",
      "episode 12, val func loss 0.19085121154785156\n",
      "\n",
      "episode 13, val func loss 0.16341376304626465\n",
      "\n",
      "episode 14, val func loss 0.1790468990802765\n",
      "\n",
      "episode 15, val func loss 0.21040008962154388\n",
      "\n",
      "episode 16, val func loss 0.18990196287631989\n",
      "\n",
      "Val func train loss in epoch 11:0.19625485222786665\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.16203095018863678\n",
      "\n",
      "episode 2, val func loss 0.19115203619003296\n",
      "\n",
      "episode 3, val func loss 0.22730322182178497\n",
      "\n",
      "episode 4, val func loss 0.2258528470993042\n",
      "\n",
      "episode 5, val func loss 0.17665855586528778\n",
      "\n",
      "episode 6, val func loss 0.1761937439441681\n",
      "\n",
      "episode 7, val func loss 0.16547608375549316\n",
      "\n",
      "episode 8, val func loss 0.21093660593032837\n",
      "\n",
      "episode 9, val func loss 0.17550519108772278\n",
      "\n",
      "episode 10, val func loss 0.23183505237102509\n",
      "\n",
      "episode 11, val func loss 0.19488559663295746\n",
      "\n",
      "episode 12, val func loss 0.203078031539917\n",
      "\n",
      "episode 13, val func loss 0.2197975367307663\n",
      "\n",
      "episode 14, val func loss 0.20105569064617157\n",
      "\n",
      "episode 15, val func loss 0.19114552438259125\n",
      "\n",
      "episode 16, val func loss 0.19075369834899902\n",
      "\n",
      "Val func train loss in epoch 12:0.19647877290844917\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18114645779132843\n",
      "\n",
      "episode 2, val func loss 0.17573370039463043\n",
      "\n",
      "episode 3, val func loss 0.19467051327228546\n",
      "\n",
      "episode 4, val func loss 0.19080506265163422\n",
      "\n",
      "episode 5, val func loss 0.22098328173160553\n",
      "\n",
      "episode 6, val func loss 0.21250663697719574\n",
      "\n",
      "episode 7, val func loss 0.17572763562202454\n",
      "\n",
      "episode 8, val func loss 0.23312336206436157\n",
      "\n",
      "episode 9, val func loss 0.19036510586738586\n",
      "\n",
      "episode 10, val func loss 0.166020005941391\n",
      "\n",
      "episode 11, val func loss 0.2258981317281723\n",
      "\n",
      "episode 12, val func loss 0.18929722905158997\n",
      "\n",
      "episode 13, val func loss 0.20095881819725037\n",
      "\n",
      "episode 14, val func loss 0.22486720979213715\n",
      "\n",
      "episode 15, val func loss 0.16340744495391846\n",
      "\n",
      "episode 16, val func loss 0.20352961122989655\n",
      "\n",
      "Val func train loss in epoch 13:0.19681501295417547\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.16814200580120087\n",
      "\n",
      "episode 2, val func loss 0.2033056616783142\n",
      "\n",
      "episode 3, val func loss 0.20956195890903473\n",
      "\n",
      "episode 4, val func loss 0.16196846961975098\n",
      "\n",
      "episode 5, val func loss 0.2196710854768753\n",
      "\n",
      "episode 6, val func loss 0.17625755071640015\n",
      "\n",
      "episode 7, val func loss 0.19439543783664703\n",
      "\n",
      "episode 8, val func loss 0.17689381539821625\n",
      "\n",
      "episode 9, val func loss 0.22700288891792297\n",
      "\n",
      "episode 10, val func loss 0.22596405446529388\n",
      "\n",
      "episode 11, val func loss 0.2015560418367386\n",
      "\n",
      "episode 12, val func loss 0.1903872787952423\n",
      "\n",
      "episode 13, val func loss 0.1902284473180771\n",
      "\n",
      "episode 14, val func loss 0.19139742851257324\n",
      "\n",
      "episode 15, val func loss 0.2312970608472824\n",
      "\n",
      "episode 16, val func loss 0.1753809154033661\n",
      "\n",
      "Val func train loss in epoch 14:0.1964631313458085\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20880167186260223\n",
      "\n",
      "episode 2, val func loss 0.2197640985250473\n",
      "\n",
      "episode 3, val func loss 0.1642506718635559\n",
      "\n",
      "episode 4, val func loss 0.22342918813228607\n",
      "\n",
      "episode 5, val func loss 0.17810384929180145\n",
      "\n",
      "episode 6, val func loss 0.17673741281032562\n",
      "\n",
      "episode 7, val func loss 0.16978396475315094\n",
      "\n",
      "episode 8, val func loss 0.19105403125286102\n",
      "\n",
      "episode 9, val func loss 0.2251974195241928\n",
      "\n",
      "episode 10, val func loss 0.189669668674469\n",
      "\n",
      "episode 11, val func loss 0.17690621316432953\n",
      "\n",
      "episode 12, val func loss 0.20207135379314423\n",
      "\n",
      "episode 13, val func loss 0.1943884789943695\n",
      "\n",
      "episode 14, val func loss 0.19071243703365326\n",
      "\n",
      "episode 15, val func loss 0.2058480978012085\n",
      "\n",
      "episode 16, val func loss 0.2375217080116272\n",
      "\n",
      "Val func train loss in epoch 15:0.19714001659303904\n",
      "***********************TIME WAS 4.999796092510223 min*****************************\n",
      "\n",
      "**********************ROUND 114 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.014334174804389477\n",
      "\n",
      "episode 2, policy loss -0.04942205548286438\n",
      "\n",
      "episode 3, policy loss -0.07429101318120956\n",
      "\n",
      "episode 4, policy loss 0.015996547415852547\n",
      "\n",
      "episode 5, policy loss -0.024471251294016838\n",
      "\n",
      "episode 6, policy loss -0.10388986021280289\n",
      "\n",
      "episode 7, policy loss -0.023963088169693947\n",
      "\n",
      "episode 8, policy loss -0.013530372641980648\n",
      "\n",
      "episode 9, policy loss -0.08461175858974457\n",
      "\n",
      "episode 10, policy loss -0.04991042613983154\n",
      "\n",
      "episode 11, policy loss -0.07096833735704422\n",
      "\n",
      "episode 12, policy loss -0.11985383182764053\n",
      "\n",
      "episode 13, policy loss -0.06182911992073059\n",
      "\n",
      "episode 14, policy loss -0.09447593986988068\n",
      "\n",
      "episode 15, policy loss -0.06111981347203255\n",
      "\n",
      "episode 16, policy loss -0.04843674600124359\n",
      "\n",
      "Policy train loss in epoch 0:-0.05494445259682834\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.048305854201316833\n",
      "\n",
      "episode 2, policy loss -0.061177678406238556\n",
      "\n",
      "episode 3, policy loss -0.009661306627094746\n",
      "\n",
      "episode 4, policy loss -0.06055804342031479\n",
      "\n",
      "episode 5, policy loss -0.10381019115447998\n",
      "\n",
      "episode 6, policy loss 0.015789948403835297\n",
      "\n",
      "episode 7, policy loss -0.02578643709421158\n",
      "\n",
      "episode 8, policy loss -0.02576475404202938\n",
      "\n",
      "episode 9, policy loss -0.05382300913333893\n",
      "\n",
      "episode 10, policy loss -0.08590858429670334\n",
      "\n",
      "episode 11, policy loss -0.09562799334526062\n",
      "\n",
      "episode 12, policy loss -0.12123420089483261\n",
      "\n",
      "episode 13, policy loss -0.02315378375351429\n",
      "\n",
      "episode 14, policy loss -0.05192466452717781\n",
      "\n",
      "episode 15, policy loss -0.07181204855442047\n",
      "\n",
      "episode 16, policy loss -0.08082401752471924\n",
      "\n",
      "Policy train loss in epoch 1:-0.05647391366073862\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.048343874514102936\n",
      "\n",
      "episode 2, policy loss -0.08577881008386612\n",
      "\n",
      "episode 3, policy loss -0.10479736328125\n",
      "\n",
      "episode 4, policy loss -0.027218041941523552\n",
      "\n",
      "episode 5, policy loss 0.01381007581949234\n",
      "\n",
      "episode 6, policy loss -0.05441579967737198\n",
      "\n",
      "episode 7, policy loss -0.05258744955062866\n",
      "\n",
      "episode 8, policy loss -0.09542274475097656\n",
      "\n",
      "episode 9, policy loss -0.02665204554796219\n",
      "\n",
      "episode 10, policy loss -0.023146241903305054\n",
      "\n",
      "episode 11, policy loss -0.06281127035617828\n",
      "\n",
      "episode 12, policy loss -0.01332776714116335\n",
      "\n",
      "episode 13, policy loss -0.062045902013778687\n",
      "\n",
      "episode 14, policy loss -0.07229249179363251\n",
      "\n",
      "episode 15, policy loss -0.08072581142187119\n",
      "\n",
      "episode 16, policy loss -0.12203755974769592\n",
      "\n",
      "Policy train loss in epoch 2:-0.057362068619113415\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.02810361050069332\n",
      "\n",
      "episode 2, policy loss 0.014985594898462296\n",
      "\n",
      "episode 3, policy loss -0.08434852212667465\n",
      "\n",
      "episode 4, policy loss -0.09516458958387375\n",
      "\n",
      "episode 5, policy loss -0.0725683718919754\n",
      "\n",
      "episode 6, policy loss -0.026767205446958542\n",
      "\n",
      "episode 7, policy loss -0.01359381340444088\n",
      "\n",
      "episode 8, policy loss -0.052077267318964005\n",
      "\n",
      "episode 9, policy loss -0.10415896773338318\n",
      "\n",
      "episode 10, policy loss -0.061192046850919724\n",
      "\n",
      "episode 11, policy loss -0.047535065561532974\n",
      "\n",
      "episode 12, policy loss -0.12141221016645432\n",
      "\n",
      "episode 13, policy loss -0.08062867820262909\n",
      "\n",
      "episode 14, policy loss -0.06072463095188141\n",
      "\n",
      "episode 15, policy loss -0.05283976346254349\n",
      "\n",
      "episode 16, policy loss -0.023837564513087273\n",
      "\n",
      "Policy train loss in epoch 3:-0.05687291955109686\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19645799696445465\n",
      "\n",
      "episode 2, val func loss 0.18131037056446075\n",
      "\n",
      "episode 3, val func loss 0.17689216136932373\n",
      "\n",
      "episode 4, val func loss 0.1683177500963211\n",
      "\n",
      "episode 5, val func loss 0.2131771296262741\n",
      "\n",
      "episode 6, val func loss 0.17185857892036438\n",
      "\n",
      "episode 7, val func loss 0.17035901546478271\n",
      "\n",
      "episode 8, val func loss 0.2144860476255417\n",
      "\n",
      "episode 9, val func loss 0.19277282059192657\n",
      "\n",
      "episode 10, val func loss 0.18767833709716797\n",
      "\n",
      "episode 11, val func loss 0.2016204446554184\n",
      "\n",
      "episode 12, val func loss 0.19293685257434845\n",
      "\n",
      "episode 13, val func loss 0.1483643800020218\n",
      "\n",
      "episode 14, val func loss 0.18482577800750732\n",
      "\n",
      "episode 15, val func loss 0.16964714229106903\n",
      "\n",
      "episode 16, val func loss 0.21533693373203278\n",
      "\n",
      "Val func train loss in epoch 0:0.18662760872393847\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19315670430660248\n",
      "\n",
      "episode 2, val func loss 0.167475625872612\n",
      "\n",
      "episode 3, val func loss 0.21671324968338013\n",
      "\n",
      "episode 4, val func loss 0.1688847541809082\n",
      "\n",
      "episode 5, val func loss 0.16866835951805115\n",
      "\n",
      "episode 6, val func loss 0.17677660286426544\n",
      "\n",
      "episode 7, val func loss 0.18710564076900482\n",
      "\n",
      "episode 8, val func loss 0.19651645421981812\n",
      "\n",
      "episode 9, val func loss 0.18109068274497986\n",
      "\n",
      "episode 10, val func loss 0.21520556509494781\n",
      "\n",
      "episode 11, val func loss 0.14664261043071747\n",
      "\n",
      "episode 12, val func loss 0.19358831644058228\n",
      "\n",
      "episode 13, val func loss 0.2127237319946289\n",
      "\n",
      "episode 14, val func loss 0.2014230638742447\n",
      "\n",
      "episode 15, val func loss 0.18420352041721344\n",
      "\n",
      "episode 16, val func loss 0.17224133014678955\n",
      "\n",
      "Val func train loss in epoch 1:0.18640101328492165\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18454033136367798\n",
      "\n",
      "episode 2, val func loss 0.21473203599452972\n",
      "\n",
      "episode 3, val func loss 0.19683650135993958\n",
      "\n",
      "episode 4, val func loss 0.1928461343050003\n",
      "\n",
      "episode 5, val func loss 0.18703122437000275\n",
      "\n",
      "episode 6, val func loss 0.17819532752037048\n",
      "\n",
      "episode 7, val func loss 0.16956636309623718\n",
      "\n",
      "episode 8, val func loss 0.14767196774482727\n",
      "\n",
      "episode 9, val func loss 0.1812429279088974\n",
      "\n",
      "episode 10, val func loss 0.17068850994110107\n",
      "\n",
      "episode 11, val func loss 0.2028493732213974\n",
      "\n",
      "episode 12, val func loss 0.19469065964221954\n",
      "\n",
      "episode 13, val func loss 0.1691395789384842\n",
      "\n",
      "episode 14, val func loss 0.21803833544254303\n",
      "\n",
      "episode 15, val func loss 0.21396726369857788\n",
      "\n",
      "episode 16, val func loss 0.1689004749059677\n",
      "\n",
      "Val func train loss in epoch 2:0.18693356309086084\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.169138565659523\n",
      "\n",
      "episode 2, val func loss 0.18455074727535248\n",
      "\n",
      "episode 3, val func loss 0.19344773888587952\n",
      "\n",
      "episode 4, val func loss 0.2145724594593048\n",
      "\n",
      "episode 5, val func loss 0.2127762734889984\n",
      "\n",
      "episode 6, val func loss 0.17141442000865936\n",
      "\n",
      "episode 7, val func loss 0.15004998445510864\n",
      "\n",
      "episode 8, val func loss 0.192654550075531\n",
      "\n",
      "episode 9, val func loss 0.2131325900554657\n",
      "\n",
      "episode 10, val func loss 0.18080651760101318\n",
      "\n",
      "episode 11, val func loss 0.18699911236763\n",
      "\n",
      "episode 12, val func loss 0.19665208458900452\n",
      "\n",
      "episode 13, val func loss 0.17096993327140808\n",
      "\n",
      "episode 14, val func loss 0.17753595113754272\n",
      "\n",
      "episode 15, val func loss 0.20220565795898438\n",
      "\n",
      "episode 16, val func loss 0.16898022592067719\n",
      "\n",
      "Val func train loss in epoch 3:0.1866179257631302\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.16653911769390106\n",
      "\n",
      "episode 2, val func loss 0.14516426622867584\n",
      "\n",
      "episode 3, val func loss 0.16884839534759521\n",
      "\n",
      "episode 4, val func loss 0.1966918259859085\n",
      "\n",
      "episode 5, val func loss 0.20424295961856842\n",
      "\n",
      "episode 6, val func loss 0.1779400259256363\n",
      "\n",
      "episode 7, val func loss 0.2188466340303421\n",
      "\n",
      "episode 8, val func loss 0.16915364563465118\n",
      "\n",
      "episode 9, val func loss 0.1937156319618225\n",
      "\n",
      "episode 10, val func loss 0.19323034584522247\n",
      "\n",
      "episode 11, val func loss 0.2128118872642517\n",
      "\n",
      "episode 12, val func loss 0.18439683318138123\n",
      "\n",
      "episode 13, val func loss 0.21394555270671844\n",
      "\n",
      "episode 14, val func loss 0.18947185575962067\n",
      "\n",
      "episode 15, val func loss 0.18172894418239594\n",
      "\n",
      "episode 16, val func loss 0.1729826182126999\n",
      "\n",
      "Val func train loss in epoch 4:0.18685690872371197\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1711830347776413\n",
      "\n",
      "episode 2, val func loss 0.18727397918701172\n",
      "\n",
      "episode 3, val func loss 0.16913944482803345\n",
      "\n",
      "episode 4, val func loss 0.16569459438323975\n",
      "\n",
      "episode 5, val func loss 0.19755807518959045\n",
      "\n",
      "episode 6, val func loss 0.14498215913772583\n",
      "\n",
      "episode 7, val func loss 0.19484280049800873\n",
      "\n",
      "episode 8, val func loss 0.18522292375564575\n",
      "\n",
      "episode 9, val func loss 0.19423124194145203\n",
      "\n",
      "episode 10, val func loss 0.1810140609741211\n",
      "\n",
      "episode 11, val func loss 0.17064662277698517\n",
      "\n",
      "episode 12, val func loss 0.21382775902748108\n",
      "\n",
      "episode 13, val func loss 0.2128858119249344\n",
      "\n",
      "episode 14, val func loss 0.178486168384552\n",
      "\n",
      "episode 15, val func loss 0.20138123631477356\n",
      "\n",
      "episode 16, val func loss 0.2129129320383072\n",
      "\n",
      "Val func train loss in epoch 5:0.18633017782121897\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1729825884103775\n",
      "\n",
      "episode 2, val func loss 0.1875174641609192\n",
      "\n",
      "episode 3, val func loss 0.1476244181394577\n",
      "\n",
      "episode 4, val func loss 0.1687512844800949\n",
      "\n",
      "episode 5, val func loss 0.18798483908176422\n",
      "\n",
      "episode 6, val func loss 0.19719675183296204\n",
      "\n",
      "episode 7, val func loss 0.19611528515815735\n",
      "\n",
      "episode 8, val func loss 0.21611705422401428\n",
      "\n",
      "episode 9, val func loss 0.1809227466583252\n",
      "\n",
      "episode 10, val func loss 0.177703857421875\n",
      "\n",
      "episode 11, val func loss 0.17026109993457794\n",
      "\n",
      "episode 12, val func loss 0.19347326457500458\n",
      "\n",
      "episode 13, val func loss 0.21265654265880585\n",
      "\n",
      "episode 14, val func loss 0.16982905566692352\n",
      "\n",
      "episode 15, val func loss 0.20165209472179413\n",
      "\n",
      "episode 16, val func loss 0.2153090238571167\n",
      "\n",
      "Val func train loss in epoch 6:0.18725608568638563\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.21290495991706848\n",
      "\n",
      "episode 2, val func loss 0.16975000500679016\n",
      "\n",
      "episode 3, val func loss 0.19635121524333954\n",
      "\n",
      "episode 4, val func loss 0.17137795686721802\n",
      "\n",
      "episode 5, val func loss 0.19321087002754211\n",
      "\n",
      "episode 6, val func loss 0.14636878669261932\n",
      "\n",
      "episode 7, val func loss 0.17746584117412567\n",
      "\n",
      "episode 8, val func loss 0.1664426624774933\n",
      "\n",
      "episode 9, val func loss 0.2194669246673584\n",
      "\n",
      "episode 10, val func loss 0.18766430020332336\n",
      "\n",
      "episode 11, val func loss 0.19487281143665314\n",
      "\n",
      "episode 12, val func loss 0.21653001010417938\n",
      "\n",
      "episode 13, val func loss 0.20144857466220856\n",
      "\n",
      "episode 14, val func loss 0.17056584358215332\n",
      "\n",
      "episode 15, val func loss 0.1814529001712799\n",
      "\n",
      "episode 16, val func loss 0.18396921455860138\n",
      "\n",
      "Val func train loss in epoch 7:0.18686517979949713\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.20131945610046387\n",
      "\n",
      "episode 2, val func loss 0.1507827788591385\n",
      "\n",
      "episode 3, val func loss 0.18139107525348663\n",
      "\n",
      "episode 4, val func loss 0.17188899219036102\n",
      "\n",
      "episode 5, val func loss 0.16919700801372528\n",
      "\n",
      "episode 6, val func loss 0.1878482550382614\n",
      "\n",
      "episode 7, val func loss 0.19704337418079376\n",
      "\n",
      "episode 8, val func loss 0.1689320206642151\n",
      "\n",
      "episode 9, val func loss 0.1852991133928299\n",
      "\n",
      "episode 10, val func loss 0.16732928156852722\n",
      "\n",
      "episode 11, val func loss 0.2151140719652176\n",
      "\n",
      "episode 12, val func loss 0.1962929666042328\n",
      "\n",
      "episode 13, val func loss 0.17706674337387085\n",
      "\n",
      "episode 14, val func loss 0.21447020769119263\n",
      "\n",
      "episode 15, val func loss 0.19357240200042725\n",
      "\n",
      "episode 16, val func loss 0.21263138949871063\n",
      "\n",
      "Val func train loss in epoch 8:0.1868861960247159\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17086707055568695\n",
      "\n",
      "episode 2, val func loss 0.17792975902557373\n",
      "\n",
      "episode 3, val func loss 0.21273894608020782\n",
      "\n",
      "episode 4, val func loss 0.20121747255325317\n",
      "\n",
      "episode 5, val func loss 0.17144079506397247\n",
      "\n",
      "episode 6, val func loss 0.1937311440706253\n",
      "\n",
      "episode 7, val func loss 0.1462329775094986\n",
      "\n",
      "episode 8, val func loss 0.18467773497104645\n",
      "\n",
      "episode 9, val func loss 0.18196697533130646\n",
      "\n",
      "episode 10, val func loss 0.1964372843503952\n",
      "\n",
      "episode 11, val func loss 0.2157570868730545\n",
      "\n",
      "episode 12, val func loss 0.16752296686172485\n",
      "\n",
      "episode 13, val func loss 0.16905498504638672\n",
      "\n",
      "episode 14, val func loss 0.18697938323020935\n",
      "\n",
      "episode 15, val func loss 0.19306933879852295\n",
      "\n",
      "episode 16, val func loss 0.2163722813129425\n",
      "\n",
      "Val func train loss in epoch 9:0.18662476260215044\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.21291430294513702\n",
      "\n",
      "episode 2, val func loss 0.17758671939373016\n",
      "\n",
      "episode 3, val func loss 0.16978520154953003\n",
      "\n",
      "episode 4, val func loss 0.183649480342865\n",
      "\n",
      "episode 5, val func loss 0.19646728038787842\n",
      "\n",
      "episode 6, val func loss 0.18710723519325256\n",
      "\n",
      "episode 7, val func loss 0.1933387666940689\n",
      "\n",
      "episode 8, val func loss 0.20157970488071442\n",
      "\n",
      "episode 9, val func loss 0.17107553780078888\n",
      "\n",
      "episode 10, val func loss 0.21459098160266876\n",
      "\n",
      "episode 11, val func loss 0.16767293214797974\n",
      "\n",
      "episode 12, val func loss 0.168991357088089\n",
      "\n",
      "episode 13, val func loss 0.14580968022346497\n",
      "\n",
      "episode 14, val func loss 0.18207010626792908\n",
      "\n",
      "episode 15, val func loss 0.1957615613937378\n",
      "\n",
      "episode 16, val func loss 0.21843035519123077\n",
      "\n",
      "Val func train loss in epoch 10:0.1866769501939416\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1460636556148529\n",
      "\n",
      "episode 2, val func loss 0.194270059466362\n",
      "\n",
      "episode 3, val func loss 0.18706287443637848\n",
      "\n",
      "episode 4, val func loss 0.17759793996810913\n",
      "\n",
      "episode 5, val func loss 0.2014101892709732\n",
      "\n",
      "episode 6, val func loss 0.18339616060256958\n",
      "\n",
      "episode 7, val func loss 0.1933443546295166\n",
      "\n",
      "episode 8, val func loss 0.1974036991596222\n",
      "\n",
      "episode 9, val func loss 0.21393123269081116\n",
      "\n",
      "episode 10, val func loss 0.2130301147699356\n",
      "\n",
      "episode 11, val func loss 0.2129884660243988\n",
      "\n",
      "episode 12, val func loss 0.18142247200012207\n",
      "\n",
      "episode 13, val func loss 0.17166802287101746\n",
      "\n",
      "episode 14, val func loss 0.17051486670970917\n",
      "\n",
      "episode 15, val func loss 0.17164567112922668\n",
      "\n",
      "episode 16, val func loss 0.1693303883075714\n",
      "\n",
      "Val func train loss in epoch 11:0.18656751047819853\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19415776431560516\n",
      "\n",
      "episode 2, val func loss 0.1446404606103897\n",
      "\n",
      "episode 3, val func loss 0.1983577162027359\n",
      "\n",
      "episode 4, val func loss 0.1691872626543045\n",
      "\n",
      "episode 5, val func loss 0.1707865446805954\n",
      "\n",
      "episode 6, val func loss 0.19684112071990967\n",
      "\n",
      "episode 7, val func loss 0.16614091396331787\n",
      "\n",
      "episode 8, val func loss 0.20339418947696686\n",
      "\n",
      "episode 9, val func loss 0.1773471236228943\n",
      "\n",
      "episode 10, val func loss 0.2172113060951233\n",
      "\n",
      "episode 11, val func loss 0.21291977167129517\n",
      "\n",
      "episode 12, val func loss 0.21360132098197937\n",
      "\n",
      "episode 13, val func loss 0.1714744120836258\n",
      "\n",
      "episode 14, val func loss 0.18452060222625732\n",
      "\n",
      "episode 15, val func loss 0.1887315958738327\n",
      "\n",
      "episode 16, val func loss 0.181871235370636\n",
      "\n",
      "Val func train loss in epoch 12:0.1869489587843418\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.17268677055835724\n",
      "\n",
      "episode 2, val func loss 0.21322232484817505\n",
      "\n",
      "episode 3, val func loss 0.21325671672821045\n",
      "\n",
      "episode 4, val func loss 0.1812153309583664\n",
      "\n",
      "episode 5, val func loss 0.1929416060447693\n",
      "\n",
      "episode 6, val func loss 0.19646823406219482\n",
      "\n",
      "episode 7, val func loss 0.18711364269256592\n",
      "\n",
      "episode 8, val func loss 0.147019162774086\n",
      "\n",
      "episode 9, val func loss 0.21301718056201935\n",
      "\n",
      "episode 10, val func loss 0.19334441423416138\n",
      "\n",
      "episode 11, val func loss 0.17055650055408478\n",
      "\n",
      "episode 12, val func loss 0.1773681640625\n",
      "\n",
      "episode 13, val func loss 0.18537139892578125\n",
      "\n",
      "episode 14, val func loss 0.20238499343395233\n",
      "\n",
      "episode 15, val func loss 0.16901062428951263\n",
      "\n",
      "episode 16, val func loss 0.16892455518245697\n",
      "\n",
      "Val func train loss in epoch 13:0.18649385124444962\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.16710710525512695\n",
      "\n",
      "episode 2, val func loss 0.16913679242134094\n",
      "\n",
      "episode 3, val func loss 0.19577988982200623\n",
      "\n",
      "episode 4, val func loss 0.19486574828624725\n",
      "\n",
      "episode 5, val func loss 0.1690654158592224\n",
      "\n",
      "episode 6, val func loss 0.17070536315441132\n",
      "\n",
      "episode 7, val func loss 0.2152261584997177\n",
      "\n",
      "episode 8, val func loss 0.18124690651893616\n",
      "\n",
      "episode 9, val func loss 0.1933135986328125\n",
      "\n",
      "episode 10, val func loss 0.21497449278831482\n",
      "\n",
      "episode 11, val func loss 0.21239905059337616\n",
      "\n",
      "episode 12, val func loss 0.1840808391571045\n",
      "\n",
      "episode 13, val func loss 0.18874065577983856\n",
      "\n",
      "episode 14, val func loss 0.17930388450622559\n",
      "\n",
      "episode 15, val func loss 0.20142875611782074\n",
      "\n",
      "episode 16, val func loss 0.15017865598201752\n",
      "\n",
      "Val func train loss in epoch 14:0.18672208208590746\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19283294677734375\n",
      "\n",
      "episode 2, val func loss 0.18709535896778107\n",
      "\n",
      "episode 3, val func loss 0.1839885711669922\n",
      "\n",
      "episode 4, val func loss 0.18103107810020447\n",
      "\n",
      "episode 5, val func loss 0.1935463845729828\n",
      "\n",
      "episode 6, val func loss 0.2133563607931137\n",
      "\n",
      "episode 7, val func loss 0.16891247034072876\n",
      "\n",
      "episode 8, val func loss 0.14611467719078064\n",
      "\n",
      "episode 9, val func loss 0.19598233699798584\n",
      "\n",
      "episode 10, val func loss 0.16659778356552124\n",
      "\n",
      "episode 11, val func loss 0.20275729894638062\n",
      "\n",
      "episode 12, val func loss 0.17763037979602814\n",
      "\n",
      "episode 13, val func loss 0.16910290718078613\n",
      "\n",
      "episode 14, val func loss 0.17060597240924835\n",
      "\n",
      "episode 15, val func loss 0.2184935212135315\n",
      "\n",
      "episode 16, val func loss 0.2158258706331253\n",
      "\n",
      "Val func train loss in epoch 15:0.1864921199157834\n",
      "***********************TIME WAS 4.998513189951579 min*****************************\n",
      "\n",
      "**********************ROUND 115 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.017612094059586525\n",
      "\n",
      "episode 2, policy loss -0.059258170425891876\n",
      "\n",
      "episode 3, policy loss 0.048931945115327835\n",
      "\n",
      "episode 4, policy loss -0.04167504981160164\n",
      "\n",
      "episode 5, policy loss -0.01665116846561432\n",
      "\n",
      "episode 6, policy loss 0.027284257113933563\n",
      "\n",
      "episode 7, policy loss -0.007580034900456667\n",
      "\n",
      "episode 8, policy loss -0.06434288620948792\n",
      "\n",
      "episode 9, policy loss -0.013724645599722862\n",
      "\n",
      "episode 10, policy loss -0.015443028882145882\n",
      "\n",
      "episode 11, policy loss -0.003931368235498667\n",
      "\n",
      "episode 12, policy loss 0.02592616155743599\n",
      "\n",
      "episode 13, policy loss -0.09048750251531601\n",
      "\n",
      "episode 14, policy loss 0.0011520739644765854\n",
      "\n",
      "episode 15, policy loss -0.033402204513549805\n",
      "\n",
      "episode 16, policy loss -0.05756363645195961\n",
      "\n",
      "Policy train loss in epoch 0:-0.019898584519978613\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.024794163182377815\n",
      "\n",
      "episode 2, policy loss -0.03533575311303139\n",
      "\n",
      "episode 3, policy loss 0.04593907669186592\n",
      "\n",
      "episode 4, policy loss -0.02602311223745346\n",
      "\n",
      "episode 5, policy loss -0.06733715534210205\n",
      "\n",
      "episode 6, policy loss -0.017528800293803215\n",
      "\n",
      "episode 7, policy loss 0.001016643363982439\n",
      "\n",
      "episode 8, policy loss -0.017990007996559143\n",
      "\n",
      "episode 9, policy loss -0.008533498272299767\n",
      "\n",
      "episode 10, policy loss -0.09352844953536987\n",
      "\n",
      "episode 11, policy loss -0.0657472014427185\n",
      "\n",
      "episode 12, policy loss -0.05910608172416687\n",
      "\n",
      "episode 13, policy loss -0.006728893145918846\n",
      "\n",
      "episode 14, policy loss 0.027011195197701454\n",
      "\n",
      "episode 15, policy loss -0.04400903359055519\n",
      "\n",
      "episode 16, policy loss -0.014966677874326706\n",
      "\n",
      "Policy train loss in epoch 1:-0.022379599133273587\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.026811331510543823\n",
      "\n",
      "episode 2, policy loss 0.044036343693733215\n",
      "\n",
      "episode 3, policy loss -0.04327733442187309\n",
      "\n",
      "episode 4, policy loss -0.00639284448698163\n",
      "\n",
      "episode 5, policy loss 3.989944525528699e-05\n",
      "\n",
      "episode 6, policy loss -0.06549907475709915\n",
      "\n",
      "episode 7, policy loss 0.022747136652469635\n",
      "\n",
      "episode 8, policy loss -0.015712639316916466\n",
      "\n",
      "episode 9, policy loss -0.02726813405752182\n",
      "\n",
      "episode 10, policy loss -0.018154717981815338\n",
      "\n",
      "episode 11, policy loss -0.018709329888224602\n",
      "\n",
      "episode 12, policy loss -0.09247647225856781\n",
      "\n",
      "episode 13, policy loss -0.0605693981051445\n",
      "\n",
      "episode 14, policy loss -0.009055149741470814\n",
      "\n",
      "episode 15, policy loss -0.06894251704216003\n",
      "\n",
      "episode 16, policy loss -0.03532593697309494\n",
      "\n",
      "Policy train loss in epoch 2:-0.022984302358054265\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.06632401794195175\n",
      "\n",
      "episode 2, policy loss -0.01570604182779789\n",
      "\n",
      "episode 3, policy loss -0.02680973894894123\n",
      "\n",
      "episode 4, policy loss -0.0090302973985672\n",
      "\n",
      "episode 5, policy loss 0.04385800287127495\n",
      "\n",
      "episode 6, policy loss -0.019071828573942184\n",
      "\n",
      "episode 7, policy loss 0.02290298417210579\n",
      "\n",
      "episode 8, policy loss -0.0003996817977167666\n",
      "\n",
      "episode 9, policy loss -0.09359600394964218\n",
      "\n",
      "episode 10, policy loss -0.04342741146683693\n",
      "\n",
      "episode 11, policy loss -0.03537704050540924\n",
      "\n",
      "episode 12, policy loss -0.06761616468429565\n",
      "\n",
      "episode 13, policy loss -0.05929379165172577\n",
      "\n",
      "episode 14, policy loss 0.026872243732213974\n",
      "\n",
      "episode 15, policy loss -0.017594128847122192\n",
      "\n",
      "episode 16, policy loss -0.006032910197973251\n",
      "\n",
      "Policy train loss in epoch 3:-0.02291536418852047\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.14635074138641357\n",
      "\n",
      "episode 2, val func loss 0.17129237949848175\n",
      "\n",
      "episode 3, val func loss 0.1971581131219864\n",
      "\n",
      "episode 4, val func loss 0.16323789954185486\n",
      "\n",
      "episode 5, val func loss 0.1681949347257614\n",
      "\n",
      "episode 6, val func loss 0.17787830531597137\n",
      "\n",
      "episode 7, val func loss 0.18630275130271912\n",
      "\n",
      "episode 8, val func loss 0.17595161497592926\n",
      "\n",
      "episode 9, val func loss 0.20229195058345795\n",
      "\n",
      "episode 10, val func loss 0.21482634544372559\n",
      "\n",
      "episode 11, val func loss 0.15945731103420258\n",
      "\n",
      "episode 12, val func loss 0.175592839717865\n",
      "\n",
      "episode 13, val func loss 0.23646126687526703\n",
      "\n",
      "episode 14, val func loss 0.18910901248455048\n",
      "\n",
      "episode 15, val func loss 0.19435293972492218\n",
      "\n",
      "episode 16, val func loss 0.20762231945991516\n",
      "\n",
      "Val func train loss in epoch 0:0.18538004532456398\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18068984150886536\n",
      "\n",
      "episode 2, val func loss 0.17238649725914001\n",
      "\n",
      "episode 3, val func loss 0.16876594722270966\n",
      "\n",
      "episode 4, val func loss 0.1886783242225647\n",
      "\n",
      "episode 5, val func loss 0.23231689631938934\n",
      "\n",
      "episode 6, val func loss 0.19698746502399445\n",
      "\n",
      "episode 7, val func loss 0.1995444893836975\n",
      "\n",
      "episode 8, val func loss 0.14693638682365417\n",
      "\n",
      "episode 9, val func loss 0.17630256712436676\n",
      "\n",
      "episode 10, val func loss 0.16176781058311462\n",
      "\n",
      "episode 11, val func loss 0.18615739047527313\n",
      "\n",
      "episode 12, val func loss 0.21335580945014954\n",
      "\n",
      "episode 13, val func loss 0.19547413289546967\n",
      "\n",
      "episode 14, val func loss 0.2096334546804428\n",
      "\n",
      "episode 15, val func loss 0.16009245812892914\n",
      "\n",
      "episode 16, val func loss 0.17608468234539032\n",
      "\n",
      "Val func train loss in epoch 1:0.18532338459044695\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.2092919647693634\n",
      "\n",
      "episode 2, val func loss 0.23524674773216248\n",
      "\n",
      "episode 3, val func loss 0.17769713699817657\n",
      "\n",
      "episode 4, val func loss 0.18863309919834137\n",
      "\n",
      "episode 5, val func loss 0.16835999488830566\n",
      "\n",
      "episode 6, val func loss 0.17675738036632538\n",
      "\n",
      "episode 7, val func loss 0.19490182399749756\n",
      "\n",
      "episode 8, val func loss 0.1997375339269638\n",
      "\n",
      "episode 9, val func loss 0.18755996227264404\n",
      "\n",
      "episode 10, val func loss 0.1766805499792099\n",
      "\n",
      "episode 11, val func loss 0.17092132568359375\n",
      "\n",
      "episode 12, val func loss 0.21226881444454193\n",
      "\n",
      "episode 13, val func loss 0.16101805865764618\n",
      "\n",
      "episode 14, val func loss 0.1434907168149948\n",
      "\n",
      "episode 15, val func loss 0.15986357629299164\n",
      "\n",
      "episode 16, val func loss 0.1984957605600357\n",
      "\n",
      "Val func train loss in epoch 2:0.18505777791142464\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.17160148918628693\n",
      "\n",
      "episode 2, val func loss 0.16820217669010162\n",
      "\n",
      "episode 3, val func loss 0.17685405910015106\n",
      "\n",
      "episode 4, val func loss 0.15868820250034332\n",
      "\n",
      "episode 5, val func loss 0.1864074468612671\n",
      "\n",
      "episode 6, val func loss 0.21139594912528992\n",
      "\n",
      "episode 7, val func loss 0.19623135030269623\n",
      "\n",
      "episode 8, val func loss 0.18941141664981842\n",
      "\n",
      "episode 9, val func loss 0.21232634782791138\n",
      "\n",
      "episode 10, val func loss 0.1993853747844696\n",
      "\n",
      "episode 11, val func loss 0.15135431289672852\n",
      "\n",
      "episode 12, val func loss 0.17893250286579132\n",
      "\n",
      "episode 13, val func loss 0.17721472680568695\n",
      "\n",
      "episode 14, val func loss 0.16300351917743683\n",
      "\n",
      "episode 15, val func loss 0.19662465155124664\n",
      "\n",
      "episode 16, val func loss 0.2344985008239746\n",
      "\n",
      "Val func train loss in epoch 3:0.18575825169682503\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.16015134751796722\n",
      "\n",
      "episode 2, val func loss 0.16771329939365387\n",
      "\n",
      "episode 3, val func loss 0.20175690948963165\n",
      "\n",
      "episode 4, val func loss 0.23586754500865936\n",
      "\n",
      "episode 5, val func loss 0.17720115184783936\n",
      "\n",
      "episode 6, val func loss 0.17070834338665009\n",
      "\n",
      "episode 7, val func loss 0.1946803778409958\n",
      "\n",
      "episode 8, val func loss 0.21131329238414764\n",
      "\n",
      "episode 9, val func loss 0.17615501582622528\n",
      "\n",
      "episode 10, val func loss 0.19688467681407928\n",
      "\n",
      "episode 11, val func loss 0.14735916256904602\n",
      "\n",
      "episode 12, val func loss 0.18916568160057068\n",
      "\n",
      "episode 13, val func loss 0.2080986648797989\n",
      "\n",
      "episode 14, val func loss 0.16194024682044983\n",
      "\n",
      "episode 15, val func loss 0.1759972870349884\n",
      "\n",
      "episode 16, val func loss 0.1863672435283661\n",
      "\n",
      "Val func train loss in epoch 4:0.18508501537144184\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19488133490085602\n",
      "\n",
      "episode 2, val func loss 0.1756831705570221\n",
      "\n",
      "episode 3, val func loss 0.18987154960632324\n",
      "\n",
      "episode 4, val func loss 0.1709543913602829\n",
      "\n",
      "episode 5, val func loss 0.15929701924324036\n",
      "\n",
      "episode 6, val func loss 0.16798080503940582\n",
      "\n",
      "episode 7, val func loss 0.20258603990077972\n",
      "\n",
      "episode 8, val func loss 0.20970888435840607\n",
      "\n",
      "episode 9, val func loss 0.17725801467895508\n",
      "\n",
      "episode 10, val func loss 0.23406825959682465\n",
      "\n",
      "episode 11, val func loss 0.14606653153896332\n",
      "\n",
      "episode 12, val func loss 0.16268767416477203\n",
      "\n",
      "episode 13, val func loss 0.18772384524345398\n",
      "\n",
      "episode 14, val func loss 0.21133171021938324\n",
      "\n",
      "episode 15, val func loss 0.19697310030460358\n",
      "\n",
      "episode 16, val func loss 0.1765296459197998\n",
      "\n",
      "Val func train loss in epoch 5:0.185225123539567\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17543034255504608\n",
      "\n",
      "episode 2, val func loss 0.194604754447937\n",
      "\n",
      "episode 3, val func loss 0.23423336446285248\n",
      "\n",
      "episode 4, val func loss 0.17771334946155548\n",
      "\n",
      "episode 5, val func loss 0.20799100399017334\n",
      "\n",
      "episode 6, val func loss 0.17649990320205688\n",
      "\n",
      "episode 7, val func loss 0.17073006927967072\n",
      "\n",
      "episode 8, val func loss 0.14543627202510834\n",
      "\n",
      "episode 9, val func loss 0.19688363373279572\n",
      "\n",
      "episode 10, val func loss 0.18886137008666992\n",
      "\n",
      "episode 11, val func loss 0.1604781299829483\n",
      "\n",
      "episode 12, val func loss 0.2127852737903595\n",
      "\n",
      "episode 13, val func loss 0.18610689043998718\n",
      "\n",
      "episode 14, val func loss 0.16020922362804413\n",
      "\n",
      "episode 15, val func loss 0.16805963218212128\n",
      "\n",
      "episode 16, val func loss 0.20251867175102234\n",
      "\n",
      "Val func train loss in epoch 6:0.1849088678136468\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.23679086565971375\n",
      "\n",
      "episode 2, val func loss 0.17699092626571655\n",
      "\n",
      "episode 3, val func loss 0.19711679220199585\n",
      "\n",
      "episode 4, val func loss 0.21152961254119873\n",
      "\n",
      "episode 5, val func loss 0.18750417232513428\n",
      "\n",
      "episode 6, val func loss 0.1634482890367508\n",
      "\n",
      "episode 7, val func loss 0.1633552610874176\n",
      "\n",
      "episode 8, val func loss 0.20765678584575653\n",
      "\n",
      "episode 9, val func loss 0.18857669830322266\n",
      "\n",
      "episode 10, val func loss 0.1945122480392456\n",
      "\n",
      "episode 11, val func loss 0.17057114839553833\n",
      "\n",
      "episode 12, val func loss 0.1676660031080246\n",
      "\n",
      "episode 13, val func loss 0.1761154979467392\n",
      "\n",
      "episode 14, val func loss 0.20086322724819183\n",
      "\n",
      "episode 15, val func loss 0.1752282828092575\n",
      "\n",
      "episode 16, val func loss 0.14358332753181458\n",
      "\n",
      "Val func train loss in epoch 7:0.1850943211466074\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.20098140835762024\n",
      "\n",
      "episode 2, val func loss 0.17543403804302216\n",
      "\n",
      "episode 3, val func loss 0.235057070851326\n",
      "\n",
      "episode 4, val func loss 0.16047260165214539\n",
      "\n",
      "episode 5, val func loss 0.14402717351913452\n",
      "\n",
      "episode 6, val func loss 0.17743869125843048\n",
      "\n",
      "episode 7, val func loss 0.18926790356636047\n",
      "\n",
      "episode 8, val func loss 0.20867186784744263\n",
      "\n",
      "episode 9, val func loss 0.17578229308128357\n",
      "\n",
      "episode 10, val func loss 0.1608765423297882\n",
      "\n",
      "episode 11, val func loss 0.21303622424602509\n",
      "\n",
      "episode 12, val func loss 0.1866866797208786\n",
      "\n",
      "episode 13, val func loss 0.1948469877243042\n",
      "\n",
      "episode 14, val func loss 0.1677299588918686\n",
      "\n",
      "episode 15, val func loss 0.17066197097301483\n",
      "\n",
      "episode 16, val func loss 0.19675040245056152\n",
      "\n",
      "Val func train loss in epoch 8:0.1848576134070754\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1448640078306198\n",
      "\n",
      "episode 2, val func loss 0.17614655196666718\n",
      "\n",
      "episode 3, val func loss 0.17058010399341583\n",
      "\n",
      "episode 4, val func loss 0.16034814715385437\n",
      "\n",
      "episode 5, val func loss 0.18635091185569763\n",
      "\n",
      "episode 6, val func loss 0.17520073056221008\n",
      "\n",
      "episode 7, val func loss 0.2162807285785675\n",
      "\n",
      "episode 8, val func loss 0.2108704298734665\n",
      "\n",
      "episode 9, val func loss 0.1955903321504593\n",
      "\n",
      "episode 10, val func loss 0.189618319272995\n",
      "\n",
      "episode 11, val func loss 0.2337525486946106\n",
      "\n",
      "episode 12, val func loss 0.1789449155330658\n",
      "\n",
      "episode 13, val func loss 0.1966134011745453\n",
      "\n",
      "episode 14, val func loss 0.1649308204650879\n",
      "\n",
      "episode 15, val func loss 0.1692838966846466\n",
      "\n",
      "episode 16, val func loss 0.19978240132331848\n",
      "\n",
      "Val func train loss in epoch 9:0.18557239044457674\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.16868199408054352\n",
      "\n",
      "episode 2, val func loss 0.1997736096382141\n",
      "\n",
      "episode 3, val func loss 0.17055009305477142\n",
      "\n",
      "episode 4, val func loss 0.17824654281139374\n",
      "\n",
      "episode 5, val func loss 0.1439487338066101\n",
      "\n",
      "episode 6, val func loss 0.2131415754556656\n",
      "\n",
      "episode 7, val func loss 0.17564083635807037\n",
      "\n",
      "episode 8, val func loss 0.15963886678218842\n",
      "\n",
      "episode 9, val func loss 0.18996480107307434\n",
      "\n",
      "episode 10, val func loss 0.23706068098545074\n",
      "\n",
      "episode 11, val func loss 0.1760382205247879\n",
      "\n",
      "episode 12, val func loss 0.20898035168647766\n",
      "\n",
      "episode 13, val func loss 0.1618397831916809\n",
      "\n",
      "episode 14, val func loss 0.19478006660938263\n",
      "\n",
      "episode 15, val func loss 0.186770498752594\n",
      "\n",
      "episode 16, val func loss 0.19692303240299225\n",
      "\n",
      "Val func train loss in epoch 10:0.1851237304508686\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.23304226994514465\n",
      "\n",
      "episode 2, val func loss 0.2000255584716797\n",
      "\n",
      "episode 3, val func loss 0.18826250731945038\n",
      "\n",
      "episode 4, val func loss 0.1474420577287674\n",
      "\n",
      "episode 5, val func loss 0.16815027594566345\n",
      "\n",
      "episode 6, val func loss 0.17109794914722443\n",
      "\n",
      "episode 7, val func loss 0.1757524311542511\n",
      "\n",
      "episode 8, val func loss 0.2121140956878662\n",
      "\n",
      "episode 9, val func loss 0.16088366508483887\n",
      "\n",
      "episode 10, val func loss 0.15984486043453217\n",
      "\n",
      "episode 11, val func loss 0.17634263634681702\n",
      "\n",
      "episode 12, val func loss 0.1963072419166565\n",
      "\n",
      "episode 13, val func loss 0.17677006125450134\n",
      "\n",
      "episode 14, val func loss 0.21095408499240875\n",
      "\n",
      "episode 15, val func loss 0.19845212996006012\n",
      "\n",
      "episode 16, val func loss 0.18924769759178162\n",
      "\n",
      "Val func train loss in epoch 11:0.18529309518635273\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17758303880691528\n",
      "\n",
      "episode 2, val func loss 0.19702894985675812\n",
      "\n",
      "episode 3, val func loss 0.17680686712265015\n",
      "\n",
      "episode 4, val func loss 0.18722012639045715\n",
      "\n",
      "episode 5, val func loss 0.21162454783916473\n",
      "\n",
      "episode 6, val func loss 0.18858326971530914\n",
      "\n",
      "episode 7, val func loss 0.16181713342666626\n",
      "\n",
      "episode 8, val func loss 0.23307354748249054\n",
      "\n",
      "episode 9, val func loss 0.16755311191082\n",
      "\n",
      "episode 10, val func loss 0.14537256956100464\n",
      "\n",
      "episode 11, val func loss 0.17070916295051575\n",
      "\n",
      "episode 12, val func loss 0.2002016007900238\n",
      "\n",
      "episode 13, val func loss 0.16072070598602295\n",
      "\n",
      "episode 14, val func loss 0.20884159207344055\n",
      "\n",
      "episode 15, val func loss 0.19493429362773895\n",
      "\n",
      "episode 16, val func loss 0.17538870871067047\n",
      "\n",
      "Val func train loss in epoch 12:0.18484120164066553\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.17701345682144165\n",
      "\n",
      "episode 2, val func loss 0.21297511458396912\n",
      "\n",
      "episode 3, val func loss 0.16028457880020142\n",
      "\n",
      "episode 4, val func loss 0.16720862686634064\n",
      "\n",
      "episode 5, val func loss 0.20899781584739685\n",
      "\n",
      "episode 6, val func loss 0.14454258978366852\n",
      "\n",
      "episode 7, val func loss 0.2341962456703186\n",
      "\n",
      "episode 8, val func loss 0.20113272964954376\n",
      "\n",
      "episode 9, val func loss 0.16132836043834686\n",
      "\n",
      "episode 10, val func loss 0.19678349792957306\n",
      "\n",
      "episode 11, val func loss 0.1757570207118988\n",
      "\n",
      "episode 12, val func loss 0.1698884516954422\n",
      "\n",
      "episode 13, val func loss 0.19449877738952637\n",
      "\n",
      "episode 14, val func loss 0.17620667815208435\n",
      "\n",
      "episode 15, val func loss 0.18913410604000092\n",
      "\n",
      "episode 16, val func loss 0.18601259589195251\n",
      "\n",
      "Val func train loss in epoch 13:0.1847475403919816\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19413861632347107\n",
      "\n",
      "episode 2, val func loss 0.2123546153306961\n",
      "\n",
      "episode 3, val func loss 0.16664111614227295\n",
      "\n",
      "episode 4, val func loss 0.17014168202877045\n",
      "\n",
      "episode 5, val func loss 0.16220718622207642\n",
      "\n",
      "episode 6, val func loss 0.1460144817829132\n",
      "\n",
      "episode 7, val func loss 0.1870623081922531\n",
      "\n",
      "episode 8, val func loss 0.17581090331077576\n",
      "\n",
      "episode 9, val func loss 0.24024078249931335\n",
      "\n",
      "episode 10, val func loss 0.19030770659446716\n",
      "\n",
      "episode 11, val func loss 0.21037499606609344\n",
      "\n",
      "episode 12, val func loss 0.19742634892463684\n",
      "\n",
      "episode 13, val func loss 0.17523778975009918\n",
      "\n",
      "episode 14, val func loss 0.16246625781059265\n",
      "\n",
      "episode 15, val func loss 0.19923612475395203\n",
      "\n",
      "episode 16, val func loss 0.17679230868816376\n",
      "\n",
      "Val func train loss in epoch 14:0.18540332652628422\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1949017196893692\n",
      "\n",
      "episode 2, val func loss 0.17594732344150543\n",
      "\n",
      "episode 3, val func loss 0.23146700859069824\n",
      "\n",
      "episode 4, val func loss 0.17696136236190796\n",
      "\n",
      "episode 5, val func loss 0.18743392825126648\n",
      "\n",
      "episode 6, val func loss 0.17841899394989014\n",
      "\n",
      "episode 7, val func loss 0.19667546451091766\n",
      "\n",
      "episode 8, val func loss 0.16094093024730682\n",
      "\n",
      "episode 9, val func loss 0.14274367690086365\n",
      "\n",
      "episode 10, val func loss 0.16815634071826935\n",
      "\n",
      "episode 11, val func loss 0.19163194298744202\n",
      "\n",
      "episode 12, val func loss 0.21611018478870392\n",
      "\n",
      "episode 13, val func loss 0.20346637070178986\n",
      "\n",
      "episode 14, val func loss 0.2073371708393097\n",
      "\n",
      "episode 15, val func loss 0.16074572503566742\n",
      "\n",
      "episode 16, val func loss 0.16917471587657928\n",
      "\n",
      "Val func train loss in epoch 15:0.18513205368071795\n",
      "***********************TIME WAS 5.003022619088491 min*****************************\n",
      "\n",
      "**********************ROUND 116 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.07478714734315872\n",
      "\n",
      "episode 2, policy loss 0.011572076007723808\n",
      "\n",
      "episode 3, policy loss 0.07063113898038864\n",
      "\n",
      "episode 4, policy loss 0.06908746063709259\n",
      "\n",
      "episode 5, policy loss 0.021855339407920837\n",
      "\n",
      "episode 6, policy loss 0.029950248077511787\n",
      "\n",
      "episode 7, policy loss 0.10170689970254898\n",
      "\n",
      "episode 8, policy loss 0.04187272489070892\n",
      "\n",
      "episode 9, policy loss 0.021114882081747055\n",
      "\n",
      "episode 10, policy loss 0.04473115876317024\n",
      "\n",
      "episode 11, policy loss 0.08554389327764511\n",
      "\n",
      "episode 12, policy loss 0.06825348734855652\n",
      "\n",
      "episode 13, policy loss 0.06233968213200569\n",
      "\n",
      "episode 14, policy loss 0.06091461330652237\n",
      "\n",
      "episode 15, policy loss 0.05112504959106445\n",
      "\n",
      "episode 16, policy loss 0.044511232525110245\n",
      "\n",
      "Policy train loss in epoch 0:0.05374981462955475\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.042338572442531586\n",
      "\n",
      "episode 2, policy loss 0.02214365452528\n",
      "\n",
      "episode 3, policy loss 0.06644690781831741\n",
      "\n",
      "episode 4, policy loss 0.10122459381818771\n",
      "\n",
      "episode 5, policy loss 0.04334103316068649\n",
      "\n",
      "episode 6, policy loss 0.049960095435380936\n",
      "\n",
      "episode 7, policy loss 0.0818999782204628\n",
      "\n",
      "episode 8, policy loss 0.06300076842308044\n",
      "\n",
      "episode 9, policy loss 0.0009108168887905777\n",
      "\n",
      "episode 10, policy loss 0.0671091303229332\n",
      "\n",
      "episode 11, policy loss 0.02169787511229515\n",
      "\n",
      "episode 12, policy loss 0.04122904688119888\n",
      "\n",
      "episode 13, policy loss 0.05868808552622795\n",
      "\n",
      "episode 14, policy loss 0.030124271288514137\n",
      "\n",
      "episode 15, policy loss 0.0639813244342804\n",
      "\n",
      "episode 16, policy loss 0.06771079450845718\n",
      "\n",
      "Policy train loss in epoch 1:0.051362934300414054\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.06036630645394325\n",
      "\n",
      "episode 2, policy loss 0.07975365221500397\n",
      "\n",
      "episode 3, policy loss 0.06794627010822296\n",
      "\n",
      "episode 4, policy loss 0.058512572199106216\n",
      "\n",
      "episode 5, policy loss 0.021561341360211372\n",
      "\n",
      "episode 6, policy loss 0.049580540508031845\n",
      "\n",
      "episode 7, policy loss 0.039869461208581924\n",
      "\n",
      "episode 8, policy loss 0.030653811991214752\n",
      "\n",
      "episode 9, policy loss 0.001593349501490593\n",
      "\n",
      "episode 10, policy loss 0.06722582131624222\n",
      "\n",
      "episode 11, policy loss 0.1018969863653183\n",
      "\n",
      "episode 12, policy loss 0.06676047295331955\n",
      "\n",
      "episode 13, policy loss 0.020728204399347305\n",
      "\n",
      "episode 14, policy loss 0.04165002331137657\n",
      "\n",
      "episode 15, policy loss 0.04332629218697548\n",
      "\n",
      "episode 16, policy loss 0.06491214781999588\n",
      "\n",
      "Policy train loss in epoch 2:0.05102107836864889\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.030102793127298355\n",
      "\n",
      "episode 2, policy loss 0.06689754128456116\n",
      "\n",
      "episode 3, policy loss 0.10181845724582672\n",
      "\n",
      "episode 4, policy loss 0.06725069135427475\n",
      "\n",
      "episode 5, policy loss 0.08263827115297318\n",
      "\n",
      "episode 6, policy loss 0.06350632756948471\n",
      "\n",
      "episode 7, policy loss 0.021655308082699776\n",
      "\n",
      "episode 8, policy loss 0.06481394916772842\n",
      "\n",
      "episode 9, policy loss 0.04646211862564087\n",
      "\n",
      "episode 10, policy loss 0.041193705052137375\n",
      "\n",
      "episode 11, policy loss 0.019686495885252953\n",
      "\n",
      "episode 12, policy loss 0.06420641392469406\n",
      "\n",
      "episode 13, policy loss 0.04990135878324509\n",
      "\n",
      "episode 14, policy loss 0.05887111276388168\n",
      "\n",
      "episode 15, policy loss 0.0016930022975429893\n",
      "\n",
      "episode 16, policy loss 0.0406871922314167\n",
      "\n",
      "Policy train loss in epoch 3:0.051336546159291174\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.14628966152668\n",
      "\n",
      "episode 2, val func loss 0.17626601457595825\n",
      "\n",
      "episode 3, val func loss 0.17640283703804016\n",
      "\n",
      "episode 4, val func loss 0.16876521706581116\n",
      "\n",
      "episode 5, val func loss 0.18318380415439606\n",
      "\n",
      "episode 6, val func loss 0.16090290248394012\n",
      "\n",
      "episode 7, val func loss 0.1879633218050003\n",
      "\n",
      "episode 8, val func loss 0.20270372927188873\n",
      "\n",
      "episode 9, val func loss 0.1702800691127777\n",
      "\n",
      "episode 10, val func loss 0.14052064716815948\n",
      "\n",
      "episode 11, val func loss 0.18229886889457703\n",
      "\n",
      "episode 12, val func loss 0.17341487109661102\n",
      "\n",
      "episode 13, val func loss 0.17885154485702515\n",
      "\n",
      "episode 14, val func loss 0.16586433351039886\n",
      "\n",
      "episode 15, val func loss 0.18879227340221405\n",
      "\n",
      "episode 16, val func loss 0.20260301232337952\n",
      "\n",
      "Val func train loss in epoch 0:0.1753189442679286\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17995287477970123\n",
      "\n",
      "episode 2, val func loss 0.13966813683509827\n",
      "\n",
      "episode 3, val func loss 0.18680568039417267\n",
      "\n",
      "episode 4, val func loss 0.17172487080097198\n",
      "\n",
      "episode 5, val func loss 0.1598576307296753\n",
      "\n",
      "episode 6, val func loss 0.17320546507835388\n",
      "\n",
      "episode 7, val func loss 0.20184510946273804\n",
      "\n",
      "episode 8, val func loss 0.16693633794784546\n",
      "\n",
      "episode 9, val func loss 0.18028408288955688\n",
      "\n",
      "episode 10, val func loss 0.17667058110237122\n",
      "\n",
      "episode 11, val func loss 0.1826709657907486\n",
      "\n",
      "episode 12, val func loss 0.2016046792268753\n",
      "\n",
      "episode 13, val func loss 0.17844855785369873\n",
      "\n",
      "episode 14, val func loss 0.1707904040813446\n",
      "\n",
      "episode 15, val func loss 0.1474754959344864\n",
      "\n",
      "episode 16, val func loss 0.1925218403339386\n",
      "\n",
      "Val func train loss in epoch 1:0.17565391957759857\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1713484525680542\n",
      "\n",
      "episode 2, val func loss 0.1809825450181961\n",
      "\n",
      "episode 3, val func loss 0.15962742269039154\n",
      "\n",
      "episode 4, val func loss 0.1446959376335144\n",
      "\n",
      "episode 5, val func loss 0.16935798525810242\n",
      "\n",
      "episode 6, val func loss 0.16788631677627563\n",
      "\n",
      "episode 7, val func loss 0.18880143761634827\n",
      "\n",
      "episode 8, val func loss 0.20593979954719543\n",
      "\n",
      "episode 9, val func loss 0.18995772302150726\n",
      "\n",
      "episode 10, val func loss 0.1781272441148758\n",
      "\n",
      "episode 11, val func loss 0.1742924600839615\n",
      "\n",
      "episode 12, val func loss 0.20352685451507568\n",
      "\n",
      "episode 13, val func loss 0.17989565432071686\n",
      "\n",
      "episode 14, val func loss 0.14699538052082062\n",
      "\n",
      "episode 15, val func loss 0.18384616076946259\n",
      "\n",
      "episode 16, val func loss 0.1774456650018692\n",
      "\n",
      "Val func train loss in epoch 2:0.17642043996602297\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1849076896905899\n",
      "\n",
      "episode 2, val func loss 0.2027699202299118\n",
      "\n",
      "episode 3, val func loss 0.13992825150489807\n",
      "\n",
      "episode 4, val func loss 0.1832636147737503\n",
      "\n",
      "episode 5, val func loss 0.1439441442489624\n",
      "\n",
      "episode 6, val func loss 0.17163094878196716\n",
      "\n",
      "episode 7, val func loss 0.16861464083194733\n",
      "\n",
      "episode 8, val func loss 0.18370512127876282\n",
      "\n",
      "episode 9, val func loss 0.17580518126487732\n",
      "\n",
      "episode 10, val func loss 0.17027544975280762\n",
      "\n",
      "episode 11, val func loss 0.1820579171180725\n",
      "\n",
      "episode 12, val func loss 0.1587880253791809\n",
      "\n",
      "episode 13, val func loss 0.17719653248786926\n",
      "\n",
      "episode 14, val func loss 0.18667788803577423\n",
      "\n",
      "episode 15, val func loss 0.1692374050617218\n",
      "\n",
      "episode 16, val func loss 0.20166148245334625\n",
      "\n",
      "Val func train loss in epoch 3:0.17502901330590248\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17152142524719238\n",
      "\n",
      "episode 2, val func loss 0.1592751443386078\n",
      "\n",
      "episode 3, val func loss 0.18216721713542938\n",
      "\n",
      "episode 4, val func loss 0.172260582447052\n",
      "\n",
      "episode 5, val func loss 0.205688938498497\n",
      "\n",
      "episode 6, val func loss 0.2032717615365982\n",
      "\n",
      "episode 7, val func loss 0.18649402260780334\n",
      "\n",
      "episode 8, val func loss 0.18787500262260437\n",
      "\n",
      "episode 9, val func loss 0.18466079235076904\n",
      "\n",
      "episode 10, val func loss 0.1801598221063614\n",
      "\n",
      "episode 11, val func loss 0.17569804191589355\n",
      "\n",
      "episode 12, val func loss 0.17647424340248108\n",
      "\n",
      "episode 13, val func loss 0.14699549973011017\n",
      "\n",
      "episode 14, val func loss 0.16701285541057587\n",
      "\n",
      "episode 15, val func loss 0.14019069075584412\n",
      "\n",
      "episode 16, val func loss 0.1749688684940338\n",
      "\n",
      "Val func train loss in epoch 4:0.17591968178749084\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18427322804927826\n",
      "\n",
      "episode 2, val func loss 0.17267079651355743\n",
      "\n",
      "episode 3, val func loss 0.1382298767566681\n",
      "\n",
      "episode 4, val func loss 0.16124029457569122\n",
      "\n",
      "episode 5, val func loss 0.16822709143161774\n",
      "\n",
      "episode 6, val func loss 0.20580661296844482\n",
      "\n",
      "episode 7, val func loss 0.16656248271465302\n",
      "\n",
      "episode 8, val func loss 0.18089061975479126\n",
      "\n",
      "episode 9, val func loss 0.17098160088062286\n",
      "\n",
      "episode 10, val func loss 0.2035037726163864\n",
      "\n",
      "episode 11, val func loss 0.14905959367752075\n",
      "\n",
      "episode 12, val func loss 0.17673352360725403\n",
      "\n",
      "episode 13, val func loss 0.18189534544944763\n",
      "\n",
      "episode 14, val func loss 0.18574002385139465\n",
      "\n",
      "episode 15, val func loss 0.17788562178611755\n",
      "\n",
      "episode 16, val func loss 0.18853707611560822\n",
      "\n",
      "Val func train loss in epoch 5:0.17576484754681587\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18835540115833282\n",
      "\n",
      "episode 2, val func loss 0.14277859032154083\n",
      "\n",
      "episode 3, val func loss 0.17942476272583008\n",
      "\n",
      "episode 4, val func loss 0.1831328123807907\n",
      "\n",
      "episode 5, val func loss 0.20118172466754913\n",
      "\n",
      "episode 6, val func loss 0.15952478349208832\n",
      "\n",
      "episode 7, val func loss 0.20375625789165497\n",
      "\n",
      "episode 8, val func loss 0.1442515254020691\n",
      "\n",
      "episode 9, val func loss 0.1830284744501114\n",
      "\n",
      "episode 10, val func loss 0.1845235377550125\n",
      "\n",
      "episode 11, val func loss 0.17707796394824982\n",
      "\n",
      "episode 12, val func loss 0.17239555716514587\n",
      "\n",
      "episode 13, val func loss 0.1746298372745514\n",
      "\n",
      "episode 14, val func loss 0.170074462890625\n",
      "\n",
      "episode 15, val func loss 0.16723185777664185\n",
      "\n",
      "episode 16, val func loss 0.16503281891345978\n",
      "\n",
      "Val func train loss in epoch 6:0.17477502301335335\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18362340331077576\n",
      "\n",
      "episode 2, val func loss 0.17471414804458618\n",
      "\n",
      "episode 3, val func loss 0.19255642592906952\n",
      "\n",
      "episode 4, val func loss 0.18260399997234344\n",
      "\n",
      "episode 5, val func loss 0.20406071841716766\n",
      "\n",
      "episode 6, val func loss 0.16845178604125977\n",
      "\n",
      "episode 7, val func loss 0.1778300404548645\n",
      "\n",
      "episode 8, val func loss 0.18646804988384247\n",
      "\n",
      "episode 9, val func loss 0.15890134871006012\n",
      "\n",
      "episode 10, val func loss 0.1465269774198532\n",
      "\n",
      "episode 11, val func loss 0.18260031938552856\n",
      "\n",
      "episode 12, val func loss 0.20378722250461578\n",
      "\n",
      "episode 13, val func loss 0.14041894674301147\n",
      "\n",
      "episode 14, val func loss 0.17177240550518036\n",
      "\n",
      "episode 15, val func loss 0.16518810391426086\n",
      "\n",
      "episode 16, val func loss 0.17378927767276764\n",
      "\n",
      "Val func train loss in epoch 7:0.1758308233693242\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16849754750728607\n",
      "\n",
      "episode 2, val func loss 0.2060881108045578\n",
      "\n",
      "episode 3, val func loss 0.1709400862455368\n",
      "\n",
      "episode 4, val func loss 0.160079225897789\n",
      "\n",
      "episode 5, val func loss 0.17497172951698303\n",
      "\n",
      "episode 6, val func loss 0.18847909569740295\n",
      "\n",
      "episode 7, val func loss 0.18626073002815247\n",
      "\n",
      "episode 8, val func loss 0.178225576877594\n",
      "\n",
      "episode 9, val func loss 0.18489305675029755\n",
      "\n",
      "episode 10, val func loss 0.17162440717220306\n",
      "\n",
      "episode 11, val func loss 0.15282896161079407\n",
      "\n",
      "episode 12, val func loss 0.18176579475402832\n",
      "\n",
      "episode 13, val func loss 0.18310613930225372\n",
      "\n",
      "episode 14, val func loss 0.1670783907175064\n",
      "\n",
      "episode 15, val func loss 0.20305854082107544\n",
      "\n",
      "episode 16, val func loss 0.13866348564624786\n",
      "\n",
      "Val func train loss in epoch 8:0.17603505495935678\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1839667409658432\n",
      "\n",
      "episode 2, val func loss 0.20541013777256012\n",
      "\n",
      "episode 3, val func loss 0.1687384694814682\n",
      "\n",
      "episode 4, val func loss 0.1828913688659668\n",
      "\n",
      "episode 5, val func loss 0.18058209121227264\n",
      "\n",
      "episode 6, val func loss 0.15920186042785645\n",
      "\n",
      "episode 7, val func loss 0.20263029634952545\n",
      "\n",
      "episode 8, val func loss 0.14602036774158478\n",
      "\n",
      "episode 9, val func loss 0.17221184074878693\n",
      "\n",
      "episode 10, val func loss 0.1775251030921936\n",
      "\n",
      "episode 11, val func loss 0.17292851209640503\n",
      "\n",
      "episode 12, val func loss 0.16665248572826385\n",
      "\n",
      "episode 13, val func loss 0.14063961803913116\n",
      "\n",
      "episode 14, val func loss 0.18597294390201569\n",
      "\n",
      "episode 15, val func loss 0.17533141374588013\n",
      "\n",
      "episode 16, val func loss 0.18967881798744202\n",
      "\n",
      "Val func train loss in epoch 9:0.17564887925982475\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.13929851353168488\n",
      "\n",
      "episode 2, val func loss 0.1716771423816681\n",
      "\n",
      "episode 3, val func loss 0.1605583280324936\n",
      "\n",
      "episode 4, val func loss 0.14403238892555237\n",
      "\n",
      "episode 5, val func loss 0.20466524362564087\n",
      "\n",
      "episode 6, val func loss 0.20613141357898712\n",
      "\n",
      "episode 7, val func loss 0.1711059808731079\n",
      "\n",
      "episode 8, val func loss 0.1862034648656845\n",
      "\n",
      "episode 9, val func loss 0.18304775655269623\n",
      "\n",
      "episode 10, val func loss 0.1673094779253006\n",
      "\n",
      "episode 11, val func loss 0.18075570464134216\n",
      "\n",
      "episode 12, val func loss 0.17982280254364014\n",
      "\n",
      "episode 13, val func loss 0.17724211513996124\n",
      "\n",
      "episode 14, val func loss 0.1779065728187561\n",
      "\n",
      "episode 15, val func loss 0.18739737570285797\n",
      "\n",
      "episode 16, val func loss 0.17202414572238922\n",
      "\n",
      "Val func train loss in epoch 10:0.1755736516788602\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.17210987210273743\n",
      "\n",
      "episode 2, val func loss 0.15896916389465332\n",
      "\n",
      "episode 3, val func loss 0.1825796663761139\n",
      "\n",
      "episode 4, val func loss 0.1664065569639206\n",
      "\n",
      "episode 5, val func loss 0.1672823280096054\n",
      "\n",
      "episode 6, val func loss 0.17785891890525818\n",
      "\n",
      "episode 7, val func loss 0.13840964436531067\n",
      "\n",
      "episode 8, val func loss 0.1432085782289505\n",
      "\n",
      "episode 9, val func loss 0.1877218335866928\n",
      "\n",
      "episode 10, val func loss 0.17351771891117096\n",
      "\n",
      "episode 11, val func loss 0.20340177416801453\n",
      "\n",
      "episode 12, val func loss 0.18011964857578278\n",
      "\n",
      "episode 13, val func loss 0.1862087845802307\n",
      "\n",
      "episode 14, val func loss 0.17538531124591827\n",
      "\n",
      "episode 15, val func loss 0.20455990731716156\n",
      "\n",
      "episode 16, val func loss 0.189407080411911\n",
      "\n",
      "Val func train loss in epoch 11:0.17544667422771454\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17257831990718842\n",
      "\n",
      "episode 2, val func loss 0.16513797640800476\n",
      "\n",
      "episode 3, val func loss 0.18444401025772095\n",
      "\n",
      "episode 4, val func loss 0.17502959072589874\n",
      "\n",
      "episode 5, val func loss 0.1435224562883377\n",
      "\n",
      "episode 6, val func loss 0.13831403851509094\n",
      "\n",
      "episode 7, val func loss 0.2072203904390335\n",
      "\n",
      "episode 8, val func loss 0.2077203243970871\n",
      "\n",
      "episode 9, val func loss 0.18680821359157562\n",
      "\n",
      "episode 10, val func loss 0.18969565629959106\n",
      "\n",
      "episode 11, val func loss 0.17763660848140717\n",
      "\n",
      "episode 12, val func loss 0.17322050034999847\n",
      "\n",
      "episode 13, val func loss 0.18056073784828186\n",
      "\n",
      "episode 14, val func loss 0.16185463964939117\n",
      "\n",
      "episode 15, val func loss 0.17554643750190735\n",
      "\n",
      "episode 16, val func loss 0.18599174916744232\n",
      "\n",
      "Val func train loss in epoch 12:0.17658010311424732\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18571791052818298\n",
      "\n",
      "episode 2, val func loss 0.14715738594532013\n",
      "\n",
      "episode 3, val func loss 0.17740677297115326\n",
      "\n",
      "episode 4, val func loss 0.140425905585289\n",
      "\n",
      "episode 5, val func loss 0.2044714242219925\n",
      "\n",
      "episode 6, val func loss 0.18171793222427368\n",
      "\n",
      "episode 7, val func loss 0.17535395920276642\n",
      "\n",
      "episode 8, val func loss 0.17123568058013916\n",
      "\n",
      "episode 9, val func loss 0.1835423856973648\n",
      "\n",
      "episode 10, val func loss 0.17251740396022797\n",
      "\n",
      "episode 11, val func loss 0.1599022001028061\n",
      "\n",
      "episode 12, val func loss 0.16998565196990967\n",
      "\n",
      "episode 13, val func loss 0.18857444822788239\n",
      "\n",
      "episode 14, val func loss 0.16644534468650818\n",
      "\n",
      "episode 15, val func loss 0.20443592965602875\n",
      "\n",
      "episode 16, val func loss 0.1826150119304657\n",
      "\n",
      "Val func train loss in epoch 13:0.17571908421814442\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1807948797941208\n",
      "\n",
      "episode 2, val func loss 0.18598146736621857\n",
      "\n",
      "episode 3, val func loss 0.16283705830574036\n",
      "\n",
      "episode 4, val func loss 0.18896746635437012\n",
      "\n",
      "episode 5, val func loss 0.18352454900741577\n",
      "\n",
      "episode 6, val func loss 0.20226894319057465\n",
      "\n",
      "episode 7, val func loss 0.14225396513938904\n",
      "\n",
      "episode 8, val func loss 0.172783762216568\n",
      "\n",
      "episode 9, val func loss 0.20497184991836548\n",
      "\n",
      "episode 10, val func loss 0.16873034834861755\n",
      "\n",
      "episode 11, val func loss 0.1815645843744278\n",
      "\n",
      "episode 12, val func loss 0.17942295968532562\n",
      "\n",
      "episode 13, val func loss 0.16647782921791077\n",
      "\n",
      "episode 14, val func loss 0.17526933550834656\n",
      "\n",
      "episode 15, val func loss 0.1710706651210785\n",
      "\n",
      "episode 16, val func loss 0.14447881281375885\n",
      "\n",
      "Val func train loss in epoch 14:0.17571240477263927\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1726163923740387\n",
      "\n",
      "episode 2, val func loss 0.17904800176620483\n",
      "\n",
      "episode 3, val func loss 0.1840963214635849\n",
      "\n",
      "episode 4, val func loss 0.17547538876533508\n",
      "\n",
      "episode 5, val func loss 0.20421341061592102\n",
      "\n",
      "episode 6, val func loss 0.20284822583198547\n",
      "\n",
      "episode 7, val func loss 0.18570168316364288\n",
      "\n",
      "episode 8, val func loss 0.18335691094398499\n",
      "\n",
      "episode 9, val func loss 0.16886459290981293\n",
      "\n",
      "episode 10, val func loss 0.16037136316299438\n",
      "\n",
      "episode 11, val func loss 0.1799495816230774\n",
      "\n",
      "episode 12, val func loss 0.188345268368721\n",
      "\n",
      "episode 13, val func loss 0.1457168310880661\n",
      "\n",
      "episode 14, val func loss 0.1404079645872116\n",
      "\n",
      "episode 15, val func loss 0.1687440723180771\n",
      "\n",
      "episode 16, val func loss 0.17181743681430817\n",
      "\n",
      "Val func train loss in epoch 15:0.1757233403623104\n",
      "***********************TIME WAS 5.00370257695516 min*****************************\n",
      "\n",
      "**********************ROUND 117 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.08464571833610535\n",
      "\n",
      "episode 2, policy loss -0.06305037438869476\n",
      "\n",
      "episode 3, policy loss -0.12692752480506897\n",
      "\n",
      "episode 4, policy loss -0.07181373983621597\n",
      "\n",
      "episode 5, policy loss -0.05836808308959007\n",
      "\n",
      "episode 6, policy loss -0.06340350210666656\n",
      "\n",
      "episode 7, policy loss -0.05753730237483978\n",
      "\n",
      "episode 8, policy loss -0.12722767889499664\n",
      "\n",
      "episode 9, policy loss -0.11134324967861176\n",
      "\n",
      "episode 10, policy loss -0.07001648843288422\n",
      "\n",
      "episode 11, policy loss -0.09647884964942932\n",
      "\n",
      "episode 12, policy loss -0.10385677218437195\n",
      "\n",
      "episode 13, policy loss -0.11255209147930145\n",
      "\n",
      "episode 14, policy loss -0.11109413951635361\n",
      "\n",
      "episode 15, policy loss -0.0820518359541893\n",
      "\n",
      "episode 16, policy loss -0.059602539986371994\n",
      "\n",
      "Policy train loss in epoch 0:-0.08749811816960573\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.11266664415597916\n",
      "\n",
      "episode 2, policy loss -0.10877805948257446\n",
      "\n",
      "episode 3, policy loss -0.11511294543743134\n",
      "\n",
      "episode 4, policy loss -0.0849284753203392\n",
      "\n",
      "episode 5, policy loss -0.10792260617017746\n",
      "\n",
      "episode 6, policy loss -0.0717778280377388\n",
      "\n",
      "episode 7, policy loss -0.12370837479829788\n",
      "\n",
      "episode 8, policy loss -0.0768023431301117\n",
      "\n",
      "episode 9, policy loss -0.06132735684514046\n",
      "\n",
      "episode 10, policy loss -0.06234477087855339\n",
      "\n",
      "episode 11, policy loss -0.06297626346349716\n",
      "\n",
      "episode 12, policy loss -0.09234917908906937\n",
      "\n",
      "episode 13, policy loss -0.05811261013150215\n",
      "\n",
      "episode 14, policy loss -0.09880911558866501\n",
      "\n",
      "episode 15, policy loss -0.13018454611301422\n",
      "\n",
      "episode 16, policy loss -0.07044515013694763\n",
      "\n",
      "Policy train loss in epoch 1:-0.08989039179868996\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.06347452849149704\n",
      "\n",
      "episode 2, policy loss -0.07141023129224777\n",
      "\n",
      "episode 3, policy loss -0.13321295380592346\n",
      "\n",
      "episode 4, policy loss -0.06129484996199608\n",
      "\n",
      "episode 5, policy loss -0.12823161482810974\n",
      "\n",
      "episode 6, policy loss -0.11044508218765259\n",
      "\n",
      "episode 7, policy loss -0.06001254916191101\n",
      "\n",
      "episode 8, policy loss -0.10676126182079315\n",
      "\n",
      "episode 9, policy loss -0.07045063376426697\n",
      "\n",
      "episode 10, policy loss -0.055879317224025726\n",
      "\n",
      "episode 11, policy loss -0.09842206537723541\n",
      "\n",
      "episode 12, policy loss -0.08269225805997849\n",
      "\n",
      "episode 13, policy loss -0.0765802189707756\n",
      "\n",
      "episode 14, policy loss -0.11493749171495438\n",
      "\n",
      "episode 15, policy loss -0.09260314702987671\n",
      "\n",
      "episode 16, policy loss -0.11880536377429962\n",
      "\n",
      "Policy train loss in epoch 2:-0.09032584796659648\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.059099480509757996\n",
      "\n",
      "episode 2, policy loss -0.056253425776958466\n",
      "\n",
      "episode 3, policy loss -0.0705181136727333\n",
      "\n",
      "episode 4, policy loss -0.11657972633838654\n",
      "\n",
      "episode 5, policy loss -0.13264207541942596\n",
      "\n",
      "episode 6, policy loss -0.061806343495845795\n",
      "\n",
      "episode 7, policy loss -0.09906540811061859\n",
      "\n",
      "episode 8, policy loss -0.11002752184867859\n",
      "\n",
      "episode 9, policy loss -0.11771276593208313\n",
      "\n",
      "episode 10, policy loss -0.1279788464307785\n",
      "\n",
      "episode 11, policy loss -0.077691450715065\n",
      "\n",
      "episode 12, policy loss -0.07222101837396622\n",
      "\n",
      "episode 13, policy loss -0.10807864367961884\n",
      "\n",
      "episode 14, policy loss -0.06250813603401184\n",
      "\n",
      "episode 15, policy loss -0.08443403244018555\n",
      "\n",
      "episode 16, policy loss -0.09240112453699112\n",
      "\n",
      "Policy train loss in epoch 3:-0.09056363208219409\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.18234951794147491\n",
      "\n",
      "episode 2, val func loss 0.2016705870628357\n",
      "\n",
      "episode 3, val func loss 0.20316182076931\n",
      "\n",
      "episode 4, val func loss 0.1780846267938614\n",
      "\n",
      "episode 5, val func loss 0.20891396701335907\n",
      "\n",
      "episode 6, val func loss 0.16986845433712006\n",
      "\n",
      "episode 7, val func loss 0.17591509222984314\n",
      "\n",
      "episode 8, val func loss 0.2050180733203888\n",
      "\n",
      "episode 9, val func loss 0.21247020363807678\n",
      "\n",
      "episode 10, val func loss 0.20288650691509247\n",
      "\n",
      "episode 11, val func loss 0.2031574249267578\n",
      "\n",
      "episode 12, val func loss 0.17588455975055695\n",
      "\n",
      "episode 13, val func loss 0.18054750561714172\n",
      "\n",
      "episode 14, val func loss 0.18486621975898743\n",
      "\n",
      "episode 15, val func loss 0.17370487749576569\n",
      "\n",
      "episode 16, val func loss 0.21439890563488007\n",
      "\n",
      "Val func train loss in epoch 0:0.19205614645034075\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1776404231786728\n",
      "\n",
      "episode 2, val func loss 0.169586181640625\n",
      "\n",
      "episode 3, val func loss 0.17363516986370087\n",
      "\n",
      "episode 4, val func loss 0.20568031072616577\n",
      "\n",
      "episode 5, val func loss 0.18469586968421936\n",
      "\n",
      "episode 6, val func loss 0.1978020966053009\n",
      "\n",
      "episode 7, val func loss 0.17673487961292267\n",
      "\n",
      "episode 8, val func loss 0.20133733749389648\n",
      "\n",
      "episode 9, val func loss 0.17788097262382507\n",
      "\n",
      "episode 10, val func loss 0.21051225066184998\n",
      "\n",
      "episode 11, val func loss 0.20226086676120758\n",
      "\n",
      "episode 12, val func loss 0.2067648321390152\n",
      "\n",
      "episode 13, val func loss 0.21337461471557617\n",
      "\n",
      "episode 14, val func loss 0.17921748757362366\n",
      "\n",
      "episode 15, val func loss 0.19686749577522278\n",
      "\n",
      "episode 16, val func loss 0.18380078673362732\n",
      "\n",
      "Val func train loss in epoch 1:0.19111197348684072\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17079994082450867\n",
      "\n",
      "episode 2, val func loss 0.17559713125228882\n",
      "\n",
      "episode 3, val func loss 0.17558790743350983\n",
      "\n",
      "episode 4, val func loss 0.17699220776557922\n",
      "\n",
      "episode 5, val func loss 0.18520215153694153\n",
      "\n",
      "episode 6, val func loss 0.197793647646904\n",
      "\n",
      "episode 7, val func loss 0.20149335265159607\n",
      "\n",
      "episode 8, val func loss 0.1774173080921173\n",
      "\n",
      "episode 9, val func loss 0.20691850781440735\n",
      "\n",
      "episode 10, val func loss 0.18165278434753418\n",
      "\n",
      "episode 11, val func loss 0.19755049049854279\n",
      "\n",
      "episode 12, val func loss 0.204487144947052\n",
      "\n",
      "episode 13, val func loss 0.175446555018425\n",
      "\n",
      "episode 14, val func loss 0.20169568061828613\n",
      "\n",
      "episode 15, val func loss 0.2128453552722931\n",
      "\n",
      "episode 16, val func loss 0.20858509838581085\n",
      "\n",
      "Val func train loss in epoch 2:0.1906290790066123\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.17512711882591248\n",
      "\n",
      "episode 2, val func loss 0.17649675905704498\n",
      "\n",
      "episode 3, val func loss 0.19766314327716827\n",
      "\n",
      "episode 4, val func loss 0.20096337795257568\n",
      "\n",
      "episode 5, val func loss 0.20644214749336243\n",
      "\n",
      "episode 6, val func loss 0.1842043399810791\n",
      "\n",
      "episode 7, val func loss 0.17790941894054413\n",
      "\n",
      "episode 8, val func loss 0.17018313705921173\n",
      "\n",
      "episode 9, val func loss 0.181086465716362\n",
      "\n",
      "episode 10, val func loss 0.1751999706029892\n",
      "\n",
      "episode 11, val func loss 0.21906618773937225\n",
      "\n",
      "episode 12, val func loss 0.19643141329288483\n",
      "\n",
      "episode 13, val func loss 0.1758834272623062\n",
      "\n",
      "episode 14, val func loss 0.21059195697307587\n",
      "\n",
      "episode 15, val func loss 0.20192267000675201\n",
      "\n",
      "episode 16, val func loss 0.20313146710395813\n",
      "\n",
      "Val func train loss in epoch 3:0.19076893758028746\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1819923222064972\n",
      "\n",
      "episode 2, val func loss 0.20809993147850037\n",
      "\n",
      "episode 3, val func loss 0.18525297939777374\n",
      "\n",
      "episode 4, val func loss 0.19721251726150513\n",
      "\n",
      "episode 5, val func loss 0.20386385917663574\n",
      "\n",
      "episode 6, val func loss 0.1752023696899414\n",
      "\n",
      "episode 7, val func loss 0.20587590336799622\n",
      "\n",
      "episode 8, val func loss 0.17859774827957153\n",
      "\n",
      "episode 9, val func loss 0.18509238958358765\n",
      "\n",
      "episode 10, val func loss 0.17509423196315765\n",
      "\n",
      "episode 11, val func loss 0.20162539184093475\n",
      "\n",
      "episode 12, val func loss 0.20105695724487305\n",
      "\n",
      "episode 13, val func loss 0.1684066504240036\n",
      "\n",
      "episode 14, val func loss 0.1738782823085785\n",
      "\n",
      "episode 15, val func loss 0.21561141312122345\n",
      "\n",
      "episode 16, val func loss 0.19766803085803986\n",
      "\n",
      "Val func train loss in epoch 4:0.19090818613767624\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17896512150764465\n",
      "\n",
      "episode 2, val func loss 0.2137797623872757\n",
      "\n",
      "episode 3, val func loss 0.17719435691833496\n",
      "\n",
      "episode 4, val func loss 0.17310762405395508\n",
      "\n",
      "episode 5, val func loss 0.18421579897403717\n",
      "\n",
      "episode 6, val func loss 0.17556607723236084\n",
      "\n",
      "episode 7, val func loss 0.2001522332429886\n",
      "\n",
      "episode 8, val func loss 0.18097904324531555\n",
      "\n",
      "episode 9, val func loss 0.21155455708503723\n",
      "\n",
      "episode 10, val func loss 0.17346954345703125\n",
      "\n",
      "episode 11, val func loss 0.20685073733329773\n",
      "\n",
      "episode 12, val func loss 0.2015334516763687\n",
      "\n",
      "episode 13, val func loss 0.19821515679359436\n",
      "\n",
      "episode 14, val func loss 0.19601242244243622\n",
      "\n",
      "episode 15, val func loss 0.20464392006397247\n",
      "\n",
      "episode 16, val func loss 0.1750650703907013\n",
      "\n",
      "Val func train loss in epoch 5:0.190706554800272\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1980661004781723\n",
      "\n",
      "episode 2, val func loss 0.20241375267505646\n",
      "\n",
      "episode 3, val func loss 0.18514716625213623\n",
      "\n",
      "episode 4, val func loss 0.18037883937358856\n",
      "\n",
      "episode 5, val func loss 0.21128086745738983\n",
      "\n",
      "episode 6, val func loss 0.17583167552947998\n",
      "\n",
      "episode 7, val func loss 0.19615451991558075\n",
      "\n",
      "episode 8, val func loss 0.2057439386844635\n",
      "\n",
      "episode 9, val func loss 0.17534402012825012\n",
      "\n",
      "episode 10, val func loss 0.20057810842990875\n",
      "\n",
      "episode 11, val func loss 0.20663931965827942\n",
      "\n",
      "episode 12, val func loss 0.21010689437389374\n",
      "\n",
      "episode 13, val func loss 0.17465931177139282\n",
      "\n",
      "episode 14, val func loss 0.17803698778152466\n",
      "\n",
      "episode 15, val func loss 0.1701532006263733\n",
      "\n",
      "episode 16, val func loss 0.18439334630966187\n",
      "\n",
      "Val func train loss in epoch 6:0.19093300309032202\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18217600882053375\n",
      "\n",
      "episode 2, val func loss 0.21590998768806458\n",
      "\n",
      "episode 3, val func loss 0.2109266221523285\n",
      "\n",
      "episode 4, val func loss 0.1766790747642517\n",
      "\n",
      "episode 5, val func loss 0.17468084394931793\n",
      "\n",
      "episode 6, val func loss 0.1770375669002533\n",
      "\n",
      "episode 7, val func loss 0.1705169975757599\n",
      "\n",
      "episode 8, val func loss 0.20107930898666382\n",
      "\n",
      "episode 9, val func loss 0.17391544580459595\n",
      "\n",
      "episode 10, val func loss 0.18376973271369934\n",
      "\n",
      "episode 11, val func loss 0.2068658471107483\n",
      "\n",
      "episode 12, val func loss 0.20026305317878723\n",
      "\n",
      "episode 13, val func loss 0.20626750588417053\n",
      "\n",
      "episode 14, val func loss 0.19681167602539062\n",
      "\n",
      "episode 15, val func loss 0.17853906750679016\n",
      "\n",
      "episode 16, val func loss 0.1978999525308609\n",
      "\n",
      "Val func train loss in epoch 7:0.19083366822451353\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17820528149604797\n",
      "\n",
      "episode 2, val func loss 0.20374532043933868\n",
      "\n",
      "episode 3, val func loss 0.17441584169864655\n",
      "\n",
      "episode 4, val func loss 0.17743849754333496\n",
      "\n",
      "episode 5, val func loss 0.19729876518249512\n",
      "\n",
      "episode 6, val func loss 0.2129901498556137\n",
      "\n",
      "episode 7, val func loss 0.20893076062202454\n",
      "\n",
      "episode 8, val func loss 0.20476974546909332\n",
      "\n",
      "episode 9, val func loss 0.20088548958301544\n",
      "\n",
      "episode 10, val func loss 0.17556650936603546\n",
      "\n",
      "episode 11, val func loss 0.17622961103916168\n",
      "\n",
      "episode 12, val func loss 0.19580824673175812\n",
      "\n",
      "episode 13, val func loss 0.16888996958732605\n",
      "\n",
      "episode 14, val func loss 0.20249512791633606\n",
      "\n",
      "episode 15, val func loss 0.18571878969669342\n",
      "\n",
      "episode 16, val func loss 0.17938187718391418\n",
      "\n",
      "Val func train loss in epoch 8:0.1901731239631772\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17410583794116974\n",
      "\n",
      "episode 2, val func loss 0.21344676613807678\n",
      "\n",
      "episode 3, val func loss 0.21685005724430084\n",
      "\n",
      "episode 4, val func loss 0.1983727216720581\n",
      "\n",
      "episode 5, val func loss 0.175361767411232\n",
      "\n",
      "episode 6, val func loss 0.17917028069496155\n",
      "\n",
      "episode 7, val func loss 0.17873530089855194\n",
      "\n",
      "episode 8, val func loss 0.17086650431156158\n",
      "\n",
      "episode 9, val func loss 0.20174458622932434\n",
      "\n",
      "episode 10, val func loss 0.20601233839988708\n",
      "\n",
      "episode 11, val func loss 0.17545980215072632\n",
      "\n",
      "episode 12, val func loss 0.18084165453910828\n",
      "\n",
      "episode 13, val func loss 0.20029054582118988\n",
      "\n",
      "episode 14, val func loss 0.20614372193813324\n",
      "\n",
      "episode 15, val func loss 0.19609788060188293\n",
      "\n",
      "episode 16, val func loss 0.18421649932861328\n",
      "\n",
      "Val func train loss in epoch 9:0.19110726658254862\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.198819100856781\n",
      "\n",
      "episode 2, val func loss 0.2070430964231491\n",
      "\n",
      "episode 3, val func loss 0.17410092055797577\n",
      "\n",
      "episode 4, val func loss 0.18752986192703247\n",
      "\n",
      "episode 5, val func loss 0.18295890092849731\n",
      "\n",
      "episode 6, val func loss 0.19677546620368958\n",
      "\n",
      "episode 7, val func loss 0.2115412801504135\n",
      "\n",
      "episode 8, val func loss 0.20131894946098328\n",
      "\n",
      "episode 9, val func loss 0.2054530829191208\n",
      "\n",
      "episode 10, val func loss 0.17693427205085754\n",
      "\n",
      "episode 11, val func loss 0.17603090405464172\n",
      "\n",
      "episode 12, val func loss 0.1708037108182907\n",
      "\n",
      "episode 13, val func loss 0.1805272400379181\n",
      "\n",
      "episode 14, val func loss 0.1757686883211136\n",
      "\n",
      "episode 15, val func loss 0.20112454891204834\n",
      "\n",
      "episode 16, val func loss 0.20871101319789886\n",
      "\n",
      "Val func train loss in epoch 10:0.19096506480127573\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.17291784286499023\n",
      "\n",
      "episode 2, val func loss 0.17659440636634827\n",
      "\n",
      "episode 3, val func loss 0.20120683312416077\n",
      "\n",
      "episode 4, val func loss 0.2158416360616684\n",
      "\n",
      "episode 5, val func loss 0.20656022429466248\n",
      "\n",
      "episode 6, val func loss 0.1783355176448822\n",
      "\n",
      "episode 7, val func loss 0.19671274721622467\n",
      "\n",
      "episode 8, val func loss 0.18451657891273499\n",
      "\n",
      "episode 9, val func loss 0.17677034437656403\n",
      "\n",
      "episode 10, val func loss 0.20912101864814758\n",
      "\n",
      "episode 11, val func loss 0.1736161857843399\n",
      "\n",
      "episode 12, val func loss 0.20526176691055298\n",
      "\n",
      "episode 13, val func loss 0.17230792343616486\n",
      "\n",
      "episode 14, val func loss 0.18283990025520325\n",
      "\n",
      "episode 15, val func loss 0.1978481113910675\n",
      "\n",
      "episode 16, val func loss 0.20204056799411774\n",
      "\n",
      "Val func train loss in epoch 11:0.19078072533011436\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17539425194263458\n",
      "\n",
      "episode 2, val func loss 0.20980669558048248\n",
      "\n",
      "episode 3, val func loss 0.18589290976524353\n",
      "\n",
      "episode 4, val func loss 0.2048874944448471\n",
      "\n",
      "episode 5, val func loss 0.17923882603645325\n",
      "\n",
      "episode 6, val func loss 0.20169490575790405\n",
      "\n",
      "episode 7, val func loss 0.17594024538993835\n",
      "\n",
      "episode 8, val func loss 0.2066459208726883\n",
      "\n",
      "episode 9, val func loss 0.17897991836071014\n",
      "\n",
      "episode 10, val func loss 0.19526293873786926\n",
      "\n",
      "episode 11, val func loss 0.17507590353488922\n",
      "\n",
      "episode 12, val func loss 0.16832180321216583\n",
      "\n",
      "episode 13, val func loss 0.1975303739309311\n",
      "\n",
      "episode 14, val func loss 0.2002740204334259\n",
      "\n",
      "episode 15, val func loss 0.21490740776062012\n",
      "\n",
      "episode 16, val func loss 0.18145358562469482\n",
      "\n",
      "Val func train loss in epoch 12:0.19070670008659363\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.17749077081680298\n",
      "\n",
      "episode 2, val func loss 0.18195924162864685\n",
      "\n",
      "episode 3, val func loss 0.19891902804374695\n",
      "\n",
      "episode 4, val func loss 0.20246022939682007\n",
      "\n",
      "episode 5, val func loss 0.19719298183918\n",
      "\n",
      "episode 6, val func loss 0.175143301486969\n",
      "\n",
      "episode 7, val func loss 0.20013925433158875\n",
      "\n",
      "episode 8, val func loss 0.16922497749328613\n",
      "\n",
      "episode 9, val func loss 0.17545588314533234\n",
      "\n",
      "episode 10, val func loss 0.20581166446208954\n",
      "\n",
      "episode 11, val func loss 0.1765216737985611\n",
      "\n",
      "episode 12, val func loss 0.17518238723278046\n",
      "\n",
      "episode 13, val func loss 0.2131047546863556\n",
      "\n",
      "episode 14, val func loss 0.21034900844097137\n",
      "\n",
      "episode 15, val func loss 0.1843816190958023\n",
      "\n",
      "episode 16, val func loss 0.20408104360103607\n",
      "\n",
      "Val func train loss in epoch 13:0.1904636137187481\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.2089831382036209\n",
      "\n",
      "episode 2, val func loss 0.17194566130638123\n",
      "\n",
      "episode 3, val func loss 0.1784207820892334\n",
      "\n",
      "episode 4, val func loss 0.17830587923526764\n",
      "\n",
      "episode 5, val func loss 0.20040205121040344\n",
      "\n",
      "episode 6, val func loss 0.1978663206100464\n",
      "\n",
      "episode 7, val func loss 0.21543444693088531\n",
      "\n",
      "episode 8, val func loss 0.1755705326795578\n",
      "\n",
      "episode 9, val func loss 0.20685209333896637\n",
      "\n",
      "episode 10, val func loss 0.1775454878807068\n",
      "\n",
      "episode 11, val func loss 0.20556968450546265\n",
      "\n",
      "episode 12, val func loss 0.17772269248962402\n",
      "\n",
      "episode 13, val func loss 0.20091871917247772\n",
      "\n",
      "episode 14, val func loss 0.1830521523952484\n",
      "\n",
      "episode 15, val func loss 0.18645747005939484\n",
      "\n",
      "episode 16, val func loss 0.19655299186706543\n",
      "\n",
      "Val func train loss in epoch 14:0.1913500064983964\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.17580075562000275\n",
      "\n",
      "episode 2, val func loss 0.20667383074760437\n",
      "\n",
      "episode 3, val func loss 0.20219039916992188\n",
      "\n",
      "episode 4, val func loss 0.19897083938121796\n",
      "\n",
      "episode 5, val func loss 0.18635335564613342\n",
      "\n",
      "episode 6, val func loss 0.17461901903152466\n",
      "\n",
      "episode 7, val func loss 0.17766262590885162\n",
      "\n",
      "episode 8, val func loss 0.2020413875579834\n",
      "\n",
      "episode 9, val func loss 0.16903048753738403\n",
      "\n",
      "episode 10, val func loss 0.21287864446640015\n",
      "\n",
      "episode 11, val func loss 0.19703683257102966\n",
      "\n",
      "episode 12, val func loss 0.21431949734687805\n",
      "\n",
      "episode 13, val func loss 0.17760653793811798\n",
      "\n",
      "episode 14, val func loss 0.17530059814453125\n",
      "\n",
      "episode 15, val func loss 0.2048255354166031\n",
      "\n",
      "episode 16, val func loss 0.1851155012845993\n",
      "\n",
      "Val func train loss in epoch 15:0.19127661548554897\n",
      "***********************TIME WAS 5.0045275012652075 min*****************************\n",
      "\n",
      "**********************ROUND 118 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.0655478984117508\n",
      "\n",
      "episode 2, policy loss 0.04159174859523773\n",
      "\n",
      "episode 3, policy loss -0.017316678538918495\n",
      "\n",
      "episode 4, policy loss 0.03962674364447594\n",
      "\n",
      "episode 5, policy loss -0.013980134390294552\n",
      "\n",
      "episode 6, policy loss 0.003401180962100625\n",
      "\n",
      "episode 7, policy loss 0.016188010573387146\n",
      "\n",
      "episode 8, policy loss 0.03228088095784187\n",
      "\n",
      "episode 9, policy loss 0.03568786010146141\n",
      "\n",
      "episode 10, policy loss 0.040187768638134\n",
      "\n",
      "episode 11, policy loss 0.05987510457634926\n",
      "\n",
      "episode 12, policy loss 0.04134811460971832\n",
      "\n",
      "episode 13, policy loss -0.012206098064780235\n",
      "\n",
      "episode 14, policy loss 0.061608508229255676\n",
      "\n",
      "episode 15, policy loss 0.03544044494628906\n",
      "\n",
      "episode 16, policy loss 0.029460089281201363\n",
      "\n",
      "Policy train loss in epoch 0:0.02867134015832562\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.03479425609111786\n",
      "\n",
      "episode 2, policy loss 0.057532355189323425\n",
      "\n",
      "episode 3, policy loss -0.027103571221232414\n",
      "\n",
      "episode 4, policy loss 0.02757915109395981\n",
      "\n",
      "episode 5, policy loss 0.03399907797574997\n",
      "\n",
      "episode 6, policy loss 0.059140972793102264\n",
      "\n",
      "episode 7, policy loss 0.016691390424966812\n",
      "\n",
      "episode 8, policy loss -0.013066142797470093\n",
      "\n",
      "episode 9, policy loss 0.03416891768574715\n",
      "\n",
      "episode 10, policy loss 0.04004793241620064\n",
      "\n",
      "episode 11, policy loss -0.017503010109066963\n",
      "\n",
      "episode 12, policy loss 0.001104998285882175\n",
      "\n",
      "episode 13, policy loss 0.04122959077358246\n",
      "\n",
      "episode 14, policy loss 0.057697296142578125\n",
      "\n",
      "episode 15, policy loss 0.03244156017899513\n",
      "\n",
      "episode 16, policy loss 0.032334014773368835\n",
      "\n",
      "Policy train loss in epoch 1:0.025693049356050324\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.016616933047771454\n",
      "\n",
      "episode 2, policy loss 0.05706930533051491\n",
      "\n",
      "episode 3, policy loss 0.057503145188093185\n",
      "\n",
      "episode 4, policy loss -0.0138058140873909\n",
      "\n",
      "episode 5, policy loss -0.027969881892204285\n",
      "\n",
      "episode 6, policy loss 0.015018545091152191\n",
      "\n",
      "episode 7, policy loss 0.05411958321928978\n",
      "\n",
      "episode 8, policy loss 0.03885995224118233\n",
      "\n",
      "episode 9, policy loss 0.03194897621870041\n",
      "\n",
      "episode 10, policy loss 0.026883307844400406\n",
      "\n",
      "episode 11, policy loss 0.03315344452857971\n",
      "\n",
      "episode 12, policy loss 0.0316975973546505\n",
      "\n",
      "episode 13, policy loss 0.0011631451779976487\n",
      "\n",
      "episode 14, policy loss 0.03379816934466362\n",
      "\n",
      "episode 15, policy loss 0.03196341544389725\n",
      "\n",
      "episode 16, policy loss 0.0411229245364666\n",
      "\n",
      "Policy train loss in epoch 2:0.024744305155763868\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.057353246957063675\n",
      "\n",
      "episode 2, policy loss 0.053710851818323135\n",
      "\n",
      "episode 3, policy loss 0.033391766250133514\n",
      "\n",
      "episode 4, policy loss -0.0006167301326058805\n",
      "\n",
      "episode 5, policy loss 0.033657241612672806\n",
      "\n",
      "episode 6, policy loss -0.02826370857656002\n",
      "\n",
      "episode 7, policy loss 0.03900418058037758\n",
      "\n",
      "episode 8, policy loss 0.026588402688503265\n",
      "\n",
      "episode 9, policy loss 0.05782420560717583\n",
      "\n",
      "episode 10, policy loss 0.014763765037059784\n",
      "\n",
      "episode 11, policy loss -0.01402366440743208\n",
      "\n",
      "episode 12, policy loss 0.03935415297746658\n",
      "\n",
      "episode 13, policy loss 0.031246772035956383\n",
      "\n",
      "episode 14, policy loss -0.016607919707894325\n",
      "\n",
      "episode 15, policy loss 0.030376801267266273\n",
      "\n",
      "episode 16, policy loss 0.031934283673763275\n",
      "\n",
      "Policy train loss in epoch 3:0.024355852980079362\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.2120220810174942\n",
      "\n",
      "episode 2, val func loss 0.1864173710346222\n",
      "\n",
      "episode 3, val func loss 0.18709440529346466\n",
      "\n",
      "episode 4, val func loss 0.19068196415901184\n",
      "\n",
      "episode 5, val func loss 0.18452228605747223\n",
      "\n",
      "episode 6, val func loss 0.16824330389499664\n",
      "\n",
      "episode 7, val func loss 0.1923726350069046\n",
      "\n",
      "episode 8, val func loss 0.17350827157497406\n",
      "\n",
      "episode 9, val func loss 0.18415376543998718\n",
      "\n",
      "episode 10, val func loss 0.18233615159988403\n",
      "\n",
      "episode 11, val func loss 0.22001509368419647\n",
      "\n",
      "episode 12, val func loss 0.18672603368759155\n",
      "\n",
      "episode 13, val func loss 0.16386333107948303\n",
      "\n",
      "episode 14, val func loss 0.18913887441158295\n",
      "\n",
      "episode 15, val func loss 0.16968375444412231\n",
      "\n",
      "episode 16, val func loss 0.21067309379577637\n",
      "\n",
      "Val func train loss in epoch 0:0.18759077601134777\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18383321166038513\n",
      "\n",
      "episode 2, val func loss 0.21312011778354645\n",
      "\n",
      "episode 3, val func loss 0.21119093894958496\n",
      "\n",
      "episode 4, val func loss 0.19088658690452576\n",
      "\n",
      "episode 5, val func loss 0.1863054633140564\n",
      "\n",
      "episode 6, val func loss 0.18931783735752106\n",
      "\n",
      "episode 7, val func loss 0.18494977056980133\n",
      "\n",
      "episode 8, val func loss 0.1938951164484024\n",
      "\n",
      "episode 9, val func loss 0.16861259937286377\n",
      "\n",
      "episode 10, val func loss 0.18669767677783966\n",
      "\n",
      "episode 11, val func loss 0.17310881614685059\n",
      "\n",
      "episode 12, val func loss 0.19076840579509735\n",
      "\n",
      "episode 13, val func loss 0.18821874260902405\n",
      "\n",
      "episode 14, val func loss 0.21354623138904572\n",
      "\n",
      "episode 15, val func loss 0.16310220956802368\n",
      "\n",
      "episode 16, val func loss 0.17006747424602509\n",
      "\n",
      "Val func train loss in epoch 1:0.1879763249307871\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.21548761427402496\n",
      "\n",
      "episode 2, val func loss 0.169716015458107\n",
      "\n",
      "episode 3, val func loss 0.1856013685464859\n",
      "\n",
      "episode 4, val func loss 0.18974345922470093\n",
      "\n",
      "episode 5, val func loss 0.18950138986110687\n",
      "\n",
      "episode 6, val func loss 0.1842457801103592\n",
      "\n",
      "episode 7, val func loss 0.18625713884830475\n",
      "\n",
      "episode 8, val func loss 0.18307362496852875\n",
      "\n",
      "episode 9, val func loss 0.19329842925071716\n",
      "\n",
      "episode 10, val func loss 0.18911361694335938\n",
      "\n",
      "episode 11, val func loss 0.21243444085121155\n",
      "\n",
      "episode 12, val func loss 0.1683582216501236\n",
      "\n",
      "episode 13, val func loss 0.17459529638290405\n",
      "\n",
      "episode 14, val func loss 0.18304309248924255\n",
      "\n",
      "episode 15, val func loss 0.2146691232919693\n",
      "\n",
      "episode 16, val func loss 0.16567198932170868\n",
      "\n",
      "Val func train loss in epoch 2:0.1878006625920534\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18385452032089233\n",
      "\n",
      "episode 2, val func loss 0.21320362389087677\n",
      "\n",
      "episode 3, val func loss 0.18699343502521515\n",
      "\n",
      "episode 4, val func loss 0.2104058861732483\n",
      "\n",
      "episode 5, val func loss 0.18767817318439484\n",
      "\n",
      "episode 6, val func loss 0.2125300168991089\n",
      "\n",
      "episode 7, val func loss 0.19013819098472595\n",
      "\n",
      "episode 8, val func loss 0.18727000057697296\n",
      "\n",
      "episode 9, val func loss 0.19223584234714508\n",
      "\n",
      "episode 10, val func loss 0.18391385674476624\n",
      "\n",
      "episode 11, val func loss 0.18350155651569366\n",
      "\n",
      "episode 12, val func loss 0.17078663408756256\n",
      "\n",
      "episode 13, val func loss 0.18968039751052856\n",
      "\n",
      "episode 14, val func loss 0.1647486835718155\n",
      "\n",
      "episode 15, val func loss 0.16974547505378723\n",
      "\n",
      "episode 16, val func loss 0.17310602962970734\n",
      "\n",
      "Val func train loss in epoch 3:0.18748702015727758\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.21860671043395996\n",
      "\n",
      "episode 2, val func loss 0.18957100808620453\n",
      "\n",
      "episode 3, val func loss 0.18496523797512054\n",
      "\n",
      "episode 4, val func loss 0.1826946884393692\n",
      "\n",
      "episode 5, val func loss 0.16561344265937805\n",
      "\n",
      "episode 6, val func loss 0.18976178765296936\n",
      "\n",
      "episode 7, val func loss 0.21215103566646576\n",
      "\n",
      "episode 8, val func loss 0.16966049373149872\n",
      "\n",
      "episode 9, val func loss 0.1750531643629074\n",
      "\n",
      "episode 10, val func loss 0.2109367996454239\n",
      "\n",
      "episode 11, val func loss 0.1837841123342514\n",
      "\n",
      "episode 12, val func loss 0.18948854506015778\n",
      "\n",
      "episode 13, val func loss 0.18406574428081512\n",
      "\n",
      "episode 14, val func loss 0.18642058968544006\n",
      "\n",
      "episode 15, val func loss 0.19281792640686035\n",
      "\n",
      "episode 16, val func loss 0.17010582983493805\n",
      "\n",
      "Val func train loss in epoch 4:0.187856069765985\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18703490495681763\n",
      "\n",
      "episode 2, val func loss 0.19268395006656647\n",
      "\n",
      "episode 3, val func loss 0.21524539589881897\n",
      "\n",
      "episode 4, val func loss 0.18317334353923798\n",
      "\n",
      "episode 5, val func loss 0.1880728304386139\n",
      "\n",
      "episode 6, val func loss 0.16623501479625702\n",
      "\n",
      "episode 7, val func loss 0.1905498057603836\n",
      "\n",
      "episode 8, val func loss 0.1690439134836197\n",
      "\n",
      "episode 9, val func loss 0.18431925773620605\n",
      "\n",
      "episode 10, val func loss 0.1885344684123993\n",
      "\n",
      "episode 11, val func loss 0.1857626736164093\n",
      "\n",
      "episode 12, val func loss 0.17086215317249298\n",
      "\n",
      "episode 13, val func loss 0.17290182411670685\n",
      "\n",
      "episode 14, val func loss 0.21973705291748047\n",
      "\n",
      "episode 15, val func loss 0.18321533501148224\n",
      "\n",
      "episode 16, val func loss 0.212470144033432\n",
      "\n",
      "Val func train loss in epoch 5:0.18811512924730778\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18307271599769592\n",
      "\n",
      "episode 2, val func loss 0.19181299209594727\n",
      "\n",
      "episode 3, val func loss 0.1871742606163025\n",
      "\n",
      "episode 4, val func loss 0.18495383858680725\n",
      "\n",
      "episode 5, val func loss 0.21065625548362732\n",
      "\n",
      "episode 6, val func loss 0.18981698155403137\n",
      "\n",
      "episode 7, val func loss 0.21288913488388062\n",
      "\n",
      "episode 8, val func loss 0.1696881651878357\n",
      "\n",
      "episode 9, val func loss 0.2115228921175003\n",
      "\n",
      "episode 10, val func loss 0.1763850748538971\n",
      "\n",
      "episode 11, val func loss 0.1874719262123108\n",
      "\n",
      "episode 12, val func loss 0.18476946651935577\n",
      "\n",
      "episode 13, val func loss 0.1890750229358673\n",
      "\n",
      "episode 14, val func loss 0.16989293694496155\n",
      "\n",
      "episode 15, val func loss 0.18443557620048523\n",
      "\n",
      "episode 16, val func loss 0.16308344900608063\n",
      "\n",
      "Val func train loss in epoch 6:0.18729379307478666\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1855052411556244\n",
      "\n",
      "episode 2, val func loss 0.17079772055149078\n",
      "\n",
      "episode 3, val func loss 0.21971552073955536\n",
      "\n",
      "episode 4, val func loss 0.2176157534122467\n",
      "\n",
      "episode 5, val func loss 0.18323557078838348\n",
      "\n",
      "episode 6, val func loss 0.18756987154483795\n",
      "\n",
      "episode 7, val func loss 0.20961512625217438\n",
      "\n",
      "episode 8, val func loss 0.18927375972270966\n",
      "\n",
      "episode 9, val func loss 0.1705988347530365\n",
      "\n",
      "episode 10, val func loss 0.17500123381614685\n",
      "\n",
      "episode 11, val func loss 0.18901638686656952\n",
      "\n",
      "episode 12, val func loss 0.18335144221782684\n",
      "\n",
      "episode 13, val func loss 0.19363777339458466\n",
      "\n",
      "episode 14, val func loss 0.1682789921760559\n",
      "\n",
      "episode 15, val func loss 0.19012311100959778\n",
      "\n",
      "episode 16, val func loss 0.18770359456539154\n",
      "\n",
      "Val func train loss in epoch 7:0.18881499581038952\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.18341131508350372\n",
      "\n",
      "episode 2, val func loss 0.19054295122623444\n",
      "\n",
      "episode 3, val func loss 0.17238058149814606\n",
      "\n",
      "episode 4, val func loss 0.18291227519512177\n",
      "\n",
      "episode 5, val func loss 0.18290509283542633\n",
      "\n",
      "episode 6, val func loss 0.19311921298503876\n",
      "\n",
      "episode 7, val func loss 0.2125944048166275\n",
      "\n",
      "episode 8, val func loss 0.2105897068977356\n",
      "\n",
      "episode 9, val func loss 0.17184560000896454\n",
      "\n",
      "episode 10, val func loss 0.1705988347530365\n",
      "\n",
      "episode 11, val func loss 0.1888091117143631\n",
      "\n",
      "episode 12, val func loss 0.1845938116312027\n",
      "\n",
      "episode 13, val func loss 0.16667300462722778\n",
      "\n",
      "episode 14, val func loss 0.18877872824668884\n",
      "\n",
      "episode 15, val func loss 0.1900690793991089\n",
      "\n",
      "episode 16, val func loss 0.22041641175746918\n",
      "\n",
      "Val func train loss in epoch 8:0.18814000766724348\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18660052120685577\n",
      "\n",
      "episode 2, val func loss 0.17317859828472137\n",
      "\n",
      "episode 3, val func loss 0.18910640478134155\n",
      "\n",
      "episode 4, val func loss 0.18327288329601288\n",
      "\n",
      "episode 5, val func loss 0.16997915506362915\n",
      "\n",
      "episode 6, val func loss 0.1830655038356781\n",
      "\n",
      "episode 7, val func loss 0.21307621896266937\n",
      "\n",
      "episode 8, val func loss 0.1833895444869995\n",
      "\n",
      "episode 9, val func loss 0.1926022619009018\n",
      "\n",
      "episode 10, val func loss 0.16962872445583344\n",
      "\n",
      "episode 11, val func loss 0.1664648950099945\n",
      "\n",
      "episode 12, val func loss 0.18507517874240875\n",
      "\n",
      "episode 13, val func loss 0.21151277422904968\n",
      "\n",
      "episode 14, val func loss 0.21498465538024902\n",
      "\n",
      "episode 15, val func loss 0.18895524740219116\n",
      "\n",
      "episode 16, val func loss 0.1903090476989746\n",
      "\n",
      "Val func train loss in epoch 9:0.18757510092109442\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1697007119655609\n",
      "\n",
      "episode 2, val func loss 0.18243958055973053\n",
      "\n",
      "episode 3, val func loss 0.18410325050354004\n",
      "\n",
      "episode 4, val func loss 0.17002175748348236\n",
      "\n",
      "episode 5, val func loss 0.21203279495239258\n",
      "\n",
      "episode 6, val func loss 0.21585474908351898\n",
      "\n",
      "episode 7, val func loss 0.18741528689861298\n",
      "\n",
      "episode 8, val func loss 0.1898636668920517\n",
      "\n",
      "episode 9, val func loss 0.16675236821174622\n",
      "\n",
      "episode 10, val func loss 0.18651214241981506\n",
      "\n",
      "episode 11, val func loss 0.184087336063385\n",
      "\n",
      "episode 12, val func loss 0.21188105642795563\n",
      "\n",
      "episode 13, val func loss 0.18991942703723907\n",
      "\n",
      "episode 14, val func loss 0.19224874675273895\n",
      "\n",
      "episode 15, val func loss 0.17355021834373474\n",
      "\n",
      "episode 16, val func loss 0.1860598772764206\n",
      "\n",
      "Val func train loss in epoch 10:0.18765268567949533\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1934366226196289\n",
      "\n",
      "episode 2, val func loss 0.1849193572998047\n",
      "\n",
      "episode 3, val func loss 0.21744389832019806\n",
      "\n",
      "episode 4, val func loss 0.18433921039104462\n",
      "\n",
      "episode 5, val func loss 0.17090368270874023\n",
      "\n",
      "episode 6, val func loss 0.1821855902671814\n",
      "\n",
      "episode 7, val func loss 0.18354997038841248\n",
      "\n",
      "episode 8, val func loss 0.21149905025959015\n",
      "\n",
      "episode 9, val func loss 0.17322617769241333\n",
      "\n",
      "episode 10, val func loss 0.18754127621650696\n",
      "\n",
      "episode 11, val func loss 0.18774724006652832\n",
      "\n",
      "episode 12, val func loss 0.1693977564573288\n",
      "\n",
      "episode 13, val func loss 0.18552374839782715\n",
      "\n",
      "episode 14, val func loss 0.21361269056797028\n",
      "\n",
      "episode 15, val func loss 0.18887658417224884\n",
      "\n",
      "episode 16, val func loss 0.16523683071136475\n",
      "\n",
      "Val func train loss in epoch 11:0.1874649804085493\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18923601508140564\n",
      "\n",
      "episode 2, val func loss 0.18696080148220062\n",
      "\n",
      "episode 3, val func loss 0.20963901281356812\n",
      "\n",
      "episode 4, val func loss 0.1939612776041031\n",
      "\n",
      "episode 5, val func loss 0.16611121594905853\n",
      "\n",
      "episode 6, val func loss 0.18313077092170715\n",
      "\n",
      "episode 7, val func loss 0.2143942415714264\n",
      "\n",
      "episode 8, val func loss 0.18330931663513184\n",
      "\n",
      "episode 9, val func loss 0.17386631667613983\n",
      "\n",
      "episode 10, val func loss 0.1685113161802292\n",
      "\n",
      "episode 11, val func loss 0.1884775012731552\n",
      "\n",
      "episode 12, val func loss 0.1908353567123413\n",
      "\n",
      "episode 13, val func loss 0.1864197999238968\n",
      "\n",
      "episode 14, val func loss 0.18367531895637512\n",
      "\n",
      "episode 15, val func loss 0.17079836130142212\n",
      "\n",
      "episode 16, val func loss 0.2157907783985138\n",
      "\n",
      "Val func train loss in epoch 12:0.18781983759254217\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18392322957515717\n",
      "\n",
      "episode 2, val func loss 0.1734578162431717\n",
      "\n",
      "episode 3, val func loss 0.18398356437683105\n",
      "\n",
      "episode 4, val func loss 0.18837809562683105\n",
      "\n",
      "episode 5, val func loss 0.18454809486865997\n",
      "\n",
      "episode 6, val func loss 0.1698898822069168\n",
      "\n",
      "episode 7, val func loss 0.18858744204044342\n",
      "\n",
      "episode 8, val func loss 0.1684713214635849\n",
      "\n",
      "episode 9, val func loss 0.21275053918361664\n",
      "\n",
      "episode 10, val func loss 0.18603117763996124\n",
      "\n",
      "episode 11, val func loss 0.1896374374628067\n",
      "\n",
      "episode 12, val func loss 0.1824544072151184\n",
      "\n",
      "episode 13, val func loss 0.16574661433696747\n",
      "\n",
      "episode 14, val func loss 0.2124340534210205\n",
      "\n",
      "episode 15, val func loss 0.1924007534980774\n",
      "\n",
      "episode 16, val func loss 0.21310460567474365\n",
      "\n",
      "Val func train loss in epoch 13:0.18723743967711926\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1885468065738678\n",
      "\n",
      "episode 2, val func loss 0.18384332954883575\n",
      "\n",
      "episode 3, val func loss 0.18447652459144592\n",
      "\n",
      "episode 4, val func loss 0.17139439284801483\n",
      "\n",
      "episode 5, val func loss 0.16654126346111298\n",
      "\n",
      "episode 6, val func loss 0.18962781131267548\n",
      "\n",
      "episode 7, val func loss 0.18528763949871063\n",
      "\n",
      "episode 8, val func loss 0.21213772892951965\n",
      "\n",
      "episode 9, val func loss 0.1931074857711792\n",
      "\n",
      "episode 10, val func loss 0.16900470852851868\n",
      "\n",
      "episode 11, val func loss 0.17289331555366516\n",
      "\n",
      "episode 12, val func loss 0.18860667943954468\n",
      "\n",
      "episode 13, val func loss 0.2188420593738556\n",
      "\n",
      "episode 14, val func loss 0.18593166768550873\n",
      "\n",
      "episode 15, val func loss 0.21258176863193512\n",
      "\n",
      "episode 16, val func loss 0.18227021396160126\n",
      "\n",
      "Val func train loss in epoch 14:0.18781833723187447\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18666893243789673\n",
      "\n",
      "episode 2, val func loss 0.19261476397514343\n",
      "\n",
      "episode 3, val func loss 0.2097369283437729\n",
      "\n",
      "episode 4, val func loss 0.21075187623500824\n",
      "\n",
      "episode 5, val func loss 0.16811372339725494\n",
      "\n",
      "episode 6, val func loss 0.18600930273532867\n",
      "\n",
      "episode 7, val func loss 0.18803538382053375\n",
      "\n",
      "episode 8, val func loss 0.1759590059518814\n",
      "\n",
      "episode 9, val func loss 0.2132592797279358\n",
      "\n",
      "episode 10, val func loss 0.18722178041934967\n",
      "\n",
      "episode 11, val func loss 0.16980215907096863\n",
      "\n",
      "episode 12, val func loss 0.18387438356876373\n",
      "\n",
      "episode 13, val func loss 0.1896687000989914\n",
      "\n",
      "episode 14, val func loss 0.19159072637557983\n",
      "\n",
      "episode 15, val func loss 0.18290159106254578\n",
      "\n",
      "episode 16, val func loss 0.16806168854236603\n",
      "\n",
      "Val func train loss in epoch 15:0.18776688911020756\n",
      "***********************TIME WAS 5.004687066872915 min*****************************\n",
      "\n",
      "**********************ROUND 119 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.03171703591942787\n",
      "\n",
      "episode 2, policy loss -0.03665466606616974\n",
      "\n",
      "episode 3, policy loss 0.05801195651292801\n",
      "\n",
      "episode 4, policy loss -0.03588404878973961\n",
      "\n",
      "episode 5, policy loss -0.024724513292312622\n",
      "\n",
      "episode 6, policy loss -0.03145008161664009\n",
      "\n",
      "episode 7, policy loss -0.009533248841762543\n",
      "\n",
      "episode 8, policy loss -0.053746894001960754\n",
      "\n",
      "episode 9, policy loss -0.01343296468257904\n",
      "\n",
      "episode 10, policy loss 0.003693889593705535\n",
      "\n",
      "episode 11, policy loss 0.034626904875040054\n",
      "\n",
      "episode 12, policy loss 0.007044337689876556\n",
      "\n",
      "episode 13, policy loss -0.06702513247728348\n",
      "\n",
      "episode 14, policy loss -0.04004022106528282\n",
      "\n",
      "episode 15, policy loss -0.0503481850028038\n",
      "\n",
      "episode 16, policy loss -0.017429031431674957\n",
      "\n",
      "Policy train loss in epoch 0:-0.015323428917326964\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.04125827178359032\n",
      "\n",
      "episode 2, policy loss 0.0016554751200601459\n",
      "\n",
      "episode 3, policy loss 0.02233913727104664\n",
      "\n",
      "episode 4, policy loss 0.05139177292585373\n",
      "\n",
      "episode 5, policy loss -0.016873233020305634\n",
      "\n",
      "episode 6, policy loss -0.06694742292165756\n",
      "\n",
      "episode 7, policy loss -0.057574786245822906\n",
      "\n",
      "episode 8, policy loss 0.006712938658893108\n",
      "\n",
      "episode 9, policy loss -0.016186634078621864\n",
      "\n",
      "episode 10, policy loss -0.03297289460897446\n",
      "\n",
      "episode 11, policy loss -0.049673158675432205\n",
      "\n",
      "episode 12, policy loss 0.034895867109298706\n",
      "\n",
      "episode 13, policy loss -0.04438462108373642\n",
      "\n",
      "episode 14, policy loss -0.009060819633305073\n",
      "\n",
      "episode 15, policy loss -0.03302646428346634\n",
      "\n",
      "episode 16, policy loss -0.040553878992795944\n",
      "\n",
      "Policy train loss in epoch 1:-0.018219812140159775\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.017681267112493515\n",
      "\n",
      "episode 2, policy loss 0.0013700049603357911\n",
      "\n",
      "episode 3, policy loss -0.047132086008787155\n",
      "\n",
      "episode 4, policy loss 0.008071153424680233\n",
      "\n",
      "episode 5, policy loss 0.05119318515062332\n",
      "\n",
      "episode 6, policy loss -0.0571681447327137\n",
      "\n",
      "episode 7, policy loss -0.0331786647439003\n",
      "\n",
      "episode 8, policy loss 0.021446259692311287\n",
      "\n",
      "episode 9, policy loss -0.010954609140753746\n",
      "\n",
      "episode 10, policy loss -0.05038224905729294\n",
      "\n",
      "episode 11, policy loss -0.01632244698703289\n",
      "\n",
      "episode 12, policy loss -0.06821410357952118\n",
      "\n",
      "episode 13, policy loss 0.03368709236383438\n",
      "\n",
      "episode 14, policy loss -0.04170098155736923\n",
      "\n",
      "episode 15, policy loss -0.0417247898876667\n",
      "\n",
      "episode 16, policy loss -0.03196531906723976\n",
      "\n",
      "Policy train loss in epoch 2:-0.01879106039268663\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.021387070417404175\n",
      "\n",
      "episode 2, policy loss 0.0015653250738978386\n",
      "\n",
      "episode 3, policy loss -0.04219633713364601\n",
      "\n",
      "episode 4, policy loss 0.006445355247706175\n",
      "\n",
      "episode 5, policy loss 0.03364694491028786\n",
      "\n",
      "episode 6, policy loss -0.051133789122104645\n",
      "\n",
      "episode 7, policy loss -0.016168957576155663\n",
      "\n",
      "episode 8, policy loss -0.01777075231075287\n",
      "\n",
      "episode 9, policy loss -0.03265443071722984\n",
      "\n",
      "episode 10, policy loss -0.03392321616411209\n",
      "\n",
      "episode 11, policy loss -0.058574460446834564\n",
      "\n",
      "episode 12, policy loss -0.04588085412979126\n",
      "\n",
      "episode 13, policy loss -0.04044358804821968\n",
      "\n",
      "episode 14, policy loss -0.010413038544356823\n",
      "\n",
      "episode 15, policy loss -0.06840433180332184\n",
      "\n",
      "episode 16, policy loss 0.04982612654566765\n",
      "\n",
      "Policy train loss in epoch 3:-0.0190433083625976\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.22316879034042358\n",
      "\n",
      "episode 2, val func loss 0.1934521496295929\n",
      "\n",
      "episode 3, val func loss 0.21965384483337402\n",
      "\n",
      "episode 4, val func loss 0.18513409793376923\n",
      "\n",
      "episode 5, val func loss 0.19037966430187225\n",
      "\n",
      "episode 6, val func loss 0.22284285724163055\n",
      "\n",
      "episode 7, val func loss 0.18798653781414032\n",
      "\n",
      "episode 8, val func loss 0.16481010615825653\n",
      "\n",
      "episode 9, val func loss 0.19534049928188324\n",
      "\n",
      "episode 10, val func loss 0.20090654492378235\n",
      "\n",
      "episode 11, val func loss 0.16115091741085052\n",
      "\n",
      "episode 12, val func loss 0.20278722047805786\n",
      "\n",
      "episode 13, val func loss 0.2051774561405182\n",
      "\n",
      "episode 14, val func loss 0.1552266776561737\n",
      "\n",
      "episode 15, val func loss 0.17800617218017578\n",
      "\n",
      "episode 16, val func loss 0.19951312243938446\n",
      "\n",
      "Val func train loss in epoch 0:0.19284604117274284\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1824740171432495\n",
      "\n",
      "episode 2, val func loss 0.20193544030189514\n",
      "\n",
      "episode 3, val func loss 0.1820477992296219\n",
      "\n",
      "episode 4, val func loss 0.19948230683803558\n",
      "\n",
      "episode 5, val func loss 0.18982937932014465\n",
      "\n",
      "episode 6, val func loss 0.2269018292427063\n",
      "\n",
      "episode 7, val func loss 0.20129092037677765\n",
      "\n",
      "episode 8, val func loss 0.20346355438232422\n",
      "\n",
      "episode 9, val func loss 0.22153984010219574\n",
      "\n",
      "episode 10, val func loss 0.1944422572851181\n",
      "\n",
      "episode 11, val func loss 0.19737090170383453\n",
      "\n",
      "episode 12, val func loss 0.16919995844364166\n",
      "\n",
      "episode 13, val func loss 0.22012491524219513\n",
      "\n",
      "episode 14, val func loss 0.16687947511672974\n",
      "\n",
      "episode 15, val func loss 0.176886186003685\n",
      "\n",
      "episode 16, val func loss 0.15966981649398804\n",
      "\n",
      "Val func train loss in epoch 1:0.19334616232663393\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1996103674173355\n",
      "\n",
      "episode 2, val func loss 0.15132734179496765\n",
      "\n",
      "episode 3, val func loss 0.2082688808441162\n",
      "\n",
      "episode 4, val func loss 0.15770655870437622\n",
      "\n",
      "episode 5, val func loss 0.18305782973766327\n",
      "\n",
      "episode 6, val func loss 0.194867342710495\n",
      "\n",
      "episode 7, val func loss 0.22621499001979828\n",
      "\n",
      "episode 8, val func loss 0.16117556393146515\n",
      "\n",
      "episode 9, val func loss 0.17673124372959137\n",
      "\n",
      "episode 10, val func loss 0.1916705220937729\n",
      "\n",
      "episode 11, val func loss 0.20437902212142944\n",
      "\n",
      "episode 12, val func loss 0.19860005378723145\n",
      "\n",
      "episode 13, val func loss 0.18803389370441437\n",
      "\n",
      "episode 14, val func loss 0.1939498484134674\n",
      "\n",
      "episode 15, val func loss 0.22305068373680115\n",
      "\n",
      "episode 16, val func loss 0.2211448848247528\n",
      "\n",
      "Val func train loss in epoch 2:0.19248681422322989\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.22168707847595215\n",
      "\n",
      "episode 2, val func loss 0.2024814635515213\n",
      "\n",
      "episode 3, val func loss 0.20061396062374115\n",
      "\n",
      "episode 4, val func loss 0.19014334678649902\n",
      "\n",
      "episode 5, val func loss 0.16139455139636993\n",
      "\n",
      "episode 6, val func loss 0.19806304574012756\n",
      "\n",
      "episode 7, val func loss 0.19373242557048798\n",
      "\n",
      "episode 8, val func loss 0.2253425419330597\n",
      "\n",
      "episode 9, val func loss 0.1830137073993683\n",
      "\n",
      "episode 10, val func loss 0.19794368743896484\n",
      "\n",
      "episode 11, val func loss 0.18993636965751648\n",
      "\n",
      "episode 12, val func loss 0.2064584642648697\n",
      "\n",
      "episode 13, val func loss 0.158005028963089\n",
      "\n",
      "episode 14, val func loss 0.21997539699077606\n",
      "\n",
      "episode 15, val func loss 0.1777992695569992\n",
      "\n",
      "episode 16, val func loss 0.16256949305534363\n",
      "\n",
      "Val func train loss in epoch 3:0.19307248946279287\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1994832158088684\n",
      "\n",
      "episode 2, val func loss 0.19344036281108856\n",
      "\n",
      "episode 3, val func loss 0.19479304552078247\n",
      "\n",
      "episode 4, val func loss 0.1836596429347992\n",
      "\n",
      "episode 5, val func loss 0.1774909645318985\n",
      "\n",
      "episode 6, val func loss 0.20524433255195618\n",
      "\n",
      "episode 7, val func loss 0.16419386863708496\n",
      "\n",
      "episode 8, val func loss 0.15766440331935883\n",
      "\n",
      "episode 9, val func loss 0.22618715465068817\n",
      "\n",
      "episode 10, val func loss 0.18336056172847748\n",
      "\n",
      "episode 11, val func loss 0.22203640639781952\n",
      "\n",
      "episode 12, val func loss 0.2041177749633789\n",
      "\n",
      "episode 13, val func loss 0.19854454696178436\n",
      "\n",
      "episode 14, val func loss 0.19025291502475739\n",
      "\n",
      "episode 15, val func loss 0.22108156979084015\n",
      "\n",
      "episode 16, val func loss 0.16123944520950317\n",
      "\n",
      "Val func train loss in epoch 4:0.1926743881776929\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.2035372406244278\n",
      "\n",
      "episode 2, val func loss 0.1622963398694992\n",
      "\n",
      "episode 3, val func loss 0.1920487880706787\n",
      "\n",
      "episode 4, val func loss 0.19840584695339203\n",
      "\n",
      "episode 5, val func loss 0.2210366427898407\n",
      "\n",
      "episode 6, val func loss 0.1861715167760849\n",
      "\n",
      "episode 7, val func loss 0.1922823041677475\n",
      "\n",
      "episode 8, val func loss 0.2008620947599411\n",
      "\n",
      "episode 9, val func loss 0.19616709649562836\n",
      "\n",
      "episode 10, val func loss 0.22024160623550415\n",
      "\n",
      "episode 11, val func loss 0.15918461978435516\n",
      "\n",
      "episode 12, val func loss 0.17674121260643005\n",
      "\n",
      "episode 13, val func loss 0.20225031673908234\n",
      "\n",
      "episode 14, val func loss 0.1836208552122116\n",
      "\n",
      "episode 15, val func loss 0.1628861278295517\n",
      "\n",
      "episode 16, val func loss 0.22127658128738403\n",
      "\n",
      "Val func train loss in epoch 5:0.19243807438760996\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1831951141357422\n",
      "\n",
      "episode 2, val func loss 0.19957563281059265\n",
      "\n",
      "episode 3, val func loss 0.207598477602005\n",
      "\n",
      "episode 4, val func loss 0.1834142953157425\n",
      "\n",
      "episode 5, val func loss 0.19290754199028015\n",
      "\n",
      "episode 6, val func loss 0.22285111248493195\n",
      "\n",
      "episode 7, val func loss 0.19854910671710968\n",
      "\n",
      "episode 8, val func loss 0.1901230663061142\n",
      "\n",
      "episode 9, val func loss 0.17849789559841156\n",
      "\n",
      "episode 10, val func loss 0.2021062672138214\n",
      "\n",
      "episode 11, val func loss 0.15852311253547668\n",
      "\n",
      "episode 12, val func loss 0.16406477987766266\n",
      "\n",
      "episode 13, val func loss 0.21979999542236328\n",
      "\n",
      "episode 14, val func loss 0.2240835279226303\n",
      "\n",
      "episode 15, val func loss 0.15940208733081818\n",
      "\n",
      "episode 16, val func loss 0.193055659532547\n",
      "\n",
      "Val func train loss in epoch 6:0.1923592295497656\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19976039230823517\n",
      "\n",
      "episode 2, val func loss 0.21801143884658813\n",
      "\n",
      "episode 3, val func loss 0.22202575206756592\n",
      "\n",
      "episode 4, val func loss 0.1646033078432083\n",
      "\n",
      "episode 5, val func loss 0.1855272650718689\n",
      "\n",
      "episode 6, val func loss 0.1622871309518814\n",
      "\n",
      "episode 7, val func loss 0.1553484946489334\n",
      "\n",
      "episode 8, val func loss 0.1932641565799713\n",
      "\n",
      "episode 9, val func loss 0.22861066460609436\n",
      "\n",
      "episode 10, val func loss 0.20112894475460052\n",
      "\n",
      "episode 11, val func loss 0.19121374189853668\n",
      "\n",
      "episode 12, val func loss 0.20613066852092743\n",
      "\n",
      "episode 13, val func loss 0.18260939419269562\n",
      "\n",
      "episode 14, val func loss 0.1960349678993225\n",
      "\n",
      "episode 15, val func loss 0.1765335500240326\n",
      "\n",
      "episode 16, val func loss 0.2035628706216812\n",
      "\n",
      "Val func train loss in epoch 7:0.19291579630225897\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.19041170179843903\n",
      "\n",
      "episode 2, val func loss 0.2039877027273178\n",
      "\n",
      "episode 3, val func loss 0.2201295793056488\n",
      "\n",
      "episode 4, val func loss 0.20430006086826324\n",
      "\n",
      "episode 5, val func loss 0.16719770431518555\n",
      "\n",
      "episode 6, val func loss 0.19557221233844757\n",
      "\n",
      "episode 7, val func loss 0.1999877244234085\n",
      "\n",
      "episode 8, val func loss 0.1625293642282486\n",
      "\n",
      "episode 9, val func loss 0.18320146203041077\n",
      "\n",
      "episode 10, val func loss 0.17704230546951294\n",
      "\n",
      "episode 11, val func loss 0.19215528666973114\n",
      "\n",
      "episode 12, val func loss 0.18172264099121094\n",
      "\n",
      "episode 13, val func loss 0.22597496211528778\n",
      "\n",
      "episode 14, val func loss 0.1517096608877182\n",
      "\n",
      "episode 15, val func loss 0.22900409996509552\n",
      "\n",
      "episode 16, val func loss 0.20242616534233093\n",
      "\n",
      "Val func train loss in epoch 8:0.19295953959226608\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.19070729613304138\n",
      "\n",
      "episode 2, val func loss 0.1605016440153122\n",
      "\n",
      "episode 3, val func loss 0.20271675288677216\n",
      "\n",
      "episode 4, val func loss 0.20203298330307007\n",
      "\n",
      "episode 5, val func loss 0.21964965760707855\n",
      "\n",
      "episode 6, val func loss 0.1995917707681656\n",
      "\n",
      "episode 7, val func loss 0.21557851135730743\n",
      "\n",
      "episode 8, val func loss 0.17917148768901825\n",
      "\n",
      "episode 9, val func loss 0.20297108590602875\n",
      "\n",
      "episode 10, val func loss 0.16370929777622223\n",
      "\n",
      "episode 11, val func loss 0.21774747967720032\n",
      "\n",
      "episode 12, val func loss 0.18464601039886475\n",
      "\n",
      "episode 13, val func loss 0.1635812669992447\n",
      "\n",
      "episode 14, val func loss 0.18075968325138092\n",
      "\n",
      "episode 15, val func loss 0.19996410608291626\n",
      "\n",
      "episode 16, val func loss 0.19488169252872467\n",
      "\n",
      "Val func train loss in epoch 9:0.19238817039877176\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20677201449871063\n",
      "\n",
      "episode 2, val func loss 0.19795556366443634\n",
      "\n",
      "episode 3, val func loss 0.18130925297737122\n",
      "\n",
      "episode 4, val func loss 0.17759385704994202\n",
      "\n",
      "episode 5, val func loss 0.16427993774414062\n",
      "\n",
      "episode 6, val func loss 0.1926109939813614\n",
      "\n",
      "episode 7, val func loss 0.22152581810951233\n",
      "\n",
      "episode 8, val func loss 0.1998933106660843\n",
      "\n",
      "episode 9, val func loss 0.19218316674232483\n",
      "\n",
      "episode 10, val func loss 0.163101464509964\n",
      "\n",
      "episode 11, val func loss 0.18596960604190826\n",
      "\n",
      "episode 12, val func loss 0.2251015305519104\n",
      "\n",
      "episode 13, val func loss 0.21939733624458313\n",
      "\n",
      "episode 14, val func loss 0.1566198766231537\n",
      "\n",
      "episode 15, val func loss 0.1906585544347763\n",
      "\n",
      "episode 16, val func loss 0.20737068355083466\n",
      "\n",
      "Val func train loss in epoch 10:0.19264643546193838\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19926601648330688\n",
      "\n",
      "episode 2, val func loss 0.16246962547302246\n",
      "\n",
      "episode 3, val func loss 0.19472002983093262\n",
      "\n",
      "episode 4, val func loss 0.2019645869731903\n",
      "\n",
      "episode 5, val func loss 0.20483890175819397\n",
      "\n",
      "episode 6, val func loss 0.18422214686870575\n",
      "\n",
      "episode 7, val func loss 0.2233533412218094\n",
      "\n",
      "episode 8, val func loss 0.2180292159318924\n",
      "\n",
      "episode 9, val func loss 0.19118031859397888\n",
      "\n",
      "episode 10, val func loss 0.187941312789917\n",
      "\n",
      "episode 11, val func loss 0.16099552810192108\n",
      "\n",
      "episode 12, val func loss 0.19474145770072937\n",
      "\n",
      "episode 13, val func loss 0.1789868175983429\n",
      "\n",
      "episode 14, val func loss 0.2000245302915573\n",
      "\n",
      "episode 15, val func loss 0.21998564898967743\n",
      "\n",
      "episode 16, val func loss 0.15749050676822662\n",
      "\n",
      "Val func train loss in epoch 11:0.19251312408596277\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19221921265125275\n",
      "\n",
      "episode 2, val func loss 0.18209105730056763\n",
      "\n",
      "episode 3, val func loss 0.20418916642665863\n",
      "\n",
      "episode 4, val func loss 0.22343233227729797\n",
      "\n",
      "episode 5, val func loss 0.18097977340221405\n",
      "\n",
      "episode 6, val func loss 0.17671987414360046\n",
      "\n",
      "episode 7, val func loss 0.19050222635269165\n",
      "\n",
      "episode 8, val func loss 0.22502613067626953\n",
      "\n",
      "episode 9, val func loss 0.1584463119506836\n",
      "\n",
      "episode 10, val func loss 0.19964417815208435\n",
      "\n",
      "episode 11, val func loss 0.22122441232204437\n",
      "\n",
      "episode 12, val func loss 0.19884257018566132\n",
      "\n",
      "episode 13, val func loss 0.16487649083137512\n",
      "\n",
      "episode 14, val func loss 0.15664994716644287\n",
      "\n",
      "episode 15, val func loss 0.20491014420986176\n",
      "\n",
      "episode 16, val func loss 0.19406074285507202\n",
      "\n",
      "Val func train loss in epoch 12:0.19211341068148613\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19589459896087646\n",
      "\n",
      "episode 2, val func loss 0.20601588487625122\n",
      "\n",
      "episode 3, val func loss 0.2025499939918518\n",
      "\n",
      "episode 4, val func loss 0.16351620852947235\n",
      "\n",
      "episode 5, val func loss 0.15990197658538818\n",
      "\n",
      "episode 6, val func loss 0.20049145817756653\n",
      "\n",
      "episode 7, val func loss 0.21970762312412262\n",
      "\n",
      "episode 8, val func loss 0.19775506854057312\n",
      "\n",
      "episode 9, val func loss 0.22158117592334747\n",
      "\n",
      "episode 10, val func loss 0.1603139191865921\n",
      "\n",
      "episode 11, val func loss 0.1827184110879898\n",
      "\n",
      "episode 12, val func loss 0.17539003491401672\n",
      "\n",
      "episode 13, val func loss 0.22330330312252045\n",
      "\n",
      "episode 14, val func loss 0.18861526250839233\n",
      "\n",
      "episode 15, val func loss 0.19282324612140656\n",
      "\n",
      "episode 16, val func loss 0.18432170152664185\n",
      "\n",
      "Val func train loss in epoch 13:0.1921812416985631\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.22390641272068024\n",
      "\n",
      "episode 2, val func loss 0.22058534622192383\n",
      "\n",
      "episode 3, val func loss 0.19389066100120544\n",
      "\n",
      "episode 4, val func loss 0.17901717126369476\n",
      "\n",
      "episode 5, val func loss 0.20080280303955078\n",
      "\n",
      "episode 6, val func loss 0.19989793002605438\n",
      "\n",
      "episode 7, val func loss 0.188057079911232\n",
      "\n",
      "episode 8, val func loss 0.21807223558425903\n",
      "\n",
      "episode 9, val func loss 0.1648925244808197\n",
      "\n",
      "episode 10, val func loss 0.18388831615447998\n",
      "\n",
      "episode 11, val func loss 0.2021160125732422\n",
      "\n",
      "episode 12, val func loss 0.15768852829933167\n",
      "\n",
      "episode 13, val func loss 0.15808500349521637\n",
      "\n",
      "episode 14, val func loss 0.19306805729866028\n",
      "\n",
      "episode 15, val func loss 0.19547401368618011\n",
      "\n",
      "episode 16, val func loss 0.20530912280082703\n",
      "\n",
      "Val func train loss in epoch 14:0.19279695115983486\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.224991574883461\n",
      "\n",
      "episode 2, val func loss 0.15335626900196075\n",
      "\n",
      "episode 3, val func loss 0.20975899696350098\n",
      "\n",
      "episode 4, val func loss 0.2015468329191208\n",
      "\n",
      "episode 5, val func loss 0.18406237661838531\n",
      "\n",
      "episode 6, val func loss 0.19885624945163727\n",
      "\n",
      "episode 7, val func loss 0.1645050197839737\n",
      "\n",
      "episode 8, val func loss 0.19259357452392578\n",
      "\n",
      "episode 9, val func loss 0.22073087096214294\n",
      "\n",
      "episode 10, val func loss 0.1782379448413849\n",
      "\n",
      "episode 11, val func loss 0.16227714717388153\n",
      "\n",
      "episode 12, val func loss 0.19181185960769653\n",
      "\n",
      "episode 13, val func loss 0.1850154995918274\n",
      "\n",
      "episode 14, val func loss 0.2237573266029358\n",
      "\n",
      "episode 15, val func loss 0.20386426150798798\n",
      "\n",
      "episode 16, val func loss 0.19598928093910217\n",
      "\n",
      "Val func train loss in epoch 15:0.1932096928358078\n",
      "***********************TIME WAS 5.001877216498057 min*****************************\n",
      "\n",
      "**********************ROUND 120 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.02861228585243225\n",
      "\n",
      "episode 2, policy loss -0.00656096450984478\n",
      "\n",
      "episode 3, policy loss -0.06604227423667908\n",
      "\n",
      "episode 4, policy loss -0.02187166176736355\n",
      "\n",
      "episode 5, policy loss -0.0072091119363904\n",
      "\n",
      "episode 6, policy loss -0.04402966797351837\n",
      "\n",
      "episode 7, policy loss -0.10203411430120468\n",
      "\n",
      "episode 8, policy loss -0.060664910823106766\n",
      "\n",
      "episode 9, policy loss -0.04467238113284111\n",
      "\n",
      "episode 10, policy loss -0.031329888850450516\n",
      "\n",
      "episode 11, policy loss -0.07826410979032516\n",
      "\n",
      "episode 12, policy loss -0.08089838176965714\n",
      "\n",
      "episode 13, policy loss -0.03831793740391731\n",
      "\n",
      "episode 14, policy loss -0.019549880176782608\n",
      "\n",
      "episode 15, policy loss -0.010830054059624672\n",
      "\n",
      "episode 16, policy loss -0.053354837000370026\n",
      "\n",
      "Policy train loss in epoch 0:-0.043390153849031776\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.00923815369606018\n",
      "\n",
      "episode 2, policy loss -0.10341964662075043\n",
      "\n",
      "episode 3, policy loss -0.04651521518826485\n",
      "\n",
      "episode 4, policy loss -0.043587930500507355\n",
      "\n",
      "episode 5, policy loss -0.0742405503988266\n",
      "\n",
      "episode 6, policy loss -0.010327224619686604\n",
      "\n",
      "episode 7, policy loss -0.015175837092101574\n",
      "\n",
      "episode 8, policy loss -0.045994218438863754\n",
      "\n",
      "episode 9, policy loss -0.02230307087302208\n",
      "\n",
      "episode 10, policy loss -0.03300074487924576\n",
      "\n",
      "episode 11, policy loss -0.08352403342723846\n",
      "\n",
      "episode 12, policy loss -0.054231271147727966\n",
      "\n",
      "episode 13, policy loss -0.02892281860113144\n",
      "\n",
      "episode 14, policy loss -0.06277094781398773\n",
      "\n",
      "episode 15, policy loss -0.039050742983818054\n",
      "\n",
      "episode 16, policy loss -0.08604064583778381\n",
      "\n",
      "Policy train loss in epoch 1:-0.04739644075743854\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.10549160093069077\n",
      "\n",
      "episode 2, policy loss -0.04701578617095947\n",
      "\n",
      "episode 3, policy loss -0.06278613954782486\n",
      "\n",
      "episode 4, policy loss -0.02273442968726158\n",
      "\n",
      "episode 5, policy loss -0.04013112932443619\n",
      "\n",
      "episode 6, policy loss -0.0834178552031517\n",
      "\n",
      "episode 7, policy loss -0.034800153225660324\n",
      "\n",
      "episode 8, policy loss -0.012138386256992817\n",
      "\n",
      "episode 9, policy loss -0.07599855959415436\n",
      "\n",
      "episode 10, policy loss -0.04762518033385277\n",
      "\n",
      "episode 11, policy loss -0.053910303860902786\n",
      "\n",
      "episode 12, policy loss -0.029075339436531067\n",
      "\n",
      "episode 13, policy loss -0.08584959805011749\n",
      "\n",
      "episode 14, policy loss -0.009461918845772743\n",
      "\n",
      "episode 15, policy loss -0.016553733497858047\n",
      "\n",
      "episode 16, policy loss -0.04337252676486969\n",
      "\n",
      "Policy train loss in epoch 2:-0.04814766504568979\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.016667630523443222\n",
      "\n",
      "episode 2, policy loss -0.03424472734332085\n",
      "\n",
      "episode 3, policy loss -0.04835795983672142\n",
      "\n",
      "episode 4, policy loss -0.046887822449207306\n",
      "\n",
      "episode 5, policy loss -0.07553683966398239\n",
      "\n",
      "episode 6, policy loss -0.06350365281105042\n",
      "\n",
      "episode 7, policy loss -0.009562227874994278\n",
      "\n",
      "episode 8, policy loss -0.10558445751667023\n",
      "\n",
      "episode 9, policy loss -0.08322147279977798\n",
      "\n",
      "episode 10, policy loss -0.029193442314863205\n",
      "\n",
      "episode 11, policy loss -0.04020725563168526\n",
      "\n",
      "episode 12, policy loss -0.05425538867712021\n",
      "\n",
      "episode 13, policy loss -0.043877556920051575\n",
      "\n",
      "episode 14, policy loss -0.08551102131605148\n",
      "\n",
      "episode 15, policy loss -0.012301439419388771\n",
      "\n",
      "episode 16, policy loss -0.022440725937485695\n",
      "\n",
      "Policy train loss in epoch 3:-0.04820960131473839\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1903754621744156\n",
      "\n",
      "episode 2, val func loss 0.20378534495830536\n",
      "\n",
      "episode 3, val func loss 0.22003310918807983\n",
      "\n",
      "episode 4, val func loss 0.20631210505962372\n",
      "\n",
      "episode 5, val func loss 0.18303871154785156\n",
      "\n",
      "episode 6, val func loss 0.19996193051338196\n",
      "\n",
      "episode 7, val func loss 0.18693900108337402\n",
      "\n",
      "episode 8, val func loss 0.19649437069892883\n",
      "\n",
      "episode 9, val func loss 0.15679746866226196\n",
      "\n",
      "episode 10, val func loss 0.18166986107826233\n",
      "\n",
      "episode 11, val func loss 0.18182991445064545\n",
      "\n",
      "episode 12, val func loss 0.17469866573810577\n",
      "\n",
      "episode 13, val func loss 0.18702107667922974\n",
      "\n",
      "episode 14, val func loss 0.17112478613853455\n",
      "\n",
      "episode 15, val func loss 0.21354566514492035\n",
      "\n",
      "episode 16, val func loss 0.17110587656497955\n",
      "\n",
      "Val func train loss in epoch 0:0.18904583435505629\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18109023571014404\n",
      "\n",
      "episode 2, val func loss 0.20733074843883514\n",
      "\n",
      "episode 3, val func loss 0.17227765917778015\n",
      "\n",
      "episode 4, val func loss 0.20816996693611145\n",
      "\n",
      "episode 5, val func loss 0.15681596100330353\n",
      "\n",
      "episode 6, val func loss 0.21899321675300598\n",
      "\n",
      "episode 7, val func loss 0.1968679428100586\n",
      "\n",
      "episode 8, val func loss 0.17970767617225647\n",
      "\n",
      "episode 9, val func loss 0.20040011405944824\n",
      "\n",
      "episode 10, val func loss 0.1753227412700653\n",
      "\n",
      "episode 11, val func loss 0.18366087973117828\n",
      "\n",
      "episode 12, val func loss 0.18602682650089264\n",
      "\n",
      "episode 13, val func loss 0.19103141129016876\n",
      "\n",
      "episode 14, val func loss 0.18500718474388123\n",
      "\n",
      "episode 15, val func loss 0.20061169564723969\n",
      "\n",
      "episode 16, val func loss 0.182733952999115\n",
      "\n",
      "Val func train loss in epoch 1:0.18912801332771778\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.15816284716129303\n",
      "\n",
      "episode 2, val func loss 0.19744665920734406\n",
      "\n",
      "episode 3, val func loss 0.20969946682453156\n",
      "\n",
      "episode 4, val func loss 0.18561458587646484\n",
      "\n",
      "episode 5, val func loss 0.2022133767604828\n",
      "\n",
      "episode 6, val func loss 0.17355124652385712\n",
      "\n",
      "episode 7, val func loss 0.182844877243042\n",
      "\n",
      "episode 8, val func loss 0.19138894975185394\n",
      "\n",
      "episode 9, val func loss 0.18177762627601624\n",
      "\n",
      "episode 10, val func loss 0.21929046511650085\n",
      "\n",
      "episode 11, val func loss 0.1862533837556839\n",
      "\n",
      "episode 12, val func loss 0.2066526859998703\n",
      "\n",
      "episode 13, val func loss 0.19955569505691528\n",
      "\n",
      "episode 14, val func loss 0.1820559799671173\n",
      "\n",
      "episode 15, val func loss 0.17189642786979675\n",
      "\n",
      "episode 16, val func loss 0.17504626512527466\n",
      "\n",
      "Val func train loss in epoch 2:0.1889656586572528\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.21075543761253357\n",
      "\n",
      "episode 2, val func loss 0.1575218141078949\n",
      "\n",
      "episode 3, val func loss 0.181458979845047\n",
      "\n",
      "episode 4, val func loss 0.18166567385196686\n",
      "\n",
      "episode 5, val func loss 0.2205750197172165\n",
      "\n",
      "episode 6, val func loss 0.17188023030757904\n",
      "\n",
      "episode 7, val func loss 0.2068774253129959\n",
      "\n",
      "episode 8, val func loss 0.19117581844329834\n",
      "\n",
      "episode 9, val func loss 0.1962234228849411\n",
      "\n",
      "episode 10, val func loss 0.17649617791175842\n",
      "\n",
      "episode 11, val func loss 0.2023153305053711\n",
      "\n",
      "episode 12, val func loss 0.1865263432264328\n",
      "\n",
      "episode 13, val func loss 0.1733684241771698\n",
      "\n",
      "episode 14, val func loss 0.1812203824520111\n",
      "\n",
      "episode 15, val func loss 0.1856166422367096\n",
      "\n",
      "episode 16, val func loss 0.1995747685432434\n",
      "\n",
      "Val func train loss in epoch 3:0.1889532431960106\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19068925082683563\n",
      "\n",
      "episode 2, val func loss 0.20565491914749146\n",
      "\n",
      "episode 3, val func loss 0.19928818941116333\n",
      "\n",
      "episode 4, val func loss 0.1858275830745697\n",
      "\n",
      "episode 5, val func loss 0.1861264705657959\n",
      "\n",
      "episode 6, val func loss 0.1753627508878708\n",
      "\n",
      "episode 7, val func loss 0.20707575976848602\n",
      "\n",
      "episode 8, val func loss 0.209159255027771\n",
      "\n",
      "episode 9, val func loss 0.1967189460992813\n",
      "\n",
      "episode 10, val func loss 0.15705478191375732\n",
      "\n",
      "episode 11, val func loss 0.21830466389656067\n",
      "\n",
      "episode 12, val func loss 0.18218186497688293\n",
      "\n",
      "episode 13, val func loss 0.1834481656551361\n",
      "\n",
      "episode 14, val func loss 0.17332912981510162\n",
      "\n",
      "episode 15, val func loss 0.18243254721164703\n",
      "\n",
      "episode 16, val func loss 0.17282333970069885\n",
      "\n",
      "Val func train loss in epoch 4:0.1890923511236906\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.15695780515670776\n",
      "\n",
      "episode 2, val func loss 0.18112102150917053\n",
      "\n",
      "episode 3, val func loss 0.18651610612869263\n",
      "\n",
      "episode 4, val func loss 0.1819828748703003\n",
      "\n",
      "episode 5, val func loss 0.20622676610946655\n",
      "\n",
      "episode 6, val func loss 0.1739180088043213\n",
      "\n",
      "episode 7, val func loss 0.17161470651626587\n",
      "\n",
      "episode 8, val func loss 0.1854308396577835\n",
      "\n",
      "episode 9, val func loss 0.17094799876213074\n",
      "\n",
      "episode 10, val func loss 0.22050662338733673\n",
      "\n",
      "episode 11, val func loss 0.19075354933738708\n",
      "\n",
      "episode 12, val func loss 0.19891344010829926\n",
      "\n",
      "episode 13, val func loss 0.2046862095594406\n",
      "\n",
      "episode 14, val func loss 0.18280711770057678\n",
      "\n",
      "episode 15, val func loss 0.20578588545322418\n",
      "\n",
      "episode 16, val func loss 0.1975538730621338\n",
      "\n",
      "Val func train loss in epoch 5:0.18848267663270235\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.2074972242116928\n",
      "\n",
      "episode 2, val func loss 0.1856798529624939\n",
      "\n",
      "episode 3, val func loss 0.1932811588048935\n",
      "\n",
      "episode 4, val func loss 0.18160144984722137\n",
      "\n",
      "episode 5, val func loss 0.17168943583965302\n",
      "\n",
      "episode 6, val func loss 0.18122607469558716\n",
      "\n",
      "episode 7, val func loss 0.20988059043884277\n",
      "\n",
      "episode 8, val func loss 0.15664148330688477\n",
      "\n",
      "episode 9, val func loss 0.22323890030384064\n",
      "\n",
      "episode 10, val func loss 0.19683663547039032\n",
      "\n",
      "episode 11, val func loss 0.1816844791173935\n",
      "\n",
      "episode 12, val func loss 0.17541947960853577\n",
      "\n",
      "episode 13, val func loss 0.17185045778751373\n",
      "\n",
      "episode 14, val func loss 0.19949647784233093\n",
      "\n",
      "episode 15, val func loss 0.20229709148406982\n",
      "\n",
      "episode 16, val func loss 0.1862950176000595\n",
      "\n",
      "Val func train loss in epoch 6:0.18903848808258772\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17512431740760803\n",
      "\n",
      "episode 2, val func loss 0.18135026097297668\n",
      "\n",
      "episode 3, val func loss 0.15741606056690216\n",
      "\n",
      "episode 4, val func loss 0.1835104525089264\n",
      "\n",
      "episode 5, val func loss 0.18131335079669952\n",
      "\n",
      "episode 6, val func loss 0.2210923135280609\n",
      "\n",
      "episode 7, val func loss 0.1993529051542282\n",
      "\n",
      "episode 8, val func loss 0.1803167164325714\n",
      "\n",
      "episode 9, val func loss 0.20751720666885376\n",
      "\n",
      "episode 10, val func loss 0.20674613118171692\n",
      "\n",
      "episode 11, val func loss 0.20739708840847015\n",
      "\n",
      "episode 12, val func loss 0.18983569741249084\n",
      "\n",
      "episode 13, val func loss 0.1977081298828125\n",
      "\n",
      "episode 14, val func loss 0.1750289350748062\n",
      "\n",
      "episode 15, val func loss 0.17235706746578217\n",
      "\n",
      "episode 16, val func loss 0.19062723219394684\n",
      "\n",
      "Val func train loss in epoch 7:0.1891683666035533\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17055676877498627\n",
      "\n",
      "episode 2, val func loss 0.17092975974082947\n",
      "\n",
      "episode 3, val func loss 0.20045512914657593\n",
      "\n",
      "episode 4, val func loss 0.19182893633842468\n",
      "\n",
      "episode 5, val func loss 0.1826934814453125\n",
      "\n",
      "episode 6, val func loss 0.1816003918647766\n",
      "\n",
      "episode 7, val func loss 0.1864141821861267\n",
      "\n",
      "episode 8, val func loss 0.17522169649600983\n",
      "\n",
      "episode 9, val func loss 0.18518567085266113\n",
      "\n",
      "episode 10, val func loss 0.20688225328922272\n",
      "\n",
      "episode 11, val func loss 0.19666384160518646\n",
      "\n",
      "episode 12, val func loss 0.20882096886634827\n",
      "\n",
      "episode 13, val func loss 0.2174932211637497\n",
      "\n",
      "episode 14, val func loss 0.2000965029001236\n",
      "\n",
      "episode 15, val func loss 0.19172242283821106\n",
      "\n",
      "episode 16, val func loss 0.15792331099510193\n",
      "\n",
      "Val func train loss in epoch 8:0.18903053365647793\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20208287239074707\n",
      "\n",
      "episode 2, val func loss 0.19985805451869965\n",
      "\n",
      "episode 3, val func loss 0.1738199144601822\n",
      "\n",
      "episode 4, val func loss 0.17226728796958923\n",
      "\n",
      "episode 5, val func loss 0.1740604043006897\n",
      "\n",
      "episode 6, val func loss 0.18176203966140747\n",
      "\n",
      "episode 7, val func loss 0.21274028718471527\n",
      "\n",
      "episode 8, val func loss 0.19030295312404633\n",
      "\n",
      "episode 9, val func loss 0.18208536505699158\n",
      "\n",
      "episode 10, val func loss 0.15705779194831848\n",
      "\n",
      "episode 11, val func loss 0.22039930522441864\n",
      "\n",
      "episode 12, val func loss 0.20533332228660583\n",
      "\n",
      "episode 13, val func loss 0.18684354424476624\n",
      "\n",
      "episode 14, val func loss 0.18657462298870087\n",
      "\n",
      "episode 15, val func loss 0.1872185915708542\n",
      "\n",
      "episode 16, val func loss 0.19694644212722778\n",
      "\n",
      "Val func train loss in epoch 9:0.18933454994112253\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.2027912735939026\n",
      "\n",
      "episode 2, val func loss 0.19670230150222778\n",
      "\n",
      "episode 3, val func loss 0.18439020216464996\n",
      "\n",
      "episode 4, val func loss 0.18580006062984467\n",
      "\n",
      "episode 5, val func loss 0.20675931870937347\n",
      "\n",
      "episode 6, val func loss 0.15735377371311188\n",
      "\n",
      "episode 7, val func loss 0.2086099237203598\n",
      "\n",
      "episode 8, val func loss 0.19005568325519562\n",
      "\n",
      "episode 9, val func loss 0.18161708116531372\n",
      "\n",
      "episode 10, val func loss 0.1742268204689026\n",
      "\n",
      "episode 11, val func loss 0.17105881869792938\n",
      "\n",
      "episode 12, val func loss 0.17177005112171173\n",
      "\n",
      "episode 13, val func loss 0.20045773684978485\n",
      "\n",
      "episode 14, val func loss 0.21991783380508423\n",
      "\n",
      "episode 15, val func loss 0.18078356981277466\n",
      "\n",
      "episode 16, val func loss 0.18549785017967224\n",
      "\n",
      "Val func train loss in epoch 10:0.18861201871186495\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.17043684422969818\n",
      "\n",
      "episode 2, val func loss 0.15684780478477478\n",
      "\n",
      "episode 3, val func loss 0.18131700158119202\n",
      "\n",
      "episode 4, val func loss 0.2087288796901703\n",
      "\n",
      "episode 5, val func loss 0.17383691668510437\n",
      "\n",
      "episode 6, val func loss 0.20721286535263062\n",
      "\n",
      "episode 7, val func loss 0.20172028243541718\n",
      "\n",
      "episode 8, val func loss 0.19776728749275208\n",
      "\n",
      "episode 9, val func loss 0.19743749499320984\n",
      "\n",
      "episode 10, val func loss 0.174025297164917\n",
      "\n",
      "episode 11, val func loss 0.18800857663154602\n",
      "\n",
      "episode 12, val func loss 0.18875575065612793\n",
      "\n",
      "episode 13, val func loss 0.18277035653591156\n",
      "\n",
      "episode 14, val func loss 0.18299207091331482\n",
      "\n",
      "episode 15, val func loss 0.18818411231040955\n",
      "\n",
      "episode 16, val func loss 0.22159838676452637\n",
      "\n",
      "Val func train loss in epoch 11:0.1888524955138564\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1701076328754425\n",
      "\n",
      "episode 2, val func loss 0.1824204921722412\n",
      "\n",
      "episode 3, val func loss 0.19446896016597748\n",
      "\n",
      "episode 4, val func loss 0.19201353192329407\n",
      "\n",
      "episode 5, val func loss 0.20287680625915527\n",
      "\n",
      "episode 6, val func loss 0.20573434233665466\n",
      "\n",
      "episode 7, val func loss 0.1749139130115509\n",
      "\n",
      "episode 8, val func loss 0.21889829635620117\n",
      "\n",
      "episode 9, val func loss 0.17720475792884827\n",
      "\n",
      "episode 10, val func loss 0.1997258961200714\n",
      "\n",
      "episode 11, val func loss 0.18573373556137085\n",
      "\n",
      "episode 12, val func loss 0.1811104714870453\n",
      "\n",
      "episode 13, val func loss 0.20879219472408295\n",
      "\n",
      "episode 14, val func loss 0.15656104683876038\n",
      "\n",
      "episode 15, val func loss 0.17898505926132202\n",
      "\n",
      "episode 16, val func loss 0.18894274532794952\n",
      "\n",
      "Val func train loss in epoch 12:0.188655617646873\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.17399978637695312\n",
      "\n",
      "episode 2, val func loss 0.19019180536270142\n",
      "\n",
      "episode 3, val func loss 0.18134385347366333\n",
      "\n",
      "episode 4, val func loss 0.21200793981552124\n",
      "\n",
      "episode 5, val func loss 0.21939004957675934\n",
      "\n",
      "episode 6, val func loss 0.20438691973686218\n",
      "\n",
      "episode 7, val func loss 0.17437578737735748\n",
      "\n",
      "episode 8, val func loss 0.19822867214679718\n",
      "\n",
      "episode 9, val func loss 0.18764643371105194\n",
      "\n",
      "episode 10, val func loss 0.18567180633544922\n",
      "\n",
      "episode 11, val func loss 0.1801251918077469\n",
      "\n",
      "episode 12, val func loss 0.19566133618354797\n",
      "\n",
      "episode 13, val func loss 0.18115298449993134\n",
      "\n",
      "episode 14, val func loss 0.15415197610855103\n",
      "\n",
      "episode 15, val func loss 0.20795084536075592\n",
      "\n",
      "episode 16, val func loss 0.16978035867214203\n",
      "\n",
      "Val func train loss in epoch 13:0.18850410915911198\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17534902691841125\n",
      "\n",
      "episode 2, val func loss 0.19580578804016113\n",
      "\n",
      "episode 3, val func loss 0.21248793601989746\n",
      "\n",
      "episode 4, val func loss 0.16856935620307922\n",
      "\n",
      "episode 5, val func loss 0.1846262514591217\n",
      "\n",
      "episode 6, val func loss 0.20577679574489594\n",
      "\n",
      "episode 7, val func loss 0.18555769324302673\n",
      "\n",
      "episode 8, val func loss 0.18360169231891632\n",
      "\n",
      "episode 9, val func loss 0.19957712292671204\n",
      "\n",
      "episode 10, val func loss 0.15439747273921967\n",
      "\n",
      "episode 11, val func loss 0.21958152949810028\n",
      "\n",
      "episode 12, val func loss 0.18537302315235138\n",
      "\n",
      "episode 13, val func loss 0.1715875267982483\n",
      "\n",
      "episode 14, val func loss 0.18171489238739014\n",
      "\n",
      "episode 15, val func loss 0.1921321451663971\n",
      "\n",
      "episode 16, val func loss 0.20430219173431396\n",
      "\n",
      "Val func train loss in epoch 14:0.18877752777189016\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18636998534202576\n",
      "\n",
      "episode 2, val func loss 0.19691024720668793\n",
      "\n",
      "episode 3, val func loss 0.1752895712852478\n",
      "\n",
      "episode 4, val func loss 0.18234802782535553\n",
      "\n",
      "episode 5, val func loss 0.1815088540315628\n",
      "\n",
      "episode 6, val func loss 0.18585707247257233\n",
      "\n",
      "episode 7, val func loss 0.21003499627113342\n",
      "\n",
      "episode 8, val func loss 0.20728248357772827\n",
      "\n",
      "episode 9, val func loss 0.19967256486415863\n",
      "\n",
      "episode 10, val func loss 0.17257913947105408\n",
      "\n",
      "episode 11, val func loss 0.22003547847270966\n",
      "\n",
      "episode 12, val func loss 0.20215176045894623\n",
      "\n",
      "episode 13, val func loss 0.1563854217529297\n",
      "\n",
      "episode 14, val func loss 0.17335928976535797\n",
      "\n",
      "episode 15, val func loss 0.19233030080795288\n",
      "\n",
      "episode 16, val func loss 0.18344475328922272\n",
      "\n",
      "Val func train loss in epoch 15:0.18909749668091536\n",
      "***********************TIME WAS 5.002493651707967 min*****************************\n",
      "\n",
      "**********************ROUND 121 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.047955259680747986\n",
      "\n",
      "episode 2, policy loss -0.014893066138029099\n",
      "\n",
      "episode 3, policy loss 0.0013274871744215488\n",
      "\n",
      "episode 4, policy loss -0.00691296998411417\n",
      "\n",
      "episode 5, policy loss -0.0040049985982477665\n",
      "\n",
      "episode 6, policy loss -0.019304631277918816\n",
      "\n",
      "episode 7, policy loss -0.032987501472234726\n",
      "\n",
      "episode 8, policy loss -0.021581541746854782\n",
      "\n",
      "episode 9, policy loss -0.041645925492048264\n",
      "\n",
      "episode 10, policy loss 0.0031239776872098446\n",
      "\n",
      "episode 11, policy loss -0.038771163672208786\n",
      "\n",
      "episode 12, policy loss -0.011069826781749725\n",
      "\n",
      "episode 13, policy loss 0.015300572849810123\n",
      "\n",
      "episode 14, policy loss 0.03173873573541641\n",
      "\n",
      "episode 15, policy loss 0.053669530898332596\n",
      "\n",
      "episode 16, policy loss -0.01623642072081566\n",
      "\n",
      "Policy train loss in epoch 0:-0.003393280116142705\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.012384830042719841\n",
      "\n",
      "episode 2, policy loss -0.041368164122104645\n",
      "\n",
      "episode 3, policy loss 0.012957485392689705\n",
      "\n",
      "episode 4, policy loss -0.03938949108123779\n",
      "\n",
      "episode 5, policy loss 0.03230183571577072\n",
      "\n",
      "episode 6, policy loss -0.026688024401664734\n",
      "\n",
      "episode 7, policy loss 0.04106036573648453\n",
      "\n",
      "episode 8, policy loss -0.020306628197431564\n",
      "\n",
      "episode 9, policy loss -0.024597492069005966\n",
      "\n",
      "episode 10, policy loss 0.05269545316696167\n",
      "\n",
      "episode 11, policy loss -0.01645047403872013\n",
      "\n",
      "episode 12, policy loss -0.011212577112019062\n",
      "\n",
      "episode 13, policy loss 0.0003208957496099174\n",
      "\n",
      "episode 14, policy loss -0.005235538352280855\n",
      "\n",
      "episode 15, policy loss -0.017497273162007332\n",
      "\n",
      "episode 16, policy loss -0.03330177441239357\n",
      "\n",
      "Policy train loss in epoch 1:-0.0068185144518793095\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.04277066886425018\n",
      "\n",
      "episode 2, policy loss -0.04129072651267052\n",
      "\n",
      "episode 3, policy loss -0.027288630604743958\n",
      "\n",
      "episode 4, policy loss -0.026008496060967445\n",
      "\n",
      "episode 5, policy loss -0.019906464964151382\n",
      "\n",
      "episode 6, policy loss -0.0053084674291312695\n",
      "\n",
      "episode 7, policy loss -0.013040781021118164\n",
      "\n",
      "episode 8, policy loss 0.05090073123574257\n",
      "\n",
      "episode 9, policy loss 0.030281566083431244\n",
      "\n",
      "episode 10, policy loss -0.033686328679323196\n",
      "\n",
      "episode 11, policy loss -0.01119943242520094\n",
      "\n",
      "episode 12, policy loss 0.0009081128519028425\n",
      "\n",
      "episode 13, policy loss -0.01679006963968277\n",
      "\n",
      "episode 14, policy loss -0.01802271418273449\n",
      "\n",
      "episode 15, policy loss 0.011445678770542145\n",
      "\n",
      "episode 16, policy loss 0.04108737036585808\n",
      "\n",
      "Policy train loss in epoch 2:-0.00754308256728109\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.005849583074450493\n",
      "\n",
      "episode 2, policy loss 0.050724878907203674\n",
      "\n",
      "episode 3, policy loss -0.0253819040954113\n",
      "\n",
      "episode 4, policy loss 0.012357134371995926\n",
      "\n",
      "episode 5, policy loss -0.04345722496509552\n",
      "\n",
      "episode 6, policy loss -0.01741848699748516\n",
      "\n",
      "episode 7, policy loss -0.017861977219581604\n",
      "\n",
      "episode 8, policy loss 0.030180158093571663\n",
      "\n",
      "episode 9, policy loss -0.03423677012324333\n",
      "\n",
      "episode 10, policy loss -0.042357008904218674\n",
      "\n",
      "episode 11, policy loss -0.011793273501098156\n",
      "\n",
      "episode 12, policy loss 0.0005843776743859053\n",
      "\n",
      "episode 13, policy loss -0.01426077913492918\n",
      "\n",
      "episode 14, policy loss 0.04076734930276871\n",
      "\n",
      "episode 15, policy loss -0.02740274742245674\n",
      "\n",
      "episode 16, policy loss -0.021470122039318085\n",
      "\n",
      "Policy train loss in epoch 3:-0.007929748695460148\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.21347416937351227\n",
      "\n",
      "episode 2, val func loss 0.16155989468097687\n",
      "\n",
      "episode 3, val func loss 0.2074325680732727\n",
      "\n",
      "episode 4, val func loss 0.16719374060630798\n",
      "\n",
      "episode 5, val func loss 0.18324537575244904\n",
      "\n",
      "episode 6, val func loss 0.19610653817653656\n",
      "\n",
      "episode 7, val func loss 0.20486855506896973\n",
      "\n",
      "episode 8, val func loss 0.19616924226284027\n",
      "\n",
      "episode 9, val func loss 0.1701337844133377\n",
      "\n",
      "episode 10, val func loss 0.19294573366641998\n",
      "\n",
      "episode 11, val func loss 0.1667087972164154\n",
      "\n",
      "episode 12, val func loss 0.17925532162189484\n",
      "\n",
      "episode 13, val func loss 0.184457466006279\n",
      "\n",
      "episode 14, val func loss 0.16117188334465027\n",
      "\n",
      "episode 15, val func loss 0.20469480752944946\n",
      "\n",
      "episode 16, val func loss 0.18310381472110748\n",
      "\n",
      "Val func train loss in epoch 0:0.18578260578215122\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19505664706230164\n",
      "\n",
      "episode 2, val func loss 0.17958413064479828\n",
      "\n",
      "episode 3, val func loss 0.18203675746917725\n",
      "\n",
      "episode 4, val func loss 0.16018208861351013\n",
      "\n",
      "episode 5, val func loss 0.2042628675699234\n",
      "\n",
      "episode 6, val func loss 0.19711630046367645\n",
      "\n",
      "episode 7, val func loss 0.16128353774547577\n",
      "\n",
      "episode 8, val func loss 0.20305107533931732\n",
      "\n",
      "episode 9, val func loss 0.16714948415756226\n",
      "\n",
      "episode 10, val func loss 0.1833260953426361\n",
      "\n",
      "episode 11, val func loss 0.1706109642982483\n",
      "\n",
      "episode 12, val func loss 0.21355687081813812\n",
      "\n",
      "episode 13, val func loss 0.19318664073944092\n",
      "\n",
      "episode 14, val func loss 0.18476486206054688\n",
      "\n",
      "episode 15, val func loss 0.20758754014968872\n",
      "\n",
      "episode 16, val func loss 0.16709116101264954\n",
      "\n",
      "Val func train loss in epoch 1:0.1856154389679432\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19248828291893005\n",
      "\n",
      "episode 2, val func loss 0.16060255467891693\n",
      "\n",
      "episode 3, val func loss 0.1956758052110672\n",
      "\n",
      "episode 4, val func loss 0.18209460377693176\n",
      "\n",
      "episode 5, val func loss 0.1671208143234253\n",
      "\n",
      "episode 6, val func loss 0.16685539484024048\n",
      "\n",
      "episode 7, val func loss 0.20715458691120148\n",
      "\n",
      "episode 8, val func loss 0.1954972892999649\n",
      "\n",
      "episode 9, val func loss 0.1611930876970291\n",
      "\n",
      "episode 10, val func loss 0.2043871432542801\n",
      "\n",
      "episode 11, val func loss 0.20375336706638336\n",
      "\n",
      "episode 12, val func loss 0.1832420378923416\n",
      "\n",
      "episode 13, val func loss 0.21272113919258118\n",
      "\n",
      "episode 14, val func loss 0.17869986593723297\n",
      "\n",
      "episode 15, val func loss 0.1851043552160263\n",
      "\n",
      "episode 16, val func loss 0.17054979503154755\n",
      "\n",
      "Val func train loss in epoch 2:0.18544625770300627\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.16205807030200958\n",
      "\n",
      "episode 2, val func loss 0.2068558782339096\n",
      "\n",
      "episode 3, val func loss 0.1976180374622345\n",
      "\n",
      "episode 4, val func loss 0.16779401898384094\n",
      "\n",
      "episode 5, val func loss 0.1839938759803772\n",
      "\n",
      "episode 6, val func loss 0.2135702669620514\n",
      "\n",
      "episode 7, val func loss 0.17918449640274048\n",
      "\n",
      "episode 8, val func loss 0.18407568335533142\n",
      "\n",
      "episode 9, val func loss 0.16738669574260712\n",
      "\n",
      "episode 10, val func loss 0.16975030303001404\n",
      "\n",
      "episode 11, val func loss 0.1942881941795349\n",
      "\n",
      "episode 12, val func loss 0.18017147481441498\n",
      "\n",
      "episode 13, val func loss 0.19279387593269348\n",
      "\n",
      "episode 14, val func loss 0.204059898853302\n",
      "\n",
      "episode 15, val func loss 0.1611032783985138\n",
      "\n",
      "episode 16, val func loss 0.2036808282136917\n",
      "\n",
      "Val func train loss in epoch 3:0.1855240548029542\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19506828486919403\n",
      "\n",
      "episode 2, val func loss 0.18403814733028412\n",
      "\n",
      "episode 3, val func loss 0.20772328972816467\n",
      "\n",
      "episode 4, val func loss 0.2048175036907196\n",
      "\n",
      "episode 5, val func loss 0.19348402321338654\n",
      "\n",
      "episode 6, val func loss 0.16154764592647552\n",
      "\n",
      "episode 7, val func loss 0.20281153917312622\n",
      "\n",
      "episode 8, val func loss 0.17955756187438965\n",
      "\n",
      "episode 9, val func loss 0.180719792842865\n",
      "\n",
      "episode 10, val func loss 0.1738826036453247\n",
      "\n",
      "episode 11, val func loss 0.19545115530490875\n",
      "\n",
      "episode 12, val func loss 0.1628437638282776\n",
      "\n",
      "episode 13, val func loss 0.18163257837295532\n",
      "\n",
      "episode 14, val func loss 0.16657303273677826\n",
      "\n",
      "episode 15, val func loss 0.16917619109153748\n",
      "\n",
      "episode 16, val func loss 0.21175189316272736\n",
      "\n",
      "Val func train loss in epoch 4:0.18569243792444468\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.16248168051242828\n",
      "\n",
      "episode 2, val func loss 0.20396825671195984\n",
      "\n",
      "episode 3, val func loss 0.21336369216442108\n",
      "\n",
      "episode 4, val func loss 0.18235841393470764\n",
      "\n",
      "episode 5, val func loss 0.17856638133525848\n",
      "\n",
      "episode 6, val func loss 0.18323247134685516\n",
      "\n",
      "episode 7, val func loss 0.19480843842029572\n",
      "\n",
      "episode 8, val func loss 0.16131319105625153\n",
      "\n",
      "episode 9, val func loss 0.17037919163703918\n",
      "\n",
      "episode 10, val func loss 0.1667819619178772\n",
      "\n",
      "episode 11, val func loss 0.16752780973911285\n",
      "\n",
      "episode 12, val func loss 0.20686329901218414\n",
      "\n",
      "episode 13, val func loss 0.1959121823310852\n",
      "\n",
      "episode 14, val func loss 0.1817072182893753\n",
      "\n",
      "episode 15, val func loss 0.20494374632835388\n",
      "\n",
      "episode 16, val func loss 0.1948254257440567\n",
      "\n",
      "Val func train loss in epoch 5:0.1855645850300789\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1655581295490265\n",
      "\n",
      "episode 2, val func loss 0.20348139107227325\n",
      "\n",
      "episode 3, val func loss 0.2117483764886856\n",
      "\n",
      "episode 4, val func loss 0.1641937792301178\n",
      "\n",
      "episode 5, val func loss 0.18090176582336426\n",
      "\n",
      "episode 6, val func loss 0.1937132328748703\n",
      "\n",
      "episode 7, val func loss 0.20634055137634277\n",
      "\n",
      "episode 8, val func loss 0.17137570679187775\n",
      "\n",
      "episode 9, val func loss 0.18352088332176208\n",
      "\n",
      "episode 10, val func loss 0.16056448221206665\n",
      "\n",
      "episode 11, val func loss 0.19481129944324493\n",
      "\n",
      "episode 12, val func loss 0.17716582119464874\n",
      "\n",
      "episode 13, val func loss 0.18307644128799438\n",
      "\n",
      "episode 14, val func loss 0.2053898423910141\n",
      "\n",
      "episode 15, val func loss 0.19524890184402466\n",
      "\n",
      "episode 16, val func loss 0.1670912206172943\n",
      "\n",
      "Val func train loss in epoch 6:0.185261364094913\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.20686641335487366\n",
      "\n",
      "episode 2, val func loss 0.19184480607509613\n",
      "\n",
      "episode 3, val func loss 0.17328286170959473\n",
      "\n",
      "episode 4, val func loss 0.1771678775548935\n",
      "\n",
      "episode 5, val func loss 0.20589886605739594\n",
      "\n",
      "episode 6, val func loss 0.16391780972480774\n",
      "\n",
      "episode 7, val func loss 0.1685868352651596\n",
      "\n",
      "episode 8, val func loss 0.19549560546875\n",
      "\n",
      "episode 9, val func loss 0.19440484046936035\n",
      "\n",
      "episode 10, val func loss 0.18080343306064606\n",
      "\n",
      "episode 11, val func loss 0.18393363058567047\n",
      "\n",
      "episode 12, val func loss 0.1865161806344986\n",
      "\n",
      "episode 13, val func loss 0.21585321426391602\n",
      "\n",
      "episode 14, val func loss 0.16177880764007568\n",
      "\n",
      "episode 15, val func loss 0.1599496304988861\n",
      "\n",
      "episode 16, val func loss 0.20424291491508484\n",
      "\n",
      "Val func train loss in epoch 7:0.18565898295491934\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.20670117437839508\n",
      "\n",
      "episode 2, val func loss 0.17936080694198608\n",
      "\n",
      "episode 3, val func loss 0.16795992851257324\n",
      "\n",
      "episode 4, val func loss 0.18381895124912262\n",
      "\n",
      "episode 5, val func loss 0.2024490088224411\n",
      "\n",
      "episode 6, val func loss 0.1671716421842575\n",
      "\n",
      "episode 7, val func loss 0.18330006301403046\n",
      "\n",
      "episode 8, val func loss 0.19430409371852875\n",
      "\n",
      "episode 9, val func loss 0.1625487357378006\n",
      "\n",
      "episode 10, val func loss 0.16996601223945618\n",
      "\n",
      "episode 11, val func loss 0.20810739696025848\n",
      "\n",
      "episode 12, val func loss 0.18128050863742828\n",
      "\n",
      "episode 13, val func loss 0.16169457137584686\n",
      "\n",
      "episode 14, val func loss 0.19429682195186615\n",
      "\n",
      "episode 15, val func loss 0.19773650169372559\n",
      "\n",
      "episode 16, val func loss 0.20432735979557037\n",
      "\n",
      "Val func train loss in epoch 8:0.18531397357583046\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20574814081192017\n",
      "\n",
      "episode 2, val func loss 0.19537343084812164\n",
      "\n",
      "episode 3, val func loss 0.16587814688682556\n",
      "\n",
      "episode 4, val func loss 0.19326886534690857\n",
      "\n",
      "episode 5, val func loss 0.1805974692106247\n",
      "\n",
      "episode 6, val func loss 0.1659349799156189\n",
      "\n",
      "episode 7, val func loss 0.16954830288887024\n",
      "\n",
      "episode 8, val func loss 0.20596152544021606\n",
      "\n",
      "episode 9, val func loss 0.18419237434864044\n",
      "\n",
      "episode 10, val func loss 0.16909193992614746\n",
      "\n",
      "episode 11, val func loss 0.20429933071136475\n",
      "\n",
      "episode 12, val func loss 0.18227174878120422\n",
      "\n",
      "episode 13, val func loss 0.15758773684501648\n",
      "\n",
      "episode 14, val func loss 0.19582557678222656\n",
      "\n",
      "episode 15, val func loss 0.21584270894527435\n",
      "\n",
      "episode 16, val func loss 0.18160001933574677\n",
      "\n",
      "Val func train loss in epoch 9:0.18581389356404543\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.15997052192687988\n",
      "\n",
      "episode 2, val func loss 0.21430225670337677\n",
      "\n",
      "episode 3, val func loss 0.15811343491077423\n",
      "\n",
      "episode 4, val func loss 0.1679195761680603\n",
      "\n",
      "episode 5, val func loss 0.19568412005901337\n",
      "\n",
      "episode 6, val func loss 0.1805136799812317\n",
      "\n",
      "episode 7, val func loss 0.19350887835025787\n",
      "\n",
      "episode 8, val func loss 0.18206292390823364\n",
      "\n",
      "episode 9, val func loss 0.18432992696762085\n",
      "\n",
      "episode 10, val func loss 0.1715797334909439\n",
      "\n",
      "episode 11, val func loss 0.20626860857009888\n",
      "\n",
      "episode 12, val func loss 0.20422816276550293\n",
      "\n",
      "episode 13, val func loss 0.19434382021427155\n",
      "\n",
      "episode 14, val func loss 0.20542369782924652\n",
      "\n",
      "episode 15, val func loss 0.16721971333026886\n",
      "\n",
      "episode 16, val func loss 0.18322518467903137\n",
      "\n",
      "Val func train loss in epoch 10:0.1855433899909258\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.160325288772583\n",
      "\n",
      "episode 2, val func loss 0.20418663322925568\n",
      "\n",
      "episode 3, val func loss 0.16849489510059357\n",
      "\n",
      "episode 4, val func loss 0.18324653804302216\n",
      "\n",
      "episode 5, val func loss 0.1595354974269867\n",
      "\n",
      "episode 6, val func loss 0.18509896099567413\n",
      "\n",
      "episode 7, val func loss 0.19700510799884796\n",
      "\n",
      "episode 8, val func loss 0.1935739517211914\n",
      "\n",
      "episode 9, val func loss 0.20840081572532654\n",
      "\n",
      "episode 10, val func loss 0.17872354388237\n",
      "\n",
      "episode 11, val func loss 0.2114734649658203\n",
      "\n",
      "episode 12, val func loss 0.18319573998451233\n",
      "\n",
      "episode 13, val func loss 0.1697346717119217\n",
      "\n",
      "episode 14, val func loss 0.19476045668125153\n",
      "\n",
      "episode 15, val func loss 0.20322772860527039\n",
      "\n",
      "episode 16, val func loss 0.1727442443370819\n",
      "\n",
      "Val func train loss in epoch 11:0.18585797119885683\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19519221782684326\n",
      "\n",
      "episode 2, val func loss 0.18214134871959686\n",
      "\n",
      "episode 3, val func loss 0.2016083300113678\n",
      "\n",
      "episode 4, val func loss 0.16177642345428467\n",
      "\n",
      "episode 5, val func loss 0.16108490526676178\n",
      "\n",
      "episode 6, val func loss 0.21335001289844513\n",
      "\n",
      "episode 7, val func loss 0.19539494812488556\n",
      "\n",
      "episode 8, val func loss 0.2064189314842224\n",
      "\n",
      "episode 9, val func loss 0.1848295032978058\n",
      "\n",
      "episode 10, val func loss 0.16727517545223236\n",
      "\n",
      "episode 11, val func loss 0.16733390092849731\n",
      "\n",
      "episode 12, val func loss 0.18355639278888702\n",
      "\n",
      "episode 13, val func loss 0.19334043562412262\n",
      "\n",
      "episode 14, val func loss 0.17129245400428772\n",
      "\n",
      "episode 15, val func loss 0.1783311665058136\n",
      "\n",
      "episode 16, val func loss 0.2039855569601059\n",
      "\n",
      "Val func train loss in epoch 12:0.18543198145926\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.21188969910144806\n",
      "\n",
      "episode 2, val func loss 0.19251462817192078\n",
      "\n",
      "episode 3, val func loss 0.16766859591007233\n",
      "\n",
      "episode 4, val func loss 0.2039138227701187\n",
      "\n",
      "episode 5, val func loss 0.16195148229599\n",
      "\n",
      "episode 6, val func loss 0.18051031231880188\n",
      "\n",
      "episode 7, val func loss 0.1646459847688675\n",
      "\n",
      "episode 8, val func loss 0.18515098094940186\n",
      "\n",
      "episode 9, val func loss 0.18356364965438843\n",
      "\n",
      "episode 10, val func loss 0.19713479280471802\n",
      "\n",
      "episode 11, val func loss 0.19655174016952515\n",
      "\n",
      "episode 12, val func loss 0.1621648371219635\n",
      "\n",
      "episode 13, val func loss 0.18285709619522095\n",
      "\n",
      "episode 14, val func loss 0.2065812051296234\n",
      "\n",
      "episode 15, val func loss 0.171257883310318\n",
      "\n",
      "episode 16, val func loss 0.2029224932193756\n",
      "\n",
      "Val func train loss in epoch 13:0.18570495024323463\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.21253246068954468\n",
      "\n",
      "episode 2, val func loss 0.2057688981294632\n",
      "\n",
      "episode 3, val func loss 0.19681930541992188\n",
      "\n",
      "episode 4, val func loss 0.18519073724746704\n",
      "\n",
      "episode 5, val func loss 0.1604858785867691\n",
      "\n",
      "episode 6, val func loss 0.16691981256008148\n",
      "\n",
      "episode 7, val func loss 0.1680924892425537\n",
      "\n",
      "episode 8, val func loss 0.19483575224876404\n",
      "\n",
      "episode 9, val func loss 0.18123431503772736\n",
      "\n",
      "episode 10, val func loss 0.20318332314491272\n",
      "\n",
      "episode 11, val func loss 0.1685009002685547\n",
      "\n",
      "episode 12, val func loss 0.1939394474029541\n",
      "\n",
      "episode 13, val func loss 0.16117899119853973\n",
      "\n",
      "episode 14, val func loss 0.18519826233386993\n",
      "\n",
      "episode 15, val func loss 0.17994965612888336\n",
      "\n",
      "episode 16, val func loss 0.20237047970294952\n",
      "\n",
      "Val func train loss in epoch 14:0.18538754433393478\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.2112264633178711\n",
      "\n",
      "episode 2, val func loss 0.1887797862291336\n",
      "\n",
      "episode 3, val func loss 0.19726666808128357\n",
      "\n",
      "episode 4, val func loss 0.20288901031017303\n",
      "\n",
      "episode 5, val func loss 0.1799807995557785\n",
      "\n",
      "episode 6, val func loss 0.16566921770572662\n",
      "\n",
      "episode 7, val func loss 0.2044455111026764\n",
      "\n",
      "episode 8, val func loss 0.16662496328353882\n",
      "\n",
      "episode 9, val func loss 0.18349862098693848\n",
      "\n",
      "episode 10, val func loss 0.19558149576187134\n",
      "\n",
      "episode 11, val func loss 0.17108412086963654\n",
      "\n",
      "episode 12, val func loss 0.16125623881816864\n",
      "\n",
      "episode 13, val func loss 0.18048095703125\n",
      "\n",
      "episode 14, val func loss 0.208311066031456\n",
      "\n",
      "episode 15, val func loss 0.1587161272764206\n",
      "\n",
      "episode 16, val func loss 0.19883519411087036\n",
      "\n",
      "Val func train loss in epoch 15:0.1859153900295496\n",
      "***********************TIME WAS 5.002386852105459 min*****************************\n",
      "\n",
      "**********************ROUND 122 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.04090185835957527\n",
      "\n",
      "episode 2, policy loss -0.0006297291838563979\n",
      "\n",
      "episode 3, policy loss -0.04663626104593277\n",
      "\n",
      "episode 4, policy loss -0.02217206545174122\n",
      "\n",
      "episode 5, policy loss -0.062107719480991364\n",
      "\n",
      "episode 6, policy loss -0.010512185283005238\n",
      "\n",
      "episode 7, policy loss -0.03997749090194702\n",
      "\n",
      "episode 8, policy loss -0.016703708097338676\n",
      "\n",
      "episode 9, policy loss -0.04134083911776543\n",
      "\n",
      "episode 10, policy loss -0.04448191449046135\n",
      "\n",
      "episode 11, policy loss -0.021629545837640762\n",
      "\n",
      "episode 12, policy loss -0.11420294642448425\n",
      "\n",
      "episode 13, policy loss -0.014319217763841152\n",
      "\n",
      "episode 14, policy loss -0.01514369249343872\n",
      "\n",
      "episode 15, policy loss 0.01238760631531477\n",
      "\n",
      "episode 16, policy loss 0.01587497629225254\n",
      "\n",
      "Policy train loss in epoch 0:-0.02890603695777827\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.03173420578241348\n",
      "\n",
      "episode 2, policy loss -0.051708005368709564\n",
      "\n",
      "episode 3, policy loss -0.04664769023656845\n",
      "\n",
      "episode 4, policy loss -0.017905989661812782\n",
      "\n",
      "episode 5, policy loss -0.04112324118614197\n",
      "\n",
      "episode 6, policy loss -0.004043936263769865\n",
      "\n",
      "episode 7, policy loss -0.023219512775540352\n",
      "\n",
      "episode 8, policy loss -0.0535147488117218\n",
      "\n",
      "episode 9, policy loss -0.04030952975153923\n",
      "\n",
      "episode 10, policy loss -0.017728349193930626\n",
      "\n",
      "episode 11, policy loss -0.015565837733447552\n",
      "\n",
      "episode 12, policy loss -0.012482807971537113\n",
      "\n",
      "episode 13, policy loss -0.11628089845180511\n",
      "\n",
      "episode 14, policy loss -0.07187847793102264\n",
      "\n",
      "episode 15, policy loss 0.008857731707394123\n",
      "\n",
      "episode 16, policy loss 0.012752247974276543\n",
      "\n",
      "Policy train loss in epoch 1:-0.03265832821489312\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.010420603677630424\n",
      "\n",
      "episode 2, policy loss -0.04684219881892204\n",
      "\n",
      "episode 3, policy loss -0.11609476804733276\n",
      "\n",
      "episode 4, policy loss -0.016952309757471085\n",
      "\n",
      "episode 5, policy loss -0.07161775231361389\n",
      "\n",
      "episode 6, policy loss -0.054841477423906326\n",
      "\n",
      "episode 7, policy loss -0.04279129207134247\n",
      "\n",
      "episode 8, policy loss -0.05333484709262848\n",
      "\n",
      "episode 9, policy loss -0.03400842472910881\n",
      "\n",
      "episode 10, policy loss -0.018819795921444893\n",
      "\n",
      "episode 11, policy loss -0.023531712591648102\n",
      "\n",
      "episode 12, policy loss -0.019204284995794296\n",
      "\n",
      "episode 13, policy loss 0.0083623006939888\n",
      "\n",
      "episode 14, policy loss -0.004690820351243019\n",
      "\n",
      "episode 15, policy loss 0.011163600720465183\n",
      "\n",
      "episode 16, policy loss -0.043030694127082825\n",
      "\n",
      "Policy train loss in epoch 2:-0.033540942531544715\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.005252880975604057\n",
      "\n",
      "episode 2, policy loss -0.11561039090156555\n",
      "\n",
      "episode 3, policy loss 0.007967100478708744\n",
      "\n",
      "episode 4, policy loss -0.053473446518182755\n",
      "\n",
      "episode 5, policy loss -0.019403383135795593\n",
      "\n",
      "episode 6, policy loss -0.03498987853527069\n",
      "\n",
      "episode 7, policy loss -0.04272359237074852\n",
      "\n",
      "episode 8, policy loss -0.04803843796253204\n",
      "\n",
      "episode 9, policy loss -0.05482683330774307\n",
      "\n",
      "episode 10, policy loss -0.02410050295293331\n",
      "\n",
      "episode 11, policy loss 0.011088740080595016\n",
      "\n",
      "episode 12, policy loss -0.0185256265103817\n",
      "\n",
      "episode 13, policy loss -0.012729010544717312\n",
      "\n",
      "episode 14, policy loss -0.04271932691335678\n",
      "\n",
      "episode 15, policy loss -0.07027110457420349\n",
      "\n",
      "episode 16, policy loss -0.016599711030721664\n",
      "\n",
      "Policy train loss in epoch 3:-0.0337630178546533\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.2195734828710556\n",
      "\n",
      "episode 2, val func loss 0.1667463630437851\n",
      "\n",
      "episode 3, val func loss 0.16605150699615479\n",
      "\n",
      "episode 4, val func loss 0.19146664440631866\n",
      "\n",
      "episode 5, val func loss 0.19817614555358887\n",
      "\n",
      "episode 6, val func loss 0.19962209463119507\n",
      "\n",
      "episode 7, val func loss 0.16116656363010406\n",
      "\n",
      "episode 8, val func loss 0.15964262187480927\n",
      "\n",
      "episode 9, val func loss 0.18272219598293304\n",
      "\n",
      "episode 10, val func loss 0.17764784395694733\n",
      "\n",
      "episode 11, val func loss 0.19681833684444427\n",
      "\n",
      "episode 12, val func loss 0.15410976111888885\n",
      "\n",
      "episode 13, val func loss 0.19690294563770294\n",
      "\n",
      "episode 14, val func loss 0.18560689687728882\n",
      "\n",
      "episode 15, val func loss 0.18352068960666656\n",
      "\n",
      "episode 16, val func loss 0.17923560738563538\n",
      "\n",
      "Val func train loss in epoch 0:0.1824381062760949\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1584043651819229\n",
      "\n",
      "episode 2, val func loss 0.16557914018630981\n",
      "\n",
      "episode 3, val func loss 0.16689936816692352\n",
      "\n",
      "episode 4, val func loss 0.15226997435092926\n",
      "\n",
      "episode 5, val func loss 0.19333969056606293\n",
      "\n",
      "episode 6, val func loss 0.19683821499347687\n",
      "\n",
      "episode 7, val func loss 0.18521806597709656\n",
      "\n",
      "episode 8, val func loss 0.1811329871416092\n",
      "\n",
      "episode 9, val func loss 0.17752502858638763\n",
      "\n",
      "episode 10, val func loss 0.2203301042318344\n",
      "\n",
      "episode 11, val func loss 0.1826627254486084\n",
      "\n",
      "episode 12, val func loss 0.19694580137729645\n",
      "\n",
      "episode 13, val func loss 0.19835518300533295\n",
      "\n",
      "episode 14, val func loss 0.17839716374874115\n",
      "\n",
      "episode 15, val func loss 0.19378699362277985\n",
      "\n",
      "episode 16, val func loss 0.16179469227790833\n",
      "\n",
      "Val func train loss in epoch 1:0.18184246867895126\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18271556496620178\n",
      "\n",
      "episode 2, val func loss 0.1692730337381363\n",
      "\n",
      "episode 3, val func loss 0.18404239416122437\n",
      "\n",
      "episode 4, val func loss 0.16626907885074615\n",
      "\n",
      "episode 5, val func loss 0.19708526134490967\n",
      "\n",
      "episode 6, val func loss 0.1532391756772995\n",
      "\n",
      "episode 7, val func loss 0.19764180481433868\n",
      "\n",
      "episode 8, val func loss 0.22293077409267426\n",
      "\n",
      "episode 9, val func loss 0.17656835913658142\n",
      "\n",
      "episode 10, val func loss 0.15652604401111603\n",
      "\n",
      "episode 11, val func loss 0.1974388062953949\n",
      "\n",
      "episode 12, val func loss 0.15780851244926453\n",
      "\n",
      "episode 13, val func loss 0.17956098914146423\n",
      "\n",
      "episode 14, val func loss 0.19329577684402466\n",
      "\n",
      "episode 15, val func loss 0.18019920587539673\n",
      "\n",
      "episode 16, val func loss 0.20056293904781342\n",
      "\n",
      "Val func train loss in epoch 2:0.18219735752791166\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19047164916992188\n",
      "\n",
      "episode 2, val func loss 0.183236226439476\n",
      "\n",
      "episode 3, val func loss 0.16002045571804047\n",
      "\n",
      "episode 4, val func loss 0.19699221849441528\n",
      "\n",
      "episode 5, val func loss 0.17952241003513336\n",
      "\n",
      "episode 6, val func loss 0.1972057819366455\n",
      "\n",
      "episode 7, val func loss 0.19444788992404938\n",
      "\n",
      "episode 8, val func loss 0.18336118757724762\n",
      "\n",
      "episode 9, val func loss 0.17993763089179993\n",
      "\n",
      "episode 10, val func loss 0.19775362312793732\n",
      "\n",
      "episode 11, val func loss 0.16714061796665192\n",
      "\n",
      "episode 12, val func loss 0.21632356941699982\n",
      "\n",
      "episode 13, val func loss 0.16092923283576965\n",
      "\n",
      "episode 14, val func loss 0.15375740826129913\n",
      "\n",
      "episode 15, val func loss 0.18759971857070923\n",
      "\n",
      "episode 16, val func loss 0.16839629411697388\n",
      "\n",
      "Val func train loss in epoch 3:0.1823184946551919\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1830715388059616\n",
      "\n",
      "episode 2, val func loss 0.17940564453601837\n",
      "\n",
      "episode 3, val func loss 0.17870111763477325\n",
      "\n",
      "episode 4, val func loss 0.15745656192302704\n",
      "\n",
      "episode 5, val func loss 0.19827570021152496\n",
      "\n",
      "episode 6, val func loss 0.22350332140922546\n",
      "\n",
      "episode 7, val func loss 0.16715553402900696\n",
      "\n",
      "episode 8, val func loss 0.1973140835762024\n",
      "\n",
      "episode 9, val func loss 0.16641265153884888\n",
      "\n",
      "episode 10, val func loss 0.18507973849773407\n",
      "\n",
      "episode 11, val func loss 0.19757507741451263\n",
      "\n",
      "episode 12, val func loss 0.19484226405620575\n",
      "\n",
      "episode 13, val func loss 0.19212298095226288\n",
      "\n",
      "episode 14, val func loss 0.15910638868808746\n",
      "\n",
      "episode 15, val func loss 0.18174175918102264\n",
      "\n",
      "episode 16, val func loss 0.15379147231578827\n",
      "\n",
      "Val func train loss in epoch 4:0.18222223967313766\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1827680766582489\n",
      "\n",
      "episode 2, val func loss 0.17834186553955078\n",
      "\n",
      "episode 3, val func loss 0.15930891036987305\n",
      "\n",
      "episode 4, val func loss 0.19702666997909546\n",
      "\n",
      "episode 5, val func loss 0.16543538868427277\n",
      "\n",
      "episode 6, val func loss 0.18289844691753387\n",
      "\n",
      "episode 7, val func loss 0.15810199081897736\n",
      "\n",
      "episode 8, val func loss 0.1651533544063568\n",
      "\n",
      "episode 9, val func loss 0.1517597734928131\n",
      "\n",
      "episode 10, val func loss 0.1993807554244995\n",
      "\n",
      "episode 11, val func loss 0.1850307732820511\n",
      "\n",
      "episode 12, val func loss 0.17926332354545593\n",
      "\n",
      "episode 13, val func loss 0.1961452215909958\n",
      "\n",
      "episode 14, val func loss 0.19834057986736298\n",
      "\n",
      "episode 15, val func loss 0.19048573076725006\n",
      "\n",
      "episode 16, val func loss 0.21727094054222107\n",
      "\n",
      "Val func train loss in epoch 5:0.1816694876179099\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18177255988121033\n",
      "\n",
      "episode 2, val func loss 0.1605951339006424\n",
      "\n",
      "episode 3, val func loss 0.1696433424949646\n",
      "\n",
      "episode 4, val func loss 0.15236195921897888\n",
      "\n",
      "episode 5, val func loss 0.1836204081773758\n",
      "\n",
      "episode 6, val func loss 0.19639427959918976\n",
      "\n",
      "episode 7, val func loss 0.1980200707912445\n",
      "\n",
      "episode 8, val func loss 0.17825116217136383\n",
      "\n",
      "episode 9, val func loss 0.17873089015483856\n",
      "\n",
      "episode 10, val func loss 0.1956464797258377\n",
      "\n",
      "episode 11, val func loss 0.16021345555782318\n",
      "\n",
      "episode 12, val func loss 0.19457878172397614\n",
      "\n",
      "episode 13, val func loss 0.18097145855426788\n",
      "\n",
      "episode 14, val func loss 0.16886457800865173\n",
      "\n",
      "episode 15, val func loss 0.1961638480424881\n",
      "\n",
      "episode 16, val func loss 0.2143598198890686\n",
      "\n",
      "Val func train loss in epoch 6:0.18188676424324512\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17999127507209778\n",
      "\n",
      "episode 2, val func loss 0.21390587091445923\n",
      "\n",
      "episode 3, val func loss 0.16268892586231232\n",
      "\n",
      "episode 4, val func loss 0.18594223260879517\n",
      "\n",
      "episode 5, val func loss 0.2000591903924942\n",
      "\n",
      "episode 6, val func loss 0.1664821356534958\n",
      "\n",
      "episode 7, val func loss 0.18743573129177094\n",
      "\n",
      "episode 8, val func loss 0.1809634417295456\n",
      "\n",
      "episode 9, val func loss 0.15831677615642548\n",
      "\n",
      "episode 10, val func loss 0.1962658017873764\n",
      "\n",
      "episode 11, val func loss 0.1974329799413681\n",
      "\n",
      "episode 12, val func loss 0.1948726326227188\n",
      "\n",
      "episode 13, val func loss 0.15054155886173248\n",
      "\n",
      "episode 14, val func loss 0.17842404544353485\n",
      "\n",
      "episode 15, val func loss 0.16551733016967773\n",
      "\n",
      "episode 16, val func loss 0.19883468747138977\n",
      "\n",
      "Val func train loss in epoch 7:0.18235466349869967\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.15234607458114624\n",
      "\n",
      "episode 2, val func loss 0.22048057615756989\n",
      "\n",
      "episode 3, val func loss 0.18015998601913452\n",
      "\n",
      "episode 4, val func loss 0.15926694869995117\n",
      "\n",
      "episode 5, val func loss 0.19474215805530548\n",
      "\n",
      "episode 6, val func loss 0.19864331185817719\n",
      "\n",
      "episode 7, val func loss 0.19829535484313965\n",
      "\n",
      "episode 8, val func loss 0.18238823115825653\n",
      "\n",
      "episode 9, val func loss 0.16674329340457916\n",
      "\n",
      "episode 10, val func loss 0.19810117781162262\n",
      "\n",
      "episode 11, val func loss 0.18117639422416687\n",
      "\n",
      "episode 12, val func loss 0.16557998955249786\n",
      "\n",
      "episode 13, val func loss 0.17999835312366486\n",
      "\n",
      "episode 14, val func loss 0.19275127351284027\n",
      "\n",
      "episode 15, val func loss 0.18330535292625427\n",
      "\n",
      "episode 16, val func loss 0.1575326919555664\n",
      "\n",
      "Val func train loss in epoch 8:0.18196944799274206\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.19231991469860077\n",
      "\n",
      "episode 2, val func loss 0.18298625946044922\n",
      "\n",
      "episode 3, val func loss 0.18196575343608856\n",
      "\n",
      "episode 4, val func loss 0.17643339931964874\n",
      "\n",
      "episode 5, val func loss 0.15677441656589508\n",
      "\n",
      "episode 6, val func loss 0.1645190268754959\n",
      "\n",
      "episode 7, val func loss 0.16564251482486725\n",
      "\n",
      "episode 8, val func loss 0.19681695103645325\n",
      "\n",
      "episode 9, val func loss 0.19737671315670013\n",
      "\n",
      "episode 10, val func loss 0.1519283801317215\n",
      "\n",
      "episode 11, val func loss 0.2166782021522522\n",
      "\n",
      "episode 12, val func loss 0.18043197691440582\n",
      "\n",
      "episode 13, val func loss 0.16181796789169312\n",
      "\n",
      "episode 14, val func loss 0.20048846304416656\n",
      "\n",
      "episode 15, val func loss 0.18279165029525757\n",
      "\n",
      "episode 16, val func loss 0.1952330321073532\n",
      "\n",
      "Val func train loss in epoch 9:0.18151278886944056\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.21467328071594238\n",
      "\n",
      "episode 2, val func loss 0.16839174926280975\n",
      "\n",
      "episode 3, val func loss 0.19803908467292786\n",
      "\n",
      "episode 4, val func loss 0.18182119727134705\n",
      "\n",
      "episode 5, val func loss 0.18532328307628632\n",
      "\n",
      "episode 6, val func loss 0.1582641899585724\n",
      "\n",
      "episode 7, val func loss 0.1952684074640274\n",
      "\n",
      "episode 8, val func loss 0.1577935814857483\n",
      "\n",
      "episode 9, val func loss 0.19111275672912598\n",
      "\n",
      "episode 10, val func loss 0.20129813253879547\n",
      "\n",
      "episode 11, val func loss 0.16610383987426758\n",
      "\n",
      "episode 12, val func loss 0.18128712475299835\n",
      "\n",
      "episode 13, val func loss 0.1528661996126175\n",
      "\n",
      "episode 14, val func loss 0.19692344963550568\n",
      "\n",
      "episode 15, val func loss 0.18097944557666779\n",
      "\n",
      "episode 16, val func loss 0.17706388235092163\n",
      "\n",
      "Val func train loss in epoch 10:0.1817006003111601\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16619116067886353\n",
      "\n",
      "episode 2, val func loss 0.1837092787027359\n",
      "\n",
      "episode 3, val func loss 0.22078506648540497\n",
      "\n",
      "episode 4, val func loss 0.15871527791023254\n",
      "\n",
      "episode 5, val func loss 0.15283678472042084\n",
      "\n",
      "episode 6, val func loss 0.1804390251636505\n",
      "\n",
      "episode 7, val func loss 0.159023255109787\n",
      "\n",
      "episode 8, val func loss 0.1778268814086914\n",
      "\n",
      "episode 9, val func loss 0.18287308514118195\n",
      "\n",
      "episode 10, val func loss 0.19658595323562622\n",
      "\n",
      "episode 11, val func loss 0.1801762878894806\n",
      "\n",
      "episode 12, val func loss 0.16634085774421692\n",
      "\n",
      "episode 13, val func loss 0.19724473357200623\n",
      "\n",
      "episode 14, val func loss 0.19705872237682343\n",
      "\n",
      "episode 15, val func loss 0.19787490367889404\n",
      "\n",
      "episode 16, val func loss 0.19180049002170563\n",
      "\n",
      "Val func train loss in epoch 11:0.1818426102399826\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1606600135564804\n",
      "\n",
      "episode 2, val func loss 0.19904014468193054\n",
      "\n",
      "episode 3, val func loss 0.15935198962688446\n",
      "\n",
      "episode 4, val func loss 0.18522553145885468\n",
      "\n",
      "episode 5, val func loss 0.19868408143520355\n",
      "\n",
      "episode 6, val func loss 0.1832837611436844\n",
      "\n",
      "episode 7, val func loss 0.16453450918197632\n",
      "\n",
      "episode 8, val func loss 0.19716954231262207\n",
      "\n",
      "episode 9, val func loss 0.16667355597019196\n",
      "\n",
      "episode 10, val func loss 0.15226319432258606\n",
      "\n",
      "episode 11, val func loss 0.19255594909191132\n",
      "\n",
      "episode 12, val func loss 0.2189582735300064\n",
      "\n",
      "episode 13, val func loss 0.18249323964118958\n",
      "\n",
      "episode 14, val func loss 0.1780521124601364\n",
      "\n",
      "episode 15, val func loss 0.1791609674692154\n",
      "\n",
      "episode 16, val func loss 0.1974910944700241\n",
      "\n",
      "Val func train loss in epoch 12:0.1822248725220561\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1977539360523224\n",
      "\n",
      "episode 2, val func loss 0.1871958076953888\n",
      "\n",
      "episode 3, val func loss 0.18261857330799103\n",
      "\n",
      "episode 4, val func loss 0.18091848492622375\n",
      "\n",
      "episode 5, val func loss 0.17887447774410248\n",
      "\n",
      "episode 6, val func loss 0.15906228125095367\n",
      "\n",
      "episode 7, val func loss 0.16646426916122437\n",
      "\n",
      "episode 8, val func loss 0.16605119407176971\n",
      "\n",
      "episode 9, val func loss 0.15174569189548492\n",
      "\n",
      "episode 10, val func loss 0.1994297057390213\n",
      "\n",
      "episode 11, val func loss 0.19951920211315155\n",
      "\n",
      "episode 12, val func loss 0.22327664494514465\n",
      "\n",
      "episode 13, val func loss 0.15701912343502045\n",
      "\n",
      "episode 14, val func loss 0.19639945030212402\n",
      "\n",
      "episode 15, val func loss 0.19270436465740204\n",
      "\n",
      "episode 16, val func loss 0.1784701943397522\n",
      "\n",
      "Val func train loss in epoch 13:0.18234396260231733\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17933093011379242\n",
      "\n",
      "episode 2, val func loss 0.21509721875190735\n",
      "\n",
      "episode 3, val func loss 0.19839072227478027\n",
      "\n",
      "episode 4, val func loss 0.19816195964813232\n",
      "\n",
      "episode 5, val func loss 0.15475019812583923\n",
      "\n",
      "episode 6, val func loss 0.18257591128349304\n",
      "\n",
      "episode 7, val func loss 0.18009218573570251\n",
      "\n",
      "episode 8, val func loss 0.19926553964614868\n",
      "\n",
      "episode 9, val func loss 0.18495787680149078\n",
      "\n",
      "episode 10, val func loss 0.18016177415847778\n",
      "\n",
      "episode 11, val func loss 0.16689787805080414\n",
      "\n",
      "episode 12, val func loss 0.15946343541145325\n",
      "\n",
      "episode 13, val func loss 0.16282892227172852\n",
      "\n",
      "episode 14, val func loss 0.15606024861335754\n",
      "\n",
      "episode 15, val func loss 0.19404909014701843\n",
      "\n",
      "episode 16, val func loss 0.1990918070077896\n",
      "\n",
      "Val func train loss in epoch 14:0.18194848112761974\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.15330563485622406\n",
      "\n",
      "episode 2, val func loss 0.15902139246463776\n",
      "\n",
      "episode 3, val func loss 0.19308947026729584\n",
      "\n",
      "episode 4, val func loss 0.19731219112873077\n",
      "\n",
      "episode 5, val func loss 0.1826690137386322\n",
      "\n",
      "episode 6, val func loss 0.17877115309238434\n",
      "\n",
      "episode 7, val func loss 0.1784871518611908\n",
      "\n",
      "episode 8, val func loss 0.1980230063199997\n",
      "\n",
      "episode 9, val func loss 0.1594839096069336\n",
      "\n",
      "episode 10, val func loss 0.21618437767028809\n",
      "\n",
      "episode 11, val func loss 0.19386665523052216\n",
      "\n",
      "episode 12, val func loss 0.18005730211734772\n",
      "\n",
      "episode 13, val func loss 0.18545611202716827\n",
      "\n",
      "episode 14, val func loss 0.16696803271770477\n",
      "\n",
      "episode 15, val func loss 0.17004679143428802\n",
      "\n",
      "episode 16, val func loss 0.19675105810165405\n",
      "\n",
      "Val func train loss in epoch 15:0.18184332828968763\n",
      "***********************TIME WAS 4.99956997235616 min*****************************\n",
      "\n",
      "**********************ROUND 123 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.037288848310709\n",
      "\n",
      "episode 2, policy loss 0.036025531589984894\n",
      "\n",
      "episode 3, policy loss 0.009278729557991028\n",
      "\n",
      "episode 4, policy loss 0.06550734490156174\n",
      "\n",
      "episode 5, policy loss 0.016697121784090996\n",
      "\n",
      "episode 6, policy loss 0.02337477169930935\n",
      "\n",
      "episode 7, policy loss 0.05547260865569115\n",
      "\n",
      "episode 8, policy loss -0.001516229473054409\n",
      "\n",
      "episode 9, policy loss 0.07541463524103165\n",
      "\n",
      "episode 10, policy loss 0.06801707297563553\n",
      "\n",
      "episode 11, policy loss 0.07353384792804718\n",
      "\n",
      "episode 12, policy loss 0.0649520680308342\n",
      "\n",
      "episode 13, policy loss 0.053990788757801056\n",
      "\n",
      "episode 14, policy loss 0.10414918512105942\n",
      "\n",
      "episode 15, policy loss 0.052270837128162384\n",
      "\n",
      "episode 16, policy loss 0.06871108710765839\n",
      "\n",
      "Policy train loss in epoch 0:0.050198015582282096\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.07360664010047913\n",
      "\n",
      "episode 2, policy loss 0.00491994759067893\n",
      "\n",
      "episode 3, policy loss 0.10199613869190216\n",
      "\n",
      "episode 4, policy loss 0.05999170243740082\n",
      "\n",
      "episode 5, policy loss 0.06597977876663208\n",
      "\n",
      "episode 6, policy loss 0.023693470284342766\n",
      "\n",
      "episode 7, policy loss 0.062381647527217865\n",
      "\n",
      "episode 8, policy loss 0.056643303483724594\n",
      "\n",
      "episode 9, policy loss 0.050660908222198486\n",
      "\n",
      "episode 10, policy loss 0.030514433979988098\n",
      "\n",
      "episode 11, policy loss 0.013208172284066677\n",
      "\n",
      "episode 12, policy loss 0.06501763314008713\n",
      "\n",
      "episode 13, policy loss 0.02764955163002014\n",
      "\n",
      "episode 14, policy loss 0.049410440027713776\n",
      "\n",
      "episode 15, policy loss -0.0027296363841742277\n",
      "\n",
      "episode 16, policy loss 0.07114096730947495\n",
      "\n",
      "Policy train loss in epoch 1:0.047130318693234585\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.06251358985900879\n",
      "\n",
      "episode 2, policy loss 0.10129223763942719\n",
      "\n",
      "episode 3, policy loss 0.06605201959609985\n",
      "\n",
      "episode 4, policy loss 0.023611146956682205\n",
      "\n",
      "episode 5, policy loss 0.0709296464920044\n",
      "\n",
      "episode 6, policy loss 0.03157007694244385\n",
      "\n",
      "episode 7, policy loss 0.050870757550001144\n",
      "\n",
      "episode 8, policy loss 0.012074099853634834\n",
      "\n",
      "episode 9, policy loss 0.07078175246715546\n",
      "\n",
      "episode 10, policy loss 0.05879119411110878\n",
      "\n",
      "episode 11, policy loss 0.05039415508508682\n",
      "\n",
      "episode 12, policy loss 0.05547153949737549\n",
      "\n",
      "episode 13, policy loss 0.06471551209688187\n",
      "\n",
      "episode 14, policy loss -0.0017195955151692033\n",
      "\n",
      "episode 15, policy loss 0.02680821157991886\n",
      "\n",
      "episode 16, policy loss 0.0037968107499182224\n",
      "\n",
      "Policy train loss in epoch 2:0.04674707218509866\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.07134692370891571\n",
      "\n",
      "episode 2, policy loss -0.0022871920373290777\n",
      "\n",
      "episode 3, policy loss 0.061453986912965775\n",
      "\n",
      "episode 4, policy loss 0.03019925206899643\n",
      "\n",
      "episode 5, policy loss 0.012235534377396107\n",
      "\n",
      "episode 6, policy loss 0.004090010654181242\n",
      "\n",
      "episode 7, policy loss 0.058851420879364014\n",
      "\n",
      "episode 8, policy loss 0.05553893372416496\n",
      "\n",
      "episode 9, policy loss 0.06607747077941895\n",
      "\n",
      "episode 10, policy loss 0.04854174330830574\n",
      "\n",
      "episode 11, policy loss 0.02391025982797146\n",
      "\n",
      "episode 12, policy loss 0.026612430810928345\n",
      "\n",
      "episode 13, policy loss 0.049385394901037216\n",
      "\n",
      "episode 14, policy loss 0.10112419724464417\n",
      "\n",
      "episode 15, policy loss 0.06363491714000702\n",
      "\n",
      "episode 16, policy loss 0.07079772651195526\n",
      "\n",
      "Policy train loss in epoch 3:0.04634456317580771\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19067588448524475\n",
      "\n",
      "episode 2, val func loss 0.22083726525306702\n",
      "\n",
      "episode 3, val func loss 0.1497354507446289\n",
      "\n",
      "episode 4, val func loss 0.17506276071071625\n",
      "\n",
      "episode 5, val func loss 0.16104774177074432\n",
      "\n",
      "episode 6, val func loss 0.18330106139183044\n",
      "\n",
      "episode 7, val func loss 0.15732553601264954\n",
      "\n",
      "episode 8, val func loss 0.1770092099905014\n",
      "\n",
      "episode 9, val func loss 0.19842486083507538\n",
      "\n",
      "episode 10, val func loss 0.18507909774780273\n",
      "\n",
      "episode 11, val func loss 0.2071782797574997\n",
      "\n",
      "episode 12, val func loss 0.18791957199573517\n",
      "\n",
      "episode 13, val func loss 0.19788581132888794\n",
      "\n",
      "episode 14, val func loss 0.18687033653259277\n",
      "\n",
      "episode 15, val func loss 0.1851961761713028\n",
      "\n",
      "episode 16, val func loss 0.21795909106731415\n",
      "\n",
      "Val func train loss in epoch 0:0.18634425848722458\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.15543122589588165\n",
      "\n",
      "episode 2, val func loss 0.20114192366600037\n",
      "\n",
      "episode 3, val func loss 0.21834790706634521\n",
      "\n",
      "episode 4, val func loss 0.18811960518360138\n",
      "\n",
      "episode 5, val func loss 0.18069922924041748\n",
      "\n",
      "episode 6, val func loss 0.1820196956396103\n",
      "\n",
      "episode 7, val func loss 0.15112712979316711\n",
      "\n",
      "episode 8, val func loss 0.1805342137813568\n",
      "\n",
      "episode 9, val func loss 0.1942768543958664\n",
      "\n",
      "episode 10, val func loss 0.1909606009721756\n",
      "\n",
      "episode 11, val func loss 0.22337117791175842\n",
      "\n",
      "episode 12, val func loss 0.20534980297088623\n",
      "\n",
      "episode 13, val func loss 0.18658789992332458\n",
      "\n",
      "episode 14, val func loss 0.19610339403152466\n",
      "\n",
      "episode 15, val func loss 0.17595407366752625\n",
      "\n",
      "episode 16, val func loss 0.162558913230896\n",
      "\n",
      "Val func train loss in epoch 1:0.18703647796064615\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18493539094924927\n",
      "\n",
      "episode 2, val func loss 0.18250177800655365\n",
      "\n",
      "episode 3, val func loss 0.19964873790740967\n",
      "\n",
      "episode 4, val func loss 0.16061048209667206\n",
      "\n",
      "episode 5, val func loss 0.21901193261146545\n",
      "\n",
      "episode 6, val func loss 0.18491435050964355\n",
      "\n",
      "episode 7, val func loss 0.15273679792881012\n",
      "\n",
      "episode 8, val func loss 0.19002825021743774\n",
      "\n",
      "episode 9, val func loss 0.14991526305675507\n",
      "\n",
      "episode 10, val func loss 0.1994805634021759\n",
      "\n",
      "episode 11, val func loss 0.18925809860229492\n",
      "\n",
      "episode 12, val func loss 0.17214582860469818\n",
      "\n",
      "episode 13, val func loss 0.21956110000610352\n",
      "\n",
      "episode 14, val func loss 0.20492342114448547\n",
      "\n",
      "episode 15, val func loss 0.19071918725967407\n",
      "\n",
      "episode 16, val func loss 0.17837294936180115\n",
      "\n",
      "Val func train loss in epoch 2:0.18617275822907686\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18093395233154297\n",
      "\n",
      "episode 2, val func loss 0.1509220451116562\n",
      "\n",
      "episode 3, val func loss 0.18210887908935547\n",
      "\n",
      "episode 4, val func loss 0.2217119336128235\n",
      "\n",
      "episode 5, val func loss 0.18979412317276\n",
      "\n",
      "episode 6, val func loss 0.1839674711227417\n",
      "\n",
      "episode 7, val func loss 0.190408855676651\n",
      "\n",
      "episode 8, val func loss 0.1838982105255127\n",
      "\n",
      "episode 9, val func loss 0.19684584438800812\n",
      "\n",
      "episode 10, val func loss 0.2010406106710434\n",
      "\n",
      "episode 11, val func loss 0.15658490359783173\n",
      "\n",
      "episode 12, val func loss 0.16298066079616547\n",
      "\n",
      "episode 13, val func loss 0.20683059096336365\n",
      "\n",
      "episode 14, val func loss 0.21711845695972443\n",
      "\n",
      "episode 15, val func loss 0.1873449683189392\n",
      "\n",
      "episode 16, val func loss 0.17732647061347961\n",
      "\n",
      "Val func train loss in epoch 3:0.18686362355947495\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17331533133983612\n",
      "\n",
      "episode 2, val func loss 0.2175019383430481\n",
      "\n",
      "episode 3, val func loss 0.19431833922863007\n",
      "\n",
      "episode 4, val func loss 0.15286864340305328\n",
      "\n",
      "episode 5, val func loss 0.1780797690153122\n",
      "\n",
      "episode 6, val func loss 0.18589049577713013\n",
      "\n",
      "episode 7, val func loss 0.1978885680437088\n",
      "\n",
      "episode 8, val func loss 0.16237665712833405\n",
      "\n",
      "episode 9, val func loss 0.18318906426429749\n",
      "\n",
      "episode 10, val func loss 0.20839303731918335\n",
      "\n",
      "episode 11, val func loss 0.15630236268043518\n",
      "\n",
      "episode 12, val func loss 0.2229272574186325\n",
      "\n",
      "episode 13, val func loss 0.19133789837360382\n",
      "\n",
      "episode 14, val func loss 0.1848621964454651\n",
      "\n",
      "episode 15, val func loss 0.1890794187784195\n",
      "\n",
      "episode 16, val func loss 0.18850189447402954\n",
      "\n",
      "Val func train loss in epoch 4:0.18667705450206995\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19134092330932617\n",
      "\n",
      "episode 2, val func loss 0.17534515261650085\n",
      "\n",
      "episode 3, val func loss 0.18561133742332458\n",
      "\n",
      "episode 4, val func loss 0.19424711167812347\n",
      "\n",
      "episode 5, val func loss 0.1526966542005539\n",
      "\n",
      "episode 6, val func loss 0.18334446847438812\n",
      "\n",
      "episode 7, val func loss 0.18667888641357422\n",
      "\n",
      "episode 8, val func loss 0.1833835244178772\n",
      "\n",
      "episode 9, val func loss 0.17771095037460327\n",
      "\n",
      "episode 10, val func loss 0.1986871361732483\n",
      "\n",
      "episode 11, val func loss 0.2184225618839264\n",
      "\n",
      "episode 12, val func loss 0.22125104069709778\n",
      "\n",
      "episode 13, val func loss 0.208426371216774\n",
      "\n",
      "episode 14, val func loss 0.19031193852424622\n",
      "\n",
      "episode 15, val func loss 0.1639588177204132\n",
      "\n",
      "episode 16, val func loss 0.15639008581638336\n",
      "\n",
      "Val func train loss in epoch 5:0.18673793505877256\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17507773637771606\n",
      "\n",
      "episode 2, val func loss 0.16216060519218445\n",
      "\n",
      "episode 3, val func loss 0.1881607323884964\n",
      "\n",
      "episode 4, val func loss 0.18522997200489044\n",
      "\n",
      "episode 5, val func loss 0.18905405700206757\n",
      "\n",
      "episode 6, val func loss 0.2077651023864746\n",
      "\n",
      "episode 7, val func loss 0.22038045525550842\n",
      "\n",
      "episode 8, val func loss 0.17813266813755035\n",
      "\n",
      "episode 9, val func loss 0.19720685482025146\n",
      "\n",
      "episode 10, val func loss 0.19358287751674652\n",
      "\n",
      "episode 11, val func loss 0.18465863168239594\n",
      "\n",
      "episode 12, val func loss 0.1562412530183792\n",
      "\n",
      "episode 13, val func loss 0.18459230661392212\n",
      "\n",
      "episode 14, val func loss 0.21947769820690155\n",
      "\n",
      "episode 15, val func loss 0.1907155066728592\n",
      "\n",
      "episode 16, val func loss 0.15303219854831696\n",
      "\n",
      "Val func train loss in epoch 6:0.18659179098904133\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19108587503433228\n",
      "\n",
      "episode 2, val func loss 0.1745862513780594\n",
      "\n",
      "episode 3, val func loss 0.19394858181476593\n",
      "\n",
      "episode 4, val func loss 0.17860715091228485\n",
      "\n",
      "episode 5, val func loss 0.1891760379076004\n",
      "\n",
      "episode 6, val func loss 0.16175523400306702\n",
      "\n",
      "episode 7, val func loss 0.15696096420288086\n",
      "\n",
      "episode 8, val func loss 0.1822727620601654\n",
      "\n",
      "episode 9, val func loss 0.18357248604297638\n",
      "\n",
      "episode 10, val func loss 0.22101044654846191\n",
      "\n",
      "episode 11, val func loss 0.20759187638759613\n",
      "\n",
      "episode 12, val func loss 0.18576642870903015\n",
      "\n",
      "episode 13, val func loss 0.22124886512756348\n",
      "\n",
      "episode 14, val func loss 0.14957861602306366\n",
      "\n",
      "episode 15, val func loss 0.19973552227020264\n",
      "\n",
      "episode 16, val func loss 0.18882140517234802\n",
      "\n",
      "Val func train loss in epoch 7:0.1866074064746499\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.18364819884300232\n",
      "\n",
      "episode 2, val func loss 0.17840136587619781\n",
      "\n",
      "episode 3, val func loss 0.18304987251758575\n",
      "\n",
      "episode 4, val func loss 0.19732075929641724\n",
      "\n",
      "episode 5, val func loss 0.1738266944885254\n",
      "\n",
      "episode 6, val func loss 0.18586230278015137\n",
      "\n",
      "episode 7, val func loss 0.18964830040931702\n",
      "\n",
      "episode 8, val func loss 0.2206626534461975\n",
      "\n",
      "episode 9, val func loss 0.1979885697364807\n",
      "\n",
      "episode 10, val func loss 0.22010816633701324\n",
      "\n",
      "episode 11, val func loss 0.16313979029655457\n",
      "\n",
      "episode 12, val func loss 0.18938365578651428\n",
      "\n",
      "episode 13, val func loss 0.21020305156707764\n",
      "\n",
      "episode 14, val func loss 0.1877271831035614\n",
      "\n",
      "episode 15, val func loss 0.15769800543785095\n",
      "\n",
      "episode 16, val func loss 0.1541377156972885\n",
      "\n",
      "Val func train loss in epoch 8:0.18705039285123348\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17364619672298431\n",
      "\n",
      "episode 2, val func loss 0.1900739222764969\n",
      "\n",
      "episode 3, val func loss 0.19943438470363617\n",
      "\n",
      "episode 4, val func loss 0.22067350149154663\n",
      "\n",
      "episode 5, val func loss 0.15562155842781067\n",
      "\n",
      "episode 6, val func loss 0.18879477679729462\n",
      "\n",
      "episode 7, val func loss 0.16404612362384796\n",
      "\n",
      "episode 8, val func loss 0.1821744441986084\n",
      "\n",
      "episode 9, val func loss 0.19777369499206543\n",
      "\n",
      "episode 10, val func loss 0.18814583122730255\n",
      "\n",
      "episode 11, val func loss 0.1817905157804489\n",
      "\n",
      "episode 12, val func loss 0.17871131002902985\n",
      "\n",
      "episode 13, val func loss 0.20681613683700562\n",
      "\n",
      "episode 14, val func loss 0.15098212659358978\n",
      "\n",
      "episode 15, val func loss 0.21872073411941528\n",
      "\n",
      "episode 16, val func loss 0.185510516166687\n",
      "\n",
      "Val func train loss in epoch 9:0.18643223587423563\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.22238226234912872\n",
      "\n",
      "episode 2, val func loss 0.19751468300819397\n",
      "\n",
      "episode 3, val func loss 0.1967533677816391\n",
      "\n",
      "episode 4, val func loss 0.21653668582439423\n",
      "\n",
      "episode 5, val func loss 0.1549730747938156\n",
      "\n",
      "episode 6, val func loss 0.18713314831256866\n",
      "\n",
      "episode 7, val func loss 0.18898172676563263\n",
      "\n",
      "episode 8, val func loss 0.18700821697711945\n",
      "\n",
      "episode 9, val func loss 0.1578350067138672\n",
      "\n",
      "episode 10, val func loss 0.2047472447156906\n",
      "\n",
      "episode 11, val func loss 0.1883830577135086\n",
      "\n",
      "episode 12, val func loss 0.18792729079723358\n",
      "\n",
      "episode 13, val func loss 0.1611250638961792\n",
      "\n",
      "episode 14, val func loss 0.17996783554553986\n",
      "\n",
      "episode 15, val func loss 0.17651773989200592\n",
      "\n",
      "episode 16, val func loss 0.18165269494056702\n",
      "\n",
      "Val func train loss in epoch 10:0.18683994375169277\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1794024109840393\n",
      "\n",
      "episode 2, val func loss 0.1727551370859146\n",
      "\n",
      "episode 3, val func loss 0.1633651852607727\n",
      "\n",
      "episode 4, val func loss 0.19652001559734344\n",
      "\n",
      "episode 5, val func loss 0.18725146353244781\n",
      "\n",
      "episode 6, val func loss 0.21006065607070923\n",
      "\n",
      "episode 7, val func loss 0.15448902547359467\n",
      "\n",
      "episode 8, val func loss 0.19509701430797577\n",
      "\n",
      "episode 9, val func loss 0.1882682889699936\n",
      "\n",
      "episode 10, val func loss 0.22032010555267334\n",
      "\n",
      "episode 11, val func loss 0.15718646347522736\n",
      "\n",
      "episode 12, val func loss 0.18292436003684998\n",
      "\n",
      "episode 13, val func loss 0.180542454123497\n",
      "\n",
      "episode 14, val func loss 0.2209288626909256\n",
      "\n",
      "episode 15, val func loss 0.1848158836364746\n",
      "\n",
      "episode 16, val func loss 0.19121986627578735\n",
      "\n",
      "Val func train loss in epoch 11:0.18657169956713915\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19825945794582367\n",
      "\n",
      "episode 2, val func loss 0.21778403222560883\n",
      "\n",
      "episode 3, val func loss 0.189020574092865\n",
      "\n",
      "episode 4, val func loss 0.18151971697807312\n",
      "\n",
      "episode 5, val func loss 0.20760893821716309\n",
      "\n",
      "episode 6, val func loss 0.18753956258296967\n",
      "\n",
      "episode 7, val func loss 0.18796104192733765\n",
      "\n",
      "episode 8, val func loss 0.16264458000659943\n",
      "\n",
      "episode 9, val func loss 0.1977471262216568\n",
      "\n",
      "episode 10, val func loss 0.1852201372385025\n",
      "\n",
      "episode 11, val func loss 0.2199399769306183\n",
      "\n",
      "episode 12, val func loss 0.18695370852947235\n",
      "\n",
      "episode 13, val func loss 0.17424173653125763\n",
      "\n",
      "episode 14, val func loss 0.15067654848098755\n",
      "\n",
      "episode 15, val func loss 0.1834675520658493\n",
      "\n",
      "episode 16, val func loss 0.1565784364938736\n",
      "\n",
      "Val func train loss in epoch 12:0.18669769540429115\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.16290858387947083\n",
      "\n",
      "episode 2, val func loss 0.2218189686536789\n",
      "\n",
      "episode 3, val func loss 0.1771828830242157\n",
      "\n",
      "episode 4, val func loss 0.18947966396808624\n",
      "\n",
      "episode 5, val func loss 0.15631267428398132\n",
      "\n",
      "episode 6, val func loss 0.1842886358499527\n",
      "\n",
      "episode 7, val func loss 0.21798573434352875\n",
      "\n",
      "episode 8, val func loss 0.19967220723628998\n",
      "\n",
      "episode 9, val func loss 0.1882227063179016\n",
      "\n",
      "episode 10, val func loss 0.17558546364307404\n",
      "\n",
      "episode 11, val func loss 0.1864539086818695\n",
      "\n",
      "episode 12, val func loss 0.19723987579345703\n",
      "\n",
      "episode 13, val func loss 0.18920692801475525\n",
      "\n",
      "episode 14, val func loss 0.20799390971660614\n",
      "\n",
      "episode 15, val func loss 0.18246950209140778\n",
      "\n",
      "episode 16, val func loss 0.14941562712192535\n",
      "\n",
      "Val func train loss in epoch 13:0.18663982953876257\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18173350393772125\n",
      "\n",
      "episode 2, val func loss 0.15605208277702332\n",
      "\n",
      "episode 3, val func loss 0.18438445031642914\n",
      "\n",
      "episode 4, val func loss 0.19927160441875458\n",
      "\n",
      "episode 5, val func loss 0.20649735629558563\n",
      "\n",
      "episode 6, val func loss 0.2013179510831833\n",
      "\n",
      "episode 7, val func loss 0.17518597841262817\n",
      "\n",
      "episode 8, val func loss 0.19142748415470123\n",
      "\n",
      "episode 9, val func loss 0.17770664393901825\n",
      "\n",
      "episode 10, val func loss 0.21726666390895844\n",
      "\n",
      "episode 11, val func loss 0.15316185355186462\n",
      "\n",
      "episode 12, val func loss 0.19020196795463562\n",
      "\n",
      "episode 13, val func loss 0.1644897758960724\n",
      "\n",
      "episode 14, val func loss 0.21894745528697968\n",
      "\n",
      "episode 15, val func loss 0.19071181118488312\n",
      "\n",
      "episode 16, val func loss 0.18476739525794983\n",
      "\n",
      "Val func train loss in epoch 14:0.18707024864852428\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18763555586338043\n",
      "\n",
      "episode 2, val func loss 0.18038775026798248\n",
      "\n",
      "episode 3, val func loss 0.15552553534507751\n",
      "\n",
      "episode 4, val func loss 0.2211235761642456\n",
      "\n",
      "episode 5, val func loss 0.20838041603565216\n",
      "\n",
      "episode 6, val func loss 0.1485929787158966\n",
      "\n",
      "episode 7, val func loss 0.1925065815448761\n",
      "\n",
      "episode 8, val func loss 0.19923877716064453\n",
      "\n",
      "episode 9, val func loss 0.18268731236457825\n",
      "\n",
      "episode 10, val func loss 0.16260577738285065\n",
      "\n",
      "episode 11, val func loss 0.18347300589084625\n",
      "\n",
      "episode 12, val func loss 0.19677792489528656\n",
      "\n",
      "episode 13, val func loss 0.18682383000850677\n",
      "\n",
      "episode 14, val func loss 0.21809379756450653\n",
      "\n",
      "episode 15, val func loss 0.1765906810760498\n",
      "\n",
      "episode 16, val func loss 0.19195958971977234\n",
      "\n",
      "Val func train loss in epoch 15:0.18702519312500954\n",
      "***********************TIME WAS 4.999895111719767 min*****************************\n",
      "\n",
      "**********************ROUND 124 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.028686635196208954\n",
      "\n",
      "episode 2, policy loss 0.04673387482762337\n",
      "\n",
      "episode 3, policy loss 0.0454583577811718\n",
      "\n",
      "episode 4, policy loss 0.039368562400341034\n",
      "\n",
      "episode 5, policy loss 0.02693328633904457\n",
      "\n",
      "episode 6, policy loss 0.07763270288705826\n",
      "\n",
      "episode 7, policy loss 0.045263856649398804\n",
      "\n",
      "episode 8, policy loss 0.05843638256192207\n",
      "\n",
      "episode 9, policy loss 0.039468079805374146\n",
      "\n",
      "episode 10, policy loss 0.05865417793393135\n",
      "\n",
      "episode 11, policy loss 0.005967542063444853\n",
      "\n",
      "episode 12, policy loss -0.050808973610401154\n",
      "\n",
      "episode 13, policy loss 0.0784531757235527\n",
      "\n",
      "episode 14, policy loss 0.05079085752367973\n",
      "\n",
      "episode 15, policy loss 0.060991257429122925\n",
      "\n",
      "episode 16, policy loss 0.027327656745910645\n",
      "\n",
      "Policy train loss in epoch 0:0.039959839516086504\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.060943037271499634\n",
      "\n",
      "episode 2, policy loss 0.005277546588331461\n",
      "\n",
      "episode 3, policy loss 0.045074302703142166\n",
      "\n",
      "episode 4, policy loss 0.03445233404636383\n",
      "\n",
      "episode 5, policy loss 0.05039804428815842\n",
      "\n",
      "episode 6, policy loss 0.07594241946935654\n",
      "\n",
      "episode 7, policy loss 0.040058836340904236\n",
      "\n",
      "episode 8, policy loss 0.02668176032602787\n",
      "\n",
      "episode 9, policy loss 0.03937487676739693\n",
      "\n",
      "episode 10, policy loss 0.05845881998538971\n",
      "\n",
      "episode 11, policy loss 0.07600728422403336\n",
      "\n",
      "episode 12, policy loss 0.057526424527168274\n",
      "\n",
      "episode 13, policy loss 0.01801406592130661\n",
      "\n",
      "episode 14, policy loss 0.024459071457386017\n",
      "\n",
      "episode 15, policy loss -0.05160536617040634\n",
      "\n",
      "episode 16, policy loss 0.04015583544969559\n",
      "\n",
      "Policy train loss in epoch 1:0.03757620582473464\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.026782779023051262\n",
      "\n",
      "episode 2, policy loss -0.05208182334899902\n",
      "\n",
      "episode 3, policy loss 0.01776767522096634\n",
      "\n",
      "episode 4, policy loss 0.07595191895961761\n",
      "\n",
      "episode 5, policy loss 0.03848203271627426\n",
      "\n",
      "episode 6, policy loss 0.024621574208140373\n",
      "\n",
      "episode 7, policy loss 0.05833059921860695\n",
      "\n",
      "episode 8, policy loss 0.03371298313140869\n",
      "\n",
      "episode 9, policy loss 0.050201207399368286\n",
      "\n",
      "episode 10, policy loss 0.07601678371429443\n",
      "\n",
      "episode 11, policy loss 0.05665985122323036\n",
      "\n",
      "episode 12, policy loss 0.00453902455046773\n",
      "\n",
      "episode 13, policy loss 0.03894471004605293\n",
      "\n",
      "episode 14, policy loss 0.04597749561071396\n",
      "\n",
      "episode 15, policy loss 0.06024659425020218\n",
      "\n",
      "episode 16, policy loss 0.03951181843876839\n",
      "\n",
      "Policy train loss in epoch 2:0.037229076522635296\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.0390581339597702\n",
      "\n",
      "episode 2, policy loss 0.07590954005718231\n",
      "\n",
      "episode 3, policy loss 0.07658427953720093\n",
      "\n",
      "episode 4, policy loss 0.039130061864852905\n",
      "\n",
      "episode 5, policy loss 0.057107359170913696\n",
      "\n",
      "episode 6, policy loss 0.02387729100883007\n",
      "\n",
      "episode 7, policy loss 0.05021292716264725\n",
      "\n",
      "episode 8, policy loss 0.05770770087838173\n",
      "\n",
      "episode 9, policy loss 0.06060165539383888\n",
      "\n",
      "episode 10, policy loss 0.03865083307027817\n",
      "\n",
      "episode 11, policy loss 0.026775378733873367\n",
      "\n",
      "episode 12, policy loss 0.005717208608984947\n",
      "\n",
      "episode 13, policy loss -0.05096834525465965\n",
      "\n",
      "episode 14, policy loss 0.018047096207737923\n",
      "\n",
      "episode 15, policy loss 0.045705944299697876\n",
      "\n",
      "episode 16, policy loss 0.03386393561959267\n",
      "\n",
      "Policy train loss in epoch 3:0.037373812519945204\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.18302784860134125\n",
      "\n",
      "episode 2, val func loss 0.19589954614639282\n",
      "\n",
      "episode 3, val func loss 0.23088179528713226\n",
      "\n",
      "episode 4, val func loss 0.18353042006492615\n",
      "\n",
      "episode 5, val func loss 0.1839638650417328\n",
      "\n",
      "episode 6, val func loss 0.1812935322523117\n",
      "\n",
      "episode 7, val func loss 0.19347912073135376\n",
      "\n",
      "episode 8, val func loss 0.19990436732769012\n",
      "\n",
      "episode 9, val func loss 0.20176410675048828\n",
      "\n",
      "episode 10, val func loss 0.17060571908950806\n",
      "\n",
      "episode 11, val func loss 0.19735181331634521\n",
      "\n",
      "episode 12, val func loss 0.17663276195526123\n",
      "\n",
      "episode 13, val func loss 0.18403682112693787\n",
      "\n",
      "episode 14, val func loss 0.20090584456920624\n",
      "\n",
      "episode 15, val func loss 0.1636512279510498\n",
      "\n",
      "episode 16, val func loss 0.1734948605298996\n",
      "\n",
      "Val func train loss in epoch 0:0.18877647817134857\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19519628584384918\n",
      "\n",
      "episode 2, val func loss 0.16291984915733337\n",
      "\n",
      "episode 3, val func loss 0.1743297427892685\n",
      "\n",
      "episode 4, val func loss 0.19951178133487701\n",
      "\n",
      "episode 5, val func loss 0.20038962364196777\n",
      "\n",
      "episode 6, val func loss 0.2277003973722458\n",
      "\n",
      "episode 7, val func loss 0.183240607380867\n",
      "\n",
      "episode 8, val func loss 0.20043601095676422\n",
      "\n",
      "episode 9, val func loss 0.18380801379680634\n",
      "\n",
      "episode 10, val func loss 0.1838514357805252\n",
      "\n",
      "episode 11, val func loss 0.1700429618358612\n",
      "\n",
      "episode 12, val func loss 0.1820935606956482\n",
      "\n",
      "episode 13, val func loss 0.18243761360645294\n",
      "\n",
      "episode 14, val func loss 0.20581668615341187\n",
      "\n",
      "episode 15, val func loss 0.1982552707195282\n",
      "\n",
      "episode 16, val func loss 0.18454250693321228\n",
      "\n",
      "Val func train loss in epoch 1:0.1896607717499137\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.2326183319091797\n",
      "\n",
      "episode 2, val func loss 0.20026443898677826\n",
      "\n",
      "episode 3, val func loss 0.1836797147989273\n",
      "\n",
      "episode 4, val func loss 0.2017003744840622\n",
      "\n",
      "episode 5, val func loss 0.20075483620166779\n",
      "\n",
      "episode 6, val func loss 0.20099826157093048\n",
      "\n",
      "episode 7, val func loss 0.18478505313396454\n",
      "\n",
      "episode 8, val func loss 0.17172187566757202\n",
      "\n",
      "episode 9, val func loss 0.18327303230762482\n",
      "\n",
      "episode 10, val func loss 0.18386977910995483\n",
      "\n",
      "episode 11, val func loss 0.19459183514118195\n",
      "\n",
      "episode 12, val func loss 0.18628491461277008\n",
      "\n",
      "episode 13, val func loss 0.17273668944835663\n",
      "\n",
      "episode 14, val func loss 0.19540970027446747\n",
      "\n",
      "episode 15, val func loss 0.1628759205341339\n",
      "\n",
      "episode 16, val func loss 0.1734778881072998\n",
      "\n",
      "Val func train loss in epoch 2:0.18931516539305449\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1833287626504898\n",
      "\n",
      "episode 2, val func loss 0.16259759664535522\n",
      "\n",
      "episode 3, val func loss 0.16950097680091858\n",
      "\n",
      "episode 4, val func loss 0.19847317039966583\n",
      "\n",
      "episode 5, val func loss 0.18431465327739716\n",
      "\n",
      "episode 6, val func loss 0.1847241073846817\n",
      "\n",
      "episode 7, val func loss 0.19377250969409943\n",
      "\n",
      "episode 8, val func loss 0.19858737289905548\n",
      "\n",
      "episode 9, val func loss 0.18307985365390778\n",
      "\n",
      "episode 10, val func loss 0.1771167665719986\n",
      "\n",
      "episode 11, val func loss 0.2026529759168625\n",
      "\n",
      "episode 12, val func loss 0.23255154490470886\n",
      "\n",
      "episode 13, val func loss 0.1821737289428711\n",
      "\n",
      "episode 14, val func loss 0.20089121162891388\n",
      "\n",
      "episode 15, val func loss 0.20376966893672943\n",
      "\n",
      "episode 16, val func loss 0.17411400377750397\n",
      "\n",
      "Val func train loss in epoch 3:0.18947805650532246\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1980675309896469\n",
      "\n",
      "episode 2, val func loss 0.1697281301021576\n",
      "\n",
      "episode 3, val func loss 0.20270517468452454\n",
      "\n",
      "episode 4, val func loss 0.18543872237205505\n",
      "\n",
      "episode 5, val func loss 0.17704544961452484\n",
      "\n",
      "episode 6, val func loss 0.20091235637664795\n",
      "\n",
      "episode 7, val func loss 0.2002909779548645\n",
      "\n",
      "episode 8, val func loss 0.19643300771713257\n",
      "\n",
      "episode 9, val func loss 0.23007036745548248\n",
      "\n",
      "episode 10, val func loss 0.17361381649971008\n",
      "\n",
      "episode 11, val func loss 0.18363066017627716\n",
      "\n",
      "episode 12, val func loss 0.18179909884929657\n",
      "\n",
      "episode 13, val func loss 0.1938639134168625\n",
      "\n",
      "episode 14, val func loss 0.18375708162784576\n",
      "\n",
      "episode 15, val func loss 0.1826390027999878\n",
      "\n",
      "episode 16, val func loss 0.16335809230804443\n",
      "\n",
      "Val func train loss in epoch 4:0.1889595864340663\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.2032565027475357\n",
      "\n",
      "episode 2, val func loss 0.18300406634807587\n",
      "\n",
      "episode 3, val func loss 0.1951882392168045\n",
      "\n",
      "episode 4, val func loss 0.20029854774475098\n",
      "\n",
      "episode 5, val func loss 0.2005479335784912\n",
      "\n",
      "episode 6, val func loss 0.18111573159694672\n",
      "\n",
      "episode 7, val func loss 0.19846588373184204\n",
      "\n",
      "episode 8, val func loss 0.1733282506465912\n",
      "\n",
      "episode 9, val func loss 0.18541386723518372\n",
      "\n",
      "episode 10, val func loss 0.16887545585632324\n",
      "\n",
      "episode 11, val func loss 0.16384853422641754\n",
      "\n",
      "episode 12, val func loss 0.1828610599040985\n",
      "\n",
      "episode 13, val func loss 0.18323495984077454\n",
      "\n",
      "episode 14, val func loss 0.19558922946453094\n",
      "\n",
      "episode 15, val func loss 0.23143453896045685\n",
      "\n",
      "episode 16, val func loss 0.1760963350534439\n",
      "\n",
      "Val func train loss in epoch 5:0.18890994600951672\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19827747344970703\n",
      "\n",
      "episode 2, val func loss 0.18411582708358765\n",
      "\n",
      "episode 3, val func loss 0.18559423089027405\n",
      "\n",
      "episode 4, val func loss 0.1640586405992508\n",
      "\n",
      "episode 5, val func loss 0.20316340029239655\n",
      "\n",
      "episode 6, val func loss 0.1835995614528656\n",
      "\n",
      "episode 7, val func loss 0.19952476024627686\n",
      "\n",
      "episode 8, val func loss 0.1689813882112503\n",
      "\n",
      "episode 9, val func loss 0.23092466592788696\n",
      "\n",
      "episode 10, val func loss 0.19435182213783264\n",
      "\n",
      "episode 11, val func loss 0.18361631035804749\n",
      "\n",
      "episode 12, val func loss 0.1837387979030609\n",
      "\n",
      "episode 13, val func loss 0.17683805525302887\n",
      "\n",
      "episode 14, val func loss 0.17433451116085052\n",
      "\n",
      "episode 15, val func loss 0.20060916244983673\n",
      "\n",
      "episode 16, val func loss 0.19598513841629028\n",
      "\n",
      "Val func train loss in epoch 6:0.1892321091145277\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1830524206161499\n",
      "\n",
      "episode 2, val func loss 0.19865044951438904\n",
      "\n",
      "episode 3, val func loss 0.1634301394224167\n",
      "\n",
      "episode 4, val func loss 0.18596558272838593\n",
      "\n",
      "episode 5, val func loss 0.17465649545192719\n",
      "\n",
      "episode 6, val func loss 0.17335295677185059\n",
      "\n",
      "episode 7, val func loss 0.1956336498260498\n",
      "\n",
      "episode 8, val func loss 0.20133060216903687\n",
      "\n",
      "episode 9, val func loss 0.18081440031528473\n",
      "\n",
      "episode 10, val func loss 0.16844823956489563\n",
      "\n",
      "episode 11, val func loss 0.18239673972129822\n",
      "\n",
      "episode 12, val func loss 0.23241503536701202\n",
      "\n",
      "episode 13, val func loss 0.20018474757671356\n",
      "\n",
      "episode 14, val func loss 0.1966758817434311\n",
      "\n",
      "episode 15, val func loss 0.20235192775726318\n",
      "\n",
      "episode 16, val func loss 0.18343281745910645\n",
      "\n",
      "Val func train loss in epoch 7:0.18892450537532568\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1939425766468048\n",
      "\n",
      "episode 2, val func loss 0.20186297595500946\n",
      "\n",
      "episode 3, val func loss 0.19940884411334991\n",
      "\n",
      "episode 4, val func loss 0.17906348407268524\n",
      "\n",
      "episode 5, val func loss 0.18393196165561676\n",
      "\n",
      "episode 6, val func loss 0.17431306838989258\n",
      "\n",
      "episode 7, val func loss 0.16333803534507751\n",
      "\n",
      "episode 8, val func loss 0.1813419610261917\n",
      "\n",
      "episode 9, val func loss 0.18795710802078247\n",
      "\n",
      "episode 10, val func loss 0.23961901664733887\n",
      "\n",
      "episode 11, val func loss 0.1997160166501999\n",
      "\n",
      "episode 12, val func loss 0.20186138153076172\n",
      "\n",
      "episode 13, val func loss 0.18377354741096497\n",
      "\n",
      "episode 14, val func loss 0.20298150181770325\n",
      "\n",
      "episode 15, val func loss 0.18380041420459747\n",
      "\n",
      "episode 16, val func loss 0.1709495633840561\n",
      "\n",
      "Val func train loss in epoch 8:0.19049134105443954\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20150259137153625\n",
      "\n",
      "episode 2, val func loss 0.1988086700439453\n",
      "\n",
      "episode 3, val func loss 0.2024984210729599\n",
      "\n",
      "episode 4, val func loss 0.16390535235404968\n",
      "\n",
      "episode 5, val func loss 0.22830329835414886\n",
      "\n",
      "episode 6, val func loss 0.18311341106891632\n",
      "\n",
      "episode 7, val func loss 0.17037193477153778\n",
      "\n",
      "episode 8, val func loss 0.19371072947978973\n",
      "\n",
      "episode 9, val func loss 0.17792005836963654\n",
      "\n",
      "episode 10, val func loss 0.18226024508476257\n",
      "\n",
      "episode 11, val func loss 0.18357139825820923\n",
      "\n",
      "episode 12, val func loss 0.20148518681526184\n",
      "\n",
      "episode 13, val func loss 0.1734069138765335\n",
      "\n",
      "episode 14, val func loss 0.19548967480659485\n",
      "\n",
      "episode 15, val func loss 0.18407051265239716\n",
      "\n",
      "episode 16, val func loss 0.1862936019897461\n",
      "\n",
      "Val func train loss in epoch 9:0.1891695000231266\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.17342257499694824\n",
      "\n",
      "episode 2, val func loss 0.19873465597629547\n",
      "\n",
      "episode 3, val func loss 0.20409157872200012\n",
      "\n",
      "episode 4, val func loss 0.1815427541732788\n",
      "\n",
      "episode 5, val func loss 0.20064659416675568\n",
      "\n",
      "episode 6, val func loss 0.18549156188964844\n",
      "\n",
      "episode 7, val func loss 0.17714948952198029\n",
      "\n",
      "episode 8, val func loss 0.18361228704452515\n",
      "\n",
      "episode 9, val func loss 0.18267910182476044\n",
      "\n",
      "episode 10, val func loss 0.19626177847385406\n",
      "\n",
      "episode 11, val func loss 0.20072102546691895\n",
      "\n",
      "episode 12, val func loss 0.16305901110172272\n",
      "\n",
      "episode 13, val func loss 0.16902637481689453\n",
      "\n",
      "episode 14, val func loss 0.23586957156658173\n",
      "\n",
      "episode 15, val func loss 0.18384979665279388\n",
      "\n",
      "episode 16, val func loss 0.19460448622703552\n",
      "\n",
      "Val func train loss in epoch 10:0.18942266516387463\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.2002197951078415\n",
      "\n",
      "episode 2, val func loss 0.17475369572639465\n",
      "\n",
      "episode 3, val func loss 0.1845264881849289\n",
      "\n",
      "episode 4, val func loss 0.22581349313259125\n",
      "\n",
      "episode 5, val func loss 0.2016935795545578\n",
      "\n",
      "episode 6, val func loss 0.18469339609146118\n",
      "\n",
      "episode 7, val func loss 0.18621158599853516\n",
      "\n",
      "episode 8, val func loss 0.18429827690124512\n",
      "\n",
      "episode 9, val func loss 0.2024603933095932\n",
      "\n",
      "episode 10, val func loss 0.19895106554031372\n",
      "\n",
      "episode 11, val func loss 0.19656705856323242\n",
      "\n",
      "episode 12, val func loss 0.16891399025917053\n",
      "\n",
      "episode 13, val func loss 0.19789481163024902\n",
      "\n",
      "episode 14, val func loss 0.1742360144853592\n",
      "\n",
      "episode 15, val func loss 0.18146058917045593\n",
      "\n",
      "episode 16, val func loss 0.16308286786079407\n",
      "\n",
      "Val func train loss in epoch 11:0.18911106884479523\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18429064750671387\n",
      "\n",
      "episode 2, val func loss 0.19885998964309692\n",
      "\n",
      "episode 3, val func loss 0.18172115087509155\n",
      "\n",
      "episode 4, val func loss 0.1945108324289322\n",
      "\n",
      "episode 5, val func loss 0.19624553620815277\n",
      "\n",
      "episode 6, val func loss 0.2004421502351761\n",
      "\n",
      "episode 7, val func loss 0.18285100162029266\n",
      "\n",
      "episode 8, val func loss 0.1742607057094574\n",
      "\n",
      "episode 9, val func loss 0.1637703776359558\n",
      "\n",
      "episode 10, val func loss 0.20085923373699188\n",
      "\n",
      "episode 11, val func loss 0.1855798065662384\n",
      "\n",
      "episode 12, val func loss 0.23132163286209106\n",
      "\n",
      "episode 13, val func loss 0.17604725062847137\n",
      "\n",
      "episode 14, val func loss 0.18351894617080688\n",
      "\n",
      "episode 15, val func loss 0.16935408115386963\n",
      "\n",
      "episode 16, val func loss 0.20291776955127716\n",
      "\n",
      "Val func train loss in epoch 12:0.18915944453328848\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18562167882919312\n",
      "\n",
      "episode 2, val func loss 0.18361987173557281\n",
      "\n",
      "episode 3, val func loss 0.20278136432170868\n",
      "\n",
      "episode 4, val func loss 0.16947156190872192\n",
      "\n",
      "episode 5, val func loss 0.19404898583889008\n",
      "\n",
      "episode 6, val func loss 0.1741599589586258\n",
      "\n",
      "episode 7, val func loss 0.18302245438098907\n",
      "\n",
      "episode 8, val func loss 0.2290297895669937\n",
      "\n",
      "episode 9, val func loss 0.19648490846157074\n",
      "\n",
      "episode 10, val func loss 0.18225525319576263\n",
      "\n",
      "episode 11, val func loss 0.18342354893684387\n",
      "\n",
      "episode 12, val func loss 0.1638868749141693\n",
      "\n",
      "episode 13, val func loss 0.20049941539764404\n",
      "\n",
      "episode 14, val func loss 0.2004701793193817\n",
      "\n",
      "episode 15, val func loss 0.19870364665985107\n",
      "\n",
      "episode 16, val func loss 0.17550796270370483\n",
      "\n",
      "Val func train loss in epoch 13:0.18893671594560146\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.194672629237175\n",
      "\n",
      "episode 2, val func loss 0.18149712681770325\n",
      "\n",
      "episode 3, val func loss 0.16889365017414093\n",
      "\n",
      "episode 4, val func loss 0.17335063219070435\n",
      "\n",
      "episode 5, val func loss 0.19544082880020142\n",
      "\n",
      "episode 6, val func loss 0.18397563695907593\n",
      "\n",
      "episode 7, val func loss 0.2017723172903061\n",
      "\n",
      "episode 8, val func loss 0.23366746306419373\n",
      "\n",
      "episode 9, val func loss 0.2036791890859604\n",
      "\n",
      "episode 10, val func loss 0.16344450414180756\n",
      "\n",
      "episode 11, val func loss 0.1856335550546646\n",
      "\n",
      "episode 12, val func loss 0.20143119990825653\n",
      "\n",
      "episode 13, val func loss 0.1791357547044754\n",
      "\n",
      "episode 14, val func loss 0.18385519087314606\n",
      "\n",
      "episode 15, val func loss 0.1989075243473053\n",
      "\n",
      "episode 16, val func loss 0.1839699149131775\n",
      "\n",
      "Val func train loss in epoch 14:0.18958294484764338\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18215325474739075\n",
      "\n",
      "episode 2, val func loss 0.16359715163707733\n",
      "\n",
      "episode 3, val func loss 0.2041134238243103\n",
      "\n",
      "episode 4, val func loss 0.20182517170906067\n",
      "\n",
      "episode 5, val func loss 0.20108570158481598\n",
      "\n",
      "episode 6, val func loss 0.18341127038002014\n",
      "\n",
      "episode 7, val func loss 0.1826147437095642\n",
      "\n",
      "episode 8, val func loss 0.23211809992790222\n",
      "\n",
      "episode 9, val func loss 0.19430086016654968\n",
      "\n",
      "episode 10, val func loss 0.1835523098707199\n",
      "\n",
      "episode 11, val func loss 0.17732630670070648\n",
      "\n",
      "episode 12, val func loss 0.17032091319561005\n",
      "\n",
      "episode 13, val func loss 0.18585146963596344\n",
      "\n",
      "episode 14, val func loss 0.17477840185165405\n",
      "\n",
      "episode 15, val func loss 0.19820769131183624\n",
      "\n",
      "episode 16, val func loss 0.19636662304401398\n",
      "\n",
      "Val func train loss in epoch 15:0.18947646208107471\n",
      "***********************TIME WAS 5.002708351612091 min*****************************\n",
      "\n",
      "**********************ROUND 125 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.026995552703738213\n",
      "\n",
      "episode 2, policy loss -0.019212719053030014\n",
      "\n",
      "episode 3, policy loss -0.014350850135087967\n",
      "\n",
      "episode 4, policy loss -0.06780989468097687\n",
      "\n",
      "episode 5, policy loss -0.004053162876516581\n",
      "\n",
      "episode 6, policy loss -0.05975719541311264\n",
      "\n",
      "episode 7, policy loss -0.06732579320669174\n",
      "\n",
      "episode 8, policy loss -0.026057139039039612\n",
      "\n",
      "episode 9, policy loss -0.04230419173836708\n",
      "\n",
      "episode 10, policy loss -0.045501139014959335\n",
      "\n",
      "episode 11, policy loss 0.0014878264628350735\n",
      "\n",
      "episode 12, policy loss -0.05203132703900337\n",
      "\n",
      "episode 13, policy loss -0.06522431969642639\n",
      "\n",
      "episode 14, policy loss -0.06144469231367111\n",
      "\n",
      "episode 15, policy loss -0.02854716219007969\n",
      "\n",
      "episode 16, policy loss -0.017931578680872917\n",
      "\n",
      "Policy train loss in epoch 0:-0.037316180707421154\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.06238780915737152\n",
      "\n",
      "episode 2, policy loss -0.06604939699172974\n",
      "\n",
      "episode 3, policy loss -0.01797882653772831\n",
      "\n",
      "episode 4, policy loss -0.024098852649331093\n",
      "\n",
      "episode 5, policy loss -0.0398009717464447\n",
      "\n",
      "episode 6, policy loss -0.07062140852212906\n",
      "\n",
      "episode 7, policy loss -0.02456291764974594\n",
      "\n",
      "episode 8, policy loss -0.04747543856501579\n",
      "\n",
      "episode 9, policy loss -0.028617996722459793\n",
      "\n",
      "episode 10, policy loss -0.06919283419847488\n",
      "\n",
      "episode 11, policy loss -0.004748993553221226\n",
      "\n",
      "episode 12, policy loss -0.05318434536457062\n",
      "\n",
      "episode 13, policy loss -3.2118012313731015e-05\n",
      "\n",
      "episode 14, policy loss -0.04107199236750603\n",
      "\n",
      "episode 15, policy loss -0.023935414850711823\n",
      "\n",
      "episode 16, policy loss -0.0629681646823883\n",
      "\n",
      "Policy train loss in epoch 1:-0.03979546759819641\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.06757374852895737\n",
      "\n",
      "episode 2, policy loss -0.048777926713228226\n",
      "\n",
      "episode 3, policy loss -0.0540052130818367\n",
      "\n",
      "episode 4, policy loss -0.017291883006691933\n",
      "\n",
      "episode 5, policy loss -0.07317665219306946\n",
      "\n",
      "episode 6, policy loss -0.04304445907473564\n",
      "\n",
      "episode 7, policy loss -0.0283438041806221\n",
      "\n",
      "episode 8, policy loss 0.0006980227772146463\n",
      "\n",
      "episode 9, policy loss -0.06204983592033386\n",
      "\n",
      "episode 10, policy loss -0.06851357966661453\n",
      "\n",
      "episode 11, policy loss -0.06262931227684021\n",
      "\n",
      "episode 12, policy loss -0.021354924887418747\n",
      "\n",
      "episode 13, policy loss -0.00438199145719409\n",
      "\n",
      "episode 14, policy loss -0.022082597017288208\n",
      "\n",
      "episode 15, policy loss -0.03889939934015274\n",
      "\n",
      "episode 16, policy loss -0.025288810953497887\n",
      "\n",
      "Policy train loss in epoch 2:-0.03979475722007919\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.026100745424628258\n",
      "\n",
      "episode 2, policy loss -0.06957435607910156\n",
      "\n",
      "episode 3, policy loss -0.006715364288538694\n",
      "\n",
      "episode 4, policy loss -0.02330060862004757\n",
      "\n",
      "episode 5, policy loss -0.02624768204987049\n",
      "\n",
      "episode 6, policy loss -0.02686109021306038\n",
      "\n",
      "episode 7, policy loss -0.05286557227373123\n",
      "\n",
      "episode 8, policy loss -0.06598091870546341\n",
      "\n",
      "episode 9, policy loss -0.035090371966362\n",
      "\n",
      "episode 10, policy loss -0.016744697466492653\n",
      "\n",
      "episode 11, policy loss -0.0002936525270342827\n",
      "\n",
      "episode 12, policy loss -0.06178613752126694\n",
      "\n",
      "episode 13, policy loss -0.06022384390234947\n",
      "\n",
      "episode 14, policy loss -0.04468419775366783\n",
      "\n",
      "episode 15, policy loss -0.07199657708406448\n",
      "\n",
      "episode 16, policy loss -0.04403472691774368\n",
      "\n",
      "Policy train loss in epoch 3:-0.039531283924588934\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17720654606819153\n",
      "\n",
      "episode 2, val func loss 0.20706330239772797\n",
      "\n",
      "episode 3, val func loss 0.18567126989364624\n",
      "\n",
      "episode 4, val func loss 0.18402813374996185\n",
      "\n",
      "episode 5, val func loss 0.21312177181243896\n",
      "\n",
      "episode 6, val func loss 0.19959458708763123\n",
      "\n",
      "episode 7, val func loss 0.2176211029291153\n",
      "\n",
      "episode 8, val func loss 0.1807042807340622\n",
      "\n",
      "episode 9, val func loss 0.17402112483978271\n",
      "\n",
      "episode 10, val func loss 0.17603397369384766\n",
      "\n",
      "episode 11, val func loss 0.17533202469348907\n",
      "\n",
      "episode 12, val func loss 0.16474224627017975\n",
      "\n",
      "episode 13, val func loss 0.1839100420475006\n",
      "\n",
      "episode 14, val func loss 0.20046205818653107\n",
      "\n",
      "episode 15, val func loss 0.18707077205181122\n",
      "\n",
      "episode 16, val func loss 0.1762579381465912\n",
      "\n",
      "Val func train loss in epoch 0:0.18767757341265678\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18669217824935913\n",
      "\n",
      "episode 2, val func loss 0.21199077367782593\n",
      "\n",
      "episode 3, val func loss 0.17570975422859192\n",
      "\n",
      "episode 4, val func loss 0.1978520154953003\n",
      "\n",
      "episode 5, val func loss 0.2079901099205017\n",
      "\n",
      "episode 6, val func loss 0.18495814502239227\n",
      "\n",
      "episode 7, val func loss 0.18423070013523102\n",
      "\n",
      "episode 8, val func loss 0.16506309807300568\n",
      "\n",
      "episode 9, val func loss 0.18092073500156403\n",
      "\n",
      "episode 10, val func loss 0.19921958446502686\n",
      "\n",
      "episode 11, val func loss 0.17647705972194672\n",
      "\n",
      "episode 12, val func loss 0.1759803593158722\n",
      "\n",
      "episode 13, val func loss 0.17370274662971497\n",
      "\n",
      "episode 14, val func loss 0.18451495468616486\n",
      "\n",
      "episode 15, val func loss 0.1776602417230606\n",
      "\n",
      "episode 16, val func loss 0.2182834893465042\n",
      "\n",
      "Val func train loss in epoch 1:0.1875778716057539\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.16517536342144012\n",
      "\n",
      "episode 2, val func loss 0.20711202919483185\n",
      "\n",
      "episode 3, val func loss 0.18026235699653625\n",
      "\n",
      "episode 4, val func loss 0.18448591232299805\n",
      "\n",
      "episode 5, val func loss 0.20025517046451569\n",
      "\n",
      "episode 6, val func loss 0.17651338875293732\n",
      "\n",
      "episode 7, val func loss 0.19827958941459656\n",
      "\n",
      "episode 8, val func loss 0.17594528198242188\n",
      "\n",
      "episode 9, val func loss 0.18421638011932373\n",
      "\n",
      "episode 10, val func loss 0.21146957576274872\n",
      "\n",
      "episode 11, val func loss 0.17679816484451294\n",
      "\n",
      "episode 12, val func loss 0.1758936047554016\n",
      "\n",
      "episode 13, val func loss 0.18656378984451294\n",
      "\n",
      "episode 14, val func loss 0.21624834835529327\n",
      "\n",
      "episode 15, val func loss 0.1852376013994217\n",
      "\n",
      "episode 16, val func loss 0.1750616431236267\n",
      "\n",
      "Val func train loss in epoch 2:0.18746988754719496\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18110093474388123\n",
      "\n",
      "episode 2, val func loss 0.17516064643859863\n",
      "\n",
      "episode 3, val func loss 0.17554563283920288\n",
      "\n",
      "episode 4, val func loss 0.20119823515415192\n",
      "\n",
      "episode 5, val func loss 0.16580608487129211\n",
      "\n",
      "episode 6, val func loss 0.18382367491722107\n",
      "\n",
      "episode 7, val func loss 0.17801252007484436\n",
      "\n",
      "episode 8, val func loss 0.173273965716362\n",
      "\n",
      "episode 9, val func loss 0.2122342586517334\n",
      "\n",
      "episode 10, val func loss 0.18677620589733124\n",
      "\n",
      "episode 11, val func loss 0.20747198164463043\n",
      "\n",
      "episode 12, val func loss 0.19867701828479767\n",
      "\n",
      "episode 13, val func loss 0.21614697575569153\n",
      "\n",
      "episode 14, val func loss 0.1868085414171219\n",
      "\n",
      "episode 15, val func loss 0.1838478446006775\n",
      "\n",
      "episode 16, val func loss 0.17720146477222443\n",
      "\n",
      "Val func train loss in epoch 3:0.18769287411123514\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1751403659582138\n",
      "\n",
      "episode 2, val func loss 0.1866503804922104\n",
      "\n",
      "episode 3, val func loss 0.1843271106481552\n",
      "\n",
      "episode 4, val func loss 0.2164682000875473\n",
      "\n",
      "episode 5, val func loss 0.18045827746391296\n",
      "\n",
      "episode 6, val func loss 0.21181567013263702\n",
      "\n",
      "episode 7, val func loss 0.1979920119047165\n",
      "\n",
      "episode 8, val func loss 0.19904978573322296\n",
      "\n",
      "episode 9, val func loss 0.17684368789196014\n",
      "\n",
      "episode 10, val func loss 0.2078418731689453\n",
      "\n",
      "episode 11, val func loss 0.17640922963619232\n",
      "\n",
      "episode 12, val func loss 0.17684835195541382\n",
      "\n",
      "episode 13, val func loss 0.16501882672309875\n",
      "\n",
      "episode 14, val func loss 0.1851578652858734\n",
      "\n",
      "episode 15, val func loss 0.1841302514076233\n",
      "\n",
      "episode 16, val func loss 0.1749168038368225\n",
      "\n",
      "Val func train loss in epoch 4:0.1874417932704091\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1752593070268631\n",
      "\n",
      "episode 2, val func loss 0.20175080001354218\n",
      "\n",
      "episode 3, val func loss 0.17999215424060822\n",
      "\n",
      "episode 4, val func loss 0.21814079582691193\n",
      "\n",
      "episode 5, val func loss 0.1764487773180008\n",
      "\n",
      "episode 6, val func loss 0.17596335709095\n",
      "\n",
      "episode 7, val func loss 0.186945840716362\n",
      "\n",
      "episode 8, val func loss 0.1648426651954651\n",
      "\n",
      "episode 9, val func loss 0.18527653813362122\n",
      "\n",
      "episode 10, val func loss 0.19809578359127045\n",
      "\n",
      "episode 11, val func loss 0.18587306141853333\n",
      "\n",
      "episode 12, val func loss 0.20771808922290802\n",
      "\n",
      "episode 13, val func loss 0.21160782873630524\n",
      "\n",
      "episode 14, val func loss 0.17373813688755035\n",
      "\n",
      "episode 15, val func loss 0.1852024346590042\n",
      "\n",
      "episode 16, val func loss 0.17716625332832336\n",
      "\n",
      "Val func train loss in epoch 5:0.18775136396288872\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1999272108078003\n",
      "\n",
      "episode 2, val func loss 0.18481217324733734\n",
      "\n",
      "episode 3, val func loss 0.18702414631843567\n",
      "\n",
      "episode 4, val func loss 0.18619298934936523\n",
      "\n",
      "episode 5, val func loss 0.1651080846786499\n",
      "\n",
      "episode 6, val func loss 0.1755456179380417\n",
      "\n",
      "episode 7, val func loss 0.17660367488861084\n",
      "\n",
      "episode 8, val func loss 0.1739024668931961\n",
      "\n",
      "episode 9, val func loss 0.19936363399028778\n",
      "\n",
      "episode 10, val func loss 0.17713388800621033\n",
      "\n",
      "episode 11, val func loss 0.18011027574539185\n",
      "\n",
      "episode 12, val func loss 0.2175532430410385\n",
      "\n",
      "episode 13, val func loss 0.20726118981838226\n",
      "\n",
      "episode 14, val func loss 0.21215052902698517\n",
      "\n",
      "episode 15, val func loss 0.184275284409523\n",
      "\n",
      "episode 16, val func loss 0.17598314583301544\n",
      "\n",
      "Val func train loss in epoch 6:0.18768422212451696\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.16497626900672913\n",
      "\n",
      "episode 2, val func loss 0.18424701690673828\n",
      "\n",
      "episode 3, val func loss 0.19973032176494598\n",
      "\n",
      "episode 4, val func loss 0.17594940960407257\n",
      "\n",
      "episode 5, val func loss 0.17387250065803528\n",
      "\n",
      "episode 6, val func loss 0.18033036589622498\n",
      "\n",
      "episode 7, val func loss 0.20745283365249634\n",
      "\n",
      "episode 8, val func loss 0.2124323695898056\n",
      "\n",
      "episode 9, val func loss 0.17754913866519928\n",
      "\n",
      "episode 10, val func loss 0.19906005263328552\n",
      "\n",
      "episode 11, val func loss 0.21696947515010834\n",
      "\n",
      "episode 12, val func loss 0.1870346963405609\n",
      "\n",
      "episode 13, val func loss 0.18437092006206512\n",
      "\n",
      "episode 14, val func loss 0.1761925220489502\n",
      "\n",
      "episode 15, val func loss 0.1873965859413147\n",
      "\n",
      "episode 16, val func loss 0.1771521121263504\n",
      "\n",
      "Val func train loss in epoch 7:0.18779478687793016\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17693708837032318\n",
      "\n",
      "episode 2, val func loss 0.20760340988636017\n",
      "\n",
      "episode 3, val func loss 0.19978274405002594\n",
      "\n",
      "episode 4, val func loss 0.21236006915569305\n",
      "\n",
      "episode 5, val func loss 0.1771870106458664\n",
      "\n",
      "episode 6, val func loss 0.19820939004421234\n",
      "\n",
      "episode 7, val func loss 0.18467123806476593\n",
      "\n",
      "episode 8, val func loss 0.17393316328525543\n",
      "\n",
      "episode 9, val func loss 0.21676822006702423\n",
      "\n",
      "episode 10, val func loss 0.17654100060462952\n",
      "\n",
      "episode 11, val func loss 0.1867787390947342\n",
      "\n",
      "episode 12, val func loss 0.1841314733028412\n",
      "\n",
      "episode 13, val func loss 0.1843358427286148\n",
      "\n",
      "episode 14, val func loss 0.16452471911907196\n",
      "\n",
      "episode 15, val func loss 0.17533369362354279\n",
      "\n",
      "episode 16, val func loss 0.18026718497276306\n",
      "\n",
      "Val func train loss in epoch 8:0.18746031168848276\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18408025801181793\n",
      "\n",
      "episode 2, val func loss 0.17553769052028656\n",
      "\n",
      "episode 3, val func loss 0.2180246114730835\n",
      "\n",
      "episode 4, val func loss 0.20739708840847015\n",
      "\n",
      "episode 5, val func loss 0.19952385127544403\n",
      "\n",
      "episode 6, val func loss 0.17379482090473175\n",
      "\n",
      "episode 7, val func loss 0.18497471511363983\n",
      "\n",
      "episode 8, val func loss 0.17637883126735687\n",
      "\n",
      "episode 9, val func loss 0.17522132396697998\n",
      "\n",
      "episode 10, val func loss 0.16493642330169678\n",
      "\n",
      "episode 11, val func loss 0.18509365618228912\n",
      "\n",
      "episode 12, val func loss 0.19879762828350067\n",
      "\n",
      "episode 13, val func loss 0.1770334243774414\n",
      "\n",
      "episode 14, val func loss 0.18648512661457062\n",
      "\n",
      "episode 15, val func loss 0.1810215711593628\n",
      "\n",
      "episode 16, val func loss 0.21164529025554657\n",
      "\n",
      "Val func train loss in epoch 9:0.18749664444476366\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19814284145832062\n",
      "\n",
      "episode 2, val func loss 0.19865413010120392\n",
      "\n",
      "episode 3, val func loss 0.21616750955581665\n",
      "\n",
      "episode 4, val func loss 0.1754058599472046\n",
      "\n",
      "episode 5, val func loss 0.176937535405159\n",
      "\n",
      "episode 6, val func loss 0.18689864873886108\n",
      "\n",
      "episode 7, val func loss 0.17578229308128357\n",
      "\n",
      "episode 8, val func loss 0.1846824586391449\n",
      "\n",
      "episode 9, val func loss 0.2073737531900406\n",
      "\n",
      "episode 10, val func loss 0.17690764367580414\n",
      "\n",
      "episode 11, val func loss 0.18377996981143951\n",
      "\n",
      "episode 12, val func loss 0.21379879117012024\n",
      "\n",
      "episode 13, val func loss 0.17711485922336578\n",
      "\n",
      "episode 14, val func loss 0.17986923456192017\n",
      "\n",
      "episode 15, val func loss 0.16514471173286438\n",
      "\n",
      "episode 16, val func loss 0.1855824887752533\n",
      "\n",
      "Val func train loss in epoch 10:0.18764017056673765\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18537084758281708\n",
      "\n",
      "episode 2, val func loss 0.17390680313110352\n",
      "\n",
      "episode 3, val func loss 0.1871374249458313\n",
      "\n",
      "episode 4, val func loss 0.16489902138710022\n",
      "\n",
      "episode 5, val func loss 0.17743432521820068\n",
      "\n",
      "episode 6, val func loss 0.18169169127941132\n",
      "\n",
      "episode 7, val func loss 0.21623243391513824\n",
      "\n",
      "episode 8, val func loss 0.18530456721782684\n",
      "\n",
      "episode 9, val func loss 0.198027566075325\n",
      "\n",
      "episode 10, val func loss 0.1763218343257904\n",
      "\n",
      "episode 11, val func loss 0.1847115010023117\n",
      "\n",
      "episode 12, val func loss 0.17655405402183533\n",
      "\n",
      "episode 13, val func loss 0.17482958734035492\n",
      "\n",
      "episode 14, val func loss 0.20160430669784546\n",
      "\n",
      "episode 15, val func loss 0.20718346536159515\n",
      "\n",
      "episode 16, val func loss 0.2129698246717453\n",
      "\n",
      "Val func train loss in epoch 11:0.18776120338588953\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1761714667081833\n",
      "\n",
      "episode 2, val func loss 0.1992957890033722\n",
      "\n",
      "episode 3, val func loss 0.17556217312812805\n",
      "\n",
      "episode 4, val func loss 0.16497378051280975\n",
      "\n",
      "episode 5, val func loss 0.18708595633506775\n",
      "\n",
      "episode 6, val func loss 0.18678876757621765\n",
      "\n",
      "episode 7, val func loss 0.18191027641296387\n",
      "\n",
      "episode 8, val func loss 0.17697328329086304\n",
      "\n",
      "episode 9, val func loss 0.1841709315776825\n",
      "\n",
      "episode 10, val func loss 0.17331334948539734\n",
      "\n",
      "episode 11, val func loss 0.1867562234401703\n",
      "\n",
      "episode 12, val func loss 0.2141343057155609\n",
      "\n",
      "episode 13, val func loss 0.19967655837535858\n",
      "\n",
      "episode 14, val func loss 0.17580485343933105\n",
      "\n",
      "episode 15, val func loss 0.216569721698761\n",
      "\n",
      "episode 16, val func loss 0.207694873213768\n",
      "\n",
      "Val func train loss in epoch 12:0.1879301443696022\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.174896240234375\n",
      "\n",
      "episode 2, val func loss 0.1859951913356781\n",
      "\n",
      "episode 3, val func loss 0.17546027898788452\n",
      "\n",
      "episode 4, val func loss 0.1805904060602188\n",
      "\n",
      "episode 5, val func loss 0.17823897302150726\n",
      "\n",
      "episode 6, val func loss 0.16559046506881714\n",
      "\n",
      "episode 7, val func loss 0.18376095592975616\n",
      "\n",
      "episode 8, val func loss 0.18753856420516968\n",
      "\n",
      "episode 9, val func loss 0.19891726970672607\n",
      "\n",
      "episode 10, val func loss 0.20728729665279388\n",
      "\n",
      "episode 11, val func loss 0.21155494451522827\n",
      "\n",
      "episode 12, val func loss 0.1766834706068039\n",
      "\n",
      "episode 13, val func loss 0.19833245873451233\n",
      "\n",
      "episode 14, val func loss 0.17691747844219208\n",
      "\n",
      "episode 15, val func loss 0.1842322200536728\n",
      "\n",
      "episode 16, val func loss 0.2162165492773056\n",
      "\n",
      "Val func train loss in epoch 13:0.1876382976770401\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18229879438877106\n",
      "\n",
      "episode 2, val func loss 0.1770440638065338\n",
      "\n",
      "episode 3, val func loss 0.2166052907705307\n",
      "\n",
      "episode 4, val func loss 0.20763199031352997\n",
      "\n",
      "episode 5, val func loss 0.1758989691734314\n",
      "\n",
      "episode 6, val func loss 0.212955042719841\n",
      "\n",
      "episode 7, val func loss 0.1749526411294937\n",
      "\n",
      "episode 8, val func loss 0.17733383178710938\n",
      "\n",
      "episode 9, val func loss 0.18469026684761047\n",
      "\n",
      "episode 10, val func loss 0.18407133221626282\n",
      "\n",
      "episode 11, val func loss 0.1990727186203003\n",
      "\n",
      "episode 12, val func loss 0.1744033247232437\n",
      "\n",
      "episode 13, val func loss 0.1868760883808136\n",
      "\n",
      "episode 14, val func loss 0.19785328209400177\n",
      "\n",
      "episode 15, val func loss 0.16515080630779266\n",
      "\n",
      "episode 16, val func loss 0.18627533316612244\n",
      "\n",
      "Val func train loss in epoch 14:0.1876946110278368\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.17481999099254608\n",
      "\n",
      "episode 2, val func loss 0.17571988701820374\n",
      "\n",
      "episode 3, val func loss 0.21750906109809875\n",
      "\n",
      "episode 4, val func loss 0.2127740979194641\n",
      "\n",
      "episode 5, val func loss 0.16472657024860382\n",
      "\n",
      "episode 6, val func loss 0.17668300867080688\n",
      "\n",
      "episode 7, val func loss 0.19840309023857117\n",
      "\n",
      "episode 8, val func loss 0.1849343329668045\n",
      "\n",
      "episode 9, val func loss 0.2075629085302353\n",
      "\n",
      "episode 10, val func loss 0.1842421293258667\n",
      "\n",
      "episode 11, val func loss 0.18657851219177246\n",
      "\n",
      "episode 12, val func loss 0.17693565785884857\n",
      "\n",
      "episode 13, val func loss 0.19908548891544342\n",
      "\n",
      "episode 14, val func loss 0.18489068746566772\n",
      "\n",
      "episode 15, val func loss 0.17572805285453796\n",
      "\n",
      "episode 16, val func loss 0.18105635046958923\n",
      "\n",
      "Val func train loss in epoch 15:0.18760311417281628\n",
      "***********************TIME WAS 5.00222608645757 min*****************************\n",
      "\n",
      "**********************ROUND 126 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.013138258829712868\n",
      "\n",
      "episode 2, policy loss -0.03792750462889671\n",
      "\n",
      "episode 3, policy loss -0.022668888792395592\n",
      "\n",
      "episode 4, policy loss -0.03274410590529442\n",
      "\n",
      "episode 5, policy loss -0.042425885796546936\n",
      "\n",
      "episode 6, policy loss -0.03358340635895729\n",
      "\n",
      "episode 7, policy loss -0.006605715490877628\n",
      "\n",
      "episode 8, policy loss -0.04122232273221016\n",
      "\n",
      "episode 9, policy loss -0.005654613953083754\n",
      "\n",
      "episode 10, policy loss 0.017860284075140953\n",
      "\n",
      "episode 11, policy loss -0.08534172177314758\n",
      "\n",
      "episode 12, policy loss -0.06016315519809723\n",
      "\n",
      "episode 13, policy loss -0.027829643338918686\n",
      "\n",
      "episode 14, policy loss 0.00031084808870218694\n",
      "\n",
      "episode 15, policy loss -0.013386975973844528\n",
      "\n",
      "episode 16, policy loss -0.018030384555459023\n",
      "\n",
      "Policy train loss in epoch 0:-0.026409465697724954\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.060009684413671494\n",
      "\n",
      "episode 2, policy loss -0.0001556414645165205\n",
      "\n",
      "episode 3, policy loss -0.0029973634518682957\n",
      "\n",
      "episode 4, policy loss -0.03346264734864235\n",
      "\n",
      "episode 5, policy loss -0.015433724038302898\n",
      "\n",
      "episode 6, policy loss -0.019536830484867096\n",
      "\n",
      "episode 7, policy loss -0.042013831436634064\n",
      "\n",
      "episode 8, policy loss 0.017237652093172073\n",
      "\n",
      "episode 9, policy loss -0.024368565529584885\n",
      "\n",
      "episode 10, policy loss -0.03224955499172211\n",
      "\n",
      "episode 11, policy loss -0.035442110151052475\n",
      "\n",
      "episode 12, policy loss -0.008096500299870968\n",
      "\n",
      "episode 13, policy loss -0.021956009790301323\n",
      "\n",
      "episode 14, policy loss -0.04237154498696327\n",
      "\n",
      "episode 15, policy loss -0.08753344416618347\n",
      "\n",
      "episode 16, policy loss -0.04599380120635033\n",
      "\n",
      "Policy train loss in epoch 1:-0.028398975104209967\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.02490854449570179\n",
      "\n",
      "episode 2, policy loss -0.03486344963312149\n",
      "\n",
      "episode 3, policy loss 0.014624598436057568\n",
      "\n",
      "episode 4, policy loss -0.019739681854844093\n",
      "\n",
      "episode 5, policy loss -0.06301618367433548\n",
      "\n",
      "episode 6, policy loss -0.04319862648844719\n",
      "\n",
      "episode 7, policy loss -0.08804871141910553\n",
      "\n",
      "episode 8, policy loss -0.03712925687432289\n",
      "\n",
      "episode 9, policy loss -0.00590903963893652\n",
      "\n",
      "episode 10, policy loss -0.01066666841506958\n",
      "\n",
      "episode 11, policy loss -0.030516600236296654\n",
      "\n",
      "episode 12, policy loss -0.02194196730852127\n",
      "\n",
      "episode 13, policy loss -0.04724215716123581\n",
      "\n",
      "episode 14, policy loss -0.015825925394892693\n",
      "\n",
      "episode 15, policy loss -0.003175894031301141\n",
      "\n",
      "episode 16, policy loss -0.04480597376823425\n",
      "\n",
      "Policy train loss in epoch 2:-0.0297727551223943\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.021679464727640152\n",
      "\n",
      "episode 2, policy loss -0.03698999062180519\n",
      "\n",
      "episode 3, policy loss -0.043736595660448074\n",
      "\n",
      "episode 4, policy loss -0.035305868834257126\n",
      "\n",
      "episode 5, policy loss -0.021820805966854095\n",
      "\n",
      "episode 6, policy loss 0.014443616382777691\n",
      "\n",
      "episode 7, policy loss -0.03145907074213028\n",
      "\n",
      "episode 8, policy loss -0.007243307773023844\n",
      "\n",
      "episode 9, policy loss -0.04701048880815506\n",
      "\n",
      "episode 10, policy loss -0.08782836049795151\n",
      "\n",
      "episode 11, policy loss -0.00925873126834631\n",
      "\n",
      "episode 12, policy loss -0.0632033497095108\n",
      "\n",
      "episode 13, policy loss -0.002751449588686228\n",
      "\n",
      "episode 14, policy loss -0.04504132270812988\n",
      "\n",
      "episode 15, policy loss -0.017049364745616913\n",
      "\n",
      "episode 16, policy loss -0.026728060096502304\n",
      "\n",
      "Policy train loss in epoch 3:-0.030166413460392505\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.20031960308551788\n",
      "\n",
      "episode 2, val func loss 0.18115107715129852\n",
      "\n",
      "episode 3, val func loss 0.20109224319458008\n",
      "\n",
      "episode 4, val func loss 0.19524550437927246\n",
      "\n",
      "episode 5, val func loss 0.1691664159297943\n",
      "\n",
      "episode 6, val func loss 0.18363463878631592\n",
      "\n",
      "episode 7, val func loss 0.21366633474826813\n",
      "\n",
      "episode 8, val func loss 0.2294633537530899\n",
      "\n",
      "episode 9, val func loss 0.18381144106388092\n",
      "\n",
      "episode 10, val func loss 0.17592990398406982\n",
      "\n",
      "episode 11, val func loss 0.17532886564731598\n",
      "\n",
      "episode 12, val func loss 0.17129488289356232\n",
      "\n",
      "episode 13, val func loss 0.18275216221809387\n",
      "\n",
      "episode 14, val func loss 0.19312037527561188\n",
      "\n",
      "episode 15, val func loss 0.18719930946826935\n",
      "\n",
      "episode 16, val func loss 0.18747703731060028\n",
      "\n",
      "Val func train loss in epoch 0:0.18941582180559635\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1927025467157364\n",
      "\n",
      "episode 2, val func loss 0.183811217546463\n",
      "\n",
      "episode 3, val func loss 0.18709196150302887\n",
      "\n",
      "episode 4, val func loss 0.2258087545633316\n",
      "\n",
      "episode 5, val func loss 0.1843429058790207\n",
      "\n",
      "episode 6, val func loss 0.20023761689662933\n",
      "\n",
      "episode 7, val func loss 0.19537846744060516\n",
      "\n",
      "episode 8, val func loss 0.2117834985256195\n",
      "\n",
      "episode 9, val func loss 0.18779127299785614\n",
      "\n",
      "episode 10, val func loss 0.17618553340435028\n",
      "\n",
      "episode 11, val func loss 0.18276585638523102\n",
      "\n",
      "episode 12, val func loss 0.18124864995479584\n",
      "\n",
      "episode 13, val func loss 0.17055313289165497\n",
      "\n",
      "episode 14, val func loss 0.20122092962265015\n",
      "\n",
      "episode 15, val func loss 0.17545762658119202\n",
      "\n",
      "episode 16, val func loss 0.16803213953971863\n",
      "\n",
      "Val func train loss in epoch 1:0.18902575690299273\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.23226489126682281\n",
      "\n",
      "episode 2, val func loss 0.1959836781024933\n",
      "\n",
      "episode 3, val func loss 0.18882018327713013\n",
      "\n",
      "episode 4, val func loss 0.20048674941062927\n",
      "\n",
      "episode 5, val func loss 0.1843370795249939\n",
      "\n",
      "episode 6, val func loss 0.21170668303966522\n",
      "\n",
      "episode 7, val func loss 0.2026177942752838\n",
      "\n",
      "episode 8, val func loss 0.17471227049827576\n",
      "\n",
      "episode 9, val func loss 0.1825515478849411\n",
      "\n",
      "episode 10, val func loss 0.18778061866760254\n",
      "\n",
      "episode 11, val func loss 0.1715572327375412\n",
      "\n",
      "episode 12, val func loss 0.18385672569274902\n",
      "\n",
      "episode 13, val func loss 0.17569519579410553\n",
      "\n",
      "episode 14, val func loss 0.17599093914031982\n",
      "\n",
      "episode 15, val func loss 0.1970447450876236\n",
      "\n",
      "episode 16, val func loss 0.18278656899929047\n",
      "\n",
      "Val func train loss in epoch 2:0.19051205646246672\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18398770689964294\n",
      "\n",
      "episode 2, val func loss 0.2277313619852066\n",
      "\n",
      "episode 3, val func loss 0.20016726851463318\n",
      "\n",
      "episode 4, val func loss 0.17592810094356537\n",
      "\n",
      "episode 5, val func loss 0.21208953857421875\n",
      "\n",
      "episode 6, val func loss 0.1951945424079895\n",
      "\n",
      "episode 7, val func loss 0.20104534924030304\n",
      "\n",
      "episode 8, val func loss 0.19383393228054047\n",
      "\n",
      "episode 9, val func loss 0.18739581108093262\n",
      "\n",
      "episode 10, val func loss 0.18240287899971008\n",
      "\n",
      "episode 11, val func loss 0.1752343773841858\n",
      "\n",
      "episode 12, val func loss 0.18140478432178497\n",
      "\n",
      "episode 13, val func loss 0.18353112041950226\n",
      "\n",
      "episode 14, val func loss 0.1760571151971817\n",
      "\n",
      "episode 15, val func loss 0.18796950578689575\n",
      "\n",
      "episode 16, val func loss 0.16969919204711914\n",
      "\n",
      "Val func train loss in epoch 3:0.18960453663021326\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19562852382659912\n",
      "\n",
      "episode 2, val func loss 0.1824774146080017\n",
      "\n",
      "episode 3, val func loss 0.20134755969047546\n",
      "\n",
      "episode 4, val func loss 0.1936979740858078\n",
      "\n",
      "episode 5, val func loss 0.21218112111091614\n",
      "\n",
      "episode 6, val func loss 0.17174260318279266\n",
      "\n",
      "episode 7, val func loss 0.2262602150440216\n",
      "\n",
      "episode 8, val func loss 0.18187378346920013\n",
      "\n",
      "episode 9, val func loss 0.177774116396904\n",
      "\n",
      "episode 10, val func loss 0.1869194209575653\n",
      "\n",
      "episode 11, val func loss 0.17603625357151031\n",
      "\n",
      "episode 12, val func loss 0.1874845325946808\n",
      "\n",
      "episode 13, val func loss 0.1695953905582428\n",
      "\n",
      "episode 14, val func loss 0.18383897840976715\n",
      "\n",
      "episode 15, val func loss 0.18389669060707092\n",
      "\n",
      "episode 16, val func loss 0.2013404369354248\n",
      "\n",
      "Val func train loss in epoch 4:0.1895059384405613\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.21346116065979004\n",
      "\n",
      "episode 2, val func loss 0.22971469163894653\n",
      "\n",
      "episode 3, val func loss 0.18765005469322205\n",
      "\n",
      "episode 4, val func loss 0.17614799737930298\n",
      "\n",
      "episode 5, val func loss 0.18723830580711365\n",
      "\n",
      "episode 6, val func loss 0.18173906207084656\n",
      "\n",
      "episode 7, val func loss 0.17218375205993652\n",
      "\n",
      "episode 8, val func loss 0.1841181516647339\n",
      "\n",
      "episode 9, val func loss 0.1838444024324417\n",
      "\n",
      "episode 10, val func loss 0.20027293264865875\n",
      "\n",
      "episode 11, val func loss 0.2009742259979248\n",
      "\n",
      "episode 12, val func loss 0.17558948695659637\n",
      "\n",
      "episode 13, val func loss 0.19558241963386536\n",
      "\n",
      "episode 14, val func loss 0.18247827887535095\n",
      "\n",
      "episode 15, val func loss 0.193753182888031\n",
      "\n",
      "episode 16, val func loss 0.17063570022583008\n",
      "\n",
      "Val func train loss in epoch 5:0.18971148785203695\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.2126019150018692\n",
      "\n",
      "episode 2, val func loss 0.19519992172718048\n",
      "\n",
      "episode 3, val func loss 0.18370085954666138\n",
      "\n",
      "episode 4, val func loss 0.18738391995429993\n",
      "\n",
      "episode 5, val func loss 0.1871473789215088\n",
      "\n",
      "episode 6, val func loss 0.17138268053531647\n",
      "\n",
      "episode 7, val func loss 0.20008286833763123\n",
      "\n",
      "episode 8, val func loss 0.18145540356636047\n",
      "\n",
      "episode 9, val func loss 0.17132225632667542\n",
      "\n",
      "episode 10, val func loss 0.22785551846027374\n",
      "\n",
      "episode 11, val func loss 0.20111586153507233\n",
      "\n",
      "episode 12, val func loss 0.18236641585826874\n",
      "\n",
      "episode 13, val func loss 0.19368702173233032\n",
      "\n",
      "episode 14, val func loss 0.1838139295578003\n",
      "\n",
      "episode 15, val func loss 0.1760537177324295\n",
      "\n",
      "episode 16, val func loss 0.17571868002414703\n",
      "\n",
      "Val func train loss in epoch 6:0.18943052180111408\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19520778954029083\n",
      "\n",
      "episode 2, val func loss 0.16983163356781006\n",
      "\n",
      "episode 3, val func loss 0.1753830760717392\n",
      "\n",
      "episode 4, val func loss 0.1758878529071808\n",
      "\n",
      "episode 5, val func loss 0.20158693194389343\n",
      "\n",
      "episode 6, val func loss 0.18382520973682404\n",
      "\n",
      "episode 7, val func loss 0.18232715129852295\n",
      "\n",
      "episode 8, val func loss 0.21261899173259735\n",
      "\n",
      "episode 9, val func loss 0.20091213285923004\n",
      "\n",
      "episode 10, val func loss 0.17086590826511383\n",
      "\n",
      "episode 11, val func loss 0.19312763214111328\n",
      "\n",
      "episode 12, val func loss 0.18707305192947388\n",
      "\n",
      "episode 13, val func loss 0.187208890914917\n",
      "\n",
      "episode 14, val func loss 0.18167205154895782\n",
      "\n",
      "episode 15, val func loss 0.18388406932353973\n",
      "\n",
      "episode 16, val func loss 0.22598282992839813\n",
      "\n",
      "Val func train loss in epoch 7:0.18921220023185015\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17688338458538055\n",
      "\n",
      "episode 2, val func loss 0.18674983084201813\n",
      "\n",
      "episode 3, val func loss 0.20155729353427887\n",
      "\n",
      "episode 4, val func loss 0.18746940791606903\n",
      "\n",
      "episode 5, val func loss 0.18361896276474\n",
      "\n",
      "episode 6, val func loss 0.19320057332515717\n",
      "\n",
      "episode 7, val func loss 0.1811532825231552\n",
      "\n",
      "episode 8, val func loss 0.2123711258172989\n",
      "\n",
      "episode 9, val func loss 0.19518183171749115\n",
      "\n",
      "episode 10, val func loss 0.22741810977458954\n",
      "\n",
      "episode 11, val func loss 0.18274034559726715\n",
      "\n",
      "episode 12, val func loss 0.17092815041542053\n",
      "\n",
      "episode 13, val func loss 0.17139732837677002\n",
      "\n",
      "episode 14, val func loss 0.1753542572259903\n",
      "\n",
      "episode 15, val func loss 0.20122824609279633\n",
      "\n",
      "episode 16, val func loss 0.18377134203910828\n",
      "\n",
      "Val func train loss in epoch 8:0.1894389670342207\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18145707249641418\n",
      "\n",
      "episode 2, val func loss 0.1875568926334381\n",
      "\n",
      "episode 3, val func loss 0.18796506524085999\n",
      "\n",
      "episode 4, val func loss 0.17078842222690582\n",
      "\n",
      "episode 5, val func loss 0.1825425624847412\n",
      "\n",
      "episode 6, val func loss 0.22770249843597412\n",
      "\n",
      "episode 7, val func loss 0.21200114488601685\n",
      "\n",
      "episode 8, val func loss 0.17126242816448212\n",
      "\n",
      "episode 9, val func loss 0.17699266970157623\n",
      "\n",
      "episode 10, val func loss 0.20005235075950623\n",
      "\n",
      "episode 11, val func loss 0.18375077843666077\n",
      "\n",
      "episode 12, val func loss 0.19308936595916748\n",
      "\n",
      "episode 13, val func loss 0.1953326165676117\n",
      "\n",
      "episode 14, val func loss 0.17569145560264587\n",
      "\n",
      "episode 15, val func loss 0.20073460042476654\n",
      "\n",
      "episode 16, val func loss 0.18371474742889404\n",
      "\n",
      "Val func train loss in epoch 9:0.18941466696560383\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.2273254096508026\n",
      "\n",
      "episode 2, val func loss 0.19505132734775543\n",
      "\n",
      "episode 3, val func loss 0.170612633228302\n",
      "\n",
      "episode 4, val func loss 0.2119559645652771\n",
      "\n",
      "episode 5, val func loss 0.18244922161102295\n",
      "\n",
      "episode 6, val func loss 0.19334697723388672\n",
      "\n",
      "episode 7, val func loss 0.18364231288433075\n",
      "\n",
      "episode 8, val func loss 0.17601066827774048\n",
      "\n",
      "episode 9, val func loss 0.17114205658435822\n",
      "\n",
      "episode 10, val func loss 0.18767280876636505\n",
      "\n",
      "episode 11, val func loss 0.2008608728647232\n",
      "\n",
      "episode 12, val func loss 0.20100538432598114\n",
      "\n",
      "episode 13, val func loss 0.18372514843940735\n",
      "\n",
      "episode 14, val func loss 0.18100233376026154\n",
      "\n",
      "episode 15, val func loss 0.1755627989768982\n",
      "\n",
      "episode 16, val func loss 0.18749797344207764\n",
      "\n",
      "Val func train loss in epoch 10:0.1893039932474494\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.20064395666122437\n",
      "\n",
      "episode 2, val func loss 0.19297575950622559\n",
      "\n",
      "episode 3, val func loss 0.20114567875862122\n",
      "\n",
      "episode 4, val func loss 0.18376995623111725\n",
      "\n",
      "episode 5, val func loss 0.1951798051595688\n",
      "\n",
      "episode 6, val func loss 0.18268822133541107\n",
      "\n",
      "episode 7, val func loss 0.18748939037322998\n",
      "\n",
      "episode 8, val func loss 0.1875913292169571\n",
      "\n",
      "episode 9, val func loss 0.18395058810710907\n",
      "\n",
      "episode 10, val func loss 0.1756492555141449\n",
      "\n",
      "episode 11, val func loss 0.22708098590373993\n",
      "\n",
      "episode 12, val func loss 0.1706450879573822\n",
      "\n",
      "episode 13, val func loss 0.21230530738830566\n",
      "\n",
      "episode 14, val func loss 0.18127362430095673\n",
      "\n",
      "episode 15, val func loss 0.1759600043296814\n",
      "\n",
      "episode 16, val func loss 0.17071405053138733\n",
      "\n",
      "Val func train loss in epoch 11:0.1893164375796914\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18358474969863892\n",
      "\n",
      "episode 2, val func loss 0.18849079310894012\n",
      "\n",
      "episode 3, val func loss 0.16882258653640747\n",
      "\n",
      "episode 4, val func loss 0.1810595989227295\n",
      "\n",
      "episode 5, val func loss 0.1823243498802185\n",
      "\n",
      "episode 6, val func loss 0.1943250298500061\n",
      "\n",
      "episode 7, val func loss 0.17564354836940765\n",
      "\n",
      "episode 8, val func loss 0.17564721405506134\n",
      "\n",
      "episode 9, val func loss 0.20090579986572266\n",
      "\n",
      "episode 10, val func loss 0.1710641086101532\n",
      "\n",
      "episode 11, val func loss 0.22677753865718842\n",
      "\n",
      "episode 12, val func loss 0.18383029103279114\n",
      "\n",
      "episode 13, val func loss 0.21165677905082703\n",
      "\n",
      "episode 14, val func loss 0.19527478516101837\n",
      "\n",
      "episode 15, val func loss 0.20145532488822937\n",
      "\n",
      "episode 16, val func loss 0.1878177374601364\n",
      "\n",
      "Val func train loss in epoch 12:0.18929251469671726\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1840774118900299\n",
      "\n",
      "episode 2, val func loss 0.2013237625360489\n",
      "\n",
      "episode 3, val func loss 0.1871631145477295\n",
      "\n",
      "episode 4, val func loss 0.2274528592824936\n",
      "\n",
      "episode 5, val func loss 0.17097166180610657\n",
      "\n",
      "episode 6, val func loss 0.1694709211587906\n",
      "\n",
      "episode 7, val func loss 0.17606458067893982\n",
      "\n",
      "episode 8, val func loss 0.213033989071846\n",
      "\n",
      "episode 9, val func loss 0.17572365701198578\n",
      "\n",
      "episode 10, val func loss 0.19474299252033234\n",
      "\n",
      "episode 11, val func loss 0.18228983879089355\n",
      "\n",
      "episode 12, val func loss 0.18120256066322327\n",
      "\n",
      "episode 13, val func loss 0.1879512518644333\n",
      "\n",
      "episode 14, val func loss 0.19526639580726624\n",
      "\n",
      "episode 15, val func loss 0.2001943141222\n",
      "\n",
      "episode 16, val func loss 0.18448308110237122\n",
      "\n",
      "Val func train loss in epoch 13:0.18946327455341816\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18422433733940125\n",
      "\n",
      "episode 2, val func loss 0.18360790610313416\n",
      "\n",
      "episode 3, val func loss 0.1723177284002304\n",
      "\n",
      "episode 4, val func loss 0.18389615416526794\n",
      "\n",
      "episode 5, val func loss 0.18124458193778992\n",
      "\n",
      "episode 6, val func loss 0.19431035220623016\n",
      "\n",
      "episode 7, val func loss 0.20152497291564941\n",
      "\n",
      "episode 8, val func loss 0.19575244188308716\n",
      "\n",
      "episode 9, val func loss 0.20107634365558624\n",
      "\n",
      "episode 10, val func loss 0.17546206712722778\n",
      "\n",
      "episode 11, val func loss 0.17032605409622192\n",
      "\n",
      "episode 12, val func loss 0.22767509520053864\n",
      "\n",
      "episode 13, val func loss 0.2123214304447174\n",
      "\n",
      "episode 14, val func loss 0.18729722499847412\n",
      "\n",
      "episode 15, val func loss 0.18749099969863892\n",
      "\n",
      "episode 16, val func loss 0.17687715590000153\n",
      "\n",
      "Val func train loss in epoch 14:0.1897128028795123\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19550900161266327\n",
      "\n",
      "episode 2, val func loss 0.18149268627166748\n",
      "\n",
      "episode 3, val func loss 0.2002488076686859\n",
      "\n",
      "episode 4, val func loss 0.21165728569030762\n",
      "\n",
      "episode 5, val func loss 0.18726585805416107\n",
      "\n",
      "episode 6, val func loss 0.22713544964790344\n",
      "\n",
      "episode 7, val func loss 0.17091499269008636\n",
      "\n",
      "episode 8, val func loss 0.19270068407058716\n",
      "\n",
      "episode 9, val func loss 0.1836109459400177\n",
      "\n",
      "episode 10, val func loss 0.1826762557029724\n",
      "\n",
      "episode 11, val func loss 0.18728765845298767\n",
      "\n",
      "episode 12, val func loss 0.18361973762512207\n",
      "\n",
      "episode 13, val func loss 0.1711001992225647\n",
      "\n",
      "episode 14, val func loss 0.17592328786849976\n",
      "\n",
      "episode 15, val func loss 0.17558029294013977\n",
      "\n",
      "episode 16, val func loss 0.201118603348732\n",
      "\n",
      "Val func train loss in epoch 15:0.18924010917544365\n",
      "***********************TIME WAS 5.005689597129821 min*****************************\n",
      "\n",
      "**********************ROUND 127 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.04894675686955452\n",
      "\n",
      "episode 2, policy loss -0.03382918983697891\n",
      "\n",
      "episode 3, policy loss -0.040662191808223724\n",
      "\n",
      "episode 4, policy loss -0.05877883359789848\n",
      "\n",
      "episode 5, policy loss -0.06894848495721817\n",
      "\n",
      "episode 6, policy loss -0.05098942667245865\n",
      "\n",
      "episode 7, policy loss -0.013710393570363522\n",
      "\n",
      "episode 8, policy loss -0.074180468916893\n",
      "\n",
      "episode 9, policy loss -0.03375330939888954\n",
      "\n",
      "episode 10, policy loss -0.039621781557798386\n",
      "\n",
      "episode 11, policy loss -0.04882471263408661\n",
      "\n",
      "episode 12, policy loss -0.050576042383909225\n",
      "\n",
      "episode 13, policy loss -0.06217961013317108\n",
      "\n",
      "episode 14, policy loss -0.018902283161878586\n",
      "\n",
      "episode 15, policy loss -0.07528793066740036\n",
      "\n",
      "episode 16, policy loss -0.03873540088534355\n",
      "\n",
      "Policy train loss in epoch 0:-0.047370426065754145\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.033627621829509735\n",
      "\n",
      "episode 2, policy loss -0.06358566135168076\n",
      "\n",
      "episode 3, policy loss -0.06451402604579926\n",
      "\n",
      "episode 4, policy loss -0.03676720708608627\n",
      "\n",
      "episode 5, policy loss -0.04933059960603714\n",
      "\n",
      "episode 6, policy loss -0.01656794548034668\n",
      "\n",
      "episode 7, policy loss -0.0511978343129158\n",
      "\n",
      "episode 8, policy loss -0.0765092745423317\n",
      "\n",
      "episode 9, policy loss -0.05246156454086304\n",
      "\n",
      "episode 10, policy loss -0.02190532721579075\n",
      "\n",
      "episode 11, policy loss -0.07209789752960205\n",
      "\n",
      "episode 12, policy loss -0.043947700411081314\n",
      "\n",
      "episode 13, policy loss -0.05958937481045723\n",
      "\n",
      "episode 14, policy loss -0.07541326433420181\n",
      "\n",
      "episode 15, policy loss -0.044345516711473465\n",
      "\n",
      "episode 16, policy loss -0.04045054689049721\n",
      "\n",
      "Policy train loss in epoch 1:-0.05014446016866714\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.0767977386713028\n",
      "\n",
      "episode 2, policy loss -0.0617469847202301\n",
      "\n",
      "episode 3, policy loss -0.021338149905204773\n",
      "\n",
      "episode 4, policy loss -0.051437489688396454\n",
      "\n",
      "episode 5, policy loss -0.03891487792134285\n",
      "\n",
      "episode 6, policy loss -0.045605603605508804\n",
      "\n",
      "episode 7, policy loss -0.05176226422190666\n",
      "\n",
      "episode 8, policy loss -0.07641293853521347\n",
      "\n",
      "episode 9, policy loss -0.040252819657325745\n",
      "\n",
      "episode 10, policy loss -0.07364718616008759\n",
      "\n",
      "episode 11, policy loss -0.05042734369635582\n",
      "\n",
      "episode 12, policy loss -0.05646796524524689\n",
      "\n",
      "episode 13, policy loss -0.04330342635512352\n",
      "\n",
      "episode 14, policy loss -0.06507309526205063\n",
      "\n",
      "episode 15, policy loss -0.01654871180653572\n",
      "\n",
      "episode 16, policy loss -0.03486406058073044\n",
      "\n",
      "Policy train loss in epoch 2:-0.05028754100203514\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.045566994696855545\n",
      "\n",
      "episode 2, policy loss -0.0728117823600769\n",
      "\n",
      "episode 3, policy loss -0.052034538239240646\n",
      "\n",
      "episode 4, policy loss -0.03513982519507408\n",
      "\n",
      "episode 5, policy loss -0.05220587179064751\n",
      "\n",
      "episode 6, policy loss -0.06402131915092468\n",
      "\n",
      "episode 7, policy loss -0.05802240967750549\n",
      "\n",
      "episode 8, policy loss -0.07740838825702667\n",
      "\n",
      "episode 9, policy loss -0.06350230425596237\n",
      "\n",
      "episode 10, policy loss -0.02053559571504593\n",
      "\n",
      "episode 11, policy loss -0.04296521097421646\n",
      "\n",
      "episode 12, policy loss -0.07702948153018951\n",
      "\n",
      "episode 13, policy loss -0.039756953716278076\n",
      "\n",
      "episode 14, policy loss -0.040940526872873306\n",
      "\n",
      "episode 15, policy loss -0.05080276355147362\n",
      "\n",
      "episode 16, policy loss -0.01613815873861313\n",
      "\n",
      "Policy train loss in epoch 3:-0.050555132795125246\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1781555712223053\n",
      "\n",
      "episode 2, val func loss 0.19300439953804016\n",
      "\n",
      "episode 3, val func loss 0.17807137966156006\n",
      "\n",
      "episode 4, val func loss 0.18791747093200684\n",
      "\n",
      "episode 5, val func loss 0.1956816166639328\n",
      "\n",
      "episode 6, val func loss 0.20379245281219482\n",
      "\n",
      "episode 7, val func loss 0.17744694650173187\n",
      "\n",
      "episode 8, val func loss 0.16646692156791687\n",
      "\n",
      "episode 9, val func loss 0.2027316391468048\n",
      "\n",
      "episode 10, val func loss 0.19069978594779968\n",
      "\n",
      "episode 11, val func loss 0.19980138540267944\n",
      "\n",
      "episode 12, val func loss 0.1726914942264557\n",
      "\n",
      "episode 13, val func loss 0.18860730528831482\n",
      "\n",
      "episode 14, val func loss 0.17532794177532196\n",
      "\n",
      "episode 15, val func loss 0.1658840924501419\n",
      "\n",
      "episode 16, val func loss 0.19791418313980103\n",
      "\n",
      "Val func train loss in epoch 0:0.185887161642313\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1726587414741516\n",
      "\n",
      "episode 2, val func loss 0.17703580856323242\n",
      "\n",
      "episode 3, val func loss 0.19978120923042297\n",
      "\n",
      "episode 4, val func loss 0.2033899426460266\n",
      "\n",
      "episode 5, val func loss 0.1884802281856537\n",
      "\n",
      "episode 6, val func loss 0.1928400844335556\n",
      "\n",
      "episode 7, val func loss 0.16575711965560913\n",
      "\n",
      "episode 8, val func loss 0.17579129338264465\n",
      "\n",
      "episode 9, val func loss 0.1660633087158203\n",
      "\n",
      "episode 10, val func loss 0.18755216896533966\n",
      "\n",
      "episode 11, val func loss 0.20258647203445435\n",
      "\n",
      "episode 12, val func loss 0.19536027312278748\n",
      "\n",
      "episode 13, val func loss 0.1779467612504959\n",
      "\n",
      "episode 14, val func loss 0.17849478125572205\n",
      "\n",
      "episode 15, val func loss 0.19065368175506592\n",
      "\n",
      "episode 16, val func loss 0.1976427435874939\n",
      "\n",
      "Val func train loss in epoch 1:0.18575216364115477\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.16515478491783142\n",
      "\n",
      "episode 2, val func loss 0.1930048167705536\n",
      "\n",
      "episode 3, val func loss 0.20303578674793243\n",
      "\n",
      "episode 4, val func loss 0.1782529354095459\n",
      "\n",
      "episode 5, val func loss 0.16625986993312836\n",
      "\n",
      "episode 6, val func loss 0.176829531788826\n",
      "\n",
      "episode 7, val func loss 0.19509123265743256\n",
      "\n",
      "episode 8, val func loss 0.1888260692358017\n",
      "\n",
      "episode 9, val func loss 0.199542835354805\n",
      "\n",
      "episode 10, val func loss 0.2035706639289856\n",
      "\n",
      "episode 11, val func loss 0.17815320193767548\n",
      "\n",
      "episode 12, val func loss 0.19822485744953156\n",
      "\n",
      "episode 13, val func loss 0.17537063360214233\n",
      "\n",
      "episode 14, val func loss 0.19083736836910248\n",
      "\n",
      "episode 15, val func loss 0.18786460161209106\n",
      "\n",
      "episode 16, val func loss 0.17282550036907196\n",
      "\n",
      "Val func train loss in epoch 2:0.1858027931302786\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19564765691757202\n",
      "\n",
      "episode 2, val func loss 0.1977437138557434\n",
      "\n",
      "episode 3, val func loss 0.16614662110805511\n",
      "\n",
      "episode 4, val func loss 0.20365402102470398\n",
      "\n",
      "episode 5, val func loss 0.17692255973815918\n",
      "\n",
      "episode 6, val func loss 0.19284369051456451\n",
      "\n",
      "episode 7, val func loss 0.17261932790279388\n",
      "\n",
      "episode 8, val func loss 0.165578693151474\n",
      "\n",
      "episode 9, val func loss 0.18786144256591797\n",
      "\n",
      "episode 10, val func loss 0.19102159142494202\n",
      "\n",
      "episode 11, val func loss 0.1781381517648697\n",
      "\n",
      "episode 12, val func loss 0.1885918378829956\n",
      "\n",
      "episode 13, val func loss 0.20257984101772308\n",
      "\n",
      "episode 14, val func loss 0.17874646186828613\n",
      "\n",
      "episode 15, val func loss 0.1760701686143875\n",
      "\n",
      "episode 16, val func loss 0.1995905190706253\n",
      "\n",
      "Val func train loss in epoch 3:0.18585976865142584\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1929902583360672\n",
      "\n",
      "episode 2, val func loss 0.1906794011592865\n",
      "\n",
      "episode 3, val func loss 0.1726696491241455\n",
      "\n",
      "episode 4, val func loss 0.177978977560997\n",
      "\n",
      "episode 5, val func loss 0.17704786360263824\n",
      "\n",
      "episode 6, val func loss 0.1661890745162964\n",
      "\n",
      "episode 7, val func loss 0.18845467269420624\n",
      "\n",
      "episode 8, val func loss 0.19986359775066376\n",
      "\n",
      "episode 9, val func loss 0.17563293874263763\n",
      "\n",
      "episode 10, val func loss 0.20334485173225403\n",
      "\n",
      "episode 11, val func loss 0.1869095265865326\n",
      "\n",
      "episode 12, val func loss 0.19853314757347107\n",
      "\n",
      "episode 13, val func loss 0.16660863161087036\n",
      "\n",
      "episode 14, val func loss 0.17857730388641357\n",
      "\n",
      "episode 15, val func loss 0.19543971121311188\n",
      "\n",
      "episode 16, val func loss 0.20306828618049622\n",
      "\n",
      "Val func train loss in epoch 4:0.1858742432668805\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17557449638843536\n",
      "\n",
      "episode 2, val func loss 0.20315232872962952\n",
      "\n",
      "episode 3, val func loss 0.20030978322029114\n",
      "\n",
      "episode 4, val func loss 0.17820902168750763\n",
      "\n",
      "episode 5, val func loss 0.17816448211669922\n",
      "\n",
      "episode 6, val func loss 0.18813735246658325\n",
      "\n",
      "episode 7, val func loss 0.1659972220659256\n",
      "\n",
      "episode 8, val func loss 0.1726231575012207\n",
      "\n",
      "episode 9, val func loss 0.17740561068058014\n",
      "\n",
      "episode 10, val func loss 0.190555602312088\n",
      "\n",
      "episode 11, val func loss 0.19290505349636078\n",
      "\n",
      "episode 12, val func loss 0.1873718649148941\n",
      "\n",
      "episode 13, val func loss 0.16580474376678467\n",
      "\n",
      "episode 14, val func loss 0.19782806932926178\n",
      "\n",
      "episode 15, val func loss 0.1954340785741806\n",
      "\n",
      "episode 16, val func loss 0.2037443071603775\n",
      "\n",
      "Val func train loss in epoch 5:0.18582607340067625\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17261415719985962\n",
      "\n",
      "episode 2, val func loss 0.2031298577785492\n",
      "\n",
      "episode 3, val func loss 0.19286976754665375\n",
      "\n",
      "episode 4, val func loss 0.19066166877746582\n",
      "\n",
      "episode 5, val func loss 0.17803964018821716\n",
      "\n",
      "episode 6, val func loss 0.2038065642118454\n",
      "\n",
      "episode 7, val func loss 0.18818384408950806\n",
      "\n",
      "episode 8, val func loss 0.16654136776924133\n",
      "\n",
      "episode 9, val func loss 0.178043395280838\n",
      "\n",
      "episode 10, val func loss 0.1662904918193817\n",
      "\n",
      "episode 11, val func loss 0.1752936989068985\n",
      "\n",
      "episode 12, val func loss 0.20065242052078247\n",
      "\n",
      "episode 13, val func loss 0.19792257249355316\n",
      "\n",
      "episode 14, val func loss 0.18812496960163116\n",
      "\n",
      "episode 15, val func loss 0.19534771144390106\n",
      "\n",
      "episode 16, val func loss 0.1775844395160675\n",
      "\n",
      "Val func train loss in epoch 6:0.18594416044652462\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1866682767868042\n",
      "\n",
      "episode 2, val func loss 0.16619916260242462\n",
      "\n",
      "episode 3, val func loss 0.1958664208650589\n",
      "\n",
      "episode 4, val func loss 0.19849954545497894\n",
      "\n",
      "episode 5, val func loss 0.1883552372455597\n",
      "\n",
      "episode 6, val func loss 0.1727164387702942\n",
      "\n",
      "episode 7, val func loss 0.17534756660461426\n",
      "\n",
      "episode 8, val func loss 0.19081911444664001\n",
      "\n",
      "episode 9, val func loss 0.16506266593933105\n",
      "\n",
      "episode 10, val func loss 0.20302915573120117\n",
      "\n",
      "episode 11, val func loss 0.2035854607820511\n",
      "\n",
      "episode 12, val func loss 0.17691053450107574\n",
      "\n",
      "episode 13, val func loss 0.19295750558376312\n",
      "\n",
      "episode 14, val func loss 0.1783682256937027\n",
      "\n",
      "episode 15, val func loss 0.1996452510356903\n",
      "\n",
      "episode 16, val func loss 0.17803598940372467\n",
      "\n",
      "Val func train loss in epoch 7:0.18575415946543217\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17862731218338013\n",
      "\n",
      "episode 2, val func loss 0.19542713463306427\n",
      "\n",
      "episode 3, val func loss 0.1996142566204071\n",
      "\n",
      "episode 4, val func loss 0.18841378390789032\n",
      "\n",
      "episode 5, val func loss 0.16567392647266388\n",
      "\n",
      "episode 6, val func loss 0.19077685475349426\n",
      "\n",
      "episode 7, val func loss 0.17789387702941895\n",
      "\n",
      "episode 8, val func loss 0.19805170595645905\n",
      "\n",
      "episode 9, val func loss 0.187674418091774\n",
      "\n",
      "episode 10, val func loss 0.1659504622220993\n",
      "\n",
      "episode 11, val func loss 0.19337265193462372\n",
      "\n",
      "episode 12, val func loss 0.17753872275352478\n",
      "\n",
      "episode 13, val func loss 0.1755012422800064\n",
      "\n",
      "episode 14, val func loss 0.20351217687129974\n",
      "\n",
      "episode 15, val func loss 0.17282965779304504\n",
      "\n",
      "episode 16, val func loss 0.20291805267333984\n",
      "\n",
      "Val func train loss in epoch 8:0.18586101476103067\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1955224573612213\n",
      "\n",
      "episode 2, val func loss 0.17564548552036285\n",
      "\n",
      "episode 3, val func loss 0.19286392629146576\n",
      "\n",
      "episode 4, val func loss 0.1907135546207428\n",
      "\n",
      "episode 5, val func loss 0.17863552272319794\n",
      "\n",
      "episode 6, val func loss 0.19967809319496155\n",
      "\n",
      "episode 7, val func loss 0.1773703247308731\n",
      "\n",
      "episode 8, val func loss 0.16564364731311798\n",
      "\n",
      "episode 9, val func loss 0.1729118824005127\n",
      "\n",
      "episode 10, val func loss 0.17825692892074585\n",
      "\n",
      "episode 11, val func loss 0.16620516777038574\n",
      "\n",
      "episode 12, val func loss 0.18823057413101196\n",
      "\n",
      "episode 13, val func loss 0.1976357102394104\n",
      "\n",
      "episode 14, val func loss 0.20370812714099884\n",
      "\n",
      "episode 15, val func loss 0.18798667192459106\n",
      "\n",
      "episode 16, val func loss 0.20298714935779572\n",
      "\n",
      "Val func train loss in epoch 9:0.18587470147758722\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.1886618286371231\n",
      "\n",
      "episode 2, val func loss 0.17286750674247742\n",
      "\n",
      "episode 3, val func loss 0.20245800912380219\n",
      "\n",
      "episode 4, val func loss 0.19528207182884216\n",
      "\n",
      "episode 5, val func loss 0.19816452264785767\n",
      "\n",
      "episode 6, val func loss 0.18749727308750153\n",
      "\n",
      "episode 7, val func loss 0.1650358885526657\n",
      "\n",
      "episode 8, val func loss 0.17822279036045074\n",
      "\n",
      "episode 9, val func loss 0.17547181248664856\n",
      "\n",
      "episode 10, val func loss 0.20385883748531342\n",
      "\n",
      "episode 11, val func loss 0.20045924186706543\n",
      "\n",
      "episode 12, val func loss 0.17717471718788147\n",
      "\n",
      "episode 13, val func loss 0.17804855108261108\n",
      "\n",
      "episode 14, val func loss 0.19291388988494873\n",
      "\n",
      "episode 15, val func loss 0.1662273406982422\n",
      "\n",
      "episode 16, val func loss 0.1907355934381485\n",
      "\n",
      "Val func train loss in epoch 10:0.18581749219447374\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.17868126928806305\n",
      "\n",
      "episode 2, val func loss 0.1660686880350113\n",
      "\n",
      "episode 3, val func loss 0.17533321678638458\n",
      "\n",
      "episode 4, val func loss 0.18942062556743622\n",
      "\n",
      "episode 5, val func loss 0.19807811081409454\n",
      "\n",
      "episode 6, val func loss 0.2029201239347458\n",
      "\n",
      "episode 7, val func loss 0.17791076004505157\n",
      "\n",
      "episode 8, val func loss 0.1953100562095642\n",
      "\n",
      "episode 9, val func loss 0.19951945543289185\n",
      "\n",
      "episode 10, val func loss 0.1774691790342331\n",
      "\n",
      "episode 11, val func loss 0.2032478153705597\n",
      "\n",
      "episode 12, val func loss 0.1908102035522461\n",
      "\n",
      "episode 13, val func loss 0.1663326919078827\n",
      "\n",
      "episode 14, val func loss 0.18712647259235382\n",
      "\n",
      "episode 15, val func loss 0.19304290413856506\n",
      "\n",
      "episode 16, val func loss 0.17270363867282867\n",
      "\n",
      "Val func train loss in epoch 11:0.18587345071136951\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.20351028442382812\n",
      "\n",
      "episode 2, val func loss 0.19955946505069733\n",
      "\n",
      "episode 3, val func loss 0.17702853679656982\n",
      "\n",
      "episode 4, val func loss 0.1752576380968094\n",
      "\n",
      "episode 5, val func loss 0.20258493721485138\n",
      "\n",
      "episode 6, val func loss 0.18870432674884796\n",
      "\n",
      "episode 7, val func loss 0.18722841143608093\n",
      "\n",
      "episode 8, val func loss 0.19543631374835968\n",
      "\n",
      "episode 9, val func loss 0.1729082316160202\n",
      "\n",
      "episode 10, val func loss 0.1789408028125763\n",
      "\n",
      "episode 11, val func loss 0.19062581658363342\n",
      "\n",
      "episode 12, val func loss 0.19316734373569489\n",
      "\n",
      "episode 13, val func loss 0.19802528619766235\n",
      "\n",
      "episode 14, val func loss 0.17806948721408844\n",
      "\n",
      "episode 15, val func loss 0.16529250144958496\n",
      "\n",
      "episode 16, val func loss 0.16652634739875793\n",
      "\n",
      "Val func train loss in epoch 12:0.18580410815775394\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1935926079750061\n",
      "\n",
      "episode 2, val func loss 0.20022989809513092\n",
      "\n",
      "episode 3, val func loss 0.16498097777366638\n",
      "\n",
      "episode 4, val func loss 0.16597306728363037\n",
      "\n",
      "episode 5, val func loss 0.19062042236328125\n",
      "\n",
      "episode 6, val func loss 0.18855948746204376\n",
      "\n",
      "episode 7, val func loss 0.19807836413383484\n",
      "\n",
      "episode 8, val func loss 0.17556646466255188\n",
      "\n",
      "episode 9, val func loss 0.20260964334011078\n",
      "\n",
      "episode 10, val func loss 0.17262697219848633\n",
      "\n",
      "episode 11, val func loss 0.2035181224346161\n",
      "\n",
      "episode 12, val func loss 0.1783619374036789\n",
      "\n",
      "episode 13, val func loss 0.17789888381958008\n",
      "\n",
      "episode 14, val func loss 0.19557510316371918\n",
      "\n",
      "episode 15, val func loss 0.1768263280391693\n",
      "\n",
      "episode 16, val func loss 0.18820039927959442\n",
      "\n",
      "Val func train loss in epoch 13:0.1858261674642563\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17821726202964783\n",
      "\n",
      "episode 2, val func loss 0.20271220803260803\n",
      "\n",
      "episode 3, val func loss 0.19291114807128906\n",
      "\n",
      "episode 4, val func loss 0.17568053305149078\n",
      "\n",
      "episode 5, val func loss 0.16616274416446686\n",
      "\n",
      "episode 6, val func loss 0.17255675792694092\n",
      "\n",
      "episode 7, val func loss 0.1908039003610611\n",
      "\n",
      "episode 8, val func loss 0.1951090544462204\n",
      "\n",
      "episode 9, val func loss 0.199811190366745\n",
      "\n",
      "episode 10, val func loss 0.19778944551944733\n",
      "\n",
      "episode 11, val func loss 0.16600771248340607\n",
      "\n",
      "episode 12, val func loss 0.2036268711090088\n",
      "\n",
      "episode 13, val func loss 0.17694370448589325\n",
      "\n",
      "episode 14, val func loss 0.1872664839029312\n",
      "\n",
      "episode 15, val func loss 0.17785677313804626\n",
      "\n",
      "episode 16, val func loss 0.18856805562973022\n",
      "\n",
      "Val func train loss in epoch 14:0.18575149029493332\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.188227578997612\n",
      "\n",
      "episode 2, val func loss 0.1782044917345047\n",
      "\n",
      "episode 3, val func loss 0.1960483193397522\n",
      "\n",
      "episode 4, val func loss 0.17276149988174438\n",
      "\n",
      "episode 5, val func loss 0.20261150598526\n",
      "\n",
      "episode 6, val func loss 0.19990220665931702\n",
      "\n",
      "episode 7, val func loss 0.16588537395000458\n",
      "\n",
      "episode 8, val func loss 0.19072552025318146\n",
      "\n",
      "episode 9, val func loss 0.20353537797927856\n",
      "\n",
      "episode 10, val func loss 0.1869988739490509\n",
      "\n",
      "episode 11, val func loss 0.1980666071176529\n",
      "\n",
      "episode 12, val func loss 0.17563755810260773\n",
      "\n",
      "episode 13, val func loss 0.19317041337490082\n",
      "\n",
      "episode 14, val func loss 0.17875999212265015\n",
      "\n",
      "episode 15, val func loss 0.165836900472641\n",
      "\n",
      "episode 16, val func loss 0.1767527163028717\n",
      "\n",
      "Val func train loss in epoch 15:0.18582030851393938\n",
      "***********************TIME WAS 5.001688039302826 min*****************************\n",
      "\n",
      "**********************ROUND 128 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.08555416762828827\n",
      "\n",
      "episode 2, policy loss -0.012273470871150494\n",
      "\n",
      "episode 3, policy loss -0.053604792803525925\n",
      "\n",
      "episode 4, policy loss -0.0661284551024437\n",
      "\n",
      "episode 5, policy loss -0.10850722342729568\n",
      "\n",
      "episode 6, policy loss -0.012643419206142426\n",
      "\n",
      "episode 7, policy loss -0.032731007784605026\n",
      "\n",
      "episode 8, policy loss -0.14955966174602509\n",
      "\n",
      "episode 9, policy loss -0.08064844459295273\n",
      "\n",
      "episode 10, policy loss -0.0374901182949543\n",
      "\n",
      "episode 11, policy loss -0.049144208431243896\n",
      "\n",
      "episode 12, policy loss -0.01730372942984104\n",
      "\n",
      "episode 13, policy loss -0.04499910771846771\n",
      "\n",
      "episode 14, policy loss -0.07481247931718826\n",
      "\n",
      "episode 15, policy loss -0.03702879697084427\n",
      "\n",
      "episode 16, policy loss -0.06136829033493996\n",
      "\n",
      "Policy train loss in epoch 0:-0.0577373358537443\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.03842834755778313\n",
      "\n",
      "episode 2, policy loss -0.049970194697380066\n",
      "\n",
      "episode 3, policy loss -0.06389199942350388\n",
      "\n",
      "episode 4, policy loss -0.08815853297710419\n",
      "\n",
      "episode 5, policy loss -0.05783079192042351\n",
      "\n",
      "episode 6, policy loss -0.04524900019168854\n",
      "\n",
      "episode 7, policy loss -0.01782933436334133\n",
      "\n",
      "episode 8, policy loss -0.14885152876377106\n",
      "\n",
      "episode 9, policy loss -0.11084898561239243\n",
      "\n",
      "episode 10, policy loss -0.06113205477595329\n",
      "\n",
      "episode 11, policy loss -0.019798435270786285\n",
      "\n",
      "episode 12, policy loss -0.07309740781784058\n",
      "\n",
      "episode 13, policy loss -0.04082297533750534\n",
      "\n",
      "episode 14, policy loss -0.012824871577322483\n",
      "\n",
      "episode 15, policy loss -0.03267688304185867\n",
      "\n",
      "episode 16, policy loss -0.08244527876377106\n",
      "\n",
      "Policy train loss in epoch 1:-0.058991038880776614\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.01485197339206934\n",
      "\n",
      "episode 2, policy loss -0.03921956941485405\n",
      "\n",
      "episode 3, policy loss -0.032708268612623215\n",
      "\n",
      "episode 4, policy loss -0.03960252180695534\n",
      "\n",
      "episode 5, policy loss -0.08178161829710007\n",
      "\n",
      "episode 6, policy loss -0.14881925284862518\n",
      "\n",
      "episode 7, policy loss -0.05085918307304382\n",
      "\n",
      "episode 8, policy loss -0.0933624729514122\n",
      "\n",
      "episode 9, policy loss -0.018614407628774643\n",
      "\n",
      "episode 10, policy loss -0.07512744516134262\n",
      "\n",
      "episode 11, policy loss -0.062442611902952194\n",
      "\n",
      "episode 12, policy loss -0.019299056380987167\n",
      "\n",
      "episode 13, policy loss -0.04866721108555794\n",
      "\n",
      "episode 14, policy loss -0.06920700520277023\n",
      "\n",
      "episode 15, policy loss -0.11183945834636688\n",
      "\n",
      "episode 16, policy loss -0.060991935431957245\n",
      "\n",
      "Policy train loss in epoch 2:-0.06046212447108701\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.011871055699884892\n",
      "\n",
      "episode 2, policy loss -0.07556136697530746\n",
      "\n",
      "episode 3, policy loss -0.15225039422512054\n",
      "\n",
      "episode 4, policy loss -0.06283504515886307\n",
      "\n",
      "episode 5, policy loss -0.04987103492021561\n",
      "\n",
      "episode 6, policy loss -0.07059083133935928\n",
      "\n",
      "episode 7, policy loss -0.03283003345131874\n",
      "\n",
      "episode 8, policy loss -0.08288536965847015\n",
      "\n",
      "episode 9, policy loss -0.09230585396289825\n",
      "\n",
      "episode 10, policy loss -0.019442273303866386\n",
      "\n",
      "episode 11, policy loss -0.020050492137670517\n",
      "\n",
      "episode 12, policy loss -0.11286330223083496\n",
      "\n",
      "episode 13, policy loss -0.04136991873383522\n",
      "\n",
      "episode 14, policy loss -0.04920470342040062\n",
      "\n",
      "episode 15, policy loss -0.03956719860434532\n",
      "\n",
      "episode 16, policy loss -0.06199130415916443\n",
      "\n",
      "Policy train loss in epoch 3:-0.060968136123847216\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1711236834526062\n",
      "\n",
      "episode 2, val func loss 0.18388117849826813\n",
      "\n",
      "episode 3, val func loss 0.17923946678638458\n",
      "\n",
      "episode 4, val func loss 0.1593291461467743\n",
      "\n",
      "episode 5, val func loss 0.1784317046403885\n",
      "\n",
      "episode 6, val func loss 0.15610451996326447\n",
      "\n",
      "episode 7, val func loss 0.19083870947360992\n",
      "\n",
      "episode 8, val func loss 0.2045263797044754\n",
      "\n",
      "episode 9, val func loss 0.19928646087646484\n",
      "\n",
      "episode 10, val func loss 0.1795046627521515\n",
      "\n",
      "episode 11, val func loss 0.16207419335842133\n",
      "\n",
      "episode 12, val func loss 0.21835744380950928\n",
      "\n",
      "episode 13, val func loss 0.2305433303117752\n",
      "\n",
      "episode 14, val func loss 0.20558704435825348\n",
      "\n",
      "episode 15, val func loss 0.18427065014839172\n",
      "\n",
      "episode 16, val func loss 0.20819714665412903\n",
      "\n",
      "Val func train loss in epoch 0:0.18820598255842924\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1659603714942932\n",
      "\n",
      "episode 2, val func loss 0.1803821474313736\n",
      "\n",
      "episode 3, val func loss 0.1839515119791031\n",
      "\n",
      "episode 4, val func loss 0.205261692404747\n",
      "\n",
      "episode 5, val func loss 0.18175511062145233\n",
      "\n",
      "episode 6, val func loss 0.24470458924770355\n",
      "\n",
      "episode 7, val func loss 0.20335981249809265\n",
      "\n",
      "episode 8, val func loss 0.20697709918022156\n",
      "\n",
      "episode 9, val func loss 0.19134970009326935\n",
      "\n",
      "episode 10, val func loss 0.19902020692825317\n",
      "\n",
      "episode 11, val func loss 0.16393691301345825\n",
      "\n",
      "episode 12, val func loss 0.21669530868530273\n",
      "\n",
      "episode 13, val func loss 0.1639701873064041\n",
      "\n",
      "episode 14, val func loss 0.18147410452365875\n",
      "\n",
      "episode 15, val func loss 0.18209385871887207\n",
      "\n",
      "episode 16, val func loss 0.17146539688110352\n",
      "\n",
      "Val func train loss in epoch 1:0.1901473756879568\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.21044549345970154\n",
      "\n",
      "episode 2, val func loss 0.1835901439189911\n",
      "\n",
      "episode 3, val func loss 0.17853862047195435\n",
      "\n",
      "episode 4, val func loss 0.22464601695537567\n",
      "\n",
      "episode 5, val func loss 0.15964123606681824\n",
      "\n",
      "episode 6, val func loss 0.16155804693698883\n",
      "\n",
      "episode 7, val func loss 0.17141015827655792\n",
      "\n",
      "episode 8, val func loss 0.15711291134357452\n",
      "\n",
      "episode 9, val func loss 0.1985969990491867\n",
      "\n",
      "episode 10, val func loss 0.18969063460826874\n",
      "\n",
      "episode 11, val func loss 0.18078379333019257\n",
      "\n",
      "episode 12, val func loss 0.1793975830078125\n",
      "\n",
      "episode 13, val func loss 0.23628424108028412\n",
      "\n",
      "episode 14, val func loss 0.2019616812467575\n",
      "\n",
      "episode 15, val func loss 0.20312190055847168\n",
      "\n",
      "episode 16, val func loss 0.18098746240139008\n",
      "\n",
      "Val func train loss in epoch 2:0.18861043266952038\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1724930703639984\n",
      "\n",
      "episode 2, val func loss 0.19825628399848938\n",
      "\n",
      "episode 3, val func loss 0.17947271466255188\n",
      "\n",
      "episode 4, val func loss 0.15806922316551208\n",
      "\n",
      "episode 5, val func loss 0.17986758053302765\n",
      "\n",
      "episode 6, val func loss 0.1838548481464386\n",
      "\n",
      "episode 7, val func loss 0.2024131417274475\n",
      "\n",
      "episode 8, val func loss 0.15926618874073029\n",
      "\n",
      "episode 9, val func loss 0.20512352883815765\n",
      "\n",
      "episode 10, val func loss 0.17900995910167694\n",
      "\n",
      "episode 11, val func loss 0.1906398981809616\n",
      "\n",
      "episode 12, val func loss 0.2101038098335266\n",
      "\n",
      "episode 13, val func loss 0.23814882338047028\n",
      "\n",
      "episode 14, val func loss 0.22031979262828827\n",
      "\n",
      "episode 15, val func loss 0.1809164136648178\n",
      "\n",
      "episode 16, val func loss 0.16321076452732086\n",
      "\n",
      "Val func train loss in epoch 3:0.1888228775933385\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.16425864398479462\n",
      "\n",
      "episode 2, val func loss 0.17967912554740906\n",
      "\n",
      "episode 3, val func loss 0.22935806214809418\n",
      "\n",
      "episode 4, val func loss 0.18997599184513092\n",
      "\n",
      "episode 5, val func loss 0.2049562633037567\n",
      "\n",
      "episode 6, val func loss 0.18163876235485077\n",
      "\n",
      "episode 7, val func loss 0.19074837863445282\n",
      "\n",
      "episode 8, val func loss 0.2072112262248993\n",
      "\n",
      "episode 9, val func loss 0.18021923303604126\n",
      "\n",
      "episode 10, val func loss 0.19912391901016235\n",
      "\n",
      "episode 11, val func loss 0.171148419380188\n",
      "\n",
      "episode 12, val func loss 0.2045944482088089\n",
      "\n",
      "episode 13, val func loss 0.15603651106357574\n",
      "\n",
      "episode 14, val func loss 0.15898019075393677\n",
      "\n",
      "episode 15, val func loss 0.18218302726745605\n",
      "\n",
      "episode 16, val func loss 0.2246858775615692\n",
      "\n",
      "Val func train loss in epoch 4:0.18904988002032042\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18138837814331055\n",
      "\n",
      "episode 2, val func loss 0.17957666516304016\n",
      "\n",
      "episode 3, val func loss 0.15779389441013336\n",
      "\n",
      "episode 4, val func loss 0.18494732677936554\n",
      "\n",
      "episode 5, val func loss 0.1778365522623062\n",
      "\n",
      "episode 6, val func loss 0.2020348310470581\n",
      "\n",
      "episode 7, val func loss 0.16051587462425232\n",
      "\n",
      "episode 8, val func loss 0.22085969150066376\n",
      "\n",
      "episode 9, val func loss 0.18985465168952942\n",
      "\n",
      "episode 10, val func loss 0.2349509596824646\n",
      "\n",
      "episode 11, val func loss 0.1719275861978531\n",
      "\n",
      "episode 12, val func loss 0.1979711353778839\n",
      "\n",
      "episode 13, val func loss 0.20342199504375458\n",
      "\n",
      "episode 14, val func loss 0.1818442940711975\n",
      "\n",
      "episode 15, val func loss 0.16246192157268524\n",
      "\n",
      "episode 16, val func loss 0.20714415609836578\n",
      "\n",
      "Val func train loss in epoch 5:0.1884081196039915\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.16099514067173004\n",
      "\n",
      "episode 2, val func loss 0.20762033760547638\n",
      "\n",
      "episode 3, val func loss 0.17745892703533173\n",
      "\n",
      "episode 4, val func loss 0.20308969914913177\n",
      "\n",
      "episode 5, val func loss 0.18094071745872498\n",
      "\n",
      "episode 6, val func loss 0.19866280257701874\n",
      "\n",
      "episode 7, val func loss 0.17148739099502563\n",
      "\n",
      "episode 8, val func loss 0.16141776740550995\n",
      "\n",
      "episode 9, val func loss 0.22111831605434418\n",
      "\n",
      "episode 10, val func loss 0.2361718863248825\n",
      "\n",
      "episode 11, val func loss 0.18986886739730835\n",
      "\n",
      "episode 12, val func loss 0.1589677333831787\n",
      "\n",
      "episode 13, val func loss 0.1857176274061203\n",
      "\n",
      "episode 14, val func loss 0.18000930547714233\n",
      "\n",
      "episode 15, val func loss 0.20210599899291992\n",
      "\n",
      "episode 16, val func loss 0.18116499483585358\n",
      "\n",
      "Val func train loss in epoch 6:0.1885498445481062\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.15810658037662506\n",
      "\n",
      "episode 2, val func loss 0.22099582850933075\n",
      "\n",
      "episode 3, val func loss 0.17156115174293518\n",
      "\n",
      "episode 4, val func loss 0.17963869869709015\n",
      "\n",
      "episode 5, val func loss 0.20220738649368286\n",
      "\n",
      "episode 6, val func loss 0.19011010229587555\n",
      "\n",
      "episode 7, val func loss 0.17919640243053436\n",
      "\n",
      "episode 8, val func loss 0.2037912905216217\n",
      "\n",
      "episode 9, val func loss 0.20968039333820343\n",
      "\n",
      "episode 10, val func loss 0.18124157190322876\n",
      "\n",
      "episode 11, val func loss 0.18407262861728668\n",
      "\n",
      "episode 12, val func loss 0.1597198247909546\n",
      "\n",
      "episode 13, val func loss 0.198654443025589\n",
      "\n",
      "episode 14, val func loss 0.23683391511440277\n",
      "\n",
      "episode 15, val func loss 0.177636981010437\n",
      "\n",
      "episode 16, val func loss 0.1619569957256317\n",
      "\n",
      "Val func train loss in epoch 7:0.18846276216208935\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.20218044519424438\n",
      "\n",
      "episode 2, val func loss 0.17826810479164124\n",
      "\n",
      "episode 3, val func loss 0.23252026736736298\n",
      "\n",
      "episode 4, val func loss 0.1906946301460266\n",
      "\n",
      "episode 5, val func loss 0.18053759634494781\n",
      "\n",
      "episode 6, val func loss 0.16344678401947021\n",
      "\n",
      "episode 7, val func loss 0.16082003712654114\n",
      "\n",
      "episode 8, val func loss 0.20644764602184296\n",
      "\n",
      "episode 9, val func loss 0.18170493841171265\n",
      "\n",
      "episode 10, val func loss 0.21958334743976593\n",
      "\n",
      "episode 11, val func loss 0.1845989227294922\n",
      "\n",
      "episode 12, val func loss 0.16020303964614868\n",
      "\n",
      "episode 13, val func loss 0.1809258759021759\n",
      "\n",
      "episode 14, val func loss 0.19915366172790527\n",
      "\n",
      "episode 15, val func loss 0.17098936438560486\n",
      "\n",
      "episode 16, val func loss 0.20379236340522766\n",
      "\n",
      "Val func train loss in epoch 8:0.1884916890412569\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1814952939748764\n",
      "\n",
      "episode 2, val func loss 0.1799052506685257\n",
      "\n",
      "episode 3, val func loss 0.19894327223300934\n",
      "\n",
      "episode 4, val func loss 0.23763211071491241\n",
      "\n",
      "episode 5, val func loss 0.20199212431907654\n",
      "\n",
      "episode 6, val func loss 0.1896050125360489\n",
      "\n",
      "episode 7, val func loss 0.17283864319324493\n",
      "\n",
      "episode 8, val func loss 0.21838413178920746\n",
      "\n",
      "episode 9, val func loss 0.20372436940670013\n",
      "\n",
      "episode 10, val func loss 0.18323779106140137\n",
      "\n",
      "episode 11, val func loss 0.18675532937049866\n",
      "\n",
      "episode 12, val func loss 0.16003702580928802\n",
      "\n",
      "episode 13, val func loss 0.20728962123394012\n",
      "\n",
      "episode 14, val func loss 0.17757925391197205\n",
      "\n",
      "episode 15, val func loss 0.16005440056324005\n",
      "\n",
      "episode 16, val func loss 0.16147246956825256\n",
      "\n",
      "Val func train loss in epoch 9:0.18880913127213717\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.2098858505487442\n",
      "\n",
      "episode 2, val func loss 0.20235514640808105\n",
      "\n",
      "episode 3, val func loss 0.15607424080371857\n",
      "\n",
      "episode 4, val func loss 0.1595378965139389\n",
      "\n",
      "episode 5, val func loss 0.224478617310524\n",
      "\n",
      "episode 6, val func loss 0.1710280328989029\n",
      "\n",
      "episode 7, val func loss 0.1778409779071808\n",
      "\n",
      "episode 8, val func loss 0.17905469238758087\n",
      "\n",
      "episode 9, val func loss 0.2378968894481659\n",
      "\n",
      "episode 10, val func loss 0.20341114699840546\n",
      "\n",
      "episode 11, val func loss 0.18478775024414062\n",
      "\n",
      "episode 12, val func loss 0.18088701367378235\n",
      "\n",
      "episode 13, val func loss 0.1899227499961853\n",
      "\n",
      "episode 14, val func loss 0.16238322854042053\n",
      "\n",
      "episode 15, val func loss 0.1796790212392807\n",
      "\n",
      "episode 16, val func loss 0.19789259135723114\n",
      "\n",
      "Val func train loss in epoch 10:0.1885697403922677\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.2189544439315796\n",
      "\n",
      "episode 2, val func loss 0.23324044048786163\n",
      "\n",
      "episode 3, val func loss 0.20359425246715546\n",
      "\n",
      "episode 4, val func loss 0.16300071775913239\n",
      "\n",
      "episode 5, val func loss 0.1815827190876007\n",
      "\n",
      "episode 6, val func loss 0.17382016777992249\n",
      "\n",
      "episode 7, val func loss 0.20289558172225952\n",
      "\n",
      "episode 8, val func loss 0.1811804622411728\n",
      "\n",
      "episode 9, val func loss 0.15676984190940857\n",
      "\n",
      "episode 10, val func loss 0.18430456519126892\n",
      "\n",
      "episode 11, val func loss 0.2162109911441803\n",
      "\n",
      "episode 12, val func loss 0.20164339244365692\n",
      "\n",
      "episode 13, val func loss 0.15932701528072357\n",
      "\n",
      "episode 14, val func loss 0.17971304059028625\n",
      "\n",
      "episode 15, val func loss 0.17775116860866547\n",
      "\n",
      "episode 16, val func loss 0.18992693722248077\n",
      "\n",
      "Val func train loss in epoch 11:0.1889947336167097\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18513290584087372\n",
      "\n",
      "episode 2, val func loss 0.1617112159729004\n",
      "\n",
      "episode 3, val func loss 0.2030433565378189\n",
      "\n",
      "episode 4, val func loss 0.1712673306465149\n",
      "\n",
      "episode 5, val func loss 0.15933117270469666\n",
      "\n",
      "episode 6, val func loss 0.17846481502056122\n",
      "\n",
      "episode 7, val func loss 0.1562642604112625\n",
      "\n",
      "episode 8, val func loss 0.20356862246990204\n",
      "\n",
      "episode 9, val func loss 0.24067576229572296\n",
      "\n",
      "episode 10, val func loss 0.20775403082370758\n",
      "\n",
      "episode 11, val func loss 0.18081024289131165\n",
      "\n",
      "episode 12, val func loss 0.19891589879989624\n",
      "\n",
      "episode 13, val func loss 0.17918804287910461\n",
      "\n",
      "episode 14, val func loss 0.2171555459499359\n",
      "\n",
      "episode 15, val func loss 0.19171081483364105\n",
      "\n",
      "episode 16, val func loss 0.18167641758918762\n",
      "\n",
      "Val func train loss in epoch 12:0.18854190222918987\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.2316734939813614\n",
      "\n",
      "episode 2, val func loss 0.17416535317897797\n",
      "\n",
      "episode 3, val func loss 0.16353659331798553\n",
      "\n",
      "episode 4, val func loss 0.2025967687368393\n",
      "\n",
      "episode 5, val func loss 0.2079659402370453\n",
      "\n",
      "episode 6, val func loss 0.16023556888103485\n",
      "\n",
      "episode 7, val func loss 0.20369546115398407\n",
      "\n",
      "episode 8, val func loss 0.2240135818719864\n",
      "\n",
      "episode 9, val func loss 0.19853198528289795\n",
      "\n",
      "episode 10, val func loss 0.1586615890264511\n",
      "\n",
      "episode 11, val func loss 0.1813499629497528\n",
      "\n",
      "episode 12, val func loss 0.18066950142383575\n",
      "\n",
      "episode 13, val func loss 0.17779852449893951\n",
      "\n",
      "episode 14, val func loss 0.18424567580223083\n",
      "\n",
      "episode 15, val func loss 0.19016265869140625\n",
      "\n",
      "episode 16, val func loss 0.1798332929611206\n",
      "\n",
      "Val func train loss in epoch 13:0.1886959969997406\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.20931804180145264\n",
      "\n",
      "episode 2, val func loss 0.17114654183387756\n",
      "\n",
      "episode 3, val func loss 0.2031688243150711\n",
      "\n",
      "episode 4, val func loss 0.15770475566387177\n",
      "\n",
      "episode 5, val func loss 0.17772436141967773\n",
      "\n",
      "episode 6, val func loss 0.16156668961048126\n",
      "\n",
      "episode 7, val func loss 0.17953313887119293\n",
      "\n",
      "episode 8, val func loss 0.23728244006633759\n",
      "\n",
      "episode 9, val func loss 0.22030727565288544\n",
      "\n",
      "episode 10, val func loss 0.18087972700595856\n",
      "\n",
      "episode 11, val func loss 0.198345348238945\n",
      "\n",
      "episode 12, val func loss 0.1834595948457718\n",
      "\n",
      "episode 13, val func loss 0.19068196415901184\n",
      "\n",
      "episode 14, val func loss 0.20314063131809235\n",
      "\n",
      "episode 15, val func loss 0.18622444570064545\n",
      "\n",
      "episode 16, val func loss 0.1611240655183792\n",
      "\n",
      "Val func train loss in epoch 14:0.18885049037635326\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18401511013507843\n",
      "\n",
      "episode 2, val func loss 0.22597959637641907\n",
      "\n",
      "episode 3, val func loss 0.20011764764785767\n",
      "\n",
      "episode 4, val func loss 0.1595592051744461\n",
      "\n",
      "episode 5, val func loss 0.15639084577560425\n",
      "\n",
      "episode 6, val func loss 0.18968375027179718\n",
      "\n",
      "episode 7, val func loss 0.17129001021385193\n",
      "\n",
      "episode 8, val func loss 0.20229381322860718\n",
      "\n",
      "episode 9, val func loss 0.2089429497718811\n",
      "\n",
      "episode 10, val func loss 0.1807813197374344\n",
      "\n",
      "episode 11, val func loss 0.17968197166919708\n",
      "\n",
      "episode 12, val func loss 0.2359372228384018\n",
      "\n",
      "episode 13, val func loss 0.2033042162656784\n",
      "\n",
      "episode 14, val func loss 0.17775821685791016\n",
      "\n",
      "episode 15, val func loss 0.16215042769908905\n",
      "\n",
      "episode 16, val func loss 0.18010997772216797\n",
      "\n",
      "Val func train loss in epoch 15:0.18862476758658886\n",
      "***********************TIME WAS 5.005073690414429 min*****************************\n",
      "\n",
      "**********************ROUND 129 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.014460359700024128\n",
      "\n",
      "episode 2, policy loss -0.005365293938666582\n",
      "\n",
      "episode 3, policy loss -0.036001596599817276\n",
      "\n",
      "episode 4, policy loss -0.03853169456124306\n",
      "\n",
      "episode 5, policy loss 0.014976521022617817\n",
      "\n",
      "episode 6, policy loss -0.0486958771944046\n",
      "\n",
      "episode 7, policy loss -0.02727595344185829\n",
      "\n",
      "episode 8, policy loss -0.00703765545040369\n",
      "\n",
      "episode 9, policy loss -0.020432811230421066\n",
      "\n",
      "episode 10, policy loss -0.024809429422020912\n",
      "\n",
      "episode 11, policy loss -0.0541219636797905\n",
      "\n",
      "episode 12, policy loss -0.026121411472558975\n",
      "\n",
      "episode 13, policy loss -0.0344357006251812\n",
      "\n",
      "episode 14, policy loss -0.01688510552048683\n",
      "\n",
      "episode 15, policy loss -0.06972167640924454\n",
      "\n",
      "episode 16, policy loss -0.001108552678488195\n",
      "\n",
      "Policy train loss in epoch 0:-0.0256267850563745\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.017717394977808\n",
      "\n",
      "episode 2, policy loss -0.02453000098466873\n",
      "\n",
      "episode 3, policy loss -0.02025570534169674\n",
      "\n",
      "episode 4, policy loss -0.015967249870300293\n",
      "\n",
      "episode 5, policy loss -0.0024661088827997446\n",
      "\n",
      "episode 6, policy loss -0.07170261442661285\n",
      "\n",
      "episode 7, policy loss -0.04918649420142174\n",
      "\n",
      "episode 8, policy loss 0.015183776617050171\n",
      "\n",
      "episode 9, policy loss -0.041624173521995544\n",
      "\n",
      "episode 10, policy loss -0.026726029813289642\n",
      "\n",
      "episode 11, policy loss -0.057599831372499466\n",
      "\n",
      "episode 12, policy loss -0.039142511785030365\n",
      "\n",
      "episode 13, policy loss -0.02216329798102379\n",
      "\n",
      "episode 14, policy loss -0.03048340603709221\n",
      "\n",
      "episode 15, policy loss -0.04159243404865265\n",
      "\n",
      "episode 16, policy loss -0.010407947935163975\n",
      "\n",
      "Policy train loss in epoch 1:-0.028523839035187848\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.030559442937374115\n",
      "\n",
      "episode 2, policy loss -0.0724528506398201\n",
      "\n",
      "episode 3, policy loss -0.027384690940380096\n",
      "\n",
      "episode 4, policy loss -0.04167360067367554\n",
      "\n",
      "episode 5, policy loss 0.015570726245641708\n",
      "\n",
      "episode 6, policy loss -0.010151817463338375\n",
      "\n",
      "episode 7, policy loss -0.0203574039041996\n",
      "\n",
      "episode 8, policy loss -0.025848982855677605\n",
      "\n",
      "episode 9, policy loss -0.020558258518576622\n",
      "\n",
      "episode 10, policy loss -0.0419248528778553\n",
      "\n",
      "episode 11, policy loss -0.022598739713430405\n",
      "\n",
      "episode 12, policy loss -0.056834567338228226\n",
      "\n",
      "episode 13, policy loss -0.0019582812674343586\n",
      "\n",
      "episode 14, policy loss -0.03972309082746506\n",
      "\n",
      "episode 15, policy loss -0.04896245896816254\n",
      "\n",
      "episode 16, policy loss -0.016491776332259178\n",
      "\n",
      "Policy train loss in epoch 2:-0.028869380563264713\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.04042895510792732\n",
      "\n",
      "episode 2, policy loss -0.02820287086069584\n",
      "\n",
      "episode 3, policy loss -0.048925045877695084\n",
      "\n",
      "episode 4, policy loss -0.0385558120906353\n",
      "\n",
      "episode 5, policy loss -0.07112983614206314\n",
      "\n",
      "episode 6, policy loss -0.020977891981601715\n",
      "\n",
      "episode 7, policy loss -0.02925274893641472\n",
      "\n",
      "episode 8, policy loss -0.05634400248527527\n",
      "\n",
      "episode 9, policy loss -0.04174607992172241\n",
      "\n",
      "episode 10, policy loss -0.0191664919257164\n",
      "\n",
      "episode 11, policy loss -0.02511572651565075\n",
      "\n",
      "episode 12, policy loss -0.009773124009370804\n",
      "\n",
      "episode 13, policy loss 0.017296988517045975\n",
      "\n",
      "episode 14, policy loss -0.0014497932279482484\n",
      "\n",
      "episode 15, policy loss -0.01609111577272415\n",
      "\n",
      "episode 16, policy loss -0.021312009543180466\n",
      "\n",
      "Policy train loss in epoch 3:-0.028198407242598478\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19830061495304108\n",
      "\n",
      "episode 2, val func loss 0.1763361692428589\n",
      "\n",
      "episode 3, val func loss 0.18160411715507507\n",
      "\n",
      "episode 4, val func loss 0.20077167451381683\n",
      "\n",
      "episode 5, val func loss 0.17723946273326874\n",
      "\n",
      "episode 6, val func loss 0.19406037032604218\n",
      "\n",
      "episode 7, val func loss 0.2202460765838623\n",
      "\n",
      "episode 8, val func loss 0.1914755403995514\n",
      "\n",
      "episode 9, val func loss 0.1662261039018631\n",
      "\n",
      "episode 10, val func loss 0.1889321506023407\n",
      "\n",
      "episode 11, val func loss 0.20056761801242828\n",
      "\n",
      "episode 12, val func loss 0.1971832662820816\n",
      "\n",
      "episode 13, val func loss 0.17965802550315857\n",
      "\n",
      "episode 14, val func loss 0.18257856369018555\n",
      "\n",
      "episode 15, val func loss 0.20152461528778076\n",
      "\n",
      "episode 16, val func loss 0.19114139676094055\n",
      "\n",
      "Val func train loss in epoch 0:0.19049036037176847\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19086158275604248\n",
      "\n",
      "episode 2, val func loss 0.17793919146060944\n",
      "\n",
      "episode 3, val func loss 0.17601048946380615\n",
      "\n",
      "episode 4, val func loss 0.1826702207326889\n",
      "\n",
      "episode 5, val func loss 0.16540955007076263\n",
      "\n",
      "episode 6, val func loss 0.17973797023296356\n",
      "\n",
      "episode 7, val func loss 0.2014409601688385\n",
      "\n",
      "episode 8, val func loss 0.18108108639717102\n",
      "\n",
      "episode 9, val func loss 0.20229995250701904\n",
      "\n",
      "episode 10, val func loss 0.18844296038150787\n",
      "\n",
      "episode 11, val func loss 0.19153526425361633\n",
      "\n",
      "episode 12, val func loss 0.19855041801929474\n",
      "\n",
      "episode 13, val func loss 0.20058608055114746\n",
      "\n",
      "episode 14, val func loss 0.1970519870519638\n",
      "\n",
      "episode 15, val func loss 0.19434431195259094\n",
      "\n",
      "episode 16, val func loss 0.21856646239757538\n",
      "\n",
      "Val func train loss in epoch 1:0.1904080305248499\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18355470895767212\n",
      "\n",
      "episode 2, val func loss 0.19657760858535767\n",
      "\n",
      "episode 3, val func loss 0.2010527104139328\n",
      "\n",
      "episode 4, val func loss 0.19383397698402405\n",
      "\n",
      "episode 5, val func loss 0.19459322094917297\n",
      "\n",
      "episode 6, val func loss 0.1821974515914917\n",
      "\n",
      "episode 7, val func loss 0.19042442739009857\n",
      "\n",
      "episode 8, val func loss 0.18148459494113922\n",
      "\n",
      "episode 9, val func loss 0.175867959856987\n",
      "\n",
      "episode 10, val func loss 0.20212891697883606\n",
      "\n",
      "episode 11, val func loss 0.2226734608411789\n",
      "\n",
      "episode 12, val func loss 0.16454188525676727\n",
      "\n",
      "episode 13, val func loss 0.20196934044361115\n",
      "\n",
      "episode 14, val func loss 0.18864402174949646\n",
      "\n",
      "episode 15, val func loss 0.1776193529367447\n",
      "\n",
      "episode 16, val func loss 0.19874684512615204\n",
      "\n",
      "Val func train loss in epoch 2:0.19099440518766642\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19413550198078156\n",
      "\n",
      "episode 2, val func loss 0.2015003114938736\n",
      "\n",
      "episode 3, val func loss 0.18050965666770935\n",
      "\n",
      "episode 4, val func loss 0.2009032964706421\n",
      "\n",
      "episode 5, val func loss 0.1768396645784378\n",
      "\n",
      "episode 6, val func loss 0.19058410823345184\n",
      "\n",
      "episode 7, val func loss 0.18947012722492218\n",
      "\n",
      "episode 8, val func loss 0.16603262722492218\n",
      "\n",
      "episode 9, val func loss 0.22014908492565155\n",
      "\n",
      "episode 10, val func loss 0.19134020805358887\n",
      "\n",
      "episode 11, val func loss 0.20042270421981812\n",
      "\n",
      "episode 12, val func loss 0.177362859249115\n",
      "\n",
      "episode 13, val func loss 0.18119551241397858\n",
      "\n",
      "episode 14, val func loss 0.19722910225391388\n",
      "\n",
      "episode 15, val func loss 0.18275566399097443\n",
      "\n",
      "episode 16, val func loss 0.19832327961921692\n",
      "\n",
      "Val func train loss in epoch 3:0.19054710678756237\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.20142799615859985\n",
      "\n",
      "episode 2, val func loss 0.1661466509103775\n",
      "\n",
      "episode 3, val func loss 0.20058350265026093\n",
      "\n",
      "episode 4, val func loss 0.17773309350013733\n",
      "\n",
      "episode 5, val func loss 0.1890656054019928\n",
      "\n",
      "episode 6, val func loss 0.22048313915729523\n",
      "\n",
      "episode 7, val func loss 0.20097042620182037\n",
      "\n",
      "episode 8, val func loss 0.18156296014785767\n",
      "\n",
      "episode 9, val func loss 0.19672264158725739\n",
      "\n",
      "episode 10, val func loss 0.18092478811740875\n",
      "\n",
      "episode 11, val func loss 0.19414640963077545\n",
      "\n",
      "episode 12, val func loss 0.19162480533123016\n",
      "\n",
      "episode 13, val func loss 0.17623774707317352\n",
      "\n",
      "episode 14, val func loss 0.18273797631263733\n",
      "\n",
      "episode 15, val func loss 0.19865955412387848\n",
      "\n",
      "episode 16, val func loss 0.19116240739822388\n",
      "\n",
      "Val func train loss in epoch 4:0.19063685648143291\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.2005586177110672\n",
      "\n",
      "episode 2, val func loss 0.19119144976139069\n",
      "\n",
      "episode 3, val func loss 0.18299797177314758\n",
      "\n",
      "episode 4, val func loss 0.19426383078098297\n",
      "\n",
      "episode 5, val func loss 0.16566886007785797\n",
      "\n",
      "episode 6, val func loss 0.22021880745887756\n",
      "\n",
      "episode 7, val func loss 0.18166916072368622\n",
      "\n",
      "episode 8, val func loss 0.19852344691753387\n",
      "\n",
      "episode 9, val func loss 0.20076283812522888\n",
      "\n",
      "episode 10, val func loss 0.19647100567817688\n",
      "\n",
      "episode 11, val func loss 0.1897306740283966\n",
      "\n",
      "episode 12, val func loss 0.1812797635793686\n",
      "\n",
      "episode 13, val func loss 0.17765440046787262\n",
      "\n",
      "episode 14, val func loss 0.2015441507101059\n",
      "\n",
      "episode 15, val func loss 0.1762823909521103\n",
      "\n",
      "episode 16, val func loss 0.19100968539714813\n",
      "\n",
      "Val func train loss in epoch 5:0.1906141908839345\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19106054306030273\n",
      "\n",
      "episode 2, val func loss 0.19456221163272858\n",
      "\n",
      "episode 3, val func loss 0.2017480581998825\n",
      "\n",
      "episode 4, val func loss 0.1795816868543625\n",
      "\n",
      "episode 5, val func loss 0.177651509642601\n",
      "\n",
      "episode 6, val func loss 0.19083571434020996\n",
      "\n",
      "episode 7, val func loss 0.20201529562473297\n",
      "\n",
      "episode 8, val func loss 0.18124553561210632\n",
      "\n",
      "episode 9, val func loss 0.19753190875053406\n",
      "\n",
      "episode 10, val func loss 0.2204778790473938\n",
      "\n",
      "episode 11, val func loss 0.16641731560230255\n",
      "\n",
      "episode 12, val func loss 0.20081114768981934\n",
      "\n",
      "episode 13, val func loss 0.1765165627002716\n",
      "\n",
      "episode 14, val func loss 0.1829306185245514\n",
      "\n",
      "episode 15, val func loss 0.18938705325126648\n",
      "\n",
      "episode 16, val func loss 0.19834166765213013\n",
      "\n",
      "Val func train loss in epoch 6:0.19069466926157475\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18019427359104156\n",
      "\n",
      "episode 2, val func loss 0.1759651005268097\n",
      "\n",
      "episode 3, val func loss 0.19889844954013824\n",
      "\n",
      "episode 4, val func loss 0.2011869251728058\n",
      "\n",
      "episode 5, val func loss 0.19057242572307587\n",
      "\n",
      "episode 6, val func loss 0.1781853586435318\n",
      "\n",
      "episode 7, val func loss 0.19826139509677887\n",
      "\n",
      "episode 8, val func loss 0.19463518261909485\n",
      "\n",
      "episode 9, val func loss 0.16513241827487946\n",
      "\n",
      "episode 10, val func loss 0.1909061074256897\n",
      "\n",
      "episode 11, val func loss 0.18268218636512756\n",
      "\n",
      "episode 12, val func loss 0.2012716829776764\n",
      "\n",
      "episode 13, val func loss 0.20093205571174622\n",
      "\n",
      "episode 14, val func loss 0.2188878357410431\n",
      "\n",
      "episode 15, val func loss 0.18279233574867249\n",
      "\n",
      "episode 16, val func loss 0.19091691076755524\n",
      "\n",
      "Val func train loss in epoch 7:0.19071379024535418\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1822681725025177\n",
      "\n",
      "episode 2, val func loss 0.18206679821014404\n",
      "\n",
      "episode 3, val func loss 0.21952778100967407\n",
      "\n",
      "episode 4, val func loss 0.1827079802751541\n",
      "\n",
      "episode 5, val func loss 0.1658981442451477\n",
      "\n",
      "episode 6, val func loss 0.2004132717847824\n",
      "\n",
      "episode 7, val func loss 0.19067974388599396\n",
      "\n",
      "episode 8, val func loss 0.1981976181268692\n",
      "\n",
      "episode 9, val func loss 0.202081099152565\n",
      "\n",
      "episode 10, val func loss 0.2023247927427292\n",
      "\n",
      "episode 11, val func loss 0.1941099613904953\n",
      "\n",
      "episode 12, val func loss 0.1887509822845459\n",
      "\n",
      "episode 13, val func loss 0.19860827922821045\n",
      "\n",
      "episode 14, val func loss 0.1775786131620407\n",
      "\n",
      "episode 15, val func loss 0.17661932110786438\n",
      "\n",
      "episode 16, val func loss 0.190629780292511\n",
      "\n",
      "Val func train loss in epoch 8:0.19077889621257782\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18903006613254547\n",
      "\n",
      "episode 2, val func loss 0.20091910660266876\n",
      "\n",
      "episode 3, val func loss 0.19421793520450592\n",
      "\n",
      "episode 4, val func loss 0.1800743043422699\n",
      "\n",
      "episode 5, val func loss 0.18245559930801392\n",
      "\n",
      "episode 6, val func loss 0.17583146691322327\n",
      "\n",
      "episode 7, val func loss 0.1912851780653\n",
      "\n",
      "episode 8, val func loss 0.18127180635929108\n",
      "\n",
      "episode 9, val func loss 0.20209328830242157\n",
      "\n",
      "episode 10, val func loss 0.16479074954986572\n",
      "\n",
      "episode 11, val func loss 0.19075800478458405\n",
      "\n",
      "episode 12, val func loss 0.19800445437431335\n",
      "\n",
      "episode 13, val func loss 0.19882583618164062\n",
      "\n",
      "episode 14, val func loss 0.20057052373886108\n",
      "\n",
      "episode 15, val func loss 0.2202528566122055\n",
      "\n",
      "episode 16, val func loss 0.17722554504871368\n",
      "\n",
      "Val func train loss in epoch 9:0.1904754200950265\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19857417047023773\n",
      "\n",
      "episode 2, val func loss 0.19090068340301514\n",
      "\n",
      "episode 3, val func loss 0.19062909483909607\n",
      "\n",
      "episode 4, val func loss 0.19314081966876984\n",
      "\n",
      "episode 5, val func loss 0.20082134008407593\n",
      "\n",
      "episode 6, val func loss 0.19423796236515045\n",
      "\n",
      "episode 7, val func loss 0.20102156698703766\n",
      "\n",
      "episode 8, val func loss 0.1655472218990326\n",
      "\n",
      "episode 9, val func loss 0.17758671939373016\n",
      "\n",
      "episode 10, val func loss 0.1980765014886856\n",
      "\n",
      "episode 11, val func loss 0.20210514962673187\n",
      "\n",
      "episode 12, val func loss 0.17912614345550537\n",
      "\n",
      "episode 13, val func loss 0.18111339211463928\n",
      "\n",
      "episode 14, val func loss 0.1827099472284317\n",
      "\n",
      "episode 15, val func loss 0.17581956088542938\n",
      "\n",
      "episode 16, val func loss 0.22164610028266907\n",
      "\n",
      "Val func train loss in epoch 10:0.19081602338701487\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1970263123512268\n",
      "\n",
      "episode 2, val func loss 0.2015555053949356\n",
      "\n",
      "episode 3, val func loss 0.17748750746250153\n",
      "\n",
      "episode 4, val func loss 0.19075709581375122\n",
      "\n",
      "episode 5, val func loss 0.19881762564182281\n",
      "\n",
      "episode 6, val func loss 0.20091772079467773\n",
      "\n",
      "episode 7, val func loss 0.21830148994922638\n",
      "\n",
      "episode 8, val func loss 0.19443188607692719\n",
      "\n",
      "episode 9, val func loss 0.18185921013355255\n",
      "\n",
      "episode 10, val func loss 0.19212780892848969\n",
      "\n",
      "episode 11, val func loss 0.1826818883419037\n",
      "\n",
      "episode 12, val func loss 0.18864719569683075\n",
      "\n",
      "episode 13, val func loss 0.18111419677734375\n",
      "\n",
      "episode 14, val func loss 0.20093436539173126\n",
      "\n",
      "episode 15, val func loss 0.16459773480892181\n",
      "\n",
      "episode 16, val func loss 0.1787736415863037\n",
      "\n",
      "Val func train loss in epoch 11:0.19062694907188416\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17880170047283173\n",
      "\n",
      "episode 2, val func loss 0.16458919644355774\n",
      "\n",
      "episode 3, val func loss 0.20279468595981598\n",
      "\n",
      "episode 4, val func loss 0.19085444509983063\n",
      "\n",
      "episode 5, val func loss 0.1943570077419281\n",
      "\n",
      "episode 6, val func loss 0.20077477395534515\n",
      "\n",
      "episode 7, val func loss 0.18296685814857483\n",
      "\n",
      "episode 8, val func loss 0.19011083245277405\n",
      "\n",
      "episode 9, val func loss 0.19644837081432343\n",
      "\n",
      "episode 10, val func loss 0.18023453652858734\n",
      "\n",
      "episode 11, val func loss 0.22042059898376465\n",
      "\n",
      "episode 12, val func loss 0.20035651326179504\n",
      "\n",
      "episode 13, val func loss 0.19086094200611115\n",
      "\n",
      "episode 14, val func loss 0.1982657015323639\n",
      "\n",
      "episode 15, val func loss 0.17653676867485046\n",
      "\n",
      "episode 16, val func loss 0.18157577514648438\n",
      "\n",
      "Val func train loss in epoch 12:0.19062179420143366\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.201481431722641\n",
      "\n",
      "episode 2, val func loss 0.21940061450004578\n",
      "\n",
      "episode 3, val func loss 0.1767074167728424\n",
      "\n",
      "episode 4, val func loss 0.17752481997013092\n",
      "\n",
      "episode 5, val func loss 0.19195964932441711\n",
      "\n",
      "episode 6, val func loss 0.18936994671821594\n",
      "\n",
      "episode 7, val func loss 0.18278735876083374\n",
      "\n",
      "episode 8, val func loss 0.18119727075099945\n",
      "\n",
      "episode 9, val func loss 0.20068934559822083\n",
      "\n",
      "episode 10, val func loss 0.20172019302845\n",
      "\n",
      "episode 11, val func loss 0.19773536920547485\n",
      "\n",
      "episode 12, val func loss 0.17972992360591888\n",
      "\n",
      "episode 13, val func loss 0.19855590164661407\n",
      "\n",
      "episode 14, val func loss 0.1909525990486145\n",
      "\n",
      "episode 15, val func loss 0.19388286769390106\n",
      "\n",
      "episode 16, val func loss 0.16643746197223663\n",
      "\n",
      "Val func train loss in epoch 13:0.19063326064497232\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18018627166748047\n",
      "\n",
      "episode 2, val func loss 0.19413453340530396\n",
      "\n",
      "episode 3, val func loss 0.16510258615016937\n",
      "\n",
      "episode 4, val func loss 0.1979619711637497\n",
      "\n",
      "episode 5, val func loss 0.1916373074054718\n",
      "\n",
      "episode 6, val func loss 0.18836461007595062\n",
      "\n",
      "episode 7, val func loss 0.19085678458213806\n",
      "\n",
      "episode 8, val func loss 0.17598757147789001\n",
      "\n",
      "episode 9, val func loss 0.20175418257713318\n",
      "\n",
      "episode 10, val func loss 0.17779424786567688\n",
      "\n",
      "episode 11, val func loss 0.20122800767421722\n",
      "\n",
      "episode 12, val func loss 0.1984439194202423\n",
      "\n",
      "episode 13, val func loss 0.1823830008506775\n",
      "\n",
      "episode 14, val func loss 0.18322207033634186\n",
      "\n",
      "episode 15, val func loss 0.21903552114963531\n",
      "\n",
      "episode 16, val func loss 0.2004687786102295\n",
      "\n",
      "Val func train loss in epoch 14:0.19053508527576923\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.2007429152727127\n",
      "\n",
      "episode 2, val func loss 0.2013167142868042\n",
      "\n",
      "episode 3, val func loss 0.1676761656999588\n",
      "\n",
      "episode 4, val func loss 0.18072567880153656\n",
      "\n",
      "episode 5, val func loss 0.17749656736850739\n",
      "\n",
      "episode 6, val func loss 0.19090726971626282\n",
      "\n",
      "episode 7, val func loss 0.20076601207256317\n",
      "\n",
      "episode 8, val func loss 0.1829971820116043\n",
      "\n",
      "episode 9, val func loss 0.19210882484912872\n",
      "\n",
      "episode 10, val func loss 0.19920897483825684\n",
      "\n",
      "episode 11, val func loss 0.18109555542469025\n",
      "\n",
      "episode 12, val func loss 0.17590096592903137\n",
      "\n",
      "episode 13, val func loss 0.22058019042015076\n",
      "\n",
      "episode 14, val func loss 0.19698159396648407\n",
      "\n",
      "episode 15, val func loss 0.1908285766839981\n",
      "\n",
      "episode 16, val func loss 0.19476667046546936\n",
      "\n",
      "Val func train loss in epoch 15:0.19088124111294746\n",
      "***********************TIME WAS 5.003861526648204 min*****************************\n",
      "\n",
      "**********************ROUND 130 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.010888372547924519\n",
      "\n",
      "episode 2, policy loss -0.05961407348513603\n",
      "\n",
      "episode 3, policy loss 0.03088563121855259\n",
      "\n",
      "episode 4, policy loss 0.006239200476557016\n",
      "\n",
      "episode 5, policy loss 0.0029852031730115414\n",
      "\n",
      "episode 6, policy loss -0.030148988589644432\n",
      "\n",
      "episode 7, policy loss -0.026011569425463676\n",
      "\n",
      "episode 8, policy loss 0.024849506095051765\n",
      "\n",
      "episode 9, policy loss -0.012026211246848106\n",
      "\n",
      "episode 10, policy loss -0.05984929949045181\n",
      "\n",
      "episode 11, policy loss -0.05925543233752251\n",
      "\n",
      "episode 12, policy loss 0.004951239097863436\n",
      "\n",
      "episode 13, policy loss -0.053005944937467575\n",
      "\n",
      "episode 14, policy loss -0.002499941037967801\n",
      "\n",
      "episode 15, policy loss -0.03927340358495712\n",
      "\n",
      "episode 16, policy loss -0.053261514753103256\n",
      "\n",
      "Policy train loss in epoch 0:-0.020995248210965656\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.07051318883895874\n",
      "\n",
      "episode 2, policy loss -0.06098758801817894\n",
      "\n",
      "episode 3, policy loss -0.031175605952739716\n",
      "\n",
      "episode 4, policy loss -0.022763241082429886\n",
      "\n",
      "episode 5, policy loss -0.05743510648608208\n",
      "\n",
      "episode 6, policy loss 0.002170847961679101\n",
      "\n",
      "episode 7, policy loss -0.02880396507680416\n",
      "\n",
      "episode 8, policy loss 0.0028755036182701588\n",
      "\n",
      "episode 9, policy loss -0.004172549583017826\n",
      "\n",
      "episode 10, policy loss -0.06351976096630096\n",
      "\n",
      "episode 11, policy loss 0.024311279878020287\n",
      "\n",
      "episode 12, policy loss 0.02763006091117859\n",
      "\n",
      "episode 13, policy loss -0.05484861508011818\n",
      "\n",
      "episode 14, policy loss -0.012408110313117504\n",
      "\n",
      "episode 15, policy loss -0.04160856828093529\n",
      "\n",
      "episode 16, policy loss 0.0011940893018618226\n",
      "\n",
      "Policy train loss in epoch 1:-0.024378407375479583\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.012018232606351376\n",
      "\n",
      "episode 2, policy loss 0.002983198734000325\n",
      "\n",
      "episode 3, policy loss 0.00162936607375741\n",
      "\n",
      "episode 4, policy loss -0.023732667788863182\n",
      "\n",
      "episode 5, policy loss -0.056766100227832794\n",
      "\n",
      "episode 6, policy loss -0.028738901019096375\n",
      "\n",
      "episode 7, policy loss -0.031108975410461426\n",
      "\n",
      "episode 8, policy loss 0.023160558193922043\n",
      "\n",
      "episode 9, policy loss -0.00568612152710557\n",
      "\n",
      "episode 10, policy loss -0.06300134211778641\n",
      "\n",
      "episode 11, policy loss 0.027118543162941933\n",
      "\n",
      "episode 12, policy loss -0.04122990369796753\n",
      "\n",
      "episode 13, policy loss 0.00034240313107147813\n",
      "\n",
      "episode 14, policy loss -0.07085146754980087\n",
      "\n",
      "episode 15, policy loss -0.05828205868601799\n",
      "\n",
      "episode 16, policy loss -0.06416729092597961\n",
      "\n",
      "Policy train loss in epoch 2:-0.02502181201634812\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.012589627876877785\n",
      "\n",
      "episode 2, policy loss -0.04170896112918854\n",
      "\n",
      "episode 3, policy loss -0.07058877497911453\n",
      "\n",
      "episode 4, policy loss -0.05631005018949509\n",
      "\n",
      "episode 5, policy loss -0.02405841462314129\n",
      "\n",
      "episode 6, policy loss 0.0013019782491028309\n",
      "\n",
      "episode 7, policy loss 0.02379637025296688\n",
      "\n",
      "episode 8, policy loss -0.06400381028652191\n",
      "\n",
      "episode 9, policy loss -0.05840935558080673\n",
      "\n",
      "episode 10, policy loss 0.0002903528802562505\n",
      "\n",
      "episode 11, policy loss -0.005396976601332426\n",
      "\n",
      "episode 12, policy loss -0.06354118138551712\n",
      "\n",
      "episode 13, policy loss 0.001482132007367909\n",
      "\n",
      "episode 14, policy loss -0.031505804508924484\n",
      "\n",
      "episode 15, policy loss 0.027121366932988167\n",
      "\n",
      "episode 16, policy loss -0.02901878021657467\n",
      "\n",
      "Policy train loss in epoch 3:-0.025196221065925783\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.21477019786834717\n",
      "\n",
      "episode 2, val func loss 0.1658182144165039\n",
      "\n",
      "episode 3, val func loss 0.1888612061738968\n",
      "\n",
      "episode 4, val func loss 0.19284935295581818\n",
      "\n",
      "episode 5, val func loss 0.19721998274326324\n",
      "\n",
      "episode 6, val func loss 0.2246212512254715\n",
      "\n",
      "episode 7, val func loss 0.20553116500377655\n",
      "\n",
      "episode 8, val func loss 0.17986369132995605\n",
      "\n",
      "episode 9, val func loss 0.20387865602970123\n",
      "\n",
      "episode 10, val func loss 0.1963648796081543\n",
      "\n",
      "episode 11, val func loss 0.18054822087287903\n",
      "\n",
      "episode 12, val func loss 0.18622581660747528\n",
      "\n",
      "episode 13, val func loss 0.1833471804857254\n",
      "\n",
      "episode 14, val func loss 0.2117089033126831\n",
      "\n",
      "episode 15, val func loss 0.20142443478107452\n",
      "\n",
      "episode 16, val func loss 0.20496849715709686\n",
      "\n",
      "Val func train loss in epoch 0:0.19612510316073895\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19717030227184296\n",
      "\n",
      "episode 2, val func loss 0.21476417779922485\n",
      "\n",
      "episode 3, val func loss 0.1909533590078354\n",
      "\n",
      "episode 4, val func loss 0.1808190941810608\n",
      "\n",
      "episode 5, val func loss 0.18369442224502563\n",
      "\n",
      "episode 6, val func loss 0.19599919021129608\n",
      "\n",
      "episode 7, val func loss 0.2121027708053589\n",
      "\n",
      "episode 8, val func loss 0.20559437572956085\n",
      "\n",
      "episode 9, val func loss 0.2019156962633133\n",
      "\n",
      "episode 10, val func loss 0.17902125418186188\n",
      "\n",
      "episode 11, val func loss 0.2054908275604248\n",
      "\n",
      "episode 12, val func loss 0.1927931308746338\n",
      "\n",
      "episode 13, val func loss 0.20238223671913147\n",
      "\n",
      "episode 14, val func loss 0.22165441513061523\n",
      "\n",
      "episode 15, val func loss 0.1658376008272171\n",
      "\n",
      "episode 16, val func loss 0.1875714510679245\n",
      "\n",
      "Val func train loss in epoch 1:0.19611026905477047\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19652646780014038\n",
      "\n",
      "episode 2, val func loss 0.21470846235752106\n",
      "\n",
      "episode 3, val func loss 0.1863870620727539\n",
      "\n",
      "episode 4, val func loss 0.19692504405975342\n",
      "\n",
      "episode 5, val func loss 0.18323230743408203\n",
      "\n",
      "episode 6, val func loss 0.17997336387634277\n",
      "\n",
      "episode 7, val func loss 0.20366038382053375\n",
      "\n",
      "episode 8, val func loss 0.2123100757598877\n",
      "\n",
      "episode 9, val func loss 0.20545326173305511\n",
      "\n",
      "episode 10, val func loss 0.17991743981838226\n",
      "\n",
      "episode 11, val func loss 0.20511020720005035\n",
      "\n",
      "episode 12, val func loss 0.19299836456775665\n",
      "\n",
      "episode 13, val func loss 0.22148804366588593\n",
      "\n",
      "episode 14, val func loss 0.18909765779972076\n",
      "\n",
      "episode 15, val func loss 0.20096451044082642\n",
      "\n",
      "episode 16, val func loss 0.1647804081439972\n",
      "\n",
      "Val func train loss in epoch 2:0.1958458162844181\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20549671351909637\n",
      "\n",
      "episode 2, val func loss 0.19295468926429749\n",
      "\n",
      "episode 3, val func loss 0.18593335151672363\n",
      "\n",
      "episode 4, val func loss 0.19685059785842896\n",
      "\n",
      "episode 5, val func loss 0.22293932735919952\n",
      "\n",
      "episode 6, val func loss 0.21519118547439575\n",
      "\n",
      "episode 7, val func loss 0.19622720777988434\n",
      "\n",
      "episode 8, val func loss 0.21128197014331818\n",
      "\n",
      "episode 9, val func loss 0.1803324818611145\n",
      "\n",
      "episode 10, val func loss 0.20463827252388\n",
      "\n",
      "episode 11, val func loss 0.2005721777677536\n",
      "\n",
      "episode 12, val func loss 0.1832507997751236\n",
      "\n",
      "episode 13, val func loss 0.184840127825737\n",
      "\n",
      "episode 14, val func loss 0.2003202736377716\n",
      "\n",
      "episode 15, val func loss 0.1899695247411728\n",
      "\n",
      "episode 16, val func loss 0.16510963439941406\n",
      "\n",
      "Val func train loss in epoch 3:0.19599427096545696\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.20533417165279388\n",
      "\n",
      "episode 2, val func loss 0.16397204995155334\n",
      "\n",
      "episode 3, val func loss 0.20265959203243256\n",
      "\n",
      "episode 4, val func loss 0.18347886204719543\n",
      "\n",
      "episode 5, val func loss 0.18602517247200012\n",
      "\n",
      "episode 6, val func loss 0.21383211016654968\n",
      "\n",
      "episode 7, val func loss 0.19720877707004547\n",
      "\n",
      "episode 8, val func loss 0.21514753997325897\n",
      "\n",
      "episode 9, val func loss 0.20540955662727356\n",
      "\n",
      "episode 10, val func loss 0.22142240405082703\n",
      "\n",
      "episode 11, val func loss 0.20020896196365356\n",
      "\n",
      "episode 12, val func loss 0.19835583865642548\n",
      "\n",
      "episode 13, val func loss 0.18621668219566345\n",
      "\n",
      "episode 14, val func loss 0.19773969054222107\n",
      "\n",
      "episode 15, val func loss 0.18088871240615845\n",
      "\n",
      "episode 16, val func loss 0.18842214345932007\n",
      "\n",
      "Val func train loss in epoch 4:0.19664514157921076\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.20423667132854462\n",
      "\n",
      "episode 2, val func loss 0.2057301551103592\n",
      "\n",
      "episode 3, val func loss 0.1873481571674347\n",
      "\n",
      "episode 4, val func loss 0.21430979669094086\n",
      "\n",
      "episode 5, val func loss 0.16346201300621033\n",
      "\n",
      "episode 6, val func loss 0.20680035650730133\n",
      "\n",
      "episode 7, val func loss 0.18341311812400818\n",
      "\n",
      "episode 8, val func loss 0.1967279613018036\n",
      "\n",
      "episode 9, val func loss 0.18704991042613983\n",
      "\n",
      "episode 10, val func loss 0.1801285594701767\n",
      "\n",
      "episode 11, val func loss 0.19263827800750732\n",
      "\n",
      "episode 12, val func loss 0.17967568337917328\n",
      "\n",
      "episode 13, val func loss 0.21580477058887482\n",
      "\n",
      "episode 14, val func loss 0.22486606240272522\n",
      "\n",
      "episode 15, val func loss 0.20264826714992523\n",
      "\n",
      "episode 16, val func loss 0.19643394649028778\n",
      "\n",
      "Val func train loss in epoch 5:0.1963296066969633\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.20556354522705078\n",
      "\n",
      "episode 2, val func loss 0.20998863875865936\n",
      "\n",
      "episode 3, val func loss 0.19794929027557373\n",
      "\n",
      "episode 4, val func loss 0.20006060600280762\n",
      "\n",
      "episode 5, val func loss 0.18930576741695404\n",
      "\n",
      "episode 6, val func loss 0.19524027407169342\n",
      "\n",
      "episode 7, val func loss 0.20048888027668\n",
      "\n",
      "episode 8, val func loss 0.16505056619644165\n",
      "\n",
      "episode 9, val func loss 0.17872072756290436\n",
      "\n",
      "episode 10, val func loss 0.1834307760000229\n",
      "\n",
      "episode 11, val func loss 0.22480596601963043\n",
      "\n",
      "episode 12, val func loss 0.19665801525115967\n",
      "\n",
      "episode 13, val func loss 0.2077932208776474\n",
      "\n",
      "episode 14, val func loss 0.21594367921352386\n",
      "\n",
      "episode 15, val func loss 0.1879226118326187\n",
      "\n",
      "episode 16, val func loss 0.17972785234451294\n",
      "\n",
      "Val func train loss in epoch 6:0.19616565108299255\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18334153294563293\n",
      "\n",
      "episode 2, val func loss 0.19687104225158691\n",
      "\n",
      "episode 3, val func loss 0.20127807557582855\n",
      "\n",
      "episode 4, val func loss 0.20470941066741943\n",
      "\n",
      "episode 5, val func loss 0.22078236937522888\n",
      "\n",
      "episode 6, val func loss 0.19699816405773163\n",
      "\n",
      "episode 7, val func loss 0.2073259949684143\n",
      "\n",
      "episode 8, val func loss 0.19734984636306763\n",
      "\n",
      "episode 9, val func loss 0.1808055192232132\n",
      "\n",
      "episode 10, val func loss 0.18823856115341187\n",
      "\n",
      "episode 11, val func loss 0.21289420127868652\n",
      "\n",
      "episode 12, val func loss 0.16343602538108826\n",
      "\n",
      "episode 13, val func loss 0.18603748083114624\n",
      "\n",
      "episode 14, val func loss 0.20622432231903076\n",
      "\n",
      "episode 15, val func loss 0.17974737286567688\n",
      "\n",
      "episode 16, val func loss 0.21593014895915985\n",
      "\n",
      "Val func train loss in epoch 7:0.19637312926352024\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17824682593345642\n",
      "\n",
      "episode 2, val func loss 0.16364184021949768\n",
      "\n",
      "episode 3, val func loss 0.18743187189102173\n",
      "\n",
      "episode 4, val func loss 0.21574915945529938\n",
      "\n",
      "episode 5, val func loss 0.20554980635643005\n",
      "\n",
      "episode 6, val func loss 0.223744735121727\n",
      "\n",
      "episode 7, val func loss 0.18354500830173492\n",
      "\n",
      "episode 8, val func loss 0.2111416459083557\n",
      "\n",
      "episode 9, val func loss 0.1877094954252243\n",
      "\n",
      "episode 10, val func loss 0.20429350435733795\n",
      "\n",
      "episode 11, val func loss 0.1975669115781784\n",
      "\n",
      "episode 12, val func loss 0.20038539171218872\n",
      "\n",
      "episode 13, val func loss 0.20046570897102356\n",
      "\n",
      "episode 14, val func loss 0.19734922051429749\n",
      "\n",
      "episode 15, val func loss 0.1947447806596756\n",
      "\n",
      "episode 16, val func loss 0.18105348944664001\n",
      "\n",
      "Val func train loss in epoch 8:0.19578871224075556\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20461221039295197\n",
      "\n",
      "episode 2, val func loss 0.19658790528774261\n",
      "\n",
      "episode 3, val func loss 0.16421079635620117\n",
      "\n",
      "episode 4, val func loss 0.2116820365190506\n",
      "\n",
      "episode 5, val func loss 0.21493974328041077\n",
      "\n",
      "episode 6, val func loss 0.17979304492473602\n",
      "\n",
      "episode 7, val func loss 0.1928400844335556\n",
      "\n",
      "episode 8, val func loss 0.20569010078907013\n",
      "\n",
      "episode 9, val func loss 0.17829157412052155\n",
      "\n",
      "episode 10, val func loss 0.1832868605852127\n",
      "\n",
      "episode 11, val func loss 0.20285393297672272\n",
      "\n",
      "episode 12, val func loss 0.18749892711639404\n",
      "\n",
      "episode 13, val func loss 0.19637063145637512\n",
      "\n",
      "episode 14, val func loss 0.22387351095676422\n",
      "\n",
      "episode 15, val func loss 0.18586641550064087\n",
      "\n",
      "episode 16, val func loss 0.2029932588338852\n",
      "\n",
      "Val func train loss in epoch 9:0.1957119395956397\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.2051408588886261\n",
      "\n",
      "episode 2, val func loss 0.2204638123512268\n",
      "\n",
      "episode 3, val func loss 0.19784007966518402\n",
      "\n",
      "episode 4, val func loss 0.200053408741951\n",
      "\n",
      "episode 5, val func loss 0.1948101669549942\n",
      "\n",
      "episode 6, val func loss 0.1694812774658203\n",
      "\n",
      "episode 7, val func loss 0.20000852644443512\n",
      "\n",
      "episode 8, val func loss 0.1971449851989746\n",
      "\n",
      "episode 9, val func loss 0.1937071830034256\n",
      "\n",
      "episode 10, val func loss 0.21485432982444763\n",
      "\n",
      "episode 11, val func loss 0.1832600086927414\n",
      "\n",
      "episode 12, val func loss 0.17988118529319763\n",
      "\n",
      "episode 13, val func loss 0.2136950045824051\n",
      "\n",
      "episode 14, val func loss 0.18611308932304382\n",
      "\n",
      "episode 15, val func loss 0.17729362845420837\n",
      "\n",
      "episode 16, val func loss 0.20612667500972748\n",
      "\n",
      "Val func train loss in epoch 10:0.19624213874340057\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.21619179844856262\n",
      "\n",
      "episode 2, val func loss 0.17983673512935638\n",
      "\n",
      "episode 3, val func loss 0.1776944249868393\n",
      "\n",
      "episode 4, val func loss 0.20488527417182922\n",
      "\n",
      "episode 5, val func loss 0.16373750567436218\n",
      "\n",
      "episode 6, val func loss 0.20559684932231903\n",
      "\n",
      "episode 7, val func loss 0.21185551583766937\n",
      "\n",
      "episode 8, val func loss 0.18361598253250122\n",
      "\n",
      "episode 9, val func loss 0.2008827030658722\n",
      "\n",
      "episode 10, val func loss 0.18725129961967468\n",
      "\n",
      "episode 11, val func loss 0.22066786885261536\n",
      "\n",
      "episode 12, val func loss 0.1973077952861786\n",
      "\n",
      "episode 13, val func loss 0.19488778710365295\n",
      "\n",
      "episode 14, val func loss 0.19692134857177734\n",
      "\n",
      "episode 15, val func loss 0.20478405058383942\n",
      "\n",
      "episode 16, val func loss 0.18931250274181366\n",
      "\n",
      "Val func train loss in epoch 11:0.19596434012055397\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.21100786328315735\n",
      "\n",
      "episode 2, val func loss 0.17927762866020203\n",
      "\n",
      "episode 3, val func loss 0.1797802597284317\n",
      "\n",
      "episode 4, val func loss 0.19705051183700562\n",
      "\n",
      "episode 5, val func loss 0.21557043492794037\n",
      "\n",
      "episode 6, val func loss 0.20675170421600342\n",
      "\n",
      "episode 7, val func loss 0.20567412674427032\n",
      "\n",
      "episode 8, val func loss 0.1857825219631195\n",
      "\n",
      "episode 9, val func loss 0.16381624341011047\n",
      "\n",
      "episode 10, val func loss 0.1832134872674942\n",
      "\n",
      "episode 11, val func loss 0.2032468467950821\n",
      "\n",
      "episode 12, val func loss 0.20159456133842468\n",
      "\n",
      "episode 13, val func loss 0.19636766612529755\n",
      "\n",
      "episode 14, val func loss 0.18894651532173157\n",
      "\n",
      "episode 15, val func loss 0.22154124081134796\n",
      "\n",
      "episode 16, val func loss 0.19327105581760406\n",
      "\n",
      "Val func train loss in epoch 12:0.19580579176545143\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19692853093147278\n",
      "\n",
      "episode 2, val func loss 0.22083228826522827\n",
      "\n",
      "episode 3, val func loss 0.20416401326656342\n",
      "\n",
      "episode 4, val func loss 0.18448606133460999\n",
      "\n",
      "episode 5, val func loss 0.19014765322208405\n",
      "\n",
      "episode 6, val func loss 0.19691185653209686\n",
      "\n",
      "episode 7, val func loss 0.18689537048339844\n",
      "\n",
      "episode 8, val func loss 0.16464973986148834\n",
      "\n",
      "episode 9, val func loss 0.20180802047252655\n",
      "\n",
      "episode 10, val func loss 0.20381617546081543\n",
      "\n",
      "episode 11, val func loss 0.21236401796340942\n",
      "\n",
      "episode 12, val func loss 0.19247254729270935\n",
      "\n",
      "episode 13, val func loss 0.21492457389831543\n",
      "\n",
      "episode 14, val func loss 0.17906565964221954\n",
      "\n",
      "episode 15, val func loss 0.20536692440509796\n",
      "\n",
      "episode 16, val func loss 0.1799432337284088\n",
      "\n",
      "Val func train loss in epoch 13:0.1959235416725278\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.21478714048862457\n",
      "\n",
      "episode 2, val func loss 0.19667890667915344\n",
      "\n",
      "episode 3, val func loss 0.18594788014888763\n",
      "\n",
      "episode 4, val func loss 0.2222808450460434\n",
      "\n",
      "episode 5, val func loss 0.17989481985569\n",
      "\n",
      "episode 6, val func loss 0.18840815126895905\n",
      "\n",
      "episode 7, val func loss 0.2113221287727356\n",
      "\n",
      "episode 8, val func loss 0.19298243522644043\n",
      "\n",
      "episode 9, val func loss 0.1961362361907959\n",
      "\n",
      "episode 10, val func loss 0.18356138467788696\n",
      "\n",
      "episode 11, val func loss 0.20232349634170532\n",
      "\n",
      "episode 12, val func loss 0.20526939630508423\n",
      "\n",
      "episode 13, val func loss 0.16473054885864258\n",
      "\n",
      "episode 14, val func loss 0.20093290507793427\n",
      "\n",
      "episode 15, val func loss 0.18019510805606842\n",
      "\n",
      "episode 16, val func loss 0.20546047389507294\n",
      "\n",
      "Val func train loss in epoch 14:0.1956819910556078\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.16499893367290497\n",
      "\n",
      "episode 2, val func loss 0.19307862222194672\n",
      "\n",
      "episode 3, val func loss 0.1799720972776413\n",
      "\n",
      "episode 4, val func loss 0.2039792835712433\n",
      "\n",
      "episode 5, val func loss 0.1973351389169693\n",
      "\n",
      "episode 6, val func loss 0.177594393491745\n",
      "\n",
      "episode 7, val func loss 0.20545566082000732\n",
      "\n",
      "episode 8, val func loss 0.1874988079071045\n",
      "\n",
      "episode 9, val func loss 0.18324677646160126\n",
      "\n",
      "episode 10, val func loss 0.18582765758037567\n",
      "\n",
      "episode 11, val func loss 0.19637715816497803\n",
      "\n",
      "episode 12, val func loss 0.20711131393909454\n",
      "\n",
      "episode 13, val func loss 0.21556176245212555\n",
      "\n",
      "episode 14, val func loss 0.2023223638534546\n",
      "\n",
      "episode 15, val func loss 0.22227096557617188\n",
      "\n",
      "episode 16, val func loss 0.21052373945713043\n",
      "\n",
      "Val func train loss in epoch 15:0.1958221672102809\n",
      "***********************TIME WAS 5.004603930314382 min*****************************\n",
      "\n",
      "**********************ROUND 131 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.04232530668377876\n",
      "\n",
      "episode 2, policy loss -0.043920423835515976\n",
      "\n",
      "episode 3, policy loss -0.0007554402691312134\n",
      "\n",
      "episode 4, policy loss 0.03522283211350441\n",
      "\n",
      "episode 5, policy loss 0.03167908638715744\n",
      "\n",
      "episode 6, policy loss -0.04172215983271599\n",
      "\n",
      "episode 7, policy loss -0.010194515809416771\n",
      "\n",
      "episode 8, policy loss -0.03980463370680809\n",
      "\n",
      "episode 9, policy loss -0.014811428263783455\n",
      "\n",
      "episode 10, policy loss -0.04087933525443077\n",
      "\n",
      "episode 11, policy loss -0.03602397441864014\n",
      "\n",
      "episode 12, policy loss 0.023329611867666245\n",
      "\n",
      "episode 13, policy loss 0.025572022423148155\n",
      "\n",
      "episode 14, policy loss 0.0018583342898637056\n",
      "\n",
      "episode 15, policy loss -0.010630461387336254\n",
      "\n",
      "episode 16, policy loss -0.040596943348646164\n",
      "\n",
      "Policy train loss in epoch 0:-0.012750170983053977\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.045408859848976135\n",
      "\n",
      "episode 2, policy loss 0.0002411964233033359\n",
      "\n",
      "episode 3, policy loss 0.03007662110030651\n",
      "\n",
      "episode 4, policy loss 0.023579319939017296\n",
      "\n",
      "episode 5, policy loss -0.04167778044939041\n",
      "\n",
      "episode 6, policy loss -0.018350355327129364\n",
      "\n",
      "episode 7, policy loss -0.041751060634851456\n",
      "\n",
      "episode 8, policy loss -0.011444988660514355\n",
      "\n",
      "episode 9, policy loss -0.042734820395708084\n",
      "\n",
      "episode 10, policy loss 0.0340181328356266\n",
      "\n",
      "episode 11, policy loss -0.05342123284935951\n",
      "\n",
      "episode 12, policy loss -0.012982746586203575\n",
      "\n",
      "episode 13, policy loss -0.0073153916746377945\n",
      "\n",
      "episode 14, policy loss -0.05721161887049675\n",
      "\n",
      "episode 15, policy loss -0.04297737032175064\n",
      "\n",
      "episode 16, policy loss 0.023089345544576645\n",
      "\n",
      "Policy train loss in epoch 1:-0.01651697561101173\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.04653456434607506\n",
      "\n",
      "episode 2, policy loss -0.006441387347877026\n",
      "\n",
      "episode 3, policy loss 0.030645698308944702\n",
      "\n",
      "episode 4, policy loss 0.022656671702861786\n",
      "\n",
      "episode 5, policy loss -0.043811261653900146\n",
      "\n",
      "episode 6, policy loss -0.018459349870681763\n",
      "\n",
      "episode 7, policy loss -0.04278531298041344\n",
      "\n",
      "episode 8, policy loss -0.04164823889732361\n",
      "\n",
      "episode 9, policy loss 0.023891830816864967\n",
      "\n",
      "episode 10, policy loss 0.0006503094336949289\n",
      "\n",
      "episode 11, policy loss 0.03386218100786209\n",
      "\n",
      "episode 12, policy loss -0.042004186660051346\n",
      "\n",
      "episode 13, policy loss -0.05395176634192467\n",
      "\n",
      "episode 14, policy loss -0.013364648446440697\n",
      "\n",
      "episode 15, policy loss -0.0585116483271122\n",
      "\n",
      "episode 16, policy loss -0.01338449027389288\n",
      "\n",
      "Policy train loss in epoch 2:-0.016824385242216522\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.0005828639841638505\n",
      "\n",
      "episode 2, policy loss -0.04665588214993477\n",
      "\n",
      "episode 3, policy loss -0.04334848001599312\n",
      "\n",
      "episode 4, policy loss -0.042805735021829605\n",
      "\n",
      "episode 5, policy loss -0.0064683579839766026\n",
      "\n",
      "episode 6, policy loss 0.022355221211910248\n",
      "\n",
      "episode 7, policy loss 0.031519658863544464\n",
      "\n",
      "episode 8, policy loss -0.05957544595003128\n",
      "\n",
      "episode 9, policy loss 0.02326793223619461\n",
      "\n",
      "episode 10, policy loss -0.053710613399744034\n",
      "\n",
      "episode 11, policy loss -0.011822168715298176\n",
      "\n",
      "episode 12, policy loss 0.03365946188569069\n",
      "\n",
      "episode 13, policy loss -0.04173830896615982\n",
      "\n",
      "episode 14, policy loss -0.013262039981782436\n",
      "\n",
      "episode 15, policy loss -0.018388891592621803\n",
      "\n",
      "episode 16, policy loss -0.0439748577773571\n",
      "\n",
      "Policy train loss in epoch 3:-0.016897852710826555\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.21324804425239563\n",
      "\n",
      "episode 2, val func loss 0.1993372142314911\n",
      "\n",
      "episode 3, val func loss 0.20269723236560822\n",
      "\n",
      "episode 4, val func loss 0.22607149183750153\n",
      "\n",
      "episode 5, val func loss 0.18565841019153595\n",
      "\n",
      "episode 6, val func loss 0.17913325130939484\n",
      "\n",
      "episode 7, val func loss 0.17948806285858154\n",
      "\n",
      "episode 8, val func loss 0.1854206621646881\n",
      "\n",
      "episode 9, val func loss 0.16589826345443726\n",
      "\n",
      "episode 10, val func loss 0.19969765841960907\n",
      "\n",
      "episode 11, val func loss 0.19771982729434967\n",
      "\n",
      "episode 12, val func loss 0.20386546850204468\n",
      "\n",
      "episode 13, val func loss 0.21970228850841522\n",
      "\n",
      "episode 14, val func loss 0.16519196331501007\n",
      "\n",
      "episode 15, val func loss 0.19179490208625793\n",
      "\n",
      "episode 16, val func loss 0.18562109768390656\n",
      "\n",
      "Val func train loss in epoch 0:0.1937841149047017\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.21316714584827423\n",
      "\n",
      "episode 2, val func loss 0.18481996655464172\n",
      "\n",
      "episode 3, val func loss 0.19551053643226624\n",
      "\n",
      "episode 4, val func loss 0.2018512636423111\n",
      "\n",
      "episode 5, val func loss 0.1802828013896942\n",
      "\n",
      "episode 6, val func loss 0.2000168114900589\n",
      "\n",
      "episode 7, val func loss 0.18721985816955566\n",
      "\n",
      "episode 8, val func loss 0.17592492699623108\n",
      "\n",
      "episode 9, val func loss 0.16510100662708282\n",
      "\n",
      "episode 10, val func loss 0.2168542444705963\n",
      "\n",
      "episode 11, val func loss 0.22662441432476044\n",
      "\n",
      "episode 12, val func loss 0.16639523208141327\n",
      "\n",
      "episode 13, val func loss 0.20049595832824707\n",
      "\n",
      "episode 14, val func loss 0.17274993658065796\n",
      "\n",
      "episode 15, val func loss 0.1957940012216568\n",
      "\n",
      "episode 16, val func loss 0.1919306516647339\n",
      "\n",
      "Val func train loss in epoch 1:0.19217117223888636\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17380480468273163\n",
      "\n",
      "episode 2, val func loss 0.19623976945877075\n",
      "\n",
      "episode 3, val func loss 0.1976354867219925\n",
      "\n",
      "episode 4, val func loss 0.20330168306827545\n",
      "\n",
      "episode 5, val func loss 0.165602445602417\n",
      "\n",
      "episode 6, val func loss 0.21387025713920593\n",
      "\n",
      "episode 7, val func loss 0.19193387031555176\n",
      "\n",
      "episode 8, val func loss 0.2005893886089325\n",
      "\n",
      "episode 9, val func loss 0.20097409188747406\n",
      "\n",
      "episode 10, val func loss 0.22560526430606842\n",
      "\n",
      "episode 11, val func loss 0.18501456081867218\n",
      "\n",
      "episode 12, val func loss 0.18058288097381592\n",
      "\n",
      "episode 13, val func loss 0.16542355716228485\n",
      "\n",
      "episode 14, val func loss 0.1875704526901245\n",
      "\n",
      "episode 15, val func loss 0.17374876141548157\n",
      "\n",
      "episode 16, val func loss 0.21624618768692017\n",
      "\n",
      "Val func train loss in epoch 2:0.19238396640866995\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19196917116641998\n",
      "\n",
      "episode 2, val func loss 0.1650184690952301\n",
      "\n",
      "episode 3, val func loss 0.1846962571144104\n",
      "\n",
      "episode 4, val func loss 0.22736027836799622\n",
      "\n",
      "episode 5, val func loss 0.16557979583740234\n",
      "\n",
      "episode 6, val func loss 0.2141924500465393\n",
      "\n",
      "episode 7, val func loss 0.20095732808113098\n",
      "\n",
      "episode 8, val func loss 0.19578465819358826\n",
      "\n",
      "episode 9, val func loss 0.17247025668621063\n",
      "\n",
      "episode 10, val func loss 0.17920756340026855\n",
      "\n",
      "episode 11, val func loss 0.19587567448616028\n",
      "\n",
      "episode 12, val func loss 0.17461219429969788\n",
      "\n",
      "episode 13, val func loss 0.20246632397174835\n",
      "\n",
      "episode 14, val func loss 0.20066875219345093\n",
      "\n",
      "episode 15, val func loss 0.1858857274055481\n",
      "\n",
      "episode 16, val func loss 0.2162698656320572\n",
      "\n",
      "Val func train loss in epoch 3:0.19206342287361622\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18633215129375458\n",
      "\n",
      "episode 2, val func loss 0.20187145471572876\n",
      "\n",
      "episode 3, val func loss 0.1960485279560089\n",
      "\n",
      "episode 4, val func loss 0.22580039501190186\n",
      "\n",
      "episode 5, val func loss 0.21624942123889923\n",
      "\n",
      "episode 6, val func loss 0.1735311895608902\n",
      "\n",
      "episode 7, val func loss 0.18485602736473083\n",
      "\n",
      "episode 8, val func loss 0.1753627210855484\n",
      "\n",
      "episode 9, val func loss 0.19220808148384094\n",
      "\n",
      "episode 10, val func loss 0.16618409752845764\n",
      "\n",
      "episode 11, val func loss 0.20075641572475433\n",
      "\n",
      "episode 12, val func loss 0.17882056534290314\n",
      "\n",
      "episode 13, val func loss 0.20248988270759583\n",
      "\n",
      "episode 14, val func loss 0.1653784066438675\n",
      "\n",
      "episode 15, val func loss 0.21462689340114594\n",
      "\n",
      "episode 16, val func loss 0.19704662263393402\n",
      "\n",
      "Val func train loss in epoch 4:0.19234767835587263\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19613169133663177\n",
      "\n",
      "episode 2, val func loss 0.2137024998664856\n",
      "\n",
      "episode 3, val func loss 0.18496140837669373\n",
      "\n",
      "episode 4, val func loss 0.19975848495960236\n",
      "\n",
      "episode 5, val func loss 0.1944025754928589\n",
      "\n",
      "episode 6, val func loss 0.22536233067512512\n",
      "\n",
      "episode 7, val func loss 0.1762007176876068\n",
      "\n",
      "episode 8, val func loss 0.2153463214635849\n",
      "\n",
      "episode 9, val func loss 0.20167233049869537\n",
      "\n",
      "episode 10, val func loss 0.1824139803647995\n",
      "\n",
      "episode 11, val func loss 0.19971750676631927\n",
      "\n",
      "episode 12, val func loss 0.18812593817710876\n",
      "\n",
      "episode 13, val func loss 0.1756187081336975\n",
      "\n",
      "episode 14, val func loss 0.19170670211315155\n",
      "\n",
      "episode 15, val func loss 0.16511687636375427\n",
      "\n",
      "episode 16, val func loss 0.16648107767105103\n",
      "\n",
      "Val func train loss in epoch 5:0.1922949468716979\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17203527688980103\n",
      "\n",
      "episode 2, val func loss 0.17363911867141724\n",
      "\n",
      "episode 3, val func loss 0.2191883623600006\n",
      "\n",
      "episode 4, val func loss 0.22249644994735718\n",
      "\n",
      "episode 5, val func loss 0.22922740876674652\n",
      "\n",
      "episode 6, val func loss 0.2034207284450531\n",
      "\n",
      "episode 7, val func loss 0.19207200407981873\n",
      "\n",
      "episode 8, val func loss 0.16509124636650085\n",
      "\n",
      "episode 9, val func loss 0.19616453349590302\n",
      "\n",
      "episode 10, val func loss 0.18560218811035156\n",
      "\n",
      "episode 11, val func loss 0.19440124928951263\n",
      "\n",
      "episode 12, val func loss 0.16997015476226807\n",
      "\n",
      "episode 13, val func loss 0.19964027404785156\n",
      "\n",
      "episode 14, val func loss 0.1866115927696228\n",
      "\n",
      "episode 15, val func loss 0.20245690643787384\n",
      "\n",
      "episode 16, val func loss 0.17876115441322327\n",
      "\n",
      "Val func train loss in epoch 6:0.19317366555333138\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.20212988555431366\n",
      "\n",
      "episode 2, val func loss 0.20226147770881653\n",
      "\n",
      "episode 3, val func loss 0.1947273164987564\n",
      "\n",
      "episode 4, val func loss 0.18562151491641998\n",
      "\n",
      "episode 5, val func loss 0.18935605883598328\n",
      "\n",
      "episode 6, val func loss 0.2254139930009842\n",
      "\n",
      "episode 7, val func loss 0.1690349578857422\n",
      "\n",
      "episode 8, val func loss 0.19610048830509186\n",
      "\n",
      "episode 9, val func loss 0.21744902431964874\n",
      "\n",
      "episode 10, val func loss 0.2140015959739685\n",
      "\n",
      "episode 11, val func loss 0.17234916985034943\n",
      "\n",
      "episode 12, val func loss 0.20064492523670197\n",
      "\n",
      "episode 13, val func loss 0.17419952154159546\n",
      "\n",
      "episode 14, val func loss 0.19191765785217285\n",
      "\n",
      "episode 15, val func loss 0.16502805054187775\n",
      "\n",
      "episode 16, val func loss 0.1789310723543167\n",
      "\n",
      "Val func train loss in epoch 7:0.19244791939854622\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1975623071193695\n",
      "\n",
      "episode 2, val func loss 0.17375729978084564\n",
      "\n",
      "episode 3, val func loss 0.19166801869869232\n",
      "\n",
      "episode 4, val func loss 0.1849842369556427\n",
      "\n",
      "episode 5, val func loss 0.16511870920658112\n",
      "\n",
      "episode 6, val func loss 0.20128154754638672\n",
      "\n",
      "episode 7, val func loss 0.20180097222328186\n",
      "\n",
      "episode 8, val func loss 0.20222461223602295\n",
      "\n",
      "episode 9, val func loss 0.166731059551239\n",
      "\n",
      "episode 10, val func loss 0.21329693496227264\n",
      "\n",
      "episode 11, val func loss 0.18508820235729218\n",
      "\n",
      "episode 12, val func loss 0.22544997930526733\n",
      "\n",
      "episode 13, val func loss 0.18061766028404236\n",
      "\n",
      "episode 14, val func loss 0.19616413116455078\n",
      "\n",
      "episode 15, val func loss 0.21535828709602356\n",
      "\n",
      "episode 16, val func loss 0.17352475225925446\n",
      "\n",
      "Val func train loss in epoch 8:0.19216429442167282\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.19976554811000824\n",
      "\n",
      "episode 2, val func loss 0.19258567690849304\n",
      "\n",
      "episode 3, val func loss 0.17283479869365692\n",
      "\n",
      "episode 4, val func loss 0.20282432436943054\n",
      "\n",
      "episode 5, val func loss 0.21758390963077545\n",
      "\n",
      "episode 6, val func loss 0.1787254810333252\n",
      "\n",
      "episode 7, val func loss 0.16579604148864746\n",
      "\n",
      "episode 8, val func loss 0.19603735208511353\n",
      "\n",
      "episode 9, val func loss 0.2018999606370926\n",
      "\n",
      "episode 10, val func loss 0.17378711700439453\n",
      "\n",
      "episode 11, val func loss 0.22674521803855896\n",
      "\n",
      "episode 12, val func loss 0.18481364846229553\n",
      "\n",
      "episode 13, val func loss 0.19580867886543274\n",
      "\n",
      "episode 14, val func loss 0.1859131157398224\n",
      "\n",
      "episode 15, val func loss 0.16498473286628723\n",
      "\n",
      "episode 16, val func loss 0.21340428292751312\n",
      "\n",
      "Val func train loss in epoch 9:0.19209436792880297\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.17315833270549774\n",
      "\n",
      "episode 2, val func loss 0.18637056648731232\n",
      "\n",
      "episode 3, val func loss 0.19595050811767578\n",
      "\n",
      "episode 4, val func loss 0.16521954536437988\n",
      "\n",
      "episode 5, val func loss 0.22645054757595062\n",
      "\n",
      "episode 6, val func loss 0.21727046370506287\n",
      "\n",
      "episode 7, val func loss 0.1918153017759323\n",
      "\n",
      "episode 8, val func loss 0.20021024346351624\n",
      "\n",
      "episode 9, val func loss 0.19565831124782562\n",
      "\n",
      "episode 10, val func loss 0.20199017226696014\n",
      "\n",
      "episode 11, val func loss 0.1760854721069336\n",
      "\n",
      "episode 12, val func loss 0.19997644424438477\n",
      "\n",
      "episode 13, val func loss 0.18030019104480743\n",
      "\n",
      "episode 14, val func loss 0.2130136936903\n",
      "\n",
      "episode 15, val func loss 0.16805998980998993\n",
      "\n",
      "episode 16, val func loss 0.18504196405410767\n",
      "\n",
      "Val func train loss in epoch 10:0.1922857342287898\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18498709797859192\n",
      "\n",
      "episode 2, val func loss 0.17925946414470673\n",
      "\n",
      "episode 3, val func loss 0.20067299902439117\n",
      "\n",
      "episode 4, val func loss 0.16504524648189545\n",
      "\n",
      "episode 5, val func loss 0.20195505023002625\n",
      "\n",
      "episode 6, val func loss 0.2027411311864853\n",
      "\n",
      "episode 7, val func loss 0.1657215654850006\n",
      "\n",
      "episode 8, val func loss 0.17430329322814941\n",
      "\n",
      "episode 9, val func loss 0.1722860485315323\n",
      "\n",
      "episode 10, val func loss 0.22692689299583435\n",
      "\n",
      "episode 11, val func loss 0.1848546415567398\n",
      "\n",
      "episode 12, val func loss 0.21404419839382172\n",
      "\n",
      "episode 13, val func loss 0.19613148272037506\n",
      "\n",
      "episode 14, val func loss 0.19176752865314484\n",
      "\n",
      "episode 15, val func loss 0.21746544539928436\n",
      "\n",
      "episode 16, val func loss 0.1958158314228058\n",
      "\n",
      "Val func train loss in epoch 11:0.19212361983954906\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19606997072696686\n",
      "\n",
      "episode 2, val func loss 0.19517844915390015\n",
      "\n",
      "episode 3, val func loss 0.20174333453178406\n",
      "\n",
      "episode 4, val func loss 0.18539254367351532\n",
      "\n",
      "episode 5, val func loss 0.17771625518798828\n",
      "\n",
      "episode 6, val func loss 0.18143823742866516\n",
      "\n",
      "episode 7, val func loss 0.22535088658332825\n",
      "\n",
      "episode 8, val func loss 0.16550183296203613\n",
      "\n",
      "episode 9, val func loss 0.16739793121814728\n",
      "\n",
      "episode 10, val func loss 0.1999451071023941\n",
      "\n",
      "episode 11, val func loss 0.20129525661468506\n",
      "\n",
      "episode 12, val func loss 0.17207218706607819\n",
      "\n",
      "episode 13, val func loss 0.1848389208316803\n",
      "\n",
      "episode 14, val func loss 0.21812745928764343\n",
      "\n",
      "episode 15, val func loss 0.19194163382053375\n",
      "\n",
      "episode 16, val func loss 0.21443939208984375\n",
      "\n",
      "Val func train loss in epoch 12:0.19240308739244938\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.20284128189086914\n",
      "\n",
      "episode 2, val func loss 0.2140173763036728\n",
      "\n",
      "episode 3, val func loss 0.19592146575450897\n",
      "\n",
      "episode 4, val func loss 0.1859918236732483\n",
      "\n",
      "episode 5, val func loss 0.22574402391910553\n",
      "\n",
      "episode 6, val func loss 0.19996249675750732\n",
      "\n",
      "episode 7, val func loss 0.16805733740329742\n",
      "\n",
      "episode 8, val func loss 0.1849292665719986\n",
      "\n",
      "episode 9, val func loss 0.19504901766777039\n",
      "\n",
      "episode 10, val func loss 0.18000660836696625\n",
      "\n",
      "episode 11, val func loss 0.2160263955593109\n",
      "\n",
      "episode 12, val func loss 0.1650463044643402\n",
      "\n",
      "episode 13, val func loss 0.2001757174730301\n",
      "\n",
      "episode 14, val func loss 0.1752036213874817\n",
      "\n",
      "episode 15, val func loss 0.17294228076934814\n",
      "\n",
      "episode 16, val func loss 0.19221849739551544\n",
      "\n",
      "Val func train loss in epoch 13:0.1921333447098732\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.20103543996810913\n",
      "\n",
      "episode 2, val func loss 0.1790425330400467\n",
      "\n",
      "episode 3, val func loss 0.16507907211780548\n",
      "\n",
      "episode 4, val func loss 0.19712738692760468\n",
      "\n",
      "episode 5, val func loss 0.1849404275417328\n",
      "\n",
      "episode 6, val func loss 0.22705647349357605\n",
      "\n",
      "episode 7, val func loss 0.1852959394454956\n",
      "\n",
      "episode 8, val func loss 0.2166159301996231\n",
      "\n",
      "episode 9, val func loss 0.16665267944335938\n",
      "\n",
      "episode 10, val func loss 0.1922019124031067\n",
      "\n",
      "episode 11, val func loss 0.1957050859928131\n",
      "\n",
      "episode 12, val func loss 0.2009611576795578\n",
      "\n",
      "episode 13, val func loss 0.2132415771484375\n",
      "\n",
      "episode 14, val func loss 0.17510607838630676\n",
      "\n",
      "episode 15, val func loss 0.20193950831890106\n",
      "\n",
      "episode 16, val func loss 0.17331908643245697\n",
      "\n",
      "Val func train loss in epoch 14:0.1922075180336833\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20056140422821045\n",
      "\n",
      "episode 2, val func loss 0.17464187741279602\n",
      "\n",
      "episode 3, val func loss 0.19201287627220154\n",
      "\n",
      "episode 4, val func loss 0.19591811299324036\n",
      "\n",
      "episode 5, val func loss 0.22658029198646545\n",
      "\n",
      "episode 6, val func loss 0.185410276055336\n",
      "\n",
      "episode 7, val func loss 0.2008446604013443\n",
      "\n",
      "episode 8, val func loss 0.16517336666584015\n",
      "\n",
      "episode 9, val func loss 0.20282356441020966\n",
      "\n",
      "episode 10, val func loss 0.16578082740306854\n",
      "\n",
      "episode 11, val func loss 0.18478460609912872\n",
      "\n",
      "episode 12, val func loss 0.21699745953083038\n",
      "\n",
      "episode 13, val func loss 0.2135400027036667\n",
      "\n",
      "episode 14, val func loss 0.17281898856163025\n",
      "\n",
      "episode 15, val func loss 0.17962877452373505\n",
      "\n",
      "episode 16, val func loss 0.19535842537879944\n",
      "\n",
      "Val func train loss in epoch 15:0.19205471966415644\n",
      "***********************TIME WAS 5.004555237293244 min*****************************\n",
      "\n",
      "**********************ROUND 132 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.05092058330774307\n",
      "\n",
      "episode 2, policy loss -0.006317155435681343\n",
      "\n",
      "episode 3, policy loss -0.04279011860489845\n",
      "\n",
      "episode 4, policy loss -0.05014165863394737\n",
      "\n",
      "episode 5, policy loss 0.00047893234295770526\n",
      "\n",
      "episode 6, policy loss -0.037550993263721466\n",
      "\n",
      "episode 7, policy loss -0.0360749289393425\n",
      "\n",
      "episode 8, policy loss -0.043921202421188354\n",
      "\n",
      "episode 9, policy loss 0.013797379098832607\n",
      "\n",
      "episode 10, policy loss -0.035067714750766754\n",
      "\n",
      "episode 11, policy loss -0.05058145150542259\n",
      "\n",
      "episode 12, policy loss -0.0252771507948637\n",
      "\n",
      "episode 13, policy loss -0.04764103889465332\n",
      "\n",
      "episode 14, policy loss -0.034034520387649536\n",
      "\n",
      "episode 15, policy loss -0.04373643919825554\n",
      "\n",
      "episode 16, policy loss -0.07320012152194977\n",
      "\n",
      "Policy train loss in epoch 0:-0.03518617288864334\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.049663249403238297\n",
      "\n",
      "episode 2, policy loss 0.010539306327700615\n",
      "\n",
      "episode 3, policy loss -0.0013194481143727899\n",
      "\n",
      "episode 4, policy loss -0.060596007853746414\n",
      "\n",
      "episode 5, policy loss -0.03596009686589241\n",
      "\n",
      "episode 6, policy loss -0.03766466677188873\n",
      "\n",
      "episode 7, policy loss -0.03092280961573124\n",
      "\n",
      "episode 8, policy loss -0.05647878348827362\n",
      "\n",
      "episode 9, policy loss -0.07614924758672714\n",
      "\n",
      "episode 10, policy loss -0.055011212825775146\n",
      "\n",
      "episode 11, policy loss -0.045830026268959045\n",
      "\n",
      "episode 12, policy loss -0.03830757364630699\n",
      "\n",
      "episode 13, policy loss -0.04023004323244095\n",
      "\n",
      "episode 14, policy loss -0.046544529497623444\n",
      "\n",
      "episode 15, policy loss -0.052932340651750565\n",
      "\n",
      "episode 16, policy loss -0.017392663285136223\n",
      "\n",
      "Policy train loss in epoch 1:-0.03965396204876015\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.03773178905248642\n",
      "\n",
      "episode 2, policy loss -0.04119733348488808\n",
      "\n",
      "episode 3, policy loss -0.05154069513082504\n",
      "\n",
      "episode 4, policy loss -0.05618502199649811\n",
      "\n",
      "episode 5, policy loss -0.038546979427337646\n",
      "\n",
      "episode 6, policy loss -0.07693055272102356\n",
      "\n",
      "episode 7, policy loss -0.06196900084614754\n",
      "\n",
      "episode 8, policy loss -0.03930099681019783\n",
      "\n",
      "episode 9, policy loss -0.017277490347623825\n",
      "\n",
      "episode 10, policy loss -0.05693658068776131\n",
      "\n",
      "episode 11, policy loss -0.05292610824108124\n",
      "\n",
      "episode 12, policy loss 0.009664292447268963\n",
      "\n",
      "episode 13, policy loss -0.04647744074463844\n",
      "\n",
      "episode 14, policy loss -0.046205081045627594\n",
      "\n",
      "episode 15, policy loss -0.031248172745108604\n",
      "\n",
      "episode 16, policy loss -0.0033649064134806395\n",
      "\n",
      "Policy train loss in epoch 2:-0.04051086607796606\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.05308593437075615\n",
      "\n",
      "episode 2, policy loss -0.05167152360081673\n",
      "\n",
      "episode 3, policy loss -0.06210979074239731\n",
      "\n",
      "episode 4, policy loss -0.031178733333945274\n",
      "\n",
      "episode 5, policy loss -0.05662056803703308\n",
      "\n",
      "episode 6, policy loss -0.03965550661087036\n",
      "\n",
      "episode 7, policy loss -0.039028044790029526\n",
      "\n",
      "episode 8, policy loss -0.03760455921292305\n",
      "\n",
      "episode 9, policy loss -0.04085890203714371\n",
      "\n",
      "episode 10, policy loss -0.05588892102241516\n",
      "\n",
      "episode 11, policy loss -0.004227277357131243\n",
      "\n",
      "episode 12, policy loss -0.04726661741733551\n",
      "\n",
      "episode 13, policy loss -0.017469478771090508\n",
      "\n",
      "episode 14, policy loss -0.0767083466053009\n",
      "\n",
      "episode 15, policy loss -0.04570073261857033\n",
      "\n",
      "episode 16, policy loss 0.009965733624994755\n",
      "\n",
      "Policy train loss in epoch 3:-0.040569325181422755\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19316525757312775\n",
      "\n",
      "episode 2, val func loss 0.196476012468338\n",
      "\n",
      "episode 3, val func loss 0.21633057296276093\n",
      "\n",
      "episode 4, val func loss 0.2086007297039032\n",
      "\n",
      "episode 5, val func loss 0.21002966165542603\n",
      "\n",
      "episode 6, val func loss 0.16511127352714539\n",
      "\n",
      "episode 7, val func loss 0.20864897966384888\n",
      "\n",
      "episode 8, val func loss 0.16689346730709076\n",
      "\n",
      "episode 9, val func loss 0.1863706260919571\n",
      "\n",
      "episode 10, val func loss 0.18555575609207153\n",
      "\n",
      "episode 11, val func loss 0.1818334013223648\n",
      "\n",
      "episode 12, val func loss 0.17812548577785492\n",
      "\n",
      "episode 13, val func loss 0.20829728245735168\n",
      "\n",
      "episode 14, val func loss 0.19546495378017426\n",
      "\n",
      "episode 15, val func loss 0.18225006759166718\n",
      "\n",
      "episode 16, val func loss 0.19859573245048523\n",
      "\n",
      "Val func train loss in epoch 0:0.19260932877659798\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1658080667257309\n",
      "\n",
      "episode 2, val func loss 0.21721749007701874\n",
      "\n",
      "episode 3, val func loss 0.20864465832710266\n",
      "\n",
      "episode 4, val func loss 0.16425299644470215\n",
      "\n",
      "episode 5, val func loss 0.19499331712722778\n",
      "\n",
      "episode 6, val func loss 0.20664265751838684\n",
      "\n",
      "episode 7, val func loss 0.18174462020397186\n",
      "\n",
      "episode 8, val func loss 0.18255619704723358\n",
      "\n",
      "episode 9, val func loss 0.19872228801250458\n",
      "\n",
      "episode 10, val func loss 0.17936797440052032\n",
      "\n",
      "episode 11, val func loss 0.20826472342014313\n",
      "\n",
      "episode 12, val func loss 0.1862955093383789\n",
      "\n",
      "episode 13, val func loss 0.19256247580051422\n",
      "\n",
      "episode 14, val func loss 0.19685077667236328\n",
      "\n",
      "episode 15, val func loss 0.18562550842761993\n",
      "\n",
      "episode 16, val func loss 0.20993411540985107\n",
      "\n",
      "Val func train loss in epoch 1:0.19246771093457937\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19524894654750824\n",
      "\n",
      "episode 2, val func loss 0.20996791124343872\n",
      "\n",
      "episode 3, val func loss 0.2166217714548111\n",
      "\n",
      "episode 4, val func loss 0.18635347485542297\n",
      "\n",
      "episode 5, val func loss 0.17892180383205414\n",
      "\n",
      "episode 6, val func loss 0.18268942832946777\n",
      "\n",
      "episode 7, val func loss 0.2064967006444931\n",
      "\n",
      "episode 8, val func loss 0.16482600569725037\n",
      "\n",
      "episode 9, val func loss 0.20837514102458954\n",
      "\n",
      "episode 10, val func loss 0.20865991711616516\n",
      "\n",
      "episode 11, val func loss 0.1929808109998703\n",
      "\n",
      "episode 12, val func loss 0.19633585214614868\n",
      "\n",
      "episode 13, val func loss 0.185516357421875\n",
      "\n",
      "episode 14, val func loss 0.19874323904514313\n",
      "\n",
      "episode 15, val func loss 0.18207819759845734\n",
      "\n",
      "episode 16, val func loss 0.16628974676132202\n",
      "\n",
      "Val func train loss in epoch 2:0.1925065815448761\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.198744535446167\n",
      "\n",
      "episode 2, val func loss 0.17820926010608673\n",
      "\n",
      "episode 3, val func loss 0.18602868914604187\n",
      "\n",
      "episode 4, val func loss 0.2177930772304535\n",
      "\n",
      "episode 5, val func loss 0.19538947939872742\n",
      "\n",
      "episode 6, val func loss 0.20835457742214203\n",
      "\n",
      "episode 7, val func loss 0.1928642839193344\n",
      "\n",
      "episode 8, val func loss 0.1821451187133789\n",
      "\n",
      "episode 9, val func loss 0.1642889827489853\n",
      "\n",
      "episode 10, val func loss 0.19663342833518982\n",
      "\n",
      "episode 11, val func loss 0.20968487858772278\n",
      "\n",
      "episode 12, val func loss 0.16616152226924896\n",
      "\n",
      "episode 13, val func loss 0.18214823305606842\n",
      "\n",
      "episode 14, val func loss 0.18645010888576508\n",
      "\n",
      "episode 15, val func loss 0.2093677520751953\n",
      "\n",
      "episode 16, val func loss 0.20743460953235626\n",
      "\n",
      "Val func train loss in epoch 3:0.19260615855455399\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1929784119129181\n",
      "\n",
      "episode 2, val func loss 0.18639519810676575\n",
      "\n",
      "episode 3, val func loss 0.16657590866088867\n",
      "\n",
      "episode 4, val func loss 0.18512746691703796\n",
      "\n",
      "episode 5, val func loss 0.19669774174690247\n",
      "\n",
      "episode 6, val func loss 0.21664103865623474\n",
      "\n",
      "episode 7, val func loss 0.17904400825500488\n",
      "\n",
      "episode 8, val func loss 0.19497710466384888\n",
      "\n",
      "episode 9, val func loss 0.2085554301738739\n",
      "\n",
      "episode 10, val func loss 0.19878725707530975\n",
      "\n",
      "episode 11, val func loss 0.20829613506793976\n",
      "\n",
      "episode 12, val func loss 0.182684525847435\n",
      "\n",
      "episode 13, val func loss 0.18179728090763092\n",
      "\n",
      "episode 14, val func loss 0.20983651280403137\n",
      "\n",
      "episode 15, val func loss 0.20751547813415527\n",
      "\n",
      "episode 16, val func loss 0.1639304757118225\n",
      "\n",
      "Val func train loss in epoch 4:0.1924899984151125\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19860529899597168\n",
      "\n",
      "episode 2, val func loss 0.20715859532356262\n",
      "\n",
      "episode 3, val func loss 0.20849767327308655\n",
      "\n",
      "episode 4, val func loss 0.18576212227344513\n",
      "\n",
      "episode 5, val func loss 0.1965230107307434\n",
      "\n",
      "episode 6, val func loss 0.2099725306034088\n",
      "\n",
      "episode 7, val func loss 0.1863255351781845\n",
      "\n",
      "episode 8, val func loss 0.20885753631591797\n",
      "\n",
      "episode 9, val func loss 0.16519831120967865\n",
      "\n",
      "episode 10, val func loss 0.16682736575603485\n",
      "\n",
      "episode 11, val func loss 0.1928170770406723\n",
      "\n",
      "episode 12, val func loss 0.18234629929065704\n",
      "\n",
      "episode 13, val func loss 0.19650274515151978\n",
      "\n",
      "episode 14, val func loss 0.21940770745277405\n",
      "\n",
      "episode 15, val func loss 0.17794911563396454\n",
      "\n",
      "episode 16, val func loss 0.18204143643379211\n",
      "\n",
      "Val func train loss in epoch 5:0.19279952254146338\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1820395588874817\n",
      "\n",
      "episode 2, val func loss 0.16406665742397308\n",
      "\n",
      "episode 3, val func loss 0.2069871425628662\n",
      "\n",
      "episode 4, val func loss 0.18620769679546356\n",
      "\n",
      "episode 5, val func loss 0.16657103598117828\n",
      "\n",
      "episode 6, val func loss 0.18526703119277954\n",
      "\n",
      "episode 7, val func loss 0.19534945487976074\n",
      "\n",
      "episode 8, val func loss 0.19668956100940704\n",
      "\n",
      "episode 9, val func loss 0.21671094000339508\n",
      "\n",
      "episode 10, val func loss 0.18197540938854218\n",
      "\n",
      "episode 11, val func loss 0.20878790318965912\n",
      "\n",
      "episode 12, val func loss 0.20863334834575653\n",
      "\n",
      "episode 13, val func loss 0.19867710769176483\n",
      "\n",
      "episode 14, val func loss 0.19336414337158203\n",
      "\n",
      "episode 15, val func loss 0.20975357294082642\n",
      "\n",
      "episode 16, val func loss 0.17830762267112732\n",
      "\n",
      "Val func train loss in epoch 6:0.19246176164597273\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.16493219137191772\n",
      "\n",
      "episode 2, val func loss 0.18452313542366028\n",
      "\n",
      "episode 3, val func loss 0.20045135915279388\n",
      "\n",
      "episode 4, val func loss 0.18223905563354492\n",
      "\n",
      "episode 5, val func loss 0.1857776641845703\n",
      "\n",
      "episode 6, val func loss 0.19336000084877014\n",
      "\n",
      "episode 7, val func loss 0.20868103206157684\n",
      "\n",
      "episode 8, val func loss 0.21002201735973358\n",
      "\n",
      "episode 9, val func loss 0.20895422995090485\n",
      "\n",
      "episode 10, val func loss 0.20627260208129883\n",
      "\n",
      "episode 11, val func loss 0.21624861657619476\n",
      "\n",
      "episode 12, val func loss 0.19506189227104187\n",
      "\n",
      "episode 13, val func loss 0.18015824258327484\n",
      "\n",
      "episode 14, val func loss 0.19617682695388794\n",
      "\n",
      "episode 15, val func loss 0.18657444417476654\n",
      "\n",
      "episode 16, val func loss 0.16403412818908691\n",
      "\n",
      "Val func train loss in epoch 7:0.19271671492606401\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.20882457494735718\n",
      "\n",
      "episode 2, val func loss 0.18269012868404388\n",
      "\n",
      "episode 3, val func loss 0.21811790764331818\n",
      "\n",
      "episode 4, val func loss 0.18625465035438538\n",
      "\n",
      "episode 5, val func loss 0.2065436840057373\n",
      "\n",
      "episode 6, val func loss 0.17983309924602509\n",
      "\n",
      "episode 7, val func loss 0.21001045405864716\n",
      "\n",
      "episode 8, val func loss 0.19512751698493958\n",
      "\n",
      "episode 9, val func loss 0.1855749636888504\n",
      "\n",
      "episode 10, val func loss 0.19632339477539062\n",
      "\n",
      "episode 11, val func loss 0.1824249029159546\n",
      "\n",
      "episode 12, val func loss 0.19859610497951508\n",
      "\n",
      "episode 13, val func loss 0.16356445848941803\n",
      "\n",
      "episode 14, val func loss 0.19290180504322052\n",
      "\n",
      "episode 15, val func loss 0.2103007584810257\n",
      "\n",
      "episode 16, val func loss 0.16545459628105164\n",
      "\n",
      "Val func train loss in epoch 8:0.19265893753618002\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.1655137538909912\n",
      "\n",
      "episode 2, val func loss 0.20944006741046906\n",
      "\n",
      "episode 3, val func loss 0.16365887224674225\n",
      "\n",
      "episode 4, val func loss 0.18660657107830048\n",
      "\n",
      "episode 5, val func loss 0.20766383409500122\n",
      "\n",
      "episode 6, val func loss 0.19494563341140747\n",
      "\n",
      "episode 7, val func loss 0.19668148458003998\n",
      "\n",
      "episode 8, val func loss 0.20856992900371552\n",
      "\n",
      "episode 9, val func loss 0.21013636887073517\n",
      "\n",
      "episode 10, val func loss 0.18027319014072418\n",
      "\n",
      "episode 11, val func loss 0.19880203902721405\n",
      "\n",
      "episode 12, val func loss 0.21633094549179077\n",
      "\n",
      "episode 13, val func loss 0.1817755103111267\n",
      "\n",
      "episode 14, val func loss 0.1852790266275406\n",
      "\n",
      "episode 15, val func loss 0.18227820098400116\n",
      "\n",
      "episode 16, val func loss 0.19262827932834625\n",
      "\n",
      "Val func train loss in epoch 9:0.19253648165613413\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20858383178710938\n",
      "\n",
      "episode 2, val func loss 0.18212160468101501\n",
      "\n",
      "episode 3, val func loss 0.21782052516937256\n",
      "\n",
      "episode 4, val func loss 0.1864519566297531\n",
      "\n",
      "episode 5, val func loss 0.19267983734607697\n",
      "\n",
      "episode 6, val func loss 0.19868160784244537\n",
      "\n",
      "episode 7, val func loss 0.21002745628356934\n",
      "\n",
      "episode 8, val func loss 0.16463054716587067\n",
      "\n",
      "episode 9, val func loss 0.19534263014793396\n",
      "\n",
      "episode 10, val func loss 0.20700612664222717\n",
      "\n",
      "episode 11, val func loss 0.19662581384181976\n",
      "\n",
      "episode 12, val func loss 0.1856633871793747\n",
      "\n",
      "episode 13, val func loss 0.17895956337451935\n",
      "\n",
      "episode 14, val func loss 0.18174076080322266\n",
      "\n",
      "episode 15, val func loss 0.16662633419036865\n",
      "\n",
      "episode 16, val func loss 0.2088518589735031\n",
      "\n",
      "Val func train loss in epoch 10:0.19261336512863636\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16563725471496582\n",
      "\n",
      "episode 2, val func loss 0.2082972377538681\n",
      "\n",
      "episode 3, val func loss 0.1927579790353775\n",
      "\n",
      "episode 4, val func loss 0.18200741708278656\n",
      "\n",
      "episode 5, val func loss 0.19885338842868805\n",
      "\n",
      "episode 6, val func loss 0.18211887776851654\n",
      "\n",
      "episode 7, val func loss 0.18572254478931427\n",
      "\n",
      "episode 8, val func loss 0.20976446568965912\n",
      "\n",
      "episode 9, val func loss 0.18620142340660095\n",
      "\n",
      "episode 10, val func loss 0.1949937492609024\n",
      "\n",
      "episode 11, val func loss 0.1793321967124939\n",
      "\n",
      "episode 12, val func loss 0.20850354433059692\n",
      "\n",
      "episode 13, val func loss 0.21647097170352936\n",
      "\n",
      "episode 14, val func loss 0.19646653532981873\n",
      "\n",
      "episode 15, val func loss 0.16502194106578827\n",
      "\n",
      "episode 16, val func loss 0.20841696858406067\n",
      "\n",
      "Val func train loss in epoch 11:0.19253540597856045\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19859832525253296\n",
      "\n",
      "episode 2, val func loss 0.20908750593662262\n",
      "\n",
      "episode 3, val func loss 0.1862601488828659\n",
      "\n",
      "episode 4, val func loss 0.2166525274515152\n",
      "\n",
      "episode 5, val func loss 0.19513648748397827\n",
      "\n",
      "episode 6, val func loss 0.16453294456005096\n",
      "\n",
      "episode 7, val func loss 0.18232578039169312\n",
      "\n",
      "episode 8, val func loss 0.1818866729736328\n",
      "\n",
      "episode 9, val func loss 0.206899031996727\n",
      "\n",
      "episode 10, val func loss 0.19296322762966156\n",
      "\n",
      "episode 11, val func loss 0.20984986424446106\n",
      "\n",
      "episode 12, val func loss 0.18528668582439423\n",
      "\n",
      "episode 13, val func loss 0.16631163656711578\n",
      "\n",
      "episode 14, val func loss 0.17815545201301575\n",
      "\n",
      "episode 15, val func loss 0.2086237668991089\n",
      "\n",
      "episode 16, val func loss 0.19713152945041656\n",
      "\n",
      "Val func train loss in epoch 12:0.19248134922236204\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19296322762966156\n",
      "\n",
      "episode 2, val func loss 0.19538427889347076\n",
      "\n",
      "episode 3, val func loss 0.2075629085302353\n",
      "\n",
      "episode 4, val func loss 0.19863159954547882\n",
      "\n",
      "episode 5, val func loss 0.18229658901691437\n",
      "\n",
      "episode 6, val func loss 0.21625842154026031\n",
      "\n",
      "episode 7, val func loss 0.1795884072780609\n",
      "\n",
      "episode 8, val func loss 0.208679661154747\n",
      "\n",
      "episode 9, val func loss 0.19639654457569122\n",
      "\n",
      "episode 10, val func loss 0.18193121254444122\n",
      "\n",
      "episode 11, val func loss 0.185580313205719\n",
      "\n",
      "episode 12, val func loss 0.20870383083820343\n",
      "\n",
      "episode 13, val func loss 0.1645883023738861\n",
      "\n",
      "episode 14, val func loss 0.1659322828054428\n",
      "\n",
      "episode 15, val func loss 0.18642935156822205\n",
      "\n",
      "episode 16, val func loss 0.2100992202758789\n",
      "\n",
      "Val func train loss in epoch 13:0.1925641344860196\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.21030870079994202\n",
      "\n",
      "episode 2, val func loss 0.21020495891571045\n",
      "\n",
      "episode 3, val func loss 0.18677295744419098\n",
      "\n",
      "episode 4, val func loss 0.19889125227928162\n",
      "\n",
      "episode 5, val func loss 0.16377019882202148\n",
      "\n",
      "episode 6, val func loss 0.182154580950737\n",
      "\n",
      "episode 7, val func loss 0.16648727655410767\n",
      "\n",
      "episode 8, val func loss 0.20707081258296967\n",
      "\n",
      "episode 9, val func loss 0.17869392037391663\n",
      "\n",
      "episode 10, val func loss 0.1855016052722931\n",
      "\n",
      "episode 11, val func loss 0.19287629425525665\n",
      "\n",
      "episode 12, val func loss 0.21732953190803528\n",
      "\n",
      "episode 13, val func loss 0.18182429671287537\n",
      "\n",
      "episode 14, val func loss 0.1949126422405243\n",
      "\n",
      "episode 15, val func loss 0.19659395515918732\n",
      "\n",
      "episode 16, val func loss 0.2085321694612503\n",
      "\n",
      "Val func train loss in epoch 14:0.19262032210826874\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1963946372270584\n",
      "\n",
      "episode 2, val func loss 0.1866413652896881\n",
      "\n",
      "episode 3, val func loss 0.20629912614822388\n",
      "\n",
      "episode 4, val func loss 0.19523513317108154\n",
      "\n",
      "episode 5, val func loss 0.19898153841495514\n",
      "\n",
      "episode 6, val func loss 0.19368048012256622\n",
      "\n",
      "episode 7, val func loss 0.20866890251636505\n",
      "\n",
      "episode 8, val func loss 0.1663784235715866\n",
      "\n",
      "episode 9, val func loss 0.21712929010391235\n",
      "\n",
      "episode 10, val func loss 0.17826201021671295\n",
      "\n",
      "episode 11, val func loss 0.20991100370883942\n",
      "\n",
      "episode 12, val func loss 0.16343456506729126\n",
      "\n",
      "episode 13, val func loss 0.20913900434970856\n",
      "\n",
      "episode 14, val func loss 0.1863172948360443\n",
      "\n",
      "episode 15, val func loss 0.18226714432239532\n",
      "\n",
      "episode 16, val func loss 0.18179574608802795\n",
      "\n",
      "Val func train loss in epoch 15:0.19253347907215357\n",
      "***********************TIME WAS 5.014938839276632 min*****************************\n",
      "\n",
      "**********************ROUND 133 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.023728040978312492\n",
      "\n",
      "episode 2, policy loss -0.001864003948867321\n",
      "\n",
      "episode 3, policy loss -0.02183656580746174\n",
      "\n",
      "episode 4, policy loss -0.05204145237803459\n",
      "\n",
      "episode 5, policy loss -0.0651535764336586\n",
      "\n",
      "episode 6, policy loss -0.056310076266527176\n",
      "\n",
      "episode 7, policy loss -0.0626959577202797\n",
      "\n",
      "episode 8, policy loss -0.009664861485362053\n",
      "\n",
      "episode 9, policy loss -0.09044436365365982\n",
      "\n",
      "episode 10, policy loss -0.015013828873634338\n",
      "\n",
      "episode 11, policy loss -0.054269108921289444\n",
      "\n",
      "episode 12, policy loss -0.054967958480119705\n",
      "\n",
      "episode 13, policy loss -0.033763185143470764\n",
      "\n",
      "episode 14, policy loss -0.0982770323753357\n",
      "\n",
      "episode 15, policy loss -0.10672146826982498\n",
      "\n",
      "episode 16, policy loss -0.08034392446279526\n",
      "\n",
      "Policy train loss in epoch 0:-0.051693462824914604\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.10715486854314804\n",
      "\n",
      "episode 2, policy loss -0.037335705012083054\n",
      "\n",
      "episode 3, policy loss -0.0163503997027874\n",
      "\n",
      "episode 4, policy loss -0.06443408131599426\n",
      "\n",
      "episode 5, policy loss -0.07998223602771759\n",
      "\n",
      "episode 6, policy loss -0.06002232804894447\n",
      "\n",
      "episode 7, policy loss -0.0719163715839386\n",
      "\n",
      "episode 8, policy loss -0.012042224407196045\n",
      "\n",
      "episode 9, policy loss -0.05481816455721855\n",
      "\n",
      "episode 10, policy loss -0.0989932268857956\n",
      "\n",
      "episode 11, policy loss -0.0560787133872509\n",
      "\n",
      "episode 12, policy loss -0.03646259754896164\n",
      "\n",
      "episode 13, policy loss -0.01351398415863514\n",
      "\n",
      "episode 14, policy loss -0.09247054159641266\n",
      "\n",
      "episode 15, policy loss -0.03248970955610275\n",
      "\n",
      "episode 16, policy loss -0.05654611065983772\n",
      "\n",
      "Policy train loss in epoch 1:-0.055663203937001526\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.10764365643262863\n",
      "\n",
      "episode 2, policy loss -0.057065192610025406\n",
      "\n",
      "episode 3, policy loss -0.012269124388694763\n",
      "\n",
      "episode 4, policy loss -0.01749582029879093\n",
      "\n",
      "episode 5, policy loss -0.06476996839046478\n",
      "\n",
      "episode 6, policy loss -0.07186305522918701\n",
      "\n",
      "episode 7, policy loss -0.09875598549842834\n",
      "\n",
      "episode 8, policy loss -0.05625108256936073\n",
      "\n",
      "episode 9, policy loss -0.05508134886622429\n",
      "\n",
      "episode 10, policy loss -0.09241020679473877\n",
      "\n",
      "episode 11, policy loss -0.013999889604747295\n",
      "\n",
      "episode 12, policy loss -0.03778700903058052\n",
      "\n",
      "episode 13, policy loss -0.08090685307979584\n",
      "\n",
      "episode 14, policy loss -0.03636562079191208\n",
      "\n",
      "episode 15, policy loss -0.05945116654038429\n",
      "\n",
      "episode 16, policy loss -0.03243095800280571\n",
      "\n",
      "Policy train loss in epoch 2:-0.05590918363304809\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.05529550835490227\n",
      "\n",
      "episode 2, policy loss -0.01204103883355856\n",
      "\n",
      "episode 3, policy loss -0.09828361868858337\n",
      "\n",
      "episode 4, policy loss -0.013719235546886921\n",
      "\n",
      "episode 5, policy loss -0.05740620195865631\n",
      "\n",
      "episode 6, policy loss -0.03188676759600639\n",
      "\n",
      "episode 7, policy loss -0.08105507493019104\n",
      "\n",
      "episode 8, policy loss -0.060117725282907486\n",
      "\n",
      "episode 9, policy loss -0.10757576674222946\n",
      "\n",
      "episode 10, policy loss -0.0380660817027092\n",
      "\n",
      "episode 11, policy loss -0.05616297945380211\n",
      "\n",
      "episode 12, policy loss -0.09250710904598236\n",
      "\n",
      "episode 13, policy loss -0.01719566248357296\n",
      "\n",
      "episode 14, policy loss -0.03640289232134819\n",
      "\n",
      "episode 15, policy loss -0.06493256986141205\n",
      "\n",
      "episode 16, policy loss -0.07249026000499725\n",
      "\n",
      "Policy train loss in epoch 3:-0.05594615580048412\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.20583336055278778\n",
      "\n",
      "episode 2, val func loss 0.1762218028306961\n",
      "\n",
      "episode 3, val func loss 0.1618705689907074\n",
      "\n",
      "episode 4, val func loss 0.19719921052455902\n",
      "\n",
      "episode 5, val func loss 0.18863169848918915\n",
      "\n",
      "episode 6, val func loss 0.15511198341846466\n",
      "\n",
      "episode 7, val func loss 0.18002285063266754\n",
      "\n",
      "episode 8, val func loss 0.19879569113254547\n",
      "\n",
      "episode 9, val func loss 0.20411856472492218\n",
      "\n",
      "episode 10, val func loss 0.20459552109241486\n",
      "\n",
      "episode 11, val func loss 0.19994203746318817\n",
      "\n",
      "episode 12, val func loss 0.21594564616680145\n",
      "\n",
      "episode 13, val func loss 0.18973201513290405\n",
      "\n",
      "episode 14, val func loss 0.22221729159355164\n",
      "\n",
      "episode 15, val func loss 0.20332473516464233\n",
      "\n",
      "episode 16, val func loss 0.19089823961257935\n",
      "\n",
      "Val func train loss in epoch 0:0.19340382609516382\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.2147175371646881\n",
      "\n",
      "episode 2, val func loss 0.18058240413665771\n",
      "\n",
      "episode 3, val func loss 0.16265329718589783\n",
      "\n",
      "episode 4, val func loss 0.20427566766738892\n",
      "\n",
      "episode 5, val func loss 0.19945386052131653\n",
      "\n",
      "episode 6, val func loss 0.20419616997241974\n",
      "\n",
      "episode 7, val func loss 0.19006915390491486\n",
      "\n",
      "episode 8, val func loss 0.17939291894435883\n",
      "\n",
      "episode 9, val func loss 0.18558046221733093\n",
      "\n",
      "episode 10, val func loss 0.2250095009803772\n",
      "\n",
      "episode 11, val func loss 0.18865133821964264\n",
      "\n",
      "episode 12, val func loss 0.2054068148136139\n",
      "\n",
      "episode 13, val func loss 0.19897378981113434\n",
      "\n",
      "episode 14, val func loss 0.2039748877286911\n",
      "\n",
      "episode 15, val func loss 0.19582724571228027\n",
      "\n",
      "episode 16, val func loss 0.157436341047287\n",
      "\n",
      "Val func train loss in epoch 1:0.19351258687675\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.20360295474529266\n",
      "\n",
      "episode 2, val func loss 0.21462801098823547\n",
      "\n",
      "episode 3, val func loss 0.1894451081752777\n",
      "\n",
      "episode 4, val func loss 0.20541156828403473\n",
      "\n",
      "episode 5, val func loss 0.17682430148124695\n",
      "\n",
      "episode 6, val func loss 0.19876690208911896\n",
      "\n",
      "episode 7, val func loss 0.17950518429279327\n",
      "\n",
      "episode 8, val func loss 0.22420668601989746\n",
      "\n",
      "episode 9, val func loss 0.16175082325935364\n",
      "\n",
      "episode 10, val func loss 0.2039496898651123\n",
      "\n",
      "episode 11, val func loss 0.1974077820777893\n",
      "\n",
      "episode 12, val func loss 0.18861837685108185\n",
      "\n",
      "episode 13, val func loss 0.2041216343641281\n",
      "\n",
      "episode 14, val func loss 0.20002667605876923\n",
      "\n",
      "episode 15, val func loss 0.18780659139156342\n",
      "\n",
      "episode 16, val func loss 0.15607473254203796\n",
      "\n",
      "Val func train loss in epoch 2:0.19325918890535831\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18070459365844727\n",
      "\n",
      "episode 2, val func loss 0.1971772462129593\n",
      "\n",
      "episode 3, val func loss 0.18849574029445648\n",
      "\n",
      "episode 4, val func loss 0.17545874416828156\n",
      "\n",
      "episode 5, val func loss 0.2050405591726303\n",
      "\n",
      "episode 6, val func loss 0.15380693972110748\n",
      "\n",
      "episode 7, val func loss 0.19083578884601593\n",
      "\n",
      "episode 8, val func loss 0.2061445266008377\n",
      "\n",
      "episode 9, val func loss 0.19978444278240204\n",
      "\n",
      "episode 10, val func loss 0.21510222554206848\n",
      "\n",
      "episode 11, val func loss 0.2217593789100647\n",
      "\n",
      "episode 12, val func loss 0.16503305733203888\n",
      "\n",
      "episode 13, val func loss 0.20054806768894196\n",
      "\n",
      "episode 14, val func loss 0.1883281022310257\n",
      "\n",
      "episode 15, val func loss 0.2039882242679596\n",
      "\n",
      "episode 16, val func loss 0.20447039604187012\n",
      "\n",
      "Val func train loss in epoch 3:0.19354237709194422\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19960089027881622\n",
      "\n",
      "episode 2, val func loss 0.20447184145450592\n",
      "\n",
      "episode 3, val func loss 0.1989084929227829\n",
      "\n",
      "episode 4, val func loss 0.18040074408054352\n",
      "\n",
      "episode 5, val func loss 0.19714289903640747\n",
      "\n",
      "episode 6, val func loss 0.2054494023323059\n",
      "\n",
      "episode 7, val func loss 0.20451310276985168\n",
      "\n",
      "episode 8, val func loss 0.16257470846176147\n",
      "\n",
      "episode 9, val func loss 0.1891556829214096\n",
      "\n",
      "episode 10, val func loss 0.2037767767906189\n",
      "\n",
      "episode 11, val func loss 0.214910089969635\n",
      "\n",
      "episode 12, val func loss 0.15555761754512787\n",
      "\n",
      "episode 13, val func loss 0.17683319747447968\n",
      "\n",
      "episode 14, val func loss 0.22360806167125702\n",
      "\n",
      "episode 15, val func loss 0.18567825853824615\n",
      "\n",
      "episode 16, val func loss 0.18991203606128693\n",
      "\n",
      "Val func train loss in epoch 4:0.19328086264431477\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19902212917804718\n",
      "\n",
      "episode 2, val func loss 0.22448639571666718\n",
      "\n",
      "episode 3, val func loss 0.18964718282222748\n",
      "\n",
      "episode 4, val func loss 0.19644689559936523\n",
      "\n",
      "episode 5, val func loss 0.18942174315452576\n",
      "\n",
      "episode 6, val func loss 0.2145622968673706\n",
      "\n",
      "episode 7, val func loss 0.20425884425640106\n",
      "\n",
      "episode 8, val func loss 0.16289213299751282\n",
      "\n",
      "episode 9, val func loss 0.18211427330970764\n",
      "\n",
      "episode 10, val func loss 0.19967085123062134\n",
      "\n",
      "episode 11, val func loss 0.15451842546463013\n",
      "\n",
      "episode 12, val func loss 0.17579860985279083\n",
      "\n",
      "episode 13, val func loss 0.20491069555282593\n",
      "\n",
      "episode 14, val func loss 0.1853451132774353\n",
      "\n",
      "episode 15, val func loss 0.20778775215148926\n",
      "\n",
      "episode 16, val func loss 0.20714034140110016\n",
      "\n",
      "Val func train loss in epoch 5:0.19362648017704487\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18865877389907837\n",
      "\n",
      "episode 2, val func loss 0.20478738844394684\n",
      "\n",
      "episode 3, val func loss 0.19885121285915375\n",
      "\n",
      "episode 4, val func loss 0.1869710236787796\n",
      "\n",
      "episode 5, val func loss 0.18105816841125488\n",
      "\n",
      "episode 6, val func loss 0.20493198931217194\n",
      "\n",
      "episode 7, val func loss 0.2148948758840561\n",
      "\n",
      "episode 8, val func loss 0.22283023595809937\n",
      "\n",
      "episode 9, val func loss 0.19974373281002045\n",
      "\n",
      "episode 10, val func loss 0.20392459630966187\n",
      "\n",
      "episode 11, val func loss 0.2041870802640915\n",
      "\n",
      "episode 12, val func loss 0.18973223865032196\n",
      "\n",
      "episode 13, val func loss 0.1629825234413147\n",
      "\n",
      "episode 14, val func loss 0.19597497582435608\n",
      "\n",
      "episode 15, val func loss 0.1783214509487152\n",
      "\n",
      "episode 16, val func loss 0.1557203084230423\n",
      "\n",
      "Val func train loss in epoch 6:0.19334816094487906\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.20385116338729858\n",
      "\n",
      "episode 2, val func loss 0.18989640474319458\n",
      "\n",
      "episode 3, val func loss 0.17949722707271576\n",
      "\n",
      "episode 4, val func loss 0.19919918477535248\n",
      "\n",
      "episode 5, val func loss 0.1620364636182785\n",
      "\n",
      "episode 6, val func loss 0.1538316309452057\n",
      "\n",
      "episode 7, val func loss 0.21721112728118896\n",
      "\n",
      "episode 8, val func loss 0.18527725338935852\n",
      "\n",
      "episode 9, val func loss 0.20616765320301056\n",
      "\n",
      "episode 10, val func loss 0.19781117141246796\n",
      "\n",
      "episode 11, val func loss 0.20442917943000793\n",
      "\n",
      "episode 12, val func loss 0.18933500349521637\n",
      "\n",
      "episode 13, val func loss 0.20386222004890442\n",
      "\n",
      "episode 14, val func loss 0.22151942551136017\n",
      "\n",
      "episode 15, val func loss 0.18098190426826477\n",
      "\n",
      "episode 16, val func loss 0.2003796249628067\n",
      "\n",
      "Val func train loss in epoch 7:0.1934554148465395\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.20516304671764374\n",
      "\n",
      "episode 2, val func loss 0.18905337154865265\n",
      "\n",
      "episode 3, val func loss 0.19945763051509857\n",
      "\n",
      "episode 4, val func loss 0.18971416354179382\n",
      "\n",
      "episode 5, val func loss 0.17555034160614014\n",
      "\n",
      "episode 6, val func loss 0.20475459098815918\n",
      "\n",
      "episode 7, val func loss 0.18528175354003906\n",
      "\n",
      "episode 8, val func loss 0.2166074961423874\n",
      "\n",
      "episode 9, val func loss 0.22505927085876465\n",
      "\n",
      "episode 10, val func loss 0.1988828480243683\n",
      "\n",
      "episode 11, val func loss 0.16211099922657013\n",
      "\n",
      "episode 12, val func loss 0.1815866380929947\n",
      "\n",
      "episode 13, val func loss 0.19646906852722168\n",
      "\n",
      "episode 14, val func loss 0.2039906531572342\n",
      "\n",
      "episode 15, val func loss 0.20397721230983734\n",
      "\n",
      "episode 16, val func loss 0.15601199865341187\n",
      "\n",
      "Val func train loss in epoch 8:0.19335444271564484\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20374895632266998\n",
      "\n",
      "episode 2, val func loss 0.22233574092388153\n",
      "\n",
      "episode 3, val func loss 0.18662294745445251\n",
      "\n",
      "episode 4, val func loss 0.20398937165737152\n",
      "\n",
      "episode 5, val func loss 0.17717353999614716\n",
      "\n",
      "episode 6, val func loss 0.18054638803005219\n",
      "\n",
      "episode 7, val func loss 0.18832795321941376\n",
      "\n",
      "episode 8, val func loss 0.19768889248371124\n",
      "\n",
      "episode 9, val func loss 0.19886697828769684\n",
      "\n",
      "episode 10, val func loss 0.19973726570606232\n",
      "\n",
      "episode 11, val func loss 0.20401105284690857\n",
      "\n",
      "episode 12, val func loss 0.1542598158121109\n",
      "\n",
      "episode 13, val func loss 0.20573563873767853\n",
      "\n",
      "episode 14, val func loss 0.18979327380657196\n",
      "\n",
      "episode 15, val func loss 0.21513965725898743\n",
      "\n",
      "episode 16, val func loss 0.16214965283870697\n",
      "\n",
      "Val func train loss in epoch 9:0.19313294533640146\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20396913588047028\n",
      "\n",
      "episode 2, val func loss 0.18913808465003967\n",
      "\n",
      "episode 3, val func loss 0.15613411366939545\n",
      "\n",
      "episode 4, val func loss 0.19877152144908905\n",
      "\n",
      "episode 5, val func loss 0.2147054225206375\n",
      "\n",
      "episode 6, val func loss 0.18044422566890717\n",
      "\n",
      "episode 7, val func loss 0.2233157455921173\n",
      "\n",
      "episode 8, val func loss 0.20547045767307281\n",
      "\n",
      "episode 9, val func loss 0.20411400496959686\n",
      "\n",
      "episode 10, val func loss 0.19960525631904602\n",
      "\n",
      "episode 11, val func loss 0.1769515424966812\n",
      "\n",
      "episode 12, val func loss 0.16197003424167633\n",
      "\n",
      "episode 13, val func loss 0.2043682187795639\n",
      "\n",
      "episode 14, val func loss 0.19673345983028412\n",
      "\n",
      "episode 15, val func loss 0.1888808012008667\n",
      "\n",
      "episode 16, val func loss 0.1859966367483139\n",
      "\n",
      "Val func train loss in epoch 10:0.1931605413556099\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.203675776720047\n",
      "\n",
      "episode 2, val func loss 0.18864275515079498\n",
      "\n",
      "episode 3, val func loss 0.16223086416721344\n",
      "\n",
      "episode 4, val func loss 0.2047208696603775\n",
      "\n",
      "episode 5, val func loss 0.15449759364128113\n",
      "\n",
      "episode 6, val func loss 0.17606109380722046\n",
      "\n",
      "episode 7, val func loss 0.2154725342988968\n",
      "\n",
      "episode 8, val func loss 0.19954173266887665\n",
      "\n",
      "episode 9, val func loss 0.18530727922916412\n",
      "\n",
      "episode 10, val func loss 0.1991235464811325\n",
      "\n",
      "episode 11, val func loss 0.1974964737892151\n",
      "\n",
      "episode 12, val func loss 0.2236325442790985\n",
      "\n",
      "episode 13, val func loss 0.20378276705741882\n",
      "\n",
      "episode 14, val func loss 0.20503754913806915\n",
      "\n",
      "episode 15, val func loss 0.18974484503269196\n",
      "\n",
      "episode 16, val func loss 0.18248282372951508\n",
      "\n",
      "Val func train loss in epoch 11:0.19321569055318832\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18954028189182281\n",
      "\n",
      "episode 2, val func loss 0.19615592062473297\n",
      "\n",
      "episode 3, val func loss 0.16260981559753418\n",
      "\n",
      "episode 4, val func loss 0.21438537538051605\n",
      "\n",
      "episode 5, val func loss 0.2219994217157364\n",
      "\n",
      "episode 6, val func loss 0.20365475118160248\n",
      "\n",
      "episode 7, val func loss 0.20402610301971436\n",
      "\n",
      "episode 8, val func loss 0.1819125860929489\n",
      "\n",
      "episode 9, val func loss 0.19920630753040314\n",
      "\n",
      "episode 10, val func loss 0.18656201660633087\n",
      "\n",
      "episode 11, val func loss 0.15475653111934662\n",
      "\n",
      "episode 12, val func loss 0.2056383490562439\n",
      "\n",
      "episode 13, val func loss 0.1884024739265442\n",
      "\n",
      "episode 14, val func loss 0.2051089107990265\n",
      "\n",
      "episode 15, val func loss 0.1751493215560913\n",
      "\n",
      "episode 16, val func loss 0.20028376579284668\n",
      "\n",
      "Val func train loss in epoch 12:0.19308699574321508\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1907442957162857\n",
      "\n",
      "episode 2, val func loss 0.20634953677654266\n",
      "\n",
      "episode 3, val func loss 0.1855127066373825\n",
      "\n",
      "episode 4, val func loss 0.19897906482219696\n",
      "\n",
      "episode 5, val func loss 0.20368677377700806\n",
      "\n",
      "episode 6, val func loss 0.19970297813415527\n",
      "\n",
      "episode 7, val func loss 0.2052435278892517\n",
      "\n",
      "episode 8, val func loss 0.18932001292705536\n",
      "\n",
      "episode 9, val func loss 0.16254642605781555\n",
      "\n",
      "episode 10, val func loss 0.17784759402275085\n",
      "\n",
      "episode 11, val func loss 0.2147417664527893\n",
      "\n",
      "episode 12, val func loss 0.19681061804294586\n",
      "\n",
      "episode 13, val func loss 0.18029655516147614\n",
      "\n",
      "episode 14, val func loss 0.22319026291370392\n",
      "\n",
      "episode 15, val func loss 0.15465787053108215\n",
      "\n",
      "episode 16, val func loss 0.20432032644748688\n",
      "\n",
      "Val func train loss in epoch 13:0.19337189476937056\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.20521406829357147\n",
      "\n",
      "episode 2, val func loss 0.19906647503376007\n",
      "\n",
      "episode 3, val func loss 0.15469656884670258\n",
      "\n",
      "episode 4, val func loss 0.18870295584201813\n",
      "\n",
      "episode 5, val func loss 0.18592844903469086\n",
      "\n",
      "episode 6, val func loss 0.17605124413967133\n",
      "\n",
      "episode 7, val func loss 0.22381192445755005\n",
      "\n",
      "episode 8, val func loss 0.20455601811408997\n",
      "\n",
      "episode 9, val func loss 0.19739381968975067\n",
      "\n",
      "episode 10, val func loss 0.16196799278259277\n",
      "\n",
      "episode 11, val func loss 0.20385926961898804\n",
      "\n",
      "episode 12, val func loss 0.18015480041503906\n",
      "\n",
      "episode 13, val func loss 0.2052675187587738\n",
      "\n",
      "episode 14, val func loss 0.21455645561218262\n",
      "\n",
      "episode 15, val func loss 0.19965212047100067\n",
      "\n",
      "episode 16, val func loss 0.18940533697605133\n",
      "\n",
      "Val func train loss in epoch 14:0.1931428136304021\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1987859457731247\n",
      "\n",
      "episode 2, val func loss 0.203971266746521\n",
      "\n",
      "episode 3, val func loss 0.16227233409881592\n",
      "\n",
      "episode 4, val func loss 0.17725548148155212\n",
      "\n",
      "episode 5, val func loss 0.20506058633327484\n",
      "\n",
      "episode 6, val func loss 0.19948947429656982\n",
      "\n",
      "episode 7, val func loss 0.17957723140716553\n",
      "\n",
      "episode 8, val func loss 0.18544907867908478\n",
      "\n",
      "episode 9, val func loss 0.1905868649482727\n",
      "\n",
      "episode 10, val func loss 0.22592082619667053\n",
      "\n",
      "episode 11, val func loss 0.216411754488945\n",
      "\n",
      "episode 12, val func loss 0.188471257686615\n",
      "\n",
      "episode 13, val func loss 0.15454530715942383\n",
      "\n",
      "episode 14, val func loss 0.20392882823944092\n",
      "\n",
      "episode 15, val func loss 0.19675375521183014\n",
      "\n",
      "episode 16, val func loss 0.20397502183914185\n",
      "\n",
      "Val func train loss in epoch 15:0.19327843841165304\n",
      "***********************TIME WAS 5.010996798674266 min*****************************\n",
      "\n",
      "**********************ROUND 134 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.0018228687113150954\n",
      "\n",
      "episode 2, policy loss -0.015218192711472511\n",
      "\n",
      "episode 3, policy loss 0.005813931114971638\n",
      "\n",
      "episode 4, policy loss -0.018775328993797302\n",
      "\n",
      "episode 5, policy loss -0.026030493900179863\n",
      "\n",
      "episode 6, policy loss -0.02167525701224804\n",
      "\n",
      "episode 7, policy loss -0.01370109524577856\n",
      "\n",
      "episode 8, policy loss -0.0629771277308464\n",
      "\n",
      "episode 9, policy loss 0.021970201283693314\n",
      "\n",
      "episode 10, policy loss 0.003923173062503338\n",
      "\n",
      "episode 11, policy loss -0.0021877065300941467\n",
      "\n",
      "episode 12, policy loss 0.01976519078016281\n",
      "\n",
      "episode 13, policy loss -0.0014923902926966548\n",
      "\n",
      "episode 14, policy loss -0.029446447268128395\n",
      "\n",
      "episode 15, policy loss -0.00573901180177927\n",
      "\n",
      "episode 16, policy loss -0.042235102504491806\n",
      "\n",
      "Policy train loss in epoch 0:-0.011636424314929172\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.00640559196472168\n",
      "\n",
      "episode 2, policy loss -0.03275448828935623\n",
      "\n",
      "episode 3, policy loss -0.02863680198788643\n",
      "\n",
      "episode 4, policy loss -0.063735730946064\n",
      "\n",
      "episode 5, policy loss -0.005557768978178501\n",
      "\n",
      "episode 6, policy loss 0.01901552639901638\n",
      "\n",
      "episode 7, policy loss -0.02491442672908306\n",
      "\n",
      "episode 8, policy loss 0.01837029680609703\n",
      "\n",
      "episode 9, policy loss -0.007681723218411207\n",
      "\n",
      "episode 10, policy loss 0.001954156206920743\n",
      "\n",
      "episode 11, policy loss -0.02682783268392086\n",
      "\n",
      "episode 12, policy loss -0.00416470505297184\n",
      "\n",
      "episode 13, policy loss -0.00803385116159916\n",
      "\n",
      "episode 14, policy loss -0.030302785336971283\n",
      "\n",
      "episode 15, policy loss -0.014774443581700325\n",
      "\n",
      "episode 16, policy loss -0.04184262827038765\n",
      "\n",
      "Policy train loss in epoch 1:-0.01601829992432613\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.006889544427394867\n",
      "\n",
      "episode 2, policy loss -0.0288362018764019\n",
      "\n",
      "episode 3, policy loss -0.00541028194129467\n",
      "\n",
      "episode 4, policy loss 0.018722958862781525\n",
      "\n",
      "episode 5, policy loss -0.04174209386110306\n",
      "\n",
      "episode 6, policy loss -0.029676856473088264\n",
      "\n",
      "episode 7, policy loss -0.015387339517474174\n",
      "\n",
      "episode 8, policy loss -0.027959950268268585\n",
      "\n",
      "episode 9, policy loss -0.02816298045217991\n",
      "\n",
      "episode 10, policy loss -0.008166161365807056\n",
      "\n",
      "episode 11, policy loss 0.01743760146200657\n",
      "\n",
      "episode 12, policy loss -0.007106986362487078\n",
      "\n",
      "episode 13, policy loss -0.06412750482559204\n",
      "\n",
      "episode 14, policy loss 0.0025340961292386055\n",
      "\n",
      "episode 15, policy loss -0.005586710292845964\n",
      "\n",
      "episode 16, policy loss -0.033623434603214264\n",
      "\n",
      "Policy train loss in epoch 2:-0.01649883686332032\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.01678640954196453\n",
      "\n",
      "episode 2, policy loss -0.007859979756176472\n",
      "\n",
      "episode 3, policy loss -0.00541616091504693\n",
      "\n",
      "episode 4, policy loss -0.027805330231785774\n",
      "\n",
      "episode 5, policy loss -0.028629155829548836\n",
      "\n",
      "episode 6, policy loss -0.03365900367498398\n",
      "\n",
      "episode 7, policy loss -0.028029317036271095\n",
      "\n",
      "episode 8, policy loss 0.017540207132697105\n",
      "\n",
      "episode 9, policy loss -0.014698697254061699\n",
      "\n",
      "episode 10, policy loss -0.007687809411436319\n",
      "\n",
      "episode 11, policy loss -0.005776240956038237\n",
      "\n",
      "episode 12, policy loss -0.06566103547811508\n",
      "\n",
      "episode 13, policy loss 0.0014792759902775288\n",
      "\n",
      "episode 14, policy loss -0.04272729158401489\n",
      "\n",
      "episode 15, policy loss -0.008348217234015465\n",
      "\n",
      "episode 16, policy loss -0.03092224709689617\n",
      "\n",
      "Policy train loss in epoch 3:-0.016963412112090737\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19744160771369934\n",
      "\n",
      "episode 2, val func loss 0.2087346762418747\n",
      "\n",
      "episode 3, val func loss 0.19552011787891388\n",
      "\n",
      "episode 4, val func loss 0.18599887192249298\n",
      "\n",
      "episode 5, val func loss 0.1788436472415924\n",
      "\n",
      "episode 6, val func loss 0.18887634575366974\n",
      "\n",
      "episode 7, val func loss 0.2143382579088211\n",
      "\n",
      "episode 8, val func loss 0.16135092079639435\n",
      "\n",
      "episode 9, val func loss 0.20082643628120422\n",
      "\n",
      "episode 10, val func loss 0.19067463278770447\n",
      "\n",
      "episode 11, val func loss 0.1932518631219864\n",
      "\n",
      "episode 12, val func loss 0.16745048761367798\n",
      "\n",
      "episode 13, val func loss 0.18416547775268555\n",
      "\n",
      "episode 14, val func loss 0.20155273377895355\n",
      "\n",
      "episode 15, val func loss 0.2163255214691162\n",
      "\n",
      "episode 16, val func loss 0.19774484634399414\n",
      "\n",
      "Val func train loss in epoch 0:0.1926935277879238\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.16204610466957092\n",
      "\n",
      "episode 2, val func loss 0.20163890719413757\n",
      "\n",
      "episode 3, val func loss 0.19981101155281067\n",
      "\n",
      "episode 4, val func loss 0.19464591145515442\n",
      "\n",
      "episode 5, val func loss 0.16739806532859802\n",
      "\n",
      "episode 6, val func loss 0.18883879482746124\n",
      "\n",
      "episode 7, val func loss 0.20782878994941711\n",
      "\n",
      "episode 8, val func loss 0.1901009976863861\n",
      "\n",
      "episode 9, val func loss 0.21278448402881622\n",
      "\n",
      "episode 10, val func loss 0.18400615453720093\n",
      "\n",
      "episode 11, val func loss 0.1848667562007904\n",
      "\n",
      "episode 12, val func loss 0.19811145961284637\n",
      "\n",
      "episode 13, val func loss 0.19369493424892426\n",
      "\n",
      "episode 14, val func loss 0.2164551317691803\n",
      "\n",
      "episode 15, val func loss 0.177575945854187\n",
      "\n",
      "episode 16, val func loss 0.19694896042346954\n",
      "\n",
      "Val func train loss in epoch 1:0.19229702558368444\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.2082672119140625\n",
      "\n",
      "episode 2, val func loss 0.1932387351989746\n",
      "\n",
      "episode 3, val func loss 0.21466894447803497\n",
      "\n",
      "episode 4, val func loss 0.20081840455532074\n",
      "\n",
      "episode 5, val func loss 0.19805479049682617\n",
      "\n",
      "episode 6, val func loss 0.16226345300674438\n",
      "\n",
      "episode 7, val func loss 0.1675470769405365\n",
      "\n",
      "episode 8, val func loss 0.19482584297657013\n",
      "\n",
      "episode 9, val func loss 0.18414850533008575\n",
      "\n",
      "episode 10, val func loss 0.19701315462589264\n",
      "\n",
      "episode 11, val func loss 0.21630054712295532\n",
      "\n",
      "episode 12, val func loss 0.20182394981384277\n",
      "\n",
      "episode 13, val func loss 0.18415169417858124\n",
      "\n",
      "episode 14, val func loss 0.18878209590911865\n",
      "\n",
      "episode 15, val func loss 0.17656655609607697\n",
      "\n",
      "episode 16, val func loss 0.1904841810464859\n",
      "\n",
      "Val func train loss in epoch 2:0.19243469648063183\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19689875841140747\n",
      "\n",
      "episode 2, val func loss 0.17651641368865967\n",
      "\n",
      "episode 3, val func loss 0.1978665441274643\n",
      "\n",
      "episode 4, val func loss 0.19325551390647888\n",
      "\n",
      "episode 5, val func loss 0.20057247579097748\n",
      "\n",
      "episode 6, val func loss 0.20193924009799957\n",
      "\n",
      "episode 7, val func loss 0.20777535438537598\n",
      "\n",
      "episode 8, val func loss 0.21242760121822357\n",
      "\n",
      "episode 9, val func loss 0.18452785909175873\n",
      "\n",
      "episode 10, val func loss 0.16869141161441803\n",
      "\n",
      "episode 11, val func loss 0.16327720880508423\n",
      "\n",
      "episode 12, val func loss 0.18959586322307587\n",
      "\n",
      "episode 13, val func loss 0.18497994542121887\n",
      "\n",
      "episode 14, val func loss 0.19492250680923462\n",
      "\n",
      "episode 15, val func loss 0.21623601019382477\n",
      "\n",
      "episode 16, val func loss 0.1890006959438324\n",
      "\n",
      "Val func train loss in epoch 3:0.19240521267056465\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.16679970920085907\n",
      "\n",
      "episode 2, val func loss 0.19506259262561798\n",
      "\n",
      "episode 3, val func loss 0.16110506653785706\n",
      "\n",
      "episode 4, val func loss 0.18399077653884888\n",
      "\n",
      "episode 5, val func loss 0.20877668261528015\n",
      "\n",
      "episode 6, val func loss 0.20291389524936676\n",
      "\n",
      "episode 7, val func loss 0.184266597032547\n",
      "\n",
      "episode 8, val func loss 0.17607402801513672\n",
      "\n",
      "episode 9, val func loss 0.21666181087493896\n",
      "\n",
      "episode 10, val func loss 0.21314679086208344\n",
      "\n",
      "episode 11, val func loss 0.1998046636581421\n",
      "\n",
      "episode 12, val func loss 0.18918746709823608\n",
      "\n",
      "episode 13, val func loss 0.19719980657100677\n",
      "\n",
      "episode 14, val func loss 0.189265176653862\n",
      "\n",
      "episode 15, val func loss 0.19869782030582428\n",
      "\n",
      "episode 16, val func loss 0.19492748379707336\n",
      "\n",
      "Val func train loss in epoch 4:0.19236752297729254\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17900657653808594\n",
      "\n",
      "episode 2, val func loss 0.20151449739933014\n",
      "\n",
      "episode 3, val func loss 0.1931118369102478\n",
      "\n",
      "episode 4, val func loss 0.16627515852451324\n",
      "\n",
      "episode 5, val func loss 0.21833975613117218\n",
      "\n",
      "episode 6, val func loss 0.19660070538520813\n",
      "\n",
      "episode 7, val func loss 0.20849481225013733\n",
      "\n",
      "episode 8, val func loss 0.1843210756778717\n",
      "\n",
      "episode 9, val func loss 0.18881240487098694\n",
      "\n",
      "episode 10, val func loss 0.19817860424518585\n",
      "\n",
      "episode 11, val func loss 0.16217975318431854\n",
      "\n",
      "episode 12, val func loss 0.1899387091398239\n",
      "\n",
      "episode 13, val func loss 0.21189822256565094\n",
      "\n",
      "episode 14, val func loss 0.18503651022911072\n",
      "\n",
      "episode 15, val func loss 0.1972215175628662\n",
      "\n",
      "episode 16, val func loss 0.19919776916503906\n",
      "\n",
      "Val func train loss in epoch 5:0.1925079943612218\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18472348153591156\n",
      "\n",
      "episode 2, val func loss 0.18917807936668396\n",
      "\n",
      "episode 3, val func loss 0.21156273782253265\n",
      "\n",
      "episode 4, val func loss 0.16822342574596405\n",
      "\n",
      "episode 5, val func loss 0.18445667624473572\n",
      "\n",
      "episode 6, val func loss 0.2161378711462021\n",
      "\n",
      "episode 7, val func loss 0.1905367374420166\n",
      "\n",
      "episode 8, val func loss 0.20798052847385406\n",
      "\n",
      "episode 9, val func loss 0.197995126247406\n",
      "\n",
      "episode 10, val func loss 0.19497859477996826\n",
      "\n",
      "episode 11, val func loss 0.1618368774652481\n",
      "\n",
      "episode 12, val func loss 0.1932738870382309\n",
      "\n",
      "episode 13, val func loss 0.1764603555202484\n",
      "\n",
      "episode 14, val func loss 0.20278839766979218\n",
      "\n",
      "episode 15, val func loss 0.1971781849861145\n",
      "\n",
      "episode 16, val func loss 0.20092852413654327\n",
      "\n",
      "Val func train loss in epoch 6:0.19238996785134077\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.16697674989700317\n",
      "\n",
      "episode 2, val func loss 0.1614874303340912\n",
      "\n",
      "episode 3, val func loss 0.1887417882680893\n",
      "\n",
      "episode 4, val func loss 0.20020855963230133\n",
      "\n",
      "episode 5, val func loss 0.18437153100967407\n",
      "\n",
      "episode 6, val func loss 0.18404902517795563\n",
      "\n",
      "episode 7, val func loss 0.17719486355781555\n",
      "\n",
      "episode 8, val func loss 0.19012518227100372\n",
      "\n",
      "episode 9, val func loss 0.19509553909301758\n",
      "\n",
      "episode 10, val func loss 0.1933184117078781\n",
      "\n",
      "episode 11, val func loss 0.19692139327526093\n",
      "\n",
      "episode 12, val func loss 0.21639472246170044\n",
      "\n",
      "episode 13, val func loss 0.1980537325143814\n",
      "\n",
      "episode 14, val func loss 0.20164796710014343\n",
      "\n",
      "episode 15, val func loss 0.20785091817378998\n",
      "\n",
      "episode 16, val func loss 0.21220970153808594\n",
      "\n",
      "Val func train loss in epoch 7:0.19216546975076199\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16248658299446106\n",
      "\n",
      "episode 2, val func loss 0.2081698328256607\n",
      "\n",
      "episode 3, val func loss 0.18918968737125397\n",
      "\n",
      "episode 4, val func loss 0.21619802713394165\n",
      "\n",
      "episode 5, val func loss 0.1845845729112625\n",
      "\n",
      "episode 6, val func loss 0.19349977374076843\n",
      "\n",
      "episode 7, val func loss 0.21300043165683746\n",
      "\n",
      "episode 8, val func loss 0.1948348730802536\n",
      "\n",
      "episode 9, val func loss 0.19991269707679749\n",
      "\n",
      "episode 10, val func loss 0.20162855088710785\n",
      "\n",
      "episode 11, val func loss 0.18973353505134583\n",
      "\n",
      "episode 12, val func loss 0.19731345772743225\n",
      "\n",
      "episode 13, val func loss 0.18501883745193481\n",
      "\n",
      "episode 14, val func loss 0.1790188103914261\n",
      "\n",
      "episode 15, val func loss 0.1681920737028122\n",
      "\n",
      "episode 16, val func loss 0.19818134605884552\n",
      "\n",
      "Val func train loss in epoch 8:0.19256019312888384\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.196957066655159\n",
      "\n",
      "episode 2, val func loss 0.2021915167570114\n",
      "\n",
      "episode 3, val func loss 0.18398728966712952\n",
      "\n",
      "episode 4, val func loss 0.19305552542209625\n",
      "\n",
      "episode 5, val func loss 0.1612486094236374\n",
      "\n",
      "episode 6, val func loss 0.18931177258491516\n",
      "\n",
      "episode 7, val func loss 0.17558977007865906\n",
      "\n",
      "episode 8, val func loss 0.21608151495456696\n",
      "\n",
      "episode 9, val func loss 0.2085302621126175\n",
      "\n",
      "episode 10, val func loss 0.18396811187267303\n",
      "\n",
      "episode 11, val func loss 0.19010525941848755\n",
      "\n",
      "episode 12, val func loss 0.19934506714344025\n",
      "\n",
      "episode 13, val func loss 0.16857565939426422\n",
      "\n",
      "episode 14, val func loss 0.19523724913597107\n",
      "\n",
      "episode 15, val func loss 0.19857054948806763\n",
      "\n",
      "episode 16, val func loss 0.21630975604057312\n",
      "\n",
      "Val func train loss in epoch 9:0.19244156125932932\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20838965475559235\n",
      "\n",
      "episode 2, val func loss 0.18508104979991913\n",
      "\n",
      "episode 3, val func loss 0.21614737808704376\n",
      "\n",
      "episode 4, val func loss 0.20192325115203857\n",
      "\n",
      "episode 5, val func loss 0.19539062678813934\n",
      "\n",
      "episode 6, val func loss 0.1929364651441574\n",
      "\n",
      "episode 7, val func loss 0.19795182347297668\n",
      "\n",
      "episode 8, val func loss 0.20019058883190155\n",
      "\n",
      "episode 9, val func loss 0.16187125444412231\n",
      "\n",
      "episode 10, val func loss 0.19700875878334045\n",
      "\n",
      "episode 11, val func loss 0.1888284534215927\n",
      "\n",
      "episode 12, val func loss 0.1770193874835968\n",
      "\n",
      "episode 13, val func loss 0.19028253853321075\n",
      "\n",
      "episode 14, val func loss 0.16670651733875275\n",
      "\n",
      "episode 15, val func loss 0.21324585378170013\n",
      "\n",
      "episode 16, val func loss 0.184082493185997\n",
      "\n",
      "Val func train loss in epoch 10:0.1923160059377551\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1771293729543686\n",
      "\n",
      "episode 2, val func loss 0.20783621072769165\n",
      "\n",
      "episode 3, val func loss 0.184231698513031\n",
      "\n",
      "episode 4, val func loss 0.16175618767738342\n",
      "\n",
      "episode 5, val func loss 0.19065867364406586\n",
      "\n",
      "episode 6, val func loss 0.2165869027376175\n",
      "\n",
      "episode 7, val func loss 0.1950806826353073\n",
      "\n",
      "episode 8, val func loss 0.1930498480796814\n",
      "\n",
      "episode 9, val func loss 0.20170502364635468\n",
      "\n",
      "episode 10, val func loss 0.18414157629013062\n",
      "\n",
      "episode 11, val func loss 0.1968170702457428\n",
      "\n",
      "episode 12, val func loss 0.21222521364688873\n",
      "\n",
      "episode 13, val func loss 0.19795285165309906\n",
      "\n",
      "episode 14, val func loss 0.19890768826007843\n",
      "\n",
      "episode 15, val func loss 0.1685192734003067\n",
      "\n",
      "episode 16, val func loss 0.18941378593444824\n",
      "\n",
      "Val func train loss in epoch 11:0.19225075375288725\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.21117578446865082\n",
      "\n",
      "episode 2, val func loss 0.17878586053848267\n",
      "\n",
      "episode 3, val func loss 0.1971166431903839\n",
      "\n",
      "episode 4, val func loss 0.19484461843967438\n",
      "\n",
      "episode 5, val func loss 0.20180188119411469\n",
      "\n",
      "episode 6, val func loss 0.18435396254062653\n",
      "\n",
      "episode 7, val func loss 0.19340455532073975\n",
      "\n",
      "episode 8, val func loss 0.1664557009935379\n",
      "\n",
      "episode 9, val func loss 0.21704529225826263\n",
      "\n",
      "episode 10, val func loss 0.18916790187358856\n",
      "\n",
      "episode 11, val func loss 0.19173461198806763\n",
      "\n",
      "episode 12, val func loss 0.20793525874614716\n",
      "\n",
      "episode 13, val func loss 0.2004014551639557\n",
      "\n",
      "episode 14, val func loss 0.18390224874019623\n",
      "\n",
      "episode 15, val func loss 0.16251526772975922\n",
      "\n",
      "episode 16, val func loss 0.19813218712806702\n",
      "\n",
      "Val func train loss in epoch 12:0.19242332689464092\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.20789526402950287\n",
      "\n",
      "episode 2, val func loss 0.1990896761417389\n",
      "\n",
      "episode 3, val func loss 0.21653631329536438\n",
      "\n",
      "episode 4, val func loss 0.16289110481739044\n",
      "\n",
      "episode 5, val func loss 0.19377756118774414\n",
      "\n",
      "episode 6, val func loss 0.19017621874809265\n",
      "\n",
      "episode 7, val func loss 0.19482749700546265\n",
      "\n",
      "episode 8, val func loss 0.1842954158782959\n",
      "\n",
      "episode 9, val func loss 0.18400076031684875\n",
      "\n",
      "episode 10, val func loss 0.20208638906478882\n",
      "\n",
      "episode 11, val func loss 0.1765701025724411\n",
      "\n",
      "episode 12, val func loss 0.1667131632566452\n",
      "\n",
      "episode 13, val func loss 0.2149176001548767\n",
      "\n",
      "episode 14, val func loss 0.18899215757846832\n",
      "\n",
      "episode 15, val func loss 0.19813376665115356\n",
      "\n",
      "episode 16, val func loss 0.19693464040756226\n",
      "\n",
      "Val func train loss in epoch 13:0.19236485194414854\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.21617914736270905\n",
      "\n",
      "episode 2, val func loss 0.17735040187835693\n",
      "\n",
      "episode 3, val func loss 0.19966499507427216\n",
      "\n",
      "episode 4, val func loss 0.18449953198432922\n",
      "\n",
      "episode 5, val func loss 0.19502855837345123\n",
      "\n",
      "episode 6, val func loss 0.18401241302490234\n",
      "\n",
      "episode 7, val func loss 0.16201362013816833\n",
      "\n",
      "episode 8, val func loss 0.20189841091632843\n",
      "\n",
      "episode 9, val func loss 0.21333152055740356\n",
      "\n",
      "episode 10, val func loss 0.20786052942276\n",
      "\n",
      "episode 11, val func loss 0.16728182137012482\n",
      "\n",
      "episode 12, val func loss 0.1897539496421814\n",
      "\n",
      "episode 13, val func loss 0.19686755537986755\n",
      "\n",
      "episode 14, val func loss 0.19799256324768066\n",
      "\n",
      "episode 15, val func loss 0.18913841247558594\n",
      "\n",
      "episode 16, val func loss 0.19345159828662872\n",
      "\n",
      "Val func train loss in epoch 14:0.1922703143209219\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20785611867904663\n",
      "\n",
      "episode 2, val func loss 0.1949024647474289\n",
      "\n",
      "episode 3, val func loss 0.1768471747636795\n",
      "\n",
      "episode 4, val func loss 0.1841324120759964\n",
      "\n",
      "episode 5, val func loss 0.18919827044010162\n",
      "\n",
      "episode 6, val func loss 0.19121237099170685\n",
      "\n",
      "episode 7, val func loss 0.21375034749507904\n",
      "\n",
      "episode 8, val func loss 0.1671779602766037\n",
      "\n",
      "episode 9, val func loss 0.19375263154506683\n",
      "\n",
      "episode 10, val func loss 0.1971420794725418\n",
      "\n",
      "episode 11, val func loss 0.19810277223587036\n",
      "\n",
      "episode 12, val func loss 0.2165476381778717\n",
      "\n",
      "episode 13, val func loss 0.18457715213298798\n",
      "\n",
      "episode 14, val func loss 0.20175540447235107\n",
      "\n",
      "episode 15, val func loss 0.20007503032684326\n",
      "\n",
      "episode 16, val func loss 0.16194812953472137\n",
      "\n",
      "Val func train loss in epoch 15:0.19243612233549356\n",
      "***********************TIME WAS 5.007857577006022 min*****************************\n",
      "\n",
      "**********************ROUND 135 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.02678227797150612\n",
      "\n",
      "episode 2, policy loss -0.03254187852144241\n",
      "\n",
      "episode 3, policy loss -0.029741603881120682\n",
      "\n",
      "episode 4, policy loss -0.049798306077718735\n",
      "\n",
      "episode 5, policy loss -0.027799488976597786\n",
      "\n",
      "episode 6, policy loss -0.00036571762757375836\n",
      "\n",
      "episode 7, policy loss 0.03890567645430565\n",
      "\n",
      "episode 8, policy loss -0.028392521664500237\n",
      "\n",
      "episode 9, policy loss -0.04078384116292\n",
      "\n",
      "episode 10, policy loss -0.014675918966531754\n",
      "\n",
      "episode 11, policy loss -0.07151932269334793\n",
      "\n",
      "episode 12, policy loss -0.058645252138376236\n",
      "\n",
      "episode 13, policy loss -0.010682307183742523\n",
      "\n",
      "episode 14, policy loss -0.062164079397916794\n",
      "\n",
      "episode 15, policy loss -0.017973029986023903\n",
      "\n",
      "episode 16, policy loss 0.022044073790311813\n",
      "\n",
      "Policy train loss in epoch 0:-0.025682237250293838\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.015423381701111794\n",
      "\n",
      "episode 2, policy loss -0.053435809910297394\n",
      "\n",
      "episode 3, policy loss -0.06128278747200966\n",
      "\n",
      "episode 4, policy loss -0.01186244748532772\n",
      "\n",
      "episode 5, policy loss -0.0020617919508367777\n",
      "\n",
      "episode 6, policy loss -0.017945555970072746\n",
      "\n",
      "episode 7, policy loss -0.03658486157655716\n",
      "\n",
      "episode 8, policy loss 0.022154364734888077\n",
      "\n",
      "episode 9, policy loss -0.042457740753889084\n",
      "\n",
      "episode 10, policy loss -0.03142674267292023\n",
      "\n",
      "episode 11, policy loss -0.07158265262842178\n",
      "\n",
      "episode 12, policy loss -0.045650914311409\n",
      "\n",
      "episode 13, policy loss -0.06665176898241043\n",
      "\n",
      "episode 14, policy loss -0.0448506698012352\n",
      "\n",
      "episode 15, policy loss 0.0362054705619812\n",
      "\n",
      "episode 16, policy loss -0.03199371322989464\n",
      "\n",
      "Policy train loss in epoch 1:-0.02967818769684527\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.06685016304254532\n",
      "\n",
      "episode 2, policy loss -0.011818934231996536\n",
      "\n",
      "episode 3, policy loss 0.0354485884308815\n",
      "\n",
      "episode 4, policy loss -0.053434666246175766\n",
      "\n",
      "episode 5, policy loss -0.04504340514540672\n",
      "\n",
      "episode 6, policy loss -0.03294511139392853\n",
      "\n",
      "episode 7, policy loss -0.03676726669073105\n",
      "\n",
      "episode 8, policy loss -0.04490208998322487\n",
      "\n",
      "episode 9, policy loss -0.01612052135169506\n",
      "\n",
      "episode 10, policy loss -0.03232286870479584\n",
      "\n",
      "episode 11, policy loss -0.003360355505719781\n",
      "\n",
      "episode 12, policy loss -0.0715363398194313\n",
      "\n",
      "episode 13, policy loss 0.02098478563129902\n",
      "\n",
      "episode 14, policy loss -0.06096337363123894\n",
      "\n",
      "episode 15, policy loss -0.018587229773402214\n",
      "\n",
      "episode 16, policy loss -0.04578626900911331\n",
      "\n",
      "Policy train loss in epoch 2:-0.030250326279201545\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.012924659997224808\n",
      "\n",
      "episode 2, policy loss -0.03689904883503914\n",
      "\n",
      "episode 3, policy loss -0.032304797321558\n",
      "\n",
      "episode 4, policy loss -0.06663291156291962\n",
      "\n",
      "episode 5, policy loss -0.0716262012720108\n",
      "\n",
      "episode 6, policy loss -0.002760180039331317\n",
      "\n",
      "episode 7, policy loss 0.03429329767823219\n",
      "\n",
      "episode 8, policy loss -0.020031806081533432\n",
      "\n",
      "episode 9, policy loss -0.05374239385128021\n",
      "\n",
      "episode 10, policy loss -0.01639213226735592\n",
      "\n",
      "episode 11, policy loss -0.04562823101878166\n",
      "\n",
      "episode 12, policy loss -0.04473147168755531\n",
      "\n",
      "episode 13, policy loss -0.06260383129119873\n",
      "\n",
      "episode 14, policy loss 0.020860131829977036\n",
      "\n",
      "episode 15, policy loss -0.033034007996320724\n",
      "\n",
      "episode 16, policy loss -0.04637332260608673\n",
      "\n",
      "Policy train loss in epoch 3:-0.0306582228949992\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.15456287562847137\n",
      "\n",
      "episode 2, val func loss 0.20774626731872559\n",
      "\n",
      "episode 3, val func loss 0.18147999048233032\n",
      "\n",
      "episode 4, val func loss 0.1749899685382843\n",
      "\n",
      "episode 5, val func loss 0.19742493331432343\n",
      "\n",
      "episode 6, val func loss 0.15758514404296875\n",
      "\n",
      "episode 7, val func loss 0.21068075299263\n",
      "\n",
      "episode 8, val func loss 0.18850663304328918\n",
      "\n",
      "episode 9, val func loss 0.1751357465982437\n",
      "\n",
      "episode 10, val func loss 0.18042568862438202\n",
      "\n",
      "episode 11, val func loss 0.18856683373451233\n",
      "\n",
      "episode 12, val func loss 0.21908599138259888\n",
      "\n",
      "episode 13, val func loss 0.19085299968719482\n",
      "\n",
      "episode 14, val func loss 0.19910414516925812\n",
      "\n",
      "episode 15, val func loss 0.18867073953151703\n",
      "\n",
      "episode 16, val func loss 0.19794368743896484\n",
      "\n",
      "Val func train loss in epoch 0:0.18829764984548092\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19759532809257507\n",
      "\n",
      "episode 2, val func loss 0.1970028281211853\n",
      "\n",
      "episode 3, val func loss 0.17645065486431122\n",
      "\n",
      "episode 4, val func loss 0.2078741192817688\n",
      "\n",
      "episode 5, val func loss 0.2192911058664322\n",
      "\n",
      "episode 6, val func loss 0.1996309906244278\n",
      "\n",
      "episode 7, val func loss 0.18836365640163422\n",
      "\n",
      "episode 8, val func loss 0.1544313281774521\n",
      "\n",
      "episode 9, val func loss 0.15987126529216766\n",
      "\n",
      "episode 10, val func loss 0.20902451872825623\n",
      "\n",
      "episode 11, val func loss 0.1903650313615799\n",
      "\n",
      "episode 12, val func loss 0.1884860247373581\n",
      "\n",
      "episode 13, val func loss 0.1748914122581482\n",
      "\n",
      "episode 14, val func loss 0.18820898234844208\n",
      "\n",
      "episode 15, val func loss 0.1808631420135498\n",
      "\n",
      "episode 16, val func loss 0.18082430958747864\n",
      "\n",
      "Val func train loss in epoch 1:0.18832341860979795\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17507398128509521\n",
      "\n",
      "episode 2, val func loss 0.20971529185771942\n",
      "\n",
      "episode 3, val func loss 0.21912866830825806\n",
      "\n",
      "episode 4, val func loss 0.154180109500885\n",
      "\n",
      "episode 5, val func loss 0.15996676683425903\n",
      "\n",
      "episode 6, val func loss 0.20741376280784607\n",
      "\n",
      "episode 7, val func loss 0.17602653801441193\n",
      "\n",
      "episode 8, val func loss 0.1813637763261795\n",
      "\n",
      "episode 9, val func loss 0.19985651969909668\n",
      "\n",
      "episode 10, val func loss 0.18858449161052704\n",
      "\n",
      "episode 11, val func loss 0.18848025798797607\n",
      "\n",
      "episode 12, val func loss 0.19042491912841797\n",
      "\n",
      "episode 13, val func loss 0.17920121550559998\n",
      "\n",
      "episode 14, val func loss 0.1878845989704132\n",
      "\n",
      "episode 15, val func loss 0.197036474943161\n",
      "\n",
      "episode 16, val func loss 0.19736406207084656\n",
      "\n",
      "Val func train loss in epoch 2:0.1882313396781683\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1883770376443863\n",
      "\n",
      "episode 2, val func loss 0.1879618763923645\n",
      "\n",
      "episode 3, val func loss 0.19718721508979797\n",
      "\n",
      "episode 4, val func loss 0.17634116113185883\n",
      "\n",
      "episode 5, val func loss 0.17793618142604828\n",
      "\n",
      "episode 6, val func loss 0.1541023552417755\n",
      "\n",
      "episode 7, val func loss 0.15920187532901764\n",
      "\n",
      "episode 8, val func loss 0.19734634459018707\n",
      "\n",
      "episode 9, val func loss 0.18088677525520325\n",
      "\n",
      "episode 10, val func loss 0.20194058120250702\n",
      "\n",
      "episode 11, val func loss 0.1908930093050003\n",
      "\n",
      "episode 12, val func loss 0.21131613850593567\n",
      "\n",
      "episode 13, val func loss 0.17510704696178436\n",
      "\n",
      "episode 14, val func loss 0.1885606348514557\n",
      "\n",
      "episode 15, val func loss 0.20858986675739288\n",
      "\n",
      "episode 16, val func loss 0.21901923418045044\n",
      "\n",
      "Val func train loss in epoch 3:0.18842295836657286\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18825936317443848\n",
      "\n",
      "episode 2, val func loss 0.17700400948524475\n",
      "\n",
      "episode 3, val func loss 0.18908905982971191\n",
      "\n",
      "episode 4, val func loss 0.18826976418495178\n",
      "\n",
      "episode 5, val func loss 0.17581972479820251\n",
      "\n",
      "episode 6, val func loss 0.19947564601898193\n",
      "\n",
      "episode 7, val func loss 0.15961965918540955\n",
      "\n",
      "episode 8, val func loss 0.17868392169475555\n",
      "\n",
      "episode 9, val func loss 0.15291765332221985\n",
      "\n",
      "episode 10, val func loss 0.1976345330476761\n",
      "\n",
      "episode 11, val func loss 0.19052283465862274\n",
      "\n",
      "episode 12, val func loss 0.2202366590499878\n",
      "\n",
      "episode 13, val func loss 0.18062791228294373\n",
      "\n",
      "episode 14, val func loss 0.21035273373126984\n",
      "\n",
      "episode 15, val func loss 0.209779292345047\n",
      "\n",
      "episode 16, val func loss 0.19716335833072662\n",
      "\n",
      "Val func train loss in epoch 4:0.18846600782126188\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1599208265542984\n",
      "\n",
      "episode 2, val func loss 0.1754046529531479\n",
      "\n",
      "episode 3, val func loss 0.18830884993076324\n",
      "\n",
      "episode 4, val func loss 0.18850772082805634\n",
      "\n",
      "episode 5, val func loss 0.1905786246061325\n",
      "\n",
      "episode 6, val func loss 0.20905299484729767\n",
      "\n",
      "episode 7, val func loss 0.17863324284553528\n",
      "\n",
      "episode 8, val func loss 0.1537313014268875\n",
      "\n",
      "episode 9, val func loss 0.1997559368610382\n",
      "\n",
      "episode 10, val func loss 0.19745279848575592\n",
      "\n",
      "episode 11, val func loss 0.19720464944839478\n",
      "\n",
      "episode 12, val func loss 0.2191862314939499\n",
      "\n",
      "episode 13, val func loss 0.18817661702632904\n",
      "\n",
      "episode 14, val func loss 0.2073325514793396\n",
      "\n",
      "episode 15, val func loss 0.1763872504234314\n",
      "\n",
      "episode 16, val func loss 0.18218658864498138\n",
      "\n",
      "Val func train loss in epoch 5:0.1882388023659587\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.15988269448280334\n",
      "\n",
      "episode 2, val func loss 0.17530232667922974\n",
      "\n",
      "episode 3, val func loss 0.1807543784379959\n",
      "\n",
      "episode 4, val func loss 0.18832635879516602\n",
      "\n",
      "episode 5, val func loss 0.22115570306777954\n",
      "\n",
      "episode 6, val func loss 0.18920111656188965\n",
      "\n",
      "episode 7, val func loss 0.19078323245048523\n",
      "\n",
      "episode 8, val func loss 0.2104232907295227\n",
      "\n",
      "episode 9, val func loss 0.18856656551361084\n",
      "\n",
      "episode 10, val func loss 0.1970910280942917\n",
      "\n",
      "episode 11, val func loss 0.17832836508750916\n",
      "\n",
      "episode 12, val func loss 0.15597622096538544\n",
      "\n",
      "episode 13, val func loss 0.19738571345806122\n",
      "\n",
      "episode 14, val func loss 0.17724241316318512\n",
      "\n",
      "episode 15, val func loss 0.19904473423957825\n",
      "\n",
      "episode 16, val func loss 0.20782575011253357\n",
      "\n",
      "Val func train loss in epoch 6:0.1885806182399392\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19946925342082977\n",
      "\n",
      "episode 2, val func loss 0.18820518255233765\n",
      "\n",
      "episode 3, val func loss 0.19108644127845764\n",
      "\n",
      "episode 4, val func loss 0.19744879007339478\n",
      "\n",
      "episode 5, val func loss 0.20834411680698395\n",
      "\n",
      "episode 6, val func loss 0.17607931792736053\n",
      "\n",
      "episode 7, val func loss 0.18839871883392334\n",
      "\n",
      "episode 8, val func loss 0.1885266900062561\n",
      "\n",
      "episode 9, val func loss 0.19720925390720367\n",
      "\n",
      "episode 10, val func loss 0.17498859763145447\n",
      "\n",
      "episode 11, val func loss 0.20839525759220123\n",
      "\n",
      "episode 12, val func loss 0.17864280939102173\n",
      "\n",
      "episode 13, val func loss 0.21888500452041626\n",
      "\n",
      "episode 14, val func loss 0.18208570778369904\n",
      "\n",
      "episode 15, val func loss 0.1601647287607193\n",
      "\n",
      "episode 16, val func loss 0.1540875881910324\n",
      "\n",
      "Val func train loss in epoch 7:0.18825109116733074\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.18793274462223053\n",
      "\n",
      "episode 2, val func loss 0.2093915343284607\n",
      "\n",
      "episode 3, val func loss 0.19746775925159454\n",
      "\n",
      "episode 4, val func loss 0.1809638887643814\n",
      "\n",
      "episode 5, val func loss 0.1903240829706192\n",
      "\n",
      "episode 6, val func loss 0.15192121267318726\n",
      "\n",
      "episode 7, val func loss 0.22005343437194824\n",
      "\n",
      "episode 8, val func loss 0.15672969818115234\n",
      "\n",
      "episode 9, val func loss 0.17500759661197662\n",
      "\n",
      "episode 10, val func loss 0.18887048959732056\n",
      "\n",
      "episode 11, val func loss 0.17508214712142944\n",
      "\n",
      "episode 12, val func loss 0.21118906140327454\n",
      "\n",
      "episode 13, val func loss 0.19757896661758423\n",
      "\n",
      "episode 14, val func loss 0.18871942162513733\n",
      "\n",
      "episode 15, val func loss 0.17841677367687225\n",
      "\n",
      "episode 16, val func loss 0.19884105026721954\n",
      "\n",
      "Val func train loss in epoch 8:0.1880306163802743\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20556242763996124\n",
      "\n",
      "episode 2, val func loss 0.17689985036849976\n",
      "\n",
      "episode 3, val func loss 0.19840370118618011\n",
      "\n",
      "episode 4, val func loss 0.1809537559747696\n",
      "\n",
      "episode 5, val func loss 0.19050399959087372\n",
      "\n",
      "episode 6, val func loss 0.16266918182373047\n",
      "\n",
      "episode 7, val func loss 0.17580655217170715\n",
      "\n",
      "episode 8, val func loss 0.15217691659927368\n",
      "\n",
      "episode 9, val func loss 0.19867996871471405\n",
      "\n",
      "episode 10, val func loss 0.2036646157503128\n",
      "\n",
      "episode 11, val func loss 0.22198250889778137\n",
      "\n",
      "episode 12, val func loss 0.19041679799556732\n",
      "\n",
      "episode 13, val func loss 0.21101701259613037\n",
      "\n",
      "episode 14, val func loss 0.1817760020494461\n",
      "\n",
      "episode 15, val func loss 0.18908581137657166\n",
      "\n",
      "episode 16, val func loss 0.19749820232391357\n",
      "\n",
      "Val func train loss in epoch 9:0.18981858156621456\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.15406237542629242\n",
      "\n",
      "episode 2, val func loss 0.17503531277179718\n",
      "\n",
      "episode 3, val func loss 0.22032418847084045\n",
      "\n",
      "episode 4, val func loss 0.18085388839244843\n",
      "\n",
      "episode 5, val func loss 0.15610744059085846\n",
      "\n",
      "episode 6, val func loss 0.18268859386444092\n",
      "\n",
      "episode 7, val func loss 0.18963880836963654\n",
      "\n",
      "episode 8, val func loss 0.2109866738319397\n",
      "\n",
      "episode 9, val func loss 0.1973966509103775\n",
      "\n",
      "episode 10, val func loss 0.18825429677963257\n",
      "\n",
      "episode 11, val func loss 0.20642906427383423\n",
      "\n",
      "episode 12, val func loss 0.19921700656414032\n",
      "\n",
      "episode 13, val func loss 0.18093115091323853\n",
      "\n",
      "episode 14, val func loss 0.19055189192295074\n",
      "\n",
      "episode 15, val func loss 0.19159388542175293\n",
      "\n",
      "episode 16, val func loss 0.19698703289031982\n",
      "\n",
      "Val func train loss in epoch 10:0.1888161413371563\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.15317505598068237\n",
      "\n",
      "episode 2, val func loss 0.15716426074504852\n",
      "\n",
      "episode 3, val func loss 0.1982143521308899\n",
      "\n",
      "episode 4, val func loss 0.18920749425888062\n",
      "\n",
      "episode 5, val func loss 0.20313887298107147\n",
      "\n",
      "episode 6, val func loss 0.17521360516548157\n",
      "\n",
      "episode 7, val func loss 0.18857578933238983\n",
      "\n",
      "episode 8, val func loss 0.19085580110549927\n",
      "\n",
      "episode 9, val func loss 0.19737227261066437\n",
      "\n",
      "episode 10, val func loss 0.17539310455322266\n",
      "\n",
      "episode 11, val func loss 0.20842266082763672\n",
      "\n",
      "episode 12, val func loss 0.21930798888206482\n",
      "\n",
      "episode 13, val func loss 0.18405310809612274\n",
      "\n",
      "episode 14, val func loss 0.18838033080101013\n",
      "\n",
      "episode 15, val func loss 0.20723596215248108\n",
      "\n",
      "episode 16, val func loss 0.17780832946300507\n",
      "\n",
      "Val func train loss in epoch 11:0.18834493681788445\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.21911369264125824\n",
      "\n",
      "episode 2, val func loss 0.17739003896713257\n",
      "\n",
      "episode 3, val func loss 0.18886442482471466\n",
      "\n",
      "episode 4, val func loss 0.20558492839336395\n",
      "\n",
      "episode 5, val func loss 0.19224853813648224\n",
      "\n",
      "episode 6, val func loss 0.1882437914609909\n",
      "\n",
      "episode 7, val func loss 0.20775152742862701\n",
      "\n",
      "episode 8, val func loss 0.18914353847503662\n",
      "\n",
      "episode 9, val func loss 0.1602870523929596\n",
      "\n",
      "episode 10, val func loss 0.1814713478088379\n",
      "\n",
      "episode 11, val func loss 0.1751067191362381\n",
      "\n",
      "episode 12, val func loss 0.20162427425384521\n",
      "\n",
      "episode 13, val func loss 0.19822846353054047\n",
      "\n",
      "episode 14, val func loss 0.1752159744501114\n",
      "\n",
      "episode 15, val func loss 0.15125538408756256\n",
      "\n",
      "episode 16, val func loss 0.19812284409999847\n",
      "\n",
      "Val func train loss in epoch 12:0.18810328375548124\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19803231954574585\n",
      "\n",
      "episode 2, val func loss 0.18129725754261017\n",
      "\n",
      "episode 3, val func loss 0.1887548714876175\n",
      "\n",
      "episode 4, val func loss 0.20864282548427582\n",
      "\n",
      "episode 5, val func loss 0.1602068543434143\n",
      "\n",
      "episode 6, val func loss 0.1991063803434372\n",
      "\n",
      "episode 7, val func loss 0.15558786690235138\n",
      "\n",
      "episode 8, val func loss 0.21927852928638458\n",
      "\n",
      "episode 9, val func loss 0.17638389766216278\n",
      "\n",
      "episode 10, val func loss 0.1970292627811432\n",
      "\n",
      "episode 11, val func loss 0.18842005729675293\n",
      "\n",
      "episode 12, val func loss 0.20874059200286865\n",
      "\n",
      "episode 13, val func loss 0.18129375576972961\n",
      "\n",
      "episode 14, val func loss 0.17511875927448273\n",
      "\n",
      "episode 15, val func loss 0.1878361999988556\n",
      "\n",
      "episode 16, val func loss 0.19054636359214783\n",
      "\n",
      "Val func train loss in epoch 13:0.18851723708212376\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1975059062242508\n",
      "\n",
      "episode 2, val func loss 0.15736834704875946\n",
      "\n",
      "episode 3, val func loss 0.19761089980602264\n",
      "\n",
      "episode 4, val func loss 0.18093734979629517\n",
      "\n",
      "episode 5, val func loss 0.2103135883808136\n",
      "\n",
      "episode 6, val func loss 0.21015392243862152\n",
      "\n",
      "episode 7, val func loss 0.18852068483829498\n",
      "\n",
      "episode 8, val func loss 0.18853133916854858\n",
      "\n",
      "episode 9, val func loss 0.17605134844779968\n",
      "\n",
      "episode 10, val func loss 0.1542666256427765\n",
      "\n",
      "episode 11, val func loss 0.1781896948814392\n",
      "\n",
      "episode 12, val func loss 0.17515477538108826\n",
      "\n",
      "episode 13, val func loss 0.18788766860961914\n",
      "\n",
      "episode 14, val func loss 0.19064462184906006\n",
      "\n",
      "episode 15, val func loss 0.21936170756816864\n",
      "\n",
      "episode 16, val func loss 0.19985829293727875\n",
      "\n",
      "Val func train loss in epoch 14:0.1882722983136773\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.1883898675441742\n",
      "\n",
      "episode 2, val func loss 0.20860655605793\n",
      "\n",
      "episode 3, val func loss 0.19957897067070007\n",
      "\n",
      "episode 4, val func loss 0.1976228654384613\n",
      "\n",
      "episode 5, val func loss 0.19147056341171265\n",
      "\n",
      "episode 6, val func loss 0.1553058922290802\n",
      "\n",
      "episode 7, val func loss 0.17773102223873138\n",
      "\n",
      "episode 8, val func loss 0.17523294687271118\n",
      "\n",
      "episode 9, val func loss 0.21925872564315796\n",
      "\n",
      "episode 10, val func loss 0.18130162358283997\n",
      "\n",
      "episode 11, val func loss 0.20803608000278473\n",
      "\n",
      "episode 12, val func loss 0.15845800936222076\n",
      "\n",
      "episode 13, val func loss 0.19731028378009796\n",
      "\n",
      "episode 14, val func loss 0.17516891658306122\n",
      "\n",
      "episode 15, val func loss 0.1885826140642166\n",
      "\n",
      "episode 16, val func loss 0.1879025101661682\n",
      "\n",
      "Val func train loss in epoch 15:0.18812234047800303\n",
      "***********************TIME WAS 5.006293475627899 min*****************************\n",
      "\n",
      "**********************ROUND 136 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.06978211551904678\n",
      "\n",
      "episode 2, policy loss -0.07670365273952484\n",
      "\n",
      "episode 3, policy loss -0.04919867962598801\n",
      "\n",
      "episode 4, policy loss -0.08528009802103043\n",
      "\n",
      "episode 5, policy loss -0.061308544129133224\n",
      "\n",
      "episode 6, policy loss -0.043130237609148026\n",
      "\n",
      "episode 7, policy loss -0.06920884549617767\n",
      "\n",
      "episode 8, policy loss -0.025321902707219124\n",
      "\n",
      "episode 9, policy loss -0.05725190043449402\n",
      "\n",
      "episode 10, policy loss -0.043153632432222366\n",
      "\n",
      "episode 11, policy loss -0.013958903960883617\n",
      "\n",
      "episode 12, policy loss -0.07743699848651886\n",
      "\n",
      "episode 13, policy loss 0.016614016145467758\n",
      "\n",
      "episode 14, policy loss -0.07294800877571106\n",
      "\n",
      "episode 15, policy loss -0.04170805588364601\n",
      "\n",
      "episode 16, policy loss -0.0637454017996788\n",
      "\n",
      "Policy train loss in epoch 0:-0.05209518509218469\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.042135097086429596\n",
      "\n",
      "episode 2, policy loss -0.042716510593891144\n",
      "\n",
      "episode 3, policy loss -0.08105795085430145\n",
      "\n",
      "episode 4, policy loss -0.08009261637926102\n",
      "\n",
      "episode 5, policy loss -0.06032651290297508\n",
      "\n",
      "episode 6, policy loss -0.0699247345328331\n",
      "\n",
      "episode 7, policy loss -0.07741396874189377\n",
      "\n",
      "episode 8, policy loss -0.05649353191256523\n",
      "\n",
      "episode 9, policy loss -0.09261854737997055\n",
      "\n",
      "episode 10, policy loss -0.07346489280462265\n",
      "\n",
      "episode 11, policy loss -0.04491320624947548\n",
      "\n",
      "episode 12, policy loss -0.024989694356918335\n",
      "\n",
      "episode 13, policy loss 0.016117176041007042\n",
      "\n",
      "episode 14, policy loss -0.05542723834514618\n",
      "\n",
      "episode 15, policy loss -0.06539195030927658\n",
      "\n",
      "episode 16, policy loss -0.016019096598029137\n",
      "\n",
      "Policy train loss in epoch 1:-0.05417927331291139\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.07044224441051483\n",
      "\n",
      "episode 2, policy loss -0.07443148642778397\n",
      "\n",
      "episode 3, policy loss 0.015685319900512695\n",
      "\n",
      "episode 4, policy loss -0.06295948475599289\n",
      "\n",
      "episode 5, policy loss -0.04533195123076439\n",
      "\n",
      "episode 6, policy loss -0.08190543204545975\n",
      "\n",
      "episode 7, policy loss -0.058209873735904694\n",
      "\n",
      "episode 8, policy loss -0.09111683815717697\n",
      "\n",
      "episode 9, policy loss -0.07771340012550354\n",
      "\n",
      "episode 10, policy loss -0.02583101950585842\n",
      "\n",
      "episode 11, policy loss -0.054804880172014236\n",
      "\n",
      "episode 12, policy loss -0.08458471298217773\n",
      "\n",
      "episode 13, policy loss -0.0660243108868599\n",
      "\n",
      "episode 14, policy loss -0.01593843661248684\n",
      "\n",
      "episode 15, policy loss -0.04344748705625534\n",
      "\n",
      "episode 16, policy loss -0.046130504459142685\n",
      "\n",
      "Policy train loss in epoch 2:-0.05519917141646147\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.055174194276332855\n",
      "\n",
      "episode 2, policy loss -0.04369992017745972\n",
      "\n",
      "episode 3, policy loss -0.04528682306408882\n",
      "\n",
      "episode 4, policy loss -0.07671348005533218\n",
      "\n",
      "episode 5, policy loss -0.08197125047445297\n",
      "\n",
      "episode 6, policy loss -0.09192059934139252\n",
      "\n",
      "episode 7, policy loss 0.014589769765734673\n",
      "\n",
      "episode 8, policy loss -0.06520126014947891\n",
      "\n",
      "episode 9, policy loss -0.07406297326087952\n",
      "\n",
      "episode 10, policy loss -0.05771549791097641\n",
      "\n",
      "episode 11, policy loss -0.015624359250068665\n",
      "\n",
      "episode 12, policy loss -0.06998063623905182\n",
      "\n",
      "episode 13, policy loss -0.08426304161548615\n",
      "\n",
      "episode 14, policy loss -0.045765794813632965\n",
      "\n",
      "episode 15, policy loss -0.024889623746275902\n",
      "\n",
      "episode 16, policy loss -0.06322736293077469\n",
      "\n",
      "Policy train loss in epoch 3:-0.05505669047124684\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1946609616279602\n",
      "\n",
      "episode 2, val func loss 0.20470847189426422\n",
      "\n",
      "episode 3, val func loss 0.20401689410209656\n",
      "\n",
      "episode 4, val func loss 0.1961277276277542\n",
      "\n",
      "episode 5, val func loss 0.19767819344997406\n",
      "\n",
      "episode 6, val func loss 0.20509754121303558\n",
      "\n",
      "episode 7, val func loss 0.19665251672267914\n",
      "\n",
      "episode 8, val func loss 0.19694872200489044\n",
      "\n",
      "episode 9, val func loss 0.1570313274860382\n",
      "\n",
      "episode 10, val func loss 0.19458505511283875\n",
      "\n",
      "episode 11, val func loss 0.18341359496116638\n",
      "\n",
      "episode 12, val func loss 0.18559370934963226\n",
      "\n",
      "episode 13, val func loss 0.17830412089824677\n",
      "\n",
      "episode 14, val func loss 0.1902320683002472\n",
      "\n",
      "episode 15, val func loss 0.1582004874944687\n",
      "\n",
      "episode 16, val func loss 0.19256511330604553\n",
      "\n",
      "Val func train loss in epoch 0:0.18973853159695864\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19465918838977814\n",
      "\n",
      "episode 2, val func loss 0.19782128930091858\n",
      "\n",
      "episode 3, val func loss 0.18305887281894684\n",
      "\n",
      "episode 4, val func loss 0.18504561483860016\n",
      "\n",
      "episode 5, val func loss 0.19607117772102356\n",
      "\n",
      "episode 6, val func loss 0.2048875242471695\n",
      "\n",
      "episode 7, val func loss 0.19608145952224731\n",
      "\n",
      "episode 8, val func loss 0.20327714085578918\n",
      "\n",
      "episode 9, val func loss 0.20165756344795227\n",
      "\n",
      "episode 10, val func loss 0.16064453125\n",
      "\n",
      "episode 11, val func loss 0.19371870160102844\n",
      "\n",
      "episode 12, val func loss 0.19655972719192505\n",
      "\n",
      "episode 13, val func loss 0.1895151138305664\n",
      "\n",
      "episode 14, val func loss 0.19705802202224731\n",
      "\n",
      "episode 15, val func loss 0.1788235604763031\n",
      "\n",
      "episode 16, val func loss 0.15588563680648804\n",
      "\n",
      "Val func train loss in epoch 1:0.1896728202700615\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1777147501707077\n",
      "\n",
      "episode 2, val func loss 0.1534460186958313\n",
      "\n",
      "episode 3, val func loss 0.19264289736747742\n",
      "\n",
      "episode 4, val func loss 0.19888462126255035\n",
      "\n",
      "episode 5, val func loss 0.19259439408779144\n",
      "\n",
      "episode 6, val func loss 0.20517535507678986\n",
      "\n",
      "episode 7, val func loss 0.19443364441394806\n",
      "\n",
      "episode 8, val func loss 0.19640375673770905\n",
      "\n",
      "episode 9, val func loss 0.20462453365325928\n",
      "\n",
      "episode 10, val func loss 0.1945175975561142\n",
      "\n",
      "episode 11, val func loss 0.1857592612504959\n",
      "\n",
      "episode 12, val func loss 0.18333636224269867\n",
      "\n",
      "episode 13, val func loss 0.15946431457996368\n",
      "\n",
      "episode 14, val func loss 0.20197844505310059\n",
      "\n",
      "episode 15, val func loss 0.19672240316867828\n",
      "\n",
      "episode 16, val func loss 0.19753895699977875\n",
      "\n",
      "Val func train loss in epoch 2:0.1897023320198059\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18279698491096497\n",
      "\n",
      "episode 2, val func loss 0.20482109487056732\n",
      "\n",
      "episode 3, val func loss 0.158646821975708\n",
      "\n",
      "episode 4, val func loss 0.1970464438199997\n",
      "\n",
      "episode 5, val func loss 0.19495035707950592\n",
      "\n",
      "episode 6, val func loss 0.20322662591934204\n",
      "\n",
      "episode 7, val func loss 0.19785934686660767\n",
      "\n",
      "episode 8, val func loss 0.15352042019367218\n",
      "\n",
      "episode 9, val func loss 0.19735044240951538\n",
      "\n",
      "episode 10, val func loss 0.19553105533123016\n",
      "\n",
      "episode 11, val func loss 0.18488706648349762\n",
      "\n",
      "episode 12, val func loss 0.1773151308298111\n",
      "\n",
      "episode 13, val func loss 0.1948438584804535\n",
      "\n",
      "episode 14, val func loss 0.20260120928287506\n",
      "\n",
      "episode 15, val func loss 0.19020789861679077\n",
      "\n",
      "episode 16, val func loss 0.19336795806884766\n",
      "\n",
      "Val func train loss in epoch 3:0.18931079469621181\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19466815888881683\n",
      "\n",
      "episode 2, val func loss 0.18345408141613007\n",
      "\n",
      "episode 3, val func loss 0.196014866232872\n",
      "\n",
      "episode 4, val func loss 0.20217962563037872\n",
      "\n",
      "episode 5, val func loss 0.20491376519203186\n",
      "\n",
      "episode 6, val func loss 0.19661261141300201\n",
      "\n",
      "episode 7, val func loss 0.1586696356534958\n",
      "\n",
      "episode 8, val func loss 0.17711983621120453\n",
      "\n",
      "episode 9, val func loss 0.20343361794948578\n",
      "\n",
      "episode 10, val func loss 0.18495634198188782\n",
      "\n",
      "episode 11, val func loss 0.1977803260087967\n",
      "\n",
      "episode 12, val func loss 0.19271907210350037\n",
      "\n",
      "episode 13, val func loss 0.19801123440265656\n",
      "\n",
      "episode 14, val func loss 0.1954299956560135\n",
      "\n",
      "episode 15, val func loss 0.1544557362794876\n",
      "\n",
      "episode 16, val func loss 0.19001653790473938\n",
      "\n",
      "Val func train loss in epoch 4:0.18940221518278122\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.15460741519927979\n",
      "\n",
      "episode 2, val func loss 0.2022327035665512\n",
      "\n",
      "episode 3, val func loss 0.19467835128307343\n",
      "\n",
      "episode 4, val func loss 0.19679269194602966\n",
      "\n",
      "episode 5, val func loss 0.19012752175331116\n",
      "\n",
      "episode 6, val func loss 0.19663172960281372\n",
      "\n",
      "episode 7, val func loss 0.19717232882976532\n",
      "\n",
      "episode 8, val func loss 0.18647544085979462\n",
      "\n",
      "episode 9, val func loss 0.20563724637031555\n",
      "\n",
      "episode 10, val func loss 0.19578944146633148\n",
      "\n",
      "episode 11, val func loss 0.17783524096012115\n",
      "\n",
      "episode 12, val func loss 0.18226727843284607\n",
      "\n",
      "episode 13, val func loss 0.15777863562107086\n",
      "\n",
      "episode 14, val func loss 0.20415638387203217\n",
      "\n",
      "episode 15, val func loss 0.1965823471546173\n",
      "\n",
      "episode 16, val func loss 0.19337211549282074\n",
      "\n",
      "Val func train loss in epoch 5:0.1895085545256734\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.15739703178405762\n",
      "\n",
      "episode 2, val func loss 0.1930357664823532\n",
      "\n",
      "episode 3, val func loss 0.1913701742887497\n",
      "\n",
      "episode 4, val func loss 0.19461359083652496\n",
      "\n",
      "episode 5, val func loss 0.1850409060716629\n",
      "\n",
      "episode 6, val func loss 0.1776413768529892\n",
      "\n",
      "episode 7, val func loss 0.20311059057712555\n",
      "\n",
      "episode 8, val func loss 0.19698591530323029\n",
      "\n",
      "episode 9, val func loss 0.19539880752563477\n",
      "\n",
      "episode 10, val func loss 0.15610891580581665\n",
      "\n",
      "episode 11, val func loss 0.2048719972372055\n",
      "\n",
      "episode 12, val func loss 0.20216365158557892\n",
      "\n",
      "episode 13, val func loss 0.19464822113513947\n",
      "\n",
      "episode 14, val func loss 0.19674716889858246\n",
      "\n",
      "episode 15, val func loss 0.1972828209400177\n",
      "\n",
      "episode 16, val func loss 0.1829848736524582\n",
      "\n",
      "Val func train loss in epoch 6:0.18933761306107044\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1956157088279724\n",
      "\n",
      "episode 2, val func loss 0.2017204761505127\n",
      "\n",
      "episode 3, val func loss 0.1548168808221817\n",
      "\n",
      "episode 4, val func loss 0.19690431654453278\n",
      "\n",
      "episode 5, val func loss 0.20270048081874847\n",
      "\n",
      "episode 6, val func loss 0.19272905588150024\n",
      "\n",
      "episode 7, val func loss 0.1582893580198288\n",
      "\n",
      "episode 8, val func loss 0.18481221795082092\n",
      "\n",
      "episode 9, val func loss 0.19557808339595795\n",
      "\n",
      "episode 10, val func loss 0.19707535207271576\n",
      "\n",
      "episode 11, val func loss 0.17739063501358032\n",
      "\n",
      "episode 12, val func loss 0.1826210916042328\n",
      "\n",
      "episode 13, val func loss 0.19104166328907013\n",
      "\n",
      "episode 14, val func loss 0.19777895510196686\n",
      "\n",
      "episode 15, val func loss 0.1946861296892166\n",
      "\n",
      "episode 16, val func loss 0.2052491307258606\n",
      "\n",
      "Val func train loss in epoch 7:0.1893130959942937\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.20517374575138092\n",
      "\n",
      "episode 2, val func loss 0.1951955407857895\n",
      "\n",
      "episode 3, val func loss 0.19438022375106812\n",
      "\n",
      "episode 4, val func loss 0.1899651437997818\n",
      "\n",
      "episode 5, val func loss 0.19311930239200592\n",
      "\n",
      "episode 6, val func loss 0.17830878496170044\n",
      "\n",
      "episode 7, val func loss 0.15895771980285645\n",
      "\n",
      "episode 8, val func loss 0.19503767788410187\n",
      "\n",
      "episode 9, val func loss 0.18488478660583496\n",
      "\n",
      "episode 10, val func loss 0.1983690857887268\n",
      "\n",
      "episode 11, val func loss 0.2042747586965561\n",
      "\n",
      "episode 12, val func loss 0.1976454257965088\n",
      "\n",
      "episode 13, val func loss 0.15256349742412567\n",
      "\n",
      "episode 14, val func loss 0.2039029747247696\n",
      "\n",
      "episode 15, val func loss 0.18265904486179352\n",
      "\n",
      "episode 16, val func loss 0.19775988161563873\n",
      "\n",
      "Val func train loss in epoch 8:0.18951234966516495\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18268971145153046\n",
      "\n",
      "episode 2, val func loss 0.1592293381690979\n",
      "\n",
      "episode 3, val func loss 0.1930341124534607\n",
      "\n",
      "episode 4, val func loss 0.15480215847492218\n",
      "\n",
      "episode 5, val func loss 0.19506621360778809\n",
      "\n",
      "episode 6, val func loss 0.17721356451511383\n",
      "\n",
      "episode 7, val func loss 0.1845606118440628\n",
      "\n",
      "episode 8, val func loss 0.19748984277248383\n",
      "\n",
      "episode 9, val func loss 0.19465376436710358\n",
      "\n",
      "episode 10, val func loss 0.20464855432510376\n",
      "\n",
      "episode 11, val func loss 0.1981317698955536\n",
      "\n",
      "episode 12, val func loss 0.19856344163417816\n",
      "\n",
      "episode 13, val func loss 0.19507883489131927\n",
      "\n",
      "episode 14, val func loss 0.2028106451034546\n",
      "\n",
      "episode 15, val func loss 0.20176950097084045\n",
      "\n",
      "episode 16, val func loss 0.1898011565208435\n",
      "\n",
      "Val func train loss in epoch 9:0.18934645131230354\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19736994802951813\n",
      "\n",
      "episode 2, val func loss 0.18088187277317047\n",
      "\n",
      "episode 3, val func loss 0.16321910917758942\n",
      "\n",
      "episode 4, val func loss 0.2064490169286728\n",
      "\n",
      "episode 5, val func loss 0.15687568485736847\n",
      "\n",
      "episode 6, val func loss 0.18532736599445343\n",
      "\n",
      "episode 7, val func loss 0.1826375275850296\n",
      "\n",
      "episode 8, val func loss 0.2054448127746582\n",
      "\n",
      "episode 9, val func loss 0.20499221980571747\n",
      "\n",
      "episode 10, val func loss 0.19672895967960358\n",
      "\n",
      "episode 11, val func loss 0.19449254870414734\n",
      "\n",
      "episode 12, val func loss 0.19298969209194183\n",
      "\n",
      "episode 13, val func loss 0.1910935789346695\n",
      "\n",
      "episode 14, val func loss 0.1948847770690918\n",
      "\n",
      "episode 15, val func loss 0.1968545764684677\n",
      "\n",
      "episode 16, val func loss 0.19650401175022125\n",
      "\n",
      "Val func train loss in epoch 10:0.19042160641402006\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16217461228370667\n",
      "\n",
      "episode 2, val func loss 0.1956968903541565\n",
      "\n",
      "episode 3, val func loss 0.19628655910491943\n",
      "\n",
      "episode 4, val func loss 0.18259650468826294\n",
      "\n",
      "episode 5, val func loss 0.20346783101558685\n",
      "\n",
      "episode 6, val func loss 0.1774163544178009\n",
      "\n",
      "episode 7, val func loss 0.19490762054920197\n",
      "\n",
      "episode 8, val func loss 0.1927649974822998\n",
      "\n",
      "episode 9, val func loss 0.20488043129444122\n",
      "\n",
      "episode 10, val func loss 0.18503369390964508\n",
      "\n",
      "episode 11, val func loss 0.20295289158821106\n",
      "\n",
      "episode 12, val func loss 0.19700050354003906\n",
      "\n",
      "episode 13, val func loss 0.15425929427146912\n",
      "\n",
      "episode 14, val func loss 0.1900801658630371\n",
      "\n",
      "episode 15, val func loss 0.19728362560272217\n",
      "\n",
      "episode 16, val func loss 0.1968432515859604\n",
      "\n",
      "Val func train loss in epoch 11:0.18960282672196627\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.20165559649467468\n",
      "\n",
      "episode 2, val func loss 0.20247036218643188\n",
      "\n",
      "episode 3, val func loss 0.15627597272396088\n",
      "\n",
      "episode 4, val func loss 0.20517697930335999\n",
      "\n",
      "episode 5, val func loss 0.1832817792892456\n",
      "\n",
      "episode 6, val func loss 0.18987633287906647\n",
      "\n",
      "episode 7, val func loss 0.19671444594860077\n",
      "\n",
      "episode 8, val func loss 0.18498854339122772\n",
      "\n",
      "episode 9, val func loss 0.1948312371969223\n",
      "\n",
      "episode 10, val func loss 0.15838856995105743\n",
      "\n",
      "episode 11, val func loss 0.1974206566810608\n",
      "\n",
      "episode 12, val func loss 0.17715877294540405\n",
      "\n",
      "episode 13, val func loss 0.19488202035427094\n",
      "\n",
      "episode 14, val func loss 0.19570794701576233\n",
      "\n",
      "episode 15, val func loss 0.19824111461639404\n",
      "\n",
      "episode 16, val func loss 0.19294197857379913\n",
      "\n",
      "Val func train loss in epoch 12:0.18937576934695244\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19473445415496826\n",
      "\n",
      "episode 2, val func loss 0.19472889602184296\n",
      "\n",
      "episode 3, val func loss 0.19042754173278809\n",
      "\n",
      "episode 4, val func loss 0.1928020566701889\n",
      "\n",
      "episode 5, val func loss 0.19534285366535187\n",
      "\n",
      "episode 6, val func loss 0.202539324760437\n",
      "\n",
      "episode 7, val func loss 0.18317227065563202\n",
      "\n",
      "episode 8, val func loss 0.20109330117702484\n",
      "\n",
      "episode 9, val func loss 0.19674372673034668\n",
      "\n",
      "episode 10, val func loss 0.17912472784519196\n",
      "\n",
      "episode 11, val func loss 0.185987189412117\n",
      "\n",
      "episode 12, val func loss 0.15606500208377838\n",
      "\n",
      "episode 13, val func loss 0.19662168622016907\n",
      "\n",
      "episode 14, val func loss 0.1976861208677292\n",
      "\n",
      "episode 15, val func loss 0.20454616844654083\n",
      "\n",
      "episode 16, val func loss 0.15753720700740814\n",
      "\n",
      "Val func train loss in epoch 13:0.1893220329657197\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19172672927379608\n",
      "\n",
      "episode 2, val func loss 0.15714651346206665\n",
      "\n",
      "episode 3, val func loss 0.20541523396968842\n",
      "\n",
      "episode 4, val func loss 0.19449885189533234\n",
      "\n",
      "episode 5, val func loss 0.19739127159118652\n",
      "\n",
      "episode 6, val func loss 0.20347091555595398\n",
      "\n",
      "episode 7, val func loss 0.19774337112903595\n",
      "\n",
      "episode 8, val func loss 0.194446861743927\n",
      "\n",
      "episode 9, val func loss 0.1967865377664566\n",
      "\n",
      "episode 10, val func loss 0.19549183547496796\n",
      "\n",
      "episode 11, val func loss 0.19425620138645172\n",
      "\n",
      "episode 12, val func loss 0.18426427245140076\n",
      "\n",
      "episode 13, val func loss 0.15787632763385773\n",
      "\n",
      "episode 14, val func loss 0.1785719394683838\n",
      "\n",
      "episode 15, val func loss 0.18515299260616302\n",
      "\n",
      "episode 16, val func loss 0.20454935729503632\n",
      "\n",
      "Val func train loss in epoch 14:0.18992432579398155\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.15186306834220886\n",
      "\n",
      "episode 2, val func loss 0.19841812551021576\n",
      "\n",
      "episode 3, val func loss 0.20906680822372437\n",
      "\n",
      "episode 4, val func loss 0.1836840808391571\n",
      "\n",
      "episode 5, val func loss 0.1967570036649704\n",
      "\n",
      "episode 6, val func loss 0.1944686472415924\n",
      "\n",
      "episode 7, val func loss 0.18511977791786194\n",
      "\n",
      "episode 8, val func loss 0.20473387837409973\n",
      "\n",
      "episode 9, val func loss 0.20249027013778687\n",
      "\n",
      "episode 10, val func loss 0.193240687251091\n",
      "\n",
      "episode 11, val func loss 0.18997444212436676\n",
      "\n",
      "episode 12, val func loss 0.17838625609874725\n",
      "\n",
      "episode 13, val func loss 0.19674772024154663\n",
      "\n",
      "episode 14, val func loss 0.1596938669681549\n",
      "\n",
      "episode 15, val func loss 0.19754339754581451\n",
      "\n",
      "episode 16, val func loss 0.1966925710439682\n",
      "\n",
      "Val func train loss in epoch 15:0.18993003759533167\n",
      "***********************TIME WAS 5.007784525553386 min*****************************\n",
      "\n",
      "**********************ROUND 137 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.055503666400909424\n",
      "\n",
      "episode 2, policy loss -0.0155995087698102\n",
      "\n",
      "episode 3, policy loss -0.06792624294757843\n",
      "\n",
      "episode 4, policy loss 0.01164827961474657\n",
      "\n",
      "episode 5, policy loss 0.038487061858177185\n",
      "\n",
      "episode 6, policy loss -0.08401868492364883\n",
      "\n",
      "episode 7, policy loss -0.020044073462486267\n",
      "\n",
      "episode 8, policy loss -0.046500615775585175\n",
      "\n",
      "episode 9, policy loss 0.010049107484519482\n",
      "\n",
      "episode 10, policy loss -0.09507855772972107\n",
      "\n",
      "episode 11, policy loss 0.0019521975191310048\n",
      "\n",
      "episode 12, policy loss -0.050549887120723724\n",
      "\n",
      "episode 13, policy loss -0.08260749280452728\n",
      "\n",
      "episode 14, policy loss -0.06762319058179855\n",
      "\n",
      "episode 15, policy loss -0.005871995352208614\n",
      "\n",
      "episode 16, policy loss -0.010259293019771576\n",
      "\n",
      "Policy train loss in epoch 0:-0.03371541015076218\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.08835259824991226\n",
      "\n",
      "episode 2, policy loss 0.008266394026577473\n",
      "\n",
      "episode 3, policy loss -0.04816561937332153\n",
      "\n",
      "episode 4, policy loss -0.021801454946398735\n",
      "\n",
      "episode 5, policy loss -0.07582975178956985\n",
      "\n",
      "episode 6, policy loss -0.005406436510384083\n",
      "\n",
      "episode 7, policy loss -0.09492971003055573\n",
      "\n",
      "episode 8, policy loss -0.010880484245717525\n",
      "\n",
      "episode 9, policy loss 0.036193352192640305\n",
      "\n",
      "episode 10, policy loss 0.01012342981994152\n",
      "\n",
      "episode 11, policy loss -0.06991375237703323\n",
      "\n",
      "episode 12, policy loss -0.02306821383535862\n",
      "\n",
      "episode 13, policy loss -0.084805428981781\n",
      "\n",
      "episode 14, policy loss -0.048257406800985336\n",
      "\n",
      "episode 15, policy loss -0.06173669919371605\n",
      "\n",
      "episode 16, policy loss 0.0006521198083646595\n",
      "\n",
      "Policy train loss in epoch 1:-0.036119516280450625\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.05051713436841965\n",
      "\n",
      "episode 2, policy loss 0.033813800662755966\n",
      "\n",
      "episode 3, policy loss -0.0702211856842041\n",
      "\n",
      "episode 4, policy loss -0.09385254979133606\n",
      "\n",
      "episode 5, policy loss 0.0007049539708532393\n",
      "\n",
      "episode 6, policy loss -0.07805094122886658\n",
      "\n",
      "episode 7, policy loss 0.005509635433554649\n",
      "\n",
      "episode 8, policy loss -0.08986881375312805\n",
      "\n",
      "episode 9, policy loss -0.024942804127931595\n",
      "\n",
      "episode 10, policy loss 0.010001391172409058\n",
      "\n",
      "episode 11, policy loss -0.08379293978214264\n",
      "\n",
      "episode 12, policy loss -0.02243509702384472\n",
      "\n",
      "episode 13, policy loss -0.04919368773698807\n",
      "\n",
      "episode 14, policy loss -0.06013387814164162\n",
      "\n",
      "episode 15, policy loss -0.011628856882452965\n",
      "\n",
      "episode 16, policy loss -0.006712622940540314\n",
      "\n",
      "Policy train loss in epoch 2:-0.036957545638870215\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.06069125235080719\n",
      "\n",
      "episode 2, policy loss -0.05109178647398949\n",
      "\n",
      "episode 3, policy loss -0.02444165013730526\n",
      "\n",
      "episode 4, policy loss 0.005936088971793652\n",
      "\n",
      "episode 5, policy loss -0.022661780938506126\n",
      "\n",
      "episode 6, policy loss -0.07787282764911652\n",
      "\n",
      "episode 7, policy loss -0.09479736536741257\n",
      "\n",
      "episode 8, policy loss 0.03423268347978592\n",
      "\n",
      "episode 9, policy loss -0.06966783851385117\n",
      "\n",
      "episode 10, policy loss 0.001308778184466064\n",
      "\n",
      "episode 11, policy loss -0.04851839691400528\n",
      "\n",
      "episode 12, policy loss -0.0841076448559761\n",
      "\n",
      "episode 13, policy loss -0.007187856826931238\n",
      "\n",
      "episode 14, policy loss 0.009911632165312767\n",
      "\n",
      "episode 15, policy loss -0.09080272912979126\n",
      "\n",
      "episode 16, policy loss -0.011294925585389137\n",
      "\n",
      "Policy train loss in epoch 3:-0.03698417949635768\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.17637571692466736\n",
      "\n",
      "episode 2, val func loss 0.16792310774326324\n",
      "\n",
      "episode 3, val func loss 0.22620800137519836\n",
      "\n",
      "episode 4, val func loss 0.18402810394763947\n",
      "\n",
      "episode 5, val func loss 0.17890337109565735\n",
      "\n",
      "episode 6, val func loss 0.2122046947479248\n",
      "\n",
      "episode 7, val func loss 0.223520427942276\n",
      "\n",
      "episode 8, val func loss 0.18374304473400116\n",
      "\n",
      "episode 9, val func loss 0.1882215440273285\n",
      "\n",
      "episode 10, val func loss 0.18387654423713684\n",
      "\n",
      "episode 11, val func loss 0.2204694002866745\n",
      "\n",
      "episode 12, val func loss 0.17620737850666046\n",
      "\n",
      "episode 13, val func loss 0.2155311107635498\n",
      "\n",
      "episode 14, val func loss 0.16593722999095917\n",
      "\n",
      "episode 15, val func loss 0.1467878669500351\n",
      "\n",
      "episode 16, val func loss 0.1996009349822998\n",
      "\n",
      "Val func train loss in epoch 0:0.1905961548909545\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17717576026916504\n",
      "\n",
      "episode 2, val func loss 0.22666221857070923\n",
      "\n",
      "episode 3, val func loss 0.16206878423690796\n",
      "\n",
      "episode 4, val func loss 0.18447868525981903\n",
      "\n",
      "episode 5, val func loss 0.2235819399356842\n",
      "\n",
      "episode 6, val func loss 0.21632744371891022\n",
      "\n",
      "episode 7, val func loss 0.17318221926689148\n",
      "\n",
      "episode 8, val func loss 0.16878542304039001\n",
      "\n",
      "episode 9, val func loss 0.1832360029220581\n",
      "\n",
      "episode 10, val func loss 0.17938309907913208\n",
      "\n",
      "episode 11, val func loss 0.21118322014808655\n",
      "\n",
      "episode 12, val func loss 0.22519469261169434\n",
      "\n",
      "episode 13, val func loss 0.18443942070007324\n",
      "\n",
      "episode 14, val func loss 0.19874031841754913\n",
      "\n",
      "episode 15, val func loss 0.18862728774547577\n",
      "\n",
      "episode 16, val func loss 0.14664386212825775\n",
      "\n",
      "Val func train loss in epoch 1:0.19060689862817526\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1766125112771988\n",
      "\n",
      "episode 2, val func loss 0.22478140890598297\n",
      "\n",
      "episode 3, val func loss 0.18326137959957123\n",
      "\n",
      "episode 4, val func loss 0.14601266384124756\n",
      "\n",
      "episode 5, val func loss 0.2224230170249939\n",
      "\n",
      "episode 6, val func loss 0.16323323547840118\n",
      "\n",
      "episode 7, val func loss 0.21151532232761383\n",
      "\n",
      "episode 8, val func loss 0.22411060333251953\n",
      "\n",
      "episode 9, val func loss 0.16780021786689758\n",
      "\n",
      "episode 10, val func loss 0.18418273329734802\n",
      "\n",
      "episode 11, val func loss 0.18862384557724\n",
      "\n",
      "episode 12, val func loss 0.17280112206935883\n",
      "\n",
      "episode 13, val func loss 0.17924417555332184\n",
      "\n",
      "episode 14, val func loss 0.21654640138149261\n",
      "\n",
      "episode 15, val func loss 0.19950225949287415\n",
      "\n",
      "episode 16, val func loss 0.1839095652103424\n",
      "\n",
      "Val func train loss in epoch 2:0.19028502888977528\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.1831100583076477\n",
      "\n",
      "episode 2, val func loss 0.18386495113372803\n",
      "\n",
      "episode 3, val func loss 0.18434259295463562\n",
      "\n",
      "episode 4, val func loss 0.1675768792629242\n",
      "\n",
      "episode 5, val func loss 0.1993006467819214\n",
      "\n",
      "episode 6, val func loss 0.22563010454177856\n",
      "\n",
      "episode 7, val func loss 0.21614736318588257\n",
      "\n",
      "episode 8, val func loss 0.22183747589588165\n",
      "\n",
      "episode 9, val func loss 0.1885291039943695\n",
      "\n",
      "episode 10, val func loss 0.2089177817106247\n",
      "\n",
      "episode 11, val func loss 0.18154478073120117\n",
      "\n",
      "episode 12, val func loss 0.17746484279632568\n",
      "\n",
      "episode 13, val func loss 0.1500307023525238\n",
      "\n",
      "episode 14, val func loss 0.22202621400356293\n",
      "\n",
      "episode 15, val func loss 0.16570645570755005\n",
      "\n",
      "episode 16, val func loss 0.17431168258190155\n",
      "\n",
      "Val func train loss in epoch 3:0.1906463522464037\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17650899291038513\n",
      "\n",
      "episode 2, val func loss 0.18304555118083954\n",
      "\n",
      "episode 3, val func loss 0.22697071731090546\n",
      "\n",
      "episode 4, val func loss 0.1783439666032791\n",
      "\n",
      "episode 5, val func loss 0.18951043486595154\n",
      "\n",
      "episode 6, val func loss 0.20052416622638702\n",
      "\n",
      "episode 7, val func loss 0.1662903130054474\n",
      "\n",
      "episode 8, val func loss 0.22432135045528412\n",
      "\n",
      "episode 9, val func loss 0.21312950551509857\n",
      "\n",
      "episode 10, val func loss 0.1626911163330078\n",
      "\n",
      "episode 11, val func loss 0.2163480669260025\n",
      "\n",
      "episode 12, val func loss 0.18452848494052887\n",
      "\n",
      "episode 13, val func loss 0.1735112965106964\n",
      "\n",
      "episode 14, val func loss 0.22252382338047028\n",
      "\n",
      "episode 15, val func loss 0.14690732955932617\n",
      "\n",
      "episode 16, val func loss 0.18368162214756012\n",
      "\n",
      "Val func train loss in epoch 4:0.19055229611694813\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1836051344871521\n",
      "\n",
      "episode 2, val func loss 0.14608219265937805\n",
      "\n",
      "episode 3, val func loss 0.21071046590805054\n",
      "\n",
      "episode 4, val func loss 0.18303392827510834\n",
      "\n",
      "episode 5, val func loss 0.22239747643470764\n",
      "\n",
      "episode 6, val func loss 0.17283575236797333\n",
      "\n",
      "episode 7, val func loss 0.16328032314777374\n",
      "\n",
      "episode 8, val func loss 0.17870625853538513\n",
      "\n",
      "episode 9, val func loss 0.1667039692401886\n",
      "\n",
      "episode 10, val func loss 0.17696335911750793\n",
      "\n",
      "episode 11, val func loss 0.22605657577514648\n",
      "\n",
      "episode 12, val func loss 0.21777236461639404\n",
      "\n",
      "episode 13, val func loss 0.18412818014621735\n",
      "\n",
      "episode 14, val func loss 0.18918216228485107\n",
      "\n",
      "episode 15, val func loss 0.1998002827167511\n",
      "\n",
      "episode 16, val func loss 0.22558249533176422\n",
      "\n",
      "Val func train loss in epoch 5:0.19042755756527185\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17963500320911407\n",
      "\n",
      "episode 2, val func loss 0.2240869700908661\n",
      "\n",
      "episode 3, val func loss 0.22206293046474457\n",
      "\n",
      "episode 4, val func loss 0.1886686533689499\n",
      "\n",
      "episode 5, val func loss 0.17765431106090546\n",
      "\n",
      "episode 6, val func loss 0.15159818530082703\n",
      "\n",
      "episode 7, val func loss 0.20821577310562134\n",
      "\n",
      "episode 8, val func loss 0.18527118861675262\n",
      "\n",
      "episode 9, val func loss 0.21585501730442047\n",
      "\n",
      "episode 10, val func loss 0.1753229945898056\n",
      "\n",
      "episode 11, val func loss 0.16469265520572662\n",
      "\n",
      "episode 12, val func loss 0.19914764165878296\n",
      "\n",
      "episode 13, val func loss 0.223101407289505\n",
      "\n",
      "episode 14, val func loss 0.16668018698692322\n",
      "\n",
      "episode 15, val func loss 0.18452188372612\n",
      "\n",
      "episode 16, val func loss 0.18392007052898407\n",
      "\n",
      "Val func train loss in epoch 6:0.19065217953175306\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.2005968540906906\n",
      "\n",
      "episode 2, val func loss 0.17182935774326324\n",
      "\n",
      "episode 3, val func loss 0.2273421585559845\n",
      "\n",
      "episode 4, val func loss 0.1769000142812729\n",
      "\n",
      "episode 5, val func loss 0.14438746869564056\n",
      "\n",
      "episode 6, val func loss 0.1830553561449051\n",
      "\n",
      "episode 7, val func loss 0.1842668056488037\n",
      "\n",
      "episode 8, val func loss 0.18855565786361694\n",
      "\n",
      "episode 9, val func loss 0.16734255850315094\n",
      "\n",
      "episode 10, val func loss 0.2165203094482422\n",
      "\n",
      "episode 11, val func loss 0.21190881729125977\n",
      "\n",
      "episode 12, val func loss 0.16303446888923645\n",
      "\n",
      "episode 13, val func loss 0.1836932897567749\n",
      "\n",
      "episode 14, val func loss 0.22340865433216095\n",
      "\n",
      "episode 15, val func loss 0.17945314943790436\n",
      "\n",
      "episode 16, val func loss 0.22167405486106873\n",
      "\n",
      "Val func train loss in epoch 7:0.1902480609714985\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.21580038964748383\n",
      "\n",
      "episode 2, val func loss 0.16476263105869293\n",
      "\n",
      "episode 3, val func loss 0.2212117314338684\n",
      "\n",
      "episode 4, val func loss 0.20920436084270477\n",
      "\n",
      "episode 5, val func loss 0.17527569830417633\n",
      "\n",
      "episode 6, val func loss 0.19854702055454254\n",
      "\n",
      "episode 7, val func loss 0.22193141281604767\n",
      "\n",
      "episode 8, val func loss 0.18119694292545319\n",
      "\n",
      "episode 9, val func loss 0.1842249184846878\n",
      "\n",
      "episode 10, val func loss 0.1850837916135788\n",
      "\n",
      "episode 11, val func loss 0.2242577224969864\n",
      "\n",
      "episode 12, val func loss 0.17644061148166656\n",
      "\n",
      "episode 13, val func loss 0.16846802830696106\n",
      "\n",
      "episode 14, val func loss 0.1450522541999817\n",
      "\n",
      "episode 15, val func loss 0.1841495782136917\n",
      "\n",
      "episode 16, val func loss 0.18947924673557281\n",
      "\n",
      "Val func train loss in epoch 8:0.19031789619475603\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.21451807022094727\n",
      "\n",
      "episode 2, val func loss 0.14300161600112915\n",
      "\n",
      "episode 3, val func loss 0.22791072726249695\n",
      "\n",
      "episode 4, val func loss 0.2241281419992447\n",
      "\n",
      "episode 5, val func loss 0.21670356392860413\n",
      "\n",
      "episode 6, val func loss 0.16738441586494446\n",
      "\n",
      "episode 7, val func loss 0.1988113522529602\n",
      "\n",
      "episode 8, val func loss 0.17967908084392548\n",
      "\n",
      "episode 9, val func loss 0.18817757070064545\n",
      "\n",
      "episode 10, val func loss 0.1765177994966507\n",
      "\n",
      "episode 11, val func loss 0.18356315791606903\n",
      "\n",
      "episode 12, val func loss 0.22276756167411804\n",
      "\n",
      "episode 13, val func loss 0.18499140441417694\n",
      "\n",
      "episode 14, val func loss 0.1837325394153595\n",
      "\n",
      "episode 15, val func loss 0.16452530026435852\n",
      "\n",
      "episode 16, val func loss 0.17333605885505676\n",
      "\n",
      "Val func train loss in epoch 9:0.19060927256941795\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.22420161962509155\n",
      "\n",
      "episode 2, val func loss 0.178724005818367\n",
      "\n",
      "episode 3, val func loss 0.18387548625469208\n",
      "\n",
      "episode 4, val func loss 0.18298983573913574\n",
      "\n",
      "episode 5, val func loss 0.142985537648201\n",
      "\n",
      "episode 6, val func loss 0.2154647260904312\n",
      "\n",
      "episode 7, val func loss 0.18980295956134796\n",
      "\n",
      "episode 8, val func loss 0.17692714929580688\n",
      "\n",
      "episode 9, val func loss 0.16687102615833282\n",
      "\n",
      "episode 10, val func loss 0.16268999874591827\n",
      "\n",
      "episode 11, val func loss 0.21657806634902954\n",
      "\n",
      "episode 12, val func loss 0.2258749008178711\n",
      "\n",
      "episode 13, val func loss 0.22234056890010834\n",
      "\n",
      "episode 14, val func loss 0.1986585259437561\n",
      "\n",
      "episode 15, val func loss 0.17434300482273102\n",
      "\n",
      "episode 16, val func loss 0.18373636901378632\n",
      "\n",
      "Val func train loss in epoch 10:0.19037898629903793\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.21570582687854767\n",
      "\n",
      "episode 2, val func loss 0.17512379586696625\n",
      "\n",
      "episode 3, val func loss 0.17054860293865204\n",
      "\n",
      "episode 4, val func loss 0.18375778198242188\n",
      "\n",
      "episode 5, val func loss 0.1844065934419632\n",
      "\n",
      "episode 6, val func loss 0.22723481059074402\n",
      "\n",
      "episode 7, val func loss 0.22371019423007965\n",
      "\n",
      "episode 8, val func loss 0.18380986154079437\n",
      "\n",
      "episode 9, val func loss 0.1790355145931244\n",
      "\n",
      "episode 10, val func loss 0.1452292799949646\n",
      "\n",
      "episode 11, val func loss 0.22380845248699188\n",
      "\n",
      "episode 12, val func loss 0.1887262463569641\n",
      "\n",
      "episode 13, val func loss 0.19915249943733215\n",
      "\n",
      "episode 14, val func loss 0.2108704149723053\n",
      "\n",
      "episode 15, val func loss 0.17649947106838226\n",
      "\n",
      "episode 16, val func loss 0.1644444763660431\n",
      "\n",
      "Val func train loss in epoch 11:0.1907539889216423\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18500974774360657\n",
      "\n",
      "episode 2, val func loss 0.16879980266094208\n",
      "\n",
      "episode 3, val func loss 0.18368899822235107\n",
      "\n",
      "episode 4, val func loss 0.16313950717449188\n",
      "\n",
      "episode 5, val func loss 0.1435157060623169\n",
      "\n",
      "episode 6, val func loss 0.21572871506214142\n",
      "\n",
      "episode 7, val func loss 0.17157262563705444\n",
      "\n",
      "episode 8, val func loss 0.18992963433265686\n",
      "\n",
      "episode 9, val func loss 0.18298323452472687\n",
      "\n",
      "episode 10, val func loss 0.22572262585163116\n",
      "\n",
      "episode 11, val func loss 0.19986484944820404\n",
      "\n",
      "episode 12, val func loss 0.1790708750486374\n",
      "\n",
      "episode 13, val func loss 0.22209976613521576\n",
      "\n",
      "episode 14, val func loss 0.17653386294841766\n",
      "\n",
      "episode 15, val func loss 0.2155108004808426\n",
      "\n",
      "episode 16, val func loss 0.22355781495571136\n",
      "\n",
      "Val func train loss in epoch 12:0.19042053539305925\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18871340155601501\n",
      "\n",
      "episode 2, val func loss 0.16693469882011414\n",
      "\n",
      "episode 3, val func loss 0.18491405248641968\n",
      "\n",
      "episode 4, val func loss 0.2221875786781311\n",
      "\n",
      "episode 5, val func loss 0.17114205658435822\n",
      "\n",
      "episode 6, val func loss 0.18082308769226074\n",
      "\n",
      "episode 7, val func loss 0.22476136684417725\n",
      "\n",
      "episode 8, val func loss 0.21621352434158325\n",
      "\n",
      "episode 9, val func loss 0.21080365777015686\n",
      "\n",
      "episode 10, val func loss 0.17321622371673584\n",
      "\n",
      "episode 11, val func loss 0.17660647630691528\n",
      "\n",
      "episode 12, val func loss 0.19923311471939087\n",
      "\n",
      "episode 13, val func loss 0.22191987931728363\n",
      "\n",
      "episode 14, val func loss 0.18358945846557617\n",
      "\n",
      "episode 15, val func loss 0.18467745184898376\n",
      "\n",
      "episode 16, val func loss 0.14651034772396088\n",
      "\n",
      "Val func train loss in epoch 13:0.19076539855450392\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.22330091893672943\n",
      "\n",
      "episode 2, val func loss 0.22178135812282562\n",
      "\n",
      "episode 3, val func loss 0.215730220079422\n",
      "\n",
      "episode 4, val func loss 0.17368361353874207\n",
      "\n",
      "episode 5, val func loss 0.1798011213541031\n",
      "\n",
      "episode 6, val func loss 0.21052111685276031\n",
      "\n",
      "episode 7, val func loss 0.17656686902046204\n",
      "\n",
      "episode 8, val func loss 0.22439809143543243\n",
      "\n",
      "episode 9, val func loss 0.18337886035442352\n",
      "\n",
      "episode 10, val func loss 0.18857388198375702\n",
      "\n",
      "episode 11, val func loss 0.1468016803264618\n",
      "\n",
      "episode 12, val func loss 0.19883213937282562\n",
      "\n",
      "episode 13, val func loss 0.16379868984222412\n",
      "\n",
      "episode 14, val func loss 0.18368297815322876\n",
      "\n",
      "episode 15, val func loss 0.16718991100788116\n",
      "\n",
      "episode 16, val func loss 0.18403734266757965\n",
      "\n",
      "Val func train loss in epoch 14:0.19012992456555367\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.22594094276428223\n",
      "\n",
      "episode 2, val func loss 0.22767043113708496\n",
      "\n",
      "episode 3, val func loss 0.19992613792419434\n",
      "\n",
      "episode 4, val func loss 0.17856687307357788\n",
      "\n",
      "episode 5, val func loss 0.1726679652929306\n",
      "\n",
      "episode 6, val func loss 0.16767793893814087\n",
      "\n",
      "episode 7, val func loss 0.1828886717557907\n",
      "\n",
      "episode 8, val func loss 0.21673206984996796\n",
      "\n",
      "episode 9, val func loss 0.1888970136642456\n",
      "\n",
      "episode 10, val func loss 0.18404069542884827\n",
      "\n",
      "episode 11, val func loss 0.14464695751667023\n",
      "\n",
      "episode 12, val func loss 0.1767430305480957\n",
      "\n",
      "episode 13, val func loss 0.16264669597148895\n",
      "\n",
      "episode 14, val func loss 0.2238035649061203\n",
      "\n",
      "episode 15, val func loss 0.18437081575393677\n",
      "\n",
      "episode 16, val func loss 0.2126191407442093\n",
      "\n",
      "Val func train loss in epoch 15:0.19061493407934904\n",
      "***********************TIME WAS 5.005867159366607 min*****************************\n",
      "\n",
      "**********************ROUND 138 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.01221768744289875\n",
      "\n",
      "episode 2, policy loss -0.0184091255068779\n",
      "\n",
      "episode 3, policy loss -0.043662142008543015\n",
      "\n",
      "episode 4, policy loss -0.023556038737297058\n",
      "\n",
      "episode 5, policy loss -0.06391255557537079\n",
      "\n",
      "episode 6, policy loss -0.05736932158470154\n",
      "\n",
      "episode 7, policy loss -0.04698636755347252\n",
      "\n",
      "episode 8, policy loss -0.010466312058269978\n",
      "\n",
      "episode 9, policy loss -0.045289911329746246\n",
      "\n",
      "episode 10, policy loss -0.028021490201354027\n",
      "\n",
      "episode 11, policy loss -0.06537526845932007\n",
      "\n",
      "episode 12, policy loss -0.06429971754550934\n",
      "\n",
      "episode 13, policy loss -0.0365520678460598\n",
      "\n",
      "episode 14, policy loss 0.003077189903706312\n",
      "\n",
      "episode 15, policy loss -0.01772916689515114\n",
      "\n",
      "episode 16, policy loss -0.05054985731840134\n",
      "\n",
      "Policy train loss in epoch 0:-0.0363324900099542\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.05064690113067627\n",
      "\n",
      "episode 2, policy loss 0.0014877499779686332\n",
      "\n",
      "episode 3, policy loss -0.04485880956053734\n",
      "\n",
      "episode 4, policy loss -0.011462257243692875\n",
      "\n",
      "episode 5, policy loss -0.027248213067650795\n",
      "\n",
      "episode 6, policy loss -0.06769774854183197\n",
      "\n",
      "episode 7, policy loss -0.019339999184012413\n",
      "\n",
      "episode 8, policy loss -0.06579791754484177\n",
      "\n",
      "episode 9, policy loss -0.028796808794140816\n",
      "\n",
      "episode 10, policy loss -0.06778205186128616\n",
      "\n",
      "episode 11, policy loss -0.047338470816612244\n",
      "\n",
      "episode 12, policy loss -0.06345109641551971\n",
      "\n",
      "episode 13, policy loss -0.027147604152560234\n",
      "\n",
      "episode 14, policy loss -0.0247469712048769\n",
      "\n",
      "episode 15, policy loss -0.036898642778396606\n",
      "\n",
      "episode 16, policy loss -0.04826866835355759\n",
      "\n",
      "Policy train loss in epoch 1:-0.039374650667014066\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.024203374981880188\n",
      "\n",
      "episode 2, policy loss -0.04818404093384743\n",
      "\n",
      "episode 3, policy loss -0.06410031020641327\n",
      "\n",
      "episode 4, policy loss -0.00037520297337323427\n",
      "\n",
      "episode 5, policy loss -0.019846998155117035\n",
      "\n",
      "episode 6, policy loss -0.04849471524357796\n",
      "\n",
      "episode 7, policy loss -0.06832683831453323\n",
      "\n",
      "episode 8, policy loss -0.013375886715948582\n",
      "\n",
      "episode 9, policy loss -0.06220492720603943\n",
      "\n",
      "episode 10, policy loss -0.0285614263266325\n",
      "\n",
      "episode 11, policy loss -0.026500582695007324\n",
      "\n",
      "episode 12, policy loss -0.046952128410339355\n",
      "\n",
      "episode 13, policy loss -0.026116125285625458\n",
      "\n",
      "episode 14, policy loss -0.03726109489798546\n",
      "\n",
      "episode 15, policy loss -0.06837041676044464\n",
      "\n",
      "episode 16, policy loss -0.0454271174967289\n",
      "\n",
      "Policy train loss in epoch 2:-0.039268824162718374\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.04550383239984512\n",
      "\n",
      "episode 2, policy loss -0.048379167914390564\n",
      "\n",
      "episode 3, policy loss -0.027865581214427948\n",
      "\n",
      "episode 4, policy loss -0.04963328689336777\n",
      "\n",
      "episode 5, policy loss -0.024190830066800117\n",
      "\n",
      "episode 6, policy loss -0.06630539149045944\n",
      "\n",
      "episode 7, policy loss -0.01981831155717373\n",
      "\n",
      "episode 8, policy loss -0.02806083671748638\n",
      "\n",
      "episode 9, policy loss -0.06747613847255707\n",
      "\n",
      "episode 10, policy loss -0.001245794934220612\n",
      "\n",
      "episode 11, policy loss -0.06909014284610748\n",
      "\n",
      "episode 12, policy loss -0.02819800190627575\n",
      "\n",
      "episode 13, policy loss -0.013428348116576672\n",
      "\n",
      "episode 14, policy loss -0.0668807402253151\n",
      "\n",
      "episode 15, policy loss -0.038493562489748\n",
      "\n",
      "episode 16, policy loss -0.048772621899843216\n",
      "\n",
      "Policy train loss in epoch 3:-0.040208911821537185\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.18797433376312256\n",
      "\n",
      "episode 2, val func loss 0.16967004537582397\n",
      "\n",
      "episode 3, val func loss 0.19514785706996918\n",
      "\n",
      "episode 4, val func loss 0.19300109148025513\n",
      "\n",
      "episode 5, val func loss 0.1953502595424652\n",
      "\n",
      "episode 6, val func loss 0.17501159012317657\n",
      "\n",
      "episode 7, val func loss 0.1919945925474167\n",
      "\n",
      "episode 8, val func loss 0.1730475276708603\n",
      "\n",
      "episode 9, val func loss 0.21067030727863312\n",
      "\n",
      "episode 10, val func loss 0.18975399434566498\n",
      "\n",
      "episode 11, val func loss 0.17067959904670715\n",
      "\n",
      "episode 12, val func loss 0.1925768256187439\n",
      "\n",
      "episode 13, val func loss 0.1608252078294754\n",
      "\n",
      "episode 14, val func loss 0.18584653735160828\n",
      "\n",
      "episode 15, val func loss 0.176734060049057\n",
      "\n",
      "episode 16, val func loss 0.1848410964012146\n",
      "\n",
      "Val func train loss in epoch 0:0.18457030784338713\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1927918642759323\n",
      "\n",
      "episode 2, val func loss 0.1602167934179306\n",
      "\n",
      "episode 3, val func loss 0.17018060386180878\n",
      "\n",
      "episode 4, val func loss 0.18568110466003418\n",
      "\n",
      "episode 5, val func loss 0.1900065690279007\n",
      "\n",
      "episode 6, val func loss 0.17339900135993958\n",
      "\n",
      "episode 7, val func loss 0.17130093276500702\n",
      "\n",
      "episode 8, val func loss 0.18380741775035858\n",
      "\n",
      "episode 9, val func loss 0.17666609585285187\n",
      "\n",
      "episode 10, val func loss 0.1957278698682785\n",
      "\n",
      "episode 11, val func loss 0.21064049005508423\n",
      "\n",
      "episode 12, val func loss 0.170057475566864\n",
      "\n",
      "episode 13, val func loss 0.18835072219371796\n",
      "\n",
      "episode 14, val func loss 0.1922573447227478\n",
      "\n",
      "episode 15, val func loss 0.19494368135929108\n",
      "\n",
      "episode 16, val func loss 0.19305168092250824\n",
      "\n",
      "Val func train loss in epoch 1:0.18431747797876596\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.17681263387203217\n",
      "\n",
      "episode 2, val func loss 0.19263029098510742\n",
      "\n",
      "episode 3, val func loss 0.18548157811164856\n",
      "\n",
      "episode 4, val func loss 0.19300924241542816\n",
      "\n",
      "episode 5, val func loss 0.21042050421237946\n",
      "\n",
      "episode 6, val func loss 0.18384721875190735\n",
      "\n",
      "episode 7, val func loss 0.17047199606895447\n",
      "\n",
      "episode 8, val func loss 0.1895817071199417\n",
      "\n",
      "episode 9, val func loss 0.1949397176504135\n",
      "\n",
      "episode 10, val func loss 0.1618361473083496\n",
      "\n",
      "episode 11, val func loss 0.1885184645652771\n",
      "\n",
      "episode 12, val func loss 0.19507227838039398\n",
      "\n",
      "episode 13, val func loss 0.17011281847953796\n",
      "\n",
      "episode 14, val func loss 0.17127157747745514\n",
      "\n",
      "episode 15, val func loss 0.17323027551174164\n",
      "\n",
      "episode 16, val func loss 0.19323639571666718\n",
      "\n",
      "Val func train loss in epoch 2:0.1844045529142022\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.15980622172355652\n",
      "\n",
      "episode 2, val func loss 0.1912153959274292\n",
      "\n",
      "episode 3, val func loss 0.19688117504119873\n",
      "\n",
      "episode 4, val func loss 0.19382841885089874\n",
      "\n",
      "episode 5, val func loss 0.19500160217285156\n",
      "\n",
      "episode 6, val func loss 0.17109565436840057\n",
      "\n",
      "episode 7, val func loss 0.2100268304347992\n",
      "\n",
      "episode 8, val func loss 0.1776765137910843\n",
      "\n",
      "episode 9, val func loss 0.18569329380989075\n",
      "\n",
      "episode 10, val func loss 0.1708526611328125\n",
      "\n",
      "episode 11, val func loss 0.17436820268630981\n",
      "\n",
      "episode 12, val func loss 0.18383491039276123\n",
      "\n",
      "episode 13, val func loss 0.19227048754692078\n",
      "\n",
      "episode 14, val func loss 0.1709946095943451\n",
      "\n",
      "episode 15, val func loss 0.18773405253887177\n",
      "\n",
      "episode 16, val func loss 0.19319264590740204\n",
      "\n",
      "Val func train loss in epoch 3:0.1846545422449708\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.19749392569065094\n",
      "\n",
      "episode 2, val func loss 0.210895836353302\n",
      "\n",
      "episode 3, val func loss 0.17030930519104004\n",
      "\n",
      "episode 4, val func loss 0.18363063037395477\n",
      "\n",
      "episode 5, val func loss 0.16122016310691833\n",
      "\n",
      "episode 6, val func loss 0.19230984151363373\n",
      "\n",
      "episode 7, val func loss 0.18596887588500977\n",
      "\n",
      "episode 8, val func loss 0.17679829895496368\n",
      "\n",
      "episode 9, val func loss 0.19481338560581207\n",
      "\n",
      "episode 10, val func loss 0.1734762340784073\n",
      "\n",
      "episode 11, val func loss 0.19373711943626404\n",
      "\n",
      "episode 12, val func loss 0.18758709728717804\n",
      "\n",
      "episode 13, val func loss 0.16969749331474304\n",
      "\n",
      "episode 14, val func loss 0.19005218148231506\n",
      "\n",
      "episode 15, val func loss 0.19259902834892273\n",
      "\n",
      "episode 16, val func loss 0.17024283111095428\n",
      "\n",
      "Val func train loss in epoch 4:0.18442701548337936\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19575314223766327\n",
      "\n",
      "episode 2, val func loss 0.19253693521022797\n",
      "\n",
      "episode 3, val func loss 0.16151149570941925\n",
      "\n",
      "episode 4, val func loss 0.185328409075737\n",
      "\n",
      "episode 5, val func loss 0.1769082099199295\n",
      "\n",
      "episode 6, val func loss 0.1919783353805542\n",
      "\n",
      "episode 7, val func loss 0.19264458119869232\n",
      "\n",
      "episode 8, val func loss 0.17212805151939392\n",
      "\n",
      "episode 9, val func loss 0.18382582068443298\n",
      "\n",
      "episode 10, val func loss 0.17288841307163239\n",
      "\n",
      "episode 11, val func loss 0.19484035670757294\n",
      "\n",
      "episode 12, val func loss 0.16955772042274475\n",
      "\n",
      "episode 13, val func loss 0.1683153361082077\n",
      "\n",
      "episode 14, val func loss 0.1866939216852188\n",
      "\n",
      "episode 15, val func loss 0.2110317349433899\n",
      "\n",
      "episode 16, val func loss 0.19012901186943054\n",
      "\n",
      "Val func train loss in epoch 5:0.18412946723401546\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17181386053562164\n",
      "\n",
      "episode 2, val func loss 0.19074586033821106\n",
      "\n",
      "episode 3, val func loss 0.1942850798368454\n",
      "\n",
      "episode 4, val func loss 0.20668919384479523\n",
      "\n",
      "episode 5, val func loss 0.17287597060203552\n",
      "\n",
      "episode 6, val func loss 0.17828774452209473\n",
      "\n",
      "episode 7, val func loss 0.18944168090820312\n",
      "\n",
      "episode 8, val func loss 0.1841905415058136\n",
      "\n",
      "episode 9, val func loss 0.16809003055095673\n",
      "\n",
      "episode 10, val func loss 0.19865427911281586\n",
      "\n",
      "episode 11, val func loss 0.18699151277542114\n",
      "\n",
      "episode 12, val func loss 0.1753048300743103\n",
      "\n",
      "episode 13, val func loss 0.19064919650554657\n",
      "\n",
      "episode 14, val func loss 0.16118550300598145\n",
      "\n",
      "episode 15, val func loss 0.19235911965370178\n",
      "\n",
      "episode 16, val func loss 0.19280655682086945\n",
      "\n",
      "Val func train loss in epoch 6:0.18464818503707647\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19054044783115387\n",
      "\n",
      "episode 2, val func loss 0.17146790027618408\n",
      "\n",
      "episode 3, val func loss 0.18419820070266724\n",
      "\n",
      "episode 4, val func loss 0.16247785091400146\n",
      "\n",
      "episode 5, val func loss 0.21078485250473022\n",
      "\n",
      "episode 6, val func loss 0.19170717895030975\n",
      "\n",
      "episode 7, val func loss 0.19653865694999695\n",
      "\n",
      "episode 8, val func loss 0.19457551836967468\n",
      "\n",
      "episode 9, val func loss 0.18805761635303497\n",
      "\n",
      "episode 10, val func loss 0.17686288058757782\n",
      "\n",
      "episode 11, val func loss 0.17071227729320526\n",
      "\n",
      "episode 12, val func loss 0.17003418505191803\n",
      "\n",
      "episode 13, val func loss 0.18499183654785156\n",
      "\n",
      "episode 14, val func loss 0.18979701399803162\n",
      "\n",
      "episode 15, val func loss 0.19489508867263794\n",
      "\n",
      "episode 16, val func loss 0.17316803336143494\n",
      "\n",
      "Val func train loss in epoch 7:0.18442559614777565\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1699206829071045\n",
      "\n",
      "episode 2, val func loss 0.1905495822429657\n",
      "\n",
      "episode 3, val func loss 0.17622220516204834\n",
      "\n",
      "episode 4, val func loss 0.19230258464813232\n",
      "\n",
      "episode 5, val func loss 0.19586388766765594\n",
      "\n",
      "episode 6, val func loss 0.21000857651233673\n",
      "\n",
      "episode 7, val func loss 0.17420221865177155\n",
      "\n",
      "episode 8, val func loss 0.1923256516456604\n",
      "\n",
      "episode 9, val func loss 0.1891283243894577\n",
      "\n",
      "episode 10, val func loss 0.19543901085853577\n",
      "\n",
      "episode 11, val func loss 0.18413178622722626\n",
      "\n",
      "episode 12, val func loss 0.1610029637813568\n",
      "\n",
      "episode 13, val func loss 0.17117151618003845\n",
      "\n",
      "episode 14, val func loss 0.16927893459796906\n",
      "\n",
      "episode 15, val func loss 0.19567759335041046\n",
      "\n",
      "episode 16, val func loss 0.18608134984970093\n",
      "\n",
      "Val func train loss in epoch 8:0.18458167929202318\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.19252973794937134\n",
      "\n",
      "episode 2, val func loss 0.18410715460777283\n",
      "\n",
      "episode 3, val func loss 0.1935642510652542\n",
      "\n",
      "episode 4, val func loss 0.18981517851352692\n",
      "\n",
      "episode 5, val func loss 0.1950078308582306\n",
      "\n",
      "episode 6, val func loss 0.18893061578273773\n",
      "\n",
      "episode 7, val func loss 0.16423356533050537\n",
      "\n",
      "episode 8, val func loss 0.19460852444171906\n",
      "\n",
      "episode 9, val func loss 0.17097394168376923\n",
      "\n",
      "episode 10, val func loss 0.17717191576957703\n",
      "\n",
      "episode 11, val func loss 0.2106224149465561\n",
      "\n",
      "episode 12, val func loss 0.1854115128517151\n",
      "\n",
      "episode 13, val func loss 0.1926012486219406\n",
      "\n",
      "episode 14, val func loss 0.17081181704998016\n",
      "\n",
      "episode 15, val func loss 0.17002689838409424\n",
      "\n",
      "episode 16, val func loss 0.17293325066566467\n",
      "\n",
      "Val func train loss in epoch 9:0.18458436615765095\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19311654567718506\n",
      "\n",
      "episode 2, val func loss 0.1698617786169052\n",
      "\n",
      "episode 3, val func loss 0.17071516811847687\n",
      "\n",
      "episode 4, val func loss 0.15983343124389648\n",
      "\n",
      "episode 5, val func loss 0.19302895665168762\n",
      "\n",
      "episode 6, val func loss 0.210694819688797\n",
      "\n",
      "episode 7, val func loss 0.1686883270740509\n",
      "\n",
      "episode 8, val func loss 0.18428827822208405\n",
      "\n",
      "episode 9, val func loss 0.1766766905784607\n",
      "\n",
      "episode 10, val func loss 0.17421641945838928\n",
      "\n",
      "episode 11, val func loss 0.18531450629234314\n",
      "\n",
      "episode 12, val func loss 0.1958896666765213\n",
      "\n",
      "episode 13, val func loss 0.1898171454668045\n",
      "\n",
      "episode 14, val func loss 0.19253405928611755\n",
      "\n",
      "episode 15, val func loss 0.19455818831920624\n",
      "\n",
      "episode 16, val func loss 0.18897458910942078\n",
      "\n",
      "Val func train loss in epoch 10:0.18426303565502167\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1848958134651184\n",
      "\n",
      "episode 2, val func loss 0.1892199069261551\n",
      "\n",
      "episode 3, val func loss 0.1915353685617447\n",
      "\n",
      "episode 4, val func loss 0.16208770871162415\n",
      "\n",
      "episode 5, val func loss 0.18767160177230835\n",
      "\n",
      "episode 6, val func loss 0.1737114042043686\n",
      "\n",
      "episode 7, val func loss 0.21050138771533966\n",
      "\n",
      "episode 8, val func loss 0.1764906346797943\n",
      "\n",
      "episode 9, val func loss 0.16949664056301117\n",
      "\n",
      "episode 10, val func loss 0.1960752010345459\n",
      "\n",
      "episode 11, val func loss 0.16817021369934082\n",
      "\n",
      "episode 12, val func loss 0.18448245525360107\n",
      "\n",
      "episode 13, val func loss 0.19330978393554688\n",
      "\n",
      "episode 14, val func loss 0.17176227271556854\n",
      "\n",
      "episode 15, val func loss 0.19662436842918396\n",
      "\n",
      "episode 16, val func loss 0.1920739859342575\n",
      "\n",
      "Val func train loss in epoch 11:0.18425679672509432\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.16924408078193665\n",
      "\n",
      "episode 2, val func loss 0.18676604330539703\n",
      "\n",
      "episode 3, val func loss 0.17167353630065918\n",
      "\n",
      "episode 4, val func loss 0.197165384888649\n",
      "\n",
      "episode 5, val func loss 0.18589940667152405\n",
      "\n",
      "episode 6, val func loss 0.17623545229434967\n",
      "\n",
      "episode 7, val func loss 0.19045519828796387\n",
      "\n",
      "episode 8, val func loss 0.19257274270057678\n",
      "\n",
      "episode 9, val func loss 0.1909583956003189\n",
      "\n",
      "episode 10, val func loss 0.19221580028533936\n",
      "\n",
      "episode 11, val func loss 0.17368949949741364\n",
      "\n",
      "episode 12, val func loss 0.19648201763629913\n",
      "\n",
      "episode 13, val func loss 0.17528179287910461\n",
      "\n",
      "episode 14, val func loss 0.18530644476413727\n",
      "\n",
      "episode 15, val func loss 0.2093883454799652\n",
      "\n",
      "episode 16, val func loss 0.16089120507240295\n",
      "\n",
      "Val func train loss in epoch 12:0.18463908415287733\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1935501992702484\n",
      "\n",
      "episode 2, val func loss 0.16922259330749512\n",
      "\n",
      "episode 3, val func loss 0.19406932592391968\n",
      "\n",
      "episode 4, val func loss 0.1907278448343277\n",
      "\n",
      "episode 5, val func loss 0.19539304077625275\n",
      "\n",
      "episode 6, val func loss 0.19483582675457\n",
      "\n",
      "episode 7, val func loss 0.17147767543792725\n",
      "\n",
      "episode 8, val func loss 0.1739102154970169\n",
      "\n",
      "episode 9, val func loss 0.18889528512954712\n",
      "\n",
      "episode 10, val func loss 0.20973210036754608\n",
      "\n",
      "episode 11, val func loss 0.1858980804681778\n",
      "\n",
      "episode 12, val func loss 0.19314847886562347\n",
      "\n",
      "episode 13, val func loss 0.16054101288318634\n",
      "\n",
      "episode 14, val func loss 0.17697350680828094\n",
      "\n",
      "episode 15, val func loss 0.1845061033964157\n",
      "\n",
      "episode 16, val func loss 0.17130808532238007\n",
      "\n",
      "Val func train loss in epoch 13:0.1846368359401822\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.17282991111278534\n",
      "\n",
      "episode 2, val func loss 0.18748462200164795\n",
      "\n",
      "episode 3, val func loss 0.16933253407478333\n",
      "\n",
      "episode 4, val func loss 0.19306552410125732\n",
      "\n",
      "episode 5, val func loss 0.19776877760887146\n",
      "\n",
      "episode 6, val func loss 0.19500309228897095\n",
      "\n",
      "episode 7, val func loss 0.17003285884857178\n",
      "\n",
      "episode 8, val func loss 0.19384019076824188\n",
      "\n",
      "episode 9, val func loss 0.1616881787776947\n",
      "\n",
      "episode 10, val func loss 0.1851688027381897\n",
      "\n",
      "episode 11, val func loss 0.1774720698595047\n",
      "\n",
      "episode 12, val func loss 0.1716129332780838\n",
      "\n",
      "episode 13, val func loss 0.1914343684911728\n",
      "\n",
      "episode 14, val func loss 0.21003425121307373\n",
      "\n",
      "episode 15, val func loss 0.19017541408538818\n",
      "\n",
      "episode 16, val func loss 0.18474897742271423\n",
      "\n",
      "Val func train loss in epoch 14:0.1844807816669345\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.17600616812705994\n",
      "\n",
      "episode 2, val func loss 0.16079765558242798\n",
      "\n",
      "episode 3, val func loss 0.1921588033437729\n",
      "\n",
      "episode 4, val func loss 0.17058750987052917\n",
      "\n",
      "episode 5, val func loss 0.19463719427585602\n",
      "\n",
      "episode 6, val func loss 0.1703893095254898\n",
      "\n",
      "episode 7, val func loss 0.1959591805934906\n",
      "\n",
      "episode 8, val func loss 0.16965042054653168\n",
      "\n",
      "episode 9, val func loss 0.1740465611219406\n",
      "\n",
      "episode 10, val func loss 0.1952323317527771\n",
      "\n",
      "episode 11, val func loss 0.1918223649263382\n",
      "\n",
      "episode 12, val func loss 0.20963817834854126\n",
      "\n",
      "episode 13, val func loss 0.18359681963920593\n",
      "\n",
      "episode 14, val func loss 0.18756157159805298\n",
      "\n",
      "episode 15, val func loss 0.18897604942321777\n",
      "\n",
      "episode 16, val func loss 0.18561935424804688\n",
      "\n",
      "Val func train loss in epoch 15:0.18416746705770493\n",
      "***********************TIME WAS 5.006472448507945 min*****************************\n",
      "\n",
      "**********************ROUND 139 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.08024615049362183\n",
      "\n",
      "episode 2, policy loss 0.045458875596523285\n",
      "\n",
      "episode 3, policy loss 0.05598159506917\n",
      "\n",
      "episode 4, policy loss 0.053544435650110245\n",
      "\n",
      "episode 5, policy loss 0.035791393369436264\n",
      "\n",
      "episode 6, policy loss 0.00558296637609601\n",
      "\n",
      "episode 7, policy loss 0.0516061894595623\n",
      "\n",
      "episode 8, policy loss -0.008903369307518005\n",
      "\n",
      "episode 9, policy loss 0.06953606009483337\n",
      "\n",
      "episode 10, policy loss 0.042054854333400726\n",
      "\n",
      "episode 11, policy loss 0.03232662379741669\n",
      "\n",
      "episode 12, policy loss 0.046201758086681366\n",
      "\n",
      "episode 13, policy loss 0.032196659594774246\n",
      "\n",
      "episode 14, policy loss 0.005016290582716465\n",
      "\n",
      "episode 15, policy loss -0.0002777570625767112\n",
      "\n",
      "episode 16, policy loss -0.018473999574780464\n",
      "\n",
      "Policy train loss in epoch 0:0.032993045409966726\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.04896245151758194\n",
      "\n",
      "episode 2, policy loss 0.04170822352170944\n",
      "\n",
      "episode 3, policy loss 0.07661520689725876\n",
      "\n",
      "episode 4, policy loss 0.04068732261657715\n",
      "\n",
      "episode 5, policy loss -0.01928114704787731\n",
      "\n",
      "episode 6, policy loss 0.04573003575205803\n",
      "\n",
      "episode 7, policy loss 0.05432593822479248\n",
      "\n",
      "episode 8, policy loss 0.0316656157374382\n",
      "\n",
      "episode 9, policy loss 0.0706537663936615\n",
      "\n",
      "episode 10, policy loss 0.032392337918281555\n",
      "\n",
      "episode 11, policy loss 0.048353251069784164\n",
      "\n",
      "episode 12, policy loss -0.009777363389730453\n",
      "\n",
      "episode 13, policy loss -0.00534255662932992\n",
      "\n",
      "episode 14, policy loss 0.002096707234159112\n",
      "\n",
      "episode 15, policy loss 0.03225208818912506\n",
      "\n",
      "episode 16, policy loss 0.0036795921623706818\n",
      "\n",
      "Policy train loss in epoch 1:0.030920091885491274\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.07402748614549637\n",
      "\n",
      "episode 2, policy loss 0.047435589134693146\n",
      "\n",
      "episode 3, policy loss 0.040419045835733414\n",
      "\n",
      "episode 4, policy loss -0.02182392217218876\n",
      "\n",
      "episode 5, policy loss 0.03263646364212036\n",
      "\n",
      "episode 6, policy loss 0.0025692107155919075\n",
      "\n",
      "episode 7, policy loss 0.04774856194853783\n",
      "\n",
      "episode 8, policy loss 0.04560748487710953\n",
      "\n",
      "episode 9, policy loss -0.009131668135523796\n",
      "\n",
      "episode 10, policy loss 0.03118380531668663\n",
      "\n",
      "episode 11, policy loss 0.06978568434715271\n",
      "\n",
      "episode 12, policy loss 0.03156869485974312\n",
      "\n",
      "episode 13, policy loss 0.038684871047735214\n",
      "\n",
      "episode 14, policy loss -0.0026266255881637335\n",
      "\n",
      "episode 15, policy loss 0.005189154762774706\n",
      "\n",
      "episode 16, policy loss 0.052320968359708786\n",
      "\n",
      "Policy train loss in epoch 2:0.030349675318575464\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.004724767524749041\n",
      "\n",
      "episode 2, policy loss -0.022208793088793755\n",
      "\n",
      "episode 3, policy loss -0.009652004577219486\n",
      "\n",
      "episode 4, policy loss 0.04773440212011337\n",
      "\n",
      "episode 5, policy loss 0.053524501621723175\n",
      "\n",
      "episode 6, policy loss 0.03192371502518654\n",
      "\n",
      "episode 7, policy loss 0.03102879412472248\n",
      "\n",
      "episode 8, policy loss 0.07532081753015518\n",
      "\n",
      "episode 9, policy loss 0.0479389987885952\n",
      "\n",
      "episode 10, policy loss 0.03979182988405228\n",
      "\n",
      "episode 11, policy loss 0.03784842789173126\n",
      "\n",
      "episode 12, policy loss -0.0042527406476438046\n",
      "\n",
      "episode 13, policy loss 0.04508446156978607\n",
      "\n",
      "episode 14, policy loss 0.07160409539937973\n",
      "\n",
      "episode 15, policy loss 0.032632358372211456\n",
      "\n",
      "episode 16, policy loss 0.0020370769780129194\n",
      "\n",
      "Policy train loss in epoch 3:0.030317544282297604\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.20474733412265778\n",
      "\n",
      "episode 2, val func loss 0.17446094751358032\n",
      "\n",
      "episode 3, val func loss 0.17715893685817719\n",
      "\n",
      "episode 4, val func loss 0.17324553430080414\n",
      "\n",
      "episode 5, val func loss 0.16811420023441315\n",
      "\n",
      "episode 6, val func loss 0.16106098890304565\n",
      "\n",
      "episode 7, val func loss 0.1890324503183365\n",
      "\n",
      "episode 8, val func loss 0.18989814817905426\n",
      "\n",
      "episode 9, val func loss 0.17007069289684296\n",
      "\n",
      "episode 10, val func loss 0.21219860017299652\n",
      "\n",
      "episode 11, val func loss 0.19356952607631683\n",
      "\n",
      "episode 12, val func loss 0.16734187304973602\n",
      "\n",
      "episode 13, val func loss 0.17642657458782196\n",
      "\n",
      "episode 14, val func loss 0.187776118516922\n",
      "\n",
      "episode 15, val func loss 0.18286888301372528\n",
      "\n",
      "episode 16, val func loss 0.19740882515907288\n",
      "\n",
      "Val func train loss in epoch 0:0.18283622711896896\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17652776837348938\n",
      "\n",
      "episode 2, val func loss 0.19089633226394653\n",
      "\n",
      "episode 3, val func loss 0.1669319123029709\n",
      "\n",
      "episode 4, val func loss 0.20488689839839935\n",
      "\n",
      "episode 5, val func loss 0.18942904472351074\n",
      "\n",
      "episode 6, val func loss 0.170344278216362\n",
      "\n",
      "episode 7, val func loss 0.18141232430934906\n",
      "\n",
      "episode 8, val func loss 0.17489147186279297\n",
      "\n",
      "episode 9, val func loss 0.16649101674556732\n",
      "\n",
      "episode 10, val func loss 0.20242945849895477\n",
      "\n",
      "episode 11, val func loss 0.1903201788663864\n",
      "\n",
      "episode 12, val func loss 0.20970045030117035\n",
      "\n",
      "episode 13, val func loss 0.18955081701278687\n",
      "\n",
      "episode 14, val func loss 0.16101029515266418\n",
      "\n",
      "episode 15, val func loss 0.17504936456680298\n",
      "\n",
      "episode 16, val func loss 0.1740005761384964\n",
      "\n",
      "Val func train loss in epoch 1:0.18274201173335314\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.16176454722881317\n",
      "\n",
      "episode 2, val func loss 0.19168202579021454\n",
      "\n",
      "episode 3, val func loss 0.17099829018115997\n",
      "\n",
      "episode 4, val func loss 0.17500652372837067\n",
      "\n",
      "episode 5, val func loss 0.1884268969297409\n",
      "\n",
      "episode 6, val func loss 0.16801971197128296\n",
      "\n",
      "episode 7, val func loss 0.17558786273002625\n",
      "\n",
      "episode 8, val func loss 0.20594686269760132\n",
      "\n",
      "episode 9, val func loss 0.1752910614013672\n",
      "\n",
      "episode 10, val func loss 0.16825401782989502\n",
      "\n",
      "episode 11, val func loss 0.202271968126297\n",
      "\n",
      "episode 12, val func loss 0.18987531960010529\n",
      "\n",
      "episode 13, val func loss 0.1805891990661621\n",
      "\n",
      "episode 14, val func loss 0.16839677095413208\n",
      "\n",
      "episode 15, val func loss 0.18744468688964844\n",
      "\n",
      "episode 16, val func loss 0.20756328105926514\n",
      "\n",
      "Val func train loss in epoch 2:0.18231993913650513\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.17636919021606445\n",
      "\n",
      "episode 2, val func loss 0.16703404486179352\n",
      "\n",
      "episode 3, val func loss 0.17275375127792358\n",
      "\n",
      "episode 4, val func loss 0.19121359288692474\n",
      "\n",
      "episode 5, val func loss 0.17491313815116882\n",
      "\n",
      "episode 6, val func loss 0.1893097311258316\n",
      "\n",
      "episode 7, val func loss 0.17379726469516754\n",
      "\n",
      "episode 8, val func loss 0.2068416029214859\n",
      "\n",
      "episode 9, val func loss 0.20710669457912445\n",
      "\n",
      "episode 10, val func loss 0.19129148125648499\n",
      "\n",
      "episode 11, val func loss 0.18157532811164856\n",
      "\n",
      "episode 12, val func loss 0.17506003379821777\n",
      "\n",
      "episode 13, val func loss 0.16865390539169312\n",
      "\n",
      "episode 14, val func loss 0.16249355673789978\n",
      "\n",
      "episode 15, val func loss 0.20016922056674957\n",
      "\n",
      "episode 16, val func loss 0.18879857659339905\n",
      "\n",
      "Val func train loss in epoch 3:0.1829613195732236\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17379559576511383\n",
      "\n",
      "episode 2, val func loss 0.18807774782180786\n",
      "\n",
      "episode 3, val func loss 0.2075158804655075\n",
      "\n",
      "episode 4, val func loss 0.18217600882053375\n",
      "\n",
      "episode 5, val func loss 0.16882944107055664\n",
      "\n",
      "episode 6, val func loss 0.17728322744369507\n",
      "\n",
      "episode 7, val func loss 0.20623035728931427\n",
      "\n",
      "episode 8, val func loss 0.1755930483341217\n",
      "\n",
      "episode 9, val func loss 0.18985992670059204\n",
      "\n",
      "episode 10, val func loss 0.16957810521125793\n",
      "\n",
      "episode 11, val func loss 0.19025607407093048\n",
      "\n",
      "episode 12, val func loss 0.17286759614944458\n",
      "\n",
      "episode 13, val func loss 0.20131169259548187\n",
      "\n",
      "episode 14, val func loss 0.16177967190742493\n",
      "\n",
      "episode 15, val func loss 0.16690027713775635\n",
      "\n",
      "episode 16, val func loss 0.18757621943950653\n",
      "\n",
      "Val func train loss in epoch 4:0.18247692938894033\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.16852429509162903\n",
      "\n",
      "episode 2, val func loss 0.17286889255046844\n",
      "\n",
      "episode 3, val func loss 0.16731539368629456\n",
      "\n",
      "episode 4, val func loss 0.20264287292957306\n",
      "\n",
      "episode 5, val func loss 0.18926984071731567\n",
      "\n",
      "episode 6, val func loss 0.18814177811145782\n",
      "\n",
      "episode 7, val func loss 0.18192794919013977\n",
      "\n",
      "episode 8, val func loss 0.1752508580684662\n",
      "\n",
      "episode 9, val func loss 0.20545895397663116\n",
      "\n",
      "episode 10, val func loss 0.17386282980442047\n",
      "\n",
      "episode 11, val func loss 0.1890566051006317\n",
      "\n",
      "episode 12, val func loss 0.19018854200839996\n",
      "\n",
      "episode 13, val func loss 0.20709170401096344\n",
      "\n",
      "episode 14, val func loss 0.17172113060951233\n",
      "\n",
      "episode 15, val func loss 0.16275933384895325\n",
      "\n",
      "episode 16, val func loss 0.17763614654541016\n",
      "\n",
      "Val func train loss in epoch 5:0.1827323203906417\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18879488110542297\n",
      "\n",
      "episode 2, val func loss 0.16826502978801727\n",
      "\n",
      "episode 3, val func loss 0.16743475198745728\n",
      "\n",
      "episode 4, val func loss 0.17632600665092468\n",
      "\n",
      "episode 5, val func loss 0.17305955290794373\n",
      "\n",
      "episode 6, val func loss 0.16229179501533508\n",
      "\n",
      "episode 7, val func loss 0.1768498420715332\n",
      "\n",
      "episode 8, val func loss 0.21220241487026215\n",
      "\n",
      "episode 9, val func loss 0.19075344502925873\n",
      "\n",
      "episode 10, val func loss 0.19139091670513153\n",
      "\n",
      "episode 11, val func loss 0.20890843868255615\n",
      "\n",
      "episode 12, val func loss 0.18195390701293945\n",
      "\n",
      "episode 13, val func loss 0.19846105575561523\n",
      "\n",
      "episode 14, val func loss 0.1685340702533722\n",
      "\n",
      "episode 15, val func loss 0.19102250039577484\n",
      "\n",
      "episode 16, val func loss 0.1775681972503662\n",
      "\n",
      "Val func train loss in epoch 6:0.18336355034261942\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18505698442459106\n",
      "\n",
      "episode 2, val func loss 0.16773918271064758\n",
      "\n",
      "episode 3, val func loss 0.17193235456943512\n",
      "\n",
      "episode 4, val func loss 0.17527858912944794\n",
      "\n",
      "episode 5, val func loss 0.2066299170255661\n",
      "\n",
      "episode 6, val func loss 0.1904561072587967\n",
      "\n",
      "episode 7, val func loss 0.17368029057979584\n",
      "\n",
      "episode 8, val func loss 0.1879315972328186\n",
      "\n",
      "episode 9, val func loss 0.17187270522117615\n",
      "\n",
      "episode 10, val func loss 0.16177673637866974\n",
      "\n",
      "episode 11, val func loss 0.1888241171836853\n",
      "\n",
      "episode 12, val func loss 0.2086179256439209\n",
      "\n",
      "episode 13, val func loss 0.17791065573692322\n",
      "\n",
      "episode 14, val func loss 0.1716952919960022\n",
      "\n",
      "episode 15, val func loss 0.19914498925209045\n",
      "\n",
      "episode 16, val func loss 0.19088809192180634\n",
      "\n",
      "Val func train loss in epoch 7:0.18308972101658583\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16926151514053345\n",
      "\n",
      "episode 2, val func loss 0.20682375133037567\n",
      "\n",
      "episode 3, val func loss 0.20838746428489685\n",
      "\n",
      "episode 4, val func loss 0.17528121173381805\n",
      "\n",
      "episode 5, val func loss 0.19084040820598602\n",
      "\n",
      "episode 6, val func loss 0.1874546855688095\n",
      "\n",
      "episode 7, val func loss 0.18751272559165955\n",
      "\n",
      "episode 8, val func loss 0.1819061040878296\n",
      "\n",
      "episode 9, val func loss 0.1636175960302353\n",
      "\n",
      "episode 10, val func loss 0.177528515458107\n",
      "\n",
      "episode 11, val func loss 0.19886158406734467\n",
      "\n",
      "episode 12, val func loss 0.16716837882995605\n",
      "\n",
      "episode 13, val func loss 0.1736505627632141\n",
      "\n",
      "episode 14, val func loss 0.18961894512176514\n",
      "\n",
      "episode 15, val func loss 0.16839595139026642\n",
      "\n",
      "episode 16, val func loss 0.17277288436889648\n",
      "\n",
      "Val func train loss in epoch 8:0.18244264274835587\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20114801824092865\n",
      "\n",
      "episode 2, val func loss 0.17566001415252686\n",
      "\n",
      "episode 3, val func loss 0.1729867309331894\n",
      "\n",
      "episode 4, val func loss 0.1814325600862503\n",
      "\n",
      "episode 5, val func loss 0.1724357306957245\n",
      "\n",
      "episode 6, val func loss 0.16807083785533905\n",
      "\n",
      "episode 7, val func loss 0.19048701226711273\n",
      "\n",
      "episode 8, val func loss 0.16648615896701813\n",
      "\n",
      "episode 9, val func loss 0.18762771785259247\n",
      "\n",
      "episode 10, val func loss 0.20666703581809998\n",
      "\n",
      "episode 11, val func loss 0.1873084455728531\n",
      "\n",
      "episode 12, val func loss 0.20410792529582977\n",
      "\n",
      "episode 13, val func loss 0.16612185537815094\n",
      "\n",
      "episode 14, val func loss 0.17686322331428528\n",
      "\n",
      "episode 15, val func loss 0.19204281270503998\n",
      "\n",
      "episode 16, val func loss 0.1691703349351883\n",
      "\n",
      "Val func train loss in epoch 9:0.1824135258793831\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.17610293626785278\n",
      "\n",
      "episode 2, val func loss 0.18121623992919922\n",
      "\n",
      "episode 3, val func loss 0.2061612904071808\n",
      "\n",
      "episode 4, val func loss 0.19302766025066376\n",
      "\n",
      "episode 5, val func loss 0.17191265523433685\n",
      "\n",
      "episode 6, val func loss 0.17556557059288025\n",
      "\n",
      "episode 7, val func loss 0.18992146849632263\n",
      "\n",
      "episode 8, val func loss 0.167917862534523\n",
      "\n",
      "episode 9, val func loss 0.20779067277908325\n",
      "\n",
      "episode 10, val func loss 0.1884099394083023\n",
      "\n",
      "episode 11, val func loss 0.16896118223667145\n",
      "\n",
      "episode 12, val func loss 0.20503301918506622\n",
      "\n",
      "episode 13, val func loss 0.18861766159534454\n",
      "\n",
      "episode 14, val func loss 0.16164560616016388\n",
      "\n",
      "episode 15, val func loss 0.16762663424015045\n",
      "\n",
      "episode 16, val func loss 0.17668338119983673\n",
      "\n",
      "Val func train loss in epoch 10:0.18291211128234863\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.16937032341957092\n",
      "\n",
      "episode 2, val func loss 0.20634882152080536\n",
      "\n",
      "episode 3, val func loss 0.1877942681312561\n",
      "\n",
      "episode 4, val func loss 0.17338985204696655\n",
      "\n",
      "episode 5, val func loss 0.1673612892627716\n",
      "\n",
      "episode 6, val func loss 0.16147923469543457\n",
      "\n",
      "episode 7, val func loss 0.2017667591571808\n",
      "\n",
      "episode 8, val func loss 0.18860365450382233\n",
      "\n",
      "episode 9, val func loss 0.1671878546476364\n",
      "\n",
      "episode 10, val func loss 0.1917770951986313\n",
      "\n",
      "episode 11, val func loss 0.18277963995933533\n",
      "\n",
      "episode 12, val func loss 0.2070394605398178\n",
      "\n",
      "episode 13, val func loss 0.17313902080059052\n",
      "\n",
      "episode 14, val func loss 0.17655827105045319\n",
      "\n",
      "episode 15, val func loss 0.1901051104068756\n",
      "\n",
      "episode 16, val func loss 0.17521792650222778\n",
      "\n",
      "Val func train loss in epoch 11:0.182494911365211\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.17344073951244354\n",
      "\n",
      "episode 2, val func loss 0.190658301115036\n",
      "\n",
      "episode 3, val func loss 0.19021540880203247\n",
      "\n",
      "episode 4, val func loss 0.17364531755447388\n",
      "\n",
      "episode 5, val func loss 0.17581042647361755\n",
      "\n",
      "episode 6, val func loss 0.1617002636194229\n",
      "\n",
      "episode 7, val func loss 0.18208345770835876\n",
      "\n",
      "episode 8, val func loss 0.1670445203781128\n",
      "\n",
      "episode 9, val func loss 0.20246095955371857\n",
      "\n",
      "episode 10, val func loss 0.16761280596256256\n",
      "\n",
      "episode 11, val func loss 0.20699027180671692\n",
      "\n",
      "episode 12, val func loss 0.20821714401245117\n",
      "\n",
      "episode 13, val func loss 0.18717192113399506\n",
      "\n",
      "episode 14, val func loss 0.18973785638809204\n",
      "\n",
      "episode 15, val func loss 0.1736152172088623\n",
      "\n",
      "episode 16, val func loss 0.17563723027706146\n",
      "\n",
      "Val func train loss in epoch 12:0.18287761509418488\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18797676265239716\n",
      "\n",
      "episode 2, val func loss 0.18989160656929016\n",
      "\n",
      "episode 3, val func loss 0.17545360326766968\n",
      "\n",
      "episode 4, val func loss 0.19884474575519562\n",
      "\n",
      "episode 5, val func loss 0.1731029599905014\n",
      "\n",
      "episode 6, val func loss 0.20538009703159332\n",
      "\n",
      "episode 7, val func loss 0.17038759589195251\n",
      "\n",
      "episode 8, val func loss 0.16283760964870453\n",
      "\n",
      "episode 9, val func loss 0.18239015340805054\n",
      "\n",
      "episode 10, val func loss 0.20769308507442474\n",
      "\n",
      "episode 11, val func loss 0.17241206765174866\n",
      "\n",
      "episode 12, val func loss 0.16567842662334442\n",
      "\n",
      "episode 13, val func loss 0.1889161318540573\n",
      "\n",
      "episode 14, val func loss 0.19114075601100922\n",
      "\n",
      "episode 15, val func loss 0.17676693201065063\n",
      "\n",
      "episode 16, val func loss 0.16699998080730438\n",
      "\n",
      "Val func train loss in epoch 13:0.1822420321404934\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19215509295463562\n",
      "\n",
      "episode 2, val func loss 0.16625367105007172\n",
      "\n",
      "episode 3, val func loss 0.16758131980895996\n",
      "\n",
      "episode 4, val func loss 0.1882731020450592\n",
      "\n",
      "episode 5, val func loss 0.21078099310398102\n",
      "\n",
      "episode 6, val func loss 0.18173527717590332\n",
      "\n",
      "episode 7, val func loss 0.1768094003200531\n",
      "\n",
      "episode 8, val func loss 0.20214976370334625\n",
      "\n",
      "episode 9, val func loss 0.17520968616008759\n",
      "\n",
      "episode 10, val func loss 0.1734391748905182\n",
      "\n",
      "episode 11, val func loss 0.16715168952941895\n",
      "\n",
      "episode 12, val func loss 0.18770578503608704\n",
      "\n",
      "episode 13, val func loss 0.19102764129638672\n",
      "\n",
      "episode 14, val func loss 0.20425398647785187\n",
      "\n",
      "episode 15, val func loss 0.16401831805706024\n",
      "\n",
      "episode 16, val func loss 0.17498482763767242\n",
      "\n",
      "Val func train loss in epoch 14:0.18272060807794333\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19053427875041962\n",
      "\n",
      "episode 2, val func loss 0.18182095885276794\n",
      "\n",
      "episode 3, val func loss 0.17514503002166748\n",
      "\n",
      "episode 4, val func loss 0.20674772560596466\n",
      "\n",
      "episode 5, val func loss 0.2003442347049713\n",
      "\n",
      "episode 6, val func loss 0.1767517477273941\n",
      "\n",
      "episode 7, val func loss 0.16895951330661774\n",
      "\n",
      "episode 8, val func loss 0.1897379457950592\n",
      "\n",
      "episode 9, val func loss 0.1735183447599411\n",
      "\n",
      "episode 10, val func loss 0.16167931258678436\n",
      "\n",
      "episode 11, val func loss 0.1675793081521988\n",
      "\n",
      "episode 12, val func loss 0.19141322374343872\n",
      "\n",
      "episode 13, val func loss 0.20733825862407684\n",
      "\n",
      "episode 14, val func loss 0.1663300096988678\n",
      "\n",
      "episode 15, val func loss 0.18912267684936523\n",
      "\n",
      "episode 16, val func loss 0.17317460477352142\n",
      "\n",
      "Val func train loss in epoch 15:0.18251232337206602\n",
      "***********************TIME WAS 5.0070547580719 min*****************************\n",
      "\n",
      "**********************ROUND 140 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.08785957843065262\n",
      "\n",
      "episode 2, policy loss 0.05310475826263428\n",
      "\n",
      "episode 3, policy loss 0.05114573985338211\n",
      "\n",
      "episode 4, policy loss 0.02542446367442608\n",
      "\n",
      "episode 5, policy loss 0.05303952470421791\n",
      "\n",
      "episode 6, policy loss 0.08762870728969574\n",
      "\n",
      "episode 7, policy loss 0.08510063588619232\n",
      "\n",
      "episode 8, policy loss 0.06389930844306946\n",
      "\n",
      "episode 9, policy loss 0.060629162937402725\n",
      "\n",
      "episode 10, policy loss 0.0009920825250446796\n",
      "\n",
      "episode 11, policy loss 0.04566376656293869\n",
      "\n",
      "episode 12, policy loss 0.036796387284994125\n",
      "\n",
      "episode 13, policy loss 0.04515920951962471\n",
      "\n",
      "episode 14, policy loss 0.00929618626832962\n",
      "\n",
      "episode 15, policy loss 0.07606520503759384\n",
      "\n",
      "episode 16, policy loss 0.04635908454656601\n",
      "\n",
      "Policy train loss in epoch 0:0.05176023757667281\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.06162073090672493\n",
      "\n",
      "episode 2, policy loss 0.055983901023864746\n",
      "\n",
      "episode 3, policy loss 0.04455511271953583\n",
      "\n",
      "episode 4, policy loss 0.0744137167930603\n",
      "\n",
      "episode 5, policy loss 0.08465820550918579\n",
      "\n",
      "episode 6, policy loss 0.045692648738622665\n",
      "\n",
      "episode 7, policy loss 0.08465971052646637\n",
      "\n",
      "episode 8, policy loss 0.03547549247741699\n",
      "\n",
      "episode 9, policy loss 0.009311682544648647\n",
      "\n",
      "episode 10, policy loss 0.04454176500439644\n",
      "\n",
      "episode 11, policy loss 0.06358757615089417\n",
      "\n",
      "episode 12, policy loss -0.0004333368269726634\n",
      "\n",
      "episode 13, policy loss 0.0433189757168293\n",
      "\n",
      "episode 14, policy loss 0.08309417963027954\n",
      "\n",
      "episode 15, policy loss 0.022830266505479813\n",
      "\n",
      "episode 16, policy loss 0.04325292259454727\n",
      "\n",
      "Policy train loss in epoch 1:0.04978522187593626\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.023128509521484375\n",
      "\n",
      "episode 2, policy loss -0.0013301834696903825\n",
      "\n",
      "episode 3, policy loss 0.043398089706897736\n",
      "\n",
      "episode 4, policy loss 0.06355346739292145\n",
      "\n",
      "episode 5, policy loss 0.008025470189750195\n",
      "\n",
      "episode 6, policy loss 0.05927295237779617\n",
      "\n",
      "episode 7, policy loss 0.08221002668142319\n",
      "\n",
      "episode 8, policy loss 0.0733243003487587\n",
      "\n",
      "episode 9, policy loss 0.08443807810544968\n",
      "\n",
      "episode 10, policy loss 0.05260100215673447\n",
      "\n",
      "episode 11, policy loss 0.03463870659470558\n",
      "\n",
      "episode 12, policy loss 0.04326382651925087\n",
      "\n",
      "episode 13, policy loss 0.045488715171813965\n",
      "\n",
      "episode 14, policy loss 0.044638194143772125\n",
      "\n",
      "episode 15, policy loss 0.044160641729831696\n",
      "\n",
      "episode 16, policy loss 0.0872483104467392\n",
      "\n",
      "Policy train loss in epoch 2:0.04925375672610244\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.08284134417772293\n",
      "\n",
      "episode 2, policy loss 0.04171956330537796\n",
      "\n",
      "episode 3, policy loss -0.0027564021293073893\n",
      "\n",
      "episode 4, policy loss 0.08546197414398193\n",
      "\n",
      "episode 5, policy loss 0.05204005911946297\n",
      "\n",
      "episode 6, policy loss 0.06275869905948639\n",
      "\n",
      "episode 7, policy loss 0.007889388129115105\n",
      "\n",
      "episode 8, policy loss 0.08569181710481644\n",
      "\n",
      "episode 9, policy loss 0.03545881807804108\n",
      "\n",
      "episode 10, policy loss 0.04625099152326584\n",
      "\n",
      "episode 11, policy loss 0.045289717614650726\n",
      "\n",
      "episode 12, policy loss 0.07469099014997482\n",
      "\n",
      "episode 13, policy loss 0.04329110309481621\n",
      "\n",
      "episode 14, policy loss 0.059043753892183304\n",
      "\n",
      "episode 15, policy loss 0.024212151765823364\n",
      "\n",
      "episode 16, policy loss 0.04384433105587959\n",
      "\n",
      "Policy train loss in epoch 3:0.049233018755330704\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.2045244574546814\n",
      "\n",
      "episode 2, val func loss 0.19290344417095184\n",
      "\n",
      "episode 3, val func loss 0.172138512134552\n",
      "\n",
      "episode 4, val func loss 0.18612124025821686\n",
      "\n",
      "episode 5, val func loss 0.17944349348545074\n",
      "\n",
      "episode 6, val func loss 0.1628699153661728\n",
      "\n",
      "episode 7, val func loss 0.19852977991104126\n",
      "\n",
      "episode 8, val func loss 0.1814255714416504\n",
      "\n",
      "episode 9, val func loss 0.1806839257478714\n",
      "\n",
      "episode 10, val func loss 0.18346039950847626\n",
      "\n",
      "episode 11, val func loss 0.19472315907478333\n",
      "\n",
      "episode 12, val func loss 0.1901896744966507\n",
      "\n",
      "episode 13, val func loss 0.19945089519023895\n",
      "\n",
      "episode 14, val func loss 0.18312643468379974\n",
      "\n",
      "episode 15, val func loss 0.18331310153007507\n",
      "\n",
      "episode 16, val func loss 0.2200106829404831\n",
      "\n",
      "Val func train loss in epoch 0:0.1883071679621935\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.180734321475029\n",
      "\n",
      "episode 2, val func loss 0.21946290135383606\n",
      "\n",
      "episode 3, val func loss 0.18090084195137024\n",
      "\n",
      "episode 4, val func loss 0.1859046369791031\n",
      "\n",
      "episode 5, val func loss 0.17099225521087646\n",
      "\n",
      "episode 6, val func loss 0.18156607449054718\n",
      "\n",
      "episode 7, val func loss 0.1933843344449997\n",
      "\n",
      "episode 8, val func loss 0.18399201333522797\n",
      "\n",
      "episode 9, val func loss 0.199067160487175\n",
      "\n",
      "episode 10, val func loss 0.16009630262851715\n",
      "\n",
      "episode 11, val func loss 0.19394390285015106\n",
      "\n",
      "episode 12, val func loss 0.19881004095077515\n",
      "\n",
      "episode 13, val func loss 0.2071225792169571\n",
      "\n",
      "episode 14, val func loss 0.18339787423610687\n",
      "\n",
      "episode 15, val func loss 0.18227995932102203\n",
      "\n",
      "episode 16, val func loss 0.19079965353012085\n",
      "\n",
      "Val func train loss in epoch 1:0.18827842827886343\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.16136416792869568\n",
      "\n",
      "episode 2, val func loss 0.19263876974582672\n",
      "\n",
      "episode 3, val func loss 0.205551877617836\n",
      "\n",
      "episode 4, val func loss 0.18644702434539795\n",
      "\n",
      "episode 5, val func loss 0.18110089004039764\n",
      "\n",
      "episode 6, val func loss 0.18314112722873688\n",
      "\n",
      "episode 7, val func loss 0.17003072798252106\n",
      "\n",
      "episode 8, val func loss 0.1902710646390915\n",
      "\n",
      "episode 9, val func loss 0.19925253093242645\n",
      "\n",
      "episode 10, val func loss 0.18228425085544586\n",
      "\n",
      "episode 11, val func loss 0.17864729464054108\n",
      "\n",
      "episode 12, val func loss 0.18271471560001373\n",
      "\n",
      "episode 13, val func loss 0.19441480934619904\n",
      "\n",
      "episode 14, val func loss 0.1803823858499527\n",
      "\n",
      "episode 15, val func loss 0.22030049562454224\n",
      "\n",
      "episode 16, val func loss 0.198337584733963\n",
      "\n",
      "Val func train loss in epoch 2:0.18792998231947422\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20356722176074982\n",
      "\n",
      "episode 2, val func loss 0.2185998260974884\n",
      "\n",
      "episode 3, val func loss 0.18560068309307098\n",
      "\n",
      "episode 4, val func loss 0.18380586802959442\n",
      "\n",
      "episode 5, val func loss 0.1815045177936554\n",
      "\n",
      "episode 6, val func loss 0.18706415593624115\n",
      "\n",
      "episode 7, val func loss 0.1930515021085739\n",
      "\n",
      "episode 8, val func loss 0.18116600811481476\n",
      "\n",
      "episode 9, val func loss 0.19894073903560638\n",
      "\n",
      "episode 10, val func loss 0.16008666157722473\n",
      "\n",
      "episode 11, val func loss 0.19409014284610748\n",
      "\n",
      "episode 12, val func loss 0.1900312453508377\n",
      "\n",
      "episode 13, val func loss 0.16835668683052063\n",
      "\n",
      "episode 14, val func loss 0.18337975442409515\n",
      "\n",
      "episode 15, val func loss 0.19964022934436798\n",
      "\n",
      "episode 16, val func loss 0.18338610231876373\n",
      "\n",
      "Val func train loss in epoch 3:0.18826695904135704\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.198364719748497\n",
      "\n",
      "episode 2, val func loss 0.19000332057476044\n",
      "\n",
      "episode 3, val func loss 0.18238690495491028\n",
      "\n",
      "episode 4, val func loss 0.20526929199695587\n",
      "\n",
      "episode 5, val func loss 0.21933408081531525\n",
      "\n",
      "episode 6, val func loss 0.1844455450773239\n",
      "\n",
      "episode 7, val func loss 0.1842091679573059\n",
      "\n",
      "episode 8, val func loss 0.2001333087682724\n",
      "\n",
      "episode 9, val func loss 0.16848640143871307\n",
      "\n",
      "episode 10, val func loss 0.18060830235481262\n",
      "\n",
      "episode 11, val func loss 0.19554544985294342\n",
      "\n",
      "episode 12, val func loss 0.1963299959897995\n",
      "\n",
      "episode 13, val func loss 0.184156134724617\n",
      "\n",
      "episode 14, val func loss 0.16009952127933502\n",
      "\n",
      "episode 15, val func loss 0.18721498548984528\n",
      "\n",
      "episode 16, val func loss 0.17907275259494781\n",
      "\n",
      "Val func train loss in epoch 4:0.18847874272614717\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19274260103702545\n",
      "\n",
      "episode 2, val func loss 0.18203134834766388\n",
      "\n",
      "episode 3, val func loss 0.19019554555416107\n",
      "\n",
      "episode 4, val func loss 0.18286767601966858\n",
      "\n",
      "episode 5, val func loss 0.1823086142539978\n",
      "\n",
      "episode 6, val func loss 0.19800922274589539\n",
      "\n",
      "episode 7, val func loss 0.1786981225013733\n",
      "\n",
      "episode 8, val func loss 0.19271938502788544\n",
      "\n",
      "episode 9, val func loss 0.1836797446012497\n",
      "\n",
      "episode 10, val func loss 0.21972772479057312\n",
      "\n",
      "episode 11, val func loss 0.16859379410743713\n",
      "\n",
      "episode 12, val func loss 0.19885492324829102\n",
      "\n",
      "episode 13, val func loss 0.18042908608913422\n",
      "\n",
      "episode 14, val func loss 0.15967470407485962\n",
      "\n",
      "episode 15, val func loss 0.1878044605255127\n",
      "\n",
      "episode 16, val func loss 0.20518635213375092\n",
      "\n",
      "Val func train loss in epoch 5:0.18772020656615496\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18495091795921326\n",
      "\n",
      "episode 2, val func loss 0.178802952170372\n",
      "\n",
      "episode 3, val func loss 0.18327337503433228\n",
      "\n",
      "episode 4, val func loss 0.1823781281709671\n",
      "\n",
      "episode 5, val func loss 0.17965425550937653\n",
      "\n",
      "episode 6, val func loss 0.1979740411043167\n",
      "\n",
      "episode 7, val func loss 0.1936706155538559\n",
      "\n",
      "episode 8, val func loss 0.18476839363574982\n",
      "\n",
      "episode 9, val func loss 0.19949620962142944\n",
      "\n",
      "episode 10, val func loss 0.20637647807598114\n",
      "\n",
      "episode 11, val func loss 0.16685384511947632\n",
      "\n",
      "episode 12, val func loss 0.18317566812038422\n",
      "\n",
      "episode 13, val func loss 0.19333578646183014\n",
      "\n",
      "episode 14, val func loss 0.21810640394687653\n",
      "\n",
      "episode 15, val func loss 0.15989995002746582\n",
      "\n",
      "episode 16, val func loss 0.18881690502166748\n",
      "\n",
      "Val func train loss in epoch 6:0.18759587034583092\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.16141879558563232\n",
      "\n",
      "episode 2, val func loss 0.1841733157634735\n",
      "\n",
      "episode 3, val func loss 0.1983080804347992\n",
      "\n",
      "episode 4, val func loss 0.20637977123260498\n",
      "\n",
      "episode 5, val func loss 0.18334588408470154\n",
      "\n",
      "episode 6, val func loss 0.1863139569759369\n",
      "\n",
      "episode 7, val func loss 0.18066494166851044\n",
      "\n",
      "episode 8, val func loss 0.19204647839069366\n",
      "\n",
      "episode 9, val func loss 0.1697625368833542\n",
      "\n",
      "episode 10, val func loss 0.18115457892417908\n",
      "\n",
      "episode 11, val func loss 0.21813541650772095\n",
      "\n",
      "episode 12, val func loss 0.1882093846797943\n",
      "\n",
      "episode 13, val func loss 0.1794171929359436\n",
      "\n",
      "episode 14, val func loss 0.17999064922332764\n",
      "\n",
      "episode 15, val func loss 0.19688266515731812\n",
      "\n",
      "episode 16, val func loss 0.19546878337860107\n",
      "\n",
      "Val func train loss in epoch 7:0.18760452698916197\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.18034519255161285\n",
      "\n",
      "episode 2, val func loss 0.18438620865345\n",
      "\n",
      "episode 3, val func loss 0.20286759734153748\n",
      "\n",
      "episode 4, val func loss 0.2194662094116211\n",
      "\n",
      "episode 5, val func loss 0.19224262237548828\n",
      "\n",
      "episode 6, val func loss 0.19766826927661896\n",
      "\n",
      "episode 7, val func loss 0.18338578939437866\n",
      "\n",
      "episode 8, val func loss 0.1687890887260437\n",
      "\n",
      "episode 9, val func loss 0.19765812158584595\n",
      "\n",
      "episode 10, val func loss 0.18147826194763184\n",
      "\n",
      "episode 11, val func loss 0.18286851048469543\n",
      "\n",
      "episode 12, val func loss 0.19191332161426544\n",
      "\n",
      "episode 13, val func loss 0.1912948042154312\n",
      "\n",
      "episode 14, val func loss 0.162461519241333\n",
      "\n",
      "episode 15, val func loss 0.19126901030540466\n",
      "\n",
      "episode 16, val func loss 0.18106991052627563\n",
      "\n",
      "Val func train loss in epoch 8:0.18807277735322714\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.16027012467384338\n",
      "\n",
      "episode 2, val func loss 0.2066211998462677\n",
      "\n",
      "episode 3, val func loss 0.1896613985300064\n",
      "\n",
      "episode 4, val func loss 0.19682951271533966\n",
      "\n",
      "episode 5, val func loss 0.17884188890457153\n",
      "\n",
      "episode 6, val func loss 0.19922097027301788\n",
      "\n",
      "episode 7, val func loss 0.1928739845752716\n",
      "\n",
      "episode 8, val func loss 0.18268266320228577\n",
      "\n",
      "episode 9, val func loss 0.18125489354133606\n",
      "\n",
      "episode 10, val func loss 0.16676343977451324\n",
      "\n",
      "episode 11, val func loss 0.18610349297523499\n",
      "\n",
      "episode 12, val func loss 0.18047268688678741\n",
      "\n",
      "episode 13, val func loss 0.19024242460727692\n",
      "\n",
      "episode 14, val func loss 0.18152907490730286\n",
      "\n",
      "episode 15, val func loss 0.2206147313117981\n",
      "\n",
      "episode 16, val func loss 0.17758110165596008\n",
      "\n",
      "Val func train loss in epoch 9:0.18697272427380085\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18362998962402344\n",
      "\n",
      "episode 2, val func loss 0.1722157597541809\n",
      "\n",
      "episode 3, val func loss 0.1831677109003067\n",
      "\n",
      "episode 4, val func loss 0.18804343044757843\n",
      "\n",
      "episode 5, val func loss 0.1932022124528885\n",
      "\n",
      "episode 6, val func loss 0.18349668383598328\n",
      "\n",
      "episode 7, val func loss 0.18876588344573975\n",
      "\n",
      "episode 8, val func loss 0.19789816439151764\n",
      "\n",
      "episode 9, val func loss 0.20596693456172943\n",
      "\n",
      "episode 10, val func loss 0.16090621054172516\n",
      "\n",
      "episode 11, val func loss 0.18239443004131317\n",
      "\n",
      "episode 12, val func loss 0.19575265049934387\n",
      "\n",
      "episode 13, val func loss 0.17921489477157593\n",
      "\n",
      "episode 14, val func loss 0.18272794783115387\n",
      "\n",
      "episode 15, val func loss 0.1913750171661377\n",
      "\n",
      "episode 16, val func loss 0.21974356472492218\n",
      "\n",
      "Val func train loss in epoch 10:0.1880313428118825\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19361504912376404\n",
      "\n",
      "episode 2, val func loss 0.18270829319953918\n",
      "\n",
      "episode 3, val func loss 0.1877373605966568\n",
      "\n",
      "episode 4, val func loss 0.17958688735961914\n",
      "\n",
      "episode 5, val func loss 0.21874910593032837\n",
      "\n",
      "episode 6, val func loss 0.17869062721729279\n",
      "\n",
      "episode 7, val func loss 0.19683213531970978\n",
      "\n",
      "episode 8, val func loss 0.187204048037529\n",
      "\n",
      "episode 9, val func loss 0.16167274117469788\n",
      "\n",
      "episode 10, val func loss 0.18307580053806305\n",
      "\n",
      "episode 11, val func loss 0.1923743188381195\n",
      "\n",
      "episode 12, val func loss 0.16976475715637207\n",
      "\n",
      "episode 13, val func loss 0.1817801147699356\n",
      "\n",
      "episode 14, val func loss 0.2059958130121231\n",
      "\n",
      "episode 15, val func loss 0.18017563223838806\n",
      "\n",
      "episode 16, val func loss 0.1978757679462433\n",
      "\n",
      "Val func train loss in epoch 11:0.18736490327864885\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18977512419223785\n",
      "\n",
      "episode 2, val func loss 0.19324730336666107\n",
      "\n",
      "episode 3, val func loss 0.16096115112304688\n",
      "\n",
      "episode 4, val func loss 0.18201561272144318\n",
      "\n",
      "episode 5, val func loss 0.16893257200717926\n",
      "\n",
      "episode 6, val func loss 0.19749996066093445\n",
      "\n",
      "episode 7, val func loss 0.17829148471355438\n",
      "\n",
      "episode 8, val func loss 0.18194477260112762\n",
      "\n",
      "episode 9, val func loss 0.20682364702224731\n",
      "\n",
      "episode 10, val func loss 0.21930280327796936\n",
      "\n",
      "episode 11, val func loss 0.18645179271697998\n",
      "\n",
      "episode 12, val func loss 0.18238221108913422\n",
      "\n",
      "episode 13, val func loss 0.1928277462720871\n",
      "\n",
      "episode 14, val func loss 0.18315061926841736\n",
      "\n",
      "episode 15, val func loss 0.17995759844779968\n",
      "\n",
      "episode 16, val func loss 0.19620800018310547\n",
      "\n",
      "Val func train loss in epoch 12:0.18748577497899532\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.16111451387405396\n",
      "\n",
      "episode 2, val func loss 0.20431925356388092\n",
      "\n",
      "episode 3, val func loss 0.17838889360427856\n",
      "\n",
      "episode 4, val func loss 0.18734264373779297\n",
      "\n",
      "episode 5, val func loss 0.19132058322429657\n",
      "\n",
      "episode 6, val func loss 0.18327568471431732\n",
      "\n",
      "episode 7, val func loss 0.17702561616897583\n",
      "\n",
      "episode 8, val func loss 0.16549274325370789\n",
      "\n",
      "episode 9, val func loss 0.19259440898895264\n",
      "\n",
      "episode 10, val func loss 0.21601635217666626\n",
      "\n",
      "episode 11, val func loss 0.19510531425476074\n",
      "\n",
      "episode 12, val func loss 0.19805806875228882\n",
      "\n",
      "episode 13, val func loss 0.18118974566459656\n",
      "\n",
      "episode 14, val func loss 0.1835133135318756\n",
      "\n",
      "episode 15, val func loss 0.1815318465232849\n",
      "\n",
      "episode 16, val func loss 0.19430576264858246\n",
      "\n",
      "Val func train loss in epoch 13:0.1869121715426445\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18854236602783203\n",
      "\n",
      "episode 2, val func loss 0.17739830911159515\n",
      "\n",
      "episode 3, val func loss 0.18056422472000122\n",
      "\n",
      "episode 4, val func loss 0.2080804407596588\n",
      "\n",
      "episode 5, val func loss 0.16561035811901093\n",
      "\n",
      "episode 6, val func loss 0.19729773700237274\n",
      "\n",
      "episode 7, val func loss 0.18369200825691223\n",
      "\n",
      "episode 8, val func loss 0.18177630007266998\n",
      "\n",
      "episode 9, val func loss 0.1802971065044403\n",
      "\n",
      "episode 10, val func loss 0.21435041725635529\n",
      "\n",
      "episode 11, val func loss 0.19318082928657532\n",
      "\n",
      "episode 12, val func loss 0.19660626351833344\n",
      "\n",
      "episode 13, val func loss 0.16608735918998718\n",
      "\n",
      "episode 14, val func loss 0.19993601739406586\n",
      "\n",
      "episode 15, val func loss 0.17985063791275024\n",
      "\n",
      "episode 16, val func loss 0.1820182204246521\n",
      "\n",
      "Val func train loss in epoch 14:0.1872055372223258\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.16016608476638794\n",
      "\n",
      "episode 2, val func loss 0.21055574715137482\n",
      "\n",
      "episode 3, val func loss 0.19456735253334045\n",
      "\n",
      "episode 4, val func loss 0.17877064645290375\n",
      "\n",
      "episode 5, val func loss 0.19891895353794098\n",
      "\n",
      "episode 6, val func loss 0.18107178807258606\n",
      "\n",
      "episode 7, val func loss 0.19275487959384918\n",
      "\n",
      "episode 8, val func loss 0.18159689009189606\n",
      "\n",
      "episode 9, val func loss 0.2185070812702179\n",
      "\n",
      "episode 10, val func loss 0.1833588182926178\n",
      "\n",
      "episode 11, val func loss 0.19063705205917358\n",
      "\n",
      "episode 12, val func loss 0.1980653703212738\n",
      "\n",
      "episode 13, val func loss 0.1694791615009308\n",
      "\n",
      "episode 14, val func loss 0.1824834942817688\n",
      "\n",
      "episode 15, val func loss 0.18349742889404297\n",
      "\n",
      "episode 16, val func loss 0.18805260956287384\n",
      "\n",
      "Val func train loss in epoch 15:0.18828020989894867\n",
      "***********************TIME WAS 5.005776568253835 min*****************************\n",
      "\n",
      "**********************ROUND 141 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.375\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.02561364509165287\n",
      "\n",
      "episode 2, policy loss -0.017123034223914146\n",
      "\n",
      "episode 3, policy loss -0.03709477558732033\n",
      "\n",
      "episode 4, policy loss -0.0792977437376976\n",
      "\n",
      "episode 5, policy loss -0.026912422850728035\n",
      "\n",
      "episode 6, policy loss 0.0021235595922917128\n",
      "\n",
      "episode 7, policy loss -0.026407504454255104\n",
      "\n",
      "episode 8, policy loss 0.03293690085411072\n",
      "\n",
      "episode 9, policy loss -0.033954549580812454\n",
      "\n",
      "episode 10, policy loss -0.012380318716168404\n",
      "\n",
      "episode 11, policy loss -0.03152715787291527\n",
      "\n",
      "episode 12, policy loss -0.000281420536339283\n",
      "\n",
      "episode 13, policy loss -0.01087261363863945\n",
      "\n",
      "episode 14, policy loss -0.009878959506750107\n",
      "\n",
      "episode 15, policy loss -0.01453427318483591\n",
      "\n",
      "episode 16, policy loss -0.04489592835307121\n",
      "\n",
      "Policy train loss in epoch 0:-0.02098211793054361\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.03019888699054718\n",
      "\n",
      "episode 2, policy loss -0.0288548581302166\n",
      "\n",
      "episode 3, policy loss -0.010117463767528534\n",
      "\n",
      "episode 4, policy loss -0.032788071781396866\n",
      "\n",
      "episode 5, policy loss -0.01574481837451458\n",
      "\n",
      "episode 6, policy loss -0.03633371368050575\n",
      "\n",
      "episode 7, policy loss 0.03209777548909187\n",
      "\n",
      "episode 8, policy loss -0.04156668484210968\n",
      "\n",
      "episode 9, policy loss 0.0010058007901534438\n",
      "\n",
      "episode 10, policy loss -0.011830521747469902\n",
      "\n",
      "episode 11, policy loss -0.07995665818452835\n",
      "\n",
      "episode 12, policy loss 7.308696513064206e-05\n",
      "\n",
      "episode 13, policy loss -0.02477702684700489\n",
      "\n",
      "episode 14, policy loss -0.011941280215978622\n",
      "\n",
      "episode 15, policy loss -0.048227012157440186\n",
      "\n",
      "episode 16, policy loss -0.0300273597240448\n",
      "\n",
      "Policy train loss in epoch 1:-0.023074230824931874\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.031039226800203323\n",
      "\n",
      "episode 2, policy loss -0.0021782265976071358\n",
      "\n",
      "episode 3, policy loss -0.014738322235643864\n",
      "\n",
      "episode 4, policy loss -0.02968982607126236\n",
      "\n",
      "episode 5, policy loss -0.012758921831846237\n",
      "\n",
      "episode 6, policy loss -0.08192241936922073\n",
      "\n",
      "episode 7, policy loss -0.036399539560079575\n",
      "\n",
      "episode 8, policy loss -0.048769500106573105\n",
      "\n",
      "episode 9, policy loss -0.03523092716932297\n",
      "\n",
      "episode 10, policy loss -0.03143471106886864\n",
      "\n",
      "episode 11, policy loss -0.04295765236020088\n",
      "\n",
      "episode 12, policy loss -0.0014534899964928627\n",
      "\n",
      "episode 13, policy loss -0.01691155508160591\n",
      "\n",
      "episode 14, policy loss -0.025556419044733047\n",
      "\n",
      "episode 15, policy loss -0.01709406077861786\n",
      "\n",
      "episode 16, policy loss 0.03449008986353874\n",
      "\n",
      "Policy train loss in epoch 2:-0.024602794263046235\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.033856138586997986\n",
      "\n",
      "episode 2, policy loss -0.011979668401181698\n",
      "\n",
      "episode 3, policy loss -0.04365919902920723\n",
      "\n",
      "episode 4, policy loss -0.08186177909374237\n",
      "\n",
      "episode 5, policy loss -0.04854467883706093\n",
      "\n",
      "episode 6, policy loss -0.029674911871552467\n",
      "\n",
      "episode 7, policy loss -0.014334138482809067\n",
      "\n",
      "episode 8, policy loss -0.0012314539635553956\n",
      "\n",
      "episode 9, policy loss -0.01474912278354168\n",
      "\n",
      "episode 10, policy loss 0.03357280418276787\n",
      "\n",
      "episode 11, policy loss -0.03226572275161743\n",
      "\n",
      "episode 12, policy loss -0.03652093559503555\n",
      "\n",
      "episode 13, policy loss -0.031444352120161057\n",
      "\n",
      "episode 14, policy loss -0.002516423584893346\n",
      "\n",
      "episode 15, policy loss -0.01736506074666977\n",
      "\n",
      "episode 16, policy loss -0.02586432360112667\n",
      "\n",
      "Policy train loss in epoch 3:-0.02451844407914905\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.18235604465007782\n",
      "\n",
      "episode 2, val func loss 0.18613873422145844\n",
      "\n",
      "episode 3, val func loss 0.16735883057117462\n",
      "\n",
      "episode 4, val func loss 0.19653388857841492\n",
      "\n",
      "episode 5, val func loss 0.16350749135017395\n",
      "\n",
      "episode 6, val func loss 0.19553446769714355\n",
      "\n",
      "episode 7, val func loss 0.1867123246192932\n",
      "\n",
      "episode 8, val func loss 0.18168582022190094\n",
      "\n",
      "episode 9, val func loss 0.18901170790195465\n",
      "\n",
      "episode 10, val func loss 0.2063683271408081\n",
      "\n",
      "episode 11, val func loss 0.1577809602022171\n",
      "\n",
      "episode 12, val func loss 0.182490274310112\n",
      "\n",
      "episode 13, val func loss 0.18746496737003326\n",
      "\n",
      "episode 14, val func loss 0.17943517863750458\n",
      "\n",
      "episode 15, val func loss 0.16217464208602905\n",
      "\n",
      "episode 16, val func loss 0.18286485970020294\n",
      "\n",
      "Val func train loss in epoch 0:0.1817136574536562\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18614284694194794\n",
      "\n",
      "episode 2, val func loss 0.18368253111839294\n",
      "\n",
      "episode 3, val func loss 0.16310659050941467\n",
      "\n",
      "episode 4, val func loss 0.18704551458358765\n",
      "\n",
      "episode 5, val func loss 0.16723132133483887\n",
      "\n",
      "episode 6, val func loss 0.1620139479637146\n",
      "\n",
      "episode 7, val func loss 0.1875794529914856\n",
      "\n",
      "episode 8, val func loss 0.19585800170898438\n",
      "\n",
      "episode 9, val func loss 0.17966030538082123\n",
      "\n",
      "episode 10, val func loss 0.18171754479408264\n",
      "\n",
      "episode 11, val func loss 0.1822299212217331\n",
      "\n",
      "episode 12, val func loss 0.20707473158836365\n",
      "\n",
      "episode 13, val func loss 0.15720060467720032\n",
      "\n",
      "episode 14, val func loss 0.18357998132705688\n",
      "\n",
      "episode 15, val func loss 0.18859665095806122\n",
      "\n",
      "episode 16, val func loss 0.1961241215467453\n",
      "\n",
      "Val func train loss in epoch 1:0.18180275429040194\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19584079086780548\n",
      "\n",
      "episode 2, val func loss 0.18332765996456146\n",
      "\n",
      "episode 3, val func loss 0.185914546251297\n",
      "\n",
      "episode 4, val func loss 0.18731889128684998\n",
      "\n",
      "episode 5, val func loss 0.2073909491300583\n",
      "\n",
      "episode 6, val func loss 0.1823567897081375\n",
      "\n",
      "episode 7, val func loss 0.1622025966644287\n",
      "\n",
      "episode 8, val func loss 0.1669810712337494\n",
      "\n",
      "episode 9, val func loss 0.1817939281463623\n",
      "\n",
      "episode 10, val func loss 0.15744000673294067\n",
      "\n",
      "episode 11, val func loss 0.1962561160326004\n",
      "\n",
      "episode 12, val func loss 0.18204115331172943\n",
      "\n",
      "episode 13, val func loss 0.18068578839302063\n",
      "\n",
      "episode 14, val func loss 0.16273780167102814\n",
      "\n",
      "episode 15, val func loss 0.18887287378311157\n",
      "\n",
      "episode 16, val func loss 0.18741261959075928\n",
      "\n",
      "Val func train loss in epoch 2:0.18178584892302752\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.18027575314044952\n",
      "\n",
      "episode 2, val func loss 0.1671365201473236\n",
      "\n",
      "episode 3, val func loss 0.19629636406898499\n",
      "\n",
      "episode 4, val func loss 0.16187739372253418\n",
      "\n",
      "episode 5, val func loss 0.1824101209640503\n",
      "\n",
      "episode 6, val func loss 0.18622244894504547\n",
      "\n",
      "episode 7, val func loss 0.1870301365852356\n",
      "\n",
      "episode 8, val func loss 0.18217086791992188\n",
      "\n",
      "episode 9, val func loss 0.18155018985271454\n",
      "\n",
      "episode 10, val func loss 0.16341082751750946\n",
      "\n",
      "episode 11, val func loss 0.18648956716060638\n",
      "\n",
      "episode 12, val func loss 0.18351536989212036\n",
      "\n",
      "episode 13, val func loss 0.20606224238872528\n",
      "\n",
      "episode 14, val func loss 0.18870124220848083\n",
      "\n",
      "episode 15, val func loss 0.19632045924663544\n",
      "\n",
      "episode 16, val func loss 0.15886245667934418\n",
      "\n",
      "Val func train loss in epoch 3:0.18177074752748013\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18703895807266235\n",
      "\n",
      "episode 2, val func loss 0.19593015313148499\n",
      "\n",
      "episode 3, val func loss 0.16745583713054657\n",
      "\n",
      "episode 4, val func loss 0.18251487612724304\n",
      "\n",
      "episode 5, val func loss 0.15526457130908966\n",
      "\n",
      "episode 6, val func loss 0.16252239048480988\n",
      "\n",
      "episode 7, val func loss 0.21070855855941772\n",
      "\n",
      "episode 8, val func loss 0.181143119931221\n",
      "\n",
      "episode 9, val func loss 0.18370352685451508\n",
      "\n",
      "episode 10, val func loss 0.16131609678268433\n",
      "\n",
      "episode 11, val func loss 0.18574410676956177\n",
      "\n",
      "episode 12, val func loss 0.18769897520542145\n",
      "\n",
      "episode 13, val func loss 0.18880139291286469\n",
      "\n",
      "episode 14, val func loss 0.19608819484710693\n",
      "\n",
      "episode 15, val func loss 0.1828830987215042\n",
      "\n",
      "episode 16, val func loss 0.18368779122829437\n",
      "\n",
      "Val func train loss in epoch 4:0.18203135300427675\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.18649649620056152\n",
      "\n",
      "episode 2, val func loss 0.1805296242237091\n",
      "\n",
      "episode 3, val func loss 0.20606490969657898\n",
      "\n",
      "episode 4, val func loss 0.1820070892572403\n",
      "\n",
      "episode 5, val func loss 0.16807487607002258\n",
      "\n",
      "episode 6, val func loss 0.1874711811542511\n",
      "\n",
      "episode 7, val func loss 0.1805334985256195\n",
      "\n",
      "episode 8, val func loss 0.19628643989562988\n",
      "\n",
      "episode 9, val func loss 0.1831391453742981\n",
      "\n",
      "episode 10, val func loss 0.16313256323337555\n",
      "\n",
      "episode 11, val func loss 0.18240423500537872\n",
      "\n",
      "episode 12, val func loss 0.18960049748420715\n",
      "\n",
      "episode 13, val func loss 0.18768364191055298\n",
      "\n",
      "episode 14, val func loss 0.19663769006729126\n",
      "\n",
      "episode 15, val func loss 0.16113242506980896\n",
      "\n",
      "episode 16, val func loss 0.15561430156230927\n",
      "\n",
      "Val func train loss in epoch 5:0.18167553842067719\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.187513068318367\n",
      "\n",
      "episode 2, val func loss 0.16262193024158478\n",
      "\n",
      "episode 3, val func loss 0.18337324261665344\n",
      "\n",
      "episode 4, val func loss 0.15454629063606262\n",
      "\n",
      "episode 5, val func loss 0.18694521486759186\n",
      "\n",
      "episode 6, val func loss 0.18753109872341156\n",
      "\n",
      "episode 7, val func loss 0.19678299129009247\n",
      "\n",
      "episode 8, val func loss 0.18307790160179138\n",
      "\n",
      "episode 9, val func loss 0.18195973336696625\n",
      "\n",
      "episode 10, val func loss 0.19597265124320984\n",
      "\n",
      "episode 11, val func loss 0.18876121938228607\n",
      "\n",
      "episode 12, val func loss 0.18302631378173828\n",
      "\n",
      "episode 13, val func loss 0.20426875352859497\n",
      "\n",
      "episode 14, val func loss 0.1652725785970688\n",
      "\n",
      "episode 15, val func loss 0.16874264180660248\n",
      "\n",
      "episode 16, val func loss 0.18086744844913483\n",
      "\n",
      "Val func train loss in epoch 6:0.1819539424031973\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1966964453458786\n",
      "\n",
      "episode 2, val func loss 0.19595949351787567\n",
      "\n",
      "episode 3, val func loss 0.20718471705913544\n",
      "\n",
      "episode 4, val func loss 0.16707631945610046\n",
      "\n",
      "episode 5, val func loss 0.15638063848018646\n",
      "\n",
      "episode 6, val func loss 0.16128641366958618\n",
      "\n",
      "episode 7, val func loss 0.1873825341463089\n",
      "\n",
      "episode 8, val func loss 0.1895407885313034\n",
      "\n",
      "episode 9, val func loss 0.16279485821723938\n",
      "\n",
      "episode 10, val func loss 0.18690189719200134\n",
      "\n",
      "episode 11, val func loss 0.183549165725708\n",
      "\n",
      "episode 12, val func loss 0.1876956671476364\n",
      "\n",
      "episode 13, val func loss 0.18256747722625732\n",
      "\n",
      "episode 14, val func loss 0.18043942749500275\n",
      "\n",
      "episode 15, val func loss 0.1810358315706253\n",
      "\n",
      "episode 16, val func loss 0.18266510963439941\n",
      "\n",
      "Val func train loss in epoch 7:0.18182229902595282\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16745470464229584\n",
      "\n",
      "episode 2, val func loss 0.19624188542366028\n",
      "\n",
      "episode 3, val func loss 0.16339269280433655\n",
      "\n",
      "episode 4, val func loss 0.18731440603733063\n",
      "\n",
      "episode 5, val func loss 0.15790028870105743\n",
      "\n",
      "episode 6, val func loss 0.18031638860702515\n",
      "\n",
      "episode 7, val func loss 0.18641819059848785\n",
      "\n",
      "episode 8, val func loss 0.18263496458530426\n",
      "\n",
      "episode 9, val func loss 0.1968521922826767\n",
      "\n",
      "episode 10, val func loss 0.18977874517440796\n",
      "\n",
      "episode 11, val func loss 0.20958676934242249\n",
      "\n",
      "episode 12, val func loss 0.18309623003005981\n",
      "\n",
      "episode 13, val func loss 0.18714597821235657\n",
      "\n",
      "episode 14, val func loss 0.18197110295295715\n",
      "\n",
      "episode 15, val func loss 0.18036718666553497\n",
      "\n",
      "episode 16, val func loss 0.16485315561294556\n",
      "\n",
      "Val func train loss in epoch 8:0.1822078051045537\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18024544417858124\n",
      "\n",
      "episode 2, val func loss 0.19684599339962006\n",
      "\n",
      "episode 3, val func loss 0.18248164653778076\n",
      "\n",
      "episode 4, val func loss 0.19662857055664062\n",
      "\n",
      "episode 5, val func loss 0.18753871321678162\n",
      "\n",
      "episode 6, val func loss 0.18617035448551178\n",
      "\n",
      "episode 7, val func loss 0.15610264241695404\n",
      "\n",
      "episode 8, val func loss 0.1808852106332779\n",
      "\n",
      "episode 9, val func loss 0.18367977440357208\n",
      "\n",
      "episode 10, val func loss 0.16307999193668365\n",
      "\n",
      "episode 11, val func loss 0.1678306609392166\n",
      "\n",
      "episode 12, val func loss 0.16137835383415222\n",
      "\n",
      "episode 13, val func loss 0.18940125405788422\n",
      "\n",
      "episode 14, val func loss 0.2079780101776123\n",
      "\n",
      "episode 15, val func loss 0.18760113418102264\n",
      "\n",
      "episode 16, val func loss 0.183906689286232\n",
      "\n",
      "Val func train loss in epoch 9:0.18198465276509523\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18224692344665527\n",
      "\n",
      "episode 2, val func loss 0.1651218682527542\n",
      "\n",
      "episode 3, val func loss 0.18066957592964172\n",
      "\n",
      "episode 4, val func loss 0.19590069353580475\n",
      "\n",
      "episode 5, val func loss 0.1888139545917511\n",
      "\n",
      "episode 6, val func loss 0.18735875189304352\n",
      "\n",
      "episode 7, val func loss 0.16733449697494507\n",
      "\n",
      "episode 8, val func loss 0.18701425194740295\n",
      "\n",
      "episode 9, val func loss 0.18644867837429047\n",
      "\n",
      "episode 10, val func loss 0.16179873049259186\n",
      "\n",
      "episode 11, val func loss 0.18315601348876953\n",
      "\n",
      "episode 12, val func loss 0.18256013095378876\n",
      "\n",
      "episode 13, val func loss 0.19632239639759064\n",
      "\n",
      "episode 14, val func loss 0.18167567253112793\n",
      "\n",
      "episode 15, val func loss 0.15648259222507477\n",
      "\n",
      "episode 16, val func loss 0.20702429115772247\n",
      "\n",
      "Val func train loss in epoch 10:0.1818705638870597\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1873924434185028\n",
      "\n",
      "episode 2, val func loss 0.19623592495918274\n",
      "\n",
      "episode 3, val func loss 0.18634717166423798\n",
      "\n",
      "episode 4, val func loss 0.18048825860023499\n",
      "\n",
      "episode 5, val func loss 0.20612989366054535\n",
      "\n",
      "episode 6, val func loss 0.1582498550415039\n",
      "\n",
      "episode 7, val func loss 0.16773134469985962\n",
      "\n",
      "episode 8, val func loss 0.19615957140922546\n",
      "\n",
      "episode 9, val func loss 0.1619943529367447\n",
      "\n",
      "episode 10, val func loss 0.18678726255893707\n",
      "\n",
      "episode 11, val func loss 0.18247613310813904\n",
      "\n",
      "episode 12, val func loss 0.18307584524154663\n",
      "\n",
      "episode 13, val func loss 0.1827010065317154\n",
      "\n",
      "episode 14, val func loss 0.18897823989391327\n",
      "\n",
      "episode 15, val func loss 0.1631436049938202\n",
      "\n",
      "episode 16, val func loss 0.18272633850574493\n",
      "\n",
      "Val func train loss in epoch 11:0.18191357795149088\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18847055733203888\n",
      "\n",
      "episode 2, val func loss 0.1877220869064331\n",
      "\n",
      "episode 3, val func loss 0.18328280746936798\n",
      "\n",
      "episode 4, val func loss 0.16736289858818054\n",
      "\n",
      "episode 5, val func loss 0.18234369158744812\n",
      "\n",
      "episode 6, val func loss 0.20715627074241638\n",
      "\n",
      "episode 7, val func loss 0.15702605247497559\n",
      "\n",
      "episode 8, val func loss 0.1821727305650711\n",
      "\n",
      "episode 9, val func loss 0.1866462528705597\n",
      "\n",
      "episode 10, val func loss 0.18036110699176788\n",
      "\n",
      "episode 11, val func loss 0.19609254598617554\n",
      "\n",
      "episode 12, val func loss 0.1864725798368454\n",
      "\n",
      "episode 13, val func loss 0.19598567485809326\n",
      "\n",
      "episode 14, val func loss 0.18143633008003235\n",
      "\n",
      "episode 15, val func loss 0.16200637817382812\n",
      "\n",
      "episode 16, val func loss 0.16355274617671967\n",
      "\n",
      "Val func train loss in epoch 12:0.1817556694149971\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.16190707683563232\n",
      "\n",
      "episode 2, val func loss 0.19573824107646942\n",
      "\n",
      "episode 3, val func loss 0.18625794351100922\n",
      "\n",
      "episode 4, val func loss 0.15559567511081696\n",
      "\n",
      "episode 5, val func loss 0.1830616444349289\n",
      "\n",
      "episode 6, val func loss 0.18721947073936462\n",
      "\n",
      "episode 7, val func loss 0.20890718698501587\n",
      "\n",
      "episode 8, val func loss 0.16716529428958893\n",
      "\n",
      "episode 9, val func loss 0.1631174385547638\n",
      "\n",
      "episode 10, val func loss 0.18736262619495392\n",
      "\n",
      "episode 11, val func loss 0.1825682371854782\n",
      "\n",
      "episode 12, val func loss 0.18208687007427216\n",
      "\n",
      "episode 13, val func loss 0.18864300847053528\n",
      "\n",
      "episode 14, val func loss 0.183599054813385\n",
      "\n",
      "episode 15, val func loss 0.18045510351657867\n",
      "\n",
      "episode 16, val func loss 0.19622251391410828\n",
      "\n",
      "Val func train loss in epoch 13:0.18186921160668135\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.16343966126441956\n",
      "\n",
      "episode 2, val func loss 0.16148434579372406\n",
      "\n",
      "episode 3, val func loss 0.18288904428482056\n",
      "\n",
      "episode 4, val func loss 0.1548050343990326\n",
      "\n",
      "episode 5, val func loss 0.19707322120666504\n",
      "\n",
      "episode 6, val func loss 0.19046282768249512\n",
      "\n",
      "episode 7, val func loss 0.21020951867103577\n",
      "\n",
      "episode 8, val func loss 0.19646967947483063\n",
      "\n",
      "episode 9, val func loss 0.16728997230529785\n",
      "\n",
      "episode 10, val func loss 0.18035224080085754\n",
      "\n",
      "episode 11, val func loss 0.18045076727867126\n",
      "\n",
      "episode 12, val func loss 0.18321286141872406\n",
      "\n",
      "episode 13, val func loss 0.18814170360565186\n",
      "\n",
      "episode 14, val func loss 0.18723401427268982\n",
      "\n",
      "episode 15, val func loss 0.18404197692871094\n",
      "\n",
      "episode 16, val func loss 0.18801365792751312\n",
      "\n",
      "Val func train loss in epoch 14:0.18222315795719624\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18700434267520905\n",
      "\n",
      "episode 2, val func loss 0.19623234868049622\n",
      "\n",
      "episode 3, val func loss 0.18650177121162415\n",
      "\n",
      "episode 4, val func loss 0.16745297610759735\n",
      "\n",
      "episode 5, val func loss 0.19626951217651367\n",
      "\n",
      "episode 6, val func loss 0.18758749961853027\n",
      "\n",
      "episode 7, val func loss 0.18884821236133575\n",
      "\n",
      "episode 8, val func loss 0.18112845718860626\n",
      "\n",
      "episode 9, val func loss 0.20598308742046356\n",
      "\n",
      "episode 10, val func loss 0.18386492133140564\n",
      "\n",
      "episode 11, val func loss 0.18322932720184326\n",
      "\n",
      "episode 12, val func loss 0.1811068207025528\n",
      "\n",
      "episode 13, val func loss 0.18244647979736328\n",
      "\n",
      "episode 14, val func loss 0.16330695152282715\n",
      "\n",
      "episode 15, val func loss 0.16399823129177094\n",
      "\n",
      "episode 16, val func loss 0.15562982857227325\n",
      "\n",
      "Val func train loss in epoch 15:0.1819119229912758\n",
      "***********************TIME WAS 5.004026484489441 min*****************************\n",
      "\n",
      "**********************ROUND 142 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.015980910509824753\n",
      "\n",
      "episode 2, policy loss -0.07476872205734253\n",
      "\n",
      "episode 3, policy loss -0.07831104844808578\n",
      "\n",
      "episode 4, policy loss -0.06743472814559937\n",
      "\n",
      "episode 5, policy loss -0.0885259360074997\n",
      "\n",
      "episode 6, policy loss -0.11313463002443314\n",
      "\n",
      "episode 7, policy loss -0.07827917486429214\n",
      "\n",
      "episode 8, policy loss -0.08003271371126175\n",
      "\n",
      "episode 9, policy loss -0.14793583750724792\n",
      "\n",
      "episode 10, policy loss -0.11922787129878998\n",
      "\n",
      "episode 11, policy loss -0.11013893038034439\n",
      "\n",
      "episode 12, policy loss -0.07638495415449142\n",
      "\n",
      "episode 13, policy loss -0.09179846942424774\n",
      "\n",
      "episode 14, policy loss -0.0540410578250885\n",
      "\n",
      "episode 15, policy loss -0.13885396718978882\n",
      "\n",
      "episode 16, policy loss -0.058460768312215805\n",
      "\n",
      "Policy train loss in epoch 0:-0.08708185749128461\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.11158714443445206\n",
      "\n",
      "episode 2, policy loss -0.11308776587247849\n",
      "\n",
      "episode 3, policy loss -0.08200578391551971\n",
      "\n",
      "episode 4, policy loss -0.14162255823612213\n",
      "\n",
      "episode 5, policy loss -0.08173810690641403\n",
      "\n",
      "episode 6, policy loss -0.07926145941019058\n",
      "\n",
      "episode 7, policy loss -0.054345909506082535\n",
      "\n",
      "episode 8, policy loss -0.12203110009431839\n",
      "\n",
      "episode 9, policy loss -0.08231377601623535\n",
      "\n",
      "episode 10, policy loss -0.08474865555763245\n",
      "\n",
      "episode 11, policy loss -0.05644761398434639\n",
      "\n",
      "episode 12, policy loss -0.023899894207715988\n",
      "\n",
      "episode 13, policy loss -0.08660126477479935\n",
      "\n",
      "episode 14, policy loss -0.14946600794792175\n",
      "\n",
      "episode 15, policy loss -0.09352639317512512\n",
      "\n",
      "episode 16, policy loss -0.07016919553279877\n",
      "\n",
      "Policy train loss in epoch 1:-0.08955328934825957\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.15115515887737274\n",
      "\n",
      "episode 2, policy loss -0.08411434292793274\n",
      "\n",
      "episode 3, policy loss -0.08219262212514877\n",
      "\n",
      "episode 4, policy loss -0.11424913257360458\n",
      "\n",
      "episode 5, policy loss -0.12139194458723068\n",
      "\n",
      "episode 6, policy loss -0.054333023726940155\n",
      "\n",
      "episode 7, policy loss -0.09346882253885269\n",
      "\n",
      "episode 8, policy loss -0.059596795588731766\n",
      "\n",
      "episode 9, policy loss -0.08301670849323273\n",
      "\n",
      "episode 10, policy loss -0.07845860719680786\n",
      "\n",
      "episode 11, policy loss -0.11308476328849792\n",
      "\n",
      "episode 12, policy loss -0.0684955045580864\n",
      "\n",
      "episode 13, policy loss -0.08766352385282516\n",
      "\n",
      "episode 14, policy loss -0.0810752883553505\n",
      "\n",
      "episode 15, policy loss -0.14242041110992432\n",
      "\n",
      "episode 16, policy loss -0.024667592719197273\n",
      "\n",
      "Policy train loss in epoch 2:-0.08996151515748352\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.08432922512292862\n",
      "\n",
      "episode 2, policy loss -0.15201622247695923\n",
      "\n",
      "episode 3, policy loss -0.08196041733026505\n",
      "\n",
      "episode 4, policy loss -0.09597285836935043\n",
      "\n",
      "episode 5, policy loss -0.024324413388967514\n",
      "\n",
      "episode 6, policy loss -0.08362548053264618\n",
      "\n",
      "episode 7, policy loss -0.05479877442121506\n",
      "\n",
      "episode 8, policy loss -0.05961034819483757\n",
      "\n",
      "episode 9, policy loss -0.14272147417068481\n",
      "\n",
      "episode 10, policy loss -0.08571083843708038\n",
      "\n",
      "episode 11, policy loss -0.11540208756923676\n",
      "\n",
      "episode 12, policy loss -0.06963168829679489\n",
      "\n",
      "episode 13, policy loss -0.12176105380058289\n",
      "\n",
      "episode 14, policy loss -0.1149546205997467\n",
      "\n",
      "episode 15, policy loss -0.07921675592660904\n",
      "\n",
      "episode 16, policy loss -0.08708514273166656\n",
      "\n",
      "Policy train loss in epoch 3:-0.09082008758559823\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.14390210807323456\n",
      "\n",
      "episode 2, val func loss 0.18421778082847595\n",
      "\n",
      "episode 3, val func loss 0.20031733810901642\n",
      "\n",
      "episode 4, val func loss 0.2288169264793396\n",
      "\n",
      "episode 5, val func loss 0.18736371397972107\n",
      "\n",
      "episode 6, val func loss 0.22689120471477509\n",
      "\n",
      "episode 7, val func loss 0.19317971169948578\n",
      "\n",
      "episode 8, val func loss 0.20340867340564728\n",
      "\n",
      "episode 9, val func loss 0.19910690188407898\n",
      "\n",
      "episode 10, val func loss 0.20651081204414368\n",
      "\n",
      "episode 11, val func loss 0.19520264863967896\n",
      "\n",
      "episode 12, val func loss 0.18965403735637665\n",
      "\n",
      "episode 13, val func loss 0.18438683450222015\n",
      "\n",
      "episode 14, val func loss 0.1901417225599289\n",
      "\n",
      "episode 15, val func loss 0.18938052654266357\n",
      "\n",
      "episode 16, val func loss 0.17708389461040497\n",
      "\n",
      "Val func train loss in epoch 0:0.19372280221432447\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1818055361509323\n",
      "\n",
      "episode 2, val func loss 0.19822575151920319\n",
      "\n",
      "episode 3, val func loss 0.21002690494060516\n",
      "\n",
      "episode 4, val func loss 0.1984628289937973\n",
      "\n",
      "episode 5, val func loss 0.20606696605682373\n",
      "\n",
      "episode 6, val func loss 0.19022966921329498\n",
      "\n",
      "episode 7, val func loss 0.15143975615501404\n",
      "\n",
      "episode 8, val func loss 0.1941152662038803\n",
      "\n",
      "episode 9, val func loss 0.18197263777256012\n",
      "\n",
      "episode 10, val func loss 0.1934627890586853\n",
      "\n",
      "episode 11, val func loss 0.2215505689382553\n",
      "\n",
      "episode 12, val func loss 0.1769161820411682\n",
      "\n",
      "episode 13, val func loss 0.1876710057258606\n",
      "\n",
      "episode 14, val func loss 0.1969648003578186\n",
      "\n",
      "episode 15, val func loss 0.18708595633506775\n",
      "\n",
      "episode 16, val func loss 0.2283841222524643\n",
      "\n",
      "Val func train loss in epoch 1:0.19402379635721445\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.1882234662771225\n",
      "\n",
      "episode 2, val func loss 0.19301621615886688\n",
      "\n",
      "episode 3, val func loss 0.190176859498024\n",
      "\n",
      "episode 4, val func loss 0.19858285784721375\n",
      "\n",
      "episode 5, val func loss 0.147860586643219\n",
      "\n",
      "episode 6, val func loss 0.18675626814365387\n",
      "\n",
      "episode 7, val func loss 0.2062528282403946\n",
      "\n",
      "episode 8, val func loss 0.18801453709602356\n",
      "\n",
      "episode 9, val func loss 0.18054570257663727\n",
      "\n",
      "episode 10, val func loss 0.2245073765516281\n",
      "\n",
      "episode 11, val func loss 0.22100983560085297\n",
      "\n",
      "episode 12, val func loss 0.17993254959583282\n",
      "\n",
      "episode 13, val func loss 0.19776323437690735\n",
      "\n",
      "episode 14, val func loss 0.1924618035554886\n",
      "\n",
      "episode 15, val func loss 0.1778521090745926\n",
      "\n",
      "episode 16, val func loss 0.20454834401607513\n",
      "\n",
      "Val func train loss in epoch 2:0.1923440359532833\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.17779678106307983\n",
      "\n",
      "episode 2, val func loss 0.18006250262260437\n",
      "\n",
      "episode 3, val func loss 0.18827563524246216\n",
      "\n",
      "episode 4, val func loss 0.1862962543964386\n",
      "\n",
      "episode 5, val func loss 0.22660863399505615\n",
      "\n",
      "episode 6, val func loss 0.1968652456998825\n",
      "\n",
      "episode 7, val func loss 0.2067158818244934\n",
      "\n",
      "episode 8, val func loss 0.19324734807014465\n",
      "\n",
      "episode 9, val func loss 0.19068001210689545\n",
      "\n",
      "episode 10, val func loss 0.19231928884983063\n",
      "\n",
      "episode 11, val func loss 0.22011439502239227\n",
      "\n",
      "episode 12, val func loss 0.20360982418060303\n",
      "\n",
      "episode 13, val func loss 0.19895106554031372\n",
      "\n",
      "episode 14, val func loss 0.18168561160564423\n",
      "\n",
      "episode 15, val func loss 0.18911531567573547\n",
      "\n",
      "episode 16, val func loss 0.14941199123859406\n",
      "\n",
      "Val func train loss in epoch 3:0.19260973669588566\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.18085305392742157\n",
      "\n",
      "episode 2, val func loss 0.220044806599617\n",
      "\n",
      "episode 3, val func loss 0.1985272914171219\n",
      "\n",
      "episode 4, val func loss 0.19072003662586212\n",
      "\n",
      "episode 5, val func loss 0.1770925521850586\n",
      "\n",
      "episode 6, val func loss 0.20583128929138184\n",
      "\n",
      "episode 7, val func loss 0.14540065824985504\n",
      "\n",
      "episode 8, val func loss 0.19240987300872803\n",
      "\n",
      "episode 9, val func loss 0.19671528041362762\n",
      "\n",
      "episode 10, val func loss 0.18000277876853943\n",
      "\n",
      "episode 11, val func loss 0.18780407309532166\n",
      "\n",
      "episode 12, val func loss 0.19320780038833618\n",
      "\n",
      "episode 13, val func loss 0.18662187457084656\n",
      "\n",
      "episode 14, val func loss 0.20764745771884918\n",
      "\n",
      "episode 15, val func loss 0.18838855624198914\n",
      "\n",
      "episode 16, val func loss 0.2256702035665512\n",
      "\n",
      "Val func train loss in epoch 4:0.1923085991293192\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.19222398102283478\n",
      "\n",
      "episode 2, val func loss 0.22053876519203186\n",
      "\n",
      "episode 3, val func loss 0.18690422177314758\n",
      "\n",
      "episode 4, val func loss 0.14881916344165802\n",
      "\n",
      "episode 5, val func loss 0.19374582171440125\n",
      "\n",
      "episode 6, val func loss 0.19828768074512482\n",
      "\n",
      "episode 7, val func loss 0.18064291775226593\n",
      "\n",
      "episode 8, val func loss 0.17824436724185944\n",
      "\n",
      "episode 9, val func loss 0.19039392471313477\n",
      "\n",
      "episode 10, val func loss 0.22509914636611938\n",
      "\n",
      "episode 11, val func loss 0.1877388209104538\n",
      "\n",
      "episode 12, val func loss 0.18026256561279297\n",
      "\n",
      "episode 13, val func loss 0.19854885339736938\n",
      "\n",
      "episode 14, val func loss 0.20542843639850616\n",
      "\n",
      "episode 15, val func loss 0.18831871449947357\n",
      "\n",
      "episode 16, val func loss 0.20633840560913086\n",
      "\n",
      "Val func train loss in epoch 5:0.19259598664939404\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.22078688442707062\n",
      "\n",
      "episode 2, val func loss 0.18782711029052734\n",
      "\n",
      "episode 3, val func loss 0.19862191379070282\n",
      "\n",
      "episode 4, val func loss 0.18124663829803467\n",
      "\n",
      "episode 5, val func loss 0.19273348152637482\n",
      "\n",
      "episode 6, val func loss 0.1803894340991974\n",
      "\n",
      "episode 7, val func loss 0.20363101363182068\n",
      "\n",
      "episode 8, val func loss 0.1932721734046936\n",
      "\n",
      "episode 9, val func loss 0.18844375014305115\n",
      "\n",
      "episode 10, val func loss 0.1777353733778\n",
      "\n",
      "episode 11, val func loss 0.19710880517959595\n",
      "\n",
      "episode 12, val func loss 0.2068794071674347\n",
      "\n",
      "episode 13, val func loss 0.22569893300533295\n",
      "\n",
      "episode 14, val func loss 0.18645089864730835\n",
      "\n",
      "episode 15, val func loss 0.14579275250434875\n",
      "\n",
      "episode 16, val func loss 0.19092294573783875\n",
      "\n",
      "Val func train loss in epoch 6:0.19234634470194578\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1884526014328003\n",
      "\n",
      "episode 2, val func loss 0.1910618543624878\n",
      "\n",
      "episode 3, val func loss 0.20648567378520966\n",
      "\n",
      "episode 4, val func loss 0.14692451059818268\n",
      "\n",
      "episode 5, val func loss 0.1799452006816864\n",
      "\n",
      "episode 6, val func loss 0.19731849431991577\n",
      "\n",
      "episode 7, val func loss 0.1877421885728836\n",
      "\n",
      "episode 8, val func loss 0.22128839790821075\n",
      "\n",
      "episode 9, val func loss 0.18628716468811035\n",
      "\n",
      "episode 10, val func loss 0.22490790486335754\n",
      "\n",
      "episode 11, val func loss 0.20464208722114563\n",
      "\n",
      "episode 12, val func loss 0.1982148289680481\n",
      "\n",
      "episode 13, val func loss 0.17877769470214844\n",
      "\n",
      "episode 14, val func loss 0.1936149150133133\n",
      "\n",
      "episode 15, val func loss 0.19273459911346436\n",
      "\n",
      "episode 16, val func loss 0.18100684881210327\n",
      "\n",
      "Val func train loss in epoch 7:0.19246281031519175\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.19837021827697754\n",
      "\n",
      "episode 2, val func loss 0.1802125871181488\n",
      "\n",
      "episode 3, val func loss 0.19030696153640747\n",
      "\n",
      "episode 4, val func loss 0.18783773481845856\n",
      "\n",
      "episode 5, val func loss 0.19741569459438324\n",
      "\n",
      "episode 6, val func loss 0.19225841760635376\n",
      "\n",
      "episode 7, val func loss 0.2071262001991272\n",
      "\n",
      "episode 8, val func loss 0.1799842268228531\n",
      "\n",
      "episode 9, val func loss 0.19304512441158295\n",
      "\n",
      "episode 10, val func loss 0.20634712278842926\n",
      "\n",
      "episode 11, val func loss 0.22185683250427246\n",
      "\n",
      "episode 12, val func loss 0.18847405910491943\n",
      "\n",
      "episode 13, val func loss 0.18648898601531982\n",
      "\n",
      "episode 14, val func loss 0.17821532487869263\n",
      "\n",
      "episode 15, val func loss 0.14736133813858032\n",
      "\n",
      "episode 16, val func loss 0.22369331121444702\n",
      "\n",
      "Val func train loss in epoch 8:0.1924371337518096\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.19747966527938843\n",
      "\n",
      "episode 2, val func loss 0.20611152052879333\n",
      "\n",
      "episode 3, val func loss 0.2235429286956787\n",
      "\n",
      "episode 4, val func loss 0.19851720333099365\n",
      "\n",
      "episode 5, val func loss 0.180802121758461\n",
      "\n",
      "episode 6, val func loss 0.1811668872833252\n",
      "\n",
      "episode 7, val func loss 0.1934492141008377\n",
      "\n",
      "episode 8, val func loss 0.2040998488664627\n",
      "\n",
      "episode 9, val func loss 0.17833222448825836\n",
      "\n",
      "episode 10, val func loss 0.220412015914917\n",
      "\n",
      "episode 11, val func loss 0.18853722512722015\n",
      "\n",
      "episode 12, val func loss 0.14654025435447693\n",
      "\n",
      "episode 13, val func loss 0.1864033341407776\n",
      "\n",
      "episode 14, val func loss 0.19100713729858398\n",
      "\n",
      "episode 15, val func loss 0.1875232607126236\n",
      "\n",
      "episode 16, val func loss 0.19205087423324585\n",
      "\n",
      "Val func train loss in epoch 9:0.19224848225712776\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20610485970973969\n",
      "\n",
      "episode 2, val func loss 0.1456453949213028\n",
      "\n",
      "episode 3, val func loss 0.1986997425556183\n",
      "\n",
      "episode 4, val func loss 0.18836364150047302\n",
      "\n",
      "episode 5, val func loss 0.17926020920276642\n",
      "\n",
      "episode 6, val func loss 0.18635690212249756\n",
      "\n",
      "episode 7, val func loss 0.18759632110595703\n",
      "\n",
      "episode 8, val func loss 0.1912098526954651\n",
      "\n",
      "episode 9, val func loss 0.18016527593135834\n",
      "\n",
      "episode 10, val func loss 0.19706453382968903\n",
      "\n",
      "episode 11, val func loss 0.17732056975364685\n",
      "\n",
      "episode 12, val func loss 0.22514833509922028\n",
      "\n",
      "episode 13, val func loss 0.22131356596946716\n",
      "\n",
      "episode 14, val func loss 0.20619426667690277\n",
      "\n",
      "episode 15, val func loss 0.19257541000843048\n",
      "\n",
      "episode 16, val func loss 0.19360817968845367\n",
      "\n",
      "Val func train loss in epoch 10:0.19228919129818678\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19812028110027313\n",
      "\n",
      "episode 2, val func loss 0.1892934888601303\n",
      "\n",
      "episode 3, val func loss 0.1886207014322281\n",
      "\n",
      "episode 4, val func loss 0.18001964688301086\n",
      "\n",
      "episode 5, val func loss 0.17786195874214172\n",
      "\n",
      "episode 6, val func loss 0.19850295782089233\n",
      "\n",
      "episode 7, val func loss 0.22600114345550537\n",
      "\n",
      "episode 8, val func loss 0.19143971800804138\n",
      "\n",
      "episode 9, val func loss 0.18642836809158325\n",
      "\n",
      "episode 10, val func loss 0.20537179708480835\n",
      "\n",
      "episode 11, val func loss 0.192189559340477\n",
      "\n",
      "episode 12, val func loss 0.22066742181777954\n",
      "\n",
      "episode 13, val func loss 0.19350562989711761\n",
      "\n",
      "episode 14, val func loss 0.20601792633533478\n",
      "\n",
      "episode 15, val func loss 0.14905676245689392\n",
      "\n",
      "episode 16, val func loss 0.1815241277217865\n",
      "\n",
      "Val func train loss in epoch 11:0.19278884306550026\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19285252690315247\n",
      "\n",
      "episode 2, val func loss 0.2037346065044403\n",
      "\n",
      "episode 3, val func loss 0.20616838335990906\n",
      "\n",
      "episode 4, val func loss 0.1866341531276703\n",
      "\n",
      "episode 5, val func loss 0.18057937920093536\n",
      "\n",
      "episode 6, val func loss 0.17806226015090942\n",
      "\n",
      "episode 7, val func loss 0.19295452535152435\n",
      "\n",
      "episode 8, val func loss 0.19672785699367523\n",
      "\n",
      "episode 9, val func loss 0.14531545341014862\n",
      "\n",
      "episode 10, val func loss 0.1991751343011856\n",
      "\n",
      "episode 11, val func loss 0.1887189894914627\n",
      "\n",
      "episode 12, val func loss 0.2240315079689026\n",
      "\n",
      "episode 13, val func loss 0.17876583337783813\n",
      "\n",
      "episode 14, val func loss 0.18786583840847015\n",
      "\n",
      "episode 15, val func loss 0.19184647500514984\n",
      "\n",
      "episode 16, val func loss 0.2244773507118225\n",
      "\n",
      "Val func train loss in epoch 12:0.1923693921416998\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18941357731819153\n",
      "\n",
      "episode 2, val func loss 0.220951646566391\n",
      "\n",
      "episode 3, val func loss 0.20090866088867188\n",
      "\n",
      "episode 4, val func loss 0.2198724001646042\n",
      "\n",
      "episode 5, val func loss 0.18962091207504272\n",
      "\n",
      "episode 6, val func loss 0.2007548063993454\n",
      "\n",
      "episode 7, val func loss 0.18230441212654114\n",
      "\n",
      "episode 8, val func loss 0.20596206188201904\n",
      "\n",
      "episode 9, val func loss 0.19224487245082855\n",
      "\n",
      "episode 10, val func loss 0.14586539566516876\n",
      "\n",
      "episode 11, val func loss 0.19310209155082703\n",
      "\n",
      "episode 12, val func loss 0.17645177245140076\n",
      "\n",
      "episode 13, val func loss 0.1882622390985489\n",
      "\n",
      "episode 14, val func loss 0.20979852974414825\n",
      "\n",
      "episode 15, val func loss 0.17889678478240967\n",
      "\n",
      "episode 16, val func loss 0.1869344264268875\n",
      "\n",
      "Val func train loss in epoch 13:0.19258403684943914\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.1922866553068161\n",
      "\n",
      "episode 2, val func loss 0.22036100924015045\n",
      "\n",
      "episode 3, val func loss 0.20642469823360443\n",
      "\n",
      "episode 4, val func loss 0.19614271819591522\n",
      "\n",
      "episode 5, val func loss 0.1891888827085495\n",
      "\n",
      "episode 6, val func loss 0.19860728085041046\n",
      "\n",
      "episode 7, val func loss 0.1884271800518036\n",
      "\n",
      "episode 8, val func loss 0.18660514056682587\n",
      "\n",
      "episode 9, val func loss 0.17704661190509796\n",
      "\n",
      "episode 10, val func loss 0.17898787558078766\n",
      "\n",
      "episode 11, val func loss 0.22832298278808594\n",
      "\n",
      "episode 12, val func loss 0.18014520406723022\n",
      "\n",
      "episode 13, val func loss 0.18781135976314545\n",
      "\n",
      "episode 14, val func loss 0.14528805017471313\n",
      "\n",
      "episode 15, val func loss 0.2059330940246582\n",
      "\n",
      "episode 16, val func loss 0.1970694661140442\n",
      "\n",
      "Val func train loss in epoch 14:0.1924155130982399\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19314660131931305\n",
      "\n",
      "episode 2, val func loss 0.20654085278511047\n",
      "\n",
      "episode 3, val func loss 0.18072858452796936\n",
      "\n",
      "episode 4, val func loss 0.14724023640155792\n",
      "\n",
      "episode 5, val func loss 0.2239186316728592\n",
      "\n",
      "episode 6, val func loss 0.1883954554796219\n",
      "\n",
      "episode 7, val func loss 0.19741207361221313\n",
      "\n",
      "episode 8, val func loss 0.17798863351345062\n",
      "\n",
      "episode 9, val func loss 0.1876644492149353\n",
      "\n",
      "episode 10, val func loss 0.1907070428133011\n",
      "\n",
      "episode 11, val func loss 0.17952881753444672\n",
      "\n",
      "episode 12, val func loss 0.19831189513206482\n",
      "\n",
      "episode 13, val func loss 0.18658845126628876\n",
      "\n",
      "episode 14, val func loss 0.20562031865119934\n",
      "\n",
      "episode 15, val func loss 0.22135262191295624\n",
      "\n",
      "episode 16, val func loss 0.1923065036535263\n",
      "\n",
      "Val func train loss in epoch 15:0.1923406980931759\n",
      "***********************TIME WAS 5.008050811290741 min*****************************\n",
      "\n",
      "**********************ROUND 143 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.00237280479632318\n",
      "\n",
      "episode 2, policy loss -0.020267564803361893\n",
      "\n",
      "episode 3, policy loss 0.012873014435172081\n",
      "\n",
      "episode 4, policy loss 0.03631783649325371\n",
      "\n",
      "episode 5, policy loss -0.05091996490955353\n",
      "\n",
      "episode 6, policy loss -0.027667906135320663\n",
      "\n",
      "episode 7, policy loss -0.05254914611577988\n",
      "\n",
      "episode 8, policy loss -0.10061971098184586\n",
      "\n",
      "episode 9, policy loss -0.005684998817741871\n",
      "\n",
      "episode 10, policy loss -0.025517521426081657\n",
      "\n",
      "episode 11, policy loss -0.07254813611507416\n",
      "\n",
      "episode 12, policy loss 0.014714800752699375\n",
      "\n",
      "episode 13, policy loss -0.026733286678791046\n",
      "\n",
      "episode 14, policy loss -0.05251709371805191\n",
      "\n",
      "episode 15, policy loss 0.013412096537649632\n",
      "\n",
      "episode 16, policy loss 0.016910791397094727\n",
      "\n",
      "Policy train loss in epoch 0:-0.021448099680128507\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.03139141574501991\n",
      "\n",
      "episode 2, policy loss -0.025614110752940178\n",
      "\n",
      "episode 3, policy loss -0.00642125541344285\n",
      "\n",
      "episode 4, policy loss 0.0163619052618742\n",
      "\n",
      "episode 5, policy loss -0.051193542778491974\n",
      "\n",
      "episode 6, policy loss -0.051241837441921234\n",
      "\n",
      "episode 7, policy loss -0.028626132756471634\n",
      "\n",
      "episode 8, policy loss -0.051863834261894226\n",
      "\n",
      "episode 9, policy loss -0.02382853627204895\n",
      "\n",
      "episode 10, policy loss -0.1004447415471077\n",
      "\n",
      "episode 11, policy loss 0.008256903849542141\n",
      "\n",
      "episode 12, policy loss -0.014714336022734642\n",
      "\n",
      "episode 13, policy loss 0.013493519276380539\n",
      "\n",
      "episode 14, policy loss 0.01378021202981472\n",
      "\n",
      "episode 15, policy loss -0.07292796671390533\n",
      "\n",
      "episode 16, policy loss -0.02770959958434105\n",
      "\n",
      "Policy train loss in epoch 1:-0.023206371086416766\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.055102936923503876\n",
      "\n",
      "episode 2, policy loss -0.052134230732917786\n",
      "\n",
      "episode 3, policy loss -0.02917596325278282\n",
      "\n",
      "episode 4, policy loss -0.02789877913892269\n",
      "\n",
      "episode 5, policy loss 0.030385274440050125\n",
      "\n",
      "episode 6, policy loss -0.00805952399969101\n",
      "\n",
      "episode 7, policy loss 0.0147078363224864\n",
      "\n",
      "episode 8, policy loss -0.1013338640332222\n",
      "\n",
      "episode 9, policy loss -0.07259736210107803\n",
      "\n",
      "episode 10, policy loss 0.008559120818972588\n",
      "\n",
      "episode 11, policy loss -0.027849022299051285\n",
      "\n",
      "episode 12, policy loss 0.014359396882355213\n",
      "\n",
      "episode 13, policy loss -0.015366940759122372\n",
      "\n",
      "episode 14, policy loss 0.013010792434215546\n",
      "\n",
      "episode 15, policy loss -0.05084484815597534\n",
      "\n",
      "episode 16, policy loss -0.027436694130301476\n",
      "\n",
      "Policy train loss in epoch 2:-0.024173609039280564\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.05574147030711174\n",
      "\n",
      "episode 2, policy loss -0.029051756486296654\n",
      "\n",
      "episode 3, policy loss 0.01278260163962841\n",
      "\n",
      "episode 4, policy loss -0.02828928641974926\n",
      "\n",
      "episode 5, policy loss 0.013347950764000416\n",
      "\n",
      "episode 6, policy loss -0.02805974707007408\n",
      "\n",
      "episode 7, policy loss -0.05319259688258171\n",
      "\n",
      "episode 8, policy loss 0.007252309005707502\n",
      "\n",
      "episode 9, policy loss 0.014062031172215939\n",
      "\n",
      "episode 10, policy loss -0.008630921132862568\n",
      "\n",
      "episode 11, policy loss -0.052664902061223984\n",
      "\n",
      "episode 12, policy loss -0.0729864165186882\n",
      "\n",
      "episode 13, policy loss -0.1015564352273941\n",
      "\n",
      "episode 14, policy loss -0.01518797967582941\n",
      "\n",
      "episode 15, policy loss 0.03075546771287918\n",
      "\n",
      "episode 16, policy loss -0.028782054781913757\n",
      "\n",
      "Policy train loss in epoch 3:-0.024746450391830876\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.15830260515213013\n",
      "\n",
      "episode 2, val func loss 0.1973835527896881\n",
      "\n",
      "episode 3, val func loss 0.1798967868089676\n",
      "\n",
      "episode 4, val func loss 0.2185274213552475\n",
      "\n",
      "episode 5, val func loss 0.16914333403110504\n",
      "\n",
      "episode 6, val func loss 0.17367030680179596\n",
      "\n",
      "episode 7, val func loss 0.24285490810871124\n",
      "\n",
      "episode 8, val func loss 0.17544147372245789\n",
      "\n",
      "episode 9, val func loss 0.19065284729003906\n",
      "\n",
      "episode 10, val func loss 0.19340981543064117\n",
      "\n",
      "episode 11, val func loss 0.17484420537948608\n",
      "\n",
      "episode 12, val func loss 0.18398453295230865\n",
      "\n",
      "episode 13, val func loss 0.1942170262336731\n",
      "\n",
      "episode 14, val func loss 0.17387188971042633\n",
      "\n",
      "episode 15, val func loss 0.1804467737674713\n",
      "\n",
      "episode 16, val func loss 0.20664994418621063\n",
      "\n",
      "Val func train loss in epoch 0:0.1883310889825225\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.19745689630508423\n",
      "\n",
      "episode 2, val func loss 0.17507250607013702\n",
      "\n",
      "episode 3, val func loss 0.18068081140518188\n",
      "\n",
      "episode 4, val func loss 0.24506568908691406\n",
      "\n",
      "episode 5, val func loss 0.193396657705307\n",
      "\n",
      "episode 6, val func loss 0.1572011113166809\n",
      "\n",
      "episode 7, val func loss 0.1734544336795807\n",
      "\n",
      "episode 8, val func loss 0.21871866285800934\n",
      "\n",
      "episode 9, val func loss 0.17530599236488342\n",
      "\n",
      "episode 10, val func loss 0.19378376007080078\n",
      "\n",
      "episode 11, val func loss 0.20606903731822968\n",
      "\n",
      "episode 12, val func loss 0.18066103756427765\n",
      "\n",
      "episode 13, val func loss 0.1677507609128952\n",
      "\n",
      "episode 14, val func loss 0.18432949483394623\n",
      "\n",
      "episode 15, val func loss 0.17524951696395874\n",
      "\n",
      "episode 16, val func loss 0.19107946753501892\n",
      "\n",
      "Val func train loss in epoch 1:0.1884547397494316\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18102088570594788\n",
      "\n",
      "episode 2, val func loss 0.17236651480197906\n",
      "\n",
      "episode 3, val func loss 0.17949533462524414\n",
      "\n",
      "episode 4, val func loss 0.22187572717666626\n",
      "\n",
      "episode 5, val func loss 0.17496271431446075\n",
      "\n",
      "episode 6, val func loss 0.17502227425575256\n",
      "\n",
      "episode 7, val func loss 0.1666090488433838\n",
      "\n",
      "episode 8, val func loss 0.1912277489900589\n",
      "\n",
      "episode 9, val func loss 0.17153850197792053\n",
      "\n",
      "episode 10, val func loss 0.1974908411502838\n",
      "\n",
      "episode 11, val func loss 0.20707358419895172\n",
      "\n",
      "episode 12, val func loss 0.24521003663539886\n",
      "\n",
      "episode 13, val func loss 0.19347093999385834\n",
      "\n",
      "episode 14, val func loss 0.15780992805957794\n",
      "\n",
      "episode 15, val func loss 0.1937265396118164\n",
      "\n",
      "episode 16, val func loss 0.18424466252326965\n",
      "\n",
      "Val func train loss in epoch 2:0.18832158017903566\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.19754980504512787\n",
      "\n",
      "episode 2, val func loss 0.1704363226890564\n",
      "\n",
      "episode 3, val func loss 0.19073379039764404\n",
      "\n",
      "episode 4, val func loss 0.21863099932670593\n",
      "\n",
      "episode 5, val func loss 0.17991352081298828\n",
      "\n",
      "episode 6, val func loss 0.19367022812366486\n",
      "\n",
      "episode 7, val func loss 0.17530113458633423\n",
      "\n",
      "episode 8, val func loss 0.17323264479637146\n",
      "\n",
      "episode 9, val func loss 0.17481082677841187\n",
      "\n",
      "episode 10, val func loss 0.19392095506191254\n",
      "\n",
      "episode 11, val func loss 0.17937436699867249\n",
      "\n",
      "episode 12, val func loss 0.1848757266998291\n",
      "\n",
      "episode 13, val func loss 0.20760120451450348\n",
      "\n",
      "episode 14, val func loss 0.17489565908908844\n",
      "\n",
      "episode 15, val func loss 0.1555490493774414\n",
      "\n",
      "episode 16, val func loss 0.24722112715244293\n",
      "\n",
      "Val func train loss in epoch 3:0.1886073350906372\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17953814566135406\n",
      "\n",
      "episode 2, val func loss 0.1718459129333496\n",
      "\n",
      "episode 3, val func loss 0.1750294268131256\n",
      "\n",
      "episode 4, val func loss 0.15616022050380707\n",
      "\n",
      "episode 5, val func loss 0.2453615814447403\n",
      "\n",
      "episode 6, val func loss 0.1971806287765503\n",
      "\n",
      "episode 7, val func loss 0.17496834695339203\n",
      "\n",
      "episode 8, val func loss 0.16779279708862305\n",
      "\n",
      "episode 9, val func loss 0.1905396729707718\n",
      "\n",
      "episode 10, val func loss 0.1841346174478531\n",
      "\n",
      "episode 11, val func loss 0.21903344988822937\n",
      "\n",
      "episode 12, val func loss 0.19307027757167816\n",
      "\n",
      "episode 13, val func loss 0.2061862200498581\n",
      "\n",
      "episode 14, val func loss 0.19355995953083038\n",
      "\n",
      "episode 15, val func loss 0.1799445003271103\n",
      "\n",
      "episode 16, val func loss 0.17707306146621704\n",
      "\n",
      "Val func train loss in epoch 4:0.18821367621421814\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17574933171272278\n",
      "\n",
      "episode 2, val func loss 0.19763213396072388\n",
      "\n",
      "episode 3, val func loss 0.16868659853935242\n",
      "\n",
      "episode 4, val func loss 0.18005794286727905\n",
      "\n",
      "episode 5, val func loss 0.1937004178762436\n",
      "\n",
      "episode 6, val func loss 0.15602202713489532\n",
      "\n",
      "episode 7, val func loss 0.19491729140281677\n",
      "\n",
      "episode 8, val func loss 0.2209656834602356\n",
      "\n",
      "episode 9, val func loss 0.17192421853542328\n",
      "\n",
      "episode 10, val func loss 0.1845073699951172\n",
      "\n",
      "episode 11, val func loss 0.1748703122138977\n",
      "\n",
      "episode 12, val func loss 0.1729436218738556\n",
      "\n",
      "episode 13, val func loss 0.17974083125591278\n",
      "\n",
      "episode 14, val func loss 0.246359184384346\n",
      "\n",
      "episode 15, val func loss 0.2069736123085022\n",
      "\n",
      "episode 16, val func loss 0.19085709750652313\n",
      "\n",
      "Val func train loss in epoch 5:0.18849422968924046\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.18410535156726837\n",
      "\n",
      "episode 2, val func loss 0.17447136342525482\n",
      "\n",
      "episode 3, val func loss 0.24270401895046234\n",
      "\n",
      "episode 4, val func loss 0.1905229389667511\n",
      "\n",
      "episode 5, val func loss 0.18161241710186005\n",
      "\n",
      "episode 6, val func loss 0.21846948564052582\n",
      "\n",
      "episode 7, val func loss 0.19379504024982452\n",
      "\n",
      "episode 8, val func loss 0.17666767537593842\n",
      "\n",
      "episode 9, val func loss 0.19737911224365234\n",
      "\n",
      "episode 10, val func loss 0.1927623748779297\n",
      "\n",
      "episode 11, val func loss 0.1582818627357483\n",
      "\n",
      "episode 12, val func loss 0.17366020381450653\n",
      "\n",
      "episode 13, val func loss 0.1751420795917511\n",
      "\n",
      "episode 14, val func loss 0.18063834309577942\n",
      "\n",
      "episode 15, val func loss 0.20712678134441376\n",
      "\n",
      "episode 16, val func loss 0.1666499227285385\n",
      "\n",
      "Val func train loss in epoch 6:0.18837431073188782\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.17508627474308014\n",
      "\n",
      "episode 2, val func loss 0.19542326033115387\n",
      "\n",
      "episode 3, val func loss 0.17489409446716309\n",
      "\n",
      "episode 4, val func loss 0.17207159101963043\n",
      "\n",
      "episode 5, val func loss 0.1978796273469925\n",
      "\n",
      "episode 6, val func loss 0.1554497927427292\n",
      "\n",
      "episode 7, val func loss 0.18150287866592407\n",
      "\n",
      "episode 8, val func loss 0.17962592840194702\n",
      "\n",
      "episode 9, val func loss 0.1913018822669983\n",
      "\n",
      "episode 10, val func loss 0.18472754955291748\n",
      "\n",
      "episode 11, val func loss 0.24503478407859802\n",
      "\n",
      "episode 12, val func loss 0.2060936689376831\n",
      "\n",
      "episode 13, val func loss 0.17045453190803528\n",
      "\n",
      "episode 14, val func loss 0.17522011697292328\n",
      "\n",
      "episode 15, val func loss 0.19301937520503998\n",
      "\n",
      "episode 16, val func loss 0.21888595819473267\n",
      "\n",
      "Val func train loss in epoch 7:0.18854195717722178\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.16881528496742249\n",
      "\n",
      "episode 2, val func loss 0.19373542070388794\n",
      "\n",
      "episode 3, val func loss 0.17520558834075928\n",
      "\n",
      "episode 4, val func loss 0.20612832903862\n",
      "\n",
      "episode 5, val func loss 0.2435896098613739\n",
      "\n",
      "episode 6, val func loss 0.1906224936246872\n",
      "\n",
      "episode 7, val func loss 0.21872678399085999\n",
      "\n",
      "episode 8, val func loss 0.174512580037117\n",
      "\n",
      "episode 9, val func loss 0.17972971498966217\n",
      "\n",
      "episode 10, val func loss 0.19309139251708984\n",
      "\n",
      "episode 11, val func loss 0.17628158628940582\n",
      "\n",
      "episode 12, val func loss 0.18139508366584778\n",
      "\n",
      "episode 13, val func loss 0.15749798715114594\n",
      "\n",
      "episode 14, val func loss 0.17391149699687958\n",
      "\n",
      "episode 15, val func loss 0.19737529754638672\n",
      "\n",
      "episode 16, val func loss 0.18467310070991516\n",
      "\n",
      "Val func train loss in epoch 8:0.1884557344019413\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17482608556747437\n",
      "\n",
      "episode 2, val func loss 0.1662069857120514\n",
      "\n",
      "episode 3, val func loss 0.17543019354343414\n",
      "\n",
      "episode 4, val func loss 0.18259406089782715\n",
      "\n",
      "episode 5, val func loss 0.24952776730060577\n",
      "\n",
      "episode 6, val func loss 0.17960424721240997\n",
      "\n",
      "episode 7, val func loss 0.20682969689369202\n",
      "\n",
      "episode 8, val func loss 0.1932213008403778\n",
      "\n",
      "episode 9, val func loss 0.190927654504776\n",
      "\n",
      "episode 10, val func loss 0.1611780971288681\n",
      "\n",
      "episode 11, val func loss 0.18450480699539185\n",
      "\n",
      "episode 12, val func loss 0.19763022661209106\n",
      "\n",
      "episode 13, val func loss 0.21882511675357819\n",
      "\n",
      "episode 14, val func loss 0.19346536695957184\n",
      "\n",
      "episode 15, val func loss 0.1745927333831787\n",
      "\n",
      "episode 16, val func loss 0.17302890121936798\n",
      "\n",
      "Val func train loss in epoch 9:0.18889957759529352\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.17255884408950806\n",
      "\n",
      "episode 2, val func loss 0.17479419708251953\n",
      "\n",
      "episode 3, val func loss 0.17478662729263306\n",
      "\n",
      "episode 4, val func loss 0.18492388725280762\n",
      "\n",
      "episode 5, val func loss 0.20784632861614227\n",
      "\n",
      "episode 6, val func loss 0.19555163383483887\n",
      "\n",
      "episode 7, val func loss 0.1945304125547409\n",
      "\n",
      "episode 8, val func loss 0.24383094906806946\n",
      "\n",
      "episode 9, val func loss 0.1595485508441925\n",
      "\n",
      "episode 10, val func loss 0.17768004536628723\n",
      "\n",
      "episode 11, val func loss 0.18153323233127594\n",
      "\n",
      "episode 12, val func loss 0.19054840505123138\n",
      "\n",
      "episode 13, val func loss 0.21999506652355194\n",
      "\n",
      "episode 14, val func loss 0.19753196835517883\n",
      "\n",
      "episode 15, val func loss 0.16728290915489197\n",
      "\n",
      "episode 16, val func loss 0.18084195256233215\n",
      "\n",
      "Val func train loss in epoch 10:0.1889865631237626\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19406965374946594\n",
      "\n",
      "episode 2, val func loss 0.16700202226638794\n",
      "\n",
      "episode 3, val func loss 0.18049797415733337\n",
      "\n",
      "episode 4, val func loss 0.19438378512859344\n",
      "\n",
      "episode 5, val func loss 0.18021197617053986\n",
      "\n",
      "episode 6, val func loss 0.19061298668384552\n",
      "\n",
      "episode 7, val func loss 0.17519578337669373\n",
      "\n",
      "episode 8, val func loss 0.17484627664089203\n",
      "\n",
      "episode 9, val func loss 0.15662363171577454\n",
      "\n",
      "episode 10, val func loss 0.17351439595222473\n",
      "\n",
      "episode 11, val func loss 0.2065799981355667\n",
      "\n",
      "episode 12, val func loss 0.197568878531456\n",
      "\n",
      "episode 13, val func loss 0.24597537517547607\n",
      "\n",
      "episode 14, val func loss 0.17196263372898102\n",
      "\n",
      "episode 15, val func loss 0.18420037627220154\n",
      "\n",
      "episode 16, val func loss 0.22000513970851898\n",
      "\n",
      "Val func train loss in epoch 11:0.18832818046212196\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1802946776151657\n",
      "\n",
      "episode 2, val func loss 0.15732397139072418\n",
      "\n",
      "episode 3, val func loss 0.20605500042438507\n",
      "\n",
      "episode 4, val func loss 0.2426445186138153\n",
      "\n",
      "episode 5, val func loss 0.1933434158563614\n",
      "\n",
      "episode 6, val func loss 0.18253998458385468\n",
      "\n",
      "episode 7, val func loss 0.18427981436252594\n",
      "\n",
      "episode 8, val func loss 0.17702016234397888\n",
      "\n",
      "episode 9, val func loss 0.1928694248199463\n",
      "\n",
      "episode 10, val func loss 0.1763705462217331\n",
      "\n",
      "episode 11, val func loss 0.1972608119249344\n",
      "\n",
      "episode 12, val func loss 0.21921102702617645\n",
      "\n",
      "episode 13, val func loss 0.17290717363357544\n",
      "\n",
      "episode 14, val func loss 0.17499275505542755\n",
      "\n",
      "episode 15, val func loss 0.16685844957828522\n",
      "\n",
      "episode 16, val func loss 0.19111546874046326\n",
      "\n",
      "Val func train loss in epoch 12:0.18844295013695955\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.2075732797384262\n",
      "\n",
      "episode 2, val func loss 0.166330948472023\n",
      "\n",
      "episode 3, val func loss 0.19587239623069763\n",
      "\n",
      "episode 4, val func loss 0.19152088463306427\n",
      "\n",
      "episode 5, val func loss 0.17162027955055237\n",
      "\n",
      "episode 6, val func loss 0.18472285568714142\n",
      "\n",
      "episode 7, val func loss 0.1749010980129242\n",
      "\n",
      "episode 8, val func loss 0.2453141212463379\n",
      "\n",
      "episode 9, val func loss 0.18015511333942413\n",
      "\n",
      "episode 10, val func loss 0.21867570281028748\n",
      "\n",
      "episode 11, val func loss 0.1772676557302475\n",
      "\n",
      "episode 12, val func loss 0.1928020417690277\n",
      "\n",
      "episode 13, val func loss 0.16041173040866852\n",
      "\n",
      "episode 14, val func loss 0.1833147406578064\n",
      "\n",
      "episode 15, val func loss 0.17665855586528778\n",
      "\n",
      "episode 16, val func loss 0.19727090001106262\n",
      "\n",
      "Val func train loss in epoch 13:0.1890257690101862\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19331581890583038\n",
      "\n",
      "episode 2, val func loss 0.16726788878440857\n",
      "\n",
      "episode 3, val func loss 0.22034549713134766\n",
      "\n",
      "episode 4, val func loss 0.17488059401512146\n",
      "\n",
      "episode 5, val func loss 0.17959041893482208\n",
      "\n",
      "episode 6, val func loss 0.18497487902641296\n",
      "\n",
      "episode 7, val func loss 0.17143158614635468\n",
      "\n",
      "episode 8, val func loss 0.1815059930086136\n",
      "\n",
      "episode 9, val func loss 0.17183561623096466\n",
      "\n",
      "episode 10, val func loss 0.1979246735572815\n",
      "\n",
      "episode 11, val func loss 0.24739991128444672\n",
      "\n",
      "episode 12, val func loss 0.19502881169319153\n",
      "\n",
      "episode 13, val func loss 0.15639396011829376\n",
      "\n",
      "episode 14, val func loss 0.19057299196720123\n",
      "\n",
      "episode 15, val func loss 0.1756497472524643\n",
      "\n",
      "episode 16, val func loss 0.20586448907852173\n",
      "\n",
      "Val func train loss in epoch 14:0.1883739298209548\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.21863815188407898\n",
      "\n",
      "episode 2, val func loss 0.17538627982139587\n",
      "\n",
      "episode 3, val func loss 0.1818523406982422\n",
      "\n",
      "episode 4, val func loss 0.19063661992549896\n",
      "\n",
      "episode 5, val func loss 0.17541995644569397\n",
      "\n",
      "episode 6, val func loss 0.175617516040802\n",
      "\n",
      "episode 7, val func loss 0.18426111340522766\n",
      "\n",
      "episode 8, val func loss 0.19737078249454498\n",
      "\n",
      "episode 9, val func loss 0.2456611543893814\n",
      "\n",
      "episode 10, val func loss 0.2068977952003479\n",
      "\n",
      "episode 11, val func loss 0.17222991585731506\n",
      "\n",
      "episode 12, val func loss 0.1937943398952484\n",
      "\n",
      "episode 13, val func loss 0.15645091235637665\n",
      "\n",
      "episode 14, val func loss 0.18019290268421173\n",
      "\n",
      "episode 15, val func loss 0.19397523999214172\n",
      "\n",
      "episode 16, val func loss 0.16794012486934662\n",
      "\n",
      "Val func train loss in epoch 15:0.18852032162249088\n",
      "***********************TIME WAS 5.005345475673676 min*****************************\n",
      "\n",
      "**********************ROUND 144 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.0003605881938710809\n",
      "\n",
      "episode 2, policy loss -0.018757179379463196\n",
      "\n",
      "episode 3, policy loss -0.026421526446938515\n",
      "\n",
      "episode 4, policy loss -0.08565310388803482\n",
      "\n",
      "episode 5, policy loss -0.032333746552467346\n",
      "\n",
      "episode 6, policy loss -0.019971197471022606\n",
      "\n",
      "episode 7, policy loss -0.0777672827243805\n",
      "\n",
      "episode 8, policy loss -0.07531744241714478\n",
      "\n",
      "episode 9, policy loss -0.04908363148570061\n",
      "\n",
      "episode 10, policy loss -0.02735176682472229\n",
      "\n",
      "episode 11, policy loss -0.06243668869137764\n",
      "\n",
      "episode 12, policy loss -0.04542038217186928\n",
      "\n",
      "episode 13, policy loss -0.06842266023159027\n",
      "\n",
      "episode 14, policy loss -0.03725198283791542\n",
      "\n",
      "episode 15, policy loss -0.025081513449549675\n",
      "\n",
      "episode 16, policy loss -0.06721125543117523\n",
      "\n",
      "Policy train loss in epoch 0:-0.04492762176232645\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.027641206979751587\n",
      "\n",
      "episode 2, policy loss -0.0262120570987463\n",
      "\n",
      "episode 3, policy loss -0.06908905506134033\n",
      "\n",
      "episode 4, policy loss -0.06828657537698746\n",
      "\n",
      "episode 5, policy loss -0.04102160781621933\n",
      "\n",
      "episode 6, policy loss -0.06351576745510101\n",
      "\n",
      "episode 7, policy loss -0.03283097222447395\n",
      "\n",
      "episode 8, policy loss -0.013324753381311893\n",
      "\n",
      "episode 9, policy loss -0.09178612381219864\n",
      "\n",
      "episode 10, policy loss -0.07878720015287399\n",
      "\n",
      "episode 11, policy loss -0.04736076295375824\n",
      "\n",
      "episode 12, policy loss -0.05154253914952278\n",
      "\n",
      "episode 13, policy loss -0.08247481286525726\n",
      "\n",
      "episode 14, policy loss -0.017719144001603127\n",
      "\n",
      "episode 15, policy loss -0.02985069341957569\n",
      "\n",
      "episode 16, policy loss -0.03620512783527374\n",
      "\n",
      "Policy train loss in epoch 1:-0.04860302497399971\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.08269371092319489\n",
      "\n",
      "episode 2, policy loss -0.06957574188709259\n",
      "\n",
      "episode 3, policy loss -0.036801207810640335\n",
      "\n",
      "episode 4, policy loss -0.01683466136455536\n",
      "\n",
      "episode 5, policy loss -0.012143295258283615\n",
      "\n",
      "episode 6, policy loss -0.040506988763809204\n",
      "\n",
      "episode 7, policy loss -0.05186380445957184\n",
      "\n",
      "episode 8, policy loss -0.027824636548757553\n",
      "\n",
      "episode 9, policy loss -0.04705099016427994\n",
      "\n",
      "episode 10, policy loss -0.06482677161693573\n",
      "\n",
      "episode 11, policy loss -0.06746606528759003\n",
      "\n",
      "episode 12, policy loss -0.027386659756302834\n",
      "\n",
      "episode 13, policy loss -0.03333346173167229\n",
      "\n",
      "episode 14, policy loss -0.07873144000768661\n",
      "\n",
      "episode 15, policy loss -0.03056308999657631\n",
      "\n",
      "episode 16, policy loss -0.09099980443716049\n",
      "\n",
      "Policy train loss in epoch 2:-0.04866264562588185\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.07833956182003021\n",
      "\n",
      "episode 2, policy loss -0.06946443021297455\n",
      "\n",
      "episode 3, policy loss -0.04628787934780121\n",
      "\n",
      "episode 4, policy loss -0.030647380277514458\n",
      "\n",
      "episode 5, policy loss -0.09099384397268295\n",
      "\n",
      "episode 6, policy loss -0.018246598541736603\n",
      "\n",
      "episode 7, policy loss -0.013032276183366776\n",
      "\n",
      "episode 8, policy loss -0.0411200150847435\n",
      "\n",
      "episode 9, policy loss -0.03236711397767067\n",
      "\n",
      "episode 10, policy loss -0.05040840059518814\n",
      "\n",
      "episode 11, policy loss -0.026810184121131897\n",
      "\n",
      "episode 12, policy loss -0.0674903616309166\n",
      "\n",
      "episode 13, policy loss -0.0638437271118164\n",
      "\n",
      "episode 14, policy loss -0.028354398906230927\n",
      "\n",
      "episode 15, policy loss -0.03575705364346504\n",
      "\n",
      "episode 16, policy loss -0.08206743001937866\n",
      "\n",
      "Policy train loss in epoch 3:-0.04845191596541554\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.20726610720157623\n",
      "\n",
      "episode 2, val func loss 0.17865844070911407\n",
      "\n",
      "episode 3, val func loss 0.19743558764457703\n",
      "\n",
      "episode 4, val func loss 0.18718479573726654\n",
      "\n",
      "episode 5, val func loss 0.20604224503040314\n",
      "\n",
      "episode 6, val func loss 0.16570444405078888\n",
      "\n",
      "episode 7, val func loss 0.18786965310573578\n",
      "\n",
      "episode 8, val func loss 0.2234613597393036\n",
      "\n",
      "episode 9, val func loss 0.18025535345077515\n",
      "\n",
      "episode 10, val func loss 0.20064756274223328\n",
      "\n",
      "episode 11, val func loss 0.16976012289524078\n",
      "\n",
      "episode 12, val func loss 0.1797245740890503\n",
      "\n",
      "episode 13, val func loss 0.1758698672056198\n",
      "\n",
      "episode 14, val func loss 0.18296633660793304\n",
      "\n",
      "episode 15, val func loss 0.20717187225818634\n",
      "\n",
      "episode 16, val func loss 0.1894712895154953\n",
      "\n",
      "Val func train loss in epoch 0:0.1899681007489562\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.2073245644569397\n",
      "\n",
      "episode 2, val func loss 0.17933215200901031\n",
      "\n",
      "episode 3, val func loss 0.17874287068843842\n",
      "\n",
      "episode 4, val func loss 0.19721518456935883\n",
      "\n",
      "episode 5, val func loss 0.20698390901088715\n",
      "\n",
      "episode 6, val func loss 0.18010546267032623\n",
      "\n",
      "episode 7, val func loss 0.1653176248073578\n",
      "\n",
      "episode 8, val func loss 0.18993479013442993\n",
      "\n",
      "episode 9, val func loss 0.2233099788427353\n",
      "\n",
      "episode 10, val func loss 0.18726210296154022\n",
      "\n",
      "episode 11, val func loss 0.17589060962200165\n",
      "\n",
      "episode 12, val func loss 0.18804442882537842\n",
      "\n",
      "episode 13, val func loss 0.18295492231845856\n",
      "\n",
      "episode 14, val func loss 0.20612198114395142\n",
      "\n",
      "episode 15, val func loss 0.2009180337190628\n",
      "\n",
      "episode 16, val func loss 0.16953104734420776\n",
      "\n",
      "Val func train loss in epoch 1:0.18993685394525528\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18303637206554413\n",
      "\n",
      "episode 2, val func loss 0.19730567932128906\n",
      "\n",
      "episode 3, val func loss 0.16944937407970428\n",
      "\n",
      "episode 4, val func loss 0.18789072334766388\n",
      "\n",
      "episode 5, val func loss 0.2005683332681656\n",
      "\n",
      "episode 6, val func loss 0.17595018446445465\n",
      "\n",
      "episode 7, val func loss 0.1896691769361496\n",
      "\n",
      "episode 8, val func loss 0.18726706504821777\n",
      "\n",
      "episode 9, val func loss 0.22359980642795563\n",
      "\n",
      "episode 10, val func loss 0.18015044927597046\n",
      "\n",
      "episode 11, val func loss 0.17877790331840515\n",
      "\n",
      "episode 12, val func loss 0.16485318541526794\n",
      "\n",
      "episode 13, val func loss 0.2073906809091568\n",
      "\n",
      "episode 14, val func loss 0.20649003982543945\n",
      "\n",
      "episode 15, val func loss 0.17948134243488312\n",
      "\n",
      "episode 16, val func loss 0.20704194903373718\n",
      "\n",
      "Val func train loss in epoch 2:0.1899326415732503\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.17894266545772552\n",
      "\n",
      "episode 2, val func loss 0.20556269586086273\n",
      "\n",
      "episode 3, val func loss 0.20053376257419586\n",
      "\n",
      "episode 4, val func loss 0.20660500228405\n",
      "\n",
      "episode 5, val func loss 0.19105204939842224\n",
      "\n",
      "episode 6, val func loss 0.2227359116077423\n",
      "\n",
      "episode 7, val func loss 0.18813900649547577\n",
      "\n",
      "episode 8, val func loss 0.17017808556556702\n",
      "\n",
      "episode 9, val func loss 0.18793173134326935\n",
      "\n",
      "episode 10, val func loss 0.18002332746982574\n",
      "\n",
      "episode 11, val func loss 0.17559240758419037\n",
      "\n",
      "episode 12, val func loss 0.2074611932039261\n",
      "\n",
      "episode 13, val func loss 0.17955991625785828\n",
      "\n",
      "episode 14, val func loss 0.19755390286445618\n",
      "\n",
      "episode 15, val func loss 0.18292087316513062\n",
      "\n",
      "episode 16, val func loss 0.16460996866226196\n",
      "\n",
      "Val func train loss in epoch 3:0.189962656237185\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.1646033525466919\n",
      "\n",
      "episode 2, val func loss 0.18318921327590942\n",
      "\n",
      "episode 3, val func loss 0.1869557499885559\n",
      "\n",
      "episode 4, val func loss 0.19787733256816864\n",
      "\n",
      "episode 5, val func loss 0.22442708909511566\n",
      "\n",
      "episode 6, val func loss 0.20641912519931793\n",
      "\n",
      "episode 7, val func loss 0.16930247843265533\n",
      "\n",
      "episode 8, val func loss 0.20636679232120514\n",
      "\n",
      "episode 9, val func loss 0.18050023913383484\n",
      "\n",
      "episode 10, val func loss 0.20055633783340454\n",
      "\n",
      "episode 11, val func loss 0.1806277483701706\n",
      "\n",
      "episode 12, val func loss 0.1769580841064453\n",
      "\n",
      "episode 13, val func loss 0.17926925420761108\n",
      "\n",
      "episode 14, val func loss 0.19014647603034973\n",
      "\n",
      "episode 15, val func loss 0.20724046230316162\n",
      "\n",
      "episode 16, val func loss 0.1881324201822281\n",
      "\n",
      "Val func train loss in epoch 4:0.1901607597246766\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1871555745601654\n",
      "\n",
      "episode 2, val func loss 0.1756279170513153\n",
      "\n",
      "episode 3, val func loss 0.1893157809972763\n",
      "\n",
      "episode 4, val func loss 0.1884547919034958\n",
      "\n",
      "episode 5, val func loss 0.18058599531650543\n",
      "\n",
      "episode 6, val func loss 0.20787115395069122\n",
      "\n",
      "episode 7, val func loss 0.19762100279331207\n",
      "\n",
      "episode 8, val func loss 0.17874842882156372\n",
      "\n",
      "episode 9, val func loss 0.16966095566749573\n",
      "\n",
      "episode 10, val func loss 0.20565789937973022\n",
      "\n",
      "episode 11, val func loss 0.18350863456726074\n",
      "\n",
      "episode 12, val func loss 0.22283944487571716\n",
      "\n",
      "episode 13, val func loss 0.18012267351150513\n",
      "\n",
      "episode 14, val func loss 0.1661730855703354\n",
      "\n",
      "episode 15, val func loss 0.20668627321720123\n",
      "\n",
      "episode 16, val func loss 0.20081333816051483\n",
      "\n",
      "Val func train loss in epoch 5:0.19005268439650536\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1831793636083603\n",
      "\n",
      "episode 2, val func loss 0.200761616230011\n",
      "\n",
      "episode 3, val func loss 0.17578093707561493\n",
      "\n",
      "episode 4, val func loss 0.18803435564041138\n",
      "\n",
      "episode 5, val func loss 0.1871972680091858\n",
      "\n",
      "episode 6, val func loss 0.2074548453092575\n",
      "\n",
      "episode 7, val func loss 0.20613960921764374\n",
      "\n",
      "episode 8, val func loss 0.2233884334564209\n",
      "\n",
      "episode 9, val func loss 0.16965509951114655\n",
      "\n",
      "episode 10, val func loss 0.1660037636756897\n",
      "\n",
      "episode 11, val func loss 0.19025775790214539\n",
      "\n",
      "episode 12, val func loss 0.19703063368797302\n",
      "\n",
      "episode 13, val func loss 0.17948615550994873\n",
      "\n",
      "episode 14, val func loss 0.18005003035068512\n",
      "\n",
      "episode 15, val func loss 0.17868930101394653\n",
      "\n",
      "episode 16, val func loss 0.20736762881278992\n",
      "\n",
      "Val func train loss in epoch 6:0.1900297999382019\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.18936476111412048\n",
      "\n",
      "episode 2, val func loss 0.2065582275390625\n",
      "\n",
      "episode 3, val func loss 0.1828901469707489\n",
      "\n",
      "episode 4, val func loss 0.17860908806324005\n",
      "\n",
      "episode 5, val func loss 0.2072363942861557\n",
      "\n",
      "episode 6, val func loss 0.2066427767276764\n",
      "\n",
      "episode 7, val func loss 0.18769103288650513\n",
      "\n",
      "episode 8, val func loss 0.16975264251232147\n",
      "\n",
      "episode 9, val func loss 0.16593147814273834\n",
      "\n",
      "episode 10, val func loss 0.18009798228740692\n",
      "\n",
      "episode 11, val func loss 0.17580264806747437\n",
      "\n",
      "episode 12, val func loss 0.20105917751789093\n",
      "\n",
      "episode 13, val func loss 0.22381806373596191\n",
      "\n",
      "episode 14, val func loss 0.17916688323020935\n",
      "\n",
      "episode 15, val func loss 0.18806129693984985\n",
      "\n",
      "episode 16, val func loss 0.19738680124282837\n",
      "\n",
      "Val func train loss in epoch 7:0.19000433757901192\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.1873280107975006\n",
      "\n",
      "episode 2, val func loss 0.17578904330730438\n",
      "\n",
      "episode 3, val func loss 0.17950434982776642\n",
      "\n",
      "episode 4, val func loss 0.17858654260635376\n",
      "\n",
      "episode 5, val func loss 0.18045656383037567\n",
      "\n",
      "episode 6, val func loss 0.18930348753929138\n",
      "\n",
      "episode 7, val func loss 0.19747157394886017\n",
      "\n",
      "episode 8, val func loss 0.18298642337322235\n",
      "\n",
      "episode 9, val func loss 0.20667648315429688\n",
      "\n",
      "episode 10, val func loss 0.16501764953136444\n",
      "\n",
      "episode 11, val func loss 0.16941086947917938\n",
      "\n",
      "episode 12, val func loss 0.18789760768413544\n",
      "\n",
      "episode 13, val func loss 0.2073453813791275\n",
      "\n",
      "episode 14, val func loss 0.20062927901744843\n",
      "\n",
      "episode 15, val func loss 0.2064908742904663\n",
      "\n",
      "episode 16, val func loss 0.2231711894273758\n",
      "\n",
      "Val func train loss in epoch 8:0.1898790830746293\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18076452612876892\n",
      "\n",
      "episode 2, val func loss 0.1674962192773819\n",
      "\n",
      "episode 3, val func loss 0.17972292006015778\n",
      "\n",
      "episode 4, val func loss 0.19031639397144318\n",
      "\n",
      "episode 5, val func loss 0.1691698133945465\n",
      "\n",
      "episode 6, val func loss 0.1793239861726761\n",
      "\n",
      "episode 7, val func loss 0.18880502879619598\n",
      "\n",
      "episode 8, val func loss 0.1832498013973236\n",
      "\n",
      "episode 9, val func loss 0.20796875655651093\n",
      "\n",
      "episode 10, val func loss 0.20842519402503967\n",
      "\n",
      "episode 11, val func loss 0.22400988638401031\n",
      "\n",
      "episode 12, val func loss 0.17575310170650482\n",
      "\n",
      "episode 13, val func loss 0.2064395397901535\n",
      "\n",
      "episode 14, val func loss 0.19738765060901642\n",
      "\n",
      "episode 15, val func loss 0.200873464345932\n",
      "\n",
      "episode 16, val func loss 0.1892508715391159\n",
      "\n",
      "Val func train loss in epoch 9:0.1905598221346736\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.20516467094421387\n",
      "\n",
      "episode 2, val func loss 0.16656677424907684\n",
      "\n",
      "episode 3, val func loss 0.18020634353160858\n",
      "\n",
      "episode 4, val func loss 0.1794051080942154\n",
      "\n",
      "episode 5, val func loss 0.18361322581768036\n",
      "\n",
      "episode 6, val func loss 0.18924760818481445\n",
      "\n",
      "episode 7, val func loss 0.1870441436767578\n",
      "\n",
      "episode 8, val func loss 0.1754971444606781\n",
      "\n",
      "episode 9, val func loss 0.20801368355751038\n",
      "\n",
      "episode 10, val func loss 0.16946549713611603\n",
      "\n",
      "episode 11, val func loss 0.1787501722574234\n",
      "\n",
      "episode 12, val func loss 0.20052023231983185\n",
      "\n",
      "episode 13, val func loss 0.1971512734889984\n",
      "\n",
      "episode 14, val func loss 0.2064998894929886\n",
      "\n",
      "episode 15, val func loss 0.22279806435108185\n",
      "\n",
      "episode 16, val func loss 0.18818119168281555\n",
      "\n",
      "Val func train loss in epoch 10:0.18988281395286322\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19744712114334106\n",
      "\n",
      "episode 2, val func loss 0.1907147914171219\n",
      "\n",
      "episode 3, val func loss 0.17608726024627686\n",
      "\n",
      "episode 4, val func loss 0.1871335506439209\n",
      "\n",
      "episode 5, val func loss 0.1835433393716812\n",
      "\n",
      "episode 6, val func loss 0.18915076553821564\n",
      "\n",
      "episode 7, val func loss 0.2086537480354309\n",
      "\n",
      "episode 8, val func loss 0.20783084630966187\n",
      "\n",
      "episode 9, val func loss 0.18021507561206818\n",
      "\n",
      "episode 10, val func loss 0.22316765785217285\n",
      "\n",
      "episode 11, val func loss 0.1704568713903427\n",
      "\n",
      "episode 12, val func loss 0.2052222639322281\n",
      "\n",
      "episode 13, val func loss 0.17979338765144348\n",
      "\n",
      "episode 14, val func loss 0.20073771476745605\n",
      "\n",
      "episode 15, val func loss 0.17977182567119598\n",
      "\n",
      "episode 16, val func loss 0.16490373015403748\n",
      "\n",
      "Val func train loss in epoch 11:0.1903018718585372\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.18720419704914093\n",
      "\n",
      "episode 2, val func loss 0.18968236446380615\n",
      "\n",
      "episode 3, val func loss 0.17982524633407593\n",
      "\n",
      "episode 4, val func loss 0.17558881640434265\n",
      "\n",
      "episode 5, val func loss 0.20730672776699066\n",
      "\n",
      "episode 6, val func loss 0.18008241057395935\n",
      "\n",
      "episode 7, val func loss 0.1665375530719757\n",
      "\n",
      "episode 8, val func loss 0.17017769813537598\n",
      "\n",
      "episode 9, val func loss 0.1881074756383896\n",
      "\n",
      "episode 10, val func loss 0.2233048379421234\n",
      "\n",
      "episode 11, val func loss 0.20709598064422607\n",
      "\n",
      "episode 12, val func loss 0.20069384574890137\n",
      "\n",
      "episode 13, val func loss 0.17916256189346313\n",
      "\n",
      "episode 14, val func loss 0.19703534245491028\n",
      "\n",
      "episode 15, val func loss 0.20569662749767303\n",
      "\n",
      "episode 16, val func loss 0.18320804834365845\n",
      "\n",
      "Val func train loss in epoch 12:0.1900443583726883\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.17621220648288727\n",
      "\n",
      "episode 2, val func loss 0.18731985986232758\n",
      "\n",
      "episode 3, val func loss 0.20690052211284637\n",
      "\n",
      "episode 4, val func loss 0.16928327083587646\n",
      "\n",
      "episode 5, val func loss 0.1880456656217575\n",
      "\n",
      "episode 6, val func loss 0.19751125574111938\n",
      "\n",
      "episode 7, val func loss 0.18307213485240936\n",
      "\n",
      "episode 8, val func loss 0.18947377800941467\n",
      "\n",
      "episode 9, val func loss 0.17877624928951263\n",
      "\n",
      "episode 10, val func loss 0.22391696274280548\n",
      "\n",
      "episode 11, val func loss 0.18028296530246735\n",
      "\n",
      "episode 12, val func loss 0.1796714961528778\n",
      "\n",
      "episode 13, val func loss 0.2058650553226471\n",
      "\n",
      "episode 14, val func loss 0.2070566713809967\n",
      "\n",
      "episode 15, val func loss 0.16583359241485596\n",
      "\n",
      "episode 16, val func loss 0.2004883587360382\n",
      "\n",
      "Val func train loss in epoch 13:0.1899818778038025\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19720202684402466\n",
      "\n",
      "episode 2, val func loss 0.17000964283943176\n",
      "\n",
      "episode 3, val func loss 0.20550218224525452\n",
      "\n",
      "episode 4, val func loss 0.20642942190170288\n",
      "\n",
      "episode 5, val func loss 0.1657261997461319\n",
      "\n",
      "episode 6, val func loss 0.22313663363456726\n",
      "\n",
      "episode 7, val func loss 0.1833314150571823\n",
      "\n",
      "episode 8, val func loss 0.1898178905248642\n",
      "\n",
      "episode 9, val func loss 0.18810832500457764\n",
      "\n",
      "episode 10, val func loss 0.18030457198619843\n",
      "\n",
      "episode 11, val func loss 0.17932960391044617\n",
      "\n",
      "episode 12, val func loss 0.17873455584049225\n",
      "\n",
      "episode 13, val func loss 0.18695029616355896\n",
      "\n",
      "episode 14, val func loss 0.20151901245117188\n",
      "\n",
      "episode 15, val func loss 0.175355464220047\n",
      "\n",
      "episode 16, val func loss 0.2078387290239334\n",
      "\n",
      "Val func train loss in epoch 14:0.18995599821209908\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.22385071218013763\n",
      "\n",
      "episode 2, val func loss 0.20693106949329376\n",
      "\n",
      "episode 3, val func loss 0.20057885348796844\n",
      "\n",
      "episode 4, val func loss 0.1886504590511322\n",
      "\n",
      "episode 5, val func loss 0.1840723305940628\n",
      "\n",
      "episode 6, val func loss 0.20526401698589325\n",
      "\n",
      "episode 7, val func loss 0.19718587398529053\n",
      "\n",
      "episode 8, val func loss 0.19080589711666107\n",
      "\n",
      "episode 9, val func loss 0.1790703684091568\n",
      "\n",
      "episode 10, val func loss 0.18030992150306702\n",
      "\n",
      "episode 11, val func loss 0.17538873851299286\n",
      "\n",
      "episode 12, val func loss 0.18892118334770203\n",
      "\n",
      "episode 13, val func loss 0.1693827509880066\n",
      "\n",
      "episode 14, val func loss 0.17935366928577423\n",
      "\n",
      "episode 15, val func loss 0.2080443948507309\n",
      "\n",
      "episode 16, val func loss 0.16481366753578186\n",
      "\n",
      "Val func train loss in epoch 15:0.19016399420797825\n",
      "***********************TIME WAS 5.003350834051768 min*****************************\n",
      "\n",
      "**********************ROUND 145 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.08032917231321335\n",
      "\n",
      "episode 2, policy loss -0.014269326813519001\n",
      "\n",
      "episode 3, policy loss -0.0670609399676323\n",
      "\n",
      "episode 4, policy loss -0.04752100631594658\n",
      "\n",
      "episode 5, policy loss -0.058525651693344116\n",
      "\n",
      "episode 6, policy loss -0.007928569801151752\n",
      "\n",
      "episode 7, policy loss -0.053779736161231995\n",
      "\n",
      "episode 8, policy loss -0.09348482638597488\n",
      "\n",
      "episode 9, policy loss -0.04833121970295906\n",
      "\n",
      "episode 10, policy loss -0.02668064646422863\n",
      "\n",
      "episode 11, policy loss -0.021488087251782417\n",
      "\n",
      "episode 12, policy loss -0.06715316325426102\n",
      "\n",
      "episode 13, policy loss 0.020967410877346992\n",
      "\n",
      "episode 14, policy loss -0.13155671954154968\n",
      "\n",
      "episode 15, policy loss -0.0908268466591835\n",
      "\n",
      "episode 16, policy loss -0.013069093227386475\n",
      "\n",
      "Policy train loss in epoch 0:-0.05006484966725111\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.020857855677604675\n",
      "\n",
      "episode 2, policy loss -0.013418642804026604\n",
      "\n",
      "episode 3, policy loss -0.025661157444119453\n",
      "\n",
      "episode 4, policy loss -0.09697432070970535\n",
      "\n",
      "episode 5, policy loss -0.02824437990784645\n",
      "\n",
      "episode 6, policy loss -0.13411706686019897\n",
      "\n",
      "episode 7, policy loss -0.09352118521928787\n",
      "\n",
      "episode 8, policy loss -0.05868496000766754\n",
      "\n",
      "episode 9, policy loss -0.07374503463506699\n",
      "\n",
      "episode 10, policy loss -0.007372439373284578\n",
      "\n",
      "episode 11, policy loss -0.05184565857052803\n",
      "\n",
      "episode 12, policy loss -0.09117761254310608\n",
      "\n",
      "episode 13, policy loss -0.051257528364658356\n",
      "\n",
      "episode 14, policy loss -0.02421550452709198\n",
      "\n",
      "episode 15, policy loss -0.05412992462515831\n",
      "\n",
      "episode 16, policy loss -0.06999539583921432\n",
      "\n",
      "Policy train loss in epoch 1:-0.053343934734584764\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.07311499118804932\n",
      "\n",
      "episode 2, policy loss -0.02606199122965336\n",
      "\n",
      "episode 3, policy loss -0.050382424145936966\n",
      "\n",
      "episode 4, policy loss -0.0520540326833725\n",
      "\n",
      "episode 5, policy loss -0.07031645625829697\n",
      "\n",
      "episode 6, policy loss -0.007036108989268541\n",
      "\n",
      "episode 7, policy loss -0.0912729874253273\n",
      "\n",
      "episode 8, policy loss -0.0527043491601944\n",
      "\n",
      "episode 9, policy loss -0.02903944067656994\n",
      "\n",
      "episode 10, policy loss -0.05898104980587959\n",
      "\n",
      "episode 11, policy loss -0.09823661297559738\n",
      "\n",
      "episode 12, policy loss -0.02462262474000454\n",
      "\n",
      "episode 13, policy loss -0.1350538730621338\n",
      "\n",
      "episode 14, policy loss -0.09370560944080353\n",
      "\n",
      "episode 15, policy loss -0.013618065975606441\n",
      "\n",
      "episode 16, policy loss 0.0206778421998024\n",
      "\n",
      "Policy train loss in epoch 2:-0.05347017347230576\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.02106529101729393\n",
      "\n",
      "episode 2, policy loss -0.07345370203256607\n",
      "\n",
      "episode 3, policy loss -0.06985235214233398\n",
      "\n",
      "episode 4, policy loss -0.13510453701019287\n",
      "\n",
      "episode 5, policy loss -0.05505608767271042\n",
      "\n",
      "episode 6, policy loss -0.013365823775529861\n",
      "\n",
      "episode 7, policy loss -0.006788765545934439\n",
      "\n",
      "episode 8, policy loss -0.09626851975917816\n",
      "\n",
      "episode 9, policy loss -0.05181887373328209\n",
      "\n",
      "episode 10, policy loss -0.05150824412703514\n",
      "\n",
      "episode 11, policy loss -0.02965851128101349\n",
      "\n",
      "episode 12, policy loss -0.026179596781730652\n",
      "\n",
      "episode 13, policy loss -0.02414698526263237\n",
      "\n",
      "episode 14, policy loss -0.09030316025018692\n",
      "\n",
      "episode 15, policy loss -0.09254685789346695\n",
      "\n",
      "episode 16, policy loss -0.05890880525112152\n",
      "\n",
      "Policy train loss in epoch 3:-0.05336847071885131\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1763264238834381\n",
      "\n",
      "episode 2, val func loss 0.19976142048835754\n",
      "\n",
      "episode 3, val func loss 0.22025036811828613\n",
      "\n",
      "episode 4, val func loss 0.17960217595100403\n",
      "\n",
      "episode 5, val func loss 0.22122208774089813\n",
      "\n",
      "episode 6, val func loss 0.18833200633525848\n",
      "\n",
      "episode 7, val func loss 0.22028939425945282\n",
      "\n",
      "episode 8, val func loss 0.2154386341571808\n",
      "\n",
      "episode 9, val func loss 0.17739035189151764\n",
      "\n",
      "episode 10, val func loss 0.19569958746433258\n",
      "\n",
      "episode 11, val func loss 0.18764223158359528\n",
      "\n",
      "episode 12, val func loss 0.18147429823875427\n",
      "\n",
      "episode 13, val func loss 0.1490814983844757\n",
      "\n",
      "episode 14, val func loss 0.17448057234287262\n",
      "\n",
      "episode 15, val func loss 0.18641529977321625\n",
      "\n",
      "episode 16, val func loss 0.24080105125904083\n",
      "\n",
      "Val func train loss in epoch 0:0.19463796261698008\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.17400111258029938\n",
      "\n",
      "episode 2, val func loss 0.14465388655662537\n",
      "\n",
      "episode 3, val func loss 0.1746811717748642\n",
      "\n",
      "episode 4, val func loss 0.175550177693367\n",
      "\n",
      "episode 5, val func loss 0.18999813497066498\n",
      "\n",
      "episode 6, val func loss 0.19867964088916779\n",
      "\n",
      "episode 7, val func loss 0.24293319880962372\n",
      "\n",
      "episode 8, val func loss 0.2003304660320282\n",
      "\n",
      "episode 9, val func loss 0.1882546842098236\n",
      "\n",
      "episode 10, val func loss 0.2211555391550064\n",
      "\n",
      "episode 11, val func loss 0.18108287453651428\n",
      "\n",
      "episode 12, val func loss 0.2188137173652649\n",
      "\n",
      "episode 13, val func loss 0.18162798881530762\n",
      "\n",
      "episode 14, val func loss 0.21418190002441406\n",
      "\n",
      "episode 15, val func loss 0.18664219975471497\n",
      "\n",
      "episode 16, val func loss 0.21940331161022186\n",
      "\n",
      "Val func train loss in epoch 1:0.19449937529861927\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.21403516829013824\n",
      "\n",
      "episode 2, val func loss 0.18759556114673615\n",
      "\n",
      "episode 3, val func loss 0.18325380980968475\n",
      "\n",
      "episode 4, val func loss 0.17580153048038483\n",
      "\n",
      "episode 5, val func loss 0.21969889104366302\n",
      "\n",
      "episode 6, val func loss 0.23706693947315216\n",
      "\n",
      "episode 7, val func loss 0.17790712416172028\n",
      "\n",
      "episode 8, val func loss 0.1958456039428711\n",
      "\n",
      "episode 9, val func loss 0.22103463113307953\n",
      "\n",
      "episode 10, val func loss 0.18031954765319824\n",
      "\n",
      "episode 11, val func loss 0.17592348158359528\n",
      "\n",
      "episode 12, val func loss 0.19999243319034576\n",
      "\n",
      "episode 13, val func loss 0.1445000022649765\n",
      "\n",
      "episode 14, val func loss 0.189078688621521\n",
      "\n",
      "episode 15, val func loss 0.22286450862884521\n",
      "\n",
      "episode 16, val func loss 0.18755419552326202\n",
      "\n",
      "Val func train loss in epoch 2:0.19452950730919838\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.2187442183494568\n",
      "\n",
      "episode 2, val func loss 0.22139744460582733\n",
      "\n",
      "episode 3, val func loss 0.19985049962997437\n",
      "\n",
      "episode 4, val func loss 0.1745608001947403\n",
      "\n",
      "episode 5, val func loss 0.21913690865039825\n",
      "\n",
      "episode 6, val func loss 0.18845218420028687\n",
      "\n",
      "episode 7, val func loss 0.1823657751083374\n",
      "\n",
      "episode 8, val func loss 0.18135245144367218\n",
      "\n",
      "episode 9, val func loss 0.14867764711380005\n",
      "\n",
      "episode 10, val func loss 0.17674964666366577\n",
      "\n",
      "episode 11, val func loss 0.24196137487888336\n",
      "\n",
      "episode 12, val func loss 0.18898577988147736\n",
      "\n",
      "episode 13, val func loss 0.19689933955669403\n",
      "\n",
      "episode 14, val func loss 0.2209261655807495\n",
      "\n",
      "episode 15, val func loss 0.17576782405376434\n",
      "\n",
      "episode 16, val func loss 0.18615224957466125\n",
      "\n",
      "Val func train loss in epoch 3:0.19512376934289932\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.180403470993042\n",
      "\n",
      "episode 2, val func loss 0.23757126927375793\n",
      "\n",
      "episode 3, val func loss 0.17775428295135498\n",
      "\n",
      "episode 4, val func loss 0.21958011388778687\n",
      "\n",
      "episode 5, val func loss 0.18752451241016388\n",
      "\n",
      "episode 6, val func loss 0.18049228191375732\n",
      "\n",
      "episode 7, val func loss 0.1957002729177475\n",
      "\n",
      "episode 8, val func loss 0.19991369545459747\n",
      "\n",
      "episode 9, val func loss 0.22086766362190247\n",
      "\n",
      "episode 10, val func loss 0.2152918130159378\n",
      "\n",
      "episode 11, val func loss 0.17703719437122345\n",
      "\n",
      "episode 12, val func loss 0.18643201887607574\n",
      "\n",
      "episode 13, val func loss 0.14777430891990662\n",
      "\n",
      "episode 14, val func loss 0.1882077157497406\n",
      "\n",
      "episode 15, val func loss 0.22015751898288727\n",
      "\n",
      "episode 16, val func loss 0.1740892082452774\n",
      "\n",
      "Val func train loss in epoch 4:0.19429983384907246\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.145005002617836\n",
      "\n",
      "episode 2, val func loss 0.19714142382144928\n",
      "\n",
      "episode 3, val func loss 0.17408785223960876\n",
      "\n",
      "episode 4, val func loss 0.22212839126586914\n",
      "\n",
      "episode 5, val func loss 0.2005191147327423\n",
      "\n",
      "episode 6, val func loss 0.17867615818977356\n",
      "\n",
      "episode 7, val func loss 0.18686817586421967\n",
      "\n",
      "episode 8, val func loss 0.17588338255882263\n",
      "\n",
      "episode 9, val func loss 0.18847614526748657\n",
      "\n",
      "episode 10, val func loss 0.23994852602481842\n",
      "\n",
      "episode 11, val func loss 0.2206728607416153\n",
      "\n",
      "episode 12, val func loss 0.18055574595928192\n",
      "\n",
      "episode 13, val func loss 0.17687197029590607\n",
      "\n",
      "episode 14, val func loss 0.18820609152317047\n",
      "\n",
      "episode 15, val func loss 0.2147228866815567\n",
      "\n",
      "episode 16, val func loss 0.21904423832893372\n",
      "\n",
      "Val func train loss in epoch 5:0.19430049788206816\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.22093966603279114\n",
      "\n",
      "episode 2, val func loss 0.1795104444026947\n",
      "\n",
      "episode 3, val func loss 0.19571280479431152\n",
      "\n",
      "episode 4, val func loss 0.21870987117290497\n",
      "\n",
      "episode 5, val func loss 0.17509588599205017\n",
      "\n",
      "episode 6, val func loss 0.1882360279560089\n",
      "\n",
      "episode 7, val func loss 0.14818793535232544\n",
      "\n",
      "episode 8, val func loss 0.18030573427677155\n",
      "\n",
      "episode 9, val func loss 0.18668034672737122\n",
      "\n",
      "episode 10, val func loss 0.21824076771736145\n",
      "\n",
      "episode 11, val func loss 0.20023179054260254\n",
      "\n",
      "episode 12, val func loss 0.17468726634979248\n",
      "\n",
      "episode 13, val func loss 0.17881989479064941\n",
      "\n",
      "episode 14, val func loss 0.22206081449985504\n",
      "\n",
      "episode 15, val func loss 0.18888981640338898\n",
      "\n",
      "episode 16, val func loss 0.24054162204265594\n",
      "\n",
      "Val func train loss in epoch 6:0.19480316806584597\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19651469588279724\n",
      "\n",
      "episode 2, val func loss 0.18037325143814087\n",
      "\n",
      "episode 3, val func loss 0.1744343340396881\n",
      "\n",
      "episode 4, val func loss 0.18738433718681335\n",
      "\n",
      "episode 5, val func loss 0.2146771103143692\n",
      "\n",
      "episode 6, val func loss 0.17971213161945343\n",
      "\n",
      "episode 7, val func loss 0.18658757209777832\n",
      "\n",
      "episode 8, val func loss 0.2348444163799286\n",
      "\n",
      "episode 9, val func loss 0.17898717522621155\n",
      "\n",
      "episode 10, val func loss 0.21936124563217163\n",
      "\n",
      "episode 11, val func loss 0.20021268725395203\n",
      "\n",
      "episode 12, val func loss 0.18857266008853912\n",
      "\n",
      "episode 13, val func loss 0.14894866943359375\n",
      "\n",
      "episode 14, val func loss 0.22104759514331818\n",
      "\n",
      "episode 15, val func loss 0.17973782122135162\n",
      "\n",
      "episode 16, val func loss 0.22089597582817078\n",
      "\n",
      "Val func train loss in epoch 7:0.19451822992414236\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.17864546179771423\n",
      "\n",
      "episode 2, val func loss 0.18002468347549438\n",
      "\n",
      "episode 3, val func loss 0.19839809834957123\n",
      "\n",
      "episode 4, val func loss 0.24296431243419647\n",
      "\n",
      "episode 5, val func loss 0.14387159049510956\n",
      "\n",
      "episode 6, val func loss 0.18845674395561218\n",
      "\n",
      "episode 7, val func loss 0.22120679914951324\n",
      "\n",
      "episode 8, val func loss 0.1752854734659195\n",
      "\n",
      "episode 9, val func loss 0.18780717253684998\n",
      "\n",
      "episode 10, val func loss 0.21945837140083313\n",
      "\n",
      "episode 11, val func loss 0.174443781375885\n",
      "\n",
      "episode 12, val func loss 0.17777056992053986\n",
      "\n",
      "episode 13, val func loss 0.2207963764667511\n",
      "\n",
      "episode 14, val func loss 0.18624867498874664\n",
      "\n",
      "episode 15, val func loss 0.21530471742153168\n",
      "\n",
      "episode 16, val func loss 0.20002484321594238\n",
      "\n",
      "Val func train loss in epoch 8:0.19441922940313816\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17692840099334717\n",
      "\n",
      "episode 2, val func loss 0.220889613032341\n",
      "\n",
      "episode 3, val func loss 0.18632741272449493\n",
      "\n",
      "episode 4, val func loss 0.23675954341888428\n",
      "\n",
      "episode 5, val func loss 0.19574835896492004\n",
      "\n",
      "episode 6, val func loss 0.21900500357151031\n",
      "\n",
      "episode 7, val func loss 0.18748262524604797\n",
      "\n",
      "episode 8, val func loss 0.188665971159935\n",
      "\n",
      "episode 9, val func loss 0.1793932318687439\n",
      "\n",
      "episode 10, val func loss 0.2145223468542099\n",
      "\n",
      "episode 11, val func loss 0.2193920761346817\n",
      "\n",
      "episode 12, val func loss 0.18099872767925262\n",
      "\n",
      "episode 13, val func loss 0.2001815140247345\n",
      "\n",
      "episode 14, val func loss 0.1483975350856781\n",
      "\n",
      "episode 15, val func loss 0.17991068959236145\n",
      "\n",
      "episode 16, val func loss 0.17411506175994873\n",
      "\n",
      "Val func train loss in epoch 9:0.19429488200694323\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19751642644405365\n",
      "\n",
      "episode 2, val func loss 0.22220399975776672\n",
      "\n",
      "episode 3, val func loss 0.17555983364582062\n",
      "\n",
      "episode 4, val func loss 0.18915410339832306\n",
      "\n",
      "episode 5, val func loss 0.1785859316587448\n",
      "\n",
      "episode 6, val func loss 0.2418745756149292\n",
      "\n",
      "episode 7, val func loss 0.17416206002235413\n",
      "\n",
      "episode 8, val func loss 0.22156400978565216\n",
      "\n",
      "episode 9, val func loss 0.1802418828010559\n",
      "\n",
      "episode 10, val func loss 0.21583089232444763\n",
      "\n",
      "episode 11, val func loss 0.2191362828016281\n",
      "\n",
      "episode 12, val func loss 0.17825672030448914\n",
      "\n",
      "episode 13, val func loss 0.14997731149196625\n",
      "\n",
      "episode 14, val func loss 0.18633805215358734\n",
      "\n",
      "episode 15, val func loss 0.1884629875421524\n",
      "\n",
      "episode 16, val func loss 0.1998208910226822\n",
      "\n",
      "Val func train loss in epoch 10:0.19491787254810333\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.18772949278354645\n",
      "\n",
      "episode 2, val func loss 0.17585328221321106\n",
      "\n",
      "episode 3, val func loss 0.2169022411108017\n",
      "\n",
      "episode 4, val func loss 0.17388013005256653\n",
      "\n",
      "episode 5, val func loss 0.1794113665819168\n",
      "\n",
      "episode 6, val func loss 0.19656281173229218\n",
      "\n",
      "episode 7, val func loss 0.18834541738033295\n",
      "\n",
      "episode 8, val func loss 0.1452367603778839\n",
      "\n",
      "episode 9, val func loss 0.2210567742586136\n",
      "\n",
      "episode 10, val func loss 0.17589779198169708\n",
      "\n",
      "episode 11, val func loss 0.24053825438022614\n",
      "\n",
      "episode 12, val func loss 0.19994623959064484\n",
      "\n",
      "episode 13, val func loss 0.18627949059009552\n",
      "\n",
      "episode 14, val func loss 0.21975448727607727\n",
      "\n",
      "episode 15, val func loss 0.18047747015953064\n",
      "\n",
      "episode 16, val func loss 0.22063814103603363\n",
      "\n",
      "Val func train loss in epoch 11:0.1942818844690919\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.14800678193569183\n",
      "\n",
      "episode 2, val func loss 0.1882041096687317\n",
      "\n",
      "episode 3, val func loss 0.21995411813259125\n",
      "\n",
      "episode 4, val func loss 0.1765204519033432\n",
      "\n",
      "episode 5, val func loss 0.2195652723312378\n",
      "\n",
      "episode 6, val func loss 0.21569646894931793\n",
      "\n",
      "episode 7, val func loss 0.22130322456359863\n",
      "\n",
      "episode 8, val func loss 0.1960141658782959\n",
      "\n",
      "episode 9, val func loss 0.17781007289886475\n",
      "\n",
      "episode 10, val func loss 0.23687264323234558\n",
      "\n",
      "episode 11, val func loss 0.18621428310871124\n",
      "\n",
      "episode 12, val func loss 0.1877661794424057\n",
      "\n",
      "episode 13, val func loss 0.181031733751297\n",
      "\n",
      "episode 14, val func loss 0.20023520290851593\n",
      "\n",
      "episode 15, val func loss 0.1813087910413742\n",
      "\n",
      "episode 16, val func loss 0.1747712343931198\n",
      "\n",
      "Val func train loss in epoch 12:0.19445467088371515\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1743231862783432\n",
      "\n",
      "episode 2, val func loss 0.14626142382621765\n",
      "\n",
      "episode 3, val func loss 0.17499800026416779\n",
      "\n",
      "episode 4, val func loss 0.17540612816810608\n",
      "\n",
      "episode 5, val func loss 0.22414663434028625\n",
      "\n",
      "episode 6, val func loss 0.22224648296833038\n",
      "\n",
      "episode 7, val func loss 0.17853446304798126\n",
      "\n",
      "episode 8, val func loss 0.19892430305480957\n",
      "\n",
      "episode 9, val func loss 0.18922735750675201\n",
      "\n",
      "episode 10, val func loss 0.22155088186264038\n",
      "\n",
      "episode 11, val func loss 0.1881442666053772\n",
      "\n",
      "episode 12, val func loss 0.1802670955657959\n",
      "\n",
      "episode 13, val func loss 0.20006512105464935\n",
      "\n",
      "episode 14, val func loss 0.23568211495876312\n",
      "\n",
      "episode 15, val func loss 0.186777263879776\n",
      "\n",
      "episode 16, val func loss 0.22177265584468842\n",
      "\n",
      "Val func train loss in epoch 13:0.19489546120166779\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19604146480560303\n",
      "\n",
      "episode 2, val func loss 0.2196778655052185\n",
      "\n",
      "episode 3, val func loss 0.1873568445444107\n",
      "\n",
      "episode 4, val func loss 0.18249087035655975\n",
      "\n",
      "episode 5, val func loss 0.15052127838134766\n",
      "\n",
      "episode 6, val func loss 0.21504978835582733\n",
      "\n",
      "episode 7, val func loss 0.2209988534450531\n",
      "\n",
      "episode 8, val func loss 0.19967518746852875\n",
      "\n",
      "episode 9, val func loss 0.18816141784191132\n",
      "\n",
      "episode 10, val func loss 0.17532029747962952\n",
      "\n",
      "episode 11, val func loss 0.22051186859607697\n",
      "\n",
      "episode 12, val func loss 0.17896270751953125\n",
      "\n",
      "episode 13, val func loss 0.1885577142238617\n",
      "\n",
      "episode 14, val func loss 0.1759273111820221\n",
      "\n",
      "episode 15, val func loss 0.17419633269309998\n",
      "\n",
      "episode 16, val func loss 0.24140876531600952\n",
      "\n",
      "Val func train loss in epoch 14:0.1946786604821682\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19695444405078888\n",
      "\n",
      "episode 2, val func loss 0.22002367675304413\n",
      "\n",
      "episode 3, val func loss 0.18617837131023407\n",
      "\n",
      "episode 4, val func loss 0.18843135237693787\n",
      "\n",
      "episode 5, val func loss 0.2194337248802185\n",
      "\n",
      "episode 6, val func loss 0.1801270991563797\n",
      "\n",
      "episode 7, val func loss 0.2209942638874054\n",
      "\n",
      "episode 8, val func loss 0.1874506175518036\n",
      "\n",
      "episode 9, val func loss 0.23573164641857147\n",
      "\n",
      "episode 10, val func loss 0.20016270875930786\n",
      "\n",
      "episode 11, val func loss 0.1753462553024292\n",
      "\n",
      "episode 12, val func loss 0.17774376273155212\n",
      "\n",
      "episode 13, val func loss 0.18113400042057037\n",
      "\n",
      "episode 14, val func loss 0.14726150035858154\n",
      "\n",
      "episode 15, val func loss 0.21662430465221405\n",
      "\n",
      "episode 16, val func loss 0.18000029027462006\n",
      "\n",
      "Val func train loss in epoch 15:0.19459987618029118\n",
      "***********************TIME WAS 5.007286091645558 min*****************************\n",
      "\n",
      "**********************ROUND 146 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.061468806117773056\n",
      "\n",
      "episode 2, policy loss -0.02247724123299122\n",
      "\n",
      "episode 3, policy loss -0.04782189428806305\n",
      "\n",
      "episode 4, policy loss -0.09456418454647064\n",
      "\n",
      "episode 5, policy loss -0.07162307947874069\n",
      "\n",
      "episode 6, policy loss -0.04572552070021629\n",
      "\n",
      "episode 7, policy loss -0.04825054109096527\n",
      "\n",
      "episode 8, policy loss -0.05427241325378418\n",
      "\n",
      "episode 9, policy loss -0.07035322487354279\n",
      "\n",
      "episode 10, policy loss -0.04045945778489113\n",
      "\n",
      "episode 11, policy loss -0.10765865445137024\n",
      "\n",
      "episode 12, policy loss -0.04776456579566002\n",
      "\n",
      "episode 13, policy loss -0.03488343209028244\n",
      "\n",
      "episode 14, policy loss -0.10053873062133789\n",
      "\n",
      "episode 15, policy loss -0.05941799655556679\n",
      "\n",
      "episode 16, policy loss -0.10572688281536102\n",
      "\n",
      "Policy train loss in epoch 0:-0.06331291410606354\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.03861324489116669\n",
      "\n",
      "episode 2, policy loss -0.11245837807655334\n",
      "\n",
      "episode 3, policy loss -0.10268522053956985\n",
      "\n",
      "episode 4, policy loss -0.07413750141859055\n",
      "\n",
      "episode 5, policy loss -0.0443292073905468\n",
      "\n",
      "episode 6, policy loss -0.045895062386989594\n",
      "\n",
      "episode 7, policy loss -0.07520370930433273\n",
      "\n",
      "episode 8, policy loss -0.1000170037150383\n",
      "\n",
      "episode 9, policy loss -0.04560340568423271\n",
      "\n",
      "episode 10, policy loss -0.05682653188705444\n",
      "\n",
      "episode 11, policy loss -0.030747242271900177\n",
      "\n",
      "episode 12, policy loss -0.053974464535713196\n",
      "\n",
      "episode 13, policy loss -0.07346780598163605\n",
      "\n",
      "episode 14, policy loss -0.10557074844837189\n",
      "\n",
      "episode 15, policy loss -0.06187642738223076\n",
      "\n",
      "episode 16, policy loss -0.050292208790779114\n",
      "\n",
      "Policy train loss in epoch 1:-0.06698113516904414\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.07392043620347977\n",
      "\n",
      "episode 2, policy loss -0.030946476384997368\n",
      "\n",
      "episode 3, policy loss -0.055072102695703506\n",
      "\n",
      "episode 4, policy loss -0.10349259525537491\n",
      "\n",
      "episode 5, policy loss -0.04133452847599983\n",
      "\n",
      "episode 6, policy loss -0.10157237946987152\n",
      "\n",
      "episode 7, policy loss -0.0452427975833416\n",
      "\n",
      "episode 8, policy loss -0.056995708495378494\n",
      "\n",
      "episode 9, policy loss -0.1144132986664772\n",
      "\n",
      "episode 10, policy loss -0.1075042113661766\n",
      "\n",
      "episode 11, policy loss -0.049834106117486954\n",
      "\n",
      "episode 12, policy loss -0.04782162606716156\n",
      "\n",
      "episode 13, policy loss -0.0762590616941452\n",
      "\n",
      "episode 14, policy loss -0.06225118413567543\n",
      "\n",
      "episode 15, policy loss -0.050862908363342285\n",
      "\n",
      "episode 16, policy loss -0.07655737549066544\n",
      "\n",
      "Policy train loss in epoch 2:-0.06838004977907985\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.06156733259558678\n",
      "\n",
      "episode 2, policy loss -0.07665809243917465\n",
      "\n",
      "episode 3, policy loss -0.0765257477760315\n",
      "\n",
      "episode 4, policy loss -0.11429104954004288\n",
      "\n",
      "episode 5, policy loss -0.04969951510429382\n",
      "\n",
      "episode 6, policy loss -0.10841193050146103\n",
      "\n",
      "episode 7, policy loss -0.04823847487568855\n",
      "\n",
      "episode 8, policy loss -0.10118602216243744\n",
      "\n",
      "episode 9, policy loss -0.04555080458521843\n",
      "\n",
      "episode 10, policy loss -0.07367844879627228\n",
      "\n",
      "episode 11, policy loss -0.0560460165143013\n",
      "\n",
      "episode 12, policy loss -0.05094216763973236\n",
      "\n",
      "episode 13, policy loss -0.04161311686038971\n",
      "\n",
      "episode 14, policy loss -0.031201886013150215\n",
      "\n",
      "episode 15, policy loss -0.05705971643328667\n",
      "\n",
      "episode 16, policy loss -0.1039394810795784\n",
      "\n",
      "Policy train loss in epoch 3:-0.06853811268229038\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.20030969381332397\n",
      "\n",
      "episode 2, val func loss 0.1927543729543686\n",
      "\n",
      "episode 3, val func loss 0.2070125937461853\n",
      "\n",
      "episode 4, val func loss 0.22437255084514618\n",
      "\n",
      "episode 5, val func loss 0.19592240452766418\n",
      "\n",
      "episode 6, val func loss 0.218411386013031\n",
      "\n",
      "episode 7, val func loss 0.18743328750133514\n",
      "\n",
      "episode 8, val func loss 0.1694129854440689\n",
      "\n",
      "episode 9, val func loss 0.19090130925178528\n",
      "\n",
      "episode 10, val func loss 0.2012491226196289\n",
      "\n",
      "episode 11, val func loss 0.22490276396274567\n",
      "\n",
      "episode 12, val func loss 0.19808392226696014\n",
      "\n",
      "episode 13, val func loss 0.19450229406356812\n",
      "\n",
      "episode 14, val func loss 0.20630842447280884\n",
      "\n",
      "episode 15, val func loss 0.17744196951389313\n",
      "\n",
      "episode 16, val func loss 0.18911494314670563\n",
      "\n",
      "Val func train loss in epoch 0:0.1986333765089512\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.22551237046718597\n",
      "\n",
      "episode 2, val func loss 0.20652426779270172\n",
      "\n",
      "episode 3, val func loss 0.18891936540603638\n",
      "\n",
      "episode 4, val func loss 0.21765246987342834\n",
      "\n",
      "episode 5, val func loss 0.22212080657482147\n",
      "\n",
      "episode 6, val func loss 0.1993335634469986\n",
      "\n",
      "episode 7, val func loss 0.18754906952381134\n",
      "\n",
      "episode 8, val func loss 0.16944125294685364\n",
      "\n",
      "episode 9, val func loss 0.19831490516662598\n",
      "\n",
      "episode 10, val func loss 0.19590094685554504\n",
      "\n",
      "episode 11, val func loss 0.19460715353488922\n",
      "\n",
      "episode 12, val func loss 0.20124174654483795\n",
      "\n",
      "episode 13, val func loss 0.20652709901332855\n",
      "\n",
      "episode 14, val func loss 0.17748799920082092\n",
      "\n",
      "episode 15, val func loss 0.1926293820142746\n",
      "\n",
      "episode 16, val func loss 0.1898188441991806\n",
      "\n",
      "Val func train loss in epoch 1:0.19834882766008377\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.2181755006313324\n",
      "\n",
      "episode 2, val func loss 0.17668838798999786\n",
      "\n",
      "episode 3, val func loss 0.19321611523628235\n",
      "\n",
      "episode 4, val func loss 0.22246508300304413\n",
      "\n",
      "episode 5, val func loss 0.19570782780647278\n",
      "\n",
      "episode 6, val func loss 0.1898604929447174\n",
      "\n",
      "episode 7, val func loss 0.1994289755821228\n",
      "\n",
      "episode 8, val func loss 0.22536683082580566\n",
      "\n",
      "episode 9, val func loss 0.20663084089756012\n",
      "\n",
      "episode 10, val func loss 0.18748418986797333\n",
      "\n",
      "episode 11, val func loss 0.20136216282844543\n",
      "\n",
      "episode 12, val func loss 0.19277556240558624\n",
      "\n",
      "episode 13, val func loss 0.2063634693622589\n",
      "\n",
      "episode 14, val func loss 0.1692737191915512\n",
      "\n",
      "episode 15, val func loss 0.19833706319332123\n",
      "\n",
      "episode 16, val func loss 0.18924464285373688\n",
      "\n",
      "Val func train loss in epoch 2:0.19827380403876305\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.22505886852741241\n",
      "\n",
      "episode 2, val func loss 0.20677687227725983\n",
      "\n",
      "episode 3, val func loss 0.19262364506721497\n",
      "\n",
      "episode 4, val func loss 0.20686280727386475\n",
      "\n",
      "episode 5, val func loss 0.1874680370092392\n",
      "\n",
      "episode 6, val func loss 0.20121420919895172\n",
      "\n",
      "episode 7, val func loss 0.21735337376594543\n",
      "\n",
      "episode 8, val func loss 0.17741267383098602\n",
      "\n",
      "episode 9, val func loss 0.16887204349040985\n",
      "\n",
      "episode 10, val func loss 0.19563010334968567\n",
      "\n",
      "episode 11, val func loss 0.19000202417373657\n",
      "\n",
      "episode 12, val func loss 0.1994924396276474\n",
      "\n",
      "episode 13, val func loss 0.19355419278144836\n",
      "\n",
      "episode 14, val func loss 0.19821125268936157\n",
      "\n",
      "episode 15, val func loss 0.18902438879013062\n",
      "\n",
      "episode 16, val func loss 0.22311845421791077\n",
      "\n",
      "Val func train loss in epoch 3:0.19829221162945032\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.20139628648757935\n",
      "\n",
      "episode 2, val func loss 0.18720820546150208\n",
      "\n",
      "episode 3, val func loss 0.19249512255191803\n",
      "\n",
      "episode 4, val func loss 0.16851672530174255\n",
      "\n",
      "episode 5, val func loss 0.19809643924236298\n",
      "\n",
      "episode 6, val func loss 0.18910042941570282\n",
      "\n",
      "episode 7, val func loss 0.199391707777977\n",
      "\n",
      "episode 8, val func loss 0.2066424936056137\n",
      "\n",
      "episode 9, val func loss 0.19009949266910553\n",
      "\n",
      "episode 10, val func loss 0.22542142868041992\n",
      "\n",
      "episode 11, val func loss 0.22170864045619965\n",
      "\n",
      "episode 12, val func loss 0.2066650390625\n",
      "\n",
      "episode 13, val func loss 0.17786720395088196\n",
      "\n",
      "episode 14, val func loss 0.2164449542760849\n",
      "\n",
      "episode 15, val func loss 0.19631294906139374\n",
      "\n",
      "episode 16, val func loss 0.19582493603229523\n",
      "\n",
      "Val func train loss in epoch 4:0.19832450337707996\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.17855225503444672\n",
      "\n",
      "episode 2, val func loss 0.19076065719127655\n",
      "\n",
      "episode 3, val func loss 0.2064923793077469\n",
      "\n",
      "episode 4, val func loss 0.1936780959367752\n",
      "\n",
      "episode 5, val func loss 0.19839486479759216\n",
      "\n",
      "episode 6, val func loss 0.19573874771595\n",
      "\n",
      "episode 7, val func loss 0.20015345513820648\n",
      "\n",
      "episode 8, val func loss 0.1925845444202423\n",
      "\n",
      "episode 9, val func loss 0.1683945208787918\n",
      "\n",
      "episode 10, val func loss 0.21938568353652954\n",
      "\n",
      "episode 11, val func loss 0.18705040216445923\n",
      "\n",
      "episode 12, val func loss 0.22594672441482544\n",
      "\n",
      "episode 13, val func loss 0.2220073789358139\n",
      "\n",
      "episode 14, val func loss 0.18929263949394226\n",
      "\n",
      "episode 15, val func loss 0.2013038545846939\n",
      "\n",
      "episode 16, val func loss 0.2072671502828598\n",
      "\n",
      "Val func train loss in epoch 5:0.1985627096146345\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19605454802513123\n",
      "\n",
      "episode 2, val func loss 0.20142199099063873\n",
      "\n",
      "episode 3, val func loss 0.19841252267360687\n",
      "\n",
      "episode 4, val func loss 0.22488760948181152\n",
      "\n",
      "episode 5, val func loss 0.19596199691295624\n",
      "\n",
      "episode 6, val func loss 0.20630212128162384\n",
      "\n",
      "episode 7, val func loss 0.2214105725288391\n",
      "\n",
      "episode 8, val func loss 0.20683807134628296\n",
      "\n",
      "episode 9, val func loss 0.1777404546737671\n",
      "\n",
      "episode 10, val func loss 0.1994655281305313\n",
      "\n",
      "episode 11, val func loss 0.18921251595020294\n",
      "\n",
      "episode 12, val func loss 0.21703243255615234\n",
      "\n",
      "episode 13, val func loss 0.19255203008651733\n",
      "\n",
      "episode 14, val func loss 0.169001504778862\n",
      "\n",
      "episode 15, val func loss 0.189945250749588\n",
      "\n",
      "episode 16, val func loss 0.18718956410884857\n",
      "\n",
      "Val func train loss in epoch 6:0.19833929464221\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.20145700871944427\n",
      "\n",
      "episode 2, val func loss 0.19832868874073029\n",
      "\n",
      "episode 3, val func loss 0.16862303018569946\n",
      "\n",
      "episode 4, val func loss 0.1770801544189453\n",
      "\n",
      "episode 5, val func loss 0.19274473190307617\n",
      "\n",
      "episode 6, val func loss 0.18883652985095978\n",
      "\n",
      "episode 7, val func loss 0.21958164870738983\n",
      "\n",
      "episode 8, val func loss 0.1897806078195572\n",
      "\n",
      "episode 9, val func loss 0.20658867061138153\n",
      "\n",
      "episode 10, val func loss 0.22290068864822388\n",
      "\n",
      "episode 11, val func loss 0.18735703825950623\n",
      "\n",
      "episode 12, val func loss 0.19268052279949188\n",
      "\n",
      "episode 13, val func loss 0.19612076878547668\n",
      "\n",
      "episode 14, val func loss 0.2061443328857422\n",
      "\n",
      "episode 15, val func loss 0.19939899444580078\n",
      "\n",
      "episode 16, val func loss 0.22438248991966248\n",
      "\n",
      "Val func train loss in epoch 7:0.198250369168818\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.19868257641792297\n",
      "\n",
      "episode 2, val func loss 0.22468136250972748\n",
      "\n",
      "episode 3, val func loss 0.19936414062976837\n",
      "\n",
      "episode 4, val func loss 0.18830792605876923\n",
      "\n",
      "episode 5, val func loss 0.206059068441391\n",
      "\n",
      "episode 6, val func loss 0.19309885799884796\n",
      "\n",
      "episode 7, val func loss 0.19613118469715118\n",
      "\n",
      "episode 8, val func loss 0.17758680880069733\n",
      "\n",
      "episode 9, val func loss 0.19344981014728546\n",
      "\n",
      "episode 10, val func loss 0.20170946419239044\n",
      "\n",
      "episode 11, val func loss 0.16846856474876404\n",
      "\n",
      "episode 12, val func loss 0.18980631232261658\n",
      "\n",
      "episode 13, val func loss 0.20727813243865967\n",
      "\n",
      "episode 14, val func loss 0.18926529586315155\n",
      "\n",
      "episode 15, val func loss 0.220113143324852\n",
      "\n",
      "episode 16, val func loss 0.22331437468528748\n",
      "\n",
      "Val func train loss in epoch 8:0.19858231395483017\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.16891448199748993\n",
      "\n",
      "episode 2, val func loss 0.2209876924753189\n",
      "\n",
      "episode 3, val func loss 0.19641371071338654\n",
      "\n",
      "episode 4, val func loss 0.201680526137352\n",
      "\n",
      "episode 5, val func loss 0.19705134630203247\n",
      "\n",
      "episode 6, val func loss 0.20736469328403473\n",
      "\n",
      "episode 7, val func loss 0.1881157010793686\n",
      "\n",
      "episode 8, val func loss 0.21652793884277344\n",
      "\n",
      "episode 9, val func loss 0.19946932792663574\n",
      "\n",
      "episode 10, val func loss 0.22495347261428833\n",
      "\n",
      "episode 11, val func loss 0.19261932373046875\n",
      "\n",
      "episode 12, val func loss 0.18932029604911804\n",
      "\n",
      "episode 13, val func loss 0.20664361119270325\n",
      "\n",
      "episode 14, val func loss 0.19807687401771545\n",
      "\n",
      "episode 15, val func loss 0.1772942990064621\n",
      "\n",
      "episode 16, val func loss 0.19015862047672272\n",
      "\n",
      "Val func train loss in epoch 9:0.19847449474036694\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.16855081915855408\n",
      "\n",
      "episode 2, val func loss 0.20746219158172607\n",
      "\n",
      "episode 3, val func loss 0.19951698184013367\n",
      "\n",
      "episode 4, val func loss 0.17715153098106384\n",
      "\n",
      "episode 5, val func loss 0.19573572278022766\n",
      "\n",
      "episode 6, val func loss 0.19814692437648773\n",
      "\n",
      "episode 7, val func loss 0.18886665999889374\n",
      "\n",
      "episode 8, val func loss 0.22198070585727692\n",
      "\n",
      "episode 9, val func loss 0.1873241364955902\n",
      "\n",
      "episode 10, val func loss 0.21692641079425812\n",
      "\n",
      "episode 11, val func loss 0.22423578798770905\n",
      "\n",
      "episode 12, val func loss 0.19262191653251648\n",
      "\n",
      "episode 13, val func loss 0.20123428106307983\n",
      "\n",
      "episode 14, val func loss 0.1954105645418167\n",
      "\n",
      "episode 15, val func loss 0.1924879252910614\n",
      "\n",
      "episode 16, val func loss 0.206394761800766\n",
      "\n",
      "Val func train loss in epoch 10:0.1983779575675726\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1776147186756134\n",
      "\n",
      "episode 2, val func loss 0.18986812233924866\n",
      "\n",
      "episode 3, val func loss 0.22685876488685608\n",
      "\n",
      "episode 4, val func loss 0.19260840117931366\n",
      "\n",
      "episode 5, val func loss 0.202484592795372\n",
      "\n",
      "episode 6, val func loss 0.21916203200817108\n",
      "\n",
      "episode 7, val func loss 0.1873895823955536\n",
      "\n",
      "episode 8, val func loss 0.168710395693779\n",
      "\n",
      "episode 9, val func loss 0.1894732415676117\n",
      "\n",
      "episode 10, val func loss 0.19162485003471375\n",
      "\n",
      "episode 11, val func loss 0.19529989361763\n",
      "\n",
      "episode 12, val func loss 0.20618107914924622\n",
      "\n",
      "episode 13, val func loss 0.2191440612077713\n",
      "\n",
      "episode 14, val func loss 0.20073804259300232\n",
      "\n",
      "episode 15, val func loss 0.20020948350429535\n",
      "\n",
      "episode 16, val func loss 0.20673422515392303\n",
      "\n",
      "Val func train loss in epoch 11:0.19838134292513132\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19547848403453827\n",
      "\n",
      "episode 2, val func loss 0.20231567323207855\n",
      "\n",
      "episode 3, val func loss 0.20506742596626282\n",
      "\n",
      "episode 4, val func loss 0.22528763115406036\n",
      "\n",
      "episode 5, val func loss 0.1772763729095459\n",
      "\n",
      "episode 6, val func loss 0.18781110644340515\n",
      "\n",
      "episode 7, val func loss 0.20831669867038727\n",
      "\n",
      "episode 8, val func loss 0.1918063461780548\n",
      "\n",
      "episode 9, val func loss 0.1969050168991089\n",
      "\n",
      "episode 10, val func loss 0.1990712285041809\n",
      "\n",
      "episode 11, val func loss 0.1894141137599945\n",
      "\n",
      "episode 12, val func loss 0.21540944278240204\n",
      "\n",
      "episode 13, val func loss 0.19021445512771606\n",
      "\n",
      "episode 14, val func loss 0.1935988813638687\n",
      "\n",
      "episode 15, val func loss 0.16838566958904266\n",
      "\n",
      "episode 16, val func loss 0.22318601608276367\n",
      "\n",
      "Val func train loss in epoch 12:0.19809653516858816\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.18870913982391357\n",
      "\n",
      "episode 2, val func loss 0.2065635770559311\n",
      "\n",
      "episode 3, val func loss 0.1985885351896286\n",
      "\n",
      "episode 4, val func loss 0.21790196001529694\n",
      "\n",
      "episode 5, val func loss 0.1683407872915268\n",
      "\n",
      "episode 6, val func loss 0.2195839285850525\n",
      "\n",
      "episode 7, val func loss 0.19206558167934418\n",
      "\n",
      "episode 8, val func loss 0.19409486651420593\n",
      "\n",
      "episode 9, val func loss 0.1890469640493393\n",
      "\n",
      "episode 10, val func loss 0.22333690524101257\n",
      "\n",
      "episode 11, val func loss 0.17768150568008423\n",
      "\n",
      "episode 12, val func loss 0.19736875593662262\n",
      "\n",
      "episode 13, val func loss 0.20705661177635193\n",
      "\n",
      "episode 14, val func loss 0.18594402074813843\n",
      "\n",
      "episode 15, val func loss 0.1945805847644806\n",
      "\n",
      "episode 16, val func loss 0.20070482790470123\n",
      "\n",
      "Val func train loss in epoch 13:0.1975980345159769\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.22663532197475433\n",
      "\n",
      "episode 2, val func loss 0.19796445965766907\n",
      "\n",
      "episode 3, val func loss 0.17172759771347046\n",
      "\n",
      "episode 4, val func loss 0.1984548419713974\n",
      "\n",
      "episode 5, val func loss 0.19360090792179108\n",
      "\n",
      "episode 6, val func loss 0.19306376576423645\n",
      "\n",
      "episode 7, val func loss 0.1939888447523117\n",
      "\n",
      "episode 8, val func loss 0.20627491176128387\n",
      "\n",
      "episode 9, val func loss 0.18625508248806\n",
      "\n",
      "episode 10, val func loss 0.1726524382829666\n",
      "\n",
      "episode 11, val func loss 0.18580657243728638\n",
      "\n",
      "episode 12, val func loss 0.21423645317554474\n",
      "\n",
      "episode 13, val func loss 0.1895390897989273\n",
      "\n",
      "episode 14, val func loss 0.1976788341999054\n",
      "\n",
      "episode 15, val func loss 0.22203506529331207\n",
      "\n",
      "episode 16, val func loss 0.22426465153694153\n",
      "\n",
      "Val func train loss in epoch 14:0.19838617742061615\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.19672444462776184\n",
      "\n",
      "episode 2, val func loss 0.22737407684326172\n",
      "\n",
      "episode 3, val func loss 0.19726181030273438\n",
      "\n",
      "episode 4, val func loss 0.2192617505788803\n",
      "\n",
      "episode 5, val func loss 0.19670873880386353\n",
      "\n",
      "episode 6, val func loss 0.18219389021396637\n",
      "\n",
      "episode 7, val func loss 0.2080911248922348\n",
      "\n",
      "episode 8, val func loss 0.1884087771177292\n",
      "\n",
      "episode 9, val func loss 0.2021944224834442\n",
      "\n",
      "episode 10, val func loss 0.2064071148633957\n",
      "\n",
      "episode 11, val func loss 0.16879762709140778\n",
      "\n",
      "episode 12, val func loss 0.21961042284965515\n",
      "\n",
      "episode 13, val func loss 0.19021013379096985\n",
      "\n",
      "episode 14, val func loss 0.18855376541614532\n",
      "\n",
      "episode 15, val func loss 0.1981206238269806\n",
      "\n",
      "episode 16, val func loss 0.19336143136024475\n",
      "\n",
      "Val func train loss in epoch 15:0.19895500969141722\n",
      "***********************TIME WAS 5.004919751485189 min*****************************\n",
      "\n",
      "**********************ROUND 147 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.008825177326798439\n",
      "\n",
      "episode 2, policy loss -0.033480580896139145\n",
      "\n",
      "episode 3, policy loss 0.010803424753248692\n",
      "\n",
      "episode 4, policy loss -0.02715488150715828\n",
      "\n",
      "episode 5, policy loss -0.0015561782056465745\n",
      "\n",
      "episode 6, policy loss -0.050083912909030914\n",
      "\n",
      "episode 7, policy loss -0.023528989404439926\n",
      "\n",
      "episode 8, policy loss -0.004891376476734877\n",
      "\n",
      "episode 9, policy loss -0.021479101851582527\n",
      "\n",
      "episode 10, policy loss -0.01757855713367462\n",
      "\n",
      "episode 11, policy loss -0.047857172787189484\n",
      "\n",
      "episode 12, policy loss 0.006240622606128454\n",
      "\n",
      "episode 13, policy loss -0.05343307927250862\n",
      "\n",
      "episode 14, policy loss -0.024895863607525826\n",
      "\n",
      "episode 15, policy loss -0.04626159369945526\n",
      "\n",
      "episode 16, policy loss -0.041498128324747086\n",
      "\n",
      "Policy train loss in epoch 0:-0.024092534127703402\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.05163264274597168\n",
      "\n",
      "episode 2, policy loss 0.0003755029756575823\n",
      "\n",
      "episode 3, policy loss -0.04632745310664177\n",
      "\n",
      "episode 4, policy loss 0.0035659836139529943\n",
      "\n",
      "episode 5, policy loss -0.021189844235777855\n",
      "\n",
      "episode 6, policy loss -0.042130228132009506\n",
      "\n",
      "episode 7, policy loss -0.023726364597678185\n",
      "\n",
      "episode 8, policy loss -0.05864409729838371\n",
      "\n",
      "episode 9, policy loss -0.05288209766149521\n",
      "\n",
      "episode 10, policy loss -0.050659045577049255\n",
      "\n",
      "episode 11, policy loss -0.029072782024741173\n",
      "\n",
      "episode 12, policy loss -0.02204517275094986\n",
      "\n",
      "episode 13, policy loss -0.034532032907009125\n",
      "\n",
      "episode 14, policy loss -0.0054885162971913815\n",
      "\n",
      "episode 15, policy loss -0.025085384026169777\n",
      "\n",
      "episode 16, policy loss -0.0065414984710514545\n",
      "\n",
      "Policy train loss in epoch 1:-0.029125979577656835\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.04932757467031479\n",
      "\n",
      "episode 2, policy loss -0.058877915143966675\n",
      "\n",
      "episode 3, policy loss -0.028794489800930023\n",
      "\n",
      "episode 4, policy loss -0.03482571244239807\n",
      "\n",
      "episode 5, policy loss -0.006355571560561657\n",
      "\n",
      "episode 6, policy loss -0.04431573301553726\n",
      "\n",
      "episode 7, policy loss -0.02526259981095791\n",
      "\n",
      "episode 8, policy loss -0.006537945009768009\n",
      "\n",
      "episode 9, policy loss -0.022713126614689827\n",
      "\n",
      "episode 10, policy loss 0.002668434986844659\n",
      "\n",
      "episode 11, policy loss -0.049679309129714966\n",
      "\n",
      "episode 12, policy loss -0.022450357675552368\n",
      "\n",
      "episode 13, policy loss -0.0004907030379399657\n",
      "\n",
      "episode 14, policy loss -0.02468920685350895\n",
      "\n",
      "episode 15, policy loss -0.05284373462200165\n",
      "\n",
      "episode 16, policy loss -0.05160417780280113\n",
      "\n",
      "Policy train loss in epoch 2:-0.029756232637737412\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.025362275540828705\n",
      "\n",
      "episode 2, policy loss -0.058798812329769135\n",
      "\n",
      "episode 3, policy loss -0.035138312727212906\n",
      "\n",
      "episode 4, policy loss -0.006323179695755243\n",
      "\n",
      "episode 5, policy loss -8.686640649102628e-05\n",
      "\n",
      "episode 6, policy loss -0.050407327711582184\n",
      "\n",
      "episode 7, policy loss -0.006701576057821512\n",
      "\n",
      "episode 8, policy loss -0.02556672692298889\n",
      "\n",
      "episode 9, policy loss -0.052243608981370926\n",
      "\n",
      "episode 10, policy loss -0.029449235647916794\n",
      "\n",
      "episode 11, policy loss -0.0222077164798975\n",
      "\n",
      "episode 12, policy loss 0.0028424772899597883\n",
      "\n",
      "episode 13, policy loss -0.02220647595822811\n",
      "\n",
      "episode 14, policy loss -0.052532076835632324\n",
      "\n",
      "episode 15, policy loss -0.04453732818365097\n",
      "\n",
      "episode 16, policy loss -0.04938839375972748\n",
      "\n",
      "Policy train loss in epoch 3:-0.02988171474680712\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.1868373602628708\n",
      "\n",
      "episode 2, val func loss 0.17686572670936584\n",
      "\n",
      "episode 3, val func loss 0.19958911836147308\n",
      "\n",
      "episode 4, val func loss 0.19810882210731506\n",
      "\n",
      "episode 5, val func loss 0.19807395339012146\n",
      "\n",
      "episode 6, val func loss 0.17641949653625488\n",
      "\n",
      "episode 7, val func loss 0.17159321904182434\n",
      "\n",
      "episode 8, val func loss 0.1954461634159088\n",
      "\n",
      "episode 9, val func loss 0.20144425332546234\n",
      "\n",
      "episode 10, val func loss 0.20138902962207794\n",
      "\n",
      "episode 11, val func loss 0.187041237950325\n",
      "\n",
      "episode 12, val func loss 0.18959739804267883\n",
      "\n",
      "episode 13, val func loss 0.17062826454639435\n",
      "\n",
      "episode 14, val func loss 0.1921953707933426\n",
      "\n",
      "episode 15, val func loss 0.18711745738983154\n",
      "\n",
      "episode 16, val func loss 0.17859454452991486\n",
      "\n",
      "Val func train loss in epoch 0:0.1881838385015726\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.16932551562786102\n",
      "\n",
      "episode 2, val func loss 0.18730677664279938\n",
      "\n",
      "episode 3, val func loss 0.190043106675148\n",
      "\n",
      "episode 4, val func loss 0.1771780401468277\n",
      "\n",
      "episode 5, val func loss 0.20339837670326233\n",
      "\n",
      "episode 6, val func loss 0.19895637035369873\n",
      "\n",
      "episode 7, val func loss 0.1701967716217041\n",
      "\n",
      "episode 8, val func loss 0.18677407503128052\n",
      "\n",
      "episode 9, val func loss 0.17556437849998474\n",
      "\n",
      "episode 10, val func loss 0.192274808883667\n",
      "\n",
      "episode 11, val func loss 0.2008589506149292\n",
      "\n",
      "episode 12, val func loss 0.19580024480819702\n",
      "\n",
      "episode 13, val func loss 0.1796978861093521\n",
      "\n",
      "episode 14, val func loss 0.18758253753185272\n",
      "\n",
      "episode 15, val func loss 0.1986035257577896\n",
      "\n",
      "episode 16, val func loss 0.19778980314731598\n",
      "\n",
      "Val func train loss in epoch 1:0.18820944800972939\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.19506236910820007\n",
      "\n",
      "episode 2, val func loss 0.17798370122909546\n",
      "\n",
      "episode 3, val func loss 0.2004937082529068\n",
      "\n",
      "episode 4, val func loss 0.19864965975284576\n",
      "\n",
      "episode 5, val func loss 0.2013479322195053\n",
      "\n",
      "episode 6, val func loss 0.1872064769268036\n",
      "\n",
      "episode 7, val func loss 0.19279256463050842\n",
      "\n",
      "episode 8, val func loss 0.17929597198963165\n",
      "\n",
      "episode 9, val func loss 0.1980411261320114\n",
      "\n",
      "episode 10, val func loss 0.18972264230251312\n",
      "\n",
      "episode 11, val func loss 0.19873107969760895\n",
      "\n",
      "episode 12, val func loss 0.17559897899627686\n",
      "\n",
      "episode 13, val func loss 0.18740414083003998\n",
      "\n",
      "episode 14, val func loss 0.17031094431877136\n",
      "\n",
      "episode 15, val func loss 0.16861067712306976\n",
      "\n",
      "episode 16, val func loss 0.18665190041065216\n",
      "\n",
      "Val func train loss in epoch 2:0.18799399212002754\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.2010168880224228\n",
      "\n",
      "episode 2, val func loss 0.2024555504322052\n",
      "\n",
      "episode 3, val func loss 0.1698029786348343\n",
      "\n",
      "episode 4, val func loss 0.16861146688461304\n",
      "\n",
      "episode 5, val func loss 0.18713822960853577\n",
      "\n",
      "episode 6, val func loss 0.1862994283437729\n",
      "\n",
      "episode 7, val func loss 0.19869036972522736\n",
      "\n",
      "episode 8, val func loss 0.18684253096580505\n",
      "\n",
      "episode 9, val func loss 0.1785360425710678\n",
      "\n",
      "episode 10, val func loss 0.1892041116952896\n",
      "\n",
      "episode 11, val func loss 0.1975003331899643\n",
      "\n",
      "episode 12, val func loss 0.17617064714431763\n",
      "\n",
      "episode 13, val func loss 0.1949746161699295\n",
      "\n",
      "episode 14, val func loss 0.17728979885578156\n",
      "\n",
      "episode 15, val func loss 0.19998766481876373\n",
      "\n",
      "episode 16, val func loss 0.1920887976884842\n",
      "\n",
      "Val func train loss in epoch 3:0.18791309092193842\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.17727026343345642\n",
      "\n",
      "episode 2, val func loss 0.19731298089027405\n",
      "\n",
      "episode 3, val func loss 0.17162534594535828\n",
      "\n",
      "episode 4, val func loss 0.1869375854730606\n",
      "\n",
      "episode 5, val func loss 0.16924023628234863\n",
      "\n",
      "episode 6, val func loss 0.17921236157417297\n",
      "\n",
      "episode 7, val func loss 0.19158564507961273\n",
      "\n",
      "episode 8, val func loss 0.1872009038925171\n",
      "\n",
      "episode 9, val func loss 0.19328628480434418\n",
      "\n",
      "episode 10, val func loss 0.19958919286727905\n",
      "\n",
      "episode 11, val func loss 0.18733207881450653\n",
      "\n",
      "episode 12, val func loss 0.19614356756210327\n",
      "\n",
      "episode 13, val func loss 0.19971835613250732\n",
      "\n",
      "episode 14, val func loss 0.20005500316619873\n",
      "\n",
      "episode 15, val func loss 0.20025044679641724\n",
      "\n",
      "episode 16, val func loss 0.17959806323051453\n",
      "\n",
      "Val func train loss in epoch 4:0.18852239474654198\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1947934925556183\n",
      "\n",
      "episode 2, val func loss 0.17899563908576965\n",
      "\n",
      "episode 3, val func loss 0.20097380876541138\n",
      "\n",
      "episode 4, val func loss 0.16956526041030884\n",
      "\n",
      "episode 5, val func loss 0.19935216009616852\n",
      "\n",
      "episode 6, val func loss 0.19037719070911407\n",
      "\n",
      "episode 7, val func loss 0.17642053961753845\n",
      "\n",
      "episode 8, val func loss 0.20020632445812225\n",
      "\n",
      "episode 9, val func loss 0.19859708845615387\n",
      "\n",
      "episode 10, val func loss 0.1861894428730011\n",
      "\n",
      "episode 11, val func loss 0.1695769727230072\n",
      "\n",
      "episode 12, val func loss 0.19665618240833282\n",
      "\n",
      "episode 13, val func loss 0.17516827583312988\n",
      "\n",
      "episode 14, val func loss 0.18788018822669983\n",
      "\n",
      "episode 15, val func loss 0.19662851095199585\n",
      "\n",
      "episode 16, val func loss 0.18893060088157654\n",
      "\n",
      "Val func train loss in epoch 5:0.18814447987824678\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.1893017441034317\n",
      "\n",
      "episode 2, val func loss 0.18446572124958038\n",
      "\n",
      "episode 3, val func loss 0.19727614521980286\n",
      "\n",
      "episode 4, val func loss 0.17126935720443726\n",
      "\n",
      "episode 5, val func loss 0.19679787755012512\n",
      "\n",
      "episode 6, val func loss 0.17742812633514404\n",
      "\n",
      "episode 7, val func loss 0.17854216694831848\n",
      "\n",
      "episode 8, val func loss 0.2001831829547882\n",
      "\n",
      "episode 9, val func loss 0.1695776879787445\n",
      "\n",
      "episode 10, val func loss 0.20125143229961395\n",
      "\n",
      "episode 11, val func loss 0.18576261401176453\n",
      "\n",
      "episode 12, val func loss 0.1901891529560089\n",
      "\n",
      "episode 13, val func loss 0.2015768140554428\n",
      "\n",
      "episode 14, val func loss 0.17478686571121216\n",
      "\n",
      "episode 15, val func loss 0.18871481716632843\n",
      "\n",
      "episode 16, val func loss 0.19828800857067108\n",
      "\n",
      "Val func train loss in epoch 6:0.1878382321447134\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.19909435510635376\n",
      "\n",
      "episode 2, val func loss 0.1946122646331787\n",
      "\n",
      "episode 3, val func loss 0.19522778689861298\n",
      "\n",
      "episode 4, val func loss 0.17561693489551544\n",
      "\n",
      "episode 5, val func loss 0.18668405711650848\n",
      "\n",
      "episode 6, val func loss 0.1872599720954895\n",
      "\n",
      "episode 7, val func loss 0.1787339150905609\n",
      "\n",
      "episode 8, val func loss 0.18676038086414337\n",
      "\n",
      "episode 9, val func loss 0.20085616409778595\n",
      "\n",
      "episode 10, val func loss 0.17151769995689392\n",
      "\n",
      "episode 11, val func loss 0.17508213222026825\n",
      "\n",
      "episode 12, val func loss 0.18911461532115936\n",
      "\n",
      "episode 13, val func loss 0.16968828439712524\n",
      "\n",
      "episode 14, val func loss 0.20331868529319763\n",
      "\n",
      "episode 15, val func loss 0.2002979815006256\n",
      "\n",
      "episode 16, val func loss 0.19091477990150452\n",
      "\n",
      "Val func train loss in epoch 7:0.18779875058680773\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.19031313061714172\n",
      "\n",
      "episode 2, val func loss 0.20144319534301758\n",
      "\n",
      "episode 3, val func loss 0.1966737061738968\n",
      "\n",
      "episode 4, val func loss 0.18935473263263702\n",
      "\n",
      "episode 5, val func loss 0.19042597711086273\n",
      "\n",
      "episode 6, val func loss 0.17799191176891327\n",
      "\n",
      "episode 7, val func loss 0.1926414668560028\n",
      "\n",
      "episode 8, val func loss 0.17074859142303467\n",
      "\n",
      "episode 9, val func loss 0.19937826693058014\n",
      "\n",
      "episode 10, val func loss 0.17710474133491516\n",
      "\n",
      "episode 11, val func loss 0.2007560282945633\n",
      "\n",
      "episode 12, val func loss 0.19810594618320465\n",
      "\n",
      "episode 13, val func loss 0.17816060781478882\n",
      "\n",
      "episode 14, val func loss 0.16847218573093414\n",
      "\n",
      "episode 15, val func loss 0.18576213717460632\n",
      "\n",
      "episode 16, val func loss 0.19542157649993896\n",
      "\n",
      "Val func train loss in epoch 8:0.18829713761806488\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.17208614945411682\n",
      "\n",
      "episode 2, val func loss 0.19680504500865936\n",
      "\n",
      "episode 3, val func loss 0.19867180287837982\n",
      "\n",
      "episode 4, val func loss 0.1953192800283432\n",
      "\n",
      "episode 5, val func loss 0.17679400742053986\n",
      "\n",
      "episode 6, val func loss 0.18673673272132874\n",
      "\n",
      "episode 7, val func loss 0.19808122515678406\n",
      "\n",
      "episode 8, val func loss 0.1878126859664917\n",
      "\n",
      "episode 9, val func loss 0.1763429492712021\n",
      "\n",
      "episode 10, val func loss 0.17885589599609375\n",
      "\n",
      "episode 11, val func loss 0.18636301159858704\n",
      "\n",
      "episode 12, val func loss 0.16894645988941193\n",
      "\n",
      "episode 13, val func loss 0.1935238242149353\n",
      "\n",
      "episode 14, val func loss 0.20292891561985016\n",
      "\n",
      "episode 15, val func loss 0.1899157613515854\n",
      "\n",
      "episode 16, val func loss 0.20341573655605316\n",
      "\n",
      "Val func train loss in epoch 9:0.18828746769577265\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.18319955468177795\n",
      "\n",
      "episode 2, val func loss 0.20082461833953857\n",
      "\n",
      "episode 3, val func loss 0.18879170715808868\n",
      "\n",
      "episode 4, val func loss 0.1796601414680481\n",
      "\n",
      "episode 5, val func loss 0.1999945044517517\n",
      "\n",
      "episode 6, val func loss 0.1968493014574051\n",
      "\n",
      "episode 7, val func loss 0.17255714535713196\n",
      "\n",
      "episode 8, val func loss 0.19377870857715607\n",
      "\n",
      "episode 9, val func loss 0.17709745466709137\n",
      "\n",
      "episode 10, val func loss 0.20067919790744781\n",
      "\n",
      "episode 11, val func loss 0.18757836520671844\n",
      "\n",
      "episode 12, val func loss 0.18783743679523468\n",
      "\n",
      "episode 13, val func loss 0.17629261314868927\n",
      "\n",
      "episode 14, val func loss 0.1683322638273239\n",
      "\n",
      "episode 15, val func loss 0.1926918923854828\n",
      "\n",
      "episode 16, val func loss 0.2004423588514328\n",
      "\n",
      "Val func train loss in epoch 10:0.18791295401751995\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.19844794273376465\n",
      "\n",
      "episode 2, val func loss 0.19962303340435028\n",
      "\n",
      "episode 3, val func loss 0.18773701786994934\n",
      "\n",
      "episode 4, val func loss 0.17005285620689392\n",
      "\n",
      "episode 5, val func loss 0.17892713844776154\n",
      "\n",
      "episode 6, val func loss 0.1874307096004486\n",
      "\n",
      "episode 7, val func loss 0.19073650240898132\n",
      "\n",
      "episode 8, val func loss 0.17655879259109497\n",
      "\n",
      "episode 9, val func loss 0.19212429225444794\n",
      "\n",
      "episode 10, val func loss 0.185786172747612\n",
      "\n",
      "episode 11, val func loss 0.20210017263889313\n",
      "\n",
      "episode 12, val func loss 0.19955268502235413\n",
      "\n",
      "episode 13, val func loss 0.16893774271011353\n",
      "\n",
      "episode 14, val func loss 0.19598212838172913\n",
      "\n",
      "episode 15, val func loss 0.19948363304138184\n",
      "\n",
      "episode 16, val func loss 0.17657485604286194\n",
      "\n",
      "Val func train loss in epoch 11:0.1881284797564149\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.2001212239265442\n",
      "\n",
      "episode 2, val func loss 0.1874619424343109\n",
      "\n",
      "episode 3, val func loss 0.2018912434577942\n",
      "\n",
      "episode 4, val func loss 0.1747853308916092\n",
      "\n",
      "episode 5, val func loss 0.19757047295570374\n",
      "\n",
      "episode 6, val func loss 0.19383372366428375\n",
      "\n",
      "episode 7, val func loss 0.17662185430526733\n",
      "\n",
      "episode 8, val func loss 0.1690906584262848\n",
      "\n",
      "episode 9, val func loss 0.19094109535217285\n",
      "\n",
      "episode 10, val func loss 0.18859440088272095\n",
      "\n",
      "episode 11, val func loss 0.19830326735973358\n",
      "\n",
      "episode 12, val func loss 0.18968236446380615\n",
      "\n",
      "episode 13, val func loss 0.18845361471176147\n",
      "\n",
      "episode 14, val func loss 0.1778641641139984\n",
      "\n",
      "episode 15, val func loss 0.17163147032260895\n",
      "\n",
      "episode 16, val func loss 0.19653648138046265\n",
      "\n",
      "Val func train loss in epoch 12:0.18771145679056644\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19749073684215546\n",
      "\n",
      "episode 2, val func loss 0.2020317167043686\n",
      "\n",
      "episode 3, val func loss 0.18732896447181702\n",
      "\n",
      "episode 4, val func loss 0.17669367790222168\n",
      "\n",
      "episode 5, val func loss 0.192908376455307\n",
      "\n",
      "episode 6, val func loss 0.1988554447889328\n",
      "\n",
      "episode 7, val func loss 0.17922548949718475\n",
      "\n",
      "episode 8, val func loss 0.1704864203929901\n",
      "\n",
      "episode 9, val func loss 0.18737034499645233\n",
      "\n",
      "episode 10, val func loss 0.20079053938388824\n",
      "\n",
      "episode 11, val func loss 0.18603673577308655\n",
      "\n",
      "episode 12, val func loss 0.18973201513290405\n",
      "\n",
      "episode 13, val func loss 0.1698840856552124\n",
      "\n",
      "episode 14, val func loss 0.19803932309150696\n",
      "\n",
      "episode 15, val func loss 0.19784919917583466\n",
      "\n",
      "episode 16, val func loss 0.17630477249622345\n",
      "\n",
      "Val func train loss in epoch 13:0.18818924017250538\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.19397656619548798\n",
      "\n",
      "episode 2, val func loss 0.18551167845726013\n",
      "\n",
      "episode 3, val func loss 0.17647238075733185\n",
      "\n",
      "episode 4, val func loss 0.1992783099412918\n",
      "\n",
      "episode 5, val func loss 0.19086088240146637\n",
      "\n",
      "episode 6, val func loss 0.1895839422941208\n",
      "\n",
      "episode 7, val func loss 0.19912301003932953\n",
      "\n",
      "episode 8, val func loss 0.17080862820148468\n",
      "\n",
      "episode 9, val func loss 0.17526398599147797\n",
      "\n",
      "episode 10, val func loss 0.19456306099891663\n",
      "\n",
      "episode 11, val func loss 0.20208187401294708\n",
      "\n",
      "episode 12, val func loss 0.18283429741859436\n",
      "\n",
      "episode 13, val func loss 0.20257672667503357\n",
      "\n",
      "episode 14, val func loss 0.18266823887825012\n",
      "\n",
      "episode 15, val func loss 0.18977928161621094\n",
      "\n",
      "episode 16, val func loss 0.1726987361907959\n",
      "\n",
      "Val func train loss in epoch 14:0.18800510000437498\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.20071016252040863\n",
      "\n",
      "episode 2, val func loss 0.17933858931064606\n",
      "\n",
      "episode 3, val func loss 0.20108938217163086\n",
      "\n",
      "episode 4, val func loss 0.19001023471355438\n",
      "\n",
      "episode 5, val func loss 0.17727802693843842\n",
      "\n",
      "episode 6, val func loss 0.18886789679527283\n",
      "\n",
      "episode 7, val func loss 0.1899167001247406\n",
      "\n",
      "episode 8, val func loss 0.17633338272571564\n",
      "\n",
      "episode 9, val func loss 0.19693823158740997\n",
      "\n",
      "episode 10, val func loss 0.18948878347873688\n",
      "\n",
      "episode 11, val func loss 0.19725309312343597\n",
      "\n",
      "episode 12, val func loss 0.18621277809143066\n",
      "\n",
      "episode 13, val func loss 0.2012505829334259\n",
      "\n",
      "episode 14, val func loss 0.1695622354745865\n",
      "\n",
      "episode 15, val func loss 0.1693565994501114\n",
      "\n",
      "episode 16, val func loss 0.198282390832901\n",
      "\n",
      "Val func train loss in epoch 15:0.18824306689202785\n",
      "***********************TIME WAS 5.007729542255402 min*****************************\n",
      "\n",
      "**********************ROUND 148 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.03305710479617119\n",
      "\n",
      "episode 2, policy loss -0.08023425191640854\n",
      "\n",
      "episode 3, policy loss -0.0940089300274849\n",
      "\n",
      "episode 4, policy loss -0.06685635447502136\n",
      "\n",
      "episode 5, policy loss -0.05272011458873749\n",
      "\n",
      "episode 6, policy loss -0.07813768088817596\n",
      "\n",
      "episode 7, policy loss -0.0790790542960167\n",
      "\n",
      "episode 8, policy loss -0.04493724927306175\n",
      "\n",
      "episode 9, policy loss -0.04761621356010437\n",
      "\n",
      "episode 10, policy loss -0.07796208560466766\n",
      "\n",
      "episode 11, policy loss -0.03030647151172161\n",
      "\n",
      "episode 12, policy loss -0.013313887640833855\n",
      "\n",
      "episode 13, policy loss -0.0924084410071373\n",
      "\n",
      "episode 14, policy loss -0.07057730853557587\n",
      "\n",
      "episode 15, policy loss -0.10369054973125458\n",
      "\n",
      "episode 16, policy loss -0.11857962608337402\n",
      "\n",
      "Policy train loss in epoch 0:-0.0677178327459842\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.10494299232959747\n",
      "\n",
      "episode 2, policy loss -0.07818969339132309\n",
      "\n",
      "episode 3, policy loss -0.09575541317462921\n",
      "\n",
      "episode 4, policy loss -0.05797943100333214\n",
      "\n",
      "episode 5, policy loss -0.09704819321632385\n",
      "\n",
      "episode 6, policy loss -0.042848262935876846\n",
      "\n",
      "episode 7, policy loss -0.10404560714960098\n",
      "\n",
      "episode 8, policy loss -0.04487426206469536\n",
      "\n",
      "episode 9, policy loss -0.07348378747701645\n",
      "\n",
      "episode 10, policy loss -0.11977164447307587\n",
      "\n",
      "episode 11, policy loss -0.05053062364459038\n",
      "\n",
      "episode 12, policy loss -0.016077455133199692\n",
      "\n",
      "episode 13, policy loss -0.07970884442329407\n",
      "\n",
      "episode 14, policy loss -0.07978193461894989\n",
      "\n",
      "episode 15, policy loss -0.07337253540754318\n",
      "\n",
      "episode 16, policy loss -0.03264324367046356\n",
      "\n",
      "Policy train loss in epoch 1:-0.0719408702570945\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.043182969093322754\n",
      "\n",
      "episode 2, policy loss -0.050303179770708084\n",
      "\n",
      "episode 3, policy loss -0.09632784873247147\n",
      "\n",
      "episode 4, policy loss -0.09775468707084656\n",
      "\n",
      "episode 5, policy loss -0.07978027313947678\n",
      "\n",
      "episode 6, policy loss -0.07482584565877914\n",
      "\n",
      "episode 7, policy loss -0.058650728315114975\n",
      "\n",
      "episode 8, policy loss -0.0747523084282875\n",
      "\n",
      "episode 9, policy loss -0.08007156848907471\n",
      "\n",
      "episode 10, policy loss -0.08027059584856033\n",
      "\n",
      "episode 11, policy loss -0.015925874933600426\n",
      "\n",
      "episode 12, policy loss -0.03250591829419136\n",
      "\n",
      "episode 13, policy loss -0.10650622099637985\n",
      "\n",
      "episode 14, policy loss -0.046315066516399384\n",
      "\n",
      "episode 15, policy loss -0.12117085605859756\n",
      "\n",
      "episode 16, policy loss -0.1072271466255188\n",
      "\n",
      "Policy train loss in epoch 2:-0.0728481929982081\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.03415393829345703\n",
      "\n",
      "episode 2, policy loss -0.07511407136917114\n",
      "\n",
      "episode 3, policy loss -0.09629683941602707\n",
      "\n",
      "episode 4, policy loss -0.05907068029046059\n",
      "\n",
      "episode 5, policy loss -0.12119437009096146\n",
      "\n",
      "episode 6, policy loss -0.050059739500284195\n",
      "\n",
      "episode 7, policy loss -0.08114518970251083\n",
      "\n",
      "episode 8, policy loss -0.04420150816440582\n",
      "\n",
      "episode 9, policy loss -0.07990234345197678\n",
      "\n",
      "episode 10, policy loss -0.10728943347930908\n",
      "\n",
      "episode 11, policy loss -0.1070014014840126\n",
      "\n",
      "episode 12, policy loss -0.04609205201268196\n",
      "\n",
      "episode 13, policy loss -0.016905980184674263\n",
      "\n",
      "episode 14, policy loss -0.0977024957537651\n",
      "\n",
      "episode 15, policy loss -0.07532672584056854\n",
      "\n",
      "episode 16, policy loss -0.08053791522979736\n",
      "\n",
      "Policy train loss in epoch 3:-0.07324966776650399\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.2023654282093048\n",
      "\n",
      "episode 2, val func loss 0.2086830586194992\n",
      "\n",
      "episode 3, val func loss 0.21979303658008575\n",
      "\n",
      "episode 4, val func loss 0.21514266729354858\n",
      "\n",
      "episode 5, val func loss 0.17432798445224762\n",
      "\n",
      "episode 6, val func loss 0.20019203424453735\n",
      "\n",
      "episode 7, val func loss 0.20251145958900452\n",
      "\n",
      "episode 8, val func loss 0.1875656545162201\n",
      "\n",
      "episode 9, val func loss 0.2113030105829239\n",
      "\n",
      "episode 10, val func loss 0.15330606698989868\n",
      "\n",
      "episode 11, val func loss 0.20391514897346497\n",
      "\n",
      "episode 12, val func loss 0.18402479588985443\n",
      "\n",
      "episode 13, val func loss 0.19857071340084076\n",
      "\n",
      "episode 14, val func loss 0.21787874400615692\n",
      "\n",
      "episode 15, val func loss 0.19641052186489105\n",
      "\n",
      "episode 16, val func loss 0.20144934952259064\n",
      "\n",
      "Val func train loss in epoch 0:0.19858997967094183\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.18497565388679504\n",
      "\n",
      "episode 2, val func loss 0.20039446651935577\n",
      "\n",
      "episode 3, val func loss 0.1940094530582428\n",
      "\n",
      "episode 4, val func loss 0.20939280092716217\n",
      "\n",
      "episode 5, val func loss 0.20420141518115997\n",
      "\n",
      "episode 6, val func loss 0.20445095002651215\n",
      "\n",
      "episode 7, val func loss 0.19775733351707458\n",
      "\n",
      "episode 8, val func loss 0.20098567008972168\n",
      "\n",
      "episode 9, val func loss 0.17188315093517303\n",
      "\n",
      "episode 10, val func loss 0.22207413613796234\n",
      "\n",
      "episode 11, val func loss 0.15154984593391418\n",
      "\n",
      "episode 12, val func loss 0.21358802914619446\n",
      "\n",
      "episode 13, val func loss 0.18390671908855438\n",
      "\n",
      "episode 14, val func loss 0.20371611416339874\n",
      "\n",
      "episode 15, val func loss 0.20048069953918457\n",
      "\n",
      "episode 16, val func loss 0.21478094160556793\n",
      "\n",
      "Val func train loss in epoch 1:0.19738421123474836\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.18733003735542297\n",
      "\n",
      "episode 2, val func loss 0.20023703575134277\n",
      "\n",
      "episode 3, val func loss 0.21170884370803833\n",
      "\n",
      "episode 4, val func loss 0.19386586546897888\n",
      "\n",
      "episode 5, val func loss 0.196253702044487\n",
      "\n",
      "episode 6, val func loss 0.2008265256881714\n",
      "\n",
      "episode 7, val func loss 0.18468353152275085\n",
      "\n",
      "episode 8, val func loss 0.20321232080459595\n",
      "\n",
      "episode 9, val func loss 0.20085328817367554\n",
      "\n",
      "episode 10, val func loss 0.17230358719825745\n",
      "\n",
      "episode 11, val func loss 0.19836308062076569\n",
      "\n",
      "episode 12, val func loss 0.2113635241985321\n",
      "\n",
      "episode 13, val func loss 0.20723210275173187\n",
      "\n",
      "episode 14, val func loss 0.21639743447303772\n",
      "\n",
      "episode 15, val func loss 0.1573251187801361\n",
      "\n",
      "episode 16, val func loss 0.21426984667778015\n",
      "\n",
      "Val func train loss in epoch 2:0.19726411532610655\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20129351317882538\n",
      "\n",
      "episode 2, val func loss 0.20216017961502075\n",
      "\n",
      "episode 3, val func loss 0.21595825254917145\n",
      "\n",
      "episode 4, val func loss 0.20470325648784637\n",
      "\n",
      "episode 5, val func loss 0.212135449051857\n",
      "\n",
      "episode 6, val func loss 0.19922907650470734\n",
      "\n",
      "episode 7, val func loss 0.1977657526731491\n",
      "\n",
      "episode 8, val func loss 0.15103751420974731\n",
      "\n",
      "episode 9, val func loss 0.18537890911102295\n",
      "\n",
      "episode 10, val func loss 0.17469319701194763\n",
      "\n",
      "episode 11, val func loss 0.2155979871749878\n",
      "\n",
      "episode 12, val func loss 0.20314553380012512\n",
      "\n",
      "episode 13, val func loss 0.20355363190174103\n",
      "\n",
      "episode 14, val func loss 0.2115561068058014\n",
      "\n",
      "episode 15, val func loss 0.19485779106616974\n",
      "\n",
      "episode 16, val func loss 0.182930126786232\n",
      "\n",
      "Val func train loss in epoch 3:0.19724976737052202\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.20067885518074036\n",
      "\n",
      "episode 2, val func loss 0.18456760048866272\n",
      "\n",
      "episode 3, val func loss 0.1748417317867279\n",
      "\n",
      "episode 4, val func loss 0.20347018539905548\n",
      "\n",
      "episode 5, val func loss 0.1519959717988968\n",
      "\n",
      "episode 6, val func loss 0.20256954431533813\n",
      "\n",
      "episode 7, val func loss 0.18407046794891357\n",
      "\n",
      "episode 8, val func loss 0.19603030383586884\n",
      "\n",
      "episode 9, val func loss 0.19678258895874023\n",
      "\n",
      "episode 10, val func loss 0.20130296051502228\n",
      "\n",
      "episode 11, val func loss 0.22113776206970215\n",
      "\n",
      "episode 12, val func loss 0.21542420983314514\n",
      "\n",
      "episode 13, val func loss 0.21555285155773163\n",
      "\n",
      "episode 14, val func loss 0.2014445662498474\n",
      "\n",
      "episode 15, val func loss 0.21079979836940765\n",
      "\n",
      "episode 16, val func loss 0.2052876055240631\n",
      "\n",
      "Val func train loss in epoch 4:0.19787231273949146\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.20022645592689514\n",
      "\n",
      "episode 2, val func loss 0.1958245187997818\n",
      "\n",
      "episode 3, val func loss 0.18718044459819794\n",
      "\n",
      "episode 4, val func loss 0.20117764174938202\n",
      "\n",
      "episode 5, val func loss 0.18767771124839783\n",
      "\n",
      "episode 6, val func loss 0.20483098924160004\n",
      "\n",
      "episode 7, val func loss 0.15225651860237122\n",
      "\n",
      "episode 8, val func loss 0.2107119858264923\n",
      "\n",
      "episode 9, val func loss 0.19712139666080475\n",
      "\n",
      "episode 10, val func loss 0.17248964309692383\n",
      "\n",
      "episode 11, val func loss 0.203021839261055\n",
      "\n",
      "episode 12, val func loss 0.2178184688091278\n",
      "\n",
      "episode 13, val func loss 0.21763557195663452\n",
      "\n",
      "episode 14, val func loss 0.202749565243721\n",
      "\n",
      "episode 15, val func loss 0.21781791746616364\n",
      "\n",
      "episode 16, val func loss 0.20404227077960968\n",
      "\n",
      "Val func train loss in epoch 5:0.1982864337041974\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.17537179589271545\n",
      "\n",
      "episode 2, val func loss 0.20439913868904114\n",
      "\n",
      "episode 3, val func loss 0.19834984838962555\n",
      "\n",
      "episode 4, val func loss 0.20402945578098297\n",
      "\n",
      "episode 5, val func loss 0.21043790876865387\n",
      "\n",
      "episode 6, val func loss 0.20167666673660278\n",
      "\n",
      "episode 7, val func loss 0.20054519176483154\n",
      "\n",
      "episode 8, val func loss 0.19570131599903107\n",
      "\n",
      "episode 9, val func loss 0.2014559954404831\n",
      "\n",
      "episode 10, val func loss 0.18432685732841492\n",
      "\n",
      "episode 11, val func loss 0.21587473154067993\n",
      "\n",
      "episode 12, val func loss 0.21379347145557404\n",
      "\n",
      "episode 13, val func loss 0.1509881615638733\n",
      "\n",
      "episode 14, val func loss 0.1844032108783722\n",
      "\n",
      "episode 15, val func loss 0.20389984548091888\n",
      "\n",
      "episode 16, val func loss 0.2183174043893814\n",
      "\n",
      "Val func train loss in epoch 6:0.19772318750619888\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.21557007730007172\n",
      "\n",
      "episode 2, val func loss 0.20185354351997375\n",
      "\n",
      "episode 3, val func loss 0.19827938079833984\n",
      "\n",
      "episode 4, val func loss 0.20518286526203156\n",
      "\n",
      "episode 5, val func loss 0.18554480373859406\n",
      "\n",
      "episode 6, val func loss 0.15166465938091278\n",
      "\n",
      "episode 7, val func loss 0.21835468709468842\n",
      "\n",
      "episode 8, val func loss 0.21296414732933044\n",
      "\n",
      "episode 9, val func loss 0.1740703135728836\n",
      "\n",
      "episode 10, val func loss 0.2015373855829239\n",
      "\n",
      "episode 11, val func loss 0.1852492243051529\n",
      "\n",
      "episode 12, val func loss 0.2094699591398239\n",
      "\n",
      "episode 13, val func loss 0.2001124918460846\n",
      "\n",
      "episode 14, val func loss 0.19413889944553375\n",
      "\n",
      "episode 15, val func loss 0.20327062904834747\n",
      "\n",
      "episode 16, val func loss 0.20180420577526093\n",
      "\n",
      "Val func train loss in epoch 7:0.1974417045712471\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.19990521669387817\n",
      "\n",
      "episode 2, val func loss 0.2130439579486847\n",
      "\n",
      "episode 3, val func loss 0.19742046296596527\n",
      "\n",
      "episode 4, val func loss 0.20294587314128876\n",
      "\n",
      "episode 5, val func loss 0.20252490043640137\n",
      "\n",
      "episode 6, val func loss 0.21810345351696014\n",
      "\n",
      "episode 7, val func loss 0.20570676028728485\n",
      "\n",
      "episode 8, val func loss 0.20071148872375488\n",
      "\n",
      "episode 9, val func loss 0.15361467003822327\n",
      "\n",
      "episode 10, val func loss 0.2079618275165558\n",
      "\n",
      "episode 11, val func loss 0.17392310500144958\n",
      "\n",
      "episode 12, val func loss 0.19302630424499512\n",
      "\n",
      "episode 13, val func loss 0.2005995512008667\n",
      "\n",
      "episode 14, val func loss 0.18565061688423157\n",
      "\n",
      "episode 15, val func loss 0.21444112062454224\n",
      "\n",
      "episode 16, val func loss 0.1844709813594818\n",
      "\n",
      "Val func train loss in epoch 8:0.19712814316153526\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.20073004066944122\n",
      "\n",
      "episode 2, val func loss 0.19448977708816528\n",
      "\n",
      "episode 3, val func loss 0.2043810337781906\n",
      "\n",
      "episode 4, val func loss 0.2112634927034378\n",
      "\n",
      "episode 5, val func loss 0.20603390038013458\n",
      "\n",
      "episode 6, val func loss 0.20298324525356293\n",
      "\n",
      "episode 7, val func loss 0.18759997189044952\n",
      "\n",
      "episode 8, val func loss 0.20127180218696594\n",
      "\n",
      "episode 9, val func loss 0.21785666048526764\n",
      "\n",
      "episode 10, val func loss 0.18464446067810059\n",
      "\n",
      "episode 11, val func loss 0.15023204684257507\n",
      "\n",
      "episode 12, val func loss 0.19760148227214813\n",
      "\n",
      "episode 13, val func loss 0.17379698157310486\n",
      "\n",
      "episode 14, val func loss 0.20219780504703522\n",
      "\n",
      "episode 15, val func loss 0.21869628131389618\n",
      "\n",
      "episode 16, val func loss 0.2103876918554306\n",
      "\n",
      "Val func train loss in epoch 9:0.19776041712611914\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.21686525642871857\n",
      "\n",
      "episode 2, val func loss 0.20443511009216309\n",
      "\n",
      "episode 3, val func loss 0.21705259382724762\n",
      "\n",
      "episode 4, val func loss 0.20127837359905243\n",
      "\n",
      "episode 5, val func loss 0.20264461636543274\n",
      "\n",
      "episode 6, val func loss 0.212473064661026\n",
      "\n",
      "episode 7, val func loss 0.1564764827489853\n",
      "\n",
      "episode 8, val func loss 0.21075129508972168\n",
      "\n",
      "episode 9, val func loss 0.20280000567436218\n",
      "\n",
      "episode 10, val func loss 0.18516317009925842\n",
      "\n",
      "episode 11, val func loss 0.19665922224521637\n",
      "\n",
      "episode 12, val func loss 0.18531343340873718\n",
      "\n",
      "episode 13, val func loss 0.17237699031829834\n",
      "\n",
      "episode 14, val func loss 0.20194792747497559\n",
      "\n",
      "episode 15, val func loss 0.20375853776931763\n",
      "\n",
      "episode 16, val func loss 0.2022445946931839\n",
      "\n",
      "Val func train loss in epoch 10:0.19826504215598106\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.21630777418613434\n",
      "\n",
      "episode 2, val func loss 0.17217226326465607\n",
      "\n",
      "episode 3, val func loss 0.19908325374126434\n",
      "\n",
      "episode 4, val func loss 0.19879987835884094\n",
      "\n",
      "episode 5, val func loss 0.2019004076719284\n",
      "\n",
      "episode 6, val func loss 0.21095915138721466\n",
      "\n",
      "episode 7, val func loss 0.19971543550491333\n",
      "\n",
      "episode 8, val func loss 0.1878613829612732\n",
      "\n",
      "episode 9, val func loss 0.20563159883022308\n",
      "\n",
      "episode 10, val func loss 0.19366273283958435\n",
      "\n",
      "episode 11, val func loss 0.18383899331092834\n",
      "\n",
      "episode 12, val func loss 0.20945537090301514\n",
      "\n",
      "episode 13, val func loss 0.1956726610660553\n",
      "\n",
      "episode 14, val func loss 0.21888385713100433\n",
      "\n",
      "episode 15, val func loss 0.14747656881809235\n",
      "\n",
      "episode 16, val func loss 0.20290854573249817\n",
      "\n",
      "Val func train loss in epoch 11:0.19652061723172665\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19464343786239624\n",
      "\n",
      "episode 2, val func loss 0.19691704213619232\n",
      "\n",
      "episode 3, val func loss 0.21223782002925873\n",
      "\n",
      "episode 4, val func loss 0.19940996170043945\n",
      "\n",
      "episode 5, val func loss 0.18907536566257477\n",
      "\n",
      "episode 6, val func loss 0.20484431087970734\n",
      "\n",
      "episode 7, val func loss 0.2004200518131256\n",
      "\n",
      "episode 8, val func loss 0.2053190916776657\n",
      "\n",
      "episode 9, val func loss 0.15615473687648773\n",
      "\n",
      "episode 10, val func loss 0.21142339706420898\n",
      "\n",
      "episode 11, val func loss 0.20365792512893677\n",
      "\n",
      "episode 12, val func loss 0.1869800090789795\n",
      "\n",
      "episode 13, val func loss 0.21502964198589325\n",
      "\n",
      "episode 14, val func loss 0.17331090569496155\n",
      "\n",
      "episode 15, val func loss 0.19711452722549438\n",
      "\n",
      "episode 16, val func loss 0.2090580016374588\n",
      "\n",
      "Val func train loss in epoch 12:0.19722476415336132\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.1945870965719223\n",
      "\n",
      "episode 2, val func loss 0.21448861062526703\n",
      "\n",
      "episode 3, val func loss 0.21678276360034943\n",
      "\n",
      "episode 4, val func loss 0.20331557095050812\n",
      "\n",
      "episode 5, val func loss 0.1979655623435974\n",
      "\n",
      "episode 6, val func loss 0.2061275839805603\n",
      "\n",
      "episode 7, val func loss 0.1996949315071106\n",
      "\n",
      "episode 8, val func loss 0.19967755675315857\n",
      "\n",
      "episode 9, val func loss 0.18663056194782257\n",
      "\n",
      "episode 10, val func loss 0.1761174499988556\n",
      "\n",
      "episode 11, val func loss 0.2166372835636139\n",
      "\n",
      "episode 12, val func loss 0.20109230279922485\n",
      "\n",
      "episode 13, val func loss 0.1823687106370926\n",
      "\n",
      "episode 14, val func loss 0.20894251763820648\n",
      "\n",
      "episode 15, val func loss 0.21067051589488983\n",
      "\n",
      "episode 16, val func loss 0.1520863175392151\n",
      "\n",
      "Val func train loss in epoch 13:0.19794908352196217\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.21910034120082855\n",
      "\n",
      "episode 2, val func loss 0.18425171077251434\n",
      "\n",
      "episode 3, val func loss 0.19597254693508148\n",
      "\n",
      "episode 4, val func loss 0.1516796499490738\n",
      "\n",
      "episode 5, val func loss 0.19814433157444\n",
      "\n",
      "episode 6, val func loss 0.17330114543437958\n",
      "\n",
      "episode 7, val func loss 0.21489159762859344\n",
      "\n",
      "episode 8, val func loss 0.20139439404010773\n",
      "\n",
      "episode 9, val func loss 0.20994101464748383\n",
      "\n",
      "episode 10, val func loss 0.2013920545578003\n",
      "\n",
      "episode 11, val func loss 0.20490671694278717\n",
      "\n",
      "episode 12, val func loss 0.19682012498378754\n",
      "\n",
      "episode 13, val func loss 0.18437014520168304\n",
      "\n",
      "episode 14, val func loss 0.20174449682235718\n",
      "\n",
      "episode 15, val func loss 0.2119770050048828\n",
      "\n",
      "episode 16, val func loss 0.20483869314193726\n",
      "\n",
      "Val func train loss in epoch 14:0.19717037305235863\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.2087569236755371\n",
      "\n",
      "episode 2, val func loss 0.19957789778709412\n",
      "\n",
      "episode 3, val func loss 0.1977146863937378\n",
      "\n",
      "episode 4, val func loss 0.20025096833705902\n",
      "\n",
      "episode 5, val func loss 0.20417478680610657\n",
      "\n",
      "episode 6, val func loss 0.18671882152557373\n",
      "\n",
      "episode 7, val func loss 0.21216654777526855\n",
      "\n",
      "episode 8, val func loss 0.17415787279605865\n",
      "\n",
      "episode 9, val func loss 0.1833489090204239\n",
      "\n",
      "episode 10, val func loss 0.2042294591665268\n",
      "\n",
      "episode 11, val func loss 0.19406010210514069\n",
      "\n",
      "episode 12, val func loss 0.1535642445087433\n",
      "\n",
      "episode 13, val func loss 0.21676693856716156\n",
      "\n",
      "episode 14, val func loss 0.1985424906015396\n",
      "\n",
      "episode 15, val func loss 0.2006649374961853\n",
      "\n",
      "episode 16, val func loss 0.21619394421577454\n",
      "\n",
      "Val func train loss in epoch 15:0.1969305956736207\n",
      "***********************TIME WAS 5.00597544113795 min*****************************\n",
      "\n",
      "**********************ROUND 149 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.07703781872987747\n",
      "\n",
      "episode 2, policy loss 0.06783514469861984\n",
      "\n",
      "episode 3, policy loss 0.04820384085178375\n",
      "\n",
      "episode 4, policy loss 0.0695769339799881\n",
      "\n",
      "episode 5, policy loss 0.059342771768569946\n",
      "\n",
      "episode 6, policy loss 0.07515662163496017\n",
      "\n",
      "episode 7, policy loss 0.0845700055360794\n",
      "\n",
      "episode 8, policy loss 0.06845560669898987\n",
      "\n",
      "episode 9, policy loss 0.021835600957274437\n",
      "\n",
      "episode 10, policy loss 0.01427697204053402\n",
      "\n",
      "episode 11, policy loss 0.0444369800388813\n",
      "\n",
      "episode 12, policy loss 0.0334918387234211\n",
      "\n",
      "episode 13, policy loss 0.017996976152062416\n",
      "\n",
      "episode 14, policy loss 0.01121958252042532\n",
      "\n",
      "episode 15, policy loss 0.0796060562133789\n",
      "\n",
      "episode 16, policy loss 0.08428455889225006\n",
      "\n",
      "Policy train loss in epoch 0:0.05358295683981851\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.08426055312156677\n",
      "\n",
      "episode 2, policy loss 0.016737135127186775\n",
      "\n",
      "episode 3, policy loss 0.0838668942451477\n",
      "\n",
      "episode 4, policy loss 0.02101324312388897\n",
      "\n",
      "episode 5, policy loss 0.031230244785547256\n",
      "\n",
      "episode 6, policy loss 0.06201941519975662\n",
      "\n",
      "episode 7, policy loss 0.009939529001712799\n",
      "\n",
      "episode 8, policy loss 0.0689672902226448\n",
      "\n",
      "episode 9, policy loss 0.062353912740945816\n",
      "\n",
      "episode 10, policy loss 0.035038530826568604\n",
      "\n",
      "episode 11, policy loss 0.06606467068195343\n",
      "\n",
      "episode 12, policy loss 0.0729934349656105\n",
      "\n",
      "episode 13, policy loss 0.013787131756544113\n",
      "\n",
      "episode 14, policy loss 0.05181724205613136\n",
      "\n",
      "episode 15, policy loss 0.043305933475494385\n",
      "\n",
      "episode 16, policy loss 0.07610715180635452\n",
      "\n",
      "Policy train loss in epoch 1:0.0499688945710659\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.06324195861816406\n",
      "\n",
      "episode 2, policy loss 0.03153110295534134\n",
      "\n",
      "episode 3, policy loss 0.07311717420816422\n",
      "\n",
      "episode 4, policy loss 0.013690873049199581\n",
      "\n",
      "episode 5, policy loss 0.08296402543783188\n",
      "\n",
      "episode 6, policy loss 0.01595969684422016\n",
      "\n",
      "episode 7, policy loss 0.061239246279001236\n",
      "\n",
      "episode 8, policy loss 0.02059250697493553\n",
      "\n",
      "episode 9, policy loss 0.07601488381624222\n",
      "\n",
      "episode 10, policy loss 0.03443571552634239\n",
      "\n",
      "episode 11, policy loss 0.008609669283032417\n",
      "\n",
      "episode 12, policy loss 0.08034246414899826\n",
      "\n",
      "episode 13, policy loss 0.06602133810520172\n",
      "\n",
      "episode 14, policy loss 0.05112601816654205\n",
      "\n",
      "episode 15, policy loss 0.06820390373468399\n",
      "\n",
      "episode 16, policy loss 0.044210899621248245\n",
      "\n",
      "Policy train loss in epoch 2:0.04945634229807183\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.008350756950676441\n",
      "\n",
      "episode 2, policy loss 0.06182795763015747\n",
      "\n",
      "episode 3, policy loss 0.08262459933757782\n",
      "\n",
      "episode 4, policy loss 0.035447992384433746\n",
      "\n",
      "episode 5, policy loss 0.020413750782608986\n",
      "\n",
      "episode 6, policy loss 0.01513055618852377\n",
      "\n",
      "episode 7, policy loss 0.013633997179567814\n",
      "\n",
      "episode 8, policy loss 0.07365050911903381\n",
      "\n",
      "episode 9, policy loss 0.08031965047121048\n",
      "\n",
      "episode 10, policy loss 0.06811114400625229\n",
      "\n",
      "episode 11, policy loss 0.05183599516749382\n",
      "\n",
      "episode 12, policy loss 0.0659601017832756\n",
      "\n",
      "episode 13, policy loss 0.031256262212991714\n",
      "\n",
      "episode 14, policy loss 0.043378427624702454\n",
      "\n",
      "episode 15, policy loss 0.07644525915384293\n",
      "\n",
      "episode 16, policy loss 0.061645202338695526\n",
      "\n",
      "Policy train loss in epoch 3:0.04937701014569029\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.2114088535308838\n",
      "\n",
      "episode 2, val func loss 0.18232440948486328\n",
      "\n",
      "episode 3, val func loss 0.2061913162469864\n",
      "\n",
      "episode 4, val func loss 0.1929229348897934\n",
      "\n",
      "episode 5, val func loss 0.18395598232746124\n",
      "\n",
      "episode 6, val func loss 0.1950429528951645\n",
      "\n",
      "episode 7, val func loss 0.19741784036159515\n",
      "\n",
      "episode 8, val func loss 0.19883309304714203\n",
      "\n",
      "episode 9, val func loss 0.19915178418159485\n",
      "\n",
      "episode 10, val func loss 0.21109850704669952\n",
      "\n",
      "episode 11, val func loss 0.20927657186985016\n",
      "\n",
      "episode 12, val func loss 0.17614206671714783\n",
      "\n",
      "episode 13, val func loss 0.19443188607692719\n",
      "\n",
      "episode 14, val func loss 0.1830795705318451\n",
      "\n",
      "episode 15, val func loss 0.18074239790439606\n",
      "\n",
      "episode 16, val func loss 0.21985994279384613\n",
      "\n",
      "Val func train loss in epoch 0:0.1963675068691373\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1963430494070053\n",
      "\n",
      "episode 2, val func loss 0.2179819792509079\n",
      "\n",
      "episode 3, val func loss 0.20984649658203125\n",
      "\n",
      "episode 4, val func loss 0.18026202917099\n",
      "\n",
      "episode 5, val func loss 0.1960931122303009\n",
      "\n",
      "episode 6, val func loss 0.20772838592529297\n",
      "\n",
      "episode 7, val func loss 0.2062118798494339\n",
      "\n",
      "episode 8, val func loss 0.19574867188930511\n",
      "\n",
      "episode 9, val func loss 0.204886332154274\n",
      "\n",
      "episode 10, val func loss 0.1809198558330536\n",
      "\n",
      "episode 11, val func loss 0.20031142234802246\n",
      "\n",
      "episode 12, val func loss 0.1850368231534958\n",
      "\n",
      "episode 13, val func loss 0.19190701842308044\n",
      "\n",
      "episode 14, val func loss 0.18379564583301544\n",
      "\n",
      "episode 15, val func loss 0.17843113839626312\n",
      "\n",
      "episode 16, val func loss 0.2094409465789795\n",
      "\n",
      "Val func train loss in epoch 1:0.19655904918909073\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.22049541771411896\n",
      "\n",
      "episode 2, val func loss 0.19292280077934265\n",
      "\n",
      "episode 3, val func loss 0.17805692553520203\n",
      "\n",
      "episode 4, val func loss 0.21076524257659912\n",
      "\n",
      "episode 5, val func loss 0.19448396563529968\n",
      "\n",
      "episode 6, val func loss 0.21122543513774872\n",
      "\n",
      "episode 7, val func loss 0.19738613069057465\n",
      "\n",
      "episode 8, val func loss 0.19103945791721344\n",
      "\n",
      "episode 9, val func loss 0.20725806057453156\n",
      "\n",
      "episode 10, val func loss 0.18244346976280212\n",
      "\n",
      "episode 11, val func loss 0.18714050948619843\n",
      "\n",
      "episode 12, val func loss 0.21103692054748535\n",
      "\n",
      "episode 13, val func loss 0.19491781294345856\n",
      "\n",
      "episode 14, val func loss 0.19885320961475372\n",
      "\n",
      "episode 15, val func loss 0.17834028601646423\n",
      "\n",
      "episode 16, val func loss 0.19694137573242188\n",
      "\n",
      "Val func train loss in epoch 2:0.19708168879151344\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.20161676406860352\n",
      "\n",
      "episode 2, val func loss 0.2134866714477539\n",
      "\n",
      "episode 3, val func loss 0.2132253497838974\n",
      "\n",
      "episode 4, val func loss 0.21650351583957672\n",
      "\n",
      "episode 5, val func loss 0.1989879608154297\n",
      "\n",
      "episode 6, val func loss 0.17830152809619904\n",
      "\n",
      "episode 7, val func loss 0.2006911039352417\n",
      "\n",
      "episode 8, val func loss 0.18438592553138733\n",
      "\n",
      "episode 9, val func loss 0.19338056445121765\n",
      "\n",
      "episode 10, val func loss 0.18085923790931702\n",
      "\n",
      "episode 11, val func loss 0.21216981112957\n",
      "\n",
      "episode 12, val func loss 0.19460786879062653\n",
      "\n",
      "episode 13, val func loss 0.2128976583480835\n",
      "\n",
      "episode 14, val func loss 0.19144216179847717\n",
      "\n",
      "episode 15, val func loss 0.18352322280406952\n",
      "\n",
      "episode 16, val func loss 0.18259496986865997\n",
      "\n",
      "Val func train loss in epoch 3:0.19741714466363192\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.21149258315563202\n",
      "\n",
      "episode 2, val func loss 0.21647217869758606\n",
      "\n",
      "episode 3, val func loss 0.21128802001476288\n",
      "\n",
      "episode 4, val func loss 0.1944759041070938\n",
      "\n",
      "episode 5, val func loss 0.20795978605747223\n",
      "\n",
      "episode 6, val func loss 0.18128401041030884\n",
      "\n",
      "episode 7, val func loss 0.18642176687717438\n",
      "\n",
      "episode 8, val func loss 0.20962010324001312\n",
      "\n",
      "episode 9, val func loss 0.19333495199680328\n",
      "\n",
      "episode 10, val func loss 0.18345767259597778\n",
      "\n",
      "episode 11, val func loss 0.1976373940706253\n",
      "\n",
      "episode 12, val func loss 0.19930987060070038\n",
      "\n",
      "episode 13, val func loss 0.18167398869991302\n",
      "\n",
      "episode 14, val func loss 0.19997459650039673\n",
      "\n",
      "episode 15, val func loss 0.17846812307834625\n",
      "\n",
      "episode 16, val func loss 0.1926109343767166\n",
      "\n",
      "Val func train loss in epoch 4:0.19659261777997017\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1810314953327179\n",
      "\n",
      "episode 2, val func loss 0.19885706901550293\n",
      "\n",
      "episode 3, val func loss 0.2106451839208603\n",
      "\n",
      "episode 4, val func loss 0.21595625579357147\n",
      "\n",
      "episode 5, val func loss 0.1909308284521103\n",
      "\n",
      "episode 6, val func loss 0.1787649244070053\n",
      "\n",
      "episode 7, val func loss 0.18169960379600525\n",
      "\n",
      "episode 8, val func loss 0.1857183277606964\n",
      "\n",
      "episode 9, val func loss 0.21031393110752106\n",
      "\n",
      "episode 10, val func loss 0.1983576864004135\n",
      "\n",
      "episode 11, val func loss 0.19948989152908325\n",
      "\n",
      "episode 12, val func loss 0.20868505537509918\n",
      "\n",
      "episode 13, val func loss 0.2107708603143692\n",
      "\n",
      "episode 14, val func loss 0.19493426382541656\n",
      "\n",
      "episode 15, val func loss 0.1942356377840042\n",
      "\n",
      "episode 16, val func loss 0.18455424904823303\n",
      "\n",
      "Val func train loss in epoch 5:0.19655907899141312\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.19395515322685242\n",
      "\n",
      "episode 2, val func loss 0.2110682874917984\n",
      "\n",
      "episode 3, val func loss 0.19917160272598267\n",
      "\n",
      "episode 4, val func loss 0.1947854608297348\n",
      "\n",
      "episode 5, val func loss 0.18118534982204437\n",
      "\n",
      "episode 6, val func loss 0.21198363602161407\n",
      "\n",
      "episode 7, val func loss 0.1912386417388916\n",
      "\n",
      "episode 8, val func loss 0.18415667116641998\n",
      "\n",
      "episode 9, val func loss 0.17994068562984467\n",
      "\n",
      "episode 10, val func loss 0.20920291543006897\n",
      "\n",
      "episode 11, val func loss 0.20771799981594086\n",
      "\n",
      "episode 12, val func loss 0.19620472192764282\n",
      "\n",
      "episode 13, val func loss 0.20140258967876434\n",
      "\n",
      "episode 14, val func loss 0.21630382537841797\n",
      "\n",
      "episode 15, val func loss 0.1792372465133667\n",
      "\n",
      "episode 16, val func loss 0.18495316803455353\n",
      "\n",
      "Val func train loss in epoch 6:0.19640674721449614\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.21106038987636566\n",
      "\n",
      "episode 2, val func loss 0.1990794688463211\n",
      "\n",
      "episode 3, val func loss 0.18072062730789185\n",
      "\n",
      "episode 4, val func loss 0.2117311656475067\n",
      "\n",
      "episode 5, val func loss 0.199551060795784\n",
      "\n",
      "episode 6, val func loss 0.2180718183517456\n",
      "\n",
      "episode 7, val func loss 0.21207331120967865\n",
      "\n",
      "episode 8, val func loss 0.19349244236946106\n",
      "\n",
      "episode 9, val func loss 0.1909637749195099\n",
      "\n",
      "episode 10, val func loss 0.179025799036026\n",
      "\n",
      "episode 11, val func loss 0.18074703216552734\n",
      "\n",
      "episode 12, val func loss 0.19688928127288818\n",
      "\n",
      "episode 13, val func loss 0.1858183890581131\n",
      "\n",
      "episode 14, val func loss 0.1841934472322464\n",
      "\n",
      "episode 15, val func loss 0.20974072813987732\n",
      "\n",
      "episode 16, val func loss 0.19505314528942108\n",
      "\n",
      "Val func train loss in epoch 7:0.19676324259489775\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.2113078385591507\n",
      "\n",
      "episode 2, val func loss 0.19492116570472717\n",
      "\n",
      "episode 3, val func loss 0.21627500653266907\n",
      "\n",
      "episode 4, val func loss 0.21169428527355194\n",
      "\n",
      "episode 5, val func loss 0.19095362722873688\n",
      "\n",
      "episode 6, val func loss 0.18586154282093048\n",
      "\n",
      "episode 7, val func loss 0.19690698385238647\n",
      "\n",
      "episode 8, val func loss 0.19516265392303467\n",
      "\n",
      "episode 9, val func loss 0.18198499083518982\n",
      "\n",
      "episode 10, val func loss 0.18511760234832764\n",
      "\n",
      "episode 11, val func loss 0.19938646256923676\n",
      "\n",
      "episode 12, val func loss 0.19716563820838928\n",
      "\n",
      "episode 13, val func loss 0.2126336395740509\n",
      "\n",
      "episode 14, val func loss 0.17948082089424133\n",
      "\n",
      "episode 15, val func loss 0.21176500618457794\n",
      "\n",
      "episode 16, val func loss 0.17997995018959045\n",
      "\n",
      "Val func train loss in epoch 8:0.19691232591867447\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.18356402218341827\n",
      "\n",
      "episode 2, val func loss 0.19966326653957367\n",
      "\n",
      "episode 3, val func loss 0.18107621371746063\n",
      "\n",
      "episode 4, val func loss 0.19397777318954468\n",
      "\n",
      "episode 5, val func loss 0.1948966234922409\n",
      "\n",
      "episode 6, val func loss 0.21734805405139923\n",
      "\n",
      "episode 7, val func loss 0.21069100499153137\n",
      "\n",
      "episode 8, val func loss 0.18061625957489014\n",
      "\n",
      "episode 9, val func loss 0.196915403008461\n",
      "\n",
      "episode 10, val func loss 0.20770077407360077\n",
      "\n",
      "episode 11, val func loss 0.17958596348762512\n",
      "\n",
      "episode 12, val func loss 0.18599048256874084\n",
      "\n",
      "episode 13, val func loss 0.19966332614421844\n",
      "\n",
      "episode 14, val func loss 0.19059380888938904\n",
      "\n",
      "episode 15, val func loss 0.20924155414104462\n",
      "\n",
      "episode 16, val func loss 0.2108502984046936\n",
      "\n",
      "Val func train loss in epoch 9:0.19639842677861452\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.19156156480312347\n",
      "\n",
      "episode 2, val func loss 0.18285904824733734\n",
      "\n",
      "episode 3, val func loss 0.17974217236042023\n",
      "\n",
      "episode 4, val func loss 0.21272683143615723\n",
      "\n",
      "episode 5, val func loss 0.21705932915210724\n",
      "\n",
      "episode 6, val func loss 0.18383453786373138\n",
      "\n",
      "episode 7, val func loss 0.2107255458831787\n",
      "\n",
      "episode 8, val func loss 0.199026420712471\n",
      "\n",
      "episode 9, val func loss 0.19302916526794434\n",
      "\n",
      "episode 10, val func loss 0.1803882122039795\n",
      "\n",
      "episode 11, val func loss 0.17875194549560547\n",
      "\n",
      "episode 12, val func loss 0.1999422013759613\n",
      "\n",
      "episode 13, val func loss 0.19492939114570618\n",
      "\n",
      "episode 14, val func loss 0.1976357102394104\n",
      "\n",
      "episode 15, val func loss 0.21148209273815155\n",
      "\n",
      "episode 16, val func loss 0.21026089787483215\n",
      "\n",
      "Val func train loss in epoch 10:0.19649719167500734\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1913447231054306\n",
      "\n",
      "episode 2, val func loss 0.21001215279102325\n",
      "\n",
      "episode 3, val func loss 0.18351559340953827\n",
      "\n",
      "episode 4, val func loss 0.21280577778816223\n",
      "\n",
      "episode 5, val func loss 0.18016253411769867\n",
      "\n",
      "episode 6, val func loss 0.19442027807235718\n",
      "\n",
      "episode 7, val func loss 0.1815682351589203\n",
      "\n",
      "episode 8, val func loss 0.21100227534770966\n",
      "\n",
      "episode 9, val func loss 0.19500327110290527\n",
      "\n",
      "episode 10, val func loss 0.19766119122505188\n",
      "\n",
      "episode 11, val func loss 0.18389034271240234\n",
      "\n",
      "episode 12, val func loss 0.1979416012763977\n",
      "\n",
      "episode 13, val func loss 0.21619506180286407\n",
      "\n",
      "episode 14, val func loss 0.17823576927185059\n",
      "\n",
      "episode 15, val func loss 0.1993490308523178\n",
      "\n",
      "episode 16, val func loss 0.20872336626052856\n",
      "\n",
      "Val func train loss in epoch 11:0.1963644502684474\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.19713209569454193\n",
      "\n",
      "episode 2, val func loss 0.19852174818515778\n",
      "\n",
      "episode 3, val func loss 0.18262264132499695\n",
      "\n",
      "episode 4, val func loss 0.19151639938354492\n",
      "\n",
      "episode 5, val func loss 0.18374282121658325\n",
      "\n",
      "episode 6, val func loss 0.18293289840221405\n",
      "\n",
      "episode 7, val func loss 0.1959841549396515\n",
      "\n",
      "episode 8, val func loss 0.18147006630897522\n",
      "\n",
      "episode 9, val func loss 0.2108139842748642\n",
      "\n",
      "episode 10, val func loss 0.21295857429504395\n",
      "\n",
      "episode 11, val func loss 0.19275806844234467\n",
      "\n",
      "episode 12, val func loss 0.21806414425373077\n",
      "\n",
      "episode 13, val func loss 0.1784278303384781\n",
      "\n",
      "episode 14, val func loss 0.20949223637580872\n",
      "\n",
      "episode 15, val func loss 0.2067447155714035\n",
      "\n",
      "episode 16, val func loss 0.2002830058336258\n",
      "\n",
      "Val func train loss in epoch 12:0.19646658655256033\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.19460242986679077\n",
      "\n",
      "episode 2, val func loss 0.21673128008842468\n",
      "\n",
      "episode 3, val func loss 0.20190848410129547\n",
      "\n",
      "episode 4, val func loss 0.21053768694400787\n",
      "\n",
      "episode 5, val func loss 0.20901285111904144\n",
      "\n",
      "episode 6, val func loss 0.18278074264526367\n",
      "\n",
      "episode 7, val func loss 0.19267527759075165\n",
      "\n",
      "episode 8, val func loss 0.19290728867053986\n",
      "\n",
      "episode 9, val func loss 0.21293586492538452\n",
      "\n",
      "episode 10, val func loss 0.20035569369792938\n",
      "\n",
      "episode 11, val func loss 0.17833088338375092\n",
      "\n",
      "episode 12, val func loss 0.1985781341791153\n",
      "\n",
      "episode 13, val func loss 0.18315382301807404\n",
      "\n",
      "episode 14, val func loss 0.20788495242595673\n",
      "\n",
      "episode 15, val func loss 0.1819322109222412\n",
      "\n",
      "episode 16, val func loss 0.18134932219982147\n",
      "\n",
      "Val func train loss in epoch 13:0.1966048078611493\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.18577422201633453\n",
      "\n",
      "episode 2, val func loss 0.2090173214673996\n",
      "\n",
      "episode 3, val func loss 0.19432242214679718\n",
      "\n",
      "episode 4, val func loss 0.19826728105545044\n",
      "\n",
      "episode 5, val func loss 0.19772712886333466\n",
      "\n",
      "episode 6, val func loss 0.19852998852729797\n",
      "\n",
      "episode 7, val func loss 0.21102146804332733\n",
      "\n",
      "episode 8, val func loss 0.18022917211055756\n",
      "\n",
      "episode 9, val func loss 0.18306955695152283\n",
      "\n",
      "episode 10, val func loss 0.1795719563961029\n",
      "\n",
      "episode 11, val func loss 0.21639451384544373\n",
      "\n",
      "episode 12, val func loss 0.19075846672058105\n",
      "\n",
      "episode 13, val func loss 0.19399908185005188\n",
      "\n",
      "episode 14, val func loss 0.2096787393093109\n",
      "\n",
      "episode 15, val func loss 0.17842969298362732\n",
      "\n",
      "episode 16, val func loss 0.21185937523841858\n",
      "\n",
      "Val func train loss in epoch 14:0.1961656492203474\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.18109425902366638\n",
      "\n",
      "episode 2, val func loss 0.20083682239055634\n",
      "\n",
      "episode 3, val func loss 0.2100149691104889\n",
      "\n",
      "episode 4, val func loss 0.19525200128555298\n",
      "\n",
      "episode 5, val func loss 0.18372170627117157\n",
      "\n",
      "episode 6, val func loss 0.21088990569114685\n",
      "\n",
      "episode 7, val func loss 0.18009984493255615\n",
      "\n",
      "episode 8, val func loss 0.21008655428886414\n",
      "\n",
      "episode 9, val func loss 0.19392554461956024\n",
      "\n",
      "episode 10, val func loss 0.18304531276226044\n",
      "\n",
      "episode 11, val func loss 0.21069444715976715\n",
      "\n",
      "episode 12, val func loss 0.197567880153656\n",
      "\n",
      "episode 13, val func loss 0.17907604575157166\n",
      "\n",
      "episode 14, val func loss 0.21581679582595825\n",
      "\n",
      "episode 15, val func loss 0.18900816142559052\n",
      "\n",
      "episode 16, val func loss 0.1985369771718979\n",
      "\n",
      "Val func train loss in epoch 15:0.1962292017415166\n",
      "***********************TIME WAS 5.00227541923523 min*****************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_buffers=16 # keep it simpler\n",
    "num_rounds = 150 # give it more of a chance to learn policy, which can only change a little over each round.\n",
    "for i in range(num_rounds):\n",
    "    start = time.time()\n",
    "    print(f\"**********************ROUND {i} ***************************\\n\")\n",
    "    run_round(i, policy_optimizer, val_optimizer, num_buffers, policy_epochs, val_epochs, policy_clip_range, entropy_loss_weight)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"***********************TIME WAS {elapsed / 60} min*****************************\\n\")\n",
    "    # I think the entropy was too low last time, let's see if this fixes the issue.\n",
    "    if i > 40:\n",
    "        entropy_loss_weight = max(entropy_loss_weight / 2, 1e-4)#1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d3d395a-839a-45f7-8f79-cfbfa0e90751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "bb = get_bb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96ce72c0-29f1-48dd-bd1a-18cdca882626",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = bb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71843156-cf00-48a4-b862-03ec2e501a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ppo_helper.SentenceOutputSingleEpisode at 0x7f6cce2cd700>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a388eee-55cb-4e0e-9068-35a92241ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "055b7571-6ce4-4df1-ba5b-157892cbdfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 3, 4, 6, 3, 5, 6, 6, 6, 6],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.traces[0, b.seed_offset - 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a0eb8bf-7528-4f0b-bc92-56cc5d79222f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6, 4, 4, 3, 4, 3, 3, 6, 3], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.traces[0, :b.seed_offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c61e4553-3585-4124-8f6d-be73751f6268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.terminated[0, :b.seed_offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6deb2f4-56f3-4cff-97f2-8c52065b13e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right, this only includes the seed_offset and forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ae178a9-18b3-4c94-96ec-8bd3a94cb181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "         0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "         0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba255e87-4340-4977-a554-242c130580f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "         0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "         0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33253a1b-47c7-4103-9238-5870e4fb0889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1166, 0.1461, 0.1247, 0.1473, 0.1472, 0.1652, 0.2321, 0.1912, 0.1981,\n",
       "         0.2100, 0.2204, 0.2485, 0.2359, 0.3388, 0.2648, 0.3144, 0.3081, 0.3698,\n",
       "         0.3228, 0.3306, 0.3449, 0.3384, 0.3414],\n",
       "        [0.1197, 0.1326, 0.1776, 0.1499, 0.1604, 0.1757, 0.1779, 0.1833, 0.1893,\n",
       "         0.2096, 0.2820, 0.2347, 0.2535, 0.2630, 0.2801, 0.2851, 0.3352, 0.3063,\n",
       "         0.3088, 0.3182, 0.3314, 0.3416, 0.3456],\n",
       "        [0.1032, 0.1243, 0.1381, 0.1525, 0.1863, 0.1898, 0.1822, 0.2010, 0.2081,\n",
       "         0.1930, 0.2515, 0.2528, 0.3011, 0.2594, 0.3402, 0.3120, 0.3003, 0.2870,\n",
       "         0.3072, 0.3094, 0.3220, 0.3697, 0.3497],\n",
       "        [0.1233, 0.1230, 0.1489, 0.1414, 0.1430, 0.1703, 0.1693, 0.2058, 0.2049,\n",
       "         0.2300, 0.2128, 0.2134, 0.2331, 0.2509, 0.2788, 0.2717, 0.2919, 0.2938,\n",
       "         0.3249, 0.3314, 0.3305, 0.3358, 0.3662],\n",
       "        [0.1214, 0.1414, 0.1236, 0.1774, 0.1622, 0.1641, 0.1831, 0.1950, 0.2104,\n",
       "         0.2105, 0.3210, 0.2456, 0.2557, 0.2534, 0.2664, 0.2764, 0.2932, 0.3560,\n",
       "         0.4152, 0.3219, 0.3848, 0.3384, 0.3325],\n",
       "        [0.1060, 0.1212, 0.1332, 0.1593, 0.1495, 0.1559, 0.1850, 0.1864, 0.1962,\n",
       "         0.2388, 0.2147, 0.2418, 0.2479, 0.2597, 0.2546, 0.2933, 0.2880, 0.3031,\n",
       "         0.2963, 0.3134, 0.3235, 0.3213, 0.3536],\n",
       "        [0.1158, 0.1116, 0.1330, 0.1505, 0.1487, 0.1652, 0.2108, 0.2126, 0.2316,\n",
       "         0.2205, 0.2240, 0.2384, 0.2613, 0.2762, 0.2640, 0.2806, 0.2765, 0.3026,\n",
       "         0.3088, 0.3184, 0.3359, 0.3431, 0.3516],\n",
       "        [0.1052, 0.1577, 0.1495, 0.1518, 0.1467, 0.1762, 0.1622, 0.2041, 0.1966,\n",
       "         0.2309, 0.2296, 0.2409, 0.2555, 0.2374, 0.2613, 0.2770, 0.2904, 0.2886,\n",
       "         0.3097, 0.3592, 0.3440, 0.3381, 0.3409]], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2346e9e3-67b0-4680-bee4-209488e7266a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 6, 6, 6, 6, 5, 4, 6, 5, 6, 6, 6, 5, 3, 5, 6, 6, 3, 5, 5, 6, 6, 6],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.traces[1, b.seed_offset - 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bde46aeb-6e91-4f8b-8650-92bb66f07007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 1., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.rewards[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e2b5f67-19fb-4b6b-a953-2456ad47eecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_return(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1322af7-7ff8-41ce-8d76-d1b528e2cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically, close to 5, but a little less because entropy was still a thing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
