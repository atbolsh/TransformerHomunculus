{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc7a75c-b93b-4e05-8262-4ab31ab4bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model import *\n",
    "from agent_internals import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4669c268-33a4-4cce-afa6-a4c6963a51ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppo_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c26e1c5-c3d8-4fb3-9f6e-5a63e30e2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = DefaultAgentBrain(7).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd60716-ccea-459a-a29a-a99c256239c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will write a demo reward func\n",
    "# Reward func has to accept a batch of traces and the seed offset\n",
    "# Reward func must provide 0 for everything after termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ddf90d5-56c7-4559-afea-4d80539386af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def reward_func_full(traces, seed_offset, past_terminated, contexts=None):\n",
    "#    # ignore contexts for now\n",
    "#    with torch.no_grad():\n",
    "#        batches, trace_length = traces.size()\n",
    "#        reward_len = trace_length - seed_offset + 1 # includes reward for initial seed\n",
    "#        rewards = torch.zeros(batches, reward_len, device=traces.device)\n",
    "#        for i in range(reward_len):\n",
    "#            trace_index = i + seed_offset - 1 # includes reward for initial seed\n",
    "#            rewards[:, i] += torch.logical_and(\n",
    "#                             torch.logical_and((traces[:, trace_index] > 2),  \\\n",
    "#                                               (torch.logical_not(past_terminated[:, i]))), \\\n",
    "#                             (((traces[:, trace_index] - traces[:, trace_index-1]) % 4) == 1)) * 1.0\n",
    "#            rewards[:, i] += torch.logical_and((traces[:, trace_index] == 2),  \\\n",
    "#                                              (torch.logical_not(past_terminated[:, i]))) * 5.0 # teach it to finish early\n",
    "#    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8904b6c-4654-4adb-9430-3e257c51d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 4's get rewards; nothing else matters.\n",
    "def reward_func_stupid(traces, seed_offset, past_terminated, contexts=None):\n",
    "    # ignore contexts for now\n",
    "    with torch.no_grad():\n",
    "        batches, trace_length = traces.size()\n",
    "        reward_len = trace_length - seed_offset + 1 # includes reward for initial seed\n",
    "        rewards = torch.zeros(batches, reward_len, device=traces.device)\n",
    "        for i in range(reward_len):\n",
    "            trace_index = i + seed_offset - 1 # includes reward for initial seed\n",
    "            rewards[:, i] += torch.logical_and((traces[:, trace_index] == 4),  \\\n",
    "                                              (torch.logical_not(past_terminated[:, i]))) * 5.0 # teach it to finish early\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b340a538-1e1c-4479-abe7-7a9622c86ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 4's get rewards; nothing else matters.\n",
    "def reward_func_modular(traces, seed_offset, past_terminated, contexts=None):\n",
    "    # ignore contexts for now\n",
    "    with torch.no_grad():\n",
    "        batches, trace_length = traces.size()\n",
    "        reward_len = trace_length - seed_offset + 1 # includes reward for initial seed\n",
    "        rewards = torch.zeros(batches, reward_len, device=traces.device)\n",
    "        for i in range(reward_len):\n",
    "            trace_index = i + seed_offset - 1 # includes reward for initial seed\n",
    "            rewards[:, i] += torch.logical_and(\n",
    "                             torch.logical_and((traces[:, trace_index] > 2),  \\\n",
    "                                               (torch.logical_not(past_terminated[:, i]))), \\\n",
    "                             (((traces[:, trace_index] - traces[:, trace_index-1]) % 4) == 1)) * 1.0\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b7d066-e994-454b-8997-b0d1f62ef2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only a reward at the end\n",
    "def reward_func_final(traces, seed_offset, past_terminated, contexts=None):\n",
    "    # ignore contexts for now\n",
    "    with torch.no_grad():\n",
    "        batches, trace_length = traces.size()\n",
    "        reward_len = trace_length - seed_offset + 1 # includes reward for initial seed\n",
    "        rewards = torch.zeros(batches, reward_len, device=traces.device)\n",
    "        for i in range(reward_len):\n",
    "            trace_index = i + seed_offset - 1 # includes reward for initial seed\n",
    "            rewards[:, i] += torch.logical_and((traces[:, trace_index] == 2),  \\\n",
    "                                              (torch.logical_not(past_terminated[:, i]))) * 5.0 # teach it to finish early\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea0ec61-2a44-4a66-a623-8e38493dca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_func_full(traces, seed_offset, past_terminated, contexts=None):\n",
    "    return reward_func_modular(traces, seed_offset, past_terminated, contexts) + \\\n",
    "           reward_func_final(traces, seed_offset, past_terminated, contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49668e1-2af5-49eb-896c-81d53225df41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd0feb-b740-4ef2-8939-6479d9d0dbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96b3ee36-bbfa-4000-8961-ad9c157b421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_func = reward_func_stupid #reward_func_modular #reward_func_stupid #reward_func_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91cf3f9c-a37d-46aa-bc81-e64e508cedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_value(x):\n",
    "#    with torch.no_grad():\n",
    "#        val = brain.dopamine(brain.text_enc(x))\n",
    "#    return val\n",
    "\n",
    "# First attempt will have full gradient for brain - ruining the val func - and full gradient for val func.\n",
    "# Another attempt will have a smarter gradient for the policy (only the generator, not the encoder)\n",
    "get_value = SolitaryValueFunc(7).cuda()\n",
    "get_value.text_enc = brain.text_enc\n",
    "get_value.dopamine = brain.dopamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "084b864c-ade3-4004-8c8f-5745590aa262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the lunar lander demo code: gamma 0.99, tau 0.97.\n",
    "# Will maybe change later since the env is so different\n",
    "#                                        policy,  value,  gamma, tau, reward_func\n",
    "env_buffer = SentenceOutputSingleEpisode(brain, get_value, 0.99, 0.97, reward_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc2fab2c-2533-4499-abef-c6d486cad531",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = torch.randint(3, 7, (3, 10), device=brain.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa249a68-14ae-463d-9faa-28e767521be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6918],\n",
       "        [-4.1317],\n",
       "        [-3.6766]], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_value(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cf847b7-8bee-4e9e-b3a8-1063c8cabfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_buffer.fill(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6c57425-1e83-4f63-8a80-3cb3c3b9e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, that's tested, now let's test an actual full training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d3dfb2b-1772-4d72-a9d2-fb5850d07a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seeds(minVal=3, maxVal=7, lenSeeds=10, batchSize=16, device='cuda'):\n",
    "    return torch.randint(minVal, maxVal, (batchSize, lenSeeds), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c06daee4-2a09-43e4-947d-83e50026a2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24009999999999995"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87969ccd-dc0c-46ec-97a5-58a9646972be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "def get_bb(num_buffers=64):\n",
    "    buffer_buffer = []\n",
    "    for i in range(num_buffers):\n",
    "        print(i)\n",
    "        # Let's try to make this particular system simpler on the value func, \n",
    "        # make it focus on the here-and-now, more. Old vals: 0.99, 0.97\n",
    "        #                                                      0.7, 0.6\n",
    "        buffer = SentenceOutputSingleEpisode(brain, get_value, 0.0, 0.0, reward_func)\n",
    "        buffer.fill(get_seeds(batchSize=8))\n",
    "        buffer = buffer.to('cpu') # avoid eating VRAM\n",
    "        buffer_buffer.append(buffer)\n",
    "    return buffer_buffer\n",
    "num_buffers=64\n",
    "buffer_buffer = get_bb(num_buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90bc3944-9981-4794-8b4d-33084df0b7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3150b90>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a40bae10>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3ed1be0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f2a8daa6960>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a402de20>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f2a8da7cc20>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a5043fb0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3ea6f60>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f2a8daa55b0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3c33b60>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a304a2d0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3049160>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a304b260>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3153c50>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3153d40>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f2a8daa49e0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a30498e0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a41bc7a0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3152c60>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3150c20>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3153fe0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a31515e0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3048cb0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3153bf0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3153f50>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164200>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a31641d0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a31640e0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164770>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a31645f0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164980>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a419c8c0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164830>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164b90>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3049d60>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3048c80>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a304a2a0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a31643e0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a31644a0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164c80>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164500>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164710>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164d40>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164fe0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a4a44ec0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164860>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a31649e0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164590>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a31650d0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a31642c0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164fb0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a31645c0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164c20>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3165070>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3165160>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a31650a0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3165370>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164260>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a4015580>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164f20>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3165190>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a31655e0>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3164a70>,\n",
       " <ppo_helper.SentenceOutputSingleEpisode at 0x7f29a3165520>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8589a79d-4a54-4bec-8b3f-4f6abdc32a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5f47d90-d5a2-486d-9178-ff2147860e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing it so that only the dopamine portion is affected\n",
    "# not sure if this option makes the most sense *here*, but it makes the most sense in general.\n",
    "# that is, other modes will learn the representation, and the dopamine is only responsible for the evaluation.\n",
    "val_optimizer = optim.Adam(get_value.dopamine.parameters(), lr=0.0005, betas=(0.9, 0.98), eps=1e-9)\n",
    "val_epochs = 16 #16 # old is 80, but that's only sampling a few per turn; we're gonna go through the whole buffer-buffer\n",
    "# 16 was too much, let's go with 2 times through all 64 16-batch sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dec4efba-dc53-471c-a8b6-2002294cea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this training loop is just for 'burning in' to have an initial value func that corresponds to the policy;\n",
    "# the other one (later) will include clamping and is slightly more advanced\n",
    "# this is 8 Gb VRAM, by the way (at batchSize 16). Not *too* surprising, but I will need the bigger system right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bdfd38f-84c5-4784-bc69-b79a5260aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def train_val_func(val_optimizer, epochs, buffer_buffer):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"==========Epoch {epoch}=====================\")\n",
    "        get_value.train()\n",
    "        train_loss = 0\n",
    "        random.shuffle(buffer_buffer)\n",
    "        i = 0\n",
    "        for buffer in buffer_buffer:\n",
    "            i += 1\n",
    "            buffer = buffer.cuda()\n",
    "            val_optimizer.zero_grad()\n",
    "            new_vals = buffer.get_values(evaluation = False) # call value func correctly, with gradients\n",
    "            loss = mse_loss(new_vals, buffer.returns)\n",
    "            loss.backward()\n",
    "            val_optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            print(f\"episode {i}, val func loss {loss.item()}\\n\")\n",
    "            buffer = buffer.cpu()\n",
    "        val_optimizer.zero_grad()\n",
    "        print(f\"Val func train loss in epoch {epoch}:{train_loss / (len(buffer_buffer))}\")\n",
    "#train_val_func(val_optimizer, val_epochs, buffer_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a18ceb68-9b96-4ec3-b534-6b30102dad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's recalculate gaes after burn-in, to get any progress on the policy network at all\n",
    "def restore_coherence(buffer_buffer):\n",
    "    for buffer in buffer_buffer:\n",
    "        buffer=buffer.cuda()\n",
    "        buffer.values = buffer.get_values() # retrained val func\n",
    "        buffer.gaes = buffer.get_gaes()\n",
    "        buffer = buffer.cpu()\n",
    "    return buffer_buffer\n",
    "#buffer_buffer = restore_coherence(buffer_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd128d6d-108d-448f-8dee-fe8eff958162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77447829-a88f-42c7-9627-c85afbc6cdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64219914-608f-4794-b100-46b5ca3f97d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "319d3839-93f9-4777-b0c4-0acf482a6e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_optimizer = optim.Adam(brain.parameters(), lr=0.0003, betas=(0.9, 0.98), eps=1e-9)\n",
    "policy_epochs = 4\n",
    "epochs = policy_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f741a965-8e75-4dfb-a108-6773dfda70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_clip_range = 0.1 #0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08e06795-b9b7-4e60-8d2f-4b658502e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_loss_weight = 5e-2 #0.01 I think this is too high for the policy I'm trying to produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d60ae67-9029-481b-8a34-700d93923497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchsize 8 is the correct path. THis is like 7.5 gigs of VRAM\n",
    "# just barely enough to work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "159d38c7-4d36-4213-a9eb-67684ae1bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_policy(policy_optimizer, epochs, buffer_buffer, policy_clip_range=0.1, entropy_loss_weight=0.01):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"==========Epoch {epoch}=====================\")\n",
    "        brain.train()\n",
    "        train_loss = 0\n",
    "        random.shuffle(buffer_buffer)\n",
    "        i = 0\n",
    "        for buffer in buffer_buffer:\n",
    "            i += 1\n",
    "            buffer = buffer.cuda()\n",
    "            #seeds = buffer.traces[:, :buffer.seed_offset]\n",
    "            policy_optimizer.zero_grad()\n",
    "            # hopefully no torch.no_grad's in that generation func, huh\n",
    "            # NO, this is NOT the correct path. I need logpas that correspond to the traces, no others\n",
    "            # traces, logpas, entropies = brain.generate(seeds)\n",
    "            # THIS is the correct one. Can be accelerated by passing in masks, later.\n",
    "            logpas, entropies = brain.compute_probabilities(buffer.traces, buffer.seed_offset, buffer.contexts)\n",
    "            #print(logpas.size())\n",
    "            #print(buffer.logpas.size())\n",
    "            # Add constraints to kill logpas / entropis in past_terminated? Just to avoid confusion?\n",
    "            ratios = (logpas - buffer.logpas).exp()\n",
    "            pi_obj = buffer.gaes * ratios\n",
    "            pi_obj_clipped = buffer.gaes * ratios.clamp(1.0 - policy_clip_range,\n",
    "                                                       1.0 + policy_clip_range)\n",
    "            policy_loss = -torch.min(pi_obj, pi_obj_clipped).mean()\n",
    "            entropy_loss = -entropies.mean() * entropy_loss_weight\n",
    "            \n",
    "            loss = policy_loss + entropy_loss\n",
    "    \n",
    "            loss.backward()\n",
    "            policy_optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            print(f\"episode {i}, policy loss {loss.item()}\\n\")\n",
    "            buffer = buffer.cpu()\n",
    "        policy_optimizer.zero_grad()\n",
    "        print(f\"Policy train loss in epoch {epoch}:{train_loss / (len(buffer_buffer))}\")\n",
    "#train_policy(policy_optimizer, policy_epochs, buffer_buffer, policy_clip_range, entropy_loss_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f123b67b-f5af-4d31-abe6-5661a4cb35cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find some way of clearing all the nonesense from the VRAM, I don't need the training artefacts to persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cef9e3f5-5c11-4318-9fcb-92f132258674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1dc0ea2-3071-4f74-9686-d57d43f9666d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10008716583251953"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d452b720-00cf-41f4-a9a1-0711a6ff51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_return(bb):\n",
    "    \"\"\"The average return (at the end of the seeds alone) from a buffer-buffer\"\"\"\n",
    "    s = torch.zeros(bb[0].returns[:, 0].size(), device = bb[0].returns[:, 0].device)\n",
    "    for b in bb:\n",
    "        s += bb[0].returns[:, 0]\n",
    "    return torch.sum(s).item()/(len(bb) * bb[0].returns.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5e219e4-0fb3-4cfa-a71e-9d589769a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no policy optimization on first round, only subsequent\n",
    "def run_round(round_num, policy_optimizer, val_optimizer, num_buffers=64, policy_epochs=4, val_epochs=16, policy_clip_range=0.5, entropy_loss_weight=1e-3):\n",
    "    # First, get some samples\n",
    "    brain.eval()\n",
    "    get_value.eval()\n",
    "    buffer_buffer = get_bb(num_buffers) # run the inference side\n",
    "    print(f\"Return before training was {average_return(buffer_buffer)}\")\n",
    "    if round_num > 0:\n",
    "        train_policy(policy_optimizer, policy_epochs, buffer_buffer, policy_clip_range, entropy_loss_weight)\n",
    "    train_val_func(val_optimizer, val_epochs, buffer_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "585410f6-6e85-49e8-8d0d-e4a321b44082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************ROUND 0 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 16.809741973876953\n",
      "\n",
      "episode 2, val func loss 7713.18359375\n",
      "\n",
      "episode 3, val func loss 381.5754089355469\n",
      "\n",
      "episode 4, val func loss 673.3908081054688\n",
      "\n",
      "episode 5, val func loss 98.31396484375\n",
      "\n",
      "episode 6, val func loss 18.95507049560547\n",
      "\n",
      "episode 7, val func loss 50.3583869934082\n",
      "\n",
      "episode 8, val func loss 44.9396858215332\n",
      "\n",
      "episode 9, val func loss 92.9799575805664\n",
      "\n",
      "episode 10, val func loss 4.098732948303223\n",
      "\n",
      "episode 11, val func loss 46.45364761352539\n",
      "\n",
      "episode 12, val func loss 160.7159881591797\n",
      "\n",
      "episode 13, val func loss 47.65835189819336\n",
      "\n",
      "episode 14, val func loss 11.609933853149414\n",
      "\n",
      "episode 15, val func loss 0.7637920379638672\n",
      "\n",
      "episode 16, val func loss 13.92902946472168\n",
      "\n",
      "Val func train loss in epoch 0:585.9835059046745\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 43.05809020996094\n",
      "\n",
      "episode 2, val func loss 12.171830177307129\n",
      "\n",
      "episode 3, val func loss 10.107428550720215\n",
      "\n",
      "episode 4, val func loss 23.752771377563477\n",
      "\n",
      "episode 5, val func loss 1.761008858680725\n",
      "\n",
      "episode 6, val func loss 2.8075857162475586\n",
      "\n",
      "episode 7, val func loss 32.899322509765625\n",
      "\n",
      "episode 8, val func loss 6.222557067871094\n",
      "\n",
      "episode 9, val func loss 12.526322364807129\n",
      "\n",
      "episode 10, val func loss 1.98305344581604\n",
      "\n",
      "episode 11, val func loss 0.5400464534759521\n",
      "\n",
      "episode 12, val func loss 1.1906756162643433\n",
      "\n",
      "episode 13, val func loss 5.393191337585449\n",
      "\n",
      "episode 14, val func loss 4.602790832519531\n",
      "\n",
      "episode 15, val func loss 8.587308883666992\n",
      "\n",
      "episode 16, val func loss 2.8677024841308594\n",
      "\n",
      "Val func train loss in epoch 1:10.654480367898941\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.038956642150879\n",
      "\n",
      "episode 2, val func loss 0.7415115833282471\n",
      "\n",
      "episode 3, val func loss 0.9390087127685547\n",
      "\n",
      "episode 4, val func loss 1.7643914222717285\n",
      "\n",
      "episode 5, val func loss 2.1053357124328613\n",
      "\n",
      "episode 6, val func loss 3.13977313041687\n",
      "\n",
      "episode 7, val func loss 5.423135280609131\n",
      "\n",
      "episode 8, val func loss 6.451920509338379\n",
      "\n",
      "episode 9, val func loss 0.5047812461853027\n",
      "\n",
      "episode 10, val func loss 1.5336695909500122\n",
      "\n",
      "episode 11, val func loss 5.803086757659912\n",
      "\n",
      "episode 12, val func loss 8.871007919311523\n",
      "\n",
      "episode 13, val func loss 1.6911216974258423\n",
      "\n",
      "episode 14, val func loss 1.3982162475585938\n",
      "\n",
      "episode 15, val func loss 0.3728565573692322\n",
      "\n",
      "episode 16, val func loss 1.5444631576538086\n",
      "\n",
      "Val func train loss in epoch 2:2.70770226046443\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.3428270816802979\n",
      "\n",
      "episode 2, val func loss 1.1393343210220337\n",
      "\n",
      "episode 3, val func loss 1.3087161779403687\n",
      "\n",
      "episode 4, val func loss 6.43836784362793\n",
      "\n",
      "episode 5, val func loss 0.48968634009361267\n",
      "\n",
      "episode 6, val func loss 0.837749183177948\n",
      "\n",
      "episode 7, val func loss 2.6155588626861572\n",
      "\n",
      "episode 8, val func loss 2.2104122638702393\n",
      "\n",
      "episode 9, val func loss 4.486786365509033\n",
      "\n",
      "episode 10, val func loss 1.2345174551010132\n",
      "\n",
      "episode 11, val func loss 0.42920982837677\n",
      "\n",
      "episode 12, val func loss 0.9134823679924011\n",
      "\n",
      "episode 13, val func loss 2.0399527549743652\n",
      "\n",
      "episode 14, val func loss 2.8995327949523926\n",
      "\n",
      "episode 15, val func loss 1.1331312656402588\n",
      "\n",
      "episode 16, val func loss 1.07216477394104\n",
      "\n",
      "Val func train loss in epoch 3:1.9119643550366163\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8037057518959045\n",
      "\n",
      "episode 2, val func loss 0.9959031343460083\n",
      "\n",
      "episode 3, val func loss 2.72238826751709\n",
      "\n",
      "episode 4, val func loss 1.0890713930130005\n",
      "\n",
      "episode 5, val func loss 0.6483147740364075\n",
      "\n",
      "episode 6, val func loss 0.23022376000881195\n",
      "\n",
      "episode 7, val func loss 0.5252737402915955\n",
      "\n",
      "episode 8, val func loss 1.787591576576233\n",
      "\n",
      "episode 9, val func loss 1.8866757154464722\n",
      "\n",
      "episode 10, val func loss 0.19173407554626465\n",
      "\n",
      "episode 11, val func loss 1.8720744848251343\n",
      "\n",
      "episode 12, val func loss 1.037473440170288\n",
      "\n",
      "episode 13, val func loss 0.45904654264450073\n",
      "\n",
      "episode 14, val func loss 0.6834760904312134\n",
      "\n",
      "episode 15, val func loss 0.9859330654144287\n",
      "\n",
      "episode 16, val func loss 0.43777939677238464\n",
      "\n",
      "Val func train loss in epoch 4:1.0222915755584836\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.050853967666626\n",
      "\n",
      "episode 2, val func loss 1.3818402290344238\n",
      "\n",
      "episode 3, val func loss 0.5045320987701416\n",
      "\n",
      "episode 4, val func loss 0.5689029097557068\n",
      "\n",
      "episode 5, val func loss 0.7295441031455994\n",
      "\n",
      "episode 6, val func loss 0.3920924663543701\n",
      "\n",
      "episode 7, val func loss 0.6422709822654724\n",
      "\n",
      "episode 8, val func loss 0.8065664768218994\n",
      "\n",
      "episode 9, val func loss 0.7267442941665649\n",
      "\n",
      "episode 10, val func loss 0.17205530405044556\n",
      "\n",
      "episode 11, val func loss 0.7659218907356262\n",
      "\n",
      "episode 12, val func loss 0.5114352107048035\n",
      "\n",
      "episode 13, val func loss 2.3834080696105957\n",
      "\n",
      "episode 14, val func loss 0.7266314029693604\n",
      "\n",
      "episode 15, val func loss 0.49325019121170044\n",
      "\n",
      "episode 16, val func loss 1.049262285232544\n",
      "\n",
      "Val func train loss in epoch 5:0.8065819926559925\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7255025506019592\n",
      "\n",
      "episode 2, val func loss 0.5172737836837769\n",
      "\n",
      "episode 3, val func loss 0.6902157664299011\n",
      "\n",
      "episode 4, val func loss 0.7214982509613037\n",
      "\n",
      "episode 5, val func loss 1.1493456363677979\n",
      "\n",
      "episode 6, val func loss 1.1200859546661377\n",
      "\n",
      "episode 7, val func loss 1.2906774282455444\n",
      "\n",
      "episode 8, val func loss 0.4270239770412445\n",
      "\n",
      "episode 9, val func loss 0.8304315209388733\n",
      "\n",
      "episode 10, val func loss 3.3125126361846924\n",
      "\n",
      "episode 11, val func loss 1.1509875059127808\n",
      "\n",
      "episode 12, val func loss 0.695878267288208\n",
      "\n",
      "episode 13, val func loss 1.2120122909545898\n",
      "\n",
      "episode 14, val func loss 2.1818509101867676\n",
      "\n",
      "episode 15, val func loss 0.7644529938697815\n",
      "\n",
      "episode 16, val func loss 0.6110700368881226\n",
      "\n",
      "Val func train loss in epoch 6:1.0875512193888426\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.0578014850616455\n",
      "\n",
      "episode 2, val func loss 2.0461103916168213\n",
      "\n",
      "episode 3, val func loss 0.8030636310577393\n",
      "\n",
      "episode 4, val func loss 1.062584400177002\n",
      "\n",
      "episode 5, val func loss 0.5601796507835388\n",
      "\n",
      "episode 6, val func loss 5.079461097717285\n",
      "\n",
      "episode 7, val func loss 0.6407387256622314\n",
      "\n",
      "episode 8, val func loss 1.341357946395874\n",
      "\n",
      "episode 9, val func loss 1.0919384956359863\n",
      "\n",
      "episode 10, val func loss 1.883628249168396\n",
      "\n",
      "episode 11, val func loss 0.30946820974349976\n",
      "\n",
      "episode 12, val func loss 0.7054429650306702\n",
      "\n",
      "episode 13, val func loss 1.193476915359497\n",
      "\n",
      "episode 14, val func loss 1.128152847290039\n",
      "\n",
      "episode 15, val func loss 0.5301520228385925\n",
      "\n",
      "episode 16, val func loss 1.0344833135604858\n",
      "\n",
      "Val func train loss in epoch 7:1.2792525216937065\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.898940086364746\n",
      "\n",
      "episode 2, val func loss 0.5122374296188354\n",
      "\n",
      "episode 3, val func loss 0.748241126537323\n",
      "\n",
      "episode 4, val func loss 1.3134621381759644\n",
      "\n",
      "episode 5, val func loss 0.18903794884681702\n",
      "\n",
      "episode 6, val func loss 0.5069029331207275\n",
      "\n",
      "episode 7, val func loss 1.1807746887207031\n",
      "\n",
      "episode 8, val func loss 0.5750910043716431\n",
      "\n",
      "episode 9, val func loss 0.4851935803890228\n",
      "\n",
      "episode 10, val func loss 0.7059075236320496\n",
      "\n",
      "episode 11, val func loss 0.6952596306800842\n",
      "\n",
      "episode 12, val func loss 0.6985628008842468\n",
      "\n",
      "episode 13, val func loss 0.6553727984428406\n",
      "\n",
      "episode 14, val func loss 0.7919631600379944\n",
      "\n",
      "episode 15, val func loss 0.5415273308753967\n",
      "\n",
      "episode 16, val func loss 0.48659202456474304\n",
      "\n",
      "Val func train loss in epoch 8:0.7490666378289461\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.44836166501045227\n",
      "\n",
      "episode 2, val func loss 0.7143217921257019\n",
      "\n",
      "episode 3, val func loss 0.6610985994338989\n",
      "\n",
      "episode 4, val func loss 1.0191502571105957\n",
      "\n",
      "episode 5, val func loss 1.88507080078125\n",
      "\n",
      "episode 6, val func loss 0.5189955830574036\n",
      "\n",
      "episode 7, val func loss 0.6213091015815735\n",
      "\n",
      "episode 8, val func loss 1.3433424234390259\n",
      "\n",
      "episode 9, val func loss 0.417224645614624\n",
      "\n",
      "episode 10, val func loss 0.7338029742240906\n",
      "\n",
      "episode 11, val func loss 0.6973516941070557\n",
      "\n",
      "episode 12, val func loss 0.17192502319812775\n",
      "\n",
      "episode 13, val func loss 0.5444188117980957\n",
      "\n",
      "episode 14, val func loss 0.2591284215450287\n",
      "\n",
      "episode 15, val func loss 0.8236658573150635\n",
      "\n",
      "episode 16, val func loss 0.5827615857124329\n",
      "\n",
      "Val func train loss in epoch 9:0.7151205772534013\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.740071177482605\n",
      "\n",
      "episode 2, val func loss 0.371527761220932\n",
      "\n",
      "episode 3, val func loss 0.4729519784450531\n",
      "\n",
      "episode 4, val func loss 0.4080876111984253\n",
      "\n",
      "episode 5, val func loss 0.1580282747745514\n",
      "\n",
      "episode 6, val func loss 1.0943529605865479\n",
      "\n",
      "episode 7, val func loss 0.753655731678009\n",
      "\n",
      "episode 8, val func loss 1.9769177436828613\n",
      "\n",
      "episode 9, val func loss 0.5781768560409546\n",
      "\n",
      "episode 10, val func loss 0.625295877456665\n",
      "\n",
      "episode 11, val func loss 0.7063900828361511\n",
      "\n",
      "episode 12, val func loss 1.2331196069717407\n",
      "\n",
      "episode 13, val func loss 0.21204791963100433\n",
      "\n",
      "episode 14, val func loss 0.9772069454193115\n",
      "\n",
      "episode 15, val func loss 0.577768862247467\n",
      "\n",
      "episode 16, val func loss 1.1750460863113403\n",
      "\n",
      "Val func train loss in epoch 10:0.7537903422489762\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6162004470825195\n",
      "\n",
      "episode 2, val func loss 0.6758846640586853\n",
      "\n",
      "episode 3, val func loss 0.593273401260376\n",
      "\n",
      "episode 4, val func loss 0.6629704236984253\n",
      "\n",
      "episode 5, val func loss 0.82087242603302\n",
      "\n",
      "episode 6, val func loss 1.1137795448303223\n",
      "\n",
      "episode 7, val func loss 0.49044063687324524\n",
      "\n",
      "episode 8, val func loss 1.5281380414962769\n",
      "\n",
      "episode 9, val func loss 0.5986281633377075\n",
      "\n",
      "episode 10, val func loss 0.37994563579559326\n",
      "\n",
      "episode 11, val func loss 0.8366448879241943\n",
      "\n",
      "episode 12, val func loss 0.7433190941810608\n",
      "\n",
      "episode 13, val func loss 0.15966621041297913\n",
      "\n",
      "episode 14, val func loss 1.665191650390625\n",
      "\n",
      "episode 15, val func loss 0.7661070227622986\n",
      "\n",
      "episode 16, val func loss 2.5406856536865234\n",
      "\n",
      "Val func train loss in epoch 11:0.8869842439889908\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.2098817676305771\n",
      "\n",
      "episode 2, val func loss 0.9449108242988586\n",
      "\n",
      "episode 3, val func loss 1.7060540914535522\n",
      "\n",
      "episode 4, val func loss 0.7727593183517456\n",
      "\n",
      "episode 5, val func loss 3.335547685623169\n",
      "\n",
      "episode 6, val func loss 2.034787893295288\n",
      "\n",
      "episode 7, val func loss 2.7495529651641846\n",
      "\n",
      "episode 8, val func loss 1.3467581272125244\n",
      "\n",
      "episode 9, val func loss 0.5633033514022827\n",
      "\n",
      "episode 10, val func loss 1.7934290170669556\n",
      "\n",
      "episode 11, val func loss 0.18350282311439514\n",
      "\n",
      "episode 12, val func loss 0.9631262421607971\n",
      "\n",
      "episode 13, val func loss 2.897529363632202\n",
      "\n",
      "episode 14, val func loss 0.592821478843689\n",
      "\n",
      "episode 15, val func loss 1.556187391281128\n",
      "\n",
      "episode 16, val func loss 2.9949498176574707\n",
      "\n",
      "Val func train loss in epoch 12:1.5403188848868012\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6154246926307678\n",
      "\n",
      "episode 2, val func loss 1.246888518333435\n",
      "\n",
      "episode 3, val func loss 2.238187313079834\n",
      "\n",
      "episode 4, val func loss 0.8893254399299622\n",
      "\n",
      "episode 5, val func loss 0.6367285251617432\n",
      "\n",
      "episode 6, val func loss 4.506232261657715\n",
      "\n",
      "episode 7, val func loss 1.7602710723876953\n",
      "\n",
      "episode 8, val func loss 1.7725802659988403\n",
      "\n",
      "episode 9, val func loss 5.8694167137146\n",
      "\n",
      "episode 10, val func loss 1.1019117832183838\n",
      "\n",
      "episode 11, val func loss 9.024199485778809\n",
      "\n",
      "episode 12, val func loss 1.1376838684082031\n",
      "\n",
      "episode 13, val func loss 3.522077798843384\n",
      "\n",
      "episode 14, val func loss 5.008651256561279\n",
      "\n",
      "episode 15, val func loss 0.33498361706733704\n",
      "\n",
      "episode 16, val func loss 2.6670494079589844\n",
      "\n",
      "Val func train loss in epoch 13:2.6457257512956858\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.3924949169158936\n",
      "\n",
      "episode 2, val func loss 0.5210078954696655\n",
      "\n",
      "episode 3, val func loss 3.928044319152832\n",
      "\n",
      "episode 4, val func loss 1.2331032752990723\n",
      "\n",
      "episode 5, val func loss 1.3042844533920288\n",
      "\n",
      "episode 6, val func loss 5.101621150970459\n",
      "\n",
      "episode 7, val func loss 0.5551084876060486\n",
      "\n",
      "episode 8, val func loss 2.272778034210205\n",
      "\n",
      "episode 9, val func loss 2.3715665340423584\n",
      "\n",
      "episode 10, val func loss 1.821110486984253\n",
      "\n",
      "episode 11, val func loss 0.943621039390564\n",
      "\n",
      "episode 12, val func loss 1.1718991994857788\n",
      "\n",
      "episode 13, val func loss 4.048739910125732\n",
      "\n",
      "episode 14, val func loss 0.3934131860733032\n",
      "\n",
      "episode 15, val func loss 1.025168776512146\n",
      "\n",
      "episode 16, val func loss 8.826910018920898\n",
      "\n",
      "Val func train loss in epoch 14:2.3694294802844524\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.4441057443618774\n",
      "\n",
      "episode 2, val func loss 16.355504989624023\n",
      "\n",
      "episode 3, val func loss 2.7962770462036133\n",
      "\n",
      "episode 4, val func loss 0.7634323239326477\n",
      "\n",
      "episode 5, val func loss 22.31795883178711\n",
      "\n",
      "episode 6, val func loss 0.6849915385246277\n",
      "\n",
      "episode 7, val func loss 15.45254135131836\n",
      "\n",
      "episode 8, val func loss 16.417522430419922\n",
      "\n",
      "episode 9, val func loss 0.6422750353813171\n",
      "\n",
      "episode 10, val func loss 12.067256927490234\n",
      "\n",
      "episode 11, val func loss 16.724018096923828\n",
      "\n",
      "episode 12, val func loss 0.7744379639625549\n",
      "\n",
      "episode 13, val func loss 3.1937265396118164\n",
      "\n",
      "episode 14, val func loss 9.01081371307373\n",
      "\n",
      "episode 15, val func loss 10.387084007263184\n",
      "\n",
      "episode 16, val func loss 8.549627304077148\n",
      "\n",
      "Val func train loss in epoch 15:8.59884836524725\n",
      "***********************TIME WAS 5.10031019449234 min*****************************\n",
      "\n",
      "**********************ROUND 1 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -1.2030529975891113\n",
      "\n",
      "episode 2, policy loss -0.23692956566810608\n",
      "\n",
      "episode 3, policy loss -0.7626090049743652\n",
      "\n",
      "episode 4, policy loss -0.3560608923435211\n",
      "\n",
      "episode 5, policy loss -0.3956834077835083\n",
      "\n",
      "episode 6, policy loss -0.2270466387271881\n",
      "\n",
      "episode 7, policy loss -0.3815082609653473\n",
      "\n",
      "episode 8, policy loss -0.46690988540649414\n",
      "\n",
      "episode 9, policy loss -0.48713380098342896\n",
      "\n",
      "episode 10, policy loss -0.7425353527069092\n",
      "\n",
      "episode 11, policy loss -0.5600993633270264\n",
      "\n",
      "episode 12, policy loss -1.1817978620529175\n",
      "\n",
      "episode 13, policy loss -0.8037359714508057\n",
      "\n",
      "episode 14, policy loss -1.3783116340637207\n",
      "\n",
      "episode 15, policy loss -0.8963422179222107\n",
      "\n",
      "episode 16, policy loss -0.5915119647979736\n",
      "\n",
      "Policy train loss in epoch 0:-0.6669543012976646\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -1.1725059747695923\n",
      "\n",
      "episode 2, policy loss -1.1642701625823975\n",
      "\n",
      "episode 3, policy loss -0.9525253176689148\n",
      "\n",
      "episode 4, policy loss -0.6308380365371704\n",
      "\n",
      "episode 5, policy loss -0.5508483052253723\n",
      "\n",
      "episode 6, policy loss -0.9330001473426819\n",
      "\n",
      "episode 7, policy loss -0.7747822999954224\n",
      "\n",
      "episode 8, policy loss -0.7339630126953125\n",
      "\n",
      "episode 9, policy loss -1.0041135549545288\n",
      "\n",
      "episode 10, policy loss -1.3325550556182861\n",
      "\n",
      "episode 11, policy loss -0.9458334445953369\n",
      "\n",
      "episode 12, policy loss -0.8766589164733887\n",
      "\n",
      "episode 13, policy loss -1.038342833518982\n",
      "\n",
      "episode 14, policy loss -0.8397194743156433\n",
      "\n",
      "episode 15, policy loss -0.8947824835777283\n",
      "\n",
      "episode 16, policy loss -1.393707513809204\n",
      "\n",
      "Policy train loss in epoch 1:-0.9524029083549976\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -1.1099803447723389\n",
      "\n",
      "episode 2, policy loss -1.15691339969635\n",
      "\n",
      "episode 3, policy loss -0.9344689846038818\n",
      "\n",
      "episode 4, policy loss -1.0132560729980469\n",
      "\n",
      "episode 5, policy loss -0.6727400422096252\n",
      "\n",
      "episode 6, policy loss -0.9428856372833252\n",
      "\n",
      "episode 7, policy loss -1.3596538305282593\n",
      "\n",
      "episode 8, policy loss -0.6392635107040405\n",
      "\n",
      "episode 9, policy loss -0.855341374874115\n",
      "\n",
      "episode 10, policy loss -0.9109946489334106\n",
      "\n",
      "episode 11, policy loss -1.3515896797180176\n",
      "\n",
      "episode 12, policy loss -1.3935811519622803\n",
      "\n",
      "episode 13, policy loss -0.85145503282547\n",
      "\n",
      "episode 14, policy loss -0.9023032188415527\n",
      "\n",
      "episode 15, policy loss -1.0812801122665405\n",
      "\n",
      "episode 16, policy loss -1.041741132736206\n",
      "\n",
      "Policy train loss in epoch 2:-1.0135905109345913\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -1.4008591175079346\n",
      "\n",
      "episode 2, policy loss -1.152034878730774\n",
      "\n",
      "episode 3, policy loss -1.0741382837295532\n",
      "\n",
      "episode 4, policy loss -0.6468472480773926\n",
      "\n",
      "episode 5, policy loss -1.4250409603118896\n",
      "\n",
      "episode 6, policy loss -0.850802481174469\n",
      "\n",
      "episode 7, policy loss -1.1768256425857544\n",
      "\n",
      "episode 8, policy loss -0.850123405456543\n",
      "\n",
      "episode 9, policy loss -1.0277624130249023\n",
      "\n",
      "episode 10, policy loss -0.6320286393165588\n",
      "\n",
      "episode 11, policy loss -0.9641834497451782\n",
      "\n",
      "episode 12, policy loss -1.0174145698547363\n",
      "\n",
      "episode 13, policy loss -0.9489073157310486\n",
      "\n",
      "episode 14, policy loss -1.3115931749343872\n",
      "\n",
      "episode 15, policy loss -0.9179912209510803\n",
      "\n",
      "episode 16, policy loss -0.9804261922836304\n",
      "\n",
      "Policy train loss in epoch 3:-1.0235611870884895\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.4204506874084473\n",
      "\n",
      "episode 2, val func loss 77.29895782470703\n",
      "\n",
      "episode 3, val func loss 81.77584838867188\n",
      "\n",
      "episode 4, val func loss 133.6411590576172\n",
      "\n",
      "episode 5, val func loss 24.538986206054688\n",
      "\n",
      "episode 6, val func loss 8.400384902954102\n",
      "\n",
      "episode 7, val func loss 38.53488540649414\n",
      "\n",
      "episode 8, val func loss 48.36479568481445\n",
      "\n",
      "episode 9, val func loss 88.97084045410156\n",
      "\n",
      "episode 10, val func loss 14.759561538696289\n",
      "\n",
      "episode 11, val func loss 0.9856054782867432\n",
      "\n",
      "episode 12, val func loss 11.87852668762207\n",
      "\n",
      "episode 13, val func loss 48.867740631103516\n",
      "\n",
      "episode 14, val func loss 75.61227416992188\n",
      "\n",
      "episode 15, val func loss 23.843612670898438\n",
      "\n",
      "episode 16, val func loss 0.7163288593292236\n",
      "\n",
      "Val func train loss in epoch 0:42.5381224155426\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 16.829036712646484\n",
      "\n",
      "episode 2, val func loss 44.16082763671875\n",
      "\n",
      "episode 3, val func loss 45.90071105957031\n",
      "\n",
      "episode 4, val func loss 10.754522323608398\n",
      "\n",
      "episode 5, val func loss 7.454949378967285\n",
      "\n",
      "episode 6, val func loss 0.8936101198196411\n",
      "\n",
      "episode 7, val func loss 6.707849502563477\n",
      "\n",
      "episode 8, val func loss 10.682161331176758\n",
      "\n",
      "episode 9, val func loss 15.59064769744873\n",
      "\n",
      "episode 10, val func loss 21.13441276550293\n",
      "\n",
      "episode 11, val func loss 3.709010362625122\n",
      "\n",
      "episode 12, val func loss 0.4318166971206665\n",
      "\n",
      "episode 13, val func loss 1.7046393156051636\n",
      "\n",
      "episode 14, val func loss 10.60427474975586\n",
      "\n",
      "episode 15, val func loss 5.047056674957275\n",
      "\n",
      "episode 16, val func loss 8.080317497253418\n",
      "\n",
      "Val func train loss in epoch 1:13.105365239083767\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.3744022846221924\n",
      "\n",
      "episode 2, val func loss 0.7862535715103149\n",
      "\n",
      "episode 3, val func loss 1.5337083339691162\n",
      "\n",
      "episode 4, val func loss 4.37315559387207\n",
      "\n",
      "episode 5, val func loss 3.6320130825042725\n",
      "\n",
      "episode 6, val func loss 2.3416144847869873\n",
      "\n",
      "episode 7, val func loss 1.4819241762161255\n",
      "\n",
      "episode 8, val func loss 0.6922406554222107\n",
      "\n",
      "episode 9, val func loss 0.4569193124771118\n",
      "\n",
      "episode 10, val func loss 2.1807711124420166\n",
      "\n",
      "episode 11, val func loss 2.3797976970672607\n",
      "\n",
      "episode 12, val func loss 1.3811442852020264\n",
      "\n",
      "episode 13, val func loss 0.8928054571151733\n",
      "\n",
      "episode 14, val func loss 1.0951040983200073\n",
      "\n",
      "episode 15, val func loss 0.9618798494338989\n",
      "\n",
      "episode 16, val func loss 1.4757264852523804\n",
      "\n",
      "Val func train loss in epoch 2:1.6899662800133228\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.3104462623596191\n",
      "\n",
      "episode 2, val func loss 1.3133115768432617\n",
      "\n",
      "episode 3, val func loss 1.1762140989303589\n",
      "\n",
      "episode 4, val func loss 0.918721079826355\n",
      "\n",
      "episode 5, val func loss 0.986350953578949\n",
      "\n",
      "episode 6, val func loss 1.4612579345703125\n",
      "\n",
      "episode 7, val func loss 1.202986478805542\n",
      "\n",
      "episode 8, val func loss 0.8894786834716797\n",
      "\n",
      "episode 9, val func loss 0.9239427447319031\n",
      "\n",
      "episode 10, val func loss 1.2010836601257324\n",
      "\n",
      "episode 11, val func loss 0.8458162546157837\n",
      "\n",
      "episode 12, val func loss 1.112716555595398\n",
      "\n",
      "episode 13, val func loss 1.4080687761306763\n",
      "\n",
      "episode 14, val func loss 0.9578273892402649\n",
      "\n",
      "episode 15, val func loss 0.8239044547080994\n",
      "\n",
      "episode 16, val func loss 0.41312554478645325\n",
      "\n",
      "Val func train loss in epoch 3:1.0590782780200243\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8220441937446594\n",
      "\n",
      "episode 2, val func loss 0.8950906991958618\n",
      "\n",
      "episode 3, val func loss 1.0071183443069458\n",
      "\n",
      "episode 4, val func loss 0.9949336051940918\n",
      "\n",
      "episode 5, val func loss 0.7761671543121338\n",
      "\n",
      "episode 6, val func loss 1.3118352890014648\n",
      "\n",
      "episode 7, val func loss 0.959446907043457\n",
      "\n",
      "episode 8, val func loss 0.420033723115921\n",
      "\n",
      "episode 9, val func loss 0.8328031897544861\n",
      "\n",
      "episode 10, val func loss 0.8889168500900269\n",
      "\n",
      "episode 11, val func loss 0.9274851083755493\n",
      "\n",
      "episode 12, val func loss 0.8089452981948853\n",
      "\n",
      "episode 13, val func loss 0.8839716911315918\n",
      "\n",
      "episode 14, val func loss 0.6801671981811523\n",
      "\n",
      "episode 15, val func loss 0.9990689754486084\n",
      "\n",
      "episode 16, val func loss 1.0577681064605713\n",
      "\n",
      "Val func train loss in epoch 4:0.8916122708469629\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7701915502548218\n",
      "\n",
      "episode 2, val func loss 1.264905333518982\n",
      "\n",
      "episode 3, val func loss 0.8291001915931702\n",
      "\n",
      "episode 4, val func loss 0.8160783648490906\n",
      "\n",
      "episode 5, val func loss 0.9236122965812683\n",
      "\n",
      "episode 6, val func loss 0.9010545611381531\n",
      "\n",
      "episode 7, val func loss 0.9040655493736267\n",
      "\n",
      "episode 8, val func loss 0.5701683759689331\n",
      "\n",
      "episode 9, val func loss 0.8771682381629944\n",
      "\n",
      "episode 10, val func loss 1.025475025177002\n",
      "\n",
      "episode 11, val func loss 0.7588348388671875\n",
      "\n",
      "episode 12, val func loss 0.8972085118293762\n",
      "\n",
      "episode 13, val func loss 0.6566789746284485\n",
      "\n",
      "episode 14, val func loss 0.40082696080207825\n",
      "\n",
      "episode 15, val func loss 1.0867350101470947\n",
      "\n",
      "episode 16, val func loss 1.0240522623062134\n",
      "\n",
      "Val func train loss in epoch 5:0.8566347528249025\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7518994808197021\n",
      "\n",
      "episode 2, val func loss 0.8044458627700806\n",
      "\n",
      "episode 3, val func loss 0.6189901828765869\n",
      "\n",
      "episode 4, val func loss 0.911356508731842\n",
      "\n",
      "episode 5, val func loss 1.0717641115188599\n",
      "\n",
      "episode 6, val func loss 1.2615195512771606\n",
      "\n",
      "episode 7, val func loss 0.8097854256629944\n",
      "\n",
      "episode 8, val func loss 0.8902654647827148\n",
      "\n",
      "episode 9, val func loss 1.0073845386505127\n",
      "\n",
      "episode 10, val func loss 0.4067806303501129\n",
      "\n",
      "episode 11, val func loss 0.6633914709091187\n",
      "\n",
      "episode 12, val func loss 0.8949477076530457\n",
      "\n",
      "episode 13, val func loss 0.9142459630966187\n",
      "\n",
      "episode 14, val func loss 0.9127103090286255\n",
      "\n",
      "episode 15, val func loss 1.0207551717758179\n",
      "\n",
      "episode 16, val func loss 0.8029110431671143\n",
      "\n",
      "Val func train loss in epoch 6:0.8589470889419317\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.9844667315483093\n",
      "\n",
      "episode 2, val func loss 1.1192594766616821\n",
      "\n",
      "episode 3, val func loss 0.8503023982048035\n",
      "\n",
      "episode 4, val func loss 0.9046579003334045\n",
      "\n",
      "episode 5, val func loss 0.9038320779800415\n",
      "\n",
      "episode 6, val func loss 0.9545716047286987\n",
      "\n",
      "episode 7, val func loss 0.5714356899261475\n",
      "\n",
      "episode 8, val func loss 0.75227290391922\n",
      "\n",
      "episode 9, val func loss 1.2063902616500854\n",
      "\n",
      "episode 10, val func loss 0.9664986729621887\n",
      "\n",
      "episode 11, val func loss 0.681384801864624\n",
      "\n",
      "episode 12, val func loss 0.9769386649131775\n",
      "\n",
      "episode 13, val func loss 0.7996522784233093\n",
      "\n",
      "episode 14, val func loss 0.7546089887619019\n",
      "\n",
      "episode 15, val func loss 0.3913274109363556\n",
      "\n",
      "episode 16, val func loss 0.9623751640319824\n",
      "\n",
      "Val func train loss in epoch 7:0.8612484391778708\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8231868147850037\n",
      "\n",
      "episode 2, val func loss 1.0387030839920044\n",
      "\n",
      "episode 3, val func loss 0.7752938866615295\n",
      "\n",
      "episode 4, val func loss 0.9568570256233215\n",
      "\n",
      "episode 5, val func loss 0.9070084691047668\n",
      "\n",
      "episode 6, val func loss 1.0665429830551147\n",
      "\n",
      "episode 7, val func loss 0.9802118539810181\n",
      "\n",
      "episode 8, val func loss 0.5657972097396851\n",
      "\n",
      "episode 9, val func loss 0.6579596996307373\n",
      "\n",
      "episode 10, val func loss 0.8934044241905212\n",
      "\n",
      "episode 11, val func loss 0.8143879771232605\n",
      "\n",
      "episode 12, val func loss 0.7924296259880066\n",
      "\n",
      "episode 13, val func loss 0.8921248316764832\n",
      "\n",
      "episode 14, val func loss 0.8307430744171143\n",
      "\n",
      "episode 15, val func loss 0.42661523818969727\n",
      "\n",
      "episode 16, val func loss 1.2243186235427856\n",
      "\n",
      "Val func train loss in epoch 8:0.8528490513563156\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.008311152458191\n",
      "\n",
      "episode 2, val func loss 1.2450013160705566\n",
      "\n",
      "episode 3, val func loss 0.6565501093864441\n",
      "\n",
      "episode 4, val func loss 0.8897486925125122\n",
      "\n",
      "episode 5, val func loss 0.9131121635437012\n",
      "\n",
      "episode 6, val func loss 0.38133347034454346\n",
      "\n",
      "episode 7, val func loss 0.9988860487937927\n",
      "\n",
      "episode 8, val func loss 0.8465599417686462\n",
      "\n",
      "episode 9, val func loss 0.6026607155799866\n",
      "\n",
      "episode 10, val func loss 0.9612085819244385\n",
      "\n",
      "episode 11, val func loss 0.9320906400680542\n",
      "\n",
      "episode 12, val func loss 0.8906503319740295\n",
      "\n",
      "episode 13, val func loss 0.7648438215255737\n",
      "\n",
      "episode 14, val func loss 1.0365090370178223\n",
      "\n",
      "episode 15, val func loss 0.9149095416069031\n",
      "\n",
      "episode 16, val func loss 0.9163732528686523\n",
      "\n",
      "Val func train loss in epoch 9:0.8724218010902405\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.817708432674408\n",
      "\n",
      "episode 2, val func loss 0.9545774459838867\n",
      "\n",
      "episode 3, val func loss 0.6303682923316956\n",
      "\n",
      "episode 4, val func loss 0.9990304112434387\n",
      "\n",
      "episode 5, val func loss 1.1949646472930908\n",
      "\n",
      "episode 6, val func loss 0.9094142317771912\n",
      "\n",
      "episode 7, val func loss 1.0762939453125\n",
      "\n",
      "episode 8, val func loss 0.9592104554176331\n",
      "\n",
      "episode 9, val func loss 0.7691154479980469\n",
      "\n",
      "episode 10, val func loss 0.601272463798523\n",
      "\n",
      "episode 11, val func loss 1.2104322910308838\n",
      "\n",
      "episode 12, val func loss 0.39453110098838806\n",
      "\n",
      "episode 13, val func loss 0.7411581873893738\n",
      "\n",
      "episode 14, val func loss 1.03841233253479\n",
      "\n",
      "episode 15, val func loss 0.9772853851318359\n",
      "\n",
      "episode 16, val func loss 1.0264859199523926\n",
      "\n",
      "Val func train loss in epoch 10:0.8937663119286299\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.677339494228363\n",
      "\n",
      "episode 2, val func loss 0.8776098489761353\n",
      "\n",
      "episode 3, val func loss 0.8022388219833374\n",
      "\n",
      "episode 4, val func loss 0.8609682321548462\n",
      "\n",
      "episode 5, val func loss 0.9958616495132446\n",
      "\n",
      "episode 6, val func loss 1.3190975189208984\n",
      "\n",
      "episode 7, val func loss 0.8717678189277649\n",
      "\n",
      "episode 8, val func loss 0.7576230764389038\n",
      "\n",
      "episode 9, val func loss 1.1084758043289185\n",
      "\n",
      "episode 10, val func loss 0.5452051758766174\n",
      "\n",
      "episode 11, val func loss 0.9831538796424866\n",
      "\n",
      "episode 12, val func loss 0.8811678886413574\n",
      "\n",
      "episode 13, val func loss 0.9889340996742249\n",
      "\n",
      "episode 14, val func loss 0.4071013033390045\n",
      "\n",
      "episode 15, val func loss 0.8387432098388672\n",
      "\n",
      "episode 16, val func loss 0.8897334337234497\n",
      "\n",
      "Val func train loss in epoch 11:0.8628138285130262\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.898693859577179\n",
      "\n",
      "episode 2, val func loss 0.960148274898529\n",
      "\n",
      "episode 3, val func loss 1.1033228635787964\n",
      "\n",
      "episode 4, val func loss 1.2353084087371826\n",
      "\n",
      "episode 5, val func loss 0.8003953099250793\n",
      "\n",
      "episode 6, val func loss 0.8245563507080078\n",
      "\n",
      "episode 7, val func loss 0.9391002058982849\n",
      "\n",
      "episode 8, val func loss 0.9109623432159424\n",
      "\n",
      "episode 9, val func loss 0.42794069647789\n",
      "\n",
      "episode 10, val func loss 0.8005324602127075\n",
      "\n",
      "episode 11, val func loss 0.8591710329055786\n",
      "\n",
      "episode 12, val func loss 0.6263301372528076\n",
      "\n",
      "episode 13, val func loss 0.5510266423225403\n",
      "\n",
      "episode 14, val func loss 1.111554741859436\n",
      "\n",
      "episode 15, val func loss 1.0239782333374023\n",
      "\n",
      "episode 16, val func loss 0.8311230540275574\n",
      "\n",
      "Val func train loss in epoch 12:0.8690090384334326\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.7830536365509033\n",
      "\n",
      "episode 2, val func loss 0.794837474822998\n",
      "\n",
      "episode 3, val func loss 0.9338505268096924\n",
      "\n",
      "episode 4, val func loss 0.77476567029953\n",
      "\n",
      "episode 5, val func loss 1.011677861213684\n",
      "\n",
      "episode 6, val func loss 1.2136619091033936\n",
      "\n",
      "episode 7, val func loss 0.9583005905151367\n",
      "\n",
      "episode 8, val func loss 1.5023795366287231\n",
      "\n",
      "episode 9, val func loss 0.8963747620582581\n",
      "\n",
      "episode 10, val func loss 1.164526104927063\n",
      "\n",
      "episode 11, val func loss 1.092597246170044\n",
      "\n",
      "episode 12, val func loss 1.7215040922164917\n",
      "\n",
      "episode 13, val func loss 0.8700743317604065\n",
      "\n",
      "episode 14, val func loss 1.0354790687561035\n",
      "\n",
      "episode 15, val func loss 1.6593284606933594\n",
      "\n",
      "episode 16, val func loss 0.4206218421459198\n",
      "\n",
      "Val func train loss in epoch 13:1.0520645696669817\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.1019411087036133\n",
      "\n",
      "episode 2, val func loss 1.0367499589920044\n",
      "\n",
      "episode 3, val func loss 1.4491915702819824\n",
      "\n",
      "episode 4, val func loss 1.5767643451690674\n",
      "\n",
      "episode 5, val func loss 1.0179381370544434\n",
      "\n",
      "episode 6, val func loss 1.1620301008224487\n",
      "\n",
      "episode 7, val func loss 1.0745807886123657\n",
      "\n",
      "episode 8, val func loss 0.41295483708381653\n",
      "\n",
      "episode 9, val func loss 1.0693129301071167\n",
      "\n",
      "episode 10, val func loss 0.9538806676864624\n",
      "\n",
      "episode 11, val func loss 0.5388309955596924\n",
      "\n",
      "episode 12, val func loss 1.4082837104797363\n",
      "\n",
      "episode 13, val func loss 1.7363135814666748\n",
      "\n",
      "episode 14, val func loss 0.9949028491973877\n",
      "\n",
      "episode 15, val func loss 3.5149612426757812\n",
      "\n",
      "episode 16, val func loss 0.7764793038368225\n",
      "\n",
      "Val func train loss in epoch 14:1.3015697579830885\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 3.657198190689087\n",
      "\n",
      "episode 2, val func loss 0.9900503158569336\n",
      "\n",
      "episode 3, val func loss 1.6346782445907593\n",
      "\n",
      "episode 4, val func loss 1.6942634582519531\n",
      "\n",
      "episode 5, val func loss 1.2469444274902344\n",
      "\n",
      "episode 6, val func loss 1.3650583028793335\n",
      "\n",
      "episode 7, val func loss 1.3623939752578735\n",
      "\n",
      "episode 8, val func loss 0.6767774224281311\n",
      "\n",
      "episode 9, val func loss 0.9971383213996887\n",
      "\n",
      "episode 10, val func loss 0.9080363512039185\n",
      "\n",
      "episode 11, val func loss 1.0701584815979004\n",
      "\n",
      "episode 12, val func loss 0.4108857214450836\n",
      "\n",
      "episode 13, val func loss 0.8357348442077637\n",
      "\n",
      "episode 14, val func loss 0.644370436668396\n",
      "\n",
      "episode 15, val func loss 0.7587345242500305\n",
      "\n",
      "episode 16, val func loss 0.9450284242630005\n",
      "\n",
      "Val func train loss in epoch 15:1.1998407151550055\n",
      "***********************TIME WAS 5.192819452285766 min*****************************\n",
      "\n",
      "**********************ROUND 2 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.04592641070485115\n",
      "\n",
      "episode 2, policy loss -0.14007319509983063\n",
      "\n",
      "episode 3, policy loss 0.06905967742204666\n",
      "\n",
      "episode 4, policy loss -0.01758858561515808\n",
      "\n",
      "episode 5, policy loss 0.059307120740413666\n",
      "\n",
      "episode 6, policy loss -0.011476919054985046\n",
      "\n",
      "episode 7, policy loss -0.10883112251758575\n",
      "\n",
      "episode 8, policy loss -0.0739322379231453\n",
      "\n",
      "episode 9, policy loss 0.0040215179324150085\n",
      "\n",
      "episode 10, policy loss -0.11714182794094086\n",
      "\n",
      "episode 11, policy loss 0.040533896535634995\n",
      "\n",
      "episode 12, policy loss -0.11792498826980591\n",
      "\n",
      "episode 13, policy loss 0.03970383107662201\n",
      "\n",
      "episode 14, policy loss -0.07341646403074265\n",
      "\n",
      "episode 15, policy loss -0.0067703016102313995\n",
      "\n",
      "episode 16, policy loss 0.07454533129930496\n",
      "\n",
      "Policy train loss in epoch 0:-0.026619417360052466\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.08054503798484802\n",
      "\n",
      "episode 2, policy loss -0.013223804533481598\n",
      "\n",
      "episode 3, policy loss 0.06881683319807053\n",
      "\n",
      "episode 4, policy loss -0.1296057254076004\n",
      "\n",
      "episode 5, policy loss -0.10842239111661911\n",
      "\n",
      "episode 6, policy loss -0.1314300298690796\n",
      "\n",
      "episode 7, policy loss -0.07421626150608063\n",
      "\n",
      "episode 8, policy loss -0.08862724155187607\n",
      "\n",
      "episode 9, policy loss 0.05921488255262375\n",
      "\n",
      "episode 10, policy loss 0.022589273750782013\n",
      "\n",
      "episode 11, policy loss -0.014035679399967194\n",
      "\n",
      "episode 12, policy loss 0.06026000529527664\n",
      "\n",
      "episode 13, policy loss -0.15290513634681702\n",
      "\n",
      "episode 14, policy loss 0.02196153998374939\n",
      "\n",
      "episode 15, policy loss -0.014034345746040344\n",
      "\n",
      "episode 16, policy loss -0.012944519519805908\n",
      "\n",
      "Policy train loss in epoch 1:-0.0366967273876071\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.05640696734189987\n",
      "\n",
      "episode 2, policy loss -0.15574344992637634\n",
      "\n",
      "episode 3, policy loss -0.012350887060165405\n",
      "\n",
      "episode 4, policy loss -0.1176157146692276\n",
      "\n",
      "episode 5, policy loss -0.13888637721538544\n",
      "\n",
      "episode 6, policy loss -0.09015141427516937\n",
      "\n",
      "episode 7, policy loss 0.055868566036224365\n",
      "\n",
      "episode 8, policy loss -0.022707153111696243\n",
      "\n",
      "episode 9, policy loss 0.01943061500787735\n",
      "\n",
      "episode 10, policy loss -0.138217493891716\n",
      "\n",
      "episode 11, policy loss -0.09066133201122284\n",
      "\n",
      "episode 12, policy loss 0.019574351608753204\n",
      "\n",
      "episode 13, policy loss 0.06149228662252426\n",
      "\n",
      "episode 14, policy loss -0.012744218111038208\n",
      "\n",
      "episode 15, policy loss -0.07877834141254425\n",
      "\n",
      "episode 16, policy loss -0.02082166075706482\n",
      "\n",
      "Policy train loss in epoch 2:-0.04161907848902047\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.019151203334331512\n",
      "\n",
      "episode 2, policy loss -0.1410500705242157\n",
      "\n",
      "episode 3, policy loss -0.014924518764019012\n",
      "\n",
      "episode 4, policy loss -0.07919272780418396\n",
      "\n",
      "episode 5, policy loss -0.11701551824808121\n",
      "\n",
      "episode 6, policy loss -0.13838399946689606\n",
      "\n",
      "episode 7, policy loss -0.1573997139930725\n",
      "\n",
      "episode 8, policy loss -0.01487695425748825\n",
      "\n",
      "episode 9, policy loss 0.055612243711948395\n",
      "\n",
      "episode 10, policy loss -0.02312970533967018\n",
      "\n",
      "episode 11, policy loss -0.090852752327919\n",
      "\n",
      "episode 12, policy loss 0.01902395486831665\n",
      "\n",
      "episode 13, policy loss 0.0608040988445282\n",
      "\n",
      "episode 14, policy loss -0.020707309246063232\n",
      "\n",
      "episode 15, policy loss 0.05448431521654129\n",
      "\n",
      "episode 16, policy loss -0.09313425421714783\n",
      "\n",
      "Policy train loss in epoch 3:-0.04259948176331818\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.5432584881782532\n",
      "\n",
      "episode 2, val func loss 1.7626065015792847\n",
      "\n",
      "episode 3, val func loss 1.076225996017456\n",
      "\n",
      "episode 4, val func loss 1.75552237033844\n",
      "\n",
      "episode 5, val func loss 1.8303868770599365\n",
      "\n",
      "episode 6, val func loss 1.2409321069717407\n",
      "\n",
      "episode 7, val func loss 1.7513058185577393\n",
      "\n",
      "episode 8, val func loss 1.4889699220657349\n",
      "\n",
      "episode 9, val func loss 0.3473983407020569\n",
      "\n",
      "episode 10, val func loss 1.6091245412826538\n",
      "\n",
      "episode 11, val func loss 1.9741575717926025\n",
      "\n",
      "episode 12, val func loss 1.2315977811813354\n",
      "\n",
      "episode 13, val func loss 1.4889072179794312\n",
      "\n",
      "episode 14, val func loss 1.1848433017730713\n",
      "\n",
      "episode 15, val func loss 0.7466080784797668\n",
      "\n",
      "episode 16, val func loss 0.6584104299545288\n",
      "\n",
      "Val func train loss in epoch 0:1.293140958994627\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.28040531277656555\n",
      "\n",
      "episode 2, val func loss 1.9691509008407593\n",
      "\n",
      "episode 3, val func loss 1.5297473669052124\n",
      "\n",
      "episode 4, val func loss 2.1222445964813232\n",
      "\n",
      "episode 5, val func loss 0.9360264539718628\n",
      "\n",
      "episode 6, val func loss 3.1366312503814697\n",
      "\n",
      "episode 7, val func loss 0.7975090146064758\n",
      "\n",
      "episode 8, val func loss 3.327369451522827\n",
      "\n",
      "episode 9, val func loss 2.402952194213867\n",
      "\n",
      "episode 10, val func loss 1.4539510011672974\n",
      "\n",
      "episode 11, val func loss 1.2552409172058105\n",
      "\n",
      "episode 12, val func loss 0.9951301217079163\n",
      "\n",
      "episode 13, val func loss 1.9672693014144897\n",
      "\n",
      "episode 14, val func loss 0.6297334432601929\n",
      "\n",
      "episode 15, val func loss 1.188231110572815\n",
      "\n",
      "episode 16, val func loss 2.019171714782715\n",
      "\n",
      "Val func train loss in epoch 1:1.625672759488225\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.9066627025604248\n",
      "\n",
      "episode 2, val func loss 1.718022108078003\n",
      "\n",
      "episode 3, val func loss 1.6773273944854736\n",
      "\n",
      "episode 4, val func loss 1.5530444383621216\n",
      "\n",
      "episode 5, val func loss 1.1032463312149048\n",
      "\n",
      "episode 6, val func loss 2.131650686264038\n",
      "\n",
      "episode 7, val func loss 0.3813786804676056\n",
      "\n",
      "episode 8, val func loss 2.6055753231048584\n",
      "\n",
      "episode 9, val func loss 1.787874698638916\n",
      "\n",
      "episode 10, val func loss 2.2989799976348877\n",
      "\n",
      "episode 11, val func loss 0.7790833711624146\n",
      "\n",
      "episode 12, val func loss 2.5756285190582275\n",
      "\n",
      "episode 13, val func loss 1.0675452947616577\n",
      "\n",
      "episode 14, val func loss 2.756160259246826\n",
      "\n",
      "episode 15, val func loss 0.8471673130989075\n",
      "\n",
      "episode 16, val func loss 4.337855815887451\n",
      "\n",
      "Val func train loss in epoch 2:1.8454501833766699\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.3966193199157715\n",
      "\n",
      "episode 2, val func loss 3.218933582305908\n",
      "\n",
      "episode 3, val func loss 0.3668627142906189\n",
      "\n",
      "episode 4, val func loss 2.721022367477417\n",
      "\n",
      "episode 5, val func loss 4.990741729736328\n",
      "\n",
      "episode 6, val func loss 2.0286874771118164\n",
      "\n",
      "episode 7, val func loss 5.430922985076904\n",
      "\n",
      "episode 8, val func loss 0.7879617214202881\n",
      "\n",
      "episode 9, val func loss 3.4201343059539795\n",
      "\n",
      "episode 10, val func loss 2.325791835784912\n",
      "\n",
      "episode 11, val func loss 2.6154582500457764\n",
      "\n",
      "episode 12, val func loss 4.7020697593688965\n",
      "\n",
      "episode 13, val func loss 2.7169368267059326\n",
      "\n",
      "episode 14, val func loss 0.9021017551422119\n",
      "\n",
      "episode 15, val func loss 3.3950958251953125\n",
      "\n",
      "episode 16, val func loss 2.5009708404541016\n",
      "\n",
      "Val func train loss in epoch 3:2.782519455999136\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.19566011428833\n",
      "\n",
      "episode 2, val func loss 1.9858604669570923\n",
      "\n",
      "episode 3, val func loss 2.07024884223938\n",
      "\n",
      "episode 4, val func loss 2.034921646118164\n",
      "\n",
      "episode 5, val func loss 1.469942569732666\n",
      "\n",
      "episode 6, val func loss 0.9870363473892212\n",
      "\n",
      "episode 7, val func loss 1.8815746307373047\n",
      "\n",
      "episode 8, val func loss 1.8081215620040894\n",
      "\n",
      "episode 9, val func loss 1.4814655780792236\n",
      "\n",
      "episode 10, val func loss 0.2853987514972687\n",
      "\n",
      "episode 11, val func loss 2.275007486343384\n",
      "\n",
      "episode 12, val func loss 1.1104092597961426\n",
      "\n",
      "episode 13, val func loss 1.6906805038452148\n",
      "\n",
      "episode 14, val func loss 1.0811975002288818\n",
      "\n",
      "episode 15, val func loss 2.392731189727783\n",
      "\n",
      "episode 16, val func loss 0.4977438151836395\n",
      "\n",
      "Val func train loss in epoch 4:1.5780000165104866\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.477833867073059\n",
      "\n",
      "episode 2, val func loss 2.604663133621216\n",
      "\n",
      "episode 3, val func loss 0.9014387130737305\n",
      "\n",
      "episode 4, val func loss 3.4303195476531982\n",
      "\n",
      "episode 5, val func loss 1.5298138856887817\n",
      "\n",
      "episode 6, val func loss 2.0355064868927\n",
      "\n",
      "episode 7, val func loss 3.0228464603424072\n",
      "\n",
      "episode 8, val func loss 0.659144937992096\n",
      "\n",
      "episode 9, val func loss 1.0221914052963257\n",
      "\n",
      "episode 10, val func loss 2.5330238342285156\n",
      "\n",
      "episode 11, val func loss 0.36979979276657104\n",
      "\n",
      "episode 12, val func loss 2.764592170715332\n",
      "\n",
      "episode 13, val func loss 1.3639318943023682\n",
      "\n",
      "episode 14, val func loss 1.768488883972168\n",
      "\n",
      "episode 15, val func loss 1.915181040763855\n",
      "\n",
      "episode 16, val func loss 1.0811729431152344\n",
      "\n",
      "Val func train loss in epoch 5:1.7799968123435974\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.5771600604057312\n",
      "\n",
      "episode 2, val func loss 1.1628419160842896\n",
      "\n",
      "episode 3, val func loss 0.2954174280166626\n",
      "\n",
      "episode 4, val func loss 1.0782668590545654\n",
      "\n",
      "episode 5, val func loss 0.9536156058311462\n",
      "\n",
      "episode 6, val func loss 1.7713682651519775\n",
      "\n",
      "episode 7, val func loss 1.2089475393295288\n",
      "\n",
      "episode 8, val func loss 2.5105135440826416\n",
      "\n",
      "episode 9, val func loss 1.5228317975997925\n",
      "\n",
      "episode 10, val func loss 0.9571825265884399\n",
      "\n",
      "episode 11, val func loss 1.8267567157745361\n",
      "\n",
      "episode 12, val func loss 1.6169475317001343\n",
      "\n",
      "episode 13, val func loss 1.2432191371917725\n",
      "\n",
      "episode 14, val func loss 2.0468995571136475\n",
      "\n",
      "episode 15, val func loss 1.6821240186691284\n",
      "\n",
      "episode 16, val func loss 2.013671636581421\n",
      "\n",
      "Val func train loss in epoch 6:1.4042352586984634\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.9649469256401062\n",
      "\n",
      "episode 2, val func loss 2.0248892307281494\n",
      "\n",
      "episode 3, val func loss 1.7705920934677124\n",
      "\n",
      "episode 4, val func loss 1.610781192779541\n",
      "\n",
      "episode 5, val func loss 0.6526003479957581\n",
      "\n",
      "episode 6, val func loss 1.546011209487915\n",
      "\n",
      "episode 7, val func loss 0.5283554196357727\n",
      "\n",
      "episode 8, val func loss 3.0642454624176025\n",
      "\n",
      "episode 9, val func loss 0.9415886402130127\n",
      "\n",
      "episode 10, val func loss 1.9209084510803223\n",
      "\n",
      "episode 11, val func loss 1.9446985721588135\n",
      "\n",
      "episode 12, val func loss 1.8144394159317017\n",
      "\n",
      "episode 13, val func loss 2.1106014251708984\n",
      "\n",
      "episode 14, val func loss 1.0809876918792725\n",
      "\n",
      "episode 15, val func loss 1.145530104637146\n",
      "\n",
      "episode 16, val func loss 1.0840178728103638\n",
      "\n",
      "Val func train loss in epoch 7:1.5128246285021305\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.486453652381897\n",
      "\n",
      "episode 2, val func loss 1.4955955743789673\n",
      "\n",
      "episode 3, val func loss 0.9502825736999512\n",
      "\n",
      "episode 4, val func loss 1.2267359495162964\n",
      "\n",
      "episode 5, val func loss 1.5918164253234863\n",
      "\n",
      "episode 6, val func loss 1.5788713693618774\n",
      "\n",
      "episode 7, val func loss 0.7112546563148499\n",
      "\n",
      "episode 8, val func loss 1.7044750452041626\n",
      "\n",
      "episode 9, val func loss 2.075202465057373\n",
      "\n",
      "episode 10, val func loss 0.29835399985313416\n",
      "\n",
      "episode 11, val func loss 1.7348556518554688\n",
      "\n",
      "episode 12, val func loss 1.6965184211730957\n",
      "\n",
      "episode 13, val func loss 0.7462261915206909\n",
      "\n",
      "episode 14, val func loss 1.0940624475479126\n",
      "\n",
      "episode 15, val func loss 0.8019131422042847\n",
      "\n",
      "episode 16, val func loss 1.310886263847351\n",
      "\n",
      "Val func train loss in epoch 8:1.28146898932755\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.7355231046676636\n",
      "\n",
      "episode 2, val func loss 1.007311224937439\n",
      "\n",
      "episode 3, val func loss 1.8749828338623047\n",
      "\n",
      "episode 4, val func loss 0.37261947989463806\n",
      "\n",
      "episode 5, val func loss 1.9436914920806885\n",
      "\n",
      "episode 6, val func loss 1.2707765102386475\n",
      "\n",
      "episode 7, val func loss 1.9157240390777588\n",
      "\n",
      "episode 8, val func loss 1.2691822052001953\n",
      "\n",
      "episode 9, val func loss 1.7014247179031372\n",
      "\n",
      "episode 10, val func loss 1.7966058254241943\n",
      "\n",
      "episode 11, val func loss 1.2545793056488037\n",
      "\n",
      "episode 12, val func loss 0.7693790197372437\n",
      "\n",
      "episode 13, val func loss 0.8218327760696411\n",
      "\n",
      "episode 14, val func loss 1.5641881227493286\n",
      "\n",
      "episode 15, val func loss 0.52986741065979\n",
      "\n",
      "episode 16, val func loss 1.6491843461990356\n",
      "\n",
      "Val func train loss in epoch 9:1.3423045258969069\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.3898313343524933\n",
      "\n",
      "episode 2, val func loss 1.4942647218704224\n",
      "\n",
      "episode 3, val func loss 1.0359457731246948\n",
      "\n",
      "episode 4, val func loss 1.037100076675415\n",
      "\n",
      "episode 5, val func loss 1.237067461013794\n",
      "\n",
      "episode 6, val func loss 2.1111788749694824\n",
      "\n",
      "episode 7, val func loss 0.8402134776115417\n",
      "\n",
      "episode 8, val func loss 0.6365454792976379\n",
      "\n",
      "episode 9, val func loss 1.5937803983688354\n",
      "\n",
      "episode 10, val func loss 1.2019110918045044\n",
      "\n",
      "episode 11, val func loss 1.7214264869689941\n",
      "\n",
      "episode 12, val func loss 1.7159935235977173\n",
      "\n",
      "episode 13, val func loss 1.7797292470932007\n",
      "\n",
      "episode 14, val func loss 1.4853711128234863\n",
      "\n",
      "episode 15, val func loss 2.243889808654785\n",
      "\n",
      "episode 16, val func loss 0.694896936416626\n",
      "\n",
      "Val func train loss in epoch 10:1.326196612790227\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.7105809450149536\n",
      "\n",
      "episode 2, val func loss 1.0698742866516113\n",
      "\n",
      "episode 3, val func loss 1.7009238004684448\n",
      "\n",
      "episode 4, val func loss 1.0387156009674072\n",
      "\n",
      "episode 5, val func loss 0.5634454488754272\n",
      "\n",
      "episode 6, val func loss 0.7637244462966919\n",
      "\n",
      "episode 7, val func loss 2.0427210330963135\n",
      "\n",
      "episode 8, val func loss 0.7932342290878296\n",
      "\n",
      "episode 9, val func loss 2.039255142211914\n",
      "\n",
      "episode 10, val func loss 1.2916336059570312\n",
      "\n",
      "episode 11, val func loss 1.692696452140808\n",
      "\n",
      "episode 12, val func loss 1.5986123085021973\n",
      "\n",
      "episode 13, val func loss 0.5472783446311951\n",
      "\n",
      "episode 14, val func loss 1.1507678031921387\n",
      "\n",
      "episode 15, val func loss 1.721286654472351\n",
      "\n",
      "episode 16, val func loss 1.6342616081237793\n",
      "\n",
      "Val func train loss in epoch 11:1.3349382318556309\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.1163188219070435\n",
      "\n",
      "episode 2, val func loss 1.6960750818252563\n",
      "\n",
      "episode 3, val func loss 1.99659264087677\n",
      "\n",
      "episode 4, val func loss 1.5879600048065186\n",
      "\n",
      "episode 5, val func loss 1.1568169593811035\n",
      "\n",
      "episode 6, val func loss 1.8396846055984497\n",
      "\n",
      "episode 7, val func loss 0.5274922251701355\n",
      "\n",
      "episode 8, val func loss 2.3460986614227295\n",
      "\n",
      "episode 9, val func loss 1.5948785543441772\n",
      "\n",
      "episode 10, val func loss 2.3221373558044434\n",
      "\n",
      "episode 11, val func loss 1.7849180698394775\n",
      "\n",
      "episode 12, val func loss 2.930894374847412\n",
      "\n",
      "episode 13, val func loss 0.3967912495136261\n",
      "\n",
      "episode 14, val func loss 1.538625955581665\n",
      "\n",
      "episode 15, val func loss 1.023215413093567\n",
      "\n",
      "episode 16, val func loss 1.178269863128662\n",
      "\n",
      "Val func train loss in epoch 12:1.5647981148213148\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.4505935907363892\n",
      "\n",
      "episode 2, val func loss 1.1828434467315674\n",
      "\n",
      "episode 3, val func loss 1.5416810512542725\n",
      "\n",
      "episode 4, val func loss 2.492271900177002\n",
      "\n",
      "episode 5, val func loss 0.76640784740448\n",
      "\n",
      "episode 6, val func loss 1.80763578414917\n",
      "\n",
      "episode 7, val func loss 0.3482883870601654\n",
      "\n",
      "episode 8, val func loss 1.59464693069458\n",
      "\n",
      "episode 9, val func loss 2.3624773025512695\n",
      "\n",
      "episode 10, val func loss 1.624819040298462\n",
      "\n",
      "episode 11, val func loss 0.7601262331008911\n",
      "\n",
      "episode 12, val func loss 2.6346168518066406\n",
      "\n",
      "episode 13, val func loss 2.1255993843078613\n",
      "\n",
      "episode 14, val func loss 2.4162137508392334\n",
      "\n",
      "episode 15, val func loss 1.7133122682571411\n",
      "\n",
      "episode 16, val func loss 1.0275888442993164\n",
      "\n",
      "Val func train loss in epoch 13:1.6155701633542776\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.8235129117965698\n",
      "\n",
      "episode 2, val func loss 1.4232070446014404\n",
      "\n",
      "episode 3, val func loss 2.0648419857025146\n",
      "\n",
      "episode 4, val func loss 1.239451289176941\n",
      "\n",
      "episode 5, val func loss 0.9015546441078186\n",
      "\n",
      "episode 6, val func loss 1.78914213180542\n",
      "\n",
      "episode 7, val func loss 2.1695377826690674\n",
      "\n",
      "episode 8, val func loss 1.4481309652328491\n",
      "\n",
      "episode 9, val func loss 1.486246109008789\n",
      "\n",
      "episode 10, val func loss 1.6252487897872925\n",
      "\n",
      "episode 11, val func loss 1.4670010805130005\n",
      "\n",
      "episode 12, val func loss 0.284275621175766\n",
      "\n",
      "episode 13, val func loss 1.9018031358718872\n",
      "\n",
      "episode 14, val func loss 0.7024575471878052\n",
      "\n",
      "episode 15, val func loss 1.892551302909851\n",
      "\n",
      "episode 16, val func loss 0.60512375831604\n",
      "\n",
      "Val func train loss in epoch 14:1.4265053812414408\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.5214931964874268\n",
      "\n",
      "episode 2, val func loss 0.8233485817909241\n",
      "\n",
      "episode 3, val func loss 1.9435601234436035\n",
      "\n",
      "episode 4, val func loss 1.6896666288375854\n",
      "\n",
      "episode 5, val func loss 2.7193663120269775\n",
      "\n",
      "episode 6, val func loss 0.27715763449668884\n",
      "\n",
      "episode 7, val func loss 3.0312812328338623\n",
      "\n",
      "episode 8, val func loss 1.6144506931304932\n",
      "\n",
      "episode 9, val func loss 2.7982981204986572\n",
      "\n",
      "episode 10, val func loss 1.1153422594070435\n",
      "\n",
      "episode 11, val func loss 1.686945915222168\n",
      "\n",
      "episode 12, val func loss 1.1323273181915283\n",
      "\n",
      "episode 13, val func loss 2.3128960132598877\n",
      "\n",
      "episode 14, val func loss 1.484764575958252\n",
      "\n",
      "episode 15, val func loss 1.647553563117981\n",
      "\n",
      "episode 16, val func loss 1.4596476554870605\n",
      "\n",
      "Val func train loss in epoch 15:1.6411312390118837\n",
      "***********************TIME WAS 5.159352298577627 min*****************************\n",
      "\n",
      "**********************ROUND 3 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.00342608243227005\n",
      "\n",
      "episode 2, policy loss -0.26193252205848694\n",
      "\n",
      "episode 3, policy loss -0.1776660978794098\n",
      "\n",
      "episode 4, policy loss 0.014120101928710938\n",
      "\n",
      "episode 5, policy loss -0.27351537346839905\n",
      "\n",
      "episode 6, policy loss -0.0032601505517959595\n",
      "\n",
      "episode 7, policy loss -0.3950729966163635\n",
      "\n",
      "episode 8, policy loss -0.2208564132452011\n",
      "\n",
      "episode 9, policy loss -0.43131038546562195\n",
      "\n",
      "episode 10, policy loss -0.14727193117141724\n",
      "\n",
      "episode 11, policy loss -0.1536402553319931\n",
      "\n",
      "episode 12, policy loss -0.16997721791267395\n",
      "\n",
      "episode 13, policy loss -0.2405465841293335\n",
      "\n",
      "episode 14, policy loss -0.0706101804971695\n",
      "\n",
      "episode 15, policy loss -0.06062963977456093\n",
      "\n",
      "episode 16, policy loss -0.12211433053016663\n",
      "\n",
      "Policy train loss in epoch 0:-0.16942861839197576\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.44918176531791687\n",
      "\n",
      "episode 2, policy loss -0.2561052739620209\n",
      "\n",
      "episode 3, policy loss -0.23555314540863037\n",
      "\n",
      "episode 4, policy loss -0.1262645423412323\n",
      "\n",
      "episode 5, policy loss -0.07509797066450119\n",
      "\n",
      "episode 6, policy loss -0.4212038218975067\n",
      "\n",
      "episode 7, policy loss -0.19572514295578003\n",
      "\n",
      "episode 8, policy loss -0.1728592813014984\n",
      "\n",
      "episode 9, policy loss -0.022995151579380035\n",
      "\n",
      "episode 10, policy loss -0.24903494119644165\n",
      "\n",
      "episode 11, policy loss -0.06487459689378738\n",
      "\n",
      "episode 12, policy loss 0.0028876885771751404\n",
      "\n",
      "episode 13, policy loss -0.09609152376651764\n",
      "\n",
      "episode 14, policy loss -0.18481528759002686\n",
      "\n",
      "episode 15, policy loss -0.29216399788856506\n",
      "\n",
      "episode 16, policy loss -0.19220325350761414\n",
      "\n",
      "Policy train loss in epoch 1:-0.18945512548089027\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.18577128648757935\n",
      "\n",
      "episode 2, policy loss -0.07201860845088959\n",
      "\n",
      "episode 3, policy loss -0.19348260760307312\n",
      "\n",
      "episode 4, policy loss -0.08834522217512131\n",
      "\n",
      "episode 5, policy loss -0.2782611548900604\n",
      "\n",
      "episode 6, policy loss -0.10189712047576904\n",
      "\n",
      "episode 7, policy loss -0.47382062673568726\n",
      "\n",
      "episode 8, policy loss -0.43138062953948975\n",
      "\n",
      "episode 9, policy loss -0.21068787574768066\n",
      "\n",
      "episode 10, policy loss -0.2596721053123474\n",
      "\n",
      "episode 11, policy loss -0.1858365833759308\n",
      "\n",
      "episode 12, policy loss -0.0341290682554245\n",
      "\n",
      "episode 13, policy loss -0.3006399869918823\n",
      "\n",
      "episode 14, policy loss -0.2615029513835907\n",
      "\n",
      "episode 15, policy loss -0.14971813559532166\n",
      "\n",
      "episode 16, policy loss -0.003661535680294037\n",
      "\n",
      "Policy train loss in epoch 2:-0.20192659366875887\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.1845622956752777\n",
      "\n",
      "episode 2, policy loss -0.00257796049118042\n",
      "\n",
      "episode 3, policy loss -0.08758188039064407\n",
      "\n",
      "episode 4, policy loss -0.10389149188995361\n",
      "\n",
      "episode 5, policy loss -0.273176372051239\n",
      "\n",
      "episode 6, policy loss -0.2951171398162842\n",
      "\n",
      "episode 7, policy loss -0.261871337890625\n",
      "\n",
      "episode 8, policy loss -0.2571299374103546\n",
      "\n",
      "episode 9, policy loss -0.1910989135503769\n",
      "\n",
      "episode 10, policy loss -0.14558914303779602\n",
      "\n",
      "episode 11, policy loss -0.032090503722429276\n",
      "\n",
      "episode 12, policy loss -0.07254024595022202\n",
      "\n",
      "episode 13, policy loss -0.42994600534439087\n",
      "\n",
      "episode 14, policy loss -0.47072842717170715\n",
      "\n",
      "episode 15, policy loss -0.18828922510147095\n",
      "\n",
      "episode 16, policy loss -0.2046012580394745\n",
      "\n",
      "Policy train loss in epoch 3:-0.20004950859583914\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.320958137512207\n",
      "\n",
      "episode 2, val func loss 3.471233606338501\n",
      "\n",
      "episode 3, val func loss 1.5453786849975586\n",
      "\n",
      "episode 4, val func loss 2.5196924209594727\n",
      "\n",
      "episode 5, val func loss 3.0303173065185547\n",
      "\n",
      "episode 6, val func loss 1.968914270401001\n",
      "\n",
      "episode 7, val func loss 2.229083776473999\n",
      "\n",
      "episode 8, val func loss 3.1636552810668945\n",
      "\n",
      "episode 9, val func loss 3.1599366664886475\n",
      "\n",
      "episode 10, val func loss 1.8812119960784912\n",
      "\n",
      "episode 11, val func loss 3.750386953353882\n",
      "\n",
      "episode 12, val func loss 4.060717582702637\n",
      "\n",
      "episode 13, val func loss 2.855586290359497\n",
      "\n",
      "episode 14, val func loss 2.3285903930664062\n",
      "\n",
      "episode 15, val func loss 3.2392120361328125\n",
      "\n",
      "episode 16, val func loss 1.7545602321624756\n",
      "\n",
      "Val func train loss in epoch 0:2.704964727163315\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.7736706733703613\n",
      "\n",
      "episode 2, val func loss 2.942854642868042\n",
      "\n",
      "episode 3, val func loss 3.2144205570220947\n",
      "\n",
      "episode 4, val func loss 3.15818452835083\n",
      "\n",
      "episode 5, val func loss 2.312793254852295\n",
      "\n",
      "episode 6, val func loss 2.3169682025909424\n",
      "\n",
      "episode 7, val func loss 3.2776708602905273\n",
      "\n",
      "episode 8, val func loss 3.353864908218384\n",
      "\n",
      "episode 9, val func loss 2.9423768520355225\n",
      "\n",
      "episode 10, val func loss 3.2679405212402344\n",
      "\n",
      "episode 11, val func loss 1.6959978342056274\n",
      "\n",
      "episode 12, val func loss 2.5502853393554688\n",
      "\n",
      "episode 13, val func loss 3.0630404949188232\n",
      "\n",
      "episode 14, val func loss 1.6632554531097412\n",
      "\n",
      "episode 15, val func loss 1.981740951538086\n",
      "\n",
      "episode 16, val func loss 4.40177583694458\n",
      "\n",
      "Val func train loss in epoch 1:2.8073025569319725\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.785003423690796\n",
      "\n",
      "episode 2, val func loss 4.73976993560791\n",
      "\n",
      "episode 3, val func loss 3.149393320083618\n",
      "\n",
      "episode 4, val func loss 3.5146396160125732\n",
      "\n",
      "episode 5, val func loss 3.706763982772827\n",
      "\n",
      "episode 6, val func loss 2.3025522232055664\n",
      "\n",
      "episode 7, val func loss 1.8524647951126099\n",
      "\n",
      "episode 8, val func loss 1.5960112810134888\n",
      "\n",
      "episode 9, val func loss 3.3258707523345947\n",
      "\n",
      "episode 10, val func loss 3.5363240242004395\n",
      "\n",
      "episode 11, val func loss 3.0472750663757324\n",
      "\n",
      "episode 12, val func loss 2.373546838760376\n",
      "\n",
      "episode 13, val func loss 2.7448983192443848\n",
      "\n",
      "episode 14, val func loss 3.247730255126953\n",
      "\n",
      "episode 15, val func loss 1.7603347301483154\n",
      "\n",
      "episode 16, val func loss 2.410210132598877\n",
      "\n",
      "Val func train loss in epoch 2:2.8807992935180664\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 3.840188503265381\n",
      "\n",
      "episode 2, val func loss 2.288600206375122\n",
      "\n",
      "episode 3, val func loss 2.9886083602905273\n",
      "\n",
      "episode 4, val func loss 3.738921642303467\n",
      "\n",
      "episode 5, val func loss 1.6915701627731323\n",
      "\n",
      "episode 6, val func loss 5.201086521148682\n",
      "\n",
      "episode 7, val func loss 1.96611487865448\n",
      "\n",
      "episode 8, val func loss 3.7769410610198975\n",
      "\n",
      "episode 9, val func loss 3.79966139793396\n",
      "\n",
      "episode 10, val func loss 1.6305351257324219\n",
      "\n",
      "episode 11, val func loss 3.2927207946777344\n",
      "\n",
      "episode 12, val func loss 3.273526430130005\n",
      "\n",
      "episode 13, val func loss 1.658137321472168\n",
      "\n",
      "episode 14, val func loss 4.186816692352295\n",
      "\n",
      "episode 15, val func loss 2.8734562397003174\n",
      "\n",
      "episode 16, val func loss 2.534675121307373\n",
      "\n",
      "Val func train loss in epoch 3:3.04634752869606\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.9689111709594727\n",
      "\n",
      "episode 2, val func loss 2.27694034576416\n",
      "\n",
      "episode 3, val func loss 3.386904001235962\n",
      "\n",
      "episode 4, val func loss 1.6615736484527588\n",
      "\n",
      "episode 5, val func loss 2.5231449604034424\n",
      "\n",
      "episode 6, val func loss 3.7047119140625\n",
      "\n",
      "episode 7, val func loss 1.8160712718963623\n",
      "\n",
      "episode 8, val func loss 2.830406665802002\n",
      "\n",
      "episode 9, val func loss 1.653954267501831\n",
      "\n",
      "episode 10, val func loss 2.685930013656616\n",
      "\n",
      "episode 11, val func loss 1.6756057739257812\n",
      "\n",
      "episode 12, val func loss 2.403940200805664\n",
      "\n",
      "episode 13, val func loss 2.9505841732025146\n",
      "\n",
      "episode 14, val func loss 2.2149159908294678\n",
      "\n",
      "episode 15, val func loss 3.0781147480010986\n",
      "\n",
      "episode 16, val func loss 3.2169060707092285\n",
      "\n",
      "Val func train loss in epoch 4:2.565538451075554\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 3.3839356899261475\n",
      "\n",
      "episode 2, val func loss 1.8256969451904297\n",
      "\n",
      "episode 3, val func loss 1.9090855121612549\n",
      "\n",
      "episode 4, val func loss 4.094653606414795\n",
      "\n",
      "episode 5, val func loss 3.828441619873047\n",
      "\n",
      "episode 6, val func loss 3.9283182621002197\n",
      "\n",
      "episode 7, val func loss 3.236607551574707\n",
      "\n",
      "episode 8, val func loss 2.012615442276001\n",
      "\n",
      "episode 9, val func loss 3.5926849842071533\n",
      "\n",
      "episode 10, val func loss 3.268570899963379\n",
      "\n",
      "episode 11, val func loss 2.6306326389312744\n",
      "\n",
      "episode 12, val func loss 3.6182005405426025\n",
      "\n",
      "episode 13, val func loss 3.3715741634368896\n",
      "\n",
      "episode 14, val func loss 2.311237335205078\n",
      "\n",
      "episode 15, val func loss 4.307741165161133\n",
      "\n",
      "episode 16, val func loss 1.774787425994873\n",
      "\n",
      "Val func train loss in epoch 5:3.0684239864349365\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.7149691581726074\n",
      "\n",
      "episode 2, val func loss 1.8973388671875\n",
      "\n",
      "episode 3, val func loss 2.889721393585205\n",
      "\n",
      "episode 4, val func loss 2.3042988777160645\n",
      "\n",
      "episode 5, val func loss 2.241798162460327\n",
      "\n",
      "episode 6, val func loss 2.5357086658477783\n",
      "\n",
      "episode 7, val func loss 3.2541112899780273\n",
      "\n",
      "episode 8, val func loss 1.8765521049499512\n",
      "\n",
      "episode 9, val func loss 1.8365206718444824\n",
      "\n",
      "episode 10, val func loss 3.69933819770813\n",
      "\n",
      "episode 11, val func loss 2.3442392349243164\n",
      "\n",
      "episode 12, val func loss 2.946075916290283\n",
      "\n",
      "episode 13, val func loss 3.399547576904297\n",
      "\n",
      "episode 14, val func loss 3.2491867542266846\n",
      "\n",
      "episode 15, val func loss 3.652960777282715\n",
      "\n",
      "episode 16, val func loss 2.787975788116455\n",
      "\n",
      "Val func train loss in epoch 6:2.6643964648246765\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.5558220148086548\n",
      "\n",
      "episode 2, val func loss 2.908543586730957\n",
      "\n",
      "episode 3, val func loss 2.7436940670013428\n",
      "\n",
      "episode 4, val func loss 2.249998092651367\n",
      "\n",
      "episode 5, val func loss 3.4356229305267334\n",
      "\n",
      "episode 6, val func loss 3.3206169605255127\n",
      "\n",
      "episode 7, val func loss 2.895153284072876\n",
      "\n",
      "episode 8, val func loss 3.56716251373291\n",
      "\n",
      "episode 9, val func loss 3.057063341140747\n",
      "\n",
      "episode 10, val func loss 1.7926199436187744\n",
      "\n",
      "episode 11, val func loss 1.924416422843933\n",
      "\n",
      "episode 12, val func loss 3.7586276531219482\n",
      "\n",
      "episode 13, val func loss 1.5956326723098755\n",
      "\n",
      "episode 14, val func loss 3.312645435333252\n",
      "\n",
      "episode 15, val func loss 5.2758893966674805\n",
      "\n",
      "episode 16, val func loss 2.872861862182617\n",
      "\n",
      "Val func train loss in epoch 7:2.8916481360793114\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 4.52935791015625\n",
      "\n",
      "episode 2, val func loss 2.7283730506896973\n",
      "\n",
      "episode 3, val func loss 2.571458339691162\n",
      "\n",
      "episode 4, val func loss 4.890381813049316\n",
      "\n",
      "episode 5, val func loss 2.40718674659729\n",
      "\n",
      "episode 6, val func loss 2.881406784057617\n",
      "\n",
      "episode 7, val func loss 3.0042290687561035\n",
      "\n",
      "episode 8, val func loss 1.7741892337799072\n",
      "\n",
      "episode 9, val func loss 2.967801094055176\n",
      "\n",
      "episode 10, val func loss 2.846245288848877\n",
      "\n",
      "episode 11, val func loss 4.128132343292236\n",
      "\n",
      "episode 12, val func loss 2.21793794631958\n",
      "\n",
      "episode 13, val func loss 3.548513174057007\n",
      "\n",
      "episode 14, val func loss 1.8220562934875488\n",
      "\n",
      "episode 15, val func loss 3.029491901397705\n",
      "\n",
      "episode 16, val func loss 1.581676959991455\n",
      "\n",
      "Val func train loss in epoch 8:2.933027371764183\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.5922837257385254\n",
      "\n",
      "episode 2, val func loss 4.409878730773926\n",
      "\n",
      "episode 3, val func loss 2.3184468746185303\n",
      "\n",
      "episode 4, val func loss 1.8664418458938599\n",
      "\n",
      "episode 5, val func loss 3.96299147605896\n",
      "\n",
      "episode 6, val func loss 2.8680570125579834\n",
      "\n",
      "episode 7, val func loss 3.5948781967163086\n",
      "\n",
      "episode 8, val func loss 3.4887125492095947\n",
      "\n",
      "episode 9, val func loss 3.8104426860809326\n",
      "\n",
      "episode 10, val func loss 2.8598036766052246\n",
      "\n",
      "episode 11, val func loss 1.9766017198562622\n",
      "\n",
      "episode 12, val func loss 3.819521188735962\n",
      "\n",
      "episode 13, val func loss 2.7725753784179688\n",
      "\n",
      "episode 14, val func loss 4.647852897644043\n",
      "\n",
      "episode 15, val func loss 1.7327934503555298\n",
      "\n",
      "episode 16, val func loss 2.2450554370880127\n",
      "\n",
      "Val func train loss in epoch 9:2.9978960528969765\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.7802695035934448\n",
      "\n",
      "episode 2, val func loss 3.194626569747925\n",
      "\n",
      "episode 3, val func loss 2.9029109477996826\n",
      "\n",
      "episode 4, val func loss 2.9904141426086426\n",
      "\n",
      "episode 5, val func loss 1.6806280612945557\n",
      "\n",
      "episode 6, val func loss 3.879155397415161\n",
      "\n",
      "episode 7, val func loss 2.166860342025757\n",
      "\n",
      "episode 8, val func loss 1.8141906261444092\n",
      "\n",
      "episode 9, val func loss 2.8997671604156494\n",
      "\n",
      "episode 10, val func loss 3.198822021484375\n",
      "\n",
      "episode 11, val func loss 1.6598454713821411\n",
      "\n",
      "episode 12, val func loss 2.3760805130004883\n",
      "\n",
      "episode 13, val func loss 2.4823851585388184\n",
      "\n",
      "episode 14, val func loss 2.955392599105835\n",
      "\n",
      "episode 15, val func loss 2.2823545932769775\n",
      "\n",
      "episode 16, val func loss 2.6416149139404297\n",
      "\n",
      "Val func train loss in epoch 10:2.5565823763608932\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.6741572618484497\n",
      "\n",
      "episode 2, val func loss 1.6732354164123535\n",
      "\n",
      "episode 3, val func loss 3.090378761291504\n",
      "\n",
      "episode 4, val func loss 2.166057825088501\n",
      "\n",
      "episode 5, val func loss 3.2211947441101074\n",
      "\n",
      "episode 6, val func loss 2.0463342666625977\n",
      "\n",
      "episode 7, val func loss 3.6804511547088623\n",
      "\n",
      "episode 8, val func loss 2.2705748081207275\n",
      "\n",
      "episode 9, val func loss 2.901121139526367\n",
      "\n",
      "episode 10, val func loss 2.9209342002868652\n",
      "\n",
      "episode 11, val func loss 2.7140960693359375\n",
      "\n",
      "episode 12, val func loss 3.1495349407196045\n",
      "\n",
      "episode 13, val func loss 2.3457694053649902\n",
      "\n",
      "episode 14, val func loss 1.7114332914352417\n",
      "\n",
      "episode 15, val func loss 2.6497230529785156\n",
      "\n",
      "episode 16, val func loss 2.9472739696502686\n",
      "\n",
      "Val func train loss in epoch 11:2.572641894221306\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 3.2231943607330322\n",
      "\n",
      "episode 2, val func loss 2.173588275909424\n",
      "\n",
      "episode 3, val func loss 2.391136646270752\n",
      "\n",
      "episode 4, val func loss 3.9053776264190674\n",
      "\n",
      "episode 5, val func loss 3.280334949493408\n",
      "\n",
      "episode 6, val func loss 2.7151474952697754\n",
      "\n",
      "episode 7, val func loss 1.7191433906555176\n",
      "\n",
      "episode 8, val func loss 2.8307044506073\n",
      "\n",
      "episode 9, val func loss 2.149768114089966\n",
      "\n",
      "episode 10, val func loss 1.6081278324127197\n",
      "\n",
      "episode 11, val func loss 2.6819844245910645\n",
      "\n",
      "episode 12, val func loss 1.7013287544250488\n",
      "\n",
      "episode 13, val func loss 2.9832663536071777\n",
      "\n",
      "episode 14, val func loss 2.8969779014587402\n",
      "\n",
      "episode 15, val func loss 2.3966946601867676\n",
      "\n",
      "episode 16, val func loss 3.1360998153686523\n",
      "\n",
      "Val func train loss in epoch 12:2.612054690718651\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 2.8988640308380127\n",
      "\n",
      "episode 2, val func loss 1.6944129467010498\n",
      "\n",
      "episode 3, val func loss 1.8881219625473022\n",
      "\n",
      "episode 4, val func loss 2.8101892471313477\n",
      "\n",
      "episode 5, val func loss 2.591730833053589\n",
      "\n",
      "episode 6, val func loss 2.1984007358551025\n",
      "\n",
      "episode 7, val func loss 2.305082082748413\n",
      "\n",
      "episode 8, val func loss 2.4446158409118652\n",
      "\n",
      "episode 9, val func loss 3.0704421997070312\n",
      "\n",
      "episode 10, val func loss 2.6442925930023193\n",
      "\n",
      "episode 11, val func loss 1.6325229406356812\n",
      "\n",
      "episode 12, val func loss 2.9866714477539062\n",
      "\n",
      "episode 13, val func loss 3.8956518173217773\n",
      "\n",
      "episode 14, val func loss 1.7004690170288086\n",
      "\n",
      "episode 15, val func loss 3.434558391571045\n",
      "\n",
      "episode 16, val func loss 3.4275200366973877\n",
      "\n",
      "Val func train loss in epoch 13:2.60147163271904\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.3618111610412598\n",
      "\n",
      "episode 2, val func loss 2.9672834873199463\n",
      "\n",
      "episode 3, val func loss 1.8331451416015625\n",
      "\n",
      "episode 4, val func loss 3.177870988845825\n",
      "\n",
      "episode 5, val func loss 1.8928701877593994\n",
      "\n",
      "episode 6, val func loss 2.6620781421661377\n",
      "\n",
      "episode 7, val func loss 2.5750160217285156\n",
      "\n",
      "episode 8, val func loss 4.388949394226074\n",
      "\n",
      "episode 9, val func loss 2.679651975631714\n",
      "\n",
      "episode 10, val func loss 2.836717367172241\n",
      "\n",
      "episode 11, val func loss 3.850423812866211\n",
      "\n",
      "episode 12, val func loss 3.0505259037017822\n",
      "\n",
      "episode 13, val func loss 2.1967694759368896\n",
      "\n",
      "episode 14, val func loss 3.204110860824585\n",
      "\n",
      "episode 15, val func loss 1.6443710327148438\n",
      "\n",
      "episode 16, val func loss 3.085576057434082\n",
      "\n",
      "Val func train loss in epoch 14:2.775448188185692\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.5471439361572266\n",
      "\n",
      "episode 2, val func loss 3.0989928245544434\n",
      "\n",
      "episode 3, val func loss 2.6544601917266846\n",
      "\n",
      "episode 4, val func loss 2.7261815071105957\n",
      "\n",
      "episode 5, val func loss 1.6494492292404175\n",
      "\n",
      "episode 6, val func loss 2.915271282196045\n",
      "\n",
      "episode 7, val func loss 3.156801462173462\n",
      "\n",
      "episode 8, val func loss 2.076942205429077\n",
      "\n",
      "episode 9, val func loss 3.272695302963257\n",
      "\n",
      "episode 10, val func loss 1.6446609497070312\n",
      "\n",
      "episode 11, val func loss 2.3236382007598877\n",
      "\n",
      "episode 12, val func loss 1.6918116807937622\n",
      "\n",
      "episode 13, val func loss 3.205000638961792\n",
      "\n",
      "episode 14, val func loss 3.0588037967681885\n",
      "\n",
      "episode 15, val func loss 3.6491799354553223\n",
      "\n",
      "episode 16, val func loss 2.2293002605438232\n",
      "\n",
      "Val func train loss in epoch 15:2.6187708377838135\n",
      "***********************TIME WAS 5.152808753649394 min*****************************\n",
      "\n",
      "**********************ROUND 4 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.8098073601722717\n",
      "\n",
      "episode 2, policy loss -0.8590036034584045\n",
      "\n",
      "episode 3, policy loss -0.9260513782501221\n",
      "\n",
      "episode 4, policy loss -0.9455763697624207\n",
      "\n",
      "episode 5, policy loss -0.512582540512085\n",
      "\n",
      "episode 6, policy loss -0.7444273233413696\n",
      "\n",
      "episode 7, policy loss -0.7529822587966919\n",
      "\n",
      "episode 8, policy loss -0.6322400569915771\n",
      "\n",
      "episode 9, policy loss -0.7068557143211365\n",
      "\n",
      "episode 10, policy loss -0.5177810192108154\n",
      "\n",
      "episode 11, policy loss -0.25969627499580383\n",
      "\n",
      "episode 12, policy loss -0.40504971146583557\n",
      "\n",
      "episode 13, policy loss -0.6128050684928894\n",
      "\n",
      "episode 14, policy loss -0.21507064998149872\n",
      "\n",
      "episode 15, policy loss -0.8712497353553772\n",
      "\n",
      "episode 16, policy loss -0.5083472728729248\n",
      "\n",
      "Policy train loss in epoch 0:-0.6424703961238265\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.9078758955001831\n",
      "\n",
      "episode 2, policy loss -0.21466854214668274\n",
      "\n",
      "episode 3, policy loss -0.6121575832366943\n",
      "\n",
      "episode 4, policy loss -0.6288217306137085\n",
      "\n",
      "episode 5, policy loss -0.40408480167388916\n",
      "\n",
      "episode 6, policy loss -0.5159435868263245\n",
      "\n",
      "episode 7, policy loss -0.8707921504974365\n",
      "\n",
      "episode 8, policy loss -0.7477579116821289\n",
      "\n",
      "episode 9, policy loss -0.7042825222015381\n",
      "\n",
      "episode 10, policy loss -0.8048979043960571\n",
      "\n",
      "episode 11, policy loss -0.7365657687187195\n",
      "\n",
      "episode 12, policy loss -0.925542950630188\n",
      "\n",
      "episode 13, policy loss -0.8925769329071045\n",
      "\n",
      "episode 14, policy loss -0.5079241991043091\n",
      "\n",
      "episode 15, policy loss -0.5003345012664795\n",
      "\n",
      "episode 16, policy loss -0.25827664136886597\n",
      "\n",
      "Policy train loss in epoch 1:-0.6395314764231443\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.5158525705337524\n",
      "\n",
      "episode 2, policy loss -0.6286466121673584\n",
      "\n",
      "episode 3, policy loss -0.7042460441589355\n",
      "\n",
      "episode 4, policy loss -0.5003486275672913\n",
      "\n",
      "episode 5, policy loss -0.8925715684890747\n",
      "\n",
      "episode 6, policy loss -0.8707265853881836\n",
      "\n",
      "episode 7, policy loss -0.25829580426216125\n",
      "\n",
      "episode 8, policy loss -0.8048931360244751\n",
      "\n",
      "episode 9, policy loss -0.9075602293014526\n",
      "\n",
      "episode 10, policy loss -0.6119707226753235\n",
      "\n",
      "episode 11, policy loss -0.7365925908088684\n",
      "\n",
      "episode 12, policy loss -0.21445505321025848\n",
      "\n",
      "episode 13, policy loss -0.9255849123001099\n",
      "\n",
      "episode 14, policy loss -0.7477745413780212\n",
      "\n",
      "episode 15, policy loss -0.5080026388168335\n",
      "\n",
      "episode 16, policy loss -0.4040463864803314\n",
      "\n",
      "Policy train loss in epoch 2:-0.639473001472652\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.5004457831382751\n",
      "\n",
      "episode 2, policy loss -0.8049913048744202\n",
      "\n",
      "episode 3, policy loss -0.404092013835907\n",
      "\n",
      "episode 4, policy loss -0.7044008374214172\n",
      "\n",
      "episode 5, policy loss -0.9256983399391174\n",
      "\n",
      "episode 6, policy loss -0.6288318634033203\n",
      "\n",
      "episode 7, policy loss -0.5160484313964844\n",
      "\n",
      "episode 8, policy loss -0.6121665239334106\n",
      "\n",
      "episode 9, policy loss -0.5081851482391357\n",
      "\n",
      "episode 10, policy loss -0.7367982268333435\n",
      "\n",
      "episode 11, policy loss -0.8710150718688965\n",
      "\n",
      "episode 12, policy loss -0.2586030662059784\n",
      "\n",
      "episode 13, policy loss -0.9079076647758484\n",
      "\n",
      "episode 14, policy loss -0.7480932474136353\n",
      "\n",
      "episode 15, policy loss -0.21484336256980896\n",
      "\n",
      "episode 16, policy loss -0.8930419087409973\n",
      "\n",
      "Policy train loss in epoch 3:-0.6396976746618748\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 3.9086389541625977\n",
      "\n",
      "episode 2, val func loss 4.232451438903809\n",
      "\n",
      "episode 3, val func loss 3.696613311767578\n",
      "\n",
      "episode 4, val func loss 3.900200366973877\n",
      "\n",
      "episode 5, val func loss 3.002166509628296\n",
      "\n",
      "episode 6, val func loss 3.670511484146118\n",
      "\n",
      "episode 7, val func loss 3.015615701675415\n",
      "\n",
      "episode 8, val func loss 2.3257715702056885\n",
      "\n",
      "episode 9, val func loss 3.2410600185394287\n",
      "\n",
      "episode 10, val func loss 4.29887056350708\n",
      "\n",
      "episode 11, val func loss 3.1622331142425537\n",
      "\n",
      "episode 12, val func loss 4.518207550048828\n",
      "\n",
      "episode 13, val func loss 4.493963718414307\n",
      "\n",
      "episode 14, val func loss 2.443821907043457\n",
      "\n",
      "episode 15, val func loss 3.0462796688079834\n",
      "\n",
      "episode 16, val func loss 4.646719932556152\n",
      "\n",
      "Val func train loss in epoch 0:3.600195363163948\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 3.1841278076171875\n",
      "\n",
      "episode 2, val func loss 3.3469736576080322\n",
      "\n",
      "episode 3, val func loss 3.8070459365844727\n",
      "\n",
      "episode 4, val func loss 3.019575357437134\n",
      "\n",
      "episode 5, val func loss 3.8579490184783936\n",
      "\n",
      "episode 6, val func loss 3.8881120681762695\n",
      "\n",
      "episode 7, val func loss 4.521931171417236\n",
      "\n",
      "episode 8, val func loss 4.813416957855225\n",
      "\n",
      "episode 9, val func loss 4.497574806213379\n",
      "\n",
      "episode 10, val func loss 4.215444087982178\n",
      "\n",
      "episode 11, val func loss 4.798032283782959\n",
      "\n",
      "episode 12, val func loss 3.1005334854125977\n",
      "\n",
      "episode 13, val func loss 5.7041120529174805\n",
      "\n",
      "episode 14, val func loss 2.3814797401428223\n",
      "\n",
      "episode 15, val func loss 4.681447505950928\n",
      "\n",
      "episode 16, val func loss 2.6331329345703125\n",
      "\n",
      "Val func train loss in epoch 1:3.903180554509163\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.217771053314209\n",
      "\n",
      "episode 2, val func loss 4.241258144378662\n",
      "\n",
      "episode 3, val func loss 3.281824827194214\n",
      "\n",
      "episode 4, val func loss 4.906546115875244\n",
      "\n",
      "episode 5, val func loss 3.687784433364868\n",
      "\n",
      "episode 6, val func loss 3.3790433406829834\n",
      "\n",
      "episode 7, val func loss 3.772862434387207\n",
      "\n",
      "episode 8, val func loss 2.851119041442871\n",
      "\n",
      "episode 9, val func loss 3.8032166957855225\n",
      "\n",
      "episode 10, val func loss 3.7959253787994385\n",
      "\n",
      "episode 11, val func loss 3.0946543216705322\n",
      "\n",
      "episode 12, val func loss 4.628576755523682\n",
      "\n",
      "episode 13, val func loss 4.239835262298584\n",
      "\n",
      "episode 14, val func loss 2.5569167137145996\n",
      "\n",
      "episode 15, val func loss 4.974257946014404\n",
      "\n",
      "episode 16, val func loss 2.9743871688842773\n",
      "\n",
      "Val func train loss in epoch 2:3.650373727083206\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 5.377447605133057\n",
      "\n",
      "episode 2, val func loss 3.028650999069214\n",
      "\n",
      "episode 3, val func loss 3.6543726921081543\n",
      "\n",
      "episode 4, val func loss 3.021092414855957\n",
      "\n",
      "episode 5, val func loss 4.934544563293457\n",
      "\n",
      "episode 6, val func loss 4.28706169128418\n",
      "\n",
      "episode 7, val func loss 3.8967063426971436\n",
      "\n",
      "episode 8, val func loss 3.146791696548462\n",
      "\n",
      "episode 9, val func loss 4.55701208114624\n",
      "\n",
      "episode 10, val func loss 2.455029010772705\n",
      "\n",
      "episode 11, val func loss 4.312636852264404\n",
      "\n",
      "episode 12, val func loss 2.386413812637329\n",
      "\n",
      "episode 13, val func loss 3.769625425338745\n",
      "\n",
      "episode 14, val func loss 3.4325859546661377\n",
      "\n",
      "episode 15, val func loss 3.604337692260742\n",
      "\n",
      "episode 16, val func loss 3.1288058757781982\n",
      "\n",
      "Val func train loss in epoch 3:3.687069669365883\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 4.587976932525635\n",
      "\n",
      "episode 2, val func loss 2.6530263423919678\n",
      "\n",
      "episode 3, val func loss 2.2877554893493652\n",
      "\n",
      "episode 4, val func loss 4.947904109954834\n",
      "\n",
      "episode 5, val func loss 4.1701884269714355\n",
      "\n",
      "episode 6, val func loss 4.300608158111572\n",
      "\n",
      "episode 7, val func loss 5.806708335876465\n",
      "\n",
      "episode 8, val func loss 3.124129056930542\n",
      "\n",
      "episode 9, val func loss 3.029733896255493\n",
      "\n",
      "episode 10, val func loss 3.258525848388672\n",
      "\n",
      "episode 11, val func loss 4.012958526611328\n",
      "\n",
      "episode 12, val func loss 3.1547958850860596\n",
      "\n",
      "episode 13, val func loss 4.782171726226807\n",
      "\n",
      "episode 14, val func loss 4.499569892883301\n",
      "\n",
      "episode 15, val func loss 2.836916446685791\n",
      "\n",
      "episode 16, val func loss 3.6875710487365723\n",
      "\n",
      "Val func train loss in epoch 4:3.821283757686615\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 3.5984554290771484\n",
      "\n",
      "episode 2, val func loss 3.108595132827759\n",
      "\n",
      "episode 3, val func loss 2.8186118602752686\n",
      "\n",
      "episode 4, val func loss 4.79019021987915\n",
      "\n",
      "episode 5, val func loss 3.140397787094116\n",
      "\n",
      "episode 6, val func loss 2.2474005222320557\n",
      "\n",
      "episode 7, val func loss 2.246450424194336\n",
      "\n",
      "episode 8, val func loss 3.9483423233032227\n",
      "\n",
      "episode 9, val func loss 4.7329511642456055\n",
      "\n",
      "episode 10, val func loss 3.681896448135376\n",
      "\n",
      "episode 11, val func loss 4.8724365234375\n",
      "\n",
      "episode 12, val func loss 3.7925899028778076\n",
      "\n",
      "episode 13, val func loss 3.0134987831115723\n",
      "\n",
      "episode 14, val func loss 4.486103534698486\n",
      "\n",
      "episode 15, val func loss 3.8852200508117676\n",
      "\n",
      "episode 16, val func loss 4.5130720138549805\n",
      "\n",
      "Val func train loss in epoch 5:3.6797632575035095\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 4.3102335929870605\n",
      "\n",
      "episode 2, val func loss 3.7036523818969727\n",
      "\n",
      "episode 3, val func loss 2.8295507431030273\n",
      "\n",
      "episode 4, val func loss 4.234551429748535\n",
      "\n",
      "episode 5, val func loss 3.0127475261688232\n",
      "\n",
      "episode 6, val func loss 3.923356056213379\n",
      "\n",
      "episode 7, val func loss 3.469193935394287\n",
      "\n",
      "episode 8, val func loss 3.0409750938415527\n",
      "\n",
      "episode 9, val func loss 3.35483717918396\n",
      "\n",
      "episode 10, val func loss 4.325944423675537\n",
      "\n",
      "episode 11, val func loss 3.5051422119140625\n",
      "\n",
      "episode 12, val func loss 3.0024006366729736\n",
      "\n",
      "episode 13, val func loss 4.655871391296387\n",
      "\n",
      "episode 14, val func loss 2.9803414344787598\n",
      "\n",
      "episode 15, val func loss 4.529949188232422\n",
      "\n",
      "episode 16, val func loss 2.302074909210205\n",
      "\n",
      "Val func train loss in epoch 6:3.5738013833761215\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 3.4229750633239746\n",
      "\n",
      "episode 2, val func loss 2.818319320678711\n",
      "\n",
      "episode 3, val func loss 4.276587963104248\n",
      "\n",
      "episode 4, val func loss 2.3083596229553223\n",
      "\n",
      "episode 5, val func loss 3.134244680404663\n",
      "\n",
      "episode 6, val func loss 2.9723961353302\n",
      "\n",
      "episode 7, val func loss 3.5731918811798096\n",
      "\n",
      "episode 8, val func loss 2.3994741439819336\n",
      "\n",
      "episode 9, val func loss 3.6399667263031006\n",
      "\n",
      "episode 10, val func loss 3.680363893508911\n",
      "\n",
      "episode 11, val func loss 3.0103769302368164\n",
      "\n",
      "episode 12, val func loss 4.269405364990234\n",
      "\n",
      "episode 13, val func loss 3.1705026626586914\n",
      "\n",
      "episode 14, val func loss 4.510983943939209\n",
      "\n",
      "episode 15, val func loss 4.590489387512207\n",
      "\n",
      "episode 16, val func loss 4.282271862030029\n",
      "\n",
      "Val func train loss in epoch 7:3.503744348883629\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 3.189239263534546\n",
      "\n",
      "episode 2, val func loss 2.8568708896636963\n",
      "\n",
      "episode 3, val func loss 3.510910987854004\n",
      "\n",
      "episode 4, val func loss 3.6896727085113525\n",
      "\n",
      "episode 5, val func loss 2.2356836795806885\n",
      "\n",
      "episode 6, val func loss 3.064382553100586\n",
      "\n",
      "episode 7, val func loss 2.8581881523132324\n",
      "\n",
      "episode 8, val func loss 4.192847728729248\n",
      "\n",
      "episode 9, val func loss 3.1322195529937744\n",
      "\n",
      "episode 10, val func loss 4.646845817565918\n",
      "\n",
      "episode 11, val func loss 4.516871929168701\n",
      "\n",
      "episode 12, val func loss 3.870130777359009\n",
      "\n",
      "episode 13, val func loss 2.956162929534912\n",
      "\n",
      "episode 14, val func loss 4.2564005851745605\n",
      "\n",
      "episode 15, val func loss 3.479036569595337\n",
      "\n",
      "episode 16, val func loss 4.337916851043701\n",
      "\n",
      "Val func train loss in epoch 8:3.549586310982704\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 4.5244975090026855\n",
      "\n",
      "episode 2, val func loss 4.363324165344238\n",
      "\n",
      "episode 3, val func loss 2.976597785949707\n",
      "\n",
      "episode 4, val func loss 3.1427645683288574\n",
      "\n",
      "episode 5, val func loss 4.241252899169922\n",
      "\n",
      "episode 6, val func loss 3.6851654052734375\n",
      "\n",
      "episode 7, val func loss 3.5224199295043945\n",
      "\n",
      "episode 8, val func loss 2.8253657817840576\n",
      "\n",
      "episode 9, val func loss 2.2838327884674072\n",
      "\n",
      "episode 10, val func loss 4.529296875\n",
      "\n",
      "episode 11, val func loss 2.9658193588256836\n",
      "\n",
      "episode 12, val func loss 3.4359798431396484\n",
      "\n",
      "episode 13, val func loss 3.554838180541992\n",
      "\n",
      "episode 14, val func loss 4.264431476593018\n",
      "\n",
      "episode 15, val func loss 2.466496467590332\n",
      "\n",
      "episode 16, val func loss 3.2393507957458496\n",
      "\n",
      "Val func train loss in epoch 9:3.501339614391327\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 4.536317825317383\n",
      "\n",
      "episode 2, val func loss 2.8264362812042236\n",
      "\n",
      "episode 3, val func loss 4.525390148162842\n",
      "\n",
      "episode 4, val func loss 3.107743978500366\n",
      "\n",
      "episode 5, val func loss 3.5591351985931396\n",
      "\n",
      "episode 6, val func loss 4.6215105056762695\n",
      "\n",
      "episode 7, val func loss 2.2542505264282227\n",
      "\n",
      "episode 8, val func loss 3.1322762966156006\n",
      "\n",
      "episode 9, val func loss 3.5489070415496826\n",
      "\n",
      "episode 10, val func loss 3.1409149169921875\n",
      "\n",
      "episode 11, val func loss 4.5227580070495605\n",
      "\n",
      "episode 12, val func loss 4.429475784301758\n",
      "\n",
      "episode 13, val func loss 3.422837018966675\n",
      "\n",
      "episode 14, val func loss 3.7817256450653076\n",
      "\n",
      "episode 15, val func loss 3.081298589706421\n",
      "\n",
      "episode 16, val func loss 2.4030673503875732\n",
      "\n",
      "Val func train loss in epoch 10:3.5558778196573257\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 3.391988515853882\n",
      "\n",
      "episode 2, val func loss 3.688948392868042\n",
      "\n",
      "episode 3, val func loss 3.5300912857055664\n",
      "\n",
      "episode 4, val func loss 3.602754831314087\n",
      "\n",
      "episode 5, val func loss 3.7938668727874756\n",
      "\n",
      "episode 6, val func loss 2.3209242820739746\n",
      "\n",
      "episode 7, val func loss 5.330021381378174\n",
      "\n",
      "episode 8, val func loss 4.691565036773682\n",
      "\n",
      "episode 9, val func loss 4.4638471603393555\n",
      "\n",
      "episode 10, val func loss 4.937070369720459\n",
      "\n",
      "episode 11, val func loss 2.9853546619415283\n",
      "\n",
      "episode 12, val func loss 3.124241352081299\n",
      "\n",
      "episode 13, val func loss 4.00841760635376\n",
      "\n",
      "episode 14, val func loss 2.2656195163726807\n",
      "\n",
      "episode 15, val func loss 3.025114059448242\n",
      "\n",
      "episode 16, val func loss 4.528472900390625\n",
      "\n",
      "Val func train loss in epoch 11:3.730518639087677\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 3.209453582763672\n",
      "\n",
      "episode 2, val func loss 3.642292022705078\n",
      "\n",
      "episode 3, val func loss 3.169121265411377\n",
      "\n",
      "episode 4, val func loss 2.2457046508789062\n",
      "\n",
      "episode 5, val func loss 3.0289599895477295\n",
      "\n",
      "episode 6, val func loss 4.488745212554932\n",
      "\n",
      "episode 7, val func loss 3.5507752895355225\n",
      "\n",
      "episode 8, val func loss 4.410495758056641\n",
      "\n",
      "episode 9, val func loss 4.594971656799316\n",
      "\n",
      "episode 10, val func loss 2.862513780593872\n",
      "\n",
      "episode 11, val func loss 3.6620864868164062\n",
      "\n",
      "episode 12, val func loss 2.2411136627197266\n",
      "\n",
      "episode 13, val func loss 3.672974109649658\n",
      "\n",
      "episode 14, val func loss 4.235035419464111\n",
      "\n",
      "episode 15, val func loss 3.1125595569610596\n",
      "\n",
      "episode 16, val func loss 4.302908420562744\n",
      "\n",
      "Val func train loss in epoch 12:3.526856929063797\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 4.236349582672119\n",
      "\n",
      "episode 2, val func loss 2.861548662185669\n",
      "\n",
      "episode 3, val func loss 2.249039888381958\n",
      "\n",
      "episode 4, val func loss 4.711081504821777\n",
      "\n",
      "episode 5, val func loss 3.659545660018921\n",
      "\n",
      "episode 6, val func loss 3.1399576663970947\n",
      "\n",
      "episode 7, val func loss 4.886383533477783\n",
      "\n",
      "episode 8, val func loss 3.0249719619750977\n",
      "\n",
      "episode 9, val func loss 4.509006023406982\n",
      "\n",
      "episode 10, val func loss 3.285459518432617\n",
      "\n",
      "episode 11, val func loss 3.5690059661865234\n",
      "\n",
      "episode 12, val func loss 4.692179203033447\n",
      "\n",
      "episode 13, val func loss 2.4593751430511475\n",
      "\n",
      "episode 14, val func loss 3.103081226348877\n",
      "\n",
      "episode 15, val func loss 3.558516263961792\n",
      "\n",
      "episode 16, val func loss 3.9282586574554443\n",
      "\n",
      "Val func train loss in epoch 13:3.617110028862953\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 4.296898365020752\n",
      "\n",
      "episode 2, val func loss 4.56714391708374\n",
      "\n",
      "episode 3, val func loss 2.4562859535217285\n",
      "\n",
      "episode 4, val func loss 4.603749752044678\n",
      "\n",
      "episode 5, val func loss 3.05973482131958\n",
      "\n",
      "episode 6, val func loss 2.9807913303375244\n",
      "\n",
      "episode 7, val func loss 3.2866787910461426\n",
      "\n",
      "episode 8, val func loss 3.0000784397125244\n",
      "\n",
      "episode 9, val func loss 3.5050408840179443\n",
      "\n",
      "episode 10, val func loss 3.6439874172210693\n",
      "\n",
      "episode 11, val func loss 3.660186290740967\n",
      "\n",
      "episode 12, val func loss 2.8412845134735107\n",
      "\n",
      "episode 13, val func loss 4.289323806762695\n",
      "\n",
      "episode 14, val func loss 4.325049877166748\n",
      "\n",
      "episode 15, val func loss 2.394196033477783\n",
      "\n",
      "episode 16, val func loss 3.6418936252593994\n",
      "\n",
      "Val func train loss in epoch 14:3.534520238637924\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 3.124924659729004\n",
      "\n",
      "episode 2, val func loss 2.367171049118042\n",
      "\n",
      "episode 3, val func loss 2.9721364974975586\n",
      "\n",
      "episode 4, val func loss 4.717070579528809\n",
      "\n",
      "episode 5, val func loss 3.4623520374298096\n",
      "\n",
      "episode 6, val func loss 3.516387939453125\n",
      "\n",
      "episode 7, val func loss 2.550874948501587\n",
      "\n",
      "episode 8, val func loss 4.779774188995361\n",
      "\n",
      "episode 9, val func loss 3.057605743408203\n",
      "\n",
      "episode 10, val func loss 3.9062161445617676\n",
      "\n",
      "episode 11, val func loss 2.9926552772521973\n",
      "\n",
      "episode 12, val func loss 4.2812886238098145\n",
      "\n",
      "episode 13, val func loss 4.34902811050415\n",
      "\n",
      "episode 14, val func loss 3.206726551055908\n",
      "\n",
      "episode 15, val func loss 3.569636821746826\n",
      "\n",
      "episode 16, val func loss 4.2255048751831055\n",
      "\n",
      "Val func train loss in epoch 15:3.5674596279859543\n",
      "***********************TIME WAS 5.152678461869558 min*****************************\n",
      "\n",
      "**********************ROUND 5 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.83373761177063\n",
      "\n",
      "episode 2, policy loss -2.746006965637207\n",
      "\n",
      "episode 3, policy loss -2.8347206115722656\n",
      "\n",
      "episode 4, policy loss -2.8355660438537598\n",
      "\n",
      "episode 5, policy loss -2.8089988231658936\n",
      "\n",
      "episode 6, policy loss -2.782491683959961\n",
      "\n",
      "episode 7, policy loss -2.8375232219696045\n",
      "\n",
      "episode 8, policy loss -2.837881088256836\n",
      "\n",
      "episode 9, policy loss -2.8115737438201904\n",
      "\n",
      "episode 10, policy loss -2.8384690284729004\n",
      "\n",
      "episode 11, policy loss -2.8386573791503906\n",
      "\n",
      "episode 12, policy loss -2.8118999004364014\n",
      "\n",
      "episode 13, policy loss -2.811821460723877\n",
      "\n",
      "episode 14, policy loss -2.8390462398529053\n",
      "\n",
      "episode 15, policy loss -2.8391077518463135\n",
      "\n",
      "episode 16, policy loss -2.8391878604888916\n",
      "\n",
      "Policy train loss in epoch 0:-2.8216680884361267\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.839221954345703\n",
      "\n",
      "episode 2, policy loss -2.839278221130371\n",
      "\n",
      "episode 3, policy loss -2.8126471042633057\n",
      "\n",
      "episode 4, policy loss -2.839341163635254\n",
      "\n",
      "episode 5, policy loss -2.8393666744232178\n",
      "\n",
      "episode 6, policy loss -2.839395761489868\n",
      "\n",
      "episode 7, policy loss -2.754624605178833\n",
      "\n",
      "episode 8, policy loss -2.839428663253784\n",
      "\n",
      "episode 9, policy loss -2.811998128890991\n",
      "\n",
      "episode 10, policy loss -2.839454412460327\n",
      "\n",
      "episode 11, policy loss -2.7849087715148926\n",
      "\n",
      "episode 12, policy loss -2.8123626708984375\n",
      "\n",
      "episode 13, policy loss -2.8125662803649902\n",
      "\n",
      "episode 14, policy loss -2.8394973278045654\n",
      "\n",
      "episode 15, policy loss -2.839503288269043\n",
      "\n",
      "episode 16, policy loss -2.8395097255706787\n",
      "\n",
      "Policy train loss in epoch 1:-2.8239440470933914\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.83951473236084\n",
      "\n",
      "episode 2, policy loss -2.8120758533477783\n",
      "\n",
      "episode 3, policy loss -2.839526414871216\n",
      "\n",
      "episode 4, policy loss -2.839527130126953\n",
      "\n",
      "episode 5, policy loss -2.8395347595214844\n",
      "\n",
      "episode 6, policy loss -2.83954119682312\n",
      "\n",
      "episode 7, policy loss -2.812617301940918\n",
      "\n",
      "episode 8, policy loss -2.812877655029297\n",
      "\n",
      "episode 9, policy loss -2.812427043914795\n",
      "\n",
      "episode 10, policy loss -2.8395514488220215\n",
      "\n",
      "episode 11, policy loss -2.754757881164551\n",
      "\n",
      "episode 12, policy loss -2.8395557403564453\n",
      "\n",
      "episode 13, policy loss -2.8395590782165527\n",
      "\n",
      "episode 14, policy loss -2.8395581245422363\n",
      "\n",
      "episode 15, policy loss -2.785000801086426\n",
      "\n",
      "episode 16, policy loss -2.8395681381225586\n",
      "\n",
      "Policy train loss in epoch 2:-2.8240745812654495\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.812638521194458\n",
      "\n",
      "episode 2, policy loss -2.839567184448242\n",
      "\n",
      "episode 3, policy loss -2.8121252059936523\n",
      "\n",
      "episode 4, policy loss -2.8395700454711914\n",
      "\n",
      "episode 5, policy loss -2.8124523162841797\n",
      "\n",
      "episode 6, policy loss -2.8395731449127197\n",
      "\n",
      "episode 7, policy loss -2.8395752906799316\n",
      "\n",
      "episode 8, policy loss -2.8129100799560547\n",
      "\n",
      "episode 9, policy loss -2.8395767211914062\n",
      "\n",
      "episode 10, policy loss -2.839576482772827\n",
      "\n",
      "episode 11, policy loss -2.8395798206329346\n",
      "\n",
      "episode 12, policy loss -2.7547852993011475\n",
      "\n",
      "episode 13, policy loss -2.8395824432373047\n",
      "\n",
      "episode 14, policy loss -2.785019874572754\n",
      "\n",
      "episode 15, policy loss -2.839582681655884\n",
      "\n",
      "episode 16, policy loss -2.839585542678833\n",
      "\n",
      "Policy train loss in epoch 3:-2.82410629093647\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 7.6910600662231445\n",
      "\n",
      "episode 2, val func loss 2.572251796722412\n",
      "\n",
      "episode 3, val func loss 7.510848522186279\n",
      "\n",
      "episode 4, val func loss 4.167227745056152\n",
      "\n",
      "episode 5, val func loss 2.66395902633667\n",
      "\n",
      "episode 6, val func loss 5.044097900390625\n",
      "\n",
      "episode 7, val func loss 3.144641399383545\n",
      "\n",
      "episode 8, val func loss 3.2143821716308594\n",
      "\n",
      "episode 9, val func loss 4.0737104415893555\n",
      "\n",
      "episode 10, val func loss 2.367236852645874\n",
      "\n",
      "episode 11, val func loss 3.1700313091278076\n",
      "\n",
      "episode 12, val func loss 3.276900291442871\n",
      "\n",
      "episode 13, val func loss 2.312194585800171\n",
      "\n",
      "episode 14, val func loss 3.139620542526245\n",
      "\n",
      "episode 15, val func loss 2.7318038940429688\n",
      "\n",
      "episode 16, val func loss 2.295182228088379\n",
      "\n",
      "Val func train loss in epoch 0:3.710946798324585\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.688946008682251\n",
      "\n",
      "episode 2, val func loss 2.5934338569641113\n",
      "\n",
      "episode 3, val func loss 2.476848602294922\n",
      "\n",
      "episode 4, val func loss 2.6244912147521973\n",
      "\n",
      "episode 5, val func loss 2.610164165496826\n",
      "\n",
      "episode 6, val func loss 2.306750535964966\n",
      "\n",
      "episode 7, val func loss 2.4957339763641357\n",
      "\n",
      "episode 8, val func loss 2.6603212356567383\n",
      "\n",
      "episode 9, val func loss 2.5885252952575684\n",
      "\n",
      "episode 10, val func loss 2.3922438621520996\n",
      "\n",
      "episode 11, val func loss 2.4513726234436035\n",
      "\n",
      "episode 12, val func loss 2.3475656509399414\n",
      "\n",
      "episode 13, val func loss 2.412533760070801\n",
      "\n",
      "episode 14, val func loss 2.5682027339935303\n",
      "\n",
      "episode 15, val func loss 2.382157325744629\n",
      "\n",
      "episode 16, val func loss 2.4476640224456787\n",
      "\n",
      "Val func train loss in epoch 1:2.502934679389\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.319824457168579\n",
      "\n",
      "episode 2, val func loss 2.4342596530914307\n",
      "\n",
      "episode 3, val func loss 2.4018492698669434\n",
      "\n",
      "episode 4, val func loss 2.400463581085205\n",
      "\n",
      "episode 5, val func loss 2.516862630844116\n",
      "\n",
      "episode 6, val func loss 2.294478178024292\n",
      "\n",
      "episode 7, val func loss 2.3240761756896973\n",
      "\n",
      "episode 8, val func loss 2.371223211288452\n",
      "\n",
      "episode 9, val func loss 2.472397565841675\n",
      "\n",
      "episode 10, val func loss 2.286997079849243\n",
      "\n",
      "episode 11, val func loss 2.2990164756774902\n",
      "\n",
      "episode 12, val func loss 2.4876511096954346\n",
      "\n",
      "episode 13, val func loss 2.57491135597229\n",
      "\n",
      "episode 14, val func loss 2.3286445140838623\n",
      "\n",
      "episode 15, val func loss 2.36533260345459\n",
      "\n",
      "episode 16, val func loss 2.4991040229797363\n",
      "\n",
      "Val func train loss in epoch 2:2.398568242788315\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.3184680938720703\n",
      "\n",
      "episode 2, val func loss 2.382770299911499\n",
      "\n",
      "episode 3, val func loss 2.2992775440216064\n",
      "\n",
      "episode 4, val func loss 2.3204541206359863\n",
      "\n",
      "episode 5, val func loss 2.4824304580688477\n",
      "\n",
      "episode 6, val func loss 2.2826521396636963\n",
      "\n",
      "episode 7, val func loss 2.549839973449707\n",
      "\n",
      "episode 8, val func loss 2.495124101638794\n",
      "\n",
      "episode 9, val func loss 2.379040002822876\n",
      "\n",
      "episode 10, val func loss 2.3804445266723633\n",
      "\n",
      "episode 11, val func loss 2.372321844100952\n",
      "\n",
      "episode 12, val func loss 2.5240695476531982\n",
      "\n",
      "episode 13, val func loss 2.2923102378845215\n",
      "\n",
      "episode 14, val func loss 2.3057706356048584\n",
      "\n",
      "episode 15, val func loss 2.446563720703125\n",
      "\n",
      "episode 16, val func loss 2.390394926071167\n",
      "\n",
      "Val func train loss in epoch 3:2.3888707607984543\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.4812192916870117\n",
      "\n",
      "episode 2, val func loss 2.2966725826263428\n",
      "\n",
      "episode 3, val func loss 2.306868314743042\n",
      "\n",
      "episode 4, val func loss 2.326836585998535\n",
      "\n",
      "episode 5, val func loss 2.369067668914795\n",
      "\n",
      "episode 6, val func loss 2.4163293838500977\n",
      "\n",
      "episode 7, val func loss 2.538304328918457\n",
      "\n",
      "episode 8, val func loss 2.5052783489227295\n",
      "\n",
      "episode 9, val func loss 2.337096929550171\n",
      "\n",
      "episode 10, val func loss 2.386509656906128\n",
      "\n",
      "episode 11, val func loss 2.381615161895752\n",
      "\n",
      "episode 12, val func loss 2.5096800327301025\n",
      "\n",
      "episode 13, val func loss 2.2867720127105713\n",
      "\n",
      "episode 14, val func loss 2.414708137512207\n",
      "\n",
      "episode 15, val func loss 2.559988021850586\n",
      "\n",
      "episode 16, val func loss 2.3276207447052\n",
      "\n",
      "Val func train loss in epoch 4:2.402785450220108\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 2.4078574180603027\n",
      "\n",
      "episode 2, val func loss 2.287294387817383\n",
      "\n",
      "episode 3, val func loss 2.520925760269165\n",
      "\n",
      "episode 4, val func loss 2.5040481090545654\n",
      "\n",
      "episode 5, val func loss 2.324434757232666\n",
      "\n",
      "episode 6, val func loss 2.496422290802002\n",
      "\n",
      "episode 7, val func loss 2.370645523071289\n",
      "\n",
      "episode 8, val func loss 2.3874576091766357\n",
      "\n",
      "episode 9, val func loss 2.2960684299468994\n",
      "\n",
      "episode 10, val func loss 2.4542336463928223\n",
      "\n",
      "episode 11, val func loss 2.5505714416503906\n",
      "\n",
      "episode 12, val func loss 2.3270115852355957\n",
      "\n",
      "episode 13, val func loss 2.3696935176849365\n",
      "\n",
      "episode 14, val func loss 2.300539016723633\n",
      "\n",
      "episode 15, val func loss 2.3968310356140137\n",
      "\n",
      "episode 16, val func loss 2.290966510772705\n",
      "\n",
      "Val func train loss in epoch 5:2.392812564969063\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.380419969558716\n",
      "\n",
      "episode 2, val func loss 2.300598382949829\n",
      "\n",
      "episode 3, val func loss 2.562847137451172\n",
      "\n",
      "episode 4, val func loss 2.4903295040130615\n",
      "\n",
      "episode 5, val func loss 2.387287139892578\n",
      "\n",
      "episode 6, val func loss 2.3784096240997314\n",
      "\n",
      "episode 7, val func loss 2.3862147331237793\n",
      "\n",
      "episode 8, val func loss 2.322099447250366\n",
      "\n",
      "episode 9, val func loss 2.4596943855285645\n",
      "\n",
      "episode 10, val func loss 2.3126399517059326\n",
      "\n",
      "episode 11, val func loss 2.510439872741699\n",
      "\n",
      "episode 12, val func loss 2.309093713760376\n",
      "\n",
      "episode 13, val func loss 2.518460512161255\n",
      "\n",
      "episode 14, val func loss 2.3181874752044678\n",
      "\n",
      "episode 15, val func loss 2.3241803646087646\n",
      "\n",
      "episode 16, val func loss 2.409038782119751\n",
      "\n",
      "Val func train loss in epoch 6:2.3981213122606277\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 2.341081142425537\n",
      "\n",
      "episode 2, val func loss 2.472991943359375\n",
      "\n",
      "episode 3, val func loss 2.4570302963256836\n",
      "\n",
      "episode 4, val func loss 2.5424375534057617\n",
      "\n",
      "episode 5, val func loss 2.4135611057281494\n",
      "\n",
      "episode 6, val func loss 2.315098524093628\n",
      "\n",
      "episode 7, val func loss 2.316866636276245\n",
      "\n",
      "episode 8, val func loss 2.2896862030029297\n",
      "\n",
      "episode 9, val func loss 2.3891420364379883\n",
      "\n",
      "episode 10, val func loss 2.378394365310669\n",
      "\n",
      "episode 11, val func loss 2.2961626052856445\n",
      "\n",
      "episode 12, val func loss 2.4936225414276123\n",
      "\n",
      "episode 13, val func loss 2.369290351867676\n",
      "\n",
      "episode 14, val func loss 2.326819896697998\n",
      "\n",
      "episode 15, val func loss 2.4730095863342285\n",
      "\n",
      "episode 16, val func loss 2.5650265216827393\n",
      "\n",
      "Val func train loss in epoch 7:2.4025138318538666\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.3756966590881348\n",
      "\n",
      "episode 2, val func loss 2.336554527282715\n",
      "\n",
      "episode 3, val func loss 2.3973443508148193\n",
      "\n",
      "episode 4, val func loss 2.296365261077881\n",
      "\n",
      "episode 5, val func loss 2.3249783515930176\n",
      "\n",
      "episode 6, val func loss 2.529982566833496\n",
      "\n",
      "episode 7, val func loss 2.3052005767822266\n",
      "\n",
      "episode 8, val func loss 2.3023488521575928\n",
      "\n",
      "episode 9, val func loss 2.56853985786438\n",
      "\n",
      "episode 10, val func loss 2.376094102859497\n",
      "\n",
      "episode 11, val func loss 2.2944693565368652\n",
      "\n",
      "episode 12, val func loss 2.50412917137146\n",
      "\n",
      "episode 13, val func loss 2.4792230129241943\n",
      "\n",
      "episode 14, val func loss 2.371371030807495\n",
      "\n",
      "episode 15, val func loss 2.451442241668701\n",
      "\n",
      "episode 16, val func loss 2.3879427909851074\n",
      "\n",
      "Val func train loss in epoch 8:2.393855169415474\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 2.458902597427368\n",
      "\n",
      "episode 2, val func loss 2.3962395191192627\n",
      "\n",
      "episode 3, val func loss 2.5581579208374023\n",
      "\n",
      "episode 4, val func loss 2.383507490158081\n",
      "\n",
      "episode 5, val func loss 2.4851036071777344\n",
      "\n",
      "episode 6, val func loss 2.315424680709839\n",
      "\n",
      "episode 7, val func loss 2.2980597019195557\n",
      "\n",
      "episode 8, val func loss 2.481670618057251\n",
      "\n",
      "episode 9, val func loss 2.2972867488861084\n",
      "\n",
      "episode 10, val func loss 2.4102797508239746\n",
      "\n",
      "episode 11, val func loss 2.3069448471069336\n",
      "\n",
      "episode 12, val func loss 2.511767864227295\n",
      "\n",
      "episode 13, val func loss 2.374319314956665\n",
      "\n",
      "episode 14, val func loss 2.378835678100586\n",
      "\n",
      "episode 15, val func loss 2.328674793243408\n",
      "\n",
      "episode 16, val func loss 2.448289632797241\n",
      "\n",
      "Val func train loss in epoch 9:2.402091547846794\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.487035036087036\n",
      "\n",
      "episode 2, val func loss 2.5234947204589844\n",
      "\n",
      "episode 3, val func loss 2.4190192222595215\n",
      "\n",
      "episode 4, val func loss 2.2895195484161377\n",
      "\n",
      "episode 5, val func loss 2.312500476837158\n",
      "\n",
      "episode 6, val func loss 2.388932704925537\n",
      "\n",
      "episode 7, val func loss 2.302225112915039\n",
      "\n",
      "episode 8, val func loss 2.535338878631592\n",
      "\n",
      "episode 9, val func loss 2.463073492050171\n",
      "\n",
      "episode 10, val func loss 2.484795570373535\n",
      "\n",
      "episode 11, val func loss 2.377190351486206\n",
      "\n",
      "episode 12, val func loss 2.3422343730926514\n",
      "\n",
      "episode 13, val func loss 2.5858118534088135\n",
      "\n",
      "episode 14, val func loss 2.294724702835083\n",
      "\n",
      "episode 15, val func loss 2.403480052947998\n",
      "\n",
      "episode 16, val func loss 2.3389947414398193\n",
      "\n",
      "Val func train loss in epoch 10:2.40927317738533\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 2.391091823577881\n",
      "\n",
      "episode 2, val func loss 2.42885160446167\n",
      "\n",
      "episode 3, val func loss 2.504323720932007\n",
      "\n",
      "episode 4, val func loss 2.519731044769287\n",
      "\n",
      "episode 5, val func loss 2.368273973464966\n",
      "\n",
      "episode 6, val func loss 2.518951892852783\n",
      "\n",
      "episode 7, val func loss 2.4893808364868164\n",
      "\n",
      "episode 8, val func loss 2.6473441123962402\n",
      "\n",
      "episode 9, val func loss 2.3737435340881348\n",
      "\n",
      "episode 10, val func loss 2.487689733505249\n",
      "\n",
      "episode 11, val func loss 2.2983176708221436\n",
      "\n",
      "episode 12, val func loss 2.504697322845459\n",
      "\n",
      "episode 13, val func loss 2.4104886054992676\n",
      "\n",
      "episode 14, val func loss 2.3166682720184326\n",
      "\n",
      "episode 15, val func loss 2.431393623352051\n",
      "\n",
      "episode 16, val func loss 2.291313648223877\n",
      "\n",
      "Val func train loss in epoch 11:2.4363913387060165\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 2.427598714828491\n",
      "\n",
      "episode 2, val func loss 2.2848236560821533\n",
      "\n",
      "episode 3, val func loss 2.567265033721924\n",
      "\n",
      "episode 4, val func loss 2.304946184158325\n",
      "\n",
      "episode 5, val func loss 2.4083995819091797\n",
      "\n",
      "episode 6, val func loss 2.2963809967041016\n",
      "\n",
      "episode 7, val func loss 2.339216947555542\n",
      "\n",
      "episode 8, val func loss 2.4107587337493896\n",
      "\n",
      "episode 9, val func loss 2.5064234733581543\n",
      "\n",
      "episode 10, val func loss 2.477341651916504\n",
      "\n",
      "episode 11, val func loss 2.3861184120178223\n",
      "\n",
      "episode 12, val func loss 2.3704161643981934\n",
      "\n",
      "episode 13, val func loss 2.2874133586883545\n",
      "\n",
      "episode 14, val func loss 2.5123300552368164\n",
      "\n",
      "episode 15, val func loss 2.5262374877929688\n",
      "\n",
      "episode 16, val func loss 2.560917377471924\n",
      "\n",
      "Val func train loss in epoch 12:2.4166617393493652\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 2.395331621170044\n",
      "\n",
      "episode 2, val func loss 2.463714122772217\n",
      "\n",
      "episode 3, val func loss 2.287602424621582\n",
      "\n",
      "episode 4, val func loss 2.473205804824829\n",
      "\n",
      "episode 5, val func loss 2.371593713760376\n",
      "\n",
      "episode 6, val func loss 2.4095559120178223\n",
      "\n",
      "episode 7, val func loss 2.3778483867645264\n",
      "\n",
      "episode 8, val func loss 2.3227055072784424\n",
      "\n",
      "episode 9, val func loss 2.3038947582244873\n",
      "\n",
      "episode 10, val func loss 2.334904193878174\n",
      "\n",
      "episode 11, val func loss 2.5058434009552\n",
      "\n",
      "episode 12, val func loss 2.5643680095672607\n",
      "\n",
      "episode 13, val func loss 2.5365817546844482\n",
      "\n",
      "episode 14, val func loss 2.38322377204895\n",
      "\n",
      "episode 15, val func loss 2.3211734294891357\n",
      "\n",
      "episode 16, val func loss 2.2754690647125244\n",
      "\n",
      "Val func train loss in epoch 13:2.395438492298126\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.3223915100097656\n",
      "\n",
      "episode 2, val func loss 2.4509477615356445\n",
      "\n",
      "episode 3, val func loss 2.288271188735962\n",
      "\n",
      "episode 4, val func loss 2.5056567192077637\n",
      "\n",
      "episode 5, val func loss 2.373814105987549\n",
      "\n",
      "episode 6, val func loss 2.5028603076934814\n",
      "\n",
      "episode 7, val func loss 2.5888452529907227\n",
      "\n",
      "episode 8, val func loss 2.3722424507141113\n",
      "\n",
      "episode 9, val func loss 2.462843894958496\n",
      "\n",
      "episode 10, val func loss 2.3273398876190186\n",
      "\n",
      "episode 11, val func loss 2.6382837295532227\n",
      "\n",
      "episode 12, val func loss 2.4977192878723145\n",
      "\n",
      "episode 13, val func loss 2.3346705436706543\n",
      "\n",
      "episode 14, val func loss 2.4107391834259033\n",
      "\n",
      "episode 15, val func loss 2.39487886428833\n",
      "\n",
      "episode 16, val func loss 2.570507049560547\n",
      "\n",
      "Val func train loss in epoch 14:2.440125733613968\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.3733887672424316\n",
      "\n",
      "episode 2, val func loss 2.428337574005127\n",
      "\n",
      "episode 3, val func loss 2.348513126373291\n",
      "\n",
      "episode 4, val func loss 2.417330741882324\n",
      "\n",
      "episode 5, val func loss 2.513251304626465\n",
      "\n",
      "episode 6, val func loss 2.5254204273223877\n",
      "\n",
      "episode 7, val func loss 2.319493532180786\n",
      "\n",
      "episode 8, val func loss 2.4603357315063477\n",
      "\n",
      "episode 9, val func loss 2.528775215148926\n",
      "\n",
      "episode 10, val func loss 2.368764877319336\n",
      "\n",
      "episode 11, val func loss 2.363013982772827\n",
      "\n",
      "episode 12, val func loss 2.288512945175171\n",
      "\n",
      "episode 13, val func loss 2.3656632900238037\n",
      "\n",
      "episode 14, val func loss 2.583643674850464\n",
      "\n",
      "episode 15, val func loss 2.3001692295074463\n",
      "\n",
      "episode 16, val func loss 2.4480831623077393\n",
      "\n",
      "Val func train loss in epoch 15:2.4145435988903046\n",
      "***********************TIME WAS 5.152462613582611 min*****************************\n",
      "\n",
      "**********************ROUND 6 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.625345766544342\n",
      "\n",
      "episode 2, policy loss -0.6253471970558167\n",
      "\n",
      "episode 3, policy loss -0.6253455281257629\n",
      "\n",
      "episode 4, policy loss -0.6253456473350525\n",
      "\n",
      "episode 5, policy loss -0.6253454089164734\n",
      "\n",
      "episode 6, policy loss -0.6253467202186584\n",
      "\n",
      "episode 7, policy loss -0.6253465414047241\n",
      "\n",
      "episode 8, policy loss -0.625346302986145\n",
      "\n",
      "episode 9, policy loss -0.6253451108932495\n",
      "\n",
      "episode 10, policy loss -0.6253465414047241\n",
      "\n",
      "episode 11, policy loss -0.6253466606140137\n",
      "\n",
      "episode 12, policy loss -0.625346302986145\n",
      "\n",
      "episode 13, policy loss -0.6253463625907898\n",
      "\n",
      "episode 14, policy loss -0.6253465414047241\n",
      "\n",
      "episode 15, policy loss -0.6253464221954346\n",
      "\n",
      "episode 16, policy loss -0.599614143371582\n",
      "\n",
      "Policy train loss in epoch 0:-0.6237379498779774\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.625345766544342\n",
      "\n",
      "episode 2, policy loss -0.6253460049629211\n",
      "\n",
      "episode 3, policy loss -0.6253477334976196\n",
      "\n",
      "episode 4, policy loss -0.6253471374511719\n",
      "\n",
      "episode 5, policy loss -0.6253462433815002\n",
      "\n",
      "episode 6, policy loss -0.6253471374511719\n",
      "\n",
      "episode 7, policy loss -0.6253457069396973\n",
      "\n",
      "episode 8, policy loss -0.625346839427948\n",
      "\n",
      "episode 9, policy loss -0.6253463625907898\n",
      "\n",
      "episode 10, policy loss -0.6253461837768555\n",
      "\n",
      "episode 11, policy loss -0.6253468990325928\n",
      "\n",
      "episode 12, policy loss -0.6253470778465271\n",
      "\n",
      "episode 13, policy loss -0.625346839427948\n",
      "\n",
      "episode 14, policy loss -0.6253465414047241\n",
      "\n",
      "episode 15, policy loss -0.6253460645675659\n",
      "\n",
      "episode 16, policy loss -0.5968210101127625\n",
      "\n",
      "Policy train loss in epoch 1:-0.6235637217760086\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.625346302986145\n",
      "\n",
      "episode 2, policy loss -0.6253464221954346\n",
      "\n",
      "episode 3, policy loss -0.6253466606140137\n",
      "\n",
      "episode 4, policy loss -0.6253464221954346\n",
      "\n",
      "episode 5, policy loss -0.6253460645675659\n",
      "\n",
      "episode 6, policy loss -0.6253461837768555\n",
      "\n",
      "episode 7, policy loss -0.6253462433815002\n",
      "\n",
      "episode 8, policy loss -0.6253461241722107\n",
      "\n",
      "episode 9, policy loss -0.6253460049629211\n",
      "\n",
      "episode 10, policy loss -0.6253460645675659\n",
      "\n",
      "episode 11, policy loss -0.6253461837768555\n",
      "\n",
      "episode 12, policy loss -0.5996137261390686\n",
      "\n",
      "episode 13, policy loss -0.6253459453582764\n",
      "\n",
      "episode 14, policy loss -0.6253460645675659\n",
      "\n",
      "episode 15, policy loss -0.6253459453582764\n",
      "\n",
      "episode 16, policy loss -0.6253458857536316\n",
      "\n",
      "Policy train loss in epoch 2:-0.6237378902733326\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.599613606929779\n",
      "\n",
      "episode 2, policy loss -0.6253459453582764\n",
      "\n",
      "episode 3, policy loss -0.6253459453582764\n",
      "\n",
      "episode 4, policy loss -0.6253458857536316\n",
      "\n",
      "episode 5, policy loss -0.6253460049629211\n",
      "\n",
      "episode 6, policy loss -0.6253458857536316\n",
      "\n",
      "episode 7, policy loss -0.6253458261489868\n",
      "\n",
      "episode 8, policy loss -0.6253458261489868\n",
      "\n",
      "episode 9, policy loss -0.6253459453582764\n",
      "\n",
      "episode 10, policy loss -0.6253460049629211\n",
      "\n",
      "episode 11, policy loss -0.6253458261489868\n",
      "\n",
      "episode 12, policy loss -0.6253458261489868\n",
      "\n",
      "episode 13, policy loss -0.625345766544342\n",
      "\n",
      "episode 14, policy loss -0.625345766544342\n",
      "\n",
      "episode 15, policy loss -0.6253458857536316\n",
      "\n",
      "episode 16, policy loss -0.6253457069396973\n",
      "\n",
      "Policy train loss in epoch 3:-0.6237376034259796\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.2873752117156982\n",
      "\n",
      "episode 2, val func loss 2.3084444999694824\n",
      "\n",
      "episode 3, val func loss 2.3000385761260986\n",
      "\n",
      "episode 4, val func loss 2.297234535217285\n",
      "\n",
      "episode 5, val func loss 2.3494648933410645\n",
      "\n",
      "episode 6, val func loss 2.293510913848877\n",
      "\n",
      "episode 7, val func loss 2.2906672954559326\n",
      "\n",
      "episode 8, val func loss 2.380737781524658\n",
      "\n",
      "episode 9, val func loss 2.3623108863830566\n",
      "\n",
      "episode 10, val func loss 2.2754101753234863\n",
      "\n",
      "episode 11, val func loss 2.4342966079711914\n",
      "\n",
      "episode 12, val func loss 2.2845566272735596\n",
      "\n",
      "episode 13, val func loss 2.3282535076141357\n",
      "\n",
      "episode 14, val func loss 2.2829320430755615\n",
      "\n",
      "episode 15, val func loss 2.23095703125\n",
      "\n",
      "episode 16, val func loss 2.2752928733825684\n",
      "\n",
      "Val func train loss in epoch 0:2.311342716217041\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.2888901233673096\n",
      "\n",
      "episode 2, val func loss 2.2856602668762207\n",
      "\n",
      "episode 3, val func loss 2.353736639022827\n",
      "\n",
      "episode 4, val func loss 2.645005226135254\n",
      "\n",
      "episode 5, val func loss 2.44063401222229\n",
      "\n",
      "episode 6, val func loss 2.381443500518799\n",
      "\n",
      "episode 7, val func loss 2.539462089538574\n",
      "\n",
      "episode 8, val func loss 2.2287676334381104\n",
      "\n",
      "episode 9, val func loss 2.4084746837615967\n",
      "\n",
      "episode 10, val func loss 2.316541910171509\n",
      "\n",
      "episode 11, val func loss 2.4093894958496094\n",
      "\n",
      "episode 12, val func loss 2.240307331085205\n",
      "\n",
      "episode 13, val func loss 2.3555681705474854\n",
      "\n",
      "episode 14, val func loss 2.171967029571533\n",
      "\n",
      "episode 15, val func loss 2.3750836849212646\n",
      "\n",
      "episode 16, val func loss 2.3645355701446533\n",
      "\n",
      "Val func train loss in epoch 1:2.362841710448265\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.2930691242218018\n",
      "\n",
      "episode 2, val func loss 2.214463233947754\n",
      "\n",
      "episode 3, val func loss 2.297593593597412\n",
      "\n",
      "episode 4, val func loss 2.293653726577759\n",
      "\n",
      "episode 5, val func loss 2.323615074157715\n",
      "\n",
      "episode 6, val func loss 2.2069175243377686\n",
      "\n",
      "episode 7, val func loss 2.3513429164886475\n",
      "\n",
      "episode 8, val func loss 2.262284278869629\n",
      "\n",
      "episode 9, val func loss 2.42991042137146\n",
      "\n",
      "episode 10, val func loss 3.1301615238189697\n",
      "\n",
      "episode 11, val func loss 2.280848503112793\n",
      "\n",
      "episode 12, val func loss 3.0318655967712402\n",
      "\n",
      "episode 13, val func loss 2.3118722438812256\n",
      "\n",
      "episode 14, val func loss 2.7641544342041016\n",
      "\n",
      "episode 15, val func loss 2.5088839530944824\n",
      "\n",
      "episode 16, val func loss 2.3871383666992188\n",
      "\n",
      "Val func train loss in epoch 2:2.4429859071969986\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.631293296813965\n",
      "\n",
      "episode 2, val func loss 2.2682454586029053\n",
      "\n",
      "episode 3, val func loss 2.539060592651367\n",
      "\n",
      "episode 4, val func loss 2.389904260635376\n",
      "\n",
      "episode 5, val func loss 2.2957799434661865\n",
      "\n",
      "episode 6, val func loss 2.4679906368255615\n",
      "\n",
      "episode 7, val func loss 2.290945529937744\n",
      "\n",
      "episode 8, val func loss 2.3896937370300293\n",
      "\n",
      "episode 9, val func loss 2.407580852508545\n",
      "\n",
      "episode 10, val func loss 2.316728115081787\n",
      "\n",
      "episode 11, val func loss 2.448406457901001\n",
      "\n",
      "episode 12, val func loss 2.338306188583374\n",
      "\n",
      "episode 13, val func loss 2.4211416244506836\n",
      "\n",
      "episode 14, val func loss 2.328822374343872\n",
      "\n",
      "episode 15, val func loss 2.252448558807373\n",
      "\n",
      "episode 16, val func loss 2.3294498920440674\n",
      "\n",
      "Val func train loss in epoch 3:2.38223734498024\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.2846741676330566\n",
      "\n",
      "episode 2, val func loss 2.3041768074035645\n",
      "\n",
      "episode 3, val func loss 2.3126471042633057\n",
      "\n",
      "episode 4, val func loss 2.215271472930908\n",
      "\n",
      "episode 5, val func loss 2.283362865447998\n",
      "\n",
      "episode 6, val func loss 2.2697207927703857\n",
      "\n",
      "episode 7, val func loss 2.1867434978485107\n",
      "\n",
      "episode 8, val func loss 2.1899917125701904\n",
      "\n",
      "episode 9, val func loss 2.1456639766693115\n",
      "\n",
      "episode 10, val func loss 2.2140934467315674\n",
      "\n",
      "episode 11, val func loss 2.050022602081299\n",
      "\n",
      "episode 12, val func loss 2.215299129486084\n",
      "\n",
      "episode 13, val func loss 2.0968897342681885\n",
      "\n",
      "episode 14, val func loss 2.2476413249969482\n",
      "\n",
      "episode 15, val func loss 2.0765700340270996\n",
      "\n",
      "episode 16, val func loss 2.1605732440948486\n",
      "\n",
      "Val func train loss in epoch 4:2.203333869576454\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 2.282365560531616\n",
      "\n",
      "episode 2, val func loss 2.1524553298950195\n",
      "\n",
      "episode 3, val func loss 2.3306119441986084\n",
      "\n",
      "episode 4, val func loss 2.2671592235565186\n",
      "\n",
      "episode 5, val func loss 2.4014194011688232\n",
      "\n",
      "episode 6, val func loss 2.313338041305542\n",
      "\n",
      "episode 7, val func loss 2.3444223403930664\n",
      "\n",
      "episode 8, val func loss 2.287069320678711\n",
      "\n",
      "episode 9, val func loss 2.2814793586730957\n",
      "\n",
      "episode 10, val func loss 2.326665163040161\n",
      "\n",
      "episode 11, val func loss 2.2531583309173584\n",
      "\n",
      "episode 12, val func loss 2.3003523349761963\n",
      "\n",
      "episode 13, val func loss 2.269695520401001\n",
      "\n",
      "episode 14, val func loss 2.227848529815674\n",
      "\n",
      "episode 15, val func loss 2.167703151702881\n",
      "\n",
      "episode 16, val func loss 2.419921636581421\n",
      "\n",
      "Val func train loss in epoch 5:2.289104074239731\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.147118330001831\n",
      "\n",
      "episode 2, val func loss 2.2122740745544434\n",
      "\n",
      "episode 3, val func loss 2.213489055633545\n",
      "\n",
      "episode 4, val func loss 2.237740993499756\n",
      "\n",
      "episode 5, val func loss 2.2084834575653076\n",
      "\n",
      "episode 6, val func loss 2.3111748695373535\n",
      "\n",
      "episode 7, val func loss 2.148790121078491\n",
      "\n",
      "episode 8, val func loss 2.149717330932617\n",
      "\n",
      "episode 9, val func loss 2.2107503414154053\n",
      "\n",
      "episode 10, val func loss 2.323232650756836\n",
      "\n",
      "episode 11, val func loss 2.1858792304992676\n",
      "\n",
      "episode 12, val func loss 2.3395259380340576\n",
      "\n",
      "episode 13, val func loss 2.1324305534362793\n",
      "\n",
      "episode 14, val func loss 2.312000274658203\n",
      "\n",
      "episode 15, val func loss 2.159682512283325\n",
      "\n",
      "episode 16, val func loss 2.2199759483337402\n",
      "\n",
      "Val func train loss in epoch 6:2.2195166051387787\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 2.2319514751434326\n",
      "\n",
      "episode 2, val func loss 2.3262763023376465\n",
      "\n",
      "episode 3, val func loss 2.2252845764160156\n",
      "\n",
      "episode 4, val func loss 2.313533306121826\n",
      "\n",
      "episode 5, val func loss 2.2194104194641113\n",
      "\n",
      "episode 6, val func loss 2.295232057571411\n",
      "\n",
      "episode 7, val func loss 2.2562499046325684\n",
      "\n",
      "episode 8, val func loss 2.2464072704315186\n",
      "\n",
      "episode 9, val func loss 2.2066380977630615\n",
      "\n",
      "episode 10, val func loss 2.2370035648345947\n",
      "\n",
      "episode 11, val func loss 2.268550157546997\n",
      "\n",
      "episode 12, val func loss 2.147416114807129\n",
      "\n",
      "episode 13, val func loss 2.181110143661499\n",
      "\n",
      "episode 14, val func loss 2.320172071456909\n",
      "\n",
      "episode 15, val func loss 2.102954149246216\n",
      "\n",
      "episode 16, val func loss 2.1125926971435547\n",
      "\n",
      "Val func train loss in epoch 7:2.2306738942861557\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.221116542816162\n",
      "\n",
      "episode 2, val func loss 2.277175188064575\n",
      "\n",
      "episode 3, val func loss 2.118830442428589\n",
      "\n",
      "episode 4, val func loss 2.278932809829712\n",
      "\n",
      "episode 5, val func loss 2.272855281829834\n",
      "\n",
      "episode 6, val func loss 2.280109405517578\n",
      "\n",
      "episode 7, val func loss 2.4133718013763428\n",
      "\n",
      "episode 8, val func loss 2.2129974365234375\n",
      "\n",
      "episode 9, val func loss 2.257298469543457\n",
      "\n",
      "episode 10, val func loss 2.157794713973999\n",
      "\n",
      "episode 11, val func loss 2.2574727535247803\n",
      "\n",
      "episode 12, val func loss 2.204559087753296\n",
      "\n",
      "episode 13, val func loss 2.086336612701416\n",
      "\n",
      "episode 14, val func loss 2.1820006370544434\n",
      "\n",
      "episode 15, val func loss 2.1082942485809326\n",
      "\n",
      "episode 16, val func loss 2.21769642829895\n",
      "\n",
      "Val func train loss in epoch 8:2.221677616238594\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 2.035179615020752\n",
      "\n",
      "episode 2, val func loss 2.2460885047912598\n",
      "\n",
      "episode 3, val func loss 2.250596284866333\n",
      "\n",
      "episode 4, val func loss 2.2671844959259033\n",
      "\n",
      "episode 5, val func loss 2.186638593673706\n",
      "\n",
      "episode 6, val func loss 2.1232645511627197\n",
      "\n",
      "episode 7, val func loss 2.229978561401367\n",
      "\n",
      "episode 8, val func loss 2.2223546504974365\n",
      "\n",
      "episode 9, val func loss 2.3276917934417725\n",
      "\n",
      "episode 10, val func loss 2.180295944213867\n",
      "\n",
      "episode 11, val func loss 2.4506430625915527\n",
      "\n",
      "episode 12, val func loss 2.2494561672210693\n",
      "\n",
      "episode 13, val func loss 2.205651044845581\n",
      "\n",
      "episode 14, val func loss 2.1375157833099365\n",
      "\n",
      "episode 15, val func loss 2.2222235202789307\n",
      "\n",
      "episode 16, val func loss 2.1398820877075195\n",
      "\n",
      "Val func train loss in epoch 9:2.2171652913093567\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.1907668113708496\n",
      "\n",
      "episode 2, val func loss 2.165409564971924\n",
      "\n",
      "episode 3, val func loss 2.1656746864318848\n",
      "\n",
      "episode 4, val func loss 2.2092721462249756\n",
      "\n",
      "episode 5, val func loss 2.1330065727233887\n",
      "\n",
      "episode 6, val func loss 2.2515766620635986\n",
      "\n",
      "episode 7, val func loss 2.15490984916687\n",
      "\n",
      "episode 8, val func loss 2.2057368755340576\n",
      "\n",
      "episode 9, val func loss 2.2131621837615967\n",
      "\n",
      "episode 10, val func loss 2.3078062534332275\n",
      "\n",
      "episode 11, val func loss 2.1771399974823\n",
      "\n",
      "episode 12, val func loss 2.129258871078491\n",
      "\n",
      "episode 13, val func loss 2.0993871688842773\n",
      "\n",
      "episode 14, val func loss 2.0581905841827393\n",
      "\n",
      "episode 15, val func loss 2.0708775520324707\n",
      "\n",
      "episode 16, val func loss 2.1651408672332764\n",
      "\n",
      "Val func train loss in epoch 10:2.1685822904109955\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 2.105271816253662\n",
      "\n",
      "episode 2, val func loss 2.13570499420166\n",
      "\n",
      "episode 3, val func loss 2.0979340076446533\n",
      "\n",
      "episode 4, val func loss 2.302844762802124\n",
      "\n",
      "episode 5, val func loss 2.860208749771118\n",
      "\n",
      "episode 6, val func loss 2.206101417541504\n",
      "\n",
      "episode 7, val func loss 2.6275694370269775\n",
      "\n",
      "episode 8, val func loss 2.0966081619262695\n",
      "\n",
      "episode 9, val func loss 2.3871705532073975\n",
      "\n",
      "episode 10, val func loss 2.1803741455078125\n",
      "\n",
      "episode 11, val func loss 2.4008400440216064\n",
      "\n",
      "episode 12, val func loss 2.307520627975464\n",
      "\n",
      "episode 13, val func loss 2.354806661605835\n",
      "\n",
      "episode 14, val func loss 2.323377847671509\n",
      "\n",
      "episode 15, val func loss 2.2472946643829346\n",
      "\n",
      "episode 16, val func loss 2.2662296295166016\n",
      "\n",
      "Val func train loss in epoch 11:2.3062410950660706\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 2.265716314315796\n",
      "\n",
      "episode 2, val func loss 2.2511088848114014\n",
      "\n",
      "episode 3, val func loss 2.2246179580688477\n",
      "\n",
      "episode 4, val func loss 2.3146910667419434\n",
      "\n",
      "episode 5, val func loss 2.1839520931243896\n",
      "\n",
      "episode 6, val func loss 2.249979019165039\n",
      "\n",
      "episode 7, val func loss 2.14957857131958\n",
      "\n",
      "episode 8, val func loss 2.195561408996582\n",
      "\n",
      "episode 9, val func loss 2.257176160812378\n",
      "\n",
      "episode 10, val func loss 2.2745227813720703\n",
      "\n",
      "episode 11, val func loss 2.3037898540496826\n",
      "\n",
      "episode 12, val func loss 2.140533208847046\n",
      "\n",
      "episode 13, val func loss 2.29483962059021\n",
      "\n",
      "episode 14, val func loss 2.0206167697906494\n",
      "\n",
      "episode 15, val func loss 2.2041397094726562\n",
      "\n",
      "episode 16, val func loss 2.0515997409820557\n",
      "\n",
      "Val func train loss in epoch 12:2.2114014476537704\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 2.138620615005493\n",
      "\n",
      "episode 2, val func loss 2.049823045730591\n",
      "\n",
      "episode 3, val func loss 2.30523943901062\n",
      "\n",
      "episode 4, val func loss 2.2734551429748535\n",
      "\n",
      "episode 5, val func loss 2.0282890796661377\n",
      "\n",
      "episode 6, val func loss 2.2866854667663574\n",
      "\n",
      "episode 7, val func loss 2.1983797550201416\n",
      "\n",
      "episode 8, val func loss 2.173146963119507\n",
      "\n",
      "episode 9, val func loss 2.1489174365997314\n",
      "\n",
      "episode 10, val func loss 1.9990772008895874\n",
      "\n",
      "episode 11, val func loss 2.213604211807251\n",
      "\n",
      "episode 12, val func loss 2.313178300857544\n",
      "\n",
      "episode 13, val func loss 2.3399744033813477\n",
      "\n",
      "episode 14, val func loss 2.3258473873138428\n",
      "\n",
      "episode 15, val func loss 2.184973955154419\n",
      "\n",
      "episode 16, val func loss 2.1273550987243652\n",
      "\n",
      "Val func train loss in epoch 13:2.194160468876362\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.273089647293091\n",
      "\n",
      "episode 2, val func loss 2.128190517425537\n",
      "\n",
      "episode 3, val func loss 2.193134069442749\n",
      "\n",
      "episode 4, val func loss 2.266309976577759\n",
      "\n",
      "episode 5, val func loss 2.1592352390289307\n",
      "\n",
      "episode 6, val func loss 2.2210607528686523\n",
      "\n",
      "episode 7, val func loss 2.2846014499664307\n",
      "\n",
      "episode 8, val func loss 2.179471492767334\n",
      "\n",
      "episode 9, val func loss 2.286789894104004\n",
      "\n",
      "episode 10, val func loss 2.074535369873047\n",
      "\n",
      "episode 11, val func loss 2.239628314971924\n",
      "\n",
      "episode 12, val func loss 2.186903476715088\n",
      "\n",
      "episode 13, val func loss 2.172373056411743\n",
      "\n",
      "episode 14, val func loss 2.144376039505005\n",
      "\n",
      "episode 15, val func loss 2.148736000061035\n",
      "\n",
      "episode 16, val func loss 2.08365797996521\n",
      "\n",
      "Val func train loss in epoch 14:2.190130829811096\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.036068916320801\n",
      "\n",
      "episode 2, val func loss 2.1322054862976074\n",
      "\n",
      "episode 3, val func loss 2.0367794036865234\n",
      "\n",
      "episode 4, val func loss 2.062839984893799\n",
      "\n",
      "episode 5, val func loss 2.046666145324707\n",
      "\n",
      "episode 6, val func loss 2.046844482421875\n",
      "\n",
      "episode 7, val func loss 2.156865358352661\n",
      "\n",
      "episode 8, val func loss 2.119086980819702\n",
      "\n",
      "episode 9, val func loss 2.301719903945923\n",
      "\n",
      "episode 10, val func loss 2.8981170654296875\n",
      "\n",
      "episode 11, val func loss 2.7913811206817627\n",
      "\n",
      "episode 12, val func loss 2.268766403198242\n",
      "\n",
      "episode 13, val func loss 2.345012664794922\n",
      "\n",
      "episode 14, val func loss 2.4477672576904297\n",
      "\n",
      "episode 15, val func loss 2.109382152557373\n",
      "\n",
      "episode 16, val func loss 2.391789197921753\n",
      "\n",
      "Val func train loss in epoch 15:2.2619557827711105\n",
      "***********************TIME WAS 5.148393817742666 min*****************************\n",
      "\n",
      "**********************ROUND 7 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.23783805966377258\n",
      "\n",
      "episode 2, policy loss -0.23783741891384125\n",
      "\n",
      "episode 3, policy loss -0.23783765733242035\n",
      "\n",
      "episode 4, policy loss -0.237837553024292\n",
      "\n",
      "episode 5, policy loss -0.23783792555332184\n",
      "\n",
      "episode 6, policy loss -0.23783813416957855\n",
      "\n",
      "episode 7, policy loss -0.237837553024292\n",
      "\n",
      "episode 8, policy loss -0.23783685266971588\n",
      "\n",
      "episode 9, policy loss -0.23783716559410095\n",
      "\n",
      "episode 10, policy loss -0.23783788084983826\n",
      "\n",
      "episode 11, policy loss -0.23783841729164124\n",
      "\n",
      "episode 12, policy loss -0.23783795535564423\n",
      "\n",
      "episode 13, policy loss -0.23783695697784424\n",
      "\n",
      "episode 14, policy loss -0.23783759772777557\n",
      "\n",
      "episode 15, policy loss -0.23783756792545319\n",
      "\n",
      "episode 16, policy loss -0.23783747851848602\n",
      "\n",
      "Policy train loss in epoch 0:-0.23783763591200113\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.2378377914428711\n",
      "\n",
      "episode 2, policy loss -0.2378375381231308\n",
      "\n",
      "episode 3, policy loss -0.23783691227436066\n",
      "\n",
      "episode 4, policy loss -0.23783747851848602\n",
      "\n",
      "episode 5, policy loss -0.23783741891384125\n",
      "\n",
      "episode 6, policy loss -0.23783738911151886\n",
      "\n",
      "episode 7, policy loss -0.2378380298614502\n",
      "\n",
      "episode 8, policy loss -0.23783762753009796\n",
      "\n",
      "episode 9, policy loss -0.23783765733242035\n",
      "\n",
      "episode 10, policy loss -0.23783795535564423\n",
      "\n",
      "episode 11, policy loss -0.2378368228673935\n",
      "\n",
      "episode 12, policy loss -0.23783762753009796\n",
      "\n",
      "episode 13, policy loss -0.23783817887306213\n",
      "\n",
      "episode 14, policy loss -0.2378370612859726\n",
      "\n",
      "episode 15, policy loss -0.23783786594867706\n",
      "\n",
      "episode 16, policy loss -0.23783835768699646\n",
      "\n",
      "Policy train loss in epoch 1:-0.23783760704100132\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.23783734440803528\n",
      "\n",
      "episode 2, policy loss -0.23783811926841736\n",
      "\n",
      "episode 3, policy loss -0.23783805966377258\n",
      "\n",
      "episode 4, policy loss -0.2378377616405487\n",
      "\n",
      "episode 5, policy loss -0.23783788084983826\n",
      "\n",
      "episode 6, policy loss -0.23783855140209198\n",
      "\n",
      "episode 7, policy loss -0.23783765733242035\n",
      "\n",
      "episode 8, policy loss -0.2378375381231308\n",
      "\n",
      "episode 9, policy loss -0.237837016582489\n",
      "\n",
      "episode 10, policy loss -0.2378380447626114\n",
      "\n",
      "episode 11, policy loss -0.23783688247203827\n",
      "\n",
      "episode 12, policy loss -0.23783747851848602\n",
      "\n",
      "episode 13, policy loss -0.2378370612859726\n",
      "\n",
      "episode 14, policy loss -0.23783773183822632\n",
      "\n",
      "episode 15, policy loss -0.23783741891384125\n",
      "\n",
      "episode 16, policy loss -0.23783759772777557\n",
      "\n",
      "Policy train loss in epoch 2:-0.23783763404935598\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.23783759772777557\n",
      "\n",
      "episode 2, policy loss -0.2378370761871338\n",
      "\n",
      "episode 3, policy loss -0.2378372848033905\n",
      "\n",
      "episode 4, policy loss -0.237838014960289\n",
      "\n",
      "episode 5, policy loss -0.237837553024292\n",
      "\n",
      "episode 6, policy loss -0.23783738911151886\n",
      "\n",
      "episode 7, policy loss -0.23783746361732483\n",
      "\n",
      "episode 8, policy loss -0.2378378063440323\n",
      "\n",
      "episode 9, policy loss -0.23783762753009796\n",
      "\n",
      "episode 10, policy loss -0.2378380000591278\n",
      "\n",
      "episode 11, policy loss -0.23783712089061737\n",
      "\n",
      "episode 12, policy loss -0.23783794045448303\n",
      "\n",
      "episode 13, policy loss -0.23783676326274872\n",
      "\n",
      "episode 14, policy loss -0.2378384917974472\n",
      "\n",
      "episode 15, policy loss -0.23783767223358154\n",
      "\n",
      "episode 16, policy loss -0.237838014960289\n",
      "\n",
      "Policy train loss in epoch 3:-0.23783761356025934\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.1603310108184814\n",
      "\n",
      "episode 2, val func loss 2.2989659309387207\n",
      "\n",
      "episode 3, val func loss 2.215104341506958\n",
      "\n",
      "episode 4, val func loss 2.2227437496185303\n",
      "\n",
      "episode 5, val func loss 2.1882071495056152\n",
      "\n",
      "episode 6, val func loss 2.173685073852539\n",
      "\n",
      "episode 7, val func loss 2.2469046115875244\n",
      "\n",
      "episode 8, val func loss 2.0649664402008057\n",
      "\n",
      "episode 9, val func loss 2.184709072113037\n",
      "\n",
      "episode 10, val func loss 2.2647342681884766\n",
      "\n",
      "episode 11, val func loss 2.2077744007110596\n",
      "\n",
      "episode 12, val func loss 2.0685505867004395\n",
      "\n",
      "episode 13, val func loss 2.190307378768921\n",
      "\n",
      "episode 14, val func loss 2.073284387588501\n",
      "\n",
      "episode 15, val func loss 2.0808959007263184\n",
      "\n",
      "episode 16, val func loss 2.1144561767578125\n",
      "\n",
      "Val func train loss in epoch 0:2.1722262799739838\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.0448482036590576\n",
      "\n",
      "episode 2, val func loss 2.011399745941162\n",
      "\n",
      "episode 3, val func loss 1.9250085353851318\n",
      "\n",
      "episode 4, val func loss 2.093935251235962\n",
      "\n",
      "episode 5, val func loss 2.0289697647094727\n",
      "\n",
      "episode 6, val func loss 2.0724191665649414\n",
      "\n",
      "episode 7, val func loss 2.049252510070801\n",
      "\n",
      "episode 8, val func loss 2.0339016914367676\n",
      "\n",
      "episode 9, val func loss 2.108959197998047\n",
      "\n",
      "episode 10, val func loss 2.0418527126312256\n",
      "\n",
      "episode 11, val func loss 2.1691043376922607\n",
      "\n",
      "episode 12, val func loss 2.0908734798431396\n",
      "\n",
      "episode 13, val func loss 1.8653568029403687\n",
      "\n",
      "episode 14, val func loss 2.0977087020874023\n",
      "\n",
      "episode 15, val func loss 2.058932065963745\n",
      "\n",
      "episode 16, val func loss 2.1394660472869873\n",
      "\n",
      "Val func train loss in epoch 1:2.0519992634654045\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.1421847343444824\n",
      "\n",
      "episode 2, val func loss 2.0022494792938232\n",
      "\n",
      "episode 3, val func loss 2.029653549194336\n",
      "\n",
      "episode 4, val func loss 2.1134848594665527\n",
      "\n",
      "episode 5, val func loss 2.188450813293457\n",
      "\n",
      "episode 6, val func loss 1.9345593452453613\n",
      "\n",
      "episode 7, val func loss 2.2222135066986084\n",
      "\n",
      "episode 8, val func loss 2.023773670196533\n",
      "\n",
      "episode 9, val func loss 2.336686849594116\n",
      "\n",
      "episode 10, val func loss 1.9447386264801025\n",
      "\n",
      "episode 11, val func loss 2.4471395015716553\n",
      "\n",
      "episode 12, val func loss 1.9875763654708862\n",
      "\n",
      "episode 13, val func loss 2.1714181900024414\n",
      "\n",
      "episode 14, val func loss 1.8812538385391235\n",
      "\n",
      "episode 15, val func loss 2.1364755630493164\n",
      "\n",
      "episode 16, val func loss 2.009915351867676\n",
      "\n",
      "Val func train loss in epoch 2:2.0982358902692795\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.00781512260437\n",
      "\n",
      "episode 2, val func loss 2.109438180923462\n",
      "\n",
      "episode 3, val func loss 2.0734572410583496\n",
      "\n",
      "episode 4, val func loss 2.147552251815796\n",
      "\n",
      "episode 5, val func loss 1.9685478210449219\n",
      "\n",
      "episode 6, val func loss 2.0342471599578857\n",
      "\n",
      "episode 7, val func loss 1.98252534866333\n",
      "\n",
      "episode 8, val func loss 2.001776695251465\n",
      "\n",
      "episode 9, val func loss 2.1000795364379883\n",
      "\n",
      "episode 10, val func loss 2.1268157958984375\n",
      "\n",
      "episode 11, val func loss 2.076322078704834\n",
      "\n",
      "episode 12, val func loss 2.0828158855438232\n",
      "\n",
      "episode 13, val func loss 2.1155190467834473\n",
      "\n",
      "episode 14, val func loss 2.1694657802581787\n",
      "\n",
      "episode 15, val func loss 2.0113413333892822\n",
      "\n",
      "episode 16, val func loss 1.9457592964172363\n",
      "\n",
      "Val func train loss in epoch 3:2.0595924109220505\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.1650781631469727\n",
      "\n",
      "episode 2, val func loss 2.11885666847229\n",
      "\n",
      "episode 3, val func loss 2.175340175628662\n",
      "\n",
      "episode 4, val func loss 3.000563383102417\n",
      "\n",
      "episode 5, val func loss 2.8549370765686035\n",
      "\n",
      "episode 6, val func loss 2.4081482887268066\n",
      "\n",
      "episode 7, val func loss 2.5079636573791504\n",
      "\n",
      "episode 8, val func loss 2.3749911785125732\n",
      "\n",
      "episode 9, val func loss 2.01924991607666\n",
      "\n",
      "episode 10, val func loss 2.409290075302124\n",
      "\n",
      "episode 11, val func loss 2.287583827972412\n",
      "\n",
      "episode 12, val func loss 2.2967724800109863\n",
      "\n",
      "episode 13, val func loss 2.3367888927459717\n",
      "\n",
      "episode 14, val func loss 2.088994026184082\n",
      "\n",
      "episode 15, val func loss 2.108530282974243\n",
      "\n",
      "episode 16, val func loss 2.236426591873169\n",
      "\n",
      "Val func train loss in epoch 4:2.3368446677923203\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.974419355392456\n",
      "\n",
      "episode 2, val func loss 2.3415637016296387\n",
      "\n",
      "episode 3, val func loss 2.1039316654205322\n",
      "\n",
      "episode 4, val func loss 2.140143632888794\n",
      "\n",
      "episode 5, val func loss 2.209219217300415\n",
      "\n",
      "episode 6, val func loss 2.1684224605560303\n",
      "\n",
      "episode 7, val func loss 2.2028470039367676\n",
      "\n",
      "episode 8, val func loss 1.9338302612304688\n",
      "\n",
      "episode 9, val func loss 2.2481396198272705\n",
      "\n",
      "episode 10, val func loss 2.06612491607666\n",
      "\n",
      "episode 11, val func loss 2.0780885219573975\n",
      "\n",
      "episode 12, val func loss 2.2851483821868896\n",
      "\n",
      "episode 13, val func loss 2.169642686843872\n",
      "\n",
      "episode 14, val func loss 2.047330379486084\n",
      "\n",
      "episode 15, val func loss 2.037058115005493\n",
      "\n",
      "episode 16, val func loss 2.1403918266296387\n",
      "\n",
      "Val func train loss in epoch 5:2.1341438591480255\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.105013370513916\n",
      "\n",
      "episode 2, val func loss 2.116488218307495\n",
      "\n",
      "episode 3, val func loss 2.216447353363037\n",
      "\n",
      "episode 4, val func loss 2.0714926719665527\n",
      "\n",
      "episode 5, val func loss 2.020411729812622\n",
      "\n",
      "episode 6, val func loss 2.1198031902313232\n",
      "\n",
      "episode 7, val func loss 2.1629347801208496\n",
      "\n",
      "episode 8, val func loss 1.9602465629577637\n",
      "\n",
      "episode 9, val func loss 2.073469400405884\n",
      "\n",
      "episode 10, val func loss 2.000176429748535\n",
      "\n",
      "episode 11, val func loss 2.027712345123291\n",
      "\n",
      "episode 12, val func loss 1.969390630722046\n",
      "\n",
      "episode 13, val func loss 2.1694562435150146\n",
      "\n",
      "episode 14, val func loss 2.010175943374634\n",
      "\n",
      "episode 15, val func loss 2.0302722454071045\n",
      "\n",
      "episode 16, val func loss 2.1291556358337402\n",
      "\n",
      "Val func train loss in epoch 6:2.073915421962738\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.9162083864212036\n",
      "\n",
      "episode 2, val func loss 2.137887716293335\n",
      "\n",
      "episode 3, val func loss 1.8889274597167969\n",
      "\n",
      "episode 4, val func loss 2.0878796577453613\n",
      "\n",
      "episode 5, val func loss 2.056525468826294\n",
      "\n",
      "episode 6, val func loss 2.1118319034576416\n",
      "\n",
      "episode 7, val func loss 1.993775486946106\n",
      "\n",
      "episode 8, val func loss 2.0861406326293945\n",
      "\n",
      "episode 9, val func loss 1.9570561647415161\n",
      "\n",
      "episode 10, val func loss 1.9406399726867676\n",
      "\n",
      "episode 11, val func loss 2.0906941890716553\n",
      "\n",
      "episode 12, val func loss 1.764632225036621\n",
      "\n",
      "episode 13, val func loss 1.8384007215499878\n",
      "\n",
      "episode 14, val func loss 1.9043962955474854\n",
      "\n",
      "episode 15, val func loss 1.8531759977340698\n",
      "\n",
      "episode 16, val func loss 2.1036434173583984\n",
      "\n",
      "Val func train loss in epoch 7:1.9832384809851646\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.8586186170578003\n",
      "\n",
      "episode 2, val func loss 1.8689626455307007\n",
      "\n",
      "episode 3, val func loss 1.810437560081482\n",
      "\n",
      "episode 4, val func loss 2.0148556232452393\n",
      "\n",
      "episode 5, val func loss 2.333524227142334\n",
      "\n",
      "episode 6, val func loss 2.1980061531066895\n",
      "\n",
      "episode 7, val func loss 1.9955790042877197\n",
      "\n",
      "episode 8, val func loss 1.9361070394515991\n",
      "\n",
      "episode 9, val func loss 2.084693670272827\n",
      "\n",
      "episode 10, val func loss 1.911581039428711\n",
      "\n",
      "episode 11, val func loss 2.1865029335021973\n",
      "\n",
      "episode 12, val func loss 2.042381763458252\n",
      "\n",
      "episode 13, val func loss 1.88142728805542\n",
      "\n",
      "episode 14, val func loss 2.0058693885803223\n",
      "\n",
      "episode 15, val func loss 1.9407910108566284\n",
      "\n",
      "episode 16, val func loss 1.8978424072265625\n",
      "\n",
      "Val func train loss in epoch 8:1.9979487732052803\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 2.0092461109161377\n",
      "\n",
      "episode 2, val func loss 1.8869222402572632\n",
      "\n",
      "episode 3, val func loss 2.011052370071411\n",
      "\n",
      "episode 4, val func loss 1.9227850437164307\n",
      "\n",
      "episode 5, val func loss 1.9563024044036865\n",
      "\n",
      "episode 6, val func loss 2.0077826976776123\n",
      "\n",
      "episode 7, val func loss 2.0555341243743896\n",
      "\n",
      "episode 8, val func loss 2.1004276275634766\n",
      "\n",
      "episode 9, val func loss 1.8737473487854004\n",
      "\n",
      "episode 10, val func loss 1.8496581315994263\n",
      "\n",
      "episode 11, val func loss 2.193479537963867\n",
      "\n",
      "episode 12, val func loss 2.021667957305908\n",
      "\n",
      "episode 13, val func loss 1.7905560731887817\n",
      "\n",
      "episode 14, val func loss 2.009058713912964\n",
      "\n",
      "episode 15, val func loss 1.722402811050415\n",
      "\n",
      "episode 16, val func loss 2.0119457244873047\n",
      "\n",
      "Val func train loss in epoch 9:1.9639105573296547\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.712097406387329\n",
      "\n",
      "episode 2, val func loss 4.783749103546143\n",
      "\n",
      "episode 3, val func loss 4.894664764404297\n",
      "\n",
      "episode 4, val func loss 3.4256234169006348\n",
      "\n",
      "episode 5, val func loss 3.0225226879119873\n",
      "\n",
      "episode 6, val func loss 3.452364444732666\n",
      "\n",
      "episode 7, val func loss 2.2277846336364746\n",
      "\n",
      "episode 8, val func loss 2.607769012451172\n",
      "\n",
      "episode 9, val func loss 2.5008459091186523\n",
      "\n",
      "episode 10, val func loss 2.3685872554779053\n",
      "\n",
      "episode 11, val func loss 2.753462076187134\n",
      "\n",
      "episode 12, val func loss 2.4106807708740234\n",
      "\n",
      "episode 13, val func loss 2.4423422813415527\n",
      "\n",
      "episode 14, val func loss 2.4952425956726074\n",
      "\n",
      "episode 15, val func loss 2.308849334716797\n",
      "\n",
      "episode 16, val func loss 2.3677327632904053\n",
      "\n",
      "Val func train loss in epoch 10:2.9233949035406113\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 2.4289140701293945\n",
      "\n",
      "episode 2, val func loss 2.330852746963501\n",
      "\n",
      "episode 3, val func loss 2.3559317588806152\n",
      "\n",
      "episode 4, val func loss 2.366959571838379\n",
      "\n",
      "episode 5, val func loss 2.372732400894165\n",
      "\n",
      "episode 6, val func loss 2.3483755588531494\n",
      "\n",
      "episode 7, val func loss 2.3446707725524902\n",
      "\n",
      "episode 8, val func loss 2.28615665435791\n",
      "\n",
      "episode 9, val func loss 2.3339693546295166\n",
      "\n",
      "episode 10, val func loss 2.3482789993286133\n",
      "\n",
      "episode 11, val func loss 2.270657539367676\n",
      "\n",
      "episode 12, val func loss 2.274451971054077\n",
      "\n",
      "episode 13, val func loss 2.3318443298339844\n",
      "\n",
      "episode 14, val func loss 2.352947950363159\n",
      "\n",
      "episode 15, val func loss 2.2493836879730225\n",
      "\n",
      "episode 16, val func loss 2.25580096244812\n",
      "\n",
      "Val func train loss in epoch 11:2.328245520591736\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 2.288529396057129\n",
      "\n",
      "episode 2, val func loss 2.263139247894287\n",
      "\n",
      "episode 3, val func loss 2.2897393703460693\n",
      "\n",
      "episode 4, val func loss 2.22009539604187\n",
      "\n",
      "episode 5, val func loss 2.2335989475250244\n",
      "\n",
      "episode 6, val func loss 2.327272653579712\n",
      "\n",
      "episode 7, val func loss 2.2401628494262695\n",
      "\n",
      "episode 8, val func loss 2.3150267601013184\n",
      "\n",
      "episode 9, val func loss 2.200028419494629\n",
      "\n",
      "episode 10, val func loss 2.157205104827881\n",
      "\n",
      "episode 11, val func loss 2.2489137649536133\n",
      "\n",
      "episode 12, val func loss 2.209705352783203\n",
      "\n",
      "episode 13, val func loss 2.2117087841033936\n",
      "\n",
      "episode 14, val func loss 2.1221208572387695\n",
      "\n",
      "episode 15, val func loss 2.1869328022003174\n",
      "\n",
      "episode 16, val func loss 2.2889490127563477\n",
      "\n",
      "Val func train loss in epoch 12:2.2376955449581146\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 2.1459767818450928\n",
      "\n",
      "episode 2, val func loss 2.3365418910980225\n",
      "\n",
      "episode 3, val func loss 2.091049909591675\n",
      "\n",
      "episode 4, val func loss 2.2882893085479736\n",
      "\n",
      "episode 5, val func loss 2.261937141418457\n",
      "\n",
      "episode 6, val func loss 2.154634714126587\n",
      "\n",
      "episode 7, val func loss 2.230285406112671\n",
      "\n",
      "episode 8, val func loss 2.1901021003723145\n",
      "\n",
      "episode 9, val func loss 2.243957996368408\n",
      "\n",
      "episode 10, val func loss 2.1208503246307373\n",
      "\n",
      "episode 11, val func loss 2.1875879764556885\n",
      "\n",
      "episode 12, val func loss 2.1878368854522705\n",
      "\n",
      "episode 13, val func loss 2.1508214473724365\n",
      "\n",
      "episode 14, val func loss 2.1729941368103027\n",
      "\n",
      "episode 15, val func loss 2.1472718715667725\n",
      "\n",
      "episode 16, val func loss 2.2417094707489014\n",
      "\n",
      "Val func train loss in epoch 13:2.1969904601573944\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.987973928451538\n",
      "\n",
      "episode 2, val func loss 2.2423033714294434\n",
      "\n",
      "episode 3, val func loss 2.2937262058258057\n",
      "\n",
      "episode 4, val func loss 2.1342713832855225\n",
      "\n",
      "episode 5, val func loss 2.235562324523926\n",
      "\n",
      "episode 6, val func loss 2.1787893772125244\n",
      "\n",
      "episode 7, val func loss 2.240351438522339\n",
      "\n",
      "episode 8, val func loss 2.362365961074829\n",
      "\n",
      "episode 9, val func loss 2.1636598110198975\n",
      "\n",
      "episode 10, val func loss 2.147918701171875\n",
      "\n",
      "episode 11, val func loss 2.1526939868927\n",
      "\n",
      "episode 12, val func loss 2.147470712661743\n",
      "\n",
      "episode 13, val func loss 2.1833789348602295\n",
      "\n",
      "episode 14, val func loss 1.997734785079956\n",
      "\n",
      "episode 15, val func loss 2.0370559692382812\n",
      "\n",
      "episode 16, val func loss 2.1132845878601074\n",
      "\n",
      "Val func train loss in epoch 14:2.16365884244442\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.3900351524353027\n",
      "\n",
      "episode 2, val func loss 2.129312038421631\n",
      "\n",
      "episode 3, val func loss 2.024545192718506\n",
      "\n",
      "episode 4, val func loss 2.1378602981567383\n",
      "\n",
      "episode 5, val func loss 2.171419858932495\n",
      "\n",
      "episode 6, val func loss 2.161991834640503\n",
      "\n",
      "episode 7, val func loss 1.957540512084961\n",
      "\n",
      "episode 8, val func loss 2.1805953979492188\n",
      "\n",
      "episode 9, val func loss 2.0749406814575195\n",
      "\n",
      "episode 10, val func loss 2.0434730052948\n",
      "\n",
      "episode 11, val func loss 2.0363545417785645\n",
      "\n",
      "episode 12, val func loss 2.2324628829956055\n",
      "\n",
      "episode 13, val func loss 2.018930196762085\n",
      "\n",
      "episode 14, val func loss 2.095050573348999\n",
      "\n",
      "episode 15, val func loss 2.057706356048584\n",
      "\n",
      "episode 16, val func loss 2.168555498123169\n",
      "\n",
      "Val func train loss in epoch 15:2.1175483763217926\n",
      "***********************TIME WAS 5.147063374519348 min*****************************\n",
      "\n",
      "**********************ROUND 8 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.5032956004142761\n",
      "\n",
      "episode 2, policy loss -0.5032989978790283\n",
      "\n",
      "episode 3, policy loss -0.503294825553894\n",
      "\n",
      "episode 4, policy loss -0.5032996535301208\n",
      "\n",
      "episode 5, policy loss -0.5032959580421448\n",
      "\n",
      "episode 6, policy loss -0.5032931566238403\n",
      "\n",
      "episode 7, policy loss -0.5032914280891418\n",
      "\n",
      "episode 8, policy loss -0.5032957792282104\n",
      "\n",
      "episode 9, policy loss -0.5032997727394104\n",
      "\n",
      "episode 10, policy loss -0.5032971501350403\n",
      "\n",
      "episode 11, policy loss -0.5032957792282104\n",
      "\n",
      "episode 12, policy loss -0.5032986402511597\n",
      "\n",
      "episode 13, policy loss -0.5032939910888672\n",
      "\n",
      "episode 14, policy loss -0.5032964944839478\n",
      "\n",
      "episode 15, policy loss -0.5032991766929626\n",
      "\n",
      "episode 16, policy loss -0.5032966136932373\n",
      "\n",
      "Policy train loss in epoch 0:-0.5032964386045933\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.5032931566238403\n",
      "\n",
      "episode 2, policy loss -0.5032913088798523\n",
      "\n",
      "episode 3, policy loss -0.5032957792282104\n",
      "\n",
      "episode 4, policy loss -0.5032997131347656\n",
      "\n",
      "episode 5, policy loss -0.5032957196235657\n",
      "\n",
      "episode 6, policy loss -0.5032998323440552\n",
      "\n",
      "episode 7, policy loss -0.5032985806465149\n",
      "\n",
      "episode 8, policy loss -0.5032991766929626\n",
      "\n",
      "episode 9, policy loss -0.503294825553894\n",
      "\n",
      "episode 10, policy loss -0.5032958984375\n",
      "\n",
      "episode 11, policy loss -0.5032959580421448\n",
      "\n",
      "episode 12, policy loss -0.503294050693512\n",
      "\n",
      "episode 13, policy loss -0.5032989382743835\n",
      "\n",
      "episode 14, policy loss -0.5032966136932373\n",
      "\n",
      "episode 15, policy loss -0.5032970309257507\n",
      "\n",
      "episode 16, policy loss -0.5032966732978821\n",
      "\n",
      "Policy train loss in epoch 1:-0.5032964535057545\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.5032997727394104\n",
      "\n",
      "episode 2, policy loss -0.5032933354377747\n",
      "\n",
      "episode 3, policy loss -0.503294825553894\n",
      "\n",
      "episode 4, policy loss -0.5032967925071716\n",
      "\n",
      "episode 5, policy loss -0.5032966732978821\n",
      "\n",
      "episode 6, policy loss -0.5032914280891418\n",
      "\n",
      "episode 7, policy loss -0.503294050693512\n",
      "\n",
      "episode 8, policy loss -0.5032991766929626\n",
      "\n",
      "episode 9, policy loss -0.5032998323440552\n",
      "\n",
      "episode 10, policy loss -0.5032986402511597\n",
      "\n",
      "episode 11, policy loss -0.5032989978790283\n",
      "\n",
      "episode 12, policy loss -0.5032960176467896\n",
      "\n",
      "episode 13, policy loss -0.5032970905303955\n",
      "\n",
      "episode 14, policy loss -0.5032957792282104\n",
      "\n",
      "episode 15, policy loss -0.5032958984375\n",
      "\n",
      "episode 16, policy loss -0.5032957792282104\n",
      "\n",
      "Policy train loss in epoch 2:-0.5032965056598186\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.5032958388328552\n",
      "\n",
      "episode 2, policy loss -0.5032958388328552\n",
      "\n",
      "episode 3, policy loss -0.5032958984375\n",
      "\n",
      "episode 4, policy loss -0.5032913684844971\n",
      "\n",
      "episode 5, policy loss -0.5032990574836731\n",
      "\n",
      "episode 6, policy loss -0.5032939910888672\n",
      "\n",
      "episode 7, policy loss -0.5032966136932373\n",
      "\n",
      "episode 8, policy loss -0.5032985210418701\n",
      "\n",
      "episode 9, policy loss -0.503294825553894\n",
      "\n",
      "episode 10, policy loss -0.5032960176467896\n",
      "\n",
      "episode 11, policy loss -0.5032997727394104\n",
      "\n",
      "episode 12, policy loss -0.5032997727394104\n",
      "\n",
      "episode 13, policy loss -0.5032991766929626\n",
      "\n",
      "episode 14, policy loss -0.5032932758331299\n",
      "\n",
      "episode 15, policy loss -0.5032966136932373\n",
      "\n",
      "episode 16, policy loss -0.5032970905303955\n",
      "\n",
      "Policy train loss in epoch 3:-0.5032964795827866\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.100903034210205\n",
      "\n",
      "episode 2, val func loss 2.1587538719177246\n",
      "\n",
      "episode 3, val func loss 2.072484016418457\n",
      "\n",
      "episode 4, val func loss 2.159698486328125\n",
      "\n",
      "episode 5, val func loss 2.034909248352051\n",
      "\n",
      "episode 6, val func loss 1.998935580253601\n",
      "\n",
      "episode 7, val func loss 1.958000898361206\n",
      "\n",
      "episode 8, val func loss 1.9595824480056763\n",
      "\n",
      "episode 9, val func loss 1.8759236335754395\n",
      "\n",
      "episode 10, val func loss 1.9028165340423584\n",
      "\n",
      "episode 11, val func loss 2.004246711730957\n",
      "\n",
      "episode 12, val func loss 1.9824687242507935\n",
      "\n",
      "episode 13, val func loss 2.563321113586426\n",
      "\n",
      "episode 14, val func loss 4.161895275115967\n",
      "\n",
      "episode 15, val func loss 2.475292682647705\n",
      "\n",
      "episode 16, val func loss 2.5893852710723877\n",
      "\n",
      "Val func train loss in epoch 0:2.2499135956168175\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 3.1845452785491943\n",
      "\n",
      "episode 2, val func loss 2.2785468101501465\n",
      "\n",
      "episode 3, val func loss 2.2268283367156982\n",
      "\n",
      "episode 4, val func loss 2.742067813873291\n",
      "\n",
      "episode 5, val func loss 2.4085097312927246\n",
      "\n",
      "episode 6, val func loss 2.2044100761413574\n",
      "\n",
      "episode 7, val func loss 2.5297789573669434\n",
      "\n",
      "episode 8, val func loss 2.2324655055999756\n",
      "\n",
      "episode 9, val func loss 2.2946994304656982\n",
      "\n",
      "episode 10, val func loss 2.438997745513916\n",
      "\n",
      "episode 11, val func loss 2.352473258972168\n",
      "\n",
      "episode 12, val func loss 2.222118854522705\n",
      "\n",
      "episode 13, val func loss 2.3756911754608154\n",
      "\n",
      "episode 14, val func loss 2.1681268215179443\n",
      "\n",
      "episode 15, val func loss 2.278789758682251\n",
      "\n",
      "episode 16, val func loss 2.255628824234009\n",
      "\n",
      "Val func train loss in epoch 1:2.3871048986911774\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.152937650680542\n",
      "\n",
      "episode 2, val func loss 2.100834846496582\n",
      "\n",
      "episode 3, val func loss 2.2390918731689453\n",
      "\n",
      "episode 4, val func loss 2.010903835296631\n",
      "\n",
      "episode 5, val func loss 2.1608312129974365\n",
      "\n",
      "episode 6, val func loss 2.0809788703918457\n",
      "\n",
      "episode 7, val func loss 2.0170302391052246\n",
      "\n",
      "episode 8, val func loss 2.1863112449645996\n",
      "\n",
      "episode 9, val func loss 1.9653929471969604\n",
      "\n",
      "episode 10, val func loss 2.1280882358551025\n",
      "\n",
      "episode 11, val func loss 2.1546528339385986\n",
      "\n",
      "episode 12, val func loss 2.084263324737549\n",
      "\n",
      "episode 13, val func loss 2.196427822113037\n",
      "\n",
      "episode 14, val func loss 1.9139132499694824\n",
      "\n",
      "episode 15, val func loss 2.1089932918548584\n",
      "\n",
      "episode 16, val func loss 1.9679920673370361\n",
      "\n",
      "Val func train loss in epoch 2:2.091790221631527\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.162654399871826\n",
      "\n",
      "episode 2, val func loss 1.9825695753097534\n",
      "\n",
      "episode 3, val func loss 1.8313674926757812\n",
      "\n",
      "episode 4, val func loss 1.9337407350540161\n",
      "\n",
      "episode 5, val func loss 1.9465229511260986\n",
      "\n",
      "episode 6, val func loss 2.0046885013580322\n",
      "\n",
      "episode 7, val func loss 2.199690818786621\n",
      "\n",
      "episode 8, val func loss 1.8746185302734375\n",
      "\n",
      "episode 9, val func loss 1.9866759777069092\n",
      "\n",
      "episode 10, val func loss 1.9815337657928467\n",
      "\n",
      "episode 11, val func loss 1.9172594547271729\n",
      "\n",
      "episode 12, val func loss 2.0158615112304688\n",
      "\n",
      "episode 13, val func loss 1.8728044033050537\n",
      "\n",
      "episode 14, val func loss 1.9371201992034912\n",
      "\n",
      "episode 15, val func loss 1.8428860902786255\n",
      "\n",
      "episode 16, val func loss 1.764823317527771\n",
      "\n",
      "Val func train loss in epoch 3:1.953426107764244\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.9033854007720947\n",
      "\n",
      "episode 2, val func loss 1.8744094371795654\n",
      "\n",
      "episode 3, val func loss 2.1727540493011475\n",
      "\n",
      "episode 4, val func loss 2.449336290359497\n",
      "\n",
      "episode 5, val func loss 1.906645655632019\n",
      "\n",
      "episode 6, val func loss 2.17576003074646\n",
      "\n",
      "episode 7, val func loss 2.390205144882202\n",
      "\n",
      "episode 8, val func loss 1.8960461616516113\n",
      "\n",
      "episode 9, val func loss 2.667300224304199\n",
      "\n",
      "episode 10, val func loss 1.8976829051971436\n",
      "\n",
      "episode 11, val func loss 2.0547516345977783\n",
      "\n",
      "episode 12, val func loss 2.148087501525879\n",
      "\n",
      "episode 13, val func loss 2.3319573402404785\n",
      "\n",
      "episode 14, val func loss 2.1710622310638428\n",
      "\n",
      "episode 15, val func loss 2.2258331775665283\n",
      "\n",
      "episode 16, val func loss 2.0783395767211914\n",
      "\n",
      "Val func train loss in epoch 4:2.1464722976088524\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 2.0947911739349365\n",
      "\n",
      "episode 2, val func loss 2.0549020767211914\n",
      "\n",
      "episode 3, val func loss 1.9763535261154175\n",
      "\n",
      "episode 4, val func loss 2.0937891006469727\n",
      "\n",
      "episode 5, val func loss 2.103795289993286\n",
      "\n",
      "episode 6, val func loss 1.9491198062896729\n",
      "\n",
      "episode 7, val func loss 1.8652228116989136\n",
      "\n",
      "episode 8, val func loss 1.9625252485275269\n",
      "\n",
      "episode 9, val func loss 1.8126775026321411\n",
      "\n",
      "episode 10, val func loss 1.715332269668579\n",
      "\n",
      "episode 11, val func loss 1.738377332687378\n",
      "\n",
      "episode 12, val func loss 1.7783541679382324\n",
      "\n",
      "episode 13, val func loss 1.9020644426345825\n",
      "\n",
      "episode 14, val func loss 1.5967473983764648\n",
      "\n",
      "episode 15, val func loss 1.8069454431533813\n",
      "\n",
      "episode 16, val func loss 1.7877975702285767\n",
      "\n",
      "Val func train loss in epoch 5:1.8899246975779533\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 3.106748580932617\n",
      "\n",
      "episode 2, val func loss 3.1157352924346924\n",
      "\n",
      "episode 3, val func loss 26.57372283935547\n",
      "\n",
      "episode 4, val func loss 9.650045394897461\n",
      "\n",
      "episode 5, val func loss 14.433830261230469\n",
      "\n",
      "episode 6, val func loss 8.845817565917969\n",
      "\n",
      "episode 7, val func loss 3.068690538406372\n",
      "\n",
      "episode 8, val func loss 3.8474373817443848\n",
      "\n",
      "episode 9, val func loss 7.358039855957031\n",
      "\n",
      "episode 10, val func loss 6.105674743652344\n",
      "\n",
      "episode 11, val func loss 3.310164213180542\n",
      "\n",
      "episode 12, val func loss 2.339937925338745\n",
      "\n",
      "episode 13, val func loss 3.1895599365234375\n",
      "\n",
      "episode 14, val func loss 3.8721280097961426\n",
      "\n",
      "episode 15, val func loss 3.286113977432251\n",
      "\n",
      "episode 16, val func loss 2.396425485610962\n",
      "\n",
      "Val func train loss in epoch 6:6.5312545001506805\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 2.4420273303985596\n",
      "\n",
      "episode 2, val func loss 3.2395684719085693\n",
      "\n",
      "episode 3, val func loss 3.126490831375122\n",
      "\n",
      "episode 4, val func loss 2.518498420715332\n",
      "\n",
      "episode 5, val func loss 2.3625495433807373\n",
      "\n",
      "episode 6, val func loss 2.5634679794311523\n",
      "\n",
      "episode 7, val func loss 2.8462607860565186\n",
      "\n",
      "episode 8, val func loss 2.681534767150879\n",
      "\n",
      "episode 9, val func loss 2.367652654647827\n",
      "\n",
      "episode 10, val func loss 2.2863669395446777\n",
      "\n",
      "episode 11, val func loss 2.577253580093384\n",
      "\n",
      "episode 12, val func loss 2.6107962131500244\n",
      "\n",
      "episode 13, val func loss 2.503079891204834\n",
      "\n",
      "episode 14, val func loss 2.290938138961792\n",
      "\n",
      "episode 15, val func loss 2.340559720993042\n",
      "\n",
      "episode 16, val func loss 2.444908857345581\n",
      "\n",
      "Val func train loss in epoch 7:2.575122132897377\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.527010917663574\n",
      "\n",
      "episode 2, val func loss 2.411451578140259\n",
      "\n",
      "episode 3, val func loss 2.316168785095215\n",
      "\n",
      "episode 4, val func loss 2.321753978729248\n",
      "\n",
      "episode 5, val func loss 2.3869802951812744\n",
      "\n",
      "episode 6, val func loss 2.457502603530884\n",
      "\n",
      "episode 7, val func loss 2.31657338142395\n",
      "\n",
      "episode 8, val func loss 2.295116424560547\n",
      "\n",
      "episode 9, val func loss 2.3677632808685303\n",
      "\n",
      "episode 10, val func loss 2.377110719680786\n",
      "\n",
      "episode 11, val func loss 2.3245091438293457\n",
      "\n",
      "episode 12, val func loss 2.3642969131469727\n",
      "\n",
      "episode 13, val func loss 2.32153582572937\n",
      "\n",
      "episode 14, val func loss 2.3966197967529297\n",
      "\n",
      "episode 15, val func loss 2.342275857925415\n",
      "\n",
      "episode 16, val func loss 2.371453046798706\n",
      "\n",
      "Val func train loss in epoch 8:2.368632659316063\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 2.365818977355957\n",
      "\n",
      "episode 2, val func loss 2.3513693809509277\n",
      "\n",
      "episode 3, val func loss 2.306763172149658\n",
      "\n",
      "episode 4, val func loss 2.3608155250549316\n",
      "\n",
      "episode 5, val func loss 2.3699774742126465\n",
      "\n",
      "episode 6, val func loss 2.316248655319214\n",
      "\n",
      "episode 7, val func loss 2.3170292377471924\n",
      "\n",
      "episode 8, val func loss 2.3923447132110596\n",
      "\n",
      "episode 9, val func loss 2.3576278686523438\n",
      "\n",
      "episode 10, val func loss 2.3105452060699463\n",
      "\n",
      "episode 11, val func loss 2.3667492866516113\n",
      "\n",
      "episode 12, val func loss 2.252561092376709\n",
      "\n",
      "episode 13, val func loss 2.374755620956421\n",
      "\n",
      "episode 14, val func loss 2.3066608905792236\n",
      "\n",
      "episode 15, val func loss 2.2955880165100098\n",
      "\n",
      "episode 16, val func loss 2.311370849609375\n",
      "\n",
      "Val func train loss in epoch 9:2.3347641229629517\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.366262435913086\n",
      "\n",
      "episode 2, val func loss 2.3051037788391113\n",
      "\n",
      "episode 3, val func loss 2.3008835315704346\n",
      "\n",
      "episode 4, val func loss 2.3118860721588135\n",
      "\n",
      "episode 5, val func loss 2.38215970993042\n",
      "\n",
      "episode 6, val func loss 2.3479530811309814\n",
      "\n",
      "episode 7, val func loss 2.3082478046417236\n",
      "\n",
      "episode 8, val func loss 2.4117026329040527\n",
      "\n",
      "episode 9, val func loss 2.3462276458740234\n",
      "\n",
      "episode 10, val func loss 2.320157289505005\n",
      "\n",
      "episode 11, val func loss 2.273967981338501\n",
      "\n",
      "episode 12, val func loss 2.345284938812256\n",
      "\n",
      "episode 13, val func loss 2.347852945327759\n",
      "\n",
      "episode 14, val func loss 2.359654188156128\n",
      "\n",
      "episode 15, val func loss 2.283555507659912\n",
      "\n",
      "episode 16, val func loss 2.3299317359924316\n",
      "\n",
      "Val func train loss in epoch 10:2.333801954984665\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 2.3838038444519043\n",
      "\n",
      "episode 2, val func loss 2.3316738605499268\n",
      "\n",
      "episode 3, val func loss 2.327763795852661\n",
      "\n",
      "episode 4, val func loss 2.3547091484069824\n",
      "\n",
      "episode 5, val func loss 2.3261234760284424\n",
      "\n",
      "episode 6, val func loss 2.2587244510650635\n",
      "\n",
      "episode 7, val func loss 2.3942413330078125\n",
      "\n",
      "episode 8, val func loss 2.3753035068511963\n",
      "\n",
      "episode 9, val func loss 2.2833290100097656\n",
      "\n",
      "episode 10, val func loss 2.3126726150512695\n",
      "\n",
      "episode 11, val func loss 2.326850414276123\n",
      "\n",
      "episode 12, val func loss 2.280543088912964\n",
      "\n",
      "episode 13, val func loss 2.337682008743286\n",
      "\n",
      "episode 14, val func loss 2.285651206970215\n",
      "\n",
      "episode 15, val func loss 2.3515050411224365\n",
      "\n",
      "episode 16, val func loss 2.3021490573883057\n",
      "\n",
      "Val func train loss in epoch 11:2.327045366168022\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 2.3202922344207764\n",
      "\n",
      "episode 2, val func loss 2.240732431411743\n",
      "\n",
      "episode 3, val func loss 2.2737178802490234\n",
      "\n",
      "episode 4, val func loss 2.3768105506896973\n",
      "\n",
      "episode 5, val func loss 2.371340036392212\n",
      "\n",
      "episode 6, val func loss 2.3364222049713135\n",
      "\n",
      "episode 7, val func loss 2.315723180770874\n",
      "\n",
      "episode 8, val func loss 2.330454111099243\n",
      "\n",
      "episode 9, val func loss 2.311267137527466\n",
      "\n",
      "episode 10, val func loss 2.2824995517730713\n",
      "\n",
      "episode 11, val func loss 2.3492963314056396\n",
      "\n",
      "episode 12, val func loss 2.305103063583374\n",
      "\n",
      "episode 13, val func loss 2.2723076343536377\n",
      "\n",
      "episode 14, val func loss 2.3884024620056152\n",
      "\n",
      "episode 15, val func loss 2.3520021438598633\n",
      "\n",
      "episode 16, val func loss 2.2973883152008057\n",
      "\n",
      "Val func train loss in epoch 12:2.320234954357147\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 2.3333795070648193\n",
      "\n",
      "episode 2, val func loss 2.2868528366088867\n",
      "\n",
      "episode 3, val func loss 2.296427011489868\n",
      "\n",
      "episode 4, val func loss 2.410264253616333\n",
      "\n",
      "episode 5, val func loss 2.287882089614868\n",
      "\n",
      "episode 6, val func loss 2.313265562057495\n",
      "\n",
      "episode 7, val func loss 2.3104281425476074\n",
      "\n",
      "episode 8, val func loss 2.2819204330444336\n",
      "\n",
      "episode 9, val func loss 2.2773470878601074\n",
      "\n",
      "episode 10, val func loss 2.3587775230407715\n",
      "\n",
      "episode 11, val func loss 2.332735776901245\n",
      "\n",
      "episode 12, val func loss 2.3389761447906494\n",
      "\n",
      "episode 13, val func loss 2.294175863265991\n",
      "\n",
      "episode 14, val func loss 2.347374439239502\n",
      "\n",
      "episode 15, val func loss 2.36910080909729\n",
      "\n",
      "episode 16, val func loss 2.359740734100342\n",
      "\n",
      "Val func train loss in epoch 13:2.324915513396263\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.287259578704834\n",
      "\n",
      "episode 2, val func loss 2.2780864238739014\n",
      "\n",
      "episode 3, val func loss 2.3157541751861572\n",
      "\n",
      "episode 4, val func loss 2.3411712646484375\n",
      "\n",
      "episode 5, val func loss 2.35019850730896\n",
      "\n",
      "episode 6, val func loss 2.372896432876587\n",
      "\n",
      "episode 7, val func loss 2.286672830581665\n",
      "\n",
      "episode 8, val func loss 2.291349411010742\n",
      "\n",
      "episode 9, val func loss 2.351546287536621\n",
      "\n",
      "episode 10, val func loss 2.331425189971924\n",
      "\n",
      "episode 11, val func loss 2.276883125305176\n",
      "\n",
      "episode 12, val func loss 2.3439900875091553\n",
      "\n",
      "episode 13, val func loss 2.307654619216919\n",
      "\n",
      "episode 14, val func loss 2.3646938800811768\n",
      "\n",
      "episode 15, val func loss 2.3333868980407715\n",
      "\n",
      "episode 16, val func loss 2.304142951965332\n",
      "\n",
      "Val func train loss in epoch 14:2.3210694789886475\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.3325438499450684\n",
      "\n",
      "episode 2, val func loss 2.349658489227295\n",
      "\n",
      "episode 3, val func loss 2.336984157562256\n",
      "\n",
      "episode 4, val func loss 2.3660123348236084\n",
      "\n",
      "episode 5, val func loss 2.2748396396636963\n",
      "\n",
      "episode 6, val func loss 2.310401201248169\n",
      "\n",
      "episode 7, val func loss 2.331866979598999\n",
      "\n",
      "episode 8, val func loss 2.406794786453247\n",
      "\n",
      "episode 9, val func loss 2.3074769973754883\n",
      "\n",
      "episode 10, val func loss 2.305745840072632\n",
      "\n",
      "episode 11, val func loss 2.3627476692199707\n",
      "\n",
      "episode 12, val func loss 2.244436025619507\n",
      "\n",
      "episode 13, val func loss 2.2782516479492188\n",
      "\n",
      "episode 14, val func loss 2.2988672256469727\n",
      "\n",
      "episode 15, val func loss 2.2842016220092773\n",
      "\n",
      "episode 16, val func loss 2.274847984313965\n",
      "\n",
      "Val func train loss in epoch 15:2.3166047781705856\n",
      "***********************TIME WAS 5.1338209986686705 min*****************************\n",
      "\n",
      "**********************ROUND 9 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.8823903203010559\n",
      "\n",
      "episode 2, policy loss -0.8823904395103455\n",
      "\n",
      "episode 3, policy loss -0.8823904395103455\n",
      "\n",
      "episode 4, policy loss -0.8823904395103455\n",
      "\n",
      "episode 5, policy loss -0.8823902010917664\n",
      "\n",
      "episode 6, policy loss -0.8823903203010559\n",
      "\n",
      "episode 7, policy loss -0.8823904395103455\n",
      "\n",
      "episode 8, policy loss -0.8823902010917664\n",
      "\n",
      "episode 9, policy loss -0.8823902010917664\n",
      "\n",
      "episode 10, policy loss -0.8823902606964111\n",
      "\n",
      "episode 11, policy loss -0.8823902010917664\n",
      "\n",
      "episode 12, policy loss -0.8823902010917664\n",
      "\n",
      "episode 13, policy loss -0.8823904991149902\n",
      "\n",
      "episode 14, policy loss -0.8823903203010559\n",
      "\n",
      "episode 15, policy loss -0.8823904395103455\n",
      "\n",
      "episode 16, policy loss -0.8823902606964111\n",
      "\n",
      "Policy train loss in epoch 0:-0.8823903240263462\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.8823904991149902\n",
      "\n",
      "episode 2, policy loss -0.8823903203010559\n",
      "\n",
      "episode 3, policy loss -0.8823904395103455\n",
      "\n",
      "episode 4, policy loss -0.8823902010917664\n",
      "\n",
      "episode 5, policy loss -0.8823903203010559\n",
      "\n",
      "episode 6, policy loss -0.8823900818824768\n",
      "\n",
      "episode 7, policy loss -0.8823902606964111\n",
      "\n",
      "episode 8, policy loss -0.8823906183242798\n",
      "\n",
      "episode 9, policy loss -0.8823903203010559\n",
      "\n",
      "episode 10, policy loss -0.8823903203010559\n",
      "\n",
      "episode 11, policy loss -0.8823902606964111\n",
      "\n",
      "episode 12, policy loss -0.8823904991149902\n",
      "\n",
      "episode 13, policy loss -0.8823900818824768\n",
      "\n",
      "episode 14, policy loss -0.8823900818824768\n",
      "\n",
      "episode 15, policy loss -0.8823903203010559\n",
      "\n",
      "episode 16, policy loss -0.8823902606964111\n",
      "\n",
      "Policy train loss in epoch 1:-0.8823903053998947\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.8823902606964111\n",
      "\n",
      "episode 2, policy loss -0.8823902010917664\n",
      "\n",
      "episode 3, policy loss -0.8823903203010559\n",
      "\n",
      "episode 4, policy loss -0.8823904991149902\n",
      "\n",
      "episode 5, policy loss -0.8823903203010559\n",
      "\n",
      "episode 6, policy loss -0.8823903203010559\n",
      "\n",
      "episode 7, policy loss -0.8823903203010559\n",
      "\n",
      "episode 8, policy loss -0.8823902010917664\n",
      "\n",
      "episode 9, policy loss -0.8823903203010559\n",
      "\n",
      "episode 10, policy loss -0.8823902010917664\n",
      "\n",
      "episode 11, policy loss -0.8823900818824768\n",
      "\n",
      "episode 12, policy loss -0.8823902606964111\n",
      "\n",
      "episode 13, policy loss -0.8823903799057007\n",
      "\n",
      "episode 14, policy loss -0.8823903203010559\n",
      "\n",
      "episode 15, policy loss -0.8823903203010559\n",
      "\n",
      "episode 16, policy loss -0.8823904395103455\n",
      "\n",
      "Policy train loss in epoch 2:-0.8823902979493141\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.882390022277832\n",
      "\n",
      "episode 2, policy loss -0.8823906183242798\n",
      "\n",
      "episode 3, policy loss -0.8823904395103455\n",
      "\n",
      "episode 4, policy loss -0.8823904395103455\n",
      "\n",
      "episode 5, policy loss -0.882390558719635\n",
      "\n",
      "episode 6, policy loss -0.8823904395103455\n",
      "\n",
      "episode 7, policy loss -0.8823902010917664\n",
      "\n",
      "episode 8, policy loss -0.8823903203010559\n",
      "\n",
      "episode 9, policy loss -0.8823904991149902\n",
      "\n",
      "episode 10, policy loss -0.8823903203010559\n",
      "\n",
      "episode 11, policy loss -0.8823902606964111\n",
      "\n",
      "episode 12, policy loss -0.8823902606964111\n",
      "\n",
      "episode 13, policy loss -0.8823902010917664\n",
      "\n",
      "episode 14, policy loss -0.8823904395103455\n",
      "\n",
      "episode 15, policy loss -0.8823902606964111\n",
      "\n",
      "episode 16, policy loss -0.8823901414871216\n",
      "\n",
      "Policy train loss in epoch 3:-0.8823903389275074\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.3388659954071045\n",
      "\n",
      "episode 2, val func loss 2.306743860244751\n",
      "\n",
      "episode 3, val func loss 2.3295998573303223\n",
      "\n",
      "episode 4, val func loss 2.338153123855591\n",
      "\n",
      "episode 5, val func loss 2.2386374473571777\n",
      "\n",
      "episode 6, val func loss 2.3189690113067627\n",
      "\n",
      "episode 7, val func loss 2.2605202198028564\n",
      "\n",
      "episode 8, val func loss 2.2799370288848877\n",
      "\n",
      "episode 9, val func loss 2.32624888420105\n",
      "\n",
      "episode 10, val func loss 2.2181127071380615\n",
      "\n",
      "episode 11, val func loss 2.2714409828186035\n",
      "\n",
      "episode 12, val func loss 2.3033833503723145\n",
      "\n",
      "episode 13, val func loss 2.2924716472625732\n",
      "\n",
      "episode 14, val func loss 2.299490213394165\n",
      "\n",
      "episode 15, val func loss 2.382075071334839\n",
      "\n",
      "episode 16, val func loss 2.3196191787719727\n",
      "\n",
      "Val func train loss in epoch 0:2.3015167862176895\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.2663514614105225\n",
      "\n",
      "episode 2, val func loss 2.313788652420044\n",
      "\n",
      "episode 3, val func loss 2.2819485664367676\n",
      "\n",
      "episode 4, val func loss 2.2495367527008057\n",
      "\n",
      "episode 5, val func loss 2.1961889266967773\n",
      "\n",
      "episode 6, val func loss 2.250936269760132\n",
      "\n",
      "episode 7, val func loss 2.1965315341949463\n",
      "\n",
      "episode 8, val func loss 2.2150533199310303\n",
      "\n",
      "episode 9, val func loss 2.320239782333374\n",
      "\n",
      "episode 10, val func loss 2.2255537509918213\n",
      "\n",
      "episode 11, val func loss 2.2393434047698975\n",
      "\n",
      "episode 12, val func loss 2.3289825916290283\n",
      "\n",
      "episode 13, val func loss 2.254737377166748\n",
      "\n",
      "episode 14, val func loss 2.2103078365325928\n",
      "\n",
      "episode 15, val func loss 2.1891396045684814\n",
      "\n",
      "episode 16, val func loss 2.17672061920166\n",
      "\n",
      "Val func train loss in epoch 1:2.2447100281715393\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.200819253921509\n",
      "\n",
      "episode 2, val func loss 2.2282979488372803\n",
      "\n",
      "episode 3, val func loss 2.1713085174560547\n",
      "\n",
      "episode 4, val func loss 2.1653339862823486\n",
      "\n",
      "episode 5, val func loss 2.0715219974517822\n",
      "\n",
      "episode 6, val func loss 2.1493442058563232\n",
      "\n",
      "episode 7, val func loss 2.11006760597229\n",
      "\n",
      "episode 8, val func loss 2.2008001804351807\n",
      "\n",
      "episode 9, val func loss 2.015566110610962\n",
      "\n",
      "episode 10, val func loss 2.1402266025543213\n",
      "\n",
      "episode 11, val func loss 2.1337382793426514\n",
      "\n",
      "episode 12, val func loss 2.2510390281677246\n",
      "\n",
      "episode 13, val func loss 2.4090187549591064\n",
      "\n",
      "episode 14, val func loss 4.287390232086182\n",
      "\n",
      "episode 15, val func loss 3.2136170864105225\n",
      "\n",
      "episode 16, val func loss 6.77267599105835\n",
      "\n",
      "Val func train loss in epoch 2:2.6575478613376617\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 3.0593454837799072\n",
      "\n",
      "episode 2, val func loss 5.934091567993164\n",
      "\n",
      "episode 3, val func loss 2.4817633628845215\n",
      "\n",
      "episode 4, val func loss 4.824106693267822\n",
      "\n",
      "episode 5, val func loss 2.9522719383239746\n",
      "\n",
      "episode 6, val func loss 2.8556599617004395\n",
      "\n",
      "episode 7, val func loss 3.797802448272705\n",
      "\n",
      "episode 8, val func loss 2.6633877754211426\n",
      "\n",
      "episode 9, val func loss 2.5531673431396484\n",
      "\n",
      "episode 10, val func loss 3.3069801330566406\n",
      "\n",
      "episode 11, val func loss 2.740802526473999\n",
      "\n",
      "episode 12, val func loss 2.298189878463745\n",
      "\n",
      "episode 13, val func loss 2.8763043880462646\n",
      "\n",
      "episode 14, val func loss 2.7308197021484375\n",
      "\n",
      "episode 15, val func loss 2.381528377532959\n",
      "\n",
      "episode 16, val func loss 2.622450351715088\n",
      "\n",
      "Val func train loss in epoch 3:3.1299169957637787\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.622091293334961\n",
      "\n",
      "episode 2, val func loss 2.3916614055633545\n",
      "\n",
      "episode 3, val func loss 2.4242050647735596\n",
      "\n",
      "episode 4, val func loss 2.504579782485962\n",
      "\n",
      "episode 5, val func loss 2.4445433616638184\n",
      "\n",
      "episode 6, val func loss 2.35052752494812\n",
      "\n",
      "episode 7, val func loss 2.466656446456909\n",
      "\n",
      "episode 8, val func loss 2.487475872039795\n",
      "\n",
      "episode 9, val func loss 2.366316080093384\n",
      "\n",
      "episode 10, val func loss 2.2736263275146484\n",
      "\n",
      "episode 11, val func loss 2.3996267318725586\n",
      "\n",
      "episode 12, val func loss 2.403318405151367\n",
      "\n",
      "episode 13, val func loss 2.354509115219116\n",
      "\n",
      "episode 14, val func loss 2.3087825775146484\n",
      "\n",
      "episode 15, val func loss 2.374678373336792\n",
      "\n",
      "episode 16, val func loss 2.3705601692199707\n",
      "\n",
      "Val func train loss in epoch 4:2.4089474081993103\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 2.3001792430877686\n",
      "\n",
      "episode 2, val func loss 2.3258795738220215\n",
      "\n",
      "episode 3, val func loss 2.378495693206787\n",
      "\n",
      "episode 4, val func loss 2.292922258377075\n",
      "\n",
      "episode 5, val func loss 2.359787702560425\n",
      "\n",
      "episode 6, val func loss 2.3934552669525146\n",
      "\n",
      "episode 7, val func loss 2.3420958518981934\n",
      "\n",
      "episode 8, val func loss 2.3490407466888428\n",
      "\n",
      "episode 9, val func loss 2.320120096206665\n",
      "\n",
      "episode 10, val func loss 2.3237783908843994\n",
      "\n",
      "episode 11, val func loss 2.2549867630004883\n",
      "\n",
      "episode 12, val func loss 2.34598445892334\n",
      "\n",
      "episode 13, val func loss 2.305515766143799\n",
      "\n",
      "episode 14, val func loss 2.3480093479156494\n",
      "\n",
      "episode 15, val func loss 2.3748619556427\n",
      "\n",
      "episode 16, val func loss 2.3320541381835938\n",
      "\n",
      "Val func train loss in epoch 5:2.3341979533433914\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.3166677951812744\n",
      "\n",
      "episode 2, val func loss 2.272944688796997\n",
      "\n",
      "episode 3, val func loss 2.3487226963043213\n",
      "\n",
      "episode 4, val func loss 2.2873730659484863\n",
      "\n",
      "episode 5, val func loss 2.3310787677764893\n",
      "\n",
      "episode 6, val func loss 2.3397748470306396\n",
      "\n",
      "episode 7, val func loss 2.2732770442962646\n",
      "\n",
      "episode 8, val func loss 2.2624542713165283\n",
      "\n",
      "episode 9, val func loss 2.2622432708740234\n",
      "\n",
      "episode 10, val func loss 2.3545186519622803\n",
      "\n",
      "episode 11, val func loss 2.2802817821502686\n",
      "\n",
      "episode 12, val func loss 2.2741713523864746\n",
      "\n",
      "episode 13, val func loss 2.329493999481201\n",
      "\n",
      "episode 14, val func loss 2.2923920154571533\n",
      "\n",
      "episode 15, val func loss 2.2141435146331787\n",
      "\n",
      "episode 16, val func loss 2.266738176345825\n",
      "\n",
      "Val func train loss in epoch 6:2.294142246246338\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 2.2996983528137207\n",
      "\n",
      "episode 2, val func loss 2.2845983505249023\n",
      "\n",
      "episode 3, val func loss 2.315369129180908\n",
      "\n",
      "episode 4, val func loss 2.326225519180298\n",
      "\n",
      "episode 5, val func loss 2.3334174156188965\n",
      "\n",
      "episode 6, val func loss 2.351872682571411\n",
      "\n",
      "episode 7, val func loss 2.258406400680542\n",
      "\n",
      "episode 8, val func loss 2.2816882133483887\n",
      "\n",
      "episode 9, val func loss 2.253985643386841\n",
      "\n",
      "episode 10, val func loss 2.3222358226776123\n",
      "\n",
      "episode 11, val func loss 2.25411057472229\n",
      "\n",
      "episode 12, val func loss 2.4026429653167725\n",
      "\n",
      "episode 13, val func loss 2.2399063110351562\n",
      "\n",
      "episode 14, val func loss 2.2730908393859863\n",
      "\n",
      "episode 15, val func loss 2.2983531951904297\n",
      "\n",
      "episode 16, val func loss 2.2478830814361572\n",
      "\n",
      "Val func train loss in epoch 7:2.2964677810668945\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.295637607574463\n",
      "\n",
      "episode 2, val func loss 2.3303487300872803\n",
      "\n",
      "episode 3, val func loss 2.2459027767181396\n",
      "\n",
      "episode 4, val func loss 2.3157777786254883\n",
      "\n",
      "episode 5, val func loss 2.1787898540496826\n",
      "\n",
      "episode 6, val func loss 2.2573885917663574\n",
      "\n",
      "episode 7, val func loss 2.2547664642333984\n",
      "\n",
      "episode 8, val func loss 2.23518967628479\n",
      "\n",
      "episode 9, val func loss 2.204920768737793\n",
      "\n",
      "episode 10, val func loss 2.3044400215148926\n",
      "\n",
      "episode 11, val func loss 2.213702917098999\n",
      "\n",
      "episode 12, val func loss 2.313298225402832\n",
      "\n",
      "episode 13, val func loss 2.2107203006744385\n",
      "\n",
      "episode 14, val func loss 2.1911351680755615\n",
      "\n",
      "episode 15, val func loss 2.2378499507904053\n",
      "\n",
      "episode 16, val func loss 2.276777982711792\n",
      "\n",
      "Val func train loss in epoch 8:2.2541654258966446\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 2.2309467792510986\n",
      "\n",
      "episode 2, val func loss 2.2395193576812744\n",
      "\n",
      "episode 3, val func loss 2.2869467735290527\n",
      "\n",
      "episode 4, val func loss 2.2292892932891846\n",
      "\n",
      "episode 5, val func loss 2.236616373062134\n",
      "\n",
      "episode 6, val func loss 2.256035566329956\n",
      "\n",
      "episode 7, val func loss 2.282909631729126\n",
      "\n",
      "episode 8, val func loss 2.209005117416382\n",
      "\n",
      "episode 9, val func loss 2.246603012084961\n",
      "\n",
      "episode 10, val func loss 2.2475829124450684\n",
      "\n",
      "episode 11, val func loss 2.2365386486053467\n",
      "\n",
      "episode 12, val func loss 2.2370762825012207\n",
      "\n",
      "episode 13, val func loss 2.1412036418914795\n",
      "\n",
      "episode 14, val func loss 2.1786177158355713\n",
      "\n",
      "episode 15, val func loss 2.3224785327911377\n",
      "\n",
      "episode 16, val func loss 2.270111560821533\n",
      "\n",
      "Val func train loss in epoch 9:2.240717574954033\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.4061458110809326\n",
      "\n",
      "episode 2, val func loss 2.179903268814087\n",
      "\n",
      "episode 3, val func loss 2.2681665420532227\n",
      "\n",
      "episode 4, val func loss 2.1587064266204834\n",
      "\n",
      "episode 5, val func loss 2.141756772994995\n",
      "\n",
      "episode 6, val func loss 2.1943204402923584\n",
      "\n",
      "episode 7, val func loss 2.1628241539001465\n",
      "\n",
      "episode 8, val func loss 2.097553014755249\n",
      "\n",
      "episode 9, val func loss 2.1073198318481445\n",
      "\n",
      "episode 10, val func loss 2.13346004486084\n",
      "\n",
      "episode 11, val func loss 2.275670289993286\n",
      "\n",
      "episode 12, val func loss 2.1435630321502686\n",
      "\n",
      "episode 13, val func loss 2.2418782711029053\n",
      "\n",
      "episode 14, val func loss 2.173963785171509\n",
      "\n",
      "episode 15, val func loss 2.2541301250457764\n",
      "\n",
      "episode 16, val func loss 2.1277475357055664\n",
      "\n",
      "Val func train loss in epoch 10:2.1916943341493607\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 2.1872217655181885\n",
      "\n",
      "episode 2, val func loss 2.254107713699341\n",
      "\n",
      "episode 3, val func loss 2.1675987243652344\n",
      "\n",
      "episode 4, val func loss 2.237579822540283\n",
      "\n",
      "episode 5, val func loss 2.2404608726501465\n",
      "\n",
      "episode 6, val func loss 2.104010581970215\n",
      "\n",
      "episode 7, val func loss 2.2553608417510986\n",
      "\n",
      "episode 8, val func loss 2.2564172744750977\n",
      "\n",
      "episode 9, val func loss 2.083883047103882\n",
      "\n",
      "episode 10, val func loss 2.0801291465759277\n",
      "\n",
      "episode 11, val func loss 2.1043877601623535\n",
      "\n",
      "episode 12, val func loss 2.1024169921875\n",
      "\n",
      "episode 13, val func loss 2.0682687759399414\n",
      "\n",
      "episode 14, val func loss 2.232654094696045\n",
      "\n",
      "episode 15, val func loss 2.061282157897949\n",
      "\n",
      "episode 16, val func loss 2.18821382522583\n",
      "\n",
      "Val func train loss in epoch 11:2.1639995872974396\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 2.060539484024048\n",
      "\n",
      "episode 2, val func loss 1.9845867156982422\n",
      "\n",
      "episode 3, val func loss 2.065150499343872\n",
      "\n",
      "episode 4, val func loss 1.9749524593353271\n",
      "\n",
      "episode 5, val func loss 2.0284531116485596\n",
      "\n",
      "episode 6, val func loss 1.882155418395996\n",
      "\n",
      "episode 7, val func loss 1.9426026344299316\n",
      "\n",
      "episode 8, val func loss 2.0023045539855957\n",
      "\n",
      "episode 9, val func loss 1.7955670356750488\n",
      "\n",
      "episode 10, val func loss 2.132580280303955\n",
      "\n",
      "episode 11, val func loss 2.058007001876831\n",
      "\n",
      "episode 12, val func loss 2.5525565147399902\n",
      "\n",
      "episode 13, val func loss 2.4295477867126465\n",
      "\n",
      "episode 14, val func loss 23.246078491210938\n",
      "\n",
      "episode 15, val func loss 9.863496780395508\n",
      "\n",
      "episode 16, val func loss 8.002687454223633\n",
      "\n",
      "Val func train loss in epoch 12:4.251329138875008\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 17.63495445251465\n",
      "\n",
      "episode 2, val func loss 4.818238258361816\n",
      "\n",
      "episode 3, val func loss 5.323194980621338\n",
      "\n",
      "episode 4, val func loss 10.005006790161133\n",
      "\n",
      "episode 5, val func loss 6.090533256530762\n",
      "\n",
      "episode 6, val func loss 2.5861423015594482\n",
      "\n",
      "episode 7, val func loss 4.718378067016602\n",
      "\n",
      "episode 8, val func loss 6.278110027313232\n",
      "\n",
      "episode 9, val func loss 4.49465799331665\n",
      "\n",
      "episode 10, val func loss 2.453465461730957\n",
      "\n",
      "episode 11, val func loss 3.469693899154663\n",
      "\n",
      "episode 12, val func loss 4.430158615112305\n",
      "\n",
      "episode 13, val func loss 4.218446254730225\n",
      "\n",
      "episode 14, val func loss 3.0283660888671875\n",
      "\n",
      "episode 15, val func loss 2.4111227989196777\n",
      "\n",
      "episode 16, val func loss 3.0403032302856445\n",
      "\n",
      "Val func train loss in epoch 13:5.312548279762268\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 3.6783013343811035\n",
      "\n",
      "episode 2, val func loss 3.26898193359375\n",
      "\n",
      "episode 3, val func loss 2.652923345565796\n",
      "\n",
      "episode 4, val func loss 2.4246227741241455\n",
      "\n",
      "episode 5, val func loss 2.6843550205230713\n",
      "\n",
      "episode 6, val func loss 2.9708032608032227\n",
      "\n",
      "episode 7, val func loss 2.9576616287231445\n",
      "\n",
      "episode 8, val func loss 2.523167610168457\n",
      "\n",
      "episode 9, val func loss 2.324847459793091\n",
      "\n",
      "episode 10, val func loss 2.6402525901794434\n",
      "\n",
      "episode 11, val func loss 2.725154161453247\n",
      "\n",
      "episode 12, val func loss 2.6531786918640137\n",
      "\n",
      "episode 13, val func loss 2.4881629943847656\n",
      "\n",
      "episode 14, val func loss 2.3260915279388428\n",
      "\n",
      "episode 15, val func loss 2.4207751750946045\n",
      "\n",
      "episode 16, val func loss 2.5849504470825195\n",
      "\n",
      "Val func train loss in epoch 14:2.707764372229576\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.5069236755371094\n",
      "\n",
      "episode 2, val func loss 2.305858850479126\n",
      "\n",
      "episode 3, val func loss 2.338045358657837\n",
      "\n",
      "episode 4, val func loss 2.491943836212158\n",
      "\n",
      "episode 5, val func loss 2.445047378540039\n",
      "\n",
      "episode 6, val func loss 2.4180028438568115\n",
      "\n",
      "episode 7, val func loss 2.3137214183807373\n",
      "\n",
      "episode 8, val func loss 2.4311184883117676\n",
      "\n",
      "episode 9, val func loss 2.424860715866089\n",
      "\n",
      "episode 10, val func loss 2.4404237270355225\n",
      "\n",
      "episode 11, val func loss 2.303870916366577\n",
      "\n",
      "episode 12, val func loss 2.4286322593688965\n",
      "\n",
      "episode 13, val func loss 2.352503538131714\n",
      "\n",
      "episode 14, val func loss 2.491041898727417\n",
      "\n",
      "episode 15, val func loss 2.4165146350860596\n",
      "\n",
      "episode 16, val func loss 2.3651199340820312\n",
      "\n",
      "Val func train loss in epoch 15:2.4046018421649933\n",
      "***********************TIME WAS 5.130060772101085 min*****************************\n",
      "\n",
      "**********************ROUND 10 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.6492706537246704\n",
      "\n",
      "episode 2, policy loss -0.6492710709571838\n",
      "\n",
      "episode 3, policy loss -0.6492708325386047\n",
      "\n",
      "episode 4, policy loss -0.6492713093757629\n",
      "\n",
      "episode 5, policy loss -0.6492704153060913\n",
      "\n",
      "episode 6, policy loss -0.6492717266082764\n",
      "\n",
      "episode 7, policy loss -0.6492710113525391\n",
      "\n",
      "episode 8, policy loss -0.6492705345153809\n",
      "\n",
      "episode 9, policy loss -0.6492717862129211\n",
      "\n",
      "episode 10, policy loss -0.6492705345153809\n",
      "\n",
      "episode 11, policy loss -0.64927077293396\n",
      "\n",
      "episode 12, policy loss -0.6492704153060913\n",
      "\n",
      "episode 13, policy loss -0.6492704749107361\n",
      "\n",
      "episode 14, policy loss -0.6492700576782227\n",
      "\n",
      "episode 15, policy loss -0.6492719650268555\n",
      "\n",
      "episode 16, policy loss -0.6492704749107361\n",
      "\n",
      "Policy train loss in epoch 0:-0.6492708772420883\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.6492699980735779\n",
      "\n",
      "episode 2, policy loss -0.6492704749107361\n",
      "\n",
      "episode 3, policy loss -0.6492717862129211\n",
      "\n",
      "episode 4, policy loss -0.6492717266082764\n",
      "\n",
      "episode 5, policy loss -0.6492711305618286\n",
      "\n",
      "episode 6, policy loss -0.6492705345153809\n",
      "\n",
      "episode 7, policy loss -0.6492704749107361\n",
      "\n",
      "episode 8, policy loss -0.6492720246315002\n",
      "\n",
      "episode 9, policy loss -0.6492711305618286\n",
      "\n",
      "episode 10, policy loss -0.6492710709571838\n",
      "\n",
      "episode 11, policy loss -0.6492705941200256\n",
      "\n",
      "episode 12, policy loss -0.6492704749107361\n",
      "\n",
      "episode 13, policy loss -0.6492708921432495\n",
      "\n",
      "episode 14, policy loss -0.6492703557014465\n",
      "\n",
      "episode 15, policy loss -0.6492706537246704\n",
      "\n",
      "episode 16, policy loss -0.6492705941200256\n",
      "\n",
      "Policy train loss in epoch 1:-0.6492708697915077\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.6492707133293152\n",
      "\n",
      "episode 2, policy loss -0.6492710709571838\n",
      "\n",
      "episode 3, policy loss -0.6492705345153809\n",
      "\n",
      "episode 4, policy loss -0.6492719650268555\n",
      "\n",
      "episode 5, policy loss -0.6492706537246704\n",
      "\n",
      "episode 6, policy loss -0.6492705345153809\n",
      "\n",
      "episode 7, policy loss -0.6492704153060913\n",
      "\n",
      "episode 8, policy loss -0.6492704749107361\n",
      "\n",
      "episode 9, policy loss -0.6492699384689331\n",
      "\n",
      "episode 10, policy loss -0.6492708921432495\n",
      "\n",
      "episode 11, policy loss -0.6492711305618286\n",
      "\n",
      "episode 12, policy loss -0.6492710709571838\n",
      "\n",
      "episode 13, policy loss -0.6492704153060913\n",
      "\n",
      "episode 14, policy loss -0.6492704153060913\n",
      "\n",
      "episode 15, policy loss -0.6492716670036316\n",
      "\n",
      "episode 16, policy loss -0.6492717266082764\n",
      "\n",
      "Policy train loss in epoch 2:-0.6492708511650562\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.6492710113525391\n",
      "\n",
      "episode 2, policy loss -0.6492712497711182\n",
      "\n",
      "episode 3, policy loss -0.6492704749107361\n",
      "\n",
      "episode 4, policy loss -0.6492708325386047\n",
      "\n",
      "episode 5, policy loss -0.6492703557014465\n",
      "\n",
      "episode 6, policy loss -0.6492700576782227\n",
      "\n",
      "episode 7, policy loss -0.6492705345153809\n",
      "\n",
      "episode 8, policy loss -0.6492717862129211\n",
      "\n",
      "episode 9, policy loss -0.6492705345153809\n",
      "\n",
      "episode 10, policy loss -0.6492710113525391\n",
      "\n",
      "episode 11, policy loss -0.6492704749107361\n",
      "\n",
      "episode 12, policy loss -0.6492717862129211\n",
      "\n",
      "episode 13, policy loss -0.6492706537246704\n",
      "\n",
      "episode 14, policy loss -0.6492705345153809\n",
      "\n",
      "episode 15, policy loss -0.64927077293396\n",
      "\n",
      "episode 16, policy loss -0.6492718458175659\n",
      "\n",
      "Policy train loss in epoch 3:-0.6492708697915077\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.306781053543091\n",
      "\n",
      "episode 2, val func loss 2.2693188190460205\n",
      "\n",
      "episode 3, val func loss 2.304070234298706\n",
      "\n",
      "episode 4, val func loss 2.3708865642547607\n",
      "\n",
      "episode 5, val func loss 2.3899683952331543\n",
      "\n",
      "episode 6, val func loss 2.41441011428833\n",
      "\n",
      "episode 7, val func loss 2.349094867706299\n",
      "\n",
      "episode 8, val func loss 2.344499349594116\n",
      "\n",
      "episode 9, val func loss 2.3586204051971436\n",
      "\n",
      "episode 10, val func loss 2.346544027328491\n",
      "\n",
      "episode 11, val func loss 2.391385555267334\n",
      "\n",
      "episode 12, val func loss 2.336409330368042\n",
      "\n",
      "episode 13, val func loss 2.3528835773468018\n",
      "\n",
      "episode 14, val func loss 2.3688530921936035\n",
      "\n",
      "episode 15, val func loss 2.375741481781006\n",
      "\n",
      "episode 16, val func loss 2.3195443153381348\n",
      "\n",
      "Val func train loss in epoch 0:2.3499381989240646\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.3170251846313477\n",
      "\n",
      "episode 2, val func loss 2.3594462871551514\n",
      "\n",
      "episode 3, val func loss 2.3339998722076416\n",
      "\n",
      "episode 4, val func loss 2.2570903301239014\n",
      "\n",
      "episode 5, val func loss 2.319770097732544\n",
      "\n",
      "episode 6, val func loss 2.3051085472106934\n",
      "\n",
      "episode 7, val func loss 2.334589719772339\n",
      "\n",
      "episode 8, val func loss 2.316795825958252\n",
      "\n",
      "episode 9, val func loss 2.26894474029541\n",
      "\n",
      "episode 10, val func loss 2.34584379196167\n",
      "\n",
      "episode 11, val func loss 2.3626322746276855\n",
      "\n",
      "episode 12, val func loss 2.332184314727783\n",
      "\n",
      "episode 13, val func loss 2.332892417907715\n",
      "\n",
      "episode 14, val func loss 2.296980381011963\n",
      "\n",
      "episode 15, val func loss 2.2091989517211914\n",
      "\n",
      "episode 16, val func loss 2.3272011280059814\n",
      "\n",
      "Val func train loss in epoch 1:2.3137314915657043\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.3103222846984863\n",
      "\n",
      "episode 2, val func loss 2.3489797115325928\n",
      "\n",
      "episode 3, val func loss 2.244492769241333\n",
      "\n",
      "episode 4, val func loss 2.32358455657959\n",
      "\n",
      "episode 5, val func loss 2.282388925552368\n",
      "\n",
      "episode 6, val func loss 2.2698864936828613\n",
      "\n",
      "episode 7, val func loss 2.368945598602295\n",
      "\n",
      "episode 8, val func loss 2.328270673751831\n",
      "\n",
      "episode 9, val func loss 2.2615034580230713\n",
      "\n",
      "episode 10, val func loss 2.258777141571045\n",
      "\n",
      "episode 11, val func loss 2.2144224643707275\n",
      "\n",
      "episode 12, val func loss 2.23551607131958\n",
      "\n",
      "episode 13, val func loss 2.293919086456299\n",
      "\n",
      "episode 14, val func loss 2.2781245708465576\n",
      "\n",
      "episode 15, val func loss 2.2629942893981934\n",
      "\n",
      "episode 16, val func loss 2.2223575115203857\n",
      "\n",
      "Val func train loss in epoch 2:2.281530350446701\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.3667023181915283\n",
      "\n",
      "episode 2, val func loss 2.3253214359283447\n",
      "\n",
      "episode 3, val func loss 2.2405917644500732\n",
      "\n",
      "episode 4, val func loss 2.3114235401153564\n",
      "\n",
      "episode 5, val func loss 2.3152108192443848\n",
      "\n",
      "episode 6, val func loss 2.2734899520874023\n",
      "\n",
      "episode 7, val func loss 2.3162457942962646\n",
      "\n",
      "episode 8, val func loss 2.268383502960205\n",
      "\n",
      "episode 9, val func loss 2.2700130939483643\n",
      "\n",
      "episode 10, val func loss 2.269322156906128\n",
      "\n",
      "episode 11, val func loss 2.3769736289978027\n",
      "\n",
      "episode 12, val func loss 2.3447868824005127\n",
      "\n",
      "episode 13, val func loss 2.3012945652008057\n",
      "\n",
      "episode 14, val func loss 2.3142874240875244\n",
      "\n",
      "episode 15, val func loss 2.2115237712860107\n",
      "\n",
      "episode 16, val func loss 2.3065316677093506\n",
      "\n",
      "Val func train loss in epoch 3:2.3007563948631287\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.24823260307312\n",
      "\n",
      "episode 2, val func loss 2.217545986175537\n",
      "\n",
      "episode 3, val func loss 2.248992919921875\n",
      "\n",
      "episode 4, val func loss 2.326711893081665\n",
      "\n",
      "episode 5, val func loss 2.2413127422332764\n",
      "\n",
      "episode 6, val func loss 2.252520799636841\n",
      "\n",
      "episode 7, val func loss 2.284431219100952\n",
      "\n",
      "episode 8, val func loss 2.1391210556030273\n",
      "\n",
      "episode 9, val func loss 2.3418936729431152\n",
      "\n",
      "episode 10, val func loss 2.2407798767089844\n",
      "\n",
      "episode 11, val func loss 2.2870662212371826\n",
      "\n",
      "episode 12, val func loss 2.2360222339630127\n",
      "\n",
      "episode 13, val func loss 2.1969237327575684\n",
      "\n",
      "episode 14, val func loss 2.1623713970184326\n",
      "\n",
      "episode 15, val func loss 2.2311012744903564\n",
      "\n",
      "episode 16, val func loss 2.212480306625366\n",
      "\n",
      "Val func train loss in epoch 4:2.2417192459106445\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 2.15474534034729\n",
      "\n",
      "episode 2, val func loss 2.2093570232391357\n",
      "\n",
      "episode 3, val func loss 2.155524253845215\n",
      "\n",
      "episode 4, val func loss 2.1886096000671387\n",
      "\n",
      "episode 5, val func loss 2.268768787384033\n",
      "\n",
      "episode 6, val func loss 2.1323039531707764\n",
      "\n",
      "episode 7, val func loss 2.236771583557129\n",
      "\n",
      "episode 8, val func loss 2.2543399333953857\n",
      "\n",
      "episode 9, val func loss 2.2122538089752197\n",
      "\n",
      "episode 10, val func loss 2.2297768592834473\n",
      "\n",
      "episode 11, val func loss 2.094284772872925\n",
      "\n",
      "episode 12, val func loss 2.1437299251556396\n",
      "\n",
      "episode 13, val func loss 2.2100701332092285\n",
      "\n",
      "episode 14, val func loss 2.1835789680480957\n",
      "\n",
      "episode 15, val func loss 2.2336156368255615\n",
      "\n",
      "episode 16, val func loss 2.144270658493042\n",
      "\n",
      "Val func train loss in epoch 5:2.190750077366829\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.070019006729126\n",
      "\n",
      "episode 2, val func loss 2.1745920181274414\n",
      "\n",
      "episode 3, val func loss 2.1190145015716553\n",
      "\n",
      "episode 4, val func loss 2.2276604175567627\n",
      "\n",
      "episode 5, val func loss 2.150010585784912\n",
      "\n",
      "episode 6, val func loss 2.158822536468506\n",
      "\n",
      "episode 7, val func loss 1.940178394317627\n",
      "\n",
      "episode 8, val func loss 2.209885597229004\n",
      "\n",
      "episode 9, val func loss 2.0559489727020264\n",
      "\n",
      "episode 10, val func loss 2.0437538623809814\n",
      "\n",
      "episode 11, val func loss 1.9609718322753906\n",
      "\n",
      "episode 12, val func loss 2.112484931945801\n",
      "\n",
      "episode 13, val func loss 2.153151273727417\n",
      "\n",
      "episode 14, val func loss 2.141535997390747\n",
      "\n",
      "episode 15, val func loss 2.1548678874969482\n",
      "\n",
      "episode 16, val func loss 1.991464376449585\n",
      "\n",
      "Val func train loss in epoch 6:2.1040226370096207\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 2.0095415115356445\n",
      "\n",
      "episode 2, val func loss 2.1769540309906006\n",
      "\n",
      "episode 3, val func loss 1.9566963911056519\n",
      "\n",
      "episode 4, val func loss 2.037724018096924\n",
      "\n",
      "episode 5, val func loss 2.2815003395080566\n",
      "\n",
      "episode 6, val func loss 1.9753217697143555\n",
      "\n",
      "episode 7, val func loss 2.0628437995910645\n",
      "\n",
      "episode 8, val func loss 1.9887508153915405\n",
      "\n",
      "episode 9, val func loss 2.0391979217529297\n",
      "\n",
      "episode 10, val func loss 1.9902608394622803\n",
      "\n",
      "episode 11, val func loss 2.0443177223205566\n",
      "\n",
      "episode 12, val func loss 1.9615906476974487\n",
      "\n",
      "episode 13, val func loss 2.174043655395508\n",
      "\n",
      "episode 14, val func loss 1.9257590770721436\n",
      "\n",
      "episode 15, val func loss 1.9814521074295044\n",
      "\n",
      "episode 16, val func loss 1.9560723304748535\n",
      "\n",
      "Val func train loss in epoch 7:2.0351266860961914\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.085357666015625\n",
      "\n",
      "episode 2, val func loss 2.0559451580047607\n",
      "\n",
      "episode 3, val func loss 2.0733370780944824\n",
      "\n",
      "episode 4, val func loss 1.9629309177398682\n",
      "\n",
      "episode 5, val func loss 2.0316812992095947\n",
      "\n",
      "episode 6, val func loss 2.057758092880249\n",
      "\n",
      "episode 7, val func loss 1.7515151500701904\n",
      "\n",
      "episode 8, val func loss 2.059403896331787\n",
      "\n",
      "episode 9, val func loss 2.065023422241211\n",
      "\n",
      "episode 10, val func loss 1.9887032508850098\n",
      "\n",
      "episode 11, val func loss 2.119551658630371\n",
      "\n",
      "episode 12, val func loss 1.7703546285629272\n",
      "\n",
      "episode 13, val func loss 2.1852023601531982\n",
      "\n",
      "episode 14, val func loss 2.017209529876709\n",
      "\n",
      "episode 15, val func loss 1.7668778896331787\n",
      "\n",
      "episode 16, val func loss 1.9539941549301147\n",
      "\n",
      "Val func train loss in epoch 8:1.9965528845787048\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.7880858182907104\n",
      "\n",
      "episode 2, val func loss 1.8810999393463135\n",
      "\n",
      "episode 3, val func loss 1.9921338558197021\n",
      "\n",
      "episode 4, val func loss 2.100022554397583\n",
      "\n",
      "episode 5, val func loss 2.1139020919799805\n",
      "\n",
      "episode 6, val func loss 1.8601512908935547\n",
      "\n",
      "episode 7, val func loss 1.9633241891860962\n",
      "\n",
      "episode 8, val func loss 1.7870746850967407\n",
      "\n",
      "episode 9, val func loss 1.8719552755355835\n",
      "\n",
      "episode 10, val func loss 1.83169686794281\n",
      "\n",
      "episode 11, val func loss 1.8004117012023926\n",
      "\n",
      "episode 12, val func loss 1.7248363494873047\n",
      "\n",
      "episode 13, val func loss 1.8240015506744385\n",
      "\n",
      "episode 14, val func loss 1.9929753541946411\n",
      "\n",
      "episode 15, val func loss 1.9322075843811035\n",
      "\n",
      "episode 16, val func loss 1.6470803022384644\n",
      "\n",
      "Val func train loss in epoch 9:1.8819349631667137\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.56347393989563\n",
      "\n",
      "episode 2, val func loss 1.873792290687561\n",
      "\n",
      "episode 3, val func loss 2.0723929405212402\n",
      "\n",
      "episode 4, val func loss 2.1321802139282227\n",
      "\n",
      "episode 5, val func loss 2.846733570098877\n",
      "\n",
      "episode 6, val func loss 1.8313655853271484\n",
      "\n",
      "episode 7, val func loss 2.6218321323394775\n",
      "\n",
      "episode 8, val func loss 1.8114805221557617\n",
      "\n",
      "episode 9, val func loss 2.352762460708618\n",
      "\n",
      "episode 10, val func loss 2.074068307876587\n",
      "\n",
      "episode 11, val func loss 2.0579111576080322\n",
      "\n",
      "episode 12, val func loss 2.1068599224090576\n",
      "\n",
      "episode 13, val func loss 1.97773015499115\n",
      "\n",
      "episode 14, val func loss 1.8892351388931274\n",
      "\n",
      "episode 15, val func loss 2.0407655239105225\n",
      "\n",
      "episode 16, val func loss 2.2431459426879883\n",
      "\n",
      "Val func train loss in epoch 10:2.1559831127524376\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.690194010734558\n",
      "\n",
      "episode 2, val func loss 2.489496946334839\n",
      "\n",
      "episode 3, val func loss 1.9100176095962524\n",
      "\n",
      "episode 4, val func loss 1.9645475149154663\n",
      "\n",
      "episode 5, val func loss 2.22684645652771\n",
      "\n",
      "episode 6, val func loss 2.1671812534332275\n",
      "\n",
      "episode 7, val func loss 2.5614640712738037\n",
      "\n",
      "episode 8, val func loss 4.136682987213135\n",
      "\n",
      "episode 9, val func loss 2.2572269439697266\n",
      "\n",
      "episode 10, val func loss 4.770336151123047\n",
      "\n",
      "episode 11, val func loss 2.5436601638793945\n",
      "\n",
      "episode 12, val func loss 2.184614419937134\n",
      "\n",
      "episode 13, val func loss 5.275810241699219\n",
      "\n",
      "episode 14, val func loss 2.5600552558898926\n",
      "\n",
      "episode 15, val func loss 3.97363018989563\n",
      "\n",
      "episode 16, val func loss 3.177645206451416\n",
      "\n",
      "Val func train loss in epoch 11:2.868088088929653\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 2.1855363845825195\n",
      "\n",
      "episode 2, val func loss 3.294347047805786\n",
      "\n",
      "episode 3, val func loss 3.5769646167755127\n",
      "\n",
      "episode 4, val func loss 2.450028419494629\n",
      "\n",
      "episode 5, val func loss 2.4080634117126465\n",
      "\n",
      "episode 6, val func loss 3.0816495418548584\n",
      "\n",
      "episode 7, val func loss 2.930647611618042\n",
      "\n",
      "episode 8, val func loss 2.370875597000122\n",
      "\n",
      "episode 9, val func loss 2.303865671157837\n",
      "\n",
      "episode 10, val func loss 2.667933225631714\n",
      "\n",
      "episode 11, val func loss 2.6652398109436035\n",
      "\n",
      "episode 12, val func loss 2.3248202800750732\n",
      "\n",
      "episode 13, val func loss 2.178602695465088\n",
      "\n",
      "episode 14, val func loss 2.469496011734009\n",
      "\n",
      "episode 15, val func loss 2.524158000946045\n",
      "\n",
      "episode 16, val func loss 2.2925760746002197\n",
      "\n",
      "Val func train loss in epoch 12:2.6078002750873566\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 2.190260648727417\n",
      "\n",
      "episode 2, val func loss 2.3674612045288086\n",
      "\n",
      "episode 3, val func loss 2.4399349689483643\n",
      "\n",
      "episode 4, val func loss 2.308320999145508\n",
      "\n",
      "episode 5, val func loss 2.1801669597625732\n",
      "\n",
      "episode 6, val func loss 2.3018977642059326\n",
      "\n",
      "episode 7, val func loss 2.393388271331787\n",
      "\n",
      "episode 8, val func loss 2.2622995376586914\n",
      "\n",
      "episode 9, val func loss 2.143679618835449\n",
      "\n",
      "episode 10, val func loss 2.29573130607605\n",
      "\n",
      "episode 11, val func loss 2.2910900115966797\n",
      "\n",
      "episode 12, val func loss 2.147791624069214\n",
      "\n",
      "episode 13, val func loss 2.1636197566986084\n",
      "\n",
      "episode 14, val func loss 2.2436723709106445\n",
      "\n",
      "episode 15, val func loss 2.3512356281280518\n",
      "\n",
      "episode 16, val func loss 2.2959697246551514\n",
      "\n",
      "Val func train loss in epoch 13:2.273532524704933\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.3482089042663574\n",
      "\n",
      "episode 2, val func loss 2.239525318145752\n",
      "\n",
      "episode 3, val func loss 2.2298789024353027\n",
      "\n",
      "episode 4, val func loss 2.228489875793457\n",
      "\n",
      "episode 5, val func loss 2.1539220809936523\n",
      "\n",
      "episode 6, val func loss 2.141958236694336\n",
      "\n",
      "episode 7, val func loss 2.214080572128296\n",
      "\n",
      "episode 8, val func loss 2.2226674556732178\n",
      "\n",
      "episode 9, val func loss 2.209139585494995\n",
      "\n",
      "episode 10, val func loss 2.171504497528076\n",
      "\n",
      "episode 11, val func loss 2.121166467666626\n",
      "\n",
      "episode 12, val func loss 2.06634521484375\n",
      "\n",
      "episode 13, val func loss 2.101465940475464\n",
      "\n",
      "episode 14, val func loss 2.1583592891693115\n",
      "\n",
      "episode 15, val func loss 2.128506898880005\n",
      "\n",
      "episode 16, val func loss 2.1568450927734375\n",
      "\n",
      "Val func train loss in epoch 14:2.1807540208101273\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.2797021865844727\n",
      "\n",
      "episode 2, val func loss 2.1671206951141357\n",
      "\n",
      "episode 3, val func loss 2.2025721073150635\n",
      "\n",
      "episode 4, val func loss 2.1294281482696533\n",
      "\n",
      "episode 5, val func loss 2.1241002082824707\n",
      "\n",
      "episode 6, val func loss 2.2083139419555664\n",
      "\n",
      "episode 7, val func loss 2.0502655506134033\n",
      "\n",
      "episode 8, val func loss 2.05880069732666\n",
      "\n",
      "episode 9, val func loss 2.0721170902252197\n",
      "\n",
      "episode 10, val func loss 1.9880739450454712\n",
      "\n",
      "episode 11, val func loss 2.1084980964660645\n",
      "\n",
      "episode 12, val func loss 2.0151145458221436\n",
      "\n",
      "episode 13, val func loss 1.8879461288452148\n",
      "\n",
      "episode 14, val func loss 2.0559816360473633\n",
      "\n",
      "episode 15, val func loss 2.0630011558532715\n",
      "\n",
      "episode 16, val func loss 2.0155045986175537\n",
      "\n",
      "Val func train loss in epoch 15:2.089158795773983\n",
      "***********************TIME WAS 5.121101792653402 min*****************************\n",
      "\n",
      "**********************ROUND 11 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -1.6161131858825684\n",
      "\n",
      "episode 2, policy loss -1.6161137819290161\n",
      "\n",
      "episode 3, policy loss -1.6161136627197266\n",
      "\n",
      "episode 4, policy loss -1.6161143779754639\n",
      "\n",
      "episode 5, policy loss -1.6161139011383057\n",
      "\n",
      "episode 6, policy loss -1.6161136627197266\n",
      "\n",
      "episode 7, policy loss -1.6161141395568848\n",
      "\n",
      "episode 8, policy loss -1.6161136627197266\n",
      "\n",
      "episode 9, policy loss -1.6161149740219116\n",
      "\n",
      "episode 10, policy loss -1.6161154508590698\n",
      "\n",
      "episode 11, policy loss -1.6161129474639893\n",
      "\n",
      "episode 12, policy loss -1.6161140203475952\n",
      "\n",
      "episode 13, policy loss -1.6161140203475952\n",
      "\n",
      "episode 14, policy loss -1.6161142587661743\n",
      "\n",
      "episode 15, policy loss -1.6161129474639893\n",
      "\n",
      "episode 16, policy loss -1.6161150932312012\n",
      "\n",
      "Policy train loss in epoch 0:-1.616114005446434\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -1.6161143779754639\n",
      "\n",
      "episode 2, policy loss -1.6161155700683594\n",
      "\n",
      "episode 3, policy loss -1.6161142587661743\n",
      "\n",
      "episode 4, policy loss -1.6161140203475952\n",
      "\n",
      "episode 5, policy loss -1.6161140203475952\n",
      "\n",
      "episode 6, policy loss -1.6161139011383057\n",
      "\n",
      "episode 7, policy loss -1.6161144971847534\n",
      "\n",
      "episode 8, policy loss -1.6161139011383057\n",
      "\n",
      "episode 9, policy loss -1.6161139011383057\n",
      "\n",
      "episode 10, policy loss -1.6161150932312012\n",
      "\n",
      "episode 11, policy loss -1.6161150932312012\n",
      "\n",
      "episode 12, policy loss -1.6161139011383057\n",
      "\n",
      "episode 13, policy loss -1.6161130666732788\n",
      "\n",
      "episode 14, policy loss -1.6161131858825684\n",
      "\n",
      "episode 15, policy loss -1.616113543510437\n",
      "\n",
      "episode 16, policy loss -1.6161147356033325\n",
      "\n",
      "Policy train loss in epoch 1:-1.616114191710949\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -1.6161142587661743\n",
      "\n",
      "episode 2, policy loss -1.6161153316497803\n",
      "\n",
      "episode 3, policy loss -1.6161141395568848\n",
      "\n",
      "episode 4, policy loss -1.616114616394043\n",
      "\n",
      "episode 5, policy loss -1.6161158084869385\n",
      "\n",
      "episode 6, policy loss -1.616113543510437\n",
      "\n",
      "episode 7, policy loss -1.616114854812622\n",
      "\n",
      "episode 8, policy loss -1.6161144971847534\n",
      "\n",
      "episode 9, policy loss -1.6161141395568848\n",
      "\n",
      "episode 10, policy loss -1.6161141395568848\n",
      "\n",
      "episode 11, policy loss -1.616113305091858\n",
      "\n",
      "episode 12, policy loss -1.6161153316497803\n",
      "\n",
      "episode 13, policy loss -1.6161130666732788\n",
      "\n",
      "episode 14, policy loss -1.6161141395568848\n",
      "\n",
      "episode 15, policy loss -1.616114854812622\n",
      "\n",
      "episode 16, policy loss -1.6161142587661743\n",
      "\n",
      "Policy train loss in epoch 2:-1.616114392876625\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -1.616115927696228\n",
      "\n",
      "episode 2, policy loss -1.6161144971847534\n",
      "\n",
      "episode 3, policy loss -1.6161153316497803\n",
      "\n",
      "episode 4, policy loss -1.6161144971847534\n",
      "\n",
      "episode 5, policy loss -1.6161140203475952\n",
      "\n",
      "episode 6, policy loss -1.6161136627197266\n",
      "\n",
      "episode 7, policy loss -1.6161144971847534\n",
      "\n",
      "episode 8, policy loss -1.616114854812622\n",
      "\n",
      "episode 9, policy loss -1.6161147356033325\n",
      "\n",
      "episode 10, policy loss -1.6161154508590698\n",
      "\n",
      "episode 11, policy loss -1.616113305091858\n",
      "\n",
      "episode 12, policy loss -1.616113305091858\n",
      "\n",
      "episode 13, policy loss -1.6161143779754639\n",
      "\n",
      "episode 14, policy loss -1.6161141395568848\n",
      "\n",
      "episode 15, policy loss -1.6161141395568848\n",
      "\n",
      "episode 16, policy loss -1.6161143779754639\n",
      "\n",
      "Policy train loss in epoch 3:-1.6161144450306892\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.0287091732025146\n",
      "\n",
      "episode 2, val func loss 2.05051851272583\n",
      "\n",
      "episode 3, val func loss 1.9990994930267334\n",
      "\n",
      "episode 4, val func loss 2.1212048530578613\n",
      "\n",
      "episode 5, val func loss 2.0528502464294434\n",
      "\n",
      "episode 6, val func loss 2.005385637283325\n",
      "\n",
      "episode 7, val func loss 1.9121787548065186\n",
      "\n",
      "episode 8, val func loss 2.018864154815674\n",
      "\n",
      "episode 9, val func loss 2.012171745300293\n",
      "\n",
      "episode 10, val func loss 2.0034842491149902\n",
      "\n",
      "episode 11, val func loss 1.821043610572815\n",
      "\n",
      "episode 12, val func loss 1.974916696548462\n",
      "\n",
      "episode 13, val func loss 1.9288206100463867\n",
      "\n",
      "episode 14, val func loss 1.8974062204360962\n",
      "\n",
      "episode 15, val func loss 1.8969653844833374\n",
      "\n",
      "episode 16, val func loss 1.7309565544128418\n",
      "\n",
      "Val func train loss in epoch 0:1.9659109935164452\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.8117125034332275\n",
      "\n",
      "episode 2, val func loss 1.7638291120529175\n",
      "\n",
      "episode 3, val func loss 1.5606409311294556\n",
      "\n",
      "episode 4, val func loss 1.6051820516586304\n",
      "\n",
      "episode 5, val func loss 1.8678579330444336\n",
      "\n",
      "episode 6, val func loss 1.8396872282028198\n",
      "\n",
      "episode 7, val func loss 1.7318774461746216\n",
      "\n",
      "episode 8, val func loss 1.6174061298370361\n",
      "\n",
      "episode 9, val func loss 1.5208369493484497\n",
      "\n",
      "episode 10, val func loss 1.7092500925064087\n",
      "\n",
      "episode 11, val func loss 1.6092125177383423\n",
      "\n",
      "episode 12, val func loss 1.9764082431793213\n",
      "\n",
      "episode 13, val func loss 1.4849112033843994\n",
      "\n",
      "episode 14, val func loss 1.742397665977478\n",
      "\n",
      "episode 15, val func loss 1.7599791288375854\n",
      "\n",
      "episode 16, val func loss 2.057886838912964\n",
      "\n",
      "Val func train loss in epoch 1:1.7286922484636307\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.7037742137908936\n",
      "\n",
      "episode 2, val func loss 2.2828493118286133\n",
      "\n",
      "episode 3, val func loss 1.6690901517868042\n",
      "\n",
      "episode 4, val func loss 2.041449546813965\n",
      "\n",
      "episode 5, val func loss 1.6098445653915405\n",
      "\n",
      "episode 6, val func loss 1.9932796955108643\n",
      "\n",
      "episode 7, val func loss 1.705098032951355\n",
      "\n",
      "episode 8, val func loss 2.6052887439727783\n",
      "\n",
      "episode 9, val func loss 4.719245433807373\n",
      "\n",
      "episode 10, val func loss 2.82296085357666\n",
      "\n",
      "episode 11, val func loss 5.036985874176025\n",
      "\n",
      "episode 12, val func loss 2.1851553916931152\n",
      "\n",
      "episode 13, val func loss 2.0270273685455322\n",
      "\n",
      "episode 14, val func loss 3.8974106311798096\n",
      "\n",
      "episode 15, val func loss 1.986503005027771\n",
      "\n",
      "episode 16, val func loss 3.0206985473632812\n",
      "\n",
      "Val func train loss in epoch 2:2.581666335463524\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.710669755935669\n",
      "\n",
      "episode 2, val func loss 2.0993995666503906\n",
      "\n",
      "episode 3, val func loss 2.514683246612549\n",
      "\n",
      "episode 4, val func loss 2.870339870452881\n",
      "\n",
      "episode 5, val func loss 2.3217804431915283\n",
      "\n",
      "episode 6, val func loss 2.0963151454925537\n",
      "\n",
      "episode 7, val func loss 2.3743889331817627\n",
      "\n",
      "episode 8, val func loss 2.3966095447540283\n",
      "\n",
      "episode 9, val func loss 2.287353277206421\n",
      "\n",
      "episode 10, val func loss 2.2603447437286377\n",
      "\n",
      "episode 11, val func loss 2.314861297607422\n",
      "\n",
      "episode 12, val func loss 2.4361021518707275\n",
      "\n",
      "episode 13, val func loss 2.275019884109497\n",
      "\n",
      "episode 14, val func loss 2.1511805057525635\n",
      "\n",
      "episode 15, val func loss 2.3116071224212646\n",
      "\n",
      "episode 16, val func loss 2.427090644836426\n",
      "\n",
      "Val func train loss in epoch 3:2.36548413336277\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.3007919788360596\n",
      "\n",
      "episode 2, val func loss 2.1515560150146484\n",
      "\n",
      "episode 3, val func loss 2.332735300064087\n",
      "\n",
      "episode 4, val func loss 2.203185558319092\n",
      "\n",
      "episode 5, val func loss 2.150674819946289\n",
      "\n",
      "episode 6, val func loss 2.305630683898926\n",
      "\n",
      "episode 7, val func loss 2.1557326316833496\n",
      "\n",
      "episode 8, val func loss 2.057326316833496\n",
      "\n",
      "episode 9, val func loss 2.0001795291900635\n",
      "\n",
      "episode 10, val func loss 2.1948904991149902\n",
      "\n",
      "episode 11, val func loss 2.1851396560668945\n",
      "\n",
      "episode 12, val func loss 2.127087116241455\n",
      "\n",
      "episode 13, val func loss 2.006277561187744\n",
      "\n",
      "episode 14, val func loss 2.0142693519592285\n",
      "\n",
      "episode 15, val func loss 2.143627882003784\n",
      "\n",
      "episode 16, val func loss 2.0711333751678467\n",
      "\n",
      "Val func train loss in epoch 4:2.150014892220497\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.9918047189712524\n",
      "\n",
      "episode 2, val func loss 2.03059720993042\n",
      "\n",
      "episode 3, val func loss 2.0097241401672363\n",
      "\n",
      "episode 4, val func loss 1.9891347885131836\n",
      "\n",
      "episode 5, val func loss 2.1750001907348633\n",
      "\n",
      "episode 6, val func loss 2.14375638961792\n",
      "\n",
      "episode 7, val func loss 2.0707855224609375\n",
      "\n",
      "episode 8, val func loss 1.9093884229660034\n",
      "\n",
      "episode 9, val func loss 2.087184190750122\n",
      "\n",
      "episode 10, val func loss 1.97073495388031\n",
      "\n",
      "episode 11, val func loss 2.168792486190796\n",
      "\n",
      "episode 12, val func loss 1.9888455867767334\n",
      "\n",
      "episode 13, val func loss 1.8424949645996094\n",
      "\n",
      "episode 14, val func loss 1.8886959552764893\n",
      "\n",
      "episode 15, val func loss 2.0647168159484863\n",
      "\n",
      "episode 16, val func loss 1.9048007726669312\n",
      "\n",
      "Val func train loss in epoch 5:2.014778569340706\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.036882162094116\n",
      "\n",
      "episode 2, val func loss 1.9457014799118042\n",
      "\n",
      "episode 3, val func loss 1.8475613594055176\n",
      "\n",
      "episode 4, val func loss 1.9072766304016113\n",
      "\n",
      "episode 5, val func loss 2.0336904525756836\n",
      "\n",
      "episode 6, val func loss 1.7692127227783203\n",
      "\n",
      "episode 7, val func loss 1.7529945373535156\n",
      "\n",
      "episode 8, val func loss 1.8258416652679443\n",
      "\n",
      "episode 9, val func loss 1.9479830265045166\n",
      "\n",
      "episode 10, val func loss 1.7508397102355957\n",
      "\n",
      "episode 11, val func loss 1.8936693668365479\n",
      "\n",
      "episode 12, val func loss 1.8368971347808838\n",
      "\n",
      "episode 13, val func loss 1.7592252492904663\n",
      "\n",
      "episode 14, val func loss 1.8325579166412354\n",
      "\n",
      "episode 15, val func loss 1.7634530067443848\n",
      "\n",
      "episode 16, val func loss 1.6769742965698242\n",
      "\n",
      "Val func train loss in epoch 6:1.848797544836998\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.8093901872634888\n",
      "\n",
      "episode 2, val func loss 1.659322738647461\n",
      "\n",
      "episode 3, val func loss 1.5941369533538818\n",
      "\n",
      "episode 4, val func loss 1.7574948072433472\n",
      "\n",
      "episode 5, val func loss 1.5985187292099\n",
      "\n",
      "episode 6, val func loss 1.7537901401519775\n",
      "\n",
      "episode 7, val func loss 1.819679617881775\n",
      "\n",
      "episode 8, val func loss 1.7530159950256348\n",
      "\n",
      "episode 9, val func loss 1.836823582649231\n",
      "\n",
      "episode 10, val func loss 1.5014622211456299\n",
      "\n",
      "episode 11, val func loss 1.6416959762573242\n",
      "\n",
      "episode 12, val func loss 1.9321627616882324\n",
      "\n",
      "episode 13, val func loss 1.9662644863128662\n",
      "\n",
      "episode 14, val func loss 2.107517957687378\n",
      "\n",
      "episode 15, val func loss 1.5009435415267944\n",
      "\n",
      "episode 16, val func loss 2.4773049354553223\n",
      "\n",
      "Val func train loss in epoch 7:1.7943452894687653\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.0870039463043213\n",
      "\n",
      "episode 2, val func loss 2.2145614624023438\n",
      "\n",
      "episode 3, val func loss 1.9114018678665161\n",
      "\n",
      "episode 4, val func loss 1.997753381729126\n",
      "\n",
      "episode 5, val func loss 1.6486448049545288\n",
      "\n",
      "episode 6, val func loss 1.6383213996887207\n",
      "\n",
      "episode 7, val func loss 1.8542287349700928\n",
      "\n",
      "episode 8, val func loss 1.6955515146255493\n",
      "\n",
      "episode 9, val func loss 1.78363037109375\n",
      "\n",
      "episode 10, val func loss 1.735952377319336\n",
      "\n",
      "episode 11, val func loss 1.6924949884414673\n",
      "\n",
      "episode 12, val func loss 1.7569406032562256\n",
      "\n",
      "episode 13, val func loss 1.6035057306289673\n",
      "\n",
      "episode 14, val func loss 1.6045781373977661\n",
      "\n",
      "episode 15, val func loss 1.6565886735916138\n",
      "\n",
      "episode 16, val func loss 1.6637160778045654\n",
      "\n",
      "Val func train loss in epoch 8:1.7840546295046806\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.571685791015625\n",
      "\n",
      "episode 2, val func loss 1.8976876735687256\n",
      "\n",
      "episode 3, val func loss 1.5469410419464111\n",
      "\n",
      "episode 4, val func loss 1.5443795919418335\n",
      "\n",
      "episode 5, val func loss 1.7794824838638306\n",
      "\n",
      "episode 6, val func loss 1.8256800174713135\n",
      "\n",
      "episode 7, val func loss 1.6870293617248535\n",
      "\n",
      "episode 8, val func loss 1.6282685995101929\n",
      "\n",
      "episode 9, val func loss 1.7061101198196411\n",
      "\n",
      "episode 10, val func loss 1.6077719926834106\n",
      "\n",
      "episode 11, val func loss 1.7631912231445312\n",
      "\n",
      "episode 12, val func loss 1.6263182163238525\n",
      "\n",
      "episode 13, val func loss 1.7617626190185547\n",
      "\n",
      "episode 14, val func loss 1.7777183055877686\n",
      "\n",
      "episode 15, val func loss 1.8123654127120972\n",
      "\n",
      "episode 16, val func loss 1.704297661781311\n",
      "\n",
      "Val func train loss in epoch 9:1.702543132007122\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.9937031269073486\n",
      "\n",
      "episode 2, val func loss 1.7217732667922974\n",
      "\n",
      "episode 3, val func loss 1.411582589149475\n",
      "\n",
      "episode 4, val func loss 1.523661732673645\n",
      "\n",
      "episode 5, val func loss 1.792083740234375\n",
      "\n",
      "episode 6, val func loss 1.7044336795806885\n",
      "\n",
      "episode 7, val func loss 1.8089598417282104\n",
      "\n",
      "episode 8, val func loss 1.99912428855896\n",
      "\n",
      "episode 9, val func loss 1.9513471126556396\n",
      "\n",
      "episode 10, val func loss 1.539754867553711\n",
      "\n",
      "episode 11, val func loss 1.5366101264953613\n",
      "\n",
      "episode 12, val func loss 1.7633205652236938\n",
      "\n",
      "episode 13, val func loss 1.7911317348480225\n",
      "\n",
      "episode 14, val func loss 1.7499468326568604\n",
      "\n",
      "episode 15, val func loss 1.5354710817337036\n",
      "\n",
      "episode 16, val func loss 1.5193873643875122\n",
      "\n",
      "Val func train loss in epoch 10:1.708893246948719\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.480042576789856\n",
      "\n",
      "episode 2, val func loss 1.5475713014602661\n",
      "\n",
      "episode 3, val func loss 1.6034698486328125\n",
      "\n",
      "episode 4, val func loss 1.8250696659088135\n",
      "\n",
      "episode 5, val func loss 1.7413440942764282\n",
      "\n",
      "episode 6, val func loss 1.5496143102645874\n",
      "\n",
      "episode 7, val func loss 1.6457319259643555\n",
      "\n",
      "episode 8, val func loss 1.525787353515625\n",
      "\n",
      "episode 9, val func loss 1.4920909404754639\n",
      "\n",
      "episode 10, val func loss 1.2874164581298828\n",
      "\n",
      "episode 11, val func loss 1.4798935651779175\n",
      "\n",
      "episode 12, val func loss 1.424899697303772\n",
      "\n",
      "episode 13, val func loss 1.7205685377120972\n",
      "\n",
      "episode 14, val func loss 1.8409548997879028\n",
      "\n",
      "episode 15, val func loss 1.9212065935134888\n",
      "\n",
      "episode 16, val func loss 1.5620607137680054\n",
      "\n",
      "Val func train loss in epoch 11:1.6029826551675797\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.831225872039795\n",
      "\n",
      "episode 2, val func loss 1.7220619916915894\n",
      "\n",
      "episode 3, val func loss 1.6542019844055176\n",
      "\n",
      "episode 4, val func loss 1.1989312171936035\n",
      "\n",
      "episode 5, val func loss 1.5141927003860474\n",
      "\n",
      "episode 6, val func loss 2.1019949913024902\n",
      "\n",
      "episode 7, val func loss 1.7275450229644775\n",
      "\n",
      "episode 8, val func loss 1.673538088798523\n",
      "\n",
      "episode 9, val func loss 1.7506123781204224\n",
      "\n",
      "episode 10, val func loss 1.5014894008636475\n",
      "\n",
      "episode 11, val func loss 1.5341343879699707\n",
      "\n",
      "episode 12, val func loss 1.56646728515625\n",
      "\n",
      "episode 13, val func loss 1.7541693449020386\n",
      "\n",
      "episode 14, val func loss 1.7690695524215698\n",
      "\n",
      "episode 15, val func loss 1.790391206741333\n",
      "\n",
      "episode 16, val func loss 1.6518135070800781\n",
      "\n",
      "Val func train loss in epoch 12:1.6713649332523346\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.807679533958435\n",
      "\n",
      "episode 2, val func loss 1.6500492095947266\n",
      "\n",
      "episode 3, val func loss 1.5890552997589111\n",
      "\n",
      "episode 4, val func loss 1.621665120124817\n",
      "\n",
      "episode 5, val func loss 1.6479041576385498\n",
      "\n",
      "episode 6, val func loss 1.6162378787994385\n",
      "\n",
      "episode 7, val func loss 1.5591951608657837\n",
      "\n",
      "episode 8, val func loss 1.7180875539779663\n",
      "\n",
      "episode 9, val func loss 1.4818695783615112\n",
      "\n",
      "episode 10, val func loss 1.8517481088638306\n",
      "\n",
      "episode 11, val func loss 1.6773524284362793\n",
      "\n",
      "episode 12, val func loss 2.071552038192749\n",
      "\n",
      "episode 13, val func loss 1.5799895524978638\n",
      "\n",
      "episode 14, val func loss 1.816670298576355\n",
      "\n",
      "episode 15, val func loss 1.838531255722046\n",
      "\n",
      "episode 16, val func loss 1.479196310043335\n",
      "\n",
      "Val func train loss in epoch 13:1.6879239678382874\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.680584192276001\n",
      "\n",
      "episode 2, val func loss 1.746662974357605\n",
      "\n",
      "episode 3, val func loss 1.9051371812820435\n",
      "\n",
      "episode 4, val func loss 1.5188003778457642\n",
      "\n",
      "episode 5, val func loss 1.7094799280166626\n",
      "\n",
      "episode 6, val func loss 1.616453766822815\n",
      "\n",
      "episode 7, val func loss 1.5148069858551025\n",
      "\n",
      "episode 8, val func loss 1.5730704069137573\n",
      "\n",
      "episode 9, val func loss 1.5003612041473389\n",
      "\n",
      "episode 10, val func loss 1.9677704572677612\n",
      "\n",
      "episode 11, val func loss 1.8636173009872437\n",
      "\n",
      "episode 12, val func loss 1.8113123178482056\n",
      "\n",
      "episode 13, val func loss 1.764722466468811\n",
      "\n",
      "episode 14, val func loss 1.5916141271591187\n",
      "\n",
      "episode 15, val func loss 1.5569013357162476\n",
      "\n",
      "episode 16, val func loss 1.9347257614135742\n",
      "\n",
      "Val func train loss in epoch 14:1.7035012990236282\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.6997425556182861\n",
      "\n",
      "episode 2, val func loss 1.636580467224121\n",
      "\n",
      "episode 3, val func loss 1.8502240180969238\n",
      "\n",
      "episode 4, val func loss 1.8002283573150635\n",
      "\n",
      "episode 5, val func loss 1.5505515336990356\n",
      "\n",
      "episode 6, val func loss 2.017456531524658\n",
      "\n",
      "episode 7, val func loss 1.7287365198135376\n",
      "\n",
      "episode 8, val func loss 1.7752118110656738\n",
      "\n",
      "episode 9, val func loss 1.823164939880371\n",
      "\n",
      "episode 10, val func loss 1.6184732913970947\n",
      "\n",
      "episode 11, val func loss 1.894521713256836\n",
      "\n",
      "episode 12, val func loss 1.7765049934387207\n",
      "\n",
      "episode 13, val func loss 1.7573859691619873\n",
      "\n",
      "episode 14, val func loss 1.6820685863494873\n",
      "\n",
      "episode 15, val func loss 2.4053800106048584\n",
      "\n",
      "episode 16, val func loss 2.4981184005737305\n",
      "\n",
      "Val func train loss in epoch 15:1.844646856188774\n",
      "***********************TIME WAS 5.120221412181854 min*****************************\n",
      "\n",
      "**********************ROUND 12 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.07323112338781357\n",
      "\n",
      "episode 2, policy loss 0.07320881634950638\n",
      "\n",
      "episode 3, policy loss 0.07320436835289001\n",
      "\n",
      "episode 4, policy loss 0.07322221249341965\n",
      "\n",
      "episode 5, policy loss 0.07322237640619278\n",
      "\n",
      "episode 6, policy loss 0.07321826368570328\n",
      "\n",
      "episode 7, policy loss 0.07321231812238693\n",
      "\n",
      "episode 8, policy loss 0.07320904731750488\n",
      "\n",
      "episode 9, policy loss 0.07321203500032425\n",
      "\n",
      "episode 10, policy loss 0.07321831583976746\n",
      "\n",
      "episode 11, policy loss 0.07320492714643478\n",
      "\n",
      "episode 12, policy loss 0.07322315126657486\n",
      "\n",
      "episode 13, policy loss 0.07323243468999863\n",
      "\n",
      "episode 14, policy loss 0.07323121279478073\n",
      "\n",
      "episode 15, policy loss 0.07322770357131958\n",
      "\n",
      "episode 16, policy loss 0.07323785871267319\n",
      "\n",
      "Policy train loss in epoch 0:0.07321976032108068\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.07321195304393768\n",
      "\n",
      "episode 2, policy loss 0.0732090175151825\n",
      "\n",
      "episode 3, policy loss 0.07320881634950638\n",
      "\n",
      "episode 4, policy loss 0.07323234528303146\n",
      "\n",
      "episode 5, policy loss 0.0732182040810585\n",
      "\n",
      "episode 6, policy loss 0.07323110848665237\n",
      "\n",
      "episode 7, policy loss 0.073222316801548\n",
      "\n",
      "episode 8, policy loss 0.0732378363609314\n",
      "\n",
      "episode 9, policy loss 0.07320485264062881\n",
      "\n",
      "episode 10, policy loss 0.07321829348802567\n",
      "\n",
      "episode 11, policy loss 0.07322212308645248\n",
      "\n",
      "episode 12, policy loss 0.0732276663184166\n",
      "\n",
      "episode 13, policy loss 0.07320418953895569\n",
      "\n",
      "episode 14, policy loss 0.07322309911251068\n",
      "\n",
      "episode 15, policy loss 0.0732310339808464\n",
      "\n",
      "episode 16, policy loss 0.07321218401193619\n",
      "\n",
      "Policy train loss in epoch 1:0.0732196900062263\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.07321815937757492\n",
      "\n",
      "episode 2, policy loss 0.07323102653026581\n",
      "\n",
      "episode 3, policy loss 0.07323100417852402\n",
      "\n",
      "episode 4, policy loss 0.07321808487176895\n",
      "\n",
      "episode 5, policy loss 0.07320871204137802\n",
      "\n",
      "episode 6, policy loss 0.07320478558540344\n",
      "\n",
      "episode 7, policy loss 0.07323769479990005\n",
      "\n",
      "episode 8, policy loss 0.07321204245090485\n",
      "\n",
      "episode 9, policy loss 0.07323221862316132\n",
      "\n",
      "episode 10, policy loss 0.07321175187826157\n",
      "\n",
      "episode 11, policy loss 0.07322754710912704\n",
      "\n",
      "episode 12, policy loss 0.07322204858064651\n",
      "\n",
      "episode 13, policy loss 0.07320408523082733\n",
      "\n",
      "episode 14, policy loss 0.07322206348180771\n",
      "\n",
      "episode 15, policy loss 0.0732228010892868\n",
      "\n",
      "episode 16, policy loss 0.07320873439311981\n",
      "\n",
      "Policy train loss in epoch 2:0.07321954751387239\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.0732085183262825\n",
      "\n",
      "episode 2, policy loss 0.07322730123996735\n",
      "\n",
      "episode 3, policy loss 0.07321793586015701\n",
      "\n",
      "episode 4, policy loss 0.07322277873754501\n",
      "\n",
      "episode 5, policy loss 0.07323063164949417\n",
      "\n",
      "episode 6, policy loss 0.0732044130563736\n",
      "\n",
      "episode 7, policy loss 0.07323189824819565\n",
      "\n",
      "episode 8, policy loss 0.07322163134813309\n",
      "\n",
      "episode 9, policy loss 0.07321766018867493\n",
      "\n",
      "episode 10, policy loss 0.07320377975702286\n",
      "\n",
      "episode 11, policy loss 0.07321136444807053\n",
      "\n",
      "episode 12, policy loss 0.07322175800800323\n",
      "\n",
      "episode 13, policy loss 0.07320837676525116\n",
      "\n",
      "episode 14, policy loss 0.07323054224252701\n",
      "\n",
      "episode 15, policy loss 0.07321146875619888\n",
      "\n",
      "episode 16, policy loss 0.07323702424764633\n",
      "\n",
      "Policy train loss in epoch 3:0.07321919267997146\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 8.925612449645996\n",
      "\n",
      "episode 2, val func loss 5.7643723487854\n",
      "\n",
      "episode 3, val func loss 5.04968786239624\n",
      "\n",
      "episode 4, val func loss 8.421268463134766\n",
      "\n",
      "episode 5, val func loss 2.1831374168395996\n",
      "\n",
      "episode 6, val func loss 4.173184871673584\n",
      "\n",
      "episode 7, val func loss 3.751528263092041\n",
      "\n",
      "episode 8, val func loss 2.3589048385620117\n",
      "\n",
      "episode 9, val func loss 2.7589335441589355\n",
      "\n",
      "episode 10, val func loss 3.972588062286377\n",
      "\n",
      "episode 11, val func loss 3.2403969764709473\n",
      "\n",
      "episode 12, val func loss 2.2817251682281494\n",
      "\n",
      "episode 13, val func loss 2.401777505874634\n",
      "\n",
      "episode 14, val func loss 2.948622465133667\n",
      "\n",
      "episode 15, val func loss 2.8957602977752686\n",
      "\n",
      "episode 16, val func loss 2.4847724437713623\n",
      "\n",
      "Val func train loss in epoch 0:3.975767061114311\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.272810697555542\n",
      "\n",
      "episode 2, val func loss 2.580193042755127\n",
      "\n",
      "episode 3, val func loss 2.814722776412964\n",
      "\n",
      "episode 4, val func loss 2.604679584503174\n",
      "\n",
      "episode 5, val func loss 2.270174264907837\n",
      "\n",
      "episode 6, val func loss 2.265662431716919\n",
      "\n",
      "episode 7, val func loss 2.497868061065674\n",
      "\n",
      "episode 8, val func loss 2.629530668258667\n",
      "\n",
      "episode 9, val func loss 2.396801471710205\n",
      "\n",
      "episode 10, val func loss 2.2307865619659424\n",
      "\n",
      "episode 11, val func loss 2.2967512607574463\n",
      "\n",
      "episode 12, val func loss 2.407407760620117\n",
      "\n",
      "episode 13, val func loss 2.374720811843872\n",
      "\n",
      "episode 14, val func loss 2.336810827255249\n",
      "\n",
      "episode 15, val func loss 2.262993097305298\n",
      "\n",
      "episode 16, val func loss 2.257312059402466\n",
      "\n",
      "Val func train loss in epoch 1:2.406201586127281\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.358139991760254\n",
      "\n",
      "episode 2, val func loss 2.3124606609344482\n",
      "\n",
      "episode 3, val func loss 2.2721505165100098\n",
      "\n",
      "episode 4, val func loss 2.2735660076141357\n",
      "\n",
      "episode 5, val func loss 2.2374844551086426\n",
      "\n",
      "episode 6, val func loss 2.2684547901153564\n",
      "\n",
      "episode 7, val func loss 2.215839147567749\n",
      "\n",
      "episode 8, val func loss 2.2432446479797363\n",
      "\n",
      "episode 9, val func loss 2.2238337993621826\n",
      "\n",
      "episode 10, val func loss 2.2552804946899414\n",
      "\n",
      "episode 11, val func loss 2.31811261177063\n",
      "\n",
      "episode 12, val func loss 2.224569320678711\n",
      "\n",
      "episode 13, val func loss 2.2366490364074707\n",
      "\n",
      "episode 14, val func loss 2.210343837738037\n",
      "\n",
      "episode 15, val func loss 2.225053548812866\n",
      "\n",
      "episode 16, val func loss 2.22162127494812\n",
      "\n",
      "Val func train loss in epoch 2:2.256050258874893\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.208805561065674\n",
      "\n",
      "episode 2, val func loss 2.1073367595672607\n",
      "\n",
      "episode 3, val func loss 2.2217442989349365\n",
      "\n",
      "episode 4, val func loss 2.20449161529541\n",
      "\n",
      "episode 5, val func loss 2.3893654346466064\n",
      "\n",
      "episode 6, val func loss 2.2461955547332764\n",
      "\n",
      "episode 7, val func loss 2.1672914028167725\n",
      "\n",
      "episode 8, val func loss 2.1876518726348877\n",
      "\n",
      "episode 9, val func loss 2.06327486038208\n",
      "\n",
      "episode 10, val func loss 2.1252102851867676\n",
      "\n",
      "episode 11, val func loss 2.1774373054504395\n",
      "\n",
      "episode 12, val func loss 2.154841899871826\n",
      "\n",
      "episode 13, val func loss 2.1573359966278076\n",
      "\n",
      "episode 14, val func loss 2.1056084632873535\n",
      "\n",
      "episode 15, val func loss 2.123544454574585\n",
      "\n",
      "episode 16, val func loss 2.133112668991089\n",
      "\n",
      "Val func train loss in epoch 3:2.1733280271291733\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.201524257659912\n",
      "\n",
      "episode 2, val func loss 2.1867728233337402\n",
      "\n",
      "episode 3, val func loss 2.1277475357055664\n",
      "\n",
      "episode 4, val func loss 2.1437604427337646\n",
      "\n",
      "episode 5, val func loss 2.0203604698181152\n",
      "\n",
      "episode 6, val func loss 2.037156105041504\n",
      "\n",
      "episode 7, val func loss 2.0323681831359863\n",
      "\n",
      "episode 8, val func loss 2.0373711585998535\n",
      "\n",
      "episode 9, val func loss 2.070657253265381\n",
      "\n",
      "episode 10, val func loss 2.0097763538360596\n",
      "\n",
      "episode 11, val func loss 2.048092842102051\n",
      "\n",
      "episode 12, val func loss 2.046571969985962\n",
      "\n",
      "episode 13, val func loss 2.0501198768615723\n",
      "\n",
      "episode 14, val func loss 1.928221344947815\n",
      "\n",
      "episode 15, val func loss 2.11464262008667\n",
      "\n",
      "episode 16, val func loss 1.9803978204727173\n",
      "\n",
      "Val func train loss in epoch 4:2.064721316099167\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.9634374380111694\n",
      "\n",
      "episode 2, val func loss 1.9371612071990967\n",
      "\n",
      "episode 3, val func loss 1.8702837228775024\n",
      "\n",
      "episode 4, val func loss 2.0063202381134033\n",
      "\n",
      "episode 5, val func loss 2.0366413593292236\n",
      "\n",
      "episode 6, val func loss 2.0013136863708496\n",
      "\n",
      "episode 7, val func loss 1.8987146615982056\n",
      "\n",
      "episode 8, val func loss 1.9125767946243286\n",
      "\n",
      "episode 9, val func loss 1.9179325103759766\n",
      "\n",
      "episode 10, val func loss 1.8822582960128784\n",
      "\n",
      "episode 11, val func loss 1.914068341255188\n",
      "\n",
      "episode 12, val func loss 2.042673349380493\n",
      "\n",
      "episode 13, val func loss 1.756859302520752\n",
      "\n",
      "episode 14, val func loss 1.8104907274246216\n",
      "\n",
      "episode 15, val func loss 1.8624951839447021\n",
      "\n",
      "episode 16, val func loss 1.949716329574585\n",
      "\n",
      "Val func train loss in epoch 5:1.922683946788311\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.7283786535263062\n",
      "\n",
      "episode 2, val func loss 1.8281235694885254\n",
      "\n",
      "episode 3, val func loss 1.8113423585891724\n",
      "\n",
      "episode 4, val func loss 1.8172072172164917\n",
      "\n",
      "episode 5, val func loss 1.5794756412506104\n",
      "\n",
      "episode 6, val func loss 1.811180591583252\n",
      "\n",
      "episode 7, val func loss 1.7300564050674438\n",
      "\n",
      "episode 8, val func loss 1.9870694875717163\n",
      "\n",
      "episode 9, val func loss 1.7353862524032593\n",
      "\n",
      "episode 10, val func loss 1.797681212425232\n",
      "\n",
      "episode 11, val func loss 1.8427228927612305\n",
      "\n",
      "episode 12, val func loss 1.7300012111663818\n",
      "\n",
      "episode 13, val func loss 1.6798956394195557\n",
      "\n",
      "episode 14, val func loss 1.7118711471557617\n",
      "\n",
      "episode 15, val func loss 1.6116760969161987\n",
      "\n",
      "episode 16, val func loss 1.7316631078720093\n",
      "\n",
      "Val func train loss in epoch 6:1.7583582177758217\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.6647419929504395\n",
      "\n",
      "episode 2, val func loss 1.7448803186416626\n",
      "\n",
      "episode 3, val func loss 1.7153500318527222\n",
      "\n",
      "episode 4, val func loss 1.5454078912734985\n",
      "\n",
      "episode 5, val func loss 1.6024417877197266\n",
      "\n",
      "episode 6, val func loss 1.7123560905456543\n",
      "\n",
      "episode 7, val func loss 2.0822644233703613\n",
      "\n",
      "episode 8, val func loss 1.6581720113754272\n",
      "\n",
      "episode 9, val func loss 2.0148820877075195\n",
      "\n",
      "episode 10, val func loss 1.7620786428451538\n",
      "\n",
      "episode 11, val func loss 1.5992584228515625\n",
      "\n",
      "episode 12, val func loss 1.8708401918411255\n",
      "\n",
      "episode 13, val func loss 2.0544650554656982\n",
      "\n",
      "episode 14, val func loss 1.9139097929000854\n",
      "\n",
      "episode 15, val func loss 2.000657558441162\n",
      "\n",
      "episode 16, val func loss 1.784322738647461\n",
      "\n",
      "Val func train loss in epoch 7:1.7953768149018288\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.89299476146698\n",
      "\n",
      "episode 2, val func loss 1.9520645141601562\n",
      "\n",
      "episode 3, val func loss 1.8608909845352173\n",
      "\n",
      "episode 4, val func loss 1.930951714515686\n",
      "\n",
      "episode 5, val func loss 1.993890404701233\n",
      "\n",
      "episode 6, val func loss 1.630520224571228\n",
      "\n",
      "episode 7, val func loss 1.7565838098526\n",
      "\n",
      "episode 8, val func loss 2.0147006511688232\n",
      "\n",
      "episode 9, val func loss 1.837477684020996\n",
      "\n",
      "episode 10, val func loss 1.7532438039779663\n",
      "\n",
      "episode 11, val func loss 1.9550721645355225\n",
      "\n",
      "episode 12, val func loss 1.7999950647354126\n",
      "\n",
      "episode 13, val func loss 1.7341463565826416\n",
      "\n",
      "episode 14, val func loss 1.9651432037353516\n",
      "\n",
      "episode 15, val func loss 1.8709660768508911\n",
      "\n",
      "episode 16, val func loss 1.8506592512130737\n",
      "\n",
      "Val func train loss in epoch 8:1.8624562919139862\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.758909821510315\n",
      "\n",
      "episode 2, val func loss 1.6827458143234253\n",
      "\n",
      "episode 3, val func loss 1.9335721731185913\n",
      "\n",
      "episode 4, val func loss 1.9973541498184204\n",
      "\n",
      "episode 5, val func loss 1.7923626899719238\n",
      "\n",
      "episode 6, val func loss 1.7915245294570923\n",
      "\n",
      "episode 7, val func loss 2.0728228092193604\n",
      "\n",
      "episode 8, val func loss 2.0934557914733887\n",
      "\n",
      "episode 9, val func loss 1.9097025394439697\n",
      "\n",
      "episode 10, val func loss 1.8537551164627075\n",
      "\n",
      "episode 11, val func loss 1.8227365016937256\n",
      "\n",
      "episode 12, val func loss 1.8497859239578247\n",
      "\n",
      "episode 13, val func loss 1.656577706336975\n",
      "\n",
      "episode 14, val func loss 1.6409069299697876\n",
      "\n",
      "episode 15, val func loss 1.6517819166183472\n",
      "\n",
      "episode 16, val func loss 1.7367446422576904\n",
      "\n",
      "Val func train loss in epoch 9:1.8277961909770966\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.7923684120178223\n",
      "\n",
      "episode 2, val func loss 1.6445633172988892\n",
      "\n",
      "episode 3, val func loss 1.5986695289611816\n",
      "\n",
      "episode 4, val func loss 1.8320339918136597\n",
      "\n",
      "episode 5, val func loss 1.911537528038025\n",
      "\n",
      "episode 6, val func loss 1.634919285774231\n",
      "\n",
      "episode 7, val func loss 1.5317195653915405\n",
      "\n",
      "episode 8, val func loss 1.8445115089416504\n",
      "\n",
      "episode 9, val func loss 1.7871381044387817\n",
      "\n",
      "episode 10, val func loss 1.6446994543075562\n",
      "\n",
      "episode 11, val func loss 1.832540512084961\n",
      "\n",
      "episode 12, val func loss 1.769044280052185\n",
      "\n",
      "episode 13, val func loss 1.644460916519165\n",
      "\n",
      "episode 14, val func loss 1.6609458923339844\n",
      "\n",
      "episode 15, val func loss 1.5374687910079956\n",
      "\n",
      "episode 16, val func loss 1.8482729196548462\n",
      "\n",
      "Val func train loss in epoch 10:1.7196808755397797\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.540634036064148\n",
      "\n",
      "episode 2, val func loss 1.6593775749206543\n",
      "\n",
      "episode 3, val func loss 1.527656078338623\n",
      "\n",
      "episode 4, val func loss 1.5768769979476929\n",
      "\n",
      "episode 5, val func loss 1.6306630373001099\n",
      "\n",
      "episode 6, val func loss 1.715685486793518\n",
      "\n",
      "episode 7, val func loss 1.6566495895385742\n",
      "\n",
      "episode 8, val func loss 1.569639801979065\n",
      "\n",
      "episode 9, val func loss 1.6019761562347412\n",
      "\n",
      "episode 10, val func loss 1.4672799110412598\n",
      "\n",
      "episode 11, val func loss 1.6087430715560913\n",
      "\n",
      "episode 12, val func loss 1.7937612533569336\n",
      "\n",
      "episode 13, val func loss 1.7291224002838135\n",
      "\n",
      "episode 14, val func loss 1.82415771484375\n",
      "\n",
      "episode 15, val func loss 1.7276172637939453\n",
      "\n",
      "episode 16, val func loss 1.831175446510315\n",
      "\n",
      "Val func train loss in epoch 11:1.6538134887814522\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.6114192008972168\n",
      "\n",
      "episode 2, val func loss 1.7648946046829224\n",
      "\n",
      "episode 3, val func loss 1.570591688156128\n",
      "\n",
      "episode 4, val func loss 1.6369287967681885\n",
      "\n",
      "episode 5, val func loss 1.5934120416641235\n",
      "\n",
      "episode 6, val func loss 1.6833728551864624\n",
      "\n",
      "episode 7, val func loss 1.5390887260437012\n",
      "\n",
      "episode 8, val func loss 1.774703025817871\n",
      "\n",
      "episode 9, val func loss 1.7953757047653198\n",
      "\n",
      "episode 10, val func loss 1.8287161588668823\n",
      "\n",
      "episode 11, val func loss 1.6502214670181274\n",
      "\n",
      "episode 12, val func loss 1.5232892036437988\n",
      "\n",
      "episode 13, val func loss 1.939903736114502\n",
      "\n",
      "episode 14, val func loss 1.642144799232483\n",
      "\n",
      "episode 15, val func loss 1.7599643468856812\n",
      "\n",
      "episode 16, val func loss 1.7224899530410767\n",
      "\n",
      "Val func train loss in epoch 12:1.6897822692990303\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.8533905744552612\n",
      "\n",
      "episode 2, val func loss 1.7579193115234375\n",
      "\n",
      "episode 3, val func loss 1.6738768815994263\n",
      "\n",
      "episode 4, val func loss 1.9320377111434937\n",
      "\n",
      "episode 5, val func loss 1.8821364641189575\n",
      "\n",
      "episode 6, val func loss 1.7614325284957886\n",
      "\n",
      "episode 7, val func loss 1.7378009557724\n",
      "\n",
      "episode 8, val func loss 1.7565354108810425\n",
      "\n",
      "episode 9, val func loss 1.7238574028015137\n",
      "\n",
      "episode 10, val func loss 1.6650609970092773\n",
      "\n",
      "episode 11, val func loss 1.6928200721740723\n",
      "\n",
      "episode 12, val func loss 1.787050724029541\n",
      "\n",
      "episode 13, val func loss 1.908386468887329\n",
      "\n",
      "episode 14, val func loss 1.885995626449585\n",
      "\n",
      "episode 15, val func loss 1.9388059377670288\n",
      "\n",
      "episode 16, val func loss 1.6161794662475586\n",
      "\n",
      "Val func train loss in epoch 13:1.785830408334732\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.6289193630218506\n",
      "\n",
      "episode 2, val func loss 1.84811532497406\n",
      "\n",
      "episode 3, val func loss 1.6551164388656616\n",
      "\n",
      "episode 4, val func loss 1.7380523681640625\n",
      "\n",
      "episode 5, val func loss 1.7410870790481567\n",
      "\n",
      "episode 6, val func loss 1.6645481586456299\n",
      "\n",
      "episode 7, val func loss 1.8373454809188843\n",
      "\n",
      "episode 8, val func loss 1.4984893798828125\n",
      "\n",
      "episode 9, val func loss 1.7365124225616455\n",
      "\n",
      "episode 10, val func loss 1.8718849420547485\n",
      "\n",
      "episode 11, val func loss 1.7727117538452148\n",
      "\n",
      "episode 12, val func loss 1.580271601676941\n",
      "\n",
      "episode 13, val func loss 1.5650582313537598\n",
      "\n",
      "episode 14, val func loss 1.8051283359527588\n",
      "\n",
      "episode 15, val func loss 1.7000683546066284\n",
      "\n",
      "episode 16, val func loss 2.015730857849121\n",
      "\n",
      "Val func train loss in epoch 14:1.728690005838871\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.4617044925689697\n",
      "\n",
      "episode 2, val func loss 1.4442739486694336\n",
      "\n",
      "episode 3, val func loss 2.0019214153289795\n",
      "\n",
      "episode 4, val func loss 1.8021997213363647\n",
      "\n",
      "episode 5, val func loss 1.7254635095596313\n",
      "\n",
      "episode 6, val func loss 1.838500738143921\n",
      "\n",
      "episode 7, val func loss 1.761344075202942\n",
      "\n",
      "episode 8, val func loss 1.6087640523910522\n",
      "\n",
      "episode 9, val func loss 1.568296194076538\n",
      "\n",
      "episode 10, val func loss 1.7939194440841675\n",
      "\n",
      "episode 11, val func loss 1.8139715194702148\n",
      "\n",
      "episode 12, val func loss 1.5972018241882324\n",
      "\n",
      "episode 13, val func loss 1.4978281259536743\n",
      "\n",
      "episode 14, val func loss 1.6856625080108643\n",
      "\n",
      "episode 15, val func loss 1.7726019620895386\n",
      "\n",
      "episode 16, val func loss 1.6088672876358032\n",
      "\n",
      "Val func train loss in epoch 15:1.6864075511693954\n",
      "***********************TIME WAS 5.122477368513743 min*****************************\n",
      "\n",
      "**********************ROUND 13 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.243666887283325\n",
      "\n",
      "episode 2, policy loss -2.243666648864746\n",
      "\n",
      "episode 3, policy loss -2.243666410446167\n",
      "\n",
      "episode 4, policy loss -2.243666648864746\n",
      "\n",
      "episode 5, policy loss -2.243666410446167\n",
      "\n",
      "episode 6, policy loss -2.243666172027588\n",
      "\n",
      "episode 7, policy loss -2.243666648864746\n",
      "\n",
      "episode 8, policy loss -2.243666887283325\n",
      "\n",
      "episode 9, policy loss -2.243666410446167\n",
      "\n",
      "episode 10, policy loss -2.243666648864746\n",
      "\n",
      "episode 11, policy loss -2.243666887283325\n",
      "\n",
      "episode 12, policy loss -2.2436671257019043\n",
      "\n",
      "episode 13, policy loss -2.2436671257019043\n",
      "\n",
      "episode 14, policy loss -2.2436671257019043\n",
      "\n",
      "episode 15, policy loss -2.2436673641204834\n",
      "\n",
      "episode 16, policy loss -2.2436671257019043\n",
      "\n",
      "Policy train loss in epoch 0:-2.243666782975197\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.2436673641204834\n",
      "\n",
      "episode 2, policy loss -2.2436673641204834\n",
      "\n",
      "episode 3, policy loss -2.2436676025390625\n",
      "\n",
      "episode 4, policy loss -2.2436678409576416\n",
      "\n",
      "episode 5, policy loss -2.2436678409576416\n",
      "\n",
      "episode 6, policy loss -2.2436678409576416\n",
      "\n",
      "episode 7, policy loss -2.2436678409576416\n",
      "\n",
      "episode 8, policy loss -2.2436680793762207\n",
      "\n",
      "episode 9, policy loss -2.2436680793762207\n",
      "\n",
      "episode 10, policy loss -2.2436680793762207\n",
      "\n",
      "episode 11, policy loss -2.2436676025390625\n",
      "\n",
      "episode 12, policy loss -2.2436680793762207\n",
      "\n",
      "episode 13, policy loss -2.2436680793762207\n",
      "\n",
      "episode 14, policy loss -2.2436680793762207\n",
      "\n",
      "episode 15, policy loss -2.2436680793762207\n",
      "\n",
      "episode 16, policy loss -2.2436680793762207\n",
      "\n",
      "Policy train loss in epoch 1:-2.243667870759964\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.2436680793762207\n",
      "\n",
      "episode 2, policy loss -2.2436680793762207\n",
      "\n",
      "episode 3, policy loss -2.2436680793762207\n",
      "\n",
      "episode 4, policy loss -2.2436683177948\n",
      "\n",
      "episode 5, policy loss -2.2436683177948\n",
      "\n",
      "episode 6, policy loss -2.243668556213379\n",
      "\n",
      "episode 7, policy loss -2.243669033050537\n",
      "\n",
      "episode 8, policy loss -2.243669033050537\n",
      "\n",
      "episode 9, policy loss -2.243669033050537\n",
      "\n",
      "episode 10, policy loss -2.243669033050537\n",
      "\n",
      "episode 11, policy loss -2.2436695098876953\n",
      "\n",
      "episode 12, policy loss -2.243669271469116\n",
      "\n",
      "episode 13, policy loss -2.243669271469116\n",
      "\n",
      "episode 14, policy loss -2.243669271469116\n",
      "\n",
      "episode 15, policy loss -2.2436695098876953\n",
      "\n",
      "episode 16, policy loss -2.2436697483062744\n",
      "\n",
      "Policy train loss in epoch 2:-2.243668884038925\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.243669271469116\n",
      "\n",
      "episode 2, policy loss -2.2436697483062744\n",
      "\n",
      "episode 3, policy loss -2.2436697483062744\n",
      "\n",
      "episode 4, policy loss -2.2436695098876953\n",
      "\n",
      "episode 5, policy loss -2.2436697483062744\n",
      "\n",
      "episode 6, policy loss -2.243669271469116\n",
      "\n",
      "episode 7, policy loss -2.2436697483062744\n",
      "\n",
      "episode 8, policy loss -2.2436695098876953\n",
      "\n",
      "episode 9, policy loss -2.2436697483062744\n",
      "\n",
      "episode 10, policy loss -2.243669271469116\n",
      "\n",
      "episode 11, policy loss -2.2436697483062744\n",
      "\n",
      "episode 12, policy loss -2.2436697483062744\n",
      "\n",
      "episode 13, policy loss -2.2436697483062744\n",
      "\n",
      "episode 14, policy loss -2.2436695098876953\n",
      "\n",
      "episode 15, policy loss -2.2436697483062744\n",
      "\n",
      "episode 16, policy loss -2.2436695098876953\n",
      "\n",
      "Policy train loss in epoch 3:-2.2436695992946625\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.822514295578003\n",
      "\n",
      "episode 2, val func loss 1.6070835590362549\n",
      "\n",
      "episode 3, val func loss 2.114811897277832\n",
      "\n",
      "episode 4, val func loss 1.888431429862976\n",
      "\n",
      "episode 5, val func loss 1.6189953088760376\n",
      "\n",
      "episode 6, val func loss 1.8798149824142456\n",
      "\n",
      "episode 7, val func loss 2.327120065689087\n",
      "\n",
      "episode 8, val func loss 1.8155585527420044\n",
      "\n",
      "episode 9, val func loss 2.0825395584106445\n",
      "\n",
      "episode 10, val func loss 1.605979323387146\n",
      "\n",
      "episode 11, val func loss 1.737183690071106\n",
      "\n",
      "episode 12, val func loss 1.8418142795562744\n",
      "\n",
      "episode 13, val func loss 2.349653959274292\n",
      "\n",
      "episode 14, val func loss 1.8777222633361816\n",
      "\n",
      "episode 15, val func loss 2.6873347759246826\n",
      "\n",
      "episode 16, val func loss 2.110673427581787\n",
      "\n",
      "Val func train loss in epoch 0:1.9604519605636597\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.056666374206543\n",
      "\n",
      "episode 2, val func loss 3.2873499393463135\n",
      "\n",
      "episode 3, val func loss 3.55019474029541\n",
      "\n",
      "episode 4, val func loss 4.099107265472412\n",
      "\n",
      "episode 5, val func loss 2.4796829223632812\n",
      "\n",
      "episode 6, val func loss 2.1985762119293213\n",
      "\n",
      "episode 7, val func loss 3.5809173583984375\n",
      "\n",
      "episode 8, val func loss 3.0753891468048096\n",
      "\n",
      "episode 9, val func loss 2.044512987136841\n",
      "\n",
      "episode 10, val func loss 2.0801053047180176\n",
      "\n",
      "episode 11, val func loss 2.551331043243408\n",
      "\n",
      "episode 12, val func loss 2.3140370845794678\n",
      "\n",
      "episode 13, val func loss 1.9258335828781128\n",
      "\n",
      "episode 14, val func loss 2.281116008758545\n",
      "\n",
      "episode 15, val func loss 2.279425621032715\n",
      "\n",
      "episode 16, val func loss 2.0351619720458984\n",
      "\n",
      "Val func train loss in epoch 1:2.614962972700596\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.08738374710083\n",
      "\n",
      "episode 2, val func loss 2.1773219108581543\n",
      "\n",
      "episode 3, val func loss 1.7750085592269897\n",
      "\n",
      "episode 4, val func loss 2.0356247425079346\n",
      "\n",
      "episode 5, val func loss 2.061471462249756\n",
      "\n",
      "episode 6, val func loss 1.8583338260650635\n",
      "\n",
      "episode 7, val func loss 1.7853413820266724\n",
      "\n",
      "episode 8, val func loss 1.9706518650054932\n",
      "\n",
      "episode 9, val func loss 1.9201252460479736\n",
      "\n",
      "episode 10, val func loss 1.566634178161621\n",
      "\n",
      "episode 11, val func loss 1.7033860683441162\n",
      "\n",
      "episode 12, val func loss 1.5971434116363525\n",
      "\n",
      "episode 13, val func loss 1.7520818710327148\n",
      "\n",
      "episode 14, val func loss 1.8932181596755981\n",
      "\n",
      "episode 15, val func loss 1.553263783454895\n",
      "\n",
      "episode 16, val func loss 1.6639635562896729\n",
      "\n",
      "Val func train loss in epoch 2:1.8375596106052399\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.820778250694275\n",
      "\n",
      "episode 2, val func loss 1.6602100133895874\n",
      "\n",
      "episode 3, val func loss 1.829693078994751\n",
      "\n",
      "episode 4, val func loss 1.7122639417648315\n",
      "\n",
      "episode 5, val func loss 1.843700647354126\n",
      "\n",
      "episode 6, val func loss 1.6282216310501099\n",
      "\n",
      "episode 7, val func loss 1.6219841241836548\n",
      "\n",
      "episode 8, val func loss 1.577882170677185\n",
      "\n",
      "episode 9, val func loss 1.6436026096343994\n",
      "\n",
      "episode 10, val func loss 1.5866161584854126\n",
      "\n",
      "episode 11, val func loss 1.634615182876587\n",
      "\n",
      "episode 12, val func loss 1.5782411098480225\n",
      "\n",
      "episode 13, val func loss 1.7191753387451172\n",
      "\n",
      "episode 14, val func loss 1.689059853553772\n",
      "\n",
      "episode 15, val func loss 1.3991881608963013\n",
      "\n",
      "episode 16, val func loss 1.4803894758224487\n",
      "\n",
      "Val func train loss in epoch 3:1.6516013592481613\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.7591944932937622\n",
      "\n",
      "episode 2, val func loss 1.7748790979385376\n",
      "\n",
      "episode 3, val func loss 1.557698130607605\n",
      "\n",
      "episode 4, val func loss 1.8223843574523926\n",
      "\n",
      "episode 5, val func loss 1.481305480003357\n",
      "\n",
      "episode 6, val func loss 1.7349382638931274\n",
      "\n",
      "episode 7, val func loss 1.6634937524795532\n",
      "\n",
      "episode 8, val func loss 1.7171430587768555\n",
      "\n",
      "episode 9, val func loss 1.8027888536453247\n",
      "\n",
      "episode 10, val func loss 1.5871731042861938\n",
      "\n",
      "episode 11, val func loss 1.5991376638412476\n",
      "\n",
      "episode 12, val func loss 1.5245897769927979\n",
      "\n",
      "episode 13, val func loss 1.7809803485870361\n",
      "\n",
      "episode 14, val func loss 1.7064857482910156\n",
      "\n",
      "episode 15, val func loss 1.7603647708892822\n",
      "\n",
      "episode 16, val func loss 1.5870331525802612\n",
      "\n",
      "Val func train loss in epoch 4:1.6787243783473969\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.4827063083648682\n",
      "\n",
      "episode 2, val func loss 1.8317052125930786\n",
      "\n",
      "episode 3, val func loss 1.672720193862915\n",
      "\n",
      "episode 4, val func loss 1.7325701713562012\n",
      "\n",
      "episode 5, val func loss 1.5343973636627197\n",
      "\n",
      "episode 6, val func loss 1.796724796295166\n",
      "\n",
      "episode 7, val func loss 1.5211927890777588\n",
      "\n",
      "episode 8, val func loss 1.5052061080932617\n",
      "\n",
      "episode 9, val func loss 1.8630722761154175\n",
      "\n",
      "episode 10, val func loss 1.5239410400390625\n",
      "\n",
      "episode 11, val func loss 1.6218531131744385\n",
      "\n",
      "episode 12, val func loss 1.5786843299865723\n",
      "\n",
      "episode 13, val func loss 1.8195257186889648\n",
      "\n",
      "episode 14, val func loss 1.3642545938491821\n",
      "\n",
      "episode 15, val func loss 1.6206741333007812\n",
      "\n",
      "episode 16, val func loss 1.544973611831665\n",
      "\n",
      "Val func train loss in epoch 5:1.6258876100182533\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.4055594205856323\n",
      "\n",
      "episode 2, val func loss 2.014172077178955\n",
      "\n",
      "episode 3, val func loss 1.7544267177581787\n",
      "\n",
      "episode 4, val func loss 2.0332024097442627\n",
      "\n",
      "episode 5, val func loss 1.6815675497055054\n",
      "\n",
      "episode 6, val func loss 2.0749270915985107\n",
      "\n",
      "episode 7, val func loss 1.8542207479476929\n",
      "\n",
      "episode 8, val func loss 1.8388047218322754\n",
      "\n",
      "episode 9, val func loss 1.9148367643356323\n",
      "\n",
      "episode 10, val func loss 1.936442494392395\n",
      "\n",
      "episode 11, val func loss 1.6780050992965698\n",
      "\n",
      "episode 12, val func loss 1.6902004480361938\n",
      "\n",
      "episode 13, val func loss 1.8308460712432861\n",
      "\n",
      "episode 14, val func loss 1.8342267274856567\n",
      "\n",
      "episode 15, val func loss 1.7385343313217163\n",
      "\n",
      "episode 16, val func loss 1.7734285593032837\n",
      "\n",
      "Val func train loss in epoch 6:1.8158375769853592\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.7512834072113037\n",
      "\n",
      "episode 2, val func loss 2.1108157634735107\n",
      "\n",
      "episode 3, val func loss 1.6634740829467773\n",
      "\n",
      "episode 4, val func loss 1.7078388929367065\n",
      "\n",
      "episode 5, val func loss 1.7707488536834717\n",
      "\n",
      "episode 6, val func loss 1.9465190172195435\n",
      "\n",
      "episode 7, val func loss 1.777222752571106\n",
      "\n",
      "episode 8, val func loss 1.6539957523345947\n",
      "\n",
      "episode 9, val func loss 1.659385323524475\n",
      "\n",
      "episode 10, val func loss 1.9810150861740112\n",
      "\n",
      "episode 11, val func loss 1.5785911083221436\n",
      "\n",
      "episode 12, val func loss 1.7644673585891724\n",
      "\n",
      "episode 13, val func loss 1.7954304218292236\n",
      "\n",
      "episode 14, val func loss 1.6450802087783813\n",
      "\n",
      "episode 15, val func loss 1.6823296546936035\n",
      "\n",
      "episode 16, val func loss 1.7150249481201172\n",
      "\n",
      "Val func train loss in epoch 7:1.7627014145255089\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.5236982107162476\n",
      "\n",
      "episode 2, val func loss 1.7493951320648193\n",
      "\n",
      "episode 3, val func loss 1.7086838483810425\n",
      "\n",
      "episode 4, val func loss 1.3816568851470947\n",
      "\n",
      "episode 5, val func loss 1.6078572273254395\n",
      "\n",
      "episode 6, val func loss 1.5428401231765747\n",
      "\n",
      "episode 7, val func loss 1.7108004093170166\n",
      "\n",
      "episode 8, val func loss 1.7339438199996948\n",
      "\n",
      "episode 9, val func loss 1.696714997291565\n",
      "\n",
      "episode 10, val func loss 1.5944513082504272\n",
      "\n",
      "episode 11, val func loss 1.9255735874176025\n",
      "\n",
      "episode 12, val func loss 1.5017229318618774\n",
      "\n",
      "episode 13, val func loss 1.7469701766967773\n",
      "\n",
      "episode 14, val func loss 2.045466184616089\n",
      "\n",
      "episode 15, val func loss 1.746429443359375\n",
      "\n",
      "episode 16, val func loss 1.8724547624588013\n",
      "\n",
      "Val func train loss in epoch 8:1.6930411905050278\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.6527111530303955\n",
      "\n",
      "episode 2, val func loss 1.7556605339050293\n",
      "\n",
      "episode 3, val func loss 1.6924971342086792\n",
      "\n",
      "episode 4, val func loss 1.7061094045639038\n",
      "\n",
      "episode 5, val func loss 1.6650505065917969\n",
      "\n",
      "episode 6, val func loss 1.72675359249115\n",
      "\n",
      "episode 7, val func loss 1.6903337240219116\n",
      "\n",
      "episode 8, val func loss 1.7592382431030273\n",
      "\n",
      "episode 9, val func loss 1.4748512506484985\n",
      "\n",
      "episode 10, val func loss 1.6399682760238647\n",
      "\n",
      "episode 11, val func loss 1.5384067296981812\n",
      "\n",
      "episode 12, val func loss 1.6400095224380493\n",
      "\n",
      "episode 13, val func loss 1.6761058568954468\n",
      "\n",
      "episode 14, val func loss 1.7265853881835938\n",
      "\n",
      "episode 15, val func loss 1.984349012374878\n",
      "\n",
      "episode 16, val func loss 1.76678466796875\n",
      "\n",
      "Val func train loss in epoch 9:1.6934634372591972\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.6722787618637085\n",
      "\n",
      "episode 2, val func loss 1.4977095127105713\n",
      "\n",
      "episode 3, val func loss 1.6476006507873535\n",
      "\n",
      "episode 4, val func loss 1.895443320274353\n",
      "\n",
      "episode 5, val func loss 1.5812033414840698\n",
      "\n",
      "episode 6, val func loss 1.6660031080245972\n",
      "\n",
      "episode 7, val func loss 1.421377182006836\n",
      "\n",
      "episode 8, val func loss 1.75917649269104\n",
      "\n",
      "episode 9, val func loss 1.566092848777771\n",
      "\n",
      "episode 10, val func loss 1.8750019073486328\n",
      "\n",
      "episode 11, val func loss 1.5522092580795288\n",
      "\n",
      "episode 12, val func loss 1.5960159301757812\n",
      "\n",
      "episode 13, val func loss 1.558159589767456\n",
      "\n",
      "episode 14, val func loss 1.6401876211166382\n",
      "\n",
      "episode 15, val func loss 1.7037181854248047\n",
      "\n",
      "episode 16, val func loss 1.7343761920928955\n",
      "\n",
      "Val func train loss in epoch 10:1.6479096189141273\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.809030294418335\n",
      "\n",
      "episode 2, val func loss 1.6868103742599487\n",
      "\n",
      "episode 3, val func loss 1.5803920030593872\n",
      "\n",
      "episode 4, val func loss 1.785914421081543\n",
      "\n",
      "episode 5, val func loss 1.6404705047607422\n",
      "\n",
      "episode 6, val func loss 1.6471080780029297\n",
      "\n",
      "episode 7, val func loss 1.743479609489441\n",
      "\n",
      "episode 8, val func loss 1.61661958694458\n",
      "\n",
      "episode 9, val func loss 1.6702337265014648\n",
      "\n",
      "episode 10, val func loss 1.6913460493087769\n",
      "\n",
      "episode 11, val func loss 1.6958668231964111\n",
      "\n",
      "episode 12, val func loss 1.897136926651001\n",
      "\n",
      "episode 13, val func loss 1.7938684225082397\n",
      "\n",
      "episode 14, val func loss 1.8729569911956787\n",
      "\n",
      "episode 15, val func loss 1.5691102743148804\n",
      "\n",
      "episode 16, val func loss 1.5443894863128662\n",
      "\n",
      "Val func train loss in epoch 11:1.702795848250389\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.5398647785186768\n",
      "\n",
      "episode 2, val func loss 1.721008539199829\n",
      "\n",
      "episode 3, val func loss 1.5997165441513062\n",
      "\n",
      "episode 4, val func loss 1.3111830949783325\n",
      "\n",
      "episode 5, val func loss 1.7652188539505005\n",
      "\n",
      "episode 6, val func loss 1.7248139381408691\n",
      "\n",
      "episode 7, val func loss 1.8650392293930054\n",
      "\n",
      "episode 8, val func loss 1.591817855834961\n",
      "\n",
      "episode 9, val func loss 1.6740890741348267\n",
      "\n",
      "episode 10, val func loss 1.7215927839279175\n",
      "\n",
      "episode 11, val func loss 1.7407081127166748\n",
      "\n",
      "episode 12, val func loss 1.738330364227295\n",
      "\n",
      "episode 13, val func loss 1.6152012348175049\n",
      "\n",
      "episode 14, val func loss 1.6838054656982422\n",
      "\n",
      "episode 15, val func loss 1.6771615743637085\n",
      "\n",
      "episode 16, val func loss 1.5684919357299805\n",
      "\n",
      "Val func train loss in epoch 12:1.658627711236477\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.690168857574463\n",
      "\n",
      "episode 2, val func loss 1.8322317600250244\n",
      "\n",
      "episode 3, val func loss 1.5719075202941895\n",
      "\n",
      "episode 4, val func loss 1.7864248752593994\n",
      "\n",
      "episode 5, val func loss 1.810737133026123\n",
      "\n",
      "episode 6, val func loss 1.6279363632202148\n",
      "\n",
      "episode 7, val func loss 1.6513534784317017\n",
      "\n",
      "episode 8, val func loss 1.448803186416626\n",
      "\n",
      "episode 9, val func loss 1.576142430305481\n",
      "\n",
      "episode 10, val func loss 1.6575732231140137\n",
      "\n",
      "episode 11, val func loss 1.4290937185287476\n",
      "\n",
      "episode 12, val func loss 1.7220546007156372\n",
      "\n",
      "episode 13, val func loss 1.7298932075500488\n",
      "\n",
      "episode 14, val func loss 1.6026359796524048\n",
      "\n",
      "episode 15, val func loss 1.8816362619400024\n",
      "\n",
      "episode 16, val func loss 1.9173502922058105\n",
      "\n",
      "Val func train loss in epoch 13:1.683496430516243\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.7709320783615112\n",
      "\n",
      "episode 2, val func loss 1.6342076063156128\n",
      "\n",
      "episode 3, val func loss 1.5936684608459473\n",
      "\n",
      "episode 4, val func loss 1.760185956954956\n",
      "\n",
      "episode 5, val func loss 1.9716309309005737\n",
      "\n",
      "episode 6, val func loss 1.812021017074585\n",
      "\n",
      "episode 7, val func loss 1.8180290460586548\n",
      "\n",
      "episode 8, val func loss 1.9036178588867188\n",
      "\n",
      "episode 9, val func loss 1.7143278121948242\n",
      "\n",
      "episode 10, val func loss 1.8478440046310425\n",
      "\n",
      "episode 11, val func loss 1.7604289054870605\n",
      "\n",
      "episode 12, val func loss 2.354165554046631\n",
      "\n",
      "episode 13, val func loss 2.0172836780548096\n",
      "\n",
      "episode 14, val func loss 2.3436825275421143\n",
      "\n",
      "episode 15, val func loss 1.9620331525802612\n",
      "\n",
      "episode 16, val func loss 2.2692928314208984\n",
      "\n",
      "Val func train loss in epoch 14:1.9083344638347626\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.056901454925537\n",
      "\n",
      "episode 2, val func loss 1.9111577272415161\n",
      "\n",
      "episode 3, val func loss 2.025587320327759\n",
      "\n",
      "episode 4, val func loss 1.7891281843185425\n",
      "\n",
      "episode 5, val func loss 1.828857183456421\n",
      "\n",
      "episode 6, val func loss 1.9659284353256226\n",
      "\n",
      "episode 7, val func loss 1.9488794803619385\n",
      "\n",
      "episode 8, val func loss 1.9045045375823975\n",
      "\n",
      "episode 9, val func loss 1.8157891035079956\n",
      "\n",
      "episode 10, val func loss 1.9447250366210938\n",
      "\n",
      "episode 11, val func loss 1.7593348026275635\n",
      "\n",
      "episode 12, val func loss 1.748507022857666\n",
      "\n",
      "episode 13, val func loss 1.8494482040405273\n",
      "\n",
      "episode 14, val func loss 1.7771846055984497\n",
      "\n",
      "episode 15, val func loss 1.8758399486541748\n",
      "\n",
      "episode 16, val func loss 1.7506967782974243\n",
      "\n",
      "Val func train loss in epoch 15:1.8720293641090393\n",
      "***********************TIME WAS 5.1191797415415445 min*****************************\n",
      "\n",
      "**********************ROUND 14 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -1.7469114065170288\n",
      "\n",
      "episode 2, policy loss -1.7469114065170288\n",
      "\n",
      "episode 3, policy loss -1.746911644935608\n",
      "\n",
      "episode 4, policy loss -1.746911644935608\n",
      "\n",
      "episode 5, policy loss -1.7469117641448975\n",
      "\n",
      "episode 6, policy loss -1.746911644935608\n",
      "\n",
      "episode 7, policy loss -1.746911644935608\n",
      "\n",
      "episode 8, policy loss -1.746911644935608\n",
      "\n",
      "episode 9, policy loss -1.746911644935608\n",
      "\n",
      "episode 10, policy loss -1.7469117641448975\n",
      "\n",
      "episode 11, policy loss -1.7469117641448975\n",
      "\n",
      "episode 12, policy loss -1.746911644935608\n",
      "\n",
      "episode 13, policy loss -1.7469117641448975\n",
      "\n",
      "episode 14, policy loss -1.746911644935608\n",
      "\n",
      "episode 15, policy loss -1.7469117641448975\n",
      "\n",
      "episode 16, policy loss -1.7469117641448975\n",
      "\n",
      "Policy train loss in epoch 0:-1.746911659836769\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -1.746911644935608\n",
      "\n",
      "episode 2, policy loss -1.746911644935608\n",
      "\n",
      "episode 3, policy loss -1.7469117641448975\n",
      "\n",
      "episode 4, policy loss -1.746911644935608\n",
      "\n",
      "episode 5, policy loss -1.7469117641448975\n",
      "\n",
      "episode 6, policy loss -1.7469117641448975\n",
      "\n",
      "episode 7, policy loss -1.7469117641448975\n",
      "\n",
      "episode 8, policy loss -1.746911644935608\n",
      "\n",
      "episode 9, policy loss -1.746911644935608\n",
      "\n",
      "episode 10, policy loss -1.7469117641448975\n",
      "\n",
      "episode 11, policy loss -1.7469117641448975\n",
      "\n",
      "episode 12, policy loss -1.7469117641448975\n",
      "\n",
      "episode 13, policy loss -1.7469114065170288\n",
      "\n",
      "episode 14, policy loss -1.7469114065170288\n",
      "\n",
      "episode 15, policy loss -1.7469117641448975\n",
      "\n",
      "episode 16, policy loss -1.7469117641448975\n",
      "\n",
      "Policy train loss in epoch 1:-1.746911682188511\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -1.746911644935608\n",
      "\n",
      "episode 2, policy loss -1.746911644935608\n",
      "\n",
      "episode 3, policy loss -1.7469117641448975\n",
      "\n",
      "episode 4, policy loss -1.7469117641448975\n",
      "\n",
      "episode 5, policy loss -1.746911644935608\n",
      "\n",
      "episode 6, policy loss -1.746911644935608\n",
      "\n",
      "episode 7, policy loss -1.7469117641448975\n",
      "\n",
      "episode 8, policy loss -1.7469117641448975\n",
      "\n",
      "episode 9, policy loss -1.7469114065170288\n",
      "\n",
      "episode 10, policy loss -1.7469117641448975\n",
      "\n",
      "episode 11, policy loss -1.746911644935608\n",
      "\n",
      "episode 12, policy loss -1.7469117641448975\n",
      "\n",
      "episode 13, policy loss -1.7469117641448975\n",
      "\n",
      "episode 14, policy loss -1.7469117641448975\n",
      "\n",
      "episode 15, policy loss -1.746911644935608\n",
      "\n",
      "episode 16, policy loss -1.7469117641448975\n",
      "\n",
      "Policy train loss in epoch 2:-1.746911697089672\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -1.746911644935608\n",
      "\n",
      "episode 2, policy loss -1.7469117641448975\n",
      "\n",
      "episode 3, policy loss -1.746911644935608\n",
      "\n",
      "episode 4, policy loss -1.7469114065170288\n",
      "\n",
      "episode 5, policy loss -1.7469117641448975\n",
      "\n",
      "episode 6, policy loss -1.7469117641448975\n",
      "\n",
      "episode 7, policy loss -1.7469117641448975\n",
      "\n",
      "episode 8, policy loss -1.7469117641448975\n",
      "\n",
      "episode 9, policy loss -1.746911644935608\n",
      "\n",
      "episode 10, policy loss -1.746911644935608\n",
      "\n",
      "episode 11, policy loss -1.7469117641448975\n",
      "\n",
      "episode 12, policy loss -1.746911644935608\n",
      "\n",
      "episode 13, policy loss -1.7469117641448975\n",
      "\n",
      "episode 14, policy loss -1.7469117641448975\n",
      "\n",
      "episode 15, policy loss -1.7469117641448975\n",
      "\n",
      "episode 16, policy loss -1.7469117641448975\n",
      "\n",
      "Policy train loss in epoch 3:-1.7469117045402527\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.7143014669418335\n",
      "\n",
      "episode 2, val func loss 1.6416596174240112\n",
      "\n",
      "episode 3, val func loss 1.694797158241272\n",
      "\n",
      "episode 4, val func loss 1.77964186668396\n",
      "\n",
      "episode 5, val func loss 1.6452046632766724\n",
      "\n",
      "episode 6, val func loss 1.7464966773986816\n",
      "\n",
      "episode 7, val func loss 1.610522747039795\n",
      "\n",
      "episode 8, val func loss 1.778361201286316\n",
      "\n",
      "episode 9, val func loss 1.5641132593154907\n",
      "\n",
      "episode 10, val func loss 1.5803532600402832\n",
      "\n",
      "episode 11, val func loss 1.7522772550582886\n",
      "\n",
      "episode 12, val func loss 1.7776967287063599\n",
      "\n",
      "episode 13, val func loss 1.4356344938278198\n",
      "\n",
      "episode 14, val func loss 1.8846744298934937\n",
      "\n",
      "episode 15, val func loss 1.7479664087295532\n",
      "\n",
      "episode 16, val func loss 1.4803632497787476\n",
      "\n",
      "Val func train loss in epoch 0:1.6771290302276611\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.72995924949646\n",
      "\n",
      "episode 2, val func loss 1.7950286865234375\n",
      "\n",
      "episode 3, val func loss 1.742240309715271\n",
      "\n",
      "episode 4, val func loss 1.6721991300582886\n",
      "\n",
      "episode 5, val func loss 1.727743148803711\n",
      "\n",
      "episode 6, val func loss 1.5494192838668823\n",
      "\n",
      "episode 7, val func loss 1.7352913618087769\n",
      "\n",
      "episode 8, val func loss 1.7698765993118286\n",
      "\n",
      "episode 9, val func loss 1.8364307880401611\n",
      "\n",
      "episode 10, val func loss 1.5170519351959229\n",
      "\n",
      "episode 11, val func loss 1.7611421346664429\n",
      "\n",
      "episode 12, val func loss 1.6722843647003174\n",
      "\n",
      "episode 13, val func loss 1.7705174684524536\n",
      "\n",
      "episode 14, val func loss 1.6950428485870361\n",
      "\n",
      "episode 15, val func loss 1.7956244945526123\n",
      "\n",
      "episode 16, val func loss 1.608837604522705\n",
      "\n",
      "Val func train loss in epoch 1:1.7111680880188942\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.77848482131958\n",
      "\n",
      "episode 2, val func loss 1.8556272983551025\n",
      "\n",
      "episode 3, val func loss 1.5496370792388916\n",
      "\n",
      "episode 4, val func loss 1.7838927507400513\n",
      "\n",
      "episode 5, val func loss 1.8442165851593018\n",
      "\n",
      "episode 6, val func loss 1.8348679542541504\n",
      "\n",
      "episode 7, val func loss 1.8018043041229248\n",
      "\n",
      "episode 8, val func loss 1.6503376960754395\n",
      "\n",
      "episode 9, val func loss 1.7654541730880737\n",
      "\n",
      "episode 10, val func loss 1.7080374956130981\n",
      "\n",
      "episode 11, val func loss 1.9209394454956055\n",
      "\n",
      "episode 12, val func loss 1.694840669631958\n",
      "\n",
      "episode 13, val func loss 1.6496280431747437\n",
      "\n",
      "episode 14, val func loss 1.6380702257156372\n",
      "\n",
      "episode 15, val func loss 1.842179536819458\n",
      "\n",
      "episode 16, val func loss 1.7406951189041138\n",
      "\n",
      "Val func train loss in epoch 2:1.7536695748567581\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.600080966949463\n",
      "\n",
      "episode 2, val func loss 1.8794918060302734\n",
      "\n",
      "episode 3, val func loss 1.8353898525238037\n",
      "\n",
      "episode 4, val func loss 1.7493382692337036\n",
      "\n",
      "episode 5, val func loss 1.4855213165283203\n",
      "\n",
      "episode 6, val func loss 1.9740972518920898\n",
      "\n",
      "episode 7, val func loss 1.6315340995788574\n",
      "\n",
      "episode 8, val func loss 1.9557359218597412\n",
      "\n",
      "episode 9, val func loss 1.6614142656326294\n",
      "\n",
      "episode 10, val func loss 1.6837105751037598\n",
      "\n",
      "episode 11, val func loss 1.7356680631637573\n",
      "\n",
      "episode 12, val func loss 1.7232424020767212\n",
      "\n",
      "episode 13, val func loss 1.7457308769226074\n",
      "\n",
      "episode 14, val func loss 1.677890658378601\n",
      "\n",
      "episode 15, val func loss 1.8519172668457031\n",
      "\n",
      "episode 16, val func loss 1.6409162282943726\n",
      "\n",
      "Val func train loss in epoch 3:1.7394799888134003\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.6776326894760132\n",
      "\n",
      "episode 2, val func loss 2.0403568744659424\n",
      "\n",
      "episode 3, val func loss 1.8512310981750488\n",
      "\n",
      "episode 4, val func loss 1.7245498895645142\n",
      "\n",
      "episode 5, val func loss 1.7579952478408813\n",
      "\n",
      "episode 6, val func loss 1.775505781173706\n",
      "\n",
      "episode 7, val func loss 1.6054883003234863\n",
      "\n",
      "episode 8, val func loss 1.7490695714950562\n",
      "\n",
      "episode 9, val func loss 1.6147176027297974\n",
      "\n",
      "episode 10, val func loss 1.774335503578186\n",
      "\n",
      "episode 11, val func loss 1.754670262336731\n",
      "\n",
      "episode 12, val func loss 1.7686867713928223\n",
      "\n",
      "episode 13, val func loss 1.4737250804901123\n",
      "\n",
      "episode 14, val func loss 1.6416317224502563\n",
      "\n",
      "episode 15, val func loss 1.8702963590621948\n",
      "\n",
      "episode 16, val func loss 1.5945922136306763\n",
      "\n",
      "Val func train loss in epoch 4:1.729655310511589\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.6962910890579224\n",
      "\n",
      "episode 2, val func loss 1.6465290784835815\n",
      "\n",
      "episode 3, val func loss 1.576356291770935\n",
      "\n",
      "episode 4, val func loss 1.5321811437606812\n",
      "\n",
      "episode 5, val func loss 1.6672013998031616\n",
      "\n",
      "episode 6, val func loss 1.8150217533111572\n",
      "\n",
      "episode 7, val func loss 1.544494867324829\n",
      "\n",
      "episode 8, val func loss 1.6547108888626099\n",
      "\n",
      "episode 9, val func loss 1.7341749668121338\n",
      "\n",
      "episode 10, val func loss 1.4976619482040405\n",
      "\n",
      "episode 11, val func loss 1.6952035427093506\n",
      "\n",
      "episode 12, val func loss 1.577971339225769\n",
      "\n",
      "episode 13, val func loss 1.572266936302185\n",
      "\n",
      "episode 14, val func loss 1.5359810590744019\n",
      "\n",
      "episode 15, val func loss 1.6446354389190674\n",
      "\n",
      "episode 16, val func loss 1.6115493774414062\n",
      "\n",
      "Val func train loss in epoch 5:1.625139445066452\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.8227555751800537\n",
      "\n",
      "episode 2, val func loss 1.591921091079712\n",
      "\n",
      "episode 3, val func loss 1.7329994440078735\n",
      "\n",
      "episode 4, val func loss 1.6112300157546997\n",
      "\n",
      "episode 5, val func loss 1.5769320726394653\n",
      "\n",
      "episode 6, val func loss 1.6406805515289307\n",
      "\n",
      "episode 7, val func loss 1.5849465131759644\n",
      "\n",
      "episode 8, val func loss 1.701619029045105\n",
      "\n",
      "episode 9, val func loss 1.6264411211013794\n",
      "\n",
      "episode 10, val func loss 2.027078866958618\n",
      "\n",
      "episode 11, val func loss 1.5919674634933472\n",
      "\n",
      "episode 12, val func loss 1.7248938083648682\n",
      "\n",
      "episode 13, val func loss 1.5192466974258423\n",
      "\n",
      "episode 14, val func loss 1.5157418251037598\n",
      "\n",
      "episode 15, val func loss 1.4928494691848755\n",
      "\n",
      "episode 16, val func loss 1.5752863883972168\n",
      "\n",
      "Val func train loss in epoch 6:1.646036870777607\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.6810187101364136\n",
      "\n",
      "episode 2, val func loss 1.7002609968185425\n",
      "\n",
      "episode 3, val func loss 1.754631757736206\n",
      "\n",
      "episode 4, val func loss 1.6211179494857788\n",
      "\n",
      "episode 5, val func loss 1.4165523052215576\n",
      "\n",
      "episode 6, val func loss 1.9267621040344238\n",
      "\n",
      "episode 7, val func loss 1.7126573324203491\n",
      "\n",
      "episode 8, val func loss 1.685080885887146\n",
      "\n",
      "episode 9, val func loss 1.486790418624878\n",
      "\n",
      "episode 10, val func loss 1.499612808227539\n",
      "\n",
      "episode 11, val func loss 1.5286457538604736\n",
      "\n",
      "episode 12, val func loss 1.5854843854904175\n",
      "\n",
      "episode 13, val func loss 1.7675971984863281\n",
      "\n",
      "episode 14, val func loss 1.730338215827942\n",
      "\n",
      "episode 15, val func loss 2.09074068069458\n",
      "\n",
      "episode 16, val func loss 2.0383713245391846\n",
      "\n",
      "Val func train loss in epoch 7:1.701603926718235\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.6587777137756348\n",
      "\n",
      "episode 2, val func loss 1.9287605285644531\n",
      "\n",
      "episode 3, val func loss 1.5759648084640503\n",
      "\n",
      "episode 4, val func loss 1.876321792602539\n",
      "\n",
      "episode 5, val func loss 1.8556572198867798\n",
      "\n",
      "episode 6, val func loss 1.8819620609283447\n",
      "\n",
      "episode 7, val func loss 2.0838351249694824\n",
      "\n",
      "episode 8, val func loss 1.8175405263900757\n",
      "\n",
      "episode 9, val func loss 1.8389815092086792\n",
      "\n",
      "episode 10, val func loss 1.7905864715576172\n",
      "\n",
      "episode 11, val func loss 1.8568902015686035\n",
      "\n",
      "episode 12, val func loss 1.6319173574447632\n",
      "\n",
      "episode 13, val func loss 1.591770052909851\n",
      "\n",
      "episode 14, val func loss 1.6895321607589722\n",
      "\n",
      "episode 15, val func loss 1.7151548862457275\n",
      "\n",
      "episode 16, val func loss 1.7940757274627686\n",
      "\n",
      "Val func train loss in epoch 8:1.7867330089211464\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.72135329246521\n",
      "\n",
      "episode 2, val func loss 1.6953336000442505\n",
      "\n",
      "episode 3, val func loss 1.7841567993164062\n",
      "\n",
      "episode 4, val func loss 1.7398728132247925\n",
      "\n",
      "episode 5, val func loss 1.7356914281845093\n",
      "\n",
      "episode 6, val func loss 1.901300072669983\n",
      "\n",
      "episode 7, val func loss 1.9023072719573975\n",
      "\n",
      "episode 8, val func loss 2.167649984359741\n",
      "\n",
      "episode 9, val func loss 1.8727843761444092\n",
      "\n",
      "episode 10, val func loss 2.076873302459717\n",
      "\n",
      "episode 11, val func loss 1.98427414894104\n",
      "\n",
      "episode 12, val func loss 2.007206916809082\n",
      "\n",
      "episode 13, val func loss 1.7385189533233643\n",
      "\n",
      "episode 14, val func loss 1.7324689626693726\n",
      "\n",
      "episode 15, val func loss 1.9283441305160522\n",
      "\n",
      "episode 16, val func loss 1.8394553661346436\n",
      "\n",
      "Val func train loss in epoch 9:1.8642244637012482\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.938265323638916\n",
      "\n",
      "episode 2, val func loss 2.040436267852783\n",
      "\n",
      "episode 3, val func loss 1.6588616371154785\n",
      "\n",
      "episode 4, val func loss 1.8935168981552124\n",
      "\n",
      "episode 5, val func loss 1.7280027866363525\n",
      "\n",
      "episode 6, val func loss 1.70784330368042\n",
      "\n",
      "episode 7, val func loss 1.6781738996505737\n",
      "\n",
      "episode 8, val func loss 1.7769842147827148\n",
      "\n",
      "episode 9, val func loss 1.692394733428955\n",
      "\n",
      "episode 10, val func loss 1.718202829360962\n",
      "\n",
      "episode 11, val func loss 1.6592984199523926\n",
      "\n",
      "episode 12, val func loss 1.529165506362915\n",
      "\n",
      "episode 13, val func loss 1.6825387477874756\n",
      "\n",
      "episode 14, val func loss 1.580660343170166\n",
      "\n",
      "episode 15, val func loss 1.6803240776062012\n",
      "\n",
      "episode 16, val func loss 1.9718097448349\n",
      "\n",
      "Val func train loss in epoch 10:1.7460299208760262\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.9788352251052856\n",
      "\n",
      "episode 2, val func loss 1.6947872638702393\n",
      "\n",
      "episode 3, val func loss 1.6073299646377563\n",
      "\n",
      "episode 4, val func loss 1.776906132698059\n",
      "\n",
      "episode 5, val func loss 1.5666265487670898\n",
      "\n",
      "episode 6, val func loss 1.467825174331665\n",
      "\n",
      "episode 7, val func loss 1.5006000995635986\n",
      "\n",
      "episode 8, val func loss 1.6570056676864624\n",
      "\n",
      "episode 9, val func loss 1.8375191688537598\n",
      "\n",
      "episode 10, val func loss 1.6708420515060425\n",
      "\n",
      "episode 11, val func loss 1.666306734085083\n",
      "\n",
      "episode 12, val func loss 1.640034556388855\n",
      "\n",
      "episode 13, val func loss 1.7979382276535034\n",
      "\n",
      "episode 14, val func loss 1.6904231309890747\n",
      "\n",
      "episode 15, val func loss 1.5698750019073486\n",
      "\n",
      "episode 16, val func loss 1.637139916419983\n",
      "\n",
      "Val func train loss in epoch 11:1.6724996790289879\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.4744269847869873\n",
      "\n",
      "episode 2, val func loss 1.6906795501708984\n",
      "\n",
      "episode 3, val func loss 1.740817904472351\n",
      "\n",
      "episode 4, val func loss 1.5030759572982788\n",
      "\n",
      "episode 5, val func loss 1.8320112228393555\n",
      "\n",
      "episode 6, val func loss 1.7749803066253662\n",
      "\n",
      "episode 7, val func loss 1.7833141088485718\n",
      "\n",
      "episode 8, val func loss 1.4854952096939087\n",
      "\n",
      "episode 9, val func loss 1.7766458988189697\n",
      "\n",
      "episode 10, val func loss 1.8128712177276611\n",
      "\n",
      "episode 11, val func loss 1.7359755039215088\n",
      "\n",
      "episode 12, val func loss 1.9740222692489624\n",
      "\n",
      "episode 13, val func loss 1.7815006971359253\n",
      "\n",
      "episode 14, val func loss 1.673067331314087\n",
      "\n",
      "episode 15, val func loss 1.6995246410369873\n",
      "\n",
      "episode 16, val func loss 1.6635677814483643\n",
      "\n",
      "Val func train loss in epoch 12:1.7126235365867615\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.8014408349990845\n",
      "\n",
      "episode 2, val func loss 1.7802668809890747\n",
      "\n",
      "episode 3, val func loss 1.496717929840088\n",
      "\n",
      "episode 4, val func loss 1.4718961715698242\n",
      "\n",
      "episode 5, val func loss 1.6853327751159668\n",
      "\n",
      "episode 6, val func loss 1.4542070627212524\n",
      "\n",
      "episode 7, val func loss 1.7475725412368774\n",
      "\n",
      "episode 8, val func loss 1.7698020935058594\n",
      "\n",
      "episode 9, val func loss 1.809244990348816\n",
      "\n",
      "episode 10, val func loss 1.6792207956314087\n",
      "\n",
      "episode 11, val func loss 1.680471658706665\n",
      "\n",
      "episode 12, val func loss 1.5481033325195312\n",
      "\n",
      "episode 13, val func loss 1.9133381843566895\n",
      "\n",
      "episode 14, val func loss 1.7771755456924438\n",
      "\n",
      "episode 15, val func loss 1.7099761962890625\n",
      "\n",
      "episode 16, val func loss 1.6407053470611572\n",
      "\n",
      "Val func train loss in epoch 13:1.6853420212864876\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.6305898427963257\n",
      "\n",
      "episode 2, val func loss 1.866097331047058\n",
      "\n",
      "episode 3, val func loss 1.6401704549789429\n",
      "\n",
      "episode 4, val func loss 1.4556294679641724\n",
      "\n",
      "episode 5, val func loss 1.6518001556396484\n",
      "\n",
      "episode 6, val func loss 1.6036053895950317\n",
      "\n",
      "episode 7, val func loss 1.6556649208068848\n",
      "\n",
      "episode 8, val func loss 1.5077320337295532\n",
      "\n",
      "episode 9, val func loss 1.8400099277496338\n",
      "\n",
      "episode 10, val func loss 1.7304767370224\n",
      "\n",
      "episode 11, val func loss 1.6545095443725586\n",
      "\n",
      "episode 12, val func loss 1.545891523361206\n",
      "\n",
      "episode 13, val func loss 1.4913887977600098\n",
      "\n",
      "episode 14, val func loss 1.322918176651001\n",
      "\n",
      "episode 15, val func loss 1.6155964136123657\n",
      "\n",
      "episode 16, val func loss 1.6440751552581787\n",
      "\n",
      "Val func train loss in epoch 14:1.6160097420215607\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.4583072662353516\n",
      "\n",
      "episode 2, val func loss 1.716807246208191\n",
      "\n",
      "episode 3, val func loss 1.590091586112976\n",
      "\n",
      "episode 4, val func loss 1.5856512784957886\n",
      "\n",
      "episode 5, val func loss 1.6887781620025635\n",
      "\n",
      "episode 6, val func loss 1.5776430368423462\n",
      "\n",
      "episode 7, val func loss 1.5770118236541748\n",
      "\n",
      "episode 8, val func loss 1.7929521799087524\n",
      "\n",
      "episode 9, val func loss 1.6862003803253174\n",
      "\n",
      "episode 10, val func loss 1.5581426620483398\n",
      "\n",
      "episode 11, val func loss 1.746114730834961\n",
      "\n",
      "episode 12, val func loss 1.7998216152191162\n",
      "\n",
      "episode 13, val func loss 1.6484273672103882\n",
      "\n",
      "episode 14, val func loss 1.7394452095031738\n",
      "\n",
      "episode 15, val func loss 1.7826038599014282\n",
      "\n",
      "episode 16, val func loss 1.7529174089431763\n",
      "\n",
      "Val func train loss in epoch 15:1.6688072383403778\n",
      "***********************TIME WAS 4.819106515248617 min*****************************\n",
      "\n",
      "**********************ROUND 15 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.3946619033813477\n",
      "\n",
      "episode 2, policy loss -2.3946616649627686\n",
      "\n",
      "episode 3, policy loss -2.3946616649627686\n",
      "\n",
      "episode 4, policy loss -2.3946616649627686\n",
      "\n",
      "episode 5, policy loss -2.3946616649627686\n",
      "\n",
      "episode 6, policy loss -2.3946616649627686\n",
      "\n",
      "episode 7, policy loss -2.3946619033813477\n",
      "\n",
      "episode 8, policy loss -2.3946619033813477\n",
      "\n",
      "episode 9, policy loss -2.3946616649627686\n",
      "\n",
      "episode 10, policy loss -2.3946616649627686\n",
      "\n",
      "episode 11, policy loss -2.3946619033813477\n",
      "\n",
      "episode 12, policy loss -2.3946616649627686\n",
      "\n",
      "episode 13, policy loss -2.3946619033813477\n",
      "\n",
      "episode 14, policy loss -2.3946616649627686\n",
      "\n",
      "episode 15, policy loss -2.3946616649627686\n",
      "\n",
      "episode 16, policy loss -2.3946616649627686\n",
      "\n",
      "Policy train loss in epoch 0:-2.3946617394685745\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.3946619033813477\n",
      "\n",
      "episode 2, policy loss -2.3946616649627686\n",
      "\n",
      "episode 3, policy loss -2.3946616649627686\n",
      "\n",
      "episode 4, policy loss -2.3946616649627686\n",
      "\n",
      "episode 5, policy loss -2.3946616649627686\n",
      "\n",
      "episode 6, policy loss -2.3946619033813477\n",
      "\n",
      "episode 7, policy loss -2.3946616649627686\n",
      "\n",
      "episode 8, policy loss -2.3946619033813477\n",
      "\n",
      "episode 9, policy loss -2.3946616649627686\n",
      "\n",
      "episode 10, policy loss -2.3946616649627686\n",
      "\n",
      "episode 11, policy loss -2.3946616649627686\n",
      "\n",
      "episode 12, policy loss -2.3946619033813477\n",
      "\n",
      "episode 13, policy loss -2.3946616649627686\n",
      "\n",
      "episode 14, policy loss -2.3946619033813477\n",
      "\n",
      "episode 15, policy loss -2.3946619033813477\n",
      "\n",
      "episode 16, policy loss -2.3946616649627686\n",
      "\n",
      "Policy train loss in epoch 1:-2.3946617543697357\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.3946619033813477\n",
      "\n",
      "episode 2, policy loss -2.3946619033813477\n",
      "\n",
      "episode 3, policy loss -2.3946616649627686\n",
      "\n",
      "episode 4, policy loss -2.3946619033813477\n",
      "\n",
      "episode 5, policy loss -2.3946616649627686\n",
      "\n",
      "episode 6, policy loss -2.3946619033813477\n",
      "\n",
      "episode 7, policy loss -2.3946616649627686\n",
      "\n",
      "episode 8, policy loss -2.3946616649627686\n",
      "\n",
      "episode 9, policy loss -2.3946619033813477\n",
      "\n",
      "episode 10, policy loss -2.3946619033813477\n",
      "\n",
      "episode 11, policy loss -2.3946616649627686\n",
      "\n",
      "episode 12, policy loss -2.3946616649627686\n",
      "\n",
      "episode 13, policy loss -2.3946616649627686\n",
      "\n",
      "episode 14, policy loss -2.3946616649627686\n",
      "\n",
      "episode 15, policy loss -2.3946616649627686\n",
      "\n",
      "episode 16, policy loss -2.3946616649627686\n",
      "\n",
      "Policy train loss in epoch 2:-2.3946617543697357\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.3946616649627686\n",
      "\n",
      "episode 2, policy loss -2.3946619033813477\n",
      "\n",
      "episode 3, policy loss -2.3946616649627686\n",
      "\n",
      "episode 4, policy loss -2.3946616649627686\n",
      "\n",
      "episode 5, policy loss -2.3946616649627686\n",
      "\n",
      "episode 6, policy loss -2.3946616649627686\n",
      "\n",
      "episode 7, policy loss -2.3946619033813477\n",
      "\n",
      "episode 8, policy loss -2.3946616649627686\n",
      "\n",
      "episode 9, policy loss -2.3946616649627686\n",
      "\n",
      "episode 10, policy loss -2.3946619033813477\n",
      "\n",
      "episode 11, policy loss -2.3946619033813477\n",
      "\n",
      "episode 12, policy loss -2.3946616649627686\n",
      "\n",
      "episode 13, policy loss -2.3946619033813477\n",
      "\n",
      "episode 14, policy loss -2.3946616649627686\n",
      "\n",
      "episode 15, policy loss -2.3946616649627686\n",
      "\n",
      "episode 16, policy loss -2.3946619033813477\n",
      "\n",
      "Policy train loss in epoch 3:-2.3946617543697357\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.7866116762161255\n",
      "\n",
      "episode 2, val func loss 1.715149998664856\n",
      "\n",
      "episode 3, val func loss 2.3647541999816895\n",
      "\n",
      "episode 4, val func loss 2.045523166656494\n",
      "\n",
      "episode 5, val func loss 3.590080976486206\n",
      "\n",
      "episode 6, val func loss 3.305274724960327\n",
      "\n",
      "episode 7, val func loss 3.736624002456665\n",
      "\n",
      "episode 8, val func loss 2.31661319732666\n",
      "\n",
      "episode 9, val func loss 1.9224436283111572\n",
      "\n",
      "episode 10, val func loss 3.1033308506011963\n",
      "\n",
      "episode 11, val func loss 2.7789862155914307\n",
      "\n",
      "episode 12, val func loss 2.112316608428955\n",
      "\n",
      "episode 13, val func loss 1.8737152814865112\n",
      "\n",
      "episode 14, val func loss 2.2039554119110107\n",
      "\n",
      "episode 15, val func loss 2.4050989151000977\n",
      "\n",
      "episode 16, val func loss 2.015774965286255\n",
      "\n",
      "Val func train loss in epoch 0:2.4547658637166023\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.188410520553589\n",
      "\n",
      "episode 2, val func loss 2.216883897781372\n",
      "\n",
      "episode 3, val func loss 1.9813109636306763\n",
      "\n",
      "episode 4, val func loss 1.9965488910675049\n",
      "\n",
      "episode 5, val func loss 2.0740747451782227\n",
      "\n",
      "episode 6, val func loss 1.8451368808746338\n",
      "\n",
      "episode 7, val func loss 1.9393961429595947\n",
      "\n",
      "episode 8, val func loss 2.1521849632263184\n",
      "\n",
      "episode 9, val func loss 1.5795923471450806\n",
      "\n",
      "episode 10, val func loss 1.8719732761383057\n",
      "\n",
      "episode 11, val func loss 1.8567036390304565\n",
      "\n",
      "episode 12, val func loss 1.7400766611099243\n",
      "\n",
      "episode 13, val func loss 1.5795235633850098\n",
      "\n",
      "episode 14, val func loss 2.0440614223480225\n",
      "\n",
      "episode 15, val func loss 1.8322718143463135\n",
      "\n",
      "episode 16, val func loss 1.5597007274627686\n",
      "\n",
      "Val func train loss in epoch 1:1.903615653514862\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.7775318622589111\n",
      "\n",
      "episode 2, val func loss 1.6686022281646729\n",
      "\n",
      "episode 3, val func loss 1.6693435907363892\n",
      "\n",
      "episode 4, val func loss 1.7733845710754395\n",
      "\n",
      "episode 5, val func loss 1.6144675016403198\n",
      "\n",
      "episode 6, val func loss 1.6131261587142944\n",
      "\n",
      "episode 7, val func loss 1.6206190586090088\n",
      "\n",
      "episode 8, val func loss 1.5380749702453613\n",
      "\n",
      "episode 9, val func loss 1.6308534145355225\n",
      "\n",
      "episode 10, val func loss 1.5970886945724487\n",
      "\n",
      "episode 11, val func loss 1.7852040529251099\n",
      "\n",
      "episode 12, val func loss 1.620088815689087\n",
      "\n",
      "episode 13, val func loss 1.9216992855072021\n",
      "\n",
      "episode 14, val func loss 1.6234197616577148\n",
      "\n",
      "episode 15, val func loss 1.4022208452224731\n",
      "\n",
      "episode 16, val func loss 1.6074564456939697\n",
      "\n",
      "Val func train loss in epoch 2:1.6539488285779953\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.7622252702713013\n",
      "\n",
      "episode 2, val func loss 1.6804448366165161\n",
      "\n",
      "episode 3, val func loss 1.754017949104309\n",
      "\n",
      "episode 4, val func loss 1.6717190742492676\n",
      "\n",
      "episode 5, val func loss 1.7644609212875366\n",
      "\n",
      "episode 6, val func loss 1.416759967803955\n",
      "\n",
      "episode 7, val func loss 1.5932115316390991\n",
      "\n",
      "episode 8, val func loss 1.508188009262085\n",
      "\n",
      "episode 9, val func loss 1.6550427675247192\n",
      "\n",
      "episode 10, val func loss 1.388581395149231\n",
      "\n",
      "episode 11, val func loss 1.611143708229065\n",
      "\n",
      "episode 12, val func loss 1.8329811096191406\n",
      "\n",
      "episode 13, val func loss 1.6743336915969849\n",
      "\n",
      "episode 14, val func loss 1.6517677307128906\n",
      "\n",
      "episode 15, val func loss 1.7071821689605713\n",
      "\n",
      "episode 16, val func loss 1.6649059057235718\n",
      "\n",
      "Val func train loss in epoch 3:1.6460603773593903\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.6354377269744873\n",
      "\n",
      "episode 2, val func loss 1.6863566637039185\n",
      "\n",
      "episode 3, val func loss 1.75681471824646\n",
      "\n",
      "episode 4, val func loss 1.707826018333435\n",
      "\n",
      "episode 5, val func loss 1.4853425025939941\n",
      "\n",
      "episode 6, val func loss 1.9241920709609985\n",
      "\n",
      "episode 7, val func loss 1.5178438425064087\n",
      "\n",
      "episode 8, val func loss 1.6573772430419922\n",
      "\n",
      "episode 9, val func loss 1.6125174760818481\n",
      "\n",
      "episode 10, val func loss 1.651299238204956\n",
      "\n",
      "episode 11, val func loss 1.7170758247375488\n",
      "\n",
      "episode 12, val func loss 1.6767452955245972\n",
      "\n",
      "episode 13, val func loss 1.62026846408844\n",
      "\n",
      "episode 14, val func loss 1.6028109788894653\n",
      "\n",
      "episode 15, val func loss 1.35850989818573\n",
      "\n",
      "episode 16, val func loss 1.6016850471496582\n",
      "\n",
      "Val func train loss in epoch 4:1.6382564380764961\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.631036400794983\n",
      "\n",
      "episode 2, val func loss 1.551160216331482\n",
      "\n",
      "episode 3, val func loss 1.661413311958313\n",
      "\n",
      "episode 4, val func loss 1.3866628408432007\n",
      "\n",
      "episode 5, val func loss 1.727092981338501\n",
      "\n",
      "episode 6, val func loss 1.6806846857070923\n",
      "\n",
      "episode 7, val func loss 1.623401165008545\n",
      "\n",
      "episode 8, val func loss 1.6152215003967285\n",
      "\n",
      "episode 9, val func loss 1.4973559379577637\n",
      "\n",
      "episode 10, val func loss 1.4931398630142212\n",
      "\n",
      "episode 11, val func loss 1.622011661529541\n",
      "\n",
      "episode 12, val func loss 1.4351236820220947\n",
      "\n",
      "episode 13, val func loss 1.422350525856018\n",
      "\n",
      "episode 14, val func loss 1.6758549213409424\n",
      "\n",
      "episode 15, val func loss 1.5885372161865234\n",
      "\n",
      "episode 16, val func loss 1.543467402458191\n",
      "\n",
      "Val func train loss in epoch 5:1.5721571445465088\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.559741497039795\n",
      "\n",
      "episode 2, val func loss 1.722217082977295\n",
      "\n",
      "episode 3, val func loss 1.6121816635131836\n",
      "\n",
      "episode 4, val func loss 1.6075212955474854\n",
      "\n",
      "episode 5, val func loss 1.5018306970596313\n",
      "\n",
      "episode 6, val func loss 1.4138768911361694\n",
      "\n",
      "episode 7, val func loss 1.6805613040924072\n",
      "\n",
      "episode 8, val func loss 1.5151735544204712\n",
      "\n",
      "episode 9, val func loss 1.6515027284622192\n",
      "\n",
      "episode 10, val func loss 1.4235780239105225\n",
      "\n",
      "episode 11, val func loss 1.5833121538162231\n",
      "\n",
      "episode 12, val func loss 1.69979727268219\n",
      "\n",
      "episode 13, val func loss 1.7774827480316162\n",
      "\n",
      "episode 14, val func loss 1.81679105758667\n",
      "\n",
      "episode 15, val func loss 1.54695725440979\n",
      "\n",
      "episode 16, val func loss 1.681750774383545\n",
      "\n",
      "Val func train loss in epoch 6:1.6121422499418259\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.487947702407837\n",
      "\n",
      "episode 2, val func loss 1.744789481163025\n",
      "\n",
      "episode 3, val func loss 1.6273794174194336\n",
      "\n",
      "episode 4, val func loss 1.627829909324646\n",
      "\n",
      "episode 5, val func loss 1.7193104028701782\n",
      "\n",
      "episode 6, val func loss 1.8780087232589722\n",
      "\n",
      "episode 7, val func loss 1.5241928100585938\n",
      "\n",
      "episode 8, val func loss 1.5303245782852173\n",
      "\n",
      "episode 9, val func loss 1.6451668739318848\n",
      "\n",
      "episode 10, val func loss 1.8324223756790161\n",
      "\n",
      "episode 11, val func loss 1.582241415977478\n",
      "\n",
      "episode 12, val func loss 1.6803866624832153\n",
      "\n",
      "episode 13, val func loss 1.540190577507019\n",
      "\n",
      "episode 14, val func loss 1.6426693201065063\n",
      "\n",
      "episode 15, val func loss 1.749423861503601\n",
      "\n",
      "episode 16, val func loss 1.6274425983428955\n",
      "\n",
      "Val func train loss in epoch 7:1.65248291939497\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.7209875583648682\n",
      "\n",
      "episode 2, val func loss 1.728089690208435\n",
      "\n",
      "episode 3, val func loss 1.6256862878799438\n",
      "\n",
      "episode 4, val func loss 1.6169606447219849\n",
      "\n",
      "episode 5, val func loss 1.4297678470611572\n",
      "\n",
      "episode 6, val func loss 1.7740262746810913\n",
      "\n",
      "episode 7, val func loss 1.5655564069747925\n",
      "\n",
      "episode 8, val func loss 1.8578423261642456\n",
      "\n",
      "episode 9, val func loss 1.6107147932052612\n",
      "\n",
      "episode 10, val func loss 1.732375979423523\n",
      "\n",
      "episode 11, val func loss 1.53763747215271\n",
      "\n",
      "episode 12, val func loss 1.5861865282058716\n",
      "\n",
      "episode 13, val func loss 1.8041043281555176\n",
      "\n",
      "episode 14, val func loss 1.62435781955719\n",
      "\n",
      "episode 15, val func loss 1.8488068580627441\n",
      "\n",
      "episode 16, val func loss 1.5417289733886719\n",
      "\n",
      "Val func train loss in epoch 8:1.6628018617630005\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.790377140045166\n",
      "\n",
      "episode 2, val func loss 1.5625524520874023\n",
      "\n",
      "episode 3, val func loss 1.6047043800354004\n",
      "\n",
      "episode 4, val func loss 1.7680944204330444\n",
      "\n",
      "episode 5, val func loss 1.7651447057724\n",
      "\n",
      "episode 6, val func loss 1.4368857145309448\n",
      "\n",
      "episode 7, val func loss 1.5800284147262573\n",
      "\n",
      "episode 8, val func loss 1.3718643188476562\n",
      "\n",
      "episode 9, val func loss 1.6274510622024536\n",
      "\n",
      "episode 10, val func loss 1.2746590375900269\n",
      "\n",
      "episode 11, val func loss 1.7734133005142212\n",
      "\n",
      "episode 12, val func loss 1.741556167602539\n",
      "\n",
      "episode 13, val func loss 1.8515204191207886\n",
      "\n",
      "episode 14, val func loss 1.6088672876358032\n",
      "\n",
      "episode 15, val func loss 1.5961575508117676\n",
      "\n",
      "episode 16, val func loss 1.4985907077789307\n",
      "\n",
      "Val func train loss in epoch 9:1.6157416924834251\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.425102710723877\n",
      "\n",
      "episode 2, val func loss 1.7380998134613037\n",
      "\n",
      "episode 3, val func loss 1.7852256298065186\n",
      "\n",
      "episode 4, val func loss 1.4860877990722656\n",
      "\n",
      "episode 5, val func loss 1.7697176933288574\n",
      "\n",
      "episode 6, val func loss 1.6952683925628662\n",
      "\n",
      "episode 7, val func loss 1.9778894186019897\n",
      "\n",
      "episode 8, val func loss 1.717794418334961\n",
      "\n",
      "episode 9, val func loss 1.818341851234436\n",
      "\n",
      "episode 10, val func loss 1.6042377948760986\n",
      "\n",
      "episode 11, val func loss 1.8402968645095825\n",
      "\n",
      "episode 12, val func loss 1.7100485563278198\n",
      "\n",
      "episode 13, val func loss 2.2038023471832275\n",
      "\n",
      "episode 14, val func loss 1.8745768070220947\n",
      "\n",
      "episode 15, val func loss 1.7260208129882812\n",
      "\n",
      "episode 16, val func loss 1.6254690885543823\n",
      "\n",
      "Val func train loss in epoch 10:1.7498737499117851\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.9713867902755737\n",
      "\n",
      "episode 2, val func loss 1.5962060689926147\n",
      "\n",
      "episode 3, val func loss 1.833294153213501\n",
      "\n",
      "episode 4, val func loss 1.7661904096603394\n",
      "\n",
      "episode 5, val func loss 1.7385536432266235\n",
      "\n",
      "episode 6, val func loss 1.6057692766189575\n",
      "\n",
      "episode 7, val func loss 1.8715424537658691\n",
      "\n",
      "episode 8, val func loss 1.7806671857833862\n",
      "\n",
      "episode 9, val func loss 1.5605193376541138\n",
      "\n",
      "episode 10, val func loss 1.499603271484375\n",
      "\n",
      "episode 11, val func loss 1.9065274000167847\n",
      "\n",
      "episode 12, val func loss 1.6883511543273926\n",
      "\n",
      "episode 13, val func loss 1.6810730695724487\n",
      "\n",
      "episode 14, val func loss 1.6893118619918823\n",
      "\n",
      "episode 15, val func loss 1.7673708200454712\n",
      "\n",
      "episode 16, val func loss 1.8757420778274536\n",
      "\n",
      "Val func train loss in epoch 11:1.7395068109035492\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.7042546272277832\n",
      "\n",
      "episode 2, val func loss 1.7313053607940674\n",
      "\n",
      "episode 3, val func loss 1.9432318210601807\n",
      "\n",
      "episode 4, val func loss 1.813071608543396\n",
      "\n",
      "episode 5, val func loss 1.9786406755447388\n",
      "\n",
      "episode 6, val func loss 1.974468469619751\n",
      "\n",
      "episode 7, val func loss 1.5165445804595947\n",
      "\n",
      "episode 8, val func loss 1.421366810798645\n",
      "\n",
      "episode 9, val func loss 1.7135906219482422\n",
      "\n",
      "episode 10, val func loss 1.7776570320129395\n",
      "\n",
      "episode 11, val func loss 1.5671300888061523\n",
      "\n",
      "episode 12, val func loss 1.6346094608306885\n",
      "\n",
      "episode 13, val func loss 1.591015100479126\n",
      "\n",
      "episode 14, val func loss 1.6066207885742188\n",
      "\n",
      "episode 15, val func loss 1.5109519958496094\n",
      "\n",
      "episode 16, val func loss 1.4276257753372192\n",
      "\n",
      "Val func train loss in epoch 12:1.682005301117897\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.8194749355316162\n",
      "\n",
      "episode 2, val func loss 1.4880664348602295\n",
      "\n",
      "episode 3, val func loss 1.5127532482147217\n",
      "\n",
      "episode 4, val func loss 1.8471951484680176\n",
      "\n",
      "episode 5, val func loss 1.487032413482666\n",
      "\n",
      "episode 6, val func loss 1.4516299962997437\n",
      "\n",
      "episode 7, val func loss 1.51543128490448\n",
      "\n",
      "episode 8, val func loss 1.5930993556976318\n",
      "\n",
      "episode 9, val func loss 1.695513367652893\n",
      "\n",
      "episode 10, val func loss 1.8109906911849976\n",
      "\n",
      "episode 11, val func loss 1.6162670850753784\n",
      "\n",
      "episode 12, val func loss 1.72249436378479\n",
      "\n",
      "episode 13, val func loss 1.6125839948654175\n",
      "\n",
      "episode 14, val func loss 1.6068567037582397\n",
      "\n",
      "episode 15, val func loss 1.507401704788208\n",
      "\n",
      "episode 16, val func loss 1.5524919033050537\n",
      "\n",
      "Val func train loss in epoch 13:1.6149551644921303\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.6444827318191528\n",
      "\n",
      "episode 2, val func loss 1.663528323173523\n",
      "\n",
      "episode 3, val func loss 1.6390951871871948\n",
      "\n",
      "episode 4, val func loss 1.4429380893707275\n",
      "\n",
      "episode 5, val func loss 1.6805015802383423\n",
      "\n",
      "episode 6, val func loss 1.5658966302871704\n",
      "\n",
      "episode 7, val func loss 1.5358721017837524\n",
      "\n",
      "episode 8, val func loss 1.6367475986480713\n",
      "\n",
      "episode 9, val func loss 1.6696780920028687\n",
      "\n",
      "episode 10, val func loss 1.7614513635635376\n",
      "\n",
      "episode 11, val func loss 1.6032078266143799\n",
      "\n",
      "episode 12, val func loss 1.8196762800216675\n",
      "\n",
      "episode 13, val func loss 1.6656566858291626\n",
      "\n",
      "episode 14, val func loss 1.8216941356658936\n",
      "\n",
      "episode 15, val func loss 1.658531904220581\n",
      "\n",
      "episode 16, val func loss 1.7833279371261597\n",
      "\n",
      "Val func train loss in epoch 14:1.6620179042220116\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.5450990200042725\n",
      "\n",
      "episode 2, val func loss 1.8210800886154175\n",
      "\n",
      "episode 3, val func loss 2.000775098800659\n",
      "\n",
      "episode 4, val func loss 2.178070306777954\n",
      "\n",
      "episode 5, val func loss 1.89957594871521\n",
      "\n",
      "episode 6, val func loss 1.5230213403701782\n",
      "\n",
      "episode 7, val func loss 2.050396680831909\n",
      "\n",
      "episode 8, val func loss 1.923791527748108\n",
      "\n",
      "episode 9, val func loss 1.7255536317825317\n",
      "\n",
      "episode 10, val func loss 2.0539989471435547\n",
      "\n",
      "episode 11, val func loss 1.7844126224517822\n",
      "\n",
      "episode 12, val func loss 1.7774064540863037\n",
      "\n",
      "episode 13, val func loss 1.5193859338760376\n",
      "\n",
      "episode 14, val func loss 1.672202706336975\n",
      "\n",
      "episode 15, val func loss 1.6592450141906738\n",
      "\n",
      "episode 16, val func loss 1.6146565675735474\n",
      "\n",
      "Val func train loss in epoch 15:1.7967919930815697\n",
      "***********************TIME WAS 4.799085187911987 min*****************************\n",
      "\n",
      "**********************ROUND 16 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.23067307472229\n",
      "\n",
      "episode 2, policy loss -2.230672597885132\n",
      "\n",
      "episode 3, policy loss -2.2306740283966064\n",
      "\n",
      "episode 4, policy loss -2.2306716442108154\n",
      "\n",
      "episode 5, policy loss -2.2306718826293945\n",
      "\n",
      "episode 6, policy loss -2.2306723594665527\n",
      "\n",
      "episode 7, policy loss -2.230672597885132\n",
      "\n",
      "episode 8, policy loss -2.230673313140869\n",
      "\n",
      "episode 9, policy loss -2.23067307472229\n",
      "\n",
      "episode 10, policy loss -2.23067307472229\n",
      "\n",
      "episode 11, policy loss -2.2306716442108154\n",
      "\n",
      "episode 12, policy loss -2.230672597885132\n",
      "\n",
      "episode 13, policy loss -2.2306716442108154\n",
      "\n",
      "episode 14, policy loss -2.2306716442108154\n",
      "\n",
      "episode 15, policy loss -2.230673313140869\n",
      "\n",
      "episode 16, policy loss -2.2306723594665527\n",
      "\n",
      "Policy train loss in epoch 0:-2.2306725531816483\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.2306721210479736\n",
      "\n",
      "episode 2, policy loss -2.2306714057922363\n",
      "\n",
      "episode 3, policy loss -2.2306716442108154\n",
      "\n",
      "episode 4, policy loss -2.2306723594665527\n",
      "\n",
      "episode 5, policy loss -2.2306723594665527\n",
      "\n",
      "episode 6, policy loss -2.230672836303711\n",
      "\n",
      "episode 7, policy loss -2.2306714057922363\n",
      "\n",
      "episode 8, policy loss -2.23067307472229\n",
      "\n",
      "episode 9, policy loss -2.2306714057922363\n",
      "\n",
      "episode 10, policy loss -2.2306737899780273\n",
      "\n",
      "episode 11, policy loss -2.2306723594665527\n",
      "\n",
      "episode 12, policy loss -2.230672836303711\n",
      "\n",
      "episode 13, policy loss -2.2306714057922363\n",
      "\n",
      "episode 14, policy loss -2.2306723594665527\n",
      "\n",
      "episode 15, policy loss -2.230672836303711\n",
      "\n",
      "episode 16, policy loss -2.23067307472229\n",
      "\n",
      "Policy train loss in epoch 1:-2.2306723296642303\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.2306723594665527\n",
      "\n",
      "episode 2, policy loss -2.2306723594665527\n",
      "\n",
      "episode 3, policy loss -2.2306714057922363\n",
      "\n",
      "episode 4, policy loss -2.230672836303711\n",
      "\n",
      "episode 5, policy loss -2.2306723594665527\n",
      "\n",
      "episode 6, policy loss -2.2306721210479736\n",
      "\n",
      "episode 7, policy loss -2.2306716442108154\n",
      "\n",
      "episode 8, policy loss -2.230672836303711\n",
      "\n",
      "episode 9, policy loss -2.2306714057922363\n",
      "\n",
      "episode 10, policy loss -2.2306714057922363\n",
      "\n",
      "episode 11, policy loss -2.23067307472229\n",
      "\n",
      "episode 12, policy loss -2.2306723594665527\n",
      "\n",
      "episode 13, policy loss -2.2306737899780273\n",
      "\n",
      "episode 14, policy loss -2.23067307472229\n",
      "\n",
      "episode 15, policy loss -2.230672836303711\n",
      "\n",
      "episode 16, policy loss -2.2306714057922363\n",
      "\n",
      "Policy train loss in epoch 2:-2.2306723296642303\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.2306723594665527\n",
      "\n",
      "episode 2, policy loss -2.23067307472229\n",
      "\n",
      "episode 3, policy loss -2.2306723594665527\n",
      "\n",
      "episode 4, policy loss -2.230672836303711\n",
      "\n",
      "episode 5, policy loss -2.2306723594665527\n",
      "\n",
      "episode 6, policy loss -2.2306723594665527\n",
      "\n",
      "episode 7, policy loss -2.2306714057922363\n",
      "\n",
      "episode 8, policy loss -2.2306714057922363\n",
      "\n",
      "episode 9, policy loss -2.2306714057922363\n",
      "\n",
      "episode 10, policy loss -2.2306716442108154\n",
      "\n",
      "episode 11, policy loss -2.2306721210479736\n",
      "\n",
      "episode 12, policy loss -2.2306737899780273\n",
      "\n",
      "episode 13, policy loss -2.230672836303711\n",
      "\n",
      "episode 14, policy loss -2.23067307472229\n",
      "\n",
      "episode 15, policy loss -2.230672836303711\n",
      "\n",
      "episode 16, policy loss -2.2306714057922363\n",
      "\n",
      "Policy train loss in epoch 3:-2.2306723296642303\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.6937236785888672\n",
      "\n",
      "episode 2, val func loss 1.770215630531311\n",
      "\n",
      "episode 3, val func loss 1.8272029161453247\n",
      "\n",
      "episode 4, val func loss 1.7950786352157593\n",
      "\n",
      "episode 5, val func loss 1.6617063283920288\n",
      "\n",
      "episode 6, val func loss 1.7174551486968994\n",
      "\n",
      "episode 7, val func loss 1.4864245653152466\n",
      "\n",
      "episode 8, val func loss 1.490035891532898\n",
      "\n",
      "episode 9, val func loss 1.7908529043197632\n",
      "\n",
      "episode 10, val func loss 1.4779564142227173\n",
      "\n",
      "episode 11, val func loss 1.8483200073242188\n",
      "\n",
      "episode 12, val func loss 1.6965222358703613\n",
      "\n",
      "episode 13, val func loss 1.5862841606140137\n",
      "\n",
      "episode 14, val func loss 1.6465263366699219\n",
      "\n",
      "episode 15, val func loss 1.6478434801101685\n",
      "\n",
      "episode 16, val func loss 1.7496272325515747\n",
      "\n",
      "Val func train loss in epoch 0:1.6803609728813171\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.7121217250823975\n",
      "\n",
      "episode 2, val func loss 1.518334984779358\n",
      "\n",
      "episode 3, val func loss 1.79531729221344\n",
      "\n",
      "episode 4, val func loss 1.8429715633392334\n",
      "\n",
      "episode 5, val func loss 1.7195110321044922\n",
      "\n",
      "episode 6, val func loss 1.4796723127365112\n",
      "\n",
      "episode 7, val func loss 1.671886920928955\n",
      "\n",
      "episode 8, val func loss 1.7012979984283447\n",
      "\n",
      "episode 9, val func loss 1.4878756999969482\n",
      "\n",
      "episode 10, val func loss 1.5464695692062378\n",
      "\n",
      "episode 11, val func loss 1.5712170600891113\n",
      "\n",
      "episode 12, val func loss 1.5129033327102661\n",
      "\n",
      "episode 13, val func loss 1.7132530212402344\n",
      "\n",
      "episode 14, val func loss 1.7524899244308472\n",
      "\n",
      "episode 15, val func loss 1.7182785272598267\n",
      "\n",
      "episode 16, val func loss 1.4312305450439453\n",
      "\n",
      "Val func train loss in epoch 1:1.6359269693493843\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.6354724168777466\n",
      "\n",
      "episode 2, val func loss 1.780652403831482\n",
      "\n",
      "episode 3, val func loss 1.5920073986053467\n",
      "\n",
      "episode 4, val func loss 1.822791576385498\n",
      "\n",
      "episode 5, val func loss 1.5480403900146484\n",
      "\n",
      "episode 6, val func loss 1.6941777467727661\n",
      "\n",
      "episode 7, val func loss 1.6642265319824219\n",
      "\n",
      "episode 8, val func loss 1.7350462675094604\n",
      "\n",
      "episode 9, val func loss 1.4992457628250122\n",
      "\n",
      "episode 10, val func loss 1.6509153842926025\n",
      "\n",
      "episode 11, val func loss 1.659943699836731\n",
      "\n",
      "episode 12, val func loss 1.5495022535324097\n",
      "\n",
      "episode 13, val func loss 1.673988699913025\n",
      "\n",
      "episode 14, val func loss 1.6134942770004272\n",
      "\n",
      "episode 15, val func loss 1.5056345462799072\n",
      "\n",
      "episode 16, val func loss 1.8248242139816284\n",
      "\n",
      "Val func train loss in epoch 2:1.6531227231025696\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.5361192226409912\n",
      "\n",
      "episode 2, val func loss 1.6474162340164185\n",
      "\n",
      "episode 3, val func loss 1.6265746355056763\n",
      "\n",
      "episode 4, val func loss 1.5942578315734863\n",
      "\n",
      "episode 5, val func loss 1.8044636249542236\n",
      "\n",
      "episode 6, val func loss 1.663636565208435\n",
      "\n",
      "episode 7, val func loss 1.4897425174713135\n",
      "\n",
      "episode 8, val func loss 1.3482342958450317\n",
      "\n",
      "episode 9, val func loss 1.6736576557159424\n",
      "\n",
      "episode 10, val func loss 1.48860502243042\n",
      "\n",
      "episode 11, val func loss 1.6146552562713623\n",
      "\n",
      "episode 12, val func loss 1.5023354291915894\n",
      "\n",
      "episode 13, val func loss 1.517956256866455\n",
      "\n",
      "episode 14, val func loss 1.7036747932434082\n",
      "\n",
      "episode 15, val func loss 1.59906005859375\n",
      "\n",
      "episode 16, val func loss 1.6913514137268066\n",
      "\n",
      "Val func train loss in epoch 3:1.5938588008284569\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.4842655658721924\n",
      "\n",
      "episode 2, val func loss 1.7047802209854126\n",
      "\n",
      "episode 3, val func loss 1.3994817733764648\n",
      "\n",
      "episode 4, val func loss 1.6170814037322998\n",
      "\n",
      "episode 5, val func loss 1.6371761560440063\n",
      "\n",
      "episode 6, val func loss 1.579552173614502\n",
      "\n",
      "episode 7, val func loss 1.6985334157943726\n",
      "\n",
      "episode 8, val func loss 1.4416468143463135\n",
      "\n",
      "episode 9, val func loss 1.4835741519927979\n",
      "\n",
      "episode 10, val func loss 1.615011215209961\n",
      "\n",
      "episode 11, val func loss 1.6892539262771606\n",
      "\n",
      "episode 12, val func loss 1.714081883430481\n",
      "\n",
      "episode 13, val func loss 1.6395033597946167\n",
      "\n",
      "episode 14, val func loss 1.7171435356140137\n",
      "\n",
      "episode 15, val func loss 1.6956472396850586\n",
      "\n",
      "episode 16, val func loss 1.8040392398834229\n",
      "\n",
      "Val func train loss in epoch 4:1.6200482547283173\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.308477520942688\n",
      "\n",
      "episode 2, val func loss 1.7108745574951172\n",
      "\n",
      "episode 3, val func loss 1.4227434396743774\n",
      "\n",
      "episode 4, val func loss 1.5314677953720093\n",
      "\n",
      "episode 5, val func loss 1.6524598598480225\n",
      "\n",
      "episode 6, val func loss 1.7420294284820557\n",
      "\n",
      "episode 7, val func loss 1.8279974460601807\n",
      "\n",
      "episode 8, val func loss 1.6292452812194824\n",
      "\n",
      "episode 9, val func loss 1.7149457931518555\n",
      "\n",
      "episode 10, val func loss 1.7737221717834473\n",
      "\n",
      "episode 11, val func loss 1.8180792331695557\n",
      "\n",
      "episode 12, val func loss 1.769144058227539\n",
      "\n",
      "episode 13, val func loss 1.6412818431854248\n",
      "\n",
      "episode 14, val func loss 1.50397789478302\n",
      "\n",
      "episode 15, val func loss 1.7063456773757935\n",
      "\n",
      "episode 16, val func loss 1.8022328615188599\n",
      "\n",
      "Val func train loss in epoch 5:1.6596890538930893\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.6028348207473755\n",
      "\n",
      "episode 2, val func loss 1.6405696868896484\n",
      "\n",
      "episode 3, val func loss 1.6116886138916016\n",
      "\n",
      "episode 4, val func loss 1.631684422492981\n",
      "\n",
      "episode 5, val func loss 1.5411523580551147\n",
      "\n",
      "episode 6, val func loss 1.6805340051651\n",
      "\n",
      "episode 7, val func loss 1.8261561393737793\n",
      "\n",
      "episode 8, val func loss 1.8778495788574219\n",
      "\n",
      "episode 9, val func loss 1.636855125427246\n",
      "\n",
      "episode 10, val func loss 2.1943225860595703\n",
      "\n",
      "episode 11, val func loss 1.5021127462387085\n",
      "\n",
      "episode 12, val func loss 1.6740106344223022\n",
      "\n",
      "episode 13, val func loss 1.81708824634552\n",
      "\n",
      "episode 14, val func loss 2.1039462089538574\n",
      "\n",
      "episode 15, val func loss 2.2112905979156494\n",
      "\n",
      "episode 16, val func loss 2.2585601806640625\n",
      "\n",
      "Val func train loss in epoch 6:1.8006659969687462\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.915475606918335\n",
      "\n",
      "episode 2, val func loss 1.8353074789047241\n",
      "\n",
      "episode 3, val func loss 2.1282730102539062\n",
      "\n",
      "episode 4, val func loss 1.9775922298431396\n",
      "\n",
      "episode 5, val func loss 1.9173963069915771\n",
      "\n",
      "episode 6, val func loss 1.9715921878814697\n",
      "\n",
      "episode 7, val func loss 2.1361050605773926\n",
      "\n",
      "episode 8, val func loss 1.9266220331192017\n",
      "\n",
      "episode 9, val func loss 2.146002769470215\n",
      "\n",
      "episode 10, val func loss 2.0590198040008545\n",
      "\n",
      "episode 11, val func loss 2.036025285720825\n",
      "\n",
      "episode 12, val func loss 1.9103609323501587\n",
      "\n",
      "episode 13, val func loss 2.087620735168457\n",
      "\n",
      "episode 14, val func loss 1.887472152709961\n",
      "\n",
      "episode 15, val func loss 1.839858055114746\n",
      "\n",
      "episode 16, val func loss 1.7557623386383057\n",
      "\n",
      "Val func train loss in epoch 7:1.9706553742289543\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.7559270858764648\n",
      "\n",
      "episode 2, val func loss 1.9422783851623535\n",
      "\n",
      "episode 3, val func loss 1.8392298221588135\n",
      "\n",
      "episode 4, val func loss 1.5820519924163818\n",
      "\n",
      "episode 5, val func loss 1.7572882175445557\n",
      "\n",
      "episode 6, val func loss 1.6161144971847534\n",
      "\n",
      "episode 7, val func loss 1.5773357152938843\n",
      "\n",
      "episode 8, val func loss 1.6101582050323486\n",
      "\n",
      "episode 9, val func loss 1.5436573028564453\n",
      "\n",
      "episode 10, val func loss 1.7817028760910034\n",
      "\n",
      "episode 11, val func loss 1.813607096672058\n",
      "\n",
      "episode 12, val func loss 1.588227391242981\n",
      "\n",
      "episode 13, val func loss 1.5882266759872437\n",
      "\n",
      "episode 14, val func loss 1.712241768836975\n",
      "\n",
      "episode 15, val func loss 1.6401052474975586\n",
      "\n",
      "episode 16, val func loss 1.7212693691253662\n",
      "\n",
      "Val func train loss in epoch 8:1.6918388530611992\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.7271960973739624\n",
      "\n",
      "episode 2, val func loss 1.5260066986083984\n",
      "\n",
      "episode 3, val func loss 1.6519888639450073\n",
      "\n",
      "episode 4, val func loss 1.7434954643249512\n",
      "\n",
      "episode 5, val func loss 1.5365196466445923\n",
      "\n",
      "episode 6, val func loss 1.6259727478027344\n",
      "\n",
      "episode 7, val func loss 1.3098851442337036\n",
      "\n",
      "episode 8, val func loss 1.7651255130767822\n",
      "\n",
      "episode 9, val func loss 1.4949705600738525\n",
      "\n",
      "episode 10, val func loss 1.6005597114562988\n",
      "\n",
      "episode 11, val func loss 1.4109828472137451\n",
      "\n",
      "episode 12, val func loss 1.4526586532592773\n",
      "\n",
      "episode 13, val func loss 1.7076843976974487\n",
      "\n",
      "episode 14, val func loss 1.66963791847229\n",
      "\n",
      "episode 15, val func loss 1.614504337310791\n",
      "\n",
      "episode 16, val func loss 1.5499941110610962\n",
      "\n",
      "Val func train loss in epoch 9:1.5866989195346832\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.7506405115127563\n",
      "\n",
      "episode 2, val func loss 1.5222687721252441\n",
      "\n",
      "episode 3, val func loss 1.5501141548156738\n",
      "\n",
      "episode 4, val func loss 1.5904552936553955\n",
      "\n",
      "episode 5, val func loss 1.6762770414352417\n",
      "\n",
      "episode 6, val func loss 1.5739682912826538\n",
      "\n",
      "episode 7, val func loss 1.466156005859375\n",
      "\n",
      "episode 8, val func loss 1.5370062589645386\n",
      "\n",
      "episode 9, val func loss 1.5861053466796875\n",
      "\n",
      "episode 10, val func loss 1.5433661937713623\n",
      "\n",
      "episode 11, val func loss 1.5210723876953125\n",
      "\n",
      "episode 12, val func loss 1.7808136940002441\n",
      "\n",
      "episode 13, val func loss 1.8093540668487549\n",
      "\n",
      "episode 14, val func loss 1.8405861854553223\n",
      "\n",
      "episode 15, val func loss 1.6761866807937622\n",
      "\n",
      "episode 16, val func loss 1.6697391271591187\n",
      "\n",
      "Val func train loss in epoch 10:1.6308818757534027\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.715759515762329\n",
      "\n",
      "episode 2, val func loss 1.7268818616867065\n",
      "\n",
      "episode 3, val func loss 1.632374882698059\n",
      "\n",
      "episode 4, val func loss 1.6438353061676025\n",
      "\n",
      "episode 5, val func loss 1.764740228652954\n",
      "\n",
      "episode 6, val func loss 1.6349533796310425\n",
      "\n",
      "episode 7, val func loss 1.7160911560058594\n",
      "\n",
      "episode 8, val func loss 1.590222716331482\n",
      "\n",
      "episode 9, val func loss 1.7801815271377563\n",
      "\n",
      "episode 10, val func loss 1.587746024131775\n",
      "\n",
      "episode 11, val func loss 1.5771023035049438\n",
      "\n",
      "episode 12, val func loss 1.5265536308288574\n",
      "\n",
      "episode 13, val func loss 1.4406453371047974\n",
      "\n",
      "episode 14, val func loss 1.7338522672653198\n",
      "\n",
      "episode 15, val func loss 1.704114556312561\n",
      "\n",
      "episode 16, val func loss 1.8133866786956787\n",
      "\n",
      "Val func train loss in epoch 11:1.6617775857448578\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.7918701171875\n",
      "\n",
      "episode 2, val func loss 1.572588562965393\n",
      "\n",
      "episode 3, val func loss 1.718180537223816\n",
      "\n",
      "episode 4, val func loss 1.695921540260315\n",
      "\n",
      "episode 5, val func loss 1.7366414070129395\n",
      "\n",
      "episode 6, val func loss 1.4847843647003174\n",
      "\n",
      "episode 7, val func loss 1.8076285123825073\n",
      "\n",
      "episode 8, val func loss 1.8646479845046997\n",
      "\n",
      "episode 9, val func loss 1.651049256324768\n",
      "\n",
      "episode 10, val func loss 1.8035434484481812\n",
      "\n",
      "episode 11, val func loss 1.6983795166015625\n",
      "\n",
      "episode 12, val func loss 1.7248865365982056\n",
      "\n",
      "episode 13, val func loss 1.5367270708084106\n",
      "\n",
      "episode 14, val func loss 1.5628780126571655\n",
      "\n",
      "episode 15, val func loss 1.731696605682373\n",
      "\n",
      "episode 16, val func loss 1.7183259725570679\n",
      "\n",
      "Val func train loss in epoch 12:1.6937343403697014\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.9440757036209106\n",
      "\n",
      "episode 2, val func loss 1.5997012853622437\n",
      "\n",
      "episode 3, val func loss 1.8067957162857056\n",
      "\n",
      "episode 4, val func loss 1.5009735822677612\n",
      "\n",
      "episode 5, val func loss 1.746431827545166\n",
      "\n",
      "episode 6, val func loss 1.8062154054641724\n",
      "\n",
      "episode 7, val func loss 1.7887804508209229\n",
      "\n",
      "episode 8, val func loss 1.6413875818252563\n",
      "\n",
      "episode 9, val func loss 1.6959185600280762\n",
      "\n",
      "episode 10, val func loss 1.8829654455184937\n",
      "\n",
      "episode 11, val func loss 1.5186206102371216\n",
      "\n",
      "episode 12, val func loss 1.5958834886550903\n",
      "\n",
      "episode 13, val func loss 1.6480132341384888\n",
      "\n",
      "episode 14, val func loss 1.490754246711731\n",
      "\n",
      "episode 15, val func loss 1.4749424457550049\n",
      "\n",
      "episode 16, val func loss 1.4643537998199463\n",
      "\n",
      "Val func train loss in epoch 13:1.6628633365035057\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.6144263744354248\n",
      "\n",
      "episode 2, val func loss 1.6628390550613403\n",
      "\n",
      "episode 3, val func loss 1.6792410612106323\n",
      "\n",
      "episode 4, val func loss 1.6908822059631348\n",
      "\n",
      "episode 5, val func loss 1.7067493200302124\n",
      "\n",
      "episode 6, val func loss 1.6596623659133911\n",
      "\n",
      "episode 7, val func loss 1.8649579286575317\n",
      "\n",
      "episode 8, val func loss 1.7444515228271484\n",
      "\n",
      "episode 9, val func loss 1.9689381122589111\n",
      "\n",
      "episode 10, val func loss 1.570910096168518\n",
      "\n",
      "episode 11, val func loss 1.7421581745147705\n",
      "\n",
      "episode 12, val func loss 1.783552646636963\n",
      "\n",
      "episode 13, val func loss 1.7847042083740234\n",
      "\n",
      "episode 14, val func loss 1.8005924224853516\n",
      "\n",
      "episode 15, val func loss 1.8240596055984497\n",
      "\n",
      "episode 16, val func loss 1.51702082157135\n",
      "\n",
      "Val func train loss in epoch 14:1.725946620106697\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.8565667867660522\n",
      "\n",
      "episode 2, val func loss 1.7127529382705688\n",
      "\n",
      "episode 3, val func loss 1.5007679462432861\n",
      "\n",
      "episode 4, val func loss 1.8123024702072144\n",
      "\n",
      "episode 5, val func loss 1.649099588394165\n",
      "\n",
      "episode 6, val func loss 1.7966046333312988\n",
      "\n",
      "episode 7, val func loss 1.6935299634933472\n",
      "\n",
      "episode 8, val func loss 1.7274823188781738\n",
      "\n",
      "episode 9, val func loss 1.6522325277328491\n",
      "\n",
      "episode 10, val func loss 1.8571701049804688\n",
      "\n",
      "episode 11, val func loss 1.942116618156433\n",
      "\n",
      "episode 12, val func loss 1.7737184762954712\n",
      "\n",
      "episode 13, val func loss 1.661368489265442\n",
      "\n",
      "episode 14, val func loss 1.6230591535568237\n",
      "\n",
      "episode 15, val func loss 1.5549209117889404\n",
      "\n",
      "episode 16, val func loss 1.4878336191177368\n",
      "\n",
      "Val func train loss in epoch 15:1.706345409154892\n",
      "***********************TIME WAS 4.947290285428365 min*****************************\n",
      "\n",
      "**********************ROUND 17 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -1.9661368131637573\n",
      "\n",
      "episode 2, policy loss -1.9661366939544678\n",
      "\n",
      "episode 3, policy loss -1.9661364555358887\n",
      "\n",
      "episode 4, policy loss -1.9661366939544678\n",
      "\n",
      "episode 5, policy loss -1.9661366939544678\n",
      "\n",
      "episode 6, policy loss -1.9661366939544678\n",
      "\n",
      "episode 7, policy loss -1.9661363363265991\n",
      "\n",
      "episode 8, policy loss -1.9661364555358887\n",
      "\n",
      "episode 9, policy loss -1.9661363363265991\n",
      "\n",
      "episode 10, policy loss -1.9661366939544678\n",
      "\n",
      "episode 11, policy loss -1.9661366939544678\n",
      "\n",
      "episode 12, policy loss -1.9661364555358887\n",
      "\n",
      "episode 13, policy loss -1.9661366939544678\n",
      "\n",
      "episode 14, policy loss -1.9661366939544678\n",
      "\n",
      "episode 15, policy loss -1.9661364555358887\n",
      "\n",
      "episode 16, policy loss -1.9661364555358887\n",
      "\n",
      "Policy train loss in epoch 0:-1.9661365821957588\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -1.9661366939544678\n",
      "\n",
      "episode 2, policy loss -1.9661364555358887\n",
      "\n",
      "episode 3, policy loss -1.9661364555358887\n",
      "\n",
      "episode 4, policy loss -1.9661364555358887\n",
      "\n",
      "episode 5, policy loss -1.9661366939544678\n",
      "\n",
      "episode 6, policy loss -1.9661366939544678\n",
      "\n",
      "episode 7, policy loss -1.9661366939544678\n",
      "\n",
      "episode 8, policy loss -1.9661363363265991\n",
      "\n",
      "episode 9, policy loss -1.9661366939544678\n",
      "\n",
      "episode 10, policy loss -1.9661363363265991\n",
      "\n",
      "episode 11, policy loss -1.9661364555358887\n",
      "\n",
      "episode 12, policy loss -1.9661366939544678\n",
      "\n",
      "episode 13, policy loss -1.9661366939544678\n",
      "\n",
      "episode 14, policy loss -1.9661366939544678\n",
      "\n",
      "episode 15, policy loss -1.9661364555358887\n",
      "\n",
      "episode 16, policy loss -1.9661366939544678\n",
      "\n",
      "Policy train loss in epoch 1:-1.9661365747451782\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -1.9661366939544678\n",
      "\n",
      "episode 2, policy loss -1.9661364555358887\n",
      "\n",
      "episode 3, policy loss -1.9661364555358887\n",
      "\n",
      "episode 4, policy loss -1.9661366939544678\n",
      "\n",
      "episode 5, policy loss -1.9661366939544678\n",
      "\n",
      "episode 6, policy loss -1.9661366939544678\n",
      "\n",
      "episode 7, policy loss -1.9661363363265991\n",
      "\n",
      "episode 8, policy loss -1.9661366939544678\n",
      "\n",
      "episode 9, policy loss -1.9661366939544678\n",
      "\n",
      "episode 10, policy loss -1.9661366939544678\n",
      "\n",
      "episode 11, policy loss -1.9661366939544678\n",
      "\n",
      "episode 12, policy loss -1.9661364555358887\n",
      "\n",
      "episode 13, policy loss -1.9661363363265991\n",
      "\n",
      "episode 14, policy loss -1.9661364555358887\n",
      "\n",
      "episode 15, policy loss -1.9661364555358887\n",
      "\n",
      "episode 16, policy loss -1.9661366939544678\n",
      "\n",
      "Policy train loss in epoch 2:-1.9661365747451782\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -1.9661364555358887\n",
      "\n",
      "episode 2, policy loss -1.9661366939544678\n",
      "\n",
      "episode 3, policy loss -1.9661366939544678\n",
      "\n",
      "episode 4, policy loss -1.9661366939544678\n",
      "\n",
      "episode 5, policy loss -1.9661366939544678\n",
      "\n",
      "episode 6, policy loss -1.9661364555358887\n",
      "\n",
      "episode 7, policy loss -1.9661363363265991\n",
      "\n",
      "episode 8, policy loss -1.9661363363265991\n",
      "\n",
      "episode 9, policy loss -1.9661366939544678\n",
      "\n",
      "episode 10, policy loss -1.9661366939544678\n",
      "\n",
      "episode 11, policy loss -1.9661366939544678\n",
      "\n",
      "episode 12, policy loss -1.9661366939544678\n",
      "\n",
      "episode 13, policy loss -1.9661364555358887\n",
      "\n",
      "episode 14, policy loss -1.9661364555358887\n",
      "\n",
      "episode 15, policy loss -1.9661364555358887\n",
      "\n",
      "episode 16, policy loss -1.9661366939544678\n",
      "\n",
      "Policy train loss in epoch 3:-1.9661365747451782\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.554201602935791\n",
      "\n",
      "episode 2, val func loss 1.5626808404922485\n",
      "\n",
      "episode 3, val func loss 1.5393139123916626\n",
      "\n",
      "episode 4, val func loss 1.7710262537002563\n",
      "\n",
      "episode 5, val func loss 1.6966500282287598\n",
      "\n",
      "episode 6, val func loss 1.4548912048339844\n",
      "\n",
      "episode 7, val func loss 1.3829896450042725\n",
      "\n",
      "episode 8, val func loss 1.4032341241836548\n",
      "\n",
      "episode 9, val func loss 1.477410078048706\n",
      "\n",
      "episode 10, val func loss 1.4095872640609741\n",
      "\n",
      "episode 11, val func loss 1.651148796081543\n",
      "\n",
      "episode 12, val func loss 1.3211554288864136\n",
      "\n",
      "episode 13, val func loss 1.5314968824386597\n",
      "\n",
      "episode 14, val func loss 1.4517292976379395\n",
      "\n",
      "episode 15, val func loss 1.5638699531555176\n",
      "\n",
      "episode 16, val func loss 1.895553469657898\n",
      "\n",
      "Val func train loss in epoch 0:1.5416836738586426\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.7562934160232544\n",
      "\n",
      "episode 2, val func loss 1.6470839977264404\n",
      "\n",
      "episode 3, val func loss 1.75626802444458\n",
      "\n",
      "episode 4, val func loss 1.6976149082183838\n",
      "\n",
      "episode 5, val func loss 1.7635085582733154\n",
      "\n",
      "episode 6, val func loss 1.9412487745285034\n",
      "\n",
      "episode 7, val func loss 1.440306305885315\n",
      "\n",
      "episode 8, val func loss 1.4997278451919556\n",
      "\n",
      "episode 9, val func loss 1.5948753356933594\n",
      "\n",
      "episode 10, val func loss 1.556547999382019\n",
      "\n",
      "episode 11, val func loss 1.63209867477417\n",
      "\n",
      "episode 12, val func loss 1.6208184957504272\n",
      "\n",
      "episode 13, val func loss 1.6829731464385986\n",
      "\n",
      "episode 14, val func loss 1.3970582485198975\n",
      "\n",
      "episode 15, val func loss 1.7042393684387207\n",
      "\n",
      "episode 16, val func loss 1.6487925052642822\n",
      "\n",
      "Val func train loss in epoch 1:1.6462159752845764\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.585289716720581\n",
      "\n",
      "episode 2, val func loss 1.5567474365234375\n",
      "\n",
      "episode 3, val func loss 1.6381378173828125\n",
      "\n",
      "episode 4, val func loss 1.5077691078186035\n",
      "\n",
      "episode 5, val func loss 1.7856800556182861\n",
      "\n",
      "episode 6, val func loss 1.7141743898391724\n",
      "\n",
      "episode 7, val func loss 1.77219820022583\n",
      "\n",
      "episode 8, val func loss 1.6257233619689941\n",
      "\n",
      "episode 9, val func loss 1.689444899559021\n",
      "\n",
      "episode 10, val func loss 1.6310980319976807\n",
      "\n",
      "episode 11, val func loss 1.9421228170394897\n",
      "\n",
      "episode 12, val func loss 1.7555675506591797\n",
      "\n",
      "episode 13, val func loss 3.2148687839508057\n",
      "\n",
      "episode 14, val func loss 2.283728837966919\n",
      "\n",
      "episode 15, val func loss 1.8390119075775146\n",
      "\n",
      "episode 16, val func loss 5.622899532318115\n",
      "\n",
      "Val func train loss in epoch 2:2.0727789029479027\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 3.2233190536499023\n",
      "\n",
      "episode 2, val func loss 5.510187149047852\n",
      "\n",
      "episode 3, val func loss 4.450944900512695\n",
      "\n",
      "episode 4, val func loss 2.3152801990509033\n",
      "\n",
      "episode 5, val func loss 2.0189082622528076\n",
      "\n",
      "episode 6, val func loss 3.5424373149871826\n",
      "\n",
      "episode 7, val func loss 3.699434995651245\n",
      "\n",
      "episode 8, val func loss 2.737046718597412\n",
      "\n",
      "episode 9, val func loss 2.1829674243927\n",
      "\n",
      "episode 10, val func loss 1.9744504690170288\n",
      "\n",
      "episode 11, val func loss 2.2201130390167236\n",
      "\n",
      "episode 12, val func loss 2.4752824306488037\n",
      "\n",
      "episode 13, val func loss 2.4432590007781982\n",
      "\n",
      "episode 14, val func loss 2.083636522293091\n",
      "\n",
      "episode 15, val func loss 2.0980288982391357\n",
      "\n",
      "episode 16, val func loss 2.295694589614868\n",
      "\n",
      "Val func train loss in epoch 3:2.8294369354844093\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.1037518978118896\n",
      "\n",
      "episode 2, val func loss 1.9681532382965088\n",
      "\n",
      "episode 3, val func loss 2.1305272579193115\n",
      "\n",
      "episode 4, val func loss 2.1863787174224854\n",
      "\n",
      "episode 5, val func loss 2.106973886489868\n",
      "\n",
      "episode 6, val func loss 2.029545783996582\n",
      "\n",
      "episode 7, val func loss 2.1565794944763184\n",
      "\n",
      "episode 8, val func loss 2.0245277881622314\n",
      "\n",
      "episode 9, val func loss 2.027182102203369\n",
      "\n",
      "episode 10, val func loss 1.998091697692871\n",
      "\n",
      "episode 11, val func loss 2.0723555088043213\n",
      "\n",
      "episode 12, val func loss 1.9912166595458984\n",
      "\n",
      "episode 13, val func loss 1.9014166593551636\n",
      "\n",
      "episode 14, val func loss 2.0111169815063477\n",
      "\n",
      "episode 15, val func loss 1.8490551710128784\n",
      "\n",
      "episode 16, val func loss 1.8227185010910034\n",
      "\n",
      "Val func train loss in epoch 4:2.0237244591116905\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.8562171459197998\n",
      "\n",
      "episode 2, val func loss 1.7178597450256348\n",
      "\n",
      "episode 3, val func loss 1.6509724855422974\n",
      "\n",
      "episode 4, val func loss 1.7820743322372437\n",
      "\n",
      "episode 5, val func loss 1.9226850271224976\n",
      "\n",
      "episode 6, val func loss 1.8693681955337524\n",
      "\n",
      "episode 7, val func loss 1.74484121799469\n",
      "\n",
      "episode 8, val func loss 1.6949440240859985\n",
      "\n",
      "episode 9, val func loss 1.796892762184143\n",
      "\n",
      "episode 10, val func loss 1.6176871061325073\n",
      "\n",
      "episode 11, val func loss 1.6741960048675537\n",
      "\n",
      "episode 12, val func loss 1.6607270240783691\n",
      "\n",
      "episode 13, val func loss 1.858607292175293\n",
      "\n",
      "episode 14, val func loss 1.7506977319717407\n",
      "\n",
      "episode 15, val func loss 1.9123402833938599\n",
      "\n",
      "episode 16, val func loss 1.5936472415924072\n",
      "\n",
      "Val func train loss in epoch 5:1.7564848512411118\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.9068806171417236\n",
      "\n",
      "episode 2, val func loss 1.9098809957504272\n",
      "\n",
      "episode 3, val func loss 1.8509860038757324\n",
      "\n",
      "episode 4, val func loss 1.6383355855941772\n",
      "\n",
      "episode 5, val func loss 1.749218225479126\n",
      "\n",
      "episode 6, val func loss 1.6686749458312988\n",
      "\n",
      "episode 7, val func loss 1.654104471206665\n",
      "\n",
      "episode 8, val func loss 1.631492257118225\n",
      "\n",
      "episode 9, val func loss 1.8373576402664185\n",
      "\n",
      "episode 10, val func loss 1.715374231338501\n",
      "\n",
      "episode 11, val func loss 1.883209228515625\n",
      "\n",
      "episode 12, val func loss 1.612305760383606\n",
      "\n",
      "episode 13, val func loss 1.576874852180481\n",
      "\n",
      "episode 14, val func loss 1.60071861743927\n",
      "\n",
      "episode 15, val func loss 1.8009426593780518\n",
      "\n",
      "episode 16, val func loss 1.5003390312194824\n",
      "\n",
      "Val func train loss in epoch 6:1.7210434451699257\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.6171536445617676\n",
      "\n",
      "episode 2, val func loss 1.7008305788040161\n",
      "\n",
      "episode 3, val func loss 1.5959641933441162\n",
      "\n",
      "episode 4, val func loss 1.51583731174469\n",
      "\n",
      "episode 5, val func loss 1.7449201345443726\n",
      "\n",
      "episode 6, val func loss 1.512431263923645\n",
      "\n",
      "episode 7, val func loss 1.7062321901321411\n",
      "\n",
      "episode 8, val func loss 1.6999797821044922\n",
      "\n",
      "episode 9, val func loss 1.614586591720581\n",
      "\n",
      "episode 10, val func loss 1.9774889945983887\n",
      "\n",
      "episode 11, val func loss 1.3994381427764893\n",
      "\n",
      "episode 12, val func loss 1.8488667011260986\n",
      "\n",
      "episode 13, val func loss 1.6712504625320435\n",
      "\n",
      "episode 14, val func loss 1.6973508596420288\n",
      "\n",
      "episode 15, val func loss 1.6664881706237793\n",
      "\n",
      "episode 16, val func loss 1.5392357110977173\n",
      "\n",
      "Val func train loss in epoch 7:1.656753420829773\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.6886961460113525\n",
      "\n",
      "episode 2, val func loss 1.615272879600525\n",
      "\n",
      "episode 3, val func loss 1.4907089471817017\n",
      "\n",
      "episode 4, val func loss 1.6227436065673828\n",
      "\n",
      "episode 5, val func loss 1.4479479789733887\n",
      "\n",
      "episode 6, val func loss 1.8366559743881226\n",
      "\n",
      "episode 7, val func loss 1.8450589179992676\n",
      "\n",
      "episode 8, val func loss 1.6170560121536255\n",
      "\n",
      "episode 9, val func loss 1.5389281511306763\n",
      "\n",
      "episode 10, val func loss 1.8168292045593262\n",
      "\n",
      "episode 11, val func loss 1.7263469696044922\n",
      "\n",
      "episode 12, val func loss 1.4722763299942017\n",
      "\n",
      "episode 13, val func loss 1.844096064567566\n",
      "\n",
      "episode 14, val func loss 1.6477017402648926\n",
      "\n",
      "episode 15, val func loss 1.5463670492172241\n",
      "\n",
      "episode 16, val func loss 1.826062798500061\n",
      "\n",
      "Val func train loss in epoch 8:1.6614217981696129\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.55726158618927\n",
      "\n",
      "episode 2, val func loss 1.5874688625335693\n",
      "\n",
      "episode 3, val func loss 1.7570691108703613\n",
      "\n",
      "episode 4, val func loss 1.5687555074691772\n",
      "\n",
      "episode 5, val func loss 1.685986876487732\n",
      "\n",
      "episode 6, val func loss 1.7304551601409912\n",
      "\n",
      "episode 7, val func loss 1.6246490478515625\n",
      "\n",
      "episode 8, val func loss 1.4937822818756104\n",
      "\n",
      "episode 9, val func loss 1.5616309642791748\n",
      "\n",
      "episode 10, val func loss 1.588409662246704\n",
      "\n",
      "episode 11, val func loss 1.4280047416687012\n",
      "\n",
      "episode 12, val func loss 1.5764853954315186\n",
      "\n",
      "episode 13, val func loss 1.5476953983306885\n",
      "\n",
      "episode 14, val func loss 1.9728211164474487\n",
      "\n",
      "episode 15, val func loss 1.6998268365859985\n",
      "\n",
      "episode 16, val func loss 1.8148553371429443\n",
      "\n",
      "Val func train loss in epoch 9:1.6371973678469658\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.6475926637649536\n",
      "\n",
      "episode 2, val func loss 1.810118317604065\n",
      "\n",
      "episode 3, val func loss 1.5158655643463135\n",
      "\n",
      "episode 4, val func loss 1.6301963329315186\n",
      "\n",
      "episode 5, val func loss 1.6154390573501587\n",
      "\n",
      "episode 6, val func loss 1.7549687623977661\n",
      "\n",
      "episode 7, val func loss 1.7615036964416504\n",
      "\n",
      "episode 8, val func loss 1.6038166284561157\n",
      "\n",
      "episode 9, val func loss 1.7371909618377686\n",
      "\n",
      "episode 10, val func loss 1.5693150758743286\n",
      "\n",
      "episode 11, val func loss 1.6941890716552734\n",
      "\n",
      "episode 12, val func loss 1.5530784130096436\n",
      "\n",
      "episode 13, val func loss 1.578281283378601\n",
      "\n",
      "episode 14, val func loss 1.6194202899932861\n",
      "\n",
      "episode 15, val func loss 1.4852451086044312\n",
      "\n",
      "episode 16, val func loss 1.5391581058502197\n",
      "\n",
      "Val func train loss in epoch 10:1.6322112083435059\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.3136940002441406\n",
      "\n",
      "episode 2, val func loss 1.688028335571289\n",
      "\n",
      "episode 3, val func loss 1.5669642686843872\n",
      "\n",
      "episode 4, val func loss 1.6501803398132324\n",
      "\n",
      "episode 5, val func loss 1.6008201837539673\n",
      "\n",
      "episode 6, val func loss 1.465701937675476\n",
      "\n",
      "episode 7, val func loss 1.744202971458435\n",
      "\n",
      "episode 8, val func loss 1.5457196235656738\n",
      "\n",
      "episode 9, val func loss 1.5368062257766724\n",
      "\n",
      "episode 10, val func loss 1.450413465499878\n",
      "\n",
      "episode 11, val func loss 1.4927610158920288\n",
      "\n",
      "episode 12, val func loss 1.7680072784423828\n",
      "\n",
      "episode 13, val func loss 1.9723514318466187\n",
      "\n",
      "episode 14, val func loss 1.6854125261306763\n",
      "\n",
      "episode 15, val func loss 1.8265228271484375\n",
      "\n",
      "episode 16, val func loss 1.639660120010376\n",
      "\n",
      "Val func train loss in epoch 11:1.6217029094696045\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.8235574960708618\n",
      "\n",
      "episode 2, val func loss 1.770208477973938\n",
      "\n",
      "episode 3, val func loss 1.530671238899231\n",
      "\n",
      "episode 4, val func loss 1.5337700843811035\n",
      "\n",
      "episode 5, val func loss 1.4905644655227661\n",
      "\n",
      "episode 6, val func loss 1.6780542135238647\n",
      "\n",
      "episode 7, val func loss 1.5421133041381836\n",
      "\n",
      "episode 8, val func loss 1.6238585710525513\n",
      "\n",
      "episode 9, val func loss 1.4585402011871338\n",
      "\n",
      "episode 10, val func loss 1.7225204706192017\n",
      "\n",
      "episode 11, val func loss 1.9038516283035278\n",
      "\n",
      "episode 12, val func loss 1.6276053190231323\n",
      "\n",
      "episode 13, val func loss 1.7482770681381226\n",
      "\n",
      "episode 14, val func loss 1.8050991296768188\n",
      "\n",
      "episode 15, val func loss 1.816673755645752\n",
      "\n",
      "episode 16, val func loss 2.026468515396118\n",
      "\n",
      "Val func train loss in epoch 12:1.6938646212220192\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.8287718296051025\n",
      "\n",
      "episode 2, val func loss 1.8562891483306885\n",
      "\n",
      "episode 3, val func loss 1.7013007402420044\n",
      "\n",
      "episode 4, val func loss 1.607209324836731\n",
      "\n",
      "episode 5, val func loss 1.7371692657470703\n",
      "\n",
      "episode 6, val func loss 1.843613862991333\n",
      "\n",
      "episode 7, val func loss 1.710052490234375\n",
      "\n",
      "episode 8, val func loss 1.6655983924865723\n",
      "\n",
      "episode 9, val func loss 1.6840449571609497\n",
      "\n",
      "episode 10, val func loss 1.59837007522583\n",
      "\n",
      "episode 11, val func loss 1.56063711643219\n",
      "\n",
      "episode 12, val func loss 1.6750363111495972\n",
      "\n",
      "episode 13, val func loss 1.6513197422027588\n",
      "\n",
      "episode 14, val func loss 1.7151745557785034\n",
      "\n",
      "episode 15, val func loss 1.4934649467468262\n",
      "\n",
      "episode 16, val func loss 1.3768315315246582\n",
      "\n",
      "Val func train loss in epoch 13:1.6690552681684494\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.5870503187179565\n",
      "\n",
      "episode 2, val func loss 1.678531527519226\n",
      "\n",
      "episode 3, val func loss 1.43787682056427\n",
      "\n",
      "episode 4, val func loss 1.5087043046951294\n",
      "\n",
      "episode 5, val func loss 1.5798685550689697\n",
      "\n",
      "episode 6, val func loss 1.766114354133606\n",
      "\n",
      "episode 7, val func loss 1.639998435974121\n",
      "\n",
      "episode 8, val func loss 1.7659132480621338\n",
      "\n",
      "episode 9, val func loss 1.6480991840362549\n",
      "\n",
      "episode 10, val func loss 1.688589334487915\n",
      "\n",
      "episode 11, val func loss 1.8223028182983398\n",
      "\n",
      "episode 12, val func loss 1.6552562713623047\n",
      "\n",
      "episode 13, val func loss 1.7582718133926392\n",
      "\n",
      "episode 14, val func loss 1.7520381212234497\n",
      "\n",
      "episode 15, val func loss 2.0520918369293213\n",
      "\n",
      "episode 16, val func loss 1.788820743560791\n",
      "\n",
      "Val func train loss in epoch 14:1.6955954805016518\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.5437430143356323\n",
      "\n",
      "episode 2, val func loss 1.7017842531204224\n",
      "\n",
      "episode 3, val func loss 1.8833141326904297\n",
      "\n",
      "episode 4, val func loss 1.5467184782028198\n",
      "\n",
      "episode 5, val func loss 1.583740472793579\n",
      "\n",
      "episode 6, val func loss 1.9209177494049072\n",
      "\n",
      "episode 7, val func loss 1.800520896911621\n",
      "\n",
      "episode 8, val func loss 1.5934916734695435\n",
      "\n",
      "episode 9, val func loss 1.550081491470337\n",
      "\n",
      "episode 10, val func loss 1.5891684293746948\n",
      "\n",
      "episode 11, val func loss 1.4778777360916138\n",
      "\n",
      "episode 12, val func loss 1.5084974765777588\n",
      "\n",
      "episode 13, val func loss 1.7025361061096191\n",
      "\n",
      "episode 14, val func loss 1.7791708707809448\n",
      "\n",
      "episode 15, val func loss 1.881850242614746\n",
      "\n",
      "episode 16, val func loss 1.7440013885498047\n",
      "\n",
      "Val func train loss in epoch 15:1.6754634007811546\n",
      "***********************TIME WAS 4.807362512747447 min*****************************\n",
      "\n",
      "**********************ROUND 18 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.3025107383728027\n",
      "\n",
      "episode 2, policy loss -2.3025104999542236\n",
      "\n",
      "episode 3, policy loss -2.302510976791382\n",
      "\n",
      "episode 4, policy loss -2.3025104999542236\n",
      "\n",
      "episode 5, policy loss -2.3025104999542236\n",
      "\n",
      "episode 6, policy loss -2.302510976791382\n",
      "\n",
      "episode 7, policy loss -2.302511215209961\n",
      "\n",
      "episode 8, policy loss -2.3025107383728027\n",
      "\n",
      "episode 9, policy loss -2.3025104999542236\n",
      "\n",
      "episode 10, policy loss -2.302511215209961\n",
      "\n",
      "episode 11, policy loss -2.302511215209961\n",
      "\n",
      "episode 12, policy loss -2.302510976791382\n",
      "\n",
      "episode 13, policy loss -2.302511215209961\n",
      "\n",
      "episode 14, policy loss -2.3025107383728027\n",
      "\n",
      "episode 15, policy loss -2.3025107383728027\n",
      "\n",
      "episode 16, policy loss -2.3025107383728027\n",
      "\n",
      "Policy train loss in epoch 0:-2.302510842680931\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.302510976791382\n",
      "\n",
      "episode 2, policy loss -2.3025104999542236\n",
      "\n",
      "episode 3, policy loss -2.3025107383728027\n",
      "\n",
      "episode 4, policy loss -2.302510976791382\n",
      "\n",
      "episode 5, policy loss -2.3025107383728027\n",
      "\n",
      "episode 6, policy loss -2.3025104999542236\n",
      "\n",
      "episode 7, policy loss -2.302511215209961\n",
      "\n",
      "episode 8, policy loss -2.3025107383728027\n",
      "\n",
      "episode 9, policy loss -2.3025104999542236\n",
      "\n",
      "episode 10, policy loss -2.302511215209961\n",
      "\n",
      "episode 11, policy loss -2.302511215209961\n",
      "\n",
      "episode 12, policy loss -2.302511215209961\n",
      "\n",
      "episode 13, policy loss -2.302510976791382\n",
      "\n",
      "episode 14, policy loss -2.3025107383728027\n",
      "\n",
      "episode 15, policy loss -2.3025107383728027\n",
      "\n",
      "episode 16, policy loss -2.3025104999542236\n",
      "\n",
      "Policy train loss in epoch 1:-2.302510842680931\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.3025104999542236\n",
      "\n",
      "episode 2, policy loss -2.302511215209961\n",
      "\n",
      "episode 3, policy loss -2.302510976791382\n",
      "\n",
      "episode 4, policy loss -2.3025104999542236\n",
      "\n",
      "episode 5, policy loss -2.302511215209961\n",
      "\n",
      "episode 6, policy loss -2.3025107383728027\n",
      "\n",
      "episode 7, policy loss -2.3025107383728027\n",
      "\n",
      "episode 8, policy loss -2.302511215209961\n",
      "\n",
      "episode 9, policy loss -2.3025104999542236\n",
      "\n",
      "episode 10, policy loss -2.302510976791382\n",
      "\n",
      "episode 11, policy loss -2.3025107383728027\n",
      "\n",
      "episode 12, policy loss -2.3025104999542236\n",
      "\n",
      "episode 13, policy loss -2.3025107383728027\n",
      "\n",
      "episode 14, policy loss -2.302511215209961\n",
      "\n",
      "episode 15, policy loss -2.3025107383728027\n",
      "\n",
      "episode 16, policy loss -2.302510976791382\n",
      "\n",
      "Policy train loss in epoch 2:-2.302510842680931\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.3025104999542236\n",
      "\n",
      "episode 2, policy loss -2.3025107383728027\n",
      "\n",
      "episode 3, policy loss -2.302511215209961\n",
      "\n",
      "episode 4, policy loss -2.3025107383728027\n",
      "\n",
      "episode 5, policy loss -2.302511215209961\n",
      "\n",
      "episode 6, policy loss -2.3025107383728027\n",
      "\n",
      "episode 7, policy loss -2.3025107383728027\n",
      "\n",
      "episode 8, policy loss -2.3025104999542236\n",
      "\n",
      "episode 9, policy loss -2.302511215209961\n",
      "\n",
      "episode 10, policy loss -2.302510976791382\n",
      "\n",
      "episode 11, policy loss -2.3025104999542236\n",
      "\n",
      "episode 12, policy loss -2.302510976791382\n",
      "\n",
      "episode 13, policy loss -2.3025107383728027\n",
      "\n",
      "episode 14, policy loss -2.3025104999542236\n",
      "\n",
      "episode 15, policy loss -2.302511215209961\n",
      "\n",
      "episode 16, policy loss -2.302510976791382\n",
      "\n",
      "Policy train loss in epoch 3:-2.302510842680931\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.6827603578567505\n",
      "\n",
      "episode 2, val func loss 1.3706021308898926\n",
      "\n",
      "episode 3, val func loss 1.5455130338668823\n",
      "\n",
      "episode 4, val func loss 1.4898097515106201\n",
      "\n",
      "episode 5, val func loss 1.5569647550582886\n",
      "\n",
      "episode 6, val func loss 1.553745150566101\n",
      "\n",
      "episode 7, val func loss 1.8618558645248413\n",
      "\n",
      "episode 8, val func loss 1.6712826490402222\n",
      "\n",
      "episode 9, val func loss 1.4312400817871094\n",
      "\n",
      "episode 10, val func loss 1.4555130004882812\n",
      "\n",
      "episode 11, val func loss 1.7413887977600098\n",
      "\n",
      "episode 12, val func loss 1.499666452407837\n",
      "\n",
      "episode 13, val func loss 1.6176482439041138\n",
      "\n",
      "episode 14, val func loss 1.6017272472381592\n",
      "\n",
      "episode 15, val func loss 1.4368057250976562\n",
      "\n",
      "episode 16, val func loss 1.5678375959396362\n",
      "\n",
      "Val func train loss in epoch 0:1.567772552371025\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.5362510681152344\n",
      "\n",
      "episode 2, val func loss 1.806889295578003\n",
      "\n",
      "episode 3, val func loss 1.5494773387908936\n",
      "\n",
      "episode 4, val func loss 1.4224861860275269\n",
      "\n",
      "episode 5, val func loss 1.7071194648742676\n",
      "\n",
      "episode 6, val func loss 1.6825112104415894\n",
      "\n",
      "episode 7, val func loss 1.78449285030365\n",
      "\n",
      "episode 8, val func loss 1.7549301385879517\n",
      "\n",
      "episode 9, val func loss 2.0589139461517334\n",
      "\n",
      "episode 10, val func loss 1.6034964323043823\n",
      "\n",
      "episode 11, val func loss 1.4372737407684326\n",
      "\n",
      "episode 12, val func loss 1.8783177137374878\n",
      "\n",
      "episode 13, val func loss 1.5372313261032104\n",
      "\n",
      "episode 14, val func loss 1.5310566425323486\n",
      "\n",
      "episode 15, val func loss 1.7098736763000488\n",
      "\n",
      "episode 16, val func loss 1.819042682647705\n",
      "\n",
      "Val func train loss in epoch 1:1.676210232079029\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.76019287109375\n",
      "\n",
      "episode 2, val func loss 1.7040505409240723\n",
      "\n",
      "episode 3, val func loss 1.5852727890014648\n",
      "\n",
      "episode 4, val func loss 1.7829151153564453\n",
      "\n",
      "episode 5, val func loss 1.7892627716064453\n",
      "\n",
      "episode 6, val func loss 1.8965132236480713\n",
      "\n",
      "episode 7, val func loss 1.801390290260315\n",
      "\n",
      "episode 8, val func loss 1.6894863843917847\n",
      "\n",
      "episode 9, val func loss 2.1921727657318115\n",
      "\n",
      "episode 10, val func loss 1.5513995885849\n",
      "\n",
      "episode 11, val func loss 1.7166472673416138\n",
      "\n",
      "episode 12, val func loss 1.69707453250885\n",
      "\n",
      "episode 13, val func loss 1.9827613830566406\n",
      "\n",
      "episode 14, val func loss 1.7492696046829224\n",
      "\n",
      "episode 15, val func loss 1.7592936754226685\n",
      "\n",
      "episode 16, val func loss 1.791021466255188\n",
      "\n",
      "Val func train loss in epoch 2:1.778045266866684\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.687602162361145\n",
      "\n",
      "episode 2, val func loss 1.7168083190917969\n",
      "\n",
      "episode 3, val func loss 1.5311464071273804\n",
      "\n",
      "episode 4, val func loss 1.7351068258285522\n",
      "\n",
      "episode 5, val func loss 1.7260385751724243\n",
      "\n",
      "episode 6, val func loss 1.7106844186782837\n",
      "\n",
      "episode 7, val func loss 1.7486711740493774\n",
      "\n",
      "episode 8, val func loss 1.7761921882629395\n",
      "\n",
      "episode 9, val func loss 1.5364941358566284\n",
      "\n",
      "episode 10, val func loss 1.8119564056396484\n",
      "\n",
      "episode 11, val func loss 1.6449283361434937\n",
      "\n",
      "episode 12, val func loss 2.0045077800750732\n",
      "\n",
      "episode 13, val func loss 1.7667018175125122\n",
      "\n",
      "episode 14, val func loss 1.7363547086715698\n",
      "\n",
      "episode 15, val func loss 1.7309129238128662\n",
      "\n",
      "episode 16, val func loss 1.933867335319519\n",
      "\n",
      "Val func train loss in epoch 3:1.7373733446002007\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.545176386833191\n",
      "\n",
      "episode 2, val func loss 1.5650830268859863\n",
      "\n",
      "episode 3, val func loss 1.5555871725082397\n",
      "\n",
      "episode 4, val func loss 1.86910879611969\n",
      "\n",
      "episode 5, val func loss 1.620848298072815\n",
      "\n",
      "episode 6, val func loss 1.7620989084243774\n",
      "\n",
      "episode 7, val func loss 1.6648402214050293\n",
      "\n",
      "episode 8, val func loss 1.744699478149414\n",
      "\n",
      "episode 9, val func loss 1.7810248136520386\n",
      "\n",
      "episode 10, val func loss 1.745158076286316\n",
      "\n",
      "episode 11, val func loss 1.6230518817901611\n",
      "\n",
      "episode 12, val func loss 1.8184791803359985\n",
      "\n",
      "episode 13, val func loss 1.6685926914215088\n",
      "\n",
      "episode 14, val func loss 1.7774001359939575\n",
      "\n",
      "episode 15, val func loss 1.7637617588043213\n",
      "\n",
      "episode 16, val func loss 1.6525907516479492\n",
      "\n",
      "Val func train loss in epoch 4:1.697343848645687\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.5420081615447998\n",
      "\n",
      "episode 2, val func loss 1.6237239837646484\n",
      "\n",
      "episode 3, val func loss 1.6578153371810913\n",
      "\n",
      "episode 4, val func loss 1.2981557846069336\n",
      "\n",
      "episode 5, val func loss 1.6705350875854492\n",
      "\n",
      "episode 6, val func loss 1.6719084978103638\n",
      "\n",
      "episode 7, val func loss 1.5124256610870361\n",
      "\n",
      "episode 8, val func loss 1.5179393291473389\n",
      "\n",
      "episode 9, val func loss 1.4922187328338623\n",
      "\n",
      "episode 10, val func loss 1.8462015390396118\n",
      "\n",
      "episode 11, val func loss 1.4444040060043335\n",
      "\n",
      "episode 12, val func loss 1.6045492887496948\n",
      "\n",
      "episode 13, val func loss 1.5591858625411987\n",
      "\n",
      "episode 14, val func loss 1.646849513053894\n",
      "\n",
      "episode 15, val func loss 1.7536009550094604\n",
      "\n",
      "episode 16, val func loss 1.4943721294403076\n",
      "\n",
      "Val func train loss in epoch 5:1.5834933668375015\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.6882543563842773\n",
      "\n",
      "episode 2, val func loss 1.5049299001693726\n",
      "\n",
      "episode 3, val func loss 1.5560204982757568\n",
      "\n",
      "episode 4, val func loss 1.6244078874588013\n",
      "\n",
      "episode 5, val func loss 1.528097152709961\n",
      "\n",
      "episode 6, val func loss 1.3882919549942017\n",
      "\n",
      "episode 7, val func loss 1.6511715650558472\n",
      "\n",
      "episode 8, val func loss 1.4659545421600342\n",
      "\n",
      "episode 9, val func loss 1.58220374584198\n",
      "\n",
      "episode 10, val func loss 1.8050297498703003\n",
      "\n",
      "episode 11, val func loss 1.6829452514648438\n",
      "\n",
      "episode 12, val func loss 2.001490831375122\n",
      "\n",
      "episode 13, val func loss 1.6729484796524048\n",
      "\n",
      "episode 14, val func loss 1.6922717094421387\n",
      "\n",
      "episode 15, val func loss 1.65377938747406\n",
      "\n",
      "episode 16, val func loss 1.6391407251358032\n",
      "\n",
      "Val func train loss in epoch 6:1.6335586085915565\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.457398533821106\n",
      "\n",
      "episode 2, val func loss 1.6689894199371338\n",
      "\n",
      "episode 3, val func loss 1.5284503698349\n",
      "\n",
      "episode 4, val func loss 1.7035051584243774\n",
      "\n",
      "episode 5, val func loss 1.6422724723815918\n",
      "\n",
      "episode 6, val func loss 1.7285279035568237\n",
      "\n",
      "episode 7, val func loss 1.63625168800354\n",
      "\n",
      "episode 8, val func loss 1.6559535264968872\n",
      "\n",
      "episode 9, val func loss 1.6782810688018799\n",
      "\n",
      "episode 10, val func loss 1.89143705368042\n",
      "\n",
      "episode 11, val func loss 1.5656476020812988\n",
      "\n",
      "episode 12, val func loss 1.8219538927078247\n",
      "\n",
      "episode 13, val func loss 1.4059146642684937\n",
      "\n",
      "episode 14, val func loss 1.379263997077942\n",
      "\n",
      "episode 15, val func loss 1.6649460792541504\n",
      "\n",
      "episode 16, val func loss 1.6544196605682373\n",
      "\n",
      "Val func train loss in epoch 7:1.630200818181038\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.4205125570297241\n",
      "\n",
      "episode 2, val func loss 1.5532705783843994\n",
      "\n",
      "episode 3, val func loss 1.6898412704467773\n",
      "\n",
      "episode 4, val func loss 1.6137685775756836\n",
      "\n",
      "episode 5, val func loss 1.3702154159545898\n",
      "\n",
      "episode 6, val func loss 1.4793466329574585\n",
      "\n",
      "episode 7, val func loss 1.5535244941711426\n",
      "\n",
      "episode 8, val func loss 1.321873426437378\n",
      "\n",
      "episode 9, val func loss 1.5574277639389038\n",
      "\n",
      "episode 10, val func loss 1.577720284461975\n",
      "\n",
      "episode 11, val func loss 1.6542415618896484\n",
      "\n",
      "episode 12, val func loss 1.7097200155258179\n",
      "\n",
      "episode 13, val func loss 1.5312832593917847\n",
      "\n",
      "episode 14, val func loss 1.6259722709655762\n",
      "\n",
      "episode 15, val func loss 1.6526265144348145\n",
      "\n",
      "episode 16, val func loss 1.7346622943878174\n",
      "\n",
      "Val func train loss in epoch 8:1.5653754323720932\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.6426030397415161\n",
      "\n",
      "episode 2, val func loss 1.6026363372802734\n",
      "\n",
      "episode 3, val func loss 1.745779037475586\n",
      "\n",
      "episode 4, val func loss 1.4060972929000854\n",
      "\n",
      "episode 5, val func loss 1.7809664011001587\n",
      "\n",
      "episode 6, val func loss 1.451622724533081\n",
      "\n",
      "episode 7, val func loss 1.66597318649292\n",
      "\n",
      "episode 8, val func loss 1.5490175485610962\n",
      "\n",
      "episode 9, val func loss 1.7123950719833374\n",
      "\n",
      "episode 10, val func loss 1.732228398323059\n",
      "\n",
      "episode 11, val func loss 1.55092191696167\n",
      "\n",
      "episode 12, val func loss 1.6794776916503906\n",
      "\n",
      "episode 13, val func loss 1.5497008562088013\n",
      "\n",
      "episode 14, val func loss 1.566644310951233\n",
      "\n",
      "episode 15, val func loss 1.658011555671692\n",
      "\n",
      "episode 16, val func loss 1.8451169729232788\n",
      "\n",
      "Val func train loss in epoch 9:1.6336995214223862\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.7045520544052124\n",
      "\n",
      "episode 2, val func loss 1.7667443752288818\n",
      "\n",
      "episode 3, val func loss 1.429909110069275\n",
      "\n",
      "episode 4, val func loss 1.6200392246246338\n",
      "\n",
      "episode 5, val func loss 1.7774641513824463\n",
      "\n",
      "episode 6, val func loss 1.6140179634094238\n",
      "\n",
      "episode 7, val func loss 1.5196254253387451\n",
      "\n",
      "episode 8, val func loss 1.7489224672317505\n",
      "\n",
      "episode 9, val func loss 1.571462869644165\n",
      "\n",
      "episode 10, val func loss 1.5801175832748413\n",
      "\n",
      "episode 11, val func loss 1.5018330812454224\n",
      "\n",
      "episode 12, val func loss 1.5540592670440674\n",
      "\n",
      "episode 13, val func loss 1.6328704357147217\n",
      "\n",
      "episode 14, val func loss 1.5171079635620117\n",
      "\n",
      "episode 15, val func loss 1.6191468238830566\n",
      "\n",
      "episode 16, val func loss 1.5121028423309326\n",
      "\n",
      "Val func train loss in epoch 10:1.6043734773993492\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.656129002571106\n",
      "\n",
      "episode 2, val func loss 1.955181360244751\n",
      "\n",
      "episode 3, val func loss 1.6980912685394287\n",
      "\n",
      "episode 4, val func loss 1.7350491285324097\n",
      "\n",
      "episode 5, val func loss 1.4399656057357788\n",
      "\n",
      "episode 6, val func loss 1.4265495538711548\n",
      "\n",
      "episode 7, val func loss 1.581154227256775\n",
      "\n",
      "episode 8, val func loss 1.9871087074279785\n",
      "\n",
      "episode 9, val func loss 1.7170350551605225\n",
      "\n",
      "episode 10, val func loss 1.520728588104248\n",
      "\n",
      "episode 11, val func loss 1.5245915651321411\n",
      "\n",
      "episode 12, val func loss 1.882098913192749\n",
      "\n",
      "episode 13, val func loss 1.5399967432022095\n",
      "\n",
      "episode 14, val func loss 1.6477657556533813\n",
      "\n",
      "episode 15, val func loss 1.5846272706985474\n",
      "\n",
      "episode 16, val func loss 1.3895606994628906\n",
      "\n",
      "Val func train loss in epoch 11:1.6428520902991295\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.6075899600982666\n",
      "\n",
      "episode 2, val func loss 1.7814079523086548\n",
      "\n",
      "episode 3, val func loss 1.5005395412445068\n",
      "\n",
      "episode 4, val func loss 1.521277904510498\n",
      "\n",
      "episode 5, val func loss 1.6725200414657593\n",
      "\n",
      "episode 6, val func loss 1.5630522966384888\n",
      "\n",
      "episode 7, val func loss 1.4707419872283936\n",
      "\n",
      "episode 8, val func loss 1.6478279829025269\n",
      "\n",
      "episode 9, val func loss 1.4040005207061768\n",
      "\n",
      "episode 10, val func loss 1.7103267908096313\n",
      "\n",
      "episode 11, val func loss 1.608006238937378\n",
      "\n",
      "episode 12, val func loss 1.6161612272262573\n",
      "\n",
      "episode 13, val func loss 1.5933222770690918\n",
      "\n",
      "episode 14, val func loss 1.589131236076355\n",
      "\n",
      "episode 15, val func loss 1.616503357887268\n",
      "\n",
      "episode 16, val func loss 1.861290693283081\n",
      "\n",
      "Val func train loss in epoch 12:1.6102312505245209\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.7479443550109863\n",
      "\n",
      "episode 2, val func loss 1.8703147172927856\n",
      "\n",
      "episode 3, val func loss 1.7907044887542725\n",
      "\n",
      "episode 4, val func loss 1.84634268283844\n",
      "\n",
      "episode 5, val func loss 1.7418928146362305\n",
      "\n",
      "episode 6, val func loss 1.6907446384429932\n",
      "\n",
      "episode 7, val func loss 1.6992496252059937\n",
      "\n",
      "episode 8, val func loss 1.5792535543441772\n",
      "\n",
      "episode 9, val func loss 1.5956283807754517\n",
      "\n",
      "episode 10, val func loss 1.6244503259658813\n",
      "\n",
      "episode 11, val func loss 1.642271637916565\n",
      "\n",
      "episode 12, val func loss 1.511420726776123\n",
      "\n",
      "episode 13, val func loss 1.7096281051635742\n",
      "\n",
      "episode 14, val func loss 1.3732112646102905\n",
      "\n",
      "episode 15, val func loss 1.616631269454956\n",
      "\n",
      "episode 16, val func loss 1.6140437126159668\n",
      "\n",
      "Val func train loss in epoch 13:1.665858268737793\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.7955471277236938\n",
      "\n",
      "episode 2, val func loss 1.679809808731079\n",
      "\n",
      "episode 3, val func loss 1.634503722190857\n",
      "\n",
      "episode 4, val func loss 1.8581115007400513\n",
      "\n",
      "episode 5, val func loss 1.619770884513855\n",
      "\n",
      "episode 6, val func loss 1.9382039308547974\n",
      "\n",
      "episode 7, val func loss 1.7190427780151367\n",
      "\n",
      "episode 8, val func loss 1.7419294118881226\n",
      "\n",
      "episode 9, val func loss 1.821070671081543\n",
      "\n",
      "episode 10, val func loss 1.6537584066390991\n",
      "\n",
      "episode 11, val func loss 1.6901304721832275\n",
      "\n",
      "episode 12, val func loss 1.5273454189300537\n",
      "\n",
      "episode 13, val func loss 1.5598015785217285\n",
      "\n",
      "episode 14, val func loss 1.7597638368606567\n",
      "\n",
      "episode 15, val func loss 1.4831444025039673\n",
      "\n",
      "episode 16, val func loss 1.6142292022705078\n",
      "\n",
      "Val func train loss in epoch 14:1.6935101971030235\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.4941879510879517\n",
      "\n",
      "episode 2, val func loss 1.4383492469787598\n",
      "\n",
      "episode 3, val func loss 1.7642605304718018\n",
      "\n",
      "episode 4, val func loss 1.5800189971923828\n",
      "\n",
      "episode 5, val func loss 1.3939342498779297\n",
      "\n",
      "episode 6, val func loss 1.64609956741333\n",
      "\n",
      "episode 7, val func loss 1.83259916305542\n",
      "\n",
      "episode 8, val func loss 1.497969150543213\n",
      "\n",
      "episode 9, val func loss 1.5248035192489624\n",
      "\n",
      "episode 10, val func loss 1.6939293146133423\n",
      "\n",
      "episode 11, val func loss 1.8700196743011475\n",
      "\n",
      "episode 12, val func loss 1.7098582983016968\n",
      "\n",
      "episode 13, val func loss 1.7020764350891113\n",
      "\n",
      "episode 14, val func loss 1.6283828020095825\n",
      "\n",
      "episode 15, val func loss 1.7860603332519531\n",
      "\n",
      "episode 16, val func loss 1.464285135269165\n",
      "\n",
      "Val func train loss in epoch 15:1.6266771480441093\n",
      "***********************TIME WAS 5.103441806634267 min*****************************\n",
      "\n",
      "**********************ROUND 19 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.3651866912841797\n",
      "\n",
      "episode 2, policy loss -2.3651866912841797\n",
      "\n",
      "episode 3, policy loss -2.3651866912841797\n",
      "\n",
      "episode 4, policy loss -2.3651866912841797\n",
      "\n",
      "episode 5, policy loss -2.3651866912841797\n",
      "\n",
      "episode 6, policy loss -2.3651866912841797\n",
      "\n",
      "episode 7, policy loss -2.3651866912841797\n",
      "\n",
      "episode 8, policy loss -2.3651866912841797\n",
      "\n",
      "episode 9, policy loss -2.3651866912841797\n",
      "\n",
      "episode 10, policy loss -2.3651866912841797\n",
      "\n",
      "episode 11, policy loss -2.3651866912841797\n",
      "\n",
      "episode 12, policy loss -2.3651866912841797\n",
      "\n",
      "episode 13, policy loss -2.3651866912841797\n",
      "\n",
      "episode 14, policy loss -2.3651864528656006\n",
      "\n",
      "episode 15, policy loss -2.3651866912841797\n",
      "\n",
      "episode 16, policy loss -2.3651866912841797\n",
      "\n",
      "Policy train loss in epoch 0:-2.3651866763830185\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.3651866912841797\n",
      "\n",
      "episode 2, policy loss -2.3651866912841797\n",
      "\n",
      "episode 3, policy loss -2.3651866912841797\n",
      "\n",
      "episode 4, policy loss -2.3651866912841797\n",
      "\n",
      "episode 5, policy loss -2.3651866912841797\n",
      "\n",
      "episode 6, policy loss -2.3651866912841797\n",
      "\n",
      "episode 7, policy loss -2.3651866912841797\n",
      "\n",
      "episode 8, policy loss -2.3651866912841797\n",
      "\n",
      "episode 9, policy loss -2.3651866912841797\n",
      "\n",
      "episode 10, policy loss -2.3651866912841797\n",
      "\n",
      "episode 11, policy loss -2.3651866912841797\n",
      "\n",
      "episode 12, policy loss -2.3651866912841797\n",
      "\n",
      "episode 13, policy loss -2.3651864528656006\n",
      "\n",
      "episode 14, policy loss -2.3651866912841797\n",
      "\n",
      "episode 15, policy loss -2.3651866912841797\n",
      "\n",
      "episode 16, policy loss -2.3651866912841797\n",
      "\n",
      "Policy train loss in epoch 1:-2.3651866763830185\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.3651866912841797\n",
      "\n",
      "episode 2, policy loss -2.3651866912841797\n",
      "\n",
      "episode 3, policy loss -2.3651866912841797\n",
      "\n",
      "episode 4, policy loss -2.3651866912841797\n",
      "\n",
      "episode 5, policy loss -2.3651866912841797\n",
      "\n",
      "episode 6, policy loss -2.3651866912841797\n",
      "\n",
      "episode 7, policy loss -2.3651866912841797\n",
      "\n",
      "episode 8, policy loss -2.3651866912841797\n",
      "\n",
      "episode 9, policy loss -2.3651866912841797\n",
      "\n",
      "episode 10, policy loss -2.3651866912841797\n",
      "\n",
      "episode 11, policy loss -2.3651864528656006\n",
      "\n",
      "episode 12, policy loss -2.3651866912841797\n",
      "\n",
      "episode 13, policy loss -2.3651866912841797\n",
      "\n",
      "episode 14, policy loss -2.3651866912841797\n",
      "\n",
      "episode 15, policy loss -2.3651866912841797\n",
      "\n",
      "episode 16, policy loss -2.3651866912841797\n",
      "\n",
      "Policy train loss in epoch 2:-2.3651866763830185\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.3651866912841797\n",
      "\n",
      "episode 2, policy loss -2.3651866912841797\n",
      "\n",
      "episode 3, policy loss -2.3651866912841797\n",
      "\n",
      "episode 4, policy loss -2.3651866912841797\n",
      "\n",
      "episode 5, policy loss -2.3651866912841797\n",
      "\n",
      "episode 6, policy loss -2.3651866912841797\n",
      "\n",
      "episode 7, policy loss -2.3651866912841797\n",
      "\n",
      "episode 8, policy loss -2.3651866912841797\n",
      "\n",
      "episode 9, policy loss -2.3651866912841797\n",
      "\n",
      "episode 10, policy loss -2.3651866912841797\n",
      "\n",
      "episode 11, policy loss -2.3651864528656006\n",
      "\n",
      "episode 12, policy loss -2.3651866912841797\n",
      "\n",
      "episode 13, policy loss -2.3651866912841797\n",
      "\n",
      "episode 14, policy loss -2.3651866912841797\n",
      "\n",
      "episode 15, policy loss -2.3651866912841797\n",
      "\n",
      "episode 16, policy loss -2.3651866912841797\n",
      "\n",
      "Policy train loss in epoch 3:-2.3651866763830185\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.4461123943328857\n",
      "\n",
      "episode 2, val func loss 1.549764633178711\n",
      "\n",
      "episode 3, val func loss 1.5559594631195068\n",
      "\n",
      "episode 4, val func loss 1.6224021911621094\n",
      "\n",
      "episode 5, val func loss 1.8456835746765137\n",
      "\n",
      "episode 6, val func loss 1.3945246934890747\n",
      "\n",
      "episode 7, val func loss 1.6121515035629272\n",
      "\n",
      "episode 8, val func loss 1.670412302017212\n",
      "\n",
      "episode 9, val func loss 1.6700658798217773\n",
      "\n",
      "episode 10, val func loss 1.7015448808670044\n",
      "\n",
      "episode 11, val func loss 1.7596664428710938\n",
      "\n",
      "episode 12, val func loss 1.670380711555481\n",
      "\n",
      "episode 13, val func loss 1.7818981409072876\n",
      "\n",
      "episode 14, val func loss 1.5498398542404175\n",
      "\n",
      "episode 15, val func loss 1.792717695236206\n",
      "\n",
      "episode 16, val func loss 1.800092339515686\n",
      "\n",
      "Val func train loss in epoch 0:1.6514510437846184\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.6044741868972778\n",
      "\n",
      "episode 2, val func loss 1.6764370203018188\n",
      "\n",
      "episode 3, val func loss 1.7002135515213013\n",
      "\n",
      "episode 4, val func loss 1.595560073852539\n",
      "\n",
      "episode 5, val func loss 1.67432701587677\n",
      "\n",
      "episode 6, val func loss 1.7048330307006836\n",
      "\n",
      "episode 7, val func loss 1.6046322584152222\n",
      "\n",
      "episode 8, val func loss 1.470298171043396\n",
      "\n",
      "episode 9, val func loss 1.79536771774292\n",
      "\n",
      "episode 10, val func loss 1.7756555080413818\n",
      "\n",
      "episode 11, val func loss 1.7421526908874512\n",
      "\n",
      "episode 12, val func loss 1.5047475099563599\n",
      "\n",
      "episode 13, val func loss 1.9455153942108154\n",
      "\n",
      "episode 14, val func loss 1.6308623552322388\n",
      "\n",
      "episode 15, val func loss 1.6266025304794312\n",
      "\n",
      "episode 16, val func loss 1.920977234840393\n",
      "\n",
      "Val func train loss in epoch 1:1.685791015625\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.8735562562942505\n",
      "\n",
      "episode 2, val func loss 1.6228002309799194\n",
      "\n",
      "episode 3, val func loss 1.7165895700454712\n",
      "\n",
      "episode 4, val func loss 1.5508266687393188\n",
      "\n",
      "episode 5, val func loss 1.8031777143478394\n",
      "\n",
      "episode 6, val func loss 1.7062517404556274\n",
      "\n",
      "episode 7, val func loss 1.4778128862380981\n",
      "\n",
      "episode 8, val func loss 1.4112006425857544\n",
      "\n",
      "episode 9, val func loss 1.5555263757705688\n",
      "\n",
      "episode 10, val func loss 1.6069191694259644\n",
      "\n",
      "episode 11, val func loss 1.5254685878753662\n",
      "\n",
      "episode 12, val func loss 1.4992072582244873\n",
      "\n",
      "episode 13, val func loss 1.5756206512451172\n",
      "\n",
      "episode 14, val func loss 1.89824378490448\n",
      "\n",
      "episode 15, val func loss 1.6493979692459106\n",
      "\n",
      "episode 16, val func loss 1.3804644346237183\n",
      "\n",
      "Val func train loss in epoch 2:1.6158164963126183\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.8010739088058472\n",
      "\n",
      "episode 2, val func loss 1.5208660364151\n",
      "\n",
      "episode 3, val func loss 1.6333333253860474\n",
      "\n",
      "episode 4, val func loss 1.7166420221328735\n",
      "\n",
      "episode 5, val func loss 1.6870485544204712\n",
      "\n",
      "episode 6, val func loss 1.5846540927886963\n",
      "\n",
      "episode 7, val func loss 1.646667718887329\n",
      "\n",
      "episode 8, val func loss 1.8292336463928223\n",
      "\n",
      "episode 9, val func loss 1.770796775817871\n",
      "\n",
      "episode 10, val func loss 1.412057876586914\n",
      "\n",
      "episode 11, val func loss 1.8241666555404663\n",
      "\n",
      "episode 12, val func loss 1.712424397468567\n",
      "\n",
      "episode 13, val func loss 1.578878402709961\n",
      "\n",
      "episode 14, val func loss 1.6624191999435425\n",
      "\n",
      "episode 15, val func loss 1.6235389709472656\n",
      "\n",
      "episode 16, val func loss 1.8017611503601074\n",
      "\n",
      "Val func train loss in epoch 3:1.6753476709127426\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.782301425933838\n",
      "\n",
      "episode 2, val func loss 1.6778982877731323\n",
      "\n",
      "episode 3, val func loss 1.692974328994751\n",
      "\n",
      "episode 4, val func loss 1.6838538646697998\n",
      "\n",
      "episode 5, val func loss 1.6443744897842407\n",
      "\n",
      "episode 6, val func loss 1.7171612977981567\n",
      "\n",
      "episode 7, val func loss 1.4917479753494263\n",
      "\n",
      "episode 8, val func loss 1.6962028741836548\n",
      "\n",
      "episode 9, val func loss 1.6077450513839722\n",
      "\n",
      "episode 10, val func loss 1.5838643312454224\n",
      "\n",
      "episode 11, val func loss 1.5383894443511963\n",
      "\n",
      "episode 12, val func loss 1.6770392656326294\n",
      "\n",
      "episode 13, val func loss 1.7880312204360962\n",
      "\n",
      "episode 14, val func loss 1.7731635570526123\n",
      "\n",
      "episode 15, val func loss 1.5727075338363647\n",
      "\n",
      "episode 16, val func loss 1.5080726146697998\n",
      "\n",
      "Val func train loss in epoch 4:1.6522204726934433\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.4440072774887085\n",
      "\n",
      "episode 2, val func loss 1.699752688407898\n",
      "\n",
      "episode 3, val func loss 1.5148564577102661\n",
      "\n",
      "episode 4, val func loss 1.6776411533355713\n",
      "\n",
      "episode 5, val func loss 1.5661014318466187\n",
      "\n",
      "episode 6, val func loss 1.4978939294815063\n",
      "\n",
      "episode 7, val func loss 1.3628569841384888\n",
      "\n",
      "episode 8, val func loss 1.62632155418396\n",
      "\n",
      "episode 9, val func loss 1.4998215436935425\n",
      "\n",
      "episode 10, val func loss 1.6917647123336792\n",
      "\n",
      "episode 11, val func loss 1.3843345642089844\n",
      "\n",
      "episode 12, val func loss 1.69007408618927\n",
      "\n",
      "episode 13, val func loss 1.5019721984863281\n",
      "\n",
      "episode 14, val func loss 1.574158787727356\n",
      "\n",
      "episode 15, val func loss 1.7355138063430786\n",
      "\n",
      "episode 16, val func loss 1.5922605991363525\n",
      "\n",
      "Val func train loss in epoch 5:1.5662082359194756\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.7156342267990112\n",
      "\n",
      "episode 2, val func loss 1.6588925123214722\n",
      "\n",
      "episode 3, val func loss 1.8794211149215698\n",
      "\n",
      "episode 4, val func loss 1.794966697692871\n",
      "\n",
      "episode 5, val func loss 1.6816612482070923\n",
      "\n",
      "episode 6, val func loss 1.5683742761611938\n",
      "\n",
      "episode 7, val func loss 1.499220848083496\n",
      "\n",
      "episode 8, val func loss 1.5103000402450562\n",
      "\n",
      "episode 9, val func loss 1.7651878595352173\n",
      "\n",
      "episode 10, val func loss 1.724708080291748\n",
      "\n",
      "episode 11, val func loss 1.856914758682251\n",
      "\n",
      "episode 12, val func loss 1.6381149291992188\n",
      "\n",
      "episode 13, val func loss 1.6617103815078735\n",
      "\n",
      "episode 14, val func loss 1.4288866519927979\n",
      "\n",
      "episode 15, val func loss 1.7439221143722534\n",
      "\n",
      "episode 16, val func loss 1.60746169090271\n",
      "\n",
      "Val func train loss in epoch 6:1.6709610894322395\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.5678558349609375\n",
      "\n",
      "episode 2, val func loss 1.5999568700790405\n",
      "\n",
      "episode 3, val func loss 1.4573185443878174\n",
      "\n",
      "episode 4, val func loss 1.7550573348999023\n",
      "\n",
      "episode 5, val func loss 1.7597112655639648\n",
      "\n",
      "episode 6, val func loss 1.4098875522613525\n",
      "\n",
      "episode 7, val func loss 1.3205993175506592\n",
      "\n",
      "episode 8, val func loss 1.6686731576919556\n",
      "\n",
      "episode 9, val func loss 1.5638998746871948\n",
      "\n",
      "episode 10, val func loss 1.49513840675354\n",
      "\n",
      "episode 11, val func loss 1.5632271766662598\n",
      "\n",
      "episode 12, val func loss 1.6575363874435425\n",
      "\n",
      "episode 13, val func loss 1.6988900899887085\n",
      "\n",
      "episode 14, val func loss 1.4849826097488403\n",
      "\n",
      "episode 15, val func loss 1.6334978342056274\n",
      "\n",
      "episode 16, val func loss 1.6400725841522217\n",
      "\n",
      "Val func train loss in epoch 7:1.5797690525650978\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.5558966398239136\n",
      "\n",
      "episode 2, val func loss 1.668190360069275\n",
      "\n",
      "episode 3, val func loss 1.70630943775177\n",
      "\n",
      "episode 4, val func loss 1.6332203149795532\n",
      "\n",
      "episode 5, val func loss 1.5709794759750366\n",
      "\n",
      "episode 6, val func loss 1.6683967113494873\n",
      "\n",
      "episode 7, val func loss 1.7907764911651611\n",
      "\n",
      "episode 8, val func loss 1.571171522140503\n",
      "\n",
      "episode 9, val func loss 1.7143502235412598\n",
      "\n",
      "episode 10, val func loss 1.8040108680725098\n",
      "\n",
      "episode 11, val func loss 1.5470668077468872\n",
      "\n",
      "episode 12, val func loss 1.6180850267410278\n",
      "\n",
      "episode 13, val func loss 1.6208195686340332\n",
      "\n",
      "episode 14, val func loss 1.6860073804855347\n",
      "\n",
      "episode 15, val func loss 1.7034988403320312\n",
      "\n",
      "episode 16, val func loss 1.68032968044281\n",
      "\n",
      "Val func train loss in epoch 8:1.6586943343281746\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.5816763639450073\n",
      "\n",
      "episode 2, val func loss 1.5908749103546143\n",
      "\n",
      "episode 3, val func loss 1.7252968549728394\n",
      "\n",
      "episode 4, val func loss 1.6878085136413574\n",
      "\n",
      "episode 5, val func loss 1.8129940032958984\n",
      "\n",
      "episode 6, val func loss 1.5190544128417969\n",
      "\n",
      "episode 7, val func loss 1.4908498525619507\n",
      "\n",
      "episode 8, val func loss 1.6571437120437622\n",
      "\n",
      "episode 9, val func loss 1.7974658012390137\n",
      "\n",
      "episode 10, val func loss 1.8474764823913574\n",
      "\n",
      "episode 11, val func loss 1.9103304147720337\n",
      "\n",
      "episode 12, val func loss 1.5549185276031494\n",
      "\n",
      "episode 13, val func loss 1.8951674699783325\n",
      "\n",
      "episode 14, val func loss 1.7129896879196167\n",
      "\n",
      "episode 15, val func loss 1.720960259437561\n",
      "\n",
      "episode 16, val func loss 1.537946343421936\n",
      "\n",
      "Val func train loss in epoch 9:1.6901846006512642\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.6698943376541138\n",
      "\n",
      "episode 2, val func loss 1.8148998022079468\n",
      "\n",
      "episode 3, val func loss 1.5199886560440063\n",
      "\n",
      "episode 4, val func loss 1.578635811805725\n",
      "\n",
      "episode 5, val func loss 1.6384841203689575\n",
      "\n",
      "episode 6, val func loss 1.3410297632217407\n",
      "\n",
      "episode 7, val func loss 1.4387675523757935\n",
      "\n",
      "episode 8, val func loss 1.5225355625152588\n",
      "\n",
      "episode 9, val func loss 1.8648871183395386\n",
      "\n",
      "episode 10, val func loss 1.817365050315857\n",
      "\n",
      "episode 11, val func loss 1.6501836776733398\n",
      "\n",
      "episode 12, val func loss 1.6532599925994873\n",
      "\n",
      "episode 13, val func loss 1.5923774242401123\n",
      "\n",
      "episode 14, val func loss 1.715410828590393\n",
      "\n",
      "episode 15, val func loss 1.6308075189590454\n",
      "\n",
      "episode 16, val func loss 1.9596985578536987\n",
      "\n",
      "Val func train loss in epoch 10:1.6505141109228134\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.51100754737854\n",
      "\n",
      "episode 2, val func loss 1.70047926902771\n",
      "\n",
      "episode 3, val func loss 1.740399956703186\n",
      "\n",
      "episode 4, val func loss 1.5415596961975098\n",
      "\n",
      "episode 5, val func loss 1.591654658317566\n",
      "\n",
      "episode 6, val func loss 1.4150729179382324\n",
      "\n",
      "episode 7, val func loss 1.6252713203430176\n",
      "\n",
      "episode 8, val func loss 1.5691386461257935\n",
      "\n",
      "episode 9, val func loss 2.0416970252990723\n",
      "\n",
      "episode 10, val func loss 1.7795156240463257\n",
      "\n",
      "episode 11, val func loss 1.6594085693359375\n",
      "\n",
      "episode 12, val func loss 1.7707884311676025\n",
      "\n",
      "episode 13, val func loss 1.5500301122665405\n",
      "\n",
      "episode 14, val func loss 1.6026338338851929\n",
      "\n",
      "episode 15, val func loss 1.6538547277450562\n",
      "\n",
      "episode 16, val func loss 1.7097582817077637\n",
      "\n",
      "Val func train loss in epoch 11:1.6538919135928154\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.7012560367584229\n",
      "\n",
      "episode 2, val func loss 1.8984063863754272\n",
      "\n",
      "episode 3, val func loss 1.7336539030075073\n",
      "\n",
      "episode 4, val func loss 1.43727445602417\n",
      "\n",
      "episode 5, val func loss 1.6586896181106567\n",
      "\n",
      "episode 6, val func loss 1.7903881072998047\n",
      "\n",
      "episode 7, val func loss 1.6985032558441162\n",
      "\n",
      "episode 8, val func loss 1.3716230392456055\n",
      "\n",
      "episode 9, val func loss 1.706331729888916\n",
      "\n",
      "episode 10, val func loss 1.6995348930358887\n",
      "\n",
      "episode 11, val func loss 1.634131908416748\n",
      "\n",
      "episode 12, val func loss 1.5775192975997925\n",
      "\n",
      "episode 13, val func loss 1.4467874765396118\n",
      "\n",
      "episode 14, val func loss 1.9242862462997437\n",
      "\n",
      "episode 15, val func loss 1.7875908613204956\n",
      "\n",
      "episode 16, val func loss 1.6169902086257935\n",
      "\n",
      "Val func train loss in epoch 12:1.6676854640245438\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.662350058555603\n",
      "\n",
      "episode 2, val func loss 1.8913731575012207\n",
      "\n",
      "episode 3, val func loss 1.5462998151779175\n",
      "\n",
      "episode 4, val func loss 1.6322859525680542\n",
      "\n",
      "episode 5, val func loss 1.761354923248291\n",
      "\n",
      "episode 6, val func loss 1.6055734157562256\n",
      "\n",
      "episode 7, val func loss 1.8332161903381348\n",
      "\n",
      "episode 8, val func loss 1.5277159214019775\n",
      "\n",
      "episode 9, val func loss 1.885711908340454\n",
      "\n",
      "episode 10, val func loss 2.00003719329834\n",
      "\n",
      "episode 11, val func loss 1.7353899478912354\n",
      "\n",
      "episode 12, val func loss 1.6593780517578125\n",
      "\n",
      "episode 13, val func loss 1.7043277025222778\n",
      "\n",
      "episode 14, val func loss 1.8291854858398438\n",
      "\n",
      "episode 15, val func loss 1.7609412670135498\n",
      "\n",
      "episode 16, val func loss 1.8123303651809692\n",
      "\n",
      "Val func train loss in epoch 13:1.7404669597744942\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.5832607746124268\n",
      "\n",
      "episode 2, val func loss 1.8980541229248047\n",
      "\n",
      "episode 3, val func loss 1.6731570959091187\n",
      "\n",
      "episode 4, val func loss 1.61180579662323\n",
      "\n",
      "episode 5, val func loss 1.8133611679077148\n",
      "\n",
      "episode 6, val func loss 1.5908275842666626\n",
      "\n",
      "episode 7, val func loss 2.0951356887817383\n",
      "\n",
      "episode 8, val func loss 1.5229326486587524\n",
      "\n",
      "episode 9, val func loss 1.773164987564087\n",
      "\n",
      "episode 10, val func loss 1.7967373132705688\n",
      "\n",
      "episode 11, val func loss 1.8623212575912476\n",
      "\n",
      "episode 12, val func loss 1.7447662353515625\n",
      "\n",
      "episode 13, val func loss 1.6565970182418823\n",
      "\n",
      "episode 14, val func loss 1.7898218631744385\n",
      "\n",
      "episode 15, val func loss 1.7507623434066772\n",
      "\n",
      "episode 16, val func loss 1.632469654083252\n",
      "\n",
      "Val func train loss in epoch 14:1.7371984720230103\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.7403439283370972\n",
      "\n",
      "episode 2, val func loss 1.7483850717544556\n",
      "\n",
      "episode 3, val func loss 1.8567016124725342\n",
      "\n",
      "episode 4, val func loss 1.5457665920257568\n",
      "\n",
      "episode 5, val func loss 1.5421582460403442\n",
      "\n",
      "episode 6, val func loss 1.6105701923370361\n",
      "\n",
      "episode 7, val func loss 1.591099500656128\n",
      "\n",
      "episode 8, val func loss 1.6613343954086304\n",
      "\n",
      "episode 9, val func loss 1.7828134298324585\n",
      "\n",
      "episode 10, val func loss 1.701377272605896\n",
      "\n",
      "episode 11, val func loss 1.5804005861282349\n",
      "\n",
      "episode 12, val func loss 1.5079060792922974\n",
      "\n",
      "episode 13, val func loss 1.6776334047317505\n",
      "\n",
      "episode 14, val func loss 1.667971134185791\n",
      "\n",
      "episode 15, val func loss 1.7892990112304688\n",
      "\n",
      "episode 16, val func loss 1.6618834733963013\n",
      "\n",
      "Val func train loss in epoch 15:1.6666027456521988\n",
      "***********************TIME WAS 5.103227877616883 min*****************************\n",
      "\n",
      "**********************ROUND 20 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.248382806777954\n",
      "\n",
      "episode 2, policy loss -2.248382806777954\n",
      "\n",
      "episode 3, policy loss -2.248382806777954\n",
      "\n",
      "episode 4, policy loss -2.248382568359375\n",
      "\n",
      "episode 5, policy loss -2.248382568359375\n",
      "\n",
      "episode 6, policy loss -2.248382568359375\n",
      "\n",
      "episode 7, policy loss -2.248382806777954\n",
      "\n",
      "episode 8, policy loss -2.248382806777954\n",
      "\n",
      "episode 9, policy loss -2.248382806777954\n",
      "\n",
      "episode 10, policy loss -2.248382806777954\n",
      "\n",
      "episode 11, policy loss -2.248382806777954\n",
      "\n",
      "episode 12, policy loss -2.248382806777954\n",
      "\n",
      "episode 13, policy loss -2.248382568359375\n",
      "\n",
      "episode 14, policy loss -2.248382806777954\n",
      "\n",
      "episode 15, policy loss -2.248382806777954\n",
      "\n",
      "episode 16, policy loss -2.248382806777954\n",
      "\n",
      "Policy train loss in epoch 0:-2.2483827471733093\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.248382806777954\n",
      "\n",
      "episode 2, policy loss -2.248382806777954\n",
      "\n",
      "episode 3, policy loss -2.248382806777954\n",
      "\n",
      "episode 4, policy loss -2.248382806777954\n",
      "\n",
      "episode 5, policy loss -2.248382806777954\n",
      "\n",
      "episode 6, policy loss -2.248382568359375\n",
      "\n",
      "episode 7, policy loss -2.248382806777954\n",
      "\n",
      "episode 8, policy loss -2.248382568359375\n",
      "\n",
      "episode 9, policy loss -2.248382806777954\n",
      "\n",
      "episode 10, policy loss -2.248382806777954\n",
      "\n",
      "episode 11, policy loss -2.248382806777954\n",
      "\n",
      "episode 12, policy loss -2.248382806777954\n",
      "\n",
      "episode 13, policy loss -2.248382806777954\n",
      "\n",
      "episode 14, policy loss -2.248382568359375\n",
      "\n",
      "episode 15, policy loss -2.248382806777954\n",
      "\n",
      "episode 16, policy loss -2.248382568359375\n",
      "\n",
      "Policy train loss in epoch 1:-2.2483827471733093\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.248382806777954\n",
      "\n",
      "episode 2, policy loss -2.248382806777954\n",
      "\n",
      "episode 3, policy loss -2.248382568359375\n",
      "\n",
      "episode 4, policy loss -2.248382568359375\n",
      "\n",
      "episode 5, policy loss -2.248382806777954\n",
      "\n",
      "episode 6, policy loss -2.248382806777954\n",
      "\n",
      "episode 7, policy loss -2.248382806777954\n",
      "\n",
      "episode 8, policy loss -2.248382806777954\n",
      "\n",
      "episode 9, policy loss -2.248382806777954\n",
      "\n",
      "episode 10, policy loss -2.248382568359375\n",
      "\n",
      "episode 11, policy loss -2.248382806777954\n",
      "\n",
      "episode 12, policy loss -2.248382806777954\n",
      "\n",
      "episode 13, policy loss -2.248382568359375\n",
      "\n",
      "episode 14, policy loss -2.248382806777954\n",
      "\n",
      "episode 15, policy loss -2.248382806777954\n",
      "\n",
      "episode 16, policy loss -2.248382806777954\n",
      "\n",
      "Policy train loss in epoch 2:-2.2483827471733093\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.248382568359375\n",
      "\n",
      "episode 2, policy loss -2.248382806777954\n",
      "\n",
      "episode 3, policy loss -2.248382568359375\n",
      "\n",
      "episode 4, policy loss -2.248382806777954\n",
      "\n",
      "episode 5, policy loss -2.248382806777954\n",
      "\n",
      "episode 6, policy loss -2.248382806777954\n",
      "\n",
      "episode 7, policy loss -2.248382568359375\n",
      "\n",
      "episode 8, policy loss -2.248382806777954\n",
      "\n",
      "episode 9, policy loss -2.248382806777954\n",
      "\n",
      "episode 10, policy loss -2.248382568359375\n",
      "\n",
      "episode 11, policy loss -2.248382806777954\n",
      "\n",
      "episode 12, policy loss -2.248382806777954\n",
      "\n",
      "episode 13, policy loss -2.248382806777954\n",
      "\n",
      "episode 14, policy loss -2.248382806777954\n",
      "\n",
      "episode 15, policy loss -2.248382806777954\n",
      "\n",
      "episode 16, policy loss -2.248382806777954\n",
      "\n",
      "Policy train loss in epoch 3:-2.2483827471733093\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.6144589185714722\n",
      "\n",
      "episode 2, val func loss 1.594110131263733\n",
      "\n",
      "episode 3, val func loss 1.8155786991119385\n",
      "\n",
      "episode 4, val func loss 1.8773459196090698\n",
      "\n",
      "episode 5, val func loss 1.8064380884170532\n",
      "\n",
      "episode 6, val func loss 1.8624122142791748\n",
      "\n",
      "episode 7, val func loss 1.9575530290603638\n",
      "\n",
      "episode 8, val func loss 1.8807392120361328\n",
      "\n",
      "episode 9, val func loss 1.7006244659423828\n",
      "\n",
      "episode 10, val func loss 1.7620309591293335\n",
      "\n",
      "episode 11, val func loss 1.7725286483764648\n",
      "\n",
      "episode 12, val func loss 1.7480857372283936\n",
      "\n",
      "episode 13, val func loss 1.6600899696350098\n",
      "\n",
      "episode 14, val func loss 1.8080021142959595\n",
      "\n",
      "episode 15, val func loss 1.7769219875335693\n",
      "\n",
      "episode 16, val func loss 1.5920758247375488\n",
      "\n",
      "Val func train loss in epoch 0:1.764312244951725\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.8462598323822021\n",
      "\n",
      "episode 2, val func loss 1.7535209655761719\n",
      "\n",
      "episode 3, val func loss 1.5226271152496338\n",
      "\n",
      "episode 4, val func loss 1.6796116828918457\n",
      "\n",
      "episode 5, val func loss 1.8020230531692505\n",
      "\n",
      "episode 6, val func loss 1.7205780744552612\n",
      "\n",
      "episode 7, val func loss 1.6862550973892212\n",
      "\n",
      "episode 8, val func loss 1.6100234985351562\n",
      "\n",
      "episode 9, val func loss 1.6132806539535522\n",
      "\n",
      "episode 10, val func loss 1.7248458862304688\n",
      "\n",
      "episode 11, val func loss 1.9460448026657104\n",
      "\n",
      "episode 12, val func loss 1.538403868675232\n",
      "\n",
      "episode 13, val func loss 1.6446181535720825\n",
      "\n",
      "episode 14, val func loss 1.5486698150634766\n",
      "\n",
      "episode 15, val func loss 1.5289396047592163\n",
      "\n",
      "episode 16, val func loss 1.755421757698059\n",
      "\n",
      "Val func train loss in epoch 1:1.6825702413916588\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.6917508840560913\n",
      "\n",
      "episode 2, val func loss 1.5564781427383423\n",
      "\n",
      "episode 3, val func loss 1.5870872735977173\n",
      "\n",
      "episode 4, val func loss 1.3339115381240845\n",
      "\n",
      "episode 5, val func loss 1.6379375457763672\n",
      "\n",
      "episode 6, val func loss 1.5830539464950562\n",
      "\n",
      "episode 7, val func loss 1.67056405544281\n",
      "\n",
      "episode 8, val func loss 1.3589149713516235\n",
      "\n",
      "episode 9, val func loss 1.6628979444503784\n",
      "\n",
      "episode 10, val func loss 1.6273651123046875\n",
      "\n",
      "episode 11, val func loss 1.6022785902023315\n",
      "\n",
      "episode 12, val func loss 1.7866016626358032\n",
      "\n",
      "episode 13, val func loss 1.7848798036575317\n",
      "\n",
      "episode 14, val func loss 1.4851980209350586\n",
      "\n",
      "episode 15, val func loss 1.611153483390808\n",
      "\n",
      "episode 16, val func loss 1.7431474924087524\n",
      "\n",
      "Val func train loss in epoch 2:1.6077012792229652\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.67631995677948\n",
      "\n",
      "episode 2, val func loss 1.7553117275238037\n",
      "\n",
      "episode 3, val func loss 1.681679129600525\n",
      "\n",
      "episode 4, val func loss 1.5797059535980225\n",
      "\n",
      "episode 5, val func loss 1.5043574571609497\n",
      "\n",
      "episode 6, val func loss 1.603613018989563\n",
      "\n",
      "episode 7, val func loss 1.7588497400283813\n",
      "\n",
      "episode 8, val func loss 1.9212865829467773\n",
      "\n",
      "episode 9, val func loss 1.7191842794418335\n",
      "\n",
      "episode 10, val func loss 1.8521701097488403\n",
      "\n",
      "episode 11, val func loss 1.4642964601516724\n",
      "\n",
      "episode 12, val func loss 1.7914462089538574\n",
      "\n",
      "episode 13, val func loss 1.7078254222869873\n",
      "\n",
      "episode 14, val func loss 1.5052201747894287\n",
      "\n",
      "episode 15, val func loss 1.6818181276321411\n",
      "\n",
      "episode 16, val func loss 1.9112399816513062\n",
      "\n",
      "Val func train loss in epoch 3:1.694645270705223\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.6946431398391724\n",
      "\n",
      "episode 2, val func loss 1.6822987794876099\n",
      "\n",
      "episode 3, val func loss 1.558330774307251\n",
      "\n",
      "episode 4, val func loss 1.7640838623046875\n",
      "\n",
      "episode 5, val func loss 1.8577468395233154\n",
      "\n",
      "episode 6, val func loss 1.7717288732528687\n",
      "\n",
      "episode 7, val func loss 1.6460552215576172\n",
      "\n",
      "episode 8, val func loss 1.774477481842041\n",
      "\n",
      "episode 9, val func loss 1.776839256286621\n",
      "\n",
      "episode 10, val func loss 1.8592944145202637\n",
      "\n",
      "episode 11, val func loss 1.6872828006744385\n",
      "\n",
      "episode 12, val func loss 1.9256031513214111\n",
      "\n",
      "episode 13, val func loss 1.8855669498443604\n",
      "\n",
      "episode 14, val func loss 1.7486339807510376\n",
      "\n",
      "episode 15, val func loss 1.7400697469711304\n",
      "\n",
      "episode 16, val func loss 1.716906189918518\n",
      "\n",
      "Val func train loss in epoch 4:1.7555975914001465\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.5819072723388672\n",
      "\n",
      "episode 2, val func loss 1.574655532836914\n",
      "\n",
      "episode 3, val func loss 1.501534342765808\n",
      "\n",
      "episode 4, val func loss 1.858025312423706\n",
      "\n",
      "episode 5, val func loss 1.57197105884552\n",
      "\n",
      "episode 6, val func loss 1.772544503211975\n",
      "\n",
      "episode 7, val func loss 1.596599817276001\n",
      "\n",
      "episode 8, val func loss 1.6280601024627686\n",
      "\n",
      "episode 9, val func loss 1.6298590898513794\n",
      "\n",
      "episode 10, val func loss 1.6942424774169922\n",
      "\n",
      "episode 11, val func loss 1.6675273180007935\n",
      "\n",
      "episode 12, val func loss 1.79884934425354\n",
      "\n",
      "episode 13, val func loss 1.4528497457504272\n",
      "\n",
      "episode 14, val func loss 1.5829461812973022\n",
      "\n",
      "episode 15, val func loss 1.6075620651245117\n",
      "\n",
      "episode 16, val func loss 1.6731524467468262\n",
      "\n",
      "Val func train loss in epoch 5:1.6370179131627083\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.4666990041732788\n",
      "\n",
      "episode 2, val func loss 1.6099376678466797\n",
      "\n",
      "episode 3, val func loss 1.6855477094650269\n",
      "\n",
      "episode 4, val func loss 2.019000291824341\n",
      "\n",
      "episode 5, val func loss 1.737536907196045\n",
      "\n",
      "episode 6, val func loss 1.7681329250335693\n",
      "\n",
      "episode 7, val func loss 1.6657147407531738\n",
      "\n",
      "episode 8, val func loss 1.757728934288025\n",
      "\n",
      "episode 9, val func loss 1.6867891550064087\n",
      "\n",
      "episode 10, val func loss 1.743808627128601\n",
      "\n",
      "episode 11, val func loss 1.5343329906463623\n",
      "\n",
      "episode 12, val func loss 2.022538661956787\n",
      "\n",
      "episode 13, val func loss 1.8993923664093018\n",
      "\n",
      "episode 14, val func loss 1.7535772323608398\n",
      "\n",
      "episode 15, val func loss 1.698617935180664\n",
      "\n",
      "episode 16, val func loss 1.6554875373840332\n",
      "\n",
      "Val func train loss in epoch 6:1.731552667915821\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.7629008293151855\n",
      "\n",
      "episode 2, val func loss 1.6000328063964844\n",
      "\n",
      "episode 3, val func loss 1.5219132900238037\n",
      "\n",
      "episode 4, val func loss 1.7407581806182861\n",
      "\n",
      "episode 5, val func loss 1.606232762336731\n",
      "\n",
      "episode 6, val func loss 1.6407995223999023\n",
      "\n",
      "episode 7, val func loss 1.6756588220596313\n",
      "\n",
      "episode 8, val func loss 1.5949981212615967\n",
      "\n",
      "episode 9, val func loss 1.6202160120010376\n",
      "\n",
      "episode 10, val func loss 1.57217538356781\n",
      "\n",
      "episode 11, val func loss 1.4546210765838623\n",
      "\n",
      "episode 12, val func loss 1.6283856630325317\n",
      "\n",
      "episode 13, val func loss 1.7477624416351318\n",
      "\n",
      "episode 14, val func loss 1.6822607517242432\n",
      "\n",
      "episode 15, val func loss 1.4695731401443481\n",
      "\n",
      "episode 16, val func loss 1.6328612565994263\n",
      "\n",
      "Val func train loss in epoch 7:1.6219468787312508\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.7562365531921387\n",
      "\n",
      "episode 2, val func loss 1.4710043668746948\n",
      "\n",
      "episode 3, val func loss 1.569332480430603\n",
      "\n",
      "episode 4, val func loss 1.7582005262374878\n",
      "\n",
      "episode 5, val func loss 1.7252368927001953\n",
      "\n",
      "episode 6, val func loss 1.745560884475708\n",
      "\n",
      "episode 7, val func loss 1.6682085990905762\n",
      "\n",
      "episode 8, val func loss 1.6443098783493042\n",
      "\n",
      "episode 9, val func loss 1.5613775253295898\n",
      "\n",
      "episode 10, val func loss 1.5433235168457031\n",
      "\n",
      "episode 11, val func loss 1.813072919845581\n",
      "\n",
      "episode 12, val func loss 1.6688112020492554\n",
      "\n",
      "episode 13, val func loss 1.5112261772155762\n",
      "\n",
      "episode 14, val func loss 1.3742406368255615\n",
      "\n",
      "episode 15, val func loss 1.53313410282135\n",
      "\n",
      "episode 16, val func loss 1.6278648376464844\n",
      "\n",
      "Val func train loss in epoch 8:1.623196318745613\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.7929505109786987\n",
      "\n",
      "episode 2, val func loss 1.7567274570465088\n",
      "\n",
      "episode 3, val func loss 1.5683398246765137\n",
      "\n",
      "episode 4, val func loss 1.4943466186523438\n",
      "\n",
      "episode 5, val func loss 1.6541874408721924\n",
      "\n",
      "episode 6, val func loss 1.6901367902755737\n",
      "\n",
      "episode 7, val func loss 1.6067873239517212\n",
      "\n",
      "episode 8, val func loss 1.633476972579956\n",
      "\n",
      "episode 9, val func loss 1.673624873161316\n",
      "\n",
      "episode 10, val func loss 1.5926567316055298\n",
      "\n",
      "episode 11, val func loss 1.422088861465454\n",
      "\n",
      "episode 12, val func loss 1.6293151378631592\n",
      "\n",
      "episode 13, val func loss 1.7151131629943848\n",
      "\n",
      "episode 14, val func loss 1.5481846332550049\n",
      "\n",
      "episode 15, val func loss 1.6843910217285156\n",
      "\n",
      "episode 16, val func loss 1.6822792291641235\n",
      "\n",
      "Val func train loss in epoch 9:1.6340379118919373\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.645642876625061\n",
      "\n",
      "episode 2, val func loss 1.7478840351104736\n",
      "\n",
      "episode 3, val func loss 1.6097630262374878\n",
      "\n",
      "episode 4, val func loss 1.5664620399475098\n",
      "\n",
      "episode 5, val func loss 1.5856393575668335\n",
      "\n",
      "episode 6, val func loss 1.603607416152954\n",
      "\n",
      "episode 7, val func loss 1.3544319868087769\n",
      "\n",
      "episode 8, val func loss 1.6784522533416748\n",
      "\n",
      "episode 9, val func loss 1.8265105485916138\n",
      "\n",
      "episode 10, val func loss 1.6211994886398315\n",
      "\n",
      "episode 11, val func loss 1.6300878524780273\n",
      "\n",
      "episode 12, val func loss 1.4400231838226318\n",
      "\n",
      "episode 13, val func loss 1.722941517829895\n",
      "\n",
      "episode 14, val func loss 1.707419991493225\n",
      "\n",
      "episode 15, val func loss 1.6378138065338135\n",
      "\n",
      "episode 16, val func loss 1.8174078464508057\n",
      "\n",
      "Val func train loss in epoch 10:1.6372054517269135\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.6927791833877563\n",
      "\n",
      "episode 2, val func loss 1.7149356603622437\n",
      "\n",
      "episode 3, val func loss 1.4906424283981323\n",
      "\n",
      "episode 4, val func loss 1.7269673347473145\n",
      "\n",
      "episode 5, val func loss 1.6215969324111938\n",
      "\n",
      "episode 6, val func loss 1.5929595232009888\n",
      "\n",
      "episode 7, val func loss 1.40941321849823\n",
      "\n",
      "episode 8, val func loss 1.6477690935134888\n",
      "\n",
      "episode 9, val func loss 1.7191517353057861\n",
      "\n",
      "episode 10, val func loss 1.6436210870742798\n",
      "\n",
      "episode 11, val func loss 1.6785905361175537\n",
      "\n",
      "episode 12, val func loss 1.6556028127670288\n",
      "\n",
      "episode 13, val func loss 1.7609742879867554\n",
      "\n",
      "episode 14, val func loss 1.630484938621521\n",
      "\n",
      "episode 15, val func loss 1.860364556312561\n",
      "\n",
      "episode 16, val func loss 1.5545989274978638\n",
      "\n",
      "Val func train loss in epoch 11:1.6500282660126686\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.673359751701355\n",
      "\n",
      "episode 2, val func loss 1.722799301147461\n",
      "\n",
      "episode 3, val func loss 1.7725571393966675\n",
      "\n",
      "episode 4, val func loss 1.6380901336669922\n",
      "\n",
      "episode 5, val func loss 1.718361735343933\n",
      "\n",
      "episode 6, val func loss 1.6121710538864136\n",
      "\n",
      "episode 7, val func loss 1.6943027973175049\n",
      "\n",
      "episode 8, val func loss 1.543580412864685\n",
      "\n",
      "episode 9, val func loss 1.9200595617294312\n",
      "\n",
      "episode 10, val func loss 1.5939503908157349\n",
      "\n",
      "episode 11, val func loss 1.6431434154510498\n",
      "\n",
      "episode 12, val func loss 1.5516173839569092\n",
      "\n",
      "episode 13, val func loss 1.8753949403762817\n",
      "\n",
      "episode 14, val func loss 1.833469271659851\n",
      "\n",
      "episode 15, val func loss 1.4128718376159668\n",
      "\n",
      "episode 16, val func loss 1.8184847831726074\n",
      "\n",
      "Val func train loss in epoch 12:1.6890133693814278\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.7548288106918335\n",
      "\n",
      "episode 2, val func loss 1.5183906555175781\n",
      "\n",
      "episode 3, val func loss 1.6993789672851562\n",
      "\n",
      "episode 4, val func loss 1.6303772926330566\n",
      "\n",
      "episode 5, val func loss 1.6826454401016235\n",
      "\n",
      "episode 6, val func loss 1.3080050945281982\n",
      "\n",
      "episode 7, val func loss 1.518769383430481\n",
      "\n",
      "episode 8, val func loss 1.733888030052185\n",
      "\n",
      "episode 9, val func loss 1.427224040031433\n",
      "\n",
      "episode 10, val func loss 1.7304389476776123\n",
      "\n",
      "episode 11, val func loss 1.577241063117981\n",
      "\n",
      "episode 12, val func loss 1.6267800331115723\n",
      "\n",
      "episode 13, val func loss 1.6563647985458374\n",
      "\n",
      "episode 14, val func loss 1.6257641315460205\n",
      "\n",
      "episode 15, val func loss 1.681800365447998\n",
      "\n",
      "episode 16, val func loss 1.6761572360992432\n",
      "\n",
      "Val func train loss in epoch 13:1.6155033931136131\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.6377253532409668\n",
      "\n",
      "episode 2, val func loss 1.5012476444244385\n",
      "\n",
      "episode 3, val func loss 1.5730348825454712\n",
      "\n",
      "episode 4, val func loss 1.51786470413208\n",
      "\n",
      "episode 5, val func loss 1.608253836631775\n",
      "\n",
      "episode 6, val func loss 1.7398595809936523\n",
      "\n",
      "episode 7, val func loss 1.62941312789917\n",
      "\n",
      "episode 8, val func loss 1.8269308805465698\n",
      "\n",
      "episode 9, val func loss 1.5297495126724243\n",
      "\n",
      "episode 10, val func loss 1.5709130764007568\n",
      "\n",
      "episode 11, val func loss 1.910886526107788\n",
      "\n",
      "episode 12, val func loss 1.7758996486663818\n",
      "\n",
      "episode 13, val func loss 1.7203558683395386\n",
      "\n",
      "episode 14, val func loss 1.7102558612823486\n",
      "\n",
      "episode 15, val func loss 1.6117547750473022\n",
      "\n",
      "episode 16, val func loss 1.6430259943008423\n",
      "\n",
      "Val func train loss in epoch 14:1.6566982045769691\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.6405112743377686\n",
      "\n",
      "episode 2, val func loss 1.5576337575912476\n",
      "\n",
      "episode 3, val func loss 1.6055744886398315\n",
      "\n",
      "episode 4, val func loss 1.6600980758666992\n",
      "\n",
      "episode 5, val func loss 1.88491690158844\n",
      "\n",
      "episode 6, val func loss 1.6576943397521973\n",
      "\n",
      "episode 7, val func loss 1.7253968715667725\n",
      "\n",
      "episode 8, val func loss 1.51610267162323\n",
      "\n",
      "episode 9, val func loss 1.6371148824691772\n",
      "\n",
      "episode 10, val func loss 1.4997286796569824\n",
      "\n",
      "episode 11, val func loss 1.5782525539398193\n",
      "\n",
      "episode 12, val func loss 1.4803411960601807\n",
      "\n",
      "episode 13, val func loss 1.7342404127120972\n",
      "\n",
      "episode 14, val func loss 1.5931357145309448\n",
      "\n",
      "episode 15, val func loss 1.5201982259750366\n",
      "\n",
      "episode 16, val func loss 1.614022970199585\n",
      "\n",
      "Val func train loss in epoch 15:1.6190601885318756\n",
      "***********************TIME WAS 5.111826046307882 min*****************************\n",
      "\n",
      "**********************ROUND 21 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.3372206687927246\n",
      "\n",
      "episode 2, policy loss -2.3372206687927246\n",
      "\n",
      "episode 3, policy loss -2.3372206687927246\n",
      "\n",
      "episode 4, policy loss -2.3372206687927246\n",
      "\n",
      "episode 5, policy loss -2.3372206687927246\n",
      "\n",
      "episode 6, policy loss -2.3372206687927246\n",
      "\n",
      "episode 7, policy loss -2.3372206687927246\n",
      "\n",
      "episode 8, policy loss -2.3372206687927246\n",
      "\n",
      "episode 9, policy loss -2.3372206687927246\n",
      "\n",
      "episode 10, policy loss -2.3372206687927246\n",
      "\n",
      "episode 11, policy loss -2.3372204303741455\n",
      "\n",
      "episode 12, policy loss -2.3372206687927246\n",
      "\n",
      "episode 13, policy loss -2.3372209072113037\n",
      "\n",
      "episode 14, policy loss -2.3372206687927246\n",
      "\n",
      "episode 15, policy loss -2.3372206687927246\n",
      "\n",
      "episode 16, policy loss -2.3372206687927246\n",
      "\n",
      "Policy train loss in epoch 0:-2.3372206687927246\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.3372209072113037\n",
      "\n",
      "episode 2, policy loss -2.3372206687927246\n",
      "\n",
      "episode 3, policy loss -2.3372206687927246\n",
      "\n",
      "episode 4, policy loss -2.3372206687927246\n",
      "\n",
      "episode 5, policy loss -2.3372206687927246\n",
      "\n",
      "episode 6, policy loss -2.3372206687927246\n",
      "\n",
      "episode 7, policy loss -2.3372206687927246\n",
      "\n",
      "episode 8, policy loss -2.3372206687927246\n",
      "\n",
      "episode 9, policy loss -2.3372206687927246\n",
      "\n",
      "episode 10, policy loss -2.3372206687927246\n",
      "\n",
      "episode 11, policy loss -2.3372206687927246\n",
      "\n",
      "episode 12, policy loss -2.3372206687927246\n",
      "\n",
      "episode 13, policy loss -2.3372206687927246\n",
      "\n",
      "episode 14, policy loss -2.3372206687927246\n",
      "\n",
      "episode 15, policy loss -2.3372206687927246\n",
      "\n",
      "episode 16, policy loss -2.3372204303741455\n",
      "\n",
      "Policy train loss in epoch 1:-2.3372206687927246\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.3372206687927246\n",
      "\n",
      "episode 2, policy loss -2.3372206687927246\n",
      "\n",
      "episode 3, policy loss -2.3372206687927246\n",
      "\n",
      "episode 4, policy loss -2.3372206687927246\n",
      "\n",
      "episode 5, policy loss -2.3372206687927246\n",
      "\n",
      "episode 6, policy loss -2.3372206687927246\n",
      "\n",
      "episode 7, policy loss -2.3372209072113037\n",
      "\n",
      "episode 8, policy loss -2.3372206687927246\n",
      "\n",
      "episode 9, policy loss -2.3372206687927246\n",
      "\n",
      "episode 10, policy loss -2.3372206687927246\n",
      "\n",
      "episode 11, policy loss -2.3372206687927246\n",
      "\n",
      "episode 12, policy loss -2.3372204303741455\n",
      "\n",
      "episode 13, policy loss -2.3372206687927246\n",
      "\n",
      "episode 14, policy loss -2.3372206687927246\n",
      "\n",
      "episode 15, policy loss -2.3372206687927246\n",
      "\n",
      "episode 16, policy loss -2.3372206687927246\n",
      "\n",
      "Policy train loss in epoch 2:-2.3372206687927246\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.3372206687927246\n",
      "\n",
      "episode 2, policy loss -2.3372206687927246\n",
      "\n",
      "episode 3, policy loss -2.3372206687927246\n",
      "\n",
      "episode 4, policy loss -2.3372209072113037\n",
      "\n",
      "episode 5, policy loss -2.3372206687927246\n",
      "\n",
      "episode 6, policy loss -2.3372206687927246\n",
      "\n",
      "episode 7, policy loss -2.3372204303741455\n",
      "\n",
      "episode 8, policy loss -2.3372206687927246\n",
      "\n",
      "episode 9, policy loss -2.3372206687927246\n",
      "\n",
      "episode 10, policy loss -2.3372206687927246\n",
      "\n",
      "episode 11, policy loss -2.3372206687927246\n",
      "\n",
      "episode 12, policy loss -2.3372206687927246\n",
      "\n",
      "episode 13, policy loss -2.3372206687927246\n",
      "\n",
      "episode 14, policy loss -2.3372206687927246\n",
      "\n",
      "episode 15, policy loss -2.3372206687927246\n",
      "\n",
      "episode 16, policy loss -2.3372206687927246\n",
      "\n",
      "Policy train loss in epoch 3:-2.3372206687927246\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.4507001638412476\n",
      "\n",
      "episode 2, val func loss 1.597220778465271\n",
      "\n",
      "episode 3, val func loss 1.6165871620178223\n",
      "\n",
      "episode 4, val func loss 1.7183862924575806\n",
      "\n",
      "episode 5, val func loss 1.6672353744506836\n",
      "\n",
      "episode 6, val func loss 1.5883785486221313\n",
      "\n",
      "episode 7, val func loss 1.7122822999954224\n",
      "\n",
      "episode 8, val func loss 1.6369355916976929\n",
      "\n",
      "episode 9, val func loss 1.6212844848632812\n",
      "\n",
      "episode 10, val func loss 1.6949639320373535\n",
      "\n",
      "episode 11, val func loss 1.9908649921417236\n",
      "\n",
      "episode 12, val func loss 1.6497365236282349\n",
      "\n",
      "episode 13, val func loss 1.6789299249649048\n",
      "\n",
      "episode 14, val func loss 1.5158147811889648\n",
      "\n",
      "episode 15, val func loss 1.5925554037094116\n",
      "\n",
      "episode 16, val func loss 1.6757359504699707\n",
      "\n",
      "Val func train loss in epoch 0:1.650475762784481\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.65292489528656\n",
      "\n",
      "episode 2, val func loss 1.7629872560501099\n",
      "\n",
      "episode 3, val func loss 1.7202470302581787\n",
      "\n",
      "episode 4, val func loss 1.5444008111953735\n",
      "\n",
      "episode 5, val func loss 1.7038214206695557\n",
      "\n",
      "episode 6, val func loss 1.719974398612976\n",
      "\n",
      "episode 7, val func loss 1.7426769733428955\n",
      "\n",
      "episode 8, val func loss 1.4994205236434937\n",
      "\n",
      "episode 9, val func loss 1.6891511678695679\n",
      "\n",
      "episode 10, val func loss 1.4361088275909424\n",
      "\n",
      "episode 11, val func loss 1.6995216608047485\n",
      "\n",
      "episode 12, val func loss 1.5238116979599\n",
      "\n",
      "episode 13, val func loss 1.6920169591903687\n",
      "\n",
      "episode 14, val func loss 1.5354171991348267\n",
      "\n",
      "episode 15, val func loss 1.5276343822479248\n",
      "\n",
      "episode 16, val func loss 1.6023449897766113\n",
      "\n",
      "Val func train loss in epoch 1:1.628278762102127\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.7743563652038574\n",
      "\n",
      "episode 2, val func loss 1.5988633632659912\n",
      "\n",
      "episode 3, val func loss 1.52328360080719\n",
      "\n",
      "episode 4, val func loss 1.5869351625442505\n",
      "\n",
      "episode 5, val func loss 1.6470214128494263\n",
      "\n",
      "episode 6, val func loss 1.6666622161865234\n",
      "\n",
      "episode 7, val func loss 1.5303997993469238\n",
      "\n",
      "episode 8, val func loss 1.5537270307540894\n",
      "\n",
      "episode 9, val func loss 1.5088351964950562\n",
      "\n",
      "episode 10, val func loss 1.5989259481430054\n",
      "\n",
      "episode 11, val func loss 1.6835196018218994\n",
      "\n",
      "episode 12, val func loss 1.7139531373977661\n",
      "\n",
      "episode 13, val func loss 1.5679230690002441\n",
      "\n",
      "episode 14, val func loss 1.7522451877593994\n",
      "\n",
      "episode 15, val func loss 1.5082601308822632\n",
      "\n",
      "episode 16, val func loss 1.7428960800170898\n",
      "\n",
      "Val func train loss in epoch 2:1.622362956404686\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.6146926879882812\n",
      "\n",
      "episode 2, val func loss 1.3625893592834473\n",
      "\n",
      "episode 3, val func loss 1.6198326349258423\n",
      "\n",
      "episode 4, val func loss 1.7516855001449585\n",
      "\n",
      "episode 5, val func loss 1.5662981271743774\n",
      "\n",
      "episode 6, val func loss 1.6120951175689697\n",
      "\n",
      "episode 7, val func loss 1.6699888706207275\n",
      "\n",
      "episode 8, val func loss 1.723568320274353\n",
      "\n",
      "episode 9, val func loss 1.451985239982605\n",
      "\n",
      "episode 10, val func loss 1.4589805603027344\n",
      "\n",
      "episode 11, val func loss 1.5772781372070312\n",
      "\n",
      "episode 12, val func loss 1.2720271348953247\n",
      "\n",
      "episode 13, val func loss 1.381733775138855\n",
      "\n",
      "episode 14, val func loss 1.5423749685287476\n",
      "\n",
      "episode 15, val func loss 1.7102352380752563\n",
      "\n",
      "episode 16, val func loss 1.6798553466796875\n",
      "\n",
      "Val func train loss in epoch 3:1.56220131367445\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.4039164781570435\n",
      "\n",
      "episode 2, val func loss 1.7402695417404175\n",
      "\n",
      "episode 3, val func loss 1.5015636682510376\n",
      "\n",
      "episode 4, val func loss 1.7723125219345093\n",
      "\n",
      "episode 5, val func loss 1.4665156602859497\n",
      "\n",
      "episode 6, val func loss 1.7940113544464111\n",
      "\n",
      "episode 7, val func loss 1.4566731452941895\n",
      "\n",
      "episode 8, val func loss 1.5692604780197144\n",
      "\n",
      "episode 9, val func loss 1.4967188835144043\n",
      "\n",
      "episode 10, val func loss 1.4877158403396606\n",
      "\n",
      "episode 11, val func loss 1.5662931203842163\n",
      "\n",
      "episode 12, val func loss 1.5682862997055054\n",
      "\n",
      "episode 13, val func loss 1.5383745431900024\n",
      "\n",
      "episode 14, val func loss 1.8732109069824219\n",
      "\n",
      "episode 15, val func loss 1.56831693649292\n",
      "\n",
      "episode 16, val func loss 1.702401876449585\n",
      "\n",
      "Val func train loss in epoch 4:1.5941150784492493\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.686699628829956\n",
      "\n",
      "episode 2, val func loss 1.8080776929855347\n",
      "\n",
      "episode 3, val func loss 1.6534494161605835\n",
      "\n",
      "episode 4, val func loss 1.6266111135482788\n",
      "\n",
      "episode 5, val func loss 1.5648133754730225\n",
      "\n",
      "episode 6, val func loss 1.5990766286849976\n",
      "\n",
      "episode 7, val func loss 1.5823252201080322\n",
      "\n",
      "episode 8, val func loss 1.5737578868865967\n",
      "\n",
      "episode 9, val func loss 1.5260344743728638\n",
      "\n",
      "episode 10, val func loss 1.6959909200668335\n",
      "\n",
      "episode 11, val func loss 1.8652901649475098\n",
      "\n",
      "episode 12, val func loss 1.8109807968139648\n",
      "\n",
      "episode 13, val func loss 1.7022290229797363\n",
      "\n",
      "episode 14, val func loss 1.7781786918640137\n",
      "\n",
      "episode 15, val func loss 2.027371883392334\n",
      "\n",
      "episode 16, val func loss 1.5511584281921387\n",
      "\n",
      "Val func train loss in epoch 5:1.6907528340816498\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.7063912153244019\n",
      "\n",
      "episode 2, val func loss 1.905832052230835\n",
      "\n",
      "episode 3, val func loss 2.052934169769287\n",
      "\n",
      "episode 4, val func loss 1.9007329940795898\n",
      "\n",
      "episode 5, val func loss 1.9749873876571655\n",
      "\n",
      "episode 6, val func loss 1.6845179796218872\n",
      "\n",
      "episode 7, val func loss 1.9407521486282349\n",
      "\n",
      "episode 8, val func loss 1.7974504232406616\n",
      "\n",
      "episode 9, val func loss 1.6041393280029297\n",
      "\n",
      "episode 10, val func loss 1.5007039308547974\n",
      "\n",
      "episode 11, val func loss 1.7509136199951172\n",
      "\n",
      "episode 12, val func loss 1.858020305633545\n",
      "\n",
      "episode 13, val func loss 1.6561468839645386\n",
      "\n",
      "episode 14, val func loss 1.63133704662323\n",
      "\n",
      "episode 15, val func loss 1.9040637016296387\n",
      "\n",
      "episode 16, val func loss 1.794719934463501\n",
      "\n",
      "Val func train loss in epoch 6:1.79147769510746\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.7802671194076538\n",
      "\n",
      "episode 2, val func loss 1.7588649988174438\n",
      "\n",
      "episode 3, val func loss 1.7746788263320923\n",
      "\n",
      "episode 4, val func loss 1.6190680265426636\n",
      "\n",
      "episode 5, val func loss 1.694465160369873\n",
      "\n",
      "episode 6, val func loss 1.4889988899230957\n",
      "\n",
      "episode 7, val func loss 1.7500380277633667\n",
      "\n",
      "episode 8, val func loss 1.532693862915039\n",
      "\n",
      "episode 9, val func loss 1.4733428955078125\n",
      "\n",
      "episode 10, val func loss 1.5269334316253662\n",
      "\n",
      "episode 11, val func loss 1.7471914291381836\n",
      "\n",
      "episode 12, val func loss 1.762245535850525\n",
      "\n",
      "episode 13, val func loss 1.5245381593704224\n",
      "\n",
      "episode 14, val func loss 1.5728846788406372\n",
      "\n",
      "episode 15, val func loss 1.5349844694137573\n",
      "\n",
      "episode 16, val func loss 1.5358461141586304\n",
      "\n",
      "Val func train loss in epoch 7:1.6298151016235352\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.5087645053863525\n",
      "\n",
      "episode 2, val func loss 1.518325686454773\n",
      "\n",
      "episode 3, val func loss 1.767834186553955\n",
      "\n",
      "episode 4, val func loss 1.7263728380203247\n",
      "\n",
      "episode 5, val func loss 1.7443935871124268\n",
      "\n",
      "episode 6, val func loss 1.3913068771362305\n",
      "\n",
      "episode 7, val func loss 1.7694048881530762\n",
      "\n",
      "episode 8, val func loss 1.5708681344985962\n",
      "\n",
      "episode 9, val func loss 1.677610993385315\n",
      "\n",
      "episode 10, val func loss 1.6805607080459595\n",
      "\n",
      "episode 11, val func loss 1.7410751581192017\n",
      "\n",
      "episode 12, val func loss 1.4427073001861572\n",
      "\n",
      "episode 13, val func loss 1.5286287069320679\n",
      "\n",
      "episode 14, val func loss 1.4721789360046387\n",
      "\n",
      "episode 15, val func loss 1.5724070072174072\n",
      "\n",
      "episode 16, val func loss 1.6504300832748413\n",
      "\n",
      "Val func train loss in epoch 8:1.6101793497800827\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.4782052040100098\n",
      "\n",
      "episode 2, val func loss 1.7918576002120972\n",
      "\n",
      "episode 3, val func loss 1.673506736755371\n",
      "\n",
      "episode 4, val func loss 1.860064148902893\n",
      "\n",
      "episode 5, val func loss 1.4572656154632568\n",
      "\n",
      "episode 6, val func loss 1.5526355504989624\n",
      "\n",
      "episode 7, val func loss 1.7294362783432007\n",
      "\n",
      "episode 8, val func loss 1.783844232559204\n",
      "\n",
      "episode 9, val func loss 1.829346776008606\n",
      "\n",
      "episode 10, val func loss 1.6156738996505737\n",
      "\n",
      "episode 11, val func loss 1.647666096687317\n",
      "\n",
      "episode 12, val func loss 1.8348667621612549\n",
      "\n",
      "episode 13, val func loss 1.5901429653167725\n",
      "\n",
      "episode 14, val func loss 1.651105523109436\n",
      "\n",
      "episode 15, val func loss 1.5936788320541382\n",
      "\n",
      "episode 16, val func loss 1.7073765993118286\n",
      "\n",
      "Val func train loss in epoch 9:1.6747920513153076\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.6163302659988403\n",
      "\n",
      "episode 2, val func loss 1.5891766548156738\n",
      "\n",
      "episode 3, val func loss 1.4996287822723389\n",
      "\n",
      "episode 4, val func loss 1.7275125980377197\n",
      "\n",
      "episode 5, val func loss 1.5268919467926025\n",
      "\n",
      "episode 6, val func loss 1.67714524269104\n",
      "\n",
      "episode 7, val func loss 1.5434530973434448\n",
      "\n",
      "episode 8, val func loss 1.6442335844039917\n",
      "\n",
      "episode 9, val func loss 1.5253853797912598\n",
      "\n",
      "episode 10, val func loss 1.7461482286453247\n",
      "\n",
      "episode 11, val func loss 1.5318052768707275\n",
      "\n",
      "episode 12, val func loss 1.522270917892456\n",
      "\n",
      "episode 13, val func loss 1.4743576049804688\n",
      "\n",
      "episode 14, val func loss 1.5763591527938843\n",
      "\n",
      "episode 15, val func loss 1.389377474784851\n",
      "\n",
      "episode 16, val func loss 1.7347750663757324\n",
      "\n",
      "Val func train loss in epoch 10:1.5828032046556473\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.6503654718399048\n",
      "\n",
      "episode 2, val func loss 1.8943849802017212\n",
      "\n",
      "episode 3, val func loss 1.5462255477905273\n",
      "\n",
      "episode 4, val func loss 1.7292699813842773\n",
      "\n",
      "episode 5, val func loss 1.4795314073562622\n",
      "\n",
      "episode 6, val func loss 1.5377306938171387\n",
      "\n",
      "episode 7, val func loss 1.602366328239441\n",
      "\n",
      "episode 8, val func loss 1.533669352531433\n",
      "\n",
      "episode 9, val func loss 1.3832813501358032\n",
      "\n",
      "episode 10, val func loss 1.3074907064437866\n",
      "\n",
      "episode 11, val func loss 1.7675457000732422\n",
      "\n",
      "episode 12, val func loss 1.5902447700500488\n",
      "\n",
      "episode 13, val func loss 1.5798527002334595\n",
      "\n",
      "episode 14, val func loss 1.9166202545166016\n",
      "\n",
      "episode 15, val func loss 1.6730400323867798\n",
      "\n",
      "episode 16, val func loss 1.87501060962677\n",
      "\n",
      "Val func train loss in epoch 11:1.6291643679141998\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.618714451789856\n",
      "\n",
      "episode 2, val func loss 1.7708837985992432\n",
      "\n",
      "episode 3, val func loss 1.6016873121261597\n",
      "\n",
      "episode 4, val func loss 1.61484694480896\n",
      "\n",
      "episode 5, val func loss 1.6481907367706299\n",
      "\n",
      "episode 6, val func loss 1.6597424745559692\n",
      "\n",
      "episode 7, val func loss 1.6334855556488037\n",
      "\n",
      "episode 8, val func loss 1.5637812614440918\n",
      "\n",
      "episode 9, val func loss 1.714102864265442\n",
      "\n",
      "episode 10, val func loss 1.3191343545913696\n",
      "\n",
      "episode 11, val func loss 1.6914315223693848\n",
      "\n",
      "episode 12, val func loss 1.8389900922775269\n",
      "\n",
      "episode 13, val func loss 1.5593159198760986\n",
      "\n",
      "episode 14, val func loss 1.6488604545593262\n",
      "\n",
      "episode 15, val func loss 1.6324462890625\n",
      "\n",
      "episode 16, val func loss 1.5864715576171875\n",
      "\n",
      "Val func train loss in epoch 12:1.6313803493976593\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.5889630317687988\n",
      "\n",
      "episode 2, val func loss 1.4303615093231201\n",
      "\n",
      "episode 3, val func loss 1.6203676462173462\n",
      "\n",
      "episode 4, val func loss 1.7088812589645386\n",
      "\n",
      "episode 5, val func loss 1.5562119483947754\n",
      "\n",
      "episode 6, val func loss 1.5292365550994873\n",
      "\n",
      "episode 7, val func loss 1.7024039030075073\n",
      "\n",
      "episode 8, val func loss 1.5387308597564697\n",
      "\n",
      "episode 9, val func loss 1.5376335382461548\n",
      "\n",
      "episode 10, val func loss 1.7424452304840088\n",
      "\n",
      "episode 11, val func loss 1.6463227272033691\n",
      "\n",
      "episode 12, val func loss 1.5317025184631348\n",
      "\n",
      "episode 13, val func loss 1.461221694946289\n",
      "\n",
      "episode 14, val func loss 1.4698150157928467\n",
      "\n",
      "episode 15, val func loss 1.7234505414962769\n",
      "\n",
      "episode 16, val func loss 1.7281277179718018\n",
      "\n",
      "Val func train loss in epoch 13:1.5947422310709953\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.396111249923706\n",
      "\n",
      "episode 2, val func loss 1.5102306604385376\n",
      "\n",
      "episode 3, val func loss 1.7658857107162476\n",
      "\n",
      "episode 4, val func loss 1.806774616241455\n",
      "\n",
      "episode 5, val func loss 1.6135212182998657\n",
      "\n",
      "episode 6, val func loss 1.5367611646652222\n",
      "\n",
      "episode 7, val func loss 1.7858983278274536\n",
      "\n",
      "episode 8, val func loss 1.7276110649108887\n",
      "\n",
      "episode 9, val func loss 1.6833795309066772\n",
      "\n",
      "episode 10, val func loss 1.715425968170166\n",
      "\n",
      "episode 11, val func loss 1.4281593561172485\n",
      "\n",
      "episode 12, val func loss 1.551726222038269\n",
      "\n",
      "episode 13, val func loss 1.5358080863952637\n",
      "\n",
      "episode 14, val func loss 1.6406663656234741\n",
      "\n",
      "episode 15, val func loss 1.6416412591934204\n",
      "\n",
      "episode 16, val func loss 1.6948314905166626\n",
      "\n",
      "Val func train loss in epoch 14:1.6271520182490349\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.765329360961914\n",
      "\n",
      "episode 2, val func loss 1.642979383468628\n",
      "\n",
      "episode 3, val func loss 1.5542458295822144\n",
      "\n",
      "episode 4, val func loss 1.7467221021652222\n",
      "\n",
      "episode 5, val func loss 1.9081346988677979\n",
      "\n",
      "episode 6, val func loss 1.7592029571533203\n",
      "\n",
      "episode 7, val func loss 1.582032322883606\n",
      "\n",
      "episode 8, val func loss 1.7556530237197876\n",
      "\n",
      "episode 9, val func loss 1.6787323951721191\n",
      "\n",
      "episode 10, val func loss 1.465972900390625\n",
      "\n",
      "episode 11, val func loss 1.8135526180267334\n",
      "\n",
      "episode 12, val func loss 1.4902665615081787\n",
      "\n",
      "episode 13, val func loss 1.9561930894851685\n",
      "\n",
      "episode 14, val func loss 1.5915378332138062\n",
      "\n",
      "episode 15, val func loss 1.721781611442566\n",
      "\n",
      "episode 16, val func loss 1.8340258598327637\n",
      "\n",
      "Val func train loss in epoch 15:1.7041476592421532\n",
      "***********************TIME WAS 4.931020585695903 min*****************************\n",
      "\n",
      "**********************ROUND 22 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.4353692531585693\n",
      "\n",
      "episode 2, policy loss -2.4353690147399902\n",
      "\n",
      "episode 3, policy loss -2.4353692531585693\n",
      "\n",
      "episode 4, policy loss -2.4353692531585693\n",
      "\n",
      "episode 5, policy loss -2.4353692531585693\n",
      "\n",
      "episode 6, policy loss -2.4353692531585693\n",
      "\n",
      "episode 7, policy loss -2.4353692531585693\n",
      "\n",
      "episode 8, policy loss -2.4353694915771484\n",
      "\n",
      "episode 9, policy loss -2.4353692531585693\n",
      "\n",
      "episode 10, policy loss -2.4353694915771484\n",
      "\n",
      "episode 11, policy loss -2.4353694915771484\n",
      "\n",
      "episode 12, policy loss -2.4353692531585693\n",
      "\n",
      "episode 13, policy loss -2.4353690147399902\n",
      "\n",
      "episode 14, policy loss -2.4353692531585693\n",
      "\n",
      "episode 15, policy loss -2.4353694915771484\n",
      "\n",
      "episode 16, policy loss -2.4353690147399902\n",
      "\n",
      "Policy train loss in epoch 0:-2.4353692680597305\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.4353694915771484\n",
      "\n",
      "episode 2, policy loss -2.4353692531585693\n",
      "\n",
      "episode 3, policy loss -2.4353692531585693\n",
      "\n",
      "episode 4, policy loss -2.4353692531585693\n",
      "\n",
      "episode 5, policy loss -2.4353692531585693\n",
      "\n",
      "episode 6, policy loss -2.4353694915771484\n",
      "\n",
      "episode 7, policy loss -2.4353690147399902\n",
      "\n",
      "episode 8, policy loss -2.4353694915771484\n",
      "\n",
      "episode 9, policy loss -2.4353692531585693\n",
      "\n",
      "episode 10, policy loss -2.4353692531585693\n",
      "\n",
      "episode 11, policy loss -2.4353692531585693\n",
      "\n",
      "episode 12, policy loss -2.4353690147399902\n",
      "\n",
      "episode 13, policy loss -2.4353694915771484\n",
      "\n",
      "episode 14, policy loss -2.4353690147399902\n",
      "\n",
      "episode 15, policy loss -2.4353692531585693\n",
      "\n",
      "episode 16, policy loss -2.4353692531585693\n",
      "\n",
      "Policy train loss in epoch 1:-2.4353692680597305\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.4353694915771484\n",
      "\n",
      "episode 2, policy loss -2.4353690147399902\n",
      "\n",
      "episode 3, policy loss -2.4353692531585693\n",
      "\n",
      "episode 4, policy loss -2.4353694915771484\n",
      "\n",
      "episode 5, policy loss -2.4353692531585693\n",
      "\n",
      "episode 6, policy loss -2.4353694915771484\n",
      "\n",
      "episode 7, policy loss -2.4353692531585693\n",
      "\n",
      "episode 8, policy loss -2.4353692531585693\n",
      "\n",
      "episode 9, policy loss -2.4353694915771484\n",
      "\n",
      "episode 10, policy loss -2.4353692531585693\n",
      "\n",
      "episode 11, policy loss -2.4353692531585693\n",
      "\n",
      "episode 12, policy loss -2.4353690147399902\n",
      "\n",
      "episode 13, policy loss -2.4353692531585693\n",
      "\n",
      "episode 14, policy loss -2.4353690147399902\n",
      "\n",
      "episode 15, policy loss -2.4353692531585693\n",
      "\n",
      "episode 16, policy loss -2.4353692531585693\n",
      "\n",
      "Policy train loss in epoch 2:-2.4353692680597305\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.4353690147399902\n",
      "\n",
      "episode 2, policy loss -2.4353692531585693\n",
      "\n",
      "episode 3, policy loss -2.4353694915771484\n",
      "\n",
      "episode 4, policy loss -2.4353692531585693\n",
      "\n",
      "episode 5, policy loss -2.4353692531585693\n",
      "\n",
      "episode 6, policy loss -2.4353692531585693\n",
      "\n",
      "episode 7, policy loss -2.4353692531585693\n",
      "\n",
      "episode 8, policy loss -2.4353694915771484\n",
      "\n",
      "episode 9, policy loss -2.4353694915771484\n",
      "\n",
      "episode 10, policy loss -2.4353694915771484\n",
      "\n",
      "episode 11, policy loss -2.4353690147399902\n",
      "\n",
      "episode 12, policy loss -2.4353692531585693\n",
      "\n",
      "episode 13, policy loss -2.4353692531585693\n",
      "\n",
      "episode 14, policy loss -2.4353692531585693\n",
      "\n",
      "episode 15, policy loss -2.4353690147399902\n",
      "\n",
      "episode 16, policy loss -2.4353692531585693\n",
      "\n",
      "Policy train loss in epoch 3:-2.4353692680597305\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.9294911623001099\n",
      "\n",
      "episode 2, val func loss 1.8091387748718262\n",
      "\n",
      "episode 3, val func loss 1.4972326755523682\n",
      "\n",
      "episode 4, val func loss 1.8134922981262207\n",
      "\n",
      "episode 5, val func loss 1.551831841468811\n",
      "\n",
      "episode 6, val func loss 1.65603768825531\n",
      "\n",
      "episode 7, val func loss 1.673979640007019\n",
      "\n",
      "episode 8, val func loss 1.5405755043029785\n",
      "\n",
      "episode 9, val func loss 1.5801342725753784\n",
      "\n",
      "episode 10, val func loss 1.4632164239883423\n",
      "\n",
      "episode 11, val func loss 1.7981317043304443\n",
      "\n",
      "episode 12, val func loss 1.747727632522583\n",
      "\n",
      "episode 13, val func loss 1.6949154138565063\n",
      "\n",
      "episode 14, val func loss 1.7265357971191406\n",
      "\n",
      "episode 15, val func loss 1.7301406860351562\n",
      "\n",
      "episode 16, val func loss 1.7106151580810547\n",
      "\n",
      "Val func train loss in epoch 0:1.682699792087078\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.7000573873519897\n",
      "\n",
      "episode 2, val func loss 1.7400972843170166\n",
      "\n",
      "episode 3, val func loss 1.6218321323394775\n",
      "\n",
      "episode 4, val func loss 1.6460853815078735\n",
      "\n",
      "episode 5, val func loss 1.5853102207183838\n",
      "\n",
      "episode 6, val func loss 1.7340970039367676\n",
      "\n",
      "episode 7, val func loss 1.56240975856781\n",
      "\n",
      "episode 8, val func loss 1.4656248092651367\n",
      "\n",
      "episode 9, val func loss 1.4314943552017212\n",
      "\n",
      "episode 10, val func loss 1.7026938199996948\n",
      "\n",
      "episode 11, val func loss 1.638757348060608\n",
      "\n",
      "episode 12, val func loss 1.6167017221450806\n",
      "\n",
      "episode 13, val func loss 1.7980175018310547\n",
      "\n",
      "episode 14, val func loss 1.7449146509170532\n",
      "\n",
      "episode 15, val func loss 1.5811651945114136\n",
      "\n",
      "episode 16, val func loss 1.4242421388626099\n",
      "\n",
      "Val func train loss in epoch 1:1.6245937943458557\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.751394271850586\n",
      "\n",
      "episode 2, val func loss 1.639780044555664\n",
      "\n",
      "episode 3, val func loss 1.493349552154541\n",
      "\n",
      "episode 4, val func loss 1.7190488576889038\n",
      "\n",
      "episode 5, val func loss 1.4589015245437622\n",
      "\n",
      "episode 6, val func loss 1.5456792116165161\n",
      "\n",
      "episode 7, val func loss 1.5994584560394287\n",
      "\n",
      "episode 8, val func loss 1.5763070583343506\n",
      "\n",
      "episode 9, val func loss 1.843191146850586\n",
      "\n",
      "episode 10, val func loss 1.876241683959961\n",
      "\n",
      "episode 11, val func loss 1.629506230354309\n",
      "\n",
      "episode 12, val func loss 1.7967168092727661\n",
      "\n",
      "episode 13, val func loss 1.7668952941894531\n",
      "\n",
      "episode 14, val func loss 1.7539547681808472\n",
      "\n",
      "episode 15, val func loss 1.6274198293685913\n",
      "\n",
      "episode 16, val func loss 1.7996176481246948\n",
      "\n",
      "Val func train loss in epoch 2:1.67984139919281\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.8343366384506226\n",
      "\n",
      "episode 2, val func loss 1.6153414249420166\n",
      "\n",
      "episode 3, val func loss 1.5019724369049072\n",
      "\n",
      "episode 4, val func loss 1.6294511556625366\n",
      "\n",
      "episode 5, val func loss 1.5783897638320923\n",
      "\n",
      "episode 6, val func loss 1.5703843832015991\n",
      "\n",
      "episode 7, val func loss 1.5330957174301147\n",
      "\n",
      "episode 8, val func loss 1.691213607788086\n",
      "\n",
      "episode 9, val func loss 1.605774164199829\n",
      "\n",
      "episode 10, val func loss 1.5460095405578613\n",
      "\n",
      "episode 11, val func loss 1.527119755744934\n",
      "\n",
      "episode 12, val func loss 1.5529062747955322\n",
      "\n",
      "episode 13, val func loss 1.840893268585205\n",
      "\n",
      "episode 14, val func loss 1.4876275062561035\n",
      "\n",
      "episode 15, val func loss 1.8378276824951172\n",
      "\n",
      "episode 16, val func loss 1.669166922569275\n",
      "\n",
      "Val func train loss in epoch 3:1.6263443902134895\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.6727162599563599\n",
      "\n",
      "episode 2, val func loss 1.7187906503677368\n",
      "\n",
      "episode 3, val func loss 1.7288872003555298\n",
      "\n",
      "episode 4, val func loss 1.74539315700531\n",
      "\n",
      "episode 5, val func loss 1.4855015277862549\n",
      "\n",
      "episode 6, val func loss 1.5547739267349243\n",
      "\n",
      "episode 7, val func loss 1.6256283521652222\n",
      "\n",
      "episode 8, val func loss 1.7371491193771362\n",
      "\n",
      "episode 9, val func loss 1.6553318500518799\n",
      "\n",
      "episode 10, val func loss 1.726960301399231\n",
      "\n",
      "episode 11, val func loss 1.7425734996795654\n",
      "\n",
      "episode 12, val func loss 1.574454665184021\n",
      "\n",
      "episode 13, val func loss 1.5998826026916504\n",
      "\n",
      "episode 14, val func loss 1.6336557865142822\n",
      "\n",
      "episode 15, val func loss 1.5198500156402588\n",
      "\n",
      "episode 16, val func loss 1.4527549743652344\n",
      "\n",
      "Val func train loss in epoch 4:1.6358939930796623\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.6964670419692993\n",
      "\n",
      "episode 2, val func loss 1.3763056993484497\n",
      "\n",
      "episode 3, val func loss 1.5952918529510498\n",
      "\n",
      "episode 4, val func loss 1.8328310251235962\n",
      "\n",
      "episode 5, val func loss 1.573163628578186\n",
      "\n",
      "episode 6, val func loss 1.647829532623291\n",
      "\n",
      "episode 7, val func loss 1.5440545082092285\n",
      "\n",
      "episode 8, val func loss 1.5045433044433594\n",
      "\n",
      "episode 9, val func loss 1.5080502033233643\n",
      "\n",
      "episode 10, val func loss 1.4639010429382324\n",
      "\n",
      "episode 11, val func loss 1.7309000492095947\n",
      "\n",
      "episode 12, val func loss 1.7113027572631836\n",
      "\n",
      "episode 13, val func loss 1.3549668788909912\n",
      "\n",
      "episode 14, val func loss 1.5639615058898926\n",
      "\n",
      "episode 15, val func loss 1.5638214349746704\n",
      "\n",
      "episode 16, val func loss 1.6553361415863037\n",
      "\n",
      "Val func train loss in epoch 5:1.5826704129576683\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.6949492692947388\n",
      "\n",
      "episode 2, val func loss 1.8501615524291992\n",
      "\n",
      "episode 3, val func loss 1.6723361015319824\n",
      "\n",
      "episode 4, val func loss 1.8073582649230957\n",
      "\n",
      "episode 5, val func loss 1.651715874671936\n",
      "\n",
      "episode 6, val func loss 1.5601283311843872\n",
      "\n",
      "episode 7, val func loss 1.5232700109481812\n",
      "\n",
      "episode 8, val func loss 1.6342971324920654\n",
      "\n",
      "episode 9, val func loss 1.606752634048462\n",
      "\n",
      "episode 10, val func loss 1.6348419189453125\n",
      "\n",
      "episode 11, val func loss 1.7610691785812378\n",
      "\n",
      "episode 12, val func loss 1.6238195896148682\n",
      "\n",
      "episode 13, val func loss 1.652611255645752\n",
      "\n",
      "episode 14, val func loss 1.698843002319336\n",
      "\n",
      "episode 15, val func loss 1.6081875562667847\n",
      "\n",
      "episode 16, val func loss 1.6365864276885986\n",
      "\n",
      "Val func train loss in epoch 6:1.663558006286621\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.5623321533203125\n",
      "\n",
      "episode 2, val func loss 1.5048738718032837\n",
      "\n",
      "episode 3, val func loss 1.7309216260910034\n",
      "\n",
      "episode 4, val func loss 1.4937019348144531\n",
      "\n",
      "episode 5, val func loss 1.4057060480117798\n",
      "\n",
      "episode 6, val func loss 1.4853299856185913\n",
      "\n",
      "episode 7, val func loss 1.7462915182113647\n",
      "\n",
      "episode 8, val func loss 1.4416919946670532\n",
      "\n",
      "episode 9, val func loss 1.4845283031463623\n",
      "\n",
      "episode 10, val func loss 1.6757670640945435\n",
      "\n",
      "episode 11, val func loss 1.8477554321289062\n",
      "\n",
      "episode 12, val func loss 1.8322727680206299\n",
      "\n",
      "episode 13, val func loss 1.67704439163208\n",
      "\n",
      "episode 14, val func loss 1.7017329931259155\n",
      "\n",
      "episode 15, val func loss 1.6670044660568237\n",
      "\n",
      "episode 16, val func loss 1.6460362672805786\n",
      "\n",
      "Val func train loss in epoch 7:1.61893692612648\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.6289138793945312\n",
      "\n",
      "episode 2, val func loss 1.5360496044158936\n",
      "\n",
      "episode 3, val func loss 1.69065523147583\n",
      "\n",
      "episode 4, val func loss 1.6228399276733398\n",
      "\n",
      "episode 5, val func loss 1.6238818168640137\n",
      "\n",
      "episode 6, val func loss 1.9083225727081299\n",
      "\n",
      "episode 7, val func loss 1.7812472581863403\n",
      "\n",
      "episode 8, val func loss 1.946914553642273\n",
      "\n",
      "episode 9, val func loss 1.6148239374160767\n",
      "\n",
      "episode 10, val func loss 1.503005862236023\n",
      "\n",
      "episode 11, val func loss 1.788048267364502\n",
      "\n",
      "episode 12, val func loss 1.6371339559555054\n",
      "\n",
      "episode 13, val func loss 1.5861833095550537\n",
      "\n",
      "episode 14, val func loss 1.7167733907699585\n",
      "\n",
      "episode 15, val func loss 1.5859873294830322\n",
      "\n",
      "episode 16, val func loss 1.5768260955810547\n",
      "\n",
      "Val func train loss in epoch 8:1.6717254370450974\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.5583232641220093\n",
      "\n",
      "episode 2, val func loss 1.5699669122695923\n",
      "\n",
      "episode 3, val func loss 1.5238336324691772\n",
      "\n",
      "episode 4, val func loss 1.6931885480880737\n",
      "\n",
      "episode 5, val func loss 1.7433804273605347\n",
      "\n",
      "episode 6, val func loss 1.7167763710021973\n",
      "\n",
      "episode 7, val func loss 1.6985679864883423\n",
      "\n",
      "episode 8, val func loss 1.5770195722579956\n",
      "\n",
      "episode 9, val func loss 1.8545900583267212\n",
      "\n",
      "episode 10, val func loss 1.7693594694137573\n",
      "\n",
      "episode 11, val func loss 1.4505122900009155\n",
      "\n",
      "episode 12, val func loss 1.8522312641143799\n",
      "\n",
      "episode 13, val func loss 1.8548498153686523\n",
      "\n",
      "episode 14, val func loss 1.4691208600997925\n",
      "\n",
      "episode 15, val func loss 1.5392701625823975\n",
      "\n",
      "episode 16, val func loss 1.6993474960327148\n",
      "\n",
      "Val func train loss in epoch 9:1.6606461331248283\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.6802986860275269\n",
      "\n",
      "episode 2, val func loss 1.6181026697158813\n",
      "\n",
      "episode 3, val func loss 1.8819552659988403\n",
      "\n",
      "episode 4, val func loss 1.5198358297348022\n",
      "\n",
      "episode 5, val func loss 1.7687312364578247\n",
      "\n",
      "episode 6, val func loss 1.9169690608978271\n",
      "\n",
      "episode 7, val func loss 1.657307505607605\n",
      "\n",
      "episode 8, val func loss 1.7315418720245361\n",
      "\n",
      "episode 9, val func loss 1.6524008512496948\n",
      "\n",
      "episode 10, val func loss 1.720243215560913\n",
      "\n",
      "episode 11, val func loss 1.7152726650238037\n",
      "\n",
      "episode 12, val func loss 1.524411916732788\n",
      "\n",
      "episode 13, val func loss 1.660632610321045\n",
      "\n",
      "episode 14, val func loss 1.695487380027771\n",
      "\n",
      "episode 15, val func loss 1.830038070678711\n",
      "\n",
      "episode 16, val func loss 1.6546276807785034\n",
      "\n",
      "Val func train loss in epoch 10:1.7017410323023796\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.4718221426010132\n",
      "\n",
      "episode 2, val func loss 1.545155644416809\n",
      "\n",
      "episode 3, val func loss 1.8162928819656372\n",
      "\n",
      "episode 4, val func loss 1.69246244430542\n",
      "\n",
      "episode 5, val func loss 1.6926754713058472\n",
      "\n",
      "episode 6, val func loss 1.5572564601898193\n",
      "\n",
      "episode 7, val func loss 1.6755726337432861\n",
      "\n",
      "episode 8, val func loss 1.77285897731781\n",
      "\n",
      "episode 9, val func loss 1.5762128829956055\n",
      "\n",
      "episode 10, val func loss 1.6884609460830688\n",
      "\n",
      "episode 11, val func loss 1.6171518564224243\n",
      "\n",
      "episode 12, val func loss 1.7300523519515991\n",
      "\n",
      "episode 13, val func loss 1.6653589010238647\n",
      "\n",
      "episode 14, val func loss 1.7879565954208374\n",
      "\n",
      "episode 15, val func loss 1.5115636587142944\n",
      "\n",
      "episode 16, val func loss 1.7784603834152222\n",
      "\n",
      "Val func train loss in epoch 11:1.661207139492035\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.6500400304794312\n",
      "\n",
      "episode 2, val func loss 1.77903151512146\n",
      "\n",
      "episode 3, val func loss 1.6858346462249756\n",
      "\n",
      "episode 4, val func loss 1.6618613004684448\n",
      "\n",
      "episode 5, val func loss 1.8837233781814575\n",
      "\n",
      "episode 6, val func loss 1.491008996963501\n",
      "\n",
      "episode 7, val func loss 1.7710481882095337\n",
      "\n",
      "episode 8, val func loss 1.713494896888733\n",
      "\n",
      "episode 9, val func loss 1.8404494524002075\n",
      "\n",
      "episode 10, val func loss 1.79538893699646\n",
      "\n",
      "episode 11, val func loss 1.604237675666809\n",
      "\n",
      "episode 12, val func loss 1.641662836074829\n",
      "\n",
      "episode 13, val func loss 1.6475495100021362\n",
      "\n",
      "episode 14, val func loss 1.7300949096679688\n",
      "\n",
      "episode 15, val func loss 1.9265940189361572\n",
      "\n",
      "episode 16, val func loss 1.6900802850723267\n",
      "\n",
      "Val func train loss in epoch 12:1.719506286084652\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.6672946214675903\n",
      "\n",
      "episode 2, val func loss 1.516042709350586\n",
      "\n",
      "episode 3, val func loss 1.6170631647109985\n",
      "\n",
      "episode 4, val func loss 1.7310117483139038\n",
      "\n",
      "episode 5, val func loss 1.6693390607833862\n",
      "\n",
      "episode 6, val func loss 1.5993549823760986\n",
      "\n",
      "episode 7, val func loss 1.7232835292816162\n",
      "\n",
      "episode 8, val func loss 1.749361515045166\n",
      "\n",
      "episode 9, val func loss 1.8100619316101074\n",
      "\n",
      "episode 10, val func loss 1.4846580028533936\n",
      "\n",
      "episode 11, val func loss 1.766477346420288\n",
      "\n",
      "episode 12, val func loss 1.6603434085845947\n",
      "\n",
      "episode 13, val func loss 1.5899914503097534\n",
      "\n",
      "episode 14, val func loss 1.5314085483551025\n",
      "\n",
      "episode 15, val func loss 1.5446512699127197\n",
      "\n",
      "episode 16, val func loss 1.7431491613388062\n",
      "\n",
      "Val func train loss in epoch 13:1.650218278169632\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.888146996498108\n",
      "\n",
      "episode 2, val func loss 1.5316334962844849\n",
      "\n",
      "episode 3, val func loss 1.4782482385635376\n",
      "\n",
      "episode 4, val func loss 1.7047958374023438\n",
      "\n",
      "episode 5, val func loss 1.6890015602111816\n",
      "\n",
      "episode 6, val func loss 1.873740553855896\n",
      "\n",
      "episode 7, val func loss 1.597413420677185\n",
      "\n",
      "episode 8, val func loss 1.5738118886947632\n",
      "\n",
      "episode 9, val func loss 1.8393999338150024\n",
      "\n",
      "episode 10, val func loss 1.6580877304077148\n",
      "\n",
      "episode 11, val func loss 1.6866365671157837\n",
      "\n",
      "episode 12, val func loss 1.5862226486206055\n",
      "\n",
      "episode 13, val func loss 1.4777120351791382\n",
      "\n",
      "episode 14, val func loss 1.6507774591445923\n",
      "\n",
      "episode 15, val func loss 1.528191089630127\n",
      "\n",
      "episode 16, val func loss 1.7308396100997925\n",
      "\n",
      "Val func train loss in epoch 14:1.655916191637516\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.985391616821289\n",
      "\n",
      "episode 2, val func loss 1.6969422101974487\n",
      "\n",
      "episode 3, val func loss 1.601399540901184\n",
      "\n",
      "episode 4, val func loss 1.7269443273544312\n",
      "\n",
      "episode 5, val func loss 1.5169140100479126\n",
      "\n",
      "episode 6, val func loss 1.6619129180908203\n",
      "\n",
      "episode 7, val func loss 1.757699728012085\n",
      "\n",
      "episode 8, val func loss 1.6412030458450317\n",
      "\n",
      "episode 9, val func loss 1.9056552648544312\n",
      "\n",
      "episode 10, val func loss 1.7329397201538086\n",
      "\n",
      "episode 11, val func loss 1.6030330657958984\n",
      "\n",
      "episode 12, val func loss 1.800290822982788\n",
      "\n",
      "episode 13, val func loss 1.688205599784851\n",
      "\n",
      "episode 14, val func loss 1.5961098670959473\n",
      "\n",
      "episode 15, val func loss 1.6532129049301147\n",
      "\n",
      "episode 16, val func loss 1.7028974294662476\n",
      "\n",
      "Val func train loss in epoch 15:1.704422004520893\n",
      "***********************TIME WAS 4.804237413406372 min*****************************\n",
      "\n",
      "**********************ROUND 23 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.1648693084716797\n",
      "\n",
      "episode 2, policy loss -2.1648693084716797\n",
      "\n",
      "episode 3, policy loss -2.164869546890259\n",
      "\n",
      "episode 4, policy loss -2.1648693084716797\n",
      "\n",
      "episode 5, policy loss -2.1648693084716797\n",
      "\n",
      "episode 6, policy loss -2.164869546890259\n",
      "\n",
      "episode 7, policy loss -2.1648693084716797\n",
      "\n",
      "episode 8, policy loss -2.1648693084716797\n",
      "\n",
      "episode 9, policy loss -2.1648693084716797\n",
      "\n",
      "episode 10, policy loss -2.1648693084716797\n",
      "\n",
      "episode 11, policy loss -2.164869546890259\n",
      "\n",
      "episode 12, policy loss -2.1648693084716797\n",
      "\n",
      "episode 13, policy loss -2.164869546890259\n",
      "\n",
      "episode 14, policy loss -2.1648693084716797\n",
      "\n",
      "episode 15, policy loss -2.1648693084716797\n",
      "\n",
      "episode 16, policy loss -2.1648693084716797\n",
      "\n",
      "Policy train loss in epoch 0:-2.1648693680763245\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.164869546890259\n",
      "\n",
      "episode 2, policy loss -2.164869546890259\n",
      "\n",
      "episode 3, policy loss -2.1648693084716797\n",
      "\n",
      "episode 4, policy loss -2.1648693084716797\n",
      "\n",
      "episode 5, policy loss -2.1648693084716797\n",
      "\n",
      "episode 6, policy loss -2.1648693084716797\n",
      "\n",
      "episode 7, policy loss -2.1648693084716797\n",
      "\n",
      "episode 8, policy loss -2.1648693084716797\n",
      "\n",
      "episode 9, policy loss -2.1648693084716797\n",
      "\n",
      "episode 10, policy loss -2.164869546890259\n",
      "\n",
      "episode 11, policy loss -2.164869546890259\n",
      "\n",
      "episode 12, policy loss -2.1648693084716797\n",
      "\n",
      "episode 13, policy loss -2.1648693084716797\n",
      "\n",
      "episode 14, policy loss -2.1648693084716797\n",
      "\n",
      "episode 15, policy loss -2.1648693084716797\n",
      "\n",
      "episode 16, policy loss -2.1648693084716797\n",
      "\n",
      "Policy train loss in epoch 1:-2.1648693680763245\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.164869546890259\n",
      "\n",
      "episode 2, policy loss -2.1648693084716797\n",
      "\n",
      "episode 3, policy loss -2.1648693084716797\n",
      "\n",
      "episode 4, policy loss -2.1648693084716797\n",
      "\n",
      "episode 5, policy loss -2.1648693084716797\n",
      "\n",
      "episode 6, policy loss -2.1648693084716797\n",
      "\n",
      "episode 7, policy loss -2.164869546890259\n",
      "\n",
      "episode 8, policy loss -2.1648693084716797\n",
      "\n",
      "episode 9, policy loss -2.1648693084716797\n",
      "\n",
      "episode 10, policy loss -2.1648693084716797\n",
      "\n",
      "episode 11, policy loss -2.1648693084716797\n",
      "\n",
      "episode 12, policy loss -2.1648693084716797\n",
      "\n",
      "episode 13, policy loss -2.1648693084716797\n",
      "\n",
      "episode 14, policy loss -2.164869546890259\n",
      "\n",
      "episode 15, policy loss -2.164869546890259\n",
      "\n",
      "episode 16, policy loss -2.1648693084716797\n",
      "\n",
      "Policy train loss in epoch 2:-2.1648693680763245\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.1648693084716797\n",
      "\n",
      "episode 2, policy loss -2.1648693084716797\n",
      "\n",
      "episode 3, policy loss -2.164869546890259\n",
      "\n",
      "episode 4, policy loss -2.1648693084716797\n",
      "\n",
      "episode 5, policy loss -2.1648693084716797\n",
      "\n",
      "episode 6, policy loss -2.164869546890259\n",
      "\n",
      "episode 7, policy loss -2.164869546890259\n",
      "\n",
      "episode 8, policy loss -2.1648693084716797\n",
      "\n",
      "episode 9, policy loss -2.1648693084716797\n",
      "\n",
      "episode 10, policy loss -2.1648693084716797\n",
      "\n",
      "episode 11, policy loss -2.1648693084716797\n",
      "\n",
      "episode 12, policy loss -2.1648693084716797\n",
      "\n",
      "episode 13, policy loss -2.1648693084716797\n",
      "\n",
      "episode 14, policy loss -2.1648693084716797\n",
      "\n",
      "episode 15, policy loss -2.164869546890259\n",
      "\n",
      "episode 16, policy loss -2.1648693084716797\n",
      "\n",
      "Policy train loss in epoch 3:-2.1648693680763245\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.7319997549057007\n",
      "\n",
      "episode 2, val func loss 1.4827868938446045\n",
      "\n",
      "episode 3, val func loss 1.5881534814834595\n",
      "\n",
      "episode 4, val func loss 1.5831140279769897\n",
      "\n",
      "episode 5, val func loss 1.566691517829895\n",
      "\n",
      "episode 6, val func loss 1.5438997745513916\n",
      "\n",
      "episode 7, val func loss 1.5119785070419312\n",
      "\n",
      "episode 8, val func loss 1.4288066625595093\n",
      "\n",
      "episode 9, val func loss 1.7087870836257935\n",
      "\n",
      "episode 10, val func loss 1.49253511428833\n",
      "\n",
      "episode 11, val func loss 1.581653118133545\n",
      "\n",
      "episode 12, val func loss 1.4383310079574585\n",
      "\n",
      "episode 13, val func loss 1.7619152069091797\n",
      "\n",
      "episode 14, val func loss 1.705851435661316\n",
      "\n",
      "episode 15, val func loss 1.7363872528076172\n",
      "\n",
      "episode 16, val func loss 1.7434017658233643\n",
      "\n",
      "Val func train loss in epoch 0:1.6003932878375053\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.225012183189392\n",
      "\n",
      "episode 2, val func loss 1.594826102256775\n",
      "\n",
      "episode 3, val func loss 1.4903346300125122\n",
      "\n",
      "episode 4, val func loss 1.5923266410827637\n",
      "\n",
      "episode 5, val func loss 1.666183352470398\n",
      "\n",
      "episode 6, val func loss 1.5904256105422974\n",
      "\n",
      "episode 7, val func loss 1.6192773580551147\n",
      "\n",
      "episode 8, val func loss 1.5945881605148315\n",
      "\n",
      "episode 9, val func loss 1.6557412147521973\n",
      "\n",
      "episode 10, val func loss 1.4069831371307373\n",
      "\n",
      "episode 11, val func loss 1.7617313861846924\n",
      "\n",
      "episode 12, val func loss 1.5404667854309082\n",
      "\n",
      "episode 13, val func loss 1.8205463886260986\n",
      "\n",
      "episode 14, val func loss 1.639837384223938\n",
      "\n",
      "episode 15, val func loss 1.6066346168518066\n",
      "\n",
      "episode 16, val func loss 1.6474096775054932\n",
      "\n",
      "Val func train loss in epoch 1:1.5907702893018723\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.6465001106262207\n",
      "\n",
      "episode 2, val func loss 1.3209331035614014\n",
      "\n",
      "episode 3, val func loss 1.6372560262680054\n",
      "\n",
      "episode 4, val func loss 1.7547718286514282\n",
      "\n",
      "episode 5, val func loss 1.6007342338562012\n",
      "\n",
      "episode 6, val func loss 1.5621713399887085\n",
      "\n",
      "episode 7, val func loss 1.8405752182006836\n",
      "\n",
      "episode 8, val func loss 1.6141667366027832\n",
      "\n",
      "episode 9, val func loss 1.5942538976669312\n",
      "\n",
      "episode 10, val func loss 1.7247787714004517\n",
      "\n",
      "episode 11, val func loss 1.6965959072113037\n",
      "\n",
      "episode 12, val func loss 1.5626367330551147\n",
      "\n",
      "episode 13, val func loss 1.668886661529541\n",
      "\n",
      "episode 14, val func loss 1.9425979852676392\n",
      "\n",
      "episode 15, val func loss 1.632763147354126\n",
      "\n",
      "episode 16, val func loss 1.59138822555542\n",
      "\n",
      "Val func train loss in epoch 2:1.6494381204247475\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.6060781478881836\n",
      "\n",
      "episode 2, val func loss 1.379435658454895\n",
      "\n",
      "episode 3, val func loss 1.2564022541046143\n",
      "\n",
      "episode 4, val func loss 1.65169358253479\n",
      "\n",
      "episode 5, val func loss 1.504782795906067\n",
      "\n",
      "episode 6, val func loss 1.5925886631011963\n",
      "\n",
      "episode 7, val func loss 1.67368483543396\n",
      "\n",
      "episode 8, val func loss 1.6228806972503662\n",
      "\n",
      "episode 9, val func loss 1.470131754875183\n",
      "\n",
      "episode 10, val func loss 1.5551844835281372\n",
      "\n",
      "episode 11, val func loss 1.6269962787628174\n",
      "\n",
      "episode 12, val func loss 1.6045832633972168\n",
      "\n",
      "episode 13, val func loss 1.3394006490707397\n",
      "\n",
      "episode 14, val func loss 1.5867464542388916\n",
      "\n",
      "episode 15, val func loss 1.5920562744140625\n",
      "\n",
      "episode 16, val func loss 1.637899398803711\n",
      "\n",
      "Val func train loss in epoch 3:1.543784074485302\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.7710150480270386\n",
      "\n",
      "episode 2, val func loss 1.8459714651107788\n",
      "\n",
      "episode 3, val func loss 1.5907868146896362\n",
      "\n",
      "episode 4, val func loss 1.4893027544021606\n",
      "\n",
      "episode 5, val func loss 1.6151517629623413\n",
      "\n",
      "episode 6, val func loss 1.6652908325195312\n",
      "\n",
      "episode 7, val func loss 1.65070378780365\n",
      "\n",
      "episode 8, val func loss 1.7747080326080322\n",
      "\n",
      "episode 9, val func loss 1.6244820356369019\n",
      "\n",
      "episode 10, val func loss 1.5381098985671997\n",
      "\n",
      "episode 11, val func loss 1.5854343175888062\n",
      "\n",
      "episode 12, val func loss 1.6624419689178467\n",
      "\n",
      "episode 13, val func loss 1.5355236530303955\n",
      "\n",
      "episode 14, val func loss 1.588206171989441\n",
      "\n",
      "episode 15, val func loss 1.5073810815811157\n",
      "\n",
      "episode 16, val func loss 1.6757129430770874\n",
      "\n",
      "Val func train loss in epoch 4:1.6325139105319977\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.7238659858703613\n",
      "\n",
      "episode 2, val func loss 1.4435811042785645\n",
      "\n",
      "episode 3, val func loss 1.7965351343154907\n",
      "\n",
      "episode 4, val func loss 1.4959977865219116\n",
      "\n",
      "episode 5, val func loss 1.7744685411453247\n",
      "\n",
      "episode 6, val func loss 1.4945118427276611\n",
      "\n",
      "episode 7, val func loss 1.5284864902496338\n",
      "\n",
      "episode 8, val func loss 1.5873987674713135\n",
      "\n",
      "episode 9, val func loss 1.90926992893219\n",
      "\n",
      "episode 10, val func loss 1.2227396965026855\n",
      "\n",
      "episode 11, val func loss 1.41802179813385\n",
      "\n",
      "episode 12, val func loss 2.026874303817749\n",
      "\n",
      "episode 13, val func loss 2.0179173946380615\n",
      "\n",
      "episode 14, val func loss 1.733083724975586\n",
      "\n",
      "episode 15, val func loss 1.6346044540405273\n",
      "\n",
      "episode 16, val func loss 1.3436237573623657\n",
      "\n",
      "Val func train loss in epoch 5:1.6344362944364548\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.5218369960784912\n",
      "\n",
      "episode 2, val func loss 1.4829519987106323\n",
      "\n",
      "episode 3, val func loss 1.8590854406356812\n",
      "\n",
      "episode 4, val func loss 1.5441168546676636\n",
      "\n",
      "episode 5, val func loss 1.5903971195220947\n",
      "\n",
      "episode 6, val func loss 1.5316725969314575\n",
      "\n",
      "episode 7, val func loss 1.6331628561019897\n",
      "\n",
      "episode 8, val func loss 1.4469064474105835\n",
      "\n",
      "episode 9, val func loss 1.610568881034851\n",
      "\n",
      "episode 10, val func loss 1.4940563440322876\n",
      "\n",
      "episode 11, val func loss 1.6599349975585938\n",
      "\n",
      "episode 12, val func loss 1.6125397682189941\n",
      "\n",
      "episode 13, val func loss 1.6264452934265137\n",
      "\n",
      "episode 14, val func loss 1.6454609632492065\n",
      "\n",
      "episode 15, val func loss 1.53294837474823\n",
      "\n",
      "episode 16, val func loss 1.5203715562820435\n",
      "\n",
      "Val func train loss in epoch 6:1.5820285305380821\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.5261826515197754\n",
      "\n",
      "episode 2, val func loss 1.417554497718811\n",
      "\n",
      "episode 3, val func loss 1.6260312795639038\n",
      "\n",
      "episode 4, val func loss 1.6450233459472656\n",
      "\n",
      "episode 5, val func loss 1.477137565612793\n",
      "\n",
      "episode 6, val func loss 1.6050785779953003\n",
      "\n",
      "episode 7, val func loss 1.671860933303833\n",
      "\n",
      "episode 8, val func loss 2.0428082942962646\n",
      "\n",
      "episode 9, val func loss 1.5646039247512817\n",
      "\n",
      "episode 10, val func loss 1.6341289281845093\n",
      "\n",
      "episode 11, val func loss 1.684000015258789\n",
      "\n",
      "episode 12, val func loss 1.4749047756195068\n",
      "\n",
      "episode 13, val func loss 1.5835033655166626\n",
      "\n",
      "episode 14, val func loss 1.567118763923645\n",
      "\n",
      "episode 15, val func loss 1.6477338075637817\n",
      "\n",
      "episode 16, val func loss 1.35818350315094\n",
      "\n",
      "Val func train loss in epoch 7:1.5953658893704414\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.7733741998672485\n",
      "\n",
      "episode 2, val func loss 1.5896238088607788\n",
      "\n",
      "episode 3, val func loss 1.4736298322677612\n",
      "\n",
      "episode 4, val func loss 1.8698408603668213\n",
      "\n",
      "episode 5, val func loss 1.5721482038497925\n",
      "\n",
      "episode 6, val func loss 1.519350290298462\n",
      "\n",
      "episode 7, val func loss 1.5011671781539917\n",
      "\n",
      "episode 8, val func loss 1.6503541469573975\n",
      "\n",
      "episode 9, val func loss 1.5042072534561157\n",
      "\n",
      "episode 10, val func loss 1.8388803005218506\n",
      "\n",
      "episode 11, val func loss 1.6295318603515625\n",
      "\n",
      "episode 12, val func loss 1.7523243427276611\n",
      "\n",
      "episode 13, val func loss 1.688209891319275\n",
      "\n",
      "episode 14, val func loss 1.716441035270691\n",
      "\n",
      "episode 15, val func loss 1.6424217224121094\n",
      "\n",
      "episode 16, val func loss 1.5222285985946655\n",
      "\n",
      "Val func train loss in epoch 8:1.6402333453297615\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.5564152002334595\n",
      "\n",
      "episode 2, val func loss 1.6063677072525024\n",
      "\n",
      "episode 3, val func loss 1.7050718069076538\n",
      "\n",
      "episode 4, val func loss 1.9288909435272217\n",
      "\n",
      "episode 5, val func loss 1.58510160446167\n",
      "\n",
      "episode 6, val func loss 1.4338963031768799\n",
      "\n",
      "episode 7, val func loss 1.6321839094161987\n",
      "\n",
      "episode 8, val func loss 1.6449694633483887\n",
      "\n",
      "episode 9, val func loss 1.7299591302871704\n",
      "\n",
      "episode 10, val func loss 1.639974594116211\n",
      "\n",
      "episode 11, val func loss 1.9000897407531738\n",
      "\n",
      "episode 12, val func loss 1.5354316234588623\n",
      "\n",
      "episode 13, val func loss 1.5045537948608398\n",
      "\n",
      "episode 14, val func loss 1.3252480030059814\n",
      "\n",
      "episode 15, val func loss 1.7681927680969238\n",
      "\n",
      "episode 16, val func loss 1.1417285203933716\n",
      "\n",
      "Val func train loss in epoch 9:1.6023796945810318\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.4391543865203857\n",
      "\n",
      "episode 2, val func loss 1.6857579946517944\n",
      "\n",
      "episode 3, val func loss 1.5183862447738647\n",
      "\n",
      "episode 4, val func loss 1.8531752824783325\n",
      "\n",
      "episode 5, val func loss 1.652216911315918\n",
      "\n",
      "episode 6, val func loss 1.6721030473709106\n",
      "\n",
      "episode 7, val func loss 1.7837798595428467\n",
      "\n",
      "episode 8, val func loss 1.7801109552383423\n",
      "\n",
      "episode 9, val func loss 1.5075433254241943\n",
      "\n",
      "episode 10, val func loss 1.653200387954712\n",
      "\n",
      "episode 11, val func loss 1.6355801820755005\n",
      "\n",
      "episode 12, val func loss 1.6514594554901123\n",
      "\n",
      "episode 13, val func loss 1.6342523097991943\n",
      "\n",
      "episode 14, val func loss 1.6694309711456299\n",
      "\n",
      "episode 15, val func loss 1.5836278200149536\n",
      "\n",
      "episode 16, val func loss 1.5600305795669556\n",
      "\n",
      "Val func train loss in epoch 10:1.642488107085228\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.5967453718185425\n",
      "\n",
      "episode 2, val func loss 1.9969748258590698\n",
      "\n",
      "episode 3, val func loss 1.3781331777572632\n",
      "\n",
      "episode 4, val func loss 1.5283265113830566\n",
      "\n",
      "episode 5, val func loss 1.626188039779663\n",
      "\n",
      "episode 6, val func loss 1.5172172784805298\n",
      "\n",
      "episode 7, val func loss 1.56461763381958\n",
      "\n",
      "episode 8, val func loss 1.7861758470535278\n",
      "\n",
      "episode 9, val func loss 1.5954128503799438\n",
      "\n",
      "episode 10, val func loss 1.7192622423171997\n",
      "\n",
      "episode 11, val func loss 1.56868577003479\n",
      "\n",
      "episode 12, val func loss 1.8551334142684937\n",
      "\n",
      "episode 13, val func loss 1.6214390993118286\n",
      "\n",
      "episode 14, val func loss 1.5806434154510498\n",
      "\n",
      "episode 15, val func loss 1.5276451110839844\n",
      "\n",
      "episode 16, val func loss 1.6608225107192993\n",
      "\n",
      "Val func train loss in epoch 11:1.632713943719864\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.5975736379623413\n",
      "\n",
      "episode 2, val func loss 1.9927786588668823\n",
      "\n",
      "episode 3, val func loss 1.6883175373077393\n",
      "\n",
      "episode 4, val func loss 1.7767459154129028\n",
      "\n",
      "episode 5, val func loss 1.6231082677841187\n",
      "\n",
      "episode 6, val func loss 1.6911065578460693\n",
      "\n",
      "episode 7, val func loss 1.797619342803955\n",
      "\n",
      "episode 8, val func loss 1.8517837524414062\n",
      "\n",
      "episode 9, val func loss 1.418572187423706\n",
      "\n",
      "episode 10, val func loss 1.6967555284500122\n",
      "\n",
      "episode 11, val func loss 1.4814237356185913\n",
      "\n",
      "episode 12, val func loss 1.6501622200012207\n",
      "\n",
      "episode 13, val func loss 1.6181648969650269\n",
      "\n",
      "episode 14, val func loss 1.6435673236846924\n",
      "\n",
      "episode 15, val func loss 1.4910719394683838\n",
      "\n",
      "episode 16, val func loss 1.7179688215255737\n",
      "\n",
      "Val func train loss in epoch 12:1.6710450202226639\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.5865731239318848\n",
      "\n",
      "episode 2, val func loss 1.7075746059417725\n",
      "\n",
      "episode 3, val func loss 1.4297930002212524\n",
      "\n",
      "episode 4, val func loss 1.5222712755203247\n",
      "\n",
      "episode 5, val func loss 1.4113733768463135\n",
      "\n",
      "episode 6, val func loss 1.400815725326538\n",
      "\n",
      "episode 7, val func loss 1.523287296295166\n",
      "\n",
      "episode 8, val func loss 1.974672794342041\n",
      "\n",
      "episode 9, val func loss 1.5490245819091797\n",
      "\n",
      "episode 10, val func loss 1.3727586269378662\n",
      "\n",
      "episode 11, val func loss 1.5607990026474\n",
      "\n",
      "episode 12, val func loss 1.5493141412734985\n",
      "\n",
      "episode 13, val func loss 1.4927942752838135\n",
      "\n",
      "episode 14, val func loss 1.731955885887146\n",
      "\n",
      "episode 15, val func loss 1.6086286306381226\n",
      "\n",
      "episode 16, val func loss 1.6641035079956055\n",
      "\n",
      "Val func train loss in epoch 13:1.5678587406873703\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.6349012851715088\n",
      "\n",
      "episode 2, val func loss 1.5395935773849487\n",
      "\n",
      "episode 3, val func loss 1.2908116579055786\n",
      "\n",
      "episode 4, val func loss 1.4372727870941162\n",
      "\n",
      "episode 5, val func loss 1.5773268938064575\n",
      "\n",
      "episode 6, val func loss 1.6354296207427979\n",
      "\n",
      "episode 7, val func loss 1.5347031354904175\n",
      "\n",
      "episode 8, val func loss 1.586434245109558\n",
      "\n",
      "episode 9, val func loss 1.5411953926086426\n",
      "\n",
      "episode 10, val func loss 1.6786065101623535\n",
      "\n",
      "episode 11, val func loss 1.3919862508773804\n",
      "\n",
      "episode 12, val func loss 1.6184674501419067\n",
      "\n",
      "episode 13, val func loss 1.7127608060836792\n",
      "\n",
      "episode 14, val func loss 1.6424081325531006\n",
      "\n",
      "episode 15, val func loss 1.6102055311203003\n",
      "\n",
      "episode 16, val func loss 1.4271544218063354\n",
      "\n",
      "Val func train loss in epoch 14:1.5537036061286926\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.6645690202713013\n",
      "\n",
      "episode 2, val func loss 1.824089765548706\n",
      "\n",
      "episode 3, val func loss 1.5780303478240967\n",
      "\n",
      "episode 4, val func loss 1.4995098114013672\n",
      "\n",
      "episode 5, val func loss 1.6219083070755005\n",
      "\n",
      "episode 6, val func loss 1.5120224952697754\n",
      "\n",
      "episode 7, val func loss 1.6542888879776\n",
      "\n",
      "episode 8, val func loss 1.7225857973098755\n",
      "\n",
      "episode 9, val func loss 1.7121827602386475\n",
      "\n",
      "episode 10, val func loss 1.395668387413025\n",
      "\n",
      "episode 11, val func loss 1.533762812614441\n",
      "\n",
      "episode 12, val func loss 1.8682812452316284\n",
      "\n",
      "episode 13, val func loss 1.663228988647461\n",
      "\n",
      "episode 14, val func loss 1.65091872215271\n",
      "\n",
      "episode 15, val func loss 1.5261114835739136\n",
      "\n",
      "episode 16, val func loss 1.322374939918518\n",
      "\n",
      "Val func train loss in epoch 15:1.6093458607792854\n",
      "***********************TIME WAS 4.805373613039652 min*****************************\n",
      "\n",
      "**********************ROUND 24 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.3127710819244385\n",
      "\n",
      "episode 2, policy loss -2.3127710819244385\n",
      "\n",
      "episode 3, policy loss -2.3127710819244385\n",
      "\n",
      "episode 4, policy loss -2.3127713203430176\n",
      "\n",
      "episode 5, policy loss -2.3127713203430176\n",
      "\n",
      "episode 6, policy loss -2.3127710819244385\n",
      "\n",
      "episode 7, policy loss -2.3127710819244385\n",
      "\n",
      "episode 8, policy loss -2.3127713203430176\n",
      "\n",
      "episode 9, policy loss -2.3127710819244385\n",
      "\n",
      "episode 10, policy loss -2.3127710819244385\n",
      "\n",
      "episode 11, policy loss -2.3127713203430176\n",
      "\n",
      "episode 12, policy loss -2.3127713203430176\n",
      "\n",
      "episode 13, policy loss -2.3127710819244385\n",
      "\n",
      "episode 14, policy loss -2.3127713203430176\n",
      "\n",
      "episode 15, policy loss -2.3127713203430176\n",
      "\n",
      "episode 16, policy loss -2.3127710819244385\n",
      "\n",
      "Policy train loss in epoch 0:-2.312771186232567\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.3127710819244385\n",
      "\n",
      "episode 2, policy loss -2.3127710819244385\n",
      "\n",
      "episode 3, policy loss -2.3127713203430176\n",
      "\n",
      "episode 4, policy loss -2.3127710819244385\n",
      "\n",
      "episode 5, policy loss -2.3127713203430176\n",
      "\n",
      "episode 6, policy loss -2.3127710819244385\n",
      "\n",
      "episode 7, policy loss -2.3127710819244385\n",
      "\n",
      "episode 8, policy loss -2.3127713203430176\n",
      "\n",
      "episode 9, policy loss -2.3127713203430176\n",
      "\n",
      "episode 10, policy loss -2.3127710819244385\n",
      "\n",
      "episode 11, policy loss -2.3127713203430176\n",
      "\n",
      "episode 12, policy loss -2.3127713203430176\n",
      "\n",
      "episode 13, policy loss -2.3127710819244385\n",
      "\n",
      "episode 14, policy loss -2.3127713203430176\n",
      "\n",
      "episode 15, policy loss -2.3127710819244385\n",
      "\n",
      "episode 16, policy loss -2.3127710819244385\n",
      "\n",
      "Policy train loss in epoch 1:-2.312771186232567\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.3127710819244385\n",
      "\n",
      "episode 2, policy loss -2.3127710819244385\n",
      "\n",
      "episode 3, policy loss -2.3127710819244385\n",
      "\n",
      "episode 4, policy loss -2.3127713203430176\n",
      "\n",
      "episode 5, policy loss -2.3127713203430176\n",
      "\n",
      "episode 6, policy loss -2.3127713203430176\n",
      "\n",
      "episode 7, policy loss -2.3127713203430176\n",
      "\n",
      "episode 8, policy loss -2.3127710819244385\n",
      "\n",
      "episode 9, policy loss -2.3127713203430176\n",
      "\n",
      "episode 10, policy loss -2.3127710819244385\n",
      "\n",
      "episode 11, policy loss -2.3127710819244385\n",
      "\n",
      "episode 12, policy loss -2.3127710819244385\n",
      "\n",
      "episode 13, policy loss -2.3127713203430176\n",
      "\n",
      "episode 14, policy loss -2.3127710819244385\n",
      "\n",
      "episode 15, policy loss -2.3127710819244385\n",
      "\n",
      "episode 16, policy loss -2.3127713203430176\n",
      "\n",
      "Policy train loss in epoch 2:-2.312771186232567\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.3127713203430176\n",
      "\n",
      "episode 2, policy loss -2.3127710819244385\n",
      "\n",
      "episode 3, policy loss -2.3127713203430176\n",
      "\n",
      "episode 4, policy loss -2.3127710819244385\n",
      "\n",
      "episode 5, policy loss -2.3127710819244385\n",
      "\n",
      "episode 6, policy loss -2.3127710819244385\n",
      "\n",
      "episode 7, policy loss -2.3127710819244385\n",
      "\n",
      "episode 8, policy loss -2.3127710819244385\n",
      "\n",
      "episode 9, policy loss -2.3127713203430176\n",
      "\n",
      "episode 10, policy loss -2.3127713203430176\n",
      "\n",
      "episode 11, policy loss -2.3127710819244385\n",
      "\n",
      "episode 12, policy loss -2.3127713203430176\n",
      "\n",
      "episode 13, policy loss -2.3127710819244385\n",
      "\n",
      "episode 14, policy loss -2.3127710819244385\n",
      "\n",
      "episode 15, policy loss -2.3127713203430176\n",
      "\n",
      "episode 16, policy loss -2.3127713203430176\n",
      "\n",
      "Policy train loss in epoch 3:-2.312771186232567\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.5427559614181519\n",
      "\n",
      "episode 2, val func loss 1.6459062099456787\n",
      "\n",
      "episode 3, val func loss 1.695030927658081\n",
      "\n",
      "episode 4, val func loss 1.6344867944717407\n",
      "\n",
      "episode 5, val func loss 1.7641688585281372\n",
      "\n",
      "episode 6, val func loss 1.78403639793396\n",
      "\n",
      "episode 7, val func loss 1.7013862133026123\n",
      "\n",
      "episode 8, val func loss 1.56875741481781\n",
      "\n",
      "episode 9, val func loss 1.575564980506897\n",
      "\n",
      "episode 10, val func loss 1.843261480331421\n",
      "\n",
      "episode 11, val func loss 1.6703788042068481\n",
      "\n",
      "episode 12, val func loss 1.7507975101470947\n",
      "\n",
      "episode 13, val func loss 1.7005618810653687\n",
      "\n",
      "episode 14, val func loss 1.5047544240951538\n",
      "\n",
      "episode 15, val func loss 1.5612744092941284\n",
      "\n",
      "episode 16, val func loss 1.5631023645401\n",
      "\n",
      "Val func train loss in epoch 0:1.656639039516449\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.6730672121047974\n",
      "\n",
      "episode 2, val func loss 1.8003581762313843\n",
      "\n",
      "episode 3, val func loss 1.4489604234695435\n",
      "\n",
      "episode 4, val func loss 1.651339054107666\n",
      "\n",
      "episode 5, val func loss 1.4899846315383911\n",
      "\n",
      "episode 6, val func loss 1.529355764389038\n",
      "\n",
      "episode 7, val func loss 1.5950199365615845\n",
      "\n",
      "episode 8, val func loss 1.3819931745529175\n",
      "\n",
      "episode 9, val func loss 1.5626087188720703\n",
      "\n",
      "episode 10, val func loss 1.6843187808990479\n",
      "\n",
      "episode 11, val func loss 1.6221572160720825\n",
      "\n",
      "episode 12, val func loss 1.6824009418487549\n",
      "\n",
      "episode 13, val func loss 1.660948634147644\n",
      "\n",
      "episode 14, val func loss 1.8432058095932007\n",
      "\n",
      "episode 15, val func loss 1.628134846687317\n",
      "\n",
      "episode 16, val func loss 1.6730194091796875\n",
      "\n",
      "Val func train loss in epoch 1:1.6204295456409454\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.919646978378296\n",
      "\n",
      "episode 2, val func loss 1.6399815082550049\n",
      "\n",
      "episode 3, val func loss 1.6523288488388062\n",
      "\n",
      "episode 4, val func loss 1.600386619567871\n",
      "\n",
      "episode 5, val func loss 1.527958631515503\n",
      "\n",
      "episode 6, val func loss 1.6925593614578247\n",
      "\n",
      "episode 7, val func loss 1.62110435962677\n",
      "\n",
      "episode 8, val func loss 1.5956891775131226\n",
      "\n",
      "episode 9, val func loss 1.6758869886398315\n",
      "\n",
      "episode 10, val func loss 1.6466717720031738\n",
      "\n",
      "episode 11, val func loss 1.7793903350830078\n",
      "\n",
      "episode 12, val func loss 1.7078043222427368\n",
      "\n",
      "episode 13, val func loss 1.7010581493377686\n",
      "\n",
      "episode 14, val func loss 1.52500319480896\n",
      "\n",
      "episode 15, val func loss 1.774901032447815\n",
      "\n",
      "episode 16, val func loss 1.6961148977279663\n",
      "\n",
      "Val func train loss in epoch 2:1.6722803860902786\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.8791285753250122\n",
      "\n",
      "episode 2, val func loss 1.6987680196762085\n",
      "\n",
      "episode 3, val func loss 1.8694071769714355\n",
      "\n",
      "episode 4, val func loss 1.5829315185546875\n",
      "\n",
      "episode 5, val func loss 1.6944942474365234\n",
      "\n",
      "episode 6, val func loss 1.5349899530410767\n",
      "\n",
      "episode 7, val func loss 1.6856449842453003\n",
      "\n",
      "episode 8, val func loss 1.691927433013916\n",
      "\n",
      "episode 9, val func loss 1.446972131729126\n",
      "\n",
      "episode 10, val func loss 1.6902313232421875\n",
      "\n",
      "episode 11, val func loss 1.6586977243423462\n",
      "\n",
      "episode 12, val func loss 1.637110710144043\n",
      "\n",
      "episode 13, val func loss 1.7317852973937988\n",
      "\n",
      "episode 14, val func loss 1.6283267736434937\n",
      "\n",
      "episode 15, val func loss 1.6698493957519531\n",
      "\n",
      "episode 16, val func loss 1.7683274745941162\n",
      "\n",
      "Val func train loss in epoch 3:1.6792870461940765\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.612399697303772\n",
      "\n",
      "episode 2, val func loss 1.919599175453186\n",
      "\n",
      "episode 3, val func loss 1.5770410299301147\n",
      "\n",
      "episode 4, val func loss 1.5465638637542725\n",
      "\n",
      "episode 5, val func loss 1.6189935207366943\n",
      "\n",
      "episode 6, val func loss 1.7107157707214355\n",
      "\n",
      "episode 7, val func loss 1.6371508836746216\n",
      "\n",
      "episode 8, val func loss 1.5863796472549438\n",
      "\n",
      "episode 9, val func loss 1.9367839097976685\n",
      "\n",
      "episode 10, val func loss 1.8085403442382812\n",
      "\n",
      "episode 11, val func loss 1.7550934553146362\n",
      "\n",
      "episode 12, val func loss 1.5197120904922485\n",
      "\n",
      "episode 13, val func loss 1.4616609811782837\n",
      "\n",
      "episode 14, val func loss 1.8313767910003662\n",
      "\n",
      "episode 15, val func loss 1.7982054948806763\n",
      "\n",
      "episode 16, val func loss 1.6812877655029297\n",
      "\n",
      "Val func train loss in epoch 4:1.6875940263271332\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.8140201568603516\n",
      "\n",
      "episode 2, val func loss 1.5662205219268799\n",
      "\n",
      "episode 3, val func loss 1.6161736249923706\n",
      "\n",
      "episode 4, val func loss 1.7067532539367676\n",
      "\n",
      "episode 5, val func loss 1.7021512985229492\n",
      "\n",
      "episode 6, val func loss 1.6018239259719849\n",
      "\n",
      "episode 7, val func loss 1.5098156929016113\n",
      "\n",
      "episode 8, val func loss 1.7412779331207275\n",
      "\n",
      "episode 9, val func loss 1.8722037076950073\n",
      "\n",
      "episode 10, val func loss 1.6072560548782349\n",
      "\n",
      "episode 11, val func loss 1.710195541381836\n",
      "\n",
      "episode 12, val func loss 1.7058603763580322\n",
      "\n",
      "episode 13, val func loss 1.657519817352295\n",
      "\n",
      "episode 14, val func loss 1.5156140327453613\n",
      "\n",
      "episode 15, val func loss 1.641196846961975\n",
      "\n",
      "episode 16, val func loss 1.7185131311416626\n",
      "\n",
      "Val func train loss in epoch 5:1.667912244796753\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.7429041862487793\n",
      "\n",
      "episode 2, val func loss 1.6521960496902466\n",
      "\n",
      "episode 3, val func loss 1.73065984249115\n",
      "\n",
      "episode 4, val func loss 1.7060109376907349\n",
      "\n",
      "episode 5, val func loss 1.5116908550262451\n",
      "\n",
      "episode 6, val func loss 1.5120640993118286\n",
      "\n",
      "episode 7, val func loss 1.7193442583084106\n",
      "\n",
      "episode 8, val func loss 1.4499455690383911\n",
      "\n",
      "episode 9, val func loss 1.6580559015274048\n",
      "\n",
      "episode 10, val func loss 1.6182987689971924\n",
      "\n",
      "episode 11, val func loss 1.6951907873153687\n",
      "\n",
      "episode 12, val func loss 1.5039209127426147\n",
      "\n",
      "episode 13, val func loss 1.6136364936828613\n",
      "\n",
      "episode 14, val func loss 1.5955113172531128\n",
      "\n",
      "episode 15, val func loss 1.574741005897522\n",
      "\n",
      "episode 16, val func loss 1.7887777090072632\n",
      "\n",
      "Val func train loss in epoch 6:1.6295592933893204\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.6440013647079468\n",
      "\n",
      "episode 2, val func loss 1.5980397462844849\n",
      "\n",
      "episode 3, val func loss 1.590010643005371\n",
      "\n",
      "episode 4, val func loss 1.9785090684890747\n",
      "\n",
      "episode 5, val func loss 1.5028414726257324\n",
      "\n",
      "episode 6, val func loss 1.790037751197815\n",
      "\n",
      "episode 7, val func loss 1.719992995262146\n",
      "\n",
      "episode 8, val func loss 1.5111281871795654\n",
      "\n",
      "episode 9, val func loss 1.5508891344070435\n",
      "\n",
      "episode 10, val func loss 1.6160200834274292\n",
      "\n",
      "episode 11, val func loss 1.7035322189331055\n",
      "\n",
      "episode 12, val func loss 1.6195868253707886\n",
      "\n",
      "episode 13, val func loss 1.674103856086731\n",
      "\n",
      "episode 14, val func loss 1.8040608167648315\n",
      "\n",
      "episode 15, val func loss 1.7054404020309448\n",
      "\n",
      "episode 16, val func loss 1.8659017086029053\n",
      "\n",
      "Val func train loss in epoch 7:1.6796310171484947\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.6376498937606812\n",
      "\n",
      "episode 2, val func loss 1.7548565864562988\n",
      "\n",
      "episode 3, val func loss 1.6088804006576538\n",
      "\n",
      "episode 4, val func loss 1.622630000114441\n",
      "\n",
      "episode 5, val func loss 1.555965781211853\n",
      "\n",
      "episode 6, val func loss 1.6982767581939697\n",
      "\n",
      "episode 7, val func loss 1.6584447622299194\n",
      "\n",
      "episode 8, val func loss 1.6226136684417725\n",
      "\n",
      "episode 9, val func loss 1.6233205795288086\n",
      "\n",
      "episode 10, val func loss 1.6381388902664185\n",
      "\n",
      "episode 11, val func loss 1.571951150894165\n",
      "\n",
      "episode 12, val func loss 1.5971336364746094\n",
      "\n",
      "episode 13, val func loss 1.6496179103851318\n",
      "\n",
      "episode 14, val func loss 1.5933701992034912\n",
      "\n",
      "episode 15, val func loss 1.2980103492736816\n",
      "\n",
      "episode 16, val func loss 1.6955289840698242\n",
      "\n",
      "Val func train loss in epoch 8:1.61414934694767\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.5770787000656128\n",
      "\n",
      "episode 2, val func loss 1.4920697212219238\n",
      "\n",
      "episode 3, val func loss 1.5609190464019775\n",
      "\n",
      "episode 4, val func loss 1.6428017616271973\n",
      "\n",
      "episode 5, val func loss 1.835371494293213\n",
      "\n",
      "episode 6, val func loss 1.8196758031845093\n",
      "\n",
      "episode 7, val func loss 1.7289797067642212\n",
      "\n",
      "episode 8, val func loss 1.5953584909439087\n",
      "\n",
      "episode 9, val func loss 1.6613110303878784\n",
      "\n",
      "episode 10, val func loss 1.7111543416976929\n",
      "\n",
      "episode 11, val func loss 1.6844062805175781\n",
      "\n",
      "episode 12, val func loss 1.61807382106781\n",
      "\n",
      "episode 13, val func loss 1.510356068611145\n",
      "\n",
      "episode 14, val func loss 1.6149173974990845\n",
      "\n",
      "episode 15, val func loss 1.6967413425445557\n",
      "\n",
      "episode 16, val func loss 1.6235638856887817\n",
      "\n",
      "Val func train loss in epoch 9:1.6482986807823181\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.7141999006271362\n",
      "\n",
      "episode 2, val func loss 1.5038141012191772\n",
      "\n",
      "episode 3, val func loss 1.7885457277297974\n",
      "\n",
      "episode 4, val func loss 1.6402214765548706\n",
      "\n",
      "episode 5, val func loss 1.4289278984069824\n",
      "\n",
      "episode 6, val func loss 1.603222131729126\n",
      "\n",
      "episode 7, val func loss 1.4389290809631348\n",
      "\n",
      "episode 8, val func loss 1.6390680074691772\n",
      "\n",
      "episode 9, val func loss 1.5158063173294067\n",
      "\n",
      "episode 10, val func loss 1.4883280992507935\n",
      "\n",
      "episode 11, val func loss 1.4912605285644531\n",
      "\n",
      "episode 12, val func loss 1.7018296718597412\n",
      "\n",
      "episode 13, val func loss 1.5154087543487549\n",
      "\n",
      "episode 14, val func loss 1.5115017890930176\n",
      "\n",
      "episode 15, val func loss 1.7776226997375488\n",
      "\n",
      "episode 16, val func loss 1.5979915857315063\n",
      "\n",
      "Val func train loss in epoch 10:1.584792360663414\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.5089213848114014\n",
      "\n",
      "episode 2, val func loss 1.7524346113204956\n",
      "\n",
      "episode 3, val func loss 1.4990649223327637\n",
      "\n",
      "episode 4, val func loss 1.6334511041641235\n",
      "\n",
      "episode 5, val func loss 1.545311689376831\n",
      "\n",
      "episode 6, val func loss 1.6052584648132324\n",
      "\n",
      "episode 7, val func loss 1.5168952941894531\n",
      "\n",
      "episode 8, val func loss 1.6895337104797363\n",
      "\n",
      "episode 9, val func loss 1.5726746320724487\n",
      "\n",
      "episode 10, val func loss 1.7054888010025024\n",
      "\n",
      "episode 11, val func loss 1.6174817085266113\n",
      "\n",
      "episode 12, val func loss 1.51236093044281\n",
      "\n",
      "episode 13, val func loss 1.5336803197860718\n",
      "\n",
      "episode 14, val func loss 1.5879414081573486\n",
      "\n",
      "episode 15, val func loss 1.6849876642227173\n",
      "\n",
      "episode 16, val func loss 1.6977827548980713\n",
      "\n",
      "Val func train loss in epoch 11:1.6039543375372887\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.7082257270812988\n",
      "\n",
      "episode 2, val func loss 1.7804102897644043\n",
      "\n",
      "episode 3, val func loss 1.553623080253601\n",
      "\n",
      "episode 4, val func loss 1.7290339469909668\n",
      "\n",
      "episode 5, val func loss 1.7949556112289429\n",
      "\n",
      "episode 6, val func loss 1.5652655363082886\n",
      "\n",
      "episode 7, val func loss 1.470661997795105\n",
      "\n",
      "episode 8, val func loss 1.611019492149353\n",
      "\n",
      "episode 9, val func loss 1.397803783416748\n",
      "\n",
      "episode 10, val func loss 1.6907275915145874\n",
      "\n",
      "episode 11, val func loss 1.5793720483779907\n",
      "\n",
      "episode 12, val func loss 1.7116241455078125\n",
      "\n",
      "episode 13, val func loss 1.8630523681640625\n",
      "\n",
      "episode 14, val func loss 1.5813995599746704\n",
      "\n",
      "episode 15, val func loss 1.5430716276168823\n",
      "\n",
      "episode 16, val func loss 1.5788174867630005\n",
      "\n",
      "Val func train loss in epoch 12:1.6349415183067322\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.6153199672698975\n",
      "\n",
      "episode 2, val func loss 1.692832350730896\n",
      "\n",
      "episode 3, val func loss 1.6371264457702637\n",
      "\n",
      "episode 4, val func loss 1.4483134746551514\n",
      "\n",
      "episode 5, val func loss 1.7089437246322632\n",
      "\n",
      "episode 6, val func loss 1.5493413209915161\n",
      "\n",
      "episode 7, val func loss 1.5284099578857422\n",
      "\n",
      "episode 8, val func loss 1.8739948272705078\n",
      "\n",
      "episode 9, val func loss 1.549071192741394\n",
      "\n",
      "episode 10, val func loss 1.5030211210250854\n",
      "\n",
      "episode 11, val func loss 1.4324771165847778\n",
      "\n",
      "episode 12, val func loss 1.53982675075531\n",
      "\n",
      "episode 13, val func loss 1.5559576749801636\n",
      "\n",
      "episode 14, val func loss 1.7417997121810913\n",
      "\n",
      "episode 15, val func loss 1.688630223274231\n",
      "\n",
      "episode 16, val func loss 1.7886953353881836\n",
      "\n",
      "Val func train loss in epoch 13:1.6158600747585297\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.5976871252059937\n",
      "\n",
      "episode 2, val func loss 1.8819363117218018\n",
      "\n",
      "episode 3, val func loss 1.751099944114685\n",
      "\n",
      "episode 4, val func loss 1.8723164796829224\n",
      "\n",
      "episode 5, val func loss 1.817945122718811\n",
      "\n",
      "episode 6, val func loss 1.6740692853927612\n",
      "\n",
      "episode 7, val func loss 1.8739653825759888\n",
      "\n",
      "episode 8, val func loss 1.6512302160263062\n",
      "\n",
      "episode 9, val func loss 1.5761216878890991\n",
      "\n",
      "episode 10, val func loss 1.5974712371826172\n",
      "\n",
      "episode 11, val func loss 1.639851689338684\n",
      "\n",
      "episode 12, val func loss 1.4829210042953491\n",
      "\n",
      "episode 13, val func loss 1.6957117319107056\n",
      "\n",
      "episode 14, val func loss 1.5218807458877563\n",
      "\n",
      "episode 15, val func loss 1.6879518032073975\n",
      "\n",
      "episode 16, val func loss 1.6844278573989868\n",
      "\n",
      "Val func train loss in epoch 14:1.6879117265343666\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.553355097770691\n",
      "\n",
      "episode 2, val func loss 1.6157522201538086\n",
      "\n",
      "episode 3, val func loss 1.6221095323562622\n",
      "\n",
      "episode 4, val func loss 1.660810112953186\n",
      "\n",
      "episode 5, val func loss 1.6129637956619263\n",
      "\n",
      "episode 6, val func loss 1.6000512838363647\n",
      "\n",
      "episode 7, val func loss 1.5594643354415894\n",
      "\n",
      "episode 8, val func loss 1.6983447074890137\n",
      "\n",
      "episode 9, val func loss 1.7223881483078003\n",
      "\n",
      "episode 10, val func loss 1.9398757219314575\n",
      "\n",
      "episode 11, val func loss 1.595458984375\n",
      "\n",
      "episode 12, val func loss 1.4533320665359497\n",
      "\n",
      "episode 13, val func loss 1.5921047925949097\n",
      "\n",
      "episode 14, val func loss 1.487033724784851\n",
      "\n",
      "episode 15, val func loss 1.4734851121902466\n",
      "\n",
      "episode 16, val func loss 1.659088134765625\n",
      "\n",
      "Val func train loss in epoch 15:1.6153511106967926\n",
      "***********************TIME WAS 4.81246634721756 min*****************************\n",
      "\n",
      "**********************ROUND 25 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.1534132957458496\n",
      "\n",
      "episode 2, policy loss -2.153413772583008\n",
      "\n",
      "episode 3, policy loss -2.153413772583008\n",
      "\n",
      "episode 4, policy loss -2.1534135341644287\n",
      "\n",
      "episode 5, policy loss -2.153413772583008\n",
      "\n",
      "episode 6, policy loss -2.153413772583008\n",
      "\n",
      "episode 7, policy loss -2.1534135341644287\n",
      "\n",
      "episode 8, policy loss -2.153413772583008\n",
      "\n",
      "episode 9, policy loss -2.153413772583008\n",
      "\n",
      "episode 10, policy loss -2.1534135341644287\n",
      "\n",
      "episode 11, policy loss -2.153413772583008\n",
      "\n",
      "episode 12, policy loss -2.153413772583008\n",
      "\n",
      "episode 13, policy loss -2.1534135341644287\n",
      "\n",
      "episode 14, policy loss -2.153413772583008\n",
      "\n",
      "episode 15, policy loss -2.153413772583008\n",
      "\n",
      "episode 16, policy loss -2.153413772583008\n",
      "\n",
      "Policy train loss in epoch 0:-2.1534136831760406\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.153413772583008\n",
      "\n",
      "episode 2, policy loss -2.153413772583008\n",
      "\n",
      "episode 3, policy loss -2.153413772583008\n",
      "\n",
      "episode 4, policy loss -2.1534132957458496\n",
      "\n",
      "episode 5, policy loss -2.153413772583008\n",
      "\n",
      "episode 6, policy loss -2.1534135341644287\n",
      "\n",
      "episode 7, policy loss -2.153413772583008\n",
      "\n",
      "episode 8, policy loss -2.153413772583008\n",
      "\n",
      "episode 9, policy loss -2.1534135341644287\n",
      "\n",
      "episode 10, policy loss -2.153413772583008\n",
      "\n",
      "episode 11, policy loss -2.153413772583008\n",
      "\n",
      "episode 12, policy loss -2.153413772583008\n",
      "\n",
      "episode 13, policy loss -2.153413772583008\n",
      "\n",
      "episode 14, policy loss -2.1534135341644287\n",
      "\n",
      "episode 15, policy loss -2.153413772583008\n",
      "\n",
      "episode 16, policy loss -2.1534135341644287\n",
      "\n",
      "Policy train loss in epoch 1:-2.1534136831760406\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.1534135341644287\n",
      "\n",
      "episode 2, policy loss -2.153413772583008\n",
      "\n",
      "episode 3, policy loss -2.1534132957458496\n",
      "\n",
      "episode 4, policy loss -2.153413772583008\n",
      "\n",
      "episode 5, policy loss -2.153413772583008\n",
      "\n",
      "episode 6, policy loss -2.153413772583008\n",
      "\n",
      "episode 7, policy loss -2.153413772583008\n",
      "\n",
      "episode 8, policy loss -2.1534135341644287\n",
      "\n",
      "episode 9, policy loss -2.153413772583008\n",
      "\n",
      "episode 10, policy loss -2.153413772583008\n",
      "\n",
      "episode 11, policy loss -2.1534135341644287\n",
      "\n",
      "episode 12, policy loss -2.153413772583008\n",
      "\n",
      "episode 13, policy loss -2.1534135341644287\n",
      "\n",
      "episode 14, policy loss -2.153413772583008\n",
      "\n",
      "episode 15, policy loss -2.153413772583008\n",
      "\n",
      "episode 16, policy loss -2.153413772583008\n",
      "\n",
      "Policy train loss in epoch 2:-2.1534136831760406\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.1534135341644287\n",
      "\n",
      "episode 2, policy loss -2.1534135341644287\n",
      "\n",
      "episode 3, policy loss -2.153413772583008\n",
      "\n",
      "episode 4, policy loss -2.153413772583008\n",
      "\n",
      "episode 5, policy loss -2.1534132957458496\n",
      "\n",
      "episode 6, policy loss -2.153413772583008\n",
      "\n",
      "episode 7, policy loss -2.153413772583008\n",
      "\n",
      "episode 8, policy loss -2.1534135341644287\n",
      "\n",
      "episode 9, policy loss -2.153413772583008\n",
      "\n",
      "episode 10, policy loss -2.1534135341644287\n",
      "\n",
      "episode 11, policy loss -2.153413772583008\n",
      "\n",
      "episode 12, policy loss -2.153413772583008\n",
      "\n",
      "episode 13, policy loss -2.153413772583008\n",
      "\n",
      "episode 14, policy loss -2.153413772583008\n",
      "\n",
      "episode 15, policy loss -2.153413772583008\n",
      "\n",
      "episode 16, policy loss -2.153413772583008\n",
      "\n",
      "Policy train loss in epoch 3:-2.1534136831760406\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.7232831716537476\n",
      "\n",
      "episode 2, val func loss 1.7703838348388672\n",
      "\n",
      "episode 3, val func loss 1.7574373483657837\n",
      "\n",
      "episode 4, val func loss 1.708677053451538\n",
      "\n",
      "episode 5, val func loss 1.6305769681930542\n",
      "\n",
      "episode 6, val func loss 1.7262340784072876\n",
      "\n",
      "episode 7, val func loss 1.735344648361206\n",
      "\n",
      "episode 8, val func loss 1.623596429824829\n",
      "\n",
      "episode 9, val func loss 1.87558913230896\n",
      "\n",
      "episode 10, val func loss 1.6459954977035522\n",
      "\n",
      "episode 11, val func loss 1.603047490119934\n",
      "\n",
      "episode 12, val func loss 1.7870746850967407\n",
      "\n",
      "episode 13, val func loss 1.5239856243133545\n",
      "\n",
      "episode 14, val func loss 1.655815839767456\n",
      "\n",
      "episode 15, val func loss 1.5241938829421997\n",
      "\n",
      "episode 16, val func loss 1.6149135828018188\n",
      "\n",
      "Val func train loss in epoch 0:1.6816343292593956\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.4242074489593506\n",
      "\n",
      "episode 2, val func loss 1.7114752531051636\n",
      "\n",
      "episode 3, val func loss 1.508077621459961\n",
      "\n",
      "episode 4, val func loss 1.6044933795928955\n",
      "\n",
      "episode 5, val func loss 1.6694669723510742\n",
      "\n",
      "episode 6, val func loss 1.5597156286239624\n",
      "\n",
      "episode 7, val func loss 1.7230901718139648\n",
      "\n",
      "episode 8, val func loss 1.3971264362335205\n",
      "\n",
      "episode 9, val func loss 1.402000904083252\n",
      "\n",
      "episode 10, val func loss 1.6585530042648315\n",
      "\n",
      "episode 11, val func loss 1.632201075553894\n",
      "\n",
      "episode 12, val func loss 1.6990396976470947\n",
      "\n",
      "episode 13, val func loss 1.6380407810211182\n",
      "\n",
      "episode 14, val func loss 1.4970366954803467\n",
      "\n",
      "episode 15, val func loss 1.7370260953903198\n",
      "\n",
      "episode 16, val func loss 1.6252087354660034\n",
      "\n",
      "Val func train loss in epoch 1:1.592922493815422\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.586982250213623\n",
      "\n",
      "episode 2, val func loss 1.6830189228057861\n",
      "\n",
      "episode 3, val func loss 1.62708580493927\n",
      "\n",
      "episode 4, val func loss 1.5744171142578125\n",
      "\n",
      "episode 5, val func loss 1.5739915370941162\n",
      "\n",
      "episode 6, val func loss 1.5785982608795166\n",
      "\n",
      "episode 7, val func loss 1.4626133441925049\n",
      "\n",
      "episode 8, val func loss 1.6670565605163574\n",
      "\n",
      "episode 9, val func loss 1.5759831666946411\n",
      "\n",
      "episode 10, val func loss 1.8270330429077148\n",
      "\n",
      "episode 11, val func loss 1.5558677911758423\n",
      "\n",
      "episode 12, val func loss 1.559410572052002\n",
      "\n",
      "episode 13, val func loss 1.7489395141601562\n",
      "\n",
      "episode 14, val func loss 1.5000990629196167\n",
      "\n",
      "episode 15, val func loss 1.5562371015548706\n",
      "\n",
      "episode 16, val func loss 1.7958827018737793\n",
      "\n",
      "Val func train loss in epoch 2:1.6170760467648506\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.5835692882537842\n",
      "\n",
      "episode 2, val func loss 1.6264663934707642\n",
      "\n",
      "episode 3, val func loss 1.5885813236236572\n",
      "\n",
      "episode 4, val func loss 1.4855494499206543\n",
      "\n",
      "episode 5, val func loss 1.6766586303710938\n",
      "\n",
      "episode 6, val func loss 1.4825879335403442\n",
      "\n",
      "episode 7, val func loss 1.4021480083465576\n",
      "\n",
      "episode 8, val func loss 1.6629234552383423\n",
      "\n",
      "episode 9, val func loss 1.6018575429916382\n",
      "\n",
      "episode 10, val func loss 1.6065778732299805\n",
      "\n",
      "episode 11, val func loss 1.5057473182678223\n",
      "\n",
      "episode 12, val func loss 1.6089272499084473\n",
      "\n",
      "episode 13, val func loss 1.6969103813171387\n",
      "\n",
      "episode 14, val func loss 1.5789669752120972\n",
      "\n",
      "episode 15, val func loss 1.7046566009521484\n",
      "\n",
      "episode 16, val func loss 1.80852210521698\n",
      "\n",
      "Val func train loss in epoch 3:1.6012906581163406\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.6630592346191406\n",
      "\n",
      "episode 2, val func loss 1.788849115371704\n",
      "\n",
      "episode 3, val func loss 1.816588044166565\n",
      "\n",
      "episode 4, val func loss 1.7455562353134155\n",
      "\n",
      "episode 5, val func loss 1.6366660594940186\n",
      "\n",
      "episode 6, val func loss 1.9101630449295044\n",
      "\n",
      "episode 7, val func loss 1.7798779010772705\n",
      "\n",
      "episode 8, val func loss 1.7315196990966797\n",
      "\n",
      "episode 9, val func loss 1.7188161611557007\n",
      "\n",
      "episode 10, val func loss 1.7175581455230713\n",
      "\n",
      "episode 11, val func loss 1.6557285785675049\n",
      "\n",
      "episode 12, val func loss 1.6399238109588623\n",
      "\n",
      "episode 13, val func loss 1.713735818862915\n",
      "\n",
      "episode 14, val func loss 1.7177700996398926\n",
      "\n",
      "episode 15, val func loss 1.6893343925476074\n",
      "\n",
      "episode 16, val func loss 1.6832003593444824\n",
      "\n",
      "Val func train loss in epoch 4:1.725521668791771\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.7424235343933105\n",
      "\n",
      "episode 2, val func loss 1.7592833042144775\n",
      "\n",
      "episode 3, val func loss 1.556728720664978\n",
      "\n",
      "episode 4, val func loss 1.5989998579025269\n",
      "\n",
      "episode 5, val func loss 1.6104825735092163\n",
      "\n",
      "episode 6, val func loss 1.738189935684204\n",
      "\n",
      "episode 7, val func loss 1.7616173028945923\n",
      "\n",
      "episode 8, val func loss 1.650160312652588\n",
      "\n",
      "episode 9, val func loss 1.6475898027420044\n",
      "\n",
      "episode 10, val func loss 1.649539589881897\n",
      "\n",
      "episode 11, val func loss 1.5226151943206787\n",
      "\n",
      "episode 12, val func loss 1.5775997638702393\n",
      "\n",
      "episode 13, val func loss 1.6638317108154297\n",
      "\n",
      "episode 14, val func loss 1.5058610439300537\n",
      "\n",
      "episode 15, val func loss 1.637879729270935\n",
      "\n",
      "episode 16, val func loss 1.7106202840805054\n",
      "\n",
      "Val func train loss in epoch 5:1.6458389163017273\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.7610751390457153\n",
      "\n",
      "episode 2, val func loss 1.6014288663864136\n",
      "\n",
      "episode 3, val func loss 1.6763501167297363\n",
      "\n",
      "episode 4, val func loss 1.6955490112304688\n",
      "\n",
      "episode 5, val func loss 1.655474305152893\n",
      "\n",
      "episode 6, val func loss 1.658860445022583\n",
      "\n",
      "episode 7, val func loss 1.6376240253448486\n",
      "\n",
      "episode 8, val func loss 1.809490442276001\n",
      "\n",
      "episode 9, val func loss 1.6934746503829956\n",
      "\n",
      "episode 10, val func loss 1.6356377601623535\n",
      "\n",
      "episode 11, val func loss 1.6517480611801147\n",
      "\n",
      "episode 12, val func loss 1.7626430988311768\n",
      "\n",
      "episode 13, val func loss 1.6657755374908447\n",
      "\n",
      "episode 14, val func loss 1.5031046867370605\n",
      "\n",
      "episode 15, val func loss 1.7661045789718628\n",
      "\n",
      "episode 16, val func loss 1.7319700717926025\n",
      "\n",
      "Val func train loss in epoch 6:1.6816444247961044\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.5164473056793213\n",
      "\n",
      "episode 2, val func loss 1.7774196863174438\n",
      "\n",
      "episode 3, val func loss 1.496665596961975\n",
      "\n",
      "episode 4, val func loss 1.6586017608642578\n",
      "\n",
      "episode 5, val func loss 1.7774044275283813\n",
      "\n",
      "episode 6, val func loss 1.6730681657791138\n",
      "\n",
      "episode 7, val func loss 1.4390618801116943\n",
      "\n",
      "episode 8, val func loss 1.6556878089904785\n",
      "\n",
      "episode 9, val func loss 1.727481484413147\n",
      "\n",
      "episode 10, val func loss 1.582175612449646\n",
      "\n",
      "episode 11, val func loss 1.4698619842529297\n",
      "\n",
      "episode 12, val func loss 1.3812332153320312\n",
      "\n",
      "episode 13, val func loss 1.47869074344635\n",
      "\n",
      "episode 14, val func loss 1.4138240814208984\n",
      "\n",
      "episode 15, val func loss 1.5549471378326416\n",
      "\n",
      "episode 16, val func loss 1.5878952741622925\n",
      "\n",
      "Val func train loss in epoch 7:1.5744041353464127\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.6196528673171997\n",
      "\n",
      "episode 2, val func loss 1.6902270317077637\n",
      "\n",
      "episode 3, val func loss 1.7647204399108887\n",
      "\n",
      "episode 4, val func loss 1.4947357177734375\n",
      "\n",
      "episode 5, val func loss 1.5943145751953125\n",
      "\n",
      "episode 6, val func loss 1.7804526090621948\n",
      "\n",
      "episode 7, val func loss 1.6142319440841675\n",
      "\n",
      "episode 8, val func loss 1.539206624031067\n",
      "\n",
      "episode 9, val func loss 1.622674584388733\n",
      "\n",
      "episode 10, val func loss 1.5022399425506592\n",
      "\n",
      "episode 11, val func loss 1.737319827079773\n",
      "\n",
      "episode 12, val func loss 1.5805879831314087\n",
      "\n",
      "episode 13, val func loss 1.5123969316482544\n",
      "\n",
      "episode 14, val func loss 1.7174437046051025\n",
      "\n",
      "episode 15, val func loss 1.655571460723877\n",
      "\n",
      "episode 16, val func loss 1.7768633365631104\n",
      "\n",
      "Val func train loss in epoch 8:1.6376649737358093\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.5764681100845337\n",
      "\n",
      "episode 2, val func loss 1.6135894060134888\n",
      "\n",
      "episode 3, val func loss 1.4978687763214111\n",
      "\n",
      "episode 4, val func loss 1.5613605976104736\n",
      "\n",
      "episode 5, val func loss 1.4917157888412476\n",
      "\n",
      "episode 6, val func loss 1.7254196405410767\n",
      "\n",
      "episode 7, val func loss 1.6042331457138062\n",
      "\n",
      "episode 8, val func loss 1.516249656677246\n",
      "\n",
      "episode 9, val func loss 1.6331257820129395\n",
      "\n",
      "episode 10, val func loss 1.5472406148910522\n",
      "\n",
      "episode 11, val func loss 1.6270742416381836\n",
      "\n",
      "episode 12, val func loss 1.7710946798324585\n",
      "\n",
      "episode 13, val func loss 1.776389241218567\n",
      "\n",
      "episode 14, val func loss 1.6346626281738281\n",
      "\n",
      "episode 15, val func loss 1.6020292043685913\n",
      "\n",
      "episode 16, val func loss 1.89229154586792\n",
      "\n",
      "Val func train loss in epoch 9:1.6294258162379265\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.6503409147262573\n",
      "\n",
      "episode 2, val func loss 1.9836286306381226\n",
      "\n",
      "episode 3, val func loss 1.5201791524887085\n",
      "\n",
      "episode 4, val func loss 1.6585955619812012\n",
      "\n",
      "episode 5, val func loss 1.6641674041748047\n",
      "\n",
      "episode 6, val func loss 1.753968596458435\n",
      "\n",
      "episode 7, val func loss 1.6501617431640625\n",
      "\n",
      "episode 8, val func loss 1.7229148149490356\n",
      "\n",
      "episode 9, val func loss 1.748152732849121\n",
      "\n",
      "episode 10, val func loss 1.5626024007797241\n",
      "\n",
      "episode 11, val func loss 1.763247013092041\n",
      "\n",
      "episode 12, val func loss 1.6992754936218262\n",
      "\n",
      "episode 13, val func loss 1.5942401885986328\n",
      "\n",
      "episode 14, val func loss 1.6127471923828125\n",
      "\n",
      "episode 15, val func loss 1.6179512739181519\n",
      "\n",
      "episode 16, val func loss 1.4403331279754639\n",
      "\n",
      "Val func train loss in epoch 10:1.6651566401124\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.6306207180023193\n",
      "\n",
      "episode 2, val func loss 1.765085220336914\n",
      "\n",
      "episode 3, val func loss 1.628236174583435\n",
      "\n",
      "episode 4, val func loss 1.6533116102218628\n",
      "\n",
      "episode 5, val func loss 1.3738806247711182\n",
      "\n",
      "episode 6, val func loss 1.5863109827041626\n",
      "\n",
      "episode 7, val func loss 1.5887786149978638\n",
      "\n",
      "episode 8, val func loss 1.595159649848938\n",
      "\n",
      "episode 9, val func loss 1.505858063697815\n",
      "\n",
      "episode 10, val func loss 1.6032519340515137\n",
      "\n",
      "episode 11, val func loss 1.661075472831726\n",
      "\n",
      "episode 12, val func loss 1.8709806203842163\n",
      "\n",
      "episode 13, val func loss 1.6060998439788818\n",
      "\n",
      "episode 14, val func loss 1.6105964183807373\n",
      "\n",
      "episode 15, val func loss 1.8048930168151855\n",
      "\n",
      "episode 16, val func loss 1.7772927284240723\n",
      "\n",
      "Val func train loss in epoch 11:1.6413394808769226\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.7372307777404785\n",
      "\n",
      "episode 2, val func loss 1.6828075647354126\n",
      "\n",
      "episode 3, val func loss 1.4988189935684204\n",
      "\n",
      "episode 4, val func loss 1.670383334159851\n",
      "\n",
      "episode 5, val func loss 1.7037556171417236\n",
      "\n",
      "episode 6, val func loss 1.707816481590271\n",
      "\n",
      "episode 7, val func loss 1.8985954523086548\n",
      "\n",
      "episode 8, val func loss 1.6379178762435913\n",
      "\n",
      "episode 9, val func loss 2.01595401763916\n",
      "\n",
      "episode 10, val func loss 1.6839687824249268\n",
      "\n",
      "episode 11, val func loss 1.5423943996429443\n",
      "\n",
      "episode 12, val func loss 1.4131078720092773\n",
      "\n",
      "episode 13, val func loss 1.8035904169082642\n",
      "\n",
      "episode 14, val func loss 1.5904501676559448\n",
      "\n",
      "episode 15, val func loss 1.6542441844940186\n",
      "\n",
      "episode 16, val func loss 1.6757938861846924\n",
      "\n",
      "Val func train loss in epoch 12:1.682301864027977\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.6911582946777344\n",
      "\n",
      "episode 2, val func loss 1.5220521688461304\n",
      "\n",
      "episode 3, val func loss 1.608020305633545\n",
      "\n",
      "episode 4, val func loss 1.513564109802246\n",
      "\n",
      "episode 5, val func loss 1.5533610582351685\n",
      "\n",
      "episode 6, val func loss 1.6105866432189941\n",
      "\n",
      "episode 7, val func loss 1.4656739234924316\n",
      "\n",
      "episode 8, val func loss 1.6944681406021118\n",
      "\n",
      "episode 9, val func loss 1.5973069667816162\n",
      "\n",
      "episode 10, val func loss 1.7325247526168823\n",
      "\n",
      "episode 11, val func loss 1.5817043781280518\n",
      "\n",
      "episode 12, val func loss 1.5422649383544922\n",
      "\n",
      "episode 13, val func loss 1.77786123752594\n",
      "\n",
      "episode 14, val func loss 1.4381654262542725\n",
      "\n",
      "episode 15, val func loss 1.6187623739242554\n",
      "\n",
      "episode 16, val func loss 1.6548690795898438\n",
      "\n",
      "Val func train loss in epoch 13:1.6001464873552322\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.6836872100830078\n",
      "\n",
      "episode 2, val func loss 1.6514688730239868\n",
      "\n",
      "episode 3, val func loss 1.7125407457351685\n",
      "\n",
      "episode 4, val func loss 1.5251421928405762\n",
      "\n",
      "episode 5, val func loss 1.605863332748413\n",
      "\n",
      "episode 6, val func loss 1.6071369647979736\n",
      "\n",
      "episode 7, val func loss 1.7507158517837524\n",
      "\n",
      "episode 8, val func loss 1.6321033239364624\n",
      "\n",
      "episode 9, val func loss 1.5429071187973022\n",
      "\n",
      "episode 10, val func loss 1.504744052886963\n",
      "\n",
      "episode 11, val func loss 1.6450084447860718\n",
      "\n",
      "episode 12, val func loss 1.644574761390686\n",
      "\n",
      "episode 13, val func loss 1.89479398727417\n",
      "\n",
      "episode 14, val func loss 1.5291476249694824\n",
      "\n",
      "episode 15, val func loss 1.6894805431365967\n",
      "\n",
      "episode 16, val func loss 1.57172691822052\n",
      "\n",
      "Val func train loss in epoch 14:1.6369401216506958\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.6930418014526367\n",
      "\n",
      "episode 2, val func loss 1.5796505212783813\n",
      "\n",
      "episode 3, val func loss 1.594311237335205\n",
      "\n",
      "episode 4, val func loss 1.5264511108398438\n",
      "\n",
      "episode 5, val func loss 1.657326102256775\n",
      "\n",
      "episode 6, val func loss 1.713655948638916\n",
      "\n",
      "episode 7, val func loss 1.5686254501342773\n",
      "\n",
      "episode 8, val func loss 1.4955337047576904\n",
      "\n",
      "episode 9, val func loss 1.7174572944641113\n",
      "\n",
      "episode 10, val func loss 1.6708301305770874\n",
      "\n",
      "episode 11, val func loss 1.6346765756607056\n",
      "\n",
      "episode 12, val func loss 1.7007873058319092\n",
      "\n",
      "episode 13, val func loss 1.6408427953720093\n",
      "\n",
      "episode 14, val func loss 1.5811867713928223\n",
      "\n",
      "episode 15, val func loss 1.6693592071533203\n",
      "\n",
      "episode 16, val func loss 1.455618143081665\n",
      "\n",
      "Val func train loss in epoch 15:1.6187096312642097\n",
      "***********************TIME WAS 4.813747111956278 min*****************************\n",
      "\n",
      "**********************ROUND 26 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.336479902267456\n",
      "\n",
      "episode 2, policy loss -2.336479902267456\n",
      "\n",
      "episode 3, policy loss -2.336479902267456\n",
      "\n",
      "episode 4, policy loss -2.336479663848877\n",
      "\n",
      "episode 5, policy loss -2.336480140686035\n",
      "\n",
      "episode 6, policy loss -2.336479902267456\n",
      "\n",
      "episode 7, policy loss -2.336479902267456\n",
      "\n",
      "episode 8, policy loss -2.336479902267456\n",
      "\n",
      "episode 9, policy loss -2.336479902267456\n",
      "\n",
      "episode 10, policy loss -2.336479902267456\n",
      "\n",
      "episode 11, policy loss -2.336479663848877\n",
      "\n",
      "episode 12, policy loss -2.336479902267456\n",
      "\n",
      "episode 13, policy loss -2.336479663848877\n",
      "\n",
      "episode 14, policy loss -2.336480140686035\n",
      "\n",
      "episode 15, policy loss -2.336480140686035\n",
      "\n",
      "episode 16, policy loss -2.336480140686035\n",
      "\n",
      "Policy train loss in epoch 0:-2.3364799171686172\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.336479663848877\n",
      "\n",
      "episode 2, policy loss -2.336479663848877\n",
      "\n",
      "episode 3, policy loss -2.336480140686035\n",
      "\n",
      "episode 4, policy loss -2.336479902267456\n",
      "\n",
      "episode 5, policy loss -2.336479902267456\n",
      "\n",
      "episode 6, policy loss -2.336480140686035\n",
      "\n",
      "episode 7, policy loss -2.336479663848877\n",
      "\n",
      "episode 8, policy loss -2.336479902267456\n",
      "\n",
      "episode 9, policy loss -2.336479902267456\n",
      "\n",
      "episode 10, policy loss -2.336480140686035\n",
      "\n",
      "episode 11, policy loss -2.336480140686035\n",
      "\n",
      "episode 12, policy loss -2.336479902267456\n",
      "\n",
      "episode 13, policy loss -2.336479902267456\n",
      "\n",
      "episode 14, policy loss -2.336479902267456\n",
      "\n",
      "episode 15, policy loss -2.336479902267456\n",
      "\n",
      "episode 16, policy loss -2.336479902267456\n",
      "\n",
      "Policy train loss in epoch 1:-2.3364799171686172\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.336479902267456\n",
      "\n",
      "episode 2, policy loss -2.336480140686035\n",
      "\n",
      "episode 3, policy loss -2.336479902267456\n",
      "\n",
      "episode 4, policy loss -2.336479663848877\n",
      "\n",
      "episode 5, policy loss -2.336480140686035\n",
      "\n",
      "episode 6, policy loss -2.336479902267456\n",
      "\n",
      "episode 7, policy loss -2.336479902267456\n",
      "\n",
      "episode 8, policy loss -2.336480140686035\n",
      "\n",
      "episode 9, policy loss -2.336479902267456\n",
      "\n",
      "episode 10, policy loss -2.336479663848877\n",
      "\n",
      "episode 11, policy loss -2.336479902267456\n",
      "\n",
      "episode 12, policy loss -2.336479663848877\n",
      "\n",
      "episode 13, policy loss -2.336480140686035\n",
      "\n",
      "episode 14, policy loss -2.336479902267456\n",
      "\n",
      "episode 15, policy loss -2.336479902267456\n",
      "\n",
      "episode 16, policy loss -2.336479902267456\n",
      "\n",
      "Policy train loss in epoch 2:-2.3364799171686172\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.336479902267456\n",
      "\n",
      "episode 2, policy loss -2.336480140686035\n",
      "\n",
      "episode 3, policy loss -2.336479663848877\n",
      "\n",
      "episode 4, policy loss -2.336479902267456\n",
      "\n",
      "episode 5, policy loss -2.336479663848877\n",
      "\n",
      "episode 6, policy loss -2.336480140686035\n",
      "\n",
      "episode 7, policy loss -2.336479902267456\n",
      "\n",
      "episode 8, policy loss -2.336480140686035\n",
      "\n",
      "episode 9, policy loss -2.336479663848877\n",
      "\n",
      "episode 10, policy loss -2.336479902267456\n",
      "\n",
      "episode 11, policy loss -2.336479902267456\n",
      "\n",
      "episode 12, policy loss -2.336479902267456\n",
      "\n",
      "episode 13, policy loss -2.336480140686035\n",
      "\n",
      "episode 14, policy loss -2.336479902267456\n",
      "\n",
      "episode 15, policy loss -2.336479902267456\n",
      "\n",
      "episode 16, policy loss -2.336479902267456\n",
      "\n",
      "Policy train loss in epoch 3:-2.3364799171686172\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.6690788269042969\n",
      "\n",
      "episode 2, val func loss 1.5096800327301025\n",
      "\n",
      "episode 3, val func loss 1.5552295446395874\n",
      "\n",
      "episode 4, val func loss 1.7679966688156128\n",
      "\n",
      "episode 5, val func loss 1.8226962089538574\n",
      "\n",
      "episode 6, val func loss 1.6813201904296875\n",
      "\n",
      "episode 7, val func loss 1.6157894134521484\n",
      "\n",
      "episode 8, val func loss 1.65537428855896\n",
      "\n",
      "episode 9, val func loss 1.664729118347168\n",
      "\n",
      "episode 10, val func loss 1.6744489669799805\n",
      "\n",
      "episode 11, val func loss 1.5753498077392578\n",
      "\n",
      "episode 12, val func loss 1.6160948276519775\n",
      "\n",
      "episode 13, val func loss 1.655025839805603\n",
      "\n",
      "episode 14, val func loss 1.671244502067566\n",
      "\n",
      "episode 15, val func loss 1.6207342147827148\n",
      "\n",
      "episode 16, val func loss 1.7299541234970093\n",
      "\n",
      "Val func train loss in epoch 0:1.6552966609597206\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.726472020149231\n",
      "\n",
      "episode 2, val func loss 1.4967790842056274\n",
      "\n",
      "episode 3, val func loss 1.671448826789856\n",
      "\n",
      "episode 4, val func loss 1.5088106393814087\n",
      "\n",
      "episode 5, val func loss 1.6985054016113281\n",
      "\n",
      "episode 6, val func loss 1.7934972047805786\n",
      "\n",
      "episode 7, val func loss 1.5109857320785522\n",
      "\n",
      "episode 8, val func loss 1.6846494674682617\n",
      "\n",
      "episode 9, val func loss 1.5852659940719604\n",
      "\n",
      "episode 10, val func loss 1.5376709699630737\n",
      "\n",
      "episode 11, val func loss 1.5670216083526611\n",
      "\n",
      "episode 12, val func loss 1.6262264251708984\n",
      "\n",
      "episode 13, val func loss 1.6846541166305542\n",
      "\n",
      "episode 14, val func loss 1.572898030281067\n",
      "\n",
      "episode 15, val func loss 1.6732372045516968\n",
      "\n",
      "episode 16, val func loss 1.407618522644043\n",
      "\n",
      "Val func train loss in epoch 1:1.609108828008175\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.7106916904449463\n",
      "\n",
      "episode 2, val func loss 1.6357786655426025\n",
      "\n",
      "episode 3, val func loss 1.5099329948425293\n",
      "\n",
      "episode 4, val func loss 1.5452548265457153\n",
      "\n",
      "episode 5, val func loss 1.5727871656417847\n",
      "\n",
      "episode 6, val func loss 1.8551350831985474\n",
      "\n",
      "episode 7, val func loss 1.3877867460250854\n",
      "\n",
      "episode 8, val func loss 1.5266209840774536\n",
      "\n",
      "episode 9, val func loss 1.643446922302246\n",
      "\n",
      "episode 10, val func loss 1.7573003768920898\n",
      "\n",
      "episode 11, val func loss 1.6918835639953613\n",
      "\n",
      "episode 12, val func loss 1.7362772226333618\n",
      "\n",
      "episode 13, val func loss 1.559634804725647\n",
      "\n",
      "episode 14, val func loss 1.8081825971603394\n",
      "\n",
      "episode 15, val func loss 1.6167291402816772\n",
      "\n",
      "episode 16, val func loss 1.711329460144043\n",
      "\n",
      "Val func train loss in epoch 2:1.6417982652783394\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.7234300374984741\n",
      "\n",
      "episode 2, val func loss 1.653364658355713\n",
      "\n",
      "episode 3, val func loss 1.7558318376541138\n",
      "\n",
      "episode 4, val func loss 1.6843137741088867\n",
      "\n",
      "episode 5, val func loss 1.3979473114013672\n",
      "\n",
      "episode 6, val func loss 1.7458566427230835\n",
      "\n",
      "episode 7, val func loss 1.6717524528503418\n",
      "\n",
      "episode 8, val func loss 1.87107515335083\n",
      "\n",
      "episode 9, val func loss 1.8624297380447388\n",
      "\n",
      "episode 10, val func loss 1.7428723573684692\n",
      "\n",
      "episode 11, val func loss 1.571388602256775\n",
      "\n",
      "episode 12, val func loss 1.640973448753357\n",
      "\n",
      "episode 13, val func loss 1.5800611972808838\n",
      "\n",
      "episode 14, val func loss 1.5459338426589966\n",
      "\n",
      "episode 15, val func loss 1.7412868738174438\n",
      "\n",
      "episode 16, val func loss 1.5910992622375488\n",
      "\n",
      "Val func train loss in epoch 3:1.673726074397564\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.903332233428955\n",
      "\n",
      "episode 2, val func loss 1.6680076122283936\n",
      "\n",
      "episode 3, val func loss 1.585086703300476\n",
      "\n",
      "episode 4, val func loss 1.5658016204833984\n",
      "\n",
      "episode 5, val func loss 1.62302827835083\n",
      "\n",
      "episode 6, val func loss 1.64939546585083\n",
      "\n",
      "episode 7, val func loss 2.121189594268799\n",
      "\n",
      "episode 8, val func loss 1.8317089080810547\n",
      "\n",
      "episode 9, val func loss 1.7216695547103882\n",
      "\n",
      "episode 10, val func loss 1.501091718673706\n",
      "\n",
      "episode 11, val func loss 1.8595550060272217\n",
      "\n",
      "episode 12, val func loss 1.6090147495269775\n",
      "\n",
      "episode 13, val func loss 1.477638602256775\n",
      "\n",
      "episode 14, val func loss 1.6845165491104126\n",
      "\n",
      "episode 15, val func loss 1.668826937675476\n",
      "\n",
      "episode 16, val func loss 1.8214818239212036\n",
      "\n",
      "Val func train loss in epoch 4:1.705709084868431\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.8552496433258057\n",
      "\n",
      "episode 2, val func loss 1.7532581090927124\n",
      "\n",
      "episode 3, val func loss 1.6186679601669312\n",
      "\n",
      "episode 4, val func loss 1.7251265048980713\n",
      "\n",
      "episode 5, val func loss 1.7790420055389404\n",
      "\n",
      "episode 6, val func loss 1.6536248922348022\n",
      "\n",
      "episode 7, val func loss 1.6514090299606323\n",
      "\n",
      "episode 8, val func loss 1.8861804008483887\n",
      "\n",
      "episode 9, val func loss 1.5293009281158447\n",
      "\n",
      "episode 10, val func loss 1.923787236213684\n",
      "\n",
      "episode 11, val func loss 1.823580026626587\n",
      "\n",
      "episode 12, val func loss 1.6496347188949585\n",
      "\n",
      "episode 13, val func loss 1.7137606143951416\n",
      "\n",
      "episode 14, val func loss 1.5403343439102173\n",
      "\n",
      "episode 15, val func loss 1.7447946071624756\n",
      "\n",
      "episode 16, val func loss 1.5886421203613281\n",
      "\n",
      "Val func train loss in epoch 5:1.7147745713591576\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.6475802659988403\n",
      "\n",
      "episode 2, val func loss 1.6998579502105713\n",
      "\n",
      "episode 3, val func loss 1.7206840515136719\n",
      "\n",
      "episode 4, val func loss 1.8804374933242798\n",
      "\n",
      "episode 5, val func loss 1.660874605178833\n",
      "\n",
      "episode 6, val func loss 1.6817113161087036\n",
      "\n",
      "episode 7, val func loss 1.6330641508102417\n",
      "\n",
      "episode 8, val func loss 1.6387180089950562\n",
      "\n",
      "episode 9, val func loss 1.7662546634674072\n",
      "\n",
      "episode 10, val func loss 1.7299516201019287\n",
      "\n",
      "episode 11, val func loss 1.5648950338363647\n",
      "\n",
      "episode 12, val func loss 1.688547968864441\n",
      "\n",
      "episode 13, val func loss 1.7245503664016724\n",
      "\n",
      "episode 14, val func loss 1.6513644456863403\n",
      "\n",
      "episode 15, val func loss 1.7433185577392578\n",
      "\n",
      "episode 16, val func loss 1.76152503490448\n",
      "\n",
      "Val func train loss in epoch 6:1.6995834708213806\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.5826656818389893\n",
      "\n",
      "episode 2, val func loss 1.5707173347473145\n",
      "\n",
      "episode 3, val func loss 1.692436933517456\n",
      "\n",
      "episode 4, val func loss 1.4457846879959106\n",
      "\n",
      "episode 5, val func loss 1.6958953142166138\n",
      "\n",
      "episode 6, val func loss 1.893945336341858\n",
      "\n",
      "episode 7, val func loss 1.7826379537582397\n",
      "\n",
      "episode 8, val func loss 1.6840574741363525\n",
      "\n",
      "episode 9, val func loss 1.7137491703033447\n",
      "\n",
      "episode 10, val func loss 1.5803430080413818\n",
      "\n",
      "episode 11, val func loss 1.4503275156021118\n",
      "\n",
      "episode 12, val func loss 1.510481595993042\n",
      "\n",
      "episode 13, val func loss 1.6499826908111572\n",
      "\n",
      "episode 14, val func loss 1.5713093280792236\n",
      "\n",
      "episode 15, val func loss 1.9025076627731323\n",
      "\n",
      "episode 16, val func loss 1.6609992980957031\n",
      "\n",
      "Val func train loss in epoch 7:1.6492400616407394\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.7199290990829468\n",
      "\n",
      "episode 2, val func loss 1.8648748397827148\n",
      "\n",
      "episode 3, val func loss 1.7694944143295288\n",
      "\n",
      "episode 4, val func loss 1.6503444910049438\n",
      "\n",
      "episode 5, val func loss 1.8421685695648193\n",
      "\n",
      "episode 6, val func loss 1.5372563600540161\n",
      "\n",
      "episode 7, val func loss 1.6537449359893799\n",
      "\n",
      "episode 8, val func loss 1.8145864009857178\n",
      "\n",
      "episode 9, val func loss 1.7813321352005005\n",
      "\n",
      "episode 10, val func loss 1.8537744283676147\n",
      "\n",
      "episode 11, val func loss 1.7147117853164673\n",
      "\n",
      "episode 12, val func loss 1.7800837755203247\n",
      "\n",
      "episode 13, val func loss 1.7101902961730957\n",
      "\n",
      "episode 14, val func loss 1.4144718647003174\n",
      "\n",
      "episode 15, val func loss 1.7692124843597412\n",
      "\n",
      "episode 16, val func loss 1.5796263217926025\n",
      "\n",
      "Val func train loss in epoch 8:1.7159876376390457\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.654015064239502\n",
      "\n",
      "episode 2, val func loss 1.5478039979934692\n",
      "\n",
      "episode 3, val func loss 1.5969915390014648\n",
      "\n",
      "episode 4, val func loss 1.4928847551345825\n",
      "\n",
      "episode 5, val func loss 1.4777984619140625\n",
      "\n",
      "episode 6, val func loss 1.7006016969680786\n",
      "\n",
      "episode 7, val func loss 1.5771007537841797\n",
      "\n",
      "episode 8, val func loss 1.711498498916626\n",
      "\n",
      "episode 9, val func loss 1.5248035192489624\n",
      "\n",
      "episode 10, val func loss 1.429944634437561\n",
      "\n",
      "episode 11, val func loss 1.487967848777771\n",
      "\n",
      "episode 12, val func loss 1.7832984924316406\n",
      "\n",
      "episode 13, val func loss 1.8423218727111816\n",
      "\n",
      "episode 14, val func loss 1.5487436056137085\n",
      "\n",
      "episode 15, val func loss 1.6472824811935425\n",
      "\n",
      "episode 16, val func loss 1.6899971961975098\n",
      "\n",
      "Val func train loss in epoch 9:1.6070659011602402\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.852344274520874\n",
      "\n",
      "episode 2, val func loss 1.735653281211853\n",
      "\n",
      "episode 3, val func loss 1.4634912014007568\n",
      "\n",
      "episode 4, val func loss 1.585286021232605\n",
      "\n",
      "episode 5, val func loss 1.5473525524139404\n",
      "\n",
      "episode 6, val func loss 1.6711552143096924\n",
      "\n",
      "episode 7, val func loss 1.5519362688064575\n",
      "\n",
      "episode 8, val func loss 1.7138856649398804\n",
      "\n",
      "episode 9, val func loss 1.6322182416915894\n",
      "\n",
      "episode 10, val func loss 1.7738558053970337\n",
      "\n",
      "episode 11, val func loss 1.3996034860610962\n",
      "\n",
      "episode 12, val func loss 1.5364073514938354\n",
      "\n",
      "episode 13, val func loss 1.764660120010376\n",
      "\n",
      "episode 14, val func loss 1.5628780126571655\n",
      "\n",
      "episode 15, val func loss 1.4015235900878906\n",
      "\n",
      "episode 16, val func loss 1.6874909400939941\n",
      "\n",
      "Val func train loss in epoch 10:1.617483876645565\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.703902244567871\n",
      "\n",
      "episode 2, val func loss 1.6789885759353638\n",
      "\n",
      "episode 3, val func loss 1.7515416145324707\n",
      "\n",
      "episode 4, val func loss 1.6881942749023438\n",
      "\n",
      "episode 5, val func loss 1.5310100317001343\n",
      "\n",
      "episode 6, val func loss 1.5584564208984375\n",
      "\n",
      "episode 7, val func loss 1.5352107286453247\n",
      "\n",
      "episode 8, val func loss 1.79396653175354\n",
      "\n",
      "episode 9, val func loss 1.781426191329956\n",
      "\n",
      "episode 10, val func loss 1.3802547454833984\n",
      "\n",
      "episode 11, val func loss 1.839337944984436\n",
      "\n",
      "episode 12, val func loss 1.5857348442077637\n",
      "\n",
      "episode 13, val func loss 1.9966094493865967\n",
      "\n",
      "episode 14, val func loss 1.7757818698883057\n",
      "\n",
      "episode 15, val func loss 1.5704759359359741\n",
      "\n",
      "episode 16, val func loss 1.4742587804794312\n",
      "\n",
      "Val func train loss in epoch 11:1.6653218865394592\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.685477375984192\n",
      "\n",
      "episode 2, val func loss 1.5904808044433594\n",
      "\n",
      "episode 3, val func loss 1.8417836427688599\n",
      "\n",
      "episode 4, val func loss 1.526284098625183\n",
      "\n",
      "episode 5, val func loss 1.5413910150527954\n",
      "\n",
      "episode 6, val func loss 1.4959759712219238\n",
      "\n",
      "episode 7, val func loss 1.8533833026885986\n",
      "\n",
      "episode 8, val func loss 1.8042075634002686\n",
      "\n",
      "episode 9, val func loss 1.5389670133590698\n",
      "\n",
      "episode 10, val func loss 1.429192304611206\n",
      "\n",
      "episode 11, val func loss 1.6574113368988037\n",
      "\n",
      "episode 12, val func loss 1.5420340299606323\n",
      "\n",
      "episode 13, val func loss 1.7471754550933838\n",
      "\n",
      "episode 14, val func loss 1.8172229528427124\n",
      "\n",
      "episode 15, val func loss 1.5724142789840698\n",
      "\n",
      "episode 16, val func loss 1.5834439992904663\n",
      "\n",
      "Val func train loss in epoch 12:1.6391778215765953\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.441845178604126\n",
      "\n",
      "episode 2, val func loss 1.4888219833374023\n",
      "\n",
      "episode 3, val func loss 1.6204800605773926\n",
      "\n",
      "episode 4, val func loss 1.526480793952942\n",
      "\n",
      "episode 5, val func loss 1.5906168222427368\n",
      "\n",
      "episode 6, val func loss 1.6211923360824585\n",
      "\n",
      "episode 7, val func loss 1.5914311408996582\n",
      "\n",
      "episode 8, val func loss 1.53228759765625\n",
      "\n",
      "episode 9, val func loss 1.549850344657898\n",
      "\n",
      "episode 10, val func loss 1.7978575229644775\n",
      "\n",
      "episode 11, val func loss 1.6590417623519897\n",
      "\n",
      "episode 12, val func loss 1.5355572700500488\n",
      "\n",
      "episode 13, val func loss 1.6176189184188843\n",
      "\n",
      "episode 14, val func loss 1.8818811178207397\n",
      "\n",
      "episode 15, val func loss 1.7236162424087524\n",
      "\n",
      "episode 16, val func loss 1.6607962846755981\n",
      "\n",
      "Val func train loss in epoch 13:1.6149609610438347\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.713881015777588\n",
      "\n",
      "episode 2, val func loss 1.613383412361145\n",
      "\n",
      "episode 3, val func loss 1.534372329711914\n",
      "\n",
      "episode 4, val func loss 1.5996068716049194\n",
      "\n",
      "episode 5, val func loss 1.5748573541641235\n",
      "\n",
      "episode 6, val func loss 1.749006748199463\n",
      "\n",
      "episode 7, val func loss 1.6495494842529297\n",
      "\n",
      "episode 8, val func loss 1.6273412704467773\n",
      "\n",
      "episode 9, val func loss 1.5658377408981323\n",
      "\n",
      "episode 10, val func loss 1.5242915153503418\n",
      "\n",
      "episode 11, val func loss 1.6227047443389893\n",
      "\n",
      "episode 12, val func loss 1.547433614730835\n",
      "\n",
      "episode 13, val func loss 1.6081324815750122\n",
      "\n",
      "episode 14, val func loss 1.734042763710022\n",
      "\n",
      "episode 15, val func loss 1.760398507118225\n",
      "\n",
      "episode 16, val func loss 1.5122522115707397\n",
      "\n",
      "Val func train loss in epoch 14:1.6210682541131973\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.671428918838501\n",
      "\n",
      "episode 2, val func loss 1.4925041198730469\n",
      "\n",
      "episode 3, val func loss 1.746961236000061\n",
      "\n",
      "episode 4, val func loss 1.69838285446167\n",
      "\n",
      "episode 5, val func loss 1.5012540817260742\n",
      "\n",
      "episode 6, val func loss 1.5055431127548218\n",
      "\n",
      "episode 7, val func loss 1.737492322921753\n",
      "\n",
      "episode 8, val func loss 1.589641809463501\n",
      "\n",
      "episode 9, val func loss 1.5240442752838135\n",
      "\n",
      "episode 10, val func loss 1.570130467414856\n",
      "\n",
      "episode 11, val func loss 1.687748670578003\n",
      "\n",
      "episode 12, val func loss 1.651543140411377\n",
      "\n",
      "episode 13, val func loss 1.648402214050293\n",
      "\n",
      "episode 14, val func loss 1.5971869230270386\n",
      "\n",
      "episode 15, val func loss 1.6720483303070068\n",
      "\n",
      "episode 16, val func loss 1.698323130607605\n",
      "\n",
      "Val func train loss in epoch 15:1.6245397254824638\n",
      "***********************TIME WAS 4.836055223147074 min*****************************\n",
      "\n",
      "**********************ROUND 27 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.26016902923584\n",
      "\n",
      "episode 2, policy loss -2.26016902923584\n",
      "\n",
      "episode 3, policy loss -2.26016902923584\n",
      "\n",
      "episode 4, policy loss -2.26016902923584\n",
      "\n",
      "episode 5, policy loss -2.26016902923584\n",
      "\n",
      "episode 6, policy loss -2.26016902923584\n",
      "\n",
      "episode 7, policy loss -2.26016902923584\n",
      "\n",
      "episode 8, policy loss -2.26016902923584\n",
      "\n",
      "episode 9, policy loss -2.260169267654419\n",
      "\n",
      "episode 10, policy loss -2.26016902923584\n",
      "\n",
      "episode 11, policy loss -2.2601687908172607\n",
      "\n",
      "episode 12, policy loss -2.26016902923584\n",
      "\n",
      "episode 13, policy loss -2.26016902923584\n",
      "\n",
      "episode 14, policy loss -2.26016902923584\n",
      "\n",
      "episode 15, policy loss -2.26016902923584\n",
      "\n",
      "episode 16, policy loss -2.26016902923584\n",
      "\n",
      "Policy train loss in epoch 0:-2.26016902923584\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.2601687908172607\n",
      "\n",
      "episode 2, policy loss -2.26016902923584\n",
      "\n",
      "episode 3, policy loss -2.26016902923584\n",
      "\n",
      "episode 4, policy loss -2.26016902923584\n",
      "\n",
      "episode 5, policy loss -2.26016902923584\n",
      "\n",
      "episode 6, policy loss -2.26016902923584\n",
      "\n",
      "episode 7, policy loss -2.26016902923584\n",
      "\n",
      "episode 8, policy loss -2.26016902923584\n",
      "\n",
      "episode 9, policy loss -2.26016902923584\n",
      "\n",
      "episode 10, policy loss -2.26016902923584\n",
      "\n",
      "episode 11, policy loss -2.26016902923584\n",
      "\n",
      "episode 12, policy loss -2.260169267654419\n",
      "\n",
      "episode 13, policy loss -2.26016902923584\n",
      "\n",
      "episode 14, policy loss -2.26016902923584\n",
      "\n",
      "episode 15, policy loss -2.26016902923584\n",
      "\n",
      "episode 16, policy loss -2.26016902923584\n",
      "\n",
      "Policy train loss in epoch 1:-2.26016902923584\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.26016902923584\n",
      "\n",
      "episode 2, policy loss -2.26016902923584\n",
      "\n",
      "episode 3, policy loss -2.26016902923584\n",
      "\n",
      "episode 4, policy loss -2.26016902923584\n",
      "\n",
      "episode 5, policy loss -2.26016902923584\n",
      "\n",
      "episode 6, policy loss -2.26016902923584\n",
      "\n",
      "episode 7, policy loss -2.26016902923584\n",
      "\n",
      "episode 8, policy loss -2.26016902923584\n",
      "\n",
      "episode 9, policy loss -2.260169267654419\n",
      "\n",
      "episode 10, policy loss -2.26016902923584\n",
      "\n",
      "episode 11, policy loss -2.26016902923584\n",
      "\n",
      "episode 12, policy loss -2.26016902923584\n",
      "\n",
      "episode 13, policy loss -2.26016902923584\n",
      "\n",
      "episode 14, policy loss -2.26016902923584\n",
      "\n",
      "episode 15, policy loss -2.2601687908172607\n",
      "\n",
      "episode 16, policy loss -2.26016902923584\n",
      "\n",
      "Policy train loss in epoch 2:-2.26016902923584\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.26016902923584\n",
      "\n",
      "episode 2, policy loss -2.2601687908172607\n",
      "\n",
      "episode 3, policy loss -2.26016902923584\n",
      "\n",
      "episode 4, policy loss -2.260169267654419\n",
      "\n",
      "episode 5, policy loss -2.26016902923584\n",
      "\n",
      "episode 6, policy loss -2.26016902923584\n",
      "\n",
      "episode 7, policy loss -2.26016902923584\n",
      "\n",
      "episode 8, policy loss -2.26016902923584\n",
      "\n",
      "episode 9, policy loss -2.26016902923584\n",
      "\n",
      "episode 10, policy loss -2.26016902923584\n",
      "\n",
      "episode 11, policy loss -2.26016902923584\n",
      "\n",
      "episode 12, policy loss -2.26016902923584\n",
      "\n",
      "episode 13, policy loss -2.26016902923584\n",
      "\n",
      "episode 14, policy loss -2.26016902923584\n",
      "\n",
      "episode 15, policy loss -2.26016902923584\n",
      "\n",
      "episode 16, policy loss -2.26016902923584\n",
      "\n",
      "Policy train loss in epoch 3:-2.26016902923584\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.7390047311782837\n",
      "\n",
      "episode 2, val func loss 1.5852465629577637\n",
      "\n",
      "episode 3, val func loss 1.4028370380401611\n",
      "\n",
      "episode 4, val func loss 1.7237725257873535\n",
      "\n",
      "episode 5, val func loss 1.6339170932769775\n",
      "\n",
      "episode 6, val func loss 1.7081998586654663\n",
      "\n",
      "episode 7, val func loss 1.8015552759170532\n",
      "\n",
      "episode 8, val func loss 1.6981552839279175\n",
      "\n",
      "episode 9, val func loss 1.5757572650909424\n",
      "\n",
      "episode 10, val func loss 1.6947897672653198\n",
      "\n",
      "episode 11, val func loss 1.5564544200897217\n",
      "\n",
      "episode 12, val func loss 1.5558860301971436\n",
      "\n",
      "episode 13, val func loss 1.4671393632888794\n",
      "\n",
      "episode 14, val func loss 1.266300082206726\n",
      "\n",
      "episode 15, val func loss 1.5938621759414673\n",
      "\n",
      "episode 16, val func loss 1.7742600440979004\n",
      "\n",
      "Val func train loss in epoch 0:1.6110710948705673\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.6810213327407837\n",
      "\n",
      "episode 2, val func loss 1.7248936891555786\n",
      "\n",
      "episode 3, val func loss 1.6903377771377563\n",
      "\n",
      "episode 4, val func loss 1.8177828788757324\n",
      "\n",
      "episode 5, val func loss 1.619771957397461\n",
      "\n",
      "episode 6, val func loss 1.5423226356506348\n",
      "\n",
      "episode 7, val func loss 1.4937467575073242\n",
      "\n",
      "episode 8, val func loss 1.553255558013916\n",
      "\n",
      "episode 9, val func loss 1.3999263048171997\n",
      "\n",
      "episode 10, val func loss 1.8428434133529663\n",
      "\n",
      "episode 11, val func loss 1.4484654664993286\n",
      "\n",
      "episode 12, val func loss 1.4769550561904907\n",
      "\n",
      "episode 13, val func loss 1.6716645956039429\n",
      "\n",
      "episode 14, val func loss 1.6332815885543823\n",
      "\n",
      "episode 15, val func loss 1.5666546821594238\n",
      "\n",
      "episode 16, val func loss 1.7898403406143188\n",
      "\n",
      "Val func train loss in epoch 1:1.6220477521419525\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.7286739349365234\n",
      "\n",
      "episode 2, val func loss 1.9483438730239868\n",
      "\n",
      "episode 3, val func loss 1.5861670970916748\n",
      "\n",
      "episode 4, val func loss 1.5776339769363403\n",
      "\n",
      "episode 5, val func loss 1.4655545949935913\n",
      "\n",
      "episode 6, val func loss 1.656083345413208\n",
      "\n",
      "episode 7, val func loss 1.7306102514266968\n",
      "\n",
      "episode 8, val func loss 1.4084612131118774\n",
      "\n",
      "episode 9, val func loss 1.6453615427017212\n",
      "\n",
      "episode 10, val func loss 1.493012547492981\n",
      "\n",
      "episode 11, val func loss 1.4838231801986694\n",
      "\n",
      "episode 12, val func loss 1.6211179494857788\n",
      "\n",
      "episode 13, val func loss 1.525953769683838\n",
      "\n",
      "episode 14, val func loss 1.4280344247817993\n",
      "\n",
      "episode 15, val func loss 1.7931417226791382\n",
      "\n",
      "episode 16, val func loss 1.7297794818878174\n",
      "\n",
      "Val func train loss in epoch 2:1.6138595566153526\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.5179914236068726\n",
      "\n",
      "episode 2, val func loss 1.7211788892745972\n",
      "\n",
      "episode 3, val func loss 1.6619534492492676\n",
      "\n",
      "episode 4, val func loss 1.6815952062606812\n",
      "\n",
      "episode 5, val func loss 1.603304386138916\n",
      "\n",
      "episode 6, val func loss 1.7033575773239136\n",
      "\n",
      "episode 7, val func loss 1.7184553146362305\n",
      "\n",
      "episode 8, val func loss 1.72533118724823\n",
      "\n",
      "episode 9, val func loss 1.8273801803588867\n",
      "\n",
      "episode 10, val func loss 1.6081984043121338\n",
      "\n",
      "episode 11, val func loss 1.4117610454559326\n",
      "\n",
      "episode 12, val func loss 1.6380751132965088\n",
      "\n",
      "episode 13, val func loss 1.6164425611495972\n",
      "\n",
      "episode 14, val func loss 1.6878228187561035\n",
      "\n",
      "episode 15, val func loss 1.729419231414795\n",
      "\n",
      "episode 16, val func loss 1.597922444343567\n",
      "\n",
      "Val func train loss in epoch 3:1.6531368270516396\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.8897550106048584\n",
      "\n",
      "episode 2, val func loss 1.6784144639968872\n",
      "\n",
      "episode 3, val func loss 1.3849360942840576\n",
      "\n",
      "episode 4, val func loss 1.9195599555969238\n",
      "\n",
      "episode 5, val func loss 1.5846327543258667\n",
      "\n",
      "episode 6, val func loss 1.5195658206939697\n",
      "\n",
      "episode 7, val func loss 1.7344801425933838\n",
      "\n",
      "episode 8, val func loss 1.6661224365234375\n",
      "\n",
      "episode 9, val func loss 1.662931203842163\n",
      "\n",
      "episode 10, val func loss 1.3816121816635132\n",
      "\n",
      "episode 11, val func loss 1.586690902709961\n",
      "\n",
      "episode 12, val func loss 1.5497220754623413\n",
      "\n",
      "episode 13, val func loss 1.6114085912704468\n",
      "\n",
      "episode 14, val func loss 1.4513238668441772\n",
      "\n",
      "episode 15, val func loss 1.5102565288543701\n",
      "\n",
      "episode 16, val func loss 1.6355000734329224\n",
      "\n",
      "Val func train loss in epoch 4:1.610432006418705\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.4791144132614136\n",
      "\n",
      "episode 2, val func loss 1.7410269975662231\n",
      "\n",
      "episode 3, val func loss 1.6767737865447998\n",
      "\n",
      "episode 4, val func loss 1.5490059852600098\n",
      "\n",
      "episode 5, val func loss 1.5019686222076416\n",
      "\n",
      "episode 6, val func loss 1.750685691833496\n",
      "\n",
      "episode 7, val func loss 1.6885923147201538\n",
      "\n",
      "episode 8, val func loss 1.5414233207702637\n",
      "\n",
      "episode 9, val func loss 1.6326078176498413\n",
      "\n",
      "episode 10, val func loss 1.6527764797210693\n",
      "\n",
      "episode 11, val func loss 1.7355154752731323\n",
      "\n",
      "episode 12, val func loss 1.35490882396698\n",
      "\n",
      "episode 13, val func loss 1.626939058303833\n",
      "\n",
      "episode 14, val func loss 1.5892481803894043\n",
      "\n",
      "episode 15, val func loss 1.3186891078948975\n",
      "\n",
      "episode 16, val func loss 1.4559437036514282\n",
      "\n",
      "Val func train loss in epoch 5:1.5809512361884117\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.6242793798446655\n",
      "\n",
      "episode 2, val func loss 1.622725486755371\n",
      "\n",
      "episode 3, val func loss 1.7962086200714111\n",
      "\n",
      "episode 4, val func loss 1.6997604370117188\n",
      "\n",
      "episode 5, val func loss 1.756885051727295\n",
      "\n",
      "episode 6, val func loss 1.596663475036621\n",
      "\n",
      "episode 7, val func loss 1.5472346544265747\n",
      "\n",
      "episode 8, val func loss 1.4767192602157593\n",
      "\n",
      "episode 9, val func loss 1.5898199081420898\n",
      "\n",
      "episode 10, val func loss 1.662943720817566\n",
      "\n",
      "episode 11, val func loss 1.7764759063720703\n",
      "\n",
      "episode 12, val func loss 1.5743211507797241\n",
      "\n",
      "episode 13, val func loss 1.53291654586792\n",
      "\n",
      "episode 14, val func loss 1.6796543598175049\n",
      "\n",
      "episode 15, val func loss 1.662272572517395\n",
      "\n",
      "episode 16, val func loss 1.962293028831482\n",
      "\n",
      "Val func train loss in epoch 6:1.660073347389698\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.7976027727127075\n",
      "\n",
      "episode 2, val func loss 1.8326631784439087\n",
      "\n",
      "episode 3, val func loss 1.7317142486572266\n",
      "\n",
      "episode 4, val func loss 1.643259882926941\n",
      "\n",
      "episode 5, val func loss 1.6166965961456299\n",
      "\n",
      "episode 6, val func loss 1.4185450077056885\n",
      "\n",
      "episode 7, val func loss 1.5987275838851929\n",
      "\n",
      "episode 8, val func loss 1.6785125732421875\n",
      "\n",
      "episode 9, val func loss 1.4697060585021973\n",
      "\n",
      "episode 10, val func loss 1.9019347429275513\n",
      "\n",
      "episode 11, val func loss 1.5943843126296997\n",
      "\n",
      "episode 12, val func loss 1.722960114479065\n",
      "\n",
      "episode 13, val func loss 1.9071556329727173\n",
      "\n",
      "episode 14, val func loss 1.6514455080032349\n",
      "\n",
      "episode 15, val func loss 1.6074703931808472\n",
      "\n",
      "episode 16, val func loss 1.527645468711853\n",
      "\n",
      "Val func train loss in epoch 7:1.6687765046954155\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.8112040758132935\n",
      "\n",
      "episode 2, val func loss 1.742350459098816\n",
      "\n",
      "episode 3, val func loss 1.6351441144943237\n",
      "\n",
      "episode 4, val func loss 1.7536343336105347\n",
      "\n",
      "episode 5, val func loss 1.6651521921157837\n",
      "\n",
      "episode 6, val func loss 1.5052655935287476\n",
      "\n",
      "episode 7, val func loss 1.773777723312378\n",
      "\n",
      "episode 8, val func loss 1.5472259521484375\n",
      "\n",
      "episode 9, val func loss 1.8076852560043335\n",
      "\n",
      "episode 10, val func loss 1.691217064857483\n",
      "\n",
      "episode 11, val func loss 1.4808319807052612\n",
      "\n",
      "episode 12, val func loss 1.5900930166244507\n",
      "\n",
      "episode 13, val func loss 1.5262305736541748\n",
      "\n",
      "episode 14, val func loss 1.399489402770996\n",
      "\n",
      "episode 15, val func loss 1.6091206073760986\n",
      "\n",
      "episode 16, val func loss 1.4412407875061035\n",
      "\n",
      "Val func train loss in epoch 8:1.623728945851326\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.72979736328125\n",
      "\n",
      "episode 2, val func loss 1.7180849313735962\n",
      "\n",
      "episode 3, val func loss 1.6156022548675537\n",
      "\n",
      "episode 4, val func loss 1.87456214427948\n",
      "\n",
      "episode 5, val func loss 1.6624908447265625\n",
      "\n",
      "episode 6, val func loss 1.734270691871643\n",
      "\n",
      "episode 7, val func loss 1.7661428451538086\n",
      "\n",
      "episode 8, val func loss 1.647602915763855\n",
      "\n",
      "episode 9, val func loss 1.7500401735305786\n",
      "\n",
      "episode 10, val func loss 1.675220012664795\n",
      "\n",
      "episode 11, val func loss 1.5113070011138916\n",
      "\n",
      "episode 12, val func loss 1.6895602941513062\n",
      "\n",
      "episode 13, val func loss 1.6839442253112793\n",
      "\n",
      "episode 14, val func loss 1.47650146484375\n",
      "\n",
      "episode 15, val func loss 1.6655195951461792\n",
      "\n",
      "episode 16, val func loss 1.5491619110107422\n",
      "\n",
      "Val func train loss in epoch 9:1.671863041818142\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.411049246788025\n",
      "\n",
      "episode 2, val func loss 1.8719067573547363\n",
      "\n",
      "episode 3, val func loss 1.6486783027648926\n",
      "\n",
      "episode 4, val func loss 1.5658721923828125\n",
      "\n",
      "episode 5, val func loss 1.59791100025177\n",
      "\n",
      "episode 6, val func loss 1.7066296339035034\n",
      "\n",
      "episode 7, val func loss 1.604504942893982\n",
      "\n",
      "episode 8, val func loss 1.5952258110046387\n",
      "\n",
      "episode 9, val func loss 1.5917352437973022\n",
      "\n",
      "episode 10, val func loss 1.6601943969726562\n",
      "\n",
      "episode 11, val func loss 1.4851751327514648\n",
      "\n",
      "episode 12, val func loss 1.5095921754837036\n",
      "\n",
      "episode 13, val func loss 1.502871036529541\n",
      "\n",
      "episode 14, val func loss 1.5321074724197388\n",
      "\n",
      "episode 15, val func loss 1.5300074815750122\n",
      "\n",
      "episode 16, val func loss 1.48525869846344\n",
      "\n",
      "Val func train loss in epoch 10:1.5811699703335762\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.6327258348464966\n",
      "\n",
      "episode 2, val func loss 1.6262871026992798\n",
      "\n",
      "episode 3, val func loss 1.4767875671386719\n",
      "\n",
      "episode 4, val func loss 1.7442964315414429\n",
      "\n",
      "episode 5, val func loss 1.6398919820785522\n",
      "\n",
      "episode 6, val func loss 1.9048558473587036\n",
      "\n",
      "episode 7, val func loss 1.7613784074783325\n",
      "\n",
      "episode 8, val func loss 1.653419852256775\n",
      "\n",
      "episode 9, val func loss 1.5353596210479736\n",
      "\n",
      "episode 10, val func loss 1.6911702156066895\n",
      "\n",
      "episode 11, val func loss 1.5023345947265625\n",
      "\n",
      "episode 12, val func loss 1.5301074981689453\n",
      "\n",
      "episode 13, val func loss 1.5951107740402222\n",
      "\n",
      "episode 14, val func loss 1.650593638420105\n",
      "\n",
      "episode 15, val func loss 1.5447750091552734\n",
      "\n",
      "episode 16, val func loss 1.5851261615753174\n",
      "\n",
      "Val func train loss in epoch 11:1.629638783633709\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.5788174867630005\n",
      "\n",
      "episode 2, val func loss 1.6740351915359497\n",
      "\n",
      "episode 3, val func loss 1.5568112134933472\n",
      "\n",
      "episode 4, val func loss 1.7874513864517212\n",
      "\n",
      "episode 5, val func loss 1.5745348930358887\n",
      "\n",
      "episode 6, val func loss 1.6126168966293335\n",
      "\n",
      "episode 7, val func loss 1.4101128578186035\n",
      "\n",
      "episode 8, val func loss 1.7906237840652466\n",
      "\n",
      "episode 9, val func loss 1.5343945026397705\n",
      "\n",
      "episode 10, val func loss 1.8225560188293457\n",
      "\n",
      "episode 11, val func loss 1.706648826599121\n",
      "\n",
      "episode 12, val func loss 1.5134360790252686\n",
      "\n",
      "episode 13, val func loss 1.5897618532180786\n",
      "\n",
      "episode 14, val func loss 1.6774219274520874\n",
      "\n",
      "episode 15, val func loss 1.5887680053710938\n",
      "\n",
      "episode 16, val func loss 1.6721386909484863\n",
      "\n",
      "Val func train loss in epoch 12:1.6306331008672714\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.591870903968811\n",
      "\n",
      "episode 2, val func loss 1.5968173742294312\n",
      "\n",
      "episode 3, val func loss 1.7489814758300781\n",
      "\n",
      "episode 4, val func loss 1.6966907978057861\n",
      "\n",
      "episode 5, val func loss 1.585053563117981\n",
      "\n",
      "episode 6, val func loss 1.6398335695266724\n",
      "\n",
      "episode 7, val func loss 1.484230399131775\n",
      "\n",
      "episode 8, val func loss 1.609923005104065\n",
      "\n",
      "episode 9, val func loss 1.7023262977600098\n",
      "\n",
      "episode 10, val func loss 1.5556083917617798\n",
      "\n",
      "episode 11, val func loss 1.532166600227356\n",
      "\n",
      "episode 12, val func loss 1.6106481552124023\n",
      "\n",
      "episode 13, val func loss 1.387762427330017\n",
      "\n",
      "episode 14, val func loss 1.5384223461151123\n",
      "\n",
      "episode 15, val func loss 1.5082658529281616\n",
      "\n",
      "episode 16, val func loss 1.65359365940094\n",
      "\n",
      "Val func train loss in epoch 13:1.5901371762156487\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.8270034790039062\n",
      "\n",
      "episode 2, val func loss 1.6505568027496338\n",
      "\n",
      "episode 3, val func loss 1.6583142280578613\n",
      "\n",
      "episode 4, val func loss 1.7453762292861938\n",
      "\n",
      "episode 5, val func loss 1.6557081937789917\n",
      "\n",
      "episode 6, val func loss 1.5120271444320679\n",
      "\n",
      "episode 7, val func loss 1.5416860580444336\n",
      "\n",
      "episode 8, val func loss 1.6943439245224\n",
      "\n",
      "episode 9, val func loss 1.5269715785980225\n",
      "\n",
      "episode 10, val func loss 1.41477370262146\n",
      "\n",
      "episode 11, val func loss 1.557169795036316\n",
      "\n",
      "episode 12, val func loss 1.6167864799499512\n",
      "\n",
      "episode 13, val func loss 1.4576488733291626\n",
      "\n",
      "episode 14, val func loss 1.6299735307693481\n",
      "\n",
      "episode 15, val func loss 1.6182836294174194\n",
      "\n",
      "episode 16, val func loss 1.723197340965271\n",
      "\n",
      "Val func train loss in epoch 14:1.6143638119101524\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.632110595703125\n",
      "\n",
      "episode 2, val func loss 1.4990997314453125\n",
      "\n",
      "episode 3, val func loss 1.3432685136795044\n",
      "\n",
      "episode 4, val func loss 1.6515637636184692\n",
      "\n",
      "episode 5, val func loss 1.6881777048110962\n",
      "\n",
      "episode 6, val func loss 1.7011829614639282\n",
      "\n",
      "episode 7, val func loss 1.4641505479812622\n",
      "\n",
      "episode 8, val func loss 1.6013120412826538\n",
      "\n",
      "episode 9, val func loss 1.489667534828186\n",
      "\n",
      "episode 10, val func loss 1.6192876100540161\n",
      "\n",
      "episode 11, val func loss 1.7957412004470825\n",
      "\n",
      "episode 12, val func loss 1.547570824623108\n",
      "\n",
      "episode 13, val func loss 1.703555703163147\n",
      "\n",
      "episode 14, val func loss 1.7139763832092285\n",
      "\n",
      "episode 15, val func loss 1.4034818410873413\n",
      "\n",
      "episode 16, val func loss 1.6858129501342773\n",
      "\n",
      "Val func train loss in epoch 15:1.5962474942207336\n",
      "***********************TIME WAS 4.814571305116018 min*****************************\n",
      "\n",
      "**********************ROUND 28 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.3489291667938232\n",
      "\n",
      "episode 2, policy loss -2.348928928375244\n",
      "\n",
      "episode 3, policy loss -2.348928928375244\n",
      "\n",
      "episode 4, policy loss -2.348928928375244\n",
      "\n",
      "episode 5, policy loss -2.348928928375244\n",
      "\n",
      "episode 6, policy loss -2.348928689956665\n",
      "\n",
      "episode 7, policy loss -2.348928928375244\n",
      "\n",
      "episode 8, policy loss -2.348928928375244\n",
      "\n",
      "episode 9, policy loss -2.348928928375244\n",
      "\n",
      "episode 10, policy loss -2.348928928375244\n",
      "\n",
      "episode 11, policy loss -2.348928928375244\n",
      "\n",
      "episode 12, policy loss -2.348928928375244\n",
      "\n",
      "episode 13, policy loss -2.348928928375244\n",
      "\n",
      "episode 14, policy loss -2.348928689956665\n",
      "\n",
      "episode 15, policy loss -2.348928689956665\n",
      "\n",
      "episode 16, policy loss -2.348928928375244\n",
      "\n",
      "Policy train loss in epoch 0:-2.3489288985729218\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.348928928375244\n",
      "\n",
      "episode 2, policy loss -2.348928928375244\n",
      "\n",
      "episode 3, policy loss -2.348928928375244\n",
      "\n",
      "episode 4, policy loss -2.348928928375244\n",
      "\n",
      "episode 5, policy loss -2.348928928375244\n",
      "\n",
      "episode 6, policy loss -2.348928928375244\n",
      "\n",
      "episode 7, policy loss -2.3489291667938232\n",
      "\n",
      "episode 8, policy loss -2.348928689956665\n",
      "\n",
      "episode 9, policy loss -2.348928689956665\n",
      "\n",
      "episode 10, policy loss -2.348928689956665\n",
      "\n",
      "episode 11, policy loss -2.348928928375244\n",
      "\n",
      "episode 12, policy loss -2.348928928375244\n",
      "\n",
      "episode 13, policy loss -2.348928928375244\n",
      "\n",
      "episode 14, policy loss -2.348928928375244\n",
      "\n",
      "episode 15, policy loss -2.348928928375244\n",
      "\n",
      "episode 16, policy loss -2.348928928375244\n",
      "\n",
      "Policy train loss in epoch 1:-2.3489288985729218\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.348928928375244\n",
      "\n",
      "episode 2, policy loss -2.348928928375244\n",
      "\n",
      "episode 3, policy loss -2.348928928375244\n",
      "\n",
      "episode 4, policy loss -2.348928928375244\n",
      "\n",
      "episode 5, policy loss -2.348928689956665\n",
      "\n",
      "episode 6, policy loss -2.348928928375244\n",
      "\n",
      "episode 7, policy loss -2.348928689956665\n",
      "\n",
      "episode 8, policy loss -2.348928928375244\n",
      "\n",
      "episode 9, policy loss -2.348928928375244\n",
      "\n",
      "episode 10, policy loss -2.348928928375244\n",
      "\n",
      "episode 11, policy loss -2.348928928375244\n",
      "\n",
      "episode 12, policy loss -2.348928928375244\n",
      "\n",
      "episode 13, policy loss -2.348928928375244\n",
      "\n",
      "episode 14, policy loss -2.348928928375244\n",
      "\n",
      "episode 15, policy loss -2.348928689956665\n",
      "\n",
      "episode 16, policy loss -2.3489291667938232\n",
      "\n",
      "Policy train loss in epoch 2:-2.3489288985729218\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.348928928375244\n",
      "\n",
      "episode 2, policy loss -2.348928928375244\n",
      "\n",
      "episode 3, policy loss -2.348928928375244\n",
      "\n",
      "episode 4, policy loss -2.348928928375244\n",
      "\n",
      "episode 5, policy loss -2.348928928375244\n",
      "\n",
      "episode 6, policy loss -2.348928928375244\n",
      "\n",
      "episode 7, policy loss -2.348928928375244\n",
      "\n",
      "episode 8, policy loss -2.348928928375244\n",
      "\n",
      "episode 9, policy loss -2.3489291667938232\n",
      "\n",
      "episode 10, policy loss -2.348928928375244\n",
      "\n",
      "episode 11, policy loss -2.348928689956665\n",
      "\n",
      "episode 12, policy loss -2.348928928375244\n",
      "\n",
      "episode 13, policy loss -2.348928928375244\n",
      "\n",
      "episode 14, policy loss -2.348928689956665\n",
      "\n",
      "episode 15, policy loss -2.348928928375244\n",
      "\n",
      "episode 16, policy loss -2.348928689956665\n",
      "\n",
      "Policy train loss in epoch 3:-2.3489288985729218\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.5899654626846313\n",
      "\n",
      "episode 2, val func loss 1.6529273986816406\n",
      "\n",
      "episode 3, val func loss 1.5283299684524536\n",
      "\n",
      "episode 4, val func loss 1.6283817291259766\n",
      "\n",
      "episode 5, val func loss 1.6186822652816772\n",
      "\n",
      "episode 6, val func loss 1.6648931503295898\n",
      "\n",
      "episode 7, val func loss 1.7716213464736938\n",
      "\n",
      "episode 8, val func loss 1.761963963508606\n",
      "\n",
      "episode 9, val func loss 1.5339360237121582\n",
      "\n",
      "episode 10, val func loss 1.472249984741211\n",
      "\n",
      "episode 11, val func loss 1.6421200037002563\n",
      "\n",
      "episode 12, val func loss 1.7611279487609863\n",
      "\n",
      "episode 13, val func loss 1.5217292308807373\n",
      "\n",
      "episode 14, val func loss 1.7596315145492554\n",
      "\n",
      "episode 15, val func loss 1.6843143701553345\n",
      "\n",
      "episode 16, val func loss 1.55527663230896\n",
      "\n",
      "Val func train loss in epoch 0:1.634196937084198\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.7567230463027954\n",
      "\n",
      "episode 2, val func loss 1.8452472686767578\n",
      "\n",
      "episode 3, val func loss 1.6078871488571167\n",
      "\n",
      "episode 4, val func loss 1.7729703187942505\n",
      "\n",
      "episode 5, val func loss 1.6616116762161255\n",
      "\n",
      "episode 6, val func loss 1.6047378778457642\n",
      "\n",
      "episode 7, val func loss 1.6865506172180176\n",
      "\n",
      "episode 8, val func loss 1.7966548204421997\n",
      "\n",
      "episode 9, val func loss 1.7875512838363647\n",
      "\n",
      "episode 10, val func loss 1.73611581325531\n",
      "\n",
      "episode 11, val func loss 1.5499088764190674\n",
      "\n",
      "episode 12, val func loss 1.871349811553955\n",
      "\n",
      "episode 13, val func loss 1.7402970790863037\n",
      "\n",
      "episode 14, val func loss 1.818856954574585\n",
      "\n",
      "episode 15, val func loss 1.5632878541946411\n",
      "\n",
      "episode 16, val func loss 1.6357892751693726\n",
      "\n",
      "Val func train loss in epoch 1:1.7147212326526642\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.660191297531128\n",
      "\n",
      "episode 2, val func loss 1.6759333610534668\n",
      "\n",
      "episode 3, val func loss 1.6037638187408447\n",
      "\n",
      "episode 4, val func loss 1.692244529724121\n",
      "\n",
      "episode 5, val func loss 1.6226741075515747\n",
      "\n",
      "episode 6, val func loss 1.7592717409133911\n",
      "\n",
      "episode 7, val func loss 1.4940154552459717\n",
      "\n",
      "episode 8, val func loss 1.7705624103546143\n",
      "\n",
      "episode 9, val func loss 1.7432397603988647\n",
      "\n",
      "episode 10, val func loss 1.4832254648208618\n",
      "\n",
      "episode 11, val func loss 1.4836208820343018\n",
      "\n",
      "episode 12, val func loss 1.5077996253967285\n",
      "\n",
      "episode 13, val func loss 1.5566625595092773\n",
      "\n",
      "episode 14, val func loss 1.6551216840744019\n",
      "\n",
      "episode 15, val func loss 1.425564169883728\n",
      "\n",
      "episode 16, val func loss 1.670146107673645\n",
      "\n",
      "Val func train loss in epoch 2:1.6127523109316826\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.628825068473816\n",
      "\n",
      "episode 2, val func loss 1.5872570276260376\n",
      "\n",
      "episode 3, val func loss 1.4943091869354248\n",
      "\n",
      "episode 4, val func loss 1.5918174982070923\n",
      "\n",
      "episode 5, val func loss 1.588310956954956\n",
      "\n",
      "episode 6, val func loss 1.3936817646026611\n",
      "\n",
      "episode 7, val func loss 1.7582626342773438\n",
      "\n",
      "episode 8, val func loss 1.4694799184799194\n",
      "\n",
      "episode 9, val func loss 1.3876694440841675\n",
      "\n",
      "episode 10, val func loss 1.6165045499801636\n",
      "\n",
      "episode 11, val func loss 1.663794994354248\n",
      "\n",
      "episode 12, val func loss 1.502475380897522\n",
      "\n",
      "episode 13, val func loss 1.5039023160934448\n",
      "\n",
      "episode 14, val func loss 1.5997965335845947\n",
      "\n",
      "episode 15, val func loss 1.737152338027954\n",
      "\n",
      "episode 16, val func loss 1.498416543006897\n",
      "\n",
      "Val func train loss in epoch 3:1.5638535097241402\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.621156930923462\n",
      "\n",
      "episode 2, val func loss 1.7091976404190063\n",
      "\n",
      "episode 3, val func loss 1.6460249423980713\n",
      "\n",
      "episode 4, val func loss 1.5929073095321655\n",
      "\n",
      "episode 5, val func loss 1.5112323760986328\n",
      "\n",
      "episode 6, val func loss 1.5297961235046387\n",
      "\n",
      "episode 7, val func loss 1.6057730913162231\n",
      "\n",
      "episode 8, val func loss 1.730000615119934\n",
      "\n",
      "episode 9, val func loss 1.595441222190857\n",
      "\n",
      "episode 10, val func loss 1.6302671432495117\n",
      "\n",
      "episode 11, val func loss 1.8767882585525513\n",
      "\n",
      "episode 12, val func loss 1.5730547904968262\n",
      "\n",
      "episode 13, val func loss 1.6158900260925293\n",
      "\n",
      "episode 14, val func loss 1.4854907989501953\n",
      "\n",
      "episode 15, val func loss 1.5661675930023193\n",
      "\n",
      "episode 16, val func loss 1.633208155632019\n",
      "\n",
      "Val func train loss in epoch 4:1.620149813592434\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.5740551948547363\n",
      "\n",
      "episode 2, val func loss 1.732656478881836\n",
      "\n",
      "episode 3, val func loss 1.5002859830856323\n",
      "\n",
      "episode 4, val func loss 1.6736921072006226\n",
      "\n",
      "episode 5, val func loss 1.5642046928405762\n",
      "\n",
      "episode 6, val func loss 1.481121301651001\n",
      "\n",
      "episode 7, val func loss 1.6070365905761719\n",
      "\n",
      "episode 8, val func loss 1.9043166637420654\n",
      "\n",
      "episode 9, val func loss 1.4102036952972412\n",
      "\n",
      "episode 10, val func loss 1.4623627662658691\n",
      "\n",
      "episode 11, val func loss 1.7752934694290161\n",
      "\n",
      "episode 12, val func loss 1.5664122104644775\n",
      "\n",
      "episode 13, val func loss 1.5449726581573486\n",
      "\n",
      "episode 14, val func loss 1.860018253326416\n",
      "\n",
      "episode 15, val func loss 1.8407235145568848\n",
      "\n",
      "episode 16, val func loss 1.712202548980713\n",
      "\n",
      "Val func train loss in epoch 5:1.638097383081913\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.6393462419509888\n",
      "\n",
      "episode 2, val func loss 1.5615272521972656\n",
      "\n",
      "episode 3, val func loss 1.6803317070007324\n",
      "\n",
      "episode 4, val func loss 1.57992684841156\n",
      "\n",
      "episode 5, val func loss 1.6598796844482422\n",
      "\n",
      "episode 6, val func loss 1.7492222785949707\n",
      "\n",
      "episode 7, val func loss 1.5945683717727661\n",
      "\n",
      "episode 8, val func loss 1.5135083198547363\n",
      "\n",
      "episode 9, val func loss 1.4586858749389648\n",
      "\n",
      "episode 10, val func loss 1.5607472658157349\n",
      "\n",
      "episode 11, val func loss 1.5856199264526367\n",
      "\n",
      "episode 12, val func loss 1.6415982246398926\n",
      "\n",
      "episode 13, val func loss 1.561416506767273\n",
      "\n",
      "episode 14, val func loss 1.4881871938705444\n",
      "\n",
      "episode 15, val func loss 1.4522686004638672\n",
      "\n",
      "episode 16, val func loss 1.4512803554534912\n",
      "\n",
      "Val func train loss in epoch 6:1.5736321657896042\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.6450475454330444\n",
      "\n",
      "episode 2, val func loss 1.6186517477035522\n",
      "\n",
      "episode 3, val func loss 1.5720503330230713\n",
      "\n",
      "episode 4, val func loss 1.612522006034851\n",
      "\n",
      "episode 5, val func loss 1.4590524435043335\n",
      "\n",
      "episode 6, val func loss 1.6314233541488647\n",
      "\n",
      "episode 7, val func loss 1.5371860265731812\n",
      "\n",
      "episode 8, val func loss 1.3668081760406494\n",
      "\n",
      "episode 9, val func loss 1.4885516166687012\n",
      "\n",
      "episode 10, val func loss 1.6549265384674072\n",
      "\n",
      "episode 11, val func loss 1.7939066886901855\n",
      "\n",
      "episode 12, val func loss 1.512431263923645\n",
      "\n",
      "episode 13, val func loss 1.7868237495422363\n",
      "\n",
      "episode 14, val func loss 1.4460557699203491\n",
      "\n",
      "episode 15, val func loss 1.7270594835281372\n",
      "\n",
      "episode 16, val func loss 1.7430496215820312\n",
      "\n",
      "Val func train loss in epoch 7:1.599721647799015\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.944326400756836\n",
      "\n",
      "episode 2, val func loss 1.5877528190612793\n",
      "\n",
      "episode 3, val func loss 1.4349032640457153\n",
      "\n",
      "episode 4, val func loss 1.6384917497634888\n",
      "\n",
      "episode 5, val func loss 1.621399998664856\n",
      "\n",
      "episode 6, val func loss 1.674146294593811\n",
      "\n",
      "episode 7, val func loss 1.714187502861023\n",
      "\n",
      "episode 8, val func loss 1.6467080116271973\n",
      "\n",
      "episode 9, val func loss 1.6171735525131226\n",
      "\n",
      "episode 10, val func loss 1.7596737146377563\n",
      "\n",
      "episode 11, val func loss 1.3283987045288086\n",
      "\n",
      "episode 12, val func loss 1.4578927755355835\n",
      "\n",
      "episode 13, val func loss 1.7381763458251953\n",
      "\n",
      "episode 14, val func loss 1.4366157054901123\n",
      "\n",
      "episode 15, val func loss 1.6141586303710938\n",
      "\n",
      "episode 16, val func loss 1.7050857543945312\n",
      "\n",
      "Val func train loss in epoch 8:1.6199432015419006\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.5095336437225342\n",
      "\n",
      "episode 2, val func loss 1.5232365131378174\n",
      "\n",
      "episode 3, val func loss 1.5459376573562622\n",
      "\n",
      "episode 4, val func loss 1.5149799585342407\n",
      "\n",
      "episode 5, val func loss 1.4178316593170166\n",
      "\n",
      "episode 6, val func loss 1.5427496433258057\n",
      "\n",
      "episode 7, val func loss 1.6242141723632812\n",
      "\n",
      "episode 8, val func loss 1.5494160652160645\n",
      "\n",
      "episode 9, val func loss 1.6742730140686035\n",
      "\n",
      "episode 10, val func loss 1.5488102436065674\n",
      "\n",
      "episode 11, val func loss 1.6569066047668457\n",
      "\n",
      "episode 12, val func loss 1.691487431526184\n",
      "\n",
      "episode 13, val func loss 1.6927341222763062\n",
      "\n",
      "episode 14, val func loss 1.637860894203186\n",
      "\n",
      "episode 15, val func loss 1.5656465291976929\n",
      "\n",
      "episode 16, val func loss 1.5947786569595337\n",
      "\n",
      "Val func train loss in epoch 9:1.5806498005986214\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.619942545890808\n",
      "\n",
      "episode 2, val func loss 1.5558843612670898\n",
      "\n",
      "episode 3, val func loss 1.6259909868240356\n",
      "\n",
      "episode 4, val func loss 1.6116386651992798\n",
      "\n",
      "episode 5, val func loss 1.5523698329925537\n",
      "\n",
      "episode 6, val func loss 1.4402841329574585\n",
      "\n",
      "episode 7, val func loss 1.628843903541565\n",
      "\n",
      "episode 8, val func loss 1.5096206665039062\n",
      "\n",
      "episode 9, val func loss 1.6773037910461426\n",
      "\n",
      "episode 10, val func loss 1.5672489404678345\n",
      "\n",
      "episode 11, val func loss 1.529372215270996\n",
      "\n",
      "episode 12, val func loss 1.5971463918685913\n",
      "\n",
      "episode 13, val func loss 1.6326563358306885\n",
      "\n",
      "episode 14, val func loss 1.7317728996276855\n",
      "\n",
      "episode 15, val func loss 1.479028344154358\n",
      "\n",
      "episode 16, val func loss 1.5952558517456055\n",
      "\n",
      "Val func train loss in epoch 10:1.5846474915742874\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.530741810798645\n",
      "\n",
      "episode 2, val func loss 1.4606517553329468\n",
      "\n",
      "episode 3, val func loss 1.6448944807052612\n",
      "\n",
      "episode 4, val func loss 1.5138065814971924\n",
      "\n",
      "episode 5, val func loss 1.7707267999649048\n",
      "\n",
      "episode 6, val func loss 1.8058407306671143\n",
      "\n",
      "episode 7, val func loss 1.6531951427459717\n",
      "\n",
      "episode 8, val func loss 1.7180759906768799\n",
      "\n",
      "episode 9, val func loss 1.570462942123413\n",
      "\n",
      "episode 10, val func loss 1.5290892124176025\n",
      "\n",
      "episode 11, val func loss 1.4770528078079224\n",
      "\n",
      "episode 12, val func loss 1.561269998550415\n",
      "\n",
      "episode 13, val func loss 1.5924288034439087\n",
      "\n",
      "episode 14, val func loss 1.6998780965805054\n",
      "\n",
      "episode 15, val func loss 1.54134202003479\n",
      "\n",
      "episode 16, val func loss 1.6367526054382324\n",
      "\n",
      "Val func train loss in epoch 11:1.6066381111741066\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.7505288124084473\n",
      "\n",
      "episode 2, val func loss 1.5891687870025635\n",
      "\n",
      "episode 3, val func loss 1.6557714939117432\n",
      "\n",
      "episode 4, val func loss 1.598958969116211\n",
      "\n",
      "episode 5, val func loss 1.6130595207214355\n",
      "\n",
      "episode 6, val func loss 1.764197826385498\n",
      "\n",
      "episode 7, val func loss 1.6152678728103638\n",
      "\n",
      "episode 8, val func loss 1.6348129510879517\n",
      "\n",
      "episode 9, val func loss 1.514845848083496\n",
      "\n",
      "episode 10, val func loss 1.674831748008728\n",
      "\n",
      "episode 11, val func loss 1.46407949924469\n",
      "\n",
      "episode 12, val func loss 1.6311148405075073\n",
      "\n",
      "episode 13, val func loss 1.3325858116149902\n",
      "\n",
      "episode 14, val func loss 1.6422308683395386\n",
      "\n",
      "episode 15, val func loss 1.5217385292053223\n",
      "\n",
      "episode 16, val func loss 1.5868409872055054\n",
      "\n",
      "Val func train loss in epoch 12:1.5993771478533745\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.65532386302948\n",
      "\n",
      "episode 2, val func loss 1.719849705696106\n",
      "\n",
      "episode 3, val func loss 1.7491133213043213\n",
      "\n",
      "episode 4, val func loss 1.6216742992401123\n",
      "\n",
      "episode 5, val func loss 1.3763679265975952\n",
      "\n",
      "episode 6, val func loss 1.6649216413497925\n",
      "\n",
      "episode 7, val func loss 1.5524141788482666\n",
      "\n",
      "episode 8, val func loss 1.5587695837020874\n",
      "\n",
      "episode 9, val func loss 1.6630680561065674\n",
      "\n",
      "episode 10, val func loss 1.3461085557937622\n",
      "\n",
      "episode 11, val func loss 1.66536545753479\n",
      "\n",
      "episode 12, val func loss 1.441102147102356\n",
      "\n",
      "episode 13, val func loss 1.6604809761047363\n",
      "\n",
      "episode 14, val func loss 1.6067674160003662\n",
      "\n",
      "episode 15, val func loss 1.7344871759414673\n",
      "\n",
      "episode 16, val func loss 1.5592645406723022\n",
      "\n",
      "Val func train loss in epoch 13:1.5984424278140068\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.46866774559021\n",
      "\n",
      "episode 2, val func loss 1.446932315826416\n",
      "\n",
      "episode 3, val func loss 1.6095727682113647\n",
      "\n",
      "episode 4, val func loss 1.4989784955978394\n",
      "\n",
      "episode 5, val func loss 1.5810739994049072\n",
      "\n",
      "episode 6, val func loss 1.6549617052078247\n",
      "\n",
      "episode 7, val func loss 1.4518791437149048\n",
      "\n",
      "episode 8, val func loss 1.4969501495361328\n",
      "\n",
      "episode 9, val func loss 1.4129917621612549\n",
      "\n",
      "episode 10, val func loss 1.4730224609375\n",
      "\n",
      "episode 11, val func loss 1.515310287475586\n",
      "\n",
      "episode 12, val func loss 1.3244715929031372\n",
      "\n",
      "episode 13, val func loss 1.6695122718811035\n",
      "\n",
      "episode 14, val func loss 1.5016990900039673\n",
      "\n",
      "episode 15, val func loss 1.6266405582427979\n",
      "\n",
      "episode 16, val func loss 1.416369915008545\n",
      "\n",
      "Val func train loss in epoch 14:1.5093146413564682\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.4513370990753174\n",
      "\n",
      "episode 2, val func loss 1.7768393754959106\n",
      "\n",
      "episode 3, val func loss 1.6119753122329712\n",
      "\n",
      "episode 4, val func loss 1.7295316457748413\n",
      "\n",
      "episode 5, val func loss 1.6796413660049438\n",
      "\n",
      "episode 6, val func loss 1.6550813913345337\n",
      "\n",
      "episode 7, val func loss 1.4267991781234741\n",
      "\n",
      "episode 8, val func loss 1.6612467765808105\n",
      "\n",
      "episode 9, val func loss 1.765791416168213\n",
      "\n",
      "episode 10, val func loss 1.5558050870895386\n",
      "\n",
      "episode 11, val func loss 1.754367709159851\n",
      "\n",
      "episode 12, val func loss 1.5924029350280762\n",
      "\n",
      "episode 13, val func loss 1.6267368793487549\n",
      "\n",
      "episode 14, val func loss 1.7178970575332642\n",
      "\n",
      "episode 15, val func loss 1.682960867881775\n",
      "\n",
      "episode 16, val func loss 1.8179141283035278\n",
      "\n",
      "Val func train loss in epoch 15:1.6566455140709877\n",
      "***********************TIME WAS 4.823994914690654 min*****************************\n",
      "\n",
      "**********************ROUND 29 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.187356948852539\n",
      "\n",
      "episode 2, policy loss -2.187357187271118\n",
      "\n",
      "episode 3, policy loss -2.1873574256896973\n",
      "\n",
      "episode 4, policy loss -2.187357187271118\n",
      "\n",
      "episode 5, policy loss -2.187357187271118\n",
      "\n",
      "episode 6, policy loss -2.187357187271118\n",
      "\n",
      "episode 7, policy loss -2.187357187271118\n",
      "\n",
      "episode 8, policy loss -2.187357187271118\n",
      "\n",
      "episode 9, policy loss -2.187356948852539\n",
      "\n",
      "episode 10, policy loss -2.187357187271118\n",
      "\n",
      "episode 11, policy loss -2.187356948852539\n",
      "\n",
      "episode 12, policy loss -2.187356948852539\n",
      "\n",
      "episode 13, policy loss -2.1873574256896973\n",
      "\n",
      "episode 14, policy loss -2.187357187271118\n",
      "\n",
      "episode 15, policy loss -2.187357187271118\n",
      "\n",
      "episode 16, policy loss -2.187357187271118\n",
      "\n",
      "Policy train loss in epoch 0:-2.1873571574687958\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.187356948852539\n",
      "\n",
      "episode 2, policy loss -2.1873574256896973\n",
      "\n",
      "episode 3, policy loss -2.187357187271118\n",
      "\n",
      "episode 4, policy loss -2.187357187271118\n",
      "\n",
      "episode 5, policy loss -2.187356948852539\n",
      "\n",
      "episode 6, policy loss -2.187357187271118\n",
      "\n",
      "episode 7, policy loss -2.1873574256896973\n",
      "\n",
      "episode 8, policy loss -2.187357187271118\n",
      "\n",
      "episode 9, policy loss -2.187357187271118\n",
      "\n",
      "episode 10, policy loss -2.187357187271118\n",
      "\n",
      "episode 11, policy loss -2.187357187271118\n",
      "\n",
      "episode 12, policy loss -2.187356948852539\n",
      "\n",
      "episode 13, policy loss -2.187356948852539\n",
      "\n",
      "episode 14, policy loss -2.187357187271118\n",
      "\n",
      "episode 15, policy loss -2.187357187271118\n",
      "\n",
      "episode 16, policy loss -2.187357187271118\n",
      "\n",
      "Policy train loss in epoch 1:-2.1873571574687958\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.187357187271118\n",
      "\n",
      "episode 2, policy loss -2.187356948852539\n",
      "\n",
      "episode 3, policy loss -2.1873574256896973\n",
      "\n",
      "episode 4, policy loss -2.187357187271118\n",
      "\n",
      "episode 5, policy loss -2.187357187271118\n",
      "\n",
      "episode 6, policy loss -2.187357187271118\n",
      "\n",
      "episode 7, policy loss -2.187357187271118\n",
      "\n",
      "episode 8, policy loss -2.187357187271118\n",
      "\n",
      "episode 9, policy loss -2.187356948852539\n",
      "\n",
      "episode 10, policy loss -2.187357187271118\n",
      "\n",
      "episode 11, policy loss -2.187356948852539\n",
      "\n",
      "episode 12, policy loss -2.187357187271118\n",
      "\n",
      "episode 13, policy loss -2.187357187271118\n",
      "\n",
      "episode 14, policy loss -2.187357187271118\n",
      "\n",
      "episode 15, policy loss -2.187356948852539\n",
      "\n",
      "episode 16, policy loss -2.1873574256896973\n",
      "\n",
      "Policy train loss in epoch 2:-2.1873571574687958\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.1873574256896973\n",
      "\n",
      "episode 2, policy loss -2.187357187271118\n",
      "\n",
      "episode 3, policy loss -2.187357187271118\n",
      "\n",
      "episode 4, policy loss -2.187356948852539\n",
      "\n",
      "episode 5, policy loss -2.187356948852539\n",
      "\n",
      "episode 6, policy loss -2.187357187271118\n",
      "\n",
      "episode 7, policy loss -2.187357187271118\n",
      "\n",
      "episode 8, policy loss -2.187357187271118\n",
      "\n",
      "episode 9, policy loss -2.187356948852539\n",
      "\n",
      "episode 10, policy loss -2.187357187271118\n",
      "\n",
      "episode 11, policy loss -2.187356948852539\n",
      "\n",
      "episode 12, policy loss -2.187357187271118\n",
      "\n",
      "episode 13, policy loss -2.1873574256896973\n",
      "\n",
      "episode 14, policy loss -2.187357187271118\n",
      "\n",
      "episode 15, policy loss -2.187357187271118\n",
      "\n",
      "episode 16, policy loss -2.187357187271118\n",
      "\n",
      "Policy train loss in epoch 3:-2.1873571574687958\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.453716516494751\n",
      "\n",
      "episode 2, val func loss 1.4306740760803223\n",
      "\n",
      "episode 3, val func loss 1.4956239461898804\n",
      "\n",
      "episode 4, val func loss 1.644838809967041\n",
      "\n",
      "episode 5, val func loss 1.5349560976028442\n",
      "\n",
      "episode 6, val func loss 1.436597466468811\n",
      "\n",
      "episode 7, val func loss 1.6091090440750122\n",
      "\n",
      "episode 8, val func loss 1.4669249057769775\n",
      "\n",
      "episode 9, val func loss 1.3645200729370117\n",
      "\n",
      "episode 10, val func loss 1.6306313276290894\n",
      "\n",
      "episode 11, val func loss 1.6878114938735962\n",
      "\n",
      "episode 12, val func loss 1.6110615730285645\n",
      "\n",
      "episode 13, val func loss 1.5626907348632812\n",
      "\n",
      "episode 14, val func loss 1.7770150899887085\n",
      "\n",
      "episode 15, val func loss 1.4735580682754517\n",
      "\n",
      "episode 16, val func loss 1.5646533966064453\n",
      "\n",
      "Val func train loss in epoch 0:1.5465239137411118\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.647923231124878\n",
      "\n",
      "episode 2, val func loss 1.700101613998413\n",
      "\n",
      "episode 3, val func loss 1.4715948104858398\n",
      "\n",
      "episode 4, val func loss 1.636600136756897\n",
      "\n",
      "episode 5, val func loss 1.4064439535140991\n",
      "\n",
      "episode 6, val func loss 1.3620811700820923\n",
      "\n",
      "episode 7, val func loss 1.7627249956130981\n",
      "\n",
      "episode 8, val func loss 1.5203391313552856\n",
      "\n",
      "episode 9, val func loss 1.6191222667694092\n",
      "\n",
      "episode 10, val func loss 1.5742450952529907\n",
      "\n",
      "episode 11, val func loss 1.5784987211227417\n",
      "\n",
      "episode 12, val func loss 1.7313125133514404\n",
      "\n",
      "episode 13, val func loss 1.4847041368484497\n",
      "\n",
      "episode 14, val func loss 1.4744973182678223\n",
      "\n",
      "episode 15, val func loss 1.4201700687408447\n",
      "\n",
      "episode 16, val func loss 1.530382752418518\n",
      "\n",
      "Val func train loss in epoch 1:1.5575463697314262\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.580147624015808\n",
      "\n",
      "episode 2, val func loss 1.5956166982650757\n",
      "\n",
      "episode 3, val func loss 1.5314466953277588\n",
      "\n",
      "episode 4, val func loss 1.4853824377059937\n",
      "\n",
      "episode 5, val func loss 1.69028902053833\n",
      "\n",
      "episode 6, val func loss 1.6488370895385742\n",
      "\n",
      "episode 7, val func loss 1.7264450788497925\n",
      "\n",
      "episode 8, val func loss 1.455988883972168\n",
      "\n",
      "episode 9, val func loss 1.594300389289856\n",
      "\n",
      "episode 10, val func loss 1.50649094581604\n",
      "\n",
      "episode 11, val func loss 1.4311825037002563\n",
      "\n",
      "episode 12, val func loss 1.5322428941726685\n",
      "\n",
      "episode 13, val func loss 1.6547095775604248\n",
      "\n",
      "episode 14, val func loss 1.4096848964691162\n",
      "\n",
      "episode 15, val func loss 1.4082260131835938\n",
      "\n",
      "episode 16, val func loss 1.6024410724639893\n",
      "\n",
      "Val func train loss in epoch 2:1.5533394888043404\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.4988397359848022\n",
      "\n",
      "episode 2, val func loss 1.6408549547195435\n",
      "\n",
      "episode 3, val func loss 1.4061346054077148\n",
      "\n",
      "episode 4, val func loss 1.4069035053253174\n",
      "\n",
      "episode 5, val func loss 1.6063363552093506\n",
      "\n",
      "episode 6, val func loss 1.5264723300933838\n",
      "\n",
      "episode 7, val func loss 1.441612958908081\n",
      "\n",
      "episode 8, val func loss 1.308651089668274\n",
      "\n",
      "episode 9, val func loss 1.4507635831832886\n",
      "\n",
      "episode 10, val func loss 1.4284040927886963\n",
      "\n",
      "episode 11, val func loss 1.5485742092132568\n",
      "\n",
      "episode 12, val func loss 1.7131825685501099\n",
      "\n",
      "episode 13, val func loss 1.540642499923706\n",
      "\n",
      "episode 14, val func loss 1.4698346853256226\n",
      "\n",
      "episode 15, val func loss 1.4962947368621826\n",
      "\n",
      "episode 16, val func loss 1.4045312404632568\n",
      "\n",
      "Val func train loss in epoch 3:1.4930020719766617\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.439170002937317\n",
      "\n",
      "episode 2, val func loss 1.5528446435928345\n",
      "\n",
      "episode 3, val func loss 1.4638967514038086\n",
      "\n",
      "episode 4, val func loss 1.4564772844314575\n",
      "\n",
      "episode 5, val func loss 1.4429001808166504\n",
      "\n",
      "episode 6, val func loss 1.5635277032852173\n",
      "\n",
      "episode 7, val func loss 1.8146318197250366\n",
      "\n",
      "episode 8, val func loss 1.4013540744781494\n",
      "\n",
      "episode 9, val func loss 1.5752278566360474\n",
      "\n",
      "episode 10, val func loss 1.3850266933441162\n",
      "\n",
      "episode 11, val func loss 1.551986575126648\n",
      "\n",
      "episode 12, val func loss 1.5099585056304932\n",
      "\n",
      "episode 13, val func loss 1.4590270519256592\n",
      "\n",
      "episode 14, val func loss 1.3964473009109497\n",
      "\n",
      "episode 15, val func loss 1.5004866123199463\n",
      "\n",
      "episode 16, val func loss 1.862804889678955\n",
      "\n",
      "Val func train loss in epoch 4:1.5234854966402054\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.7669999599456787\n",
      "\n",
      "episode 2, val func loss 1.6379456520080566\n",
      "\n",
      "episode 3, val func loss 1.9608428478240967\n",
      "\n",
      "episode 4, val func loss 1.79931640625\n",
      "\n",
      "episode 5, val func loss 1.5757005214691162\n",
      "\n",
      "episode 6, val func loss 1.3854342699050903\n",
      "\n",
      "episode 7, val func loss 1.7434076070785522\n",
      "\n",
      "episode 8, val func loss 1.6901812553405762\n",
      "\n",
      "episode 9, val func loss 1.7243099212646484\n",
      "\n",
      "episode 10, val func loss 1.460940957069397\n",
      "\n",
      "episode 11, val func loss 1.6522164344787598\n",
      "\n",
      "episode 12, val func loss 1.4221025705337524\n",
      "\n",
      "episode 13, val func loss 1.6378062963485718\n",
      "\n",
      "episode 14, val func loss 1.5301272869110107\n",
      "\n",
      "episode 15, val func loss 1.6584049463272095\n",
      "\n",
      "episode 16, val func loss 1.8058478832244873\n",
      "\n",
      "Val func train loss in epoch 5:1.6532240509986877\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.5377625226974487\n",
      "\n",
      "episode 2, val func loss 1.5534570217132568\n",
      "\n",
      "episode 3, val func loss 1.5075623989105225\n",
      "\n",
      "episode 4, val func loss 1.6225277185440063\n",
      "\n",
      "episode 5, val func loss 1.6252269744873047\n",
      "\n",
      "episode 6, val func loss 1.438590407371521\n",
      "\n",
      "episode 7, val func loss 1.479796051979065\n",
      "\n",
      "episode 8, val func loss 1.4725900888442993\n",
      "\n",
      "episode 9, val func loss 1.4464495182037354\n",
      "\n",
      "episode 10, val func loss 1.6658458709716797\n",
      "\n",
      "episode 11, val func loss 1.7953771352767944\n",
      "\n",
      "episode 12, val func loss 1.482194185256958\n",
      "\n",
      "episode 13, val func loss 1.6364096403121948\n",
      "\n",
      "episode 14, val func loss 1.422002911567688\n",
      "\n",
      "episode 15, val func loss 1.534292459487915\n",
      "\n",
      "episode 16, val func loss 1.8384153842926025\n",
      "\n",
      "Val func train loss in epoch 6:1.566156268119812\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.4862512350082397\n",
      "\n",
      "episode 2, val func loss 1.6998409032821655\n",
      "\n",
      "episode 3, val func loss 1.5545400381088257\n",
      "\n",
      "episode 4, val func loss 1.5307064056396484\n",
      "\n",
      "episode 5, val func loss 1.2624257802963257\n",
      "\n",
      "episode 6, val func loss 1.3760812282562256\n",
      "\n",
      "episode 7, val func loss 1.6881017684936523\n",
      "\n",
      "episode 8, val func loss 1.363994836807251\n",
      "\n",
      "episode 9, val func loss 1.6768794059753418\n",
      "\n",
      "episode 10, val func loss 1.5254311561584473\n",
      "\n",
      "episode 11, val func loss 1.6632719039916992\n",
      "\n",
      "episode 12, val func loss 1.349714756011963\n",
      "\n",
      "episode 13, val func loss 1.6724789142608643\n",
      "\n",
      "episode 14, val func loss 1.8029793500900269\n",
      "\n",
      "episode 15, val func loss 1.6750876903533936\n",
      "\n",
      "episode 16, val func loss 1.5520693063735962\n",
      "\n",
      "Val func train loss in epoch 7:1.5549909174442291\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.700310230255127\n",
      "\n",
      "episode 2, val func loss 1.5261483192443848\n",
      "\n",
      "episode 3, val func loss 1.6913790702819824\n",
      "\n",
      "episode 4, val func loss 1.46626877784729\n",
      "\n",
      "episode 5, val func loss 1.3654911518096924\n",
      "\n",
      "episode 6, val func loss 1.4081776142120361\n",
      "\n",
      "episode 7, val func loss 1.4989229440689087\n",
      "\n",
      "episode 8, val func loss 1.7363537549972534\n",
      "\n",
      "episode 9, val func loss 1.5255906581878662\n",
      "\n",
      "episode 10, val func loss 1.5131237506866455\n",
      "\n",
      "episode 11, val func loss 1.6526027917861938\n",
      "\n",
      "episode 12, val func loss 1.4943588972091675\n",
      "\n",
      "episode 13, val func loss 1.728967308998108\n",
      "\n",
      "episode 14, val func loss 1.3591493368148804\n",
      "\n",
      "episode 15, val func loss 1.5048599243164062\n",
      "\n",
      "episode 16, val func loss 1.6300827264785767\n",
      "\n",
      "Val func train loss in epoch 8:1.5501117035746574\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.667182445526123\n",
      "\n",
      "episode 2, val func loss 1.4660810232162476\n",
      "\n",
      "episode 3, val func loss 1.5959668159484863\n",
      "\n",
      "episode 4, val func loss 1.5334004163742065\n",
      "\n",
      "episode 5, val func loss 1.5137170553207397\n",
      "\n",
      "episode 6, val func loss 1.3980958461761475\n",
      "\n",
      "episode 7, val func loss 1.6449397802352905\n",
      "\n",
      "episode 8, val func loss 1.4344680309295654\n",
      "\n",
      "episode 9, val func loss 1.4832347631454468\n",
      "\n",
      "episode 10, val func loss 1.631555199623108\n",
      "\n",
      "episode 11, val func loss 1.6259719133377075\n",
      "\n",
      "episode 12, val func loss 1.7361115217208862\n",
      "\n",
      "episode 13, val func loss 1.5504302978515625\n",
      "\n",
      "episode 14, val func loss 1.40285062789917\n",
      "\n",
      "episode 15, val func loss 1.5568788051605225\n",
      "\n",
      "episode 16, val func loss 1.550795555114746\n",
      "\n",
      "Val func train loss in epoch 9:1.5494800060987473\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.363854169845581\n",
      "\n",
      "episode 2, val func loss 1.58263099193573\n",
      "\n",
      "episode 3, val func loss 1.516937255859375\n",
      "\n",
      "episode 4, val func loss 1.448743462562561\n",
      "\n",
      "episode 5, val func loss 1.5115598440170288\n",
      "\n",
      "episode 6, val func loss 1.440077781677246\n",
      "\n",
      "episode 7, val func loss 1.344919204711914\n",
      "\n",
      "episode 8, val func loss 1.512713074684143\n",
      "\n",
      "episode 9, val func loss 1.70598304271698\n",
      "\n",
      "episode 10, val func loss 1.5243927240371704\n",
      "\n",
      "episode 11, val func loss 1.4630718231201172\n",
      "\n",
      "episode 12, val func loss 1.6821380853652954\n",
      "\n",
      "episode 13, val func loss 1.6892198324203491\n",
      "\n",
      "episode 14, val func loss 1.3517875671386719\n",
      "\n",
      "episode 15, val func loss 1.5594031810760498\n",
      "\n",
      "episode 16, val func loss 1.5436038970947266\n",
      "\n",
      "Val func train loss in epoch 10:1.5150647461414337\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.570913314819336\n",
      "\n",
      "episode 2, val func loss 1.4442412853240967\n",
      "\n",
      "episode 3, val func loss 1.4505199193954468\n",
      "\n",
      "episode 4, val func loss 1.4732208251953125\n",
      "\n",
      "episode 5, val func loss 1.6030346155166626\n",
      "\n",
      "episode 6, val func loss 1.4872219562530518\n",
      "\n",
      "episode 7, val func loss 1.4485536813735962\n",
      "\n",
      "episode 8, val func loss 1.4520996809005737\n",
      "\n",
      "episode 9, val func loss 1.6045061349868774\n",
      "\n",
      "episode 10, val func loss 1.4599968194961548\n",
      "\n",
      "episode 11, val func loss 1.5428128242492676\n",
      "\n",
      "episode 12, val func loss 1.5358014106750488\n",
      "\n",
      "episode 13, val func loss 1.4584354162216187\n",
      "\n",
      "episode 14, val func loss 1.312826156616211\n",
      "\n",
      "episode 15, val func loss 1.61522376537323\n",
      "\n",
      "episode 16, val func loss 1.459890604019165\n",
      "\n",
      "Val func train loss in epoch 11:1.494956150650978\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.5289137363433838\n",
      "\n",
      "episode 2, val func loss 1.405380129814148\n",
      "\n",
      "episode 3, val func loss 1.2845145463943481\n",
      "\n",
      "episode 4, val func loss 1.3539361953735352\n",
      "\n",
      "episode 5, val func loss 1.4833738803863525\n",
      "\n",
      "episode 6, val func loss 1.4998549222946167\n",
      "\n",
      "episode 7, val func loss 1.4821414947509766\n",
      "\n",
      "episode 8, val func loss 1.4843825101852417\n",
      "\n",
      "episode 9, val func loss 1.5142955780029297\n",
      "\n",
      "episode 10, val func loss 1.4835082292556763\n",
      "\n",
      "episode 11, val func loss 1.6163116693496704\n",
      "\n",
      "episode 12, val func loss 1.4171719551086426\n",
      "\n",
      "episode 13, val func loss 1.6046444177627563\n",
      "\n",
      "episode 14, val func loss 1.6679401397705078\n",
      "\n",
      "episode 15, val func loss 1.5286937952041626\n",
      "\n",
      "episode 16, val func loss 1.473502278327942\n",
      "\n",
      "Val func train loss in epoch 12:1.4892853423953056\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.4039665460586548\n",
      "\n",
      "episode 2, val func loss 1.5175317525863647\n",
      "\n",
      "episode 3, val func loss 1.6446185111999512\n",
      "\n",
      "episode 4, val func loss 1.4695968627929688\n",
      "\n",
      "episode 5, val func loss 1.493409514427185\n",
      "\n",
      "episode 6, val func loss 1.3947159051895142\n",
      "\n",
      "episode 7, val func loss 1.3821767568588257\n",
      "\n",
      "episode 8, val func loss 1.3873465061187744\n",
      "\n",
      "episode 9, val func loss 1.3897733688354492\n",
      "\n",
      "episode 10, val func loss 1.5648680925369263\n",
      "\n",
      "episode 11, val func loss 1.5873652696609497\n",
      "\n",
      "episode 12, val func loss 1.3532294034957886\n",
      "\n",
      "episode 13, val func loss 1.5704288482666016\n",
      "\n",
      "episode 14, val func loss 1.5712214708328247\n",
      "\n",
      "episode 15, val func loss 1.75177001953125\n",
      "\n",
      "episode 16, val func loss 1.5266720056533813\n",
      "\n",
      "Val func train loss in epoch 13:1.5005431771278381\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.5912535190582275\n",
      "\n",
      "episode 2, val func loss 1.6692452430725098\n",
      "\n",
      "episode 3, val func loss 1.619022011756897\n",
      "\n",
      "episode 4, val func loss 1.5927131175994873\n",
      "\n",
      "episode 5, val func loss 1.6379549503326416\n",
      "\n",
      "episode 6, val func loss 1.3550580739974976\n",
      "\n",
      "episode 7, val func loss 1.8346256017684937\n",
      "\n",
      "episode 8, val func loss 1.4249958992004395\n",
      "\n",
      "episode 9, val func loss 1.49454927444458\n",
      "\n",
      "episode 10, val func loss 1.7416468858718872\n",
      "\n",
      "episode 11, val func loss 1.5623066425323486\n",
      "\n",
      "episode 12, val func loss 1.6365814208984375\n",
      "\n",
      "episode 13, val func loss 1.51668381690979\n",
      "\n",
      "episode 14, val func loss 1.508110761642456\n",
      "\n",
      "episode 15, val func loss 1.4277113676071167\n",
      "\n",
      "episode 16, val func loss 1.5830124616622925\n",
      "\n",
      "Val func train loss in epoch 14:1.574716940522194\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.5423870086669922\n",
      "\n",
      "episode 2, val func loss 1.6419363021850586\n",
      "\n",
      "episode 3, val func loss 1.5171986818313599\n",
      "\n",
      "episode 4, val func loss 1.2796821594238281\n",
      "\n",
      "episode 5, val func loss 1.6120413541793823\n",
      "\n",
      "episode 6, val func loss 1.4298062324523926\n",
      "\n",
      "episode 7, val func loss 1.2442102432250977\n",
      "\n",
      "episode 8, val func loss 1.3810746669769287\n",
      "\n",
      "episode 9, val func loss 1.381062626838684\n",
      "\n",
      "episode 10, val func loss 1.3477405309677124\n",
      "\n",
      "episode 11, val func loss 1.4212030172348022\n",
      "\n",
      "episode 12, val func loss 1.5381057262420654\n",
      "\n",
      "episode 13, val func loss 1.2916194200515747\n",
      "\n",
      "episode 14, val func loss 1.7202880382537842\n",
      "\n",
      "episode 15, val func loss 1.4646117687225342\n",
      "\n",
      "episode 16, val func loss 1.251842975616455\n",
      "\n",
      "Val func train loss in epoch 15:1.4415506720542908\n",
      "***********************TIME WAS 4.818689012527466 min*****************************\n",
      "\n",
      "**********************ROUND 30 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.4254150390625\n",
      "\n",
      "episode 2, policy loss -2.4254150390625\n",
      "\n",
      "episode 3, policy loss -2.425414800643921\n",
      "\n",
      "episode 4, policy loss -2.425414800643921\n",
      "\n",
      "episode 5, policy loss -2.425414800643921\n",
      "\n",
      "episode 6, policy loss -2.4254150390625\n",
      "\n",
      "episode 7, policy loss -2.425414562225342\n",
      "\n",
      "episode 8, policy loss -2.4254150390625\n",
      "\n",
      "episode 9, policy loss -2.4254143238067627\n",
      "\n",
      "episode 10, policy loss -2.425414800643921\n",
      "\n",
      "episode 11, policy loss -2.425414800643921\n",
      "\n",
      "episode 12, policy loss -2.425414800643921\n",
      "\n",
      "episode 13, policy loss -2.425414800643921\n",
      "\n",
      "episode 14, policy loss -2.425414562225342\n",
      "\n",
      "episode 15, policy loss -2.4254150390625\n",
      "\n",
      "episode 16, policy loss -2.425414800643921\n",
      "\n",
      "Policy train loss in epoch 0:-2.425414815545082\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.425414562225342\n",
      "\n",
      "episode 2, policy loss -2.4254143238067627\n",
      "\n",
      "episode 3, policy loss -2.425414800643921\n",
      "\n",
      "episode 4, policy loss -2.425414800643921\n",
      "\n",
      "episode 5, policy loss -2.425414800643921\n",
      "\n",
      "episode 6, policy loss -2.425414800643921\n",
      "\n",
      "episode 7, policy loss -2.425414800643921\n",
      "\n",
      "episode 8, policy loss -2.4254150390625\n",
      "\n",
      "episode 9, policy loss -2.425414800643921\n",
      "\n",
      "episode 10, policy loss -2.425414800643921\n",
      "\n",
      "episode 11, policy loss -2.425414562225342\n",
      "\n",
      "episode 12, policy loss -2.4254150390625\n",
      "\n",
      "episode 13, policy loss -2.4254150390625\n",
      "\n",
      "episode 14, policy loss -2.4254150390625\n",
      "\n",
      "episode 15, policy loss -2.4254150390625\n",
      "\n",
      "episode 16, policy loss -2.425414800643921\n",
      "\n",
      "Policy train loss in epoch 1:-2.425414815545082\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.4254150390625\n",
      "\n",
      "episode 2, policy loss -2.425414800643921\n",
      "\n",
      "episode 3, policy loss -2.425414800643921\n",
      "\n",
      "episode 4, policy loss -2.425414800643921\n",
      "\n",
      "episode 5, policy loss -2.425414562225342\n",
      "\n",
      "episode 6, policy loss -2.4254150390625\n",
      "\n",
      "episode 7, policy loss -2.425414800643921\n",
      "\n",
      "episode 8, policy loss -2.4254150390625\n",
      "\n",
      "episode 9, policy loss -2.425414800643921\n",
      "\n",
      "episode 10, policy loss -2.425414562225342\n",
      "\n",
      "episode 11, policy loss -2.425414800643921\n",
      "\n",
      "episode 12, policy loss -2.4254143238067627\n",
      "\n",
      "episode 13, policy loss -2.4254150390625\n",
      "\n",
      "episode 14, policy loss -2.425414800643921\n",
      "\n",
      "episode 15, policy loss -2.4254150390625\n",
      "\n",
      "episode 16, policy loss -2.425414800643921\n",
      "\n",
      "Policy train loss in epoch 2:-2.425414815545082\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.425414562225342\n",
      "\n",
      "episode 2, policy loss -2.4254143238067627\n",
      "\n",
      "episode 3, policy loss -2.425414562225342\n",
      "\n",
      "episode 4, policy loss -2.425414800643921\n",
      "\n",
      "episode 5, policy loss -2.425414800643921\n",
      "\n",
      "episode 6, policy loss -2.4254150390625\n",
      "\n",
      "episode 7, policy loss -2.425414800643921\n",
      "\n",
      "episode 8, policy loss -2.4254150390625\n",
      "\n",
      "episode 9, policy loss -2.4254150390625\n",
      "\n",
      "episode 10, policy loss -2.425414800643921\n",
      "\n",
      "episode 11, policy loss -2.425414800643921\n",
      "\n",
      "episode 12, policy loss -2.425414800643921\n",
      "\n",
      "episode 13, policy loss -2.425414800643921\n",
      "\n",
      "episode 14, policy loss -2.425414800643921\n",
      "\n",
      "episode 15, policy loss -2.4254150390625\n",
      "\n",
      "episode 16, policy loss -2.4254150390625\n",
      "\n",
      "Policy train loss in epoch 3:-2.425414815545082\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.5839918851852417\n",
      "\n",
      "episode 2, val func loss 1.4880740642547607\n",
      "\n",
      "episode 3, val func loss 1.6030439138412476\n",
      "\n",
      "episode 4, val func loss 1.517701268196106\n",
      "\n",
      "episode 5, val func loss 1.5765430927276611\n",
      "\n",
      "episode 6, val func loss 1.4114187955856323\n",
      "\n",
      "episode 7, val func loss 1.592214822769165\n",
      "\n",
      "episode 8, val func loss 1.3711881637573242\n",
      "\n",
      "episode 9, val func loss 1.59721040725708\n",
      "\n",
      "episode 10, val func loss 1.4330997467041016\n",
      "\n",
      "episode 11, val func loss 1.6141717433929443\n",
      "\n",
      "episode 12, val func loss 1.606393575668335\n",
      "\n",
      "episode 13, val func loss 1.4006049633026123\n",
      "\n",
      "episode 14, val func loss 1.5938211679458618\n",
      "\n",
      "episode 15, val func loss 1.531158447265625\n",
      "\n",
      "episode 16, val func loss 1.530856966972351\n",
      "\n",
      "Val func train loss in epoch 0:1.5282183140516281\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.4415329694747925\n",
      "\n",
      "episode 2, val func loss 1.502319574356079\n",
      "\n",
      "episode 3, val func loss 1.3684415817260742\n",
      "\n",
      "episode 4, val func loss 1.4034783840179443\n",
      "\n",
      "episode 5, val func loss 1.62148118019104\n",
      "\n",
      "episode 6, val func loss 1.6326382160186768\n",
      "\n",
      "episode 7, val func loss 1.7293281555175781\n",
      "\n",
      "episode 8, val func loss 1.504280924797058\n",
      "\n",
      "episode 9, val func loss 1.4645992517471313\n",
      "\n",
      "episode 10, val func loss 1.417120099067688\n",
      "\n",
      "episode 11, val func loss 1.4217567443847656\n",
      "\n",
      "episode 12, val func loss 1.3901368379592896\n",
      "\n",
      "episode 13, val func loss 1.4449632167816162\n",
      "\n",
      "episode 14, val func loss 1.3651213645935059\n",
      "\n",
      "episode 15, val func loss 1.303906798362732\n",
      "\n",
      "episode 16, val func loss 1.3748931884765625\n",
      "\n",
      "Val func train loss in epoch 1:1.4616249054670334\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.3990952968597412\n",
      "\n",
      "episode 2, val func loss 1.2778284549713135\n",
      "\n",
      "episode 3, val func loss 1.3320735692977905\n",
      "\n",
      "episode 4, val func loss 1.365400791168213\n",
      "\n",
      "episode 5, val func loss 1.4638636112213135\n",
      "\n",
      "episode 6, val func loss 1.457737684249878\n",
      "\n",
      "episode 7, val func loss 1.5471770763397217\n",
      "\n",
      "episode 8, val func loss 1.2828559875488281\n",
      "\n",
      "episode 9, val func loss 1.5278210639953613\n",
      "\n",
      "episode 10, val func loss 1.7302128076553345\n",
      "\n",
      "episode 11, val func loss 1.2399275302886963\n",
      "\n",
      "episode 12, val func loss 1.4173065423965454\n",
      "\n",
      "episode 13, val func loss 1.3354331254959106\n",
      "\n",
      "episode 14, val func loss 1.6416027545928955\n",
      "\n",
      "episode 15, val func loss 1.418793797492981\n",
      "\n",
      "episode 16, val func loss 1.6439813375473022\n",
      "\n",
      "Val func train loss in epoch 2:1.4425694644451141\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.6230531930923462\n",
      "\n",
      "episode 2, val func loss 1.4390850067138672\n",
      "\n",
      "episode 3, val func loss 1.926659107208252\n",
      "\n",
      "episode 4, val func loss 1.6689066886901855\n",
      "\n",
      "episode 5, val func loss 1.4110872745513916\n",
      "\n",
      "episode 6, val func loss 1.702038288116455\n",
      "\n",
      "episode 7, val func loss 1.466802716255188\n",
      "\n",
      "episode 8, val func loss 1.5766260623931885\n",
      "\n",
      "episode 9, val func loss 1.547678828239441\n",
      "\n",
      "episode 10, val func loss 1.6569551229476929\n",
      "\n",
      "episode 11, val func loss 1.4935911893844604\n",
      "\n",
      "episode 12, val func loss 1.3028290271759033\n",
      "\n",
      "episode 13, val func loss 1.4333614110946655\n",
      "\n",
      "episode 14, val func loss 1.5221710205078125\n",
      "\n",
      "episode 15, val func loss 1.4002060890197754\n",
      "\n",
      "episode 16, val func loss 1.4741488695144653\n",
      "\n",
      "Val func train loss in epoch 3:1.5403249934315681\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.44120192527771\n",
      "\n",
      "episode 2, val func loss 1.5595048666000366\n",
      "\n",
      "episode 3, val func loss 1.473928689956665\n",
      "\n",
      "episode 4, val func loss 1.3389558792114258\n",
      "\n",
      "episode 5, val func loss 1.2034087181091309\n",
      "\n",
      "episode 6, val func loss 1.30983567237854\n",
      "\n",
      "episode 7, val func loss 1.4188642501831055\n",
      "\n",
      "episode 8, val func loss 1.4375907182693481\n",
      "\n",
      "episode 9, val func loss 1.2641290426254272\n",
      "\n",
      "episode 10, val func loss 1.4497342109680176\n",
      "\n",
      "episode 11, val func loss 1.6398296356201172\n",
      "\n",
      "episode 12, val func loss 1.2607587575912476\n",
      "\n",
      "episode 13, val func loss 1.560680627822876\n",
      "\n",
      "episode 14, val func loss 1.4741201400756836\n",
      "\n",
      "episode 15, val func loss 1.4211978912353516\n",
      "\n",
      "episode 16, val func loss 1.3737812042236328\n",
      "\n",
      "Val func train loss in epoch 4:1.4142201393842697\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.538543939590454\n",
      "\n",
      "episode 2, val func loss 1.7017252445220947\n",
      "\n",
      "episode 3, val func loss 1.5739421844482422\n",
      "\n",
      "episode 4, val func loss 1.494192123413086\n",
      "\n",
      "episode 5, val func loss 1.4131803512573242\n",
      "\n",
      "episode 6, val func loss 1.6635745763778687\n",
      "\n",
      "episode 7, val func loss 1.5510234832763672\n",
      "\n",
      "episode 8, val func loss 1.5165561437606812\n",
      "\n",
      "episode 9, val func loss 1.2909748554229736\n",
      "\n",
      "episode 10, val func loss 1.16041100025177\n",
      "\n",
      "episode 11, val func loss 1.5507107973098755\n",
      "\n",
      "episode 12, val func loss 1.6847023963928223\n",
      "\n",
      "episode 13, val func loss 1.4237704277038574\n",
      "\n",
      "episode 14, val func loss 1.514312744140625\n",
      "\n",
      "episode 15, val func loss 1.555959939956665\n",
      "\n",
      "episode 16, val func loss 1.4685231447219849\n",
      "\n",
      "Val func train loss in epoch 5:1.5063814595341682\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.4533393383026123\n",
      "\n",
      "episode 2, val func loss 1.5767046213150024\n",
      "\n",
      "episode 3, val func loss 1.5800729990005493\n",
      "\n",
      "episode 4, val func loss 1.3721076250076294\n",
      "\n",
      "episode 5, val func loss 1.5282254219055176\n",
      "\n",
      "episode 6, val func loss 1.697513461112976\n",
      "\n",
      "episode 7, val func loss 1.3573030233383179\n",
      "\n",
      "episode 8, val func loss 1.34009850025177\n",
      "\n",
      "episode 9, val func loss 1.3312723636627197\n",
      "\n",
      "episode 10, val func loss 1.4317076206207275\n",
      "\n",
      "episode 11, val func loss 1.3985658884048462\n",
      "\n",
      "episode 12, val func loss 1.5151103734970093\n",
      "\n",
      "episode 13, val func loss 1.6162976026535034\n",
      "\n",
      "episode 14, val func loss 1.3218493461608887\n",
      "\n",
      "episode 15, val func loss 1.5763633251190186\n",
      "\n",
      "episode 16, val func loss 1.5501906871795654\n",
      "\n",
      "Val func train loss in epoch 6:1.4779201373457909\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.4460903406143188\n",
      "\n",
      "episode 2, val func loss 1.4289731979370117\n",
      "\n",
      "episode 3, val func loss 1.4816855192184448\n",
      "\n",
      "episode 4, val func loss 1.4132258892059326\n",
      "\n",
      "episode 5, val func loss 1.4310438632965088\n",
      "\n",
      "episode 6, val func loss 1.4447011947631836\n",
      "\n",
      "episode 7, val func loss 1.5479212999343872\n",
      "\n",
      "episode 8, val func loss 1.5350524187088013\n",
      "\n",
      "episode 9, val func loss 1.56099534034729\n",
      "\n",
      "episode 10, val func loss 1.5387126207351685\n",
      "\n",
      "episode 11, val func loss 1.5684423446655273\n",
      "\n",
      "episode 12, val func loss 1.4755656719207764\n",
      "\n",
      "episode 13, val func loss 1.544334053993225\n",
      "\n",
      "episode 14, val func loss 1.432098388671875\n",
      "\n",
      "episode 15, val func loss 1.3496075868606567\n",
      "\n",
      "episode 16, val func loss 1.338454008102417\n",
      "\n",
      "Val func train loss in epoch 7:1.4710564836859703\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.5162287950515747\n",
      "\n",
      "episode 2, val func loss 1.8161238431930542\n",
      "\n",
      "episode 3, val func loss 1.485231876373291\n",
      "\n",
      "episode 4, val func loss 1.388758659362793\n",
      "\n",
      "episode 5, val func loss 1.5075174570083618\n",
      "\n",
      "episode 6, val func loss 1.6663888692855835\n",
      "\n",
      "episode 7, val func loss 1.3280941247940063\n",
      "\n",
      "episode 8, val func loss 1.3915988206863403\n",
      "\n",
      "episode 9, val func loss 1.4815796613693237\n",
      "\n",
      "episode 10, val func loss 1.438263177871704\n",
      "\n",
      "episode 11, val func loss 1.3888696432113647\n",
      "\n",
      "episode 12, val func loss 1.5434629917144775\n",
      "\n",
      "episode 13, val func loss 1.5219428539276123\n",
      "\n",
      "episode 14, val func loss 1.624181866645813\n",
      "\n",
      "episode 15, val func loss 1.7515474557876587\n",
      "\n",
      "episode 16, val func loss 1.327202558517456\n",
      "\n",
      "Val func train loss in epoch 8:1.511062040925026\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.4007115364074707\n",
      "\n",
      "episode 2, val func loss 1.5751936435699463\n",
      "\n",
      "episode 3, val func loss 1.58213472366333\n",
      "\n",
      "episode 4, val func loss 1.38906991481781\n",
      "\n",
      "episode 5, val func loss 1.4025534391403198\n",
      "\n",
      "episode 6, val func loss 1.516309380531311\n",
      "\n",
      "episode 7, val func loss 1.6231099367141724\n",
      "\n",
      "episode 8, val func loss 1.448545217514038\n",
      "\n",
      "episode 9, val func loss 1.6069090366363525\n",
      "\n",
      "episode 10, val func loss 1.4783488512039185\n",
      "\n",
      "episode 11, val func loss 1.4645344018936157\n",
      "\n",
      "episode 12, val func loss 1.3583014011383057\n",
      "\n",
      "episode 13, val func loss 1.5773297548294067\n",
      "\n",
      "episode 14, val func loss 1.2964144945144653\n",
      "\n",
      "episode 15, val func loss 1.4492758512496948\n",
      "\n",
      "episode 16, val func loss 1.2888469696044922\n",
      "\n",
      "Val func train loss in epoch 9:1.4660992845892906\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.3162552118301392\n",
      "\n",
      "episode 2, val func loss 1.3518719673156738\n",
      "\n",
      "episode 3, val func loss 1.500780701637268\n",
      "\n",
      "episode 4, val func loss 1.425144076347351\n",
      "\n",
      "episode 5, val func loss 1.3626683950424194\n",
      "\n",
      "episode 6, val func loss 1.5279710292816162\n",
      "\n",
      "episode 7, val func loss 1.4813251495361328\n",
      "\n",
      "episode 8, val func loss 1.4245707988739014\n",
      "\n",
      "episode 9, val func loss 1.4313782453536987\n",
      "\n",
      "episode 10, val func loss 1.3323283195495605\n",
      "\n",
      "episode 11, val func loss 1.4267669916152954\n",
      "\n",
      "episode 12, val func loss 1.2359261512756348\n",
      "\n",
      "episode 13, val func loss 1.5006519556045532\n",
      "\n",
      "episode 14, val func loss 1.3980573415756226\n",
      "\n",
      "episode 15, val func loss 1.4090371131896973\n",
      "\n",
      "episode 16, val func loss 1.5862644910812378\n",
      "\n",
      "Val func train loss in epoch 10:1.4194373711943626\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.3299577236175537\n",
      "\n",
      "episode 2, val func loss 1.4200485944747925\n",
      "\n",
      "episode 3, val func loss 1.4787559509277344\n",
      "\n",
      "episode 4, val func loss 1.1407617330551147\n",
      "\n",
      "episode 5, val func loss 1.4203218221664429\n",
      "\n",
      "episode 6, val func loss 1.1711432933807373\n",
      "\n",
      "episode 7, val func loss 1.4292370080947876\n",
      "\n",
      "episode 8, val func loss 1.4097167253494263\n",
      "\n",
      "episode 9, val func loss 1.357869267463684\n",
      "\n",
      "episode 10, val func loss 1.37651789188385\n",
      "\n",
      "episode 11, val func loss 1.4570587873458862\n",
      "\n",
      "episode 12, val func loss 1.247828483581543\n",
      "\n",
      "episode 13, val func loss 1.3114012479782104\n",
      "\n",
      "episode 14, val func loss 1.606834053993225\n",
      "\n",
      "episode 15, val func loss 1.5967687368392944\n",
      "\n",
      "episode 16, val func loss 1.4530260562896729\n",
      "\n",
      "Val func train loss in epoch 11:1.3879529610276222\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.3935843706130981\n",
      "\n",
      "episode 2, val func loss 1.2928626537322998\n",
      "\n",
      "episode 3, val func loss 1.3539609909057617\n",
      "\n",
      "episode 4, val func loss 1.3168959617614746\n",
      "\n",
      "episode 5, val func loss 1.4684803485870361\n",
      "\n",
      "episode 6, val func loss 1.3235881328582764\n",
      "\n",
      "episode 7, val func loss 1.2964025735855103\n",
      "\n",
      "episode 8, val func loss 1.4128869771957397\n",
      "\n",
      "episode 9, val func loss 1.3013461828231812\n",
      "\n",
      "episode 10, val func loss 1.2252057790756226\n",
      "\n",
      "episode 11, val func loss 1.5125198364257812\n",
      "\n",
      "episode 12, val func loss 1.152189016342163\n",
      "\n",
      "episode 13, val func loss 1.3268132209777832\n",
      "\n",
      "episode 14, val func loss 1.2419432401657104\n",
      "\n",
      "episode 15, val func loss 1.4816927909851074\n",
      "\n",
      "episode 16, val func loss 1.4781289100646973\n",
      "\n",
      "Val func train loss in epoch 12:1.3486563116312027\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.305640459060669\n",
      "\n",
      "episode 2, val func loss 1.4671672582626343\n",
      "\n",
      "episode 3, val func loss 1.4650038480758667\n",
      "\n",
      "episode 4, val func loss 1.3989758491516113\n",
      "\n",
      "episode 5, val func loss 1.5258166790008545\n",
      "\n",
      "episode 6, val func loss 1.3661154508590698\n",
      "\n",
      "episode 7, val func loss 1.5135661363601685\n",
      "\n",
      "episode 8, val func loss 1.3680436611175537\n",
      "\n",
      "episode 9, val func loss 1.4363420009613037\n",
      "\n",
      "episode 10, val func loss 1.4223603010177612\n",
      "\n",
      "episode 11, val func loss 1.2820826768875122\n",
      "\n",
      "episode 12, val func loss 1.3322921991348267\n",
      "\n",
      "episode 13, val func loss 1.3850475549697876\n",
      "\n",
      "episode 14, val func loss 1.2786717414855957\n",
      "\n",
      "episode 15, val func loss 1.3440132141113281\n",
      "\n",
      "episode 16, val func loss 1.2890892028808594\n",
      "\n",
      "Val func train loss in epoch 13:1.3862642645835876\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.363767385482788\n",
      "\n",
      "episode 2, val func loss 1.3849023580551147\n",
      "\n",
      "episode 3, val func loss 1.2337392568588257\n",
      "\n",
      "episode 4, val func loss 1.4669524431228638\n",
      "\n",
      "episode 5, val func loss 1.391804575920105\n",
      "\n",
      "episode 6, val func loss 1.27408766746521\n",
      "\n",
      "episode 7, val func loss 1.4432787895202637\n",
      "\n",
      "episode 8, val func loss 1.5398163795471191\n",
      "\n",
      "episode 9, val func loss 1.4427963495254517\n",
      "\n",
      "episode 10, val func loss 1.270011067390442\n",
      "\n",
      "episode 11, val func loss 1.251845121383667\n",
      "\n",
      "episode 12, val func loss 1.42597234249115\n",
      "\n",
      "episode 13, val func loss 1.3392143249511719\n",
      "\n",
      "episode 14, val func loss 1.6611162424087524\n",
      "\n",
      "episode 15, val func loss 1.5044368505477905\n",
      "\n",
      "episode 16, val func loss 1.3081876039505005\n",
      "\n",
      "Val func train loss in epoch 14:1.393870547413826\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.4122815132141113\n",
      "\n",
      "episode 2, val func loss 1.442138671875\n",
      "\n",
      "episode 3, val func loss 1.4090656042099\n",
      "\n",
      "episode 4, val func loss 1.3416314125061035\n",
      "\n",
      "episode 5, val func loss 1.5357738733291626\n",
      "\n",
      "episode 6, val func loss 1.38721764087677\n",
      "\n",
      "episode 7, val func loss 1.4638030529022217\n",
      "\n",
      "episode 8, val func loss 1.272200107574463\n",
      "\n",
      "episode 9, val func loss 1.5640209913253784\n",
      "\n",
      "episode 10, val func loss 1.2775243520736694\n",
      "\n",
      "episode 11, val func loss 1.3860416412353516\n",
      "\n",
      "episode 12, val func loss 1.4974567890167236\n",
      "\n",
      "episode 13, val func loss 1.5442571640014648\n",
      "\n",
      "episode 14, val func loss 1.4925719499588013\n",
      "\n",
      "episode 15, val func loss 1.4889204502105713\n",
      "\n",
      "episode 16, val func loss 1.44575834274292\n",
      "\n",
      "Val func train loss in epoch 15:1.4350414723157883\n",
      "***********************TIME WAS 4.812149719397227 min*****************************\n",
      "\n",
      "**********************ROUND 31 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.66495943069458\n",
      "\n",
      "episode 2, policy loss -2.66495943069458\n",
      "\n",
      "episode 3, policy loss -2.66495943069458\n",
      "\n",
      "episode 4, policy loss -2.66495943069458\n",
      "\n",
      "episode 5, policy loss -2.66495943069458\n",
      "\n",
      "episode 6, policy loss -2.66495943069458\n",
      "\n",
      "episode 7, policy loss -2.66495943069458\n",
      "\n",
      "episode 8, policy loss -2.66495943069458\n",
      "\n",
      "episode 9, policy loss -2.66495943069458\n",
      "\n",
      "episode 10, policy loss -2.66495943069458\n",
      "\n",
      "episode 11, policy loss -2.66495943069458\n",
      "\n",
      "episode 12, policy loss -2.66495943069458\n",
      "\n",
      "episode 13, policy loss -2.66495943069458\n",
      "\n",
      "episode 14, policy loss -2.66495943069458\n",
      "\n",
      "episode 15, policy loss -2.66495943069458\n",
      "\n",
      "episode 16, policy loss -2.66495943069458\n",
      "\n",
      "Policy train loss in epoch 0:-2.66495943069458\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.66495943069458\n",
      "\n",
      "episode 2, policy loss -2.66495943069458\n",
      "\n",
      "episode 3, policy loss -2.66495943069458\n",
      "\n",
      "episode 4, policy loss -2.66495943069458\n",
      "\n",
      "episode 5, policy loss -2.66495943069458\n",
      "\n",
      "episode 6, policy loss -2.66495943069458\n",
      "\n",
      "episode 7, policy loss -2.66495943069458\n",
      "\n",
      "episode 8, policy loss -2.66495943069458\n",
      "\n",
      "episode 9, policy loss -2.66495943069458\n",
      "\n",
      "episode 10, policy loss -2.66495943069458\n",
      "\n",
      "episode 11, policy loss -2.66495943069458\n",
      "\n",
      "episode 12, policy loss -2.66495943069458\n",
      "\n",
      "episode 13, policy loss -2.66495943069458\n",
      "\n",
      "episode 14, policy loss -2.66495943069458\n",
      "\n",
      "episode 15, policy loss -2.66495943069458\n",
      "\n",
      "episode 16, policy loss -2.66495943069458\n",
      "\n",
      "Policy train loss in epoch 1:-2.66495943069458\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.66495943069458\n",
      "\n",
      "episode 2, policy loss -2.66495943069458\n",
      "\n",
      "episode 3, policy loss -2.66495943069458\n",
      "\n",
      "episode 4, policy loss -2.66495943069458\n",
      "\n",
      "episode 5, policy loss -2.66495943069458\n",
      "\n",
      "episode 6, policy loss -2.66495943069458\n",
      "\n",
      "episode 7, policy loss -2.66495943069458\n",
      "\n",
      "episode 8, policy loss -2.66495943069458\n",
      "\n",
      "episode 9, policy loss -2.66495943069458\n",
      "\n",
      "episode 10, policy loss -2.66495943069458\n",
      "\n",
      "episode 11, policy loss -2.66495943069458\n",
      "\n",
      "episode 12, policy loss -2.66495943069458\n",
      "\n",
      "episode 13, policy loss -2.66495943069458\n",
      "\n",
      "episode 14, policy loss -2.66495943069458\n",
      "\n",
      "episode 15, policy loss -2.66495943069458\n",
      "\n",
      "episode 16, policy loss -2.66495943069458\n",
      "\n",
      "Policy train loss in epoch 2:-2.66495943069458\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.66495943069458\n",
      "\n",
      "episode 2, policy loss -2.66495943069458\n",
      "\n",
      "episode 3, policy loss -2.66495943069458\n",
      "\n",
      "episode 4, policy loss -2.66495943069458\n",
      "\n",
      "episode 5, policy loss -2.66495943069458\n",
      "\n",
      "episode 6, policy loss -2.66495943069458\n",
      "\n",
      "episode 7, policy loss -2.66495943069458\n",
      "\n",
      "episode 8, policy loss -2.66495943069458\n",
      "\n",
      "episode 9, policy loss -2.66495943069458\n",
      "\n",
      "episode 10, policy loss -2.66495943069458\n",
      "\n",
      "episode 11, policy loss -2.66495943069458\n",
      "\n",
      "episode 12, policy loss -2.66495943069458\n",
      "\n",
      "episode 13, policy loss -2.66495943069458\n",
      "\n",
      "episode 14, policy loss -2.66495943069458\n",
      "\n",
      "episode 15, policy loss -2.66495943069458\n",
      "\n",
      "episode 16, policy loss -2.66495943069458\n",
      "\n",
      "Policy train loss in epoch 3:-2.66495943069458\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.418947696685791\n",
      "\n",
      "episode 2, val func loss 1.596001386642456\n",
      "\n",
      "episode 3, val func loss 1.226525902748108\n",
      "\n",
      "episode 4, val func loss 1.3808603286743164\n",
      "\n",
      "episode 5, val func loss 1.4401099681854248\n",
      "\n",
      "episode 6, val func loss 1.3333057165145874\n",
      "\n",
      "episode 7, val func loss 1.4438161849975586\n",
      "\n",
      "episode 8, val func loss 1.348634123802185\n",
      "\n",
      "episode 9, val func loss 1.409291386604309\n",
      "\n",
      "episode 10, val func loss 1.3168562650680542\n",
      "\n",
      "episode 11, val func loss 1.1986162662506104\n",
      "\n",
      "episode 12, val func loss 1.1860568523406982\n",
      "\n",
      "episode 13, val func loss 1.4254233837127686\n",
      "\n",
      "episode 14, val func loss 1.3998171091079712\n",
      "\n",
      "episode 15, val func loss 1.3104585409164429\n",
      "\n",
      "episode 16, val func loss 1.4483836889266968\n",
      "\n",
      "Val func train loss in epoch 0:1.3676940500736237\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.3492951393127441\n",
      "\n",
      "episode 2, val func loss 1.5514293909072876\n",
      "\n",
      "episode 3, val func loss 1.5164430141448975\n",
      "\n",
      "episode 4, val func loss 1.5386873483657837\n",
      "\n",
      "episode 5, val func loss 1.5189331769943237\n",
      "\n",
      "episode 6, val func loss 1.4895908832550049\n",
      "\n",
      "episode 7, val func loss 1.2766308784484863\n",
      "\n",
      "episode 8, val func loss 1.27059006690979\n",
      "\n",
      "episode 9, val func loss 1.4271676540374756\n",
      "\n",
      "episode 10, val func loss 1.376204490661621\n",
      "\n",
      "episode 11, val func loss 1.1309260129928589\n",
      "\n",
      "episode 12, val func loss 1.3364061117172241\n",
      "\n",
      "episode 13, val func loss 1.5440163612365723\n",
      "\n",
      "episode 14, val func loss 1.3368980884552002\n",
      "\n",
      "episode 15, val func loss 1.4550169706344604\n",
      "\n",
      "episode 16, val func loss 1.4942584037780762\n",
      "\n",
      "Val func train loss in epoch 1:1.413280874490738\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.2660568952560425\n",
      "\n",
      "episode 2, val func loss 1.4468454122543335\n",
      "\n",
      "episode 3, val func loss 1.4027864933013916\n",
      "\n",
      "episode 4, val func loss 1.4515668153762817\n",
      "\n",
      "episode 5, val func loss 1.1317442655563354\n",
      "\n",
      "episode 6, val func loss 1.205608606338501\n",
      "\n",
      "episode 7, val func loss 1.4644218683242798\n",
      "\n",
      "episode 8, val func loss 1.2586429119110107\n",
      "\n",
      "episode 9, val func loss 1.3645708560943604\n",
      "\n",
      "episode 10, val func loss 1.2659507989883423\n",
      "\n",
      "episode 11, val func loss 1.548819899559021\n",
      "\n",
      "episode 12, val func loss 1.467046856880188\n",
      "\n",
      "episode 13, val func loss 1.3878998756408691\n",
      "\n",
      "episode 14, val func loss 1.4520652294158936\n",
      "\n",
      "episode 15, val func loss 1.4573063850402832\n",
      "\n",
      "episode 16, val func loss 1.4411983489990234\n",
      "\n",
      "Val func train loss in epoch 2:1.3757832199335098\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.4727506637573242\n",
      "\n",
      "episode 2, val func loss 1.2366679906845093\n",
      "\n",
      "episode 3, val func loss 1.5629746913909912\n",
      "\n",
      "episode 4, val func loss 1.3073424100875854\n",
      "\n",
      "episode 5, val func loss 1.3665833473205566\n",
      "\n",
      "episode 6, val func loss 1.413240909576416\n",
      "\n",
      "episode 7, val func loss 1.3249802589416504\n",
      "\n",
      "episode 8, val func loss 1.3239576816558838\n",
      "\n",
      "episode 9, val func loss 1.2806649208068848\n",
      "\n",
      "episode 10, val func loss 1.8180757761001587\n",
      "\n",
      "episode 11, val func loss 1.4780635833740234\n",
      "\n",
      "episode 12, val func loss 1.4755183458328247\n",
      "\n",
      "episode 13, val func loss 1.4679967164993286\n",
      "\n",
      "episode 14, val func loss 1.4172605276107788\n",
      "\n",
      "episode 15, val func loss 1.6646944284439087\n",
      "\n",
      "episode 16, val func loss 1.233143925666809\n",
      "\n",
      "Val func train loss in epoch 3:1.4277447611093521\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.4736145734786987\n",
      "\n",
      "episode 2, val func loss 1.3324530124664307\n",
      "\n",
      "episode 3, val func loss 1.536133885383606\n",
      "\n",
      "episode 4, val func loss 1.6492854356765747\n",
      "\n",
      "episode 5, val func loss 1.1049021482467651\n",
      "\n",
      "episode 6, val func loss 1.3857907056808472\n",
      "\n",
      "episode 7, val func loss 1.238118290901184\n",
      "\n",
      "episode 8, val func loss 1.3587794303894043\n",
      "\n",
      "episode 9, val func loss 1.4024722576141357\n",
      "\n",
      "episode 10, val func loss 1.4101685285568237\n",
      "\n",
      "episode 11, val func loss 1.2975777387619019\n",
      "\n",
      "episode 12, val func loss 1.3053513765335083\n",
      "\n",
      "episode 13, val func loss 1.3333388566970825\n",
      "\n",
      "episode 14, val func loss 1.0700829029083252\n",
      "\n",
      "episode 15, val func loss 1.5465866327285767\n",
      "\n",
      "episode 16, val func loss 1.2828295230865479\n",
      "\n",
      "Val func train loss in epoch 4:1.3579678311944008\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.417027235031128\n",
      "\n",
      "episode 2, val func loss 1.3565537929534912\n",
      "\n",
      "episode 3, val func loss 1.3109186887741089\n",
      "\n",
      "episode 4, val func loss 1.2749916315078735\n",
      "\n",
      "episode 5, val func loss 1.4165860414505005\n",
      "\n",
      "episode 6, val func loss 1.445639967918396\n",
      "\n",
      "episode 7, val func loss 1.3361483812332153\n",
      "\n",
      "episode 8, val func loss 1.4447280168533325\n",
      "\n",
      "episode 9, val func loss 1.3843456506729126\n",
      "\n",
      "episode 10, val func loss 1.2307792901992798\n",
      "\n",
      "episode 11, val func loss 1.6577754020690918\n",
      "\n",
      "episode 12, val func loss 1.3949015140533447\n",
      "\n",
      "episode 13, val func loss 1.5621200799942017\n",
      "\n",
      "episode 14, val func loss 1.3576308488845825\n",
      "\n",
      "episode 15, val func loss 1.3641455173492432\n",
      "\n",
      "episode 16, val func loss 1.5051848888397217\n",
      "\n",
      "Val func train loss in epoch 5:1.4037173092365265\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.5509536266326904\n",
      "\n",
      "episode 2, val func loss 1.400599479675293\n",
      "\n",
      "episode 3, val func loss 1.3104767799377441\n",
      "\n",
      "episode 4, val func loss 1.320820927619934\n",
      "\n",
      "episode 5, val func loss 1.3849178552627563\n",
      "\n",
      "episode 6, val func loss 1.3154301643371582\n",
      "\n",
      "episode 7, val func loss 1.6915607452392578\n",
      "\n",
      "episode 8, val func loss 1.4311443567276\n",
      "\n",
      "episode 9, val func loss 1.2744115591049194\n",
      "\n",
      "episode 10, val func loss 1.3502082824707031\n",
      "\n",
      "episode 11, val func loss 1.3576651811599731\n",
      "\n",
      "episode 12, val func loss 1.5023252964019775\n",
      "\n",
      "episode 13, val func loss 1.2499492168426514\n",
      "\n",
      "episode 14, val func loss 1.2713350057601929\n",
      "\n",
      "episode 15, val func loss 1.5038704872131348\n",
      "\n",
      "episode 16, val func loss 1.3525251150131226\n",
      "\n",
      "Val func train loss in epoch 6:1.3917621299624443\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.339423656463623\n",
      "\n",
      "episode 2, val func loss 1.3891055583953857\n",
      "\n",
      "episode 3, val func loss 1.4525134563446045\n",
      "\n",
      "episode 4, val func loss 1.494484305381775\n",
      "\n",
      "episode 5, val func loss 1.4351783990859985\n",
      "\n",
      "episode 6, val func loss 1.1300718784332275\n",
      "\n",
      "episode 7, val func loss 1.5655672550201416\n",
      "\n",
      "episode 8, val func loss 1.2132757902145386\n",
      "\n",
      "episode 9, val func loss 1.2153445482254028\n",
      "\n",
      "episode 10, val func loss 1.5032947063446045\n",
      "\n",
      "episode 11, val func loss 1.5170207023620605\n",
      "\n",
      "episode 12, val func loss 1.2670732736587524\n",
      "\n",
      "episode 13, val func loss 1.2322016954421997\n",
      "\n",
      "episode 14, val func loss 1.3851873874664307\n",
      "\n",
      "episode 15, val func loss 1.2469829320907593\n",
      "\n",
      "episode 16, val func loss 1.2003451585769653\n",
      "\n",
      "Val func train loss in epoch 7:1.3491919189691544\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.4366921186447144\n",
      "\n",
      "episode 2, val func loss 1.2643041610717773\n",
      "\n",
      "episode 3, val func loss 1.1526436805725098\n",
      "\n",
      "episode 4, val func loss 1.3763691186904907\n",
      "\n",
      "episode 5, val func loss 1.2347455024719238\n",
      "\n",
      "episode 6, val func loss 1.1290481090545654\n",
      "\n",
      "episode 7, val func loss 1.183813214302063\n",
      "\n",
      "episode 8, val func loss 1.582590937614441\n",
      "\n",
      "episode 9, val func loss 1.304199457168579\n",
      "\n",
      "episode 10, val func loss 1.4449946880340576\n",
      "\n",
      "episode 11, val func loss 1.3320280313491821\n",
      "\n",
      "episode 12, val func loss 1.2594523429870605\n",
      "\n",
      "episode 13, val func loss 1.311907410621643\n",
      "\n",
      "episode 14, val func loss 1.2372639179229736\n",
      "\n",
      "episode 15, val func loss 1.4888100624084473\n",
      "\n",
      "episode 16, val func loss 1.3534626960754395\n",
      "\n",
      "Val func train loss in epoch 8:1.3182703405618668\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.6051918268203735\n",
      "\n",
      "episode 2, val func loss 1.4801299571990967\n",
      "\n",
      "episode 3, val func loss 1.2109884023666382\n",
      "\n",
      "episode 4, val func loss 1.5122658014297485\n",
      "\n",
      "episode 5, val func loss 1.400739073753357\n",
      "\n",
      "episode 6, val func loss 1.2750039100646973\n",
      "\n",
      "episode 7, val func loss 1.1900614500045776\n",
      "\n",
      "episode 8, val func loss 1.4373769760131836\n",
      "\n",
      "episode 9, val func loss 1.1958587169647217\n",
      "\n",
      "episode 10, val func loss 1.2656478881835938\n",
      "\n",
      "episode 11, val func loss 1.407252311706543\n",
      "\n",
      "episode 12, val func loss 1.2772939205169678\n",
      "\n",
      "episode 13, val func loss 1.2505624294281006\n",
      "\n",
      "episode 14, val func loss 1.2766516208648682\n",
      "\n",
      "episode 15, val func loss 1.3576231002807617\n",
      "\n",
      "episode 16, val func loss 1.3433003425598145\n",
      "\n",
      "Val func train loss in epoch 9:1.3428717330098152\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.389100193977356\n",
      "\n",
      "episode 2, val func loss 1.6175298690795898\n",
      "\n",
      "episode 3, val func loss 1.4181101322174072\n",
      "\n",
      "episode 4, val func loss 1.4098103046417236\n",
      "\n",
      "episode 5, val func loss 1.3833255767822266\n",
      "\n",
      "episode 6, val func loss 1.397329568862915\n",
      "\n",
      "episode 7, val func loss 1.3314357995986938\n",
      "\n",
      "episode 8, val func loss 1.4023643732070923\n",
      "\n",
      "episode 9, val func loss 1.3621866703033447\n",
      "\n",
      "episode 10, val func loss 1.5311015844345093\n",
      "\n",
      "episode 11, val func loss 1.319117546081543\n",
      "\n",
      "episode 12, val func loss 1.6002286672592163\n",
      "\n",
      "episode 13, val func loss 1.1907910108566284\n",
      "\n",
      "episode 14, val func loss 1.2552037239074707\n",
      "\n",
      "episode 15, val func loss 1.237361192703247\n",
      "\n",
      "episode 16, val func loss 1.2849888801574707\n",
      "\n",
      "Val func train loss in epoch 10:1.3831240683794022\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.455903172492981\n",
      "\n",
      "episode 2, val func loss 1.2006391286849976\n",
      "\n",
      "episode 3, val func loss 1.382083535194397\n",
      "\n",
      "episode 4, val func loss 1.6712114810943604\n",
      "\n",
      "episode 5, val func loss 1.3875051736831665\n",
      "\n",
      "episode 6, val func loss 1.3132473230361938\n",
      "\n",
      "episode 7, val func loss 1.360703706741333\n",
      "\n",
      "episode 8, val func loss 1.2963145971298218\n",
      "\n",
      "episode 9, val func loss 1.614137053489685\n",
      "\n",
      "episode 10, val func loss 1.366281509399414\n",
      "\n",
      "episode 11, val func loss 1.2401231527328491\n",
      "\n",
      "episode 12, val func loss 1.2399542331695557\n",
      "\n",
      "episode 13, val func loss 1.2733005285263062\n",
      "\n",
      "episode 14, val func loss 1.2966400384902954\n",
      "\n",
      "episode 15, val func loss 1.2973145246505737\n",
      "\n",
      "episode 16, val func loss 1.2321449518203735\n",
      "\n",
      "Val func train loss in epoch 11:1.351719006896019\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.3837344646453857\n",
      "\n",
      "episode 2, val func loss 1.2234140634536743\n",
      "\n",
      "episode 3, val func loss 1.4057865142822266\n",
      "\n",
      "episode 4, val func loss 1.3304641246795654\n",
      "\n",
      "episode 5, val func loss 1.5349751710891724\n",
      "\n",
      "episode 6, val func loss 1.3946146965026855\n",
      "\n",
      "episode 7, val func loss 1.4455900192260742\n",
      "\n",
      "episode 8, val func loss 1.478792428970337\n",
      "\n",
      "episode 9, val func loss 1.3634525537490845\n",
      "\n",
      "episode 10, val func loss 1.4246501922607422\n",
      "\n",
      "episode 11, val func loss 1.2524993419647217\n",
      "\n",
      "episode 12, val func loss 1.2937108278274536\n",
      "\n",
      "episode 13, val func loss 1.527284026145935\n",
      "\n",
      "episode 14, val func loss 1.3942720890045166\n",
      "\n",
      "episode 15, val func loss 1.4866089820861816\n",
      "\n",
      "episode 16, val func loss 1.5054177045822144\n",
      "\n",
      "Val func train loss in epoch 12:1.4028292000293732\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.3885021209716797\n",
      "\n",
      "episode 2, val func loss 1.3878331184387207\n",
      "\n",
      "episode 3, val func loss 1.5107448101043701\n",
      "\n",
      "episode 4, val func loss 1.4335064888000488\n",
      "\n",
      "episode 5, val func loss 1.5363587141036987\n",
      "\n",
      "episode 6, val func loss 1.320937991142273\n",
      "\n",
      "episode 7, val func loss 1.0781620740890503\n",
      "\n",
      "episode 8, val func loss 1.4433064460754395\n",
      "\n",
      "episode 9, val func loss 1.186974287033081\n",
      "\n",
      "episode 10, val func loss 1.3401217460632324\n",
      "\n",
      "episode 11, val func loss 1.2550067901611328\n",
      "\n",
      "episode 12, val func loss 1.3336600065231323\n",
      "\n",
      "episode 13, val func loss 1.4353127479553223\n",
      "\n",
      "episode 14, val func loss 1.4737941026687622\n",
      "\n",
      "episode 15, val func loss 1.5754072666168213\n",
      "\n",
      "episode 16, val func loss 1.5090491771697998\n",
      "\n",
      "Val func train loss in epoch 13:1.3880423679947853\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.1803839206695557\n",
      "\n",
      "episode 2, val func loss 1.4796358346939087\n",
      "\n",
      "episode 3, val func loss 1.1504123210906982\n",
      "\n",
      "episode 4, val func loss 1.4498481750488281\n",
      "\n",
      "episode 5, val func loss 1.3004283905029297\n",
      "\n",
      "episode 6, val func loss 1.359201192855835\n",
      "\n",
      "episode 7, val func loss 1.4945615530014038\n",
      "\n",
      "episode 8, val func loss 1.484449028968811\n",
      "\n",
      "episode 9, val func loss 1.3163478374481201\n",
      "\n",
      "episode 10, val func loss 1.4852560758590698\n",
      "\n",
      "episode 11, val func loss 1.4252568483352661\n",
      "\n",
      "episode 12, val func loss 1.2095242738723755\n",
      "\n",
      "episode 13, val func loss 1.2331379652023315\n",
      "\n",
      "episode 14, val func loss 1.3789938688278198\n",
      "\n",
      "episode 15, val func loss 1.4559605121612549\n",
      "\n",
      "episode 16, val func loss 1.3118890523910522\n",
      "\n",
      "Val func train loss in epoch 14:1.3572054281830788\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.285219430923462\n",
      "\n",
      "episode 2, val func loss 1.4263956546783447\n",
      "\n",
      "episode 3, val func loss 1.1443495750427246\n",
      "\n",
      "episode 4, val func loss 1.494038462638855\n",
      "\n",
      "episode 5, val func loss 1.3916867971420288\n",
      "\n",
      "episode 6, val func loss 1.1826022863388062\n",
      "\n",
      "episode 7, val func loss 1.694631576538086\n",
      "\n",
      "episode 8, val func loss 1.430466890335083\n",
      "\n",
      "episode 9, val func loss 1.3110404014587402\n",
      "\n",
      "episode 10, val func loss 1.400018334388733\n",
      "\n",
      "episode 11, val func loss 1.5936203002929688\n",
      "\n",
      "episode 12, val func loss 1.2829267978668213\n",
      "\n",
      "episode 13, val func loss 1.2652050256729126\n",
      "\n",
      "episode 14, val func loss 1.4978809356689453\n",
      "\n",
      "episode 15, val func loss 1.6417927742004395\n",
      "\n",
      "episode 16, val func loss 1.2140514850616455\n",
      "\n",
      "Val func train loss in epoch 15:1.3909954205155373\n",
      "***********************TIME WAS 4.802716147899628 min*****************************\n",
      "\n",
      "**********************ROUND 32 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.7874081134796143\n",
      "\n",
      "episode 2, policy loss -2.7874083518981934\n",
      "\n",
      "episode 3, policy loss -2.7874083518981934\n",
      "\n",
      "episode 4, policy loss -2.7874083518981934\n",
      "\n",
      "episode 5, policy loss -2.7874081134796143\n",
      "\n",
      "episode 6, policy loss -2.7874083518981934\n",
      "\n",
      "episode 7, policy loss -2.7874083518981934\n",
      "\n",
      "episode 8, policy loss -2.7874083518981934\n",
      "\n",
      "episode 9, policy loss -2.7874081134796143\n",
      "\n",
      "episode 10, policy loss -2.7874081134796143\n",
      "\n",
      "episode 11, policy loss -2.7874083518981934\n",
      "\n",
      "episode 12, policy loss -2.7874081134796143\n",
      "\n",
      "episode 13, policy loss -2.7874083518981934\n",
      "\n",
      "episode 14, policy loss -2.7874083518981934\n",
      "\n",
      "episode 15, policy loss -2.7874083518981934\n",
      "\n",
      "episode 16, policy loss -2.7874083518981934\n",
      "\n",
      "Policy train loss in epoch 0:-2.7874082773923874\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.7874083518981934\n",
      "\n",
      "episode 2, policy loss -2.7874083518981934\n",
      "\n",
      "episode 3, policy loss -2.7874081134796143\n",
      "\n",
      "episode 4, policy loss -2.7874083518981934\n",
      "\n",
      "episode 5, policy loss -2.7874083518981934\n",
      "\n",
      "episode 6, policy loss -2.7874083518981934\n",
      "\n",
      "episode 7, policy loss -2.7874083518981934\n",
      "\n",
      "episode 8, policy loss -2.7874081134796143\n",
      "\n",
      "episode 9, policy loss -2.7874081134796143\n",
      "\n",
      "episode 10, policy loss -2.7874083518981934\n",
      "\n",
      "episode 11, policy loss -2.7874083518981934\n",
      "\n",
      "episode 12, policy loss -2.7874081134796143\n",
      "\n",
      "episode 13, policy loss -2.7874083518981934\n",
      "\n",
      "episode 14, policy loss -2.7874083518981934\n",
      "\n",
      "episode 15, policy loss -2.7874081134796143\n",
      "\n",
      "episode 16, policy loss -2.7874083518981934\n",
      "\n",
      "Policy train loss in epoch 1:-2.7874082773923874\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.7874081134796143\n",
      "\n",
      "episode 2, policy loss -2.7874083518981934\n",
      "\n",
      "episode 3, policy loss -2.7874081134796143\n",
      "\n",
      "episode 4, policy loss -2.7874081134796143\n",
      "\n",
      "episode 5, policy loss -2.7874083518981934\n",
      "\n",
      "episode 6, policy loss -2.7874083518981934\n",
      "\n",
      "episode 7, policy loss -2.7874083518981934\n",
      "\n",
      "episode 8, policy loss -2.7874081134796143\n",
      "\n",
      "episode 9, policy loss -2.7874083518981934\n",
      "\n",
      "episode 10, policy loss -2.7874083518981934\n",
      "\n",
      "episode 11, policy loss -2.7874083518981934\n",
      "\n",
      "episode 12, policy loss -2.7874083518981934\n",
      "\n",
      "episode 13, policy loss -2.7874081134796143\n",
      "\n",
      "episode 14, policy loss -2.7874083518981934\n",
      "\n",
      "episode 15, policy loss -2.7874083518981934\n",
      "\n",
      "episode 16, policy loss -2.7874083518981934\n",
      "\n",
      "Policy train loss in epoch 2:-2.7874082773923874\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.7874081134796143\n",
      "\n",
      "episode 2, policy loss -2.7874081134796143\n",
      "\n",
      "episode 3, policy loss -2.7874083518981934\n",
      "\n",
      "episode 4, policy loss -2.7874083518981934\n",
      "\n",
      "episode 5, policy loss -2.7874083518981934\n",
      "\n",
      "episode 6, policy loss -2.7874083518981934\n",
      "\n",
      "episode 7, policy loss -2.7874083518981934\n",
      "\n",
      "episode 8, policy loss -2.7874083518981934\n",
      "\n",
      "episode 9, policy loss -2.7874081134796143\n",
      "\n",
      "episode 10, policy loss -2.7874083518981934\n",
      "\n",
      "episode 11, policy loss -2.7874083518981934\n",
      "\n",
      "episode 12, policy loss -2.7874081134796143\n",
      "\n",
      "episode 13, policy loss -2.7874083518981934\n",
      "\n",
      "episode 14, policy loss -2.7874083518981934\n",
      "\n",
      "episode 15, policy loss -2.7874081134796143\n",
      "\n",
      "episode 16, policy loss -2.7874083518981934\n",
      "\n",
      "Policy train loss in epoch 3:-2.7874082773923874\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.4454820156097412\n",
      "\n",
      "episode 2, val func loss 1.4088033437728882\n",
      "\n",
      "episode 3, val func loss 1.4211950302124023\n",
      "\n",
      "episode 4, val func loss 1.2562854290008545\n",
      "\n",
      "episode 5, val func loss 1.3060173988342285\n",
      "\n",
      "episode 6, val func loss 1.4189019203186035\n",
      "\n",
      "episode 7, val func loss 1.2374225854873657\n",
      "\n",
      "episode 8, val func loss 1.3121585845947266\n",
      "\n",
      "episode 9, val func loss 1.2517369985580444\n",
      "\n",
      "episode 10, val func loss 1.6811169385910034\n",
      "\n",
      "episode 11, val func loss 1.228715181350708\n",
      "\n",
      "episode 12, val func loss 1.242299199104309\n",
      "\n",
      "episode 13, val func loss 1.392926812171936\n",
      "\n",
      "episode 14, val func loss 1.4094314575195312\n",
      "\n",
      "episode 15, val func loss 1.45108962059021\n",
      "\n",
      "episode 16, val func loss 1.3177038431167603\n",
      "\n",
      "Val func train loss in epoch 0:1.361330397427082\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.3764687776565552\n",
      "\n",
      "episode 2, val func loss 1.4753391742706299\n",
      "\n",
      "episode 3, val func loss 1.4413560628890991\n",
      "\n",
      "episode 4, val func loss 1.2332618236541748\n",
      "\n",
      "episode 5, val func loss 1.4081199169158936\n",
      "\n",
      "episode 6, val func loss 1.4113073348999023\n",
      "\n",
      "episode 7, val func loss 1.3933546543121338\n",
      "\n",
      "episode 8, val func loss 1.3763749599456787\n",
      "\n",
      "episode 9, val func loss 1.5508363246917725\n",
      "\n",
      "episode 10, val func loss 1.1495665311813354\n",
      "\n",
      "episode 11, val func loss 1.4588288068771362\n",
      "\n",
      "episode 12, val func loss 1.2975785732269287\n",
      "\n",
      "episode 13, val func loss 1.522197961807251\n",
      "\n",
      "episode 14, val func loss 1.4883136749267578\n",
      "\n",
      "episode 15, val func loss 1.2900062799453735\n",
      "\n",
      "episode 16, val func loss 1.3084591627120972\n",
      "\n",
      "Val func train loss in epoch 1:1.386335626244545\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.498756766319275\n",
      "\n",
      "episode 2, val func loss 1.3782706260681152\n",
      "\n",
      "episode 3, val func loss 1.2766797542572021\n",
      "\n",
      "episode 4, val func loss 1.4032142162322998\n",
      "\n",
      "episode 5, val func loss 1.352699637413025\n",
      "\n",
      "episode 6, val func loss 1.3916374444961548\n",
      "\n",
      "episode 7, val func loss 1.3547662496566772\n",
      "\n",
      "episode 8, val func loss 1.4370568990707397\n",
      "\n",
      "episode 9, val func loss 1.2152972221374512\n",
      "\n",
      "episode 10, val func loss 1.2943038940429688\n",
      "\n",
      "episode 11, val func loss 1.3651714324951172\n",
      "\n",
      "episode 12, val func loss 1.4882615804672241\n",
      "\n",
      "episode 13, val func loss 1.6648818254470825\n",
      "\n",
      "episode 14, val func loss 1.759525179862976\n",
      "\n",
      "episode 15, val func loss 1.372481346130371\n",
      "\n",
      "episode 16, val func loss 1.4872405529022217\n",
      "\n",
      "Val func train loss in epoch 2:1.4212652891874313\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.4571934938430786\n",
      "\n",
      "episode 2, val func loss 1.6127746105194092\n",
      "\n",
      "episode 3, val func loss 1.41090726852417\n",
      "\n",
      "episode 4, val func loss 1.6245955228805542\n",
      "\n",
      "episode 5, val func loss 1.3214032649993896\n",
      "\n",
      "episode 6, val func loss 1.5474216938018799\n",
      "\n",
      "episode 7, val func loss 1.2533310651779175\n",
      "\n",
      "episode 8, val func loss 1.5414291620254517\n",
      "\n",
      "episode 9, val func loss 1.4948903322219849\n",
      "\n",
      "episode 10, val func loss 1.4582061767578125\n",
      "\n",
      "episode 11, val func loss 1.3689465522766113\n",
      "\n",
      "episode 12, val func loss 1.3221217393875122\n",
      "\n",
      "episode 13, val func loss 1.2816720008850098\n",
      "\n",
      "episode 14, val func loss 1.589375615119934\n",
      "\n",
      "episode 15, val func loss 1.5542594194412231\n",
      "\n",
      "episode 16, val func loss 1.20443856716156\n",
      "\n",
      "Val func train loss in epoch 3:1.4401854053139687\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.4498380422592163\n",
      "\n",
      "episode 2, val func loss 1.590921401977539\n",
      "\n",
      "episode 3, val func loss 1.2758448123931885\n",
      "\n",
      "episode 4, val func loss 1.279847264289856\n",
      "\n",
      "episode 5, val func loss 1.2887649536132812\n",
      "\n",
      "episode 6, val func loss 1.5189273357391357\n",
      "\n",
      "episode 7, val func loss 1.6064220666885376\n",
      "\n",
      "episode 8, val func loss 1.4258452653884888\n",
      "\n",
      "episode 9, val func loss 1.2855513095855713\n",
      "\n",
      "episode 10, val func loss 1.2602074146270752\n",
      "\n",
      "episode 11, val func loss 1.4238215684890747\n",
      "\n",
      "episode 12, val func loss 1.488553762435913\n",
      "\n",
      "episode 13, val func loss 1.2540819644927979\n",
      "\n",
      "episode 14, val func loss 1.3075361251831055\n",
      "\n",
      "episode 15, val func loss 1.3838120698928833\n",
      "\n",
      "episode 16, val func loss 1.2122222185134888\n",
      "\n",
      "Val func train loss in epoch 4:1.378262348473072\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.4566502571105957\n",
      "\n",
      "episode 2, val func loss 1.3716378211975098\n",
      "\n",
      "episode 3, val func loss 1.3715907335281372\n",
      "\n",
      "episode 4, val func loss 1.2527797222137451\n",
      "\n",
      "episode 5, val func loss 1.3701399564743042\n",
      "\n",
      "episode 6, val func loss 1.3508286476135254\n",
      "\n",
      "episode 7, val func loss 1.4607646465301514\n",
      "\n",
      "episode 8, val func loss 1.272757649421692\n",
      "\n",
      "episode 9, val func loss 1.2948002815246582\n",
      "\n",
      "episode 10, val func loss 1.6231069564819336\n",
      "\n",
      "episode 11, val func loss 1.2970131635665894\n",
      "\n",
      "episode 12, val func loss 1.432376742362976\n",
      "\n",
      "episode 13, val func loss 1.3025825023651123\n",
      "\n",
      "episode 14, val func loss 1.36872398853302\n",
      "\n",
      "episode 15, val func loss 1.4762308597564697\n",
      "\n",
      "episode 16, val func loss 1.3332927227020264\n",
      "\n",
      "Val func train loss in epoch 5:1.377204790711403\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.3329150676727295\n",
      "\n",
      "episode 2, val func loss 1.4464908838272095\n",
      "\n",
      "episode 3, val func loss 1.3916125297546387\n",
      "\n",
      "episode 4, val func loss 1.3898874521255493\n",
      "\n",
      "episode 5, val func loss 1.569815993309021\n",
      "\n",
      "episode 6, val func loss 1.3463772535324097\n",
      "\n",
      "episode 7, val func loss 1.2874263525009155\n",
      "\n",
      "episode 8, val func loss 1.2953883409500122\n",
      "\n",
      "episode 9, val func loss 1.4003973007202148\n",
      "\n",
      "episode 10, val func loss 1.325026035308838\n",
      "\n",
      "episode 11, val func loss 1.501529335975647\n",
      "\n",
      "episode 12, val func loss 1.1562778949737549\n",
      "\n",
      "episode 13, val func loss 1.2638201713562012\n",
      "\n",
      "episode 14, val func loss 1.4333655834197998\n",
      "\n",
      "episode 15, val func loss 1.087615966796875\n",
      "\n",
      "episode 16, val func loss 1.2408548593521118\n",
      "\n",
      "Val func train loss in epoch 6:1.3418000638484955\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.3271348476409912\n",
      "\n",
      "episode 2, val func loss 1.3827837705612183\n",
      "\n",
      "episode 3, val func loss 1.2345492839813232\n",
      "\n",
      "episode 4, val func loss 1.1827718019485474\n",
      "\n",
      "episode 5, val func loss 1.4336211681365967\n",
      "\n",
      "episode 6, val func loss 1.2938392162322998\n",
      "\n",
      "episode 7, val func loss 1.4453128576278687\n",
      "\n",
      "episode 8, val func loss 1.6935203075408936\n",
      "\n",
      "episode 9, val func loss 1.3288360834121704\n",
      "\n",
      "episode 10, val func loss 1.2443571090698242\n",
      "\n",
      "episode 11, val func loss 1.5914297103881836\n",
      "\n",
      "episode 12, val func loss 1.4701156616210938\n",
      "\n",
      "episode 13, val func loss 1.6307151317596436\n",
      "\n",
      "episode 14, val func loss 1.5277230739593506\n",
      "\n",
      "episode 15, val func loss 1.429784893989563\n",
      "\n",
      "episode 16, val func loss 1.563407301902771\n",
      "\n",
      "Val func train loss in epoch 7:1.4237438887357712\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.294700026512146\n",
      "\n",
      "episode 2, val func loss 1.4025428295135498\n",
      "\n",
      "episode 3, val func loss 1.4677516222000122\n",
      "\n",
      "episode 4, val func loss 1.6281380653381348\n",
      "\n",
      "episode 5, val func loss 1.3550373315811157\n",
      "\n",
      "episode 6, val func loss 1.3486011028289795\n",
      "\n",
      "episode 7, val func loss 1.6111187934875488\n",
      "\n",
      "episode 8, val func loss 1.2452861070632935\n",
      "\n",
      "episode 9, val func loss 1.2674344778060913\n",
      "\n",
      "episode 10, val func loss 1.2175160646438599\n",
      "\n",
      "episode 11, val func loss 1.3818942308425903\n",
      "\n",
      "episode 12, val func loss 1.5964995622634888\n",
      "\n",
      "episode 13, val func loss 1.3209972381591797\n",
      "\n",
      "episode 14, val func loss 1.3795490264892578\n",
      "\n",
      "episode 15, val func loss 1.3836700916290283\n",
      "\n",
      "episode 16, val func loss 1.3521809577941895\n",
      "\n",
      "Val func train loss in epoch 8:1.3908073455095291\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.2506778240203857\n",
      "\n",
      "episode 2, val func loss 1.5057134628295898\n",
      "\n",
      "episode 3, val func loss 1.3666186332702637\n",
      "\n",
      "episode 4, val func loss 1.203908085823059\n",
      "\n",
      "episode 5, val func loss 1.4249563217163086\n",
      "\n",
      "episode 6, val func loss 1.4746512174606323\n",
      "\n",
      "episode 7, val func loss 1.1417335271835327\n",
      "\n",
      "episode 8, val func loss 1.2947062253952026\n",
      "\n",
      "episode 9, val func loss 1.5217421054840088\n",
      "\n",
      "episode 10, val func loss 1.4711995124816895\n",
      "\n",
      "episode 11, val func loss 1.334452748298645\n",
      "\n",
      "episode 12, val func loss 1.2992732524871826\n",
      "\n",
      "episode 13, val func loss 1.460432767868042\n",
      "\n",
      "episode 14, val func loss 1.3405020236968994\n",
      "\n",
      "episode 15, val func loss 1.3360562324523926\n",
      "\n",
      "episode 16, val func loss 1.2853718996047974\n",
      "\n",
      "Val func train loss in epoch 9:1.3569997400045395\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.5260835886001587\n",
      "\n",
      "episode 2, val func loss 1.5080939531326294\n",
      "\n",
      "episode 3, val func loss 1.35624361038208\n",
      "\n",
      "episode 4, val func loss 1.426953673362732\n",
      "\n",
      "episode 5, val func loss 1.546286940574646\n",
      "\n",
      "episode 6, val func loss 1.5169955492019653\n",
      "\n",
      "episode 7, val func loss 1.1882601976394653\n",
      "\n",
      "episode 8, val func loss 1.4440526962280273\n",
      "\n",
      "episode 9, val func loss 1.4638210535049438\n",
      "\n",
      "episode 10, val func loss 1.233399510383606\n",
      "\n",
      "episode 11, val func loss 1.3303649425506592\n",
      "\n",
      "episode 12, val func loss 1.122650384902954\n",
      "\n",
      "episode 13, val func loss 1.3920258283615112\n",
      "\n",
      "episode 14, val func loss 1.2919306755065918\n",
      "\n",
      "episode 15, val func loss 1.3892399072647095\n",
      "\n",
      "episode 16, val func loss 1.576783299446106\n",
      "\n",
      "Val func train loss in epoch 10:1.394574113190174\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.3441449403762817\n",
      "\n",
      "episode 2, val func loss 1.2346786260604858\n",
      "\n",
      "episode 3, val func loss 1.2719581127166748\n",
      "\n",
      "episode 4, val func loss 1.4055908918380737\n",
      "\n",
      "episode 5, val func loss 1.4874554872512817\n",
      "\n",
      "episode 6, val func loss 1.1385176181793213\n",
      "\n",
      "episode 7, val func loss 1.307068109512329\n",
      "\n",
      "episode 8, val func loss 1.5145084857940674\n",
      "\n",
      "episode 9, val func loss 1.2930351495742798\n",
      "\n",
      "episode 10, val func loss 1.1928037405014038\n",
      "\n",
      "episode 11, val func loss 1.325954794883728\n",
      "\n",
      "episode 12, val func loss 1.298839807510376\n",
      "\n",
      "episode 13, val func loss 1.3926149606704712\n",
      "\n",
      "episode 14, val func loss 1.3427762985229492\n",
      "\n",
      "episode 15, val func loss 1.4169235229492188\n",
      "\n",
      "episode 16, val func loss 1.4976950883865356\n",
      "\n",
      "Val func train loss in epoch 11:1.3415353521704674\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.4532142877578735\n",
      "\n",
      "episode 2, val func loss 1.383851408958435\n",
      "\n",
      "episode 3, val func loss 1.5619739294052124\n",
      "\n",
      "episode 4, val func loss 1.418800711631775\n",
      "\n",
      "episode 5, val func loss 1.2774169445037842\n",
      "\n",
      "episode 6, val func loss 1.0564770698547363\n",
      "\n",
      "episode 7, val func loss 1.4492759704589844\n",
      "\n",
      "episode 8, val func loss 1.408531904220581\n",
      "\n",
      "episode 9, val func loss 1.4661198854446411\n",
      "\n",
      "episode 10, val func loss 1.3768478631973267\n",
      "\n",
      "episode 11, val func loss 1.2659720182418823\n",
      "\n",
      "episode 12, val func loss 1.240824818611145\n",
      "\n",
      "episode 13, val func loss 1.3037811517715454\n",
      "\n",
      "episode 14, val func loss 1.5808361768722534\n",
      "\n",
      "episode 15, val func loss 1.3524365425109863\n",
      "\n",
      "episode 16, val func loss 1.3853967189788818\n",
      "\n",
      "Val func train loss in epoch 12:1.3738598376512527\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.5255461931228638\n",
      "\n",
      "episode 2, val func loss 1.3422905206680298\n",
      "\n",
      "episode 3, val func loss 1.4637091159820557\n",
      "\n",
      "episode 4, val func loss 1.5579968690872192\n",
      "\n",
      "episode 5, val func loss 1.4800680875778198\n",
      "\n",
      "episode 6, val func loss 1.5311239957809448\n",
      "\n",
      "episode 7, val func loss 1.3163836002349854\n",
      "\n",
      "episode 8, val func loss 1.356487512588501\n",
      "\n",
      "episode 9, val func loss 1.6244035959243774\n",
      "\n",
      "episode 10, val func loss 1.4509849548339844\n",
      "\n",
      "episode 11, val func loss 1.289596438407898\n",
      "\n",
      "episode 12, val func loss 1.2363780736923218\n",
      "\n",
      "episode 13, val func loss 1.4317355155944824\n",
      "\n",
      "episode 14, val func loss 1.3759136199951172\n",
      "\n",
      "episode 15, val func loss 1.4016083478927612\n",
      "\n",
      "episode 16, val func loss 1.1598964929580688\n",
      "\n",
      "Val func train loss in epoch 13:1.4090076833963394\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.3764774799346924\n",
      "\n",
      "episode 2, val func loss 1.4268903732299805\n",
      "\n",
      "episode 3, val func loss 1.3292268514633179\n",
      "\n",
      "episode 4, val func loss 1.336728811264038\n",
      "\n",
      "episode 5, val func loss 1.3746001720428467\n",
      "\n",
      "episode 6, val func loss 1.2017136812210083\n",
      "\n",
      "episode 7, val func loss 1.570292353630066\n",
      "\n",
      "episode 8, val func loss 1.3436896800994873\n",
      "\n",
      "episode 9, val func loss 1.405029296875\n",
      "\n",
      "episode 10, val func loss 1.1400278806686401\n",
      "\n",
      "episode 11, val func loss 1.256183385848999\n",
      "\n",
      "episode 12, val func loss 1.3545284271240234\n",
      "\n",
      "episode 13, val func loss 1.1907099485397339\n",
      "\n",
      "episode 14, val func loss 1.4997541904449463\n",
      "\n",
      "episode 15, val func loss 1.2052879333496094\n",
      "\n",
      "episode 16, val func loss 1.2960721254348755\n",
      "\n",
      "Val func train loss in epoch 14:1.331700786948204\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.274488091468811\n",
      "\n",
      "episode 2, val func loss 1.2905021905899048\n",
      "\n",
      "episode 3, val func loss 1.393052339553833\n",
      "\n",
      "episode 4, val func loss 1.4360066652297974\n",
      "\n",
      "episode 5, val func loss 1.615114688873291\n",
      "\n",
      "episode 6, val func loss 1.2302180528640747\n",
      "\n",
      "episode 7, val func loss 1.1924445629119873\n",
      "\n",
      "episode 8, val func loss 1.482743501663208\n",
      "\n",
      "episode 9, val func loss 1.2039788961410522\n",
      "\n",
      "episode 10, val func loss 1.3073115348815918\n",
      "\n",
      "episode 11, val func loss 1.372107982635498\n",
      "\n",
      "episode 12, val func loss 1.1298856735229492\n",
      "\n",
      "episode 13, val func loss 1.4430243968963623\n",
      "\n",
      "episode 14, val func loss 1.1703559160232544\n",
      "\n",
      "episode 15, val func loss 1.5323083400726318\n",
      "\n",
      "episode 16, val func loss 1.2661432027816772\n",
      "\n",
      "Val func train loss in epoch 15:1.3337303772568703\n",
      "***********************TIME WAS 4.8005993088086445 min*****************************\n",
      "\n",
      "**********************ROUND 33 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.863800048828125\n",
      "\n",
      "episode 2, policy loss -2.863800048828125\n",
      "\n",
      "episode 3, policy loss -2.863800048828125\n",
      "\n",
      "episode 4, policy loss -2.863800048828125\n",
      "\n",
      "episode 5, policy loss -2.863800048828125\n",
      "\n",
      "episode 6, policy loss -2.863800048828125\n",
      "\n",
      "episode 7, policy loss -2.863800048828125\n",
      "\n",
      "episode 8, policy loss -2.863800048828125\n",
      "\n",
      "episode 9, policy loss -2.863800048828125\n",
      "\n",
      "episode 10, policy loss -2.863800048828125\n",
      "\n",
      "episode 11, policy loss -2.863800048828125\n",
      "\n",
      "episode 12, policy loss -2.863800048828125\n",
      "\n",
      "episode 13, policy loss -2.863800048828125\n",
      "\n",
      "episode 14, policy loss -2.863800048828125\n",
      "\n",
      "episode 15, policy loss -2.863800048828125\n",
      "\n",
      "episode 16, policy loss -2.863800048828125\n",
      "\n",
      "Policy train loss in epoch 0:-2.863800048828125\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.863800048828125\n",
      "\n",
      "episode 2, policy loss -2.863800048828125\n",
      "\n",
      "episode 3, policy loss -2.863800048828125\n",
      "\n",
      "episode 4, policy loss -2.863800048828125\n",
      "\n",
      "episode 5, policy loss -2.863800048828125\n",
      "\n",
      "episode 6, policy loss -2.863800048828125\n",
      "\n",
      "episode 7, policy loss -2.863800048828125\n",
      "\n",
      "episode 8, policy loss -2.863800048828125\n",
      "\n",
      "episode 9, policy loss -2.863800048828125\n",
      "\n",
      "episode 10, policy loss -2.863800048828125\n",
      "\n",
      "episode 11, policy loss -2.863800048828125\n",
      "\n",
      "episode 12, policy loss -2.863800048828125\n",
      "\n",
      "episode 13, policy loss -2.863800048828125\n",
      "\n",
      "episode 14, policy loss -2.863800048828125\n",
      "\n",
      "episode 15, policy loss -2.863800048828125\n",
      "\n",
      "episode 16, policy loss -2.863800048828125\n",
      "\n",
      "Policy train loss in epoch 1:-2.863800048828125\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.863800048828125\n",
      "\n",
      "episode 2, policy loss -2.863800048828125\n",
      "\n",
      "episode 3, policy loss -2.863800048828125\n",
      "\n",
      "episode 4, policy loss -2.863800048828125\n",
      "\n",
      "episode 5, policy loss -2.863800048828125\n",
      "\n",
      "episode 6, policy loss -2.863800048828125\n",
      "\n",
      "episode 7, policy loss -2.863800048828125\n",
      "\n",
      "episode 8, policy loss -2.863800048828125\n",
      "\n",
      "episode 9, policy loss -2.863800048828125\n",
      "\n",
      "episode 10, policy loss -2.863800048828125\n",
      "\n",
      "episode 11, policy loss -2.863800048828125\n",
      "\n",
      "episode 12, policy loss -2.863800048828125\n",
      "\n",
      "episode 13, policy loss -2.863800048828125\n",
      "\n",
      "episode 14, policy loss -2.863800048828125\n",
      "\n",
      "episode 15, policy loss -2.863800048828125\n",
      "\n",
      "episode 16, policy loss -2.863800048828125\n",
      "\n",
      "Policy train loss in epoch 2:-2.863800048828125\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.863800048828125\n",
      "\n",
      "episode 2, policy loss -2.863800048828125\n",
      "\n",
      "episode 3, policy loss -2.863800048828125\n",
      "\n",
      "episode 4, policy loss -2.863800048828125\n",
      "\n",
      "episode 5, policy loss -2.863800048828125\n",
      "\n",
      "episode 6, policy loss -2.863800048828125\n",
      "\n",
      "episode 7, policy loss -2.863800048828125\n",
      "\n",
      "episode 8, policy loss -2.863800048828125\n",
      "\n",
      "episode 9, policy loss -2.863800048828125\n",
      "\n",
      "episode 10, policy loss -2.863800048828125\n",
      "\n",
      "episode 11, policy loss -2.863800048828125\n",
      "\n",
      "episode 12, policy loss -2.863800048828125\n",
      "\n",
      "episode 13, policy loss -2.863800048828125\n",
      "\n",
      "episode 14, policy loss -2.863800048828125\n",
      "\n",
      "episode 15, policy loss -2.863800048828125\n",
      "\n",
      "episode 16, policy loss -2.863800048828125\n",
      "\n",
      "Policy train loss in epoch 3:-2.863800048828125\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.6793733835220337\n",
      "\n",
      "episode 2, val func loss 1.3859610557556152\n",
      "\n",
      "episode 3, val func loss 1.2284451723098755\n",
      "\n",
      "episode 4, val func loss 1.5976287126541138\n",
      "\n",
      "episode 5, val func loss 1.1815440654754639\n",
      "\n",
      "episode 6, val func loss 1.5092679262161255\n",
      "\n",
      "episode 7, val func loss 1.4528820514678955\n",
      "\n",
      "episode 8, val func loss 1.3502123355865479\n",
      "\n",
      "episode 9, val func loss 1.3077232837677002\n",
      "\n",
      "episode 10, val func loss 1.230979561805725\n",
      "\n",
      "episode 11, val func loss 1.4257184267044067\n",
      "\n",
      "episode 12, val func loss 1.6007592678070068\n",
      "\n",
      "episode 13, val func loss 1.3958804607391357\n",
      "\n",
      "episode 14, val func loss 1.4432681798934937\n",
      "\n",
      "episode 15, val func loss 1.463776707649231\n",
      "\n",
      "episode 16, val func loss 1.6194000244140625\n",
      "\n",
      "Val func train loss in epoch 0:1.429551288485527\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.3478283882141113\n",
      "\n",
      "episode 2, val func loss 1.32696533203125\n",
      "\n",
      "episode 3, val func loss 1.2172292470932007\n",
      "\n",
      "episode 4, val func loss 1.4571688175201416\n",
      "\n",
      "episode 5, val func loss 1.0968683958053589\n",
      "\n",
      "episode 6, val func loss 1.2566694021224976\n",
      "\n",
      "episode 7, val func loss 1.2180653810501099\n",
      "\n",
      "episode 8, val func loss 1.6314183473587036\n",
      "\n",
      "episode 9, val func loss 1.2939733266830444\n",
      "\n",
      "episode 10, val func loss 1.146507740020752\n",
      "\n",
      "episode 11, val func loss 1.421663761138916\n",
      "\n",
      "episode 12, val func loss 1.418947696685791\n",
      "\n",
      "episode 13, val func loss 1.3647029399871826\n",
      "\n",
      "episode 14, val func loss 1.3958663940429688\n",
      "\n",
      "episode 15, val func loss 1.1596202850341797\n",
      "\n",
      "episode 16, val func loss 1.3236911296844482\n",
      "\n",
      "Val func train loss in epoch 1:1.317324161529541\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.2876144647598267\n",
      "\n",
      "episode 2, val func loss 1.2960454225540161\n",
      "\n",
      "episode 3, val func loss 1.3572970628738403\n",
      "\n",
      "episode 4, val func loss 1.4148555994033813\n",
      "\n",
      "episode 5, val func loss 1.3670228719711304\n",
      "\n",
      "episode 6, val func loss 1.2257845401763916\n",
      "\n",
      "episode 7, val func loss 1.2436081171035767\n",
      "\n",
      "episode 8, val func loss 1.2559173107147217\n",
      "\n",
      "episode 9, val func loss 1.3022106885910034\n",
      "\n",
      "episode 10, val func loss 1.3002080917358398\n",
      "\n",
      "episode 11, val func loss 1.1780413389205933\n",
      "\n",
      "episode 12, val func loss 1.1942155361175537\n",
      "\n",
      "episode 13, val func loss 1.5044525861740112\n",
      "\n",
      "episode 14, val func loss 1.2547192573547363\n",
      "\n",
      "episode 15, val func loss 1.2122355699539185\n",
      "\n",
      "episode 16, val func loss 1.2832303047180176\n",
      "\n",
      "Val func train loss in epoch 2:1.29234117269516\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.3634692430496216\n",
      "\n",
      "episode 2, val func loss 1.3407697677612305\n",
      "\n",
      "episode 3, val func loss 1.3661472797393799\n",
      "\n",
      "episode 4, val func loss 1.5500242710113525\n",
      "\n",
      "episode 5, val func loss 1.2558130025863647\n",
      "\n",
      "episode 6, val func loss 1.375732421875\n",
      "\n",
      "episode 7, val func loss 1.514354944229126\n",
      "\n",
      "episode 8, val func loss 1.5639147758483887\n",
      "\n",
      "episode 9, val func loss 1.4051055908203125\n",
      "\n",
      "episode 10, val func loss 1.3308846950531006\n",
      "\n",
      "episode 11, val func loss 1.2837169170379639\n",
      "\n",
      "episode 12, val func loss 1.1189054250717163\n",
      "\n",
      "episode 13, val func loss 1.172754168510437\n",
      "\n",
      "episode 14, val func loss 1.4830307960510254\n",
      "\n",
      "episode 15, val func loss 1.2499699592590332\n",
      "\n",
      "episode 16, val func loss 1.1294620037078857\n",
      "\n",
      "Val func train loss in epoch 3:1.3440034538507462\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.4647281169891357\n",
      "\n",
      "episode 2, val func loss 1.3279774188995361\n",
      "\n",
      "episode 3, val func loss 1.3699661493301392\n",
      "\n",
      "episode 4, val func loss 1.5969191789627075\n",
      "\n",
      "episode 5, val func loss 1.4920568466186523\n",
      "\n",
      "episode 6, val func loss 1.4903624057769775\n",
      "\n",
      "episode 7, val func loss 1.4405262470245361\n",
      "\n",
      "episode 8, val func loss 1.2721041440963745\n",
      "\n",
      "episode 9, val func loss 1.1753582954406738\n",
      "\n",
      "episode 10, val func loss 1.3400617837905884\n",
      "\n",
      "episode 11, val func loss 1.3764756917953491\n",
      "\n",
      "episode 12, val func loss 1.3398456573486328\n",
      "\n",
      "episode 13, val func loss 1.3665002584457397\n",
      "\n",
      "episode 14, val func loss 1.3681275844573975\n",
      "\n",
      "episode 15, val func loss 1.4818698167800903\n",
      "\n",
      "episode 16, val func loss 1.242354154586792\n",
      "\n",
      "Val func train loss in epoch 4:1.3840771093964577\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.3578133583068848\n",
      "\n",
      "episode 2, val func loss 1.278313159942627\n",
      "\n",
      "episode 3, val func loss 1.686411738395691\n",
      "\n",
      "episode 4, val func loss 1.3455226421356201\n",
      "\n",
      "episode 5, val func loss 1.121556043624878\n",
      "\n",
      "episode 6, val func loss 1.4546185731887817\n",
      "\n",
      "episode 7, val func loss 1.4019513130187988\n",
      "\n",
      "episode 8, val func loss 1.2331582307815552\n",
      "\n",
      "episode 9, val func loss 1.1873186826705933\n",
      "\n",
      "episode 10, val func loss 1.1728492975234985\n",
      "\n",
      "episode 11, val func loss 1.4427493810653687\n",
      "\n",
      "episode 12, val func loss 1.4087918996810913\n",
      "\n",
      "episode 13, val func loss 1.397605061531067\n",
      "\n",
      "episode 14, val func loss 1.2645848989486694\n",
      "\n",
      "episode 15, val func loss 1.3081337213516235\n",
      "\n",
      "episode 16, val func loss 1.4262970685958862\n",
      "\n",
      "Val func train loss in epoch 5:1.3429796919226646\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.2432005405426025\n",
      "\n",
      "episode 2, val func loss 1.4390524625778198\n",
      "\n",
      "episode 3, val func loss 1.7022688388824463\n",
      "\n",
      "episode 4, val func loss 1.3746873140335083\n",
      "\n",
      "episode 5, val func loss 1.4587236642837524\n",
      "\n",
      "episode 6, val func loss 1.3561737537384033\n",
      "\n",
      "episode 7, val func loss 1.308294415473938\n",
      "\n",
      "episode 8, val func loss 1.3292064666748047\n",
      "\n",
      "episode 9, val func loss 1.2875099182128906\n",
      "\n",
      "episode 10, val func loss 1.6056365966796875\n",
      "\n",
      "episode 11, val func loss 1.3750107288360596\n",
      "\n",
      "episode 12, val func loss 1.4245134592056274\n",
      "\n",
      "episode 13, val func loss 1.293365478515625\n",
      "\n",
      "episode 14, val func loss 1.317312479019165\n",
      "\n",
      "episode 15, val func loss 1.3893922567367554\n",
      "\n",
      "episode 16, val func loss 1.459370493888855\n",
      "\n",
      "Val func train loss in epoch 6:1.3977324292063713\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.436669111251831\n",
      "\n",
      "episode 2, val func loss 1.1286933422088623\n",
      "\n",
      "episode 3, val func loss 1.3035308122634888\n",
      "\n",
      "episode 4, val func loss 1.3893564939498901\n",
      "\n",
      "episode 5, val func loss 1.3637529611587524\n",
      "\n",
      "episode 6, val func loss 1.4065641164779663\n",
      "\n",
      "episode 7, val func loss 1.3336434364318848\n",
      "\n",
      "episode 8, val func loss 1.3246371746063232\n",
      "\n",
      "episode 9, val func loss 1.1450084447860718\n",
      "\n",
      "episode 10, val func loss 1.5374895334243774\n",
      "\n",
      "episode 11, val func loss 1.2957844734191895\n",
      "\n",
      "episode 12, val func loss 1.3626474142074585\n",
      "\n",
      "episode 13, val func loss 1.1889532804489136\n",
      "\n",
      "episode 14, val func loss 1.2224849462509155\n",
      "\n",
      "episode 15, val func loss 1.0938643217086792\n",
      "\n",
      "episode 16, val func loss 1.4989811182022095\n",
      "\n",
      "Val func train loss in epoch 7:1.3145038112998009\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.239206075668335\n",
      "\n",
      "episode 2, val func loss 1.482759714126587\n",
      "\n",
      "episode 3, val func loss 1.2183853387832642\n",
      "\n",
      "episode 4, val func loss 1.3212465047836304\n",
      "\n",
      "episode 5, val func loss 1.24606192111969\n",
      "\n",
      "episode 6, val func loss 1.280339002609253\n",
      "\n",
      "episode 7, val func loss 1.3086106777191162\n",
      "\n",
      "episode 8, val func loss 1.4060553312301636\n",
      "\n",
      "episode 9, val func loss 1.2900949716567993\n",
      "\n",
      "episode 10, val func loss 1.2159730195999146\n",
      "\n",
      "episode 11, val func loss 1.1352602243423462\n",
      "\n",
      "episode 12, val func loss 1.4703166484832764\n",
      "\n",
      "episode 13, val func loss 1.3567665815353394\n",
      "\n",
      "episode 14, val func loss 1.2996305227279663\n",
      "\n",
      "episode 15, val func loss 1.3343493938446045\n",
      "\n",
      "episode 16, val func loss 1.452864646911621\n",
      "\n",
      "Val func train loss in epoch 8:1.3161200359463692\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.344571828842163\n",
      "\n",
      "episode 2, val func loss 1.3815126419067383\n",
      "\n",
      "episode 3, val func loss 1.3117700815200806\n",
      "\n",
      "episode 4, val func loss 1.3968431949615479\n",
      "\n",
      "episode 5, val func loss 1.2462656497955322\n",
      "\n",
      "episode 6, val func loss 1.1542197465896606\n",
      "\n",
      "episode 7, val func loss 1.2363029718399048\n",
      "\n",
      "episode 8, val func loss 1.376373529434204\n",
      "\n",
      "episode 9, val func loss 1.597778558731079\n",
      "\n",
      "episode 10, val func loss 1.3871642351150513\n",
      "\n",
      "episode 11, val func loss 1.2407702207565308\n",
      "\n",
      "episode 12, val func loss 1.200700044631958\n",
      "\n",
      "episode 13, val func loss 1.3521873950958252\n",
      "\n",
      "episode 14, val func loss 1.3806304931640625\n",
      "\n",
      "episode 15, val func loss 1.4768807888031006\n",
      "\n",
      "episode 16, val func loss 1.46128511428833\n",
      "\n",
      "Val func train loss in epoch 9:1.3465785309672356\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.4031418561935425\n",
      "\n",
      "episode 2, val func loss 1.2975250482559204\n",
      "\n",
      "episode 3, val func loss 1.7377402782440186\n",
      "\n",
      "episode 4, val func loss 1.1635276079177856\n",
      "\n",
      "episode 5, val func loss 1.2282065153121948\n",
      "\n",
      "episode 6, val func loss 1.1868910789489746\n",
      "\n",
      "episode 7, val func loss 1.4632755517959595\n",
      "\n",
      "episode 8, val func loss 1.5874738693237305\n",
      "\n",
      "episode 9, val func loss 1.4441752433776855\n",
      "\n",
      "episode 10, val func loss 1.2364064455032349\n",
      "\n",
      "episode 11, val func loss 1.389539361000061\n",
      "\n",
      "episode 12, val func loss 1.5473567247390747\n",
      "\n",
      "episode 13, val func loss 1.1451406478881836\n",
      "\n",
      "episode 14, val func loss 1.5115748643875122\n",
      "\n",
      "episode 15, val func loss 1.5953059196472168\n",
      "\n",
      "episode 16, val func loss 1.2463959455490112\n",
      "\n",
      "Val func train loss in epoch 10:1.3864798098802567\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.3713037967681885\n",
      "\n",
      "episode 2, val func loss 1.1998342275619507\n",
      "\n",
      "episode 3, val func loss 1.2990810871124268\n",
      "\n",
      "episode 4, val func loss 1.2158721685409546\n",
      "\n",
      "episode 5, val func loss 1.3104310035705566\n",
      "\n",
      "episode 6, val func loss 1.3647308349609375\n",
      "\n",
      "episode 7, val func loss 1.4263441562652588\n",
      "\n",
      "episode 8, val func loss 1.1676803827285767\n",
      "\n",
      "episode 9, val func loss 1.3900558948516846\n",
      "\n",
      "episode 10, val func loss 1.4787780046463013\n",
      "\n",
      "episode 11, val func loss 1.4623526334762573\n",
      "\n",
      "episode 12, val func loss 1.447352409362793\n",
      "\n",
      "episode 13, val func loss 1.359997272491455\n",
      "\n",
      "episode 14, val func loss 1.3434906005859375\n",
      "\n",
      "episode 15, val func loss 1.3337537050247192\n",
      "\n",
      "episode 16, val func loss 1.264870285987854\n",
      "\n",
      "Val func train loss in epoch 11:1.3397455289959908\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.289029836654663\n",
      "\n",
      "episode 2, val func loss 1.3006130456924438\n",
      "\n",
      "episode 3, val func loss 1.339247703552246\n",
      "\n",
      "episode 4, val func loss 1.4976849555969238\n",
      "\n",
      "episode 5, val func loss 1.2784112691879272\n",
      "\n",
      "episode 6, val func loss 1.3154128789901733\n",
      "\n",
      "episode 7, val func loss 1.3774508237838745\n",
      "\n",
      "episode 8, val func loss 1.3958783149719238\n",
      "\n",
      "episode 9, val func loss 1.359345555305481\n",
      "\n",
      "episode 10, val func loss 1.227554202079773\n",
      "\n",
      "episode 11, val func loss 1.2375344038009644\n",
      "\n",
      "episode 12, val func loss 1.2755157947540283\n",
      "\n",
      "episode 13, val func loss 1.3401130437850952\n",
      "\n",
      "episode 14, val func loss 1.5237202644348145\n",
      "\n",
      "episode 15, val func loss 1.4280238151550293\n",
      "\n",
      "episode 16, val func loss 1.3112112283706665\n",
      "\n",
      "Val func train loss in epoch 12:1.3435466960072517\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.4313918352127075\n",
      "\n",
      "episode 2, val func loss 1.2889268398284912\n",
      "\n",
      "episode 3, val func loss 1.482165813446045\n",
      "\n",
      "episode 4, val func loss 1.5956547260284424\n",
      "\n",
      "episode 5, val func loss 1.264385461807251\n",
      "\n",
      "episode 6, val func loss 1.3560166358947754\n",
      "\n",
      "episode 7, val func loss 1.2544516324996948\n",
      "\n",
      "episode 8, val func loss 1.2155439853668213\n",
      "\n",
      "episode 9, val func loss 1.0900602340698242\n",
      "\n",
      "episode 10, val func loss 1.1395058631896973\n",
      "\n",
      "episode 11, val func loss 1.440298318862915\n",
      "\n",
      "episode 12, val func loss 1.4913253784179688\n",
      "\n",
      "episode 13, val func loss 1.41415536403656\n",
      "\n",
      "episode 14, val func loss 1.3487238883972168\n",
      "\n",
      "episode 15, val func loss 1.3339983224868774\n",
      "\n",
      "episode 16, val func loss 1.293626070022583\n",
      "\n",
      "Val func train loss in epoch 13:1.340014398097992\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.220053791999817\n",
      "\n",
      "episode 2, val func loss 1.4384814500808716\n",
      "\n",
      "episode 3, val func loss 1.2507727146148682\n",
      "\n",
      "episode 4, val func loss 1.269718050956726\n",
      "\n",
      "episode 5, val func loss 1.3152271509170532\n",
      "\n",
      "episode 6, val func loss 1.3692996501922607\n",
      "\n",
      "episode 7, val func loss 1.1471587419509888\n",
      "\n",
      "episode 8, val func loss 1.256669044494629\n",
      "\n",
      "episode 9, val func loss 1.2847992181777954\n",
      "\n",
      "episode 10, val func loss 1.3090792894363403\n",
      "\n",
      "episode 11, val func loss 1.1745305061340332\n",
      "\n",
      "episode 12, val func loss 1.544150948524475\n",
      "\n",
      "episode 13, val func loss 1.500099539756775\n",
      "\n",
      "episode 14, val func loss 1.2650386095046997\n",
      "\n",
      "episode 15, val func loss 1.1963269710540771\n",
      "\n",
      "episode 16, val func loss 1.2630071640014648\n",
      "\n",
      "Val func train loss in epoch 14:1.3002758026123047\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.4884135723114014\n",
      "\n",
      "episode 2, val func loss 1.189517617225647\n",
      "\n",
      "episode 3, val func loss 1.3558104038238525\n",
      "\n",
      "episode 4, val func loss 1.500073790550232\n",
      "\n",
      "episode 5, val func loss 1.4126358032226562\n",
      "\n",
      "episode 6, val func loss 1.235371708869934\n",
      "\n",
      "episode 7, val func loss 1.3463166952133179\n",
      "\n",
      "episode 8, val func loss 1.4249991178512573\n",
      "\n",
      "episode 9, val func loss 1.4271718263626099\n",
      "\n",
      "episode 10, val func loss 1.255936861038208\n",
      "\n",
      "episode 11, val func loss 1.4620437622070312\n",
      "\n",
      "episode 12, val func loss 1.1568341255187988\n",
      "\n",
      "episode 13, val func loss 1.2677468061447144\n",
      "\n",
      "episode 14, val func loss 1.24429452419281\n",
      "\n",
      "episode 15, val func loss 1.5508315563201904\n",
      "\n",
      "episode 16, val func loss 1.2571492195129395\n",
      "\n",
      "Val func train loss in epoch 15:1.34844671189785\n",
      "***********************TIME WAS 4.801882088184357 min*****************************\n",
      "\n",
      "**********************ROUND 34 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.7938759326934814\n",
      "\n",
      "episode 2, policy loss -2.7938759326934814\n",
      "\n",
      "episode 3, policy loss -2.7938759326934814\n",
      "\n",
      "episode 4, policy loss -2.7938759326934814\n",
      "\n",
      "episode 5, policy loss -2.7938759326934814\n",
      "\n",
      "episode 6, policy loss -2.7938759326934814\n",
      "\n",
      "episode 7, policy loss -2.7938759326934814\n",
      "\n",
      "episode 8, policy loss -2.7938759326934814\n",
      "\n",
      "episode 9, policy loss -2.7938759326934814\n",
      "\n",
      "episode 10, policy loss -2.7938759326934814\n",
      "\n",
      "episode 11, policy loss -2.7938759326934814\n",
      "\n",
      "episode 12, policy loss -2.7938759326934814\n",
      "\n",
      "episode 13, policy loss -2.7938759326934814\n",
      "\n",
      "episode 14, policy loss -2.7938759326934814\n",
      "\n",
      "episode 15, policy loss -2.7938759326934814\n",
      "\n",
      "episode 16, policy loss -2.7938759326934814\n",
      "\n",
      "Policy train loss in epoch 0:-2.7938759326934814\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.7938759326934814\n",
      "\n",
      "episode 2, policy loss -2.7938759326934814\n",
      "\n",
      "episode 3, policy loss -2.7938759326934814\n",
      "\n",
      "episode 4, policy loss -2.7938759326934814\n",
      "\n",
      "episode 5, policy loss -2.7938759326934814\n",
      "\n",
      "episode 6, policy loss -2.7938759326934814\n",
      "\n",
      "episode 7, policy loss -2.7938759326934814\n",
      "\n",
      "episode 8, policy loss -2.7938759326934814\n",
      "\n",
      "episode 9, policy loss -2.7938759326934814\n",
      "\n",
      "episode 10, policy loss -2.7938759326934814\n",
      "\n",
      "episode 11, policy loss -2.7938759326934814\n",
      "\n",
      "episode 12, policy loss -2.7938759326934814\n",
      "\n",
      "episode 13, policy loss -2.7938759326934814\n",
      "\n",
      "episode 14, policy loss -2.7938759326934814\n",
      "\n",
      "episode 15, policy loss -2.7938759326934814\n",
      "\n",
      "episode 16, policy loss -2.7938759326934814\n",
      "\n",
      "Policy train loss in epoch 1:-2.7938759326934814\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.7938759326934814\n",
      "\n",
      "episode 2, policy loss -2.7938759326934814\n",
      "\n",
      "episode 3, policy loss -2.7938759326934814\n",
      "\n",
      "episode 4, policy loss -2.7938759326934814\n",
      "\n",
      "episode 5, policy loss -2.7938759326934814\n",
      "\n",
      "episode 6, policy loss -2.7938759326934814\n",
      "\n",
      "episode 7, policy loss -2.7938759326934814\n",
      "\n",
      "episode 8, policy loss -2.7938759326934814\n",
      "\n",
      "episode 9, policy loss -2.7938759326934814\n",
      "\n",
      "episode 10, policy loss -2.7938759326934814\n",
      "\n",
      "episode 11, policy loss -2.7938759326934814\n",
      "\n",
      "episode 12, policy loss -2.7938759326934814\n",
      "\n",
      "episode 13, policy loss -2.7938759326934814\n",
      "\n",
      "episode 14, policy loss -2.7938759326934814\n",
      "\n",
      "episode 15, policy loss -2.7938759326934814\n",
      "\n",
      "episode 16, policy loss -2.7938759326934814\n",
      "\n",
      "Policy train loss in epoch 2:-2.7938759326934814\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.7938759326934814\n",
      "\n",
      "episode 2, policy loss -2.7938759326934814\n",
      "\n",
      "episode 3, policy loss -2.7938759326934814\n",
      "\n",
      "episode 4, policy loss -2.7938759326934814\n",
      "\n",
      "episode 5, policy loss -2.7938759326934814\n",
      "\n",
      "episode 6, policy loss -2.7938759326934814\n",
      "\n",
      "episode 7, policy loss -2.7938759326934814\n",
      "\n",
      "episode 8, policy loss -2.7938759326934814\n",
      "\n",
      "episode 9, policy loss -2.7938759326934814\n",
      "\n",
      "episode 10, policy loss -2.7938759326934814\n",
      "\n",
      "episode 11, policy loss -2.7938759326934814\n",
      "\n",
      "episode 12, policy loss -2.7938759326934814\n",
      "\n",
      "episode 13, policy loss -2.7938759326934814\n",
      "\n",
      "episode 14, policy loss -2.7938759326934814\n",
      "\n",
      "episode 15, policy loss -2.7938759326934814\n",
      "\n",
      "episode 16, policy loss -2.7938759326934814\n",
      "\n",
      "Policy train loss in epoch 3:-2.7938759326934814\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.2632811069488525\n",
      "\n",
      "episode 2, val func loss 1.0380991697311401\n",
      "\n",
      "episode 3, val func loss 1.4890695810317993\n",
      "\n",
      "episode 4, val func loss 1.2956982851028442\n",
      "\n",
      "episode 5, val func loss 1.7338035106658936\n",
      "\n",
      "episode 6, val func loss 1.2746750116348267\n",
      "\n",
      "episode 7, val func loss 1.3093923330307007\n",
      "\n",
      "episode 8, val func loss 1.5787107944488525\n",
      "\n",
      "episode 9, val func loss 1.3916192054748535\n",
      "\n",
      "episode 10, val func loss 1.2586413621902466\n",
      "\n",
      "episode 11, val func loss 1.340222716331482\n",
      "\n",
      "episode 12, val func loss 1.3920694589614868\n",
      "\n",
      "episode 13, val func loss 1.4689576625823975\n",
      "\n",
      "episode 14, val func loss 1.3224560022354126\n",
      "\n",
      "episode 15, val func loss 1.2666152715682983\n",
      "\n",
      "episode 16, val func loss 1.21823251247406\n",
      "\n",
      "Val func train loss in epoch 0:1.3525964990258217\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.511803388595581\n",
      "\n",
      "episode 2, val func loss 1.3392311334609985\n",
      "\n",
      "episode 3, val func loss 1.236183762550354\n",
      "\n",
      "episode 4, val func loss 1.2676478624343872\n",
      "\n",
      "episode 5, val func loss 1.2823164463043213\n",
      "\n",
      "episode 6, val func loss 1.3651195764541626\n",
      "\n",
      "episode 7, val func loss 1.3659069538116455\n",
      "\n",
      "episode 8, val func loss 1.4428452253341675\n",
      "\n",
      "episode 9, val func loss 1.427911400794983\n",
      "\n",
      "episode 10, val func loss 1.3372775316238403\n",
      "\n",
      "episode 11, val func loss 1.388746738433838\n",
      "\n",
      "episode 12, val func loss 1.221923828125\n",
      "\n",
      "episode 13, val func loss 1.202623724937439\n",
      "\n",
      "episode 14, val func loss 1.1347135305404663\n",
      "\n",
      "episode 15, val func loss 1.4498060941696167\n",
      "\n",
      "episode 16, val func loss 1.356049656867981\n",
      "\n",
      "Val func train loss in epoch 1:1.3331316784024239\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.4729622602462769\n",
      "\n",
      "episode 2, val func loss 1.569054365158081\n",
      "\n",
      "episode 3, val func loss 1.2486417293548584\n",
      "\n",
      "episode 4, val func loss 1.4645850658416748\n",
      "\n",
      "episode 5, val func loss 1.302135705947876\n",
      "\n",
      "episode 6, val func loss 1.101922631263733\n",
      "\n",
      "episode 7, val func loss 1.4629024267196655\n",
      "\n",
      "episode 8, val func loss 1.2934839725494385\n",
      "\n",
      "episode 9, val func loss 1.0278257131576538\n",
      "\n",
      "episode 10, val func loss 1.4926058053970337\n",
      "\n",
      "episode 11, val func loss 1.5217304229736328\n",
      "\n",
      "episode 12, val func loss 1.289308786392212\n",
      "\n",
      "episode 13, val func loss 1.5326558351516724\n",
      "\n",
      "episode 14, val func loss 1.2947760820388794\n",
      "\n",
      "episode 15, val func loss 1.3755666017532349\n",
      "\n",
      "episode 16, val func loss 1.3780697584152222\n",
      "\n",
      "Val func train loss in epoch 2:1.3642641976475716\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.1592614650726318\n",
      "\n",
      "episode 2, val func loss 1.375497579574585\n",
      "\n",
      "episode 3, val func loss 1.2683687210083008\n",
      "\n",
      "episode 4, val func loss 1.3601545095443726\n",
      "\n",
      "episode 5, val func loss 1.2924641370773315\n",
      "\n",
      "episode 6, val func loss 1.4978289604187012\n",
      "\n",
      "episode 7, val func loss 1.296804666519165\n",
      "\n",
      "episode 8, val func loss 1.204565167427063\n",
      "\n",
      "episode 9, val func loss 1.3676464557647705\n",
      "\n",
      "episode 10, val func loss 1.1907838582992554\n",
      "\n",
      "episode 11, val func loss 1.5811376571655273\n",
      "\n",
      "episode 12, val func loss 1.3698800802230835\n",
      "\n",
      "episode 13, val func loss 1.139214277267456\n",
      "\n",
      "episode 14, val func loss 1.3221946954727173\n",
      "\n",
      "episode 15, val func loss 1.3595468997955322\n",
      "\n",
      "episode 16, val func loss 1.2863414287567139\n",
      "\n",
      "Val func train loss in epoch 3:1.3169806599617004\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.2944746017456055\n",
      "\n",
      "episode 2, val func loss 1.0782119035720825\n",
      "\n",
      "episode 3, val func loss 1.3965344429016113\n",
      "\n",
      "episode 4, val func loss 1.437929630279541\n",
      "\n",
      "episode 5, val func loss 1.270986795425415\n",
      "\n",
      "episode 6, val func loss 1.3378582000732422\n",
      "\n",
      "episode 7, val func loss 1.462955355644226\n",
      "\n",
      "episode 8, val func loss 1.4455955028533936\n",
      "\n",
      "episode 9, val func loss 1.3899568319320679\n",
      "\n",
      "episode 10, val func loss 1.433058500289917\n",
      "\n",
      "episode 11, val func loss 1.5525715351104736\n",
      "\n",
      "episode 12, val func loss 1.1708590984344482\n",
      "\n",
      "episode 13, val func loss 1.230928659439087\n",
      "\n",
      "episode 14, val func loss 1.3666490316390991\n",
      "\n",
      "episode 15, val func loss 1.3023743629455566\n",
      "\n",
      "episode 16, val func loss 1.2521655559539795\n",
      "\n",
      "Val func train loss in epoch 4:1.3389443755149841\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.265702724456787\n",
      "\n",
      "episode 2, val func loss 1.0553042888641357\n",
      "\n",
      "episode 3, val func loss 1.1383851766586304\n",
      "\n",
      "episode 4, val func loss 1.124268651008606\n",
      "\n",
      "episode 5, val func loss 1.5887551307678223\n",
      "\n",
      "episode 6, val func loss 1.4565058946609497\n",
      "\n",
      "episode 7, val func loss 1.3363889455795288\n",
      "\n",
      "episode 8, val func loss 1.3152635097503662\n",
      "\n",
      "episode 9, val func loss 1.2470675706863403\n",
      "\n",
      "episode 10, val func loss 1.193209171295166\n",
      "\n",
      "episode 11, val func loss 1.4389855861663818\n",
      "\n",
      "episode 12, val func loss 1.2608038187026978\n",
      "\n",
      "episode 13, val func loss 1.4138896465301514\n",
      "\n",
      "episode 14, val func loss 1.2297407388687134\n",
      "\n",
      "episode 15, val func loss 1.3390737771987915\n",
      "\n",
      "episode 16, val func loss 1.210558533668518\n",
      "\n",
      "Val func train loss in epoch 5:1.2883689478039742\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.4718220233917236\n",
      "\n",
      "episode 2, val func loss 1.3922350406646729\n",
      "\n",
      "episode 3, val func loss 1.3302631378173828\n",
      "\n",
      "episode 4, val func loss 1.1832046508789062\n",
      "\n",
      "episode 5, val func loss 1.4169509410858154\n",
      "\n",
      "episode 6, val func loss 1.3939666748046875\n",
      "\n",
      "episode 7, val func loss 1.144007682800293\n",
      "\n",
      "episode 8, val func loss 1.2423427104949951\n",
      "\n",
      "episode 9, val func loss 1.2005730867385864\n",
      "\n",
      "episode 10, val func loss 1.3089052438735962\n",
      "\n",
      "episode 11, val func loss 1.1185129880905151\n",
      "\n",
      "episode 12, val func loss 1.4060473442077637\n",
      "\n",
      "episode 13, val func loss 1.4975115060806274\n",
      "\n",
      "episode 14, val func loss 1.3347551822662354\n",
      "\n",
      "episode 15, val func loss 1.2505463361740112\n",
      "\n",
      "episode 16, val func loss 1.3886281251907349\n",
      "\n",
      "Val func train loss in epoch 6:1.3175170421600342\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.279707431793213\n",
      "\n",
      "episode 2, val func loss 1.196178674697876\n",
      "\n",
      "episode 3, val func loss 1.423555850982666\n",
      "\n",
      "episode 4, val func loss 1.1518584489822388\n",
      "\n",
      "episode 5, val func loss 1.3156954050064087\n",
      "\n",
      "episode 6, val func loss 1.4132128953933716\n",
      "\n",
      "episode 7, val func loss 1.3422181606292725\n",
      "\n",
      "episode 8, val func loss 1.3483177423477173\n",
      "\n",
      "episode 9, val func loss 1.4695308208465576\n",
      "\n",
      "episode 10, val func loss 1.4365489482879639\n",
      "\n",
      "episode 11, val func loss 1.559074878692627\n",
      "\n",
      "episode 12, val func loss 1.3678537607192993\n",
      "\n",
      "episode 13, val func loss 1.402524709701538\n",
      "\n",
      "episode 14, val func loss 1.396917462348938\n",
      "\n",
      "episode 15, val func loss 1.4084142446517944\n",
      "\n",
      "episode 16, val func loss 1.3187528848648071\n",
      "\n",
      "Val func train loss in epoch 7:1.364397644996643\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.351144790649414\n",
      "\n",
      "episode 2, val func loss 1.4657938480377197\n",
      "\n",
      "episode 3, val func loss 1.24359130859375\n",
      "\n",
      "episode 4, val func loss 1.3793854713439941\n",
      "\n",
      "episode 5, val func loss 1.4603006839752197\n",
      "\n",
      "episode 6, val func loss 1.5548615455627441\n",
      "\n",
      "episode 7, val func loss 1.3695688247680664\n",
      "\n",
      "episode 8, val func loss 1.3446179628372192\n",
      "\n",
      "episode 9, val func loss 1.2867369651794434\n",
      "\n",
      "episode 10, val func loss 1.1583712100982666\n",
      "\n",
      "episode 11, val func loss 1.532950758934021\n",
      "\n",
      "episode 12, val func loss 1.2780512571334839\n",
      "\n",
      "episode 13, val func loss 1.1846784353256226\n",
      "\n",
      "episode 14, val func loss 1.4146846532821655\n",
      "\n",
      "episode 15, val func loss 1.5755980014801025\n",
      "\n",
      "episode 16, val func loss 1.476340413093567\n",
      "\n",
      "Val func train loss in epoch 8:1.379792258143425\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.4570794105529785\n",
      "\n",
      "episode 2, val func loss 1.2580825090408325\n",
      "\n",
      "episode 3, val func loss 1.4284950494766235\n",
      "\n",
      "episode 4, val func loss 1.12152099609375\n",
      "\n",
      "episode 5, val func loss 1.1137992143630981\n",
      "\n",
      "episode 6, val func loss 1.2344779968261719\n",
      "\n",
      "episode 7, val func loss 1.3988094329833984\n",
      "\n",
      "episode 8, val func loss 1.154323935508728\n",
      "\n",
      "episode 9, val func loss 1.4470185041427612\n",
      "\n",
      "episode 10, val func loss 1.4828345775604248\n",
      "\n",
      "episode 11, val func loss 1.3624286651611328\n",
      "\n",
      "episode 12, val func loss 1.3042384386062622\n",
      "\n",
      "episode 13, val func loss 1.4675744771957397\n",
      "\n",
      "episode 14, val func loss 1.397861361503601\n",
      "\n",
      "episode 15, val func loss 1.4750728607177734\n",
      "\n",
      "episode 16, val func loss 1.252568006515503\n",
      "\n",
      "Val func train loss in epoch 9:1.3347615897655487\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.497611403465271\n",
      "\n",
      "episode 2, val func loss 1.4225049018859863\n",
      "\n",
      "episode 3, val func loss 1.21157968044281\n",
      "\n",
      "episode 4, val func loss 1.2370407581329346\n",
      "\n",
      "episode 5, val func loss 1.2135319709777832\n",
      "\n",
      "episode 6, val func loss 1.3377681970596313\n",
      "\n",
      "episode 7, val func loss 1.4609943628311157\n",
      "\n",
      "episode 8, val func loss 1.3647353649139404\n",
      "\n",
      "episode 9, val func loss 1.2001159191131592\n",
      "\n",
      "episode 10, val func loss 1.254066824913025\n",
      "\n",
      "episode 11, val func loss 1.5041714906692505\n",
      "\n",
      "episode 12, val func loss 1.3144251108169556\n",
      "\n",
      "episode 13, val func loss 1.2420903444290161\n",
      "\n",
      "episode 14, val func loss 1.2367578744888306\n",
      "\n",
      "episode 15, val func loss 1.3564561605453491\n",
      "\n",
      "episode 16, val func loss 1.253643274307251\n",
      "\n",
      "Val func train loss in epoch 10:1.3192183524370193\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.4073837995529175\n",
      "\n",
      "episode 2, val func loss 1.218164324760437\n",
      "\n",
      "episode 3, val func loss 1.3407773971557617\n",
      "\n",
      "episode 4, val func loss 1.4006474018096924\n",
      "\n",
      "episode 5, val func loss 1.1503889560699463\n",
      "\n",
      "episode 6, val func loss 1.2014070749282837\n",
      "\n",
      "episode 7, val func loss 1.3827879428863525\n",
      "\n",
      "episode 8, val func loss 1.341556191444397\n",
      "\n",
      "episode 9, val func loss 1.3681161403656006\n",
      "\n",
      "episode 10, val func loss 1.2325022220611572\n",
      "\n",
      "episode 11, val func loss 1.3126542568206787\n",
      "\n",
      "episode 12, val func loss 1.218519926071167\n",
      "\n",
      "episode 13, val func loss 1.3779399394989014\n",
      "\n",
      "episode 14, val func loss 1.4777085781097412\n",
      "\n",
      "episode 15, val func loss 1.4758654832839966\n",
      "\n",
      "episode 16, val func loss 1.36503005027771\n",
      "\n",
      "Val func train loss in epoch 11:1.3294656053185463\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.3004651069641113\n",
      "\n",
      "episode 2, val func loss 1.323503017425537\n",
      "\n",
      "episode 3, val func loss 1.1477572917938232\n",
      "\n",
      "episode 4, val func loss 1.3177714347839355\n",
      "\n",
      "episode 5, val func loss 1.147912621498108\n",
      "\n",
      "episode 6, val func loss 1.2210217714309692\n",
      "\n",
      "episode 7, val func loss 1.2732906341552734\n",
      "\n",
      "episode 8, val func loss 1.406009554862976\n",
      "\n",
      "episode 9, val func loss 1.4305299520492554\n",
      "\n",
      "episode 10, val func loss 1.3968348503112793\n",
      "\n",
      "episode 11, val func loss 1.3328310251235962\n",
      "\n",
      "episode 12, val func loss 1.3945823907852173\n",
      "\n",
      "episode 13, val func loss 1.3291736841201782\n",
      "\n",
      "episode 14, val func loss 1.3468899726867676\n",
      "\n",
      "episode 15, val func loss 1.33167564868927\n",
      "\n",
      "episode 16, val func loss 1.1038017272949219\n",
      "\n",
      "Val func train loss in epoch 12:1.3002531677484512\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.2825376987457275\n",
      "\n",
      "episode 2, val func loss 1.425210952758789\n",
      "\n",
      "episode 3, val func loss 1.3307801485061646\n",
      "\n",
      "episode 4, val func loss 1.3847966194152832\n",
      "\n",
      "episode 5, val func loss 1.2224726676940918\n",
      "\n",
      "episode 6, val func loss 1.280897855758667\n",
      "\n",
      "episode 7, val func loss 1.3577841520309448\n",
      "\n",
      "episode 8, val func loss 1.381226897239685\n",
      "\n",
      "episode 9, val func loss 1.2337285280227661\n",
      "\n",
      "episode 10, val func loss 1.3629560470581055\n",
      "\n",
      "episode 11, val func loss 1.1418614387512207\n",
      "\n",
      "episode 12, val func loss 1.5278048515319824\n",
      "\n",
      "episode 13, val func loss 1.2507890462875366\n",
      "\n",
      "episode 14, val func loss 1.4337329864501953\n",
      "\n",
      "episode 15, val func loss 1.4139035940170288\n",
      "\n",
      "episode 16, val func loss 1.4908251762390137\n",
      "\n",
      "Val func train loss in epoch 13:1.3450817912817001\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.3023639917373657\n",
      "\n",
      "episode 2, val func loss 1.1670935153961182\n",
      "\n",
      "episode 3, val func loss 1.4590450525283813\n",
      "\n",
      "episode 4, val func loss 1.297570824623108\n",
      "\n",
      "episode 5, val func loss 1.1617857217788696\n",
      "\n",
      "episode 6, val func loss 1.140088677406311\n",
      "\n",
      "episode 7, val func loss 1.3148539066314697\n",
      "\n",
      "episode 8, val func loss 1.312347650527954\n",
      "\n",
      "episode 9, val func loss 1.3978818655014038\n",
      "\n",
      "episode 10, val func loss 1.29904043674469\n",
      "\n",
      "episode 11, val func loss 1.3649741411209106\n",
      "\n",
      "episode 12, val func loss 1.2563382387161255\n",
      "\n",
      "episode 13, val func loss 1.3679165840148926\n",
      "\n",
      "episode 14, val func loss 1.374477744102478\n",
      "\n",
      "episode 15, val func loss 1.278188943862915\n",
      "\n",
      "episode 16, val func loss 1.5361742973327637\n",
      "\n",
      "Val func train loss in epoch 14:1.3143838495016098\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.1625920534133911\n",
      "\n",
      "episode 2, val func loss 1.13693106174469\n",
      "\n",
      "episode 3, val func loss 1.1485013961791992\n",
      "\n",
      "episode 4, val func loss 1.6406642198562622\n",
      "\n",
      "episode 5, val func loss 1.1589564085006714\n",
      "\n",
      "episode 6, val func loss 1.406880497932434\n",
      "\n",
      "episode 7, val func loss 1.2825100421905518\n",
      "\n",
      "episode 8, val func loss 1.4767197370529175\n",
      "\n",
      "episode 9, val func loss 1.3096438646316528\n",
      "\n",
      "episode 10, val func loss 1.2820450067520142\n",
      "\n",
      "episode 11, val func loss 1.2408959865570068\n",
      "\n",
      "episode 12, val func loss 1.4525963068008423\n",
      "\n",
      "episode 13, val func loss 1.4219549894332886\n",
      "\n",
      "episode 14, val func loss 1.3996018171310425\n",
      "\n",
      "episode 15, val func loss 1.6317731142044067\n",
      "\n",
      "episode 16, val func loss 1.2469764947891235\n",
      "\n",
      "Val func train loss in epoch 15:1.3374526873230934\n",
      "***********************TIME WAS 4.809666804472605 min*****************************\n",
      "\n",
      "**********************ROUND 35 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.8467347621917725\n",
      "\n",
      "episode 2, policy loss -2.8467347621917725\n",
      "\n",
      "episode 3, policy loss -2.8467347621917725\n",
      "\n",
      "episode 4, policy loss -2.8467347621917725\n",
      "\n",
      "episode 5, policy loss -2.8467347621917725\n",
      "\n",
      "episode 6, policy loss -2.8467347621917725\n",
      "\n",
      "episode 7, policy loss -2.8467347621917725\n",
      "\n",
      "episode 8, policy loss -2.8467347621917725\n",
      "\n",
      "episode 9, policy loss -2.8467350006103516\n",
      "\n",
      "episode 10, policy loss -2.8467347621917725\n",
      "\n",
      "episode 11, policy loss -2.8467347621917725\n",
      "\n",
      "episode 12, policy loss -2.8467347621917725\n",
      "\n",
      "episode 13, policy loss -2.8467347621917725\n",
      "\n",
      "episode 14, policy loss -2.8467347621917725\n",
      "\n",
      "episode 15, policy loss -2.8467347621917725\n",
      "\n",
      "episode 16, policy loss -2.8467347621917725\n",
      "\n",
      "Policy train loss in epoch 0:-2.8467347770929337\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.8467347621917725\n",
      "\n",
      "episode 2, policy loss -2.8467347621917725\n",
      "\n",
      "episode 3, policy loss -2.8467347621917725\n",
      "\n",
      "episode 4, policy loss -2.8467347621917725\n",
      "\n",
      "episode 5, policy loss -2.8467347621917725\n",
      "\n",
      "episode 6, policy loss -2.8467347621917725\n",
      "\n",
      "episode 7, policy loss -2.8467347621917725\n",
      "\n",
      "episode 8, policy loss -2.8467347621917725\n",
      "\n",
      "episode 9, policy loss -2.8467347621917725\n",
      "\n",
      "episode 10, policy loss -2.8467347621917725\n",
      "\n",
      "episode 11, policy loss -2.8467350006103516\n",
      "\n",
      "episode 12, policy loss -2.8467347621917725\n",
      "\n",
      "episode 13, policy loss -2.8467347621917725\n",
      "\n",
      "episode 14, policy loss -2.8467347621917725\n",
      "\n",
      "episode 15, policy loss -2.8467347621917725\n",
      "\n",
      "episode 16, policy loss -2.8467347621917725\n",
      "\n",
      "Policy train loss in epoch 1:-2.8467347770929337\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.8467347621917725\n",
      "\n",
      "episode 2, policy loss -2.8467347621917725\n",
      "\n",
      "episode 3, policy loss -2.8467347621917725\n",
      "\n",
      "episode 4, policy loss -2.8467347621917725\n",
      "\n",
      "episode 5, policy loss -2.8467347621917725\n",
      "\n",
      "episode 6, policy loss -2.8467347621917725\n",
      "\n",
      "episode 7, policy loss -2.8467347621917725\n",
      "\n",
      "episode 8, policy loss -2.8467347621917725\n",
      "\n",
      "episode 9, policy loss -2.8467347621917725\n",
      "\n",
      "episode 10, policy loss -2.8467347621917725\n",
      "\n",
      "episode 11, policy loss -2.8467350006103516\n",
      "\n",
      "episode 12, policy loss -2.8467347621917725\n",
      "\n",
      "episode 13, policy loss -2.8467347621917725\n",
      "\n",
      "episode 14, policy loss -2.8467347621917725\n",
      "\n",
      "episode 15, policy loss -2.8467347621917725\n",
      "\n",
      "episode 16, policy loss -2.8467347621917725\n",
      "\n",
      "Policy train loss in epoch 2:-2.8467347770929337\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.8467350006103516\n",
      "\n",
      "episode 2, policy loss -2.8467347621917725\n",
      "\n",
      "episode 3, policy loss -2.8467347621917725\n",
      "\n",
      "episode 4, policy loss -2.8467347621917725\n",
      "\n",
      "episode 5, policy loss -2.8467347621917725\n",
      "\n",
      "episode 6, policy loss -2.8467347621917725\n",
      "\n",
      "episode 7, policy loss -2.8467347621917725\n",
      "\n",
      "episode 8, policy loss -2.8467347621917725\n",
      "\n",
      "episode 9, policy loss -2.8467347621917725\n",
      "\n",
      "episode 10, policy loss -2.8467347621917725\n",
      "\n",
      "episode 11, policy loss -2.8467347621917725\n",
      "\n",
      "episode 12, policy loss -2.8467347621917725\n",
      "\n",
      "episode 13, policy loss -2.8467347621917725\n",
      "\n",
      "episode 14, policy loss -2.8467347621917725\n",
      "\n",
      "episode 15, policy loss -2.8467347621917725\n",
      "\n",
      "episode 16, policy loss -2.8467347621917725\n",
      "\n",
      "Policy train loss in epoch 3:-2.8467347770929337\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.4214210510253906\n",
      "\n",
      "episode 2, val func loss 1.4212234020233154\n",
      "\n",
      "episode 3, val func loss 1.2418615818023682\n",
      "\n",
      "episode 4, val func loss 1.355802297592163\n",
      "\n",
      "episode 5, val func loss 1.3643722534179688\n",
      "\n",
      "episode 6, val func loss 1.2727906703948975\n",
      "\n",
      "episode 7, val func loss 1.4318691492080688\n",
      "\n",
      "episode 8, val func loss 1.402425765991211\n",
      "\n",
      "episode 9, val func loss 1.260807752609253\n",
      "\n",
      "episode 10, val func loss 1.4721099138259888\n",
      "\n",
      "episode 11, val func loss 1.3802599906921387\n",
      "\n",
      "episode 12, val func loss 1.409081220626831\n",
      "\n",
      "episode 13, val func loss 1.2603418827056885\n",
      "\n",
      "episode 14, val func loss 1.259023666381836\n",
      "\n",
      "episode 15, val func loss 1.2763031721115112\n",
      "\n",
      "episode 16, val func loss 1.261691689491272\n",
      "\n",
      "Val func train loss in epoch 0:1.343211591243744\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.2941977977752686\n",
      "\n",
      "episode 2, val func loss 1.5349280834197998\n",
      "\n",
      "episode 3, val func loss 1.3303171396255493\n",
      "\n",
      "episode 4, val func loss 1.3353123664855957\n",
      "\n",
      "episode 5, val func loss 1.4707984924316406\n",
      "\n",
      "episode 6, val func loss 1.3992074728012085\n",
      "\n",
      "episode 7, val func loss 1.360897183418274\n",
      "\n",
      "episode 8, val func loss 1.3377325534820557\n",
      "\n",
      "episode 9, val func loss 1.1606042385101318\n",
      "\n",
      "episode 10, val func loss 1.2970259189605713\n",
      "\n",
      "episode 11, val func loss 1.2146409749984741\n",
      "\n",
      "episode 12, val func loss 1.3290191888809204\n",
      "\n",
      "episode 13, val func loss 1.4343516826629639\n",
      "\n",
      "episode 14, val func loss 1.391756296157837\n",
      "\n",
      "episode 15, val func loss 1.367288589477539\n",
      "\n",
      "episode 16, val func loss 1.2293444871902466\n",
      "\n",
      "Val func train loss in epoch 1:1.3429639041423798\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.4801673889160156\n",
      "\n",
      "episode 2, val func loss 1.2969095706939697\n",
      "\n",
      "episode 3, val func loss 1.1892153024673462\n",
      "\n",
      "episode 4, val func loss 1.4460322856903076\n",
      "\n",
      "episode 5, val func loss 1.407138705253601\n",
      "\n",
      "episode 6, val func loss 1.503530502319336\n",
      "\n",
      "episode 7, val func loss 1.320608139038086\n",
      "\n",
      "episode 8, val func loss 1.4633699655532837\n",
      "\n",
      "episode 9, val func loss 1.3101955652236938\n",
      "\n",
      "episode 10, val func loss 1.2118010520935059\n",
      "\n",
      "episode 11, val func loss 1.453487753868103\n",
      "\n",
      "episode 12, val func loss 1.3114840984344482\n",
      "\n",
      "episode 13, val func loss 1.387006402015686\n",
      "\n",
      "episode 14, val func loss 1.4634164571762085\n",
      "\n",
      "episode 15, val func loss 1.4937336444854736\n",
      "\n",
      "episode 16, val func loss 1.3863723278045654\n",
      "\n",
      "Val func train loss in epoch 2:1.382779322564602\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.2895668745040894\n",
      "\n",
      "episode 2, val func loss 1.3069721460342407\n",
      "\n",
      "episode 3, val func loss 1.2672818899154663\n",
      "\n",
      "episode 4, val func loss 1.3794562816619873\n",
      "\n",
      "episode 5, val func loss 1.4261587858200073\n",
      "\n",
      "episode 6, val func loss 1.2944427728652954\n",
      "\n",
      "episode 7, val func loss 1.490440845489502\n",
      "\n",
      "episode 8, val func loss 1.5072839260101318\n",
      "\n",
      "episode 9, val func loss 1.1589549779891968\n",
      "\n",
      "episode 10, val func loss 1.2585341930389404\n",
      "\n",
      "episode 11, val func loss 1.3369274139404297\n",
      "\n",
      "episode 12, val func loss 1.474587321281433\n",
      "\n",
      "episode 13, val func loss 1.2042979001998901\n",
      "\n",
      "episode 14, val func loss 1.2874538898468018\n",
      "\n",
      "episode 15, val func loss 1.2738088369369507\n",
      "\n",
      "episode 16, val func loss 1.25742769241333\n",
      "\n",
      "Val func train loss in epoch 3:1.3258497342467308\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.2555601596832275\n",
      "\n",
      "episode 2, val func loss 1.1410906314849854\n",
      "\n",
      "episode 3, val func loss 1.300498127937317\n",
      "\n",
      "episode 4, val func loss 1.3510314226150513\n",
      "\n",
      "episode 5, val func loss 1.304863691329956\n",
      "\n",
      "episode 6, val func loss 1.3707258701324463\n",
      "\n",
      "episode 7, val func loss 1.4833495616912842\n",
      "\n",
      "episode 8, val func loss 1.368725299835205\n",
      "\n",
      "episode 9, val func loss 1.2005914449691772\n",
      "\n",
      "episode 10, val func loss 1.2899925708770752\n",
      "\n",
      "episode 11, val func loss 1.508382797241211\n",
      "\n",
      "episode 12, val func loss 1.3674628734588623\n",
      "\n",
      "episode 13, val func loss 1.2521395683288574\n",
      "\n",
      "episode 14, val func loss 1.37894606590271\n",
      "\n",
      "episode 15, val func loss 1.532962679862976\n",
      "\n",
      "episode 16, val func loss 1.2800313234329224\n",
      "\n",
      "Val func train loss in epoch 4:1.336647130548954\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.3485994338989258\n",
      "\n",
      "episode 2, val func loss 1.265322208404541\n",
      "\n",
      "episode 3, val func loss 1.399629831314087\n",
      "\n",
      "episode 4, val func loss 1.306122899055481\n",
      "\n",
      "episode 5, val func loss 1.179856300354004\n",
      "\n",
      "episode 6, val func loss 1.2972605228424072\n",
      "\n",
      "episode 7, val func loss 1.2403266429901123\n",
      "\n",
      "episode 8, val func loss 1.1739463806152344\n",
      "\n",
      "episode 9, val func loss 1.1981247663497925\n",
      "\n",
      "episode 10, val func loss 1.3797372579574585\n",
      "\n",
      "episode 11, val func loss 1.2732597589492798\n",
      "\n",
      "episode 12, val func loss 1.530969262123108\n",
      "\n",
      "episode 13, val func loss 1.2889147996902466\n",
      "\n",
      "episode 14, val func loss 1.5258842706680298\n",
      "\n",
      "episode 15, val func loss 1.3907982110977173\n",
      "\n",
      "episode 16, val func loss 1.4744288921356201\n",
      "\n",
      "Val func train loss in epoch 5:1.3295738399028778\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.2242010831832886\n",
      "\n",
      "episode 2, val func loss 1.4625192880630493\n",
      "\n",
      "episode 3, val func loss 1.3900892734527588\n",
      "\n",
      "episode 4, val func loss 1.2827097177505493\n",
      "\n",
      "episode 5, val func loss 1.3954195976257324\n",
      "\n",
      "episode 6, val func loss 1.3550337553024292\n",
      "\n",
      "episode 7, val func loss 1.4421271085739136\n",
      "\n",
      "episode 8, val func loss 1.2004300355911255\n",
      "\n",
      "episode 9, val func loss 1.3109980821609497\n",
      "\n",
      "episode 10, val func loss 1.2136306762695312\n",
      "\n",
      "episode 11, val func loss 1.3583396673202515\n",
      "\n",
      "episode 12, val func loss 1.3720636367797852\n",
      "\n",
      "episode 13, val func loss 1.3370051383972168\n",
      "\n",
      "episode 14, val func loss 1.3191752433776855\n",
      "\n",
      "episode 15, val func loss 1.238850712776184\n",
      "\n",
      "episode 16, val func loss 1.206932783126831\n",
      "\n",
      "Val func train loss in epoch 6:1.319345362484455\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.5561596155166626\n",
      "\n",
      "episode 2, val func loss 1.3721296787261963\n",
      "\n",
      "episode 3, val func loss 1.1595522165298462\n",
      "\n",
      "episode 4, val func loss 1.3763539791107178\n",
      "\n",
      "episode 5, val func loss 1.3675315380096436\n",
      "\n",
      "episode 6, val func loss 1.111016035079956\n",
      "\n",
      "episode 7, val func loss 1.2171292304992676\n",
      "\n",
      "episode 8, val func loss 1.3866745233535767\n",
      "\n",
      "episode 9, val func loss 1.2300293445587158\n",
      "\n",
      "episode 10, val func loss 1.2037732601165771\n",
      "\n",
      "episode 11, val func loss 1.42071533203125\n",
      "\n",
      "episode 12, val func loss 1.2119128704071045\n",
      "\n",
      "episode 13, val func loss 1.4762547016143799\n",
      "\n",
      "episode 14, val func loss 1.6802091598510742\n",
      "\n",
      "episode 15, val func loss 1.3176833391189575\n",
      "\n",
      "episode 16, val func loss 1.4600939750671387\n",
      "\n",
      "Val func train loss in epoch 7:1.3467011749744415\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.425895094871521\n",
      "\n",
      "episode 2, val func loss 1.2736929655075073\n",
      "\n",
      "episode 3, val func loss 1.4957982301712036\n",
      "\n",
      "episode 4, val func loss 1.2410361766815186\n",
      "\n",
      "episode 5, val func loss 1.3762338161468506\n",
      "\n",
      "episode 6, val func loss 1.23737633228302\n",
      "\n",
      "episode 7, val func loss 1.2491400241851807\n",
      "\n",
      "episode 8, val func loss 1.3347951173782349\n",
      "\n",
      "episode 9, val func loss 1.2348653078079224\n",
      "\n",
      "episode 10, val func loss 1.478070616722107\n",
      "\n",
      "episode 11, val func loss 1.3733346462249756\n",
      "\n",
      "episode 12, val func loss 1.229637861251831\n",
      "\n",
      "episode 13, val func loss 1.3891404867172241\n",
      "\n",
      "episode 14, val func loss 1.3857324123382568\n",
      "\n",
      "episode 15, val func loss 1.3362054824829102\n",
      "\n",
      "episode 16, val func loss 1.3025020360946655\n",
      "\n",
      "Val func train loss in epoch 8:1.335216037929058\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.3436185121536255\n",
      "\n",
      "episode 2, val func loss 1.3830547332763672\n",
      "\n",
      "episode 3, val func loss 1.6475180387496948\n",
      "\n",
      "episode 4, val func loss 1.408959150314331\n",
      "\n",
      "episode 5, val func loss 1.3325402736663818\n",
      "\n",
      "episode 6, val func loss 1.332858681678772\n",
      "\n",
      "episode 7, val func loss 1.3965113162994385\n",
      "\n",
      "episode 8, val func loss 1.3183512687683105\n",
      "\n",
      "episode 9, val func loss 1.300255298614502\n",
      "\n",
      "episode 10, val func loss 1.2356765270233154\n",
      "\n",
      "episode 11, val func loss 1.357409954071045\n",
      "\n",
      "episode 12, val func loss 1.4988762140274048\n",
      "\n",
      "episode 13, val func loss 1.4324662685394287\n",
      "\n",
      "episode 14, val func loss 1.2836323976516724\n",
      "\n",
      "episode 15, val func loss 1.2860474586486816\n",
      "\n",
      "episode 16, val func loss 1.3267138004302979\n",
      "\n",
      "Val func train loss in epoch 9:1.3677806183695793\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.2279748916625977\n",
      "\n",
      "episode 2, val func loss 1.5462095737457275\n",
      "\n",
      "episode 3, val func loss 1.556033968925476\n",
      "\n",
      "episode 4, val func loss 1.2121819257736206\n",
      "\n",
      "episode 5, val func loss 1.367473840713501\n",
      "\n",
      "episode 6, val func loss 1.1160403490066528\n",
      "\n",
      "episode 7, val func loss 1.1776403188705444\n",
      "\n",
      "episode 8, val func loss 1.3878177404403687\n",
      "\n",
      "episode 9, val func loss 1.2870672941207886\n",
      "\n",
      "episode 10, val func loss 1.5341120958328247\n",
      "\n",
      "episode 11, val func loss 1.0912301540374756\n",
      "\n",
      "episode 12, val func loss 1.4520611763000488\n",
      "\n",
      "episode 13, val func loss 1.3599988222122192\n",
      "\n",
      "episode 14, val func loss 1.4189398288726807\n",
      "\n",
      "episode 15, val func loss 1.1082615852355957\n",
      "\n",
      "episode 16, val func loss 1.524208903312683\n",
      "\n",
      "Val func train loss in epoch 10:1.3354532793164253\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.315003752708435\n",
      "\n",
      "episode 2, val func loss 1.6172009706497192\n",
      "\n",
      "episode 3, val func loss 1.2591354846954346\n",
      "\n",
      "episode 4, val func loss 1.3337976932525635\n",
      "\n",
      "episode 5, val func loss 1.3796026706695557\n",
      "\n",
      "episode 6, val func loss 1.1949732303619385\n",
      "\n",
      "episode 7, val func loss 1.2210431098937988\n",
      "\n",
      "episode 8, val func loss 1.3851886987686157\n",
      "\n",
      "episode 9, val func loss 1.2344729900360107\n",
      "\n",
      "episode 10, val func loss 1.2830913066864014\n",
      "\n",
      "episode 11, val func loss 1.3129005432128906\n",
      "\n",
      "episode 12, val func loss 1.3243794441223145\n",
      "\n",
      "episode 13, val func loss 1.3102436065673828\n",
      "\n",
      "episode 14, val func loss 1.4354857206344604\n",
      "\n",
      "episode 15, val func loss 1.273634910583496\n",
      "\n",
      "episode 16, val func loss 1.4254459142684937\n",
      "\n",
      "Val func train loss in epoch 11:1.3316000029444695\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.4642289876937866\n",
      "\n",
      "episode 2, val func loss 1.5680116415023804\n",
      "\n",
      "episode 3, val func loss 1.2933794260025024\n",
      "\n",
      "episode 4, val func loss 1.3442161083221436\n",
      "\n",
      "episode 5, val func loss 1.227603793144226\n",
      "\n",
      "episode 6, val func loss 1.3318159580230713\n",
      "\n",
      "episode 7, val func loss 1.5480539798736572\n",
      "\n",
      "episode 8, val func loss 1.220959186553955\n",
      "\n",
      "episode 9, val func loss 1.3738962411880493\n",
      "\n",
      "episode 10, val func loss 1.3684931993484497\n",
      "\n",
      "episode 11, val func loss 1.354538917541504\n",
      "\n",
      "episode 12, val func loss 1.2809498310089111\n",
      "\n",
      "episode 13, val func loss 1.1596773862838745\n",
      "\n",
      "episode 14, val func loss 1.574690818786621\n",
      "\n",
      "episode 15, val func loss 1.2379364967346191\n",
      "\n",
      "episode 16, val func loss 1.3143115043640137\n",
      "\n",
      "Val func train loss in epoch 12:1.3539227172732353\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.455636739730835\n",
      "\n",
      "episode 2, val func loss 1.2104754447937012\n",
      "\n",
      "episode 3, val func loss 1.3837498426437378\n",
      "\n",
      "episode 4, val func loss 1.2993427515029907\n",
      "\n",
      "episode 5, val func loss 1.3935115337371826\n",
      "\n",
      "episode 6, val func loss 1.407929539680481\n",
      "\n",
      "episode 7, val func loss 1.4398998022079468\n",
      "\n",
      "episode 8, val func loss 1.3361681699752808\n",
      "\n",
      "episode 9, val func loss 1.2822507619857788\n",
      "\n",
      "episode 10, val func loss 1.3198844194412231\n",
      "\n",
      "episode 11, val func loss 1.2966530323028564\n",
      "\n",
      "episode 12, val func loss 1.45526123046875\n",
      "\n",
      "episode 13, val func loss 1.3087660074234009\n",
      "\n",
      "episode 14, val func loss 1.5117546319961548\n",
      "\n",
      "episode 15, val func loss 1.434080719947815\n",
      "\n",
      "episode 16, val func loss 1.2759512662887573\n",
      "\n",
      "Val func train loss in epoch 13:1.3632072433829308\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.4220725297927856\n",
      "\n",
      "episode 2, val func loss 1.3628449440002441\n",
      "\n",
      "episode 3, val func loss 1.2992757558822632\n",
      "\n",
      "episode 4, val func loss 1.3251869678497314\n",
      "\n",
      "episode 5, val func loss 1.2307460308074951\n",
      "\n",
      "episode 6, val func loss 1.2174370288848877\n",
      "\n",
      "episode 7, val func loss 1.214393973350525\n",
      "\n",
      "episode 8, val func loss 1.483716368675232\n",
      "\n",
      "episode 9, val func loss 1.3561793565750122\n",
      "\n",
      "episode 10, val func loss 1.1116608381271362\n",
      "\n",
      "episode 11, val func loss 1.4285930395126343\n",
      "\n",
      "episode 12, val func loss 1.1678130626678467\n",
      "\n",
      "episode 13, val func loss 1.1882935762405396\n",
      "\n",
      "episode 14, val func loss 1.5077579021453857\n",
      "\n",
      "episode 15, val func loss 1.2818875312805176\n",
      "\n",
      "episode 16, val func loss 1.325021505355835\n",
      "\n",
      "Val func train loss in epoch 14:1.3076800256967545\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.3803811073303223\n",
      "\n",
      "episode 2, val func loss 1.4499717950820923\n",
      "\n",
      "episode 3, val func loss 1.390534520149231\n",
      "\n",
      "episode 4, val func loss 1.2274773120880127\n",
      "\n",
      "episode 5, val func loss 1.3383647203445435\n",
      "\n",
      "episode 6, val func loss 1.2968083620071411\n",
      "\n",
      "episode 7, val func loss 1.2938858270645142\n",
      "\n",
      "episode 8, val func loss 1.4664649963378906\n",
      "\n",
      "episode 9, val func loss 1.3848034143447876\n",
      "\n",
      "episode 10, val func loss 1.2314494848251343\n",
      "\n",
      "episode 11, val func loss 1.4570796489715576\n",
      "\n",
      "episode 12, val func loss 1.2959692478179932\n",
      "\n",
      "episode 13, val func loss 1.3096089363098145\n",
      "\n",
      "episode 14, val func loss 1.4661575555801392\n",
      "\n",
      "episode 15, val func loss 1.1826547384262085\n",
      "\n",
      "episode 16, val func loss 1.3031058311462402\n",
      "\n",
      "Val func train loss in epoch 15:1.3421698436141014\n",
      "***********************TIME WAS 4.8047240773836775 min*****************************\n",
      "\n",
      "**********************ROUND 36 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.006396532058716\n",
      "\n",
      "episode 2, policy loss -3.006396532058716\n",
      "\n",
      "episode 3, policy loss -3.006396532058716\n",
      "\n",
      "episode 4, policy loss -3.006396532058716\n",
      "\n",
      "episode 5, policy loss -3.006396532058716\n",
      "\n",
      "episode 6, policy loss -3.006396532058716\n",
      "\n",
      "episode 7, policy loss -3.006396532058716\n",
      "\n",
      "episode 8, policy loss -3.006396532058716\n",
      "\n",
      "episode 9, policy loss -3.006396532058716\n",
      "\n",
      "episode 10, policy loss -3.006396532058716\n",
      "\n",
      "episode 11, policy loss -3.006396532058716\n",
      "\n",
      "episode 12, policy loss -3.006396532058716\n",
      "\n",
      "episode 13, policy loss -3.006396532058716\n",
      "\n",
      "episode 14, policy loss -3.006396532058716\n",
      "\n",
      "episode 15, policy loss -3.006396532058716\n",
      "\n",
      "episode 16, policy loss -3.006396532058716\n",
      "\n",
      "Policy train loss in epoch 0:-3.006396532058716\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.006396532058716\n",
      "\n",
      "episode 2, policy loss -3.006396532058716\n",
      "\n",
      "episode 3, policy loss -3.006396532058716\n",
      "\n",
      "episode 4, policy loss -3.006396532058716\n",
      "\n",
      "episode 5, policy loss -3.006396532058716\n",
      "\n",
      "episode 6, policy loss -3.006396532058716\n",
      "\n",
      "episode 7, policy loss -3.006396532058716\n",
      "\n",
      "episode 8, policy loss -3.006396532058716\n",
      "\n",
      "episode 9, policy loss -3.006396532058716\n",
      "\n",
      "episode 10, policy loss -3.006396532058716\n",
      "\n",
      "episode 11, policy loss -3.006396532058716\n",
      "\n",
      "episode 12, policy loss -3.006396532058716\n",
      "\n",
      "episode 13, policy loss -3.006396532058716\n",
      "\n",
      "episode 14, policy loss -3.006396532058716\n",
      "\n",
      "episode 15, policy loss -3.006396532058716\n",
      "\n",
      "episode 16, policy loss -3.006396532058716\n",
      "\n",
      "Policy train loss in epoch 1:-3.006396532058716\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.006396532058716\n",
      "\n",
      "episode 2, policy loss -3.006396532058716\n",
      "\n",
      "episode 3, policy loss -3.006396532058716\n",
      "\n",
      "episode 4, policy loss -3.006396532058716\n",
      "\n",
      "episode 5, policy loss -3.006396532058716\n",
      "\n",
      "episode 6, policy loss -3.006396532058716\n",
      "\n",
      "episode 7, policy loss -3.006396532058716\n",
      "\n",
      "episode 8, policy loss -3.006396532058716\n",
      "\n",
      "episode 9, policy loss -3.006396532058716\n",
      "\n",
      "episode 10, policy loss -3.006396532058716\n",
      "\n",
      "episode 11, policy loss -3.006396532058716\n",
      "\n",
      "episode 12, policy loss -3.006396532058716\n",
      "\n",
      "episode 13, policy loss -3.006396532058716\n",
      "\n",
      "episode 14, policy loss -3.006396532058716\n",
      "\n",
      "episode 15, policy loss -3.006396532058716\n",
      "\n",
      "episode 16, policy loss -3.006396532058716\n",
      "\n",
      "Policy train loss in epoch 2:-3.006396532058716\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.006396532058716\n",
      "\n",
      "episode 2, policy loss -3.006396532058716\n",
      "\n",
      "episode 3, policy loss -3.006396532058716\n",
      "\n",
      "episode 4, policy loss -3.006396532058716\n",
      "\n",
      "episode 5, policy loss -3.006396532058716\n",
      "\n",
      "episode 6, policy loss -3.006396532058716\n",
      "\n",
      "episode 7, policy loss -3.006396532058716\n",
      "\n",
      "episode 8, policy loss -3.006396532058716\n",
      "\n",
      "episode 9, policy loss -3.006396532058716\n",
      "\n",
      "episode 10, policy loss -3.006396532058716\n",
      "\n",
      "episode 11, policy loss -3.006396532058716\n",
      "\n",
      "episode 12, policy loss -3.006396532058716\n",
      "\n",
      "episode 13, policy loss -3.006396532058716\n",
      "\n",
      "episode 14, policy loss -3.006396532058716\n",
      "\n",
      "episode 15, policy loss -3.006396532058716\n",
      "\n",
      "episode 16, policy loss -3.006396532058716\n",
      "\n",
      "Policy train loss in epoch 3:-3.006396532058716\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.207869291305542\n",
      "\n",
      "episode 2, val func loss 1.4158282279968262\n",
      "\n",
      "episode 3, val func loss 1.312206745147705\n",
      "\n",
      "episode 4, val func loss 1.2496615648269653\n",
      "\n",
      "episode 5, val func loss 1.464133858680725\n",
      "\n",
      "episode 6, val func loss 1.3459055423736572\n",
      "\n",
      "episode 7, val func loss 1.494143009185791\n",
      "\n",
      "episode 8, val func loss 1.3763294219970703\n",
      "\n",
      "episode 9, val func loss 1.1752324104309082\n",
      "\n",
      "episode 10, val func loss 1.1949107646942139\n",
      "\n",
      "episode 11, val func loss 1.3513450622558594\n",
      "\n",
      "episode 12, val func loss 1.4108296632766724\n",
      "\n",
      "episode 13, val func loss 1.5028223991394043\n",
      "\n",
      "episode 14, val func loss 1.3384137153625488\n",
      "\n",
      "episode 15, val func loss 1.5279319286346436\n",
      "\n",
      "episode 16, val func loss 1.2318397760391235\n",
      "\n",
      "Val func train loss in epoch 0:1.3499627113342285\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.51283597946167\n",
      "\n",
      "episode 2, val func loss 1.289252519607544\n",
      "\n",
      "episode 3, val func loss 1.3749301433563232\n",
      "\n",
      "episode 4, val func loss 1.236301064491272\n",
      "\n",
      "episode 5, val func loss 1.3430945873260498\n",
      "\n",
      "episode 6, val func loss 1.4340040683746338\n",
      "\n",
      "episode 7, val func loss 1.3469325304031372\n",
      "\n",
      "episode 8, val func loss 1.4550426006317139\n",
      "\n",
      "episode 9, val func loss 1.4959254264831543\n",
      "\n",
      "episode 10, val func loss 1.57191801071167\n",
      "\n",
      "episode 11, val func loss 1.485432505607605\n",
      "\n",
      "episode 12, val func loss 1.2513720989227295\n",
      "\n",
      "episode 13, val func loss 1.5068727731704712\n",
      "\n",
      "episode 14, val func loss 1.4500603675842285\n",
      "\n",
      "episode 15, val func loss 1.2771356105804443\n",
      "\n",
      "episode 16, val func loss 1.2885420322418213\n",
      "\n",
      "Val func train loss in epoch 1:1.3949782699346542\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.3821691274642944\n",
      "\n",
      "episode 2, val func loss 1.391932487487793\n",
      "\n",
      "episode 3, val func loss 1.3250855207443237\n",
      "\n",
      "episode 4, val func loss 1.4433369636535645\n",
      "\n",
      "episode 5, val func loss 1.4184019565582275\n",
      "\n",
      "episode 6, val func loss 1.4486651420593262\n",
      "\n",
      "episode 7, val func loss 1.5491552352905273\n",
      "\n",
      "episode 8, val func loss 1.3944329023361206\n",
      "\n",
      "episode 9, val func loss 1.2299997806549072\n",
      "\n",
      "episode 10, val func loss 1.279397964477539\n",
      "\n",
      "episode 11, val func loss 1.4216220378875732\n",
      "\n",
      "episode 12, val func loss 1.6600573062896729\n",
      "\n",
      "episode 13, val func loss 1.3152178525924683\n",
      "\n",
      "episode 14, val func loss 1.3731204271316528\n",
      "\n",
      "episode 15, val func loss 1.3942310810089111\n",
      "\n",
      "episode 16, val func loss 1.3736217021942139\n",
      "\n",
      "Val func train loss in epoch 2:1.4000279679894447\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.3983126878738403\n",
      "\n",
      "episode 2, val func loss 1.1395598649978638\n",
      "\n",
      "episode 3, val func loss 1.2451258897781372\n",
      "\n",
      "episode 4, val func loss 1.4246770143508911\n",
      "\n",
      "episode 5, val func loss 1.1536513566970825\n",
      "\n",
      "episode 6, val func loss 1.3615633249282837\n",
      "\n",
      "episode 7, val func loss 1.3390581607818604\n",
      "\n",
      "episode 8, val func loss 1.281148076057434\n",
      "\n",
      "episode 9, val func loss 1.619297742843628\n",
      "\n",
      "episode 10, val func loss 1.4715532064437866\n",
      "\n",
      "episode 11, val func loss 1.5435476303100586\n",
      "\n",
      "episode 12, val func loss 1.472847819328308\n",
      "\n",
      "episode 13, val func loss 1.3841240406036377\n",
      "\n",
      "episode 14, val func loss 1.3870060443878174\n",
      "\n",
      "episode 15, val func loss 1.2237958908081055\n",
      "\n",
      "episode 16, val func loss 1.53119695186615\n",
      "\n",
      "Val func train loss in epoch 3:1.3735291063785553\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.4408533573150635\n",
      "\n",
      "episode 2, val func loss 1.3933300971984863\n",
      "\n",
      "episode 3, val func loss 1.273425579071045\n",
      "\n",
      "episode 4, val func loss 1.309967279434204\n",
      "\n",
      "episode 5, val func loss 1.3284368515014648\n",
      "\n",
      "episode 6, val func loss 1.3978278636932373\n",
      "\n",
      "episode 7, val func loss 1.3438267707824707\n",
      "\n",
      "episode 8, val func loss 1.4368383884429932\n",
      "\n",
      "episode 9, val func loss 1.3547251224517822\n",
      "\n",
      "episode 10, val func loss 1.3010705709457397\n",
      "\n",
      "episode 11, val func loss 1.443565011024475\n",
      "\n",
      "episode 12, val func loss 1.43097722530365\n",
      "\n",
      "episode 13, val func loss 1.3368322849273682\n",
      "\n",
      "episode 14, val func loss 1.1317546367645264\n",
      "\n",
      "episode 15, val func loss 1.4983431100845337\n",
      "\n",
      "episode 16, val func loss 1.3277168273925781\n",
      "\n",
      "Val func train loss in epoch 4:1.3593431860208511\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.4241905212402344\n",
      "\n",
      "episode 2, val func loss 1.3159656524658203\n",
      "\n",
      "episode 3, val func loss 1.4344346523284912\n",
      "\n",
      "episode 4, val func loss 1.347278118133545\n",
      "\n",
      "episode 5, val func loss 1.2287461757659912\n",
      "\n",
      "episode 6, val func loss 1.2869751453399658\n",
      "\n",
      "episode 7, val func loss 1.3968061208724976\n",
      "\n",
      "episode 8, val func loss 1.3758742809295654\n",
      "\n",
      "episode 9, val func loss 1.5227153301239014\n",
      "\n",
      "episode 10, val func loss 1.2093801498413086\n",
      "\n",
      "episode 11, val func loss 1.287301778793335\n",
      "\n",
      "episode 12, val func loss 1.1952879428863525\n",
      "\n",
      "episode 13, val func loss 1.4785689115524292\n",
      "\n",
      "episode 14, val func loss 1.3885811567306519\n",
      "\n",
      "episode 15, val func loss 1.219767689704895\n",
      "\n",
      "episode 16, val func loss 1.2986745834350586\n",
      "\n",
      "Val func train loss in epoch 5:1.3381592631340027\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.371480107307434\n",
      "\n",
      "episode 2, val func loss 1.3446323871612549\n",
      "\n",
      "episode 3, val func loss 1.4141141176223755\n",
      "\n",
      "episode 4, val func loss 1.4581769704818726\n",
      "\n",
      "episode 5, val func loss 1.3804681301116943\n",
      "\n",
      "episode 6, val func loss 1.167261004447937\n",
      "\n",
      "episode 7, val func loss 1.3246173858642578\n",
      "\n",
      "episode 8, val func loss 1.3288832902908325\n",
      "\n",
      "episode 9, val func loss 1.4267573356628418\n",
      "\n",
      "episode 10, val func loss 1.1650325059890747\n",
      "\n",
      "episode 11, val func loss 1.4441823959350586\n",
      "\n",
      "episode 12, val func loss 1.2460440397262573\n",
      "\n",
      "episode 13, val func loss 1.2952468395233154\n",
      "\n",
      "episode 14, val func loss 1.487288475036621\n",
      "\n",
      "episode 15, val func loss 1.431111216545105\n",
      "\n",
      "episode 16, val func loss 1.3427249193191528\n",
      "\n",
      "Val func train loss in epoch 6:1.3517513200640678\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.367654800415039\n",
      "\n",
      "episode 2, val func loss 1.2027298212051392\n",
      "\n",
      "episode 3, val func loss 1.4376506805419922\n",
      "\n",
      "episode 4, val func loss 1.2407865524291992\n",
      "\n",
      "episode 5, val func loss 1.2598193883895874\n",
      "\n",
      "episode 6, val func loss 1.3128299713134766\n",
      "\n",
      "episode 7, val func loss 1.4828479290008545\n",
      "\n",
      "episode 8, val func loss 1.3731637001037598\n",
      "\n",
      "episode 9, val func loss 1.5834192037582397\n",
      "\n",
      "episode 10, val func loss 1.175384759902954\n",
      "\n",
      "episode 11, val func loss 1.4111006259918213\n",
      "\n",
      "episode 12, val func loss 1.4112170934677124\n",
      "\n",
      "episode 13, val func loss 1.4149878025054932\n",
      "\n",
      "episode 14, val func loss 1.4317288398742676\n",
      "\n",
      "episode 15, val func loss 1.0757166147232056\n",
      "\n",
      "episode 16, val func loss 1.263388752937317\n",
      "\n",
      "Val func train loss in epoch 7:1.3402766585350037\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.2415274381637573\n",
      "\n",
      "episode 2, val func loss 1.4476587772369385\n",
      "\n",
      "episode 3, val func loss 1.2815024852752686\n",
      "\n",
      "episode 4, val func loss 1.4760112762451172\n",
      "\n",
      "episode 5, val func loss 1.5415314435958862\n",
      "\n",
      "episode 6, val func loss 1.213673710823059\n",
      "\n",
      "episode 7, val func loss 1.3186471462249756\n",
      "\n",
      "episode 8, val func loss 1.5268001556396484\n",
      "\n",
      "episode 9, val func loss 1.3248976469039917\n",
      "\n",
      "episode 10, val func loss 1.3750293254852295\n",
      "\n",
      "episode 11, val func loss 1.3681244850158691\n",
      "\n",
      "episode 12, val func loss 1.3274160623550415\n",
      "\n",
      "episode 13, val func loss 1.4696096181869507\n",
      "\n",
      "episode 14, val func loss 1.3015847206115723\n",
      "\n",
      "episode 15, val func loss 1.3440271615982056\n",
      "\n",
      "episode 16, val func loss 1.3771438598632812\n",
      "\n",
      "Val func train loss in epoch 8:1.3709490820765495\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.3916712999343872\n",
      "\n",
      "episode 2, val func loss 1.4011900424957275\n",
      "\n",
      "episode 3, val func loss 1.4120334386825562\n",
      "\n",
      "episode 4, val func loss 1.3628708124160767\n",
      "\n",
      "episode 5, val func loss 1.3783565759658813\n",
      "\n",
      "episode 6, val func loss 1.2357568740844727\n",
      "\n",
      "episode 7, val func loss 1.2981395721435547\n",
      "\n",
      "episode 8, val func loss 1.2765437364578247\n",
      "\n",
      "episode 9, val func loss 1.4105156660079956\n",
      "\n",
      "episode 10, val func loss 1.298032522201538\n",
      "\n",
      "episode 11, val func loss 1.3871432542800903\n",
      "\n",
      "episode 12, val func loss 1.2783608436584473\n",
      "\n",
      "episode 13, val func loss 1.4590401649475098\n",
      "\n",
      "episode 14, val func loss 1.3430066108703613\n",
      "\n",
      "episode 15, val func loss 1.2365434169769287\n",
      "\n",
      "episode 16, val func loss 1.2235933542251587\n",
      "\n",
      "Val func train loss in epoch 9:1.337049886584282\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.430657148361206\n",
      "\n",
      "episode 2, val func loss 1.2912229299545288\n",
      "\n",
      "episode 3, val func loss 1.1834176778793335\n",
      "\n",
      "episode 4, val func loss 1.2722663879394531\n",
      "\n",
      "episode 5, val func loss 1.2701226472854614\n",
      "\n",
      "episode 6, val func loss 1.4529902935028076\n",
      "\n",
      "episode 7, val func loss 1.2789608240127563\n",
      "\n",
      "episode 8, val func loss 1.2800450325012207\n",
      "\n",
      "episode 9, val func loss 1.367059350013733\n",
      "\n",
      "episode 10, val func loss 1.1804600954055786\n",
      "\n",
      "episode 11, val func loss 1.2451239824295044\n",
      "\n",
      "episode 12, val func loss 1.373741626739502\n",
      "\n",
      "episode 13, val func loss 1.4407975673675537\n",
      "\n",
      "episode 14, val func loss 1.351610779762268\n",
      "\n",
      "episode 15, val func loss 1.1807544231414795\n",
      "\n",
      "episode 16, val func loss 1.2558985948562622\n",
      "\n",
      "Val func train loss in epoch 10:1.3034455850720406\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.5194889307022095\n",
      "\n",
      "episode 2, val func loss 1.268974781036377\n",
      "\n",
      "episode 3, val func loss 1.2714329957962036\n",
      "\n",
      "episode 4, val func loss 1.2371783256530762\n",
      "\n",
      "episode 5, val func loss 1.646313190460205\n",
      "\n",
      "episode 6, val func loss 1.4336342811584473\n",
      "\n",
      "episode 7, val func loss 1.5139943361282349\n",
      "\n",
      "episode 8, val func loss 1.4593902826309204\n",
      "\n",
      "episode 9, val func loss 1.3487714529037476\n",
      "\n",
      "episode 10, val func loss 1.3690134286880493\n",
      "\n",
      "episode 11, val func loss 1.4912854433059692\n",
      "\n",
      "episode 12, val func loss 1.2595726251602173\n",
      "\n",
      "episode 13, val func loss 1.2414907217025757\n",
      "\n",
      "episode 14, val func loss 1.4107725620269775\n",
      "\n",
      "episode 15, val func loss 1.4491939544677734\n",
      "\n",
      "episode 16, val func loss 1.3007361888885498\n",
      "\n",
      "Val func train loss in epoch 11:1.3888277187943459\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.185999870300293\n",
      "\n",
      "episode 2, val func loss 1.271169900894165\n",
      "\n",
      "episode 3, val func loss 1.2492170333862305\n",
      "\n",
      "episode 4, val func loss 1.1754446029663086\n",
      "\n",
      "episode 5, val func loss 1.2704439163208008\n",
      "\n",
      "episode 6, val func loss 1.3813397884368896\n",
      "\n",
      "episode 7, val func loss 1.191375970840454\n",
      "\n",
      "episode 8, val func loss 1.1964465379714966\n",
      "\n",
      "episode 9, val func loss 1.4222885370254517\n",
      "\n",
      "episode 10, val func loss 1.167876124382019\n",
      "\n",
      "episode 11, val func loss 1.455903172492981\n",
      "\n",
      "episode 12, val func loss 1.4492144584655762\n",
      "\n",
      "episode 13, val func loss 1.2127989530563354\n",
      "\n",
      "episode 14, val func loss 1.4407113790512085\n",
      "\n",
      "episode 15, val func loss 1.2632219791412354\n",
      "\n",
      "episode 16, val func loss 1.3992259502410889\n",
      "\n",
      "Val func train loss in epoch 12:1.2957923859357834\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.3804467916488647\n",
      "\n",
      "episode 2, val func loss 1.2055655717849731\n",
      "\n",
      "episode 3, val func loss 1.502504825592041\n",
      "\n",
      "episode 4, val func loss 1.3608291149139404\n",
      "\n",
      "episode 5, val func loss 1.171883463859558\n",
      "\n",
      "episode 6, val func loss 1.3603392839431763\n",
      "\n",
      "episode 7, val func loss 1.3512779474258423\n",
      "\n",
      "episode 8, val func loss 1.2561701536178589\n",
      "\n",
      "episode 9, val func loss 1.3998256921768188\n",
      "\n",
      "episode 10, val func loss 1.320291519165039\n",
      "\n",
      "episode 11, val func loss 1.3063290119171143\n",
      "\n",
      "episode 12, val func loss 1.465099573135376\n",
      "\n",
      "episode 13, val func loss 1.346450686454773\n",
      "\n",
      "episode 14, val func loss 1.5181407928466797\n",
      "\n",
      "episode 15, val func loss 1.2284719944000244\n",
      "\n",
      "episode 16, val func loss 1.315732717514038\n",
      "\n",
      "Val func train loss in epoch 13:1.3430849462747574\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.4217272996902466\n",
      "\n",
      "episode 2, val func loss 1.3676239252090454\n",
      "\n",
      "episode 3, val func loss 1.5267423391342163\n",
      "\n",
      "episode 4, val func loss 1.3853181600570679\n",
      "\n",
      "episode 5, val func loss 1.4111636877059937\n",
      "\n",
      "episode 6, val func loss 1.5783177614212036\n",
      "\n",
      "episode 7, val func loss 1.3549206256866455\n",
      "\n",
      "episode 8, val func loss 1.2733107805252075\n",
      "\n",
      "episode 9, val func loss 1.5172626972198486\n",
      "\n",
      "episode 10, val func loss 1.2685434818267822\n",
      "\n",
      "episode 11, val func loss 1.2169047594070435\n",
      "\n",
      "episode 12, val func loss 1.1751168966293335\n",
      "\n",
      "episode 13, val func loss 1.2556781768798828\n",
      "\n",
      "episode 14, val func loss 1.0271351337432861\n",
      "\n",
      "episode 15, val func loss 1.30190908908844\n",
      "\n",
      "episode 16, val func loss 1.1928402185440063\n",
      "\n",
      "Val func train loss in epoch 14:1.3296571895480156\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.4261575937271118\n",
      "\n",
      "episode 2, val func loss 1.3835065364837646\n",
      "\n",
      "episode 3, val func loss 1.4872562885284424\n",
      "\n",
      "episode 4, val func loss 1.3144117593765259\n",
      "\n",
      "episode 5, val func loss 1.2722123861312866\n",
      "\n",
      "episode 6, val func loss 1.3439018726348877\n",
      "\n",
      "episode 7, val func loss 1.1434214115142822\n",
      "\n",
      "episode 8, val func loss 1.3400648832321167\n",
      "\n",
      "episode 9, val func loss 1.5320353507995605\n",
      "\n",
      "episode 10, val func loss 1.2916107177734375\n",
      "\n",
      "episode 11, val func loss 1.5432195663452148\n",
      "\n",
      "episode 12, val func loss 1.2742555141448975\n",
      "\n",
      "episode 13, val func loss 1.2843806743621826\n",
      "\n",
      "episode 14, val func loss 1.478710651397705\n",
      "\n",
      "episode 15, val func loss 1.1547847986221313\n",
      "\n",
      "episode 16, val func loss 1.3633300065994263\n",
      "\n",
      "Val func train loss in epoch 15:1.3520787507295609\n",
      "***********************TIME WAS 4.806798485914866 min*****************************\n",
      "\n",
      "**********************ROUND 37 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.0158963203430176\n",
      "\n",
      "episode 2, policy loss -3.0158963203430176\n",
      "\n",
      "episode 3, policy loss -3.0158963203430176\n",
      "\n",
      "episode 4, policy loss -3.0158963203430176\n",
      "\n",
      "episode 5, policy loss -3.0158963203430176\n",
      "\n",
      "episode 6, policy loss -3.0158963203430176\n",
      "\n",
      "episode 7, policy loss -3.0158963203430176\n",
      "\n",
      "episode 8, policy loss -3.0158963203430176\n",
      "\n",
      "episode 9, policy loss -3.0158963203430176\n",
      "\n",
      "episode 10, policy loss -3.0158963203430176\n",
      "\n",
      "episode 11, policy loss -3.0158963203430176\n",
      "\n",
      "episode 12, policy loss -3.0158963203430176\n",
      "\n",
      "episode 13, policy loss -3.0158963203430176\n",
      "\n",
      "episode 14, policy loss -3.0158963203430176\n",
      "\n",
      "episode 15, policy loss -3.0158963203430176\n",
      "\n",
      "episode 16, policy loss -3.0158963203430176\n",
      "\n",
      "Policy train loss in epoch 0:-3.0158963203430176\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.0158963203430176\n",
      "\n",
      "episode 2, policy loss -3.0158963203430176\n",
      "\n",
      "episode 3, policy loss -3.0158963203430176\n",
      "\n",
      "episode 4, policy loss -3.0158963203430176\n",
      "\n",
      "episode 5, policy loss -3.0158963203430176\n",
      "\n",
      "episode 6, policy loss -3.0158963203430176\n",
      "\n",
      "episode 7, policy loss -3.0158963203430176\n",
      "\n",
      "episode 8, policy loss -3.0158963203430176\n",
      "\n",
      "episode 9, policy loss -3.0158963203430176\n",
      "\n",
      "episode 10, policy loss -3.0158963203430176\n",
      "\n",
      "episode 11, policy loss -3.0158963203430176\n",
      "\n",
      "episode 12, policy loss -3.0158963203430176\n",
      "\n",
      "episode 13, policy loss -3.0158963203430176\n",
      "\n",
      "episode 14, policy loss -3.0158963203430176\n",
      "\n",
      "episode 15, policy loss -3.0158963203430176\n",
      "\n",
      "episode 16, policy loss -3.0158963203430176\n",
      "\n",
      "Policy train loss in epoch 1:-3.0158963203430176\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.0158963203430176\n",
      "\n",
      "episode 2, policy loss -3.0158963203430176\n",
      "\n",
      "episode 3, policy loss -3.0158963203430176\n",
      "\n",
      "episode 4, policy loss -3.0158963203430176\n",
      "\n",
      "episode 5, policy loss -3.0158963203430176\n",
      "\n",
      "episode 6, policy loss -3.0158963203430176\n",
      "\n",
      "episode 7, policy loss -3.0158963203430176\n",
      "\n",
      "episode 8, policy loss -3.0158963203430176\n",
      "\n",
      "episode 9, policy loss -3.0158963203430176\n",
      "\n",
      "episode 10, policy loss -3.0158963203430176\n",
      "\n",
      "episode 11, policy loss -3.0158963203430176\n",
      "\n",
      "episode 12, policy loss -3.0158963203430176\n",
      "\n",
      "episode 13, policy loss -3.0158963203430176\n",
      "\n",
      "episode 14, policy loss -3.0158963203430176\n",
      "\n",
      "episode 15, policy loss -3.0158963203430176\n",
      "\n",
      "episode 16, policy loss -3.0158963203430176\n",
      "\n",
      "Policy train loss in epoch 2:-3.0158963203430176\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.0158963203430176\n",
      "\n",
      "episode 2, policy loss -3.0158963203430176\n",
      "\n",
      "episode 3, policy loss -3.0158963203430176\n",
      "\n",
      "episode 4, policy loss -3.0158963203430176\n",
      "\n",
      "episode 5, policy loss -3.0158963203430176\n",
      "\n",
      "episode 6, policy loss -3.0158963203430176\n",
      "\n",
      "episode 7, policy loss -3.0158963203430176\n",
      "\n",
      "episode 8, policy loss -3.0158963203430176\n",
      "\n",
      "episode 9, policy loss -3.0158963203430176\n",
      "\n",
      "episode 10, policy loss -3.0158963203430176\n",
      "\n",
      "episode 11, policy loss -3.0158963203430176\n",
      "\n",
      "episode 12, policy loss -3.0158963203430176\n",
      "\n",
      "episode 13, policy loss -3.0158963203430176\n",
      "\n",
      "episode 14, policy loss -3.0158963203430176\n",
      "\n",
      "episode 15, policy loss -3.0158963203430176\n",
      "\n",
      "episode 16, policy loss -3.0158963203430176\n",
      "\n",
      "Policy train loss in epoch 3:-3.0158963203430176\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.2723069190979004\n",
      "\n",
      "episode 2, val func loss 1.4211734533309937\n",
      "\n",
      "episode 3, val func loss 1.4292957782745361\n",
      "\n",
      "episode 4, val func loss 1.258547067642212\n",
      "\n",
      "episode 5, val func loss 1.2536039352416992\n",
      "\n",
      "episode 6, val func loss 1.402448296546936\n",
      "\n",
      "episode 7, val func loss 1.3602180480957031\n",
      "\n",
      "episode 8, val func loss 1.3478635549545288\n",
      "\n",
      "episode 9, val func loss 1.3218380212783813\n",
      "\n",
      "episode 10, val func loss 1.338134765625\n",
      "\n",
      "episode 11, val func loss 1.5479854345321655\n",
      "\n",
      "episode 12, val func loss 1.1411226987838745\n",
      "\n",
      "episode 13, val func loss 1.2599225044250488\n",
      "\n",
      "episode 14, val func loss 1.388390302658081\n",
      "\n",
      "episode 15, val func loss 1.4287149906158447\n",
      "\n",
      "episode 16, val func loss 1.097898006439209\n",
      "\n",
      "Val func train loss in epoch 0:1.3293414860963821\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.4378864765167236\n",
      "\n",
      "episode 2, val func loss 1.3299368619918823\n",
      "\n",
      "episode 3, val func loss 1.535923719406128\n",
      "\n",
      "episode 4, val func loss 1.1647065877914429\n",
      "\n",
      "episode 5, val func loss 1.4359887838363647\n",
      "\n",
      "episode 6, val func loss 1.2350229024887085\n",
      "\n",
      "episode 7, val func loss 1.0186841487884521\n",
      "\n",
      "episode 8, val func loss 1.3176162242889404\n",
      "\n",
      "episode 9, val func loss 1.303731083869934\n",
      "\n",
      "episode 10, val func loss 1.5376343727111816\n",
      "\n",
      "episode 11, val func loss 1.2914602756500244\n",
      "\n",
      "episode 12, val func loss 1.3707841634750366\n",
      "\n",
      "episode 13, val func loss 1.350719928741455\n",
      "\n",
      "episode 14, val func loss 1.3830002546310425\n",
      "\n",
      "episode 15, val func loss 1.5881388187408447\n",
      "\n",
      "episode 16, val func loss 1.2772632837295532\n",
      "\n",
      "Val func train loss in epoch 1:1.3486561179161072\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.5942890644073486\n",
      "\n",
      "episode 2, val func loss 1.2313917875289917\n",
      "\n",
      "episode 3, val func loss 1.2215439081192017\n",
      "\n",
      "episode 4, val func loss 1.368797779083252\n",
      "\n",
      "episode 5, val func loss 1.2521822452545166\n",
      "\n",
      "episode 6, val func loss 1.3042584657669067\n",
      "\n",
      "episode 7, val func loss 1.186571717262268\n",
      "\n",
      "episode 8, val func loss 1.269767165184021\n",
      "\n",
      "episode 9, val func loss 1.3335597515106201\n",
      "\n",
      "episode 10, val func loss 1.2607479095458984\n",
      "\n",
      "episode 11, val func loss 1.1827582120895386\n",
      "\n",
      "episode 12, val func loss 1.24986732006073\n",
      "\n",
      "episode 13, val func loss 1.2940034866333008\n",
      "\n",
      "episode 14, val func loss 1.3312580585479736\n",
      "\n",
      "episode 15, val func loss 1.3285627365112305\n",
      "\n",
      "episode 16, val func loss 1.3817914724349976\n",
      "\n",
      "Val func train loss in epoch 2:1.2994594424962997\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.2919204235076904\n",
      "\n",
      "episode 2, val func loss 1.3259633779525757\n",
      "\n",
      "episode 3, val func loss 1.4976704120635986\n",
      "\n",
      "episode 4, val func loss 1.40022873878479\n",
      "\n",
      "episode 5, val func loss 1.3207252025604248\n",
      "\n",
      "episode 6, val func loss 1.345723271369934\n",
      "\n",
      "episode 7, val func loss 1.2016723155975342\n",
      "\n",
      "episode 8, val func loss 1.1632426977157593\n",
      "\n",
      "episode 9, val func loss 1.29670250415802\n",
      "\n",
      "episode 10, val func loss 1.536144733428955\n",
      "\n",
      "episode 11, val func loss 1.6556174755096436\n",
      "\n",
      "episode 12, val func loss 1.3056771755218506\n",
      "\n",
      "episode 13, val func loss 1.54361891746521\n",
      "\n",
      "episode 14, val func loss 1.2097113132476807\n",
      "\n",
      "episode 15, val func loss 1.4376164674758911\n",
      "\n",
      "episode 16, val func loss 1.4140127897262573\n",
      "\n",
      "Val func train loss in epoch 3:1.3716404885053635\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.6441922187805176\n",
      "\n",
      "episode 2, val func loss 1.260758876800537\n",
      "\n",
      "episode 3, val func loss 1.2675467729568481\n",
      "\n",
      "episode 4, val func loss 1.3962953090667725\n",
      "\n",
      "episode 5, val func loss 1.4153434038162231\n",
      "\n",
      "episode 6, val func loss 1.4744678735733032\n",
      "\n",
      "episode 7, val func loss 1.55978262424469\n",
      "\n",
      "episode 8, val func loss 1.547767996788025\n",
      "\n",
      "episode 9, val func loss 1.4152733087539673\n",
      "\n",
      "episode 10, val func loss 1.3176971673965454\n",
      "\n",
      "episode 11, val func loss 1.0500986576080322\n",
      "\n",
      "episode 12, val func loss 1.3785431385040283\n",
      "\n",
      "episode 13, val func loss 1.360577940940857\n",
      "\n",
      "episode 14, val func loss 1.2772365808486938\n",
      "\n",
      "episode 15, val func loss 1.349413514137268\n",
      "\n",
      "episode 16, val func loss 1.4702677726745605\n",
      "\n",
      "Val func train loss in epoch 4:1.3865789473056793\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.3798847198486328\n",
      "\n",
      "episode 2, val func loss 1.4401100873947144\n",
      "\n",
      "episode 3, val func loss 1.2425105571746826\n",
      "\n",
      "episode 4, val func loss 1.1345734596252441\n",
      "\n",
      "episode 5, val func loss 1.3035842180252075\n",
      "\n",
      "episode 6, val func loss 1.0844001770019531\n",
      "\n",
      "episode 7, val func loss 1.2301386594772339\n",
      "\n",
      "episode 8, val func loss 1.3036500215530396\n",
      "\n",
      "episode 9, val func loss 1.5284639596939087\n",
      "\n",
      "episode 10, val func loss 1.289950966835022\n",
      "\n",
      "episode 11, val func loss 1.1666171550750732\n",
      "\n",
      "episode 12, val func loss 1.2125933170318604\n",
      "\n",
      "episode 13, val func loss 1.4432618618011475\n",
      "\n",
      "episode 14, val func loss 1.32515549659729\n",
      "\n",
      "episode 15, val func loss 1.4615215063095093\n",
      "\n",
      "episode 16, val func loss 1.2662944793701172\n",
      "\n",
      "Val func train loss in epoch 5:1.3007944151759148\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.3417346477508545\n",
      "\n",
      "episode 2, val func loss 1.238122582435608\n",
      "\n",
      "episode 3, val func loss 1.3022351264953613\n",
      "\n",
      "episode 4, val func loss 1.3910236358642578\n",
      "\n",
      "episode 5, val func loss 1.2270169258117676\n",
      "\n",
      "episode 6, val func loss 1.441712498664856\n",
      "\n",
      "episode 7, val func loss 1.4689173698425293\n",
      "\n",
      "episode 8, val func loss 1.3761411905288696\n",
      "\n",
      "episode 9, val func loss 1.5119004249572754\n",
      "\n",
      "episode 10, val func loss 1.4871838092803955\n",
      "\n",
      "episode 11, val func loss 1.3969182968139648\n",
      "\n",
      "episode 12, val func loss 1.3189187049865723\n",
      "\n",
      "episode 13, val func loss 1.37644624710083\n",
      "\n",
      "episode 14, val func loss 1.4672927856445312\n",
      "\n",
      "episode 15, val func loss 1.3248472213745117\n",
      "\n",
      "episode 16, val func loss 1.3227264881134033\n",
      "\n",
      "Val func train loss in epoch 6:1.3745711222290993\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.3789113759994507\n",
      "\n",
      "episode 2, val func loss 1.4542295932769775\n",
      "\n",
      "episode 3, val func loss 1.5619763135910034\n",
      "\n",
      "episode 4, val func loss 1.404582142829895\n",
      "\n",
      "episode 5, val func loss 1.6761820316314697\n",
      "\n",
      "episode 6, val func loss 1.310322642326355\n",
      "\n",
      "episode 7, val func loss 1.6161866188049316\n",
      "\n",
      "episode 8, val func loss 1.46258544921875\n",
      "\n",
      "episode 9, val func loss 1.518567681312561\n",
      "\n",
      "episode 10, val func loss 1.4299837350845337\n",
      "\n",
      "episode 11, val func loss 1.321781039237976\n",
      "\n",
      "episode 12, val func loss 1.3164317607879639\n",
      "\n",
      "episode 13, val func loss 1.4509950876235962\n",
      "\n",
      "episode 14, val func loss 1.402632713317871\n",
      "\n",
      "episode 15, val func loss 1.3204443454742432\n",
      "\n",
      "episode 16, val func loss 1.254753828048706\n",
      "\n",
      "Val func train loss in epoch 7:1.4300353974103928\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.3269728422164917\n",
      "\n",
      "episode 2, val func loss 1.444814920425415\n",
      "\n",
      "episode 3, val func loss 1.3420794010162354\n",
      "\n",
      "episode 4, val func loss 1.3718342781066895\n",
      "\n",
      "episode 5, val func loss 1.3089712858200073\n",
      "\n",
      "episode 6, val func loss 1.416157603263855\n",
      "\n",
      "episode 7, val func loss 1.3670505285263062\n",
      "\n",
      "episode 8, val func loss 1.2277363538742065\n",
      "\n",
      "episode 9, val func loss 1.3135137557983398\n",
      "\n",
      "episode 10, val func loss 1.3885481357574463\n",
      "\n",
      "episode 11, val func loss 1.33072030544281\n",
      "\n",
      "episode 12, val func loss 1.263203740119934\n",
      "\n",
      "episode 13, val func loss 1.2512898445129395\n",
      "\n",
      "episode 14, val func loss 1.086011528968811\n",
      "\n",
      "episode 15, val func loss 1.317894458770752\n",
      "\n",
      "episode 16, val func loss 1.1994715929031372\n",
      "\n",
      "Val func train loss in epoch 8:1.309766910970211\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.619384765625\n",
      "\n",
      "episode 2, val func loss 0.9917356371879578\n",
      "\n",
      "episode 3, val func loss 1.124926209449768\n",
      "\n",
      "episode 4, val func loss 1.3623011112213135\n",
      "\n",
      "episode 5, val func loss 1.5866622924804688\n",
      "\n",
      "episode 6, val func loss 1.5051909685134888\n",
      "\n",
      "episode 7, val func loss 1.1295123100280762\n",
      "\n",
      "episode 8, val func loss 1.4550442695617676\n",
      "\n",
      "episode 9, val func loss 1.336377739906311\n",
      "\n",
      "episode 10, val func loss 1.4098765850067139\n",
      "\n",
      "episode 11, val func loss 1.104353427886963\n",
      "\n",
      "episode 12, val func loss 1.274495005607605\n",
      "\n",
      "episode 13, val func loss 1.2967934608459473\n",
      "\n",
      "episode 14, val func loss 1.447512149810791\n",
      "\n",
      "episode 15, val func loss 1.1581804752349854\n",
      "\n",
      "episode 16, val func loss 1.5782543420791626\n",
      "\n",
      "Val func train loss in epoch 9:1.336287546902895\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.21194589138031\n",
      "\n",
      "episode 2, val func loss 1.1058082580566406\n",
      "\n",
      "episode 3, val func loss 1.3157563209533691\n",
      "\n",
      "episode 4, val func loss 1.3244330883026123\n",
      "\n",
      "episode 5, val func loss 1.309693455696106\n",
      "\n",
      "episode 6, val func loss 1.1809459924697876\n",
      "\n",
      "episode 7, val func loss 1.4080913066864014\n",
      "\n",
      "episode 8, val func loss 1.5065685510635376\n",
      "\n",
      "episode 9, val func loss 1.6606740951538086\n",
      "\n",
      "episode 10, val func loss 1.2118439674377441\n",
      "\n",
      "episode 11, val func loss 1.3828459978103638\n",
      "\n",
      "episode 12, val func loss 1.4068679809570312\n",
      "\n",
      "episode 13, val func loss 1.3743709325790405\n",
      "\n",
      "episode 14, val func loss 1.4195245504379272\n",
      "\n",
      "episode 15, val func loss 1.3225781917572021\n",
      "\n",
      "episode 16, val func loss 1.436354637145996\n",
      "\n",
      "Val func train loss in epoch 10:1.3486439511179924\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.2405673265457153\n",
      "\n",
      "episode 2, val func loss 1.501576542854309\n",
      "\n",
      "episode 3, val func loss 1.3094680309295654\n",
      "\n",
      "episode 4, val func loss 1.1902881860733032\n",
      "\n",
      "episode 5, val func loss 1.2949893474578857\n",
      "\n",
      "episode 6, val func loss 1.6265896558761597\n",
      "\n",
      "episode 7, val func loss 1.5886001586914062\n",
      "\n",
      "episode 8, val func loss 1.2749742269515991\n",
      "\n",
      "episode 9, val func loss 1.4681404829025269\n",
      "\n",
      "episode 10, val func loss 1.3810203075408936\n",
      "\n",
      "episode 11, val func loss 1.4337828159332275\n",
      "\n",
      "episode 12, val func loss 1.5604294538497925\n",
      "\n",
      "episode 13, val func loss 1.2087494134902954\n",
      "\n",
      "episode 14, val func loss 1.3070729970932007\n",
      "\n",
      "episode 15, val func loss 1.2196972370147705\n",
      "\n",
      "episode 16, val func loss 1.3716269731521606\n",
      "\n",
      "Val func train loss in epoch 11:1.3735983222723007\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.616963267326355\n",
      "\n",
      "episode 2, val func loss 1.4131888151168823\n",
      "\n",
      "episode 3, val func loss 1.2650704383850098\n",
      "\n",
      "episode 4, val func loss 1.3883607387542725\n",
      "\n",
      "episode 5, val func loss 1.1974453926086426\n",
      "\n",
      "episode 6, val func loss 1.3692817687988281\n",
      "\n",
      "episode 7, val func loss 1.2865251302719116\n",
      "\n",
      "episode 8, val func loss 1.3304226398468018\n",
      "\n",
      "episode 9, val func loss 1.303682565689087\n",
      "\n",
      "episode 10, val func loss 1.2186187505722046\n",
      "\n",
      "episode 11, val func loss 1.2662969827651978\n",
      "\n",
      "episode 12, val func loss 1.547060489654541\n",
      "\n",
      "episode 13, val func loss 1.2248847484588623\n",
      "\n",
      "episode 14, val func loss 1.3197458982467651\n",
      "\n",
      "episode 15, val func loss 1.2229338884353638\n",
      "\n",
      "episode 16, val func loss 1.4198505878448486\n",
      "\n",
      "Val func train loss in epoch 12:1.3368957564234734\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.1796348094940186\n",
      "\n",
      "episode 2, val func loss 1.2128090858459473\n",
      "\n",
      "episode 3, val func loss 1.3051261901855469\n",
      "\n",
      "episode 4, val func loss 1.4756938219070435\n",
      "\n",
      "episode 5, val func loss 1.2345433235168457\n",
      "\n",
      "episode 6, val func loss 1.2729568481445312\n",
      "\n",
      "episode 7, val func loss 1.3007022142410278\n",
      "\n",
      "episode 8, val func loss 1.575282096862793\n",
      "\n",
      "episode 9, val func loss 1.6434930562973022\n",
      "\n",
      "episode 10, val func loss 1.416434645652771\n",
      "\n",
      "episode 11, val func loss 1.3513106107711792\n",
      "\n",
      "episode 12, val func loss 1.125991702079773\n",
      "\n",
      "episode 13, val func loss 1.095879316329956\n",
      "\n",
      "episode 14, val func loss 1.3844274282455444\n",
      "\n",
      "episode 15, val func loss 1.210655927658081\n",
      "\n",
      "episode 16, val func loss 1.2870138883590698\n",
      "\n",
      "Val func train loss in epoch 13:1.3169971853494644\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.1959168910980225\n",
      "\n",
      "episode 2, val func loss 1.4964945316314697\n",
      "\n",
      "episode 3, val func loss 1.3814688920974731\n",
      "\n",
      "episode 4, val func loss 1.1302125453948975\n",
      "\n",
      "episode 5, val func loss 1.3572373390197754\n",
      "\n",
      "episode 6, val func loss 1.3089709281921387\n",
      "\n",
      "episode 7, val func loss 1.5581804513931274\n",
      "\n",
      "episode 8, val func loss 1.4131426811218262\n",
      "\n",
      "episode 9, val func loss 1.125787615776062\n",
      "\n",
      "episode 10, val func loss 1.0477114915847778\n",
      "\n",
      "episode 11, val func loss 1.3848986625671387\n",
      "\n",
      "episode 12, val func loss 1.2546541690826416\n",
      "\n",
      "episode 13, val func loss 1.2155711650848389\n",
      "\n",
      "episode 14, val func loss 1.2963274717330933\n",
      "\n",
      "episode 15, val func loss 1.198806643486023\n",
      "\n",
      "episode 16, val func loss 1.4008512496948242\n",
      "\n",
      "Val func train loss in epoch 14:1.2978895455598831\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.250835657119751\n",
      "\n",
      "episode 2, val func loss 1.268399715423584\n",
      "\n",
      "episode 3, val func loss 1.1818221807479858\n",
      "\n",
      "episode 4, val func loss 1.2377444505691528\n",
      "\n",
      "episode 5, val func loss 1.2325382232666016\n",
      "\n",
      "episode 6, val func loss 1.0634490251541138\n",
      "\n",
      "episode 7, val func loss 1.3807072639465332\n",
      "\n",
      "episode 8, val func loss 1.4808727502822876\n",
      "\n",
      "episode 9, val func loss 1.3137105703353882\n",
      "\n",
      "episode 10, val func loss 1.31436288356781\n",
      "\n",
      "episode 11, val func loss 1.2253443002700806\n",
      "\n",
      "episode 12, val func loss 1.4376715421676636\n",
      "\n",
      "episode 13, val func loss 1.3636118173599243\n",
      "\n",
      "episode 14, val func loss 1.3367611169815063\n",
      "\n",
      "episode 15, val func loss 1.3628580570220947\n",
      "\n",
      "episode 16, val func loss 1.2343907356262207\n",
      "\n",
      "Val func train loss in epoch 15:1.2928175181150436\n",
      "***********************TIME WAS 4.809318693478902 min*****************************\n",
      "\n",
      "**********************ROUND 38 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.9540297985076904\n",
      "\n",
      "episode 2, policy loss -2.9540297985076904\n",
      "\n",
      "episode 3, policy loss -2.9540295600891113\n",
      "\n",
      "episode 4, policy loss -2.9540297985076904\n",
      "\n",
      "episode 5, policy loss -2.9540297985076904\n",
      "\n",
      "episode 6, policy loss -2.9540295600891113\n",
      "\n",
      "episode 7, policy loss -2.9540297985076904\n",
      "\n",
      "episode 8, policy loss -2.9540297985076904\n",
      "\n",
      "episode 9, policy loss -2.9540297985076904\n",
      "\n",
      "episode 10, policy loss -2.9540297985076904\n",
      "\n",
      "episode 11, policy loss -2.9540297985076904\n",
      "\n",
      "episode 12, policy loss -2.9540297985076904\n",
      "\n",
      "episode 13, policy loss -2.9540297985076904\n",
      "\n",
      "episode 14, policy loss -2.9540297985076904\n",
      "\n",
      "episode 15, policy loss -2.9540297985076904\n",
      "\n",
      "episode 16, policy loss -2.9540297985076904\n",
      "\n",
      "Policy train loss in epoch 0:-2.954029768705368\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.9540297985076904\n",
      "\n",
      "episode 2, policy loss -2.9540297985076904\n",
      "\n",
      "episode 3, policy loss -2.9540297985076904\n",
      "\n",
      "episode 4, policy loss -2.9540297985076904\n",
      "\n",
      "episode 5, policy loss -2.9540297985076904\n",
      "\n",
      "episode 6, policy loss -2.9540297985076904\n",
      "\n",
      "episode 7, policy loss -2.9540297985076904\n",
      "\n",
      "episode 8, policy loss -2.9540295600891113\n",
      "\n",
      "episode 9, policy loss -2.9540297985076904\n",
      "\n",
      "episode 10, policy loss -2.9540297985076904\n",
      "\n",
      "episode 11, policy loss -2.9540297985076904\n",
      "\n",
      "episode 12, policy loss -2.9540297985076904\n",
      "\n",
      "episode 13, policy loss -2.9540297985076904\n",
      "\n",
      "episode 14, policy loss -2.9540297985076904\n",
      "\n",
      "episode 15, policy loss -2.9540297985076904\n",
      "\n",
      "episode 16, policy loss -2.9540295600891113\n",
      "\n",
      "Policy train loss in epoch 1:-2.954029768705368\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.9540297985076904\n",
      "\n",
      "episode 2, policy loss -2.9540297985076904\n",
      "\n",
      "episode 3, policy loss -2.9540297985076904\n",
      "\n",
      "episode 4, policy loss -2.9540297985076904\n",
      "\n",
      "episode 5, policy loss -2.9540297985076904\n",
      "\n",
      "episode 6, policy loss -2.9540297985076904\n",
      "\n",
      "episode 7, policy loss -2.9540297985076904\n",
      "\n",
      "episode 8, policy loss -2.9540297985076904\n",
      "\n",
      "episode 9, policy loss -2.9540295600891113\n",
      "\n",
      "episode 10, policy loss -2.9540297985076904\n",
      "\n",
      "episode 11, policy loss -2.9540297985076904\n",
      "\n",
      "episode 12, policy loss -2.9540297985076904\n",
      "\n",
      "episode 13, policy loss -2.9540297985076904\n",
      "\n",
      "episode 14, policy loss -2.9540297985076904\n",
      "\n",
      "episode 15, policy loss -2.9540295600891113\n",
      "\n",
      "episode 16, policy loss -2.9540297985076904\n",
      "\n",
      "Policy train loss in epoch 2:-2.954029768705368\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.9540297985076904\n",
      "\n",
      "episode 2, policy loss -2.9540297985076904\n",
      "\n",
      "episode 3, policy loss -2.9540297985076904\n",
      "\n",
      "episode 4, policy loss -2.9540297985076904\n",
      "\n",
      "episode 5, policy loss -2.9540297985076904\n",
      "\n",
      "episode 6, policy loss -2.9540297985076904\n",
      "\n",
      "episode 7, policy loss -2.9540295600891113\n",
      "\n",
      "episode 8, policy loss -2.9540297985076904\n",
      "\n",
      "episode 9, policy loss -2.9540297985076904\n",
      "\n",
      "episode 10, policy loss -2.9540297985076904\n",
      "\n",
      "episode 11, policy loss -2.9540297985076904\n",
      "\n",
      "episode 12, policy loss -2.9540297985076904\n",
      "\n",
      "episode 13, policy loss -2.9540297985076904\n",
      "\n",
      "episode 14, policy loss -2.9540295600891113\n",
      "\n",
      "episode 15, policy loss -2.9540297985076904\n",
      "\n",
      "episode 16, policy loss -2.9540297985076904\n",
      "\n",
      "Policy train loss in epoch 3:-2.954029768705368\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.5335547924041748\n",
      "\n",
      "episode 2, val func loss 1.2589255571365356\n",
      "\n",
      "episode 3, val func loss 1.4130632877349854\n",
      "\n",
      "episode 4, val func loss 1.1709386110305786\n",
      "\n",
      "episode 5, val func loss 1.5844042301177979\n",
      "\n",
      "episode 6, val func loss 1.3573533296585083\n",
      "\n",
      "episode 7, val func loss 1.296482801437378\n",
      "\n",
      "episode 8, val func loss 1.4057163000106812\n",
      "\n",
      "episode 9, val func loss 1.1905025243759155\n",
      "\n",
      "episode 10, val func loss 1.3621801137924194\n",
      "\n",
      "episode 11, val func loss 1.236573576927185\n",
      "\n",
      "episode 12, val func loss 1.1836559772491455\n",
      "\n",
      "episode 13, val func loss 1.2069575786590576\n",
      "\n",
      "episode 14, val func loss 1.3480224609375\n",
      "\n",
      "episode 15, val func loss 1.286574363708496\n",
      "\n",
      "episode 16, val func loss 1.079763650894165\n",
      "\n",
      "Val func train loss in epoch 0:1.3071668222546577\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.3123879432678223\n",
      "\n",
      "episode 2, val func loss 1.0863875150680542\n",
      "\n",
      "episode 3, val func loss 1.2206507921218872\n",
      "\n",
      "episode 4, val func loss 1.442781925201416\n",
      "\n",
      "episode 5, val func loss 1.112094521522522\n",
      "\n",
      "episode 6, val func loss 1.344970941543579\n",
      "\n",
      "episode 7, val func loss 1.3243834972381592\n",
      "\n",
      "episode 8, val func loss 1.3948358297348022\n",
      "\n",
      "episode 9, val func loss 1.1624886989593506\n",
      "\n",
      "episode 10, val func loss 1.439832329750061\n",
      "\n",
      "episode 11, val func loss 1.3650639057159424\n",
      "\n",
      "episode 12, val func loss 1.4241806268692017\n",
      "\n",
      "episode 13, val func loss 1.2731010913848877\n",
      "\n",
      "episode 14, val func loss 1.3555514812469482\n",
      "\n",
      "episode 15, val func loss 1.3819185495376587\n",
      "\n",
      "episode 16, val func loss 1.2429932355880737\n",
      "\n",
      "Val func train loss in epoch 1:1.3052264302968979\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.342950463294983\n",
      "\n",
      "episode 2, val func loss 1.311422348022461\n",
      "\n",
      "episode 3, val func loss 1.187193512916565\n",
      "\n",
      "episode 4, val func loss 1.4163410663604736\n",
      "\n",
      "episode 5, val func loss 1.4235787391662598\n",
      "\n",
      "episode 6, val func loss 1.3719260692596436\n",
      "\n",
      "episode 7, val func loss 1.3547319173812866\n",
      "\n",
      "episode 8, val func loss 1.2013617753982544\n",
      "\n",
      "episode 9, val func loss 1.2162572145462036\n",
      "\n",
      "episode 10, val func loss 1.4025534391403198\n",
      "\n",
      "episode 11, val func loss 1.0861401557922363\n",
      "\n",
      "episode 12, val func loss 1.3673591613769531\n",
      "\n",
      "episode 13, val func loss 1.631932020187378\n",
      "\n",
      "episode 14, val func loss 1.3940423727035522\n",
      "\n",
      "episode 15, val func loss 1.3911229372024536\n",
      "\n",
      "episode 16, val func loss 1.062729835510254\n",
      "\n",
      "Val func train loss in epoch 2:1.3226026892662048\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.2969861030578613\n",
      "\n",
      "episode 2, val func loss 1.2499552965164185\n",
      "\n",
      "episode 3, val func loss 1.2711917161941528\n",
      "\n",
      "episode 4, val func loss 1.331719160079956\n",
      "\n",
      "episode 5, val func loss 1.5374938249588013\n",
      "\n",
      "episode 6, val func loss 1.3213698863983154\n",
      "\n",
      "episode 7, val func loss 1.2972792387008667\n",
      "\n",
      "episode 8, val func loss 1.4627370834350586\n",
      "\n",
      "episode 9, val func loss 1.4034777879714966\n",
      "\n",
      "episode 10, val func loss 1.4351009130477905\n",
      "\n",
      "episode 11, val func loss 1.2167937755584717\n",
      "\n",
      "episode 12, val func loss 1.2887719869613647\n",
      "\n",
      "episode 13, val func loss 1.5005297660827637\n",
      "\n",
      "episode 14, val func loss 1.5866295099258423\n",
      "\n",
      "episode 15, val func loss 1.411705732345581\n",
      "\n",
      "episode 16, val func loss 1.3223960399627686\n",
      "\n",
      "Val func train loss in epoch 3:1.3708836138248444\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.4231493473052979\n",
      "\n",
      "episode 2, val func loss 1.2117441892623901\n",
      "\n",
      "episode 3, val func loss 1.0496491193771362\n",
      "\n",
      "episode 4, val func loss 1.3768086433410645\n",
      "\n",
      "episode 5, val func loss 1.140467882156372\n",
      "\n",
      "episode 6, val func loss 1.3960167169570923\n",
      "\n",
      "episode 7, val func loss 1.485070824623108\n",
      "\n",
      "episode 8, val func loss 1.4414137601852417\n",
      "\n",
      "episode 9, val func loss 1.1059566736221313\n",
      "\n",
      "episode 10, val func loss 1.257999062538147\n",
      "\n",
      "episode 11, val func loss 1.3978033065795898\n",
      "\n",
      "episode 12, val func loss 1.4666060209274292\n",
      "\n",
      "episode 13, val func loss 1.2582919597625732\n",
      "\n",
      "episode 14, val func loss 1.1854848861694336\n",
      "\n",
      "episode 15, val func loss 1.562490701675415\n",
      "\n",
      "episode 16, val func loss 1.3547078371047974\n",
      "\n",
      "Val func train loss in epoch 4:1.3196038082242012\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.3257975578308105\n",
      "\n",
      "episode 2, val func loss 1.4445406198501587\n",
      "\n",
      "episode 3, val func loss 1.1466573476791382\n",
      "\n",
      "episode 4, val func loss 1.396628737449646\n",
      "\n",
      "episode 5, val func loss 1.2280112504959106\n",
      "\n",
      "episode 6, val func loss 1.2287036180496216\n",
      "\n",
      "episode 7, val func loss 1.468942403793335\n",
      "\n",
      "episode 8, val func loss 1.255483865737915\n",
      "\n",
      "episode 9, val func loss 1.219712495803833\n",
      "\n",
      "episode 10, val func loss 1.1547044515609741\n",
      "\n",
      "episode 11, val func loss 1.3217453956604004\n",
      "\n",
      "episode 12, val func loss 1.2730486392974854\n",
      "\n",
      "episode 13, val func loss 1.29616379737854\n",
      "\n",
      "episode 14, val func loss 1.4206401109695435\n",
      "\n",
      "episode 15, val func loss 1.2178847789764404\n",
      "\n",
      "episode 16, val func loss 1.3665155172348022\n",
      "\n",
      "Val func train loss in epoch 5:1.2978237867355347\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.0920077562332153\n",
      "\n",
      "episode 2, val func loss 1.5422544479370117\n",
      "\n",
      "episode 3, val func loss 1.2949376106262207\n",
      "\n",
      "episode 4, val func loss 1.3234505653381348\n",
      "\n",
      "episode 5, val func loss 1.4535276889801025\n",
      "\n",
      "episode 6, val func loss 1.4308955669403076\n",
      "\n",
      "episode 7, val func loss 1.4145299196243286\n",
      "\n",
      "episode 8, val func loss 1.55540931224823\n",
      "\n",
      "episode 9, val func loss 1.260573148727417\n",
      "\n",
      "episode 10, val func loss 1.224768042564392\n",
      "\n",
      "episode 11, val func loss 1.3506174087524414\n",
      "\n",
      "episode 12, val func loss 1.229189157485962\n",
      "\n",
      "episode 13, val func loss 1.4396400451660156\n",
      "\n",
      "episode 14, val func loss 1.3858073949813843\n",
      "\n",
      "episode 15, val func loss 0.9396664500236511\n",
      "\n",
      "episode 16, val func loss 1.2418066263198853\n",
      "\n",
      "Val func train loss in epoch 6:1.3236925713717937\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.314197063446045\n",
      "\n",
      "episode 2, val func loss 1.258692979812622\n",
      "\n",
      "episode 3, val func loss 1.3822195529937744\n",
      "\n",
      "episode 4, val func loss 1.3357698917388916\n",
      "\n",
      "episode 5, val func loss 1.2833737134933472\n",
      "\n",
      "episode 6, val func loss 1.3147826194763184\n",
      "\n",
      "episode 7, val func loss 1.1895538568496704\n",
      "\n",
      "episode 8, val func loss 1.09571373462677\n",
      "\n",
      "episode 9, val func loss 1.195610523223877\n",
      "\n",
      "episode 10, val func loss 1.2698041200637817\n",
      "\n",
      "episode 11, val func loss 1.1686471700668335\n",
      "\n",
      "episode 12, val func loss 1.5774015188217163\n",
      "\n",
      "episode 13, val func loss 1.294975996017456\n",
      "\n",
      "episode 14, val func loss 1.4478363990783691\n",
      "\n",
      "episode 15, val func loss 1.4400634765625\n",
      "\n",
      "episode 16, val func loss 1.50899338722229\n",
      "\n",
      "Val func train loss in epoch 7:1.3173522502183914\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.4652529954910278\n",
      "\n",
      "episode 2, val func loss 1.0862219333648682\n",
      "\n",
      "episode 3, val func loss 1.3865572214126587\n",
      "\n",
      "episode 4, val func loss 1.5959970951080322\n",
      "\n",
      "episode 5, val func loss 1.4060769081115723\n",
      "\n",
      "episode 6, val func loss 1.3525463342666626\n",
      "\n",
      "episode 7, val func loss 1.2299158573150635\n",
      "\n",
      "episode 8, val func loss 1.358054518699646\n",
      "\n",
      "episode 9, val func loss 1.470740795135498\n",
      "\n",
      "episode 10, val func loss 1.2503688335418701\n",
      "\n",
      "episode 11, val func loss 1.3548344373703003\n",
      "\n",
      "episode 12, val func loss 1.3148417472839355\n",
      "\n",
      "episode 13, val func loss 1.2524032592773438\n",
      "\n",
      "episode 14, val func loss 1.4581892490386963\n",
      "\n",
      "episode 15, val func loss 1.2917290925979614\n",
      "\n",
      "episode 16, val func loss 1.4911563396453857\n",
      "\n",
      "Val func train loss in epoch 8:1.3603054136037827\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.3232145309448242\n",
      "\n",
      "episode 2, val func loss 1.375745415687561\n",
      "\n",
      "episode 3, val func loss 1.3061509132385254\n",
      "\n",
      "episode 4, val func loss 1.5597245693206787\n",
      "\n",
      "episode 5, val func loss 1.2278574705123901\n",
      "\n",
      "episode 6, val func loss 1.4191681146621704\n",
      "\n",
      "episode 7, val func loss 1.3104045391082764\n",
      "\n",
      "episode 8, val func loss 1.3615481853485107\n",
      "\n",
      "episode 9, val func loss 1.1575888395309448\n",
      "\n",
      "episode 10, val func loss 1.3688098192214966\n",
      "\n",
      "episode 11, val func loss 1.1768428087234497\n",
      "\n",
      "episode 12, val func loss 1.5131556987762451\n",
      "\n",
      "episode 13, val func loss 1.6346473693847656\n",
      "\n",
      "episode 14, val func loss 1.3146860599517822\n",
      "\n",
      "episode 15, val func loss 1.3236573934555054\n",
      "\n",
      "episode 16, val func loss 1.19334077835083\n",
      "\n",
      "Val func train loss in epoch 9:1.3479089066386223\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.3626853227615356\n",
      "\n",
      "episode 2, val func loss 1.3716033697128296\n",
      "\n",
      "episode 3, val func loss 1.446038007736206\n",
      "\n",
      "episode 4, val func loss 1.1939862966537476\n",
      "\n",
      "episode 5, val func loss 1.378943681716919\n",
      "\n",
      "episode 6, val func loss 1.3022819757461548\n",
      "\n",
      "episode 7, val func loss 1.2868152856826782\n",
      "\n",
      "episode 8, val func loss 1.424269676208496\n",
      "\n",
      "episode 9, val func loss 1.395042896270752\n",
      "\n",
      "episode 10, val func loss 1.281913161277771\n",
      "\n",
      "episode 11, val func loss 1.3133862018585205\n",
      "\n",
      "episode 12, val func loss 1.3412822484970093\n",
      "\n",
      "episode 13, val func loss 1.2559584379196167\n",
      "\n",
      "episode 14, val func loss 1.3223440647125244\n",
      "\n",
      "episode 15, val func loss 1.2719227075576782\n",
      "\n",
      "episode 16, val func loss 1.1885732412338257\n",
      "\n",
      "Val func train loss in epoch 10:1.3210654109716415\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.4413625001907349\n",
      "\n",
      "episode 2, val func loss 1.3586602210998535\n",
      "\n",
      "episode 3, val func loss 1.2372173070907593\n",
      "\n",
      "episode 4, val func loss 1.2454235553741455\n",
      "\n",
      "episode 5, val func loss 1.2694963216781616\n",
      "\n",
      "episode 6, val func loss 1.3800348043441772\n",
      "\n",
      "episode 7, val func loss 1.491295576095581\n",
      "\n",
      "episode 8, val func loss 1.4061113595962524\n",
      "\n",
      "episode 9, val func loss 1.3523876667022705\n",
      "\n",
      "episode 10, val func loss 1.1764776706695557\n",
      "\n",
      "episode 11, val func loss 1.3687713146209717\n",
      "\n",
      "episode 12, val func loss 1.3579164743423462\n",
      "\n",
      "episode 13, val func loss 1.0816539525985718\n",
      "\n",
      "episode 14, val func loss 1.260084629058838\n",
      "\n",
      "episode 15, val func loss 1.4345927238464355\n",
      "\n",
      "episode 16, val func loss 1.6177514791488647\n",
      "\n",
      "Val func train loss in epoch 11:1.342452347278595\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.2753050327301025\n",
      "\n",
      "episode 2, val func loss 1.4323339462280273\n",
      "\n",
      "episode 3, val func loss 1.1431468725204468\n",
      "\n",
      "episode 4, val func loss 1.5152579545974731\n",
      "\n",
      "episode 5, val func loss 1.3526158332824707\n",
      "\n",
      "episode 6, val func loss 1.3697917461395264\n",
      "\n",
      "episode 7, val func loss 1.430643081665039\n",
      "\n",
      "episode 8, val func loss 1.1643366813659668\n",
      "\n",
      "episode 9, val func loss 1.2982370853424072\n",
      "\n",
      "episode 10, val func loss 1.2471342086791992\n",
      "\n",
      "episode 11, val func loss 1.3650270700454712\n",
      "\n",
      "episode 12, val func loss 1.1980491876602173\n",
      "\n",
      "episode 13, val func loss 1.2798731327056885\n",
      "\n",
      "episode 14, val func loss 1.3904101848602295\n",
      "\n",
      "episode 15, val func loss 1.2024333477020264\n",
      "\n",
      "episode 16, val func loss 1.2102246284484863\n",
      "\n",
      "Val func train loss in epoch 12:1.3046762496232986\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.1696577072143555\n",
      "\n",
      "episode 2, val func loss 1.5415469408035278\n",
      "\n",
      "episode 3, val func loss 1.2520568370819092\n",
      "\n",
      "episode 4, val func loss 1.1647189855575562\n",
      "\n",
      "episode 5, val func loss 1.3285061120986938\n",
      "\n",
      "episode 6, val func loss 1.350536823272705\n",
      "\n",
      "episode 7, val func loss 1.3473434448242188\n",
      "\n",
      "episode 8, val func loss 1.2707483768463135\n",
      "\n",
      "episode 9, val func loss 1.3573498725891113\n",
      "\n",
      "episode 10, val func loss 1.3116474151611328\n",
      "\n",
      "episode 11, val func loss 1.518110990524292\n",
      "\n",
      "episode 12, val func loss 1.3045825958251953\n",
      "\n",
      "episode 13, val func loss 1.4650709629058838\n",
      "\n",
      "episode 14, val func loss 1.4375560283660889\n",
      "\n",
      "episode 15, val func loss 1.5267726182937622\n",
      "\n",
      "episode 16, val func loss 1.19465172290802\n",
      "\n",
      "Val func train loss in epoch 13:1.3463035896420479\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.5514888763427734\n",
      "\n",
      "episode 2, val func loss 1.352593183517456\n",
      "\n",
      "episode 3, val func loss 1.2266547679901123\n",
      "\n",
      "episode 4, val func loss 1.2537413835525513\n",
      "\n",
      "episode 5, val func loss 1.2444173097610474\n",
      "\n",
      "episode 6, val func loss 1.3461337089538574\n",
      "\n",
      "episode 7, val func loss 1.2663936614990234\n",
      "\n",
      "episode 8, val func loss 1.300240397453308\n",
      "\n",
      "episode 9, val func loss 1.3883267641067505\n",
      "\n",
      "episode 10, val func loss 1.4930108785629272\n",
      "\n",
      "episode 11, val func loss 1.5691659450531006\n",
      "\n",
      "episode 12, val func loss 1.319996953010559\n",
      "\n",
      "episode 13, val func loss 1.2979490756988525\n",
      "\n",
      "episode 14, val func loss 1.3870875835418701\n",
      "\n",
      "episode 15, val func loss 1.1251906156539917\n",
      "\n",
      "episode 16, val func loss 1.3132835626602173\n",
      "\n",
      "Val func train loss in epoch 14:1.3397296667099\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.2884842157363892\n",
      "\n",
      "episode 2, val func loss 1.2726057767868042\n",
      "\n",
      "episode 3, val func loss 1.3814105987548828\n",
      "\n",
      "episode 4, val func loss 1.2379964590072632\n",
      "\n",
      "episode 5, val func loss 1.4425197839736938\n",
      "\n",
      "episode 6, val func loss 1.4618380069732666\n",
      "\n",
      "episode 7, val func loss 1.422526478767395\n",
      "\n",
      "episode 8, val func loss 1.256217122077942\n",
      "\n",
      "episode 9, val func loss 1.5086121559143066\n",
      "\n",
      "episode 10, val func loss 1.4644235372543335\n",
      "\n",
      "episode 11, val func loss 1.5501666069030762\n",
      "\n",
      "episode 12, val func loss 1.2808051109313965\n",
      "\n",
      "episode 13, val func loss 1.413740873336792\n",
      "\n",
      "episode 14, val func loss 1.5442172288894653\n",
      "\n",
      "episode 15, val func loss 1.442038893699646\n",
      "\n",
      "episode 16, val func loss 1.4082573652267456\n",
      "\n",
      "Val func train loss in epoch 15:1.3984912633895874\n",
      "***********************TIME WAS 4.812597942352295 min*****************************\n",
      "\n",
      "**********************ROUND 39 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.072815418243408\n",
      "\n",
      "episode 2, policy loss -3.072815418243408\n",
      "\n",
      "episode 3, policy loss -3.072815418243408\n",
      "\n",
      "episode 4, policy loss -3.072815418243408\n",
      "\n",
      "episode 5, policy loss -3.072815418243408\n",
      "\n",
      "episode 6, policy loss -3.072815418243408\n",
      "\n",
      "episode 7, policy loss -3.072815418243408\n",
      "\n",
      "episode 8, policy loss -3.072815418243408\n",
      "\n",
      "episode 9, policy loss -3.072815418243408\n",
      "\n",
      "episode 10, policy loss -3.072815418243408\n",
      "\n",
      "episode 11, policy loss -3.072815418243408\n",
      "\n",
      "episode 12, policy loss -3.072815418243408\n",
      "\n",
      "episode 13, policy loss -3.072815418243408\n",
      "\n",
      "episode 14, policy loss -3.072815418243408\n",
      "\n",
      "episode 15, policy loss -3.072815418243408\n",
      "\n",
      "episode 16, policy loss -3.072815418243408\n",
      "\n",
      "Policy train loss in epoch 0:-3.072815418243408\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.072815418243408\n",
      "\n",
      "episode 2, policy loss -3.072815418243408\n",
      "\n",
      "episode 3, policy loss -3.072815418243408\n",
      "\n",
      "episode 4, policy loss -3.072815418243408\n",
      "\n",
      "episode 5, policy loss -3.072815418243408\n",
      "\n",
      "episode 6, policy loss -3.072815418243408\n",
      "\n",
      "episode 7, policy loss -3.072815418243408\n",
      "\n",
      "episode 8, policy loss -3.072815418243408\n",
      "\n",
      "episode 9, policy loss -3.072815418243408\n",
      "\n",
      "episode 10, policy loss -3.072815418243408\n",
      "\n",
      "episode 11, policy loss -3.072815418243408\n",
      "\n",
      "episode 12, policy loss -3.072815418243408\n",
      "\n",
      "episode 13, policy loss -3.072815418243408\n",
      "\n",
      "episode 14, policy loss -3.072815418243408\n",
      "\n",
      "episode 15, policy loss -3.072815418243408\n",
      "\n",
      "episode 16, policy loss -3.072815418243408\n",
      "\n",
      "Policy train loss in epoch 1:-3.072815418243408\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.072815418243408\n",
      "\n",
      "episode 2, policy loss -3.072815418243408\n",
      "\n",
      "episode 3, policy loss -3.072815418243408\n",
      "\n",
      "episode 4, policy loss -3.072815418243408\n",
      "\n",
      "episode 5, policy loss -3.072815418243408\n",
      "\n",
      "episode 6, policy loss -3.072815418243408\n",
      "\n",
      "episode 7, policy loss -3.072815418243408\n",
      "\n",
      "episode 8, policy loss -3.072815418243408\n",
      "\n",
      "episode 9, policy loss -3.072815418243408\n",
      "\n",
      "episode 10, policy loss -3.072815418243408\n",
      "\n",
      "episode 11, policy loss -3.072815418243408\n",
      "\n",
      "episode 12, policy loss -3.072815418243408\n",
      "\n",
      "episode 13, policy loss -3.072815418243408\n",
      "\n",
      "episode 14, policy loss -3.072815418243408\n",
      "\n",
      "episode 15, policy loss -3.072815418243408\n",
      "\n",
      "episode 16, policy loss -3.072815418243408\n",
      "\n",
      "Policy train loss in epoch 2:-3.072815418243408\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.072815418243408\n",
      "\n",
      "episode 2, policy loss -3.072815418243408\n",
      "\n",
      "episode 3, policy loss -3.072815418243408\n",
      "\n",
      "episode 4, policy loss -3.072815418243408\n",
      "\n",
      "episode 5, policy loss -3.072815418243408\n",
      "\n",
      "episode 6, policy loss -3.072815418243408\n",
      "\n",
      "episode 7, policy loss -3.072815418243408\n",
      "\n",
      "episode 8, policy loss -3.072815418243408\n",
      "\n",
      "episode 9, policy loss -3.072815418243408\n",
      "\n",
      "episode 10, policy loss -3.072815418243408\n",
      "\n",
      "episode 11, policy loss -3.072815418243408\n",
      "\n",
      "episode 12, policy loss -3.072815418243408\n",
      "\n",
      "episode 13, policy loss -3.072815418243408\n",
      "\n",
      "episode 14, policy loss -3.072815418243408\n",
      "\n",
      "episode 15, policy loss -3.072815418243408\n",
      "\n",
      "episode 16, policy loss -3.072815418243408\n",
      "\n",
      "Policy train loss in epoch 3:-3.072815418243408\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.414197564125061\n",
      "\n",
      "episode 2, val func loss 1.1976463794708252\n",
      "\n",
      "episode 3, val func loss 1.4881455898284912\n",
      "\n",
      "episode 4, val func loss 1.4239336252212524\n",
      "\n",
      "episode 5, val func loss 1.408316731452942\n",
      "\n",
      "episode 6, val func loss 1.3339014053344727\n",
      "\n",
      "episode 7, val func loss 1.341648817062378\n",
      "\n",
      "episode 8, val func loss 1.3577525615692139\n",
      "\n",
      "episode 9, val func loss 1.301859974861145\n",
      "\n",
      "episode 10, val func loss 1.2725766897201538\n",
      "\n",
      "episode 11, val func loss 1.2387852668762207\n",
      "\n",
      "episode 12, val func loss 1.5141459703445435\n",
      "\n",
      "episode 13, val func loss 1.2366784811019897\n",
      "\n",
      "episode 14, val func loss 1.3429489135742188\n",
      "\n",
      "episode 15, val func loss 1.2788771390914917\n",
      "\n",
      "episode 16, val func loss 1.5115573406219482\n",
      "\n",
      "Val func train loss in epoch 0:1.3539357781410217\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.2337640523910522\n",
      "\n",
      "episode 2, val func loss 1.4099349975585938\n",
      "\n",
      "episode 3, val func loss 1.1943793296813965\n",
      "\n",
      "episode 4, val func loss 1.3141634464263916\n",
      "\n",
      "episode 5, val func loss 1.2963050603866577\n",
      "\n",
      "episode 6, val func loss 1.148701786994934\n",
      "\n",
      "episode 7, val func loss 1.401387333869934\n",
      "\n",
      "episode 8, val func loss 1.4266149997711182\n",
      "\n",
      "episode 9, val func loss 1.3983051776885986\n",
      "\n",
      "episode 10, val func loss 1.4513170719146729\n",
      "\n",
      "episode 11, val func loss 1.185569405555725\n",
      "\n",
      "episode 12, val func loss 1.2508577108383179\n",
      "\n",
      "episode 13, val func loss 1.20147705078125\n",
      "\n",
      "episode 14, val func loss 1.2604583501815796\n",
      "\n",
      "episode 15, val func loss 1.334708333015442\n",
      "\n",
      "episode 16, val func loss 1.4549579620361328\n",
      "\n",
      "Val func train loss in epoch 1:1.3101813793182373\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.508121371269226\n",
      "\n",
      "episode 2, val func loss 1.3423322439193726\n",
      "\n",
      "episode 3, val func loss 1.1849161386489868\n",
      "\n",
      "episode 4, val func loss 1.1225385665893555\n",
      "\n",
      "episode 5, val func loss 1.3741527795791626\n",
      "\n",
      "episode 6, val func loss 1.1691793203353882\n",
      "\n",
      "episode 7, val func loss 1.1182312965393066\n",
      "\n",
      "episode 8, val func loss 1.2836862802505493\n",
      "\n",
      "episode 9, val func loss 1.2670021057128906\n",
      "\n",
      "episode 10, val func loss 1.43500816822052\n",
      "\n",
      "episode 11, val func loss 1.411826491355896\n",
      "\n",
      "episode 12, val func loss 1.278016448020935\n",
      "\n",
      "episode 13, val func loss 1.3356069326400757\n",
      "\n",
      "episode 14, val func loss 1.557824730873108\n",
      "\n",
      "episode 15, val func loss 1.3170448541641235\n",
      "\n",
      "episode 16, val func loss 1.3171591758728027\n",
      "\n",
      "Val func train loss in epoch 2:1.3139154314994812\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.3283995389938354\n",
      "\n",
      "episode 2, val func loss 1.362998366355896\n",
      "\n",
      "episode 3, val func loss 1.4906160831451416\n",
      "\n",
      "episode 4, val func loss 1.2545841932296753\n",
      "\n",
      "episode 5, val func loss 1.3211719989776611\n",
      "\n",
      "episode 6, val func loss 1.2636865377426147\n",
      "\n",
      "episode 7, val func loss 1.2174153327941895\n",
      "\n",
      "episode 8, val func loss 1.3563798666000366\n",
      "\n",
      "episode 9, val func loss 1.0506768226623535\n",
      "\n",
      "episode 10, val func loss 1.2457842826843262\n",
      "\n",
      "episode 11, val func loss 1.4349020719528198\n",
      "\n",
      "episode 12, val func loss 1.5497524738311768\n",
      "\n",
      "episode 13, val func loss 1.4252192974090576\n",
      "\n",
      "episode 14, val func loss 1.2694531679153442\n",
      "\n",
      "episode 15, val func loss 1.2892459630966187\n",
      "\n",
      "episode 16, val func loss 1.3465733528137207\n",
      "\n",
      "Val func train loss in epoch 3:1.3254287093877792\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.2938624620437622\n",
      "\n",
      "episode 2, val func loss 1.3889060020446777\n",
      "\n",
      "episode 3, val func loss 1.3666672706604004\n",
      "\n",
      "episode 4, val func loss 1.1743168830871582\n",
      "\n",
      "episode 5, val func loss 1.219355583190918\n",
      "\n",
      "episode 6, val func loss 1.2123706340789795\n",
      "\n",
      "episode 7, val func loss 1.4563132524490356\n",
      "\n",
      "episode 8, val func loss 1.432092308998108\n",
      "\n",
      "episode 9, val func loss 1.3107666969299316\n",
      "\n",
      "episode 10, val func loss 1.607885479927063\n",
      "\n",
      "episode 11, val func loss 1.2111306190490723\n",
      "\n",
      "episode 12, val func loss 1.0957659482955933\n",
      "\n",
      "episode 13, val func loss 1.593420147895813\n",
      "\n",
      "episode 14, val func loss 1.465309500694275\n",
      "\n",
      "episode 15, val func loss 1.4405254125595093\n",
      "\n",
      "episode 16, val func loss 1.4463189840316772\n",
      "\n",
      "Val func train loss in epoch 4:1.3571879491209984\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.3880321979522705\n",
      "\n",
      "episode 2, val func loss 1.494153618812561\n",
      "\n",
      "episode 3, val func loss 1.082834243774414\n",
      "\n",
      "episode 4, val func loss 1.5006743669509888\n",
      "\n",
      "episode 5, val func loss 1.3234676122665405\n",
      "\n",
      "episode 6, val func loss 1.4742989540100098\n",
      "\n",
      "episode 7, val func loss 1.2669172286987305\n",
      "\n",
      "episode 8, val func loss 1.2805708646774292\n",
      "\n",
      "episode 9, val func loss 1.3990561962127686\n",
      "\n",
      "episode 10, val func loss 1.3070422410964966\n",
      "\n",
      "episode 11, val func loss 1.3374221324920654\n",
      "\n",
      "episode 12, val func loss 1.4043022394180298\n",
      "\n",
      "episode 13, val func loss 1.3085745573043823\n",
      "\n",
      "episode 14, val func loss 1.4701893329620361\n",
      "\n",
      "episode 15, val func loss 1.4422334432601929\n",
      "\n",
      "episode 16, val func loss 1.2046066522598267\n",
      "\n",
      "Val func train loss in epoch 5:1.3552734926342964\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.1609270572662354\n",
      "\n",
      "episode 2, val func loss 1.6997123956680298\n",
      "\n",
      "episode 3, val func loss 1.4069794416427612\n",
      "\n",
      "episode 4, val func loss 1.4048646688461304\n",
      "\n",
      "episode 5, val func loss 1.466260313987732\n",
      "\n",
      "episode 6, val func loss 1.2871938943862915\n",
      "\n",
      "episode 7, val func loss 1.1087090969085693\n",
      "\n",
      "episode 8, val func loss 1.1559209823608398\n",
      "\n",
      "episode 9, val func loss 1.3707133531570435\n",
      "\n",
      "episode 10, val func loss 1.253078579902649\n",
      "\n",
      "episode 11, val func loss 1.334153652191162\n",
      "\n",
      "episode 12, val func loss 1.332537293434143\n",
      "\n",
      "episode 13, val func loss 1.256129264831543\n",
      "\n",
      "episode 14, val func loss 1.3473962545394897\n",
      "\n",
      "episode 15, val func loss 1.4624229669570923\n",
      "\n",
      "episode 16, val func loss 1.3572235107421875\n",
      "\n",
      "Val func train loss in epoch 6:1.3377639204263687\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.2989897727966309\n",
      "\n",
      "episode 2, val func loss 1.4175975322723389\n",
      "\n",
      "episode 3, val func loss 1.199436902999878\n",
      "\n",
      "episode 4, val func loss 1.4879721403121948\n",
      "\n",
      "episode 5, val func loss 1.2969104051589966\n",
      "\n",
      "episode 6, val func loss 1.2651818990707397\n",
      "\n",
      "episode 7, val func loss 1.1628165245056152\n",
      "\n",
      "episode 8, val func loss 1.145591378211975\n",
      "\n",
      "episode 9, val func loss 1.4065020084381104\n",
      "\n",
      "episode 10, val func loss 1.5369049310684204\n",
      "\n",
      "episode 11, val func loss 1.214374303817749\n",
      "\n",
      "episode 12, val func loss 1.2914447784423828\n",
      "\n",
      "episode 13, val func loss 1.4626448154449463\n",
      "\n",
      "episode 14, val func loss 1.2507178783416748\n",
      "\n",
      "episode 15, val func loss 1.2316440343856812\n",
      "\n",
      "episode 16, val func loss 1.1402478218078613\n",
      "\n",
      "Val func train loss in epoch 7:1.3005610704421997\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.040523648262024\n",
      "\n",
      "episode 2, val func loss 1.3846830129623413\n",
      "\n",
      "episode 3, val func loss 1.4151370525360107\n",
      "\n",
      "episode 4, val func loss 1.3131917715072632\n",
      "\n",
      "episode 5, val func loss 1.3074501752853394\n",
      "\n",
      "episode 6, val func loss 1.2155787944793701\n",
      "\n",
      "episode 7, val func loss 1.3841204643249512\n",
      "\n",
      "episode 8, val func loss 1.3989737033843994\n",
      "\n",
      "episode 9, val func loss 1.3118282556533813\n",
      "\n",
      "episode 10, val func loss 1.3793270587921143\n",
      "\n",
      "episode 11, val func loss 1.4074807167053223\n",
      "\n",
      "episode 12, val func loss 1.1570395231246948\n",
      "\n",
      "episode 13, val func loss 1.4276219606399536\n",
      "\n",
      "episode 14, val func loss 1.4231631755828857\n",
      "\n",
      "episode 15, val func loss 1.3447308540344238\n",
      "\n",
      "episode 16, val func loss 1.2014080286026\n",
      "\n",
      "Val func train loss in epoch 8:1.3195161372423172\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.3720718622207642\n",
      "\n",
      "episode 2, val func loss 1.4339886903762817\n",
      "\n",
      "episode 3, val func loss 1.339684247970581\n",
      "\n",
      "episode 4, val func loss 1.2907490730285645\n",
      "\n",
      "episode 5, val func loss 1.4321986436843872\n",
      "\n",
      "episode 6, val func loss 1.4416550397872925\n",
      "\n",
      "episode 7, val func loss 1.4626755714416504\n",
      "\n",
      "episode 8, val func loss 1.336881399154663\n",
      "\n",
      "episode 9, val func loss 1.3220311403274536\n",
      "\n",
      "episode 10, val func loss 1.3835232257843018\n",
      "\n",
      "episode 11, val func loss 1.4748103618621826\n",
      "\n",
      "episode 12, val func loss 1.4896013736724854\n",
      "\n",
      "episode 13, val func loss 1.2459368705749512\n",
      "\n",
      "episode 14, val func loss 1.394949197769165\n",
      "\n",
      "episode 15, val func loss 1.3524469137191772\n",
      "\n",
      "episode 16, val func loss 1.224858045578003\n",
      "\n",
      "Val func train loss in epoch 9:1.374878853559494\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.4224399328231812\n",
      "\n",
      "episode 2, val func loss 1.4632169008255005\n",
      "\n",
      "episode 3, val func loss 1.6236788034439087\n",
      "\n",
      "episode 4, val func loss 1.1889197826385498\n",
      "\n",
      "episode 5, val func loss 1.3687183856964111\n",
      "\n",
      "episode 6, val func loss 1.3788645267486572\n",
      "\n",
      "episode 7, val func loss 1.4060791730880737\n",
      "\n",
      "episode 8, val func loss 1.3309564590454102\n",
      "\n",
      "episode 9, val func loss 1.3981157541275024\n",
      "\n",
      "episode 10, val func loss 1.2946726083755493\n",
      "\n",
      "episode 11, val func loss 1.516432523727417\n",
      "\n",
      "episode 12, val func loss 1.3718699216842651\n",
      "\n",
      "episode 13, val func loss 1.346520185470581\n",
      "\n",
      "episode 14, val func loss 1.4577372074127197\n",
      "\n",
      "episode 15, val func loss 1.294575572013855\n",
      "\n",
      "episode 16, val func loss 1.065198302268982\n",
      "\n",
      "Val func train loss in epoch 10:1.3704997524619102\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.3518891334533691\n",
      "\n",
      "episode 2, val func loss 1.2083709239959717\n",
      "\n",
      "episode 3, val func loss 1.457370400428772\n",
      "\n",
      "episode 4, val func loss 1.1281144618988037\n",
      "\n",
      "episode 5, val func loss 1.4548671245574951\n",
      "\n",
      "episode 6, val func loss 1.2602427005767822\n",
      "\n",
      "episode 7, val func loss 1.2348544597625732\n",
      "\n",
      "episode 8, val func loss 1.2459720373153687\n",
      "\n",
      "episode 9, val func loss 1.437925934791565\n",
      "\n",
      "episode 10, val func loss 1.2517606019973755\n",
      "\n",
      "episode 11, val func loss 1.2117409706115723\n",
      "\n",
      "episode 12, val func loss 1.2203407287597656\n",
      "\n",
      "episode 13, val func loss 1.192399263381958\n",
      "\n",
      "episode 14, val func loss 1.2909677028656006\n",
      "\n",
      "episode 15, val func loss 1.3149863481521606\n",
      "\n",
      "episode 16, val func loss 1.3824094533920288\n",
      "\n",
      "Val func train loss in epoch 11:1.2902632653713226\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.4835186004638672\n",
      "\n",
      "episode 2, val func loss 1.5421125888824463\n",
      "\n",
      "episode 3, val func loss 1.3786357641220093\n",
      "\n",
      "episode 4, val func loss 1.1606860160827637\n",
      "\n",
      "episode 5, val func loss 1.5251535177230835\n",
      "\n",
      "episode 6, val func loss 1.41524076461792\n",
      "\n",
      "episode 7, val func loss 1.4680815935134888\n",
      "\n",
      "episode 8, val func loss 1.4026305675506592\n",
      "\n",
      "episode 9, val func loss 1.5253262519836426\n",
      "\n",
      "episode 10, val func loss 1.5082557201385498\n",
      "\n",
      "episode 11, val func loss 1.469443678855896\n",
      "\n",
      "episode 12, val func loss 1.4692987203598022\n",
      "\n",
      "episode 13, val func loss 1.224326729774475\n",
      "\n",
      "episode 14, val func loss 1.1652199029922485\n",
      "\n",
      "episode 15, val func loss 1.5990755558013916\n",
      "\n",
      "episode 16, val func loss 1.4662721157073975\n",
      "\n",
      "Val func train loss in epoch 12:1.4252048805356026\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.3216243982315063\n",
      "\n",
      "episode 2, val func loss 1.474418044090271\n",
      "\n",
      "episode 3, val func loss 1.4246248006820679\n",
      "\n",
      "episode 4, val func loss 1.4209790229797363\n",
      "\n",
      "episode 5, val func loss 1.2822338342666626\n",
      "\n",
      "episode 6, val func loss 1.4920480251312256\n",
      "\n",
      "episode 7, val func loss 1.1097673177719116\n",
      "\n",
      "episode 8, val func loss 1.4590338468551636\n",
      "\n",
      "episode 9, val func loss 1.3815803527832031\n",
      "\n",
      "episode 10, val func loss 1.3898323774337769\n",
      "\n",
      "episode 11, val func loss 1.5176823139190674\n",
      "\n",
      "episode 12, val func loss 1.3633239269256592\n",
      "\n",
      "episode 13, val func loss 1.3105370998382568\n",
      "\n",
      "episode 14, val func loss 1.1786808967590332\n",
      "\n",
      "episode 15, val func loss 1.1703253984451294\n",
      "\n",
      "episode 16, val func loss 1.1690224409103394\n",
      "\n",
      "Val func train loss in epoch 13:1.3416071310639381\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.439475417137146\n",
      "\n",
      "episode 2, val func loss 1.1186646223068237\n",
      "\n",
      "episode 3, val func loss 1.19175386428833\n",
      "\n",
      "episode 4, val func loss 1.444776177406311\n",
      "\n",
      "episode 5, val func loss 1.4143710136413574\n",
      "\n",
      "episode 6, val func loss 1.2420154809951782\n",
      "\n",
      "episode 7, val func loss 1.0012518167495728\n",
      "\n",
      "episode 8, val func loss 1.2667412757873535\n",
      "\n",
      "episode 9, val func loss 1.4091767072677612\n",
      "\n",
      "episode 10, val func loss 1.4893192052841187\n",
      "\n",
      "episode 11, val func loss 1.1121461391448975\n",
      "\n",
      "episode 12, val func loss 1.4897613525390625\n",
      "\n",
      "episode 13, val func loss 1.3730924129486084\n",
      "\n",
      "episode 14, val func loss 1.3678333759307861\n",
      "\n",
      "episode 15, val func loss 1.4468375444412231\n",
      "\n",
      "episode 16, val func loss 1.49346923828125\n",
      "\n",
      "Val func train loss in epoch 14:1.3312928527593613\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.3114192485809326\n",
      "\n",
      "episode 2, val func loss 1.1336206197738647\n",
      "\n",
      "episode 3, val func loss 1.3438067436218262\n",
      "\n",
      "episode 4, val func loss 1.3577653169631958\n",
      "\n",
      "episode 5, val func loss 1.3077492713928223\n",
      "\n",
      "episode 6, val func loss 1.3492902517318726\n",
      "\n",
      "episode 7, val func loss 1.2322888374328613\n",
      "\n",
      "episode 8, val func loss 1.4145561456680298\n",
      "\n",
      "episode 9, val func loss 1.1271880865097046\n",
      "\n",
      "episode 10, val func loss 1.2024070024490356\n",
      "\n",
      "episode 11, val func loss 1.4512293338775635\n",
      "\n",
      "episode 12, val func loss 1.2666419744491577\n",
      "\n",
      "episode 13, val func loss 1.249738335609436\n",
      "\n",
      "episode 14, val func loss 1.4964221715927124\n",
      "\n",
      "episode 15, val func loss 1.4648195505142212\n",
      "\n",
      "episode 16, val func loss 1.4929256439208984\n",
      "\n",
      "Val func train loss in epoch 15:1.3251167833805084\n",
      "***********************TIME WAS 4.809207475185394 min*****************************\n",
      "\n",
      "**********************ROUND 40 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.0088889598846436\n",
      "\n",
      "episode 2, policy loss -3.0088889598846436\n",
      "\n",
      "episode 3, policy loss -3.0088889598846436\n",
      "\n",
      "episode 4, policy loss -3.0088889598846436\n",
      "\n",
      "episode 5, policy loss -3.0088889598846436\n",
      "\n",
      "episode 6, policy loss -3.0088889598846436\n",
      "\n",
      "episode 7, policy loss -3.0088889598846436\n",
      "\n",
      "episode 8, policy loss -3.0088889598846436\n",
      "\n",
      "episode 9, policy loss -3.0088889598846436\n",
      "\n",
      "episode 10, policy loss -3.0088889598846436\n",
      "\n",
      "episode 11, policy loss -3.0088889598846436\n",
      "\n",
      "episode 12, policy loss -3.0088889598846436\n",
      "\n",
      "episode 13, policy loss -3.0088889598846436\n",
      "\n",
      "episode 14, policy loss -3.0088889598846436\n",
      "\n",
      "episode 15, policy loss -3.0088889598846436\n",
      "\n",
      "episode 16, policy loss -3.0088889598846436\n",
      "\n",
      "Policy train loss in epoch 0:-3.0088889598846436\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.0088889598846436\n",
      "\n",
      "episode 2, policy loss -3.0088889598846436\n",
      "\n",
      "episode 3, policy loss -3.0088889598846436\n",
      "\n",
      "episode 4, policy loss -3.0088889598846436\n",
      "\n",
      "episode 5, policy loss -3.0088889598846436\n",
      "\n",
      "episode 6, policy loss -3.0088889598846436\n",
      "\n",
      "episode 7, policy loss -3.0088889598846436\n",
      "\n",
      "episode 8, policy loss -3.0088889598846436\n",
      "\n",
      "episode 9, policy loss -3.0088889598846436\n",
      "\n",
      "episode 10, policy loss -3.0088889598846436\n",
      "\n",
      "episode 11, policy loss -3.0088889598846436\n",
      "\n",
      "episode 12, policy loss -3.0088889598846436\n",
      "\n",
      "episode 13, policy loss -3.0088889598846436\n",
      "\n",
      "episode 14, policy loss -3.0088889598846436\n",
      "\n",
      "episode 15, policy loss -3.0088889598846436\n",
      "\n",
      "episode 16, policy loss -3.0088889598846436\n",
      "\n",
      "Policy train loss in epoch 1:-3.0088889598846436\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.0088889598846436\n",
      "\n",
      "episode 2, policy loss -3.0088889598846436\n",
      "\n",
      "episode 3, policy loss -3.0088889598846436\n",
      "\n",
      "episode 4, policy loss -3.0088889598846436\n",
      "\n",
      "episode 5, policy loss -3.0088889598846436\n",
      "\n",
      "episode 6, policy loss -3.0088889598846436\n",
      "\n",
      "episode 7, policy loss -3.0088889598846436\n",
      "\n",
      "episode 8, policy loss -3.0088889598846436\n",
      "\n",
      "episode 9, policy loss -3.0088889598846436\n",
      "\n",
      "episode 10, policy loss -3.0088889598846436\n",
      "\n",
      "episode 11, policy loss -3.0088889598846436\n",
      "\n",
      "episode 12, policy loss -3.0088889598846436\n",
      "\n",
      "episode 13, policy loss -3.0088889598846436\n",
      "\n",
      "episode 14, policy loss -3.0088889598846436\n",
      "\n",
      "episode 15, policy loss -3.0088889598846436\n",
      "\n",
      "episode 16, policy loss -3.0088889598846436\n",
      "\n",
      "Policy train loss in epoch 2:-3.0088889598846436\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.0088889598846436\n",
      "\n",
      "episode 2, policy loss -3.0088889598846436\n",
      "\n",
      "episode 3, policy loss -3.0088889598846436\n",
      "\n",
      "episode 4, policy loss -3.0088889598846436\n",
      "\n",
      "episode 5, policy loss -3.0088889598846436\n",
      "\n",
      "episode 6, policy loss -3.0088889598846436\n",
      "\n",
      "episode 7, policy loss -3.0088889598846436\n",
      "\n",
      "episode 8, policy loss -3.0088889598846436\n",
      "\n",
      "episode 9, policy loss -3.0088889598846436\n",
      "\n",
      "episode 10, policy loss -3.0088889598846436\n",
      "\n",
      "episode 11, policy loss -3.0088889598846436\n",
      "\n",
      "episode 12, policy loss -3.0088889598846436\n",
      "\n",
      "episode 13, policy loss -3.0088889598846436\n",
      "\n",
      "episode 14, policy loss -3.0088889598846436\n",
      "\n",
      "episode 15, policy loss -3.0088889598846436\n",
      "\n",
      "episode 16, policy loss -3.0088889598846436\n",
      "\n",
      "Policy train loss in epoch 3:-3.0088889598846436\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.4460029602050781\n",
      "\n",
      "episode 2, val func loss 1.3980411291122437\n",
      "\n",
      "episode 3, val func loss 1.2061774730682373\n",
      "\n",
      "episode 4, val func loss 1.2570278644561768\n",
      "\n",
      "episode 5, val func loss 1.1452847719192505\n",
      "\n",
      "episode 6, val func loss 1.237674355506897\n",
      "\n",
      "episode 7, val func loss 1.3330249786376953\n",
      "\n",
      "episode 8, val func loss 1.4237381219863892\n",
      "\n",
      "episode 9, val func loss 1.3795135021209717\n",
      "\n",
      "episode 10, val func loss 1.6037044525146484\n",
      "\n",
      "episode 11, val func loss 1.4538040161132812\n",
      "\n",
      "episode 12, val func loss 1.3731688261032104\n",
      "\n",
      "episode 13, val func loss 1.264647364616394\n",
      "\n",
      "episode 14, val func loss 1.248763918876648\n",
      "\n",
      "episode 15, val func loss 1.2117996215820312\n",
      "\n",
      "episode 16, val func loss 1.3740707635879517\n",
      "\n",
      "Val func train loss in epoch 0:1.334777757525444\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.341335415840149\n",
      "\n",
      "episode 2, val func loss 1.2785619497299194\n",
      "\n",
      "episode 3, val func loss 1.3287357091903687\n",
      "\n",
      "episode 4, val func loss 1.5450828075408936\n",
      "\n",
      "episode 5, val func loss 1.3441280126571655\n",
      "\n",
      "episode 6, val func loss 1.177769660949707\n",
      "\n",
      "episode 7, val func loss 1.4467254877090454\n",
      "\n",
      "episode 8, val func loss 1.1603163480758667\n",
      "\n",
      "episode 9, val func loss 1.2400834560394287\n",
      "\n",
      "episode 10, val func loss 1.560416340827942\n",
      "\n",
      "episode 11, val func loss 1.2278484106063843\n",
      "\n",
      "episode 12, val func loss 1.2722227573394775\n",
      "\n",
      "episode 13, val func loss 1.3892711400985718\n",
      "\n",
      "episode 14, val func loss 0.9961121678352356\n",
      "\n",
      "episode 15, val func loss 1.5185986757278442\n",
      "\n",
      "episode 16, val func loss 1.5855563879013062\n",
      "\n",
      "Val func train loss in epoch 1:1.3382977955043316\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.2556402683258057\n",
      "\n",
      "episode 2, val func loss 1.2799773216247559\n",
      "\n",
      "episode 3, val func loss 1.4267784357070923\n",
      "\n",
      "episode 4, val func loss 1.3523356914520264\n",
      "\n",
      "episode 5, val func loss 1.3552266359329224\n",
      "\n",
      "episode 6, val func loss 1.2973145246505737\n",
      "\n",
      "episode 7, val func loss 1.3932712078094482\n",
      "\n",
      "episode 8, val func loss 1.4574034214019775\n",
      "\n",
      "episode 9, val func loss 1.285768985748291\n",
      "\n",
      "episode 10, val func loss 1.1913654804229736\n",
      "\n",
      "episode 11, val func loss 1.2852814197540283\n",
      "\n",
      "episode 12, val func loss 1.2142333984375\n",
      "\n",
      "episode 13, val func loss 1.4623314142227173\n",
      "\n",
      "episode 14, val func loss 1.581626534461975\n",
      "\n",
      "episode 15, val func loss 1.375044345855713\n",
      "\n",
      "episode 16, val func loss 1.3128830194473267\n",
      "\n",
      "Val func train loss in epoch 2:1.3454051315784454\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.177588939666748\n",
      "\n",
      "episode 2, val func loss 1.373212218284607\n",
      "\n",
      "episode 3, val func loss 1.3260685205459595\n",
      "\n",
      "episode 4, val func loss 1.259557843208313\n",
      "\n",
      "episode 5, val func loss 1.2232557535171509\n",
      "\n",
      "episode 6, val func loss 1.3191732168197632\n",
      "\n",
      "episode 7, val func loss 1.3952980041503906\n",
      "\n",
      "episode 8, val func loss 1.287453532218933\n",
      "\n",
      "episode 9, val func loss 1.4496791362762451\n",
      "\n",
      "episode 10, val func loss 1.4532843828201294\n",
      "\n",
      "episode 11, val func loss 1.3131765127182007\n",
      "\n",
      "episode 12, val func loss 1.1865336894989014\n",
      "\n",
      "episode 13, val func loss 1.0506260395050049\n",
      "\n",
      "episode 14, val func loss 1.6712251901626587\n",
      "\n",
      "episode 15, val func loss 1.1307085752487183\n",
      "\n",
      "episode 16, val func loss 1.3342137336730957\n",
      "\n",
      "Val func train loss in epoch 3:1.3094409555196762\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.158958077430725\n",
      "\n",
      "episode 2, val func loss 1.3654582500457764\n",
      "\n",
      "episode 3, val func loss 1.3713836669921875\n",
      "\n",
      "episode 4, val func loss 1.452821969985962\n",
      "\n",
      "episode 5, val func loss 1.2866954803466797\n",
      "\n",
      "episode 6, val func loss 1.59121835231781\n",
      "\n",
      "episode 7, val func loss 1.4454286098480225\n",
      "\n",
      "episode 8, val func loss 1.338651418685913\n",
      "\n",
      "episode 9, val func loss 1.35793936252594\n",
      "\n",
      "episode 10, val func loss 1.3381390571594238\n",
      "\n",
      "episode 11, val func loss 1.50613534450531\n",
      "\n",
      "episode 12, val func loss 1.1473191976547241\n",
      "\n",
      "episode 13, val func loss 1.1340304613113403\n",
      "\n",
      "episode 14, val func loss 1.3090745210647583\n",
      "\n",
      "episode 15, val func loss 1.3367209434509277\n",
      "\n",
      "episode 16, val func loss 1.1192715167999268\n",
      "\n",
      "Val func train loss in epoch 4:1.3287028893828392\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.135198712348938\n",
      "\n",
      "episode 2, val func loss 1.3983432054519653\n",
      "\n",
      "episode 3, val func loss 1.4234685897827148\n",
      "\n",
      "episode 4, val func loss 1.270958423614502\n",
      "\n",
      "episode 5, val func loss 1.1395567655563354\n",
      "\n",
      "episode 6, val func loss 1.3927421569824219\n",
      "\n",
      "episode 7, val func loss 1.2013827562332153\n",
      "\n",
      "episode 8, val func loss 1.3185268640518188\n",
      "\n",
      "episode 9, val func loss 1.2041021585464478\n",
      "\n",
      "episode 10, val func loss 1.453473687171936\n",
      "\n",
      "episode 11, val func loss 1.161788821220398\n",
      "\n",
      "episode 12, val func loss 1.5472997426986694\n",
      "\n",
      "episode 13, val func loss 1.3563724756240845\n",
      "\n",
      "episode 14, val func loss 1.2295918464660645\n",
      "\n",
      "episode 15, val func loss 1.3029711246490479\n",
      "\n",
      "episode 16, val func loss 1.1827236413955688\n",
      "\n",
      "Val func train loss in epoch 5:1.294906310737133\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.247506022453308\n",
      "\n",
      "episode 2, val func loss 1.5199583768844604\n",
      "\n",
      "episode 3, val func loss 1.4422622919082642\n",
      "\n",
      "episode 4, val func loss 1.3050503730773926\n",
      "\n",
      "episode 5, val func loss 1.2401494979858398\n",
      "\n",
      "episode 6, val func loss 1.2177060842514038\n",
      "\n",
      "episode 7, val func loss 1.4466254711151123\n",
      "\n",
      "episode 8, val func loss 1.4660327434539795\n",
      "\n",
      "episode 9, val func loss 1.3668701648712158\n",
      "\n",
      "episode 10, val func loss 1.2367523908615112\n",
      "\n",
      "episode 11, val func loss 1.4208602905273438\n",
      "\n",
      "episode 12, val func loss 1.426703929901123\n",
      "\n",
      "episode 13, val func loss 1.5331194400787354\n",
      "\n",
      "episode 14, val func loss 1.3736029863357544\n",
      "\n",
      "episode 15, val func loss 1.468514323234558\n",
      "\n",
      "episode 16, val func loss 1.2031363248825073\n",
      "\n",
      "Val func train loss in epoch 6:1.3696781694889069\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.5020900964736938\n",
      "\n",
      "episode 2, val func loss 1.3434972763061523\n",
      "\n",
      "episode 3, val func loss 1.397545576095581\n",
      "\n",
      "episode 4, val func loss 1.4654027223587036\n",
      "\n",
      "episode 5, val func loss 1.4282985925674438\n",
      "\n",
      "episode 6, val func loss 1.1895593404769897\n",
      "\n",
      "episode 7, val func loss 1.3325717449188232\n",
      "\n",
      "episode 8, val func loss 1.4144095182418823\n",
      "\n",
      "episode 9, val func loss 1.2498456239700317\n",
      "\n",
      "episode 10, val func loss 1.2571648359298706\n",
      "\n",
      "episode 11, val func loss 1.2944145202636719\n",
      "\n",
      "episode 12, val func loss 1.331632375717163\n",
      "\n",
      "episode 13, val func loss 1.230175256729126\n",
      "\n",
      "episode 14, val func loss 1.4060438871383667\n",
      "\n",
      "episode 15, val func loss 1.2980079650878906\n",
      "\n",
      "episode 16, val func loss 1.226348638534546\n",
      "\n",
      "Val func train loss in epoch 7:1.335437998175621\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.5231852531433105\n",
      "\n",
      "episode 2, val func loss 1.224804401397705\n",
      "\n",
      "episode 3, val func loss 1.3809220790863037\n",
      "\n",
      "episode 4, val func loss 1.4697916507720947\n",
      "\n",
      "episode 5, val func loss 1.4359298944473267\n",
      "\n",
      "episode 6, val func loss 1.3901174068450928\n",
      "\n",
      "episode 7, val func loss 1.2814464569091797\n",
      "\n",
      "episode 8, val func loss 1.211229681968689\n",
      "\n",
      "episode 9, val func loss 1.3924249410629272\n",
      "\n",
      "episode 10, val func loss 1.5429528951644897\n",
      "\n",
      "episode 11, val func loss 1.226725697517395\n",
      "\n",
      "episode 12, val func loss 1.2235798835754395\n",
      "\n",
      "episode 13, val func loss 1.4020529985427856\n",
      "\n",
      "episode 14, val func loss 1.3349988460540771\n",
      "\n",
      "episode 15, val func loss 1.2891534566879272\n",
      "\n",
      "episode 16, val func loss 1.364801287651062\n",
      "\n",
      "Val func train loss in epoch 8:1.3558823019266129\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.3304566144943237\n",
      "\n",
      "episode 2, val func loss 1.3922258615493774\n",
      "\n",
      "episode 3, val func loss 1.7977062463760376\n",
      "\n",
      "episode 4, val func loss 1.3927628993988037\n",
      "\n",
      "episode 5, val func loss 1.3717174530029297\n",
      "\n",
      "episode 6, val func loss 1.196316123008728\n",
      "\n",
      "episode 7, val func loss 1.5428016185760498\n",
      "\n",
      "episode 8, val func loss 1.3445587158203125\n",
      "\n",
      "episode 9, val func loss 1.3547085523605347\n",
      "\n",
      "episode 10, val func loss 1.3279268741607666\n",
      "\n",
      "episode 11, val func loss 1.378138780593872\n",
      "\n",
      "episode 12, val func loss 1.3281710147857666\n",
      "\n",
      "episode 13, val func loss 1.4341092109680176\n",
      "\n",
      "episode 14, val func loss 1.2073930501937866\n",
      "\n",
      "episode 15, val func loss 1.2302166223526\n",
      "\n",
      "episode 16, val func loss 1.299818515777588\n",
      "\n",
      "Val func train loss in epoch 9:1.3705642595887184\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.2817986011505127\n",
      "\n",
      "episode 2, val func loss 1.336883783340454\n",
      "\n",
      "episode 3, val func loss 1.393315076828003\n",
      "\n",
      "episode 4, val func loss 1.253199577331543\n",
      "\n",
      "episode 5, val func loss 1.2326160669326782\n",
      "\n",
      "episode 6, val func loss 1.3528701066970825\n",
      "\n",
      "episode 7, val func loss 1.2871283292770386\n",
      "\n",
      "episode 8, val func loss 1.2291224002838135\n",
      "\n",
      "episode 9, val func loss 1.4195060729980469\n",
      "\n",
      "episode 10, val func loss 1.4095940589904785\n",
      "\n",
      "episode 11, val func loss 1.2964634895324707\n",
      "\n",
      "episode 12, val func loss 1.2064487934112549\n",
      "\n",
      "episode 13, val func loss 1.2325302362442017\n",
      "\n",
      "episode 14, val func loss 1.3507448434829712\n",
      "\n",
      "episode 15, val func loss 1.2164398431777954\n",
      "\n",
      "episode 16, val func loss 1.1165471076965332\n",
      "\n",
      "Val func train loss in epoch 10:1.2884505242109299\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.3214656114578247\n",
      "\n",
      "episode 2, val func loss 1.4404751062393188\n",
      "\n",
      "episode 3, val func loss 1.1293898820877075\n",
      "\n",
      "episode 4, val func loss 1.4367105960845947\n",
      "\n",
      "episode 5, val func loss 1.262281060218811\n",
      "\n",
      "episode 6, val func loss 1.3498408794403076\n",
      "\n",
      "episode 7, val func loss 1.1930326223373413\n",
      "\n",
      "episode 8, val func loss 1.3708326816558838\n",
      "\n",
      "episode 9, val func loss 1.4020559787750244\n",
      "\n",
      "episode 10, val func loss 1.4698442220687866\n",
      "\n",
      "episode 11, val func loss 1.3048299551010132\n",
      "\n",
      "episode 12, val func loss 1.3876945972442627\n",
      "\n",
      "episode 13, val func loss 1.45099675655365\n",
      "\n",
      "episode 14, val func loss 1.2300536632537842\n",
      "\n",
      "episode 15, val func loss 1.4404571056365967\n",
      "\n",
      "episode 16, val func loss 1.2545874118804932\n",
      "\n",
      "Val func train loss in epoch 11:1.3402842581272125\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.356123685836792\n",
      "\n",
      "episode 2, val func loss 1.3535192012786865\n",
      "\n",
      "episode 3, val func loss 1.3320680856704712\n",
      "\n",
      "episode 4, val func loss 1.340732455253601\n",
      "\n",
      "episode 5, val func loss 1.3198901414871216\n",
      "\n",
      "episode 6, val func loss 1.0768775939941406\n",
      "\n",
      "episode 7, val func loss 1.3083577156066895\n",
      "\n",
      "episode 8, val func loss 1.42747163772583\n",
      "\n",
      "episode 9, val func loss 1.3371062278747559\n",
      "\n",
      "episode 10, val func loss 1.3945893049240112\n",
      "\n",
      "episode 11, val func loss 1.1727041006088257\n",
      "\n",
      "episode 12, val func loss 1.1035847663879395\n",
      "\n",
      "episode 13, val func loss 1.3497768640518188\n",
      "\n",
      "episode 14, val func loss 1.4481451511383057\n",
      "\n",
      "episode 15, val func loss 1.2929998636245728\n",
      "\n",
      "episode 16, val func loss 1.339167594909668\n",
      "\n",
      "Val func train loss in epoch 12:1.3095696493983269\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.4241552352905273\n",
      "\n",
      "episode 2, val func loss 1.4111480712890625\n",
      "\n",
      "episode 3, val func loss 1.2272893190383911\n",
      "\n",
      "episode 4, val func loss 1.1902568340301514\n",
      "\n",
      "episode 5, val func loss 1.2358944416046143\n",
      "\n",
      "episode 6, val func loss 1.2767566442489624\n",
      "\n",
      "episode 7, val func loss 1.2611654996871948\n",
      "\n",
      "episode 8, val func loss 1.2562421560287476\n",
      "\n",
      "episode 9, val func loss 1.1130926609039307\n",
      "\n",
      "episode 10, val func loss 1.39394211769104\n",
      "\n",
      "episode 11, val func loss 1.364435076713562\n",
      "\n",
      "episode 12, val func loss 1.3069324493408203\n",
      "\n",
      "episode 13, val func loss 1.5172475576400757\n",
      "\n",
      "episode 14, val func loss 1.2011905908584595\n",
      "\n",
      "episode 15, val func loss 1.3836345672607422\n",
      "\n",
      "episode 16, val func loss 1.2754333019256592\n",
      "\n",
      "Val func train loss in epoch 13:1.3024260327219963\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.2082539796829224\n",
      "\n",
      "episode 2, val func loss 1.191286325454712\n",
      "\n",
      "episode 3, val func loss 1.427499532699585\n",
      "\n",
      "episode 4, val func loss 1.2290294170379639\n",
      "\n",
      "episode 5, val func loss 1.2399581670761108\n",
      "\n",
      "episode 6, val func loss 1.465333104133606\n",
      "\n",
      "episode 7, val func loss 1.3731575012207031\n",
      "\n",
      "episode 8, val func loss 1.2908016443252563\n",
      "\n",
      "episode 9, val func loss 1.3835004568099976\n",
      "\n",
      "episode 10, val func loss 1.3598166704177856\n",
      "\n",
      "episode 11, val func loss 1.1712170839309692\n",
      "\n",
      "episode 12, val func loss 1.3189553022384644\n",
      "\n",
      "episode 13, val func loss 1.2363414764404297\n",
      "\n",
      "episode 14, val func loss 1.1815593242645264\n",
      "\n",
      "episode 15, val func loss 1.1726430654525757\n",
      "\n",
      "episode 16, val func loss 1.39920973777771\n",
      "\n",
      "Val func train loss in epoch 14:1.2905351743102074\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.4741820096969604\n",
      "\n",
      "episode 2, val func loss 1.3219648599624634\n",
      "\n",
      "episode 3, val func loss 1.3943926095962524\n",
      "\n",
      "episode 4, val func loss 1.206398367881775\n",
      "\n",
      "episode 5, val func loss 1.1876189708709717\n",
      "\n",
      "episode 6, val func loss 1.285512089729309\n",
      "\n",
      "episode 7, val func loss 1.4645873308181763\n",
      "\n",
      "episode 8, val func loss 1.3290973901748657\n",
      "\n",
      "episode 9, val func loss 1.2528032064437866\n",
      "\n",
      "episode 10, val func loss 1.30081045627594\n",
      "\n",
      "episode 11, val func loss 1.389145016670227\n",
      "\n",
      "episode 12, val func loss 1.3357582092285156\n",
      "\n",
      "episode 13, val func loss 1.2166615724563599\n",
      "\n",
      "episode 14, val func loss 1.168196439743042\n",
      "\n",
      "episode 15, val func loss 1.3399447202682495\n",
      "\n",
      "episode 16, val func loss 1.2001187801361084\n",
      "\n",
      "Val func train loss in epoch 15:1.3041995018720627\n",
      "***********************TIME WAS 4.809947693347931 min*****************************\n",
      "\n",
      "**********************ROUND 41 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.1065945625305176\n",
      "\n",
      "episode 2, policy loss -3.1065945625305176\n",
      "\n",
      "episode 3, policy loss -3.1065945625305176\n",
      "\n",
      "episode 4, policy loss -3.1065945625305176\n",
      "\n",
      "episode 5, policy loss -3.1065945625305176\n",
      "\n",
      "episode 6, policy loss -3.1065945625305176\n",
      "\n",
      "episode 7, policy loss -3.1065945625305176\n",
      "\n",
      "episode 8, policy loss -3.1065945625305176\n",
      "\n",
      "episode 9, policy loss -3.1065945625305176\n",
      "\n",
      "episode 10, policy loss -3.1065945625305176\n",
      "\n",
      "episode 11, policy loss -3.1065945625305176\n",
      "\n",
      "episode 12, policy loss -3.1065945625305176\n",
      "\n",
      "episode 13, policy loss -3.1065945625305176\n",
      "\n",
      "episode 14, policy loss -3.1065945625305176\n",
      "\n",
      "episode 15, policy loss -3.1065945625305176\n",
      "\n",
      "episode 16, policy loss -3.1065945625305176\n",
      "\n",
      "Policy train loss in epoch 0:-3.1065945625305176\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.1065945625305176\n",
      "\n",
      "episode 2, policy loss -3.1065945625305176\n",
      "\n",
      "episode 3, policy loss -3.1065945625305176\n",
      "\n",
      "episode 4, policy loss -3.1065945625305176\n",
      "\n",
      "episode 5, policy loss -3.1065945625305176\n",
      "\n",
      "episode 6, policy loss -3.1065945625305176\n",
      "\n",
      "episode 7, policy loss -3.1065945625305176\n",
      "\n",
      "episode 8, policy loss -3.1065945625305176\n",
      "\n",
      "episode 9, policy loss -3.1065945625305176\n",
      "\n",
      "episode 10, policy loss -3.1065945625305176\n",
      "\n",
      "episode 11, policy loss -3.1065945625305176\n",
      "\n",
      "episode 12, policy loss -3.1065945625305176\n",
      "\n",
      "episode 13, policy loss -3.1065945625305176\n",
      "\n",
      "episode 14, policy loss -3.1065945625305176\n",
      "\n",
      "episode 15, policy loss -3.1065945625305176\n",
      "\n",
      "episode 16, policy loss -3.1065945625305176\n",
      "\n",
      "Policy train loss in epoch 1:-3.1065945625305176\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.1065945625305176\n",
      "\n",
      "episode 2, policy loss -3.1065945625305176\n",
      "\n",
      "episode 3, policy loss -3.1065945625305176\n",
      "\n",
      "episode 4, policy loss -3.1065945625305176\n",
      "\n",
      "episode 5, policy loss -3.1065945625305176\n",
      "\n",
      "episode 6, policy loss -3.1065945625305176\n",
      "\n",
      "episode 7, policy loss -3.1065945625305176\n",
      "\n",
      "episode 8, policy loss -3.1065945625305176\n",
      "\n",
      "episode 9, policy loss -3.1065945625305176\n",
      "\n",
      "episode 10, policy loss -3.1065945625305176\n",
      "\n",
      "episode 11, policy loss -3.1065945625305176\n",
      "\n",
      "episode 12, policy loss -3.1065945625305176\n",
      "\n",
      "episode 13, policy loss -3.1065945625305176\n",
      "\n",
      "episode 14, policy loss -3.1065945625305176\n",
      "\n",
      "episode 15, policy loss -3.1065945625305176\n",
      "\n",
      "episode 16, policy loss -3.1065945625305176\n",
      "\n",
      "Policy train loss in epoch 2:-3.1065945625305176\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.1065945625305176\n",
      "\n",
      "episode 2, policy loss -3.1065945625305176\n",
      "\n",
      "episode 3, policy loss -3.1065945625305176\n",
      "\n",
      "episode 4, policy loss -3.1065945625305176\n",
      "\n",
      "episode 5, policy loss -3.1065945625305176\n",
      "\n",
      "episode 6, policy loss -3.1065945625305176\n",
      "\n",
      "episode 7, policy loss -3.1065945625305176\n",
      "\n",
      "episode 8, policy loss -3.1065945625305176\n",
      "\n",
      "episode 9, policy loss -3.1065945625305176\n",
      "\n",
      "episode 10, policy loss -3.1065945625305176\n",
      "\n",
      "episode 11, policy loss -3.1065945625305176\n",
      "\n",
      "episode 12, policy loss -3.1065945625305176\n",
      "\n",
      "episode 13, policy loss -3.1065945625305176\n",
      "\n",
      "episode 14, policy loss -3.1065945625305176\n",
      "\n",
      "episode 15, policy loss -3.1065945625305176\n",
      "\n",
      "episode 16, policy loss -3.1065945625305176\n",
      "\n",
      "Policy train loss in epoch 3:-3.1065945625305176\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.4052720069885254\n",
      "\n",
      "episode 2, val func loss 1.3701106309890747\n",
      "\n",
      "episode 3, val func loss 1.2438441514968872\n",
      "\n",
      "episode 4, val func loss 1.3838937282562256\n",
      "\n",
      "episode 5, val func loss 1.4337154626846313\n",
      "\n",
      "episode 6, val func loss 1.4846715927124023\n",
      "\n",
      "episode 7, val func loss 1.3596092462539673\n",
      "\n",
      "episode 8, val func loss 1.2750449180603027\n",
      "\n",
      "episode 9, val func loss 1.1720935106277466\n",
      "\n",
      "episode 10, val func loss 1.3145184516906738\n",
      "\n",
      "episode 11, val func loss 1.3362433910369873\n",
      "\n",
      "episode 12, val func loss 1.215304970741272\n",
      "\n",
      "episode 13, val func loss 1.3074419498443604\n",
      "\n",
      "episode 14, val func loss 1.3555796146392822\n",
      "\n",
      "episode 15, val func loss 1.3385342359542847\n",
      "\n",
      "episode 16, val func loss 1.21604323387146\n",
      "\n",
      "Val func train loss in epoch 0:1.3257450684905052\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.2803899049758911\n",
      "\n",
      "episode 2, val func loss 1.4520492553710938\n",
      "\n",
      "episode 3, val func loss 1.2178022861480713\n",
      "\n",
      "episode 4, val func loss 1.3715085983276367\n",
      "\n",
      "episode 5, val func loss 1.624207615852356\n",
      "\n",
      "episode 6, val func loss 1.210340976715088\n",
      "\n",
      "episode 7, val func loss 1.4714659452438354\n",
      "\n",
      "episode 8, val func loss 1.3356504440307617\n",
      "\n",
      "episode 9, val func loss 1.1865745782852173\n",
      "\n",
      "episode 10, val func loss 1.206992745399475\n",
      "\n",
      "episode 11, val func loss 1.1577814817428589\n",
      "\n",
      "episode 12, val func loss 1.3389467000961304\n",
      "\n",
      "episode 13, val func loss 1.476779580116272\n",
      "\n",
      "episode 14, val func loss 1.5683127641677856\n",
      "\n",
      "episode 15, val func loss 1.1790728569030762\n",
      "\n",
      "episode 16, val func loss 1.2824184894561768\n",
      "\n",
      "Val func train loss in epoch 1:1.3350183889269829\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.389784574508667\n",
      "\n",
      "episode 2, val func loss 1.3094282150268555\n",
      "\n",
      "episode 3, val func loss 1.3672308921813965\n",
      "\n",
      "episode 4, val func loss 1.2572546005249023\n",
      "\n",
      "episode 5, val func loss 1.391310453414917\n",
      "\n",
      "episode 6, val func loss 1.4375889301300049\n",
      "\n",
      "episode 7, val func loss 1.4212387800216675\n",
      "\n",
      "episode 8, val func loss 1.5364608764648438\n",
      "\n",
      "episode 9, val func loss 1.366316556930542\n",
      "\n",
      "episode 10, val func loss 1.2222204208374023\n",
      "\n",
      "episode 11, val func loss 1.253299355506897\n",
      "\n",
      "episode 12, val func loss 1.1296383142471313\n",
      "\n",
      "episode 13, val func loss 1.3979709148406982\n",
      "\n",
      "episode 14, val func loss 1.212376356124878\n",
      "\n",
      "episode 15, val func loss 1.3148776292800903\n",
      "\n",
      "episode 16, val func loss 1.1976464986801147\n",
      "\n",
      "Val func train loss in epoch 2:1.325290210545063\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.4841607809066772\n",
      "\n",
      "episode 2, val func loss 1.2837319374084473\n",
      "\n",
      "episode 3, val func loss 1.335818886756897\n",
      "\n",
      "episode 4, val func loss 1.3332006931304932\n",
      "\n",
      "episode 5, val func loss 1.2012637853622437\n",
      "\n",
      "episode 6, val func loss 1.2983801364898682\n",
      "\n",
      "episode 7, val func loss 1.314955234527588\n",
      "\n",
      "episode 8, val func loss 1.1657480001449585\n",
      "\n",
      "episode 9, val func loss 1.178419589996338\n",
      "\n",
      "episode 10, val func loss 1.2853596210479736\n",
      "\n",
      "episode 11, val func loss 1.4649890661239624\n",
      "\n",
      "episode 12, val func loss 1.336223840713501\n",
      "\n",
      "episode 13, val func loss 1.4097535610198975\n",
      "\n",
      "episode 14, val func loss 1.3555432558059692\n",
      "\n",
      "episode 15, val func loss 1.310292363166809\n",
      "\n",
      "episode 16, val func loss 1.1727516651153564\n",
      "\n",
      "Val func train loss in epoch 3:1.3081620261073112\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.2871556282043457\n",
      "\n",
      "episode 2, val func loss 1.0821954011917114\n",
      "\n",
      "episode 3, val func loss 1.3092278242111206\n",
      "\n",
      "episode 4, val func loss 1.5368660688400269\n",
      "\n",
      "episode 5, val func loss 1.219402551651001\n",
      "\n",
      "episode 6, val func loss 1.1150970458984375\n",
      "\n",
      "episode 7, val func loss 1.3761988878250122\n",
      "\n",
      "episode 8, val func loss 1.3746675252914429\n",
      "\n",
      "episode 9, val func loss 1.4022992849349976\n",
      "\n",
      "episode 10, val func loss 1.346086859703064\n",
      "\n",
      "episode 11, val func loss 1.230252742767334\n",
      "\n",
      "episode 12, val func loss 1.2150391340255737\n",
      "\n",
      "episode 13, val func loss 1.540733814239502\n",
      "\n",
      "episode 14, val func loss 1.3496949672698975\n",
      "\n",
      "episode 15, val func loss 1.396185040473938\n",
      "\n",
      "episode 16, val func loss 1.3200511932373047\n",
      "\n",
      "Val func train loss in epoch 4:1.3188221231102943\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.1719520092010498\n",
      "\n",
      "episode 2, val func loss 1.56086266040802\n",
      "\n",
      "episode 3, val func loss 1.3105576038360596\n",
      "\n",
      "episode 4, val func loss 1.5037399530410767\n",
      "\n",
      "episode 5, val func loss 1.1684924364089966\n",
      "\n",
      "episode 6, val func loss 1.2900676727294922\n",
      "\n",
      "episode 7, val func loss 1.5454752445220947\n",
      "\n",
      "episode 8, val func loss 1.289961814880371\n",
      "\n",
      "episode 9, val func loss 1.3102374076843262\n",
      "\n",
      "episode 10, val func loss 1.390670895576477\n",
      "\n",
      "episode 11, val func loss 1.3733408451080322\n",
      "\n",
      "episode 12, val func loss 1.29584538936615\n",
      "\n",
      "episode 13, val func loss 1.3274648189544678\n",
      "\n",
      "episode 14, val func loss 1.188187837600708\n",
      "\n",
      "episode 15, val func loss 1.1026370525360107\n",
      "\n",
      "episode 16, val func loss 1.2109830379486084\n",
      "\n",
      "Val func train loss in epoch 5:1.3150297924876213\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.3528175354003906\n",
      "\n",
      "episode 2, val func loss 1.2864022254943848\n",
      "\n",
      "episode 3, val func loss 1.1924233436584473\n",
      "\n",
      "episode 4, val func loss 1.484389305114746\n",
      "\n",
      "episode 5, val func loss 1.2408674955368042\n",
      "\n",
      "episode 6, val func loss 1.30380380153656\n",
      "\n",
      "episode 7, val func loss 1.1693181991577148\n",
      "\n",
      "episode 8, val func loss 1.2546355724334717\n",
      "\n",
      "episode 9, val func loss 1.2642369270324707\n",
      "\n",
      "episode 10, val func loss 1.2131644487380981\n",
      "\n",
      "episode 11, val func loss 1.2084258794784546\n",
      "\n",
      "episode 12, val func loss 1.3753471374511719\n",
      "\n",
      "episode 13, val func loss 1.476826548576355\n",
      "\n",
      "episode 14, val func loss 1.487861156463623\n",
      "\n",
      "episode 15, val func loss 1.3902393579483032\n",
      "\n",
      "episode 16, val func loss 1.3661174774169922\n",
      "\n",
      "Val func train loss in epoch 6:1.3166797757148743\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.230160117149353\n",
      "\n",
      "episode 2, val func loss 1.258254051208496\n",
      "\n",
      "episode 3, val func loss 1.4513554573059082\n",
      "\n",
      "episode 4, val func loss 1.1956332921981812\n",
      "\n",
      "episode 5, val func loss 1.3650106191635132\n",
      "\n",
      "episode 6, val func loss 1.2760270833969116\n",
      "\n",
      "episode 7, val func loss 1.2689323425292969\n",
      "\n",
      "episode 8, val func loss 1.3099071979522705\n",
      "\n",
      "episode 9, val func loss 1.3910177946090698\n",
      "\n",
      "episode 10, val func loss 1.1945990324020386\n",
      "\n",
      "episode 11, val func loss 1.4657161235809326\n",
      "\n",
      "episode 12, val func loss 1.3279451131820679\n",
      "\n",
      "episode 13, val func loss 1.2857881784439087\n",
      "\n",
      "episode 14, val func loss 1.263094425201416\n",
      "\n",
      "episode 15, val func loss 1.2380846738815308\n",
      "\n",
      "episode 16, val func loss 1.2466380596160889\n",
      "\n",
      "Val func train loss in epoch 7:1.2980102226138115\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.4840096235275269\n",
      "\n",
      "episode 2, val func loss 1.3008769750595093\n",
      "\n",
      "episode 3, val func loss 1.4852633476257324\n",
      "\n",
      "episode 4, val func loss 1.2036538124084473\n",
      "\n",
      "episode 5, val func loss 1.4734432697296143\n",
      "\n",
      "episode 6, val func loss 1.243503451347351\n",
      "\n",
      "episode 7, val func loss 1.1430338621139526\n",
      "\n",
      "episode 8, val func loss 1.2922862768173218\n",
      "\n",
      "episode 9, val func loss 1.295946717262268\n",
      "\n",
      "episode 10, val func loss 1.358469843864441\n",
      "\n",
      "episode 11, val func loss 1.462179183959961\n",
      "\n",
      "episode 12, val func loss 1.3765995502471924\n",
      "\n",
      "episode 13, val func loss 1.133062720298767\n",
      "\n",
      "episode 14, val func loss 1.428792953491211\n",
      "\n",
      "episode 15, val func loss 1.149800181388855\n",
      "\n",
      "episode 16, val func loss 1.269533395767212\n",
      "\n",
      "Val func train loss in epoch 8:1.3187784478068352\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.2253793478012085\n",
      "\n",
      "episode 2, val func loss 1.4340074062347412\n",
      "\n",
      "episode 3, val func loss 1.282983422279358\n",
      "\n",
      "episode 4, val func loss 1.2066606283187866\n",
      "\n",
      "episode 5, val func loss 1.4131510257720947\n",
      "\n",
      "episode 6, val func loss 1.4471181631088257\n",
      "\n",
      "episode 7, val func loss 1.5353559255599976\n",
      "\n",
      "episode 8, val func loss 1.3617424964904785\n",
      "\n",
      "episode 9, val func loss 1.424093246459961\n",
      "\n",
      "episode 10, val func loss 1.308891773223877\n",
      "\n",
      "episode 11, val func loss 0.9665758013725281\n",
      "\n",
      "episode 12, val func loss 1.1942532062530518\n",
      "\n",
      "episode 13, val func loss 1.42954683303833\n",
      "\n",
      "episode 14, val func loss 1.3481941223144531\n",
      "\n",
      "episode 15, val func loss 1.4587491750717163\n",
      "\n",
      "episode 16, val func loss 1.3680564165115356\n",
      "\n",
      "Val func train loss in epoch 9:1.337797436863184\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.2812578678131104\n",
      "\n",
      "episode 2, val func loss 1.2601979970932007\n",
      "\n",
      "episode 3, val func loss 1.2633756399154663\n",
      "\n",
      "episode 4, val func loss 1.4253013134002686\n",
      "\n",
      "episode 5, val func loss 1.255932092666626\n",
      "\n",
      "episode 6, val func loss 1.304871678352356\n",
      "\n",
      "episode 7, val func loss 1.2551759481430054\n",
      "\n",
      "episode 8, val func loss 1.2764798402786255\n",
      "\n",
      "episode 9, val func loss 1.3252243995666504\n",
      "\n",
      "episode 10, val func loss 1.27077317237854\n",
      "\n",
      "episode 11, val func loss 1.3218326568603516\n",
      "\n",
      "episode 12, val func loss 1.33258855342865\n",
      "\n",
      "episode 13, val func loss 1.3056604862213135\n",
      "\n",
      "episode 14, val func loss 1.2874432802200317\n",
      "\n",
      "episode 15, val func loss 1.3001155853271484\n",
      "\n",
      "episode 16, val func loss 1.4023207426071167\n",
      "\n",
      "Val func train loss in epoch 10:1.3042844533920288\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.3926873207092285\n",
      "\n",
      "episode 2, val func loss 1.379412293434143\n",
      "\n",
      "episode 3, val func loss 1.1697734594345093\n",
      "\n",
      "episode 4, val func loss 1.4777580499649048\n",
      "\n",
      "episode 5, val func loss 1.2567017078399658\n",
      "\n",
      "episode 6, val func loss 1.2586678266525269\n",
      "\n",
      "episode 7, val func loss 1.1458510160446167\n",
      "\n",
      "episode 8, val func loss 1.1206618547439575\n",
      "\n",
      "episode 9, val func loss 1.2996222972869873\n",
      "\n",
      "episode 10, val func loss 1.1740657091140747\n",
      "\n",
      "episode 11, val func loss 1.2830638885498047\n",
      "\n",
      "episode 12, val func loss 1.4750900268554688\n",
      "\n",
      "episode 13, val func loss 1.3388762474060059\n",
      "\n",
      "episode 14, val func loss 1.5745574235916138\n",
      "\n",
      "episode 15, val func loss 1.2442431449890137\n",
      "\n",
      "episode 16, val func loss 1.2073191404342651\n",
      "\n",
      "Val func train loss in epoch 11:1.299896962940693\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.1546456813812256\n",
      "\n",
      "episode 2, val func loss 1.3825315237045288\n",
      "\n",
      "episode 3, val func loss 1.3817154169082642\n",
      "\n",
      "episode 4, val func loss 1.3007826805114746\n",
      "\n",
      "episode 5, val func loss 1.370497226715088\n",
      "\n",
      "episode 6, val func loss 1.3184200525283813\n",
      "\n",
      "episode 7, val func loss 1.229504942893982\n",
      "\n",
      "episode 8, val func loss 1.1265827417373657\n",
      "\n",
      "episode 9, val func loss 1.2432732582092285\n",
      "\n",
      "episode 10, val func loss 1.60154128074646\n",
      "\n",
      "episode 11, val func loss 1.3546406030654907\n",
      "\n",
      "episode 12, val func loss 1.399680495262146\n",
      "\n",
      "episode 13, val func loss 1.46211838722229\n",
      "\n",
      "episode 14, val func loss 1.216357707977295\n",
      "\n",
      "episode 15, val func loss 1.191704511642456\n",
      "\n",
      "episode 16, val func loss 1.183563232421875\n",
      "\n",
      "Val func train loss in epoch 12:1.307347483932972\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.119796633720398\n",
      "\n",
      "episode 2, val func loss 1.0585784912109375\n",
      "\n",
      "episode 3, val func loss 1.2061711549758911\n",
      "\n",
      "episode 4, val func loss 1.2690362930297852\n",
      "\n",
      "episode 5, val func loss 1.1301909685134888\n",
      "\n",
      "episode 6, val func loss 1.1323301792144775\n",
      "\n",
      "episode 7, val func loss 1.4764561653137207\n",
      "\n",
      "episode 8, val func loss 1.345963954925537\n",
      "\n",
      "episode 9, val func loss 1.1247732639312744\n",
      "\n",
      "episode 10, val func loss 1.2714327573776245\n",
      "\n",
      "episode 11, val func loss 1.170717477798462\n",
      "\n",
      "episode 12, val func loss 1.2911174297332764\n",
      "\n",
      "episode 13, val func loss 1.3975905179977417\n",
      "\n",
      "episode 14, val func loss 1.2875367403030396\n",
      "\n",
      "episode 15, val func loss 1.2976515293121338\n",
      "\n",
      "episode 16, val func loss 1.3291380405426025\n",
      "\n",
      "Val func train loss in epoch 13:1.2442800998687744\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.368384599685669\n",
      "\n",
      "episode 2, val func loss 1.1070624589920044\n",
      "\n",
      "episode 3, val func loss 1.317855954170227\n",
      "\n",
      "episode 4, val func loss 1.4334888458251953\n",
      "\n",
      "episode 5, val func loss 1.3524274826049805\n",
      "\n",
      "episode 6, val func loss 1.1989126205444336\n",
      "\n",
      "episode 7, val func loss 1.3544081449508667\n",
      "\n",
      "episode 8, val func loss 1.2598644495010376\n",
      "\n",
      "episode 9, val func loss 1.234165906906128\n",
      "\n",
      "episode 10, val func loss 1.307966709136963\n",
      "\n",
      "episode 11, val func loss 1.3372466564178467\n",
      "\n",
      "episode 12, val func loss 1.374586820602417\n",
      "\n",
      "episode 13, val func loss 1.2830063104629517\n",
      "\n",
      "episode 14, val func loss 1.2859256267547607\n",
      "\n",
      "episode 15, val func loss 1.3403010368347168\n",
      "\n",
      "episode 16, val func loss 1.2414350509643555\n",
      "\n",
      "Val func train loss in epoch 14:1.2998149171471596\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.1247501373291016\n",
      "\n",
      "episode 2, val func loss 1.2401530742645264\n",
      "\n",
      "episode 3, val func loss 1.310589075088501\n",
      "\n",
      "episode 4, val func loss 1.3556097745895386\n",
      "\n",
      "episode 5, val func loss 1.2774150371551514\n",
      "\n",
      "episode 6, val func loss 1.4596301317214966\n",
      "\n",
      "episode 7, val func loss 1.2606894969940186\n",
      "\n",
      "episode 8, val func loss 1.4860469102859497\n",
      "\n",
      "episode 9, val func loss 1.3902126550674438\n",
      "\n",
      "episode 10, val func loss 1.2104341983795166\n",
      "\n",
      "episode 11, val func loss 1.3597371578216553\n",
      "\n",
      "episode 12, val func loss 1.5676010847091675\n",
      "\n",
      "episode 13, val func loss 1.2976263761520386\n",
      "\n",
      "episode 14, val func loss 1.4437923431396484\n",
      "\n",
      "episode 15, val func loss 1.3273118734359741\n",
      "\n",
      "episode 16, val func loss 1.3305104970932007\n",
      "\n",
      "Val func train loss in epoch 15:1.340131863951683\n",
      "***********************TIME WAS 4.813261179129283 min*****************************\n",
      "\n",
      "**********************ROUND 42 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.2998616695404053\n",
      "\n",
      "episode 2, policy loss -3.2998616695404053\n",
      "\n",
      "episode 3, policy loss -3.2998616695404053\n",
      "\n",
      "episode 4, policy loss -3.2998616695404053\n",
      "\n",
      "episode 5, policy loss -3.2998616695404053\n",
      "\n",
      "episode 6, policy loss -3.2998616695404053\n",
      "\n",
      "episode 7, policy loss -3.2998616695404053\n",
      "\n",
      "episode 8, policy loss -3.2998616695404053\n",
      "\n",
      "episode 9, policy loss -3.2998616695404053\n",
      "\n",
      "episode 10, policy loss -3.2998616695404053\n",
      "\n",
      "episode 11, policy loss -3.2998616695404053\n",
      "\n",
      "episode 12, policy loss -3.2998616695404053\n",
      "\n",
      "episode 13, policy loss -3.2998616695404053\n",
      "\n",
      "episode 14, policy loss -3.2998616695404053\n",
      "\n",
      "episode 15, policy loss -3.2998616695404053\n",
      "\n",
      "episode 16, policy loss -3.2998616695404053\n",
      "\n",
      "Policy train loss in epoch 0:-3.2998616695404053\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.2998616695404053\n",
      "\n",
      "episode 2, policy loss -3.2998616695404053\n",
      "\n",
      "episode 3, policy loss -3.2998616695404053\n",
      "\n",
      "episode 4, policy loss -3.2998616695404053\n",
      "\n",
      "episode 5, policy loss -3.2998616695404053\n",
      "\n",
      "episode 6, policy loss -3.2998616695404053\n",
      "\n",
      "episode 7, policy loss -3.2998616695404053\n",
      "\n",
      "episode 8, policy loss -3.2998616695404053\n",
      "\n",
      "episode 9, policy loss -3.2998616695404053\n",
      "\n",
      "episode 10, policy loss -3.2998616695404053\n",
      "\n",
      "episode 11, policy loss -3.2998616695404053\n",
      "\n",
      "episode 12, policy loss -3.2998616695404053\n",
      "\n",
      "episode 13, policy loss -3.2998616695404053\n",
      "\n",
      "episode 14, policy loss -3.2998616695404053\n",
      "\n",
      "episode 15, policy loss -3.2998616695404053\n",
      "\n",
      "episode 16, policy loss -3.2998616695404053\n",
      "\n",
      "Policy train loss in epoch 1:-3.2998616695404053\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.2998616695404053\n",
      "\n",
      "episode 2, policy loss -3.2998616695404053\n",
      "\n",
      "episode 3, policy loss -3.2998616695404053\n",
      "\n",
      "episode 4, policy loss -3.2998616695404053\n",
      "\n",
      "episode 5, policy loss -3.2998616695404053\n",
      "\n",
      "episode 6, policy loss -3.2998616695404053\n",
      "\n",
      "episode 7, policy loss -3.2998616695404053\n",
      "\n",
      "episode 8, policy loss -3.2998616695404053\n",
      "\n",
      "episode 9, policy loss -3.2998616695404053\n",
      "\n",
      "episode 10, policy loss -3.2998616695404053\n",
      "\n",
      "episode 11, policy loss -3.2998616695404053\n",
      "\n",
      "episode 12, policy loss -3.2998616695404053\n",
      "\n",
      "episode 13, policy loss -3.2998616695404053\n",
      "\n",
      "episode 14, policy loss -3.2998616695404053\n",
      "\n",
      "episode 15, policy loss -3.2998616695404053\n",
      "\n",
      "episode 16, policy loss -3.2998616695404053\n",
      "\n",
      "Policy train loss in epoch 2:-3.2998616695404053\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.2998616695404053\n",
      "\n",
      "episode 2, policy loss -3.2998616695404053\n",
      "\n",
      "episode 3, policy loss -3.2998616695404053\n",
      "\n",
      "episode 4, policy loss -3.2998616695404053\n",
      "\n",
      "episode 5, policy loss -3.2998616695404053\n",
      "\n",
      "episode 6, policy loss -3.2998616695404053\n",
      "\n",
      "episode 7, policy loss -3.2998616695404053\n",
      "\n",
      "episode 8, policy loss -3.2998616695404053\n",
      "\n",
      "episode 9, policy loss -3.2998616695404053\n",
      "\n",
      "episode 10, policy loss -3.2998616695404053\n",
      "\n",
      "episode 11, policy loss -3.2998616695404053\n",
      "\n",
      "episode 12, policy loss -3.2998616695404053\n",
      "\n",
      "episode 13, policy loss -3.2998616695404053\n",
      "\n",
      "episode 14, policy loss -3.2998616695404053\n",
      "\n",
      "episode 15, policy loss -3.2998616695404053\n",
      "\n",
      "episode 16, policy loss -3.2998616695404053\n",
      "\n",
      "Policy train loss in epoch 3:-3.2998616695404053\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.1884757280349731\n",
      "\n",
      "episode 2, val func loss 1.2818419933319092\n",
      "\n",
      "episode 3, val func loss 1.272320032119751\n",
      "\n",
      "episode 4, val func loss 1.1875901222229004\n",
      "\n",
      "episode 5, val func loss 1.1893802881240845\n",
      "\n",
      "episode 6, val func loss 1.3122880458831787\n",
      "\n",
      "episode 7, val func loss 1.282159447669983\n",
      "\n",
      "episode 8, val func loss 1.2062584161758423\n",
      "\n",
      "episode 9, val func loss 1.219576120376587\n",
      "\n",
      "episode 10, val func loss 1.1431329250335693\n",
      "\n",
      "episode 11, val func loss 1.3473750352859497\n",
      "\n",
      "episode 12, val func loss 1.4101910591125488\n",
      "\n",
      "episode 13, val func loss 1.1857576370239258\n",
      "\n",
      "episode 14, val func loss 1.3193190097808838\n",
      "\n",
      "episode 15, val func loss 1.3419175148010254\n",
      "\n",
      "episode 16, val func loss 1.1591397523880005\n",
      "\n",
      "Val func train loss in epoch 0:1.2529201954603195\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.25369393825531\n",
      "\n",
      "episode 2, val func loss 1.1526786088943481\n",
      "\n",
      "episode 3, val func loss 1.1935111284255981\n",
      "\n",
      "episode 4, val func loss 1.3064746856689453\n",
      "\n",
      "episode 5, val func loss 1.0590676069259644\n",
      "\n",
      "episode 6, val func loss 1.187992811203003\n",
      "\n",
      "episode 7, val func loss 1.3195451498031616\n",
      "\n",
      "episode 8, val func loss 1.5971122980117798\n",
      "\n",
      "episode 9, val func loss 1.4156413078308105\n",
      "\n",
      "episode 10, val func loss 1.5895055532455444\n",
      "\n",
      "episode 11, val func loss 1.6456981897354126\n",
      "\n",
      "episode 12, val func loss 1.3236067295074463\n",
      "\n",
      "episode 13, val func loss 1.4111374616622925\n",
      "\n",
      "episode 14, val func loss 1.2340359687805176\n",
      "\n",
      "episode 15, val func loss 1.3510161638259888\n",
      "\n",
      "episode 16, val func loss 1.172408103942871\n",
      "\n",
      "Val func train loss in epoch 1:1.3258203566074371\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.2771632671356201\n",
      "\n",
      "episode 2, val func loss 1.3210606575012207\n",
      "\n",
      "episode 3, val func loss 1.3256134986877441\n",
      "\n",
      "episode 4, val func loss 1.4063167572021484\n",
      "\n",
      "episode 5, val func loss 1.2772960662841797\n",
      "\n",
      "episode 6, val func loss 1.468754529953003\n",
      "\n",
      "episode 7, val func loss 1.3177887201309204\n",
      "\n",
      "episode 8, val func loss 1.224552035331726\n",
      "\n",
      "episode 9, val func loss 1.4479345083236694\n",
      "\n",
      "episode 10, val func loss 1.5151433944702148\n",
      "\n",
      "episode 11, val func loss 1.4999386072158813\n",
      "\n",
      "episode 12, val func loss 1.5034674406051636\n",
      "\n",
      "episode 13, val func loss 1.164514422416687\n",
      "\n",
      "episode 14, val func loss 1.3076452016830444\n",
      "\n",
      "episode 15, val func loss 1.3129113912582397\n",
      "\n",
      "episode 16, val func loss 1.414710521697998\n",
      "\n",
      "Val func train loss in epoch 2:1.3615506887435913\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.2468037605285645\n",
      "\n",
      "episode 2, val func loss 1.349989652633667\n",
      "\n",
      "episode 3, val func loss 1.270735502243042\n",
      "\n",
      "episode 4, val func loss 1.5114541053771973\n",
      "\n",
      "episode 5, val func loss 1.42644202709198\n",
      "\n",
      "episode 6, val func loss 1.142398715019226\n",
      "\n",
      "episode 7, val func loss 1.216644525527954\n",
      "\n",
      "episode 8, val func loss 1.3141543865203857\n",
      "\n",
      "episode 9, val func loss 1.2257627248764038\n",
      "\n",
      "episode 10, val func loss 1.3237162828445435\n",
      "\n",
      "episode 11, val func loss 1.2669681310653687\n",
      "\n",
      "episode 12, val func loss 1.439047932624817\n",
      "\n",
      "episode 13, val func loss 1.226536512374878\n",
      "\n",
      "episode 14, val func loss 1.044404149055481\n",
      "\n",
      "episode 15, val func loss 1.1848474740982056\n",
      "\n",
      "episode 16, val func loss 1.3004257678985596\n",
      "\n",
      "Val func train loss in epoch 3:1.280645728111267\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.2777527570724487\n",
      "\n",
      "episode 2, val func loss 1.225406289100647\n",
      "\n",
      "episode 3, val func loss 1.1256235837936401\n",
      "\n",
      "episode 4, val func loss 1.373307228088379\n",
      "\n",
      "episode 5, val func loss 1.3406528234481812\n",
      "\n",
      "episode 6, val func loss 1.0912179946899414\n",
      "\n",
      "episode 7, val func loss 1.3302451372146606\n",
      "\n",
      "episode 8, val func loss 1.384035587310791\n",
      "\n",
      "episode 9, val func loss 1.5013703107833862\n",
      "\n",
      "episode 10, val func loss 1.2138330936431885\n",
      "\n",
      "episode 11, val func loss 1.2459397315979004\n",
      "\n",
      "episode 12, val func loss 1.2693265676498413\n",
      "\n",
      "episode 13, val func loss 1.3945876359939575\n",
      "\n",
      "episode 14, val func loss 1.2374005317687988\n",
      "\n",
      "episode 15, val func loss 1.6298332214355469\n",
      "\n",
      "episode 16, val func loss 1.2557802200317383\n",
      "\n",
      "Val func train loss in epoch 4:1.3060195446014404\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.2989988327026367\n",
      "\n",
      "episode 2, val func loss 1.1705244779586792\n",
      "\n",
      "episode 3, val func loss 1.1992452144622803\n",
      "\n",
      "episode 4, val func loss 1.2747001647949219\n",
      "\n",
      "episode 5, val func loss 1.3416545391082764\n",
      "\n",
      "episode 6, val func loss 1.4091004133224487\n",
      "\n",
      "episode 7, val func loss 1.241599678993225\n",
      "\n",
      "episode 8, val func loss 1.1112563610076904\n",
      "\n",
      "episode 9, val func loss 1.32941734790802\n",
      "\n",
      "episode 10, val func loss 1.3896833658218384\n",
      "\n",
      "episode 11, val func loss 1.4882057905197144\n",
      "\n",
      "episode 12, val func loss 1.3967301845550537\n",
      "\n",
      "episode 13, val func loss 1.1463898420333862\n",
      "\n",
      "episode 14, val func loss 1.3946964740753174\n",
      "\n",
      "episode 15, val func loss 1.2504485845565796\n",
      "\n",
      "episode 16, val func loss 1.2033162117004395\n",
      "\n",
      "Val func train loss in epoch 5:1.2903729677200317\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.2263834476470947\n",
      "\n",
      "episode 2, val func loss 1.3081594705581665\n",
      "\n",
      "episode 3, val func loss 1.3111227750778198\n",
      "\n",
      "episode 4, val func loss 1.4072753190994263\n",
      "\n",
      "episode 5, val func loss 1.2443066835403442\n",
      "\n",
      "episode 6, val func loss 1.2142165899276733\n",
      "\n",
      "episode 7, val func loss 1.4756625890731812\n",
      "\n",
      "episode 8, val func loss 1.4123585224151611\n",
      "\n",
      "episode 9, val func loss 1.1704716682434082\n",
      "\n",
      "episode 10, val func loss 1.4667246341705322\n",
      "\n",
      "episode 11, val func loss 1.2886093854904175\n",
      "\n",
      "episode 12, val func loss 1.3490848541259766\n",
      "\n",
      "episode 13, val func loss 1.3998446464538574\n",
      "\n",
      "episode 14, val func loss 1.4859775304794312\n",
      "\n",
      "episode 15, val func loss 1.2117663621902466\n",
      "\n",
      "episode 16, val func loss 1.2766128778457642\n",
      "\n",
      "Val func train loss in epoch 6:1.3280360847711563\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.242026686668396\n",
      "\n",
      "episode 2, val func loss 1.0846140384674072\n",
      "\n",
      "episode 3, val func loss 1.412081003189087\n",
      "\n",
      "episode 4, val func loss 1.3021866083145142\n",
      "\n",
      "episode 5, val func loss 1.5305019617080688\n",
      "\n",
      "episode 6, val func loss 1.2020082473754883\n",
      "\n",
      "episode 7, val func loss 1.2382787466049194\n",
      "\n",
      "episode 8, val func loss 1.3148765563964844\n",
      "\n",
      "episode 9, val func loss 1.2452905178070068\n",
      "\n",
      "episode 10, val func loss 1.2943782806396484\n",
      "\n",
      "episode 11, val func loss 1.295175552368164\n",
      "\n",
      "episode 12, val func loss 1.3553204536437988\n",
      "\n",
      "episode 13, val func loss 1.3394503593444824\n",
      "\n",
      "episode 14, val func loss 1.1223009824752808\n",
      "\n",
      "episode 15, val func loss 1.4135180711746216\n",
      "\n",
      "episode 16, val func loss 1.3552707433700562\n",
      "\n",
      "Val func train loss in epoch 7:1.296704925596714\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.2440210580825806\n",
      "\n",
      "episode 2, val func loss 1.3037612438201904\n",
      "\n",
      "episode 3, val func loss 1.2081795930862427\n",
      "\n",
      "episode 4, val func loss 1.143067717552185\n",
      "\n",
      "episode 5, val func loss 1.149412989616394\n",
      "\n",
      "episode 6, val func loss 1.2069458961486816\n",
      "\n",
      "episode 7, val func loss 1.300847053527832\n",
      "\n",
      "episode 8, val func loss 1.41105318069458\n",
      "\n",
      "episode 9, val func loss 1.3899142742156982\n",
      "\n",
      "episode 10, val func loss 1.202415108680725\n",
      "\n",
      "episode 11, val func loss 1.3256489038467407\n",
      "\n",
      "episode 12, val func loss 1.4841481447219849\n",
      "\n",
      "episode 13, val func loss 1.3095701932907104\n",
      "\n",
      "episode 14, val func loss 1.0661158561706543\n",
      "\n",
      "episode 15, val func loss 1.2400509119033813\n",
      "\n",
      "episode 16, val func loss 1.2946182489395142\n",
      "\n",
      "Val func train loss in epoch 8:1.267485648393631\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.153875708580017\n",
      "\n",
      "episode 2, val func loss 1.2192286252975464\n",
      "\n",
      "episode 3, val func loss 1.3598939180374146\n",
      "\n",
      "episode 4, val func loss 1.21204674243927\n",
      "\n",
      "episode 5, val func loss 1.2876687049865723\n",
      "\n",
      "episode 6, val func loss 1.0793009996414185\n",
      "\n",
      "episode 7, val func loss 1.268910527229309\n",
      "\n",
      "episode 8, val func loss 1.305237889289856\n",
      "\n",
      "episode 9, val func loss 1.083994746208191\n",
      "\n",
      "episode 10, val func loss 1.2385514974594116\n",
      "\n",
      "episode 11, val func loss 1.2897825241088867\n",
      "\n",
      "episode 12, val func loss 1.4643694162368774\n",
      "\n",
      "episode 13, val func loss 1.218456506729126\n",
      "\n",
      "episode 14, val func loss 1.3082618713378906\n",
      "\n",
      "episode 15, val func loss 1.2479904890060425\n",
      "\n",
      "episode 16, val func loss 1.1279067993164062\n",
      "\n",
      "Val func train loss in epoch 9:1.2415923103690147\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.2480223178863525\n",
      "\n",
      "episode 2, val func loss 1.4416295289993286\n",
      "\n",
      "episode 3, val func loss 1.1260864734649658\n",
      "\n",
      "episode 4, val func loss 1.1360241174697876\n",
      "\n",
      "episode 5, val func loss 1.295218825340271\n",
      "\n",
      "episode 6, val func loss 1.101084589958191\n",
      "\n",
      "episode 7, val func loss 1.2706104516983032\n",
      "\n",
      "episode 8, val func loss 1.3609833717346191\n",
      "\n",
      "episode 9, val func loss 1.3253958225250244\n",
      "\n",
      "episode 10, val func loss 1.2303670644760132\n",
      "\n",
      "episode 11, val func loss 1.3391982316970825\n",
      "\n",
      "episode 12, val func loss 1.4835331439971924\n",
      "\n",
      "episode 13, val func loss 1.2750582695007324\n",
      "\n",
      "episode 14, val func loss 1.367799997329712\n",
      "\n",
      "episode 15, val func loss 1.222090482711792\n",
      "\n",
      "episode 16, val func loss 1.50189208984375\n",
      "\n",
      "Val func train loss in epoch 10:1.2953121736645699\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.3414677381515503\n",
      "\n",
      "episode 2, val func loss 1.363241195678711\n",
      "\n",
      "episode 3, val func loss 1.2776081562042236\n",
      "\n",
      "episode 4, val func loss 1.3455967903137207\n",
      "\n",
      "episode 5, val func loss 1.2213786840438843\n",
      "\n",
      "episode 6, val func loss 1.1644773483276367\n",
      "\n",
      "episode 7, val func loss 1.2407931089401245\n",
      "\n",
      "episode 8, val func loss 1.3332087993621826\n",
      "\n",
      "episode 9, val func loss 1.2200297117233276\n",
      "\n",
      "episode 10, val func loss 1.2954241037368774\n",
      "\n",
      "episode 11, val func loss 1.335663914680481\n",
      "\n",
      "episode 12, val func loss 1.385360836982727\n",
      "\n",
      "episode 13, val func loss 1.372492790222168\n",
      "\n",
      "episode 14, val func loss 1.27874755859375\n",
      "\n",
      "episode 15, val func loss 1.3067622184753418\n",
      "\n",
      "episode 16, val func loss 1.3425427675247192\n",
      "\n",
      "Val func train loss in epoch 11:1.3015497326850891\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.255479335784912\n",
      "\n",
      "episode 2, val func loss 1.166548252105713\n",
      "\n",
      "episode 3, val func loss 1.023255467414856\n",
      "\n",
      "episode 4, val func loss 1.3369166851043701\n",
      "\n",
      "episode 5, val func loss 1.372822880744934\n",
      "\n",
      "episode 6, val func loss 1.2861605882644653\n",
      "\n",
      "episode 7, val func loss 1.1928696632385254\n",
      "\n",
      "episode 8, val func loss 1.4161847829818726\n",
      "\n",
      "episode 9, val func loss 1.2627243995666504\n",
      "\n",
      "episode 10, val func loss 1.283163070678711\n",
      "\n",
      "episode 11, val func loss 1.293633222579956\n",
      "\n",
      "episode 12, val func loss 1.299890160560608\n",
      "\n",
      "episode 13, val func loss 1.4322102069854736\n",
      "\n",
      "episode 14, val func loss 1.237135648727417\n",
      "\n",
      "episode 15, val func loss 1.4932148456573486\n",
      "\n",
      "episode 16, val func loss 1.4032964706420898\n",
      "\n",
      "Val func train loss in epoch 12:1.297219105064869\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.2844558954238892\n",
      "\n",
      "episode 2, val func loss 1.2160638570785522\n",
      "\n",
      "episode 3, val func loss 1.3190685510635376\n",
      "\n",
      "episode 4, val func loss 1.4547215700149536\n",
      "\n",
      "episode 5, val func loss 1.2699072360992432\n",
      "\n",
      "episode 6, val func loss 1.3294142484664917\n",
      "\n",
      "episode 7, val func loss 1.2082549333572388\n",
      "\n",
      "episode 8, val func loss 1.2092015743255615\n",
      "\n",
      "episode 9, val func loss 1.426971435546875\n",
      "\n",
      "episode 10, val func loss 1.153397560119629\n",
      "\n",
      "episode 11, val func loss 1.3361836671829224\n",
      "\n",
      "episode 12, val func loss 1.2976441383361816\n",
      "\n",
      "episode 13, val func loss 1.5171865224838257\n",
      "\n",
      "episode 14, val func loss 1.4754375219345093\n",
      "\n",
      "episode 15, val func loss 1.1851184368133545\n",
      "\n",
      "episode 16, val func loss 1.4337254762649536\n",
      "\n",
      "Val func train loss in epoch 13:1.3197970390319824\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.0047013759613037\n",
      "\n",
      "episode 2, val func loss 1.2208936214447021\n",
      "\n",
      "episode 3, val func loss 1.201664924621582\n",
      "\n",
      "episode 4, val func loss 1.4241485595703125\n",
      "\n",
      "episode 5, val func loss 1.3808280229568481\n",
      "\n",
      "episode 6, val func loss 1.3197975158691406\n",
      "\n",
      "episode 7, val func loss 1.3388675451278687\n",
      "\n",
      "episode 8, val func loss 1.4109429121017456\n",
      "\n",
      "episode 9, val func loss 1.3781312704086304\n",
      "\n",
      "episode 10, val func loss 1.1327847242355347\n",
      "\n",
      "episode 11, val func loss 1.3357640504837036\n",
      "\n",
      "episode 12, val func loss 1.498833417892456\n",
      "\n",
      "episode 13, val func loss 1.2584625482559204\n",
      "\n",
      "episode 14, val func loss 1.3662261962890625\n",
      "\n",
      "episode 15, val func loss 1.3014757633209229\n",
      "\n",
      "episode 16, val func loss 1.317341923713684\n",
      "\n",
      "Val func train loss in epoch 14:1.3056790232658386\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.2194514274597168\n",
      "\n",
      "episode 2, val func loss 1.1664248704910278\n",
      "\n",
      "episode 3, val func loss 1.154577374458313\n",
      "\n",
      "episode 4, val func loss 1.283754587173462\n",
      "\n",
      "episode 5, val func loss 1.3733760118484497\n",
      "\n",
      "episode 6, val func loss 1.294581413269043\n",
      "\n",
      "episode 7, val func loss 1.2812429666519165\n",
      "\n",
      "episode 8, val func loss 1.2037737369537354\n",
      "\n",
      "episode 9, val func loss 1.2453235387802124\n",
      "\n",
      "episode 10, val func loss 1.4374421834945679\n",
      "\n",
      "episode 11, val func loss 1.337507963180542\n",
      "\n",
      "episode 12, val func loss 1.076101541519165\n",
      "\n",
      "episode 13, val func loss 1.303672432899475\n",
      "\n",
      "episode 14, val func loss 1.1434818506240845\n",
      "\n",
      "episode 15, val func loss 1.400221347808838\n",
      "\n",
      "episode 16, val func loss 1.3236806392669678\n",
      "\n",
      "Val func train loss in epoch 15:1.2652883678674698\n",
      "***********************TIME WAS 4.8160387635231015 min*****************************\n",
      "\n",
      "**********************ROUND 43 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.429154872894287\n",
      "\n",
      "episode 2, policy loss -3.429154872894287\n",
      "\n",
      "episode 3, policy loss -3.429154872894287\n",
      "\n",
      "episode 4, policy loss -3.429154872894287\n",
      "\n",
      "episode 5, policy loss -3.429154872894287\n",
      "\n",
      "episode 6, policy loss -3.429154872894287\n",
      "\n",
      "episode 7, policy loss -3.429154872894287\n",
      "\n",
      "episode 8, policy loss -3.429154872894287\n",
      "\n",
      "episode 9, policy loss -3.429154872894287\n",
      "\n",
      "episode 10, policy loss -3.429154872894287\n",
      "\n",
      "episode 11, policy loss -3.429154872894287\n",
      "\n",
      "episode 12, policy loss -3.429154872894287\n",
      "\n",
      "episode 13, policy loss -3.429154872894287\n",
      "\n",
      "episode 14, policy loss -3.429154872894287\n",
      "\n",
      "episode 15, policy loss -3.429154872894287\n",
      "\n",
      "episode 16, policy loss -3.429154872894287\n",
      "\n",
      "Policy train loss in epoch 0:-3.429154872894287\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.429154872894287\n",
      "\n",
      "episode 2, policy loss -3.429154872894287\n",
      "\n",
      "episode 3, policy loss -3.429154872894287\n",
      "\n",
      "episode 4, policy loss -3.429154872894287\n",
      "\n",
      "episode 5, policy loss -3.429154872894287\n",
      "\n",
      "episode 6, policy loss -3.429154872894287\n",
      "\n",
      "episode 7, policy loss -3.429154872894287\n",
      "\n",
      "episode 8, policy loss -3.429154872894287\n",
      "\n",
      "episode 9, policy loss -3.429154872894287\n",
      "\n",
      "episode 10, policy loss -3.429154872894287\n",
      "\n",
      "episode 11, policy loss -3.429154872894287\n",
      "\n",
      "episode 12, policy loss -3.429154872894287\n",
      "\n",
      "episode 13, policy loss -3.429154872894287\n",
      "\n",
      "episode 14, policy loss -3.429154872894287\n",
      "\n",
      "episode 15, policy loss -3.429154872894287\n",
      "\n",
      "episode 16, policy loss -3.429154872894287\n",
      "\n",
      "Policy train loss in epoch 1:-3.429154872894287\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.429154872894287\n",
      "\n",
      "episode 2, policy loss -3.429154872894287\n",
      "\n",
      "episode 3, policy loss -3.429154872894287\n",
      "\n",
      "episode 4, policy loss -3.429154872894287\n",
      "\n",
      "episode 5, policy loss -3.429154872894287\n",
      "\n",
      "episode 6, policy loss -3.429154872894287\n",
      "\n",
      "episode 7, policy loss -3.429154872894287\n",
      "\n",
      "episode 8, policy loss -3.429154872894287\n",
      "\n",
      "episode 9, policy loss -3.429154872894287\n",
      "\n",
      "episode 10, policy loss -3.429154872894287\n",
      "\n",
      "episode 11, policy loss -3.429154872894287\n",
      "\n",
      "episode 12, policy loss -3.429154872894287\n",
      "\n",
      "episode 13, policy loss -3.429154872894287\n",
      "\n",
      "episode 14, policy loss -3.429154872894287\n",
      "\n",
      "episode 15, policy loss -3.429154872894287\n",
      "\n",
      "episode 16, policy loss -3.429154872894287\n",
      "\n",
      "Policy train loss in epoch 2:-3.429154872894287\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.429154872894287\n",
      "\n",
      "episode 2, policy loss -3.429154872894287\n",
      "\n",
      "episode 3, policy loss -3.429154872894287\n",
      "\n",
      "episode 4, policy loss -3.429154872894287\n",
      "\n",
      "episode 5, policy loss -3.429154872894287\n",
      "\n",
      "episode 6, policy loss -3.429154872894287\n",
      "\n",
      "episode 7, policy loss -3.429154872894287\n",
      "\n",
      "episode 8, policy loss -3.429154872894287\n",
      "\n",
      "episode 9, policy loss -3.429154872894287\n",
      "\n",
      "episode 10, policy loss -3.429154872894287\n",
      "\n",
      "episode 11, policy loss -3.429154872894287\n",
      "\n",
      "episode 12, policy loss -3.429154872894287\n",
      "\n",
      "episode 13, policy loss -3.429154872894287\n",
      "\n",
      "episode 14, policy loss -3.429154872894287\n",
      "\n",
      "episode 15, policy loss -3.429154872894287\n",
      "\n",
      "episode 16, policy loss -3.429154872894287\n",
      "\n",
      "Policy train loss in epoch 3:-3.429154872894287\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.2573301792144775\n",
      "\n",
      "episode 2, val func loss 1.2278046607971191\n",
      "\n",
      "episode 3, val func loss 1.3345799446105957\n",
      "\n",
      "episode 4, val func loss 1.2164140939712524\n",
      "\n",
      "episode 5, val func loss 1.3078560829162598\n",
      "\n",
      "episode 6, val func loss 1.350712537765503\n",
      "\n",
      "episode 7, val func loss 1.0973032712936401\n",
      "\n",
      "episode 8, val func loss 1.1867722272872925\n",
      "\n",
      "episode 9, val func loss 1.3443124294281006\n",
      "\n",
      "episode 10, val func loss 1.3015193939208984\n",
      "\n",
      "episode 11, val func loss 1.2431573867797852\n",
      "\n",
      "episode 12, val func loss 1.2445942163467407\n",
      "\n",
      "episode 13, val func loss 1.2579536437988281\n",
      "\n",
      "episode 14, val func loss 1.3993208408355713\n",
      "\n",
      "episode 15, val func loss 1.1410733461380005\n",
      "\n",
      "episode 16, val func loss 1.3592562675476074\n",
      "\n",
      "Val func train loss in epoch 0:1.2668725326657295\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.341780662536621\n",
      "\n",
      "episode 2, val func loss 1.2493352890014648\n",
      "\n",
      "episode 3, val func loss 1.388124942779541\n",
      "\n",
      "episode 4, val func loss 1.1452648639678955\n",
      "\n",
      "episode 5, val func loss 1.2182142734527588\n",
      "\n",
      "episode 6, val func loss 1.3009806871414185\n",
      "\n",
      "episode 7, val func loss 1.2133941650390625\n",
      "\n",
      "episode 8, val func loss 1.334597110748291\n",
      "\n",
      "episode 9, val func loss 1.296266794204712\n",
      "\n",
      "episode 10, val func loss 1.07119619846344\n",
      "\n",
      "episode 11, val func loss 1.3058198690414429\n",
      "\n",
      "episode 12, val func loss 1.216962456703186\n",
      "\n",
      "episode 13, val func loss 1.17549729347229\n",
      "\n",
      "episode 14, val func loss 1.2680156230926514\n",
      "\n",
      "episode 15, val func loss 1.2059394121170044\n",
      "\n",
      "episode 16, val func loss 1.0780816078186035\n",
      "\n",
      "Val func train loss in epoch 1:1.238091953098774\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.372208595275879\n",
      "\n",
      "episode 2, val func loss 1.2807246446609497\n",
      "\n",
      "episode 3, val func loss 1.282265543937683\n",
      "\n",
      "episode 4, val func loss 1.166780710220337\n",
      "\n",
      "episode 5, val func loss 1.3195369243621826\n",
      "\n",
      "episode 6, val func loss 1.2486178874969482\n",
      "\n",
      "episode 7, val func loss 1.181132197380066\n",
      "\n",
      "episode 8, val func loss 1.2533390522003174\n",
      "\n",
      "episode 9, val func loss 1.4101413488388062\n",
      "\n",
      "episode 10, val func loss 1.257699966430664\n",
      "\n",
      "episode 11, val func loss 1.2387139797210693\n",
      "\n",
      "episode 12, val func loss 1.130786657333374\n",
      "\n",
      "episode 13, val func loss 1.4947971105575562\n",
      "\n",
      "episode 14, val func loss 1.2782210111618042\n",
      "\n",
      "episode 15, val func loss 1.3095667362213135\n",
      "\n",
      "episode 16, val func loss 1.228447437286377\n",
      "\n",
      "Val func train loss in epoch 2:1.278311237692833\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.2288559675216675\n",
      "\n",
      "episode 2, val func loss 1.2092316150665283\n",
      "\n",
      "episode 3, val func loss 1.102780818939209\n",
      "\n",
      "episode 4, val func loss 1.2124301195144653\n",
      "\n",
      "episode 5, val func loss 1.2352991104125977\n",
      "\n",
      "episode 6, val func loss 1.410340666770935\n",
      "\n",
      "episode 7, val func loss 1.208038568496704\n",
      "\n",
      "episode 8, val func loss 1.25469172000885\n",
      "\n",
      "episode 9, val func loss 1.3320527076721191\n",
      "\n",
      "episode 10, val func loss 1.26145601272583\n",
      "\n",
      "episode 11, val func loss 1.158144474029541\n",
      "\n",
      "episode 12, val func loss 1.3041492700576782\n",
      "\n",
      "episode 13, val func loss 1.4079357385635376\n",
      "\n",
      "episode 14, val func loss 1.0698424577713013\n",
      "\n",
      "episode 15, val func loss 1.2082374095916748\n",
      "\n",
      "episode 16, val func loss 1.2654284238815308\n",
      "\n",
      "Val func train loss in epoch 3:1.2418071925640106\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.387473464012146\n",
      "\n",
      "episode 2, val func loss 1.093017578125\n",
      "\n",
      "episode 3, val func loss 1.3152315616607666\n",
      "\n",
      "episode 4, val func loss 1.292828917503357\n",
      "\n",
      "episode 5, val func loss 1.2086490392684937\n",
      "\n",
      "episode 6, val func loss 1.460439920425415\n",
      "\n",
      "episode 7, val func loss 1.230581283569336\n",
      "\n",
      "episode 8, val func loss 1.329285979270935\n",
      "\n",
      "episode 9, val func loss 1.347193717956543\n",
      "\n",
      "episode 10, val func loss 1.2969564199447632\n",
      "\n",
      "episode 11, val func loss 1.1879254579544067\n",
      "\n",
      "episode 12, val func loss 1.2561497688293457\n",
      "\n",
      "episode 13, val func loss 1.1652073860168457\n",
      "\n",
      "episode 14, val func loss 1.1503347158432007\n",
      "\n",
      "episode 15, val func loss 1.223146915435791\n",
      "\n",
      "episode 16, val func loss 1.4435558319091797\n",
      "\n",
      "Val func train loss in epoch 4:1.2742486223578453\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.2727129459381104\n",
      "\n",
      "episode 2, val func loss 1.204487919807434\n",
      "\n",
      "episode 3, val func loss 1.4082608222961426\n",
      "\n",
      "episode 4, val func loss 1.2511688470840454\n",
      "\n",
      "episode 5, val func loss 1.1862443685531616\n",
      "\n",
      "episode 6, val func loss 1.2526744604110718\n",
      "\n",
      "episode 7, val func loss 1.1855162382125854\n",
      "\n",
      "episode 8, val func loss 1.1171178817749023\n",
      "\n",
      "episode 9, val func loss 1.179524540901184\n",
      "\n",
      "episode 10, val func loss 1.4126222133636475\n",
      "\n",
      "episode 11, val func loss 1.2723804712295532\n",
      "\n",
      "episode 12, val func loss 1.2026374340057373\n",
      "\n",
      "episode 13, val func loss 1.312667727470398\n",
      "\n",
      "episode 14, val func loss 1.245566725730896\n",
      "\n",
      "episode 15, val func loss 1.3815208673477173\n",
      "\n",
      "episode 16, val func loss 1.2154181003570557\n",
      "\n",
      "Val func train loss in epoch 5:1.2562825977802277\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.2296780347824097\n",
      "\n",
      "episode 2, val func loss 1.287518858909607\n",
      "\n",
      "episode 3, val func loss 1.4072787761688232\n",
      "\n",
      "episode 4, val func loss 1.2146403789520264\n",
      "\n",
      "episode 5, val func loss 1.2256970405578613\n",
      "\n",
      "episode 6, val func loss 1.4381581544876099\n",
      "\n",
      "episode 7, val func loss 1.176927924156189\n",
      "\n",
      "episode 8, val func loss 1.4188168048858643\n",
      "\n",
      "episode 9, val func loss 1.2978452444076538\n",
      "\n",
      "episode 10, val func loss 1.1554704904556274\n",
      "\n",
      "episode 11, val func loss 1.211003065109253\n",
      "\n",
      "episode 12, val func loss 1.2640458345413208\n",
      "\n",
      "episode 13, val func loss 1.372294545173645\n",
      "\n",
      "episode 14, val func loss 1.209005355834961\n",
      "\n",
      "episode 15, val func loss 1.5081820487976074\n",
      "\n",
      "episode 16, val func loss 1.2423449754714966\n",
      "\n",
      "Val func train loss in epoch 6:1.2911817207932472\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.0873678922653198\n",
      "\n",
      "episode 2, val func loss 1.3584836721420288\n",
      "\n",
      "episode 3, val func loss 1.0132701396942139\n",
      "\n",
      "episode 4, val func loss 1.1210650205612183\n",
      "\n",
      "episode 5, val func loss 1.222937822341919\n",
      "\n",
      "episode 6, val func loss 1.1528311967849731\n",
      "\n",
      "episode 7, val func loss 1.2489873170852661\n",
      "\n",
      "episode 8, val func loss 1.1020376682281494\n",
      "\n",
      "episode 9, val func loss 1.101444959640503\n",
      "\n",
      "episode 10, val func loss 1.3154189586639404\n",
      "\n",
      "episode 11, val func loss 1.3005882501602173\n",
      "\n",
      "episode 12, val func loss 1.2185744047164917\n",
      "\n",
      "episode 13, val func loss 1.2270451784133911\n",
      "\n",
      "episode 14, val func loss 1.2671184539794922\n",
      "\n",
      "episode 15, val func loss 1.2915370464324951\n",
      "\n",
      "episode 16, val func loss 1.3284461498260498\n",
      "\n",
      "Val func train loss in epoch 7:1.2098221331834793\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.2338883876800537\n",
      "\n",
      "episode 2, val func loss 1.3329516649246216\n",
      "\n",
      "episode 3, val func loss 1.2830147743225098\n",
      "\n",
      "episode 4, val func loss 1.2814744710922241\n",
      "\n",
      "episode 5, val func loss 1.190266728401184\n",
      "\n",
      "episode 6, val func loss 1.2787724733352661\n",
      "\n",
      "episode 7, val func loss 1.3154834508895874\n",
      "\n",
      "episode 8, val func loss 1.3404287099838257\n",
      "\n",
      "episode 9, val func loss 1.231917381286621\n",
      "\n",
      "episode 10, val func loss 1.2896417379379272\n",
      "\n",
      "episode 11, val func loss 1.1142445802688599\n",
      "\n",
      "episode 12, val func loss 1.2142482995986938\n",
      "\n",
      "episode 13, val func loss 1.2807071208953857\n",
      "\n",
      "episode 14, val func loss 1.3041623830795288\n",
      "\n",
      "episode 15, val func loss 1.1591112613677979\n",
      "\n",
      "episode 16, val func loss 1.181301474571228\n",
      "\n",
      "Val func train loss in epoch 8:1.2519759312272072\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.1809446811676025\n",
      "\n",
      "episode 2, val func loss 1.119266152381897\n",
      "\n",
      "episode 3, val func loss 1.37859308719635\n",
      "\n",
      "episode 4, val func loss 1.1906483173370361\n",
      "\n",
      "episode 5, val func loss 1.263026237487793\n",
      "\n",
      "episode 6, val func loss 1.218806505203247\n",
      "\n",
      "episode 7, val func loss 1.4205855131149292\n",
      "\n",
      "episode 8, val func loss 1.2720820903778076\n",
      "\n",
      "episode 9, val func loss 1.3346258401870728\n",
      "\n",
      "episode 10, val func loss 1.2484426498413086\n",
      "\n",
      "episode 11, val func loss 1.2389016151428223\n",
      "\n",
      "episode 12, val func loss 1.424095869064331\n",
      "\n",
      "episode 13, val func loss 1.348793625831604\n",
      "\n",
      "episode 14, val func loss 1.1547023057937622\n",
      "\n",
      "episode 15, val func loss 1.2022441625595093\n",
      "\n",
      "episode 16, val func loss 1.2285977602005005\n",
      "\n",
      "Val func train loss in epoch 9:1.2640222758054733\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.2084333896636963\n",
      "\n",
      "episode 2, val func loss 1.4209153652191162\n",
      "\n",
      "episode 3, val func loss 1.2294474840164185\n",
      "\n",
      "episode 4, val func loss 1.3325004577636719\n",
      "\n",
      "episode 5, val func loss 1.1928293704986572\n",
      "\n",
      "episode 6, val func loss 1.2286288738250732\n",
      "\n",
      "episode 7, val func loss 1.2893626689910889\n",
      "\n",
      "episode 8, val func loss 1.2633099555969238\n",
      "\n",
      "episode 9, val func loss 1.244612455368042\n",
      "\n",
      "episode 10, val func loss 1.2952295541763306\n",
      "\n",
      "episode 11, val func loss 1.222746729850769\n",
      "\n",
      "episode 12, val func loss 1.1333317756652832\n",
      "\n",
      "episode 13, val func loss 1.4644185304641724\n",
      "\n",
      "episode 14, val func loss 1.3700928688049316\n",
      "\n",
      "episode 15, val func loss 1.2448883056640625\n",
      "\n",
      "episode 16, val func loss 1.319657564163208\n",
      "\n",
      "Val func train loss in epoch 10:1.2787753343582153\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.0537689924240112\n",
      "\n",
      "episode 2, val func loss 1.5742563009262085\n",
      "\n",
      "episode 3, val func loss 1.3384809494018555\n",
      "\n",
      "episode 4, val func loss 1.3596450090408325\n",
      "\n",
      "episode 5, val func loss 1.245730996131897\n",
      "\n",
      "episode 6, val func loss 1.3359085321426392\n",
      "\n",
      "episode 7, val func loss 1.3370227813720703\n",
      "\n",
      "episode 8, val func loss 1.2284197807312012\n",
      "\n",
      "episode 9, val func loss 1.3624475002288818\n",
      "\n",
      "episode 10, val func loss 1.1788684129714966\n",
      "\n",
      "episode 11, val func loss 1.3775081634521484\n",
      "\n",
      "episode 12, val func loss 1.235993504524231\n",
      "\n",
      "episode 13, val func loss 1.3712882995605469\n",
      "\n",
      "episode 14, val func loss 1.3226263523101807\n",
      "\n",
      "episode 15, val func loss 1.2923732995986938\n",
      "\n",
      "episode 16, val func loss 1.1176310777664185\n",
      "\n",
      "Val func train loss in epoch 11:1.295748122036457\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.1306266784667969\n",
      "\n",
      "episode 2, val func loss 1.270102620124817\n",
      "\n",
      "episode 3, val func loss 1.5554447174072266\n",
      "\n",
      "episode 4, val func loss 1.2821747064590454\n",
      "\n",
      "episode 5, val func loss 1.2824516296386719\n",
      "\n",
      "episode 6, val func loss 1.29900324344635\n",
      "\n",
      "episode 7, val func loss 1.2681764364242554\n",
      "\n",
      "episode 8, val func loss 1.2838289737701416\n",
      "\n",
      "episode 9, val func loss 1.3102060556411743\n",
      "\n",
      "episode 10, val func loss 1.2725765705108643\n",
      "\n",
      "episode 11, val func loss 1.386994481086731\n",
      "\n",
      "episode 12, val func loss 1.372942566871643\n",
      "\n",
      "episode 13, val func loss 1.1591910123825073\n",
      "\n",
      "episode 14, val func loss 1.3912197351455688\n",
      "\n",
      "episode 15, val func loss 1.0311393737792969\n",
      "\n",
      "episode 16, val func loss 1.378867745399475\n",
      "\n",
      "Val func train loss in epoch 12:1.2921841591596603\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.4599429368972778\n",
      "\n",
      "episode 2, val func loss 1.4630333185195923\n",
      "\n",
      "episode 3, val func loss 1.4570143222808838\n",
      "\n",
      "episode 4, val func loss 1.3215124607086182\n",
      "\n",
      "episode 5, val func loss 1.2138123512268066\n",
      "\n",
      "episode 6, val func loss 1.1565275192260742\n",
      "\n",
      "episode 7, val func loss 1.430403470993042\n",
      "\n",
      "episode 8, val func loss 1.3089629411697388\n",
      "\n",
      "episode 9, val func loss 1.1990493535995483\n",
      "\n",
      "episode 10, val func loss 1.3175599575042725\n",
      "\n",
      "episode 11, val func loss 1.2535228729248047\n",
      "\n",
      "episode 12, val func loss 1.238617181777954\n",
      "\n",
      "episode 13, val func loss 1.1989407539367676\n",
      "\n",
      "episode 14, val func loss 1.2283167839050293\n",
      "\n",
      "episode 15, val func loss 1.2915501594543457\n",
      "\n",
      "episode 16, val func loss 1.181447148323059\n",
      "\n",
      "Val func train loss in epoch 13:1.2950133457779884\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.1678823232650757\n",
      "\n",
      "episode 2, val func loss 1.140886902809143\n",
      "\n",
      "episode 3, val func loss 1.2716071605682373\n",
      "\n",
      "episode 4, val func loss 1.3077669143676758\n",
      "\n",
      "episode 5, val func loss 1.367078423500061\n",
      "\n",
      "episode 6, val func loss 1.09049654006958\n",
      "\n",
      "episode 7, val func loss 1.1842962503433228\n",
      "\n",
      "episode 8, val func loss 1.0202924013137817\n",
      "\n",
      "episode 9, val func loss 1.2384991645812988\n",
      "\n",
      "episode 10, val func loss 1.14340078830719\n",
      "\n",
      "episode 11, val func loss 1.3768861293792725\n",
      "\n",
      "episode 12, val func loss 1.261972427368164\n",
      "\n",
      "episode 13, val func loss 1.3279672861099243\n",
      "\n",
      "episode 14, val func loss 1.2167528867721558\n",
      "\n",
      "episode 15, val func loss 1.2846804857254028\n",
      "\n",
      "episode 16, val func loss 1.2032592296600342\n",
      "\n",
      "Val func train loss in epoch 14:1.22523283213377\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.0944422483444214\n",
      "\n",
      "episode 2, val func loss 1.3713836669921875\n",
      "\n",
      "episode 3, val func loss 1.104523777961731\n",
      "\n",
      "episode 4, val func loss 1.0797927379608154\n",
      "\n",
      "episode 5, val func loss 1.2122374773025513\n",
      "\n",
      "episode 6, val func loss 1.1984663009643555\n",
      "\n",
      "episode 7, val func loss 1.264650583267212\n",
      "\n",
      "episode 8, val func loss 1.2979294061660767\n",
      "\n",
      "episode 9, val func loss 1.1519232988357544\n",
      "\n",
      "episode 10, val func loss 1.162234902381897\n",
      "\n",
      "episode 11, val func loss 1.1460286378860474\n",
      "\n",
      "episode 12, val func loss 1.1388587951660156\n",
      "\n",
      "episode 13, val func loss 1.2243561744689941\n",
      "\n",
      "episode 14, val func loss 1.1606578826904297\n",
      "\n",
      "episode 15, val func loss 1.2887016534805298\n",
      "\n",
      "episode 16, val func loss 1.2677383422851562\n",
      "\n",
      "Val func train loss in epoch 15:1.197745367884636\n",
      "***********************TIME WAS 4.821879645188649 min*****************************\n",
      "\n",
      "**********************ROUND 44 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.6642231941223145\n",
      "\n",
      "episode 2, policy loss -3.6642231941223145\n",
      "\n",
      "episode 3, policy loss -3.6642234325408936\n",
      "\n",
      "episode 4, policy loss -3.6642231941223145\n",
      "\n",
      "episode 5, policy loss -3.6642234325408936\n",
      "\n",
      "episode 6, policy loss -3.6642231941223145\n",
      "\n",
      "episode 7, policy loss -3.6642231941223145\n",
      "\n",
      "episode 8, policy loss -3.6642231941223145\n",
      "\n",
      "episode 9, policy loss -3.6642231941223145\n",
      "\n",
      "episode 10, policy loss -3.6642231941223145\n",
      "\n",
      "episode 11, policy loss -3.6642231941223145\n",
      "\n",
      "episode 12, policy loss -3.6642231941223145\n",
      "\n",
      "episode 13, policy loss -3.6642227172851562\n",
      "\n",
      "episode 14, policy loss -3.6642231941223145\n",
      "\n",
      "episode 15, policy loss -3.6642234325408936\n",
      "\n",
      "episode 16, policy loss -3.6642234325408936\n",
      "\n",
      "Policy train loss in epoch 0:-3.664223223924637\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.6642231941223145\n",
      "\n",
      "episode 2, policy loss -3.6642234325408936\n",
      "\n",
      "episode 3, policy loss -3.6642234325408936\n",
      "\n",
      "episode 4, policy loss -3.6642231941223145\n",
      "\n",
      "episode 5, policy loss -3.6642231941223145\n",
      "\n",
      "episode 6, policy loss -3.6642234325408936\n",
      "\n",
      "episode 7, policy loss -3.6642231941223145\n",
      "\n",
      "episode 8, policy loss -3.6642231941223145\n",
      "\n",
      "episode 9, policy loss -3.6642227172851562\n",
      "\n",
      "episode 10, policy loss -3.6642231941223145\n",
      "\n",
      "episode 11, policy loss -3.6642231941223145\n",
      "\n",
      "episode 12, policy loss -3.6642234325408936\n",
      "\n",
      "episode 13, policy loss -3.6642231941223145\n",
      "\n",
      "episode 14, policy loss -3.6642231941223145\n",
      "\n",
      "episode 15, policy loss -3.6642231941223145\n",
      "\n",
      "episode 16, policy loss -3.6642231941223145\n",
      "\n",
      "Policy train loss in epoch 1:-3.664223223924637\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.6642234325408936\n",
      "\n",
      "episode 2, policy loss -3.6642231941223145\n",
      "\n",
      "episode 3, policy loss -3.6642227172851562\n",
      "\n",
      "episode 4, policy loss -3.6642234325408936\n",
      "\n",
      "episode 5, policy loss -3.6642231941223145\n",
      "\n",
      "episode 6, policy loss -3.6642231941223145\n",
      "\n",
      "episode 7, policy loss -3.6642231941223145\n",
      "\n",
      "episode 8, policy loss -3.6642231941223145\n",
      "\n",
      "episode 9, policy loss -3.6642231941223145\n",
      "\n",
      "episode 10, policy loss -3.6642231941223145\n",
      "\n",
      "episode 11, policy loss -3.6642231941223145\n",
      "\n",
      "episode 12, policy loss -3.6642231941223145\n",
      "\n",
      "episode 13, policy loss -3.6642231941223145\n",
      "\n",
      "episode 14, policy loss -3.6642234325408936\n",
      "\n",
      "episode 15, policy loss -3.6642234325408936\n",
      "\n",
      "episode 16, policy loss -3.6642231941223145\n",
      "\n",
      "Policy train loss in epoch 2:-3.664223223924637\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.6642231941223145\n",
      "\n",
      "episode 2, policy loss -3.6642227172851562\n",
      "\n",
      "episode 3, policy loss -3.6642231941223145\n",
      "\n",
      "episode 4, policy loss -3.6642231941223145\n",
      "\n",
      "episode 5, policy loss -3.6642234325408936\n",
      "\n",
      "episode 6, policy loss -3.6642231941223145\n",
      "\n",
      "episode 7, policy loss -3.6642231941223145\n",
      "\n",
      "episode 8, policy loss -3.6642231941223145\n",
      "\n",
      "episode 9, policy loss -3.6642231941223145\n",
      "\n",
      "episode 10, policy loss -3.6642231941223145\n",
      "\n",
      "episode 11, policy loss -3.6642231941223145\n",
      "\n",
      "episode 12, policy loss -3.6642234325408936\n",
      "\n",
      "episode 13, policy loss -3.6642231941223145\n",
      "\n",
      "episode 14, policy loss -3.6642234325408936\n",
      "\n",
      "episode 15, policy loss -3.6642234325408936\n",
      "\n",
      "episode 16, policy loss -3.6642231941223145\n",
      "\n",
      "Policy train loss in epoch 3:-3.664223223924637\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.1611522436141968\n",
      "\n",
      "episode 2, val func loss 1.3311960697174072\n",
      "\n",
      "episode 3, val func loss 1.201644778251648\n",
      "\n",
      "episode 4, val func loss 1.2475241422653198\n",
      "\n",
      "episode 5, val func loss 1.3006104230880737\n",
      "\n",
      "episode 6, val func loss 1.2309324741363525\n",
      "\n",
      "episode 7, val func loss 1.4419721364974976\n",
      "\n",
      "episode 8, val func loss 1.440566897392273\n",
      "\n",
      "episode 9, val func loss 1.4853965044021606\n",
      "\n",
      "episode 10, val func loss 1.1500619649887085\n",
      "\n",
      "episode 11, val func loss 1.2365946769714355\n",
      "\n",
      "episode 12, val func loss 1.2847635746002197\n",
      "\n",
      "episode 13, val func loss 1.3680435419082642\n",
      "\n",
      "episode 14, val func loss 1.204105257987976\n",
      "\n",
      "episode 15, val func loss 1.262325644493103\n",
      "\n",
      "episode 16, val func loss 1.4349271059036255\n",
      "\n",
      "Val func train loss in epoch 0:1.2988635897636414\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.2444299459457397\n",
      "\n",
      "episode 2, val func loss 1.2717827558517456\n",
      "\n",
      "episode 3, val func loss 1.420583724975586\n",
      "\n",
      "episode 4, val func loss 1.2673293352127075\n",
      "\n",
      "episode 5, val func loss 1.3689862489700317\n",
      "\n",
      "episode 6, val func loss 1.1801393032073975\n",
      "\n",
      "episode 7, val func loss 1.2115558385849\n",
      "\n",
      "episode 8, val func loss 1.1994974613189697\n",
      "\n",
      "episode 9, val func loss 1.275937557220459\n",
      "\n",
      "episode 10, val func loss 1.2053109407424927\n",
      "\n",
      "episode 11, val func loss 1.3119803667068481\n",
      "\n",
      "episode 12, val func loss 1.231204867362976\n",
      "\n",
      "episode 13, val func loss 1.1253749132156372\n",
      "\n",
      "episode 14, val func loss 1.1749340295791626\n",
      "\n",
      "episode 15, val func loss 1.0532848834991455\n",
      "\n",
      "episode 16, val func loss 1.2058708667755127\n",
      "\n",
      "Val func train loss in epoch 1:1.234262689948082\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.1191970109939575\n",
      "\n",
      "episode 2, val func loss 1.2303929328918457\n",
      "\n",
      "episode 3, val func loss 1.22702157497406\n",
      "\n",
      "episode 4, val func loss 1.0474392175674438\n",
      "\n",
      "episode 5, val func loss 1.0016686916351318\n",
      "\n",
      "episode 6, val func loss 1.1514904499053955\n",
      "\n",
      "episode 7, val func loss 1.0377187728881836\n",
      "\n",
      "episode 8, val func loss 1.1460665464401245\n",
      "\n",
      "episode 9, val func loss 1.010277271270752\n",
      "\n",
      "episode 10, val func loss 1.1187083721160889\n",
      "\n",
      "episode 11, val func loss 1.188010334968567\n",
      "\n",
      "episode 12, val func loss 1.0777727365493774\n",
      "\n",
      "episode 13, val func loss 1.2832351922988892\n",
      "\n",
      "episode 14, val func loss 1.1900951862335205\n",
      "\n",
      "episode 15, val func loss 1.1077048778533936\n",
      "\n",
      "episode 16, val func loss 1.124143362045288\n",
      "\n",
      "Val func train loss in epoch 2:1.1288089081645012\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.0024276971817017\n",
      "\n",
      "episode 2, val func loss 1.1075620651245117\n",
      "\n",
      "episode 3, val func loss 1.204073429107666\n",
      "\n",
      "episode 4, val func loss 1.2793872356414795\n",
      "\n",
      "episode 5, val func loss 1.1807054281234741\n",
      "\n",
      "episode 6, val func loss 1.0791170597076416\n",
      "\n",
      "episode 7, val func loss 1.3734421730041504\n",
      "\n",
      "episode 8, val func loss 1.2167527675628662\n",
      "\n",
      "episode 9, val func loss 1.1429908275604248\n",
      "\n",
      "episode 10, val func loss 1.234513759613037\n",
      "\n",
      "episode 11, val func loss 1.0959587097167969\n",
      "\n",
      "episode 12, val func loss 1.2655271291732788\n",
      "\n",
      "episode 13, val func loss 1.3180640935897827\n",
      "\n",
      "episode 14, val func loss 1.3121070861816406\n",
      "\n",
      "episode 15, val func loss 1.3075315952301025\n",
      "\n",
      "episode 16, val func loss 1.2191617488861084\n",
      "\n",
      "Val func train loss in epoch 3:1.2087076753377914\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.186028242111206\n",
      "\n",
      "episode 2, val func loss 1.3659487962722778\n",
      "\n",
      "episode 3, val func loss 1.270418405532837\n",
      "\n",
      "episode 4, val func loss 1.2816482782363892\n",
      "\n",
      "episode 5, val func loss 1.1806129217147827\n",
      "\n",
      "episode 6, val func loss 1.2067312002182007\n",
      "\n",
      "episode 7, val func loss 1.1976546049118042\n",
      "\n",
      "episode 8, val func loss 1.2179245948791504\n",
      "\n",
      "episode 9, val func loss 1.227378010749817\n",
      "\n",
      "episode 10, val func loss 1.2724769115447998\n",
      "\n",
      "episode 11, val func loss 1.4460625648498535\n",
      "\n",
      "episode 12, val func loss 1.2178035974502563\n",
      "\n",
      "episode 13, val func loss 1.5055214166641235\n",
      "\n",
      "episode 14, val func loss 1.2180331945419312\n",
      "\n",
      "episode 15, val func loss 1.2908821105957031\n",
      "\n",
      "episode 16, val func loss 1.1651531457901\n",
      "\n",
      "Val func train loss in epoch 4:1.265642374753952\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.10555899143219\n",
      "\n",
      "episode 2, val func loss 1.1959877014160156\n",
      "\n",
      "episode 3, val func loss 1.2826919555664062\n",
      "\n",
      "episode 4, val func loss 1.230685830116272\n",
      "\n",
      "episode 5, val func loss 1.1371159553527832\n",
      "\n",
      "episode 6, val func loss 1.1451605558395386\n",
      "\n",
      "episode 7, val func loss 1.3923022747039795\n",
      "\n",
      "episode 8, val func loss 1.298966407775879\n",
      "\n",
      "episode 9, val func loss 1.0077966451644897\n",
      "\n",
      "episode 10, val func loss 1.178520679473877\n",
      "\n",
      "episode 11, val func loss 1.1499592065811157\n",
      "\n",
      "episode 12, val func loss 1.1565176248550415\n",
      "\n",
      "episode 13, val func loss 1.136883020401001\n",
      "\n",
      "episode 14, val func loss 1.4059886932373047\n",
      "\n",
      "episode 15, val func loss 1.1597880125045776\n",
      "\n",
      "episode 16, val func loss 1.3688430786132812\n",
      "\n",
      "Val func train loss in epoch 5:1.2095479145646095\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.1377133131027222\n",
      "\n",
      "episode 2, val func loss 1.063077688217163\n",
      "\n",
      "episode 3, val func loss 1.342365026473999\n",
      "\n",
      "episode 4, val func loss 1.2892481088638306\n",
      "\n",
      "episode 5, val func loss 1.4985144138336182\n",
      "\n",
      "episode 6, val func loss 1.2656044960021973\n",
      "\n",
      "episode 7, val func loss 1.2924138307571411\n",
      "\n",
      "episode 8, val func loss 1.1763684749603271\n",
      "\n",
      "episode 9, val func loss 1.3157893419265747\n",
      "\n",
      "episode 10, val func loss 1.1859406232833862\n",
      "\n",
      "episode 11, val func loss 1.1856127977371216\n",
      "\n",
      "episode 12, val func loss 1.2622578144073486\n",
      "\n",
      "episode 13, val func loss 1.371778130531311\n",
      "\n",
      "episode 14, val func loss 1.1314364671707153\n",
      "\n",
      "episode 15, val func loss 1.1900601387023926\n",
      "\n",
      "episode 16, val func loss 1.2797155380249023\n",
      "\n",
      "Val func train loss in epoch 6:1.249243512749672\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.2255401611328125\n",
      "\n",
      "episode 2, val func loss 1.2449599504470825\n",
      "\n",
      "episode 3, val func loss 1.264979600906372\n",
      "\n",
      "episode 4, val func loss 1.2538563013076782\n",
      "\n",
      "episode 5, val func loss 1.1435816287994385\n",
      "\n",
      "episode 6, val func loss 1.3369369506835938\n",
      "\n",
      "episode 7, val func loss 1.492636799812317\n",
      "\n",
      "episode 8, val func loss 1.2910044193267822\n",
      "\n",
      "episode 9, val func loss 1.3715722560882568\n",
      "\n",
      "episode 10, val func loss 1.1771831512451172\n",
      "\n",
      "episode 11, val func loss 1.198067307472229\n",
      "\n",
      "episode 12, val func loss 1.3374532461166382\n",
      "\n",
      "episode 13, val func loss 1.3761241436004639\n",
      "\n",
      "episode 14, val func loss 1.2946438789367676\n",
      "\n",
      "episode 15, val func loss 1.1197034120559692\n",
      "\n",
      "episode 16, val func loss 1.2776401042938232\n",
      "\n",
      "Val func train loss in epoch 7:1.2753677070140839\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.1731960773468018\n",
      "\n",
      "episode 2, val func loss 1.1569510698318481\n",
      "\n",
      "episode 3, val func loss 1.1855911016464233\n",
      "\n",
      "episode 4, val func loss 1.224875569343567\n",
      "\n",
      "episode 5, val func loss 1.3641536235809326\n",
      "\n",
      "episode 6, val func loss 1.225655198097229\n",
      "\n",
      "episode 7, val func loss 1.1474088430404663\n",
      "\n",
      "episode 8, val func loss 1.189785122871399\n",
      "\n",
      "episode 9, val func loss 1.2727513313293457\n",
      "\n",
      "episode 10, val func loss 1.0825453996658325\n",
      "\n",
      "episode 11, val func loss 1.3759456872940063\n",
      "\n",
      "episode 12, val func loss 1.1419665813446045\n",
      "\n",
      "episode 13, val func loss 1.1473405361175537\n",
      "\n",
      "episode 14, val func loss 1.239558219909668\n",
      "\n",
      "episode 15, val func loss 1.240290880203247\n",
      "\n",
      "episode 16, val func loss 1.3066688776016235\n",
      "\n",
      "Val func train loss in epoch 8:1.2171677574515343\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.228009581565857\n",
      "\n",
      "episode 2, val func loss 1.10204017162323\n",
      "\n",
      "episode 3, val func loss 1.0702736377716064\n",
      "\n",
      "episode 4, val func loss 1.40848708152771\n",
      "\n",
      "episode 5, val func loss 1.1507458686828613\n",
      "\n",
      "episode 6, val func loss 1.2940939664840698\n",
      "\n",
      "episode 7, val func loss 1.186209797859192\n",
      "\n",
      "episode 8, val func loss 1.283961534500122\n",
      "\n",
      "episode 9, val func loss 0.9124017953872681\n",
      "\n",
      "episode 10, val func loss 1.2088013887405396\n",
      "\n",
      "episode 11, val func loss 1.046796441078186\n",
      "\n",
      "episode 12, val func loss 1.2342461347579956\n",
      "\n",
      "episode 13, val func loss 1.2122379541397095\n",
      "\n",
      "episode 14, val func loss 1.4040673971176147\n",
      "\n",
      "episode 15, val func loss 1.1684530973434448\n",
      "\n",
      "episode 16, val func loss 1.0950987339019775\n",
      "\n",
      "Val func train loss in epoch 9:1.1878702864050865\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.0139837265014648\n",
      "\n",
      "episode 2, val func loss 1.2369877099990845\n",
      "\n",
      "episode 3, val func loss 1.1529221534729004\n",
      "\n",
      "episode 4, val func loss 1.0993143320083618\n",
      "\n",
      "episode 5, val func loss 1.0980292558670044\n",
      "\n",
      "episode 6, val func loss 1.3147552013397217\n",
      "\n",
      "episode 7, val func loss 1.1315757036209106\n",
      "\n",
      "episode 8, val func loss 1.1865355968475342\n",
      "\n",
      "episode 9, val func loss 1.2543580532073975\n",
      "\n",
      "episode 10, val func loss 1.1757594347000122\n",
      "\n",
      "episode 11, val func loss 1.3240207433700562\n",
      "\n",
      "episode 12, val func loss 1.1085618734359741\n",
      "\n",
      "episode 13, val func loss 1.2103720903396606\n",
      "\n",
      "episode 14, val func loss 1.2209789752960205\n",
      "\n",
      "episode 15, val func loss 1.2919657230377197\n",
      "\n",
      "episode 16, val func loss 1.197224736213684\n",
      "\n",
      "Val func train loss in epoch 10:1.1885840818285942\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.1444506645202637\n",
      "\n",
      "episode 2, val func loss 1.228529691696167\n",
      "\n",
      "episode 3, val func loss 1.28970468044281\n",
      "\n",
      "episode 4, val func loss 1.1937483549118042\n",
      "\n",
      "episode 5, val func loss 0.9947699904441833\n",
      "\n",
      "episode 6, val func loss 1.2639775276184082\n",
      "\n",
      "episode 7, val func loss 1.329227328300476\n",
      "\n",
      "episode 8, val func loss 1.1025248765945435\n",
      "\n",
      "episode 9, val func loss 1.219117283821106\n",
      "\n",
      "episode 10, val func loss 1.181196928024292\n",
      "\n",
      "episode 11, val func loss 1.1689858436584473\n",
      "\n",
      "episode 12, val func loss 1.0819085836410522\n",
      "\n",
      "episode 13, val func loss 1.3697116374969482\n",
      "\n",
      "episode 14, val func loss 1.0927729606628418\n",
      "\n",
      "episode 15, val func loss 1.2640408277511597\n",
      "\n",
      "episode 16, val func loss 1.343186855316162\n",
      "\n",
      "Val func train loss in epoch 11:1.2042408771812916\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.2228155136108398\n",
      "\n",
      "episode 2, val func loss 1.1634608507156372\n",
      "\n",
      "episode 3, val func loss 1.1403660774230957\n",
      "\n",
      "episode 4, val func loss 1.2466154098510742\n",
      "\n",
      "episode 5, val func loss 1.1697709560394287\n",
      "\n",
      "episode 6, val func loss 0.9657403230667114\n",
      "\n",
      "episode 7, val func loss 1.0457267761230469\n",
      "\n",
      "episode 8, val func loss 1.05709969997406\n",
      "\n",
      "episode 9, val func loss 1.2762043476104736\n",
      "\n",
      "episode 10, val func loss 0.94026118516922\n",
      "\n",
      "episode 11, val func loss 1.2309253215789795\n",
      "\n",
      "episode 12, val func loss 1.2401459217071533\n",
      "\n",
      "episode 13, val func loss 1.2345991134643555\n",
      "\n",
      "episode 14, val func loss 1.2037725448608398\n",
      "\n",
      "episode 15, val func loss 1.1001427173614502\n",
      "\n",
      "episode 16, val func loss 1.2099688053131104\n",
      "\n",
      "Val func train loss in epoch 12:1.1529759727418423\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.1903947591781616\n",
      "\n",
      "episode 2, val func loss 1.143950343132019\n",
      "\n",
      "episode 3, val func loss 1.1676466464996338\n",
      "\n",
      "episode 4, val func loss 1.1097458600997925\n",
      "\n",
      "episode 5, val func loss 1.3657578229904175\n",
      "\n",
      "episode 6, val func loss 1.0068705081939697\n",
      "\n",
      "episode 7, val func loss 1.0700627565383911\n",
      "\n",
      "episode 8, val func loss 1.0660852193832397\n",
      "\n",
      "episode 9, val func loss 1.035475254058838\n",
      "\n",
      "episode 10, val func loss 1.1028972864151\n",
      "\n",
      "episode 11, val func loss 1.06675124168396\n",
      "\n",
      "episode 12, val func loss 1.1455823183059692\n",
      "\n",
      "episode 13, val func loss 1.019070029258728\n",
      "\n",
      "episode 14, val func loss 1.0982071161270142\n",
      "\n",
      "episode 15, val func loss 1.0805096626281738\n",
      "\n",
      "episode 16, val func loss 1.2213635444641113\n",
      "\n",
      "Val func train loss in epoch 13:1.118148148059845\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.0859413146972656\n",
      "\n",
      "episode 2, val func loss 1.1902819871902466\n",
      "\n",
      "episode 3, val func loss 1.009684681892395\n",
      "\n",
      "episode 4, val func loss 1.157606840133667\n",
      "\n",
      "episode 5, val func loss 1.048269510269165\n",
      "\n",
      "episode 6, val func loss 0.9922764897346497\n",
      "\n",
      "episode 7, val func loss 1.101111650466919\n",
      "\n",
      "episode 8, val func loss 1.0567653179168701\n",
      "\n",
      "episode 9, val func loss 1.227935791015625\n",
      "\n",
      "episode 10, val func loss 1.0842646360397339\n",
      "\n",
      "episode 11, val func loss 1.1264632940292358\n",
      "\n",
      "episode 12, val func loss 1.192470908164978\n",
      "\n",
      "episode 13, val func loss 1.1219632625579834\n",
      "\n",
      "episode 14, val func loss 1.218678593635559\n",
      "\n",
      "episode 15, val func loss 1.027320384979248\n",
      "\n",
      "episode 16, val func loss 1.0834226608276367\n",
      "\n",
      "Val func train loss in epoch 14:1.1077785827219486\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.9518960118293762\n",
      "\n",
      "episode 2, val func loss 1.2472273111343384\n",
      "\n",
      "episode 3, val func loss 1.1354302167892456\n",
      "\n",
      "episode 4, val func loss 1.2146559953689575\n",
      "\n",
      "episode 5, val func loss 1.0372984409332275\n",
      "\n",
      "episode 6, val func loss 1.1291100978851318\n",
      "\n",
      "episode 7, val func loss 1.1890426874160767\n",
      "\n",
      "episode 8, val func loss 1.3185886144638062\n",
      "\n",
      "episode 9, val func loss 1.1652752161026\n",
      "\n",
      "episode 10, val func loss 1.179919958114624\n",
      "\n",
      "episode 11, val func loss 0.9057976603507996\n",
      "\n",
      "episode 12, val func loss 1.0959430932998657\n",
      "\n",
      "episode 13, val func loss 1.0642353296279907\n",
      "\n",
      "episode 14, val func loss 0.9308966994285583\n",
      "\n",
      "episode 15, val func loss 0.9752177596092224\n",
      "\n",
      "episode 16, val func loss 1.182285189628601\n",
      "\n",
      "Val func train loss in epoch 15:1.1076762676239014\n",
      "***********************TIME WAS 4.818337817986806 min*****************************\n",
      "\n",
      "**********************ROUND 45 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.665116310119629\n",
      "\n",
      "episode 2, policy loss 1.6651172637939453\n",
      "\n",
      "episode 3, policy loss 1.6651155948638916\n",
      "\n",
      "episode 4, policy loss 1.6651153564453125\n",
      "\n",
      "episode 5, policy loss 1.665117621421814\n",
      "\n",
      "episode 6, policy loss 1.6651171445846558\n",
      "\n",
      "episode 7, policy loss 1.6651170253753662\n",
      "\n",
      "episode 8, policy loss 1.66511869430542\n",
      "\n",
      "episode 9, policy loss 1.6651153564453125\n",
      "\n",
      "episode 10, policy loss 1.6651153564453125\n",
      "\n",
      "episode 11, policy loss 1.6651157140731812\n",
      "\n",
      "episode 12, policy loss 1.665117621421814\n",
      "\n",
      "episode 13, policy loss 1.665116786956787\n",
      "\n",
      "episode 14, policy loss 1.6651151180267334\n",
      "\n",
      "episode 15, policy loss 1.6651175022125244\n",
      "\n",
      "episode 16, policy loss 1.6651194095611572\n",
      "\n",
      "Policy train loss in epoch 0:1.6651167422533035\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.66511869430542\n",
      "\n",
      "episode 2, policy loss 1.6651175022125244\n",
      "\n",
      "episode 3, policy loss 1.6651194095611572\n",
      "\n",
      "episode 4, policy loss 1.6651151180267334\n",
      "\n",
      "episode 5, policy loss 1.665117621421814\n",
      "\n",
      "episode 6, policy loss 1.6651155948638916\n",
      "\n",
      "episode 7, policy loss 1.6651170253753662\n",
      "\n",
      "episode 8, policy loss 1.665116310119629\n",
      "\n",
      "episode 9, policy loss 1.6651153564453125\n",
      "\n",
      "episode 10, policy loss 1.6651153564453125\n",
      "\n",
      "episode 11, policy loss 1.665117621421814\n",
      "\n",
      "episode 12, policy loss 1.665116786956787\n",
      "\n",
      "episode 13, policy loss 1.6651157140731812\n",
      "\n",
      "episode 14, policy loss 1.6651172637939453\n",
      "\n",
      "episode 15, policy loss 1.6651171445846558\n",
      "\n",
      "episode 16, policy loss 1.6651153564453125\n",
      "\n",
      "Policy train loss in epoch 1:1.6651167422533035\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.6651151180267334\n",
      "\n",
      "episode 2, policy loss 1.6651175022125244\n",
      "\n",
      "episode 3, policy loss 1.66511869430542\n",
      "\n",
      "episode 4, policy loss 1.6651153564453125\n",
      "\n",
      "episode 5, policy loss 1.665116786956787\n",
      "\n",
      "episode 6, policy loss 1.6651155948638916\n",
      "\n",
      "episode 7, policy loss 1.6651153564453125\n",
      "\n",
      "episode 8, policy loss 1.6651157140731812\n",
      "\n",
      "episode 9, policy loss 1.665117621421814\n",
      "\n",
      "episode 10, policy loss 1.6651194095611572\n",
      "\n",
      "episode 11, policy loss 1.6651172637939453\n",
      "\n",
      "episode 12, policy loss 1.6651171445846558\n",
      "\n",
      "episode 13, policy loss 1.665116310119629\n",
      "\n",
      "episode 14, policy loss 1.6651153564453125\n",
      "\n",
      "episode 15, policy loss 1.665117621421814\n",
      "\n",
      "episode 16, policy loss 1.6651170253753662\n",
      "\n",
      "Policy train loss in epoch 2:1.6651167422533035\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.6651170253753662\n",
      "\n",
      "episode 2, policy loss 1.6651175022125244\n",
      "\n",
      "episode 3, policy loss 1.6651153564453125\n",
      "\n",
      "episode 4, policy loss 1.665117621421814\n",
      "\n",
      "episode 5, policy loss 1.6651155948638916\n",
      "\n",
      "episode 6, policy loss 1.6651157140731812\n",
      "\n",
      "episode 7, policy loss 1.66511869430542\n",
      "\n",
      "episode 8, policy loss 1.6651151180267334\n",
      "\n",
      "episode 9, policy loss 1.6651153564453125\n",
      "\n",
      "episode 10, policy loss 1.6651172637939453\n",
      "\n",
      "episode 11, policy loss 1.665116310119629\n",
      "\n",
      "episode 12, policy loss 1.6651153564453125\n",
      "\n",
      "episode 13, policy loss 1.665117621421814\n",
      "\n",
      "episode 14, policy loss 1.665116786956787\n",
      "\n",
      "episode 15, policy loss 1.6651171445846558\n",
      "\n",
      "episode 16, policy loss 1.6651194095611572\n",
      "\n",
      "Policy train loss in epoch 3:1.6651167422533035\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.0723832845687866\n",
      "\n",
      "episode 2, val func loss 1.0449565649032593\n",
      "\n",
      "episode 3, val func loss 0.9951449036598206\n",
      "\n",
      "episode 4, val func loss 0.9720845818519592\n",
      "\n",
      "episode 5, val func loss 1.0998682975769043\n",
      "\n",
      "episode 6, val func loss 1.0293272733688354\n",
      "\n",
      "episode 7, val func loss 0.9964380860328674\n",
      "\n",
      "episode 8, val func loss 1.1450022459030151\n",
      "\n",
      "episode 9, val func loss 0.9267946481704712\n",
      "\n",
      "episode 10, val func loss 1.023302674293518\n",
      "\n",
      "episode 11, val func loss 0.9374967217445374\n",
      "\n",
      "episode 12, val func loss 1.1984988451004028\n",
      "\n",
      "episode 13, val func loss 0.9712464213371277\n",
      "\n",
      "episode 14, val func loss 1.137515902519226\n",
      "\n",
      "episode 15, val func loss 0.8923406600952148\n",
      "\n",
      "episode 16, val func loss 1.2976858615875244\n",
      "\n",
      "Val func train loss in epoch 0:1.046255435794592\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.931892991065979\n",
      "\n",
      "episode 2, val func loss 1.0085355043411255\n",
      "\n",
      "episode 3, val func loss 1.1246956586837769\n",
      "\n",
      "episode 4, val func loss 1.1040759086608887\n",
      "\n",
      "episode 5, val func loss 1.225250482559204\n",
      "\n",
      "episode 6, val func loss 0.9659938216209412\n",
      "\n",
      "episode 7, val func loss 1.0623888969421387\n",
      "\n",
      "episode 8, val func loss 1.0364480018615723\n",
      "\n",
      "episode 9, val func loss 1.0982228517532349\n",
      "\n",
      "episode 10, val func loss 1.0701947212219238\n",
      "\n",
      "episode 11, val func loss 1.260879635810852\n",
      "\n",
      "episode 12, val func loss 1.0325976610183716\n",
      "\n",
      "episode 13, val func loss 0.8804367780685425\n",
      "\n",
      "episode 14, val func loss 1.255871057510376\n",
      "\n",
      "episode 15, val func loss 1.0981297492980957\n",
      "\n",
      "episode 16, val func loss 1.1065409183502197\n",
      "\n",
      "Val func train loss in epoch 1:1.0788846649229527\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.1890581846237183\n",
      "\n",
      "episode 2, val func loss 1.0871608257293701\n",
      "\n",
      "episode 3, val func loss 1.0310931205749512\n",
      "\n",
      "episode 4, val func loss 1.126015067100525\n",
      "\n",
      "episode 5, val func loss 1.042711853981018\n",
      "\n",
      "episode 6, val func loss 1.0002466440200806\n",
      "\n",
      "episode 7, val func loss 0.9012303948402405\n",
      "\n",
      "episode 8, val func loss 1.187505841255188\n",
      "\n",
      "episode 9, val func loss 0.9979701638221741\n",
      "\n",
      "episode 10, val func loss 1.1632287502288818\n",
      "\n",
      "episode 11, val func loss 1.062226414680481\n",
      "\n",
      "episode 12, val func loss 1.0448384284973145\n",
      "\n",
      "episode 13, val func loss 1.1674398183822632\n",
      "\n",
      "episode 14, val func loss 0.9497503638267517\n",
      "\n",
      "episode 15, val func loss 1.14057457447052\n",
      "\n",
      "episode 16, val func loss 1.1927140951156616\n",
      "\n",
      "Val func train loss in epoch 2:1.0802352838218212\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.9618940353393555\n",
      "\n",
      "episode 2, val func loss 1.0556460618972778\n",
      "\n",
      "episode 3, val func loss 1.10568368434906\n",
      "\n",
      "episode 4, val func loss 1.1364848613739014\n",
      "\n",
      "episode 5, val func loss 0.9634122848510742\n",
      "\n",
      "episode 6, val func loss 0.9753031730651855\n",
      "\n",
      "episode 7, val func loss 1.098238229751587\n",
      "\n",
      "episode 8, val func loss 1.0189502239227295\n",
      "\n",
      "episode 9, val func loss 1.1737266778945923\n",
      "\n",
      "episode 10, val func loss 1.0230869054794312\n",
      "\n",
      "episode 11, val func loss 1.0647234916687012\n",
      "\n",
      "episode 12, val func loss 1.0183881521224976\n",
      "\n",
      "episode 13, val func loss 0.85798180103302\n",
      "\n",
      "episode 14, val func loss 0.9912648797035217\n",
      "\n",
      "episode 15, val func loss 1.0442384481430054\n",
      "\n",
      "episode 16, val func loss 1.0744742155075073\n",
      "\n",
      "Val func train loss in epoch 3:1.035218570381403\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.0586050748825073\n",
      "\n",
      "episode 2, val func loss 1.0498325824737549\n",
      "\n",
      "episode 3, val func loss 0.8803044557571411\n",
      "\n",
      "episode 4, val func loss 1.0375949144363403\n",
      "\n",
      "episode 5, val func loss 1.0120023488998413\n",
      "\n",
      "episode 6, val func loss 1.0940920114517212\n",
      "\n",
      "episode 7, val func loss 1.0061111450195312\n",
      "\n",
      "episode 8, val func loss 1.1660957336425781\n",
      "\n",
      "episode 9, val func loss 1.0059884786605835\n",
      "\n",
      "episode 10, val func loss 1.18006432056427\n",
      "\n",
      "episode 11, val func loss 1.0841007232666016\n",
      "\n",
      "episode 12, val func loss 0.9453118443489075\n",
      "\n",
      "episode 13, val func loss 1.0523418188095093\n",
      "\n",
      "episode 14, val func loss 1.0548590421676636\n",
      "\n",
      "episode 15, val func loss 1.0285637378692627\n",
      "\n",
      "episode 16, val func loss 1.0777859687805176\n",
      "\n",
      "Val func train loss in epoch 4:1.0458533875644207\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.0306637287139893\n",
      "\n",
      "episode 2, val func loss 0.9671644568443298\n",
      "\n",
      "episode 3, val func loss 1.0970147848129272\n",
      "\n",
      "episode 4, val func loss 0.8531656265258789\n",
      "\n",
      "episode 5, val func loss 0.970872163772583\n",
      "\n",
      "episode 6, val func loss 1.128574013710022\n",
      "\n",
      "episode 7, val func loss 1.0788434743881226\n",
      "\n",
      "episode 8, val func loss 0.9706558585166931\n",
      "\n",
      "episode 9, val func loss 1.0330075025558472\n",
      "\n",
      "episode 10, val func loss 0.9234063625335693\n",
      "\n",
      "episode 11, val func loss 0.8867055177688599\n",
      "\n",
      "episode 12, val func loss 1.107666015625\n",
      "\n",
      "episode 13, val func loss 1.0330886840820312\n",
      "\n",
      "episode 14, val func loss 0.9546124935150146\n",
      "\n",
      "episode 15, val func loss 0.9890576601028442\n",
      "\n",
      "episode 16, val func loss 1.0210654735565186\n",
      "\n",
      "Val func train loss in epoch 5:1.0028477385640144\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.816313624382019\n",
      "\n",
      "episode 2, val func loss 0.9307589530944824\n",
      "\n",
      "episode 3, val func loss 1.0428588390350342\n",
      "\n",
      "episode 4, val func loss 1.0916799306869507\n",
      "\n",
      "episode 5, val func loss 1.133414387702942\n",
      "\n",
      "episode 6, val func loss 1.1251797676086426\n",
      "\n",
      "episode 7, val func loss 1.1282620429992676\n",
      "\n",
      "episode 8, val func loss 0.933496356010437\n",
      "\n",
      "episode 9, val func loss 0.98146653175354\n",
      "\n",
      "episode 10, val func loss 0.9020595550537109\n",
      "\n",
      "episode 11, val func loss 1.0484622716903687\n",
      "\n",
      "episode 12, val func loss 0.9732629656791687\n",
      "\n",
      "episode 13, val func loss 0.9722972512245178\n",
      "\n",
      "episode 14, val func loss 1.1274082660675049\n",
      "\n",
      "episode 15, val func loss 0.9038779139518738\n",
      "\n",
      "episode 16, val func loss 0.9724872708320618\n",
      "\n",
      "Val func train loss in epoch 6:1.0052053704857826\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.153842568397522\n",
      "\n",
      "episode 2, val func loss 0.9711037874221802\n",
      "\n",
      "episode 3, val func loss 1.0701574087142944\n",
      "\n",
      "episode 4, val func loss 1.017914891242981\n",
      "\n",
      "episode 5, val func loss 0.9173600673675537\n",
      "\n",
      "episode 6, val func loss 0.9929993152618408\n",
      "\n",
      "episode 7, val func loss 1.196319818496704\n",
      "\n",
      "episode 8, val func loss 1.0232703685760498\n",
      "\n",
      "episode 9, val func loss 1.0391247272491455\n",
      "\n",
      "episode 10, val func loss 1.1630572080612183\n",
      "\n",
      "episode 11, val func loss 1.0678000450134277\n",
      "\n",
      "episode 12, val func loss 1.0536987781524658\n",
      "\n",
      "episode 13, val func loss 1.1157606840133667\n",
      "\n",
      "episode 14, val func loss 0.9703345894813538\n",
      "\n",
      "episode 15, val func loss 1.0478332042694092\n",
      "\n",
      "episode 16, val func loss 0.8724970817565918\n",
      "\n",
      "Val func train loss in epoch 7:1.0420671589672565\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.060102105140686\n",
      "\n",
      "episode 2, val func loss 1.0339281558990479\n",
      "\n",
      "episode 3, val func loss 0.8706484436988831\n",
      "\n",
      "episode 4, val func loss 0.8780180215835571\n",
      "\n",
      "episode 5, val func loss 0.8937355875968933\n",
      "\n",
      "episode 6, val func loss 0.9014843106269836\n",
      "\n",
      "episode 7, val func loss 1.0543326139450073\n",
      "\n",
      "episode 8, val func loss 1.0175491571426392\n",
      "\n",
      "episode 9, val func loss 1.1849067211151123\n",
      "\n",
      "episode 10, val func loss 0.9257011413574219\n",
      "\n",
      "episode 11, val func loss 1.0112673044204712\n",
      "\n",
      "episode 12, val func loss 1.0101333856582642\n",
      "\n",
      "episode 13, val func loss 1.1014280319213867\n",
      "\n",
      "episode 14, val func loss 0.9899194240570068\n",
      "\n",
      "episode 15, val func loss 1.0511480569839478\n",
      "\n",
      "episode 16, val func loss 1.1106972694396973\n",
      "\n",
      "Val func train loss in epoch 8:1.0059374831616879\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.9329648613929749\n",
      "\n",
      "episode 2, val func loss 1.0294647216796875\n",
      "\n",
      "episode 3, val func loss 1.027887225151062\n",
      "\n",
      "episode 4, val func loss 0.9197722673416138\n",
      "\n",
      "episode 5, val func loss 0.9354711174964905\n",
      "\n",
      "episode 6, val func loss 1.2774955034255981\n",
      "\n",
      "episode 7, val func loss 0.8846795558929443\n",
      "\n",
      "episode 8, val func loss 1.0526678562164307\n",
      "\n",
      "episode 9, val func loss 1.0189396142959595\n",
      "\n",
      "episode 10, val func loss 1.010733962059021\n",
      "\n",
      "episode 11, val func loss 1.0973687171936035\n",
      "\n",
      "episode 12, val func loss 1.0854891538619995\n",
      "\n",
      "episode 13, val func loss 1.0088982582092285\n",
      "\n",
      "episode 14, val func loss 0.8833706974983215\n",
      "\n",
      "episode 15, val func loss 0.898686945438385\n",
      "\n",
      "episode 16, val func loss 0.9196218848228455\n",
      "\n",
      "Val func train loss in epoch 9:0.9989695213735104\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.930178701877594\n",
      "\n",
      "episode 2, val func loss 0.9370681047439575\n",
      "\n",
      "episode 3, val func loss 1.0404103994369507\n",
      "\n",
      "episode 4, val func loss 1.0111249685287476\n",
      "\n",
      "episode 5, val func loss 0.9249390363693237\n",
      "\n",
      "episode 6, val func loss 0.8257458209991455\n",
      "\n",
      "episode 7, val func loss 0.9992683529853821\n",
      "\n",
      "episode 8, val func loss 0.9233263731002808\n",
      "\n",
      "episode 9, val func loss 0.9395853281021118\n",
      "\n",
      "episode 10, val func loss 0.9384243488311768\n",
      "\n",
      "episode 11, val func loss 1.1730084419250488\n",
      "\n",
      "episode 12, val func loss 0.8264315128326416\n",
      "\n",
      "episode 13, val func loss 1.0138497352600098\n",
      "\n",
      "episode 14, val func loss 0.8333614468574524\n",
      "\n",
      "episode 15, val func loss 0.9460669755935669\n",
      "\n",
      "episode 16, val func loss 0.9433751702308655\n",
      "\n",
      "Val func train loss in epoch 10:0.950385294854641\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.0000791549682617\n",
      "\n",
      "episode 2, val func loss 0.8543104529380798\n",
      "\n",
      "episode 3, val func loss 0.9856350421905518\n",
      "\n",
      "episode 4, val func loss 1.0218356847763062\n",
      "\n",
      "episode 5, val func loss 0.9700903296470642\n",
      "\n",
      "episode 6, val func loss 0.9125185608863831\n",
      "\n",
      "episode 7, val func loss 1.091705322265625\n",
      "\n",
      "episode 8, val func loss 1.0131512880325317\n",
      "\n",
      "episode 9, val func loss 1.0887627601623535\n",
      "\n",
      "episode 10, val func loss 0.8419907689094543\n",
      "\n",
      "episode 11, val func loss 0.9635701775550842\n",
      "\n",
      "episode 12, val func loss 0.9238321185112\n",
      "\n",
      "episode 13, val func loss 1.0330731868743896\n",
      "\n",
      "episode 14, val func loss 1.1347578763961792\n",
      "\n",
      "episode 15, val func loss 1.0724698305130005\n",
      "\n",
      "episode 16, val func loss 1.2020589113235474\n",
      "\n",
      "Val func train loss in epoch 11:1.0068650916218758\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.9724840521812439\n",
      "\n",
      "episode 2, val func loss 1.1034057140350342\n",
      "\n",
      "episode 3, val func loss 1.073720097541809\n",
      "\n",
      "episode 4, val func loss 0.952114462852478\n",
      "\n",
      "episode 5, val func loss 1.056996464729309\n",
      "\n",
      "episode 6, val func loss 1.1058862209320068\n",
      "\n",
      "episode 7, val func loss 1.0799449682235718\n",
      "\n",
      "episode 8, val func loss 1.0911309719085693\n",
      "\n",
      "episode 9, val func loss 1.2945128679275513\n",
      "\n",
      "episode 10, val func loss 0.9989036321640015\n",
      "\n",
      "episode 11, val func loss 1.034142017364502\n",
      "\n",
      "episode 12, val func loss 1.181742787361145\n",
      "\n",
      "episode 13, val func loss 0.9800043702125549\n",
      "\n",
      "episode 14, val func loss 1.0409356355667114\n",
      "\n",
      "episode 15, val func loss 1.1620951890945435\n",
      "\n",
      "episode 16, val func loss 1.0838178396224976\n",
      "\n",
      "Val func train loss in epoch 12:1.0757398307323456\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.9102634191513062\n",
      "\n",
      "episode 2, val func loss 0.8752593994140625\n",
      "\n",
      "episode 3, val func loss 1.2215765714645386\n",
      "\n",
      "episode 4, val func loss 0.9486150741577148\n",
      "\n",
      "episode 5, val func loss 1.0728766918182373\n",
      "\n",
      "episode 6, val func loss 1.046952486038208\n",
      "\n",
      "episode 7, val func loss 0.9729027152061462\n",
      "\n",
      "episode 8, val func loss 1.0901180505752563\n",
      "\n",
      "episode 9, val func loss 0.9755443930625916\n",
      "\n",
      "episode 10, val func loss 0.960891842842102\n",
      "\n",
      "episode 11, val func loss 1.099274754524231\n",
      "\n",
      "episode 12, val func loss 0.8973345756530762\n",
      "\n",
      "episode 13, val func loss 1.075848937034607\n",
      "\n",
      "episode 14, val func loss 0.9437952637672424\n",
      "\n",
      "episode 15, val func loss 0.7488816380500793\n",
      "\n",
      "episode 16, val func loss 0.9562165141105652\n",
      "\n",
      "Val func train loss in epoch 13:0.9872720204293728\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.9231666922569275\n",
      "\n",
      "episode 2, val func loss 0.996100664138794\n",
      "\n",
      "episode 3, val func loss 1.118619441986084\n",
      "\n",
      "episode 4, val func loss 0.923072338104248\n",
      "\n",
      "episode 5, val func loss 0.9690528512001038\n",
      "\n",
      "episode 6, val func loss 0.9590771794319153\n",
      "\n",
      "episode 7, val func loss 0.9744473695755005\n",
      "\n",
      "episode 8, val func loss 1.0610135793685913\n",
      "\n",
      "episode 9, val func loss 1.0059385299682617\n",
      "\n",
      "episode 10, val func loss 0.9760322570800781\n",
      "\n",
      "episode 11, val func loss 1.1894694566726685\n",
      "\n",
      "episode 12, val func loss 0.9341326355934143\n",
      "\n",
      "episode 13, val func loss 1.036767601966858\n",
      "\n",
      "episode 14, val func loss 1.0940080881118774\n",
      "\n",
      "episode 15, val func loss 0.9539448618888855\n",
      "\n",
      "episode 16, val func loss 1.0070955753326416\n",
      "\n",
      "Val func train loss in epoch 14:1.007621195167303\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.0242584943771362\n",
      "\n",
      "episode 2, val func loss 0.9787556529045105\n",
      "\n",
      "episode 3, val func loss 0.9634029865264893\n",
      "\n",
      "episode 4, val func loss 0.9365078806877136\n",
      "\n",
      "episode 5, val func loss 1.0744616985321045\n",
      "\n",
      "episode 6, val func loss 1.0380421876907349\n",
      "\n",
      "episode 7, val func loss 0.9613337516784668\n",
      "\n",
      "episode 8, val func loss 0.8761354088783264\n",
      "\n",
      "episode 9, val func loss 1.0062178373336792\n",
      "\n",
      "episode 10, val func loss 0.9392375946044922\n",
      "\n",
      "episode 11, val func loss 0.9639045000076294\n",
      "\n",
      "episode 12, val func loss 0.9430854916572571\n",
      "\n",
      "episode 13, val func loss 1.2041696310043335\n",
      "\n",
      "episode 14, val func loss 0.9913873672485352\n",
      "\n",
      "episode 15, val func loss 0.8889749050140381\n",
      "\n",
      "episode 16, val func loss 0.9596546292304993\n",
      "\n",
      "Val func train loss in epoch 15:0.9843456260859966\n",
      "***********************TIME WAS 4.812899589538574 min*****************************\n",
      "\n",
      "**********************ROUND 46 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.3526018857955933\n",
      "\n",
      "episode 2, policy loss 1.3526016473770142\n",
      "\n",
      "episode 3, policy loss 1.352601408958435\n",
      "\n",
      "episode 4, policy loss 1.3526010513305664\n",
      "\n",
      "episode 5, policy loss 1.3526064157485962\n",
      "\n",
      "episode 6, policy loss 1.3526039123535156\n",
      "\n",
      "episode 7, policy loss 1.352606177330017\n",
      "\n",
      "episode 8, policy loss 1.3526057004928589\n",
      "\n",
      "episode 9, policy loss 1.3526052236557007\n",
      "\n",
      "episode 10, policy loss 1.3526010513305664\n",
      "\n",
      "episode 11, policy loss 1.3526027202606201\n",
      "\n",
      "episode 12, policy loss 1.3526017665863037\n",
      "\n",
      "episode 13, policy loss 1.3526023626327515\n",
      "\n",
      "episode 14, policy loss 1.3526039123535156\n",
      "\n",
      "episode 15, policy loss 1.3526029586791992\n",
      "\n",
      "episode 16, policy loss 1.3526036739349365\n",
      "\n",
      "Policy train loss in epoch 0:1.352603241801262\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.3526064157485962\n",
      "\n",
      "episode 2, policy loss 1.3526036739349365\n",
      "\n",
      "episode 3, policy loss 1.3526010513305664\n",
      "\n",
      "episode 4, policy loss 1.3526052236557007\n",
      "\n",
      "episode 5, policy loss 1.3526029586791992\n",
      "\n",
      "episode 6, policy loss 1.3526016473770142\n",
      "\n",
      "episode 7, policy loss 1.3526039123535156\n",
      "\n",
      "episode 8, policy loss 1.3526027202606201\n",
      "\n",
      "episode 9, policy loss 1.352601408958435\n",
      "\n",
      "episode 10, policy loss 1.3526018857955933\n",
      "\n",
      "episode 11, policy loss 1.3526010513305664\n",
      "\n",
      "episode 12, policy loss 1.3526057004928589\n",
      "\n",
      "episode 13, policy loss 1.352606177330017\n",
      "\n",
      "episode 14, policy loss 1.3526023626327515\n",
      "\n",
      "episode 15, policy loss 1.3526017665863037\n",
      "\n",
      "episode 16, policy loss 1.3526039123535156\n",
      "\n",
      "Policy train loss in epoch 1:1.352603241801262\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.3526010513305664\n",
      "\n",
      "episode 2, policy loss 1.3526023626327515\n",
      "\n",
      "episode 3, policy loss 1.3526018857955933\n",
      "\n",
      "episode 4, policy loss 1.3526010513305664\n",
      "\n",
      "episode 5, policy loss 1.3526039123535156\n",
      "\n",
      "episode 6, policy loss 1.3526016473770142\n",
      "\n",
      "episode 7, policy loss 1.3526052236557007\n",
      "\n",
      "episode 8, policy loss 1.352606177330017\n",
      "\n",
      "episode 9, policy loss 1.352601408958435\n",
      "\n",
      "episode 10, policy loss 1.3526064157485962\n",
      "\n",
      "episode 11, policy loss 1.3526057004928589\n",
      "\n",
      "episode 12, policy loss 1.3526017665863037\n",
      "\n",
      "episode 13, policy loss 1.3526029586791992\n",
      "\n",
      "episode 14, policy loss 1.3526039123535156\n",
      "\n",
      "episode 15, policy loss 1.3526027202606201\n",
      "\n",
      "episode 16, policy loss 1.3526036739349365\n",
      "\n",
      "Policy train loss in epoch 2:1.352603241801262\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.3526010513305664\n",
      "\n",
      "episode 2, policy loss 1.3526029586791992\n",
      "\n",
      "episode 3, policy loss 1.352606177330017\n",
      "\n",
      "episode 4, policy loss 1.3526016473770142\n",
      "\n",
      "episode 5, policy loss 1.352601408958435\n",
      "\n",
      "episode 6, policy loss 1.3526010513305664\n",
      "\n",
      "episode 7, policy loss 1.3526036739349365\n",
      "\n",
      "episode 8, policy loss 1.3526023626327515\n",
      "\n",
      "episode 9, policy loss 1.3526057004928589\n",
      "\n",
      "episode 10, policy loss 1.3526039123535156\n",
      "\n",
      "episode 11, policy loss 1.3526039123535156\n",
      "\n",
      "episode 12, policy loss 1.3526064157485962\n",
      "\n",
      "episode 13, policy loss 1.3526018857955933\n",
      "\n",
      "episode 14, policy loss 1.3526027202606201\n",
      "\n",
      "episode 15, policy loss 1.3526017665863037\n",
      "\n",
      "episode 16, policy loss 1.3526052236557007\n",
      "\n",
      "Policy train loss in epoch 3:1.352603241801262\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.9155239462852478\n",
      "\n",
      "episode 2, val func loss 0.9925366640090942\n",
      "\n",
      "episode 3, val func loss 0.9866206049919128\n",
      "\n",
      "episode 4, val func loss 0.9918918609619141\n",
      "\n",
      "episode 5, val func loss 1.0819900035858154\n",
      "\n",
      "episode 6, val func loss 0.9573319554328918\n",
      "\n",
      "episode 7, val func loss 0.9548882246017456\n",
      "\n",
      "episode 8, val func loss 1.082459568977356\n",
      "\n",
      "episode 9, val func loss 0.9929634928703308\n",
      "\n",
      "episode 10, val func loss 1.0678894519805908\n",
      "\n",
      "episode 11, val func loss 0.9423391819000244\n",
      "\n",
      "episode 12, val func loss 1.0024216175079346\n",
      "\n",
      "episode 13, val func loss 1.045408844947815\n",
      "\n",
      "episode 14, val func loss 0.95686274766922\n",
      "\n",
      "episode 15, val func loss 0.9377856254577637\n",
      "\n",
      "episode 16, val func loss 1.0075063705444336\n",
      "\n",
      "Val func train loss in epoch 0:0.9947762601077557\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.0185123682022095\n",
      "\n",
      "episode 2, val func loss 1.0477153062820435\n",
      "\n",
      "episode 3, val func loss 0.8879360556602478\n",
      "\n",
      "episode 4, val func loss 0.8809804916381836\n",
      "\n",
      "episode 5, val func loss 0.9722421169281006\n",
      "\n",
      "episode 6, val func loss 1.032076120376587\n",
      "\n",
      "episode 7, val func loss 1.0082091093063354\n",
      "\n",
      "episode 8, val func loss 1.043656587600708\n",
      "\n",
      "episode 9, val func loss 0.8839856386184692\n",
      "\n",
      "episode 10, val func loss 1.1123381853103638\n",
      "\n",
      "episode 11, val func loss 0.9729103446006775\n",
      "\n",
      "episode 12, val func loss 1.051263451576233\n",
      "\n",
      "episode 13, val func loss 1.0282472372055054\n",
      "\n",
      "episode 14, val func loss 0.904053807258606\n",
      "\n",
      "episode 15, val func loss 1.1906778812408447\n",
      "\n",
      "episode 16, val func loss 0.8929225206375122\n",
      "\n",
      "Val func train loss in epoch 1:0.9954829514026642\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.9391591548919678\n",
      "\n",
      "episode 2, val func loss 0.9512037634849548\n",
      "\n",
      "episode 3, val func loss 1.020336389541626\n",
      "\n",
      "episode 4, val func loss 1.0759145021438599\n",
      "\n",
      "episode 5, val func loss 0.9706679582595825\n",
      "\n",
      "episode 6, val func loss 1.0453684329986572\n",
      "\n",
      "episode 7, val func loss 1.0462031364440918\n",
      "\n",
      "episode 8, val func loss 1.0577789545059204\n",
      "\n",
      "episode 9, val func loss 1.001694917678833\n",
      "\n",
      "episode 10, val func loss 0.918369472026825\n",
      "\n",
      "episode 11, val func loss 0.9916499853134155\n",
      "\n",
      "episode 12, val func loss 0.9913674592971802\n",
      "\n",
      "episode 13, val func loss 0.9695675373077393\n",
      "\n",
      "episode 14, val func loss 0.9599869847297668\n",
      "\n",
      "episode 15, val func loss 0.9003075361251831\n",
      "\n",
      "episode 16, val func loss 0.9982734322547913\n",
      "\n",
      "Val func train loss in epoch 2:0.9898656010627747\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.0351197719573975\n",
      "\n",
      "episode 2, val func loss 0.9315645694732666\n",
      "\n",
      "episode 3, val func loss 0.9887461066246033\n",
      "\n",
      "episode 4, val func loss 0.8617351651191711\n",
      "\n",
      "episode 5, val func loss 1.333825707435608\n",
      "\n",
      "episode 6, val func loss 0.8822769522666931\n",
      "\n",
      "episode 7, val func loss 1.0511305332183838\n",
      "\n",
      "episode 8, val func loss 1.0925499200820923\n",
      "\n",
      "episode 9, val func loss 0.9074235558509827\n",
      "\n",
      "episode 10, val func loss 0.95846027135849\n",
      "\n",
      "episode 11, val func loss 1.1002171039581299\n",
      "\n",
      "episode 12, val func loss 0.9417338371276855\n",
      "\n",
      "episode 13, val func loss 1.098624587059021\n",
      "\n",
      "episode 14, val func loss 1.0451633930206299\n",
      "\n",
      "episode 15, val func loss 0.9872251152992249\n",
      "\n",
      "episode 16, val func loss 1.0666197538375854\n",
      "\n",
      "Val func train loss in epoch 3:1.0176510214805603\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7993471622467041\n",
      "\n",
      "episode 2, val func loss 1.0264668464660645\n",
      "\n",
      "episode 3, val func loss 1.154091715812683\n",
      "\n",
      "episode 4, val func loss 1.1333823204040527\n",
      "\n",
      "episode 5, val func loss 0.9912596940994263\n",
      "\n",
      "episode 6, val func loss 0.982356607913971\n",
      "\n",
      "episode 7, val func loss 1.1816596984863281\n",
      "\n",
      "episode 8, val func loss 0.9913312792778015\n",
      "\n",
      "episode 9, val func loss 0.9587636590003967\n",
      "\n",
      "episode 10, val func loss 1.0747233629226685\n",
      "\n",
      "episode 11, val func loss 1.039306640625\n",
      "\n",
      "episode 12, val func loss 1.0406934022903442\n",
      "\n",
      "episode 13, val func loss 0.9832739233970642\n",
      "\n",
      "episode 14, val func loss 1.0390468835830688\n",
      "\n",
      "episode 15, val func loss 0.937428891658783\n",
      "\n",
      "episode 16, val func loss 0.9345479607582092\n",
      "\n",
      "Val func train loss in epoch 4:1.0167300030589104\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.1144520044326782\n",
      "\n",
      "episode 2, val func loss 0.9513071775436401\n",
      "\n",
      "episode 3, val func loss 0.8822552561759949\n",
      "\n",
      "episode 4, val func loss 0.8200507760047913\n",
      "\n",
      "episode 5, val func loss 1.055677056312561\n",
      "\n",
      "episode 6, val func loss 1.0055540800094604\n",
      "\n",
      "episode 7, val func loss 0.9074575901031494\n",
      "\n",
      "episode 8, val func loss 0.9239405393600464\n",
      "\n",
      "episode 9, val func loss 0.9823934435844421\n",
      "\n",
      "episode 10, val func loss 0.9739358425140381\n",
      "\n",
      "episode 11, val func loss 1.027161955833435\n",
      "\n",
      "episode 12, val func loss 0.8801504969596863\n",
      "\n",
      "episode 13, val func loss 1.0497057437896729\n",
      "\n",
      "episode 14, val func loss 0.9099224209785461\n",
      "\n",
      "episode 15, val func loss 1.0363022089004517\n",
      "\n",
      "episode 16, val func loss 0.9678911566734314\n",
      "\n",
      "Val func train loss in epoch 5:0.9680098593235016\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.0067821741104126\n",
      "\n",
      "episode 2, val func loss 1.0048301219940186\n",
      "\n",
      "episode 3, val func loss 0.9609035849571228\n",
      "\n",
      "episode 4, val func loss 0.9593600630760193\n",
      "\n",
      "episode 5, val func loss 1.0223548412322998\n",
      "\n",
      "episode 6, val func loss 1.0154868364334106\n",
      "\n",
      "episode 7, val func loss 1.0133404731750488\n",
      "\n",
      "episode 8, val func loss 0.884466290473938\n",
      "\n",
      "episode 9, val func loss 1.0700424909591675\n",
      "\n",
      "episode 10, val func loss 1.0331543684005737\n",
      "\n",
      "episode 11, val func loss 0.8795307278633118\n",
      "\n",
      "episode 12, val func loss 1.0216187238693237\n",
      "\n",
      "episode 13, val func loss 1.0695456266403198\n",
      "\n",
      "episode 14, val func loss 0.9932002425193787\n",
      "\n",
      "episode 15, val func loss 0.9073752164840698\n",
      "\n",
      "episode 16, val func loss 1.0112864971160889\n",
      "\n",
      "Val func train loss in epoch 6:0.9908298924565315\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.0729159116744995\n",
      "\n",
      "episode 2, val func loss 1.0832167863845825\n",
      "\n",
      "episode 3, val func loss 1.0577130317687988\n",
      "\n",
      "episode 4, val func loss 0.9884572625160217\n",
      "\n",
      "episode 5, val func loss 0.93409663438797\n",
      "\n",
      "episode 6, val func loss 0.9272918105125427\n",
      "\n",
      "episode 7, val func loss 1.0456403493881226\n",
      "\n",
      "episode 8, val func loss 0.9821977615356445\n",
      "\n",
      "episode 9, val func loss 0.9290493130683899\n",
      "\n",
      "episode 10, val func loss 0.8822906613349915\n",
      "\n",
      "episode 11, val func loss 0.8298421502113342\n",
      "\n",
      "episode 12, val func loss 0.9551401734352112\n",
      "\n",
      "episode 13, val func loss 0.9491770267486572\n",
      "\n",
      "episode 14, val func loss 0.9046645164489746\n",
      "\n",
      "episode 15, val func loss 0.9637766480445862\n",
      "\n",
      "episode 16, val func loss 0.9125333428382874\n",
      "\n",
      "Val func train loss in epoch 7:0.9636252112686634\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.9939415454864502\n",
      "\n",
      "episode 2, val func loss 0.881003201007843\n",
      "\n",
      "episode 3, val func loss 0.9991721510887146\n",
      "\n",
      "episode 4, val func loss 0.886759877204895\n",
      "\n",
      "episode 5, val func loss 0.9415714740753174\n",
      "\n",
      "episode 6, val func loss 1.047427773475647\n",
      "\n",
      "episode 7, val func loss 0.8966087698936462\n",
      "\n",
      "episode 8, val func loss 0.9331421256065369\n",
      "\n",
      "episode 9, val func loss 0.963632345199585\n",
      "\n",
      "episode 10, val func loss 0.9609081745147705\n",
      "\n",
      "episode 11, val func loss 0.9890770316123962\n",
      "\n",
      "episode 12, val func loss 0.938766598701477\n",
      "\n",
      "episode 13, val func loss 1.1046074628829956\n",
      "\n",
      "episode 14, val func loss 1.0007659196853638\n",
      "\n",
      "episode 15, val func loss 1.0048983097076416\n",
      "\n",
      "episode 16, val func loss 1.080060601234436\n",
      "\n",
      "Val func train loss in epoch 8:0.9763964600861073\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.0347633361816406\n",
      "\n",
      "episode 2, val func loss 1.0314626693725586\n",
      "\n",
      "episode 3, val func loss 0.8669450283050537\n",
      "\n",
      "episode 4, val func loss 0.9068310260772705\n",
      "\n",
      "episode 5, val func loss 1.0528851747512817\n",
      "\n",
      "episode 6, val func loss 1.0957496166229248\n",
      "\n",
      "episode 7, val func loss 1.0045603513717651\n",
      "\n",
      "episode 8, val func loss 0.9020596742630005\n",
      "\n",
      "episode 9, val func loss 0.9469143748283386\n",
      "\n",
      "episode 10, val func loss 0.9504648447036743\n",
      "\n",
      "episode 11, val func loss 0.9320245385169983\n",
      "\n",
      "episode 12, val func loss 0.9547168016433716\n",
      "\n",
      "episode 13, val func loss 0.8729559779167175\n",
      "\n",
      "episode 14, val func loss 0.9403488636016846\n",
      "\n",
      "episode 15, val func loss 0.9643630981445312\n",
      "\n",
      "episode 16, val func loss 0.9279294610023499\n",
      "\n",
      "Val func train loss in epoch 9:0.9615609273314476\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.9563933610916138\n",
      "\n",
      "episode 2, val func loss 0.8736153841018677\n",
      "\n",
      "episode 3, val func loss 1.0192316770553589\n",
      "\n",
      "episode 4, val func loss 1.0660921335220337\n",
      "\n",
      "episode 5, val func loss 0.8799167275428772\n",
      "\n",
      "episode 6, val func loss 0.8990041017532349\n",
      "\n",
      "episode 7, val func loss 0.9860917329788208\n",
      "\n",
      "episode 8, val func loss 1.0686756372451782\n",
      "\n",
      "episode 9, val func loss 0.9173064231872559\n",
      "\n",
      "episode 10, val func loss 0.918914794921875\n",
      "\n",
      "episode 11, val func loss 0.9520511031150818\n",
      "\n",
      "episode 12, val func loss 0.9324448704719543\n",
      "\n",
      "episode 13, val func loss 0.9888068437576294\n",
      "\n",
      "episode 14, val func loss 0.9600415825843811\n",
      "\n",
      "episode 15, val func loss 0.9333524703979492\n",
      "\n",
      "episode 16, val func loss 1.1048380136489868\n",
      "\n",
      "Val func train loss in epoch 10:0.9660485535860062\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.0799952745437622\n",
      "\n",
      "episode 2, val func loss 0.8955151438713074\n",
      "\n",
      "episode 3, val func loss 0.8582612872123718\n",
      "\n",
      "episode 4, val func loss 1.051971197128296\n",
      "\n",
      "episode 5, val func loss 0.9913234114646912\n",
      "\n",
      "episode 6, val func loss 1.0388457775115967\n",
      "\n",
      "episode 7, val func loss 1.037000060081482\n",
      "\n",
      "episode 8, val func loss 0.9510992765426636\n",
      "\n",
      "episode 9, val func loss 0.9036247730255127\n",
      "\n",
      "episode 10, val func loss 0.9238234758377075\n",
      "\n",
      "episode 11, val func loss 0.9059080481529236\n",
      "\n",
      "episode 12, val func loss 0.9977712631225586\n",
      "\n",
      "episode 13, val func loss 1.0258077383041382\n",
      "\n",
      "episode 14, val func loss 0.9578633904457092\n",
      "\n",
      "episode 15, val func loss 1.0582849979400635\n",
      "\n",
      "episode 16, val func loss 0.9586691856384277\n",
      "\n",
      "Val func train loss in epoch 11:0.9772352688014507\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.9216076731681824\n",
      "\n",
      "episode 2, val func loss 0.9935986399650574\n",
      "\n",
      "episode 3, val func loss 0.9916786551475525\n",
      "\n",
      "episode 4, val func loss 0.9656267166137695\n",
      "\n",
      "episode 5, val func loss 0.9698296785354614\n",
      "\n",
      "episode 6, val func loss 1.0065189599990845\n",
      "\n",
      "episode 7, val func loss 0.8884211778640747\n",
      "\n",
      "episode 8, val func loss 1.0402215719223022\n",
      "\n",
      "episode 9, val func loss 0.8620901107788086\n",
      "\n",
      "episode 10, val func loss 0.7976971864700317\n",
      "\n",
      "episode 11, val func loss 1.0218437910079956\n",
      "\n",
      "episode 12, val func loss 0.9153351187705994\n",
      "\n",
      "episode 13, val func loss 0.8965676426887512\n",
      "\n",
      "episode 14, val func loss 0.9569662809371948\n",
      "\n",
      "episode 15, val func loss 0.8905454277992249\n",
      "\n",
      "episode 16, val func loss 1.0738774538040161\n",
      "\n",
      "Val func train loss in epoch 12:0.9495266303420067\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.012528419494629\n",
      "\n",
      "episode 2, val func loss 1.09848153591156\n",
      "\n",
      "episode 3, val func loss 0.9884573817253113\n",
      "\n",
      "episode 4, val func loss 1.0053249597549438\n",
      "\n",
      "episode 5, val func loss 1.0569312572479248\n",
      "\n",
      "episode 6, val func loss 1.015077829360962\n",
      "\n",
      "episode 7, val func loss 0.9245180487632751\n",
      "\n",
      "episode 8, val func loss 0.9589697122573853\n",
      "\n",
      "episode 9, val func loss 1.05173659324646\n",
      "\n",
      "episode 10, val func loss 1.2527287006378174\n",
      "\n",
      "episode 11, val func loss 0.9548998475074768\n",
      "\n",
      "episode 12, val func loss 1.0315335988998413\n",
      "\n",
      "episode 13, val func loss 0.9686352610588074\n",
      "\n",
      "episode 14, val func loss 0.9416588544845581\n",
      "\n",
      "episode 15, val func loss 1.1010148525238037\n",
      "\n",
      "episode 16, val func loss 0.8335263133049011\n",
      "\n",
      "Val func train loss in epoch 13:1.0122514478862286\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.046962857246399\n",
      "\n",
      "episode 2, val func loss 0.9566892981529236\n",
      "\n",
      "episode 3, val func loss 1.1147981882095337\n",
      "\n",
      "episode 4, val func loss 0.9603245258331299\n",
      "\n",
      "episode 5, val func loss 1.020875096321106\n",
      "\n",
      "episode 6, val func loss 1.1233484745025635\n",
      "\n",
      "episode 7, val func loss 1.0988554954528809\n",
      "\n",
      "episode 8, val func loss 0.9302647113800049\n",
      "\n",
      "episode 9, val func loss 1.181397557258606\n",
      "\n",
      "episode 10, val func loss 0.8299421668052673\n",
      "\n",
      "episode 11, val func loss 0.8728956580162048\n",
      "\n",
      "episode 12, val func loss 1.0609914064407349\n",
      "\n",
      "episode 13, val func loss 0.8994777798652649\n",
      "\n",
      "episode 14, val func loss 1.1005953550338745\n",
      "\n",
      "episode 15, val func loss 1.0680137872695923\n",
      "\n",
      "episode 16, val func loss 0.9589136838912964\n",
      "\n",
      "Val func train loss in epoch 14:1.0140216276049614\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.9348530173301697\n",
      "\n",
      "episode 2, val func loss 1.0489670038223267\n",
      "\n",
      "episode 3, val func loss 0.9174371957778931\n",
      "\n",
      "episode 4, val func loss 0.9925969243049622\n",
      "\n",
      "episode 5, val func loss 1.0830670595169067\n",
      "\n",
      "episode 6, val func loss 1.0862796306610107\n",
      "\n",
      "episode 7, val func loss 0.8563992381095886\n",
      "\n",
      "episode 8, val func loss 1.0829203128814697\n",
      "\n",
      "episode 9, val func loss 1.0100611448287964\n",
      "\n",
      "episode 10, val func loss 0.8118234872817993\n",
      "\n",
      "episode 11, val func loss 0.8693953156471252\n",
      "\n",
      "episode 12, val func loss 0.9821100234985352\n",
      "\n",
      "episode 13, val func loss 0.9955428838729858\n",
      "\n",
      "episode 14, val func loss 1.0065996646881104\n",
      "\n",
      "episode 15, val func loss 0.9261178970336914\n",
      "\n",
      "episode 16, val func loss 0.9482344388961792\n",
      "\n",
      "Val func train loss in epoch 15:0.9720253273844719\n",
      "***********************TIME WAS 4.813963071505229 min*****************************\n",
      "\n",
      "**********************ROUND 47 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 3.2387683391571045\n",
      "\n",
      "episode 2, policy loss 3.238773822784424\n",
      "\n",
      "episode 3, policy loss 3.2387683391571045\n",
      "\n",
      "episode 4, policy loss 3.2387759685516357\n",
      "\n",
      "episode 5, policy loss 3.2387595176696777\n",
      "\n",
      "episode 6, policy loss 3.238779306411743\n",
      "\n",
      "episode 7, policy loss 3.238776445388794\n",
      "\n",
      "episode 8, policy loss 3.238771677017212\n",
      "\n",
      "episode 9, policy loss 3.2387688159942627\n",
      "\n",
      "episode 10, policy loss 3.2387683391571045\n",
      "\n",
      "episode 11, policy loss 3.2387640476226807\n",
      "\n",
      "episode 12, policy loss 3.2387638092041016\n",
      "\n",
      "episode 13, policy loss 3.238776206970215\n",
      "\n",
      "episode 14, policy loss 3.2387702465057373\n",
      "\n",
      "episode 15, policy loss 3.2387654781341553\n",
      "\n",
      "episode 16, policy loss 3.238770008087158\n",
      "\n",
      "Policy train loss in epoch 0:3.2387700229883194\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 3.238773822784424\n",
      "\n",
      "episode 2, policy loss 3.2387595176696777\n",
      "\n",
      "episode 3, policy loss 3.2387702465057373\n",
      "\n",
      "episode 4, policy loss 3.2387640476226807\n",
      "\n",
      "episode 5, policy loss 3.2387683391571045\n",
      "\n",
      "episode 6, policy loss 3.238776445388794\n",
      "\n",
      "episode 7, policy loss 3.238776206970215\n",
      "\n",
      "episode 8, policy loss 3.2387683391571045\n",
      "\n",
      "episode 9, policy loss 3.2387688159942627\n",
      "\n",
      "episode 10, policy loss 3.2387683391571045\n",
      "\n",
      "episode 11, policy loss 3.2387654781341553\n",
      "\n",
      "episode 12, policy loss 3.238770008087158\n",
      "\n",
      "episode 13, policy loss 3.2387759685516357\n",
      "\n",
      "episode 14, policy loss 3.238779306411743\n",
      "\n",
      "episode 15, policy loss 3.238771677017212\n",
      "\n",
      "episode 16, policy loss 3.2387638092041016\n",
      "\n",
      "Policy train loss in epoch 1:3.2387700229883194\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 3.2387595176696777\n",
      "\n",
      "episode 2, policy loss 3.2387683391571045\n",
      "\n",
      "episode 3, policy loss 3.238773822784424\n",
      "\n",
      "episode 4, policy loss 3.2387683391571045\n",
      "\n",
      "episode 5, policy loss 3.238776206970215\n",
      "\n",
      "episode 6, policy loss 3.2387688159942627\n",
      "\n",
      "episode 7, policy loss 3.2387638092041016\n",
      "\n",
      "episode 8, policy loss 3.238771677017212\n",
      "\n",
      "episode 9, policy loss 3.2387702465057373\n",
      "\n",
      "episode 10, policy loss 3.2387654781341553\n",
      "\n",
      "episode 11, policy loss 3.2387640476226807\n",
      "\n",
      "episode 12, policy loss 3.238776445388794\n",
      "\n",
      "episode 13, policy loss 3.238770008087158\n",
      "\n",
      "episode 14, policy loss 3.2387683391571045\n",
      "\n",
      "episode 15, policy loss 3.238779306411743\n",
      "\n",
      "episode 16, policy loss 3.2387759685516357\n",
      "\n",
      "Policy train loss in epoch 2:3.2387700229883194\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 3.2387702465057373\n",
      "\n",
      "episode 2, policy loss 3.2387638092041016\n",
      "\n",
      "episode 3, policy loss 3.2387595176696777\n",
      "\n",
      "episode 4, policy loss 3.238771677017212\n",
      "\n",
      "episode 5, policy loss 3.2387640476226807\n",
      "\n",
      "episode 6, policy loss 3.2387683391571045\n",
      "\n",
      "episode 7, policy loss 3.2387688159942627\n",
      "\n",
      "episode 8, policy loss 3.2387654781341553\n",
      "\n",
      "episode 9, policy loss 3.238776206970215\n",
      "\n",
      "episode 10, policy loss 3.238773822784424\n",
      "\n",
      "episode 11, policy loss 3.2387683391571045\n",
      "\n",
      "episode 12, policy loss 3.238779306411743\n",
      "\n",
      "episode 13, policy loss 3.2387759685516357\n",
      "\n",
      "episode 14, policy loss 3.2387683391571045\n",
      "\n",
      "episode 15, policy loss 3.238776445388794\n",
      "\n",
      "episode 16, policy loss 3.238770008087158\n",
      "\n",
      "Policy train loss in epoch 3:3.2387700229883194\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.036779522895813\n",
      "\n",
      "episode 2, val func loss 0.84669429063797\n",
      "\n",
      "episode 3, val func loss 0.9620646834373474\n",
      "\n",
      "episode 4, val func loss 0.9493907690048218\n",
      "\n",
      "episode 5, val func loss 0.9439014196395874\n",
      "\n",
      "episode 6, val func loss 0.8536869883537292\n",
      "\n",
      "episode 7, val func loss 0.9861230850219727\n",
      "\n",
      "episode 8, val func loss 0.898906409740448\n",
      "\n",
      "episode 9, val func loss 1.0055062770843506\n",
      "\n",
      "episode 10, val func loss 0.9243026375770569\n",
      "\n",
      "episode 11, val func loss 0.9995046854019165\n",
      "\n",
      "episode 12, val func loss 0.8847014307975769\n",
      "\n",
      "episode 13, val func loss 0.8005037307739258\n",
      "\n",
      "episode 14, val func loss 0.9526770114898682\n",
      "\n",
      "episode 15, val func loss 0.9148402810096741\n",
      "\n",
      "episode 16, val func loss 0.9814280867576599\n",
      "\n",
      "Val func train loss in epoch 0:0.9338132068514824\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8763552904129028\n",
      "\n",
      "episode 2, val func loss 0.8161321878433228\n",
      "\n",
      "episode 3, val func loss 0.8897140622138977\n",
      "\n",
      "episode 4, val func loss 0.8924567103385925\n",
      "\n",
      "episode 5, val func loss 0.9608625769615173\n",
      "\n",
      "episode 6, val func loss 0.8696163892745972\n",
      "\n",
      "episode 7, val func loss 0.9501265287399292\n",
      "\n",
      "episode 8, val func loss 1.0355441570281982\n",
      "\n",
      "episode 9, val func loss 0.9286481738090515\n",
      "\n",
      "episode 10, val func loss 0.9218249917030334\n",
      "\n",
      "episode 11, val func loss 0.9046072363853455\n",
      "\n",
      "episode 12, val func loss 1.003658652305603\n",
      "\n",
      "episode 13, val func loss 0.8831256628036499\n",
      "\n",
      "episode 14, val func loss 0.936654806137085\n",
      "\n",
      "episode 15, val func loss 0.8603194952011108\n",
      "\n",
      "episode 16, val func loss 0.7259768843650818\n",
      "\n",
      "Val func train loss in epoch 1:0.9034764878451824\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.9933853149414062\n",
      "\n",
      "episode 2, val func loss 0.8339118957519531\n",
      "\n",
      "episode 3, val func loss 0.9887770414352417\n",
      "\n",
      "episode 4, val func loss 0.7548555135726929\n",
      "\n",
      "episode 5, val func loss 0.8350573778152466\n",
      "\n",
      "episode 6, val func loss 0.8550794124603271\n",
      "\n",
      "episode 7, val func loss 1.069542646408081\n",
      "\n",
      "episode 8, val func loss 0.9568061828613281\n",
      "\n",
      "episode 9, val func loss 0.8765748143196106\n",
      "\n",
      "episode 10, val func loss 0.9189393520355225\n",
      "\n",
      "episode 11, val func loss 0.8496449589729309\n",
      "\n",
      "episode 12, val func loss 0.9865916967391968\n",
      "\n",
      "episode 13, val func loss 0.9433103203773499\n",
      "\n",
      "episode 14, val func loss 0.9837743639945984\n",
      "\n",
      "episode 15, val func loss 0.9539921283721924\n",
      "\n",
      "episode 16, val func loss 0.8889795541763306\n",
      "\n",
      "Val func train loss in epoch 2:0.9180764108896255\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8391823172569275\n",
      "\n",
      "episode 2, val func loss 0.7542169094085693\n",
      "\n",
      "episode 3, val func loss 0.8469366431236267\n",
      "\n",
      "episode 4, val func loss 1.076042652130127\n",
      "\n",
      "episode 5, val func loss 1.02083158493042\n",
      "\n",
      "episode 6, val func loss 0.9909794330596924\n",
      "\n",
      "episode 7, val func loss 0.8897043466567993\n",
      "\n",
      "episode 8, val func loss 0.8686951398849487\n",
      "\n",
      "episode 9, val func loss 0.9419660568237305\n",
      "\n",
      "episode 10, val func loss 1.0450884103775024\n",
      "\n",
      "episode 11, val func loss 0.9583523273468018\n",
      "\n",
      "episode 12, val func loss 0.876532256603241\n",
      "\n",
      "episode 13, val func loss 0.8034437298774719\n",
      "\n",
      "episode 14, val func loss 0.8913590908050537\n",
      "\n",
      "episode 15, val func loss 1.0118459463119507\n",
      "\n",
      "episode 16, val func loss 0.9387708306312561\n",
      "\n",
      "Val func train loss in epoch 3:0.9221217297017574\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8368200659751892\n",
      "\n",
      "episode 2, val func loss 0.9683274030685425\n",
      "\n",
      "episode 3, val func loss 0.9264360070228577\n",
      "\n",
      "episode 4, val func loss 0.7501524090766907\n",
      "\n",
      "episode 5, val func loss 0.8858950138092041\n",
      "\n",
      "episode 6, val func loss 0.9661169052124023\n",
      "\n",
      "episode 7, val func loss 0.8474167585372925\n",
      "\n",
      "episode 8, val func loss 0.8621203303337097\n",
      "\n",
      "episode 9, val func loss 0.9411065578460693\n",
      "\n",
      "episode 10, val func loss 0.8970710039138794\n",
      "\n",
      "episode 11, val func loss 0.9562081098556519\n",
      "\n",
      "episode 12, val func loss 0.8139118552207947\n",
      "\n",
      "episode 13, val func loss 0.932569682598114\n",
      "\n",
      "episode 14, val func loss 0.9447479248046875\n",
      "\n",
      "episode 15, val func loss 0.8568224310874939\n",
      "\n",
      "episode 16, val func loss 1.0794283151626587\n",
      "\n",
      "Val func train loss in epoch 4:0.9040719233453274\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.9636920690536499\n",
      "\n",
      "episode 2, val func loss 0.9637840390205383\n",
      "\n",
      "episode 3, val func loss 0.8579332232475281\n",
      "\n",
      "episode 4, val func loss 1.0928635597229004\n",
      "\n",
      "episode 5, val func loss 1.0222446918487549\n",
      "\n",
      "episode 6, val func loss 0.9619801044464111\n",
      "\n",
      "episode 7, val func loss 1.0417327880859375\n",
      "\n",
      "episode 8, val func loss 0.9062982797622681\n",
      "\n",
      "episode 9, val func loss 0.9511173963546753\n",
      "\n",
      "episode 10, val func loss 1.0965487957000732\n",
      "\n",
      "episode 11, val func loss 0.79534512758255\n",
      "\n",
      "episode 12, val func loss 0.7670343518257141\n",
      "\n",
      "episode 13, val func loss 0.9247914552688599\n",
      "\n",
      "episode 14, val func loss 0.7505508065223694\n",
      "\n",
      "episode 15, val func loss 0.8583417534828186\n",
      "\n",
      "episode 16, val func loss 0.9557886719703674\n",
      "\n",
      "Val func train loss in epoch 5:0.9318779446184635\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8817006349563599\n",
      "\n",
      "episode 2, val func loss 0.8931149244308472\n",
      "\n",
      "episode 3, val func loss 0.8634962439537048\n",
      "\n",
      "episode 4, val func loss 0.8785839080810547\n",
      "\n",
      "episode 5, val func loss 0.9262321591377258\n",
      "\n",
      "episode 6, val func loss 0.9110192060470581\n",
      "\n",
      "episode 7, val func loss 0.809657871723175\n",
      "\n",
      "episode 8, val func loss 0.9700559973716736\n",
      "\n",
      "episode 9, val func loss 0.9584212899208069\n",
      "\n",
      "episode 10, val func loss 0.8182578086853027\n",
      "\n",
      "episode 11, val func loss 0.8578715324401855\n",
      "\n",
      "episode 12, val func loss 0.8472368717193604\n",
      "\n",
      "episode 13, val func loss 0.8180660009384155\n",
      "\n",
      "episode 14, val func loss 0.9260615706443787\n",
      "\n",
      "episode 15, val func loss 0.8911192417144775\n",
      "\n",
      "episode 16, val func loss 0.9029483795166016\n",
      "\n",
      "Val func train loss in epoch 6:0.8846152275800705\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.0706294775009155\n",
      "\n",
      "episode 2, val func loss 0.8502597808837891\n",
      "\n",
      "episode 3, val func loss 1.0856667757034302\n",
      "\n",
      "episode 4, val func loss 0.9098336100578308\n",
      "\n",
      "episode 5, val func loss 0.8714948892593384\n",
      "\n",
      "episode 6, val func loss 0.8047029376029968\n",
      "\n",
      "episode 7, val func loss 0.9690496921539307\n",
      "\n",
      "episode 8, val func loss 0.8757861852645874\n",
      "\n",
      "episode 9, val func loss 0.9229888916015625\n",
      "\n",
      "episode 10, val func loss 0.9970343112945557\n",
      "\n",
      "episode 11, val func loss 0.8315725326538086\n",
      "\n",
      "episode 12, val func loss 0.8588210344314575\n",
      "\n",
      "episode 13, val func loss 0.9088726043701172\n",
      "\n",
      "episode 14, val func loss 0.9278115034103394\n",
      "\n",
      "episode 15, val func loss 0.8726710677146912\n",
      "\n",
      "episode 16, val func loss 0.8940550684928894\n",
      "\n",
      "Val func train loss in epoch 7:0.915703147649765\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.9018662571907043\n",
      "\n",
      "episode 2, val func loss 0.7947725653648376\n",
      "\n",
      "episode 3, val func loss 0.8907544612884521\n",
      "\n",
      "episode 4, val func loss 0.9101130366325378\n",
      "\n",
      "episode 5, val func loss 0.8723670244216919\n",
      "\n",
      "episode 6, val func loss 0.9134588241577148\n",
      "\n",
      "episode 7, val func loss 0.9589636325836182\n",
      "\n",
      "episode 8, val func loss 0.993520975112915\n",
      "\n",
      "episode 9, val func loss 0.982822597026825\n",
      "\n",
      "episode 10, val func loss 0.8832253217697144\n",
      "\n",
      "episode 11, val func loss 0.8992648720741272\n",
      "\n",
      "episode 12, val func loss 0.936132550239563\n",
      "\n",
      "episode 13, val func loss 0.8316609263420105\n",
      "\n",
      "episode 14, val func loss 1.118511438369751\n",
      "\n",
      "episode 15, val func loss 0.9552821516990662\n",
      "\n",
      "episode 16, val func loss 0.8289976119995117\n",
      "\n",
      "Val func train loss in epoch 8:0.916982140392065\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8450007438659668\n",
      "\n",
      "episode 2, val func loss 0.9932182431221008\n",
      "\n",
      "episode 3, val func loss 0.8716765642166138\n",
      "\n",
      "episode 4, val func loss 0.7713137865066528\n",
      "\n",
      "episode 5, val func loss 0.9805838465690613\n",
      "\n",
      "episode 6, val func loss 0.8879868984222412\n",
      "\n",
      "episode 7, val func loss 0.9196410775184631\n",
      "\n",
      "episode 8, val func loss 0.9293524026870728\n",
      "\n",
      "episode 9, val func loss 1.0669759511947632\n",
      "\n",
      "episode 10, val func loss 0.8585959672927856\n",
      "\n",
      "episode 11, val func loss 0.7620130181312561\n",
      "\n",
      "episode 12, val func loss 1.0633363723754883\n",
      "\n",
      "episode 13, val func loss 0.9917608499526978\n",
      "\n",
      "episode 14, val func loss 0.8633809685707092\n",
      "\n",
      "episode 15, val func loss 1.1617425680160522\n",
      "\n",
      "episode 16, val func loss 0.8558318018913269\n",
      "\n",
      "Val func train loss in epoch 9:0.9264006912708282\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.9523171186447144\n",
      "\n",
      "episode 2, val func loss 0.8411371111869812\n",
      "\n",
      "episode 3, val func loss 1.0312132835388184\n",
      "\n",
      "episode 4, val func loss 1.0373005867004395\n",
      "\n",
      "episode 5, val func loss 0.7858350872993469\n",
      "\n",
      "episode 6, val func loss 0.9806631803512573\n",
      "\n",
      "episode 7, val func loss 1.2769418954849243\n",
      "\n",
      "episode 8, val func loss 1.103242039680481\n",
      "\n",
      "episode 9, val func loss 0.9538060426712036\n",
      "\n",
      "episode 10, val func loss 0.979382336139679\n",
      "\n",
      "episode 11, val func loss 1.1115220785140991\n",
      "\n",
      "episode 12, val func loss 0.8547971844673157\n",
      "\n",
      "episode 13, val func loss 0.9072038531303406\n",
      "\n",
      "episode 14, val func loss 1.0988270044326782\n",
      "\n",
      "episode 15, val func loss 0.908620297908783\n",
      "\n",
      "episode 16, val func loss 0.8677265644073486\n",
      "\n",
      "Val func train loss in epoch 10:0.9806584790349007\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9648355841636658\n",
      "\n",
      "episode 2, val func loss 1.035596489906311\n",
      "\n",
      "episode 3, val func loss 0.9476532340049744\n",
      "\n",
      "episode 4, val func loss 0.9595904350280762\n",
      "\n",
      "episode 5, val func loss 0.9852278232574463\n",
      "\n",
      "episode 6, val func loss 0.9671473503112793\n",
      "\n",
      "episode 7, val func loss 0.9241040349006653\n",
      "\n",
      "episode 8, val func loss 0.8757241368293762\n",
      "\n",
      "episode 9, val func loss 0.8264085054397583\n",
      "\n",
      "episode 10, val func loss 0.8643908500671387\n",
      "\n",
      "episode 11, val func loss 0.8694035410881042\n",
      "\n",
      "episode 12, val func loss 0.8520651459693909\n",
      "\n",
      "episode 13, val func loss 0.8257560729980469\n",
      "\n",
      "episode 14, val func loss 0.9591328501701355\n",
      "\n",
      "episode 15, val func loss 0.9717428684234619\n",
      "\n",
      "episode 16, val func loss 0.8787583112716675\n",
      "\n",
      "Val func train loss in epoch 11:0.9192210771143436\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.8571164011955261\n",
      "\n",
      "episode 2, val func loss 1.0485635995864868\n",
      "\n",
      "episode 3, val func loss 0.8591141104698181\n",
      "\n",
      "episode 4, val func loss 0.7359121441841125\n",
      "\n",
      "episode 5, val func loss 0.867323100566864\n",
      "\n",
      "episode 6, val func loss 1.0845082998275757\n",
      "\n",
      "episode 7, val func loss 0.939591109752655\n",
      "\n",
      "episode 8, val func loss 0.80557781457901\n",
      "\n",
      "episode 9, val func loss 0.9244375228881836\n",
      "\n",
      "episode 10, val func loss 0.9703254699707031\n",
      "\n",
      "episode 11, val func loss 0.9486721754074097\n",
      "\n",
      "episode 12, val func loss 0.909949541091919\n",
      "\n",
      "episode 13, val func loss 0.8946372270584106\n",
      "\n",
      "episode 14, val func loss 0.8429522514343262\n",
      "\n",
      "episode 15, val func loss 0.8002675175666809\n",
      "\n",
      "episode 16, val func loss 0.9361010789871216\n",
      "\n",
      "Val func train loss in epoch 12:0.9015655852854252\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.9806147217750549\n",
      "\n",
      "episode 2, val func loss 0.9544475674629211\n",
      "\n",
      "episode 3, val func loss 0.9748001098632812\n",
      "\n",
      "episode 4, val func loss 1.1440298557281494\n",
      "\n",
      "episode 5, val func loss 0.83810955286026\n",
      "\n",
      "episode 6, val func loss 1.0258539915084839\n",
      "\n",
      "episode 7, val func loss 0.8735991716384888\n",
      "\n",
      "episode 8, val func loss 0.8377123475074768\n",
      "\n",
      "episode 9, val func loss 0.9043459892272949\n",
      "\n",
      "episode 10, val func loss 0.9161211848258972\n",
      "\n",
      "episode 11, val func loss 1.085336685180664\n",
      "\n",
      "episode 12, val func loss 0.9901472926139832\n",
      "\n",
      "episode 13, val func loss 0.9641892910003662\n",
      "\n",
      "episode 14, val func loss 0.9208313822746277\n",
      "\n",
      "episode 15, val func loss 0.7926770448684692\n",
      "\n",
      "episode 16, val func loss 1.0265929698944092\n",
      "\n",
      "Val func train loss in epoch 13:0.9518380723893642\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.9553940892219543\n",
      "\n",
      "episode 2, val func loss 0.7947232723236084\n",
      "\n",
      "episode 3, val func loss 0.9040652513504028\n",
      "\n",
      "episode 4, val func loss 0.8953944444656372\n",
      "\n",
      "episode 5, val func loss 0.9815806746482849\n",
      "\n",
      "episode 6, val func loss 0.7979303598403931\n",
      "\n",
      "episode 7, val func loss 0.8688600063323975\n",
      "\n",
      "episode 8, val func loss 0.8985453248023987\n",
      "\n",
      "episode 9, val func loss 0.9400999546051025\n",
      "\n",
      "episode 10, val func loss 0.8855624198913574\n",
      "\n",
      "episode 11, val func loss 0.7493762373924255\n",
      "\n",
      "episode 12, val func loss 0.9556543231010437\n",
      "\n",
      "episode 13, val func loss 0.8626844882965088\n",
      "\n",
      "episode 14, val func loss 0.8357371687889099\n",
      "\n",
      "episode 15, val func loss 0.9498329162597656\n",
      "\n",
      "episode 16, val func loss 0.8642761707305908\n",
      "\n",
      "Val func train loss in epoch 14:0.8837323188781738\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.8933908343315125\n",
      "\n",
      "episode 2, val func loss 0.8598600625991821\n",
      "\n",
      "episode 3, val func loss 1.0006214380264282\n",
      "\n",
      "episode 4, val func loss 0.8387253880500793\n",
      "\n",
      "episode 5, val func loss 0.8325304985046387\n",
      "\n",
      "episode 6, val func loss 0.8540453910827637\n",
      "\n",
      "episode 7, val func loss 0.953767716884613\n",
      "\n",
      "episode 8, val func loss 0.8470943570137024\n",
      "\n",
      "episode 9, val func loss 0.9730576276779175\n",
      "\n",
      "episode 10, val func loss 0.8604662418365479\n",
      "\n",
      "episode 11, val func loss 0.7948993444442749\n",
      "\n",
      "episode 12, val func loss 0.9171212315559387\n",
      "\n",
      "episode 13, val func loss 0.8293302059173584\n",
      "\n",
      "episode 14, val func loss 0.816410481929779\n",
      "\n",
      "episode 15, val func loss 0.9016415476799011\n",
      "\n",
      "episode 16, val func loss 0.9684407114982605\n",
      "\n",
      "Val func train loss in epoch 15:0.8838376924395561\n",
      "***********************TIME WAS 4.818131073315938 min*****************************\n",
      "\n",
      "**********************ROUND 48 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.4796331822872162\n",
      "\n",
      "episode 2, policy loss 0.4796332120895386\n",
      "\n",
      "episode 3, policy loss 0.47963252663612366\n",
      "\n",
      "episode 4, policy loss 0.4796326458454132\n",
      "\n",
      "episode 5, policy loss 0.47963351011276245\n",
      "\n",
      "episode 6, policy loss 0.4796316921710968\n",
      "\n",
      "episode 7, policy loss 0.4796328544616699\n",
      "\n",
      "episode 8, policy loss 0.47963136434555054\n",
      "\n",
      "episode 9, policy loss 0.47963231801986694\n",
      "\n",
      "episode 10, policy loss 0.4796333312988281\n",
      "\n",
      "episode 11, policy loss 0.4796336889266968\n",
      "\n",
      "episode 12, policy loss 0.47963187098503113\n",
      "\n",
      "episode 13, policy loss 0.47963282465934753\n",
      "\n",
      "episode 14, policy loss 0.479633092880249\n",
      "\n",
      "episode 15, policy loss 0.4796323776245117\n",
      "\n",
      "episode 16, policy loss 0.47963252663612366\n",
      "\n",
      "Policy train loss in epoch 0:0.47963268868625164\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.4796333312988281\n",
      "\n",
      "episode 2, policy loss 0.47963282465934753\n",
      "\n",
      "episode 3, policy loss 0.47963187098503113\n",
      "\n",
      "episode 4, policy loss 0.47963136434555054\n",
      "\n",
      "episode 5, policy loss 0.4796323776245117\n",
      "\n",
      "episode 6, policy loss 0.47963231801986694\n",
      "\n",
      "episode 7, policy loss 0.4796336889266968\n",
      "\n",
      "episode 8, policy loss 0.4796316921710968\n",
      "\n",
      "episode 9, policy loss 0.47963252663612366\n",
      "\n",
      "episode 10, policy loss 0.47963351011276245\n",
      "\n",
      "episode 11, policy loss 0.4796328544616699\n",
      "\n",
      "episode 12, policy loss 0.4796331822872162\n",
      "\n",
      "episode 13, policy loss 0.479633092880249\n",
      "\n",
      "episode 14, policy loss 0.4796326458454132\n",
      "\n",
      "episode 15, policy loss 0.47963252663612366\n",
      "\n",
      "episode 16, policy loss 0.4796332120895386\n",
      "\n",
      "Policy train loss in epoch 1:0.47963268868625164\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.479633092880249\n",
      "\n",
      "episode 2, policy loss 0.47963231801986694\n",
      "\n",
      "episode 3, policy loss 0.4796328544616699\n",
      "\n",
      "episode 4, policy loss 0.4796316921710968\n",
      "\n",
      "episode 5, policy loss 0.4796323776245117\n",
      "\n",
      "episode 6, policy loss 0.4796331822872162\n",
      "\n",
      "episode 7, policy loss 0.47963136434555054\n",
      "\n",
      "episode 8, policy loss 0.47963187098503113\n",
      "\n",
      "episode 9, policy loss 0.47963351011276245\n",
      "\n",
      "episode 10, policy loss 0.47963252663612366\n",
      "\n",
      "episode 11, policy loss 0.47963282465934753\n",
      "\n",
      "episode 12, policy loss 0.4796326458454132\n",
      "\n",
      "episode 13, policy loss 0.4796336889266968\n",
      "\n",
      "episode 14, policy loss 0.4796332120895386\n",
      "\n",
      "episode 15, policy loss 0.4796333312988281\n",
      "\n",
      "episode 16, policy loss 0.47963252663612366\n",
      "\n",
      "Policy train loss in epoch 2:0.47963268868625164\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.4796336889266968\n",
      "\n",
      "episode 2, policy loss 0.47963282465934753\n",
      "\n",
      "episode 3, policy loss 0.4796328544616699\n",
      "\n",
      "episode 4, policy loss 0.47963351011276245\n",
      "\n",
      "episode 5, policy loss 0.47963187098503113\n",
      "\n",
      "episode 6, policy loss 0.4796333312988281\n",
      "\n",
      "episode 7, policy loss 0.4796316921710968\n",
      "\n",
      "episode 8, policy loss 0.4796323776245117\n",
      "\n",
      "episode 9, policy loss 0.4796332120895386\n",
      "\n",
      "episode 10, policy loss 0.47963252663612366\n",
      "\n",
      "episode 11, policy loss 0.47963252663612366\n",
      "\n",
      "episode 12, policy loss 0.47963136434555054\n",
      "\n",
      "episode 13, policy loss 0.47963231801986694\n",
      "\n",
      "episode 14, policy loss 0.479633092880249\n",
      "\n",
      "episode 15, policy loss 0.4796331822872162\n",
      "\n",
      "episode 16, policy loss 0.4796326458454132\n",
      "\n",
      "Policy train loss in epoch 3:0.47963268868625164\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.9489342570304871\n",
      "\n",
      "episode 2, val func loss 0.8099814057350159\n",
      "\n",
      "episode 3, val func loss 0.9177040457725525\n",
      "\n",
      "episode 4, val func loss 0.9936427474021912\n",
      "\n",
      "episode 5, val func loss 0.9763321280479431\n",
      "\n",
      "episode 6, val func loss 1.0038130283355713\n",
      "\n",
      "episode 7, val func loss 1.025814414024353\n",
      "\n",
      "episode 8, val func loss 0.8359414935112\n",
      "\n",
      "episode 9, val func loss 0.9945254325866699\n",
      "\n",
      "episode 10, val func loss 0.874023973941803\n",
      "\n",
      "episode 11, val func loss 0.9601454138755798\n",
      "\n",
      "episode 12, val func loss 0.9703230261802673\n",
      "\n",
      "episode 13, val func loss 0.886271595954895\n",
      "\n",
      "episode 14, val func loss 1.031840443611145\n",
      "\n",
      "episode 15, val func loss 0.8788349628448486\n",
      "\n",
      "episode 16, val func loss 1.0210497379302979\n",
      "\n",
      "Val func train loss in epoch 0:0.9455736316740513\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.0380430221557617\n",
      "\n",
      "episode 2, val func loss 0.8544508814811707\n",
      "\n",
      "episode 3, val func loss 0.9683859348297119\n",
      "\n",
      "episode 4, val func loss 1.161072015762329\n",
      "\n",
      "episode 5, val func loss 0.8932034373283386\n",
      "\n",
      "episode 6, val func loss 1.1048054695129395\n",
      "\n",
      "episode 7, val func loss 1.0639814138412476\n",
      "\n",
      "episode 8, val func loss 0.9279285073280334\n",
      "\n",
      "episode 9, val func loss 1.0750600099563599\n",
      "\n",
      "episode 10, val func loss 0.9844939112663269\n",
      "\n",
      "episode 11, val func loss 1.0172101259231567\n",
      "\n",
      "episode 12, val func loss 1.0509963035583496\n",
      "\n",
      "episode 13, val func loss 1.142497181892395\n",
      "\n",
      "episode 14, val func loss 0.9248385429382324\n",
      "\n",
      "episode 15, val func loss 1.0033844709396362\n",
      "\n",
      "episode 16, val func loss 1.0100488662719727\n",
      "\n",
      "Val func train loss in epoch 1:1.0137750059366226\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.0753456354141235\n",
      "\n",
      "episode 2, val func loss 1.1010680198669434\n",
      "\n",
      "episode 3, val func loss 1.005677342414856\n",
      "\n",
      "episode 4, val func loss 0.9447742104530334\n",
      "\n",
      "episode 5, val func loss 1.024714469909668\n",
      "\n",
      "episode 6, val func loss 1.126163125038147\n",
      "\n",
      "episode 7, val func loss 0.9328437447547913\n",
      "\n",
      "episode 8, val func loss 1.017529845237732\n",
      "\n",
      "episode 9, val func loss 0.9894949197769165\n",
      "\n",
      "episode 10, val func loss 0.9934706687927246\n",
      "\n",
      "episode 11, val func loss 0.9452556371688843\n",
      "\n",
      "episode 12, val func loss 1.0426580905914307\n",
      "\n",
      "episode 13, val func loss 0.8744576573371887\n",
      "\n",
      "episode 14, val func loss 0.9333449602127075\n",
      "\n",
      "episode 15, val func loss 0.9616937637329102\n",
      "\n",
      "episode 16, val func loss 0.9328709840774536\n",
      "\n",
      "Val func train loss in epoch 2:0.9938351921737194\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.9203105568885803\n",
      "\n",
      "episode 2, val func loss 0.8678696751594543\n",
      "\n",
      "episode 3, val func loss 0.920660138130188\n",
      "\n",
      "episode 4, val func loss 0.9275086522102356\n",
      "\n",
      "episode 5, val func loss 0.9080890417098999\n",
      "\n",
      "episode 6, val func loss 0.9978105425834656\n",
      "\n",
      "episode 7, val func loss 0.8646368384361267\n",
      "\n",
      "episode 8, val func loss 0.8400776386260986\n",
      "\n",
      "episode 9, val func loss 1.112446904182434\n",
      "\n",
      "episode 10, val func loss 0.9477453231811523\n",
      "\n",
      "episode 11, val func loss 0.9359163641929626\n",
      "\n",
      "episode 12, val func loss 0.8662806153297424\n",
      "\n",
      "episode 13, val func loss 0.8803892135620117\n",
      "\n",
      "episode 14, val func loss 1.0930957794189453\n",
      "\n",
      "episode 15, val func loss 0.9859926104545593\n",
      "\n",
      "episode 16, val func loss 0.9072200059890747\n",
      "\n",
      "Val func train loss in epoch 3:0.9360031187534332\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.9079574942588806\n",
      "\n",
      "episode 2, val func loss 0.9444852471351624\n",
      "\n",
      "episode 3, val func loss 0.9510993957519531\n",
      "\n",
      "episode 4, val func loss 0.9821218848228455\n",
      "\n",
      "episode 5, val func loss 1.002146601676941\n",
      "\n",
      "episode 6, val func loss 1.0031813383102417\n",
      "\n",
      "episode 7, val func loss 0.7844315767288208\n",
      "\n",
      "episode 8, val func loss 0.9832475185394287\n",
      "\n",
      "episode 9, val func loss 0.794350266456604\n",
      "\n",
      "episode 10, val func loss 0.8450629115104675\n",
      "\n",
      "episode 11, val func loss 0.8882429003715515\n",
      "\n",
      "episode 12, val func loss 0.9042402505874634\n",
      "\n",
      "episode 13, val func loss 0.8900427222251892\n",
      "\n",
      "episode 14, val func loss 0.8987786173820496\n",
      "\n",
      "episode 15, val func loss 0.9991692304611206\n",
      "\n",
      "episode 16, val func loss 0.9002222418785095\n",
      "\n",
      "Val func train loss in epoch 4:0.9174237623810768\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.8678823709487915\n",
      "\n",
      "episode 2, val func loss 0.8784925937652588\n",
      "\n",
      "episode 3, val func loss 0.8988805413246155\n",
      "\n",
      "episode 4, val func loss 0.8804560899734497\n",
      "\n",
      "episode 5, val func loss 0.879997193813324\n",
      "\n",
      "episode 6, val func loss 0.9679804444313049\n",
      "\n",
      "episode 7, val func loss 0.8081656694412231\n",
      "\n",
      "episode 8, val func loss 0.808459997177124\n",
      "\n",
      "episode 9, val func loss 1.00142502784729\n",
      "\n",
      "episode 10, val func loss 0.9377809166908264\n",
      "\n",
      "episode 11, val func loss 0.9962246417999268\n",
      "\n",
      "episode 12, val func loss 0.9069972038269043\n",
      "\n",
      "episode 13, val func loss 1.0498020648956299\n",
      "\n",
      "episode 14, val func loss 0.8809517621994019\n",
      "\n",
      "episode 15, val func loss 0.9392139911651611\n",
      "\n",
      "episode 16, val func loss 1.0037075281143188\n",
      "\n",
      "Val func train loss in epoch 5:0.9191511273384094\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.9134726524353027\n",
      "\n",
      "episode 2, val func loss 0.83485347032547\n",
      "\n",
      "episode 3, val func loss 0.9263983964920044\n",
      "\n",
      "episode 4, val func loss 0.8995360732078552\n",
      "\n",
      "episode 5, val func loss 0.8791460990905762\n",
      "\n",
      "episode 6, val func loss 0.7679666876792908\n",
      "\n",
      "episode 7, val func loss 0.9166883826255798\n",
      "\n",
      "episode 8, val func loss 1.0483953952789307\n",
      "\n",
      "episode 9, val func loss 0.7974575161933899\n",
      "\n",
      "episode 10, val func loss 0.8711941242218018\n",
      "\n",
      "episode 11, val func loss 0.9412217736244202\n",
      "\n",
      "episode 12, val func loss 1.0060656070709229\n",
      "\n",
      "episode 13, val func loss 0.8609024882316589\n",
      "\n",
      "episode 14, val func loss 0.8094847202301025\n",
      "\n",
      "episode 15, val func loss 0.9773768782615662\n",
      "\n",
      "episode 16, val func loss 0.8761819005012512\n",
      "\n",
      "Val func train loss in epoch 6:0.8953963853418827\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.8789825439453125\n",
      "\n",
      "episode 2, val func loss 0.912642776966095\n",
      "\n",
      "episode 3, val func loss 0.9425133466720581\n",
      "\n",
      "episode 4, val func loss 0.8239044547080994\n",
      "\n",
      "episode 5, val func loss 0.8532161116600037\n",
      "\n",
      "episode 6, val func loss 0.9237486720085144\n",
      "\n",
      "episode 7, val func loss 0.7960742712020874\n",
      "\n",
      "episode 8, val func loss 0.9078035950660706\n",
      "\n",
      "episode 9, val func loss 0.8409661054611206\n",
      "\n",
      "episode 10, val func loss 0.9014459848403931\n",
      "\n",
      "episode 11, val func loss 0.8960966467857361\n",
      "\n",
      "episode 12, val func loss 0.9639629125595093\n",
      "\n",
      "episode 13, val func loss 0.8924119472503662\n",
      "\n",
      "episode 14, val func loss 0.9502273201942444\n",
      "\n",
      "episode 15, val func loss 0.9156542420387268\n",
      "\n",
      "episode 16, val func loss 0.7625554800033569\n",
      "\n",
      "Val func train loss in epoch 7:0.8851379007101059\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8871203064918518\n",
      "\n",
      "episode 2, val func loss 0.7807142734527588\n",
      "\n",
      "episode 3, val func loss 0.9741703867912292\n",
      "\n",
      "episode 4, val func loss 0.7584829330444336\n",
      "\n",
      "episode 5, val func loss 0.91177898645401\n",
      "\n",
      "episode 6, val func loss 0.7837945818901062\n",
      "\n",
      "episode 7, val func loss 1.0519598722457886\n",
      "\n",
      "episode 8, val func loss 0.9632677435874939\n",
      "\n",
      "episode 9, val func loss 1.0266597270965576\n",
      "\n",
      "episode 10, val func loss 1.083475947380066\n",
      "\n",
      "episode 11, val func loss 0.8727753758430481\n",
      "\n",
      "episode 12, val func loss 0.9706878066062927\n",
      "\n",
      "episode 13, val func loss 0.8948823809623718\n",
      "\n",
      "episode 14, val func loss 0.8696314096450806\n",
      "\n",
      "episode 15, val func loss 0.8892518877983093\n",
      "\n",
      "episode 16, val func loss 0.8354310989379883\n",
      "\n",
      "Val func train loss in epoch 8:0.9096302948892117\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8548363447189331\n",
      "\n",
      "episode 2, val func loss 0.8453371524810791\n",
      "\n",
      "episode 3, val func loss 0.8917633891105652\n",
      "\n",
      "episode 4, val func loss 1.073203206062317\n",
      "\n",
      "episode 5, val func loss 0.8807289600372314\n",
      "\n",
      "episode 6, val func loss 0.9556815028190613\n",
      "\n",
      "episode 7, val func loss 0.8197962045669556\n",
      "\n",
      "episode 8, val func loss 0.9466887712478638\n",
      "\n",
      "episode 9, val func loss 0.8207666873931885\n",
      "\n",
      "episode 10, val func loss 0.8662754893302917\n",
      "\n",
      "episode 11, val func loss 0.8959572315216064\n",
      "\n",
      "episode 12, val func loss 0.7918722629547119\n",
      "\n",
      "episode 13, val func loss 0.845689058303833\n",
      "\n",
      "episode 14, val func loss 1.0594993829727173\n",
      "\n",
      "episode 15, val func loss 0.8433051705360413\n",
      "\n",
      "episode 16, val func loss 0.8698641657829285\n",
      "\n",
      "Val func train loss in epoch 9:0.8913290612399578\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.9162253737449646\n",
      "\n",
      "episode 2, val func loss 0.7977702021598816\n",
      "\n",
      "episode 3, val func loss 0.8895103931427002\n",
      "\n",
      "episode 4, val func loss 0.9716259837150574\n",
      "\n",
      "episode 5, val func loss 0.8747915625572205\n",
      "\n",
      "episode 6, val func loss 0.8566998243331909\n",
      "\n",
      "episode 7, val func loss 0.9239054322242737\n",
      "\n",
      "episode 8, val func loss 0.727022111415863\n",
      "\n",
      "episode 9, val func loss 0.8335511684417725\n",
      "\n",
      "episode 10, val func loss 0.7986173629760742\n",
      "\n",
      "episode 11, val func loss 0.9527602195739746\n",
      "\n",
      "episode 12, val func loss 1.003835916519165\n",
      "\n",
      "episode 13, val func loss 0.8944835066795349\n",
      "\n",
      "episode 14, val func loss 0.9470083713531494\n",
      "\n",
      "episode 15, val func loss 0.9841537475585938\n",
      "\n",
      "episode 16, val func loss 1.051811933517456\n",
      "\n",
      "Val func train loss in epoch 10:0.9014858193695545\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9114655256271362\n",
      "\n",
      "episode 2, val func loss 1.0488255023956299\n",
      "\n",
      "episode 3, val func loss 0.8826327919960022\n",
      "\n",
      "episode 4, val func loss 0.8788048624992371\n",
      "\n",
      "episode 5, val func loss 0.8218688368797302\n",
      "\n",
      "episode 6, val func loss 0.9486511945724487\n",
      "\n",
      "episode 7, val func loss 0.9707931876182556\n",
      "\n",
      "episode 8, val func loss 0.9279877543449402\n",
      "\n",
      "episode 9, val func loss 0.8654646277427673\n",
      "\n",
      "episode 10, val func loss 1.0214074850082397\n",
      "\n",
      "episode 11, val func loss 0.9326425194740295\n",
      "\n",
      "episode 12, val func loss 0.8200798034667969\n",
      "\n",
      "episode 13, val func loss 0.9423859715461731\n",
      "\n",
      "episode 14, val func loss 0.9742950201034546\n",
      "\n",
      "episode 15, val func loss 0.8378246426582336\n",
      "\n",
      "episode 16, val func loss 1.07774019241333\n",
      "\n",
      "Val func train loss in epoch 11:0.9289293698966503\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.0099287033081055\n",
      "\n",
      "episode 2, val func loss 0.9350528120994568\n",
      "\n",
      "episode 3, val func loss 0.9336867928504944\n",
      "\n",
      "episode 4, val func loss 0.9221771955490112\n",
      "\n",
      "episode 5, val func loss 1.1355946063995361\n",
      "\n",
      "episode 6, val func loss 1.0615917444229126\n",
      "\n",
      "episode 7, val func loss 0.860053300857544\n",
      "\n",
      "episode 8, val func loss 1.042784571647644\n",
      "\n",
      "episode 9, val func loss 0.9526495933532715\n",
      "\n",
      "episode 10, val func loss 0.8849747776985168\n",
      "\n",
      "episode 11, val func loss 1.0657432079315186\n",
      "\n",
      "episode 12, val func loss 0.9029452204704285\n",
      "\n",
      "episode 13, val func loss 0.9202612638473511\n",
      "\n",
      "episode 14, val func loss 0.8272117972373962\n",
      "\n",
      "episode 15, val func loss 0.8913542628288269\n",
      "\n",
      "episode 16, val func loss 0.9175999164581299\n",
      "\n",
      "Val func train loss in epoch 12:0.953975610435009\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.9689949750900269\n",
      "\n",
      "episode 2, val func loss 0.8885205388069153\n",
      "\n",
      "episode 3, val func loss 0.9723353385925293\n",
      "\n",
      "episode 4, val func loss 0.9410069584846497\n",
      "\n",
      "episode 5, val func loss 1.181939959526062\n",
      "\n",
      "episode 6, val func loss 1.089835524559021\n",
      "\n",
      "episode 7, val func loss 0.8087180852890015\n",
      "\n",
      "episode 8, val func loss 1.0712543725967407\n",
      "\n",
      "episode 9, val func loss 0.8503729701042175\n",
      "\n",
      "episode 10, val func loss 1.0744104385375977\n",
      "\n",
      "episode 11, val func loss 0.9496685862541199\n",
      "\n",
      "episode 12, val func loss 1.0060628652572632\n",
      "\n",
      "episode 13, val func loss 0.9445807337760925\n",
      "\n",
      "episode 14, val func loss 0.9767815470695496\n",
      "\n",
      "episode 15, val func loss 1.0572896003723145\n",
      "\n",
      "episode 16, val func loss 0.8758602142333984\n",
      "\n",
      "Val func train loss in epoch 13:0.9786020442843437\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.9978725910186768\n",
      "\n",
      "episode 2, val func loss 0.9675976634025574\n",
      "\n",
      "episode 3, val func loss 0.89540696144104\n",
      "\n",
      "episode 4, val func loss 0.8675223588943481\n",
      "\n",
      "episode 5, val func loss 1.0135655403137207\n",
      "\n",
      "episode 6, val func loss 1.0355228185653687\n",
      "\n",
      "episode 7, val func loss 0.9477671980857849\n",
      "\n",
      "episode 8, val func loss 0.9393261075019836\n",
      "\n",
      "episode 9, val func loss 0.7663292288780212\n",
      "\n",
      "episode 10, val func loss 0.9774510264396667\n",
      "\n",
      "episode 11, val func loss 0.900000274181366\n",
      "\n",
      "episode 12, val func loss 0.9505032300949097\n",
      "\n",
      "episode 13, val func loss 0.8550397753715515\n",
      "\n",
      "episode 14, val func loss 0.8259181976318359\n",
      "\n",
      "episode 15, val func loss 0.8119308948516846\n",
      "\n",
      "episode 16, val func loss 0.9684850573539734\n",
      "\n",
      "Val func train loss in epoch 14:0.9200149327516556\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.9994014501571655\n",
      "\n",
      "episode 2, val func loss 0.9266969561576843\n",
      "\n",
      "episode 3, val func loss 0.9969083666801453\n",
      "\n",
      "episode 4, val func loss 0.9833155274391174\n",
      "\n",
      "episode 5, val func loss 1.0158584117889404\n",
      "\n",
      "episode 6, val func loss 0.8479337692260742\n",
      "\n",
      "episode 7, val func loss 0.9797360897064209\n",
      "\n",
      "episode 8, val func loss 0.8837593793869019\n",
      "\n",
      "episode 9, val func loss 0.8785858154296875\n",
      "\n",
      "episode 10, val func loss 0.87151038646698\n",
      "\n",
      "episode 11, val func loss 0.8981122970581055\n",
      "\n",
      "episode 12, val func loss 0.9206953048706055\n",
      "\n",
      "episode 13, val func loss 0.9427762627601624\n",
      "\n",
      "episode 14, val func loss 0.8431618809700012\n",
      "\n",
      "episode 15, val func loss 0.9346714019775391\n",
      "\n",
      "episode 16, val func loss 0.9790002703666687\n",
      "\n",
      "Val func train loss in epoch 15:0.9313827231526375\n",
      "***********************TIME WAS 4.81873943010966 min*****************************\n",
      "\n",
      "**********************ROUND 49 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.2751015424728394\n",
      "\n",
      "episode 2, policy loss 1.2751009464263916\n",
      "\n",
      "episode 3, policy loss 1.2751017808914185\n",
      "\n",
      "episode 4, policy loss 1.275100588798523\n",
      "\n",
      "episode 5, policy loss 1.2751013040542603\n",
      "\n",
      "episode 6, policy loss 1.2751009464263916\n",
      "\n",
      "episode 7, policy loss 1.2751015424728394\n",
      "\n",
      "episode 8, policy loss 1.2751013040542603\n",
      "\n",
      "episode 9, policy loss 1.2751013040542603\n",
      "\n",
      "episode 10, policy loss 1.275101661682129\n",
      "\n",
      "episode 11, policy loss 1.2751014232635498\n",
      "\n",
      "episode 12, policy loss 1.2751014232635498\n",
      "\n",
      "episode 13, policy loss 1.2751015424728394\n",
      "\n",
      "episode 14, policy loss 1.2751003503799438\n",
      "\n",
      "episode 15, policy loss 1.2751007080078125\n",
      "\n",
      "episode 16, policy loss 1.2751010656356812\n",
      "\n",
      "Policy train loss in epoch 0:1.275101214647293\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.2751013040542603\n",
      "\n",
      "episode 2, policy loss 1.2751003503799438\n",
      "\n",
      "episode 3, policy loss 1.275101661682129\n",
      "\n",
      "episode 4, policy loss 1.2751014232635498\n",
      "\n",
      "episode 5, policy loss 1.275100588798523\n",
      "\n",
      "episode 6, policy loss 1.2751015424728394\n",
      "\n",
      "episode 7, policy loss 1.2751010656356812\n",
      "\n",
      "episode 8, policy loss 1.2751013040542603\n",
      "\n",
      "episode 9, policy loss 1.2751015424728394\n",
      "\n",
      "episode 10, policy loss 1.2751009464263916\n",
      "\n",
      "episode 11, policy loss 1.2751013040542603\n",
      "\n",
      "episode 12, policy loss 1.2751014232635498\n",
      "\n",
      "episode 13, policy loss 1.2751009464263916\n",
      "\n",
      "episode 14, policy loss 1.2751007080078125\n",
      "\n",
      "episode 15, policy loss 1.2751017808914185\n",
      "\n",
      "episode 16, policy loss 1.2751015424728394\n",
      "\n",
      "Policy train loss in epoch 1:1.275101214647293\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.2751009464263916\n",
      "\n",
      "episode 2, policy loss 1.2751014232635498\n",
      "\n",
      "episode 3, policy loss 1.2751007080078125\n",
      "\n",
      "episode 4, policy loss 1.275100588798523\n",
      "\n",
      "episode 5, policy loss 1.2751014232635498\n",
      "\n",
      "episode 6, policy loss 1.2751017808914185\n",
      "\n",
      "episode 7, policy loss 1.2751009464263916\n",
      "\n",
      "episode 8, policy loss 1.2751013040542603\n",
      "\n",
      "episode 9, policy loss 1.2751013040542603\n",
      "\n",
      "episode 10, policy loss 1.2751015424728394\n",
      "\n",
      "episode 11, policy loss 1.275101661682129\n",
      "\n",
      "episode 12, policy loss 1.2751010656356812\n",
      "\n",
      "episode 13, policy loss 1.2751015424728394\n",
      "\n",
      "episode 14, policy loss 1.2751015424728394\n",
      "\n",
      "episode 15, policy loss 1.2751013040542603\n",
      "\n",
      "episode 16, policy loss 1.2751003503799438\n",
      "\n",
      "Policy train loss in epoch 2:1.275101214647293\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.2751009464263916\n",
      "\n",
      "episode 2, policy loss 1.2751013040542603\n",
      "\n",
      "episode 3, policy loss 1.275100588798523\n",
      "\n",
      "episode 4, policy loss 1.2751003503799438\n",
      "\n",
      "episode 5, policy loss 1.2751013040542603\n",
      "\n",
      "episode 6, policy loss 1.2751015424728394\n",
      "\n",
      "episode 7, policy loss 1.2751009464263916\n",
      "\n",
      "episode 8, policy loss 1.2751013040542603\n",
      "\n",
      "episode 9, policy loss 1.2751017808914185\n",
      "\n",
      "episode 10, policy loss 1.2751015424728394\n",
      "\n",
      "episode 11, policy loss 1.2751014232635498\n",
      "\n",
      "episode 12, policy loss 1.2751015424728394\n",
      "\n",
      "episode 13, policy loss 1.2751014232635498\n",
      "\n",
      "episode 14, policy loss 1.2751007080078125\n",
      "\n",
      "episode 15, policy loss 1.2751010656356812\n",
      "\n",
      "episode 16, policy loss 1.275101661682129\n",
      "\n",
      "Policy train loss in epoch 3:1.275101214647293\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.9400078654289246\n",
      "\n",
      "episode 2, val func loss 0.9397273063659668\n",
      "\n",
      "episode 3, val func loss 0.8864567279815674\n",
      "\n",
      "episode 4, val func loss 0.9668748378753662\n",
      "\n",
      "episode 5, val func loss 0.9148639440536499\n",
      "\n",
      "episode 6, val func loss 0.916296124458313\n",
      "\n",
      "episode 7, val func loss 0.8509130477905273\n",
      "\n",
      "episode 8, val func loss 0.7867448329925537\n",
      "\n",
      "episode 9, val func loss 0.8732341527938843\n",
      "\n",
      "episode 10, val func loss 0.8327998518943787\n",
      "\n",
      "episode 11, val func loss 0.7783702611923218\n",
      "\n",
      "episode 12, val func loss 0.9808696508407593\n",
      "\n",
      "episode 13, val func loss 0.96991366147995\n",
      "\n",
      "episode 14, val func loss 0.869764506816864\n",
      "\n",
      "episode 15, val func loss 0.8030229806900024\n",
      "\n",
      "episode 16, val func loss 0.8731133937835693\n",
      "\n",
      "Val func train loss in epoch 0:0.8864358216524124\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7629746198654175\n",
      "\n",
      "episode 2, val func loss 0.9414835572242737\n",
      "\n",
      "episode 3, val func loss 0.8814550042152405\n",
      "\n",
      "episode 4, val func loss 0.8022375106811523\n",
      "\n",
      "episode 5, val func loss 0.9124208092689514\n",
      "\n",
      "episode 6, val func loss 0.9121370315551758\n",
      "\n",
      "episode 7, val func loss 0.8093221187591553\n",
      "\n",
      "episode 8, val func loss 0.8158710598945618\n",
      "\n",
      "episode 9, val func loss 0.8907989859580994\n",
      "\n",
      "episode 10, val func loss 0.9452550411224365\n",
      "\n",
      "episode 11, val func loss 0.827336847782135\n",
      "\n",
      "episode 12, val func loss 0.9674014449119568\n",
      "\n",
      "episode 13, val func loss 0.8651602268218994\n",
      "\n",
      "episode 14, val func loss 0.7645084857940674\n",
      "\n",
      "episode 15, val func loss 0.8236196637153625\n",
      "\n",
      "episode 16, val func loss 0.8368839621543884\n",
      "\n",
      "Val func train loss in epoch 1:0.8599291481077671\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.844106137752533\n",
      "\n",
      "episode 2, val func loss 0.8460356593132019\n",
      "\n",
      "episode 3, val func loss 0.8365675210952759\n",
      "\n",
      "episode 4, val func loss 0.7353110909461975\n",
      "\n",
      "episode 5, val func loss 0.8509727120399475\n",
      "\n",
      "episode 6, val func loss 0.9481853246688843\n",
      "\n",
      "episode 7, val func loss 0.8494858145713806\n",
      "\n",
      "episode 8, val func loss 0.8795095086097717\n",
      "\n",
      "episode 9, val func loss 0.8583973050117493\n",
      "\n",
      "episode 10, val func loss 0.8952890634536743\n",
      "\n",
      "episode 11, val func loss 0.82240229845047\n",
      "\n",
      "episode 12, val func loss 0.9867093563079834\n",
      "\n",
      "episode 13, val func loss 0.9277642369270325\n",
      "\n",
      "episode 14, val func loss 0.8727062940597534\n",
      "\n",
      "episode 15, val func loss 1.008280873298645\n",
      "\n",
      "episode 16, val func loss 0.8162299394607544\n",
      "\n",
      "Val func train loss in epoch 2:0.8736220709979534\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.9951288104057312\n",
      "\n",
      "episode 2, val func loss 0.8940585851669312\n",
      "\n",
      "episode 3, val func loss 0.991978108882904\n",
      "\n",
      "episode 4, val func loss 0.8897568583488464\n",
      "\n",
      "episode 5, val func loss 1.0000731945037842\n",
      "\n",
      "episode 6, val func loss 0.8334305882453918\n",
      "\n",
      "episode 7, val func loss 0.7997717261314392\n",
      "\n",
      "episode 8, val func loss 0.9578323364257812\n",
      "\n",
      "episode 9, val func loss 0.8379136323928833\n",
      "\n",
      "episode 10, val func loss 0.9820480346679688\n",
      "\n",
      "episode 11, val func loss 0.9755131602287292\n",
      "\n",
      "episode 12, val func loss 0.888031005859375\n",
      "\n",
      "episode 13, val func loss 0.8900569677352905\n",
      "\n",
      "episode 14, val func loss 0.9775969386100769\n",
      "\n",
      "episode 15, val func loss 0.9400718808174133\n",
      "\n",
      "episode 16, val func loss 0.923552930355072\n",
      "\n",
      "Val func train loss in epoch 3:0.9235509224236012\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.9884088039398193\n",
      "\n",
      "episode 2, val func loss 0.8750796318054199\n",
      "\n",
      "episode 3, val func loss 0.9116273522377014\n",
      "\n",
      "episode 4, val func loss 0.7539007067680359\n",
      "\n",
      "episode 5, val func loss 0.7238317131996155\n",
      "\n",
      "episode 6, val func loss 1.005973219871521\n",
      "\n",
      "episode 7, val func loss 0.8823150396347046\n",
      "\n",
      "episode 8, val func loss 0.8573492169380188\n",
      "\n",
      "episode 9, val func loss 0.9446300268173218\n",
      "\n",
      "episode 10, val func loss 0.8198701739311218\n",
      "\n",
      "episode 11, val func loss 0.9860717058181763\n",
      "\n",
      "episode 12, val func loss 1.02653169631958\n",
      "\n",
      "episode 13, val func loss 0.8504599928855896\n",
      "\n",
      "episode 14, val func loss 0.7719740867614746\n",
      "\n",
      "episode 15, val func loss 1.115525484085083\n",
      "\n",
      "episode 16, val func loss 0.9606603980064392\n",
      "\n",
      "Val func train loss in epoch 4:0.9046380780637264\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.9146795272827148\n",
      "\n",
      "episode 2, val func loss 0.9150025248527527\n",
      "\n",
      "episode 3, val func loss 0.9241659045219421\n",
      "\n",
      "episode 4, val func loss 0.771719753742218\n",
      "\n",
      "episode 5, val func loss 0.932159960269928\n",
      "\n",
      "episode 6, val func loss 0.8820416927337646\n",
      "\n",
      "episode 7, val func loss 0.8866106867790222\n",
      "\n",
      "episode 8, val func loss 0.8696879744529724\n",
      "\n",
      "episode 9, val func loss 0.9054521918296814\n",
      "\n",
      "episode 10, val func loss 0.8235712647438049\n",
      "\n",
      "episode 11, val func loss 0.8690181374549866\n",
      "\n",
      "episode 12, val func loss 0.9570735692977905\n",
      "\n",
      "episode 13, val func loss 0.8416472673416138\n",
      "\n",
      "episode 14, val func loss 0.8822059631347656\n",
      "\n",
      "episode 15, val func loss 0.917389452457428\n",
      "\n",
      "episode 16, val func loss 1.0435621738433838\n",
      "\n",
      "Val func train loss in epoch 5:0.8959992527961731\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.9556684494018555\n",
      "\n",
      "episode 2, val func loss 0.8741042017936707\n",
      "\n",
      "episode 3, val func loss 0.8659796118736267\n",
      "\n",
      "episode 4, val func loss 0.9762439131736755\n",
      "\n",
      "episode 5, val func loss 0.8137973546981812\n",
      "\n",
      "episode 6, val func loss 0.9998583793640137\n",
      "\n",
      "episode 7, val func loss 0.8649725317955017\n",
      "\n",
      "episode 8, val func loss 1.0613491535186768\n",
      "\n",
      "episode 9, val func loss 0.777847945690155\n",
      "\n",
      "episode 10, val func loss 0.7712974548339844\n",
      "\n",
      "episode 11, val func loss 0.8835473656654358\n",
      "\n",
      "episode 12, val func loss 0.714058518409729\n",
      "\n",
      "episode 13, val func loss 0.7559267282485962\n",
      "\n",
      "episode 14, val func loss 0.9780226349830627\n",
      "\n",
      "episode 15, val func loss 0.8544563055038452\n",
      "\n",
      "episode 16, val func loss 0.9310762286186218\n",
      "\n",
      "Val func train loss in epoch 6:0.8798879235982895\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.8468203544616699\n",
      "\n",
      "episode 2, val func loss 0.9954031705856323\n",
      "\n",
      "episode 3, val func loss 0.8391347527503967\n",
      "\n",
      "episode 4, val func loss 0.891714334487915\n",
      "\n",
      "episode 5, val func loss 0.8509374856948853\n",
      "\n",
      "episode 6, val func loss 0.8257100582122803\n",
      "\n",
      "episode 7, val func loss 0.8329796195030212\n",
      "\n",
      "episode 8, val func loss 0.9147912263870239\n",
      "\n",
      "episode 9, val func loss 0.8106040954589844\n",
      "\n",
      "episode 10, val func loss 0.8216995596885681\n",
      "\n",
      "episode 11, val func loss 0.8047427535057068\n",
      "\n",
      "episode 12, val func loss 0.8693161010742188\n",
      "\n",
      "episode 13, val func loss 0.7760550379753113\n",
      "\n",
      "episode 14, val func loss 0.8087186813354492\n",
      "\n",
      "episode 15, val func loss 0.7941702008247375\n",
      "\n",
      "episode 16, val func loss 0.8507037162780762\n",
      "\n",
      "Val func train loss in epoch 7:0.8458438217639923\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.883167028427124\n",
      "\n",
      "episode 2, val func loss 0.8360641598701477\n",
      "\n",
      "episode 3, val func loss 0.8261916041374207\n",
      "\n",
      "episode 4, val func loss 0.8822152614593506\n",
      "\n",
      "episode 5, val func loss 0.8871056437492371\n",
      "\n",
      "episode 6, val func loss 0.8168521523475647\n",
      "\n",
      "episode 7, val func loss 0.8187806606292725\n",
      "\n",
      "episode 8, val func loss 0.8251619935035706\n",
      "\n",
      "episode 9, val func loss 0.7946282625198364\n",
      "\n",
      "episode 10, val func loss 0.9265172481536865\n",
      "\n",
      "episode 11, val func loss 0.7986242771148682\n",
      "\n",
      "episode 12, val func loss 0.8756670951843262\n",
      "\n",
      "episode 13, val func loss 0.9263388514518738\n",
      "\n",
      "episode 14, val func loss 0.988410234451294\n",
      "\n",
      "episode 15, val func loss 0.8656503558158875\n",
      "\n",
      "episode 16, val func loss 0.8672459721565247\n",
      "\n",
      "Val func train loss in epoch 8:0.863663800060749\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.967240035533905\n",
      "\n",
      "episode 2, val func loss 0.9104976058006287\n",
      "\n",
      "episode 3, val func loss 0.9742060303688049\n",
      "\n",
      "episode 4, val func loss 0.7961512207984924\n",
      "\n",
      "episode 5, val func loss 1.0716745853424072\n",
      "\n",
      "episode 6, val func loss 0.8798088431358337\n",
      "\n",
      "episode 7, val func loss 0.9732175469398499\n",
      "\n",
      "episode 8, val func loss 0.950402557849884\n",
      "\n",
      "episode 9, val func loss 0.8286136984825134\n",
      "\n",
      "episode 10, val func loss 1.0100347995758057\n",
      "\n",
      "episode 11, val func loss 0.8401988744735718\n",
      "\n",
      "episode 12, val func loss 0.9313191175460815\n",
      "\n",
      "episode 13, val func loss 1.0027121305465698\n",
      "\n",
      "episode 14, val func loss 0.9134137034416199\n",
      "\n",
      "episode 15, val func loss 1.0462026596069336\n",
      "\n",
      "episode 16, val func loss 0.8564262390136719\n",
      "\n",
      "Val func train loss in epoch 9:0.9345074780285358\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7946487069129944\n",
      "\n",
      "episode 2, val func loss 0.9150527715682983\n",
      "\n",
      "episode 3, val func loss 0.8982713222503662\n",
      "\n",
      "episode 4, val func loss 0.8310747742652893\n",
      "\n",
      "episode 5, val func loss 0.9444313049316406\n",
      "\n",
      "episode 6, val func loss 0.9045639038085938\n",
      "\n",
      "episode 7, val func loss 0.9034913182258606\n",
      "\n",
      "episode 8, val func loss 0.8486195802688599\n",
      "\n",
      "episode 9, val func loss 0.8660192489624023\n",
      "\n",
      "episode 10, val func loss 0.8909127712249756\n",
      "\n",
      "episode 11, val func loss 0.9345071315765381\n",
      "\n",
      "episode 12, val func loss 0.9206414818763733\n",
      "\n",
      "episode 13, val func loss 0.90220046043396\n",
      "\n",
      "episode 14, val func loss 0.8565724492073059\n",
      "\n",
      "episode 15, val func loss 0.9095600247383118\n",
      "\n",
      "episode 16, val func loss 0.9704956412315369\n",
      "\n",
      "Val func train loss in epoch 10:0.8931914307177067\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.8926274180412292\n",
      "\n",
      "episode 2, val func loss 0.9467506408691406\n",
      "\n",
      "episode 3, val func loss 0.8238417506217957\n",
      "\n",
      "episode 4, val func loss 0.8460688591003418\n",
      "\n",
      "episode 5, val func loss 0.8239575624465942\n",
      "\n",
      "episode 6, val func loss 0.8100954294204712\n",
      "\n",
      "episode 7, val func loss 0.8802111148834229\n",
      "\n",
      "episode 8, val func loss 0.924992561340332\n",
      "\n",
      "episode 9, val func loss 0.9360429644584656\n",
      "\n",
      "episode 10, val func loss 0.8275785446166992\n",
      "\n",
      "episode 11, val func loss 0.7209839224815369\n",
      "\n",
      "episode 12, val func loss 0.880706250667572\n",
      "\n",
      "episode 13, val func loss 0.8315623998641968\n",
      "\n",
      "episode 14, val func loss 0.8509275317192078\n",
      "\n",
      "episode 15, val func loss 0.9317272305488586\n",
      "\n",
      "episode 16, val func loss 0.8325936794281006\n",
      "\n",
      "Val func train loss in epoch 11:0.8600417412817478\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7508758902549744\n",
      "\n",
      "episode 2, val func loss 0.8690064549446106\n",
      "\n",
      "episode 3, val func loss 0.8342927098274231\n",
      "\n",
      "episode 4, val func loss 0.8418688178062439\n",
      "\n",
      "episode 5, val func loss 0.8310485482215881\n",
      "\n",
      "episode 6, val func loss 0.8849872946739197\n",
      "\n",
      "episode 7, val func loss 0.9206234812736511\n",
      "\n",
      "episode 8, val func loss 0.8974780440330505\n",
      "\n",
      "episode 9, val func loss 0.8863739371299744\n",
      "\n",
      "episode 10, val func loss 0.8189186453819275\n",
      "\n",
      "episode 11, val func loss 0.8120019435882568\n",
      "\n",
      "episode 12, val func loss 0.7684027552604675\n",
      "\n",
      "episode 13, val func loss 0.7773881554603577\n",
      "\n",
      "episode 14, val func loss 0.81025230884552\n",
      "\n",
      "episode 15, val func loss 0.7872572541236877\n",
      "\n",
      "episode 16, val func loss 0.8513020277023315\n",
      "\n",
      "Val func train loss in epoch 12:0.833879891782999\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8605241775512695\n",
      "\n",
      "episode 2, val func loss 0.7682133913040161\n",
      "\n",
      "episode 3, val func loss 0.8649359941482544\n",
      "\n",
      "episode 4, val func loss 0.8626193404197693\n",
      "\n",
      "episode 5, val func loss 0.8342903852462769\n",
      "\n",
      "episode 6, val func loss 0.8170729875564575\n",
      "\n",
      "episode 7, val func loss 0.9110075831413269\n",
      "\n",
      "episode 8, val func loss 0.8181529641151428\n",
      "\n",
      "episode 9, val func loss 0.7951413989067078\n",
      "\n",
      "episode 10, val func loss 0.7965487837791443\n",
      "\n",
      "episode 11, val func loss 0.8501550555229187\n",
      "\n",
      "episode 12, val func loss 0.8807799220085144\n",
      "\n",
      "episode 13, val func loss 0.8157142996788025\n",
      "\n",
      "episode 14, val func loss 0.9135631322860718\n",
      "\n",
      "episode 15, val func loss 0.965618371963501\n",
      "\n",
      "episode 16, val func loss 0.8823890686035156\n",
      "\n",
      "Val func train loss in epoch 13:0.8522954285144806\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.8617481589317322\n",
      "\n",
      "episode 2, val func loss 0.8077834844589233\n",
      "\n",
      "episode 3, val func loss 0.8852517008781433\n",
      "\n",
      "episode 4, val func loss 0.8893438577651978\n",
      "\n",
      "episode 5, val func loss 0.9573361277580261\n",
      "\n",
      "episode 6, val func loss 0.9660517573356628\n",
      "\n",
      "episode 7, val func loss 0.8712870478630066\n",
      "\n",
      "episode 8, val func loss 0.8604597449302673\n",
      "\n",
      "episode 9, val func loss 0.9542360901832581\n",
      "\n",
      "episode 10, val func loss 0.8901094794273376\n",
      "\n",
      "episode 11, val func loss 0.7621150016784668\n",
      "\n",
      "episode 12, val func loss 0.9279894828796387\n",
      "\n",
      "episode 13, val func loss 1.237978458404541\n",
      "\n",
      "episode 14, val func loss 0.8595324158668518\n",
      "\n",
      "episode 15, val func loss 0.8938583731651306\n",
      "\n",
      "episode 16, val func loss 0.8076589107513428\n",
      "\n",
      "Val func train loss in epoch 14:0.9020462557673454\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.9154567718505859\n",
      "\n",
      "episode 2, val func loss 0.9027544856071472\n",
      "\n",
      "episode 3, val func loss 0.9121315479278564\n",
      "\n",
      "episode 4, val func loss 0.8519012928009033\n",
      "\n",
      "episode 5, val func loss 0.9202984571456909\n",
      "\n",
      "episode 6, val func loss 0.7973667979240417\n",
      "\n",
      "episode 7, val func loss 0.801934540271759\n",
      "\n",
      "episode 8, val func loss 0.8142748475074768\n",
      "\n",
      "episode 9, val func loss 0.8717415928840637\n",
      "\n",
      "episode 10, val func loss 0.8946548104286194\n",
      "\n",
      "episode 11, val func loss 0.9094619154930115\n",
      "\n",
      "episode 12, val func loss 0.9289243221282959\n",
      "\n",
      "episode 13, val func loss 0.8848139643669128\n",
      "\n",
      "episode 14, val func loss 0.8329890966415405\n",
      "\n",
      "episode 15, val func loss 0.9703720211982727\n",
      "\n",
      "episode 16, val func loss 0.8008235692977905\n",
      "\n",
      "Val func train loss in epoch 15:0.875618752092123\n",
      "***********************TIME WAS 4.822450808684031 min*****************************\n",
      "\n",
      "**********************ROUND 50 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 3.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 2.005305528640747\n",
      "\n",
      "episode 2, policy loss 2.0053038597106934\n",
      "\n",
      "episode 3, policy loss 2.00531005859375\n",
      "\n",
      "episode 4, policy loss 2.0053043365478516\n",
      "\n",
      "episode 5, policy loss 2.0053067207336426\n",
      "\n",
      "episode 6, policy loss 2.005302906036377\n",
      "\n",
      "episode 7, policy loss 2.0053017139434814\n",
      "\n",
      "episode 8, policy loss 2.005312204360962\n",
      "\n",
      "episode 9, policy loss 2.0052993297576904\n",
      "\n",
      "episode 10, policy loss 2.0053069591522217\n",
      "\n",
      "episode 11, policy loss 2.005305528640747\n",
      "\n",
      "episode 12, policy loss 2.00530743598938\n",
      "\n",
      "episode 13, policy loss 2.005298614501953\n",
      "\n",
      "episode 14, policy loss 2.0053067207336426\n",
      "\n",
      "episode 15, policy loss 2.0053067207336426\n",
      "\n",
      "episode 16, policy loss 2.0053048133850098\n",
      "\n",
      "Policy train loss in epoch 0:2.005305215716362\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 2.0053043365478516\n",
      "\n",
      "episode 2, policy loss 2.0053067207336426\n",
      "\n",
      "episode 3, policy loss 2.0052993297576904\n",
      "\n",
      "episode 4, policy loss 2.005312204360962\n",
      "\n",
      "episode 5, policy loss 2.0053069591522217\n",
      "\n",
      "episode 6, policy loss 2.005298614501953\n",
      "\n",
      "episode 7, policy loss 2.00530743598938\n",
      "\n",
      "episode 8, policy loss 2.005305528640747\n",
      "\n",
      "episode 9, policy loss 2.00531005859375\n",
      "\n",
      "episode 10, policy loss 2.005302906036377\n",
      "\n",
      "episode 11, policy loss 2.0053017139434814\n",
      "\n",
      "episode 12, policy loss 2.005305528640747\n",
      "\n",
      "episode 13, policy loss 2.0053067207336426\n",
      "\n",
      "episode 14, policy loss 2.0053038597106934\n",
      "\n",
      "episode 15, policy loss 2.0053048133850098\n",
      "\n",
      "episode 16, policy loss 2.0053067207336426\n",
      "\n",
      "Policy train loss in epoch 1:2.005305215716362\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 2.0053048133850098\n",
      "\n",
      "episode 2, policy loss 2.00531005859375\n",
      "\n",
      "episode 3, policy loss 2.005302906036377\n",
      "\n",
      "episode 4, policy loss 2.0053067207336426\n",
      "\n",
      "episode 5, policy loss 2.0052993297576904\n",
      "\n",
      "episode 6, policy loss 2.0053067207336426\n",
      "\n",
      "episode 7, policy loss 2.0053067207336426\n",
      "\n",
      "episode 8, policy loss 2.005305528640747\n",
      "\n",
      "episode 9, policy loss 2.0053069591522217\n",
      "\n",
      "episode 10, policy loss 2.0053043365478516\n",
      "\n",
      "episode 11, policy loss 2.005305528640747\n",
      "\n",
      "episode 12, policy loss 2.00530743598938\n",
      "\n",
      "episode 13, policy loss 2.0053017139434814\n",
      "\n",
      "episode 14, policy loss 2.005312204360962\n",
      "\n",
      "episode 15, policy loss 2.005298614501953\n",
      "\n",
      "episode 16, policy loss 2.0053038597106934\n",
      "\n",
      "Policy train loss in epoch 2:2.005305215716362\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 2.0053067207336426\n",
      "\n",
      "episode 2, policy loss 2.0053048133850098\n",
      "\n",
      "episode 3, policy loss 2.0053069591522217\n",
      "\n",
      "episode 4, policy loss 2.0053017139434814\n",
      "\n",
      "episode 5, policy loss 2.0053043365478516\n",
      "\n",
      "episode 6, policy loss 2.0053067207336426\n",
      "\n",
      "episode 7, policy loss 2.005312204360962\n",
      "\n",
      "episode 8, policy loss 2.0053067207336426\n",
      "\n",
      "episode 9, policy loss 2.005305528640747\n",
      "\n",
      "episode 10, policy loss 2.005298614501953\n",
      "\n",
      "episode 11, policy loss 2.005305528640747\n",
      "\n",
      "episode 12, policy loss 2.0053038597106934\n",
      "\n",
      "episode 13, policy loss 2.005302906036377\n",
      "\n",
      "episode 14, policy loss 2.0052993297576904\n",
      "\n",
      "episode 15, policy loss 2.00530743598938\n",
      "\n",
      "episode 16, policy loss 2.00531005859375\n",
      "\n",
      "Policy train loss in epoch 3:2.005305215716362\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7838273644447327\n",
      "\n",
      "episode 2, val func loss 0.7655550241470337\n",
      "\n",
      "episode 3, val func loss 0.6941568851470947\n",
      "\n",
      "episode 4, val func loss 0.7933599948883057\n",
      "\n",
      "episode 5, val func loss 0.827622652053833\n",
      "\n",
      "episode 6, val func loss 0.8435781598091125\n",
      "\n",
      "episode 7, val func loss 0.868238627910614\n",
      "\n",
      "episode 8, val func loss 0.9502696990966797\n",
      "\n",
      "episode 9, val func loss 0.7781558036804199\n",
      "\n",
      "episode 10, val func loss 1.002260684967041\n",
      "\n",
      "episode 11, val func loss 0.9247497320175171\n",
      "\n",
      "episode 12, val func loss 0.8735287189483643\n",
      "\n",
      "episode 13, val func loss 1.0478664636611938\n",
      "\n",
      "episode 14, val func loss 0.91996830701828\n",
      "\n",
      "episode 15, val func loss 0.8144420981407166\n",
      "\n",
      "episode 16, val func loss 0.9407050013542175\n",
      "\n",
      "Val func train loss in epoch 0:0.8642678260803223\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8073156476020813\n",
      "\n",
      "episode 2, val func loss 0.7536537647247314\n",
      "\n",
      "episode 3, val func loss 0.8951599597930908\n",
      "\n",
      "episode 4, val func loss 0.7675380110740662\n",
      "\n",
      "episode 5, val func loss 0.8891636729240417\n",
      "\n",
      "episode 6, val func loss 0.9542629718780518\n",
      "\n",
      "episode 7, val func loss 0.9813426733016968\n",
      "\n",
      "episode 8, val func loss 0.9836357235908508\n",
      "\n",
      "episode 9, val func loss 0.8827406764030457\n",
      "\n",
      "episode 10, val func loss 0.786970317363739\n",
      "\n",
      "episode 11, val func loss 0.8718748688697815\n",
      "\n",
      "episode 12, val func loss 0.8741490244865417\n",
      "\n",
      "episode 13, val func loss 0.8677717447280884\n",
      "\n",
      "episode 14, val func loss 0.7704132199287415\n",
      "\n",
      "episode 15, val func loss 1.0347812175750732\n",
      "\n",
      "episode 16, val func loss 0.8984944820404053\n",
      "\n",
      "Val func train loss in epoch 1:0.8762042485177517\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.8636960983276367\n",
      "\n",
      "episode 2, val func loss 0.9527508616447449\n",
      "\n",
      "episode 3, val func loss 0.9971340298652649\n",
      "\n",
      "episode 4, val func loss 0.9829912781715393\n",
      "\n",
      "episode 5, val func loss 0.88234943151474\n",
      "\n",
      "episode 6, val func loss 0.9419239163398743\n",
      "\n",
      "episode 7, val func loss 1.0828590393066406\n",
      "\n",
      "episode 8, val func loss 0.8987848162651062\n",
      "\n",
      "episode 9, val func loss 0.8568629622459412\n",
      "\n",
      "episode 10, val func loss 1.0132510662078857\n",
      "\n",
      "episode 11, val func loss 0.9834318161010742\n",
      "\n",
      "episode 12, val func loss 0.9427996873855591\n",
      "\n",
      "episode 13, val func loss 0.935184895992279\n",
      "\n",
      "episode 14, val func loss 0.8534184694290161\n",
      "\n",
      "episode 15, val func loss 0.8754209876060486\n",
      "\n",
      "episode 16, val func loss 0.8625076413154602\n",
      "\n",
      "Val func train loss in epoch 2:0.9328354373574257\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8824354410171509\n",
      "\n",
      "episode 2, val func loss 0.7754853367805481\n",
      "\n",
      "episode 3, val func loss 0.8370928168296814\n",
      "\n",
      "episode 4, val func loss 0.8482712507247925\n",
      "\n",
      "episode 5, val func loss 0.7914823889732361\n",
      "\n",
      "episode 6, val func loss 0.9354544878005981\n",
      "\n",
      "episode 7, val func loss 0.8481451869010925\n",
      "\n",
      "episode 8, val func loss 0.8162822127342224\n",
      "\n",
      "episode 9, val func loss 0.8629373908042908\n",
      "\n",
      "episode 10, val func loss 0.8209852576255798\n",
      "\n",
      "episode 11, val func loss 0.8458906412124634\n",
      "\n",
      "episode 12, val func loss 0.8364539742469788\n",
      "\n",
      "episode 13, val func loss 0.8726761937141418\n",
      "\n",
      "episode 14, val func loss 0.760592520236969\n",
      "\n",
      "episode 15, val func loss 1.0131080150604248\n",
      "\n",
      "episode 16, val func loss 0.8337194919586182\n",
      "\n",
      "Val func train loss in epoch 3:0.8488132879137993\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8743111491203308\n",
      "\n",
      "episode 2, val func loss 0.8106594085693359\n",
      "\n",
      "episode 3, val func loss 0.9981333017349243\n",
      "\n",
      "episode 4, val func loss 0.8862490653991699\n",
      "\n",
      "episode 5, val func loss 0.7972831726074219\n",
      "\n",
      "episode 6, val func loss 0.7943008542060852\n",
      "\n",
      "episode 7, val func loss 0.8091828227043152\n",
      "\n",
      "episode 8, val func loss 0.8447814583778381\n",
      "\n",
      "episode 9, val func loss 0.970820426940918\n",
      "\n",
      "episode 10, val func loss 0.9993088841438293\n",
      "\n",
      "episode 11, val func loss 0.76781165599823\n",
      "\n",
      "episode 12, val func loss 0.790045440196991\n",
      "\n",
      "episode 13, val func loss 0.8270539045333862\n",
      "\n",
      "episode 14, val func loss 0.8381521701812744\n",
      "\n",
      "episode 15, val func loss 0.8272886276245117\n",
      "\n",
      "episode 16, val func loss 0.8834521174430847\n",
      "\n",
      "Val func train loss in epoch 4:0.8574271537363529\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.9438395500183105\n",
      "\n",
      "episode 2, val func loss 0.9109174609184265\n",
      "\n",
      "episode 3, val func loss 0.8392543196678162\n",
      "\n",
      "episode 4, val func loss 0.8154266476631165\n",
      "\n",
      "episode 5, val func loss 0.7935938835144043\n",
      "\n",
      "episode 6, val func loss 0.7549284100532532\n",
      "\n",
      "episode 7, val func loss 0.8272542953491211\n",
      "\n",
      "episode 8, val func loss 0.79794842004776\n",
      "\n",
      "episode 9, val func loss 0.806138277053833\n",
      "\n",
      "episode 10, val func loss 0.876674234867096\n",
      "\n",
      "episode 11, val func loss 0.7361286282539368\n",
      "\n",
      "episode 12, val func loss 0.9539734721183777\n",
      "\n",
      "episode 13, val func loss 0.7802132368087769\n",
      "\n",
      "episode 14, val func loss 0.8016336560249329\n",
      "\n",
      "episode 15, val func loss 0.7961297631263733\n",
      "\n",
      "episode 16, val func loss 0.8817707896232605\n",
      "\n",
      "Val func train loss in epoch 5:0.8322390653192997\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7704159617424011\n",
      "\n",
      "episode 2, val func loss 0.9528138637542725\n",
      "\n",
      "episode 3, val func loss 0.8813810348510742\n",
      "\n",
      "episode 4, val func loss 0.8700346946716309\n",
      "\n",
      "episode 5, val func loss 0.7467415928840637\n",
      "\n",
      "episode 6, val func loss 0.9263186454772949\n",
      "\n",
      "episode 7, val func loss 0.9133768081665039\n",
      "\n",
      "episode 8, val func loss 0.8584233522415161\n",
      "\n",
      "episode 9, val func loss 0.7852723002433777\n",
      "\n",
      "episode 10, val func loss 0.8731000423431396\n",
      "\n",
      "episode 11, val func loss 0.9309132099151611\n",
      "\n",
      "episode 12, val func loss 0.8110191822052002\n",
      "\n",
      "episode 13, val func loss 0.9413065910339355\n",
      "\n",
      "episode 14, val func loss 0.9750109314918518\n",
      "\n",
      "episode 15, val func loss 0.7882962822914124\n",
      "\n",
      "episode 16, val func loss 0.8707147240638733\n",
      "\n",
      "Val func train loss in epoch 6:0.8684462010860443\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.8048691153526306\n",
      "\n",
      "episode 2, val func loss 0.9255821704864502\n",
      "\n",
      "episode 3, val func loss 0.8464804887771606\n",
      "\n",
      "episode 4, val func loss 0.8651726841926575\n",
      "\n",
      "episode 5, val func loss 0.8687471747398376\n",
      "\n",
      "episode 6, val func loss 0.9788616299629211\n",
      "\n",
      "episode 7, val func loss 0.9455934762954712\n",
      "\n",
      "episode 8, val func loss 0.9113158583641052\n",
      "\n",
      "episode 9, val func loss 0.8911259770393372\n",
      "\n",
      "episode 10, val func loss 0.9060551524162292\n",
      "\n",
      "episode 11, val func loss 0.8766010403633118\n",
      "\n",
      "episode 12, val func loss 0.9085332155227661\n",
      "\n",
      "episode 13, val func loss 0.937974214553833\n",
      "\n",
      "episode 14, val func loss 0.8921232223510742\n",
      "\n",
      "episode 15, val func loss 0.9152742624282837\n",
      "\n",
      "episode 16, val func loss 0.9742564558982849\n",
      "\n",
      "Val func train loss in epoch 7:0.9030353836715221\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8034460544586182\n",
      "\n",
      "episode 2, val func loss 0.9049502015113831\n",
      "\n",
      "episode 3, val func loss 0.8124147057533264\n",
      "\n",
      "episode 4, val func loss 0.9524014592170715\n",
      "\n",
      "episode 5, val func loss 0.85655677318573\n",
      "\n",
      "episode 6, val func loss 0.8063815832138062\n",
      "\n",
      "episode 7, val func loss 0.9328678846359253\n",
      "\n",
      "episode 8, val func loss 1.0243736505508423\n",
      "\n",
      "episode 9, val func loss 0.7671397924423218\n",
      "\n",
      "episode 10, val func loss 0.912160336971283\n",
      "\n",
      "episode 11, val func loss 0.9204310178756714\n",
      "\n",
      "episode 12, val func loss 0.7224758863449097\n",
      "\n",
      "episode 13, val func loss 0.7960550785064697\n",
      "\n",
      "episode 14, val func loss 0.7930065989494324\n",
      "\n",
      "episode 15, val func loss 1.010681390762329\n",
      "\n",
      "episode 16, val func loss 0.9320074915885925\n",
      "\n",
      "Val func train loss in epoch 8:0.871709369122982\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8993054628372192\n",
      "\n",
      "episode 2, val func loss 0.9286931157112122\n",
      "\n",
      "episode 3, val func loss 0.7052223682403564\n",
      "\n",
      "episode 4, val func loss 0.8360487818717957\n",
      "\n",
      "episode 5, val func loss 0.8147883415222168\n",
      "\n",
      "episode 6, val func loss 0.9207808375358582\n",
      "\n",
      "episode 7, val func loss 0.7936829328536987\n",
      "\n",
      "episode 8, val func loss 0.8826678991317749\n",
      "\n",
      "episode 9, val func loss 0.8361082077026367\n",
      "\n",
      "episode 10, val func loss 0.8114229440689087\n",
      "\n",
      "episode 11, val func loss 1.0246937274932861\n",
      "\n",
      "episode 12, val func loss 0.8670883178710938\n",
      "\n",
      "episode 13, val func loss 0.8071379661560059\n",
      "\n",
      "episode 14, val func loss 0.910305380821228\n",
      "\n",
      "episode 15, val func loss 0.9238199591636658\n",
      "\n",
      "episode 16, val func loss 0.920760452747345\n",
      "\n",
      "Val func train loss in epoch 9:0.8676579184830189\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.8238661289215088\n",
      "\n",
      "episode 2, val func loss 0.7981997132301331\n",
      "\n",
      "episode 3, val func loss 1.0156108140945435\n",
      "\n",
      "episode 4, val func loss 0.9020230174064636\n",
      "\n",
      "episode 5, val func loss 0.8165047764778137\n",
      "\n",
      "episode 6, val func loss 0.8869521021842957\n",
      "\n",
      "episode 7, val func loss 0.8647006750106812\n",
      "\n",
      "episode 8, val func loss 0.8110382556915283\n",
      "\n",
      "episode 9, val func loss 0.9114887714385986\n",
      "\n",
      "episode 10, val func loss 0.7999833226203918\n",
      "\n",
      "episode 11, val func loss 0.78608638048172\n",
      "\n",
      "episode 12, val func loss 1.1374744176864624\n",
      "\n",
      "episode 13, val func loss 0.8854246735572815\n",
      "\n",
      "episode 14, val func loss 1.0765206813812256\n",
      "\n",
      "episode 15, val func loss 1.085853934288025\n",
      "\n",
      "episode 16, val func loss 0.7704089879989624\n",
      "\n",
      "Val func train loss in epoch 10:0.8982585407793522\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9020628333091736\n",
      "\n",
      "episode 2, val func loss 0.8895207643508911\n",
      "\n",
      "episode 3, val func loss 0.9307677149772644\n",
      "\n",
      "episode 4, val func loss 0.9563578963279724\n",
      "\n",
      "episode 5, val func loss 0.8317274451255798\n",
      "\n",
      "episode 6, val func loss 0.9077474474906921\n",
      "\n",
      "episode 7, val func loss 1.0667606592178345\n",
      "\n",
      "episode 8, val func loss 1.0149530172348022\n",
      "\n",
      "episode 9, val func loss 0.9614135026931763\n",
      "\n",
      "episode 10, val func loss 0.7662858963012695\n",
      "\n",
      "episode 11, val func loss 1.0263988971710205\n",
      "\n",
      "episode 12, val func loss 0.9517328143119812\n",
      "\n",
      "episode 13, val func loss 0.8591867685317993\n",
      "\n",
      "episode 14, val func loss 0.9783598184585571\n",
      "\n",
      "episode 15, val func loss 0.9533955454826355\n",
      "\n",
      "episode 16, val func loss 1.0184061527252197\n",
      "\n",
      "Val func train loss in epoch 11:0.9384423233568668\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7402926087379456\n",
      "\n",
      "episode 2, val func loss 0.9399111270904541\n",
      "\n",
      "episode 3, val func loss 0.8285051584243774\n",
      "\n",
      "episode 4, val func loss 0.8928765058517456\n",
      "\n",
      "episode 5, val func loss 0.7240434288978577\n",
      "\n",
      "episode 6, val func loss 0.8376927971839905\n",
      "\n",
      "episode 7, val func loss 0.8634849190711975\n",
      "\n",
      "episode 8, val func loss 0.8013327121734619\n",
      "\n",
      "episode 9, val func loss 0.9689714312553406\n",
      "\n",
      "episode 10, val func loss 0.7874435186386108\n",
      "\n",
      "episode 11, val func loss 0.8190593123435974\n",
      "\n",
      "episode 12, val func loss 1.0288771390914917\n",
      "\n",
      "episode 13, val func loss 0.8994985222816467\n",
      "\n",
      "episode 14, val func loss 0.8376508951187134\n",
      "\n",
      "episode 15, val func loss 0.8235267400741577\n",
      "\n",
      "episode 16, val func loss 0.8981630802154541\n",
      "\n",
      "Val func train loss in epoch 12:0.8557081185281277\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8842909336090088\n",
      "\n",
      "episode 2, val func loss 0.8837815523147583\n",
      "\n",
      "episode 3, val func loss 0.8743997812271118\n",
      "\n",
      "episode 4, val func loss 0.9141920804977417\n",
      "\n",
      "episode 5, val func loss 0.7433634996414185\n",
      "\n",
      "episode 6, val func loss 0.853061854839325\n",
      "\n",
      "episode 7, val func loss 0.8112663626670837\n",
      "\n",
      "episode 8, val func loss 0.8743574619293213\n",
      "\n",
      "episode 9, val func loss 0.8779449462890625\n",
      "\n",
      "episode 10, val func loss 0.9488687515258789\n",
      "\n",
      "episode 11, val func loss 0.771597146987915\n",
      "\n",
      "episode 12, val func loss 0.8403016328811646\n",
      "\n",
      "episode 13, val func loss 0.7559667229652405\n",
      "\n",
      "episode 14, val func loss 0.9048959612846375\n",
      "\n",
      "episode 15, val func loss 0.8054332137107849\n",
      "\n",
      "episode 16, val func loss 0.91114741563797\n",
      "\n",
      "Val func train loss in epoch 13:0.8534293323755264\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.836651086807251\n",
      "\n",
      "episode 2, val func loss 0.8889309763908386\n",
      "\n",
      "episode 3, val func loss 0.6672038435935974\n",
      "\n",
      "episode 4, val func loss 0.7898616790771484\n",
      "\n",
      "episode 5, val func loss 0.8862560391426086\n",
      "\n",
      "episode 6, val func loss 0.8128162026405334\n",
      "\n",
      "episode 7, val func loss 0.9005520343780518\n",
      "\n",
      "episode 8, val func loss 0.8090700507164001\n",
      "\n",
      "episode 9, val func loss 0.7356786727905273\n",
      "\n",
      "episode 10, val func loss 0.7589665651321411\n",
      "\n",
      "episode 11, val func loss 0.7863990068435669\n",
      "\n",
      "episode 12, val func loss 0.712627112865448\n",
      "\n",
      "episode 13, val func loss 0.8600493669509888\n",
      "\n",
      "episode 14, val func loss 0.7614489197731018\n",
      "\n",
      "episode 15, val func loss 0.8096379041671753\n",
      "\n",
      "episode 16, val func loss 0.8536573052406311\n",
      "\n",
      "Val func train loss in epoch 14:0.8043629229068756\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7711557745933533\n",
      "\n",
      "episode 2, val func loss 0.82281893491745\n",
      "\n",
      "episode 3, val func loss 0.7790550589561462\n",
      "\n",
      "episode 4, val func loss 0.814566433429718\n",
      "\n",
      "episode 5, val func loss 0.9568838477134705\n",
      "\n",
      "episode 6, val func loss 0.886281430721283\n",
      "\n",
      "episode 7, val func loss 0.8099438548088074\n",
      "\n",
      "episode 8, val func loss 0.7602108716964722\n",
      "\n",
      "episode 9, val func loss 0.7637424468994141\n",
      "\n",
      "episode 10, val func loss 0.8543069362640381\n",
      "\n",
      "episode 11, val func loss 0.769902229309082\n",
      "\n",
      "episode 12, val func loss 0.8554222583770752\n",
      "\n",
      "episode 13, val func loss 0.8584054112434387\n",
      "\n",
      "episode 14, val func loss 0.8042125701904297\n",
      "\n",
      "episode 15, val func loss 0.7987755537033081\n",
      "\n",
      "episode 16, val func loss 0.9088428616523743\n",
      "\n",
      "Val func train loss in epoch 15:0.8259079046547413\n",
      "***********************TIME WAS 4.820850535233816 min*****************************\n",
      "\n",
      "**********************ROUND 51 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 2.4851856231689453\n",
      "\n",
      "episode 2, policy loss 2.4851861000061035\n",
      "\n",
      "episode 3, policy loss 2.4851856231689453\n",
      "\n",
      "episode 4, policy loss 2.4851861000061035\n",
      "\n",
      "episode 5, policy loss 2.4851858615875244\n",
      "\n",
      "episode 6, policy loss 2.4851856231689453\n",
      "\n",
      "episode 7, policy loss 2.4851861000061035\n",
      "\n",
      "episode 8, policy loss 2.485184907913208\n",
      "\n",
      "episode 9, policy loss 2.4851858615875244\n",
      "\n",
      "episode 10, policy loss 2.4851858615875244\n",
      "\n",
      "episode 11, policy loss 2.4851861000061035\n",
      "\n",
      "episode 12, policy loss 2.4851858615875244\n",
      "\n",
      "episode 13, policy loss 2.4851858615875244\n",
      "\n",
      "episode 14, policy loss 2.4851856231689453\n",
      "\n",
      "episode 15, policy loss 2.4851861000061035\n",
      "\n",
      "episode 16, policy loss 2.4851858615875244\n",
      "\n",
      "Policy train loss in epoch 0:2.485185816884041\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 2.4851856231689453\n",
      "\n",
      "episode 2, policy loss 2.4851858615875244\n",
      "\n",
      "episode 3, policy loss 2.4851856231689453\n",
      "\n",
      "episode 4, policy loss 2.4851858615875244\n",
      "\n",
      "episode 5, policy loss 2.4851858615875244\n",
      "\n",
      "episode 6, policy loss 2.4851856231689453\n",
      "\n",
      "episode 7, policy loss 2.4851858615875244\n",
      "\n",
      "episode 8, policy loss 2.4851858615875244\n",
      "\n",
      "episode 9, policy loss 2.4851861000061035\n",
      "\n",
      "episode 10, policy loss 2.4851858615875244\n",
      "\n",
      "episode 11, policy loss 2.4851861000061035\n",
      "\n",
      "episode 12, policy loss 2.4851856231689453\n",
      "\n",
      "episode 13, policy loss 2.485184907913208\n",
      "\n",
      "episode 14, policy loss 2.4851861000061035\n",
      "\n",
      "episode 15, policy loss 2.4851861000061035\n",
      "\n",
      "episode 16, policy loss 2.4851861000061035\n",
      "\n",
      "Policy train loss in epoch 1:2.485185816884041\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 2.4851861000061035\n",
      "\n",
      "episode 2, policy loss 2.4851861000061035\n",
      "\n",
      "episode 3, policy loss 2.485184907913208\n",
      "\n",
      "episode 4, policy loss 2.4851858615875244\n",
      "\n",
      "episode 5, policy loss 2.4851858615875244\n",
      "\n",
      "episode 6, policy loss 2.4851858615875244\n",
      "\n",
      "episode 7, policy loss 2.4851858615875244\n",
      "\n",
      "episode 8, policy loss 2.4851858615875244\n",
      "\n",
      "episode 9, policy loss 2.4851856231689453\n",
      "\n",
      "episode 10, policy loss 2.4851861000061035\n",
      "\n",
      "episode 11, policy loss 2.4851858615875244\n",
      "\n",
      "episode 12, policy loss 2.4851856231689453\n",
      "\n",
      "episode 13, policy loss 2.4851856231689453\n",
      "\n",
      "episode 14, policy loss 2.4851861000061035\n",
      "\n",
      "episode 15, policy loss 2.4851856231689453\n",
      "\n",
      "episode 16, policy loss 2.4851861000061035\n",
      "\n",
      "Policy train loss in epoch 2:2.485185816884041\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 2.4851861000061035\n",
      "\n",
      "episode 2, policy loss 2.4851856231689453\n",
      "\n",
      "episode 3, policy loss 2.485184907913208\n",
      "\n",
      "episode 4, policy loss 2.4851861000061035\n",
      "\n",
      "episode 5, policy loss 2.4851858615875244\n",
      "\n",
      "episode 6, policy loss 2.4851858615875244\n",
      "\n",
      "episode 7, policy loss 2.4851858615875244\n",
      "\n",
      "episode 8, policy loss 2.4851861000061035\n",
      "\n",
      "episode 9, policy loss 2.4851856231689453\n",
      "\n",
      "episode 10, policy loss 2.4851858615875244\n",
      "\n",
      "episode 11, policy loss 2.4851858615875244\n",
      "\n",
      "episode 12, policy loss 2.4851856231689453\n",
      "\n",
      "episode 13, policy loss 2.4851858615875244\n",
      "\n",
      "episode 14, policy loss 2.4851861000061035\n",
      "\n",
      "episode 15, policy loss 2.4851861000061035\n",
      "\n",
      "episode 16, policy loss 2.4851856231689453\n",
      "\n",
      "Policy train loss in epoch 3:2.485185816884041\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.8479840159416199\n",
      "\n",
      "episode 2, val func loss 0.9897386431694031\n",
      "\n",
      "episode 3, val func loss 0.8911458253860474\n",
      "\n",
      "episode 4, val func loss 0.8155427575111389\n",
      "\n",
      "episode 5, val func loss 0.8620209097862244\n",
      "\n",
      "episode 6, val func loss 0.8214782476425171\n",
      "\n",
      "episode 7, val func loss 0.8508161902427673\n",
      "\n",
      "episode 8, val func loss 0.8176457285881042\n",
      "\n",
      "episode 9, val func loss 0.8229045271873474\n",
      "\n",
      "episode 10, val func loss 0.8441603183746338\n",
      "\n",
      "episode 11, val func loss 0.8413430452346802\n",
      "\n",
      "episode 12, val func loss 0.8949991464614868\n",
      "\n",
      "episode 13, val func loss 0.8351414203643799\n",
      "\n",
      "episode 14, val func loss 0.9103655815124512\n",
      "\n",
      "episode 15, val func loss 0.7859036922454834\n",
      "\n",
      "episode 16, val func loss 0.7921803593635559\n",
      "\n",
      "Val func train loss in epoch 0:0.85146065056324\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.894685685634613\n",
      "\n",
      "episode 2, val func loss 0.9148498177528381\n",
      "\n",
      "episode 3, val func loss 0.8494489192962646\n",
      "\n",
      "episode 4, val func loss 0.8330268263816833\n",
      "\n",
      "episode 5, val func loss 0.9924536943435669\n",
      "\n",
      "episode 6, val func loss 0.7770559787750244\n",
      "\n",
      "episode 7, val func loss 0.8730058670043945\n",
      "\n",
      "episode 8, val func loss 0.8945282697677612\n",
      "\n",
      "episode 9, val func loss 0.7292138338088989\n",
      "\n",
      "episode 10, val func loss 0.87529057264328\n",
      "\n",
      "episode 11, val func loss 0.8259732127189636\n",
      "\n",
      "episode 12, val func loss 0.889257550239563\n",
      "\n",
      "episode 13, val func loss 0.8432739973068237\n",
      "\n",
      "episode 14, val func loss 0.8784730434417725\n",
      "\n",
      "episode 15, val func loss 0.8078351616859436\n",
      "\n",
      "episode 16, val func loss 0.8862035274505615\n",
      "\n",
      "Val func train loss in epoch 1:0.8602859973907471\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7884237766265869\n",
      "\n",
      "episode 2, val func loss 0.8376033902168274\n",
      "\n",
      "episode 3, val func loss 0.7987201809883118\n",
      "\n",
      "episode 4, val func loss 0.9169644117355347\n",
      "\n",
      "episode 5, val func loss 0.7461346387863159\n",
      "\n",
      "episode 6, val func loss 0.858754575252533\n",
      "\n",
      "episode 7, val func loss 0.8876162171363831\n",
      "\n",
      "episode 8, val func loss 0.7393802404403687\n",
      "\n",
      "episode 9, val func loss 0.9070371985435486\n",
      "\n",
      "episode 10, val func loss 0.7589295506477356\n",
      "\n",
      "episode 11, val func loss 0.9913401007652283\n",
      "\n",
      "episode 12, val func loss 0.7112261056900024\n",
      "\n",
      "episode 13, val func loss 0.9326097369194031\n",
      "\n",
      "episode 14, val func loss 0.8969497680664062\n",
      "\n",
      "episode 15, val func loss 0.85302734375\n",
      "\n",
      "episode 16, val func loss 0.8309219479560852\n",
      "\n",
      "Val func train loss in epoch 2:0.8409774489700794\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8136910200119019\n",
      "\n",
      "episode 2, val func loss 0.7853655815124512\n",
      "\n",
      "episode 3, val func loss 0.830395519733429\n",
      "\n",
      "episode 4, val func loss 0.9449146389961243\n",
      "\n",
      "episode 5, val func loss 0.8056685328483582\n",
      "\n",
      "episode 6, val func loss 0.8366457223892212\n",
      "\n",
      "episode 7, val func loss 0.9616236090660095\n",
      "\n",
      "episode 8, val func loss 0.8779498338699341\n",
      "\n",
      "episode 9, val func loss 0.855800986289978\n",
      "\n",
      "episode 10, val func loss 0.9647864103317261\n",
      "\n",
      "episode 11, val func loss 0.8009105324745178\n",
      "\n",
      "episode 12, val func loss 0.8487232327461243\n",
      "\n",
      "episode 13, val func loss 0.9528743028640747\n",
      "\n",
      "episode 14, val func loss 0.7526441216468811\n",
      "\n",
      "episode 15, val func loss 0.7322948575019836\n",
      "\n",
      "episode 16, val func loss 0.8590773940086365\n",
      "\n",
      "Val func train loss in epoch 3:0.8514603935182095\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8929446935653687\n",
      "\n",
      "episode 2, val func loss 0.7798402309417725\n",
      "\n",
      "episode 3, val func loss 0.9171348214149475\n",
      "\n",
      "episode 4, val func loss 0.9167784452438354\n",
      "\n",
      "episode 5, val func loss 0.8560812473297119\n",
      "\n",
      "episode 6, val func loss 0.8946753740310669\n",
      "\n",
      "episode 7, val func loss 0.9666318893432617\n",
      "\n",
      "episode 8, val func loss 0.8947878479957581\n",
      "\n",
      "episode 9, val func loss 0.9098531603813171\n",
      "\n",
      "episode 10, val func loss 0.852397620677948\n",
      "\n",
      "episode 11, val func loss 0.7689759135246277\n",
      "\n",
      "episode 12, val func loss 0.8571435809135437\n",
      "\n",
      "episode 13, val func loss 0.9218277335166931\n",
      "\n",
      "episode 14, val func loss 0.8118762373924255\n",
      "\n",
      "episode 15, val func loss 0.9326353073120117\n",
      "\n",
      "episode 16, val func loss 0.9245227575302124\n",
      "\n",
      "Val func train loss in epoch 4:0.8811316788196564\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.8293113708496094\n",
      "\n",
      "episode 2, val func loss 0.7758059501647949\n",
      "\n",
      "episode 3, val func loss 0.8517317175865173\n",
      "\n",
      "episode 4, val func loss 0.9565969705581665\n",
      "\n",
      "episode 5, val func loss 0.891520619392395\n",
      "\n",
      "episode 6, val func loss 0.812166154384613\n",
      "\n",
      "episode 7, val func loss 0.6678103804588318\n",
      "\n",
      "episode 8, val func loss 0.9994065761566162\n",
      "\n",
      "episode 9, val func loss 0.8764912486076355\n",
      "\n",
      "episode 10, val func loss 0.816085934638977\n",
      "\n",
      "episode 11, val func loss 0.8516994118690491\n",
      "\n",
      "episode 12, val func loss 0.8053970336914062\n",
      "\n",
      "episode 13, val func loss 0.827674388885498\n",
      "\n",
      "episode 14, val func loss 0.9044942855834961\n",
      "\n",
      "episode 15, val func loss 0.7910346984863281\n",
      "\n",
      "episode 16, val func loss 0.9635358452796936\n",
      "\n",
      "Val func train loss in epoch 5:0.8512976616621017\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8121331334114075\n",
      "\n",
      "episode 2, val func loss 0.8337565660476685\n",
      "\n",
      "episode 3, val func loss 0.7575568556785583\n",
      "\n",
      "episode 4, val func loss 0.7539988160133362\n",
      "\n",
      "episode 5, val func loss 0.8040855526924133\n",
      "\n",
      "episode 6, val func loss 0.8992231488227844\n",
      "\n",
      "episode 7, val func loss 0.8750879168510437\n",
      "\n",
      "episode 8, val func loss 0.7956629991531372\n",
      "\n",
      "episode 9, val func loss 0.9172388315200806\n",
      "\n",
      "episode 10, val func loss 0.8140937089920044\n",
      "\n",
      "episode 11, val func loss 0.8527137041091919\n",
      "\n",
      "episode 12, val func loss 0.9062539339065552\n",
      "\n",
      "episode 13, val func loss 0.7108931541442871\n",
      "\n",
      "episode 14, val func loss 0.9029213786125183\n",
      "\n",
      "episode 15, val func loss 0.7973236441612244\n",
      "\n",
      "episode 16, val func loss 0.8411228656768799\n",
      "\n",
      "Val func train loss in epoch 6:0.8296291381120682\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6382725834846497\n",
      "\n",
      "episode 2, val func loss 0.6859931945800781\n",
      "\n",
      "episode 3, val func loss 0.8075403571128845\n",
      "\n",
      "episode 4, val func loss 0.8102761507034302\n",
      "\n",
      "episode 5, val func loss 0.9834256768226624\n",
      "\n",
      "episode 6, val func loss 0.8276664018630981\n",
      "\n",
      "episode 7, val func loss 0.8634009957313538\n",
      "\n",
      "episode 8, val func loss 0.7979178428649902\n",
      "\n",
      "episode 9, val func loss 0.7408400177955627\n",
      "\n",
      "episode 10, val func loss 0.7863612174987793\n",
      "\n",
      "episode 11, val func loss 0.8588377237319946\n",
      "\n",
      "episode 12, val func loss 0.9420527815818787\n",
      "\n",
      "episode 13, val func loss 0.9572016000747681\n",
      "\n",
      "episode 14, val func loss 0.8549050092697144\n",
      "\n",
      "episode 15, val func loss 0.8294137120246887\n",
      "\n",
      "episode 16, val func loss 0.7532835006713867\n",
      "\n",
      "Val func train loss in epoch 7:0.821086797863245\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.9014731049537659\n",
      "\n",
      "episode 2, val func loss 0.8182539343833923\n",
      "\n",
      "episode 3, val func loss 0.8199123740196228\n",
      "\n",
      "episode 4, val func loss 0.7988478541374207\n",
      "\n",
      "episode 5, val func loss 0.9514138698577881\n",
      "\n",
      "episode 6, val func loss 0.8845017552375793\n",
      "\n",
      "episode 7, val func loss 0.7461789846420288\n",
      "\n",
      "episode 8, val func loss 0.8201959133148193\n",
      "\n",
      "episode 9, val func loss 0.8075230121612549\n",
      "\n",
      "episode 10, val func loss 0.7520431280136108\n",
      "\n",
      "episode 11, val func loss 0.8686243891716003\n",
      "\n",
      "episode 12, val func loss 0.8590363264083862\n",
      "\n",
      "episode 13, val func loss 0.85874342918396\n",
      "\n",
      "episode 14, val func loss 0.8208650946617126\n",
      "\n",
      "episode 15, val func loss 0.8580343127250671\n",
      "\n",
      "episode 16, val func loss 0.8118681311607361\n",
      "\n",
      "Val func train loss in epoch 8:0.8360947258770466\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8393948674201965\n",
      "\n",
      "episode 2, val func loss 0.8668884634971619\n",
      "\n",
      "episode 3, val func loss 0.8493217825889587\n",
      "\n",
      "episode 4, val func loss 0.9300222396850586\n",
      "\n",
      "episode 5, val func loss 0.8518221378326416\n",
      "\n",
      "episode 6, val func loss 0.748065710067749\n",
      "\n",
      "episode 7, val func loss 0.8527753353118896\n",
      "\n",
      "episode 8, val func loss 0.8727924823760986\n",
      "\n",
      "episode 9, val func loss 0.7693140506744385\n",
      "\n",
      "episode 10, val func loss 0.7510945200920105\n",
      "\n",
      "episode 11, val func loss 0.737339198589325\n",
      "\n",
      "episode 12, val func loss 0.9273887276649475\n",
      "\n",
      "episode 13, val func loss 0.7968801856040955\n",
      "\n",
      "episode 14, val func loss 0.7694458365440369\n",
      "\n",
      "episode 15, val func loss 0.8068009614944458\n",
      "\n",
      "episode 16, val func loss 0.7276660203933716\n",
      "\n",
      "Val func train loss in epoch 9:0.8185632824897766\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.8268519043922424\n",
      "\n",
      "episode 2, val func loss 0.7496190667152405\n",
      "\n",
      "episode 3, val func loss 0.8159763813018799\n",
      "\n",
      "episode 4, val func loss 0.6927434206008911\n",
      "\n",
      "episode 5, val func loss 0.9261963963508606\n",
      "\n",
      "episode 6, val func loss 0.7891317009925842\n",
      "\n",
      "episode 7, val func loss 0.8638043999671936\n",
      "\n",
      "episode 8, val func loss 0.858494222164154\n",
      "\n",
      "episode 9, val func loss 0.8926363587379456\n",
      "\n",
      "episode 10, val func loss 0.8691433668136597\n",
      "\n",
      "episode 11, val func loss 0.9775981903076172\n",
      "\n",
      "episode 12, val func loss 0.7916026711463928\n",
      "\n",
      "episode 13, val func loss 0.8931078314781189\n",
      "\n",
      "episode 14, val func loss 0.8677148818969727\n",
      "\n",
      "episode 15, val func loss 0.8287397027015686\n",
      "\n",
      "episode 16, val func loss 0.9769079685211182\n",
      "\n",
      "Val func train loss in epoch 10:0.8512667790055275\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.8422243595123291\n",
      "\n",
      "episode 2, val func loss 0.9961170554161072\n",
      "\n",
      "episode 3, val func loss 0.8894462585449219\n",
      "\n",
      "episode 4, val func loss 0.866374135017395\n",
      "\n",
      "episode 5, val func loss 0.7910692095756531\n",
      "\n",
      "episode 6, val func loss 0.8686111569404602\n",
      "\n",
      "episode 7, val func loss 0.7921255230903625\n",
      "\n",
      "episode 8, val func loss 0.8368597030639648\n",
      "\n",
      "episode 9, val func loss 1.0041635036468506\n",
      "\n",
      "episode 10, val func loss 0.8064112663269043\n",
      "\n",
      "episode 11, val func loss 0.9741642475128174\n",
      "\n",
      "episode 12, val func loss 0.8786604404449463\n",
      "\n",
      "episode 13, val func loss 0.8681461811065674\n",
      "\n",
      "episode 14, val func loss 0.820619523525238\n",
      "\n",
      "episode 15, val func loss 0.8199098110198975\n",
      "\n",
      "episode 16, val func loss 0.8035011291503906\n",
      "\n",
      "Val func train loss in epoch 11:0.8661502189934254\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.8531195521354675\n",
      "\n",
      "episode 2, val func loss 0.7901519536972046\n",
      "\n",
      "episode 3, val func loss 0.8548706769943237\n",
      "\n",
      "episode 4, val func loss 0.8597671985626221\n",
      "\n",
      "episode 5, val func loss 0.8219947814941406\n",
      "\n",
      "episode 6, val func loss 0.8619948625564575\n",
      "\n",
      "episode 7, val func loss 0.8274553418159485\n",
      "\n",
      "episode 8, val func loss 0.8947110772132874\n",
      "\n",
      "episode 9, val func loss 0.7017177939414978\n",
      "\n",
      "episode 10, val func loss 0.8426334857940674\n",
      "\n",
      "episode 11, val func loss 1.0536926984786987\n",
      "\n",
      "episode 12, val func loss 0.7788988351821899\n",
      "\n",
      "episode 13, val func loss 0.8056735992431641\n",
      "\n",
      "episode 14, val func loss 0.7754854559898376\n",
      "\n",
      "episode 15, val func loss 0.9130330681800842\n",
      "\n",
      "episode 16, val func loss 0.821891725063324\n",
      "\n",
      "Val func train loss in epoch 12:0.8410682566463947\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.9169771671295166\n",
      "\n",
      "episode 2, val func loss 0.8889142274856567\n",
      "\n",
      "episode 3, val func loss 0.9065882563591003\n",
      "\n",
      "episode 4, val func loss 0.9365701675415039\n",
      "\n",
      "episode 5, val func loss 0.8975194096565247\n",
      "\n",
      "episode 6, val func loss 0.8652256727218628\n",
      "\n",
      "episode 7, val func loss 0.8649963736534119\n",
      "\n",
      "episode 8, val func loss 0.8372722268104553\n",
      "\n",
      "episode 9, val func loss 0.914138674736023\n",
      "\n",
      "episode 10, val func loss 0.7989575862884521\n",
      "\n",
      "episode 11, val func loss 0.7993007302284241\n",
      "\n",
      "episode 12, val func loss 0.8260093331336975\n",
      "\n",
      "episode 13, val func loss 0.8114237785339355\n",
      "\n",
      "episode 14, val func loss 0.8031847476959229\n",
      "\n",
      "episode 15, val func loss 0.9100349545478821\n",
      "\n",
      "episode 16, val func loss 0.6303856372833252\n",
      "\n",
      "Val func train loss in epoch 13:0.8504686839878559\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.8329581618309021\n",
      "\n",
      "episode 2, val func loss 0.8153278827667236\n",
      "\n",
      "episode 3, val func loss 0.8278723955154419\n",
      "\n",
      "episode 4, val func loss 0.7850348353385925\n",
      "\n",
      "episode 5, val func loss 0.914216160774231\n",
      "\n",
      "episode 6, val func loss 0.7719125747680664\n",
      "\n",
      "episode 7, val func loss 0.9045128226280212\n",
      "\n",
      "episode 8, val func loss 0.8930102586746216\n",
      "\n",
      "episode 9, val func loss 0.8261962532997131\n",
      "\n",
      "episode 10, val func loss 0.8200962543487549\n",
      "\n",
      "episode 11, val func loss 0.8400700092315674\n",
      "\n",
      "episode 12, val func loss 0.9286593198776245\n",
      "\n",
      "episode 13, val func loss 0.733896017074585\n",
      "\n",
      "episode 14, val func loss 0.7569946646690369\n",
      "\n",
      "episode 15, val func loss 0.8158789873123169\n",
      "\n",
      "episode 16, val func loss 0.7359071969985962\n",
      "\n",
      "Val func train loss in epoch 14:0.8251589871942997\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7020907402038574\n",
      "\n",
      "episode 2, val func loss 0.8500555157661438\n",
      "\n",
      "episode 3, val func loss 0.7082549333572388\n",
      "\n",
      "episode 4, val func loss 0.8357444405555725\n",
      "\n",
      "episode 5, val func loss 0.9235367178916931\n",
      "\n",
      "episode 6, val func loss 0.9375342726707458\n",
      "\n",
      "episode 7, val func loss 0.751850962638855\n",
      "\n",
      "episode 8, val func loss 0.8131533861160278\n",
      "\n",
      "episode 9, val func loss 0.7309232354164124\n",
      "\n",
      "episode 10, val func loss 0.728709876537323\n",
      "\n",
      "episode 11, val func loss 0.81239253282547\n",
      "\n",
      "episode 12, val func loss 0.7511591911315918\n",
      "\n",
      "episode 13, val func loss 0.8096922039985657\n",
      "\n",
      "episode 14, val func loss 0.8110663294792175\n",
      "\n",
      "episode 15, val func loss 0.8848006129264832\n",
      "\n",
      "episode 16, val func loss 0.8169286847114563\n",
      "\n",
      "Val func train loss in epoch 15:0.8042433522641659\n",
      "***********************TIME WAS 4.836717041333516 min*****************************\n",
      "\n",
      "**********************ROUND 52 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.2549107074737549\n",
      "\n",
      "episode 2, policy loss 1.2549103498458862\n",
      "\n",
      "episode 3, policy loss 1.2549107074737549\n",
      "\n",
      "episode 4, policy loss 1.254910945892334\n",
      "\n",
      "episode 5, policy loss 1.2549107074737549\n",
      "\n",
      "episode 6, policy loss 1.2549103498458862\n",
      "\n",
      "episode 7, policy loss 1.2549108266830444\n",
      "\n",
      "episode 8, policy loss 1.2549107074737549\n",
      "\n",
      "episode 9, policy loss 1.2549107074737549\n",
      "\n",
      "episode 10, policy loss 1.2549110651016235\n",
      "\n",
      "episode 11, policy loss 1.2549105882644653\n",
      "\n",
      "episode 12, policy loss 1.2549104690551758\n",
      "\n",
      "episode 13, policy loss 1.2549110651016235\n",
      "\n",
      "episode 14, policy loss 1.2549108266830444\n",
      "\n",
      "episode 15, policy loss 1.2549108266830444\n",
      "\n",
      "episode 16, policy loss 1.2549105882644653\n",
      "\n",
      "Policy train loss in epoch 0:1.2549107149243355\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.2549107074737549\n",
      "\n",
      "episode 2, policy loss 1.2549108266830444\n",
      "\n",
      "episode 3, policy loss 1.2549108266830444\n",
      "\n",
      "episode 4, policy loss 1.2549104690551758\n",
      "\n",
      "episode 5, policy loss 1.2549107074737549\n",
      "\n",
      "episode 6, policy loss 1.2549103498458862\n",
      "\n",
      "episode 7, policy loss 1.2549105882644653\n",
      "\n",
      "episode 8, policy loss 1.2549103498458862\n",
      "\n",
      "episode 9, policy loss 1.2549107074737549\n",
      "\n",
      "episode 10, policy loss 1.2549110651016235\n",
      "\n",
      "episode 11, policy loss 1.2549108266830444\n",
      "\n",
      "episode 12, policy loss 1.2549107074737549\n",
      "\n",
      "episode 13, policy loss 1.2549110651016235\n",
      "\n",
      "episode 14, policy loss 1.254910945892334\n",
      "\n",
      "episode 15, policy loss 1.2549105882644653\n",
      "\n",
      "episode 16, policy loss 1.2549107074737549\n",
      "\n",
      "Policy train loss in epoch 1:1.2549107149243355\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.2549104690551758\n",
      "\n",
      "episode 2, policy loss 1.254910945892334\n",
      "\n",
      "episode 3, policy loss 1.2549107074737549\n",
      "\n",
      "episode 4, policy loss 1.2549105882644653\n",
      "\n",
      "episode 5, policy loss 1.2549107074737549\n",
      "\n",
      "episode 6, policy loss 1.2549110651016235\n",
      "\n",
      "episode 7, policy loss 1.2549110651016235\n",
      "\n",
      "episode 8, policy loss 1.2549107074737549\n",
      "\n",
      "episode 9, policy loss 1.2549108266830444\n",
      "\n",
      "episode 10, policy loss 1.2549108266830444\n",
      "\n",
      "episode 11, policy loss 1.2549105882644653\n",
      "\n",
      "episode 12, policy loss 1.2549107074737549\n",
      "\n",
      "episode 13, policy loss 1.2549107074737549\n",
      "\n",
      "episode 14, policy loss 1.2549108266830444\n",
      "\n",
      "episode 15, policy loss 1.2549103498458862\n",
      "\n",
      "episode 16, policy loss 1.2549103498458862\n",
      "\n",
      "Policy train loss in epoch 2:1.2549107149243355\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.2549108266830444\n",
      "\n",
      "episode 2, policy loss 1.2549103498458862\n",
      "\n",
      "episode 3, policy loss 1.2549108266830444\n",
      "\n",
      "episode 4, policy loss 1.254910945892334\n",
      "\n",
      "episode 5, policy loss 1.2549107074737549\n",
      "\n",
      "episode 6, policy loss 1.2549107074737549\n",
      "\n",
      "episode 7, policy loss 1.2549103498458862\n",
      "\n",
      "episode 8, policy loss 1.2549107074737549\n",
      "\n",
      "episode 9, policy loss 1.2549104690551758\n",
      "\n",
      "episode 10, policy loss 1.2549107074737549\n",
      "\n",
      "episode 11, policy loss 1.2549108266830444\n",
      "\n",
      "episode 12, policy loss 1.2549105882644653\n",
      "\n",
      "episode 13, policy loss 1.2549110651016235\n",
      "\n",
      "episode 14, policy loss 1.2549105882644653\n",
      "\n",
      "episode 15, policy loss 1.2549110651016235\n",
      "\n",
      "episode 16, policy loss 1.2549107074737549\n",
      "\n",
      "Policy train loss in epoch 3:1.2549107149243355\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.8283634185791016\n",
      "\n",
      "episode 2, val func loss 0.9014302492141724\n",
      "\n",
      "episode 3, val func loss 0.8157649636268616\n",
      "\n",
      "episode 4, val func loss 0.8502073884010315\n",
      "\n",
      "episode 5, val func loss 0.9079219102859497\n",
      "\n",
      "episode 6, val func loss 0.9862536191940308\n",
      "\n",
      "episode 7, val func loss 0.7966316342353821\n",
      "\n",
      "episode 8, val func loss 0.8834019899368286\n",
      "\n",
      "episode 9, val func loss 0.93864506483078\n",
      "\n",
      "episode 10, val func loss 0.891522228717804\n",
      "\n",
      "episode 11, val func loss 0.8132154941558838\n",
      "\n",
      "episode 12, val func loss 0.8932027816772461\n",
      "\n",
      "episode 13, val func loss 0.9387761950492859\n",
      "\n",
      "episode 14, val func loss 0.7905895709991455\n",
      "\n",
      "episode 15, val func loss 0.8247304558753967\n",
      "\n",
      "episode 16, val func loss 0.8858577013015747\n",
      "\n",
      "Val func train loss in epoch 0:0.8716571666300297\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8899229168891907\n",
      "\n",
      "episode 2, val func loss 0.9247312545776367\n",
      "\n",
      "episode 3, val func loss 0.8024457097053528\n",
      "\n",
      "episode 4, val func loss 0.9159591794013977\n",
      "\n",
      "episode 5, val func loss 0.8259665369987488\n",
      "\n",
      "episode 6, val func loss 0.8474293947219849\n",
      "\n",
      "episode 7, val func loss 0.8802100419998169\n",
      "\n",
      "episode 8, val func loss 0.9942528605461121\n",
      "\n",
      "episode 9, val func loss 0.8402952551841736\n",
      "\n",
      "episode 10, val func loss 0.8671775460243225\n",
      "\n",
      "episode 11, val func loss 0.8778815269470215\n",
      "\n",
      "episode 12, val func loss 0.814839243888855\n",
      "\n",
      "episode 13, val func loss 0.7972556352615356\n",
      "\n",
      "episode 14, val func loss 0.7608597874641418\n",
      "\n",
      "episode 15, val func loss 0.8796334862709045\n",
      "\n",
      "episode 16, val func loss 0.813212513923645\n",
      "\n",
      "Val func train loss in epoch 1:0.8582545556128025\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.8682985305786133\n",
      "\n",
      "episode 2, val func loss 0.983564555644989\n",
      "\n",
      "episode 3, val func loss 0.8879334330558777\n",
      "\n",
      "episode 4, val func loss 1.0585190057754517\n",
      "\n",
      "episode 5, val func loss 0.8784136176109314\n",
      "\n",
      "episode 6, val func loss 0.8575684428215027\n",
      "\n",
      "episode 7, val func loss 0.9008066654205322\n",
      "\n",
      "episode 8, val func loss 0.9427604675292969\n",
      "\n",
      "episode 9, val func loss 0.8151952624320984\n",
      "\n",
      "episode 10, val func loss 0.8391435146331787\n",
      "\n",
      "episode 11, val func loss 0.9406211972236633\n",
      "\n",
      "episode 12, val func loss 0.7925705313682556\n",
      "\n",
      "episode 13, val func loss 0.776399552822113\n",
      "\n",
      "episode 14, val func loss 0.7778249382972717\n",
      "\n",
      "episode 15, val func loss 0.9552436470985413\n",
      "\n",
      "episode 16, val func loss 0.8283246159553528\n",
      "\n",
      "Val func train loss in epoch 2:0.8814492486417294\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8338434100151062\n",
      "\n",
      "episode 2, val func loss 0.8822462558746338\n",
      "\n",
      "episode 3, val func loss 0.7649163007736206\n",
      "\n",
      "episode 4, val func loss 0.9018923044204712\n",
      "\n",
      "episode 5, val func loss 0.8430023193359375\n",
      "\n",
      "episode 6, val func loss 0.9797104597091675\n",
      "\n",
      "episode 7, val func loss 0.8303601741790771\n",
      "\n",
      "episode 8, val func loss 0.83042973279953\n",
      "\n",
      "episode 9, val func loss 0.893906831741333\n",
      "\n",
      "episode 10, val func loss 0.7830007672309875\n",
      "\n",
      "episode 11, val func loss 0.7387964725494385\n",
      "\n",
      "episode 12, val func loss 0.7584164142608643\n",
      "\n",
      "episode 13, val func loss 0.8090582489967346\n",
      "\n",
      "episode 14, val func loss 0.822665274143219\n",
      "\n",
      "episode 15, val func loss 0.8768187165260315\n",
      "\n",
      "episode 16, val func loss 0.8252668380737305\n",
      "\n",
      "Val func train loss in epoch 3:0.8358956575393677\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.944464921951294\n",
      "\n",
      "episode 2, val func loss 0.7797010540962219\n",
      "\n",
      "episode 3, val func loss 0.8037066459655762\n",
      "\n",
      "episode 4, val func loss 0.7268079519271851\n",
      "\n",
      "episode 5, val func loss 0.8852646946907043\n",
      "\n",
      "episode 6, val func loss 0.7145325541496277\n",
      "\n",
      "episode 7, val func loss 0.8413145542144775\n",
      "\n",
      "episode 8, val func loss 0.8668344020843506\n",
      "\n",
      "episode 9, val func loss 0.8634698987007141\n",
      "\n",
      "episode 10, val func loss 0.8385887145996094\n",
      "\n",
      "episode 11, val func loss 0.7800660729408264\n",
      "\n",
      "episode 12, val func loss 0.7170769572257996\n",
      "\n",
      "episode 13, val func loss 0.9729193449020386\n",
      "\n",
      "episode 14, val func loss 0.7473957538604736\n",
      "\n",
      "episode 15, val func loss 0.7350297570228577\n",
      "\n",
      "episode 16, val func loss 0.857961118221283\n",
      "\n",
      "Val func train loss in epoch 4:0.817195899784565\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.8693340420722961\n",
      "\n",
      "episode 2, val func loss 0.931789755821228\n",
      "\n",
      "episode 3, val func loss 0.8167421221733093\n",
      "\n",
      "episode 4, val func loss 0.7827968597412109\n",
      "\n",
      "episode 5, val func loss 0.8866955637931824\n",
      "\n",
      "episode 6, val func loss 0.8805157542228699\n",
      "\n",
      "episode 7, val func loss 0.8117156624794006\n",
      "\n",
      "episode 8, val func loss 0.974044680595398\n",
      "\n",
      "episode 9, val func loss 0.7844315767288208\n",
      "\n",
      "episode 10, val func loss 0.83392333984375\n",
      "\n",
      "episode 11, val func loss 0.7687983512878418\n",
      "\n",
      "episode 12, val func loss 0.85533207654953\n",
      "\n",
      "episode 13, val func loss 0.7472347617149353\n",
      "\n",
      "episode 14, val func loss 0.8178120851516724\n",
      "\n",
      "episode 15, val func loss 0.7318387627601624\n",
      "\n",
      "episode 16, val func loss 0.8286539912223816\n",
      "\n",
      "Val func train loss in epoch 5:0.8326037116348743\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.9037415981292725\n",
      "\n",
      "episode 2, val func loss 0.8054897785186768\n",
      "\n",
      "episode 3, val func loss 0.8269212245941162\n",
      "\n",
      "episode 4, val func loss 0.9388731718063354\n",
      "\n",
      "episode 5, val func loss 0.916580855846405\n",
      "\n",
      "episode 6, val func loss 0.8287280797958374\n",
      "\n",
      "episode 7, val func loss 0.9740187525749207\n",
      "\n",
      "episode 8, val func loss 0.7686593532562256\n",
      "\n",
      "episode 9, val func loss 0.8273249268531799\n",
      "\n",
      "episode 10, val func loss 0.8925957083702087\n",
      "\n",
      "episode 11, val func loss 0.780585765838623\n",
      "\n",
      "episode 12, val func loss 0.778733491897583\n",
      "\n",
      "episode 13, val func loss 0.7843505144119263\n",
      "\n",
      "episode 14, val func loss 0.7868177890777588\n",
      "\n",
      "episode 15, val func loss 0.7731822729110718\n",
      "\n",
      "episode 16, val func loss 0.7601299285888672\n",
      "\n",
      "Val func train loss in epoch 6:0.834170825779438\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.761115312576294\n",
      "\n",
      "episode 2, val func loss 0.8168081641197205\n",
      "\n",
      "episode 3, val func loss 0.7564845085144043\n",
      "\n",
      "episode 4, val func loss 0.7220645546913147\n",
      "\n",
      "episode 5, val func loss 0.8080568909645081\n",
      "\n",
      "episode 6, val func loss 0.7134748101234436\n",
      "\n",
      "episode 7, val func loss 0.7462041974067688\n",
      "\n",
      "episode 8, val func loss 0.7542563080787659\n",
      "\n",
      "episode 9, val func loss 0.9370968341827393\n",
      "\n",
      "episode 10, val func loss 0.8375158905982971\n",
      "\n",
      "episode 11, val func loss 0.8699458837509155\n",
      "\n",
      "episode 12, val func loss 0.8275524973869324\n",
      "\n",
      "episode 13, val func loss 0.8511375784873962\n",
      "\n",
      "episode 14, val func loss 0.86342853307724\n",
      "\n",
      "episode 15, val func loss 0.8562486171722412\n",
      "\n",
      "episode 16, val func loss 0.8910592198371887\n",
      "\n",
      "Val func train loss in epoch 7:0.8132781125605106\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8797994256019592\n",
      "\n",
      "episode 2, val func loss 0.7981259822845459\n",
      "\n",
      "episode 3, val func loss 0.9320960640907288\n",
      "\n",
      "episode 4, val func loss 0.7625306248664856\n",
      "\n",
      "episode 5, val func loss 0.8454998135566711\n",
      "\n",
      "episode 6, val func loss 0.7936952114105225\n",
      "\n",
      "episode 7, val func loss 0.8440805673599243\n",
      "\n",
      "episode 8, val func loss 0.9394914507865906\n",
      "\n",
      "episode 9, val func loss 0.836081326007843\n",
      "\n",
      "episode 10, val func loss 0.9414472579956055\n",
      "\n",
      "episode 11, val func loss 0.8316988945007324\n",
      "\n",
      "episode 12, val func loss 0.9119823575019836\n",
      "\n",
      "episode 13, val func loss 0.6828539371490479\n",
      "\n",
      "episode 14, val func loss 1.097555160522461\n",
      "\n",
      "episode 15, val func loss 0.806395411491394\n",
      "\n",
      "episode 16, val func loss 1.1455481052398682\n",
      "\n",
      "Val func train loss in epoch 8:0.8780550993978977\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8399407863616943\n",
      "\n",
      "episode 2, val func loss 0.9313279390335083\n",
      "\n",
      "episode 3, val func loss 0.8962290287017822\n",
      "\n",
      "episode 4, val func loss 0.8150267004966736\n",
      "\n",
      "episode 5, val func loss 0.8762198686599731\n",
      "\n",
      "episode 6, val func loss 0.8080721497535706\n",
      "\n",
      "episode 7, val func loss 0.9508910775184631\n",
      "\n",
      "episode 8, val func loss 0.8947233557701111\n",
      "\n",
      "episode 9, val func loss 0.8874182105064392\n",
      "\n",
      "episode 10, val func loss 0.8241645097732544\n",
      "\n",
      "episode 11, val func loss 0.9368292689323425\n",
      "\n",
      "episode 12, val func loss 0.8595259189605713\n",
      "\n",
      "episode 13, val func loss 0.7965513467788696\n",
      "\n",
      "episode 14, val func loss 0.9244200587272644\n",
      "\n",
      "episode 15, val func loss 0.8640163540840149\n",
      "\n",
      "episode 16, val func loss 0.9321962594985962\n",
      "\n",
      "Val func train loss in epoch 9:0.8773470520973206\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.8813886642456055\n",
      "\n",
      "episode 2, val func loss 0.751200795173645\n",
      "\n",
      "episode 3, val func loss 1.040497064590454\n",
      "\n",
      "episode 4, val func loss 0.7771093845367432\n",
      "\n",
      "episode 5, val func loss 0.7437727451324463\n",
      "\n",
      "episode 6, val func loss 0.7798697352409363\n",
      "\n",
      "episode 7, val func loss 0.8130912780761719\n",
      "\n",
      "episode 8, val func loss 0.7695543169975281\n",
      "\n",
      "episode 9, val func loss 0.7640725374221802\n",
      "\n",
      "episode 10, val func loss 0.8800588250160217\n",
      "\n",
      "episode 11, val func loss 1.0650160312652588\n",
      "\n",
      "episode 12, val func loss 0.819706916809082\n",
      "\n",
      "episode 13, val func loss 0.7796422243118286\n",
      "\n",
      "episode 14, val func loss 0.8961735963821411\n",
      "\n",
      "episode 15, val func loss 0.7176620960235596\n",
      "\n",
      "episode 16, val func loss 0.8819641470909119\n",
      "\n",
      "Val func train loss in epoch 10:0.8350487723946571\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.8210912942886353\n",
      "\n",
      "episode 2, val func loss 0.8108059763908386\n",
      "\n",
      "episode 3, val func loss 0.7488875985145569\n",
      "\n",
      "episode 4, val func loss 0.7869662642478943\n",
      "\n",
      "episode 5, val func loss 0.7697115540504456\n",
      "\n",
      "episode 6, val func loss 0.7884188890457153\n",
      "\n",
      "episode 7, val func loss 0.7710520625114441\n",
      "\n",
      "episode 8, val func loss 0.7927883863449097\n",
      "\n",
      "episode 9, val func loss 0.7915022373199463\n",
      "\n",
      "episode 10, val func loss 0.8745900392532349\n",
      "\n",
      "episode 11, val func loss 0.7539859414100647\n",
      "\n",
      "episode 12, val func loss 0.8456897139549255\n",
      "\n",
      "episode 13, val func loss 0.7373949885368347\n",
      "\n",
      "episode 14, val func loss 0.8488866686820984\n",
      "\n",
      "episode 15, val func loss 0.7464009523391724\n",
      "\n",
      "episode 16, val func loss 0.8730109930038452\n",
      "\n",
      "Val func train loss in epoch 11:0.7975739724934101\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.9087890982627869\n",
      "\n",
      "episode 2, val func loss 0.7599436640739441\n",
      "\n",
      "episode 3, val func loss 0.9289546012878418\n",
      "\n",
      "episode 4, val func loss 0.9062482118606567\n",
      "\n",
      "episode 5, val func loss 0.8688948154449463\n",
      "\n",
      "episode 6, val func loss 0.8305360078811646\n",
      "\n",
      "episode 7, val func loss 0.8779870271682739\n",
      "\n",
      "episode 8, val func loss 0.6833391785621643\n",
      "\n",
      "episode 9, val func loss 0.9497516751289368\n",
      "\n",
      "episode 10, val func loss 0.7478018403053284\n",
      "\n",
      "episode 11, val func loss 0.8969712853431702\n",
      "\n",
      "episode 12, val func loss 0.7991737723350525\n",
      "\n",
      "episode 13, val func loss 0.8149256706237793\n",
      "\n",
      "episode 14, val func loss 0.9305697083473206\n",
      "\n",
      "episode 15, val func loss 0.8947014212608337\n",
      "\n",
      "episode 16, val func loss 0.8547335267066956\n",
      "\n",
      "Val func train loss in epoch 12:0.853332594037056\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8085553050041199\n",
      "\n",
      "episode 2, val func loss 0.8097099661827087\n",
      "\n",
      "episode 3, val func loss 0.7577031850814819\n",
      "\n",
      "episode 4, val func loss 0.7829414010047913\n",
      "\n",
      "episode 5, val func loss 0.7663722634315491\n",
      "\n",
      "episode 6, val func loss 0.8034879565238953\n",
      "\n",
      "episode 7, val func loss 0.8791527152061462\n",
      "\n",
      "episode 8, val func loss 0.80436772108078\n",
      "\n",
      "episode 9, val func loss 0.8115227222442627\n",
      "\n",
      "episode 10, val func loss 0.70921790599823\n",
      "\n",
      "episode 11, val func loss 0.8379759192466736\n",
      "\n",
      "episode 12, val func loss 0.7365599870681763\n",
      "\n",
      "episode 13, val func loss 0.7670419812202454\n",
      "\n",
      "episode 14, val func loss 0.8207077383995056\n",
      "\n",
      "episode 15, val func loss 0.7437822818756104\n",
      "\n",
      "episode 16, val func loss 0.8348450064659119\n",
      "\n",
      "Val func train loss in epoch 13:0.7921215035021305\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7142471671104431\n",
      "\n",
      "episode 2, val func loss 0.8344972133636475\n",
      "\n",
      "episode 3, val func loss 0.8280693888664246\n",
      "\n",
      "episode 4, val func loss 0.8678257465362549\n",
      "\n",
      "episode 5, val func loss 0.885654628276825\n",
      "\n",
      "episode 6, val func loss 0.8393956422805786\n",
      "\n",
      "episode 7, val func loss 0.8086963295936584\n",
      "\n",
      "episode 8, val func loss 0.8841492533683777\n",
      "\n",
      "episode 9, val func loss 0.8426664471626282\n",
      "\n",
      "episode 10, val func loss 0.7504543662071228\n",
      "\n",
      "episode 11, val func loss 0.8234373927116394\n",
      "\n",
      "episode 12, val func loss 0.7879846096038818\n",
      "\n",
      "episode 13, val func loss 0.8270191550254822\n",
      "\n",
      "episode 14, val func loss 0.7505401372909546\n",
      "\n",
      "episode 15, val func loss 0.8512212634086609\n",
      "\n",
      "episode 16, val func loss 0.8101670742034912\n",
      "\n",
      "Val func train loss in epoch 14:0.8191266134381294\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7773073315620422\n",
      "\n",
      "episode 2, val func loss 0.8780040740966797\n",
      "\n",
      "episode 3, val func loss 0.7996031641960144\n",
      "\n",
      "episode 4, val func loss 0.87066650390625\n",
      "\n",
      "episode 5, val func loss 0.7738469243049622\n",
      "\n",
      "episode 6, val func loss 0.820689857006073\n",
      "\n",
      "episode 7, val func loss 0.8364794254302979\n",
      "\n",
      "episode 8, val func loss 0.804711639881134\n",
      "\n",
      "episode 9, val func loss 0.8890153765678406\n",
      "\n",
      "episode 10, val func loss 0.7868668437004089\n",
      "\n",
      "episode 11, val func loss 0.8610330820083618\n",
      "\n",
      "episode 12, val func loss 0.8985523581504822\n",
      "\n",
      "episode 13, val func loss 0.8239015936851501\n",
      "\n",
      "episode 14, val func loss 0.9006300568580627\n",
      "\n",
      "episode 15, val func loss 0.7087306380271912\n",
      "\n",
      "episode 16, val func loss 0.9207531809806824\n",
      "\n",
      "Val func train loss in epoch 15:0.8344245031476021\n",
      "***********************TIME WAS 4.844994739691416 min*****************************\n",
      "\n",
      "**********************ROUND 53 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.04350777342915535\n",
      "\n",
      "episode 2, policy loss 0.04352591931819916\n",
      "\n",
      "episode 3, policy loss 0.04352211952209473\n",
      "\n",
      "episode 4, policy loss 0.043510157614946365\n",
      "\n",
      "episode 5, policy loss 0.04352347180247307\n",
      "\n",
      "episode 6, policy loss 0.04350857064127922\n",
      "\n",
      "episode 7, policy loss 0.043512046337127686\n",
      "\n",
      "episode 8, policy loss 0.04350430890917778\n",
      "\n",
      "episode 9, policy loss 0.04350924491882324\n",
      "\n",
      "episode 10, policy loss 0.0435253269970417\n",
      "\n",
      "episode 11, policy loss 0.0435188002884388\n",
      "\n",
      "episode 12, policy loss 0.04353199526667595\n",
      "\n",
      "episode 13, policy loss 0.04350576177239418\n",
      "\n",
      "episode 14, policy loss 0.04352862015366554\n",
      "\n",
      "episode 15, policy loss 0.04352039098739624\n",
      "\n",
      "episode 16, policy loss 0.04352658614516258\n",
      "\n",
      "Policy train loss in epoch 0:0.043517568381503224\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.04352347180247307\n",
      "\n",
      "episode 2, policy loss 0.04350430890917778\n",
      "\n",
      "episode 3, policy loss 0.04350857064127922\n",
      "\n",
      "episode 4, policy loss 0.043510157614946365\n",
      "\n",
      "episode 5, policy loss 0.04352591931819916\n",
      "\n",
      "episode 6, policy loss 0.043512046337127686\n",
      "\n",
      "episode 7, policy loss 0.04353199526667595\n",
      "\n",
      "episode 8, policy loss 0.0435253269970417\n",
      "\n",
      "episode 9, policy loss 0.04352862015366554\n",
      "\n",
      "episode 10, policy loss 0.04352039098739624\n",
      "\n",
      "episode 11, policy loss 0.04350924491882324\n",
      "\n",
      "episode 12, policy loss 0.04350777342915535\n",
      "\n",
      "episode 13, policy loss 0.04350576177239418\n",
      "\n",
      "episode 14, policy loss 0.04352658614516258\n",
      "\n",
      "episode 15, policy loss 0.0435188002884388\n",
      "\n",
      "episode 16, policy loss 0.04352211952209473\n",
      "\n",
      "Policy train loss in epoch 1:0.043517568381503224\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.04350430890917778\n",
      "\n",
      "episode 2, policy loss 0.04350576177239418\n",
      "\n",
      "episode 3, policy loss 0.04350924491882324\n",
      "\n",
      "episode 4, policy loss 0.04352591931819916\n",
      "\n",
      "episode 5, policy loss 0.04352862015366554\n",
      "\n",
      "episode 6, policy loss 0.04350857064127922\n",
      "\n",
      "episode 7, policy loss 0.04352347180247307\n",
      "\n",
      "episode 8, policy loss 0.0435188002884388\n",
      "\n",
      "episode 9, policy loss 0.04352039098739624\n",
      "\n",
      "episode 10, policy loss 0.04352211952209473\n",
      "\n",
      "episode 11, policy loss 0.04352658614516258\n",
      "\n",
      "episode 12, policy loss 0.043510157614946365\n",
      "\n",
      "episode 13, policy loss 0.0435253269970417\n",
      "\n",
      "episode 14, policy loss 0.04350777342915535\n",
      "\n",
      "episode 15, policy loss 0.04353199526667595\n",
      "\n",
      "episode 16, policy loss 0.043512046337127686\n",
      "\n",
      "Policy train loss in epoch 2:0.043517568381503224\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.04352039098739624\n",
      "\n",
      "episode 2, policy loss 0.04350430890917778\n",
      "\n",
      "episode 3, policy loss 0.04352591931819916\n",
      "\n",
      "episode 4, policy loss 0.04352211952209473\n",
      "\n",
      "episode 5, policy loss 0.0435253269970417\n",
      "\n",
      "episode 6, policy loss 0.043510157614946365\n",
      "\n",
      "episode 7, policy loss 0.04352658614516258\n",
      "\n",
      "episode 8, policy loss 0.0435188002884388\n",
      "\n",
      "episode 9, policy loss 0.04350576177239418\n",
      "\n",
      "episode 10, policy loss 0.043512046337127686\n",
      "\n",
      "episode 11, policy loss 0.04352862015366554\n",
      "\n",
      "episode 12, policy loss 0.04353199526667595\n",
      "\n",
      "episode 13, policy loss 0.04350777342915535\n",
      "\n",
      "episode 14, policy loss 0.04350857064127922\n",
      "\n",
      "episode 15, policy loss 0.04352347180247307\n",
      "\n",
      "episode 16, policy loss 0.04350924491882324\n",
      "\n",
      "Policy train loss in epoch 3:0.043517568381503224\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.9418563842773438\n",
      "\n",
      "episode 2, val func loss 0.8400388360023499\n",
      "\n",
      "episode 3, val func loss 0.9815158247947693\n",
      "\n",
      "episode 4, val func loss 0.8317842483520508\n",
      "\n",
      "episode 5, val func loss 0.7875555157661438\n",
      "\n",
      "episode 6, val func loss 1.0485490560531616\n",
      "\n",
      "episode 7, val func loss 0.914176881313324\n",
      "\n",
      "episode 8, val func loss 0.8403597474098206\n",
      "\n",
      "episode 9, val func loss 0.8191425800323486\n",
      "\n",
      "episode 10, val func loss 0.8182281851768494\n",
      "\n",
      "episode 11, val func loss 0.8460930585861206\n",
      "\n",
      "episode 12, val func loss 0.9870879054069519\n",
      "\n",
      "episode 13, val func loss 0.8545485734939575\n",
      "\n",
      "episode 14, val func loss 0.9176867008209229\n",
      "\n",
      "episode 15, val func loss 0.8966112732887268\n",
      "\n",
      "episode 16, val func loss 0.8668285012245178\n",
      "\n",
      "Val func train loss in epoch 0:0.88700395449996\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8271577954292297\n",
      "\n",
      "episode 2, val func loss 0.920821487903595\n",
      "\n",
      "episode 3, val func loss 0.7941477298736572\n",
      "\n",
      "episode 4, val func loss 0.8292433619499207\n",
      "\n",
      "episode 5, val func loss 0.849425733089447\n",
      "\n",
      "episode 6, val func loss 0.7581210136413574\n",
      "\n",
      "episode 7, val func loss 0.7989808917045593\n",
      "\n",
      "episode 8, val func loss 0.8629613518714905\n",
      "\n",
      "episode 9, val func loss 0.7316192984580994\n",
      "\n",
      "episode 10, val func loss 0.7923770546913147\n",
      "\n",
      "episode 11, val func loss 0.8482553362846375\n",
      "\n",
      "episode 12, val func loss 0.9007341265678406\n",
      "\n",
      "episode 13, val func loss 1.0076496601104736\n",
      "\n",
      "episode 14, val func loss 0.780463457107544\n",
      "\n",
      "episode 15, val func loss 0.9207285642623901\n",
      "\n",
      "episode 16, val func loss 0.7065852880477905\n",
      "\n",
      "Val func train loss in epoch 1:0.8330795094370842\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.89335697889328\n",
      "\n",
      "episode 2, val func loss 0.8314016461372375\n",
      "\n",
      "episode 3, val func loss 0.7815462350845337\n",
      "\n",
      "episode 4, val func loss 0.8945236206054688\n",
      "\n",
      "episode 5, val func loss 0.9533960223197937\n",
      "\n",
      "episode 6, val func loss 0.8704401850700378\n",
      "\n",
      "episode 7, val func loss 0.8140196204185486\n",
      "\n",
      "episode 8, val func loss 0.8877359628677368\n",
      "\n",
      "episode 9, val func loss 0.8498838543891907\n",
      "\n",
      "episode 10, val func loss 1.0471136569976807\n",
      "\n",
      "episode 11, val func loss 0.9021163582801819\n",
      "\n",
      "episode 12, val func loss 0.9916511178016663\n",
      "\n",
      "episode 13, val func loss 1.0345591306686401\n",
      "\n",
      "episode 14, val func loss 0.856025218963623\n",
      "\n",
      "episode 15, val func loss 1.1397078037261963\n",
      "\n",
      "episode 16, val func loss 1.049666404724121\n",
      "\n",
      "Val func train loss in epoch 2:0.9248214885592461\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6768945455551147\n",
      "\n",
      "episode 2, val func loss 0.9873254299163818\n",
      "\n",
      "episode 3, val func loss 0.9496229887008667\n",
      "\n",
      "episode 4, val func loss 0.9704610109329224\n",
      "\n",
      "episode 5, val func loss 0.956983745098114\n",
      "\n",
      "episode 6, val func loss 0.9544606804847717\n",
      "\n",
      "episode 7, val func loss 0.8389841318130493\n",
      "\n",
      "episode 8, val func loss 0.8102802038192749\n",
      "\n",
      "episode 9, val func loss 0.7573094964027405\n",
      "\n",
      "episode 10, val func loss 0.993371844291687\n",
      "\n",
      "episode 11, val func loss 0.7267197370529175\n",
      "\n",
      "episode 12, val func loss 0.81438148021698\n",
      "\n",
      "episode 13, val func loss 0.9547595977783203\n",
      "\n",
      "episode 14, val func loss 1.0065412521362305\n",
      "\n",
      "episode 15, val func loss 0.8910045623779297\n",
      "\n",
      "episode 16, val func loss 0.8145217895507812\n",
      "\n",
      "Val func train loss in epoch 3:0.8814764060080051\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.9162570238113403\n",
      "\n",
      "episode 2, val func loss 0.8949581980705261\n",
      "\n",
      "episode 3, val func loss 0.7879869341850281\n",
      "\n",
      "episode 4, val func loss 0.7897533178329468\n",
      "\n",
      "episode 5, val func loss 0.9946271181106567\n",
      "\n",
      "episode 6, val func loss 0.8869971632957458\n",
      "\n",
      "episode 7, val func loss 0.8625122904777527\n",
      "\n",
      "episode 8, val func loss 0.7580249905586243\n",
      "\n",
      "episode 9, val func loss 0.7639981508255005\n",
      "\n",
      "episode 10, val func loss 0.863371729850769\n",
      "\n",
      "episode 11, val func loss 0.8452475070953369\n",
      "\n",
      "episode 12, val func loss 0.962961733341217\n",
      "\n",
      "episode 13, val func loss 0.8550775647163391\n",
      "\n",
      "episode 14, val func loss 0.7936456203460693\n",
      "\n",
      "episode 15, val func loss 0.7788791656494141\n",
      "\n",
      "episode 16, val func loss 0.8134269118309021\n",
      "\n",
      "Val func train loss in epoch 4:0.8479828387498856\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.8881085515022278\n",
      "\n",
      "episode 2, val func loss 0.8809430003166199\n",
      "\n",
      "episode 3, val func loss 0.8456946015357971\n",
      "\n",
      "episode 4, val func loss 0.9114881753921509\n",
      "\n",
      "episode 5, val func loss 0.7756423950195312\n",
      "\n",
      "episode 6, val func loss 0.808222770690918\n",
      "\n",
      "episode 7, val func loss 0.8774044513702393\n",
      "\n",
      "episode 8, val func loss 0.7878336906433105\n",
      "\n",
      "episode 9, val func loss 0.6996118426322937\n",
      "\n",
      "episode 10, val func loss 0.7986525893211365\n",
      "\n",
      "episode 11, val func loss 0.7108446359634399\n",
      "\n",
      "episode 12, val func loss 0.787166953086853\n",
      "\n",
      "episode 13, val func loss 0.8599129915237427\n",
      "\n",
      "episode 14, val func loss 0.7323644161224365\n",
      "\n",
      "episode 15, val func loss 0.7570439577102661\n",
      "\n",
      "episode 16, val func loss 0.7347515225410461\n",
      "\n",
      "Val func train loss in epoch 5:0.8034804090857506\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8922498822212219\n",
      "\n",
      "episode 2, val func loss 0.7682895064353943\n",
      "\n",
      "episode 3, val func loss 0.8546659350395203\n",
      "\n",
      "episode 4, val func loss 0.7842112183570862\n",
      "\n",
      "episode 5, val func loss 0.764359176158905\n",
      "\n",
      "episode 6, val func loss 0.8143227696418762\n",
      "\n",
      "episode 7, val func loss 0.9068270921707153\n",
      "\n",
      "episode 8, val func loss 0.6915977001190186\n",
      "\n",
      "episode 9, val func loss 0.9100180864334106\n",
      "\n",
      "episode 10, val func loss 0.7210226058959961\n",
      "\n",
      "episode 11, val func loss 0.7476140856742859\n",
      "\n",
      "episode 12, val func loss 0.850321888923645\n",
      "\n",
      "episode 13, val func loss 0.7882013916969299\n",
      "\n",
      "episode 14, val func loss 0.8534571528434753\n",
      "\n",
      "episode 15, val func loss 0.8488690853118896\n",
      "\n",
      "episode 16, val func loss 0.8507635593414307\n",
      "\n",
      "Val func train loss in epoch 6:0.8154244460165501\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.8654671907424927\n",
      "\n",
      "episode 2, val func loss 0.8340050578117371\n",
      "\n",
      "episode 3, val func loss 0.7820760011672974\n",
      "\n",
      "episode 4, val func loss 0.7554991245269775\n",
      "\n",
      "episode 5, val func loss 0.8315992951393127\n",
      "\n",
      "episode 6, val func loss 0.8482621312141418\n",
      "\n",
      "episode 7, val func loss 0.7818475961685181\n",
      "\n",
      "episode 8, val func loss 0.7934877872467041\n",
      "\n",
      "episode 9, val func loss 0.7244559526443481\n",
      "\n",
      "episode 10, val func loss 0.7947292327880859\n",
      "\n",
      "episode 11, val func loss 0.7839444279670715\n",
      "\n",
      "episode 12, val func loss 0.7551954388618469\n",
      "\n",
      "episode 13, val func loss 0.8951218128204346\n",
      "\n",
      "episode 14, val func loss 0.7915581464767456\n",
      "\n",
      "episode 15, val func loss 0.7901845574378967\n",
      "\n",
      "episode 16, val func loss 0.7447200417518616\n",
      "\n",
      "Val func train loss in epoch 7:0.798259612172842\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8002774119377136\n",
      "\n",
      "episode 2, val func loss 0.7847215533256531\n",
      "\n",
      "episode 3, val func loss 0.7739647626876831\n",
      "\n",
      "episode 4, val func loss 0.7876389622688293\n",
      "\n",
      "episode 5, val func loss 0.8697972893714905\n",
      "\n",
      "episode 6, val func loss 0.787848949432373\n",
      "\n",
      "episode 7, val func loss 0.7781286239624023\n",
      "\n",
      "episode 8, val func loss 0.7753172516822815\n",
      "\n",
      "episode 9, val func loss 0.7547053694725037\n",
      "\n",
      "episode 10, val func loss 0.8742368817329407\n",
      "\n",
      "episode 11, val func loss 0.8974400758743286\n",
      "\n",
      "episode 12, val func loss 0.9004034996032715\n",
      "\n",
      "episode 13, val func loss 0.9862501621246338\n",
      "\n",
      "episode 14, val func loss 0.820863664150238\n",
      "\n",
      "episode 15, val func loss 0.8660355806350708\n",
      "\n",
      "episode 16, val func loss 0.8018766045570374\n",
      "\n",
      "Val func train loss in epoch 8:0.8287191651761532\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.7773517370223999\n",
      "\n",
      "episode 2, val func loss 0.8539130091667175\n",
      "\n",
      "episode 3, val func loss 0.7707701921463013\n",
      "\n",
      "episode 4, val func loss 0.8370552062988281\n",
      "\n",
      "episode 5, val func loss 0.7515474557876587\n",
      "\n",
      "episode 6, val func loss 0.817771852016449\n",
      "\n",
      "episode 7, val func loss 0.7002993226051331\n",
      "\n",
      "episode 8, val func loss 0.9302961826324463\n",
      "\n",
      "episode 9, val func loss 0.7059780955314636\n",
      "\n",
      "episode 10, val func loss 0.814454972743988\n",
      "\n",
      "episode 11, val func loss 0.7075764536857605\n",
      "\n",
      "episode 12, val func loss 0.9868680238723755\n",
      "\n",
      "episode 13, val func loss 0.8324060440063477\n",
      "\n",
      "episode 14, val func loss 0.8558124303817749\n",
      "\n",
      "episode 15, val func loss 0.7276099920272827\n",
      "\n",
      "episode 16, val func loss 0.7094445824623108\n",
      "\n",
      "Val func train loss in epoch 9:0.7986972220242023\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7918607592582703\n",
      "\n",
      "episode 2, val func loss 0.7962628602981567\n",
      "\n",
      "episode 3, val func loss 0.8383440971374512\n",
      "\n",
      "episode 4, val func loss 0.8905024528503418\n",
      "\n",
      "episode 5, val func loss 0.994099497795105\n",
      "\n",
      "episode 6, val func loss 0.7878826260566711\n",
      "\n",
      "episode 7, val func loss 0.9073881506919861\n",
      "\n",
      "episode 8, val func loss 0.8242199420928955\n",
      "\n",
      "episode 9, val func loss 0.7658169269561768\n",
      "\n",
      "episode 10, val func loss 0.7116881012916565\n",
      "\n",
      "episode 11, val func loss 0.8471812605857849\n",
      "\n",
      "episode 12, val func loss 0.774250864982605\n",
      "\n",
      "episode 13, val func loss 0.7486060857772827\n",
      "\n",
      "episode 14, val func loss 0.8300151228904724\n",
      "\n",
      "episode 15, val func loss 0.8417713642120361\n",
      "\n",
      "episode 16, val func loss 0.7985372543334961\n",
      "\n",
      "Val func train loss in epoch 10:0.8217767104506493\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7802218794822693\n",
      "\n",
      "episode 2, val func loss 0.8297876715660095\n",
      "\n",
      "episode 3, val func loss 0.7560415267944336\n",
      "\n",
      "episode 4, val func loss 0.7865907549858093\n",
      "\n",
      "episode 5, val func loss 0.7530561685562134\n",
      "\n",
      "episode 6, val func loss 0.7900926470756531\n",
      "\n",
      "episode 7, val func loss 0.8254609704017639\n",
      "\n",
      "episode 8, val func loss 0.7690673470497131\n",
      "\n",
      "episode 9, val func loss 0.9831516742706299\n",
      "\n",
      "episode 10, val func loss 0.9177088737487793\n",
      "\n",
      "episode 11, val func loss 0.93002849817276\n",
      "\n",
      "episode 12, val func loss 0.7852944135665894\n",
      "\n",
      "episode 13, val func loss 0.7429414987564087\n",
      "\n",
      "episode 14, val func loss 0.7871188521385193\n",
      "\n",
      "episode 15, val func loss 0.7969777584075928\n",
      "\n",
      "episode 16, val func loss 0.8251771926879883\n",
      "\n",
      "Val func train loss in epoch 11:0.8161698579788208\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.008477807044983\n",
      "\n",
      "episode 2, val func loss 0.961152970790863\n",
      "\n",
      "episode 3, val func loss 0.8009473085403442\n",
      "\n",
      "episode 4, val func loss 0.5591405630111694\n",
      "\n",
      "episode 5, val func loss 0.8142824172973633\n",
      "\n",
      "episode 6, val func loss 1.0876431465148926\n",
      "\n",
      "episode 7, val func loss 0.9092804789543152\n",
      "\n",
      "episode 8, val func loss 0.9435566067695618\n",
      "\n",
      "episode 9, val func loss 0.9052903652191162\n",
      "\n",
      "episode 10, val func loss 0.8527810573577881\n",
      "\n",
      "episode 11, val func loss 0.8072214722633362\n",
      "\n",
      "episode 12, val func loss 1.1246787309646606\n",
      "\n",
      "episode 13, val func loss 0.7729828953742981\n",
      "\n",
      "episode 14, val func loss 1.007191777229309\n",
      "\n",
      "episode 15, val func loss 0.8358747959136963\n",
      "\n",
      "episode 16, val func loss 1.0692543983459473\n",
      "\n",
      "Val func train loss in epoch 12:0.9037347994744778\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8457062840461731\n",
      "\n",
      "episode 2, val func loss 0.8949865698814392\n",
      "\n",
      "episode 3, val func loss 0.8507052063941956\n",
      "\n",
      "episode 4, val func loss 0.9610304236412048\n",
      "\n",
      "episode 5, val func loss 0.954806387424469\n",
      "\n",
      "episode 6, val func loss 1.0126667022705078\n",
      "\n",
      "episode 7, val func loss 0.8920419216156006\n",
      "\n",
      "episode 8, val func loss 0.8403841853141785\n",
      "\n",
      "episode 9, val func loss 0.9067509770393372\n",
      "\n",
      "episode 10, val func loss 0.81891268491745\n",
      "\n",
      "episode 11, val func loss 0.781636118888855\n",
      "\n",
      "episode 12, val func loss 0.9360557198524475\n",
      "\n",
      "episode 13, val func loss 0.8170211911201477\n",
      "\n",
      "episode 14, val func loss 0.8658400774002075\n",
      "\n",
      "episode 15, val func loss 0.8380022644996643\n",
      "\n",
      "episode 16, val func loss 0.8969672918319702\n",
      "\n",
      "Val func train loss in epoch 13:0.8820946253836155\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.8096381425857544\n",
      "\n",
      "episode 2, val func loss 1.0017884969711304\n",
      "\n",
      "episode 3, val func loss 0.6693129539489746\n",
      "\n",
      "episode 4, val func loss 1.009582757949829\n",
      "\n",
      "episode 5, val func loss 0.770356297492981\n",
      "\n",
      "episode 6, val func loss 0.8834097385406494\n",
      "\n",
      "episode 7, val func loss 0.7762380242347717\n",
      "\n",
      "episode 8, val func loss 0.7634655833244324\n",
      "\n",
      "episode 9, val func loss 0.7813544273376465\n",
      "\n",
      "episode 10, val func loss 0.8843023180961609\n",
      "\n",
      "episode 11, val func loss 0.9427320957183838\n",
      "\n",
      "episode 12, val func loss 0.8140576481819153\n",
      "\n",
      "episode 13, val func loss 0.8409885168075562\n",
      "\n",
      "episode 14, val func loss 0.7916631698608398\n",
      "\n",
      "episode 15, val func loss 0.8066306710243225\n",
      "\n",
      "episode 16, val func loss 0.7810405492782593\n",
      "\n",
      "Val func train loss in epoch 14:0.8329100869596004\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7678970694541931\n",
      "\n",
      "episode 2, val func loss 0.8023607730865479\n",
      "\n",
      "episode 3, val func loss 0.7529457211494446\n",
      "\n",
      "episode 4, val func loss 0.8335058689117432\n",
      "\n",
      "episode 5, val func loss 0.8005324602127075\n",
      "\n",
      "episode 6, val func loss 0.7106469869613647\n",
      "\n",
      "episode 7, val func loss 0.7818754315376282\n",
      "\n",
      "episode 8, val func loss 0.7177343964576721\n",
      "\n",
      "episode 9, val func loss 0.8361926078796387\n",
      "\n",
      "episode 10, val func loss 0.7702105045318604\n",
      "\n",
      "episode 11, val func loss 0.7992258071899414\n",
      "\n",
      "episode 12, val func loss 0.7434217929840088\n",
      "\n",
      "episode 13, val func loss 0.8170806169509888\n",
      "\n",
      "episode 14, val func loss 0.7704838514328003\n",
      "\n",
      "episode 15, val func loss 0.7821962237358093\n",
      "\n",
      "episode 16, val func loss 0.9014043807983398\n",
      "\n",
      "Val func train loss in epoch 15:0.786732155829668\n",
      "***********************TIME WAS 4.836736516157786 min*****************************\n",
      "\n",
      "**********************ROUND 54 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 2.2754225730895996\n",
      "\n",
      "episode 2, policy loss 2.275423526763916\n",
      "\n",
      "episode 3, policy loss 2.275421619415283\n",
      "\n",
      "episode 4, policy loss 2.275423526763916\n",
      "\n",
      "episode 5, policy loss 2.2754204273223877\n",
      "\n",
      "episode 6, policy loss 2.2754173278808594\n",
      "\n",
      "episode 7, policy loss 2.275418519973755\n",
      "\n",
      "episode 8, policy loss 2.275418996810913\n",
      "\n",
      "episode 9, policy loss 2.275423049926758\n",
      "\n",
      "episode 10, policy loss 2.275424003601074\n",
      "\n",
      "episode 11, policy loss 2.2754204273223877\n",
      "\n",
      "episode 12, policy loss 2.275423765182495\n",
      "\n",
      "episode 13, policy loss 2.275418758392334\n",
      "\n",
      "episode 14, policy loss 2.2754130363464355\n",
      "\n",
      "episode 15, policy loss 2.2754180431365967\n",
      "\n",
      "episode 16, policy loss 2.2754204273223877\n",
      "\n",
      "Policy train loss in epoch 0:2.2754205018281937\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 2.2754180431365967\n",
      "\n",
      "episode 2, policy loss 2.275418519973755\n",
      "\n",
      "episode 3, policy loss 2.2754130363464355\n",
      "\n",
      "episode 4, policy loss 2.2754173278808594\n",
      "\n",
      "episode 5, policy loss 2.2754204273223877\n",
      "\n",
      "episode 6, policy loss 2.275418758392334\n",
      "\n",
      "episode 7, policy loss 2.275423765182495\n",
      "\n",
      "episode 8, policy loss 2.275423049926758\n",
      "\n",
      "episode 9, policy loss 2.275423526763916\n",
      "\n",
      "episode 10, policy loss 2.275423526763916\n",
      "\n",
      "episode 11, policy loss 2.275424003601074\n",
      "\n",
      "episode 12, policy loss 2.2754225730895996\n",
      "\n",
      "episode 13, policy loss 2.2754204273223877\n",
      "\n",
      "episode 14, policy loss 2.2754204273223877\n",
      "\n",
      "episode 15, policy loss 2.275421619415283\n",
      "\n",
      "episode 16, policy loss 2.275418996810913\n",
      "\n",
      "Policy train loss in epoch 1:2.2754205018281937\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 2.275418519973755\n",
      "\n",
      "episode 2, policy loss 2.275423526763916\n",
      "\n",
      "episode 3, policy loss 2.275424003601074\n",
      "\n",
      "episode 4, policy loss 2.275423765182495\n",
      "\n",
      "episode 5, policy loss 2.2754180431365967\n",
      "\n",
      "episode 6, policy loss 2.2754173278808594\n",
      "\n",
      "episode 7, policy loss 2.275418996810913\n",
      "\n",
      "episode 8, policy loss 2.2754130363464355\n",
      "\n",
      "episode 9, policy loss 2.275423049926758\n",
      "\n",
      "episode 10, policy loss 2.2754204273223877\n",
      "\n",
      "episode 11, policy loss 2.275423526763916\n",
      "\n",
      "episode 12, policy loss 2.2754225730895996\n",
      "\n",
      "episode 13, policy loss 2.2754204273223877\n",
      "\n",
      "episode 14, policy loss 2.275421619415283\n",
      "\n",
      "episode 15, policy loss 2.275418758392334\n",
      "\n",
      "episode 16, policy loss 2.2754204273223877\n",
      "\n",
      "Policy train loss in epoch 2:2.2754205018281937\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 2.275421619415283\n",
      "\n",
      "episode 2, policy loss 2.275423049926758\n",
      "\n",
      "episode 3, policy loss 2.275424003601074\n",
      "\n",
      "episode 4, policy loss 2.2754130363464355\n",
      "\n",
      "episode 5, policy loss 2.275418519973755\n",
      "\n",
      "episode 6, policy loss 2.2754225730895996\n",
      "\n",
      "episode 7, policy loss 2.2754204273223877\n",
      "\n",
      "episode 8, policy loss 2.2754173278808594\n",
      "\n",
      "episode 9, policy loss 2.275418758392334\n",
      "\n",
      "episode 10, policy loss 2.275423526763916\n",
      "\n",
      "episode 11, policy loss 2.275418996810913\n",
      "\n",
      "episode 12, policy loss 2.2754204273223877\n",
      "\n",
      "episode 13, policy loss 2.275423526763916\n",
      "\n",
      "episode 14, policy loss 2.2754204273223877\n",
      "\n",
      "episode 15, policy loss 2.275423765182495\n",
      "\n",
      "episode 16, policy loss 2.2754180431365967\n",
      "\n",
      "Policy train loss in epoch 3:2.2754205018281937\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.886989414691925\n",
      "\n",
      "episode 2, val func loss 0.8398210406303406\n",
      "\n",
      "episode 3, val func loss 0.82213294506073\n",
      "\n",
      "episode 4, val func loss 0.7702150940895081\n",
      "\n",
      "episode 5, val func loss 0.89483642578125\n",
      "\n",
      "episode 6, val func loss 0.7737493515014648\n",
      "\n",
      "episode 7, val func loss 0.9806636571884155\n",
      "\n",
      "episode 8, val func loss 0.8231844902038574\n",
      "\n",
      "episode 9, val func loss 0.8759799003601074\n",
      "\n",
      "episode 10, val func loss 0.8786787390708923\n",
      "\n",
      "episode 11, val func loss 0.8983626961708069\n",
      "\n",
      "episode 12, val func loss 0.7518404126167297\n",
      "\n",
      "episode 13, val func loss 0.7721763253211975\n",
      "\n",
      "episode 14, val func loss 0.845124363899231\n",
      "\n",
      "episode 15, val func loss 0.7379728555679321\n",
      "\n",
      "episode 16, val func loss 0.8631979823112488\n",
      "\n",
      "Val func train loss in epoch 0:0.8384328559041023\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7738385796546936\n",
      "\n",
      "episode 2, val func loss 0.8536732196807861\n",
      "\n",
      "episode 3, val func loss 0.8498650789260864\n",
      "\n",
      "episode 4, val func loss 0.7427754998207092\n",
      "\n",
      "episode 5, val func loss 0.9094259738922119\n",
      "\n",
      "episode 6, val func loss 0.735525906085968\n",
      "\n",
      "episode 7, val func loss 0.7485358119010925\n",
      "\n",
      "episode 8, val func loss 0.7808720469474792\n",
      "\n",
      "episode 9, val func loss 0.7306092381477356\n",
      "\n",
      "episode 10, val func loss 0.9361497759819031\n",
      "\n",
      "episode 11, val func loss 0.7707582712173462\n",
      "\n",
      "episode 12, val func loss 0.7427770495414734\n",
      "\n",
      "episode 13, val func loss 0.7797428965568542\n",
      "\n",
      "episode 14, val func loss 0.8589209914207458\n",
      "\n",
      "episode 15, val func loss 0.7641754150390625\n",
      "\n",
      "episode 16, val func loss 0.8239973187446594\n",
      "\n",
      "Val func train loss in epoch 1:0.8001026920974255\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7997404932975769\n",
      "\n",
      "episode 2, val func loss 0.8470715284347534\n",
      "\n",
      "episode 3, val func loss 0.7031022906303406\n",
      "\n",
      "episode 4, val func loss 0.8422793745994568\n",
      "\n",
      "episode 5, val func loss 0.6809062361717224\n",
      "\n",
      "episode 6, val func loss 0.75584477186203\n",
      "\n",
      "episode 7, val func loss 0.789409339427948\n",
      "\n",
      "episode 8, val func loss 0.8542414903640747\n",
      "\n",
      "episode 9, val func loss 0.8048426508903503\n",
      "\n",
      "episode 10, val func loss 0.8033613562583923\n",
      "\n",
      "episode 11, val func loss 0.7343393564224243\n",
      "\n",
      "episode 12, val func loss 0.7859697937965393\n",
      "\n",
      "episode 13, val func loss 0.857499897480011\n",
      "\n",
      "episode 14, val func loss 0.781672477722168\n",
      "\n",
      "episode 15, val func loss 0.833203136920929\n",
      "\n",
      "episode 16, val func loss 0.7016395330429077\n",
      "\n",
      "Val func train loss in epoch 2:0.7859452329576015\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8590882420539856\n",
      "\n",
      "episode 2, val func loss 0.8204800486564636\n",
      "\n",
      "episode 3, val func loss 0.9657406210899353\n",
      "\n",
      "episode 4, val func loss 0.8732302188873291\n",
      "\n",
      "episode 5, val func loss 0.8224042057991028\n",
      "\n",
      "episode 6, val func loss 0.9151778817176819\n",
      "\n",
      "episode 7, val func loss 0.947739839553833\n",
      "\n",
      "episode 8, val func loss 1.0069578886032104\n",
      "\n",
      "episode 9, val func loss 0.7209821343421936\n",
      "\n",
      "episode 10, val func loss 0.8526102304458618\n",
      "\n",
      "episode 11, val func loss 1.021497368812561\n",
      "\n",
      "episode 12, val func loss 0.9027968049049377\n",
      "\n",
      "episode 13, val func loss 1.109458565711975\n",
      "\n",
      "episode 14, val func loss 0.8512294888496399\n",
      "\n",
      "episode 15, val func loss 0.8216055035591125\n",
      "\n",
      "episode 16, val func loss 0.945815920829773\n",
      "\n",
      "Val func train loss in epoch 3:0.9023009352385998\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8730563521385193\n",
      "\n",
      "episode 2, val func loss 0.7459729313850403\n",
      "\n",
      "episode 3, val func loss 0.8769022226333618\n",
      "\n",
      "episode 4, val func loss 0.7965323328971863\n",
      "\n",
      "episode 5, val func loss 0.8290782570838928\n",
      "\n",
      "episode 6, val func loss 0.9049096703529358\n",
      "\n",
      "episode 7, val func loss 0.8026202917098999\n",
      "\n",
      "episode 8, val func loss 0.7384259104728699\n",
      "\n",
      "episode 9, val func loss 0.9001231789588928\n",
      "\n",
      "episode 10, val func loss 0.89313805103302\n",
      "\n",
      "episode 11, val func loss 0.8345735669136047\n",
      "\n",
      "episode 12, val func loss 0.8313839435577393\n",
      "\n",
      "episode 13, val func loss 0.7732889652252197\n",
      "\n",
      "episode 14, val func loss 0.7500005960464478\n",
      "\n",
      "episode 15, val func loss 0.8375847935676575\n",
      "\n",
      "episode 16, val func loss 0.7801533937454224\n",
      "\n",
      "Val func train loss in epoch 4:0.8229840286076069\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.876236081123352\n",
      "\n",
      "episode 2, val func loss 0.9195537567138672\n",
      "\n",
      "episode 3, val func loss 0.7921283841133118\n",
      "\n",
      "episode 4, val func loss 0.9148539900779724\n",
      "\n",
      "episode 5, val func loss 0.8436843156814575\n",
      "\n",
      "episode 6, val func loss 0.7868420481681824\n",
      "\n",
      "episode 7, val func loss 0.7914576530456543\n",
      "\n",
      "episode 8, val func loss 0.9988142848014832\n",
      "\n",
      "episode 9, val func loss 0.885406494140625\n",
      "\n",
      "episode 10, val func loss 0.8123922348022461\n",
      "\n",
      "episode 11, val func loss 0.881477952003479\n",
      "\n",
      "episode 12, val func loss 0.8875348567962646\n",
      "\n",
      "episode 13, val func loss 0.8231868147850037\n",
      "\n",
      "episode 14, val func loss 0.8460386395454407\n",
      "\n",
      "episode 15, val func loss 0.8160392045974731\n",
      "\n",
      "episode 16, val func loss 0.7971985936164856\n",
      "\n",
      "Val func train loss in epoch 5:0.8545528315007687\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7624231576919556\n",
      "\n",
      "episode 2, val func loss 0.9204338788986206\n",
      "\n",
      "episode 3, val func loss 0.7528679966926575\n",
      "\n",
      "episode 4, val func loss 0.7906110882759094\n",
      "\n",
      "episode 5, val func loss 0.8443906903266907\n",
      "\n",
      "episode 6, val func loss 0.7573718428611755\n",
      "\n",
      "episode 7, val func loss 0.73800128698349\n",
      "\n",
      "episode 8, val func loss 0.7340026497840881\n",
      "\n",
      "episode 9, val func loss 0.7768412232398987\n",
      "\n",
      "episode 10, val func loss 0.9169126152992249\n",
      "\n",
      "episode 11, val func loss 0.798448383808136\n",
      "\n",
      "episode 12, val func loss 0.7472913861274719\n",
      "\n",
      "episode 13, val func loss 0.8243924975395203\n",
      "\n",
      "episode 14, val func loss 0.7765693068504333\n",
      "\n",
      "episode 15, val func loss 0.9189779162406921\n",
      "\n",
      "episode 16, val func loss 0.7579140067100525\n",
      "\n",
      "Val func train loss in epoch 6:0.8010906204581261\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.8188344836235046\n",
      "\n",
      "episode 2, val func loss 0.8103620409965515\n",
      "\n",
      "episode 3, val func loss 0.8546543121337891\n",
      "\n",
      "episode 4, val func loss 0.7967577576637268\n",
      "\n",
      "episode 5, val func loss 0.8335012793540955\n",
      "\n",
      "episode 6, val func loss 0.9016327261924744\n",
      "\n",
      "episode 7, val func loss 0.8550443649291992\n",
      "\n",
      "episode 8, val func loss 0.8952416181564331\n",
      "\n",
      "episode 9, val func loss 0.7712652683258057\n",
      "\n",
      "episode 10, val func loss 0.8357869982719421\n",
      "\n",
      "episode 11, val func loss 0.7711426615715027\n",
      "\n",
      "episode 12, val func loss 0.7409830093383789\n",
      "\n",
      "episode 13, val func loss 0.7299753427505493\n",
      "\n",
      "episode 14, val func loss 0.8693739771842957\n",
      "\n",
      "episode 15, val func loss 0.8093949556350708\n",
      "\n",
      "episode 16, val func loss 0.77360999584198\n",
      "\n",
      "Val func train loss in epoch 7:0.8167225494980812\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8110544681549072\n",
      "\n",
      "episode 2, val func loss 0.744930624961853\n",
      "\n",
      "episode 3, val func loss 0.8197116255760193\n",
      "\n",
      "episode 4, val func loss 0.824129045009613\n",
      "\n",
      "episode 5, val func loss 0.8829841613769531\n",
      "\n",
      "episode 6, val func loss 0.7669277191162109\n",
      "\n",
      "episode 7, val func loss 0.6931884288787842\n",
      "\n",
      "episode 8, val func loss 0.8017172813415527\n",
      "\n",
      "episode 9, val func loss 0.7380487322807312\n",
      "\n",
      "episode 10, val func loss 0.7746091485023499\n",
      "\n",
      "episode 11, val func loss 0.7178003191947937\n",
      "\n",
      "episode 12, val func loss 0.7319074273109436\n",
      "\n",
      "episode 13, val func loss 0.8710712194442749\n",
      "\n",
      "episode 14, val func loss 0.8407976627349854\n",
      "\n",
      "episode 15, val func loss 0.7906434535980225\n",
      "\n",
      "episode 16, val func loss 0.7935417890548706\n",
      "\n",
      "Val func train loss in epoch 8:0.7876914441585541\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8746167421340942\n",
      "\n",
      "episode 2, val func loss 0.8425654768943787\n",
      "\n",
      "episode 3, val func loss 0.8622002005577087\n",
      "\n",
      "episode 4, val func loss 0.731558620929718\n",
      "\n",
      "episode 5, val func loss 0.782317578792572\n",
      "\n",
      "episode 6, val func loss 0.9979056119918823\n",
      "\n",
      "episode 7, val func loss 0.8332096934318542\n",
      "\n",
      "episode 8, val func loss 0.82961505651474\n",
      "\n",
      "episode 9, val func loss 0.8768224716186523\n",
      "\n",
      "episode 10, val func loss 0.8012154698371887\n",
      "\n",
      "episode 11, val func loss 0.8021197319030762\n",
      "\n",
      "episode 12, val func loss 0.923177182674408\n",
      "\n",
      "episode 13, val func loss 0.7295658588409424\n",
      "\n",
      "episode 14, val func loss 0.8771696090698242\n",
      "\n",
      "episode 15, val func loss 0.9725873470306396\n",
      "\n",
      "episode 16, val func loss 0.9047028422355652\n",
      "\n",
      "Val func train loss in epoch 9:0.8525843434035778\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.8514925241470337\n",
      "\n",
      "episode 2, val func loss 0.7295016646385193\n",
      "\n",
      "episode 3, val func loss 0.767087459564209\n",
      "\n",
      "episode 4, val func loss 0.8157716989517212\n",
      "\n",
      "episode 5, val func loss 0.8047226071357727\n",
      "\n",
      "episode 6, val func loss 0.7079479694366455\n",
      "\n",
      "episode 7, val func loss 0.8355093002319336\n",
      "\n",
      "episode 8, val func loss 0.8975772857666016\n",
      "\n",
      "episode 9, val func loss 0.9066354036331177\n",
      "\n",
      "episode 10, val func loss 1.0139557123184204\n",
      "\n",
      "episode 11, val func loss 0.7959986329078674\n",
      "\n",
      "episode 12, val func loss 0.8021112680435181\n",
      "\n",
      "episode 13, val func loss 0.885115921497345\n",
      "\n",
      "episode 14, val func loss 0.8460192680358887\n",
      "\n",
      "episode 15, val func loss 0.8293835520744324\n",
      "\n",
      "episode 16, val func loss 0.8903892636299133\n",
      "\n",
      "Val func train loss in epoch 10:0.8362012207508087\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7937242388725281\n",
      "\n",
      "episode 2, val func loss 0.8226796388626099\n",
      "\n",
      "episode 3, val func loss 0.7980144619941711\n",
      "\n",
      "episode 4, val func loss 0.8530814051628113\n",
      "\n",
      "episode 5, val func loss 0.7829036116600037\n",
      "\n",
      "episode 6, val func loss 0.8692192435264587\n",
      "\n",
      "episode 7, val func loss 0.7968264818191528\n",
      "\n",
      "episode 8, val func loss 0.7896488308906555\n",
      "\n",
      "episode 9, val func loss 0.6705790758132935\n",
      "\n",
      "episode 10, val func loss 0.7476674318313599\n",
      "\n",
      "episode 11, val func loss 0.7625291347503662\n",
      "\n",
      "episode 12, val func loss 0.7306650280952454\n",
      "\n",
      "episode 13, val func loss 0.7464748024940491\n",
      "\n",
      "episode 14, val func loss 0.7701316475868225\n",
      "\n",
      "episode 15, val func loss 0.9079298377037048\n",
      "\n",
      "episode 16, val func loss 0.8677159547805786\n",
      "\n",
      "Val func train loss in epoch 11:0.7943619266152382\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.8648689985275269\n",
      "\n",
      "episode 2, val func loss 0.7923867702484131\n",
      "\n",
      "episode 3, val func loss 0.7951341271400452\n",
      "\n",
      "episode 4, val func loss 0.7518933415412903\n",
      "\n",
      "episode 5, val func loss 0.9385945796966553\n",
      "\n",
      "episode 6, val func loss 0.8156912326812744\n",
      "\n",
      "episode 7, val func loss 0.9652359485626221\n",
      "\n",
      "episode 8, val func loss 0.8855189681053162\n",
      "\n",
      "episode 9, val func loss 0.6996577978134155\n",
      "\n",
      "episode 10, val func loss 0.6803256273269653\n",
      "\n",
      "episode 11, val func loss 0.9539000391960144\n",
      "\n",
      "episode 12, val func loss 0.7955252528190613\n",
      "\n",
      "episode 13, val func loss 0.8858644366264343\n",
      "\n",
      "episode 14, val func loss 0.8091989755630493\n",
      "\n",
      "episode 15, val func loss 0.7567372918128967\n",
      "\n",
      "episode 16, val func loss 0.7817392945289612\n",
      "\n",
      "Val func train loss in epoch 12:0.8232670426368713\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.9551826119422913\n",
      "\n",
      "episode 2, val func loss 0.7529711723327637\n",
      "\n",
      "episode 3, val func loss 0.9058684706687927\n",
      "\n",
      "episode 4, val func loss 0.9196999073028564\n",
      "\n",
      "episode 5, val func loss 0.8795426487922668\n",
      "\n",
      "episode 6, val func loss 0.9095581769943237\n",
      "\n",
      "episode 7, val func loss 0.9219523668289185\n",
      "\n",
      "episode 8, val func loss 0.9113950729370117\n",
      "\n",
      "episode 9, val func loss 0.8843730688095093\n",
      "\n",
      "episode 10, val func loss 0.8703764081001282\n",
      "\n",
      "episode 11, val func loss 0.7842127680778503\n",
      "\n",
      "episode 12, val func loss 0.778035581111908\n",
      "\n",
      "episode 13, val func loss 0.7449808716773987\n",
      "\n",
      "episode 14, val func loss 0.8206591606140137\n",
      "\n",
      "episode 15, val func loss 0.7566606402397156\n",
      "\n",
      "episode 16, val func loss 0.7067461013793945\n",
      "\n",
      "Val func train loss in epoch 13:0.8438884392380714\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.8184607028961182\n",
      "\n",
      "episode 2, val func loss 0.7445447444915771\n",
      "\n",
      "episode 3, val func loss 0.8561365604400635\n",
      "\n",
      "episode 4, val func loss 0.8378230333328247\n",
      "\n",
      "episode 5, val func loss 0.7182460427284241\n",
      "\n",
      "episode 6, val func loss 0.74294513463974\n",
      "\n",
      "episode 7, val func loss 0.7997304201126099\n",
      "\n",
      "episode 8, val func loss 0.9349619150161743\n",
      "\n",
      "episode 9, val func loss 0.7762664556503296\n",
      "\n",
      "episode 10, val func loss 0.8896524906158447\n",
      "\n",
      "episode 11, val func loss 0.7794854640960693\n",
      "\n",
      "episode 12, val func loss 0.8309601545333862\n",
      "\n",
      "episode 13, val func loss 0.8611059188842773\n",
      "\n",
      "episode 14, val func loss 0.8787426352500916\n",
      "\n",
      "episode 15, val func loss 0.7726162672042847\n",
      "\n",
      "episode 16, val func loss 0.7296353578567505\n",
      "\n",
      "Val func train loss in epoch 14:0.8107070811092854\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.8255838751792908\n",
      "\n",
      "episode 2, val func loss 0.7465039491653442\n",
      "\n",
      "episode 3, val func loss 0.7600507736206055\n",
      "\n",
      "episode 4, val func loss 0.9480516314506531\n",
      "\n",
      "episode 5, val func loss 0.806637167930603\n",
      "\n",
      "episode 6, val func loss 0.8720658421516418\n",
      "\n",
      "episode 7, val func loss 0.8121115565299988\n",
      "\n",
      "episode 8, val func loss 0.8700217604637146\n",
      "\n",
      "episode 9, val func loss 0.7796741127967834\n",
      "\n",
      "episode 10, val func loss 0.7958720922470093\n",
      "\n",
      "episode 11, val func loss 0.75652676820755\n",
      "\n",
      "episode 12, val func loss 0.8976379036903381\n",
      "\n",
      "episode 13, val func loss 0.7821878790855408\n",
      "\n",
      "episode 14, val func loss 0.8166449069976807\n",
      "\n",
      "episode 15, val func loss 0.8112402558326721\n",
      "\n",
      "episode 16, val func loss 0.7680755257606506\n",
      "\n",
      "Val func train loss in epoch 15:0.8155553750693798\n",
      "***********************TIME WAS 4.834553360939026 min*****************************\n",
      "\n",
      "**********************ROUND 55 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.8014365434646606\n",
      "\n",
      "episode 2, policy loss 0.8014367818832397\n",
      "\n",
      "episode 3, policy loss 0.8014380931854248\n",
      "\n",
      "episode 4, policy loss 0.8014364242553711\n",
      "\n",
      "episode 5, policy loss 0.8014371991157532\n",
      "\n",
      "episode 6, policy loss 0.8014373779296875\n",
      "\n",
      "episode 7, policy loss 0.8014369010925293\n",
      "\n",
      "episode 8, policy loss 0.8014370799064636\n",
      "\n",
      "episode 9, policy loss 0.8014360070228577\n",
      "\n",
      "episode 10, policy loss 0.8014373183250427\n",
      "\n",
      "episode 11, policy loss 0.8014367818832397\n",
      "\n",
      "episode 12, policy loss 0.8014365434646606\n",
      "\n",
      "episode 13, policy loss 0.8014373183250427\n",
      "\n",
      "episode 14, policy loss 0.8014379143714905\n",
      "\n",
      "episode 15, policy loss 0.8014379143714905\n",
      "\n",
      "episode 16, policy loss 0.8014373183250427\n",
      "\n",
      "Policy train loss in epoch 0:0.8014370948076248\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.8014369010925293\n",
      "\n",
      "episode 2, policy loss 0.8014367818832397\n",
      "\n",
      "episode 3, policy loss 0.8014365434646606\n",
      "\n",
      "episode 4, policy loss 0.8014373183250427\n",
      "\n",
      "episode 5, policy loss 0.8014373183250427\n",
      "\n",
      "episode 6, policy loss 0.8014367818832397\n",
      "\n",
      "episode 7, policy loss 0.8014373779296875\n",
      "\n",
      "episode 8, policy loss 0.8014371991157532\n",
      "\n",
      "episode 9, policy loss 0.8014360070228577\n",
      "\n",
      "episode 10, policy loss 0.8014379143714905\n",
      "\n",
      "episode 11, policy loss 0.8014380931854248\n",
      "\n",
      "episode 12, policy loss 0.8014370799064636\n",
      "\n",
      "episode 13, policy loss 0.8014364242553711\n",
      "\n",
      "episode 14, policy loss 0.8014365434646606\n",
      "\n",
      "episode 15, policy loss 0.8014373183250427\n",
      "\n",
      "episode 16, policy loss 0.8014379143714905\n",
      "\n",
      "Policy train loss in epoch 1:0.8014370948076248\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.8014373779296875\n",
      "\n",
      "episode 2, policy loss 0.8014380931854248\n",
      "\n",
      "episode 3, policy loss 0.8014373183250427\n",
      "\n",
      "episode 4, policy loss 0.8014371991157532\n",
      "\n",
      "episode 5, policy loss 0.8014360070228577\n",
      "\n",
      "episode 6, policy loss 0.8014365434646606\n",
      "\n",
      "episode 7, policy loss 0.8014379143714905\n",
      "\n",
      "episode 8, policy loss 0.8014364242553711\n",
      "\n",
      "episode 9, policy loss 0.8014373183250427\n",
      "\n",
      "episode 10, policy loss 0.8014367818832397\n",
      "\n",
      "episode 11, policy loss 0.8014379143714905\n",
      "\n",
      "episode 12, policy loss 0.8014367818832397\n",
      "\n",
      "episode 13, policy loss 0.8014365434646606\n",
      "\n",
      "episode 14, policy loss 0.8014369010925293\n",
      "\n",
      "episode 15, policy loss 0.8014373183250427\n",
      "\n",
      "episode 16, policy loss 0.8014370799064636\n",
      "\n",
      "Policy train loss in epoch 2:0.8014370948076248\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.8014380931854248\n",
      "\n",
      "episode 2, policy loss 0.8014379143714905\n",
      "\n",
      "episode 3, policy loss 0.8014373183250427\n",
      "\n",
      "episode 4, policy loss 0.8014373183250427\n",
      "\n",
      "episode 5, policy loss 0.8014379143714905\n",
      "\n",
      "episode 6, policy loss 0.8014373779296875\n",
      "\n",
      "episode 7, policy loss 0.8014360070228577\n",
      "\n",
      "episode 8, policy loss 0.8014371991157532\n",
      "\n",
      "episode 9, policy loss 0.8014369010925293\n",
      "\n",
      "episode 10, policy loss 0.8014365434646606\n",
      "\n",
      "episode 11, policy loss 0.8014365434646606\n",
      "\n",
      "episode 12, policy loss 0.8014367818832397\n",
      "\n",
      "episode 13, policy loss 0.8014370799064636\n",
      "\n",
      "episode 14, policy loss 0.8014364242553711\n",
      "\n",
      "episode 15, policy loss 0.8014367818832397\n",
      "\n",
      "episode 16, policy loss 0.8014373183250427\n",
      "\n",
      "Policy train loss in epoch 3:0.8014370948076248\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.8270898461341858\n",
      "\n",
      "episode 2, val func loss 0.8489879369735718\n",
      "\n",
      "episode 3, val func loss 0.8503080010414124\n",
      "\n",
      "episode 4, val func loss 0.809179425239563\n",
      "\n",
      "episode 5, val func loss 0.9062473773956299\n",
      "\n",
      "episode 6, val func loss 0.8684121966362\n",
      "\n",
      "episode 7, val func loss 0.7473424673080444\n",
      "\n",
      "episode 8, val func loss 0.716765284538269\n",
      "\n",
      "episode 9, val func loss 0.7718300223350525\n",
      "\n",
      "episode 10, val func loss 0.8313155770301819\n",
      "\n",
      "episode 11, val func loss 0.8038957118988037\n",
      "\n",
      "episode 12, val func loss 0.9644433856010437\n",
      "\n",
      "episode 13, val func loss 0.7906045913696289\n",
      "\n",
      "episode 14, val func loss 1.0325651168823242\n",
      "\n",
      "episode 15, val func loss 0.7878945469856262\n",
      "\n",
      "episode 16, val func loss 0.8940404057502747\n",
      "\n",
      "Val func train loss in epoch 0:0.8406826183199883\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7677965760231018\n",
      "\n",
      "episode 2, val func loss 0.9127535820007324\n",
      "\n",
      "episode 3, val func loss 0.7427074909210205\n",
      "\n",
      "episode 4, val func loss 0.8356733322143555\n",
      "\n",
      "episode 5, val func loss 0.8875982165336609\n",
      "\n",
      "episode 6, val func loss 0.7711753249168396\n",
      "\n",
      "episode 7, val func loss 0.7483130693435669\n",
      "\n",
      "episode 8, val func loss 0.7518725395202637\n",
      "\n",
      "episode 9, val func loss 0.8056474924087524\n",
      "\n",
      "episode 10, val func loss 0.7722821831703186\n",
      "\n",
      "episode 11, val func loss 0.7972774505615234\n",
      "\n",
      "episode 12, val func loss 0.8879101872444153\n",
      "\n",
      "episode 13, val func loss 0.6881949305534363\n",
      "\n",
      "episode 14, val func loss 0.7863739132881165\n",
      "\n",
      "episode 15, val func loss 0.786617636680603\n",
      "\n",
      "episode 16, val func loss 0.8062580227851868\n",
      "\n",
      "Val func train loss in epoch 1:0.7967782467603683\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7515784502029419\n",
      "\n",
      "episode 2, val func loss 0.7674041390419006\n",
      "\n",
      "episode 3, val func loss 0.806149959564209\n",
      "\n",
      "episode 4, val func loss 0.7356602549552917\n",
      "\n",
      "episode 5, val func loss 0.7909740209579468\n",
      "\n",
      "episode 6, val func loss 0.9443836212158203\n",
      "\n",
      "episode 7, val func loss 0.8467211723327637\n",
      "\n",
      "episode 8, val func loss 0.7684910297393799\n",
      "\n",
      "episode 9, val func loss 0.8139767050743103\n",
      "\n",
      "episode 10, val func loss 0.9793120622634888\n",
      "\n",
      "episode 11, val func loss 0.8308249711990356\n",
      "\n",
      "episode 12, val func loss 0.8197021484375\n",
      "\n",
      "episode 13, val func loss 0.8143390417098999\n",
      "\n",
      "episode 14, val func loss 0.7474888563156128\n",
      "\n",
      "episode 15, val func loss 0.8226832747459412\n",
      "\n",
      "episode 16, val func loss 0.7862412929534912\n",
      "\n",
      "Val func train loss in epoch 2:0.8141206875443459\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8672738671302795\n",
      "\n",
      "episode 2, val func loss 0.899950385093689\n",
      "\n",
      "episode 3, val func loss 0.8240648508071899\n",
      "\n",
      "episode 4, val func loss 0.8751282095909119\n",
      "\n",
      "episode 5, val func loss 0.8022710084915161\n",
      "\n",
      "episode 6, val func loss 0.871027410030365\n",
      "\n",
      "episode 7, val func loss 0.7024264931678772\n",
      "\n",
      "episode 8, val func loss 0.8015294671058655\n",
      "\n",
      "episode 9, val func loss 0.7626226544380188\n",
      "\n",
      "episode 10, val func loss 0.7422037720680237\n",
      "\n",
      "episode 11, val func loss 0.8847575187683105\n",
      "\n",
      "episode 12, val func loss 0.8185184597969055\n",
      "\n",
      "episode 13, val func loss 0.9148404002189636\n",
      "\n",
      "episode 14, val func loss 0.676967203617096\n",
      "\n",
      "episode 15, val func loss 0.8452514410018921\n",
      "\n",
      "episode 16, val func loss 0.8918750882148743\n",
      "\n",
      "Val func train loss in epoch 3:0.8237942643463612\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7720056772232056\n",
      "\n",
      "episode 2, val func loss 0.7014570832252502\n",
      "\n",
      "episode 3, val func loss 0.8041526079177856\n",
      "\n",
      "episode 4, val func loss 0.8936892151832581\n",
      "\n",
      "episode 5, val func loss 0.8057078719139099\n",
      "\n",
      "episode 6, val func loss 0.896937906742096\n",
      "\n",
      "episode 7, val func loss 0.7991527915000916\n",
      "\n",
      "episode 8, val func loss 0.7763044834136963\n",
      "\n",
      "episode 9, val func loss 0.7944973707199097\n",
      "\n",
      "episode 10, val func loss 0.8515248894691467\n",
      "\n",
      "episode 11, val func loss 0.7659368515014648\n",
      "\n",
      "episode 12, val func loss 0.7635459303855896\n",
      "\n",
      "episode 13, val func loss 0.8111410737037659\n",
      "\n",
      "episode 14, val func loss 0.7981136441230774\n",
      "\n",
      "episode 15, val func loss 0.8984988927841187\n",
      "\n",
      "episode 16, val func loss 0.8582234978675842\n",
      "\n",
      "Val func train loss in epoch 4:0.8119306117296219\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.887805700302124\n",
      "\n",
      "episode 2, val func loss 0.816935658454895\n",
      "\n",
      "episode 3, val func loss 0.817926824092865\n",
      "\n",
      "episode 4, val func loss 0.8356808423995972\n",
      "\n",
      "episode 5, val func loss 0.7712684273719788\n",
      "\n",
      "episode 6, val func loss 0.7167214155197144\n",
      "\n",
      "episode 7, val func loss 0.8420143127441406\n",
      "\n",
      "episode 8, val func loss 0.7440128326416016\n",
      "\n",
      "episode 9, val func loss 0.7201043367385864\n",
      "\n",
      "episode 10, val func loss 0.7442408204078674\n",
      "\n",
      "episode 11, val func loss 0.898743212223053\n",
      "\n",
      "episode 12, val func loss 0.7609716057777405\n",
      "\n",
      "episode 13, val func loss 0.7646681666374207\n",
      "\n",
      "episode 14, val func loss 0.9012743234634399\n",
      "\n",
      "episode 15, val func loss 0.7611210346221924\n",
      "\n",
      "episode 16, val func loss 0.7600131034851074\n",
      "\n",
      "Val func train loss in epoch 5:0.7964689135551453\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8480635285377502\n",
      "\n",
      "episode 2, val func loss 0.8664336800575256\n",
      "\n",
      "episode 3, val func loss 0.7723820209503174\n",
      "\n",
      "episode 4, val func loss 0.9258238673210144\n",
      "\n",
      "episode 5, val func loss 0.8354517817497253\n",
      "\n",
      "episode 6, val func loss 0.8526992201805115\n",
      "\n",
      "episode 7, val func loss 0.8675704002380371\n",
      "\n",
      "episode 8, val func loss 0.7291492223739624\n",
      "\n",
      "episode 9, val func loss 0.77689129114151\n",
      "\n",
      "episode 10, val func loss 0.8809716701507568\n",
      "\n",
      "episode 11, val func loss 0.7323288321495056\n",
      "\n",
      "episode 12, val func loss 0.8827353119850159\n",
      "\n",
      "episode 13, val func loss 0.7831742763519287\n",
      "\n",
      "episode 14, val func loss 0.7071927785873413\n",
      "\n",
      "episode 15, val func loss 0.8316596746444702\n",
      "\n",
      "episode 16, val func loss 0.880070686340332\n",
      "\n",
      "Val func train loss in epoch 6:0.8232873901724815\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7938039898872375\n",
      "\n",
      "episode 2, val func loss 0.9110495448112488\n",
      "\n",
      "episode 3, val func loss 0.8492915034294128\n",
      "\n",
      "episode 4, val func loss 0.8739147186279297\n",
      "\n",
      "episode 5, val func loss 0.8833187222480774\n",
      "\n",
      "episode 6, val func loss 0.8128319978713989\n",
      "\n",
      "episode 7, val func loss 0.7536640167236328\n",
      "\n",
      "episode 8, val func loss 0.9905831813812256\n",
      "\n",
      "episode 9, val func loss 0.835705041885376\n",
      "\n",
      "episode 10, val func loss 0.829405665397644\n",
      "\n",
      "episode 11, val func loss 0.7878775000572205\n",
      "\n",
      "episode 12, val func loss 0.8200814127922058\n",
      "\n",
      "episode 13, val func loss 0.8487724661827087\n",
      "\n",
      "episode 14, val func loss 0.7315965294837952\n",
      "\n",
      "episode 15, val func loss 0.7524574398994446\n",
      "\n",
      "episode 16, val func loss 0.7857396602630615\n",
      "\n",
      "Val func train loss in epoch 7:0.8287558369338512\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7407023310661316\n",
      "\n",
      "episode 2, val func loss 0.8401810526847839\n",
      "\n",
      "episode 3, val func loss 0.8925562500953674\n",
      "\n",
      "episode 4, val func loss 0.7341753244400024\n",
      "\n",
      "episode 5, val func loss 0.7576600909233093\n",
      "\n",
      "episode 6, val func loss 0.8744012117385864\n",
      "\n",
      "episode 7, val func loss 0.881127655506134\n",
      "\n",
      "episode 8, val func loss 0.7812423706054688\n",
      "\n",
      "episode 9, val func loss 0.8820942044258118\n",
      "\n",
      "episode 10, val func loss 0.8460507988929749\n",
      "\n",
      "episode 11, val func loss 0.7753602266311646\n",
      "\n",
      "episode 12, val func loss 0.9406492710113525\n",
      "\n",
      "episode 13, val func loss 0.7918317914009094\n",
      "\n",
      "episode 14, val func loss 0.7642286419868469\n",
      "\n",
      "episode 15, val func loss 0.7910450100898743\n",
      "\n",
      "episode 16, val func loss 0.7898773550987244\n",
      "\n",
      "Val func train loss in epoch 8:0.8176989741623402\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.7824369072914124\n",
      "\n",
      "episode 2, val func loss 0.8532091379165649\n",
      "\n",
      "episode 3, val func loss 0.85877525806427\n",
      "\n",
      "episode 4, val func loss 0.7962766289710999\n",
      "\n",
      "episode 5, val func loss 0.7264114022254944\n",
      "\n",
      "episode 6, val func loss 1.0255286693572998\n",
      "\n",
      "episode 7, val func loss 0.7966750860214233\n",
      "\n",
      "episode 8, val func loss 0.7619963884353638\n",
      "\n",
      "episode 9, val func loss 0.9588598608970642\n",
      "\n",
      "episode 10, val func loss 0.8049558997154236\n",
      "\n",
      "episode 11, val func loss 0.7903463840484619\n",
      "\n",
      "episode 12, val func loss 0.8782453536987305\n",
      "\n",
      "episode 13, val func loss 0.7715741395950317\n",
      "\n",
      "episode 14, val func loss 0.7529805898666382\n",
      "\n",
      "episode 15, val func loss 0.7406917214393616\n",
      "\n",
      "episode 16, val func loss 0.8471422791481018\n",
      "\n",
      "Val func train loss in epoch 9:0.8216316066682339\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.8409533500671387\n",
      "\n",
      "episode 2, val func loss 0.8426931500434875\n",
      "\n",
      "episode 3, val func loss 0.6964808106422424\n",
      "\n",
      "episode 4, val func loss 0.7961264252662659\n",
      "\n",
      "episode 5, val func loss 0.8851073980331421\n",
      "\n",
      "episode 6, val func loss 0.7442256212234497\n",
      "\n",
      "episode 7, val func loss 0.6608397960662842\n",
      "\n",
      "episode 8, val func loss 0.6016231775283813\n",
      "\n",
      "episode 9, val func loss 0.8799440264701843\n",
      "\n",
      "episode 10, val func loss 0.855482280254364\n",
      "\n",
      "episode 11, val func loss 0.8951915502548218\n",
      "\n",
      "episode 12, val func loss 0.8073561191558838\n",
      "\n",
      "episode 13, val func loss 0.7217569947242737\n",
      "\n",
      "episode 14, val func loss 0.8086434602737427\n",
      "\n",
      "episode 15, val func loss 0.8069853186607361\n",
      "\n",
      "episode 16, val func loss 0.7991481423377991\n",
      "\n",
      "Val func train loss in epoch 10:0.7901598513126373\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9088106751441956\n",
      "\n",
      "episode 2, val func loss 0.7952011823654175\n",
      "\n",
      "episode 3, val func loss 0.7780212759971619\n",
      "\n",
      "episode 4, val func loss 0.7169971466064453\n",
      "\n",
      "episode 5, val func loss 0.9064658880233765\n",
      "\n",
      "episode 6, val func loss 0.8042393922805786\n",
      "\n",
      "episode 7, val func loss 0.7889404296875\n",
      "\n",
      "episode 8, val func loss 0.8005807399749756\n",
      "\n",
      "episode 9, val func loss 0.7659225463867188\n",
      "\n",
      "episode 10, val func loss 0.9174538850784302\n",
      "\n",
      "episode 11, val func loss 0.9441372752189636\n",
      "\n",
      "episode 12, val func loss 0.7829543352127075\n",
      "\n",
      "episode 13, val func loss 0.779152512550354\n",
      "\n",
      "episode 14, val func loss 0.7942747473716736\n",
      "\n",
      "episode 15, val func loss 0.6788637638092041\n",
      "\n",
      "episode 16, val func loss 0.7582377791404724\n",
      "\n",
      "Val func train loss in epoch 11:0.8075158484280109\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.8065081834793091\n",
      "\n",
      "episode 2, val func loss 0.8096132874488831\n",
      "\n",
      "episode 3, val func loss 0.9308744668960571\n",
      "\n",
      "episode 4, val func loss 0.7156403064727783\n",
      "\n",
      "episode 5, val func loss 0.7204691767692566\n",
      "\n",
      "episode 6, val func loss 0.8178903460502625\n",
      "\n",
      "episode 7, val func loss 0.8439142107963562\n",
      "\n",
      "episode 8, val func loss 0.7545403242111206\n",
      "\n",
      "episode 9, val func loss 0.7226085066795349\n",
      "\n",
      "episode 10, val func loss 0.792446494102478\n",
      "\n",
      "episode 11, val func loss 0.7959890365600586\n",
      "\n",
      "episode 12, val func loss 0.7023313045501709\n",
      "\n",
      "episode 13, val func loss 0.8140259981155396\n",
      "\n",
      "episode 14, val func loss 0.7966291904449463\n",
      "\n",
      "episode 15, val func loss 0.7942649126052856\n",
      "\n",
      "episode 16, val func loss 0.8505464196205139\n",
      "\n",
      "Val func train loss in epoch 12:0.7917682603001595\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8562078475952148\n",
      "\n",
      "episode 2, val func loss 0.7854584455490112\n",
      "\n",
      "episode 3, val func loss 0.7821775078773499\n",
      "\n",
      "episode 4, val func loss 0.8149739503860474\n",
      "\n",
      "episode 5, val func loss 0.7335009574890137\n",
      "\n",
      "episode 6, val func loss 0.8430067896842957\n",
      "\n",
      "episode 7, val func loss 0.8006644248962402\n",
      "\n",
      "episode 8, val func loss 0.8588641881942749\n",
      "\n",
      "episode 9, val func loss 0.7065154314041138\n",
      "\n",
      "episode 10, val func loss 0.7274554967880249\n",
      "\n",
      "episode 11, val func loss 0.7671440243721008\n",
      "\n",
      "episode 12, val func loss 0.779246985912323\n",
      "\n",
      "episode 13, val func loss 0.8420038819313049\n",
      "\n",
      "episode 14, val func loss 0.8830519318580627\n",
      "\n",
      "episode 15, val func loss 0.7870201468467712\n",
      "\n",
      "episode 16, val func loss 0.8042616248130798\n",
      "\n",
      "Val func train loss in epoch 13:0.7982221022248268\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6363790035247803\n",
      "\n",
      "episode 2, val func loss 0.8433023691177368\n",
      "\n",
      "episode 3, val func loss 0.7919965386390686\n",
      "\n",
      "episode 4, val func loss 0.8350327610969543\n",
      "\n",
      "episode 5, val func loss 0.9559951424598694\n",
      "\n",
      "episode 6, val func loss 0.7728442549705505\n",
      "\n",
      "episode 7, val func loss 0.7628393173217773\n",
      "\n",
      "episode 8, val func loss 0.8902069926261902\n",
      "\n",
      "episode 9, val func loss 0.7826645970344543\n",
      "\n",
      "episode 10, val func loss 0.8609799146652222\n",
      "\n",
      "episode 11, val func loss 0.8359972834587097\n",
      "\n",
      "episode 12, val func loss 0.7197843194007874\n",
      "\n",
      "episode 13, val func loss 0.7239248752593994\n",
      "\n",
      "episode 14, val func loss 0.7962484359741211\n",
      "\n",
      "episode 15, val func loss 0.7255318760871887\n",
      "\n",
      "episode 16, val func loss 0.7276662588119507\n",
      "\n",
      "Val func train loss in epoch 14:0.7913371212780476\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.8556293845176697\n",
      "\n",
      "episode 2, val func loss 0.7106557488441467\n",
      "\n",
      "episode 3, val func loss 0.8107200264930725\n",
      "\n",
      "episode 4, val func loss 0.9689502120018005\n",
      "\n",
      "episode 5, val func loss 0.7185499668121338\n",
      "\n",
      "episode 6, val func loss 0.7772715091705322\n",
      "\n",
      "episode 7, val func loss 0.804348349571228\n",
      "\n",
      "episode 8, val func loss 0.8945460915565491\n",
      "\n",
      "episode 9, val func loss 0.8325905203819275\n",
      "\n",
      "episode 10, val func loss 0.78240567445755\n",
      "\n",
      "episode 11, val func loss 0.7306035757064819\n",
      "\n",
      "episode 12, val func loss 0.8789083957672119\n",
      "\n",
      "episode 13, val func loss 0.8275625109672546\n",
      "\n",
      "episode 14, val func loss 0.7848253846168518\n",
      "\n",
      "episode 15, val func loss 0.8608834743499756\n",
      "\n",
      "episode 16, val func loss 0.7789767980575562\n",
      "\n",
      "Val func train loss in epoch 15:0.8135892264544964\n",
      "***********************TIME WAS 4.828945032755533 min*****************************\n",
      "\n",
      "**********************ROUND 56 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 3.0062592029571533\n",
      "\n",
      "episode 2, policy loss 3.006258726119995\n",
      "\n",
      "episode 3, policy loss 3.0062592029571533\n",
      "\n",
      "episode 4, policy loss 3.0062592029571533\n",
      "\n",
      "episode 5, policy loss 3.006258964538574\n",
      "\n",
      "episode 6, policy loss 3.006258964538574\n",
      "\n",
      "episode 7, policy loss 3.0062592029571533\n",
      "\n",
      "episode 8, policy loss 3.0062596797943115\n",
      "\n",
      "episode 9, policy loss 3.0062592029571533\n",
      "\n",
      "episode 10, policy loss 3.006258964538574\n",
      "\n",
      "episode 11, policy loss 3.006258964538574\n",
      "\n",
      "episode 12, policy loss 3.006258964538574\n",
      "\n",
      "episode 13, policy loss 3.006258964538574\n",
      "\n",
      "episode 14, policy loss 3.006258964538574\n",
      "\n",
      "episode 15, policy loss 3.0062592029571533\n",
      "\n",
      "episode 16, policy loss 3.006258964538574\n",
      "\n",
      "Policy train loss in epoch 0:3.0062590837478638\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 3.0062592029571533\n",
      "\n",
      "episode 2, policy loss 3.0062592029571533\n",
      "\n",
      "episode 3, policy loss 3.006258964538574\n",
      "\n",
      "episode 4, policy loss 3.006258964538574\n",
      "\n",
      "episode 5, policy loss 3.0062592029571533\n",
      "\n",
      "episode 6, policy loss 3.006258964538574\n",
      "\n",
      "episode 7, policy loss 3.0062596797943115\n",
      "\n",
      "episode 8, policy loss 3.0062592029571533\n",
      "\n",
      "episode 9, policy loss 3.0062592029571533\n",
      "\n",
      "episode 10, policy loss 3.006258964538574\n",
      "\n",
      "episode 11, policy loss 3.006258964538574\n",
      "\n",
      "episode 12, policy loss 3.006258964538574\n",
      "\n",
      "episode 13, policy loss 3.006258964538574\n",
      "\n",
      "episode 14, policy loss 3.0062592029571533\n",
      "\n",
      "episode 15, policy loss 3.006258964538574\n",
      "\n",
      "episode 16, policy loss 3.006258726119995\n",
      "\n",
      "Policy train loss in epoch 1:3.0062590837478638\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 3.006258964538574\n",
      "\n",
      "episode 2, policy loss 3.006258964538574\n",
      "\n",
      "episode 3, policy loss 3.006258964538574\n",
      "\n",
      "episode 4, policy loss 3.0062592029571533\n",
      "\n",
      "episode 5, policy loss 3.006258964538574\n",
      "\n",
      "episode 6, policy loss 3.006258964538574\n",
      "\n",
      "episode 7, policy loss 3.006258726119995\n",
      "\n",
      "episode 8, policy loss 3.0062592029571533\n",
      "\n",
      "episode 9, policy loss 3.006258964538574\n",
      "\n",
      "episode 10, policy loss 3.006258964538574\n",
      "\n",
      "episode 11, policy loss 3.0062592029571533\n",
      "\n",
      "episode 12, policy loss 3.0062592029571533\n",
      "\n",
      "episode 13, policy loss 3.0062596797943115\n",
      "\n",
      "episode 14, policy loss 3.006258964538574\n",
      "\n",
      "episode 15, policy loss 3.0062592029571533\n",
      "\n",
      "episode 16, policy loss 3.0062592029571533\n",
      "\n",
      "Policy train loss in epoch 2:3.0062590837478638\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 3.006258726119995\n",
      "\n",
      "episode 2, policy loss 3.0062592029571533\n",
      "\n",
      "episode 3, policy loss 3.006258964538574\n",
      "\n",
      "episode 4, policy loss 3.006258964538574\n",
      "\n",
      "episode 5, policy loss 3.006258964538574\n",
      "\n",
      "episode 6, policy loss 3.0062592029571533\n",
      "\n",
      "episode 7, policy loss 3.006258964538574\n",
      "\n",
      "episode 8, policy loss 3.0062596797943115\n",
      "\n",
      "episode 9, policy loss 3.006258964538574\n",
      "\n",
      "episode 10, policy loss 3.006258964538574\n",
      "\n",
      "episode 11, policy loss 3.0062592029571533\n",
      "\n",
      "episode 12, policy loss 3.0062592029571533\n",
      "\n",
      "episode 13, policy loss 3.006258964538574\n",
      "\n",
      "episode 14, policy loss 3.0062592029571533\n",
      "\n",
      "episode 15, policy loss 3.0062592029571533\n",
      "\n",
      "episode 16, policy loss 3.006258964538574\n",
      "\n",
      "Policy train loss in epoch 3:3.0062590837478638\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.9403164386749268\n",
      "\n",
      "episode 2, val func loss 0.9882888793945312\n",
      "\n",
      "episode 3, val func loss 0.8740369081497192\n",
      "\n",
      "episode 4, val func loss 0.8075944781303406\n",
      "\n",
      "episode 5, val func loss 0.7140499949455261\n",
      "\n",
      "episode 6, val func loss 0.8514789938926697\n",
      "\n",
      "episode 7, val func loss 0.780635416507721\n",
      "\n",
      "episode 8, val func loss 0.8305352330207825\n",
      "\n",
      "episode 9, val func loss 0.8814582228660583\n",
      "\n",
      "episode 10, val func loss 0.7986639142036438\n",
      "\n",
      "episode 11, val func loss 0.7710448503494263\n",
      "\n",
      "episode 12, val func loss 0.8016320466995239\n",
      "\n",
      "episode 13, val func loss 0.7289133667945862\n",
      "\n",
      "episode 14, val func loss 0.7340771555900574\n",
      "\n",
      "episode 15, val func loss 0.8071193695068359\n",
      "\n",
      "episode 16, val func loss 0.8797176480293274\n",
      "\n",
      "Val func train loss in epoch 0:0.8243476822972298\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.9073082804679871\n",
      "\n",
      "episode 2, val func loss 0.8644834160804749\n",
      "\n",
      "episode 3, val func loss 0.7754179835319519\n",
      "\n",
      "episode 4, val func loss 0.6802581548690796\n",
      "\n",
      "episode 5, val func loss 0.8734422922134399\n",
      "\n",
      "episode 6, val func loss 0.7549110054969788\n",
      "\n",
      "episode 7, val func loss 0.8795240521430969\n",
      "\n",
      "episode 8, val func loss 0.7762605547904968\n",
      "\n",
      "episode 9, val func loss 0.9531949162483215\n",
      "\n",
      "episode 10, val func loss 0.6835222244262695\n",
      "\n",
      "episode 11, val func loss 0.7711189985275269\n",
      "\n",
      "episode 12, val func loss 0.849214494228363\n",
      "\n",
      "episode 13, val func loss 0.8212202191352844\n",
      "\n",
      "episode 14, val func loss 0.7851004004478455\n",
      "\n",
      "episode 15, val func loss 0.9080960154533386\n",
      "\n",
      "episode 16, val func loss 0.8213504552841187\n",
      "\n",
      "Val func train loss in epoch 1:0.8190264664590359\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.8485270142555237\n",
      "\n",
      "episode 2, val func loss 0.9886364340782166\n",
      "\n",
      "episode 3, val func loss 0.7916348576545715\n",
      "\n",
      "episode 4, val func loss 0.9141302704811096\n",
      "\n",
      "episode 5, val func loss 0.8925880193710327\n",
      "\n",
      "episode 6, val func loss 0.8093820810317993\n",
      "\n",
      "episode 7, val func loss 0.7677839398384094\n",
      "\n",
      "episode 8, val func loss 0.8098103404045105\n",
      "\n",
      "episode 9, val func loss 0.7951008677482605\n",
      "\n",
      "episode 10, val func loss 0.7643766403198242\n",
      "\n",
      "episode 11, val func loss 0.7678557634353638\n",
      "\n",
      "episode 12, val func loss 0.8072070479393005\n",
      "\n",
      "episode 13, val func loss 0.7397839426994324\n",
      "\n",
      "episode 14, val func loss 0.8309213519096375\n",
      "\n",
      "episode 15, val func loss 0.7452328205108643\n",
      "\n",
      "episode 16, val func loss 0.8708715438842773\n",
      "\n",
      "Val func train loss in epoch 2:0.8214901834726334\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.7024240493774414\n",
      "\n",
      "episode 2, val func loss 0.8528249263763428\n",
      "\n",
      "episode 3, val func loss 0.8268356323242188\n",
      "\n",
      "episode 4, val func loss 0.7512189149856567\n",
      "\n",
      "episode 5, val func loss 0.7294665575027466\n",
      "\n",
      "episode 6, val func loss 0.8046717047691345\n",
      "\n",
      "episode 7, val func loss 0.7436121106147766\n",
      "\n",
      "episode 8, val func loss 0.8087838292121887\n",
      "\n",
      "episode 9, val func loss 0.7147659659385681\n",
      "\n",
      "episode 10, val func loss 0.6957738995552063\n",
      "\n",
      "episode 11, val func loss 0.7666817903518677\n",
      "\n",
      "episode 12, val func loss 0.8265162110328674\n",
      "\n",
      "episode 13, val func loss 0.7112789154052734\n",
      "\n",
      "episode 14, val func loss 0.9089274406433105\n",
      "\n",
      "episode 15, val func loss 0.715587317943573\n",
      "\n",
      "episode 16, val func loss 0.8808265328407288\n",
      "\n",
      "Val func train loss in epoch 3:0.7775122374296188\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7769963145256042\n",
      "\n",
      "episode 2, val func loss 0.8893468976020813\n",
      "\n",
      "episode 3, val func loss 0.7802743911743164\n",
      "\n",
      "episode 4, val func loss 0.7084509134292603\n",
      "\n",
      "episode 5, val func loss 0.7297208309173584\n",
      "\n",
      "episode 6, val func loss 0.8175931572914124\n",
      "\n",
      "episode 7, val func loss 0.7100861072540283\n",
      "\n",
      "episode 8, val func loss 0.7844488024711609\n",
      "\n",
      "episode 9, val func loss 0.8046182990074158\n",
      "\n",
      "episode 10, val func loss 0.7808950543403625\n",
      "\n",
      "episode 11, val func loss 0.8545737266540527\n",
      "\n",
      "episode 12, val func loss 0.7043347954750061\n",
      "\n",
      "episode 13, val func loss 0.8004993796348572\n",
      "\n",
      "episode 14, val func loss 0.7850985527038574\n",
      "\n",
      "episode 15, val func loss 0.8785992860794067\n",
      "\n",
      "episode 16, val func loss 0.7702895402908325\n",
      "\n",
      "Val func train loss in epoch 4:0.7859891280531883\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.9320953488349915\n",
      "\n",
      "episode 2, val func loss 0.7724977731704712\n",
      "\n",
      "episode 3, val func loss 0.8968465924263\n",
      "\n",
      "episode 4, val func loss 0.8701247572898865\n",
      "\n",
      "episode 5, val func loss 0.8943610191345215\n",
      "\n",
      "episode 6, val func loss 0.8019197583198547\n",
      "\n",
      "episode 7, val func loss 0.780552089214325\n",
      "\n",
      "episode 8, val func loss 0.8844360113143921\n",
      "\n",
      "episode 9, val func loss 0.7387385964393616\n",
      "\n",
      "episode 10, val func loss 0.8189567923545837\n",
      "\n",
      "episode 11, val func loss 0.8354678750038147\n",
      "\n",
      "episode 12, val func loss 0.8146696090698242\n",
      "\n",
      "episode 13, val func loss 0.9420239329338074\n",
      "\n",
      "episode 14, val func loss 0.8595032095909119\n",
      "\n",
      "episode 15, val func loss 0.7033228874206543\n",
      "\n",
      "episode 16, val func loss 0.7831587791442871\n",
      "\n",
      "Val func train loss in epoch 5:0.8330421894788742\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.9551221132278442\n",
      "\n",
      "episode 2, val func loss 0.8070600628852844\n",
      "\n",
      "episode 3, val func loss 0.793665885925293\n",
      "\n",
      "episode 4, val func loss 0.9381223320960999\n",
      "\n",
      "episode 5, val func loss 0.8119818568229675\n",
      "\n",
      "episode 6, val func loss 0.8104404211044312\n",
      "\n",
      "episode 7, val func loss 0.8043885827064514\n",
      "\n",
      "episode 8, val func loss 0.8168417811393738\n",
      "\n",
      "episode 9, val func loss 0.8569526672363281\n",
      "\n",
      "episode 10, val func loss 0.7804421186447144\n",
      "\n",
      "episode 11, val func loss 0.8557112216949463\n",
      "\n",
      "episode 12, val func loss 0.7760356664657593\n",
      "\n",
      "episode 13, val func loss 0.7353373169898987\n",
      "\n",
      "episode 14, val func loss 0.7380203008651733\n",
      "\n",
      "episode 15, val func loss 0.8093388676643372\n",
      "\n",
      "episode 16, val func loss 0.7689490914344788\n",
      "\n",
      "Val func train loss in epoch 6:0.8161506429314613\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.8407647013664246\n",
      "\n",
      "episode 2, val func loss 0.6854468584060669\n",
      "\n",
      "episode 3, val func loss 0.691857635974884\n",
      "\n",
      "episode 4, val func loss 0.8435551524162292\n",
      "\n",
      "episode 5, val func loss 0.7626978158950806\n",
      "\n",
      "episode 6, val func loss 0.7661916613578796\n",
      "\n",
      "episode 7, val func loss 0.87303227186203\n",
      "\n",
      "episode 8, val func loss 0.9323141574859619\n",
      "\n",
      "episode 9, val func loss 0.7387005686759949\n",
      "\n",
      "episode 10, val func loss 0.8115372061729431\n",
      "\n",
      "episode 11, val func loss 0.7630011439323425\n",
      "\n",
      "episode 12, val func loss 0.7590667009353638\n",
      "\n",
      "episode 13, val func loss 0.7331708669662476\n",
      "\n",
      "episode 14, val func loss 0.7874947786331177\n",
      "\n",
      "episode 15, val func loss 0.8075145483016968\n",
      "\n",
      "episode 16, val func loss 0.7919921875\n",
      "\n",
      "Val func train loss in epoch 7:0.7867711409926414\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7492753267288208\n",
      "\n",
      "episode 2, val func loss 0.8863064646720886\n",
      "\n",
      "episode 3, val func loss 0.6895928978919983\n",
      "\n",
      "episode 4, val func loss 0.6929354667663574\n",
      "\n",
      "episode 5, val func loss 0.7595143914222717\n",
      "\n",
      "episode 6, val func loss 0.7480806112289429\n",
      "\n",
      "episode 7, val func loss 0.8350481390953064\n",
      "\n",
      "episode 8, val func loss 0.9191101789474487\n",
      "\n",
      "episode 9, val func loss 0.7702177166938782\n",
      "\n",
      "episode 10, val func loss 0.8481306433677673\n",
      "\n",
      "episode 11, val func loss 0.7950358390808105\n",
      "\n",
      "episode 12, val func loss 0.835012674331665\n",
      "\n",
      "episode 13, val func loss 0.9323774576187134\n",
      "\n",
      "episode 14, val func loss 0.8264132738113403\n",
      "\n",
      "episode 15, val func loss 0.922664999961853\n",
      "\n",
      "episode 16, val func loss 0.7208386659622192\n",
      "\n",
      "Val func train loss in epoch 8:0.8081596717238426\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8027372360229492\n",
      "\n",
      "episode 2, val func loss 0.7619601488113403\n",
      "\n",
      "episode 3, val func loss 0.7886335253715515\n",
      "\n",
      "episode 4, val func loss 0.8132599592208862\n",
      "\n",
      "episode 5, val func loss 0.8338854312896729\n",
      "\n",
      "episode 6, val func loss 0.7507047653198242\n",
      "\n",
      "episode 7, val func loss 0.7552312612533569\n",
      "\n",
      "episode 8, val func loss 0.8707695007324219\n",
      "\n",
      "episode 9, val func loss 0.7921731472015381\n",
      "\n",
      "episode 10, val func loss 0.7977936863899231\n",
      "\n",
      "episode 11, val func loss 0.6880441308021545\n",
      "\n",
      "episode 12, val func loss 0.70743727684021\n",
      "\n",
      "episode 13, val func loss 0.7094292044639587\n",
      "\n",
      "episode 14, val func loss 0.7864336371421814\n",
      "\n",
      "episode 15, val func loss 0.9679069519042969\n",
      "\n",
      "episode 16, val func loss 0.7101227641105652\n",
      "\n",
      "Val func train loss in epoch 9:0.7835326641798019\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.8228138089179993\n",
      "\n",
      "episode 2, val func loss 0.9179500341415405\n",
      "\n",
      "episode 3, val func loss 0.8845534920692444\n",
      "\n",
      "episode 4, val func loss 0.8027172088623047\n",
      "\n",
      "episode 5, val func loss 0.7700233459472656\n",
      "\n",
      "episode 6, val func loss 0.8433606028556824\n",
      "\n",
      "episode 7, val func loss 0.8261644840240479\n",
      "\n",
      "episode 8, val func loss 0.785207211971283\n",
      "\n",
      "episode 9, val func loss 0.7583652138710022\n",
      "\n",
      "episode 10, val func loss 0.7224469780921936\n",
      "\n",
      "episode 11, val func loss 0.7159359455108643\n",
      "\n",
      "episode 12, val func loss 0.92564857006073\n",
      "\n",
      "episode 13, val func loss 0.8201579451560974\n",
      "\n",
      "episode 14, val func loss 0.7975313067436218\n",
      "\n",
      "episode 15, val func loss 0.8034606575965881\n",
      "\n",
      "episode 16, val func loss 0.7614372968673706\n",
      "\n",
      "Val func train loss in epoch 10:0.8098608814179897\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7420942783355713\n",
      "\n",
      "episode 2, val func loss 0.7220093607902527\n",
      "\n",
      "episode 3, val func loss 0.7139020562171936\n",
      "\n",
      "episode 4, val func loss 0.8181315064430237\n",
      "\n",
      "episode 5, val func loss 0.7717180848121643\n",
      "\n",
      "episode 6, val func loss 0.8283557295799255\n",
      "\n",
      "episode 7, val func loss 0.8043517470359802\n",
      "\n",
      "episode 8, val func loss 0.9030309319496155\n",
      "\n",
      "episode 9, val func loss 0.7601165175437927\n",
      "\n",
      "episode 10, val func loss 1.0255458354949951\n",
      "\n",
      "episode 11, val func loss 0.7719823122024536\n",
      "\n",
      "episode 12, val func loss 0.9174789786338806\n",
      "\n",
      "episode 13, val func loss 0.7522740960121155\n",
      "\n",
      "episode 14, val func loss 0.9079906940460205\n",
      "\n",
      "episode 15, val func loss 0.7556009888648987\n",
      "\n",
      "episode 16, val func loss 0.9402527213096619\n",
      "\n",
      "Val func train loss in epoch 11:0.8209272399544716\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.0737884044647217\n",
      "\n",
      "episode 2, val func loss 0.8288243412971497\n",
      "\n",
      "episode 3, val func loss 1.1442515850067139\n",
      "\n",
      "episode 4, val func loss 0.8290057182312012\n",
      "\n",
      "episode 5, val func loss 1.0707107782363892\n",
      "\n",
      "episode 6, val func loss 0.832150936126709\n",
      "\n",
      "episode 7, val func loss 0.916779100894928\n",
      "\n",
      "episode 8, val func loss 1.0002952814102173\n",
      "\n",
      "episode 9, val func loss 0.754990816116333\n",
      "\n",
      "episode 10, val func loss 0.9418330192565918\n",
      "\n",
      "episode 11, val func loss 0.7733802795410156\n",
      "\n",
      "episode 12, val func loss 0.91376131772995\n",
      "\n",
      "episode 13, val func loss 0.930414617061615\n",
      "\n",
      "episode 14, val func loss 0.7667818665504456\n",
      "\n",
      "episode 15, val func loss 0.7225423455238342\n",
      "\n",
      "episode 16, val func loss 0.8785029053688049\n",
      "\n",
      "Val func train loss in epoch 12:0.8986258320510387\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6917967796325684\n",
      "\n",
      "episode 2, val func loss 0.8720757961273193\n",
      "\n",
      "episode 3, val func loss 0.8073647022247314\n",
      "\n",
      "episode 4, val func loss 0.8282430768013\n",
      "\n",
      "episode 5, val func loss 0.9007840752601624\n",
      "\n",
      "episode 6, val func loss 0.7775759696960449\n",
      "\n",
      "episode 7, val func loss 0.8587026596069336\n",
      "\n",
      "episode 8, val func loss 0.8056400418281555\n",
      "\n",
      "episode 9, val func loss 0.790258526802063\n",
      "\n",
      "episode 10, val func loss 0.8813579678535461\n",
      "\n",
      "episode 11, val func loss 0.7883622646331787\n",
      "\n",
      "episode 12, val func loss 0.7957367300987244\n",
      "\n",
      "episode 13, val func loss 0.8659754991531372\n",
      "\n",
      "episode 14, val func loss 0.7160395979881287\n",
      "\n",
      "episode 15, val func loss 0.7757192254066467\n",
      "\n",
      "episode 16, val func loss 0.8629103899002075\n",
      "\n",
      "Val func train loss in epoch 13:0.813658956438303\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6540567874908447\n",
      "\n",
      "episode 2, val func loss 0.8179683685302734\n",
      "\n",
      "episode 3, val func loss 0.8061913251876831\n",
      "\n",
      "episode 4, val func loss 0.8227218389511108\n",
      "\n",
      "episode 5, val func loss 0.8333548903465271\n",
      "\n",
      "episode 6, val func loss 0.712627112865448\n",
      "\n",
      "episode 7, val func loss 0.7863995432853699\n",
      "\n",
      "episode 8, val func loss 0.8639494180679321\n",
      "\n",
      "episode 9, val func loss 0.8065786957740784\n",
      "\n",
      "episode 10, val func loss 0.8384028077125549\n",
      "\n",
      "episode 11, val func loss 0.7689192295074463\n",
      "\n",
      "episode 12, val func loss 0.7914767861366272\n",
      "\n",
      "episode 13, val func loss 0.7403983473777771\n",
      "\n",
      "episode 14, val func loss 0.8581758141517639\n",
      "\n",
      "episode 15, val func loss 0.755652129650116\n",
      "\n",
      "episode 16, val func loss 0.7461551427841187\n",
      "\n",
      "Val func train loss in epoch 14:0.7876892648637295\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7580302953720093\n",
      "\n",
      "episode 2, val func loss 0.8132867813110352\n",
      "\n",
      "episode 3, val func loss 0.7882634997367859\n",
      "\n",
      "episode 4, val func loss 0.9304129481315613\n",
      "\n",
      "episode 5, val func loss 0.7480655312538147\n",
      "\n",
      "episode 6, val func loss 0.7500882744789124\n",
      "\n",
      "episode 7, val func loss 0.8024666905403137\n",
      "\n",
      "episode 8, val func loss 0.924357533454895\n",
      "\n",
      "episode 9, val func loss 0.7685245275497437\n",
      "\n",
      "episode 10, val func loss 0.7958966493606567\n",
      "\n",
      "episode 11, val func loss 0.6432877779006958\n",
      "\n",
      "episode 12, val func loss 0.8920435309410095\n",
      "\n",
      "episode 13, val func loss 0.9553908109664917\n",
      "\n",
      "episode 14, val func loss 0.8547331094741821\n",
      "\n",
      "episode 15, val func loss 0.6989721059799194\n",
      "\n",
      "episode 16, val func loss 0.908187210559845\n",
      "\n",
      "Val func train loss in epoch 15:0.814500454813242\n",
      "***********************TIME WAS 4.842895778020223 min*****************************\n",
      "\n",
      "**********************ROUND 57 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 2.714548349380493\n",
      "\n",
      "episode 2, policy loss 2.714547634124756\n",
      "\n",
      "episode 3, policy loss 2.7145473957061768\n",
      "\n",
      "episode 4, policy loss 2.7145466804504395\n",
      "\n",
      "episode 5, policy loss 2.7145485877990723\n",
      "\n",
      "episode 6, policy loss 2.7145473957061768\n",
      "\n",
      "episode 7, policy loss 2.714548349380493\n",
      "\n",
      "episode 8, policy loss 2.714548110961914\n",
      "\n",
      "episode 9, policy loss 2.714548349380493\n",
      "\n",
      "episode 10, policy loss 2.714548349380493\n",
      "\n",
      "episode 11, policy loss 2.714550018310547\n",
      "\n",
      "episode 12, policy loss 2.714548349380493\n",
      "\n",
      "episode 13, policy loss 2.714548349380493\n",
      "\n",
      "episode 14, policy loss 2.714547872543335\n",
      "\n",
      "episode 15, policy loss 2.7145473957061768\n",
      "\n",
      "episode 16, policy loss 2.714548110961914\n",
      "\n",
      "Policy train loss in epoch 0:2.7145480811595917\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 2.714548349380493\n",
      "\n",
      "episode 2, policy loss 2.7145473957061768\n",
      "\n",
      "episode 3, policy loss 2.714548110961914\n",
      "\n",
      "episode 4, policy loss 2.714547634124756\n",
      "\n",
      "episode 5, policy loss 2.714550018310547\n",
      "\n",
      "episode 6, policy loss 2.714548349380493\n",
      "\n",
      "episode 7, policy loss 2.714548349380493\n",
      "\n",
      "episode 8, policy loss 2.714548110961914\n",
      "\n",
      "episode 9, policy loss 2.714548349380493\n",
      "\n",
      "episode 10, policy loss 2.714548349380493\n",
      "\n",
      "episode 11, policy loss 2.714547872543335\n",
      "\n",
      "episode 12, policy loss 2.7145466804504395\n",
      "\n",
      "episode 13, policy loss 2.7145485877990723\n",
      "\n",
      "episode 14, policy loss 2.714548349380493\n",
      "\n",
      "episode 15, policy loss 2.7145473957061768\n",
      "\n",
      "episode 16, policy loss 2.7145473957061768\n",
      "\n",
      "Policy train loss in epoch 1:2.7145480811595917\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 2.714548110961914\n",
      "\n",
      "episode 2, policy loss 2.714550018310547\n",
      "\n",
      "episode 3, policy loss 2.7145466804504395\n",
      "\n",
      "episode 4, policy loss 2.714548349380493\n",
      "\n",
      "episode 5, policy loss 2.714547634124756\n",
      "\n",
      "episode 6, policy loss 2.714548349380493\n",
      "\n",
      "episode 7, policy loss 2.7145473957061768\n",
      "\n",
      "episode 8, policy loss 2.714548349380493\n",
      "\n",
      "episode 9, policy loss 2.714548349380493\n",
      "\n",
      "episode 10, policy loss 2.714548349380493\n",
      "\n",
      "episode 11, policy loss 2.7145485877990723\n",
      "\n",
      "episode 12, policy loss 2.7145473957061768\n",
      "\n",
      "episode 13, policy loss 2.714548110961914\n",
      "\n",
      "episode 14, policy loss 2.714548349380493\n",
      "\n",
      "episode 15, policy loss 2.714547872543335\n",
      "\n",
      "episode 16, policy loss 2.7145473957061768\n",
      "\n",
      "Policy train loss in epoch 2:2.7145480811595917\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 2.714548349380493\n",
      "\n",
      "episode 2, policy loss 2.7145473957061768\n",
      "\n",
      "episode 3, policy loss 2.714550018310547\n",
      "\n",
      "episode 4, policy loss 2.714547872543335\n",
      "\n",
      "episode 5, policy loss 2.714548349380493\n",
      "\n",
      "episode 6, policy loss 2.7145473957061768\n",
      "\n",
      "episode 7, policy loss 2.714548349380493\n",
      "\n",
      "episode 8, policy loss 2.7145473957061768\n",
      "\n",
      "episode 9, policy loss 2.714548110961914\n",
      "\n",
      "episode 10, policy loss 2.714548349380493\n",
      "\n",
      "episode 11, policy loss 2.714548349380493\n",
      "\n",
      "episode 12, policy loss 2.714548349380493\n",
      "\n",
      "episode 13, policy loss 2.7145485877990723\n",
      "\n",
      "episode 14, policy loss 2.7145466804504395\n",
      "\n",
      "episode 15, policy loss 2.714548110961914\n",
      "\n",
      "episode 16, policy loss 2.714547634124756\n",
      "\n",
      "Policy train loss in epoch 3:2.7145480811595917\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.8376380205154419\n",
      "\n",
      "episode 2, val func loss 0.8955395221710205\n",
      "\n",
      "episode 3, val func loss 0.7804812788963318\n",
      "\n",
      "episode 4, val func loss 0.8474913835525513\n",
      "\n",
      "episode 5, val func loss 0.8023721575737\n",
      "\n",
      "episode 6, val func loss 0.7775053381919861\n",
      "\n",
      "episode 7, val func loss 0.8687374591827393\n",
      "\n",
      "episode 8, val func loss 0.7087222337722778\n",
      "\n",
      "episode 9, val func loss 0.7612485885620117\n",
      "\n",
      "episode 10, val func loss 0.7920241355895996\n",
      "\n",
      "episode 11, val func loss 0.7693559527397156\n",
      "\n",
      "episode 12, val func loss 0.7583280205726624\n",
      "\n",
      "episode 13, val func loss 0.8114320039749146\n",
      "\n",
      "episode 14, val func loss 0.7743044495582581\n",
      "\n",
      "episode 15, val func loss 0.786408007144928\n",
      "\n",
      "episode 16, val func loss 0.7731553912162781\n",
      "\n",
      "Val func train loss in epoch 0:0.796546496450901\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8479167222976685\n",
      "\n",
      "episode 2, val func loss 0.7952522039413452\n",
      "\n",
      "episode 3, val func loss 0.7624462842941284\n",
      "\n",
      "episode 4, val func loss 0.75020831823349\n",
      "\n",
      "episode 5, val func loss 0.6835412979125977\n",
      "\n",
      "episode 6, val func loss 0.7744606733322144\n",
      "\n",
      "episode 7, val func loss 0.820225179195404\n",
      "\n",
      "episode 8, val func loss 0.80812668800354\n",
      "\n",
      "episode 9, val func loss 0.830251932144165\n",
      "\n",
      "episode 10, val func loss 0.8554913997650146\n",
      "\n",
      "episode 11, val func loss 0.8556337952613831\n",
      "\n",
      "episode 12, val func loss 0.7750914096832275\n",
      "\n",
      "episode 13, val func loss 0.769818127155304\n",
      "\n",
      "episode 14, val func loss 0.8909245729446411\n",
      "\n",
      "episode 15, val func loss 0.7715902328491211\n",
      "\n",
      "episode 16, val func loss 0.8037914037704468\n",
      "\n",
      "Val func train loss in epoch 1:0.7996731400489807\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7349475622177124\n",
      "\n",
      "episode 2, val func loss 0.8423956036567688\n",
      "\n",
      "episode 3, val func loss 0.8155397772789001\n",
      "\n",
      "episode 4, val func loss 0.7407323718070984\n",
      "\n",
      "episode 5, val func loss 0.8127699494361877\n",
      "\n",
      "episode 6, val func loss 0.7476952075958252\n",
      "\n",
      "episode 7, val func loss 0.8162307739257812\n",
      "\n",
      "episode 8, val func loss 0.7515678405761719\n",
      "\n",
      "episode 9, val func loss 0.7942225337028503\n",
      "\n",
      "episode 10, val func loss 0.8385893702507019\n",
      "\n",
      "episode 11, val func loss 0.8710119724273682\n",
      "\n",
      "episode 12, val func loss 0.730252742767334\n",
      "\n",
      "episode 13, val func loss 0.8125088810920715\n",
      "\n",
      "episode 14, val func loss 0.7961397767066956\n",
      "\n",
      "episode 15, val func loss 0.6854634284973145\n",
      "\n",
      "episode 16, val func loss 0.8707761764526367\n",
      "\n",
      "Val func train loss in epoch 2:0.7913027480244637\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6671819090843201\n",
      "\n",
      "episode 2, val func loss 0.9081197381019592\n",
      "\n",
      "episode 3, val func loss 0.7130345106124878\n",
      "\n",
      "episode 4, val func loss 0.8617336750030518\n",
      "\n",
      "episode 5, val func loss 0.8168050050735474\n",
      "\n",
      "episode 6, val func loss 0.7789706587791443\n",
      "\n",
      "episode 7, val func loss 0.8219900131225586\n",
      "\n",
      "episode 8, val func loss 0.654852032661438\n",
      "\n",
      "episode 9, val func loss 0.7972581386566162\n",
      "\n",
      "episode 10, val func loss 0.7718126773834229\n",
      "\n",
      "episode 11, val func loss 0.7378413081169128\n",
      "\n",
      "episode 12, val func loss 0.8001176714897156\n",
      "\n",
      "episode 13, val func loss 0.7536411285400391\n",
      "\n",
      "episode 14, val func loss 0.8594967722892761\n",
      "\n",
      "episode 15, val func loss 0.8382046222686768\n",
      "\n",
      "episode 16, val func loss 0.8898191452026367\n",
      "\n",
      "Val func train loss in epoch 3:0.7919299378991127\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6079084873199463\n",
      "\n",
      "episode 2, val func loss 0.7660452723503113\n",
      "\n",
      "episode 3, val func loss 0.8223164081573486\n",
      "\n",
      "episode 4, val func loss 0.7993870973587036\n",
      "\n",
      "episode 5, val func loss 0.7901037335395813\n",
      "\n",
      "episode 6, val func loss 0.8794373273849487\n",
      "\n",
      "episode 7, val func loss 0.7522114515304565\n",
      "\n",
      "episode 8, val func loss 0.8075344562530518\n",
      "\n",
      "episode 9, val func loss 0.7369551658630371\n",
      "\n",
      "episode 10, val func loss 0.8176392316818237\n",
      "\n",
      "episode 11, val func loss 0.7405219674110413\n",
      "\n",
      "episode 12, val func loss 0.7113422751426697\n",
      "\n",
      "episode 13, val func loss 0.8088307976722717\n",
      "\n",
      "episode 14, val func loss 0.6728441715240479\n",
      "\n",
      "episode 15, val func loss 0.8722013831138611\n",
      "\n",
      "episode 16, val func loss 0.7699150443077087\n",
      "\n",
      "Val func train loss in epoch 4:0.7721996419131756\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6991799473762512\n",
      "\n",
      "episode 2, val func loss 0.7757730484008789\n",
      "\n",
      "episode 3, val func loss 0.7038815021514893\n",
      "\n",
      "episode 4, val func loss 0.8224490880966187\n",
      "\n",
      "episode 5, val func loss 0.7952306866645813\n",
      "\n",
      "episode 6, val func loss 0.8949099183082581\n",
      "\n",
      "episode 7, val func loss 0.8726481795310974\n",
      "\n",
      "episode 8, val func loss 0.6959936618804932\n",
      "\n",
      "episode 9, val func loss 0.7470806837081909\n",
      "\n",
      "episode 10, val func loss 0.9270762205123901\n",
      "\n",
      "episode 11, val func loss 0.6966195702552795\n",
      "\n",
      "episode 12, val func loss 0.9300671815872192\n",
      "\n",
      "episode 13, val func loss 0.9012690186500549\n",
      "\n",
      "episode 14, val func loss 0.6779203414916992\n",
      "\n",
      "episode 15, val func loss 0.8300850987434387\n",
      "\n",
      "episode 16, val func loss 0.9712491631507874\n",
      "\n",
      "Val func train loss in epoch 5:0.8088395819067955\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6258271336555481\n",
      "\n",
      "episode 2, val func loss 0.8704219460487366\n",
      "\n",
      "episode 3, val func loss 0.8507179617881775\n",
      "\n",
      "episode 4, val func loss 0.826411247253418\n",
      "\n",
      "episode 5, val func loss 0.8518046736717224\n",
      "\n",
      "episode 6, val func loss 0.8609904646873474\n",
      "\n",
      "episode 7, val func loss 0.72266685962677\n",
      "\n",
      "episode 8, val func loss 0.8685170412063599\n",
      "\n",
      "episode 9, val func loss 0.8005399703979492\n",
      "\n",
      "episode 10, val func loss 0.7670560479164124\n",
      "\n",
      "episode 11, val func loss 0.785599410533905\n",
      "\n",
      "episode 12, val func loss 0.7220067977905273\n",
      "\n",
      "episode 13, val func loss 0.8689665198326111\n",
      "\n",
      "episode 14, val func loss 0.7748957276344299\n",
      "\n",
      "episode 15, val func loss 0.7590978145599365\n",
      "\n",
      "episode 16, val func loss 0.8776806592941284\n",
      "\n",
      "Val func train loss in epoch 6:0.8020750172436237\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7768539786338806\n",
      "\n",
      "episode 2, val func loss 0.7436415553092957\n",
      "\n",
      "episode 3, val func loss 0.7673490643501282\n",
      "\n",
      "episode 4, val func loss 0.8921767473220825\n",
      "\n",
      "episode 5, val func loss 0.7174017429351807\n",
      "\n",
      "episode 6, val func loss 0.7132551670074463\n",
      "\n",
      "episode 7, val func loss 0.7411916851997375\n",
      "\n",
      "episode 8, val func loss 0.944412887096405\n",
      "\n",
      "episode 9, val func loss 0.8275576829910278\n",
      "\n",
      "episode 10, val func loss 0.8620357513427734\n",
      "\n",
      "episode 11, val func loss 0.9992647767066956\n",
      "\n",
      "episode 12, val func loss 0.75925612449646\n",
      "\n",
      "episode 13, val func loss 0.8124882578849792\n",
      "\n",
      "episode 14, val func loss 0.9063578248023987\n",
      "\n",
      "episode 15, val func loss 0.844202995300293\n",
      "\n",
      "episode 16, val func loss 0.7488955855369568\n",
      "\n",
      "Val func train loss in epoch 7:0.8160213641822338\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8032050132751465\n",
      "\n",
      "episode 2, val func loss 0.812358021736145\n",
      "\n",
      "episode 3, val func loss 0.9137713313102722\n",
      "\n",
      "episode 4, val func loss 0.812629222869873\n",
      "\n",
      "episode 5, val func loss 0.8301068544387817\n",
      "\n",
      "episode 6, val func loss 0.7305651307106018\n",
      "\n",
      "episode 7, val func loss 0.8556402325630188\n",
      "\n",
      "episode 8, val func loss 0.724712073802948\n",
      "\n",
      "episode 9, val func loss 0.794882595539093\n",
      "\n",
      "episode 10, val func loss 0.7826546430587769\n",
      "\n",
      "episode 11, val func loss 0.7299924492835999\n",
      "\n",
      "episode 12, val func loss 0.6595302224159241\n",
      "\n",
      "episode 13, val func loss 0.8236421942710876\n",
      "\n",
      "episode 14, val func loss 0.7640954852104187\n",
      "\n",
      "episode 15, val func loss 0.8798480033874512\n",
      "\n",
      "episode 16, val func loss 0.8291640877723694\n",
      "\n",
      "Val func train loss in epoch 8:0.7966748476028442\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.76584792137146\n",
      "\n",
      "episode 2, val func loss 0.7662039399147034\n",
      "\n",
      "episode 3, val func loss 0.774516761302948\n",
      "\n",
      "episode 4, val func loss 0.8496784567832947\n",
      "\n",
      "episode 5, val func loss 0.6980879306793213\n",
      "\n",
      "episode 6, val func loss 0.7925863265991211\n",
      "\n",
      "episode 7, val func loss 0.772986114025116\n",
      "\n",
      "episode 8, val func loss 0.7099214196205139\n",
      "\n",
      "episode 9, val func loss 0.899017870426178\n",
      "\n",
      "episode 10, val func loss 0.7491404414176941\n",
      "\n",
      "episode 11, val func loss 0.776296854019165\n",
      "\n",
      "episode 12, val func loss 0.8273507952690125\n",
      "\n",
      "episode 13, val func loss 0.7688812613487244\n",
      "\n",
      "episode 14, val func loss 0.7853242754936218\n",
      "\n",
      "episode 15, val func loss 0.7101914882659912\n",
      "\n",
      "episode 16, val func loss 0.7770716547966003\n",
      "\n",
      "Val func train loss in epoch 9:0.7764439694583416\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.8459376692771912\n",
      "\n",
      "episode 2, val func loss 0.8149465918540955\n",
      "\n",
      "episode 3, val func loss 0.8517858982086182\n",
      "\n",
      "episode 4, val func loss 0.7533353567123413\n",
      "\n",
      "episode 5, val func loss 0.8177265524864197\n",
      "\n",
      "episode 6, val func loss 0.6914359927177429\n",
      "\n",
      "episode 7, val func loss 0.7638213038444519\n",
      "\n",
      "episode 8, val func loss 0.7297688722610474\n",
      "\n",
      "episode 9, val func loss 0.7902157306671143\n",
      "\n",
      "episode 10, val func loss 0.8103223443031311\n",
      "\n",
      "episode 11, val func loss 0.8455134034156799\n",
      "\n",
      "episode 12, val func loss 0.8436045050621033\n",
      "\n",
      "episode 13, val func loss 0.8649904727935791\n",
      "\n",
      "episode 14, val func loss 0.7012542486190796\n",
      "\n",
      "episode 15, val func loss 0.7293859124183655\n",
      "\n",
      "episode 16, val func loss 0.7328088879585266\n",
      "\n",
      "Val func train loss in epoch 10:0.786678358912468\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.8227299451828003\n",
      "\n",
      "episode 2, val func loss 0.6520440578460693\n",
      "\n",
      "episode 3, val func loss 0.8278833031654358\n",
      "\n",
      "episode 4, val func loss 0.7324525713920593\n",
      "\n",
      "episode 5, val func loss 0.7750884294509888\n",
      "\n",
      "episode 6, val func loss 0.695567786693573\n",
      "\n",
      "episode 7, val func loss 0.7494469881057739\n",
      "\n",
      "episode 8, val func loss 0.7929377555847168\n",
      "\n",
      "episode 9, val func loss 0.78116375207901\n",
      "\n",
      "episode 10, val func loss 0.7487849593162537\n",
      "\n",
      "episode 11, val func loss 0.7311205863952637\n",
      "\n",
      "episode 12, val func loss 0.8517676591873169\n",
      "\n",
      "episode 13, val func loss 0.8598030209541321\n",
      "\n",
      "episode 14, val func loss 0.9063917398452759\n",
      "\n",
      "episode 15, val func loss 0.8632875084877014\n",
      "\n",
      "episode 16, val func loss 0.639566957950592\n",
      "\n",
      "Val func train loss in epoch 11:0.7768773138523102\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.9041361808776855\n",
      "\n",
      "episode 2, val func loss 0.9582891464233398\n",
      "\n",
      "episode 3, val func loss 0.9081895351409912\n",
      "\n",
      "episode 4, val func loss 0.9646686315536499\n",
      "\n",
      "episode 5, val func loss 0.8780396580696106\n",
      "\n",
      "episode 6, val func loss 0.8058132529258728\n",
      "\n",
      "episode 7, val func loss 0.8348705768585205\n",
      "\n",
      "episode 8, val func loss 0.8432806134223938\n",
      "\n",
      "episode 9, val func loss 0.8586045503616333\n",
      "\n",
      "episode 10, val func loss 0.8693190813064575\n",
      "\n",
      "episode 11, val func loss 0.8622876405715942\n",
      "\n",
      "episode 12, val func loss 0.8628591895103455\n",
      "\n",
      "episode 13, val func loss 0.8518898487091064\n",
      "\n",
      "episode 14, val func loss 0.7472820281982422\n",
      "\n",
      "episode 15, val func loss 0.8102047443389893\n",
      "\n",
      "episode 16, val func loss 0.6947075724601746\n",
      "\n",
      "Val func train loss in epoch 12:0.853402640670538\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8552501797676086\n",
      "\n",
      "episode 2, val func loss 0.6873810291290283\n",
      "\n",
      "episode 3, val func loss 0.7992712259292603\n",
      "\n",
      "episode 4, val func loss 0.8698657751083374\n",
      "\n",
      "episode 5, val func loss 0.7657262086868286\n",
      "\n",
      "episode 6, val func loss 0.7110413312911987\n",
      "\n",
      "episode 7, val func loss 0.7846300601959229\n",
      "\n",
      "episode 8, val func loss 0.7108831405639648\n",
      "\n",
      "episode 9, val func loss 0.86243736743927\n",
      "\n",
      "episode 10, val func loss 0.7766806483268738\n",
      "\n",
      "episode 11, val func loss 0.8941389918327332\n",
      "\n",
      "episode 12, val func loss 0.8193674683570862\n",
      "\n",
      "episode 13, val func loss 0.8450260162353516\n",
      "\n",
      "episode 14, val func loss 0.7252702713012695\n",
      "\n",
      "episode 15, val func loss 0.7699718475341797\n",
      "\n",
      "episode 16, val func loss 0.7656256556510925\n",
      "\n",
      "Val func train loss in epoch 13:0.7901604510843754\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6847760677337646\n",
      "\n",
      "episode 2, val func loss 0.8123312592506409\n",
      "\n",
      "episode 3, val func loss 0.7414111495018005\n",
      "\n",
      "episode 4, val func loss 0.8922269344329834\n",
      "\n",
      "episode 5, val func loss 0.7978377938270569\n",
      "\n",
      "episode 6, val func loss 0.8405929207801819\n",
      "\n",
      "episode 7, val func loss 0.9363314509391785\n",
      "\n",
      "episode 8, val func loss 0.8767528533935547\n",
      "\n",
      "episode 9, val func loss 0.7628271579742432\n",
      "\n",
      "episode 10, val func loss 0.7426652908325195\n",
      "\n",
      "episode 11, val func loss 0.9424552321434021\n",
      "\n",
      "episode 12, val func loss 0.7936350703239441\n",
      "\n",
      "episode 13, val func loss 0.7486362457275391\n",
      "\n",
      "episode 14, val func loss 0.845011830329895\n",
      "\n",
      "episode 15, val func loss 0.7903558015823364\n",
      "\n",
      "episode 16, val func loss 0.8211998343467712\n",
      "\n",
      "Val func train loss in epoch 14:0.8143154308199883\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.884608268737793\n",
      "\n",
      "episode 2, val func loss 0.8650836944580078\n",
      "\n",
      "episode 3, val func loss 0.7333288192749023\n",
      "\n",
      "episode 4, val func loss 0.731287956237793\n",
      "\n",
      "episode 5, val func loss 0.7411238551139832\n",
      "\n",
      "episode 6, val func loss 0.7101746797561646\n",
      "\n",
      "episode 7, val func loss 0.7802822589874268\n",
      "\n",
      "episode 8, val func loss 0.8219348192214966\n",
      "\n",
      "episode 9, val func loss 0.7629034519195557\n",
      "\n",
      "episode 10, val func loss 0.851923406124115\n",
      "\n",
      "episode 11, val func loss 0.8308603763580322\n",
      "\n",
      "episode 12, val func loss 0.765125036239624\n",
      "\n",
      "episode 13, val func loss 0.6890611052513123\n",
      "\n",
      "episode 14, val func loss 0.8236439228057861\n",
      "\n",
      "episode 15, val func loss 0.9146314263343811\n",
      "\n",
      "episode 16, val func loss 0.756710410118103\n",
      "\n",
      "Val func train loss in epoch 15:0.7914177179336548\n",
      "***********************TIME WAS 4.835531334082286 min*****************************\n",
      "\n",
      "**********************ROUND 58 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.594244122505188\n",
      "\n",
      "episode 2, policy loss 0.5942429900169373\n",
      "\n",
      "episode 3, policy loss 0.5942438244819641\n",
      "\n",
      "episode 4, policy loss 0.5942432880401611\n",
      "\n",
      "episode 5, policy loss 0.5942426323890686\n",
      "\n",
      "episode 6, policy loss 0.5942440032958984\n",
      "\n",
      "episode 7, policy loss 0.5942434072494507\n",
      "\n",
      "episode 8, policy loss 0.5942438244819641\n",
      "\n",
      "episode 9, policy loss 0.5942432284355164\n",
      "\n",
      "episode 10, policy loss 0.5942429900169373\n",
      "\n",
      "episode 11, policy loss 0.594243049621582\n",
      "\n",
      "episode 12, policy loss 0.5942433476448059\n",
      "\n",
      "episode 13, policy loss 0.5942436456680298\n",
      "\n",
      "episode 14, policy loss 0.594243049621582\n",
      "\n",
      "episode 15, policy loss 0.5942445993423462\n",
      "\n",
      "episode 16, policy loss 0.5942438244819641\n",
      "\n",
      "Policy train loss in epoch 0:0.5942434892058372\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.5942438244819641\n",
      "\n",
      "episode 2, policy loss 0.5942429900169373\n",
      "\n",
      "episode 3, policy loss 0.5942426323890686\n",
      "\n",
      "episode 4, policy loss 0.5942434072494507\n",
      "\n",
      "episode 5, policy loss 0.594244122505188\n",
      "\n",
      "episode 6, policy loss 0.5942445993423462\n",
      "\n",
      "episode 7, policy loss 0.5942438244819641\n",
      "\n",
      "episode 8, policy loss 0.5942432880401611\n",
      "\n",
      "episode 9, policy loss 0.5942438244819641\n",
      "\n",
      "episode 10, policy loss 0.5942436456680298\n",
      "\n",
      "episode 11, policy loss 0.5942433476448059\n",
      "\n",
      "episode 12, policy loss 0.594243049621582\n",
      "\n",
      "episode 13, policy loss 0.5942429900169373\n",
      "\n",
      "episode 14, policy loss 0.5942432284355164\n",
      "\n",
      "episode 15, policy loss 0.594243049621582\n",
      "\n",
      "episode 16, policy loss 0.5942440032958984\n",
      "\n",
      "Policy train loss in epoch 1:0.5942434892058372\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.5942438244819641\n",
      "\n",
      "episode 2, policy loss 0.5942438244819641\n",
      "\n",
      "episode 3, policy loss 0.5942432880401611\n",
      "\n",
      "episode 4, policy loss 0.594243049621582\n",
      "\n",
      "episode 5, policy loss 0.5942432284355164\n",
      "\n",
      "episode 6, policy loss 0.5942440032958984\n",
      "\n",
      "episode 7, policy loss 0.5942429900169373\n",
      "\n",
      "episode 8, policy loss 0.5942436456680298\n",
      "\n",
      "episode 9, policy loss 0.594243049621582\n",
      "\n",
      "episode 10, policy loss 0.594244122505188\n",
      "\n",
      "episode 11, policy loss 0.5942438244819641\n",
      "\n",
      "episode 12, policy loss 0.5942445993423462\n",
      "\n",
      "episode 13, policy loss 0.5942433476448059\n",
      "\n",
      "episode 14, policy loss 0.5942426323890686\n",
      "\n",
      "episode 15, policy loss 0.5942434072494507\n",
      "\n",
      "episode 16, policy loss 0.5942429900169373\n",
      "\n",
      "Policy train loss in epoch 2:0.5942434892058372\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.5942438244819641\n",
      "\n",
      "episode 2, policy loss 0.5942436456680298\n",
      "\n",
      "episode 3, policy loss 0.5942434072494507\n",
      "\n",
      "episode 4, policy loss 0.5942438244819641\n",
      "\n",
      "episode 5, policy loss 0.5942440032958984\n",
      "\n",
      "episode 6, policy loss 0.5942429900169373\n",
      "\n",
      "episode 7, policy loss 0.5942429900169373\n",
      "\n",
      "episode 8, policy loss 0.594243049621582\n",
      "\n",
      "episode 9, policy loss 0.5942445993423462\n",
      "\n",
      "episode 10, policy loss 0.5942432284355164\n",
      "\n",
      "episode 11, policy loss 0.594244122505188\n",
      "\n",
      "episode 12, policy loss 0.5942426323890686\n",
      "\n",
      "episode 13, policy loss 0.5942438244819641\n",
      "\n",
      "episode 14, policy loss 0.5942432880401611\n",
      "\n",
      "episode 15, policy loss 0.594243049621582\n",
      "\n",
      "episode 16, policy loss 0.5942433476448059\n",
      "\n",
      "Policy train loss in epoch 3:0.5942434892058372\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7952209115028381\n",
      "\n",
      "episode 2, val func loss 0.9284016489982605\n",
      "\n",
      "episode 3, val func loss 0.9235199689865112\n",
      "\n",
      "episode 4, val func loss 0.825878381729126\n",
      "\n",
      "episode 5, val func loss 0.7573692798614502\n",
      "\n",
      "episode 6, val func loss 0.8674379587173462\n",
      "\n",
      "episode 7, val func loss 0.8493861556053162\n",
      "\n",
      "episode 8, val func loss 0.7898241877555847\n",
      "\n",
      "episode 9, val func loss 0.8342899084091187\n",
      "\n",
      "episode 10, val func loss 0.8108459115028381\n",
      "\n",
      "episode 11, val func loss 0.8176490068435669\n",
      "\n",
      "episode 12, val func loss 0.8139446377754211\n",
      "\n",
      "episode 13, val func loss 0.7897879481315613\n",
      "\n",
      "episode 14, val func loss 0.9660228490829468\n",
      "\n",
      "episode 15, val func loss 0.9007497429847717\n",
      "\n",
      "episode 16, val func loss 0.7852849960327148\n",
      "\n",
      "Val func train loss in epoch 0:0.8409758433699608\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8137121796607971\n",
      "\n",
      "episode 2, val func loss 0.7709968686103821\n",
      "\n",
      "episode 3, val func loss 0.8021553754806519\n",
      "\n",
      "episode 4, val func loss 0.7312843799591064\n",
      "\n",
      "episode 5, val func loss 0.7284350395202637\n",
      "\n",
      "episode 6, val func loss 0.7707938551902771\n",
      "\n",
      "episode 7, val func loss 0.6309364438056946\n",
      "\n",
      "episode 8, val func loss 0.7413795590400696\n",
      "\n",
      "episode 9, val func loss 0.7520654797554016\n",
      "\n",
      "episode 10, val func loss 0.7508127093315125\n",
      "\n",
      "episode 11, val func loss 0.7937135696411133\n",
      "\n",
      "episode 12, val func loss 0.8161683678627014\n",
      "\n",
      "episode 13, val func loss 0.7822912335395813\n",
      "\n",
      "episode 14, val func loss 0.9103114008903503\n",
      "\n",
      "episode 15, val func loss 0.7249299883842468\n",
      "\n",
      "episode 16, val func loss 0.794249951839447\n",
      "\n",
      "Val func train loss in epoch 1:0.7696397751569748\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6830523014068604\n",
      "\n",
      "episode 2, val func loss 0.7917304635047913\n",
      "\n",
      "episode 3, val func loss 0.7875115275382996\n",
      "\n",
      "episode 4, val func loss 0.7361229658126831\n",
      "\n",
      "episode 5, val func loss 0.8455996513366699\n",
      "\n",
      "episode 6, val func loss 0.663253128528595\n",
      "\n",
      "episode 7, val func loss 0.712685227394104\n",
      "\n",
      "episode 8, val func loss 0.7503871321678162\n",
      "\n",
      "episode 9, val func loss 0.762557327747345\n",
      "\n",
      "episode 10, val func loss 0.8369059562683105\n",
      "\n",
      "episode 11, val func loss 0.8188822269439697\n",
      "\n",
      "episode 12, val func loss 0.6941051483154297\n",
      "\n",
      "episode 13, val func loss 0.7625578045845032\n",
      "\n",
      "episode 14, val func loss 0.7062922120094299\n",
      "\n",
      "episode 15, val func loss 0.7717903256416321\n",
      "\n",
      "episode 16, val func loss 0.7451340556144714\n",
      "\n",
      "Val func train loss in epoch 2:0.7542854659259319\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6853382587432861\n",
      "\n",
      "episode 2, val func loss 0.8446423411369324\n",
      "\n",
      "episode 3, val func loss 0.9605799317359924\n",
      "\n",
      "episode 4, val func loss 0.738195538520813\n",
      "\n",
      "episode 5, val func loss 0.8339190483093262\n",
      "\n",
      "episode 6, val func loss 0.8761987686157227\n",
      "\n",
      "episode 7, val func loss 0.7519000768661499\n",
      "\n",
      "episode 8, val func loss 0.7686465978622437\n",
      "\n",
      "episode 9, val func loss 0.7682570815086365\n",
      "\n",
      "episode 10, val func loss 0.673391580581665\n",
      "\n",
      "episode 11, val func loss 0.8424896597862244\n",
      "\n",
      "episode 12, val func loss 0.8135061264038086\n",
      "\n",
      "episode 13, val func loss 0.7488557696342468\n",
      "\n",
      "episode 14, val func loss 0.7914644479751587\n",
      "\n",
      "episode 15, val func loss 0.7462435364723206\n",
      "\n",
      "episode 16, val func loss 0.7048275470733643\n",
      "\n",
      "Val func train loss in epoch 3:0.7842785194516182\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7718124389648438\n",
      "\n",
      "episode 2, val func loss 0.6652652025222778\n",
      "\n",
      "episode 3, val func loss 0.7617636919021606\n",
      "\n",
      "episode 4, val func loss 0.69991534948349\n",
      "\n",
      "episode 5, val func loss 0.8460076451301575\n",
      "\n",
      "episode 6, val func loss 0.7222452759742737\n",
      "\n",
      "episode 7, val func loss 0.7972733378410339\n",
      "\n",
      "episode 8, val func loss 0.7262719869613647\n",
      "\n",
      "episode 9, val func loss 0.6780869960784912\n",
      "\n",
      "episode 10, val func loss 0.6211337447166443\n",
      "\n",
      "episode 11, val func loss 0.8122945427894592\n",
      "\n",
      "episode 12, val func loss 0.7883665561676025\n",
      "\n",
      "episode 13, val func loss 0.7278959155082703\n",
      "\n",
      "episode 14, val func loss 0.794359564781189\n",
      "\n",
      "episode 15, val func loss 0.6897802352905273\n",
      "\n",
      "episode 16, val func loss 0.7706809043884277\n",
      "\n",
      "Val func train loss in epoch 4:0.7420720867812634\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7873311638832092\n",
      "\n",
      "episode 2, val func loss 0.814324676990509\n",
      "\n",
      "episode 3, val func loss 0.6640311479568481\n",
      "\n",
      "episode 4, val func loss 0.7824072241783142\n",
      "\n",
      "episode 5, val func loss 0.797822892665863\n",
      "\n",
      "episode 6, val func loss 0.7774267196655273\n",
      "\n",
      "episode 7, val func loss 0.7278698086738586\n",
      "\n",
      "episode 8, val func loss 0.7360771298408508\n",
      "\n",
      "episode 9, val func loss 0.8290457129478455\n",
      "\n",
      "episode 10, val func loss 0.8968381881713867\n",
      "\n",
      "episode 11, val func loss 0.772643506526947\n",
      "\n",
      "episode 12, val func loss 0.8333967328071594\n",
      "\n",
      "episode 13, val func loss 0.7390075325965881\n",
      "\n",
      "episode 14, val func loss 0.8256030678749084\n",
      "\n",
      "episode 15, val func loss 0.8618986010551453\n",
      "\n",
      "episode 16, val func loss 0.7741556763648987\n",
      "\n",
      "Val func train loss in epoch 5:0.7887424863874912\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8588169813156128\n",
      "\n",
      "episode 2, val func loss 0.7477686405181885\n",
      "\n",
      "episode 3, val func loss 0.763953685760498\n",
      "\n",
      "episode 4, val func loss 0.8043858408927917\n",
      "\n",
      "episode 5, val func loss 0.7335289716720581\n",
      "\n",
      "episode 6, val func loss 0.734105110168457\n",
      "\n",
      "episode 7, val func loss 0.771439790725708\n",
      "\n",
      "episode 8, val func loss 0.7357272505760193\n",
      "\n",
      "episode 9, val func loss 0.8302468061447144\n",
      "\n",
      "episode 10, val func loss 0.798967182636261\n",
      "\n",
      "episode 11, val func loss 0.7902193665504456\n",
      "\n",
      "episode 12, val func loss 0.7851600646972656\n",
      "\n",
      "episode 13, val func loss 0.8023045063018799\n",
      "\n",
      "episode 14, val func loss 0.7624985575675964\n",
      "\n",
      "episode 15, val func loss 0.8551188111305237\n",
      "\n",
      "episode 16, val func loss 0.735584020614624\n",
      "\n",
      "Val func train loss in epoch 6:0.7818640992045403\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7916348576545715\n",
      "\n",
      "episode 2, val func loss 0.7761210799217224\n",
      "\n",
      "episode 3, val func loss 0.7172365188598633\n",
      "\n",
      "episode 4, val func loss 0.6988250017166138\n",
      "\n",
      "episode 5, val func loss 0.6752110719680786\n",
      "\n",
      "episode 6, val func loss 0.8127233982086182\n",
      "\n",
      "episode 7, val func loss 0.7861757874488831\n",
      "\n",
      "episode 8, val func loss 0.73353511095047\n",
      "\n",
      "episode 9, val func loss 0.7813427448272705\n",
      "\n",
      "episode 10, val func loss 0.7781910300254822\n",
      "\n",
      "episode 11, val func loss 0.7706567645072937\n",
      "\n",
      "episode 12, val func loss 0.6771543622016907\n",
      "\n",
      "episode 13, val func loss 0.8067057132720947\n",
      "\n",
      "episode 14, val func loss 0.8634121417999268\n",
      "\n",
      "episode 15, val func loss 0.793910026550293\n",
      "\n",
      "episode 16, val func loss 0.7655787467956543\n",
      "\n",
      "Val func train loss in epoch 7:0.7642758972942829\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7620722651481628\n",
      "\n",
      "episode 2, val func loss 0.8125525712966919\n",
      "\n",
      "episode 3, val func loss 0.707767903804779\n",
      "\n",
      "episode 4, val func loss 0.7033352255821228\n",
      "\n",
      "episode 5, val func loss 0.7642987966537476\n",
      "\n",
      "episode 6, val func loss 0.743949830532074\n",
      "\n",
      "episode 7, val func loss 0.6878950595855713\n",
      "\n",
      "episode 8, val func loss 0.7427768707275391\n",
      "\n",
      "episode 9, val func loss 0.6942969560623169\n",
      "\n",
      "episode 10, val func loss 0.7220000624656677\n",
      "\n",
      "episode 11, val func loss 0.6191604733467102\n",
      "\n",
      "episode 12, val func loss 0.864119827747345\n",
      "\n",
      "episode 13, val func loss 0.7489449977874756\n",
      "\n",
      "episode 14, val func loss 0.8106054663658142\n",
      "\n",
      "episode 15, val func loss 0.7082664966583252\n",
      "\n",
      "episode 16, val func loss 0.6452786922454834\n",
      "\n",
      "Val func train loss in epoch 8:0.7335825935006142\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.7583089470863342\n",
      "\n",
      "episode 2, val func loss 0.694312572479248\n",
      "\n",
      "episode 3, val func loss 0.7786787152290344\n",
      "\n",
      "episode 4, val func loss 0.7441920638084412\n",
      "\n",
      "episode 5, val func loss 0.743493378162384\n",
      "\n",
      "episode 6, val func loss 0.7600455284118652\n",
      "\n",
      "episode 7, val func loss 0.7789976596832275\n",
      "\n",
      "episode 8, val func loss 0.7198627591133118\n",
      "\n",
      "episode 9, val func loss 0.8842421174049377\n",
      "\n",
      "episode 10, val func loss 0.707126796245575\n",
      "\n",
      "episode 11, val func loss 0.8548089861869812\n",
      "\n",
      "episode 12, val func loss 0.8759379982948303\n",
      "\n",
      "episode 13, val func loss 0.7419739961624146\n",
      "\n",
      "episode 14, val func loss 0.8955740928649902\n",
      "\n",
      "episode 15, val func loss 0.7587032318115234\n",
      "\n",
      "episode 16, val func loss 0.7862706780433655\n",
      "\n",
      "Val func train loss in epoch 9:0.780158095061779\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7571593523025513\n",
      "\n",
      "episode 2, val func loss 0.7797656059265137\n",
      "\n",
      "episode 3, val func loss 0.7625088095664978\n",
      "\n",
      "episode 4, val func loss 0.8340299725532532\n",
      "\n",
      "episode 5, val func loss 0.8222619891166687\n",
      "\n",
      "episode 6, val func loss 0.7593896985054016\n",
      "\n",
      "episode 7, val func loss 0.821056067943573\n",
      "\n",
      "episode 8, val func loss 0.8473799228668213\n",
      "\n",
      "episode 9, val func loss 0.7924743294715881\n",
      "\n",
      "episode 10, val func loss 0.8771712183952332\n",
      "\n",
      "episode 11, val func loss 0.7767102122306824\n",
      "\n",
      "episode 12, val func loss 0.9095030426979065\n",
      "\n",
      "episode 13, val func loss 0.8176437020301819\n",
      "\n",
      "episode 14, val func loss 0.8199477791786194\n",
      "\n",
      "episode 15, val func loss 0.8852283954620361\n",
      "\n",
      "episode 16, val func loss 0.7521792054176331\n",
      "\n",
      "Val func train loss in epoch 10:0.8134005814790726\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9051691293716431\n",
      "\n",
      "episode 2, val func loss 0.7773870825767517\n",
      "\n",
      "episode 3, val func loss 0.8140086531639099\n",
      "\n",
      "episode 4, val func loss 0.7266805768013\n",
      "\n",
      "episode 5, val func loss 0.6438167691230774\n",
      "\n",
      "episode 6, val func loss 0.745488703250885\n",
      "\n",
      "episode 7, val func loss 0.7946315407752991\n",
      "\n",
      "episode 8, val func loss 0.7144323587417603\n",
      "\n",
      "episode 9, val func loss 0.8185181021690369\n",
      "\n",
      "episode 10, val func loss 0.7386892437934875\n",
      "\n",
      "episode 11, val func loss 0.7249386310577393\n",
      "\n",
      "episode 12, val func loss 0.7281644940376282\n",
      "\n",
      "episode 13, val func loss 0.6621350646018982\n",
      "\n",
      "episode 14, val func loss 0.7191330790519714\n",
      "\n",
      "episode 15, val func loss 0.6683845520019531\n",
      "\n",
      "episode 16, val func loss 0.7930110692977905\n",
      "\n",
      "Val func train loss in epoch 11:0.7484118156135082\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7287171483039856\n",
      "\n",
      "episode 2, val func loss 0.7142454981803894\n",
      "\n",
      "episode 3, val func loss 0.686732828617096\n",
      "\n",
      "episode 4, val func loss 0.8101783394813538\n",
      "\n",
      "episode 5, val func loss 0.809107780456543\n",
      "\n",
      "episode 6, val func loss 0.7893920540809631\n",
      "\n",
      "episode 7, val func loss 0.7962464094161987\n",
      "\n",
      "episode 8, val func loss 0.7525115609169006\n",
      "\n",
      "episode 9, val func loss 0.8689043521881104\n",
      "\n",
      "episode 10, val func loss 0.8051486015319824\n",
      "\n",
      "episode 11, val func loss 0.6838704943656921\n",
      "\n",
      "episode 12, val func loss 0.7831538915634155\n",
      "\n",
      "episode 13, val func loss 0.9086675643920898\n",
      "\n",
      "episode 14, val func loss 0.7276068925857544\n",
      "\n",
      "episode 15, val func loss 0.792527437210083\n",
      "\n",
      "episode 16, val func loss 0.838247537612915\n",
      "\n",
      "Val func train loss in epoch 12:0.7809536494314671\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8897443413734436\n",
      "\n",
      "episode 2, val func loss 0.9513981342315674\n",
      "\n",
      "episode 3, val func loss 0.8762208819389343\n",
      "\n",
      "episode 4, val func loss 0.6959742903709412\n",
      "\n",
      "episode 5, val func loss 0.856564998626709\n",
      "\n",
      "episode 6, val func loss 0.8441094160079956\n",
      "\n",
      "episode 7, val func loss 0.8190341591835022\n",
      "\n",
      "episode 8, val func loss 0.8788536787033081\n",
      "\n",
      "episode 9, val func loss 0.8204805254936218\n",
      "\n",
      "episode 10, val func loss 0.8084315657615662\n",
      "\n",
      "episode 11, val func loss 0.9828702211380005\n",
      "\n",
      "episode 12, val func loss 0.853857159614563\n",
      "\n",
      "episode 13, val func loss 0.7688605189323425\n",
      "\n",
      "episode 14, val func loss 0.8609053492546082\n",
      "\n",
      "episode 15, val func loss 0.735386073589325\n",
      "\n",
      "episode 16, val func loss 0.7415257692337036\n",
      "\n",
      "Val func train loss in epoch 13:0.8365135677158833\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.760064423084259\n",
      "\n",
      "episode 2, val func loss 0.8526928424835205\n",
      "\n",
      "episode 3, val func loss 0.8562040328979492\n",
      "\n",
      "episode 4, val func loss 0.7713664770126343\n",
      "\n",
      "episode 5, val func loss 0.7269744873046875\n",
      "\n",
      "episode 6, val func loss 0.769360363483429\n",
      "\n",
      "episode 7, val func loss 0.7440422773361206\n",
      "\n",
      "episode 8, val func loss 0.8702163100242615\n",
      "\n",
      "episode 9, val func loss 0.7807027101516724\n",
      "\n",
      "episode 10, val func loss 0.7430404424667358\n",
      "\n",
      "episode 11, val func loss 0.8343939185142517\n",
      "\n",
      "episode 12, val func loss 0.684090256690979\n",
      "\n",
      "episode 13, val func loss 0.9218310713768005\n",
      "\n",
      "episode 14, val func loss 0.7625890374183655\n",
      "\n",
      "episode 15, val func loss 0.8916864395141602\n",
      "\n",
      "episode 16, val func loss 0.7275552749633789\n",
      "\n",
      "Val func train loss in epoch 14:0.7935506477952003\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7487649917602539\n",
      "\n",
      "episode 2, val func loss 0.8548448085784912\n",
      "\n",
      "episode 3, val func loss 0.7355192303657532\n",
      "\n",
      "episode 4, val func loss 0.7643507122993469\n",
      "\n",
      "episode 5, val func loss 0.9332605004310608\n",
      "\n",
      "episode 6, val func loss 0.7292047739028931\n",
      "\n",
      "episode 7, val func loss 0.8610150218009949\n",
      "\n",
      "episode 8, val func loss 0.9379324316978455\n",
      "\n",
      "episode 9, val func loss 0.777166485786438\n",
      "\n",
      "episode 10, val func loss 0.7731623649597168\n",
      "\n",
      "episode 11, val func loss 0.9311680197715759\n",
      "\n",
      "episode 12, val func loss 0.9093611240386963\n",
      "\n",
      "episode 13, val func loss 0.8112987279891968\n",
      "\n",
      "episode 14, val func loss 0.7415735721588135\n",
      "\n",
      "episode 15, val func loss 0.7350919246673584\n",
      "\n",
      "episode 16, val func loss 0.5726560354232788\n",
      "\n",
      "Val func train loss in epoch 15:0.8010231703519821\n",
      "***********************TIME WAS 4.829988352457682 min*****************************\n",
      "\n",
      "**********************ROUND 59 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.37104469537734985\n",
      "\n",
      "episode 2, policy loss 0.3710457682609558\n",
      "\n",
      "episode 3, policy loss 0.37104520201683044\n",
      "\n",
      "episode 4, policy loss 0.37104639410972595\n",
      "\n",
      "episode 5, policy loss 0.3710452914237976\n",
      "\n",
      "episode 6, policy loss 0.3710469901561737\n",
      "\n",
      "episode 7, policy loss 0.37104538083076477\n",
      "\n",
      "episode 8, policy loss 0.3710429072380066\n",
      "\n",
      "episode 9, policy loss 0.3710440397262573\n",
      "\n",
      "episode 10, policy loss 0.37104395031929016\n",
      "\n",
      "episode 11, policy loss 0.37104472517967224\n",
      "\n",
      "episode 12, policy loss 0.3710460364818573\n",
      "\n",
      "episode 13, policy loss 0.3710472583770752\n",
      "\n",
      "episode 14, policy loss 0.37104612588882446\n",
      "\n",
      "episode 15, policy loss 0.37104594707489014\n",
      "\n",
      "episode 16, policy loss 0.3710459768772125\n",
      "\n",
      "Policy train loss in epoch 0:0.37104541808366776\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.37104472517967224\n",
      "\n",
      "episode 2, policy loss 0.37104395031929016\n",
      "\n",
      "episode 3, policy loss 0.37104520201683044\n",
      "\n",
      "episode 4, policy loss 0.37104639410972595\n",
      "\n",
      "episode 5, policy loss 0.3710452914237976\n",
      "\n",
      "episode 6, policy loss 0.3710429072380066\n",
      "\n",
      "episode 7, policy loss 0.3710472583770752\n",
      "\n",
      "episode 8, policy loss 0.37104594707489014\n",
      "\n",
      "episode 9, policy loss 0.3710459768772125\n",
      "\n",
      "episode 10, policy loss 0.3710457682609558\n",
      "\n",
      "episode 11, policy loss 0.3710469901561737\n",
      "\n",
      "episode 12, policy loss 0.37104469537734985\n",
      "\n",
      "episode 13, policy loss 0.3710460364818573\n",
      "\n",
      "episode 14, policy loss 0.37104538083076477\n",
      "\n",
      "episode 15, policy loss 0.37104612588882446\n",
      "\n",
      "episode 16, policy loss 0.3710440397262573\n",
      "\n",
      "Policy train loss in epoch 1:0.37104541808366776\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.37104469537734985\n",
      "\n",
      "episode 2, policy loss 0.37104520201683044\n",
      "\n",
      "episode 3, policy loss 0.37104612588882446\n",
      "\n",
      "episode 4, policy loss 0.37104395031929016\n",
      "\n",
      "episode 5, policy loss 0.3710440397262573\n",
      "\n",
      "episode 6, policy loss 0.3710429072380066\n",
      "\n",
      "episode 7, policy loss 0.3710460364818573\n",
      "\n",
      "episode 8, policy loss 0.3710457682609558\n",
      "\n",
      "episode 9, policy loss 0.3710452914237976\n",
      "\n",
      "episode 10, policy loss 0.3710459768772125\n",
      "\n",
      "episode 11, policy loss 0.37104538083076477\n",
      "\n",
      "episode 12, policy loss 0.37104594707489014\n",
      "\n",
      "episode 13, policy loss 0.3710469901561737\n",
      "\n",
      "episode 14, policy loss 0.37104472517967224\n",
      "\n",
      "episode 15, policy loss 0.37104639410972595\n",
      "\n",
      "episode 16, policy loss 0.3710472583770752\n",
      "\n",
      "Policy train loss in epoch 2:0.37104541808366776\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.37104469537734985\n",
      "\n",
      "episode 2, policy loss 0.3710440397262573\n",
      "\n",
      "episode 3, policy loss 0.3710429072380066\n",
      "\n",
      "episode 4, policy loss 0.37104395031929016\n",
      "\n",
      "episode 5, policy loss 0.3710457682609558\n",
      "\n",
      "episode 6, policy loss 0.37104538083076477\n",
      "\n",
      "episode 7, policy loss 0.3710452914237976\n",
      "\n",
      "episode 8, policy loss 0.37104594707489014\n",
      "\n",
      "episode 9, policy loss 0.37104639410972595\n",
      "\n",
      "episode 10, policy loss 0.3710469901561737\n",
      "\n",
      "episode 11, policy loss 0.3710460364818573\n",
      "\n",
      "episode 12, policy loss 0.3710472583770752\n",
      "\n",
      "episode 13, policy loss 0.37104612588882446\n",
      "\n",
      "episode 14, policy loss 0.37104472517967224\n",
      "\n",
      "episode 15, policy loss 0.3710459768772125\n",
      "\n",
      "episode 16, policy loss 0.37104520201683044\n",
      "\n",
      "Policy train loss in epoch 3:0.37104541808366776\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7143140435218811\n",
      "\n",
      "episode 2, val func loss 0.7195478081703186\n",
      "\n",
      "episode 3, val func loss 0.6986469030380249\n",
      "\n",
      "episode 4, val func loss 0.7214906811714172\n",
      "\n",
      "episode 5, val func loss 0.7663530707359314\n",
      "\n",
      "episode 6, val func loss 0.8119548559188843\n",
      "\n",
      "episode 7, val func loss 0.7097535729408264\n",
      "\n",
      "episode 8, val func loss 0.8078213930130005\n",
      "\n",
      "episode 9, val func loss 0.7533435821533203\n",
      "\n",
      "episode 10, val func loss 0.7109024524688721\n",
      "\n",
      "episode 11, val func loss 0.7947224378585815\n",
      "\n",
      "episode 12, val func loss 0.6409286856651306\n",
      "\n",
      "episode 13, val func loss 0.69046950340271\n",
      "\n",
      "episode 14, val func loss 0.750316321849823\n",
      "\n",
      "episode 15, val func loss 0.7808428406715393\n",
      "\n",
      "episode 16, val func loss 0.7316948771476746\n",
      "\n",
      "Val func train loss in epoch 0:0.737693939357996\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.6964454650878906\n",
      "\n",
      "episode 2, val func loss 0.7380173802375793\n",
      "\n",
      "episode 3, val func loss 0.7603774666786194\n",
      "\n",
      "episode 4, val func loss 0.853720486164093\n",
      "\n",
      "episode 5, val func loss 0.6960039734840393\n",
      "\n",
      "episode 6, val func loss 0.7913957238197327\n",
      "\n",
      "episode 7, val func loss 0.7831690311431885\n",
      "\n",
      "episode 8, val func loss 0.8130769729614258\n",
      "\n",
      "episode 9, val func loss 0.836594820022583\n",
      "\n",
      "episode 10, val func loss 0.7868239283561707\n",
      "\n",
      "episode 11, val func loss 0.7791449427604675\n",
      "\n",
      "episode 12, val func loss 0.6948851943016052\n",
      "\n",
      "episode 13, val func loss 0.7157929539680481\n",
      "\n",
      "episode 14, val func loss 0.7280173301696777\n",
      "\n",
      "episode 15, val func loss 0.6882869601249695\n",
      "\n",
      "episode 16, val func loss 0.6671308279037476\n",
      "\n",
      "Val func train loss in epoch 1:0.7518052160739899\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7234594821929932\n",
      "\n",
      "episode 2, val func loss 0.7883344888687134\n",
      "\n",
      "episode 3, val func loss 0.8019362688064575\n",
      "\n",
      "episode 4, val func loss 0.7387071847915649\n",
      "\n",
      "episode 5, val func loss 0.6812929511070251\n",
      "\n",
      "episode 6, val func loss 0.7465503811836243\n",
      "\n",
      "episode 7, val func loss 0.770194947719574\n",
      "\n",
      "episode 8, val func loss 0.772659957408905\n",
      "\n",
      "episode 9, val func loss 0.7439263463020325\n",
      "\n",
      "episode 10, val func loss 0.8328746557235718\n",
      "\n",
      "episode 11, val func loss 0.7831369042396545\n",
      "\n",
      "episode 12, val func loss 0.7256997227668762\n",
      "\n",
      "episode 13, val func loss 0.8040052652359009\n",
      "\n",
      "episode 14, val func loss 0.7587682008743286\n",
      "\n",
      "episode 15, val func loss 0.7009894251823425\n",
      "\n",
      "episode 16, val func loss 0.6824719905853271\n",
      "\n",
      "Val func train loss in epoch 2:0.7534380108118057\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8012712597846985\n",
      "\n",
      "episode 2, val func loss 0.7143202424049377\n",
      "\n",
      "episode 3, val func loss 0.7896387577056885\n",
      "\n",
      "episode 4, val func loss 0.7997625470161438\n",
      "\n",
      "episode 5, val func loss 0.7654435634613037\n",
      "\n",
      "episode 6, val func loss 0.7073438167572021\n",
      "\n",
      "episode 7, val func loss 0.8553704023361206\n",
      "\n",
      "episode 8, val func loss 0.7778200507164001\n",
      "\n",
      "episode 9, val func loss 0.7108315229415894\n",
      "\n",
      "episode 10, val func loss 0.7491264343261719\n",
      "\n",
      "episode 11, val func loss 0.7791003584861755\n",
      "\n",
      "episode 12, val func loss 0.6889621019363403\n",
      "\n",
      "episode 13, val func loss 0.6257734894752502\n",
      "\n",
      "episode 14, val func loss 0.8224784135818481\n",
      "\n",
      "episode 15, val func loss 0.7167559266090393\n",
      "\n",
      "episode 16, val func loss 0.7999135255813599\n",
      "\n",
      "Val func train loss in epoch 3:0.7564945258200169\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7213693857192993\n",
      "\n",
      "episode 2, val func loss 0.7308251857757568\n",
      "\n",
      "episode 3, val func loss 0.8257851004600525\n",
      "\n",
      "episode 4, val func loss 0.7913691401481628\n",
      "\n",
      "episode 5, val func loss 0.7308241724967957\n",
      "\n",
      "episode 6, val func loss 0.7479941248893738\n",
      "\n",
      "episode 7, val func loss 0.7014765739440918\n",
      "\n",
      "episode 8, val func loss 0.7944803237915039\n",
      "\n",
      "episode 9, val func loss 0.7277113199234009\n",
      "\n",
      "episode 10, val func loss 0.9250053763389587\n",
      "\n",
      "episode 11, val func loss 0.85047847032547\n",
      "\n",
      "episode 12, val func loss 0.708858847618103\n",
      "\n",
      "episode 13, val func loss 0.7507063746452332\n",
      "\n",
      "episode 14, val func loss 0.8227699398994446\n",
      "\n",
      "episode 15, val func loss 0.7355693578720093\n",
      "\n",
      "episode 16, val func loss 0.6521285176277161\n",
      "\n",
      "Val func train loss in epoch 4:0.7635845132172108\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7122184038162231\n",
      "\n",
      "episode 2, val func loss 0.7606101632118225\n",
      "\n",
      "episode 3, val func loss 0.6673901677131653\n",
      "\n",
      "episode 4, val func loss 0.7756940722465515\n",
      "\n",
      "episode 5, val func loss 0.7921937108039856\n",
      "\n",
      "episode 6, val func loss 0.851144552230835\n",
      "\n",
      "episode 7, val func loss 0.6384023427963257\n",
      "\n",
      "episode 8, val func loss 0.7004568576812744\n",
      "\n",
      "episode 9, val func loss 0.7127366662025452\n",
      "\n",
      "episode 10, val func loss 0.7209880948066711\n",
      "\n",
      "episode 11, val func loss 0.8133513331413269\n",
      "\n",
      "episode 12, val func loss 0.774179220199585\n",
      "\n",
      "episode 13, val func loss 0.7111598253250122\n",
      "\n",
      "episode 14, val func loss 0.7224968671798706\n",
      "\n",
      "episode 15, val func loss 0.6747662425041199\n",
      "\n",
      "episode 16, val func loss 0.6713648438453674\n",
      "\n",
      "Val func train loss in epoch 5:0.7311970852315426\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7417272329330444\n",
      "\n",
      "episode 2, val func loss 0.7172415256500244\n",
      "\n",
      "episode 3, val func loss 0.7892847657203674\n",
      "\n",
      "episode 4, val func loss 0.7323037385940552\n",
      "\n",
      "episode 5, val func loss 0.8558817505836487\n",
      "\n",
      "episode 6, val func loss 0.7800951600074768\n",
      "\n",
      "episode 7, val func loss 0.7049861550331116\n",
      "\n",
      "episode 8, val func loss 0.8323677778244019\n",
      "\n",
      "episode 9, val func loss 0.6811285018920898\n",
      "\n",
      "episode 10, val func loss 0.7429038286209106\n",
      "\n",
      "episode 11, val func loss 0.8124935626983643\n",
      "\n",
      "episode 12, val func loss 0.7764652371406555\n",
      "\n",
      "episode 13, val func loss 0.7647696733474731\n",
      "\n",
      "episode 14, val func loss 0.7056623697280884\n",
      "\n",
      "episode 15, val func loss 0.8232117891311646\n",
      "\n",
      "episode 16, val func loss 0.7374973297119141\n",
      "\n",
      "Val func train loss in epoch 6:0.7623762749135494\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7311824560165405\n",
      "\n",
      "episode 2, val func loss 0.781530499458313\n",
      "\n",
      "episode 3, val func loss 0.7741613388061523\n",
      "\n",
      "episode 4, val func loss 0.7690368294715881\n",
      "\n",
      "episode 5, val func loss 0.6827067136764526\n",
      "\n",
      "episode 6, val func loss 0.7830217480659485\n",
      "\n",
      "episode 7, val func loss 0.7301996350288391\n",
      "\n",
      "episode 8, val func loss 0.7192255258560181\n",
      "\n",
      "episode 9, val func loss 0.7874002456665039\n",
      "\n",
      "episode 10, val func loss 0.8295031785964966\n",
      "\n",
      "episode 11, val func loss 0.6989552974700928\n",
      "\n",
      "episode 12, val func loss 0.704069972038269\n",
      "\n",
      "episode 13, val func loss 0.7544124722480774\n",
      "\n",
      "episode 14, val func loss 0.7540479302406311\n",
      "\n",
      "episode 15, val func loss 0.77963787317276\n",
      "\n",
      "episode 16, val func loss 0.6728088855743408\n",
      "\n",
      "Val func train loss in epoch 7:0.746993787586689\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7280125021934509\n",
      "\n",
      "episode 2, val func loss 0.7479057312011719\n",
      "\n",
      "episode 3, val func loss 0.673406720161438\n",
      "\n",
      "episode 4, val func loss 0.6779425144195557\n",
      "\n",
      "episode 5, val func loss 0.8136641383171082\n",
      "\n",
      "episode 6, val func loss 0.6927791237831116\n",
      "\n",
      "episode 7, val func loss 0.7599981427192688\n",
      "\n",
      "episode 8, val func loss 0.7941853404045105\n",
      "\n",
      "episode 9, val func loss 0.7322485446929932\n",
      "\n",
      "episode 10, val func loss 0.6237773299217224\n",
      "\n",
      "episode 11, val func loss 0.7571495771408081\n",
      "\n",
      "episode 12, val func loss 0.8161642551422119\n",
      "\n",
      "episode 13, val func loss 0.7760601043701172\n",
      "\n",
      "episode 14, val func loss 0.7059295773506165\n",
      "\n",
      "episode 15, val func loss 0.759863555431366\n",
      "\n",
      "episode 16, val func loss 0.7956898212432861\n",
      "\n",
      "Val func train loss in epoch 8:0.740923561155796\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6873308420181274\n",
      "\n",
      "episode 2, val func loss 0.7969332337379456\n",
      "\n",
      "episode 3, val func loss 0.809030294418335\n",
      "\n",
      "episode 4, val func loss 0.8786097168922424\n",
      "\n",
      "episode 5, val func loss 0.6849080324172974\n",
      "\n",
      "episode 6, val func loss 0.8509652614593506\n",
      "\n",
      "episode 7, val func loss 0.6843494176864624\n",
      "\n",
      "episode 8, val func loss 0.7234058380126953\n",
      "\n",
      "episode 9, val func loss 0.668152391910553\n",
      "\n",
      "episode 10, val func loss 0.8299110531806946\n",
      "\n",
      "episode 11, val func loss 0.7043191194534302\n",
      "\n",
      "episode 12, val func loss 0.7276157140731812\n",
      "\n",
      "episode 13, val func loss 0.7451425790786743\n",
      "\n",
      "episode 14, val func loss 0.877229630947113\n",
      "\n",
      "episode 15, val func loss 0.6755419373512268\n",
      "\n",
      "episode 16, val func loss 0.7604579925537109\n",
      "\n",
      "Val func train loss in epoch 9:0.75649394094944\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7329376935958862\n",
      "\n",
      "episode 2, val func loss 0.7972186803817749\n",
      "\n",
      "episode 3, val func loss 0.7692431807518005\n",
      "\n",
      "episode 4, val func loss 0.7630252242088318\n",
      "\n",
      "episode 5, val func loss 0.7602788805961609\n",
      "\n",
      "episode 6, val func loss 0.7240460515022278\n",
      "\n",
      "episode 7, val func loss 0.7370005249977112\n",
      "\n",
      "episode 8, val func loss 0.7597208023071289\n",
      "\n",
      "episode 9, val func loss 0.8398127555847168\n",
      "\n",
      "episode 10, val func loss 0.7692890167236328\n",
      "\n",
      "episode 11, val func loss 0.7938191890716553\n",
      "\n",
      "episode 12, val func loss 0.7842052578926086\n",
      "\n",
      "episode 13, val func loss 0.7497475147247314\n",
      "\n",
      "episode 14, val func loss 0.6588153839111328\n",
      "\n",
      "episode 15, val func loss 0.8338414430618286\n",
      "\n",
      "episode 16, val func loss 0.776470959186554\n",
      "\n",
      "Val func train loss in epoch 10:0.7655920349061489\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7678781747817993\n",
      "\n",
      "episode 2, val func loss 0.9226919412612915\n",
      "\n",
      "episode 3, val func loss 0.6588184833526611\n",
      "\n",
      "episode 4, val func loss 0.7973429560661316\n",
      "\n",
      "episode 5, val func loss 0.7419632077217102\n",
      "\n",
      "episode 6, val func loss 0.7430423498153687\n",
      "\n",
      "episode 7, val func loss 0.7887536287307739\n",
      "\n",
      "episode 8, val func loss 0.8609573841094971\n",
      "\n",
      "episode 9, val func loss 0.7435166239738464\n",
      "\n",
      "episode 10, val func loss 0.7827558517456055\n",
      "\n",
      "episode 11, val func loss 0.7642221450805664\n",
      "\n",
      "episode 12, val func loss 0.8358027338981628\n",
      "\n",
      "episode 13, val func loss 0.8030536770820618\n",
      "\n",
      "episode 14, val func loss 0.7299330234527588\n",
      "\n",
      "episode 15, val func loss 0.7018811106681824\n",
      "\n",
      "episode 16, val func loss 0.763199508190155\n",
      "\n",
      "Val func train loss in epoch 11:0.7753632999956608\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7032169699668884\n",
      "\n",
      "episode 2, val func loss 0.7164503335952759\n",
      "\n",
      "episode 3, val func loss 0.6648985147476196\n",
      "\n",
      "episode 4, val func loss 0.793215811252594\n",
      "\n",
      "episode 5, val func loss 0.7478747367858887\n",
      "\n",
      "episode 6, val func loss 0.7409517168998718\n",
      "\n",
      "episode 7, val func loss 0.6900551319122314\n",
      "\n",
      "episode 8, val func loss 0.8559338450431824\n",
      "\n",
      "episode 9, val func loss 0.8205697536468506\n",
      "\n",
      "episode 10, val func loss 0.7997108101844788\n",
      "\n",
      "episode 11, val func loss 0.8285135626792908\n",
      "\n",
      "episode 12, val func loss 0.7395308017730713\n",
      "\n",
      "episode 13, val func loss 0.754205048084259\n",
      "\n",
      "episode 14, val func loss 0.6579751968383789\n",
      "\n",
      "episode 15, val func loss 0.7885461449623108\n",
      "\n",
      "episode 16, val func loss 0.8301383256912231\n",
      "\n",
      "Val func train loss in epoch 12:0.7582366690039635\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.7524448037147522\n",
      "\n",
      "episode 2, val func loss 0.7252593636512756\n",
      "\n",
      "episode 3, val func loss 0.7216674089431763\n",
      "\n",
      "episode 4, val func loss 0.7427250742912292\n",
      "\n",
      "episode 5, val func loss 0.7385812997817993\n",
      "\n",
      "episode 6, val func loss 0.8005861639976501\n",
      "\n",
      "episode 7, val func loss 0.7246604561805725\n",
      "\n",
      "episode 8, val func loss 0.7264501452445984\n",
      "\n",
      "episode 9, val func loss 0.7060796022415161\n",
      "\n",
      "episode 10, val func loss 0.746818482875824\n",
      "\n",
      "episode 11, val func loss 0.6925203800201416\n",
      "\n",
      "episode 12, val func loss 0.8249402642250061\n",
      "\n",
      "episode 13, val func loss 0.6755476593971252\n",
      "\n",
      "episode 14, val func loss 0.8518083691596985\n",
      "\n",
      "episode 15, val func loss 0.7379478812217712\n",
      "\n",
      "episode 16, val func loss 0.787844717502594\n",
      "\n",
      "Val func train loss in epoch 13:0.7472426295280457\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.772141695022583\n",
      "\n",
      "episode 2, val func loss 0.7476861476898193\n",
      "\n",
      "episode 3, val func loss 0.7004298567771912\n",
      "\n",
      "episode 4, val func loss 0.7198687195777893\n",
      "\n",
      "episode 5, val func loss 0.7432621121406555\n",
      "\n",
      "episode 6, val func loss 0.6874597072601318\n",
      "\n",
      "episode 7, val func loss 0.7538920044898987\n",
      "\n",
      "episode 8, val func loss 0.8627740740776062\n",
      "\n",
      "episode 9, val func loss 0.7871068120002747\n",
      "\n",
      "episode 10, val func loss 0.8724615573883057\n",
      "\n",
      "episode 11, val func loss 0.781710684299469\n",
      "\n",
      "episode 12, val func loss 0.7675384879112244\n",
      "\n",
      "episode 13, val func loss 0.7041521668434143\n",
      "\n",
      "episode 14, val func loss 0.8375241160392761\n",
      "\n",
      "episode 15, val func loss 0.77084881067276\n",
      "\n",
      "episode 16, val func loss 0.7508947849273682\n",
      "\n",
      "Val func train loss in epoch 14:0.7662344835698605\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.8341912031173706\n",
      "\n",
      "episode 2, val func loss 0.8170843124389648\n",
      "\n",
      "episode 3, val func loss 0.8280841112136841\n",
      "\n",
      "episode 4, val func loss 0.7902924418449402\n",
      "\n",
      "episode 5, val func loss 0.7510519623756409\n",
      "\n",
      "episode 6, val func loss 0.8385211229324341\n",
      "\n",
      "episode 7, val func loss 0.7179347276687622\n",
      "\n",
      "episode 8, val func loss 0.6926668286323547\n",
      "\n",
      "episode 9, val func loss 0.7117226123809814\n",
      "\n",
      "episode 10, val func loss 0.8064141869544983\n",
      "\n",
      "episode 11, val func loss 0.6725974678993225\n",
      "\n",
      "episode 12, val func loss 0.7350590825080872\n",
      "\n",
      "episode 13, val func loss 0.7472731471061707\n",
      "\n",
      "episode 14, val func loss 0.7322565317153931\n",
      "\n",
      "episode 15, val func loss 0.7691656947135925\n",
      "\n",
      "episode 16, val func loss 0.8080787062644958\n",
      "\n",
      "Val func train loss in epoch 15:0.7657746337354183\n",
      "***********************TIME WAS 4.8330667098363245 min*****************************\n",
      "\n",
      "**********************ROUND 60 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.8409193754196167\n",
      "\n",
      "episode 2, policy loss 0.8409196734428406\n",
      "\n",
      "episode 3, policy loss 0.8409184813499451\n",
      "\n",
      "episode 4, policy loss 0.8409202098846436\n",
      "\n",
      "episode 5, policy loss 0.840919017791748\n",
      "\n",
      "episode 6, policy loss 0.8409192562103271\n",
      "\n",
      "episode 7, policy loss 0.8409196138381958\n",
      "\n",
      "episode 8, policy loss 0.8409191966056824\n",
      "\n",
      "episode 9, policy loss 0.8409199714660645\n",
      "\n",
      "episode 10, policy loss 0.8409199714660645\n",
      "\n",
      "episode 11, policy loss 0.8409194946289062\n",
      "\n",
      "episode 12, policy loss 0.8409200310707092\n",
      "\n",
      "episode 13, policy loss 0.8409188985824585\n",
      "\n",
      "episode 14, policy loss 0.840919017791748\n",
      "\n",
      "episode 15, policy loss 0.8409196138381958\n",
      "\n",
      "episode 16, policy loss 0.8409205675125122\n",
      "\n",
      "Policy train loss in epoch 0:0.8409195244312286\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.8409196734428406\n",
      "\n",
      "episode 2, policy loss 0.8409193754196167\n",
      "\n",
      "episode 3, policy loss 0.8409196138381958\n",
      "\n",
      "episode 4, policy loss 0.8409205675125122\n",
      "\n",
      "episode 5, policy loss 0.8409202098846436\n",
      "\n",
      "episode 6, policy loss 0.8409200310707092\n",
      "\n",
      "episode 7, policy loss 0.840919017791748\n",
      "\n",
      "episode 8, policy loss 0.8409184813499451\n",
      "\n",
      "episode 9, policy loss 0.8409194946289062\n",
      "\n",
      "episode 10, policy loss 0.8409191966056824\n",
      "\n",
      "episode 11, policy loss 0.8409196138381958\n",
      "\n",
      "episode 12, policy loss 0.840919017791748\n",
      "\n",
      "episode 13, policy loss 0.8409199714660645\n",
      "\n",
      "episode 14, policy loss 0.8409192562103271\n",
      "\n",
      "episode 15, policy loss 0.8409188985824585\n",
      "\n",
      "episode 16, policy loss 0.8409199714660645\n",
      "\n",
      "Policy train loss in epoch 1:0.8409195244312286\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.8409193754196167\n",
      "\n",
      "episode 2, policy loss 0.8409196734428406\n",
      "\n",
      "episode 3, policy loss 0.8409199714660645\n",
      "\n",
      "episode 4, policy loss 0.8409188985824585\n",
      "\n",
      "episode 5, policy loss 0.8409196138381958\n",
      "\n",
      "episode 6, policy loss 0.8409192562103271\n",
      "\n",
      "episode 7, policy loss 0.840919017791748\n",
      "\n",
      "episode 8, policy loss 0.8409194946289062\n",
      "\n",
      "episode 9, policy loss 0.8409196138381958\n",
      "\n",
      "episode 10, policy loss 0.8409200310707092\n",
      "\n",
      "episode 11, policy loss 0.8409199714660645\n",
      "\n",
      "episode 12, policy loss 0.8409191966056824\n",
      "\n",
      "episode 13, policy loss 0.8409202098846436\n",
      "\n",
      "episode 14, policy loss 0.840919017791748\n",
      "\n",
      "episode 15, policy loss 0.8409205675125122\n",
      "\n",
      "episode 16, policy loss 0.8409184813499451\n",
      "\n",
      "Policy train loss in epoch 2:0.8409195244312286\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.8409196734428406\n",
      "\n",
      "episode 2, policy loss 0.8409192562103271\n",
      "\n",
      "episode 3, policy loss 0.8409196138381958\n",
      "\n",
      "episode 4, policy loss 0.840919017791748\n",
      "\n",
      "episode 5, policy loss 0.8409199714660645\n",
      "\n",
      "episode 6, policy loss 0.8409194946289062\n",
      "\n",
      "episode 7, policy loss 0.8409200310707092\n",
      "\n",
      "episode 8, policy loss 0.8409193754196167\n",
      "\n",
      "episode 9, policy loss 0.8409205675125122\n",
      "\n",
      "episode 10, policy loss 0.8409202098846436\n",
      "\n",
      "episode 11, policy loss 0.8409191966056824\n",
      "\n",
      "episode 12, policy loss 0.840919017791748\n",
      "\n",
      "episode 13, policy loss 0.8409188985824585\n",
      "\n",
      "episode 14, policy loss 0.8409184813499451\n",
      "\n",
      "episode 15, policy loss 0.8409196138381958\n",
      "\n",
      "episode 16, policy loss 0.8409199714660645\n",
      "\n",
      "Policy train loss in epoch 3:0.8409195244312286\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7602584958076477\n",
      "\n",
      "episode 2, val func loss 0.735001802444458\n",
      "\n",
      "episode 3, val func loss 0.8037235736846924\n",
      "\n",
      "episode 4, val func loss 0.7002643346786499\n",
      "\n",
      "episode 5, val func loss 0.7648683190345764\n",
      "\n",
      "episode 6, val func loss 0.7411454319953918\n",
      "\n",
      "episode 7, val func loss 0.7884811758995056\n",
      "\n",
      "episode 8, val func loss 0.6467926502227783\n",
      "\n",
      "episode 9, val func loss 0.791622519493103\n",
      "\n",
      "episode 10, val func loss 0.7124742269515991\n",
      "\n",
      "episode 11, val func loss 0.7550483345985413\n",
      "\n",
      "episode 12, val func loss 0.8412688970565796\n",
      "\n",
      "episode 13, val func loss 0.616044282913208\n",
      "\n",
      "episode 14, val func loss 0.7350702881813049\n",
      "\n",
      "episode 15, val func loss 0.7280563116073608\n",
      "\n",
      "episode 16, val func loss 0.7572266459465027\n",
      "\n",
      "Val func train loss in epoch 0:0.7423342056572437\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.6931530833244324\n",
      "\n",
      "episode 2, val func loss 0.7102847695350647\n",
      "\n",
      "episode 3, val func loss 0.6721972227096558\n",
      "\n",
      "episode 4, val func loss 0.6268028020858765\n",
      "\n",
      "episode 5, val func loss 0.6961108446121216\n",
      "\n",
      "episode 6, val func loss 0.6754239797592163\n",
      "\n",
      "episode 7, val func loss 0.8144698143005371\n",
      "\n",
      "episode 8, val func loss 0.7882872819900513\n",
      "\n",
      "episode 9, val func loss 0.7444481253623962\n",
      "\n",
      "episode 10, val func loss 0.7214851379394531\n",
      "\n",
      "episode 11, val func loss 0.7184022068977356\n",
      "\n",
      "episode 12, val func loss 0.7033324241638184\n",
      "\n",
      "episode 13, val func loss 0.682218074798584\n",
      "\n",
      "episode 14, val func loss 0.7839362025260925\n",
      "\n",
      "episode 15, val func loss 0.7101209163665771\n",
      "\n",
      "episode 16, val func loss 0.7046739459037781\n",
      "\n",
      "Val func train loss in epoch 1:0.7153341770172119\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.83612060546875\n",
      "\n",
      "episode 2, val func loss 0.7962391376495361\n",
      "\n",
      "episode 3, val func loss 0.8312253952026367\n",
      "\n",
      "episode 4, val func loss 0.7536519765853882\n",
      "\n",
      "episode 5, val func loss 0.9348241090774536\n",
      "\n",
      "episode 6, val func loss 0.8840035200119019\n",
      "\n",
      "episode 7, val func loss 0.8930578827857971\n",
      "\n",
      "episode 8, val func loss 0.8005218505859375\n",
      "\n",
      "episode 9, val func loss 0.7100118398666382\n",
      "\n",
      "episode 10, val func loss 0.9972047805786133\n",
      "\n",
      "episode 11, val func loss 0.7024043798446655\n",
      "\n",
      "episode 12, val func loss 0.7507776021957397\n",
      "\n",
      "episode 13, val func loss 0.821558952331543\n",
      "\n",
      "episode 14, val func loss 0.64488285779953\n",
      "\n",
      "episode 15, val func loss 0.7845044732093811\n",
      "\n",
      "episode 16, val func loss 1.0735067129135132\n",
      "\n",
      "Val func train loss in epoch 2:0.8259060047566891\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.7011752128601074\n",
      "\n",
      "episode 2, val func loss 1.291313886642456\n",
      "\n",
      "episode 3, val func loss 0.8062551617622375\n",
      "\n",
      "episode 4, val func loss 0.9377084374427795\n",
      "\n",
      "episode 5, val func loss 0.9487950205802917\n",
      "\n",
      "episode 6, val func loss 0.6697893142700195\n",
      "\n",
      "episode 7, val func loss 1.011560082435608\n",
      "\n",
      "episode 8, val func loss 1.0105422735214233\n",
      "\n",
      "episode 9, val func loss 0.7784838676452637\n",
      "\n",
      "episode 10, val func loss 0.7826997637748718\n",
      "\n",
      "episode 11, val func loss 0.8949083685874939\n",
      "\n",
      "episode 12, val func loss 0.6753904223442078\n",
      "\n",
      "episode 13, val func loss 0.8087513446807861\n",
      "\n",
      "episode 14, val func loss 0.9362574219703674\n",
      "\n",
      "episode 15, val func loss 0.867344319820404\n",
      "\n",
      "episode 16, val func loss 0.7859094142913818\n",
      "\n",
      "Val func train loss in epoch 3:0.8691802695393562\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6742842197418213\n",
      "\n",
      "episode 2, val func loss 0.8033767342567444\n",
      "\n",
      "episode 3, val func loss 0.7765193581581116\n",
      "\n",
      "episode 4, val func loss 0.7482830882072449\n",
      "\n",
      "episode 5, val func loss 0.7619267702102661\n",
      "\n",
      "episode 6, val func loss 0.7685315012931824\n",
      "\n",
      "episode 7, val func loss 0.8012889623641968\n",
      "\n",
      "episode 8, val func loss 0.7654940485954285\n",
      "\n",
      "episode 9, val func loss 0.7296207547187805\n",
      "\n",
      "episode 10, val func loss 0.7116824388504028\n",
      "\n",
      "episode 11, val func loss 0.7256373763084412\n",
      "\n",
      "episode 12, val func loss 0.758657693862915\n",
      "\n",
      "episode 13, val func loss 0.7238302230834961\n",
      "\n",
      "episode 14, val func loss 0.9248805046081543\n",
      "\n",
      "episode 15, val func loss 0.7377918362617493\n",
      "\n",
      "episode 16, val func loss 0.8164054155349731\n",
      "\n",
      "Val func train loss in epoch 4:0.7642631828784943\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.677373468875885\n",
      "\n",
      "episode 2, val func loss 0.7062064409255981\n",
      "\n",
      "episode 3, val func loss 0.7310193777084351\n",
      "\n",
      "episode 4, val func loss 0.7002040147781372\n",
      "\n",
      "episode 5, val func loss 0.6470242738723755\n",
      "\n",
      "episode 6, val func loss 0.7007429599761963\n",
      "\n",
      "episode 7, val func loss 0.701717734336853\n",
      "\n",
      "episode 8, val func loss 0.7816616892814636\n",
      "\n",
      "episode 9, val func loss 0.7299020886421204\n",
      "\n",
      "episode 10, val func loss 0.7266815304756165\n",
      "\n",
      "episode 11, val func loss 0.815073549747467\n",
      "\n",
      "episode 12, val func loss 0.8221464157104492\n",
      "\n",
      "episode 13, val func loss 0.6982214450836182\n",
      "\n",
      "episode 14, val func loss 0.7677595615386963\n",
      "\n",
      "episode 15, val func loss 0.7884912490844727\n",
      "\n",
      "episode 16, val func loss 0.7631089091300964\n",
      "\n",
      "Val func train loss in epoch 5:0.7348334193229675\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8053590059280396\n",
      "\n",
      "episode 2, val func loss 0.7224855422973633\n",
      "\n",
      "episode 3, val func loss 0.8033343553543091\n",
      "\n",
      "episode 4, val func loss 0.7232437133789062\n",
      "\n",
      "episode 5, val func loss 0.7689449787139893\n",
      "\n",
      "episode 6, val func loss 0.7707685828208923\n",
      "\n",
      "episode 7, val func loss 0.710326075553894\n",
      "\n",
      "episode 8, val func loss 0.7760958075523376\n",
      "\n",
      "episode 9, val func loss 0.8304529190063477\n",
      "\n",
      "episode 10, val func loss 0.7502018809318542\n",
      "\n",
      "episode 11, val func loss 0.8349842429161072\n",
      "\n",
      "episode 12, val func loss 0.7862563729286194\n",
      "\n",
      "episode 13, val func loss 0.7401275634765625\n",
      "\n",
      "episode 14, val func loss 0.78178471326828\n",
      "\n",
      "episode 15, val func loss 0.7817159295082092\n",
      "\n",
      "episode 16, val func loss 0.816845715045929\n",
      "\n",
      "Val func train loss in epoch 6:0.7751829624176025\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.912390410900116\n",
      "\n",
      "episode 2, val func loss 0.795297384262085\n",
      "\n",
      "episode 3, val func loss 0.8195266723632812\n",
      "\n",
      "episode 4, val func loss 0.6780133247375488\n",
      "\n",
      "episode 5, val func loss 0.7621328830718994\n",
      "\n",
      "episode 6, val func loss 0.7297177910804749\n",
      "\n",
      "episode 7, val func loss 0.866506814956665\n",
      "\n",
      "episode 8, val func loss 0.7532329559326172\n",
      "\n",
      "episode 9, val func loss 0.8638699054718018\n",
      "\n",
      "episode 10, val func loss 0.8704310655593872\n",
      "\n",
      "episode 11, val func loss 0.7962662577629089\n",
      "\n",
      "episode 12, val func loss 0.9117507934570312\n",
      "\n",
      "episode 13, val func loss 0.7424821853637695\n",
      "\n",
      "episode 14, val func loss 0.7998933792114258\n",
      "\n",
      "episode 15, val func loss 0.7249575257301331\n",
      "\n",
      "episode 16, val func loss 0.8146452307701111\n",
      "\n",
      "Val func train loss in epoch 7:0.8025696612894535\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8070583343505859\n",
      "\n",
      "episode 2, val func loss 0.747223973274231\n",
      "\n",
      "episode 3, val func loss 0.6802194118499756\n",
      "\n",
      "episode 4, val func loss 0.789630651473999\n",
      "\n",
      "episode 5, val func loss 0.7273101806640625\n",
      "\n",
      "episode 6, val func loss 0.6918423175811768\n",
      "\n",
      "episode 7, val func loss 0.8879680633544922\n",
      "\n",
      "episode 8, val func loss 0.6992324590682983\n",
      "\n",
      "episode 9, val func loss 0.8367633819580078\n",
      "\n",
      "episode 10, val func loss 0.7547791004180908\n",
      "\n",
      "episode 11, val func loss 0.7769963145256042\n",
      "\n",
      "episode 12, val func loss 0.793576717376709\n",
      "\n",
      "episode 13, val func loss 0.7417813539505005\n",
      "\n",
      "episode 14, val func loss 0.7672669887542725\n",
      "\n",
      "episode 15, val func loss 0.7921773195266724\n",
      "\n",
      "episode 16, val func loss 0.9531088471412659\n",
      "\n",
      "Val func train loss in epoch 8:0.7779334634542465\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.7021899819374084\n",
      "\n",
      "episode 2, val func loss 0.7386220693588257\n",
      "\n",
      "episode 3, val func loss 0.7989946603775024\n",
      "\n",
      "episode 4, val func loss 0.6733669638633728\n",
      "\n",
      "episode 5, val func loss 1.0243868827819824\n",
      "\n",
      "episode 6, val func loss 0.8046435713768005\n",
      "\n",
      "episode 7, val func loss 0.649378776550293\n",
      "\n",
      "episode 8, val func loss 0.8294445872306824\n",
      "\n",
      "episode 9, val func loss 0.8782841563224792\n",
      "\n",
      "episode 10, val func loss 0.6650081276893616\n",
      "\n",
      "episode 11, val func loss 0.7864990234375\n",
      "\n",
      "episode 12, val func loss 0.810541570186615\n",
      "\n",
      "episode 13, val func loss 0.6750434637069702\n",
      "\n",
      "episode 14, val func loss 0.714447557926178\n",
      "\n",
      "episode 15, val func loss 0.9296755790710449\n",
      "\n",
      "episode 16, val func loss 0.8509067296981812\n",
      "\n",
      "Val func train loss in epoch 9:0.7832146063446999\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.882524847984314\n",
      "\n",
      "episode 2, val func loss 0.7998161315917969\n",
      "\n",
      "episode 3, val func loss 0.810986340045929\n",
      "\n",
      "episode 4, val func loss 0.8318830132484436\n",
      "\n",
      "episode 5, val func loss 0.8420066237449646\n",
      "\n",
      "episode 6, val func loss 0.847055196762085\n",
      "\n",
      "episode 7, val func loss 0.715644359588623\n",
      "\n",
      "episode 8, val func loss 0.8082438111305237\n",
      "\n",
      "episode 9, val func loss 0.8622005581855774\n",
      "\n",
      "episode 10, val func loss 0.796238362789154\n",
      "\n",
      "episode 11, val func loss 0.6971114873886108\n",
      "\n",
      "episode 12, val func loss 0.7902914881706238\n",
      "\n",
      "episode 13, val func loss 0.6599285006523132\n",
      "\n",
      "episode 14, val func loss 0.6457529664039612\n",
      "\n",
      "episode 15, val func loss 0.821707546710968\n",
      "\n",
      "episode 16, val func loss 0.7961662411689758\n",
      "\n",
      "Val func train loss in epoch 10:0.787972342222929\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7173916697502136\n",
      "\n",
      "episode 2, val func loss 0.6827659010887146\n",
      "\n",
      "episode 3, val func loss 0.8426399230957031\n",
      "\n",
      "episode 4, val func loss 0.7635241150856018\n",
      "\n",
      "episode 5, val func loss 0.720247209072113\n",
      "\n",
      "episode 6, val func loss 0.7206762433052063\n",
      "\n",
      "episode 7, val func loss 0.7592900991439819\n",
      "\n",
      "episode 8, val func loss 0.764262318611145\n",
      "\n",
      "episode 9, val func loss 0.6669201254844666\n",
      "\n",
      "episode 10, val func loss 0.7802452445030212\n",
      "\n",
      "episode 11, val func loss 0.7133458852767944\n",
      "\n",
      "episode 12, val func loss 0.6782113909721375\n",
      "\n",
      "episode 13, val func loss 0.8555909991264343\n",
      "\n",
      "episode 14, val func loss 0.8082441687583923\n",
      "\n",
      "episode 15, val func loss 0.7716971635818481\n",
      "\n",
      "episode 16, val func loss 0.7833141088485718\n",
      "\n",
      "Val func train loss in epoch 11:0.7517729103565216\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.8344228863716125\n",
      "\n",
      "episode 2, val func loss 0.7320902347564697\n",
      "\n",
      "episode 3, val func loss 0.746644914150238\n",
      "\n",
      "episode 4, val func loss 0.8493828177452087\n",
      "\n",
      "episode 5, val func loss 0.7214231491088867\n",
      "\n",
      "episode 6, val func loss 0.6870456337928772\n",
      "\n",
      "episode 7, val func loss 0.778290331363678\n",
      "\n",
      "episode 8, val func loss 0.8510576486587524\n",
      "\n",
      "episode 9, val func loss 0.7216680645942688\n",
      "\n",
      "episode 10, val func loss 0.7236886620521545\n",
      "\n",
      "episode 11, val func loss 0.8196724653244019\n",
      "\n",
      "episode 12, val func loss 0.6965763568878174\n",
      "\n",
      "episode 13, val func loss 0.7571520805358887\n",
      "\n",
      "episode 14, val func loss 0.7648314833641052\n",
      "\n",
      "episode 15, val func loss 0.7888810038566589\n",
      "\n",
      "episode 16, val func loss 0.7535772919654846\n",
      "\n",
      "Val func train loss in epoch 12:0.7641503140330315\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8451078534126282\n",
      "\n",
      "episode 2, val func loss 0.7686426639556885\n",
      "\n",
      "episode 3, val func loss 0.8416204452514648\n",
      "\n",
      "episode 4, val func loss 0.7764683961868286\n",
      "\n",
      "episode 5, val func loss 0.7417513132095337\n",
      "\n",
      "episode 6, val func loss 0.7740539312362671\n",
      "\n",
      "episode 7, val func loss 0.8184709548950195\n",
      "\n",
      "episode 8, val func loss 0.822749137878418\n",
      "\n",
      "episode 9, val func loss 0.8167112469673157\n",
      "\n",
      "episode 10, val func loss 0.6898741722106934\n",
      "\n",
      "episode 11, val func loss 0.691010057926178\n",
      "\n",
      "episode 12, val func loss 0.7256391644477844\n",
      "\n",
      "episode 13, val func loss 0.6977580785751343\n",
      "\n",
      "episode 14, val func loss 0.8073880076408386\n",
      "\n",
      "episode 15, val func loss 0.7917346358299255\n",
      "\n",
      "episode 16, val func loss 0.8427393436431885\n",
      "\n",
      "Val func train loss in epoch 13:0.7782324627041817\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7931349277496338\n",
      "\n",
      "episode 2, val func loss 0.8027642369270325\n",
      "\n",
      "episode 3, val func loss 0.8205394148826599\n",
      "\n",
      "episode 4, val func loss 0.6369338035583496\n",
      "\n",
      "episode 5, val func loss 0.8093457818031311\n",
      "\n",
      "episode 6, val func loss 0.803548276424408\n",
      "\n",
      "episode 7, val func loss 0.8172264099121094\n",
      "\n",
      "episode 8, val func loss 0.7706140875816345\n",
      "\n",
      "episode 9, val func loss 0.7619344592094421\n",
      "\n",
      "episode 10, val func loss 0.701151967048645\n",
      "\n",
      "episode 11, val func loss 0.7258514761924744\n",
      "\n",
      "episode 12, val func loss 0.6628812551498413\n",
      "\n",
      "episode 13, val func loss 0.7851625680923462\n",
      "\n",
      "episode 14, val func loss 0.7782908082008362\n",
      "\n",
      "episode 15, val func loss 0.6999104022979736\n",
      "\n",
      "episode 16, val func loss 0.6978914737701416\n",
      "\n",
      "Val func train loss in epoch 14:0.7541988343000412\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7947914600372314\n",
      "\n",
      "episode 2, val func loss 0.7561658620834351\n",
      "\n",
      "episode 3, val func loss 0.7105733156204224\n",
      "\n",
      "episode 4, val func loss 0.7444209456443787\n",
      "\n",
      "episode 5, val func loss 0.7279173731803894\n",
      "\n",
      "episode 6, val func loss 0.7578304409980774\n",
      "\n",
      "episode 7, val func loss 0.7549097537994385\n",
      "\n",
      "episode 8, val func loss 0.8493380546569824\n",
      "\n",
      "episode 9, val func loss 0.686488151550293\n",
      "\n",
      "episode 10, val func loss 0.7813563346862793\n",
      "\n",
      "episode 11, val func loss 0.6795580387115479\n",
      "\n",
      "episode 12, val func loss 0.730972945690155\n",
      "\n",
      "episode 13, val func loss 0.7497155666351318\n",
      "\n",
      "episode 14, val func loss 0.7477062344551086\n",
      "\n",
      "episode 15, val func loss 0.7000581622123718\n",
      "\n",
      "episode 16, val func loss 0.7378632426261902\n",
      "\n",
      "Val func train loss in epoch 15:0.7443541176617146\n",
      "***********************TIME WAS 4.84211577574412 min*****************************\n",
      "\n",
      "**********************ROUND 61 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.0578924417495728\n",
      "\n",
      "episode 2, policy loss 1.057892084121704\n",
      "\n",
      "episode 3, policy loss 1.0578914880752563\n",
      "\n",
      "episode 4, policy loss 1.0578925609588623\n",
      "\n",
      "episode 5, policy loss 1.0578917264938354\n",
      "\n",
      "episode 6, policy loss 1.057891845703125\n",
      "\n",
      "episode 7, policy loss 1.0578924417495728\n",
      "\n",
      "episode 8, policy loss 1.0578933954238892\n",
      "\n",
      "episode 9, policy loss 1.0578914880752563\n",
      "\n",
      "episode 10, policy loss 1.0578924417495728\n",
      "\n",
      "episode 11, policy loss 1.057891845703125\n",
      "\n",
      "episode 12, policy loss 1.057891845703125\n",
      "\n",
      "episode 13, policy loss 1.0578925609588623\n",
      "\n",
      "episode 14, policy loss 1.0578927993774414\n",
      "\n",
      "episode 15, policy loss 1.0578943490982056\n",
      "\n",
      "episode 16, policy loss 1.0578930377960205\n",
      "\n",
      "Policy train loss in epoch 0:1.0578923970460892\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.0578924417495728\n",
      "\n",
      "episode 2, policy loss 1.0578914880752563\n",
      "\n",
      "episode 3, policy loss 1.057891845703125\n",
      "\n",
      "episode 4, policy loss 1.0578924417495728\n",
      "\n",
      "episode 5, policy loss 1.057892084121704\n",
      "\n",
      "episode 6, policy loss 1.0578917264938354\n",
      "\n",
      "episode 7, policy loss 1.0578925609588623\n",
      "\n",
      "episode 8, policy loss 1.0578933954238892\n",
      "\n",
      "episode 9, policy loss 1.057891845703125\n",
      "\n",
      "episode 10, policy loss 1.057891845703125\n",
      "\n",
      "episode 11, policy loss 1.0578930377960205\n",
      "\n",
      "episode 12, policy loss 1.0578927993774414\n",
      "\n",
      "episode 13, policy loss 1.0578914880752563\n",
      "\n",
      "episode 14, policy loss 1.0578943490982056\n",
      "\n",
      "episode 15, policy loss 1.0578924417495728\n",
      "\n",
      "episode 16, policy loss 1.0578925609588623\n",
      "\n",
      "Policy train loss in epoch 1:1.0578923970460892\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.0578925609588623\n",
      "\n",
      "episode 2, policy loss 1.0578914880752563\n",
      "\n",
      "episode 3, policy loss 1.0578927993774414\n",
      "\n",
      "episode 4, policy loss 1.0578925609588623\n",
      "\n",
      "episode 5, policy loss 1.0578924417495728\n",
      "\n",
      "episode 6, policy loss 1.0578917264938354\n",
      "\n",
      "episode 7, policy loss 1.0578924417495728\n",
      "\n",
      "episode 8, policy loss 1.0578924417495728\n",
      "\n",
      "episode 9, policy loss 1.057891845703125\n",
      "\n",
      "episode 10, policy loss 1.0578914880752563\n",
      "\n",
      "episode 11, policy loss 1.057892084121704\n",
      "\n",
      "episode 12, policy loss 1.057891845703125\n",
      "\n",
      "episode 13, policy loss 1.0578933954238892\n",
      "\n",
      "episode 14, policy loss 1.0578930377960205\n",
      "\n",
      "episode 15, policy loss 1.057891845703125\n",
      "\n",
      "episode 16, policy loss 1.0578943490982056\n",
      "\n",
      "Policy train loss in epoch 2:1.0578923970460892\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.057891845703125\n",
      "\n",
      "episode 2, policy loss 1.0578927993774414\n",
      "\n",
      "episode 3, policy loss 1.0578925609588623\n",
      "\n",
      "episode 4, policy loss 1.057892084121704\n",
      "\n",
      "episode 5, policy loss 1.0578914880752563\n",
      "\n",
      "episode 6, policy loss 1.0578925609588623\n",
      "\n",
      "episode 7, policy loss 1.0578930377960205\n",
      "\n",
      "episode 8, policy loss 1.0578943490982056\n",
      "\n",
      "episode 9, policy loss 1.0578924417495728\n",
      "\n",
      "episode 10, policy loss 1.0578914880752563\n",
      "\n",
      "episode 11, policy loss 1.0578917264938354\n",
      "\n",
      "episode 12, policy loss 1.0578924417495728\n",
      "\n",
      "episode 13, policy loss 1.0578933954238892\n",
      "\n",
      "episode 14, policy loss 1.057891845703125\n",
      "\n",
      "episode 15, policy loss 1.057891845703125\n",
      "\n",
      "episode 16, policy loss 1.0578924417495728\n",
      "\n",
      "Policy train loss in epoch 3:1.0578923970460892\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7309361696243286\n",
      "\n",
      "episode 2, val func loss 0.7580970525741577\n",
      "\n",
      "episode 3, val func loss 0.6905908584594727\n",
      "\n",
      "episode 4, val func loss 0.6806954741477966\n",
      "\n",
      "episode 5, val func loss 0.6740277409553528\n",
      "\n",
      "episode 6, val func loss 0.6424931287765503\n",
      "\n",
      "episode 7, val func loss 0.718730628490448\n",
      "\n",
      "episode 8, val func loss 0.6759687662124634\n",
      "\n",
      "episode 9, val func loss 0.6713419556617737\n",
      "\n",
      "episode 10, val func loss 0.6508865356445312\n",
      "\n",
      "episode 11, val func loss 0.8146770596504211\n",
      "\n",
      "episode 12, val func loss 0.8511281609535217\n",
      "\n",
      "episode 13, val func loss 0.7346936464309692\n",
      "\n",
      "episode 14, val func loss 0.8880711793899536\n",
      "\n",
      "episode 15, val func loss 0.7783108949661255\n",
      "\n",
      "episode 16, val func loss 0.7893577218055725\n",
      "\n",
      "Val func train loss in epoch 0:0.7343754358589649\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8668193221092224\n",
      "\n",
      "episode 2, val func loss 0.6370425820350647\n",
      "\n",
      "episode 3, val func loss 0.7921502590179443\n",
      "\n",
      "episode 4, val func loss 0.7874414324760437\n",
      "\n",
      "episode 5, val func loss 0.7700029015541077\n",
      "\n",
      "episode 6, val func loss 0.7146245241165161\n",
      "\n",
      "episode 7, val func loss 0.8200541138648987\n",
      "\n",
      "episode 8, val func loss 0.683786153793335\n",
      "\n",
      "episode 9, val func loss 0.7337616086006165\n",
      "\n",
      "episode 10, val func loss 0.8223487138748169\n",
      "\n",
      "episode 11, val func loss 0.8122666478157043\n",
      "\n",
      "episode 12, val func loss 0.7979230880737305\n",
      "\n",
      "episode 13, val func loss 0.6983823776245117\n",
      "\n",
      "episode 14, val func loss 0.8942775726318359\n",
      "\n",
      "episode 15, val func loss 0.8441200256347656\n",
      "\n",
      "episode 16, val func loss 0.7579152584075928\n",
      "\n",
      "Val func train loss in epoch 1:0.7770572863519192\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.827123761177063\n",
      "\n",
      "episode 2, val func loss 0.7387022972106934\n",
      "\n",
      "episode 3, val func loss 0.7185894846916199\n",
      "\n",
      "episode 4, val func loss 0.7038018703460693\n",
      "\n",
      "episode 5, val func loss 0.667706310749054\n",
      "\n",
      "episode 6, val func loss 0.8048877716064453\n",
      "\n",
      "episode 7, val func loss 0.7598478198051453\n",
      "\n",
      "episode 8, val func loss 0.7072451114654541\n",
      "\n",
      "episode 9, val func loss 0.6920214891433716\n",
      "\n",
      "episode 10, val func loss 0.714330792427063\n",
      "\n",
      "episode 11, val func loss 0.766801118850708\n",
      "\n",
      "episode 12, val func loss 0.6951776146888733\n",
      "\n",
      "episode 13, val func loss 0.6924702525138855\n",
      "\n",
      "episode 14, val func loss 0.7198401093482971\n",
      "\n",
      "episode 15, val func loss 0.73885178565979\n",
      "\n",
      "episode 16, val func loss 0.666792631149292\n",
      "\n",
      "Val func train loss in epoch 2:0.7258868888020515\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8071967363357544\n",
      "\n",
      "episode 2, val func loss 0.7282351851463318\n",
      "\n",
      "episode 3, val func loss 0.8091987371444702\n",
      "\n",
      "episode 4, val func loss 0.6859136819839478\n",
      "\n",
      "episode 5, val func loss 0.8436020016670227\n",
      "\n",
      "episode 6, val func loss 0.9579288959503174\n",
      "\n",
      "episode 7, val func loss 0.818400502204895\n",
      "\n",
      "episode 8, val func loss 0.828032910823822\n",
      "\n",
      "episode 9, val func loss 0.9540333151817322\n",
      "\n",
      "episode 10, val func loss 0.6786099076271057\n",
      "\n",
      "episode 11, val func loss 0.7078859806060791\n",
      "\n",
      "episode 12, val func loss 0.933750331401825\n",
      "\n",
      "episode 13, val func loss 0.9349405169487\n",
      "\n",
      "episode 14, val func loss 0.7517761588096619\n",
      "\n",
      "episode 15, val func loss 0.7989364266395569\n",
      "\n",
      "episode 16, val func loss 0.7915483117103577\n",
      "\n",
      "Val func train loss in epoch 3:0.8143743500113487\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8550097346305847\n",
      "\n",
      "episode 2, val func loss 0.749950110912323\n",
      "\n",
      "episode 3, val func loss 0.8062469959259033\n",
      "\n",
      "episode 4, val func loss 0.8446255922317505\n",
      "\n",
      "episode 5, val func loss 0.8220133185386658\n",
      "\n",
      "episode 6, val func loss 0.7783400416374207\n",
      "\n",
      "episode 7, val func loss 0.9568305015563965\n",
      "\n",
      "episode 8, val func loss 0.797526478767395\n",
      "\n",
      "episode 9, val func loss 0.7411473989486694\n",
      "\n",
      "episode 10, val func loss 0.7807378768920898\n",
      "\n",
      "episode 11, val func loss 0.6840019226074219\n",
      "\n",
      "episode 12, val func loss 0.7074084281921387\n",
      "\n",
      "episode 13, val func loss 0.8183737397193909\n",
      "\n",
      "episode 14, val func loss 0.781972348690033\n",
      "\n",
      "episode 15, val func loss 0.8073418736457825\n",
      "\n",
      "episode 16, val func loss 0.7738865613937378\n",
      "\n",
      "Val func train loss in epoch 4:0.7940883077681065\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7825486660003662\n",
      "\n",
      "episode 2, val func loss 0.7334510087966919\n",
      "\n",
      "episode 3, val func loss 0.7700497508049011\n",
      "\n",
      "episode 4, val func loss 0.7419247031211853\n",
      "\n",
      "episode 5, val func loss 0.6577918529510498\n",
      "\n",
      "episode 6, val func loss 0.7749311923980713\n",
      "\n",
      "episode 7, val func loss 0.7511724233627319\n",
      "\n",
      "episode 8, val func loss 0.7754302620887756\n",
      "\n",
      "episode 9, val func loss 0.67409747838974\n",
      "\n",
      "episode 10, val func loss 0.8614460825920105\n",
      "\n",
      "episode 11, val func loss 0.7319850921630859\n",
      "\n",
      "episode 12, val func loss 0.72395259141922\n",
      "\n",
      "episode 13, val func loss 0.7448017597198486\n",
      "\n",
      "episode 14, val func loss 0.7811731696128845\n",
      "\n",
      "episode 15, val func loss 0.6919596791267395\n",
      "\n",
      "episode 16, val func loss 0.6951723694801331\n",
      "\n",
      "Val func train loss in epoch 5:0.7432430051267147\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.790402889251709\n",
      "\n",
      "episode 2, val func loss 0.7892714738845825\n",
      "\n",
      "episode 3, val func loss 0.6739563345909119\n",
      "\n",
      "episode 4, val func loss 0.7264381051063538\n",
      "\n",
      "episode 5, val func loss 0.8208606839179993\n",
      "\n",
      "episode 6, val func loss 0.6849635243415833\n",
      "\n",
      "episode 7, val func loss 0.6867617964744568\n",
      "\n",
      "episode 8, val func loss 0.8909681439399719\n",
      "\n",
      "episode 9, val func loss 0.6884242296218872\n",
      "\n",
      "episode 10, val func loss 0.8494713306427002\n",
      "\n",
      "episode 11, val func loss 0.7707940936088562\n",
      "\n",
      "episode 12, val func loss 0.8881719708442688\n",
      "\n",
      "episode 13, val func loss 0.6523721218109131\n",
      "\n",
      "episode 14, val func loss 0.8365886807441711\n",
      "\n",
      "episode 15, val func loss 0.9443721175193787\n",
      "\n",
      "episode 16, val func loss 0.7377704381942749\n",
      "\n",
      "Val func train loss in epoch 6:0.7769742459058762\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7655603289604187\n",
      "\n",
      "episode 2, val func loss 1.0607696771621704\n",
      "\n",
      "episode 3, val func loss 0.6934568285942078\n",
      "\n",
      "episode 4, val func loss 0.8934283256530762\n",
      "\n",
      "episode 5, val func loss 1.1437302827835083\n",
      "\n",
      "episode 6, val func loss 1.6654975414276123\n",
      "\n",
      "episode 7, val func loss 0.9400292634963989\n",
      "\n",
      "episode 8, val func loss 0.7089118361473083\n",
      "\n",
      "episode 9, val func loss 1.0205800533294678\n",
      "\n",
      "episode 10, val func loss 0.9656209945678711\n",
      "\n",
      "episode 11, val func loss 0.7786097526550293\n",
      "\n",
      "episode 12, val func loss 0.9974721074104309\n",
      "\n",
      "episode 13, val func loss 0.9160927534103394\n",
      "\n",
      "episode 14, val func loss 0.9933738708496094\n",
      "\n",
      "episode 15, val func loss 0.8398328423500061\n",
      "\n",
      "episode 16, val func loss 0.6945699453353882\n",
      "\n",
      "Val func train loss in epoch 7:0.9423460252583027\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8358740210533142\n",
      "\n",
      "episode 2, val func loss 0.7892095446586609\n",
      "\n",
      "episode 3, val func loss 0.7452603578567505\n",
      "\n",
      "episode 4, val func loss 0.7374538779258728\n",
      "\n",
      "episode 5, val func loss 0.8123030066490173\n",
      "\n",
      "episode 6, val func loss 0.7888868451118469\n",
      "\n",
      "episode 7, val func loss 0.8758171796798706\n",
      "\n",
      "episode 8, val func loss 0.7080302834510803\n",
      "\n",
      "episode 9, val func loss 0.7460805177688599\n",
      "\n",
      "episode 10, val func loss 0.7650728225708008\n",
      "\n",
      "episode 11, val func loss 0.7790535092353821\n",
      "\n",
      "episode 12, val func loss 0.8755791187286377\n",
      "\n",
      "episode 13, val func loss 0.8449085354804993\n",
      "\n",
      "episode 14, val func loss 0.9407483339309692\n",
      "\n",
      "episode 15, val func loss 0.8508933782577515\n",
      "\n",
      "episode 16, val func loss 0.7603395581245422\n",
      "\n",
      "Val func train loss in epoch 8:0.803469430655241\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6913657784461975\n",
      "\n",
      "episode 2, val func loss 0.7158606052398682\n",
      "\n",
      "episode 3, val func loss 0.6547653079032898\n",
      "\n",
      "episode 4, val func loss 0.7791101932525635\n",
      "\n",
      "episode 5, val func loss 0.74461829662323\n",
      "\n",
      "episode 6, val func loss 0.75539231300354\n",
      "\n",
      "episode 7, val func loss 0.7506991624832153\n",
      "\n",
      "episode 8, val func loss 0.6861940026283264\n",
      "\n",
      "episode 9, val func loss 0.8088586330413818\n",
      "\n",
      "episode 10, val func loss 0.8009267449378967\n",
      "\n",
      "episode 11, val func loss 0.7575435042381287\n",
      "\n",
      "episode 12, val func loss 0.7918704748153687\n",
      "\n",
      "episode 13, val func loss 0.6727724075317383\n",
      "\n",
      "episode 14, val func loss 0.7101672887802124\n",
      "\n",
      "episode 15, val func loss 0.7163117527961731\n",
      "\n",
      "episode 16, val func loss 0.6447010040283203\n",
      "\n",
      "Val func train loss in epoch 9:0.7300723418593407\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7423421144485474\n",
      "\n",
      "episode 2, val func loss 0.7841783761978149\n",
      "\n",
      "episode 3, val func loss 0.7248274683952332\n",
      "\n",
      "episode 4, val func loss 0.7863373160362244\n",
      "\n",
      "episode 5, val func loss 0.6796345710754395\n",
      "\n",
      "episode 6, val func loss 0.7414675354957581\n",
      "\n",
      "episode 7, val func loss 0.7319331765174866\n",
      "\n",
      "episode 8, val func loss 0.7888931035995483\n",
      "\n",
      "episode 9, val func loss 0.9283130764961243\n",
      "\n",
      "episode 10, val func loss 0.8021519184112549\n",
      "\n",
      "episode 11, val func loss 0.7451909184455872\n",
      "\n",
      "episode 12, val func loss 0.7828205227851868\n",
      "\n",
      "episode 13, val func loss 0.6613725423812866\n",
      "\n",
      "episode 14, val func loss 0.6919837594032288\n",
      "\n",
      "episode 15, val func loss 0.6966982483863831\n",
      "\n",
      "episode 16, val func loss 0.8453266620635986\n",
      "\n",
      "Val func train loss in epoch 10:0.7583419568836689\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7135893106460571\n",
      "\n",
      "episode 2, val func loss 0.691929817199707\n",
      "\n",
      "episode 3, val func loss 0.8468473553657532\n",
      "\n",
      "episode 4, val func loss 0.7021170258522034\n",
      "\n",
      "episode 5, val func loss 0.776473343372345\n",
      "\n",
      "episode 6, val func loss 0.6700470447540283\n",
      "\n",
      "episode 7, val func loss 0.7421412467956543\n",
      "\n",
      "episode 8, val func loss 0.8026056885719299\n",
      "\n",
      "episode 9, val func loss 0.7880598306655884\n",
      "\n",
      "episode 10, val func loss 0.7590522766113281\n",
      "\n",
      "episode 11, val func loss 0.6617032289505005\n",
      "\n",
      "episode 12, val func loss 0.7236968278884888\n",
      "\n",
      "episode 13, val func loss 0.6936848163604736\n",
      "\n",
      "episode 14, val func loss 0.7990877032279968\n",
      "\n",
      "episode 15, val func loss 0.6520839333534241\n",
      "\n",
      "episode 16, val func loss 0.7666777968406677\n",
      "\n",
      "Val func train loss in epoch 11:0.7368623279035091\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6974276900291443\n",
      "\n",
      "episode 2, val func loss 0.7858728766441345\n",
      "\n",
      "episode 3, val func loss 0.7939978837966919\n",
      "\n",
      "episode 4, val func loss 0.7479216456413269\n",
      "\n",
      "episode 5, val func loss 0.7966139316558838\n",
      "\n",
      "episode 6, val func loss 0.6496353149414062\n",
      "\n",
      "episode 7, val func loss 0.7322473526000977\n",
      "\n",
      "episode 8, val func loss 0.7086395621299744\n",
      "\n",
      "episode 9, val func loss 0.7312231063842773\n",
      "\n",
      "episode 10, val func loss 0.7401569485664368\n",
      "\n",
      "episode 11, val func loss 0.7184219360351562\n",
      "\n",
      "episode 12, val func loss 0.6799749135971069\n",
      "\n",
      "episode 13, val func loss 0.8783667087554932\n",
      "\n",
      "episode 14, val func loss 0.7969005703926086\n",
      "\n",
      "episode 15, val func loss 0.8144105076789856\n",
      "\n",
      "episode 16, val func loss 0.6806982159614563\n",
      "\n",
      "Val func train loss in epoch 12:0.7470318228006363\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8158577680587769\n",
      "\n",
      "episode 2, val func loss 0.7943949103355408\n",
      "\n",
      "episode 3, val func loss 0.6981455683708191\n",
      "\n",
      "episode 4, val func loss 0.8948465585708618\n",
      "\n",
      "episode 5, val func loss 0.677416205406189\n",
      "\n",
      "episode 6, val func loss 0.7497225403785706\n",
      "\n",
      "episode 7, val func loss 0.7465088963508606\n",
      "\n",
      "episode 8, val func loss 0.7673161029815674\n",
      "\n",
      "episode 9, val func loss 0.6422469019889832\n",
      "\n",
      "episode 10, val func loss 0.751259446144104\n",
      "\n",
      "episode 11, val func loss 0.6828480958938599\n",
      "\n",
      "episode 12, val func loss 0.6991468071937561\n",
      "\n",
      "episode 13, val func loss 0.742336630821228\n",
      "\n",
      "episode 14, val func loss 0.6751701831817627\n",
      "\n",
      "episode 15, val func loss 0.6969224810600281\n",
      "\n",
      "episode 16, val func loss 0.6672698259353638\n",
      "\n",
      "Val func train loss in epoch 13:0.731338057667017\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6991825103759766\n",
      "\n",
      "episode 2, val func loss 0.7355954051017761\n",
      "\n",
      "episode 3, val func loss 0.7121126055717468\n",
      "\n",
      "episode 4, val func loss 0.9552061557769775\n",
      "\n",
      "episode 5, val func loss 0.7243931293487549\n",
      "\n",
      "episode 6, val func loss 0.8556766510009766\n",
      "\n",
      "episode 7, val func loss 0.7402790784835815\n",
      "\n",
      "episode 8, val func loss 0.7313192486763\n",
      "\n",
      "episode 9, val func loss 0.7794699668884277\n",
      "\n",
      "episode 10, val func loss 0.7769052982330322\n",
      "\n",
      "episode 11, val func loss 0.7877961993217468\n",
      "\n",
      "episode 12, val func loss 0.7714639902114868\n",
      "\n",
      "episode 13, val func loss 0.7414681911468506\n",
      "\n",
      "episode 14, val func loss 0.8737205862998962\n",
      "\n",
      "episode 15, val func loss 0.8897675275802612\n",
      "\n",
      "episode 16, val func loss 0.7449803948402405\n",
      "\n",
      "Val func train loss in epoch 14:0.782458558678627\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7481398582458496\n",
      "\n",
      "episode 2, val func loss 0.7385960817337036\n",
      "\n",
      "episode 3, val func loss 0.7984481453895569\n",
      "\n",
      "episode 4, val func loss 0.8502131700515747\n",
      "\n",
      "episode 5, val func loss 0.821249783039093\n",
      "\n",
      "episode 6, val func loss 0.7919877171516418\n",
      "\n",
      "episode 7, val func loss 0.8236098885536194\n",
      "\n",
      "episode 8, val func loss 0.8106709718704224\n",
      "\n",
      "episode 9, val func loss 0.7615144848823547\n",
      "\n",
      "episode 10, val func loss 0.9755987524986267\n",
      "\n",
      "episode 11, val func loss 0.7757858037948608\n",
      "\n",
      "episode 12, val func loss 0.6863846182823181\n",
      "\n",
      "episode 13, val func loss 0.934265673160553\n",
      "\n",
      "episode 14, val func loss 0.7959883213043213\n",
      "\n",
      "episode 15, val func loss 0.6706311106681824\n",
      "\n",
      "episode 16, val func loss 0.6996902823448181\n",
      "\n",
      "Val func train loss in epoch 15:0.7926734164357185\n",
      "***********************TIME WAS 4.843161300818125 min*****************************\n",
      "\n",
      "**********************ROUND 62 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.5169265270233154\n",
      "\n",
      "episode 2, policy loss 1.5169280767440796\n",
      "\n",
      "episode 3, policy loss 1.516927719116211\n",
      "\n",
      "episode 4, policy loss 1.5169273614883423\n",
      "\n",
      "episode 5, policy loss 1.516927719116211\n",
      "\n",
      "episode 6, policy loss 1.5169299840927124\n",
      "\n",
      "episode 7, policy loss 1.5169275999069214\n",
      "\n",
      "episode 8, policy loss 1.5169280767440796\n",
      "\n",
      "episode 9, policy loss 1.5169286727905273\n",
      "\n",
      "episode 10, policy loss 1.5169275999069214\n",
      "\n",
      "episode 11, policy loss 1.5169264078140259\n",
      "\n",
      "episode 12, policy loss 1.5169271230697632\n",
      "\n",
      "episode 13, policy loss 1.5169275999069214\n",
      "\n",
      "episode 14, policy loss 1.5169267654418945\n",
      "\n",
      "episode 15, policy loss 1.5169275999069214\n",
      "\n",
      "episode 16, policy loss 1.51692795753479\n",
      "\n",
      "Policy train loss in epoch 0:1.5169276744127274\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.5169280767440796\n",
      "\n",
      "episode 2, policy loss 1.5169265270233154\n",
      "\n",
      "episode 3, policy loss 1.5169275999069214\n",
      "\n",
      "episode 4, policy loss 1.5169286727905273\n",
      "\n",
      "episode 5, policy loss 1.516927719116211\n",
      "\n",
      "episode 6, policy loss 1.5169299840927124\n",
      "\n",
      "episode 7, policy loss 1.5169275999069214\n",
      "\n",
      "episode 8, policy loss 1.5169280767440796\n",
      "\n",
      "episode 9, policy loss 1.5169275999069214\n",
      "\n",
      "episode 10, policy loss 1.5169271230697632\n",
      "\n",
      "episode 11, policy loss 1.51692795753479\n",
      "\n",
      "episode 12, policy loss 1.516927719116211\n",
      "\n",
      "episode 13, policy loss 1.5169273614883423\n",
      "\n",
      "episode 14, policy loss 1.5169264078140259\n",
      "\n",
      "episode 15, policy loss 1.5169275999069214\n",
      "\n",
      "episode 16, policy loss 1.5169267654418945\n",
      "\n",
      "Policy train loss in epoch 1:1.5169276744127274\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.516927719116211\n",
      "\n",
      "episode 2, policy loss 1.5169275999069214\n",
      "\n",
      "episode 3, policy loss 1.5169280767440796\n",
      "\n",
      "episode 4, policy loss 1.5169267654418945\n",
      "\n",
      "episode 5, policy loss 1.51692795753479\n",
      "\n",
      "episode 6, policy loss 1.5169264078140259\n",
      "\n",
      "episode 7, policy loss 1.516927719116211\n",
      "\n",
      "episode 8, policy loss 1.5169275999069214\n",
      "\n",
      "episode 9, policy loss 1.5169275999069214\n",
      "\n",
      "episode 10, policy loss 1.5169265270233154\n",
      "\n",
      "episode 11, policy loss 1.5169275999069214\n",
      "\n",
      "episode 12, policy loss 1.5169299840927124\n",
      "\n",
      "episode 13, policy loss 1.5169286727905273\n",
      "\n",
      "episode 14, policy loss 1.5169271230697632\n",
      "\n",
      "episode 15, policy loss 1.5169280767440796\n",
      "\n",
      "episode 16, policy loss 1.5169273614883423\n",
      "\n",
      "Policy train loss in epoch 2:1.5169276744127274\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.516927719116211\n",
      "\n",
      "episode 2, policy loss 1.5169275999069214\n",
      "\n",
      "episode 3, policy loss 1.5169275999069214\n",
      "\n",
      "episode 4, policy loss 1.516927719116211\n",
      "\n",
      "episode 5, policy loss 1.5169286727905273\n",
      "\n",
      "episode 6, policy loss 1.51692795753479\n",
      "\n",
      "episode 7, policy loss 1.5169264078140259\n",
      "\n",
      "episode 8, policy loss 1.5169280767440796\n",
      "\n",
      "episode 9, policy loss 1.5169275999069214\n",
      "\n",
      "episode 10, policy loss 1.5169265270233154\n",
      "\n",
      "episode 11, policy loss 1.5169271230697632\n",
      "\n",
      "episode 12, policy loss 1.5169299840927124\n",
      "\n",
      "episode 13, policy loss 1.5169275999069214\n",
      "\n",
      "episode 14, policy loss 1.5169273614883423\n",
      "\n",
      "episode 15, policy loss 1.5169267654418945\n",
      "\n",
      "episode 16, policy loss 1.5169280767440796\n",
      "\n",
      "Policy train loss in epoch 3:1.5169276744127274\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.733492910861969\n",
      "\n",
      "episode 2, val func loss 0.6568585634231567\n",
      "\n",
      "episode 3, val func loss 0.6818700432777405\n",
      "\n",
      "episode 4, val func loss 0.7698221206665039\n",
      "\n",
      "episode 5, val func loss 0.7366525530815125\n",
      "\n",
      "episode 6, val func loss 0.7659733295440674\n",
      "\n",
      "episode 7, val func loss 0.754288375377655\n",
      "\n",
      "episode 8, val func loss 0.787691056728363\n",
      "\n",
      "episode 9, val func loss 0.7651667594909668\n",
      "\n",
      "episode 10, val func loss 0.7873320579528809\n",
      "\n",
      "episode 11, val func loss 0.7613555192947388\n",
      "\n",
      "episode 12, val func loss 0.7327880859375\n",
      "\n",
      "episode 13, val func loss 0.6901968717575073\n",
      "\n",
      "episode 14, val func loss 0.6985048055648804\n",
      "\n",
      "episode 15, val func loss 0.7293989658355713\n",
      "\n",
      "episode 16, val func loss 0.7764542102813721\n",
      "\n",
      "Val func train loss in epoch 0:0.7392403893172741\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8017619848251343\n",
      "\n",
      "episode 2, val func loss 0.8165795207023621\n",
      "\n",
      "episode 3, val func loss 0.7056921124458313\n",
      "\n",
      "episode 4, val func loss 0.7738066911697388\n",
      "\n",
      "episode 5, val func loss 0.8509480357170105\n",
      "\n",
      "episode 6, val func loss 0.7129274010658264\n",
      "\n",
      "episode 7, val func loss 0.6845573782920837\n",
      "\n",
      "episode 8, val func loss 0.6713622808456421\n",
      "\n",
      "episode 9, val func loss 0.8454951643943787\n",
      "\n",
      "episode 10, val func loss 0.8583873510360718\n",
      "\n",
      "episode 11, val func loss 0.7881736755371094\n",
      "\n",
      "episode 12, val func loss 0.7215338349342346\n",
      "\n",
      "episode 13, val func loss 0.740398108959198\n",
      "\n",
      "episode 14, val func loss 0.7458521127700806\n",
      "\n",
      "episode 15, val func loss 0.7759535312652588\n",
      "\n",
      "episode 16, val func loss 0.7723625302314758\n",
      "\n",
      "Val func train loss in epoch 1:0.7666119821369648\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7602006793022156\n",
      "\n",
      "episode 2, val func loss 0.8513676524162292\n",
      "\n",
      "episode 3, val func loss 0.8055438995361328\n",
      "\n",
      "episode 4, val func loss 0.7793634533882141\n",
      "\n",
      "episode 5, val func loss 0.8581534028053284\n",
      "\n",
      "episode 6, val func loss 0.7758230566978455\n",
      "\n",
      "episode 7, val func loss 0.7334021925926208\n",
      "\n",
      "episode 8, val func loss 0.8347817659378052\n",
      "\n",
      "episode 9, val func loss 0.7692406177520752\n",
      "\n",
      "episode 10, val func loss 0.7582026124000549\n",
      "\n",
      "episode 11, val func loss 0.8937892913818359\n",
      "\n",
      "episode 12, val func loss 0.8111242651939392\n",
      "\n",
      "episode 13, val func loss 0.7678073644638062\n",
      "\n",
      "episode 14, val func loss 0.7056901454925537\n",
      "\n",
      "episode 15, val func loss 0.7288536429405212\n",
      "\n",
      "episode 16, val func loss 0.7444795370101929\n",
      "\n",
      "Val func train loss in epoch 2:0.7861139737069607\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.7781150937080383\n",
      "\n",
      "episode 2, val func loss 0.7278509140014648\n",
      "\n",
      "episode 3, val func loss 0.7940887808799744\n",
      "\n",
      "episode 4, val func loss 0.6919270753860474\n",
      "\n",
      "episode 5, val func loss 0.7183606028556824\n",
      "\n",
      "episode 6, val func loss 0.7632681131362915\n",
      "\n",
      "episode 7, val func loss 0.721691370010376\n",
      "\n",
      "episode 8, val func loss 0.690093994140625\n",
      "\n",
      "episode 9, val func loss 0.7755473852157593\n",
      "\n",
      "episode 10, val func loss 0.7275813817977905\n",
      "\n",
      "episode 11, val func loss 0.8887120485305786\n",
      "\n",
      "episode 12, val func loss 0.706045389175415\n",
      "\n",
      "episode 13, val func loss 0.7550176382064819\n",
      "\n",
      "episode 14, val func loss 0.7897760272026062\n",
      "\n",
      "episode 15, val func loss 0.7420780658721924\n",
      "\n",
      "episode 16, val func loss 0.7576719522476196\n",
      "\n",
      "Val func train loss in epoch 3:0.751739114522934\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7130957841873169\n",
      "\n",
      "episode 2, val func loss 0.8363737463951111\n",
      "\n",
      "episode 3, val func loss 0.7623568177223206\n",
      "\n",
      "episode 4, val func loss 0.7955121994018555\n",
      "\n",
      "episode 5, val func loss 0.8054880499839783\n",
      "\n",
      "episode 6, val func loss 0.7257710695266724\n",
      "\n",
      "episode 7, val func loss 0.7713470458984375\n",
      "\n",
      "episode 8, val func loss 0.7795831561088562\n",
      "\n",
      "episode 9, val func loss 0.7417144775390625\n",
      "\n",
      "episode 10, val func loss 0.7277835607528687\n",
      "\n",
      "episode 11, val func loss 0.7402753829956055\n",
      "\n",
      "episode 12, val func loss 0.8042436838150024\n",
      "\n",
      "episode 13, val func loss 0.7651931047439575\n",
      "\n",
      "episode 14, val func loss 0.735545814037323\n",
      "\n",
      "episode 15, val func loss 0.8120521306991577\n",
      "\n",
      "episode 16, val func loss 0.7624186873435974\n",
      "\n",
      "Val func train loss in epoch 4:0.7674221694469452\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6295623183250427\n",
      "\n",
      "episode 2, val func loss 0.6688892841339111\n",
      "\n",
      "episode 3, val func loss 0.7561937570571899\n",
      "\n",
      "episode 4, val func loss 0.7291502952575684\n",
      "\n",
      "episode 5, val func loss 0.7027106881141663\n",
      "\n",
      "episode 6, val func loss 0.7063487768173218\n",
      "\n",
      "episode 7, val func loss 0.7904036045074463\n",
      "\n",
      "episode 8, val func loss 0.6730859279632568\n",
      "\n",
      "episode 9, val func loss 0.6822059750556946\n",
      "\n",
      "episode 10, val func loss 0.7574899196624756\n",
      "\n",
      "episode 11, val func loss 0.851439893245697\n",
      "\n",
      "episode 12, val func loss 0.7960128784179688\n",
      "\n",
      "episode 13, val func loss 0.7405490279197693\n",
      "\n",
      "episode 14, val func loss 0.6612591743469238\n",
      "\n",
      "episode 15, val func loss 0.7700721025466919\n",
      "\n",
      "episode 16, val func loss 0.8490738272666931\n",
      "\n",
      "Val func train loss in epoch 5:0.7352779656648636\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8910856246948242\n",
      "\n",
      "episode 2, val func loss 0.726411759853363\n",
      "\n",
      "episode 3, val func loss 0.808262050151825\n",
      "\n",
      "episode 4, val func loss 0.8355404734611511\n",
      "\n",
      "episode 5, val func loss 0.6273770928382874\n",
      "\n",
      "episode 6, val func loss 0.8080251216888428\n",
      "\n",
      "episode 7, val func loss 0.8650177121162415\n",
      "\n",
      "episode 8, val func loss 0.8038994669914246\n",
      "\n",
      "episode 9, val func loss 0.8268699645996094\n",
      "\n",
      "episode 10, val func loss 0.822023332118988\n",
      "\n",
      "episode 11, val func loss 0.9233649969100952\n",
      "\n",
      "episode 12, val func loss 0.7951680421829224\n",
      "\n",
      "episode 13, val func loss 0.8484931588172913\n",
      "\n",
      "episode 14, val func loss 0.8898641467094421\n",
      "\n",
      "episode 15, val func loss 1.2715734243392944\n",
      "\n",
      "episode 16, val func loss 0.9416789412498474\n",
      "\n",
      "Val func train loss in epoch 6:0.8552909567952156\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.0720574855804443\n",
      "\n",
      "episode 2, val func loss 1.2189861536026\n",
      "\n",
      "episode 3, val func loss 0.7364622950553894\n",
      "\n",
      "episode 4, val func loss 0.8982568979263306\n",
      "\n",
      "episode 5, val func loss 1.0113322734832764\n",
      "\n",
      "episode 6, val func loss 0.8792450428009033\n",
      "\n",
      "episode 7, val func loss 0.9586266279220581\n",
      "\n",
      "episode 8, val func loss 0.9394680857658386\n",
      "\n",
      "episode 9, val func loss 1.0634840726852417\n",
      "\n",
      "episode 10, val func loss 0.9116931557655334\n",
      "\n",
      "episode 11, val func loss 0.7989677786827087\n",
      "\n",
      "episode 12, val func loss 0.83756422996521\n",
      "\n",
      "episode 13, val func loss 0.8650190830230713\n",
      "\n",
      "episode 14, val func loss 0.817810595035553\n",
      "\n",
      "episode 15, val func loss 0.790623128414154\n",
      "\n",
      "episode 16, val func loss 0.8883746862411499\n",
      "\n",
      "Val func train loss in epoch 7:0.9179982244968414\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.853119969367981\n",
      "\n",
      "episode 2, val func loss 0.7068250179290771\n",
      "\n",
      "episode 3, val func loss 0.6651909351348877\n",
      "\n",
      "episode 4, val func loss 0.7493951320648193\n",
      "\n",
      "episode 5, val func loss 0.7981866002082825\n",
      "\n",
      "episode 6, val func loss 0.7366072535514832\n",
      "\n",
      "episode 7, val func loss 0.7436151504516602\n",
      "\n",
      "episode 8, val func loss 0.7653337717056274\n",
      "\n",
      "episode 9, val func loss 0.8302743434906006\n",
      "\n",
      "episode 10, val func loss 0.7649152874946594\n",
      "\n",
      "episode 11, val func loss 0.7507489919662476\n",
      "\n",
      "episode 12, val func loss 0.8675360083580017\n",
      "\n",
      "episode 13, val func loss 0.7831774950027466\n",
      "\n",
      "episode 14, val func loss 0.7770180106163025\n",
      "\n",
      "episode 15, val func loss 0.7080777883529663\n",
      "\n",
      "episode 16, val func loss 0.7991191148757935\n",
      "\n",
      "Val func train loss in epoch 8:0.768696304410696\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6455538272857666\n",
      "\n",
      "episode 2, val func loss 0.7936567664146423\n",
      "\n",
      "episode 3, val func loss 0.7496868968009949\n",
      "\n",
      "episode 4, val func loss 0.7525212168693542\n",
      "\n",
      "episode 5, val func loss 0.7265949249267578\n",
      "\n",
      "episode 6, val func loss 0.7462026476860046\n",
      "\n",
      "episode 7, val func loss 0.7239400744438171\n",
      "\n",
      "episode 8, val func loss 0.7840870022773743\n",
      "\n",
      "episode 9, val func loss 0.7214378714561462\n",
      "\n",
      "episode 10, val func loss 0.6718741059303284\n",
      "\n",
      "episode 11, val func loss 0.7897864580154419\n",
      "\n",
      "episode 12, val func loss 0.7506813406944275\n",
      "\n",
      "episode 13, val func loss 0.7038718461990356\n",
      "\n",
      "episode 14, val func loss 0.8091256618499756\n",
      "\n",
      "episode 15, val func loss 0.7128229737281799\n",
      "\n",
      "episode 16, val func loss 0.6780586242675781\n",
      "\n",
      "Val func train loss in epoch 9:0.7349938899278641\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.843095600605011\n",
      "\n",
      "episode 2, val func loss 0.7845000624656677\n",
      "\n",
      "episode 3, val func loss 0.7295751571655273\n",
      "\n",
      "episode 4, val func loss 0.8037195801734924\n",
      "\n",
      "episode 5, val func loss 0.7399872541427612\n",
      "\n",
      "episode 6, val func loss 0.7634459137916565\n",
      "\n",
      "episode 7, val func loss 0.6743718981742859\n",
      "\n",
      "episode 8, val func loss 0.919601559638977\n",
      "\n",
      "episode 9, val func loss 0.725300669670105\n",
      "\n",
      "episode 10, val func loss 0.7990607619285583\n",
      "\n",
      "episode 11, val func loss 0.6534919142723083\n",
      "\n",
      "episode 12, val func loss 0.711834728717804\n",
      "\n",
      "episode 13, val func loss 0.8803933262825012\n",
      "\n",
      "episode 14, val func loss 0.6580188870429993\n",
      "\n",
      "episode 15, val func loss 0.7454816102981567\n",
      "\n",
      "episode 16, val func loss 0.7374045252799988\n",
      "\n",
      "Val func train loss in epoch 10:0.7605802156031132\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.8154325485229492\n",
      "\n",
      "episode 2, val func loss 0.701727569103241\n",
      "\n",
      "episode 3, val func loss 0.6838749647140503\n",
      "\n",
      "episode 4, val func loss 0.7287271618843079\n",
      "\n",
      "episode 5, val func loss 0.7562183141708374\n",
      "\n",
      "episode 6, val func loss 0.9237417578697205\n",
      "\n",
      "episode 7, val func loss 0.7502827048301697\n",
      "\n",
      "episode 8, val func loss 0.7962754368782043\n",
      "\n",
      "episode 9, val func loss 0.7357959151268005\n",
      "\n",
      "episode 10, val func loss 0.7391019463539124\n",
      "\n",
      "episode 11, val func loss 0.7155657410621643\n",
      "\n",
      "episode 12, val func loss 0.6923356652259827\n",
      "\n",
      "episode 13, val func loss 0.7825539112091064\n",
      "\n",
      "episode 14, val func loss 0.6650655269622803\n",
      "\n",
      "episode 15, val func loss 0.7289320826530457\n",
      "\n",
      "episode 16, val func loss 0.7120125889778137\n",
      "\n",
      "Val func train loss in epoch 11:0.7454777397215366\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7378618121147156\n",
      "\n",
      "episode 2, val func loss 0.7864807844161987\n",
      "\n",
      "episode 3, val func loss 0.7637962698936462\n",
      "\n",
      "episode 4, val func loss 0.7748832702636719\n",
      "\n",
      "episode 5, val func loss 0.7063202261924744\n",
      "\n",
      "episode 6, val func loss 0.7417370676994324\n",
      "\n",
      "episode 7, val func loss 0.6442087292671204\n",
      "\n",
      "episode 8, val func loss 0.6640621423721313\n",
      "\n",
      "episode 9, val func loss 0.6862828731536865\n",
      "\n",
      "episode 10, val func loss 0.812044084072113\n",
      "\n",
      "episode 11, val func loss 0.6804590821266174\n",
      "\n",
      "episode 12, val func loss 0.6862564086914062\n",
      "\n",
      "episode 13, val func loss 0.8374760150909424\n",
      "\n",
      "episode 14, val func loss 0.7439041137695312\n",
      "\n",
      "episode 15, val func loss 0.7910801768302917\n",
      "\n",
      "episode 16, val func loss 0.8408905863761902\n",
      "\n",
      "Val func train loss in epoch 12:0.7436089776456356\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.9015033841133118\n",
      "\n",
      "episode 2, val func loss 0.8003668189048767\n",
      "\n",
      "episode 3, val func loss 0.8570704460144043\n",
      "\n",
      "episode 4, val func loss 0.7187772393226624\n",
      "\n",
      "episode 5, val func loss 0.7513216137886047\n",
      "\n",
      "episode 6, val func loss 0.7011747360229492\n",
      "\n",
      "episode 7, val func loss 0.8028392195701599\n",
      "\n",
      "episode 8, val func loss 0.7273221611976624\n",
      "\n",
      "episode 9, val func loss 0.8991730809211731\n",
      "\n",
      "episode 10, val func loss 0.8225380778312683\n",
      "\n",
      "episode 11, val func loss 0.770458996295929\n",
      "\n",
      "episode 12, val func loss 0.8128623366355896\n",
      "\n",
      "episode 13, val func loss 0.7349863648414612\n",
      "\n",
      "episode 14, val func loss 0.6874995827674866\n",
      "\n",
      "episode 15, val func loss 0.7458020448684692\n",
      "\n",
      "episode 16, val func loss 0.7785032391548157\n",
      "\n",
      "Val func train loss in epoch 13:0.7820124588906765\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.73231440782547\n",
      "\n",
      "episode 2, val func loss 0.8578103184700012\n",
      "\n",
      "episode 3, val func loss 0.7626421451568604\n",
      "\n",
      "episode 4, val func loss 0.6805343627929688\n",
      "\n",
      "episode 5, val func loss 0.7110403180122375\n",
      "\n",
      "episode 6, val func loss 0.8277463912963867\n",
      "\n",
      "episode 7, val func loss 0.8459768295288086\n",
      "\n",
      "episode 8, val func loss 0.7428141236305237\n",
      "\n",
      "episode 9, val func loss 0.7529695630073547\n",
      "\n",
      "episode 10, val func loss 0.8127411603927612\n",
      "\n",
      "episode 11, val func loss 0.72177654504776\n",
      "\n",
      "episode 12, val func loss 0.6943222880363464\n",
      "\n",
      "episode 13, val func loss 0.6655397415161133\n",
      "\n",
      "episode 14, val func loss 0.7222046256065369\n",
      "\n",
      "episode 15, val func loss 0.8031125664710999\n",
      "\n",
      "episode 16, val func loss 0.7238807082176208\n",
      "\n",
      "Val func train loss in epoch 14:0.7535891309380531\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7572467923164368\n",
      "\n",
      "episode 2, val func loss 0.7774770855903625\n",
      "\n",
      "episode 3, val func loss 0.7127574682235718\n",
      "\n",
      "episode 4, val func loss 0.7191860675811768\n",
      "\n",
      "episode 5, val func loss 0.5600281357765198\n",
      "\n",
      "episode 6, val func loss 0.7087240219116211\n",
      "\n",
      "episode 7, val func loss 0.791517436504364\n",
      "\n",
      "episode 8, val func loss 0.7319513559341431\n",
      "\n",
      "episode 9, val func loss 0.7332940697669983\n",
      "\n",
      "episode 10, val func loss 0.6536574363708496\n",
      "\n",
      "episode 11, val func loss 0.76978999376297\n",
      "\n",
      "episode 12, val func loss 0.6692794561386108\n",
      "\n",
      "episode 13, val func loss 0.7289594411849976\n",
      "\n",
      "episode 14, val func loss 0.6700442433357239\n",
      "\n",
      "episode 15, val func loss 0.7916496396064758\n",
      "\n",
      "episode 16, val func loss 0.7124156951904297\n",
      "\n",
      "Val func train loss in epoch 15:0.7179986461997032\n",
      "***********************TIME WAS 4.83864088455836 min*****************************\n",
      "\n",
      "**********************ROUND 63 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.5720708966255188\n",
      "\n",
      "episode 2, policy loss 0.5720723271369934\n",
      "\n",
      "episode 3, policy loss 0.572070837020874\n",
      "\n",
      "episode 4, policy loss 0.5720701813697815\n",
      "\n",
      "episode 5, policy loss 0.5720699429512024\n",
      "\n",
      "episode 6, policy loss 0.5720708966255188\n",
      "\n",
      "episode 7, policy loss 0.5720708966255188\n",
      "\n",
      "episode 8, policy loss 0.5720708966255188\n",
      "\n",
      "episode 9, policy loss 0.572070837020874\n",
      "\n",
      "episode 10, policy loss 0.5720700621604919\n",
      "\n",
      "episode 11, policy loss 0.5720697641372681\n",
      "\n",
      "episode 12, policy loss 0.572071373462677\n",
      "\n",
      "episode 13, policy loss 0.5720697641372681\n",
      "\n",
      "episode 14, policy loss 0.5720705986022949\n",
      "\n",
      "episode 15, policy loss 0.5720716118812561\n",
      "\n",
      "episode 16, policy loss 0.5720697045326233\n",
      "\n",
      "Policy train loss in epoch 0:0.57207066193223\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.5720708966255188\n",
      "\n",
      "episode 2, policy loss 0.5720701813697815\n",
      "\n",
      "episode 3, policy loss 0.5720697641372681\n",
      "\n",
      "episode 4, policy loss 0.5720708966255188\n",
      "\n",
      "episode 5, policy loss 0.5720716118812561\n",
      "\n",
      "episode 6, policy loss 0.5720705986022949\n",
      "\n",
      "episode 7, policy loss 0.5720700621604919\n",
      "\n",
      "episode 8, policy loss 0.572071373462677\n",
      "\n",
      "episode 9, policy loss 0.5720708966255188\n",
      "\n",
      "episode 10, policy loss 0.5720699429512024\n",
      "\n",
      "episode 11, policy loss 0.572070837020874\n",
      "\n",
      "episode 12, policy loss 0.5720723271369934\n",
      "\n",
      "episode 13, policy loss 0.572070837020874\n",
      "\n",
      "episode 14, policy loss 0.5720697045326233\n",
      "\n",
      "episode 15, policy loss 0.5720708966255188\n",
      "\n",
      "episode 16, policy loss 0.5720697641372681\n",
      "\n",
      "Policy train loss in epoch 1:0.57207066193223\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.5720697641372681\n",
      "\n",
      "episode 2, policy loss 0.5720708966255188\n",
      "\n",
      "episode 3, policy loss 0.5720705986022949\n",
      "\n",
      "episode 4, policy loss 0.572071373462677\n",
      "\n",
      "episode 5, policy loss 0.5720723271369934\n",
      "\n",
      "episode 6, policy loss 0.5720699429512024\n",
      "\n",
      "episode 7, policy loss 0.5720697641372681\n",
      "\n",
      "episode 8, policy loss 0.5720701813697815\n",
      "\n",
      "episode 9, policy loss 0.5720708966255188\n",
      "\n",
      "episode 10, policy loss 0.572070837020874\n",
      "\n",
      "episode 11, policy loss 0.5720708966255188\n",
      "\n",
      "episode 12, policy loss 0.5720716118812561\n",
      "\n",
      "episode 13, policy loss 0.5720700621604919\n",
      "\n",
      "episode 14, policy loss 0.572070837020874\n",
      "\n",
      "episode 15, policy loss 0.5720708966255188\n",
      "\n",
      "episode 16, policy loss 0.5720697045326233\n",
      "\n",
      "Policy train loss in epoch 2:0.57207066193223\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.572070837020874\n",
      "\n",
      "episode 2, policy loss 0.5720708966255188\n",
      "\n",
      "episode 3, policy loss 0.5720708966255188\n",
      "\n",
      "episode 4, policy loss 0.5720708966255188\n",
      "\n",
      "episode 5, policy loss 0.5720700621604919\n",
      "\n",
      "episode 6, policy loss 0.572071373462677\n",
      "\n",
      "episode 7, policy loss 0.5720723271369934\n",
      "\n",
      "episode 8, policy loss 0.5720716118812561\n",
      "\n",
      "episode 9, policy loss 0.5720697641372681\n",
      "\n",
      "episode 10, policy loss 0.5720697045326233\n",
      "\n",
      "episode 11, policy loss 0.5720708966255188\n",
      "\n",
      "episode 12, policy loss 0.5720699429512024\n",
      "\n",
      "episode 13, policy loss 0.5720701813697815\n",
      "\n",
      "episode 14, policy loss 0.5720697641372681\n",
      "\n",
      "episode 15, policy loss 0.572070837020874\n",
      "\n",
      "episode 16, policy loss 0.5720705986022949\n",
      "\n",
      "Policy train loss in epoch 3:0.57207066193223\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7067451477050781\n",
      "\n",
      "episode 2, val func loss 0.7648692727088928\n",
      "\n",
      "episode 3, val func loss 0.7281326055526733\n",
      "\n",
      "episode 4, val func loss 0.7152532339096069\n",
      "\n",
      "episode 5, val func loss 0.8071523308753967\n",
      "\n",
      "episode 6, val func loss 0.7852537035942078\n",
      "\n",
      "episode 7, val func loss 0.8641119599342346\n",
      "\n",
      "episode 8, val func loss 0.8148460388183594\n",
      "\n",
      "episode 9, val func loss 0.739780604839325\n",
      "\n",
      "episode 10, val func loss 0.766016960144043\n",
      "\n",
      "episode 11, val func loss 0.601292073726654\n",
      "\n",
      "episode 12, val func loss 0.7742351293563843\n",
      "\n",
      "episode 13, val func loss 0.718675434589386\n",
      "\n",
      "episode 14, val func loss 0.6882063746452332\n",
      "\n",
      "episode 15, val func loss 0.7124810814857483\n",
      "\n",
      "episode 16, val func loss 0.6417705416679382\n",
      "\n",
      "Val func train loss in epoch 0:0.7393014058470726\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7263547778129578\n",
      "\n",
      "episode 2, val func loss 0.685436487197876\n",
      "\n",
      "episode 3, val func loss 0.69068843126297\n",
      "\n",
      "episode 4, val func loss 0.7487508654594421\n",
      "\n",
      "episode 5, val func loss 0.6877881288528442\n",
      "\n",
      "episode 6, val func loss 0.7017516493797302\n",
      "\n",
      "episode 7, val func loss 0.7292304635047913\n",
      "\n",
      "episode 8, val func loss 0.6875038743019104\n",
      "\n",
      "episode 9, val func loss 0.7808502316474915\n",
      "\n",
      "episode 10, val func loss 0.7271649837493896\n",
      "\n",
      "episode 11, val func loss 0.6975580453872681\n",
      "\n",
      "episode 12, val func loss 0.8356539011001587\n",
      "\n",
      "episode 13, val func loss 0.6627250909805298\n",
      "\n",
      "episode 14, val func loss 0.7448424696922302\n",
      "\n",
      "episode 15, val func loss 0.8135068416595459\n",
      "\n",
      "episode 16, val func loss 0.7081189751625061\n",
      "\n",
      "Val func train loss in epoch 1:0.7267453260719776\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.8322233557701111\n",
      "\n",
      "episode 2, val func loss 0.8673182129859924\n",
      "\n",
      "episode 3, val func loss 0.8568626046180725\n",
      "\n",
      "episode 4, val func loss 0.7343733310699463\n",
      "\n",
      "episode 5, val func loss 0.8261168003082275\n",
      "\n",
      "episode 6, val func loss 0.8105078935623169\n",
      "\n",
      "episode 7, val func loss 0.81326824426651\n",
      "\n",
      "episode 8, val func loss 0.7166216373443604\n",
      "\n",
      "episode 9, val func loss 0.9195592403411865\n",
      "\n",
      "episode 10, val func loss 0.8986561298370361\n",
      "\n",
      "episode 11, val func loss 0.7845236659049988\n",
      "\n",
      "episode 12, val func loss 0.7887999415397644\n",
      "\n",
      "episode 13, val func loss 0.772294819355011\n",
      "\n",
      "episode 14, val func loss 0.801508903503418\n",
      "\n",
      "episode 15, val func loss 0.6978331804275513\n",
      "\n",
      "episode 16, val func loss 0.7332307696342468\n",
      "\n",
      "Val func train loss in epoch 2:0.8033561706542969\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8797221779823303\n",
      "\n",
      "episode 2, val func loss 0.8172439336776733\n",
      "\n",
      "episode 3, val func loss 0.835246741771698\n",
      "\n",
      "episode 4, val func loss 0.8527022004127502\n",
      "\n",
      "episode 5, val func loss 0.6520591974258423\n",
      "\n",
      "episode 6, val func loss 0.8184425830841064\n",
      "\n",
      "episode 7, val func loss 0.9360396265983582\n",
      "\n",
      "episode 8, val func loss 0.8851686716079712\n",
      "\n",
      "episode 9, val func loss 0.8070605993270874\n",
      "\n",
      "episode 10, val func loss 0.7128573060035706\n",
      "\n",
      "episode 11, val func loss 0.864609956741333\n",
      "\n",
      "episode 12, val func loss 0.8379437923431396\n",
      "\n",
      "episode 13, val func loss 0.8617835640907288\n",
      "\n",
      "episode 14, val func loss 0.7314507961273193\n",
      "\n",
      "episode 15, val func loss 0.8044620156288147\n",
      "\n",
      "episode 16, val func loss 0.748832643032074\n",
      "\n",
      "Val func train loss in epoch 3:0.8153516128659248\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8227973580360413\n",
      "\n",
      "episode 2, val func loss 1.064414381980896\n",
      "\n",
      "episode 3, val func loss 0.7268955707550049\n",
      "\n",
      "episode 4, val func loss 0.8777653574943542\n",
      "\n",
      "episode 5, val func loss 0.8494844436645508\n",
      "\n",
      "episode 6, val func loss 0.7267731428146362\n",
      "\n",
      "episode 7, val func loss 0.9079886078834534\n",
      "\n",
      "episode 8, val func loss 1.2142646312713623\n",
      "\n",
      "episode 9, val func loss 0.7035229802131653\n",
      "\n",
      "episode 10, val func loss 1.1043782234191895\n",
      "\n",
      "episode 11, val func loss 0.9728016257286072\n",
      "\n",
      "episode 12, val func loss 0.7443016767501831\n",
      "\n",
      "episode 13, val func loss 0.7937356233596802\n",
      "\n",
      "episode 14, val func loss 0.926922082901001\n",
      "\n",
      "episode 15, val func loss 0.8833150863647461\n",
      "\n",
      "episode 16, val func loss 0.9048442244529724\n",
      "\n",
      "Val func train loss in epoch 4:0.8890128135681152\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.8644243478775024\n",
      "\n",
      "episode 2, val func loss 0.7285504937171936\n",
      "\n",
      "episode 3, val func loss 0.8333708643913269\n",
      "\n",
      "episode 4, val func loss 0.8345524668693542\n",
      "\n",
      "episode 5, val func loss 0.8915375471115112\n",
      "\n",
      "episode 6, val func loss 0.8405076861381531\n",
      "\n",
      "episode 7, val func loss 0.7304521203041077\n",
      "\n",
      "episode 8, val func loss 0.7287511825561523\n",
      "\n",
      "episode 9, val func loss 0.7383977174758911\n",
      "\n",
      "episode 10, val func loss 0.8765954971313477\n",
      "\n",
      "episode 11, val func loss 0.8514333367347717\n",
      "\n",
      "episode 12, val func loss 0.687339723110199\n",
      "\n",
      "episode 13, val func loss 0.6719229221343994\n",
      "\n",
      "episode 14, val func loss 0.7765403389930725\n",
      "\n",
      "episode 15, val func loss 0.6956210136413574\n",
      "\n",
      "episode 16, val func loss 0.7925747036933899\n",
      "\n",
      "Val func train loss in epoch 5:0.7839107476174831\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7723812460899353\n",
      "\n",
      "episode 2, val func loss 0.6839881539344788\n",
      "\n",
      "episode 3, val func loss 0.7707075476646423\n",
      "\n",
      "episode 4, val func loss 0.7633015513420105\n",
      "\n",
      "episode 5, val func loss 0.7686692476272583\n",
      "\n",
      "episode 6, val func loss 0.7680858373641968\n",
      "\n",
      "episode 7, val func loss 0.6930502653121948\n",
      "\n",
      "episode 8, val func loss 0.7119383811950684\n",
      "\n",
      "episode 9, val func loss 0.7726444602012634\n",
      "\n",
      "episode 10, val func loss 0.6775959134101868\n",
      "\n",
      "episode 11, val func loss 0.7334450483322144\n",
      "\n",
      "episode 12, val func loss 0.6731986999511719\n",
      "\n",
      "episode 13, val func loss 0.6760009527206421\n",
      "\n",
      "episode 14, val func loss 0.6936333179473877\n",
      "\n",
      "episode 15, val func loss 0.6110547780990601\n",
      "\n",
      "episode 16, val func loss 0.7315650582313538\n",
      "\n",
      "Val func train loss in epoch 6:0.7188287787139416\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.8368937373161316\n",
      "\n",
      "episode 2, val func loss 0.7370221614837646\n",
      "\n",
      "episode 3, val func loss 0.8754251003265381\n",
      "\n",
      "episode 4, val func loss 0.8287110924720764\n",
      "\n",
      "episode 5, val func loss 0.6944103837013245\n",
      "\n",
      "episode 6, val func loss 0.8447353839874268\n",
      "\n",
      "episode 7, val func loss 0.7876489162445068\n",
      "\n",
      "episode 8, val func loss 0.6398128867149353\n",
      "\n",
      "episode 9, val func loss 0.798787534236908\n",
      "\n",
      "episode 10, val func loss 0.8592539429664612\n",
      "\n",
      "episode 11, val func loss 0.7180749177932739\n",
      "\n",
      "episode 12, val func loss 0.7154538035392761\n",
      "\n",
      "episode 13, val func loss 0.865696370601654\n",
      "\n",
      "episode 14, val func loss 0.804718554019928\n",
      "\n",
      "episode 15, val func loss 0.8131895065307617\n",
      "\n",
      "episode 16, val func loss 0.9191008806228638\n",
      "\n",
      "Val func train loss in epoch 7:0.7961834482848644\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7455903887748718\n",
      "\n",
      "episode 2, val func loss 0.5853595733642578\n",
      "\n",
      "episode 3, val func loss 0.78158038854599\n",
      "\n",
      "episode 4, val func loss 0.7784756422042847\n",
      "\n",
      "episode 5, val func loss 0.7557896375656128\n",
      "\n",
      "episode 6, val func loss 0.8722277283668518\n",
      "\n",
      "episode 7, val func loss 0.865504801273346\n",
      "\n",
      "episode 8, val func loss 0.7097811698913574\n",
      "\n",
      "episode 9, val func loss 0.8056676387786865\n",
      "\n",
      "episode 10, val func loss 0.9178217649459839\n",
      "\n",
      "episode 11, val func loss 0.709396481513977\n",
      "\n",
      "episode 12, val func loss 0.6760622262954712\n",
      "\n",
      "episode 13, val func loss 0.8428900241851807\n",
      "\n",
      "episode 14, val func loss 0.781857967376709\n",
      "\n",
      "episode 15, val func loss 0.9205677509307861\n",
      "\n",
      "episode 16, val func loss 0.7115285992622375\n",
      "\n",
      "Val func train loss in epoch 8:0.7787563614547253\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6996155977249146\n",
      "\n",
      "episode 2, val func loss 0.7012445330619812\n",
      "\n",
      "episode 3, val func loss 0.7287746071815491\n",
      "\n",
      "episode 4, val func loss 0.7103537917137146\n",
      "\n",
      "episode 5, val func loss 0.7362685799598694\n",
      "\n",
      "episode 6, val func loss 0.7976369857788086\n",
      "\n",
      "episode 7, val func loss 0.6718853116035461\n",
      "\n",
      "episode 8, val func loss 0.7699720859527588\n",
      "\n",
      "episode 9, val func loss 0.7078946232795715\n",
      "\n",
      "episode 10, val func loss 0.8034591674804688\n",
      "\n",
      "episode 11, val func loss 0.8389188051223755\n",
      "\n",
      "episode 12, val func loss 0.7924492955207825\n",
      "\n",
      "episode 13, val func loss 0.777847945690155\n",
      "\n",
      "episode 14, val func loss 0.7079416513442993\n",
      "\n",
      "episode 15, val func loss 0.6609228253364563\n",
      "\n",
      "episode 16, val func loss 0.7811143398284912\n",
      "\n",
      "Val func train loss in epoch 9:0.7428937591612339\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7757402062416077\n",
      "\n",
      "episode 2, val func loss 0.7543080449104309\n",
      "\n",
      "episode 3, val func loss 0.781840443611145\n",
      "\n",
      "episode 4, val func loss 0.7068606019020081\n",
      "\n",
      "episode 5, val func loss 0.7166986465454102\n",
      "\n",
      "episode 6, val func loss 0.7797293066978455\n",
      "\n",
      "episode 7, val func loss 0.7395865321159363\n",
      "\n",
      "episode 8, val func loss 0.7609691619873047\n",
      "\n",
      "episode 9, val func loss 0.733772873878479\n",
      "\n",
      "episode 10, val func loss 0.6721224784851074\n",
      "\n",
      "episode 11, val func loss 0.6972267627716064\n",
      "\n",
      "episode 12, val func loss 0.6983750462532043\n",
      "\n",
      "episode 13, val func loss 0.7478400468826294\n",
      "\n",
      "episode 14, val func loss 0.6892015933990479\n",
      "\n",
      "episode 15, val func loss 0.8325669765472412\n",
      "\n",
      "episode 16, val func loss 0.8285346031188965\n",
      "\n",
      "Val func train loss in epoch 10:0.7447108328342438\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7888808846473694\n",
      "\n",
      "episode 2, val func loss 0.6888895630836487\n",
      "\n",
      "episode 3, val func loss 0.8180946111679077\n",
      "\n",
      "episode 4, val func loss 0.70340895652771\n",
      "\n",
      "episode 5, val func loss 0.8385001420974731\n",
      "\n",
      "episode 6, val func loss 0.769338846206665\n",
      "\n",
      "episode 7, val func loss 0.6808793544769287\n",
      "\n",
      "episode 8, val func loss 0.7845389246940613\n",
      "\n",
      "episode 9, val func loss 0.793830394744873\n",
      "\n",
      "episode 10, val func loss 0.8186861276626587\n",
      "\n",
      "episode 11, val func loss 0.6633697152137756\n",
      "\n",
      "episode 12, val func loss 0.7611669301986694\n",
      "\n",
      "episode 13, val func loss 0.7399752140045166\n",
      "\n",
      "episode 14, val func loss 0.6881972551345825\n",
      "\n",
      "episode 15, val func loss 0.68348228931427\n",
      "\n",
      "episode 16, val func loss 0.8111664652824402\n",
      "\n",
      "Val func train loss in epoch 11:0.7520253546535969\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6369655728340149\n",
      "\n",
      "episode 2, val func loss 0.7730135321617126\n",
      "\n",
      "episode 3, val func loss 0.7045658230781555\n",
      "\n",
      "episode 4, val func loss 0.6882847547531128\n",
      "\n",
      "episode 5, val func loss 0.6421353220939636\n",
      "\n",
      "episode 6, val func loss 0.8394299745559692\n",
      "\n",
      "episode 7, val func loss 0.7217167615890503\n",
      "\n",
      "episode 8, val func loss 0.8482498526573181\n",
      "\n",
      "episode 9, val func loss 0.651902973651886\n",
      "\n",
      "episode 10, val func loss 0.7044433951377869\n",
      "\n",
      "episode 11, val func loss 0.6588450074195862\n",
      "\n",
      "episode 12, val func loss 0.725433349609375\n",
      "\n",
      "episode 13, val func loss 0.7700641751289368\n",
      "\n",
      "episode 14, val func loss 0.6773912906646729\n",
      "\n",
      "episode 15, val func loss 0.7093961238861084\n",
      "\n",
      "episode 16, val func loss 0.7708884477615356\n",
      "\n",
      "Val func train loss in epoch 12:0.720170397311449\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6226958632469177\n",
      "\n",
      "episode 2, val func loss 0.7451057434082031\n",
      "\n",
      "episode 3, val func loss 0.7392614483833313\n",
      "\n",
      "episode 4, val func loss 0.6912678480148315\n",
      "\n",
      "episode 5, val func loss 0.7762329578399658\n",
      "\n",
      "episode 6, val func loss 0.7167046666145325\n",
      "\n",
      "episode 7, val func loss 0.7412713170051575\n",
      "\n",
      "episode 8, val func loss 0.7321874499320984\n",
      "\n",
      "episode 9, val func loss 0.7370613217353821\n",
      "\n",
      "episode 10, val func loss 0.7235906720161438\n",
      "\n",
      "episode 11, val func loss 0.7712963223457336\n",
      "\n",
      "episode 12, val func loss 0.742611289024353\n",
      "\n",
      "episode 13, val func loss 0.6727097630500793\n",
      "\n",
      "episode 14, val func loss 0.6814486384391785\n",
      "\n",
      "episode 15, val func loss 0.7560097575187683\n",
      "\n",
      "episode 16, val func loss 0.7980759739875793\n",
      "\n",
      "Val func train loss in epoch 13:0.727970689535141\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7466370463371277\n",
      "\n",
      "episode 2, val func loss 0.6434687972068787\n",
      "\n",
      "episode 3, val func loss 0.7888934016227722\n",
      "\n",
      "episode 4, val func loss 0.7291523814201355\n",
      "\n",
      "episode 5, val func loss 0.7075137495994568\n",
      "\n",
      "episode 6, val func loss 0.6561452150344849\n",
      "\n",
      "episode 7, val func loss 0.7183117270469666\n",
      "\n",
      "episode 8, val func loss 0.6320836544036865\n",
      "\n",
      "episode 9, val func loss 0.7852285504341125\n",
      "\n",
      "episode 10, val func loss 0.6384581923484802\n",
      "\n",
      "episode 11, val func loss 0.6547034978866577\n",
      "\n",
      "episode 12, val func loss 0.823542058467865\n",
      "\n",
      "episode 13, val func loss 0.6249443888664246\n",
      "\n",
      "episode 14, val func loss 0.7484893202781677\n",
      "\n",
      "episode 15, val func loss 0.7233418226242065\n",
      "\n",
      "episode 16, val func loss 0.7225686311721802\n",
      "\n",
      "Val func train loss in epoch 14:0.7089676521718502\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6350655555725098\n",
      "\n",
      "episode 2, val func loss 0.7246053218841553\n",
      "\n",
      "episode 3, val func loss 0.7173082232475281\n",
      "\n",
      "episode 4, val func loss 0.7071767449378967\n",
      "\n",
      "episode 5, val func loss 0.7242064476013184\n",
      "\n",
      "episode 6, val func loss 0.6689671277999878\n",
      "\n",
      "episode 7, val func loss 0.6725912094116211\n",
      "\n",
      "episode 8, val func loss 0.6938044428825378\n",
      "\n",
      "episode 9, val func loss 0.7144770622253418\n",
      "\n",
      "episode 10, val func loss 0.7614591121673584\n",
      "\n",
      "episode 11, val func loss 0.7356448173522949\n",
      "\n",
      "episode 12, val func loss 0.6961555480957031\n",
      "\n",
      "episode 13, val func loss 0.7842574119567871\n",
      "\n",
      "episode 14, val func loss 0.6775575280189514\n",
      "\n",
      "episode 15, val func loss 0.783149242401123\n",
      "\n",
      "episode 16, val func loss 0.6866990327835083\n",
      "\n",
      "Val func train loss in epoch 15:0.7114453017711639\n",
      "***********************TIME WAS 4.841452296574911 min*****************************\n",
      "\n",
      "**********************ROUND 64 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.37707337737083435\n",
      "\n",
      "episode 2, policy loss -0.37707260251045227\n",
      "\n",
      "episode 3, policy loss -0.3770747780799866\n",
      "\n",
      "episode 4, policy loss -0.3770749568939209\n",
      "\n",
      "episode 5, policy loss -0.3770751953125\n",
      "\n",
      "episode 6, policy loss -0.3770736753940582\n",
      "\n",
      "episode 7, policy loss -0.3770742416381836\n",
      "\n",
      "episode 8, policy loss -0.37707415223121643\n",
      "\n",
      "episode 9, policy loss -0.3770740032196045\n",
      "\n",
      "episode 10, policy loss -0.3770746886730194\n",
      "\n",
      "episode 11, policy loss -0.37707632780075073\n",
      "\n",
      "episode 12, policy loss -0.3770723342895508\n",
      "\n",
      "episode 13, policy loss -0.37707391381263733\n",
      "\n",
      "episode 14, policy loss -0.3770744800567627\n",
      "\n",
      "episode 15, policy loss -0.37707433104515076\n",
      "\n",
      "episode 16, policy loss -0.3770771920681\n",
      "\n",
      "Policy train loss in epoch 0:-0.37707439064979553\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.3770736753940582\n",
      "\n",
      "episode 2, policy loss -0.37707433104515076\n",
      "\n",
      "episode 3, policy loss -0.37707391381263733\n",
      "\n",
      "episode 4, policy loss -0.37707415223121643\n",
      "\n",
      "episode 5, policy loss -0.3770771920681\n",
      "\n",
      "episode 6, policy loss -0.3770723342895508\n",
      "\n",
      "episode 7, policy loss -0.3770749568939209\n",
      "\n",
      "episode 8, policy loss -0.3770744800567627\n",
      "\n",
      "episode 9, policy loss -0.3770746886730194\n",
      "\n",
      "episode 10, policy loss -0.37707632780075073\n",
      "\n",
      "episode 11, policy loss -0.3770747780799866\n",
      "\n",
      "episode 12, policy loss -0.3770740032196045\n",
      "\n",
      "episode 13, policy loss -0.3770742416381836\n",
      "\n",
      "episode 14, policy loss -0.37707260251045227\n",
      "\n",
      "episode 15, policy loss -0.37707337737083435\n",
      "\n",
      "episode 16, policy loss -0.3770751953125\n",
      "\n",
      "Policy train loss in epoch 1:-0.37707439064979553\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.3770723342895508\n",
      "\n",
      "episode 2, policy loss -0.37707415223121643\n",
      "\n",
      "episode 3, policy loss -0.3770736753940582\n",
      "\n",
      "episode 4, policy loss -0.3770751953125\n",
      "\n",
      "episode 5, policy loss -0.37707632780075073\n",
      "\n",
      "episode 6, policy loss -0.37707391381263733\n",
      "\n",
      "episode 7, policy loss -0.3770747780799866\n",
      "\n",
      "episode 8, policy loss -0.3770771920681\n",
      "\n",
      "episode 9, policy loss -0.3770744800567627\n",
      "\n",
      "episode 10, policy loss -0.3770740032196045\n",
      "\n",
      "episode 11, policy loss -0.3770746886730194\n",
      "\n",
      "episode 12, policy loss -0.3770742416381836\n",
      "\n",
      "episode 13, policy loss -0.3770749568939209\n",
      "\n",
      "episode 14, policy loss -0.37707260251045227\n",
      "\n",
      "episode 15, policy loss -0.37707433104515076\n",
      "\n",
      "episode 16, policy loss -0.37707337737083435\n",
      "\n",
      "Policy train loss in epoch 2:-0.37707439064979553\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.3770736753940582\n",
      "\n",
      "episode 2, policy loss -0.37707415223121643\n",
      "\n",
      "episode 3, policy loss -0.37707433104515076\n",
      "\n",
      "episode 4, policy loss -0.3770749568939209\n",
      "\n",
      "episode 5, policy loss -0.3770746886730194\n",
      "\n",
      "episode 6, policy loss -0.3770744800567627\n",
      "\n",
      "episode 7, policy loss -0.37707337737083435\n",
      "\n",
      "episode 8, policy loss -0.3770742416381836\n",
      "\n",
      "episode 9, policy loss -0.3770771920681\n",
      "\n",
      "episode 10, policy loss -0.3770723342895508\n",
      "\n",
      "episode 11, policy loss -0.3770751953125\n",
      "\n",
      "episode 12, policy loss -0.37707260251045227\n",
      "\n",
      "episode 13, policy loss -0.3770747780799866\n",
      "\n",
      "episode 14, policy loss -0.37707632780075073\n",
      "\n",
      "episode 15, policy loss -0.3770740032196045\n",
      "\n",
      "episode 16, policy loss -0.37707391381263733\n",
      "\n",
      "Policy train loss in epoch 3:-0.37707439064979553\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.6633613705635071\n",
      "\n",
      "episode 2, val func loss 0.7932984828948975\n",
      "\n",
      "episode 3, val func loss 0.7900309562683105\n",
      "\n",
      "episode 4, val func loss 0.6607713103294373\n",
      "\n",
      "episode 5, val func loss 0.7438709735870361\n",
      "\n",
      "episode 6, val func loss 0.6665166020393372\n",
      "\n",
      "episode 7, val func loss 0.6461388468742371\n",
      "\n",
      "episode 8, val func loss 0.7281171083450317\n",
      "\n",
      "episode 9, val func loss 0.8578652143478394\n",
      "\n",
      "episode 10, val func loss 0.6896880269050598\n",
      "\n",
      "episode 11, val func loss 0.7565017342567444\n",
      "\n",
      "episode 12, val func loss 0.848788321018219\n",
      "\n",
      "episode 13, val func loss 0.8122837543487549\n",
      "\n",
      "episode 14, val func loss 0.7945364117622375\n",
      "\n",
      "episode 15, val func loss 0.9959810972213745\n",
      "\n",
      "episode 16, val func loss 0.8534218668937683\n",
      "\n",
      "Val func train loss in epoch 0:0.768823254853487\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.0031787157058716\n",
      "\n",
      "episode 2, val func loss 0.910312831401825\n",
      "\n",
      "episode 3, val func loss 0.8310534358024597\n",
      "\n",
      "episode 4, val func loss 0.9795207381248474\n",
      "\n",
      "episode 5, val func loss 0.9570720791816711\n",
      "\n",
      "episode 6, val func loss 0.9722344875335693\n",
      "\n",
      "episode 7, val func loss 0.8048879504203796\n",
      "\n",
      "episode 8, val func loss 0.7711778283119202\n",
      "\n",
      "episode 9, val func loss 0.8504264950752258\n",
      "\n",
      "episode 10, val func loss 0.678714394569397\n",
      "\n",
      "episode 11, val func loss 0.8435266017913818\n",
      "\n",
      "episode 12, val func loss 0.8183141350746155\n",
      "\n",
      "episode 13, val func loss 0.8405325412750244\n",
      "\n",
      "episode 14, val func loss 0.7440947890281677\n",
      "\n",
      "episode 15, val func loss 0.8963824510574341\n",
      "\n",
      "episode 16, val func loss 0.785939633846283\n",
      "\n",
      "Val func train loss in epoch 1:0.8554605692625046\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.8236109614372253\n",
      "\n",
      "episode 2, val func loss 0.7576932907104492\n",
      "\n",
      "episode 3, val func loss 0.6686278581619263\n",
      "\n",
      "episode 4, val func loss 0.6556695103645325\n",
      "\n",
      "episode 5, val func loss 0.817643404006958\n",
      "\n",
      "episode 6, val func loss 0.7697526812553406\n",
      "\n",
      "episode 7, val func loss 0.7749884128570557\n",
      "\n",
      "episode 8, val func loss 0.6839075088500977\n",
      "\n",
      "episode 9, val func loss 0.740502655506134\n",
      "\n",
      "episode 10, val func loss 0.7840750217437744\n",
      "\n",
      "episode 11, val func loss 0.6278969645500183\n",
      "\n",
      "episode 12, val func loss 0.8216081857681274\n",
      "\n",
      "episode 13, val func loss 0.7017675042152405\n",
      "\n",
      "episode 14, val func loss 0.7350047826766968\n",
      "\n",
      "episode 15, val func loss 0.8042551875114441\n",
      "\n",
      "episode 16, val func loss 0.6538106203079224\n",
      "\n",
      "Val func train loss in epoch 2:0.738800909370184\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.815136194229126\n",
      "\n",
      "episode 2, val func loss 0.643917441368103\n",
      "\n",
      "episode 3, val func loss 0.7613467574119568\n",
      "\n",
      "episode 4, val func loss 0.6911234855651855\n",
      "\n",
      "episode 5, val func loss 0.8262270092964172\n",
      "\n",
      "episode 6, val func loss 0.6739000678062439\n",
      "\n",
      "episode 7, val func loss 0.7215274572372437\n",
      "\n",
      "episode 8, val func loss 0.7536125183105469\n",
      "\n",
      "episode 9, val func loss 0.7666066288948059\n",
      "\n",
      "episode 10, val func loss 0.7114511132240295\n",
      "\n",
      "episode 11, val func loss 0.7443097829818726\n",
      "\n",
      "episode 12, val func loss 0.7373388409614563\n",
      "\n",
      "episode 13, val func loss 0.7301328182220459\n",
      "\n",
      "episode 14, val func loss 0.7748944759368896\n",
      "\n",
      "episode 15, val func loss 0.7587706446647644\n",
      "\n",
      "episode 16, val func loss 0.7105170488357544\n",
      "\n",
      "Val func train loss in epoch 3:0.7388007678091526\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8006243705749512\n",
      "\n",
      "episode 2, val func loss 0.7555742859840393\n",
      "\n",
      "episode 3, val func loss 0.6912358999252319\n",
      "\n",
      "episode 4, val func loss 0.7946469187736511\n",
      "\n",
      "episode 5, val func loss 0.7581390738487244\n",
      "\n",
      "episode 6, val func loss 0.739652156829834\n",
      "\n",
      "episode 7, val func loss 0.7524701356887817\n",
      "\n",
      "episode 8, val func loss 0.8399450182914734\n",
      "\n",
      "episode 9, val func loss 0.6374675035476685\n",
      "\n",
      "episode 10, val func loss 0.6481591463088989\n",
      "\n",
      "episode 11, val func loss 0.7824265956878662\n",
      "\n",
      "episode 12, val func loss 0.7978745698928833\n",
      "\n",
      "episode 13, val func loss 0.7030845284461975\n",
      "\n",
      "episode 14, val func loss 0.7539753317832947\n",
      "\n",
      "episode 15, val func loss 0.8879309296607971\n",
      "\n",
      "episode 16, val func loss 0.7393875122070312\n",
      "\n",
      "Val func train loss in epoch 4:0.7551621235907078\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.8398525714874268\n",
      "\n",
      "episode 2, val func loss 0.6954406499862671\n",
      "\n",
      "episode 3, val func loss 0.7092524170875549\n",
      "\n",
      "episode 4, val func loss 0.7580233216285706\n",
      "\n",
      "episode 5, val func loss 0.7038183808326721\n",
      "\n",
      "episode 6, val func loss 0.7727156281471252\n",
      "\n",
      "episode 7, val func loss 0.7490664124488831\n",
      "\n",
      "episode 8, val func loss 0.7841563820838928\n",
      "\n",
      "episode 9, val func loss 0.6869379281997681\n",
      "\n",
      "episode 10, val func loss 0.6712283492088318\n",
      "\n",
      "episode 11, val func loss 0.7068548202514648\n",
      "\n",
      "episode 12, val func loss 0.6628639698028564\n",
      "\n",
      "episode 13, val func loss 0.6412162780761719\n",
      "\n",
      "episode 14, val func loss 0.7184780240058899\n",
      "\n",
      "episode 15, val func loss 0.6852277517318726\n",
      "\n",
      "episode 16, val func loss 0.7792074680328369\n",
      "\n",
      "Val func train loss in epoch 5:0.7227712720632553\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7478781342506409\n",
      "\n",
      "episode 2, val func loss 0.612931489944458\n",
      "\n",
      "episode 3, val func loss 0.7314073443412781\n",
      "\n",
      "episode 4, val func loss 0.6342141628265381\n",
      "\n",
      "episode 5, val func loss 0.7848615646362305\n",
      "\n",
      "episode 6, val func loss 0.6609592437744141\n",
      "\n",
      "episode 7, val func loss 0.7429001927375793\n",
      "\n",
      "episode 8, val func loss 0.8434345722198486\n",
      "\n",
      "episode 9, val func loss 0.6854612231254578\n",
      "\n",
      "episode 10, val func loss 0.7508358359336853\n",
      "\n",
      "episode 11, val func loss 0.7380072474479675\n",
      "\n",
      "episode 12, val func loss 0.8780979514122009\n",
      "\n",
      "episode 13, val func loss 0.6618224382400513\n",
      "\n",
      "episode 14, val func loss 0.7920016646385193\n",
      "\n",
      "episode 15, val func loss 0.7288065552711487\n",
      "\n",
      "episode 16, val func loss 0.7864676713943481\n",
      "\n",
      "Val func train loss in epoch 6:0.7362554557621479\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7453941702842712\n",
      "\n",
      "episode 2, val func loss 0.647235631942749\n",
      "\n",
      "episode 3, val func loss 0.8177525401115417\n",
      "\n",
      "episode 4, val func loss 0.6624089479446411\n",
      "\n",
      "episode 5, val func loss 0.7704088091850281\n",
      "\n",
      "episode 6, val func loss 0.723460853099823\n",
      "\n",
      "episode 7, val func loss 0.8146838545799255\n",
      "\n",
      "episode 8, val func loss 0.6759658455848694\n",
      "\n",
      "episode 9, val func loss 0.6667107939720154\n",
      "\n",
      "episode 10, val func loss 0.6385493874549866\n",
      "\n",
      "episode 11, val func loss 0.6707948446273804\n",
      "\n",
      "episode 12, val func loss 0.7715166211128235\n",
      "\n",
      "episode 13, val func loss 0.77614825963974\n",
      "\n",
      "episode 14, val func loss 0.8742889761924744\n",
      "\n",
      "episode 15, val func loss 0.7690531015396118\n",
      "\n",
      "episode 16, val func loss 0.7710781097412109\n",
      "\n",
      "Val func train loss in epoch 7:0.7372156716883183\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8041281700134277\n",
      "\n",
      "episode 2, val func loss 0.6781618595123291\n",
      "\n",
      "episode 3, val func loss 0.6615617871284485\n",
      "\n",
      "episode 4, val func loss 0.7727651596069336\n",
      "\n",
      "episode 5, val func loss 0.8080698251724243\n",
      "\n",
      "episode 6, val func loss 0.8034507036209106\n",
      "\n",
      "episode 7, val func loss 0.6868539452552795\n",
      "\n",
      "episode 8, val func loss 0.6955661177635193\n",
      "\n",
      "episode 9, val func loss 0.7429602146148682\n",
      "\n",
      "episode 10, val func loss 0.6985238790512085\n",
      "\n",
      "episode 11, val func loss 0.7290070652961731\n",
      "\n",
      "episode 12, val func loss 0.8007932305335999\n",
      "\n",
      "episode 13, val func loss 0.7173359394073486\n",
      "\n",
      "episode 14, val func loss 0.6857917308807373\n",
      "\n",
      "episode 15, val func loss 0.7212901711463928\n",
      "\n",
      "episode 16, val func loss 0.6568573713302612\n",
      "\n",
      "Val func train loss in epoch 8:0.7289448231458664\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6531515121459961\n",
      "\n",
      "episode 2, val func loss 0.6360041499137878\n",
      "\n",
      "episode 3, val func loss 0.7083740234375\n",
      "\n",
      "episode 4, val func loss 0.7156878113746643\n",
      "\n",
      "episode 5, val func loss 0.7359136343002319\n",
      "\n",
      "episode 6, val func loss 0.8363175988197327\n",
      "\n",
      "episode 7, val func loss 0.6294604539871216\n",
      "\n",
      "episode 8, val func loss 0.7468467354774475\n",
      "\n",
      "episode 9, val func loss 0.6685015559196472\n",
      "\n",
      "episode 10, val func loss 0.7601485848426819\n",
      "\n",
      "episode 11, val func loss 0.7577213644981384\n",
      "\n",
      "episode 12, val func loss 0.6179683804512024\n",
      "\n",
      "episode 13, val func loss 0.8615158796310425\n",
      "\n",
      "episode 14, val func loss 0.6954310536384583\n",
      "\n",
      "episode 15, val func loss 0.7764726877212524\n",
      "\n",
      "episode 16, val func loss 0.7100415825843811\n",
      "\n",
      "Val func train loss in epoch 9:0.7193473130464554\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.9133056998252869\n",
      "\n",
      "episode 2, val func loss 0.7487264275550842\n",
      "\n",
      "episode 3, val func loss 0.6703140139579773\n",
      "\n",
      "episode 4, val func loss 0.6989298462867737\n",
      "\n",
      "episode 5, val func loss 0.7713794708251953\n",
      "\n",
      "episode 6, val func loss 0.7155145406723022\n",
      "\n",
      "episode 7, val func loss 0.7271766662597656\n",
      "\n",
      "episode 8, val func loss 0.7035897970199585\n",
      "\n",
      "episode 9, val func loss 0.7255955934524536\n",
      "\n",
      "episode 10, val func loss 0.7237172722816467\n",
      "\n",
      "episode 11, val func loss 0.7897202968597412\n",
      "\n",
      "episode 12, val func loss 0.8386476635932922\n",
      "\n",
      "episode 13, val func loss 0.6374587416648865\n",
      "\n",
      "episode 14, val func loss 0.7352886199951172\n",
      "\n",
      "episode 15, val func loss 0.7698277235031128\n",
      "\n",
      "episode 16, val func loss 0.9481018781661987\n",
      "\n",
      "Val func train loss in epoch 10:0.7573308907449245\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7743962407112122\n",
      "\n",
      "episode 2, val func loss 0.8271021842956543\n",
      "\n",
      "episode 3, val func loss 0.8055433630943298\n",
      "\n",
      "episode 4, val func loss 0.7142957448959351\n",
      "\n",
      "episode 5, val func loss 0.7472907304763794\n",
      "\n",
      "episode 6, val func loss 0.7847978472709656\n",
      "\n",
      "episode 7, val func loss 0.6591765284538269\n",
      "\n",
      "episode 8, val func loss 0.7934389710426331\n",
      "\n",
      "episode 9, val func loss 0.8647013306617737\n",
      "\n",
      "episode 10, val func loss 0.7185800075531006\n",
      "\n",
      "episode 11, val func loss 0.7145949006080627\n",
      "\n",
      "episode 12, val func loss 0.7260729074478149\n",
      "\n",
      "episode 13, val func loss 0.7693037986755371\n",
      "\n",
      "episode 14, val func loss 0.7514988780021667\n",
      "\n",
      "episode 15, val func loss 0.6985269784927368\n",
      "\n",
      "episode 16, val func loss 0.6966891884803772\n",
      "\n",
      "Val func train loss in epoch 11:0.7528756000101566\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.776254415512085\n",
      "\n",
      "episode 2, val func loss 0.8095361590385437\n",
      "\n",
      "episode 3, val func loss 0.7428284883499146\n",
      "\n",
      "episode 4, val func loss 0.7587525248527527\n",
      "\n",
      "episode 5, val func loss 0.7045387625694275\n",
      "\n",
      "episode 6, val func loss 0.6745015382766724\n",
      "\n",
      "episode 7, val func loss 0.7761386632919312\n",
      "\n",
      "episode 8, val func loss 0.7957601547241211\n",
      "\n",
      "episode 9, val func loss 0.7629485726356506\n",
      "\n",
      "episode 10, val func loss 0.7126782536506653\n",
      "\n",
      "episode 11, val func loss 0.818103551864624\n",
      "\n",
      "episode 12, val func loss 0.7638271450996399\n",
      "\n",
      "episode 13, val func loss 0.6375411748886108\n",
      "\n",
      "episode 14, val func loss 0.8549248576164246\n",
      "\n",
      "episode 15, val func loss 0.6727324724197388\n",
      "\n",
      "episode 16, val func loss 0.6556950211524963\n",
      "\n",
      "Val func train loss in epoch 12:0.7447976097464561\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6746418476104736\n",
      "\n",
      "episode 2, val func loss 0.651042103767395\n",
      "\n",
      "episode 3, val func loss 0.6613510847091675\n",
      "\n",
      "episode 4, val func loss 0.644766092300415\n",
      "\n",
      "episode 5, val func loss 0.7612719535827637\n",
      "\n",
      "episode 6, val func loss 0.7777029871940613\n",
      "\n",
      "episode 7, val func loss 0.6991797685623169\n",
      "\n",
      "episode 8, val func loss 0.7828675508499146\n",
      "\n",
      "episode 9, val func loss 0.7658618688583374\n",
      "\n",
      "episode 10, val func loss 0.6106834411621094\n",
      "\n",
      "episode 11, val func loss 0.7226061820983887\n",
      "\n",
      "episode 12, val func loss 0.6428828239440918\n",
      "\n",
      "episode 13, val func loss 0.75162672996521\n",
      "\n",
      "episode 14, val func loss 0.8239895701408386\n",
      "\n",
      "episode 15, val func loss 0.6710233092308044\n",
      "\n",
      "episode 16, val func loss 0.7964118719100952\n",
      "\n",
      "Val func train loss in epoch 13:0.7148693241178989\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6584346294403076\n",
      "\n",
      "episode 2, val func loss 0.6942188739776611\n",
      "\n",
      "episode 3, val func loss 0.7126791477203369\n",
      "\n",
      "episode 4, val func loss 0.7854281067848206\n",
      "\n",
      "episode 5, val func loss 0.7820489406585693\n",
      "\n",
      "episode 6, val func loss 0.7583281397819519\n",
      "\n",
      "episode 7, val func loss 0.8233057856559753\n",
      "\n",
      "episode 8, val func loss 0.7528766393661499\n",
      "\n",
      "episode 9, val func loss 0.6470345854759216\n",
      "\n",
      "episode 10, val func loss 0.8042883276939392\n",
      "\n",
      "episode 11, val func loss 0.7558637857437134\n",
      "\n",
      "episode 12, val func loss 0.8385882377624512\n",
      "\n",
      "episode 13, val func loss 0.6942411065101624\n",
      "\n",
      "episode 14, val func loss 0.6984024047851562\n",
      "\n",
      "episode 15, val func loss 0.8169028162956238\n",
      "\n",
      "episode 16, val func loss 0.6962331533432007\n",
      "\n",
      "Val func train loss in epoch 14:0.7449296675622463\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.8918606638908386\n",
      "\n",
      "episode 2, val func loss 0.7107641696929932\n",
      "\n",
      "episode 3, val func loss 0.7327685356140137\n",
      "\n",
      "episode 4, val func loss 0.628961980342865\n",
      "\n",
      "episode 5, val func loss 0.6352348327636719\n",
      "\n",
      "episode 6, val func loss 0.7063496112823486\n",
      "\n",
      "episode 7, val func loss 0.7529249787330627\n",
      "\n",
      "episode 8, val func loss 0.7333085536956787\n",
      "\n",
      "episode 9, val func loss 0.8100566267967224\n",
      "\n",
      "episode 10, val func loss 0.7722880244255066\n",
      "\n",
      "episode 11, val func loss 0.7089288234710693\n",
      "\n",
      "episode 12, val func loss 0.6973164081573486\n",
      "\n",
      "episode 13, val func loss 0.8385202288627625\n",
      "\n",
      "episode 14, val func loss 0.7731726169586182\n",
      "\n",
      "episode 15, val func loss 0.815449595451355\n",
      "\n",
      "episode 16, val func loss 0.7081637382507324\n",
      "\n",
      "Val func train loss in epoch 15:0.7447543367743492\n",
      "***********************TIME WAS 4.8394909779230755 min*****************************\n",
      "\n",
      "**********************ROUND 65 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.520163893699646\n",
      "\n",
      "episode 2, policy loss 1.520163893699646\n",
      "\n",
      "episode 3, policy loss 1.52016282081604\n",
      "\n",
      "episode 4, policy loss 1.5201635360717773\n",
      "\n",
      "episode 5, policy loss 1.520163893699646\n",
      "\n",
      "episode 6, policy loss 1.5201635360717773\n",
      "\n",
      "episode 7, policy loss 1.5201632976531982\n",
      "\n",
      "episode 8, policy loss 1.520163655281067\n",
      "\n",
      "episode 9, policy loss 1.520164132118225\n",
      "\n",
      "episode 10, policy loss 1.5201629400253296\n",
      "\n",
      "episode 11, policy loss 1.520163655281067\n",
      "\n",
      "episode 12, policy loss 1.5201635360717773\n",
      "\n",
      "episode 13, policy loss 1.5201635360717773\n",
      "\n",
      "episode 14, policy loss 1.520163893699646\n",
      "\n",
      "episode 15, policy loss 1.5201635360717773\n",
      "\n",
      "episode 16, policy loss 1.520163655281067\n",
      "\n",
      "Policy train loss in epoch 0:1.5201635882258415\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.5201635360717773\n",
      "\n",
      "episode 2, policy loss 1.5201629400253296\n",
      "\n",
      "episode 3, policy loss 1.520163893699646\n",
      "\n",
      "episode 4, policy loss 1.52016282081604\n",
      "\n",
      "episode 5, policy loss 1.5201635360717773\n",
      "\n",
      "episode 6, policy loss 1.520163655281067\n",
      "\n",
      "episode 7, policy loss 1.5201632976531982\n",
      "\n",
      "episode 8, policy loss 1.520163893699646\n",
      "\n",
      "episode 9, policy loss 1.5201635360717773\n",
      "\n",
      "episode 10, policy loss 1.5201635360717773\n",
      "\n",
      "episode 11, policy loss 1.520163655281067\n",
      "\n",
      "episode 12, policy loss 1.520163893699646\n",
      "\n",
      "episode 13, policy loss 1.5201635360717773\n",
      "\n",
      "episode 14, policy loss 1.520163655281067\n",
      "\n",
      "episode 15, policy loss 1.520163893699646\n",
      "\n",
      "episode 16, policy loss 1.520164132118225\n",
      "\n",
      "Policy train loss in epoch 1:1.5201635882258415\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.520163655281067\n",
      "\n",
      "episode 2, policy loss 1.5201635360717773\n",
      "\n",
      "episode 3, policy loss 1.5201635360717773\n",
      "\n",
      "episode 4, policy loss 1.5201635360717773\n",
      "\n",
      "episode 5, policy loss 1.5201632976531982\n",
      "\n",
      "episode 6, policy loss 1.520163893699646\n",
      "\n",
      "episode 7, policy loss 1.520163655281067\n",
      "\n",
      "episode 8, policy loss 1.520163893699646\n",
      "\n",
      "episode 9, policy loss 1.520163893699646\n",
      "\n",
      "episode 10, policy loss 1.5201635360717773\n",
      "\n",
      "episode 11, policy loss 1.52016282081604\n",
      "\n",
      "episode 12, policy loss 1.5201629400253296\n",
      "\n",
      "episode 13, policy loss 1.5201635360717773\n",
      "\n",
      "episode 14, policy loss 1.520163893699646\n",
      "\n",
      "episode 15, policy loss 1.520163655281067\n",
      "\n",
      "episode 16, policy loss 1.520164132118225\n",
      "\n",
      "Policy train loss in epoch 2:1.5201635882258415\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.5201635360717773\n",
      "\n",
      "episode 2, policy loss 1.520163893699646\n",
      "\n",
      "episode 3, policy loss 1.5201635360717773\n",
      "\n",
      "episode 4, policy loss 1.520163893699646\n",
      "\n",
      "episode 5, policy loss 1.5201635360717773\n",
      "\n",
      "episode 6, policy loss 1.5201635360717773\n",
      "\n",
      "episode 7, policy loss 1.520163655281067\n",
      "\n",
      "episode 8, policy loss 1.5201632976531982\n",
      "\n",
      "episode 9, policy loss 1.520163893699646\n",
      "\n",
      "episode 10, policy loss 1.52016282081604\n",
      "\n",
      "episode 11, policy loss 1.520163893699646\n",
      "\n",
      "episode 12, policy loss 1.5201635360717773\n",
      "\n",
      "episode 13, policy loss 1.5201629400253296\n",
      "\n",
      "episode 14, policy loss 1.520163655281067\n",
      "\n",
      "episode 15, policy loss 1.520163655281067\n",
      "\n",
      "episode 16, policy loss 1.520164132118225\n",
      "\n",
      "Policy train loss in epoch 3:1.5201635882258415\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7420531511306763\n",
      "\n",
      "episode 2, val func loss 0.7548009157180786\n",
      "\n",
      "episode 3, val func loss 0.825383722782135\n",
      "\n",
      "episode 4, val func loss 0.6941823959350586\n",
      "\n",
      "episode 5, val func loss 0.7457150220870972\n",
      "\n",
      "episode 6, val func loss 0.8476129174232483\n",
      "\n",
      "episode 7, val func loss 0.7119441032409668\n",
      "\n",
      "episode 8, val func loss 0.8504481911659241\n",
      "\n",
      "episode 9, val func loss 0.8359048962593079\n",
      "\n",
      "episode 10, val func loss 0.7913647890090942\n",
      "\n",
      "episode 11, val func loss 0.6367257833480835\n",
      "\n",
      "episode 12, val func loss 0.8300115466117859\n",
      "\n",
      "episode 13, val func loss 0.7671089172363281\n",
      "\n",
      "episode 14, val func loss 0.7279278635978699\n",
      "\n",
      "episode 15, val func loss 0.8741060495376587\n",
      "\n",
      "episode 16, val func loss 0.6842573881149292\n",
      "\n",
      "Val func train loss in epoch 0:0.7699717283248901\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.6041253805160522\n",
      "\n",
      "episode 2, val func loss 0.7344757914543152\n",
      "\n",
      "episode 3, val func loss 0.6497418880462646\n",
      "\n",
      "episode 4, val func loss 0.7635732293128967\n",
      "\n",
      "episode 5, val func loss 0.7430453300476074\n",
      "\n",
      "episode 6, val func loss 0.6721909642219543\n",
      "\n",
      "episode 7, val func loss 0.6729069352149963\n",
      "\n",
      "episode 8, val func loss 0.7028703689575195\n",
      "\n",
      "episode 9, val func loss 0.7558155059814453\n",
      "\n",
      "episode 10, val func loss 0.7269716858863831\n",
      "\n",
      "episode 11, val func loss 0.6740899682044983\n",
      "\n",
      "episode 12, val func loss 0.7449296116828918\n",
      "\n",
      "episode 13, val func loss 0.6988154053688049\n",
      "\n",
      "episode 14, val func loss 0.749853253364563\n",
      "\n",
      "episode 15, val func loss 0.8197392225265503\n",
      "\n",
      "episode 16, val func loss 0.7916039228439331\n",
      "\n",
      "Val func train loss in epoch 1:0.7190467789769173\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7742884159088135\n",
      "\n",
      "episode 2, val func loss 0.893383264541626\n",
      "\n",
      "episode 3, val func loss 0.7968444228172302\n",
      "\n",
      "episode 4, val func loss 0.7176268100738525\n",
      "\n",
      "episode 5, val func loss 0.802100419998169\n",
      "\n",
      "episode 6, val func loss 0.8014037013053894\n",
      "\n",
      "episode 7, val func loss 0.8586268424987793\n",
      "\n",
      "episode 8, val func loss 0.9096935391426086\n",
      "\n",
      "episode 9, val func loss 0.6718887686729431\n",
      "\n",
      "episode 10, val func loss 0.8833342790603638\n",
      "\n",
      "episode 11, val func loss 0.8094995021820068\n",
      "\n",
      "episode 12, val func loss 0.6734612584114075\n",
      "\n",
      "episode 13, val func loss 0.7542968392372131\n",
      "\n",
      "episode 14, val func loss 0.8242010474205017\n",
      "\n",
      "episode 15, val func loss 0.7921240329742432\n",
      "\n",
      "episode 16, val func loss 0.6630229353904724\n",
      "\n",
      "Val func train loss in epoch 2:0.7891122549772263\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8809500336647034\n",
      "\n",
      "episode 2, val func loss 0.7652246356010437\n",
      "\n",
      "episode 3, val func loss 0.692645788192749\n",
      "\n",
      "episode 4, val func loss 0.7302014827728271\n",
      "\n",
      "episode 5, val func loss 0.8800978064537048\n",
      "\n",
      "episode 6, val func loss 0.6336759924888611\n",
      "\n",
      "episode 7, val func loss 0.6892111301422119\n",
      "\n",
      "episode 8, val func loss 0.6936616897583008\n",
      "\n",
      "episode 9, val func loss 0.7553516030311584\n",
      "\n",
      "episode 10, val func loss 0.6801746487617493\n",
      "\n",
      "episode 11, val func loss 0.7755576372146606\n",
      "\n",
      "episode 12, val func loss 0.7210925817489624\n",
      "\n",
      "episode 13, val func loss 0.6826340556144714\n",
      "\n",
      "episode 14, val func loss 0.740116536617279\n",
      "\n",
      "episode 15, val func loss 0.8268307447433472\n",
      "\n",
      "episode 16, val func loss 0.8592298626899719\n",
      "\n",
      "Val func train loss in epoch 3:0.7504160143435001\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6813240051269531\n",
      "\n",
      "episode 2, val func loss 0.7384778261184692\n",
      "\n",
      "episode 3, val func loss 0.786322295665741\n",
      "\n",
      "episode 4, val func loss 0.8290178775787354\n",
      "\n",
      "episode 5, val func loss 0.6838551759719849\n",
      "\n",
      "episode 6, val func loss 0.7500726580619812\n",
      "\n",
      "episode 7, val func loss 0.8082816004753113\n",
      "\n",
      "episode 8, val func loss 0.784908652305603\n",
      "\n",
      "episode 9, val func loss 0.8349947929382324\n",
      "\n",
      "episode 10, val func loss 0.6636621952056885\n",
      "\n",
      "episode 11, val func loss 0.714144766330719\n",
      "\n",
      "episode 12, val func loss 0.6716857552528381\n",
      "\n",
      "episode 13, val func loss 0.7249525189399719\n",
      "\n",
      "episode 14, val func loss 0.8946976065635681\n",
      "\n",
      "episode 15, val func loss 0.7809816002845764\n",
      "\n",
      "episode 16, val func loss 0.7603490948677063\n",
      "\n",
      "Val func train loss in epoch 4:0.756733026355505\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7648910284042358\n",
      "\n",
      "episode 2, val func loss 0.7661543488502502\n",
      "\n",
      "episode 3, val func loss 0.6773257255554199\n",
      "\n",
      "episode 4, val func loss 0.7918679118156433\n",
      "\n",
      "episode 5, val func loss 0.7714686393737793\n",
      "\n",
      "episode 6, val func loss 0.7804057002067566\n",
      "\n",
      "episode 7, val func loss 0.7233121991157532\n",
      "\n",
      "episode 8, val func loss 0.689550518989563\n",
      "\n",
      "episode 9, val func loss 0.8105852603912354\n",
      "\n",
      "episode 10, val func loss 0.6565961837768555\n",
      "\n",
      "episode 11, val func loss 0.7805683612823486\n",
      "\n",
      "episode 12, val func loss 0.7756190299987793\n",
      "\n",
      "episode 13, val func loss 0.696083664894104\n",
      "\n",
      "episode 14, val func loss 0.8583257794380188\n",
      "\n",
      "episode 15, val func loss 0.8000521659851074\n",
      "\n",
      "episode 16, val func loss 0.7517040371894836\n",
      "\n",
      "Val func train loss in epoch 5:0.7559069097042084\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6559930443763733\n",
      "\n",
      "episode 2, val func loss 0.7623715996742249\n",
      "\n",
      "episode 3, val func loss 0.71510249376297\n",
      "\n",
      "episode 4, val func loss 0.6766449809074402\n",
      "\n",
      "episode 5, val func loss 0.7142471671104431\n",
      "\n",
      "episode 6, val func loss 0.7764406204223633\n",
      "\n",
      "episode 7, val func loss 0.6383309960365295\n",
      "\n",
      "episode 8, val func loss 0.7826687693595886\n",
      "\n",
      "episode 9, val func loss 0.8640407919883728\n",
      "\n",
      "episode 10, val func loss 0.8015692234039307\n",
      "\n",
      "episode 11, val func loss 0.7780104279518127\n",
      "\n",
      "episode 12, val func loss 0.7609627842903137\n",
      "\n",
      "episode 13, val func loss 0.8094442486763\n",
      "\n",
      "episode 14, val func loss 0.7432554364204407\n",
      "\n",
      "episode 15, val func loss 0.7242546081542969\n",
      "\n",
      "episode 16, val func loss 0.8014119267463684\n",
      "\n",
      "Val func train loss in epoch 6:0.7502968199551105\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7740297317504883\n",
      "\n",
      "episode 2, val func loss 0.734283447265625\n",
      "\n",
      "episode 3, val func loss 0.8318516612052917\n",
      "\n",
      "episode 4, val func loss 0.7117394208908081\n",
      "\n",
      "episode 5, val func loss 0.7103898525238037\n",
      "\n",
      "episode 6, val func loss 0.7870063185691833\n",
      "\n",
      "episode 7, val func loss 0.8104851841926575\n",
      "\n",
      "episode 8, val func loss 0.69322669506073\n",
      "\n",
      "episode 9, val func loss 0.8350382447242737\n",
      "\n",
      "episode 10, val func loss 0.7486283183097839\n",
      "\n",
      "episode 11, val func loss 0.8116510510444641\n",
      "\n",
      "episode 12, val func loss 0.6706076860427856\n",
      "\n",
      "episode 13, val func loss 0.8436515927314758\n",
      "\n",
      "episode 14, val func loss 0.8666711449623108\n",
      "\n",
      "episode 15, val func loss 0.7720257639884949\n",
      "\n",
      "episode 16, val func loss 0.684236466884613\n",
      "\n",
      "Val func train loss in epoch 7:0.7678451612591743\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.844963014125824\n",
      "\n",
      "episode 2, val func loss 0.7230517268180847\n",
      "\n",
      "episode 3, val func loss 0.8930453658103943\n",
      "\n",
      "episode 4, val func loss 0.7211267352104187\n",
      "\n",
      "episode 5, val func loss 0.8333292603492737\n",
      "\n",
      "episode 6, val func loss 0.7432295083999634\n",
      "\n",
      "episode 7, val func loss 0.7296775579452515\n",
      "\n",
      "episode 8, val func loss 0.8038836717605591\n",
      "\n",
      "episode 9, val func loss 0.7353185415267944\n",
      "\n",
      "episode 10, val func loss 0.7302000522613525\n",
      "\n",
      "episode 11, val func loss 0.8004510402679443\n",
      "\n",
      "episode 12, val func loss 0.6945770978927612\n",
      "\n",
      "episode 13, val func loss 0.6885210871696472\n",
      "\n",
      "episode 14, val func loss 0.7556173205375671\n",
      "\n",
      "episode 15, val func loss 0.8197281956672668\n",
      "\n",
      "episode 16, val func loss 0.8295787572860718\n",
      "\n",
      "Val func train loss in epoch 8:0.7716436833143234\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.7755054831504822\n",
      "\n",
      "episode 2, val func loss 0.7469549179077148\n",
      "\n",
      "episode 3, val func loss 0.8116647601127625\n",
      "\n",
      "episode 4, val func loss 0.8949217200279236\n",
      "\n",
      "episode 5, val func loss 0.6940825581550598\n",
      "\n",
      "episode 6, val func loss 0.6478471755981445\n",
      "\n",
      "episode 7, val func loss 0.7124801278114319\n",
      "\n",
      "episode 8, val func loss 0.7168780565261841\n",
      "\n",
      "episode 9, val func loss 0.6317158937454224\n",
      "\n",
      "episode 10, val func loss 0.6855140328407288\n",
      "\n",
      "episode 11, val func loss 0.7154678702354431\n",
      "\n",
      "episode 12, val func loss 0.7701340913772583\n",
      "\n",
      "episode 13, val func loss 0.7032744288444519\n",
      "\n",
      "episode 14, val func loss 0.7816442847251892\n",
      "\n",
      "episode 15, val func loss 0.7281082272529602\n",
      "\n",
      "episode 16, val func loss 0.722199559211731\n",
      "\n",
      "Val func train loss in epoch 9:0.7336495742201805\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7487995624542236\n",
      "\n",
      "episode 2, val func loss 0.7674632668495178\n",
      "\n",
      "episode 3, val func loss 0.7535881400108337\n",
      "\n",
      "episode 4, val func loss 0.7399833798408508\n",
      "\n",
      "episode 5, val func loss 0.7573550939559937\n",
      "\n",
      "episode 6, val func loss 0.7345889806747437\n",
      "\n",
      "episode 7, val func loss 0.6718951463699341\n",
      "\n",
      "episode 8, val func loss 0.6848537921905518\n",
      "\n",
      "episode 9, val func loss 0.7752262949943542\n",
      "\n",
      "episode 10, val func loss 0.8717078566551208\n",
      "\n",
      "episode 11, val func loss 0.708024799823761\n",
      "\n",
      "episode 12, val func loss 0.7457312941551208\n",
      "\n",
      "episode 13, val func loss 0.7369658350944519\n",
      "\n",
      "episode 14, val func loss 0.7112117409706116\n",
      "\n",
      "episode 15, val func loss 0.7542917728424072\n",
      "\n",
      "episode 16, val func loss 0.7282609939575195\n",
      "\n",
      "Val func train loss in epoch 10:0.7431217469274998\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6942120790481567\n",
      "\n",
      "episode 2, val func loss 0.7063812017440796\n",
      "\n",
      "episode 3, val func loss 0.7014133930206299\n",
      "\n",
      "episode 4, val func loss 0.7050729990005493\n",
      "\n",
      "episode 5, val func loss 0.7161278128623962\n",
      "\n",
      "episode 6, val func loss 0.7434782981872559\n",
      "\n",
      "episode 7, val func loss 0.673098087310791\n",
      "\n",
      "episode 8, val func loss 0.6280869245529175\n",
      "\n",
      "episode 9, val func loss 0.7404058575630188\n",
      "\n",
      "episode 10, val func loss 0.7333253622055054\n",
      "\n",
      "episode 11, val func loss 0.800955593585968\n",
      "\n",
      "episode 12, val func loss 0.6644111275672913\n",
      "\n",
      "episode 13, val func loss 0.7334054112434387\n",
      "\n",
      "episode 14, val func loss 0.6992091536521912\n",
      "\n",
      "episode 15, val func loss 0.678340494632721\n",
      "\n",
      "episode 16, val func loss 0.6979249119758606\n",
      "\n",
      "Val func train loss in epoch 11:0.7072405442595482\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7362024188041687\n",
      "\n",
      "episode 2, val func loss 0.6968164443969727\n",
      "\n",
      "episode 3, val func loss 0.7831671237945557\n",
      "\n",
      "episode 4, val func loss 0.7835129499435425\n",
      "\n",
      "episode 5, val func loss 0.6741777062416077\n",
      "\n",
      "episode 6, val func loss 0.72272789478302\n",
      "\n",
      "episode 7, val func loss 0.838483989238739\n",
      "\n",
      "episode 8, val func loss 0.7378696203231812\n",
      "\n",
      "episode 9, val func loss 0.7216478586196899\n",
      "\n",
      "episode 10, val func loss 0.802344799041748\n",
      "\n",
      "episode 11, val func loss 0.7435160279273987\n",
      "\n",
      "episode 12, val func loss 0.6494590044021606\n",
      "\n",
      "episode 13, val func loss 0.7996649146080017\n",
      "\n",
      "episode 14, val func loss 0.7043818831443787\n",
      "\n",
      "episode 15, val func loss 0.9028631448745728\n",
      "\n",
      "episode 16, val func loss 0.7046842575073242\n",
      "\n",
      "Val func train loss in epoch 12:0.7500950023531914\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.7136602401733398\n",
      "\n",
      "episode 2, val func loss 0.7258577942848206\n",
      "\n",
      "episode 3, val func loss 0.7585864067077637\n",
      "\n",
      "episode 4, val func loss 0.6612316966056824\n",
      "\n",
      "episode 5, val func loss 0.7597617506980896\n",
      "\n",
      "episode 6, val func loss 0.6273267269134521\n",
      "\n",
      "episode 7, val func loss 0.822235107421875\n",
      "\n",
      "episode 8, val func loss 0.7830864787101746\n",
      "\n",
      "episode 9, val func loss 0.7686019539833069\n",
      "\n",
      "episode 10, val func loss 0.7543902397155762\n",
      "\n",
      "episode 11, val func loss 0.7104880213737488\n",
      "\n",
      "episode 12, val func loss 0.7875200510025024\n",
      "\n",
      "episode 13, val func loss 0.6719813942909241\n",
      "\n",
      "episode 14, val func loss 0.6681162714958191\n",
      "\n",
      "episode 15, val func loss 0.8421939611434937\n",
      "\n",
      "episode 16, val func loss 0.8078252077102661\n",
      "\n",
      "Val func train loss in epoch 13:0.7414289563894272\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7558245658874512\n",
      "\n",
      "episode 2, val func loss 0.7149891257286072\n",
      "\n",
      "episode 3, val func loss 0.7445833086967468\n",
      "\n",
      "episode 4, val func loss 0.7815523743629456\n",
      "\n",
      "episode 5, val func loss 0.7694040536880493\n",
      "\n",
      "episode 6, val func loss 0.8549890518188477\n",
      "\n",
      "episode 7, val func loss 0.7356988191604614\n",
      "\n",
      "episode 8, val func loss 0.8102232217788696\n",
      "\n",
      "episode 9, val func loss 0.7829627990722656\n",
      "\n",
      "episode 10, val func loss 1.023032307624817\n",
      "\n",
      "episode 11, val func loss 0.7400370240211487\n",
      "\n",
      "episode 12, val func loss 0.9087027907371521\n",
      "\n",
      "episode 13, val func loss 0.7657399773597717\n",
      "\n",
      "episode 14, val func loss 0.7500871419906616\n",
      "\n",
      "episode 15, val func loss 0.8653193116188049\n",
      "\n",
      "episode 16, val func loss 0.681288480758667\n",
      "\n",
      "Val func train loss in epoch 14:0.7927771471440792\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6647356748580933\n",
      "\n",
      "episode 2, val func loss 0.7514821887016296\n",
      "\n",
      "episode 3, val func loss 0.6968368291854858\n",
      "\n",
      "episode 4, val func loss 0.80399090051651\n",
      "\n",
      "episode 5, val func loss 0.7900091409683228\n",
      "\n",
      "episode 6, val func loss 0.8019227981567383\n",
      "\n",
      "episode 7, val func loss 0.7406454682350159\n",
      "\n",
      "episode 8, val func loss 0.7245475053787231\n",
      "\n",
      "episode 9, val func loss 0.8283413648605347\n",
      "\n",
      "episode 10, val func loss 0.74056077003479\n",
      "\n",
      "episode 11, val func loss 0.7821083068847656\n",
      "\n",
      "episode 12, val func loss 0.7378445863723755\n",
      "\n",
      "episode 13, val func loss 0.8778024911880493\n",
      "\n",
      "episode 14, val func loss 0.7404105067253113\n",
      "\n",
      "episode 15, val func loss 0.7019926905632019\n",
      "\n",
      "episode 16, val func loss 0.7632539868354797\n",
      "\n",
      "Val func train loss in epoch 15:0.7591553255915642\n",
      "***********************TIME WAS 4.8396186351776125 min*****************************\n",
      "\n",
      "**********************ROUND 66 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.6217985153198242\n",
      "\n",
      "episode 2, policy loss 0.6217973828315735\n",
      "\n",
      "episode 3, policy loss 0.6217959523200989\n",
      "\n",
      "episode 4, policy loss 0.6217994689941406\n",
      "\n",
      "episode 5, policy loss 0.6217958331108093\n",
      "\n",
      "episode 6, policy loss 0.6217969059944153\n",
      "\n",
      "episode 7, policy loss 0.621798038482666\n",
      "\n",
      "episode 8, policy loss 0.6217957139015198\n",
      "\n",
      "episode 9, policy loss 0.6217978000640869\n",
      "\n",
      "episode 10, policy loss 0.6217984557151794\n",
      "\n",
      "episode 11, policy loss 0.6217994689941406\n",
      "\n",
      "episode 12, policy loss 0.6217950582504272\n",
      "\n",
      "episode 13, policy loss 0.6217960119247437\n",
      "\n",
      "episode 14, policy loss 0.6217950582504272\n",
      "\n",
      "episode 15, policy loss 0.6217976808547974\n",
      "\n",
      "episode 16, policy loss 0.6217985153198242\n",
      "\n",
      "Policy train loss in epoch 0:0.6217972412705421\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.6217958331108093\n",
      "\n",
      "episode 2, policy loss 0.6217985153198242\n",
      "\n",
      "episode 3, policy loss 0.6217994689941406\n",
      "\n",
      "episode 4, policy loss 0.6217973828315735\n",
      "\n",
      "episode 5, policy loss 0.6217978000640869\n",
      "\n",
      "episode 6, policy loss 0.6217957139015198\n",
      "\n",
      "episode 7, policy loss 0.6217994689941406\n",
      "\n",
      "episode 8, policy loss 0.6217985153198242\n",
      "\n",
      "episode 9, policy loss 0.6217950582504272\n",
      "\n",
      "episode 10, policy loss 0.6217969059944153\n",
      "\n",
      "episode 11, policy loss 0.6217984557151794\n",
      "\n",
      "episode 12, policy loss 0.621798038482666\n",
      "\n",
      "episode 13, policy loss 0.6217976808547974\n",
      "\n",
      "episode 14, policy loss 0.6217950582504272\n",
      "\n",
      "episode 15, policy loss 0.6217959523200989\n",
      "\n",
      "episode 16, policy loss 0.6217960119247437\n",
      "\n",
      "Policy train loss in epoch 1:0.6217972412705421\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.6217950582504272\n",
      "\n",
      "episode 2, policy loss 0.6217976808547974\n",
      "\n",
      "episode 3, policy loss 0.6217985153198242\n",
      "\n",
      "episode 4, policy loss 0.6217960119247437\n",
      "\n",
      "episode 5, policy loss 0.6217985153198242\n",
      "\n",
      "episode 6, policy loss 0.6217969059944153\n",
      "\n",
      "episode 7, policy loss 0.6217958331108093\n",
      "\n",
      "episode 8, policy loss 0.6217994689941406\n",
      "\n",
      "episode 9, policy loss 0.6217973828315735\n",
      "\n",
      "episode 10, policy loss 0.6217950582504272\n",
      "\n",
      "episode 11, policy loss 0.621798038482666\n",
      "\n",
      "episode 12, policy loss 0.6217994689941406\n",
      "\n",
      "episode 13, policy loss 0.6217957139015198\n",
      "\n",
      "episode 14, policy loss 0.6217978000640869\n",
      "\n",
      "episode 15, policy loss 0.6217959523200989\n",
      "\n",
      "episode 16, policy loss 0.6217984557151794\n",
      "\n",
      "Policy train loss in epoch 2:0.6217972412705421\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.6217994689941406\n",
      "\n",
      "episode 2, policy loss 0.621798038482666\n",
      "\n",
      "episode 3, policy loss 0.6217985153198242\n",
      "\n",
      "episode 4, policy loss 0.6217976808547974\n",
      "\n",
      "episode 5, policy loss 0.6217959523200989\n",
      "\n",
      "episode 6, policy loss 0.6217958331108093\n",
      "\n",
      "episode 7, policy loss 0.6217957139015198\n",
      "\n",
      "episode 8, policy loss 0.6217960119247437\n",
      "\n",
      "episode 9, policy loss 0.6217994689941406\n",
      "\n",
      "episode 10, policy loss 0.6217984557151794\n",
      "\n",
      "episode 11, policy loss 0.6217978000640869\n",
      "\n",
      "episode 12, policy loss 0.6217950582504272\n",
      "\n",
      "episode 13, policy loss 0.6217969059944153\n",
      "\n",
      "episode 14, policy loss 0.6217973828315735\n",
      "\n",
      "episode 15, policy loss 0.6217950582504272\n",
      "\n",
      "episode 16, policy loss 0.6217985153198242\n",
      "\n",
      "Policy train loss in epoch 3:0.6217972412705421\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.67502760887146\n",
      "\n",
      "episode 2, val func loss 0.6972585320472717\n",
      "\n",
      "episode 3, val func loss 0.6658846139907837\n",
      "\n",
      "episode 4, val func loss 0.7315452694892883\n",
      "\n",
      "episode 5, val func loss 0.6993537545204163\n",
      "\n",
      "episode 6, val func loss 0.715509831905365\n",
      "\n",
      "episode 7, val func loss 0.7298048138618469\n",
      "\n",
      "episode 8, val func loss 0.6679579615592957\n",
      "\n",
      "episode 9, val func loss 0.8467443585395813\n",
      "\n",
      "episode 10, val func loss 0.7433114647865295\n",
      "\n",
      "episode 11, val func loss 0.7673416137695312\n",
      "\n",
      "episode 12, val func loss 0.6870031952857971\n",
      "\n",
      "episode 13, val func loss 0.814504861831665\n",
      "\n",
      "episode 14, val func loss 0.7255619168281555\n",
      "\n",
      "episode 15, val func loss 0.7475749254226685\n",
      "\n",
      "episode 16, val func loss 0.7560754418373108\n",
      "\n",
      "Val func train loss in epoch 0:0.7294037602841854\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8398852348327637\n",
      "\n",
      "episode 2, val func loss 0.7458902597427368\n",
      "\n",
      "episode 3, val func loss 0.7503613233566284\n",
      "\n",
      "episode 4, val func loss 0.8233680129051208\n",
      "\n",
      "episode 5, val func loss 0.7164278626441956\n",
      "\n",
      "episode 6, val func loss 0.6894175410270691\n",
      "\n",
      "episode 7, val func loss 0.758414089679718\n",
      "\n",
      "episode 8, val func loss 0.8082976341247559\n",
      "\n",
      "episode 9, val func loss 0.8697460293769836\n",
      "\n",
      "episode 10, val func loss 0.7416445016860962\n",
      "\n",
      "episode 11, val func loss 0.8165354132652283\n",
      "\n",
      "episode 12, val func loss 0.8239220380783081\n",
      "\n",
      "episode 13, val func loss 0.7542306780815125\n",
      "\n",
      "episode 14, val func loss 0.7510566115379333\n",
      "\n",
      "episode 15, val func loss 0.7948118448257446\n",
      "\n",
      "episode 16, val func loss 0.7483232021331787\n",
      "\n",
      "Val func train loss in epoch 1:0.7770207673311234\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.5936793684959412\n",
      "\n",
      "episode 2, val func loss 0.678062379360199\n",
      "\n",
      "episode 3, val func loss 0.702444314956665\n",
      "\n",
      "episode 4, val func loss 0.7502805590629578\n",
      "\n",
      "episode 5, val func loss 0.6977754235267639\n",
      "\n",
      "episode 6, val func loss 0.6711864471435547\n",
      "\n",
      "episode 7, val func loss 0.71684330701828\n",
      "\n",
      "episode 8, val func loss 0.7371960878372192\n",
      "\n",
      "episode 9, val func loss 0.8484761118888855\n",
      "\n",
      "episode 10, val func loss 0.6758533120155334\n",
      "\n",
      "episode 11, val func loss 0.8108083009719849\n",
      "\n",
      "episode 12, val func loss 0.6378918886184692\n",
      "\n",
      "episode 13, val func loss 0.8154173493385315\n",
      "\n",
      "episode 14, val func loss 0.6449989080429077\n",
      "\n",
      "episode 15, val func loss 0.8088789582252502\n",
      "\n",
      "episode 16, val func loss 0.7473132014274597\n",
      "\n",
      "Val func train loss in epoch 2:0.7210691198706627\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.7107238173484802\n",
      "\n",
      "episode 2, val func loss 0.7900027632713318\n",
      "\n",
      "episode 3, val func loss 0.6957597732543945\n",
      "\n",
      "episode 4, val func loss 0.7186273336410522\n",
      "\n",
      "episode 5, val func loss 0.6864803433418274\n",
      "\n",
      "episode 6, val func loss 0.6756797432899475\n",
      "\n",
      "episode 7, val func loss 0.7310449481010437\n",
      "\n",
      "episode 8, val func loss 0.7931191921234131\n",
      "\n",
      "episode 9, val func loss 0.7370725274085999\n",
      "\n",
      "episode 10, val func loss 0.7020261883735657\n",
      "\n",
      "episode 11, val func loss 0.7319418787956238\n",
      "\n",
      "episode 12, val func loss 0.7028602957725525\n",
      "\n",
      "episode 13, val func loss 0.6753833889961243\n",
      "\n",
      "episode 14, val func loss 0.7978240251541138\n",
      "\n",
      "episode 15, val func loss 0.6661479473114014\n",
      "\n",
      "episode 16, val func loss 0.7234978079795837\n",
      "\n",
      "Val func train loss in epoch 3:0.721136998385191\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8280505537986755\n",
      "\n",
      "episode 2, val func loss 0.8049827218055725\n",
      "\n",
      "episode 3, val func loss 0.7783215045928955\n",
      "\n",
      "episode 4, val func loss 0.6457132697105408\n",
      "\n",
      "episode 5, val func loss 0.6983715891838074\n",
      "\n",
      "episode 6, val func loss 0.8144119381904602\n",
      "\n",
      "episode 7, val func loss 0.6975772976875305\n",
      "\n",
      "episode 8, val func loss 0.8214333653450012\n",
      "\n",
      "episode 9, val func loss 0.7415396571159363\n",
      "\n",
      "episode 10, val func loss 0.7557968497276306\n",
      "\n",
      "episode 11, val func loss 0.6453850269317627\n",
      "\n",
      "episode 12, val func loss 0.780649721622467\n",
      "\n",
      "episode 13, val func loss 0.8514435291290283\n",
      "\n",
      "episode 14, val func loss 0.7565587162971497\n",
      "\n",
      "episode 15, val func loss 0.7625342607498169\n",
      "\n",
      "episode 16, val func loss 0.683795690536499\n",
      "\n",
      "Val func train loss in epoch 4:0.7541603557765484\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7134881615638733\n",
      "\n",
      "episode 2, val func loss 0.6987135410308838\n",
      "\n",
      "episode 3, val func loss 0.7288399934768677\n",
      "\n",
      "episode 4, val func loss 0.7506974935531616\n",
      "\n",
      "episode 5, val func loss 0.7351675629615784\n",
      "\n",
      "episode 6, val func loss 0.7781916260719299\n",
      "\n",
      "episode 7, val func loss 0.7587589025497437\n",
      "\n",
      "episode 8, val func loss 0.7961344718933105\n",
      "\n",
      "episode 9, val func loss 0.7662547826766968\n",
      "\n",
      "episode 10, val func loss 0.7887653112411499\n",
      "\n",
      "episode 11, val func loss 0.7476509213447571\n",
      "\n",
      "episode 12, val func loss 0.7868016362190247\n",
      "\n",
      "episode 13, val func loss 0.6620199680328369\n",
      "\n",
      "episode 14, val func loss 0.9435477256774902\n",
      "\n",
      "episode 15, val func loss 0.9044821262359619\n",
      "\n",
      "episode 16, val func loss 0.8169337511062622\n",
      "\n",
      "Val func train loss in epoch 5:0.7735279984772205\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.9573367834091187\n",
      "\n",
      "episode 2, val func loss 0.890133261680603\n",
      "\n",
      "episode 3, val func loss 0.7939491271972656\n",
      "\n",
      "episode 4, val func loss 0.7528881430625916\n",
      "\n",
      "episode 5, val func loss 0.7126641869544983\n",
      "\n",
      "episode 6, val func loss 0.7636693716049194\n",
      "\n",
      "episode 7, val func loss 0.7063694000244141\n",
      "\n",
      "episode 8, val func loss 0.8141008615493774\n",
      "\n",
      "episode 9, val func loss 0.832800030708313\n",
      "\n",
      "episode 10, val func loss 0.8337448239326477\n",
      "\n",
      "episode 11, val func loss 0.7491937279701233\n",
      "\n",
      "episode 12, val func loss 0.8334693312644958\n",
      "\n",
      "episode 13, val func loss 0.7911490797996521\n",
      "\n",
      "episode 14, val func loss 0.9513110518455505\n",
      "\n",
      "episode 15, val func loss 0.8247150182723999\n",
      "\n",
      "episode 16, val func loss 0.8642327189445496\n",
      "\n",
      "Val func train loss in epoch 6:0.8169829323887825\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6709012985229492\n",
      "\n",
      "episode 2, val func loss 0.7856407165527344\n",
      "\n",
      "episode 3, val func loss 0.9881192445755005\n",
      "\n",
      "episode 4, val func loss 0.8336092829704285\n",
      "\n",
      "episode 5, val func loss 0.8104740977287292\n",
      "\n",
      "episode 6, val func loss 0.8332610726356506\n",
      "\n",
      "episode 7, val func loss 0.7731577157974243\n",
      "\n",
      "episode 8, val func loss 0.7308235168457031\n",
      "\n",
      "episode 9, val func loss 0.7877826690673828\n",
      "\n",
      "episode 10, val func loss 0.8316959738731384\n",
      "\n",
      "episode 11, val func loss 0.5997281074523926\n",
      "\n",
      "episode 12, val func loss 0.6447693705558777\n",
      "\n",
      "episode 13, val func loss 0.8521685600280762\n",
      "\n",
      "episode 14, val func loss 0.7987943887710571\n",
      "\n",
      "episode 15, val func loss 0.695246696472168\n",
      "\n",
      "episode 16, val func loss 0.8158820867538452\n",
      "\n",
      "Val func train loss in epoch 7:0.7782534249126911\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8567588925361633\n",
      "\n",
      "episode 2, val func loss 0.8198354244232178\n",
      "\n",
      "episode 3, val func loss 0.7057463526725769\n",
      "\n",
      "episode 4, val func loss 0.6873247623443604\n",
      "\n",
      "episode 5, val func loss 0.7267910838127136\n",
      "\n",
      "episode 6, val func loss 0.8571534752845764\n",
      "\n",
      "episode 7, val func loss 0.8072407245635986\n",
      "\n",
      "episode 8, val func loss 0.7901453375816345\n",
      "\n",
      "episode 9, val func loss 0.7779614329338074\n",
      "\n",
      "episode 10, val func loss 0.721967875957489\n",
      "\n",
      "episode 11, val func loss 0.7587867379188538\n",
      "\n",
      "episode 12, val func loss 0.6750312447547913\n",
      "\n",
      "episode 13, val func loss 0.6602144837379456\n",
      "\n",
      "episode 14, val func loss 0.6641530394554138\n",
      "\n",
      "episode 15, val func loss 0.6787149906158447\n",
      "\n",
      "episode 16, val func loss 0.739923894405365\n",
      "\n",
      "Val func train loss in epoch 8:0.745484359562397\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6753208041191101\n",
      "\n",
      "episode 2, val func loss 0.7692915797233582\n",
      "\n",
      "episode 3, val func loss 0.7055540680885315\n",
      "\n",
      "episode 4, val func loss 0.7860244512557983\n",
      "\n",
      "episode 5, val func loss 0.6811358332633972\n",
      "\n",
      "episode 6, val func loss 0.7131059765815735\n",
      "\n",
      "episode 7, val func loss 0.6785405874252319\n",
      "\n",
      "episode 8, val func loss 0.728840708732605\n",
      "\n",
      "episode 9, val func loss 0.7463043928146362\n",
      "\n",
      "episode 10, val func loss 0.7424218654632568\n",
      "\n",
      "episode 11, val func loss 0.7404215335845947\n",
      "\n",
      "episode 12, val func loss 0.729101836681366\n",
      "\n",
      "episode 13, val func loss 0.7555638551712036\n",
      "\n",
      "episode 14, val func loss 0.6921308636665344\n",
      "\n",
      "episode 15, val func loss 0.6861571073532104\n",
      "\n",
      "episode 16, val func loss 0.7253389358520508\n",
      "\n",
      "Val func train loss in epoch 9:0.7222033999860287\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6898947358131409\n",
      "\n",
      "episode 2, val func loss 0.6845870614051819\n",
      "\n",
      "episode 3, val func loss 0.6472088098526001\n",
      "\n",
      "episode 4, val func loss 0.7238702774047852\n",
      "\n",
      "episode 5, val func loss 0.7815224528312683\n",
      "\n",
      "episode 6, val func loss 0.8134161233901978\n",
      "\n",
      "episode 7, val func loss 0.7166830897331238\n",
      "\n",
      "episode 8, val func loss 0.6486313939094543\n",
      "\n",
      "episode 9, val func loss 0.7989267706871033\n",
      "\n",
      "episode 10, val func loss 0.7532179355621338\n",
      "\n",
      "episode 11, val func loss 0.7074296474456787\n",
      "\n",
      "episode 12, val func loss 0.8441115617752075\n",
      "\n",
      "episode 13, val func loss 0.7488434314727783\n",
      "\n",
      "episode 14, val func loss 0.8300651907920837\n",
      "\n",
      "episode 15, val func loss 0.7779137492179871\n",
      "\n",
      "episode 16, val func loss 0.7941023111343384\n",
      "\n",
      "Val func train loss in epoch 10:0.7475265339016914\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.8425722122192383\n",
      "\n",
      "episode 2, val func loss 0.7678418755531311\n",
      "\n",
      "episode 3, val func loss 0.9705348014831543\n",
      "\n",
      "episode 4, val func loss 0.6735475659370422\n",
      "\n",
      "episode 5, val func loss 0.9152255058288574\n",
      "\n",
      "episode 6, val func loss 0.7595642805099487\n",
      "\n",
      "episode 7, val func loss 0.6520326733589172\n",
      "\n",
      "episode 8, val func loss 0.7711090445518494\n",
      "\n",
      "episode 9, val func loss 0.7949591875076294\n",
      "\n",
      "episode 10, val func loss 0.7522421479225159\n",
      "\n",
      "episode 11, val func loss 0.7890048623085022\n",
      "\n",
      "episode 12, val func loss 0.6702101230621338\n",
      "\n",
      "episode 13, val func loss 0.832821249961853\n",
      "\n",
      "episode 14, val func loss 0.7236417531967163\n",
      "\n",
      "episode 15, val func loss 0.8687465786933899\n",
      "\n",
      "episode 16, val func loss 0.8249176144599915\n",
      "\n",
      "Val func train loss in epoch 11:0.7880607172846794\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7140035629272461\n",
      "\n",
      "episode 2, val func loss 0.7316243052482605\n",
      "\n",
      "episode 3, val func loss 0.771859884262085\n",
      "\n",
      "episode 4, val func loss 0.7954574227333069\n",
      "\n",
      "episode 5, val func loss 0.7455170154571533\n",
      "\n",
      "episode 6, val func loss 0.7124417424201965\n",
      "\n",
      "episode 7, val func loss 0.7588285207748413\n",
      "\n",
      "episode 8, val func loss 0.7529422044754028\n",
      "\n",
      "episode 9, val func loss 0.712962806224823\n",
      "\n",
      "episode 10, val func loss 0.7403750419616699\n",
      "\n",
      "episode 11, val func loss 0.7363712787628174\n",
      "\n",
      "episode 12, val func loss 0.7062795162200928\n",
      "\n",
      "episode 13, val func loss 0.6926498413085938\n",
      "\n",
      "episode 14, val func loss 0.7010413408279419\n",
      "\n",
      "episode 15, val func loss 0.6141864061355591\n",
      "\n",
      "episode 16, val func loss 0.6720343232154846\n",
      "\n",
      "Val func train loss in epoch 12:0.7224109508097172\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.7742982506752014\n",
      "\n",
      "episode 2, val func loss 0.7007352113723755\n",
      "\n",
      "episode 3, val func loss 0.7733482718467712\n",
      "\n",
      "episode 4, val func loss 0.728298544883728\n",
      "\n",
      "episode 5, val func loss 0.6947565078735352\n",
      "\n",
      "episode 6, val func loss 0.716076135635376\n",
      "\n",
      "episode 7, val func loss 0.8258216977119446\n",
      "\n",
      "episode 8, val func loss 0.608603298664093\n",
      "\n",
      "episode 9, val func loss 0.6396320462226868\n",
      "\n",
      "episode 10, val func loss 0.6677403450012207\n",
      "\n",
      "episode 11, val func loss 0.7825027108192444\n",
      "\n",
      "episode 12, val func loss 0.7097370624542236\n",
      "\n",
      "episode 13, val func loss 0.6837921738624573\n",
      "\n",
      "episode 14, val func loss 0.7738555669784546\n",
      "\n",
      "episode 15, val func loss 0.7720380425453186\n",
      "\n",
      "episode 16, val func loss 0.6444869637489319\n",
      "\n",
      "Val func train loss in epoch 13:0.7184826768934727\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6551845669746399\n",
      "\n",
      "episode 2, val func loss 0.7940128445625305\n",
      "\n",
      "episode 3, val func loss 0.7826062440872192\n",
      "\n",
      "episode 4, val func loss 0.7118769288063049\n",
      "\n",
      "episode 5, val func loss 0.7308754324913025\n",
      "\n",
      "episode 6, val func loss 0.6721587181091309\n",
      "\n",
      "episode 7, val func loss 0.7042014002799988\n",
      "\n",
      "episode 8, val func loss 0.7647573947906494\n",
      "\n",
      "episode 9, val func loss 0.7062231302261353\n",
      "\n",
      "episode 10, val func loss 0.7790749669075012\n",
      "\n",
      "episode 11, val func loss 0.7803747653961182\n",
      "\n",
      "episode 12, val func loss 0.641130268573761\n",
      "\n",
      "episode 13, val func loss 0.7655876874923706\n",
      "\n",
      "episode 14, val func loss 0.9754939079284668\n",
      "\n",
      "episode 15, val func loss 0.736355185508728\n",
      "\n",
      "episode 16, val func loss 0.8854929804801941\n",
      "\n",
      "Val func train loss in epoch 14:0.7553379014134407\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.8862547278404236\n",
      "\n",
      "episode 2, val func loss 0.8501749634742737\n",
      "\n",
      "episode 3, val func loss 0.8293871879577637\n",
      "\n",
      "episode 4, val func loss 0.8698896765708923\n",
      "\n",
      "episode 5, val func loss 0.843390941619873\n",
      "\n",
      "episode 6, val func loss 0.6342349648475647\n",
      "\n",
      "episode 7, val func loss 0.782896876335144\n",
      "\n",
      "episode 8, val func loss 0.6956174969673157\n",
      "\n",
      "episode 9, val func loss 0.766097366809845\n",
      "\n",
      "episode 10, val func loss 0.6899481415748596\n",
      "\n",
      "episode 11, val func loss 0.7016537189483643\n",
      "\n",
      "episode 12, val func loss 0.8023775219917297\n",
      "\n",
      "episode 13, val func loss 0.7722060084342957\n",
      "\n",
      "episode 14, val func loss 0.72515869140625\n",
      "\n",
      "episode 15, val func loss 0.7155839800834656\n",
      "\n",
      "episode 16, val func loss 0.7334924340248108\n",
      "\n",
      "Val func train loss in epoch 15:0.7686477936804295\n",
      "***********************TIME WAS 4.842902890841166 min*****************************\n",
      "\n",
      "**********************ROUND 67 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.0933895111083984\n",
      "\n",
      "episode 2, policy loss 1.0933893918991089\n",
      "\n",
      "episode 3, policy loss 1.0933878421783447\n",
      "\n",
      "episode 4, policy loss 1.0933890342712402\n",
      "\n",
      "episode 5, policy loss 1.0933905839920044\n",
      "\n",
      "episode 6, policy loss 1.0933895111083984\n",
      "\n",
      "episode 7, policy loss 1.0933901071548462\n",
      "\n",
      "episode 8, policy loss 1.0933890342712402\n",
      "\n",
      "episode 9, policy loss 1.0933897495269775\n",
      "\n",
      "episode 10, policy loss 1.0933895111083984\n",
      "\n",
      "episode 11, policy loss 1.093388557434082\n",
      "\n",
      "episode 12, policy loss 1.093388319015503\n",
      "\n",
      "episode 13, policy loss 1.093389630317688\n",
      "\n",
      "episode 14, policy loss 1.0933895111083984\n",
      "\n",
      "episode 15, policy loss 1.0933891534805298\n",
      "\n",
      "episode 16, policy loss 1.0933901071548462\n",
      "\n",
      "Policy train loss in epoch 0:1.0933893471956253\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.0933897495269775\n",
      "\n",
      "episode 2, policy loss 1.0933893918991089\n",
      "\n",
      "episode 3, policy loss 1.093388557434082\n",
      "\n",
      "episode 4, policy loss 1.093388319015503\n",
      "\n",
      "episode 5, policy loss 1.0933905839920044\n",
      "\n",
      "episode 6, policy loss 1.0933901071548462\n",
      "\n",
      "episode 7, policy loss 1.0933890342712402\n",
      "\n",
      "episode 8, policy loss 1.0933895111083984\n",
      "\n",
      "episode 9, policy loss 1.0933878421783447\n",
      "\n",
      "episode 10, policy loss 1.0933895111083984\n",
      "\n",
      "episode 11, policy loss 1.093389630317688\n",
      "\n",
      "episode 12, policy loss 1.0933895111083984\n",
      "\n",
      "episode 13, policy loss 1.0933891534805298\n",
      "\n",
      "episode 14, policy loss 1.0933890342712402\n",
      "\n",
      "episode 15, policy loss 1.0933901071548462\n",
      "\n",
      "episode 16, policy loss 1.0933895111083984\n",
      "\n",
      "Policy train loss in epoch 1:1.0933893471956253\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.0933895111083984\n",
      "\n",
      "episode 2, policy loss 1.0933895111083984\n",
      "\n",
      "episode 3, policy loss 1.0933890342712402\n",
      "\n",
      "episode 4, policy loss 1.093389630317688\n",
      "\n",
      "episode 5, policy loss 1.093388319015503\n",
      "\n",
      "episode 6, policy loss 1.0933901071548462\n",
      "\n",
      "episode 7, policy loss 1.0933878421783447\n",
      "\n",
      "episode 8, policy loss 1.0933901071548462\n",
      "\n",
      "episode 9, policy loss 1.0933905839920044\n",
      "\n",
      "episode 10, policy loss 1.0933895111083984\n",
      "\n",
      "episode 11, policy loss 1.0933891534805298\n",
      "\n",
      "episode 12, policy loss 1.0933890342712402\n",
      "\n",
      "episode 13, policy loss 1.093388557434082\n",
      "\n",
      "episode 14, policy loss 1.0933893918991089\n",
      "\n",
      "episode 15, policy loss 1.0933895111083984\n",
      "\n",
      "episode 16, policy loss 1.0933897495269775\n",
      "\n",
      "Policy train loss in epoch 2:1.0933893471956253\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.0933890342712402\n",
      "\n",
      "episode 2, policy loss 1.0933893918991089\n",
      "\n",
      "episode 3, policy loss 1.0933897495269775\n",
      "\n",
      "episode 4, policy loss 1.093384861946106\n",
      "\n",
      "episode 5, policy loss 1.0933657884597778\n",
      "\n",
      "episode 6, policy loss 1.0928387641906738\n",
      "\n",
      "episode 7, policy loss 1.056248664855957\n",
      "\n",
      "episode 8, policy loss 1.2925528287887573\n",
      "\n",
      "episode 9, policy loss 1.1704870462417603\n",
      "\n",
      "episode 10, policy loss 1.0484967231750488\n",
      "\n",
      "episode 11, policy loss 1.0752677917480469\n",
      "\n",
      "episode 12, policy loss 1.0772788524627686\n",
      "\n",
      "episode 13, policy loss 1.073664665222168\n",
      "\n",
      "episode 14, policy loss 1.0560429096221924\n",
      "\n",
      "episode 15, policy loss 0.993026077747345\n",
      "\n",
      "episode 16, policy loss 1.059045672416687\n",
      "\n",
      "Policy train loss in epoch 3:1.0913668014109135\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.846635103225708\n",
      "\n",
      "episode 2, val func loss 0.7811318635940552\n",
      "\n",
      "episode 3, val func loss 0.7140506505966187\n",
      "\n",
      "episode 4, val func loss 0.7000316977500916\n",
      "\n",
      "episode 5, val func loss 0.7316243648529053\n",
      "\n",
      "episode 6, val func loss 0.6823272705078125\n",
      "\n",
      "episode 7, val func loss 0.636056661605835\n",
      "\n",
      "episode 8, val func loss 0.6701974868774414\n",
      "\n",
      "episode 9, val func loss 0.7703644633293152\n",
      "\n",
      "episode 10, val func loss 0.6565017700195312\n",
      "\n",
      "episode 11, val func loss 0.722280740737915\n",
      "\n",
      "episode 12, val func loss 0.7224205732345581\n",
      "\n",
      "episode 13, val func loss 0.7342397570610046\n",
      "\n",
      "episode 14, val func loss 0.7102152109146118\n",
      "\n",
      "episode 15, val func loss 0.6271229982376099\n",
      "\n",
      "episode 16, val func loss 0.7217268943786621\n",
      "\n",
      "Val func train loss in epoch 0:0.7141829691827297\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.6815494298934937\n",
      "\n",
      "episode 2, val func loss 0.8006122708320618\n",
      "\n",
      "episode 3, val func loss 0.7299970388412476\n",
      "\n",
      "episode 4, val func loss 0.6831415891647339\n",
      "\n",
      "episode 5, val func loss 0.759713888168335\n",
      "\n",
      "episode 6, val func loss 0.628495991230011\n",
      "\n",
      "episode 7, val func loss 0.6425607204437256\n",
      "\n",
      "episode 8, val func loss 0.6768589019775391\n",
      "\n",
      "episode 9, val func loss 0.6819168925285339\n",
      "\n",
      "episode 10, val func loss 0.6418572664260864\n",
      "\n",
      "episode 11, val func loss 0.7513955235481262\n",
      "\n",
      "episode 12, val func loss 0.7300637364387512\n",
      "\n",
      "episode 13, val func loss 0.7371435165405273\n",
      "\n",
      "episode 14, val func loss 0.7588099837303162\n",
      "\n",
      "episode 15, val func loss 0.649359405040741\n",
      "\n",
      "episode 16, val func loss 0.7554895877838135\n",
      "\n",
      "Val func train loss in epoch 1:0.7068103589117527\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7022477984428406\n",
      "\n",
      "episode 2, val func loss 0.7200170159339905\n",
      "\n",
      "episode 3, val func loss 0.7007678747177124\n",
      "\n",
      "episode 4, val func loss 0.679815411567688\n",
      "\n",
      "episode 5, val func loss 0.7311363220214844\n",
      "\n",
      "episode 6, val func loss 0.7617342472076416\n",
      "\n",
      "episode 7, val func loss 0.7197874188423157\n",
      "\n",
      "episode 8, val func loss 0.7682628035545349\n",
      "\n",
      "episode 9, val func loss 0.8230106830596924\n",
      "\n",
      "episode 10, val func loss 0.9071952104568481\n",
      "\n",
      "episode 11, val func loss 0.6620951294898987\n",
      "\n",
      "episode 12, val func loss 0.6117129325866699\n",
      "\n",
      "episode 13, val func loss 0.7182824611663818\n",
      "\n",
      "episode 14, val func loss 0.8184852600097656\n",
      "\n",
      "episode 15, val func loss 0.7147483825683594\n",
      "\n",
      "episode 16, val func loss 0.7182356715202332\n",
      "\n",
      "Val func train loss in epoch 2:0.7348459139466286\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.9023077487945557\n",
      "\n",
      "episode 2, val func loss 0.6837924718856812\n",
      "\n",
      "episode 3, val func loss 0.6294018030166626\n",
      "\n",
      "episode 4, val func loss 0.8582867383956909\n",
      "\n",
      "episode 5, val func loss 0.7176542282104492\n",
      "\n",
      "episode 6, val func loss 0.7292358875274658\n",
      "\n",
      "episode 7, val func loss 0.797879695892334\n",
      "\n",
      "episode 8, val func loss 0.7589622139930725\n",
      "\n",
      "episode 9, val func loss 0.7036668062210083\n",
      "\n",
      "episode 10, val func loss 0.7183263897895813\n",
      "\n",
      "episode 11, val func loss 0.7887852787971497\n",
      "\n",
      "episode 12, val func loss 0.7762826085090637\n",
      "\n",
      "episode 13, val func loss 0.6997346878051758\n",
      "\n",
      "episode 14, val func loss 0.7836779952049255\n",
      "\n",
      "episode 15, val func loss 0.7970777750015259\n",
      "\n",
      "episode 16, val func loss 0.6848897933959961\n",
      "\n",
      "Val func train loss in epoch 3:0.7518726326525211\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6736887097358704\n",
      "\n",
      "episode 2, val func loss 0.7744669318199158\n",
      "\n",
      "episode 3, val func loss 0.7793936729431152\n",
      "\n",
      "episode 4, val func loss 0.6970937848091125\n",
      "\n",
      "episode 5, val func loss 0.7644570469856262\n",
      "\n",
      "episode 6, val func loss 0.7123313546180725\n",
      "\n",
      "episode 7, val func loss 0.830553412437439\n",
      "\n",
      "episode 8, val func loss 0.663580060005188\n",
      "\n",
      "episode 9, val func loss 0.7536815404891968\n",
      "\n",
      "episode 10, val func loss 0.7065284848213196\n",
      "\n",
      "episode 11, val func loss 0.7359133362770081\n",
      "\n",
      "episode 12, val func loss 0.7382017970085144\n",
      "\n",
      "episode 13, val func loss 0.6937242150306702\n",
      "\n",
      "episode 14, val func loss 0.7238656878471375\n",
      "\n",
      "episode 15, val func loss 0.7068794369697571\n",
      "\n",
      "episode 16, val func loss 0.6882419586181641\n",
      "\n",
      "Val func train loss in epoch 4:0.7276625894010067\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.8518633246421814\n",
      "\n",
      "episode 2, val func loss 0.6973155736923218\n",
      "\n",
      "episode 3, val func loss 0.8240782618522644\n",
      "\n",
      "episode 4, val func loss 0.6954361796379089\n",
      "\n",
      "episode 5, val func loss 0.7977614998817444\n",
      "\n",
      "episode 6, val func loss 0.6732286214828491\n",
      "\n",
      "episode 7, val func loss 0.752252995967865\n",
      "\n",
      "episode 8, val func loss 0.7031843662261963\n",
      "\n",
      "episode 9, val func loss 0.7578927874565125\n",
      "\n",
      "episode 10, val func loss 0.6875169277191162\n",
      "\n",
      "episode 11, val func loss 0.8131352663040161\n",
      "\n",
      "episode 12, val func loss 0.6789070963859558\n",
      "\n",
      "episode 13, val func loss 0.7513364553451538\n",
      "\n",
      "episode 14, val func loss 0.7073812484741211\n",
      "\n",
      "episode 15, val func loss 0.7186931371688843\n",
      "\n",
      "episode 16, val func loss 0.6760919690132141\n",
      "\n",
      "Val func train loss in epoch 5:0.7366297319531441\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8368671536445618\n",
      "\n",
      "episode 2, val func loss 0.7300194501876831\n",
      "\n",
      "episode 3, val func loss 0.7750264406204224\n",
      "\n",
      "episode 4, val func loss 0.6476148366928101\n",
      "\n",
      "episode 5, val func loss 0.7104833722114563\n",
      "\n",
      "episode 6, val func loss 0.7070648670196533\n",
      "\n",
      "episode 7, val func loss 0.6567845940589905\n",
      "\n",
      "episode 8, val func loss 0.7745844721794128\n",
      "\n",
      "episode 9, val func loss 0.7070127129554749\n",
      "\n",
      "episode 10, val func loss 0.7095463275909424\n",
      "\n",
      "episode 11, val func loss 0.7576675415039062\n",
      "\n",
      "episode 12, val func loss 0.769426703453064\n",
      "\n",
      "episode 13, val func loss 0.7457826733589172\n",
      "\n",
      "episode 14, val func loss 0.6820805668830872\n",
      "\n",
      "episode 15, val func loss 0.6414462924003601\n",
      "\n",
      "episode 16, val func loss 0.7328839898109436\n",
      "\n",
      "Val func train loss in epoch 6:0.7240182496607304\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7215963006019592\n",
      "\n",
      "episode 2, val func loss 0.7367671728134155\n",
      "\n",
      "episode 3, val func loss 0.7025976777076721\n",
      "\n",
      "episode 4, val func loss 0.7593553066253662\n",
      "\n",
      "episode 5, val func loss 0.7887092232704163\n",
      "\n",
      "episode 6, val func loss 0.6690351366996765\n",
      "\n",
      "episode 7, val func loss 0.6546907424926758\n",
      "\n",
      "episode 8, val func loss 0.6972406506538391\n",
      "\n",
      "episode 9, val func loss 0.7409254908561707\n",
      "\n",
      "episode 10, val func loss 0.7881929874420166\n",
      "\n",
      "episode 11, val func loss 0.717677891254425\n",
      "\n",
      "episode 12, val func loss 0.7018972635269165\n",
      "\n",
      "episode 13, val func loss 0.685791552066803\n",
      "\n",
      "episode 14, val func loss 0.8106382489204407\n",
      "\n",
      "episode 15, val func loss 0.7438265085220337\n",
      "\n",
      "episode 16, val func loss 0.8978212475776672\n",
      "\n",
      "Val func train loss in epoch 7:0.7385477125644684\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7944432497024536\n",
      "\n",
      "episode 2, val func loss 0.6839914321899414\n",
      "\n",
      "episode 3, val func loss 0.8312154412269592\n",
      "\n",
      "episode 4, val func loss 0.8021248579025269\n",
      "\n",
      "episode 5, val func loss 0.7688633799552917\n",
      "\n",
      "episode 6, val func loss 0.7401494979858398\n",
      "\n",
      "episode 7, val func loss 0.7772144079208374\n",
      "\n",
      "episode 8, val func loss 0.7204053997993469\n",
      "\n",
      "episode 9, val func loss 0.7782094478607178\n",
      "\n",
      "episode 10, val func loss 0.7398415803909302\n",
      "\n",
      "episode 11, val func loss 0.7411639094352722\n",
      "\n",
      "episode 12, val func loss 0.8202115297317505\n",
      "\n",
      "episode 13, val func loss 0.7510301470756531\n",
      "\n",
      "episode 14, val func loss 0.6387394666671753\n",
      "\n",
      "episode 15, val func loss 0.7711706161499023\n",
      "\n",
      "episode 16, val func loss 0.9891020655632019\n",
      "\n",
      "Val func train loss in epoch 8:0.7717422768473625\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.7669767737388611\n",
      "\n",
      "episode 2, val func loss 0.6974945068359375\n",
      "\n",
      "episode 3, val func loss 0.6921620965003967\n",
      "\n",
      "episode 4, val func loss 0.7810725569725037\n",
      "\n",
      "episode 5, val func loss 0.81993168592453\n",
      "\n",
      "episode 6, val func loss 0.7685911059379578\n",
      "\n",
      "episode 7, val func loss 0.7285740375518799\n",
      "\n",
      "episode 8, val func loss 0.9187045693397522\n",
      "\n",
      "episode 9, val func loss 0.8550798892974854\n",
      "\n",
      "episode 10, val func loss 0.7977083325386047\n",
      "\n",
      "episode 11, val func loss 1.1613081693649292\n",
      "\n",
      "episode 12, val func loss 0.6753590106964111\n",
      "\n",
      "episode 13, val func loss 0.831947922706604\n",
      "\n",
      "episode 14, val func loss 1.1344759464263916\n",
      "\n",
      "episode 15, val func loss 0.6476064920425415\n",
      "\n",
      "episode 16, val func loss 0.6550416946411133\n",
      "\n",
      "Val func train loss in epoch 9:0.8082521744072437\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7934520840644836\n",
      "\n",
      "episode 2, val func loss 0.7435236573219299\n",
      "\n",
      "episode 3, val func loss 0.7481998801231384\n",
      "\n",
      "episode 4, val func loss 0.7816041111946106\n",
      "\n",
      "episode 5, val func loss 0.7242617607116699\n",
      "\n",
      "episode 6, val func loss 0.7716233730316162\n",
      "\n",
      "episode 7, val func loss 0.7068705558776855\n",
      "\n",
      "episode 8, val func loss 0.7772179841995239\n",
      "\n",
      "episode 9, val func loss 0.6758038401603699\n",
      "\n",
      "episode 10, val func loss 0.7206799387931824\n",
      "\n",
      "episode 11, val func loss 0.7272868156433105\n",
      "\n",
      "episode 12, val func loss 0.7145364284515381\n",
      "\n",
      "episode 13, val func loss 0.71625816822052\n",
      "\n",
      "episode 14, val func loss 0.6240797638893127\n",
      "\n",
      "episode 15, val func loss 0.6911521553993225\n",
      "\n",
      "episode 16, val func loss 0.664024293422699\n",
      "\n",
      "Val func train loss in epoch 10:0.7237859256565571\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7865970730781555\n",
      "\n",
      "episode 2, val func loss 0.6533825397491455\n",
      "\n",
      "episode 3, val func loss 0.704753041267395\n",
      "\n",
      "episode 4, val func loss 0.6223626732826233\n",
      "\n",
      "episode 5, val func loss 0.7120223641395569\n",
      "\n",
      "episode 6, val func loss 0.6972255706787109\n",
      "\n",
      "episode 7, val func loss 0.5657485723495483\n",
      "\n",
      "episode 8, val func loss 0.8912168145179749\n",
      "\n",
      "episode 9, val func loss 0.6673451662063599\n",
      "\n",
      "episode 10, val func loss 0.80540931224823\n",
      "\n",
      "episode 11, val func loss 0.6690412759780884\n",
      "\n",
      "episode 12, val func loss 0.7157866358757019\n",
      "\n",
      "episode 13, val func loss 0.7265601754188538\n",
      "\n",
      "episode 14, val func loss 0.7282723188400269\n",
      "\n",
      "episode 15, val func loss 0.6464444994926453\n",
      "\n",
      "episode 16, val func loss 0.6297827959060669\n",
      "\n",
      "Val func train loss in epoch 11:0.7013719268143177\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.778753399848938\n",
      "\n",
      "episode 2, val func loss 0.7175840139389038\n",
      "\n",
      "episode 3, val func loss 0.6912410855293274\n",
      "\n",
      "episode 4, val func loss 0.7356560230255127\n",
      "\n",
      "episode 5, val func loss 0.7811155319213867\n",
      "\n",
      "episode 6, val func loss 0.7076998353004456\n",
      "\n",
      "episode 7, val func loss 0.7040275931358337\n",
      "\n",
      "episode 8, val func loss 0.6768221855163574\n",
      "\n",
      "episode 9, val func loss 0.6415422558784485\n",
      "\n",
      "episode 10, val func loss 0.7601699829101562\n",
      "\n",
      "episode 11, val func loss 0.6750720739364624\n",
      "\n",
      "episode 12, val func loss 0.7900508642196655\n",
      "\n",
      "episode 13, val func loss 0.7000683546066284\n",
      "\n",
      "episode 14, val func loss 0.7146199345588684\n",
      "\n",
      "episode 15, val func loss 0.7318259477615356\n",
      "\n",
      "episode 16, val func loss 0.5898886322975159\n",
      "\n",
      "Val func train loss in epoch 12:0.7122586071491241\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6482426524162292\n",
      "\n",
      "episode 2, val func loss 0.6288298964500427\n",
      "\n",
      "episode 3, val func loss 0.8125446438789368\n",
      "\n",
      "episode 4, val func loss 0.7356501817703247\n",
      "\n",
      "episode 5, val func loss 0.6215178370475769\n",
      "\n",
      "episode 6, val func loss 0.7102130651473999\n",
      "\n",
      "episode 7, val func loss 0.6867653727531433\n",
      "\n",
      "episode 8, val func loss 0.6501672267913818\n",
      "\n",
      "episode 9, val func loss 0.7126160860061646\n",
      "\n",
      "episode 10, val func loss 0.6911993026733398\n",
      "\n",
      "episode 11, val func loss 0.6138814091682434\n",
      "\n",
      "episode 12, val func loss 0.686766505241394\n",
      "\n",
      "episode 13, val func loss 0.7062684893608093\n",
      "\n",
      "episode 14, val func loss 0.7136452794075012\n",
      "\n",
      "episode 15, val func loss 0.6412425637245178\n",
      "\n",
      "episode 16, val func loss 0.7835386395454407\n",
      "\n",
      "Val func train loss in epoch 13:0.6901930719614029\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7784796357154846\n",
      "\n",
      "episode 2, val func loss 0.6915453672409058\n",
      "\n",
      "episode 3, val func loss 0.667682409286499\n",
      "\n",
      "episode 4, val func loss 0.6765395402908325\n",
      "\n",
      "episode 5, val func loss 0.6769360899925232\n",
      "\n",
      "episode 6, val func loss 0.6987932324409485\n",
      "\n",
      "episode 7, val func loss 0.7293975949287415\n",
      "\n",
      "episode 8, val func loss 0.7143105268478394\n",
      "\n",
      "episode 9, val func loss 0.7409663200378418\n",
      "\n",
      "episode 10, val func loss 0.6763845086097717\n",
      "\n",
      "episode 11, val func loss 0.7562431693077087\n",
      "\n",
      "episode 12, val func loss 0.6615036129951477\n",
      "\n",
      "episode 13, val func loss 0.6703119277954102\n",
      "\n",
      "episode 14, val func loss 0.7401217818260193\n",
      "\n",
      "episode 15, val func loss 0.6242474913597107\n",
      "\n",
      "episode 16, val func loss 0.7386471629142761\n",
      "\n",
      "Val func train loss in epoch 14:0.7026318982243538\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6973602771759033\n",
      "\n",
      "episode 2, val func loss 0.7203229069709778\n",
      "\n",
      "episode 3, val func loss 0.7042382955551147\n",
      "\n",
      "episode 4, val func loss 0.7360568046569824\n",
      "\n",
      "episode 5, val func loss 0.7419768571853638\n",
      "\n",
      "episode 6, val func loss 0.6721805334091187\n",
      "\n",
      "episode 7, val func loss 0.6298143267631531\n",
      "\n",
      "episode 8, val func loss 0.7391770482063293\n",
      "\n",
      "episode 9, val func loss 0.7004667520523071\n",
      "\n",
      "episode 10, val func loss 0.6744214296340942\n",
      "\n",
      "episode 11, val func loss 0.7185244560241699\n",
      "\n",
      "episode 12, val func loss 0.7587249875068665\n",
      "\n",
      "episode 13, val func loss 0.6454886794090271\n",
      "\n",
      "episode 14, val func loss 0.733357310295105\n",
      "\n",
      "episode 15, val func loss 0.7823710441589355\n",
      "\n",
      "episode 16, val func loss 0.7526059746742249\n",
      "\n",
      "Val func train loss in epoch 15:0.7129429802298546\n",
      "***********************TIME WAS 4.845393053690592 min*****************************\n",
      "\n",
      "**********************ROUND 68 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 2.5560226440429688\n",
      "\n",
      "episode 2, policy loss 2.8653321266174316\n",
      "\n",
      "episode 3, policy loss 3.08211612701416\n",
      "\n",
      "episode 4, policy loss 2.901735305786133\n",
      "\n",
      "episode 5, policy loss 2.8766181468963623\n",
      "\n",
      "episode 6, policy loss 3.1582770347595215\n",
      "\n",
      "episode 7, policy loss 3.0145199298858643\n",
      "\n",
      "episode 8, policy loss 2.8468995094299316\n",
      "\n",
      "episode 9, policy loss 3.040374279022217\n",
      "\n",
      "episode 10, policy loss 2.99477219581604\n",
      "\n",
      "episode 11, policy loss 3.1023194789886475\n",
      "\n",
      "episode 12, policy loss 2.93561053276062\n",
      "\n",
      "episode 13, policy loss 2.7646539211273193\n",
      "\n",
      "episode 14, policy loss 3.022852659225464\n",
      "\n",
      "episode 15, policy loss 2.8998000621795654\n",
      "\n",
      "episode 16, policy loss 3.0581204891204834\n",
      "\n",
      "Policy train loss in epoch 0:2.9450015276670456\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 2.916879177093506\n",
      "\n",
      "episode 2, policy loss 3.015829563140869\n",
      "\n",
      "episode 3, policy loss 3.115375280380249\n",
      "\n",
      "episode 4, policy loss 2.8811862468719482\n",
      "\n",
      "episode 5, policy loss 2.9596569538116455\n",
      "\n",
      "episode 6, policy loss 2.890828847885132\n",
      "\n",
      "episode 7, policy loss 2.85239839553833\n",
      "\n",
      "episode 8, policy loss 2.895209312438965\n",
      "\n",
      "episode 9, policy loss 2.9132120609283447\n",
      "\n",
      "episode 10, policy loss 2.4498744010925293\n",
      "\n",
      "episode 11, policy loss 2.6628384590148926\n",
      "\n",
      "episode 12, policy loss 2.7346034049987793\n",
      "\n",
      "episode 13, policy loss 2.377469062805176\n",
      "\n",
      "episode 14, policy loss 2.8645050525665283\n",
      "\n",
      "episode 15, policy loss 2.7105791568756104\n",
      "\n",
      "episode 16, policy loss 2.82796311378479\n",
      "\n",
      "Policy train loss in epoch 1:2.816775530576706\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 2.3867239952087402\n",
      "\n",
      "episode 2, policy loss 2.7469470500946045\n",
      "\n",
      "episode 3, policy loss 2.712099313735962\n",
      "\n",
      "episode 4, policy loss 2.549042224884033\n",
      "\n",
      "episode 5, policy loss 2.713841438293457\n",
      "\n",
      "episode 6, policy loss 2.8286821842193604\n",
      "\n",
      "episode 7, policy loss 2.5972917079925537\n",
      "\n",
      "episode 8, policy loss 2.867657423019409\n",
      "\n",
      "episode 9, policy loss 2.687021255493164\n",
      "\n",
      "episode 10, policy loss 2.644104242324829\n",
      "\n",
      "episode 11, policy loss 2.7600386142730713\n",
      "\n",
      "episode 12, policy loss 2.678995132446289\n",
      "\n",
      "episode 13, policy loss 2.548478364944458\n",
      "\n",
      "episode 14, policy loss 2.4631857872009277\n",
      "\n",
      "episode 15, policy loss 2.6737284660339355\n",
      "\n",
      "episode 16, policy loss 2.849010944366455\n",
      "\n",
      "Policy train loss in epoch 2:2.669178009033203\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 2.549112319946289\n",
      "\n",
      "episode 2, policy loss 2.68700909614563\n",
      "\n",
      "episode 3, policy loss 2.867645025253296\n",
      "\n",
      "episode 4, policy loss 2.7121899127960205\n",
      "\n",
      "episode 5, policy loss 2.5484445095062256\n",
      "\n",
      "episode 6, policy loss 2.3870792388916016\n",
      "\n",
      "episode 7, policy loss 2.5972468852996826\n",
      "\n",
      "episode 8, policy loss 2.678908109664917\n",
      "\n",
      "episode 9, policy loss 2.7470245361328125\n",
      "\n",
      "episode 10, policy loss 2.828580379486084\n",
      "\n",
      "episode 11, policy loss 2.713723659515381\n",
      "\n",
      "episode 12, policy loss 2.8488059043884277\n",
      "\n",
      "episode 13, policy loss 2.462905168533325\n",
      "\n",
      "episode 14, policy loss 2.6436502933502197\n",
      "\n",
      "episode 15, policy loss 2.673210620880127\n",
      "\n",
      "episode 16, policy loss 2.7590696811676025\n",
      "\n",
      "Policy train loss in epoch 3:2.6690378338098526\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 6.744395732879639\n",
      "\n",
      "episode 2, val func loss 5.693558692932129\n",
      "\n",
      "episode 3, val func loss 6.66929817199707\n",
      "\n",
      "episode 4, val func loss 6.411727428436279\n",
      "\n",
      "episode 5, val func loss 6.139902114868164\n",
      "\n",
      "episode 6, val func loss 5.770383358001709\n",
      "\n",
      "episode 7, val func loss 5.991076469421387\n",
      "\n",
      "episode 8, val func loss 5.918917655944824\n",
      "\n",
      "episode 9, val func loss 5.416403293609619\n",
      "\n",
      "episode 10, val func loss 6.518322467803955\n",
      "\n",
      "episode 11, val func loss 5.545290470123291\n",
      "\n",
      "episode 12, val func loss 5.526937484741211\n",
      "\n",
      "episode 13, val func loss 5.815549373626709\n",
      "\n",
      "episode 14, val func loss 4.9760050773620605\n",
      "\n",
      "episode 15, val func loss 6.128235816955566\n",
      "\n",
      "episode 16, val func loss 6.120092868804932\n",
      "\n",
      "Val func train loss in epoch 0:5.961631029844284\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 4.923846244812012\n",
      "\n",
      "episode 2, val func loss 5.823451995849609\n",
      "\n",
      "episode 3, val func loss 4.852657794952393\n",
      "\n",
      "episode 4, val func loss 5.766845226287842\n",
      "\n",
      "episode 5, val func loss 5.963493824005127\n",
      "\n",
      "episode 6, val func loss 5.469225883483887\n",
      "\n",
      "episode 7, val func loss 5.423129081726074\n",
      "\n",
      "episode 8, val func loss 5.309342861175537\n",
      "\n",
      "episode 9, val func loss 6.410569190979004\n",
      "\n",
      "episode 10, val func loss 5.6979570388793945\n",
      "\n",
      "episode 11, val func loss 5.455410003662109\n",
      "\n",
      "episode 12, val func loss 6.097448825836182\n",
      "\n",
      "episode 13, val func loss 5.857872009277344\n",
      "\n",
      "episode 14, val func loss 5.639884948730469\n",
      "\n",
      "episode 15, val func loss 5.617260456085205\n",
      "\n",
      "episode 16, val func loss 5.9438018798828125\n",
      "\n",
      "Val func train loss in epoch 1:5.6407623291015625\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 5.39765739440918\n",
      "\n",
      "episode 2, val func loss 5.158570766448975\n",
      "\n",
      "episode 3, val func loss 5.57785701751709\n",
      "\n",
      "episode 4, val func loss 5.380125045776367\n",
      "\n",
      "episode 5, val func loss 5.454560279846191\n",
      "\n",
      "episode 6, val func loss 5.648679733276367\n",
      "\n",
      "episode 7, val func loss 5.286663055419922\n",
      "\n",
      "episode 8, val func loss 5.641362190246582\n",
      "\n",
      "episode 9, val func loss 4.965010166168213\n",
      "\n",
      "episode 10, val func loss 5.821230888366699\n",
      "\n",
      "episode 11, val func loss 5.88871955871582\n",
      "\n",
      "episode 12, val func loss 6.090263843536377\n",
      "\n",
      "episode 13, val func loss 5.240974426269531\n",
      "\n",
      "episode 14, val func loss 5.490516185760498\n",
      "\n",
      "episode 15, val func loss 5.737743854522705\n",
      "\n",
      "episode 16, val func loss 5.410292625427246\n",
      "\n",
      "Val func train loss in epoch 2:5.511889189481735\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 5.705679893493652\n",
      "\n",
      "episode 2, val func loss 5.766637325286865\n",
      "\n",
      "episode 3, val func loss 5.226025104522705\n",
      "\n",
      "episode 4, val func loss 5.146740436553955\n",
      "\n",
      "episode 5, val func loss 5.69633674621582\n",
      "\n",
      "episode 6, val func loss 6.186670303344727\n",
      "\n",
      "episode 7, val func loss 5.6910600662231445\n",
      "\n",
      "episode 8, val func loss 5.803258419036865\n",
      "\n",
      "episode 9, val func loss 6.18673038482666\n",
      "\n",
      "episode 10, val func loss 5.6833624839782715\n",
      "\n",
      "episode 11, val func loss 5.691808223724365\n",
      "\n",
      "episode 12, val func loss 5.956053256988525\n",
      "\n",
      "episode 13, val func loss 5.563499450683594\n",
      "\n",
      "episode 14, val func loss 5.3496856689453125\n",
      "\n",
      "episode 15, val func loss 4.89465856552124\n",
      "\n",
      "episode 16, val func loss 5.886129856109619\n",
      "\n",
      "Val func train loss in epoch 3:5.652146011590958\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 5.7856340408325195\n",
      "\n",
      "episode 2, val func loss 5.780465126037598\n",
      "\n",
      "episode 3, val func loss 5.101557731628418\n",
      "\n",
      "episode 4, val func loss 4.488245010375977\n",
      "\n",
      "episode 5, val func loss 5.96585750579834\n",
      "\n",
      "episode 6, val func loss 5.501945972442627\n",
      "\n",
      "episode 7, val func loss 5.78093147277832\n",
      "\n",
      "episode 8, val func loss 5.385642051696777\n",
      "\n",
      "episode 9, val func loss 5.621718883514404\n",
      "\n",
      "episode 10, val func loss 6.138956546783447\n",
      "\n",
      "episode 11, val func loss 5.423369884490967\n",
      "\n",
      "episode 12, val func loss 5.2419233322143555\n",
      "\n",
      "episode 13, val func loss 5.486778736114502\n",
      "\n",
      "episode 14, val func loss 5.688671588897705\n",
      "\n",
      "episode 15, val func loss 5.07814359664917\n",
      "\n",
      "episode 16, val func loss 5.664997577667236\n",
      "\n",
      "Val func train loss in epoch 4:5.508427441120148\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 5.638162612915039\n",
      "\n",
      "episode 2, val func loss 5.6754560470581055\n",
      "\n",
      "episode 3, val func loss 5.019889831542969\n",
      "\n",
      "episode 4, val func loss 4.964757919311523\n",
      "\n",
      "episode 5, val func loss 5.975253105163574\n",
      "\n",
      "episode 6, val func loss 5.720789432525635\n",
      "\n",
      "episode 7, val func loss 5.9691548347473145\n",
      "\n",
      "episode 8, val func loss 5.856681823730469\n",
      "\n",
      "episode 9, val func loss 5.712403774261475\n",
      "\n",
      "episode 10, val func loss 4.985764980316162\n",
      "\n",
      "episode 11, val func loss 5.239586353302002\n",
      "\n",
      "episode 12, val func loss 5.136643409729004\n",
      "\n",
      "episode 13, val func loss 6.158009052276611\n",
      "\n",
      "episode 14, val func loss 6.401984214782715\n",
      "\n",
      "episode 15, val func loss 5.886367321014404\n",
      "\n",
      "episode 16, val func loss 5.876237869262695\n",
      "\n",
      "Val func train loss in epoch 5:5.638571411371231\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 5.5404133796691895\n",
      "\n",
      "episode 2, val func loss 5.874216079711914\n",
      "\n",
      "episode 3, val func loss 5.743643283843994\n",
      "\n",
      "episode 4, val func loss 5.6591572761535645\n",
      "\n",
      "episode 5, val func loss 5.911097049713135\n",
      "\n",
      "episode 6, val func loss 5.753993034362793\n",
      "\n",
      "episode 7, val func loss 5.69331169128418\n",
      "\n",
      "episode 8, val func loss 4.731400489807129\n",
      "\n",
      "episode 9, val func loss 5.952900409698486\n",
      "\n",
      "episode 10, val func loss 5.483780860900879\n",
      "\n",
      "episode 11, val func loss 5.778285980224609\n",
      "\n",
      "episode 12, val func loss 5.359626770019531\n",
      "\n",
      "episode 13, val func loss 5.9754638671875\n",
      "\n",
      "episode 14, val func loss 5.780428886413574\n",
      "\n",
      "episode 15, val func loss 5.339101314544678\n",
      "\n",
      "episode 16, val func loss 6.01791524887085\n",
      "\n",
      "Val func train loss in epoch 6:5.662170976400375\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 5.97092342376709\n",
      "\n",
      "episode 2, val func loss 5.62491512298584\n",
      "\n",
      "episode 3, val func loss 4.459214210510254\n",
      "\n",
      "episode 4, val func loss 5.564314365386963\n",
      "\n",
      "episode 5, val func loss 5.533560276031494\n",
      "\n",
      "episode 6, val func loss 5.835901737213135\n",
      "\n",
      "episode 7, val func loss 5.436570167541504\n",
      "\n",
      "episode 8, val func loss 5.774194717407227\n",
      "\n",
      "episode 9, val func loss 5.9298996925354\n",
      "\n",
      "episode 10, val func loss 5.870492935180664\n",
      "\n",
      "episode 11, val func loss 5.836726188659668\n",
      "\n",
      "episode 12, val func loss 5.927475929260254\n",
      "\n",
      "episode 13, val func loss 5.378036022186279\n",
      "\n",
      "episode 14, val func loss 4.966310501098633\n",
      "\n",
      "episode 15, val func loss 4.664817810058594\n",
      "\n",
      "episode 16, val func loss 5.9300642013549805\n",
      "\n",
      "Val func train loss in epoch 7:5.543963581323624\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 5.991006851196289\n",
      "\n",
      "episode 2, val func loss 5.415319919586182\n",
      "\n",
      "episode 3, val func loss 5.638697147369385\n",
      "\n",
      "episode 4, val func loss 6.0670881271362305\n",
      "\n",
      "episode 5, val func loss 6.0831074714660645\n",
      "\n",
      "episode 6, val func loss 6.109017372131348\n",
      "\n",
      "episode 7, val func loss 5.040284633636475\n",
      "\n",
      "episode 8, val func loss 5.57626485824585\n",
      "\n",
      "episode 9, val func loss 5.4741339683532715\n",
      "\n",
      "episode 10, val func loss 4.9859724044799805\n",
      "\n",
      "episode 11, val func loss 5.444530487060547\n",
      "\n",
      "episode 12, val func loss 5.595065116882324\n",
      "\n",
      "episode 13, val func loss 5.585810661315918\n",
      "\n",
      "episode 14, val func loss 5.883934020996094\n",
      "\n",
      "episode 15, val func loss 5.031579494476318\n",
      "\n",
      "episode 16, val func loss 5.797408580780029\n",
      "\n",
      "Val func train loss in epoch 8:5.607451319694519\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 5.380456924438477\n",
      "\n",
      "episode 2, val func loss 5.107468605041504\n",
      "\n",
      "episode 3, val func loss 5.967276096343994\n",
      "\n",
      "episode 4, val func loss 5.380320072174072\n",
      "\n",
      "episode 5, val func loss 5.87335729598999\n",
      "\n",
      "episode 6, val func loss 5.062270641326904\n",
      "\n",
      "episode 7, val func loss 4.696349620819092\n",
      "\n",
      "episode 8, val func loss 5.577455520629883\n",
      "\n",
      "episode 9, val func loss 5.67733097076416\n",
      "\n",
      "episode 10, val func loss 5.86826229095459\n",
      "\n",
      "episode 11, val func loss 5.269969940185547\n",
      "\n",
      "episode 12, val func loss 5.529079914093018\n",
      "\n",
      "episode 13, val func loss 5.82520055770874\n",
      "\n",
      "episode 14, val func loss 5.224064350128174\n",
      "\n",
      "episode 15, val func loss 6.338057994842529\n",
      "\n",
      "episode 16, val func loss 5.195272922515869\n",
      "\n",
      "Val func train loss in epoch 9:5.498262107372284\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 5.3061628341674805\n",
      "\n",
      "episode 2, val func loss 5.81648063659668\n",
      "\n",
      "episode 3, val func loss 5.240081787109375\n",
      "\n",
      "episode 4, val func loss 5.019558429718018\n",
      "\n",
      "episode 5, val func loss 5.376684665679932\n",
      "\n",
      "episode 6, val func loss 5.510317802429199\n",
      "\n",
      "episode 7, val func loss 5.70867919921875\n",
      "\n",
      "episode 8, val func loss 5.686755657196045\n",
      "\n",
      "episode 9, val func loss 5.130972862243652\n",
      "\n",
      "episode 10, val func loss 5.722684860229492\n",
      "\n",
      "episode 11, val func loss 5.320818901062012\n",
      "\n",
      "episode 12, val func loss 5.584693908691406\n",
      "\n",
      "episode 13, val func loss 5.5983381271362305\n",
      "\n",
      "episode 14, val func loss 5.398072242736816\n",
      "\n",
      "episode 15, val func loss 4.883591175079346\n",
      "\n",
      "episode 16, val func loss 5.463713645935059\n",
      "\n",
      "Val func train loss in epoch 10:5.422975420951843\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 5.554262161254883\n",
      "\n",
      "episode 2, val func loss 5.61900520324707\n",
      "\n",
      "episode 3, val func loss 5.65313196182251\n",
      "\n",
      "episode 4, val func loss 5.82529354095459\n",
      "\n",
      "episode 5, val func loss 5.381209850311279\n",
      "\n",
      "episode 6, val func loss 5.565305233001709\n",
      "\n",
      "episode 7, val func loss 5.709799289703369\n",
      "\n",
      "episode 8, val func loss 5.283612251281738\n",
      "\n",
      "episode 9, val func loss 6.121367931365967\n",
      "\n",
      "episode 10, val func loss 4.937215328216553\n",
      "\n",
      "episode 11, val func loss 5.38106107711792\n",
      "\n",
      "episode 12, val func loss 4.491529941558838\n",
      "\n",
      "episode 13, val func loss 5.461137771606445\n",
      "\n",
      "episode 14, val func loss 5.248837471008301\n",
      "\n",
      "episode 15, val func loss 5.8121185302734375\n",
      "\n",
      "episode 16, val func loss 4.853069305419922\n",
      "\n",
      "Val func train loss in epoch 11:5.431122303009033\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 5.427995681762695\n",
      "\n",
      "episode 2, val func loss 5.569188117980957\n",
      "\n",
      "episode 3, val func loss 4.7476019859313965\n",
      "\n",
      "episode 4, val func loss 5.161535739898682\n",
      "\n",
      "episode 5, val func loss 5.842583656311035\n",
      "\n",
      "episode 6, val func loss 4.693319320678711\n",
      "\n",
      "episode 7, val func loss 5.887686252593994\n",
      "\n",
      "episode 8, val func loss 5.9010772705078125\n",
      "\n",
      "episode 9, val func loss 5.743392467498779\n",
      "\n",
      "episode 10, val func loss 5.421684265136719\n",
      "\n",
      "episode 11, val func loss 5.4494733810424805\n",
      "\n",
      "episode 12, val func loss 5.36642599105835\n",
      "\n",
      "episode 13, val func loss 5.478516101837158\n",
      "\n",
      "episode 14, val func loss 5.289392948150635\n",
      "\n",
      "episode 15, val func loss 5.489391803741455\n",
      "\n",
      "episode 16, val func loss 5.086047172546387\n",
      "\n",
      "Val func train loss in epoch 12:5.409707009792328\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 5.594052791595459\n",
      "\n",
      "episode 2, val func loss 6.06029748916626\n",
      "\n",
      "episode 3, val func loss 5.482485771179199\n",
      "\n",
      "episode 4, val func loss 5.359080791473389\n",
      "\n",
      "episode 5, val func loss 5.695744037628174\n",
      "\n",
      "episode 6, val func loss 5.406003952026367\n",
      "\n",
      "episode 7, val func loss 5.58059024810791\n",
      "\n",
      "episode 8, val func loss 5.413336277008057\n",
      "\n",
      "episode 9, val func loss 5.318147659301758\n",
      "\n",
      "episode 10, val func loss 5.4717936515808105\n",
      "\n",
      "episode 11, val func loss 5.5020294189453125\n",
      "\n",
      "episode 12, val func loss 5.88295841217041\n",
      "\n",
      "episode 13, val func loss 5.758561134338379\n",
      "\n",
      "episode 14, val func loss 4.905465126037598\n",
      "\n",
      "episode 15, val func loss 5.812262058258057\n",
      "\n",
      "episode 16, val func loss 4.903860092163086\n",
      "\n",
      "Val func train loss in epoch 13:5.509166806936264\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 5.763586521148682\n",
      "\n",
      "episode 2, val func loss 6.050014495849609\n",
      "\n",
      "episode 3, val func loss 5.882551670074463\n",
      "\n",
      "episode 4, val func loss 5.839931964874268\n",
      "\n",
      "episode 5, val func loss 5.6681809425354\n",
      "\n",
      "episode 6, val func loss 5.882896423339844\n",
      "\n",
      "episode 7, val func loss 6.005557060241699\n",
      "\n",
      "episode 8, val func loss 5.57484769821167\n",
      "\n",
      "episode 9, val func loss 4.964414119720459\n",
      "\n",
      "episode 10, val func loss 5.576217174530029\n",
      "\n",
      "episode 11, val func loss 5.998727798461914\n",
      "\n",
      "episode 12, val func loss 4.991331100463867\n",
      "\n",
      "episode 13, val func loss 4.893198490142822\n",
      "\n",
      "episode 14, val func loss 5.515899658203125\n",
      "\n",
      "episode 15, val func loss 5.3204474449157715\n",
      "\n",
      "episode 16, val func loss 4.774917125701904\n",
      "\n",
      "Val func train loss in epoch 14:5.5439199805259705\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 5.200998783111572\n",
      "\n",
      "episode 2, val func loss 6.2401556968688965\n",
      "\n",
      "episode 3, val func loss 5.215943813323975\n",
      "\n",
      "episode 4, val func loss 4.981658458709717\n",
      "\n",
      "episode 5, val func loss 5.549333095550537\n",
      "\n",
      "episode 6, val func loss 5.300688743591309\n",
      "\n",
      "episode 7, val func loss 5.53700065612793\n",
      "\n",
      "episode 8, val func loss 5.557608604431152\n",
      "\n",
      "episode 9, val func loss 5.304622650146484\n",
      "\n",
      "episode 10, val func loss 5.629387378692627\n",
      "\n",
      "episode 11, val func loss 5.3953423500061035\n",
      "\n",
      "episode 12, val func loss 4.698763847351074\n",
      "\n",
      "episode 13, val func loss 4.393568992614746\n",
      "\n",
      "episode 14, val func loss 6.001901626586914\n",
      "\n",
      "episode 15, val func loss 5.6525702476501465\n",
      "\n",
      "episode 16, val func loss 5.676604747772217\n",
      "\n",
      "Val func train loss in epoch 15:5.3960093557834625\n",
      "***********************TIME WAS 4.847052284081777 min*****************************\n",
      "\n",
      "**********************ROUND 69 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.9288902282714844\n",
      "\n",
      "episode 2, policy loss 0.7754939198493958\n",
      "\n",
      "episode 3, policy loss 1.1159522533416748\n",
      "\n",
      "episode 4, policy loss 0.9312669038772583\n",
      "\n",
      "episode 5, policy loss 2.1238465309143066\n",
      "\n",
      "episode 6, policy loss 1.2112274169921875\n",
      "\n",
      "episode 7, policy loss 0.9583810567855835\n",
      "\n",
      "episode 8, policy loss 0.9017535448074341\n",
      "\n",
      "episode 9, policy loss 1.375862956047058\n",
      "\n",
      "episode 10, policy loss 1.3020991086959839\n",
      "\n",
      "episode 11, policy loss 0.8604030013084412\n",
      "\n",
      "episode 12, policy loss 0.5895557999610901\n",
      "\n",
      "episode 13, policy loss 0.9449469447135925\n",
      "\n",
      "episode 14, policy loss 0.7833651900291443\n",
      "\n",
      "episode 15, policy loss 0.4550734758377075\n",
      "\n",
      "episode 16, policy loss 0.8698235154151917\n",
      "\n",
      "Policy train loss in epoch 0:1.0079963654279709\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.9665566086769104\n",
      "\n",
      "episode 2, policy loss 1.0759228467941284\n",
      "\n",
      "episode 3, policy loss 0.7248287200927734\n",
      "\n",
      "episode 4, policy loss 1.0998574495315552\n",
      "\n",
      "episode 5, policy loss 0.9611427187919617\n",
      "\n",
      "episode 6, policy loss 0.5656974911689758\n",
      "\n",
      "episode 7, policy loss 1.1250594854354858\n",
      "\n",
      "episode 8, policy loss 1.1614181995391846\n",
      "\n",
      "episode 9, policy loss 0.34731680154800415\n",
      "\n",
      "episode 10, policy loss 0.675117015838623\n",
      "\n",
      "episode 11, policy loss 0.7333902716636658\n",
      "\n",
      "episode 12, policy loss 0.8059857487678528\n",
      "\n",
      "episode 13, policy loss 1.571815013885498\n",
      "\n",
      "episode 14, policy loss 0.6569640636444092\n",
      "\n",
      "episode 15, policy loss 0.7520816922187805\n",
      "\n",
      "episode 16, policy loss 0.7141873240470886\n",
      "\n",
      "Policy train loss in epoch 1:0.8710838407278061\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.796209454536438\n",
      "\n",
      "episode 2, policy loss 0.3324070870876312\n",
      "\n",
      "episode 3, policy loss 0.9305468201637268\n",
      "\n",
      "episode 4, policy loss 0.646185576915741\n",
      "\n",
      "episode 5, policy loss 0.8060163259506226\n",
      "\n",
      "episode 6, policy loss 0.7520858645439148\n",
      "\n",
      "episode 7, policy loss 0.824647068977356\n",
      "\n",
      "episode 8, policy loss 0.7141898274421692\n",
      "\n",
      "episode 9, policy loss 0.673641562461853\n",
      "\n",
      "episode 10, policy loss 0.9746721386909485\n",
      "\n",
      "episode 11, policy loss 1.056058406829834\n",
      "\n",
      "episode 12, policy loss 0.9315276741981506\n",
      "\n",
      "episode 13, policy loss 0.73345547914505\n",
      "\n",
      "episode 14, policy loss 0.6569721102714539\n",
      "\n",
      "episode 15, policy loss 0.45399710536003113\n",
      "\n",
      "episode 16, policy loss 1.5718306303024292\n",
      "\n",
      "Policy train loss in epoch 2:0.8034026958048344\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.6736416816711426\n",
      "\n",
      "episode 2, policy loss 0.4539971351623535\n",
      "\n",
      "episode 3, policy loss 0.6569721698760986\n",
      "\n",
      "episode 4, policy loss 0.7141900062561035\n",
      "\n",
      "episode 5, policy loss 1.056058406829834\n",
      "\n",
      "episode 6, policy loss 0.7334555387496948\n",
      "\n",
      "episode 7, policy loss 0.9305475354194641\n",
      "\n",
      "episode 8, policy loss 0.6461860537528992\n",
      "\n",
      "episode 9, policy loss 0.9315277338027954\n",
      "\n",
      "episode 10, policy loss 0.974672257900238\n",
      "\n",
      "episode 11, policy loss 0.3324081301689148\n",
      "\n",
      "episode 12, policy loss 1.5718307495117188\n",
      "\n",
      "episode 13, policy loss 0.8060166835784912\n",
      "\n",
      "episode 14, policy loss 0.7520861029624939\n",
      "\n",
      "episode 15, policy loss 0.8246472477912903\n",
      "\n",
      "episode 16, policy loss 0.7962110042572021\n",
      "\n",
      "Policy train loss in epoch 3:0.8034030273556709\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.6184396743774414\n",
      "\n",
      "episode 2, val func loss 1.8676748275756836\n",
      "\n",
      "episode 3, val func loss 0.9946707487106323\n",
      "\n",
      "episode 4, val func loss 0.8287723660469055\n",
      "\n",
      "episode 5, val func loss 0.6410744786262512\n",
      "\n",
      "episode 6, val func loss 0.3345804810523987\n",
      "\n",
      "episode 7, val func loss 0.40976816415786743\n",
      "\n",
      "episode 8, val func loss 0.16296041011810303\n",
      "\n",
      "episode 9, val func loss 0.0856102779507637\n",
      "\n",
      "episode 10, val func loss 0.34829452633857727\n",
      "\n",
      "episode 11, val func loss 0.3047015964984894\n",
      "\n",
      "episode 12, val func loss 0.7177388072013855\n",
      "\n",
      "episode 13, val func loss 0.22312559187412262\n",
      "\n",
      "episode 14, val func loss 0.1335720270872116\n",
      "\n",
      "episode 15, val func loss 0.4277682304382324\n",
      "\n",
      "episode 16, val func loss 0.39915895462036133\n",
      "\n",
      "Val func train loss in epoch 0:0.6561194476671517\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.21696820855140686\n",
      "\n",
      "episode 2, val func loss 0.26221349835395813\n",
      "\n",
      "episode 3, val func loss 0.4825138449668884\n",
      "\n",
      "episode 4, val func loss 0.26800093054771423\n",
      "\n",
      "episode 5, val func loss 0.4953307509422302\n",
      "\n",
      "episode 6, val func loss 0.2210119515657425\n",
      "\n",
      "episode 7, val func loss 0.16074077785015106\n",
      "\n",
      "episode 8, val func loss 0.04707549884915352\n",
      "\n",
      "episode 9, val func loss 0.17095807194709778\n",
      "\n",
      "episode 10, val func loss 0.5573481321334839\n",
      "\n",
      "episode 11, val func loss 0.44113242626190186\n",
      "\n",
      "episode 12, val func loss 0.46546342968940735\n",
      "\n",
      "episode 13, val func loss 0.5927898287773132\n",
      "\n",
      "episode 14, val func loss 0.3025049567222595\n",
      "\n",
      "episode 15, val func loss 0.4220111072063446\n",
      "\n",
      "episode 16, val func loss 0.15064939856529236\n",
      "\n",
      "Val func train loss in epoch 1:0.3285445508081466\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.5409919023513794\n",
      "\n",
      "episode 2, val func loss 0.39640942215919495\n",
      "\n",
      "episode 3, val func loss 0.1403205692768097\n",
      "\n",
      "episode 4, val func loss 0.31498369574546814\n",
      "\n",
      "episode 5, val func loss 0.14572280645370483\n",
      "\n",
      "episode 6, val func loss 0.030914025381207466\n",
      "\n",
      "episode 7, val func loss 0.15946151316165924\n",
      "\n",
      "episode 8, val func loss 0.13518454134464264\n",
      "\n",
      "episode 9, val func loss 0.13998934626579285\n",
      "\n",
      "episode 10, val func loss 0.40153342485427856\n",
      "\n",
      "episode 11, val func loss 0.26328766345977783\n",
      "\n",
      "episode 12, val func loss 0.4270453453063965\n",
      "\n",
      "episode 13, val func loss 0.14292113482952118\n",
      "\n",
      "episode 14, val func loss 0.2642163932323456\n",
      "\n",
      "episode 15, val func loss 0.40873709321022034\n",
      "\n",
      "episode 16, val func loss 0.5581431984901428\n",
      "\n",
      "Val func train loss in epoch 2:0.2793663797201589\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.13325509428977966\n",
      "\n",
      "episode 2, val func loss 0.13675685226917267\n",
      "\n",
      "episode 3, val func loss 0.4044915437698364\n",
      "\n",
      "episode 4, val func loss 0.14180657267570496\n",
      "\n",
      "episode 5, val func loss 0.5311675667762756\n",
      "\n",
      "episode 6, val func loss 0.14116623997688293\n",
      "\n",
      "episode 7, val func loss 0.014350018464028835\n",
      "\n",
      "episode 8, val func loss 0.3997080624103546\n",
      "\n",
      "episode 9, val func loss 0.401508092880249\n",
      "\n",
      "episode 10, val func loss 0.13199731707572937\n",
      "\n",
      "episode 11, val func loss 0.39863163232803345\n",
      "\n",
      "episode 12, val func loss 0.14389820396900177\n",
      "\n",
      "episode 13, val func loss 0.26943790912628174\n",
      "\n",
      "episode 14, val func loss 0.27196380496025085\n",
      "\n",
      "episode 15, val func loss 0.5212299823760986\n",
      "\n",
      "episode 16, val func loss 0.27756670117378235\n",
      "\n",
      "Val func train loss in epoch 3:0.26993347465759143\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.13924552500247955\n",
      "\n",
      "episode 2, val func loss 0.5186302661895752\n",
      "\n",
      "episode 3, val func loss 0.13582363724708557\n",
      "\n",
      "episode 4, val func loss 0.3982737362384796\n",
      "\n",
      "episode 5, val func loss 0.25520458817481995\n",
      "\n",
      "episode 6, val func loss 0.13279032707214355\n",
      "\n",
      "episode 7, val func loss 0.39930260181427\n",
      "\n",
      "episode 8, val func loss 0.008264628238976002\n",
      "\n",
      "episode 9, val func loss 0.3978922963142395\n",
      "\n",
      "episode 10, val func loss 0.26347967982292175\n",
      "\n",
      "episode 11, val func loss 0.5086925029754639\n",
      "\n",
      "episode 12, val func loss 0.4036298096179962\n",
      "\n",
      "episode 13, val func loss 0.13001197576522827\n",
      "\n",
      "episode 14, val func loss 0.2655267119407654\n",
      "\n",
      "episode 15, val func loss 0.1429789811372757\n",
      "\n",
      "episode 16, val func loss 0.1385645717382431\n",
      "\n",
      "Val func train loss in epoch 4:0.2648944899556227\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.5303102135658264\n",
      "\n",
      "episode 2, val func loss 0.394709974527359\n",
      "\n",
      "episode 3, val func loss 0.1318277269601822\n",
      "\n",
      "episode 4, val func loss 0.5227572321891785\n",
      "\n",
      "episode 5, val func loss 0.26103582978248596\n",
      "\n",
      "episode 6, val func loss 0.14614519476890564\n",
      "\n",
      "episode 7, val func loss 0.13378316164016724\n",
      "\n",
      "episode 8, val func loss 0.010100016370415688\n",
      "\n",
      "episode 9, val func loss 0.12128034979104996\n",
      "\n",
      "episode 10, val func loss 0.39684411883354187\n",
      "\n",
      "episode 11, val func loss 0.13924017548561096\n",
      "\n",
      "episode 12, val func loss 0.27031561732292175\n",
      "\n",
      "episode 13, val func loss 0.3979298174381256\n",
      "\n",
      "episode 14, val func loss 0.39455747604370117\n",
      "\n",
      "episode 15, val func loss 0.1320084035396576\n",
      "\n",
      "episode 16, val func loss 0.2693558633327484\n",
      "\n",
      "Val func train loss in epoch 5:0.26576257322449237\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.14271537959575653\n",
      "\n",
      "episode 2, val func loss 0.37653857469558716\n",
      "\n",
      "episode 3, val func loss 0.3902567923069\n",
      "\n",
      "episode 4, val func loss 0.38459768891334534\n",
      "\n",
      "episode 5, val func loss 0.5252389311790466\n",
      "\n",
      "episode 6, val func loss 0.1330370008945465\n",
      "\n",
      "episode 7, val func loss 0.12811605632305145\n",
      "\n",
      "episode 8, val func loss 0.40240490436553955\n",
      "\n",
      "episode 9, val func loss 0.269546240568161\n",
      "\n",
      "episode 10, val func loss 0.13744720816612244\n",
      "\n",
      "episode 11, val func loss 0.009185104630887508\n",
      "\n",
      "episode 12, val func loss 0.1344013214111328\n",
      "\n",
      "episode 13, val func loss 0.2714295983314514\n",
      "\n",
      "episode 14, val func loss 0.5301782488822937\n",
      "\n",
      "episode 15, val func loss 0.2557774782180786\n",
      "\n",
      "episode 16, val func loss 0.12979218363761902\n",
      "\n",
      "Val func train loss in epoch 6:0.26379141950747\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.13248422741889954\n",
      "\n",
      "episode 2, val func loss 0.39103615283966064\n",
      "\n",
      "episode 3, val func loss 0.2676970958709717\n",
      "\n",
      "episode 4, val func loss 0.14065046608448029\n",
      "\n",
      "episode 5, val func loss 0.4920022785663605\n",
      "\n",
      "episode 6, val func loss 0.3975578546524048\n",
      "\n",
      "episode 7, val func loss 0.37130650877952576\n",
      "\n",
      "episode 8, val func loss 0.1388038545846939\n",
      "\n",
      "episode 9, val func loss 0.11127673089504242\n",
      "\n",
      "episode 10, val func loss 0.014937393367290497\n",
      "\n",
      "episode 11, val func loss 0.2516842484474182\n",
      "\n",
      "episode 12, val func loss 0.3634519577026367\n",
      "\n",
      "episode 13, val func loss 0.1287560909986496\n",
      "\n",
      "episode 14, val func loss 0.521491289138794\n",
      "\n",
      "episode 15, val func loss 0.2726799249649048\n",
      "\n",
      "episode 16, val func loss 0.14058303833007812\n",
      "\n",
      "Val func train loss in epoch 7:0.2585249445401132\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.3852025866508484\n",
      "\n",
      "episode 2, val func loss 0.24038133025169373\n",
      "\n",
      "episode 3, val func loss 0.13593000173568726\n",
      "\n",
      "episode 4, val func loss 0.3729240298271179\n",
      "\n",
      "episode 5, val func loss 0.13625995814800262\n",
      "\n",
      "episode 6, val func loss 0.26060518622398376\n",
      "\n",
      "episode 7, val func loss 0.3766532242298126\n",
      "\n",
      "episode 8, val func loss 0.48170921206474304\n",
      "\n",
      "episode 9, val func loss 0.37240469455718994\n",
      "\n",
      "episode 10, val func loss 0.13764244318008423\n",
      "\n",
      "episode 11, val func loss 0.48807191848754883\n",
      "\n",
      "episode 12, val func loss 0.13298848271369934\n",
      "\n",
      "episode 13, val func loss 0.27512434124946594\n",
      "\n",
      "episode 14, val func loss 0.13914437592029572\n",
      "\n",
      "episode 15, val func loss 0.015580417588353157\n",
      "\n",
      "episode 16, val func loss 0.12093564122915268\n",
      "\n",
      "Val func train loss in epoch 8:0.25447236525360495\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.2582264244556427\n",
      "\n",
      "episode 2, val func loss 0.49635767936706543\n",
      "\n",
      "episode 3, val func loss 0.11467736214399338\n",
      "\n",
      "episode 4, val func loss 0.11499142646789551\n",
      "\n",
      "episode 5, val func loss 0.37233951687812805\n",
      "\n",
      "episode 6, val func loss 0.14299480617046356\n",
      "\n",
      "episode 7, val func loss 0.5086671710014343\n",
      "\n",
      "episode 8, val func loss 0.26583167910575867\n",
      "\n",
      "episode 9, val func loss 0.3732643723487854\n",
      "\n",
      "episode 10, val func loss 0.13595549762248993\n",
      "\n",
      "episode 11, val func loss 0.1412971466779709\n",
      "\n",
      "episode 12, val func loss 0.1153477281332016\n",
      "\n",
      "episode 13, val func loss 0.2643912136554718\n",
      "\n",
      "episode 14, val func loss 0.3825182020664215\n",
      "\n",
      "episode 15, val func loss 0.016829954460263252\n",
      "\n",
      "episode 16, val func loss 0.3828393220901489\n",
      "\n",
      "Val func train loss in epoch 9:0.25540809391532093\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.39818233251571655\n",
      "\n",
      "episode 2, val func loss 0.13582289218902588\n",
      "\n",
      "episode 3, val func loss 0.26275405287742615\n",
      "\n",
      "episode 4, val func loss 0.5154944062232971\n",
      "\n",
      "episode 5, val func loss 0.2742844223976135\n",
      "\n",
      "episode 6, val func loss 0.2532133162021637\n",
      "\n",
      "episode 7, val func loss 0.14100952446460724\n",
      "\n",
      "episode 8, val func loss 0.13942112028598785\n",
      "\n",
      "episode 9, val func loss 0.3640575408935547\n",
      "\n",
      "episode 10, val func loss 0.3894001245498657\n",
      "\n",
      "episode 11, val func loss 0.5233060121536255\n",
      "\n",
      "episode 12, val func loss 0.13730844855308533\n",
      "\n",
      "episode 13, val func loss 0.13547784090042114\n",
      "\n",
      "episode 14, val func loss 0.39137616753578186\n",
      "\n",
      "episode 15, val func loss 0.016259631142020226\n",
      "\n",
      "episode 16, val func loss 0.13029128313064575\n",
      "\n",
      "Val func train loss in epoch 10:0.2629786947509274\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.13170890510082245\n",
      "\n",
      "episode 2, val func loss 0.25916942954063416\n",
      "\n",
      "episode 3, val func loss 0.3963354825973511\n",
      "\n",
      "episode 4, val func loss 0.5212634801864624\n",
      "\n",
      "episode 5, val func loss 0.13312548398971558\n",
      "\n",
      "episode 6, val func loss 0.13701839745044708\n",
      "\n",
      "episode 7, val func loss 0.012773231603205204\n",
      "\n",
      "episode 8, val func loss 0.39123544096946716\n",
      "\n",
      "episode 9, val func loss 0.37825942039489746\n",
      "\n",
      "episode 10, val func loss 0.13449810445308685\n",
      "\n",
      "episode 11, val func loss 0.26657408475875854\n",
      "\n",
      "episode 12, val func loss 0.23972003161907196\n",
      "\n",
      "episode 13, val func loss 0.4966110289096832\n",
      "\n",
      "episode 14, val func loss 0.14004167914390564\n",
      "\n",
      "episode 15, val func loss 0.1434219926595688\n",
      "\n",
      "episode 16, val func loss 0.38069140911102295\n",
      "\n",
      "Val func train loss in epoch 11:0.2601529751555063\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.3668394982814789\n",
      "\n",
      "episode 2, val func loss 0.14929738640785217\n",
      "\n",
      "episode 3, val func loss 0.5074489116668701\n",
      "\n",
      "episode 4, val func loss 0.03761310502886772\n",
      "\n",
      "episode 5, val func loss 0.515834629535675\n",
      "\n",
      "episode 6, val func loss 0.1380995810031891\n",
      "\n",
      "episode 7, val func loss 0.2775111794471741\n",
      "\n",
      "episode 8, val func loss 0.39629051089286804\n",
      "\n",
      "episode 9, val func loss 0.39072003960609436\n",
      "\n",
      "episode 10, val func loss 0.25226378440856934\n",
      "\n",
      "episode 11, val func loss 0.13537810742855072\n",
      "\n",
      "episode 12, val func loss 0.14459779858589172\n",
      "\n",
      "episode 13, val func loss 0.13332504034042358\n",
      "\n",
      "episode 14, val func loss 0.2519054710865021\n",
      "\n",
      "episode 15, val func loss 0.37421637773513794\n",
      "\n",
      "episode 16, val func loss 0.12798289954662323\n",
      "\n",
      "Val func train loss in epoch 12:0.2624577700626105\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.12656842172145844\n",
      "\n",
      "episode 2, val func loss 0.3721708655357361\n",
      "\n",
      "episode 3, val func loss 0.260643869638443\n",
      "\n",
      "episode 4, val func loss 0.1296137273311615\n",
      "\n",
      "episode 5, val func loss 0.3933626711368561\n",
      "\n",
      "episode 6, val func loss 0.13745200634002686\n",
      "\n",
      "episode 7, val func loss 0.3694681227207184\n",
      "\n",
      "episode 8, val func loss 0.2652025818824768\n",
      "\n",
      "episode 9, val func loss 0.13533565402030945\n",
      "\n",
      "episode 10, val func loss 0.2642076015472412\n",
      "\n",
      "episode 11, val func loss 0.010564991272985935\n",
      "\n",
      "episode 12, val func loss 0.38698628544807434\n",
      "\n",
      "episode 13, val func loss 0.13903246819972992\n",
      "\n",
      "episode 14, val func loss 0.4673813283443451\n",
      "\n",
      "episode 15, val func loss 0.4858991801738739\n",
      "\n",
      "episode 16, val func loss 0.15564009547233582\n",
      "\n",
      "Val func train loss in epoch 13:0.2562206169241108\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.12576204538345337\n",
      "\n",
      "episode 2, val func loss 0.019036946818232536\n",
      "\n",
      "episode 3, val func loss 0.1511264443397522\n",
      "\n",
      "episode 4, val func loss 0.2662542164325714\n",
      "\n",
      "episode 5, val func loss 0.12957145273685455\n",
      "\n",
      "episode 6, val func loss 0.12284617871046066\n",
      "\n",
      "episode 7, val func loss 0.4992300271987915\n",
      "\n",
      "episode 8, val func loss 0.3843236267566681\n",
      "\n",
      "episode 9, val func loss 0.38104185461997986\n",
      "\n",
      "episode 10, val func loss 0.2554838955402374\n",
      "\n",
      "episode 11, val func loss 0.14349934458732605\n",
      "\n",
      "episode 12, val func loss 0.13330888748168945\n",
      "\n",
      "episode 13, val func loss 0.49772390723228455\n",
      "\n",
      "episode 14, val func loss 0.27110663056373596\n",
      "\n",
      "episode 15, val func loss 0.39823976159095764\n",
      "\n",
      "episode 16, val func loss 0.38947367668151855\n",
      "\n",
      "Val func train loss in epoch 14:0.2605018060421571\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.14104492962360382\n",
      "\n",
      "episode 2, val func loss 0.38776805996894836\n",
      "\n",
      "episode 3, val func loss 0.14079321920871735\n",
      "\n",
      "episode 4, val func loss 0.1334361582994461\n",
      "\n",
      "episode 5, val func loss 0.13983096182346344\n",
      "\n",
      "episode 6, val func loss 0.395672470331192\n",
      "\n",
      "episode 7, val func loss 0.2678488790988922\n",
      "\n",
      "episode 8, val func loss 0.26421087980270386\n",
      "\n",
      "episode 9, val func loss 0.38235124945640564\n",
      "\n",
      "episode 10, val func loss 0.017863791435956955\n",
      "\n",
      "episode 11, val func loss 0.46951258182525635\n",
      "\n",
      "episode 12, val func loss 0.2504154145717621\n",
      "\n",
      "episode 13, val func loss 0.523294985294342\n",
      "\n",
      "episode 14, val func loss 0.13872575759887695\n",
      "\n",
      "episode 15, val func loss 0.1353507936000824\n",
      "\n",
      "episode 16, val func loss 0.40710482001304626\n",
      "\n",
      "Val func train loss in epoch 15:0.2622015594970435\n",
      "***********************TIME WAS 4.844666175047556 min*****************************\n",
      "\n",
      "**********************ROUND 70 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -5.21414852142334\n",
      "\n",
      "episode 2, policy loss -5.214151382446289\n",
      "\n",
      "episode 3, policy loss -5.2141571044921875\n",
      "\n",
      "episode 4, policy loss -5.214161396026611\n",
      "\n",
      "episode 5, policy loss -5.214171886444092\n",
      "\n",
      "episode 6, policy loss -5.214177131652832\n",
      "\n",
      "episode 7, policy loss -5.214183807373047\n",
      "\n",
      "episode 8, policy loss -5.214189052581787\n",
      "\n",
      "episode 9, policy loss -5.214197635650635\n",
      "\n",
      "episode 10, policy loss -5.214210033416748\n",
      "\n",
      "episode 11, policy loss -5.214221954345703\n",
      "\n",
      "episode 12, policy loss -5.214229106903076\n",
      "\n",
      "episode 13, policy loss -5.214242458343506\n",
      "\n",
      "episode 14, policy loss -5.2142486572265625\n",
      "\n",
      "episode 15, policy loss -5.214256763458252\n",
      "\n",
      "episode 16, policy loss -5.214263439178467\n",
      "\n",
      "Policy train loss in epoch 0:-5.214200645685196\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -5.214273929595947\n",
      "\n",
      "episode 2, policy loss -5.214282512664795\n",
      "\n",
      "episode 3, policy loss -5.214292049407959\n",
      "\n",
      "episode 4, policy loss -5.214300632476807\n",
      "\n",
      "episode 5, policy loss -5.214305877685547\n",
      "\n",
      "episode 6, policy loss -5.214311122894287\n",
      "\n",
      "episode 7, policy loss -5.214315891265869\n",
      "\n",
      "episode 8, policy loss -5.214320659637451\n",
      "\n",
      "episode 9, policy loss -5.214324474334717\n",
      "\n",
      "episode 10, policy loss -5.214327812194824\n",
      "\n",
      "episode 11, policy loss -5.214330196380615\n",
      "\n",
      "episode 12, policy loss -5.214332103729248\n",
      "\n",
      "episode 13, policy loss -5.214334964752197\n",
      "\n",
      "episode 14, policy loss -5.214336395263672\n",
      "\n",
      "episode 15, policy loss -5.214337348937988\n",
      "\n",
      "episode 16, policy loss -5.214338779449463\n",
      "\n",
      "Policy train loss in epoch 1:-5.214316546916962\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -5.214339733123779\n",
      "\n",
      "episode 2, policy loss -5.2143402099609375\n",
      "\n",
      "episode 3, policy loss -5.214341163635254\n",
      "\n",
      "episode 4, policy loss -5.214341640472412\n",
      "\n",
      "episode 5, policy loss -5.214341640472412\n",
      "\n",
      "episode 6, policy loss -5.214341640472412\n",
      "\n",
      "episode 7, policy loss -5.2143425941467285\n",
      "\n",
      "episode 8, policy loss -5.2143425941467285\n",
      "\n",
      "episode 9, policy loss -5.214343070983887\n",
      "\n",
      "episode 10, policy loss -5.214344024658203\n",
      "\n",
      "episode 11, policy loss -5.214344024658203\n",
      "\n",
      "episode 12, policy loss -5.214344024658203\n",
      "\n",
      "episode 13, policy loss -5.2143449783325195\n",
      "\n",
      "episode 14, policy loss -5.214345455169678\n",
      "\n",
      "episode 15, policy loss -5.214345455169678\n",
      "\n",
      "episode 16, policy loss -5.214345932006836\n",
      "\n",
      "Policy train loss in epoch 2:-5.214343011379242\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -5.214345455169678\n",
      "\n",
      "episode 2, policy loss -5.214345932006836\n",
      "\n",
      "episode 3, policy loss -5.214346408843994\n",
      "\n",
      "episode 4, policy loss -5.214346408843994\n",
      "\n",
      "episode 5, policy loss -5.214346408843994\n",
      "\n",
      "episode 6, policy loss -5.214346408843994\n",
      "\n",
      "episode 7, policy loss -5.214346408843994\n",
      "\n",
      "episode 8, policy loss -5.214346408843994\n",
      "\n",
      "episode 9, policy loss -5.214346408843994\n",
      "\n",
      "episode 10, policy loss -5.214346408843994\n",
      "\n",
      "episode 11, policy loss -5.214346408843994\n",
      "\n",
      "episode 12, policy loss -5.214346408843994\n",
      "\n",
      "episode 13, policy loss -5.214346408843994\n",
      "\n",
      "episode 14, policy loss -5.214346408843994\n",
      "\n",
      "episode 15, policy loss -5.214346408843994\n",
      "\n",
      "episode 16, policy loss -5.214346408843994\n",
      "\n",
      "Policy train loss in epoch 3:-5.214346319437027\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 23.937259674072266\n",
      "\n",
      "episode 2, val func loss 19.87611961364746\n",
      "\n",
      "episode 3, val func loss 15.141233444213867\n",
      "\n",
      "episode 4, val func loss 9.708413124084473\n",
      "\n",
      "episode 5, val func loss 4.09648323059082\n",
      "\n",
      "episode 6, val func loss 2.302222967147827\n",
      "\n",
      "episode 7, val func loss 6.16595983505249\n",
      "\n",
      "episode 8, val func loss 4.221229553222656\n",
      "\n",
      "episode 9, val func loss 2.686535120010376\n",
      "\n",
      "episode 10, val func loss 2.206329107284546\n",
      "\n",
      "episode 11, val func loss 2.13081955909729\n",
      "\n",
      "episode 12, val func loss 2.357546806335449\n",
      "\n",
      "episode 13, val func loss 2.5351529121398926\n",
      "\n",
      "episode 14, val func loss 2.4780211448669434\n",
      "\n",
      "episode 15, val func loss 2.4747443199157715\n",
      "\n",
      "episode 16, val func loss 2.432072401046753\n",
      "\n",
      "Val func train loss in epoch 0:6.546883925795555\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.3005406856536865\n",
      "\n",
      "episode 2, val func loss 2.2748706340789795\n",
      "\n",
      "episode 3, val func loss 2.353264093399048\n",
      "\n",
      "episode 4, val func loss 2.452982187271118\n",
      "\n",
      "episode 5, val func loss 2.4259588718414307\n",
      "\n",
      "episode 6, val func loss 2.398402690887451\n",
      "\n",
      "episode 7, val func loss 2.3479270935058594\n",
      "\n",
      "episode 8, val func loss 2.3855769634246826\n",
      "\n",
      "episode 9, val func loss 2.338585615158081\n",
      "\n",
      "episode 10, val func loss 2.2967727184295654\n",
      "\n",
      "episode 11, val func loss 2.366767406463623\n",
      "\n",
      "episode 12, val func loss 2.3655006885528564\n",
      "\n",
      "episode 13, val func loss 2.2739741802215576\n",
      "\n",
      "episode 14, val func loss 2.2836496829986572\n",
      "\n",
      "episode 15, val func loss 2.263082504272461\n",
      "\n",
      "episode 16, val func loss 2.2626380920410156\n",
      "\n",
      "Val func train loss in epoch 1:2.3369058817625046\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.267167091369629\n",
      "\n",
      "episode 2, val func loss 2.2873456478118896\n",
      "\n",
      "episode 3, val func loss 2.3474481105804443\n",
      "\n",
      "episode 4, val func loss 2.28831148147583\n",
      "\n",
      "episode 5, val func loss 2.2430920600891113\n",
      "\n",
      "episode 6, val func loss 2.2680554389953613\n",
      "\n",
      "episode 7, val func loss 2.303779363632202\n",
      "\n",
      "episode 8, val func loss 2.273699998855591\n",
      "\n",
      "episode 9, val func loss 2.3069581985473633\n",
      "\n",
      "episode 10, val func loss 2.2865195274353027\n",
      "\n",
      "episode 11, val func loss 2.2920124530792236\n",
      "\n",
      "episode 12, val func loss 2.3086655139923096\n",
      "\n",
      "episode 13, val func loss 2.262117862701416\n",
      "\n",
      "episode 14, val func loss 2.2811615467071533\n",
      "\n",
      "episode 15, val func loss 2.3202786445617676\n",
      "\n",
      "episode 16, val func loss 2.231689453125\n",
      "\n",
      "Val func train loss in epoch 2:2.2855188995599747\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.287611722946167\n",
      "\n",
      "episode 2, val func loss 2.2544968128204346\n",
      "\n",
      "episode 3, val func loss 2.2771570682525635\n",
      "\n",
      "episode 4, val func loss 2.2188994884490967\n",
      "\n",
      "episode 5, val func loss 2.2561347484588623\n",
      "\n",
      "episode 6, val func loss 2.304750919342041\n",
      "\n",
      "episode 7, val func loss 2.28398060798645\n",
      "\n",
      "episode 8, val func loss 2.256258726119995\n",
      "\n",
      "episode 9, val func loss 2.2486236095428467\n",
      "\n",
      "episode 10, val func loss 2.2019107341766357\n",
      "\n",
      "episode 11, val func loss 2.252701759338379\n",
      "\n",
      "episode 12, val func loss 2.197589635848999\n",
      "\n",
      "episode 13, val func loss 2.2353854179382324\n",
      "\n",
      "episode 14, val func loss 2.1823277473449707\n",
      "\n",
      "episode 15, val func loss 2.188122272491455\n",
      "\n",
      "episode 16, val func loss 2.1842119693756104\n",
      "\n",
      "Val func train loss in epoch 3:2.239385202527046\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.159693717956543\n",
      "\n",
      "episode 2, val func loss 2.2262890338897705\n",
      "\n",
      "episode 3, val func loss 2.1628811359405518\n",
      "\n",
      "episode 4, val func loss 2.2147586345672607\n",
      "\n",
      "episode 5, val func loss 2.146199941635132\n",
      "\n",
      "episode 6, val func loss 2.1614761352539062\n",
      "\n",
      "episode 7, val func loss 2.1779019832611084\n",
      "\n",
      "episode 8, val func loss 2.2107350826263428\n",
      "\n",
      "episode 9, val func loss 2.0937154293060303\n",
      "\n",
      "episode 10, val func loss 2.104585886001587\n",
      "\n",
      "episode 11, val func loss 2.2239177227020264\n",
      "\n",
      "episode 12, val func loss 2.074306011199951\n",
      "\n",
      "episode 13, val func loss 2.080808162689209\n",
      "\n",
      "episode 14, val func loss 1.9967492818832397\n",
      "\n",
      "episode 15, val func loss 1.969828724861145\n",
      "\n",
      "episode 16, val func loss 1.8822964429855347\n",
      "\n",
      "Val func train loss in epoch 4:2.1178839579224586\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 2.0392041206359863\n",
      "\n",
      "episode 2, val func loss 1.978629469871521\n",
      "\n",
      "episode 3, val func loss 1.8425008058547974\n",
      "\n",
      "episode 4, val func loss 1.7911639213562012\n",
      "\n",
      "episode 5, val func loss 1.8096930980682373\n",
      "\n",
      "episode 6, val func loss 1.926131248474121\n",
      "\n",
      "episode 7, val func loss 1.6551454067230225\n",
      "\n",
      "episode 8, val func loss 1.8900067806243896\n",
      "\n",
      "episode 9, val func loss 2.014714479446411\n",
      "\n",
      "episode 10, val func loss 1.7642993927001953\n",
      "\n",
      "episode 11, val func loss 1.8540477752685547\n",
      "\n",
      "episode 12, val func loss 1.7825905084609985\n",
      "\n",
      "episode 13, val func loss 1.6161800622940063\n",
      "\n",
      "episode 14, val func loss 1.679547905921936\n",
      "\n",
      "episode 15, val func loss 1.7529512643814087\n",
      "\n",
      "episode 16, val func loss 1.7427096366882324\n",
      "\n",
      "Val func train loss in epoch 5:1.8212197422981262\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.5234733819961548\n",
      "\n",
      "episode 2, val func loss 1.7919343709945679\n",
      "\n",
      "episode 3, val func loss 1.7835142612457275\n",
      "\n",
      "episode 4, val func loss 1.8531134128570557\n",
      "\n",
      "episode 5, val func loss 1.7523789405822754\n",
      "\n",
      "episode 6, val func loss 1.7278132438659668\n",
      "\n",
      "episode 7, val func loss 1.4308921098709106\n",
      "\n",
      "episode 8, val func loss 1.7911046743392944\n",
      "\n",
      "episode 9, val func loss 1.8084962368011475\n",
      "\n",
      "episode 10, val func loss 1.6395753622055054\n",
      "\n",
      "episode 11, val func loss 1.6258641481399536\n",
      "\n",
      "episode 12, val func loss 1.530027985572815\n",
      "\n",
      "episode 13, val func loss 1.5579495429992676\n",
      "\n",
      "episode 14, val func loss 1.471032738685608\n",
      "\n",
      "episode 15, val func loss 1.4649029970169067\n",
      "\n",
      "episode 16, val func loss 1.591594934463501\n",
      "\n",
      "Val func train loss in epoch 6:1.646479271352291\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.4062443971633911\n",
      "\n",
      "episode 2, val func loss 1.554728627204895\n",
      "\n",
      "episode 3, val func loss 1.4989339113235474\n",
      "\n",
      "episode 4, val func loss 1.550742506980896\n",
      "\n",
      "episode 5, val func loss 1.433217167854309\n",
      "\n",
      "episode 6, val func loss 1.4949722290039062\n",
      "\n",
      "episode 7, val func loss 1.5486034154891968\n",
      "\n",
      "episode 8, val func loss 1.5437425374984741\n",
      "\n",
      "episode 9, val func loss 1.5484051704406738\n",
      "\n",
      "episode 10, val func loss 1.4225271940231323\n",
      "\n",
      "episode 11, val func loss 1.388519525527954\n",
      "\n",
      "episode 12, val func loss 1.4986019134521484\n",
      "\n",
      "episode 13, val func loss 1.525848388671875\n",
      "\n",
      "episode 14, val func loss 1.6805728673934937\n",
      "\n",
      "episode 15, val func loss 1.2807179689407349\n",
      "\n",
      "episode 16, val func loss 1.6289827823638916\n",
      "\n",
      "Val func train loss in epoch 7:1.5003350377082825\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.5620133876800537\n",
      "\n",
      "episode 2, val func loss 1.5650359392166138\n",
      "\n",
      "episode 3, val func loss 1.6273735761642456\n",
      "\n",
      "episode 4, val func loss 1.2950119972229004\n",
      "\n",
      "episode 5, val func loss 1.228938102722168\n",
      "\n",
      "episode 6, val func loss 1.4319210052490234\n",
      "\n",
      "episode 7, val func loss 1.4617135524749756\n",
      "\n",
      "episode 8, val func loss 1.661522626876831\n",
      "\n",
      "episode 9, val func loss 1.1779441833496094\n",
      "\n",
      "episode 10, val func loss 1.346008539199829\n",
      "\n",
      "episode 11, val func loss 1.4520715475082397\n",
      "\n",
      "episode 12, val func loss 1.5491124391555786\n",
      "\n",
      "episode 13, val func loss 1.4657050371170044\n",
      "\n",
      "episode 14, val func loss 1.4247825145721436\n",
      "\n",
      "episode 15, val func loss 1.4583137035369873\n",
      "\n",
      "episode 16, val func loss 1.4507580995559692\n",
      "\n",
      "Val func train loss in epoch 8:1.4473891407251358\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.3357375860214233\n",
      "\n",
      "episode 2, val func loss 1.2855913639068604\n",
      "\n",
      "episode 3, val func loss 1.4443111419677734\n",
      "\n",
      "episode 4, val func loss 1.4650373458862305\n",
      "\n",
      "episode 5, val func loss 1.3649983406066895\n",
      "\n",
      "episode 6, val func loss 1.3289333581924438\n",
      "\n",
      "episode 7, val func loss 1.30730140209198\n",
      "\n",
      "episode 8, val func loss 1.4113643169403076\n",
      "\n",
      "episode 9, val func loss 1.3662573099136353\n",
      "\n",
      "episode 10, val func loss 1.3372900485992432\n",
      "\n",
      "episode 11, val func loss 1.3055682182312012\n",
      "\n",
      "episode 12, val func loss 1.2889199256896973\n",
      "\n",
      "episode 13, val func loss 1.2897757291793823\n",
      "\n",
      "episode 14, val func loss 1.3363234996795654\n",
      "\n",
      "episode 15, val func loss 1.2611340284347534\n",
      "\n",
      "episode 16, val func loss 1.1896611452102661\n",
      "\n",
      "Val func train loss in epoch 9:1.3323877975344658\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.5550354719161987\n",
      "\n",
      "episode 2, val func loss 1.0907113552093506\n",
      "\n",
      "episode 3, val func loss 1.3195955753326416\n",
      "\n",
      "episode 4, val func loss 1.2398189306259155\n",
      "\n",
      "episode 5, val func loss 1.543985366821289\n",
      "\n",
      "episode 6, val func loss 1.4241316318511963\n",
      "\n",
      "episode 7, val func loss 1.2703258991241455\n",
      "\n",
      "episode 8, val func loss 1.6651109457015991\n",
      "\n",
      "episode 9, val func loss 1.4153472185134888\n",
      "\n",
      "episode 10, val func loss 1.4084562063217163\n",
      "\n",
      "episode 11, val func loss 1.3091862201690674\n",
      "\n",
      "episode 12, val func loss 1.77851140499115\n",
      "\n",
      "episode 13, val func loss 1.5671604871749878\n",
      "\n",
      "episode 14, val func loss 1.6846013069152832\n",
      "\n",
      "episode 15, val func loss 1.3317204713821411\n",
      "\n",
      "episode 16, val func loss 1.6281765699386597\n",
      "\n",
      "Val func train loss in epoch 10:1.451992191374302\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.47640061378479\n",
      "\n",
      "episode 2, val func loss 1.2171212434768677\n",
      "\n",
      "episode 3, val func loss 1.6356947422027588\n",
      "\n",
      "episode 4, val func loss 1.6039372682571411\n",
      "\n",
      "episode 5, val func loss 1.3268707990646362\n",
      "\n",
      "episode 6, val func loss 1.5829499959945679\n",
      "\n",
      "episode 7, val func loss 1.5016512870788574\n",
      "\n",
      "episode 8, val func loss 1.3979291915893555\n",
      "\n",
      "episode 9, val func loss 1.4026128053665161\n",
      "\n",
      "episode 10, val func loss 1.3742903470993042\n",
      "\n",
      "episode 11, val func loss 1.3753397464752197\n",
      "\n",
      "episode 12, val func loss 1.6896324157714844\n",
      "\n",
      "episode 13, val func loss 1.496087670326233\n",
      "\n",
      "episode 14, val func loss 1.3974652290344238\n",
      "\n",
      "episode 15, val func loss 1.2781832218170166\n",
      "\n",
      "episode 16, val func loss 1.3524571657180786\n",
      "\n",
      "Val func train loss in epoch 11:1.4442889839410782\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.3840737342834473\n",
      "\n",
      "episode 2, val func loss 1.5163425207138062\n",
      "\n",
      "episode 3, val func loss 1.505985140800476\n",
      "\n",
      "episode 4, val func loss 1.4955525398254395\n",
      "\n",
      "episode 5, val func loss 1.3193718194961548\n",
      "\n",
      "episode 6, val func loss 1.2312347888946533\n",
      "\n",
      "episode 7, val func loss 1.2278324365615845\n",
      "\n",
      "episode 8, val func loss 1.2752605676651\n",
      "\n",
      "episode 9, val func loss 1.348193883895874\n",
      "\n",
      "episode 10, val func loss 1.280507206916809\n",
      "\n",
      "episode 11, val func loss 1.4709254503250122\n",
      "\n",
      "episode 12, val func loss 1.2135074138641357\n",
      "\n",
      "episode 13, val func loss 1.3550777435302734\n",
      "\n",
      "episode 14, val func loss 1.3622173070907593\n",
      "\n",
      "episode 15, val func loss 1.3111708164215088\n",
      "\n",
      "episode 16, val func loss 1.3578896522521973\n",
      "\n",
      "Val func train loss in epoch 12:1.353446438908577\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.4945108890533447\n",
      "\n",
      "episode 2, val func loss 1.338257074356079\n",
      "\n",
      "episode 3, val func loss 1.700958251953125\n",
      "\n",
      "episode 4, val func loss 1.2584165334701538\n",
      "\n",
      "episode 5, val func loss 1.2602964639663696\n",
      "\n",
      "episode 6, val func loss 1.4041191339492798\n",
      "\n",
      "episode 7, val func loss 1.2226896286010742\n",
      "\n",
      "episode 8, val func loss 1.0384443998336792\n",
      "\n",
      "episode 9, val func loss 1.5139820575714111\n",
      "\n",
      "episode 10, val func loss 1.2484164237976074\n",
      "\n",
      "episode 11, val func loss 1.314834713935852\n",
      "\n",
      "episode 12, val func loss 1.298561930656433\n",
      "\n",
      "episode 13, val func loss 1.3057169914245605\n",
      "\n",
      "episode 14, val func loss 1.3162996768951416\n",
      "\n",
      "episode 15, val func loss 1.3325719833374023\n",
      "\n",
      "episode 16, val func loss 1.2657595872879028\n",
      "\n",
      "Val func train loss in epoch 13:1.3321147337555885\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.2930089235305786\n",
      "\n",
      "episode 2, val func loss 1.3235589265823364\n",
      "\n",
      "episode 3, val func loss 1.3412619829177856\n",
      "\n",
      "episode 4, val func loss 1.49814772605896\n",
      "\n",
      "episode 5, val func loss 1.4607603549957275\n",
      "\n",
      "episode 6, val func loss 1.4147799015045166\n",
      "\n",
      "episode 7, val func loss 1.1320233345031738\n",
      "\n",
      "episode 8, val func loss 1.449253797531128\n",
      "\n",
      "episode 9, val func loss 1.1805789470672607\n",
      "\n",
      "episode 10, val func loss 1.2860913276672363\n",
      "\n",
      "episode 11, val func loss 1.2561861276626587\n",
      "\n",
      "episode 12, val func loss 1.6911053657531738\n",
      "\n",
      "episode 13, val func loss 1.3234350681304932\n",
      "\n",
      "episode 14, val func loss 1.3124973773956299\n",
      "\n",
      "episode 15, val func loss 1.4520072937011719\n",
      "\n",
      "episode 16, val func loss 1.225854754447937\n",
      "\n",
      "Val func train loss in epoch 14:1.3525344505906105\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.4993740320205688\n",
      "\n",
      "episode 2, val func loss 1.2994885444641113\n",
      "\n",
      "episode 3, val func loss 1.287797212600708\n",
      "\n",
      "episode 4, val func loss 1.316165566444397\n",
      "\n",
      "episode 5, val func loss 1.3013437986373901\n",
      "\n",
      "episode 6, val func loss 1.2464849948883057\n",
      "\n",
      "episode 7, val func loss 1.164396047592163\n",
      "\n",
      "episode 8, val func loss 1.2745261192321777\n",
      "\n",
      "episode 9, val func loss 1.0896104574203491\n",
      "\n",
      "episode 10, val func loss 1.4277113676071167\n",
      "\n",
      "episode 11, val func loss 1.3428421020507812\n",
      "\n",
      "episode 12, val func loss 1.4454448223114014\n",
      "\n",
      "episode 13, val func loss 1.5106785297393799\n",
      "\n",
      "episode 14, val func loss 1.3947203159332275\n",
      "\n",
      "episode 15, val func loss 1.2877085208892822\n",
      "\n",
      "episode 16, val func loss 1.2637274265289307\n",
      "\n",
      "Val func train loss in epoch 15:1.3220012411475182\n",
      "***********************TIME WAS 4.855296687285105 min*****************************\n",
      "\n",
      "**********************ROUND 71 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.8273427486419678\n",
      "\n",
      "episode 2, policy loss -2.827342987060547\n",
      "\n",
      "episode 3, policy loss -2.827342987060547\n",
      "\n",
      "episode 4, policy loss -2.827342987060547\n",
      "\n",
      "episode 5, policy loss -2.827342987060547\n",
      "\n",
      "episode 6, policy loss -2.827342987060547\n",
      "\n",
      "episode 7, policy loss -2.827342987060547\n",
      "\n",
      "episode 8, policy loss -2.827342987060547\n",
      "\n",
      "episode 9, policy loss -2.827342987060547\n",
      "\n",
      "episode 10, policy loss -2.827342987060547\n",
      "\n",
      "episode 11, policy loss -2.827342987060547\n",
      "\n",
      "episode 12, policy loss -2.827342987060547\n",
      "\n",
      "episode 13, policy loss -2.827342987060547\n",
      "\n",
      "episode 14, policy loss -2.827342987060547\n",
      "\n",
      "episode 15, policy loss -2.8273427486419678\n",
      "\n",
      "episode 16, policy loss -2.8273427486419678\n",
      "\n",
      "Policy train loss in epoch 0:-2.8273429423570633\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.827342987060547\n",
      "\n",
      "episode 2, policy loss -2.827342987060547\n",
      "\n",
      "episode 3, policy loss -2.8273427486419678\n",
      "\n",
      "episode 4, policy loss -2.827342987060547\n",
      "\n",
      "episode 5, policy loss -2.8273427486419678\n",
      "\n",
      "episode 6, policy loss -2.827342987060547\n",
      "\n",
      "episode 7, policy loss -2.8273427486419678\n",
      "\n",
      "episode 8, policy loss -2.827342987060547\n",
      "\n",
      "episode 9, policy loss -2.827342987060547\n",
      "\n",
      "episode 10, policy loss -2.827342987060547\n",
      "\n",
      "episode 11, policy loss -2.827342987060547\n",
      "\n",
      "episode 12, policy loss -2.827342987060547\n",
      "\n",
      "episode 13, policy loss -2.827342987060547\n",
      "\n",
      "episode 14, policy loss -2.827342987060547\n",
      "\n",
      "episode 15, policy loss -2.827342987060547\n",
      "\n",
      "episode 16, policy loss -2.827342987060547\n",
      "\n",
      "Policy train loss in epoch 1:-2.8273429423570633\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.827342987060547\n",
      "\n",
      "episode 2, policy loss -2.827342987060547\n",
      "\n",
      "episode 3, policy loss -2.8273427486419678\n",
      "\n",
      "episode 4, policy loss -2.827342987060547\n",
      "\n",
      "episode 5, policy loss -2.827342987060547\n",
      "\n",
      "episode 6, policy loss -2.827342987060547\n",
      "\n",
      "episode 7, policy loss -2.827342987060547\n",
      "\n",
      "episode 8, policy loss -2.827342987060547\n",
      "\n",
      "episode 9, policy loss -2.827342987060547\n",
      "\n",
      "episode 10, policy loss -2.827342987060547\n",
      "\n",
      "episode 11, policy loss -2.827342987060547\n",
      "\n",
      "episode 12, policy loss -2.827342987060547\n",
      "\n",
      "episode 13, policy loss -2.827342987060547\n",
      "\n",
      "episode 14, policy loss -2.827342987060547\n",
      "\n",
      "episode 15, policy loss -2.827342987060547\n",
      "\n",
      "episode 16, policy loss -2.827342987060547\n",
      "\n",
      "Policy train loss in epoch 2:-2.8273429721593857\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.8273427486419678\n",
      "\n",
      "episode 2, policy loss -2.827342987060547\n",
      "\n",
      "episode 3, policy loss -2.827342987060547\n",
      "\n",
      "episode 4, policy loss -2.827342987060547\n",
      "\n",
      "episode 5, policy loss -2.827342987060547\n",
      "\n",
      "episode 6, policy loss -2.8273427486419678\n",
      "\n",
      "episode 7, policy loss -2.827342987060547\n",
      "\n",
      "episode 8, policy loss -2.827342987060547\n",
      "\n",
      "episode 9, policy loss -2.827342987060547\n",
      "\n",
      "episode 10, policy loss -2.8273427486419678\n",
      "\n",
      "episode 11, policy loss -2.827342987060547\n",
      "\n",
      "episode 12, policy loss -2.827342987060547\n",
      "\n",
      "episode 13, policy loss -2.827342987060547\n",
      "\n",
      "episode 14, policy loss -2.827342987060547\n",
      "\n",
      "episode 15, policy loss -2.827342987060547\n",
      "\n",
      "episode 16, policy loss -2.827342987060547\n",
      "\n",
      "Policy train loss in epoch 3:-2.8273429423570633\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.4298641681671143\n",
      "\n",
      "episode 2, val func loss 1.2571773529052734\n",
      "\n",
      "episode 3, val func loss 1.090199589729309\n",
      "\n",
      "episode 4, val func loss 1.4607136249542236\n",
      "\n",
      "episode 5, val func loss 1.5220814943313599\n",
      "\n",
      "episode 6, val func loss 1.3604798316955566\n",
      "\n",
      "episode 7, val func loss 1.4106284379959106\n",
      "\n",
      "episode 8, val func loss 1.2911940813064575\n",
      "\n",
      "episode 9, val func loss 1.3143235445022583\n",
      "\n",
      "episode 10, val func loss 1.2938607931137085\n",
      "\n",
      "episode 11, val func loss 1.2056995630264282\n",
      "\n",
      "episode 12, val func loss 1.3384976387023926\n",
      "\n",
      "episode 13, val func loss 1.3906450271606445\n",
      "\n",
      "episode 14, val func loss 1.307807445526123\n",
      "\n",
      "episode 15, val func loss 1.1638504266738892\n",
      "\n",
      "episode 16, val func loss 1.3725115060806274\n",
      "\n",
      "Val func train loss in epoch 0:1.3255959078669548\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.2343635559082031\n",
      "\n",
      "episode 2, val func loss 1.3352516889572144\n",
      "\n",
      "episode 3, val func loss 1.384943962097168\n",
      "\n",
      "episode 4, val func loss 1.249732494354248\n",
      "\n",
      "episode 5, val func loss 1.3794307708740234\n",
      "\n",
      "episode 6, val func loss 1.3315006494522095\n",
      "\n",
      "episode 7, val func loss 1.2892471551895142\n",
      "\n",
      "episode 8, val func loss 1.3221458196640015\n",
      "\n",
      "episode 9, val func loss 1.1419974565505981\n",
      "\n",
      "episode 10, val func loss 1.1874737739562988\n",
      "\n",
      "episode 11, val func loss 1.4812464714050293\n",
      "\n",
      "episode 12, val func loss 1.6290044784545898\n",
      "\n",
      "episode 13, val func loss 1.8550790548324585\n",
      "\n",
      "episode 14, val func loss 1.457919955253601\n",
      "\n",
      "episode 15, val func loss 1.7631886005401611\n",
      "\n",
      "episode 16, val func loss 1.3091671466827393\n",
      "\n",
      "Val func train loss in epoch 1:1.3969808146357536\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.3925538063049316\n",
      "\n",
      "episode 2, val func loss 1.3503329753875732\n",
      "\n",
      "episode 3, val func loss 1.3836658000946045\n",
      "\n",
      "episode 4, val func loss 1.4299626350402832\n",
      "\n",
      "episode 5, val func loss 1.2897711992263794\n",
      "\n",
      "episode 6, val func loss 1.5262000560760498\n",
      "\n",
      "episode 7, val func loss 1.191654920578003\n",
      "\n",
      "episode 8, val func loss 1.2894924879074097\n",
      "\n",
      "episode 9, val func loss 1.2953051328659058\n",
      "\n",
      "episode 10, val func loss 1.2523808479309082\n",
      "\n",
      "episode 11, val func loss 1.4108670949935913\n",
      "\n",
      "episode 12, val func loss 1.3062492609024048\n",
      "\n",
      "episode 13, val func loss 1.311698079109192\n",
      "\n",
      "episode 14, val func loss 1.37234628200531\n",
      "\n",
      "episode 15, val func loss 1.3344645500183105\n",
      "\n",
      "episode 16, val func loss 1.1944820880889893\n",
      "\n",
      "Val func train loss in epoch 2:1.3332142010331154\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.1128885746002197\n",
      "\n",
      "episode 2, val func loss 1.3369251489639282\n",
      "\n",
      "episode 3, val func loss 1.534447193145752\n",
      "\n",
      "episode 4, val func loss 1.3336727619171143\n",
      "\n",
      "episode 5, val func loss 1.3163353204727173\n",
      "\n",
      "episode 6, val func loss 1.2475978136062622\n",
      "\n",
      "episode 7, val func loss 1.2609323263168335\n",
      "\n",
      "episode 8, val func loss 1.3958557844161987\n",
      "\n",
      "episode 9, val func loss 1.3905067443847656\n",
      "\n",
      "episode 10, val func loss 1.3580361604690552\n",
      "\n",
      "episode 11, val func loss 1.3816545009613037\n",
      "\n",
      "episode 12, val func loss 1.3149946928024292\n",
      "\n",
      "episode 13, val func loss 1.1529040336608887\n",
      "\n",
      "episode 14, val func loss 1.209895133972168\n",
      "\n",
      "episode 15, val func loss 1.3752431869506836\n",
      "\n",
      "episode 16, val func loss 1.3001389503479004\n",
      "\n",
      "Val func train loss in epoch 3:1.3138767704367638\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.3905526399612427\n",
      "\n",
      "episode 2, val func loss 1.3334332704544067\n",
      "\n",
      "episode 3, val func loss 1.4382802248001099\n",
      "\n",
      "episode 4, val func loss 1.5863537788391113\n",
      "\n",
      "episode 5, val func loss 1.1898936033248901\n",
      "\n",
      "episode 6, val func loss 1.4168651103973389\n",
      "\n",
      "episode 7, val func loss 1.371099591255188\n",
      "\n",
      "episode 8, val func loss 1.2965689897537231\n",
      "\n",
      "episode 9, val func loss 1.219343900680542\n",
      "\n",
      "episode 10, val func loss 1.3373279571533203\n",
      "\n",
      "episode 11, val func loss 1.2958959341049194\n",
      "\n",
      "episode 12, val func loss 1.0390641689300537\n",
      "\n",
      "episode 13, val func loss 1.45763099193573\n",
      "\n",
      "episode 14, val func loss 1.202412724494934\n",
      "\n",
      "episode 15, val func loss 1.313488245010376\n",
      "\n",
      "episode 16, val func loss 1.1775028705596924\n",
      "\n",
      "Val func train loss in epoch 4:1.3166071251034737\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.2435578107833862\n",
      "\n",
      "episode 2, val func loss 1.3999561071395874\n",
      "\n",
      "episode 3, val func loss 1.2671818733215332\n",
      "\n",
      "episode 4, val func loss 1.3802179098129272\n",
      "\n",
      "episode 5, val func loss 1.3402597904205322\n",
      "\n",
      "episode 6, val func loss 1.1654502153396606\n",
      "\n",
      "episode 7, val func loss 1.1921290159225464\n",
      "\n",
      "episode 8, val func loss 1.1159498691558838\n",
      "\n",
      "episode 9, val func loss 1.2233067750930786\n",
      "\n",
      "episode 10, val func loss 1.3697841167449951\n",
      "\n",
      "episode 11, val func loss 1.3641849756240845\n",
      "\n",
      "episode 12, val func loss 1.4152694940567017\n",
      "\n",
      "episode 13, val func loss 1.2143970727920532\n",
      "\n",
      "episode 14, val func loss 1.1745296716690063\n",
      "\n",
      "episode 15, val func loss 1.3711702823638916\n",
      "\n",
      "episode 16, val func loss 1.2984728813171387\n",
      "\n",
      "Val func train loss in epoch 5:1.283488616347313\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.486756682395935\n",
      "\n",
      "episode 2, val func loss 1.4390521049499512\n",
      "\n",
      "episode 3, val func loss 1.142948031425476\n",
      "\n",
      "episode 4, val func loss 1.1889930963516235\n",
      "\n",
      "episode 5, val func loss 1.3134595155715942\n",
      "\n",
      "episode 6, val func loss 1.3875213861465454\n",
      "\n",
      "episode 7, val func loss 1.5006356239318848\n",
      "\n",
      "episode 8, val func loss 0.9354762434959412\n",
      "\n",
      "episode 9, val func loss 1.219588041305542\n",
      "\n",
      "episode 10, val func loss 1.1840919256210327\n",
      "\n",
      "episode 11, val func loss 1.269734263420105\n",
      "\n",
      "episode 12, val func loss 1.3985131978988647\n",
      "\n",
      "episode 13, val func loss 1.2882283926010132\n",
      "\n",
      "episode 14, val func loss 1.366190791130066\n",
      "\n",
      "episode 15, val func loss 1.40718674659729\n",
      "\n",
      "episode 16, val func loss 1.1695313453674316\n",
      "\n",
      "Val func train loss in epoch 6:1.2936192117631435\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.3106846809387207\n",
      "\n",
      "episode 2, val func loss 1.4052469730377197\n",
      "\n",
      "episode 3, val func loss 1.2378020286560059\n",
      "\n",
      "episode 4, val func loss 1.1947789192199707\n",
      "\n",
      "episode 5, val func loss 1.1757675409317017\n",
      "\n",
      "episode 6, val func loss 1.1794040203094482\n",
      "\n",
      "episode 7, val func loss 1.3451365232467651\n",
      "\n",
      "episode 8, val func loss 1.370254397392273\n",
      "\n",
      "episode 9, val func loss 1.3213305473327637\n",
      "\n",
      "episode 10, val func loss 1.2213469743728638\n",
      "\n",
      "episode 11, val func loss 1.2414501905441284\n",
      "\n",
      "episode 12, val func loss 1.1874228715896606\n",
      "\n",
      "episode 13, val func loss 1.4371135234832764\n",
      "\n",
      "episode 14, val func loss 1.297031044960022\n",
      "\n",
      "episode 15, val func loss 1.4192498922348022\n",
      "\n",
      "episode 16, val func loss 1.285373568534851\n",
      "\n",
      "Val func train loss in epoch 7:1.2893371060490608\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.297924518585205\n",
      "\n",
      "episode 2, val func loss 1.3704687356948853\n",
      "\n",
      "episode 3, val func loss 1.5127702951431274\n",
      "\n",
      "episode 4, val func loss 1.2494468688964844\n",
      "\n",
      "episode 5, val func loss 1.4353903532028198\n",
      "\n",
      "episode 6, val func loss 1.24960458278656\n",
      "\n",
      "episode 7, val func loss 1.3427878618240356\n",
      "\n",
      "episode 8, val func loss 1.3023686408996582\n",
      "\n",
      "episode 9, val func loss 1.2948131561279297\n",
      "\n",
      "episode 10, val func loss 1.2906115055084229\n",
      "\n",
      "episode 11, val func loss 1.528171420097351\n",
      "\n",
      "episode 12, val func loss 1.2226272821426392\n",
      "\n",
      "episode 13, val func loss 1.2707878351211548\n",
      "\n",
      "episode 14, val func loss 1.3110021352767944\n",
      "\n",
      "episode 15, val func loss 1.3092963695526123\n",
      "\n",
      "episode 16, val func loss 1.3682738542556763\n",
      "\n",
      "Val func train loss in epoch 8:1.3347715884447098\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.4034068584442139\n",
      "\n",
      "episode 2, val func loss 1.3828073740005493\n",
      "\n",
      "episode 3, val func loss 1.2451685667037964\n",
      "\n",
      "episode 4, val func loss 1.2688720226287842\n",
      "\n",
      "episode 5, val func loss 1.194492220878601\n",
      "\n",
      "episode 6, val func loss 1.2649339437484741\n",
      "\n",
      "episode 7, val func loss 1.3318661451339722\n",
      "\n",
      "episode 8, val func loss 1.3675259351730347\n",
      "\n",
      "episode 9, val func loss 1.2508063316345215\n",
      "\n",
      "episode 10, val func loss 1.1315926313400269\n",
      "\n",
      "episode 11, val func loss 1.2909296751022339\n",
      "\n",
      "episode 12, val func loss 1.5649948120117188\n",
      "\n",
      "episode 13, val func loss 1.2128931283950806\n",
      "\n",
      "episode 14, val func loss 1.2004541158676147\n",
      "\n",
      "episode 15, val func loss 1.0273603200912476\n",
      "\n",
      "episode 16, val func loss 1.1862084865570068\n",
      "\n",
      "Val func train loss in epoch 9:1.2702695354819298\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.2015281915664673\n",
      "\n",
      "episode 2, val func loss 1.2464666366577148\n",
      "\n",
      "episode 3, val func loss 1.3043495416641235\n",
      "\n",
      "episode 4, val func loss 1.4219766855239868\n",
      "\n",
      "episode 5, val func loss 1.255425214767456\n",
      "\n",
      "episode 6, val func loss 1.317036747932434\n",
      "\n",
      "episode 7, val func loss 1.474794864654541\n",
      "\n",
      "episode 8, val func loss 1.2056814432144165\n",
      "\n",
      "episode 9, val func loss 1.4557077884674072\n",
      "\n",
      "episode 10, val func loss 1.3882802724838257\n",
      "\n",
      "episode 11, val func loss 1.015055775642395\n",
      "\n",
      "episode 12, val func loss 1.2093205451965332\n",
      "\n",
      "episode 13, val func loss 1.3440800905227661\n",
      "\n",
      "episode 14, val func loss 1.4915950298309326\n",
      "\n",
      "episode 15, val func loss 1.3000593185424805\n",
      "\n",
      "episode 16, val func loss 1.3664155006408691\n",
      "\n",
      "Val func train loss in epoch 10:1.3123608529567719\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.2112150192260742\n",
      "\n",
      "episode 2, val func loss 1.2908689975738525\n",
      "\n",
      "episode 3, val func loss 1.446800708770752\n",
      "\n",
      "episode 4, val func loss 1.2340028285980225\n",
      "\n",
      "episode 5, val func loss 1.2505022287368774\n",
      "\n",
      "episode 6, val func loss 1.4207831621170044\n",
      "\n",
      "episode 7, val func loss 1.304954171180725\n",
      "\n",
      "episode 8, val func loss 1.6962950229644775\n",
      "\n",
      "episode 9, val func loss 1.3026847839355469\n",
      "\n",
      "episode 10, val func loss 1.2196308374404907\n",
      "\n",
      "episode 11, val func loss 1.443033218383789\n",
      "\n",
      "episode 12, val func loss 1.3381515741348267\n",
      "\n",
      "episode 13, val func loss 1.2567983865737915\n",
      "\n",
      "episode 14, val func loss 1.401347279548645\n",
      "\n",
      "episode 15, val func loss 1.20401132106781\n",
      "\n",
      "episode 16, val func loss 1.404687523841858\n",
      "\n",
      "Val func train loss in epoch 11:1.339110441505909\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.1960126161575317\n",
      "\n",
      "episode 2, val func loss 1.3448474407196045\n",
      "\n",
      "episode 3, val func loss 1.1284247636795044\n",
      "\n",
      "episode 4, val func loss 1.0502419471740723\n",
      "\n",
      "episode 5, val func loss 1.266745924949646\n",
      "\n",
      "episode 6, val func loss 1.5209646224975586\n",
      "\n",
      "episode 7, val func loss 1.3637171983718872\n",
      "\n",
      "episode 8, val func loss 1.31011164188385\n",
      "\n",
      "episode 9, val func loss 1.2534010410308838\n",
      "\n",
      "episode 10, val func loss 1.108323097229004\n",
      "\n",
      "episode 11, val func loss 1.344408631324768\n",
      "\n",
      "episode 12, val func loss 1.3317852020263672\n",
      "\n",
      "episode 13, val func loss 1.21498703956604\n",
      "\n",
      "episode 14, val func loss 1.2403165102005005\n",
      "\n",
      "episode 15, val func loss 1.3071345090866089\n",
      "\n",
      "episode 16, val func loss 1.043190360069275\n",
      "\n",
      "Val func train loss in epoch 12:1.2515382841229439\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.1952760219573975\n",
      "\n",
      "episode 2, val func loss 1.279604196548462\n",
      "\n",
      "episode 3, val func loss 1.222755789756775\n",
      "\n",
      "episode 4, val func loss 1.366655707359314\n",
      "\n",
      "episode 5, val func loss 1.4036868810653687\n",
      "\n",
      "episode 6, val func loss 1.2124532461166382\n",
      "\n",
      "episode 7, val func loss 1.164965271949768\n",
      "\n",
      "episode 8, val func loss 1.3749983310699463\n",
      "\n",
      "episode 9, val func loss 1.1906211376190186\n",
      "\n",
      "episode 10, val func loss 1.1358405351638794\n",
      "\n",
      "episode 11, val func loss 1.3511136770248413\n",
      "\n",
      "episode 12, val func loss 1.221373438835144\n",
      "\n",
      "episode 13, val func loss 1.6280854940414429\n",
      "\n",
      "episode 14, val func loss 1.5748344659805298\n",
      "\n",
      "episode 15, val func loss 1.4083583354949951\n",
      "\n",
      "episode 16, val func loss 1.2939304113388062\n",
      "\n",
      "Val func train loss in epoch 13:1.3140345588326454\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.1597403287887573\n",
      "\n",
      "episode 2, val func loss 1.3910396099090576\n",
      "\n",
      "episode 3, val func loss 1.4538835287094116\n",
      "\n",
      "episode 4, val func loss 1.1848950386047363\n",
      "\n",
      "episode 5, val func loss 1.3484296798706055\n",
      "\n",
      "episode 6, val func loss 1.555221438407898\n",
      "\n",
      "episode 7, val func loss 1.1553514003753662\n",
      "\n",
      "episode 8, val func loss 1.1943840980529785\n",
      "\n",
      "episode 9, val func loss 1.2551547288894653\n",
      "\n",
      "episode 10, val func loss 1.2991877794265747\n",
      "\n",
      "episode 11, val func loss 1.2988253831863403\n",
      "\n",
      "episode 12, val func loss 1.276782751083374\n",
      "\n",
      "episode 13, val func loss 1.4949108362197876\n",
      "\n",
      "episode 14, val func loss 1.3099758625030518\n",
      "\n",
      "episode 15, val func loss 1.2991217374801636\n",
      "\n",
      "episode 16, val func loss 1.2699657678604126\n",
      "\n",
      "Val func train loss in epoch 14:1.3091793730854988\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.1288342475891113\n",
      "\n",
      "episode 2, val func loss 1.2281458377838135\n",
      "\n",
      "episode 3, val func loss 1.1739517450332642\n",
      "\n",
      "episode 4, val func loss 1.2345569133758545\n",
      "\n",
      "episode 5, val func loss 1.273171305656433\n",
      "\n",
      "episode 6, val func loss 1.3038314580917358\n",
      "\n",
      "episode 7, val func loss 1.4954994916915894\n",
      "\n",
      "episode 8, val func loss 1.3379110097885132\n",
      "\n",
      "episode 9, val func loss 1.2845431566238403\n",
      "\n",
      "episode 10, val func loss 1.1453273296356201\n",
      "\n",
      "episode 11, val func loss 1.2722088098526\n",
      "\n",
      "episode 12, val func loss 1.1433072090148926\n",
      "\n",
      "episode 13, val func loss 1.3946815729141235\n",
      "\n",
      "episode 14, val func loss 1.3632488250732422\n",
      "\n",
      "episode 15, val func loss 1.2748196125030518\n",
      "\n",
      "episode 16, val func loss 1.217857003211975\n",
      "\n",
      "Val func train loss in epoch 15:1.2669934704899788\n",
      "***********************TIME WAS 4.849521271387736 min*****************************\n",
      "\n",
      "**********************ROUND 72 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.254432439804077\n",
      "\n",
      "episode 2, policy loss -3.254432439804077\n",
      "\n",
      "episode 3, policy loss -3.254431962966919\n",
      "\n",
      "episode 4, policy loss -3.254432439804077\n",
      "\n",
      "episode 5, policy loss -3.254432439804077\n",
      "\n",
      "episode 6, policy loss -3.254432439804077\n",
      "\n",
      "episode 7, policy loss -3.254432439804077\n",
      "\n",
      "episode 8, policy loss -3.254432439804077\n",
      "\n",
      "episode 9, policy loss -3.254432439804077\n",
      "\n",
      "episode 10, policy loss -3.254431962966919\n",
      "\n",
      "episode 11, policy loss -3.254432439804077\n",
      "\n",
      "episode 12, policy loss -3.254432439804077\n",
      "\n",
      "episode 13, policy loss -3.254432439804077\n",
      "\n",
      "episode 14, policy loss -3.2544326782226562\n",
      "\n",
      "episode 15, policy loss -3.2544326782226562\n",
      "\n",
      "episode 16, policy loss -3.254432439804077\n",
      "\n",
      "Policy train loss in epoch 0:-3.2544324100017548\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.254432439804077\n",
      "\n",
      "episode 2, policy loss -3.254432439804077\n",
      "\n",
      "episode 3, policy loss -3.254432439804077\n",
      "\n",
      "episode 4, policy loss -3.254432439804077\n",
      "\n",
      "episode 5, policy loss -3.2544326782226562\n",
      "\n",
      "episode 6, policy loss -3.2544326782226562\n",
      "\n",
      "episode 7, policy loss -3.2544326782226562\n",
      "\n",
      "episode 8, policy loss -3.254432439804077\n",
      "\n",
      "episode 9, policy loss -3.254432439804077\n",
      "\n",
      "episode 10, policy loss -3.254432439804077\n",
      "\n",
      "episode 11, policy loss -3.254432439804077\n",
      "\n",
      "episode 12, policy loss -3.254432439804077\n",
      "\n",
      "episode 13, policy loss -3.254432439804077\n",
      "\n",
      "episode 14, policy loss -3.254432439804077\n",
      "\n",
      "episode 15, policy loss -3.254432439804077\n",
      "\n",
      "episode 16, policy loss -3.254432439804077\n",
      "\n",
      "Policy train loss in epoch 1:-3.2544324845075607\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.254431962966919\n",
      "\n",
      "episode 2, policy loss -3.254432439804077\n",
      "\n",
      "episode 3, policy loss -3.254432439804077\n",
      "\n",
      "episode 4, policy loss -3.2544326782226562\n",
      "\n",
      "episode 5, policy loss -3.2544326782226562\n",
      "\n",
      "episode 6, policy loss -3.2544326782226562\n",
      "\n",
      "episode 7, policy loss -3.2544326782226562\n",
      "\n",
      "episode 8, policy loss -3.254432439804077\n",
      "\n",
      "episode 9, policy loss -3.2544326782226562\n",
      "\n",
      "episode 10, policy loss -3.254432439804077\n",
      "\n",
      "episode 11, policy loss -3.254432439804077\n",
      "\n",
      "episode 12, policy loss -3.2544326782226562\n",
      "\n",
      "episode 13, policy loss -3.254432439804077\n",
      "\n",
      "episode 14, policy loss -3.2544326782226562\n",
      "\n",
      "episode 15, policy loss -3.254432439804077\n",
      "\n",
      "episode 16, policy loss -3.254432439804077\n",
      "\n",
      "Policy train loss in epoch 2:-3.254432514309883\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.254432439804077\n",
      "\n",
      "episode 2, policy loss -3.254432439804077\n",
      "\n",
      "episode 3, policy loss -3.2544326782226562\n",
      "\n",
      "episode 4, policy loss -3.254432439804077\n",
      "\n",
      "episode 5, policy loss -3.254432439804077\n",
      "\n",
      "episode 6, policy loss -3.254432439804077\n",
      "\n",
      "episode 7, policy loss -3.2544326782226562\n",
      "\n",
      "episode 8, policy loss -3.254432439804077\n",
      "\n",
      "episode 9, policy loss -3.254432439804077\n",
      "\n",
      "episode 10, policy loss -3.2544326782226562\n",
      "\n",
      "episode 11, policy loss -3.254432439804077\n",
      "\n",
      "episode 12, policy loss -3.254432439804077\n",
      "\n",
      "episode 13, policy loss -3.2544326782226562\n",
      "\n",
      "episode 14, policy loss -3.254432439804077\n",
      "\n",
      "episode 15, policy loss -3.254432439804077\n",
      "\n",
      "episode 16, policy loss -3.2544326782226562\n",
      "\n",
      "Policy train loss in epoch 3:-3.254432514309883\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.128389596939087\n",
      "\n",
      "episode 2, val func loss 1.4367364645004272\n",
      "\n",
      "episode 3, val func loss 1.147333025932312\n",
      "\n",
      "episode 4, val func loss 1.1775363683700562\n",
      "\n",
      "episode 5, val func loss 1.2199190855026245\n",
      "\n",
      "episode 6, val func loss 1.2726548910140991\n",
      "\n",
      "episode 7, val func loss 1.2533199787139893\n",
      "\n",
      "episode 8, val func loss 1.1395277976989746\n",
      "\n",
      "episode 9, val func loss 1.2456928491592407\n",
      "\n",
      "episode 10, val func loss 1.2626025676727295\n",
      "\n",
      "episode 11, val func loss 1.1946443319320679\n",
      "\n",
      "episode 12, val func loss 1.2877323627471924\n",
      "\n",
      "episode 13, val func loss 1.49535071849823\n",
      "\n",
      "episode 14, val func loss 1.270593285560608\n",
      "\n",
      "episode 15, val func loss 1.3383564949035645\n",
      "\n",
      "episode 16, val func loss 1.2405434846878052\n",
      "\n",
      "Val func train loss in epoch 0:1.256933331489563\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.089612364768982\n",
      "\n",
      "episode 2, val func loss 1.3467611074447632\n",
      "\n",
      "episode 3, val func loss 1.3070305585861206\n",
      "\n",
      "episode 4, val func loss 1.339224100112915\n",
      "\n",
      "episode 5, val func loss 1.316590428352356\n",
      "\n",
      "episode 6, val func loss 1.3668105602264404\n",
      "\n",
      "episode 7, val func loss 1.2753156423568726\n",
      "\n",
      "episode 8, val func loss 1.1869115829467773\n",
      "\n",
      "episode 9, val func loss 1.3569438457489014\n",
      "\n",
      "episode 10, val func loss 1.3304818868637085\n",
      "\n",
      "episode 11, val func loss 1.3809993267059326\n",
      "\n",
      "episode 12, val func loss 1.539435863494873\n",
      "\n",
      "episode 13, val func loss 1.2317016124725342\n",
      "\n",
      "episode 14, val func loss 1.3316998481750488\n",
      "\n",
      "episode 15, val func loss 1.5287814140319824\n",
      "\n",
      "episode 16, val func loss 1.2739851474761963\n",
      "\n",
      "Val func train loss in epoch 1:1.3251428306102753\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.6269233226776123\n",
      "\n",
      "episode 2, val func loss 1.4198386669158936\n",
      "\n",
      "episode 3, val func loss 1.3778690099716187\n",
      "\n",
      "episode 4, val func loss 1.306225061416626\n",
      "\n",
      "episode 5, val func loss 1.4287070035934448\n",
      "\n",
      "episode 6, val func loss 1.4397274255752563\n",
      "\n",
      "episode 7, val func loss 1.3102997541427612\n",
      "\n",
      "episode 8, val func loss 1.1983755826950073\n",
      "\n",
      "episode 9, val func loss 1.3592349290847778\n",
      "\n",
      "episode 10, val func loss 1.1409635543823242\n",
      "\n",
      "episode 11, val func loss 1.3234386444091797\n",
      "\n",
      "episode 12, val func loss 1.41632080078125\n",
      "\n",
      "episode 13, val func loss 1.3406423330307007\n",
      "\n",
      "episode 14, val func loss 1.1422563791275024\n",
      "\n",
      "episode 15, val func loss 1.1055924892425537\n",
      "\n",
      "episode 16, val func loss 1.398503065109253\n",
      "\n",
      "Val func train loss in epoch 2:1.333432376384735\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.2094529867172241\n",
      "\n",
      "episode 2, val func loss 1.4168387651443481\n",
      "\n",
      "episode 3, val func loss 1.2073626518249512\n",
      "\n",
      "episode 4, val func loss 1.3928409814834595\n",
      "\n",
      "episode 5, val func loss 1.122658610343933\n",
      "\n",
      "episode 6, val func loss 1.2061609029769897\n",
      "\n",
      "episode 7, val func loss 1.3350316286087036\n",
      "\n",
      "episode 8, val func loss 1.3370541334152222\n",
      "\n",
      "episode 9, val func loss 1.1413649320602417\n",
      "\n",
      "episode 10, val func loss 1.1577560901641846\n",
      "\n",
      "episode 11, val func loss 1.2722569704055786\n",
      "\n",
      "episode 12, val func loss 1.2225291728973389\n",
      "\n",
      "episode 13, val func loss 1.119141697883606\n",
      "\n",
      "episode 14, val func loss 1.2411094903945923\n",
      "\n",
      "episode 15, val func loss 1.207103967666626\n",
      "\n",
      "episode 16, val func loss 1.2859067916870117\n",
      "\n",
      "Val func train loss in epoch 3:1.2421606108546257\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.3108961582183838\n",
      "\n",
      "episode 2, val func loss 1.264419436454773\n",
      "\n",
      "episode 3, val func loss 1.4179543256759644\n",
      "\n",
      "episode 4, val func loss 1.2804853916168213\n",
      "\n",
      "episode 5, val func loss 1.2815042734146118\n",
      "\n",
      "episode 6, val func loss 1.170119047164917\n",
      "\n",
      "episode 7, val func loss 1.1725517511367798\n",
      "\n",
      "episode 8, val func loss 1.2919479608535767\n",
      "\n",
      "episode 9, val func loss 1.3324766159057617\n",
      "\n",
      "episode 10, val func loss 1.3510854244232178\n",
      "\n",
      "episode 11, val func loss 1.3617160320281982\n",
      "\n",
      "episode 12, val func loss 1.244701862335205\n",
      "\n",
      "episode 13, val func loss 1.2838889360427856\n",
      "\n",
      "episode 14, val func loss 1.2391389608383179\n",
      "\n",
      "episode 15, val func loss 1.1186693906784058\n",
      "\n",
      "episode 16, val func loss 1.2621210813522339\n",
      "\n",
      "Val func train loss in epoch 4:1.273979790508747\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.162668228149414\n",
      "\n",
      "episode 2, val func loss 1.1651214361190796\n",
      "\n",
      "episode 3, val func loss 1.199021816253662\n",
      "\n",
      "episode 4, val func loss 1.2074140310287476\n",
      "\n",
      "episode 5, val func loss 1.2661806344985962\n",
      "\n",
      "episode 6, val func loss 1.185683250427246\n",
      "\n",
      "episode 7, val func loss 1.3274996280670166\n",
      "\n",
      "episode 8, val func loss 1.2487353086471558\n",
      "\n",
      "episode 9, val func loss 1.1443110704421997\n",
      "\n",
      "episode 10, val func loss 1.356325387954712\n",
      "\n",
      "episode 11, val func loss 1.2597769498825073\n",
      "\n",
      "episode 12, val func loss 1.329756259918213\n",
      "\n",
      "episode 13, val func loss 1.25814950466156\n",
      "\n",
      "episode 14, val func loss 1.1567364931106567\n",
      "\n",
      "episode 15, val func loss 1.2220581769943237\n",
      "\n",
      "episode 16, val func loss 1.311208724975586\n",
      "\n",
      "Val func train loss in epoch 5:1.2375404313206673\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.3508771657943726\n",
      "\n",
      "episode 2, val func loss 1.4402990341186523\n",
      "\n",
      "episode 3, val func loss 1.3009611368179321\n",
      "\n",
      "episode 4, val func loss 1.2901033163070679\n",
      "\n",
      "episode 5, val func loss 1.3347529172897339\n",
      "\n",
      "episode 6, val func loss 1.096433401107788\n",
      "\n",
      "episode 7, val func loss 1.3556934595108032\n",
      "\n",
      "episode 8, val func loss 1.2650853395462036\n",
      "\n",
      "episode 9, val func loss 1.3883476257324219\n",
      "\n",
      "episode 10, val func loss 1.0402730703353882\n",
      "\n",
      "episode 11, val func loss 1.334986686706543\n",
      "\n",
      "episode 12, val func loss 1.1691874265670776\n",
      "\n",
      "episode 13, val func loss 1.2552411556243896\n",
      "\n",
      "episode 14, val func loss 1.3748927116394043\n",
      "\n",
      "episode 15, val func loss 1.3236280679702759\n",
      "\n",
      "episode 16, val func loss 1.1381402015686035\n",
      "\n",
      "Val func train loss in epoch 6:1.278681419789791\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.2031447887420654\n",
      "\n",
      "episode 2, val func loss 1.367087483406067\n",
      "\n",
      "episode 3, val func loss 1.253163456916809\n",
      "\n",
      "episode 4, val func loss 1.0999624729156494\n",
      "\n",
      "episode 5, val func loss 1.187900185585022\n",
      "\n",
      "episode 6, val func loss 1.1469100713729858\n",
      "\n",
      "episode 7, val func loss 1.268512487411499\n",
      "\n",
      "episode 8, val func loss 1.262080430984497\n",
      "\n",
      "episode 9, val func loss 1.0926234722137451\n",
      "\n",
      "episode 10, val func loss 1.202354907989502\n",
      "\n",
      "episode 11, val func loss 1.2320387363433838\n",
      "\n",
      "episode 12, val func loss 1.218315601348877\n",
      "\n",
      "episode 13, val func loss 1.1818642616271973\n",
      "\n",
      "episode 14, val func loss 1.1820248365402222\n",
      "\n",
      "episode 15, val func loss 1.2250479459762573\n",
      "\n",
      "episode 16, val func loss 1.1379529237747192\n",
      "\n",
      "Val func train loss in epoch 7:1.2038115039467812\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.2630488872528076\n",
      "\n",
      "episode 2, val func loss 1.1731040477752686\n",
      "\n",
      "episode 3, val func loss 1.2486909627914429\n",
      "\n",
      "episode 4, val func loss 1.2224308252334595\n",
      "\n",
      "episode 5, val func loss 1.3990511894226074\n",
      "\n",
      "episode 6, val func loss 1.3667446374893188\n",
      "\n",
      "episode 7, val func loss 1.1759217977523804\n",
      "\n",
      "episode 8, val func loss 1.276726245880127\n",
      "\n",
      "episode 9, val func loss 1.2331987619400024\n",
      "\n",
      "episode 10, val func loss 1.2044316530227661\n",
      "\n",
      "episode 11, val func loss 1.14434015750885\n",
      "\n",
      "episode 12, val func loss 1.1474889516830444\n",
      "\n",
      "episode 13, val func loss 1.2545459270477295\n",
      "\n",
      "episode 14, val func loss 1.365803837776184\n",
      "\n",
      "episode 15, val func loss 1.2217602729797363\n",
      "\n",
      "episode 16, val func loss 1.2321857213974\n",
      "\n",
      "Val func train loss in epoch 8:1.2455921173095703\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.3400073051452637\n",
      "\n",
      "episode 2, val func loss 1.2381495237350464\n",
      "\n",
      "episode 3, val func loss 1.142815351486206\n",
      "\n",
      "episode 4, val func loss 1.2855414152145386\n",
      "\n",
      "episode 5, val func loss 1.1261647939682007\n",
      "\n",
      "episode 6, val func loss 1.3579007387161255\n",
      "\n",
      "episode 7, val func loss 1.3956793546676636\n",
      "\n",
      "episode 8, val func loss 1.211654543876648\n",
      "\n",
      "episode 9, val func loss 1.4787229299545288\n",
      "\n",
      "episode 10, val func loss 1.078811764717102\n",
      "\n",
      "episode 11, val func loss 1.189652442932129\n",
      "\n",
      "episode 12, val func loss 1.4606411457061768\n",
      "\n",
      "episode 13, val func loss 1.4184869527816772\n",
      "\n",
      "episode 14, val func loss 1.3141448497772217\n",
      "\n",
      "episode 15, val func loss 1.1551109552383423\n",
      "\n",
      "episode 16, val func loss 1.2442761659622192\n",
      "\n",
      "Val func train loss in epoch 9:1.277360014617443\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.3773952722549438\n",
      "\n",
      "episode 2, val func loss 1.247897982597351\n",
      "\n",
      "episode 3, val func loss 1.350239872932434\n",
      "\n",
      "episode 4, val func loss 1.2399754524230957\n",
      "\n",
      "episode 5, val func loss 1.0973085165023804\n",
      "\n",
      "episode 6, val func loss 1.2284072637557983\n",
      "\n",
      "episode 7, val func loss 1.2456588745117188\n",
      "\n",
      "episode 8, val func loss 1.2981690168380737\n",
      "\n",
      "episode 9, val func loss 1.274384617805481\n",
      "\n",
      "episode 10, val func loss 1.1827723979949951\n",
      "\n",
      "episode 11, val func loss 1.5087153911590576\n",
      "\n",
      "episode 12, val func loss 1.441079020500183\n",
      "\n",
      "episode 13, val func loss 1.1701242923736572\n",
      "\n",
      "episode 14, val func loss 1.5513070821762085\n",
      "\n",
      "episode 15, val func loss 1.2766472101211548\n",
      "\n",
      "episode 16, val func loss 1.2385936975479126\n",
      "\n",
      "Val func train loss in epoch 10:1.2955422475934029\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.2443969249725342\n",
      "\n",
      "episode 2, val func loss 1.349568486213684\n",
      "\n",
      "episode 3, val func loss 1.3534268140792847\n",
      "\n",
      "episode 4, val func loss 1.2123101949691772\n",
      "\n",
      "episode 5, val func loss 1.4255430698394775\n",
      "\n",
      "episode 6, val func loss 1.3212366104125977\n",
      "\n",
      "episode 7, val func loss 1.323531985282898\n",
      "\n",
      "episode 8, val func loss 1.1624681949615479\n",
      "\n",
      "episode 9, val func loss 1.339990258216858\n",
      "\n",
      "episode 10, val func loss 1.296102523803711\n",
      "\n",
      "episode 11, val func loss 1.2957537174224854\n",
      "\n",
      "episode 12, val func loss 1.3735331296920776\n",
      "\n",
      "episode 13, val func loss 1.2975679636001587\n",
      "\n",
      "episode 14, val func loss 1.139668583869934\n",
      "\n",
      "episode 15, val func loss 1.2239404916763306\n",
      "\n",
      "episode 16, val func loss 1.1918762922286987\n",
      "\n",
      "Val func train loss in epoch 11:1.284432202577591\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.2635715007781982\n",
      "\n",
      "episode 2, val func loss 1.2432904243469238\n",
      "\n",
      "episode 3, val func loss 1.2191946506500244\n",
      "\n",
      "episode 4, val func loss 1.125390887260437\n",
      "\n",
      "episode 5, val func loss 1.2482990026474\n",
      "\n",
      "episode 6, val func loss 1.306358814239502\n",
      "\n",
      "episode 7, val func loss 1.3576685190200806\n",
      "\n",
      "episode 8, val func loss 1.3035030364990234\n",
      "\n",
      "episode 9, val func loss 1.4690101146697998\n",
      "\n",
      "episode 10, val func loss 1.175767421722412\n",
      "\n",
      "episode 11, val func loss 1.4731156826019287\n",
      "\n",
      "episode 12, val func loss 1.2116338014602661\n",
      "\n",
      "episode 13, val func loss 1.2934327125549316\n",
      "\n",
      "episode 14, val func loss 1.0913597345352173\n",
      "\n",
      "episode 15, val func loss 1.1791236400604248\n",
      "\n",
      "episode 16, val func loss 1.2107081413269043\n",
      "\n",
      "Val func train loss in epoch 12:1.2607142552733421\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.3314567804336548\n",
      "\n",
      "episode 2, val func loss 1.0865927934646606\n",
      "\n",
      "episode 3, val func loss 1.349833369255066\n",
      "\n",
      "episode 4, val func loss 1.2027812004089355\n",
      "\n",
      "episode 5, val func loss 1.2934848070144653\n",
      "\n",
      "episode 6, val func loss 1.1255160570144653\n",
      "\n",
      "episode 7, val func loss 1.1045444011688232\n",
      "\n",
      "episode 8, val func loss 1.304801106452942\n",
      "\n",
      "episode 9, val func loss 1.3650074005126953\n",
      "\n",
      "episode 10, val func loss 1.2504830360412598\n",
      "\n",
      "episode 11, val func loss 1.1555664539337158\n",
      "\n",
      "episode 12, val func loss 1.0305646657943726\n",
      "\n",
      "episode 13, val func loss 1.2870690822601318\n",
      "\n",
      "episode 14, val func loss 1.3054344654083252\n",
      "\n",
      "episode 15, val func loss 1.29691743850708\n",
      "\n",
      "episode 16, val func loss 1.2190486192703247\n",
      "\n",
      "Val func train loss in epoch 13:1.2318188548088074\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.304134726524353\n",
      "\n",
      "episode 2, val func loss 1.1646572351455688\n",
      "\n",
      "episode 3, val func loss 1.1215119361877441\n",
      "\n",
      "episode 4, val func loss 1.1608004570007324\n",
      "\n",
      "episode 5, val func loss 1.3320859670639038\n",
      "\n",
      "episode 6, val func loss 1.2941391468048096\n",
      "\n",
      "episode 7, val func loss 1.210167407989502\n",
      "\n",
      "episode 8, val func loss 1.1581777334213257\n",
      "\n",
      "episode 9, val func loss 1.2771694660186768\n",
      "\n",
      "episode 10, val func loss 1.3747478723526\n",
      "\n",
      "episode 11, val func loss 1.0374107360839844\n",
      "\n",
      "episode 12, val func loss 1.1546005010604858\n",
      "\n",
      "episode 13, val func loss 1.093821406364441\n",
      "\n",
      "episode 14, val func loss 1.332265019416809\n",
      "\n",
      "episode 15, val func loss 1.2152022123336792\n",
      "\n",
      "episode 16, val func loss 1.1485545635223389\n",
      "\n",
      "Val func train loss in epoch 14:1.2112153992056847\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.2640968561172485\n",
      "\n",
      "episode 2, val func loss 1.4515233039855957\n",
      "\n",
      "episode 3, val func loss 1.1937137842178345\n",
      "\n",
      "episode 4, val func loss 1.2330962419509888\n",
      "\n",
      "episode 5, val func loss 1.1283386945724487\n",
      "\n",
      "episode 6, val func loss 1.212267518043518\n",
      "\n",
      "episode 7, val func loss 1.3338514566421509\n",
      "\n",
      "episode 8, val func loss 1.246685266494751\n",
      "\n",
      "episode 9, val func loss 1.0815881490707397\n",
      "\n",
      "episode 10, val func loss 1.10353422164917\n",
      "\n",
      "episode 11, val func loss 0.9349653720855713\n",
      "\n",
      "episode 12, val func loss 1.2768326997756958\n",
      "\n",
      "episode 13, val func loss 1.186231255531311\n",
      "\n",
      "episode 14, val func loss 1.154615044593811\n",
      "\n",
      "episode 15, val func loss 1.1437957286834717\n",
      "\n",
      "episode 16, val func loss 1.2161962985992432\n",
      "\n",
      "Val func train loss in epoch 15:1.1975832432508469\n",
      "***********************TIME WAS 4.848527872562409 min*****************************\n",
      "\n",
      "**********************ROUND 73 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.355807065963745\n",
      "\n",
      "episode 2, policy loss -3.355807065963745\n",
      "\n",
      "episode 3, policy loss -3.355807065963745\n",
      "\n",
      "episode 4, policy loss -3.355806589126587\n",
      "\n",
      "episode 5, policy loss -3.355806589126587\n",
      "\n",
      "episode 6, policy loss -3.355806589126587\n",
      "\n",
      "episode 7, policy loss -3.355806589126587\n",
      "\n",
      "episode 8, policy loss -3.355807065963745\n",
      "\n",
      "episode 9, policy loss -3.355806589126587\n",
      "\n",
      "episode 10, policy loss -3.355806589126587\n",
      "\n",
      "episode 11, policy loss -3.355806589126587\n",
      "\n",
      "episode 12, policy loss -3.355806589126587\n",
      "\n",
      "episode 13, policy loss -3.355807065963745\n",
      "\n",
      "episode 14, policy loss -3.355806589126587\n",
      "\n",
      "episode 15, policy loss -3.355807065963745\n",
      "\n",
      "episode 16, policy loss -3.355807065963745\n",
      "\n",
      "Policy train loss in epoch 0:-3.3558067977428436\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.355807065963745\n",
      "\n",
      "episode 2, policy loss -3.355807065963745\n",
      "\n",
      "episode 3, policy loss -3.355807065963745\n",
      "\n",
      "episode 4, policy loss -3.355807065963745\n",
      "\n",
      "episode 5, policy loss -3.355807065963745\n",
      "\n",
      "episode 6, policy loss -3.355807065963745\n",
      "\n",
      "episode 7, policy loss -3.355807065963745\n",
      "\n",
      "episode 8, policy loss -3.355807065963745\n",
      "\n",
      "episode 9, policy loss -3.355806589126587\n",
      "\n",
      "episode 10, policy loss -3.355807065963745\n",
      "\n",
      "episode 11, policy loss -3.355807065963745\n",
      "\n",
      "episode 12, policy loss -3.355807065963745\n",
      "\n",
      "episode 13, policy loss -3.355807065963745\n",
      "\n",
      "episode 14, policy loss -3.355807065963745\n",
      "\n",
      "episode 15, policy loss -3.355806589126587\n",
      "\n",
      "episode 16, policy loss -3.355807065963745\n",
      "\n",
      "Policy train loss in epoch 1:-3.3558070063591003\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.355806589126587\n",
      "\n",
      "episode 2, policy loss -3.355807065963745\n",
      "\n",
      "episode 3, policy loss -3.355807065963745\n",
      "\n",
      "episode 4, policy loss -3.355807065963745\n",
      "\n",
      "episode 5, policy loss -3.355807065963745\n",
      "\n",
      "episode 6, policy loss -3.355807065963745\n",
      "\n",
      "episode 7, policy loss -3.355807065963745\n",
      "\n",
      "episode 8, policy loss -3.355807065963745\n",
      "\n",
      "episode 9, policy loss -3.355806589126587\n",
      "\n",
      "episode 10, policy loss -3.355807065963745\n",
      "\n",
      "episode 11, policy loss -3.355806589126587\n",
      "\n",
      "episode 12, policy loss -3.355807065963745\n",
      "\n",
      "episode 13, policy loss -3.355807065963745\n",
      "\n",
      "episode 14, policy loss -3.355807065963745\n",
      "\n",
      "episode 15, policy loss -3.355807065963745\n",
      "\n",
      "episode 16, policy loss -3.355807065963745\n",
      "\n",
      "Policy train loss in epoch 2:-3.355806976556778\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.355807065963745\n",
      "\n",
      "episode 2, policy loss -3.355807065963745\n",
      "\n",
      "episode 3, policy loss -3.355807065963745\n",
      "\n",
      "episode 4, policy loss -3.355807065963745\n",
      "\n",
      "episode 5, policy loss -3.355807065963745\n",
      "\n",
      "episode 6, policy loss -3.355807065963745\n",
      "\n",
      "episode 7, policy loss -3.355806589126587\n",
      "\n",
      "episode 8, policy loss -3.355807065963745\n",
      "\n",
      "episode 9, policy loss -3.355806589126587\n",
      "\n",
      "episode 10, policy loss -3.355807065963745\n",
      "\n",
      "episode 11, policy loss -3.355807065963745\n",
      "\n",
      "episode 12, policy loss -3.355806589126587\n",
      "\n",
      "episode 13, policy loss -3.355806589126587\n",
      "\n",
      "episode 14, policy loss -3.355807065963745\n",
      "\n",
      "episode 15, policy loss -3.355807065963745\n",
      "\n",
      "episode 16, policy loss -3.355807065963745\n",
      "\n",
      "Policy train loss in epoch 3:-3.3558069467544556\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.1961541175842285\n",
      "\n",
      "episode 2, val func loss 1.1664618253707886\n",
      "\n",
      "episode 3, val func loss 1.3515076637268066\n",
      "\n",
      "episode 4, val func loss 1.1525603532791138\n",
      "\n",
      "episode 5, val func loss 1.341078519821167\n",
      "\n",
      "episode 6, val func loss 1.2850496768951416\n",
      "\n",
      "episode 7, val func loss 1.3419867753982544\n",
      "\n",
      "episode 8, val func loss 1.285950779914856\n",
      "\n",
      "episode 9, val func loss 1.1929751634597778\n",
      "\n",
      "episode 10, val func loss 1.1763038635253906\n",
      "\n",
      "episode 11, val func loss 1.3301671743392944\n",
      "\n",
      "episode 12, val func loss 1.247591495513916\n",
      "\n",
      "episode 13, val func loss 1.1571117639541626\n",
      "\n",
      "episode 14, val func loss 1.1263848543167114\n",
      "\n",
      "episode 15, val func loss 1.1303480863571167\n",
      "\n",
      "episode 16, val func loss 1.2963837385177612\n",
      "\n",
      "Val func train loss in epoch 0:1.2361259907484055\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.2378607988357544\n",
      "\n",
      "episode 2, val func loss 1.0920735597610474\n",
      "\n",
      "episode 3, val func loss 1.3633168935775757\n",
      "\n",
      "episode 4, val func loss 1.0781725645065308\n",
      "\n",
      "episode 5, val func loss 1.4088550806045532\n",
      "\n",
      "episode 6, val func loss 1.3240824937820435\n",
      "\n",
      "episode 7, val func loss 1.2847836017608643\n",
      "\n",
      "episode 8, val func loss 1.3115520477294922\n",
      "\n",
      "episode 9, val func loss 1.3600122928619385\n",
      "\n",
      "episode 10, val func loss 1.3437583446502686\n",
      "\n",
      "episode 11, val func loss 1.1164634227752686\n",
      "\n",
      "episode 12, val func loss 1.19041109085083\n",
      "\n",
      "episode 13, val func loss 1.2137333154678345\n",
      "\n",
      "episode 14, val func loss 1.3132896423339844\n",
      "\n",
      "episode 15, val func loss 1.2219414710998535\n",
      "\n",
      "episode 16, val func loss 1.1635240316390991\n",
      "\n",
      "Val func train loss in epoch 1:1.2514894157648087\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.220275640487671\n",
      "\n",
      "episode 2, val func loss 1.1627751588821411\n",
      "\n",
      "episode 3, val func loss 1.509299874305725\n",
      "\n",
      "episode 4, val func loss 1.320088267326355\n",
      "\n",
      "episode 5, val func loss 1.3213683366775513\n",
      "\n",
      "episode 6, val func loss 1.1621458530426025\n",
      "\n",
      "episode 7, val func loss 1.467578411102295\n",
      "\n",
      "episode 8, val func loss 1.2749322652816772\n",
      "\n",
      "episode 9, val func loss 1.0310648679733276\n",
      "\n",
      "episode 10, val func loss 1.2693870067596436\n",
      "\n",
      "episode 11, val func loss 1.0902748107910156\n",
      "\n",
      "episode 12, val func loss 1.3208849430084229\n",
      "\n",
      "episode 13, val func loss 1.2087733745574951\n",
      "\n",
      "episode 14, val func loss 1.2123610973358154\n",
      "\n",
      "episode 15, val func loss 1.3085424900054932\n",
      "\n",
      "episode 16, val func loss 1.1856294870376587\n",
      "\n",
      "Val func train loss in epoch 2:1.2540863677859306\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.2963727712631226\n",
      "\n",
      "episode 2, val func loss 1.1119637489318848\n",
      "\n",
      "episode 3, val func loss 1.1223629713058472\n",
      "\n",
      "episode 4, val func loss 1.3216471672058105\n",
      "\n",
      "episode 5, val func loss 1.17717444896698\n",
      "\n",
      "episode 6, val func loss 1.3983412981033325\n",
      "\n",
      "episode 7, val func loss 1.3046138286590576\n",
      "\n",
      "episode 8, val func loss 1.3470360040664673\n",
      "\n",
      "episode 9, val func loss 1.281387209892273\n",
      "\n",
      "episode 10, val func loss 1.2088568210601807\n",
      "\n",
      "episode 11, val func loss 1.285422921180725\n",
      "\n",
      "episode 12, val func loss 1.2209768295288086\n",
      "\n",
      "episode 13, val func loss 1.2219834327697754\n",
      "\n",
      "episode 14, val func loss 1.2484393119812012\n",
      "\n",
      "episode 15, val func loss 1.2371934652328491\n",
      "\n",
      "episode 16, val func loss 1.144374132156372\n",
      "\n",
      "Val func train loss in epoch 3:1.245509147644043\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.209728717803955\n",
      "\n",
      "episode 2, val func loss 1.2006891965866089\n",
      "\n",
      "episode 3, val func loss 1.252055287361145\n",
      "\n",
      "episode 4, val func loss 1.2369924783706665\n",
      "\n",
      "episode 5, val func loss 1.085163950920105\n",
      "\n",
      "episode 6, val func loss 1.2246443033218384\n",
      "\n",
      "episode 7, val func loss 1.1818732023239136\n",
      "\n",
      "episode 8, val func loss 1.2906185388565063\n",
      "\n",
      "episode 9, val func loss 1.141324520111084\n",
      "\n",
      "episode 10, val func loss 1.1821434497833252\n",
      "\n",
      "episode 11, val func loss 1.2116557359695435\n",
      "\n",
      "episode 12, val func loss 1.2563695907592773\n",
      "\n",
      "episode 13, val func loss 1.390565037727356\n",
      "\n",
      "episode 14, val func loss 0.9874008893966675\n",
      "\n",
      "episode 15, val func loss 1.2244983911514282\n",
      "\n",
      "episode 16, val func loss 1.2072670459747314\n",
      "\n",
      "Val func train loss in epoch 4:1.2051868960261345\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.183756947517395\n",
      "\n",
      "episode 2, val func loss 1.28664231300354\n",
      "\n",
      "episode 3, val func loss 1.4159841537475586\n",
      "\n",
      "episode 4, val func loss 1.2476950883865356\n",
      "\n",
      "episode 5, val func loss 1.1800838708877563\n",
      "\n",
      "episode 6, val func loss 1.3349053859710693\n",
      "\n",
      "episode 7, val func loss 1.210465669631958\n",
      "\n",
      "episode 8, val func loss 1.0163532495498657\n",
      "\n",
      "episode 9, val func loss 1.3440669775009155\n",
      "\n",
      "episode 10, val func loss 1.0609685182571411\n",
      "\n",
      "episode 11, val func loss 1.1657694578170776\n",
      "\n",
      "episode 12, val func loss 1.2197084426879883\n",
      "\n",
      "episode 13, val func loss 1.1039825677871704\n",
      "\n",
      "episode 14, val func loss 1.1866999864578247\n",
      "\n",
      "episode 15, val func loss 1.3597691059112549\n",
      "\n",
      "episode 16, val func loss 1.4151599407196045\n",
      "\n",
      "Val func train loss in epoch 5:1.233250729739666\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.162336826324463\n",
      "\n",
      "episode 2, val func loss 1.0946056842803955\n",
      "\n",
      "episode 3, val func loss 1.235853672027588\n",
      "\n",
      "episode 4, val func loss 1.2105982303619385\n",
      "\n",
      "episode 5, val func loss 1.2051504850387573\n",
      "\n",
      "episode 6, val func loss 1.0536448955535889\n",
      "\n",
      "episode 7, val func loss 1.2889341115951538\n",
      "\n",
      "episode 8, val func loss 1.1075761318206787\n",
      "\n",
      "episode 9, val func loss 1.1829631328582764\n",
      "\n",
      "episode 10, val func loss 1.1039589643478394\n",
      "\n",
      "episode 11, val func loss 1.0377358198165894\n",
      "\n",
      "episode 12, val func loss 1.2092434167861938\n",
      "\n",
      "episode 13, val func loss 1.4498320817947388\n",
      "\n",
      "episode 14, val func loss 1.400701642036438\n",
      "\n",
      "episode 15, val func loss 1.3779934644699097\n",
      "\n",
      "episode 16, val func loss 1.025924563407898\n",
      "\n",
      "Val func train loss in epoch 6:1.196690820157528\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.3082588911056519\n",
      "\n",
      "episode 2, val func loss 1.3309236764907837\n",
      "\n",
      "episode 3, val func loss 1.1542894840240479\n",
      "\n",
      "episode 4, val func loss 1.1094462871551514\n",
      "\n",
      "episode 5, val func loss 1.2222144603729248\n",
      "\n",
      "episode 6, val func loss 1.2392828464508057\n",
      "\n",
      "episode 7, val func loss 1.3102741241455078\n",
      "\n",
      "episode 8, val func loss 1.3161392211914062\n",
      "\n",
      "episode 9, val func loss 1.329033374786377\n",
      "\n",
      "episode 10, val func loss 1.2399837970733643\n",
      "\n",
      "episode 11, val func loss 1.3195067644119263\n",
      "\n",
      "episode 12, val func loss 1.2662968635559082\n",
      "\n",
      "episode 13, val func loss 1.3371270895004272\n",
      "\n",
      "episode 14, val func loss 1.2416282892227173\n",
      "\n",
      "episode 15, val func loss 1.152133584022522\n",
      "\n",
      "episode 16, val func loss 1.246200442314148\n",
      "\n",
      "Val func train loss in epoch 7:1.2576711997389793\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.125905156135559\n",
      "\n",
      "episode 2, val func loss 1.2650318145751953\n",
      "\n",
      "episode 3, val func loss 1.3163394927978516\n",
      "\n",
      "episode 4, val func loss 1.2639601230621338\n",
      "\n",
      "episode 5, val func loss 1.206739068031311\n",
      "\n",
      "episode 6, val func loss 1.2149513959884644\n",
      "\n",
      "episode 7, val func loss 1.1382415294647217\n",
      "\n",
      "episode 8, val func loss 1.1425906419754028\n",
      "\n",
      "episode 9, val func loss 1.32346773147583\n",
      "\n",
      "episode 10, val func loss 1.1620073318481445\n",
      "\n",
      "episode 11, val func loss 1.2046101093292236\n",
      "\n",
      "episode 12, val func loss 1.1481133699417114\n",
      "\n",
      "episode 13, val func loss 1.1119177341461182\n",
      "\n",
      "episode 14, val func loss 1.1372085809707642\n",
      "\n",
      "episode 15, val func loss 1.0762299299240112\n",
      "\n",
      "episode 16, val func loss 1.2496228218078613\n",
      "\n",
      "Val func train loss in epoch 8:1.192933551967144\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.2285792827606201\n",
      "\n",
      "episode 2, val func loss 1.198253870010376\n",
      "\n",
      "episode 3, val func loss 1.1685160398483276\n",
      "\n",
      "episode 4, val func loss 1.2091939449310303\n",
      "\n",
      "episode 5, val func loss 1.3727377653121948\n",
      "\n",
      "episode 6, val func loss 1.2502341270446777\n",
      "\n",
      "episode 7, val func loss 1.290152907371521\n",
      "\n",
      "episode 8, val func loss 1.2644996643066406\n",
      "\n",
      "episode 9, val func loss 1.2138493061065674\n",
      "\n",
      "episode 10, val func loss 1.159753680229187\n",
      "\n",
      "episode 11, val func loss 1.361659049987793\n",
      "\n",
      "episode 12, val func loss 1.313764214515686\n",
      "\n",
      "episode 13, val func loss 1.3520965576171875\n",
      "\n",
      "episode 14, val func loss 1.1286836862564087\n",
      "\n",
      "episode 15, val func loss 1.2543325424194336\n",
      "\n",
      "episode 16, val func loss 1.2060991525650024\n",
      "\n",
      "Val func train loss in epoch 9:1.2482753619551659\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.1335110664367676\n",
      "\n",
      "episode 2, val func loss 1.2963323593139648\n",
      "\n",
      "episode 3, val func loss 1.3411126136779785\n",
      "\n",
      "episode 4, val func loss 0.9994620084762573\n",
      "\n",
      "episode 5, val func loss 1.1849526166915894\n",
      "\n",
      "episode 6, val func loss 1.1424224376678467\n",
      "\n",
      "episode 7, val func loss 1.1792289018630981\n",
      "\n",
      "episode 8, val func loss 1.128166913986206\n",
      "\n",
      "episode 9, val func loss 1.2980149984359741\n",
      "\n",
      "episode 10, val func loss 1.428114891052246\n",
      "\n",
      "episode 11, val func loss 1.1073545217514038\n",
      "\n",
      "episode 12, val func loss 1.2483350038528442\n",
      "\n",
      "episode 13, val func loss 1.256004810333252\n",
      "\n",
      "episode 14, val func loss 0.9893843531608582\n",
      "\n",
      "episode 15, val func loss 1.2745410203933716\n",
      "\n",
      "episode 16, val func loss 1.3553372621536255\n",
      "\n",
      "Val func train loss in epoch 10:1.2101422362029552\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.3254886865615845\n",
      "\n",
      "episode 2, val func loss 1.0931460857391357\n",
      "\n",
      "episode 3, val func loss 1.165963053703308\n",
      "\n",
      "episode 4, val func loss 1.2375408411026\n",
      "\n",
      "episode 5, val func loss 1.1273167133331299\n",
      "\n",
      "episode 6, val func loss 1.2774908542633057\n",
      "\n",
      "episode 7, val func loss 1.3072636127471924\n",
      "\n",
      "episode 8, val func loss 1.2644948959350586\n",
      "\n",
      "episode 9, val func loss 1.3166948556900024\n",
      "\n",
      "episode 10, val func loss 0.9519283771514893\n",
      "\n",
      "episode 11, val func loss 1.140587329864502\n",
      "\n",
      "episode 12, val func loss 1.2495222091674805\n",
      "\n",
      "episode 13, val func loss 1.2835654020309448\n",
      "\n",
      "episode 14, val func loss 1.1841977834701538\n",
      "\n",
      "episode 15, val func loss 1.2383936643600464\n",
      "\n",
      "episode 16, val func loss 1.31071937084198\n",
      "\n",
      "Val func train loss in epoch 11:1.2171446084976196\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.1274175643920898\n",
      "\n",
      "episode 2, val func loss 1.2328200340270996\n",
      "\n",
      "episode 3, val func loss 1.1079074144363403\n",
      "\n",
      "episode 4, val func loss 1.1859920024871826\n",
      "\n",
      "episode 5, val func loss 1.0300660133361816\n",
      "\n",
      "episode 6, val func loss 1.0962151288986206\n",
      "\n",
      "episode 7, val func loss 1.3652628660202026\n",
      "\n",
      "episode 8, val func loss 1.152354121208191\n",
      "\n",
      "episode 9, val func loss 1.3337892293930054\n",
      "\n",
      "episode 10, val func loss 1.2893186807632446\n",
      "\n",
      "episode 11, val func loss 1.1927884817123413\n",
      "\n",
      "episode 12, val func loss 1.4560325145721436\n",
      "\n",
      "episode 13, val func loss 1.406101107597351\n",
      "\n",
      "episode 14, val func loss 1.2148520946502686\n",
      "\n",
      "episode 15, val func loss 1.1553640365600586\n",
      "\n",
      "episode 16, val func loss 1.2123581171035767\n",
      "\n",
      "Val func train loss in epoch 12:1.2224149629473686\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.296095848083496\n",
      "\n",
      "episode 2, val func loss 1.376213788986206\n",
      "\n",
      "episode 3, val func loss 1.090577244758606\n",
      "\n",
      "episode 4, val func loss 1.218005895614624\n",
      "\n",
      "episode 5, val func loss 1.2023818492889404\n",
      "\n",
      "episode 6, val func loss 1.4175158739089966\n",
      "\n",
      "episode 7, val func loss 1.1810860633850098\n",
      "\n",
      "episode 8, val func loss 1.0551024675369263\n",
      "\n",
      "episode 9, val func loss 1.260818362236023\n",
      "\n",
      "episode 10, val func loss 1.2306956052780151\n",
      "\n",
      "episode 11, val func loss 1.0748543739318848\n",
      "\n",
      "episode 12, val func loss 1.3616390228271484\n",
      "\n",
      "episode 13, val func loss 1.3197462558746338\n",
      "\n",
      "episode 14, val func loss 1.3095206022262573\n",
      "\n",
      "episode 15, val func loss 1.0384397506713867\n",
      "\n",
      "episode 16, val func loss 1.26048743724823\n",
      "\n",
      "Val func train loss in epoch 13:1.230823777616024\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.4461952447891235\n",
      "\n",
      "episode 2, val func loss 1.3497458696365356\n",
      "\n",
      "episode 3, val func loss 1.1880093812942505\n",
      "\n",
      "episode 4, val func loss 1.3017733097076416\n",
      "\n",
      "episode 5, val func loss 1.2479180097579956\n",
      "\n",
      "episode 6, val func loss 1.1437007188796997\n",
      "\n",
      "episode 7, val func loss 1.3814181089401245\n",
      "\n",
      "episode 8, val func loss 1.2456873655319214\n",
      "\n",
      "episode 9, val func loss 1.1780130863189697\n",
      "\n",
      "episode 10, val func loss 1.1013058423995972\n",
      "\n",
      "episode 11, val func loss 1.2361781597137451\n",
      "\n",
      "episode 12, val func loss 1.2702289819717407\n",
      "\n",
      "episode 13, val func loss 1.1239858865737915\n",
      "\n",
      "episode 14, val func loss 1.3006747961044312\n",
      "\n",
      "episode 15, val func loss 1.3329277038574219\n",
      "\n",
      "episode 16, val func loss 1.265049695968628\n",
      "\n",
      "Val func train loss in epoch 14:1.257050760090351\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.4824668169021606\n",
      "\n",
      "episode 2, val func loss 1.1628899574279785\n",
      "\n",
      "episode 3, val func loss 1.5276060104370117\n",
      "\n",
      "episode 4, val func loss 1.3220411539077759\n",
      "\n",
      "episode 5, val func loss 1.281313180923462\n",
      "\n",
      "episode 6, val func loss 1.1957402229309082\n",
      "\n",
      "episode 7, val func loss 1.1078011989593506\n",
      "\n",
      "episode 8, val func loss 1.5631173849105835\n",
      "\n",
      "episode 9, val func loss 1.410414695739746\n",
      "\n",
      "episode 10, val func loss 1.2369054555892944\n",
      "\n",
      "episode 11, val func loss 1.090247631072998\n",
      "\n",
      "episode 12, val func loss 1.159302830696106\n",
      "\n",
      "episode 13, val func loss 1.5161892175674438\n",
      "\n",
      "episode 14, val func loss 1.2679835557937622\n",
      "\n",
      "episode 15, val func loss 1.3490006923675537\n",
      "\n",
      "episode 16, val func loss 1.2554867267608643\n",
      "\n",
      "Val func train loss in epoch 15:1.3080316707491875\n",
      "***********************TIME WAS 4.8528189619382225 min*****************************\n",
      "\n",
      "**********************ROUND 74 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.3462417125701904\n",
      "\n",
      "episode 2, policy loss -3.3462417125701904\n",
      "\n",
      "episode 3, policy loss -3.3462414741516113\n",
      "\n",
      "episode 4, policy loss -3.3462417125701904\n",
      "\n",
      "episode 5, policy loss -3.3462414741516113\n",
      "\n",
      "episode 6, policy loss -3.3462417125701904\n",
      "\n",
      "episode 7, policy loss -3.3462417125701904\n",
      "\n",
      "episode 8, policy loss -3.3462417125701904\n",
      "\n",
      "episode 9, policy loss -3.3462417125701904\n",
      "\n",
      "episode 10, policy loss -3.3462417125701904\n",
      "\n",
      "episode 11, policy loss -3.3462414741516113\n",
      "\n",
      "episode 12, policy loss -3.3462417125701904\n",
      "\n",
      "episode 13, policy loss -3.3462414741516113\n",
      "\n",
      "episode 14, policy loss -3.3462414741516113\n",
      "\n",
      "episode 15, policy loss -3.3462417125701904\n",
      "\n",
      "episode 16, policy loss -3.3462414741516113\n",
      "\n",
      "Policy train loss in epoch 0:-3.3462416231632233\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.3462417125701904\n",
      "\n",
      "episode 2, policy loss -3.3462417125701904\n",
      "\n",
      "episode 3, policy loss -3.3462414741516113\n",
      "\n",
      "episode 4, policy loss -3.3462417125701904\n",
      "\n",
      "episode 5, policy loss -3.3462417125701904\n",
      "\n",
      "episode 6, policy loss -3.3462417125701904\n",
      "\n",
      "episode 7, policy loss -3.3462414741516113\n",
      "\n",
      "episode 8, policy loss -3.3462417125701904\n",
      "\n",
      "episode 9, policy loss -3.3462417125701904\n",
      "\n",
      "episode 10, policy loss -3.3462417125701904\n",
      "\n",
      "episode 11, policy loss -3.3462417125701904\n",
      "\n",
      "episode 12, policy loss -3.3462417125701904\n",
      "\n",
      "episode 13, policy loss -3.3462414741516113\n",
      "\n",
      "episode 14, policy loss -3.3462417125701904\n",
      "\n",
      "episode 15, policy loss -3.3462414741516113\n",
      "\n",
      "episode 16, policy loss -3.3462417125701904\n",
      "\n",
      "Policy train loss in epoch 1:-3.3462416529655457\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.3462414741516113\n",
      "\n",
      "episode 2, policy loss -3.3462417125701904\n",
      "\n",
      "episode 3, policy loss -3.3462417125701904\n",
      "\n",
      "episode 4, policy loss -3.3462414741516113\n",
      "\n",
      "episode 5, policy loss -3.3462414741516113\n",
      "\n",
      "episode 6, policy loss -3.3462417125701904\n",
      "\n",
      "episode 7, policy loss -3.3462417125701904\n",
      "\n",
      "episode 8, policy loss -3.3462414741516113\n",
      "\n",
      "episode 9, policy loss -3.3462417125701904\n",
      "\n",
      "episode 10, policy loss -3.3462417125701904\n",
      "\n",
      "episode 11, policy loss -3.3462417125701904\n",
      "\n",
      "episode 12, policy loss -3.3462417125701904\n",
      "\n",
      "episode 13, policy loss -3.3462417125701904\n",
      "\n",
      "episode 14, policy loss -3.3462414741516113\n",
      "\n",
      "episode 15, policy loss -3.3462417125701904\n",
      "\n",
      "episode 16, policy loss -3.3462417125701904\n",
      "\n",
      "Policy train loss in epoch 2:-3.3462416380643845\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.3462414741516113\n",
      "\n",
      "episode 2, policy loss -3.3462414741516113\n",
      "\n",
      "episode 3, policy loss -3.3462414741516113\n",
      "\n",
      "episode 4, policy loss -3.3462417125701904\n",
      "\n",
      "episode 5, policy loss -3.3462417125701904\n",
      "\n",
      "episode 6, policy loss -3.3462417125701904\n",
      "\n",
      "episode 7, policy loss -3.3462417125701904\n",
      "\n",
      "episode 8, policy loss -3.3462417125701904\n",
      "\n",
      "episode 9, policy loss -3.3462417125701904\n",
      "\n",
      "episode 10, policy loss -3.3462417125701904\n",
      "\n",
      "episode 11, policy loss -3.3462417125701904\n",
      "\n",
      "episode 12, policy loss -3.3462417125701904\n",
      "\n",
      "episode 13, policy loss -3.3462417125701904\n",
      "\n",
      "episode 14, policy loss -3.3462417125701904\n",
      "\n",
      "episode 15, policy loss -3.3462414741516113\n",
      "\n",
      "episode 16, policy loss -3.3462417125701904\n",
      "\n",
      "Policy train loss in epoch 3:-3.3462416529655457\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.1004706621170044\n",
      "\n",
      "episode 2, val func loss 1.296056866645813\n",
      "\n",
      "episode 3, val func loss 1.4839421510696411\n",
      "\n",
      "episode 4, val func loss 1.4107918739318848\n",
      "\n",
      "episode 5, val func loss 1.1410868167877197\n",
      "\n",
      "episode 6, val func loss 1.12407386302948\n",
      "\n",
      "episode 7, val func loss 1.1167024374008179\n",
      "\n",
      "episode 8, val func loss 1.2847875356674194\n",
      "\n",
      "episode 9, val func loss 1.3069370985031128\n",
      "\n",
      "episode 10, val func loss 1.3855669498443604\n",
      "\n",
      "episode 11, val func loss 1.1366640329360962\n",
      "\n",
      "episode 12, val func loss 1.0779283046722412\n",
      "\n",
      "episode 13, val func loss 1.4156839847564697\n",
      "\n",
      "episode 14, val func loss 1.215786337852478\n",
      "\n",
      "episode 15, val func loss 1.1586507558822632\n",
      "\n",
      "episode 16, val func loss 1.2286229133605957\n",
      "\n",
      "Val func train loss in epoch 0:1.2427345365285873\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.1109652519226074\n",
      "\n",
      "episode 2, val func loss 1.1601346731185913\n",
      "\n",
      "episode 3, val func loss 1.2655584812164307\n",
      "\n",
      "episode 4, val func loss 1.2118079662322998\n",
      "\n",
      "episode 5, val func loss 1.2656368017196655\n",
      "\n",
      "episode 6, val func loss 1.3352241516113281\n",
      "\n",
      "episode 7, val func loss 1.308457374572754\n",
      "\n",
      "episode 8, val func loss 1.1811877489089966\n",
      "\n",
      "episode 9, val func loss 1.1548280715942383\n",
      "\n",
      "episode 10, val func loss 1.0628650188446045\n",
      "\n",
      "episode 11, val func loss 1.23342764377594\n",
      "\n",
      "episode 12, val func loss 1.14275324344635\n",
      "\n",
      "episode 13, val func loss 1.2282096147537231\n",
      "\n",
      "episode 14, val func loss 1.343166708946228\n",
      "\n",
      "episode 15, val func loss 1.1524559259414673\n",
      "\n",
      "episode 16, val func loss 1.1928714513778687\n",
      "\n",
      "Val func train loss in epoch 1:1.2093468829989433\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.1708471775054932\n",
      "\n",
      "episode 2, val func loss 1.2436463832855225\n",
      "\n",
      "episode 3, val func loss 0.9577671885490417\n",
      "\n",
      "episode 4, val func loss 1.1086928844451904\n",
      "\n",
      "episode 5, val func loss 1.231691598892212\n",
      "\n",
      "episode 6, val func loss 1.2173393964767456\n",
      "\n",
      "episode 7, val func loss 1.0626776218414307\n",
      "\n",
      "episode 8, val func loss 1.1429988145828247\n",
      "\n",
      "episode 9, val func loss 1.066938877105713\n",
      "\n",
      "episode 10, val func loss 1.1167395114898682\n",
      "\n",
      "episode 11, val func loss 1.1167634725570679\n",
      "\n",
      "episode 12, val func loss 1.4100285768508911\n",
      "\n",
      "episode 13, val func loss 1.2225065231323242\n",
      "\n",
      "episode 14, val func loss 1.3730051517486572\n",
      "\n",
      "episode 15, val func loss 1.3330477476119995\n",
      "\n",
      "episode 16, val func loss 1.1678270101547241\n",
      "\n",
      "Val func train loss in epoch 2:1.1839073710143566\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.1759830713272095\n",
      "\n",
      "episode 2, val func loss 1.3010962009429932\n",
      "\n",
      "episode 3, val func loss 1.2853429317474365\n",
      "\n",
      "episode 4, val func loss 1.207077980041504\n",
      "\n",
      "episode 5, val func loss 1.209970235824585\n",
      "\n",
      "episode 6, val func loss 1.1334689855575562\n",
      "\n",
      "episode 7, val func loss 1.2493042945861816\n",
      "\n",
      "episode 8, val func loss 1.3192287683486938\n",
      "\n",
      "episode 9, val func loss 1.1381946802139282\n",
      "\n",
      "episode 10, val func loss 1.1191134452819824\n",
      "\n",
      "episode 11, val func loss 1.235079288482666\n",
      "\n",
      "episode 12, val func loss 1.2053548097610474\n",
      "\n",
      "episode 13, val func loss 1.16372811794281\n",
      "\n",
      "episode 14, val func loss 1.3539440631866455\n",
      "\n",
      "episode 15, val func loss 1.2360942363739014\n",
      "\n",
      "episode 16, val func loss 1.4194271564483643\n",
      "\n",
      "Val func train loss in epoch 3:1.234525516629219\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.1598505973815918\n",
      "\n",
      "episode 2, val func loss 1.0561606884002686\n",
      "\n",
      "episode 3, val func loss 1.031477689743042\n",
      "\n",
      "episode 4, val func loss 1.0698601007461548\n",
      "\n",
      "episode 5, val func loss 1.1795361042022705\n",
      "\n",
      "episode 6, val func loss 1.0802072286605835\n",
      "\n",
      "episode 7, val func loss 1.0709116458892822\n",
      "\n",
      "episode 8, val func loss 1.1982383728027344\n",
      "\n",
      "episode 9, val func loss 1.3646458387374878\n",
      "\n",
      "episode 10, val func loss 1.2123714685440063\n",
      "\n",
      "episode 11, val func loss 1.3286575078964233\n",
      "\n",
      "episode 12, val func loss 1.4005898237228394\n",
      "\n",
      "episode 13, val func loss 1.2480719089508057\n",
      "\n",
      "episode 14, val func loss 1.207608938217163\n",
      "\n",
      "episode 15, val func loss 1.2886899709701538\n",
      "\n",
      "episode 16, val func loss 1.1164145469665527\n",
      "\n",
      "Val func train loss in epoch 4:1.18833077698946\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.153017282485962\n",
      "\n",
      "episode 2, val func loss 1.1006418466567993\n",
      "\n",
      "episode 3, val func loss 1.3024542331695557\n",
      "\n",
      "episode 4, val func loss 1.205093502998352\n",
      "\n",
      "episode 5, val func loss 1.2279975414276123\n",
      "\n",
      "episode 6, val func loss 1.1193987131118774\n",
      "\n",
      "episode 7, val func loss 1.2784202098846436\n",
      "\n",
      "episode 8, val func loss 1.262677550315857\n",
      "\n",
      "episode 9, val func loss 1.131592035293579\n",
      "\n",
      "episode 10, val func loss 1.1800165176391602\n",
      "\n",
      "episode 11, val func loss 1.3351033926010132\n",
      "\n",
      "episode 12, val func loss 1.5319328308105469\n",
      "\n",
      "episode 13, val func loss 1.0630394220352173\n",
      "\n",
      "episode 14, val func loss 1.067218542098999\n",
      "\n",
      "episode 15, val func loss 1.3985176086425781\n",
      "\n",
      "episode 16, val func loss 1.4166390895843506\n",
      "\n",
      "Val func train loss in epoch 5:1.2358600199222565\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.165798544883728\n",
      "\n",
      "episode 2, val func loss 0.9963117837905884\n",
      "\n",
      "episode 3, val func loss 1.3509142398834229\n",
      "\n",
      "episode 4, val func loss 1.1598608493804932\n",
      "\n",
      "episode 5, val func loss 1.3244831562042236\n",
      "\n",
      "episode 6, val func loss 1.2072045803070068\n",
      "\n",
      "episode 7, val func loss 1.1967252492904663\n",
      "\n",
      "episode 8, val func loss 1.1841890811920166\n",
      "\n",
      "episode 9, val func loss 1.2037636041641235\n",
      "\n",
      "episode 10, val func loss 1.0087110996246338\n",
      "\n",
      "episode 11, val func loss 1.2313765287399292\n",
      "\n",
      "episode 12, val func loss 1.189325213432312\n",
      "\n",
      "episode 13, val func loss 1.3748290538787842\n",
      "\n",
      "episode 14, val func loss 1.059312105178833\n",
      "\n",
      "episode 15, val func loss 1.1230310201644897\n",
      "\n",
      "episode 16, val func loss 1.299541711807251\n",
      "\n",
      "Val func train loss in epoch 6:1.192211113870144\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.0477919578552246\n",
      "\n",
      "episode 2, val func loss 1.4996464252471924\n",
      "\n",
      "episode 3, val func loss 1.1743125915527344\n",
      "\n",
      "episode 4, val func loss 1.335642695426941\n",
      "\n",
      "episode 5, val func loss 1.1253077983856201\n",
      "\n",
      "episode 6, val func loss 1.332815408706665\n",
      "\n",
      "episode 7, val func loss 1.1977753639221191\n",
      "\n",
      "episode 8, val func loss 1.2602787017822266\n",
      "\n",
      "episode 9, val func loss 1.1081185340881348\n",
      "\n",
      "episode 10, val func loss 1.159395694732666\n",
      "\n",
      "episode 11, val func loss 1.179466724395752\n",
      "\n",
      "episode 12, val func loss 1.280663251876831\n",
      "\n",
      "episode 13, val func loss 1.1417948007583618\n",
      "\n",
      "episode 14, val func loss 1.2360632419586182\n",
      "\n",
      "episode 15, val func loss 1.1097654104232788\n",
      "\n",
      "episode 16, val func loss 1.4125041961669922\n",
      "\n",
      "Val func train loss in epoch 7:1.2250839248299599\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.3276056051254272\n",
      "\n",
      "episode 2, val func loss 1.196692943572998\n",
      "\n",
      "episode 3, val func loss 1.3299516439437866\n",
      "\n",
      "episode 4, val func loss 1.2188342809677124\n",
      "\n",
      "episode 5, val func loss 1.1581789255142212\n",
      "\n",
      "episode 6, val func loss 1.285647988319397\n",
      "\n",
      "episode 7, val func loss 1.1968151330947876\n",
      "\n",
      "episode 8, val func loss 1.1709671020507812\n",
      "\n",
      "episode 9, val func loss 1.1084332466125488\n",
      "\n",
      "episode 10, val func loss 1.2011653184890747\n",
      "\n",
      "episode 11, val func loss 1.2522088289260864\n",
      "\n",
      "episode 12, val func loss 1.1551330089569092\n",
      "\n",
      "episode 13, val func loss 1.18423593044281\n",
      "\n",
      "episode 14, val func loss 1.3718552589416504\n",
      "\n",
      "episode 15, val func loss 1.2452871799468994\n",
      "\n",
      "episode 16, val func loss 1.2021883726119995\n",
      "\n",
      "Val func train loss in epoch 8:1.2253250479698181\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.1166173219680786\n",
      "\n",
      "episode 2, val func loss 1.2969975471496582\n",
      "\n",
      "episode 3, val func loss 1.2592002153396606\n",
      "\n",
      "episode 4, val func loss 1.2490789890289307\n",
      "\n",
      "episode 5, val func loss 1.1545931100845337\n",
      "\n",
      "episode 6, val func loss 1.3729356527328491\n",
      "\n",
      "episode 7, val func loss 1.2154395580291748\n",
      "\n",
      "episode 8, val func loss 1.196533441543579\n",
      "\n",
      "episode 9, val func loss 1.206214189529419\n",
      "\n",
      "episode 10, val func loss 1.2689006328582764\n",
      "\n",
      "episode 11, val func loss 1.156144380569458\n",
      "\n",
      "episode 12, val func loss 1.1784223318099976\n",
      "\n",
      "episode 13, val func loss 1.2161539793014526\n",
      "\n",
      "episode 14, val func loss 0.9995080828666687\n",
      "\n",
      "episode 15, val func loss 1.0604861974716187\n",
      "\n",
      "episode 16, val func loss 1.278252124786377\n",
      "\n",
      "Val func train loss in epoch 9:1.2015923596918583\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.1032570600509644\n",
      "\n",
      "episode 2, val func loss 1.0754821300506592\n",
      "\n",
      "episode 3, val func loss 1.1256537437438965\n",
      "\n",
      "episode 4, val func loss 1.4338959455490112\n",
      "\n",
      "episode 5, val func loss 1.1845160722732544\n",
      "\n",
      "episode 6, val func loss 1.149326205253601\n",
      "\n",
      "episode 7, val func loss 1.2614978551864624\n",
      "\n",
      "episode 8, val func loss 1.2066302299499512\n",
      "\n",
      "episode 9, val func loss 1.2632203102111816\n",
      "\n",
      "episode 10, val func loss 1.3004144430160522\n",
      "\n",
      "episode 11, val func loss 1.0708258152008057\n",
      "\n",
      "episode 12, val func loss 1.4096856117248535\n",
      "\n",
      "episode 13, val func loss 1.2331383228302002\n",
      "\n",
      "episode 14, val func loss 1.0662182569503784\n",
      "\n",
      "episode 15, val func loss 1.336713433265686\n",
      "\n",
      "episode 16, val func loss 1.5215215682983398\n",
      "\n",
      "Val func train loss in epoch 10:1.2338748127222061\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.254310131072998\n",
      "\n",
      "episode 2, val func loss 1.1873356103897095\n",
      "\n",
      "episode 3, val func loss 1.1815669536590576\n",
      "\n",
      "episode 4, val func loss 1.1973220109939575\n",
      "\n",
      "episode 5, val func loss 1.3265396356582642\n",
      "\n",
      "episode 6, val func loss 1.025290608406067\n",
      "\n",
      "episode 7, val func loss 1.196485996246338\n",
      "\n",
      "episode 8, val func loss 1.1074031591415405\n",
      "\n",
      "episode 9, val func loss 1.1433923244476318\n",
      "\n",
      "episode 10, val func loss 1.0830339193344116\n",
      "\n",
      "episode 11, val func loss 1.2531274557113647\n",
      "\n",
      "episode 12, val func loss 0.9892499446868896\n",
      "\n",
      "episode 13, val func loss 1.1357501745224\n",
      "\n",
      "episode 14, val func loss 1.2177385091781616\n",
      "\n",
      "episode 15, val func loss 1.0355165004730225\n",
      "\n",
      "episode 16, val func loss 1.1225924491882324\n",
      "\n",
      "Val func train loss in epoch 11:1.153540961444378\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.1840403079986572\n",
      "\n",
      "episode 2, val func loss 1.3192615509033203\n",
      "\n",
      "episode 3, val func loss 1.1606441736221313\n",
      "\n",
      "episode 4, val func loss 1.3082631826400757\n",
      "\n",
      "episode 5, val func loss 1.1903762817382812\n",
      "\n",
      "episode 6, val func loss 1.3293507099151611\n",
      "\n",
      "episode 7, val func loss 1.2536824941635132\n",
      "\n",
      "episode 8, val func loss 1.3500349521636963\n",
      "\n",
      "episode 9, val func loss 1.1107200384140015\n",
      "\n",
      "episode 10, val func loss 1.3612899780273438\n",
      "\n",
      "episode 11, val func loss 1.0775400400161743\n",
      "\n",
      "episode 12, val func loss 1.1736780405044556\n",
      "\n",
      "episode 13, val func loss 1.3056634664535522\n",
      "\n",
      "episode 14, val func loss 1.1215802431106567\n",
      "\n",
      "episode 15, val func loss 1.5044156312942505\n",
      "\n",
      "episode 16, val func loss 1.0976122617721558\n",
      "\n",
      "Val func train loss in epoch 12:1.2405095845460892\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.3978469371795654\n",
      "\n",
      "episode 2, val func loss 1.2451964616775513\n",
      "\n",
      "episode 3, val func loss 1.0626779794692993\n",
      "\n",
      "episode 4, val func loss 1.2958035469055176\n",
      "\n",
      "episode 5, val func loss 1.1936938762664795\n",
      "\n",
      "episode 6, val func loss 0.9474849104881287\n",
      "\n",
      "episode 7, val func loss 1.233502984046936\n",
      "\n",
      "episode 8, val func loss 1.3081378936767578\n",
      "\n",
      "episode 9, val func loss 1.1679073572158813\n",
      "\n",
      "episode 10, val func loss 1.2696936130523682\n",
      "\n",
      "episode 11, val func loss 1.1857399940490723\n",
      "\n",
      "episode 12, val func loss 1.1808103322982788\n",
      "\n",
      "episode 13, val func loss 1.3147271871566772\n",
      "\n",
      "episode 14, val func loss 1.093876600265503\n",
      "\n",
      "episode 15, val func loss 1.38712739944458\n",
      "\n",
      "episode 16, val func loss 1.1365448236465454\n",
      "\n",
      "Val func train loss in epoch 13:1.2137982435524464\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.2222822904586792\n",
      "\n",
      "episode 2, val func loss 1.3596495389938354\n",
      "\n",
      "episode 3, val func loss 1.2211436033248901\n",
      "\n",
      "episode 4, val func loss 1.283877968788147\n",
      "\n",
      "episode 5, val func loss 1.1053403615951538\n",
      "\n",
      "episode 6, val func loss 1.0909620523452759\n",
      "\n",
      "episode 7, val func loss 1.2402191162109375\n",
      "\n",
      "episode 8, val func loss 1.1791507005691528\n",
      "\n",
      "episode 9, val func loss 1.2068341970443726\n",
      "\n",
      "episode 10, val func loss 1.2566096782684326\n",
      "\n",
      "episode 11, val func loss 1.1218898296356201\n",
      "\n",
      "episode 12, val func loss 1.2057883739471436\n",
      "\n",
      "episode 13, val func loss 1.3222765922546387\n",
      "\n",
      "episode 14, val func loss 1.2539794445037842\n",
      "\n",
      "episode 15, val func loss 1.3168615102767944\n",
      "\n",
      "episode 16, val func loss 1.1993484497070312\n",
      "\n",
      "Val func train loss in epoch 14:1.224138356745243\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.1284247636795044\n",
      "\n",
      "episode 2, val func loss 1.214023232460022\n",
      "\n",
      "episode 3, val func loss 1.1486340761184692\n",
      "\n",
      "episode 4, val func loss 1.0341744422912598\n",
      "\n",
      "episode 5, val func loss 1.4226443767547607\n",
      "\n",
      "episode 6, val func loss 1.252829909324646\n",
      "\n",
      "episode 7, val func loss 1.1103644371032715\n",
      "\n",
      "episode 8, val func loss 1.231355905532837\n",
      "\n",
      "episode 9, val func loss 1.18559992313385\n",
      "\n",
      "episode 10, val func loss 1.2479568719863892\n",
      "\n",
      "episode 11, val func loss 1.3072874546051025\n",
      "\n",
      "episode 12, val func loss 1.2294245958328247\n",
      "\n",
      "episode 13, val func loss 1.2898449897766113\n",
      "\n",
      "episode 14, val func loss 1.1403857469558716\n",
      "\n",
      "episode 15, val func loss 1.134719729423523\n",
      "\n",
      "episode 16, val func loss 0.9753623604774475\n",
      "\n",
      "Val func train loss in epoch 15:1.1908145509660244\n",
      "***********************TIME WAS 4.856991648674011 min*****************************\n",
      "\n",
      "**********************ROUND 75 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.578855514526367\n",
      "\n",
      "episode 2, policy loss -3.578855514526367\n",
      "\n",
      "episode 3, policy loss -3.578855514526367\n",
      "\n",
      "episode 4, policy loss -3.578855514526367\n",
      "\n",
      "episode 5, policy loss -3.578855037689209\n",
      "\n",
      "episode 6, policy loss -3.578855514526367\n",
      "\n",
      "episode 7, policy loss -3.578855037689209\n",
      "\n",
      "episode 8, policy loss -3.578855037689209\n",
      "\n",
      "episode 9, policy loss -3.578855514526367\n",
      "\n",
      "episode 10, policy loss -3.578855514526367\n",
      "\n",
      "episode 11, policy loss -3.578855514526367\n",
      "\n",
      "episode 12, policy loss -3.578855514526367\n",
      "\n",
      "episode 13, policy loss -3.578855514526367\n",
      "\n",
      "episode 14, policy loss -3.578855037689209\n",
      "\n",
      "episode 15, policy loss -3.578855514526367\n",
      "\n",
      "episode 16, policy loss -3.578855514526367\n",
      "\n",
      "Policy train loss in epoch 0:-3.5788553953170776\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.578855514526367\n",
      "\n",
      "episode 2, policy loss -3.578855514526367\n",
      "\n",
      "episode 3, policy loss -3.578855514526367\n",
      "\n",
      "episode 4, policy loss -3.578855514526367\n",
      "\n",
      "episode 5, policy loss -3.578855514526367\n",
      "\n",
      "episode 6, policy loss -3.578855514526367\n",
      "\n",
      "episode 7, policy loss -3.578855514526367\n",
      "\n",
      "episode 8, policy loss -3.578855514526367\n",
      "\n",
      "episode 9, policy loss -3.578855037689209\n",
      "\n",
      "episode 10, policy loss -3.578855514526367\n",
      "\n",
      "episode 11, policy loss -3.578855037689209\n",
      "\n",
      "episode 12, policy loss -3.578855514526367\n",
      "\n",
      "episode 13, policy loss -3.578855037689209\n",
      "\n",
      "episode 14, policy loss -3.578855514526367\n",
      "\n",
      "episode 15, policy loss -3.578855514526367\n",
      "\n",
      "episode 16, policy loss -3.578855514526367\n",
      "\n",
      "Policy train loss in epoch 1:-3.5788554251194\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.578855514526367\n",
      "\n",
      "episode 2, policy loss -3.578855514526367\n",
      "\n",
      "episode 3, policy loss -3.578855514526367\n",
      "\n",
      "episode 4, policy loss -3.578855514526367\n",
      "\n",
      "episode 5, policy loss -3.578855514526367\n",
      "\n",
      "episode 6, policy loss -3.578855514526367\n",
      "\n",
      "episode 7, policy loss -3.578855514526367\n",
      "\n",
      "episode 8, policy loss -3.578855514526367\n",
      "\n",
      "episode 9, policy loss -3.578855514526367\n",
      "\n",
      "episode 10, policy loss -3.578855037689209\n",
      "\n",
      "episode 11, policy loss -3.578855037689209\n",
      "\n",
      "episode 12, policy loss -3.578855514526367\n",
      "\n",
      "episode 13, policy loss -3.578855514526367\n",
      "\n",
      "episode 14, policy loss -3.578855514526367\n",
      "\n",
      "episode 15, policy loss -3.578855514526367\n",
      "\n",
      "episode 16, policy loss -3.578855514526367\n",
      "\n",
      "Policy train loss in epoch 2:-3.5788554549217224\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.578855514526367\n",
      "\n",
      "episode 2, policy loss -3.578855514526367\n",
      "\n",
      "episode 3, policy loss -3.578855037689209\n",
      "\n",
      "episode 4, policy loss -3.578855514526367\n",
      "\n",
      "episode 5, policy loss -3.578855514526367\n",
      "\n",
      "episode 6, policy loss -3.578855514526367\n",
      "\n",
      "episode 7, policy loss -3.578855514526367\n",
      "\n",
      "episode 8, policy loss -3.578855514526367\n",
      "\n",
      "episode 9, policy loss -3.578855514526367\n",
      "\n",
      "episode 10, policy loss -3.578855037689209\n",
      "\n",
      "episode 11, policy loss -3.578855514526367\n",
      "\n",
      "episode 12, policy loss -3.578855514526367\n",
      "\n",
      "episode 13, policy loss -3.578855514526367\n",
      "\n",
      "episode 14, policy loss -3.578855514526367\n",
      "\n",
      "episode 15, policy loss -3.578855514526367\n",
      "\n",
      "episode 16, policy loss -3.578855037689209\n",
      "\n",
      "Policy train loss in epoch 3:-3.5788554251194\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.0870420932769775\n",
      "\n",
      "episode 2, val func loss 1.2423896789550781\n",
      "\n",
      "episode 3, val func loss 1.1349718570709229\n",
      "\n",
      "episode 4, val func loss 1.2173327207565308\n",
      "\n",
      "episode 5, val func loss 1.1716597080230713\n",
      "\n",
      "episode 6, val func loss 1.3096402883529663\n",
      "\n",
      "episode 7, val func loss 1.1676846742630005\n",
      "\n",
      "episode 8, val func loss 1.247501254081726\n",
      "\n",
      "episode 9, val func loss 1.1719633340835571\n",
      "\n",
      "episode 10, val func loss 1.3884416818618774\n",
      "\n",
      "episode 11, val func loss 1.2106940746307373\n",
      "\n",
      "episode 12, val func loss 1.1515617370605469\n",
      "\n",
      "episode 13, val func loss 1.1712019443511963\n",
      "\n",
      "episode 14, val func loss 1.2767711877822876\n",
      "\n",
      "episode 15, val func loss 1.18569016456604\n",
      "\n",
      "episode 16, val func loss 1.180180311203003\n",
      "\n",
      "Val func train loss in epoch 0:1.20717041939497\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.2489008903503418\n",
      "\n",
      "episode 2, val func loss 1.13480806350708\n",
      "\n",
      "episode 3, val func loss 1.1799734830856323\n",
      "\n",
      "episode 4, val func loss 1.2218585014343262\n",
      "\n",
      "episode 5, val func loss 1.3328251838684082\n",
      "\n",
      "episode 6, val func loss 1.2088121175765991\n",
      "\n",
      "episode 7, val func loss 1.3021351099014282\n",
      "\n",
      "episode 8, val func loss 1.3375685214996338\n",
      "\n",
      "episode 9, val func loss 1.1225355863571167\n",
      "\n",
      "episode 10, val func loss 1.1293346881866455\n",
      "\n",
      "episode 11, val func loss 1.2478187084197998\n",
      "\n",
      "episode 12, val func loss 1.0315319299697876\n",
      "\n",
      "episode 13, val func loss 1.1088049411773682\n",
      "\n",
      "episode 14, val func loss 1.2671589851379395\n",
      "\n",
      "episode 15, val func loss 1.0648247003555298\n",
      "\n",
      "episode 16, val func loss 1.208102822303772\n",
      "\n",
      "Val func train loss in epoch 1:1.196687139570713\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.189835548400879\n",
      "\n",
      "episode 2, val func loss 1.3326077461242676\n",
      "\n",
      "episode 3, val func loss 1.2064523696899414\n",
      "\n",
      "episode 4, val func loss 1.2498794794082642\n",
      "\n",
      "episode 5, val func loss 1.2041124105453491\n",
      "\n",
      "episode 6, val func loss 1.259037733078003\n",
      "\n",
      "episode 7, val func loss 1.213295817375183\n",
      "\n",
      "episode 8, val func loss 1.1633800268173218\n",
      "\n",
      "episode 9, val func loss 1.260356068611145\n",
      "\n",
      "episode 10, val func loss 1.0977098941802979\n",
      "\n",
      "episode 11, val func loss 1.1371004581451416\n",
      "\n",
      "episode 12, val func loss 1.2010607719421387\n",
      "\n",
      "episode 13, val func loss 1.1348750591278076\n",
      "\n",
      "episode 14, val func loss 1.1707005500793457\n",
      "\n",
      "episode 15, val func loss 1.0863392353057861\n",
      "\n",
      "episode 16, val func loss 1.0217915773391724\n",
      "\n",
      "Val func train loss in epoch 2:1.1830334216356277\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.19716215133667\n",
      "\n",
      "episode 2, val func loss 1.1152215003967285\n",
      "\n",
      "episode 3, val func loss 1.2292160987854004\n",
      "\n",
      "episode 4, val func loss 1.160300612449646\n",
      "\n",
      "episode 5, val func loss 1.1490336656570435\n",
      "\n",
      "episode 6, val func loss 1.1167551279067993\n",
      "\n",
      "episode 7, val func loss 1.2433912754058838\n",
      "\n",
      "episode 8, val func loss 1.2171083688735962\n",
      "\n",
      "episode 9, val func loss 1.0870754718780518\n",
      "\n",
      "episode 10, val func loss 1.1605191230773926\n",
      "\n",
      "episode 11, val func loss 1.1704202890396118\n",
      "\n",
      "episode 12, val func loss 1.2481650114059448\n",
      "\n",
      "episode 13, val func loss 1.187262773513794\n",
      "\n",
      "episode 14, val func loss 1.0802205801010132\n",
      "\n",
      "episode 15, val func loss 1.3341823816299438\n",
      "\n",
      "episode 16, val func loss 1.1706626415252686\n",
      "\n",
      "Val func train loss in epoch 3:1.1791685670614243\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.1571698188781738\n",
      "\n",
      "episode 2, val func loss 1.3175004720687866\n",
      "\n",
      "episode 3, val func loss 1.3080154657363892\n",
      "\n",
      "episode 4, val func loss 1.1293400526046753\n",
      "\n",
      "episode 5, val func loss 1.1704140901565552\n",
      "\n",
      "episode 6, val func loss 1.1664222478866577\n",
      "\n",
      "episode 7, val func loss 1.0337680578231812\n",
      "\n",
      "episode 8, val func loss 1.2297316789627075\n",
      "\n",
      "episode 9, val func loss 1.2499059438705444\n",
      "\n",
      "episode 10, val func loss 1.1757012605667114\n",
      "\n",
      "episode 11, val func loss 1.2244139909744263\n",
      "\n",
      "episode 12, val func loss 1.1488243341445923\n",
      "\n",
      "episode 13, val func loss 1.0128555297851562\n",
      "\n",
      "episode 14, val func loss 1.270370602607727\n",
      "\n",
      "episode 15, val func loss 1.1222975254058838\n",
      "\n",
      "episode 16, val func loss 1.114121437072754\n",
      "\n",
      "Val func train loss in epoch 4:1.1769282817840576\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.224067211151123\n",
      "\n",
      "episode 2, val func loss 1.3733019828796387\n",
      "\n",
      "episode 3, val func loss 1.1273024082183838\n",
      "\n",
      "episode 4, val func loss 1.0895938873291016\n",
      "\n",
      "episode 5, val func loss 0.971310019493103\n",
      "\n",
      "episode 6, val func loss 1.2969155311584473\n",
      "\n",
      "episode 7, val func loss 1.1381093263626099\n",
      "\n",
      "episode 8, val func loss 1.239512324333191\n",
      "\n",
      "episode 9, val func loss 1.2284197807312012\n",
      "\n",
      "episode 10, val func loss 1.2425024509429932\n",
      "\n",
      "episode 11, val func loss 1.0564115047454834\n",
      "\n",
      "episode 12, val func loss 1.0350035429000854\n",
      "\n",
      "episode 13, val func loss 1.2369171380996704\n",
      "\n",
      "episode 14, val func loss 1.127577304840088\n",
      "\n",
      "episode 15, val func loss 1.2465115785598755\n",
      "\n",
      "episode 16, val func loss 1.0953707695007324\n",
      "\n",
      "Val func train loss in epoch 5:1.170551672577858\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.1558243036270142\n",
      "\n",
      "episode 2, val func loss 1.0372825860977173\n",
      "\n",
      "episode 3, val func loss 1.0466283559799194\n",
      "\n",
      "episode 4, val func loss 1.0377825498580933\n",
      "\n",
      "episode 5, val func loss 1.2618504762649536\n",
      "\n",
      "episode 6, val func loss 1.0677740573883057\n",
      "\n",
      "episode 7, val func loss 1.0976626873016357\n",
      "\n",
      "episode 8, val func loss 1.10751211643219\n",
      "\n",
      "episode 9, val func loss 1.0886317491531372\n",
      "\n",
      "episode 10, val func loss 1.1709644794464111\n",
      "\n",
      "episode 11, val func loss 1.1919482946395874\n",
      "\n",
      "episode 12, val func loss 1.2194631099700928\n",
      "\n",
      "episode 13, val func loss 1.2614550590515137\n",
      "\n",
      "episode 14, val func loss 1.0817670822143555\n",
      "\n",
      "episode 15, val func loss 1.3383976221084595\n",
      "\n",
      "episode 16, val func loss 1.1874524354934692\n",
      "\n",
      "Val func train loss in epoch 6:1.1470248103141785\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.2906386852264404\n",
      "\n",
      "episode 2, val func loss 1.251528024673462\n",
      "\n",
      "episode 3, val func loss 1.146153450012207\n",
      "\n",
      "episode 4, val func loss 1.2130366563796997\n",
      "\n",
      "episode 5, val func loss 1.2536174058914185\n",
      "\n",
      "episode 6, val func loss 0.9649447798728943\n",
      "\n",
      "episode 7, val func loss 1.138506531715393\n",
      "\n",
      "episode 8, val func loss 1.20530366897583\n",
      "\n",
      "episode 9, val func loss 1.1934422254562378\n",
      "\n",
      "episode 10, val func loss 1.148939609527588\n",
      "\n",
      "episode 11, val func loss 1.2395137548446655\n",
      "\n",
      "episode 12, val func loss 1.1520755290985107\n",
      "\n",
      "episode 13, val func loss 1.010930061340332\n",
      "\n",
      "episode 14, val func loss 1.0318208932876587\n",
      "\n",
      "episode 15, val func loss 1.1490453481674194\n",
      "\n",
      "episode 16, val func loss 1.0578738451004028\n",
      "\n",
      "Val func train loss in epoch 7:1.152960654348135\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8998912572860718\n",
      "\n",
      "episode 2, val func loss 0.9891359210014343\n",
      "\n",
      "episode 3, val func loss 1.3478960990905762\n",
      "\n",
      "episode 4, val func loss 1.2339332103729248\n",
      "\n",
      "episode 5, val func loss 1.2039514780044556\n",
      "\n",
      "episode 6, val func loss 1.1339281797409058\n",
      "\n",
      "episode 7, val func loss 1.1861263513565063\n",
      "\n",
      "episode 8, val func loss 1.1437301635742188\n",
      "\n",
      "episode 9, val func loss 1.154651403427124\n",
      "\n",
      "episode 10, val func loss 1.2352803945541382\n",
      "\n",
      "episode 11, val func loss 1.1526724100112915\n",
      "\n",
      "episode 12, val func loss 1.1972295045852661\n",
      "\n",
      "episode 13, val func loss 1.4106032848358154\n",
      "\n",
      "episode 14, val func loss 1.1173350811004639\n",
      "\n",
      "episode 15, val func loss 1.1868247985839844\n",
      "\n",
      "episode 16, val func loss 0.978018581867218\n",
      "\n",
      "Val func train loss in epoch 8:1.1607005074620247\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.316315770149231\n",
      "\n",
      "episode 2, val func loss 1.2206780910491943\n",
      "\n",
      "episode 3, val func loss 1.0806524753570557\n",
      "\n",
      "episode 4, val func loss 1.218356966972351\n",
      "\n",
      "episode 5, val func loss 1.167980432510376\n",
      "\n",
      "episode 6, val func loss 1.3492454290390015\n",
      "\n",
      "episode 7, val func loss 1.0590847730636597\n",
      "\n",
      "episode 8, val func loss 1.0840142965316772\n",
      "\n",
      "episode 9, val func loss 1.22207510471344\n",
      "\n",
      "episode 10, val func loss 1.248856544494629\n",
      "\n",
      "episode 11, val func loss 1.3221750259399414\n",
      "\n",
      "episode 12, val func loss 1.3838752508163452\n",
      "\n",
      "episode 13, val func loss 1.1593806743621826\n",
      "\n",
      "episode 14, val func loss 1.179841160774231\n",
      "\n",
      "episode 15, val func loss 1.3209500312805176\n",
      "\n",
      "episode 16, val func loss 1.3552833795547485\n",
      "\n",
      "Val func train loss in epoch 9:1.2305478379130363\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.4497489929199219\n",
      "\n",
      "episode 2, val func loss 1.470603108406067\n",
      "\n",
      "episode 3, val func loss 0.9571678638458252\n",
      "\n",
      "episode 4, val func loss 1.2368285655975342\n",
      "\n",
      "episode 5, val func loss 1.1004117727279663\n",
      "\n",
      "episode 6, val func loss 1.306312918663025\n",
      "\n",
      "episode 7, val func loss 1.1991856098175049\n",
      "\n",
      "episode 8, val func loss 1.0224133729934692\n",
      "\n",
      "episode 9, val func loss 1.314076542854309\n",
      "\n",
      "episode 10, val func loss 1.1413031816482544\n",
      "\n",
      "episode 11, val func loss 1.111617088317871\n",
      "\n",
      "episode 12, val func loss 1.1141586303710938\n",
      "\n",
      "episode 13, val func loss 0.9950467348098755\n",
      "\n",
      "episode 14, val func loss 1.0268371105194092\n",
      "\n",
      "episode 15, val func loss 0.9371055960655212\n",
      "\n",
      "episode 16, val func loss 1.1618678569793701\n",
      "\n",
      "Val func train loss in epoch 10:1.1590428091585636\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.0797715187072754\n",
      "\n",
      "episode 2, val func loss 1.069894552230835\n",
      "\n",
      "episode 3, val func loss 1.029370903968811\n",
      "\n",
      "episode 4, val func loss 1.2821131944656372\n",
      "\n",
      "episode 5, val func loss 1.15048348903656\n",
      "\n",
      "episode 6, val func loss 0.9699110388755798\n",
      "\n",
      "episode 7, val func loss 1.2098749876022339\n",
      "\n",
      "episode 8, val func loss 1.0279732942581177\n",
      "\n",
      "episode 9, val func loss 0.9850178956985474\n",
      "\n",
      "episode 10, val func loss 1.1302694082260132\n",
      "\n",
      "episode 11, val func loss 1.2128170728683472\n",
      "\n",
      "episode 12, val func loss 1.1379268169403076\n",
      "\n",
      "episode 13, val func loss 1.1311808824539185\n",
      "\n",
      "episode 14, val func loss 1.1647337675094604\n",
      "\n",
      "episode 15, val func loss 1.1725480556488037\n",
      "\n",
      "episode 16, val func loss 1.4199522733688354\n",
      "\n",
      "Val func train loss in epoch 11:1.1358649469912052\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.1470983028411865\n",
      "\n",
      "episode 2, val func loss 1.1947813034057617\n",
      "\n",
      "episode 3, val func loss 0.9328176379203796\n",
      "\n",
      "episode 4, val func loss 1.2008129358291626\n",
      "\n",
      "episode 5, val func loss 1.2466905117034912\n",
      "\n",
      "episode 6, val func loss 1.3450037240982056\n",
      "\n",
      "episode 7, val func loss 1.0852456092834473\n",
      "\n",
      "episode 8, val func loss 1.1094774007797241\n",
      "\n",
      "episode 9, val func loss 1.1003532409667969\n",
      "\n",
      "episode 10, val func loss 1.153995394706726\n",
      "\n",
      "episode 11, val func loss 1.0794821977615356\n",
      "\n",
      "episode 12, val func loss 1.1740093231201172\n",
      "\n",
      "episode 13, val func loss 1.205887794494629\n",
      "\n",
      "episode 14, val func loss 1.0089516639709473\n",
      "\n",
      "episode 15, val func loss 1.1849639415740967\n",
      "\n",
      "episode 16, val func loss 1.2279434204101562\n",
      "\n",
      "Val func train loss in epoch 12:1.1498446501791477\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.18764328956604\n",
      "\n",
      "episode 2, val func loss 1.2807369232177734\n",
      "\n",
      "episode 3, val func loss 1.009572148323059\n",
      "\n",
      "episode 4, val func loss 1.3147920370101929\n",
      "\n",
      "episode 5, val func loss 1.2031358480453491\n",
      "\n",
      "episode 6, val func loss 0.8743667602539062\n",
      "\n",
      "episode 7, val func loss 1.0283974409103394\n",
      "\n",
      "episode 8, val func loss 1.2369773387908936\n",
      "\n",
      "episode 9, val func loss 1.242199420928955\n",
      "\n",
      "episode 10, val func loss 1.264541506767273\n",
      "\n",
      "episode 11, val func loss 1.3647997379302979\n",
      "\n",
      "episode 12, val func loss 1.0908559560775757\n",
      "\n",
      "episode 13, val func loss 1.0464922189712524\n",
      "\n",
      "episode 14, val func loss 1.1953710317611694\n",
      "\n",
      "episode 15, val func loss 1.2197988033294678\n",
      "\n",
      "episode 16, val func loss 1.349177360534668\n",
      "\n",
      "Val func train loss in epoch 13:1.1818036139011383\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.3441171646118164\n",
      "\n",
      "episode 2, val func loss 1.271332859992981\n",
      "\n",
      "episode 3, val func loss 1.0121015310287476\n",
      "\n",
      "episode 4, val func loss 1.1874397993087769\n",
      "\n",
      "episode 5, val func loss 1.1337709426879883\n",
      "\n",
      "episode 6, val func loss 1.1191043853759766\n",
      "\n",
      "episode 7, val func loss 1.1063209772109985\n",
      "\n",
      "episode 8, val func loss 1.2906094789505005\n",
      "\n",
      "episode 9, val func loss 1.0218162536621094\n",
      "\n",
      "episode 10, val func loss 1.1129262447357178\n",
      "\n",
      "episode 11, val func loss 1.1398183107376099\n",
      "\n",
      "episode 12, val func loss 1.307229995727539\n",
      "\n",
      "episode 13, val func loss 1.1180585622787476\n",
      "\n",
      "episode 14, val func loss 1.0200488567352295\n",
      "\n",
      "episode 15, val func loss 1.3385181427001953\n",
      "\n",
      "episode 16, val func loss 1.0706509351730347\n",
      "\n",
      "Val func train loss in epoch 14:1.162116527557373\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.1267590522766113\n",
      "\n",
      "episode 2, val func loss 1.0830714702606201\n",
      "\n",
      "episode 3, val func loss 0.9764044284820557\n",
      "\n",
      "episode 4, val func loss 1.1607654094696045\n",
      "\n",
      "episode 5, val func loss 1.3010305166244507\n",
      "\n",
      "episode 6, val func loss 1.016729474067688\n",
      "\n",
      "episode 7, val func loss 1.2182854413986206\n",
      "\n",
      "episode 8, val func loss 1.1440671682357788\n",
      "\n",
      "episode 9, val func loss 1.4045360088348389\n",
      "\n",
      "episode 10, val func loss 1.213643193244934\n",
      "\n",
      "episode 11, val func loss 1.1161075830459595\n",
      "\n",
      "episode 12, val func loss 1.0824180841445923\n",
      "\n",
      "episode 13, val func loss 1.1380615234375\n",
      "\n",
      "episode 14, val func loss 1.2818533182144165\n",
      "\n",
      "episode 15, val func loss 1.035404086112976\n",
      "\n",
      "episode 16, val func loss 1.157676339149475\n",
      "\n",
      "Val func train loss in epoch 15:1.1535508185625076\n",
      "***********************TIME WAS 4.85514543056488 min*****************************\n",
      "\n",
      "**********************ROUND 76 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.523589611053467\n",
      "\n",
      "episode 2, policy loss -3.523589611053467\n",
      "\n",
      "episode 3, policy loss -3.523589611053467\n",
      "\n",
      "episode 4, policy loss -3.523589611053467\n",
      "\n",
      "episode 5, policy loss -3.523589611053467\n",
      "\n",
      "episode 6, policy loss -3.523589611053467\n",
      "\n",
      "episode 7, policy loss -3.523589611053467\n",
      "\n",
      "episode 8, policy loss -3.523589611053467\n",
      "\n",
      "episode 9, policy loss -3.523589611053467\n",
      "\n",
      "episode 10, policy loss -3.523589611053467\n",
      "\n",
      "episode 11, policy loss -3.523589611053467\n",
      "\n",
      "episode 12, policy loss -3.523589611053467\n",
      "\n",
      "episode 13, policy loss -3.523589611053467\n",
      "\n",
      "episode 14, policy loss -3.523589611053467\n",
      "\n",
      "episode 15, policy loss -3.523589611053467\n",
      "\n",
      "episode 16, policy loss -3.523589611053467\n",
      "\n",
      "Policy train loss in epoch 0:-3.523589611053467\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.523589611053467\n",
      "\n",
      "episode 2, policy loss -3.523589611053467\n",
      "\n",
      "episode 3, policy loss -3.523589611053467\n",
      "\n",
      "episode 4, policy loss -3.523589611053467\n",
      "\n",
      "episode 5, policy loss -3.523589611053467\n",
      "\n",
      "episode 6, policy loss -3.523589611053467\n",
      "\n",
      "episode 7, policy loss -3.523589611053467\n",
      "\n",
      "episode 8, policy loss -3.523589611053467\n",
      "\n",
      "episode 9, policy loss -3.523589611053467\n",
      "\n",
      "episode 10, policy loss -3.523589611053467\n",
      "\n",
      "episode 11, policy loss -3.523589611053467\n",
      "\n",
      "episode 12, policy loss -3.523589611053467\n",
      "\n",
      "episode 13, policy loss -3.523589611053467\n",
      "\n",
      "episode 14, policy loss -3.523589611053467\n",
      "\n",
      "episode 15, policy loss -3.523589611053467\n",
      "\n",
      "episode 16, policy loss -3.523589611053467\n",
      "\n",
      "Policy train loss in epoch 1:-3.523589611053467\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.523589611053467\n",
      "\n",
      "episode 2, policy loss -3.523589611053467\n",
      "\n",
      "episode 3, policy loss -3.523589611053467\n",
      "\n",
      "episode 4, policy loss -3.523589611053467\n",
      "\n",
      "episode 5, policy loss -3.523589611053467\n",
      "\n",
      "episode 6, policy loss -3.523589611053467\n",
      "\n",
      "episode 7, policy loss -3.523589611053467\n",
      "\n",
      "episode 8, policy loss -3.523589611053467\n",
      "\n",
      "episode 9, policy loss -3.523589611053467\n",
      "\n",
      "episode 10, policy loss -3.523589611053467\n",
      "\n",
      "episode 11, policy loss -3.523589611053467\n",
      "\n",
      "episode 12, policy loss -3.523589611053467\n",
      "\n",
      "episode 13, policy loss -3.523589611053467\n",
      "\n",
      "episode 14, policy loss -3.523589611053467\n",
      "\n",
      "episode 15, policy loss -3.523589611053467\n",
      "\n",
      "episode 16, policy loss -3.523589611053467\n",
      "\n",
      "Policy train loss in epoch 2:-3.523589611053467\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.523589611053467\n",
      "\n",
      "episode 2, policy loss -3.523589611053467\n",
      "\n",
      "episode 3, policy loss -3.523589611053467\n",
      "\n",
      "episode 4, policy loss -3.523589611053467\n",
      "\n",
      "episode 5, policy loss -3.523589611053467\n",
      "\n",
      "episode 6, policy loss -3.523589611053467\n",
      "\n",
      "episode 7, policy loss -3.523589611053467\n",
      "\n",
      "episode 8, policy loss -3.523589611053467\n",
      "\n",
      "episode 9, policy loss -3.523589611053467\n",
      "\n",
      "episode 10, policy loss -3.523589611053467\n",
      "\n",
      "episode 11, policy loss -3.523589611053467\n",
      "\n",
      "episode 12, policy loss -3.523589611053467\n",
      "\n",
      "episode 13, policy loss -3.523589611053467\n",
      "\n",
      "episode 14, policy loss -3.523589611053467\n",
      "\n",
      "episode 15, policy loss -3.523589611053467\n",
      "\n",
      "episode 16, policy loss -3.523589611053467\n",
      "\n",
      "Policy train loss in epoch 3:-3.523589611053467\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.0429975986480713\n",
      "\n",
      "episode 2, val func loss 0.9484639763832092\n",
      "\n",
      "episode 3, val func loss 1.0111258029937744\n",
      "\n",
      "episode 4, val func loss 1.2912877798080444\n",
      "\n",
      "episode 5, val func loss 1.1711845397949219\n",
      "\n",
      "episode 6, val func loss 1.228682041168213\n",
      "\n",
      "episode 7, val func loss 1.4761149883270264\n",
      "\n",
      "episode 8, val func loss 1.2030540704727173\n",
      "\n",
      "episode 9, val func loss 1.1247541904449463\n",
      "\n",
      "episode 10, val func loss 1.1437079906463623\n",
      "\n",
      "episode 11, val func loss 0.9119887351989746\n",
      "\n",
      "episode 12, val func loss 1.0618704557418823\n",
      "\n",
      "episode 13, val func loss 1.2232791185379028\n",
      "\n",
      "episode 14, val func loss 1.0436744689941406\n",
      "\n",
      "episode 15, val func loss 0.953421413898468\n",
      "\n",
      "episode 16, val func loss 1.048404335975647\n",
      "\n",
      "Val func train loss in epoch 0:1.1177507191896439\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.1808615922927856\n",
      "\n",
      "episode 2, val func loss 1.1772955656051636\n",
      "\n",
      "episode 3, val func loss 1.178542971611023\n",
      "\n",
      "episode 4, val func loss 0.9633568525314331\n",
      "\n",
      "episode 5, val func loss 1.1228752136230469\n",
      "\n",
      "episode 6, val func loss 1.1477415561676025\n",
      "\n",
      "episode 7, val func loss 1.0324747562408447\n",
      "\n",
      "episode 8, val func loss 1.1056690216064453\n",
      "\n",
      "episode 9, val func loss 1.146106481552124\n",
      "\n",
      "episode 10, val func loss 0.9977816343307495\n",
      "\n",
      "episode 11, val func loss 1.1562169790267944\n",
      "\n",
      "episode 12, val func loss 1.1322904825210571\n",
      "\n",
      "episode 13, val func loss 1.0935529470443726\n",
      "\n",
      "episode 14, val func loss 1.1309912204742432\n",
      "\n",
      "episode 15, val func loss 1.0063084363937378\n",
      "\n",
      "episode 16, val func loss 1.1135103702545166\n",
      "\n",
      "Val func train loss in epoch 1:1.1053485050797462\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.09348726272583\n",
      "\n",
      "episode 2, val func loss 1.1513816118240356\n",
      "\n",
      "episode 3, val func loss 1.0331292152404785\n",
      "\n",
      "episode 4, val func loss 1.1835018396377563\n",
      "\n",
      "episode 5, val func loss 1.1061862707138062\n",
      "\n",
      "episode 6, val func loss 1.002739667892456\n",
      "\n",
      "episode 7, val func loss 1.2173576354980469\n",
      "\n",
      "episode 8, val func loss 0.902829647064209\n",
      "\n",
      "episode 9, val func loss 1.254616141319275\n",
      "\n",
      "episode 10, val func loss 1.133162260055542\n",
      "\n",
      "episode 11, val func loss 1.229792833328247\n",
      "\n",
      "episode 12, val func loss 1.125815987586975\n",
      "\n",
      "episode 13, val func loss 1.080132007598877\n",
      "\n",
      "episode 14, val func loss 1.1090682744979858\n",
      "\n",
      "episode 15, val func loss 1.0916615724563599\n",
      "\n",
      "episode 16, val func loss 1.160704255104065\n",
      "\n",
      "Val func train loss in epoch 2:1.1172229051589966\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.0448850393295288\n",
      "\n",
      "episode 2, val func loss 1.14417564868927\n",
      "\n",
      "episode 3, val func loss 1.0661076307296753\n",
      "\n",
      "episode 4, val func loss 1.198825716972351\n",
      "\n",
      "episode 5, val func loss 1.2499388456344604\n",
      "\n",
      "episode 6, val func loss 1.1682268381118774\n",
      "\n",
      "episode 7, val func loss 1.1427595615386963\n",
      "\n",
      "episode 8, val func loss 0.9694768786430359\n",
      "\n",
      "episode 9, val func loss 1.1603676080703735\n",
      "\n",
      "episode 10, val func loss 1.2146269083023071\n",
      "\n",
      "episode 11, val func loss 1.1882394552230835\n",
      "\n",
      "episode 12, val func loss 1.1868841648101807\n",
      "\n",
      "episode 13, val func loss 1.121009349822998\n",
      "\n",
      "episode 14, val func loss 1.266451120376587\n",
      "\n",
      "episode 15, val func loss 1.3030016422271729\n",
      "\n",
      "episode 16, val func loss 1.1907236576080322\n",
      "\n",
      "Val func train loss in epoch 3:1.1634812541306019\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.2240982055664062\n",
      "\n",
      "episode 2, val func loss 1.024276614189148\n",
      "\n",
      "episode 3, val func loss 0.9825103878974915\n",
      "\n",
      "episode 4, val func loss 1.3246688842773438\n",
      "\n",
      "episode 5, val func loss 1.1389490365982056\n",
      "\n",
      "episode 6, val func loss 1.3048286437988281\n",
      "\n",
      "episode 7, val func loss 1.0184087753295898\n",
      "\n",
      "episode 8, val func loss 1.1172902584075928\n",
      "\n",
      "episode 9, val func loss 1.1032174825668335\n",
      "\n",
      "episode 10, val func loss 1.202884316444397\n",
      "\n",
      "episode 11, val func loss 1.013790249824524\n",
      "\n",
      "episode 12, val func loss 1.0715135335922241\n",
      "\n",
      "episode 13, val func loss 1.130681037902832\n",
      "\n",
      "episode 14, val func loss 1.021873116493225\n",
      "\n",
      "episode 15, val func loss 1.278576135635376\n",
      "\n",
      "episode 16, val func loss 1.0003465414047241\n",
      "\n",
      "Val func train loss in epoch 4:1.1223695762455463\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.1345508098602295\n",
      "\n",
      "episode 2, val func loss 1.2901949882507324\n",
      "\n",
      "episode 3, val func loss 1.1126765012741089\n",
      "\n",
      "episode 4, val func loss 1.0932914018630981\n",
      "\n",
      "episode 5, val func loss 1.3108346462249756\n",
      "\n",
      "episode 6, val func loss 1.0506446361541748\n",
      "\n",
      "episode 7, val func loss 1.2192569971084595\n",
      "\n",
      "episode 8, val func loss 1.0258229970932007\n",
      "\n",
      "episode 9, val func loss 1.130238652229309\n",
      "\n",
      "episode 10, val func loss 1.1184583902359009\n",
      "\n",
      "episode 11, val func loss 0.972087025642395\n",
      "\n",
      "episode 12, val func loss 0.9105987548828125\n",
      "\n",
      "episode 13, val func loss 1.2347166538238525\n",
      "\n",
      "episode 14, val func loss 1.0395981073379517\n",
      "\n",
      "episode 15, val func loss 1.100338101387024\n",
      "\n",
      "episode 16, val func loss 1.2529852390289307\n",
      "\n",
      "Val func train loss in epoch 5:1.1247683688998222\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.108675479888916\n",
      "\n",
      "episode 2, val func loss 1.2229490280151367\n",
      "\n",
      "episode 3, val func loss 1.0363264083862305\n",
      "\n",
      "episode 4, val func loss 1.2089630365371704\n",
      "\n",
      "episode 5, val func loss 1.0560249090194702\n",
      "\n",
      "episode 6, val func loss 1.1613562107086182\n",
      "\n",
      "episode 7, val func loss 1.1133956909179688\n",
      "\n",
      "episode 8, val func loss 1.0504097938537598\n",
      "\n",
      "episode 9, val func loss 1.1914622783660889\n",
      "\n",
      "episode 10, val func loss 1.2485730648040771\n",
      "\n",
      "episode 11, val func loss 1.3823965787887573\n",
      "\n",
      "episode 12, val func loss 1.126067876815796\n",
      "\n",
      "episode 13, val func loss 1.2905703783035278\n",
      "\n",
      "episode 14, val func loss 1.280344843864441\n",
      "\n",
      "episode 15, val func loss 0.9922435879707336\n",
      "\n",
      "episode 16, val func loss 1.1473987102508545\n",
      "\n",
      "Val func train loss in epoch 6:1.1635723672807217\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.1123100519180298\n",
      "\n",
      "episode 2, val func loss 1.1027618646621704\n",
      "\n",
      "episode 3, val func loss 1.3124189376831055\n",
      "\n",
      "episode 4, val func loss 1.1263850927352905\n",
      "\n",
      "episode 5, val func loss 1.0930474996566772\n",
      "\n",
      "episode 6, val func loss 1.1493092775344849\n",
      "\n",
      "episode 7, val func loss 1.123424768447876\n",
      "\n",
      "episode 8, val func loss 1.266406536102295\n",
      "\n",
      "episode 9, val func loss 1.0857124328613281\n",
      "\n",
      "episode 10, val func loss 1.2749797105789185\n",
      "\n",
      "episode 11, val func loss 1.224952220916748\n",
      "\n",
      "episode 12, val func loss 1.1049975156784058\n",
      "\n",
      "episode 13, val func loss 0.9873510003089905\n",
      "\n",
      "episode 14, val func loss 1.2811061143875122\n",
      "\n",
      "episode 15, val func loss 1.2064495086669922\n",
      "\n",
      "episode 16, val func loss 1.1143832206726074\n",
      "\n",
      "Val func train loss in epoch 7:1.1603747345507145\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.9628020524978638\n",
      "\n",
      "episode 2, val func loss 1.092969298362732\n",
      "\n",
      "episode 3, val func loss 1.0357776880264282\n",
      "\n",
      "episode 4, val func loss 1.167138934135437\n",
      "\n",
      "episode 5, val func loss 1.0410315990447998\n",
      "\n",
      "episode 6, val func loss 1.149381399154663\n",
      "\n",
      "episode 7, val func loss 1.163259744644165\n",
      "\n",
      "episode 8, val func loss 1.016573429107666\n",
      "\n",
      "episode 9, val func loss 0.9885168075561523\n",
      "\n",
      "episode 10, val func loss 1.0963383913040161\n",
      "\n",
      "episode 11, val func loss 1.0240591764450073\n",
      "\n",
      "episode 12, val func loss 0.9540700912475586\n",
      "\n",
      "episode 13, val func loss 1.1082077026367188\n",
      "\n",
      "episode 14, val func loss 1.192387342453003\n",
      "\n",
      "episode 15, val func loss 1.1903185844421387\n",
      "\n",
      "episode 16, val func loss 1.036226749420166\n",
      "\n",
      "Val func train loss in epoch 8:1.0761911869049072\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.9553870558738708\n",
      "\n",
      "episode 2, val func loss 0.9810647964477539\n",
      "\n",
      "episode 3, val func loss 1.035314679145813\n",
      "\n",
      "episode 4, val func loss 0.947403609752655\n",
      "\n",
      "episode 5, val func loss 1.0558264255523682\n",
      "\n",
      "episode 6, val func loss 1.3087022304534912\n",
      "\n",
      "episode 7, val func loss 1.1819363832473755\n",
      "\n",
      "episode 8, val func loss 1.0748556852340698\n",
      "\n",
      "episode 9, val func loss 1.0772593021392822\n",
      "\n",
      "episode 10, val func loss 1.0425822734832764\n",
      "\n",
      "episode 11, val func loss 1.0294189453125\n",
      "\n",
      "episode 12, val func loss 1.1656858921051025\n",
      "\n",
      "episode 13, val func loss 1.150579571723938\n",
      "\n",
      "episode 14, val func loss 0.9894598722457886\n",
      "\n",
      "episode 15, val func loss 1.2692652940750122\n",
      "\n",
      "episode 16, val func loss 1.0275722742080688\n",
      "\n",
      "Val func train loss in epoch 9:1.0807696431875229\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.2653768062591553\n",
      "\n",
      "episode 2, val func loss 1.1500494480133057\n",
      "\n",
      "episode 3, val func loss 1.1445354223251343\n",
      "\n",
      "episode 4, val func loss 0.9951131343841553\n",
      "\n",
      "episode 5, val func loss 1.0148816108703613\n",
      "\n",
      "episode 6, val func loss 0.9838461875915527\n",
      "\n",
      "episode 7, val func loss 1.1721853017807007\n",
      "\n",
      "episode 8, val func loss 1.0486754179000854\n",
      "\n",
      "episode 9, val func loss 1.0183742046356201\n",
      "\n",
      "episode 10, val func loss 1.0225374698638916\n",
      "\n",
      "episode 11, val func loss 1.1943305730819702\n",
      "\n",
      "episode 12, val func loss 1.0073283910751343\n",
      "\n",
      "episode 13, val func loss 1.1711230278015137\n",
      "\n",
      "episode 14, val func loss 1.1577413082122803\n",
      "\n",
      "episode 15, val func loss 0.9800867438316345\n",
      "\n",
      "episode 16, val func loss 1.097042202949524\n",
      "\n",
      "Val func train loss in epoch 10:1.0889517031610012\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.0574157238006592\n",
      "\n",
      "episode 2, val func loss 0.9995233416557312\n",
      "\n",
      "episode 3, val func loss 1.1085929870605469\n",
      "\n",
      "episode 4, val func loss 1.2148984670639038\n",
      "\n",
      "episode 5, val func loss 1.179436206817627\n",
      "\n",
      "episode 6, val func loss 1.0922858715057373\n",
      "\n",
      "episode 7, val func loss 1.1218355894088745\n",
      "\n",
      "episode 8, val func loss 1.0678038597106934\n",
      "\n",
      "episode 9, val func loss 0.9877289533615112\n",
      "\n",
      "episode 10, val func loss 1.2090680599212646\n",
      "\n",
      "episode 11, val func loss 0.9270985126495361\n",
      "\n",
      "episode 12, val func loss 0.9931959509849548\n",
      "\n",
      "episode 13, val func loss 1.1661767959594727\n",
      "\n",
      "episode 14, val func loss 1.2042205333709717\n",
      "\n",
      "episode 15, val func loss 1.1708335876464844\n",
      "\n",
      "episode 16, val func loss 1.1103253364562988\n",
      "\n",
      "Val func train loss in epoch 11:1.1006524860858917\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.0303720235824585\n",
      "\n",
      "episode 2, val func loss 1.1329619884490967\n",
      "\n",
      "episode 3, val func loss 1.140116810798645\n",
      "\n",
      "episode 4, val func loss 1.1224849224090576\n",
      "\n",
      "episode 5, val func loss 1.0150445699691772\n",
      "\n",
      "episode 6, val func loss 1.206455945968628\n",
      "\n",
      "episode 7, val func loss 1.1155574321746826\n",
      "\n",
      "episode 8, val func loss 1.11741304397583\n",
      "\n",
      "episode 9, val func loss 1.0921934843063354\n",
      "\n",
      "episode 10, val func loss 1.069774866104126\n",
      "\n",
      "episode 11, val func loss 1.0286872386932373\n",
      "\n",
      "episode 12, val func loss 1.072089672088623\n",
      "\n",
      "episode 13, val func loss 0.9502723813056946\n",
      "\n",
      "episode 14, val func loss 1.0946041345596313\n",
      "\n",
      "episode 15, val func loss 1.235184669494629\n",
      "\n",
      "episode 16, val func loss 1.2183743715286255\n",
      "\n",
      "Val func train loss in epoch 12:1.1025992222130299\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.0549484491348267\n",
      "\n",
      "episode 2, val func loss 1.1753705739974976\n",
      "\n",
      "episode 3, val func loss 1.0972462892532349\n",
      "\n",
      "episode 4, val func loss 1.1557773351669312\n",
      "\n",
      "episode 5, val func loss 1.1013734340667725\n",
      "\n",
      "episode 6, val func loss 1.0915817022323608\n",
      "\n",
      "episode 7, val func loss 0.9762440919876099\n",
      "\n",
      "episode 8, val func loss 0.9620804190635681\n",
      "\n",
      "episode 9, val func loss 1.0741961002349854\n",
      "\n",
      "episode 10, val func loss 1.0932680368423462\n",
      "\n",
      "episode 11, val func loss 0.9778342247009277\n",
      "\n",
      "episode 12, val func loss 1.075269103050232\n",
      "\n",
      "episode 13, val func loss 1.1770031452178955\n",
      "\n",
      "episode 14, val func loss 1.030478835105896\n",
      "\n",
      "episode 15, val func loss 1.1669604778289795\n",
      "\n",
      "episode 16, val func loss 1.1918270587921143\n",
      "\n",
      "Val func train loss in epoch 13:1.0875912047922611\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.176002025604248\n",
      "\n",
      "episode 2, val func loss 0.9672991633415222\n",
      "\n",
      "episode 3, val func loss 1.0354859828948975\n",
      "\n",
      "episode 4, val func loss 1.0537973642349243\n",
      "\n",
      "episode 5, val func loss 1.2392797470092773\n",
      "\n",
      "episode 6, val func loss 1.2031631469726562\n",
      "\n",
      "episode 7, val func loss 1.0673549175262451\n",
      "\n",
      "episode 8, val func loss 1.2016706466674805\n",
      "\n",
      "episode 9, val func loss 1.134072184562683\n",
      "\n",
      "episode 10, val func loss 0.9251036047935486\n",
      "\n",
      "episode 11, val func loss 0.9169237017631531\n",
      "\n",
      "episode 12, val func loss 1.0910471677780151\n",
      "\n",
      "episode 13, val func loss 0.9547139406204224\n",
      "\n",
      "episode 14, val func loss 1.2892968654632568\n",
      "\n",
      "episode 15, val func loss 1.2752151489257812\n",
      "\n",
      "episode 16, val func loss 0.9425210952758789\n",
      "\n",
      "Val func train loss in epoch 14:1.0920591689646244\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.0278576612472534\n",
      "\n",
      "episode 2, val func loss 0.9882856011390686\n",
      "\n",
      "episode 3, val func loss 1.0355042219161987\n",
      "\n",
      "episode 4, val func loss 0.968226432800293\n",
      "\n",
      "episode 5, val func loss 1.2499979734420776\n",
      "\n",
      "episode 6, val func loss 0.9842039942741394\n",
      "\n",
      "episode 7, val func loss 1.100183367729187\n",
      "\n",
      "episode 8, val func loss 0.9064931869506836\n",
      "\n",
      "episode 9, val func loss 0.9802523255348206\n",
      "\n",
      "episode 10, val func loss 1.167220950126648\n",
      "\n",
      "episode 11, val func loss 1.1783013343811035\n",
      "\n",
      "episode 12, val func loss 0.9642117023468018\n",
      "\n",
      "episode 13, val func loss 1.1870630979537964\n",
      "\n",
      "episode 14, val func loss 1.0393458604812622\n",
      "\n",
      "episode 15, val func loss 1.0885004997253418\n",
      "\n",
      "episode 16, val func loss 0.9991155862808228\n",
      "\n",
      "Val func train loss in epoch 15:1.0540477372705936\n",
      "***********************TIME WAS 4.851862851778666 min*****************************\n",
      "\n",
      "**********************ROUND 77 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.296072244644165\n",
      "\n",
      "episode 2, policy loss -3.296072006225586\n",
      "\n",
      "episode 3, policy loss -3.296072006225586\n",
      "\n",
      "episode 4, policy loss -3.296072006225586\n",
      "\n",
      "episode 5, policy loss -3.296072006225586\n",
      "\n",
      "episode 6, policy loss -3.296072006225586\n",
      "\n",
      "episode 7, policy loss -3.296072006225586\n",
      "\n",
      "episode 8, policy loss -3.296072006225586\n",
      "\n",
      "episode 9, policy loss -3.296072006225586\n",
      "\n",
      "episode 10, policy loss -3.296072006225586\n",
      "\n",
      "episode 11, policy loss -3.296072006225586\n",
      "\n",
      "episode 12, policy loss -3.296072006225586\n",
      "\n",
      "episode 13, policy loss -3.296072006225586\n",
      "\n",
      "episode 14, policy loss -3.296072006225586\n",
      "\n",
      "episode 15, policy loss -3.296072006225586\n",
      "\n",
      "episode 16, policy loss -3.296072006225586\n",
      "\n",
      "Policy train loss in epoch 0:-3.296072021126747\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.296072244644165\n",
      "\n",
      "episode 2, policy loss -3.296072006225586\n",
      "\n",
      "episode 3, policy loss -3.296072006225586\n",
      "\n",
      "episode 4, policy loss -3.296072006225586\n",
      "\n",
      "episode 5, policy loss -3.296072006225586\n",
      "\n",
      "episode 6, policy loss -3.296072006225586\n",
      "\n",
      "episode 7, policy loss -3.296072006225586\n",
      "\n",
      "episode 8, policy loss -3.296072006225586\n",
      "\n",
      "episode 9, policy loss -3.296072006225586\n",
      "\n",
      "episode 10, policy loss -3.296072006225586\n",
      "\n",
      "episode 11, policy loss -3.296072006225586\n",
      "\n",
      "episode 12, policy loss -3.296072244644165\n",
      "\n",
      "episode 13, policy loss -3.296072006225586\n",
      "\n",
      "episode 14, policy loss -3.296072006225586\n",
      "\n",
      "episode 15, policy loss -3.296072006225586\n",
      "\n",
      "episode 16, policy loss -3.296072006225586\n",
      "\n",
      "Policy train loss in epoch 1:-3.2960720360279083\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.296072244644165\n",
      "\n",
      "episode 2, policy loss -3.296072006225586\n",
      "\n",
      "episode 3, policy loss -3.296072006225586\n",
      "\n",
      "episode 4, policy loss -3.296072006225586\n",
      "\n",
      "episode 5, policy loss -3.296072006225586\n",
      "\n",
      "episode 6, policy loss -3.296072006225586\n",
      "\n",
      "episode 7, policy loss -3.296072244644165\n",
      "\n",
      "episode 8, policy loss -3.296072244644165\n",
      "\n",
      "episode 9, policy loss -3.296072244644165\n",
      "\n",
      "episode 10, policy loss -3.296072006225586\n",
      "\n",
      "episode 11, policy loss -3.296072006225586\n",
      "\n",
      "episode 12, policy loss -3.296072006225586\n",
      "\n",
      "episode 13, policy loss -3.296072006225586\n",
      "\n",
      "episode 14, policy loss -3.296072244644165\n",
      "\n",
      "episode 15, policy loss -3.296072006225586\n",
      "\n",
      "episode 16, policy loss -3.296072006225586\n",
      "\n",
      "Policy train loss in epoch 2:-3.296072080731392\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.296072006225586\n",
      "\n",
      "episode 2, policy loss -3.296072006225586\n",
      "\n",
      "episode 3, policy loss -3.296072244644165\n",
      "\n",
      "episode 4, policy loss -3.296072244644165\n",
      "\n",
      "episode 5, policy loss -3.296072244644165\n",
      "\n",
      "episode 6, policy loss -3.296072244644165\n",
      "\n",
      "episode 7, policy loss -3.296072006225586\n",
      "\n",
      "episode 8, policy loss -3.296072006225586\n",
      "\n",
      "episode 9, policy loss -3.296072006225586\n",
      "\n",
      "episode 10, policy loss -3.296072006225586\n",
      "\n",
      "episode 11, policy loss -3.296072006225586\n",
      "\n",
      "episode 12, policy loss -3.296072006225586\n",
      "\n",
      "episode 13, policy loss -3.296072006225586\n",
      "\n",
      "episode 14, policy loss -3.296072006225586\n",
      "\n",
      "episode 15, policy loss -3.296072006225586\n",
      "\n",
      "episode 16, policy loss -3.296072006225586\n",
      "\n",
      "Policy train loss in epoch 3:-3.2960720658302307\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.2274190187454224\n",
      "\n",
      "episode 2, val func loss 1.0123372077941895\n",
      "\n",
      "episode 3, val func loss 1.0785243511199951\n",
      "\n",
      "episode 4, val func loss 1.1007860898971558\n",
      "\n",
      "episode 5, val func loss 1.130372405052185\n",
      "\n",
      "episode 6, val func loss 1.0443321466445923\n",
      "\n",
      "episode 7, val func loss 0.9772678017616272\n",
      "\n",
      "episode 8, val func loss 0.9735049605369568\n",
      "\n",
      "episode 9, val func loss 1.058395266532898\n",
      "\n",
      "episode 10, val func loss 0.9853816032409668\n",
      "\n",
      "episode 11, val func loss 1.2008781433105469\n",
      "\n",
      "episode 12, val func loss 1.1108245849609375\n",
      "\n",
      "episode 13, val func loss 1.0641582012176514\n",
      "\n",
      "episode 14, val func loss 1.0782233476638794\n",
      "\n",
      "episode 15, val func loss 1.022222876548767\n",
      "\n",
      "episode 16, val func loss 1.142769694328308\n",
      "\n",
      "Val func train loss in epoch 0:1.075462356209755\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.1041858196258545\n",
      "\n",
      "episode 2, val func loss 1.0426985025405884\n",
      "\n",
      "episode 3, val func loss 1.0828319787979126\n",
      "\n",
      "episode 4, val func loss 0.965220034122467\n",
      "\n",
      "episode 5, val func loss 0.9670596718788147\n",
      "\n",
      "episode 6, val func loss 1.0479861497879028\n",
      "\n",
      "episode 7, val func loss 1.0112318992614746\n",
      "\n",
      "episode 8, val func loss 1.1086666584014893\n",
      "\n",
      "episode 9, val func loss 0.9965659379959106\n",
      "\n",
      "episode 10, val func loss 1.008876085281372\n",
      "\n",
      "episode 11, val func loss 1.0674629211425781\n",
      "\n",
      "episode 12, val func loss 1.0113765001296997\n",
      "\n",
      "episode 13, val func loss 0.9118309020996094\n",
      "\n",
      "episode 14, val func loss 1.026533603668213\n",
      "\n",
      "episode 15, val func loss 1.0604541301727295\n",
      "\n",
      "episode 16, val func loss 1.098388910293579\n",
      "\n",
      "Val func train loss in epoch 1:1.0319606065750122\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.996562123298645\n",
      "\n",
      "episode 2, val func loss 1.1825145483016968\n",
      "\n",
      "episode 3, val func loss 1.063583254814148\n",
      "\n",
      "episode 4, val func loss 1.2002885341644287\n",
      "\n",
      "episode 5, val func loss 1.0578994750976562\n",
      "\n",
      "episode 6, val func loss 1.0901437997817993\n",
      "\n",
      "episode 7, val func loss 1.152518630027771\n",
      "\n",
      "episode 8, val func loss 1.2180302143096924\n",
      "\n",
      "episode 9, val func loss 1.1700202226638794\n",
      "\n",
      "episode 10, val func loss 0.9995099306106567\n",
      "\n",
      "episode 11, val func loss 1.0451130867004395\n",
      "\n",
      "episode 12, val func loss 1.094632863998413\n",
      "\n",
      "episode 13, val func loss 0.9162932634353638\n",
      "\n",
      "episode 14, val func loss 1.0566993951797485\n",
      "\n",
      "episode 15, val func loss 1.0999714136123657\n",
      "\n",
      "episode 16, val func loss 1.0872175693511963\n",
      "\n",
      "Val func train loss in epoch 2:1.0894373953342438\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.1336597204208374\n",
      "\n",
      "episode 2, val func loss 1.1074333190917969\n",
      "\n",
      "episode 3, val func loss 1.062825322151184\n",
      "\n",
      "episode 4, val func loss 1.0309391021728516\n",
      "\n",
      "episode 5, val func loss 1.0995925664901733\n",
      "\n",
      "episode 6, val func loss 1.0173993110656738\n",
      "\n",
      "episode 7, val func loss 1.1289527416229248\n",
      "\n",
      "episode 8, val func loss 1.0335915088653564\n",
      "\n",
      "episode 9, val func loss 1.0268651247024536\n",
      "\n",
      "episode 10, val func loss 1.1168408393859863\n",
      "\n",
      "episode 11, val func loss 1.0208923816680908\n",
      "\n",
      "episode 12, val func loss 1.012067437171936\n",
      "\n",
      "episode 13, val func loss 1.1526567935943604\n",
      "\n",
      "episode 14, val func loss 1.0811132192611694\n",
      "\n",
      "episode 15, val func loss 0.8549602627754211\n",
      "\n",
      "episode 16, val func loss 1.091712474822998\n",
      "\n",
      "Val func train loss in epoch 3:1.0607188828289509\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.1309627294540405\n",
      "\n",
      "episode 2, val func loss 1.0385316610336304\n",
      "\n",
      "episode 3, val func loss 1.1394037008285522\n",
      "\n",
      "episode 4, val func loss 0.9287635087966919\n",
      "\n",
      "episode 5, val func loss 1.0496037006378174\n",
      "\n",
      "episode 6, val func loss 0.925858736038208\n",
      "\n",
      "episode 7, val func loss 1.124002456665039\n",
      "\n",
      "episode 8, val func loss 0.9770087003707886\n",
      "\n",
      "episode 9, val func loss 1.0727430582046509\n",
      "\n",
      "episode 10, val func loss 0.94223552942276\n",
      "\n",
      "episode 11, val func loss 1.05802321434021\n",
      "\n",
      "episode 12, val func loss 0.9410403966903687\n",
      "\n",
      "episode 13, val func loss 1.0631006956100464\n",
      "\n",
      "episode 14, val func loss 1.0121322870254517\n",
      "\n",
      "episode 15, val func loss 1.0503565073013306\n",
      "\n",
      "episode 16, val func loss 1.0798590183258057\n",
      "\n",
      "Val func train loss in epoch 4:1.033351618796587\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.9606499075889587\n",
      "\n",
      "episode 2, val func loss 1.0152727365493774\n",
      "\n",
      "episode 3, val func loss 1.043014645576477\n",
      "\n",
      "episode 4, val func loss 0.9139124155044556\n",
      "\n",
      "episode 5, val func loss 1.15351402759552\n",
      "\n",
      "episode 6, val func loss 1.0592753887176514\n",
      "\n",
      "episode 7, val func loss 1.2920570373535156\n",
      "\n",
      "episode 8, val func loss 1.1184996366500854\n",
      "\n",
      "episode 9, val func loss 1.2599860429763794\n",
      "\n",
      "episode 10, val func loss 1.023703694343567\n",
      "\n",
      "episode 11, val func loss 1.0209628343582153\n",
      "\n",
      "episode 12, val func loss 0.9167908430099487\n",
      "\n",
      "episode 13, val func loss 1.2122914791107178\n",
      "\n",
      "episode 14, val func loss 0.9648784399032593\n",
      "\n",
      "episode 15, val func loss 1.1632821559906006\n",
      "\n",
      "episode 16, val func loss 1.081274151802063\n",
      "\n",
      "Val func train loss in epoch 5:1.0749603398144245\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.9071504473686218\n",
      "\n",
      "episode 2, val func loss 1.1920331716537476\n",
      "\n",
      "episode 3, val func loss 1.1168080568313599\n",
      "\n",
      "episode 4, val func loss 1.071407437324524\n",
      "\n",
      "episode 5, val func loss 1.0029596090316772\n",
      "\n",
      "episode 6, val func loss 0.9743310809135437\n",
      "\n",
      "episode 7, val func loss 0.9275342226028442\n",
      "\n",
      "episode 8, val func loss 1.044600248336792\n",
      "\n",
      "episode 9, val func loss 1.0713486671447754\n",
      "\n",
      "episode 10, val func loss 0.8952444195747375\n",
      "\n",
      "episode 11, val func loss 1.0084785223007202\n",
      "\n",
      "episode 12, val func loss 1.0614880323410034\n",
      "\n",
      "episode 13, val func loss 1.0622978210449219\n",
      "\n",
      "episode 14, val func loss 1.0323046445846558\n",
      "\n",
      "episode 15, val func loss 1.0700652599334717\n",
      "\n",
      "episode 16, val func loss 0.9161834716796875\n",
      "\n",
      "Val func train loss in epoch 6:1.0221396945416927\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.0102012157440186\n",
      "\n",
      "episode 2, val func loss 1.0437371730804443\n",
      "\n",
      "episode 3, val func loss 1.0631933212280273\n",
      "\n",
      "episode 4, val func loss 1.0861210823059082\n",
      "\n",
      "episode 5, val func loss 1.1189433336257935\n",
      "\n",
      "episode 6, val func loss 1.112270712852478\n",
      "\n",
      "episode 7, val func loss 1.007170557975769\n",
      "\n",
      "episode 8, val func loss 1.0536646842956543\n",
      "\n",
      "episode 9, val func loss 1.1296111345291138\n",
      "\n",
      "episode 10, val func loss 0.9608527421951294\n",
      "\n",
      "episode 11, val func loss 0.8945670127868652\n",
      "\n",
      "episode 12, val func loss 1.039429783821106\n",
      "\n",
      "episode 13, val func loss 1.0906143188476562\n",
      "\n",
      "episode 14, val func loss 1.0232897996902466\n",
      "\n",
      "episode 15, val func loss 1.1000701189041138\n",
      "\n",
      "episode 16, val func loss 1.1200273036956787\n",
      "\n",
      "Val func train loss in epoch 7:1.0533602684736252\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.9852656126022339\n",
      "\n",
      "episode 2, val func loss 0.960287868976593\n",
      "\n",
      "episode 3, val func loss 0.9822489023208618\n",
      "\n",
      "episode 4, val func loss 1.0591676235198975\n",
      "\n",
      "episode 5, val func loss 1.0330133438110352\n",
      "\n",
      "episode 6, val func loss 1.047202706336975\n",
      "\n",
      "episode 7, val func loss 1.142552375793457\n",
      "\n",
      "episode 8, val func loss 0.9565825462341309\n",
      "\n",
      "episode 9, val func loss 1.012359857559204\n",
      "\n",
      "episode 10, val func loss 1.0779809951782227\n",
      "\n",
      "episode 11, val func loss 0.9532684087753296\n",
      "\n",
      "episode 12, val func loss 1.163155436515808\n",
      "\n",
      "episode 13, val func loss 1.0124646425247192\n",
      "\n",
      "episode 14, val func loss 1.050065279006958\n",
      "\n",
      "episode 15, val func loss 1.0385488271713257\n",
      "\n",
      "episode 16, val func loss 0.9449670314788818\n",
      "\n",
      "Val func train loss in epoch 8:1.026195716112852\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.0273785591125488\n",
      "\n",
      "episode 2, val func loss 1.0923606157302856\n",
      "\n",
      "episode 3, val func loss 0.9015688896179199\n",
      "\n",
      "episode 4, val func loss 1.0744900703430176\n",
      "\n",
      "episode 5, val func loss 0.9807446002960205\n",
      "\n",
      "episode 6, val func loss 0.9235467910766602\n",
      "\n",
      "episode 7, val func loss 0.9449381828308105\n",
      "\n",
      "episode 8, val func loss 0.9379251003265381\n",
      "\n",
      "episode 9, val func loss 0.9764784574508667\n",
      "\n",
      "episode 10, val func loss 1.0342363119125366\n",
      "\n",
      "episode 11, val func loss 1.1757904291152954\n",
      "\n",
      "episode 12, val func loss 0.8983245491981506\n",
      "\n",
      "episode 13, val func loss 1.2007039785385132\n",
      "\n",
      "episode 14, val func loss 1.1155368089675903\n",
      "\n",
      "episode 15, val func loss 1.2187753915786743\n",
      "\n",
      "episode 16, val func loss 1.098436951637268\n",
      "\n",
      "Val func train loss in epoch 9:1.0375772304832935\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.0454295873641968\n",
      "\n",
      "episode 2, val func loss 1.1286410093307495\n",
      "\n",
      "episode 3, val func loss 1.1428391933441162\n",
      "\n",
      "episode 4, val func loss 1.221977949142456\n",
      "\n",
      "episode 5, val func loss 1.028416633605957\n",
      "\n",
      "episode 6, val func loss 1.0354644060134888\n",
      "\n",
      "episode 7, val func loss 1.1482138633728027\n",
      "\n",
      "episode 8, val func loss 1.0485634803771973\n",
      "\n",
      "episode 9, val func loss 1.036259412765503\n",
      "\n",
      "episode 10, val func loss 1.158825397491455\n",
      "\n",
      "episode 11, val func loss 1.1820037364959717\n",
      "\n",
      "episode 12, val func loss 1.0256561040878296\n",
      "\n",
      "episode 13, val func loss 0.9854222536087036\n",
      "\n",
      "episode 14, val func loss 1.0829112529754639\n",
      "\n",
      "episode 15, val func loss 1.0239900350570679\n",
      "\n",
      "episode 16, val func loss 1.1959885358810425\n",
      "\n",
      "Val func train loss in epoch 10:1.093162678182125\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.0402683019638062\n",
      "\n",
      "episode 2, val func loss 1.096575379371643\n",
      "\n",
      "episode 3, val func loss 1.1776982545852661\n",
      "\n",
      "episode 4, val func loss 0.9627811908721924\n",
      "\n",
      "episode 5, val func loss 1.2043055295944214\n",
      "\n",
      "episode 6, val func loss 1.0097086429595947\n",
      "\n",
      "episode 7, val func loss 1.1825364828109741\n",
      "\n",
      "episode 8, val func loss 1.1155169010162354\n",
      "\n",
      "episode 9, val func loss 1.1464439630508423\n",
      "\n",
      "episode 10, val func loss 1.0034165382385254\n",
      "\n",
      "episode 11, val func loss 0.9011552333831787\n",
      "\n",
      "episode 12, val func loss 0.8927130103111267\n",
      "\n",
      "episode 13, val func loss 0.8465344309806824\n",
      "\n",
      "episode 14, val func loss 0.9898000359535217\n",
      "\n",
      "episode 15, val func loss 0.9630982875823975\n",
      "\n",
      "episode 16, val func loss 0.9292780160903931\n",
      "\n",
      "Val func train loss in epoch 11:1.0288643874228\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.0014907121658325\n",
      "\n",
      "episode 2, val func loss 1.0784873962402344\n",
      "\n",
      "episode 3, val func loss 0.888683557510376\n",
      "\n",
      "episode 4, val func loss 1.0476806163787842\n",
      "\n",
      "episode 5, val func loss 0.9911229014396667\n",
      "\n",
      "episode 6, val func loss 0.8749542236328125\n",
      "\n",
      "episode 7, val func loss 1.0012613534927368\n",
      "\n",
      "episode 8, val func loss 0.9906332492828369\n",
      "\n",
      "episode 9, val func loss 0.8503080010414124\n",
      "\n",
      "episode 10, val func loss 0.8836044073104858\n",
      "\n",
      "episode 11, val func loss 1.0186924934387207\n",
      "\n",
      "episode 12, val func loss 0.9801645874977112\n",
      "\n",
      "episode 13, val func loss 0.8771906495094299\n",
      "\n",
      "episode 14, val func loss 0.9790922999382019\n",
      "\n",
      "episode 15, val func loss 0.9745410680770874\n",
      "\n",
      "episode 16, val func loss 1.1812225580215454\n",
      "\n",
      "Val func train loss in epoch 12:0.9761956296861172\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.9567694664001465\n",
      "\n",
      "episode 2, val func loss 0.8841887712478638\n",
      "\n",
      "episode 3, val func loss 1.0193490982055664\n",
      "\n",
      "episode 4, val func loss 1.0672048330307007\n",
      "\n",
      "episode 5, val func loss 1.0470070838928223\n",
      "\n",
      "episode 6, val func loss 0.9750520586967468\n",
      "\n",
      "episode 7, val func loss 0.9127851128578186\n",
      "\n",
      "episode 8, val func loss 1.049340009689331\n",
      "\n",
      "episode 9, val func loss 1.0331133604049683\n",
      "\n",
      "episode 10, val func loss 1.0538370609283447\n",
      "\n",
      "episode 11, val func loss 0.9384989142417908\n",
      "\n",
      "episode 12, val func loss 0.9602630734443665\n",
      "\n",
      "episode 13, val func loss 1.0561634302139282\n",
      "\n",
      "episode 14, val func loss 0.9484918117523193\n",
      "\n",
      "episode 15, val func loss 1.0561326742172241\n",
      "\n",
      "episode 16, val func loss 0.9012570977210999\n",
      "\n",
      "Val func train loss in epoch 13:0.9912158660590649\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.917856752872467\n",
      "\n",
      "episode 2, val func loss 1.0213910341262817\n",
      "\n",
      "episode 3, val func loss 1.0428814888000488\n",
      "\n",
      "episode 4, val func loss 0.9337899684906006\n",
      "\n",
      "episode 5, val func loss 1.0102849006652832\n",
      "\n",
      "episode 6, val func loss 1.2231032848358154\n",
      "\n",
      "episode 7, val func loss 1.1136263608932495\n",
      "\n",
      "episode 8, val func loss 0.8880369663238525\n",
      "\n",
      "episode 9, val func loss 0.8999647498130798\n",
      "\n",
      "episode 10, val func loss 1.2002122402191162\n",
      "\n",
      "episode 11, val func loss 0.9794366359710693\n",
      "\n",
      "episode 12, val func loss 0.9118284583091736\n",
      "\n",
      "episode 13, val func loss 0.9668899178504944\n",
      "\n",
      "episode 14, val func loss 0.9377192854881287\n",
      "\n",
      "episode 15, val func loss 0.9146196246147156\n",
      "\n",
      "episode 16, val func loss 0.8754850625991821\n",
      "\n",
      "Val func train loss in epoch 14:0.9898204207420349\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.0517120361328125\n",
      "\n",
      "episode 2, val func loss 1.117066740989685\n",
      "\n",
      "episode 3, val func loss 1.118951678276062\n",
      "\n",
      "episode 4, val func loss 0.8900701999664307\n",
      "\n",
      "episode 5, val func loss 1.0184284448623657\n",
      "\n",
      "episode 6, val func loss 0.9763907194137573\n",
      "\n",
      "episode 7, val func loss 1.0100516080856323\n",
      "\n",
      "episode 8, val func loss 0.8941929340362549\n",
      "\n",
      "episode 9, val func loss 0.9965853691101074\n",
      "\n",
      "episode 10, val func loss 1.0115025043487549\n",
      "\n",
      "episode 11, val func loss 0.9591563940048218\n",
      "\n",
      "episode 12, val func loss 0.8693013787269592\n",
      "\n",
      "episode 13, val func loss 1.0752524137496948\n",
      "\n",
      "episode 14, val func loss 1.1687235832214355\n",
      "\n",
      "episode 15, val func loss 0.8623166680335999\n",
      "\n",
      "episode 16, val func loss 1.1014039516448975\n",
      "\n",
      "Val func train loss in epoch 15:1.0075691640377045\n",
      "***********************TIME WAS 4.857058425744374 min*****************************\n",
      "\n",
      "**********************ROUND 78 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.274083375930786\n",
      "\n",
      "episode 2, policy loss -2.274083375930786\n",
      "\n",
      "episode 3, policy loss -2.274083375930786\n",
      "\n",
      "episode 4, policy loss -2.274083375930786\n",
      "\n",
      "episode 5, policy loss -2.274083375930786\n",
      "\n",
      "episode 6, policy loss -2.274083375930786\n",
      "\n",
      "episode 7, policy loss -2.274083375930786\n",
      "\n",
      "episode 8, policy loss -2.274083375930786\n",
      "\n",
      "episode 9, policy loss -2.274083375930786\n",
      "\n",
      "episode 10, policy loss -2.274083375930786\n",
      "\n",
      "episode 11, policy loss -2.274083375930786\n",
      "\n",
      "episode 12, policy loss -2.274083375930786\n",
      "\n",
      "episode 13, policy loss -2.274083375930786\n",
      "\n",
      "episode 14, policy loss -2.274083375930786\n",
      "\n",
      "episode 15, policy loss -2.274083375930786\n",
      "\n",
      "episode 16, policy loss -2.274083375930786\n",
      "\n",
      "Policy train loss in epoch 0:-2.274083375930786\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.274083375930786\n",
      "\n",
      "episode 2, policy loss -2.274083375930786\n",
      "\n",
      "episode 3, policy loss -2.274083375930786\n",
      "\n",
      "episode 4, policy loss -2.274083375930786\n",
      "\n",
      "episode 5, policy loss -2.274083375930786\n",
      "\n",
      "episode 6, policy loss -2.274083375930786\n",
      "\n",
      "episode 7, policy loss -2.274083375930786\n",
      "\n",
      "episode 8, policy loss -2.274083375930786\n",
      "\n",
      "episode 9, policy loss -2.274083375930786\n",
      "\n",
      "episode 10, policy loss -2.274083375930786\n",
      "\n",
      "episode 11, policy loss -2.274083375930786\n",
      "\n",
      "episode 12, policy loss -2.274083375930786\n",
      "\n",
      "episode 13, policy loss -2.274083375930786\n",
      "\n",
      "episode 14, policy loss -2.274083375930786\n",
      "\n",
      "episode 15, policy loss -2.274083375930786\n",
      "\n",
      "episode 16, policy loss -2.274083375930786\n",
      "\n",
      "Policy train loss in epoch 1:-2.274083375930786\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -2.274083375930786\n",
      "\n",
      "episode 2, policy loss -2.274083375930786\n",
      "\n",
      "episode 3, policy loss -2.274083375930786\n",
      "\n",
      "episode 4, policy loss -2.274083375930786\n",
      "\n",
      "episode 5, policy loss -2.274083375930786\n",
      "\n",
      "episode 6, policy loss -2.274083375930786\n",
      "\n",
      "episode 7, policy loss -2.274083375930786\n",
      "\n",
      "episode 8, policy loss -2.274083375930786\n",
      "\n",
      "episode 9, policy loss -2.274083375930786\n",
      "\n",
      "episode 10, policy loss -2.274083375930786\n",
      "\n",
      "episode 11, policy loss -2.274083375930786\n",
      "\n",
      "episode 12, policy loss -2.274083375930786\n",
      "\n",
      "episode 13, policy loss -2.274083375930786\n",
      "\n",
      "episode 14, policy loss -2.274083375930786\n",
      "\n",
      "episode 15, policy loss -2.274083375930786\n",
      "\n",
      "episode 16, policy loss -2.274083375930786\n",
      "\n",
      "Policy train loss in epoch 2:-2.274083375930786\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.274083375930786\n",
      "\n",
      "episode 2, policy loss -2.274083375930786\n",
      "\n",
      "episode 3, policy loss -2.274083375930786\n",
      "\n",
      "episode 4, policy loss -2.274083375930786\n",
      "\n",
      "episode 5, policy loss -2.274083375930786\n",
      "\n",
      "episode 6, policy loss -2.274083375930786\n",
      "\n",
      "episode 7, policy loss -2.274083375930786\n",
      "\n",
      "episode 8, policy loss -2.274083375930786\n",
      "\n",
      "episode 9, policy loss -2.274083375930786\n",
      "\n",
      "episode 10, policy loss -2.274083375930786\n",
      "\n",
      "episode 11, policy loss -2.274083375930786\n",
      "\n",
      "episode 12, policy loss -2.274083375930786\n",
      "\n",
      "episode 13, policy loss -2.274083375930786\n",
      "\n",
      "episode 14, policy loss -2.274083375930786\n",
      "\n",
      "episode 15, policy loss -2.274083375930786\n",
      "\n",
      "episode 16, policy loss -2.274083375930786\n",
      "\n",
      "Policy train loss in epoch 3:-2.274083375930786\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.0104790925979614\n",
      "\n",
      "episode 2, val func loss 1.026548981666565\n",
      "\n",
      "episode 3, val func loss 1.1319968700408936\n",
      "\n",
      "episode 4, val func loss 0.9397868514060974\n",
      "\n",
      "episode 5, val func loss 1.1000721454620361\n",
      "\n",
      "episode 6, val func loss 1.0085750818252563\n",
      "\n",
      "episode 7, val func loss 0.9946667551994324\n",
      "\n",
      "episode 8, val func loss 1.037797212600708\n",
      "\n",
      "episode 9, val func loss 0.9735373258590698\n",
      "\n",
      "episode 10, val func loss 0.8185887932777405\n",
      "\n",
      "episode 11, val func loss 0.9011509418487549\n",
      "\n",
      "episode 12, val func loss 0.8455296754837036\n",
      "\n",
      "episode 13, val func loss 0.9569960236549377\n",
      "\n",
      "episode 14, val func loss 0.9175458550453186\n",
      "\n",
      "episode 15, val func loss 1.0933864116668701\n",
      "\n",
      "episode 16, val func loss 0.9785942435264587\n",
      "\n",
      "Val func train loss in epoch 0:0.9834532663226128\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.1258023977279663\n",
      "\n",
      "episode 2, val func loss 0.8491340279579163\n",
      "\n",
      "episode 3, val func loss 0.9321532845497131\n",
      "\n",
      "episode 4, val func loss 1.0892635583877563\n",
      "\n",
      "episode 5, val func loss 1.0337659120559692\n",
      "\n",
      "episode 6, val func loss 0.9325453639030457\n",
      "\n",
      "episode 7, val func loss 0.7346717119216919\n",
      "\n",
      "episode 8, val func loss 1.0734518766403198\n",
      "\n",
      "episode 9, val func loss 0.9774243235588074\n",
      "\n",
      "episode 10, val func loss 0.9477905035018921\n",
      "\n",
      "episode 11, val func loss 0.9466859698295593\n",
      "\n",
      "episode 12, val func loss 0.9905443787574768\n",
      "\n",
      "episode 13, val func loss 0.8926481604576111\n",
      "\n",
      "episode 14, val func loss 0.9357687830924988\n",
      "\n",
      "episode 15, val func loss 1.1317631006240845\n",
      "\n",
      "episode 16, val func loss 0.8777205348014832\n",
      "\n",
      "Val func train loss in epoch 1:0.966945867985487\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.9493187665939331\n",
      "\n",
      "episode 2, val func loss 1.1123700141906738\n",
      "\n",
      "episode 3, val func loss 0.9887767434120178\n",
      "\n",
      "episode 4, val func loss 0.901982843875885\n",
      "\n",
      "episode 5, val func loss 1.0131962299346924\n",
      "\n",
      "episode 6, val func loss 1.0253976583480835\n",
      "\n",
      "episode 7, val func loss 0.9943105578422546\n",
      "\n",
      "episode 8, val func loss 1.07318913936615\n",
      "\n",
      "episode 9, val func loss 1.1023833751678467\n",
      "\n",
      "episode 10, val func loss 0.9185963869094849\n",
      "\n",
      "episode 11, val func loss 1.0526992082595825\n",
      "\n",
      "episode 12, val func loss 0.9883595705032349\n",
      "\n",
      "episode 13, val func loss 0.9829158186912537\n",
      "\n",
      "episode 14, val func loss 0.99498051404953\n",
      "\n",
      "episode 15, val func loss 0.9599165320396423\n",
      "\n",
      "episode 16, val func loss 1.2299981117248535\n",
      "\n",
      "Val func train loss in epoch 2:1.01802446693182\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8635768890380859\n",
      "\n",
      "episode 2, val func loss 0.9660043716430664\n",
      "\n",
      "episode 3, val func loss 1.1688567399978638\n",
      "\n",
      "episode 4, val func loss 1.0308479070663452\n",
      "\n",
      "episode 5, val func loss 1.0989673137664795\n",
      "\n",
      "episode 6, val func loss 1.1333515644073486\n",
      "\n",
      "episode 7, val func loss 0.9808011651039124\n",
      "\n",
      "episode 8, val func loss 1.0518289804458618\n",
      "\n",
      "episode 9, val func loss 1.1165096759796143\n",
      "\n",
      "episode 10, val func loss 0.9524779915809631\n",
      "\n",
      "episode 11, val func loss 1.0566561222076416\n",
      "\n",
      "episode 12, val func loss 0.9431189298629761\n",
      "\n",
      "episode 13, val func loss 1.0630565881729126\n",
      "\n",
      "episode 14, val func loss 1.002476692199707\n",
      "\n",
      "episode 15, val func loss 1.0407283306121826\n",
      "\n",
      "episode 16, val func loss 1.3400657176971436\n",
      "\n",
      "Val func train loss in epoch 3:1.0505828112363815\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7948419451713562\n",
      "\n",
      "episode 2, val func loss 0.9479259252548218\n",
      "\n",
      "episode 3, val func loss 1.3176863193511963\n",
      "\n",
      "episode 4, val func loss 1.0938085317611694\n",
      "\n",
      "episode 5, val func loss 1.000248670578003\n",
      "\n",
      "episode 6, val func loss 1.0162023305892944\n",
      "\n",
      "episode 7, val func loss 1.2347761392593384\n",
      "\n",
      "episode 8, val func loss 0.8515415191650391\n",
      "\n",
      "episode 9, val func loss 0.97366863489151\n",
      "\n",
      "episode 10, val func loss 1.0725512504577637\n",
      "\n",
      "episode 11, val func loss 1.1829463243484497\n",
      "\n",
      "episode 12, val func loss 1.0923066139221191\n",
      "\n",
      "episode 13, val func loss 0.8129967451095581\n",
      "\n",
      "episode 14, val func loss 0.8950008749961853\n",
      "\n",
      "episode 15, val func loss 0.9559520483016968\n",
      "\n",
      "episode 16, val func loss 0.7904735207557678\n",
      "\n",
      "Val func train loss in epoch 4:1.0020579621195793\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.0045336484909058\n",
      "\n",
      "episode 2, val func loss 0.8955110907554626\n",
      "\n",
      "episode 3, val func loss 0.9534348249435425\n",
      "\n",
      "episode 4, val func loss 0.9402331709861755\n",
      "\n",
      "episode 5, val func loss 0.984025239944458\n",
      "\n",
      "episode 6, val func loss 0.969139039516449\n",
      "\n",
      "episode 7, val func loss 0.954886257648468\n",
      "\n",
      "episode 8, val func loss 0.8267543911933899\n",
      "\n",
      "episode 9, val func loss 0.8541386127471924\n",
      "\n",
      "episode 10, val func loss 0.9979453682899475\n",
      "\n",
      "episode 11, val func loss 1.1103847026824951\n",
      "\n",
      "episode 12, val func loss 1.0535190105438232\n",
      "\n",
      "episode 13, val func loss 0.9655432105064392\n",
      "\n",
      "episode 14, val func loss 0.8886470198631287\n",
      "\n",
      "episode 15, val func loss 0.9740982055664062\n",
      "\n",
      "episode 16, val func loss 1.0516411066055298\n",
      "\n",
      "Val func train loss in epoch 5:0.9640271812677383\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.0347262620925903\n",
      "\n",
      "episode 2, val func loss 1.103468656539917\n",
      "\n",
      "episode 3, val func loss 0.8756412863731384\n",
      "\n",
      "episode 4, val func loss 0.9736645221710205\n",
      "\n",
      "episode 5, val func loss 0.8286049365997314\n",
      "\n",
      "episode 6, val func loss 1.0028525590896606\n",
      "\n",
      "episode 7, val func loss 1.0549510717391968\n",
      "\n",
      "episode 8, val func loss 0.9085870385169983\n",
      "\n",
      "episode 9, val func loss 1.1236428022384644\n",
      "\n",
      "episode 10, val func loss 0.8605644702911377\n",
      "\n",
      "episode 11, val func loss 0.8629301190376282\n",
      "\n",
      "episode 12, val func loss 1.0617042779922485\n",
      "\n",
      "episode 13, val func loss 0.9190160632133484\n",
      "\n",
      "episode 14, val func loss 0.9619765281677246\n",
      "\n",
      "episode 15, val func loss 0.9293873310089111\n",
      "\n",
      "episode 16, val func loss 0.9705074429512024\n",
      "\n",
      "Val func train loss in epoch 6:0.9670140855014324\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.9234943389892578\n",
      "\n",
      "episode 2, val func loss 0.821255087852478\n",
      "\n",
      "episode 3, val func loss 1.059934377670288\n",
      "\n",
      "episode 4, val func loss 1.0171068906784058\n",
      "\n",
      "episode 5, val func loss 1.0395557880401611\n",
      "\n",
      "episode 6, val func loss 1.017572283744812\n",
      "\n",
      "episode 7, val func loss 1.211011528968811\n",
      "\n",
      "episode 8, val func loss 0.9542356133460999\n",
      "\n",
      "episode 9, val func loss 0.9142311215400696\n",
      "\n",
      "episode 10, val func loss 1.0422580242156982\n",
      "\n",
      "episode 11, val func loss 0.9703712463378906\n",
      "\n",
      "episode 12, val func loss 0.8863967657089233\n",
      "\n",
      "episode 13, val func loss 0.9447663426399231\n",
      "\n",
      "episode 14, val func loss 0.9507005214691162\n",
      "\n",
      "episode 15, val func loss 1.104473352432251\n",
      "\n",
      "episode 16, val func loss 0.8191201686859131\n",
      "\n",
      "Val func train loss in epoch 7:0.9797802157700062\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.9587689638137817\n",
      "\n",
      "episode 2, val func loss 1.0615336894989014\n",
      "\n",
      "episode 3, val func loss 1.0560023784637451\n",
      "\n",
      "episode 4, val func loss 0.8763575553894043\n",
      "\n",
      "episode 5, val func loss 0.8938865065574646\n",
      "\n",
      "episode 6, val func loss 1.000696063041687\n",
      "\n",
      "episode 7, val func loss 0.8621709942817688\n",
      "\n",
      "episode 8, val func loss 0.9985880851745605\n",
      "\n",
      "episode 9, val func loss 0.8966116905212402\n",
      "\n",
      "episode 10, val func loss 1.073280692100525\n",
      "\n",
      "episode 11, val func loss 0.9800488948822021\n",
      "\n",
      "episode 12, val func loss 1.005466103553772\n",
      "\n",
      "episode 13, val func loss 1.0274529457092285\n",
      "\n",
      "episode 14, val func loss 0.9169347286224365\n",
      "\n",
      "episode 15, val func loss 0.8813416957855225\n",
      "\n",
      "episode 16, val func loss 1.1041361093521118\n",
      "\n",
      "Val func train loss in epoch 8:0.974579818546772\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.089643120765686\n",
      "\n",
      "episode 2, val func loss 0.9379672408103943\n",
      "\n",
      "episode 3, val func loss 1.061698079109192\n",
      "\n",
      "episode 4, val func loss 0.8680979013442993\n",
      "\n",
      "episode 5, val func loss 1.1484582424163818\n",
      "\n",
      "episode 6, val func loss 1.1497215032577515\n",
      "\n",
      "episode 7, val func loss 0.8552484512329102\n",
      "\n",
      "episode 8, val func loss 1.1629400253295898\n",
      "\n",
      "episode 9, val func loss 1.0650380849838257\n",
      "\n",
      "episode 10, val func loss 0.9046942591667175\n",
      "\n",
      "episode 11, val func loss 1.0151535272598267\n",
      "\n",
      "episode 12, val func loss 1.0072718858718872\n",
      "\n",
      "episode 13, val func loss 0.9273262023925781\n",
      "\n",
      "episode 14, val func loss 1.1101809740066528\n",
      "\n",
      "episode 15, val func loss 1.0171748399734497\n",
      "\n",
      "episode 16, val func loss 1.0276641845703125\n",
      "\n",
      "Val func train loss in epoch 9:1.021767407655716\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.117423176765442\n",
      "\n",
      "episode 2, val func loss 1.0070464611053467\n",
      "\n",
      "episode 3, val func loss 1.0509675741195679\n",
      "\n",
      "episode 4, val func loss 1.03621244430542\n",
      "\n",
      "episode 5, val func loss 0.9720256924629211\n",
      "\n",
      "episode 6, val func loss 1.0620146989822388\n",
      "\n",
      "episode 7, val func loss 1.009950876235962\n",
      "\n",
      "episode 8, val func loss 0.9695302844047546\n",
      "\n",
      "episode 9, val func loss 0.9919288754463196\n",
      "\n",
      "episode 10, val func loss 0.8901318311691284\n",
      "\n",
      "episode 11, val func loss 0.8209304213523865\n",
      "\n",
      "episode 12, val func loss 1.0012301206588745\n",
      "\n",
      "episode 13, val func loss 0.9163861870765686\n",
      "\n",
      "episode 14, val func loss 0.8855005502700806\n",
      "\n",
      "episode 15, val func loss 0.9445126056671143\n",
      "\n",
      "episode 16, val func loss 0.8565470576286316\n",
      "\n",
      "Val func train loss in epoch 10:0.9707711786031723\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9705926179885864\n",
      "\n",
      "episode 2, val func loss 0.9090896248817444\n",
      "\n",
      "episode 3, val func loss 0.9079079031944275\n",
      "\n",
      "episode 4, val func loss 1.111079454421997\n",
      "\n",
      "episode 5, val func loss 0.9565370082855225\n",
      "\n",
      "episode 6, val func loss 0.7826024293899536\n",
      "\n",
      "episode 7, val func loss 0.9777430891990662\n",
      "\n",
      "episode 8, val func loss 1.229701042175293\n",
      "\n",
      "episode 9, val func loss 0.922261118888855\n",
      "\n",
      "episode 10, val func loss 0.8568643927574158\n",
      "\n",
      "episode 11, val func loss 1.1858612298965454\n",
      "\n",
      "episode 12, val func loss 0.9929078221321106\n",
      "\n",
      "episode 13, val func loss 0.8886305689811707\n",
      "\n",
      "episode 14, val func loss 0.9044514894485474\n",
      "\n",
      "episode 15, val func loss 0.9112849831581116\n",
      "\n",
      "episode 16, val func loss 1.0941078662872314\n",
      "\n",
      "Val func train loss in epoch 11:0.9751014150679111\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.1138049364089966\n",
      "\n",
      "episode 2, val func loss 0.9136195778846741\n",
      "\n",
      "episode 3, val func loss 0.9244617819786072\n",
      "\n",
      "episode 4, val func loss 0.9564424157142639\n",
      "\n",
      "episode 5, val func loss 0.9358277916908264\n",
      "\n",
      "episode 6, val func loss 0.8915849924087524\n",
      "\n",
      "episode 7, val func loss 0.85802161693573\n",
      "\n",
      "episode 8, val func loss 0.9023231863975525\n",
      "\n",
      "episode 9, val func loss 1.0423266887664795\n",
      "\n",
      "episode 10, val func loss 1.0057592391967773\n",
      "\n",
      "episode 11, val func loss 1.0314394235610962\n",
      "\n",
      "episode 12, val func loss 0.9449846744537354\n",
      "\n",
      "episode 13, val func loss 0.9744253754615784\n",
      "\n",
      "episode 14, val func loss 0.9490343928337097\n",
      "\n",
      "episode 15, val func loss 0.9687607288360596\n",
      "\n",
      "episode 16, val func loss 1.0198456048965454\n",
      "\n",
      "Val func train loss in epoch 12:0.9645414017140865\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8773747682571411\n",
      "\n",
      "episode 2, val func loss 0.958954393863678\n",
      "\n",
      "episode 3, val func loss 0.8649259209632874\n",
      "\n",
      "episode 4, val func loss 0.8681973218917847\n",
      "\n",
      "episode 5, val func loss 0.8924708962440491\n",
      "\n",
      "episode 6, val func loss 0.9849153757095337\n",
      "\n",
      "episode 7, val func loss 0.8088297843933105\n",
      "\n",
      "episode 8, val func loss 0.9103196263313293\n",
      "\n",
      "episode 9, val func loss 0.8887465000152588\n",
      "\n",
      "episode 10, val func loss 0.947800874710083\n",
      "\n",
      "episode 11, val func loss 0.7261297702789307\n",
      "\n",
      "episode 12, val func loss 1.0080513954162598\n",
      "\n",
      "episode 13, val func loss 0.9695277810096741\n",
      "\n",
      "episode 14, val func loss 0.9597830176353455\n",
      "\n",
      "episode 15, val func loss 0.8944708704948425\n",
      "\n",
      "episode 16, val func loss 0.9451305866241455\n",
      "\n",
      "Val func train loss in epoch 13:0.9066018052399158\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.9231270551681519\n",
      "\n",
      "episode 2, val func loss 0.81980961561203\n",
      "\n",
      "episode 3, val func loss 1.0534993410110474\n",
      "\n",
      "episode 4, val func loss 1.0346343517303467\n",
      "\n",
      "episode 5, val func loss 1.0686370134353638\n",
      "\n",
      "episode 6, val func loss 0.9729849100112915\n",
      "\n",
      "episode 7, val func loss 0.8747765421867371\n",
      "\n",
      "episode 8, val func loss 0.9511539936065674\n",
      "\n",
      "episode 9, val func loss 0.9024396538734436\n",
      "\n",
      "episode 10, val func loss 0.8669416904449463\n",
      "\n",
      "episode 11, val func loss 0.9487838745117188\n",
      "\n",
      "episode 12, val func loss 0.9986806511878967\n",
      "\n",
      "episode 13, val func loss 0.892074704170227\n",
      "\n",
      "episode 14, val func loss 0.9075111150741577\n",
      "\n",
      "episode 15, val func loss 0.9148359298706055\n",
      "\n",
      "episode 16, val func loss 0.8799483180046082\n",
      "\n",
      "Val func train loss in epoch 14:0.9381149224936962\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.793373703956604\n",
      "\n",
      "episode 2, val func loss 1.076480507850647\n",
      "\n",
      "episode 3, val func loss 0.9423217177391052\n",
      "\n",
      "episode 4, val func loss 0.8679938912391663\n",
      "\n",
      "episode 5, val func loss 0.9888486862182617\n",
      "\n",
      "episode 6, val func loss 0.9452566504478455\n",
      "\n",
      "episode 7, val func loss 0.8307579755783081\n",
      "\n",
      "episode 8, val func loss 0.8926467895507812\n",
      "\n",
      "episode 9, val func loss 0.8934918642044067\n",
      "\n",
      "episode 10, val func loss 0.8903772234916687\n",
      "\n",
      "episode 11, val func loss 0.9167864322662354\n",
      "\n",
      "episode 12, val func loss 0.7830942273139954\n",
      "\n",
      "episode 13, val func loss 0.8432146310806274\n",
      "\n",
      "episode 14, val func loss 0.8410932421684265\n",
      "\n",
      "episode 15, val func loss 0.8876929879188538\n",
      "\n",
      "episode 16, val func loss 0.783678412437439\n",
      "\n",
      "Val func train loss in epoch 15:0.8860693089663982\n",
      "***********************TIME WAS 4.862529142697652 min*****************************\n",
      "\n",
      "**********************ROUND 79 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.9866376519203186\n",
      "\n",
      "episode 2, policy loss -0.9866376519203186\n",
      "\n",
      "episode 3, policy loss -0.9866376519203186\n",
      "\n",
      "episode 4, policy loss -0.9866376519203186\n",
      "\n",
      "episode 5, policy loss -0.9866376519203186\n",
      "\n",
      "episode 6, policy loss -0.9866376519203186\n",
      "\n",
      "episode 7, policy loss -0.9866376519203186\n",
      "\n",
      "episode 8, policy loss -0.9866376519203186\n",
      "\n",
      "episode 9, policy loss -0.9866377711296082\n",
      "\n",
      "episode 10, policy loss -0.9866376519203186\n",
      "\n",
      "episode 11, policy loss -0.9866376519203186\n",
      "\n",
      "episode 12, policy loss -0.9866376519203186\n",
      "\n",
      "episode 13, policy loss -0.9866376519203186\n",
      "\n",
      "episode 14, policy loss -0.9866377711296082\n",
      "\n",
      "episode 15, policy loss -0.9866377711296082\n",
      "\n",
      "episode 16, policy loss -0.9866375923156738\n",
      "\n",
      "Policy train loss in epoch 0:-0.9866376705467701\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.9866376519203186\n",
      "\n",
      "episode 2, policy loss -0.9866376519203186\n",
      "\n",
      "episode 3, policy loss -0.9866376519203186\n",
      "\n",
      "episode 4, policy loss -0.9866376519203186\n",
      "\n",
      "episode 5, policy loss -0.9866376519203186\n",
      "\n",
      "episode 6, policy loss -0.9866377711296082\n",
      "\n",
      "episode 7, policy loss -0.9866377711296082\n",
      "\n",
      "episode 8, policy loss -0.9866376519203186\n",
      "\n",
      "episode 9, policy loss -0.9866376519203186\n",
      "\n",
      "episode 10, policy loss -0.9866376519203186\n",
      "\n",
      "episode 11, policy loss -0.9866376519203186\n",
      "\n",
      "episode 12, policy loss -0.9866376519203186\n",
      "\n",
      "episode 13, policy loss -0.9866377711296082\n",
      "\n",
      "episode 14, policy loss -0.9866376519203186\n",
      "\n",
      "episode 15, policy loss -0.9866376519203186\n",
      "\n",
      "episode 16, policy loss -0.9866376519203186\n",
      "\n",
      "Policy train loss in epoch 1:-0.9866376742720604\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.9866376519203186\n",
      "\n",
      "episode 2, policy loss -0.9866376519203186\n",
      "\n",
      "episode 3, policy loss -0.9866376519203186\n",
      "\n",
      "episode 4, policy loss -0.9866376519203186\n",
      "\n",
      "episode 5, policy loss -0.9866377711296082\n",
      "\n",
      "episode 6, policy loss -0.9866376519203186\n",
      "\n",
      "episode 7, policy loss -0.9866376519203186\n",
      "\n",
      "episode 8, policy loss -0.9866376519203186\n",
      "\n",
      "episode 9, policy loss -0.9866377711296082\n",
      "\n",
      "episode 10, policy loss -0.9866376519203186\n",
      "\n",
      "episode 11, policy loss -0.9866376519203186\n",
      "\n",
      "episode 12, policy loss -0.9866376519203186\n",
      "\n",
      "episode 13, policy loss -0.9866376519203186\n",
      "\n",
      "episode 14, policy loss -0.9866376519203186\n",
      "\n",
      "episode 15, policy loss -0.9866376519203186\n",
      "\n",
      "episode 16, policy loss -0.9866377711296082\n",
      "\n",
      "Policy train loss in epoch 2:-0.9866376742720604\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.9866376519203186\n",
      "\n",
      "episode 2, policy loss -0.9866376519203186\n",
      "\n",
      "episode 3, policy loss -0.9866376519203186\n",
      "\n",
      "episode 4, policy loss -0.9866376519203186\n",
      "\n",
      "episode 5, policy loss -0.9866376519203186\n",
      "\n",
      "episode 6, policy loss -0.9866376519203186\n",
      "\n",
      "episode 7, policy loss -0.9866376519203186\n",
      "\n",
      "episode 8, policy loss -0.9866377711296082\n",
      "\n",
      "episode 9, policy loss -0.9866376519203186\n",
      "\n",
      "episode 10, policy loss -0.9866376519203186\n",
      "\n",
      "episode 11, policy loss -0.9866377711296082\n",
      "\n",
      "episode 12, policy loss -0.9866376519203186\n",
      "\n",
      "episode 13, policy loss -0.9866376519203186\n",
      "\n",
      "episode 14, policy loss -0.9866376519203186\n",
      "\n",
      "episode 15, policy loss -0.9866377711296082\n",
      "\n",
      "episode 16, policy loss -0.9866376519203186\n",
      "\n",
      "Policy train loss in epoch 3:-0.9866376742720604\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.8110217452049255\n",
      "\n",
      "episode 2, val func loss 0.9098433256149292\n",
      "\n",
      "episode 3, val func loss 1.0003582239151\n",
      "\n",
      "episode 4, val func loss 0.9110204577445984\n",
      "\n",
      "episode 5, val func loss 1.0236371755599976\n",
      "\n",
      "episode 6, val func loss 1.0618857145309448\n",
      "\n",
      "episode 7, val func loss 0.8784332275390625\n",
      "\n",
      "episode 8, val func loss 0.8798044323921204\n",
      "\n",
      "episode 9, val func loss 1.0695303678512573\n",
      "\n",
      "episode 10, val func loss 0.9599886536598206\n",
      "\n",
      "episode 11, val func loss 0.8081436157226562\n",
      "\n",
      "episode 12, val func loss 0.8975712656974792\n",
      "\n",
      "episode 13, val func loss 0.9277319312095642\n",
      "\n",
      "episode 14, val func loss 0.9958556890487671\n",
      "\n",
      "episode 15, val func loss 0.9123014807701111\n",
      "\n",
      "episode 16, val func loss 0.9234040379524231\n",
      "\n",
      "Val func train loss in epoch 0:0.9356582090258598\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.9398806095123291\n",
      "\n",
      "episode 2, val func loss 0.9129210114479065\n",
      "\n",
      "episode 3, val func loss 0.8715381026268005\n",
      "\n",
      "episode 4, val func loss 1.000952959060669\n",
      "\n",
      "episode 5, val func loss 0.9742227792739868\n",
      "\n",
      "episode 6, val func loss 0.9838081002235413\n",
      "\n",
      "episode 7, val func loss 0.8852811455726624\n",
      "\n",
      "episode 8, val func loss 1.4866973161697388\n",
      "\n",
      "episode 9, val func loss 0.8832777142524719\n",
      "\n",
      "episode 10, val func loss 1.0698840618133545\n",
      "\n",
      "episode 11, val func loss 1.0107388496398926\n",
      "\n",
      "episode 12, val func loss 1.043104887008667\n",
      "\n",
      "episode 13, val func loss 0.9872990846633911\n",
      "\n",
      "episode 14, val func loss 1.1602470874786377\n",
      "\n",
      "episode 15, val func loss 1.059390664100647\n",
      "\n",
      "episode 16, val func loss 0.904481053352356\n",
      "\n",
      "Val func train loss in epoch 1:1.0108578391373158\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.1358009576797485\n",
      "\n",
      "episode 2, val func loss 0.9923146367073059\n",
      "\n",
      "episode 3, val func loss 1.01291024684906\n",
      "\n",
      "episode 4, val func loss 0.922443151473999\n",
      "\n",
      "episode 5, val func loss 0.9688249826431274\n",
      "\n",
      "episode 6, val func loss 1.007836937904358\n",
      "\n",
      "episode 7, val func loss 0.9376406669616699\n",
      "\n",
      "episode 8, val func loss 0.9344390630722046\n",
      "\n",
      "episode 9, val func loss 0.8898899555206299\n",
      "\n",
      "episode 10, val func loss 1.0868823528289795\n",
      "\n",
      "episode 11, val func loss 0.9965709447860718\n",
      "\n",
      "episode 12, val func loss 0.9523817300796509\n",
      "\n",
      "episode 13, val func loss 0.8936888575553894\n",
      "\n",
      "episode 14, val func loss 0.9928030967712402\n",
      "\n",
      "episode 15, val func loss 0.9268790483474731\n",
      "\n",
      "episode 16, val func loss 1.0945169925689697\n",
      "\n",
      "Val func train loss in epoch 2:0.9841139763593674\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.0386826992034912\n",
      "\n",
      "episode 2, val func loss 0.8908934593200684\n",
      "\n",
      "episode 3, val func loss 1.1415663957595825\n",
      "\n",
      "episode 4, val func loss 1.0489590167999268\n",
      "\n",
      "episode 5, val func loss 1.1018588542938232\n",
      "\n",
      "episode 6, val func loss 0.9774022698402405\n",
      "\n",
      "episode 7, val func loss 1.03171706199646\n",
      "\n",
      "episode 8, val func loss 0.8884345293045044\n",
      "\n",
      "episode 9, val func loss 0.8372007012367249\n",
      "\n",
      "episode 10, val func loss 0.9831481575965881\n",
      "\n",
      "episode 11, val func loss 0.9965720772743225\n",
      "\n",
      "episode 12, val func loss 0.9471261501312256\n",
      "\n",
      "episode 13, val func loss 0.7884935736656189\n",
      "\n",
      "episode 14, val func loss 0.8628442287445068\n",
      "\n",
      "episode 15, val func loss 0.8940279483795166\n",
      "\n",
      "episode 16, val func loss 0.9514204263687134\n",
      "\n",
      "Val func train loss in epoch 3:0.9612717218697071\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.9578761458396912\n",
      "\n",
      "episode 2, val func loss 1.0376379489898682\n",
      "\n",
      "episode 3, val func loss 0.8196294903755188\n",
      "\n",
      "episode 4, val func loss 0.9490993618965149\n",
      "\n",
      "episode 5, val func loss 0.8943959474563599\n",
      "\n",
      "episode 6, val func loss 0.8257089853286743\n",
      "\n",
      "episode 7, val func loss 0.8277516961097717\n",
      "\n",
      "episode 8, val func loss 0.9144330620765686\n",
      "\n",
      "episode 9, val func loss 0.790694534778595\n",
      "\n",
      "episode 10, val func loss 0.7905626893043518\n",
      "\n",
      "episode 11, val func loss 0.8239539861679077\n",
      "\n",
      "episode 12, val func loss 0.8775827884674072\n",
      "\n",
      "episode 13, val func loss 0.8438025116920471\n",
      "\n",
      "episode 14, val func loss 0.9221475124359131\n",
      "\n",
      "episode 15, val func loss 0.9788119196891785\n",
      "\n",
      "episode 16, val func loss 0.7989458441734314\n",
      "\n",
      "Val func train loss in epoch 4:0.8783146515488625\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.9070364832878113\n",
      "\n",
      "episode 2, val func loss 1.0227034091949463\n",
      "\n",
      "episode 3, val func loss 0.8835248947143555\n",
      "\n",
      "episode 4, val func loss 0.8078908920288086\n",
      "\n",
      "episode 5, val func loss 0.877554714679718\n",
      "\n",
      "episode 6, val func loss 0.8818437457084656\n",
      "\n",
      "episode 7, val func loss 0.9282823204994202\n",
      "\n",
      "episode 8, val func loss 0.940909206867218\n",
      "\n",
      "episode 9, val func loss 0.9329245090484619\n",
      "\n",
      "episode 10, val func loss 1.008149266242981\n",
      "\n",
      "episode 11, val func loss 0.9402122497558594\n",
      "\n",
      "episode 12, val func loss 1.0656334161758423\n",
      "\n",
      "episode 13, val func loss 0.9968249201774597\n",
      "\n",
      "episode 14, val func loss 0.9128892421722412\n",
      "\n",
      "episode 15, val func loss 0.9600654244422913\n",
      "\n",
      "episode 16, val func loss 0.9538743495941162\n",
      "\n",
      "Val func train loss in epoch 5:0.9387699402868748\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.011959433555603\n",
      "\n",
      "episode 2, val func loss 0.9216223955154419\n",
      "\n",
      "episode 3, val func loss 0.9032058715820312\n",
      "\n",
      "episode 4, val func loss 0.8759498596191406\n",
      "\n",
      "episode 5, val func loss 0.908729076385498\n",
      "\n",
      "episode 6, val func loss 0.7396160960197449\n",
      "\n",
      "episode 7, val func loss 0.9099459052085876\n",
      "\n",
      "episode 8, val func loss 0.7806249260902405\n",
      "\n",
      "episode 9, val func loss 0.8811454772949219\n",
      "\n",
      "episode 10, val func loss 0.8988189697265625\n",
      "\n",
      "episode 11, val func loss 0.9145975708961487\n",
      "\n",
      "episode 12, val func loss 0.9148349165916443\n",
      "\n",
      "episode 13, val func loss 0.9659395813941956\n",
      "\n",
      "episode 14, val func loss 0.8654367923736572\n",
      "\n",
      "episode 15, val func loss 0.9802209138870239\n",
      "\n",
      "episode 16, val func loss 0.9966328144073486\n",
      "\n",
      "Val func train loss in epoch 6:0.9043300375342369\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.912166953086853\n",
      "\n",
      "episode 2, val func loss 0.9669191241264343\n",
      "\n",
      "episode 3, val func loss 0.9026592373847961\n",
      "\n",
      "episode 4, val func loss 0.9546353220939636\n",
      "\n",
      "episode 5, val func loss 0.8560305833816528\n",
      "\n",
      "episode 6, val func loss 0.9225802421569824\n",
      "\n",
      "episode 7, val func loss 0.885751485824585\n",
      "\n",
      "episode 8, val func loss 0.8888038992881775\n",
      "\n",
      "episode 9, val func loss 1.0533443689346313\n",
      "\n",
      "episode 10, val func loss 0.8466745018959045\n",
      "\n",
      "episode 11, val func loss 0.8266782760620117\n",
      "\n",
      "episode 12, val func loss 0.9549789428710938\n",
      "\n",
      "episode 13, val func loss 0.7601102590560913\n",
      "\n",
      "episode 14, val func loss 0.9601424932479858\n",
      "\n",
      "episode 15, val func loss 0.9268325567245483\n",
      "\n",
      "episode 16, val func loss 1.0053974390029907\n",
      "\n",
      "Val func train loss in epoch 7:0.9139816053211689\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.9916053414344788\n",
      "\n",
      "episode 2, val func loss 1.060825228691101\n",
      "\n",
      "episode 3, val func loss 0.940923810005188\n",
      "\n",
      "episode 4, val func loss 1.0979567766189575\n",
      "\n",
      "episode 5, val func loss 1.016503095626831\n",
      "\n",
      "episode 6, val func loss 0.8636046648025513\n",
      "\n",
      "episode 7, val func loss 1.0326145887374878\n",
      "\n",
      "episode 8, val func loss 1.0559146404266357\n",
      "\n",
      "episode 9, val func loss 0.9899547696113586\n",
      "\n",
      "episode 10, val func loss 0.7514827847480774\n",
      "\n",
      "episode 11, val func loss 0.860623836517334\n",
      "\n",
      "episode 12, val func loss 0.8561633825302124\n",
      "\n",
      "episode 13, val func loss 0.9486591815948486\n",
      "\n",
      "episode 14, val func loss 0.9430840015411377\n",
      "\n",
      "episode 15, val func loss 0.8482881784439087\n",
      "\n",
      "episode 16, val func loss 0.84488445520401\n",
      "\n",
      "Val func train loss in epoch 8:0.9439430460333824\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.9697019457817078\n",
      "\n",
      "episode 2, val func loss 0.8513359427452087\n",
      "\n",
      "episode 3, val func loss 1.0999138355255127\n",
      "\n",
      "episode 4, val func loss 0.892798900604248\n",
      "\n",
      "episode 5, val func loss 0.9538298845291138\n",
      "\n",
      "episode 6, val func loss 0.9260834455490112\n",
      "\n",
      "episode 7, val func loss 0.7712204456329346\n",
      "\n",
      "episode 8, val func loss 0.9516857266426086\n",
      "\n",
      "episode 9, val func loss 0.9851570129394531\n",
      "\n",
      "episode 10, val func loss 0.9794200658798218\n",
      "\n",
      "episode 11, val func loss 0.9767522811889648\n",
      "\n",
      "episode 12, val func loss 1.03529953956604\n",
      "\n",
      "episode 13, val func loss 1.0054001808166504\n",
      "\n",
      "episode 14, val func loss 0.8387685418128967\n",
      "\n",
      "episode 15, val func loss 0.8163204193115234\n",
      "\n",
      "episode 16, val func loss 0.8167340755462646\n",
      "\n",
      "Val func train loss in epoch 9:0.9294013902544975\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.8125476241111755\n",
      "\n",
      "episode 2, val func loss 0.8384328484535217\n",
      "\n",
      "episode 3, val func loss 0.8448917865753174\n",
      "\n",
      "episode 4, val func loss 0.7789238095283508\n",
      "\n",
      "episode 5, val func loss 0.9073814153671265\n",
      "\n",
      "episode 6, val func loss 0.950175940990448\n",
      "\n",
      "episode 7, val func loss 0.8752927780151367\n",
      "\n",
      "episode 8, val func loss 1.0056146383285522\n",
      "\n",
      "episode 9, val func loss 0.9380859732627869\n",
      "\n",
      "episode 10, val func loss 1.0482048988342285\n",
      "\n",
      "episode 11, val func loss 0.8789100646972656\n",
      "\n",
      "episode 12, val func loss 0.9800319075584412\n",
      "\n",
      "episode 13, val func loss 0.7985733151435852\n",
      "\n",
      "episode 14, val func loss 0.9179538488388062\n",
      "\n",
      "episode 15, val func loss 0.7563474774360657\n",
      "\n",
      "episode 16, val func loss 0.9342829585075378\n",
      "\n",
      "Val func train loss in epoch 10:0.8916032053530216\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9532132744789124\n",
      "\n",
      "episode 2, val func loss 0.9242350459098816\n",
      "\n",
      "episode 3, val func loss 0.9926973581314087\n",
      "\n",
      "episode 4, val func loss 0.9275950789451599\n",
      "\n",
      "episode 5, val func loss 1.1320711374282837\n",
      "\n",
      "episode 6, val func loss 0.7980348467826843\n",
      "\n",
      "episode 7, val func loss 1.1031019687652588\n",
      "\n",
      "episode 8, val func loss 0.884212851524353\n",
      "\n",
      "episode 9, val func loss 0.9833177924156189\n",
      "\n",
      "episode 10, val func loss 0.9805766344070435\n",
      "\n",
      "episode 11, val func loss 0.9182915091514587\n",
      "\n",
      "episode 12, val func loss 0.8732835650444031\n",
      "\n",
      "episode 13, val func loss 0.9786706566810608\n",
      "\n",
      "episode 14, val func loss 0.9524616003036499\n",
      "\n",
      "episode 15, val func loss 1.0528838634490967\n",
      "\n",
      "episode 16, val func loss 0.9486044645309448\n",
      "\n",
      "Val func train loss in epoch 11:0.9627032279968262\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.9195085763931274\n",
      "\n",
      "episode 2, val func loss 0.9860934615135193\n",
      "\n",
      "episode 3, val func loss 1.1217107772827148\n",
      "\n",
      "episode 4, val func loss 0.8131693005561829\n",
      "\n",
      "episode 5, val func loss 1.0226893424987793\n",
      "\n",
      "episode 6, val func loss 1.0274099111557007\n",
      "\n",
      "episode 7, val func loss 0.9515438079833984\n",
      "\n",
      "episode 8, val func loss 0.9406386613845825\n",
      "\n",
      "episode 9, val func loss 0.9772028923034668\n",
      "\n",
      "episode 10, val func loss 0.9607015252113342\n",
      "\n",
      "episode 11, val func loss 0.8867278695106506\n",
      "\n",
      "episode 12, val func loss 0.846933126449585\n",
      "\n",
      "episode 13, val func loss 0.9614661931991577\n",
      "\n",
      "episode 14, val func loss 0.7707436680793762\n",
      "\n",
      "episode 15, val func loss 0.8829318284988403\n",
      "\n",
      "episode 16, val func loss 0.7736445069313049\n",
      "\n",
      "Val func train loss in epoch 12:0.9276947155594826\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8544454574584961\n",
      "\n",
      "episode 2, val func loss 1.0079237222671509\n",
      "\n",
      "episode 3, val func loss 0.8511563539505005\n",
      "\n",
      "episode 4, val func loss 0.8510295152664185\n",
      "\n",
      "episode 5, val func loss 0.884212076663971\n",
      "\n",
      "episode 6, val func loss 0.8910059928894043\n",
      "\n",
      "episode 7, val func loss 0.8612075448036194\n",
      "\n",
      "episode 8, val func loss 0.8645586967468262\n",
      "\n",
      "episode 9, val func loss 0.9876654148101807\n",
      "\n",
      "episode 10, val func loss 0.8999457955360413\n",
      "\n",
      "episode 11, val func loss 0.8340544104576111\n",
      "\n",
      "episode 12, val func loss 1.0220515727996826\n",
      "\n",
      "episode 13, val func loss 0.92588871717453\n",
      "\n",
      "episode 14, val func loss 0.9123618006706238\n",
      "\n",
      "episode 15, val func loss 0.8332741856575012\n",
      "\n",
      "episode 16, val func loss 0.939643144607544\n",
      "\n",
      "Val func train loss in epoch 13:0.9012765251100063\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.9036291241645813\n",
      "\n",
      "episode 2, val func loss 0.8253905177116394\n",
      "\n",
      "episode 3, val func loss 0.9533835649490356\n",
      "\n",
      "episode 4, val func loss 0.826647162437439\n",
      "\n",
      "episode 5, val func loss 0.9684467315673828\n",
      "\n",
      "episode 6, val func loss 1.0561047792434692\n",
      "\n",
      "episode 7, val func loss 0.9016087055206299\n",
      "\n",
      "episode 8, val func loss 0.9068878293037415\n",
      "\n",
      "episode 9, val func loss 1.0448346138000488\n",
      "\n",
      "episode 10, val func loss 0.9371328949928284\n",
      "\n",
      "episode 11, val func loss 0.8181694746017456\n",
      "\n",
      "episode 12, val func loss 0.9945464134216309\n",
      "\n",
      "episode 13, val func loss 0.9162663221359253\n",
      "\n",
      "episode 14, val func loss 0.7101637721061707\n",
      "\n",
      "episode 15, val func loss 0.8693474531173706\n",
      "\n",
      "episode 16, val func loss 0.8347926139831543\n",
      "\n",
      "Val func train loss in epoch 14:0.9042094983160496\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.8316267132759094\n",
      "\n",
      "episode 2, val func loss 0.8871557116508484\n",
      "\n",
      "episode 3, val func loss 0.9519461393356323\n",
      "\n",
      "episode 4, val func loss 0.8187107443809509\n",
      "\n",
      "episode 5, val func loss 0.8555439114570618\n",
      "\n",
      "episode 6, val func loss 0.9762226939201355\n",
      "\n",
      "episode 7, val func loss 0.7889986038208008\n",
      "\n",
      "episode 8, val func loss 0.9571887254714966\n",
      "\n",
      "episode 9, val func loss 0.7535329461097717\n",
      "\n",
      "episode 10, val func loss 0.938532292842865\n",
      "\n",
      "episode 11, val func loss 0.9200713038444519\n",
      "\n",
      "episode 12, val func loss 0.9059991836547852\n",
      "\n",
      "episode 13, val func loss 0.7666804194450378\n",
      "\n",
      "episode 14, val func loss 1.0655486583709717\n",
      "\n",
      "episode 15, val func loss 0.9826855063438416\n",
      "\n",
      "episode 16, val func loss 0.938430666923523\n",
      "\n",
      "Val func train loss in epoch 15:0.8961796388030052\n",
      "***********************TIME WAS 4.86134006579717 min*****************************\n",
      "\n",
      "**********************ROUND 80 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.32606637477874756\n",
      "\n",
      "episode 2, policy loss -0.32606637477874756\n",
      "\n",
      "episode 3, policy loss -0.32606637477874756\n",
      "\n",
      "episode 4, policy loss -0.32606634497642517\n",
      "\n",
      "episode 5, policy loss -0.32606640458106995\n",
      "\n",
      "episode 6, policy loss -0.32606640458106995\n",
      "\n",
      "episode 7, policy loss -0.3260662853717804\n",
      "\n",
      "episode 8, policy loss -0.32606634497642517\n",
      "\n",
      "episode 9, policy loss -0.3260663151741028\n",
      "\n",
      "episode 10, policy loss -0.32606637477874756\n",
      "\n",
      "episode 11, policy loss -0.32606634497642517\n",
      "\n",
      "episode 12, policy loss -0.32606640458106995\n",
      "\n",
      "episode 13, policy loss -0.32606634497642517\n",
      "\n",
      "episode 14, policy loss -0.326066255569458\n",
      "\n",
      "episode 15, policy loss -0.32606637477874756\n",
      "\n",
      "episode 16, policy loss -0.32606637477874756\n",
      "\n",
      "Policy train loss in epoch 0:-0.32606635615229607\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.32606637477874756\n",
      "\n",
      "episode 2, policy loss -0.3260662853717804\n",
      "\n",
      "episode 3, policy loss -0.32606637477874756\n",
      "\n",
      "episode 4, policy loss -0.32606637477874756\n",
      "\n",
      "episode 5, policy loss -0.32606637477874756\n",
      "\n",
      "episode 6, policy loss -0.32606640458106995\n",
      "\n",
      "episode 7, policy loss -0.3260663151741028\n",
      "\n",
      "episode 8, policy loss -0.326066255569458\n",
      "\n",
      "episode 9, policy loss -0.32606634497642517\n",
      "\n",
      "episode 10, policy loss -0.32606637477874756\n",
      "\n",
      "episode 11, policy loss -0.32606634497642517\n",
      "\n",
      "episode 12, policy loss -0.32606634497642517\n",
      "\n",
      "episode 13, policy loss -0.32606634497642517\n",
      "\n",
      "episode 14, policy loss -0.32606637477874756\n",
      "\n",
      "episode 15, policy loss -0.32606637477874756\n",
      "\n",
      "episode 16, policy loss -0.32606640458106995\n",
      "\n",
      "Policy train loss in epoch 1:-0.3260663542896509\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.32606634497642517\n",
      "\n",
      "episode 2, policy loss -0.32606634497642517\n",
      "\n",
      "episode 3, policy loss -0.32606637477874756\n",
      "\n",
      "episode 4, policy loss -0.32606634497642517\n",
      "\n",
      "episode 5, policy loss -0.3260662853717804\n",
      "\n",
      "episode 6, policy loss -0.32606640458106995\n",
      "\n",
      "episode 7, policy loss -0.32606640458106995\n",
      "\n",
      "episode 8, policy loss -0.32606640458106995\n",
      "\n",
      "episode 9, policy loss -0.32606637477874756\n",
      "\n",
      "episode 10, policy loss -0.32606637477874756\n",
      "\n",
      "episode 11, policy loss -0.3260663151741028\n",
      "\n",
      "episode 12, policy loss -0.32606637477874756\n",
      "\n",
      "episode 13, policy loss -0.32606634497642517\n",
      "\n",
      "episode 14, policy loss -0.32606637477874756\n",
      "\n",
      "episode 15, policy loss -0.32606637477874756\n",
      "\n",
      "episode 16, policy loss -0.326066255569458\n",
      "\n",
      "Policy train loss in epoch 2:-0.32606635615229607\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.32606634497642517\n",
      "\n",
      "episode 2, policy loss -0.32606640458106995\n",
      "\n",
      "episode 3, policy loss -0.32606637477874756\n",
      "\n",
      "episode 4, policy loss -0.3260662853717804\n",
      "\n",
      "episode 5, policy loss -0.32606634497642517\n",
      "\n",
      "episode 6, policy loss -0.3260663151741028\n",
      "\n",
      "episode 7, policy loss -0.32606637477874756\n",
      "\n",
      "episode 8, policy loss -0.32606637477874756\n",
      "\n",
      "episode 9, policy loss -0.32606637477874756\n",
      "\n",
      "episode 10, policy loss -0.32606637477874756\n",
      "\n",
      "episode 11, policy loss -0.32606640458106995\n",
      "\n",
      "episode 12, policy loss -0.32606640458106995\n",
      "\n",
      "episode 13, policy loss -0.32606634497642517\n",
      "\n",
      "episode 14, policy loss -0.32606637477874756\n",
      "\n",
      "episode 15, policy loss -0.326066255569458\n",
      "\n",
      "episode 16, policy loss -0.32606634497642517\n",
      "\n",
      "Policy train loss in epoch 3:-0.32606635615229607\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.9894561171531677\n",
      "\n",
      "episode 2, val func loss 1.0088168382644653\n",
      "\n",
      "episode 3, val func loss 0.9976369738578796\n",
      "\n",
      "episode 4, val func loss 0.8847014307975769\n",
      "\n",
      "episode 5, val func loss 1.0419691801071167\n",
      "\n",
      "episode 6, val func loss 0.9230281114578247\n",
      "\n",
      "episode 7, val func loss 0.8409344553947449\n",
      "\n",
      "episode 8, val func loss 0.920810878276825\n",
      "\n",
      "episode 9, val func loss 0.9353678226470947\n",
      "\n",
      "episode 10, val func loss 1.0766608715057373\n",
      "\n",
      "episode 11, val func loss 0.7698251605033875\n",
      "\n",
      "episode 12, val func loss 0.8531818389892578\n",
      "\n",
      "episode 13, val func loss 0.9115992188453674\n",
      "\n",
      "episode 14, val func loss 0.7304208278656006\n",
      "\n",
      "episode 15, val func loss 0.9206224679946899\n",
      "\n",
      "episode 16, val func loss 0.8900495171546936\n",
      "\n",
      "Val func train loss in epoch 0:0.9184426069259644\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.9058565497398376\n",
      "\n",
      "episode 2, val func loss 0.8176652789115906\n",
      "\n",
      "episode 3, val func loss 0.8211796879768372\n",
      "\n",
      "episode 4, val func loss 0.8254873156547546\n",
      "\n",
      "episode 5, val func loss 0.862453281879425\n",
      "\n",
      "episode 6, val func loss 0.9230289459228516\n",
      "\n",
      "episode 7, val func loss 0.8078720569610596\n",
      "\n",
      "episode 8, val func loss 0.9964631199836731\n",
      "\n",
      "episode 9, val func loss 0.9077491760253906\n",
      "\n",
      "episode 10, val func loss 0.8744570016860962\n",
      "\n",
      "episode 11, val func loss 0.8883811235427856\n",
      "\n",
      "episode 12, val func loss 0.8392338156700134\n",
      "\n",
      "episode 13, val func loss 0.871638298034668\n",
      "\n",
      "episode 14, val func loss 0.9104439616203308\n",
      "\n",
      "episode 15, val func loss 0.8073734045028687\n",
      "\n",
      "episode 16, val func loss 0.9074921011924744\n",
      "\n",
      "Val func train loss in epoch 1:0.8729234449565411\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.9201045632362366\n",
      "\n",
      "episode 2, val func loss 0.8070745468139648\n",
      "\n",
      "episode 3, val func loss 0.8106851577758789\n",
      "\n",
      "episode 4, val func loss 0.8375635743141174\n",
      "\n",
      "episode 5, val func loss 0.8925353288650513\n",
      "\n",
      "episode 6, val func loss 0.861563503742218\n",
      "\n",
      "episode 7, val func loss 0.8018687963485718\n",
      "\n",
      "episode 8, val func loss 0.8220848441123962\n",
      "\n",
      "episode 9, val func loss 0.8969630599021912\n",
      "\n",
      "episode 10, val func loss 1.0558654069900513\n",
      "\n",
      "episode 11, val func loss 1.0702966451644897\n",
      "\n",
      "episode 12, val func loss 1.073362946510315\n",
      "\n",
      "episode 13, val func loss 1.1087545156478882\n",
      "\n",
      "episode 14, val func loss 1.0521010160446167\n",
      "\n",
      "episode 15, val func loss 1.0510433912277222\n",
      "\n",
      "episode 16, val func loss 0.9870718717575073\n",
      "\n",
      "Val func train loss in epoch 2:0.940558698028326\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.0299354791641235\n",
      "\n",
      "episode 2, val func loss 1.060490369796753\n",
      "\n",
      "episode 3, val func loss 0.8353855609893799\n",
      "\n",
      "episode 4, val func loss 0.9115968942642212\n",
      "\n",
      "episode 5, val func loss 0.8405706882476807\n",
      "\n",
      "episode 6, val func loss 0.9115251898765564\n",
      "\n",
      "episode 7, val func loss 0.8980856537818909\n",
      "\n",
      "episode 8, val func loss 0.814555823802948\n",
      "\n",
      "episode 9, val func loss 0.9228634238243103\n",
      "\n",
      "episode 10, val func loss 0.8164499402046204\n",
      "\n",
      "episode 11, val func loss 0.962295413017273\n",
      "\n",
      "episode 12, val func loss 0.7977794408798218\n",
      "\n",
      "episode 13, val func loss 1.05347740650177\n",
      "\n",
      "episode 14, val func loss 0.881654679775238\n",
      "\n",
      "episode 15, val func loss 0.91355299949646\n",
      "\n",
      "episode 16, val func loss 1.0039124488830566\n",
      "\n",
      "Val func train loss in epoch 3:0.9158832132816315\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.9140102863311768\n",
      "\n",
      "episode 2, val func loss 1.0356475114822388\n",
      "\n",
      "episode 3, val func loss 0.9903403520584106\n",
      "\n",
      "episode 4, val func loss 0.8463872075080872\n",
      "\n",
      "episode 5, val func loss 0.9699112772941589\n",
      "\n",
      "episode 6, val func loss 0.898594856262207\n",
      "\n",
      "episode 7, val func loss 1.002199649810791\n",
      "\n",
      "episode 8, val func loss 0.86573725938797\n",
      "\n",
      "episode 9, val func loss 0.8151671290397644\n",
      "\n",
      "episode 10, val func loss 0.8650045394897461\n",
      "\n",
      "episode 11, val func loss 0.8596513271331787\n",
      "\n",
      "episode 12, val func loss 0.8821349740028381\n",
      "\n",
      "episode 13, val func loss 0.7669455409049988\n",
      "\n",
      "episode 14, val func loss 0.8666268587112427\n",
      "\n",
      "episode 15, val func loss 0.8362159729003906\n",
      "\n",
      "episode 16, val func loss 0.847055971622467\n",
      "\n",
      "Val func train loss in epoch 4:0.8913519196212292\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.8659546971321106\n",
      "\n",
      "episode 2, val func loss 0.8869839906692505\n",
      "\n",
      "episode 3, val func loss 0.8319029808044434\n",
      "\n",
      "episode 4, val func loss 0.879497230052948\n",
      "\n",
      "episode 5, val func loss 0.7381122708320618\n",
      "\n",
      "episode 6, val func loss 1.024071455001831\n",
      "\n",
      "episode 7, val func loss 0.8661581873893738\n",
      "\n",
      "episode 8, val func loss 0.9933720827102661\n",
      "\n",
      "episode 9, val func loss 1.0350607633590698\n",
      "\n",
      "episode 10, val func loss 1.0771962404251099\n",
      "\n",
      "episode 11, val func loss 1.0246248245239258\n",
      "\n",
      "episode 12, val func loss 1.1041522026062012\n",
      "\n",
      "episode 13, val func loss 0.9483561515808105\n",
      "\n",
      "episode 14, val func loss 0.8449660539627075\n",
      "\n",
      "episode 15, val func loss 0.9457183480262756\n",
      "\n",
      "episode 16, val func loss 1.1230212450027466\n",
      "\n",
      "Val func train loss in epoch 5:0.9493217952549458\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8662369847297668\n",
      "\n",
      "episode 2, val func loss 0.8491606116294861\n",
      "\n",
      "episode 3, val func loss 0.9461134672164917\n",
      "\n",
      "episode 4, val func loss 1.0618846416473389\n",
      "\n",
      "episode 5, val func loss 0.8400428891181946\n",
      "\n",
      "episode 6, val func loss 1.0484683513641357\n",
      "\n",
      "episode 7, val func loss 0.9079030156135559\n",
      "\n",
      "episode 8, val func loss 0.9465711116790771\n",
      "\n",
      "episode 9, val func loss 0.9831541776657104\n",
      "\n",
      "episode 10, val func loss 0.810385525226593\n",
      "\n",
      "episode 11, val func loss 0.9155734777450562\n",
      "\n",
      "episode 12, val func loss 0.7909202575683594\n",
      "\n",
      "episode 13, val func loss 0.8663108944892883\n",
      "\n",
      "episode 14, val func loss 0.9469072818756104\n",
      "\n",
      "episode 15, val func loss 0.79090416431427\n",
      "\n",
      "episode 16, val func loss 0.9735556840896606\n",
      "\n",
      "Val func train loss in epoch 6:0.9090057834982872\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.8021540641784668\n",
      "\n",
      "episode 2, val func loss 0.8293043971061707\n",
      "\n",
      "episode 3, val func loss 0.8430665135383606\n",
      "\n",
      "episode 4, val func loss 0.8738604784011841\n",
      "\n",
      "episode 5, val func loss 0.9450361728668213\n",
      "\n",
      "episode 6, val func loss 0.9274330139160156\n",
      "\n",
      "episode 7, val func loss 0.9885794520378113\n",
      "\n",
      "episode 8, val func loss 0.9126957654953003\n",
      "\n",
      "episode 9, val func loss 0.7539641261100769\n",
      "\n",
      "episode 10, val func loss 0.8994402289390564\n",
      "\n",
      "episode 11, val func loss 0.7876182198524475\n",
      "\n",
      "episode 12, val func loss 0.836726188659668\n",
      "\n",
      "episode 13, val func loss 0.9137337803840637\n",
      "\n",
      "episode 14, val func loss 0.7760860919952393\n",
      "\n",
      "episode 15, val func loss 0.8580425381660461\n",
      "\n",
      "episode 16, val func loss 0.9349820017814636\n",
      "\n",
      "Val func train loss in epoch 7:0.867670189589262\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8951748013496399\n",
      "\n",
      "episode 2, val func loss 0.8540337681770325\n",
      "\n",
      "episode 3, val func loss 0.7725279331207275\n",
      "\n",
      "episode 4, val func loss 1.0294090509414673\n",
      "\n",
      "episode 5, val func loss 1.026196002960205\n",
      "\n",
      "episode 6, val func loss 0.8032228350639343\n",
      "\n",
      "episode 7, val func loss 0.894237220287323\n",
      "\n",
      "episode 8, val func loss 0.874758780002594\n",
      "\n",
      "episode 9, val func loss 0.9721713066101074\n",
      "\n",
      "episode 10, val func loss 0.8874890804290771\n",
      "\n",
      "episode 11, val func loss 0.827305018901825\n",
      "\n",
      "episode 12, val func loss 0.9740553498268127\n",
      "\n",
      "episode 13, val func loss 1.0424422025680542\n",
      "\n",
      "episode 14, val func loss 0.9277854561805725\n",
      "\n",
      "episode 15, val func loss 0.974162220954895\n",
      "\n",
      "episode 16, val func loss 0.8343599438667297\n",
      "\n",
      "Val func train loss in epoch 8:0.9118331857025623\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.9564200639724731\n",
      "\n",
      "episode 2, val func loss 0.818522036075592\n",
      "\n",
      "episode 3, val func loss 0.8087401390075684\n",
      "\n",
      "episode 4, val func loss 0.9119618535041809\n",
      "\n",
      "episode 5, val func loss 0.8781799674034119\n",
      "\n",
      "episode 6, val func loss 0.8891613483428955\n",
      "\n",
      "episode 7, val func loss 0.9285411238670349\n",
      "\n",
      "episode 8, val func loss 0.7220904231071472\n",
      "\n",
      "episode 9, val func loss 0.9160335659980774\n",
      "\n",
      "episode 10, val func loss 0.8397066593170166\n",
      "\n",
      "episode 11, val func loss 0.8558923602104187\n",
      "\n",
      "episode 12, val func loss 0.7967482805252075\n",
      "\n",
      "episode 13, val func loss 0.828296422958374\n",
      "\n",
      "episode 14, val func loss 1.013288140296936\n",
      "\n",
      "episode 15, val func loss 0.873958945274353\n",
      "\n",
      "episode 16, val func loss 0.8922958374023438\n",
      "\n",
      "Val func train loss in epoch 9:0.8706148229539394\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.79265958070755\n",
      "\n",
      "episode 2, val func loss 0.881925106048584\n",
      "\n",
      "episode 3, val func loss 0.9397396445274353\n",
      "\n",
      "episode 4, val func loss 0.8900904655456543\n",
      "\n",
      "episode 5, val func loss 0.8928499817848206\n",
      "\n",
      "episode 6, val func loss 0.8372698426246643\n",
      "\n",
      "episode 7, val func loss 0.988317608833313\n",
      "\n",
      "episode 8, val func loss 0.8749700784683228\n",
      "\n",
      "episode 9, val func loss 0.8686968088150024\n",
      "\n",
      "episode 10, val func loss 0.9070633053779602\n",
      "\n",
      "episode 11, val func loss 0.7753507494926453\n",
      "\n",
      "episode 12, val func loss 0.9031420350074768\n",
      "\n",
      "episode 13, val func loss 0.8737496137619019\n",
      "\n",
      "episode 14, val func loss 0.8140995502471924\n",
      "\n",
      "episode 15, val func loss 0.8168215751647949\n",
      "\n",
      "episode 16, val func loss 0.8588022589683533\n",
      "\n",
      "Val func train loss in epoch 10:0.8697217628359795\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9194765686988831\n",
      "\n",
      "episode 2, val func loss 0.9435924291610718\n",
      "\n",
      "episode 3, val func loss 0.9327921867370605\n",
      "\n",
      "episode 4, val func loss 0.9136734008789062\n",
      "\n",
      "episode 5, val func loss 0.8429344296455383\n",
      "\n",
      "episode 6, val func loss 0.8467370271682739\n",
      "\n",
      "episode 7, val func loss 0.8444205522537231\n",
      "\n",
      "episode 8, val func loss 0.7489237785339355\n",
      "\n",
      "episode 9, val func loss 1.0158137083053589\n",
      "\n",
      "episode 10, val func loss 0.9318057298660278\n",
      "\n",
      "episode 11, val func loss 0.8390796780586243\n",
      "\n",
      "episode 12, val func loss 0.9669396877288818\n",
      "\n",
      "episode 13, val func loss 0.8920324444770813\n",
      "\n",
      "episode 14, val func loss 0.8811094760894775\n",
      "\n",
      "episode 15, val func loss 0.8484770655632019\n",
      "\n",
      "episode 16, val func loss 0.8317179679870605\n",
      "\n",
      "Val func train loss in epoch 11:0.8874703831970692\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.9993997812271118\n",
      "\n",
      "episode 2, val func loss 0.889729917049408\n",
      "\n",
      "episode 3, val func loss 0.8613884449005127\n",
      "\n",
      "episode 4, val func loss 0.9758325815200806\n",
      "\n",
      "episode 5, val func loss 0.8903318047523499\n",
      "\n",
      "episode 6, val func loss 0.8033673167228699\n",
      "\n",
      "episode 7, val func loss 1.0845731496810913\n",
      "\n",
      "episode 8, val func loss 0.7904671430587769\n",
      "\n",
      "episode 9, val func loss 0.7743245363235474\n",
      "\n",
      "episode 10, val func loss 0.8286969065666199\n",
      "\n",
      "episode 11, val func loss 0.8669610619544983\n",
      "\n",
      "episode 12, val func loss 0.9649851322174072\n",
      "\n",
      "episode 13, val func loss 0.9629538059234619\n",
      "\n",
      "episode 14, val func loss 0.72676682472229\n",
      "\n",
      "episode 15, val func loss 0.8372415900230408\n",
      "\n",
      "episode 16, val func loss 0.8795500993728638\n",
      "\n",
      "Val func train loss in epoch 12:0.8835356310009956\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.0119351148605347\n",
      "\n",
      "episode 2, val func loss 0.7909117937088013\n",
      "\n",
      "episode 3, val func loss 0.84178626537323\n",
      "\n",
      "episode 4, val func loss 0.8686493039131165\n",
      "\n",
      "episode 5, val func loss 0.9981047511100769\n",
      "\n",
      "episode 6, val func loss 0.9463610649108887\n",
      "\n",
      "episode 7, val func loss 0.9285100102424622\n",
      "\n",
      "episode 8, val func loss 0.8956842422485352\n",
      "\n",
      "episode 9, val func loss 0.8902361392974854\n",
      "\n",
      "episode 10, val func loss 0.9875494837760925\n",
      "\n",
      "episode 11, val func loss 0.9833430647850037\n",
      "\n",
      "episode 12, val func loss 0.8030797243118286\n",
      "\n",
      "episode 13, val func loss 0.8569135665893555\n",
      "\n",
      "episode 14, val func loss 0.8312547206878662\n",
      "\n",
      "episode 15, val func loss 0.8472260236740112\n",
      "\n",
      "episode 16, val func loss 0.9970905780792236\n",
      "\n",
      "Val func train loss in epoch 13:0.904914740473032\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.920470654964447\n",
      "\n",
      "episode 2, val func loss 0.8078994750976562\n",
      "\n",
      "episode 3, val func loss 0.8598138689994812\n",
      "\n",
      "episode 4, val func loss 0.8212428689002991\n",
      "\n",
      "episode 5, val func loss 0.8786265254020691\n",
      "\n",
      "episode 6, val func loss 0.7829805612564087\n",
      "\n",
      "episode 7, val func loss 0.9391091465950012\n",
      "\n",
      "episode 8, val func loss 1.0457831621170044\n",
      "\n",
      "episode 9, val func loss 0.9352869987487793\n",
      "\n",
      "episode 10, val func loss 1.0282902717590332\n",
      "\n",
      "episode 11, val func loss 0.9045753479003906\n",
      "\n",
      "episode 12, val func loss 0.9736567139625549\n",
      "\n",
      "episode 13, val func loss 0.9069037437438965\n",
      "\n",
      "episode 14, val func loss 0.9458069205284119\n",
      "\n",
      "episode 15, val func loss 1.2535018920898438\n",
      "\n",
      "episode 16, val func loss 0.9173981547355652\n",
      "\n",
      "Val func train loss in epoch 14:0.9325841441750526\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.1467646360397339\n",
      "\n",
      "episode 2, val func loss 0.9392619729042053\n",
      "\n",
      "episode 3, val func loss 1.0291463136672974\n",
      "\n",
      "episode 4, val func loss 0.8864683508872986\n",
      "\n",
      "episode 5, val func loss 0.8343163728713989\n",
      "\n",
      "episode 6, val func loss 1.1501950025558472\n",
      "\n",
      "episode 7, val func loss 1.011661171913147\n",
      "\n",
      "episode 8, val func loss 0.8816311955451965\n",
      "\n",
      "episode 9, val func loss 1.0290602445602417\n",
      "\n",
      "episode 10, val func loss 0.8725975751876831\n",
      "\n",
      "episode 11, val func loss 0.7737279534339905\n",
      "\n",
      "episode 12, val func loss 0.8865690231323242\n",
      "\n",
      "episode 13, val func loss 0.7929352521896362\n",
      "\n",
      "episode 14, val func loss 0.8234751224517822\n",
      "\n",
      "episode 15, val func loss 0.9870825409889221\n",
      "\n",
      "episode 16, val func loss 0.8764069676399231\n",
      "\n",
      "Val func train loss in epoch 15:0.9325812309980392\n",
      "***********************TIME WAS 4.860313133398692 min*****************************\n",
      "\n",
      "**********************ROUND 81 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.4222552180290222\n",
      "\n",
      "episode 2, policy loss 0.42225509881973267\n",
      "\n",
      "episode 3, policy loss 0.42225518822669983\n",
      "\n",
      "episode 4, policy loss 0.4222554564476013\n",
      "\n",
      "episode 5, policy loss 0.422255277633667\n",
      "\n",
      "episode 6, policy loss 0.4222553074359894\n",
      "\n",
      "episode 7, policy loss 0.4222552180290222\n",
      "\n",
      "episode 8, policy loss 0.4222553074359894\n",
      "\n",
      "episode 9, policy loss 0.4222553074359894\n",
      "\n",
      "episode 10, policy loss 0.422255277633667\n",
      "\n",
      "episode 11, policy loss 0.422255277633667\n",
      "\n",
      "episode 12, policy loss 0.4222552180290222\n",
      "\n",
      "episode 13, policy loss 0.42225536704063416\n",
      "\n",
      "episode 14, policy loss 0.422255277633667\n",
      "\n",
      "episode 15, policy loss 0.42225536704063416\n",
      "\n",
      "episode 16, policy loss 0.422255277633667\n",
      "\n",
      "Policy train loss in epoch 0:0.422255277633667\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.42225536704063416\n",
      "\n",
      "episode 2, policy loss 0.4222554564476013\n",
      "\n",
      "episode 3, policy loss 0.422255277633667\n",
      "\n",
      "episode 4, policy loss 0.4222553074359894\n",
      "\n",
      "episode 5, policy loss 0.4222553074359894\n",
      "\n",
      "episode 6, policy loss 0.422255277633667\n",
      "\n",
      "episode 7, policy loss 0.422255277633667\n",
      "\n",
      "episode 8, policy loss 0.42225509881973267\n",
      "\n",
      "episode 9, policy loss 0.422255277633667\n",
      "\n",
      "episode 10, policy loss 0.4222552180290222\n",
      "\n",
      "episode 11, policy loss 0.4222552180290222\n",
      "\n",
      "episode 12, policy loss 0.422255277633667\n",
      "\n",
      "episode 13, policy loss 0.42225536704063416\n",
      "\n",
      "episode 14, policy loss 0.422255277633667\n",
      "\n",
      "episode 15, policy loss 0.42225518822669983\n",
      "\n",
      "episode 16, policy loss 0.4222553074359894\n",
      "\n",
      "Policy train loss in epoch 1:0.4222552813589573\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.4222552180290222\n",
      "\n",
      "episode 2, policy loss 0.4222554564476013\n",
      "\n",
      "episode 3, policy loss 0.42225518822669983\n",
      "\n",
      "episode 4, policy loss 0.4222553074359894\n",
      "\n",
      "episode 5, policy loss 0.42225509881973267\n",
      "\n",
      "episode 6, policy loss 0.422255277633667\n",
      "\n",
      "episode 7, policy loss 0.422255277633667\n",
      "\n",
      "episode 8, policy loss 0.4222553074359894\n",
      "\n",
      "episode 9, policy loss 0.4222552180290222\n",
      "\n",
      "episode 10, policy loss 0.422255277633667\n",
      "\n",
      "episode 11, policy loss 0.422255277633667\n",
      "\n",
      "episode 12, policy loss 0.422255277633667\n",
      "\n",
      "episode 13, policy loss 0.422255277633667\n",
      "\n",
      "episode 14, policy loss 0.42225536704063416\n",
      "\n",
      "episode 15, policy loss 0.42225536704063416\n",
      "\n",
      "episode 16, policy loss 0.4222553074359894\n",
      "\n",
      "Policy train loss in epoch 2:0.4222552813589573\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.4222553074359894\n",
      "\n",
      "episode 2, policy loss 0.422255277633667\n",
      "\n",
      "episode 3, policy loss 0.4222554564476013\n",
      "\n",
      "episode 4, policy loss 0.422255277633667\n",
      "\n",
      "episode 5, policy loss 0.42225536704063416\n",
      "\n",
      "episode 6, policy loss 0.422255277633667\n",
      "\n",
      "episode 7, policy loss 0.422255277633667\n",
      "\n",
      "episode 8, policy loss 0.42225509881973267\n",
      "\n",
      "episode 9, policy loss 0.4222552180290222\n",
      "\n",
      "episode 10, policy loss 0.4222552180290222\n",
      "\n",
      "episode 11, policy loss 0.4222553074359894\n",
      "\n",
      "episode 12, policy loss 0.422255277633667\n",
      "\n",
      "episode 13, policy loss 0.42225536704063416\n",
      "\n",
      "episode 14, policy loss 0.4222553074359894\n",
      "\n",
      "episode 15, policy loss 0.422255277633667\n",
      "\n",
      "episode 16, policy loss 0.42225518822669983\n",
      "\n",
      "Policy train loss in epoch 3:0.4222552813589573\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.8299500942230225\n",
      "\n",
      "episode 2, val func loss 0.8451178073883057\n",
      "\n",
      "episode 3, val func loss 0.8436145186424255\n",
      "\n",
      "episode 4, val func loss 0.8985516428947449\n",
      "\n",
      "episode 5, val func loss 0.8327515125274658\n",
      "\n",
      "episode 6, val func loss 0.7400474548339844\n",
      "\n",
      "episode 7, val func loss 0.9695059657096863\n",
      "\n",
      "episode 8, val func loss 0.8260939121246338\n",
      "\n",
      "episode 9, val func loss 0.9414055347442627\n",
      "\n",
      "episode 10, val func loss 0.9592661261558533\n",
      "\n",
      "episode 11, val func loss 0.8347960114479065\n",
      "\n",
      "episode 12, val func loss 0.9453566074371338\n",
      "\n",
      "episode 13, val func loss 0.8419181108474731\n",
      "\n",
      "episode 14, val func loss 0.8943899273872375\n",
      "\n",
      "episode 15, val func loss 0.9085529446601868\n",
      "\n",
      "episode 16, val func loss 0.8326457738876343\n",
      "\n",
      "Val func train loss in epoch 0:0.8714977465569973\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7624678611755371\n",
      "\n",
      "episode 2, val func loss 0.8983736634254456\n",
      "\n",
      "episode 3, val func loss 0.9852760434150696\n",
      "\n",
      "episode 4, val func loss 0.843105137348175\n",
      "\n",
      "episode 5, val func loss 0.876046895980835\n",
      "\n",
      "episode 6, val func loss 0.7911375164985657\n",
      "\n",
      "episode 7, val func loss 0.8055463433265686\n",
      "\n",
      "episode 8, val func loss 0.7708632349967957\n",
      "\n",
      "episode 9, val func loss 0.8258833885192871\n",
      "\n",
      "episode 10, val func loss 0.918796956539154\n",
      "\n",
      "episode 11, val func loss 0.9400259852409363\n",
      "\n",
      "episode 12, val func loss 0.8904004693031311\n",
      "\n",
      "episode 13, val func loss 0.7395085096359253\n",
      "\n",
      "episode 14, val func loss 0.8141455054283142\n",
      "\n",
      "episode 15, val func loss 0.9645095467567444\n",
      "\n",
      "episode 16, val func loss 0.8147070407867432\n",
      "\n",
      "Val func train loss in epoch 1:0.8525496311485767\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.8022538423538208\n",
      "\n",
      "episode 2, val func loss 0.833271861076355\n",
      "\n",
      "episode 3, val func loss 0.8253452777862549\n",
      "\n",
      "episode 4, val func loss 0.9002910256385803\n",
      "\n",
      "episode 5, val func loss 0.8433473110198975\n",
      "\n",
      "episode 6, val func loss 0.7043397426605225\n",
      "\n",
      "episode 7, val func loss 0.987826406955719\n",
      "\n",
      "episode 8, val func loss 0.8100783228874207\n",
      "\n",
      "episode 9, val func loss 0.7701127529144287\n",
      "\n",
      "episode 10, val func loss 0.8654090166091919\n",
      "\n",
      "episode 11, val func loss 0.7762196063995361\n",
      "\n",
      "episode 12, val func loss 0.7449162602424622\n",
      "\n",
      "episode 13, val func loss 0.8209528923034668\n",
      "\n",
      "episode 14, val func loss 0.7939677238464355\n",
      "\n",
      "episode 15, val func loss 0.8373029828071594\n",
      "\n",
      "episode 16, val func loss 0.8088318705558777\n",
      "\n",
      "Val func train loss in epoch 2:0.8202791810035706\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8086075186729431\n",
      "\n",
      "episode 2, val func loss 0.8584630489349365\n",
      "\n",
      "episode 3, val func loss 0.8366245031356812\n",
      "\n",
      "episode 4, val func loss 0.7903651595115662\n",
      "\n",
      "episode 5, val func loss 0.9385955929756165\n",
      "\n",
      "episode 6, val func loss 0.855292797088623\n",
      "\n",
      "episode 7, val func loss 0.8719794154167175\n",
      "\n",
      "episode 8, val func loss 0.9355820417404175\n",
      "\n",
      "episode 9, val func loss 0.8053579926490784\n",
      "\n",
      "episode 10, val func loss 1.1260417699813843\n",
      "\n",
      "episode 11, val func loss 0.7209915518760681\n",
      "\n",
      "episode 12, val func loss 0.8856461048126221\n",
      "\n",
      "episode 13, val func loss 0.7649389505386353\n",
      "\n",
      "episode 14, val func loss 0.9975904822349548\n",
      "\n",
      "episode 15, val func loss 0.9340791702270508\n",
      "\n",
      "episode 16, val func loss 0.8447884321212769\n",
      "\n",
      "Val func train loss in epoch 3:0.8734340332448483\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8403534293174744\n",
      "\n",
      "episode 2, val func loss 1.077942132949829\n",
      "\n",
      "episode 3, val func loss 0.8816009163856506\n",
      "\n",
      "episode 4, val func loss 0.7040523290634155\n",
      "\n",
      "episode 5, val func loss 0.8926429748535156\n",
      "\n",
      "episode 6, val func loss 0.8948799967765808\n",
      "\n",
      "episode 7, val func loss 0.8694046139717102\n",
      "\n",
      "episode 8, val func loss 0.8858939409255981\n",
      "\n",
      "episode 9, val func loss 0.9806435108184814\n",
      "\n",
      "episode 10, val func loss 0.9470165371894836\n",
      "\n",
      "episode 11, val func loss 0.856846809387207\n",
      "\n",
      "episode 12, val func loss 0.9252933263778687\n",
      "\n",
      "episode 13, val func loss 0.8546245694160461\n",
      "\n",
      "episode 14, val func loss 0.8517388105392456\n",
      "\n",
      "episode 15, val func loss 0.8207166194915771\n",
      "\n",
      "episode 16, val func loss 0.9028602242469788\n",
      "\n",
      "Val func train loss in epoch 4:0.8866569213569164\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.9655854105949402\n",
      "\n",
      "episode 2, val func loss 1.045281171798706\n",
      "\n",
      "episode 3, val func loss 0.9000405073165894\n",
      "\n",
      "episode 4, val func loss 0.8466005921363831\n",
      "\n",
      "episode 5, val func loss 1.0131423473358154\n",
      "\n",
      "episode 6, val func loss 0.802760124206543\n",
      "\n",
      "episode 7, val func loss 0.9288073182106018\n",
      "\n",
      "episode 8, val func loss 0.8624237775802612\n",
      "\n",
      "episode 9, val func loss 0.8632142543792725\n",
      "\n",
      "episode 10, val func loss 0.8848745822906494\n",
      "\n",
      "episode 11, val func loss 0.7459815740585327\n",
      "\n",
      "episode 12, val func loss 0.8652334213256836\n",
      "\n",
      "episode 13, val func loss 0.7728279232978821\n",
      "\n",
      "episode 14, val func loss 0.8802292346954346\n",
      "\n",
      "episode 15, val func loss 0.7390974164009094\n",
      "\n",
      "episode 16, val func loss 0.7996855974197388\n",
      "\n",
      "Val func train loss in epoch 5:0.8697365783154964\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8837143778800964\n",
      "\n",
      "episode 2, val func loss 1.0439112186431885\n",
      "\n",
      "episode 3, val func loss 0.7711019515991211\n",
      "\n",
      "episode 4, val func loss 0.895680844783783\n",
      "\n",
      "episode 5, val func loss 0.9676998257637024\n",
      "\n",
      "episode 6, val func loss 0.8924127817153931\n",
      "\n",
      "episode 7, val func loss 0.9269244074821472\n",
      "\n",
      "episode 8, val func loss 0.7449212670326233\n",
      "\n",
      "episode 9, val func loss 0.8901131749153137\n",
      "\n",
      "episode 10, val func loss 0.8726202249526978\n",
      "\n",
      "episode 11, val func loss 0.8507776856422424\n",
      "\n",
      "episode 12, val func loss 0.8255146741867065\n",
      "\n",
      "episode 13, val func loss 0.7562909722328186\n",
      "\n",
      "episode 14, val func loss 0.7083085179328918\n",
      "\n",
      "episode 15, val func loss 0.9430599212646484\n",
      "\n",
      "episode 16, val func loss 0.8326460719108582\n",
      "\n",
      "Val func train loss in epoch 6:0.8628561198711395\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.901491105556488\n",
      "\n",
      "episode 2, val func loss 0.9437528252601624\n",
      "\n",
      "episode 3, val func loss 0.9918790459632874\n",
      "\n",
      "episode 4, val func loss 0.8260877728462219\n",
      "\n",
      "episode 5, val func loss 0.8407384157180786\n",
      "\n",
      "episode 6, val func loss 0.8532649278640747\n",
      "\n",
      "episode 7, val func loss 0.8776522278785706\n",
      "\n",
      "episode 8, val func loss 0.8062673807144165\n",
      "\n",
      "episode 9, val func loss 0.7709007263183594\n",
      "\n",
      "episode 10, val func loss 0.7220228314399719\n",
      "\n",
      "episode 11, val func loss 0.8327366709709167\n",
      "\n",
      "episode 12, val func loss 0.8779251575469971\n",
      "\n",
      "episode 13, val func loss 0.7622080445289612\n",
      "\n",
      "episode 14, val func loss 0.7817097902297974\n",
      "\n",
      "episode 15, val func loss 0.7945278882980347\n",
      "\n",
      "episode 16, val func loss 0.7458042502403259\n",
      "\n",
      "Val func train loss in epoch 7:0.8330605663359165\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.9094860553741455\n",
      "\n",
      "episode 2, val func loss 0.7314459085464478\n",
      "\n",
      "episode 3, val func loss 0.8382440805435181\n",
      "\n",
      "episode 4, val func loss 0.8329193592071533\n",
      "\n",
      "episode 5, val func loss 0.8025272488594055\n",
      "\n",
      "episode 6, val func loss 0.7436167001724243\n",
      "\n",
      "episode 7, val func loss 0.925202488899231\n",
      "\n",
      "episode 8, val func loss 0.9273623824119568\n",
      "\n",
      "episode 9, val func loss 0.7502164840698242\n",
      "\n",
      "episode 10, val func loss 0.7670891284942627\n",
      "\n",
      "episode 11, val func loss 0.8129971027374268\n",
      "\n",
      "episode 12, val func loss 0.7238938212394714\n",
      "\n",
      "episode 13, val func loss 0.8348182439804077\n",
      "\n",
      "episode 14, val func loss 0.9088642597198486\n",
      "\n",
      "episode 15, val func loss 0.8530358076095581\n",
      "\n",
      "episode 16, val func loss 0.903182327747345\n",
      "\n",
      "Val func train loss in epoch 8:0.8290563374757767\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.875670313835144\n",
      "\n",
      "episode 2, val func loss 0.8446089625358582\n",
      "\n",
      "episode 3, val func loss 0.8889749050140381\n",
      "\n",
      "episode 4, val func loss 0.7502995729446411\n",
      "\n",
      "episode 5, val func loss 0.7400457859039307\n",
      "\n",
      "episode 6, val func loss 0.9281454086303711\n",
      "\n",
      "episode 7, val func loss 0.9171723127365112\n",
      "\n",
      "episode 8, val func loss 0.9379061460494995\n",
      "\n",
      "episode 9, val func loss 0.9477076530456543\n",
      "\n",
      "episode 10, val func loss 0.9006705284118652\n",
      "\n",
      "episode 11, val func loss 0.9116536378860474\n",
      "\n",
      "episode 12, val func loss 0.8967089653015137\n",
      "\n",
      "episode 13, val func loss 1.023773193359375\n",
      "\n",
      "episode 14, val func loss 0.9741354584693909\n",
      "\n",
      "episode 15, val func loss 0.8284817934036255\n",
      "\n",
      "episode 16, val func loss 0.823506236076355\n",
      "\n",
      "Val func train loss in epoch 9:0.8868413046002388\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.9507255554199219\n",
      "\n",
      "episode 2, val func loss 1.03165864944458\n",
      "\n",
      "episode 3, val func loss 0.7449605464935303\n",
      "\n",
      "episode 4, val func loss 0.7990238666534424\n",
      "\n",
      "episode 5, val func loss 0.8765541911125183\n",
      "\n",
      "episode 6, val func loss 0.9271600246429443\n",
      "\n",
      "episode 7, val func loss 0.8976724147796631\n",
      "\n",
      "episode 8, val func loss 0.9785823225975037\n",
      "\n",
      "episode 9, val func loss 0.8461690545082092\n",
      "\n",
      "episode 10, val func loss 0.8759033679962158\n",
      "\n",
      "episode 11, val func loss 0.6293708086013794\n",
      "\n",
      "episode 12, val func loss 0.9161121845245361\n",
      "\n",
      "episode 13, val func loss 0.8391559720039368\n",
      "\n",
      "episode 14, val func loss 0.8068323135375977\n",
      "\n",
      "episode 15, val func loss 0.6789346933364868\n",
      "\n",
      "episode 16, val func loss 0.8551813364028931\n",
      "\n",
      "Val func train loss in epoch 10:0.8533748313784599\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.8245853185653687\n",
      "\n",
      "episode 2, val func loss 0.8088462948799133\n",
      "\n",
      "episode 3, val func loss 0.9755313992500305\n",
      "\n",
      "episode 4, val func loss 0.8403453826904297\n",
      "\n",
      "episode 5, val func loss 0.7720289826393127\n",
      "\n",
      "episode 6, val func loss 0.9008137583732605\n",
      "\n",
      "episode 7, val func loss 0.8248559832572937\n",
      "\n",
      "episode 8, val func loss 0.9540286660194397\n",
      "\n",
      "episode 9, val func loss 0.8727870583534241\n",
      "\n",
      "episode 10, val func loss 0.8886404633522034\n",
      "\n",
      "episode 11, val func loss 0.8087853193283081\n",
      "\n",
      "episode 12, val func loss 0.8171274662017822\n",
      "\n",
      "episode 13, val func loss 0.8307742476463318\n",
      "\n",
      "episode 14, val func loss 0.814987301826477\n",
      "\n",
      "episode 15, val func loss 0.8611558079719543\n",
      "\n",
      "episode 16, val func loss 0.7947316765785217\n",
      "\n",
      "Val func train loss in epoch 11:0.8493765704333782\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.8508450388908386\n",
      "\n",
      "episode 2, val func loss 0.8273198008537292\n",
      "\n",
      "episode 3, val func loss 0.8098835349082947\n",
      "\n",
      "episode 4, val func loss 0.8227932453155518\n",
      "\n",
      "episode 5, val func loss 0.8996396660804749\n",
      "\n",
      "episode 6, val func loss 0.7720764875411987\n",
      "\n",
      "episode 7, val func loss 0.8621251583099365\n",
      "\n",
      "episode 8, val func loss 0.8024204969406128\n",
      "\n",
      "episode 9, val func loss 0.8479776382446289\n",
      "\n",
      "episode 10, val func loss 0.8323999047279358\n",
      "\n",
      "episode 11, val func loss 0.79314124584198\n",
      "\n",
      "episode 12, val func loss 0.7711548209190369\n",
      "\n",
      "episode 13, val func loss 0.9013396501541138\n",
      "\n",
      "episode 14, val func loss 0.9030793309211731\n",
      "\n",
      "episode 15, val func loss 0.8252663016319275\n",
      "\n",
      "episode 16, val func loss 0.7829301357269287\n",
      "\n",
      "Val func train loss in epoch 12:0.8315245285630226\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8840503692626953\n",
      "\n",
      "episode 2, val func loss 0.8930551409721375\n",
      "\n",
      "episode 3, val func loss 0.7597256898880005\n",
      "\n",
      "episode 4, val func loss 0.8576371669769287\n",
      "\n",
      "episode 5, val func loss 0.9177421927452087\n",
      "\n",
      "episode 6, val func loss 0.8724846243858337\n",
      "\n",
      "episode 7, val func loss 0.8602815866470337\n",
      "\n",
      "episode 8, val func loss 0.814056932926178\n",
      "\n",
      "episode 9, val func loss 0.821864902973175\n",
      "\n",
      "episode 10, val func loss 0.8022193908691406\n",
      "\n",
      "episode 11, val func loss 0.8752953410148621\n",
      "\n",
      "episode 12, val func loss 0.9171398282051086\n",
      "\n",
      "episode 13, val func loss 0.8982473611831665\n",
      "\n",
      "episode 14, val func loss 0.9423158168792725\n",
      "\n",
      "episode 15, val func loss 0.9206462502479553\n",
      "\n",
      "episode 16, val func loss 0.937383234500885\n",
      "\n",
      "Val func train loss in epoch 13:0.8733841143548489\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7629233598709106\n",
      "\n",
      "episode 2, val func loss 0.8283460736274719\n",
      "\n",
      "episode 3, val func loss 0.9478932619094849\n",
      "\n",
      "episode 4, val func loss 0.7964884042739868\n",
      "\n",
      "episode 5, val func loss 0.8641393780708313\n",
      "\n",
      "episode 6, val func loss 0.8539274334907532\n",
      "\n",
      "episode 7, val func loss 0.8979507088661194\n",
      "\n",
      "episode 8, val func loss 0.8070207834243774\n",
      "\n",
      "episode 9, val func loss 0.8827995657920837\n",
      "\n",
      "episode 10, val func loss 0.815450131893158\n",
      "\n",
      "episode 11, val func loss 0.9303808212280273\n",
      "\n",
      "episode 12, val func loss 0.8456557989120483\n",
      "\n",
      "episode 13, val func loss 1.015252709388733\n",
      "\n",
      "episode 14, val func loss 0.7167962193489075\n",
      "\n",
      "episode 15, val func loss 1.0159298181533813\n",
      "\n",
      "episode 16, val func loss 0.7304880023002625\n",
      "\n",
      "Val func train loss in epoch 14:0.8569651544094086\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.9209030866622925\n",
      "\n",
      "episode 2, val func loss 0.76582270860672\n",
      "\n",
      "episode 3, val func loss 1.0121009349822998\n",
      "\n",
      "episode 4, val func loss 0.8157564997673035\n",
      "\n",
      "episode 5, val func loss 0.8710135817527771\n",
      "\n",
      "episode 6, val func loss 0.8262020945549011\n",
      "\n",
      "episode 7, val func loss 0.8590055704116821\n",
      "\n",
      "episode 8, val func loss 0.8387112021446228\n",
      "\n",
      "episode 9, val func loss 0.8073095679283142\n",
      "\n",
      "episode 10, val func loss 0.8476854562759399\n",
      "\n",
      "episode 11, val func loss 0.9993636012077332\n",
      "\n",
      "episode 12, val func loss 0.7425111532211304\n",
      "\n",
      "episode 13, val func loss 0.849213182926178\n",
      "\n",
      "episode 14, val func loss 0.8643708825111389\n",
      "\n",
      "episode 15, val func loss 0.6966978907585144\n",
      "\n",
      "episode 16, val func loss 0.8486604690551758\n",
      "\n",
      "Val func train loss in epoch 15:0.8478329926729202\n",
      "***********************TIME WAS 4.862473750114441 min*****************************\n",
      "\n",
      "**********************ROUND 82 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.7992765307426453\n",
      "\n",
      "episode 2, policy loss 0.7992766499519348\n",
      "\n",
      "episode 3, policy loss 0.7992768883705139\n",
      "\n",
      "episode 4, policy loss 0.7992765307426453\n",
      "\n",
      "episode 5, policy loss 0.7992767095565796\n",
      "\n",
      "episode 6, policy loss 0.7992766499519348\n",
      "\n",
      "episode 7, policy loss 0.7992765307426453\n",
      "\n",
      "episode 8, policy loss 0.7992766499519348\n",
      "\n",
      "episode 9, policy loss 0.7992765307426453\n",
      "\n",
      "episode 10, policy loss 0.7992765307426453\n",
      "\n",
      "episode 11, policy loss 0.7992767095565796\n",
      "\n",
      "episode 12, policy loss 0.7992765307426453\n",
      "\n",
      "episode 13, policy loss 0.7992765307426453\n",
      "\n",
      "episode 14, policy loss 0.7992765307426453\n",
      "\n",
      "episode 15, policy loss 0.7992765307426453\n",
      "\n",
      "episode 16, policy loss 0.7992767095565796\n",
      "\n",
      "Policy train loss in epoch 0:0.7992766089737415\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.7992765307426453\n",
      "\n",
      "episode 2, policy loss 0.7992765307426453\n",
      "\n",
      "episode 3, policy loss 0.7992768883705139\n",
      "\n",
      "episode 4, policy loss 0.7992765307426453\n",
      "\n",
      "episode 5, policy loss 0.7992766499519348\n",
      "\n",
      "episode 6, policy loss 0.7992765307426453\n",
      "\n",
      "episode 7, policy loss 0.7992765307426453\n",
      "\n",
      "episode 8, policy loss 0.7992765307426453\n",
      "\n",
      "episode 9, policy loss 0.7992765307426453\n",
      "\n",
      "episode 10, policy loss 0.7992767095565796\n",
      "\n",
      "episode 11, policy loss 0.7992765307426453\n",
      "\n",
      "episode 12, policy loss 0.7992766499519348\n",
      "\n",
      "episode 13, policy loss 0.7992767095565796\n",
      "\n",
      "episode 14, policy loss 0.7992765307426453\n",
      "\n",
      "episode 15, policy loss 0.7992766499519348\n",
      "\n",
      "episode 16, policy loss 0.7992767095565796\n",
      "\n",
      "Policy train loss in epoch 1:0.7992766089737415\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.7992765307426453\n",
      "\n",
      "episode 2, policy loss 0.7992767095565796\n",
      "\n",
      "episode 3, policy loss 0.7992765307426453\n",
      "\n",
      "episode 4, policy loss 0.7992765307426453\n",
      "\n",
      "episode 5, policy loss 0.7992765307426453\n",
      "\n",
      "episode 6, policy loss 0.7992766499519348\n",
      "\n",
      "episode 7, policy loss 0.7992765307426453\n",
      "\n",
      "episode 8, policy loss 0.7992765307426453\n",
      "\n",
      "episode 9, policy loss 0.7992767095565796\n",
      "\n",
      "episode 10, policy loss 0.7992766499519348\n",
      "\n",
      "episode 11, policy loss 0.7992763519287109\n",
      "\n",
      "episode 12, policy loss 0.7992761731147766\n",
      "\n",
      "episode 13, policy loss 0.7992752194404602\n",
      "\n",
      "episode 14, policy loss 0.7992708086967468\n",
      "\n",
      "episode 15, policy loss 0.7992258667945862\n",
      "\n",
      "episode 16, policy loss 0.7979406714439392\n",
      "\n",
      "Policy train loss in epoch 2:0.7991894371807575\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.7572445869445801\n",
      "\n",
      "episode 2, policy loss 0.9878222346305847\n",
      "\n",
      "episode 3, policy loss 0.7573325634002686\n",
      "\n",
      "episode 4, policy loss 0.7913872599601746\n",
      "\n",
      "episode 5, policy loss 0.7985882759094238\n",
      "\n",
      "episode 6, policy loss 0.7991290092468262\n",
      "\n",
      "episode 7, policy loss 0.7992215156555176\n",
      "\n",
      "episode 8, policy loss 0.7992535829544067\n",
      "\n",
      "episode 9, policy loss 0.7992640733718872\n",
      "\n",
      "episode 10, policy loss 0.7992671728134155\n",
      "\n",
      "episode 11, policy loss 0.7992687225341797\n",
      "\n",
      "episode 12, policy loss 0.7992700338363647\n",
      "\n",
      "episode 13, policy loss 0.7992701530456543\n",
      "\n",
      "episode 14, policy loss 0.7992706298828125\n",
      "\n",
      "episode 15, policy loss 0.7992713451385498\n",
      "\n",
      "episode 16, policy loss 0.7992703318595886\n",
      "\n",
      "Policy train loss in epoch 3:0.8052582181990147\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.2516794204711914\n",
      "\n",
      "episode 2, val func loss 0.8738847970962524\n",
      "\n",
      "episode 3, val func loss 1.1507693529129028\n",
      "\n",
      "episode 4, val func loss 0.850501298904419\n",
      "\n",
      "episode 5, val func loss 0.8841114044189453\n",
      "\n",
      "episode 6, val func loss 0.8864330053329468\n",
      "\n",
      "episode 7, val func loss 0.9282389283180237\n",
      "\n",
      "episode 8, val func loss 0.9296483993530273\n",
      "\n",
      "episode 9, val func loss 0.8302298784255981\n",
      "\n",
      "episode 10, val func loss 0.9199169278144836\n",
      "\n",
      "episode 11, val func loss 0.9534765481948853\n",
      "\n",
      "episode 12, val func loss 1.0647367238998413\n",
      "\n",
      "episode 13, val func loss 0.8907873034477234\n",
      "\n",
      "episode 14, val func loss 0.7850578427314758\n",
      "\n",
      "episode 15, val func loss 0.9035428166389465\n",
      "\n",
      "episode 16, val func loss 1.0421741008758545\n",
      "\n",
      "Val func train loss in epoch 0:0.9465742968022823\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7872107028961182\n",
      "\n",
      "episode 2, val func loss 0.912003219127655\n",
      "\n",
      "episode 3, val func loss 0.8593258261680603\n",
      "\n",
      "episode 4, val func loss 0.86655592918396\n",
      "\n",
      "episode 5, val func loss 0.7945064306259155\n",
      "\n",
      "episode 6, val func loss 0.9567939043045044\n",
      "\n",
      "episode 7, val func loss 0.9014315605163574\n",
      "\n",
      "episode 8, val func loss 0.7978312373161316\n",
      "\n",
      "episode 9, val func loss 0.8412463068962097\n",
      "\n",
      "episode 10, val func loss 0.7758817672729492\n",
      "\n",
      "episode 11, val func loss 0.7994291186332703\n",
      "\n",
      "episode 12, val func loss 0.7003636956214905\n",
      "\n",
      "episode 13, val func loss 0.7604867815971375\n",
      "\n",
      "episode 14, val func loss 0.8105238080024719\n",
      "\n",
      "episode 15, val func loss 0.7968407869338989\n",
      "\n",
      "episode 16, val func loss 0.7762250900268555\n",
      "\n",
      "Val func train loss in epoch 1:0.8210410103201866\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7119795083999634\n",
      "\n",
      "episode 2, val func loss 0.7434388995170593\n",
      "\n",
      "episode 3, val func loss 0.7391806840896606\n",
      "\n",
      "episode 4, val func loss 0.7973249554634094\n",
      "\n",
      "episode 5, val func loss 0.7736877202987671\n",
      "\n",
      "episode 6, val func loss 0.685786247253418\n",
      "\n",
      "episode 7, val func loss 0.8589337468147278\n",
      "\n",
      "episode 8, val func loss 0.9015345573425293\n",
      "\n",
      "episode 9, val func loss 0.8402843475341797\n",
      "\n",
      "episode 10, val func loss 0.6811254620552063\n",
      "\n",
      "episode 11, val func loss 0.7375757098197937\n",
      "\n",
      "episode 12, val func loss 0.6921075582504272\n",
      "\n",
      "episode 13, val func loss 0.8516860008239746\n",
      "\n",
      "episode 14, val func loss 0.7116684317588806\n",
      "\n",
      "episode 15, val func loss 0.871740996837616\n",
      "\n",
      "episode 16, val func loss 0.7977398037910461\n",
      "\n",
      "Val func train loss in epoch 2:0.7747371643781662\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8220770359039307\n",
      "\n",
      "episode 2, val func loss 0.8440379500389099\n",
      "\n",
      "episode 3, val func loss 0.7225990295410156\n",
      "\n",
      "episode 4, val func loss 0.9333184361457825\n",
      "\n",
      "episode 5, val func loss 0.757209300994873\n",
      "\n",
      "episode 6, val func loss 0.8792650103569031\n",
      "\n",
      "episode 7, val func loss 0.8181043267250061\n",
      "\n",
      "episode 8, val func loss 0.8218991756439209\n",
      "\n",
      "episode 9, val func loss 0.8905996680259705\n",
      "\n",
      "episode 10, val func loss 0.9897657036781311\n",
      "\n",
      "episode 11, val func loss 0.7931454181671143\n",
      "\n",
      "episode 12, val func loss 0.7337892651557922\n",
      "\n",
      "episode 13, val func loss 0.8129579424858093\n",
      "\n",
      "episode 14, val func loss 0.8594816327095032\n",
      "\n",
      "episode 15, val func loss 0.7867574691772461\n",
      "\n",
      "episode 16, val func loss 0.8290666937828064\n",
      "\n",
      "Val func train loss in epoch 3:0.8308796286582947\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8122074604034424\n",
      "\n",
      "episode 2, val func loss 0.821013867855072\n",
      "\n",
      "episode 3, val func loss 0.8338454961776733\n",
      "\n",
      "episode 4, val func loss 0.7261171936988831\n",
      "\n",
      "episode 5, val func loss 0.7108299732208252\n",
      "\n",
      "episode 6, val func loss 0.772028923034668\n",
      "\n",
      "episode 7, val func loss 0.8010329604148865\n",
      "\n",
      "episode 8, val func loss 0.7471310496330261\n",
      "\n",
      "episode 9, val func loss 0.9437077045440674\n",
      "\n",
      "episode 10, val func loss 0.8676091432571411\n",
      "\n",
      "episode 11, val func loss 0.8525274395942688\n",
      "\n",
      "episode 12, val func loss 0.791205644607544\n",
      "\n",
      "episode 13, val func loss 0.8338764309883118\n",
      "\n",
      "episode 14, val func loss 0.7450817823410034\n",
      "\n",
      "episode 15, val func loss 0.7608731985092163\n",
      "\n",
      "episode 16, val func loss 0.7865960597991943\n",
      "\n",
      "Val func train loss in epoch 4:0.8003552705049515\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7619272470474243\n",
      "\n",
      "episode 2, val func loss 0.8231260180473328\n",
      "\n",
      "episode 3, val func loss 0.7784253358840942\n",
      "\n",
      "episode 4, val func loss 0.8627187013626099\n",
      "\n",
      "episode 5, val func loss 0.673376202583313\n",
      "\n",
      "episode 6, val func loss 0.8068177103996277\n",
      "\n",
      "episode 7, val func loss 0.7382968664169312\n",
      "\n",
      "episode 8, val func loss 0.8177672624588013\n",
      "\n",
      "episode 9, val func loss 0.8943158388137817\n",
      "\n",
      "episode 10, val func loss 0.9860280156135559\n",
      "\n",
      "episode 11, val func loss 0.882490336894989\n",
      "\n",
      "episode 12, val func loss 0.8624119162559509\n",
      "\n",
      "episode 13, val func loss 0.9697911143302917\n",
      "\n",
      "episode 14, val func loss 0.8837975263595581\n",
      "\n",
      "episode 15, val func loss 0.9468241333961487\n",
      "\n",
      "episode 16, val func loss 0.80561763048172\n",
      "\n",
      "Val func train loss in epoch 5:0.8433582410216331\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8493406772613525\n",
      "\n",
      "episode 2, val func loss 0.843678891658783\n",
      "\n",
      "episode 3, val func loss 0.8097757697105408\n",
      "\n",
      "episode 4, val func loss 1.010478138923645\n",
      "\n",
      "episode 5, val func loss 0.8086297512054443\n",
      "\n",
      "episode 6, val func loss 0.8733528852462769\n",
      "\n",
      "episode 7, val func loss 0.8476610779762268\n",
      "\n",
      "episode 8, val func loss 0.7809911370277405\n",
      "\n",
      "episode 9, val func loss 0.7654226422309875\n",
      "\n",
      "episode 10, val func loss 0.8934948444366455\n",
      "\n",
      "episode 11, val func loss 0.8697662353515625\n",
      "\n",
      "episode 12, val func loss 0.6890217661857605\n",
      "\n",
      "episode 13, val func loss 0.8348932862281799\n",
      "\n",
      "episode 14, val func loss 0.9375194907188416\n",
      "\n",
      "episode 15, val func loss 0.9322848916053772\n",
      "\n",
      "episode 16, val func loss 0.9017607569694519\n",
      "\n",
      "Val func train loss in epoch 6:0.853004515171051\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.8714563250541687\n",
      "\n",
      "episode 2, val func loss 0.7992942929267883\n",
      "\n",
      "episode 3, val func loss 0.8458387851715088\n",
      "\n",
      "episode 4, val func loss 0.8661314845085144\n",
      "\n",
      "episode 5, val func loss 0.7945083975791931\n",
      "\n",
      "episode 6, val func loss 0.75885009765625\n",
      "\n",
      "episode 7, val func loss 0.8461233377456665\n",
      "\n",
      "episode 8, val func loss 0.7699810862541199\n",
      "\n",
      "episode 9, val func loss 0.7866735458374023\n",
      "\n",
      "episode 10, val func loss 0.89007967710495\n",
      "\n",
      "episode 11, val func loss 0.8399972915649414\n",
      "\n",
      "episode 12, val func loss 0.6290220022201538\n",
      "\n",
      "episode 13, val func loss 0.7429054975509644\n",
      "\n",
      "episode 14, val func loss 0.8203368782997131\n",
      "\n",
      "episode 15, val func loss 0.7710198163986206\n",
      "\n",
      "episode 16, val func loss 0.891510546207428\n",
      "\n",
      "Val func train loss in epoch 7:0.807733066380024\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7995569109916687\n",
      "\n",
      "episode 2, val func loss 0.7806711792945862\n",
      "\n",
      "episode 3, val func loss 0.7270575761795044\n",
      "\n",
      "episode 4, val func loss 0.6858611702919006\n",
      "\n",
      "episode 5, val func loss 0.9249527454376221\n",
      "\n",
      "episode 6, val func loss 0.7499359846115112\n",
      "\n",
      "episode 7, val func loss 0.8347454071044922\n",
      "\n",
      "episode 8, val func loss 0.7864487767219543\n",
      "\n",
      "episode 9, val func loss 0.9573268294334412\n",
      "\n",
      "episode 10, val func loss 0.9419574737548828\n",
      "\n",
      "episode 11, val func loss 0.8281869888305664\n",
      "\n",
      "episode 12, val func loss 0.7455930709838867\n",
      "\n",
      "episode 13, val func loss 0.8962988257408142\n",
      "\n",
      "episode 14, val func loss 0.8087350130081177\n",
      "\n",
      "episode 15, val func loss 0.8737884163856506\n",
      "\n",
      "episode 16, val func loss 0.7607805132865906\n",
      "\n",
      "Val func train loss in epoch 8:0.8188685551285744\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8936807513237\n",
      "\n",
      "episode 2, val func loss 0.9145015478134155\n",
      "\n",
      "episode 3, val func loss 0.858587384223938\n",
      "\n",
      "episode 4, val func loss 0.8191313743591309\n",
      "\n",
      "episode 5, val func loss 0.8577623963356018\n",
      "\n",
      "episode 6, val func loss 0.7444472908973694\n",
      "\n",
      "episode 7, val func loss 0.8150492310523987\n",
      "\n",
      "episode 8, val func loss 0.8384281992912292\n",
      "\n",
      "episode 9, val func loss 0.8385306596755981\n",
      "\n",
      "episode 10, val func loss 0.7363777160644531\n",
      "\n",
      "episode 11, val func loss 0.8202261328697205\n",
      "\n",
      "episode 12, val func loss 0.811255693435669\n",
      "\n",
      "episode 13, val func loss 0.790191650390625\n",
      "\n",
      "episode 14, val func loss 0.8417690396308899\n",
      "\n",
      "episode 15, val func loss 0.8492245078086853\n",
      "\n",
      "episode 16, val func loss 0.6990163922309875\n",
      "\n",
      "Val func train loss in epoch 9:0.8205112479627132\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7454507946968079\n",
      "\n",
      "episode 2, val func loss 0.827077329158783\n",
      "\n",
      "episode 3, val func loss 0.793809711933136\n",
      "\n",
      "episode 4, val func loss 0.819072425365448\n",
      "\n",
      "episode 5, val func loss 0.6947915554046631\n",
      "\n",
      "episode 6, val func loss 0.9595162868499756\n",
      "\n",
      "episode 7, val func loss 0.7339547276496887\n",
      "\n",
      "episode 8, val func loss 0.8046949505805969\n",
      "\n",
      "episode 9, val func loss 0.847636878490448\n",
      "\n",
      "episode 10, val func loss 0.9064438343048096\n",
      "\n",
      "episode 11, val func loss 0.8199390172958374\n",
      "\n",
      "episode 12, val func loss 0.8734927773475647\n",
      "\n",
      "episode 13, val func loss 1.0477111339569092\n",
      "\n",
      "episode 14, val func loss 0.8919952511787415\n",
      "\n",
      "episode 15, val func loss 0.9596126675605774\n",
      "\n",
      "episode 16, val func loss 0.7139098048210144\n",
      "\n",
      "Val func train loss in epoch 10:0.8399443216621876\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9777655005455017\n",
      "\n",
      "episode 2, val func loss 0.7523055076599121\n",
      "\n",
      "episode 3, val func loss 0.7577072978019714\n",
      "\n",
      "episode 4, val func loss 0.8556951880455017\n",
      "\n",
      "episode 5, val func loss 0.9041609764099121\n",
      "\n",
      "episode 6, val func loss 0.847834587097168\n",
      "\n",
      "episode 7, val func loss 0.7704281210899353\n",
      "\n",
      "episode 8, val func loss 0.8325607776641846\n",
      "\n",
      "episode 9, val func loss 0.7647410035133362\n",
      "\n",
      "episode 10, val func loss 0.7688886523246765\n",
      "\n",
      "episode 11, val func loss 0.809718906879425\n",
      "\n",
      "episode 12, val func loss 0.8106555342674255\n",
      "\n",
      "episode 13, val func loss 0.8119009137153625\n",
      "\n",
      "episode 14, val func loss 0.7746694684028625\n",
      "\n",
      "episode 15, val func loss 0.7930911779403687\n",
      "\n",
      "episode 16, val func loss 0.732086181640625\n",
      "\n",
      "Val func train loss in epoch 11:0.8102631121873856\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7009402513504028\n",
      "\n",
      "episode 2, val func loss 0.8379759788513184\n",
      "\n",
      "episode 3, val func loss 0.7307246923446655\n",
      "\n",
      "episode 4, val func loss 0.7831248641014099\n",
      "\n",
      "episode 5, val func loss 0.8804658055305481\n",
      "\n",
      "episode 6, val func loss 0.65288245677948\n",
      "\n",
      "episode 7, val func loss 0.7553603053092957\n",
      "\n",
      "episode 8, val func loss 0.7322378158569336\n",
      "\n",
      "episode 9, val func loss 0.8190626502037048\n",
      "\n",
      "episode 10, val func loss 0.8864879012107849\n",
      "\n",
      "episode 11, val func loss 0.7356935739517212\n",
      "\n",
      "episode 12, val func loss 0.840133011341095\n",
      "\n",
      "episode 13, val func loss 0.7741286158561707\n",
      "\n",
      "episode 14, val func loss 0.8758330941200256\n",
      "\n",
      "episode 15, val func loss 0.6813850402832031\n",
      "\n",
      "episode 16, val func loss 0.8031209111213684\n",
      "\n",
      "Val func train loss in epoch 12:0.780597310513258\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.7350256443023682\n",
      "\n",
      "episode 2, val func loss 0.7773383855819702\n",
      "\n",
      "episode 3, val func loss 0.9230360388755798\n",
      "\n",
      "episode 4, val func loss 0.6793286800384521\n",
      "\n",
      "episode 5, val func loss 0.7638193964958191\n",
      "\n",
      "episode 6, val func loss 0.9103158116340637\n",
      "\n",
      "episode 7, val func loss 0.7413240671157837\n",
      "\n",
      "episode 8, val func loss 0.7562017440795898\n",
      "\n",
      "episode 9, val func loss 0.7450486421585083\n",
      "\n",
      "episode 10, val func loss 0.7513967752456665\n",
      "\n",
      "episode 11, val func loss 0.805212140083313\n",
      "\n",
      "episode 12, val func loss 0.8373861312866211\n",
      "\n",
      "episode 13, val func loss 0.8414433002471924\n",
      "\n",
      "episode 14, val func loss 0.784568727016449\n",
      "\n",
      "episode 15, val func loss 0.8232909440994263\n",
      "\n",
      "episode 16, val func loss 0.8711630702018738\n",
      "\n",
      "Val func train loss in epoch 13:0.7966187186539173\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.8847573399543762\n",
      "\n",
      "episode 2, val func loss 0.903684139251709\n",
      "\n",
      "episode 3, val func loss 0.7035835981369019\n",
      "\n",
      "episode 4, val func loss 0.907018780708313\n",
      "\n",
      "episode 5, val func loss 0.9057466387748718\n",
      "\n",
      "episode 6, val func loss 0.8552210330963135\n",
      "\n",
      "episode 7, val func loss 0.8505396842956543\n",
      "\n",
      "episode 8, val func loss 0.7731459140777588\n",
      "\n",
      "episode 9, val func loss 0.9778666496276855\n",
      "\n",
      "episode 10, val func loss 0.8855787515640259\n",
      "\n",
      "episode 11, val func loss 0.8589633703231812\n",
      "\n",
      "episode 12, val func loss 0.8680932521820068\n",
      "\n",
      "episode 13, val func loss 0.8400282859802246\n",
      "\n",
      "episode 14, val func loss 0.9891427159309387\n",
      "\n",
      "episode 15, val func loss 0.7738304138183594\n",
      "\n",
      "episode 16, val func loss 0.7707106471061707\n",
      "\n",
      "Val func train loss in epoch 14:0.8592444509267807\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.931839644908905\n",
      "\n",
      "episode 2, val func loss 0.7392243146896362\n",
      "\n",
      "episode 3, val func loss 0.8154188394546509\n",
      "\n",
      "episode 4, val func loss 0.7832247018814087\n",
      "\n",
      "episode 5, val func loss 0.8629408478736877\n",
      "\n",
      "episode 6, val func loss 0.940516471862793\n",
      "\n",
      "episode 7, val func loss 1.0206855535507202\n",
      "\n",
      "episode 8, val func loss 0.7012670636177063\n",
      "\n",
      "episode 9, val func loss 0.8874104619026184\n",
      "\n",
      "episode 10, val func loss 1.0240298509597778\n",
      "\n",
      "episode 11, val func loss 0.8223726153373718\n",
      "\n",
      "episode 12, val func loss 0.8857158422470093\n",
      "\n",
      "episode 13, val func loss 1.186264991760254\n",
      "\n",
      "episode 14, val func loss 0.8968502879142761\n",
      "\n",
      "episode 15, val func loss 0.9469027519226074\n",
      "\n",
      "episode 16, val func loss 1.3749371767044067\n",
      "\n",
      "Val func train loss in epoch 15:0.9262250885367393\n",
      "***********************TIME WAS 4.858414812882741 min*****************************\n",
      "\n",
      "**********************ROUND 83 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.6419731974601746\n",
      "\n",
      "episode 2, policy loss -0.641973614692688\n",
      "\n",
      "episode 3, policy loss -0.6419730186462402\n",
      "\n",
      "episode 4, policy loss -0.6419726014137268\n",
      "\n",
      "episode 5, policy loss -0.6419721245765686\n",
      "\n",
      "episode 6, policy loss -0.6419730186462402\n",
      "\n",
      "episode 7, policy loss -0.6419727802276611\n",
      "\n",
      "episode 8, policy loss -0.6419732570648193\n",
      "\n",
      "episode 9, policy loss -0.6419733166694641\n",
      "\n",
      "episode 10, policy loss -0.6419740319252014\n",
      "\n",
      "episode 11, policy loss -0.6419737935066223\n",
      "\n",
      "episode 12, policy loss -0.6419744491577148\n",
      "\n",
      "episode 13, policy loss -0.6419746279716492\n",
      "\n",
      "episode 14, policy loss -0.6419753432273865\n",
      "\n",
      "episode 15, policy loss -0.6419755220413208\n",
      "\n",
      "episode 16, policy loss -0.6419757008552551\n",
      "\n",
      "Policy train loss in epoch 0:-0.6419737748801708\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.6419758796691895\n",
      "\n",
      "episode 2, policy loss -0.641976535320282\n",
      "\n",
      "episode 3, policy loss -0.6419762969017029\n",
      "\n",
      "episode 4, policy loss -0.641976535320282\n",
      "\n",
      "episode 5, policy loss -0.6419768929481506\n",
      "\n",
      "episode 6, policy loss -0.6419768333435059\n",
      "\n",
      "episode 7, policy loss -0.6419770121574402\n",
      "\n",
      "episode 8, policy loss -0.6419774889945984\n",
      "\n",
      "episode 9, policy loss -0.6419773101806641\n",
      "\n",
      "episode 10, policy loss -0.6419773697853088\n",
      "\n",
      "episode 11, policy loss -0.6419776082038879\n",
      "\n",
      "episode 12, policy loss -0.6419776082038879\n",
      "\n",
      "episode 13, policy loss -0.6419777870178223\n",
      "\n",
      "episode 14, policy loss -0.641977846622467\n",
      "\n",
      "episode 15, policy loss -0.6419779658317566\n",
      "\n",
      "episode 16, policy loss -0.6419779658317566\n",
      "\n",
      "Policy train loss in epoch 1:-0.6419771835207939\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.6419780254364014\n",
      "\n",
      "episode 2, policy loss -0.6419780850410461\n",
      "\n",
      "episode 3, policy loss -0.6419780850410461\n",
      "\n",
      "episode 4, policy loss -0.6419780254364014\n",
      "\n",
      "episode 5, policy loss -0.6419779658317566\n",
      "\n",
      "episode 6, policy loss -0.6419780254364014\n",
      "\n",
      "episode 7, policy loss -0.6419782042503357\n",
      "\n",
      "episode 8, policy loss -0.6419783234596252\n",
      "\n",
      "episode 9, policy loss -0.6419780850410461\n",
      "\n",
      "episode 10, policy loss -0.6419780850410461\n",
      "\n",
      "episode 11, policy loss -0.6419782638549805\n",
      "\n",
      "episode 12, policy loss -0.6419782638549805\n",
      "\n",
      "episode 13, policy loss -0.6419781446456909\n",
      "\n",
      "episode 14, policy loss -0.6419782042503357\n",
      "\n",
      "episode 15, policy loss -0.6419784426689148\n",
      "\n",
      "episode 16, policy loss -0.6419783234596252\n",
      "\n",
      "Policy train loss in epoch 2:-0.6419781595468521\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.6419785022735596\n",
      "\n",
      "episode 2, policy loss -0.64197838306427\n",
      "\n",
      "episode 3, policy loss -0.64197838306427\n",
      "\n",
      "episode 4, policy loss -0.64197838306427\n",
      "\n",
      "episode 5, policy loss -0.64197838306427\n",
      "\n",
      "episode 6, policy loss -0.6419785022735596\n",
      "\n",
      "episode 7, policy loss -0.6419784426689148\n",
      "\n",
      "episode 8, policy loss -0.6419784426689148\n",
      "\n",
      "episode 9, policy loss -0.64197838306427\n",
      "\n",
      "episode 10, policy loss -0.6419784426689148\n",
      "\n",
      "episode 11, policy loss -0.6419784426689148\n",
      "\n",
      "episode 12, policy loss -0.6419784426689148\n",
      "\n",
      "episode 13, policy loss -0.64197838306427\n",
      "\n",
      "episode 14, policy loss -0.6419785618782043\n",
      "\n",
      "episode 15, policy loss -0.6419786214828491\n",
      "\n",
      "episode 16, policy loss -0.6419786214828491\n",
      "\n",
      "Policy train loss in epoch 3:-0.641978457570076\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7937731742858887\n",
      "\n",
      "episode 2, val func loss 0.7961023449897766\n",
      "\n",
      "episode 3, val func loss 0.8089168667793274\n",
      "\n",
      "episode 4, val func loss 0.91214919090271\n",
      "\n",
      "episode 5, val func loss 0.8563149571418762\n",
      "\n",
      "episode 6, val func loss 0.7533219456672668\n",
      "\n",
      "episode 7, val func loss 0.7462214827537537\n",
      "\n",
      "episode 8, val func loss 0.859283447265625\n",
      "\n",
      "episode 9, val func loss 0.9665696620941162\n",
      "\n",
      "episode 10, val func loss 0.9193763732910156\n",
      "\n",
      "episode 11, val func loss 0.7959638237953186\n",
      "\n",
      "episode 12, val func loss 0.865744411945343\n",
      "\n",
      "episode 13, val func loss 0.8964598178863525\n",
      "\n",
      "episode 14, val func loss 0.8410224914550781\n",
      "\n",
      "episode 15, val func loss 0.8718631863594055\n",
      "\n",
      "episode 16, val func loss 0.7922882437705994\n",
      "\n",
      "Val func train loss in epoch 0:0.8422107137739658\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7546638250350952\n",
      "\n",
      "episode 2, val func loss 0.8446878790855408\n",
      "\n",
      "episode 3, val func loss 0.8115647435188293\n",
      "\n",
      "episode 4, val func loss 0.8428493142127991\n",
      "\n",
      "episode 5, val func loss 0.835466206073761\n",
      "\n",
      "episode 6, val func loss 0.8100191950798035\n",
      "\n",
      "episode 7, val func loss 0.7706508040428162\n",
      "\n",
      "episode 8, val func loss 0.8866135478019714\n",
      "\n",
      "episode 9, val func loss 0.901634156703949\n",
      "\n",
      "episode 10, val func loss 0.6300202012062073\n",
      "\n",
      "episode 11, val func loss 0.9206485152244568\n",
      "\n",
      "episode 12, val func loss 0.7515937089920044\n",
      "\n",
      "episode 13, val func loss 0.9144302010536194\n",
      "\n",
      "episode 14, val func loss 0.854961097240448\n",
      "\n",
      "episode 15, val func loss 0.7262293100357056\n",
      "\n",
      "episode 16, val func loss 0.8223631381988525\n",
      "\n",
      "Val func train loss in epoch 1:0.8173997402191162\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.0622001886367798\n",
      "\n",
      "episode 2, val func loss 0.7804208993911743\n",
      "\n",
      "episode 3, val func loss 0.8651567697525024\n",
      "\n",
      "episode 4, val func loss 0.8295111060142517\n",
      "\n",
      "episode 5, val func loss 0.8448382019996643\n",
      "\n",
      "episode 6, val func loss 0.8116701245307922\n",
      "\n",
      "episode 7, val func loss 0.9591360688209534\n",
      "\n",
      "episode 8, val func loss 0.815180242061615\n",
      "\n",
      "episode 9, val func loss 0.8899090886116028\n",
      "\n",
      "episode 10, val func loss 0.8493282794952393\n",
      "\n",
      "episode 11, val func loss 0.8516787886619568\n",
      "\n",
      "episode 12, val func loss 0.7902047634124756\n",
      "\n",
      "episode 13, val func loss 0.8076720237731934\n",
      "\n",
      "episode 14, val func loss 0.8439923524856567\n",
      "\n",
      "episode 15, val func loss 0.7587686777114868\n",
      "\n",
      "episode 16, val func loss 0.6959848999977112\n",
      "\n",
      "Val func train loss in epoch 2:0.840978279709816\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8320024013519287\n",
      "\n",
      "episode 2, val func loss 0.8757351636886597\n",
      "\n",
      "episode 3, val func loss 0.7944947481155396\n",
      "\n",
      "episode 4, val func loss 1.0491923093795776\n",
      "\n",
      "episode 5, val func loss 0.9087039232254028\n",
      "\n",
      "episode 6, val func loss 0.953118622303009\n",
      "\n",
      "episode 7, val func loss 0.9243119359016418\n",
      "\n",
      "episode 8, val func loss 0.8363195061683655\n",
      "\n",
      "episode 9, val func loss 0.905379593372345\n",
      "\n",
      "episode 10, val func loss 0.8152639865875244\n",
      "\n",
      "episode 11, val func loss 0.822556734085083\n",
      "\n",
      "episode 12, val func loss 0.8259356021881104\n",
      "\n",
      "episode 13, val func loss 0.8732142448425293\n",
      "\n",
      "episode 14, val func loss 0.7994338274002075\n",
      "\n",
      "episode 15, val func loss 0.7537954449653625\n",
      "\n",
      "episode 16, val func loss 0.7590437531471252\n",
      "\n",
      "Val func train loss in epoch 3:0.8580313622951508\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.859228253364563\n",
      "\n",
      "episode 2, val func loss 0.7838577032089233\n",
      "\n",
      "episode 3, val func loss 0.8294501900672913\n",
      "\n",
      "episode 4, val func loss 0.778302013874054\n",
      "\n",
      "episode 5, val func loss 0.7676204442977905\n",
      "\n",
      "episode 6, val func loss 0.7064685821533203\n",
      "\n",
      "episode 7, val func loss 0.7665674090385437\n",
      "\n",
      "episode 8, val func loss 0.8362523317337036\n",
      "\n",
      "episode 9, val func loss 0.8823843598365784\n",
      "\n",
      "episode 10, val func loss 0.8072866797447205\n",
      "\n",
      "episode 11, val func loss 1.0401266813278198\n",
      "\n",
      "episode 12, val func loss 0.6603124141693115\n",
      "\n",
      "episode 13, val func loss 1.0266581773757935\n",
      "\n",
      "episode 14, val func loss 0.7454552054405212\n",
      "\n",
      "episode 15, val func loss 1.1219048500061035\n",
      "\n",
      "episode 16, val func loss 0.7687994241714478\n",
      "\n",
      "Val func train loss in epoch 4:0.8362921699881554\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7866584062576294\n",
      "\n",
      "episode 2, val func loss 1.0415047407150269\n",
      "\n",
      "episode 3, val func loss 0.6210898160934448\n",
      "\n",
      "episode 4, val func loss 0.7847105860710144\n",
      "\n",
      "episode 5, val func loss 0.8855324983596802\n",
      "\n",
      "episode 6, val func loss 0.7479680776596069\n",
      "\n",
      "episode 7, val func loss 0.9824779629707336\n",
      "\n",
      "episode 8, val func loss 0.7135187983512878\n",
      "\n",
      "episode 9, val func loss 0.8860349655151367\n",
      "\n",
      "episode 10, val func loss 0.9355273246765137\n",
      "\n",
      "episode 11, val func loss 0.7359909415245056\n",
      "\n",
      "episode 12, val func loss 0.8858262896537781\n",
      "\n",
      "episode 13, val func loss 0.7038410305976868\n",
      "\n",
      "episode 14, val func loss 0.9065112471580505\n",
      "\n",
      "episode 15, val func loss 0.7367187142372131\n",
      "\n",
      "episode 16, val func loss 0.8811551332473755\n",
      "\n",
      "Val func train loss in epoch 5:0.8271916583180428\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.829810619354248\n",
      "\n",
      "episode 2, val func loss 0.7406253218650818\n",
      "\n",
      "episode 3, val func loss 0.8786529302597046\n",
      "\n",
      "episode 4, val func loss 0.8202738761901855\n",
      "\n",
      "episode 5, val func loss 0.8017649054527283\n",
      "\n",
      "episode 6, val func loss 0.8066219091415405\n",
      "\n",
      "episode 7, val func loss 0.6962295174598694\n",
      "\n",
      "episode 8, val func loss 0.8242834210395813\n",
      "\n",
      "episode 9, val func loss 0.7755463719367981\n",
      "\n",
      "episode 10, val func loss 0.761059582233429\n",
      "\n",
      "episode 11, val func loss 0.7973666191101074\n",
      "\n",
      "episode 12, val func loss 0.7121412754058838\n",
      "\n",
      "episode 13, val func loss 0.9451873898506165\n",
      "\n",
      "episode 14, val func loss 0.7924414873123169\n",
      "\n",
      "episode 15, val func loss 0.8690969944000244\n",
      "\n",
      "episode 16, val func loss 0.7612494826316833\n",
      "\n",
      "Val func train loss in epoch 6:0.8007719814777374\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7676703333854675\n",
      "\n",
      "episode 2, val func loss 0.8779629468917847\n",
      "\n",
      "episode 3, val func loss 0.7370998859405518\n",
      "\n",
      "episode 4, val func loss 0.7042853236198425\n",
      "\n",
      "episode 5, val func loss 0.6952155828475952\n",
      "\n",
      "episode 6, val func loss 0.8455691933631897\n",
      "\n",
      "episode 7, val func loss 0.7853490114212036\n",
      "\n",
      "episode 8, val func loss 0.906282365322113\n",
      "\n",
      "episode 9, val func loss 0.8217493295669556\n",
      "\n",
      "episode 10, val func loss 0.8641447424888611\n",
      "\n",
      "episode 11, val func loss 0.9462341666221619\n",
      "\n",
      "episode 12, val func loss 0.890901505947113\n",
      "\n",
      "episode 13, val func loss 0.8088187575340271\n",
      "\n",
      "episode 14, val func loss 0.8866968154907227\n",
      "\n",
      "episode 15, val func loss 0.8061521649360657\n",
      "\n",
      "episode 16, val func loss 0.7428997755050659\n",
      "\n",
      "Val func train loss in epoch 7:0.8179394938051701\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8293724060058594\n",
      "\n",
      "episode 2, val func loss 0.8151483535766602\n",
      "\n",
      "episode 3, val func loss 0.8758503794670105\n",
      "\n",
      "episode 4, val func loss 0.8421189785003662\n",
      "\n",
      "episode 5, val func loss 0.7996412515640259\n",
      "\n",
      "episode 6, val func loss 0.8885720372200012\n",
      "\n",
      "episode 7, val func loss 0.8579573035240173\n",
      "\n",
      "episode 8, val func loss 0.7200493216514587\n",
      "\n",
      "episode 9, val func loss 0.8620405793190002\n",
      "\n",
      "episode 10, val func loss 0.8337910175323486\n",
      "\n",
      "episode 11, val func loss 0.7550612688064575\n",
      "\n",
      "episode 12, val func loss 0.7234964370727539\n",
      "\n",
      "episode 13, val func loss 0.8289182782173157\n",
      "\n",
      "episode 14, val func loss 0.702214777469635\n",
      "\n",
      "episode 15, val func loss 0.7960531115531921\n",
      "\n",
      "episode 16, val func loss 0.7423925399780273\n",
      "\n",
      "Val func train loss in epoch 8:0.8045423775911331\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8450284600257874\n",
      "\n",
      "episode 2, val func loss 0.7733520865440369\n",
      "\n",
      "episode 3, val func loss 0.7377240061759949\n",
      "\n",
      "episode 4, val func loss 0.9930012822151184\n",
      "\n",
      "episode 5, val func loss 0.8397576808929443\n",
      "\n",
      "episode 6, val func loss 0.7432457804679871\n",
      "\n",
      "episode 7, val func loss 0.6572521924972534\n",
      "\n",
      "episode 8, val func loss 0.7675295472145081\n",
      "\n",
      "episode 9, val func loss 0.8058454990386963\n",
      "\n",
      "episode 10, val func loss 0.7469746470451355\n",
      "\n",
      "episode 11, val func loss 0.8307140469551086\n",
      "\n",
      "episode 12, val func loss 0.9705318212509155\n",
      "\n",
      "episode 13, val func loss 0.8035101294517517\n",
      "\n",
      "episode 14, val func loss 0.6781270503997803\n",
      "\n",
      "episode 15, val func loss 0.8064169883728027\n",
      "\n",
      "episode 16, val func loss 0.839196503162384\n",
      "\n",
      "Val func train loss in epoch 9:0.8023879826068878\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7466328740119934\n",
      "\n",
      "episode 2, val func loss 0.7526928782463074\n",
      "\n",
      "episode 3, val func loss 0.6932245492935181\n",
      "\n",
      "episode 4, val func loss 0.8427122235298157\n",
      "\n",
      "episode 5, val func loss 0.7447763681411743\n",
      "\n",
      "episode 6, val func loss 0.7736184597015381\n",
      "\n",
      "episode 7, val func loss 0.7003394365310669\n",
      "\n",
      "episode 8, val func loss 0.7919597029685974\n",
      "\n",
      "episode 9, val func loss 0.686244547367096\n",
      "\n",
      "episode 10, val func loss 0.775056779384613\n",
      "\n",
      "episode 11, val func loss 0.8742055892944336\n",
      "\n",
      "episode 12, val func loss 0.7975049614906311\n",
      "\n",
      "episode 13, val func loss 0.8152208924293518\n",
      "\n",
      "episode 14, val func loss 0.7515368461608887\n",
      "\n",
      "episode 15, val func loss 0.7354490756988525\n",
      "\n",
      "episode 16, val func loss 0.8565124869346619\n",
      "\n",
      "Val func train loss in epoch 10:0.7711054794490337\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7498984336853027\n",
      "\n",
      "episode 2, val func loss 0.7732101082801819\n",
      "\n",
      "episode 3, val func loss 0.6314706206321716\n",
      "\n",
      "episode 4, val func loss 0.7934972047805786\n",
      "\n",
      "episode 5, val func loss 0.8043885827064514\n",
      "\n",
      "episode 6, val func loss 0.8432554602622986\n",
      "\n",
      "episode 7, val func loss 0.7196022868156433\n",
      "\n",
      "episode 8, val func loss 0.711592972278595\n",
      "\n",
      "episode 9, val func loss 0.7871094942092896\n",
      "\n",
      "episode 10, val func loss 0.7652677893638611\n",
      "\n",
      "episode 11, val func loss 0.6836898922920227\n",
      "\n",
      "episode 12, val func loss 0.7960637211799622\n",
      "\n",
      "episode 13, val func loss 0.7493902444839478\n",
      "\n",
      "episode 14, val func loss 0.7722479701042175\n",
      "\n",
      "episode 15, val func loss 0.7053110003471375\n",
      "\n",
      "episode 16, val func loss 0.7378743886947632\n",
      "\n",
      "Val func train loss in epoch 11:0.7514918856322765\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.704891562461853\n",
      "\n",
      "episode 2, val func loss 0.7642273306846619\n",
      "\n",
      "episode 3, val func loss 0.7625541090965271\n",
      "\n",
      "episode 4, val func loss 0.601116955280304\n",
      "\n",
      "episode 5, val func loss 0.7173376083374023\n",
      "\n",
      "episode 6, val func loss 0.8799421787261963\n",
      "\n",
      "episode 7, val func loss 0.7433164715766907\n",
      "\n",
      "episode 8, val func loss 0.8291882276535034\n",
      "\n",
      "episode 9, val func loss 0.7558180689811707\n",
      "\n",
      "episode 10, val func loss 0.7806556820869446\n",
      "\n",
      "episode 11, val func loss 0.8782693147659302\n",
      "\n",
      "episode 12, val func loss 0.7680729031562805\n",
      "\n",
      "episode 13, val func loss 0.8067828416824341\n",
      "\n",
      "episode 14, val func loss 0.8135172128677368\n",
      "\n",
      "episode 15, val func loss 0.9374978542327881\n",
      "\n",
      "episode 16, val func loss 0.8442512154579163\n",
      "\n",
      "Val func train loss in epoch 12:0.7867149710655212\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8239332437515259\n",
      "\n",
      "episode 2, val func loss 0.8706679940223694\n",
      "\n",
      "episode 3, val func loss 0.9348249435424805\n",
      "\n",
      "episode 4, val func loss 0.6466324329376221\n",
      "\n",
      "episode 5, val func loss 0.6927502155303955\n",
      "\n",
      "episode 6, val func loss 0.7746065258979797\n",
      "\n",
      "episode 7, val func loss 0.7274633049964905\n",
      "\n",
      "episode 8, val func loss 0.736993134021759\n",
      "\n",
      "episode 9, val func loss 0.779026210308075\n",
      "\n",
      "episode 10, val func loss 0.7439514994621277\n",
      "\n",
      "episode 11, val func loss 0.7498971819877625\n",
      "\n",
      "episode 12, val func loss 0.9109684824943542\n",
      "\n",
      "episode 13, val func loss 0.7405977845191956\n",
      "\n",
      "episode 14, val func loss 0.8490479588508606\n",
      "\n",
      "episode 15, val func loss 0.7926360368728638\n",
      "\n",
      "episode 16, val func loss 0.7606725692749023\n",
      "\n",
      "Val func train loss in epoch 13:0.7834168449044228\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.675894558429718\n",
      "\n",
      "episode 2, val func loss 0.8694207072257996\n",
      "\n",
      "episode 3, val func loss 0.7411646842956543\n",
      "\n",
      "episode 4, val func loss 0.690870463848114\n",
      "\n",
      "episode 5, val func loss 0.7989823818206787\n",
      "\n",
      "episode 6, val func loss 0.7026851773262024\n",
      "\n",
      "episode 7, val func loss 0.709712028503418\n",
      "\n",
      "episode 8, val func loss 0.7982087731361389\n",
      "\n",
      "episode 9, val func loss 0.8789477944374084\n",
      "\n",
      "episode 10, val func loss 0.7992932200431824\n",
      "\n",
      "episode 11, val func loss 0.8535459637641907\n",
      "\n",
      "episode 12, val func loss 0.7827772498130798\n",
      "\n",
      "episode 13, val func loss 0.6391707062721252\n",
      "\n",
      "episode 14, val func loss 0.8979337811470032\n",
      "\n",
      "episode 15, val func loss 0.7250823378562927\n",
      "\n",
      "episode 16, val func loss 0.7940632700920105\n",
      "\n",
      "Val func train loss in epoch 14:0.7723595686256886\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6124328374862671\n",
      "\n",
      "episode 2, val func loss 0.6831166744232178\n",
      "\n",
      "episode 3, val func loss 0.7164129018783569\n",
      "\n",
      "episode 4, val func loss 0.7777726054191589\n",
      "\n",
      "episode 5, val func loss 0.8011621832847595\n",
      "\n",
      "episode 6, val func loss 0.825487494468689\n",
      "\n",
      "episode 7, val func loss 0.8562180995941162\n",
      "\n",
      "episode 8, val func loss 0.8133905529975891\n",
      "\n",
      "episode 9, val func loss 0.7175979614257812\n",
      "\n",
      "episode 10, val func loss 0.8194292187690735\n",
      "\n",
      "episode 11, val func loss 0.7463520169258118\n",
      "\n",
      "episode 12, val func loss 0.8862263560295105\n",
      "\n",
      "episode 13, val func loss 0.869690477848053\n",
      "\n",
      "episode 14, val func loss 0.7220465540885925\n",
      "\n",
      "episode 15, val func loss 0.7727420926094055\n",
      "\n",
      "episode 16, val func loss 0.8210556507110596\n",
      "\n",
      "Val func train loss in epoch 15:0.7775708548724651\n",
      "***********************TIME WAS 4.867517701784769 min*****************************\n",
      "\n",
      "**********************ROUND 84 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.3924598693847656\n",
      "\n",
      "episode 2, policy loss 1.3924602270126343\n",
      "\n",
      "episode 3, policy loss 1.3924601078033447\n",
      "\n",
      "episode 4, policy loss 1.3924602270126343\n",
      "\n",
      "episode 5, policy loss 1.3924601078033447\n",
      "\n",
      "episode 6, policy loss 1.3924601078033447\n",
      "\n",
      "episode 7, policy loss 1.3924602270126343\n",
      "\n",
      "episode 8, policy loss 1.3924603462219238\n",
      "\n",
      "episode 9, policy loss 1.3924602270126343\n",
      "\n",
      "episode 10, policy loss 1.3924599885940552\n",
      "\n",
      "episode 11, policy loss 1.3924601078033447\n",
      "\n",
      "episode 12, policy loss 1.3924598693847656\n",
      "\n",
      "episode 13, policy loss 1.3924601078033447\n",
      "\n",
      "episode 14, policy loss 1.3924599885940552\n",
      "\n",
      "episode 15, policy loss 1.3924599885940552\n",
      "\n",
      "episode 16, policy loss 1.392459750175476\n",
      "\n",
      "Policy train loss in epoch 0:1.3924600780010223\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.3924598693847656\n",
      "\n",
      "episode 2, policy loss 1.3924598693847656\n",
      "\n",
      "episode 3, policy loss 1.3924596309661865\n",
      "\n",
      "episode 4, policy loss 1.392459750175476\n",
      "\n",
      "episode 5, policy loss 1.392459750175476\n",
      "\n",
      "episode 6, policy loss 1.392459511756897\n",
      "\n",
      "episode 7, policy loss 1.392459511756897\n",
      "\n",
      "episode 8, policy loss 1.392459511756897\n",
      "\n",
      "episode 9, policy loss 1.3924596309661865\n",
      "\n",
      "episode 10, policy loss 1.3924592733383179\n",
      "\n",
      "episode 11, policy loss 1.392459511756897\n",
      "\n",
      "episode 12, policy loss 1.3924592733383179\n",
      "\n",
      "episode 13, policy loss 1.3924593925476074\n",
      "\n",
      "episode 14, policy loss 1.3924592733383179\n",
      "\n",
      "episode 15, policy loss 1.3924591541290283\n",
      "\n",
      "episode 16, policy loss 1.3924592733383179\n",
      "\n",
      "Policy train loss in epoch 1:1.392459511756897\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.3924592733383179\n",
      "\n",
      "episode 2, policy loss 1.3924592733383179\n",
      "\n",
      "episode 3, policy loss 1.3924590349197388\n",
      "\n",
      "episode 4, policy loss 1.3924590349197388\n",
      "\n",
      "episode 5, policy loss 1.3924589157104492\n",
      "\n",
      "episode 6, policy loss 1.3924586772918701\n",
      "\n",
      "episode 7, policy loss 1.3924589157104492\n",
      "\n",
      "episode 8, policy loss 1.3924585580825806\n",
      "\n",
      "episode 9, policy loss 1.3924583196640015\n",
      "\n",
      "episode 10, policy loss 1.392458200454712\n",
      "\n",
      "episode 11, policy loss 1.3924578428268433\n",
      "\n",
      "episode 12, policy loss 1.392457365989685\n",
      "\n",
      "episode 13, policy loss 1.392457365989685\n",
      "\n",
      "episode 14, policy loss 1.3924570083618164\n",
      "\n",
      "episode 15, policy loss 1.3924566507339478\n",
      "\n",
      "episode 16, policy loss 1.392455816268921\n",
      "\n",
      "Policy train loss in epoch 2:1.3924581408500671\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.3924542665481567\n",
      "\n",
      "episode 2, policy loss 1.3924530744552612\n",
      "\n",
      "episode 3, policy loss 1.3924510478973389\n",
      "\n",
      "episode 4, policy loss 1.392449140548706\n",
      "\n",
      "episode 5, policy loss 1.3924448490142822\n",
      "\n",
      "episode 6, policy loss 1.392438530921936\n",
      "\n",
      "episode 7, policy loss 1.3924297094345093\n",
      "\n",
      "episode 8, policy loss 1.392406702041626\n",
      "\n",
      "episode 9, policy loss 1.3923817873001099\n",
      "\n",
      "episode 10, policy loss 1.3923085927963257\n",
      "\n",
      "episode 11, policy loss 1.3921903371810913\n",
      "\n",
      "episode 12, policy loss 1.3918572664260864\n",
      "\n",
      "episode 13, policy loss 1.3908485174179077\n",
      "\n",
      "episode 14, policy loss 1.3879023790359497\n",
      "\n",
      "episode 15, policy loss 1.3716070652008057\n",
      "\n",
      "episode 16, policy loss 1.2810124158859253\n",
      "\n",
      "Policy train loss in epoch 3:1.3837272301316261\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.8160820007324219\n",
      "\n",
      "episode 2, val func loss 0.7204369306564331\n",
      "\n",
      "episode 3, val func loss 0.8960939645767212\n",
      "\n",
      "episode 4, val func loss 0.7911630272865295\n",
      "\n",
      "episode 5, val func loss 0.6649715304374695\n",
      "\n",
      "episode 6, val func loss 0.7273038625717163\n",
      "\n",
      "episode 7, val func loss 0.8139892220497131\n",
      "\n",
      "episode 8, val func loss 0.7939960956573486\n",
      "\n",
      "episode 9, val func loss 0.74118572473526\n",
      "\n",
      "episode 10, val func loss 0.7554045915603638\n",
      "\n",
      "episode 11, val func loss 0.7589342594146729\n",
      "\n",
      "episode 12, val func loss 0.8172664046287537\n",
      "\n",
      "episode 13, val func loss 0.8406713604927063\n",
      "\n",
      "episode 14, val func loss 0.6490651965141296\n",
      "\n",
      "episode 15, val func loss 1.06485116481781\n",
      "\n",
      "episode 16, val func loss 0.9459265470504761\n",
      "\n",
      "Val func train loss in epoch 0:0.7998338676989079\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7661497592926025\n",
      "\n",
      "episode 2, val func loss 0.9734839200973511\n",
      "\n",
      "episode 3, val func loss 0.7554348111152649\n",
      "\n",
      "episode 4, val func loss 0.7247533798217773\n",
      "\n",
      "episode 5, val func loss 0.8075268864631653\n",
      "\n",
      "episode 6, val func loss 0.9044862389564514\n",
      "\n",
      "episode 7, val func loss 0.7526976466178894\n",
      "\n",
      "episode 8, val func loss 0.7384170293807983\n",
      "\n",
      "episode 9, val func loss 0.7368356585502625\n",
      "\n",
      "episode 10, val func loss 0.7412416338920593\n",
      "\n",
      "episode 11, val func loss 0.738481879234314\n",
      "\n",
      "episode 12, val func loss 0.734717845916748\n",
      "\n",
      "episode 13, val func loss 0.7809789180755615\n",
      "\n",
      "episode 14, val func loss 0.8245687484741211\n",
      "\n",
      "episode 15, val func loss 0.8495104312896729\n",
      "\n",
      "episode 16, val func loss 0.8940814733505249\n",
      "\n",
      "Val func train loss in epoch 1:0.7952103912830353\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7550413608551025\n",
      "\n",
      "episode 2, val func loss 0.7723823189735413\n",
      "\n",
      "episode 3, val func loss 0.7001851201057434\n",
      "\n",
      "episode 4, val func loss 0.8799289464950562\n",
      "\n",
      "episode 5, val func loss 0.7393223643302917\n",
      "\n",
      "episode 6, val func loss 0.7433500289916992\n",
      "\n",
      "episode 7, val func loss 0.7996645569801331\n",
      "\n",
      "episode 8, val func loss 0.6547343134880066\n",
      "\n",
      "episode 9, val func loss 0.6986240148544312\n",
      "\n",
      "episode 10, val func loss 0.8914629817008972\n",
      "\n",
      "episode 11, val func loss 0.7915236353874207\n",
      "\n",
      "episode 12, val func loss 0.8250440955162048\n",
      "\n",
      "episode 13, val func loss 0.627293050289154\n",
      "\n",
      "episode 14, val func loss 0.8540098071098328\n",
      "\n",
      "episode 15, val func loss 0.7226858139038086\n",
      "\n",
      "episode 16, val func loss 0.7487146258354187\n",
      "\n",
      "Val func train loss in epoch 2:0.7627479396760464\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8022482395172119\n",
      "\n",
      "episode 2, val func loss 0.8915185928344727\n",
      "\n",
      "episode 3, val func loss 0.679078996181488\n",
      "\n",
      "episode 4, val func loss 0.9175206422805786\n",
      "\n",
      "episode 5, val func loss 0.7483811974525452\n",
      "\n",
      "episode 6, val func loss 0.9802179932594299\n",
      "\n",
      "episode 7, val func loss 0.6810395121574402\n",
      "\n",
      "episode 8, val func loss 0.8401972055435181\n",
      "\n",
      "episode 9, val func loss 0.8689627051353455\n",
      "\n",
      "episode 10, val func loss 0.823910117149353\n",
      "\n",
      "episode 11, val func loss 0.855774462223053\n",
      "\n",
      "episode 12, val func loss 0.7988094687461853\n",
      "\n",
      "episode 13, val func loss 0.7547861933708191\n",
      "\n",
      "episode 14, val func loss 0.7657162547111511\n",
      "\n",
      "episode 15, val func loss 0.7438364028930664\n",
      "\n",
      "episode 16, val func loss 0.7375724911689758\n",
      "\n",
      "Val func train loss in epoch 3:0.8055981546640396\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7938175201416016\n",
      "\n",
      "episode 2, val func loss 0.7959373593330383\n",
      "\n",
      "episode 3, val func loss 0.8395167589187622\n",
      "\n",
      "episode 4, val func loss 0.6852091550827026\n",
      "\n",
      "episode 5, val func loss 0.8008119463920593\n",
      "\n",
      "episode 6, val func loss 0.8160092234611511\n",
      "\n",
      "episode 7, val func loss 0.756009578704834\n",
      "\n",
      "episode 8, val func loss 0.8599631190299988\n",
      "\n",
      "episode 9, val func loss 0.7319499254226685\n",
      "\n",
      "episode 10, val func loss 0.7583316564559937\n",
      "\n",
      "episode 11, val func loss 0.8262123465538025\n",
      "\n",
      "episode 12, val func loss 0.8356950879096985\n",
      "\n",
      "episode 13, val func loss 0.886948823928833\n",
      "\n",
      "episode 14, val func loss 0.7475592494010925\n",
      "\n",
      "episode 15, val func loss 0.7755178809165955\n",
      "\n",
      "episode 16, val func loss 0.7171559929847717\n",
      "\n",
      "Val func train loss in epoch 4:0.7891653515398502\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7340744137763977\n",
      "\n",
      "episode 2, val func loss 0.6685335636138916\n",
      "\n",
      "episode 3, val func loss 0.7752737998962402\n",
      "\n",
      "episode 4, val func loss 0.8891578316688538\n",
      "\n",
      "episode 5, val func loss 0.8039814829826355\n",
      "\n",
      "episode 6, val func loss 0.7962771654129028\n",
      "\n",
      "episode 7, val func loss 0.8609402775764465\n",
      "\n",
      "episode 8, val func loss 0.8035714626312256\n",
      "\n",
      "episode 9, val func loss 0.8076868057250977\n",
      "\n",
      "episode 10, val func loss 0.7549724578857422\n",
      "\n",
      "episode 11, val func loss 0.7343930006027222\n",
      "\n",
      "episode 12, val func loss 0.7175503969192505\n",
      "\n",
      "episode 13, val func loss 0.9075071215629578\n",
      "\n",
      "episode 14, val func loss 0.6907941102981567\n",
      "\n",
      "episode 15, val func loss 0.7814559936523438\n",
      "\n",
      "episode 16, val func loss 0.7303889989852905\n",
      "\n",
      "Val func train loss in epoch 5:0.7785349301993847\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.685736894607544\n",
      "\n",
      "episode 2, val func loss 0.7897533178329468\n",
      "\n",
      "episode 3, val func loss 0.7062543034553528\n",
      "\n",
      "episode 4, val func loss 0.7426528930664062\n",
      "\n",
      "episode 5, val func loss 0.8567453622817993\n",
      "\n",
      "episode 6, val func loss 0.7310002446174622\n",
      "\n",
      "episode 7, val func loss 0.6993075013160706\n",
      "\n",
      "episode 8, val func loss 0.9763059616088867\n",
      "\n",
      "episode 9, val func loss 0.7747879028320312\n",
      "\n",
      "episode 10, val func loss 0.801432192325592\n",
      "\n",
      "episode 11, val func loss 0.7649548649787903\n",
      "\n",
      "episode 12, val func loss 0.9024768471717834\n",
      "\n",
      "episode 13, val func loss 0.7348437309265137\n",
      "\n",
      "episode 14, val func loss 0.7672114372253418\n",
      "\n",
      "episode 15, val func loss 0.8873804211616516\n",
      "\n",
      "episode 16, val func loss 0.8763403296470642\n",
      "\n",
      "Val func train loss in epoch 6:0.7935740128159523\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.8641611933708191\n",
      "\n",
      "episode 2, val func loss 0.7349255084991455\n",
      "\n",
      "episode 3, val func loss 0.832784116268158\n",
      "\n",
      "episode 4, val func loss 0.8003727793693542\n",
      "\n",
      "episode 5, val func loss 0.8048942685127258\n",
      "\n",
      "episode 6, val func loss 0.834539532661438\n",
      "\n",
      "episode 7, val func loss 0.7791714072227478\n",
      "\n",
      "episode 8, val func loss 0.7176775932312012\n",
      "\n",
      "episode 9, val func loss 0.7320806384086609\n",
      "\n",
      "episode 10, val func loss 0.8357927203178406\n",
      "\n",
      "episode 11, val func loss 0.7724903225898743\n",
      "\n",
      "episode 12, val func loss 0.8308122158050537\n",
      "\n",
      "episode 13, val func loss 0.7996768355369568\n",
      "\n",
      "episode 14, val func loss 0.782423198223114\n",
      "\n",
      "episode 15, val func loss 0.7023394107818604\n",
      "\n",
      "episode 16, val func loss 0.8295541405677795\n",
      "\n",
      "Val func train loss in epoch 7:0.7908559925854206\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8486933708190918\n",
      "\n",
      "episode 2, val func loss 0.7317966222763062\n",
      "\n",
      "episode 3, val func loss 0.8096612095832825\n",
      "\n",
      "episode 4, val func loss 0.8312171697616577\n",
      "\n",
      "episode 5, val func loss 0.799187958240509\n",
      "\n",
      "episode 6, val func loss 0.779596745967865\n",
      "\n",
      "episode 7, val func loss 0.7242870330810547\n",
      "\n",
      "episode 8, val func loss 0.7661144733428955\n",
      "\n",
      "episode 9, val func loss 0.7866345643997192\n",
      "\n",
      "episode 10, val func loss 0.6545369029045105\n",
      "\n",
      "episode 11, val func loss 0.7410072684288025\n",
      "\n",
      "episode 12, val func loss 0.755213737487793\n",
      "\n",
      "episode 13, val func loss 0.7606586813926697\n",
      "\n",
      "episode 14, val func loss 0.8039841055870056\n",
      "\n",
      "episode 15, val func loss 0.6850332021713257\n",
      "\n",
      "episode 16, val func loss 0.7284380197525024\n",
      "\n",
      "Val func train loss in epoch 8:0.7628788165748119\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8356246948242188\n",
      "\n",
      "episode 2, val func loss 0.77789306640625\n",
      "\n",
      "episode 3, val func loss 0.8096727728843689\n",
      "\n",
      "episode 4, val func loss 0.8171340227127075\n",
      "\n",
      "episode 5, val func loss 0.7348107099533081\n",
      "\n",
      "episode 6, val func loss 0.7996668815612793\n",
      "\n",
      "episode 7, val func loss 0.853242814540863\n",
      "\n",
      "episode 8, val func loss 0.7925779819488525\n",
      "\n",
      "episode 9, val func loss 0.8015851974487305\n",
      "\n",
      "episode 10, val func loss 0.8292334079742432\n",
      "\n",
      "episode 11, val func loss 0.7419962882995605\n",
      "\n",
      "episode 12, val func loss 0.8706478476524353\n",
      "\n",
      "episode 13, val func loss 0.8846297264099121\n",
      "\n",
      "episode 14, val func loss 0.8311120867729187\n",
      "\n",
      "episode 15, val func loss 0.9368883371353149\n",
      "\n",
      "episode 16, val func loss 0.8555623292922974\n",
      "\n",
      "Val func train loss in epoch 9:0.8232673853635788\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.8596218228340149\n",
      "\n",
      "episode 2, val func loss 0.7126668691635132\n",
      "\n",
      "episode 3, val func loss 0.8927518129348755\n",
      "\n",
      "episode 4, val func loss 0.98248291015625\n",
      "\n",
      "episode 5, val func loss 0.80903559923172\n",
      "\n",
      "episode 6, val func loss 0.8647892475128174\n",
      "\n",
      "episode 7, val func loss 0.7212831974029541\n",
      "\n",
      "episode 8, val func loss 1.029797911643982\n",
      "\n",
      "episode 9, val func loss 0.7790597081184387\n",
      "\n",
      "episode 10, val func loss 0.8867892622947693\n",
      "\n",
      "episode 11, val func loss 0.8513800501823425\n",
      "\n",
      "episode 12, val func loss 0.8059496879577637\n",
      "\n",
      "episode 13, val func loss 1.0546379089355469\n",
      "\n",
      "episode 14, val func loss 0.7808952331542969\n",
      "\n",
      "episode 15, val func loss 0.7427287101745605\n",
      "\n",
      "episode 16, val func loss 0.8658059239387512\n",
      "\n",
      "Val func train loss in epoch 10:0.8524797409772873\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9431484341621399\n",
      "\n",
      "episode 2, val func loss 0.9295304417610168\n",
      "\n",
      "episode 3, val func loss 0.7930153012275696\n",
      "\n",
      "episode 4, val func loss 0.8355455994606018\n",
      "\n",
      "episode 5, val func loss 0.7743253707885742\n",
      "\n",
      "episode 6, val func loss 0.7607501745223999\n",
      "\n",
      "episode 7, val func loss 0.8354281783103943\n",
      "\n",
      "episode 8, val func loss 0.8560791015625\n",
      "\n",
      "episode 9, val func loss 0.6786782145500183\n",
      "\n",
      "episode 10, val func loss 0.6991239190101624\n",
      "\n",
      "episode 11, val func loss 0.8053050637245178\n",
      "\n",
      "episode 12, val func loss 0.7446404695510864\n",
      "\n",
      "episode 13, val func loss 0.8205521702766418\n",
      "\n",
      "episode 14, val func loss 0.7814726233482361\n",
      "\n",
      "episode 15, val func loss 0.7437921762466431\n",
      "\n",
      "episode 16, val func loss 0.7848894596099854\n",
      "\n",
      "Val func train loss in epoch 11:0.7991422936320305\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6626443862915039\n",
      "\n",
      "episode 2, val func loss 0.8237700462341309\n",
      "\n",
      "episode 3, val func loss 0.8051403760910034\n",
      "\n",
      "episode 4, val func loss 0.7044627070426941\n",
      "\n",
      "episode 5, val func loss 0.772701621055603\n",
      "\n",
      "episode 6, val func loss 0.7884455323219299\n",
      "\n",
      "episode 7, val func loss 0.6767482161521912\n",
      "\n",
      "episode 8, val func loss 0.6776735782623291\n",
      "\n",
      "episode 9, val func loss 0.6925976276397705\n",
      "\n",
      "episode 10, val func loss 0.8648530840873718\n",
      "\n",
      "episode 11, val func loss 0.7811274528503418\n",
      "\n",
      "episode 12, val func loss 0.717789351940155\n",
      "\n",
      "episode 13, val func loss 0.6948334574699402\n",
      "\n",
      "episode 14, val func loss 0.8770747184753418\n",
      "\n",
      "episode 15, val func loss 0.7673034071922302\n",
      "\n",
      "episode 16, val func loss 0.6478567719459534\n",
      "\n",
      "Val func train loss in epoch 12:0.7471888959407806\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.84671950340271\n",
      "\n",
      "episode 2, val func loss 0.6866764426231384\n",
      "\n",
      "episode 3, val func loss 0.7815388441085815\n",
      "\n",
      "episode 4, val func loss 0.7173433303833008\n",
      "\n",
      "episode 5, val func loss 0.7297006845474243\n",
      "\n",
      "episode 6, val func loss 0.7830824851989746\n",
      "\n",
      "episode 7, val func loss 0.8345826268196106\n",
      "\n",
      "episode 8, val func loss 0.70917809009552\n",
      "\n",
      "episode 9, val func loss 0.8686330914497375\n",
      "\n",
      "episode 10, val func loss 0.8186657428741455\n",
      "\n",
      "episode 11, val func loss 0.6417355537414551\n",
      "\n",
      "episode 12, val func loss 0.7458152770996094\n",
      "\n",
      "episode 13, val func loss 0.7549262642860413\n",
      "\n",
      "episode 14, val func loss 0.8604361414909363\n",
      "\n",
      "episode 15, val func loss 0.7137932181358337\n",
      "\n",
      "episode 16, val func loss 0.7737907767295837\n",
      "\n",
      "Val func train loss in epoch 13:0.7666636295616627\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6898611783981323\n",
      "\n",
      "episode 2, val func loss 0.8515565395355225\n",
      "\n",
      "episode 3, val func loss 0.7635415196418762\n",
      "\n",
      "episode 4, val func loss 0.811644971370697\n",
      "\n",
      "episode 5, val func loss 0.7563431262969971\n",
      "\n",
      "episode 6, val func loss 0.788214385509491\n",
      "\n",
      "episode 7, val func loss 0.7817416191101074\n",
      "\n",
      "episode 8, val func loss 0.7440804243087769\n",
      "\n",
      "episode 9, val func loss 0.7557563781738281\n",
      "\n",
      "episode 10, val func loss 0.6814361214637756\n",
      "\n",
      "episode 11, val func loss 0.8039164543151855\n",
      "\n",
      "episode 12, val func loss 0.7557124495506287\n",
      "\n",
      "episode 13, val func loss 0.8321152925491333\n",
      "\n",
      "episode 14, val func loss 0.8176987767219543\n",
      "\n",
      "episode 15, val func loss 0.8529732823371887\n",
      "\n",
      "episode 16, val func loss 0.841995894908905\n",
      "\n",
      "Val func train loss in epoch 14:0.7830367758870125\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.8875242471694946\n",
      "\n",
      "episode 2, val func loss 0.7883926033973694\n",
      "\n",
      "episode 3, val func loss 0.7933760285377502\n",
      "\n",
      "episode 4, val func loss 0.8632951974868774\n",
      "\n",
      "episode 5, val func loss 0.7513450980186462\n",
      "\n",
      "episode 6, val func loss 0.8452896475791931\n",
      "\n",
      "episode 7, val func loss 1.0703871250152588\n",
      "\n",
      "episode 8, val func loss 0.7331169843673706\n",
      "\n",
      "episode 9, val func loss 0.9361447095870972\n",
      "\n",
      "episode 10, val func loss 0.9855907559394836\n",
      "\n",
      "episode 11, val func loss 0.8335203528404236\n",
      "\n",
      "episode 12, val func loss 0.8400543928146362\n",
      "\n",
      "episode 13, val func loss 0.8832545876502991\n",
      "\n",
      "episode 14, val func loss 0.8413504958152771\n",
      "\n",
      "episode 15, val func loss 0.8520619869232178\n",
      "\n",
      "episode 16, val func loss 0.8641021847724915\n",
      "\n",
      "Val func train loss in epoch 15:0.8605503998696804\n",
      "***********************TIME WAS 4.867999231815338 min*****************************\n",
      "\n",
      "**********************ROUND 85 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 3.368640422821045\n",
      "\n",
      "episode 2, policy loss 3.242579460144043\n",
      "\n",
      "episode 3, policy loss 3.3683812618255615\n",
      "\n",
      "episode 4, policy loss 3.6574134826660156\n",
      "\n",
      "episode 5, policy loss 3.622389316558838\n",
      "\n",
      "episode 6, policy loss 3.5658280849456787\n",
      "\n",
      "episode 7, policy loss 3.5203042030334473\n",
      "\n",
      "episode 8, policy loss 3.7295432090759277\n",
      "\n",
      "episode 9, policy loss 3.715144634246826\n",
      "\n",
      "episode 10, policy loss 3.727442502975464\n",
      "\n",
      "episode 11, policy loss 3.521130084991455\n",
      "\n",
      "episode 12, policy loss 3.4946725368499756\n",
      "\n",
      "episode 13, policy loss 3.5208752155303955\n",
      "\n",
      "episode 14, policy loss 3.618460178375244\n",
      "\n",
      "episode 15, policy loss 3.4228603839874268\n",
      "\n",
      "episode 16, policy loss 3.7160935401916504\n",
      "\n",
      "Policy train loss in epoch 0:3.550734907388687\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 3.5656402111053467\n",
      "\n",
      "episode 2, policy loss 3.5316200256347656\n",
      "\n",
      "episode 3, policy loss 3.3638532161712646\n",
      "\n",
      "episode 4, policy loss 3.5315866470336914\n",
      "\n",
      "episode 5, policy loss 3.0159683227539062\n",
      "\n",
      "episode 6, policy loss 4.490908622741699\n",
      "\n",
      "episode 7, policy loss 3.2456541061401367\n",
      "\n",
      "episode 8, policy loss 3.1966638565063477\n",
      "\n",
      "episode 9, policy loss 3.599454402923584\n",
      "\n",
      "episode 10, policy loss 3.4175612926483154\n",
      "\n",
      "episode 11, policy loss 3.5921411514282227\n",
      "\n",
      "episode 12, policy loss 3.683260202407837\n",
      "\n",
      "episode 13, policy loss 3.4828288555145264\n",
      "\n",
      "episode 14, policy loss 3.4799745082855225\n",
      "\n",
      "episode 15, policy loss 3.557290554046631\n",
      "\n",
      "episode 16, policy loss 3.6247572898864746\n",
      "\n",
      "Policy train loss in epoch 1:3.523697704076767\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 3.5118045806884766\n",
      "\n",
      "episode 2, policy loss 3.1769628524780273\n",
      "\n",
      "episode 3, policy loss 2.9758405685424805\n",
      "\n",
      "episode 4, policy loss 3.178860664367676\n",
      "\n",
      "episode 5, policy loss 3.0991499423980713\n",
      "\n",
      "episode 6, policy loss 2.9326248168945312\n",
      "\n",
      "episode 7, policy loss 2.9350626468658447\n",
      "\n",
      "episode 8, policy loss 3.0871453285217285\n",
      "\n",
      "episode 9, policy loss 3.1164674758911133\n",
      "\n",
      "episode 10, policy loss 3.239952802658081\n",
      "\n",
      "episode 11, policy loss 3.1657159328460693\n",
      "\n",
      "episode 12, policy loss 3.1233272552490234\n",
      "\n",
      "episode 13, policy loss 3.208786725997925\n",
      "\n",
      "episode 14, policy loss 3.1579513549804688\n",
      "\n",
      "episode 15, policy loss 2.943175792694092\n",
      "\n",
      "episode 16, policy loss 2.888195037841797\n",
      "\n",
      "Policy train loss in epoch 2:3.108813986182213\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 3.085073232650757\n",
      "\n",
      "episode 2, policy loss 3.098097085952759\n",
      "\n",
      "episode 3, policy loss 2.9438037872314453\n",
      "\n",
      "episode 4, policy loss 2.9626779556274414\n",
      "\n",
      "episode 5, policy loss 3.197659492492676\n",
      "\n",
      "episode 6, policy loss 3.168311595916748\n",
      "\n",
      "episode 7, policy loss 3.1299149990081787\n",
      "\n",
      "episode 8, policy loss 2.9501092433929443\n",
      "\n",
      "episode 9, policy loss 3.2101430892944336\n",
      "\n",
      "episode 10, policy loss 3.243992328643799\n",
      "\n",
      "episode 11, policy loss 3.2723257541656494\n",
      "\n",
      "episode 12, policy loss 3.1255602836608887\n",
      "\n",
      "episode 13, policy loss 3.1226840019226074\n",
      "\n",
      "episode 14, policy loss 3.159066677093506\n",
      "\n",
      "episode 15, policy loss 3.161393642425537\n",
      "\n",
      "episode 16, policy loss 2.889012336730957\n",
      "\n",
      "Policy train loss in epoch 3:3.1074890941381454\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 9.91543197631836\n",
      "\n",
      "episode 2, val func loss 6.927205562591553\n",
      "\n",
      "episode 3, val func loss 8.701333045959473\n",
      "\n",
      "episode 4, val func loss 7.109250545501709\n",
      "\n",
      "episode 5, val func loss 6.470519542694092\n",
      "\n",
      "episode 6, val func loss 7.194157600402832\n",
      "\n",
      "episode 7, val func loss 6.884261608123779\n",
      "\n",
      "episode 8, val func loss 6.69792366027832\n",
      "\n",
      "episode 9, val func loss 6.643698215484619\n",
      "\n",
      "episode 10, val func loss 6.675179481506348\n",
      "\n",
      "episode 11, val func loss 6.894678115844727\n",
      "\n",
      "episode 12, val func loss 6.79780912399292\n",
      "\n",
      "episode 13, val func loss 6.324508190155029\n",
      "\n",
      "episode 14, val func loss 6.742251873016357\n",
      "\n",
      "episode 15, val func loss 6.596435546875\n",
      "\n",
      "episode 16, val func loss 6.560381889343262\n",
      "\n",
      "Val func train loss in epoch 0:7.070939123630524\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 6.624100685119629\n",
      "\n",
      "episode 2, val func loss 6.878224849700928\n",
      "\n",
      "episode 3, val func loss 6.302000045776367\n",
      "\n",
      "episode 4, val func loss 6.508286952972412\n",
      "\n",
      "episode 5, val func loss 6.055492877960205\n",
      "\n",
      "episode 6, val func loss 6.821115493774414\n",
      "\n",
      "episode 7, val func loss 6.66766881942749\n",
      "\n",
      "episode 8, val func loss 6.486589431762695\n",
      "\n",
      "episode 9, val func loss 6.490871429443359\n",
      "\n",
      "episode 10, val func loss 6.745823383331299\n",
      "\n",
      "episode 11, val func loss 6.370426654815674\n",
      "\n",
      "episode 12, val func loss 6.48878812789917\n",
      "\n",
      "episode 13, val func loss 6.414831638336182\n",
      "\n",
      "episode 14, val func loss 6.427024841308594\n",
      "\n",
      "episode 15, val func loss 6.1485185623168945\n",
      "\n",
      "episode 16, val func loss 6.587756633758545\n",
      "\n",
      "Val func train loss in epoch 1:6.501095026731491\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 6.533805847167969\n",
      "\n",
      "episode 2, val func loss 6.515988826751709\n",
      "\n",
      "episode 3, val func loss 6.460258483886719\n",
      "\n",
      "episode 4, val func loss 7.006191253662109\n",
      "\n",
      "episode 5, val func loss 6.407041549682617\n",
      "\n",
      "episode 6, val func loss 6.049168109893799\n",
      "\n",
      "episode 7, val func loss 6.506629943847656\n",
      "\n",
      "episode 8, val func loss 6.294061660766602\n",
      "\n",
      "episode 9, val func loss 6.479191303253174\n",
      "\n",
      "episode 10, val func loss 6.717956066131592\n",
      "\n",
      "episode 11, val func loss 6.742664813995361\n",
      "\n",
      "episode 12, val func loss 6.452841281890869\n",
      "\n",
      "episode 13, val func loss 6.477261066436768\n",
      "\n",
      "episode 14, val func loss 6.891123294830322\n",
      "\n",
      "episode 15, val func loss 6.38592529296875\n",
      "\n",
      "episode 16, val func loss 6.053287982940674\n",
      "\n",
      "Val func train loss in epoch 2:6.498337298631668\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 6.4103169441223145\n",
      "\n",
      "episode 2, val func loss 6.142147064208984\n",
      "\n",
      "episode 3, val func loss 6.474299907684326\n",
      "\n",
      "episode 4, val func loss 6.4265456199646\n",
      "\n",
      "episode 5, val func loss 6.349118709564209\n",
      "\n",
      "episode 6, val func loss 6.077502727508545\n",
      "\n",
      "episode 7, val func loss 6.553611755371094\n",
      "\n",
      "episode 8, val func loss 6.450952529907227\n",
      "\n",
      "episode 9, val func loss 6.817831516265869\n",
      "\n",
      "episode 10, val func loss 6.33698034286499\n",
      "\n",
      "episode 11, val func loss 6.207605361938477\n",
      "\n",
      "episode 12, val func loss 6.727211952209473\n",
      "\n",
      "episode 13, val func loss 6.493104457855225\n",
      "\n",
      "episode 14, val func loss 6.298564434051514\n",
      "\n",
      "episode 15, val func loss 6.618277072906494\n",
      "\n",
      "episode 16, val func loss 6.254697322845459\n",
      "\n",
      "Val func train loss in epoch 3:6.4149229824543\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 6.464190483093262\n",
      "\n",
      "episode 2, val func loss 6.400611877441406\n",
      "\n",
      "episode 3, val func loss 6.713230609893799\n",
      "\n",
      "episode 4, val func loss 6.059393882751465\n",
      "\n",
      "episode 5, val func loss 6.661373615264893\n",
      "\n",
      "episode 6, val func loss 6.471812725067139\n",
      "\n",
      "episode 7, val func loss 6.508659839630127\n",
      "\n",
      "episode 8, val func loss 6.451470375061035\n",
      "\n",
      "episode 9, val func loss 5.96132230758667\n",
      "\n",
      "episode 10, val func loss 6.20469856262207\n",
      "\n",
      "episode 11, val func loss 6.42103910446167\n",
      "\n",
      "episode 12, val func loss 6.3330817222595215\n",
      "\n",
      "episode 13, val func loss 6.329057693481445\n",
      "\n",
      "episode 14, val func loss 6.64080810546875\n",
      "\n",
      "episode 15, val func loss 6.1173295974731445\n",
      "\n",
      "episode 16, val func loss 6.259518146514893\n",
      "\n",
      "Val func train loss in epoch 4:6.374849915504456\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 6.14716911315918\n",
      "\n",
      "episode 2, val func loss 6.428776264190674\n",
      "\n",
      "episode 3, val func loss 6.407853603363037\n",
      "\n",
      "episode 4, val func loss 6.218301773071289\n",
      "\n",
      "episode 5, val func loss 6.494884490966797\n",
      "\n",
      "episode 6, val func loss 6.50790548324585\n",
      "\n",
      "episode 7, val func loss 5.977854251861572\n",
      "\n",
      "episode 8, val func loss 6.5475358963012695\n",
      "\n",
      "episode 9, val func loss 6.638554096221924\n",
      "\n",
      "episode 10, val func loss 6.7494401931762695\n",
      "\n",
      "episode 11, val func loss 6.305400371551514\n",
      "\n",
      "episode 12, val func loss 6.563847064971924\n",
      "\n",
      "episode 13, val func loss 6.346701622009277\n",
      "\n",
      "episode 14, val func loss 5.97058629989624\n",
      "\n",
      "episode 15, val func loss 6.467733860015869\n",
      "\n",
      "episode 16, val func loss 6.1604814529418945\n",
      "\n",
      "Val func train loss in epoch 5:6.370814114809036\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 6.249565124511719\n",
      "\n",
      "episode 2, val func loss 6.164839267730713\n",
      "\n",
      "episode 3, val func loss 6.448216915130615\n",
      "\n",
      "episode 4, val func loss 6.4813127517700195\n",
      "\n",
      "episode 5, val func loss 6.126828670501709\n",
      "\n",
      "episode 6, val func loss 6.40787935256958\n",
      "\n",
      "episode 7, val func loss 6.0236334800720215\n",
      "\n",
      "episode 8, val func loss 6.596682548522949\n",
      "\n",
      "episode 9, val func loss 6.51042366027832\n",
      "\n",
      "episode 10, val func loss 6.634799480438232\n",
      "\n",
      "episode 11, val func loss 6.589939594268799\n",
      "\n",
      "episode 12, val func loss 6.45795202255249\n",
      "\n",
      "episode 13, val func loss 6.239391803741455\n",
      "\n",
      "episode 14, val func loss 6.252684116363525\n",
      "\n",
      "episode 15, val func loss 6.3671345710754395\n",
      "\n",
      "episode 16, val func loss 6.094649791717529\n",
      "\n",
      "Val func train loss in epoch 6:6.35287082195282\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 6.088332653045654\n",
      "\n",
      "episode 2, val func loss 6.653187274932861\n",
      "\n",
      "episode 3, val func loss 6.501152992248535\n",
      "\n",
      "episode 4, val func loss 6.626106262207031\n",
      "\n",
      "episode 5, val func loss 6.243521690368652\n",
      "\n",
      "episode 6, val func loss 6.393345355987549\n",
      "\n",
      "episode 7, val func loss 6.618568420410156\n",
      "\n",
      "episode 8, val func loss 6.681742191314697\n",
      "\n",
      "episode 9, val func loss 6.337494850158691\n",
      "\n",
      "episode 10, val func loss 6.4195380210876465\n",
      "\n",
      "episode 11, val func loss 6.444591999053955\n",
      "\n",
      "episode 12, val func loss 6.328090667724609\n",
      "\n",
      "episode 13, val func loss 6.449019908905029\n",
      "\n",
      "episode 14, val func loss 6.465432167053223\n",
      "\n",
      "episode 15, val func loss 6.0094990730285645\n",
      "\n",
      "episode 16, val func loss 6.094100475311279\n",
      "\n",
      "Val func train loss in epoch 7:6.397107750177383\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 6.240077495574951\n",
      "\n",
      "episode 2, val func loss 6.72783899307251\n",
      "\n",
      "episode 3, val func loss 6.2678985595703125\n",
      "\n",
      "episode 4, val func loss 6.336765766143799\n",
      "\n",
      "episode 5, val func loss 6.2289581298828125\n",
      "\n",
      "episode 6, val func loss 6.625332355499268\n",
      "\n",
      "episode 7, val func loss 6.307119846343994\n",
      "\n",
      "episode 8, val func loss 6.46267032623291\n",
      "\n",
      "episode 9, val func loss 6.167037487030029\n",
      "\n",
      "episode 10, val func loss 6.325736999511719\n",
      "\n",
      "episode 11, val func loss 6.677684783935547\n",
      "\n",
      "episode 12, val func loss 6.171078205108643\n",
      "\n",
      "episode 13, val func loss 5.979687213897705\n",
      "\n",
      "episode 14, val func loss 6.468228816986084\n",
      "\n",
      "episode 15, val func loss 6.263803482055664\n",
      "\n",
      "episode 16, val func loss 6.372305870056152\n",
      "\n",
      "Val func train loss in epoch 8:6.351389020681381\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 6.333568572998047\n",
      "\n",
      "episode 2, val func loss 6.253873348236084\n",
      "\n",
      "episode 3, val func loss 6.259427547454834\n",
      "\n",
      "episode 4, val func loss 6.450576305389404\n",
      "\n",
      "episode 5, val func loss 6.012909889221191\n",
      "\n",
      "episode 6, val func loss 6.662715911865234\n",
      "\n",
      "episode 7, val func loss 6.022152423858643\n",
      "\n",
      "episode 8, val func loss 6.666545867919922\n",
      "\n",
      "episode 9, val func loss 6.18002986907959\n",
      "\n",
      "episode 10, val func loss 6.645422458648682\n",
      "\n",
      "episode 11, val func loss 6.462474346160889\n",
      "\n",
      "episode 12, val func loss 6.002579689025879\n",
      "\n",
      "episode 13, val func loss 6.54397439956665\n",
      "\n",
      "episode 14, val func loss 6.531830787658691\n",
      "\n",
      "episode 15, val func loss 6.515690326690674\n",
      "\n",
      "episode 16, val func loss 6.529832363128662\n",
      "\n",
      "Val func train loss in epoch 9:6.379600256681442\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 6.628485202789307\n",
      "\n",
      "episode 2, val func loss 6.031156539916992\n",
      "\n",
      "episode 3, val func loss 6.209357261657715\n",
      "\n",
      "episode 4, val func loss 7.414121627807617\n",
      "\n",
      "episode 5, val func loss 6.196093559265137\n",
      "\n",
      "episode 6, val func loss 6.048208713531494\n",
      "\n",
      "episode 7, val func loss 6.4219441413879395\n",
      "\n",
      "episode 8, val func loss 6.005521297454834\n",
      "\n",
      "episode 9, val func loss 6.525103569030762\n",
      "\n",
      "episode 10, val func loss 6.585160255432129\n",
      "\n",
      "episode 11, val func loss 6.58759880065918\n",
      "\n",
      "episode 12, val func loss 6.416618347167969\n",
      "\n",
      "episode 13, val func loss 6.112511157989502\n",
      "\n",
      "episode 14, val func loss 6.423701763153076\n",
      "\n",
      "episode 15, val func loss 6.501758098602295\n",
      "\n",
      "episode 16, val func loss 6.50596809387207\n",
      "\n",
      "Val func train loss in epoch 10:6.413331776857376\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 6.344437599182129\n",
      "\n",
      "episode 2, val func loss 6.5002121925354\n",
      "\n",
      "episode 3, val func loss 6.320856094360352\n",
      "\n",
      "episode 4, val func loss 6.2133331298828125\n",
      "\n",
      "episode 5, val func loss 6.478429317474365\n",
      "\n",
      "episode 6, val func loss 6.75117826461792\n",
      "\n",
      "episode 7, val func loss 6.5215535163879395\n",
      "\n",
      "episode 8, val func loss 6.497872352600098\n",
      "\n",
      "episode 9, val func loss 6.390339374542236\n",
      "\n",
      "episode 10, val func loss 6.190556049346924\n",
      "\n",
      "episode 11, val func loss 6.0443806648254395\n",
      "\n",
      "episode 12, val func loss 6.355536460876465\n",
      "\n",
      "episode 13, val func loss 6.290874004364014\n",
      "\n",
      "episode 14, val func loss 6.246227741241455\n",
      "\n",
      "episode 15, val func loss 6.456835746765137\n",
      "\n",
      "episode 16, val func loss 6.644132137298584\n",
      "\n",
      "Val func train loss in epoch 11:6.390422165393829\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 6.344250202178955\n",
      "\n",
      "episode 2, val func loss 6.398482799530029\n",
      "\n",
      "episode 3, val func loss 6.12225341796875\n",
      "\n",
      "episode 4, val func loss 6.369270324707031\n",
      "\n",
      "episode 5, val func loss 6.0185956954956055\n",
      "\n",
      "episode 6, val func loss 6.851930618286133\n",
      "\n",
      "episode 7, val func loss 6.146189212799072\n",
      "\n",
      "episode 8, val func loss 6.039374351501465\n",
      "\n",
      "episode 9, val func loss 6.294522762298584\n",
      "\n",
      "episode 10, val func loss 6.5375752449035645\n",
      "\n",
      "episode 11, val func loss 6.504500865936279\n",
      "\n",
      "episode 12, val func loss 6.635402679443359\n",
      "\n",
      "episode 13, val func loss 6.4950947761535645\n",
      "\n",
      "episode 14, val func loss 6.31056547164917\n",
      "\n",
      "episode 15, val func loss 6.516984939575195\n",
      "\n",
      "episode 16, val func loss 6.391262054443359\n",
      "\n",
      "Val func train loss in epoch 12:6.373515963554382\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 6.486790657043457\n",
      "\n",
      "episode 2, val func loss 5.999120235443115\n",
      "\n",
      "episode 3, val func loss 6.115415573120117\n",
      "\n",
      "episode 4, val func loss 6.619893550872803\n",
      "\n",
      "episode 5, val func loss 6.3504180908203125\n",
      "\n",
      "episode 6, val func loss 6.197009086608887\n",
      "\n",
      "episode 7, val func loss 6.324986934661865\n",
      "\n",
      "episode 8, val func loss 6.799398899078369\n",
      "\n",
      "episode 9, val func loss 6.519000053405762\n",
      "\n",
      "episode 10, val func loss 6.361949443817139\n",
      "\n",
      "episode 11, val func loss 6.553752422332764\n",
      "\n",
      "episode 12, val func loss 6.648148536682129\n",
      "\n",
      "episode 13, val func loss 6.49647331237793\n",
      "\n",
      "episode 14, val func loss 6.43092155456543\n",
      "\n",
      "episode 15, val func loss 6.5714497566223145\n",
      "\n",
      "episode 16, val func loss 6.3411030769348145\n",
      "\n",
      "Val func train loss in epoch 13:6.4259894490242\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 6.408360004425049\n",
      "\n",
      "episode 2, val func loss 6.181368827819824\n",
      "\n",
      "episode 3, val func loss 6.179022789001465\n",
      "\n",
      "episode 4, val func loss 6.51281213760376\n",
      "\n",
      "episode 5, val func loss 6.159555435180664\n",
      "\n",
      "episode 6, val func loss 6.2911057472229\n",
      "\n",
      "episode 7, val func loss 6.534730434417725\n",
      "\n",
      "episode 8, val func loss 6.664487361907959\n",
      "\n",
      "episode 9, val func loss 6.495354652404785\n",
      "\n",
      "episode 10, val func loss 6.266177177429199\n",
      "\n",
      "episode 11, val func loss 6.374372482299805\n",
      "\n",
      "episode 12, val func loss 6.431586265563965\n",
      "\n",
      "episode 13, val func loss 6.287441730499268\n",
      "\n",
      "episode 14, val func loss 6.27608060836792\n",
      "\n",
      "episode 15, val func loss 6.27695369720459\n",
      "\n",
      "episode 16, val func loss 6.787548542022705\n",
      "\n",
      "Val func train loss in epoch 14:6.382934868335724\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 6.407905578613281\n",
      "\n",
      "episode 2, val func loss 6.580681324005127\n",
      "\n",
      "episode 3, val func loss 6.4575629234313965\n",
      "\n",
      "episode 4, val func loss 6.493869304656982\n",
      "\n",
      "episode 5, val func loss 6.477813720703125\n",
      "\n",
      "episode 6, val func loss 6.1314239501953125\n",
      "\n",
      "episode 7, val func loss 6.12677001953125\n",
      "\n",
      "episode 8, val func loss 6.1457839012146\n",
      "\n",
      "episode 9, val func loss 6.654696464538574\n",
      "\n",
      "episode 10, val func loss 6.169580936431885\n",
      "\n",
      "episode 11, val func loss 6.379735469818115\n",
      "\n",
      "episode 12, val func loss 6.327445983886719\n",
      "\n",
      "episode 13, val func loss 6.2445387840271\n",
      "\n",
      "episode 14, val func loss 6.216735363006592\n",
      "\n",
      "episode 15, val func loss 6.542727947235107\n",
      "\n",
      "episode 16, val func loss 6.29630708694458\n",
      "\n",
      "Val func train loss in epoch 15:6.353348672389984\n",
      "***********************TIME WAS 4.8699186245600385 min*****************************\n",
      "\n",
      "**********************ROUND 86 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.42356163263320923\n",
      "\n",
      "episode 2, policy loss 0.247778058052063\n",
      "\n",
      "episode 3, policy loss 0.6051294803619385\n",
      "\n",
      "episode 4, policy loss 0.24478085339069366\n",
      "\n",
      "episode 5, policy loss 0.8050896525382996\n",
      "\n",
      "episode 6, policy loss 0.3206525444984436\n",
      "\n",
      "episode 7, policy loss 0.2887077331542969\n",
      "\n",
      "episode 8, policy loss 0.4776800870895386\n",
      "\n",
      "episode 9, policy loss 0.20414869487285614\n",
      "\n",
      "episode 10, policy loss 0.3500444293022156\n",
      "\n",
      "episode 11, policy loss 0.14247260987758636\n",
      "\n",
      "episode 12, policy loss 0.549231231212616\n",
      "\n",
      "episode 13, policy loss 0.8173298239707947\n",
      "\n",
      "episode 14, policy loss 0.5237556099891663\n",
      "\n",
      "episode 15, policy loss 0.8666810393333435\n",
      "\n",
      "episode 16, policy loss 0.7073913812637329\n",
      "\n",
      "Policy train loss in epoch 0:0.47340217884629965\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.597713053226471\n",
      "\n",
      "episode 2, policy loss 0.5244794487953186\n",
      "\n",
      "episode 3, policy loss 0.2691780626773834\n",
      "\n",
      "episode 4, policy loss 0.7746508121490479\n",
      "\n",
      "episode 5, policy loss 0.5395533442497253\n",
      "\n",
      "episode 6, policy loss 0.1980137974023819\n",
      "\n",
      "episode 7, policy loss 0.23391520977020264\n",
      "\n",
      "episode 8, policy loss 0.508642315864563\n",
      "\n",
      "episode 9, policy loss 0.3458343744277954\n",
      "\n",
      "episode 10, policy loss 0.6948924660682678\n",
      "\n",
      "episode 11, policy loss 0.439439058303833\n",
      "\n",
      "episode 12, policy loss 0.25122740864753723\n",
      "\n",
      "episode 13, policy loss 0.9113104343414307\n",
      "\n",
      "episode 14, policy loss 0.2843511998653412\n",
      "\n",
      "episode 15, policy loss 0.30664682388305664\n",
      "\n",
      "episode 16, policy loss 0.8743870854377747\n",
      "\n",
      "Policy train loss in epoch 1:0.48463968094438314\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.2733735144138336\n",
      "\n",
      "episode 2, policy loss 0.7989644408226013\n",
      "\n",
      "episode 3, policy loss 0.24565890431404114\n",
      "\n",
      "episode 4, policy loss 0.5242918729782104\n",
      "\n",
      "episode 5, policy loss 0.1554166078567505\n",
      "\n",
      "episode 6, policy loss 0.7880071401596069\n",
      "\n",
      "episode 7, policy loss 0.7039667963981628\n",
      "\n",
      "episode 8, policy loss 0.5095344185829163\n",
      "\n",
      "episode 9, policy loss 0.5134055018424988\n",
      "\n",
      "episode 10, policy loss 0.5855703353881836\n",
      "\n",
      "episode 11, policy loss 0.438679963350296\n",
      "\n",
      "episode 12, policy loss 0.252279132604599\n",
      "\n",
      "episode 13, policy loss 0.35174861550331116\n",
      "\n",
      "episode 14, policy loss 0.8944395780563354\n",
      "\n",
      "episode 15, policy loss 0.31919679045677185\n",
      "\n",
      "episode 16, policy loss 0.20030440390110016\n",
      "\n",
      "Policy train loss in epoch 2:0.4721773760393262\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.5185238718986511\n",
      "\n",
      "episode 2, policy loss 0.24670250713825226\n",
      "\n",
      "episode 3, policy loss 0.15254440903663635\n",
      "\n",
      "episode 4, policy loss 0.27592307329177856\n",
      "\n",
      "episode 5, policy loss 0.25319692492485046\n",
      "\n",
      "episode 6, policy loss 0.19733549654483795\n",
      "\n",
      "episode 7, policy loss 0.5335740447044373\n",
      "\n",
      "episode 8, policy loss 0.48154306411743164\n",
      "\n",
      "episode 9, policy loss 0.8098353147506714\n",
      "\n",
      "episode 10, policy loss 0.6859379410743713\n",
      "\n",
      "episode 11, policy loss 0.3546050786972046\n",
      "\n",
      "episode 12, policy loss 0.8255817294120789\n",
      "\n",
      "episode 13, policy loss 0.7681488394737244\n",
      "\n",
      "episode 14, policy loss 0.3556004762649536\n",
      "\n",
      "episode 15, policy loss 0.6083893775939941\n",
      "\n",
      "episode 16, policy loss 0.42913317680358887\n",
      "\n",
      "Policy train loss in epoch 3:0.4685359578579664\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.9894485473632812\n",
      "\n",
      "episode 2, val func loss 3.414278745651245\n",
      "\n",
      "episode 3, val func loss 2.1015625\n",
      "\n",
      "episode 4, val func loss 0.8755747079849243\n",
      "\n",
      "episode 5, val func loss 0.44263526797294617\n",
      "\n",
      "episode 6, val func loss 1.1440942287445068\n",
      "\n",
      "episode 7, val func loss 0.4922187030315399\n",
      "\n",
      "episode 8, val func loss 0.7093700170516968\n",
      "\n",
      "episode 9, val func loss 0.4402470886707306\n",
      "\n",
      "episode 10, val func loss 0.4859221875667572\n",
      "\n",
      "episode 11, val func loss 0.013516186736524105\n",
      "\n",
      "episode 12, val func loss 0.39368000626564026\n",
      "\n",
      "episode 13, val func loss 0.030621826648712158\n",
      "\n",
      "episode 14, val func loss 0.14946064352989197\n",
      "\n",
      "episode 15, val func loss 0.19267289340496063\n",
      "\n",
      "episode 16, val func loss 0.1894596517086029\n",
      "\n",
      "Val func train loss in epoch 0:0.7540477001457475\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.1873621791601181\n",
      "\n",
      "episode 2, val func loss 0.5194849371910095\n",
      "\n",
      "episode 3, val func loss 0.16209042072296143\n",
      "\n",
      "episode 4, val func loss 0.0009690338047221303\n",
      "\n",
      "episode 5, val func loss 0.27351146936416626\n",
      "\n",
      "episode 6, val func loss 0.13471540808677673\n",
      "\n",
      "episode 7, val func loss 0.0693606436252594\n",
      "\n",
      "episode 8, val func loss 0.27883222699165344\n",
      "\n",
      "episode 9, val func loss 0.5361080765724182\n",
      "\n",
      "episode 10, val func loss 0.4042784869670868\n",
      "\n",
      "episode 11, val func loss 0.40710943937301636\n",
      "\n",
      "episode 12, val func loss 0.8023704886436462\n",
      "\n",
      "episode 13, val func loss 0.27288714051246643\n",
      "\n",
      "episode 14, val func loss 0.0005608631181530654\n",
      "\n",
      "episode 15, val func loss 0.13794447481632233\n",
      "\n",
      "episode 16, val func loss 0.40804657340049744\n",
      "\n",
      "Val func train loss in epoch 1:0.2872269913968921\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.4017404019832611\n",
      "\n",
      "episode 2, val func loss 0.002007002243772149\n",
      "\n",
      "episode 3, val func loss 0.0012282528914511204\n",
      "\n",
      "episode 4, val func loss 0.2638648450374603\n",
      "\n",
      "episode 5, val func loss 0.2688317894935608\n",
      "\n",
      "episode 6, val func loss 0.13159622251987457\n",
      "\n",
      "episode 7, val func loss 0.26846176385879517\n",
      "\n",
      "episode 8, val func loss 0.1322239637374878\n",
      "\n",
      "episode 9, val func loss 0.1330725997686386\n",
      "\n",
      "episode 10, val func loss 0.400774747133255\n",
      "\n",
      "episode 11, val func loss 0.4045558571815491\n",
      "\n",
      "episode 12, val func loss 0.13878129422664642\n",
      "\n",
      "episode 13, val func loss 0.002430889056995511\n",
      "\n",
      "episode 14, val func loss 0.8088399171829224\n",
      "\n",
      "episode 15, val func loss 0.5305618047714233\n",
      "\n",
      "episode 16, val func loss 0.39521318674087524\n",
      "\n",
      "Val func train loss in epoch 2:0.26776153361424804\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.13494080305099487\n",
      "\n",
      "episode 2, val func loss 0.003917552996426821\n",
      "\n",
      "episode 3, val func loss 0.2644607722759247\n",
      "\n",
      "episode 4, val func loss 0.1438140720129013\n",
      "\n",
      "episode 5, val func loss 0.7965454459190369\n",
      "\n",
      "episode 6, val func loss 0.13829119503498077\n",
      "\n",
      "episode 7, val func loss 0.40367841720581055\n",
      "\n",
      "episode 8, val func loss 0.5312430262565613\n",
      "\n",
      "episode 9, val func loss 0.13396055996418\n",
      "\n",
      "episode 10, val func loss 0.4019967317581177\n",
      "\n",
      "episode 11, val func loss 0.3995829224586487\n",
      "\n",
      "episode 12, val func loss 0.40003880858421326\n",
      "\n",
      "episode 13, val func loss 0.002102839294821024\n",
      "\n",
      "episode 14, val func loss 0.27037739753723145\n",
      "\n",
      "episode 15, val func loss 0.005145168863236904\n",
      "\n",
      "episode 16, val func loss 0.26642826199531555\n",
      "\n",
      "Val func train loss in epoch 3:0.2685327484505251\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.0021980684250593185\n",
      "\n",
      "episode 2, val func loss 0.2697193920612335\n",
      "\n",
      "episode 3, val func loss 0.4065774977207184\n",
      "\n",
      "episode 4, val func loss 0.13584482669830322\n",
      "\n",
      "episode 5, val func loss 0.13273100554943085\n",
      "\n",
      "episode 6, val func loss 0.26946595311164856\n",
      "\n",
      "episode 7, val func loss 0.13281656801700592\n",
      "\n",
      "episode 8, val func loss 0.13343055546283722\n",
      "\n",
      "episode 9, val func loss 0.40265005826950073\n",
      "\n",
      "episode 10, val func loss 0.40354567766189575\n",
      "\n",
      "episode 11, val func loss 0.393903911113739\n",
      "\n",
      "episode 12, val func loss 0.003999010194092989\n",
      "\n",
      "episode 13, val func loss 0.2688157856464386\n",
      "\n",
      "episode 14, val func loss 0.7902321219444275\n",
      "\n",
      "episode 15, val func loss 0.003174736863002181\n",
      "\n",
      "episode 16, val func loss 0.52655029296875\n",
      "\n",
      "Val func train loss in epoch 4:0.26722846635675523\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.1433749794960022\n",
      "\n",
      "episode 2, val func loss 0.006073701661080122\n",
      "\n",
      "episode 3, val func loss 0.2627386450767517\n",
      "\n",
      "episode 4, val func loss 0.002030892064794898\n",
      "\n",
      "episode 5, val func loss 0.26504427194595337\n",
      "\n",
      "episode 6, val func loss 0.7948976159095764\n",
      "\n",
      "episode 7, val func loss 0.5326464176177979\n",
      "\n",
      "episode 8, val func loss 0.4032626450061798\n",
      "\n",
      "episode 9, val func loss 0.13506343960762024\n",
      "\n",
      "episode 10, val func loss 0.01044510304927826\n",
      "\n",
      "episode 11, val func loss 0.2629392445087433\n",
      "\n",
      "episode 12, val func loss 0.3952368199825287\n",
      "\n",
      "episode 13, val func loss 0.39142945408821106\n",
      "\n",
      "episode 14, val func loss 0.13473597168922424\n",
      "\n",
      "episode 15, val func loss 0.13667671382427216\n",
      "\n",
      "episode 16, val func loss 0.40054047107696533\n",
      "\n",
      "Val func train loss in epoch 5:0.2673210241628112\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.13405101001262665\n",
      "\n",
      "episode 2, val func loss 0.5233825445175171\n",
      "\n",
      "episode 3, val func loss 0.39777204394340515\n",
      "\n",
      "episode 4, val func loss 0.3992881774902344\n",
      "\n",
      "episode 5, val func loss 0.00912267155945301\n",
      "\n",
      "episode 6, val func loss 0.003472912358120084\n",
      "\n",
      "episode 7, val func loss 0.26510217785835266\n",
      "\n",
      "episode 8, val func loss 0.13706503808498383\n",
      "\n",
      "episode 9, val func loss 0.26630181074142456\n",
      "\n",
      "episode 10, val func loss 0.26749351620674133\n",
      "\n",
      "episode 11, val func loss 0.0028963785152882338\n",
      "\n",
      "episode 12, val func loss 0.13060635328292847\n",
      "\n",
      "episode 13, val func loss 0.4002651572227478\n",
      "\n",
      "episode 14, val func loss 0.3912360668182373\n",
      "\n",
      "episode 15, val func loss 0.1410275250673294\n",
      "\n",
      "episode 16, val func loss 0.7637690901756287\n",
      "\n",
      "Val func train loss in epoch 6:0.26455327961593866\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.14037159085273743\n",
      "\n",
      "episode 2, val func loss 0.1378394067287445\n",
      "\n",
      "episode 3, val func loss 0.029100507497787476\n",
      "\n",
      "episode 4, val func loss 0.004701999481767416\n",
      "\n",
      "episode 5, val func loss 0.40102341771125793\n",
      "\n",
      "episode 6, val func loss 0.270956426858902\n",
      "\n",
      "episode 7, val func loss 0.5351092219352722\n",
      "\n",
      "episode 8, val func loss 0.27289628982543945\n",
      "\n",
      "episode 9, val func loss 0.2714692950248718\n",
      "\n",
      "episode 10, val func loss 0.3909272253513336\n",
      "\n",
      "episode 11, val func loss 0.13578453660011292\n",
      "\n",
      "episode 12, val func loss 0.005862901918590069\n",
      "\n",
      "episode 13, val func loss 0.3939428925514221\n",
      "\n",
      "episode 14, val func loss 0.7677022218704224\n",
      "\n",
      "episode 15, val func loss 0.39743074774742126\n",
      "\n",
      "episode 16, val func loss 0.13743221759796143\n",
      "\n",
      "Val func train loss in epoch 7:0.26828443122212775\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.25819018483161926\n",
      "\n",
      "episode 2, val func loss 0.39660802483558655\n",
      "\n",
      "episode 3, val func loss 0.3937215507030487\n",
      "\n",
      "episode 4, val func loss 0.004159138537943363\n",
      "\n",
      "episode 5, val func loss 0.004486968275159597\n",
      "\n",
      "episode 6, val func loss 0.13782091438770294\n",
      "\n",
      "episode 7, val func loss 0.12864404916763306\n",
      "\n",
      "episode 8, val func loss 0.40361711382865906\n",
      "\n",
      "episode 9, val func loss 0.3896959722042084\n",
      "\n",
      "episode 10, val func loss 0.13025422394275665\n",
      "\n",
      "episode 11, val func loss 0.25955525040626526\n",
      "\n",
      "episode 12, val func loss 0.004682273603975773\n",
      "\n",
      "episode 13, val func loss 0.515625536441803\n",
      "\n",
      "episode 14, val func loss 0.7802091240882874\n",
      "\n",
      "episode 15, val func loss 0.1513742357492447\n",
      "\n",
      "episode 16, val func loss 0.26044216752052307\n",
      "\n",
      "Val func train loss in epoch 8:0.26369292053277604\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.4066272974014282\n",
      "\n",
      "episode 2, val func loss 0.7592239379882812\n",
      "\n",
      "episode 3, val func loss 0.5194240212440491\n",
      "\n",
      "episode 4, val func loss 0.010866275057196617\n",
      "\n",
      "episode 5, val func loss 0.39193764328956604\n",
      "\n",
      "episode 6, val func loss 0.005843915045261383\n",
      "\n",
      "episode 7, val func loss 0.1384638249874115\n",
      "\n",
      "episode 8, val func loss 0.4032558798789978\n",
      "\n",
      "episode 9, val func loss 0.27022475004196167\n",
      "\n",
      "episode 10, val func loss 0.2613435387611389\n",
      "\n",
      "episode 11, val func loss 0.0032078081276267767\n",
      "\n",
      "episode 12, val func loss 0.12954169511795044\n",
      "\n",
      "episode 13, val func loss 0.37016624212265015\n",
      "\n",
      "episode 14, val func loss 0.26625385880470276\n",
      "\n",
      "episode 15, val func loss 0.1352357715368271\n",
      "\n",
      "episode 16, val func loss 0.12913568317890167\n",
      "\n",
      "Val func train loss in epoch 9:0.26254700891149696\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.004401100799441338\n",
      "\n",
      "episode 2, val func loss 0.006419416517019272\n",
      "\n",
      "episode 3, val func loss 0.26373425126075745\n",
      "\n",
      "episode 4, val func loss 0.7798075675964355\n",
      "\n",
      "episode 5, val func loss 0.3868262767791748\n",
      "\n",
      "episode 6, val func loss 0.3804498016834259\n",
      "\n",
      "episode 7, val func loss 0.38519465923309326\n",
      "\n",
      "episode 8, val func loss 0.26746320724487305\n",
      "\n",
      "episode 9, val func loss 0.5089085102081299\n",
      "\n",
      "episode 10, val func loss 0.014735977165400982\n",
      "\n",
      "episode 11, val func loss 0.2653462290763855\n",
      "\n",
      "episode 12, val func loss 0.12583747506141663\n",
      "\n",
      "episode 13, val func loss 0.1385597586631775\n",
      "\n",
      "episode 14, val func loss 0.1357409507036209\n",
      "\n",
      "episode 15, val func loss 0.3981812596321106\n",
      "\n",
      "episode 16, val func loss 0.13504211604595184\n",
      "\n",
      "Val func train loss in epoch 10:0.2622905348544009\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7768253684043884\n",
      "\n",
      "episode 2, val func loss 0.4104452133178711\n",
      "\n",
      "episode 3, val func loss 0.3827105760574341\n",
      "\n",
      "episode 4, val func loss 0.14383231103420258\n",
      "\n",
      "episode 5, val func loss 0.012635290622711182\n",
      "\n",
      "episode 6, val func loss 0.2606557309627533\n",
      "\n",
      "episode 7, val func loss 0.13246963918209076\n",
      "\n",
      "episode 8, val func loss 0.26218080520629883\n",
      "\n",
      "episode 9, val func loss 0.40060797333717346\n",
      "\n",
      "episode 10, val func loss 0.3946649730205536\n",
      "\n",
      "episode 11, val func loss 0.13122400641441345\n",
      "\n",
      "episode 12, val func loss 0.26840370893478394\n",
      "\n",
      "episode 13, val func loss 0.008410201407968998\n",
      "\n",
      "episode 14, val func loss 0.005638328846544027\n",
      "\n",
      "episode 15, val func loss 0.12375801801681519\n",
      "\n",
      "episode 16, val func loss 0.5181277394294739\n",
      "\n",
      "Val func train loss in epoch 11:0.2645368677622173\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.39567309617996216\n",
      "\n",
      "episode 2, val func loss 0.2606780230998993\n",
      "\n",
      "episode 3, val func loss 0.12872058153152466\n",
      "\n",
      "episode 4, val func loss 0.5159859657287598\n",
      "\n",
      "episode 5, val func loss 0.010080155916512012\n",
      "\n",
      "episode 6, val func loss 0.1309831589460373\n",
      "\n",
      "episode 7, val func loss 0.2681673765182495\n",
      "\n",
      "episode 8, val func loss 0.2666722238063812\n",
      "\n",
      "episode 9, val func loss 0.3836866617202759\n",
      "\n",
      "episode 10, val func loss 0.40006911754608154\n",
      "\n",
      "episode 11, val func loss 0.006071551237255335\n",
      "\n",
      "episode 12, val func loss 0.3828740417957306\n",
      "\n",
      "episode 13, val func loss 0.13801947236061096\n",
      "\n",
      "episode 14, val func loss 0.13718757033348083\n",
      "\n",
      "episode 15, val func loss 0.007950475439429283\n",
      "\n",
      "episode 16, val func loss 0.7781761288642883\n",
      "\n",
      "Val func train loss in epoch 12:0.2631872250640299\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.006281596142798662\n",
      "\n",
      "episode 2, val func loss 0.13136564195156097\n",
      "\n",
      "episode 3, val func loss 0.13342849910259247\n",
      "\n",
      "episode 4, val func loss 0.3943277597427368\n",
      "\n",
      "episode 5, val func loss 0.7681752443313599\n",
      "\n",
      "episode 6, val func loss 0.2577776610851288\n",
      "\n",
      "episode 7, val func loss 0.3927118480205536\n",
      "\n",
      "episode 8, val func loss 0.3846963346004486\n",
      "\n",
      "episode 9, val func loss 0.25677788257598877\n",
      "\n",
      "episode 10, val func loss 0.13469383120536804\n",
      "\n",
      "episode 11, val func loss 0.25666701793670654\n",
      "\n",
      "episode 12, val func loss 0.01831398718059063\n",
      "\n",
      "episode 13, val func loss 0.007354873698204756\n",
      "\n",
      "episode 14, val func loss 0.39068424701690674\n",
      "\n",
      "episode 15, val func loss 0.5187787413597107\n",
      "\n",
      "episode 16, val func loss 0.13903234899044037\n",
      "\n",
      "Val func train loss in epoch 13:0.2619417196838185\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.13030056655406952\n",
      "\n",
      "episode 2, val func loss 0.23017734289169312\n",
      "\n",
      "episode 3, val func loss 0.391854465007782\n",
      "\n",
      "episode 4, val func loss 0.255133718252182\n",
      "\n",
      "episode 5, val func loss 0.030998339876532555\n",
      "\n",
      "episode 6, val func loss 0.39533084630966187\n",
      "\n",
      "episode 7, val func loss 0.13513000309467316\n",
      "\n",
      "episode 8, val func loss 0.2594335377216339\n",
      "\n",
      "episode 9, val func loss 0.14069442451000214\n",
      "\n",
      "episode 10, val func loss 0.7875891923904419\n",
      "\n",
      "episode 11, val func loss 0.002990125445649028\n",
      "\n",
      "episode 12, val func loss 0.3965713381767273\n",
      "\n",
      "episode 13, val func loss 0.4928073585033417\n",
      "\n",
      "episode 14, val func loss 0.4017350971698761\n",
      "\n",
      "episode 15, val func loss 0.020240051671862602\n",
      "\n",
      "episode 16, val func loss 0.14129722118377686\n",
      "\n",
      "Val func train loss in epoch 14:0.2632677267974941\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.01645055040717125\n",
      "\n",
      "episode 2, val func loss 0.24314577877521515\n",
      "\n",
      "episode 3, val func loss 0.3614403307437897\n",
      "\n",
      "episode 4, val func loss 0.5052739381790161\n",
      "\n",
      "episode 5, val func loss 0.007700716610997915\n",
      "\n",
      "episode 6, val func loss 0.13661621510982513\n",
      "\n",
      "episode 7, val func loss 0.39724716544151306\n",
      "\n",
      "episode 8, val func loss 0.26705461740493774\n",
      "\n",
      "episode 9, val func loss 0.12369035929441452\n",
      "\n",
      "episode 10, val func loss 0.006920751184225082\n",
      "\n",
      "episode 11, val func loss 0.25574570894241333\n",
      "\n",
      "episode 12, val func loss 0.14343707263469696\n",
      "\n",
      "episode 13, val func loss 0.12434760481119156\n",
      "\n",
      "episode 14, val func loss 0.3851602077484131\n",
      "\n",
      "episode 15, val func loss 0.7469453811645508\n",
      "\n",
      "episode 16, val func loss 0.39090269804000854\n",
      "\n",
      "Val func train loss in epoch 15:0.25700494353077374\n",
      "***********************TIME WAS 4.869755438963572 min*****************************\n",
      "\n",
      "**********************ROUND 87 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 6.198640767252073e-05\n",
      "\n",
      "episode 2, policy loss 0.00014062672562431544\n",
      "\n",
      "episode 3, policy loss 3.651577571872622e-05\n",
      "\n",
      "episode 4, policy loss 5.0507005653344095e-05\n",
      "\n",
      "episode 5, policy loss 0.00010105981345986947\n",
      "\n",
      "episode 6, policy loss 0.00010558918438619003\n",
      "\n",
      "episode 7, policy loss 0.00031432119430974126\n",
      "\n",
      "episode 8, policy loss 0.00033883185824379325\n",
      "\n",
      "episode 9, policy loss 0.00023758629686199129\n",
      "\n",
      "episode 10, policy loss 0.00011452057515271008\n",
      "\n",
      "episode 11, policy loss 0.00016316736582666636\n",
      "\n",
      "episode 12, policy loss 0.0005782083026133478\n",
      "\n",
      "episode 13, policy loss 0.0003171662683598697\n",
      "\n",
      "episode 14, policy loss 0.00020369343110360205\n",
      "\n",
      "episode 15, policy loss 0.00032962331897579134\n",
      "\n",
      "episode 16, policy loss 8.920038089854643e-05\n",
      "\n",
      "Policy train loss in epoch 0:0.0001989127440538141\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.00014272474800236523\n",
      "\n",
      "episode 2, policy loss 0.0001305776386288926\n",
      "\n",
      "episode 3, policy loss 0.00014108585310168564\n",
      "\n",
      "episode 4, policy loss 9.056473209057003e-05\n",
      "\n",
      "episode 5, policy loss 9.512704855296761e-05\n",
      "\n",
      "episode 6, policy loss 0.00038316103746183217\n",
      "\n",
      "episode 7, policy loss 0.0003374387160874903\n",
      "\n",
      "episode 8, policy loss 0.0003644709649961442\n",
      "\n",
      "episode 9, policy loss 9.895434777718037e-05\n",
      "\n",
      "episode 10, policy loss 0.0003438375424593687\n",
      "\n",
      "episode 11, policy loss 0.00013176427455618978\n",
      "\n",
      "episode 12, policy loss 0.0001834808790590614\n",
      "\n",
      "episode 13, policy loss 0.0002744306984823197\n",
      "\n",
      "episode 14, policy loss 0.0006204223609529436\n",
      "\n",
      "episode 15, policy loss 0.00022010489192325622\n",
      "\n",
      "episode 16, policy loss 0.00023494915512856096\n",
      "\n",
      "Policy train loss in epoch 1:0.00023706843057880178\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.00022163032554090023\n",
      "\n",
      "episode 2, policy loss 0.0002760880161076784\n",
      "\n",
      "episode 3, policy loss 9.73386486293748e-05\n",
      "\n",
      "episode 4, policy loss 0.00015390620683319867\n",
      "\n",
      "episode 5, policy loss 0.00010171263420488685\n",
      "\n",
      "episode 6, policy loss 0.00013472361024469137\n",
      "\n",
      "episode 7, policy loss 0.00034459965536370873\n",
      "\n",
      "episode 8, policy loss 0.0006236180197447538\n",
      "\n",
      "episode 9, policy loss 0.00037085177609696984\n",
      "\n",
      "episode 10, policy loss 0.0002370397123740986\n",
      "\n",
      "episode 11, policy loss 0.00015070033259689808\n",
      "\n",
      "episode 12, policy loss 0.0001404214126523584\n",
      "\n",
      "episode 13, policy loss 0.00034839045838452876\n",
      "\n",
      "episode 14, policy loss 0.0001006669772323221\n",
      "\n",
      "episode 15, policy loss 0.0003906354249920696\n",
      "\n",
      "episode 16, policy loss 0.00018738374637905508\n",
      "\n",
      "Policy train loss in epoch 2:0.00024248168483609334\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.00037141499342396855\n",
      "\n",
      "episode 2, policy loss 0.00018610944971442223\n",
      "\n",
      "episode 3, policy loss 0.00014128857583273202\n",
      "\n",
      "episode 4, policy loss 0.00022161942615639418\n",
      "\n",
      "episode 5, policy loss 0.00010186612780671567\n",
      "\n",
      "episode 6, policy loss 0.00014950612967368215\n",
      "\n",
      "episode 7, policy loss 0.00013437199231702834\n",
      "\n",
      "episode 8, policy loss 0.00039150845259428024\n",
      "\n",
      "episode 9, policy loss 0.000346849556080997\n",
      "\n",
      "episode 10, policy loss 0.0002754009619820863\n",
      "\n",
      "episode 11, policy loss 0.0002361578372074291\n",
      "\n",
      "episode 12, policy loss 0.00015391742635983974\n",
      "\n",
      "episode 13, policy loss 9.82437704806216e-05\n",
      "\n",
      "episode 14, policy loss 0.00034431705716997385\n",
      "\n",
      "episode 15, policy loss 0.0006216997862793505\n",
      "\n",
      "episode 16, policy loss 0.00010093007585965097\n",
      "\n",
      "Policy train loss in epoch 3:0.00024220010118369828\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.012724232859909534\n",
      "\n",
      "episode 2, val func loss 0.3741723895072937\n",
      "\n",
      "episode 3, val func loss 0.38551563024520874\n",
      "\n",
      "episode 4, val func loss 0.3981691598892212\n",
      "\n",
      "episode 5, val func loss 0.1449466198682785\n",
      "\n",
      "episode 6, val func loss 0.255374550819397\n",
      "\n",
      "episode 7, val func loss 0.2658338248729706\n",
      "\n",
      "episode 8, val func loss 0.24376454949378967\n",
      "\n",
      "episode 9, val func loss 0.01084198523312807\n",
      "\n",
      "episode 10, val func loss 0.26135194301605225\n",
      "\n",
      "episode 11, val func loss 0.2449025958776474\n",
      "\n",
      "episode 12, val func loss 0.1376717984676361\n",
      "\n",
      "episode 13, val func loss 0.5312877297401428\n",
      "\n",
      "episode 14, val func loss 0.13866853713989258\n",
      "\n",
      "episode 15, val func loss 0.25784578919410706\n",
      "\n",
      "episode 16, val func loss 0.25269758701324463\n",
      "\n",
      "Val func train loss in epoch 0:0.24473555770237\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.3887229561805725\n",
      "\n",
      "episode 2, val func loss 0.030457066372036934\n",
      "\n",
      "episode 3, val func loss 0.2644309103488922\n",
      "\n",
      "episode 4, val func loss 0.3768501877784729\n",
      "\n",
      "episode 5, val func loss 0.23995110392570496\n",
      "\n",
      "episode 6, val func loss 0.12880666553974152\n",
      "\n",
      "episode 7, val func loss 0.24699105322360992\n",
      "\n",
      "episode 8, val func loss 0.28106582164764404\n",
      "\n",
      "episode 9, val func loss 0.25406762957572937\n",
      "\n",
      "episode 10, val func loss 0.508060872554779\n",
      "\n",
      "episode 11, val func loss 0.14246496558189392\n",
      "\n",
      "episode 12, val func loss 0.20983874797821045\n",
      "\n",
      "episode 13, val func loss 0.2719692885875702\n",
      "\n",
      "episode 14, val func loss 0.025917667895555496\n",
      "\n",
      "episode 15, val func loss 0.1349322646856308\n",
      "\n",
      "episode 16, val func loss 0.36505207419395447\n",
      "\n",
      "Val func train loss in epoch 1:0.24184870475437492\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.2553395926952362\n",
      "\n",
      "episode 2, val func loss 0.2548430860042572\n",
      "\n",
      "episode 3, val func loss 0.01384279690682888\n",
      "\n",
      "episode 4, val func loss 0.39169904589653015\n",
      "\n",
      "episode 5, val func loss 0.5063241124153137\n",
      "\n",
      "episode 6, val func loss 0.012884137220680714\n",
      "\n",
      "episode 7, val func loss 0.2649027705192566\n",
      "\n",
      "episode 8, val func loss 0.2701568007469177\n",
      "\n",
      "episode 9, val func loss 0.14295434951782227\n",
      "\n",
      "episode 10, val func loss 0.2517736852169037\n",
      "\n",
      "episode 11, val func loss 0.25774946808815\n",
      "\n",
      "episode 12, val func loss 0.13407818973064423\n",
      "\n",
      "episode 13, val func loss 0.2701302170753479\n",
      "\n",
      "episode 14, val func loss 0.13354773819446564\n",
      "\n",
      "episode 15, val func loss 0.3789043426513672\n",
      "\n",
      "episode 16, val func loss 0.3849125802516937\n",
      "\n",
      "Val func train loss in epoch 2:0.2452526820707135\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.38012075424194336\n",
      "\n",
      "episode 2, val func loss 0.1327008157968521\n",
      "\n",
      "episode 3, val func loss 0.39263373613357544\n",
      "\n",
      "episode 4, val func loss 0.024199260398745537\n",
      "\n",
      "episode 5, val func loss 0.13403183221817017\n",
      "\n",
      "episode 6, val func loss 0.2706378400325775\n",
      "\n",
      "episode 7, val func loss 0.2774258852005005\n",
      "\n",
      "episode 8, val func loss 0.41790157556533813\n",
      "\n",
      "episode 9, val func loss 0.005184046924114227\n",
      "\n",
      "episode 10, val func loss 0.13169777393341064\n",
      "\n",
      "episode 11, val func loss 0.5365442633628845\n",
      "\n",
      "episode 12, val func loss 0.24807855486869812\n",
      "\n",
      "episode 13, val func loss 0.26170825958251953\n",
      "\n",
      "episode 14, val func loss 0.2613353729248047\n",
      "\n",
      "episode 15, val func loss 0.25765976309776306\n",
      "\n",
      "episode 16, val func loss 0.26507505774497986\n",
      "\n",
      "Val func train loss in epoch 3:0.24980842450167984\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.39208316802978516\n",
      "\n",
      "episode 2, val func loss 0.4023646116256714\n",
      "\n",
      "episode 3, val func loss 0.513921856880188\n",
      "\n",
      "episode 4, val func loss 0.2585717439651489\n",
      "\n",
      "episode 5, val func loss 0.13497555255889893\n",
      "\n",
      "episode 6, val func loss 0.26487261056900024\n",
      "\n",
      "episode 7, val func loss 0.0095739234238863\n",
      "\n",
      "episode 8, val func loss 0.4018533229827881\n",
      "\n",
      "episode 9, val func loss 0.25507089495658875\n",
      "\n",
      "episode 10, val func loss 0.2612573504447937\n",
      "\n",
      "episode 11, val func loss 0.2546996474266052\n",
      "\n",
      "episode 12, val func loss 0.25492361187934875\n",
      "\n",
      "episode 13, val func loss 0.13332195580005646\n",
      "\n",
      "episode 14, val func loss 0.13607093691825867\n",
      "\n",
      "episode 15, val func loss 0.26086869835853577\n",
      "\n",
      "episode 16, val func loss 0.013960801996290684\n",
      "\n",
      "Val func train loss in epoch 4:0.2467744179884903\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.008256696164608002\n",
      "\n",
      "episode 2, val func loss 0.2611277401447296\n",
      "\n",
      "episode 3, val func loss 0.0073013221845030785\n",
      "\n",
      "episode 4, val func loss 0.26571914553642273\n",
      "\n",
      "episode 5, val func loss 0.3898965120315552\n",
      "\n",
      "episode 6, val func loss 0.2604282796382904\n",
      "\n",
      "episode 7, val func loss 0.2559140920639038\n",
      "\n",
      "episode 8, val func loss 0.13105660676956177\n",
      "\n",
      "episode 9, val func loss 0.39765146374702454\n",
      "\n",
      "episode 10, val func loss 0.24554234743118286\n",
      "\n",
      "episode 11, val func loss 0.5038951635360718\n",
      "\n",
      "episode 12, val func loss 0.38184282183647156\n",
      "\n",
      "episode 13, val func loss 0.2516210973262787\n",
      "\n",
      "episode 14, val func loss 0.13133852183818817\n",
      "\n",
      "episode 15, val func loss 0.2491430938243866\n",
      "\n",
      "episode 16, val func loss 0.14542248845100403\n",
      "\n",
      "Val func train loss in epoch 5:0.24288483703276142\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.505731463432312\n",
      "\n",
      "episode 2, val func loss 0.2606744170188904\n",
      "\n",
      "episode 3, val func loss 0.36916765570640564\n",
      "\n",
      "episode 4, val func loss 0.13490568101406097\n",
      "\n",
      "episode 5, val func loss 0.3798806667327881\n",
      "\n",
      "episode 6, val func loss 0.3657795786857605\n",
      "\n",
      "episode 7, val func loss 0.2697537839412689\n",
      "\n",
      "episode 8, val func loss 0.03176409751176834\n",
      "\n",
      "episode 9, val func loss 0.2838231027126312\n",
      "\n",
      "episode 10, val func loss 0.257120281457901\n",
      "\n",
      "episode 11, val func loss 0.009368674829602242\n",
      "\n",
      "episode 12, val func loss 0.26976507902145386\n",
      "\n",
      "episode 13, val func loss 0.2403033971786499\n",
      "\n",
      "episode 14, val func loss 0.13909263908863068\n",
      "\n",
      "episode 15, val func loss 0.12655910849571228\n",
      "\n",
      "episode 16, val func loss 0.2342880517244339\n",
      "\n",
      "Val func train loss in epoch 6:0.24237360490951687\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.1361757218837738\n",
      "\n",
      "episode 2, val func loss 0.26207321882247925\n",
      "\n",
      "episode 3, val func loss 0.13531963527202606\n",
      "\n",
      "episode 4, val func loss 0.4888765215873718\n",
      "\n",
      "episode 5, val func loss 0.38222330808639526\n",
      "\n",
      "episode 6, val func loss 0.1297483742237091\n",
      "\n",
      "episode 7, val func loss 0.3792710304260254\n",
      "\n",
      "episode 8, val func loss 0.27022817730903625\n",
      "\n",
      "episode 9, val func loss 0.01583101600408554\n",
      "\n",
      "episode 10, val func loss 0.24868285655975342\n",
      "\n",
      "episode 11, val func loss 0.25322210788726807\n",
      "\n",
      "episode 12, val func loss 0.38627684116363525\n",
      "\n",
      "episode 13, val func loss 0.2666250467300415\n",
      "\n",
      "episode 14, val func loss 0.2610762417316437\n",
      "\n",
      "episode 15, val func loss 0.2554416358470917\n",
      "\n",
      "episode 16, val func loss 0.016251392662525177\n",
      "\n",
      "Val func train loss in epoch 7:0.24295769538730383\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.2628505229949951\n",
      "\n",
      "episode 2, val func loss 0.39743101596832275\n",
      "\n",
      "episode 3, val func loss 0.1358528584241867\n",
      "\n",
      "episode 4, val func loss 0.14342047274112701\n",
      "\n",
      "episode 5, val func loss 0.14004363119602203\n",
      "\n",
      "episode 6, val func loss 0.2617979645729065\n",
      "\n",
      "episode 7, val func loss 0.008052004501223564\n",
      "\n",
      "episode 8, val func loss 0.25357046723365784\n",
      "\n",
      "episode 9, val func loss 0.4029664993286133\n",
      "\n",
      "episode 10, val func loss 0.2737215757369995\n",
      "\n",
      "episode 11, val func loss 0.4004354178905487\n",
      "\n",
      "episode 12, val func loss 0.5086874961853027\n",
      "\n",
      "episode 13, val func loss 0.2661243975162506\n",
      "\n",
      "episode 14, val func loss 0.033923450857400894\n",
      "\n",
      "episode 15, val func loss 0.2672920525074005\n",
      "\n",
      "episode 16, val func loss 0.2549876272678375\n",
      "\n",
      "Val func train loss in epoch 8:0.2506973409326747\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.13430887460708618\n",
      "\n",
      "episode 2, val func loss 0.003113585989922285\n",
      "\n",
      "episode 3, val func loss 0.4069312512874603\n",
      "\n",
      "episode 4, val func loss 0.001392480218783021\n",
      "\n",
      "episode 5, val func loss 0.13538524508476257\n",
      "\n",
      "episode 6, val func loss 0.5395339131355286\n",
      "\n",
      "episode 7, val func loss 0.26917707920074463\n",
      "\n",
      "episode 8, val func loss 0.3780936896800995\n",
      "\n",
      "episode 9, val func loss 0.2689969539642334\n",
      "\n",
      "episode 10, val func loss 0.2750898599624634\n",
      "\n",
      "episode 11, val func loss 0.39711683988571167\n",
      "\n",
      "episode 12, val func loss 0.26539331674575806\n",
      "\n",
      "episode 13, val func loss 0.2574402689933777\n",
      "\n",
      "episode 14, val func loss 0.2605074346065521\n",
      "\n",
      "episode 15, val func loss 0.13631966710090637\n",
      "\n",
      "episode 16, val func loss 0.2543960213661194\n",
      "\n",
      "Val func train loss in epoch 9:0.24894978011434432\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.25205424427986145\n",
      "\n",
      "episode 2, val func loss 0.25768333673477173\n",
      "\n",
      "episode 3, val func loss 0.26008179783821106\n",
      "\n",
      "episode 4, val func loss 0.2639801502227783\n",
      "\n",
      "episode 5, val func loss 0.25479936599731445\n",
      "\n",
      "episode 6, val func loss 0.13866564631462097\n",
      "\n",
      "episode 7, val func loss 0.37714606523513794\n",
      "\n",
      "episode 8, val func loss 0.23704075813293457\n",
      "\n",
      "episode 9, val func loss 0.48078134655952454\n",
      "\n",
      "episode 10, val func loss 0.2590402662754059\n",
      "\n",
      "episode 11, val func loss 0.3927651643753052\n",
      "\n",
      "episode 12, val func loss 0.037969086319208145\n",
      "\n",
      "episode 13, val func loss 0.13923954963684082\n",
      "\n",
      "episode 14, val func loss 0.02619115449488163\n",
      "\n",
      "episode 15, val func loss 0.4156128168106079\n",
      "\n",
      "episode 16, val func loss 0.1388212889432907\n",
      "\n",
      "Val func train loss in epoch 10:0.24574200238566846\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.26379624009132385\n",
      "\n",
      "episode 2, val func loss 0.13527116179466248\n",
      "\n",
      "episode 3, val func loss 0.010542303323745728\n",
      "\n",
      "episode 4, val func loss 0.399485319852829\n",
      "\n",
      "episode 5, val func loss 0.40776410698890686\n",
      "\n",
      "episode 6, val func loss 0.26467645168304443\n",
      "\n",
      "episode 7, val func loss 0.2704022228717804\n",
      "\n",
      "episode 8, val func loss 0.39409348368644714\n",
      "\n",
      "episode 9, val func loss 0.25858408212661743\n",
      "\n",
      "episode 10, val func loss 0.13700361549854279\n",
      "\n",
      "episode 11, val func loss 0.009694939479231834\n",
      "\n",
      "episode 12, val func loss 0.25793394446372986\n",
      "\n",
      "episode 13, val func loss 0.13688896596431732\n",
      "\n",
      "episode 14, val func loss 0.2704228162765503\n",
      "\n",
      "episode 15, val func loss 0.5242230296134949\n",
      "\n",
      "episode 16, val func loss 0.2600318193435669\n",
      "\n",
      "Val func train loss in epoch 11:0.25005090644117445\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.396045446395874\n",
      "\n",
      "episode 2, val func loss 0.3932439684867859\n",
      "\n",
      "episode 3, val func loss 0.01263679750263691\n",
      "\n",
      "episode 4, val func loss 0.2629181146621704\n",
      "\n",
      "episode 5, val func loss 0.5162136554718018\n",
      "\n",
      "episode 6, val func loss 0.2554939091205597\n",
      "\n",
      "episode 7, val func loss 0.13621200621128082\n",
      "\n",
      "episode 8, val func loss 0.2623080015182495\n",
      "\n",
      "episode 9, val func loss 0.2658631205558777\n",
      "\n",
      "episode 10, val func loss 0.0089190062135458\n",
      "\n",
      "episode 11, val func loss 0.37174317240715027\n",
      "\n",
      "episode 12, val func loss 0.13000984489917755\n",
      "\n",
      "episode 13, val func loss 0.25898006558418274\n",
      "\n",
      "episode 14, val func loss 0.13764774799346924\n",
      "\n",
      "episode 15, val func loss 0.23773601651191711\n",
      "\n",
      "episode 16, val func loss 0.2505608797073364\n",
      "\n",
      "Val func train loss in epoch 12:0.243533234577626\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.2622205913066864\n",
      "\n",
      "episode 2, val func loss 0.015775790438055992\n",
      "\n",
      "episode 3, val func loss 0.00909509789198637\n",
      "\n",
      "episode 4, val func loss 0.12980729341506958\n",
      "\n",
      "episode 5, val func loss 0.2942250072956085\n",
      "\n",
      "episode 6, val func loss 0.2725767195224762\n",
      "\n",
      "episode 7, val func loss 0.2669183015823364\n",
      "\n",
      "episode 8, val func loss 0.2529553174972534\n",
      "\n",
      "episode 9, val func loss 0.2640950083732605\n",
      "\n",
      "episode 10, val func loss 0.504019558429718\n",
      "\n",
      "episode 11, val func loss 0.14696094393730164\n",
      "\n",
      "episode 12, val func loss 0.2717961072921753\n",
      "\n",
      "episode 13, val func loss 0.3835526704788208\n",
      "\n",
      "episode 14, val func loss 0.4010600745677948\n",
      "\n",
      "episode 15, val func loss 0.13772456347942352\n",
      "\n",
      "episode 16, val func loss 0.3882180154323578\n",
      "\n",
      "Val func train loss in epoch 13:0.25006256630877033\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.008016939274966717\n",
      "\n",
      "episode 2, val func loss 0.1404792219400406\n",
      "\n",
      "episode 3, val func loss 0.26862797141075134\n",
      "\n",
      "episode 4, val func loss 0.26413384079933167\n",
      "\n",
      "episode 5, val func loss 0.006393084302544594\n",
      "\n",
      "episode 6, val func loss 0.2632305920124054\n",
      "\n",
      "episode 7, val func loss 0.39197397232055664\n",
      "\n",
      "episode 8, val func loss 0.1269296556711197\n",
      "\n",
      "episode 9, val func loss 0.1244095042347908\n",
      "\n",
      "episode 10, val func loss 0.24422131478786469\n",
      "\n",
      "episode 11, val func loss 0.267117977142334\n",
      "\n",
      "episode 12, val func loss 0.5103395581245422\n",
      "\n",
      "episode 13, val func loss 0.25483211874961853\n",
      "\n",
      "episode 14, val func loss 0.38625046610832214\n",
      "\n",
      "episode 15, val func loss 0.38957804441452026\n",
      "\n",
      "episode 16, val func loss 0.2656475603580475\n",
      "\n",
      "Val func train loss in epoch 14:0.2445113638532348\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.27197667956352234\n",
      "\n",
      "episode 2, val func loss 0.13238514959812164\n",
      "\n",
      "episode 3, val func loss 0.37842419743537903\n",
      "\n",
      "episode 4, val func loss 0.26037314534187317\n",
      "\n",
      "episode 5, val func loss 0.007308917120099068\n",
      "\n",
      "episode 6, val func loss 0.005361159797757864\n",
      "\n",
      "episode 7, val func loss 0.40117940306663513\n",
      "\n",
      "episode 8, val func loss 0.13643057644367218\n",
      "\n",
      "episode 9, val func loss 0.2709852457046509\n",
      "\n",
      "episode 10, val func loss 0.26663950085639954\n",
      "\n",
      "episode 11, val func loss 0.13304480910301208\n",
      "\n",
      "episode 12, val func loss 0.2697910964488983\n",
      "\n",
      "episode 13, val func loss 0.38576990365982056\n",
      "\n",
      "episode 14, val func loss 0.26141518354415894\n",
      "\n",
      "episode 15, val func loss 0.2682853937149048\n",
      "\n",
      "episode 16, val func loss 0.48936018347740173\n",
      "\n",
      "Val func train loss in epoch 15:0.2461706590547692\n",
      "***********************TIME WAS 4.869157898426056 min*****************************\n",
      "\n",
      "**********************ROUND 88 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.05380348488688469\n",
      "\n",
      "episode 2, policy loss 0.04856576770544052\n",
      "\n",
      "episode 3, policy loss 0.015516523271799088\n",
      "\n",
      "episode 4, policy loss 0.046254586428403854\n",
      "\n",
      "episode 5, policy loss 0.04356418550014496\n",
      "\n",
      "episode 6, policy loss 0.046882934868335724\n",
      "\n",
      "episode 7, policy loss 0.06011594831943512\n",
      "\n",
      "episode 8, policy loss 0.06252958625555038\n",
      "\n",
      "episode 9, policy loss 0.05349842086434364\n",
      "\n",
      "episode 10, policy loss 0.050387922674417496\n",
      "\n",
      "episode 11, policy loss 0.052835192531347275\n",
      "\n",
      "episode 12, policy loss 0.02818423882126808\n",
      "\n",
      "episode 13, policy loss 0.007417221553623676\n",
      "\n",
      "episode 14, policy loss 0.04954471066594124\n",
      "\n",
      "episode 15, policy loss 0.02204911783337593\n",
      "\n",
      "episode 16, policy loss 0.031808532774448395\n",
      "\n",
      "Policy train loss in epoch 0:0.042059898434672505\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.004139997996389866\n",
      "\n",
      "episode 2, policy loss 0.047582484781742096\n",
      "\n",
      "episode 3, policy loss 0.05399392172694206\n",
      "\n",
      "episode 4, policy loss 0.02169741876423359\n",
      "\n",
      "episode 5, policy loss 0.05208400636911392\n",
      "\n",
      "episode 6, policy loss 0.05032845586538315\n",
      "\n",
      "episode 7, policy loss 0.03053772822022438\n",
      "\n",
      "episode 8, policy loss 0.028139090165495872\n",
      "\n",
      "episode 9, policy loss 0.052485112100839615\n",
      "\n",
      "episode 10, policy loss 0.059663597494363785\n",
      "\n",
      "episode 11, policy loss 0.06168871372938156\n",
      "\n",
      "episode 12, policy loss 0.04530274495482445\n",
      "\n",
      "episode 13, policy loss 0.0062359957955777645\n",
      "\n",
      "episode 14, policy loss 0.04281787946820259\n",
      "\n",
      "episode 15, policy loss 0.0466914065182209\n",
      "\n",
      "episode 16, policy loss 0.04803815856575966\n",
      "\n",
      "Policy train loss in epoch 1:0.040714169532293454\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.027568871155381203\n",
      "\n",
      "episode 2, policy loss 0.05238310247659683\n",
      "\n",
      "episode 3, policy loss 0.04620027542114258\n",
      "\n",
      "episode 4, policy loss 0.04878697171807289\n",
      "\n",
      "episode 5, policy loss 0.05163087323307991\n",
      "\n",
      "episode 6, policy loss 0.002713472582399845\n",
      "\n",
      "episode 7, policy loss 0.05232381075620651\n",
      "\n",
      "episode 8, policy loss 0.06105273589491844\n",
      "\n",
      "episode 9, policy loss 0.029151679947972298\n",
      "\n",
      "episode 10, policy loss 0.057621657848358154\n",
      "\n",
      "episode 11, policy loss 0.005293737631291151\n",
      "\n",
      "episode 12, policy loss 0.04382354021072388\n",
      "\n",
      "episode 13, policy loss 0.04499613121151924\n",
      "\n",
      "episode 14, policy loss 0.040489695966243744\n",
      "\n",
      "episode 15, policy loss 0.044224563986063004\n",
      "\n",
      "episode 16, policy loss 0.017984110862016678\n",
      "\n",
      "Policy train loss in epoch 2:0.03914032693137415\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.023625781759619713\n",
      "\n",
      "episode 2, policy loss 0.05436381325125694\n",
      "\n",
      "episode 3, policy loss 0.0034204490948468447\n",
      "\n",
      "episode 4, policy loss 0.0272351261228323\n",
      "\n",
      "episode 5, policy loss 0.04170979559421539\n",
      "\n",
      "episode 6, policy loss 0.048519544303417206\n",
      "\n",
      "episode 7, policy loss 0.04790906235575676\n",
      "\n",
      "episode 8, policy loss 0.05626125633716583\n",
      "\n",
      "episode 9, policy loss 0.04306739196181297\n",
      "\n",
      "episode 10, policy loss 0.0420563630759716\n",
      "\n",
      "episode 11, policy loss 0.04617379605770111\n",
      "\n",
      "episode 12, policy loss 0.04805019497871399\n",
      "\n",
      "episode 13, policy loss -0.0029062770772725344\n",
      "\n",
      "episode 14, policy loss 0.01759236305952072\n",
      "\n",
      "episode 15, policy loss 0.04375379532575607\n",
      "\n",
      "episode 16, policy loss 0.03969605639576912\n",
      "\n",
      "Policy train loss in epoch 3:0.03628303203731775\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.19216591119766235\n",
      "\n",
      "episode 2, val func loss 0.1404351443052292\n",
      "\n",
      "episode 3, val func loss 0.5411155223846436\n",
      "\n",
      "episode 4, val func loss 0.15585796535015106\n",
      "\n",
      "episode 5, val func loss 0.41536974906921387\n",
      "\n",
      "episode 6, val func loss 0.27680808305740356\n",
      "\n",
      "episode 7, val func loss 0.15608283877372742\n",
      "\n",
      "episode 8, val func loss 0.1480751484632492\n",
      "\n",
      "episode 9, val func loss 0.40788719058036804\n",
      "\n",
      "episode 10, val func loss 0.27018657326698303\n",
      "\n",
      "episode 11, val func loss 0.003192789852619171\n",
      "\n",
      "episode 12, val func loss 0.26642945408821106\n",
      "\n",
      "episode 13, val func loss 0.5518655180931091\n",
      "\n",
      "episode 14, val func loss 0.269655704498291\n",
      "\n",
      "episode 15, val func loss 0.657649576663971\n",
      "\n",
      "episode 16, val func loss 0.4022849202156067\n",
      "\n",
      "Val func train loss in epoch 0:0.30344138061627746\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.41187918186187744\n",
      "\n",
      "episode 2, val func loss 0.2890942394733429\n",
      "\n",
      "episode 3, val func loss 0.2732752859592438\n",
      "\n",
      "episode 4, val func loss 0.13372601568698883\n",
      "\n",
      "episode 5, val func loss 0.134081169962883\n",
      "\n",
      "episode 6, val func loss 0.14092743396759033\n",
      "\n",
      "episode 7, val func loss 0.14721477031707764\n",
      "\n",
      "episode 8, val func loss 0.006766067817807198\n",
      "\n",
      "episode 9, val func loss 0.27557092905044556\n",
      "\n",
      "episode 10, val func loss 0.40617433190345764\n",
      "\n",
      "episode 11, val func loss 0.40252599120140076\n",
      "\n",
      "episode 12, val func loss 0.26775267720222473\n",
      "\n",
      "episode 13, val func loss 0.6559842824935913\n",
      "\n",
      "episode 14, val func loss 0.5391813516616821\n",
      "\n",
      "episode 15, val func loss 0.1439405083656311\n",
      "\n",
      "episode 16, val func loss 0.5325961709022522\n",
      "\n",
      "Val func train loss in epoch 1:0.29754315048921853\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.3973594307899475\n",
      "\n",
      "episode 2, val func loss 0.13934019207954407\n",
      "\n",
      "episode 3, val func loss 0.13563138246536255\n",
      "\n",
      "episode 4, val func loss 0.518879771232605\n",
      "\n",
      "episode 5, val func loss 0.27280089259147644\n",
      "\n",
      "episode 6, val func loss 0.12931053340435028\n",
      "\n",
      "episode 7, val func loss 0.1343967765569687\n",
      "\n",
      "episode 8, val func loss 0.13909369707107544\n",
      "\n",
      "episode 9, val func loss 0.2701977789402008\n",
      "\n",
      "episode 10, val func loss 0.6533476710319519\n",
      "\n",
      "episode 11, val func loss 0.27429646253585815\n",
      "\n",
      "episode 12, val func loss 0.5290648937225342\n",
      "\n",
      "episode 13, val func loss 0.2748141884803772\n",
      "\n",
      "episode 14, val func loss 0.3868797719478607\n",
      "\n",
      "episode 15, val func loss 0.3900642395019531\n",
      "\n",
      "episode 16, val func loss 0.010845047421753407\n",
      "\n",
      "Val func train loss in epoch 2:0.2910201706108637\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.139882892370224\n",
      "\n",
      "episode 2, val func loss 0.12319286167621613\n",
      "\n",
      "episode 3, val func loss 0.26975855231285095\n",
      "\n",
      "episode 4, val func loss 0.40667447447776794\n",
      "\n",
      "episode 5, val func loss 0.5258186459541321\n",
      "\n",
      "episode 6, val func loss 0.6443463563919067\n",
      "\n",
      "episode 7, val func loss 0.39417994022369385\n",
      "\n",
      "episode 8, val func loss 0.2777160406112671\n",
      "\n",
      "episode 9, val func loss 0.1570812612771988\n",
      "\n",
      "episode 10, val func loss 0.2647516131401062\n",
      "\n",
      "episode 11, val func loss 0.12868604063987732\n",
      "\n",
      "episode 12, val func loss 0.412555456161499\n",
      "\n",
      "episode 13, val func loss 0.27611055970191956\n",
      "\n",
      "episode 14, val func loss 0.007451185956597328\n",
      "\n",
      "episode 15, val func loss 0.5261965990066528\n",
      "\n",
      "episode 16, val func loss 0.14486822485923767\n",
      "\n",
      "Val func train loss in epoch 3:0.2937044190475717\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.26413968205451965\n",
      "\n",
      "episode 2, val func loss 0.2690552771091461\n",
      "\n",
      "episode 3, val func loss 0.39230263233184814\n",
      "\n",
      "episode 4, val func loss 0.40116244554519653\n",
      "\n",
      "episode 5, val func loss 0.5299591422080994\n",
      "\n",
      "episode 6, val func loss 0.13508889079093933\n",
      "\n",
      "episode 7, val func loss 0.5264084935188293\n",
      "\n",
      "episode 8, val func loss 0.1350202113389969\n",
      "\n",
      "episode 9, val func loss 0.25932660698890686\n",
      "\n",
      "episode 10, val func loss 0.13866671919822693\n",
      "\n",
      "episode 11, val func loss 0.3982756435871124\n",
      "\n",
      "episode 12, val func loss 0.12409909069538116\n",
      "\n",
      "episode 13, val func loss 0.2726568877696991\n",
      "\n",
      "episode 14, val func loss 0.005926901940256357\n",
      "\n",
      "episode 15, val func loss 0.12398830056190491\n",
      "\n",
      "episode 16, val func loss 0.6732969880104065\n",
      "\n",
      "Val func train loss in epoch 4:0.29058586960309185\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.5172619223594666\n",
      "\n",
      "episode 2, val func loss 0.25933998823165894\n",
      "\n",
      "episode 3, val func loss 0.3997563123703003\n",
      "\n",
      "episode 4, val func loss 0.14433437585830688\n",
      "\n",
      "episode 5, val func loss 0.13557681441307068\n",
      "\n",
      "episode 6, val func loss 0.3799050748348236\n",
      "\n",
      "episode 7, val func loss 0.5181505680084229\n",
      "\n",
      "episode 8, val func loss 0.2673250436782837\n",
      "\n",
      "episode 9, val func loss 0.007217465899884701\n",
      "\n",
      "episode 10, val func loss 0.2659928798675537\n",
      "\n",
      "episode 11, val func loss 0.1446741819381714\n",
      "\n",
      "episode 12, val func loss 0.13257141411304474\n",
      "\n",
      "episode 13, val func loss 0.2702779173851013\n",
      "\n",
      "episode 14, val func loss 0.1244901567697525\n",
      "\n",
      "episode 15, val func loss 0.6518895626068115\n",
      "\n",
      "episode 16, val func loss 0.40838536620140076\n",
      "\n",
      "Val func train loss in epoch 5:0.2891968152835034\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.14520998299121857\n",
      "\n",
      "episode 2, val func loss 0.2555609941482544\n",
      "\n",
      "episode 3, val func loss 0.010834470391273499\n",
      "\n",
      "episode 4, val func loss 0.13234438002109528\n",
      "\n",
      "episode 5, val func loss 0.1385589987039566\n",
      "\n",
      "episode 6, val func loss 0.13819271326065063\n",
      "\n",
      "episode 7, val func loss 0.4035281240940094\n",
      "\n",
      "episode 8, val func loss 0.2736826539039612\n",
      "\n",
      "episode 9, val func loss 0.3974837362766266\n",
      "\n",
      "episode 10, val func loss 0.2726908028125763\n",
      "\n",
      "episode 11, val func loss 0.5392929911613464\n",
      "\n",
      "episode 12, val func loss 0.40804821252822876\n",
      "\n",
      "episode 13, val func loss 0.13555459678173065\n",
      "\n",
      "episode 14, val func loss 0.659267008304596\n",
      "\n",
      "episode 15, val func loss 0.26984384655952454\n",
      "\n",
      "episode 16, val func loss 0.5228925347328186\n",
      "\n",
      "Val func train loss in epoch 6:0.2939366279169917\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.004559028428047895\n",
      "\n",
      "episode 2, val func loss 0.6557336449623108\n",
      "\n",
      "episode 3, val func loss 0.2735380232334137\n",
      "\n",
      "episode 4, val func loss 0.12807847559452057\n",
      "\n",
      "episode 5, val func loss 0.26888492703437805\n",
      "\n",
      "episode 6, val func loss 0.14198236167430878\n",
      "\n",
      "episode 7, val func loss 0.5359162092208862\n",
      "\n",
      "episode 8, val func loss 0.5396907925605774\n",
      "\n",
      "episode 9, val func loss 0.13907012343406677\n",
      "\n",
      "episode 10, val func loss 0.25375935435295105\n",
      "\n",
      "episode 11, val func loss 0.3684372007846832\n",
      "\n",
      "episode 12, val func loss 0.14008449018001556\n",
      "\n",
      "episode 13, val func loss 0.37949705123901367\n",
      "\n",
      "episode 14, val func loss 0.26892393827438354\n",
      "\n",
      "episode 15, val func loss 0.3948608934879303\n",
      "\n",
      "episode 16, val func loss 0.14078301191329956\n",
      "\n",
      "Val func train loss in epoch 7:0.2896124703984242\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6578412055969238\n",
      "\n",
      "episode 2, val func loss 0.39331093430519104\n",
      "\n",
      "episode 3, val func loss 0.1412876695394516\n",
      "\n",
      "episode 4, val func loss 0.40089502930641174\n",
      "\n",
      "episode 5, val func loss 0.13497024774551392\n",
      "\n",
      "episode 6, val func loss 0.5196093320846558\n",
      "\n",
      "episode 7, val func loss 0.26760897040367126\n",
      "\n",
      "episode 8, val func loss 0.3694910407066345\n",
      "\n",
      "episode 9, val func loss 0.1320985108613968\n",
      "\n",
      "episode 10, val func loss 0.14910294115543365\n",
      "\n",
      "episode 11, val func loss 0.2590276598930359\n",
      "\n",
      "episode 12, val func loss 0.5173868536949158\n",
      "\n",
      "episode 13, val func loss 0.2767069935798645\n",
      "\n",
      "episode 14, val func loss 0.13712306320667267\n",
      "\n",
      "episode 15, val func loss 0.014865834265947342\n",
      "\n",
      "episode 16, val func loss 0.2654082775115967\n",
      "\n",
      "Val func train loss in epoch 8:0.2897959102410823\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.14387273788452148\n",
      "\n",
      "episode 2, val func loss 0.3989660143852234\n",
      "\n",
      "episode 3, val func loss 0.1382550448179245\n",
      "\n",
      "episode 4, val func loss 0.13762454688549042\n",
      "\n",
      "episode 5, val func loss 0.2562820613384247\n",
      "\n",
      "episode 6, val func loss 0.26148948073387146\n",
      "\n",
      "episode 7, val func loss 0.004725931212306023\n",
      "\n",
      "episode 8, val func loss 0.6686841249465942\n",
      "\n",
      "episode 9, val func loss 0.5215412974357605\n",
      "\n",
      "episode 10, val func loss 0.13537609577178955\n",
      "\n",
      "episode 11, val func loss 0.25208714604377747\n",
      "\n",
      "episode 12, val func loss 0.13610467314720154\n",
      "\n",
      "episode 13, val func loss 0.4121711552143097\n",
      "\n",
      "episode 14, val func loss 0.26757821440696716\n",
      "\n",
      "episode 15, val func loss 0.3954649567604065\n",
      "\n",
      "episode 16, val func loss 0.5359957814216614\n",
      "\n",
      "Val func train loss in epoch 9:0.2916387039003894\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.25013670325279236\n",
      "\n",
      "episode 2, val func loss 0.6596315503120422\n",
      "\n",
      "episode 3, val func loss 0.1369927078485489\n",
      "\n",
      "episode 4, val func loss 0.40994206070899963\n",
      "\n",
      "episode 5, val func loss 0.1332608163356781\n",
      "\n",
      "episode 6, val func loss 0.2756519317626953\n",
      "\n",
      "episode 7, val func loss 0.39837631583213806\n",
      "\n",
      "episode 8, val func loss 0.005636434070765972\n",
      "\n",
      "episode 9, val func loss 0.5350214242935181\n",
      "\n",
      "episode 10, val func loss 0.28212499618530273\n",
      "\n",
      "episode 11, val func loss 0.27367904782295227\n",
      "\n",
      "episode 12, val func loss 0.525611162185669\n",
      "\n",
      "episode 13, val func loss 0.13965144753456116\n",
      "\n",
      "episode 14, val func loss 0.4067273736000061\n",
      "\n",
      "episode 15, val func loss 0.13666503131389618\n",
      "\n",
      "episode 16, val func loss 0.13622809946537018\n",
      "\n",
      "Val func train loss in epoch 10:0.2940835689078085\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.1354791820049286\n",
      "\n",
      "episode 2, val func loss 0.5302022099494934\n",
      "\n",
      "episode 3, val func loss 0.6672695279121399\n",
      "\n",
      "episode 4, val func loss 0.00904071144759655\n",
      "\n",
      "episode 5, val func loss 0.26117077469825745\n",
      "\n",
      "episode 6, val func loss 0.27345436811447144\n",
      "\n",
      "episode 7, val func loss 0.40301239490509033\n",
      "\n",
      "episode 8, val func loss 0.5371305346488953\n",
      "\n",
      "episode 9, val func loss 0.13614952564239502\n",
      "\n",
      "episode 10, val func loss 0.2688380777835846\n",
      "\n",
      "episode 11, val func loss 0.13679885864257812\n",
      "\n",
      "episode 12, val func loss 0.12971006333827972\n",
      "\n",
      "episode 13, val func loss 0.13763850927352905\n",
      "\n",
      "episode 14, val func loss 0.39907771348953247\n",
      "\n",
      "episode 15, val func loss 0.2657736837863922\n",
      "\n",
      "episode 16, val func loss 0.3864857852458954\n",
      "\n",
      "Val func train loss in epoch 11:0.2923269950551912\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.26634714007377625\n",
      "\n",
      "episode 2, val func loss 0.6628822088241577\n",
      "\n",
      "episode 3, val func loss 0.012728193774819374\n",
      "\n",
      "episode 4, val func loss 0.24943387508392334\n",
      "\n",
      "episode 5, val func loss 0.2678900361061096\n",
      "\n",
      "episode 6, val func loss 0.12945491075515747\n",
      "\n",
      "episode 7, val func loss 0.253082275390625\n",
      "\n",
      "episode 8, val func loss 0.13278040289878845\n",
      "\n",
      "episode 9, val func loss 0.1364070624113083\n",
      "\n",
      "episode 10, val func loss 0.5055357813835144\n",
      "\n",
      "episode 11, val func loss 0.5057727098464966\n",
      "\n",
      "episode 12, val func loss 0.39638403058052063\n",
      "\n",
      "episode 13, val func loss 0.1367630511522293\n",
      "\n",
      "episode 14, val func loss 0.38810938596725464\n",
      "\n",
      "episode 15, val func loss 0.1497194916009903\n",
      "\n",
      "episode 16, val func loss 0.41158533096313477\n",
      "\n",
      "Val func train loss in epoch 12:0.2878047429258004\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.15204724669456482\n",
      "\n",
      "episode 2, val func loss 0.3883202373981476\n",
      "\n",
      "episode 3, val func loss 0.14818082749843597\n",
      "\n",
      "episode 4, val func loss 0.1437346488237381\n",
      "\n",
      "episode 5, val func loss 0.26876673102378845\n",
      "\n",
      "episode 6, val func loss 0.26262548565864563\n",
      "\n",
      "episode 7, val func loss 0.4105699062347412\n",
      "\n",
      "episode 8, val func loss 0.5296269655227661\n",
      "\n",
      "episode 9, val func loss 0.6712038516998291\n",
      "\n",
      "episode 10, val func loss 0.13650715351104736\n",
      "\n",
      "episode 11, val func loss 0.2744026482105255\n",
      "\n",
      "episode 12, val func loss 0.13513822853565216\n",
      "\n",
      "episode 13, val func loss 0.527718186378479\n",
      "\n",
      "episode 14, val func loss 0.001808802131563425\n",
      "\n",
      "episode 15, val func loss 0.27167606353759766\n",
      "\n",
      "episode 16, val func loss 0.3993340730667114\n",
      "\n",
      "Val func train loss in epoch 13:0.2951038159953896\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.27186331152915955\n",
      "\n",
      "episode 2, val func loss 0.3999035656452179\n",
      "\n",
      "episode 3, val func loss 0.40185919404029846\n",
      "\n",
      "episode 4, val func loss 0.540915310382843\n",
      "\n",
      "episode 5, val func loss 0.010530100204050541\n",
      "\n",
      "episode 6, val func loss 0.26835930347442627\n",
      "\n",
      "episode 7, val func loss 0.13902632892131805\n",
      "\n",
      "episode 8, val func loss 0.5327121019363403\n",
      "\n",
      "episode 9, val func loss 0.1398719698190689\n",
      "\n",
      "episode 10, val func loss 0.13605815172195435\n",
      "\n",
      "episode 11, val func loss 0.2667325437068939\n",
      "\n",
      "episode 12, val func loss 0.26736924052238464\n",
      "\n",
      "episode 13, val func loss 0.13744981586933136\n",
      "\n",
      "episode 14, val func loss 0.6584603786468506\n",
      "\n",
      "episode 15, val func loss 0.40296605229377747\n",
      "\n",
      "episode 16, val func loss 0.13887254893779755\n",
      "\n",
      "Val func train loss in epoch 14:0.29455936985323206\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.12923982739448547\n",
      "\n",
      "episode 2, val func loss 0.40218138694763184\n",
      "\n",
      "episode 3, val func loss 0.26169687509536743\n",
      "\n",
      "episode 4, val func loss 0.12622877955436707\n",
      "\n",
      "episode 5, val func loss 0.2625856101512909\n",
      "\n",
      "episode 6, val func loss 0.13233987987041473\n",
      "\n",
      "episode 7, val func loss 0.5514612793922424\n",
      "\n",
      "episode 8, val func loss 0.26008862257003784\n",
      "\n",
      "episode 9, val func loss 0.38419580459594727\n",
      "\n",
      "episode 10, val func loss 0.015087570063769817\n",
      "\n",
      "episode 11, val func loss 0.26774904131889343\n",
      "\n",
      "episode 12, val func loss 0.41496899724006653\n",
      "\n",
      "episode 13, val func loss 0.13404691219329834\n",
      "\n",
      "episode 14, val func loss 0.6603147387504578\n",
      "\n",
      "episode 15, val func loss 0.5230206847190857\n",
      "\n",
      "episode 16, val func loss 0.15472766757011414\n",
      "\n",
      "Val func train loss in epoch 15:0.2924958548392169\n",
      "***********************TIME WAS 4.8716143329938255 min*****************************\n",
      "\n",
      "**********************ROUND 89 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.10721249878406525\n",
      "\n",
      "episode 2, policy loss 0.0087592089548707\n",
      "\n",
      "episode 3, policy loss -0.08427661657333374\n",
      "\n",
      "episode 4, policy loss -0.08394990861415863\n",
      "\n",
      "episode 5, policy loss -0.11457385867834091\n",
      "\n",
      "episode 6, policy loss -0.05352691560983658\n",
      "\n",
      "episode 7, policy loss -0.022062012925744057\n",
      "\n",
      "episode 8, policy loss -0.11495298892259598\n",
      "\n",
      "episode 9, policy loss -0.0845610722899437\n",
      "\n",
      "episode 10, policy loss -0.08391760289669037\n",
      "\n",
      "episode 11, policy loss 0.009759248234331608\n",
      "\n",
      "episode 12, policy loss -0.023144353181123734\n",
      "\n",
      "episode 13, policy loss -0.1474178433418274\n",
      "\n",
      "episode 14, policy loss -0.053854163736104965\n",
      "\n",
      "episode 15, policy loss -0.14783655107021332\n",
      "\n",
      "episode 16, policy loss -0.11657468974590302\n",
      "\n",
      "Policy train loss in epoch 0:-0.07620891369879246\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.0853489488363266\n",
      "\n",
      "episode 2, policy loss -0.11659613996744156\n",
      "\n",
      "episode 3, policy loss -0.023636868223547935\n",
      "\n",
      "episode 4, policy loss -0.1479407250881195\n",
      "\n",
      "episode 5, policy loss -0.054150041192770004\n",
      "\n",
      "episode 6, policy loss -0.0853772833943367\n",
      "\n",
      "episode 7, policy loss -0.055127497762441635\n",
      "\n",
      "episode 8, policy loss -0.11652440577745438\n",
      "\n",
      "episode 9, policy loss -0.08507957309484482\n",
      "\n",
      "episode 10, policy loss 0.00833772961050272\n",
      "\n",
      "episode 11, policy loss -0.1480957716703415\n",
      "\n",
      "episode 12, policy loss -0.11661018431186676\n",
      "\n",
      "episode 13, policy loss 0.007877510040998459\n",
      "\n",
      "episode 14, policy loss -0.11661824584007263\n",
      "\n",
      "episode 15, policy loss -0.08609446883201599\n",
      "\n",
      "episode 16, policy loss -0.023875847458839417\n",
      "\n",
      "Policy train loss in epoch 1:-0.07780379761243239\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.0853685513138771\n",
      "\n",
      "episode 2, policy loss -0.08520324528217316\n",
      "\n",
      "episode 3, policy loss -0.14799629151821136\n",
      "\n",
      "episode 4, policy loss -0.05414195358753204\n",
      "\n",
      "episode 5, policy loss -0.11661691963672638\n",
      "\n",
      "episode 6, policy loss -0.08536966145038605\n",
      "\n",
      "episode 7, policy loss -0.02369752526283264\n",
      "\n",
      "episode 8, policy loss -0.1165381371974945\n",
      "\n",
      "episode 9, policy loss -0.023872600868344307\n",
      "\n",
      "episode 10, policy loss -0.0551210381090641\n",
      "\n",
      "episode 11, policy loss 0.008346468210220337\n",
      "\n",
      "episode 12, policy loss 0.007882170379161835\n",
      "\n",
      "episode 13, policy loss -0.11660899221897125\n",
      "\n",
      "episode 14, policy loss -0.11661285907030106\n",
      "\n",
      "episode 15, policy loss -0.08614260703325272\n",
      "\n",
      "episode 16, policy loss -0.14812153577804565\n",
      "\n",
      "Policy train loss in epoch 2:-0.07782395498361439\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.007882874459028244\n",
      "\n",
      "episode 2, policy loss -0.05413911119103432\n",
      "\n",
      "episode 3, policy loss -0.11661207675933838\n",
      "\n",
      "episode 4, policy loss -0.08521994203329086\n",
      "\n",
      "episode 5, policy loss 0.008347648195922375\n",
      "\n",
      "episode 6, policy loss -0.0861734077334404\n",
      "\n",
      "episode 7, policy loss -0.1479928195476532\n",
      "\n",
      "episode 8, policy loss -0.11661391705274582\n",
      "\n",
      "episode 9, policy loss -0.05511893704533577\n",
      "\n",
      "episode 10, policy loss -0.02387024648487568\n",
      "\n",
      "episode 11, policy loss -0.08536718785762787\n",
      "\n",
      "episode 12, policy loss -0.14812035858631134\n",
      "\n",
      "episode 13, policy loss -0.023694928735494614\n",
      "\n",
      "episode 14, policy loss -0.08537476509809494\n",
      "\n",
      "episode 15, policy loss -0.116607666015625\n",
      "\n",
      "episode 16, policy loss -0.11659082770347595\n",
      "\n",
      "Policy train loss in epoch 3:-0.0778291043243371\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.050607442855835\n",
      "\n",
      "episode 2, val func loss 0.6646246910095215\n",
      "\n",
      "episode 3, val func loss 0.7913631796836853\n",
      "\n",
      "episode 4, val func loss 0.5282455682754517\n",
      "\n",
      "episode 5, val func loss 0.8058149814605713\n",
      "\n",
      "episode 6, val func loss 0.14850552380084991\n",
      "\n",
      "episode 7, val func loss 0.2680264413356781\n",
      "\n",
      "episode 8, val func loss 0.94230055809021\n",
      "\n",
      "episode 9, val func loss 0.9307765364646912\n",
      "\n",
      "episode 10, val func loss 0.6637592315673828\n",
      "\n",
      "episode 11, val func loss 0.6428240537643433\n",
      "\n",
      "episode 12, val func loss 0.6683915257453918\n",
      "\n",
      "episode 13, val func loss 0.7874124050140381\n",
      "\n",
      "episode 14, val func loss 0.4211673438549042\n",
      "\n",
      "episode 15, val func loss 0.27030906081199646\n",
      "\n",
      "episode 16, val func loss 0.40934595465660095\n",
      "\n",
      "Val func train loss in epoch 0:0.624592156149447\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8031640648841858\n",
      "\n",
      "episode 2, val func loss 0.8148025870323181\n",
      "\n",
      "episode 3, val func loss 0.41025909781455994\n",
      "\n",
      "episode 4, val func loss 0.924570620059967\n",
      "\n",
      "episode 5, val func loss 0.6764340400695801\n",
      "\n",
      "episode 6, val func loss 0.30340147018432617\n",
      "\n",
      "episode 7, val func loss 0.1608896255493164\n",
      "\n",
      "episode 8, val func loss 0.6412498354911804\n",
      "\n",
      "episode 9, val func loss 0.25779861211776733\n",
      "\n",
      "episode 10, val func loss 0.9646344780921936\n",
      "\n",
      "episode 11, val func loss 0.661504328250885\n",
      "\n",
      "episode 12, val func loss 1.0559462308883667\n",
      "\n",
      "episode 13, val func loss 0.4045095145702362\n",
      "\n",
      "episode 14, val func loss 0.5421218276023865\n",
      "\n",
      "episode 15, val func loss 0.8057717084884644\n",
      "\n",
      "episode 16, val func loss 0.6660292148590088\n",
      "\n",
      "Val func train loss in epoch 1:0.6308179534971714\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6699172258377075\n",
      "\n",
      "episode 2, val func loss 0.2827366292476654\n",
      "\n",
      "episode 3, val func loss 0.7917008996009827\n",
      "\n",
      "episode 4, val func loss 0.9353119730949402\n",
      "\n",
      "episode 5, val func loss 0.653823971748352\n",
      "\n",
      "episode 6, val func loss 0.9271941781044006\n",
      "\n",
      "episode 7, val func loss 0.4104180932044983\n",
      "\n",
      "episode 8, val func loss 0.5401186347007751\n",
      "\n",
      "episode 9, val func loss 0.4123659133911133\n",
      "\n",
      "episode 10, val func loss 0.6575488448143005\n",
      "\n",
      "episode 11, val func loss 0.8024885654449463\n",
      "\n",
      "episode 12, val func loss 0.13741666078567505\n",
      "\n",
      "episode 13, val func loss 0.2640702724456787\n",
      "\n",
      "episode 14, val func loss 0.7906046509742737\n",
      "\n",
      "episode 15, val func loss 1.0564686059951782\n",
      "\n",
      "episode 16, val func loss 0.663112223148346\n",
      "\n",
      "Val func train loss in epoch 2:0.6247060839086771\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6669759750366211\n",
      "\n",
      "episode 2, val func loss 0.7881118059158325\n",
      "\n",
      "episode 3, val func loss 0.28279200196266174\n",
      "\n",
      "episode 4, val func loss 0.6693922877311707\n",
      "\n",
      "episode 5, val func loss 0.7969866394996643\n",
      "\n",
      "episode 6, val func loss 0.7853989005088806\n",
      "\n",
      "episode 7, val func loss 0.397889643907547\n",
      "\n",
      "episode 8, val func loss 0.6585832238197327\n",
      "\n",
      "episode 9, val func loss 0.6581795811653137\n",
      "\n",
      "episode 10, val func loss 1.0451210737228394\n",
      "\n",
      "episode 11, val func loss 0.5262191295623779\n",
      "\n",
      "episode 12, val func loss 0.9255308508872986\n",
      "\n",
      "episode 13, val func loss 0.15681326389312744\n",
      "\n",
      "episode 14, val func loss 0.3918887972831726\n",
      "\n",
      "episode 15, val func loss 0.9222676753997803\n",
      "\n",
      "episode 16, val func loss 0.2737528383731842\n",
      "\n",
      "Val func train loss in epoch 3:0.6216189805418253\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.27043023705482483\n",
      "\n",
      "episode 2, val func loss 0.6493509411811829\n",
      "\n",
      "episode 3, val func loss 1.0584980249404907\n",
      "\n",
      "episode 4, val func loss 0.6627368927001953\n",
      "\n",
      "episode 5, val func loss 0.1559484899044037\n",
      "\n",
      "episode 6, val func loss 0.5298455953598022\n",
      "\n",
      "episode 7, val func loss 0.9177328944206238\n",
      "\n",
      "episode 8, val func loss 0.40429291129112244\n",
      "\n",
      "episode 9, val func loss 0.2741173207759857\n",
      "\n",
      "episode 10, val func loss 0.769830048084259\n",
      "\n",
      "episode 11, val func loss 0.9197924137115479\n",
      "\n",
      "episode 12, val func loss 0.6613078713417053\n",
      "\n",
      "episode 13, val func loss 0.7741946578025818\n",
      "\n",
      "episode 14, val func loss 0.6647921800613403\n",
      "\n",
      "episode 15, val func loss 0.41222018003463745\n",
      "\n",
      "episode 16, val func loss 0.7919131517410278\n",
      "\n",
      "Val func train loss in epoch 4:0.6198127381503582\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.8047335147857666\n",
      "\n",
      "episode 2, val func loss 0.926774263381958\n",
      "\n",
      "episode 3, val func loss 0.1483609527349472\n",
      "\n",
      "episode 4, val func loss 0.6625601649284363\n",
      "\n",
      "episode 5, val func loss 0.9160805940628052\n",
      "\n",
      "episode 6, val func loss 0.5089608430862427\n",
      "\n",
      "episode 7, val func loss 0.671441376209259\n",
      "\n",
      "episode 8, val func loss 0.3941258192062378\n",
      "\n",
      "episode 9, val func loss 0.6678798794746399\n",
      "\n",
      "episode 10, val func loss 0.4105566442012787\n",
      "\n",
      "episode 11, val func loss 0.27168333530426025\n",
      "\n",
      "episode 12, val func loss 0.6570245623588562\n",
      "\n",
      "episode 13, val func loss 0.7841992974281311\n",
      "\n",
      "episode 14, val func loss 0.7745375037193298\n",
      "\n",
      "episode 15, val func loss 0.2855573296546936\n",
      "\n",
      "episode 16, val func loss 1.0498026609420776\n",
      "\n",
      "Val func train loss in epoch 5:0.6208924213424325\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6184628009796143\n",
      "\n",
      "episode 2, val func loss 0.9062115550041199\n",
      "\n",
      "episode 3, val func loss 0.2978194057941437\n",
      "\n",
      "episode 4, val func loss 0.28422901034355164\n",
      "\n",
      "episode 5, val func loss 0.5157642364501953\n",
      "\n",
      "episode 6, val func loss 0.7059847712516785\n",
      "\n",
      "episode 7, val func loss 0.4167954623699188\n",
      "\n",
      "episode 8, val func loss 0.1368231475353241\n",
      "\n",
      "episode 9, val func loss 0.8119943737983704\n",
      "\n",
      "episode 10, val func loss 0.7886655926704407\n",
      "\n",
      "episode 11, val func loss 0.41301023960113525\n",
      "\n",
      "episode 12, val func loss 0.9135269522666931\n",
      "\n",
      "episode 13, val func loss 0.6772559881210327\n",
      "\n",
      "episode 14, val func loss 0.7872059345245361\n",
      "\n",
      "episode 15, val func loss 1.0485389232635498\n",
      "\n",
      "episode 16, val func loss 0.6618427038192749\n",
      "\n",
      "Val func train loss in epoch 6:0.6240081936120987\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6623775362968445\n",
      "\n",
      "episode 2, val func loss 0.6683646440505981\n",
      "\n",
      "episode 3, val func loss 0.14038075506687164\n",
      "\n",
      "episode 4, val func loss 0.2756006717681885\n",
      "\n",
      "episode 5, val func loss 0.678358256816864\n",
      "\n",
      "episode 6, val func loss 0.7738659977912903\n",
      "\n",
      "episode 7, val func loss 0.6525284647941589\n",
      "\n",
      "episode 8, val func loss 0.8138861656188965\n",
      "\n",
      "episode 9, val func loss 0.5540956854820251\n",
      "\n",
      "episode 10, val func loss 0.4102407991886139\n",
      "\n",
      "episode 11, val func loss 0.9246257543563843\n",
      "\n",
      "episode 12, val func loss 0.2693105638027191\n",
      "\n",
      "episode 13, val func loss 1.0753355026245117\n",
      "\n",
      "episode 14, val func loss 0.7911137342453003\n",
      "\n",
      "episode 15, val func loss 0.40969592332839966\n",
      "\n",
      "episode 16, val func loss 0.9144930839538574\n",
      "\n",
      "Val func train loss in epoch 7:0.6258920961990952\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.40212711691856384\n",
      "\n",
      "episode 2, val func loss 0.9112735390663147\n",
      "\n",
      "episode 3, val func loss 0.6807831525802612\n",
      "\n",
      "episode 4, val func loss 0.7965952157974243\n",
      "\n",
      "episode 5, val func loss 0.28142082691192627\n",
      "\n",
      "episode 6, val func loss 0.26781755685806274\n",
      "\n",
      "episode 7, val func loss 0.6719370484352112\n",
      "\n",
      "episode 8, val func loss 0.41399475932121277\n",
      "\n",
      "episode 9, val func loss 1.076258897781372\n",
      "\n",
      "episode 10, val func loss 0.8080532550811768\n",
      "\n",
      "episode 11, val func loss 0.5270184278488159\n",
      "\n",
      "episode 12, val func loss 0.15840843319892883\n",
      "\n",
      "episode 13, val func loss 0.9241576194763184\n",
      "\n",
      "episode 14, val func loss 0.6625253558158875\n",
      "\n",
      "episode 15, val func loss 0.7735146284103394\n",
      "\n",
      "episode 16, val func loss 0.656263530254364\n",
      "\n",
      "Val func train loss in epoch 8:0.6257593352347612\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6602272987365723\n",
      "\n",
      "episode 2, val func loss 0.26777273416519165\n",
      "\n",
      "episode 3, val func loss 0.1317257285118103\n",
      "\n",
      "episode 4, val func loss 0.7776041626930237\n",
      "\n",
      "episode 5, val func loss 0.8017160296440125\n",
      "\n",
      "episode 6, val func loss 0.5022206902503967\n",
      "\n",
      "episode 7, val func loss 1.0186436176300049\n",
      "\n",
      "episode 8, val func loss 0.4405205547809601\n",
      "\n",
      "episode 9, val func loss 0.8951268792152405\n",
      "\n",
      "episode 10, val func loss 0.6701620221138\n",
      "\n",
      "episode 11, val func loss 0.8999824523925781\n",
      "\n",
      "episode 12, val func loss 0.28528785705566406\n",
      "\n",
      "episode 13, val func loss 0.6596599817276001\n",
      "\n",
      "episode 14, val func loss 0.6337935924530029\n",
      "\n",
      "episode 15, val func loss 0.41333743929862976\n",
      "\n",
      "episode 16, val func loss 0.8103493452072144\n",
      "\n",
      "Val func train loss in epoch 9:0.6167581491172314\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6444985270500183\n",
      "\n",
      "episode 2, val func loss 0.6734644770622253\n",
      "\n",
      "episode 3, val func loss 0.9276711940765381\n",
      "\n",
      "episode 4, val func loss 0.7668187022209167\n",
      "\n",
      "episode 5, val func loss 1.0276377201080322\n",
      "\n",
      "episode 6, val func loss 0.28454557061195374\n",
      "\n",
      "episode 7, val func loss 0.6686842441558838\n",
      "\n",
      "episode 8, val func loss 0.8102385401725769\n",
      "\n",
      "episode 9, val func loss 0.520928144454956\n",
      "\n",
      "episode 10, val func loss 0.6570426225662231\n",
      "\n",
      "episode 11, val func loss 0.78508061170578\n",
      "\n",
      "episode 12, val func loss 0.2684853971004486\n",
      "\n",
      "episode 13, val func loss 0.937389075756073\n",
      "\n",
      "episode 14, val func loss 0.40286144614219666\n",
      "\n",
      "episode 15, val func loss 0.14099811017513275\n",
      "\n",
      "episode 16, val func loss 0.41083618998527527\n",
      "\n",
      "Val func train loss in epoch 10:0.6204487858340144\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9105528593063354\n",
      "\n",
      "episode 2, val func loss 0.27576884627342224\n",
      "\n",
      "episode 3, val func loss 0.40577855706214905\n",
      "\n",
      "episode 4, val func loss 0.6675944328308105\n",
      "\n",
      "episode 5, val func loss 0.7986736297607422\n",
      "\n",
      "episode 6, val func loss 0.6667143106460571\n",
      "\n",
      "episode 7, val func loss 0.41135552525520325\n",
      "\n",
      "episode 8, val func loss 0.9322666525840759\n",
      "\n",
      "episode 9, val func loss 0.7911401987075806\n",
      "\n",
      "episode 10, val func loss 1.0539582967758179\n",
      "\n",
      "episode 11, val func loss 0.7872633934020996\n",
      "\n",
      "episode 12, val func loss 0.6567856669425964\n",
      "\n",
      "episode 13, val func loss 0.6579071283340454\n",
      "\n",
      "episode 14, val func loss 0.5291325449943542\n",
      "\n",
      "episode 15, val func loss 0.1420905441045761\n",
      "\n",
      "episode 16, val func loss 0.2703377604484558\n",
      "\n",
      "Val func train loss in epoch 11:0.6223325217142701\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.1401422917842865\n",
      "\n",
      "episode 2, val func loss 0.5403403043746948\n",
      "\n",
      "episode 3, val func loss 0.6628389358520508\n",
      "\n",
      "episode 4, val func loss 0.6781374216079712\n",
      "\n",
      "episode 5, val func loss 0.6481576561927795\n",
      "\n",
      "episode 6, val func loss 0.6659322381019592\n",
      "\n",
      "episode 7, val func loss 0.2833513617515564\n",
      "\n",
      "episode 8, val func loss 0.2990702986717224\n",
      "\n",
      "episode 9, val func loss 0.39444029331207275\n",
      "\n",
      "episode 10, val func loss 0.8049256801605225\n",
      "\n",
      "episode 11, val func loss 0.7931181192398071\n",
      "\n",
      "episode 12, val func loss 1.0591871738433838\n",
      "\n",
      "episode 13, val func loss 0.9157471060752869\n",
      "\n",
      "episode 14, val func loss 0.910182535648346\n",
      "\n",
      "episode 15, val func loss 0.4214310944080353\n",
      "\n",
      "episode 16, val func loss 0.7895134687423706\n",
      "\n",
      "Val func train loss in epoch 12:0.6254072487354279\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.2932591140270233\n",
      "\n",
      "episode 2, val func loss 0.7801050543785095\n",
      "\n",
      "episode 3, val func loss 0.40222588181495667\n",
      "\n",
      "episode 4, val func loss 0.6503366231918335\n",
      "\n",
      "episode 5, val func loss 0.9299820065498352\n",
      "\n",
      "episode 6, val func loss 0.6619872450828552\n",
      "\n",
      "episode 7, val func loss 0.40114104747772217\n",
      "\n",
      "episode 8, val func loss 0.6552496552467346\n",
      "\n",
      "episode 9, val func loss 0.5376210808753967\n",
      "\n",
      "episode 10, val func loss 0.7941358685493469\n",
      "\n",
      "episode 11, val func loss 0.7681995034217834\n",
      "\n",
      "episode 12, val func loss 0.6531059741973877\n",
      "\n",
      "episode 13, val func loss 1.0276720523834229\n",
      "\n",
      "episode 14, val func loss 0.9102468490600586\n",
      "\n",
      "episode 15, val func loss 0.26963743567466736\n",
      "\n",
      "episode 16, val func loss 0.14894984662532806\n",
      "\n",
      "Val func train loss in epoch 13:0.6177409524098039\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6851451992988586\n",
      "\n",
      "episode 2, val func loss 0.8224292397499084\n",
      "\n",
      "episode 3, val func loss 0.6411899924278259\n",
      "\n",
      "episode 4, val func loss 0.413038432598114\n",
      "\n",
      "episode 5, val func loss 0.27087897062301636\n",
      "\n",
      "episode 6, val func loss 0.9324836730957031\n",
      "\n",
      "episode 7, val func loss 0.9294662475585938\n",
      "\n",
      "episode 8, val func loss 0.40997788310050964\n",
      "\n",
      "episode 9, val func loss 0.6618509888648987\n",
      "\n",
      "episode 10, val func loss 0.6548305153846741\n",
      "\n",
      "episode 11, val func loss 0.27521225810050964\n",
      "\n",
      "episode 12, val func loss 0.7814173698425293\n",
      "\n",
      "episode 13, val func loss 0.527880847454071\n",
      "\n",
      "episode 14, val func loss 0.7818297743797302\n",
      "\n",
      "episode 15, val func loss 0.1377788931131363\n",
      "\n",
      "episode 16, val func loss 1.056746244430542\n",
      "\n",
      "Val func train loss in epoch 14:0.6238847831264138\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.0257196426391602\n",
      "\n",
      "episode 2, val func loss 0.7907304763793945\n",
      "\n",
      "episode 3, val func loss 0.6722402572631836\n",
      "\n",
      "episode 4, val func loss 0.7868838906288147\n",
      "\n",
      "episode 5, val func loss 0.540745198726654\n",
      "\n",
      "episode 6, val func loss 0.9236895442008972\n",
      "\n",
      "episode 7, val func loss 0.6371934413909912\n",
      "\n",
      "episode 8, val func loss 0.6307324767112732\n",
      "\n",
      "episode 9, val func loss 0.6329668760299683\n",
      "\n",
      "episode 10, val func loss 0.9224552512168884\n",
      "\n",
      "episode 11, val func loss 0.2612336277961731\n",
      "\n",
      "episode 12, val func loss 0.41226789355278015\n",
      "\n",
      "episode 13, val func loss 0.2829664647579193\n",
      "\n",
      "episode 14, val func loss 0.408549040555954\n",
      "\n",
      "episode 15, val func loss 0.7832460999488831\n",
      "\n",
      "episode 16, val func loss 0.13629090785980225\n",
      "\n",
      "Val func train loss in epoch 15:0.6154944431036711\n",
      "***********************TIME WAS 4.8749250888824465 min*****************************\n",
      "\n",
      "**********************ROUND 90 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -2.752711296081543\n",
      "\n",
      "episode 2, policy loss -2.6899030208587646\n",
      "\n",
      "episode 3, policy loss -2.8658313751220703\n",
      "\n",
      "episode 4, policy loss -2.5779337882995605\n",
      "\n",
      "episode 5, policy loss -2.6096506118774414\n",
      "\n",
      "episode 6, policy loss -2.542475938796997\n",
      "\n",
      "episode 7, policy loss -2.605611801147461\n",
      "\n",
      "episode 8, policy loss -2.79610538482666\n",
      "\n",
      "episode 9, policy loss -2.3502938747406006\n",
      "\n",
      "episode 10, policy loss -2.254251718521118\n",
      "\n",
      "episode 11, policy loss -3.145261526107788\n",
      "\n",
      "episode 12, policy loss -3.083308219909668\n",
      "\n",
      "episode 13, policy loss -2.794968605041504\n",
      "\n",
      "episode 14, policy loss -2.9544732570648193\n",
      "\n",
      "episode 15, policy loss -2.604977607727051\n",
      "\n",
      "episode 16, policy loss -2.732797145843506\n",
      "\n",
      "Policy train loss in epoch 0:-2.7100346982479095\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -2.3499481678009033\n",
      "\n",
      "episode 2, policy loss -2.604771614074707\n",
      "\n",
      "episode 3, policy loss -2.541085958480835\n",
      "\n",
      "episode 4, policy loss -2.6685032844543457\n",
      "\n",
      "episode 5, policy loss -2.6049418449401855\n",
      "\n",
      "episode 6, policy loss -3.1451268196105957\n",
      "\n",
      "episode 7, policy loss -2.732760429382324\n",
      "\n",
      "episode 8, policy loss -2.573237657546997\n",
      "\n",
      "episode 9, policy loss -3.0832226276397705\n",
      "\n",
      "episode 10, policy loss -2.6074671745300293\n",
      "\n",
      "episode 11, policy loss -2.795657157897949\n",
      "\n",
      "episode 12, policy loss -2.253955125808716\n",
      "\n",
      "episode 13, policy loss -3.079249620437622\n",
      "\n",
      "episode 14, policy loss -2.954434394836426\n",
      "\n",
      "episode 15, policy loss -2.7948691844940186\n",
      "\n",
      "episode 16, policy loss -2.85703182220459\n",
      "\n",
      "Policy train loss in epoch 1:-2.727891430258751\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.0792486667633057\n",
      "\n",
      "episode 2, policy loss -2.253962993621826\n",
      "\n",
      "episode 3, policy loss -2.7956507205963135\n",
      "\n",
      "episode 4, policy loss -2.5410571098327637\n",
      "\n",
      "episode 5, policy loss -2.6074612140655518\n",
      "\n",
      "episode 6, policy loss -2.857025146484375\n",
      "\n",
      "episode 7, policy loss -2.349898099899292\n",
      "\n",
      "episode 8, policy loss -2.604732036590576\n",
      "\n",
      "episode 9, policy loss -2.95443058013916\n",
      "\n",
      "episode 10, policy loss -2.6684811115264893\n",
      "\n",
      "episode 11, policy loss -2.573228120803833\n",
      "\n",
      "episode 12, policy loss -2.7948668003082275\n",
      "\n",
      "episode 13, policy loss -3.0832133293151855\n",
      "\n",
      "episode 14, policy loss -2.6049277782440186\n",
      "\n",
      "episode 15, policy loss -3.1451127529144287\n",
      "\n",
      "episode 16, policy loss -2.7327358722686768\n",
      "\n",
      "Policy train loss in epoch 2:-2.7278770208358765\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -2.9544296264648438\n",
      "\n",
      "episode 2, policy loss -3.0792510509490967\n",
      "\n",
      "episode 3, policy loss -2.573228120803833\n",
      "\n",
      "episode 4, policy loss -2.253955602645874\n",
      "\n",
      "episode 5, policy loss -2.6074600219726562\n",
      "\n",
      "episode 6, policy loss -3.0832133293151855\n",
      "\n",
      "episode 7, policy loss -2.7327380180358887\n",
      "\n",
      "episode 8, policy loss -2.349890947341919\n",
      "\n",
      "episode 9, policy loss -2.857022762298584\n",
      "\n",
      "episode 10, policy loss -2.795650005340576\n",
      "\n",
      "episode 11, policy loss -3.1451144218444824\n",
      "\n",
      "episode 12, policy loss -2.541055917739868\n",
      "\n",
      "episode 13, policy loss -2.604926586151123\n",
      "\n",
      "episode 14, policy loss -2.7948594093322754\n",
      "\n",
      "episode 15, policy loss -2.668480396270752\n",
      "\n",
      "episode 16, policy loss -2.6047239303588867\n",
      "\n",
      "Policy train loss in epoch 3:-2.7278750091791153\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 11.098627090454102\n",
      "\n",
      "episode 2, val func loss 10.89741039276123\n",
      "\n",
      "episode 3, val func loss 7.994380950927734\n",
      "\n",
      "episode 4, val func loss 6.9618239402771\n",
      "\n",
      "episode 5, val func loss 7.104936122894287\n",
      "\n",
      "episode 6, val func loss 7.547980308532715\n",
      "\n",
      "episode 7, val func loss 6.753302574157715\n",
      "\n",
      "episode 8, val func loss 6.528201103210449\n",
      "\n",
      "episode 9, val func loss 6.137522220611572\n",
      "\n",
      "episode 10, val func loss 6.661993503570557\n",
      "\n",
      "episode 11, val func loss 6.428542613983154\n",
      "\n",
      "episode 12, val func loss 6.528250694274902\n",
      "\n",
      "episode 13, val func loss 6.3322649002075195\n",
      "\n",
      "episode 14, val func loss 6.778985023498535\n",
      "\n",
      "episode 15, val func loss 6.857465744018555\n",
      "\n",
      "episode 16, val func loss 6.342498779296875\n",
      "\n",
      "Val func train loss in epoch 0:7.309636622667313\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 6.381099700927734\n",
      "\n",
      "episode 2, val func loss 5.721102714538574\n",
      "\n",
      "episode 3, val func loss 6.673586845397949\n",
      "\n",
      "episode 4, val func loss 6.304781913757324\n",
      "\n",
      "episode 5, val func loss 6.506570816040039\n",
      "\n",
      "episode 6, val func loss 6.698533058166504\n",
      "\n",
      "episode 7, val func loss 6.378114223480225\n",
      "\n",
      "episode 8, val func loss 6.531829833984375\n",
      "\n",
      "episode 9, val func loss 6.46329927444458\n",
      "\n",
      "episode 10, val func loss 6.589019775390625\n",
      "\n",
      "episode 11, val func loss 6.33160400390625\n",
      "\n",
      "episode 12, val func loss 6.675943374633789\n",
      "\n",
      "episode 13, val func loss 6.618734836578369\n",
      "\n",
      "episode 14, val func loss 6.516510009765625\n",
      "\n",
      "episode 15, val func loss 6.803390026092529\n",
      "\n",
      "episode 16, val func loss 5.963218688964844\n",
      "\n",
      "Val func train loss in epoch 1:6.4473336935043335\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 5.941614151000977\n",
      "\n",
      "episode 2, val func loss 6.26807165145874\n",
      "\n",
      "episode 3, val func loss 6.485413551330566\n",
      "\n",
      "episode 4, val func loss 6.3611040115356445\n",
      "\n",
      "episode 5, val func loss 6.364866733551025\n",
      "\n",
      "episode 6, val func loss 6.163253307342529\n",
      "\n",
      "episode 7, val func loss 6.970463275909424\n",
      "\n",
      "episode 8, val func loss 6.48434591293335\n",
      "\n",
      "episode 9, val func loss 6.707642555236816\n",
      "\n",
      "episode 10, val func loss 6.421647071838379\n",
      "\n",
      "episode 11, val func loss 6.48552942276001\n",
      "\n",
      "episode 12, val func loss 6.452296733856201\n",
      "\n",
      "episode 13, val func loss 5.455000400543213\n",
      "\n",
      "episode 14, val func loss 6.272679805755615\n",
      "\n",
      "episode 15, val func loss 6.4467363357543945\n",
      "\n",
      "episode 16, val func loss 6.349391937255859\n",
      "\n",
      "Val func train loss in epoch 2:6.3518785536289215\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 6.58887243270874\n",
      "\n",
      "episode 2, val func loss 6.663273334503174\n",
      "\n",
      "episode 3, val func loss 6.387861728668213\n",
      "\n",
      "episode 4, val func loss 5.564939975738525\n",
      "\n",
      "episode 5, val func loss 6.883659362792969\n",
      "\n",
      "episode 6, val func loss 6.036105632781982\n",
      "\n",
      "episode 7, val func loss 6.5011796951293945\n",
      "\n",
      "episode 8, val func loss 6.1160993576049805\n",
      "\n",
      "episode 9, val func loss 6.263145446777344\n",
      "\n",
      "episode 10, val func loss 6.557689666748047\n",
      "\n",
      "episode 11, val func loss 6.469851493835449\n",
      "\n",
      "episode 12, val func loss 6.26572847366333\n",
      "\n",
      "episode 13, val func loss 6.394097328186035\n",
      "\n",
      "episode 14, val func loss 6.716421604156494\n",
      "\n",
      "episode 15, val func loss 6.434731483459473\n",
      "\n",
      "episode 16, val func loss 6.65318489074707\n",
      "\n",
      "Val func train loss in epoch 3:6.406052619218826\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 6.618198871612549\n",
      "\n",
      "episode 2, val func loss 6.030604362487793\n",
      "\n",
      "episode 3, val func loss 6.3468475341796875\n",
      "\n",
      "episode 4, val func loss 6.268924236297607\n",
      "\n",
      "episode 5, val func loss 6.44521427154541\n",
      "\n",
      "episode 6, val func loss 6.55730676651001\n",
      "\n",
      "episode 7, val func loss 5.4220404624938965\n",
      "\n",
      "episode 8, val func loss 6.508649826049805\n",
      "\n",
      "episode 9, val func loss 6.385143756866455\n",
      "\n",
      "episode 10, val func loss 6.80278205871582\n",
      "\n",
      "episode 11, val func loss 6.6590256690979\n",
      "\n",
      "episode 12, val func loss 6.142164707183838\n",
      "\n",
      "episode 13, val func loss 6.674621105194092\n",
      "\n",
      "episode 14, val func loss 6.276561737060547\n",
      "\n",
      "episode 15, val func loss 6.455095291137695\n",
      "\n",
      "episode 16, val func loss 6.314394950866699\n",
      "\n",
      "Val func train loss in epoch 4:6.369223475456238\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 6.3263373374938965\n",
      "\n",
      "episode 2, val func loss 6.165195941925049\n",
      "\n",
      "episode 3, val func loss 6.64085054397583\n",
      "\n",
      "episode 4, val func loss 6.751219272613525\n",
      "\n",
      "episode 5, val func loss 5.536274433135986\n",
      "\n",
      "episode 6, val func loss 6.628795623779297\n",
      "\n",
      "episode 7, val func loss 6.49692440032959\n",
      "\n",
      "episode 8, val func loss 6.826156139373779\n",
      "\n",
      "episode 9, val func loss 6.72914981842041\n",
      "\n",
      "episode 10, val func loss 6.215137004852295\n",
      "\n",
      "episode 11, val func loss 6.33592414855957\n",
      "\n",
      "episode 12, val func loss 6.254713535308838\n",
      "\n",
      "episode 13, val func loss 6.366772174835205\n",
      "\n",
      "episode 14, val func loss 6.726672649383545\n",
      "\n",
      "episode 15, val func loss 6.672449588775635\n",
      "\n",
      "episode 16, val func loss 6.4955339431762695\n",
      "\n",
      "Val func train loss in epoch 5:6.44800665974617\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 6.425388813018799\n",
      "\n",
      "episode 2, val func loss 6.286337852478027\n",
      "\n",
      "episode 3, val func loss 6.481619358062744\n",
      "\n",
      "episode 4, val func loss 5.460901737213135\n",
      "\n",
      "episode 5, val func loss 6.605883598327637\n",
      "\n",
      "episode 6, val func loss 6.454328536987305\n",
      "\n",
      "episode 7, val func loss 6.127200126647949\n",
      "\n",
      "episode 8, val func loss 6.3399977684021\n",
      "\n",
      "episode 9, val func loss 6.486115455627441\n",
      "\n",
      "episode 10, val func loss 6.299023151397705\n",
      "\n",
      "episode 11, val func loss 6.16008186340332\n",
      "\n",
      "episode 12, val func loss 6.57705020904541\n",
      "\n",
      "episode 13, val func loss 6.567216873168945\n",
      "\n",
      "episode 14, val func loss 6.13748025894165\n",
      "\n",
      "episode 15, val func loss 6.454234600067139\n",
      "\n",
      "episode 16, val func loss 6.723345756530762\n",
      "\n",
      "Val func train loss in epoch 6:6.349137872457504\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 6.24403715133667\n",
      "\n",
      "episode 2, val func loss 6.573699951171875\n",
      "\n",
      "episode 3, val func loss 6.564828872680664\n",
      "\n",
      "episode 4, val func loss 6.38678503036499\n",
      "\n",
      "episode 5, val func loss 6.325972080230713\n",
      "\n",
      "episode 6, val func loss 6.30129337310791\n",
      "\n",
      "episode 7, val func loss 6.4963274002075195\n",
      "\n",
      "episode 8, val func loss 6.651909828186035\n",
      "\n",
      "episode 9, val func loss 5.49756383895874\n",
      "\n",
      "episode 10, val func loss 6.388288974761963\n",
      "\n",
      "episode 11, val func loss 6.384269714355469\n",
      "\n",
      "episode 12, val func loss 5.942112445831299\n",
      "\n",
      "episode 13, val func loss 6.527270793914795\n",
      "\n",
      "episode 14, val func loss 6.727325439453125\n",
      "\n",
      "episode 15, val func loss 6.44494104385376\n",
      "\n",
      "episode 16, val func loss 6.327085494995117\n",
      "\n",
      "Val func train loss in epoch 7:6.361481964588165\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 6.406923294067383\n",
      "\n",
      "episode 2, val func loss 6.504766941070557\n",
      "\n",
      "episode 3, val func loss 6.52069091796875\n",
      "\n",
      "episode 4, val func loss 6.19648551940918\n",
      "\n",
      "episode 5, val func loss 6.493746757507324\n",
      "\n",
      "episode 6, val func loss 6.597536087036133\n",
      "\n",
      "episode 7, val func loss 6.480658054351807\n",
      "\n",
      "episode 8, val func loss 6.330538749694824\n",
      "\n",
      "episode 9, val func loss 6.306811809539795\n",
      "\n",
      "episode 10, val func loss 6.062371253967285\n",
      "\n",
      "episode 11, val func loss 6.571590423583984\n",
      "\n",
      "episode 12, val func loss 6.1962175369262695\n",
      "\n",
      "episode 13, val func loss 6.654599666595459\n",
      "\n",
      "episode 14, val func loss 6.332106113433838\n",
      "\n",
      "episode 15, val func loss 6.325791835784912\n",
      "\n",
      "episode 16, val func loss 5.672007083892822\n",
      "\n",
      "Val func train loss in epoch 8:6.353302627801895\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 6.459259986877441\n",
      "\n",
      "episode 2, val func loss 6.074211120605469\n",
      "\n",
      "episode 3, val func loss 5.964855670928955\n",
      "\n",
      "episode 4, val func loss 6.902124881744385\n",
      "\n",
      "episode 5, val func loss 6.4367499351501465\n",
      "\n",
      "episode 6, val func loss 5.389139175415039\n",
      "\n",
      "episode 7, val func loss 6.159007549285889\n",
      "\n",
      "episode 8, val func loss 6.52771520614624\n",
      "\n",
      "episode 9, val func loss 6.640434265136719\n",
      "\n",
      "episode 10, val func loss 6.178246021270752\n",
      "\n",
      "episode 11, val func loss 6.594279766082764\n",
      "\n",
      "episode 12, val func loss 6.408121109008789\n",
      "\n",
      "episode 13, val func loss 6.04885721206665\n",
      "\n",
      "episode 14, val func loss 6.2865891456604\n",
      "\n",
      "episode 15, val func loss 6.351289749145508\n",
      "\n",
      "episode 16, val func loss 6.533370494842529\n",
      "\n",
      "Val func train loss in epoch 9:6.30964070558548\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 6.313053607940674\n",
      "\n",
      "episode 2, val func loss 6.582071781158447\n",
      "\n",
      "episode 3, val func loss 6.605880260467529\n",
      "\n",
      "episode 4, val func loss 6.290202617645264\n",
      "\n",
      "episode 5, val func loss 6.254912853240967\n",
      "\n",
      "episode 6, val func loss 6.597757339477539\n",
      "\n",
      "episode 7, val func loss 6.317790508270264\n",
      "\n",
      "episode 8, val func loss 6.390631675720215\n",
      "\n",
      "episode 9, val func loss 5.568747043609619\n",
      "\n",
      "episode 10, val func loss 6.435622692108154\n",
      "\n",
      "episode 11, val func loss 6.200249671936035\n",
      "\n",
      "episode 12, val func loss 6.5019378662109375\n",
      "\n",
      "episode 13, val func loss 6.069257736206055\n",
      "\n",
      "episode 14, val func loss 6.27146053314209\n",
      "\n",
      "episode 15, val func loss 6.520638465881348\n",
      "\n",
      "episode 16, val func loss 6.16713285446167\n",
      "\n",
      "Val func train loss in epoch 10:6.3179592192173\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 6.368231296539307\n",
      "\n",
      "episode 2, val func loss 5.53749942779541\n",
      "\n",
      "episode 3, val func loss 6.797096252441406\n",
      "\n",
      "episode 4, val func loss 6.26099157333374\n",
      "\n",
      "episode 5, val func loss 6.297458171844482\n",
      "\n",
      "episode 6, val func loss 6.417384624481201\n",
      "\n",
      "episode 7, val func loss 6.257861137390137\n",
      "\n",
      "episode 8, val func loss 6.197275161743164\n",
      "\n",
      "episode 9, val func loss 6.536013603210449\n",
      "\n",
      "episode 10, val func loss 6.543415546417236\n",
      "\n",
      "episode 11, val func loss 6.248666763305664\n",
      "\n",
      "episode 12, val func loss 6.630889415740967\n",
      "\n",
      "episode 13, val func loss 6.249143123626709\n",
      "\n",
      "episode 14, val func loss 6.482017517089844\n",
      "\n",
      "episode 15, val func loss 6.015596389770508\n",
      "\n",
      "episode 16, val func loss 6.024412631988525\n",
      "\n",
      "Val func train loss in epoch 11:6.303997039794922\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 6.515890598297119\n",
      "\n",
      "episode 2, val func loss 6.711408615112305\n",
      "\n",
      "episode 3, val func loss 6.67496395111084\n",
      "\n",
      "episode 4, val func loss 6.29832649230957\n",
      "\n",
      "episode 5, val func loss 6.052475929260254\n",
      "\n",
      "episode 6, val func loss 5.515295505523682\n",
      "\n",
      "episode 7, val func loss 6.16874885559082\n",
      "\n",
      "episode 8, val func loss 6.251953125\n",
      "\n",
      "episode 9, val func loss 6.612559795379639\n",
      "\n",
      "episode 10, val func loss 6.50484561920166\n",
      "\n",
      "episode 11, val func loss 6.542256832122803\n",
      "\n",
      "episode 12, val func loss 6.594394207000732\n",
      "\n",
      "episode 13, val func loss 6.491024017333984\n",
      "\n",
      "episode 14, val func loss 6.559361457824707\n",
      "\n",
      "episode 15, val func loss 6.3225226402282715\n",
      "\n",
      "episode 16, val func loss 6.619626522064209\n",
      "\n",
      "Val func train loss in epoch 12:6.402228385210037\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 5.372969150543213\n",
      "\n",
      "episode 2, val func loss 6.299868583679199\n",
      "\n",
      "episode 3, val func loss 6.382829666137695\n",
      "\n",
      "episode 4, val func loss 6.257310390472412\n",
      "\n",
      "episode 5, val func loss 6.498159885406494\n",
      "\n",
      "episode 6, val func loss 6.950859546661377\n",
      "\n",
      "episode 7, val func loss 6.508124351501465\n",
      "\n",
      "episode 8, val func loss 6.458232879638672\n",
      "\n",
      "episode 9, val func loss 6.564342975616455\n",
      "\n",
      "episode 10, val func loss 6.501052379608154\n",
      "\n",
      "episode 11, val func loss 6.057313442230225\n",
      "\n",
      "episode 12, val func loss 6.171003341674805\n",
      "\n",
      "episode 13, val func loss 6.358752250671387\n",
      "\n",
      "episode 14, val func loss 6.300800800323486\n",
      "\n",
      "episode 15, val func loss 6.333343029022217\n",
      "\n",
      "episode 16, val func loss 6.663810729980469\n",
      "\n",
      "Val func train loss in epoch 13:6.354923337697983\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 6.509804725646973\n",
      "\n",
      "episode 2, val func loss 6.637583255767822\n",
      "\n",
      "episode 3, val func loss 6.700933933258057\n",
      "\n",
      "episode 4, val func loss 5.472509860992432\n",
      "\n",
      "episode 5, val func loss 6.251747131347656\n",
      "\n",
      "episode 6, val func loss 6.481912612915039\n",
      "\n",
      "episode 7, val func loss 6.159818172454834\n",
      "\n",
      "episode 8, val func loss 6.8608784675598145\n",
      "\n",
      "episode 9, val func loss 6.618864059448242\n",
      "\n",
      "episode 10, val func loss 6.47387170791626\n",
      "\n",
      "episode 11, val func loss 6.699708461761475\n",
      "\n",
      "episode 12, val func loss 6.6297688484191895\n",
      "\n",
      "episode 13, val func loss 6.5445380210876465\n",
      "\n",
      "episode 14, val func loss 6.634766578674316\n",
      "\n",
      "episode 15, val func loss 6.440410137176514\n",
      "\n",
      "episode 16, val func loss 6.284740924835205\n",
      "\n",
      "Val func train loss in epoch 14:6.462616056203842\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 6.655716896057129\n",
      "\n",
      "episode 2, val func loss 6.34677267074585\n",
      "\n",
      "episode 3, val func loss 6.433035373687744\n",
      "\n",
      "episode 4, val func loss 5.581479549407959\n",
      "\n",
      "episode 5, val func loss 6.274690628051758\n",
      "\n",
      "episode 6, val func loss 5.975509166717529\n",
      "\n",
      "episode 7, val func loss 6.564584732055664\n",
      "\n",
      "episode 8, val func loss 6.252140522003174\n",
      "\n",
      "episode 9, val func loss 6.457545757293701\n",
      "\n",
      "episode 10, val func loss 6.5898027420043945\n",
      "\n",
      "episode 11, val func loss 6.366579055786133\n",
      "\n",
      "episode 12, val func loss 6.587747573852539\n",
      "\n",
      "episode 13, val func loss 6.45619535446167\n",
      "\n",
      "episode 14, val func loss 6.593449115753174\n",
      "\n",
      "episode 15, val func loss 6.381552219390869\n",
      "\n",
      "episode 16, val func loss 6.46088981628418\n",
      "\n",
      "Val func train loss in epoch 15:6.373605698347092\n",
      "***********************TIME WAS 4.8818974455197655 min*****************************\n",
      "\n",
      "**********************ROUND 91 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.387706756591797\n",
      "\n",
      "episode 2, policy loss -3.3876874446868896\n",
      "\n",
      "episode 3, policy loss -3.3877410888671875\n",
      "\n",
      "episode 4, policy loss -3.3877387046813965\n",
      "\n",
      "episode 5, policy loss -3.3877687454223633\n",
      "\n",
      "episode 6, policy loss -3.387763023376465\n",
      "\n",
      "episode 7, policy loss -3.387808084487915\n",
      "\n",
      "episode 8, policy loss -3.3878424167633057\n",
      "\n",
      "episode 9, policy loss -3.387871742248535\n",
      "\n",
      "episode 10, policy loss -3.3878896236419678\n",
      "\n",
      "episode 11, policy loss -3.387924909591675\n",
      "\n",
      "episode 12, policy loss -3.387939691543579\n",
      "\n",
      "episode 13, policy loss -3.3879599571228027\n",
      "\n",
      "episode 14, policy loss -3.3879776000976562\n",
      "\n",
      "episode 15, policy loss -3.3880155086517334\n",
      "\n",
      "episode 16, policy loss -3.388033866882324\n",
      "\n",
      "Policy train loss in epoch 0:-3.3878543227910995\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.3880422115325928\n",
      "\n",
      "episode 2, policy loss -3.388046979904175\n",
      "\n",
      "episode 3, policy loss -3.388066053390503\n",
      "\n",
      "episode 4, policy loss -3.388092279434204\n",
      "\n",
      "episode 5, policy loss -3.388120651245117\n",
      "\n",
      "episode 6, policy loss -3.388123035430908\n",
      "\n",
      "episode 7, policy loss -3.3881473541259766\n",
      "\n",
      "episode 8, policy loss -3.3881618976593018\n",
      "\n",
      "episode 9, policy loss -3.388169765472412\n",
      "\n",
      "episode 10, policy loss -3.388178825378418\n",
      "\n",
      "episode 11, policy loss -3.388190269470215\n",
      "\n",
      "episode 12, policy loss -3.388200283050537\n",
      "\n",
      "episode 13, policy loss -3.3882064819335938\n",
      "\n",
      "episode 14, policy loss -3.3882148265838623\n",
      "\n",
      "episode 15, policy loss -3.388233184814453\n",
      "\n",
      "episode 16, policy loss -3.3882274627685547\n",
      "\n",
      "Policy train loss in epoch 1:-3.3881513476371765\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.388237714767456\n",
      "\n",
      "episode 2, policy loss -3.3882503509521484\n",
      "\n",
      "episode 3, policy loss -3.388254404067993\n",
      "\n",
      "episode 4, policy loss -3.3882558345794678\n",
      "\n",
      "episode 5, policy loss -3.38826584815979\n",
      "\n",
      "episode 6, policy loss -3.3882720470428467\n",
      "\n",
      "episode 7, policy loss -3.388275146484375\n",
      "\n",
      "episode 8, policy loss -3.3882832527160645\n",
      "\n",
      "episode 9, policy loss -3.3882832527160645\n",
      "\n",
      "episode 10, policy loss -3.388291835784912\n",
      "\n",
      "episode 11, policy loss -3.388291120529175\n",
      "\n",
      "episode 12, policy loss -3.3882977962493896\n",
      "\n",
      "episode 13, policy loss -3.388303756713867\n",
      "\n",
      "episode 14, policy loss -3.388310194015503\n",
      "\n",
      "episode 15, policy loss -3.3883070945739746\n",
      "\n",
      "episode 16, policy loss -3.3883137702941895\n",
      "\n",
      "Policy train loss in epoch 2:-3.388280838727951\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.3883183002471924\n",
      "\n",
      "episode 2, policy loss -3.3883209228515625\n",
      "\n",
      "episode 3, policy loss -3.3883216381073\n",
      "\n",
      "episode 4, policy loss -3.3883275985717773\n",
      "\n",
      "episode 5, policy loss -3.3883330821990967\n",
      "\n",
      "episode 6, policy loss -3.3883306980133057\n",
      "\n",
      "episode 7, policy loss -3.3883321285247803\n",
      "\n",
      "episode 8, policy loss -3.388335704803467\n",
      "\n",
      "episode 9, policy loss -3.3883397579193115\n",
      "\n",
      "episode 10, policy loss -3.388339042663574\n",
      "\n",
      "episode 11, policy loss -3.3883419036865234\n",
      "\n",
      "episode 12, policy loss -3.3883466720581055\n",
      "\n",
      "episode 13, policy loss -3.3883488178253174\n",
      "\n",
      "episode 14, policy loss -3.3883509635925293\n",
      "\n",
      "episode 15, policy loss -3.3883566856384277\n",
      "\n",
      "episode 16, policy loss -3.3883564472198486\n",
      "\n",
      "Policy train loss in epoch 3:-3.3883375227451324\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 7.465287685394287\n",
      "\n",
      "episode 2, val func loss 6.036271095275879\n",
      "\n",
      "episode 3, val func loss 3.2647545337677\n",
      "\n",
      "episode 4, val func loss 2.083954334259033\n",
      "\n",
      "episode 5, val func loss 4.594161510467529\n",
      "\n",
      "episode 6, val func loss 2.6107845306396484\n",
      "\n",
      "episode 7, val func loss 1.4283510446548462\n",
      "\n",
      "episode 8, val func loss 1.6912696361541748\n",
      "\n",
      "episode 9, val func loss 2.278832197189331\n",
      "\n",
      "episode 10, val func loss 2.203566789627075\n",
      "\n",
      "episode 11, val func loss 1.8042961359024048\n",
      "\n",
      "episode 12, val func loss 1.5005098581314087\n",
      "\n",
      "episode 13, val func loss 1.9080274105072021\n",
      "\n",
      "episode 14, val func loss 2.1116020679473877\n",
      "\n",
      "episode 15, val func loss 1.742915153503418\n",
      "\n",
      "episode 16, val func loss 1.6446715593338013\n",
      "\n",
      "Val func train loss in epoch 0:2.7730784714221954\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.565935730934143\n",
      "\n",
      "episode 2, val func loss 1.6285899877548218\n",
      "\n",
      "episode 3, val func loss 1.657594919204712\n",
      "\n",
      "episode 4, val func loss 1.7400325536727905\n",
      "\n",
      "episode 5, val func loss 1.6550363302230835\n",
      "\n",
      "episode 6, val func loss 1.623363733291626\n",
      "\n",
      "episode 7, val func loss 1.5596126317977905\n",
      "\n",
      "episode 8, val func loss 1.5159530639648438\n",
      "\n",
      "episode 9, val func loss 1.5357863903045654\n",
      "\n",
      "episode 10, val func loss 1.7015677690505981\n",
      "\n",
      "episode 11, val func loss 1.6061654090881348\n",
      "\n",
      "episode 12, val func loss 1.5568698644638062\n",
      "\n",
      "episode 13, val func loss 1.5751113891601562\n",
      "\n",
      "episode 14, val func loss 1.303842306137085\n",
      "\n",
      "episode 15, val func loss 1.4693527221679688\n",
      "\n",
      "episode 16, val func loss 1.5434924364089966\n",
      "\n",
      "Val func train loss in epoch 1:1.5773942023515701\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.426135540008545\n",
      "\n",
      "episode 2, val func loss 1.4026849269866943\n",
      "\n",
      "episode 3, val func loss 1.263508915901184\n",
      "\n",
      "episode 4, val func loss 1.4284770488739014\n",
      "\n",
      "episode 5, val func loss 1.2310160398483276\n",
      "\n",
      "episode 6, val func loss 1.4248664379119873\n",
      "\n",
      "episode 7, val func loss 1.610467553138733\n",
      "\n",
      "episode 8, val func loss 1.256422996520996\n",
      "\n",
      "episode 9, val func loss 1.3213449716567993\n",
      "\n",
      "episode 10, val func loss 1.3507461547851562\n",
      "\n",
      "episode 11, val func loss 1.2022361755371094\n",
      "\n",
      "episode 12, val func loss 1.2288079261779785\n",
      "\n",
      "episode 13, val func loss 1.3077726364135742\n",
      "\n",
      "episode 14, val func loss 1.4952770471572876\n",
      "\n",
      "episode 15, val func loss 1.271877646446228\n",
      "\n",
      "episode 16, val func loss 1.4431025981903076\n",
      "\n",
      "Val func train loss in epoch 2:1.3540465384721756\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.3450490236282349\n",
      "\n",
      "episode 2, val func loss 1.695906639099121\n",
      "\n",
      "episode 3, val func loss 1.3926942348480225\n",
      "\n",
      "episode 4, val func loss 1.4519550800323486\n",
      "\n",
      "episode 5, val func loss 1.591076135635376\n",
      "\n",
      "episode 6, val func loss 1.28056001663208\n",
      "\n",
      "episode 7, val func loss 1.1906566619873047\n",
      "\n",
      "episode 8, val func loss 1.139332890510559\n",
      "\n",
      "episode 9, val func loss 1.6073824167251587\n",
      "\n",
      "episode 10, val func loss 1.23918879032135\n",
      "\n",
      "episode 11, val func loss 1.3392343521118164\n",
      "\n",
      "episode 12, val func loss 1.218732237815857\n",
      "\n",
      "episode 13, val func loss 1.5261818170547485\n",
      "\n",
      "episode 14, val func loss 1.283596396446228\n",
      "\n",
      "episode 15, val func loss 1.4515268802642822\n",
      "\n",
      "episode 16, val func loss 1.330609679222107\n",
      "\n",
      "Val func train loss in epoch 3:1.3802302032709122\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.3245432376861572\n",
      "\n",
      "episode 2, val func loss 1.3587305545806885\n",
      "\n",
      "episode 3, val func loss 1.3980891704559326\n",
      "\n",
      "episode 4, val func loss 1.540919303894043\n",
      "\n",
      "episode 5, val func loss 1.2370105981826782\n",
      "\n",
      "episode 6, val func loss 1.128516435623169\n",
      "\n",
      "episode 7, val func loss 1.2209810018539429\n",
      "\n",
      "episode 8, val func loss 1.2712619304656982\n",
      "\n",
      "episode 9, val func loss 1.2449909448623657\n",
      "\n",
      "episode 10, val func loss 1.2955877780914307\n",
      "\n",
      "episode 11, val func loss 1.2153831720352173\n",
      "\n",
      "episode 12, val func loss 1.315118432044983\n",
      "\n",
      "episode 13, val func loss 1.4256961345672607\n",
      "\n",
      "episode 14, val func loss 1.4393030405044556\n",
      "\n",
      "episode 15, val func loss 1.3421790599822998\n",
      "\n",
      "episode 16, val func loss 1.355497121810913\n",
      "\n",
      "Val func train loss in epoch 4:1.3196129947900772\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.5116759538650513\n",
      "\n",
      "episode 2, val func loss 1.4224042892456055\n",
      "\n",
      "episode 3, val func loss 1.4693305492401123\n",
      "\n",
      "episode 4, val func loss 1.3139774799346924\n",
      "\n",
      "episode 5, val func loss 1.3973740339279175\n",
      "\n",
      "episode 6, val func loss 1.4109957218170166\n",
      "\n",
      "episode 7, val func loss 1.4671905040740967\n",
      "\n",
      "episode 8, val func loss 1.4784605503082275\n",
      "\n",
      "episode 9, val func loss 1.1422934532165527\n",
      "\n",
      "episode 10, val func loss 1.301697015762329\n",
      "\n",
      "episode 11, val func loss 1.332005262374878\n",
      "\n",
      "episode 12, val func loss 1.5051323175430298\n",
      "\n",
      "episode 13, val func loss 1.2651159763336182\n",
      "\n",
      "episode 14, val func loss 1.3226319551467896\n",
      "\n",
      "episode 15, val func loss 1.3795993328094482\n",
      "\n",
      "episode 16, val func loss 1.2156896591186523\n",
      "\n",
      "Val func train loss in epoch 5:1.370973378419876\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.2570350170135498\n",
      "\n",
      "episode 2, val func loss 1.4259209632873535\n",
      "\n",
      "episode 3, val func loss 1.363673210144043\n",
      "\n",
      "episode 4, val func loss 1.444530725479126\n",
      "\n",
      "episode 5, val func loss 1.2900153398513794\n",
      "\n",
      "episode 6, val func loss 1.2350012063980103\n",
      "\n",
      "episode 7, val func loss 1.3335014581680298\n",
      "\n",
      "episode 8, val func loss 1.3323644399642944\n",
      "\n",
      "episode 9, val func loss 1.2895855903625488\n",
      "\n",
      "episode 10, val func loss 1.3764901161193848\n",
      "\n",
      "episode 11, val func loss 1.3074252605438232\n",
      "\n",
      "episode 12, val func loss 1.268790602684021\n",
      "\n",
      "episode 13, val func loss 1.281856656074524\n",
      "\n",
      "episode 14, val func loss 1.2796317338943481\n",
      "\n",
      "episode 15, val func loss 1.3848909139633179\n",
      "\n",
      "episode 16, val func loss 1.4540209770202637\n",
      "\n",
      "Val func train loss in epoch 6:1.332795888185501\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.4947830438613892\n",
      "\n",
      "episode 2, val func loss 1.1596148014068604\n",
      "\n",
      "episode 3, val func loss 1.3209092617034912\n",
      "\n",
      "episode 4, val func loss 1.3671619892120361\n",
      "\n",
      "episode 5, val func loss 1.3435243368148804\n",
      "\n",
      "episode 6, val func loss 1.3277369737625122\n",
      "\n",
      "episode 7, val func loss 1.3427735567092896\n",
      "\n",
      "episode 8, val func loss 1.3026783466339111\n",
      "\n",
      "episode 9, val func loss 1.3150380849838257\n",
      "\n",
      "episode 10, val func loss 1.3872209787368774\n",
      "\n",
      "episode 11, val func loss 1.2311294078826904\n",
      "\n",
      "episode 12, val func loss 1.3145695924758911\n",
      "\n",
      "episode 13, val func loss 1.2144581079483032\n",
      "\n",
      "episode 14, val func loss 1.3393230438232422\n",
      "\n",
      "episode 15, val func loss 1.3191170692443848\n",
      "\n",
      "episode 16, val func loss 1.3959062099456787\n",
      "\n",
      "Val func train loss in epoch 7:1.323496550321579\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.1314395666122437\n",
      "\n",
      "episode 2, val func loss 1.0621721744537354\n",
      "\n",
      "episode 3, val func loss 1.3025894165039062\n",
      "\n",
      "episode 4, val func loss 1.174035906791687\n",
      "\n",
      "episode 5, val func loss 1.3541892766952515\n",
      "\n",
      "episode 6, val func loss 1.3699957132339478\n",
      "\n",
      "episode 7, val func loss 1.2098116874694824\n",
      "\n",
      "episode 8, val func loss 1.3795130252838135\n",
      "\n",
      "episode 9, val func loss 1.2723098993301392\n",
      "\n",
      "episode 10, val func loss 1.4786523580551147\n",
      "\n",
      "episode 11, val func loss 1.1779619455337524\n",
      "\n",
      "episode 12, val func loss 1.1454439163208008\n",
      "\n",
      "episode 13, val func loss 1.3477649688720703\n",
      "\n",
      "episode 14, val func loss 1.3169549703598022\n",
      "\n",
      "episode 15, val func loss 1.165152907371521\n",
      "\n",
      "episode 16, val func loss 1.1657376289367676\n",
      "\n",
      "Val func train loss in epoch 8:1.2533578351140022\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.257369041442871\n",
      "\n",
      "episode 2, val func loss 1.1764006614685059\n",
      "\n",
      "episode 3, val func loss 1.162699818611145\n",
      "\n",
      "episode 4, val func loss 1.1075217723846436\n",
      "\n",
      "episode 5, val func loss 1.405995488166809\n",
      "\n",
      "episode 6, val func loss 1.2744373083114624\n",
      "\n",
      "episode 7, val func loss 1.1194825172424316\n",
      "\n",
      "episode 8, val func loss 1.2847894430160522\n",
      "\n",
      "episode 9, val func loss 1.5024430751800537\n",
      "\n",
      "episode 10, val func loss 1.2146586179733276\n",
      "\n",
      "episode 11, val func loss 0.9408881068229675\n",
      "\n",
      "episode 12, val func loss 1.2026147842407227\n",
      "\n",
      "episode 13, val func loss 1.2845056056976318\n",
      "\n",
      "episode 14, val func loss 1.3810480833053589\n",
      "\n",
      "episode 15, val func loss 1.3441059589385986\n",
      "\n",
      "episode 16, val func loss 1.3747999668121338\n",
      "\n",
      "Val func train loss in epoch 9:1.2521100156009197\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.318989872932434\n",
      "\n",
      "episode 2, val func loss 1.246444582939148\n",
      "\n",
      "episode 3, val func loss 1.1989387273788452\n",
      "\n",
      "episode 4, val func loss 1.5132925510406494\n",
      "\n",
      "episode 5, val func loss 1.299875020980835\n",
      "\n",
      "episode 6, val func loss 1.5401684045791626\n",
      "\n",
      "episode 7, val func loss 1.2935514450073242\n",
      "\n",
      "episode 8, val func loss 1.2163965702056885\n",
      "\n",
      "episode 9, val func loss 1.341066598892212\n",
      "\n",
      "episode 10, val func loss 1.2604190111160278\n",
      "\n",
      "episode 11, val func loss 1.2126777172088623\n",
      "\n",
      "episode 12, val func loss 1.4598524570465088\n",
      "\n",
      "episode 13, val func loss 1.3411766290664673\n",
      "\n",
      "episode 14, val func loss 1.1305941343307495\n",
      "\n",
      "episode 15, val func loss 1.1525198221206665\n",
      "\n",
      "episode 16, val func loss 1.2345629930496216\n",
      "\n",
      "Val func train loss in epoch 10:1.2975329086184502\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.276970386505127\n",
      "\n",
      "episode 2, val func loss 1.3615738153457642\n",
      "\n",
      "episode 3, val func loss 1.2784360647201538\n",
      "\n",
      "episode 4, val func loss 1.3475714921951294\n",
      "\n",
      "episode 5, val func loss 1.5052235126495361\n",
      "\n",
      "episode 6, val func loss 1.1883107423782349\n",
      "\n",
      "episode 7, val func loss 1.2255158424377441\n",
      "\n",
      "episode 8, val func loss 1.2692341804504395\n",
      "\n",
      "episode 9, val func loss 1.2604957818984985\n",
      "\n",
      "episode 10, val func loss 1.3024030923843384\n",
      "\n",
      "episode 11, val func loss 1.1825464963912964\n",
      "\n",
      "episode 12, val func loss 1.252281904220581\n",
      "\n",
      "episode 13, val func loss 1.2243866920471191\n",
      "\n",
      "episode 14, val func loss 1.3407647609710693\n",
      "\n",
      "episode 15, val func loss 1.1907743215560913\n",
      "\n",
      "episode 16, val func loss 1.1615736484527588\n",
      "\n",
      "Val func train loss in epoch 11:1.2730039209127426\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.3637237548828125\n",
      "\n",
      "episode 2, val func loss 1.311242699623108\n",
      "\n",
      "episode 3, val func loss 1.2005935907363892\n",
      "\n",
      "episode 4, val func loss 1.224813461303711\n",
      "\n",
      "episode 5, val func loss 1.1280592679977417\n",
      "\n",
      "episode 6, val func loss 0.9836857914924622\n",
      "\n",
      "episode 7, val func loss 1.6970748901367188\n",
      "\n",
      "episode 8, val func loss 1.2707829475402832\n",
      "\n",
      "episode 9, val func loss 1.1425707340240479\n",
      "\n",
      "episode 10, val func loss 1.4034504890441895\n",
      "\n",
      "episode 11, val func loss 1.2757136821746826\n",
      "\n",
      "episode 12, val func loss 1.2081719636917114\n",
      "\n",
      "episode 13, val func loss 1.290547251701355\n",
      "\n",
      "episode 14, val func loss 1.2988275289535522\n",
      "\n",
      "episode 15, val func loss 1.374233365058899\n",
      "\n",
      "episode 16, val func loss 1.3485321998596191\n",
      "\n",
      "Val func train loss in epoch 12:1.2826264761388302\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.3658615350723267\n",
      "\n",
      "episode 2, val func loss 1.3369033336639404\n",
      "\n",
      "episode 3, val func loss 1.1394261121749878\n",
      "\n",
      "episode 4, val func loss 1.2944004535675049\n",
      "\n",
      "episode 5, val func loss 1.1089401245117188\n",
      "\n",
      "episode 6, val func loss 1.1603761911392212\n",
      "\n",
      "episode 7, val func loss 1.2551933526992798\n",
      "\n",
      "episode 8, val func loss 1.3853808641433716\n",
      "\n",
      "episode 9, val func loss 1.2033694982528687\n",
      "\n",
      "episode 10, val func loss 1.5807439088821411\n",
      "\n",
      "episode 11, val func loss 1.3917171955108643\n",
      "\n",
      "episode 12, val func loss 1.3174148797988892\n",
      "\n",
      "episode 13, val func loss 1.1031184196472168\n",
      "\n",
      "episode 14, val func loss 1.3646690845489502\n",
      "\n",
      "episode 15, val func loss 1.4172502756118774\n",
      "\n",
      "episode 16, val func loss 1.2218005657196045\n",
      "\n",
      "Val func train loss in epoch 13:1.2904103621840477\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.1331727504730225\n",
      "\n",
      "episode 2, val func loss 1.3554191589355469\n",
      "\n",
      "episode 3, val func loss 1.3356554508209229\n",
      "\n",
      "episode 4, val func loss 1.1782677173614502\n",
      "\n",
      "episode 5, val func loss 1.2323039770126343\n",
      "\n",
      "episode 6, val func loss 1.3999693393707275\n",
      "\n",
      "episode 7, val func loss 1.3455556631088257\n",
      "\n",
      "episode 8, val func loss 1.374807596206665\n",
      "\n",
      "episode 9, val func loss 1.1727286577224731\n",
      "\n",
      "episode 10, val func loss 1.32975435256958\n",
      "\n",
      "episode 11, val func loss 1.2811508178710938\n",
      "\n",
      "episode 12, val func loss 1.187031865119934\n",
      "\n",
      "episode 13, val func loss 1.325330138206482\n",
      "\n",
      "episode 14, val func loss 1.2785180807113647\n",
      "\n",
      "episode 15, val func loss 1.2823398113250732\n",
      "\n",
      "episode 16, val func loss 1.1794506311416626\n",
      "\n",
      "Val func train loss in epoch 14:1.2744660004973412\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.377716302871704\n",
      "\n",
      "episode 2, val func loss 1.2640048265457153\n",
      "\n",
      "episode 3, val func loss 1.415295124053955\n",
      "\n",
      "episode 4, val func loss 1.2234355211257935\n",
      "\n",
      "episode 5, val func loss 1.3277702331542969\n",
      "\n",
      "episode 6, val func loss 1.268820881843567\n",
      "\n",
      "episode 7, val func loss 1.4676085710525513\n",
      "\n",
      "episode 8, val func loss 1.282159686088562\n",
      "\n",
      "episode 9, val func loss 1.2503310441970825\n",
      "\n",
      "episode 10, val func loss 1.3329236507415771\n",
      "\n",
      "episode 11, val func loss 1.2956874370574951\n",
      "\n",
      "episode 12, val func loss 1.2213693857192993\n",
      "\n",
      "episode 13, val func loss 1.3692485094070435\n",
      "\n",
      "episode 14, val func loss 1.2060801982879639\n",
      "\n",
      "episode 15, val func loss 1.1859341859817505\n",
      "\n",
      "episode 16, val func loss 1.475364089012146\n",
      "\n",
      "Val func train loss in epoch 15:1.3102343529462814\n",
      "***********************TIME WAS 4.878002830346426 min*****************************\n",
      "\n",
      "**********************ROUND 92 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.2167563438415527\n",
      "\n",
      "episode 2, policy loss -3.2167561054229736\n",
      "\n",
      "episode 3, policy loss -3.216761827468872\n",
      "\n",
      "episode 4, policy loss -3.216761350631714\n",
      "\n",
      "episode 5, policy loss -3.216764450073242\n",
      "\n",
      "episode 6, policy loss -3.216763973236084\n",
      "\n",
      "episode 7, policy loss -3.216768980026245\n",
      "\n",
      "episode 8, policy loss -3.216766357421875\n",
      "\n",
      "episode 9, policy loss -3.216771364212036\n",
      "\n",
      "episode 10, policy loss -3.21677303314209\n",
      "\n",
      "episode 11, policy loss -3.216773748397827\n",
      "\n",
      "episode 12, policy loss -3.216775417327881\n",
      "\n",
      "episode 13, policy loss -3.2167751789093018\n",
      "\n",
      "episode 14, policy loss -3.216777801513672\n",
      "\n",
      "episode 15, policy loss -3.2167789936065674\n",
      "\n",
      "episode 16, policy loss -3.216782331466675\n",
      "\n",
      "Policy train loss in epoch 0:-3.216769203543663\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.2167809009552\n",
      "\n",
      "episode 2, policy loss -3.216783046722412\n",
      "\n",
      "episode 3, policy loss -3.2167866230010986\n",
      "\n",
      "episode 4, policy loss -3.2167868614196777\n",
      "\n",
      "episode 5, policy loss -3.216787576675415\n",
      "\n",
      "episode 6, policy loss -3.2167880535125732\n",
      "\n",
      "episode 7, policy loss -3.2167892456054688\n",
      "\n",
      "episode 8, policy loss -3.216792106628418\n",
      "\n",
      "episode 9, policy loss -3.216792106628418\n",
      "\n",
      "episode 10, policy loss -3.2167913913726807\n",
      "\n",
      "episode 11, policy loss -3.216794967651367\n",
      "\n",
      "episode 12, policy loss -3.2167937755584717\n",
      "\n",
      "episode 13, policy loss -3.2167975902557373\n",
      "\n",
      "episode 14, policy loss -3.2167975902557373\n",
      "\n",
      "episode 15, policy loss -3.216798782348633\n",
      "\n",
      "episode 16, policy loss -3.216799020767212\n",
      "\n",
      "Policy train loss in epoch 1:-3.2167912274599075\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.216799736022949\n",
      "\n",
      "episode 2, policy loss -3.2168006896972656\n",
      "\n",
      "episode 3, policy loss -3.216801166534424\n",
      "\n",
      "episode 4, policy loss -3.216803789138794\n",
      "\n",
      "episode 5, policy loss -3.216803789138794\n",
      "\n",
      "episode 6, policy loss -3.2168049812316895\n",
      "\n",
      "episode 7, policy loss -3.216805934906006\n",
      "\n",
      "episode 8, policy loss -3.216805934906006\n",
      "\n",
      "episode 9, policy loss -3.2168073654174805\n",
      "\n",
      "episode 10, policy loss -3.2168080806732178\n",
      "\n",
      "episode 11, policy loss -3.2168076038360596\n",
      "\n",
      "episode 12, policy loss -3.2168095111846924\n",
      "\n",
      "episode 13, policy loss -3.2168102264404297\n",
      "\n",
      "episode 14, policy loss -3.216810941696167\n",
      "\n",
      "episode 15, policy loss -3.2168095111846924\n",
      "\n",
      "episode 16, policy loss -3.216811418533325\n",
      "\n",
      "Policy train loss in epoch 2:-3.2168062925338745\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.216813325881958\n",
      "\n",
      "episode 2, policy loss -3.216813564300537\n",
      "\n",
      "episode 3, policy loss -3.2168142795562744\n",
      "\n",
      "episode 4, policy loss -3.2168140411376953\n",
      "\n",
      "episode 5, policy loss -3.216815710067749\n",
      "\n",
      "episode 6, policy loss -3.216815710067749\n",
      "\n",
      "episode 7, policy loss -3.216815233230591\n",
      "\n",
      "episode 8, policy loss -3.216815948486328\n",
      "\n",
      "episode 9, policy loss -3.2168166637420654\n",
      "\n",
      "episode 10, policy loss -3.2168171405792236\n",
      "\n",
      "episode 11, policy loss -3.2168171405792236\n",
      "\n",
      "episode 12, policy loss -3.2168190479278564\n",
      "\n",
      "episode 13, policy loss -3.2168188095092773\n",
      "\n",
      "episode 14, policy loss -3.2168190479278564\n",
      "\n",
      "episode 15, policy loss -3.2168197631835938\n",
      "\n",
      "episode 16, policy loss -3.216820478439331\n",
      "\n",
      "Policy train loss in epoch 3:-3.216816619038582\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.2091317176818848\n",
      "\n",
      "episode 2, val func loss 1.340763807296753\n",
      "\n",
      "episode 3, val func loss 1.209885835647583\n",
      "\n",
      "episode 4, val func loss 1.2979646921157837\n",
      "\n",
      "episode 5, val func loss 1.3433281183242798\n",
      "\n",
      "episode 6, val func loss 1.2893650531768799\n",
      "\n",
      "episode 7, val func loss 1.175965666770935\n",
      "\n",
      "episode 8, val func loss 1.1759929656982422\n",
      "\n",
      "episode 9, val func loss 1.2231266498565674\n",
      "\n",
      "episode 10, val func loss 1.3314404487609863\n",
      "\n",
      "episode 11, val func loss 1.347920298576355\n",
      "\n",
      "episode 12, val func loss 1.3878145217895508\n",
      "\n",
      "episode 13, val func loss 1.2753311395645142\n",
      "\n",
      "episode 14, val func loss 1.1917493343353271\n",
      "\n",
      "episode 15, val func loss 1.3182178735733032\n",
      "\n",
      "episode 16, val func loss 1.2140631675720215\n",
      "\n",
      "Val func train loss in epoch 0:1.2707538306713104\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.0666254758834839\n",
      "\n",
      "episode 2, val func loss 1.2020502090454102\n",
      "\n",
      "episode 3, val func loss 1.1706302165985107\n",
      "\n",
      "episode 4, val func loss 1.1655924320220947\n",
      "\n",
      "episode 5, val func loss 1.4762539863586426\n",
      "\n",
      "episode 6, val func loss 1.1467115879058838\n",
      "\n",
      "episode 7, val func loss 1.1342904567718506\n",
      "\n",
      "episode 8, val func loss 1.1593395471572876\n",
      "\n",
      "episode 9, val func loss 1.2413288354873657\n",
      "\n",
      "episode 10, val func loss 1.3175498247146606\n",
      "\n",
      "episode 11, val func loss 1.1984401941299438\n",
      "\n",
      "episode 12, val func loss 1.4042155742645264\n",
      "\n",
      "episode 13, val func loss 1.240196704864502\n",
      "\n",
      "episode 14, val func loss 1.386375904083252\n",
      "\n",
      "episode 15, val func loss 1.4534072875976562\n",
      "\n",
      "episode 16, val func loss 1.099997639656067\n",
      "\n",
      "Val func train loss in epoch 1:1.241437867283821\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.32847261428833\n",
      "\n",
      "episode 2, val func loss 1.2517460584640503\n",
      "\n",
      "episode 3, val func loss 1.3057438135147095\n",
      "\n",
      "episode 4, val func loss 1.298604965209961\n",
      "\n",
      "episode 5, val func loss 1.112732172012329\n",
      "\n",
      "episode 6, val func loss 1.252743124961853\n",
      "\n",
      "episode 7, val func loss 1.198923110961914\n",
      "\n",
      "episode 8, val func loss 1.3004429340362549\n",
      "\n",
      "episode 9, val func loss 1.2501460313796997\n",
      "\n",
      "episode 10, val func loss 1.1497184038162231\n",
      "\n",
      "episode 11, val func loss 1.2169668674468994\n",
      "\n",
      "episode 12, val func loss 1.3486758470535278\n",
      "\n",
      "episode 13, val func loss 1.2906595468521118\n",
      "\n",
      "episode 14, val func loss 1.326119303703308\n",
      "\n",
      "episode 15, val func loss 1.1587681770324707\n",
      "\n",
      "episode 16, val func loss 1.247065544128418\n",
      "\n",
      "Val func train loss in epoch 2:1.2523455321788788\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.2697559595108032\n",
      "\n",
      "episode 2, val func loss 1.2303653955459595\n",
      "\n",
      "episode 3, val func loss 1.2012301683425903\n",
      "\n",
      "episode 4, val func loss 1.2590036392211914\n",
      "\n",
      "episode 5, val func loss 1.0125426054000854\n",
      "\n",
      "episode 6, val func loss 1.322064995765686\n",
      "\n",
      "episode 7, val func loss 1.2157224416732788\n",
      "\n",
      "episode 8, val func loss 1.340293049812317\n",
      "\n",
      "episode 9, val func loss 1.0828946828842163\n",
      "\n",
      "episode 10, val func loss 1.156406044960022\n",
      "\n",
      "episode 11, val func loss 1.1633834838867188\n",
      "\n",
      "episode 12, val func loss 1.2726283073425293\n",
      "\n",
      "episode 13, val func loss 1.2329106330871582\n",
      "\n",
      "episode 14, val func loss 1.0925480127334595\n",
      "\n",
      "episode 15, val func loss 1.2007404565811157\n",
      "\n",
      "episode 16, val func loss 1.3447730541229248\n",
      "\n",
      "Val func train loss in epoch 3:1.2123289331793785\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.103840947151184\n",
      "\n",
      "episode 2, val func loss 1.5125374794006348\n",
      "\n",
      "episode 3, val func loss 1.3367631435394287\n",
      "\n",
      "episode 4, val func loss 1.2712725400924683\n",
      "\n",
      "episode 5, val func loss 1.2479583024978638\n",
      "\n",
      "episode 6, val func loss 1.3550504446029663\n",
      "\n",
      "episode 7, val func loss 1.0993740558624268\n",
      "\n",
      "episode 8, val func loss 1.0357081890106201\n",
      "\n",
      "episode 9, val func loss 1.1771094799041748\n",
      "\n",
      "episode 10, val func loss 1.2033066749572754\n",
      "\n",
      "episode 11, val func loss 1.06394362449646\n",
      "\n",
      "episode 12, val func loss 1.2766915559768677\n",
      "\n",
      "episode 13, val func loss 1.1383951902389526\n",
      "\n",
      "episode 14, val func loss 1.260127305984497\n",
      "\n",
      "episode 15, val func loss 1.236295223236084\n",
      "\n",
      "episode 16, val func loss 1.190160870552063\n",
      "\n",
      "Val func train loss in epoch 4:1.219283439218998\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.3416616916656494\n",
      "\n",
      "episode 2, val func loss 1.2443324327468872\n",
      "\n",
      "episode 3, val func loss 1.129941463470459\n",
      "\n",
      "episode 4, val func loss 1.4903866052627563\n",
      "\n",
      "episode 5, val func loss 1.1555819511413574\n",
      "\n",
      "episode 6, val func loss 1.2656301259994507\n",
      "\n",
      "episode 7, val func loss 1.2598103284835815\n",
      "\n",
      "episode 8, val func loss 1.1618632078170776\n",
      "\n",
      "episode 9, val func loss 1.4780668020248413\n",
      "\n",
      "episode 10, val func loss 1.2276917695999146\n",
      "\n",
      "episode 11, val func loss 1.3229886293411255\n",
      "\n",
      "episode 12, val func loss 1.1439836025238037\n",
      "\n",
      "episode 13, val func loss 1.3053218126296997\n",
      "\n",
      "episode 14, val func loss 1.2906354665756226\n",
      "\n",
      "episode 15, val func loss 1.2178149223327637\n",
      "\n",
      "episode 16, val func loss 1.142358422279358\n",
      "\n",
      "Val func train loss in epoch 5:1.2611293271183968\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.2579642534255981\n",
      "\n",
      "episode 2, val func loss 1.2048133611679077\n",
      "\n",
      "episode 3, val func loss 1.2501657009124756\n",
      "\n",
      "episode 4, val func loss 1.2870787382125854\n",
      "\n",
      "episode 5, val func loss 1.4208569526672363\n",
      "\n",
      "episode 6, val func loss 1.1235400438308716\n",
      "\n",
      "episode 7, val func loss 1.2731136083602905\n",
      "\n",
      "episode 8, val func loss 1.199679970741272\n",
      "\n",
      "episode 9, val func loss 1.218991994857788\n",
      "\n",
      "episode 10, val func loss 1.3577938079833984\n",
      "\n",
      "episode 11, val func loss 1.3836458921432495\n",
      "\n",
      "episode 12, val func loss 1.141277551651001\n",
      "\n",
      "episode 13, val func loss 1.2036678791046143\n",
      "\n",
      "episode 14, val func loss 1.1797195672988892\n",
      "\n",
      "episode 15, val func loss 1.230839490890503\n",
      "\n",
      "episode 16, val func loss 1.1246203184127808\n",
      "\n",
      "Val func train loss in epoch 6:1.2411105707287788\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.2888869047164917\n",
      "\n",
      "episode 2, val func loss 1.0947296619415283\n",
      "\n",
      "episode 3, val func loss 1.0542370080947876\n",
      "\n",
      "episode 4, val func loss 1.3070977926254272\n",
      "\n",
      "episode 5, val func loss 1.2355645895004272\n",
      "\n",
      "episode 6, val func loss 1.3180464506149292\n",
      "\n",
      "episode 7, val func loss 1.3353554010391235\n",
      "\n",
      "episode 8, val func loss 1.0512155294418335\n",
      "\n",
      "episode 9, val func loss 1.390960931777954\n",
      "\n",
      "episode 10, val func loss 1.0824077129364014\n",
      "\n",
      "episode 11, val func loss 1.259608507156372\n",
      "\n",
      "episode 12, val func loss 1.3743547201156616\n",
      "\n",
      "episode 13, val func loss 1.32383394241333\n",
      "\n",
      "episode 14, val func loss 1.3515759706497192\n",
      "\n",
      "episode 15, val func loss 1.0768826007843018\n",
      "\n",
      "episode 16, val func loss 1.1211954355239868\n",
      "\n",
      "Val func train loss in epoch 7:1.2291220724582672\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.3913544416427612\n",
      "\n",
      "episode 2, val func loss 1.2205437421798706\n",
      "\n",
      "episode 3, val func loss 1.290109634399414\n",
      "\n",
      "episode 4, val func loss 1.3467059135437012\n",
      "\n",
      "episode 5, val func loss 1.3615399599075317\n",
      "\n",
      "episode 6, val func loss 1.2622734308242798\n",
      "\n",
      "episode 7, val func loss 1.2207094430923462\n",
      "\n",
      "episode 8, val func loss 1.073036789894104\n",
      "\n",
      "episode 9, val func loss 1.1099052429199219\n",
      "\n",
      "episode 10, val func loss 1.4445087909698486\n",
      "\n",
      "episode 11, val func loss 1.294826626777649\n",
      "\n",
      "episode 12, val func loss 1.1829464435577393\n",
      "\n",
      "episode 13, val func loss 1.1746466159820557\n",
      "\n",
      "episode 14, val func loss 1.0852570533752441\n",
      "\n",
      "episode 15, val func loss 1.3142919540405273\n",
      "\n",
      "episode 16, val func loss 1.0066072940826416\n",
      "\n",
      "Val func train loss in epoch 8:1.2362039610743523\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.3035966157913208\n",
      "\n",
      "episode 2, val func loss 1.1861048936843872\n",
      "\n",
      "episode 3, val func loss 1.0418038368225098\n",
      "\n",
      "episode 4, val func loss 1.2088454961776733\n",
      "\n",
      "episode 5, val func loss 1.3878235816955566\n",
      "\n",
      "episode 6, val func loss 1.2603651285171509\n",
      "\n",
      "episode 7, val func loss 1.2271987199783325\n",
      "\n",
      "episode 8, val func loss 1.1648379564285278\n",
      "\n",
      "episode 9, val func loss 1.2828131914138794\n",
      "\n",
      "episode 10, val func loss 1.287468433380127\n",
      "\n",
      "episode 11, val func loss 1.4089909791946411\n",
      "\n",
      "episode 12, val func loss 1.214758038520813\n",
      "\n",
      "episode 13, val func loss 1.3383500576019287\n",
      "\n",
      "episode 14, val func loss 1.1999224424362183\n",
      "\n",
      "episode 15, val func loss 1.0830585956573486\n",
      "\n",
      "episode 16, val func loss 1.1798925399780273\n",
      "\n",
      "Val func train loss in epoch 9:1.2359894067049026\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.293120265007019\n",
      "\n",
      "episode 2, val func loss 1.1816102266311646\n",
      "\n",
      "episode 3, val func loss 1.3049590587615967\n",
      "\n",
      "episode 4, val func loss 1.120945930480957\n",
      "\n",
      "episode 5, val func loss 1.1501940488815308\n",
      "\n",
      "episode 6, val func loss 1.2091530561447144\n",
      "\n",
      "episode 7, val func loss 1.1961580514907837\n",
      "\n",
      "episode 8, val func loss 1.1694682836532593\n",
      "\n",
      "episode 9, val func loss 1.2358438968658447\n",
      "\n",
      "episode 10, val func loss 1.1677210330963135\n",
      "\n",
      "episode 11, val func loss 1.179510474205017\n",
      "\n",
      "episode 12, val func loss 1.337822675704956\n",
      "\n",
      "episode 13, val func loss 0.976859986782074\n",
      "\n",
      "episode 14, val func loss 1.223683476448059\n",
      "\n",
      "episode 15, val func loss 1.2696009874343872\n",
      "\n",
      "episode 16, val func loss 1.2539292573928833\n",
      "\n",
      "Val func train loss in epoch 10:1.204411294311285\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.1468175649642944\n",
      "\n",
      "episode 2, val func loss 1.268446683883667\n",
      "\n",
      "episode 3, val func loss 1.2068967819213867\n",
      "\n",
      "episode 4, val func loss 1.1799442768096924\n",
      "\n",
      "episode 5, val func loss 1.2054502964019775\n",
      "\n",
      "episode 6, val func loss 1.28545081615448\n",
      "\n",
      "episode 7, val func loss 1.1474348306655884\n",
      "\n",
      "episode 8, val func loss 1.2360551357269287\n",
      "\n",
      "episode 9, val func loss 1.2522326707839966\n",
      "\n",
      "episode 10, val func loss 1.2424715757369995\n",
      "\n",
      "episode 11, val func loss 1.0305705070495605\n",
      "\n",
      "episode 12, val func loss 1.2857239246368408\n",
      "\n",
      "episode 13, val func loss 1.1362210512161255\n",
      "\n",
      "episode 14, val func loss 1.3135868310928345\n",
      "\n",
      "episode 15, val func loss 1.2519259452819824\n",
      "\n",
      "episode 16, val func loss 1.0162277221679688\n",
      "\n",
      "Val func train loss in epoch 11:1.2003410384058952\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.2691993713378906\n",
      "\n",
      "episode 2, val func loss 1.1649025678634644\n",
      "\n",
      "episode 3, val func loss 1.1121553182601929\n",
      "\n",
      "episode 4, val func loss 1.1557796001434326\n",
      "\n",
      "episode 5, val func loss 1.0651453733444214\n",
      "\n",
      "episode 6, val func loss 1.1917173862457275\n",
      "\n",
      "episode 7, val func loss 1.1951581239700317\n",
      "\n",
      "episode 8, val func loss 1.0997008085250854\n",
      "\n",
      "episode 9, val func loss 1.3399937152862549\n",
      "\n",
      "episode 10, val func loss 1.173048496246338\n",
      "\n",
      "episode 11, val func loss 1.384810447692871\n",
      "\n",
      "episode 12, val func loss 1.1705931425094604\n",
      "\n",
      "episode 13, val func loss 1.2596439123153687\n",
      "\n",
      "episode 14, val func loss 1.2399954795837402\n",
      "\n",
      "episode 15, val func loss 1.1820200681686401\n",
      "\n",
      "episode 16, val func loss 1.1274405717849731\n",
      "\n",
      "Val func train loss in epoch 12:1.1957065239548683\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.3533756732940674\n",
      "\n",
      "episode 2, val func loss 1.1232128143310547\n",
      "\n",
      "episode 3, val func loss 1.0929542779922485\n",
      "\n",
      "episode 4, val func loss 1.2108248472213745\n",
      "\n",
      "episode 5, val func loss 1.2518410682678223\n",
      "\n",
      "episode 6, val func loss 1.4300304651260376\n",
      "\n",
      "episode 7, val func loss 1.1945685148239136\n",
      "\n",
      "episode 8, val func loss 1.1893290281295776\n",
      "\n",
      "episode 9, val func loss 1.127463698387146\n",
      "\n",
      "episode 10, val func loss 1.296906590461731\n",
      "\n",
      "episode 11, val func loss 1.2431765794754028\n",
      "\n",
      "episode 12, val func loss 1.0879451036453247\n",
      "\n",
      "episode 13, val func loss 1.4185158014297485\n",
      "\n",
      "episode 14, val func loss 1.1483341455459595\n",
      "\n",
      "episode 15, val func loss 1.1285983324050903\n",
      "\n",
      "episode 16, val func loss 1.3812252283096313\n",
      "\n",
      "Val func train loss in epoch 13:1.2298938855528831\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.385869026184082\n",
      "\n",
      "episode 2, val func loss 1.275117039680481\n",
      "\n",
      "episode 3, val func loss 1.2619092464447021\n",
      "\n",
      "episode 4, val func loss 1.1177973747253418\n",
      "\n",
      "episode 5, val func loss 1.1778411865234375\n",
      "\n",
      "episode 6, val func loss 1.1686406135559082\n",
      "\n",
      "episode 7, val func loss 1.1443480253219604\n",
      "\n",
      "episode 8, val func loss 1.3397979736328125\n",
      "\n",
      "episode 9, val func loss 1.269545078277588\n",
      "\n",
      "episode 10, val func loss 1.112790822982788\n",
      "\n",
      "episode 11, val func loss 1.1351804733276367\n",
      "\n",
      "episode 12, val func loss 1.226374864578247\n",
      "\n",
      "episode 13, val func loss 1.2576463222503662\n",
      "\n",
      "episode 14, val func loss 1.2743644714355469\n",
      "\n",
      "episode 15, val func loss 1.2195875644683838\n",
      "\n",
      "episode 16, val func loss 1.217725396156311\n",
      "\n",
      "Val func train loss in epoch 14:1.2240334674715996\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.3662625551223755\n",
      "\n",
      "episode 2, val func loss 1.190546989440918\n",
      "\n",
      "episode 3, val func loss 1.2228034734725952\n",
      "\n",
      "episode 4, val func loss 1.2378054857254028\n",
      "\n",
      "episode 5, val func loss 1.2809251546859741\n",
      "\n",
      "episode 6, val func loss 1.259460687637329\n",
      "\n",
      "episode 7, val func loss 1.2567548751831055\n",
      "\n",
      "episode 8, val func loss 1.1723175048828125\n",
      "\n",
      "episode 9, val func loss 1.1944490671157837\n",
      "\n",
      "episode 10, val func loss 1.0844781398773193\n",
      "\n",
      "episode 11, val func loss 1.1887528896331787\n",
      "\n",
      "episode 12, val func loss 1.303565263748169\n",
      "\n",
      "episode 13, val func loss 1.2585866451263428\n",
      "\n",
      "episode 14, val func loss 1.1245962381362915\n",
      "\n",
      "episode 15, val func loss 1.3389836549758911\n",
      "\n",
      "episode 16, val func loss 1.2749816179275513\n",
      "\n",
      "Val func train loss in epoch 15:1.23470439016819\n",
      "***********************TIME WAS 4.880040200551351 min*****************************\n",
      "\n",
      "**********************ROUND 93 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.696822166442871\n",
      "\n",
      "episode 2, policy loss -3.696822166442871\n",
      "\n",
      "episode 3, policy loss -3.6968231201171875\n",
      "\n",
      "episode 4, policy loss -3.6968228816986084\n",
      "\n",
      "episode 5, policy loss -3.6968231201171875\n",
      "\n",
      "episode 6, policy loss -3.696823835372925\n",
      "\n",
      "episode 7, policy loss -3.696824550628662\n",
      "\n",
      "episode 8, policy loss -3.696824312210083\n",
      "\n",
      "episode 9, policy loss -3.6968252658843994\n",
      "\n",
      "episode 10, policy loss -3.6968252658843994\n",
      "\n",
      "episode 11, policy loss -3.6968257427215576\n",
      "\n",
      "episode 12, policy loss -3.6968259811401367\n",
      "\n",
      "episode 13, policy loss -3.696826696395874\n",
      "\n",
      "episode 14, policy loss -3.696826457977295\n",
      "\n",
      "episode 15, policy loss -3.696826934814453\n",
      "\n",
      "episode 16, policy loss -3.6968274116516113\n",
      "\n",
      "Policy train loss in epoch 0:-3.6968247443437576\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.6968274116516113\n",
      "\n",
      "episode 2, policy loss -3.6968281269073486\n",
      "\n",
      "episode 3, policy loss -3.6968281269073486\n",
      "\n",
      "episode 4, policy loss -3.6968283653259277\n",
      "\n",
      "episode 5, policy loss -3.696828842163086\n",
      "\n",
      "episode 6, policy loss -3.696829080581665\n",
      "\n",
      "episode 7, policy loss -3.6968295574188232\n",
      "\n",
      "episode 8, policy loss -3.696829080581665\n",
      "\n",
      "episode 9, policy loss -3.6968295574188232\n",
      "\n",
      "episode 10, policy loss -3.6968302726745605\n",
      "\n",
      "episode 11, policy loss -3.6968302726745605\n",
      "\n",
      "episode 12, policy loss -3.6968302726745605\n",
      "\n",
      "episode 13, policy loss -3.6968307495117188\n",
      "\n",
      "episode 14, policy loss -3.6968302726745605\n",
      "\n",
      "episode 15, policy loss -3.6968307495117188\n",
      "\n",
      "episode 16, policy loss -3.696831226348877\n",
      "\n",
      "Policy train loss in epoch 1:-3.6968294978141785\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.696831464767456\n",
      "\n",
      "episode 2, policy loss -3.696831226348877\n",
      "\n",
      "episode 3, policy loss -3.696831464767456\n",
      "\n",
      "episode 4, policy loss -3.6968319416046143\n",
      "\n",
      "episode 5, policy loss -3.6968319416046143\n",
      "\n",
      "episode 6, policy loss -3.6968321800231934\n",
      "\n",
      "episode 7, policy loss -3.6968319416046143\n",
      "\n",
      "episode 8, policy loss -3.6968321800231934\n",
      "\n",
      "episode 9, policy loss -3.6968321800231934\n",
      "\n",
      "episode 10, policy loss -3.6968321800231934\n",
      "\n",
      "episode 11, policy loss -3.6968326568603516\n",
      "\n",
      "episode 12, policy loss -3.6968328952789307\n",
      "\n",
      "episode 13, policy loss -3.6968328952789307\n",
      "\n",
      "episode 14, policy loss -3.6968328952789307\n",
      "\n",
      "episode 15, policy loss -3.696833372116089\n",
      "\n",
      "episode 16, policy loss -3.696833372116089\n",
      "\n",
      "Policy train loss in epoch 2:-3.696832299232483\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.696833372116089\n",
      "\n",
      "episode 2, policy loss -3.696833610534668\n",
      "\n",
      "episode 3, policy loss -3.696833610534668\n",
      "\n",
      "episode 4, policy loss -3.696833610534668\n",
      "\n",
      "episode 5, policy loss -3.696833372116089\n",
      "\n",
      "episode 6, policy loss -3.696833610534668\n",
      "\n",
      "episode 7, policy loss -3.696833610534668\n",
      "\n",
      "episode 8, policy loss -3.696834087371826\n",
      "\n",
      "episode 9, policy loss -3.696834087371826\n",
      "\n",
      "episode 10, policy loss -3.6968343257904053\n",
      "\n",
      "episode 11, policy loss -3.6968343257904053\n",
      "\n",
      "episode 12, policy loss -3.6968343257904053\n",
      "\n",
      "episode 13, policy loss -3.696834087371826\n",
      "\n",
      "episode 14, policy loss -3.6968343257904053\n",
      "\n",
      "episode 15, policy loss -3.6968343257904053\n",
      "\n",
      "episode 16, policy loss -3.696834087371826\n",
      "\n",
      "Policy train loss in epoch 3:-3.696833923459053\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.25031316280365\n",
      "\n",
      "episode 2, val func loss 1.182793140411377\n",
      "\n",
      "episode 3, val func loss 1.1882113218307495\n",
      "\n",
      "episode 4, val func loss 1.1384950876235962\n",
      "\n",
      "episode 5, val func loss 1.2185131311416626\n",
      "\n",
      "episode 6, val func loss 1.0618032217025757\n",
      "\n",
      "episode 7, val func loss 1.1197842359542847\n",
      "\n",
      "episode 8, val func loss 1.2436760663986206\n",
      "\n",
      "episode 9, val func loss 1.3236424922943115\n",
      "\n",
      "episode 10, val func loss 1.2209630012512207\n",
      "\n",
      "episode 11, val func loss 1.2677028179168701\n",
      "\n",
      "episode 12, val func loss 1.2689752578735352\n",
      "\n",
      "episode 13, val func loss 1.390211820602417\n",
      "\n",
      "episode 14, val func loss 1.2777281999588013\n",
      "\n",
      "episode 15, val func loss 1.1276370286941528\n",
      "\n",
      "episode 16, val func loss 1.0450721979141235\n",
      "\n",
      "Val func train loss in epoch 0:1.2078451365232468\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.2980719804763794\n",
      "\n",
      "episode 2, val func loss 1.0336744785308838\n",
      "\n",
      "episode 3, val func loss 1.2804385423660278\n",
      "\n",
      "episode 4, val func loss 1.0111075639724731\n",
      "\n",
      "episode 5, val func loss 1.0947253704071045\n",
      "\n",
      "episode 6, val func loss 1.087796688079834\n",
      "\n",
      "episode 7, val func loss 1.2589342594146729\n",
      "\n",
      "episode 8, val func loss 1.5833783149719238\n",
      "\n",
      "episode 9, val func loss 1.3120769262313843\n",
      "\n",
      "episode 10, val func loss 1.2006794214248657\n",
      "\n",
      "episode 11, val func loss 0.9858438372612\n",
      "\n",
      "episode 12, val func loss 1.3973232507705688\n",
      "\n",
      "episode 13, val func loss 1.1267164945602417\n",
      "\n",
      "episode 14, val func loss 1.309908390045166\n",
      "\n",
      "episode 15, val func loss 1.5187420845031738\n",
      "\n",
      "episode 16, val func loss 1.5231479406356812\n",
      "\n",
      "Val func train loss in epoch 1:1.2514103464782238\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.2065454721450806\n",
      "\n",
      "episode 2, val func loss 1.3034183979034424\n",
      "\n",
      "episode 3, val func loss 1.0849276781082153\n",
      "\n",
      "episode 4, val func loss 1.3620258569717407\n",
      "\n",
      "episode 5, val func loss 1.264909029006958\n",
      "\n",
      "episode 6, val func loss 1.243117332458496\n",
      "\n",
      "episode 7, val func loss 1.26641845703125\n",
      "\n",
      "episode 8, val func loss 1.1522551774978638\n",
      "\n",
      "episode 9, val func loss 1.2350645065307617\n",
      "\n",
      "episode 10, val func loss 1.0725001096725464\n",
      "\n",
      "episode 11, val func loss 1.542677402496338\n",
      "\n",
      "episode 12, val func loss 1.4073717594146729\n",
      "\n",
      "episode 13, val func loss 1.248789668083191\n",
      "\n",
      "episode 14, val func loss 1.1331336498260498\n",
      "\n",
      "episode 15, val func loss 1.2276276350021362\n",
      "\n",
      "episode 16, val func loss 1.188140869140625\n",
      "\n",
      "Val func train loss in epoch 2:1.2461826875805855\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.140374779701233\n",
      "\n",
      "episode 2, val func loss 1.2779641151428223\n",
      "\n",
      "episode 3, val func loss 1.2158796787261963\n",
      "\n",
      "episode 4, val func loss 1.302605152130127\n",
      "\n",
      "episode 5, val func loss 1.1828789710998535\n",
      "\n",
      "episode 6, val func loss 1.2913861274719238\n",
      "\n",
      "episode 7, val func loss 1.2066892385482788\n",
      "\n",
      "episode 8, val func loss 1.39171302318573\n",
      "\n",
      "episode 9, val func loss 0.9842007160186768\n",
      "\n",
      "episode 10, val func loss 1.093808889389038\n",
      "\n",
      "episode 11, val func loss 1.1769626140594482\n",
      "\n",
      "episode 12, val func loss 1.4219716787338257\n",
      "\n",
      "episode 13, val func loss 1.1715340614318848\n",
      "\n",
      "episode 14, val func loss 1.0329145193099976\n",
      "\n",
      "episode 15, val func loss 1.1579005718231201\n",
      "\n",
      "episode 16, val func loss 0.956726610660553\n",
      "\n",
      "Val func train loss in epoch 3:1.1878444217145443\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.0503547191619873\n",
      "\n",
      "episode 2, val func loss 1.2460696697235107\n",
      "\n",
      "episode 3, val func loss 1.0352872610092163\n",
      "\n",
      "episode 4, val func loss 1.2463442087173462\n",
      "\n",
      "episode 5, val func loss 1.1342629194259644\n",
      "\n",
      "episode 6, val func loss 1.3309379816055298\n",
      "\n",
      "episode 7, val func loss 1.170728087425232\n",
      "\n",
      "episode 8, val func loss 1.2817984819412231\n",
      "\n",
      "episode 9, val func loss 1.2624568939208984\n",
      "\n",
      "episode 10, val func loss 1.2206757068634033\n",
      "\n",
      "episode 11, val func loss 1.2367725372314453\n",
      "\n",
      "episode 12, val func loss 1.1904219388961792\n",
      "\n",
      "episode 13, val func loss 1.1100388765335083\n",
      "\n",
      "episode 14, val func loss 1.0278908014297485\n",
      "\n",
      "episode 15, val func loss 1.06647789478302\n",
      "\n",
      "episode 16, val func loss 1.1000581979751587\n",
      "\n",
      "Val func train loss in epoch 4:1.1694110110402107\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.1641838550567627\n",
      "\n",
      "episode 2, val func loss 1.2090202569961548\n",
      "\n",
      "episode 3, val func loss 1.1906638145446777\n",
      "\n",
      "episode 4, val func loss 1.1471292972564697\n",
      "\n",
      "episode 5, val func loss 1.0299783945083618\n",
      "\n",
      "episode 6, val func loss 1.1591538190841675\n",
      "\n",
      "episode 7, val func loss 1.2270499467849731\n",
      "\n",
      "episode 8, val func loss 1.057293176651001\n",
      "\n",
      "episode 9, val func loss 1.2630200386047363\n",
      "\n",
      "episode 10, val func loss 1.2460606098175049\n",
      "\n",
      "episode 11, val func loss 1.0789228677749634\n",
      "\n",
      "episode 12, val func loss 1.1521621942520142\n",
      "\n",
      "episode 13, val func loss 1.2206398248672485\n",
      "\n",
      "episode 14, val func loss 1.1757632493972778\n",
      "\n",
      "episode 15, val func loss 1.076033115386963\n",
      "\n",
      "episode 16, val func loss 1.36334228515625\n",
      "\n",
      "Val func train loss in epoch 5:1.1725260466337204\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.1817303895950317\n",
      "\n",
      "episode 2, val func loss 1.2717266082763672\n",
      "\n",
      "episode 3, val func loss 1.2484904527664185\n",
      "\n",
      "episode 4, val func loss 1.1080899238586426\n",
      "\n",
      "episode 5, val func loss 1.1982837915420532\n",
      "\n",
      "episode 6, val func loss 1.3132658004760742\n",
      "\n",
      "episode 7, val func loss 0.8639797568321228\n",
      "\n",
      "episode 8, val func loss 1.346534252166748\n",
      "\n",
      "episode 9, val func loss 1.2525887489318848\n",
      "\n",
      "episode 10, val func loss 1.3437809944152832\n",
      "\n",
      "episode 11, val func loss 1.1671749353408813\n",
      "\n",
      "episode 12, val func loss 1.05014967918396\n",
      "\n",
      "episode 13, val func loss 1.2169015407562256\n",
      "\n",
      "episode 14, val func loss 1.235012412071228\n",
      "\n",
      "episode 15, val func loss 1.2007653713226318\n",
      "\n",
      "episode 16, val func loss 1.3361129760742188\n",
      "\n",
      "Val func train loss in epoch 6:1.2084117271006107\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.190207600593567\n",
      "\n",
      "episode 2, val func loss 1.282418966293335\n",
      "\n",
      "episode 3, val func loss 1.2212144136428833\n",
      "\n",
      "episode 4, val func loss 1.142851710319519\n",
      "\n",
      "episode 5, val func loss 1.081278920173645\n",
      "\n",
      "episode 6, val func loss 1.1730945110321045\n",
      "\n",
      "episode 7, val func loss 1.2270113229751587\n",
      "\n",
      "episode 8, val func loss 1.1930336952209473\n",
      "\n",
      "episode 9, val func loss 1.3404520750045776\n",
      "\n",
      "episode 10, val func loss 1.0674933195114136\n",
      "\n",
      "episode 11, val func loss 1.0773309469223022\n",
      "\n",
      "episode 12, val func loss 1.266072392463684\n",
      "\n",
      "episode 13, val func loss 1.2399635314941406\n",
      "\n",
      "episode 14, val func loss 1.2538535594940186\n",
      "\n",
      "episode 15, val func loss 1.1235613822937012\n",
      "\n",
      "episode 16, val func loss 1.0856667757034302\n",
      "\n",
      "Val func train loss in epoch 7:1.1853440701961517\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.2568597793579102\n",
      "\n",
      "episode 2, val func loss 1.039399266242981\n",
      "\n",
      "episode 3, val func loss 1.2359778881072998\n",
      "\n",
      "episode 4, val func loss 1.3051258325576782\n",
      "\n",
      "episode 5, val func loss 1.208564281463623\n",
      "\n",
      "episode 6, val func loss 1.0920987129211426\n",
      "\n",
      "episode 7, val func loss 1.1022940874099731\n",
      "\n",
      "episode 8, val func loss 1.0572364330291748\n",
      "\n",
      "episode 9, val func loss 1.250131607055664\n",
      "\n",
      "episode 10, val func loss 1.0372419357299805\n",
      "\n",
      "episode 11, val func loss 1.0948535203933716\n",
      "\n",
      "episode 12, val func loss 1.2590529918670654\n",
      "\n",
      "episode 13, val func loss 1.448861837387085\n",
      "\n",
      "episode 14, val func loss 1.199393391609192\n",
      "\n",
      "episode 15, val func loss 1.296164631843567\n",
      "\n",
      "episode 16, val func loss 1.167457938194275\n",
      "\n",
      "Val func train loss in epoch 8:1.190669633448124\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.992497980594635\n",
      "\n",
      "episode 2, val func loss 1.3309494256973267\n",
      "\n",
      "episode 3, val func loss 1.2474347352981567\n",
      "\n",
      "episode 4, val func loss 1.1157212257385254\n",
      "\n",
      "episode 5, val func loss 1.1776007413864136\n",
      "\n",
      "episode 6, val func loss 1.0480209589004517\n",
      "\n",
      "episode 7, val func loss 1.1146156787872314\n",
      "\n",
      "episode 8, val func loss 1.3619307279586792\n",
      "\n",
      "episode 9, val func loss 1.340368628501892\n",
      "\n",
      "episode 10, val func loss 1.257075309753418\n",
      "\n",
      "episode 11, val func loss 1.1159312725067139\n",
      "\n",
      "episode 12, val func loss 1.152553915977478\n",
      "\n",
      "episode 13, val func loss 1.0803099870681763\n",
      "\n",
      "episode 14, val func loss 1.1579030752182007\n",
      "\n",
      "episode 15, val func loss 1.2792924642562866\n",
      "\n",
      "episode 16, val func loss 1.2066962718963623\n",
      "\n",
      "Val func train loss in epoch 9:1.1861813999712467\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.2402923107147217\n",
      "\n",
      "episode 2, val func loss 1.2915024757385254\n",
      "\n",
      "episode 3, val func loss 1.2054301500320435\n",
      "\n",
      "episode 4, val func loss 1.0556838512420654\n",
      "\n",
      "episode 5, val func loss 1.1223318576812744\n",
      "\n",
      "episode 6, val func loss 1.0695067644119263\n",
      "\n",
      "episode 7, val func loss 1.1770350933074951\n",
      "\n",
      "episode 8, val func loss 1.154991626739502\n",
      "\n",
      "episode 9, val func loss 1.0627977848052979\n",
      "\n",
      "episode 10, val func loss 1.277063012123108\n",
      "\n",
      "episode 11, val func loss 1.1688752174377441\n",
      "\n",
      "episode 12, val func loss 1.238669753074646\n",
      "\n",
      "episode 13, val func loss 1.1112558841705322\n",
      "\n",
      "episode 14, val func loss 1.2374062538146973\n",
      "\n",
      "episode 15, val func loss 1.4180525541305542\n",
      "\n",
      "episode 16, val func loss 1.0945791006088257\n",
      "\n",
      "Val func train loss in epoch 10:1.18284210562706\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.1514949798583984\n",
      "\n",
      "episode 2, val func loss 1.1870524883270264\n",
      "\n",
      "episode 3, val func loss 1.209599256515503\n",
      "\n",
      "episode 4, val func loss 1.348504662513733\n",
      "\n",
      "episode 5, val func loss 1.2525537014007568\n",
      "\n",
      "episode 6, val func loss 1.2140069007873535\n",
      "\n",
      "episode 7, val func loss 1.1400151252746582\n",
      "\n",
      "episode 8, val func loss 1.1874138116836548\n",
      "\n",
      "episode 9, val func loss 1.0658107995986938\n",
      "\n",
      "episode 10, val func loss 1.083910584449768\n",
      "\n",
      "episode 11, val func loss 1.121998906135559\n",
      "\n",
      "episode 12, val func loss 1.3273499011993408\n",
      "\n",
      "episode 13, val func loss 1.197456955909729\n",
      "\n",
      "episode 14, val func loss 1.3757907152175903\n",
      "\n",
      "episode 15, val func loss 1.0665522813796997\n",
      "\n",
      "episode 16, val func loss 1.0702372789382935\n",
      "\n",
      "Val func train loss in epoch 11:1.18748427182436\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.2164082527160645\n",
      "\n",
      "episode 2, val func loss 1.2727553844451904\n",
      "\n",
      "episode 3, val func loss 1.1580555438995361\n",
      "\n",
      "episode 4, val func loss 1.1215941905975342\n",
      "\n",
      "episode 5, val func loss 1.5898762941360474\n",
      "\n",
      "episode 6, val func loss 1.055320143699646\n",
      "\n",
      "episode 7, val func loss 1.1767911911010742\n",
      "\n",
      "episode 8, val func loss 1.1488053798675537\n",
      "\n",
      "episode 9, val func loss 1.2187082767486572\n",
      "\n",
      "episode 10, val func loss 1.2829856872558594\n",
      "\n",
      "episode 11, val func loss 1.235156774520874\n",
      "\n",
      "episode 12, val func loss 1.3628512620925903\n",
      "\n",
      "episode 13, val func loss 1.123777151107788\n",
      "\n",
      "episode 14, val func loss 1.1371655464172363\n",
      "\n",
      "episode 15, val func loss 1.3470063209533691\n",
      "\n",
      "episode 16, val func loss 1.0661228895187378\n",
      "\n",
      "Val func train loss in epoch 12:1.21958626806736\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.260742425918579\n",
      "\n",
      "episode 2, val func loss 1.119415521621704\n",
      "\n",
      "episode 3, val func loss 1.1482737064361572\n",
      "\n",
      "episode 4, val func loss 1.1011314392089844\n",
      "\n",
      "episode 5, val func loss 1.3592342138290405\n",
      "\n",
      "episode 6, val func loss 1.2417385578155518\n",
      "\n",
      "episode 7, val func loss 1.146954894065857\n",
      "\n",
      "episode 8, val func loss 1.1625136137008667\n",
      "\n",
      "episode 9, val func loss 1.0610771179199219\n",
      "\n",
      "episode 10, val func loss 1.256856918334961\n",
      "\n",
      "episode 11, val func loss 1.049725890159607\n",
      "\n",
      "episode 12, val func loss 1.3534319400787354\n",
      "\n",
      "episode 13, val func loss 1.0708234310150146\n",
      "\n",
      "episode 14, val func loss 1.1117686033248901\n",
      "\n",
      "episode 15, val func loss 1.1606837511062622\n",
      "\n",
      "episode 16, val func loss 1.0956188440322876\n",
      "\n",
      "Val func train loss in epoch 13:1.1687494292855263\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.1465905904769897\n",
      "\n",
      "episode 2, val func loss 1.0130701065063477\n",
      "\n",
      "episode 3, val func loss 1.107765555381775\n",
      "\n",
      "episode 4, val func loss 1.3709169626235962\n",
      "\n",
      "episode 5, val func loss 1.0606187582015991\n",
      "\n",
      "episode 6, val func loss 0.9643378257751465\n",
      "\n",
      "episode 7, val func loss 1.1782110929489136\n",
      "\n",
      "episode 8, val func loss 1.061730980873108\n",
      "\n",
      "episode 9, val func loss 1.0191911458969116\n",
      "\n",
      "episode 10, val func loss 1.12552011013031\n",
      "\n",
      "episode 11, val func loss 1.1669998168945312\n",
      "\n",
      "episode 12, val func loss 1.1942617893218994\n",
      "\n",
      "episode 13, val func loss 1.20894455909729\n",
      "\n",
      "episode 14, val func loss 1.133711576461792\n",
      "\n",
      "episode 15, val func loss 1.1841713190078735\n",
      "\n",
      "episode 16, val func loss 1.0570133924484253\n",
      "\n",
      "Val func train loss in epoch 14:1.1245659738779068\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.0617178678512573\n",
      "\n",
      "episode 2, val func loss 1.3191258907318115\n",
      "\n",
      "episode 3, val func loss 1.0575186014175415\n",
      "\n",
      "episode 4, val func loss 1.0406787395477295\n",
      "\n",
      "episode 5, val func loss 0.9762791395187378\n",
      "\n",
      "episode 6, val func loss 0.9340525269508362\n",
      "\n",
      "episode 7, val func loss 1.1185308694839478\n",
      "\n",
      "episode 8, val func loss 1.0531412363052368\n",
      "\n",
      "episode 9, val func loss 1.2988920211791992\n",
      "\n",
      "episode 10, val func loss 1.3413692712783813\n",
      "\n",
      "episode 11, val func loss 1.1394877433776855\n",
      "\n",
      "episode 12, val func loss 1.1093074083328247\n",
      "\n",
      "episode 13, val func loss 1.1031585931777954\n",
      "\n",
      "episode 14, val func loss 1.1492348909378052\n",
      "\n",
      "episode 15, val func loss 0.9210598468780518\n",
      "\n",
      "episode 16, val func loss 1.1622291803359985\n",
      "\n",
      "Val func train loss in epoch 15:1.1116114892065525\n",
      "***********************TIME WAS 4.888359224796295 min*****************************\n",
      "\n",
      "**********************ROUND 94 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -3.250596284866333\n",
      "\n",
      "episode 2, policy loss -3.250595808029175\n",
      "\n",
      "episode 3, policy loss -3.250596284866333\n",
      "\n",
      "episode 4, policy loss -3.250596284866333\n",
      "\n",
      "episode 5, policy loss -3.250596523284912\n",
      "\n",
      "episode 6, policy loss -3.250595808029175\n",
      "\n",
      "episode 7, policy loss -3.250595808029175\n",
      "\n",
      "episode 8, policy loss -3.250596523284912\n",
      "\n",
      "episode 9, policy loss -3.250596284866333\n",
      "\n",
      "episode 10, policy loss -3.250596523284912\n",
      "\n",
      "episode 11, policy loss -3.250596284866333\n",
      "\n",
      "episode 12, policy loss -3.250596523284912\n",
      "\n",
      "episode 13, policy loss -3.250596523284912\n",
      "\n",
      "episode 14, policy loss -3.250596523284912\n",
      "\n",
      "episode 15, policy loss -3.250596523284912\n",
      "\n",
      "episode 16, policy loss -3.250595808029175\n",
      "\n",
      "Policy train loss in epoch 0:-3.250596269965172\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -3.250596284866333\n",
      "\n",
      "episode 2, policy loss -3.250596523284912\n",
      "\n",
      "episode 3, policy loss -3.250596523284912\n",
      "\n",
      "episode 4, policy loss -3.250596523284912\n",
      "\n",
      "episode 5, policy loss -3.250596523284912\n",
      "\n",
      "episode 6, policy loss -3.250596523284912\n",
      "\n",
      "episode 7, policy loss -3.250596523284912\n",
      "\n",
      "episode 8, policy loss -3.250596523284912\n",
      "\n",
      "episode 9, policy loss -3.250596523284912\n",
      "\n",
      "episode 10, policy loss -3.250596523284912\n",
      "\n",
      "episode 11, policy loss -3.250596523284912\n",
      "\n",
      "episode 12, policy loss -3.250596523284912\n",
      "\n",
      "episode 13, policy loss -3.250596523284912\n",
      "\n",
      "episode 14, policy loss -3.250596523284912\n",
      "\n",
      "episode 15, policy loss -3.250596523284912\n",
      "\n",
      "episode 16, policy loss -3.250596523284912\n",
      "\n",
      "Policy train loss in epoch 1:-3.250596508383751\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -3.250596523284912\n",
      "\n",
      "episode 2, policy loss -3.250596523284912\n",
      "\n",
      "episode 3, policy loss -3.250596523284912\n",
      "\n",
      "episode 4, policy loss -3.250596523284912\n",
      "\n",
      "episode 5, policy loss -3.250596523284912\n",
      "\n",
      "episode 6, policy loss -3.250596523284912\n",
      "\n",
      "episode 7, policy loss -3.250596523284912\n",
      "\n",
      "episode 8, policy loss -3.250596523284912\n",
      "\n",
      "episode 9, policy loss -3.250596523284912\n",
      "\n",
      "episode 10, policy loss -3.250596523284912\n",
      "\n",
      "episode 11, policy loss -3.250596523284912\n",
      "\n",
      "episode 12, policy loss -3.250596523284912\n",
      "\n",
      "episode 13, policy loss -3.2505970001220703\n",
      "\n",
      "episode 14, policy loss -3.250596523284912\n",
      "\n",
      "episode 15, policy loss -3.2505970001220703\n",
      "\n",
      "episode 16, policy loss -3.250596523284912\n",
      "\n",
      "Policy train loss in epoch 2:-3.250596582889557\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -3.250596523284912\n",
      "\n",
      "episode 2, policy loss -3.250596523284912\n",
      "\n",
      "episode 3, policy loss -3.250596523284912\n",
      "\n",
      "episode 4, policy loss -3.250596523284912\n",
      "\n",
      "episode 5, policy loss -3.250596523284912\n",
      "\n",
      "episode 6, policy loss -3.250596523284912\n",
      "\n",
      "episode 7, policy loss -3.250596523284912\n",
      "\n",
      "episode 8, policy loss -3.250596523284912\n",
      "\n",
      "episode 9, policy loss -3.250596523284912\n",
      "\n",
      "episode 10, policy loss -3.250596523284912\n",
      "\n",
      "episode 11, policy loss -3.2505970001220703\n",
      "\n",
      "episode 12, policy loss -3.250596523284912\n",
      "\n",
      "episode 13, policy loss -3.250596523284912\n",
      "\n",
      "episode 14, policy loss -3.250596523284912\n",
      "\n",
      "episode 15, policy loss -3.250596523284912\n",
      "\n",
      "episode 16, policy loss -3.2505970001220703\n",
      "\n",
      "Policy train loss in epoch 3:-3.250596582889557\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.291563868522644\n",
      "\n",
      "episode 2, val func loss 1.3731920719146729\n",
      "\n",
      "episode 3, val func loss 0.9978646039962769\n",
      "\n",
      "episode 4, val func loss 0.964614748954773\n",
      "\n",
      "episode 5, val func loss 1.0981823205947876\n",
      "\n",
      "episode 6, val func loss 1.1625417470932007\n",
      "\n",
      "episode 7, val func loss 1.134507656097412\n",
      "\n",
      "episode 8, val func loss 1.0416733026504517\n",
      "\n",
      "episode 9, val func loss 1.1233439445495605\n",
      "\n",
      "episode 10, val func loss 1.2583732604980469\n",
      "\n",
      "episode 11, val func loss 1.3581346273422241\n",
      "\n",
      "episode 12, val func loss 1.2349807024002075\n",
      "\n",
      "episode 13, val func loss 1.0538866519927979\n",
      "\n",
      "episode 14, val func loss 0.9991173148155212\n",
      "\n",
      "episode 15, val func loss 1.3029465675354004\n",
      "\n",
      "episode 16, val func loss 1.1928757429122925\n",
      "\n",
      "Val func train loss in epoch 0:1.1617374457418919\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.3029131889343262\n",
      "\n",
      "episode 2, val func loss 1.0762654542922974\n",
      "\n",
      "episode 3, val func loss 1.2187631130218506\n",
      "\n",
      "episode 4, val func loss 1.354699730873108\n",
      "\n",
      "episode 5, val func loss 1.125742793083191\n",
      "\n",
      "episode 6, val func loss 1.1328222751617432\n",
      "\n",
      "episode 7, val func loss 1.2307485342025757\n",
      "\n",
      "episode 8, val func loss 1.1972765922546387\n",
      "\n",
      "episode 9, val func loss 1.177912712097168\n",
      "\n",
      "episode 10, val func loss 0.9781038761138916\n",
      "\n",
      "episode 11, val func loss 1.1665199995040894\n",
      "\n",
      "episode 12, val func loss 1.182239055633545\n",
      "\n",
      "episode 13, val func loss 1.2727831602096558\n",
      "\n",
      "episode 14, val func loss 1.2279645204544067\n",
      "\n",
      "episode 15, val func loss 1.1272670030593872\n",
      "\n",
      "episode 16, val func loss 0.9453258514404297\n",
      "\n",
      "Val func train loss in epoch 1:1.169834241271019\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.0986924171447754\n",
      "\n",
      "episode 2, val func loss 1.0903443098068237\n",
      "\n",
      "episode 3, val func loss 1.1434214115142822\n",
      "\n",
      "episode 4, val func loss 1.0865745544433594\n",
      "\n",
      "episode 5, val func loss 1.1827170848846436\n",
      "\n",
      "episode 6, val func loss 0.9314313530921936\n",
      "\n",
      "episode 7, val func loss 1.1684484481811523\n",
      "\n",
      "episode 8, val func loss 1.0732160806655884\n",
      "\n",
      "episode 9, val func loss 1.106252908706665\n",
      "\n",
      "episode 10, val func loss 1.1990139484405518\n",
      "\n",
      "episode 11, val func loss 1.0164744853973389\n",
      "\n",
      "episode 12, val func loss 1.1633762121200562\n",
      "\n",
      "episode 13, val func loss 1.2631971836090088\n",
      "\n",
      "episode 14, val func loss 1.0411490201950073\n",
      "\n",
      "episode 15, val func loss 1.0978490114212036\n",
      "\n",
      "episode 16, val func loss 1.2489800453186035\n",
      "\n",
      "Val func train loss in epoch 2:1.1194461546838284\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.2430346012115479\n",
      "\n",
      "episode 2, val func loss 1.0730135440826416\n",
      "\n",
      "episode 3, val func loss 1.1521865129470825\n",
      "\n",
      "episode 4, val func loss 1.1982226371765137\n",
      "\n",
      "episode 5, val func loss 1.2717127799987793\n",
      "\n",
      "episode 6, val func loss 1.1198440790176392\n",
      "\n",
      "episode 7, val func loss 1.1286208629608154\n",
      "\n",
      "episode 8, val func loss 1.2988799810409546\n",
      "\n",
      "episode 9, val func loss 1.0966545343399048\n",
      "\n",
      "episode 10, val func loss 1.0331127643585205\n",
      "\n",
      "episode 11, val func loss 1.3242805004119873\n",
      "\n",
      "episode 12, val func loss 1.2292454242706299\n",
      "\n",
      "episode 13, val func loss 1.0356223583221436\n",
      "\n",
      "episode 14, val func loss 1.100303053855896\n",
      "\n",
      "episode 15, val func loss 1.1710995435714722\n",
      "\n",
      "episode 16, val func loss 1.0642220973968506\n",
      "\n",
      "Val func train loss in epoch 3:1.1587534546852112\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.0385842323303223\n",
      "\n",
      "episode 2, val func loss 1.382718563079834\n",
      "\n",
      "episode 3, val func loss 0.9176695346832275\n",
      "\n",
      "episode 4, val func loss 0.9816038012504578\n",
      "\n",
      "episode 5, val func loss 1.2494914531707764\n",
      "\n",
      "episode 6, val func loss 1.1144744157791138\n",
      "\n",
      "episode 7, val func loss 0.9876189827919006\n",
      "\n",
      "episode 8, val func loss 1.2115203142166138\n",
      "\n",
      "episode 9, val func loss 1.155165672302246\n",
      "\n",
      "episode 10, val func loss 1.116003155708313\n",
      "\n",
      "episode 11, val func loss 1.191975712776184\n",
      "\n",
      "episode 12, val func loss 1.1159107685089111\n",
      "\n",
      "episode 13, val func loss 1.1752479076385498\n",
      "\n",
      "episode 14, val func loss 0.9462430477142334\n",
      "\n",
      "episode 15, val func loss 1.05337393283844\n",
      "\n",
      "episode 16, val func loss 1.112321138381958\n",
      "\n",
      "Val func train loss in epoch 4:1.1093701645731926\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.1240993738174438\n",
      "\n",
      "episode 2, val func loss 1.2093191146850586\n",
      "\n",
      "episode 3, val func loss 1.1661523580551147\n",
      "\n",
      "episode 4, val func loss 1.0814377069473267\n",
      "\n",
      "episode 5, val func loss 1.0676274299621582\n",
      "\n",
      "episode 6, val func loss 1.0609866380691528\n",
      "\n",
      "episode 7, val func loss 1.2589151859283447\n",
      "\n",
      "episode 8, val func loss 1.017490029335022\n",
      "\n",
      "episode 9, val func loss 1.1335399150848389\n",
      "\n",
      "episode 10, val func loss 0.9851897954940796\n",
      "\n",
      "episode 11, val func loss 1.0255948305130005\n",
      "\n",
      "episode 12, val func loss 0.9969335198402405\n",
      "\n",
      "episode 13, val func loss 1.3260489702224731\n",
      "\n",
      "episode 14, val func loss 1.0680571794509888\n",
      "\n",
      "episode 15, val func loss 1.1981301307678223\n",
      "\n",
      "episode 16, val func loss 1.0129262208938599\n",
      "\n",
      "Val func train loss in epoch 5:1.1082780249416828\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.0605626106262207\n",
      "\n",
      "episode 2, val func loss 1.1582551002502441\n",
      "\n",
      "episode 3, val func loss 1.0229716300964355\n",
      "\n",
      "episode 4, val func loss 1.1525304317474365\n",
      "\n",
      "episode 5, val func loss 1.1062761545181274\n",
      "\n",
      "episode 6, val func loss 1.2409895658493042\n",
      "\n",
      "episode 7, val func loss 0.9613611698150635\n",
      "\n",
      "episode 8, val func loss 1.0216479301452637\n",
      "\n",
      "episode 9, val func loss 1.109923243522644\n",
      "\n",
      "episode 10, val func loss 1.0562231540679932\n",
      "\n",
      "episode 11, val func loss 1.0883598327636719\n",
      "\n",
      "episode 12, val func loss 1.0238878726959229\n",
      "\n",
      "episode 13, val func loss 0.9046053290367126\n",
      "\n",
      "episode 14, val func loss 1.113515019416809\n",
      "\n",
      "episode 15, val func loss 1.0961439609527588\n",
      "\n",
      "episode 16, val func loss 1.0043033361434937\n",
      "\n",
      "Val func train loss in epoch 6:1.0700972713530064\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.990727961063385\n",
      "\n",
      "episode 2, val func loss 1.029421329498291\n",
      "\n",
      "episode 3, val func loss 0.9135763049125671\n",
      "\n",
      "episode 4, val func loss 0.9108557105064392\n",
      "\n",
      "episode 5, val func loss 1.0107661485671997\n",
      "\n",
      "episode 6, val func loss 1.0903761386871338\n",
      "\n",
      "episode 7, val func loss 1.149641752243042\n",
      "\n",
      "episode 8, val func loss 1.1377909183502197\n",
      "\n",
      "episode 9, val func loss 0.9659688472747803\n",
      "\n",
      "episode 10, val func loss 1.2242501974105835\n",
      "\n",
      "episode 11, val func loss 1.148574709892273\n",
      "\n",
      "episode 12, val func loss 1.1009045839309692\n",
      "\n",
      "episode 13, val func loss 1.0631508827209473\n",
      "\n",
      "episode 14, val func loss 0.9595836997032166\n",
      "\n",
      "episode 15, val func loss 0.9326086044311523\n",
      "\n",
      "episode 16, val func loss 0.9823111295700073\n",
      "\n",
      "Val func train loss in epoch 7:1.038156807422638\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.9305075407028198\n",
      "\n",
      "episode 2, val func loss 1.1262696981430054\n",
      "\n",
      "episode 3, val func loss 1.0430152416229248\n",
      "\n",
      "episode 4, val func loss 1.0632730722427368\n",
      "\n",
      "episode 5, val func loss 1.0742526054382324\n",
      "\n",
      "episode 6, val func loss 0.979310154914856\n",
      "\n",
      "episode 7, val func loss 1.094771146774292\n",
      "\n",
      "episode 8, val func loss 1.0117686986923218\n",
      "\n",
      "episode 9, val func loss 1.0434550046920776\n",
      "\n",
      "episode 10, val func loss 0.9507647752761841\n",
      "\n",
      "episode 11, val func loss 1.1581361293792725\n",
      "\n",
      "episode 12, val func loss 1.0113160610198975\n",
      "\n",
      "episode 13, val func loss 1.028132438659668\n",
      "\n",
      "episode 14, val func loss 1.0607342720031738\n",
      "\n",
      "episode 15, val func loss 0.9885105490684509\n",
      "\n",
      "episode 16, val func loss 1.1355186700820923\n",
      "\n",
      "Val func train loss in epoch 8:1.0437335036695004\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.155853271484375\n",
      "\n",
      "episode 2, val func loss 1.025769591331482\n",
      "\n",
      "episode 3, val func loss 1.052293300628662\n",
      "\n",
      "episode 4, val func loss 0.8574545383453369\n",
      "\n",
      "episode 5, val func loss 1.0615078210830688\n",
      "\n",
      "episode 6, val func loss 1.0779554843902588\n",
      "\n",
      "episode 7, val func loss 1.1119868755340576\n",
      "\n",
      "episode 8, val func loss 1.0117701292037964\n",
      "\n",
      "episode 9, val func loss 1.0864455699920654\n",
      "\n",
      "episode 10, val func loss 1.020192265510559\n",
      "\n",
      "episode 11, val func loss 1.0237648487091064\n",
      "\n",
      "episode 12, val func loss 1.0885426998138428\n",
      "\n",
      "episode 13, val func loss 1.038246512413025\n",
      "\n",
      "episode 14, val func loss 0.8916162848472595\n",
      "\n",
      "episode 15, val func loss 1.067835807800293\n",
      "\n",
      "episode 16, val func loss 0.894236147403717\n",
      "\n",
      "Val func train loss in epoch 9:1.0290919467806816\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.1219459772109985\n",
      "\n",
      "episode 2, val func loss 1.2504940032958984\n",
      "\n",
      "episode 3, val func loss 1.1719670295715332\n",
      "\n",
      "episode 4, val func loss 1.0046627521514893\n",
      "\n",
      "episode 5, val func loss 1.2380702495574951\n",
      "\n",
      "episode 6, val func loss 1.003739833831787\n",
      "\n",
      "episode 7, val func loss 1.0105165243148804\n",
      "\n",
      "episode 8, val func loss 0.9859703779220581\n",
      "\n",
      "episode 9, val func loss 1.062630295753479\n",
      "\n",
      "episode 10, val func loss 0.9360486268997192\n",
      "\n",
      "episode 11, val func loss 1.0563852787017822\n",
      "\n",
      "episode 12, val func loss 0.9773998260498047\n",
      "\n",
      "episode 13, val func loss 0.9697297215461731\n",
      "\n",
      "episode 14, val func loss 0.9460940957069397\n",
      "\n",
      "episode 15, val func loss 0.9871527552604675\n",
      "\n",
      "episode 16, val func loss 0.9178317785263062\n",
      "\n",
      "Val func train loss in epoch 10:1.0400399453938007\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.0818918943405151\n",
      "\n",
      "episode 2, val func loss 0.8306202292442322\n",
      "\n",
      "episode 3, val func loss 1.1188056468963623\n",
      "\n",
      "episode 4, val func loss 1.0392539501190186\n",
      "\n",
      "episode 5, val func loss 1.0712028741836548\n",
      "\n",
      "episode 6, val func loss 0.8330255746841431\n",
      "\n",
      "episode 7, val func loss 0.9854437112808228\n",
      "\n",
      "episode 8, val func loss 0.8923135995864868\n",
      "\n",
      "episode 9, val func loss 1.1178843975067139\n",
      "\n",
      "episode 10, val func loss 0.916327953338623\n",
      "\n",
      "episode 11, val func loss 1.0543859004974365\n",
      "\n",
      "episode 12, val func loss 1.1807966232299805\n",
      "\n",
      "episode 13, val func loss 1.0637481212615967\n",
      "\n",
      "episode 14, val func loss 1.075319766998291\n",
      "\n",
      "episode 15, val func loss 1.0359188318252563\n",
      "\n",
      "episode 16, val func loss 1.0986465215682983\n",
      "\n",
      "Val func train loss in epoch 11:1.0247240997850895\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.962345540523529\n",
      "\n",
      "episode 2, val func loss 1.06938898563385\n",
      "\n",
      "episode 3, val func loss 1.0339152812957764\n",
      "\n",
      "episode 4, val func loss 0.9936828017234802\n",
      "\n",
      "episode 5, val func loss 0.9451156258583069\n",
      "\n",
      "episode 6, val func loss 0.9678477048873901\n",
      "\n",
      "episode 7, val func loss 0.9701995849609375\n",
      "\n",
      "episode 8, val func loss 0.9829514622688293\n",
      "\n",
      "episode 9, val func loss 0.9045374393463135\n",
      "\n",
      "episode 10, val func loss 0.9365512132644653\n",
      "\n",
      "episode 11, val func loss 0.9167420268058777\n",
      "\n",
      "episode 12, val func loss 1.092514157295227\n",
      "\n",
      "episode 13, val func loss 1.042344093322754\n",
      "\n",
      "episode 14, val func loss 1.022588849067688\n",
      "\n",
      "episode 15, val func loss 1.0057744979858398\n",
      "\n",
      "episode 16, val func loss 0.8834272623062134\n",
      "\n",
      "Val func train loss in epoch 12:0.9831204079091549\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.9553177952766418\n",
      "\n",
      "episode 2, val func loss 0.9639126658439636\n",
      "\n",
      "episode 3, val func loss 1.0241676568984985\n",
      "\n",
      "episode 4, val func loss 1.1595852375030518\n",
      "\n",
      "episode 5, val func loss 0.9318228960037231\n",
      "\n",
      "episode 6, val func loss 0.9918574690818787\n",
      "\n",
      "episode 7, val func loss 1.0113517045974731\n",
      "\n",
      "episode 8, val func loss 1.0940049886703491\n",
      "\n",
      "episode 9, val func loss 0.9478992223739624\n",
      "\n",
      "episode 10, val func loss 0.9233622550964355\n",
      "\n",
      "episode 11, val func loss 0.9615622758865356\n",
      "\n",
      "episode 12, val func loss 0.9927738308906555\n",
      "\n",
      "episode 13, val func loss 1.0747206211090088\n",
      "\n",
      "episode 14, val func loss 0.9897934794425964\n",
      "\n",
      "episode 15, val func loss 0.9318236708641052\n",
      "\n",
      "episode 16, val func loss 0.8204188346862793\n",
      "\n",
      "Val func train loss in epoch 13:0.9858984127640724\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.962072491645813\n",
      "\n",
      "episode 2, val func loss 1.089367389678955\n",
      "\n",
      "episode 3, val func loss 0.9446154236793518\n",
      "\n",
      "episode 4, val func loss 0.9880182147026062\n",
      "\n",
      "episode 5, val func loss 0.9742612838745117\n",
      "\n",
      "episode 6, val func loss 1.0418059825897217\n",
      "\n",
      "episode 7, val func loss 0.9313862323760986\n",
      "\n",
      "episode 8, val func loss 1.0612844228744507\n",
      "\n",
      "episode 9, val func loss 1.0205680131912231\n",
      "\n",
      "episode 10, val func loss 0.9991047382354736\n",
      "\n",
      "episode 11, val func loss 1.2074483633041382\n",
      "\n",
      "episode 12, val func loss 0.9160500764846802\n",
      "\n",
      "episode 13, val func loss 0.9877189993858337\n",
      "\n",
      "episode 14, val func loss 1.2374074459075928\n",
      "\n",
      "episode 15, val func loss 0.9943663477897644\n",
      "\n",
      "episode 16, val func loss 1.1320661306381226\n",
      "\n",
      "Val func train loss in epoch 14:1.030471347272396\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.1041810512542725\n",
      "\n",
      "episode 2, val func loss 1.1560823917388916\n",
      "\n",
      "episode 3, val func loss 1.0918916463851929\n",
      "\n",
      "episode 4, val func loss 0.9890373945236206\n",
      "\n",
      "episode 5, val func loss 0.9825349450111389\n",
      "\n",
      "episode 6, val func loss 0.9899626970291138\n",
      "\n",
      "episode 7, val func loss 1.0295659303665161\n",
      "\n",
      "episode 8, val func loss 1.1221059560775757\n",
      "\n",
      "episode 9, val func loss 0.8068504333496094\n",
      "\n",
      "episode 10, val func loss 0.9468921422958374\n",
      "\n",
      "episode 11, val func loss 1.032679796218872\n",
      "\n",
      "episode 12, val func loss 0.9711065292358398\n",
      "\n",
      "episode 13, val func loss 0.9694887399673462\n",
      "\n",
      "episode 14, val func loss 0.9663412570953369\n",
      "\n",
      "episode 15, val func loss 1.0871464014053345\n",
      "\n",
      "episode 16, val func loss 0.9209780693054199\n",
      "\n",
      "Val func train loss in epoch 15:1.0104278363287449\n",
      "***********************TIME WAS 4.88441633383433 min*****************************\n",
      "\n",
      "**********************ROUND 95 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.3191065192222595\n",
      "\n",
      "episode 2, policy loss -0.31910648941993713\n",
      "\n",
      "episode 3, policy loss -0.3191065490245819\n",
      "\n",
      "episode 4, policy loss -0.3191065192222595\n",
      "\n",
      "episode 5, policy loss -0.3191065490245819\n",
      "\n",
      "episode 6, policy loss -0.3191065490245819\n",
      "\n",
      "episode 7, policy loss -0.3191065192222595\n",
      "\n",
      "episode 8, policy loss -0.31910645961761475\n",
      "\n",
      "episode 9, policy loss -0.31910645961761475\n",
      "\n",
      "episode 10, policy loss -0.3191065490245819\n",
      "\n",
      "episode 11, policy loss -0.31910648941993713\n",
      "\n",
      "episode 12, policy loss -0.3191065490245819\n",
      "\n",
      "episode 13, policy loss -0.3191065490245819\n",
      "\n",
      "episode 14, policy loss -0.31910648941993713\n",
      "\n",
      "episode 15, policy loss -0.3191065490245819\n",
      "\n",
      "episode 16, policy loss -0.3191065192222595\n",
      "\n",
      "Policy train loss in epoch 0:-0.3191065192222595\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.31910648941993713\n",
      "\n",
      "episode 2, policy loss -0.31910648941993713\n",
      "\n",
      "episode 3, policy loss -0.31910648941993713\n",
      "\n",
      "episode 4, policy loss -0.31910648941993713\n",
      "\n",
      "episode 5, policy loss -0.3191065490245819\n",
      "\n",
      "episode 6, policy loss -0.3191065490245819\n",
      "\n",
      "episode 7, policy loss -0.31910648941993713\n",
      "\n",
      "episode 8, policy loss -0.3191065490245819\n",
      "\n",
      "episode 9, policy loss -0.31910648941993713\n",
      "\n",
      "episode 10, policy loss -0.3191065490245819\n",
      "\n",
      "episode 11, policy loss -0.3191065490245819\n",
      "\n",
      "episode 12, policy loss -0.31910648941993713\n",
      "\n",
      "episode 13, policy loss -0.3191065192222595\n",
      "\n",
      "episode 14, policy loss -0.3191065490245819\n",
      "\n",
      "episode 15, policy loss -0.3191065788269043\n",
      "\n",
      "episode 16, policy loss -0.3191065490245819\n",
      "\n",
      "Policy train loss in epoch 1:-0.3191065229475498\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.31910648941993713\n",
      "\n",
      "episode 2, policy loss -0.3191065490245819\n",
      "\n",
      "episode 3, policy loss -0.3191065788269043\n",
      "\n",
      "episode 4, policy loss -0.31910648941993713\n",
      "\n",
      "episode 5, policy loss -0.3191065788269043\n",
      "\n",
      "episode 6, policy loss -0.3191065192222595\n",
      "\n",
      "episode 7, policy loss -0.3191065192222595\n",
      "\n",
      "episode 8, policy loss -0.31910648941993713\n",
      "\n",
      "episode 9, policy loss -0.3191065192222595\n",
      "\n",
      "episode 10, policy loss -0.3191065490245819\n",
      "\n",
      "episode 11, policy loss -0.31910648941993713\n",
      "\n",
      "episode 12, policy loss -0.3191065490245819\n",
      "\n",
      "episode 13, policy loss -0.31910648941993713\n",
      "\n",
      "episode 14, policy loss -0.3191065788269043\n",
      "\n",
      "episode 15, policy loss -0.3191065490245819\n",
      "\n",
      "episode 16, policy loss -0.31910645961761475\n",
      "\n",
      "Policy train loss in epoch 2:-0.31910652481019497\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.31910648941993713\n",
      "\n",
      "episode 2, policy loss -0.3191065490245819\n",
      "\n",
      "episode 3, policy loss -0.31910648941993713\n",
      "\n",
      "episode 4, policy loss -0.3191065490245819\n",
      "\n",
      "episode 5, policy loss -0.3191065490245819\n",
      "\n",
      "episode 6, policy loss -0.3191065192222595\n",
      "\n",
      "episode 7, policy loss -0.3191065490245819\n",
      "\n",
      "episode 8, policy loss -0.3191065192222595\n",
      "\n",
      "episode 9, policy loss -0.3191065490245819\n",
      "\n",
      "episode 10, policy loss -0.3191065788269043\n",
      "\n",
      "episode 11, policy loss -0.31910648941993713\n",
      "\n",
      "episode 12, policy loss -0.31910648941993713\n",
      "\n",
      "episode 13, policy loss -0.31910648941993713\n",
      "\n",
      "episode 14, policy loss -0.31910648941993713\n",
      "\n",
      "episode 15, policy loss -0.31910648941993713\n",
      "\n",
      "episode 16, policy loss -0.3191065192222595\n",
      "\n",
      "Policy train loss in epoch 3:-0.3191065192222595\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.1661521196365356\n",
      "\n",
      "episode 2, val func loss 0.9910900592803955\n",
      "\n",
      "episode 3, val func loss 1.1022204160690308\n",
      "\n",
      "episode 4, val func loss 1.0926510095596313\n",
      "\n",
      "episode 5, val func loss 0.8971453905105591\n",
      "\n",
      "episode 6, val func loss 0.9912733435630798\n",
      "\n",
      "episode 7, val func loss 0.9285718202590942\n",
      "\n",
      "episode 8, val func loss 0.8804309964179993\n",
      "\n",
      "episode 9, val func loss 0.898953914642334\n",
      "\n",
      "episode 10, val func loss 0.9784483313560486\n",
      "\n",
      "episode 11, val func loss 0.9780815839767456\n",
      "\n",
      "episode 12, val func loss 0.9928557276725769\n",
      "\n",
      "episode 13, val func loss 0.9363448023796082\n",
      "\n",
      "episode 14, val func loss 0.830816388130188\n",
      "\n",
      "episode 15, val func loss 1.0276730060577393\n",
      "\n",
      "episode 16, val func loss 0.8392636775970459\n",
      "\n",
      "Val func train loss in epoch 0:0.9707482866942883\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.9649850726127625\n",
      "\n",
      "episode 2, val func loss 1.0515072345733643\n",
      "\n",
      "episode 3, val func loss 0.9530452489852905\n",
      "\n",
      "episode 4, val func loss 1.2147578001022339\n",
      "\n",
      "episode 5, val func loss 0.9890850186347961\n",
      "\n",
      "episode 6, val func loss 0.8598110675811768\n",
      "\n",
      "episode 7, val func loss 1.1288341283798218\n",
      "\n",
      "episode 8, val func loss 0.9640881419181824\n",
      "\n",
      "episode 9, val func loss 1.291090726852417\n",
      "\n",
      "episode 10, val func loss 1.2099639177322388\n",
      "\n",
      "episode 11, val func loss 0.9151430726051331\n",
      "\n",
      "episode 12, val func loss 0.986871600151062\n",
      "\n",
      "episode 13, val func loss 0.9814183115959167\n",
      "\n",
      "episode 14, val func loss 1.1535365581512451\n",
      "\n",
      "episode 15, val func loss 1.166925072669983\n",
      "\n",
      "episode 16, val func loss 1.0535660982131958\n",
      "\n",
      "Val func train loss in epoch 1:1.0552893169224262\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.9238836169242859\n",
      "\n",
      "episode 2, val func loss 1.0229907035827637\n",
      "\n",
      "episode 3, val func loss 0.9409598112106323\n",
      "\n",
      "episode 4, val func loss 1.0116984844207764\n",
      "\n",
      "episode 5, val func loss 1.1049436330795288\n",
      "\n",
      "episode 6, val func loss 0.9420443177223206\n",
      "\n",
      "episode 7, val func loss 0.8815820813179016\n",
      "\n",
      "episode 8, val func loss 0.8785503506660461\n",
      "\n",
      "episode 9, val func loss 0.9294281005859375\n",
      "\n",
      "episode 10, val func loss 0.9655998945236206\n",
      "\n",
      "episode 11, val func loss 1.0018800497055054\n",
      "\n",
      "episode 12, val func loss 1.0887491703033447\n",
      "\n",
      "episode 13, val func loss 0.8943874835968018\n",
      "\n",
      "episode 14, val func loss 0.926021933555603\n",
      "\n",
      "episode 15, val func loss 1.0238357782363892\n",
      "\n",
      "episode 16, val func loss 1.0653650760650635\n",
      "\n",
      "Val func train loss in epoch 2:0.9751200303435326\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.9893329739570618\n",
      "\n",
      "episode 2, val func loss 1.0189199447631836\n",
      "\n",
      "episode 3, val func loss 0.8087731599807739\n",
      "\n",
      "episode 4, val func loss 0.8600692749023438\n",
      "\n",
      "episode 5, val func loss 0.9497942924499512\n",
      "\n",
      "episode 6, val func loss 0.9673141837120056\n",
      "\n",
      "episode 7, val func loss 0.9872894287109375\n",
      "\n",
      "episode 8, val func loss 0.9147030711174011\n",
      "\n",
      "episode 9, val func loss 0.9843692183494568\n",
      "\n",
      "episode 10, val func loss 0.9127821326255798\n",
      "\n",
      "episode 11, val func loss 0.9541571140289307\n",
      "\n",
      "episode 12, val func loss 0.8200827240943909\n",
      "\n",
      "episode 13, val func loss 0.9127134680747986\n",
      "\n",
      "episode 14, val func loss 1.0139851570129395\n",
      "\n",
      "episode 15, val func loss 0.8343378305435181\n",
      "\n",
      "episode 16, val func loss 0.7962188720703125\n",
      "\n",
      "Val func train loss in epoch 3:0.9203026778995991\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8508556485176086\n",
      "\n",
      "episode 2, val func loss 1.076566457748413\n",
      "\n",
      "episode 3, val func loss 0.9375731348991394\n",
      "\n",
      "episode 4, val func loss 0.9951702952384949\n",
      "\n",
      "episode 5, val func loss 0.9012953042984009\n",
      "\n",
      "episode 6, val func loss 0.8994734287261963\n",
      "\n",
      "episode 7, val func loss 0.9569272994995117\n",
      "\n",
      "episode 8, val func loss 0.8860440850257874\n",
      "\n",
      "episode 9, val func loss 0.9063196182250977\n",
      "\n",
      "episode 10, val func loss 0.8830695152282715\n",
      "\n",
      "episode 11, val func loss 1.0528916120529175\n",
      "\n",
      "episode 12, val func loss 0.8580063581466675\n",
      "\n",
      "episode 13, val func loss 0.8901032209396362\n",
      "\n",
      "episode 14, val func loss 0.8300595879554749\n",
      "\n",
      "episode 15, val func loss 0.8808521032333374\n",
      "\n",
      "episode 16, val func loss 0.9508346915245056\n",
      "\n",
      "Val func train loss in epoch 4:0.9222526475787163\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.0276274681091309\n",
      "\n",
      "episode 2, val func loss 0.9376726746559143\n",
      "\n",
      "episode 3, val func loss 0.8885267376899719\n",
      "\n",
      "episode 4, val func loss 0.9069557189941406\n",
      "\n",
      "episode 5, val func loss 0.9910417795181274\n",
      "\n",
      "episode 6, val func loss 0.9567054510116577\n",
      "\n",
      "episode 7, val func loss 0.9541869759559631\n",
      "\n",
      "episode 8, val func loss 0.9561806917190552\n",
      "\n",
      "episode 9, val func loss 1.0571738481521606\n",
      "\n",
      "episode 10, val func loss 0.897590160369873\n",
      "\n",
      "episode 11, val func loss 0.9058679938316345\n",
      "\n",
      "episode 12, val func loss 1.2023870944976807\n",
      "\n",
      "episode 13, val func loss 0.9842086434364319\n",
      "\n",
      "episode 14, val func loss 0.8380825519561768\n",
      "\n",
      "episode 15, val func loss 1.02279794216156\n",
      "\n",
      "episode 16, val func loss 1.0351624488830566\n",
      "\n",
      "Val func train loss in epoch 5:0.9726355113089085\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.9616495370864868\n",
      "\n",
      "episode 2, val func loss 1.0223584175109863\n",
      "\n",
      "episode 3, val func loss 0.8925915956497192\n",
      "\n",
      "episode 4, val func loss 0.8303976655006409\n",
      "\n",
      "episode 5, val func loss 0.8983311057090759\n",
      "\n",
      "episode 6, val func loss 0.8795469403266907\n",
      "\n",
      "episode 7, val func loss 0.9592409729957581\n",
      "\n",
      "episode 8, val func loss 1.0666872262954712\n",
      "\n",
      "episode 9, val func loss 0.8921195268630981\n",
      "\n",
      "episode 10, val func loss 0.9595224857330322\n",
      "\n",
      "episode 11, val func loss 0.9878078103065491\n",
      "\n",
      "episode 12, val func loss 0.9049348831176758\n",
      "\n",
      "episode 13, val func loss 0.8105355501174927\n",
      "\n",
      "episode 14, val func loss 0.9440764784812927\n",
      "\n",
      "episode 15, val func loss 0.8853676319122314\n",
      "\n",
      "episode 16, val func loss 1.0706900358200073\n",
      "\n",
      "Val func train loss in epoch 6:0.935366116464138\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.0847371816635132\n",
      "\n",
      "episode 2, val func loss 0.9783807992935181\n",
      "\n",
      "episode 3, val func loss 0.7947654128074646\n",
      "\n",
      "episode 4, val func loss 0.9575071930885315\n",
      "\n",
      "episode 5, val func loss 0.9221387505531311\n",
      "\n",
      "episode 6, val func loss 0.8982424736022949\n",
      "\n",
      "episode 7, val func loss 0.8895465135574341\n",
      "\n",
      "episode 8, val func loss 0.9160727262496948\n",
      "\n",
      "episode 9, val func loss 1.0190904140472412\n",
      "\n",
      "episode 10, val func loss 0.9614576697349548\n",
      "\n",
      "episode 11, val func loss 0.8292571306228638\n",
      "\n",
      "episode 12, val func loss 1.0007109642028809\n",
      "\n",
      "episode 13, val func loss 0.973410427570343\n",
      "\n",
      "episode 14, val func loss 0.9261559247970581\n",
      "\n",
      "episode 15, val func loss 0.8632729649543762\n",
      "\n",
      "episode 16, val func loss 1.0135891437530518\n",
      "\n",
      "Val func train loss in epoch 7:0.939270980656147\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.9683011174201965\n",
      "\n",
      "episode 2, val func loss 0.8814610242843628\n",
      "\n",
      "episode 3, val func loss 1.123029351234436\n",
      "\n",
      "episode 4, val func loss 0.9380367398262024\n",
      "\n",
      "episode 5, val func loss 1.072372317314148\n",
      "\n",
      "episode 6, val func loss 0.9559065103530884\n",
      "\n",
      "episode 7, val func loss 0.927855908870697\n",
      "\n",
      "episode 8, val func loss 1.0065217018127441\n",
      "\n",
      "episode 9, val func loss 0.9563260674476624\n",
      "\n",
      "episode 10, val func loss 0.9089005589485168\n",
      "\n",
      "episode 11, val func loss 0.9029347896575928\n",
      "\n",
      "episode 12, val func loss 0.9695253968238831\n",
      "\n",
      "episode 13, val func loss 1.0594749450683594\n",
      "\n",
      "episode 14, val func loss 0.8854625821113586\n",
      "\n",
      "episode 15, val func loss 0.9743446111679077\n",
      "\n",
      "episode 16, val func loss 0.951278567314148\n",
      "\n",
      "Val func train loss in epoch 8:0.9676082618534565\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.0169358253479004\n",
      "\n",
      "episode 2, val func loss 0.8577768206596375\n",
      "\n",
      "episode 3, val func loss 0.9533021450042725\n",
      "\n",
      "episode 4, val func loss 0.922185480594635\n",
      "\n",
      "episode 5, val func loss 0.8388016819953918\n",
      "\n",
      "episode 6, val func loss 0.8282805681228638\n",
      "\n",
      "episode 7, val func loss 1.0650955438613892\n",
      "\n",
      "episode 8, val func loss 0.827642023563385\n",
      "\n",
      "episode 9, val func loss 1.081800937652588\n",
      "\n",
      "episode 10, val func loss 0.9436662197113037\n",
      "\n",
      "episode 11, val func loss 0.9925870895385742\n",
      "\n",
      "episode 12, val func loss 0.9981104135513306\n",
      "\n",
      "episode 13, val func loss 0.8975948691368103\n",
      "\n",
      "episode 14, val func loss 1.0086055994033813\n",
      "\n",
      "episode 15, val func loss 0.8760653138160706\n",
      "\n",
      "episode 16, val func loss 1.162793517112732\n",
      "\n",
      "Val func train loss in epoch 9:0.9544527530670166\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.9504762887954712\n",
      "\n",
      "episode 2, val func loss 0.8437536358833313\n",
      "\n",
      "episode 3, val func loss 1.0306895971298218\n",
      "\n",
      "episode 4, val func loss 0.9065382480621338\n",
      "\n",
      "episode 5, val func loss 0.840733528137207\n",
      "\n",
      "episode 6, val func loss 0.9906293153762817\n",
      "\n",
      "episode 7, val func loss 0.8986998796463013\n",
      "\n",
      "episode 8, val func loss 0.8887218236923218\n",
      "\n",
      "episode 9, val func loss 0.8620263934135437\n",
      "\n",
      "episode 10, val func loss 1.007779836654663\n",
      "\n",
      "episode 11, val func loss 0.8695979714393616\n",
      "\n",
      "episode 12, val func loss 0.8111588358879089\n",
      "\n",
      "episode 13, val func loss 0.9054363369941711\n",
      "\n",
      "episode 14, val func loss 1.0702623128890991\n",
      "\n",
      "episode 15, val func loss 0.9252088069915771\n",
      "\n",
      "episode 16, val func loss 1.025063395500183\n",
      "\n",
      "Val func train loss in epoch 10:0.9266735129058361\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9183491468429565\n",
      "\n",
      "episode 2, val func loss 0.8895190954208374\n",
      "\n",
      "episode 3, val func loss 0.9031198024749756\n",
      "\n",
      "episode 4, val func loss 0.845210075378418\n",
      "\n",
      "episode 5, val func loss 0.844193696975708\n",
      "\n",
      "episode 6, val func loss 0.9945207238197327\n",
      "\n",
      "episode 7, val func loss 0.9771634936332703\n",
      "\n",
      "episode 8, val func loss 0.7998271584510803\n",
      "\n",
      "episode 9, val func loss 0.9282692670822144\n",
      "\n",
      "episode 10, val func loss 0.9339760541915894\n",
      "\n",
      "episode 11, val func loss 0.9181002378463745\n",
      "\n",
      "episode 12, val func loss 0.8275487422943115\n",
      "\n",
      "episode 13, val func loss 0.9901116490364075\n",
      "\n",
      "episode 14, val func loss 0.8795716762542725\n",
      "\n",
      "episode 15, val func loss 0.9079685211181641\n",
      "\n",
      "episode 16, val func loss 1.002652645111084\n",
      "\n",
      "Val func train loss in epoch 11:0.9100063741207123\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.9282049536705017\n",
      "\n",
      "episode 2, val func loss 0.8393771052360535\n",
      "\n",
      "episode 3, val func loss 0.9402162432670593\n",
      "\n",
      "episode 4, val func loss 1.1044307947158813\n",
      "\n",
      "episode 5, val func loss 0.8938739895820618\n",
      "\n",
      "episode 6, val func loss 0.9414079189300537\n",
      "\n",
      "episode 7, val func loss 0.9709481000900269\n",
      "\n",
      "episode 8, val func loss 0.8805475234985352\n",
      "\n",
      "episode 9, val func loss 1.06504225730896\n",
      "\n",
      "episode 10, val func loss 0.8643233180046082\n",
      "\n",
      "episode 11, val func loss 1.0765292644500732\n",
      "\n",
      "episode 12, val func loss 1.0091636180877686\n",
      "\n",
      "episode 13, val func loss 0.8856469392776489\n",
      "\n",
      "episode 14, val func loss 0.8475114703178406\n",
      "\n",
      "episode 15, val func loss 1.0471956729888916\n",
      "\n",
      "episode 16, val func loss 0.9920235872268677\n",
      "\n",
      "Val func train loss in epoch 12:0.955402672290802\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8840816617012024\n",
      "\n",
      "episode 2, val func loss 0.9904045462608337\n",
      "\n",
      "episode 3, val func loss 1.0883294343948364\n",
      "\n",
      "episode 4, val func loss 1.1120070219039917\n",
      "\n",
      "episode 5, val func loss 0.9344998598098755\n",
      "\n",
      "episode 6, val func loss 0.9156046509742737\n",
      "\n",
      "episode 7, val func loss 1.0377610921859741\n",
      "\n",
      "episode 8, val func loss 0.9524694085121155\n",
      "\n",
      "episode 9, val func loss 0.9053617715835571\n",
      "\n",
      "episode 10, val func loss 0.944305419921875\n",
      "\n",
      "episode 11, val func loss 0.8437539935112\n",
      "\n",
      "episode 12, val func loss 0.9465295672416687\n",
      "\n",
      "episode 13, val func loss 0.7877230644226074\n",
      "\n",
      "episode 14, val func loss 1.0175690650939941\n",
      "\n",
      "episode 15, val func loss 1.016541838645935\n",
      "\n",
      "episode 16, val func loss 1.0033442974090576\n",
      "\n",
      "Val func train loss in epoch 13:0.9612679183483124\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.000993013381958\n",
      "\n",
      "episode 2, val func loss 0.9354900121688843\n",
      "\n",
      "episode 3, val func loss 0.8520221710205078\n",
      "\n",
      "episode 4, val func loss 0.793255090713501\n",
      "\n",
      "episode 5, val func loss 0.819129467010498\n",
      "\n",
      "episode 6, val func loss 1.0079959630966187\n",
      "\n",
      "episode 7, val func loss 0.7535416483879089\n",
      "\n",
      "episode 8, val func loss 0.8918854594230652\n",
      "\n",
      "episode 9, val func loss 0.9210650324821472\n",
      "\n",
      "episode 10, val func loss 0.9001939296722412\n",
      "\n",
      "episode 11, val func loss 0.860942006111145\n",
      "\n",
      "episode 12, val func loss 0.9801573157310486\n",
      "\n",
      "episode 13, val func loss 1.0066102743148804\n",
      "\n",
      "episode 14, val func loss 0.9599303007125854\n",
      "\n",
      "episode 15, val func loss 0.8296985626220703\n",
      "\n",
      "episode 16, val func loss 0.939693808555603\n",
      "\n",
      "Val func train loss in epoch 14:0.9032877534627914\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.9178148508071899\n",
      "\n",
      "episode 2, val func loss 1.018178105354309\n",
      "\n",
      "episode 3, val func loss 0.9551816582679749\n",
      "\n",
      "episode 4, val func loss 0.844268262386322\n",
      "\n",
      "episode 5, val func loss 0.988272488117218\n",
      "\n",
      "episode 6, val func loss 0.8892823457717896\n",
      "\n",
      "episode 7, val func loss 0.8240112662315369\n",
      "\n",
      "episode 8, val func loss 0.8814916610717773\n",
      "\n",
      "episode 9, val func loss 0.9631211757659912\n",
      "\n",
      "episode 10, val func loss 0.8045944571495056\n",
      "\n",
      "episode 11, val func loss 0.9654487371444702\n",
      "\n",
      "episode 12, val func loss 0.8945252895355225\n",
      "\n",
      "episode 13, val func loss 0.8967551589012146\n",
      "\n",
      "episode 14, val func loss 0.9839472770690918\n",
      "\n",
      "episode 15, val func loss 0.8504706025123596\n",
      "\n",
      "episode 16, val func loss 0.9798645377159119\n",
      "\n",
      "Val func train loss in epoch 15:0.9160767421126366\n",
      "***********************TIME WAS 4.886978356043498 min*****************************\n",
      "\n",
      "**********************ROUND 96 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.030843155458569527\n",
      "\n",
      "episode 2, policy loss 0.030842963606119156\n",
      "\n",
      "episode 3, policy loss 0.030842820182442665\n",
      "\n",
      "episode 4, policy loss 0.03084317222237587\n",
      "\n",
      "episode 5, policy loss 0.03084319457411766\n",
      "\n",
      "episode 6, policy loss 0.030843153595924377\n",
      "\n",
      "episode 7, policy loss 0.0308432187885046\n",
      "\n",
      "episode 8, policy loss 0.030843030661344528\n",
      "\n",
      "episode 9, policy loss 0.030843107029795647\n",
      "\n",
      "episode 10, policy loss 0.03084307536482811\n",
      "\n",
      "episode 11, policy loss 0.030843036249279976\n",
      "\n",
      "episode 12, policy loss 0.03084290400147438\n",
      "\n",
      "episode 13, policy loss 0.030843166634440422\n",
      "\n",
      "episode 14, policy loss 0.030843017622828484\n",
      "\n",
      "episode 15, policy loss 0.03084316849708557\n",
      "\n",
      "episode 16, policy loss 0.030843045562505722\n",
      "\n",
      "Policy train loss in epoch 0:0.030843076878227293\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.03084312379360199\n",
      "\n",
      "episode 2, policy loss 0.030843188986182213\n",
      "\n",
      "episode 3, policy loss 0.030843203887343407\n",
      "\n",
      "episode 4, policy loss 0.030843084678053856\n",
      "\n",
      "episode 5, policy loss 0.030843039974570274\n",
      "\n",
      "episode 6, policy loss 0.030843250453472137\n",
      "\n",
      "episode 7, policy loss 0.03084314987063408\n",
      "\n",
      "episode 8, policy loss 0.030843036249279976\n",
      "\n",
      "episode 9, policy loss 0.030842820182442665\n",
      "\n",
      "episode 10, policy loss 0.030843012034893036\n",
      "\n",
      "episode 11, policy loss 0.030843215063214302\n",
      "\n",
      "episode 12, policy loss 0.03084293007850647\n",
      "\n",
      "episode 13, policy loss 0.03084307536482811\n",
      "\n",
      "episode 14, policy loss 0.03084316849708557\n",
      "\n",
      "episode 15, policy loss 0.03084314800798893\n",
      "\n",
      "episode 16, policy loss 0.030842963606119156\n",
      "\n",
      "Policy train loss in epoch 1:0.03084308817051351\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.030843224376440048\n",
      "\n",
      "episode 2, policy loss 0.030842820182442665\n",
      "\n",
      "episode 3, policy loss 0.030842920765280724\n",
      "\n",
      "episode 4, policy loss 0.030843012034893036\n",
      "\n",
      "episode 5, policy loss 0.030843142420053482\n",
      "\n",
      "episode 6, policy loss 0.030843112617731094\n",
      "\n",
      "episode 7, policy loss 0.030843155458569527\n",
      "\n",
      "episode 8, policy loss 0.030843166634440422\n",
      "\n",
      "episode 9, policy loss 0.03084307536482811\n",
      "\n",
      "episode 10, policy loss 0.030843215063214302\n",
      "\n",
      "episode 11, policy loss 0.03084302321076393\n",
      "\n",
      "episode 12, policy loss 0.030843064188957214\n",
      "\n",
      "episode 13, policy loss 0.030843215063214302\n",
      "\n",
      "episode 14, policy loss 0.030843079090118408\n",
      "\n",
      "episode 15, policy loss 0.03084304742515087\n",
      "\n",
      "episode 16, policy loss 0.030842909589409828\n",
      "\n",
      "Policy train loss in epoch 2:0.030843073967844248\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.030843153595924377\n",
      "\n",
      "episode 2, policy loss 0.030843207612633705\n",
      "\n",
      "episode 3, policy loss 0.03084317222237587\n",
      "\n",
      "episode 4, policy loss 0.030843166634440422\n",
      "\n",
      "episode 5, policy loss 0.030843015760183334\n",
      "\n",
      "episode 6, policy loss 0.030843226239085197\n",
      "\n",
      "episode 7, policy loss 0.030842941254377365\n",
      "\n",
      "episode 8, policy loss 0.03084312379360199\n",
      "\n",
      "episode 9, policy loss 0.03084290400147438\n",
      "\n",
      "episode 10, policy loss 0.030843069776892662\n",
      "\n",
      "episode 11, policy loss 0.030843064188957214\n",
      "\n",
      "episode 12, policy loss 0.030843006446957588\n",
      "\n",
      "episode 13, policy loss 0.03084280900657177\n",
      "\n",
      "episode 14, policy loss 0.030843054875731468\n",
      "\n",
      "episode 15, policy loss 0.03084307163953781\n",
      "\n",
      "episode 16, policy loss 0.03084309585392475\n",
      "\n",
      "Policy train loss in epoch 3:0.03084306768141687\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.9423982501029968\n",
      "\n",
      "episode 2, val func loss 0.920868456363678\n",
      "\n",
      "episode 3, val func loss 0.9230819344520569\n",
      "\n",
      "episode 4, val func loss 0.9308450222015381\n",
      "\n",
      "episode 5, val func loss 0.8749796152114868\n",
      "\n",
      "episode 6, val func loss 0.9128167629241943\n",
      "\n",
      "episode 7, val func loss 1.0651917457580566\n",
      "\n",
      "episode 8, val func loss 0.9785460829734802\n",
      "\n",
      "episode 9, val func loss 0.9456318020820618\n",
      "\n",
      "episode 10, val func loss 0.9815484285354614\n",
      "\n",
      "episode 11, val func loss 0.9543770551681519\n",
      "\n",
      "episode 12, val func loss 0.9302219748497009\n",
      "\n",
      "episode 13, val func loss 0.9322437047958374\n",
      "\n",
      "episode 14, val func loss 0.9151462912559509\n",
      "\n",
      "episode 15, val func loss 1.0552752017974854\n",
      "\n",
      "episode 16, val func loss 0.9143239259719849\n",
      "\n",
      "Val func train loss in epoch 0:0.9485935159027576\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8658062815666199\n",
      "\n",
      "episode 2, val func loss 0.9559518694877625\n",
      "\n",
      "episode 3, val func loss 0.8243869543075562\n",
      "\n",
      "episode 4, val func loss 0.852234423160553\n",
      "\n",
      "episode 5, val func loss 0.8847029209136963\n",
      "\n",
      "episode 6, val func loss 0.8785673975944519\n",
      "\n",
      "episode 7, val func loss 0.9649553894996643\n",
      "\n",
      "episode 8, val func loss 0.8918478488922119\n",
      "\n",
      "episode 9, val func loss 0.9216046929359436\n",
      "\n",
      "episode 10, val func loss 0.884572446346283\n",
      "\n",
      "episode 11, val func loss 0.8946261405944824\n",
      "\n",
      "episode 12, val func loss 0.8310713171958923\n",
      "\n",
      "episode 13, val func loss 0.7917312979698181\n",
      "\n",
      "episode 14, val func loss 0.8268266916275024\n",
      "\n",
      "episode 15, val func loss 0.94245445728302\n",
      "\n",
      "episode 16, val func loss 0.8371770977973938\n",
      "\n",
      "Val func train loss in epoch 1:0.8780323266983032\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.8261853456497192\n",
      "\n",
      "episode 2, val func loss 0.8393182754516602\n",
      "\n",
      "episode 3, val func loss 0.8229808807373047\n",
      "\n",
      "episode 4, val func loss 0.8847628831863403\n",
      "\n",
      "episode 5, val func loss 0.8079855442047119\n",
      "\n",
      "episode 6, val func loss 0.813299834728241\n",
      "\n",
      "episode 7, val func loss 0.7339484095573425\n",
      "\n",
      "episode 8, val func loss 0.9126250147819519\n",
      "\n",
      "episode 9, val func loss 0.7418844103813171\n",
      "\n",
      "episode 10, val func loss 0.74083012342453\n",
      "\n",
      "episode 11, val func loss 0.7951472997665405\n",
      "\n",
      "episode 12, val func loss 0.8373357057571411\n",
      "\n",
      "episode 13, val func loss 0.9285295009613037\n",
      "\n",
      "episode 14, val func loss 0.9288557767868042\n",
      "\n",
      "episode 15, val func loss 0.9818500876426697\n",
      "\n",
      "episode 16, val func loss 0.9398608207702637\n",
      "\n",
      "Val func train loss in epoch 2:0.8459624946117401\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.9175103306770325\n",
      "\n",
      "episode 2, val func loss 0.9188011884689331\n",
      "\n",
      "episode 3, val func loss 0.828592836856842\n",
      "\n",
      "episode 4, val func loss 0.833949089050293\n",
      "\n",
      "episode 5, val func loss 0.9070318937301636\n",
      "\n",
      "episode 6, val func loss 0.8528530597686768\n",
      "\n",
      "episode 7, val func loss 0.9380214810371399\n",
      "\n",
      "episode 8, val func loss 0.8586834073066711\n",
      "\n",
      "episode 9, val func loss 0.790544331073761\n",
      "\n",
      "episode 10, val func loss 0.9259207248687744\n",
      "\n",
      "episode 11, val func loss 0.9466246962547302\n",
      "\n",
      "episode 12, val func loss 0.8173723816871643\n",
      "\n",
      "episode 13, val func loss 0.87208491563797\n",
      "\n",
      "episode 14, val func loss 1.020294189453125\n",
      "\n",
      "episode 15, val func loss 0.9061664938926697\n",
      "\n",
      "episode 16, val func loss 0.8620327711105347\n",
      "\n",
      "Val func train loss in epoch 3:0.8872802369296551\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8643667697906494\n",
      "\n",
      "episode 2, val func loss 0.837057888507843\n",
      "\n",
      "episode 3, val func loss 0.8482697606086731\n",
      "\n",
      "episode 4, val func loss 0.8260673880577087\n",
      "\n",
      "episode 5, val func loss 0.9439128637313843\n",
      "\n",
      "episode 6, val func loss 0.7809706926345825\n",
      "\n",
      "episode 7, val func loss 0.9146912693977356\n",
      "\n",
      "episode 8, val func loss 0.8738269805908203\n",
      "\n",
      "episode 9, val func loss 1.0393602848052979\n",
      "\n",
      "episode 10, val func loss 0.859516978263855\n",
      "\n",
      "episode 11, val func loss 1.017624020576477\n",
      "\n",
      "episode 12, val func loss 0.9545135498046875\n",
      "\n",
      "episode 13, val func loss 0.8569422960281372\n",
      "\n",
      "episode 14, val func loss 0.8323549628257751\n",
      "\n",
      "episode 15, val func loss 0.9400269985198975\n",
      "\n",
      "episode 16, val func loss 0.8512545228004456\n",
      "\n",
      "Val func train loss in epoch 4:0.8900473266839981\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.832490086555481\n",
      "\n",
      "episode 2, val func loss 0.9144994020462036\n",
      "\n",
      "episode 3, val func loss 0.90511155128479\n",
      "\n",
      "episode 4, val func loss 0.97756028175354\n",
      "\n",
      "episode 5, val func loss 0.8657629489898682\n",
      "\n",
      "episode 6, val func loss 0.7817746996879578\n",
      "\n",
      "episode 7, val func loss 0.958541214466095\n",
      "\n",
      "episode 8, val func loss 0.8815383911132812\n",
      "\n",
      "episode 9, val func loss 0.8495364189147949\n",
      "\n",
      "episode 10, val func loss 0.8411797285079956\n",
      "\n",
      "episode 11, val func loss 0.8856323957443237\n",
      "\n",
      "episode 12, val func loss 0.9014648795127869\n",
      "\n",
      "episode 13, val func loss 0.7550037503242493\n",
      "\n",
      "episode 14, val func loss 0.9998512268066406\n",
      "\n",
      "episode 15, val func loss 0.8702542781829834\n",
      "\n",
      "episode 16, val func loss 0.8051764369010925\n",
      "\n",
      "Val func train loss in epoch 5:0.8765861056745052\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7913038730621338\n",
      "\n",
      "episode 2, val func loss 0.8133619427680969\n",
      "\n",
      "episode 3, val func loss 0.8506938219070435\n",
      "\n",
      "episode 4, val func loss 0.7995368242263794\n",
      "\n",
      "episode 5, val func loss 0.8237581253051758\n",
      "\n",
      "episode 6, val func loss 0.8494249582290649\n",
      "\n",
      "episode 7, val func loss 0.8535431027412415\n",
      "\n",
      "episode 8, val func loss 0.836533784866333\n",
      "\n",
      "episode 9, val func loss 0.8325072526931763\n",
      "\n",
      "episode 10, val func loss 0.9258789420127869\n",
      "\n",
      "episode 11, val func loss 0.9241154193878174\n",
      "\n",
      "episode 12, val func loss 0.8017639517784119\n",
      "\n",
      "episode 13, val func loss 0.9733956456184387\n",
      "\n",
      "episode 14, val func loss 0.9536680579185486\n",
      "\n",
      "episode 15, val func loss 0.7811586260795593\n",
      "\n",
      "episode 16, val func loss 0.9571772217750549\n",
      "\n",
      "Val func train loss in epoch 6:0.8604888468980789\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.8963591456413269\n",
      "\n",
      "episode 2, val func loss 0.8568397164344788\n",
      "\n",
      "episode 3, val func loss 0.8764590620994568\n",
      "\n",
      "episode 4, val func loss 0.7621650695800781\n",
      "\n",
      "episode 5, val func loss 0.9109288454055786\n",
      "\n",
      "episode 6, val func loss 0.7909423112869263\n",
      "\n",
      "episode 7, val func loss 0.7820463180541992\n",
      "\n",
      "episode 8, val func loss 0.8706803917884827\n",
      "\n",
      "episode 9, val func loss 0.9199124574661255\n",
      "\n",
      "episode 10, val func loss 0.7984182834625244\n",
      "\n",
      "episode 11, val func loss 0.871472179889679\n",
      "\n",
      "episode 12, val func loss 0.8394372463226318\n",
      "\n",
      "episode 13, val func loss 0.770865261554718\n",
      "\n",
      "episode 14, val func loss 0.8905747532844543\n",
      "\n",
      "episode 15, val func loss 0.9541451930999756\n",
      "\n",
      "episode 16, val func loss 0.8306974768638611\n",
      "\n",
      "Val func train loss in epoch 7:0.8513714820146561\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.9002967476844788\n",
      "\n",
      "episode 2, val func loss 1.0408178567886353\n",
      "\n",
      "episode 3, val func loss 0.943717896938324\n",
      "\n",
      "episode 4, val func loss 0.7849107980728149\n",
      "\n",
      "episode 5, val func loss 1.0171061754226685\n",
      "\n",
      "episode 6, val func loss 1.0172226428985596\n",
      "\n",
      "episode 7, val func loss 0.794617235660553\n",
      "\n",
      "episode 8, val func loss 0.9701561331748962\n",
      "\n",
      "episode 9, val func loss 1.021781086921692\n",
      "\n",
      "episode 10, val func loss 0.7216626405715942\n",
      "\n",
      "episode 11, val func loss 0.918183445930481\n",
      "\n",
      "episode 12, val func loss 0.9321978092193604\n",
      "\n",
      "episode 13, val func loss 0.8075324296951294\n",
      "\n",
      "episode 14, val func loss 0.8373903632164001\n",
      "\n",
      "episode 15, val func loss 0.956095278263092\n",
      "\n",
      "episode 16, val func loss 0.7359271049499512\n",
      "\n",
      "Val func train loss in epoch 8:0.8999759778380394\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8988839983940125\n",
      "\n",
      "episode 2, val func loss 0.8462368845939636\n",
      "\n",
      "episode 3, val func loss 0.7955677509307861\n",
      "\n",
      "episode 4, val func loss 0.7809965014457703\n",
      "\n",
      "episode 5, val func loss 0.7890518307685852\n",
      "\n",
      "episode 6, val func loss 0.849223792552948\n",
      "\n",
      "episode 7, val func loss 0.8547748327255249\n",
      "\n",
      "episode 8, val func loss 0.8536214828491211\n",
      "\n",
      "episode 9, val func loss 0.8539171814918518\n",
      "\n",
      "episode 10, val func loss 0.8146899938583374\n",
      "\n",
      "episode 11, val func loss 0.8196969628334045\n",
      "\n",
      "episode 12, val func loss 0.7544201016426086\n",
      "\n",
      "episode 13, val func loss 0.8033987879753113\n",
      "\n",
      "episode 14, val func loss 0.8997423052787781\n",
      "\n",
      "episode 15, val func loss 0.758011519908905\n",
      "\n",
      "episode 16, val func loss 0.9216594696044922\n",
      "\n",
      "Val func train loss in epoch 9:0.8308683373034\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7577354907989502\n",
      "\n",
      "episode 2, val func loss 0.892096996307373\n",
      "\n",
      "episode 3, val func loss 0.7357316613197327\n",
      "\n",
      "episode 4, val func loss 0.7744059562683105\n",
      "\n",
      "episode 5, val func loss 0.8009573817253113\n",
      "\n",
      "episode 6, val func loss 0.9129083156585693\n",
      "\n",
      "episode 7, val func loss 0.8077630996704102\n",
      "\n",
      "episode 8, val func loss 0.8495159149169922\n",
      "\n",
      "episode 9, val func loss 0.8935580849647522\n",
      "\n",
      "episode 10, val func loss 0.70729660987854\n",
      "\n",
      "episode 11, val func loss 0.8298468589782715\n",
      "\n",
      "episode 12, val func loss 0.9051655530929565\n",
      "\n",
      "episode 13, val func loss 0.8009414672851562\n",
      "\n",
      "episode 14, val func loss 0.8130197525024414\n",
      "\n",
      "episode 15, val func loss 0.7957680821418762\n",
      "\n",
      "episode 16, val func loss 0.8441925048828125\n",
      "\n",
      "Val func train loss in epoch 10:0.8200564831495285\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.8626944422721863\n",
      "\n",
      "episode 2, val func loss 0.8712584376335144\n",
      "\n",
      "episode 3, val func loss 0.7547246217727661\n",
      "\n",
      "episode 4, val func loss 0.9047474265098572\n",
      "\n",
      "episode 5, val func loss 0.7619779109954834\n",
      "\n",
      "episode 6, val func loss 0.7817879915237427\n",
      "\n",
      "episode 7, val func loss 0.7806643843650818\n",
      "\n",
      "episode 8, val func loss 0.7688283920288086\n",
      "\n",
      "episode 9, val func loss 0.7882370352745056\n",
      "\n",
      "episode 10, val func loss 0.7646176218986511\n",
      "\n",
      "episode 11, val func loss 0.8961098194122314\n",
      "\n",
      "episode 12, val func loss 0.8482527136802673\n",
      "\n",
      "episode 13, val func loss 0.7710752487182617\n",
      "\n",
      "episode 14, val func loss 0.8628126382827759\n",
      "\n",
      "episode 15, val func loss 0.9014501571655273\n",
      "\n",
      "episode 16, val func loss 0.7840007543563843\n",
      "\n",
      "Val func train loss in epoch 11:0.8189524747431278\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.9271482825279236\n",
      "\n",
      "episode 2, val func loss 1.0564100742340088\n",
      "\n",
      "episode 3, val func loss 0.8315804600715637\n",
      "\n",
      "episode 4, val func loss 0.8470788598060608\n",
      "\n",
      "episode 5, val func loss 0.8596264719963074\n",
      "\n",
      "episode 6, val func loss 0.9607651233673096\n",
      "\n",
      "episode 7, val func loss 0.822952926158905\n",
      "\n",
      "episode 8, val func loss 0.7775431275367737\n",
      "\n",
      "episode 9, val func loss 1.0563710927963257\n",
      "\n",
      "episode 10, val func loss 0.9142079949378967\n",
      "\n",
      "episode 11, val func loss 0.8878164887428284\n",
      "\n",
      "episode 12, val func loss 0.7851064801216125\n",
      "\n",
      "episode 13, val func loss 0.7862844467163086\n",
      "\n",
      "episode 14, val func loss 0.9009721279144287\n",
      "\n",
      "episode 15, val func loss 0.8158735632896423\n",
      "\n",
      "episode 16, val func loss 0.8564100861549377\n",
      "\n",
      "Val func train loss in epoch 12:0.8803842253983021\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8230695724487305\n",
      "\n",
      "episode 2, val func loss 0.8879228830337524\n",
      "\n",
      "episode 3, val func loss 0.8274099826812744\n",
      "\n",
      "episode 4, val func loss 0.8073954582214355\n",
      "\n",
      "episode 5, val func loss 0.9426533579826355\n",
      "\n",
      "episode 6, val func loss 0.8758248090744019\n",
      "\n",
      "episode 7, val func loss 0.8368631601333618\n",
      "\n",
      "episode 8, val func loss 0.9256773591041565\n",
      "\n",
      "episode 9, val func loss 0.877122700214386\n",
      "\n",
      "episode 10, val func loss 0.8346899151802063\n",
      "\n",
      "episode 11, val func loss 0.8267849087715149\n",
      "\n",
      "episode 12, val func loss 0.9041219353675842\n",
      "\n",
      "episode 13, val func loss 0.7102416753768921\n",
      "\n",
      "episode 14, val func loss 0.766318142414093\n",
      "\n",
      "episode 15, val func loss 0.8054260611534119\n",
      "\n",
      "episode 16, val func loss 0.7898160815238953\n",
      "\n",
      "Val func train loss in epoch 13:0.8400836251676083\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6889263987541199\n",
      "\n",
      "episode 2, val func loss 0.771608293056488\n",
      "\n",
      "episode 3, val func loss 0.8942222595214844\n",
      "\n",
      "episode 4, val func loss 0.8532801866531372\n",
      "\n",
      "episode 5, val func loss 0.8327938914299011\n",
      "\n",
      "episode 6, val func loss 0.8266577124595642\n",
      "\n",
      "episode 7, val func loss 0.8055033683776855\n",
      "\n",
      "episode 8, val func loss 0.9003702402114868\n",
      "\n",
      "episode 9, val func loss 0.9021798968315125\n",
      "\n",
      "episode 10, val func loss 0.7564959526062012\n",
      "\n",
      "episode 11, val func loss 0.6971422433853149\n",
      "\n",
      "episode 12, val func loss 0.8709236979484558\n",
      "\n",
      "episode 13, val func loss 0.7956501841545105\n",
      "\n",
      "episode 14, val func loss 0.7958324551582336\n",
      "\n",
      "episode 15, val func loss 0.8489600419998169\n",
      "\n",
      "episode 16, val func loss 0.84175705909729\n",
      "\n",
      "Val func train loss in epoch 14:0.8176439926028252\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7710259556770325\n",
      "\n",
      "episode 2, val func loss 0.8012053370475769\n",
      "\n",
      "episode 3, val func loss 0.8662503361701965\n",
      "\n",
      "episode 4, val func loss 0.7671428322792053\n",
      "\n",
      "episode 5, val func loss 0.7715152502059937\n",
      "\n",
      "episode 6, val func loss 0.7907807230949402\n",
      "\n",
      "episode 7, val func loss 0.9081298112869263\n",
      "\n",
      "episode 8, val func loss 0.8676519393920898\n",
      "\n",
      "episode 9, val func loss 0.8226240277290344\n",
      "\n",
      "episode 10, val func loss 0.7591158151626587\n",
      "\n",
      "episode 11, val func loss 0.8522630929946899\n",
      "\n",
      "episode 12, val func loss 0.8092676401138306\n",
      "\n",
      "episode 13, val func loss 0.9418628811836243\n",
      "\n",
      "episode 14, val func loss 0.769058346748352\n",
      "\n",
      "episode 15, val func loss 0.8239692449569702\n",
      "\n",
      "episode 16, val func loss 0.8907326459884644\n",
      "\n",
      "Val func train loss in epoch 15:0.8257872425019741\n",
      "***********************TIME WAS 4.8873760342597965 min*****************************\n",
      "\n",
      "**********************ROUND 97 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 3.125\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.7684151530265808\n",
      "\n",
      "episode 2, policy loss 0.7684152722358704\n",
      "\n",
      "episode 3, policy loss 0.7684152722358704\n",
      "\n",
      "episode 4, policy loss 0.7684152722358704\n",
      "\n",
      "episode 5, policy loss 0.7684152722358704\n",
      "\n",
      "episode 6, policy loss 0.7684152126312256\n",
      "\n",
      "episode 7, policy loss 0.7684152126312256\n",
      "\n",
      "episode 8, policy loss 0.7684153914451599\n",
      "\n",
      "episode 9, policy loss 0.7684152722358704\n",
      "\n",
      "episode 10, policy loss 0.7684152722358704\n",
      "\n",
      "episode 11, policy loss 0.7684152126312256\n",
      "\n",
      "episode 12, policy loss 0.7684152722358704\n",
      "\n",
      "episode 13, policy loss 0.7684152722358704\n",
      "\n",
      "episode 14, policy loss 0.7684152722358704\n",
      "\n",
      "episode 15, policy loss 0.7684152126312256\n",
      "\n",
      "episode 16, policy loss 0.7684152126312256\n",
      "\n",
      "Policy train loss in epoch 0:0.7684152536094189\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.7684152722358704\n",
      "\n",
      "episode 2, policy loss 0.7684152722358704\n",
      "\n",
      "episode 3, policy loss 0.7684152722358704\n",
      "\n",
      "episode 4, policy loss 0.7684152722358704\n",
      "\n",
      "episode 5, policy loss 0.7684152722358704\n",
      "\n",
      "episode 6, policy loss 0.7684153914451599\n",
      "\n",
      "episode 7, policy loss 0.7684152126312256\n",
      "\n",
      "episode 8, policy loss 0.7684152722358704\n",
      "\n",
      "episode 9, policy loss 0.7684152722358704\n",
      "\n",
      "episode 10, policy loss 0.7684152126312256\n",
      "\n",
      "episode 11, policy loss 0.7684152722358704\n",
      "\n",
      "episode 12, policy loss 0.7684151530265808\n",
      "\n",
      "episode 13, policy loss 0.7684152126312256\n",
      "\n",
      "episode 14, policy loss 0.7684151530265808\n",
      "\n",
      "episode 15, policy loss 0.7684152126312256\n",
      "\n",
      "episode 16, policy loss 0.7684152126312256\n",
      "\n",
      "Policy train loss in epoch 1:0.7684152461588383\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.7684152722358704\n",
      "\n",
      "episode 2, policy loss 0.7684152126312256\n",
      "\n",
      "episode 3, policy loss 0.7684152126312256\n",
      "\n",
      "episode 4, policy loss 0.7684152126312256\n",
      "\n",
      "episode 5, policy loss 0.7684152722358704\n",
      "\n",
      "episode 6, policy loss 0.7684152722358704\n",
      "\n",
      "episode 7, policy loss 0.7684152722358704\n",
      "\n",
      "episode 8, policy loss 0.7684152722358704\n",
      "\n",
      "episode 9, policy loss 0.7684152722358704\n",
      "\n",
      "episode 10, policy loss 0.7684153914451599\n",
      "\n",
      "episode 11, policy loss 0.7684152126312256\n",
      "\n",
      "episode 12, policy loss 0.7684152722358704\n",
      "\n",
      "episode 13, policy loss 0.7684152126312256\n",
      "\n",
      "episode 14, policy loss 0.7684152126312256\n",
      "\n",
      "episode 15, policy loss 0.7684151530265808\n",
      "\n",
      "episode 16, policy loss 0.7684151530265808\n",
      "\n",
      "Policy train loss in epoch 2:0.768415242433548\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.7684152126312256\n",
      "\n",
      "episode 2, policy loss 0.7684151530265808\n",
      "\n",
      "episode 3, policy loss 0.7684152722358704\n",
      "\n",
      "episode 4, policy loss 0.7684151530265808\n",
      "\n",
      "episode 5, policy loss 0.7684152126312256\n",
      "\n",
      "episode 6, policy loss 0.7684152126312256\n",
      "\n",
      "episode 7, policy loss 0.7684152126312256\n",
      "\n",
      "episode 8, policy loss 0.7684152126312256\n",
      "\n",
      "episode 9, policy loss 0.7684152722358704\n",
      "\n",
      "episode 10, policy loss 0.7684152722358704\n",
      "\n",
      "episode 11, policy loss 0.7684151530265808\n",
      "\n",
      "episode 12, policy loss 0.7684152126312256\n",
      "\n",
      "episode 13, policy loss 0.7684151530265808\n",
      "\n",
      "episode 14, policy loss 0.7684152722358704\n",
      "\n",
      "episode 15, policy loss 0.7684151530265808\n",
      "\n",
      "episode 16, policy loss 0.7684151530265808\n",
      "\n",
      "Policy train loss in epoch 3:0.768415205180645\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7768141627311707\n",
      "\n",
      "episode 2, val func loss 0.7689509391784668\n",
      "\n",
      "episode 3, val func loss 0.9077410697937012\n",
      "\n",
      "episode 4, val func loss 0.8550015687942505\n",
      "\n",
      "episode 5, val func loss 0.8716062903404236\n",
      "\n",
      "episode 6, val func loss 1.0611004829406738\n",
      "\n",
      "episode 7, val func loss 0.8173654079437256\n",
      "\n",
      "episode 8, val func loss 0.7355912327766418\n",
      "\n",
      "episode 9, val func loss 0.9456042647361755\n",
      "\n",
      "episode 10, val func loss 0.8491072058677673\n",
      "\n",
      "episode 11, val func loss 0.7471855878829956\n",
      "\n",
      "episode 12, val func loss 0.9244225025177002\n",
      "\n",
      "episode 13, val func loss 0.8222807049751282\n",
      "\n",
      "episode 14, val func loss 0.8708796501159668\n",
      "\n",
      "episode 15, val func loss 0.9352049231529236\n",
      "\n",
      "episode 16, val func loss 0.7969387769699097\n",
      "\n",
      "Val func train loss in epoch 0:0.8553621731698513\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8252649903297424\n",
      "\n",
      "episode 2, val func loss 0.8595929741859436\n",
      "\n",
      "episode 3, val func loss 0.792414665222168\n",
      "\n",
      "episode 4, val func loss 0.9141732454299927\n",
      "\n",
      "episode 5, val func loss 0.9769169688224792\n",
      "\n",
      "episode 6, val func loss 0.8585867285728455\n",
      "\n",
      "episode 7, val func loss 0.9089333415031433\n",
      "\n",
      "episode 8, val func loss 0.7503144145011902\n",
      "\n",
      "episode 9, val func loss 0.8378428816795349\n",
      "\n",
      "episode 10, val func loss 0.9188337326049805\n",
      "\n",
      "episode 11, val func loss 0.8357020020484924\n",
      "\n",
      "episode 12, val func loss 0.7715298533439636\n",
      "\n",
      "episode 13, val func loss 0.907582700252533\n",
      "\n",
      "episode 14, val func loss 0.848566472530365\n",
      "\n",
      "episode 15, val func loss 1.0354859828948975\n",
      "\n",
      "episode 16, val func loss 0.8759437203407288\n",
      "\n",
      "Val func train loss in epoch 1:0.8698552921414375\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.91808021068573\n",
      "\n",
      "episode 2, val func loss 0.8555357456207275\n",
      "\n",
      "episode 3, val func loss 1.0124013423919678\n",
      "\n",
      "episode 4, val func loss 0.7744089365005493\n",
      "\n",
      "episode 5, val func loss 0.8395078778266907\n",
      "\n",
      "episode 6, val func loss 1.0434410572052002\n",
      "\n",
      "episode 7, val func loss 0.8588672280311584\n",
      "\n",
      "episode 8, val func loss 0.8836640119552612\n",
      "\n",
      "episode 9, val func loss 0.8575873970985413\n",
      "\n",
      "episode 10, val func loss 0.7903119921684265\n",
      "\n",
      "episode 11, val func loss 0.9283229112625122\n",
      "\n",
      "episode 12, val func loss 0.8016546368598938\n",
      "\n",
      "episode 13, val func loss 0.7547670006752014\n",
      "\n",
      "episode 14, val func loss 0.809590756893158\n",
      "\n",
      "episode 15, val func loss 0.840684175491333\n",
      "\n",
      "episode 16, val func loss 0.8398523926734924\n",
      "\n",
      "Val func train loss in epoch 2:0.8630423545837402\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8440514802932739\n",
      "\n",
      "episode 2, val func loss 0.76179438829422\n",
      "\n",
      "episode 3, val func loss 0.7292259335517883\n",
      "\n",
      "episode 4, val func loss 0.9716867804527283\n",
      "\n",
      "episode 5, val func loss 0.8540964722633362\n",
      "\n",
      "episode 6, val func loss 0.9257638454437256\n",
      "\n",
      "episode 7, val func loss 0.8849931955337524\n",
      "\n",
      "episode 8, val func loss 0.9231687188148499\n",
      "\n",
      "episode 9, val func loss 0.8148044943809509\n",
      "\n",
      "episode 10, val func loss 0.7566505074501038\n",
      "\n",
      "episode 11, val func loss 0.6906924843788147\n",
      "\n",
      "episode 12, val func loss 0.7515668869018555\n",
      "\n",
      "episode 13, val func loss 0.6972346901893616\n",
      "\n",
      "episode 14, val func loss 0.7000375986099243\n",
      "\n",
      "episode 15, val func loss 0.8459840416908264\n",
      "\n",
      "episode 16, val func loss 0.7529023289680481\n",
      "\n",
      "Val func train loss in epoch 3:0.8065408654510975\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7754448652267456\n",
      "\n",
      "episode 2, val func loss 0.7340577840805054\n",
      "\n",
      "episode 3, val func loss 0.7969349026679993\n",
      "\n",
      "episode 4, val func loss 0.8789221048355103\n",
      "\n",
      "episode 5, val func loss 0.7637227773666382\n",
      "\n",
      "episode 6, val func loss 0.7928302884101868\n",
      "\n",
      "episode 7, val func loss 0.6970117092132568\n",
      "\n",
      "episode 8, val func loss 0.7690725922584534\n",
      "\n",
      "episode 9, val func loss 0.7213456630706787\n",
      "\n",
      "episode 10, val func loss 0.7366184592247009\n",
      "\n",
      "episode 11, val func loss 0.7506868243217468\n",
      "\n",
      "episode 12, val func loss 0.8140878677368164\n",
      "\n",
      "episode 13, val func loss 0.8394985198974609\n",
      "\n",
      "episode 14, val func loss 0.7839825749397278\n",
      "\n",
      "episode 15, val func loss 0.8138878345489502\n",
      "\n",
      "episode 16, val func loss 0.8012199401855469\n",
      "\n",
      "Val func train loss in epoch 4:0.7793327942490578\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7480949759483337\n",
      "\n",
      "episode 2, val func loss 0.8488510847091675\n",
      "\n",
      "episode 3, val func loss 0.7372251749038696\n",
      "\n",
      "episode 4, val func loss 0.8990825414657593\n",
      "\n",
      "episode 5, val func loss 0.8437581658363342\n",
      "\n",
      "episode 6, val func loss 0.818969190120697\n",
      "\n",
      "episode 7, val func loss 0.7648469805717468\n",
      "\n",
      "episode 8, val func loss 0.762968897819519\n",
      "\n",
      "episode 9, val func loss 0.7482101917266846\n",
      "\n",
      "episode 10, val func loss 0.8282217383384705\n",
      "\n",
      "episode 11, val func loss 0.7573305368423462\n",
      "\n",
      "episode 12, val func loss 0.9455634355545044\n",
      "\n",
      "episode 13, val func loss 0.7619469165802002\n",
      "\n",
      "episode 14, val func loss 0.7362589836120605\n",
      "\n",
      "episode 15, val func loss 0.797823965549469\n",
      "\n",
      "episode 16, val func loss 0.7256579399108887\n",
      "\n",
      "Val func train loss in epoch 5:0.7953006699681282\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.887922465801239\n",
      "\n",
      "episode 2, val func loss 0.8509321212768555\n",
      "\n",
      "episode 3, val func loss 0.7827760577201843\n",
      "\n",
      "episode 4, val func loss 0.7437317967414856\n",
      "\n",
      "episode 5, val func loss 0.927544891834259\n",
      "\n",
      "episode 6, val func loss 0.8082373142242432\n",
      "\n",
      "episode 7, val func loss 0.7209360599517822\n",
      "\n",
      "episode 8, val func loss 0.8215612769126892\n",
      "\n",
      "episode 9, val func loss 0.7540850639343262\n",
      "\n",
      "episode 10, val func loss 0.6791773438453674\n",
      "\n",
      "episode 11, val func loss 0.7875000834465027\n",
      "\n",
      "episode 12, val func loss 0.7310033440589905\n",
      "\n",
      "episode 13, val func loss 0.7717767953872681\n",
      "\n",
      "episode 14, val func loss 0.77203369140625\n",
      "\n",
      "episode 15, val func loss 0.8370683789253235\n",
      "\n",
      "episode 16, val func loss 0.7525394558906555\n",
      "\n",
      "Val func train loss in epoch 6:0.7893016338348389\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.834814727306366\n",
      "\n",
      "episode 2, val func loss 0.7190490365028381\n",
      "\n",
      "episode 3, val func loss 0.8525074124336243\n",
      "\n",
      "episode 4, val func loss 0.7753125429153442\n",
      "\n",
      "episode 5, val func loss 0.8151927590370178\n",
      "\n",
      "episode 6, val func loss 0.7801865339279175\n",
      "\n",
      "episode 7, val func loss 0.7339515686035156\n",
      "\n",
      "episode 8, val func loss 0.8234307169914246\n",
      "\n",
      "episode 9, val func loss 0.7603954076766968\n",
      "\n",
      "episode 10, val func loss 0.8447950482368469\n",
      "\n",
      "episode 11, val func loss 0.7712452411651611\n",
      "\n",
      "episode 12, val func loss 0.7999008893966675\n",
      "\n",
      "episode 13, val func loss 0.8060142993927002\n",
      "\n",
      "episode 14, val func loss 0.676947295665741\n",
      "\n",
      "episode 15, val func loss 0.6501918435096741\n",
      "\n",
      "episode 16, val func loss 0.7196843028068542\n",
      "\n",
      "Val func train loss in epoch 7:0.7727262265980244\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7940260171890259\n",
      "\n",
      "episode 2, val func loss 0.7493461966514587\n",
      "\n",
      "episode 3, val func loss 0.7040265798568726\n",
      "\n",
      "episode 4, val func loss 0.7822756171226501\n",
      "\n",
      "episode 5, val func loss 0.7311338186264038\n",
      "\n",
      "episode 6, val func loss 0.7969194054603577\n",
      "\n",
      "episode 7, val func loss 0.9383628964424133\n",
      "\n",
      "episode 8, val func loss 0.7207874059677124\n",
      "\n",
      "episode 9, val func loss 0.813507080078125\n",
      "\n",
      "episode 10, val func loss 0.8500947952270508\n",
      "\n",
      "episode 11, val func loss 0.7819221615791321\n",
      "\n",
      "episode 12, val func loss 0.8419008255004883\n",
      "\n",
      "episode 13, val func loss 0.8344666957855225\n",
      "\n",
      "episode 14, val func loss 0.8007487654685974\n",
      "\n",
      "episode 15, val func loss 0.7439241409301758\n",
      "\n",
      "episode 16, val func loss 0.7643178701400757\n",
      "\n",
      "Val func train loss in epoch 8:0.7904850170016289\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8253714442253113\n",
      "\n",
      "episode 2, val func loss 0.7743963599205017\n",
      "\n",
      "episode 3, val func loss 0.8009042739868164\n",
      "\n",
      "episode 4, val func loss 0.7916165590286255\n",
      "\n",
      "episode 5, val func loss 0.7724928259849548\n",
      "\n",
      "episode 6, val func loss 0.7781190872192383\n",
      "\n",
      "episode 7, val func loss 0.7910844087600708\n",
      "\n",
      "episode 8, val func loss 0.8385996222496033\n",
      "\n",
      "episode 9, val func loss 0.747072160243988\n",
      "\n",
      "episode 10, val func loss 0.7358899712562561\n",
      "\n",
      "episode 11, val func loss 0.8932515978813171\n",
      "\n",
      "episode 12, val func loss 0.805237889289856\n",
      "\n",
      "episode 13, val func loss 0.8874453902244568\n",
      "\n",
      "episode 14, val func loss 0.8051646947860718\n",
      "\n",
      "episode 15, val func loss 0.8254379630088806\n",
      "\n",
      "episode 16, val func loss 0.9358891248703003\n",
      "\n",
      "Val func train loss in epoch 9:0.8129983358085155\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7042966485023499\n",
      "\n",
      "episode 2, val func loss 0.7694491744041443\n",
      "\n",
      "episode 3, val func loss 0.8109122514724731\n",
      "\n",
      "episode 4, val func loss 0.8484797477722168\n",
      "\n",
      "episode 5, val func loss 0.7327030301094055\n",
      "\n",
      "episode 6, val func loss 0.8006104230880737\n",
      "\n",
      "episode 7, val func loss 0.8094163537025452\n",
      "\n",
      "episode 8, val func loss 0.7164207100868225\n",
      "\n",
      "episode 9, val func loss 0.6825416684150696\n",
      "\n",
      "episode 10, val func loss 0.717077374458313\n",
      "\n",
      "episode 11, val func loss 0.7289807200431824\n",
      "\n",
      "episode 12, val func loss 0.6978405117988586\n",
      "\n",
      "episode 13, val func loss 0.8146171569824219\n",
      "\n",
      "episode 14, val func loss 0.859021008014679\n",
      "\n",
      "episode 15, val func loss 0.7811315059661865\n",
      "\n",
      "episode 16, val func loss 0.8723294138908386\n",
      "\n",
      "Val func train loss in epoch 10:0.7716142311692238\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.794206976890564\n",
      "\n",
      "episode 2, val func loss 0.7916443943977356\n",
      "\n",
      "episode 3, val func loss 0.7573544383049011\n",
      "\n",
      "episode 4, val func loss 0.8015918731689453\n",
      "\n",
      "episode 5, val func loss 0.7382686734199524\n",
      "\n",
      "episode 6, val func loss 0.8285034894943237\n",
      "\n",
      "episode 7, val func loss 0.775503933429718\n",
      "\n",
      "episode 8, val func loss 1.0044387578964233\n",
      "\n",
      "episode 9, val func loss 0.8976143598556519\n",
      "\n",
      "episode 10, val func loss 0.725689172744751\n",
      "\n",
      "episode 11, val func loss 0.7975910902023315\n",
      "\n",
      "episode 12, val func loss 0.735629141330719\n",
      "\n",
      "episode 13, val func loss 0.8438684940338135\n",
      "\n",
      "episode 14, val func loss 0.7543383240699768\n",
      "\n",
      "episode 15, val func loss 0.7466837763786316\n",
      "\n",
      "episode 16, val func loss 0.7041251063346863\n",
      "\n",
      "Val func train loss in epoch 11:0.7935657501220703\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7339944839477539\n",
      "\n",
      "episode 2, val func loss 0.7881410121917725\n",
      "\n",
      "episode 3, val func loss 0.7395809292793274\n",
      "\n",
      "episode 4, val func loss 0.7281613945960999\n",
      "\n",
      "episode 5, val func loss 0.7957599759101868\n",
      "\n",
      "episode 6, val func loss 0.7125648856163025\n",
      "\n",
      "episode 7, val func loss 0.7917584180831909\n",
      "\n",
      "episode 8, val func loss 0.8517385721206665\n",
      "\n",
      "episode 9, val func loss 0.8332383632659912\n",
      "\n",
      "episode 10, val func loss 0.791286289691925\n",
      "\n",
      "episode 11, val func loss 0.8938907980918884\n",
      "\n",
      "episode 12, val func loss 0.8078886866569519\n",
      "\n",
      "episode 13, val func loss 0.7664586305618286\n",
      "\n",
      "episode 14, val func loss 1.0236210823059082\n",
      "\n",
      "episode 15, val func loss 0.7237171530723572\n",
      "\n",
      "episode 16, val func loss 0.8267187476158142\n",
      "\n",
      "Val func train loss in epoch 12:0.8005324639379978\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.9659073948860168\n",
      "\n",
      "episode 2, val func loss 0.7845674753189087\n",
      "\n",
      "episode 3, val func loss 1.0062161684036255\n",
      "\n",
      "episode 4, val func loss 0.93034428358078\n",
      "\n",
      "episode 5, val func loss 0.8779821395874023\n",
      "\n",
      "episode 6, val func loss 0.9775945544242859\n",
      "\n",
      "episode 7, val func loss 1.0026737451553345\n",
      "\n",
      "episode 8, val func loss 0.6805803179740906\n",
      "\n",
      "episode 9, val func loss 0.7113248109817505\n",
      "\n",
      "episode 10, val func loss 0.9019011855125427\n",
      "\n",
      "episode 11, val func loss 0.8390746116638184\n",
      "\n",
      "episode 12, val func loss 0.8602724671363831\n",
      "\n",
      "episode 13, val func loss 0.8533462285995483\n",
      "\n",
      "episode 14, val func loss 0.7374191284179688\n",
      "\n",
      "episode 15, val func loss 0.7674940228462219\n",
      "\n",
      "episode 16, val func loss 0.8145531415939331\n",
      "\n",
      "Val func train loss in epoch 13:0.8569532297551632\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7812926173210144\n",
      "\n",
      "episode 2, val func loss 0.7151824235916138\n",
      "\n",
      "episode 3, val func loss 0.8666397929191589\n",
      "\n",
      "episode 4, val func loss 0.7006545662879944\n",
      "\n",
      "episode 5, val func loss 0.7920694947242737\n",
      "\n",
      "episode 6, val func loss 0.7542387843132019\n",
      "\n",
      "episode 7, val func loss 0.7271376848220825\n",
      "\n",
      "episode 8, val func loss 0.8917065858840942\n",
      "\n",
      "episode 9, val func loss 0.8209219574928284\n",
      "\n",
      "episode 10, val func loss 0.8017838001251221\n",
      "\n",
      "episode 11, val func loss 0.7579034566879272\n",
      "\n",
      "episode 12, val func loss 0.8253499865531921\n",
      "\n",
      "episode 13, val func loss 0.6427346467971802\n",
      "\n",
      "episode 14, val func loss 0.7573726773262024\n",
      "\n",
      "episode 15, val func loss 0.6759853363037109\n",
      "\n",
      "episode 16, val func loss 0.76569664478302\n",
      "\n",
      "Val func train loss in epoch 14:0.7672919034957886\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.8019751906394958\n",
      "\n",
      "episode 2, val func loss 0.8911195397377014\n",
      "\n",
      "episode 3, val func loss 0.6938367486000061\n",
      "\n",
      "episode 4, val func loss 0.7712798714637756\n",
      "\n",
      "episode 5, val func loss 0.6566228866577148\n",
      "\n",
      "episode 6, val func loss 0.7625110745429993\n",
      "\n",
      "episode 7, val func loss 0.7156643271446228\n",
      "\n",
      "episode 8, val func loss 0.7910695672035217\n",
      "\n",
      "episode 9, val func loss 0.9087780117988586\n",
      "\n",
      "episode 10, val func loss 1.0159344673156738\n",
      "\n",
      "episode 11, val func loss 0.8423124551773071\n",
      "\n",
      "episode 12, val func loss 0.8471652269363403\n",
      "\n",
      "episode 13, val func loss 0.7454006671905518\n",
      "\n",
      "episode 14, val func loss 0.7293365597724915\n",
      "\n",
      "episode 15, val func loss 0.9050799012184143\n",
      "\n",
      "episode 16, val func loss 0.7525737881660461\n",
      "\n",
      "Val func train loss in epoch 15:0.8019162677228451\n",
      "***********************TIME WAS 4.889070101579031 min*****************************\n",
      "\n",
      "**********************ROUND 98 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.46417510509490967\n",
      "\n",
      "episode 2, policy loss 0.4641752243041992\n",
      "\n",
      "episode 3, policy loss 0.46417519450187683\n",
      "\n",
      "episode 4, policy loss 0.46417519450187683\n",
      "\n",
      "episode 5, policy loss 0.4641750752925873\n",
      "\n",
      "episode 6, policy loss 0.46417510509490967\n",
      "\n",
      "episode 7, policy loss 0.4641752243041992\n",
      "\n",
      "episode 8, policy loss 0.46417510509490967\n",
      "\n",
      "episode 9, policy loss 0.4641752243041992\n",
      "\n",
      "episode 10, policy loss 0.4641752243041992\n",
      "\n",
      "episode 11, policy loss 0.4641752243041992\n",
      "\n",
      "episode 12, policy loss 0.46417516469955444\n",
      "\n",
      "episode 13, policy loss 0.46417516469955444\n",
      "\n",
      "episode 14, policy loss 0.46417537331581116\n",
      "\n",
      "episode 15, policy loss 0.46417510509490967\n",
      "\n",
      "episode 16, policy loss 0.46417537331581116\n",
      "\n",
      "Policy train loss in epoch 0:0.4641751926392317\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.4641749858856201\n",
      "\n",
      "episode 2, policy loss 0.4641750752925873\n",
      "\n",
      "episode 3, policy loss 0.4641752243041992\n",
      "\n",
      "episode 4, policy loss 0.464175283908844\n",
      "\n",
      "episode 5, policy loss 0.46417492628097534\n",
      "\n",
      "episode 6, policy loss 0.46417519450187683\n",
      "\n",
      "episode 7, policy loss 0.4641752243041992\n",
      "\n",
      "episode 8, policy loss 0.4641750752925873\n",
      "\n",
      "episode 9, policy loss 0.4641750752925873\n",
      "\n",
      "episode 10, policy loss 0.4641749858856201\n",
      "\n",
      "episode 11, policy loss 0.4641750752925873\n",
      "\n",
      "episode 12, policy loss 0.46417510509490967\n",
      "\n",
      "episode 13, policy loss 0.46417516469955444\n",
      "\n",
      "episode 14, policy loss 0.46417492628097534\n",
      "\n",
      "episode 15, policy loss 0.4641750752925873\n",
      "\n",
      "episode 16, policy loss 0.46417510509490967\n",
      "\n",
      "Policy train loss in epoch 1:0.4641750939190388\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.4641750752925873\n",
      "\n",
      "episode 2, policy loss 0.46417489647865295\n",
      "\n",
      "episode 3, policy loss 0.46417489647865295\n",
      "\n",
      "episode 4, policy loss 0.46417519450187683\n",
      "\n",
      "episode 5, policy loss 0.46417489647865295\n",
      "\n",
      "episode 6, policy loss 0.4641750156879425\n",
      "\n",
      "episode 7, policy loss 0.46417468786239624\n",
      "\n",
      "episode 8, policy loss 0.4641749858856201\n",
      "\n",
      "episode 9, policy loss 0.464174747467041\n",
      "\n",
      "episode 10, policy loss 0.4641750752925873\n",
      "\n",
      "episode 11, policy loss 0.46417462825775146\n",
      "\n",
      "episode 12, policy loss 0.46417489647865295\n",
      "\n",
      "episode 13, policy loss 0.4641748368740082\n",
      "\n",
      "episode 14, policy loss 0.46417489647865295\n",
      "\n",
      "episode 15, policy loss 0.46417462825775146\n",
      "\n",
      "episode 16, policy loss 0.46417492628097534\n",
      "\n",
      "Policy train loss in epoch 2:0.46417489275336266\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.4641749858856201\n",
      "\n",
      "episode 2, policy loss 0.4641745090484619\n",
      "\n",
      "episode 3, policy loss 0.46417471766471863\n",
      "\n",
      "episode 4, policy loss 0.4641745090484619\n",
      "\n",
      "episode 5, policy loss 0.4641745090484619\n",
      "\n",
      "episode 6, policy loss 0.4641742408275604\n",
      "\n",
      "episode 7, policy loss 0.4641745090484619\n",
      "\n",
      "episode 8, policy loss 0.46417436003685\n",
      "\n",
      "episode 9, policy loss 0.46417421102523804\n",
      "\n",
      "episode 10, policy loss 0.4641742706298828\n",
      "\n",
      "episode 11, policy loss 0.46417421102523804\n",
      "\n",
      "episode 12, policy loss 0.4641740620136261\n",
      "\n",
      "episode 13, policy loss 0.4641738831996918\n",
      "\n",
      "episode 14, policy loss 0.4641737937927246\n",
      "\n",
      "episode 15, policy loss 0.4641737639904022\n",
      "\n",
      "episode 16, policy loss 0.46417340636253357\n",
      "\n",
      "Policy train loss in epoch 3:0.4641742464154959\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.8100284337997437\n",
      "\n",
      "episode 2, val func loss 0.8163718581199646\n",
      "\n",
      "episode 3, val func loss 0.7052828669548035\n",
      "\n",
      "episode 4, val func loss 0.8300971984863281\n",
      "\n",
      "episode 5, val func loss 0.7441179156303406\n",
      "\n",
      "episode 6, val func loss 0.7962322235107422\n",
      "\n",
      "episode 7, val func loss 0.7970491647720337\n",
      "\n",
      "episode 8, val func loss 0.8324762582778931\n",
      "\n",
      "episode 9, val func loss 0.7194700241088867\n",
      "\n",
      "episode 10, val func loss 0.937470018863678\n",
      "\n",
      "episode 11, val func loss 0.8272532820701599\n",
      "\n",
      "episode 12, val func loss 0.7451183795928955\n",
      "\n",
      "episode 13, val func loss 0.8109392523765564\n",
      "\n",
      "episode 14, val func loss 0.8264666795730591\n",
      "\n",
      "episode 15, val func loss 0.781449019908905\n",
      "\n",
      "episode 16, val func loss 0.793813169002533\n",
      "\n",
      "Val func train loss in epoch 0:0.7983522340655327\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7810834050178528\n",
      "\n",
      "episode 2, val func loss 0.7125335335731506\n",
      "\n",
      "episode 3, val func loss 0.7689083814620972\n",
      "\n",
      "episode 4, val func loss 0.8164657950401306\n",
      "\n",
      "episode 5, val func loss 0.8522998094558716\n",
      "\n",
      "episode 6, val func loss 0.7528989911079407\n",
      "\n",
      "episode 7, val func loss 0.7977245450019836\n",
      "\n",
      "episode 8, val func loss 0.7791534066200256\n",
      "\n",
      "episode 9, val func loss 0.8154656291007996\n",
      "\n",
      "episode 10, val func loss 0.8821679949760437\n",
      "\n",
      "episode 11, val func loss 0.920537531375885\n",
      "\n",
      "episode 12, val func loss 0.771083652973175\n",
      "\n",
      "episode 13, val func loss 0.8909462690353394\n",
      "\n",
      "episode 14, val func loss 0.7749754190444946\n",
      "\n",
      "episode 15, val func loss 0.7644071578979492\n",
      "\n",
      "episode 16, val func loss 0.9679632782936096\n",
      "\n",
      "Val func train loss in epoch 1:0.8155384249985218\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.8185797929763794\n",
      "\n",
      "episode 2, val func loss 1.0016016960144043\n",
      "\n",
      "episode 3, val func loss 0.8754339218139648\n",
      "\n",
      "episode 4, val func loss 0.6263214945793152\n",
      "\n",
      "episode 5, val func loss 0.7729200720787048\n",
      "\n",
      "episode 6, val func loss 0.7627516388893127\n",
      "\n",
      "episode 7, val func loss 0.7796679139137268\n",
      "\n",
      "episode 8, val func loss 0.8918178677558899\n",
      "\n",
      "episode 9, val func loss 0.7979214191436768\n",
      "\n",
      "episode 10, val func loss 0.7986807227134705\n",
      "\n",
      "episode 11, val func loss 0.7299838066101074\n",
      "\n",
      "episode 12, val func loss 0.7529975175857544\n",
      "\n",
      "episode 13, val func loss 0.756721019744873\n",
      "\n",
      "episode 14, val func loss 0.7620391249656677\n",
      "\n",
      "episode 15, val func loss 0.7563520073890686\n",
      "\n",
      "episode 16, val func loss 0.7600582242012024\n",
      "\n",
      "Val func train loss in epoch 2:0.7902405150234699\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.7615343332290649\n",
      "\n",
      "episode 2, val func loss 0.7356301546096802\n",
      "\n",
      "episode 3, val func loss 0.754949688911438\n",
      "\n",
      "episode 4, val func loss 0.8508318066596985\n",
      "\n",
      "episode 5, val func loss 0.7293016314506531\n",
      "\n",
      "episode 6, val func loss 0.7867799401283264\n",
      "\n",
      "episode 7, val func loss 0.6874638795852661\n",
      "\n",
      "episode 8, val func loss 0.836240291595459\n",
      "\n",
      "episode 9, val func loss 0.8268376588821411\n",
      "\n",
      "episode 10, val func loss 0.7583566308021545\n",
      "\n",
      "episode 11, val func loss 0.7069775462150574\n",
      "\n",
      "episode 12, val func loss 0.7010658979415894\n",
      "\n",
      "episode 13, val func loss 0.7921697497367859\n",
      "\n",
      "episode 14, val func loss 0.8562278747558594\n",
      "\n",
      "episode 15, val func loss 0.7396629452705383\n",
      "\n",
      "episode 16, val func loss 0.7001947164535522\n",
      "\n",
      "Val func train loss in epoch 3:0.764014046639204\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7464179396629333\n",
      "\n",
      "episode 2, val func loss 0.709734320640564\n",
      "\n",
      "episode 3, val func loss 0.7573146224021912\n",
      "\n",
      "episode 4, val func loss 0.7192672491073608\n",
      "\n",
      "episode 5, val func loss 0.7640680074691772\n",
      "\n",
      "episode 6, val func loss 0.8323535919189453\n",
      "\n",
      "episode 7, val func loss 0.7873860597610474\n",
      "\n",
      "episode 8, val func loss 0.886881411075592\n",
      "\n",
      "episode 9, val func loss 0.9591155648231506\n",
      "\n",
      "episode 10, val func loss 0.7775356769561768\n",
      "\n",
      "episode 11, val func loss 0.9553906917572021\n",
      "\n",
      "episode 12, val func loss 0.822739839553833\n",
      "\n",
      "episode 13, val func loss 0.9209906458854675\n",
      "\n",
      "episode 14, val func loss 0.9599546790122986\n",
      "\n",
      "episode 15, val func loss 0.924322247505188\n",
      "\n",
      "episode 16, val func loss 0.8417538404464722\n",
      "\n",
      "Val func train loss in epoch 4:0.8353266492486\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7785188555717468\n",
      "\n",
      "episode 2, val func loss 0.7490531206130981\n",
      "\n",
      "episode 3, val func loss 0.7836118340492249\n",
      "\n",
      "episode 4, val func loss 0.8692306876182556\n",
      "\n",
      "episode 5, val func loss 0.877580463886261\n",
      "\n",
      "episode 6, val func loss 0.890559196472168\n",
      "\n",
      "episode 7, val func loss 0.8907278180122375\n",
      "\n",
      "episode 8, val func loss 0.8212477564811707\n",
      "\n",
      "episode 9, val func loss 0.8970251679420471\n",
      "\n",
      "episode 10, val func loss 0.8210129141807556\n",
      "\n",
      "episode 11, val func loss 0.7495010495185852\n",
      "\n",
      "episode 12, val func loss 0.7819033861160278\n",
      "\n",
      "episode 13, val func loss 0.78145432472229\n",
      "\n",
      "episode 14, val func loss 0.793097198009491\n",
      "\n",
      "episode 15, val func loss 0.7250913381576538\n",
      "\n",
      "episode 16, val func loss 0.7151334881782532\n",
      "\n",
      "Val func train loss in epoch 5:0.8077967874705791\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8841840028762817\n",
      "\n",
      "episode 2, val func loss 0.7260304689407349\n",
      "\n",
      "episode 3, val func loss 0.9054268598556519\n",
      "\n",
      "episode 4, val func loss 0.7755764126777649\n",
      "\n",
      "episode 5, val func loss 0.6962812542915344\n",
      "\n",
      "episode 6, val func loss 0.9236121773719788\n",
      "\n",
      "episode 7, val func loss 0.8164119124412537\n",
      "\n",
      "episode 8, val func loss 0.7909064888954163\n",
      "\n",
      "episode 9, val func loss 0.8069095015525818\n",
      "\n",
      "episode 10, val func loss 0.813442051410675\n",
      "\n",
      "episode 11, val func loss 0.7691938877105713\n",
      "\n",
      "episode 12, val func loss 0.8394696116447449\n",
      "\n",
      "episode 13, val func loss 0.7962408065795898\n",
      "\n",
      "episode 14, val func loss 0.6949123740196228\n",
      "\n",
      "episode 15, val func loss 0.9358139038085938\n",
      "\n",
      "episode 16, val func loss 0.7193044424057007\n",
      "\n",
      "Val func train loss in epoch 6:0.8058572597801685\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.9093078374862671\n",
      "\n",
      "episode 2, val func loss 0.7878368496894836\n",
      "\n",
      "episode 3, val func loss 0.7491582036018372\n",
      "\n",
      "episode 4, val func loss 0.8302682042121887\n",
      "\n",
      "episode 5, val func loss 0.7407102584838867\n",
      "\n",
      "episode 6, val func loss 0.8232899904251099\n",
      "\n",
      "episode 7, val func loss 0.7389682531356812\n",
      "\n",
      "episode 8, val func loss 0.7855896353721619\n",
      "\n",
      "episode 9, val func loss 0.8343155980110168\n",
      "\n",
      "episode 10, val func loss 0.8038392663002014\n",
      "\n",
      "episode 11, val func loss 0.7004292011260986\n",
      "\n",
      "episode 12, val func loss 0.7687516808509827\n",
      "\n",
      "episode 13, val func loss 0.6777175664901733\n",
      "\n",
      "episode 14, val func loss 0.729771614074707\n",
      "\n",
      "episode 15, val func loss 0.7568147778511047\n",
      "\n",
      "episode 16, val func loss 0.7794504761695862\n",
      "\n",
      "Val func train loss in epoch 7:0.7760137133300304\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6946823596954346\n",
      "\n",
      "episode 2, val func loss 0.7311668395996094\n",
      "\n",
      "episode 3, val func loss 0.764613151550293\n",
      "\n",
      "episode 4, val func loss 0.8551986813545227\n",
      "\n",
      "episode 5, val func loss 0.7359053492546082\n",
      "\n",
      "episode 6, val func loss 0.7458720803260803\n",
      "\n",
      "episode 7, val func loss 0.7411021590232849\n",
      "\n",
      "episode 8, val func loss 0.7744905948638916\n",
      "\n",
      "episode 9, val func loss 0.7668268084526062\n",
      "\n",
      "episode 10, val func loss 0.7422893643379211\n",
      "\n",
      "episode 11, val func loss 0.7927465438842773\n",
      "\n",
      "episode 12, val func loss 0.7746754884719849\n",
      "\n",
      "episode 13, val func loss 0.741280198097229\n",
      "\n",
      "episode 14, val func loss 0.8090062737464905\n",
      "\n",
      "episode 15, val func loss 0.7739776968955994\n",
      "\n",
      "episode 16, val func loss 0.7275744080543518\n",
      "\n",
      "Val func train loss in epoch 8:0.7607129998505116\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6416329145431519\n",
      "\n",
      "episode 2, val func loss 0.8176112174987793\n",
      "\n",
      "episode 3, val func loss 0.8868708610534668\n",
      "\n",
      "episode 4, val func loss 0.7513707280158997\n",
      "\n",
      "episode 5, val func loss 0.774261474609375\n",
      "\n",
      "episode 6, val func loss 0.8227589726448059\n",
      "\n",
      "episode 7, val func loss 0.7577046155929565\n",
      "\n",
      "episode 8, val func loss 0.8017624616622925\n",
      "\n",
      "episode 9, val func loss 0.7914089560508728\n",
      "\n",
      "episode 10, val func loss 0.8353930115699768\n",
      "\n",
      "episode 11, val func loss 0.8694190979003906\n",
      "\n",
      "episode 12, val func loss 0.7991510629653931\n",
      "\n",
      "episode 13, val func loss 0.7803401947021484\n",
      "\n",
      "episode 14, val func loss 0.7347259521484375\n",
      "\n",
      "episode 15, val func loss 0.7843171954154968\n",
      "\n",
      "episode 16, val func loss 0.9248285889625549\n",
      "\n",
      "Val func train loss in epoch 9:0.7983473315834999\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7097340822219849\n",
      "\n",
      "episode 2, val func loss 0.7808586955070496\n",
      "\n",
      "episode 3, val func loss 0.8579668998718262\n",
      "\n",
      "episode 4, val func loss 0.801058828830719\n",
      "\n",
      "episode 5, val func loss 0.8475169539451599\n",
      "\n",
      "episode 6, val func loss 0.7526823878288269\n",
      "\n",
      "episode 7, val func loss 0.9769638776779175\n",
      "\n",
      "episode 8, val func loss 0.7253678441047668\n",
      "\n",
      "episode 9, val func loss 0.8147621154785156\n",
      "\n",
      "episode 10, val func loss 0.8548315167427063\n",
      "\n",
      "episode 11, val func loss 0.8198934197425842\n",
      "\n",
      "episode 12, val func loss 0.7697120308876038\n",
      "\n",
      "episode 13, val func loss 0.7362546920776367\n",
      "\n",
      "episode 14, val func loss 0.7361053228378296\n",
      "\n",
      "episode 15, val func loss 0.7403684258460999\n",
      "\n",
      "episode 16, val func loss 0.7554412484169006\n",
      "\n",
      "Val func train loss in epoch 10:0.792469896376133\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.787156879901886\n",
      "\n",
      "episode 2, val func loss 0.65851891040802\n",
      "\n",
      "episode 3, val func loss 0.823584794998169\n",
      "\n",
      "episode 4, val func loss 0.7165783047676086\n",
      "\n",
      "episode 5, val func loss 0.9051846265792847\n",
      "\n",
      "episode 6, val func loss 0.7684289216995239\n",
      "\n",
      "episode 7, val func loss 0.8081380128860474\n",
      "\n",
      "episode 8, val func loss 0.8362700343132019\n",
      "\n",
      "episode 9, val func loss 0.7312132120132446\n",
      "\n",
      "episode 10, val func loss 0.8745313286781311\n",
      "\n",
      "episode 11, val func loss 0.7798506617546082\n",
      "\n",
      "episode 12, val func loss 0.7591587901115417\n",
      "\n",
      "episode 13, val func loss 0.7625465393066406\n",
      "\n",
      "episode 14, val func loss 0.8207566142082214\n",
      "\n",
      "episode 15, val func loss 0.8197010159492493\n",
      "\n",
      "episode 16, val func loss 0.7132294774055481\n",
      "\n",
      "Val func train loss in epoch 11:0.7853030078113079\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7705473303794861\n",
      "\n",
      "episode 2, val func loss 0.8173391222953796\n",
      "\n",
      "episode 3, val func loss 0.7522716522216797\n",
      "\n",
      "episode 4, val func loss 0.8056385517120361\n",
      "\n",
      "episode 5, val func loss 0.7696985602378845\n",
      "\n",
      "episode 6, val func loss 0.8122122287750244\n",
      "\n",
      "episode 7, val func loss 0.7778826355934143\n",
      "\n",
      "episode 8, val func loss 0.7989931702613831\n",
      "\n",
      "episode 9, val func loss 0.7777418494224548\n",
      "\n",
      "episode 10, val func loss 0.7770786285400391\n",
      "\n",
      "episode 11, val func loss 0.6936980485916138\n",
      "\n",
      "episode 12, val func loss 0.8361225128173828\n",
      "\n",
      "episode 13, val func loss 0.8729772567749023\n",
      "\n",
      "episode 14, val func loss 0.7798561453819275\n",
      "\n",
      "episode 15, val func loss 0.6949277520179749\n",
      "\n",
      "episode 16, val func loss 0.8226627111434937\n",
      "\n",
      "Val func train loss in epoch 12:0.7849780097603798\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6750269532203674\n",
      "\n",
      "episode 2, val func loss 0.8417160511016846\n",
      "\n",
      "episode 3, val func loss 0.7818166613578796\n",
      "\n",
      "episode 4, val func loss 0.8713575005531311\n",
      "\n",
      "episode 5, val func loss 0.8786212205886841\n",
      "\n",
      "episode 6, val func loss 0.7663419246673584\n",
      "\n",
      "episode 7, val func loss 0.7044240236282349\n",
      "\n",
      "episode 8, val func loss 0.7985703945159912\n",
      "\n",
      "episode 9, val func loss 0.7643904685974121\n",
      "\n",
      "episode 10, val func loss 0.674302875995636\n",
      "\n",
      "episode 11, val func loss 0.7872051000595093\n",
      "\n",
      "episode 12, val func loss 0.845745325088501\n",
      "\n",
      "episode 13, val func loss 0.7272060513496399\n",
      "\n",
      "episode 14, val func loss 0.7964082956314087\n",
      "\n",
      "episode 15, val func loss 0.828783392906189\n",
      "\n",
      "episode 16, val func loss 0.7094218134880066\n",
      "\n",
      "Val func train loss in epoch 13:0.7782086282968521\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7578551173210144\n",
      "\n",
      "episode 2, val func loss 0.7440927028656006\n",
      "\n",
      "episode 3, val func loss 0.8071070313453674\n",
      "\n",
      "episode 4, val func loss 0.7545826435089111\n",
      "\n",
      "episode 5, val func loss 0.7902550101280212\n",
      "\n",
      "episode 6, val func loss 0.839239776134491\n",
      "\n",
      "episode 7, val func loss 0.7049108743667603\n",
      "\n",
      "episode 8, val func loss 0.8343068361282349\n",
      "\n",
      "episode 9, val func loss 0.6907532811164856\n",
      "\n",
      "episode 10, val func loss 0.7557870149612427\n",
      "\n",
      "episode 11, val func loss 0.8123921155929565\n",
      "\n",
      "episode 12, val func loss 0.7151755690574646\n",
      "\n",
      "episode 13, val func loss 0.7520840764045715\n",
      "\n",
      "episode 14, val func loss 0.7790802717208862\n",
      "\n",
      "episode 15, val func loss 0.8208640813827515\n",
      "\n",
      "episode 16, val func loss 0.8409885168075562\n",
      "\n",
      "Val func train loss in epoch 14:0.7749671824276447\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7614077925682068\n",
      "\n",
      "episode 2, val func loss 0.8343127965927124\n",
      "\n",
      "episode 3, val func loss 0.8637633323669434\n",
      "\n",
      "episode 4, val func loss 0.8710326552391052\n",
      "\n",
      "episode 5, val func loss 0.7600570321083069\n",
      "\n",
      "episode 6, val func loss 0.8570024371147156\n",
      "\n",
      "episode 7, val func loss 0.7818942666053772\n",
      "\n",
      "episode 8, val func loss 0.8522772192955017\n",
      "\n",
      "episode 9, val func loss 0.7147775888442993\n",
      "\n",
      "episode 10, val func loss 0.7489091753959656\n",
      "\n",
      "episode 11, val func loss 0.7783281803131104\n",
      "\n",
      "episode 12, val func loss 0.7383328676223755\n",
      "\n",
      "episode 13, val func loss 0.8300899267196655\n",
      "\n",
      "episode 14, val func loss 0.6808954477310181\n",
      "\n",
      "episode 15, val func loss 0.856214702129364\n",
      "\n",
      "episode 16, val func loss 0.82637619972229\n",
      "\n",
      "Val func train loss in epoch 15:0.7972294762730598\n",
      "***********************TIME WAS 4.975348687171936 min*****************************\n",
      "\n",
      "**********************ROUND 99 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.0967438220977783\n",
      "\n",
      "episode 2, policy loss 1.0967438220977783\n",
      "\n",
      "episode 3, policy loss 1.0967432260513306\n",
      "\n",
      "episode 4, policy loss 1.0967433452606201\n",
      "\n",
      "episode 5, policy loss 1.0967425107955933\n",
      "\n",
      "episode 6, policy loss 1.0967416763305664\n",
      "\n",
      "episode 7, policy loss 1.0967408418655396\n",
      "\n",
      "episode 8, policy loss 1.0967398881912231\n",
      "\n",
      "episode 9, policy loss 1.0967391729354858\n",
      "\n",
      "episode 10, policy loss 1.0967381000518799\n",
      "\n",
      "episode 11, policy loss 1.0967363119125366\n",
      "\n",
      "episode 12, policy loss 1.096734642982483\n",
      "\n",
      "episode 13, policy loss 1.0967342853546143\n",
      "\n",
      "episode 14, policy loss 1.0967298746109009\n",
      "\n",
      "episode 15, policy loss 1.0967248678207397\n",
      "\n",
      "episode 16, policy loss 1.0967212915420532\n",
      "\n",
      "Policy train loss in epoch 0:1.0967373549938202\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.0967168807983398\n",
      "\n",
      "episode 2, policy loss 1.0967066287994385\n",
      "\n",
      "episode 3, policy loss 1.0966949462890625\n",
      "\n",
      "episode 4, policy loss 1.096678614616394\n",
      "\n",
      "episode 5, policy loss 1.0966553688049316\n",
      "\n",
      "episode 6, policy loss 1.0965920686721802\n",
      "\n",
      "episode 7, policy loss 1.096492052078247\n",
      "\n",
      "episode 8, policy loss 1.0962563753128052\n",
      "\n",
      "episode 9, policy loss 1.0954394340515137\n",
      "\n",
      "episode 10, policy loss 1.0919358730316162\n",
      "\n",
      "episode 11, policy loss 1.0810093879699707\n",
      "\n",
      "episode 12, policy loss 1.028165340423584\n",
      "\n",
      "episode 13, policy loss 1.0301384925842285\n",
      "\n",
      "episode 14, policy loss 1.0388494729995728\n",
      "\n",
      "episode 15, policy loss 1.0002468824386597\n",
      "\n",
      "episode 16, policy loss 1.0295873880386353\n",
      "\n",
      "Policy train loss in epoch 1:1.0730103254318237\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.0367019176483154\n",
      "\n",
      "episode 2, policy loss 1.017890453338623\n",
      "\n",
      "episode 3, policy loss 1.002439022064209\n",
      "\n",
      "episode 4, policy loss 1.0161956548690796\n",
      "\n",
      "episode 5, policy loss 1.0078471899032593\n",
      "\n",
      "episode 6, policy loss 0.9951106309890747\n",
      "\n",
      "episode 7, policy loss 1.0080223083496094\n",
      "\n",
      "episode 8, policy loss 1.0051413774490356\n",
      "\n",
      "episode 9, policy loss 0.9954826831817627\n",
      "\n",
      "episode 10, policy loss 1.001926064491272\n",
      "\n",
      "episode 11, policy loss 1.0081140995025635\n",
      "\n",
      "episode 12, policy loss 0.9971736669540405\n",
      "\n",
      "episode 13, policy loss 1.0048660039901733\n",
      "\n",
      "episode 14, policy loss 1.007522463798523\n",
      "\n",
      "episode 15, policy loss 0.9931473135948181\n",
      "\n",
      "episode 16, policy loss 0.997892439365387\n",
      "\n",
      "Policy train loss in epoch 2:1.0059670805931091\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.9998392462730408\n",
      "\n",
      "episode 2, policy loss 0.9956921339035034\n",
      "\n",
      "episode 3, policy loss 0.9978665709495544\n",
      "\n",
      "episode 4, policy loss 1.0005576610565186\n",
      "\n",
      "episode 5, policy loss 0.9954512715339661\n",
      "\n",
      "episode 6, policy loss 0.9979720711708069\n",
      "\n",
      "episode 7, policy loss 0.9966707825660706\n",
      "\n",
      "episode 8, policy loss 0.9945133328437805\n",
      "\n",
      "episode 9, policy loss 0.9943327903747559\n",
      "\n",
      "episode 10, policy loss 0.9952890872955322\n",
      "\n",
      "episode 11, policy loss 0.9931203722953796\n",
      "\n",
      "episode 12, policy loss 0.9962426424026489\n",
      "\n",
      "episode 13, policy loss 0.9936498999595642\n",
      "\n",
      "episode 14, policy loss 0.996095597743988\n",
      "\n",
      "episode 15, policy loss 0.9949974417686462\n",
      "\n",
      "episode 16, policy loss 0.9971933960914612\n",
      "\n",
      "Policy train loss in epoch 3:0.9962177686393261\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.9063828587532043\n",
      "\n",
      "episode 2, val func loss 0.8075682520866394\n",
      "\n",
      "episode 3, val func loss 0.9605170488357544\n",
      "\n",
      "episode 4, val func loss 0.663482666015625\n",
      "\n",
      "episode 5, val func loss 0.7493987679481506\n",
      "\n",
      "episode 6, val func loss 0.872742235660553\n",
      "\n",
      "episode 7, val func loss 0.7828273773193359\n",
      "\n",
      "episode 8, val func loss 0.7569130063056946\n",
      "\n",
      "episode 9, val func loss 0.7859218716621399\n",
      "\n",
      "episode 10, val func loss 0.9127965569496155\n",
      "\n",
      "episode 11, val func loss 0.7989609241485596\n",
      "\n",
      "episode 12, val func loss 0.7628516554832458\n",
      "\n",
      "episode 13, val func loss 0.814228892326355\n",
      "\n",
      "episode 14, val func loss 0.6994931697845459\n",
      "\n",
      "episode 15, val func loss 0.7990259528160095\n",
      "\n",
      "episode 16, val func loss 0.8817428946495056\n",
      "\n",
      "Val func train loss in epoch 0:0.8096783831715584\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.9036263227462769\n",
      "\n",
      "episode 2, val func loss 0.9007377624511719\n",
      "\n",
      "episode 3, val func loss 0.7736746668815613\n",
      "\n",
      "episode 4, val func loss 0.7968637347221375\n",
      "\n",
      "episode 5, val func loss 0.9751263856887817\n",
      "\n",
      "episode 6, val func loss 0.7787160873413086\n",
      "\n",
      "episode 7, val func loss 0.8836555480957031\n",
      "\n",
      "episode 8, val func loss 0.8331247568130493\n",
      "\n",
      "episode 9, val func loss 0.7838415503501892\n",
      "\n",
      "episode 10, val func loss 0.7845901846885681\n",
      "\n",
      "episode 11, val func loss 0.7511804103851318\n",
      "\n",
      "episode 12, val func loss 0.6745673418045044\n",
      "\n",
      "episode 13, val func loss 0.8422473669052124\n",
      "\n",
      "episode 14, val func loss 0.8062965869903564\n",
      "\n",
      "episode 15, val func loss 0.7799508571624756\n",
      "\n",
      "episode 16, val func loss 0.63100665807724\n",
      "\n",
      "Val func train loss in epoch 1:0.8062003888189793\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.787621796131134\n",
      "\n",
      "episode 2, val func loss 0.6556347608566284\n",
      "\n",
      "episode 3, val func loss 0.9225834012031555\n",
      "\n",
      "episode 4, val func loss 0.7993617057800293\n",
      "\n",
      "episode 5, val func loss 0.7139701843261719\n",
      "\n",
      "episode 6, val func loss 0.7422069311141968\n",
      "\n",
      "episode 7, val func loss 0.6938146948814392\n",
      "\n",
      "episode 8, val func loss 0.7312081456184387\n",
      "\n",
      "episode 9, val func loss 0.7303329110145569\n",
      "\n",
      "episode 10, val func loss 0.8033132553100586\n",
      "\n",
      "episode 11, val func loss 0.7455443739891052\n",
      "\n",
      "episode 12, val func loss 0.8692633509635925\n",
      "\n",
      "episode 13, val func loss 0.7008500695228577\n",
      "\n",
      "episode 14, val func loss 0.6484056115150452\n",
      "\n",
      "episode 15, val func loss 0.7725032567977905\n",
      "\n",
      "episode 16, val func loss 0.7637368440628052\n",
      "\n",
      "Val func train loss in epoch 2:0.7550219558179379\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6927286982536316\n",
      "\n",
      "episode 2, val func loss 0.8088247776031494\n",
      "\n",
      "episode 3, val func loss 0.7198036313056946\n",
      "\n",
      "episode 4, val func loss 0.7778788208961487\n",
      "\n",
      "episode 5, val func loss 0.7299574017524719\n",
      "\n",
      "episode 6, val func loss 0.8563743233680725\n",
      "\n",
      "episode 7, val func loss 0.8351179957389832\n",
      "\n",
      "episode 8, val func loss 0.6978957056999207\n",
      "\n",
      "episode 9, val func loss 0.8365302085876465\n",
      "\n",
      "episode 10, val func loss 0.7739505767822266\n",
      "\n",
      "episode 11, val func loss 0.7303000688552856\n",
      "\n",
      "episode 12, val func loss 0.7461671829223633\n",
      "\n",
      "episode 13, val func loss 0.7279790639877319\n",
      "\n",
      "episode 14, val func loss 0.8569061756134033\n",
      "\n",
      "episode 15, val func loss 0.8548198342323303\n",
      "\n",
      "episode 16, val func loss 0.7052620649337769\n",
      "\n",
      "Val func train loss in epoch 3:0.7719060331583023\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8347822427749634\n",
      "\n",
      "episode 2, val func loss 0.7775482535362244\n",
      "\n",
      "episode 3, val func loss 0.7801430821418762\n",
      "\n",
      "episode 4, val func loss 0.8891963362693787\n",
      "\n",
      "episode 5, val func loss 0.8353724479675293\n",
      "\n",
      "episode 6, val func loss 0.6704915165901184\n",
      "\n",
      "episode 7, val func loss 0.8008698225021362\n",
      "\n",
      "episode 8, val func loss 0.7189832329750061\n",
      "\n",
      "episode 9, val func loss 0.730330765247345\n",
      "\n",
      "episode 10, val func loss 0.725730836391449\n",
      "\n",
      "episode 11, val func loss 0.8423201441764832\n",
      "\n",
      "episode 12, val func loss 0.7946935892105103\n",
      "\n",
      "episode 13, val func loss 0.6779733300209045\n",
      "\n",
      "episode 14, val func loss 0.7043046951293945\n",
      "\n",
      "episode 15, val func loss 0.7906053066253662\n",
      "\n",
      "episode 16, val func loss 0.9454421997070312\n",
      "\n",
      "Val func train loss in epoch 4:0.7824242375791073\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.8221331834793091\n",
      "\n",
      "episode 2, val func loss 0.9407303333282471\n",
      "\n",
      "episode 3, val func loss 0.7479743957519531\n",
      "\n",
      "episode 4, val func loss 0.6011160016059875\n",
      "\n",
      "episode 5, val func loss 0.7909703850746155\n",
      "\n",
      "episode 6, val func loss 0.7418652772903442\n",
      "\n",
      "episode 7, val func loss 0.8368090987205505\n",
      "\n",
      "episode 8, val func loss 0.651970386505127\n",
      "\n",
      "episode 9, val func loss 0.7215387225151062\n",
      "\n",
      "episode 10, val func loss 0.7741735577583313\n",
      "\n",
      "episode 11, val func loss 0.695548415184021\n",
      "\n",
      "episode 12, val func loss 0.7351827621459961\n",
      "\n",
      "episode 13, val func loss 0.6809568405151367\n",
      "\n",
      "episode 14, val func loss 0.7019937038421631\n",
      "\n",
      "episode 15, val func loss 0.7638174891471863\n",
      "\n",
      "episode 16, val func loss 0.7587783932685852\n",
      "\n",
      "Val func train loss in epoch 5:0.7478474341332912\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8062125444412231\n",
      "\n",
      "episode 2, val func loss 0.9755088090896606\n",
      "\n",
      "episode 3, val func loss 0.7610053420066833\n",
      "\n",
      "episode 4, val func loss 0.6367790699005127\n",
      "\n",
      "episode 5, val func loss 0.7265427112579346\n",
      "\n",
      "episode 6, val func loss 0.7634289860725403\n",
      "\n",
      "episode 7, val func loss 0.6960254311561584\n",
      "\n",
      "episode 8, val func loss 0.7906301617622375\n",
      "\n",
      "episode 9, val func loss 0.6886157989501953\n",
      "\n",
      "episode 10, val func loss 0.7588739395141602\n",
      "\n",
      "episode 11, val func loss 0.8321535587310791\n",
      "\n",
      "episode 12, val func loss 0.7755417227745056\n",
      "\n",
      "episode 13, val func loss 0.7799485325813293\n",
      "\n",
      "episode 14, val func loss 0.828642725944519\n",
      "\n",
      "episode 15, val func loss 0.7258234620094299\n",
      "\n",
      "episode 16, val func loss 0.7803168296813965\n",
      "\n",
      "Val func train loss in epoch 6:0.7703781016170979\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7365217804908752\n",
      "\n",
      "episode 2, val func loss 0.8509458899497986\n",
      "\n",
      "episode 3, val func loss 0.6807810664176941\n",
      "\n",
      "episode 4, val func loss 0.6547991037368774\n",
      "\n",
      "episode 5, val func loss 0.6841211318969727\n",
      "\n",
      "episode 6, val func loss 0.768052339553833\n",
      "\n",
      "episode 7, val func loss 0.7645937204360962\n",
      "\n",
      "episode 8, val func loss 0.748832106590271\n",
      "\n",
      "episode 9, val func loss 0.8055866360664368\n",
      "\n",
      "episode 10, val func loss 0.7266759872436523\n",
      "\n",
      "episode 11, val func loss 0.7540803551673889\n",
      "\n",
      "episode 12, val func loss 0.7307412624359131\n",
      "\n",
      "episode 13, val func loss 0.7620728015899658\n",
      "\n",
      "episode 14, val func loss 0.757807195186615\n",
      "\n",
      "episode 15, val func loss 0.8292397260665894\n",
      "\n",
      "episode 16, val func loss 0.9135016202926636\n",
      "\n",
      "Val func train loss in epoch 7:0.7605220451951027\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7422991991043091\n",
      "\n",
      "episode 2, val func loss 0.7873978018760681\n",
      "\n",
      "episode 3, val func loss 0.8047167658805847\n",
      "\n",
      "episode 4, val func loss 0.6973209381103516\n",
      "\n",
      "episode 5, val func loss 0.9074850082397461\n",
      "\n",
      "episode 6, val func loss 0.7162840366363525\n",
      "\n",
      "episode 7, val func loss 0.6810630559921265\n",
      "\n",
      "episode 8, val func loss 0.8467904329299927\n",
      "\n",
      "episode 9, val func loss 0.7489351034164429\n",
      "\n",
      "episode 10, val func loss 0.7645222544670105\n",
      "\n",
      "episode 11, val func loss 0.71489018201828\n",
      "\n",
      "episode 12, val func loss 0.7961775660514832\n",
      "\n",
      "episode 13, val func loss 0.7984237670898438\n",
      "\n",
      "episode 14, val func loss 0.8502931594848633\n",
      "\n",
      "episode 15, val func loss 0.7522054314613342\n",
      "\n",
      "episode 16, val func loss 0.9176151752471924\n",
      "\n",
      "Val func train loss in epoch 8:0.7829012423753738\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8065155744552612\n",
      "\n",
      "episode 2, val func loss 0.7120257616043091\n",
      "\n",
      "episode 3, val func loss 0.687084972858429\n",
      "\n",
      "episode 4, val func loss 0.7147709727287292\n",
      "\n",
      "episode 5, val func loss 0.779780924320221\n",
      "\n",
      "episode 6, val func loss 0.7135194540023804\n",
      "\n",
      "episode 7, val func loss 0.7799578309059143\n",
      "\n",
      "episode 8, val func loss 0.7360607981681824\n",
      "\n",
      "episode 9, val func loss 0.6715627312660217\n",
      "\n",
      "episode 10, val func loss 0.798262894153595\n",
      "\n",
      "episode 11, val func loss 0.8693792819976807\n",
      "\n",
      "episode 12, val func loss 0.7857568264007568\n",
      "\n",
      "episode 13, val func loss 0.7165533900260925\n",
      "\n",
      "episode 14, val func loss 0.7940722703933716\n",
      "\n",
      "episode 15, val func loss 0.7985838055610657\n",
      "\n",
      "episode 16, val func loss 0.7922960519790649\n",
      "\n",
      "Val func train loss in epoch 9:0.7597614713013172\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.76752769947052\n",
      "\n",
      "episode 2, val func loss 0.7048603892326355\n",
      "\n",
      "episode 3, val func loss 0.8511915802955627\n",
      "\n",
      "episode 4, val func loss 0.7413002848625183\n",
      "\n",
      "episode 5, val func loss 0.7932202219963074\n",
      "\n",
      "episode 6, val func loss 0.8212420344352722\n",
      "\n",
      "episode 7, val func loss 0.7322912812232971\n",
      "\n",
      "episode 8, val func loss 0.7956756949424744\n",
      "\n",
      "episode 9, val func loss 0.710257351398468\n",
      "\n",
      "episode 10, val func loss 0.7918122410774231\n",
      "\n",
      "episode 11, val func loss 0.756080150604248\n",
      "\n",
      "episode 12, val func loss 0.7108885645866394\n",
      "\n",
      "episode 13, val func loss 0.7764618396759033\n",
      "\n",
      "episode 14, val func loss 0.6682172417640686\n",
      "\n",
      "episode 15, val func loss 0.8247401118278503\n",
      "\n",
      "episode 16, val func loss 0.7668913006782532\n",
      "\n",
      "Val func train loss in epoch 10:0.7632911242544651\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7529779672622681\n",
      "\n",
      "episode 2, val func loss 0.684428870677948\n",
      "\n",
      "episode 3, val func loss 0.6711302995681763\n",
      "\n",
      "episode 4, val func loss 0.6205433011054993\n",
      "\n",
      "episode 5, val func loss 0.7407659292221069\n",
      "\n",
      "episode 6, val func loss 0.7178002595901489\n",
      "\n",
      "episode 7, val func loss 0.7444829940795898\n",
      "\n",
      "episode 8, val func loss 0.7248401045799255\n",
      "\n",
      "episode 9, val func loss 0.7421208620071411\n",
      "\n",
      "episode 10, val func loss 0.7440769672393799\n",
      "\n",
      "episode 11, val func loss 0.692108690738678\n",
      "\n",
      "episode 12, val func loss 0.7327159643173218\n",
      "\n",
      "episode 13, val func loss 0.8599714636802673\n",
      "\n",
      "episode 14, val func loss 0.8592552542686462\n",
      "\n",
      "episode 15, val func loss 0.7404753565788269\n",
      "\n",
      "episode 16, val func loss 0.8830843567848206\n",
      "\n",
      "Val func train loss in epoch 11:0.7444236651062965\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7240452170372009\n",
      "\n",
      "episode 2, val func loss 0.7845224738121033\n",
      "\n",
      "episode 3, val func loss 0.8949572443962097\n",
      "\n",
      "episode 4, val func loss 0.6435599327087402\n",
      "\n",
      "episode 5, val func loss 0.674830973148346\n",
      "\n",
      "episode 6, val func loss 0.787817120552063\n",
      "\n",
      "episode 7, val func loss 0.7227005362510681\n",
      "\n",
      "episode 8, val func loss 0.7198247909545898\n",
      "\n",
      "episode 9, val func loss 0.70113605260849\n",
      "\n",
      "episode 10, val func loss 0.7606690526008606\n",
      "\n",
      "episode 11, val func loss 0.7536097168922424\n",
      "\n",
      "episode 12, val func loss 0.7511940002441406\n",
      "\n",
      "episode 13, val func loss 0.9843613505363464\n",
      "\n",
      "episode 14, val func loss 0.7897088527679443\n",
      "\n",
      "episode 15, val func loss 0.76336669921875\n",
      "\n",
      "episode 16, val func loss 0.9130945205688477\n",
      "\n",
      "Val func train loss in epoch 12:0.7730874083936214\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8177443742752075\n",
      "\n",
      "episode 2, val func loss 0.7807292938232422\n",
      "\n",
      "episode 3, val func loss 0.7773464918136597\n",
      "\n",
      "episode 4, val func loss 0.9252631068229675\n",
      "\n",
      "episode 5, val func loss 0.651240885257721\n",
      "\n",
      "episode 6, val func loss 0.8426901698112488\n",
      "\n",
      "episode 7, val func loss 0.9430104494094849\n",
      "\n",
      "episode 8, val func loss 0.8054648637771606\n",
      "\n",
      "episode 9, val func loss 0.8481782078742981\n",
      "\n",
      "episode 10, val func loss 0.79814213514328\n",
      "\n",
      "episode 11, val func loss 0.8479030728340149\n",
      "\n",
      "episode 12, val func loss 0.6862373352050781\n",
      "\n",
      "episode 13, val func loss 0.7098966836929321\n",
      "\n",
      "episode 14, val func loss 0.7501373291015625\n",
      "\n",
      "episode 15, val func loss 0.7348067164421082\n",
      "\n",
      "episode 16, val func loss 0.7512567043304443\n",
      "\n",
      "Val func train loss in epoch 13:0.7918779887259007\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7130792737007141\n",
      "\n",
      "episode 2, val func loss 0.6904649138450623\n",
      "\n",
      "episode 3, val func loss 0.786720871925354\n",
      "\n",
      "episode 4, val func loss 0.8419929146766663\n",
      "\n",
      "episode 5, val func loss 0.7542111873626709\n",
      "\n",
      "episode 6, val func loss 0.8563662171363831\n",
      "\n",
      "episode 7, val func loss 0.750278890132904\n",
      "\n",
      "episode 8, val func loss 0.8201157450675964\n",
      "\n",
      "episode 9, val func loss 0.7443476319313049\n",
      "\n",
      "episode 10, val func loss 0.7288709282875061\n",
      "\n",
      "episode 11, val func loss 0.7474110126495361\n",
      "\n",
      "episode 12, val func loss 0.8207215070724487\n",
      "\n",
      "episode 13, val func loss 0.795217752456665\n",
      "\n",
      "episode 14, val func loss 0.8445326089859009\n",
      "\n",
      "episode 15, val func loss 0.8466854095458984\n",
      "\n",
      "episode 16, val func loss 0.690830647945404\n",
      "\n",
      "Val func train loss in epoch 14:0.776990469545126\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6737064123153687\n",
      "\n",
      "episode 2, val func loss 0.7497254610061646\n",
      "\n",
      "episode 3, val func loss 0.8163201212882996\n",
      "\n",
      "episode 4, val func loss 0.6408019065856934\n",
      "\n",
      "episode 5, val func loss 0.6954631805419922\n",
      "\n",
      "episode 6, val func loss 0.8333818316459656\n",
      "\n",
      "episode 7, val func loss 0.7669578194618225\n",
      "\n",
      "episode 8, val func loss 0.7205584049224854\n",
      "\n",
      "episode 9, val func loss 0.7299497723579407\n",
      "\n",
      "episode 10, val func loss 0.6795951724052429\n",
      "\n",
      "episode 11, val func loss 0.6482625603675842\n",
      "\n",
      "episode 12, val func loss 0.7131586074829102\n",
      "\n",
      "episode 13, val func loss 0.7670140862464905\n",
      "\n",
      "episode 14, val func loss 0.7115166187286377\n",
      "\n",
      "episode 15, val func loss 0.6741039156913757\n",
      "\n",
      "episode 16, val func loss 0.6554601788520813\n",
      "\n",
      "Val func train loss in epoch 15:0.7172485031187534\n",
      "***********************TIME WAS 4.893985056877137 min*****************************\n",
      "\n",
      "**********************ROUND 100 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.7112153768539429\n",
      "\n",
      "episode 2, policy loss 1.226523995399475\n",
      "\n",
      "episode 3, policy loss 1.6556490659713745\n",
      "\n",
      "episode 4, policy loss 1.508217215538025\n",
      "\n",
      "episode 5, policy loss 1.6042579412460327\n",
      "\n",
      "episode 6, policy loss 1.4151536226272583\n",
      "\n",
      "episode 7, policy loss 1.6893030405044556\n",
      "\n",
      "episode 8, policy loss 1.457590103149414\n",
      "\n",
      "episode 9, policy loss 1.719341516494751\n",
      "\n",
      "episode 10, policy loss 1.3277939558029175\n",
      "\n",
      "episode 11, policy loss 1.161671757698059\n",
      "\n",
      "episode 12, policy loss 1.81840181350708\n",
      "\n",
      "episode 13, policy loss 1.3707982301712036\n",
      "\n",
      "episode 14, policy loss 1.596445083618164\n",
      "\n",
      "episode 15, policy loss 1.4132267236709595\n",
      "\n",
      "episode 16, policy loss 1.6739102602005005\n",
      "\n",
      "Policy train loss in epoch 0:1.5218437314033508\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.275974154472351\n",
      "\n",
      "episode 2, policy loss 1.695731520652771\n",
      "\n",
      "episode 3, policy loss 1.662177562713623\n",
      "\n",
      "episode 4, policy loss 1.5894211530685425\n",
      "\n",
      "episode 5, policy loss 1.1505475044250488\n",
      "\n",
      "episode 6, policy loss 1.6709667444229126\n",
      "\n",
      "episode 7, policy loss 1.4206165075302124\n",
      "\n",
      "episode 8, policy loss 1.8006577491760254\n",
      "\n",
      "episode 9, policy loss 1.3078508377075195\n",
      "\n",
      "episode 10, policy loss 1.4357496500015259\n",
      "\n",
      "episode 11, policy loss 1.515886902809143\n",
      "\n",
      "episode 12, policy loss 1.3958712816238403\n",
      "\n",
      "episode 13, policy loss 1.6633291244506836\n",
      "\n",
      "episode 14, policy loss 1.6812762022018433\n",
      "\n",
      "episode 15, policy loss 1.3412108421325684\n",
      "\n",
      "episode 16, policy loss 1.5628080368041992\n",
      "\n",
      "Policy train loss in epoch 1:1.5106297358870506\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.5586750507354736\n",
      "\n",
      "episode 2, policy loss 1.6987547874450684\n",
      "\n",
      "episode 3, policy loss 1.4847923517227173\n",
      "\n",
      "episode 4, policy loss 1.2520135641098022\n",
      "\n",
      "episode 5, policy loss 1.652287483215332\n",
      "\n",
      "episode 6, policy loss 1.6895655393600464\n",
      "\n",
      "episode 7, policy loss 1.3995485305786133\n",
      "\n",
      "episode 8, policy loss 1.1391355991363525\n",
      "\n",
      "episode 9, policy loss 1.4300191402435303\n",
      "\n",
      "episode 10, policy loss 1.7959083318710327\n",
      "\n",
      "episode 11, policy loss 1.4189751148223877\n",
      "\n",
      "episode 12, policy loss 1.6539900302886963\n",
      "\n",
      "episode 13, policy loss 1.3553643226623535\n",
      "\n",
      "episode 14, policy loss 1.5944463014602661\n",
      "\n",
      "episode 15, policy loss 1.6952769756317139\n",
      "\n",
      "episode 16, policy loss 1.3139723539352417\n",
      "\n",
      "Policy train loss in epoch 2:1.5082953423261642\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.5891921520233154\n",
      "\n",
      "episode 2, policy loss 1.1480110883712769\n",
      "\n",
      "episode 3, policy loss 1.6681245565414429\n",
      "\n",
      "episode 4, policy loss 1.3025354146957397\n",
      "\n",
      "episode 5, policy loss 1.7242017984390259\n",
      "\n",
      "episode 6, policy loss 1.4294496774673462\n",
      "\n",
      "episode 7, policy loss 1.8076423406600952\n",
      "\n",
      "episode 8, policy loss 1.3951661586761475\n",
      "\n",
      "episode 9, policy loss 1.6618859767913818\n",
      "\n",
      "episode 10, policy loss 1.346121072769165\n",
      "\n",
      "episode 11, policy loss 1.242995023727417\n",
      "\n",
      "episode 12, policy loss 1.6484835147857666\n",
      "\n",
      "episode 13, policy loss 1.4920696020126343\n",
      "\n",
      "episode 14, policy loss 1.3908827304840088\n",
      "\n",
      "episode 15, policy loss 1.7027385234832764\n",
      "\n",
      "episode 16, policy loss 1.5664924383163452\n",
      "\n",
      "Policy train loss in epoch 3:1.507249504327774\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 3.246593952178955\n",
      "\n",
      "episode 2, val func loss 2.54274320602417\n",
      "\n",
      "episode 3, val func loss 3.3401553630828857\n",
      "\n",
      "episode 4, val func loss 2.4744553565979004\n",
      "\n",
      "episode 5, val func loss 1.944691777229309\n",
      "\n",
      "episode 6, val func loss 2.8889758586883545\n",
      "\n",
      "episode 7, val func loss 3.0863282680511475\n",
      "\n",
      "episode 8, val func loss 3.011916160583496\n",
      "\n",
      "episode 9, val func loss 2.920309066772461\n",
      "\n",
      "episode 10, val func loss 3.5949840545654297\n",
      "\n",
      "episode 11, val func loss 2.967275619506836\n",
      "\n",
      "episode 12, val func loss 2.26204252243042\n",
      "\n",
      "episode 13, val func loss 3.186882495880127\n",
      "\n",
      "episode 14, val func loss 3.3102803230285645\n",
      "\n",
      "episode 15, val func loss 3.4773523807525635\n",
      "\n",
      "episode 16, val func loss 2.614529848098755\n",
      "\n",
      "Val func train loss in epoch 0:2.929344765841961\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.364128351211548\n",
      "\n",
      "episode 2, val func loss 2.9699580669403076\n",
      "\n",
      "episode 3, val func loss 2.4456911087036133\n",
      "\n",
      "episode 4, val func loss 3.5929064750671387\n",
      "\n",
      "episode 5, val func loss 2.245711326599121\n",
      "\n",
      "episode 6, val func loss 3.1540982723236084\n",
      "\n",
      "episode 7, val func loss 2.8502070903778076\n",
      "\n",
      "episode 8, val func loss 2.5263147354125977\n",
      "\n",
      "episode 9, val func loss 3.295586109161377\n",
      "\n",
      "episode 10, val func loss 3.4051079750061035\n",
      "\n",
      "episode 11, val func loss 3.2370858192443848\n",
      "\n",
      "episode 12, val func loss 3.1780056953430176\n",
      "\n",
      "episode 13, val func loss 2.8338980674743652\n",
      "\n",
      "episode 14, val func loss 3.26587176322937\n",
      "\n",
      "episode 15, val func loss 2.677379846572876\n",
      "\n",
      "episode 16, val func loss 2.3435118198394775\n",
      "\n",
      "Val func train loss in epoch 1:2.8990914076566696\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.4035520553588867\n",
      "\n",
      "episode 2, val func loss 2.8786091804504395\n",
      "\n",
      "episode 3, val func loss 2.2243006229400635\n",
      "\n",
      "episode 4, val func loss 2.55606746673584\n",
      "\n",
      "episode 5, val func loss 2.9436028003692627\n",
      "\n",
      "episode 6, val func loss 2.316131591796875\n",
      "\n",
      "episode 7, val func loss 3.0499167442321777\n",
      "\n",
      "episode 8, val func loss 3.417949676513672\n",
      "\n",
      "episode 9, val func loss 3.411508321762085\n",
      "\n",
      "episode 10, val func loss 3.175978899002075\n",
      "\n",
      "episode 11, val func loss 3.1497445106506348\n",
      "\n",
      "episode 12, val func loss 2.801072597503662\n",
      "\n",
      "episode 13, val func loss 2.4818992614746094\n",
      "\n",
      "episode 14, val func loss 3.0625863075256348\n",
      "\n",
      "episode 15, val func loss 1.8796546459197998\n",
      "\n",
      "episode 16, val func loss 2.751905679702759\n",
      "\n",
      "Val func train loss in epoch 2:2.781530022621155\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 3.580125331878662\n",
      "\n",
      "episode 2, val func loss 3.014564275741577\n",
      "\n",
      "episode 3, val func loss 2.528409719467163\n",
      "\n",
      "episode 4, val func loss 3.261025905609131\n",
      "\n",
      "episode 5, val func loss 2.341322422027588\n",
      "\n",
      "episode 6, val func loss 3.1005024909973145\n",
      "\n",
      "episode 7, val func loss 2.0925824642181396\n",
      "\n",
      "episode 8, val func loss 3.3266005516052246\n",
      "\n",
      "episode 9, val func loss 2.7533118724823\n",
      "\n",
      "episode 10, val func loss 2.8609514236450195\n",
      "\n",
      "episode 11, val func loss 2.465012550354004\n",
      "\n",
      "episode 12, val func loss 3.0677778720855713\n",
      "\n",
      "episode 13, val func loss 2.538728952407837\n",
      "\n",
      "episode 14, val func loss 2.945147752761841\n",
      "\n",
      "episode 15, val func loss 2.804264545440674\n",
      "\n",
      "episode 16, val func loss 2.3432538509368896\n",
      "\n",
      "Val func train loss in epoch 3:2.8139738738536835\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.752122640609741\n",
      "\n",
      "episode 2, val func loss 2.3529698848724365\n",
      "\n",
      "episode 3, val func loss 2.880258798599243\n",
      "\n",
      "episode 4, val func loss 3.065598964691162\n",
      "\n",
      "episode 5, val func loss 2.1110754013061523\n",
      "\n",
      "episode 6, val func loss 3.145108938217163\n",
      "\n",
      "episode 7, val func loss 3.420738935470581\n",
      "\n",
      "episode 8, val func loss 3.52777099609375\n",
      "\n",
      "episode 9, val func loss 3.3646538257598877\n",
      "\n",
      "episode 10, val func loss 2.814866542816162\n",
      "\n",
      "episode 11, val func loss 3.004094123840332\n",
      "\n",
      "episode 12, val func loss 2.442765951156616\n",
      "\n",
      "episode 13, val func loss 2.395922899246216\n",
      "\n",
      "episode 14, val func loss 3.5633041858673096\n",
      "\n",
      "episode 15, val func loss 2.784010648727417\n",
      "\n",
      "episode 16, val func loss 2.2193806171417236\n",
      "\n",
      "Val func train loss in epoch 4:2.8652902096509933\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 2.533139944076538\n",
      "\n",
      "episode 2, val func loss 3.1315228939056396\n",
      "\n",
      "episode 3, val func loss 2.77948260307312\n",
      "\n",
      "episode 4, val func loss 2.3359389305114746\n",
      "\n",
      "episode 5, val func loss 2.7797858715057373\n",
      "\n",
      "episode 6, val func loss 3.038069486618042\n",
      "\n",
      "episode 7, val func loss 2.6164066791534424\n",
      "\n",
      "episode 8, val func loss 1.8329192399978638\n",
      "\n",
      "episode 9, val func loss 2.9852912425994873\n",
      "\n",
      "episode 10, val func loss 2.4208219051361084\n",
      "\n",
      "episode 11, val func loss 2.844860076904297\n",
      "\n",
      "episode 12, val func loss 2.4588840007781982\n",
      "\n",
      "episode 13, val func loss 2.832585334777832\n",
      "\n",
      "episode 14, val func loss 2.7667932510375977\n",
      "\n",
      "episode 15, val func loss 3.151463508605957\n",
      "\n",
      "episode 16, val func loss 3.46445631980896\n",
      "\n",
      "Val func train loss in epoch 5:2.7482763305306435\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.6011176109313965\n",
      "\n",
      "episode 2, val func loss 2.4099135398864746\n",
      "\n",
      "episode 3, val func loss 3.7014658451080322\n",
      "\n",
      "episode 4, val func loss 2.818054676055908\n",
      "\n",
      "episode 5, val func loss 3.027039051055908\n",
      "\n",
      "episode 6, val func loss 2.333359718322754\n",
      "\n",
      "episode 7, val func loss 2.848426103591919\n",
      "\n",
      "episode 8, val func loss 3.3081188201904297\n",
      "\n",
      "episode 9, val func loss 3.2415761947631836\n",
      "\n",
      "episode 10, val func loss 3.4727532863616943\n",
      "\n",
      "episode 11, val func loss 3.608781576156616\n",
      "\n",
      "episode 12, val func loss 3.1629230976104736\n",
      "\n",
      "episode 13, val func loss 3.2700395584106445\n",
      "\n",
      "episode 14, val func loss 3.330551862716675\n",
      "\n",
      "episode 15, val func loss 2.568234443664551\n",
      "\n",
      "episode 16, val func loss 2.455591917037964\n",
      "\n",
      "Val func train loss in epoch 6:3.009871706366539\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 3.621853828430176\n",
      "\n",
      "episode 2, val func loss 2.041351079940796\n",
      "\n",
      "episode 3, val func loss 3.1666460037231445\n",
      "\n",
      "episode 4, val func loss 2.615741491317749\n",
      "\n",
      "episode 5, val func loss 2.436323404312134\n",
      "\n",
      "episode 6, val func loss 3.449622869491577\n",
      "\n",
      "episode 7, val func loss 3.8333823680877686\n",
      "\n",
      "episode 8, val func loss 2.6646041870117188\n",
      "\n",
      "episode 9, val func loss 2.973825216293335\n",
      "\n",
      "episode 10, val func loss 2.970280647277832\n",
      "\n",
      "episode 11, val func loss 2.949388265609741\n",
      "\n",
      "episode 12, val func loss 2.9560706615448\n",
      "\n",
      "episode 13, val func loss 3.347388982772827\n",
      "\n",
      "episode 14, val func loss 3.1681015491485596\n",
      "\n",
      "episode 15, val func loss 2.518648386001587\n",
      "\n",
      "episode 16, val func loss 3.136838674545288\n",
      "\n",
      "Val func train loss in epoch 7:2.9906292259693146\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.022545099258423\n",
      "\n",
      "episode 2, val func loss 3.238903045654297\n",
      "\n",
      "episode 3, val func loss 3.202972412109375\n",
      "\n",
      "episode 4, val func loss 3.5659751892089844\n",
      "\n",
      "episode 5, val func loss 3.025301218032837\n",
      "\n",
      "episode 6, val func loss 2.738295078277588\n",
      "\n",
      "episode 7, val func loss 2.894181966781616\n",
      "\n",
      "episode 8, val func loss 2.252887487411499\n",
      "\n",
      "episode 9, val func loss 2.529899835586548\n",
      "\n",
      "episode 10, val func loss 3.596479654312134\n",
      "\n",
      "episode 11, val func loss 3.7372443675994873\n",
      "\n",
      "episode 12, val func loss 3.634695291519165\n",
      "\n",
      "episode 13, val func loss 3.0892016887664795\n",
      "\n",
      "episode 14, val func loss 2.751084804534912\n",
      "\n",
      "episode 15, val func loss 3.582653522491455\n",
      "\n",
      "episode 16, val func loss 2.910274028778076\n",
      "\n",
      "Val func train loss in epoch 8:3.0482871681451797\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 2.563358783721924\n",
      "\n",
      "episode 2, val func loss 2.5949504375457764\n",
      "\n",
      "episode 3, val func loss 3.308133363723755\n",
      "\n",
      "episode 4, val func loss 2.3913512229919434\n",
      "\n",
      "episode 5, val func loss 2.426612377166748\n",
      "\n",
      "episode 6, val func loss 3.1603097915649414\n",
      "\n",
      "episode 7, val func loss 3.121523141860962\n",
      "\n",
      "episode 8, val func loss 3.293947696685791\n",
      "\n",
      "episode 9, val func loss 2.780043840408325\n",
      "\n",
      "episode 10, val func loss 2.9391984939575195\n",
      "\n",
      "episode 11, val func loss 2.7134382724761963\n",
      "\n",
      "episode 12, val func loss 3.1552696228027344\n",
      "\n",
      "episode 13, val func loss 2.0640552043914795\n",
      "\n",
      "episode 14, val func loss 3.501345157623291\n",
      "\n",
      "episode 15, val func loss 3.9258668422698975\n",
      "\n",
      "episode 16, val func loss 2.75669264793396\n",
      "\n",
      "Val func train loss in epoch 9:2.9185060560703278\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.438106060028076\n",
      "\n",
      "episode 2, val func loss 3.303278684616089\n",
      "\n",
      "episode 3, val func loss 2.291555166244507\n",
      "\n",
      "episode 4, val func loss 1.8706456422805786\n",
      "\n",
      "episode 5, val func loss 2.8941938877105713\n",
      "\n",
      "episode 6, val func loss 3.933675527572632\n",
      "\n",
      "episode 7, val func loss 3.7254083156585693\n",
      "\n",
      "episode 8, val func loss 2.66780948638916\n",
      "\n",
      "episode 9, val func loss 2.8792195320129395\n",
      "\n",
      "episode 10, val func loss 3.1886041164398193\n",
      "\n",
      "episode 11, val func loss 2.5424258708953857\n",
      "\n",
      "episode 12, val func loss 3.0078115463256836\n",
      "\n",
      "episode 13, val func loss 2.1702880859375\n",
      "\n",
      "episode 14, val func loss 3.207181930541992\n",
      "\n",
      "episode 15, val func loss 3.4247281551361084\n",
      "\n",
      "episode 16, val func loss 2.9541921615600586\n",
      "\n",
      "Val func train loss in epoch 10:2.9061952605843544\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 2.7097885608673096\n",
      "\n",
      "episode 2, val func loss 2.891838550567627\n",
      "\n",
      "episode 3, val func loss 2.5035560131073\n",
      "\n",
      "episode 4, val func loss 2.443763017654419\n",
      "\n",
      "episode 5, val func loss 2.9300661087036133\n",
      "\n",
      "episode 6, val func loss 3.0991005897521973\n",
      "\n",
      "episode 7, val func loss 3.678863286972046\n",
      "\n",
      "episode 8, val func loss 3.011179208755493\n",
      "\n",
      "episode 9, val func loss 3.2585670948028564\n",
      "\n",
      "episode 10, val func loss 3.5517184734344482\n",
      "\n",
      "episode 11, val func loss 2.2967283725738525\n",
      "\n",
      "episode 12, val func loss 3.0398471355438232\n",
      "\n",
      "episode 13, val func loss 2.889815092086792\n",
      "\n",
      "episode 14, val func loss 2.8227314949035645\n",
      "\n",
      "episode 15, val func loss 2.9923746585845947\n",
      "\n",
      "episode 16, val func loss 1.7207597494125366\n",
      "\n",
      "Val func train loss in epoch 11:2.8650435879826546\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 2.309161901473999\n",
      "\n",
      "episode 2, val func loss 2.7824316024780273\n",
      "\n",
      "episode 3, val func loss 2.5639781951904297\n",
      "\n",
      "episode 4, val func loss 2.4839611053466797\n",
      "\n",
      "episode 5, val func loss 3.0069401264190674\n",
      "\n",
      "episode 6, val func loss 2.5277926921844482\n",
      "\n",
      "episode 7, val func loss 2.6936962604522705\n",
      "\n",
      "episode 8, val func loss 3.4272196292877197\n",
      "\n",
      "episode 9, val func loss 2.061466693878174\n",
      "\n",
      "episode 10, val func loss 3.7609477043151855\n",
      "\n",
      "episode 11, val func loss 2.863569498062134\n",
      "\n",
      "episode 12, val func loss 3.0857481956481934\n",
      "\n",
      "episode 13, val func loss 3.1314916610717773\n",
      "\n",
      "episode 14, val func loss 2.7186882495880127\n",
      "\n",
      "episode 15, val func loss 2.521904468536377\n",
      "\n",
      "episode 16, val func loss 3.0996949672698975\n",
      "\n",
      "Val func train loss in epoch 12:2.8149183094501495\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 2.95534348487854\n",
      "\n",
      "episode 2, val func loss 2.414687156677246\n",
      "\n",
      "episode 3, val func loss 3.368056535720825\n",
      "\n",
      "episode 4, val func loss 2.028751850128174\n",
      "\n",
      "episode 5, val func loss 3.0980045795440674\n",
      "\n",
      "episode 6, val func loss 2.342298746109009\n",
      "\n",
      "episode 7, val func loss 2.7782835960388184\n",
      "\n",
      "episode 8, val func loss 2.9429702758789062\n",
      "\n",
      "episode 9, val func loss 2.9191198348999023\n",
      "\n",
      "episode 10, val func loss 2.5671722888946533\n",
      "\n",
      "episode 11, val func loss 2.328045129776001\n",
      "\n",
      "episode 12, val func loss 2.920262336730957\n",
      "\n",
      "episode 13, val func loss 2.865478277206421\n",
      "\n",
      "episode 14, val func loss 3.6451807022094727\n",
      "\n",
      "episode 15, val func loss 3.3591558933258057\n",
      "\n",
      "episode 16, val func loss 3.362912893295288\n",
      "\n",
      "Val func train loss in epoch 13:2.8684827238321304\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 3.166672706604004\n",
      "\n",
      "episode 2, val func loss 2.9557297229766846\n",
      "\n",
      "episode 3, val func loss 3.6138200759887695\n",
      "\n",
      "episode 4, val func loss 2.320514440536499\n",
      "\n",
      "episode 5, val func loss 3.6406121253967285\n",
      "\n",
      "episode 6, val func loss 3.2147793769836426\n",
      "\n",
      "episode 7, val func loss 2.2794189453125\n",
      "\n",
      "episode 8, val func loss 2.896674156188965\n",
      "\n",
      "episode 9, val func loss 1.8229637145996094\n",
      "\n",
      "episode 10, val func loss 2.4575111865997314\n",
      "\n",
      "episode 11, val func loss 3.358299732208252\n",
      "\n",
      "episode 12, val func loss 2.402538537979126\n",
      "\n",
      "episode 13, val func loss 2.8425519466400146\n",
      "\n",
      "episode 14, val func loss 2.949047327041626\n",
      "\n",
      "episode 15, val func loss 2.756563425064087\n",
      "\n",
      "episode 16, val func loss 2.8648951053619385\n",
      "\n",
      "Val func train loss in epoch 14:2.846412032842636\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 3.633075714111328\n",
      "\n",
      "episode 2, val func loss 2.937161684036255\n",
      "\n",
      "episode 3, val func loss 2.663900375366211\n",
      "\n",
      "episode 4, val func loss 3.073657989501953\n",
      "\n",
      "episode 5, val func loss 3.171384572982788\n",
      "\n",
      "episode 6, val func loss 2.4726462364196777\n",
      "\n",
      "episode 7, val func loss 2.594616651535034\n",
      "\n",
      "episode 8, val func loss 3.34075665473938\n",
      "\n",
      "episode 9, val func loss 1.878623366355896\n",
      "\n",
      "episode 10, val func loss 2.14951753616333\n",
      "\n",
      "episode 11, val func loss 2.4796059131622314\n",
      "\n",
      "episode 12, val func loss 3.339613676071167\n",
      "\n",
      "episode 13, val func loss 3.4666383266448975\n",
      "\n",
      "episode 14, val func loss 2.526987314224243\n",
      "\n",
      "episode 15, val func loss 3.075572967529297\n",
      "\n",
      "episode 16, val func loss 2.725231170654297\n",
      "\n",
      "Val func train loss in epoch 15:2.845561884343624\n",
      "***********************TIME WAS 4.889348204930624 min*****************************\n",
      "\n",
      "**********************ROUND 101 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.3527906537055969\n",
      "\n",
      "episode 2, policy loss 0.2163514643907547\n",
      "\n",
      "episode 3, policy loss 0.3728635907173157\n",
      "\n",
      "episode 4, policy loss 0.22597268223762512\n",
      "\n",
      "episode 5, policy loss 0.27486172318458557\n",
      "\n",
      "episode 6, policy loss 0.18594442307949066\n",
      "\n",
      "episode 7, policy loss 0.24698494374752045\n",
      "\n",
      "episode 8, policy loss 0.19601218402385712\n",
      "\n",
      "episode 9, policy loss 0.36655256152153015\n",
      "\n",
      "episode 10, policy loss 0.414863258600235\n",
      "\n",
      "episode 11, policy loss 0.29125910997390747\n",
      "\n",
      "episode 12, policy loss 0.3912654221057892\n",
      "\n",
      "episode 13, policy loss 0.2809607982635498\n",
      "\n",
      "episode 14, policy loss 0.20954281091690063\n",
      "\n",
      "episode 15, policy loss 0.14929930865764618\n",
      "\n",
      "episode 16, policy loss 0.1720501184463501\n",
      "\n",
      "Policy train loss in epoch 0:0.2717234408482909\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.2808431088924408\n",
      "\n",
      "episode 2, policy loss 0.22765859961509705\n",
      "\n",
      "episode 3, policy loss 0.366784930229187\n",
      "\n",
      "episode 4, policy loss 0.24641485512256622\n",
      "\n",
      "episode 5, policy loss 0.17266960442066193\n",
      "\n",
      "episode 6, policy loss 0.18582512438297272\n",
      "\n",
      "episode 7, policy loss 0.376664400100708\n",
      "\n",
      "episode 8, policy loss 0.29203590750694275\n",
      "\n",
      "episode 9, policy loss 0.27845773100852966\n",
      "\n",
      "episode 10, policy loss 0.21025283634662628\n",
      "\n",
      "episode 11, policy loss 0.19616681337356567\n",
      "\n",
      "episode 12, policy loss 0.21714985370635986\n",
      "\n",
      "episode 13, policy loss 0.41752728819847107\n",
      "\n",
      "episode 14, policy loss 0.3388173580169678\n",
      "\n",
      "episode 15, policy loss 0.14951376616954803\n",
      "\n",
      "episode 16, policy loss 0.39347001910209656\n",
      "\n",
      "Policy train loss in epoch 1:0.27189076226204634\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.24737334251403809\n",
      "\n",
      "episode 2, policy loss 0.41767948865890503\n",
      "\n",
      "episode 3, policy loss 0.17263057827949524\n",
      "\n",
      "episode 4, policy loss 0.2175055295228958\n",
      "\n",
      "episode 5, policy loss 0.22841966152191162\n",
      "\n",
      "episode 6, policy loss 0.2786814272403717\n",
      "\n",
      "episode 7, policy loss 0.3393350839614868\n",
      "\n",
      "episode 8, policy loss 0.18624818325042725\n",
      "\n",
      "episode 9, policy loss 0.3684944808483124\n",
      "\n",
      "episode 10, policy loss 0.3940572440624237\n",
      "\n",
      "episode 11, policy loss 0.196040078997612\n",
      "\n",
      "episode 12, policy loss 0.3785898685455322\n",
      "\n",
      "episode 13, policy loss 0.29124879837036133\n",
      "\n",
      "episode 14, policy loss 0.21055123209953308\n",
      "\n",
      "episode 15, policy loss 0.14905798435211182\n",
      "\n",
      "episode 16, policy loss 0.28150099515914917\n",
      "\n",
      "Policy train loss in epoch 2:0.27233837358653545\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.196100652217865\n",
      "\n",
      "episode 2, policy loss 0.3785252273082733\n",
      "\n",
      "episode 3, policy loss 0.18635877966880798\n",
      "\n",
      "episode 4, policy loss 0.14912152290344238\n",
      "\n",
      "episode 5, policy loss 0.22872546315193176\n",
      "\n",
      "episode 6, policy loss 0.21040859818458557\n",
      "\n",
      "episode 7, policy loss 0.2781652808189392\n",
      "\n",
      "episode 8, policy loss 0.3384777009487152\n",
      "\n",
      "episode 9, policy loss 0.3678840696811676\n",
      "\n",
      "episode 10, policy loss 0.3936011493206024\n",
      "\n",
      "episode 11, policy loss 0.4173431992530823\n",
      "\n",
      "episode 12, policy loss 0.24707575142383575\n",
      "\n",
      "episode 13, policy loss 0.17243430018424988\n",
      "\n",
      "episode 14, policy loss 0.2914644181728363\n",
      "\n",
      "episode 15, policy loss 0.28129857778549194\n",
      "\n",
      "episode 16, policy loss 0.21680983901023865\n",
      "\n",
      "Policy train loss in epoch 3:0.2721121581271291\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.5551363229751587\n",
      "\n",
      "episode 2, val func loss 1.2330905199050903\n",
      "\n",
      "episode 3, val func loss 1.5584986209869385\n",
      "\n",
      "episode 4, val func loss 1.3584108352661133\n",
      "\n",
      "episode 5, val func loss 1.6105204820632935\n",
      "\n",
      "episode 6, val func loss 1.5522260665893555\n",
      "\n",
      "episode 7, val func loss 1.7484188079833984\n",
      "\n",
      "episode 8, val func loss 1.5130821466445923\n",
      "\n",
      "episode 9, val func loss 1.668946385383606\n",
      "\n",
      "episode 10, val func loss 1.7684850692749023\n",
      "\n",
      "episode 11, val func loss 1.6350401639938354\n",
      "\n",
      "episode 12, val func loss 1.7563378810882568\n",
      "\n",
      "episode 13, val func loss 1.4879553318023682\n",
      "\n",
      "episode 14, val func loss 1.3380827903747559\n",
      "\n",
      "episode 15, val func loss 1.5097217559814453\n",
      "\n",
      "episode 16, val func loss 1.5978341102600098\n",
      "\n",
      "Val func train loss in epoch 0:1.55573670566082\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.4893354177474976\n",
      "\n",
      "episode 2, val func loss 1.35056734085083\n",
      "\n",
      "episode 3, val func loss 1.2916922569274902\n",
      "\n",
      "episode 4, val func loss 1.4672693014144897\n",
      "\n",
      "episode 5, val func loss 1.504652500152588\n",
      "\n",
      "episode 6, val func loss 1.5021336078643799\n",
      "\n",
      "episode 7, val func loss 1.8290538787841797\n",
      "\n",
      "episode 8, val func loss 1.6619398593902588\n",
      "\n",
      "episode 9, val func loss 1.70674467086792\n",
      "\n",
      "episode 10, val func loss 1.7184864282608032\n",
      "\n",
      "episode 11, val func loss 1.7920501232147217\n",
      "\n",
      "episode 12, val func loss 1.5414115190505981\n",
      "\n",
      "episode 13, val func loss 1.2783880233764648\n",
      "\n",
      "episode 14, val func loss 1.3816266059875488\n",
      "\n",
      "episode 15, val func loss 1.7898898124694824\n",
      "\n",
      "episode 16, val func loss 1.2959178686141968\n",
      "\n",
      "Val func train loss in epoch 1:1.5375724509358406\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.558422565460205\n",
      "\n",
      "episode 2, val func loss 1.448438048362732\n",
      "\n",
      "episode 3, val func loss 1.2284682989120483\n",
      "\n",
      "episode 4, val func loss 1.5887529850006104\n",
      "\n",
      "episode 5, val func loss 1.374335765838623\n",
      "\n",
      "episode 6, val func loss 1.6169171333312988\n",
      "\n",
      "episode 7, val func loss 1.5709404945373535\n",
      "\n",
      "episode 8, val func loss 1.232412576675415\n",
      "\n",
      "episode 9, val func loss 1.450226902961731\n",
      "\n",
      "episode 10, val func loss 1.4686189889907837\n",
      "\n",
      "episode 11, val func loss 1.3267273902893066\n",
      "\n",
      "episode 12, val func loss 1.1998111009597778\n",
      "\n",
      "episode 13, val func loss 1.6428252458572388\n",
      "\n",
      "episode 14, val func loss 1.737478256225586\n",
      "\n",
      "episode 15, val func loss 1.425351858139038\n",
      "\n",
      "episode 16, val func loss 1.7713279724121094\n",
      "\n",
      "Val func train loss in epoch 2:1.477565973997116\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.1224696636199951\n",
      "\n",
      "episode 2, val func loss 1.6550540924072266\n",
      "\n",
      "episode 3, val func loss 1.5104877948760986\n",
      "\n",
      "episode 4, val func loss 1.9113895893096924\n",
      "\n",
      "episode 5, val func loss 1.4079092741012573\n",
      "\n",
      "episode 6, val func loss 1.502658486366272\n",
      "\n",
      "episode 7, val func loss 1.7294442653656006\n",
      "\n",
      "episode 8, val func loss 1.5575743913650513\n",
      "\n",
      "episode 9, val func loss 1.35100257396698\n",
      "\n",
      "episode 10, val func loss 1.3106046915054321\n",
      "\n",
      "episode 11, val func loss 1.5329679250717163\n",
      "\n",
      "episode 12, val func loss 1.5087851285934448\n",
      "\n",
      "episode 13, val func loss 1.6214299201965332\n",
      "\n",
      "episode 14, val func loss 1.5286245346069336\n",
      "\n",
      "episode 15, val func loss 1.720533013343811\n",
      "\n",
      "episode 16, val func loss 1.7203562259674072\n",
      "\n",
      "Val func train loss in epoch 3:1.5432057231664658\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.6092884540557861\n",
      "\n",
      "episode 2, val func loss 1.235129475593567\n",
      "\n",
      "episode 3, val func loss 1.222601294517517\n",
      "\n",
      "episode 4, val func loss 1.3669002056121826\n",
      "\n",
      "episode 5, val func loss 1.6841316223144531\n",
      "\n",
      "episode 6, val func loss 1.4463067054748535\n",
      "\n",
      "episode 7, val func loss 1.4548382759094238\n",
      "\n",
      "episode 8, val func loss 1.4585908651351929\n",
      "\n",
      "episode 9, val func loss 1.4053608179092407\n",
      "\n",
      "episode 10, val func loss 1.6002625226974487\n",
      "\n",
      "episode 11, val func loss 1.5994185209274292\n",
      "\n",
      "episode 12, val func loss 1.7435983419418335\n",
      "\n",
      "episode 13, val func loss 1.6863514184951782\n",
      "\n",
      "episode 14, val func loss 1.37441086769104\n",
      "\n",
      "episode 15, val func loss 1.673330545425415\n",
      "\n",
      "episode 16, val func loss 1.4795774221420288\n",
      "\n",
      "Val func train loss in epoch 4:1.502506084740162\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.2808338403701782\n",
      "\n",
      "episode 2, val func loss 1.5249027013778687\n",
      "\n",
      "episode 3, val func loss 1.5166900157928467\n",
      "\n",
      "episode 4, val func loss 1.1785931587219238\n",
      "\n",
      "episode 5, val func loss 1.5567736625671387\n",
      "\n",
      "episode 6, val func loss 1.8939704895019531\n",
      "\n",
      "episode 7, val func loss 1.3802236318588257\n",
      "\n",
      "episode 8, val func loss 1.6469700336456299\n",
      "\n",
      "episode 9, val func loss 1.7393746376037598\n",
      "\n",
      "episode 10, val func loss 1.5258537530899048\n",
      "\n",
      "episode 11, val func loss 1.441676139831543\n",
      "\n",
      "episode 12, val func loss 1.985119104385376\n",
      "\n",
      "episode 13, val func loss 1.7390921115875244\n",
      "\n",
      "episode 14, val func loss 1.5129499435424805\n",
      "\n",
      "episode 15, val func loss 1.3646966218948364\n",
      "\n",
      "episode 16, val func loss 1.5820614099502563\n",
      "\n",
      "Val func train loss in epoch 5:1.5543613284826279\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.3343628644943237\n",
      "\n",
      "episode 2, val func loss 1.4899156093597412\n",
      "\n",
      "episode 3, val func loss 1.5658365488052368\n",
      "\n",
      "episode 4, val func loss 1.3598722219467163\n",
      "\n",
      "episode 5, val func loss 1.5090186595916748\n",
      "\n",
      "episode 6, val func loss 1.6767381429672241\n",
      "\n",
      "episode 7, val func loss 1.2536413669586182\n",
      "\n",
      "episode 8, val func loss 1.3742198944091797\n",
      "\n",
      "episode 9, val func loss 1.43618643283844\n",
      "\n",
      "episode 10, val func loss 1.0994369983673096\n",
      "\n",
      "episode 11, val func loss 1.5852460861206055\n",
      "\n",
      "episode 12, val func loss 1.7737447023391724\n",
      "\n",
      "episode 13, val func loss 1.3921736478805542\n",
      "\n",
      "episode 14, val func loss 1.439232587814331\n",
      "\n",
      "episode 15, val func loss 1.321495771408081\n",
      "\n",
      "episode 16, val func loss 1.6056110858917236\n",
      "\n",
      "Val func train loss in epoch 6:1.4510457888245583\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.470654010772705\n",
      "\n",
      "episode 2, val func loss 1.5854856967926025\n",
      "\n",
      "episode 3, val func loss 1.6375423669815063\n",
      "\n",
      "episode 4, val func loss 1.4505025148391724\n",
      "\n",
      "episode 5, val func loss 1.3942201137542725\n",
      "\n",
      "episode 6, val func loss 1.3479504585266113\n",
      "\n",
      "episode 7, val func loss 1.3951619863510132\n",
      "\n",
      "episode 8, val func loss 1.6935945749282837\n",
      "\n",
      "episode 9, val func loss 1.0713576078414917\n",
      "\n",
      "episode 10, val func loss 1.499677300453186\n",
      "\n",
      "episode 11, val func loss 1.8338301181793213\n",
      "\n",
      "episode 12, val func loss 1.8355450630187988\n",
      "\n",
      "episode 13, val func loss 1.4695210456848145\n",
      "\n",
      "episode 14, val func loss 1.3250449895858765\n",
      "\n",
      "episode 15, val func loss 1.358540415763855\n",
      "\n",
      "episode 16, val func loss 1.700290560722351\n",
      "\n",
      "Val func train loss in epoch 7:1.5043074265122414\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.2448571920394897\n",
      "\n",
      "episode 2, val func loss 1.7069592475891113\n",
      "\n",
      "episode 3, val func loss 1.3540757894515991\n",
      "\n",
      "episode 4, val func loss 1.528791069984436\n",
      "\n",
      "episode 5, val func loss 1.2607723474502563\n",
      "\n",
      "episode 6, val func loss 1.3353309631347656\n",
      "\n",
      "episode 7, val func loss 1.780316948890686\n",
      "\n",
      "episode 8, val func loss 1.6784865856170654\n",
      "\n",
      "episode 9, val func loss 1.5638902187347412\n",
      "\n",
      "episode 10, val func loss 1.3188945055007935\n",
      "\n",
      "episode 11, val func loss 1.3988317251205444\n",
      "\n",
      "episode 12, val func loss 2.165771245956421\n",
      "\n",
      "episode 13, val func loss 1.4919610023498535\n",
      "\n",
      "episode 14, val func loss 1.8016645908355713\n",
      "\n",
      "episode 15, val func loss 1.7341749668121338\n",
      "\n",
      "episode 16, val func loss 1.492201566696167\n",
      "\n",
      "Val func train loss in epoch 8:1.5535612478852272\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.407386302947998\n",
      "\n",
      "episode 2, val func loss 1.801186442375183\n",
      "\n",
      "episode 3, val func loss 1.4442393779754639\n",
      "\n",
      "episode 4, val func loss 1.61427640914917\n",
      "\n",
      "episode 5, val func loss 1.230013132095337\n",
      "\n",
      "episode 6, val func loss 1.4850735664367676\n",
      "\n",
      "episode 7, val func loss 1.5400234460830688\n",
      "\n",
      "episode 8, val func loss 1.64422607421875\n",
      "\n",
      "episode 9, val func loss 1.367771863937378\n",
      "\n",
      "episode 10, val func loss 1.576601505279541\n",
      "\n",
      "episode 11, val func loss 1.6593379974365234\n",
      "\n",
      "episode 12, val func loss 1.886351227760315\n",
      "\n",
      "episode 13, val func loss 1.629316806793213\n",
      "\n",
      "episode 14, val func loss 1.8134807348251343\n",
      "\n",
      "episode 15, val func loss 1.5011868476867676\n",
      "\n",
      "episode 16, val func loss 1.357628583908081\n",
      "\n",
      "Val func train loss in epoch 9:1.5598812699317932\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.7373753786087036\n",
      "\n",
      "episode 2, val func loss 1.4083436727523804\n",
      "\n",
      "episode 3, val func loss 1.445651888847351\n",
      "\n",
      "episode 4, val func loss 1.5525566339492798\n",
      "\n",
      "episode 5, val func loss 1.4788686037063599\n",
      "\n",
      "episode 6, val func loss 1.4280339479446411\n",
      "\n",
      "episode 7, val func loss 1.566441297531128\n",
      "\n",
      "episode 8, val func loss 1.5670030117034912\n",
      "\n",
      "episode 9, val func loss 1.425605297088623\n",
      "\n",
      "episode 10, val func loss 1.3664368391036987\n",
      "\n",
      "episode 11, val func loss 1.5344923734664917\n",
      "\n",
      "episode 12, val func loss 1.70506751537323\n",
      "\n",
      "episode 13, val func loss 1.3980212211608887\n",
      "\n",
      "episode 14, val func loss 1.6031955480575562\n",
      "\n",
      "episode 15, val func loss 1.803149700164795\n",
      "\n",
      "episode 16, val func loss 1.7991909980773926\n",
      "\n",
      "Val func train loss in epoch 10:1.5512146204710007\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.7778475284576416\n",
      "\n",
      "episode 2, val func loss 1.6444532871246338\n",
      "\n",
      "episode 3, val func loss 1.6010102033615112\n",
      "\n",
      "episode 4, val func loss 1.3937033414840698\n",
      "\n",
      "episode 5, val func loss 1.3421740531921387\n",
      "\n",
      "episode 6, val func loss 1.578797459602356\n",
      "\n",
      "episode 7, val func loss 1.5073481798171997\n",
      "\n",
      "episode 8, val func loss 1.693494200706482\n",
      "\n",
      "episode 9, val func loss 1.6191511154174805\n",
      "\n",
      "episode 10, val func loss 1.482078194618225\n",
      "\n",
      "episode 11, val func loss 1.7792778015136719\n",
      "\n",
      "episode 12, val func loss 1.699403166770935\n",
      "\n",
      "episode 13, val func loss 1.6478571891784668\n",
      "\n",
      "episode 14, val func loss 1.1282037496566772\n",
      "\n",
      "episode 15, val func loss 1.3718644380569458\n",
      "\n",
      "episode 16, val func loss 1.569133996963501\n",
      "\n",
      "Val func train loss in epoch 11:1.552237369120121\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.5712088346481323\n",
      "\n",
      "episode 2, val func loss 1.5989477634429932\n",
      "\n",
      "episode 3, val func loss 1.5880845785140991\n",
      "\n",
      "episode 4, val func loss 1.8160865306854248\n",
      "\n",
      "episode 5, val func loss 1.3668876886367798\n",
      "\n",
      "episode 6, val func loss 1.1949559450149536\n",
      "\n",
      "episode 7, val func loss 1.565107822418213\n",
      "\n",
      "episode 8, val func loss 1.1482917070388794\n",
      "\n",
      "episode 9, val func loss 1.80726957321167\n",
      "\n",
      "episode 10, val func loss 1.6884160041809082\n",
      "\n",
      "episode 11, val func loss 1.3878579139709473\n",
      "\n",
      "episode 12, val func loss 1.4643279314041138\n",
      "\n",
      "episode 13, val func loss 1.370944857597351\n",
      "\n",
      "episode 14, val func loss 1.7416456937789917\n",
      "\n",
      "episode 15, val func loss 1.7327330112457275\n",
      "\n",
      "episode 16, val func loss 1.5596164464950562\n",
      "\n",
      "Val func train loss in epoch 12:1.537648893892765\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.4253383874893188\n",
      "\n",
      "episode 2, val func loss 1.5650653839111328\n",
      "\n",
      "episode 3, val func loss 1.4900109767913818\n",
      "\n",
      "episode 4, val func loss 1.3863693475723267\n",
      "\n",
      "episode 5, val func loss 1.776358962059021\n",
      "\n",
      "episode 6, val func loss 1.5181300640106201\n",
      "\n",
      "episode 7, val func loss 1.1670392751693726\n",
      "\n",
      "episode 8, val func loss 1.4140381813049316\n",
      "\n",
      "episode 9, val func loss 1.2966190576553345\n",
      "\n",
      "episode 10, val func loss 1.7328962087631226\n",
      "\n",
      "episode 11, val func loss 1.7796493768692017\n",
      "\n",
      "episode 12, val func loss 1.5763837099075317\n",
      "\n",
      "episode 13, val func loss 1.4631472826004028\n",
      "\n",
      "episode 14, val func loss 1.5673564672470093\n",
      "\n",
      "episode 15, val func loss 1.5037024021148682\n",
      "\n",
      "episode 16, val func loss 1.534130573272705\n",
      "\n",
      "Val func train loss in epoch 13:1.5122647285461426\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.592786431312561\n",
      "\n",
      "episode 2, val func loss 1.3266252279281616\n",
      "\n",
      "episode 3, val func loss 1.7746648788452148\n",
      "\n",
      "episode 4, val func loss 1.6513111591339111\n",
      "\n",
      "episode 5, val func loss 1.605012059211731\n",
      "\n",
      "episode 6, val func loss 1.3775135278701782\n",
      "\n",
      "episode 7, val func loss 1.3198285102844238\n",
      "\n",
      "episode 8, val func loss 1.1774383783340454\n",
      "\n",
      "episode 9, val func loss 1.5426914691925049\n",
      "\n",
      "episode 10, val func loss 1.569093108177185\n",
      "\n",
      "episode 11, val func loss 1.3305325508117676\n",
      "\n",
      "episode 12, val func loss 1.739585041999817\n",
      "\n",
      "episode 13, val func loss 1.3729947805404663\n",
      "\n",
      "episode 14, val func loss 1.5103093385696411\n",
      "\n",
      "episode 15, val func loss 1.4883098602294922\n",
      "\n",
      "episode 16, val func loss 1.3539583683013916\n",
      "\n",
      "Val func train loss in epoch 14:1.4832909181714058\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.3455545902252197\n",
      "\n",
      "episode 2, val func loss 1.5319230556488037\n",
      "\n",
      "episode 3, val func loss 1.3868842124938965\n",
      "\n",
      "episode 4, val func loss 1.431946873664856\n",
      "\n",
      "episode 5, val func loss 1.4041141271591187\n",
      "\n",
      "episode 6, val func loss 1.668233036994934\n",
      "\n",
      "episode 7, val func loss 1.621355652809143\n",
      "\n",
      "episode 8, val func loss 1.17194664478302\n",
      "\n",
      "episode 9, val func loss 1.6876202821731567\n",
      "\n",
      "episode 10, val func loss 1.6209216117858887\n",
      "\n",
      "episode 11, val func loss 1.4752832651138306\n",
      "\n",
      "episode 12, val func loss 1.4210903644561768\n",
      "\n",
      "episode 13, val func loss 1.605921745300293\n",
      "\n",
      "episode 14, val func loss 1.7483162879943848\n",
      "\n",
      "episode 15, val func loss 1.8572553396224976\n",
      "\n",
      "episode 16, val func loss 1.3617527484893799\n",
      "\n",
      "Val func train loss in epoch 15:1.5212574899196625\n",
      "***********************TIME WAS 4.890993404388428 min*****************************\n",
      "\n",
      "**********************ROUND 102 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.3142164945602417\n",
      "\n",
      "episode 2, policy loss 1.2991254329681396\n",
      "\n",
      "episode 3, policy loss 1.262089729309082\n",
      "\n",
      "episode 4, policy loss 1.3275095224380493\n",
      "\n",
      "episode 5, policy loss 1.30813467502594\n",
      "\n",
      "episode 6, policy loss 1.33428156375885\n",
      "\n",
      "episode 7, policy loss 1.1309497356414795\n",
      "\n",
      "episode 8, policy loss 1.1999626159667969\n",
      "\n",
      "episode 9, policy loss 1.1470870971679688\n",
      "\n",
      "episode 10, policy loss 1.1413017511367798\n",
      "\n",
      "episode 11, policy loss 1.1724427938461304\n",
      "\n",
      "episode 12, policy loss 1.3623250722885132\n",
      "\n",
      "episode 13, policy loss 1.1095632314682007\n",
      "\n",
      "episode 14, policy loss 1.2586079835891724\n",
      "\n",
      "episode 15, policy loss 1.217915415763855\n",
      "\n",
      "episode 16, policy loss 1.3418281078338623\n",
      "\n",
      "Policy train loss in epoch 0:1.2454588264226913\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.2286126613616943\n",
      "\n",
      "episode 2, policy loss 1.2177865505218506\n",
      "\n",
      "episode 3, policy loss 1.1333513259887695\n",
      "\n",
      "episode 4, policy loss 1.341567873954773\n",
      "\n",
      "episode 5, policy loss 1.1481281518936157\n",
      "\n",
      "episode 6, policy loss 1.2013211250305176\n",
      "\n",
      "episode 7, policy loss 1.313175082206726\n",
      "\n",
      "episode 8, policy loss 1.3130642175674438\n",
      "\n",
      "episode 9, policy loss 1.1412171125411987\n",
      "\n",
      "episode 10, policy loss 1.3347142934799194\n",
      "\n",
      "episode 11, policy loss 1.3365557193756104\n",
      "\n",
      "episode 12, policy loss 1.3605406284332275\n",
      "\n",
      "episode 13, policy loss 1.1704347133636475\n",
      "\n",
      "episode 14, policy loss 1.2560174465179443\n",
      "\n",
      "episode 15, policy loss 1.3101396560668945\n",
      "\n",
      "episode 16, policy loss 1.1054050922393799\n",
      "\n",
      "Policy train loss in epoch 1:1.2445019781589508\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.211872935295105\n",
      "\n",
      "episode 2, policy loss 1.221203327178955\n",
      "\n",
      "episode 3, policy loss 1.3259984254837036\n",
      "\n",
      "episode 4, policy loss 1.4625020027160645\n",
      "\n",
      "episode 5, policy loss 1.1531232595443726\n",
      "\n",
      "episode 6, policy loss 1.2544927597045898\n",
      "\n",
      "episode 7, policy loss 1.1402510404586792\n",
      "\n",
      "episode 8, policy loss 1.3408582210540771\n",
      "\n",
      "episode 9, policy loss 1.1334489583969116\n",
      "\n",
      "episode 10, policy loss 1.1734058856964111\n",
      "\n",
      "episode 11, policy loss 1.314743161201477\n",
      "\n",
      "episode 12, policy loss 1.3151296377182007\n",
      "\n",
      "episode 13, policy loss 1.3641459941864014\n",
      "\n",
      "episode 14, policy loss 1.3156098127365112\n",
      "\n",
      "episode 15, policy loss 1.2031570672988892\n",
      "\n",
      "episode 16, policy loss 1.1111830472946167\n",
      "\n",
      "Policy train loss in epoch 2:1.2525703459978104\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.3158212900161743\n",
      "\n",
      "episode 2, policy loss 1.1500073671340942\n",
      "\n",
      "episode 3, policy loss 1.1438382863998413\n",
      "\n",
      "episode 4, policy loss 1.1746413707733154\n",
      "\n",
      "episode 5, policy loss 1.36470627784729\n",
      "\n",
      "episode 6, policy loss 1.3438003063201904\n",
      "\n",
      "episode 7, policy loss 1.3400932550430298\n",
      "\n",
      "episode 8, policy loss 1.3378230333328247\n",
      "\n",
      "episode 9, policy loss 1.2198196649551392\n",
      "\n",
      "episode 10, policy loss 1.1352713108062744\n",
      "\n",
      "episode 11, policy loss 1.3158605098724365\n",
      "\n",
      "episode 12, policy loss 1.2034919261932373\n",
      "\n",
      "episode 13, policy loss 1.230563998222351\n",
      "\n",
      "episode 14, policy loss 1.1114403009414673\n",
      "\n",
      "episode 15, policy loss 1.31591796875\n",
      "\n",
      "episode 16, policy loss 1.2607951164245605\n",
      "\n",
      "Policy train loss in epoch 3:1.2477432489395142\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.04385244846344\n",
      "\n",
      "episode 2, val func loss 0.9521663784980774\n",
      "\n",
      "episode 3, val func loss 0.9786335825920105\n",
      "\n",
      "episode 4, val func loss 1.1389696598052979\n",
      "\n",
      "episode 5, val func loss 0.8336910605430603\n",
      "\n",
      "episode 6, val func loss 0.9512259364128113\n",
      "\n",
      "episode 7, val func loss 1.1180516481399536\n",
      "\n",
      "episode 8, val func loss 1.0912038087844849\n",
      "\n",
      "episode 9, val func loss 1.168946385383606\n",
      "\n",
      "episode 10, val func loss 0.9248371124267578\n",
      "\n",
      "episode 11, val func loss 0.9728037714958191\n",
      "\n",
      "episode 12, val func loss 1.0358744859695435\n",
      "\n",
      "episode 13, val func loss 0.9223908185958862\n",
      "\n",
      "episode 14, val func loss 0.7881413698196411\n",
      "\n",
      "episode 15, val func loss 0.9799570441246033\n",
      "\n",
      "episode 16, val func loss 1.137355923652649\n",
      "\n",
      "Val func train loss in epoch 0:1.0023813396692276\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8607544302940369\n",
      "\n",
      "episode 2, val func loss 0.803172767162323\n",
      "\n",
      "episode 3, val func loss 0.9646235108375549\n",
      "\n",
      "episode 4, val func loss 0.9014257788658142\n",
      "\n",
      "episode 5, val func loss 1.0933054685592651\n",
      "\n",
      "episode 6, val func loss 0.9879680275917053\n",
      "\n",
      "episode 7, val func loss 1.373099446296692\n",
      "\n",
      "episode 8, val func loss 0.8530580997467041\n",
      "\n",
      "episode 9, val func loss 1.2404345273971558\n",
      "\n",
      "episode 10, val func loss 1.0286636352539062\n",
      "\n",
      "episode 11, val func loss 0.9253202676773071\n",
      "\n",
      "episode 12, val func loss 0.8636577725410461\n",
      "\n",
      "episode 13, val func loss 1.0462347269058228\n",
      "\n",
      "episode 14, val func loss 1.087762475013733\n",
      "\n",
      "episode 15, val func loss 0.9085152745246887\n",
      "\n",
      "episode 16, val func loss 1.1500043869018555\n",
      "\n",
      "Val func train loss in epoch 1:1.0055000372231007\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.2544710636138916\n",
      "\n",
      "episode 2, val func loss 0.7970728278160095\n",
      "\n",
      "episode 3, val func loss 0.9014756083488464\n",
      "\n",
      "episode 4, val func loss 1.2200185060501099\n",
      "\n",
      "episode 5, val func loss 1.0908117294311523\n",
      "\n",
      "episode 6, val func loss 0.8526180386543274\n",
      "\n",
      "episode 7, val func loss 1.0155822038650513\n",
      "\n",
      "episode 8, val func loss 1.0449306964874268\n",
      "\n",
      "episode 9, val func loss 1.130405306816101\n",
      "\n",
      "episode 10, val func loss 0.9920151829719543\n",
      "\n",
      "episode 11, val func loss 1.0758622884750366\n",
      "\n",
      "episode 12, val func loss 0.8850391507148743\n",
      "\n",
      "episode 13, val func loss 0.9142532348632812\n",
      "\n",
      "episode 14, val func loss 0.915340006351471\n",
      "\n",
      "episode 15, val func loss 0.8611156940460205\n",
      "\n",
      "episode 16, val func loss 0.9437017440795898\n",
      "\n",
      "Val func train loss in epoch 2:0.9934195801615715\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8943312168121338\n",
      "\n",
      "episode 2, val func loss 0.8557130694389343\n",
      "\n",
      "episode 3, val func loss 1.0788357257843018\n",
      "\n",
      "episode 4, val func loss 1.0633946657180786\n",
      "\n",
      "episode 5, val func loss 1.173475980758667\n",
      "\n",
      "episode 6, val func loss 1.1088725328445435\n",
      "\n",
      "episode 7, val func loss 1.237816572189331\n",
      "\n",
      "episode 8, val func loss 1.0384817123413086\n",
      "\n",
      "episode 9, val func loss 1.1745164394378662\n",
      "\n",
      "episode 10, val func loss 1.0547086000442505\n",
      "\n",
      "episode 11, val func loss 0.8941113948822021\n",
      "\n",
      "episode 12, val func loss 1.1572104692459106\n",
      "\n",
      "episode 13, val func loss 0.9204412698745728\n",
      "\n",
      "episode 14, val func loss 0.9856090545654297\n",
      "\n",
      "episode 15, val func loss 0.9327284693717957\n",
      "\n",
      "episode 16, val func loss 1.0719225406646729\n",
      "\n",
      "Val func train loss in epoch 3:1.040135607123375\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.9433358311653137\n",
      "\n",
      "episode 2, val func loss 0.9887322187423706\n",
      "\n",
      "episode 3, val func loss 1.2026828527450562\n",
      "\n",
      "episode 4, val func loss 0.8901500105857849\n",
      "\n",
      "episode 5, val func loss 0.8517759442329407\n",
      "\n",
      "episode 6, val func loss 0.8803303241729736\n",
      "\n",
      "episode 7, val func loss 1.0112261772155762\n",
      "\n",
      "episode 8, val func loss 1.0140846967697144\n",
      "\n",
      "episode 9, val func loss 1.0925730466842651\n",
      "\n",
      "episode 10, val func loss 0.7443385124206543\n",
      "\n",
      "episode 11, val func loss 1.2063602209091187\n",
      "\n",
      "episode 12, val func loss 1.063355565071106\n",
      "\n",
      "episode 13, val func loss 1.0506739616394043\n",
      "\n",
      "episode 14, val func loss 0.8118405938148499\n",
      "\n",
      "episode 15, val func loss 1.161429524421692\n",
      "\n",
      "episode 16, val func loss 0.9586455225944519\n",
      "\n",
      "Val func train loss in epoch 4:0.9919709376990795\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.9824844002723694\n",
      "\n",
      "episode 2, val func loss 1.0096553564071655\n",
      "\n",
      "episode 3, val func loss 0.8699634671211243\n",
      "\n",
      "episode 4, val func loss 0.8040902018547058\n",
      "\n",
      "episode 5, val func loss 0.8267619013786316\n",
      "\n",
      "episode 6, val func loss 1.1410990953445435\n",
      "\n",
      "episode 7, val func loss 0.9809618592262268\n",
      "\n",
      "episode 8, val func loss 0.9135404229164124\n",
      "\n",
      "episode 9, val func loss 0.7394364476203918\n",
      "\n",
      "episode 10, val func loss 1.2677600383758545\n",
      "\n",
      "episode 11, val func loss 1.211693286895752\n",
      "\n",
      "episode 12, val func loss 1.2941300868988037\n",
      "\n",
      "episode 13, val func loss 1.150164008140564\n",
      "\n",
      "episode 14, val func loss 1.221778392791748\n",
      "\n",
      "episode 15, val func loss 1.0304360389709473\n",
      "\n",
      "episode 16, val func loss 0.8507100939750671\n",
      "\n",
      "Val func train loss in epoch 5:1.0184165686368942\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.0398234128952026\n",
      "\n",
      "episode 2, val func loss 1.077396035194397\n",
      "\n",
      "episode 3, val func loss 1.2141191959381104\n",
      "\n",
      "episode 4, val func loss 0.9666750431060791\n",
      "\n",
      "episode 5, val func loss 1.156285047531128\n",
      "\n",
      "episode 6, val func loss 1.1374214887619019\n",
      "\n",
      "episode 7, val func loss 1.0506887435913086\n",
      "\n",
      "episode 8, val func loss 1.1783653497695923\n",
      "\n",
      "episode 9, val func loss 0.8572985529899597\n",
      "\n",
      "episode 10, val func loss 0.7870967984199524\n",
      "\n",
      "episode 11, val func loss 1.5334886312484741\n",
      "\n",
      "episode 12, val func loss 0.889004111289978\n",
      "\n",
      "episode 13, val func loss 1.0868204832077026\n",
      "\n",
      "episode 14, val func loss 1.2721322774887085\n",
      "\n",
      "episode 15, val func loss 0.8122316598892212\n",
      "\n",
      "episode 16, val func loss 1.2810918092727661\n",
      "\n",
      "Val func train loss in epoch 6:1.0837461650371552\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.1863287687301636\n",
      "\n",
      "episode 2, val func loss 1.1356737613677979\n",
      "\n",
      "episode 3, val func loss 1.2479417324066162\n",
      "\n",
      "episode 4, val func loss 0.9236732125282288\n",
      "\n",
      "episode 5, val func loss 0.916036069393158\n",
      "\n",
      "episode 6, val func loss 0.9499555230140686\n",
      "\n",
      "episode 7, val func loss 1.0606064796447754\n",
      "\n",
      "episode 8, val func loss 0.9095950126647949\n",
      "\n",
      "episode 9, val func loss 1.0218526124954224\n",
      "\n",
      "episode 10, val func loss 1.1429320573806763\n",
      "\n",
      "episode 11, val func loss 1.1385143995285034\n",
      "\n",
      "episode 12, val func loss 0.8057708740234375\n",
      "\n",
      "episode 13, val func loss 1.1867222785949707\n",
      "\n",
      "episode 14, val func loss 1.1737693548202515\n",
      "\n",
      "episode 15, val func loss 0.9874951243400574\n",
      "\n",
      "episode 16, val func loss 0.7937263250350952\n",
      "\n",
      "Val func train loss in epoch 7:1.036287099123001\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.0314700603485107\n",
      "\n",
      "episode 2, val func loss 1.060805320739746\n",
      "\n",
      "episode 3, val func loss 1.1670154333114624\n",
      "\n",
      "episode 4, val func loss 0.7707506418228149\n",
      "\n",
      "episode 5, val func loss 0.9318554401397705\n",
      "\n",
      "episode 6, val func loss 1.2253332138061523\n",
      "\n",
      "episode 7, val func loss 0.8980932831764221\n",
      "\n",
      "episode 8, val func loss 1.2123409509658813\n",
      "\n",
      "episode 9, val func loss 0.9669823050498962\n",
      "\n",
      "episode 10, val func loss 0.9392048716545105\n",
      "\n",
      "episode 11, val func loss 0.7972801923751831\n",
      "\n",
      "episode 12, val func loss 0.7484225630760193\n",
      "\n",
      "episode 13, val func loss 0.9182273149490356\n",
      "\n",
      "episode 14, val func loss 1.1178950071334839\n",
      "\n",
      "episode 15, val func loss 1.1561017036437988\n",
      "\n",
      "episode 16, val func loss 0.8822411298751831\n",
      "\n",
      "Val func train loss in epoch 8:0.9890012145042419\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8094767928123474\n",
      "\n",
      "episode 2, val func loss 0.9434862732887268\n",
      "\n",
      "episode 3, val func loss 0.862966001033783\n",
      "\n",
      "episode 4, val func loss 0.9847445487976074\n",
      "\n",
      "episode 5, val func loss 0.8244812488555908\n",
      "\n",
      "episode 6, val func loss 1.0382457971572876\n",
      "\n",
      "episode 7, val func loss 1.0417250394821167\n",
      "\n",
      "episode 8, val func loss 0.9154300093650818\n",
      "\n",
      "episode 9, val func loss 1.152977705001831\n",
      "\n",
      "episode 10, val func loss 1.1454521417617798\n",
      "\n",
      "episode 11, val func loss 0.9302976131439209\n",
      "\n",
      "episode 12, val func loss 0.8915354609489441\n",
      "\n",
      "episode 13, val func loss 0.9270498752593994\n",
      "\n",
      "episode 14, val func loss 1.2390273809432983\n",
      "\n",
      "episode 15, val func loss 1.1302647590637207\n",
      "\n",
      "episode 16, val func loss 0.9716341495513916\n",
      "\n",
      "Val func train loss in epoch 9:0.9880496747791767\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.8693894147872925\n",
      "\n",
      "episode 2, val func loss 0.9062705636024475\n",
      "\n",
      "episode 3, val func loss 1.0067325830459595\n",
      "\n",
      "episode 4, val func loss 1.1768447160720825\n",
      "\n",
      "episode 5, val func loss 1.1184192895889282\n",
      "\n",
      "episode 6, val func loss 1.0933518409729004\n",
      "\n",
      "episode 7, val func loss 0.9801031947135925\n",
      "\n",
      "episode 8, val func loss 1.108124017715454\n",
      "\n",
      "episode 9, val func loss 1.0008314847946167\n",
      "\n",
      "episode 10, val func loss 1.0466489791870117\n",
      "\n",
      "episode 11, val func loss 0.8838587403297424\n",
      "\n",
      "episode 12, val func loss 0.857082188129425\n",
      "\n",
      "episode 13, val func loss 1.0476220846176147\n",
      "\n",
      "episode 14, val func loss 0.9683862924575806\n",
      "\n",
      "episode 15, val func loss 0.9254277348518372\n",
      "\n",
      "episode 16, val func loss 1.200714349746704\n",
      "\n",
      "Val func train loss in epoch 10:1.0118629671633244\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.1881959438323975\n",
      "\n",
      "episode 2, val func loss 0.9666253924369812\n",
      "\n",
      "episode 3, val func loss 0.801825761795044\n",
      "\n",
      "episode 4, val func loss 1.0720980167388916\n",
      "\n",
      "episode 5, val func loss 1.138292908668518\n",
      "\n",
      "episode 6, val func loss 1.113955020904541\n",
      "\n",
      "episode 7, val func loss 0.9719446897506714\n",
      "\n",
      "episode 8, val func loss 0.8099384307861328\n",
      "\n",
      "episode 9, val func loss 1.094539761543274\n",
      "\n",
      "episode 10, val func loss 0.9486984610557556\n",
      "\n",
      "episode 11, val func loss 0.7723119258880615\n",
      "\n",
      "episode 12, val func loss 1.1909669637680054\n",
      "\n",
      "episode 13, val func loss 0.9954801201820374\n",
      "\n",
      "episode 14, val func loss 0.87706458568573\n",
      "\n",
      "episode 15, val func loss 1.0659281015396118\n",
      "\n",
      "episode 16, val func loss 0.7285965085029602\n",
      "\n",
      "Val func train loss in epoch 11:0.9835289120674133\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.8124828338623047\n",
      "\n",
      "episode 2, val func loss 1.2204622030258179\n",
      "\n",
      "episode 3, val func loss 1.1021264791488647\n",
      "\n",
      "episode 4, val func loss 1.2138780355453491\n",
      "\n",
      "episode 5, val func loss 0.8653222322463989\n",
      "\n",
      "episode 6, val func loss 1.168701410293579\n",
      "\n",
      "episode 7, val func loss 1.1982181072235107\n",
      "\n",
      "episode 8, val func loss 1.0815622806549072\n",
      "\n",
      "episode 9, val func loss 1.0369952917099\n",
      "\n",
      "episode 10, val func loss 0.9112367630004883\n",
      "\n",
      "episode 11, val func loss 1.11305570602417\n",
      "\n",
      "episode 12, val func loss 1.0024657249450684\n",
      "\n",
      "episode 13, val func loss 0.7439275979995728\n",
      "\n",
      "episode 14, val func loss 0.7880984544754028\n",
      "\n",
      "episode 15, val func loss 0.8278952836990356\n",
      "\n",
      "episode 16, val func loss 1.014797329902649\n",
      "\n",
      "Val func train loss in epoch 12:1.0063266083598137\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.1165854930877686\n",
      "\n",
      "episode 2, val func loss 0.9321712255477905\n",
      "\n",
      "episode 3, val func loss 0.9016299843788147\n",
      "\n",
      "episode 4, val func loss 0.7732265591621399\n",
      "\n",
      "episode 5, val func loss 1.0157818794250488\n",
      "\n",
      "episode 6, val func loss 0.8897658586502075\n",
      "\n",
      "episode 7, val func loss 1.2073845863342285\n",
      "\n",
      "episode 8, val func loss 0.8476934432983398\n",
      "\n",
      "episode 9, val func loss 1.113588809967041\n",
      "\n",
      "episode 10, val func loss 0.9764208197593689\n",
      "\n",
      "episode 11, val func loss 1.2271023988723755\n",
      "\n",
      "episode 12, val func loss 1.1620392799377441\n",
      "\n",
      "episode 13, val func loss 1.0301673412322998\n",
      "\n",
      "episode 14, val func loss 0.8764240741729736\n",
      "\n",
      "episode 15, val func loss 1.1165168285369873\n",
      "\n",
      "episode 16, val func loss 0.969056248664856\n",
      "\n",
      "Val func train loss in epoch 13:1.009722176939249\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.936676025390625\n",
      "\n",
      "episode 2, val func loss 0.8504972457885742\n",
      "\n",
      "episode 3, val func loss 1.1201201677322388\n",
      "\n",
      "episode 4, val func loss 0.9978543519973755\n",
      "\n",
      "episode 5, val func loss 1.212885856628418\n",
      "\n",
      "episode 6, val func loss 0.9723328351974487\n",
      "\n",
      "episode 7, val func loss 1.0682004690170288\n",
      "\n",
      "episode 8, val func loss 1.2429403066635132\n",
      "\n",
      "episode 9, val func loss 1.226249098777771\n",
      "\n",
      "episode 10, val func loss 1.1109617948532104\n",
      "\n",
      "episode 11, val func loss 0.9934742450714111\n",
      "\n",
      "episode 12, val func loss 1.1268194913864136\n",
      "\n",
      "episode 13, val func loss 1.025383472442627\n",
      "\n",
      "episode 14, val func loss 0.8618274331092834\n",
      "\n",
      "episode 15, val func loss 1.1590299606323242\n",
      "\n",
      "episode 16, val func loss 0.8255069851875305\n",
      "\n",
      "Val func train loss in epoch 14:1.045672483742237\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.96052086353302\n",
      "\n",
      "episode 2, val func loss 1.2848082780838013\n",
      "\n",
      "episode 3, val func loss 1.2474830150604248\n",
      "\n",
      "episode 4, val func loss 1.1416417360305786\n",
      "\n",
      "episode 5, val func loss 1.0339281558990479\n",
      "\n",
      "episode 6, val func loss 0.815934419631958\n",
      "\n",
      "episode 7, val func loss 0.8959707617759705\n",
      "\n",
      "episode 8, val func loss 1.136404275894165\n",
      "\n",
      "episode 9, val func loss 0.93658447265625\n",
      "\n",
      "episode 10, val func loss 1.0143729448318481\n",
      "\n",
      "episode 11, val func loss 0.8334662318229675\n",
      "\n",
      "episode 12, val func loss 0.9787703156471252\n",
      "\n",
      "episode 13, val func loss 0.8505920767784119\n",
      "\n",
      "episode 14, val func loss 0.9285635352134705\n",
      "\n",
      "episode 15, val func loss 0.9886252284049988\n",
      "\n",
      "episode 16, val func loss 0.8613010048866272\n",
      "\n",
      "Val func train loss in epoch 15:0.9943104572594166\n",
      "***********************TIME WAS 4.893456939856211 min*****************************\n",
      "\n",
      "**********************ROUND 103 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.8757672905921936\n",
      "\n",
      "episode 2, policy loss 0.8757696747779846\n",
      "\n",
      "episode 3, policy loss 0.8757518529891968\n",
      "\n",
      "episode 4, policy loss 0.875762939453125\n",
      "\n",
      "episode 5, policy loss 0.8757495284080505\n",
      "\n",
      "episode 6, policy loss 0.8757571578025818\n",
      "\n",
      "episode 7, policy loss 0.8757726550102234\n",
      "\n",
      "episode 8, policy loss 0.875766396522522\n",
      "\n",
      "episode 9, policy loss 0.875747799873352\n",
      "\n",
      "episode 10, policy loss 0.9007492065429688\n",
      "\n",
      "episode 11, policy loss 0.8757452964782715\n",
      "\n",
      "episode 12, policy loss 0.8757479786872864\n",
      "\n",
      "episode 13, policy loss 0.8757618069648743\n",
      "\n",
      "episode 14, policy loss 0.8757396936416626\n",
      "\n",
      "episode 15, policy loss 0.875710129737854\n",
      "\n",
      "episode 16, policy loss 0.8757224082946777\n",
      "\n",
      "Policy train loss in epoch 0:0.8773138634860516\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.8757270574569702\n",
      "\n",
      "episode 2, policy loss 0.8757228851318359\n",
      "\n",
      "episode 3, policy loss 0.8757243752479553\n",
      "\n",
      "episode 4, policy loss 0.8757163286209106\n",
      "\n",
      "episode 5, policy loss 0.8757020235061646\n",
      "\n",
      "episode 6, policy loss 0.8756827116012573\n",
      "\n",
      "episode 7, policy loss 0.8756930232048035\n",
      "\n",
      "episode 8, policy loss 0.8757053017616272\n",
      "\n",
      "episode 9, policy loss 0.8756983280181885\n",
      "\n",
      "episode 10, policy loss 0.8756979703903198\n",
      "\n",
      "episode 11, policy loss 0.9182307124137878\n",
      "\n",
      "episode 12, policy loss 0.8757365345954895\n",
      "\n",
      "episode 13, policy loss 0.8757539391517639\n",
      "\n",
      "episode 14, policy loss 0.875783383846283\n",
      "\n",
      "episode 15, policy loss 0.8758103251457214\n",
      "\n",
      "episode 16, policy loss 0.8758379817008972\n",
      "\n",
      "Policy train loss in epoch 1:0.8783889301121235\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.8758509755134583\n",
      "\n",
      "episode 2, policy loss 0.8758601546287537\n",
      "\n",
      "episode 3, policy loss 0.90086430311203\n",
      "\n",
      "episode 4, policy loss 0.8758923411369324\n",
      "\n",
      "episode 5, policy loss 0.8758836388587952\n",
      "\n",
      "episode 6, policy loss 0.8758914470672607\n",
      "\n",
      "episode 7, policy loss 0.8758980631828308\n",
      "\n",
      "episode 8, policy loss 0.8758971691131592\n",
      "\n",
      "episode 9, policy loss 0.8759011626243591\n",
      "\n",
      "episode 10, policy loss 0.8759143352508545\n",
      "\n",
      "episode 11, policy loss 0.8759154677391052\n",
      "\n",
      "episode 12, policy loss 0.875909149646759\n",
      "\n",
      "episode 13, policy loss 0.8759109377861023\n",
      "\n",
      "episode 14, policy loss 0.8759189248085022\n",
      "\n",
      "episode 15, policy loss 0.8759217858314514\n",
      "\n",
      "episode 16, policy loss 0.8759214282035828\n",
      "\n",
      "Policy train loss in epoch 2:0.877459455281496\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.8759214282035828\n",
      "\n",
      "episode 2, policy loss 0.8759276866912842\n",
      "\n",
      "episode 3, policy loss 0.875925600528717\n",
      "\n",
      "episode 4, policy loss 0.8759228587150574\n",
      "\n",
      "episode 5, policy loss 0.8759241104125977\n",
      "\n",
      "episode 6, policy loss 0.8759271502494812\n",
      "\n",
      "episode 7, policy loss 0.8759199976921082\n",
      "\n",
      "episode 8, policy loss 0.8759210109710693\n",
      "\n",
      "episode 9, policy loss 0.9008985161781311\n",
      "\n",
      "episode 10, policy loss 0.8759215474128723\n",
      "\n",
      "episode 11, policy loss 0.8759112358093262\n",
      "\n",
      "episode 12, policy loss 0.8759148716926575\n",
      "\n",
      "episode 13, policy loss 0.8759172558784485\n",
      "\n",
      "episode 14, policy loss 0.8759163022041321\n",
      "\n",
      "episode 15, policy loss 0.875912070274353\n",
      "\n",
      "episode 16, policy loss 0.8759062886238098\n",
      "\n",
      "Policy train loss in epoch 3:0.8774804957211018\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.8628264665603638\n",
      "\n",
      "episode 2, val func loss 0.740483283996582\n",
      "\n",
      "episode 3, val func loss 0.7300319075584412\n",
      "\n",
      "episode 4, val func loss 0.7666828632354736\n",
      "\n",
      "episode 5, val func loss 0.67376309633255\n",
      "\n",
      "episode 6, val func loss 0.746653139591217\n",
      "\n",
      "episode 7, val func loss 0.7643771171569824\n",
      "\n",
      "episode 8, val func loss 0.7966272234916687\n",
      "\n",
      "episode 9, val func loss 0.7451712489128113\n",
      "\n",
      "episode 10, val func loss 0.7519694566726685\n",
      "\n",
      "episode 11, val func loss 0.6295502781867981\n",
      "\n",
      "episode 12, val func loss 0.7409989833831787\n",
      "\n",
      "episode 13, val func loss 0.7849851846694946\n",
      "\n",
      "episode 14, val func loss 0.7637823224067688\n",
      "\n",
      "episode 15, val func loss 0.6733139157295227\n",
      "\n",
      "episode 16, val func loss 0.7137535810470581\n",
      "\n",
      "Val func train loss in epoch 0:0.7428106293082237\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7149579524993896\n",
      "\n",
      "episode 2, val func loss 0.66482013463974\n",
      "\n",
      "episode 3, val func loss 0.7050020098686218\n",
      "\n",
      "episode 4, val func loss 0.7547975778579712\n",
      "\n",
      "episode 5, val func loss 0.6966634392738342\n",
      "\n",
      "episode 6, val func loss 0.7986894249916077\n",
      "\n",
      "episode 7, val func loss 0.7277610898017883\n",
      "\n",
      "episode 8, val func loss 0.7425885796546936\n",
      "\n",
      "episode 9, val func loss 0.7046082615852356\n",
      "\n",
      "episode 10, val func loss 0.7642748355865479\n",
      "\n",
      "episode 11, val func loss 0.7091784477233887\n",
      "\n",
      "episode 12, val func loss 0.6953397393226624\n",
      "\n",
      "episode 13, val func loss 0.7218858599662781\n",
      "\n",
      "episode 14, val func loss 0.8603371381759644\n",
      "\n",
      "episode 15, val func loss 0.8171690106391907\n",
      "\n",
      "episode 16, val func loss 0.8318015336990356\n",
      "\n",
      "Val func train loss in epoch 1:0.7443671897053719\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6292563080787659\n",
      "\n",
      "episode 2, val func loss 0.6914191842079163\n",
      "\n",
      "episode 3, val func loss 0.7525421977043152\n",
      "\n",
      "episode 4, val func loss 0.7716507315635681\n",
      "\n",
      "episode 5, val func loss 0.864504873752594\n",
      "\n",
      "episode 6, val func loss 0.7308232188224792\n",
      "\n",
      "episode 7, val func loss 0.7136417031288147\n",
      "\n",
      "episode 8, val func loss 0.6584987640380859\n",
      "\n",
      "episode 9, val func loss 0.6719262599945068\n",
      "\n",
      "episode 10, val func loss 0.8060548305511475\n",
      "\n",
      "episode 11, val func loss 0.6981486678123474\n",
      "\n",
      "episode 12, val func loss 0.7863914966583252\n",
      "\n",
      "episode 13, val func loss 0.719110906124115\n",
      "\n",
      "episode 14, val func loss 0.6880083680152893\n",
      "\n",
      "episode 15, val func loss 0.7194516658782959\n",
      "\n",
      "episode 16, val func loss 0.6978926658630371\n",
      "\n",
      "Val func train loss in epoch 2:0.7249576151371002\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8364007472991943\n",
      "\n",
      "episode 2, val func loss 0.7412068247795105\n",
      "\n",
      "episode 3, val func loss 0.7339724898338318\n",
      "\n",
      "episode 4, val func loss 0.7299844026565552\n",
      "\n",
      "episode 5, val func loss 0.7169360518455505\n",
      "\n",
      "episode 6, val func loss 0.8089483380317688\n",
      "\n",
      "episode 7, val func loss 0.8396764397621155\n",
      "\n",
      "episode 8, val func loss 0.6226853132247925\n",
      "\n",
      "episode 9, val func loss 0.6672665476799011\n",
      "\n",
      "episode 10, val func loss 0.6409473419189453\n",
      "\n",
      "episode 11, val func loss 0.736851155757904\n",
      "\n",
      "episode 12, val func loss 0.6854813098907471\n",
      "\n",
      "episode 13, val func loss 0.6956853866577148\n",
      "\n",
      "episode 14, val func loss 0.7721933722496033\n",
      "\n",
      "episode 15, val func loss 0.7020941376686096\n",
      "\n",
      "episode 16, val func loss 0.6999502182006836\n",
      "\n",
      "Val func train loss in epoch 3:0.7268925048410892\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6687031984329224\n",
      "\n",
      "episode 2, val func loss 0.7161362171173096\n",
      "\n",
      "episode 3, val func loss 0.7251394391059875\n",
      "\n",
      "episode 4, val func loss 0.7697046399116516\n",
      "\n",
      "episode 5, val func loss 0.7233827114105225\n",
      "\n",
      "episode 6, val func loss 0.8627418875694275\n",
      "\n",
      "episode 7, val func loss 0.7670263648033142\n",
      "\n",
      "episode 8, val func loss 0.6908307671546936\n",
      "\n",
      "episode 9, val func loss 0.7447778582572937\n",
      "\n",
      "episode 10, val func loss 0.6683797836303711\n",
      "\n",
      "episode 11, val func loss 0.7057991027832031\n",
      "\n",
      "episode 12, val func loss 0.8162034153938293\n",
      "\n",
      "episode 13, val func loss 0.7713675498962402\n",
      "\n",
      "episode 14, val func loss 0.7704042792320251\n",
      "\n",
      "episode 15, val func loss 0.7305208444595337\n",
      "\n",
      "episode 16, val func loss 0.7606491446495056\n",
      "\n",
      "Val func train loss in epoch 4:0.7432354502379894\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.841827392578125\n",
      "\n",
      "episode 2, val func loss 0.7086242437362671\n",
      "\n",
      "episode 3, val func loss 0.6924951672554016\n",
      "\n",
      "episode 4, val func loss 0.7319144606590271\n",
      "\n",
      "episode 5, val func loss 0.6942393183708191\n",
      "\n",
      "episode 6, val func loss 0.8065333962440491\n",
      "\n",
      "episode 7, val func loss 0.6251243948936462\n",
      "\n",
      "episode 8, val func loss 0.7649226188659668\n",
      "\n",
      "episode 9, val func loss 0.6993668675422668\n",
      "\n",
      "episode 10, val func loss 0.8751242160797119\n",
      "\n",
      "episode 11, val func loss 0.6942917704582214\n",
      "\n",
      "episode 12, val func loss 0.8952846527099609\n",
      "\n",
      "episode 13, val func loss 0.6464082598686218\n",
      "\n",
      "episode 14, val func loss 0.8662129640579224\n",
      "\n",
      "episode 15, val func loss 0.7780538201332092\n",
      "\n",
      "episode 16, val func loss 0.7975521087646484\n",
      "\n",
      "Val func train loss in epoch 5:0.7573734782636166\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.8666961789131165\n",
      "\n",
      "episode 2, val func loss 0.6746929287910461\n",
      "\n",
      "episode 3, val func loss 0.7216932773590088\n",
      "\n",
      "episode 4, val func loss 0.6763336658477783\n",
      "\n",
      "episode 5, val func loss 0.6962636709213257\n",
      "\n",
      "episode 6, val func loss 0.9196711778640747\n",
      "\n",
      "episode 7, val func loss 0.7215516567230225\n",
      "\n",
      "episode 8, val func loss 1.0877363681793213\n",
      "\n",
      "episode 9, val func loss 0.7392721772193909\n",
      "\n",
      "episode 10, val func loss 0.679043173789978\n",
      "\n",
      "episode 11, val func loss 0.8473439812660217\n",
      "\n",
      "episode 12, val func loss 0.6979022026062012\n",
      "\n",
      "episode 13, val func loss 0.8789294958114624\n",
      "\n",
      "episode 14, val func loss 0.692739725112915\n",
      "\n",
      "episode 15, val func loss 0.9390960335731506\n",
      "\n",
      "episode 16, val func loss 0.8075968027114868\n",
      "\n",
      "Val func train loss in epoch 6:0.7904101572930813\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7291049361228943\n",
      "\n",
      "episode 2, val func loss 0.8775263428688049\n",
      "\n",
      "episode 3, val func loss 0.7805277109146118\n",
      "\n",
      "episode 4, val func loss 0.9075844883918762\n",
      "\n",
      "episode 5, val func loss 0.7349814772605896\n",
      "\n",
      "episode 6, val func loss 0.6487433910369873\n",
      "\n",
      "episode 7, val func loss 0.7810312509536743\n",
      "\n",
      "episode 8, val func loss 0.7344179749488831\n",
      "\n",
      "episode 9, val func loss 0.8437792062759399\n",
      "\n",
      "episode 10, val func loss 0.6740682721138\n",
      "\n",
      "episode 11, val func loss 0.6508936285972595\n",
      "\n",
      "episode 12, val func loss 0.7618187069892883\n",
      "\n",
      "episode 13, val func loss 0.952372133731842\n",
      "\n",
      "episode 14, val func loss 0.8198171854019165\n",
      "\n",
      "episode 15, val func loss 0.649247407913208\n",
      "\n",
      "episode 16, val func loss 0.7082794904708862\n",
      "\n",
      "Val func train loss in epoch 7:0.7658871002495289\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8247267603874207\n",
      "\n",
      "episode 2, val func loss 0.6940047144889832\n",
      "\n",
      "episode 3, val func loss 0.6712604761123657\n",
      "\n",
      "episode 4, val func loss 0.7702407240867615\n",
      "\n",
      "episode 5, val func loss 0.7923859357833862\n",
      "\n",
      "episode 6, val func loss 0.8090896010398865\n",
      "\n",
      "episode 7, val func loss 0.7305256724357605\n",
      "\n",
      "episode 8, val func loss 0.7903079390525818\n",
      "\n",
      "episode 9, val func loss 0.5978236794471741\n",
      "\n",
      "episode 10, val func loss 1.0603042840957642\n",
      "\n",
      "episode 11, val func loss 0.7799936532974243\n",
      "\n",
      "episode 12, val func loss 0.8362979292869568\n",
      "\n",
      "episode 13, val func loss 0.5559306740760803\n",
      "\n",
      "episode 14, val func loss 0.7198945879936218\n",
      "\n",
      "episode 15, val func loss 0.7669833898544312\n",
      "\n",
      "episode 16, val func loss 0.6919171810150146\n",
      "\n",
      "Val func train loss in epoch 8:0.7557304501533508\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6707596182823181\n",
      "\n",
      "episode 2, val func loss 0.6738185882568359\n",
      "\n",
      "episode 3, val func loss 0.7222148180007935\n",
      "\n",
      "episode 4, val func loss 0.7081406712532043\n",
      "\n",
      "episode 5, val func loss 0.743383526802063\n",
      "\n",
      "episode 6, val func loss 0.703512966632843\n",
      "\n",
      "episode 7, val func loss 0.7316105365753174\n",
      "\n",
      "episode 8, val func loss 0.5716363191604614\n",
      "\n",
      "episode 9, val func loss 0.6643601655960083\n",
      "\n",
      "episode 10, val func loss 0.758204460144043\n",
      "\n",
      "episode 11, val func loss 0.7597151398658752\n",
      "\n",
      "episode 12, val func loss 0.7402608394622803\n",
      "\n",
      "episode 13, val func loss 0.6705816388130188\n",
      "\n",
      "episode 14, val func loss 0.8724820017814636\n",
      "\n",
      "episode 15, val func loss 0.811253547668457\n",
      "\n",
      "episode 16, val func loss 0.7199731469154358\n",
      "\n",
      "Val func train loss in epoch 9:0.7201192490756512\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6701100468635559\n",
      "\n",
      "episode 2, val func loss 0.7045541405677795\n",
      "\n",
      "episode 3, val func loss 0.7822284698486328\n",
      "\n",
      "episode 4, val func loss 0.7068563103675842\n",
      "\n",
      "episode 5, val func loss 0.8021278381347656\n",
      "\n",
      "episode 6, val func loss 0.6314743161201477\n",
      "\n",
      "episode 7, val func loss 0.8063026070594788\n",
      "\n",
      "episode 8, val func loss 0.7476206421852112\n",
      "\n",
      "episode 9, val func loss 0.8726149201393127\n",
      "\n",
      "episode 10, val func loss 0.6819846034049988\n",
      "\n",
      "episode 11, val func loss 0.7439454197883606\n",
      "\n",
      "episode 12, val func loss 0.6993884444236755\n",
      "\n",
      "episode 13, val func loss 0.7421256303787231\n",
      "\n",
      "episode 14, val func loss 0.77217036485672\n",
      "\n",
      "episode 15, val func loss 0.7307614088058472\n",
      "\n",
      "episode 16, val func loss 0.6980437636375427\n",
      "\n",
      "Val func train loss in epoch 10:0.737019307911396\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7497290968894958\n",
      "\n",
      "episode 2, val func loss 0.7777088284492493\n",
      "\n",
      "episode 3, val func loss 0.6419174075126648\n",
      "\n",
      "episode 4, val func loss 0.7196596264839172\n",
      "\n",
      "episode 5, val func loss 0.6931962370872498\n",
      "\n",
      "episode 6, val func loss 0.8116200566291809\n",
      "\n",
      "episode 7, val func loss 0.7495254874229431\n",
      "\n",
      "episode 8, val func loss 0.7542311549186707\n",
      "\n",
      "episode 9, val func loss 1.098784327507019\n",
      "\n",
      "episode 10, val func loss 0.7278873920440674\n",
      "\n",
      "episode 11, val func loss 0.7785421013832092\n",
      "\n",
      "episode 12, val func loss 0.8452037572860718\n",
      "\n",
      "episode 13, val func loss 0.7406257390975952\n",
      "\n",
      "episode 14, val func loss 0.7364552021026611\n",
      "\n",
      "episode 15, val func loss 0.7417330741882324\n",
      "\n",
      "episode 16, val func loss 0.8219852447509766\n",
      "\n",
      "Val func train loss in epoch 11:0.7743002958595753\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.847300112247467\n",
      "\n",
      "episode 2, val func loss 0.7660158276557922\n",
      "\n",
      "episode 3, val func loss 0.7020847797393799\n",
      "\n",
      "episode 4, val func loss 0.7483320236206055\n",
      "\n",
      "episode 5, val func loss 0.7409592866897583\n",
      "\n",
      "episode 6, val func loss 0.78057461977005\n",
      "\n",
      "episode 7, val func loss 0.6927143335342407\n",
      "\n",
      "episode 8, val func loss 0.7637608051300049\n",
      "\n",
      "episode 9, val func loss 0.7627701163291931\n",
      "\n",
      "episode 10, val func loss 0.8581134080886841\n",
      "\n",
      "episode 11, val func loss 0.7243272066116333\n",
      "\n",
      "episode 12, val func loss 0.7023897767066956\n",
      "\n",
      "episode 13, val func loss 0.6861276030540466\n",
      "\n",
      "episode 14, val func loss 0.726521372795105\n",
      "\n",
      "episode 15, val func loss 0.7009993195533752\n",
      "\n",
      "episode 16, val func loss 0.7324211597442627\n",
      "\n",
      "Val func train loss in epoch 12:0.7459632344543934\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6722221374511719\n",
      "\n",
      "episode 2, val func loss 0.805976390838623\n",
      "\n",
      "episode 3, val func loss 0.7236067652702332\n",
      "\n",
      "episode 4, val func loss 0.6966848373413086\n",
      "\n",
      "episode 5, val func loss 0.7977913022041321\n",
      "\n",
      "episode 6, val func loss 0.6895149946212769\n",
      "\n",
      "episode 7, val func loss 0.7228219509124756\n",
      "\n",
      "episode 8, val func loss 0.7070143222808838\n",
      "\n",
      "episode 9, val func loss 0.665183424949646\n",
      "\n",
      "episode 10, val func loss 0.7370849251747131\n",
      "\n",
      "episode 11, val func loss 0.6372777819633484\n",
      "\n",
      "episode 12, val func loss 0.8784012198448181\n",
      "\n",
      "episode 13, val func loss 0.6667852401733398\n",
      "\n",
      "episode 14, val func loss 0.7581183314323425\n",
      "\n",
      "episode 15, val func loss 0.7932211756706238\n",
      "\n",
      "episode 16, val func loss 0.8070645928382874\n",
      "\n",
      "Val func train loss in epoch 13:0.7349230870604515\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6599159240722656\n",
      "\n",
      "episode 2, val func loss 0.9585999250411987\n",
      "\n",
      "episode 3, val func loss 0.7560129761695862\n",
      "\n",
      "episode 4, val func loss 0.6651299595832825\n",
      "\n",
      "episode 5, val func loss 0.7745335102081299\n",
      "\n",
      "episode 6, val func loss 0.7274347543716431\n",
      "\n",
      "episode 7, val func loss 0.817388117313385\n",
      "\n",
      "episode 8, val func loss 0.7178462743759155\n",
      "\n",
      "episode 9, val func loss 0.7044236063957214\n",
      "\n",
      "episode 10, val func loss 0.7841055393218994\n",
      "\n",
      "episode 11, val func loss 0.6880003809928894\n",
      "\n",
      "episode 12, val func loss 0.7197068333625793\n",
      "\n",
      "episode 13, val func loss 0.7984620928764343\n",
      "\n",
      "episode 14, val func loss 0.829643189907074\n",
      "\n",
      "episode 15, val func loss 0.6873895525932312\n",
      "\n",
      "episode 16, val func loss 0.6668146252632141\n",
      "\n",
      "Val func train loss in epoch 14:0.7472129538655281\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6674056053161621\n",
      "\n",
      "episode 2, val func loss 0.6424787640571594\n",
      "\n",
      "episode 3, val func loss 0.7387939095497131\n",
      "\n",
      "episode 4, val func loss 0.6372554898262024\n",
      "\n",
      "episode 5, val func loss 0.8222066164016724\n",
      "\n",
      "episode 6, val func loss 0.6486207246780396\n",
      "\n",
      "episode 7, val func loss 0.6962448954582214\n",
      "\n",
      "episode 8, val func loss 0.7555360794067383\n",
      "\n",
      "episode 9, val func loss 0.6731451749801636\n",
      "\n",
      "episode 10, val func loss 0.7754440307617188\n",
      "\n",
      "episode 11, val func loss 0.6865085959434509\n",
      "\n",
      "episode 12, val func loss 0.6084038615226746\n",
      "\n",
      "episode 13, val func loss 0.7153675556182861\n",
      "\n",
      "episode 14, val func loss 0.9260124564170837\n",
      "\n",
      "episode 15, val func loss 0.6603179574012756\n",
      "\n",
      "episode 16, val func loss 0.6164893507957458\n",
      "\n",
      "Val func train loss in epoch 15:0.7043894417583942\n",
      "***********************TIME WAS 4.892878385384877 min*****************************\n",
      "\n",
      "**********************ROUND 104 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.3465238809585571\n",
      "\n",
      "episode 2, policy loss 1.346523404121399\n",
      "\n",
      "episode 3, policy loss 1.3465100526809692\n",
      "\n",
      "episode 4, policy loss 1.346502661705017\n",
      "\n",
      "episode 5, policy loss 1.3465039730072021\n",
      "\n",
      "episode 6, policy loss 1.346510648727417\n",
      "\n",
      "episode 7, policy loss 1.3464990854263306\n",
      "\n",
      "episode 8, policy loss 1.346488356590271\n",
      "\n",
      "episode 9, policy loss 1.346481204032898\n",
      "\n",
      "episode 10, policy loss 1.3464794158935547\n",
      "\n",
      "episode 11, policy loss 1.3464707136154175\n",
      "\n",
      "episode 12, policy loss 1.346472144126892\n",
      "\n",
      "episode 13, policy loss 1.346459984779358\n",
      "\n",
      "episode 14, policy loss 1.3464611768722534\n",
      "\n",
      "episode 15, policy loss 1.346449613571167\n",
      "\n",
      "episode 16, policy loss 1.3464432954788208\n",
      "\n",
      "Policy train loss in epoch 0:1.3464862257242203\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.3464183807373047\n",
      "\n",
      "episode 2, policy loss 1.346418857574463\n",
      "\n",
      "episode 3, policy loss 1.34639310836792\n",
      "\n",
      "episode 4, policy loss 1.34638249874115\n",
      "\n",
      "episode 5, policy loss 1.346379041671753\n",
      "\n",
      "episode 6, policy loss 1.3463643789291382\n",
      "\n",
      "episode 7, policy loss 1.3463134765625\n",
      "\n",
      "episode 8, policy loss 1.3463197946548462\n",
      "\n",
      "episode 9, policy loss 1.346287488937378\n",
      "\n",
      "episode 10, policy loss 1.3462618589401245\n",
      "\n",
      "episode 11, policy loss 1.3462347984313965\n",
      "\n",
      "episode 12, policy loss 1.3462153673171997\n",
      "\n",
      "episode 13, policy loss 1.346143364906311\n",
      "\n",
      "episode 14, policy loss 1.3461532592773438\n",
      "\n",
      "episode 15, policy loss 1.346099615097046\n",
      "\n",
      "episode 16, policy loss 1.3460406064987183\n",
      "\n",
      "Policy train loss in epoch 1:1.346276618540287\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.345975399017334\n",
      "\n",
      "episode 2, policy loss 1.3458799123764038\n",
      "\n",
      "episode 3, policy loss 1.345816731452942\n",
      "\n",
      "episode 4, policy loss 1.3457030057907104\n",
      "\n",
      "episode 5, policy loss 1.3455932140350342\n",
      "\n",
      "episode 6, policy loss 1.345414161682129\n",
      "\n",
      "episode 7, policy loss 1.3451859951019287\n",
      "\n",
      "episode 8, policy loss 1.3448824882507324\n",
      "\n",
      "episode 9, policy loss 1.3445227146148682\n",
      "\n",
      "episode 10, policy loss 1.3439319133758545\n",
      "\n",
      "episode 11, policy loss 1.3430500030517578\n",
      "\n",
      "episode 12, policy loss 1.3417394161224365\n",
      "\n",
      "episode 13, policy loss 1.339576244354248\n",
      "\n",
      "episode 14, policy loss 1.3353112936019897\n",
      "\n",
      "episode 15, policy loss 1.3261717557907104\n",
      "\n",
      "episode 16, policy loss 1.3038301467895508\n",
      "\n",
      "Policy train loss in epoch 2:1.3401615247130394\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.2408372163772583\n",
      "\n",
      "episode 2, policy loss 1.2521007061004639\n",
      "\n",
      "episode 3, policy loss 1.2828068733215332\n",
      "\n",
      "episode 4, policy loss 1.2859193086624146\n",
      "\n",
      "episode 5, policy loss 1.2609432935714722\n",
      "\n",
      "episode 6, policy loss 1.22796630859375\n",
      "\n",
      "episode 7, policy loss 1.239092230796814\n",
      "\n",
      "episode 8, policy loss 1.2548519372940063\n",
      "\n",
      "episode 9, policy loss 1.2401149272918701\n",
      "\n",
      "episode 10, policy loss 1.2195537090301514\n",
      "\n",
      "episode 11, policy loss 1.2272560596466064\n",
      "\n",
      "episode 12, policy loss 1.2375330924987793\n",
      "\n",
      "episode 13, policy loss 1.2380167245864868\n",
      "\n",
      "episode 14, policy loss 1.2290489673614502\n",
      "\n",
      "episode 15, policy loss 1.2167813777923584\n",
      "\n",
      "episode 16, policy loss 1.2334177494049072\n",
      "\n",
      "Policy train loss in epoch 3:1.2428900301456451\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.6924859285354614\n",
      "\n",
      "episode 2, val func loss 0.5624367594718933\n",
      "\n",
      "episode 3, val func loss 0.7632867693901062\n",
      "\n",
      "episode 4, val func loss 0.712125301361084\n",
      "\n",
      "episode 5, val func loss 0.81041020154953\n",
      "\n",
      "episode 6, val func loss 0.6578046679496765\n",
      "\n",
      "episode 7, val func loss 0.9314184188842773\n",
      "\n",
      "episode 8, val func loss 0.7130126953125\n",
      "\n",
      "episode 9, val func loss 0.8184255957603455\n",
      "\n",
      "episode 10, val func loss 0.7352154850959778\n",
      "\n",
      "episode 11, val func loss 0.7143868207931519\n",
      "\n",
      "episode 12, val func loss 0.9113631844520569\n",
      "\n",
      "episode 13, val func loss 0.7388325929641724\n",
      "\n",
      "episode 14, val func loss 0.6949686408042908\n",
      "\n",
      "episode 15, val func loss 0.8239736557006836\n",
      "\n",
      "episode 16, val func loss 0.6817317605018616\n",
      "\n",
      "Val func train loss in epoch 0:0.7476174049079418\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8149543404579163\n",
      "\n",
      "episode 2, val func loss 0.6817423701286316\n",
      "\n",
      "episode 3, val func loss 0.7025724649429321\n",
      "\n",
      "episode 4, val func loss 0.6533272862434387\n",
      "\n",
      "episode 5, val func loss 0.7877169251441956\n",
      "\n",
      "episode 6, val func loss 0.671859085559845\n",
      "\n",
      "episode 7, val func loss 0.656429648399353\n",
      "\n",
      "episode 8, val func loss 0.6846160888671875\n",
      "\n",
      "episode 9, val func loss 0.6592754125595093\n",
      "\n",
      "episode 10, val func loss 0.5950694680213928\n",
      "\n",
      "episode 11, val func loss 0.6684895753860474\n",
      "\n",
      "episode 12, val func loss 0.5866491198539734\n",
      "\n",
      "episode 13, val func loss 0.7010773420333862\n",
      "\n",
      "episode 14, val func loss 0.7115602493286133\n",
      "\n",
      "episode 15, val func loss 0.7941107749938965\n",
      "\n",
      "episode 16, val func loss 0.752784013748169\n",
      "\n",
      "Val func train loss in epoch 1:0.6951396353542805\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7453809380531311\n",
      "\n",
      "episode 2, val func loss 0.6653702855110168\n",
      "\n",
      "episode 3, val func loss 0.7528761029243469\n",
      "\n",
      "episode 4, val func loss 0.7573574781417847\n",
      "\n",
      "episode 5, val func loss 0.7320736050605774\n",
      "\n",
      "episode 6, val func loss 0.7395262718200684\n",
      "\n",
      "episode 7, val func loss 0.7387387156486511\n",
      "\n",
      "episode 8, val func loss 0.6889829635620117\n",
      "\n",
      "episode 9, val func loss 0.732332170009613\n",
      "\n",
      "episode 10, val func loss 0.5879563689231873\n",
      "\n",
      "episode 11, val func loss 0.7513238191604614\n",
      "\n",
      "episode 12, val func loss 0.6956477761268616\n",
      "\n",
      "episode 13, val func loss 0.7285199761390686\n",
      "\n",
      "episode 14, val func loss 0.8133216500282288\n",
      "\n",
      "episode 15, val func loss 0.7411324381828308\n",
      "\n",
      "episode 16, val func loss 0.7126405835151672\n",
      "\n",
      "Val func train loss in epoch 2:0.7239488214254379\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.7237734794616699\n",
      "\n",
      "episode 2, val func loss 0.6830878257751465\n",
      "\n",
      "episode 3, val func loss 0.6879124045372009\n",
      "\n",
      "episode 4, val func loss 0.6802422404289246\n",
      "\n",
      "episode 5, val func loss 0.8402948975563049\n",
      "\n",
      "episode 6, val func loss 0.7412265539169312\n",
      "\n",
      "episode 7, val func loss 0.7821436524391174\n",
      "\n",
      "episode 8, val func loss 0.8264805674552917\n",
      "\n",
      "episode 9, val func loss 0.710105836391449\n",
      "\n",
      "episode 10, val func loss 0.7612841129302979\n",
      "\n",
      "episode 11, val func loss 0.7580785751342773\n",
      "\n",
      "episode 12, val func loss 0.8822497725486755\n",
      "\n",
      "episode 13, val func loss 0.7589094638824463\n",
      "\n",
      "episode 14, val func loss 0.7997695207595825\n",
      "\n",
      "episode 15, val func loss 0.7905281186103821\n",
      "\n",
      "episode 16, val func loss 0.7927774786949158\n",
      "\n",
      "Val func train loss in epoch 3:0.7636790312826633\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6656586527824402\n",
      "\n",
      "episode 2, val func loss 0.7171705365180969\n",
      "\n",
      "episode 3, val func loss 0.7511810660362244\n",
      "\n",
      "episode 4, val func loss 0.6646376848220825\n",
      "\n",
      "episode 5, val func loss 0.6568994522094727\n",
      "\n",
      "episode 6, val func loss 0.6976502537727356\n",
      "\n",
      "episode 7, val func loss 0.6342885494232178\n",
      "\n",
      "episode 8, val func loss 0.6831254959106445\n",
      "\n",
      "episode 9, val func loss 0.7378013730049133\n",
      "\n",
      "episode 10, val func loss 0.6702144742012024\n",
      "\n",
      "episode 11, val func loss 0.8299102783203125\n",
      "\n",
      "episode 12, val func loss 0.667842447757721\n",
      "\n",
      "episode 13, val func loss 0.723499059677124\n",
      "\n",
      "episode 14, val func loss 0.6681167483329773\n",
      "\n",
      "episode 15, val func loss 0.7064653635025024\n",
      "\n",
      "episode 16, val func loss 0.6436738967895508\n",
      "\n",
      "Val func train loss in epoch 4:0.6948834583163261\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7139425277709961\n",
      "\n",
      "episode 2, val func loss 0.6859314441680908\n",
      "\n",
      "episode 3, val func loss 0.6282849907875061\n",
      "\n",
      "episode 4, val func loss 0.7323347926139832\n",
      "\n",
      "episode 5, val func loss 0.7333562970161438\n",
      "\n",
      "episode 6, val func loss 0.6969300508499146\n",
      "\n",
      "episode 7, val func loss 0.670711100101471\n",
      "\n",
      "episode 8, val func loss 0.6825156807899475\n",
      "\n",
      "episode 9, val func loss 0.6619161367416382\n",
      "\n",
      "episode 10, val func loss 0.6435438394546509\n",
      "\n",
      "episode 11, val func loss 0.7075918316841125\n",
      "\n",
      "episode 12, val func loss 0.7053907513618469\n",
      "\n",
      "episode 13, val func loss 0.6834555864334106\n",
      "\n",
      "episode 14, val func loss 0.7123761773109436\n",
      "\n",
      "episode 15, val func loss 0.7334619760513306\n",
      "\n",
      "episode 16, val func loss 0.7420476675033569\n",
      "\n",
      "Val func train loss in epoch 5:0.695861928164959\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7160835266113281\n",
      "\n",
      "episode 2, val func loss 0.7156954407691956\n",
      "\n",
      "episode 3, val func loss 0.6948955655097961\n",
      "\n",
      "episode 4, val func loss 0.7822884321212769\n",
      "\n",
      "episode 5, val func loss 0.5972023606300354\n",
      "\n",
      "episode 6, val func loss 0.6925957798957825\n",
      "\n",
      "episode 7, val func loss 0.7559871077537537\n",
      "\n",
      "episode 8, val func loss 0.7325360178947449\n",
      "\n",
      "episode 9, val func loss 0.7476388812065125\n",
      "\n",
      "episode 10, val func loss 0.7489227056503296\n",
      "\n",
      "episode 11, val func loss 0.6975746154785156\n",
      "\n",
      "episode 12, val func loss 0.7710562944412231\n",
      "\n",
      "episode 13, val func loss 0.7005102038383484\n",
      "\n",
      "episode 14, val func loss 0.6518527269363403\n",
      "\n",
      "episode 15, val func loss 0.7448012232780457\n",
      "\n",
      "episode 16, val func loss 0.6996029615402222\n",
      "\n",
      "Val func train loss in epoch 6:0.7155777402222157\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.8491758704185486\n",
      "\n",
      "episode 2, val func loss 0.7964368462562561\n",
      "\n",
      "episode 3, val func loss 0.6159092783927917\n",
      "\n",
      "episode 4, val func loss 0.6447944045066833\n",
      "\n",
      "episode 5, val func loss 0.7710443735122681\n",
      "\n",
      "episode 6, val func loss 0.7266127467155457\n",
      "\n",
      "episode 7, val func loss 0.7737579345703125\n",
      "\n",
      "episode 8, val func loss 0.7487464547157288\n",
      "\n",
      "episode 9, val func loss 0.7340620160102844\n",
      "\n",
      "episode 10, val func loss 0.7102270126342773\n",
      "\n",
      "episode 11, val func loss 0.7162413597106934\n",
      "\n",
      "episode 12, val func loss 0.6931741833686829\n",
      "\n",
      "episode 13, val func loss 0.7873122096061707\n",
      "\n",
      "episode 14, val func loss 0.6042518615722656\n",
      "\n",
      "episode 15, val func loss 0.697443425655365\n",
      "\n",
      "episode 16, val func loss 0.7210924029350281\n",
      "\n",
      "Val func train loss in epoch 7:0.7243926487863064\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7332494854927063\n",
      "\n",
      "episode 2, val func loss 0.7155357003211975\n",
      "\n",
      "episode 3, val func loss 0.6838103532791138\n",
      "\n",
      "episode 4, val func loss 0.6915028691291809\n",
      "\n",
      "episode 5, val func loss 0.815924882888794\n",
      "\n",
      "episode 6, val func loss 0.7266210317611694\n",
      "\n",
      "episode 7, val func loss 0.7753317356109619\n",
      "\n",
      "episode 8, val func loss 0.6714373826980591\n",
      "\n",
      "episode 9, val func loss 0.5653225779533386\n",
      "\n",
      "episode 10, val func loss 0.7233948111534119\n",
      "\n",
      "episode 11, val func loss 0.7746925354003906\n",
      "\n",
      "episode 12, val func loss 0.6945982575416565\n",
      "\n",
      "episode 13, val func loss 0.7015866041183472\n",
      "\n",
      "episode 14, val func loss 0.6715612411499023\n",
      "\n",
      "episode 15, val func loss 0.6892943978309631\n",
      "\n",
      "episode 16, val func loss 0.6216351389884949\n",
      "\n",
      "Val func train loss in epoch 8:0.7034686878323555\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6352550983428955\n",
      "\n",
      "episode 2, val func loss 0.6504974365234375\n",
      "\n",
      "episode 3, val func loss 0.7453943490982056\n",
      "\n",
      "episode 4, val func loss 0.7021708488464355\n",
      "\n",
      "episode 5, val func loss 0.6643409729003906\n",
      "\n",
      "episode 6, val func loss 0.7070043683052063\n",
      "\n",
      "episode 7, val func loss 0.6892498731613159\n",
      "\n",
      "episode 8, val func loss 0.7434226274490356\n",
      "\n",
      "episode 9, val func loss 0.6614371538162231\n",
      "\n",
      "episode 10, val func loss 0.6155881285667419\n",
      "\n",
      "episode 11, val func loss 0.6758403182029724\n",
      "\n",
      "episode 12, val func loss 0.6783662438392639\n",
      "\n",
      "episode 13, val func loss 0.6483081579208374\n",
      "\n",
      "episode 14, val func loss 0.6410520672798157\n",
      "\n",
      "episode 15, val func loss 0.7339475750923157\n",
      "\n",
      "episode 16, val func loss 0.760768473148346\n",
      "\n",
      "Val func train loss in epoch 9:0.6845402307808399\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7566314339637756\n",
      "\n",
      "episode 2, val func loss 0.6411749720573425\n",
      "\n",
      "episode 3, val func loss 0.6167599558830261\n",
      "\n",
      "episode 4, val func loss 0.7327249050140381\n",
      "\n",
      "episode 5, val func loss 0.760403037071228\n",
      "\n",
      "episode 6, val func loss 0.5679787993431091\n",
      "\n",
      "episode 7, val func loss 0.7324804067611694\n",
      "\n",
      "episode 8, val func loss 0.8763042092323303\n",
      "\n",
      "episode 9, val func loss 0.6403828859329224\n",
      "\n",
      "episode 10, val func loss 0.7439121007919312\n",
      "\n",
      "episode 11, val func loss 0.7098386883735657\n",
      "\n",
      "episode 12, val func loss 0.7534942030906677\n",
      "\n",
      "episode 13, val func loss 0.7630597352981567\n",
      "\n",
      "episode 14, val func loss 0.8036586046218872\n",
      "\n",
      "episode 15, val func loss 0.843008279800415\n",
      "\n",
      "episode 16, val func loss 0.716181218624115\n",
      "\n",
      "Val func train loss in epoch 10:0.72862458974123\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6586187481880188\n",
      "\n",
      "episode 2, val func loss 0.6959071159362793\n",
      "\n",
      "episode 3, val func loss 0.6859811544418335\n",
      "\n",
      "episode 4, val func loss 0.780949056148529\n",
      "\n",
      "episode 5, val func loss 0.7612497210502625\n",
      "\n",
      "episode 6, val func loss 0.7741650342941284\n",
      "\n",
      "episode 7, val func loss 0.8699410557746887\n",
      "\n",
      "episode 8, val func loss 0.8337002992630005\n",
      "\n",
      "episode 9, val func loss 0.7936119437217712\n",
      "\n",
      "episode 10, val func loss 0.8263559937477112\n",
      "\n",
      "episode 11, val func loss 0.8540259599685669\n",
      "\n",
      "episode 12, val func loss 0.7152021527290344\n",
      "\n",
      "episode 13, val func loss 0.8053648471832275\n",
      "\n",
      "episode 14, val func loss 0.8691098690032959\n",
      "\n",
      "episode 15, val func loss 0.7149439454078674\n",
      "\n",
      "episode 16, val func loss 0.7634607553482056\n",
      "\n",
      "Val func train loss in epoch 11:0.7751617282629013\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7598785758018494\n",
      "\n",
      "episode 2, val func loss 0.8818709254264832\n",
      "\n",
      "episode 3, val func loss 0.6820808053016663\n",
      "\n",
      "episode 4, val func loss 0.7181531190872192\n",
      "\n",
      "episode 5, val func loss 0.733206033706665\n",
      "\n",
      "episode 6, val func loss 0.7011914849281311\n",
      "\n",
      "episode 7, val func loss 0.7478877305984497\n",
      "\n",
      "episode 8, val func loss 0.6744008660316467\n",
      "\n",
      "episode 9, val func loss 0.630236029624939\n",
      "\n",
      "episode 10, val func loss 0.7569978833198547\n",
      "\n",
      "episode 11, val func loss 0.7783045768737793\n",
      "\n",
      "episode 12, val func loss 0.6574813723564148\n",
      "\n",
      "episode 13, val func loss 0.7674291729927063\n",
      "\n",
      "episode 14, val func loss 0.7039907574653625\n",
      "\n",
      "episode 15, val func loss 0.7359563112258911\n",
      "\n",
      "episode 16, val func loss 0.6363914012908936\n",
      "\n",
      "Val func train loss in epoch 12:0.722841065376997\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.7200663089752197\n",
      "\n",
      "episode 2, val func loss 0.8022422790527344\n",
      "\n",
      "episode 3, val func loss 0.5901061296463013\n",
      "\n",
      "episode 4, val func loss 0.6969011425971985\n",
      "\n",
      "episode 5, val func loss 0.7288661003112793\n",
      "\n",
      "episode 6, val func loss 0.6873857378959656\n",
      "\n",
      "episode 7, val func loss 0.7108187675476074\n",
      "\n",
      "episode 8, val func loss 0.6237597465515137\n",
      "\n",
      "episode 9, val func loss 0.5704900026321411\n",
      "\n",
      "episode 10, val func loss 0.6849794983863831\n",
      "\n",
      "episode 11, val func loss 0.7058560252189636\n",
      "\n",
      "episode 12, val func loss 0.7423996329307556\n",
      "\n",
      "episode 13, val func loss 0.7281867265701294\n",
      "\n",
      "episode 14, val func loss 0.6880817413330078\n",
      "\n",
      "episode 15, val func loss 0.6451707482337952\n",
      "\n",
      "episode 16, val func loss 0.8126694560050964\n",
      "\n",
      "Val func train loss in epoch 13:0.6961237527430058\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7804272174835205\n",
      "\n",
      "episode 2, val func loss 0.8425182104110718\n",
      "\n",
      "episode 3, val func loss 0.6982976794242859\n",
      "\n",
      "episode 4, val func loss 0.7789177298545837\n",
      "\n",
      "episode 5, val func loss 0.7443167567253113\n",
      "\n",
      "episode 6, val func loss 0.6801803708076477\n",
      "\n",
      "episode 7, val func loss 0.7173845171928406\n",
      "\n",
      "episode 8, val func loss 0.7577418684959412\n",
      "\n",
      "episode 9, val func loss 0.728937566280365\n",
      "\n",
      "episode 10, val func loss 0.693828284740448\n",
      "\n",
      "episode 11, val func loss 0.8885077834129333\n",
      "\n",
      "episode 12, val func loss 0.6910792589187622\n",
      "\n",
      "episode 13, val func loss 0.7231360673904419\n",
      "\n",
      "episode 14, val func loss 0.6967485547065735\n",
      "\n",
      "episode 15, val func loss 0.7430807948112488\n",
      "\n",
      "episode 16, val func loss 0.7710865139961243\n",
      "\n",
      "Val func train loss in epoch 14:0.7460118234157562\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.8939027786254883\n",
      "\n",
      "episode 2, val func loss 0.7108446955680847\n",
      "\n",
      "episode 3, val func loss 0.6895816326141357\n",
      "\n",
      "episode 4, val func loss 0.758840799331665\n",
      "\n",
      "episode 5, val func loss 0.7733520269393921\n",
      "\n",
      "episode 6, val func loss 0.6881659626960754\n",
      "\n",
      "episode 7, val func loss 0.6594836711883545\n",
      "\n",
      "episode 8, val func loss 0.716981828212738\n",
      "\n",
      "episode 9, val func loss 0.7409793138504028\n",
      "\n",
      "episode 10, val func loss 0.680848240852356\n",
      "\n",
      "episode 11, val func loss 0.7020610570907593\n",
      "\n",
      "episode 12, val func loss 0.6925414800643921\n",
      "\n",
      "episode 13, val func loss 0.7087951302528381\n",
      "\n",
      "episode 14, val func loss 0.669844925403595\n",
      "\n",
      "episode 15, val func loss 0.7558332085609436\n",
      "\n",
      "episode 16, val func loss 0.716964066028595\n",
      "\n",
      "Val func train loss in epoch 15:0.7224388010799885\n",
      "***********************TIME WAS 4.89425820906957 min*****************************\n",
      "\n",
      "**********************ROUND 105 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.720302700996399\n",
      "\n",
      "episode 2, policy loss 1.5846434831619263\n",
      "\n",
      "episode 3, policy loss 1.6625075340270996\n",
      "\n",
      "episode 4, policy loss 1.6873793601989746\n",
      "\n",
      "episode 5, policy loss 1.5917434692382812\n",
      "\n",
      "episode 6, policy loss 1.8073936700820923\n",
      "\n",
      "episode 7, policy loss 1.577912449836731\n",
      "\n",
      "episode 8, policy loss 1.5609458684921265\n",
      "\n",
      "episode 9, policy loss 1.6259852647781372\n",
      "\n",
      "episode 10, policy loss 1.6455014944076538\n",
      "\n",
      "episode 11, policy loss 1.5893620252609253\n",
      "\n",
      "episode 12, policy loss 1.582133412361145\n",
      "\n",
      "episode 13, policy loss 1.5988751649856567\n",
      "\n",
      "episode 14, policy loss 1.2393627166748047\n",
      "\n",
      "episode 15, policy loss 1.7339568138122559\n",
      "\n",
      "episode 16, policy loss 1.5330195426940918\n",
      "\n",
      "Policy train loss in epoch 0:1.6088140606880188\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.595979928970337\n",
      "\n",
      "episode 2, policy loss 1.7314656972885132\n",
      "\n",
      "episode 3, policy loss 1.8071017265319824\n",
      "\n",
      "episode 4, policy loss 1.5932750701904297\n",
      "\n",
      "episode 5, policy loss 1.633270025253296\n",
      "\n",
      "episode 6, policy loss 1.6151750087738037\n",
      "\n",
      "episode 7, policy loss 1.6770557165145874\n",
      "\n",
      "episode 8, policy loss 1.5485948324203491\n",
      "\n",
      "episode 9, policy loss 1.4669630527496338\n",
      "\n",
      "episode 10, policy loss 1.5886849164962769\n",
      "\n",
      "episode 11, policy loss 3.5790507793426514\n",
      "\n",
      "episode 12, policy loss 1.6622511148452759\n",
      "\n",
      "episode 13, policy loss 1.61359703540802\n",
      "\n",
      "episode 14, policy loss 1.5260744094848633\n",
      "\n",
      "episode 15, policy loss 1.52354097366333\n",
      "\n",
      "episode 16, policy loss 1.5515390634536743\n",
      "\n",
      "Policy train loss in epoch 1:1.732101209461689\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.7084083557128906\n",
      "\n",
      "episode 2, policy loss 1.515355110168457\n",
      "\n",
      "episode 3, policy loss 1.6105875968933105\n",
      "\n",
      "episode 4, policy loss 1.274056077003479\n",
      "\n",
      "episode 5, policy loss 1.5516331195831299\n",
      "\n",
      "episode 6, policy loss 1.693049669265747\n",
      "\n",
      "episode 7, policy loss 1.6820379495620728\n",
      "\n",
      "episode 8, policy loss 1.5910381078720093\n",
      "\n",
      "episode 9, policy loss 1.6220334768295288\n",
      "\n",
      "episode 10, policy loss 1.722388744354248\n",
      "\n",
      "episode 11, policy loss 1.5843958854675293\n",
      "\n",
      "episode 12, policy loss 1.5710325241088867\n",
      "\n",
      "episode 13, policy loss 1.790576457977295\n",
      "\n",
      "episode 14, policy loss 1.550499677658081\n",
      "\n",
      "episode 15, policy loss 1.5416938066482544\n",
      "\n",
      "episode 16, policy loss 1.592827320098877\n",
      "\n",
      "Policy train loss in epoch 2:1.6001008674502373\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.585524559020996\n",
      "\n",
      "episode 2, policy loss 1.4680564403533936\n",
      "\n",
      "episode 3, policy loss 1.2122576236724854\n",
      "\n",
      "episode 4, policy loss 1.5165947675704956\n",
      "\n",
      "episode 5, policy loss 1.6770061254501343\n",
      "\n",
      "episode 6, policy loss 1.571353793144226\n",
      "\n",
      "episode 7, policy loss 1.538596749305725\n",
      "\n",
      "episode 8, policy loss 1.645599126815796\n",
      "\n",
      "episode 9, policy loss 1.5375967025756836\n",
      "\n",
      "episode 10, policy loss 1.5376514196395874\n",
      "\n",
      "episode 11, policy loss 1.5603666305541992\n",
      "\n",
      "episode 12, policy loss 1.5083861351013184\n",
      "\n",
      "episode 13, policy loss 1.629959225654602\n",
      "\n",
      "episode 14, policy loss 1.767341136932373\n",
      "\n",
      "episode 15, policy loss 1.6800044775009155\n",
      "\n",
      "episode 16, policy loss 1.5200239419937134\n",
      "\n",
      "Policy train loss in epoch 3:1.5597699284553528\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.4646239280700684\n",
      "\n",
      "episode 2, val func loss 2.495065450668335\n",
      "\n",
      "episode 3, val func loss 2.4765377044677734\n",
      "\n",
      "episode 4, val func loss 3.422369956970215\n",
      "\n",
      "episode 5, val func loss 2.32393741607666\n",
      "\n",
      "episode 6, val func loss 2.9564876556396484\n",
      "\n",
      "episode 7, val func loss 2.128890037536621\n",
      "\n",
      "episode 8, val func loss 1.9648998975753784\n",
      "\n",
      "episode 9, val func loss 2.437157154083252\n",
      "\n",
      "episode 10, val func loss 3.0375730991363525\n",
      "\n",
      "episode 11, val func loss 2.864349842071533\n",
      "\n",
      "episode 12, val func loss 2.5012269020080566\n",
      "\n",
      "episode 13, val func loss 3.1059372425079346\n",
      "\n",
      "episode 14, val func loss 1.592201590538025\n",
      "\n",
      "episode 15, val func loss 2.6534454822540283\n",
      "\n",
      "episode 16, val func loss 2.3227288722991943\n",
      "\n",
      "Val func train loss in epoch 0:2.5467145144939423\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.352160692214966\n",
      "\n",
      "episode 2, val func loss 2.6052043437957764\n",
      "\n",
      "episode 3, val func loss 2.704902410507202\n",
      "\n",
      "episode 4, val func loss 2.240788459777832\n",
      "\n",
      "episode 5, val func loss 2.391400098800659\n",
      "\n",
      "episode 6, val func loss 2.8619298934936523\n",
      "\n",
      "episode 7, val func loss 2.5043625831604004\n",
      "\n",
      "episode 8, val func loss 2.0537023544311523\n",
      "\n",
      "episode 9, val func loss 2.618833303451538\n",
      "\n",
      "episode 10, val func loss 2.077287197113037\n",
      "\n",
      "episode 11, val func loss 3.383498191833496\n",
      "\n",
      "episode 12, val func loss 1.8671318292617798\n",
      "\n",
      "episode 13, val func loss 3.526207685470581\n",
      "\n",
      "episode 14, val func loss 2.7163400650024414\n",
      "\n",
      "episode 15, val func loss 2.874160051345825\n",
      "\n",
      "episode 16, val func loss 2.5587973594665527\n",
      "\n",
      "Val func train loss in epoch 1:2.5835441574454308\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.6283726692199707\n",
      "\n",
      "episode 2, val func loss 2.776682138442993\n",
      "\n",
      "episode 3, val func loss 3.1249582767486572\n",
      "\n",
      "episode 4, val func loss 3.4204676151275635\n",
      "\n",
      "episode 5, val func loss 3.05057954788208\n",
      "\n",
      "episode 6, val func loss 2.6507959365844727\n",
      "\n",
      "episode 7, val func loss 2.9016196727752686\n",
      "\n",
      "episode 8, val func loss 2.481667995452881\n",
      "\n",
      "episode 9, val func loss 2.2243316173553467\n",
      "\n",
      "episode 10, val func loss 2.4542737007141113\n",
      "\n",
      "episode 11, val func loss 2.2830862998962402\n",
      "\n",
      "episode 12, val func loss 2.3878254890441895\n",
      "\n",
      "episode 13, val func loss 2.9868359565734863\n",
      "\n",
      "episode 14, val func loss 2.373647928237915\n",
      "\n",
      "episode 15, val func loss 2.9195756912231445\n",
      "\n",
      "episode 16, val func loss 1.8797657489776611\n",
      "\n",
      "Val func train loss in epoch 2:2.659030392765999\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 3.1108829975128174\n",
      "\n",
      "episode 2, val func loss 2.7435264587402344\n",
      "\n",
      "episode 3, val func loss 2.7698593139648438\n",
      "\n",
      "episode 4, val func loss 1.9254591464996338\n",
      "\n",
      "episode 5, val func loss 2.3243002891540527\n",
      "\n",
      "episode 6, val func loss 3.4127423763275146\n",
      "\n",
      "episode 7, val func loss 2.4944136142730713\n",
      "\n",
      "episode 8, val func loss 2.525183916091919\n",
      "\n",
      "episode 9, val func loss 2.3062186241149902\n",
      "\n",
      "episode 10, val func loss 2.8952202796936035\n",
      "\n",
      "episode 11, val func loss 2.13891863822937\n",
      "\n",
      "episode 12, val func loss 2.2390949726104736\n",
      "\n",
      "episode 13, val func loss 2.445878028869629\n",
      "\n",
      "episode 14, val func loss 2.7033851146698\n",
      "\n",
      "episode 15, val func loss 2.5045292377471924\n",
      "\n",
      "episode 16, val func loss 3.3560068607330322\n",
      "\n",
      "Val func train loss in epoch 3:2.618476241827011\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.269294261932373\n",
      "\n",
      "episode 2, val func loss 2.232090473175049\n",
      "\n",
      "episode 3, val func loss 1.5229225158691406\n",
      "\n",
      "episode 4, val func loss 2.5986194610595703\n",
      "\n",
      "episode 5, val func loss 2.4295003414154053\n",
      "\n",
      "episode 6, val func loss 3.0405313968658447\n",
      "\n",
      "episode 7, val func loss 2.4492714405059814\n",
      "\n",
      "episode 8, val func loss 3.4116482734680176\n",
      "\n",
      "episode 9, val func loss 2.6666781902313232\n",
      "\n",
      "episode 10, val func loss 2.572312831878662\n",
      "\n",
      "episode 11, val func loss 3.2156565189361572\n",
      "\n",
      "episode 12, val func loss 2.5958545207977295\n",
      "\n",
      "episode 13, val func loss 2.068683385848999\n",
      "\n",
      "episode 14, val func loss 2.149590253829956\n",
      "\n",
      "episode 15, val func loss 3.0085442066192627\n",
      "\n",
      "episode 16, val func loss 3.070645332336426\n",
      "\n",
      "Val func train loss in epoch 4:2.5813652127981186\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 3.281912088394165\n",
      "\n",
      "episode 2, val func loss 2.607396364212036\n",
      "\n",
      "episode 3, val func loss 2.424675464630127\n",
      "\n",
      "episode 4, val func loss 1.6232569217681885\n",
      "\n",
      "episode 5, val func loss 2.1951684951782227\n",
      "\n",
      "episode 6, val func loss 2.50042986869812\n",
      "\n",
      "episode 7, val func loss 3.1281821727752686\n",
      "\n",
      "episode 8, val func loss 3.0840814113616943\n",
      "\n",
      "episode 9, val func loss 2.6059772968292236\n",
      "\n",
      "episode 10, val func loss 2.5524120330810547\n",
      "\n",
      "episode 11, val func loss 2.4431331157684326\n",
      "\n",
      "episode 12, val func loss 2.8335399627685547\n",
      "\n",
      "episode 13, val func loss 3.7248311042785645\n",
      "\n",
      "episode 14, val func loss 3.087603807449341\n",
      "\n",
      "episode 15, val func loss 2.9295387268066406\n",
      "\n",
      "episode 16, val func loss 2.6073243618011475\n",
      "\n",
      "Val func train loss in epoch 5:2.726841449737549\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.872972249984741\n",
      "\n",
      "episode 2, val func loss 3.2622926235198975\n",
      "\n",
      "episode 3, val func loss 3.215137004852295\n",
      "\n",
      "episode 4, val func loss 2.4350788593292236\n",
      "\n",
      "episode 5, val func loss 2.283442735671997\n",
      "\n",
      "episode 6, val func loss 3.209040403366089\n",
      "\n",
      "episode 7, val func loss 2.362145185470581\n",
      "\n",
      "episode 8, val func loss 2.495450258255005\n",
      "\n",
      "episode 9, val func loss 3.4169318675994873\n",
      "\n",
      "episode 10, val func loss 2.707029342651367\n",
      "\n",
      "episode 11, val func loss 2.3537068367004395\n",
      "\n",
      "episode 12, val func loss 2.1497914791107178\n",
      "\n",
      "episode 13, val func loss 3.3749098777770996\n",
      "\n",
      "episode 14, val func loss 1.650381326675415\n",
      "\n",
      "episode 15, val func loss 2.422140598297119\n",
      "\n",
      "episode 16, val func loss 2.6036064624786377\n",
      "\n",
      "Val func train loss in epoch 6:2.675878569483757\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 2.6728873252868652\n",
      "\n",
      "episode 2, val func loss 2.887805461883545\n",
      "\n",
      "episode 3, val func loss 3.3292980194091797\n",
      "\n",
      "episode 4, val func loss 2.489556312561035\n",
      "\n",
      "episode 5, val func loss 2.0410730838775635\n",
      "\n",
      "episode 6, val func loss 2.3981258869171143\n",
      "\n",
      "episode 7, val func loss 2.913585662841797\n",
      "\n",
      "episode 8, val func loss 2.307717800140381\n",
      "\n",
      "episode 9, val func loss 1.6699341535568237\n",
      "\n",
      "episode 10, val func loss 2.243089437484741\n",
      "\n",
      "episode 11, val func loss 2.528132915496826\n",
      "\n",
      "episode 12, val func loss 2.106017827987671\n",
      "\n",
      "episode 13, val func loss 2.9543991088867188\n",
      "\n",
      "episode 14, val func loss 3.2541027069091797\n",
      "\n",
      "episode 15, val func loss 2.295135974884033\n",
      "\n",
      "episode 16, val func loss 2.4962642192840576\n",
      "\n",
      "Val func train loss in epoch 7:2.5366953685879707\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.4435791969299316\n",
      "\n",
      "episode 2, val func loss 2.0230965614318848\n",
      "\n",
      "episode 3, val func loss 2.6588053703308105\n",
      "\n",
      "episode 4, val func loss 3.998887777328491\n",
      "\n",
      "episode 5, val func loss 2.8863890171051025\n",
      "\n",
      "episode 6, val func loss 2.5665624141693115\n",
      "\n",
      "episode 7, val func loss 2.099400281906128\n",
      "\n",
      "episode 8, val func loss 2.4251227378845215\n",
      "\n",
      "episode 9, val func loss 2.7762343883514404\n",
      "\n",
      "episode 10, val func loss 2.556450843811035\n",
      "\n",
      "episode 11, val func loss 3.4947755336761475\n",
      "\n",
      "episode 12, val func loss 3.0730180740356445\n",
      "\n",
      "episode 13, val func loss 3.05273175239563\n",
      "\n",
      "episode 14, val func loss 2.403620958328247\n",
      "\n",
      "episode 15, val func loss 2.7221574783325195\n",
      "\n",
      "episode 16, val func loss 2.524953842163086\n",
      "\n",
      "Val func train loss in epoch 8:2.7316116392612457\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 2.7722408771514893\n",
      "\n",
      "episode 2, val func loss 2.9898900985717773\n",
      "\n",
      "episode 3, val func loss 3.4756035804748535\n",
      "\n",
      "episode 4, val func loss 2.53639554977417\n",
      "\n",
      "episode 5, val func loss 3.440070390701294\n",
      "\n",
      "episode 6, val func loss 2.474505662918091\n",
      "\n",
      "episode 7, val func loss 1.935537338256836\n",
      "\n",
      "episode 8, val func loss 2.3311901092529297\n",
      "\n",
      "episode 9, val func loss 2.3235154151916504\n",
      "\n",
      "episode 10, val func loss 2.857656478881836\n",
      "\n",
      "episode 11, val func loss 2.7981479167938232\n",
      "\n",
      "episode 12, val func loss 3.1015913486480713\n",
      "\n",
      "episode 13, val func loss 3.0187137126922607\n",
      "\n",
      "episode 14, val func loss 2.7548975944519043\n",
      "\n",
      "episode 15, val func loss 2.516690254211426\n",
      "\n",
      "episode 16, val func loss 2.1502609252929688\n",
      "\n",
      "Val func train loss in epoch 9:2.7173067033290863\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.531036138534546\n",
      "\n",
      "episode 2, val func loss 1.774722933769226\n",
      "\n",
      "episode 3, val func loss 3.690992593765259\n",
      "\n",
      "episode 4, val func loss 2.8173139095306396\n",
      "\n",
      "episode 5, val func loss 2.603991746902466\n",
      "\n",
      "episode 6, val func loss 2.5460116863250732\n",
      "\n",
      "episode 7, val func loss 2.421914577484131\n",
      "\n",
      "episode 8, val func loss 2.6830999851226807\n",
      "\n",
      "episode 9, val func loss 3.4584543704986572\n",
      "\n",
      "episode 10, val func loss 2.9020638465881348\n",
      "\n",
      "episode 11, val func loss 2.4880189895629883\n",
      "\n",
      "episode 12, val func loss 2.214510440826416\n",
      "\n",
      "episode 13, val func loss 2.967670440673828\n",
      "\n",
      "episode 14, val func loss 2.640293598175049\n",
      "\n",
      "episode 15, val func loss 3.165799379348755\n",
      "\n",
      "episode 16, val func loss 2.704561710357666\n",
      "\n",
      "Val func train loss in epoch 10:2.7256535217165947\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 3.0614757537841797\n",
      "\n",
      "episode 2, val func loss 2.8546879291534424\n",
      "\n",
      "episode 3, val func loss 2.8337013721466064\n",
      "\n",
      "episode 4, val func loss 2.5617294311523438\n",
      "\n",
      "episode 5, val func loss 1.8134558200836182\n",
      "\n",
      "episode 6, val func loss 2.797755718231201\n",
      "\n",
      "episode 7, val func loss 3.1457228660583496\n",
      "\n",
      "episode 8, val func loss 2.485020399093628\n",
      "\n",
      "episode 9, val func loss 2.249084949493408\n",
      "\n",
      "episode 10, val func loss 2.2404680252075195\n",
      "\n",
      "episode 11, val func loss 3.177852153778076\n",
      "\n",
      "episode 12, val func loss 2.1511571407318115\n",
      "\n",
      "episode 13, val func loss 3.286190986633301\n",
      "\n",
      "episode 14, val func loss 2.25795841217041\n",
      "\n",
      "episode 15, val func loss 2.7701632976531982\n",
      "\n",
      "episode 16, val func loss 2.5648913383483887\n",
      "\n",
      "Val func train loss in epoch 11:2.6407072246074677\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 2.5380287170410156\n",
      "\n",
      "episode 2, val func loss 2.2790119647979736\n",
      "\n",
      "episode 3, val func loss 3.3509297370910645\n",
      "\n",
      "episode 4, val func loss 3.02067494392395\n",
      "\n",
      "episode 5, val func loss 2.655261278152466\n",
      "\n",
      "episode 6, val func loss 2.3781023025512695\n",
      "\n",
      "episode 7, val func loss 2.3295950889587402\n",
      "\n",
      "episode 8, val func loss 2.5109310150146484\n",
      "\n",
      "episode 9, val func loss 2.0164475440979004\n",
      "\n",
      "episode 10, val func loss 2.6829681396484375\n",
      "\n",
      "episode 11, val func loss 2.379605770111084\n",
      "\n",
      "episode 12, val func loss 3.3682072162628174\n",
      "\n",
      "episode 13, val func loss 1.8973568677902222\n",
      "\n",
      "episode 14, val func loss 2.78473162651062\n",
      "\n",
      "episode 15, val func loss 2.6610989570617676\n",
      "\n",
      "episode 16, val func loss 2.2041971683502197\n",
      "\n",
      "Val func train loss in epoch 12:2.5660717710852623\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 2.8562490940093994\n",
      "\n",
      "episode 2, val func loss 2.6987380981445312\n",
      "\n",
      "episode 3, val func loss 2.312866687774658\n",
      "\n",
      "episode 4, val func loss 2.190136432647705\n",
      "\n",
      "episode 5, val func loss 1.6150096654891968\n",
      "\n",
      "episode 6, val func loss 2.4071366786956787\n",
      "\n",
      "episode 7, val func loss 2.4539642333984375\n",
      "\n",
      "episode 8, val func loss 3.019435167312622\n",
      "\n",
      "episode 9, val func loss 2.857144594192505\n",
      "\n",
      "episode 10, val func loss 2.7332963943481445\n",
      "\n",
      "episode 11, val func loss 2.725461959838867\n",
      "\n",
      "episode 12, val func loss 2.876580238342285\n",
      "\n",
      "episode 13, val func loss 2.3074231147766113\n",
      "\n",
      "episode 14, val func loss 2.602471113204956\n",
      "\n",
      "episode 15, val func loss 2.1628923416137695\n",
      "\n",
      "episode 16, val func loss 3.428666114807129\n",
      "\n",
      "Val func train loss in epoch 13:2.577966995537281\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.4220077991485596\n",
      "\n",
      "episode 2, val func loss 2.7215189933776855\n",
      "\n",
      "episode 3, val func loss 2.9774134159088135\n",
      "\n",
      "episode 4, val func loss 2.4646599292755127\n",
      "\n",
      "episode 5, val func loss 2.687326431274414\n",
      "\n",
      "episode 6, val func loss 3.3164494037628174\n",
      "\n",
      "episode 7, val func loss 2.373224973678589\n",
      "\n",
      "episode 8, val func loss 3.4653871059417725\n",
      "\n",
      "episode 9, val func loss 2.3795764446258545\n",
      "\n",
      "episode 10, val func loss 3.7424283027648926\n",
      "\n",
      "episode 11, val func loss 2.654750108718872\n",
      "\n",
      "episode 12, val func loss 2.227259397506714\n",
      "\n",
      "episode 13, val func loss 2.3971686363220215\n",
      "\n",
      "episode 14, val func loss 1.7781082391738892\n",
      "\n",
      "episode 15, val func loss 2.2800793647766113\n",
      "\n",
      "episode 16, val func loss 2.477857828140259\n",
      "\n",
      "Val func train loss in epoch 14:2.64782602339983\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.596620798110962\n",
      "\n",
      "episode 2, val func loss 1.7188177108764648\n",
      "\n",
      "episode 3, val func loss 2.401033878326416\n",
      "\n",
      "episode 4, val func loss 3.1669909954071045\n",
      "\n",
      "episode 5, val func loss 2.5929155349731445\n",
      "\n",
      "episode 6, val func loss 3.4679505825042725\n",
      "\n",
      "episode 7, val func loss 3.1613824367523193\n",
      "\n",
      "episode 8, val func loss 2.7250595092773438\n",
      "\n",
      "episode 9, val func loss 2.372136116027832\n",
      "\n",
      "episode 10, val func loss 2.079108476638794\n",
      "\n",
      "episode 11, val func loss 2.382831573486328\n",
      "\n",
      "episode 12, val func loss 3.170154094696045\n",
      "\n",
      "episode 13, val func loss 2.320730209350586\n",
      "\n",
      "episode 14, val func loss 2.6180222034454346\n",
      "\n",
      "episode 15, val func loss 2.009544849395752\n",
      "\n",
      "episode 16, val func loss 3.42197322845459\n",
      "\n",
      "Val func train loss in epoch 15:2.637829512357712\n",
      "***********************TIME WAS 4.894196279843649 min*****************************\n",
      "\n",
      "**********************ROUND 106 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.6541672945022583\n",
      "\n",
      "episode 2, policy loss 0.7581092119216919\n",
      "\n",
      "episode 3, policy loss 0.8397513031959534\n",
      "\n",
      "episode 4, policy loss 0.8229339122772217\n",
      "\n",
      "episode 5, policy loss 0.7256891131401062\n",
      "\n",
      "episode 6, policy loss 0.8473540544509888\n",
      "\n",
      "episode 7, policy loss 0.7285135984420776\n",
      "\n",
      "episode 8, policy loss 0.7542077302932739\n",
      "\n",
      "episode 9, policy loss 0.7051857709884644\n",
      "\n",
      "episode 10, policy loss 0.6512123346328735\n",
      "\n",
      "episode 11, policy loss 0.5851354002952576\n",
      "\n",
      "episode 12, policy loss 0.8303423523902893\n",
      "\n",
      "episode 13, policy loss 0.6829783320426941\n",
      "\n",
      "episode 14, policy loss 0.613503634929657\n",
      "\n",
      "episode 15, policy loss 0.6536597013473511\n",
      "\n",
      "episode 16, policy loss 0.7283703684806824\n",
      "\n",
      "Policy train loss in epoch 0:0.7238196320831776\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.6538235545158386\n",
      "\n",
      "episode 2, policy loss 0.8525545001029968\n",
      "\n",
      "episode 3, policy loss 0.7073817849159241\n",
      "\n",
      "episode 4, policy loss 0.8312695622444153\n",
      "\n",
      "episode 5, policy loss 0.7318315505981445\n",
      "\n",
      "episode 6, policy loss 0.6140405535697937\n",
      "\n",
      "episode 7, policy loss 0.831235408782959\n",
      "\n",
      "episode 8, policy loss 0.7326866388320923\n",
      "\n",
      "episode 9, policy loss 0.6525928378105164\n",
      "\n",
      "episode 10, policy loss 0.7615537047386169\n",
      "\n",
      "episode 11, policy loss 0.6835862994194031\n",
      "\n",
      "episode 12, policy loss 0.7280383706092834\n",
      "\n",
      "episode 13, policy loss 0.8505914807319641\n",
      "\n",
      "episode 14, policy loss 0.5863124132156372\n",
      "\n",
      "episode 15, policy loss 0.7558483481407166\n",
      "\n",
      "episode 16, policy loss 0.6575571894645691\n",
      "\n",
      "Policy train loss in epoch 1:0.7269315123558044\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.7555269002914429\n",
      "\n",
      "episode 2, policy loss 0.6528422832489014\n",
      "\n",
      "episode 3, policy loss 0.8515968322753906\n",
      "\n",
      "episode 4, policy loss 0.6576598882675171\n",
      "\n",
      "episode 5, policy loss 0.6510754823684692\n",
      "\n",
      "episode 6, policy loss 0.7595458030700684\n",
      "\n",
      "episode 7, policy loss 0.7053145170211792\n",
      "\n",
      "episode 8, policy loss 0.8291829228401184\n",
      "\n",
      "episode 9, policy loss 0.8288735151290894\n",
      "\n",
      "episode 10, policy loss 0.5834356546401978\n",
      "\n",
      "episode 11, policy loss 0.6793928742408752\n",
      "\n",
      "episode 12, policy loss 0.8471746444702148\n",
      "\n",
      "episode 13, policy loss 0.7390646934509277\n",
      "\n",
      "episode 14, policy loss 0.7236586213111877\n",
      "\n",
      "episode 15, policy loss 0.6078799962997437\n",
      "\n",
      "episode 16, policy loss 0.7257709503173828\n",
      "\n",
      "Policy train loss in epoch 2:0.7248747237026691\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.7221177816390991\n",
      "\n",
      "episode 2, policy loss 0.6509831547737122\n",
      "\n",
      "episode 3, policy loss 0.7253701090812683\n",
      "\n",
      "episode 4, policy loss 0.6459307670593262\n",
      "\n",
      "episode 5, policy loss 0.6015607714653015\n",
      "\n",
      "episode 6, policy loss 0.6412855982780457\n",
      "\n",
      "episode 7, policy loss 0.8179556727409363\n",
      "\n",
      "episode 8, policy loss 0.721321165561676\n",
      "\n",
      "episode 9, policy loss 0.8430988788604736\n",
      "\n",
      "episode 10, policy loss 0.5714284777641296\n",
      "\n",
      "episode 11, policy loss 0.7489968538284302\n",
      "\n",
      "episode 12, policy loss 0.8441948294639587\n",
      "\n",
      "episode 13, policy loss 0.7471279501914978\n",
      "\n",
      "episode 14, policy loss 0.6961063146591187\n",
      "\n",
      "episode 15, policy loss 0.8211988210678101\n",
      "\n",
      "episode 16, policy loss 0.6727569103240967\n",
      "\n",
      "Policy train loss in epoch 3:0.71696462854743\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.1236326694488525\n",
      "\n",
      "episode 2, val func loss 1.9714183807373047\n",
      "\n",
      "episode 3, val func loss 2.333850383758545\n",
      "\n",
      "episode 4, val func loss 2.886302947998047\n",
      "\n",
      "episode 5, val func loss 2.974010467529297\n",
      "\n",
      "episode 6, val func loss 2.3309168815612793\n",
      "\n",
      "episode 7, val func loss 1.6852788925170898\n",
      "\n",
      "episode 8, val func loss 3.091052532196045\n",
      "\n",
      "episode 9, val func loss 2.1426525115966797\n",
      "\n",
      "episode 10, val func loss 2.8833847045898438\n",
      "\n",
      "episode 11, val func loss 1.715676188468933\n",
      "\n",
      "episode 12, val func loss 2.0029053688049316\n",
      "\n",
      "episode 13, val func loss 2.955181360244751\n",
      "\n",
      "episode 14, val func loss 2.761718988418579\n",
      "\n",
      "episode 15, val func loss 2.2537169456481934\n",
      "\n",
      "episode 16, val func loss 2.4875893592834473\n",
      "\n",
      "Val func train loss in epoch 0:2.4124555364251137\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 3.0224928855895996\n",
      "\n",
      "episode 2, val func loss 2.2608611583709717\n",
      "\n",
      "episode 3, val func loss 2.741499185562134\n",
      "\n",
      "episode 4, val func loss 2.33258318901062\n",
      "\n",
      "episode 5, val func loss 2.944504499435425\n",
      "\n",
      "episode 6, val func loss 2.427426338195801\n",
      "\n",
      "episode 7, val func loss 1.8567365407943726\n",
      "\n",
      "episode 8, val func loss 1.9568591117858887\n",
      "\n",
      "episode 9, val func loss 2.2819082736968994\n",
      "\n",
      "episode 10, val func loss 2.910957098007202\n",
      "\n",
      "episode 11, val func loss 2.383509874343872\n",
      "\n",
      "episode 12, val func loss 2.162635564804077\n",
      "\n",
      "episode 13, val func loss 2.23826265335083\n",
      "\n",
      "episode 14, val func loss 1.752004623413086\n",
      "\n",
      "episode 15, val func loss 1.682662010192871\n",
      "\n",
      "episode 16, val func loss 2.1608223915100098\n",
      "\n",
      "Val func train loss in epoch 1:2.3197328373789787\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.423470973968506\n",
      "\n",
      "episode 2, val func loss 2.4337751865386963\n",
      "\n",
      "episode 3, val func loss 2.2484264373779297\n",
      "\n",
      "episode 4, val func loss 2.8782780170440674\n",
      "\n",
      "episode 5, val func loss 2.357982873916626\n",
      "\n",
      "episode 6, val func loss 1.6454755067825317\n",
      "\n",
      "episode 7, val func loss 1.5748493671417236\n",
      "\n",
      "episode 8, val func loss 2.5249664783477783\n",
      "\n",
      "episode 9, val func loss 1.8914984464645386\n",
      "\n",
      "episode 10, val func loss 2.0354199409484863\n",
      "\n",
      "episode 11, val func loss 2.2791976928710938\n",
      "\n",
      "episode 12, val func loss 2.3015189170837402\n",
      "\n",
      "episode 13, val func loss 2.7651071548461914\n",
      "\n",
      "episode 14, val func loss 1.8780776262283325\n",
      "\n",
      "episode 15, val func loss 2.8788950443267822\n",
      "\n",
      "episode 16, val func loss 2.693011999130249\n",
      "\n",
      "Val func train loss in epoch 2:2.3006219789385796\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.80104923248291\n",
      "\n",
      "episode 2, val func loss 1.846972942352295\n",
      "\n",
      "episode 3, val func loss 2.147500991821289\n",
      "\n",
      "episode 4, val func loss 2.0649526119232178\n",
      "\n",
      "episode 5, val func loss 3.060025215148926\n",
      "\n",
      "episode 6, val func loss 2.9406838417053223\n",
      "\n",
      "episode 7, val func loss 2.5857484340667725\n",
      "\n",
      "episode 8, val func loss 1.9755362272262573\n",
      "\n",
      "episode 9, val func loss 2.389432430267334\n",
      "\n",
      "episode 10, val func loss 2.483999013900757\n",
      "\n",
      "episode 11, val func loss 1.9802258014678955\n",
      "\n",
      "episode 12, val func loss 2.5010826587677\n",
      "\n",
      "episode 13, val func loss 2.054419755935669\n",
      "\n",
      "episode 14, val func loss 2.0424530506134033\n",
      "\n",
      "episode 15, val func loss 2.400452136993408\n",
      "\n",
      "episode 16, val func loss 2.4968674182891846\n",
      "\n",
      "Val func train loss in epoch 3:2.3607126101851463\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.23787784576416\n",
      "\n",
      "episode 2, val func loss 1.9489469528198242\n",
      "\n",
      "episode 3, val func loss 2.024489402770996\n",
      "\n",
      "episode 4, val func loss 2.190870761871338\n",
      "\n",
      "episode 5, val func loss 2.139556646347046\n",
      "\n",
      "episode 6, val func loss 2.894141435623169\n",
      "\n",
      "episode 7, val func loss 1.7368049621582031\n",
      "\n",
      "episode 8, val func loss 2.7802658081054688\n",
      "\n",
      "episode 9, val func loss 2.9892849922180176\n",
      "\n",
      "episode 10, val func loss 1.59132719039917\n",
      "\n",
      "episode 11, val func loss 2.7993907928466797\n",
      "\n",
      "episode 12, val func loss 1.882561445236206\n",
      "\n",
      "episode 13, val func loss 2.191972255706787\n",
      "\n",
      "episode 14, val func loss 2.1387555599212646\n",
      "\n",
      "episode 15, val func loss 2.121737241744995\n",
      "\n",
      "episode 16, val func loss 2.3643925189971924\n",
      "\n",
      "Val func train loss in epoch 4:2.2520234882831573\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.6509594917297363\n",
      "\n",
      "episode 2, val func loss 2.129187822341919\n",
      "\n",
      "episode 3, val func loss 2.567333698272705\n",
      "\n",
      "episode 4, val func loss 2.3352530002593994\n",
      "\n",
      "episode 5, val func loss 2.127394676208496\n",
      "\n",
      "episode 6, val func loss 2.52160906791687\n",
      "\n",
      "episode 7, val func loss 3.0431413650512695\n",
      "\n",
      "episode 8, val func loss 2.975743293762207\n",
      "\n",
      "episode 9, val func loss 2.2669832706451416\n",
      "\n",
      "episode 10, val func loss 2.325401782989502\n",
      "\n",
      "episode 11, val func loss 2.8876748085021973\n",
      "\n",
      "episode 12, val func loss 2.5515365600585938\n",
      "\n",
      "episode 13, val func loss 1.70953369140625\n",
      "\n",
      "episode 14, val func loss 2.8341870307922363\n",
      "\n",
      "episode 15, val func loss 2.185208797454834\n",
      "\n",
      "episode 16, val func loss 2.1257426738739014\n",
      "\n",
      "Val func train loss in epoch 5:2.3898056894540787\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.305224895477295\n",
      "\n",
      "episode 2, val func loss 2.4102673530578613\n",
      "\n",
      "episode 3, val func loss 2.3331339359283447\n",
      "\n",
      "episode 4, val func loss 2.1576390266418457\n",
      "\n",
      "episode 5, val func loss 2.869114875793457\n",
      "\n",
      "episode 6, val func loss 1.7326726913452148\n",
      "\n",
      "episode 7, val func loss 1.5781610012054443\n",
      "\n",
      "episode 8, val func loss 3.076521873474121\n",
      "\n",
      "episode 9, val func loss 2.2917511463165283\n",
      "\n",
      "episode 10, val func loss 1.8647011518478394\n",
      "\n",
      "episode 11, val func loss 2.1805155277252197\n",
      "\n",
      "episode 12, val func loss 2.0594568252563477\n",
      "\n",
      "episode 13, val func loss 2.8335046768188477\n",
      "\n",
      "episode 14, val func loss 2.971230983734131\n",
      "\n",
      "episode 15, val func loss 2.0089077949523926\n",
      "\n",
      "episode 16, val func loss 2.2776598930358887\n",
      "\n",
      "Val func train loss in epoch 6:2.3094039782881737\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 2.239945888519287\n",
      "\n",
      "episode 2, val func loss 1.7282658815383911\n",
      "\n",
      "episode 3, val func loss 3.277193307876587\n",
      "\n",
      "episode 4, val func loss 2.2860186100006104\n",
      "\n",
      "episode 5, val func loss 2.240358829498291\n",
      "\n",
      "episode 6, val func loss 1.9133480787277222\n",
      "\n",
      "episode 7, val func loss 2.380963087081909\n",
      "\n",
      "episode 8, val func loss 1.5146290063858032\n",
      "\n",
      "episode 9, val func loss 2.5562405586242676\n",
      "\n",
      "episode 10, val func loss 1.989033579826355\n",
      "\n",
      "episode 11, val func loss 2.619178533554077\n",
      "\n",
      "episode 12, val func loss 2.99678897857666\n",
      "\n",
      "episode 13, val func loss 2.306295871734619\n",
      "\n",
      "episode 14, val func loss 2.130510091781616\n",
      "\n",
      "episode 15, val func loss 3.0702919960021973\n",
      "\n",
      "episode 16, val func loss 2.762058734893799\n",
      "\n",
      "Val func train loss in epoch 7:2.375695064663887\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.2609572410583496\n",
      "\n",
      "episode 2, val func loss 1.9207741022109985\n",
      "\n",
      "episode 3, val func loss 2.4196999073028564\n",
      "\n",
      "episode 4, val func loss 2.255934238433838\n",
      "\n",
      "episode 5, val func loss 2.435335874557495\n",
      "\n",
      "episode 6, val func loss 3.262701988220215\n",
      "\n",
      "episode 7, val func loss 2.175764799118042\n",
      "\n",
      "episode 8, val func loss 2.8181233406066895\n",
      "\n",
      "episode 9, val func loss 2.357196569442749\n",
      "\n",
      "episode 10, val func loss 2.1875391006469727\n",
      "\n",
      "episode 11, val func loss 1.5727585554122925\n",
      "\n",
      "episode 12, val func loss 1.8466883897781372\n",
      "\n",
      "episode 13, val func loss 2.840855836868286\n",
      "\n",
      "episode 14, val func loss 2.9169921875\n",
      "\n",
      "episode 15, val func loss 2.1976115703582764\n",
      "\n",
      "episode 16, val func loss 2.893228769302368\n",
      "\n",
      "Val func train loss in epoch 8:2.397635154426098\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.785244345664978\n",
      "\n",
      "episode 2, val func loss 2.1669301986694336\n",
      "\n",
      "episode 3, val func loss 1.60732901096344\n",
      "\n",
      "episode 4, val func loss 3.043339729309082\n",
      "\n",
      "episode 5, val func loss 2.943326234817505\n",
      "\n",
      "episode 6, val func loss 3.0451011657714844\n",
      "\n",
      "episode 7, val func loss 2.8746347427368164\n",
      "\n",
      "episode 8, val func loss 2.150590419769287\n",
      "\n",
      "episode 9, val func loss 2.4117369651794434\n",
      "\n",
      "episode 10, val func loss 2.744680166244507\n",
      "\n",
      "episode 11, val func loss 3.1090002059936523\n",
      "\n",
      "episode 12, val func loss 2.01727557182312\n",
      "\n",
      "episode 13, val func loss 2.217064380645752\n",
      "\n",
      "episode 14, val func loss 2.4469540119171143\n",
      "\n",
      "episode 15, val func loss 2.1001062393188477\n",
      "\n",
      "episode 16, val func loss 2.465799570083618\n",
      "\n",
      "Val func train loss in epoch 9:2.445569559931755\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.6834490299224854\n",
      "\n",
      "episode 2, val func loss 2.587952136993408\n",
      "\n",
      "episode 3, val func loss 2.1042816638946533\n",
      "\n",
      "episode 4, val func loss 2.3452823162078857\n",
      "\n",
      "episode 5, val func loss 1.8836528062820435\n",
      "\n",
      "episode 6, val func loss 2.80001163482666\n",
      "\n",
      "episode 7, val func loss 2.56650710105896\n",
      "\n",
      "episode 8, val func loss 2.0190482139587402\n",
      "\n",
      "episode 9, val func loss 3.1662960052490234\n",
      "\n",
      "episode 10, val func loss 2.173565626144409\n",
      "\n",
      "episode 11, val func loss 2.5007312297821045\n",
      "\n",
      "episode 12, val func loss 2.810844898223877\n",
      "\n",
      "episode 13, val func loss 2.3547754287719727\n",
      "\n",
      "episode 14, val func loss 2.4074385166168213\n",
      "\n",
      "episode 15, val func loss 2.771012783050537\n",
      "\n",
      "episode 16, val func loss 2.0321059226989746\n",
      "\n",
      "Val func train loss in epoch 10:2.3879347071051598\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 3.0267605781555176\n",
      "\n",
      "episode 2, val func loss 1.975417137145996\n",
      "\n",
      "episode 3, val func loss 1.9810147285461426\n",
      "\n",
      "episode 4, val func loss 2.0123331546783447\n",
      "\n",
      "episode 5, val func loss 1.6046391725540161\n",
      "\n",
      "episode 6, val func loss 1.6284574270248413\n",
      "\n",
      "episode 7, val func loss 3.147152900695801\n",
      "\n",
      "episode 8, val func loss 2.2118167877197266\n",
      "\n",
      "episode 9, val func loss 2.188905954360962\n",
      "\n",
      "episode 10, val func loss 2.354296922683716\n",
      "\n",
      "episode 11, val func loss 2.776928663253784\n",
      "\n",
      "episode 12, val func loss 2.2759087085723877\n",
      "\n",
      "episode 13, val func loss 3.2504498958587646\n",
      "\n",
      "episode 14, val func loss 2.3818984031677246\n",
      "\n",
      "episode 15, val func loss 2.4982144832611084\n",
      "\n",
      "episode 16, val func loss 1.998146414756775\n",
      "\n",
      "Val func train loss in epoch 11:2.3320213332772255\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.5084301233291626\n",
      "\n",
      "episode 2, val func loss 2.270968198776245\n",
      "\n",
      "episode 3, val func loss 2.2304599285125732\n",
      "\n",
      "episode 4, val func loss 2.8845677375793457\n",
      "\n",
      "episode 5, val func loss 2.0675783157348633\n",
      "\n",
      "episode 6, val func loss 2.4623522758483887\n",
      "\n",
      "episode 7, val func loss 2.793107509613037\n",
      "\n",
      "episode 8, val func loss 2.0354249477386475\n",
      "\n",
      "episode 9, val func loss 1.9453023672103882\n",
      "\n",
      "episode 10, val func loss 2.006711483001709\n",
      "\n",
      "episode 11, val func loss 2.141757011413574\n",
      "\n",
      "episode 12, val func loss 2.2138822078704834\n",
      "\n",
      "episode 13, val func loss 2.637740135192871\n",
      "\n",
      "episode 14, val func loss 2.2824623584747314\n",
      "\n",
      "episode 15, val func loss 2.8335671424865723\n",
      "\n",
      "episode 16, val func loss 1.7848392724990845\n",
      "\n",
      "Val func train loss in epoch 12:2.256196938455105\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 2.1803603172302246\n",
      "\n",
      "episode 2, val func loss 1.6199026107788086\n",
      "\n",
      "episode 3, val func loss 3.108356475830078\n",
      "\n",
      "episode 4, val func loss 2.7558252811431885\n",
      "\n",
      "episode 5, val func loss 2.3211982250213623\n",
      "\n",
      "episode 6, val func loss 2.2421646118164062\n",
      "\n",
      "episode 7, val func loss 2.3790528774261475\n",
      "\n",
      "episode 8, val func loss 2.7785043716430664\n",
      "\n",
      "episode 9, val func loss 1.5910927057266235\n",
      "\n",
      "episode 10, val func loss 2.2296595573425293\n",
      "\n",
      "episode 11, val func loss 2.442945718765259\n",
      "\n",
      "episode 12, val func loss 1.9094935655593872\n",
      "\n",
      "episode 13, val func loss 2.703251838684082\n",
      "\n",
      "episode 14, val func loss 2.4930570125579834\n",
      "\n",
      "episode 15, val func loss 2.339404344558716\n",
      "\n",
      "episode 16, val func loss 2.0455949306488037\n",
      "\n",
      "Val func train loss in epoch 13:2.3212415277957916\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.5994848012924194\n",
      "\n",
      "episode 2, val func loss 2.536953926086426\n",
      "\n",
      "episode 3, val func loss 1.9654541015625\n",
      "\n",
      "episode 4, val func loss 1.6801820993423462\n",
      "\n",
      "episode 5, val func loss 2.714820384979248\n",
      "\n",
      "episode 6, val func loss 2.2256662845611572\n",
      "\n",
      "episode 7, val func loss 2.101240873336792\n",
      "\n",
      "episode 8, val func loss 2.0393505096435547\n",
      "\n",
      "episode 9, val func loss 2.2918264865875244\n",
      "\n",
      "episode 10, val func loss 2.747668743133545\n",
      "\n",
      "episode 11, val func loss 2.3245160579681396\n",
      "\n",
      "episode 12, val func loss 2.2720673084259033\n",
      "\n",
      "episode 13, val func loss 2.7609338760375977\n",
      "\n",
      "episode 14, val func loss 1.904990553855896\n",
      "\n",
      "episode 15, val func loss 2.8754024505615234\n",
      "\n",
      "episode 16, val func loss 1.9317224025726318\n",
      "\n",
      "Val func train loss in epoch 14:2.2482675537467003\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.4649996757507324\n",
      "\n",
      "episode 2, val func loss 2.2380778789520264\n",
      "\n",
      "episode 3, val func loss 2.487658739089966\n",
      "\n",
      "episode 4, val func loss 2.213956117630005\n",
      "\n",
      "episode 5, val func loss 2.7183868885040283\n",
      "\n",
      "episode 6, val func loss 1.6000665426254272\n",
      "\n",
      "episode 7, val func loss 2.0916223526000977\n",
      "\n",
      "episode 8, val func loss 3.0416040420532227\n",
      "\n",
      "episode 9, val func loss 1.9842828512191772\n",
      "\n",
      "episode 10, val func loss 1.9741889238357544\n",
      "\n",
      "episode 11, val func loss 2.442060708999634\n",
      "\n",
      "episode 12, val func loss 3.0535507202148438\n",
      "\n",
      "episode 13, val func loss 1.8166567087173462\n",
      "\n",
      "episode 14, val func loss 2.0642964839935303\n",
      "\n",
      "episode 15, val func loss 2.4022483825683594\n",
      "\n",
      "episode 16, val func loss 3.0160324573516846\n",
      "\n",
      "Val func train loss in epoch 15:2.3506055921316147\n",
      "***********************TIME WAS 4.8986860871315 min*****************************\n",
      "\n",
      "**********************ROUND 107 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.8770661354064941\n",
      "\n",
      "episode 2, policy loss 1.049244999885559\n",
      "\n",
      "episode 3, policy loss 0.9023941159248352\n",
      "\n",
      "episode 4, policy loss 0.9642584919929504\n",
      "\n",
      "episode 5, policy loss 0.8895323872566223\n",
      "\n",
      "episode 6, policy loss 0.9659556150436401\n",
      "\n",
      "episode 7, policy loss 0.7714211940765381\n",
      "\n",
      "episode 8, policy loss 0.8499610424041748\n",
      "\n",
      "episode 9, policy loss 0.988271951675415\n",
      "\n",
      "episode 10, policy loss 0.8981322646141052\n",
      "\n",
      "episode 11, policy loss 0.9586687684059143\n",
      "\n",
      "episode 12, policy loss 0.8233435153961182\n",
      "\n",
      "episode 13, policy loss 0.8247523903846741\n",
      "\n",
      "episode 14, policy loss 0.9487481713294983\n",
      "\n",
      "episode 15, policy loss 0.9142650365829468\n",
      "\n",
      "episode 16, policy loss 0.6468512415885925\n",
      "\n",
      "Policy train loss in epoch 0:0.8920542076230049\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.0475677251815796\n",
      "\n",
      "episode 2, policy loss 0.8242948055267334\n",
      "\n",
      "episode 3, policy loss 0.7754095196723938\n",
      "\n",
      "episode 4, policy loss 0.9156550168991089\n",
      "\n",
      "episode 5, policy loss 0.8960390090942383\n",
      "\n",
      "episode 6, policy loss 0.9733509421348572\n",
      "\n",
      "episode 7, policy loss 0.9495837092399597\n",
      "\n",
      "episode 8, policy loss 0.8257387280464172\n",
      "\n",
      "episode 9, policy loss 0.970626175403595\n",
      "\n",
      "episode 10, policy loss 0.6472845077514648\n",
      "\n",
      "episode 11, policy loss 0.9149209260940552\n",
      "\n",
      "episode 12, policy loss 0.9604360461235046\n",
      "\n",
      "episode 13, policy loss 0.8779541850090027\n",
      "\n",
      "episode 14, policy loss 0.9902008771896362\n",
      "\n",
      "episode 15, policy loss 0.8996706008911133\n",
      "\n",
      "episode 16, policy loss 0.8529847860336304\n",
      "\n",
      "Policy train loss in epoch 1:0.8951073475182056\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.8998110890388489\n",
      "\n",
      "episode 2, policy loss 0.8255631923675537\n",
      "\n",
      "episode 3, policy loss 0.8530406355857849\n",
      "\n",
      "episode 4, policy loss 0.973258376121521\n",
      "\n",
      "episode 5, policy loss 0.9494122266769409\n",
      "\n",
      "episode 6, policy loss 0.7754518389701843\n",
      "\n",
      "episode 7, policy loss 1.047675371170044\n",
      "\n",
      "episode 8, policy loss 0.8958439826965332\n",
      "\n",
      "episode 9, policy loss 0.8241933584213257\n",
      "\n",
      "episode 10, policy loss 0.9702037572860718\n",
      "\n",
      "episode 11, policy loss 0.8777124285697937\n",
      "\n",
      "episode 12, policy loss 0.9146041870117188\n",
      "\n",
      "episode 13, policy loss 0.9154083728790283\n",
      "\n",
      "episode 14, policy loss 0.9599399566650391\n",
      "\n",
      "episode 15, policy loss 0.9897546768188477\n",
      "\n",
      "episode 16, policy loss 0.646860659122467\n",
      "\n",
      "Policy train loss in epoch 2:0.8949208818376064\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.6465895175933838\n",
      "\n",
      "episode 2, policy loss 0.9488227963447571\n",
      "\n",
      "episode 3, policy loss 0.9596215486526489\n",
      "\n",
      "episode 4, policy loss 0.9893606901168823\n",
      "\n",
      "episode 5, policy loss 0.8986528515815735\n",
      "\n",
      "episode 6, policy loss 0.8767204880714417\n",
      "\n",
      "episode 7, policy loss 0.9720878601074219\n",
      "\n",
      "episode 8, policy loss 0.9137046933174133\n",
      "\n",
      "episode 9, policy loss 0.8946373462677002\n",
      "\n",
      "episode 10, policy loss 0.7739248871803284\n",
      "\n",
      "episode 11, policy loss 0.8225659728050232\n",
      "\n",
      "episode 12, policy loss 0.9686505794525146\n",
      "\n",
      "episode 13, policy loss 0.9136739373207092\n",
      "\n",
      "episode 14, policy loss 1.0455836057662964\n",
      "\n",
      "episode 15, policy loss 0.8501954078674316\n",
      "\n",
      "episode 16, policy loss 0.8227372169494629\n",
      "\n",
      "Policy train loss in epoch 3:0.8935955874621868\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.5064756870269775\n",
      "\n",
      "episode 2, val func loss 1.6740305423736572\n",
      "\n",
      "episode 3, val func loss 1.1476465463638306\n",
      "\n",
      "episode 4, val func loss 2.280573606491089\n",
      "\n",
      "episode 5, val func loss 1.9880471229553223\n",
      "\n",
      "episode 6, val func loss 1.1030776500701904\n",
      "\n",
      "episode 7, val func loss 1.2762924432754517\n",
      "\n",
      "episode 8, val func loss 1.711762547492981\n",
      "\n",
      "episode 9, val func loss 2.412696599960327\n",
      "\n",
      "episode 10, val func loss 1.0226298570632935\n",
      "\n",
      "episode 11, val func loss 2.349879026412964\n",
      "\n",
      "episode 12, val func loss 1.972413182258606\n",
      "\n",
      "episode 13, val func loss 1.902998924255371\n",
      "\n",
      "episode 14, val func loss 1.9011797904968262\n",
      "\n",
      "episode 15, val func loss 1.8816765546798706\n",
      "\n",
      "episode 16, val func loss 1.6064175367355347\n",
      "\n",
      "Val func train loss in epoch 0:1.7336123511195183\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.13231360912323\n",
      "\n",
      "episode 2, val func loss 1.2677993774414062\n",
      "\n",
      "episode 3, val func loss 1.649863839149475\n",
      "\n",
      "episode 4, val func loss 0.98790442943573\n",
      "\n",
      "episode 5, val func loss 1.9559459686279297\n",
      "\n",
      "episode 6, val func loss 1.9492796659469604\n",
      "\n",
      "episode 7, val func loss 1.833875298500061\n",
      "\n",
      "episode 8, val func loss 1.2857393026351929\n",
      "\n",
      "episode 9, val func loss 2.021141767501831\n",
      "\n",
      "episode 10, val func loss 1.8709211349487305\n",
      "\n",
      "episode 11, val func loss 1.8100923299789429\n",
      "\n",
      "episode 12, val func loss 1.5540142059326172\n",
      "\n",
      "episode 13, val func loss 2.3114545345306396\n",
      "\n",
      "episode 14, val func loss 1.4055663347244263\n",
      "\n",
      "episode 15, val func loss 2.011439085006714\n",
      "\n",
      "episode 16, val func loss 1.8923771381378174\n",
      "\n",
      "Val func train loss in epoch 1:1.6837330013513565\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.0971049070358276\n",
      "\n",
      "episode 2, val func loss 1.91422438621521\n",
      "\n",
      "episode 3, val func loss 1.636047601699829\n",
      "\n",
      "episode 4, val func loss 2.003619909286499\n",
      "\n",
      "episode 5, val func loss 1.038460612297058\n",
      "\n",
      "episode 6, val func loss 1.4544392824172974\n",
      "\n",
      "episode 7, val func loss 2.42854905128479\n",
      "\n",
      "episode 8, val func loss 1.9389965534210205\n",
      "\n",
      "episode 9, val func loss 1.7533022165298462\n",
      "\n",
      "episode 10, val func loss 1.9930384159088135\n",
      "\n",
      "episode 11, val func loss 1.887894868850708\n",
      "\n",
      "episode 12, val func loss 2.202575206756592\n",
      "\n",
      "episode 13, val func loss 1.8499014377593994\n",
      "\n",
      "episode 14, val func loss 1.2841049432754517\n",
      "\n",
      "episode 15, val func loss 1.2928690910339355\n",
      "\n",
      "episode 16, val func loss 1.1760127544403076\n",
      "\n",
      "Val func train loss in epoch 2:1.6844463273882866\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.4755240678787231\n",
      "\n",
      "episode 2, val func loss 1.1442840099334717\n",
      "\n",
      "episode 3, val func loss 2.2806406021118164\n",
      "\n",
      "episode 4, val func loss 1.0708835124969482\n",
      "\n",
      "episode 5, val func loss 1.44417142868042\n",
      "\n",
      "episode 6, val func loss 1.9783756732940674\n",
      "\n",
      "episode 7, val func loss 1.8207379579544067\n",
      "\n",
      "episode 8, val func loss 1.9908705949783325\n",
      "\n",
      "episode 9, val func loss 1.5222022533416748\n",
      "\n",
      "episode 10, val func loss 1.8260078430175781\n",
      "\n",
      "episode 11, val func loss 1.5593245029449463\n",
      "\n",
      "episode 12, val func loss 1.1316472291946411\n",
      "\n",
      "episode 13, val func loss 1.9592822790145874\n",
      "\n",
      "episode 14, val func loss 2.0370609760284424\n",
      "\n",
      "episode 15, val func loss 1.84256911277771\n",
      "\n",
      "episode 16, val func loss 1.661655068397522\n",
      "\n",
      "Val func train loss in epoch 3:1.6715773195028305\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.2692906856536865\n",
      "\n",
      "episode 2, val func loss 1.1047029495239258\n",
      "\n",
      "episode 3, val func loss 1.50822913646698\n",
      "\n",
      "episode 4, val func loss 1.138633131980896\n",
      "\n",
      "episode 5, val func loss 2.0238137245178223\n",
      "\n",
      "episode 6, val func loss 1.6151618957519531\n",
      "\n",
      "episode 7, val func loss 2.4225616455078125\n",
      "\n",
      "episode 8, val func loss 1.637916922569275\n",
      "\n",
      "episode 9, val func loss 1.2137912511825562\n",
      "\n",
      "episode 10, val func loss 1.5762920379638672\n",
      "\n",
      "episode 11, val func loss 2.190443992614746\n",
      "\n",
      "episode 12, val func loss 1.0936686992645264\n",
      "\n",
      "episode 13, val func loss 1.853417158126831\n",
      "\n",
      "episode 14, val func loss 1.877016305923462\n",
      "\n",
      "episode 15, val func loss 1.8508481979370117\n",
      "\n",
      "episode 16, val func loss 1.4250249862670898\n",
      "\n",
      "Val func train loss in epoch 4:1.6750507950782776\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.2299748659133911\n",
      "\n",
      "episode 2, val func loss 2.2250816822052\n",
      "\n",
      "episode 3, val func loss 1.696468710899353\n",
      "\n",
      "episode 4, val func loss 1.7967227697372437\n",
      "\n",
      "episode 5, val func loss 1.5563231706619263\n",
      "\n",
      "episode 6, val func loss 1.33220374584198\n",
      "\n",
      "episode 7, val func loss 2.1404025554656982\n",
      "\n",
      "episode 8, val func loss 1.9139769077301025\n",
      "\n",
      "episode 9, val func loss 1.8074915409088135\n",
      "\n",
      "episode 10, val func loss 2.403613328933716\n",
      "\n",
      "episode 11, val func loss 2.2453877925872803\n",
      "\n",
      "episode 12, val func loss 1.818250060081482\n",
      "\n",
      "episode 13, val func loss 0.9914370775222778\n",
      "\n",
      "episode 14, val func loss 1.3518691062927246\n",
      "\n",
      "episode 15, val func loss 1.153918743133545\n",
      "\n",
      "episode 16, val func loss 2.48644757270813\n",
      "\n",
      "Val func train loss in epoch 5:1.759348101913929\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.0466845035552979\n",
      "\n",
      "episode 2, val func loss 1.9031294584274292\n",
      "\n",
      "episode 3, val func loss 1.841169834136963\n",
      "\n",
      "episode 4, val func loss 1.990468978881836\n",
      "\n",
      "episode 5, val func loss 1.9101264476776123\n",
      "\n",
      "episode 6, val func loss 1.3244446516036987\n",
      "\n",
      "episode 7, val func loss 1.288352608680725\n",
      "\n",
      "episode 8, val func loss 1.2748281955718994\n",
      "\n",
      "episode 9, val func loss 2.4275991916656494\n",
      "\n",
      "episode 10, val func loss 2.621504545211792\n",
      "\n",
      "episode 11, val func loss 1.7760504484176636\n",
      "\n",
      "episode 12, val func loss 1.849865436553955\n",
      "\n",
      "episode 13, val func loss 2.0684330463409424\n",
      "\n",
      "episode 14, val func loss 1.3413281440734863\n",
      "\n",
      "episode 15, val func loss 2.2297558784484863\n",
      "\n",
      "episode 16, val func loss 1.54115629196167\n",
      "\n",
      "Val func train loss in epoch 6:1.7771811038255692\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 1.4178392887115479\n",
      "\n",
      "episode 2, val func loss 2.0149130821228027\n",
      "\n",
      "episode 3, val func loss 1.821203351020813\n",
      "\n",
      "episode 4, val func loss 1.2518882751464844\n",
      "\n",
      "episode 5, val func loss 2.2270724773406982\n",
      "\n",
      "episode 6, val func loss 2.3962998390197754\n",
      "\n",
      "episode 7, val func loss 1.972182273864746\n",
      "\n",
      "episode 8, val func loss 1.1886149644851685\n",
      "\n",
      "episode 9, val func loss 1.6577606201171875\n",
      "\n",
      "episode 10, val func loss 2.537595748901367\n",
      "\n",
      "episode 11, val func loss 1.249881386756897\n",
      "\n",
      "episode 12, val func loss 1.8441967964172363\n",
      "\n",
      "episode 13, val func loss 1.7651861906051636\n",
      "\n",
      "episode 14, val func loss 1.84369695186615\n",
      "\n",
      "episode 15, val func loss 0.9878419041633606\n",
      "\n",
      "episode 16, val func loss 1.4977991580963135\n",
      "\n",
      "Val func train loss in epoch 7:1.729623269289732\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.4032679796218872\n",
      "\n",
      "episode 2, val func loss 1.9279848337173462\n",
      "\n",
      "episode 3, val func loss 2.436678647994995\n",
      "\n",
      "episode 4, val func loss 2.0342345237731934\n",
      "\n",
      "episode 5, val func loss 1.4507399797439575\n",
      "\n",
      "episode 6, val func loss 1.2437556982040405\n",
      "\n",
      "episode 7, val func loss 1.76962411403656\n",
      "\n",
      "episode 8, val func loss 2.4520270824432373\n",
      "\n",
      "episode 9, val func loss 1.192449927330017\n",
      "\n",
      "episode 10, val func loss 1.6966543197631836\n",
      "\n",
      "episode 11, val func loss 1.7425295114517212\n",
      "\n",
      "episode 12, val func loss 1.4022796154022217\n",
      "\n",
      "episode 13, val func loss 1.633171558380127\n",
      "\n",
      "episode 14, val func loss 1.9694031476974487\n",
      "\n",
      "episode 15, val func loss 2.201910972595215\n",
      "\n",
      "episode 16, val func loss 1.59163236618042\n",
      "\n",
      "Val func train loss in epoch 8:1.7592715173959732\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.5443553924560547\n",
      "\n",
      "episode 2, val func loss 2.0587713718414307\n",
      "\n",
      "episode 3, val func loss 1.6300045251846313\n",
      "\n",
      "episode 4, val func loss 2.3589119911193848\n",
      "\n",
      "episode 5, val func loss 2.1503593921661377\n",
      "\n",
      "episode 6, val func loss 1.8407742977142334\n",
      "\n",
      "episode 7, val func loss 1.6494770050048828\n",
      "\n",
      "episode 8, val func loss 1.6274324655532837\n",
      "\n",
      "episode 9, val func loss 1.1854255199432373\n",
      "\n",
      "episode 10, val func loss 1.5957119464874268\n",
      "\n",
      "episode 11, val func loss 0.9108655452728271\n",
      "\n",
      "episode 12, val func loss 0.9562771320343018\n",
      "\n",
      "episode 13, val func loss 1.6926922798156738\n",
      "\n",
      "episode 14, val func loss 1.391849398612976\n",
      "\n",
      "episode 15, val func loss 1.9674983024597168\n",
      "\n",
      "episode 16, val func loss 1.1001769304275513\n",
      "\n",
      "Val func train loss in epoch 9:1.6037864685058594\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.8555809259414673\n",
      "\n",
      "episode 2, val func loss 1.8354748487472534\n",
      "\n",
      "episode 3, val func loss 1.2831109762191772\n",
      "\n",
      "episode 4, val func loss 1.056046724319458\n",
      "\n",
      "episode 5, val func loss 2.074158191680908\n",
      "\n",
      "episode 6, val func loss 1.9813812971115112\n",
      "\n",
      "episode 7, val func loss 1.6824678182601929\n",
      "\n",
      "episode 8, val func loss 1.1465562582015991\n",
      "\n",
      "episode 9, val func loss 2.2540488243103027\n",
      "\n",
      "episode 10, val func loss 1.6558023691177368\n",
      "\n",
      "episode 11, val func loss 1.467763900756836\n",
      "\n",
      "episode 12, val func loss 1.6543117761611938\n",
      "\n",
      "episode 13, val func loss 1.2602746486663818\n",
      "\n",
      "episode 14, val func loss 1.8784302473068237\n",
      "\n",
      "episode 15, val func loss 1.6800450086593628\n",
      "\n",
      "episode 16, val func loss 1.1624886989593506\n",
      "\n",
      "Val func train loss in epoch 10:1.6204964071512222\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.574117660522461\n",
      "\n",
      "episode 2, val func loss 2.6521971225738525\n",
      "\n",
      "episode 3, val func loss 2.238906145095825\n",
      "\n",
      "episode 4, val func loss 1.4414637088775635\n",
      "\n",
      "episode 5, val func loss 1.8477473258972168\n",
      "\n",
      "episode 6, val func loss 1.5727516412734985\n",
      "\n",
      "episode 7, val func loss 1.906719446182251\n",
      "\n",
      "episode 8, val func loss 1.2955105304718018\n",
      "\n",
      "episode 9, val func loss 1.314969778060913\n",
      "\n",
      "episode 10, val func loss 1.6057177782058716\n",
      "\n",
      "episode 11, val func loss 2.0968117713928223\n",
      "\n",
      "episode 12, val func loss 1.3229867219924927\n",
      "\n",
      "episode 13, val func loss 1.8515183925628662\n",
      "\n",
      "episode 14, val func loss 1.5960659980773926\n",
      "\n",
      "episode 15, val func loss 1.203657865524292\n",
      "\n",
      "episode 16, val func loss 1.8915023803710938\n",
      "\n",
      "Val func train loss in epoch 11:1.7132902666926384\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.605661392211914\n",
      "\n",
      "episode 2, val func loss 1.75593900680542\n",
      "\n",
      "episode 3, val func loss 2.249462842941284\n",
      "\n",
      "episode 4, val func loss 1.2409759759902954\n",
      "\n",
      "episode 5, val func loss 2.276216506958008\n",
      "\n",
      "episode 6, val func loss 1.1393522024154663\n",
      "\n",
      "episode 7, val func loss 1.260825514793396\n",
      "\n",
      "episode 8, val func loss 1.9619593620300293\n",
      "\n",
      "episode 9, val func loss 2.1078994274139404\n",
      "\n",
      "episode 10, val func loss 1.6503633260726929\n",
      "\n",
      "episode 11, val func loss 1.4392598867416382\n",
      "\n",
      "episode 12, val func loss 1.7406377792358398\n",
      "\n",
      "episode 13, val func loss 1.1106928586959839\n",
      "\n",
      "episode 14, val func loss 2.0974442958831787\n",
      "\n",
      "episode 15, val func loss 0.9458906054496765\n",
      "\n",
      "episode 16, val func loss 1.2668633460998535\n",
      "\n",
      "Val func train loss in epoch 12:1.6155902706086636\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 2.281187057495117\n",
      "\n",
      "episode 2, val func loss 2.228624105453491\n",
      "\n",
      "episode 3, val func loss 1.812349557876587\n",
      "\n",
      "episode 4, val func loss 1.610313057899475\n",
      "\n",
      "episode 5, val func loss 1.8642399311065674\n",
      "\n",
      "episode 6, val func loss 2.0723721981048584\n",
      "\n",
      "episode 7, val func loss 1.0374128818511963\n",
      "\n",
      "episode 8, val func loss 1.7869561910629272\n",
      "\n",
      "episode 9, val func loss 1.3277791738510132\n",
      "\n",
      "episode 10, val func loss 1.8842309713363647\n",
      "\n",
      "episode 11, val func loss 1.7094330787658691\n",
      "\n",
      "episode 12, val func loss 1.397658348083496\n",
      "\n",
      "episode 13, val func loss 0.9084160923957825\n",
      "\n",
      "episode 14, val func loss 1.2920879125595093\n",
      "\n",
      "episode 15, val func loss 2.042942762374878\n",
      "\n",
      "episode 16, val func loss 1.1389238834381104\n",
      "\n",
      "Val func train loss in epoch 13:1.6496829502284527\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.197941780090332\n",
      "\n",
      "episode 2, val func loss 2.3842859268188477\n",
      "\n",
      "episode 3, val func loss 1.6924132108688354\n",
      "\n",
      "episode 4, val func loss 2.1777615547180176\n",
      "\n",
      "episode 5, val func loss 1.4900449514389038\n",
      "\n",
      "episode 6, val func loss 1.9453623294830322\n",
      "\n",
      "episode 7, val func loss 1.8975913524627686\n",
      "\n",
      "episode 8, val func loss 1.4821221828460693\n",
      "\n",
      "episode 9, val func loss 1.145477294921875\n",
      "\n",
      "episode 10, val func loss 0.9119649529457092\n",
      "\n",
      "episode 11, val func loss 1.921379804611206\n",
      "\n",
      "episode 12, val func loss 1.8719937801361084\n",
      "\n",
      "episode 13, val func loss 1.0674054622650146\n",
      "\n",
      "episode 14, val func loss 1.3627893924713135\n",
      "\n",
      "episode 15, val func loss 1.3386836051940918\n",
      "\n",
      "episode 16, val func loss 1.8471840620040894\n",
      "\n",
      "Val func train loss in epoch 14:1.6084001027047634\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.2394421100616455\n",
      "\n",
      "episode 2, val func loss 1.6172106266021729\n",
      "\n",
      "episode 3, val func loss 2.2992444038391113\n",
      "\n",
      "episode 4, val func loss 1.420246958732605\n",
      "\n",
      "episode 5, val func loss 1.9788954257965088\n",
      "\n",
      "episode 6, val func loss 2.0081088542938232\n",
      "\n",
      "episode 7, val func loss 1.3081690073013306\n",
      "\n",
      "episode 8, val func loss 1.7271711826324463\n",
      "\n",
      "episode 9, val func loss 2.140538215637207\n",
      "\n",
      "episode 10, val func loss 1.776642084121704\n",
      "\n",
      "episode 11, val func loss 2.2540535926818848\n",
      "\n",
      "episode 12, val func loss 2.1158926486968994\n",
      "\n",
      "episode 13, val func loss 1.140758752822876\n",
      "\n",
      "episode 14, val func loss 1.2555752992630005\n",
      "\n",
      "episode 15, val func loss 1.808346152305603\n",
      "\n",
      "episode 16, val func loss 1.121780276298523\n",
      "\n",
      "Val func train loss in epoch 15:1.7007547244429588\n",
      "***********************TIME WAS 4.896720317999522 min*****************************\n",
      "\n",
      "**********************ROUND 108 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.7316668033599854\n",
      "\n",
      "episode 2, policy loss 0.7573128342628479\n",
      "\n",
      "episode 3, policy loss 0.7284611463546753\n",
      "\n",
      "episode 4, policy loss 0.7049853205680847\n",
      "\n",
      "episode 5, policy loss 0.7049513459205627\n",
      "\n",
      "episode 6, policy loss 0.755803108215332\n",
      "\n",
      "episode 7, policy loss 0.7295198440551758\n",
      "\n",
      "episode 8, policy loss 0.7318567633628845\n",
      "\n",
      "episode 9, policy loss 0.7827147245407104\n",
      "\n",
      "episode 10, policy loss 0.7796905040740967\n",
      "\n",
      "episode 11, policy loss 0.7551099061965942\n",
      "\n",
      "episode 12, policy loss 0.7064346671104431\n",
      "\n",
      "episode 13, policy loss 0.7065029740333557\n",
      "\n",
      "episode 14, policy loss 0.7066541314125061\n",
      "\n",
      "episode 15, policy loss 0.7318392992019653\n",
      "\n",
      "episode 16, policy loss 0.7324506044387817\n",
      "\n",
      "Policy train loss in epoch 0:0.7341221235692501\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.7551974058151245\n",
      "\n",
      "episode 2, policy loss 0.7546877264976501\n",
      "\n",
      "episode 3, policy loss 0.7323490381240845\n",
      "\n",
      "episode 4, policy loss 0.7065486311912537\n",
      "\n",
      "episode 5, policy loss 0.7797428369522095\n",
      "\n",
      "episode 6, policy loss 0.756550669670105\n",
      "\n",
      "episode 7, policy loss 0.7300207018852234\n",
      "\n",
      "episode 8, policy loss 0.7824945449829102\n",
      "\n",
      "episode 9, policy loss 0.7058628797531128\n",
      "\n",
      "episode 10, policy loss 0.7295323014259338\n",
      "\n",
      "episode 11, policy loss 0.7053107023239136\n",
      "\n",
      "episode 12, policy loss 0.7309505343437195\n",
      "\n",
      "episode 13, policy loss 0.7298718690872192\n",
      "\n",
      "episode 14, policy loss 0.7043488025665283\n",
      "\n",
      "episode 15, policy loss 0.7336465120315552\n",
      "\n",
      "episode 16, policy loss 0.7040518522262573\n",
      "\n",
      "Policy train loss in epoch 1:0.7338229380548\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.7039404511451721\n",
      "\n",
      "episode 2, policy loss 0.7763388156890869\n",
      "\n",
      "episode 3, policy loss 0.7606390714645386\n",
      "\n",
      "episode 4, policy loss 0.7314535975456238\n",
      "\n",
      "episode 5, policy loss 0.7551081776618958\n",
      "\n",
      "episode 6, policy loss 0.7803966403007507\n",
      "\n",
      "episode 7, policy loss 0.7323533296585083\n",
      "\n",
      "episode 8, policy loss 0.7842361927032471\n",
      "\n",
      "episode 9, policy loss 0.731597900390625\n",
      "\n",
      "episode 10, policy loss 0.7080163359642029\n",
      "\n",
      "episode 11, policy loss 0.708092987537384\n",
      "\n",
      "episode 12, policy loss 0.7081593871116638\n",
      "\n",
      "episode 13, policy loss 0.7342119812965393\n",
      "\n",
      "episode 14, policy loss 0.7321413159370422\n",
      "\n",
      "episode 15, policy loss 0.7341548800468445\n",
      "\n",
      "episode 16, policy loss 0.7084279656410217\n",
      "\n",
      "Policy train loss in epoch 2:0.7368293143808842\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.7335125207901001\n",
      "\n",
      "episode 2, policy loss 0.7084985375404358\n",
      "\n",
      "episode 3, policy loss 0.7342829704284668\n",
      "\n",
      "episode 4, policy loss 0.7085079550743103\n",
      "\n",
      "episode 5, policy loss 0.7085403203964233\n",
      "\n",
      "episode 6, policy loss 0.7851356863975525\n",
      "\n",
      "episode 7, policy loss 0.7570803165435791\n",
      "\n",
      "episode 8, policy loss 0.7567108273506165\n",
      "\n",
      "episode 9, policy loss 0.7586367130279541\n",
      "\n",
      "episode 10, policy loss 0.7818106412887573\n",
      "\n",
      "episode 11, policy loss 0.7085713744163513\n",
      "\n",
      "episode 12, policy loss 0.7323975563049316\n",
      "\n",
      "episode 13, policy loss 0.7085402607917786\n",
      "\n",
      "episode 14, policy loss 0.7343438863754272\n",
      "\n",
      "episode 15, policy loss 0.7323900461196899\n",
      "\n",
      "episode 16, policy loss 0.7344620227813721\n",
      "\n",
      "Policy train loss in epoch 3:0.7364638522267342\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.9617061018943787\n",
      "\n",
      "episode 2, val func loss 0.8102705478668213\n",
      "\n",
      "episode 3, val func loss 0.7621999979019165\n",
      "\n",
      "episode 4, val func loss 0.8239411115646362\n",
      "\n",
      "episode 5, val func loss 1.045770287513733\n",
      "\n",
      "episode 6, val func loss 0.9590080976486206\n",
      "\n",
      "episode 7, val func loss 0.8932488560676575\n",
      "\n",
      "episode 8, val func loss 1.17815363407135\n",
      "\n",
      "episode 9, val func loss 0.8420144319534302\n",
      "\n",
      "episode 10, val func loss 0.6845709085464478\n",
      "\n",
      "episode 11, val func loss 1.1471494436264038\n",
      "\n",
      "episode 12, val func loss 0.7795343995094299\n",
      "\n",
      "episode 13, val func loss 0.7208020091056824\n",
      "\n",
      "episode 14, val func loss 0.7619562745094299\n",
      "\n",
      "episode 15, val func loss 0.6983665227890015\n",
      "\n",
      "episode 16, val func loss 0.680243730545044\n",
      "\n",
      "Val func train loss in epoch 0:0.859308522194624\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.0696505308151245\n",
      "\n",
      "episode 2, val func loss 0.7769270539283752\n",
      "\n",
      "episode 3, val func loss 0.7434362173080444\n",
      "\n",
      "episode 4, val func loss 0.9464053511619568\n",
      "\n",
      "episode 5, val func loss 0.7869104743003845\n",
      "\n",
      "episode 6, val func loss 0.8606354594230652\n",
      "\n",
      "episode 7, val func loss 0.750454306602478\n",
      "\n",
      "episode 8, val func loss 1.0703201293945312\n",
      "\n",
      "episode 9, val func loss 0.8520361185073853\n",
      "\n",
      "episode 10, val func loss 0.6406000256538391\n",
      "\n",
      "episode 11, val func loss 0.9590860605239868\n",
      "\n",
      "episode 12, val func loss 0.8147911429405212\n",
      "\n",
      "episode 13, val func loss 0.9375512599945068\n",
      "\n",
      "episode 14, val func loss 0.7163870334625244\n",
      "\n",
      "episode 15, val func loss 0.9712967276573181\n",
      "\n",
      "episode 16, val func loss 0.739970862865448\n",
      "\n",
      "Val func train loss in epoch 1:0.8522786721587181\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7218364477157593\n",
      "\n",
      "episode 2, val func loss 0.87165367603302\n",
      "\n",
      "episode 3, val func loss 0.8439855575561523\n",
      "\n",
      "episode 4, val func loss 1.08241868019104\n",
      "\n",
      "episode 5, val func loss 0.6957153081893921\n",
      "\n",
      "episode 6, val func loss 0.8307424187660217\n",
      "\n",
      "episode 7, val func loss 1.0108063220977783\n",
      "\n",
      "episode 8, val func loss 1.125983715057373\n",
      "\n",
      "episode 9, val func loss 0.7129979729652405\n",
      "\n",
      "episode 10, val func loss 0.8555054068565369\n",
      "\n",
      "episode 11, val func loss 0.8634623885154724\n",
      "\n",
      "episode 12, val func loss 0.8613739013671875\n",
      "\n",
      "episode 13, val func loss 0.7442806363105774\n",
      "\n",
      "episode 14, val func loss 0.8361285924911499\n",
      "\n",
      "episode 15, val func loss 0.8441453576087952\n",
      "\n",
      "episode 16, val func loss 0.9861063957214355\n",
      "\n",
      "Val func train loss in epoch 2:0.8679464235901833\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.7710508704185486\n",
      "\n",
      "episode 2, val func loss 0.6279616355895996\n",
      "\n",
      "episode 3, val func loss 0.7767557501792908\n",
      "\n",
      "episode 4, val func loss 1.0751088857650757\n",
      "\n",
      "episode 5, val func loss 0.713252604007721\n",
      "\n",
      "episode 6, val func loss 0.7386417388916016\n",
      "\n",
      "episode 7, val func loss 0.8768020272254944\n",
      "\n",
      "episode 8, val func loss 1.0555838346481323\n",
      "\n",
      "episode 9, val func loss 1.0626026391983032\n",
      "\n",
      "episode 10, val func loss 0.658196747303009\n",
      "\n",
      "episode 11, val func loss 0.6708757877349854\n",
      "\n",
      "episode 12, val func loss 0.8972488045692444\n",
      "\n",
      "episode 13, val func loss 0.8501770496368408\n",
      "\n",
      "episode 14, val func loss 0.8760326504707336\n",
      "\n",
      "episode 15, val func loss 0.74749755859375\n",
      "\n",
      "episode 16, val func loss 0.8578963875770569\n",
      "\n",
      "Val func train loss in epoch 3:0.8284803107380867\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.9749036431312561\n",
      "\n",
      "episode 2, val func loss 0.6927686333656311\n",
      "\n",
      "episode 3, val func loss 0.8953952193260193\n",
      "\n",
      "episode 4, val func loss 0.8575350642204285\n",
      "\n",
      "episode 5, val func loss 1.1203997135162354\n",
      "\n",
      "episode 6, val func loss 1.3175854682922363\n",
      "\n",
      "episode 7, val func loss 0.8762484192848206\n",
      "\n",
      "episode 8, val func loss 0.8805258274078369\n",
      "\n",
      "episode 9, val func loss 0.8717852234840393\n",
      "\n",
      "episode 10, val func loss 0.6426059007644653\n",
      "\n",
      "episode 11, val func loss 0.66754150390625\n",
      "\n",
      "episode 12, val func loss 0.7268319725990295\n",
      "\n",
      "episode 13, val func loss 1.0583946704864502\n",
      "\n",
      "episode 14, val func loss 0.9791895151138306\n",
      "\n",
      "episode 15, val func loss 0.8220908045768738\n",
      "\n",
      "episode 16, val func loss 0.9045804142951965\n",
      "\n",
      "Val func train loss in epoch 4:0.8930238746106625\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.8270670175552368\n",
      "\n",
      "episode 2, val func loss 0.6059792637825012\n",
      "\n",
      "episode 3, val func loss 1.1189143657684326\n",
      "\n",
      "episode 4, val func loss 0.6559284329414368\n",
      "\n",
      "episode 5, val func loss 0.7448050379753113\n",
      "\n",
      "episode 6, val func loss 1.0042469501495361\n",
      "\n",
      "episode 7, val func loss 0.7222912311553955\n",
      "\n",
      "episode 8, val func loss 0.827143132686615\n",
      "\n",
      "episode 9, val func loss 0.7471873164176941\n",
      "\n",
      "episode 10, val func loss 1.1011803150177002\n",
      "\n",
      "episode 11, val func loss 0.8349108695983887\n",
      "\n",
      "episode 12, val func loss 0.8464062809944153\n",
      "\n",
      "episode 13, val func loss 0.8580171465873718\n",
      "\n",
      "episode 14, val func loss 1.1738640069961548\n",
      "\n",
      "episode 15, val func loss 0.8065492510795593\n",
      "\n",
      "episode 16, val func loss 0.7226220369338989\n",
      "\n",
      "Val func train loss in epoch 5:0.849819540977478\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6303226947784424\n",
      "\n",
      "episode 2, val func loss 0.8483693599700928\n",
      "\n",
      "episode 3, val func loss 0.710010290145874\n",
      "\n",
      "episode 4, val func loss 0.6232388019561768\n",
      "\n",
      "episode 5, val func loss 0.7733708620071411\n",
      "\n",
      "episode 6, val func loss 0.6809197664260864\n",
      "\n",
      "episode 7, val func loss 1.1879098415374756\n",
      "\n",
      "episode 8, val func loss 0.8056601881980896\n",
      "\n",
      "episode 9, val func loss 0.9856463670730591\n",
      "\n",
      "episode 10, val func loss 0.6963174939155579\n",
      "\n",
      "episode 11, val func loss 1.0955573320388794\n",
      "\n",
      "episode 12, val func loss 0.8275334239006042\n",
      "\n",
      "episode 13, val func loss 0.6941412091255188\n",
      "\n",
      "episode 14, val func loss 1.1420339345932007\n",
      "\n",
      "episode 15, val func loss 0.784973680973053\n",
      "\n",
      "episode 16, val func loss 0.8945519328117371\n",
      "\n",
      "Val func train loss in epoch 6:0.8362848237156868\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7162063717842102\n",
      "\n",
      "episode 2, val func loss 0.7926440834999084\n",
      "\n",
      "episode 3, val func loss 0.8439489603042603\n",
      "\n",
      "episode 4, val func loss 0.6641975045204163\n",
      "\n",
      "episode 5, val func loss 0.7220585346221924\n",
      "\n",
      "episode 6, val func loss 0.8308202028274536\n",
      "\n",
      "episode 7, val func loss 1.0922483205795288\n",
      "\n",
      "episode 8, val func loss 0.594247579574585\n",
      "\n",
      "episode 9, val func loss 0.6321864128112793\n",
      "\n",
      "episode 10, val func loss 1.035276174545288\n",
      "\n",
      "episode 11, val func loss 0.9525410532951355\n",
      "\n",
      "episode 12, val func loss 0.6787749528884888\n",
      "\n",
      "episode 13, val func loss 0.7361188530921936\n",
      "\n",
      "episode 14, val func loss 0.8299426436424255\n",
      "\n",
      "episode 15, val func loss 0.8662360906600952\n",
      "\n",
      "episode 16, val func loss 1.0115545988082886\n",
      "\n",
      "Val func train loss in epoch 7:0.8124376460909843\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7560786604881287\n",
      "\n",
      "episode 2, val func loss 1.0608536005020142\n",
      "\n",
      "episode 3, val func loss 0.8044722080230713\n",
      "\n",
      "episode 4, val func loss 0.6424744725227356\n",
      "\n",
      "episode 5, val func loss 0.802962601184845\n",
      "\n",
      "episode 6, val func loss 0.9748855233192444\n",
      "\n",
      "episode 7, val func loss 0.6721528172492981\n",
      "\n",
      "episode 8, val func loss 0.8669372200965881\n",
      "\n",
      "episode 9, val func loss 0.9980809092521667\n",
      "\n",
      "episode 10, val func loss 0.8148453235626221\n",
      "\n",
      "episode 11, val func loss 0.8133602142333984\n",
      "\n",
      "episode 12, val func loss 0.6273514628410339\n",
      "\n",
      "episode 13, val func loss 0.8267808556556702\n",
      "\n",
      "episode 14, val func loss 0.9604853987693787\n",
      "\n",
      "episode 15, val func loss 0.8232831954956055\n",
      "\n",
      "episode 16, val func loss 0.6870457530021667\n",
      "\n",
      "Val func train loss in epoch 8:0.820753138512373\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8491125106811523\n",
      "\n",
      "episode 2, val func loss 0.9564910531044006\n",
      "\n",
      "episode 3, val func loss 0.790533185005188\n",
      "\n",
      "episode 4, val func loss 0.6585986018180847\n",
      "\n",
      "episode 5, val func loss 1.044480562210083\n",
      "\n",
      "episode 6, val func loss 0.8547589778900146\n",
      "\n",
      "episode 7, val func loss 0.7744749188423157\n",
      "\n",
      "episode 8, val func loss 0.6781198382377625\n",
      "\n",
      "episode 9, val func loss 0.9214512705802917\n",
      "\n",
      "episode 10, val func loss 0.9490465521812439\n",
      "\n",
      "episode 11, val func loss 0.750022828578949\n",
      "\n",
      "episode 12, val func loss 1.24870765209198\n",
      "\n",
      "episode 13, val func loss 0.92839515209198\n",
      "\n",
      "episode 14, val func loss 0.6710882782936096\n",
      "\n",
      "episode 15, val func loss 0.9432235360145569\n",
      "\n",
      "episode 16, val func loss 0.8414161801338196\n",
      "\n",
      "Val func train loss in epoch 9:0.8662450686097145\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.0427223443984985\n",
      "\n",
      "episode 2, val func loss 0.7772758603096008\n",
      "\n",
      "episode 3, val func loss 0.9140329957008362\n",
      "\n",
      "episode 4, val func loss 0.767537534236908\n",
      "\n",
      "episode 5, val func loss 0.633274495601654\n",
      "\n",
      "episode 6, val func loss 0.7601746320724487\n",
      "\n",
      "episode 7, val func loss 1.0126856565475464\n",
      "\n",
      "episode 8, val func loss 0.8539732098579407\n",
      "\n",
      "episode 9, val func loss 1.0307844877243042\n",
      "\n",
      "episode 10, val func loss 0.7099187970161438\n",
      "\n",
      "episode 11, val func loss 0.8783841729164124\n",
      "\n",
      "episode 12, val func loss 1.0299128293991089\n",
      "\n",
      "episode 13, val func loss 0.9169474840164185\n",
      "\n",
      "episode 14, val func loss 1.01503586769104\n",
      "\n",
      "episode 15, val func loss 0.9650945663452148\n",
      "\n",
      "episode 16, val func loss 0.7522777318954468\n",
      "\n",
      "Val func train loss in epoch 10:0.8787520416080952\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.7218852043151855\n",
      "\n",
      "episode 2, val func loss 0.6825557351112366\n",
      "\n",
      "episode 3, val func loss 0.710972011089325\n",
      "\n",
      "episode 4, val func loss 1.0947738885879517\n",
      "\n",
      "episode 5, val func loss 0.8175044059753418\n",
      "\n",
      "episode 6, val func loss 0.7279203534126282\n",
      "\n",
      "episode 7, val func loss 0.9827772974967957\n",
      "\n",
      "episode 8, val func loss 0.9228599667549133\n",
      "\n",
      "episode 9, val func loss 0.9754133224487305\n",
      "\n",
      "episode 10, val func loss 0.809825599193573\n",
      "\n",
      "episode 11, val func loss 1.079987645149231\n",
      "\n",
      "episode 12, val func loss 0.8725390434265137\n",
      "\n",
      "episode 13, val func loss 0.7433416843414307\n",
      "\n",
      "episode 14, val func loss 0.7838848829269409\n",
      "\n",
      "episode 15, val func loss 0.890339732170105\n",
      "\n",
      "episode 16, val func loss 0.6703447103500366\n",
      "\n",
      "Val func train loss in epoch 11:0.8429328426718712\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7971521615982056\n",
      "\n",
      "episode 2, val func loss 0.8630774021148682\n",
      "\n",
      "episode 3, val func loss 0.6654868721961975\n",
      "\n",
      "episode 4, val func loss 0.8831059336662292\n",
      "\n",
      "episode 5, val func loss 0.8196744918823242\n",
      "\n",
      "episode 6, val func loss 0.851809561252594\n",
      "\n",
      "episode 7, val func loss 0.685746967792511\n",
      "\n",
      "episode 8, val func loss 0.9458503723144531\n",
      "\n",
      "episode 9, val func loss 0.9327709674835205\n",
      "\n",
      "episode 10, val func loss 0.7849456071853638\n",
      "\n",
      "episode 11, val func loss 0.7635272741317749\n",
      "\n",
      "episode 12, val func loss 1.0821712017059326\n",
      "\n",
      "episode 13, val func loss 0.6635388731956482\n",
      "\n",
      "episode 14, val func loss 0.93881756067276\n",
      "\n",
      "episode 15, val func loss 0.8497114777565002\n",
      "\n",
      "episode 16, val func loss 1.1506284475326538\n",
      "\n",
      "Val func train loss in epoch 12:0.854875948280096\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.067604660987854\n",
      "\n",
      "episode 2, val func loss 0.8938740491867065\n",
      "\n",
      "episode 3, val func loss 0.9368956089019775\n",
      "\n",
      "episode 4, val func loss 0.8867940902709961\n",
      "\n",
      "episode 5, val func loss 0.710314154624939\n",
      "\n",
      "episode 6, val func loss 0.7473044991493225\n",
      "\n",
      "episode 7, val func loss 0.8282681703567505\n",
      "\n",
      "episode 8, val func loss 0.7642049789428711\n",
      "\n",
      "episode 9, val func loss 0.993059515953064\n",
      "\n",
      "episode 10, val func loss 0.7153928875923157\n",
      "\n",
      "episode 11, val func loss 1.0973529815673828\n",
      "\n",
      "episode 12, val func loss 0.6996620893478394\n",
      "\n",
      "episode 13, val func loss 0.9451149106025696\n",
      "\n",
      "episode 14, val func loss 0.8442182540893555\n",
      "\n",
      "episode 15, val func loss 1.0091111660003662\n",
      "\n",
      "episode 16, val func loss 0.7720645666122437\n",
      "\n",
      "Val func train loss in epoch 13:0.8694522865116596\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6591525077819824\n",
      "\n",
      "episode 2, val func loss 0.7283806204795837\n",
      "\n",
      "episode 3, val func loss 0.6930392980575562\n",
      "\n",
      "episode 4, val func loss 0.7828214764595032\n",
      "\n",
      "episode 5, val func loss 0.9091210961341858\n",
      "\n",
      "episode 6, val func loss 1.151654601097107\n",
      "\n",
      "episode 7, val func loss 0.9164165258407593\n",
      "\n",
      "episode 8, val func loss 0.7844362258911133\n",
      "\n",
      "episode 9, val func loss 0.8453978896141052\n",
      "\n",
      "episode 10, val func loss 0.6792639493942261\n",
      "\n",
      "episode 11, val func loss 0.7690079212188721\n",
      "\n",
      "episode 12, val func loss 1.030704140663147\n",
      "\n",
      "episode 13, val func loss 1.1407275199890137\n",
      "\n",
      "episode 14, val func loss 1.0213940143585205\n",
      "\n",
      "episode 15, val func loss 0.7628622055053711\n",
      "\n",
      "episode 16, val func loss 1.1079761981964111\n",
      "\n",
      "Val func train loss in epoch 14:0.8738972619175911\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.748791515827179\n",
      "\n",
      "episode 2, val func loss 0.8880172371864319\n",
      "\n",
      "episode 3, val func loss 0.832851231098175\n",
      "\n",
      "episode 4, val func loss 0.9578982591629028\n",
      "\n",
      "episode 5, val func loss 0.8145747780799866\n",
      "\n",
      "episode 6, val func loss 0.9664204716682434\n",
      "\n",
      "episode 7, val func loss 0.7880765199661255\n",
      "\n",
      "episode 8, val func loss 0.7117599844932556\n",
      "\n",
      "episode 9, val func loss 1.106945276260376\n",
      "\n",
      "episode 10, val func loss 0.7478029131889343\n",
      "\n",
      "episode 11, val func loss 0.7803688049316406\n",
      "\n",
      "episode 12, val func loss 1.2396656274795532\n",
      "\n",
      "episode 13, val func loss 0.7346096038818359\n",
      "\n",
      "episode 14, val func loss 0.6958603262901306\n",
      "\n",
      "episode 15, val func loss 0.6250527501106262\n",
      "\n",
      "episode 16, val func loss 0.684320867061615\n",
      "\n",
      "Val func train loss in epoch 15:0.8326885104179382\n",
      "***********************TIME WAS 4.900004768371582 min*****************************\n",
      "\n",
      "**********************ROUND 109 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.079774022102356\n",
      "\n",
      "episode 2, policy loss 1.0552095174789429\n",
      "\n",
      "episode 3, policy loss 1.0552401542663574\n",
      "\n",
      "episode 4, policy loss 1.055194616317749\n",
      "\n",
      "episode 5, policy loss 1.055160641670227\n",
      "\n",
      "episode 6, policy loss 1.0551397800445557\n",
      "\n",
      "episode 7, policy loss 1.0550403594970703\n",
      "\n",
      "episode 8, policy loss 1.0550415515899658\n",
      "\n",
      "episode 9, policy loss 1.0363962650299072\n",
      "\n",
      "episode 10, policy loss 1.0551600456237793\n",
      "\n",
      "episode 11, policy loss 1.055303692817688\n",
      "\n",
      "episode 12, policy loss 1.0553925037384033\n",
      "\n",
      "episode 13, policy loss 1.0554685592651367\n",
      "\n",
      "episode 14, policy loss 1.0555181503295898\n",
      "\n",
      "episode 15, policy loss 1.055558204650879\n",
      "\n",
      "episode 16, policy loss 0.8987181782722473\n",
      "\n",
      "Policy train loss in epoch 0:1.0458322651684284\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.0555944442749023\n",
      "\n",
      "episode 2, policy loss 1.0556217432022095\n",
      "\n",
      "episode 3, policy loss 1.0556508302688599\n",
      "\n",
      "episode 4, policy loss 1.0556870698928833\n",
      "\n",
      "episode 5, policy loss 1.0556925535202026\n",
      "\n",
      "episode 6, policy loss 1.0816320180892944\n",
      "\n",
      "episode 7, policy loss 1.0557746887207031\n",
      "\n",
      "episode 8, policy loss 0.898952305316925\n",
      "\n",
      "episode 9, policy loss 1.055898904800415\n",
      "\n",
      "episode 10, policy loss 1.0559428930282593\n",
      "\n",
      "episode 11, policy loss 1.0559797286987305\n",
      "\n",
      "episode 12, policy loss 1.0560075044631958\n",
      "\n",
      "episode 13, policy loss 1.0560330152511597\n",
      "\n",
      "episode 14, policy loss 1.0560439825057983\n",
      "\n",
      "episode 15, policy loss 1.011370062828064\n",
      "\n",
      "episode 16, policy loss 1.0560815334320068\n",
      "\n",
      "Policy train loss in epoch 1:1.0448727048933506\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.0560836791992188\n",
      "\n",
      "episode 2, policy loss 1.056105136871338\n",
      "\n",
      "episode 3, policy loss 1.0561038255691528\n",
      "\n",
      "episode 4, policy loss 1.0561068058013916\n",
      "\n",
      "episode 5, policy loss 1.011427402496338\n",
      "\n",
      "episode 6, policy loss 1.0561209917068481\n",
      "\n",
      "episode 7, policy loss 1.0561326742172241\n",
      "\n",
      "episode 8, policy loss 1.056134581565857\n",
      "\n",
      "episode 9, policy loss 1.0561394691467285\n",
      "\n",
      "episode 10, policy loss 1.056140422821045\n",
      "\n",
      "episode 11, policy loss 1.0561374425888062\n",
      "\n",
      "episode 12, policy loss 1.056145191192627\n",
      "\n",
      "episode 13, policy loss 1.0806634426116943\n",
      "\n",
      "episode 14, policy loss 1.0561457872390747\n",
      "\n",
      "episode 15, policy loss 0.8991897702217102\n",
      "\n",
      "episode 16, policy loss 1.0561491250991821\n",
      "\n",
      "Policy train loss in epoch 2:1.0450578592717648\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.0561456680297852\n",
      "\n",
      "episode 2, policy loss 1.0561444759368896\n",
      "\n",
      "episode 3, policy loss 1.0806630849838257\n",
      "\n",
      "episode 4, policy loss 1.0561507940292358\n",
      "\n",
      "episode 5, policy loss 1.0561467409133911\n",
      "\n",
      "episode 6, policy loss 1.0561411380767822\n",
      "\n",
      "episode 7, policy loss 1.0561463832855225\n",
      "\n",
      "episode 8, policy loss 1.011443853378296\n",
      "\n",
      "episode 9, policy loss 1.0561494827270508\n",
      "\n",
      "episode 10, policy loss 0.8991947770118713\n",
      "\n",
      "episode 11, policy loss 1.0561484098434448\n",
      "\n",
      "episode 12, policy loss 1.0561436414718628\n",
      "\n",
      "episode 13, policy loss 1.0561435222625732\n",
      "\n",
      "episode 14, policy loss 1.0561423301696777\n",
      "\n",
      "episode 15, policy loss 1.056139588356018\n",
      "\n",
      "episode 16, policy loss 1.056135892868042\n",
      "\n",
      "Policy train loss in epoch 3:1.0450737364590168\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.6671608090400696\n",
      "\n",
      "episode 2, val func loss 0.6163235902786255\n",
      "\n",
      "episode 3, val func loss 0.6131768822669983\n",
      "\n",
      "episode 4, val func loss 0.6916034817695618\n",
      "\n",
      "episode 5, val func loss 0.6029748320579529\n",
      "\n",
      "episode 6, val func loss 0.8315081000328064\n",
      "\n",
      "episode 7, val func loss 0.6353060603141785\n",
      "\n",
      "episode 8, val func loss 0.6482105851173401\n",
      "\n",
      "episode 9, val func loss 0.7503475546836853\n",
      "\n",
      "episode 10, val func loss 0.8018722534179688\n",
      "\n",
      "episode 11, val func loss 0.6838765740394592\n",
      "\n",
      "episode 12, val func loss 0.6795935034751892\n",
      "\n",
      "episode 13, val func loss 0.6237893104553223\n",
      "\n",
      "episode 14, val func loss 0.8002596497535706\n",
      "\n",
      "episode 15, val func loss 0.684968113899231\n",
      "\n",
      "episode 16, val func loss 0.8528059124946594\n",
      "\n",
      "Val func train loss in epoch 0:0.6989860758185387\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7168166041374207\n",
      "\n",
      "episode 2, val func loss 0.6507012844085693\n",
      "\n",
      "episode 3, val func loss 0.7066851258277893\n",
      "\n",
      "episode 4, val func loss 0.7480704188346863\n",
      "\n",
      "episode 5, val func loss 0.7330966591835022\n",
      "\n",
      "episode 6, val func loss 0.6549539566040039\n",
      "\n",
      "episode 7, val func loss 0.7716532349586487\n",
      "\n",
      "episode 8, val func loss 0.6925646066665649\n",
      "\n",
      "episode 9, val func loss 0.7128738760948181\n",
      "\n",
      "episode 10, val func loss 0.7506614327430725\n",
      "\n",
      "episode 11, val func loss 0.7145383358001709\n",
      "\n",
      "episode 12, val func loss 0.6635532379150391\n",
      "\n",
      "episode 13, val func loss 0.6123954057693481\n",
      "\n",
      "episode 14, val func loss 0.7095336318016052\n",
      "\n",
      "episode 15, val func loss 0.8100172281265259\n",
      "\n",
      "episode 16, val func loss 0.7969025373458862\n",
      "\n",
      "Val func train loss in epoch 1:0.7153135985136032\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6524024605751038\n",
      "\n",
      "episode 2, val func loss 0.6775562763214111\n",
      "\n",
      "episode 3, val func loss 0.708115816116333\n",
      "\n",
      "episode 4, val func loss 0.7662031650543213\n",
      "\n",
      "episode 5, val func loss 0.738420844078064\n",
      "\n",
      "episode 6, val func loss 0.6145005822181702\n",
      "\n",
      "episode 7, val func loss 0.5999800562858582\n",
      "\n",
      "episode 8, val func loss 0.7051814794540405\n",
      "\n",
      "episode 9, val func loss 0.7222222089767456\n",
      "\n",
      "episode 10, val func loss 0.689793050289154\n",
      "\n",
      "episode 11, val func loss 0.7078771591186523\n",
      "\n",
      "episode 12, val func loss 0.7043067216873169\n",
      "\n",
      "episode 13, val func loss 0.7433066368103027\n",
      "\n",
      "episode 14, val func loss 0.869164764881134\n",
      "\n",
      "episode 15, val func loss 0.6214760541915894\n",
      "\n",
      "episode 16, val func loss 0.6593969464302063\n",
      "\n",
      "Val func train loss in epoch 2:0.6987440139055252\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6505945324897766\n",
      "\n",
      "episode 2, val func loss 0.6699947714805603\n",
      "\n",
      "episode 3, val func loss 0.6842993497848511\n",
      "\n",
      "episode 4, val func loss 0.7031478881835938\n",
      "\n",
      "episode 5, val func loss 0.7773481011390686\n",
      "\n",
      "episode 6, val func loss 0.5744383931159973\n",
      "\n",
      "episode 7, val func loss 0.7587316632270813\n",
      "\n",
      "episode 8, val func loss 0.7331966757774353\n",
      "\n",
      "episode 9, val func loss 0.6557566523551941\n",
      "\n",
      "episode 10, val func loss 0.6698722839355469\n",
      "\n",
      "episode 11, val func loss 0.6283113360404968\n",
      "\n",
      "episode 12, val func loss 0.686838686466217\n",
      "\n",
      "episode 13, val func loss 0.8392828106880188\n",
      "\n",
      "episode 14, val func loss 0.7424550652503967\n",
      "\n",
      "episode 15, val func loss 0.7597721815109253\n",
      "\n",
      "episode 16, val func loss 0.7100945711135864\n",
      "\n",
      "Val func train loss in epoch 3:0.7027584351599216\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7069063186645508\n",
      "\n",
      "episode 2, val func loss 0.7196989059448242\n",
      "\n",
      "episode 3, val func loss 0.733638346195221\n",
      "\n",
      "episode 4, val func loss 0.7699280977249146\n",
      "\n",
      "episode 5, val func loss 0.7269483804702759\n",
      "\n",
      "episode 6, val func loss 0.681224524974823\n",
      "\n",
      "episode 7, val func loss 0.7558446526527405\n",
      "\n",
      "episode 8, val func loss 0.6444746255874634\n",
      "\n",
      "episode 9, val func loss 0.7225403189659119\n",
      "\n",
      "episode 10, val func loss 0.835185170173645\n",
      "\n",
      "episode 11, val func loss 0.598135232925415\n",
      "\n",
      "episode 12, val func loss 0.6852948069572449\n",
      "\n",
      "episode 13, val func loss 0.665912926197052\n",
      "\n",
      "episode 14, val func loss 0.619172990322113\n",
      "\n",
      "episode 15, val func loss 1.0460201501846313\n",
      "\n",
      "episode 16, val func loss 0.7042659521102905\n",
      "\n",
      "Val func train loss in epoch 4:0.7259494625031948\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7956194877624512\n",
      "\n",
      "episode 2, val func loss 0.7842069268226624\n",
      "\n",
      "episode 3, val func loss 0.7202199697494507\n",
      "\n",
      "episode 4, val func loss 0.7042636275291443\n",
      "\n",
      "episode 5, val func loss 0.685558557510376\n",
      "\n",
      "episode 6, val func loss 0.6577550768852234\n",
      "\n",
      "episode 7, val func loss 0.7390822768211365\n",
      "\n",
      "episode 8, val func loss 0.8486361503601074\n",
      "\n",
      "episode 9, val func loss 0.8306056261062622\n",
      "\n",
      "episode 10, val func loss 0.6293710470199585\n",
      "\n",
      "episode 11, val func loss 0.6969256401062012\n",
      "\n",
      "episode 12, val func loss 0.7634094953536987\n",
      "\n",
      "episode 13, val func loss 0.6549016833305359\n",
      "\n",
      "episode 14, val func loss 0.7217968106269836\n",
      "\n",
      "episode 15, val func loss 0.6848260164260864\n",
      "\n",
      "episode 16, val func loss 0.8145784735679626\n",
      "\n",
      "Val func train loss in epoch 5:0.7332348041236401\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.692513108253479\n",
      "\n",
      "episode 2, val func loss 0.7982809543609619\n",
      "\n",
      "episode 3, val func loss 0.7129449844360352\n",
      "\n",
      "episode 4, val func loss 0.73445063829422\n",
      "\n",
      "episode 5, val func loss 0.6559305787086487\n",
      "\n",
      "episode 6, val func loss 0.7869930267333984\n",
      "\n",
      "episode 7, val func loss 0.6532870531082153\n",
      "\n",
      "episode 8, val func loss 0.6793925166130066\n",
      "\n",
      "episode 9, val func loss 0.750137984752655\n",
      "\n",
      "episode 10, val func loss 0.6900596022605896\n",
      "\n",
      "episode 11, val func loss 0.7682563066482544\n",
      "\n",
      "episode 12, val func loss 0.7332029342651367\n",
      "\n",
      "episode 13, val func loss 0.6721229553222656\n",
      "\n",
      "episode 14, val func loss 0.7209597229957581\n",
      "\n",
      "episode 15, val func loss 0.6178989410400391\n",
      "\n",
      "episode 16, val func loss 0.6955239176750183\n",
      "\n",
      "Val func train loss in epoch 6:0.7101222015917301\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7844839096069336\n",
      "\n",
      "episode 2, val func loss 0.7493599653244019\n",
      "\n",
      "episode 3, val func loss 0.6406648755073547\n",
      "\n",
      "episode 4, val func loss 0.7294692397117615\n",
      "\n",
      "episode 5, val func loss 0.6545875668525696\n",
      "\n",
      "episode 6, val func loss 0.6897786855697632\n",
      "\n",
      "episode 7, val func loss 0.8454707860946655\n",
      "\n",
      "episode 8, val func loss 0.6744829416275024\n",
      "\n",
      "episode 9, val func loss 0.9933120012283325\n",
      "\n",
      "episode 10, val func loss 0.7157722115516663\n",
      "\n",
      "episode 11, val func loss 0.7808110117912292\n",
      "\n",
      "episode 12, val func loss 0.5955231785774231\n",
      "\n",
      "episode 13, val func loss 0.7055646181106567\n",
      "\n",
      "episode 14, val func loss 0.6329267621040344\n",
      "\n",
      "episode 15, val func loss 0.7161703109741211\n",
      "\n",
      "episode 16, val func loss 0.7484378218650818\n",
      "\n",
      "Val func train loss in epoch 7:0.7285509929060936\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.5945173501968384\n",
      "\n",
      "episode 2, val func loss 0.7457739114761353\n",
      "\n",
      "episode 3, val func loss 0.6785699129104614\n",
      "\n",
      "episode 4, val func loss 0.7642309069633484\n",
      "\n",
      "episode 5, val func loss 0.6511970162391663\n",
      "\n",
      "episode 6, val func loss 0.8460887670516968\n",
      "\n",
      "episode 7, val func loss 0.6005375981330872\n",
      "\n",
      "episode 8, val func loss 0.6761804223060608\n",
      "\n",
      "episode 9, val func loss 0.7783101201057434\n",
      "\n",
      "episode 10, val func loss 0.8848466873168945\n",
      "\n",
      "episode 11, val func loss 0.6934504508972168\n",
      "\n",
      "episode 12, val func loss 0.7071428894996643\n",
      "\n",
      "episode 13, val func loss 0.7648435235023499\n",
      "\n",
      "episode 14, val func loss 0.8228862881660461\n",
      "\n",
      "episode 15, val func loss 0.758404552936554\n",
      "\n",
      "episode 16, val func loss 0.6570315957069397\n",
      "\n",
      "Val func train loss in epoch 8:0.7265007495880127\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6503534317016602\n",
      "\n",
      "episode 2, val func loss 0.6471580266952515\n",
      "\n",
      "episode 3, val func loss 0.7080560326576233\n",
      "\n",
      "episode 4, val func loss 0.779342770576477\n",
      "\n",
      "episode 5, val func loss 0.7179824113845825\n",
      "\n",
      "episode 6, val func loss 0.717244029045105\n",
      "\n",
      "episode 7, val func loss 0.6737999320030212\n",
      "\n",
      "episode 8, val func loss 0.6812350153923035\n",
      "\n",
      "episode 9, val func loss 0.8187797665596008\n",
      "\n",
      "episode 10, val func loss 0.7847800254821777\n",
      "\n",
      "episode 11, val func loss 0.7068974375724792\n",
      "\n",
      "episode 12, val func loss 0.7429718375205994\n",
      "\n",
      "episode 13, val func loss 0.6881512403488159\n",
      "\n",
      "episode 14, val func loss 0.6596927642822266\n",
      "\n",
      "episode 15, val func loss 0.671965479850769\n",
      "\n",
      "episode 16, val func loss 0.7268007397651672\n",
      "\n",
      "Val func train loss in epoch 9:0.7109506838023663\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7189634442329407\n",
      "\n",
      "episode 2, val func loss 0.6691101789474487\n",
      "\n",
      "episode 3, val func loss 0.6798588633537292\n",
      "\n",
      "episode 4, val func loss 0.8918465375900269\n",
      "\n",
      "episode 5, val func loss 0.8386492729187012\n",
      "\n",
      "episode 6, val func loss 0.7329897880554199\n",
      "\n",
      "episode 7, val func loss 0.7988585829734802\n",
      "\n",
      "episode 8, val func loss 0.7037208676338196\n",
      "\n",
      "episode 9, val func loss 0.7537168264389038\n",
      "\n",
      "episode 10, val func loss 0.6552034616470337\n",
      "\n",
      "episode 11, val func loss 0.7147772312164307\n",
      "\n",
      "episode 12, val func loss 0.6716256737709045\n",
      "\n",
      "episode 13, val func loss 0.6521151661872864\n",
      "\n",
      "episode 14, val func loss 0.7127577662467957\n",
      "\n",
      "episode 15, val func loss 0.6254370212554932\n",
      "\n",
      "episode 16, val func loss 0.76130211353302\n",
      "\n",
      "Val func train loss in epoch 10:0.7238082997500896\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6823724508285522\n",
      "\n",
      "episode 2, val func loss 0.6333698630332947\n",
      "\n",
      "episode 3, val func loss 0.8615522980690002\n",
      "\n",
      "episode 4, val func loss 0.7961500287055969\n",
      "\n",
      "episode 5, val func loss 0.7182356715202332\n",
      "\n",
      "episode 6, val func loss 0.6611483693122864\n",
      "\n",
      "episode 7, val func loss 0.7242817282676697\n",
      "\n",
      "episode 8, val func loss 0.7373639345169067\n",
      "\n",
      "episode 9, val func loss 0.6739787459373474\n",
      "\n",
      "episode 10, val func loss 0.7759790420532227\n",
      "\n",
      "episode 11, val func loss 0.7038633823394775\n",
      "\n",
      "episode 12, val func loss 0.7614318132400513\n",
      "\n",
      "episode 13, val func loss 0.7777554988861084\n",
      "\n",
      "episode 14, val func loss 0.6253083348274231\n",
      "\n",
      "episode 15, val func loss 0.7552427053451538\n",
      "\n",
      "episode 16, val func loss 0.7584177851676941\n",
      "\n",
      "Val func train loss in epoch 11:0.7279032282531261\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6641251444816589\n",
      "\n",
      "episode 2, val func loss 0.6969891786575317\n",
      "\n",
      "episode 3, val func loss 0.6886996626853943\n",
      "\n",
      "episode 4, val func loss 0.7568812370300293\n",
      "\n",
      "episode 5, val func loss 0.85411137342453\n",
      "\n",
      "episode 6, val func loss 0.7861034870147705\n",
      "\n",
      "episode 7, val func loss 0.7634016871452332\n",
      "\n",
      "episode 8, val func loss 0.7172037363052368\n",
      "\n",
      "episode 9, val func loss 0.5961583852767944\n",
      "\n",
      "episode 10, val func loss 0.6965299248695374\n",
      "\n",
      "episode 11, val func loss 0.6897960305213928\n",
      "\n",
      "episode 12, val func loss 0.830110490322113\n",
      "\n",
      "episode 13, val func loss 0.6979869604110718\n",
      "\n",
      "episode 14, val func loss 0.6560741662979126\n",
      "\n",
      "episode 15, val func loss 0.5977399945259094\n",
      "\n",
      "episode 16, val func loss 0.847719132900238\n",
      "\n",
      "Val func train loss in epoch 12:0.7212269119918346\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.651645839214325\n",
      "\n",
      "episode 2, val func loss 0.7463383078575134\n",
      "\n",
      "episode 3, val func loss 0.8107628226280212\n",
      "\n",
      "episode 4, val func loss 0.7065663933753967\n",
      "\n",
      "episode 5, val func loss 0.6808236241340637\n",
      "\n",
      "episode 6, val func loss 0.6727481484413147\n",
      "\n",
      "episode 7, val func loss 0.694667398929596\n",
      "\n",
      "episode 8, val func loss 0.6861906051635742\n",
      "\n",
      "episode 9, val func loss 0.732194185256958\n",
      "\n",
      "episode 10, val func loss 0.7587499618530273\n",
      "\n",
      "episode 11, val func loss 0.6988518834114075\n",
      "\n",
      "episode 12, val func loss 0.6958834528923035\n",
      "\n",
      "episode 13, val func loss 0.5770911574363708\n",
      "\n",
      "episode 14, val func loss 0.6199612021446228\n",
      "\n",
      "episode 15, val func loss 0.6593068838119507\n",
      "\n",
      "episode 16, val func loss 0.5922144055366516\n",
      "\n",
      "Val func train loss in epoch 13:0.6864997670054436\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7344637513160706\n",
      "\n",
      "episode 2, val func loss 0.6560108661651611\n",
      "\n",
      "episode 3, val func loss 0.883901834487915\n",
      "\n",
      "episode 4, val func loss 0.7138017416000366\n",
      "\n",
      "episode 5, val func loss 1.0031965970993042\n",
      "\n",
      "episode 6, val func loss 0.6624940037727356\n",
      "\n",
      "episode 7, val func loss 0.9583553075790405\n",
      "\n",
      "episode 8, val func loss 0.6177861094474792\n",
      "\n",
      "episode 9, val func loss 0.7209674119949341\n",
      "\n",
      "episode 10, val func loss 0.7642135620117188\n",
      "\n",
      "episode 11, val func loss 0.7173421382904053\n",
      "\n",
      "episode 12, val func loss 0.8991045951843262\n",
      "\n",
      "episode 13, val func loss 0.7854931950569153\n",
      "\n",
      "episode 14, val func loss 0.6841697692871094\n",
      "\n",
      "episode 15, val func loss 0.8267927169799805\n",
      "\n",
      "episode 16, val func loss 0.7395814657211304\n",
      "\n",
      "Val func train loss in epoch 14:0.7729796916246414\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7258541584014893\n",
      "\n",
      "episode 2, val func loss 0.7633283138275146\n",
      "\n",
      "episode 3, val func loss 0.8608124852180481\n",
      "\n",
      "episode 4, val func loss 0.7879812121391296\n",
      "\n",
      "episode 5, val func loss 0.703654944896698\n",
      "\n",
      "episode 6, val func loss 0.9583892822265625\n",
      "\n",
      "episode 7, val func loss 0.6965665817260742\n",
      "\n",
      "episode 8, val func loss 0.6575157642364502\n",
      "\n",
      "episode 9, val func loss 0.8578848838806152\n",
      "\n",
      "episode 10, val func loss 0.8397201895713806\n",
      "\n",
      "episode 11, val func loss 0.6557250618934631\n",
      "\n",
      "episode 12, val func loss 0.6587314605712891\n",
      "\n",
      "episode 13, val func loss 0.6704273223876953\n",
      "\n",
      "episode 14, val func loss 0.7786298990249634\n",
      "\n",
      "episode 15, val func loss 0.7678189873695374\n",
      "\n",
      "episode 16, val func loss 0.8185862898826599\n",
      "\n",
      "Val func train loss in epoch 15:0.7626016773283482\n",
      "***********************TIME WAS 4.900470213095347 min*****************************\n",
      "\n",
      "**********************ROUND 110 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.1131701469421387\n",
      "\n",
      "episode 2, policy loss 1.1131714582443237\n",
      "\n",
      "episode 3, policy loss 1.1131731271743774\n",
      "\n",
      "episode 4, policy loss 1.113167405128479\n",
      "\n",
      "episode 5, policy loss 1.1131713390350342\n",
      "\n",
      "episode 6, policy loss 1.1131700277328491\n",
      "\n",
      "episode 7, policy loss 1.113159418106079\n",
      "\n",
      "episode 8, policy loss 1.113162875175476\n",
      "\n",
      "episode 9, policy loss 1.1131638288497925\n",
      "\n",
      "episode 10, policy loss 1.1131565570831299\n",
      "\n",
      "episode 11, policy loss 1.113153338432312\n",
      "\n",
      "episode 12, policy loss 1.1131526231765747\n",
      "\n",
      "episode 13, policy loss 1.1131528615951538\n",
      "\n",
      "episode 14, policy loss 1.113148808479309\n",
      "\n",
      "episode 15, policy loss 1.1131515502929688\n",
      "\n",
      "episode 16, policy loss 1.1131459474563599\n",
      "\n",
      "Policy train loss in epoch 0:1.1131607070565224\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.1131469011306763\n",
      "\n",
      "episode 2, policy loss 1.1131354570388794\n",
      "\n",
      "episode 3, policy loss 1.1131373643875122\n",
      "\n",
      "episode 4, policy loss 1.1131342649459839\n",
      "\n",
      "episode 5, policy loss 1.1131218671798706\n",
      "\n",
      "episode 6, policy loss 1.113115668296814\n",
      "\n",
      "episode 7, policy loss 1.1131336688995361\n",
      "\n",
      "episode 8, policy loss 1.1131196022033691\n",
      "\n",
      "episode 9, policy loss 1.113124132156372\n",
      "\n",
      "episode 10, policy loss 1.1131099462509155\n",
      "\n",
      "episode 11, policy loss 1.1131153106689453\n",
      "\n",
      "episode 12, policy loss 1.1131019592285156\n",
      "\n",
      "episode 13, policy loss 1.1131038665771484\n",
      "\n",
      "episode 14, policy loss 1.1130956411361694\n",
      "\n",
      "episode 15, policy loss 1.1130919456481934\n",
      "\n",
      "episode 16, policy loss 1.1130813360214233\n",
      "\n",
      "Policy train loss in epoch 1:1.1131168082356453\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.113093614578247\n",
      "\n",
      "episode 2, policy loss 1.1130733489990234\n",
      "\n",
      "episode 3, policy loss 1.1130778789520264\n",
      "\n",
      "episode 4, policy loss 1.1130584478378296\n",
      "\n",
      "episode 5, policy loss 1.1130555868148804\n",
      "\n",
      "episode 6, policy loss 1.1130527257919312\n",
      "\n",
      "episode 7, policy loss 1.1130433082580566\n",
      "\n",
      "episode 8, policy loss 1.113046407699585\n",
      "\n",
      "episode 9, policy loss 1.113037347793579\n",
      "\n",
      "episode 10, policy loss 1.1130207777023315\n",
      "\n",
      "episode 11, policy loss 1.1130002737045288\n",
      "\n",
      "episode 12, policy loss 1.1129876375198364\n",
      "\n",
      "episode 13, policy loss 1.112975835800171\n",
      "\n",
      "episode 14, policy loss 1.1129645109176636\n",
      "\n",
      "episode 15, policy loss 1.1129752397537231\n",
      "\n",
      "episode 16, policy loss 1.1129320859909058\n",
      "\n",
      "Policy train loss in epoch 2:1.113024689257145\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.1129108667373657\n",
      "\n",
      "episode 2, policy loss 1.112895131111145\n",
      "\n",
      "episode 3, policy loss 1.11287522315979\n",
      "\n",
      "episode 4, policy loss 1.112882137298584\n",
      "\n",
      "episode 5, policy loss 1.112844705581665\n",
      "\n",
      "episode 6, policy loss 1.112795352935791\n",
      "\n",
      "episode 7, policy loss 1.1128101348876953\n",
      "\n",
      "episode 8, policy loss 1.1127158403396606\n",
      "\n",
      "episode 9, policy loss 1.1126912832260132\n",
      "\n",
      "episode 10, policy loss 1.1126556396484375\n",
      "\n",
      "episode 11, policy loss 1.112565517425537\n",
      "\n",
      "episode 12, policy loss 1.1124694347381592\n",
      "\n",
      "episode 13, policy loss 1.1123896837234497\n",
      "\n",
      "episode 14, policy loss 1.1122523546218872\n",
      "\n",
      "episode 15, policy loss 1.111994743347168\n",
      "\n",
      "episode 16, policy loss 1.1117299795150757\n",
      "\n",
      "Policy train loss in epoch 3:1.112592376768589\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7175163626670837\n",
      "\n",
      "episode 2, val func loss 0.8658245205879211\n",
      "\n",
      "episode 3, val func loss 0.8754412531852722\n",
      "\n",
      "episode 4, val func loss 0.6124905943870544\n",
      "\n",
      "episode 5, val func loss 0.7040068507194519\n",
      "\n",
      "episode 6, val func loss 0.7380658388137817\n",
      "\n",
      "episode 7, val func loss 0.6945412158966064\n",
      "\n",
      "episode 8, val func loss 0.6712340116500854\n",
      "\n",
      "episode 9, val func loss 0.6930702924728394\n",
      "\n",
      "episode 10, val func loss 0.6787043213844299\n",
      "\n",
      "episode 11, val func loss 0.7204591035842896\n",
      "\n",
      "episode 12, val func loss 0.7062938809394836\n",
      "\n",
      "episode 13, val func loss 0.5964421033859253\n",
      "\n",
      "episode 14, val func loss 0.7922316789627075\n",
      "\n",
      "episode 15, val func loss 0.7504693865776062\n",
      "\n",
      "episode 16, val func loss 0.6260538697242737\n",
      "\n",
      "Val func train loss in epoch 0:0.7151778303086758\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7925661206245422\n",
      "\n",
      "episode 2, val func loss 0.7622697949409485\n",
      "\n",
      "episode 3, val func loss 0.7146092653274536\n",
      "\n",
      "episode 4, val func loss 0.665222704410553\n",
      "\n",
      "episode 5, val func loss 0.7182877063751221\n",
      "\n",
      "episode 6, val func loss 0.637180745601654\n",
      "\n",
      "episode 7, val func loss 0.6449346542358398\n",
      "\n",
      "episode 8, val func loss 0.6881356835365295\n",
      "\n",
      "episode 9, val func loss 0.7071369290351868\n",
      "\n",
      "episode 10, val func loss 0.6432954668998718\n",
      "\n",
      "episode 11, val func loss 0.7951838374137878\n",
      "\n",
      "episode 12, val func loss 0.6610615849494934\n",
      "\n",
      "episode 13, val func loss 0.5706554055213928\n",
      "\n",
      "episode 14, val func loss 0.7531766891479492\n",
      "\n",
      "episode 15, val func loss 0.6540008187294006\n",
      "\n",
      "episode 16, val func loss 0.675667405128479\n",
      "\n",
      "Val func train loss in epoch 1:0.6927115507423878\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6216893792152405\n",
      "\n",
      "episode 2, val func loss 0.6411819458007812\n",
      "\n",
      "episode 3, val func loss 0.6630613207817078\n",
      "\n",
      "episode 4, val func loss 0.7309417128562927\n",
      "\n",
      "episode 5, val func loss 0.6128262281417847\n",
      "\n",
      "episode 6, val func loss 0.6739736199378967\n",
      "\n",
      "episode 7, val func loss 0.7764851450920105\n",
      "\n",
      "episode 8, val func loss 0.6930427551269531\n",
      "\n",
      "episode 9, val func loss 0.7238381505012512\n",
      "\n",
      "episode 10, val func loss 0.6331665515899658\n",
      "\n",
      "episode 11, val func loss 0.7162988185882568\n",
      "\n",
      "episode 12, val func loss 0.7565755844116211\n",
      "\n",
      "episode 13, val func loss 0.6817571520805359\n",
      "\n",
      "episode 14, val func loss 0.8927313685417175\n",
      "\n",
      "episode 15, val func loss 0.6549819707870483\n",
      "\n",
      "episode 16, val func loss 0.7610759139060974\n",
      "\n",
      "Val func train loss in epoch 2:0.7021017260849476\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.7186795473098755\n",
      "\n",
      "episode 2, val func loss 0.6912640333175659\n",
      "\n",
      "episode 3, val func loss 0.7902188897132874\n",
      "\n",
      "episode 4, val func loss 0.7255278825759888\n",
      "\n",
      "episode 5, val func loss 0.8265450596809387\n",
      "\n",
      "episode 6, val func loss 0.7304380536079407\n",
      "\n",
      "episode 7, val func loss 0.6954599022865295\n",
      "\n",
      "episode 8, val func loss 0.7470365166664124\n",
      "\n",
      "episode 9, val func loss 0.7637951970100403\n",
      "\n",
      "episode 10, val func loss 0.6347571611404419\n",
      "\n",
      "episode 11, val func loss 0.6489589214324951\n",
      "\n",
      "episode 12, val func loss 0.6591232419013977\n",
      "\n",
      "episode 13, val func loss 0.6335508227348328\n",
      "\n",
      "episode 14, val func loss 0.6399134993553162\n",
      "\n",
      "episode 15, val func loss 0.6675693392753601\n",
      "\n",
      "episode 16, val func loss 0.6402255296707153\n",
      "\n",
      "Val func train loss in epoch 3:0.7008164748549461\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6548312306404114\n",
      "\n",
      "episode 2, val func loss 0.7128772139549255\n",
      "\n",
      "episode 3, val func loss 0.6561924815177917\n",
      "\n",
      "episode 4, val func loss 0.585886538028717\n",
      "\n",
      "episode 5, val func loss 0.74204021692276\n",
      "\n",
      "episode 6, val func loss 0.7204055190086365\n",
      "\n",
      "episode 7, val func loss 0.6963281631469727\n",
      "\n",
      "episode 8, val func loss 0.6503103971481323\n",
      "\n",
      "episode 9, val func loss 0.7374461889266968\n",
      "\n",
      "episode 10, val func loss 0.6663157343864441\n",
      "\n",
      "episode 11, val func loss 0.6527571082115173\n",
      "\n",
      "episode 12, val func loss 0.6722971796989441\n",
      "\n",
      "episode 13, val func loss 0.6026871800422668\n",
      "\n",
      "episode 14, val func loss 0.7408126592636108\n",
      "\n",
      "episode 15, val func loss 0.6021055579185486\n",
      "\n",
      "episode 16, val func loss 0.7198443412780762\n",
      "\n",
      "Val func train loss in epoch 4:0.6758211068809032\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6316314339637756\n",
      "\n",
      "episode 2, val func loss 0.6892521977424622\n",
      "\n",
      "episode 3, val func loss 0.688889741897583\n",
      "\n",
      "episode 4, val func loss 0.650796115398407\n",
      "\n",
      "episode 5, val func loss 0.6117306351661682\n",
      "\n",
      "episode 6, val func loss 0.682991087436676\n",
      "\n",
      "episode 7, val func loss 0.7794371843338013\n",
      "\n",
      "episode 8, val func loss 0.600555956363678\n",
      "\n",
      "episode 9, val func loss 0.7515738010406494\n",
      "\n",
      "episode 10, val func loss 0.6463395953178406\n",
      "\n",
      "episode 11, val func loss 0.7075220942497253\n",
      "\n",
      "episode 12, val func loss 0.8101263046264648\n",
      "\n",
      "episode 13, val func loss 0.6117410063743591\n",
      "\n",
      "episode 14, val func loss 0.6724504828453064\n",
      "\n",
      "episode 15, val func loss 0.7132570743560791\n",
      "\n",
      "episode 16, val func loss 0.6765121221542358\n",
      "\n",
      "Val func train loss in epoch 5:0.6828004270792007\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6123251914978027\n",
      "\n",
      "episode 2, val func loss 0.6318084001541138\n",
      "\n",
      "episode 3, val func loss 0.6003421545028687\n",
      "\n",
      "episode 4, val func loss 0.6393598914146423\n",
      "\n",
      "episode 5, val func loss 0.6989474296569824\n",
      "\n",
      "episode 6, val func loss 0.6738718748092651\n",
      "\n",
      "episode 7, val func loss 0.6688814163208008\n",
      "\n",
      "episode 8, val func loss 0.6620798110961914\n",
      "\n",
      "episode 9, val func loss 0.6545992493629456\n",
      "\n",
      "episode 10, val func loss 0.6894302368164062\n",
      "\n",
      "episode 11, val func loss 0.6654170751571655\n",
      "\n",
      "episode 12, val func loss 0.7553114891052246\n",
      "\n",
      "episode 13, val func loss 0.7437591552734375\n",
      "\n",
      "episode 14, val func loss 0.6910544633865356\n",
      "\n",
      "episode 15, val func loss 0.6008480191230774\n",
      "\n",
      "episode 16, val func loss 0.5890727639198303\n",
      "\n",
      "Val func train loss in epoch 6:0.6610692888498306\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6809338927268982\n",
      "\n",
      "episode 2, val func loss 0.5907413959503174\n",
      "\n",
      "episode 3, val func loss 0.6794173717498779\n",
      "\n",
      "episode 4, val func loss 0.7123816013336182\n",
      "\n",
      "episode 5, val func loss 0.6956053376197815\n",
      "\n",
      "episode 6, val func loss 0.5660713315010071\n",
      "\n",
      "episode 7, val func loss 0.6740480065345764\n",
      "\n",
      "episode 8, val func loss 0.6633022427558899\n",
      "\n",
      "episode 9, val func loss 0.6682665348052979\n",
      "\n",
      "episode 10, val func loss 0.6396955251693726\n",
      "\n",
      "episode 11, val func loss 0.6908827424049377\n",
      "\n",
      "episode 12, val func loss 0.7246662974357605\n",
      "\n",
      "episode 13, val func loss 0.6989935040473938\n",
      "\n",
      "episode 14, val func loss 0.7383937239646912\n",
      "\n",
      "episode 15, val func loss 0.6773068308830261\n",
      "\n",
      "episode 16, val func loss 0.7033151388168335\n",
      "\n",
      "Val func train loss in epoch 7:0.675251342356205\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6620053648948669\n",
      "\n",
      "episode 2, val func loss 0.6941325664520264\n",
      "\n",
      "episode 3, val func loss 0.7015110850334167\n",
      "\n",
      "episode 4, val func loss 0.5389705300331116\n",
      "\n",
      "episode 5, val func loss 0.7657852172851562\n",
      "\n",
      "episode 6, val func loss 0.7502840161323547\n",
      "\n",
      "episode 7, val func loss 0.6769685745239258\n",
      "\n",
      "episode 8, val func loss 0.7268913984298706\n",
      "\n",
      "episode 9, val func loss 0.7470859885215759\n",
      "\n",
      "episode 10, val func loss 0.7245646119117737\n",
      "\n",
      "episode 11, val func loss 0.6410985589027405\n",
      "\n",
      "episode 12, val func loss 0.7289748191833496\n",
      "\n",
      "episode 13, val func loss 0.7748258709907532\n",
      "\n",
      "episode 14, val func loss 0.6918765902519226\n",
      "\n",
      "episode 15, val func loss 0.6401699781417847\n",
      "\n",
      "episode 16, val func loss 0.7569266557693481\n",
      "\n",
      "Val func train loss in epoch 8:0.7013794891536236\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6908372044563293\n",
      "\n",
      "episode 2, val func loss 0.7517322301864624\n",
      "\n",
      "episode 3, val func loss 0.6452624797821045\n",
      "\n",
      "episode 4, val func loss 0.6792358160018921\n",
      "\n",
      "episode 5, val func loss 0.7176375985145569\n",
      "\n",
      "episode 6, val func loss 0.6747375726699829\n",
      "\n",
      "episode 7, val func loss 0.6777264475822449\n",
      "\n",
      "episode 8, val func loss 0.6916029453277588\n",
      "\n",
      "episode 9, val func loss 0.7312303781509399\n",
      "\n",
      "episode 10, val func loss 0.7077432870864868\n",
      "\n",
      "episode 11, val func loss 0.6923148036003113\n",
      "\n",
      "episode 12, val func loss 0.7267163991928101\n",
      "\n",
      "episode 13, val func loss 0.6529773473739624\n",
      "\n",
      "episode 14, val func loss 0.5602409839630127\n",
      "\n",
      "episode 15, val func loss 0.6770233511924744\n",
      "\n",
      "episode 16, val func loss 0.6549994945526123\n",
      "\n",
      "Val func train loss in epoch 9:0.6832511462271214\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6637089252471924\n",
      "\n",
      "episode 2, val func loss 0.6387515068054199\n",
      "\n",
      "episode 3, val func loss 0.658610463142395\n",
      "\n",
      "episode 4, val func loss 0.6086032390594482\n",
      "\n",
      "episode 5, val func loss 0.6490973234176636\n",
      "\n",
      "episode 6, val func loss 0.7121555805206299\n",
      "\n",
      "episode 7, val func loss 0.678729772567749\n",
      "\n",
      "episode 8, val func loss 0.6263872385025024\n",
      "\n",
      "episode 9, val func loss 0.6874300837516785\n",
      "\n",
      "episode 10, val func loss 0.6579708456993103\n",
      "\n",
      "episode 11, val func loss 0.6114591360092163\n",
      "\n",
      "episode 12, val func loss 0.6643052101135254\n",
      "\n",
      "episode 13, val func loss 0.6898824572563171\n",
      "\n",
      "episode 14, val func loss 0.6659376621246338\n",
      "\n",
      "episode 15, val func loss 0.7145670056343079\n",
      "\n",
      "episode 16, val func loss 0.6482390761375427\n",
      "\n",
      "Val func train loss in epoch 10:0.6609897203743458\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6219723224639893\n",
      "\n",
      "episode 2, val func loss 0.5537188053131104\n",
      "\n",
      "episode 3, val func loss 0.6348680257797241\n",
      "\n",
      "episode 4, val func loss 0.6275888085365295\n",
      "\n",
      "episode 5, val func loss 0.7128817439079285\n",
      "\n",
      "episode 6, val func loss 0.6911860108375549\n",
      "\n",
      "episode 7, val func loss 0.6449884176254272\n",
      "\n",
      "episode 8, val func loss 0.6925697326660156\n",
      "\n",
      "episode 9, val func loss 0.7393729090690613\n",
      "\n",
      "episode 10, val func loss 0.6307342648506165\n",
      "\n",
      "episode 11, val func loss 0.80324786901474\n",
      "\n",
      "episode 12, val func loss 0.7270762324333191\n",
      "\n",
      "episode 13, val func loss 0.7650244235992432\n",
      "\n",
      "episode 14, val func loss 0.661776602268219\n",
      "\n",
      "episode 15, val func loss 0.7413088083267212\n",
      "\n",
      "episode 16, val func loss 0.6993310451507568\n",
      "\n",
      "Val func train loss in epoch 11:0.6842278763651848\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7395825982093811\n",
      "\n",
      "episode 2, val func loss 0.8482950329780579\n",
      "\n",
      "episode 3, val func loss 0.6509867310523987\n",
      "\n",
      "episode 4, val func loss 0.7128395438194275\n",
      "\n",
      "episode 5, val func loss 0.7182273864746094\n",
      "\n",
      "episode 6, val func loss 0.7584737539291382\n",
      "\n",
      "episode 7, val func loss 0.7430742383003235\n",
      "\n",
      "episode 8, val func loss 0.8366560935974121\n",
      "\n",
      "episode 9, val func loss 0.6201891303062439\n",
      "\n",
      "episode 10, val func loss 0.9318978786468506\n",
      "\n",
      "episode 11, val func loss 0.7832083106040955\n",
      "\n",
      "episode 12, val func loss 0.7515550851821899\n",
      "\n",
      "episode 13, val func loss 0.7698001861572266\n",
      "\n",
      "episode 14, val func loss 0.6220535039901733\n",
      "\n",
      "episode 15, val func loss 0.7534611225128174\n",
      "\n",
      "episode 16, val func loss 0.6583048701286316\n",
      "\n",
      "Val func train loss in epoch 12:0.7436628416180611\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8137069344520569\n",
      "\n",
      "episode 2, val func loss 0.7450209856033325\n",
      "\n",
      "episode 3, val func loss 0.7031357884407043\n",
      "\n",
      "episode 4, val func loss 0.747504711151123\n",
      "\n",
      "episode 5, val func loss 0.6823943257331848\n",
      "\n",
      "episode 6, val func loss 0.6378822326660156\n",
      "\n",
      "episode 7, val func loss 0.8950949311256409\n",
      "\n",
      "episode 8, val func loss 0.7398670315742493\n",
      "\n",
      "episode 9, val func loss 0.5858179330825806\n",
      "\n",
      "episode 10, val func loss 0.5750230550765991\n",
      "\n",
      "episode 11, val func loss 0.7759761810302734\n",
      "\n",
      "episode 12, val func loss 0.6111263036727905\n",
      "\n",
      "episode 13, val func loss 0.5955721139907837\n",
      "\n",
      "episode 14, val func loss 0.7754777073860168\n",
      "\n",
      "episode 15, val func loss 0.5852040648460388\n",
      "\n",
      "episode 16, val func loss 0.6270431280136108\n",
      "\n",
      "Val func train loss in epoch 13:0.6934904642403126\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6138259768486023\n",
      "\n",
      "episode 2, val func loss 0.7307726740837097\n",
      "\n",
      "episode 3, val func loss 0.6937440037727356\n",
      "\n",
      "episode 4, val func loss 0.7610414028167725\n",
      "\n",
      "episode 5, val func loss 0.6885179877281189\n",
      "\n",
      "episode 6, val func loss 0.6997690200805664\n",
      "\n",
      "episode 7, val func loss 0.727940022945404\n",
      "\n",
      "episode 8, val func loss 0.6982002258300781\n",
      "\n",
      "episode 9, val func loss 0.6109113097190857\n",
      "\n",
      "episode 10, val func loss 0.710857093334198\n",
      "\n",
      "episode 11, val func loss 0.6873977780342102\n",
      "\n",
      "episode 12, val func loss 0.5997503995895386\n",
      "\n",
      "episode 13, val func loss 0.6586753726005554\n",
      "\n",
      "episode 14, val func loss 0.6449652314186096\n",
      "\n",
      "episode 15, val func loss 0.7535342574119568\n",
      "\n",
      "episode 16, val func loss 0.6085228323936462\n",
      "\n",
      "Val func train loss in epoch 14:0.6805265992879868\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.657241940498352\n",
      "\n",
      "episode 2, val func loss 0.7199511528015137\n",
      "\n",
      "episode 3, val func loss 0.7422904968261719\n",
      "\n",
      "episode 4, val func loss 0.6688652038574219\n",
      "\n",
      "episode 5, val func loss 0.5956974029541016\n",
      "\n",
      "episode 6, val func loss 0.5688384771347046\n",
      "\n",
      "episode 7, val func loss 0.693442702293396\n",
      "\n",
      "episode 8, val func loss 0.7235819101333618\n",
      "\n",
      "episode 9, val func loss 0.7110569477081299\n",
      "\n",
      "episode 10, val func loss 0.6616833209991455\n",
      "\n",
      "episode 11, val func loss 0.6214738488197327\n",
      "\n",
      "episode 12, val func loss 0.6835108399391174\n",
      "\n",
      "episode 13, val func loss 0.6419836282730103\n",
      "\n",
      "episode 14, val func loss 0.590840220451355\n",
      "\n",
      "episode 15, val func loss 0.6968896985054016\n",
      "\n",
      "episode 16, val func loss 0.7082377076148987\n",
      "\n",
      "Val func train loss in epoch 15:0.6678490936756134\n",
      "***********************TIME WAS 4.903197777271271 min*****************************\n",
      "\n",
      "**********************ROUND 111 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.3379250764846802\n",
      "\n",
      "episode 2, policy loss 1.3815813064575195\n",
      "\n",
      "episode 3, policy loss 1.3377501964569092\n",
      "\n",
      "episode 4, policy loss 1.3381750583648682\n",
      "\n",
      "episode 5, policy loss 1.3385199308395386\n",
      "\n",
      "episode 6, policy loss 1.338628888130188\n",
      "\n",
      "episode 7, policy loss 1.3387885093688965\n",
      "\n",
      "episode 8, policy loss 1.3679661750793457\n",
      "\n",
      "episode 9, policy loss 1.3392466306686401\n",
      "\n",
      "episode 10, policy loss 1.3394649028778076\n",
      "\n",
      "episode 11, policy loss 1.3632433414459229\n",
      "\n",
      "episode 12, policy loss 1.3398033380508423\n",
      "\n",
      "episode 13, policy loss 1.3636432886123657\n",
      "\n",
      "episode 14, policy loss 1.339940071105957\n",
      "\n",
      "episode 15, policy loss 1.340000033378601\n",
      "\n",
      "episode 16, policy loss 1.340025782585144\n",
      "\n",
      "Policy train loss in epoch 0:1.3465439081192017\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.3400849103927612\n",
      "\n",
      "episode 2, policy loss 1.340096354484558\n",
      "\n",
      "episode 3, policy loss 1.3401156663894653\n",
      "\n",
      "episode 4, policy loss 1.3638995885849\n",
      "\n",
      "episode 5, policy loss 1.3659722805023193\n",
      "\n",
      "episode 6, policy loss 1.363730549812317\n",
      "\n",
      "episode 7, policy loss 1.3401628732681274\n",
      "\n",
      "episode 8, policy loss 1.3401702642440796\n",
      "\n",
      "episode 9, policy loss 1.3401764631271362\n",
      "\n",
      "episode 10, policy loss 1.3401764631271362\n",
      "\n",
      "episode 11, policy loss 1.3401758670806885\n",
      "\n",
      "episode 12, policy loss 1.340183138847351\n",
      "\n",
      "episode 13, policy loss 1.3656266927719116\n",
      "\n",
      "episode 14, policy loss 1.3401923179626465\n",
      "\n",
      "episode 15, policy loss 1.340185284614563\n",
      "\n",
      "episode 16, policy loss 1.3401885032653809\n",
      "\n",
      "Policy train loss in epoch 1:1.3463210761547089\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.3401755094528198\n",
      "\n",
      "episode 2, policy loss 1.3659954071044922\n",
      "\n",
      "episode 3, policy loss 1.3401720523834229\n",
      "\n",
      "episode 4, policy loss 1.3639403581619263\n",
      "\n",
      "episode 5, policy loss 1.340174674987793\n",
      "\n",
      "episode 6, policy loss 1.340160846710205\n",
      "\n",
      "episode 7, policy loss 1.3401563167572021\n",
      "\n",
      "episode 8, policy loss 1.3656083345413208\n",
      "\n",
      "episode 9, policy loss 1.3637195825576782\n",
      "\n",
      "episode 10, policy loss 1.3401455879211426\n",
      "\n",
      "episode 11, policy loss 1.3401187658309937\n",
      "\n",
      "episode 12, policy loss 1.3400976657867432\n",
      "\n",
      "episode 13, policy loss 1.3401087522506714\n",
      "\n",
      "episode 14, policy loss 1.3400888442993164\n",
      "\n",
      "episode 15, policy loss 1.340090274810791\n",
      "\n",
      "episode 16, policy loss 1.3400546312332153\n",
      "\n",
      "Policy train loss in epoch 2:1.3463004752993584\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.3655030727386475\n",
      "\n",
      "episode 2, policy loss 1.3636014461517334\n",
      "\n",
      "episode 3, policy loss 1.339992880821228\n",
      "\n",
      "episode 4, policy loss 1.3399816751480103\n",
      "\n",
      "episode 5, policy loss 1.3399478197097778\n",
      "\n",
      "episode 6, policy loss 1.365724802017212\n",
      "\n",
      "episode 7, policy loss 1.339844822883606\n",
      "\n",
      "episode 8, policy loss 1.3397810459136963\n",
      "\n",
      "episode 9, policy loss 1.339647889137268\n",
      "\n",
      "episode 10, policy loss 1.3395888805389404\n",
      "\n",
      "episode 11, policy loss 1.3395142555236816\n",
      "\n",
      "episode 12, policy loss 1.3392704725265503\n",
      "\n",
      "episode 13, policy loss 1.3391164541244507\n",
      "\n",
      "episode 14, policy loss 1.3625996112823486\n",
      "\n",
      "episode 15, policy loss 1.3382328748703003\n",
      "\n",
      "episode 16, policy loss 1.337633728981018\n",
      "\n",
      "Policy train loss in epoch 3:1.3456238582730293\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.6579051613807678\n",
      "\n",
      "episode 2, val func loss 0.6781334280967712\n",
      "\n",
      "episode 3, val func loss 0.8780596256256104\n",
      "\n",
      "episode 4, val func loss 0.7241731882095337\n",
      "\n",
      "episode 5, val func loss 0.6653779745101929\n",
      "\n",
      "episode 6, val func loss 0.6715186834335327\n",
      "\n",
      "episode 7, val func loss 0.6814223527908325\n",
      "\n",
      "episode 8, val func loss 0.6114994287490845\n",
      "\n",
      "episode 9, val func loss 0.8313324451446533\n",
      "\n",
      "episode 10, val func loss 0.6741935014724731\n",
      "\n",
      "episode 11, val func loss 0.6334248781204224\n",
      "\n",
      "episode 12, val func loss 0.7033820748329163\n",
      "\n",
      "episode 13, val func loss 0.594779372215271\n",
      "\n",
      "episode 14, val func loss 0.7144942879676819\n",
      "\n",
      "episode 15, val func loss 0.6798860430717468\n",
      "\n",
      "episode 16, val func loss 0.5890132188796997\n",
      "\n",
      "Val func train loss in epoch 0:0.6867872290313244\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.6082497835159302\n",
      "\n",
      "episode 2, val func loss 0.8551453351974487\n",
      "\n",
      "episode 3, val func loss 0.6753266453742981\n",
      "\n",
      "episode 4, val func loss 0.6296828985214233\n",
      "\n",
      "episode 5, val func loss 0.6655451655387878\n",
      "\n",
      "episode 6, val func loss 0.6749030947685242\n",
      "\n",
      "episode 7, val func loss 1.0067697763442993\n",
      "\n",
      "episode 8, val func loss 0.7850179672241211\n",
      "\n",
      "episode 9, val func loss 0.7195470929145813\n",
      "\n",
      "episode 10, val func loss 0.6961116194725037\n",
      "\n",
      "episode 11, val func loss 0.5969870090484619\n",
      "\n",
      "episode 12, val func loss 0.6056227087974548\n",
      "\n",
      "episode 13, val func loss 0.6213248372077942\n",
      "\n",
      "episode 14, val func loss 0.7239910960197449\n",
      "\n",
      "episode 15, val func loss 0.6468647718429565\n",
      "\n",
      "episode 16, val func loss 0.6710437536239624\n",
      "\n",
      "Val func train loss in epoch 1:0.6988833472132683\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7025290727615356\n",
      "\n",
      "episode 2, val func loss 0.6625385284423828\n",
      "\n",
      "episode 3, val func loss 0.711203396320343\n",
      "\n",
      "episode 4, val func loss 0.9055923223495483\n",
      "\n",
      "episode 5, val func loss 0.7502740025520325\n",
      "\n",
      "episode 6, val func loss 0.7342764735221863\n",
      "\n",
      "episode 7, val func loss 0.6941818594932556\n",
      "\n",
      "episode 8, val func loss 0.85884028673172\n",
      "\n",
      "episode 9, val func loss 0.901018500328064\n",
      "\n",
      "episode 10, val func loss 0.7422760725021362\n",
      "\n",
      "episode 11, val func loss 0.7451402544975281\n",
      "\n",
      "episode 12, val func loss 0.6883722543716431\n",
      "\n",
      "episode 13, val func loss 0.8750913739204407\n",
      "\n",
      "episode 14, val func loss 0.7116925716400146\n",
      "\n",
      "episode 15, val func loss 0.6811206936836243\n",
      "\n",
      "episode 16, val func loss 0.7222610116004944\n",
      "\n",
      "Val func train loss in epoch 2:0.7554005421698093\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6025426983833313\n",
      "\n",
      "episode 2, val func loss 0.9778901934623718\n",
      "\n",
      "episode 3, val func loss 0.9043591022491455\n",
      "\n",
      "episode 4, val func loss 0.7660694122314453\n",
      "\n",
      "episode 5, val func loss 0.8661248683929443\n",
      "\n",
      "episode 6, val func loss 0.8043087124824524\n",
      "\n",
      "episode 7, val func loss 0.7771106362342834\n",
      "\n",
      "episode 8, val func loss 0.7243776917457581\n",
      "\n",
      "episode 9, val func loss 0.6836379766464233\n",
      "\n",
      "episode 10, val func loss 0.7479662895202637\n",
      "\n",
      "episode 11, val func loss 0.6602559089660645\n",
      "\n",
      "episode 12, val func loss 0.7335640788078308\n",
      "\n",
      "episode 13, val func loss 0.6930219531059265\n",
      "\n",
      "episode 14, val func loss 0.6490734815597534\n",
      "\n",
      "episode 15, val func loss 0.6626790165901184\n",
      "\n",
      "episode 16, val func loss 0.6733304858207703\n",
      "\n",
      "Val func train loss in epoch 3:0.7453945316374302\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7015020847320557\n",
      "\n",
      "episode 2, val func loss 0.8316802382469177\n",
      "\n",
      "episode 3, val func loss 0.8694103956222534\n",
      "\n",
      "episode 4, val func loss 0.7710801959037781\n",
      "\n",
      "episode 5, val func loss 0.7746815085411072\n",
      "\n",
      "episode 6, val func loss 0.8634130358695984\n",
      "\n",
      "episode 7, val func loss 0.812069296836853\n",
      "\n",
      "episode 8, val func loss 0.7046477198600769\n",
      "\n",
      "episode 9, val func loss 0.7362030148506165\n",
      "\n",
      "episode 10, val func loss 0.8556482195854187\n",
      "\n",
      "episode 11, val func loss 0.6882261037826538\n",
      "\n",
      "episode 12, val func loss 0.7417964339256287\n",
      "\n",
      "episode 13, val func loss 0.796728253364563\n",
      "\n",
      "episode 14, val func loss 0.6191826462745667\n",
      "\n",
      "episode 15, val func loss 0.7906826138496399\n",
      "\n",
      "episode 16, val func loss 0.7078520655632019\n",
      "\n",
      "Val func train loss in epoch 4:0.7665502391755581\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6734012365341187\n",
      "\n",
      "episode 2, val func loss 0.6838895082473755\n",
      "\n",
      "episode 3, val func loss 0.6902124881744385\n",
      "\n",
      "episode 4, val func loss 0.6371736526489258\n",
      "\n",
      "episode 5, val func loss 0.7545245885848999\n",
      "\n",
      "episode 6, val func loss 0.6515145897865295\n",
      "\n",
      "episode 7, val func loss 0.8337408304214478\n",
      "\n",
      "episode 8, val func loss 0.6268129348754883\n",
      "\n",
      "episode 9, val func loss 0.6921460032463074\n",
      "\n",
      "episode 10, val func loss 0.7842724323272705\n",
      "\n",
      "episode 11, val func loss 0.7873753309249878\n",
      "\n",
      "episode 12, val func loss 0.7207019925117493\n",
      "\n",
      "episode 13, val func loss 0.7700156569480896\n",
      "\n",
      "episode 14, val func loss 0.7368466258049011\n",
      "\n",
      "episode 15, val func loss 0.785427451133728\n",
      "\n",
      "episode 16, val func loss 0.7425727248191833\n",
      "\n",
      "Val func train loss in epoch 5:0.7231642529368401\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6993427276611328\n",
      "\n",
      "episode 2, val func loss 0.5537986159324646\n",
      "\n",
      "episode 3, val func loss 0.6697501540184021\n",
      "\n",
      "episode 4, val func loss 0.6877938508987427\n",
      "\n",
      "episode 5, val func loss 0.6461772322654724\n",
      "\n",
      "episode 6, val func loss 0.6622442603111267\n",
      "\n",
      "episode 7, val func loss 0.5953386425971985\n",
      "\n",
      "episode 8, val func loss 0.7242405414581299\n",
      "\n",
      "episode 9, val func loss 0.7996603846549988\n",
      "\n",
      "episode 10, val func loss 0.8784166574478149\n",
      "\n",
      "episode 11, val func loss 0.6535072922706604\n",
      "\n",
      "episode 12, val func loss 0.5975903868675232\n",
      "\n",
      "episode 13, val func loss 0.6993123888969421\n",
      "\n",
      "episode 14, val func loss 0.8193807601928711\n",
      "\n",
      "episode 15, val func loss 0.72743159532547\n",
      "\n",
      "episode 16, val func loss 0.6421136856079102\n",
      "\n",
      "Val func train loss in epoch 6:0.6910061985254288\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6223102807998657\n",
      "\n",
      "episode 2, val func loss 0.7220903635025024\n",
      "\n",
      "episode 3, val func loss 0.5564410090446472\n",
      "\n",
      "episode 4, val func loss 0.7645091414451599\n",
      "\n",
      "episode 5, val func loss 0.6637473702430725\n",
      "\n",
      "episode 6, val func loss 0.8180270791053772\n",
      "\n",
      "episode 7, val func loss 0.7599675059318542\n",
      "\n",
      "episode 8, val func loss 0.7301410436630249\n",
      "\n",
      "episode 9, val func loss 0.6577767133712769\n",
      "\n",
      "episode 10, val func loss 0.8629094362258911\n",
      "\n",
      "episode 11, val func loss 0.6142131090164185\n",
      "\n",
      "episode 12, val func loss 0.8043355941772461\n",
      "\n",
      "episode 13, val func loss 0.7249941825866699\n",
      "\n",
      "episode 14, val func loss 0.7266836762428284\n",
      "\n",
      "episode 15, val func loss 0.7203178405761719\n",
      "\n",
      "episode 16, val func loss 0.7528225779533386\n",
      "\n",
      "Val func train loss in epoch 7:0.7188304327428341\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6826019287109375\n",
      "\n",
      "episode 2, val func loss 0.7690738439559937\n",
      "\n",
      "episode 3, val func loss 0.6172387599945068\n",
      "\n",
      "episode 4, val func loss 0.6948777437210083\n",
      "\n",
      "episode 5, val func loss 0.847351610660553\n",
      "\n",
      "episode 6, val func loss 0.7584215402603149\n",
      "\n",
      "episode 7, val func loss 0.814841091632843\n",
      "\n",
      "episode 8, val func loss 0.737714946269989\n",
      "\n",
      "episode 9, val func loss 0.6665219664573669\n",
      "\n",
      "episode 10, val func loss 0.8910184502601624\n",
      "\n",
      "episode 11, val func loss 0.7613643407821655\n",
      "\n",
      "episode 12, val func loss 0.8275009989738464\n",
      "\n",
      "episode 13, val func loss 0.6455000042915344\n",
      "\n",
      "episode 14, val func loss 0.7600297927856445\n",
      "\n",
      "episode 15, val func loss 0.73002028465271\n",
      "\n",
      "episode 16, val func loss 0.8624342083930969\n",
      "\n",
      "Val func train loss in epoch 8:0.7541569694876671\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6378267407417297\n",
      "\n",
      "episode 2, val func loss 0.683107316493988\n",
      "\n",
      "episode 3, val func loss 0.7762056589126587\n",
      "\n",
      "episode 4, val func loss 0.8297087550163269\n",
      "\n",
      "episode 5, val func loss 0.6666695475578308\n",
      "\n",
      "episode 6, val func loss 0.6410260200500488\n",
      "\n",
      "episode 7, val func loss 0.7704527378082275\n",
      "\n",
      "episode 8, val func loss 0.5597169399261475\n",
      "\n",
      "episode 9, val func loss 0.6432710886001587\n",
      "\n",
      "episode 10, val func loss 0.7591379284858704\n",
      "\n",
      "episode 11, val func loss 0.6833348870277405\n",
      "\n",
      "episode 12, val func loss 0.7354651689529419\n",
      "\n",
      "episode 13, val func loss 0.6564574837684631\n",
      "\n",
      "episode 14, val func loss 0.6860213875770569\n",
      "\n",
      "episode 15, val func loss 0.668914794921875\n",
      "\n",
      "episode 16, val func loss 0.6218737959861755\n",
      "\n",
      "Val func train loss in epoch 9:0.6886993907392025\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7484297752380371\n",
      "\n",
      "episode 2, val func loss 0.6710590124130249\n",
      "\n",
      "episode 3, val func loss 0.5952011942863464\n",
      "\n",
      "episode 4, val func loss 0.7872087359428406\n",
      "\n",
      "episode 5, val func loss 0.7377747297286987\n",
      "\n",
      "episode 6, val func loss 0.9279103875160217\n",
      "\n",
      "episode 7, val func loss 0.7893605828285217\n",
      "\n",
      "episode 8, val func loss 0.7473199367523193\n",
      "\n",
      "episode 9, val func loss 0.7204297780990601\n",
      "\n",
      "episode 10, val func loss 0.6354638338088989\n",
      "\n",
      "episode 11, val func loss 0.9421789646148682\n",
      "\n",
      "episode 12, val func loss 0.6526767015457153\n",
      "\n",
      "episode 13, val func loss 0.7395578622817993\n",
      "\n",
      "episode 14, val func loss 0.7337939143180847\n",
      "\n",
      "episode 15, val func loss 0.757262110710144\n",
      "\n",
      "episode 16, val func loss 0.6879659295082092\n",
      "\n",
      "Val func train loss in epoch 10:0.7420995905995369\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6250714659690857\n",
      "\n",
      "episode 2, val func loss 0.7056518197059631\n",
      "\n",
      "episode 3, val func loss 0.8081579208374023\n",
      "\n",
      "episode 4, val func loss 0.691527247428894\n",
      "\n",
      "episode 5, val func loss 0.8008242249488831\n",
      "\n",
      "episode 6, val func loss 0.7536569237709045\n",
      "\n",
      "episode 7, val func loss 0.6610110998153687\n",
      "\n",
      "episode 8, val func loss 0.6547769904136658\n",
      "\n",
      "episode 9, val func loss 0.630209743976593\n",
      "\n",
      "episode 10, val func loss 0.6047011613845825\n",
      "\n",
      "episode 11, val func loss 0.6964049935340881\n",
      "\n",
      "episode 12, val func loss 0.8774611353874207\n",
      "\n",
      "episode 13, val func loss 0.8204038739204407\n",
      "\n",
      "episode 14, val func loss 0.7542860507965088\n",
      "\n",
      "episode 15, val func loss 0.7266258597373962\n",
      "\n",
      "episode 16, val func loss 0.7102922201156616\n",
      "\n",
      "Val func train loss in epoch 11:0.7200664207339287\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7342973947525024\n",
      "\n",
      "episode 2, val func loss 0.8613525032997131\n",
      "\n",
      "episode 3, val func loss 0.8822574019432068\n",
      "\n",
      "episode 4, val func loss 0.7660305500030518\n",
      "\n",
      "episode 5, val func loss 0.6439768671989441\n",
      "\n",
      "episode 6, val func loss 0.7596736550331116\n",
      "\n",
      "episode 7, val func loss 0.8959604501724243\n",
      "\n",
      "episode 8, val func loss 0.814111053943634\n",
      "\n",
      "episode 9, val func loss 0.7408044934272766\n",
      "\n",
      "episode 10, val func loss 0.6780772805213928\n",
      "\n",
      "episode 11, val func loss 0.9451543092727661\n",
      "\n",
      "episode 12, val func loss 0.7642274498939514\n",
      "\n",
      "episode 13, val func loss 0.7671527862548828\n",
      "\n",
      "episode 14, val func loss 0.7324733138084412\n",
      "\n",
      "episode 15, val func loss 0.5845611095428467\n",
      "\n",
      "episode 16, val func loss 0.6685455441474915\n",
      "\n",
      "Val func train loss in epoch 12:0.7649160102009773\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.7622602581977844\n",
      "\n",
      "episode 2, val func loss 0.862303614616394\n",
      "\n",
      "episode 3, val func loss 0.7521209716796875\n",
      "\n",
      "episode 4, val func loss 0.6746891140937805\n",
      "\n",
      "episode 5, val func loss 0.6844061017036438\n",
      "\n",
      "episode 6, val func loss 0.6587049961090088\n",
      "\n",
      "episode 7, val func loss 0.6461227536201477\n",
      "\n",
      "episode 8, val func loss 0.6586304903030396\n",
      "\n",
      "episode 9, val func loss 0.628244936466217\n",
      "\n",
      "episode 10, val func loss 0.8970639109611511\n",
      "\n",
      "episode 11, val func loss 0.6789258718490601\n",
      "\n",
      "episode 12, val func loss 0.6434621214866638\n",
      "\n",
      "episode 13, val func loss 0.7348957061767578\n",
      "\n",
      "episode 14, val func loss 0.6934409737586975\n",
      "\n",
      "episode 15, val func loss 0.6094284057617188\n",
      "\n",
      "episode 16, val func loss 0.8179486393928528\n",
      "\n",
      "Val func train loss in epoch 13:0.7126655541360378\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7572811245918274\n",
      "\n",
      "episode 2, val func loss 0.7800680994987488\n",
      "\n",
      "episode 3, val func loss 0.6646109819412231\n",
      "\n",
      "episode 4, val func loss 0.6532450318336487\n",
      "\n",
      "episode 5, val func loss 0.6445542573928833\n",
      "\n",
      "episode 6, val func loss 0.735356330871582\n",
      "\n",
      "episode 7, val func loss 0.6657577157020569\n",
      "\n",
      "episode 8, val func loss 0.5816829800605774\n",
      "\n",
      "episode 9, val func loss 0.6303064823150635\n",
      "\n",
      "episode 10, val func loss 0.5744220614433289\n",
      "\n",
      "episode 11, val func loss 0.6950621008872986\n",
      "\n",
      "episode 12, val func loss 0.7239750027656555\n",
      "\n",
      "episode 13, val func loss 0.7291954755783081\n",
      "\n",
      "episode 14, val func loss 0.7309718132019043\n",
      "\n",
      "episode 15, val func loss 0.8715156316757202\n",
      "\n",
      "episode 16, val func loss 0.6374857425689697\n",
      "\n",
      "Val func train loss in epoch 14:0.6922181770205498\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.759797990322113\n",
      "\n",
      "episode 2, val func loss 0.6959660649299622\n",
      "\n",
      "episode 3, val func loss 0.6002171039581299\n",
      "\n",
      "episode 4, val func loss 0.8260970711708069\n",
      "\n",
      "episode 5, val func loss 0.8839749097824097\n",
      "\n",
      "episode 6, val func loss 0.7243548035621643\n",
      "\n",
      "episode 7, val func loss 0.8644253611564636\n",
      "\n",
      "episode 8, val func loss 0.7226521372795105\n",
      "\n",
      "episode 9, val func loss 0.6863550543785095\n",
      "\n",
      "episode 10, val func loss 0.6913227438926697\n",
      "\n",
      "episode 11, val func loss 0.757777750492096\n",
      "\n",
      "episode 12, val func loss 0.6944540143013\n",
      "\n",
      "episode 13, val func loss 0.786074697971344\n",
      "\n",
      "episode 14, val func loss 0.7137584090232849\n",
      "\n",
      "episode 15, val func loss 0.7210537791252136\n",
      "\n",
      "episode 16, val func loss 0.6529497504234314\n",
      "\n",
      "Val func train loss in epoch 15:0.7363269776105881\n",
      "***********************TIME WAS 4.904607347647349 min*****************************\n",
      "\n",
      "**********************ROUND 112 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.0449551343917847\n",
      "\n",
      "episode 2, policy loss 1.0430618524551392\n",
      "\n",
      "episode 3, policy loss 1.038277268409729\n",
      "\n",
      "episode 4, policy loss 1.0264116525650024\n",
      "\n",
      "episode 5, policy loss 1.3463656902313232\n",
      "\n",
      "episode 6, policy loss 1.0136778354644775\n",
      "\n",
      "episode 7, policy loss 1.2457610368728638\n",
      "\n",
      "episode 8, policy loss 1.0369888544082642\n",
      "\n",
      "episode 9, policy loss 1.0420856475830078\n",
      "\n",
      "episode 10, policy loss 1.044769048690796\n",
      "\n",
      "episode 11, policy loss 1.0459040403366089\n",
      "\n",
      "episode 12, policy loss 1.04670250415802\n",
      "\n",
      "episode 13, policy loss 1.047096848487854\n",
      "\n",
      "episode 14, policy loss 1.097862720489502\n",
      "\n",
      "episode 15, policy loss 1.071842074394226\n",
      "\n",
      "episode 16, policy loss 1.0718098878860474\n",
      "\n",
      "Policy train loss in epoch 0:1.0789732560515404\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.0477304458618164\n",
      "\n",
      "episode 2, policy loss 1.0477981567382812\n",
      "\n",
      "episode 3, policy loss 1.0478405952453613\n",
      "\n",
      "episode 4, policy loss 1.0478789806365967\n",
      "\n",
      "episode 5, policy loss 1.098331332206726\n",
      "\n",
      "episode 6, policy loss 1.0478850603103638\n",
      "\n",
      "episode 7, policy loss 1.0478960275650024\n",
      "\n",
      "episode 8, policy loss 1.0721912384033203\n",
      "\n",
      "episode 9, policy loss 1.0478633642196655\n",
      "\n",
      "episode 10, policy loss 1.0479158163070679\n",
      "\n",
      "episode 11, policy loss 1.07308828830719\n",
      "\n",
      "episode 12, policy loss 1.047878384590149\n",
      "\n",
      "episode 13, policy loss 1.0478724241256714\n",
      "\n",
      "episode 14, policy loss 1.0743416547775269\n",
      "\n",
      "episode 15, policy loss 1.0719774961471558\n",
      "\n",
      "episode 16, policy loss 1.0477911233901978\n",
      "\n",
      "Policy train loss in epoch 1:1.0572675243020058\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.0729966163635254\n",
      "\n",
      "episode 2, policy loss 1.0477381944656372\n",
      "\n",
      "episode 3, policy loss 1.0476864576339722\n",
      "\n",
      "episode 4, policy loss 1.0476573705673218\n",
      "\n",
      "episode 5, policy loss 1.047573447227478\n",
      "\n",
      "episode 6, policy loss 1.0739831924438477\n",
      "\n",
      "episode 7, policy loss 1.0474436283111572\n",
      "\n",
      "episode 8, policy loss 1.047337293624878\n",
      "\n",
      "episode 9, policy loss 1.047199010848999\n",
      "\n",
      "episode 10, policy loss 1.0470081567764282\n",
      "\n",
      "episode 11, policy loss 1.0709623098373413\n",
      "\n",
      "episode 12, policy loss 1.0463343858718872\n",
      "\n",
      "episode 13, policy loss 1.0702643394470215\n",
      "\n",
      "episode 14, policy loss 1.0453464984893799\n",
      "\n",
      "episode 15, policy loss 1.0946853160858154\n",
      "\n",
      "episode 16, policy loss 1.0423080921173096\n",
      "\n",
      "Policy train loss in epoch 2:1.056032769382\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.0388635396957397\n",
      "\n",
      "episode 2, policy loss 1.030212640762329\n",
      "\n",
      "episode 3, policy loss 1.0150750875473022\n",
      "\n",
      "episode 4, policy loss 0.9732211232185364\n",
      "\n",
      "episode 5, policy loss 0.9705373644828796\n",
      "\n",
      "episode 6, policy loss 1.0221885442733765\n",
      "\n",
      "episode 7, policy loss 0.975759744644165\n",
      "\n",
      "episode 8, policy loss 0.9787785410881042\n",
      "\n",
      "episode 9, policy loss 0.9650080800056458\n",
      "\n",
      "episode 10, policy loss 1.0313321352005005\n",
      "\n",
      "episode 11, policy loss 0.9705348014831543\n",
      "\n",
      "episode 12, policy loss 0.9729198813438416\n",
      "\n",
      "episode 13, policy loss 0.9622411727905273\n",
      "\n",
      "episode 14, policy loss 0.9956568479537964\n",
      "\n",
      "episode 15, policy loss 0.9685644507408142\n",
      "\n",
      "episode 16, policy loss 0.9554620981216431\n",
      "\n",
      "Policy train loss in epoch 3:0.9891472533345222\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7979452610015869\n",
      "\n",
      "episode 2, val func loss 0.6832202076911926\n",
      "\n",
      "episode 3, val func loss 1.0053865909576416\n",
      "\n",
      "episode 4, val func loss 0.6849134564399719\n",
      "\n",
      "episode 5, val func loss 0.8965584635734558\n",
      "\n",
      "episode 6, val func loss 1.1075395345687866\n",
      "\n",
      "episode 7, val func loss 0.9186814427375793\n",
      "\n",
      "episode 8, val func loss 0.6309288144111633\n",
      "\n",
      "episode 9, val func loss 0.9911920428276062\n",
      "\n",
      "episode 10, val func loss 0.6693019866943359\n",
      "\n",
      "episode 11, val func loss 0.7166673541069031\n",
      "\n",
      "episode 12, val func loss 0.7408831119537354\n",
      "\n",
      "episode 13, val func loss 0.7779801487922668\n",
      "\n",
      "episode 14, val func loss 0.755066454410553\n",
      "\n",
      "episode 15, val func loss 0.6471805572509766\n",
      "\n",
      "episode 16, val func loss 0.7487719058990479\n",
      "\n",
      "Val func train loss in epoch 0:0.7982635833323002\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8156267404556274\n",
      "\n",
      "episode 2, val func loss 0.8771894574165344\n",
      "\n",
      "episode 3, val func loss 0.5916300415992737\n",
      "\n",
      "episode 4, val func loss 0.7907989621162415\n",
      "\n",
      "episode 5, val func loss 0.9716939926147461\n",
      "\n",
      "episode 6, val func loss 0.7669065594673157\n",
      "\n",
      "episode 7, val func loss 0.6902448534965515\n",
      "\n",
      "episode 8, val func loss 0.5572935938835144\n",
      "\n",
      "episode 9, val func loss 0.7004787921905518\n",
      "\n",
      "episode 10, val func loss 0.8077725172042847\n",
      "\n",
      "episode 11, val func loss 0.8134016394615173\n",
      "\n",
      "episode 12, val func loss 0.6448612213134766\n",
      "\n",
      "episode 13, val func loss 0.5816755890846252\n",
      "\n",
      "episode 14, val func loss 0.8783017992973328\n",
      "\n",
      "episode 15, val func loss 0.6503257155418396\n",
      "\n",
      "episode 16, val func loss 0.7802562117576599\n",
      "\n",
      "Val func train loss in epoch 1:0.7449036054313183\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.8425413966178894\n",
      "\n",
      "episode 2, val func loss 0.638120174407959\n",
      "\n",
      "episode 3, val func loss 0.7248526811599731\n",
      "\n",
      "episode 4, val func loss 0.7037966251373291\n",
      "\n",
      "episode 5, val func loss 0.8724315762519836\n",
      "\n",
      "episode 6, val func loss 0.5801495313644409\n",
      "\n",
      "episode 7, val func loss 0.6794995665550232\n",
      "\n",
      "episode 8, val func loss 0.6448398232460022\n",
      "\n",
      "episode 9, val func loss 0.6793250441551208\n",
      "\n",
      "episode 10, val func loss 0.6096984148025513\n",
      "\n",
      "episode 11, val func loss 0.7681788802146912\n",
      "\n",
      "episode 12, val func loss 0.8166975378990173\n",
      "\n",
      "episode 13, val func loss 0.609964907169342\n",
      "\n",
      "episode 14, val func loss 0.740189254283905\n",
      "\n",
      "episode 15, val func loss 0.8236962556838989\n",
      "\n",
      "episode 16, val func loss 0.7634709477424622\n",
      "\n",
      "Val func train loss in epoch 2:0.7185907885432243\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8602444529533386\n",
      "\n",
      "episode 2, val func loss 0.6522740125656128\n",
      "\n",
      "episode 3, val func loss 0.8489280343055725\n",
      "\n",
      "episode 4, val func loss 0.6797753572463989\n",
      "\n",
      "episode 5, val func loss 0.6646144986152649\n",
      "\n",
      "episode 6, val func loss 0.5480390191078186\n",
      "\n",
      "episode 7, val func loss 0.8367334604263306\n",
      "\n",
      "episode 8, val func loss 0.6156288981437683\n",
      "\n",
      "episode 9, val func loss 0.6999841928482056\n",
      "\n",
      "episode 10, val func loss 0.8571471571922302\n",
      "\n",
      "episode 11, val func loss 0.8211565017700195\n",
      "\n",
      "episode 12, val func loss 0.8444565534591675\n",
      "\n",
      "episode 13, val func loss 0.6848894953727722\n",
      "\n",
      "episode 14, val func loss 0.6960542798042297\n",
      "\n",
      "episode 15, val func loss 0.7596566677093506\n",
      "\n",
      "episode 16, val func loss 0.7309297323226929\n",
      "\n",
      "Val func train loss in epoch 3:0.7375320196151733\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8152174353599548\n",
      "\n",
      "episode 2, val func loss 0.6510422229766846\n",
      "\n",
      "episode 3, val func loss 0.9209349155426025\n",
      "\n",
      "episode 4, val func loss 0.6652855277061462\n",
      "\n",
      "episode 5, val func loss 0.7318124771118164\n",
      "\n",
      "episode 6, val func loss 0.6477487683296204\n",
      "\n",
      "episode 7, val func loss 0.6436911225318909\n",
      "\n",
      "episode 8, val func loss 0.691667377948761\n",
      "\n",
      "episode 9, val func loss 0.5521308183670044\n",
      "\n",
      "episode 10, val func loss 0.64067143201828\n",
      "\n",
      "episode 11, val func loss 0.6812685132026672\n",
      "\n",
      "episode 12, val func loss 0.5835000276565552\n",
      "\n",
      "episode 13, val func loss 0.8841615915298462\n",
      "\n",
      "episode 14, val func loss 0.6211827397346497\n",
      "\n",
      "episode 15, val func loss 0.7898955345153809\n",
      "\n",
      "episode 16, val func loss 0.7754090428352356\n",
      "\n",
      "Val func train loss in epoch 4:0.7059762217104435\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6672545671463013\n",
      "\n",
      "episode 2, val func loss 0.67088782787323\n",
      "\n",
      "episode 3, val func loss 0.7137743830680847\n",
      "\n",
      "episode 4, val func loss 0.6348128914833069\n",
      "\n",
      "episode 5, val func loss 0.8167033791542053\n",
      "\n",
      "episode 6, val func loss 0.7497062683105469\n",
      "\n",
      "episode 7, val func loss 0.6112239956855774\n",
      "\n",
      "episode 8, val func loss 0.8723137974739075\n",
      "\n",
      "episode 9, val func loss 0.7532403469085693\n",
      "\n",
      "episode 10, val func loss 0.86864173412323\n",
      "\n",
      "episode 11, val func loss 0.7207368016242981\n",
      "\n",
      "episode 12, val func loss 0.8035104274749756\n",
      "\n",
      "episode 13, val func loss 0.86234450340271\n",
      "\n",
      "episode 14, val func loss 0.7719043493270874\n",
      "\n",
      "episode 15, val func loss 0.6637990474700928\n",
      "\n",
      "episode 16, val func loss 0.7574108242988586\n",
      "\n",
      "Val func train loss in epoch 5:0.7461415715515614\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6881554126739502\n",
      "\n",
      "episode 2, val func loss 0.8533739447593689\n",
      "\n",
      "episode 3, val func loss 0.8331171274185181\n",
      "\n",
      "episode 4, val func loss 0.6789916753768921\n",
      "\n",
      "episode 5, val func loss 0.7772955894470215\n",
      "\n",
      "episode 6, val func loss 0.6297613978385925\n",
      "\n",
      "episode 7, val func loss 0.7537540197372437\n",
      "\n",
      "episode 8, val func loss 0.6604185104370117\n",
      "\n",
      "episode 9, val func loss 0.8891996741294861\n",
      "\n",
      "episode 10, val func loss 0.6621543169021606\n",
      "\n",
      "episode 11, val func loss 0.6454663872718811\n",
      "\n",
      "episode 12, val func loss 0.6078867316246033\n",
      "\n",
      "episode 13, val func loss 0.6540570855140686\n",
      "\n",
      "episode 14, val func loss 0.6983926892280579\n",
      "\n",
      "episode 15, val func loss 0.7295581102371216\n",
      "\n",
      "episode 16, val func loss 0.6674729585647583\n",
      "\n",
      "Val func train loss in epoch 6:0.714315976947546\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7579793930053711\n",
      "\n",
      "episode 2, val func loss 0.7241494655609131\n",
      "\n",
      "episode 3, val func loss 0.633272111415863\n",
      "\n",
      "episode 4, val func loss 0.826555609703064\n",
      "\n",
      "episode 5, val func loss 0.6701198220252991\n",
      "\n",
      "episode 6, val func loss 0.7040150165557861\n",
      "\n",
      "episode 7, val func loss 0.6456591486930847\n",
      "\n",
      "episode 8, val func loss 0.798004686832428\n",
      "\n",
      "episode 9, val func loss 0.9798468351364136\n",
      "\n",
      "episode 10, val func loss 0.6906248927116394\n",
      "\n",
      "episode 11, val func loss 0.6639894247055054\n",
      "\n",
      "episode 12, val func loss 0.80791836977005\n",
      "\n",
      "episode 13, val func loss 0.5792451500892639\n",
      "\n",
      "episode 14, val func loss 0.6791431307792664\n",
      "\n",
      "episode 15, val func loss 0.6731765866279602\n",
      "\n",
      "episode 16, val func loss 0.6519800424575806\n",
      "\n",
      "Val func train loss in epoch 7:0.717854980379343\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6858487725257874\n",
      "\n",
      "episode 2, val func loss 0.5777310132980347\n",
      "\n",
      "episode 3, val func loss 0.8017863631248474\n",
      "\n",
      "episode 4, val func loss 0.7108644247055054\n",
      "\n",
      "episode 5, val func loss 0.7408377528190613\n",
      "\n",
      "episode 6, val func loss 0.7068338394165039\n",
      "\n",
      "episode 7, val func loss 0.6129747033119202\n",
      "\n",
      "episode 8, val func loss 0.7724846005439758\n",
      "\n",
      "episode 9, val func loss 0.6191476583480835\n",
      "\n",
      "episode 10, val func loss 0.966070294380188\n",
      "\n",
      "episode 11, val func loss 0.567705512046814\n",
      "\n",
      "episode 12, val func loss 0.6768357753753662\n",
      "\n",
      "episode 13, val func loss 0.7303998470306396\n",
      "\n",
      "episode 14, val func loss 0.7164111733436584\n",
      "\n",
      "episode 15, val func loss 0.652289092540741\n",
      "\n",
      "episode 16, val func loss 0.7733598947525024\n",
      "\n",
      "Val func train loss in epoch 8:0.7069737948477268\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.750956654548645\n",
      "\n",
      "episode 2, val func loss 0.7155066728591919\n",
      "\n",
      "episode 3, val func loss 0.7352139353752136\n",
      "\n",
      "episode 4, val func loss 0.9416981935501099\n",
      "\n",
      "episode 5, val func loss 0.7041317820549011\n",
      "\n",
      "episode 6, val func loss 0.8645059466362\n",
      "\n",
      "episode 7, val func loss 0.6852906346321106\n",
      "\n",
      "episode 8, val func loss 0.6716344952583313\n",
      "\n",
      "episode 9, val func loss 0.6467498540878296\n",
      "\n",
      "episode 10, val func loss 0.9484710693359375\n",
      "\n",
      "episode 11, val func loss 0.7175682783126831\n",
      "\n",
      "episode 12, val func loss 0.6001892685890198\n",
      "\n",
      "episode 13, val func loss 0.9097609519958496\n",
      "\n",
      "episode 14, val func loss 0.7692091464996338\n",
      "\n",
      "episode 15, val func loss 0.9822043180465698\n",
      "\n",
      "episode 16, val func loss 0.7975842952728271\n",
      "\n",
      "Val func train loss in epoch 9:0.7775422185659409\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.8754695653915405\n",
      "\n",
      "episode 2, val func loss 0.701432466506958\n",
      "\n",
      "episode 3, val func loss 0.6566867828369141\n",
      "\n",
      "episode 4, val func loss 0.8455629944801331\n",
      "\n",
      "episode 5, val func loss 0.899407684803009\n",
      "\n",
      "episode 6, val func loss 0.8991228938102722\n",
      "\n",
      "episode 7, val func loss 0.7688193321228027\n",
      "\n",
      "episode 8, val func loss 0.7253448963165283\n",
      "\n",
      "episode 9, val func loss 0.7742188572883606\n",
      "\n",
      "episode 10, val func loss 0.69722980260849\n",
      "\n",
      "episode 11, val func loss 0.804088830947876\n",
      "\n",
      "episode 12, val func loss 0.6789116263389587\n",
      "\n",
      "episode 13, val func loss 0.6484758257865906\n",
      "\n",
      "episode 14, val func loss 0.8204697370529175\n",
      "\n",
      "episode 15, val func loss 0.686851441860199\n",
      "\n",
      "episode 16, val func loss 0.7080433964729309\n",
      "\n",
      "Val func train loss in epoch 10:0.7618835084140301\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9537078142166138\n",
      "\n",
      "episode 2, val func loss 0.7122758626937866\n",
      "\n",
      "episode 3, val func loss 0.7791235446929932\n",
      "\n",
      "episode 4, val func loss 0.6557130217552185\n",
      "\n",
      "episode 5, val func loss 0.7399081587791443\n",
      "\n",
      "episode 6, val func loss 0.7231677770614624\n",
      "\n",
      "episode 7, val func loss 0.6298179626464844\n",
      "\n",
      "episode 8, val func loss 0.8681831359863281\n",
      "\n",
      "episode 9, val func loss 0.7190122604370117\n",
      "\n",
      "episode 10, val func loss 0.7576358914375305\n",
      "\n",
      "episode 11, val func loss 0.9554710388183594\n",
      "\n",
      "episode 12, val func loss 0.6890161037445068\n",
      "\n",
      "episode 13, val func loss 0.7905532121658325\n",
      "\n",
      "episode 14, val func loss 0.7516112327575684\n",
      "\n",
      "episode 15, val func loss 0.6393463611602783\n",
      "\n",
      "episode 16, val func loss 0.7453470826148987\n",
      "\n",
      "Val func train loss in epoch 11:0.7568681538105011\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.5737022757530212\n",
      "\n",
      "episode 2, val func loss 0.841738760471344\n",
      "\n",
      "episode 3, val func loss 0.6742452383041382\n",
      "\n",
      "episode 4, val func loss 0.75485759973526\n",
      "\n",
      "episode 5, val func loss 0.7183669805526733\n",
      "\n",
      "episode 6, val func loss 0.6717641949653625\n",
      "\n",
      "episode 7, val func loss 0.6198262572288513\n",
      "\n",
      "episode 8, val func loss 0.788345456123352\n",
      "\n",
      "episode 9, val func loss 0.6229597926139832\n",
      "\n",
      "episode 10, val func loss 0.8654873967170715\n",
      "\n",
      "episode 11, val func loss 0.7093380093574524\n",
      "\n",
      "episode 12, val func loss 0.7468204498291016\n",
      "\n",
      "episode 13, val func loss 0.6060127019882202\n",
      "\n",
      "episode 14, val func loss 0.8760396838188171\n",
      "\n",
      "episode 15, val func loss 0.8528954386711121\n",
      "\n",
      "episode 16, val func loss 0.6917814016342163\n",
      "\n",
      "Val func train loss in epoch 12:0.7258863523602486\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6259328126907349\n",
      "\n",
      "episode 2, val func loss 0.715567946434021\n",
      "\n",
      "episode 3, val func loss 0.6368481516838074\n",
      "\n",
      "episode 4, val func loss 0.8371573090553284\n",
      "\n",
      "episode 5, val func loss 0.6087915301322937\n",
      "\n",
      "episode 6, val func loss 0.6987211108207703\n",
      "\n",
      "episode 7, val func loss 0.8979033827781677\n",
      "\n",
      "episode 8, val func loss 0.6389271020889282\n",
      "\n",
      "episode 9, val func loss 0.717418909072876\n",
      "\n",
      "episode 10, val func loss 0.6522181034088135\n",
      "\n",
      "episode 11, val func loss 0.6258672475814819\n",
      "\n",
      "episode 12, val func loss 0.8882619738578796\n",
      "\n",
      "episode 13, val func loss 0.6137908697128296\n",
      "\n",
      "episode 14, val func loss 0.7477221488952637\n",
      "\n",
      "episode 15, val func loss 0.6189969778060913\n",
      "\n",
      "episode 16, val func loss 0.7731053233146667\n",
      "\n",
      "Val func train loss in epoch 13:0.7060769312083721\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7900730967521667\n",
      "\n",
      "episode 2, val func loss 0.6408381462097168\n",
      "\n",
      "episode 3, val func loss 0.5721580982208252\n",
      "\n",
      "episode 4, val func loss 0.6529211401939392\n",
      "\n",
      "episode 5, val func loss 0.7801095843315125\n",
      "\n",
      "episode 6, val func loss 0.6366080045700073\n",
      "\n",
      "episode 7, val func loss 0.5749271512031555\n",
      "\n",
      "episode 8, val func loss 0.6269596815109253\n",
      "\n",
      "episode 9, val func loss 0.6877720355987549\n",
      "\n",
      "episode 10, val func loss 0.722143292427063\n",
      "\n",
      "episode 11, val func loss 0.9602273106575012\n",
      "\n",
      "episode 12, val func loss 0.633831799030304\n",
      "\n",
      "episode 13, val func loss 0.6742868423461914\n",
      "\n",
      "episode 14, val func loss 0.7472096681594849\n",
      "\n",
      "episode 15, val func loss 0.6648872494697571\n",
      "\n",
      "episode 16, val func loss 0.7012052536010742\n",
      "\n",
      "Val func train loss in epoch 14:0.6916348971426487\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.76167231798172\n",
      "\n",
      "episode 2, val func loss 0.6058856248855591\n",
      "\n",
      "episode 3, val func loss 0.6204953789710999\n",
      "\n",
      "episode 4, val func loss 0.7435103058815002\n",
      "\n",
      "episode 5, val func loss 0.6591120362281799\n",
      "\n",
      "episode 6, val func loss 0.6835324168205261\n",
      "\n",
      "episode 7, val func loss 0.6032816767692566\n",
      "\n",
      "episode 8, val func loss 0.8340799808502197\n",
      "\n",
      "episode 9, val func loss 0.6252133250236511\n",
      "\n",
      "episode 10, val func loss 0.7103830575942993\n",
      "\n",
      "episode 11, val func loss 0.6711443662643433\n",
      "\n",
      "episode 12, val func loss 0.6902644038200378\n",
      "\n",
      "episode 13, val func loss 0.9378801584243774\n",
      "\n",
      "episode 14, val func loss 0.6868759989738464\n",
      "\n",
      "episode 15, val func loss 0.7202979326248169\n",
      "\n",
      "episode 16, val func loss 0.6570199131965637\n",
      "\n",
      "Val func train loss in epoch 15:0.7006655558943748\n",
      "***********************TIME WAS 4.905680378278096 min*****************************\n",
      "\n",
      "**********************ROUND 113 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.5336096286773682\n",
      "\n",
      "episode 2, policy loss 1.4762217998504639\n",
      "\n",
      "episode 3, policy loss 1.6818100214004517\n",
      "\n",
      "episode 4, policy loss 1.6415767669677734\n",
      "\n",
      "episode 5, policy loss 1.5453925132751465\n",
      "\n",
      "episode 6, policy loss 1.5066674947738647\n",
      "\n",
      "episode 7, policy loss 1.516124963760376\n",
      "\n",
      "episode 8, policy loss 1.7011237144470215\n",
      "\n",
      "episode 9, policy loss 1.4429689645767212\n",
      "\n",
      "episode 10, policy loss 1.5205167531967163\n",
      "\n",
      "episode 11, policy loss 1.5608102083206177\n",
      "\n",
      "episode 12, policy loss 1.534804344177246\n",
      "\n",
      "episode 13, policy loss 1.6354564428329468\n",
      "\n",
      "episode 14, policy loss 1.586688756942749\n",
      "\n",
      "episode 15, policy loss 1.563125729560852\n",
      "\n",
      "episode 16, policy loss 1.4370535612106323\n",
      "\n",
      "Policy train loss in epoch 0:1.5552469789981842\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.5207401514053345\n",
      "\n",
      "episode 2, policy loss 1.4371347427368164\n",
      "\n",
      "episode 3, policy loss 1.5354559421539307\n",
      "\n",
      "episode 4, policy loss 1.5217316150665283\n",
      "\n",
      "episode 5, policy loss 1.5202044248580933\n",
      "\n",
      "episode 6, policy loss 1.706180214881897\n",
      "\n",
      "episode 7, policy loss 1.703710913658142\n",
      "\n",
      "episode 8, policy loss 1.5920419692993164\n",
      "\n",
      "episode 9, policy loss 1.4441437721252441\n",
      "\n",
      "episode 10, policy loss 1.5616110563278198\n",
      "\n",
      "episode 11, policy loss 1.584517478942871\n",
      "\n",
      "episode 12, policy loss 1.6543155908584595\n",
      "\n",
      "episode 13, policy loss 1.5577456951141357\n",
      "\n",
      "episode 14, policy loss 1.5508636236190796\n",
      "\n",
      "episode 15, policy loss 1.5053954124450684\n",
      "\n",
      "episode 16, policy loss 1.6248562335968018\n",
      "\n",
      "Policy train loss in epoch 1:1.5637905523180962\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.5464280843734741\n",
      "\n",
      "episode 2, policy loss 1.4993319511413574\n",
      "\n",
      "episode 3, policy loss 1.5498515367507935\n",
      "\n",
      "episode 4, policy loss 1.4608255624771118\n",
      "\n",
      "episode 5, policy loss 1.6345348358154297\n",
      "\n",
      "episode 6, policy loss 1.8132706880569458\n",
      "\n",
      "episode 7, policy loss 1.5633397102355957\n",
      "\n",
      "episode 8, policy loss 1.5192897319793701\n",
      "\n",
      "episode 9, policy loss 1.5092425346374512\n",
      "\n",
      "episode 10, policy loss 1.5023328065872192\n",
      "\n",
      "episode 11, policy loss 1.5788928270339966\n",
      "\n",
      "episode 12, policy loss 1.5115478038787842\n",
      "\n",
      "episode 13, policy loss 1.4287906885147095\n",
      "\n",
      "episode 14, policy loss 1.4385043382644653\n",
      "\n",
      "episode 15, policy loss 1.6997044086456299\n",
      "\n",
      "episode 16, policy loss 1.582540512084961\n",
      "\n",
      "Policy train loss in epoch 2:1.552401751279831\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.5834795236587524\n",
      "\n",
      "episode 2, policy loss 1.5326405763626099\n",
      "\n",
      "episode 3, policy loss 1.5541892051696777\n",
      "\n",
      "episode 4, policy loss 1.5595080852508545\n",
      "\n",
      "episode 5, policy loss 1.4431567192077637\n",
      "\n",
      "episode 6, policy loss 1.5188713073730469\n",
      "\n",
      "episode 7, policy loss 1.4352614879608154\n",
      "\n",
      "episode 8, policy loss 1.520084023475647\n",
      "\n",
      "episode 9, policy loss 1.6336427927017212\n",
      "\n",
      "episode 10, policy loss 1.6554384231567383\n",
      "\n",
      "episode 11, policy loss 1.7021428346633911\n",
      "\n",
      "episode 12, policy loss 1.5178452730178833\n",
      "\n",
      "episode 13, policy loss 1.5599054098129272\n",
      "\n",
      "episode 14, policy loss 1.5886783599853516\n",
      "\n",
      "episode 15, policy loss 1.5084178447723389\n",
      "\n",
      "episode 16, policy loss 1.6999744176864624\n",
      "\n",
      "Policy train loss in epoch 3:1.5633272677659988\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 3.0048158168792725\n",
      "\n",
      "episode 2, val func loss 2.7718112468719482\n",
      "\n",
      "episode 3, val func loss 3.0098154544830322\n",
      "\n",
      "episode 4, val func loss 2.434110164642334\n",
      "\n",
      "episode 5, val func loss 2.79176664352417\n",
      "\n",
      "episode 6, val func loss 2.967271327972412\n",
      "\n",
      "episode 7, val func loss 3.0088980197906494\n",
      "\n",
      "episode 8, val func loss 2.0113348960876465\n",
      "\n",
      "episode 9, val func loss 2.2800681591033936\n",
      "\n",
      "episode 10, val func loss 2.791714906692505\n",
      "\n",
      "episode 11, val func loss 2.7518460750579834\n",
      "\n",
      "episode 12, val func loss 3.5865681171417236\n",
      "\n",
      "episode 13, val func loss 2.772915840148926\n",
      "\n",
      "episode 14, val func loss 3.5447404384613037\n",
      "\n",
      "episode 15, val func loss 2.611199378967285\n",
      "\n",
      "episode 16, val func loss 2.6526331901550293\n",
      "\n",
      "Val func train loss in epoch 0:2.811969354748726\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.9170199632644653\n",
      "\n",
      "episode 2, val func loss 2.2721855640411377\n",
      "\n",
      "episode 3, val func loss 3.3009865283966064\n",
      "\n",
      "episode 4, val func loss 3.2438740730285645\n",
      "\n",
      "episode 5, val func loss 2.886118173599243\n",
      "\n",
      "episode 6, val func loss 2.8192715644836426\n",
      "\n",
      "episode 7, val func loss 2.8102099895477295\n",
      "\n",
      "episode 8, val func loss 2.721083164215088\n",
      "\n",
      "episode 9, val func loss 3.4691779613494873\n",
      "\n",
      "episode 10, val func loss 2.8219332695007324\n",
      "\n",
      "episode 11, val func loss 2.9069366455078125\n",
      "\n",
      "episode 12, val func loss 2.908064126968384\n",
      "\n",
      "episode 13, val func loss 3.3411660194396973\n",
      "\n",
      "episode 14, val func loss 2.7012388706207275\n",
      "\n",
      "episode 15, val func loss 2.9420969486236572\n",
      "\n",
      "episode 16, val func loss 2.638118028640747\n",
      "\n",
      "Val func train loss in epoch 1:2.8562175557017326\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 3.3197476863861084\n",
      "\n",
      "episode 2, val func loss 2.709585189819336\n",
      "\n",
      "episode 3, val func loss 2.6648359298706055\n",
      "\n",
      "episode 4, val func loss 2.731292486190796\n",
      "\n",
      "episode 5, val func loss 2.6879382133483887\n",
      "\n",
      "episode 6, val func loss 3.090785503387451\n",
      "\n",
      "episode 7, val func loss 2.9502148628234863\n",
      "\n",
      "episode 8, val func loss 2.8500723838806152\n",
      "\n",
      "episode 9, val func loss 2.9272024631500244\n",
      "\n",
      "episode 10, val func loss 3.340010643005371\n",
      "\n",
      "episode 11, val func loss 2.9107401371002197\n",
      "\n",
      "episode 12, val func loss 2.190863847732544\n",
      "\n",
      "episode 13, val func loss 2.749600410461426\n",
      "\n",
      "episode 14, val func loss 2.166334867477417\n",
      "\n",
      "episode 15, val func loss 2.577014684677124\n",
      "\n",
      "episode 16, val func loss 2.700953722000122\n",
      "\n",
      "Val func train loss in epoch 2:2.7854495644569397\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.639225482940674\n",
      "\n",
      "episode 2, val func loss 2.680800676345825\n",
      "\n",
      "episode 3, val func loss 3.132277727127075\n",
      "\n",
      "episode 4, val func loss 3.4577908515930176\n",
      "\n",
      "episode 5, val func loss 2.7208948135375977\n",
      "\n",
      "episode 6, val func loss 2.6991806030273438\n",
      "\n",
      "episode 7, val func loss 2.84883713722229\n",
      "\n",
      "episode 8, val func loss 3.1901564598083496\n",
      "\n",
      "episode 9, val func loss 2.9551610946655273\n",
      "\n",
      "episode 10, val func loss 2.2400736808776855\n",
      "\n",
      "episode 11, val func loss 2.7203078269958496\n",
      "\n",
      "episode 12, val func loss 2.2020132541656494\n",
      "\n",
      "episode 13, val func loss 2.8324737548828125\n",
      "\n",
      "episode 14, val func loss 2.4572129249572754\n",
      "\n",
      "episode 15, val func loss 2.6408774852752686\n",
      "\n",
      "episode 16, val func loss 2.65263295173645\n",
      "\n",
      "Val func train loss in epoch 3:2.754369795322418\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.7587602138519287\n",
      "\n",
      "episode 2, val func loss 2.700207233428955\n",
      "\n",
      "episode 3, val func loss 2.7987287044525146\n",
      "\n",
      "episode 4, val func loss 2.1737234592437744\n",
      "\n",
      "episode 5, val func loss 2.4998414516448975\n",
      "\n",
      "episode 6, val func loss 2.949583053588867\n",
      "\n",
      "episode 7, val func loss 2.9223082065582275\n",
      "\n",
      "episode 8, val func loss 2.8203206062316895\n",
      "\n",
      "episode 9, val func loss 2.86218523979187\n",
      "\n",
      "episode 10, val func loss 3.4353229999542236\n",
      "\n",
      "episode 11, val func loss 3.017091989517212\n",
      "\n",
      "episode 12, val func loss 2.671231746673584\n",
      "\n",
      "episode 13, val func loss 2.3034512996673584\n",
      "\n",
      "episode 14, val func loss 3.3158814907073975\n",
      "\n",
      "episode 15, val func loss 2.5636606216430664\n",
      "\n",
      "episode 16, val func loss 2.9428791999816895\n",
      "\n",
      "Val func train loss in epoch 4:2.7959485948085785\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 3.451303720474243\n",
      "\n",
      "episode 2, val func loss 2.774594306945801\n",
      "\n",
      "episode 3, val func loss 3.0507636070251465\n",
      "\n",
      "episode 4, val func loss 2.564959764480591\n",
      "\n",
      "episode 5, val func loss 2.695878505706787\n",
      "\n",
      "episode 6, val func loss 2.89917254447937\n",
      "\n",
      "episode 7, val func loss 3.4301865100860596\n",
      "\n",
      "episode 8, val func loss 2.1275861263275146\n",
      "\n",
      "episode 9, val func loss 2.8711421489715576\n",
      "\n",
      "episode 10, val func loss 2.7888236045837402\n",
      "\n",
      "episode 11, val func loss 2.773139715194702\n",
      "\n",
      "episode 12, val func loss 2.710963249206543\n",
      "\n",
      "episode 13, val func loss 2.767845630645752\n",
      "\n",
      "episode 14, val func loss 3.00927996635437\n",
      "\n",
      "episode 15, val func loss 2.299941301345825\n",
      "\n",
      "episode 16, val func loss 3.531825304031372\n",
      "\n",
      "Val func train loss in epoch 5:2.859212875366211\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.3726706504821777\n",
      "\n",
      "episode 2, val func loss 2.9435837268829346\n",
      "\n",
      "episode 3, val func loss 2.9482181072235107\n",
      "\n",
      "episode 4, val func loss 2.680527448654175\n",
      "\n",
      "episode 5, val func loss 3.1796443462371826\n",
      "\n",
      "episode 6, val func loss 2.7975945472717285\n",
      "\n",
      "episode 7, val func loss 2.208836317062378\n",
      "\n",
      "episode 8, val func loss 3.7537059783935547\n",
      "\n",
      "episode 9, val func loss 2.8046483993530273\n",
      "\n",
      "episode 10, val func loss 3.0919501781463623\n",
      "\n",
      "episode 11, val func loss 2.8892569541931152\n",
      "\n",
      "episode 12, val func loss 2.836681604385376\n",
      "\n",
      "episode 13, val func loss 2.9976980686187744\n",
      "\n",
      "episode 14, val func loss 3.0101802349090576\n",
      "\n",
      "episode 15, val func loss 2.5142874717712402\n",
      "\n",
      "episode 16, val func loss 2.5828421115875244\n",
      "\n",
      "Val func train loss in epoch 6:2.8507703840732574\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 2.5482873916625977\n",
      "\n",
      "episode 2, val func loss 2.666921854019165\n",
      "\n",
      "episode 3, val func loss 2.5076706409454346\n",
      "\n",
      "episode 4, val func loss 2.610910654067993\n",
      "\n",
      "episode 5, val func loss 2.659236192703247\n",
      "\n",
      "episode 6, val func loss 2.1083052158355713\n",
      "\n",
      "episode 7, val func loss 2.8753795623779297\n",
      "\n",
      "episode 8, val func loss 3.0536513328552246\n",
      "\n",
      "episode 9, val func loss 3.142706871032715\n",
      "\n",
      "episode 10, val func loss 2.74686336517334\n",
      "\n",
      "episode 11, val func loss 3.1118969917297363\n",
      "\n",
      "episode 12, val func loss 2.8082966804504395\n",
      "\n",
      "episode 13, val func loss 2.715059518814087\n",
      "\n",
      "episode 14, val func loss 2.0741684436798096\n",
      "\n",
      "episode 15, val func loss 3.3121070861816406\n",
      "\n",
      "episode 16, val func loss 2.685154914855957\n",
      "\n",
      "Val func train loss in epoch 7:2.7266635447740555\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.7077322006225586\n",
      "\n",
      "episode 2, val func loss 3.135613441467285\n",
      "\n",
      "episode 3, val func loss 3.2102482318878174\n",
      "\n",
      "episode 4, val func loss 3.274691104888916\n",
      "\n",
      "episode 5, val func loss 2.68623948097229\n",
      "\n",
      "episode 6, val func loss 3.1368048191070557\n",
      "\n",
      "episode 7, val func loss 2.6505420207977295\n",
      "\n",
      "episode 8, val func loss 2.570746898651123\n",
      "\n",
      "episode 9, val func loss 2.090928554534912\n",
      "\n",
      "episode 10, val func loss 2.7788822650909424\n",
      "\n",
      "episode 11, val func loss 2.6669061183929443\n",
      "\n",
      "episode 12, val func loss 2.442694664001465\n",
      "\n",
      "episode 13, val func loss 2.7296266555786133\n",
      "\n",
      "episode 14, val func loss 2.2096540927886963\n",
      "\n",
      "episode 15, val func loss 2.6926846504211426\n",
      "\n",
      "episode 16, val func loss 2.8349711894989014\n",
      "\n",
      "Val func train loss in epoch 8:2.7386853992938995\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 2.4832406044006348\n",
      "\n",
      "episode 2, val func loss 2.461207866668701\n",
      "\n",
      "episode 3, val func loss 2.851036787033081\n",
      "\n",
      "episode 4, val func loss 3.0546364784240723\n",
      "\n",
      "episode 5, val func loss 2.090538501739502\n",
      "\n",
      "episode 6, val func loss 2.1637985706329346\n",
      "\n",
      "episode 7, val func loss 3.380906581878662\n",
      "\n",
      "episode 8, val func loss 2.9312286376953125\n",
      "\n",
      "episode 9, val func loss 2.7500417232513428\n",
      "\n",
      "episode 10, val func loss 2.5458548069000244\n",
      "\n",
      "episode 11, val func loss 3.2611303329467773\n",
      "\n",
      "episode 12, val func loss 3.0980873107910156\n",
      "\n",
      "episode 13, val func loss 2.7267470359802246\n",
      "\n",
      "episode 14, val func loss 2.8972554206848145\n",
      "\n",
      "episode 15, val func loss 3.3450865745544434\n",
      "\n",
      "episode 16, val func loss 2.5163841247558594\n",
      "\n",
      "Val func train loss in epoch 9:2.7848238348960876\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.821465492248535\n",
      "\n",
      "episode 2, val func loss 2.23887300491333\n",
      "\n",
      "episode 3, val func loss 2.8476953506469727\n",
      "\n",
      "episode 4, val func loss 3.7339553833007812\n",
      "\n",
      "episode 5, val func loss 2.8704376220703125\n",
      "\n",
      "episode 6, val func loss 2.825164794921875\n",
      "\n",
      "episode 7, val func loss 3.327477216720581\n",
      "\n",
      "episode 8, val func loss 2.3927383422851562\n",
      "\n",
      "episode 9, val func loss 3.0126960277557373\n",
      "\n",
      "episode 10, val func loss 3.0019352436065674\n",
      "\n",
      "episode 11, val func loss 2.8945631980895996\n",
      "\n",
      "episode 12, val func loss 2.176492929458618\n",
      "\n",
      "episode 13, val func loss 3.3200206756591797\n",
      "\n",
      "episode 14, val func loss 2.794955015182495\n",
      "\n",
      "episode 15, val func loss 2.857004404067993\n",
      "\n",
      "episode 16, val func loss 2.798921823501587\n",
      "\n",
      "Val func train loss in epoch 10:2.8696497827768326\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 2.4478414058685303\n",
      "\n",
      "episode 2, val func loss 3.10964298248291\n",
      "\n",
      "episode 3, val func loss 2.654867172241211\n",
      "\n",
      "episode 4, val func loss 3.2004716396331787\n",
      "\n",
      "episode 5, val func loss 3.187774658203125\n",
      "\n",
      "episode 6, val func loss 2.628797769546509\n",
      "\n",
      "episode 7, val func loss 2.3376317024230957\n",
      "\n",
      "episode 8, val func loss 2.6646759510040283\n",
      "\n",
      "episode 9, val func loss 2.1609036922454834\n",
      "\n",
      "episode 10, val func loss 2.9816079139709473\n",
      "\n",
      "episode 11, val func loss 3.230684995651245\n",
      "\n",
      "episode 12, val func loss 2.5180611610412598\n",
      "\n",
      "episode 13, val func loss 2.4066104888916016\n",
      "\n",
      "episode 14, val func loss 3.239107847213745\n",
      "\n",
      "episode 15, val func loss 2.7347869873046875\n",
      "\n",
      "episode 16, val func loss 2.6892197132110596\n",
      "\n",
      "Val func train loss in epoch 11:2.7620428800582886\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 2.2934176921844482\n",
      "\n",
      "episode 2, val func loss 2.740619421005249\n",
      "\n",
      "episode 3, val func loss 2.60520076751709\n",
      "\n",
      "episode 4, val func loss 2.9387757778167725\n",
      "\n",
      "episode 5, val func loss 2.52984619140625\n",
      "\n",
      "episode 6, val func loss 2.7508130073547363\n",
      "\n",
      "episode 7, val func loss 2.5306901931762695\n",
      "\n",
      "episode 8, val func loss 2.679899215698242\n",
      "\n",
      "episode 9, val func loss 2.6532628536224365\n",
      "\n",
      "episode 10, val func loss 2.9391672611236572\n",
      "\n",
      "episode 11, val func loss 3.2260658740997314\n",
      "\n",
      "episode 12, val func loss 2.3535494804382324\n",
      "\n",
      "episode 13, val func loss 2.5374486446380615\n",
      "\n",
      "episode 14, val func loss 2.855607748031616\n",
      "\n",
      "episode 15, val func loss 3.4962456226348877\n",
      "\n",
      "episode 16, val func loss 2.727875232696533\n",
      "\n",
      "Val func train loss in epoch 12:2.7411553114652634\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 2.879775285720825\n",
      "\n",
      "episode 2, val func loss 2.951158285140991\n",
      "\n",
      "episode 3, val func loss 3.0650084018707275\n",
      "\n",
      "episode 4, val func loss 3.282227039337158\n",
      "\n",
      "episode 5, val func loss 3.091965436935425\n",
      "\n",
      "episode 6, val func loss 2.149092674255371\n",
      "\n",
      "episode 7, val func loss 2.8891584873199463\n",
      "\n",
      "episode 8, val func loss 2.7811853885650635\n",
      "\n",
      "episode 9, val func loss 2.8878002166748047\n",
      "\n",
      "episode 10, val func loss 2.4853901863098145\n",
      "\n",
      "episode 11, val func loss 3.092254400253296\n",
      "\n",
      "episode 12, val func loss 2.7946267127990723\n",
      "\n",
      "episode 13, val func loss 2.7490973472595215\n",
      "\n",
      "episode 14, val func loss 2.467172145843506\n",
      "\n",
      "episode 15, val func loss 1.9786648750305176\n",
      "\n",
      "episode 16, val func loss 2.752274990081787\n",
      "\n",
      "Val func train loss in epoch 13:2.768553242087364\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.177490234375\n",
      "\n",
      "episode 2, val func loss 2.676172971725464\n",
      "\n",
      "episode 3, val func loss 3.260258913040161\n",
      "\n",
      "episode 4, val func loss 2.7015204429626465\n",
      "\n",
      "episode 5, val func loss 3.1449060440063477\n",
      "\n",
      "episode 6, val func loss 2.737259864807129\n",
      "\n",
      "episode 7, val func loss 2.676867723464966\n",
      "\n",
      "episode 8, val func loss 2.6679434776306152\n",
      "\n",
      "episode 9, val func loss 2.6366498470306396\n",
      "\n",
      "episode 10, val func loss 2.7165844440460205\n",
      "\n",
      "episode 11, val func loss 3.0019607543945312\n",
      "\n",
      "episode 12, val func loss 2.7378594875335693\n",
      "\n",
      "episode 13, val func loss 3.1169753074645996\n",
      "\n",
      "episode 14, val func loss 2.5825302600860596\n",
      "\n",
      "episode 15, val func loss 2.6141693592071533\n",
      "\n",
      "episode 16, val func loss 2.203150987625122\n",
      "\n",
      "Val func train loss in epoch 14:2.7282687574625015\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 3.0397818088531494\n",
      "\n",
      "episode 2, val func loss 3.0953755378723145\n",
      "\n",
      "episode 3, val func loss 2.8417274951934814\n",
      "\n",
      "episode 4, val func loss 2.5672757625579834\n",
      "\n",
      "episode 5, val func loss 2.1264874935150146\n",
      "\n",
      "episode 6, val func loss 2.8436033725738525\n",
      "\n",
      "episode 7, val func loss 2.84875750541687\n",
      "\n",
      "episode 8, val func loss 2.236635684967041\n",
      "\n",
      "episode 9, val func loss 2.790149211883545\n",
      "\n",
      "episode 10, val func loss 3.1451306343078613\n",
      "\n",
      "episode 11, val func loss 2.8226773738861084\n",
      "\n",
      "episode 12, val func loss 2.6252288818359375\n",
      "\n",
      "episode 13, val func loss 2.6427719593048096\n",
      "\n",
      "episode 14, val func loss 3.3901100158691406\n",
      "\n",
      "episode 15, val func loss 2.713346004486084\n",
      "\n",
      "episode 16, val func loss 2.6467137336730957\n",
      "\n",
      "Val func train loss in epoch 15:2.773485779762268\n",
      "***********************TIME WAS 4.906836998462677 min*****************************\n",
      "\n",
      "**********************ROUND 114 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.15110939741134644\n",
      "\n",
      "episode 2, policy loss -0.2195412814617157\n",
      "\n",
      "episode 3, policy loss -0.19296254217624664\n",
      "\n",
      "episode 4, policy loss -0.152993306517601\n",
      "\n",
      "episode 5, policy loss -0.1651126891374588\n",
      "\n",
      "episode 6, policy loss -0.1948448270559311\n",
      "\n",
      "episode 7, policy loss -0.1698348969221115\n",
      "\n",
      "episode 8, policy loss -0.22101451456546783\n",
      "\n",
      "episode 9, policy loss -0.19653265178203583\n",
      "\n",
      "episode 10, policy loss -0.1948450654745102\n",
      "\n",
      "episode 11, policy loss -0.22130060195922852\n",
      "\n",
      "episode 12, policy loss -0.22146528959274292\n",
      "\n",
      "episode 13, policy loss -0.19543178379535675\n",
      "\n",
      "episode 14, policy loss -0.19542145729064941\n",
      "\n",
      "episode 15, policy loss -0.19485841691493988\n",
      "\n",
      "episode 16, policy loss -0.19429102540016174\n",
      "\n",
      "Policy train loss in epoch 0:-0.19259748421609402\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.19589005410671234\n",
      "\n",
      "episode 2, policy loss -0.22157691419124603\n",
      "\n",
      "episode 3, policy loss -0.22160090506076813\n",
      "\n",
      "episode 4, policy loss -0.17199377715587616\n",
      "\n",
      "episode 5, policy loss -0.17064215242862701\n",
      "\n",
      "episode 6, policy loss -0.169318288564682\n",
      "\n",
      "episode 7, policy loss -0.19510293006896973\n",
      "\n",
      "episode 8, policy loss -0.1943722814321518\n",
      "\n",
      "episode 9, policy loss -0.1949576884508133\n",
      "\n",
      "episode 10, policy loss -0.19570933282375336\n",
      "\n",
      "episode 11, policy loss -0.17008961737155914\n",
      "\n",
      "episode 12, policy loss -0.22164979577064514\n",
      "\n",
      "episode 13, policy loss -0.196915864944458\n",
      "\n",
      "episode 14, policy loss -0.22164344787597656\n",
      "\n",
      "episode 15, policy loss -0.19558504223823547\n",
      "\n",
      "episode 16, policy loss -0.19558517634868622\n",
      "\n",
      "Policy train loss in epoch 1:-0.19578957930207253\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.17010316252708435\n",
      "\n",
      "episode 2, policy loss -0.19693537056446075\n",
      "\n",
      "episode 3, policy loss -0.19557933509349823\n",
      "\n",
      "episode 4, policy loss -0.2216557413339615\n",
      "\n",
      "episode 5, policy loss -0.17072361707687378\n",
      "\n",
      "episode 6, policy loss -0.22166593372821808\n",
      "\n",
      "episode 7, policy loss -0.22167199850082397\n",
      "\n",
      "episode 8, policy loss -0.16935409605503082\n",
      "\n",
      "episode 9, policy loss -0.19439765810966492\n",
      "\n",
      "episode 10, policy loss -0.17205862700939178\n",
      "\n",
      "episode 11, policy loss -0.2216673642396927\n",
      "\n",
      "episode 12, policy loss -0.19603374600410461\n",
      "\n",
      "episode 13, policy loss -0.19513243436813354\n",
      "\n",
      "episode 14, policy loss -0.19499675929546356\n",
      "\n",
      "episode 15, policy loss -0.1956038475036621\n",
      "\n",
      "episode 16, policy loss -0.1957464963197708\n",
      "\n",
      "Policy train loss in epoch 2:-0.19583288673311472\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.22168441116809845\n",
      "\n",
      "episode 2, policy loss -0.19516302645206451\n",
      "\n",
      "episode 3, policy loss -0.22167439758777618\n",
      "\n",
      "episode 4, policy loss -0.19497905671596527\n",
      "\n",
      "episode 5, policy loss -0.19559288024902344\n",
      "\n",
      "episode 6, policy loss -0.19559437036514282\n",
      "\n",
      "episode 7, policy loss -0.22167082130908966\n",
      "\n",
      "episode 8, policy loss -0.1701231300830841\n",
      "\n",
      "episode 9, policy loss -0.1720648854970932\n",
      "\n",
      "episode 10, policy loss -0.22167959809303284\n",
      "\n",
      "episode 11, policy loss -0.19606426358222961\n",
      "\n",
      "episode 12, policy loss -0.19694659113883972\n",
      "\n",
      "episode 13, policy loss -0.1957530379295349\n",
      "\n",
      "episode 14, policy loss -0.19439290463924408\n",
      "\n",
      "episode 15, policy loss -0.17072437703609467\n",
      "\n",
      "episode 16, policy loss -0.1693793535232544\n",
      "\n",
      "Policy train loss in epoch 3:-0.195842944085598\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.3456501960754395\n",
      "\n",
      "episode 2, val func loss 0.9534932374954224\n",
      "\n",
      "episode 3, val func loss 0.933370053768158\n",
      "\n",
      "episode 4, val func loss 1.129450798034668\n",
      "\n",
      "episode 5, val func loss 0.8080583810806274\n",
      "\n",
      "episode 6, val func loss 0.9823060631752014\n",
      "\n",
      "episode 7, val func loss 0.9170776009559631\n",
      "\n",
      "episode 8, val func loss 0.9182137250900269\n",
      "\n",
      "episode 9, val func loss 0.9127603769302368\n",
      "\n",
      "episode 10, val func loss 0.9866907000541687\n",
      "\n",
      "episode 11, val func loss 1.0547057390213013\n",
      "\n",
      "episode 12, val func loss 0.683890163898468\n",
      "\n",
      "episode 13, val func loss 0.646573543548584\n",
      "\n",
      "episode 14, val func loss 0.8050104379653931\n",
      "\n",
      "episode 15, val func loss 0.7678893804550171\n",
      "\n",
      "episode 16, val func loss 0.72678142786026\n",
      "\n",
      "Val func train loss in epoch 0:0.9107451140880585\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.8544185757637024\n",
      "\n",
      "episode 2, val func loss 0.6899430155754089\n",
      "\n",
      "episode 3, val func loss 0.8494763970375061\n",
      "\n",
      "episode 4, val func loss 0.8552236557006836\n",
      "\n",
      "episode 5, val func loss 0.8060357570648193\n",
      "\n",
      "episode 6, val func loss 0.9697234034538269\n",
      "\n",
      "episode 7, val func loss 0.9763713479042053\n",
      "\n",
      "episode 8, val func loss 0.9059829115867615\n",
      "\n",
      "episode 9, val func loss 0.897313117980957\n",
      "\n",
      "episode 10, val func loss 0.9700791835784912\n",
      "\n",
      "episode 11, val func loss 0.8666660785675049\n",
      "\n",
      "episode 12, val func loss 0.8848392963409424\n",
      "\n",
      "episode 13, val func loss 0.7705721259117126\n",
      "\n",
      "episode 14, val func loss 0.6686584949493408\n",
      "\n",
      "episode 15, val func loss 0.7657824158668518\n",
      "\n",
      "episode 16, val func loss 0.6969388723373413\n",
      "\n",
      "Val func train loss in epoch 1:0.8392515406012535\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6507737040519714\n",
      "\n",
      "episode 2, val func loss 0.7833020687103271\n",
      "\n",
      "episode 3, val func loss 0.8952462673187256\n",
      "\n",
      "episode 4, val func loss 0.7001562118530273\n",
      "\n",
      "episode 5, val func loss 0.8075886964797974\n",
      "\n",
      "episode 6, val func loss 0.6152188181877136\n",
      "\n",
      "episode 7, val func loss 0.8184492588043213\n",
      "\n",
      "episode 8, val func loss 0.8928815126419067\n",
      "\n",
      "episode 9, val func loss 0.6405037641525269\n",
      "\n",
      "episode 10, val func loss 0.7032458186149597\n",
      "\n",
      "episode 11, val func loss 0.7563336491584778\n",
      "\n",
      "episode 12, val func loss 0.8750317692756653\n",
      "\n",
      "episode 13, val func loss 0.9341211915016174\n",
      "\n",
      "episode 14, val func loss 0.8211226463317871\n",
      "\n",
      "episode 15, val func loss 0.781147837638855\n",
      "\n",
      "episode 16, val func loss 0.9360681772232056\n",
      "\n",
      "Val func train loss in epoch 2:0.7881994619965553\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.8054718375205994\n",
      "\n",
      "episode 2, val func loss 0.970719575881958\n",
      "\n",
      "episode 3, val func loss 0.6299190521240234\n",
      "\n",
      "episode 4, val func loss 0.8298706412315369\n",
      "\n",
      "episode 5, val func loss 0.7104201912879944\n",
      "\n",
      "episode 6, val func loss 0.7600792646408081\n",
      "\n",
      "episode 7, val func loss 0.6650624871253967\n",
      "\n",
      "episode 8, val func loss 0.8041588664054871\n",
      "\n",
      "episode 9, val func loss 0.5911594033241272\n",
      "\n",
      "episode 10, val func loss 0.5774660706520081\n",
      "\n",
      "episode 11, val func loss 0.8591693639755249\n",
      "\n",
      "episode 12, val func loss 0.7465909123420715\n",
      "\n",
      "episode 13, val func loss 0.9009811878204346\n",
      "\n",
      "episode 14, val func loss 0.7594143748283386\n",
      "\n",
      "episode 15, val func loss 0.7692718505859375\n",
      "\n",
      "episode 16, val func loss 1.0263129472732544\n",
      "\n",
      "Val func train loss in epoch 3:0.7753792516887188\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7330136895179749\n",
      "\n",
      "episode 2, val func loss 0.7188476324081421\n",
      "\n",
      "episode 3, val func loss 0.9554396867752075\n",
      "\n",
      "episode 4, val func loss 0.7909517288208008\n",
      "\n",
      "episode 5, val func loss 0.7638700604438782\n",
      "\n",
      "episode 6, val func loss 0.9041997790336609\n",
      "\n",
      "episode 7, val func loss 0.758354127407074\n",
      "\n",
      "episode 8, val func loss 0.6784839630126953\n",
      "\n",
      "episode 9, val func loss 0.6550279259681702\n",
      "\n",
      "episode 10, val func loss 0.7537867426872253\n",
      "\n",
      "episode 11, val func loss 0.8893700838088989\n",
      "\n",
      "episode 12, val func loss 0.9038835763931274\n",
      "\n",
      "episode 13, val func loss 0.7725920081138611\n",
      "\n",
      "episode 14, val func loss 0.8494693040847778\n",
      "\n",
      "episode 15, val func loss 0.7987191677093506\n",
      "\n",
      "episode 16, val func loss 0.9662358164787292\n",
      "\n",
      "Val func train loss in epoch 4:0.8057653307914734\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6177865862846375\n",
      "\n",
      "episode 2, val func loss 0.9087371230125427\n",
      "\n",
      "episode 3, val func loss 0.8142955899238586\n",
      "\n",
      "episode 4, val func loss 0.9039129614830017\n",
      "\n",
      "episode 5, val func loss 0.994400680065155\n",
      "\n",
      "episode 6, val func loss 0.7253140211105347\n",
      "\n",
      "episode 7, val func loss 0.8438440561294556\n",
      "\n",
      "episode 8, val func loss 0.8217576146125793\n",
      "\n",
      "episode 9, val func loss 0.9794973731040955\n",
      "\n",
      "episode 10, val func loss 0.5873463153839111\n",
      "\n",
      "episode 11, val func loss 0.892946183681488\n",
      "\n",
      "episode 12, val func loss 0.9732167720794678\n",
      "\n",
      "episode 13, val func loss 0.6500391960144043\n",
      "\n",
      "episode 14, val func loss 0.8429151773452759\n",
      "\n",
      "episode 15, val func loss 0.7855291962623596\n",
      "\n",
      "episode 16, val func loss 0.6457512378692627\n",
      "\n",
      "Val func train loss in epoch 5:0.8117056302726269\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6954014897346497\n",
      "\n",
      "episode 2, val func loss 0.8110489249229431\n",
      "\n",
      "episode 3, val func loss 0.801301896572113\n",
      "\n",
      "episode 4, val func loss 1.0231566429138184\n",
      "\n",
      "episode 5, val func loss 0.9978773593902588\n",
      "\n",
      "episode 6, val func loss 0.7529883980751038\n",
      "\n",
      "episode 7, val func loss 0.7751381993293762\n",
      "\n",
      "episode 8, val func loss 0.7449768781661987\n",
      "\n",
      "episode 9, val func loss 0.677189826965332\n",
      "\n",
      "episode 10, val func loss 0.6719558238983154\n",
      "\n",
      "episode 11, val func loss 0.7020580768585205\n",
      "\n",
      "episode 12, val func loss 0.9532333016395569\n",
      "\n",
      "episode 13, val func loss 0.8903115391731262\n",
      "\n",
      "episode 14, val func loss 0.8140607476234436\n",
      "\n",
      "episode 15, val func loss 0.7037642002105713\n",
      "\n",
      "episode 16, val func loss 0.7966230511665344\n",
      "\n",
      "Val func train loss in epoch 6:0.8006928972899914\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.702997624874115\n",
      "\n",
      "episode 2, val func loss 0.754279613494873\n",
      "\n",
      "episode 3, val func loss 0.597217321395874\n",
      "\n",
      "episode 4, val func loss 1.075605869293213\n",
      "\n",
      "episode 5, val func loss 0.6782727837562561\n",
      "\n",
      "episode 6, val func loss 0.9557656049728394\n",
      "\n",
      "episode 7, val func loss 0.8213339447975159\n",
      "\n",
      "episode 8, val func loss 0.7689113616943359\n",
      "\n",
      "episode 9, val func loss 0.8254127502441406\n",
      "\n",
      "episode 10, val func loss 0.7100641131401062\n",
      "\n",
      "episode 11, val func loss 0.8815184831619263\n",
      "\n",
      "episode 12, val func loss 0.953613817691803\n",
      "\n",
      "episode 13, val func loss 1.02463960647583\n",
      "\n",
      "episode 14, val func loss 0.8808743357658386\n",
      "\n",
      "episode 15, val func loss 0.786524772644043\n",
      "\n",
      "episode 16, val func loss 0.87558913230896\n",
      "\n",
      "Val func train loss in epoch 7:0.8307888209819794\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.08226478099823\n",
      "\n",
      "episode 2, val func loss 0.7440064549446106\n",
      "\n",
      "episode 3, val func loss 0.9000436663627625\n",
      "\n",
      "episode 4, val func loss 0.6761220097541809\n",
      "\n",
      "episode 5, val func loss 0.8075190782546997\n",
      "\n",
      "episode 6, val func loss 0.5824866890907288\n",
      "\n",
      "episode 7, val func loss 0.8035057783126831\n",
      "\n",
      "episode 8, val func loss 0.8327441215515137\n",
      "\n",
      "episode 9, val func loss 0.8210599422454834\n",
      "\n",
      "episode 10, val func loss 0.7271462678909302\n",
      "\n",
      "episode 11, val func loss 0.991718053817749\n",
      "\n",
      "episode 12, val func loss 0.6790897846221924\n",
      "\n",
      "episode 13, val func loss 0.7844446301460266\n",
      "\n",
      "episode 14, val func loss 0.7686334848403931\n",
      "\n",
      "episode 15, val func loss 0.9303603172302246\n",
      "\n",
      "episode 16, val func loss 0.6524630784988403\n",
      "\n",
      "Val func train loss in epoch 8:0.798975508660078\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.7901204228401184\n",
      "\n",
      "episode 2, val func loss 0.7312842607498169\n",
      "\n",
      "episode 3, val func loss 0.9157964587211609\n",
      "\n",
      "episode 4, val func loss 0.8149118423461914\n",
      "\n",
      "episode 5, val func loss 0.8059034943580627\n",
      "\n",
      "episode 6, val func loss 0.8535834550857544\n",
      "\n",
      "episode 7, val func loss 0.7962509989738464\n",
      "\n",
      "episode 8, val func loss 0.6954996585845947\n",
      "\n",
      "episode 9, val func loss 0.7038319110870361\n",
      "\n",
      "episode 10, val func loss 0.7661997675895691\n",
      "\n",
      "episode 11, val func loss 0.8283613324165344\n",
      "\n",
      "episode 12, val func loss 0.9264627695083618\n",
      "\n",
      "episode 13, val func loss 1.0636943578720093\n",
      "\n",
      "episode 14, val func loss 0.9946144819259644\n",
      "\n",
      "episode 15, val func loss 0.6371071934700012\n",
      "\n",
      "episode 16, val func loss 0.7273571491241455\n",
      "\n",
      "Val func train loss in epoch 9:0.815686222165823\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7081360220909119\n",
      "\n",
      "episode 2, val func loss 0.6984841227531433\n",
      "\n",
      "episode 3, val func loss 0.8667199611663818\n",
      "\n",
      "episode 4, val func loss 0.7942571640014648\n",
      "\n",
      "episode 5, val func loss 0.8033971786499023\n",
      "\n",
      "episode 6, val func loss 0.5865879654884338\n",
      "\n",
      "episode 7, val func loss 0.786014974117279\n",
      "\n",
      "episode 8, val func loss 0.8530775904655457\n",
      "\n",
      "episode 9, val func loss 0.8368093967437744\n",
      "\n",
      "episode 10, val func loss 0.6858163475990295\n",
      "\n",
      "episode 11, val func loss 1.0471186637878418\n",
      "\n",
      "episode 12, val func loss 0.740831196308136\n",
      "\n",
      "episode 13, val func loss 0.7417445182800293\n",
      "\n",
      "episode 14, val func loss 0.6760863661766052\n",
      "\n",
      "episode 15, val func loss 0.6660618782043457\n",
      "\n",
      "episode 16, val func loss 0.8843584060668945\n",
      "\n",
      "Val func train loss in epoch 10:0.7734688594937325\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6620909571647644\n",
      "\n",
      "episode 2, val func loss 0.8524042367935181\n",
      "\n",
      "episode 3, val func loss 0.7790827751159668\n",
      "\n",
      "episode 4, val func loss 0.6307045817375183\n",
      "\n",
      "episode 5, val func loss 0.6820440888404846\n",
      "\n",
      "episode 6, val func loss 0.6945531964302063\n",
      "\n",
      "episode 7, val func loss 0.8180601596832275\n",
      "\n",
      "episode 8, val func loss 1.05552077293396\n",
      "\n",
      "episode 9, val func loss 0.7170802354812622\n",
      "\n",
      "episode 10, val func loss 0.8687772750854492\n",
      "\n",
      "episode 11, val func loss 0.8636507987976074\n",
      "\n",
      "episode 12, val func loss 0.6697835326194763\n",
      "\n",
      "episode 13, val func loss 0.8428698778152466\n",
      "\n",
      "episode 14, val func loss 0.7932522296905518\n",
      "\n",
      "episode 15, val func loss 0.8954391479492188\n",
      "\n",
      "episode 16, val func loss 0.8194888830184937\n",
      "\n",
      "Val func train loss in epoch 11:0.7903001718223095\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.9245200157165527\n",
      "\n",
      "episode 2, val func loss 0.8983483910560608\n",
      "\n",
      "episode 3, val func loss 0.7480401992797852\n",
      "\n",
      "episode 4, val func loss 0.8248299360275269\n",
      "\n",
      "episode 5, val func loss 0.6165657639503479\n",
      "\n",
      "episode 6, val func loss 0.9156366586685181\n",
      "\n",
      "episode 7, val func loss 1.050879955291748\n",
      "\n",
      "episode 8, val func loss 0.7050424814224243\n",
      "\n",
      "episode 9, val func loss 0.873184323310852\n",
      "\n",
      "episode 10, val func loss 1.0857023000717163\n",
      "\n",
      "episode 11, val func loss 0.6960404515266418\n",
      "\n",
      "episode 12, val func loss 1.0253756046295166\n",
      "\n",
      "episode 13, val func loss 0.9336382150650024\n",
      "\n",
      "episode 14, val func loss 0.5918778777122498\n",
      "\n",
      "episode 15, val func loss 0.7037954330444336\n",
      "\n",
      "episode 16, val func loss 0.7471759915351868\n",
      "\n",
      "Val func train loss in epoch 12:0.8337908498942852\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.7386289834976196\n",
      "\n",
      "episode 2, val func loss 0.8116645812988281\n",
      "\n",
      "episode 3, val func loss 0.7937583327293396\n",
      "\n",
      "episode 4, val func loss 0.7084008455276489\n",
      "\n",
      "episode 5, val func loss 0.9846877455711365\n",
      "\n",
      "episode 6, val func loss 0.7798224687576294\n",
      "\n",
      "episode 7, val func loss 0.6775059700012207\n",
      "\n",
      "episode 8, val func loss 0.9063059091567993\n",
      "\n",
      "episode 9, val func loss 0.7812344431877136\n",
      "\n",
      "episode 10, val func loss 1.0104197263717651\n",
      "\n",
      "episode 11, val func loss 0.5944414138793945\n",
      "\n",
      "episode 12, val func loss 0.7898771166801453\n",
      "\n",
      "episode 13, val func loss 0.74800705909729\n",
      "\n",
      "episode 14, val func loss 0.7957851886749268\n",
      "\n",
      "episode 15, val func loss 0.7794680595397949\n",
      "\n",
      "episode 16, val func loss 0.7205862998962402\n",
      "\n",
      "Val func train loss in epoch 13:0.7887871339917183\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.864630937576294\n",
      "\n",
      "episode 2, val func loss 0.6324628591537476\n",
      "\n",
      "episode 3, val func loss 0.7302834987640381\n",
      "\n",
      "episode 4, val func loss 0.8435140252113342\n",
      "\n",
      "episode 5, val func loss 0.8904657959938049\n",
      "\n",
      "episode 6, val func loss 0.8716762661933899\n",
      "\n",
      "episode 7, val func loss 0.8762950897216797\n",
      "\n",
      "episode 8, val func loss 0.8497000336647034\n",
      "\n",
      "episode 9, val func loss 0.7011536359786987\n",
      "\n",
      "episode 10, val func loss 0.6999642252922058\n",
      "\n",
      "episode 11, val func loss 0.7009965777397156\n",
      "\n",
      "episode 12, val func loss 0.7075498700141907\n",
      "\n",
      "episode 13, val func loss 0.927742600440979\n",
      "\n",
      "episode 14, val func loss 0.8130548596382141\n",
      "\n",
      "episode 15, val func loss 0.68772953748703\n",
      "\n",
      "episode 16, val func loss 0.8942427039146423\n",
      "\n",
      "Val func train loss in epoch 14:0.7932164072990417\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.8461143970489502\n",
      "\n",
      "episode 2, val func loss 0.9174484610557556\n",
      "\n",
      "episode 3, val func loss 0.708003044128418\n",
      "\n",
      "episode 4, val func loss 0.6560118198394775\n",
      "\n",
      "episode 5, val func loss 0.5608651041984558\n",
      "\n",
      "episode 6, val func loss 0.5844883918762207\n",
      "\n",
      "episode 7, val func loss 0.9535571336746216\n",
      "\n",
      "episode 8, val func loss 0.692904531955719\n",
      "\n",
      "episode 9, val func loss 0.8600904941558838\n",
      "\n",
      "episode 10, val func loss 0.7464227676391602\n",
      "\n",
      "episode 11, val func loss 0.8029252886772156\n",
      "\n",
      "episode 12, val func loss 0.9011259078979492\n",
      "\n",
      "episode 13, val func loss 0.9420461654663086\n",
      "\n",
      "episode 14, val func loss 0.7578845620155334\n",
      "\n",
      "episode 15, val func loss 0.8249604105949402\n",
      "\n",
      "episode 16, val func loss 0.7101966142654419\n",
      "\n",
      "Val func train loss in epoch 15:0.7790653184056282\n",
      "***********************TIME WAS 4.909674223264059 min*****************************\n",
      "\n",
      "**********************ROUND 115 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.335749626159668\n",
      "\n",
      "episode 2, policy loss 1.335757851600647\n",
      "\n",
      "episode 3, policy loss 1.335775375366211\n",
      "\n",
      "episode 4, policy loss 1.3357340097427368\n",
      "\n",
      "episode 5, policy loss 1.3357295989990234\n",
      "\n",
      "episode 6, policy loss 1.3357616662979126\n",
      "\n",
      "episode 7, policy loss 1.335723876953125\n",
      "\n",
      "episode 8, policy loss 1.335735559463501\n",
      "\n",
      "episode 9, policy loss 1.3357374668121338\n",
      "\n",
      "episode 10, policy loss 1.3357304334640503\n",
      "\n",
      "episode 11, policy loss 1.3357172012329102\n",
      "\n",
      "episode 12, policy loss 1.33573579788208\n",
      "\n",
      "episode 13, policy loss 1.3636794090270996\n",
      "\n",
      "episode 14, policy loss 1.335781455039978\n",
      "\n",
      "episode 15, policy loss 1.3358217477798462\n",
      "\n",
      "episode 16, policy loss 1.3358509540557861\n",
      "\n",
      "Policy train loss in epoch 0:1.3375013768672943\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.3358958959579468\n",
      "\n",
      "episode 2, policy loss 1.3359309434890747\n",
      "\n",
      "episode 3, policy loss 1.3359042406082153\n",
      "\n",
      "episode 4, policy loss 1.3359649181365967\n",
      "\n",
      "episode 5, policy loss 1.335971474647522\n",
      "\n",
      "episode 6, policy loss 1.3359795808792114\n",
      "\n",
      "episode 7, policy loss 1.3359947204589844\n",
      "\n",
      "episode 8, policy loss 1.3359965085983276\n",
      "\n",
      "episode 9, policy loss 1.336014986038208\n",
      "\n",
      "episode 10, policy loss 1.360349416732788\n",
      "\n",
      "episode 11, policy loss 1.3360215425491333\n",
      "\n",
      "episode 12, policy loss 1.33602774143219\n",
      "\n",
      "episode 13, policy loss 1.336029052734375\n",
      "\n",
      "episode 14, policy loss 1.3360334634780884\n",
      "\n",
      "episode 15, policy loss 1.336035132408142\n",
      "\n",
      "episode 16, policy loss 1.3360395431518555\n",
      "\n",
      "Policy train loss in epoch 1:1.3375118225812912\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.3360440731048584\n",
      "\n",
      "episode 2, policy loss 1.3360297679901123\n",
      "\n",
      "episode 3, policy loss 1.3360451459884644\n",
      "\n",
      "episode 4, policy loss 1.3360460996627808\n",
      "\n",
      "episode 5, policy loss 1.336049199104309\n",
      "\n",
      "episode 6, policy loss 1.3360379934310913\n",
      "\n",
      "episode 7, policy loss 1.3603932857513428\n",
      "\n",
      "episode 8, policy loss 1.3360521793365479\n",
      "\n",
      "episode 9, policy loss 1.3360556364059448\n",
      "\n",
      "episode 10, policy loss 1.3360487222671509\n",
      "\n",
      "episode 11, policy loss 1.3360464572906494\n",
      "\n",
      "episode 12, policy loss 1.3360422849655151\n",
      "\n",
      "episode 13, policy loss 1.336051344871521\n",
      "\n",
      "episode 14, policy loss 1.3360439538955688\n",
      "\n",
      "episode 15, policy loss 1.3360413312911987\n",
      "\n",
      "episode 16, policy loss 1.3360438346862793\n",
      "\n",
      "Policy train loss in epoch 2:1.3375669568777084\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.3360445499420166\n",
      "\n",
      "episode 2, policy loss 1.3360440731048584\n",
      "\n",
      "episode 3, policy loss 1.3603966236114502\n",
      "\n",
      "episode 4, policy loss 1.336039423942566\n",
      "\n",
      "episode 5, policy loss 1.3360340595245361\n",
      "\n",
      "episode 6, policy loss 1.3360347747802734\n",
      "\n",
      "episode 7, policy loss 1.3360258340835571\n",
      "\n",
      "episode 8, policy loss 1.3360410928726196\n",
      "\n",
      "episode 9, policy loss 1.3360331058502197\n",
      "\n",
      "episode 10, policy loss 1.336022138595581\n",
      "\n",
      "episode 11, policy loss 1.3360263109207153\n",
      "\n",
      "episode 12, policy loss 1.336021900177002\n",
      "\n",
      "episode 13, policy loss 1.3360148668289185\n",
      "\n",
      "episode 14, policy loss 1.336020588874817\n",
      "\n",
      "episode 15, policy loss 1.3360176086425781\n",
      "\n",
      "episode 16, policy loss 1.336014747619629\n",
      "\n",
      "Policy train loss in epoch 3:1.3375519812107086\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7167810201644897\n",
      "\n",
      "episode 2, val func loss 0.6014339923858643\n",
      "\n",
      "episode 3, val func loss 0.7396341562271118\n",
      "\n",
      "episode 4, val func loss 0.645822286605835\n",
      "\n",
      "episode 5, val func loss 0.8025537133216858\n",
      "\n",
      "episode 6, val func loss 0.6885490417480469\n",
      "\n",
      "episode 7, val func loss 0.7314433455467224\n",
      "\n",
      "episode 8, val func loss 0.6144180297851562\n",
      "\n",
      "episode 9, val func loss 0.746700644493103\n",
      "\n",
      "episode 10, val func loss 0.7259300947189331\n",
      "\n",
      "episode 11, val func loss 0.716841995716095\n",
      "\n",
      "episode 12, val func loss 0.8429757952690125\n",
      "\n",
      "episode 13, val func loss 0.7818881273269653\n",
      "\n",
      "episode 14, val func loss 0.6610349416732788\n",
      "\n",
      "episode 15, val func loss 0.8003970384597778\n",
      "\n",
      "episode 16, val func loss 0.866744339466095\n",
      "\n",
      "Val func train loss in epoch 0:0.7301967851817608\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7032291889190674\n",
      "\n",
      "episode 2, val func loss 0.6643573045730591\n",
      "\n",
      "episode 3, val func loss 0.7941773533821106\n",
      "\n",
      "episode 4, val func loss 0.6565390825271606\n",
      "\n",
      "episode 5, val func loss 0.8140076398849487\n",
      "\n",
      "episode 6, val func loss 0.8015062212944031\n",
      "\n",
      "episode 7, val func loss 0.8023043274879456\n",
      "\n",
      "episode 8, val func loss 0.6735767722129822\n",
      "\n",
      "episode 9, val func loss 0.6103900671005249\n",
      "\n",
      "episode 10, val func loss 0.5905558466911316\n",
      "\n",
      "episode 11, val func loss 0.6898659467697144\n",
      "\n",
      "episode 12, val func loss 0.6382474899291992\n",
      "\n",
      "episode 13, val func loss 0.6322229504585266\n",
      "\n",
      "episode 14, val func loss 0.6095129251480103\n",
      "\n",
      "episode 15, val func loss 0.6699649095535278\n",
      "\n",
      "episode 16, val func loss 0.5984371304512024\n",
      "\n",
      "Val func train loss in epoch 1:0.6843059472739697\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.8211319446563721\n",
      "\n",
      "episode 2, val func loss 0.6996337175369263\n",
      "\n",
      "episode 3, val func loss 0.6842462420463562\n",
      "\n",
      "episode 4, val func loss 0.6647502183914185\n",
      "\n",
      "episode 5, val func loss 0.6435375809669495\n",
      "\n",
      "episode 6, val func loss 0.6471536755561829\n",
      "\n",
      "episode 7, val func loss 0.7224210500717163\n",
      "\n",
      "episode 8, val func loss 0.7751174569129944\n",
      "\n",
      "episode 9, val func loss 0.6683737635612488\n",
      "\n",
      "episode 10, val func loss 0.8272892832756042\n",
      "\n",
      "episode 11, val func loss 0.6004220247268677\n",
      "\n",
      "episode 12, val func loss 0.6177102327346802\n",
      "\n",
      "episode 13, val func loss 0.5760173797607422\n",
      "\n",
      "episode 14, val func loss 0.5897974967956543\n",
      "\n",
      "episode 15, val func loss 0.6604992747306824\n",
      "\n",
      "episode 16, val func loss 0.6383131146430969\n",
      "\n",
      "Val func train loss in epoch 2:0.6772759035229683\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.5845769643783569\n",
      "\n",
      "episode 2, val func loss 0.6224548816680908\n",
      "\n",
      "episode 3, val func loss 0.6342737674713135\n",
      "\n",
      "episode 4, val func loss 0.6408297419548035\n",
      "\n",
      "episode 5, val func loss 0.6442448496818542\n",
      "\n",
      "episode 6, val func loss 0.6495514512062073\n",
      "\n",
      "episode 7, val func loss 0.6920762658119202\n",
      "\n",
      "episode 8, val func loss 0.639596164226532\n",
      "\n",
      "episode 9, val func loss 0.6382840871810913\n",
      "\n",
      "episode 10, val func loss 0.7747216820716858\n",
      "\n",
      "episode 11, val func loss 0.7067292332649231\n",
      "\n",
      "episode 12, val func loss 0.6581864953041077\n",
      "\n",
      "episode 13, val func loss 0.8096164464950562\n",
      "\n",
      "episode 14, val func loss 0.6991086602210999\n",
      "\n",
      "episode 15, val func loss 0.6120518445968628\n",
      "\n",
      "episode 16, val func loss 0.651404082775116\n",
      "\n",
      "Val func train loss in epoch 3:0.6661066636443138\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6987501978874207\n",
      "\n",
      "episode 2, val func loss 0.7543601989746094\n",
      "\n",
      "episode 3, val func loss 0.6371184587478638\n",
      "\n",
      "episode 4, val func loss 0.5951492190361023\n",
      "\n",
      "episode 5, val func loss 0.5877043008804321\n",
      "\n",
      "episode 6, val func loss 0.6570420861244202\n",
      "\n",
      "episode 7, val func loss 0.6527678370475769\n",
      "\n",
      "episode 8, val func loss 0.6619203090667725\n",
      "\n",
      "episode 9, val func loss 0.7223894000053406\n",
      "\n",
      "episode 10, val func loss 0.766608715057373\n",
      "\n",
      "episode 11, val func loss 0.6990616321563721\n",
      "\n",
      "episode 12, val func loss 0.6053203344345093\n",
      "\n",
      "episode 13, val func loss 0.6861599087715149\n",
      "\n",
      "episode 14, val func loss 0.7138508558273315\n",
      "\n",
      "episode 15, val func loss 0.6704673171043396\n",
      "\n",
      "episode 16, val func loss 0.6250488758087158\n",
      "\n",
      "Val func train loss in epoch 4:0.6708574779331684\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7053612470626831\n",
      "\n",
      "episode 2, val func loss 0.6143027544021606\n",
      "\n",
      "episode 3, val func loss 0.6249901056289673\n",
      "\n",
      "episode 4, val func loss 0.6625063419342041\n",
      "\n",
      "episode 5, val func loss 0.7549463510513306\n",
      "\n",
      "episode 6, val func loss 0.5955773591995239\n",
      "\n",
      "episode 7, val func loss 0.5900626182556152\n",
      "\n",
      "episode 8, val func loss 0.5787829160690308\n",
      "\n",
      "episode 9, val func loss 0.656606912612915\n",
      "\n",
      "episode 10, val func loss 0.6318310499191284\n",
      "\n",
      "episode 11, val func loss 0.5463113188743591\n",
      "\n",
      "episode 12, val func loss 0.6730947494506836\n",
      "\n",
      "episode 13, val func loss 0.5997545123100281\n",
      "\n",
      "episode 14, val func loss 0.6261662244796753\n",
      "\n",
      "episode 15, val func loss 0.6632266044616699\n",
      "\n",
      "episode 16, val func loss 0.5992019772529602\n",
      "\n",
      "Val func train loss in epoch 5:0.6326701901853085\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.687202513217926\n",
      "\n",
      "episode 2, val func loss 0.652415931224823\n",
      "\n",
      "episode 3, val func loss 0.6256895065307617\n",
      "\n",
      "episode 4, val func loss 0.6862773299217224\n",
      "\n",
      "episode 5, val func loss 0.6234495043754578\n",
      "\n",
      "episode 6, val func loss 0.630440354347229\n",
      "\n",
      "episode 7, val func loss 0.6572271585464478\n",
      "\n",
      "episode 8, val func loss 0.5725394487380981\n",
      "\n",
      "episode 9, val func loss 0.6317204236984253\n",
      "\n",
      "episode 10, val func loss 0.6381244659423828\n",
      "\n",
      "episode 11, val func loss 0.7115645408630371\n",
      "\n",
      "episode 12, val func loss 0.5927242040634155\n",
      "\n",
      "episode 13, val func loss 0.9390470385551453\n",
      "\n",
      "episode 14, val func loss 0.6302502751350403\n",
      "\n",
      "episode 15, val func loss 0.6424480080604553\n",
      "\n",
      "episode 16, val func loss 0.6179581880569458\n",
      "\n",
      "Val func train loss in epoch 6:0.6586924307048321\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7053138017654419\n",
      "\n",
      "episode 2, val func loss 0.7047621607780457\n",
      "\n",
      "episode 3, val func loss 0.7581354379653931\n",
      "\n",
      "episode 4, val func loss 0.7306925654411316\n",
      "\n",
      "episode 5, val func loss 0.5748905539512634\n",
      "\n",
      "episode 6, val func loss 0.7548397183418274\n",
      "\n",
      "episode 7, val func loss 0.6566401124000549\n",
      "\n",
      "episode 8, val func loss 0.6254855394363403\n",
      "\n",
      "episode 9, val func loss 0.5618910193443298\n",
      "\n",
      "episode 10, val func loss 0.6967357397079468\n",
      "\n",
      "episode 11, val func loss 0.6356642246246338\n",
      "\n",
      "episode 12, val func loss 0.698493242263794\n",
      "\n",
      "episode 13, val func loss 0.7424567937850952\n",
      "\n",
      "episode 14, val func loss 0.6348872184753418\n",
      "\n",
      "episode 15, val func loss 0.6579453945159912\n",
      "\n",
      "episode 16, val func loss 0.6245253086090088\n",
      "\n",
      "Val func train loss in epoch 7:0.6727099269628525\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7915613055229187\n",
      "\n",
      "episode 2, val func loss 0.5926979780197144\n",
      "\n",
      "episode 3, val func loss 0.8193137049674988\n",
      "\n",
      "episode 4, val func loss 0.7274956107139587\n",
      "\n",
      "episode 5, val func loss 0.639910101890564\n",
      "\n",
      "episode 6, val func loss 0.727279007434845\n",
      "\n",
      "episode 7, val func loss 0.6638608574867249\n",
      "\n",
      "episode 8, val func loss 0.7965472936630249\n",
      "\n",
      "episode 9, val func loss 0.731985867023468\n",
      "\n",
      "episode 10, val func loss 0.7355847954750061\n",
      "\n",
      "episode 11, val func loss 0.6984833478927612\n",
      "\n",
      "episode 12, val func loss 0.6475650072097778\n",
      "\n",
      "episode 13, val func loss 0.7240811586380005\n",
      "\n",
      "episode 14, val func loss 0.7376312613487244\n",
      "\n",
      "episode 15, val func loss 0.7216660380363464\n",
      "\n",
      "episode 16, val func loss 0.7057982683181763\n",
      "\n",
      "Val func train loss in epoch 8:0.7163413502275944\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6743091344833374\n",
      "\n",
      "episode 2, val func loss 0.8171897530555725\n",
      "\n",
      "episode 3, val func loss 0.6591495275497437\n",
      "\n",
      "episode 4, val func loss 0.7026411890983582\n",
      "\n",
      "episode 5, val func loss 0.8497017621994019\n",
      "\n",
      "episode 6, val func loss 0.565461277961731\n",
      "\n",
      "episode 7, val func loss 0.8186068534851074\n",
      "\n",
      "episode 8, val func loss 0.8488385081291199\n",
      "\n",
      "episode 9, val func loss 0.7576841115951538\n",
      "\n",
      "episode 10, val func loss 0.6567243337631226\n",
      "\n",
      "episode 11, val func loss 0.800448477268219\n",
      "\n",
      "episode 12, val func loss 0.8149132132530212\n",
      "\n",
      "episode 13, val func loss 0.5665878057479858\n",
      "\n",
      "episode 14, val func loss 0.6697575449943542\n",
      "\n",
      "episode 15, val func loss 0.614628255367279\n",
      "\n",
      "episode 16, val func loss 0.7782853245735168\n",
      "\n",
      "Val func train loss in epoch 9:0.724682942032814\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6460879445075989\n",
      "\n",
      "episode 2, val func loss 0.6726946830749512\n",
      "\n",
      "episode 3, val func loss 0.7384459376335144\n",
      "\n",
      "episode 4, val func loss 0.7218472361564636\n",
      "\n",
      "episode 5, val func loss 0.6636449098587036\n",
      "\n",
      "episode 6, val func loss 0.6931456923484802\n",
      "\n",
      "episode 7, val func loss 0.7325724959373474\n",
      "\n",
      "episode 8, val func loss 0.642665684223175\n",
      "\n",
      "episode 9, val func loss 0.6264709830284119\n",
      "\n",
      "episode 10, val func loss 0.6078563928604126\n",
      "\n",
      "episode 11, val func loss 0.765634298324585\n",
      "\n",
      "episode 12, val func loss 0.6421049237251282\n",
      "\n",
      "episode 13, val func loss 0.5302138924598694\n",
      "\n",
      "episode 14, val func loss 0.6873189210891724\n",
      "\n",
      "episode 15, val func loss 0.7042369246482849\n",
      "\n",
      "episode 16, val func loss 0.6340520977973938\n",
      "\n",
      "Val func train loss in epoch 10:0.6693120636045933\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.588346004486084\n",
      "\n",
      "episode 2, val func loss 0.6324954628944397\n",
      "\n",
      "episode 3, val func loss 0.630366325378418\n",
      "\n",
      "episode 4, val func loss 0.5912047624588013\n",
      "\n",
      "episode 5, val func loss 0.5702002644538879\n",
      "\n",
      "episode 6, val func loss 0.7591735124588013\n",
      "\n",
      "episode 7, val func loss 0.6633988618850708\n",
      "\n",
      "episode 8, val func loss 0.6513631343841553\n",
      "\n",
      "episode 9, val func loss 0.601816713809967\n",
      "\n",
      "episode 10, val func loss 0.6466044783592224\n",
      "\n",
      "episode 11, val func loss 0.8393509387969971\n",
      "\n",
      "episode 12, val func loss 0.6901379823684692\n",
      "\n",
      "episode 13, val func loss 0.5759304165840149\n",
      "\n",
      "episode 14, val func loss 0.7119122743606567\n",
      "\n",
      "episode 15, val func loss 0.5933998823165894\n",
      "\n",
      "episode 16, val func loss 0.9123532772064209\n",
      "\n",
      "Val func train loss in epoch 11:0.6661283932626247\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6865466833114624\n",
      "\n",
      "episode 2, val func loss 0.6154272556304932\n",
      "\n",
      "episode 3, val func loss 0.6112740635871887\n",
      "\n",
      "episode 4, val func loss 0.6853626370429993\n",
      "\n",
      "episode 5, val func loss 0.6191397905349731\n",
      "\n",
      "episode 6, val func loss 0.64066082239151\n",
      "\n",
      "episode 7, val func loss 0.8450670838356018\n",
      "\n",
      "episode 8, val func loss 0.5957508683204651\n",
      "\n",
      "episode 9, val func loss 0.5880907773971558\n",
      "\n",
      "episode 10, val func loss 0.6752599477767944\n",
      "\n",
      "episode 11, val func loss 0.6281216144561768\n",
      "\n",
      "episode 12, val func loss 0.7029616236686707\n",
      "\n",
      "episode 13, val func loss 0.6802388429641724\n",
      "\n",
      "episode 14, val func loss 0.6386004686355591\n",
      "\n",
      "episode 15, val func loss 0.6590702533721924\n",
      "\n",
      "episode 16, val func loss 0.5824140310287476\n",
      "\n",
      "Val func train loss in epoch 12:0.6533741727471352\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.5964781641960144\n",
      "\n",
      "episode 2, val func loss 0.7515079975128174\n",
      "\n",
      "episode 3, val func loss 0.5973253846168518\n",
      "\n",
      "episode 4, val func loss 0.588198721408844\n",
      "\n",
      "episode 5, val func loss 0.6148731708526611\n",
      "\n",
      "episode 6, val func loss 0.5768982768058777\n",
      "\n",
      "episode 7, val func loss 0.6196573376655579\n",
      "\n",
      "episode 8, val func loss 0.8550406694412231\n",
      "\n",
      "episode 9, val func loss 0.7172107696533203\n",
      "\n",
      "episode 10, val func loss 0.5699378252029419\n",
      "\n",
      "episode 11, val func loss 0.6494858264923096\n",
      "\n",
      "episode 12, val func loss 0.7542034983634949\n",
      "\n",
      "episode 13, val func loss 0.7435052394866943\n",
      "\n",
      "episode 14, val func loss 0.6043170690536499\n",
      "\n",
      "episode 15, val func loss 0.7216385006904602\n",
      "\n",
      "episode 16, val func loss 0.6044501662254333\n",
      "\n",
      "Val func train loss in epoch 13:0.6602955386042595\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7240473031997681\n",
      "\n",
      "episode 2, val func loss 0.6521996259689331\n",
      "\n",
      "episode 3, val func loss 0.6403269171714783\n",
      "\n",
      "episode 4, val func loss 0.7885065674781799\n",
      "\n",
      "episode 5, val func loss 0.7306157350540161\n",
      "\n",
      "episode 6, val func loss 0.7834067940711975\n",
      "\n",
      "episode 7, val func loss 0.8141613006591797\n",
      "\n",
      "episode 8, val func loss 0.7083907723426819\n",
      "\n",
      "episode 9, val func loss 0.6913794875144958\n",
      "\n",
      "episode 10, val func loss 0.7896177768707275\n",
      "\n",
      "episode 11, val func loss 0.7478163242340088\n",
      "\n",
      "episode 12, val func loss 0.6463504433631897\n",
      "\n",
      "episode 13, val func loss 0.7034175992012024\n",
      "\n",
      "episode 14, val func loss 0.6975804567337036\n",
      "\n",
      "episode 15, val func loss 0.6571710705757141\n",
      "\n",
      "episode 16, val func loss 0.669655442237854\n",
      "\n",
      "Val func train loss in epoch 14:0.7152902260422707\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7437670230865479\n",
      "\n",
      "episode 2, val func loss 0.7325518131256104\n",
      "\n",
      "episode 3, val func loss 0.6182210445404053\n",
      "\n",
      "episode 4, val func loss 0.6998475790023804\n",
      "\n",
      "episode 5, val func loss 0.7237401604652405\n",
      "\n",
      "episode 6, val func loss 0.6428415179252625\n",
      "\n",
      "episode 7, val func loss 0.7229593396186829\n",
      "\n",
      "episode 8, val func loss 0.6828581690788269\n",
      "\n",
      "episode 9, val func loss 0.6479568481445312\n",
      "\n",
      "episode 10, val func loss 0.7088445425033569\n",
      "\n",
      "episode 11, val func loss 0.7088052034378052\n",
      "\n",
      "episode 12, val func loss 0.6406831741333008\n",
      "\n",
      "episode 13, val func loss 0.6677660346031189\n",
      "\n",
      "episode 14, val func loss 0.704066812992096\n",
      "\n",
      "episode 15, val func loss 0.6167153120040894\n",
      "\n",
      "episode 16, val func loss 0.6854468584060669\n",
      "\n",
      "Val func train loss in epoch 15:0.6841919645667076\n",
      "***********************TIME WAS 4.907984141508738 min*****************************\n",
      "\n",
      "**********************ROUND 116 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.2217826843261719\n",
      "\n",
      "episode 2, policy loss 1.221781611442566\n",
      "\n",
      "episode 3, policy loss 1.2217872142791748\n",
      "\n",
      "episode 4, policy loss 1.2217788696289062\n",
      "\n",
      "episode 5, policy loss 1.2465598583221436\n",
      "\n",
      "episode 6, policy loss 1.2218241691589355\n",
      "\n",
      "episode 7, policy loss 1.2218466997146606\n",
      "\n",
      "episode 8, policy loss 1.2218726873397827\n",
      "\n",
      "episode 9, policy loss 1.2218836545944214\n",
      "\n",
      "episode 10, policy loss 1.2219008207321167\n",
      "\n",
      "episode 11, policy loss 1.2219147682189941\n",
      "\n",
      "episode 12, policy loss 1.2219157218933105\n",
      "\n",
      "episode 13, policy loss 1.2219222784042358\n",
      "\n",
      "episode 14, policy loss 1.2219324111938477\n",
      "\n",
      "episode 15, policy loss 1.22193443775177\n",
      "\n",
      "episode 16, policy loss 1.2219383716583252\n",
      "\n",
      "Policy train loss in epoch 0:1.2234110161662102\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.2219401597976685\n",
      "\n",
      "episode 2, policy loss 1.2219444513320923\n",
      "\n",
      "episode 3, policy loss 1.2219443321228027\n",
      "\n",
      "episode 4, policy loss 1.245822548866272\n",
      "\n",
      "episode 5, policy loss 1.2219492197036743\n",
      "\n",
      "episode 6, policy loss 1.2219514846801758\n",
      "\n",
      "episode 7, policy loss 1.2219531536102295\n",
      "\n",
      "episode 8, policy loss 1.2219535112380981\n",
      "\n",
      "episode 9, policy loss 1.2219558954238892\n",
      "\n",
      "episode 10, policy loss 1.2219558954238892\n",
      "\n",
      "episode 11, policy loss 1.2219555377960205\n",
      "\n",
      "episode 12, policy loss 1.2219562530517578\n",
      "\n",
      "episode 13, policy loss 1.2219568490982056\n",
      "\n",
      "episode 14, policy loss 1.2219573259353638\n",
      "\n",
      "episode 15, policy loss 1.221957802772522\n",
      "\n",
      "episode 16, policy loss 1.2219575643539429\n",
      "\n",
      "Policy train loss in epoch 1:1.2234444990754128\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.2458336353302002\n",
      "\n",
      "episode 2, policy loss 1.2219585180282593\n",
      "\n",
      "episode 3, policy loss 1.2219587564468384\n",
      "\n",
      "episode 4, policy loss 1.2219581604003906\n",
      "\n",
      "episode 5, policy loss 1.2219600677490234\n",
      "\n",
      "episode 6, policy loss 1.2219592332839966\n",
      "\n",
      "episode 7, policy loss 1.2219589948654175\n",
      "\n",
      "episode 8, policy loss 1.2219600677490234\n",
      "\n",
      "episode 9, policy loss 1.2219587564468384\n",
      "\n",
      "episode 10, policy loss 1.2219598293304443\n",
      "\n",
      "episode 11, policy loss 1.2219607830047607\n",
      "\n",
      "episode 12, policy loss 1.221959114074707\n",
      "\n",
      "episode 13, policy loss 1.221959114074707\n",
      "\n",
      "episode 14, policy loss 1.2219611406326294\n",
      "\n",
      "episode 15, policy loss 1.2219597101211548\n",
      "\n",
      "episode 16, policy loss 1.2219610214233398\n",
      "\n",
      "Policy train loss in epoch 2:1.2234516814351082\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.221961498260498\n",
      "\n",
      "episode 2, policy loss 1.2219611406326294\n",
      "\n",
      "episode 3, policy loss 1.2219606637954712\n",
      "\n",
      "episode 4, policy loss 1.221961259841919\n",
      "\n",
      "episode 5, policy loss 1.2219593524932861\n",
      "\n",
      "episode 6, policy loss 1.2219606637954712\n",
      "\n",
      "episode 7, policy loss 1.2219609022140503\n",
      "\n",
      "episode 8, policy loss 1.2219587564468384\n",
      "\n",
      "episode 9, policy loss 1.2219603061676025\n",
      "\n",
      "episode 10, policy loss 1.221962332725525\n",
      "\n",
      "episode 11, policy loss 1.2219603061676025\n",
      "\n",
      "episode 12, policy loss 1.221960186958313\n",
      "\n",
      "episode 13, policy loss 1.2458330392837524\n",
      "\n",
      "episode 14, policy loss 1.2219586372375488\n",
      "\n",
      "episode 15, policy loss 1.2219587564468384\n",
      "\n",
      "episode 16, policy loss 1.2219605445861816\n",
      "\n",
      "Policy train loss in epoch 3:1.2234523966908455\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.8025500178337097\n",
      "\n",
      "episode 2, val func loss 0.6740656495094299\n",
      "\n",
      "episode 3, val func loss 0.6934270858764648\n",
      "\n",
      "episode 4, val func loss 0.6317314505577087\n",
      "\n",
      "episode 5, val func loss 0.7414525747299194\n",
      "\n",
      "episode 6, val func loss 0.7464720606803894\n",
      "\n",
      "episode 7, val func loss 0.64091557264328\n",
      "\n",
      "episode 8, val func loss 0.6634270548820496\n",
      "\n",
      "episode 9, val func loss 0.6497611999511719\n",
      "\n",
      "episode 10, val func loss 0.6173431277275085\n",
      "\n",
      "episode 11, val func loss 0.708960235118866\n",
      "\n",
      "episode 12, val func loss 0.7130693197250366\n",
      "\n",
      "episode 13, val func loss 0.5567002892494202\n",
      "\n",
      "episode 14, val func loss 0.6767986416816711\n",
      "\n",
      "episode 15, val func loss 0.7308931946754456\n",
      "\n",
      "episode 16, val func loss 0.629740834236145\n",
      "\n",
      "Val func train loss in epoch 0:0.6798317693173885\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.6169820427894592\n",
      "\n",
      "episode 2, val func loss 0.6600001454353333\n",
      "\n",
      "episode 3, val func loss 0.6487377882003784\n",
      "\n",
      "episode 4, val func loss 0.7652559876441956\n",
      "\n",
      "episode 5, val func loss 0.6979899406433105\n",
      "\n",
      "episode 6, val func loss 0.7293346524238586\n",
      "\n",
      "episode 7, val func loss 0.6717427372932434\n",
      "\n",
      "episode 8, val func loss 0.6708839535713196\n",
      "\n",
      "episode 9, val func loss 0.6046969294548035\n",
      "\n",
      "episode 10, val func loss 0.6149787902832031\n",
      "\n",
      "episode 11, val func loss 0.7314038872718811\n",
      "\n",
      "episode 12, val func loss 0.6024076342582703\n",
      "\n",
      "episode 13, val func loss 0.596056342124939\n",
      "\n",
      "episode 14, val func loss 0.6997411847114563\n",
      "\n",
      "episode 15, val func loss 0.6584802865982056\n",
      "\n",
      "episode 16, val func loss 0.718479335308075\n",
      "\n",
      "Val func train loss in epoch 1:0.6679482273757458\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.672354519367218\n",
      "\n",
      "episode 2, val func loss 0.7037798762321472\n",
      "\n",
      "episode 3, val func loss 0.7196370959281921\n",
      "\n",
      "episode 4, val func loss 0.60398930311203\n",
      "\n",
      "episode 5, val func loss 0.6259240508079529\n",
      "\n",
      "episode 6, val func loss 0.6259639263153076\n",
      "\n",
      "episode 7, val func loss 0.6801859140396118\n",
      "\n",
      "episode 8, val func loss 0.711529016494751\n",
      "\n",
      "episode 9, val func loss 0.6085605025291443\n",
      "\n",
      "episode 10, val func loss 0.7077369689941406\n",
      "\n",
      "episode 11, val func loss 0.6423060297966003\n",
      "\n",
      "episode 12, val func loss 0.593926727771759\n",
      "\n",
      "episode 13, val func loss 0.9275339841842651\n",
      "\n",
      "episode 14, val func loss 0.6647246479988098\n",
      "\n",
      "episode 15, val func loss 0.8461441397666931\n",
      "\n",
      "episode 16, val func loss 0.7958869934082031\n",
      "\n",
      "Val func train loss in epoch 2:0.6956364810466766\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6575086712837219\n",
      "\n",
      "episode 2, val func loss 0.7424325942993164\n",
      "\n",
      "episode 3, val func loss 0.7959977984428406\n",
      "\n",
      "episode 4, val func loss 0.7017719745635986\n",
      "\n",
      "episode 5, val func loss 0.715422511100769\n",
      "\n",
      "episode 6, val func loss 0.6824150085449219\n",
      "\n",
      "episode 7, val func loss 0.8387908935546875\n",
      "\n",
      "episode 8, val func loss 0.7876664400100708\n",
      "\n",
      "episode 9, val func loss 0.721462070941925\n",
      "\n",
      "episode 10, val func loss 0.7729112505912781\n",
      "\n",
      "episode 11, val func loss 0.6481130123138428\n",
      "\n",
      "episode 12, val func loss 0.6622729897499084\n",
      "\n",
      "episode 13, val func loss 0.8701490759849548\n",
      "\n",
      "episode 14, val func loss 0.7566865682601929\n",
      "\n",
      "episode 15, val func loss 0.6303973197937012\n",
      "\n",
      "episode 16, val func loss 0.7364256381988525\n",
      "\n",
      "Val func train loss in epoch 3:0.7325264886021614\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7564406991004944\n",
      "\n",
      "episode 2, val func loss 0.5822947025299072\n",
      "\n",
      "episode 3, val func loss 0.7376796007156372\n",
      "\n",
      "episode 4, val func loss 0.7264618277549744\n",
      "\n",
      "episode 5, val func loss 0.6665403842926025\n",
      "\n",
      "episode 6, val func loss 0.7114849090576172\n",
      "\n",
      "episode 7, val func loss 0.6399915814399719\n",
      "\n",
      "episode 8, val func loss 0.6900994181632996\n",
      "\n",
      "episode 9, val func loss 0.7752946019172668\n",
      "\n",
      "episode 10, val func loss 0.7055121064186096\n",
      "\n",
      "episode 11, val func loss 0.5443949699401855\n",
      "\n",
      "episode 12, val func loss 0.7783596515655518\n",
      "\n",
      "episode 13, val func loss 0.6607505679130554\n",
      "\n",
      "episode 14, val func loss 0.6902567148208618\n",
      "\n",
      "episode 15, val func loss 0.6738449335098267\n",
      "\n",
      "episode 16, val func loss 0.6735564470291138\n",
      "\n",
      "Val func train loss in epoch 4:0.688310194760561\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6189867854118347\n",
      "\n",
      "episode 2, val func loss 0.6577224731445312\n",
      "\n",
      "episode 3, val func loss 0.7510170340538025\n",
      "\n",
      "episode 4, val func loss 0.8753023147583008\n",
      "\n",
      "episode 5, val func loss 0.6617138981819153\n",
      "\n",
      "episode 6, val func loss 0.6277533769607544\n",
      "\n",
      "episode 7, val func loss 0.6532562375068665\n",
      "\n",
      "episode 8, val func loss 0.59456866979599\n",
      "\n",
      "episode 9, val func loss 0.5855726599693298\n",
      "\n",
      "episode 10, val func loss 0.7540632486343384\n",
      "\n",
      "episode 11, val func loss 0.6503433585166931\n",
      "\n",
      "episode 12, val func loss 0.633041501045227\n",
      "\n",
      "episode 13, val func loss 0.6746158599853516\n",
      "\n",
      "episode 14, val func loss 0.7330709099769592\n",
      "\n",
      "episode 15, val func loss 0.6540403962135315\n",
      "\n",
      "episode 16, val func loss 0.5479190945625305\n",
      "\n",
      "Val func train loss in epoch 5:0.6670617386698723\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7940090298652649\n",
      "\n",
      "episode 2, val func loss 0.5591604709625244\n",
      "\n",
      "episode 3, val func loss 0.6447723507881165\n",
      "\n",
      "episode 4, val func loss 0.7270589470863342\n",
      "\n",
      "episode 5, val func loss 0.7637509107589722\n",
      "\n",
      "episode 6, val func loss 0.5953672528266907\n",
      "\n",
      "episode 7, val func loss 0.7277044057846069\n",
      "\n",
      "episode 8, val func loss 0.689968466758728\n",
      "\n",
      "episode 9, val func loss 0.7232165336608887\n",
      "\n",
      "episode 10, val func loss 0.6853771209716797\n",
      "\n",
      "episode 11, val func loss 0.5935218930244446\n",
      "\n",
      "episode 12, val func loss 0.7018051147460938\n",
      "\n",
      "episode 13, val func loss 0.7287326455116272\n",
      "\n",
      "episode 14, val func loss 0.6482223868370056\n",
      "\n",
      "episode 15, val func loss 0.5793715119361877\n",
      "\n",
      "episode 16, val func loss 0.6332656145095825\n",
      "\n",
      "Val func train loss in epoch 6:0.6747065410017967\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7053964734077454\n",
      "\n",
      "episode 2, val func loss 0.6292353868484497\n",
      "\n",
      "episode 3, val func loss 0.6797327399253845\n",
      "\n",
      "episode 4, val func loss 0.5854475498199463\n",
      "\n",
      "episode 5, val func loss 0.6838257908821106\n",
      "\n",
      "episode 6, val func loss 0.643356204032898\n",
      "\n",
      "episode 7, val func loss 0.7396119832992554\n",
      "\n",
      "episode 8, val func loss 0.7696835994720459\n",
      "\n",
      "episode 9, val func loss 0.5849358439445496\n",
      "\n",
      "episode 10, val func loss 0.7013218402862549\n",
      "\n",
      "episode 11, val func loss 0.7051990628242493\n",
      "\n",
      "episode 12, val func loss 0.6841366291046143\n",
      "\n",
      "episode 13, val func loss 0.6735308170318604\n",
      "\n",
      "episode 14, val func loss 0.6505643725395203\n",
      "\n",
      "episode 15, val func loss 0.6129624247550964\n",
      "\n",
      "episode 16, val func loss 0.6917367577552795\n",
      "\n",
      "Val func train loss in epoch 7:0.6712923422455788\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6928573250770569\n",
      "\n",
      "episode 2, val func loss 0.7017269134521484\n",
      "\n",
      "episode 3, val func loss 0.6176913976669312\n",
      "\n",
      "episode 4, val func loss 0.6991075277328491\n",
      "\n",
      "episode 5, val func loss 0.6961584091186523\n",
      "\n",
      "episode 6, val func loss 0.6347410082817078\n",
      "\n",
      "episode 7, val func loss 0.6082642078399658\n",
      "\n",
      "episode 8, val func loss 0.6086388826370239\n",
      "\n",
      "episode 9, val func loss 0.754340648651123\n",
      "\n",
      "episode 10, val func loss 0.6522532105445862\n",
      "\n",
      "episode 11, val func loss 0.6682939529418945\n",
      "\n",
      "episode 12, val func loss 0.6854522824287415\n",
      "\n",
      "episode 13, val func loss 0.6724681854248047\n",
      "\n",
      "episode 14, val func loss 0.6911676526069641\n",
      "\n",
      "episode 15, val func loss 0.6411973237991333\n",
      "\n",
      "episode 16, val func loss 0.7206110954284668\n",
      "\n",
      "Val func train loss in epoch 8:0.6715606264770031\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6781390309333801\n",
      "\n",
      "episode 2, val func loss 0.6336624622344971\n",
      "\n",
      "episode 3, val func loss 0.7154200077056885\n",
      "\n",
      "episode 4, val func loss 0.7695510983467102\n",
      "\n",
      "episode 5, val func loss 0.7398263812065125\n",
      "\n",
      "episode 6, val func loss 0.691110372543335\n",
      "\n",
      "episode 7, val func loss 0.6197505593299866\n",
      "\n",
      "episode 8, val func loss 0.7152818441390991\n",
      "\n",
      "episode 9, val func loss 0.6841861605644226\n",
      "\n",
      "episode 10, val func loss 0.6864262223243713\n",
      "\n",
      "episode 11, val func loss 0.7176256775856018\n",
      "\n",
      "episode 12, val func loss 0.6835867762565613\n",
      "\n",
      "episode 13, val func loss 0.6633324027061462\n",
      "\n",
      "episode 14, val func loss 0.6310872435569763\n",
      "\n",
      "episode 15, val func loss 0.8190557360649109\n",
      "\n",
      "episode 16, val func loss 0.689030110836029\n",
      "\n",
      "Val func train loss in epoch 9:0.6960670053958893\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7240194082260132\n",
      "\n",
      "episode 2, val func loss 0.6889849901199341\n",
      "\n",
      "episode 3, val func loss 0.7913808822631836\n",
      "\n",
      "episode 4, val func loss 0.6224147081375122\n",
      "\n",
      "episode 5, val func loss 0.6894710659980774\n",
      "\n",
      "episode 6, val func loss 0.605129599571228\n",
      "\n",
      "episode 7, val func loss 0.5482516884803772\n",
      "\n",
      "episode 8, val func loss 0.6532049775123596\n",
      "\n",
      "episode 9, val func loss 0.7110069394111633\n",
      "\n",
      "episode 10, val func loss 0.6509498953819275\n",
      "\n",
      "episode 11, val func loss 0.6991202235221863\n",
      "\n",
      "episode 12, val func loss 0.5768730640411377\n",
      "\n",
      "episode 13, val func loss 0.6970101594924927\n",
      "\n",
      "episode 14, val func loss 0.6488372683525085\n",
      "\n",
      "episode 15, val func loss 0.692363440990448\n",
      "\n",
      "episode 16, val func loss 0.6602247357368469\n",
      "\n",
      "Val func train loss in epoch 10:0.6662026904523373\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6751783490180969\n",
      "\n",
      "episode 2, val func loss 0.7132457494735718\n",
      "\n",
      "episode 3, val func loss 0.5786516070365906\n",
      "\n",
      "episode 4, val func loss 0.6467195153236389\n",
      "\n",
      "episode 5, val func loss 0.6764488816261292\n",
      "\n",
      "episode 6, val func loss 0.6737295985221863\n",
      "\n",
      "episode 7, val func loss 0.6335291862487793\n",
      "\n",
      "episode 8, val func loss 0.8983217477798462\n",
      "\n",
      "episode 9, val func loss 0.725239634513855\n",
      "\n",
      "episode 10, val func loss 0.7731415629386902\n",
      "\n",
      "episode 11, val func loss 0.6575784683227539\n",
      "\n",
      "episode 12, val func loss 0.659281849861145\n",
      "\n",
      "episode 13, val func loss 0.6803485155105591\n",
      "\n",
      "episode 14, val func loss 0.6934005618095398\n",
      "\n",
      "episode 15, val func loss 0.6929578185081482\n",
      "\n",
      "episode 16, val func loss 0.6750169396400452\n",
      "\n",
      "Val func train loss in epoch 11:0.6907993741333485\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6431589722633362\n",
      "\n",
      "episode 2, val func loss 0.6340011358261108\n",
      "\n",
      "episode 3, val func loss 0.7710453867912292\n",
      "\n",
      "episode 4, val func loss 0.6400286555290222\n",
      "\n",
      "episode 5, val func loss 0.7997707724571228\n",
      "\n",
      "episode 6, val func loss 0.6795442700386047\n",
      "\n",
      "episode 7, val func loss 0.7931815385818481\n",
      "\n",
      "episode 8, val func loss 0.770452082157135\n",
      "\n",
      "episode 9, val func loss 0.6153321862220764\n",
      "\n",
      "episode 10, val func loss 0.6789794564247131\n",
      "\n",
      "episode 11, val func loss 0.6034365296363831\n",
      "\n",
      "episode 12, val func loss 0.6602755784988403\n",
      "\n",
      "episode 13, val func loss 0.6154025793075562\n",
      "\n",
      "episode 14, val func loss 0.6087599992752075\n",
      "\n",
      "episode 15, val func loss 0.6770328879356384\n",
      "\n",
      "episode 16, val func loss 0.63395756483078\n",
      "\n",
      "Val func train loss in epoch 12:0.6765224747359753\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6618459224700928\n",
      "\n",
      "episode 2, val func loss 0.6143879890441895\n",
      "\n",
      "episode 3, val func loss 0.6678162813186646\n",
      "\n",
      "episode 4, val func loss 0.6301347017288208\n",
      "\n",
      "episode 5, val func loss 0.6672835350036621\n",
      "\n",
      "episode 6, val func loss 0.687811553478241\n",
      "\n",
      "episode 7, val func loss 0.695684015750885\n",
      "\n",
      "episode 8, val func loss 0.4939863085746765\n",
      "\n",
      "episode 9, val func loss 0.7355901002883911\n",
      "\n",
      "episode 10, val func loss 0.6643447875976562\n",
      "\n",
      "episode 11, val func loss 0.7673528790473938\n",
      "\n",
      "episode 12, val func loss 0.6296043395996094\n",
      "\n",
      "episode 13, val func loss 0.814140260219574\n",
      "\n",
      "episode 14, val func loss 0.6928165555000305\n",
      "\n",
      "episode 15, val func loss 0.777787446975708\n",
      "\n",
      "episode 16, val func loss 0.6301965713500977\n",
      "\n",
      "Val func train loss in epoch 13:0.6769239529967308\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7788826823234558\n",
      "\n",
      "episode 2, val func loss 0.5917580127716064\n",
      "\n",
      "episode 3, val func loss 0.5286174416542053\n",
      "\n",
      "episode 4, val func loss 0.6795526146888733\n",
      "\n",
      "episode 5, val func loss 0.7942812442779541\n",
      "\n",
      "episode 6, val func loss 0.6889097094535828\n",
      "\n",
      "episode 7, val func loss 0.5981639623641968\n",
      "\n",
      "episode 8, val func loss 0.6959137320518494\n",
      "\n",
      "episode 9, val func loss 0.6224275231361389\n",
      "\n",
      "episode 10, val func loss 0.5796835422515869\n",
      "\n",
      "episode 11, val func loss 0.6440513134002686\n",
      "\n",
      "episode 12, val func loss 0.7216686606407166\n",
      "\n",
      "episode 13, val func loss 0.70268714427948\n",
      "\n",
      "episode 14, val func loss 0.6685234904289246\n",
      "\n",
      "episode 15, val func loss 0.7110521793365479\n",
      "\n",
      "episode 16, val func loss 0.7032150626182556\n",
      "\n",
      "Val func train loss in epoch 14:0.6693367697298527\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6946924328804016\n",
      "\n",
      "episode 2, val func loss 0.7761996984481812\n",
      "\n",
      "episode 3, val func loss 0.7370197772979736\n",
      "\n",
      "episode 4, val func loss 0.7112329602241516\n",
      "\n",
      "episode 5, val func loss 0.7009257674217224\n",
      "\n",
      "episode 6, val func loss 0.5743904113769531\n",
      "\n",
      "episode 7, val func loss 0.7978947162628174\n",
      "\n",
      "episode 8, val func loss 0.6165190935134888\n",
      "\n",
      "episode 9, val func loss 0.8708348870277405\n",
      "\n",
      "episode 10, val func loss 0.5981628894805908\n",
      "\n",
      "episode 11, val func loss 0.7127058506011963\n",
      "\n",
      "episode 12, val func loss 0.7514761090278625\n",
      "\n",
      "episode 13, val func loss 0.6569101810455322\n",
      "\n",
      "episode 14, val func loss 0.6453140377998352\n",
      "\n",
      "episode 15, val func loss 0.7027966976165771\n",
      "\n",
      "episode 16, val func loss 0.7795015573501587\n",
      "\n",
      "Val func train loss in epoch 15:0.7079110667109489\n",
      "***********************TIME WAS 4.9039924542109175 min*****************************\n",
      "\n",
      "**********************ROUND 117 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.948042094707489\n",
      "\n",
      "episode 2, policy loss 0.9480434060096741\n",
      "\n",
      "episode 3, policy loss 0.9480429887771606\n",
      "\n",
      "episode 4, policy loss 0.948043167591095\n",
      "\n",
      "episode 5, policy loss 0.9480427503585815\n",
      "\n",
      "episode 6, policy loss 0.948043942451477\n",
      "\n",
      "episode 7, policy loss 0.9480425715446472\n",
      "\n",
      "episode 8, policy loss 0.9480429887771606\n",
      "\n",
      "episode 9, policy loss 0.9480430483818054\n",
      "\n",
      "episode 10, policy loss 0.948042631149292\n",
      "\n",
      "episode 11, policy loss 0.9480424523353577\n",
      "\n",
      "episode 12, policy loss 0.9480435252189636\n",
      "\n",
      "episode 13, policy loss 0.9480424523353577\n",
      "\n",
      "episode 14, policy loss 0.9480429887771606\n",
      "\n",
      "episode 15, policy loss 0.9480416774749756\n",
      "\n",
      "episode 16, policy loss 0.948042631149292\n",
      "\n",
      "Policy train loss in epoch 0:0.9480428323149681\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.948042631149292\n",
      "\n",
      "episode 2, policy loss 0.9480443000793457\n",
      "\n",
      "episode 3, policy loss 0.9480412602424622\n",
      "\n",
      "episode 4, policy loss 0.9480435848236084\n",
      "\n",
      "episode 5, policy loss 0.948043942451477\n",
      "\n",
      "episode 6, policy loss 0.9480422735214233\n",
      "\n",
      "episode 7, policy loss 0.9480422139167786\n",
      "\n",
      "episode 8, policy loss 0.9480417966842651\n",
      "\n",
      "episode 9, policy loss 0.9480409026145935\n",
      "\n",
      "episode 10, policy loss 0.9480423927307129\n",
      "\n",
      "episode 11, policy loss 0.9480399489402771\n",
      "\n",
      "episode 12, policy loss 0.9480422735214233\n",
      "\n",
      "episode 13, policy loss 0.9480423927307129\n",
      "\n",
      "episode 14, policy loss 0.9480417966842651\n",
      "\n",
      "episode 15, policy loss 0.9480424523353577\n",
      "\n",
      "episode 16, policy loss 0.9480417966842651\n",
      "\n",
      "Policy train loss in epoch 1:0.9480422474443913\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.9480404853820801\n",
      "\n",
      "episode 2, policy loss 0.9480400681495667\n",
      "\n",
      "episode 3, policy loss 0.9480395317077637\n",
      "\n",
      "episode 4, policy loss 0.9480398893356323\n",
      "\n",
      "episode 5, policy loss 0.9480408430099487\n",
      "\n",
      "episode 6, policy loss 0.9480407238006592\n",
      "\n",
      "episode 7, policy loss 0.9480403065681458\n",
      "\n",
      "episode 8, policy loss 0.9480387568473816\n",
      "\n",
      "episode 9, policy loss 0.9480383992195129\n",
      "\n",
      "episode 10, policy loss 0.9480380415916443\n",
      "\n",
      "episode 11, policy loss 0.9480389952659607\n",
      "\n",
      "episode 12, policy loss 0.948039710521698\n",
      "\n",
      "episode 13, policy loss 0.9480369687080383\n",
      "\n",
      "episode 14, policy loss 0.948036253452301\n",
      "\n",
      "episode 15, policy loss 0.9480379819869995\n",
      "\n",
      "episode 16, policy loss 0.948036789894104\n",
      "\n",
      "Policy train loss in epoch 2:0.9480389840900898\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.9480379223823547\n",
      "\n",
      "episode 2, policy loss 0.9480379819869995\n",
      "\n",
      "episode 3, policy loss 0.9480372071266174\n",
      "\n",
      "episode 4, policy loss 0.9480348825454712\n",
      "\n",
      "episode 5, policy loss 0.9480331540107727\n",
      "\n",
      "episode 6, policy loss 0.9480324387550354\n",
      "\n",
      "episode 7, policy loss 0.9480318427085876\n",
      "\n",
      "episode 8, policy loss 0.9480332136154175\n",
      "\n",
      "episode 9, policy loss 0.9480326771736145\n",
      "\n",
      "episode 10, policy loss 0.9480301141738892\n",
      "\n",
      "episode 11, policy loss 0.9480313062667847\n",
      "\n",
      "episode 12, policy loss 0.9480282068252563\n",
      "\n",
      "episode 13, policy loss 0.9480250477790833\n",
      "\n",
      "episode 14, policy loss 0.9480175375938416\n",
      "\n",
      "episode 15, policy loss 0.9480113387107849\n",
      "\n",
      "episode 16, policy loss 0.9479933977127075\n",
      "\n",
      "Policy train loss in epoch 3:0.9480280168354511\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.711060643196106\n",
      "\n",
      "episode 2, val func loss 0.6482557058334351\n",
      "\n",
      "episode 3, val func loss 0.641534149646759\n",
      "\n",
      "episode 4, val func loss 0.6076042056083679\n",
      "\n",
      "episode 5, val func loss 0.6167179346084595\n",
      "\n",
      "episode 6, val func loss 0.7048472762107849\n",
      "\n",
      "episode 7, val func loss 0.6326389312744141\n",
      "\n",
      "episode 8, val func loss 0.6550567150115967\n",
      "\n",
      "episode 9, val func loss 0.674456000328064\n",
      "\n",
      "episode 10, val func loss 0.626151442527771\n",
      "\n",
      "episode 11, val func loss 0.6437928676605225\n",
      "\n",
      "episode 12, val func loss 0.6766932606697083\n",
      "\n",
      "episode 13, val func loss 0.6316816806793213\n",
      "\n",
      "episode 14, val func loss 0.7393139004707336\n",
      "\n",
      "episode 15, val func loss 0.6290132999420166\n",
      "\n",
      "episode 16, val func loss 0.6611230969429016\n",
      "\n",
      "Val func train loss in epoch 0:0.6562463194131851\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.6680493950843811\n",
      "\n",
      "episode 2, val func loss 0.6376340389251709\n",
      "\n",
      "episode 3, val func loss 0.6986550092697144\n",
      "\n",
      "episode 4, val func loss 0.6226544976234436\n",
      "\n",
      "episode 5, val func loss 0.6741608381271362\n",
      "\n",
      "episode 6, val func loss 0.7548869848251343\n",
      "\n",
      "episode 7, val func loss 0.6872028708457947\n",
      "\n",
      "episode 8, val func loss 0.6231513023376465\n",
      "\n",
      "episode 9, val func loss 0.7182866334915161\n",
      "\n",
      "episode 10, val func loss 0.6623011231422424\n",
      "\n",
      "episode 11, val func loss 0.6776197552680969\n",
      "\n",
      "episode 12, val func loss 0.7271219491958618\n",
      "\n",
      "episode 13, val func loss 0.7179291248321533\n",
      "\n",
      "episode 14, val func loss 0.6353803277015686\n",
      "\n",
      "episode 15, val func loss 0.6278766393661499\n",
      "\n",
      "episode 16, val func loss 0.848744809627533\n",
      "\n",
      "Val func train loss in epoch 1:0.6863534562289715\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6524418592453003\n",
      "\n",
      "episode 2, val func loss 0.7048878073692322\n",
      "\n",
      "episode 3, val func loss 0.9001532793045044\n",
      "\n",
      "episode 4, val func loss 0.5973934531211853\n",
      "\n",
      "episode 5, val func loss 0.7452419400215149\n",
      "\n",
      "episode 6, val func loss 0.8727096915245056\n",
      "\n",
      "episode 7, val func loss 0.7269719839096069\n",
      "\n",
      "episode 8, val func loss 0.8027241230010986\n",
      "\n",
      "episode 9, val func loss 0.6895756721496582\n",
      "\n",
      "episode 10, val func loss 0.7253822088241577\n",
      "\n",
      "episode 11, val func loss 0.6956347823143005\n",
      "\n",
      "episode 12, val func loss 0.64998859167099\n",
      "\n",
      "episode 13, val func loss 0.7193721532821655\n",
      "\n",
      "episode 14, val func loss 0.6850233674049377\n",
      "\n",
      "episode 15, val func loss 0.7500619888305664\n",
      "\n",
      "episode 16, val func loss 0.7073102593421936\n",
      "\n",
      "Val func train loss in epoch 2:0.7265545725822449\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6884083151817322\n",
      "\n",
      "episode 2, val func loss 0.7200853228569031\n",
      "\n",
      "episode 3, val func loss 0.7151025533676147\n",
      "\n",
      "episode 4, val func loss 0.629365861415863\n",
      "\n",
      "episode 5, val func loss 0.5860816240310669\n",
      "\n",
      "episode 6, val func loss 0.7109512686729431\n",
      "\n",
      "episode 7, val func loss 0.7195950746536255\n",
      "\n",
      "episode 8, val func loss 0.6031792163848877\n",
      "\n",
      "episode 9, val func loss 0.6941037774085999\n",
      "\n",
      "episode 10, val func loss 0.6645323634147644\n",
      "\n",
      "episode 11, val func loss 0.6986696124076843\n",
      "\n",
      "episode 12, val func loss 0.6121580600738525\n",
      "\n",
      "episode 13, val func loss 0.596056342124939\n",
      "\n",
      "episode 14, val func loss 0.6504717469215393\n",
      "\n",
      "episode 15, val func loss 0.6642694473266602\n",
      "\n",
      "episode 16, val func loss 0.6399158835411072\n",
      "\n",
      "Val func train loss in epoch 3:0.6620591543614864\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.692823052406311\n",
      "\n",
      "episode 2, val func loss 0.624952495098114\n",
      "\n",
      "episode 3, val func loss 0.6499068737030029\n",
      "\n",
      "episode 4, val func loss 0.669689416885376\n",
      "\n",
      "episode 5, val func loss 0.7401236891746521\n",
      "\n",
      "episode 6, val func loss 0.6419730186462402\n",
      "\n",
      "episode 7, val func loss 0.7017006278038025\n",
      "\n",
      "episode 8, val func loss 0.6535631418228149\n",
      "\n",
      "episode 9, val func loss 0.5639910697937012\n",
      "\n",
      "episode 10, val func loss 0.6844924688339233\n",
      "\n",
      "episode 11, val func loss 0.7052719593048096\n",
      "\n",
      "episode 12, val func loss 0.7251245379447937\n",
      "\n",
      "episode 13, val func loss 0.7007941603660583\n",
      "\n",
      "episode 14, val func loss 0.6397346258163452\n",
      "\n",
      "episode 15, val func loss 0.707836389541626\n",
      "\n",
      "episode 16, val func loss 0.6987938284873962\n",
      "\n",
      "Val func train loss in epoch 4:0.6750482097268105\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6633841395378113\n",
      "\n",
      "episode 2, val func loss 0.7131530046463013\n",
      "\n",
      "episode 3, val func loss 0.5995041728019714\n",
      "\n",
      "episode 4, val func loss 0.7108843326568604\n",
      "\n",
      "episode 5, val func loss 0.6138321757316589\n",
      "\n",
      "episode 6, val func loss 0.637529194355011\n",
      "\n",
      "episode 7, val func loss 0.580856442451477\n",
      "\n",
      "episode 8, val func loss 0.5623190402984619\n",
      "\n",
      "episode 9, val func loss 0.5401228070259094\n",
      "\n",
      "episode 10, val func loss 0.6868920922279358\n",
      "\n",
      "episode 11, val func loss 0.6633859276771545\n",
      "\n",
      "episode 12, val func loss 0.6859357953071594\n",
      "\n",
      "episode 13, val func loss 0.6154849529266357\n",
      "\n",
      "episode 14, val func loss 0.5362134575843811\n",
      "\n",
      "episode 15, val func loss 0.6088354587554932\n",
      "\n",
      "episode 16, val func loss 0.6496179699897766\n",
      "\n",
      "Val func train loss in epoch 5:0.6292469352483749\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6122910976409912\n",
      "\n",
      "episode 2, val func loss 0.6316583752632141\n",
      "\n",
      "episode 3, val func loss 0.5673573613166809\n",
      "\n",
      "episode 4, val func loss 0.566484808921814\n",
      "\n",
      "episode 5, val func loss 0.5434145927429199\n",
      "\n",
      "episode 6, val func loss 0.6590773463249207\n",
      "\n",
      "episode 7, val func loss 0.8397805690765381\n",
      "\n",
      "episode 8, val func loss 0.646918535232544\n",
      "\n",
      "episode 9, val func loss 0.658331573009491\n",
      "\n",
      "episode 10, val func loss 0.69286048412323\n",
      "\n",
      "episode 11, val func loss 0.6203027963638306\n",
      "\n",
      "episode 12, val func loss 0.6904935836791992\n",
      "\n",
      "episode 13, val func loss 0.7041318416595459\n",
      "\n",
      "episode 14, val func loss 0.6335269212722778\n",
      "\n",
      "episode 15, val func loss 0.7840803265571594\n",
      "\n",
      "episode 16, val func loss 0.6853671073913574\n",
      "\n",
      "Val func train loss in epoch 6:0.6585048325359821\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7127305865287781\n",
      "\n",
      "episode 2, val func loss 0.7025550603866577\n",
      "\n",
      "episode 3, val func loss 0.6810296177864075\n",
      "\n",
      "episode 4, val func loss 0.6821040511131287\n",
      "\n",
      "episode 5, val func loss 0.6861034035682678\n",
      "\n",
      "episode 6, val func loss 0.6545783281326294\n",
      "\n",
      "episode 7, val func loss 0.6087813973426819\n",
      "\n",
      "episode 8, val func loss 0.6649473309516907\n",
      "\n",
      "episode 9, val func loss 0.767231822013855\n",
      "\n",
      "episode 10, val func loss 0.6355882287025452\n",
      "\n",
      "episode 11, val func loss 0.5921808481216431\n",
      "\n",
      "episode 12, val func loss 0.6302853226661682\n",
      "\n",
      "episode 13, val func loss 0.6150830388069153\n",
      "\n",
      "episode 14, val func loss 0.6248260140419006\n",
      "\n",
      "episode 15, val func loss 0.651725172996521\n",
      "\n",
      "episode 16, val func loss 0.6606206893920898\n",
      "\n",
      "Val func train loss in epoch 7:0.6606481820344925\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6035416722297668\n",
      "\n",
      "episode 2, val func loss 0.598663866519928\n",
      "\n",
      "episode 3, val func loss 0.6814859509468079\n",
      "\n",
      "episode 4, val func loss 0.6000214219093323\n",
      "\n",
      "episode 5, val func loss 0.6831571459770203\n",
      "\n",
      "episode 6, val func loss 0.5896753072738647\n",
      "\n",
      "episode 7, val func loss 0.7255326509475708\n",
      "\n",
      "episode 8, val func loss 0.6257157921791077\n",
      "\n",
      "episode 9, val func loss 0.7623050808906555\n",
      "\n",
      "episode 10, val func loss 0.6318273544311523\n",
      "\n",
      "episode 11, val func loss 0.6415020823478699\n",
      "\n",
      "episode 12, val func loss 0.7536616325378418\n",
      "\n",
      "episode 13, val func loss 0.5668908953666687\n",
      "\n",
      "episode 14, val func loss 0.6055147051811218\n",
      "\n",
      "episode 15, val func loss 0.7584604024887085\n",
      "\n",
      "episode 16, val func loss 0.5320769548416138\n",
      "\n",
      "Val func train loss in epoch 8:0.6475020572543144\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.7085895538330078\n",
      "\n",
      "episode 2, val func loss 0.6992555856704712\n",
      "\n",
      "episode 3, val func loss 0.6500222086906433\n",
      "\n",
      "episode 4, val func loss 0.6099694967269897\n",
      "\n",
      "episode 5, val func loss 0.6219419240951538\n",
      "\n",
      "episode 6, val func loss 0.6722429990768433\n",
      "\n",
      "episode 7, val func loss 0.6899356842041016\n",
      "\n",
      "episode 8, val func loss 0.6963464617729187\n",
      "\n",
      "episode 9, val func loss 0.5879160761833191\n",
      "\n",
      "episode 10, val func loss 0.7368049621582031\n",
      "\n",
      "episode 11, val func loss 0.6012676358222961\n",
      "\n",
      "episode 12, val func loss 0.6141689419746399\n",
      "\n",
      "episode 13, val func loss 0.6550381779670715\n",
      "\n",
      "episode 14, val func loss 0.6721388697624207\n",
      "\n",
      "episode 15, val func loss 0.6928482055664062\n",
      "\n",
      "episode 16, val func loss 0.6283114552497864\n",
      "\n",
      "Val func train loss in epoch 9:0.658549889922142\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6851693391799927\n",
      "\n",
      "episode 2, val func loss 0.7557134628295898\n",
      "\n",
      "episode 3, val func loss 0.5956223011016846\n",
      "\n",
      "episode 4, val func loss 0.631361722946167\n",
      "\n",
      "episode 5, val func loss 0.6302956342697144\n",
      "\n",
      "episode 6, val func loss 0.7018347978591919\n",
      "\n",
      "episode 7, val func loss 0.6647937297821045\n",
      "\n",
      "episode 8, val func loss 0.7670590877532959\n",
      "\n",
      "episode 9, val func loss 0.613256573677063\n",
      "\n",
      "episode 10, val func loss 0.7081483602523804\n",
      "\n",
      "episode 11, val func loss 0.6804145574569702\n",
      "\n",
      "episode 12, val func loss 0.701865017414093\n",
      "\n",
      "episode 13, val func loss 0.5566731691360474\n",
      "\n",
      "episode 14, val func loss 0.6832553148269653\n",
      "\n",
      "episode 15, val func loss 0.6353272199630737\n",
      "\n",
      "episode 16, val func loss 0.6854820251464844\n",
      "\n",
      "Val func train loss in epoch 10:0.6685170195996761\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.5568448305130005\n",
      "\n",
      "episode 2, val func loss 0.6074421405792236\n",
      "\n",
      "episode 3, val func loss 0.6449949145317078\n",
      "\n",
      "episode 4, val func loss 0.5761762261390686\n",
      "\n",
      "episode 5, val func loss 0.6354493498802185\n",
      "\n",
      "episode 6, val func loss 0.6360399723052979\n",
      "\n",
      "episode 7, val func loss 0.6043713092803955\n",
      "\n",
      "episode 8, val func loss 0.603898286819458\n",
      "\n",
      "episode 9, val func loss 0.6381679177284241\n",
      "\n",
      "episode 10, val func loss 0.6224533319473267\n",
      "\n",
      "episode 11, val func loss 0.6455508470535278\n",
      "\n",
      "episode 12, val func loss 0.607887864112854\n",
      "\n",
      "episode 13, val func loss 0.7760072946548462\n",
      "\n",
      "episode 14, val func loss 0.6351842880249023\n",
      "\n",
      "episode 15, val func loss 0.6256938576698303\n",
      "\n",
      "episode 16, val func loss 0.6107429265975952\n",
      "\n",
      "Val func train loss in epoch 11:0.6266815848648548\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6074442267417908\n",
      "\n",
      "episode 2, val func loss 0.6823872327804565\n",
      "\n",
      "episode 3, val func loss 0.6182213425636292\n",
      "\n",
      "episode 4, val func loss 0.6834304928779602\n",
      "\n",
      "episode 5, val func loss 0.6524947881698608\n",
      "\n",
      "episode 6, val func loss 0.6296097636222839\n",
      "\n",
      "episode 7, val func loss 0.6323645710945129\n",
      "\n",
      "episode 8, val func loss 0.6508601903915405\n",
      "\n",
      "episode 9, val func loss 0.6500388383865356\n",
      "\n",
      "episode 10, val func loss 0.680463433265686\n",
      "\n",
      "episode 11, val func loss 0.6595406532287598\n",
      "\n",
      "episode 12, val func loss 0.714611828327179\n",
      "\n",
      "episode 13, val func loss 0.6562665700912476\n",
      "\n",
      "episode 14, val func loss 0.6895071864128113\n",
      "\n",
      "episode 15, val func loss 0.7000199556350708\n",
      "\n",
      "episode 16, val func loss 0.6297731995582581\n",
      "\n",
      "Val func train loss in epoch 12:0.6585646420717239\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.7240413427352905\n",
      "\n",
      "episode 2, val func loss 0.6093836426734924\n",
      "\n",
      "episode 3, val func loss 0.7823176980018616\n",
      "\n",
      "episode 4, val func loss 0.6124418377876282\n",
      "\n",
      "episode 5, val func loss 0.7637398838996887\n",
      "\n",
      "episode 6, val func loss 0.6231281161308289\n",
      "\n",
      "episode 7, val func loss 0.7005642652511597\n",
      "\n",
      "episode 8, val func loss 0.6066036224365234\n",
      "\n",
      "episode 9, val func loss 0.6498495936393738\n",
      "\n",
      "episode 10, val func loss 0.696717381477356\n",
      "\n",
      "episode 11, val func loss 0.6625025272369385\n",
      "\n",
      "episode 12, val func loss 0.6756182909011841\n",
      "\n",
      "episode 13, val func loss 0.6958073377609253\n",
      "\n",
      "episode 14, val func loss 0.6723321676254272\n",
      "\n",
      "episode 15, val func loss 0.5818935632705688\n",
      "\n",
      "episode 16, val func loss 0.7068555951118469\n",
      "\n",
      "Val func train loss in epoch 13:0.6727373041212559\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.5817340612411499\n",
      "\n",
      "episode 2, val func loss 0.6518892049789429\n",
      "\n",
      "episode 3, val func loss 0.759914219379425\n",
      "\n",
      "episode 4, val func loss 0.6030839085578918\n",
      "\n",
      "episode 5, val func loss 0.591655433177948\n",
      "\n",
      "episode 6, val func loss 0.763515830039978\n",
      "\n",
      "episode 7, val func loss 0.7095775008201599\n",
      "\n",
      "episode 8, val func loss 0.6462346315383911\n",
      "\n",
      "episode 9, val func loss 0.6468915939331055\n",
      "\n",
      "episode 10, val func loss 0.6518351435661316\n",
      "\n",
      "episode 11, val func loss 0.6063843965530396\n",
      "\n",
      "episode 12, val func loss 0.7870047092437744\n",
      "\n",
      "episode 13, val func loss 0.6454747319221497\n",
      "\n",
      "episode 14, val func loss 0.612337052822113\n",
      "\n",
      "episode 15, val func loss 0.7246440649032593\n",
      "\n",
      "episode 16, val func loss 0.6726016998291016\n",
      "\n",
      "Val func train loss in epoch 14:0.6659236364066601\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6378520727157593\n",
      "\n",
      "episode 2, val func loss 0.8074348568916321\n",
      "\n",
      "episode 3, val func loss 0.6812493801116943\n",
      "\n",
      "episode 4, val func loss 0.6125651001930237\n",
      "\n",
      "episode 5, val func loss 0.6984883546829224\n",
      "\n",
      "episode 6, val func loss 0.6913438439369202\n",
      "\n",
      "episode 7, val func loss 0.7873402833938599\n",
      "\n",
      "episode 8, val func loss 0.5833823680877686\n",
      "\n",
      "episode 9, val func loss 0.8009936213493347\n",
      "\n",
      "episode 10, val func loss 0.654919445514679\n",
      "\n",
      "episode 11, val func loss 0.6742923855781555\n",
      "\n",
      "episode 12, val func loss 0.7113271951675415\n",
      "\n",
      "episode 13, val func loss 0.6769505739212036\n",
      "\n",
      "episode 14, val func loss 0.6365569829940796\n",
      "\n",
      "episode 15, val func loss 0.7223438024520874\n",
      "\n",
      "episode 16, val func loss 0.6624267101287842\n",
      "\n",
      "Val func train loss in epoch 15:0.6899666860699654\n",
      "***********************TIME WAS 4.907640290260315 min*****************************\n",
      "\n",
      "**********************ROUND 118 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.1388535499572754\n",
      "\n",
      "episode 2, policy loss 1.1388245820999146\n",
      "\n",
      "episode 3, policy loss 1.138765811920166\n",
      "\n",
      "episode 4, policy loss 1.1387242078781128\n",
      "\n",
      "episode 5, policy loss 1.1386066675186157\n",
      "\n",
      "episode 6, policy loss 1.1384539604187012\n",
      "\n",
      "episode 7, policy loss 1.1382417678833008\n",
      "\n",
      "episode 8, policy loss 1.1378018856048584\n",
      "\n",
      "episode 9, policy loss 1.1372207403182983\n",
      "\n",
      "episode 10, policy loss 1.135464072227478\n",
      "\n",
      "episode 11, policy loss 1.1320550441741943\n",
      "\n",
      "episode 12, policy loss 1.1206425428390503\n",
      "\n",
      "episode 13, policy loss 1.0720146894454956\n",
      "\n",
      "episode 14, policy loss 1.0777239799499512\n",
      "\n",
      "episode 15, policy loss 1.0875402688980103\n",
      "\n",
      "episode 16, policy loss 1.0393776893615723\n",
      "\n",
      "Policy train loss in epoch 0:1.1193944662809372\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.068894624710083\n",
      "\n",
      "episode 2, policy loss 1.0714291334152222\n",
      "\n",
      "episode 3, policy loss 1.0535413026809692\n",
      "\n",
      "episode 4, policy loss 1.0498965978622437\n",
      "\n",
      "episode 5, policy loss 1.0634773969650269\n",
      "\n",
      "episode 6, policy loss 1.0481711626052856\n",
      "\n",
      "episode 7, policy loss 1.0393095016479492\n",
      "\n",
      "episode 8, policy loss 1.0439894199371338\n",
      "\n",
      "episode 9, policy loss 1.0474961996078491\n",
      "\n",
      "episode 10, policy loss 1.0389342308044434\n",
      "\n",
      "episode 11, policy loss 1.051744818687439\n",
      "\n",
      "episode 12, policy loss 1.0481477975845337\n",
      "\n",
      "episode 13, policy loss 1.0380889177322388\n",
      "\n",
      "episode 14, policy loss 1.0422455072402954\n",
      "\n",
      "episode 15, policy loss 1.052289605140686\n",
      "\n",
      "episode 16, policy loss 1.0385510921478271\n",
      "\n",
      "Policy train loss in epoch 1:1.0497629567980766\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.043100357055664\n",
      "\n",
      "episode 2, policy loss 1.0480366945266724\n",
      "\n",
      "episode 3, policy loss 1.042429804801941\n",
      "\n",
      "episode 4, policy loss 1.0410327911376953\n",
      "\n",
      "episode 5, policy loss 1.046656608581543\n",
      "\n",
      "episode 6, policy loss 1.0403327941894531\n",
      "\n",
      "episode 7, policy loss 1.041273593902588\n",
      "\n",
      "episode 8, policy loss 1.0402899980545044\n",
      "\n",
      "episode 9, policy loss 1.041986107826233\n",
      "\n",
      "episode 10, policy loss 1.0401016473770142\n",
      "\n",
      "episode 11, policy loss 1.043205976486206\n",
      "\n",
      "episode 12, policy loss 1.043413519859314\n",
      "\n",
      "episode 13, policy loss 1.0423616170883179\n",
      "\n",
      "episode 14, policy loss 1.0461103916168213\n",
      "\n",
      "episode 15, policy loss 1.0418555736541748\n",
      "\n",
      "episode 16, policy loss 1.036065697669983\n",
      "\n",
      "Policy train loss in epoch 2:1.0423908233642578\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.0398948192596436\n",
      "\n",
      "episode 2, policy loss 1.0407902002334595\n",
      "\n",
      "episode 3, policy loss 1.0421029329299927\n",
      "\n",
      "episode 4, policy loss 1.0385282039642334\n",
      "\n",
      "episode 5, policy loss 1.037739872932434\n",
      "\n",
      "episode 6, policy loss 1.0391637086868286\n",
      "\n",
      "episode 7, policy loss 1.0400327444076538\n",
      "\n",
      "episode 8, policy loss 1.0403062105178833\n",
      "\n",
      "episode 9, policy loss 1.0385034084320068\n",
      "\n",
      "episode 10, policy loss 1.0401113033294678\n",
      "\n",
      "episode 11, policy loss 1.037312626838684\n",
      "\n",
      "episode 12, policy loss 1.038673758506775\n",
      "\n",
      "episode 13, policy loss 1.036759853363037\n",
      "\n",
      "episode 14, policy loss 1.0362670421600342\n",
      "\n",
      "episode 15, policy loss 1.0368880033493042\n",
      "\n",
      "episode 16, policy loss 1.034849762916565\n",
      "\n",
      "Policy train loss in epoch 3:1.0386202782392502\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.64057457447052\n",
      "\n",
      "episode 2, val func loss 0.6287809014320374\n",
      "\n",
      "episode 3, val func loss 0.72142493724823\n",
      "\n",
      "episode 4, val func loss 0.7220388054847717\n",
      "\n",
      "episode 5, val func loss 0.611339271068573\n",
      "\n",
      "episode 6, val func loss 0.6899955868721008\n",
      "\n",
      "episode 7, val func loss 0.8082205653190613\n",
      "\n",
      "episode 8, val func loss 0.5778590440750122\n",
      "\n",
      "episode 9, val func loss 0.6248353719711304\n",
      "\n",
      "episode 10, val func loss 0.6039009094238281\n",
      "\n",
      "episode 11, val func loss 0.6101794838905334\n",
      "\n",
      "episode 12, val func loss 0.6866180300712585\n",
      "\n",
      "episode 13, val func loss 0.6327052116394043\n",
      "\n",
      "episode 14, val func loss 0.7063422799110413\n",
      "\n",
      "episode 15, val func loss 0.6125646829605103\n",
      "\n",
      "episode 16, val func loss 0.7017300724983215\n",
      "\n",
      "Val func train loss in epoch 0:0.6611943580210209\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.6408471465110779\n",
      "\n",
      "episode 2, val func loss 0.664739191532135\n",
      "\n",
      "episode 3, val func loss 0.6506848335266113\n",
      "\n",
      "episode 4, val func loss 0.7778016328811646\n",
      "\n",
      "episode 5, val func loss 0.6876087188720703\n",
      "\n",
      "episode 6, val func loss 0.6955453157424927\n",
      "\n",
      "episode 7, val func loss 0.8159313201904297\n",
      "\n",
      "episode 8, val func loss 0.5993553400039673\n",
      "\n",
      "episode 9, val func loss 0.7081695199012756\n",
      "\n",
      "episode 10, val func loss 0.6515868902206421\n",
      "\n",
      "episode 11, val func loss 0.6956799030303955\n",
      "\n",
      "episode 12, val func loss 0.6229845285415649\n",
      "\n",
      "episode 13, val func loss 0.716894268989563\n",
      "\n",
      "episode 14, val func loss 0.7146690487861633\n",
      "\n",
      "episode 15, val func loss 0.6681199073791504\n",
      "\n",
      "episode 16, val func loss 0.6817499399185181\n",
      "\n",
      "Val func train loss in epoch 1:0.6870229691267014\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.5533812046051025\n",
      "\n",
      "episode 2, val func loss 0.5986678004264832\n",
      "\n",
      "episode 3, val func loss 0.689507246017456\n",
      "\n",
      "episode 4, val func loss 0.6910894513130188\n",
      "\n",
      "episode 5, val func loss 0.6304217576980591\n",
      "\n",
      "episode 6, val func loss 0.6636451482772827\n",
      "\n",
      "episode 7, val func loss 0.575766384601593\n",
      "\n",
      "episode 8, val func loss 0.7256010174751282\n",
      "\n",
      "episode 9, val func loss 0.7242414951324463\n",
      "\n",
      "episode 10, val func loss 0.6368876695632935\n",
      "\n",
      "episode 11, val func loss 0.6498040556907654\n",
      "\n",
      "episode 12, val func loss 0.6783374547958374\n",
      "\n",
      "episode 13, val func loss 0.5867710709571838\n",
      "\n",
      "episode 14, val func loss 0.6234962344169617\n",
      "\n",
      "episode 15, val func loss 0.6371551752090454\n",
      "\n",
      "episode 16, val func loss 0.6588569283485413\n",
      "\n",
      "Val func train loss in epoch 2:0.6452268809080124\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6252351403236389\n",
      "\n",
      "episode 2, val func loss 0.5965907573699951\n",
      "\n",
      "episode 3, val func loss 0.626567542552948\n",
      "\n",
      "episode 4, val func loss 0.5986338257789612\n",
      "\n",
      "episode 5, val func loss 0.6107365489006042\n",
      "\n",
      "episode 6, val func loss 0.5640280842781067\n",
      "\n",
      "episode 7, val func loss 0.5938252806663513\n",
      "\n",
      "episode 8, val func loss 0.6253966689109802\n",
      "\n",
      "episode 9, val func loss 0.6690102815628052\n",
      "\n",
      "episode 10, val func loss 0.6456173062324524\n",
      "\n",
      "episode 11, val func loss 0.6422602534294128\n",
      "\n",
      "episode 12, val func loss 0.6388165950775146\n",
      "\n",
      "episode 13, val func loss 0.6532188057899475\n",
      "\n",
      "episode 14, val func loss 0.647691547870636\n",
      "\n",
      "episode 15, val func loss 0.656546950340271\n",
      "\n",
      "episode 16, val func loss 0.6332718729972839\n",
      "\n",
      "Val func train loss in epoch 3:0.6267154663801193\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7242573499679565\n",
      "\n",
      "episode 2, val func loss 0.6921838521957397\n",
      "\n",
      "episode 3, val func loss 0.7124857902526855\n",
      "\n",
      "episode 4, val func loss 0.7272927165031433\n",
      "\n",
      "episode 5, val func loss 0.7345926761627197\n",
      "\n",
      "episode 6, val func loss 0.682567834854126\n",
      "\n",
      "episode 7, val func loss 0.7974626421928406\n",
      "\n",
      "episode 8, val func loss 0.7303426861763\n",
      "\n",
      "episode 9, val func loss 0.7450855374336243\n",
      "\n",
      "episode 10, val func loss 0.6330139636993408\n",
      "\n",
      "episode 11, val func loss 0.6743031740188599\n",
      "\n",
      "episode 12, val func loss 0.7009564638137817\n",
      "\n",
      "episode 13, val func loss 0.6376245021820068\n",
      "\n",
      "episode 14, val func loss 0.5992692708969116\n",
      "\n",
      "episode 15, val func loss 0.7065731883049011\n",
      "\n",
      "episode 16, val func loss 0.634486734867096\n",
      "\n",
      "Val func train loss in epoch 4:0.6957811489701271\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6609833836555481\n",
      "\n",
      "episode 2, val func loss 0.7165504097938538\n",
      "\n",
      "episode 3, val func loss 0.6378248929977417\n",
      "\n",
      "episode 4, val func loss 0.6187067031860352\n",
      "\n",
      "episode 5, val func loss 0.7189573049545288\n",
      "\n",
      "episode 6, val func loss 0.6062761545181274\n",
      "\n",
      "episode 7, val func loss 0.6449300646781921\n",
      "\n",
      "episode 8, val func loss 0.6126112937927246\n",
      "\n",
      "episode 9, val func loss 0.6930927038192749\n",
      "\n",
      "episode 10, val func loss 0.5539175868034363\n",
      "\n",
      "episode 11, val func loss 0.6524686813354492\n",
      "\n",
      "episode 12, val func loss 0.6455098390579224\n",
      "\n",
      "episode 13, val func loss 0.6662284731864929\n",
      "\n",
      "episode 14, val func loss 0.6009539365768433\n",
      "\n",
      "episode 15, val func loss 0.6658642292022705\n",
      "\n",
      "episode 16, val func loss 0.6598306894302368\n",
      "\n",
      "Val func train loss in epoch 5:0.6471691466867924\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.5817224383354187\n",
      "\n",
      "episode 2, val func loss 0.650863766670227\n",
      "\n",
      "episode 3, val func loss 0.6373911499977112\n",
      "\n",
      "episode 4, val func loss 0.6074379086494446\n",
      "\n",
      "episode 5, val func loss 0.5541107654571533\n",
      "\n",
      "episode 6, val func loss 0.7042805552482605\n",
      "\n",
      "episode 7, val func loss 0.5881879329681396\n",
      "\n",
      "episode 8, val func loss 0.6412204504013062\n",
      "\n",
      "episode 9, val func loss 0.6211740970611572\n",
      "\n",
      "episode 10, val func loss 0.7693251967430115\n",
      "\n",
      "episode 11, val func loss 0.7090663313865662\n",
      "\n",
      "episode 12, val func loss 0.668718695640564\n",
      "\n",
      "episode 13, val func loss 0.6346961259841919\n",
      "\n",
      "episode 14, val func loss 0.6427363753318787\n",
      "\n",
      "episode 15, val func loss 0.6881586313247681\n",
      "\n",
      "episode 16, val func loss 0.6264883875846863\n",
      "\n",
      "Val func train loss in epoch 6:0.6453486755490303\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.5951902866363525\n",
      "\n",
      "episode 2, val func loss 0.739094614982605\n",
      "\n",
      "episode 3, val func loss 0.5953299403190613\n",
      "\n",
      "episode 4, val func loss 0.6899087429046631\n",
      "\n",
      "episode 5, val func loss 0.7133659720420837\n",
      "\n",
      "episode 6, val func loss 0.7320473194122314\n",
      "\n",
      "episode 7, val func loss 0.6087580323219299\n",
      "\n",
      "episode 8, val func loss 0.64741450548172\n",
      "\n",
      "episode 9, val func loss 0.6401427388191223\n",
      "\n",
      "episode 10, val func loss 0.6252401471138\n",
      "\n",
      "episode 11, val func loss 0.631607711315155\n",
      "\n",
      "episode 12, val func loss 0.522850513458252\n",
      "\n",
      "episode 13, val func loss 0.6008641719818115\n",
      "\n",
      "episode 14, val func loss 0.6198487877845764\n",
      "\n",
      "episode 15, val func loss 0.6380366086959839\n",
      "\n",
      "episode 16, val func loss 0.6548240780830383\n",
      "\n",
      "Val func train loss in epoch 7:0.6409077607095242\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6117110848426819\n",
      "\n",
      "episode 2, val func loss 0.6894842386245728\n",
      "\n",
      "episode 3, val func loss 0.6287757158279419\n",
      "\n",
      "episode 4, val func loss 0.655126690864563\n",
      "\n",
      "episode 5, val func loss 0.6464938521385193\n",
      "\n",
      "episode 6, val func loss 0.606830358505249\n",
      "\n",
      "episode 7, val func loss 0.6513487100601196\n",
      "\n",
      "episode 8, val func loss 0.713336706161499\n",
      "\n",
      "episode 9, val func loss 0.5834442973136902\n",
      "\n",
      "episode 10, val func loss 0.6718624234199524\n",
      "\n",
      "episode 11, val func loss 0.684465765953064\n",
      "\n",
      "episode 12, val func loss 0.6220559477806091\n",
      "\n",
      "episode 13, val func loss 0.7335198521614075\n",
      "\n",
      "episode 14, val func loss 0.694791853427887\n",
      "\n",
      "episode 15, val func loss 0.643297016620636\n",
      "\n",
      "episode 16, val func loss 0.633929431438446\n",
      "\n",
      "Val func train loss in epoch 8:0.6544046215713024\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6624780297279358\n",
      "\n",
      "episode 2, val func loss 0.5618703961372375\n",
      "\n",
      "episode 3, val func loss 0.624087393283844\n",
      "\n",
      "episode 4, val func loss 0.7017384767532349\n",
      "\n",
      "episode 5, val func loss 0.6843438148498535\n",
      "\n",
      "episode 6, val func loss 0.6284993886947632\n",
      "\n",
      "episode 7, val func loss 0.5746338963508606\n",
      "\n",
      "episode 8, val func loss 0.5532883405685425\n",
      "\n",
      "episode 9, val func loss 0.6544532775878906\n",
      "\n",
      "episode 10, val func loss 0.6825779676437378\n",
      "\n",
      "episode 11, val func loss 0.6930473446846008\n",
      "\n",
      "episode 12, val func loss 0.6192770600318909\n",
      "\n",
      "episode 13, val func loss 0.6801798343658447\n",
      "\n",
      "episode 14, val func loss 0.6946089267730713\n",
      "\n",
      "episode 15, val func loss 0.5171855688095093\n",
      "\n",
      "episode 16, val func loss 0.6640282869338989\n",
      "\n",
      "Val func train loss in epoch 9:0.6372686251997948\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6288343667984009\n",
      "\n",
      "episode 2, val func loss 0.68874192237854\n",
      "\n",
      "episode 3, val func loss 0.7447911500930786\n",
      "\n",
      "episode 4, val func loss 0.6031039953231812\n",
      "\n",
      "episode 5, val func loss 0.6492966413497925\n",
      "\n",
      "episode 6, val func loss 0.6064910292625427\n",
      "\n",
      "episode 7, val func loss 0.5791837573051453\n",
      "\n",
      "episode 8, val func loss 0.6767630577087402\n",
      "\n",
      "episode 9, val func loss 0.5800057649612427\n",
      "\n",
      "episode 10, val func loss 0.6354191303253174\n",
      "\n",
      "episode 11, val func loss 0.6351409554481506\n",
      "\n",
      "episode 12, val func loss 0.6020702123641968\n",
      "\n",
      "episode 13, val func loss 0.6879972219467163\n",
      "\n",
      "episode 14, val func loss 0.7362198233604431\n",
      "\n",
      "episode 15, val func loss 0.7153051495552063\n",
      "\n",
      "episode 16, val func loss 0.7992536425590515\n",
      "\n",
      "Val func train loss in epoch 10:0.6605386137962341\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.5889932513237\n",
      "\n",
      "episode 2, val func loss 0.6380130052566528\n",
      "\n",
      "episode 3, val func loss 0.6831188201904297\n",
      "\n",
      "episode 4, val func loss 0.7563930153846741\n",
      "\n",
      "episode 5, val func loss 0.5807230472564697\n",
      "\n",
      "episode 6, val func loss 0.6714689135551453\n",
      "\n",
      "episode 7, val func loss 0.6599805355072021\n",
      "\n",
      "episode 8, val func loss 0.6482416987419128\n",
      "\n",
      "episode 9, val func loss 0.6897247433662415\n",
      "\n",
      "episode 10, val func loss 0.676360547542572\n",
      "\n",
      "episode 11, val func loss 0.6212356686592102\n",
      "\n",
      "episode 12, val func loss 0.7122277021408081\n",
      "\n",
      "episode 13, val func loss 0.6126524806022644\n",
      "\n",
      "episode 14, val func loss 0.7156259417533875\n",
      "\n",
      "episode 15, val func loss 0.5921537280082703\n",
      "\n",
      "episode 16, val func loss 0.7231131792068481\n",
      "\n",
      "Val func train loss in epoch 11:0.6606266424059868\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6589292287826538\n",
      "\n",
      "episode 2, val func loss 0.629374086856842\n",
      "\n",
      "episode 3, val func loss 0.6348145604133606\n",
      "\n",
      "episode 4, val func loss 0.5597653985023499\n",
      "\n",
      "episode 5, val func loss 0.6476162672042847\n",
      "\n",
      "episode 6, val func loss 0.7877512574195862\n",
      "\n",
      "episode 7, val func loss 0.6463168859481812\n",
      "\n",
      "episode 8, val func loss 0.6739898324012756\n",
      "\n",
      "episode 9, val func loss 0.6025195121765137\n",
      "\n",
      "episode 10, val func loss 0.5975172519683838\n",
      "\n",
      "episode 11, val func loss 0.5611593723297119\n",
      "\n",
      "episode 12, val func loss 0.6006172895431519\n",
      "\n",
      "episode 13, val func loss 0.6661034822463989\n",
      "\n",
      "episode 14, val func loss 0.551849901676178\n",
      "\n",
      "episode 15, val func loss 0.61998450756073\n",
      "\n",
      "episode 16, val func loss 0.6098427176475525\n",
      "\n",
      "Val func train loss in epoch 12:0.6280094720423222\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6106869578361511\n",
      "\n",
      "episode 2, val func loss 0.7116576433181763\n",
      "\n",
      "episode 3, val func loss 0.7866070866584778\n",
      "\n",
      "episode 4, val func loss 0.5521252751350403\n",
      "\n",
      "episode 5, val func loss 0.6038618087768555\n",
      "\n",
      "episode 6, val func loss 0.6402511596679688\n",
      "\n",
      "episode 7, val func loss 0.7008187770843506\n",
      "\n",
      "episode 8, val func loss 0.6589276194572449\n",
      "\n",
      "episode 9, val func loss 0.5956144332885742\n",
      "\n",
      "episode 10, val func loss 0.612260639667511\n",
      "\n",
      "episode 11, val func loss 0.6895245313644409\n",
      "\n",
      "episode 12, val func loss 0.6567885279655457\n",
      "\n",
      "episode 13, val func loss 0.6600338816642761\n",
      "\n",
      "episode 14, val func loss 0.6608337163925171\n",
      "\n",
      "episode 15, val func loss 0.6170406937599182\n",
      "\n",
      "episode 16, val func loss 0.6600421667098999\n",
      "\n",
      "Val func train loss in epoch 13:0.6510671824216843\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.7644006609916687\n",
      "\n",
      "episode 2, val func loss 0.767632782459259\n",
      "\n",
      "episode 3, val func loss 0.6748841404914856\n",
      "\n",
      "episode 4, val func loss 0.8273175358772278\n",
      "\n",
      "episode 5, val func loss 0.6292503476142883\n",
      "\n",
      "episode 6, val func loss 0.7334302067756653\n",
      "\n",
      "episode 7, val func loss 0.6252342462539673\n",
      "\n",
      "episode 8, val func loss 0.618229866027832\n",
      "\n",
      "episode 9, val func loss 0.6139222383499146\n",
      "\n",
      "episode 10, val func loss 0.6092135310173035\n",
      "\n",
      "episode 11, val func loss 0.6275615692138672\n",
      "\n",
      "episode 12, val func loss 0.5639506578445435\n",
      "\n",
      "episode 13, val func loss 0.6780408024787903\n",
      "\n",
      "episode 14, val func loss 0.707088828086853\n",
      "\n",
      "episode 15, val func loss 0.65157151222229\n",
      "\n",
      "episode 16, val func loss 0.586146891117096\n",
      "\n",
      "Val func train loss in epoch 14:0.6673672385513783\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6221341490745544\n",
      "\n",
      "episode 2, val func loss 0.7111813426017761\n",
      "\n",
      "episode 3, val func loss 0.641859769821167\n",
      "\n",
      "episode 4, val func loss 0.5681845545768738\n",
      "\n",
      "episode 5, val func loss 0.6129531264305115\n",
      "\n",
      "episode 6, val func loss 0.643556535243988\n",
      "\n",
      "episode 7, val func loss 0.6449094414710999\n",
      "\n",
      "episode 8, val func loss 0.6663195490837097\n",
      "\n",
      "episode 9, val func loss 0.6450440287590027\n",
      "\n",
      "episode 10, val func loss 0.7387287616729736\n",
      "\n",
      "episode 11, val func loss 0.6203938722610474\n",
      "\n",
      "episode 12, val func loss 0.6680508852005005\n",
      "\n",
      "episode 13, val func loss 0.6830931305885315\n",
      "\n",
      "episode 14, val func loss 0.6105412840843201\n",
      "\n",
      "episode 15, val func loss 0.5953477025032043\n",
      "\n",
      "episode 16, val func loss 0.6042647361755371\n",
      "\n",
      "Val func train loss in epoch 15:0.6422851793467999\n",
      "***********************TIME WAS 4.91609886487325 min*****************************\n",
      "\n",
      "**********************ROUND 119 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.8606632947921753\n",
      "\n",
      "episode 2, policy loss 1.7309523820877075\n",
      "\n",
      "episode 3, policy loss 1.6012893915176392\n",
      "\n",
      "episode 4, policy loss 1.765386700630188\n",
      "\n",
      "episode 5, policy loss 1.6958203315734863\n",
      "\n",
      "episode 6, policy loss 1.503570318222046\n",
      "\n",
      "episode 7, policy loss 1.7002887725830078\n",
      "\n",
      "episode 8, policy loss 1.8086429834365845\n",
      "\n",
      "episode 9, policy loss 1.7576103210449219\n",
      "\n",
      "episode 10, policy loss 1.8903006315231323\n",
      "\n",
      "episode 11, policy loss 1.8355817794799805\n",
      "\n",
      "episode 12, policy loss 1.767065405845642\n",
      "\n",
      "episode 13, policy loss 1.6345953941345215\n",
      "\n",
      "episode 14, policy loss 1.7087243795394897\n",
      "\n",
      "episode 15, policy loss 1.825675368309021\n",
      "\n",
      "episode 16, policy loss 1.8271491527557373\n",
      "\n",
      "Policy train loss in epoch 0:1.744582287967205\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.7970179319381714\n",
      "\n",
      "episode 2, policy loss 1.782614827156067\n",
      "\n",
      "episode 3, policy loss 1.8141324520111084\n",
      "\n",
      "episode 4, policy loss 1.7594093084335327\n",
      "\n",
      "episode 5, policy loss 1.509536862373352\n",
      "\n",
      "episode 6, policy loss 1.6359508037567139\n",
      "\n",
      "episode 7, policy loss 1.7091064453125\n",
      "\n",
      "episode 8, policy loss 1.8915711641311646\n",
      "\n",
      "episode 9, policy loss 1.6351444721221924\n",
      "\n",
      "episode 10, policy loss 1.811315894126892\n",
      "\n",
      "episode 11, policy loss 1.7044479846954346\n",
      "\n",
      "episode 12, policy loss 1.706312656402588\n",
      "\n",
      "episode 13, policy loss 1.8274097442626953\n",
      "\n",
      "episode 14, policy loss 1.8260219097137451\n",
      "\n",
      "episode 15, policy loss 1.8365435600280762\n",
      "\n",
      "episode 16, policy loss 1.7678508758544922\n",
      "\n",
      "Policy train loss in epoch 1:1.7508991807699203\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.6360313892364502\n",
      "\n",
      "episode 2, policy loss 1.827424168586731\n",
      "\n",
      "episode 3, policy loss 1.7972500324249268\n",
      "\n",
      "episode 4, policy loss 1.5096275806427002\n",
      "\n",
      "episode 5, policy loss 1.8260270357131958\n",
      "\n",
      "episode 6, policy loss 1.7044904232025146\n",
      "\n",
      "episode 7, policy loss 1.7063279151916504\n",
      "\n",
      "episode 8, policy loss 1.8142741918563843\n",
      "\n",
      "episode 9, policy loss 1.89162015914917\n",
      "\n",
      "episode 10, policy loss 1.7091479301452637\n",
      "\n",
      "episode 11, policy loss 1.7678179740905762\n",
      "\n",
      "episode 12, policy loss 1.6351666450500488\n",
      "\n",
      "episode 13, policy loss 1.7827677726745605\n",
      "\n",
      "episode 14, policy loss 1.759507417678833\n",
      "\n",
      "episode 15, policy loss 1.811293363571167\n",
      "\n",
      "episode 16, policy loss 1.8365046977996826\n",
      "\n",
      "Policy train loss in epoch 2:1.750954918563366\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.8915863037109375\n",
      "\n",
      "episode 2, policy loss 1.7971587181091309\n",
      "\n",
      "episode 3, policy loss 1.7090809345245361\n",
      "\n",
      "episode 4, policy loss 1.6350911855697632\n",
      "\n",
      "episode 5, policy loss 1.7062112092971802\n",
      "\n",
      "episode 6, policy loss 1.509503722190857\n",
      "\n",
      "episode 7, policy loss 1.70433509349823\n",
      "\n",
      "episode 8, policy loss 1.8364167213439941\n",
      "\n",
      "episode 9, policy loss 1.7593790292739868\n",
      "\n",
      "episode 10, policy loss 1.8272192478179932\n",
      "\n",
      "episode 11, policy loss 1.8140536546707153\n",
      "\n",
      "episode 12, policy loss 1.6357035636901855\n",
      "\n",
      "episode 13, policy loss 1.8257262706756592\n",
      "\n",
      "episode 14, policy loss 1.7823964357376099\n",
      "\n",
      "episode 15, policy loss 1.8108824491500854\n",
      "\n",
      "episode 16, policy loss 1.7672609090805054\n",
      "\n",
      "Policy train loss in epoch 3:1.7507503405213356\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 3.5826616287231445\n",
      "\n",
      "episode 2, val func loss 2.598212242126465\n",
      "\n",
      "episode 3, val func loss 3.253138303756714\n",
      "\n",
      "episode 4, val func loss 3.589573383331299\n",
      "\n",
      "episode 5, val func loss 1.8999196290969849\n",
      "\n",
      "episode 6, val func loss 3.5674524307250977\n",
      "\n",
      "episode 7, val func loss 3.716487169265747\n",
      "\n",
      "episode 8, val func loss 2.903738260269165\n",
      "\n",
      "episode 9, val func loss 2.788510322570801\n",
      "\n",
      "episode 10, val func loss 2.970271348953247\n",
      "\n",
      "episode 11, val func loss 3.5387582778930664\n",
      "\n",
      "episode 12, val func loss 2.9091684818267822\n",
      "\n",
      "episode 13, val func loss 2.6000027656555176\n",
      "\n",
      "episode 14, val func loss 2.156409978866577\n",
      "\n",
      "episode 15, val func loss 2.546269655227661\n",
      "\n",
      "episode 16, val func loss 3.46950364112854\n",
      "\n",
      "Val func train loss in epoch 0:3.0056298449635506\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.89463210105896\n",
      "\n",
      "episode 2, val func loss 3.2701058387756348\n",
      "\n",
      "episode 3, val func loss 3.1623806953430176\n",
      "\n",
      "episode 4, val func loss 3.432966470718384\n",
      "\n",
      "episode 5, val func loss 3.6321678161621094\n",
      "\n",
      "episode 6, val func loss 3.4665188789367676\n",
      "\n",
      "episode 7, val func loss 3.202988624572754\n",
      "\n",
      "episode 8, val func loss 3.1852948665618896\n",
      "\n",
      "episode 9, val func loss 3.033006429672241\n",
      "\n",
      "episode 10, val func loss 3.7121775150299072\n",
      "\n",
      "episode 11, val func loss 1.8887827396392822\n",
      "\n",
      "episode 12, val func loss 2.315340757369995\n",
      "\n",
      "episode 13, val func loss 3.1799468994140625\n",
      "\n",
      "episode 14, val func loss 2.6909561157226562\n",
      "\n",
      "episode 15, val func loss 2.8011064529418945\n",
      "\n",
      "episode 16, val func loss 3.6622023582458496\n",
      "\n",
      "Val func train loss in epoch 1:3.095660910010338\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 3.2517552375793457\n",
      "\n",
      "episode 2, val func loss 3.256302833557129\n",
      "\n",
      "episode 3, val func loss 2.442497730255127\n",
      "\n",
      "episode 4, val func loss 3.084298849105835\n",
      "\n",
      "episode 5, val func loss 2.9774303436279297\n",
      "\n",
      "episode 6, val func loss 3.7539374828338623\n",
      "\n",
      "episode 7, val func loss 2.9631989002227783\n",
      "\n",
      "episode 8, val func loss 2.905228614807129\n",
      "\n",
      "episode 9, val func loss 2.3740921020507812\n",
      "\n",
      "episode 10, val func loss 3.0606470108032227\n",
      "\n",
      "episode 11, val func loss 2.269641637802124\n",
      "\n",
      "episode 12, val func loss 3.35847544670105\n",
      "\n",
      "episode 13, val func loss 2.622549057006836\n",
      "\n",
      "episode 14, val func loss 2.9143762588500977\n",
      "\n",
      "episode 15, val func loss 3.4880573749542236\n",
      "\n",
      "episode 16, val func loss 3.731710195541382\n",
      "\n",
      "Val func train loss in epoch 2:3.0283874422311783\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.611119270324707\n",
      "\n",
      "episode 2, val func loss 2.6931004524230957\n",
      "\n",
      "episode 3, val func loss 2.96720027923584\n",
      "\n",
      "episode 4, val func loss 2.3638107776641846\n",
      "\n",
      "episode 5, val func loss 3.264639139175415\n",
      "\n",
      "episode 6, val func loss 2.7055704593658447\n",
      "\n",
      "episode 7, val func loss 3.0169785022735596\n",
      "\n",
      "episode 8, val func loss 2.354177474975586\n",
      "\n",
      "episode 9, val func loss 2.760580062866211\n",
      "\n",
      "episode 10, val func loss 3.6515188217163086\n",
      "\n",
      "episode 11, val func loss 3.3273701667785645\n",
      "\n",
      "episode 12, val func loss 3.1414570808410645\n",
      "\n",
      "episode 13, val func loss 3.1147823333740234\n",
      "\n",
      "episode 14, val func loss 2.9068949222564697\n",
      "\n",
      "episode 15, val func loss 3.328613758087158\n",
      "\n",
      "episode 16, val func loss 1.993886947631836\n",
      "\n",
      "Val func train loss in epoch 3:2.8876062780618668\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.6619644165039062\n",
      "\n",
      "episode 2, val func loss 3.0070841312408447\n",
      "\n",
      "episode 3, val func loss 1.8056049346923828\n",
      "\n",
      "episode 4, val func loss 2.335289239883423\n",
      "\n",
      "episode 5, val func loss 2.9891059398651123\n",
      "\n",
      "episode 6, val func loss 3.155550718307495\n",
      "\n",
      "episode 7, val func loss 2.9906606674194336\n",
      "\n",
      "episode 8, val func loss 2.798017740249634\n",
      "\n",
      "episode 9, val func loss 3.164928913116455\n",
      "\n",
      "episode 10, val func loss 2.3282582759857178\n",
      "\n",
      "episode 11, val func loss 3.308833360671997\n",
      "\n",
      "episode 12, val func loss 3.3685240745544434\n",
      "\n",
      "episode 13, val func loss 3.1364221572875977\n",
      "\n",
      "episode 14, val func loss 3.668065071105957\n",
      "\n",
      "episode 15, val func loss 3.1922879219055176\n",
      "\n",
      "episode 16, val func loss 3.336636781692505\n",
      "\n",
      "Val func train loss in epoch 4:2.9529521465301514\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 3.756600856781006\n",
      "\n",
      "episode 2, val func loss 3.068661689758301\n",
      "\n",
      "episode 3, val func loss 3.3208651542663574\n",
      "\n",
      "episode 4, val func loss 2.74180006980896\n",
      "\n",
      "episode 5, val func loss 2.1461520195007324\n",
      "\n",
      "episode 6, val func loss 2.8225419521331787\n",
      "\n",
      "episode 7, val func loss 1.9146690368652344\n",
      "\n",
      "episode 8, val func loss 3.2409770488739014\n",
      "\n",
      "episode 9, val func loss 3.646343231201172\n",
      "\n",
      "episode 10, val func loss 3.082477569580078\n",
      "\n",
      "episode 11, val func loss 3.327522039413452\n",
      "\n",
      "episode 12, val func loss 3.4530911445617676\n",
      "\n",
      "episode 13, val func loss 2.3701231479644775\n",
      "\n",
      "episode 14, val func loss 3.4870171546936035\n",
      "\n",
      "episode 15, val func loss 2.9108214378356934\n",
      "\n",
      "episode 16, val func loss 2.875816822052002\n",
      "\n",
      "Val func train loss in epoch 5:3.01034252345562\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 3.1560564041137695\n",
      "\n",
      "episode 2, val func loss 3.3685688972473145\n",
      "\n",
      "episode 3, val func loss 3.228062629699707\n",
      "\n",
      "episode 4, val func loss 3.109731912612915\n",
      "\n",
      "episode 5, val func loss 3.134953022003174\n",
      "\n",
      "episode 6, val func loss 3.5377423763275146\n",
      "\n",
      "episode 7, val func loss 3.3862266540527344\n",
      "\n",
      "episode 8, val func loss 3.290020227432251\n",
      "\n",
      "episode 9, val func loss 3.276323080062866\n",
      "\n",
      "episode 10, val func loss 2.4520719051361084\n",
      "\n",
      "episode 11, val func loss 3.5622689723968506\n",
      "\n",
      "episode 12, val func loss 2.601672887802124\n",
      "\n",
      "episode 13, val func loss 2.4190309047698975\n",
      "\n",
      "episode 14, val func loss 2.9757673740386963\n",
      "\n",
      "episode 15, val func loss 2.6664087772369385\n",
      "\n",
      "episode 16, val func loss 1.7899885177612305\n",
      "\n",
      "Val func train loss in epoch 6:2.9971809089183807\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 3.2220849990844727\n",
      "\n",
      "episode 2, val func loss 2.306995153427124\n",
      "\n",
      "episode 3, val func loss 3.16426157951355\n",
      "\n",
      "episode 4, val func loss 2.8119990825653076\n",
      "\n",
      "episode 5, val func loss 2.77134108543396\n",
      "\n",
      "episode 6, val func loss 2.5440964698791504\n",
      "\n",
      "episode 7, val func loss 3.048506021499634\n",
      "\n",
      "episode 8, val func loss 3.6395161151885986\n",
      "\n",
      "episode 9, val func loss 3.182316780090332\n",
      "\n",
      "episode 10, val func loss 3.304506778717041\n",
      "\n",
      "episode 11, val func loss 3.6503257751464844\n",
      "\n",
      "episode 12, val func loss 2.919853687286377\n",
      "\n",
      "episode 13, val func loss 2.355609655380249\n",
      "\n",
      "episode 14, val func loss 3.4675512313842773\n",
      "\n",
      "episode 15, val func loss 3.020893096923828\n",
      "\n",
      "episode 16, val func loss 2.0210134983062744\n",
      "\n",
      "Val func train loss in epoch 7:2.9644294381141663\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.618032693862915\n",
      "\n",
      "episode 2, val func loss 2.7517998218536377\n",
      "\n",
      "episode 3, val func loss 3.4525017738342285\n",
      "\n",
      "episode 4, val func loss 2.3069307804107666\n",
      "\n",
      "episode 5, val func loss 3.1320841312408447\n",
      "\n",
      "episode 6, val func loss 3.471245288848877\n",
      "\n",
      "episode 7, val func loss 3.59114670753479\n",
      "\n",
      "episode 8, val func loss 3.0892467498779297\n",
      "\n",
      "episode 9, val func loss 1.9176405668258667\n",
      "\n",
      "episode 10, val func loss 2.873016834259033\n",
      "\n",
      "episode 11, val func loss 2.280616521835327\n",
      "\n",
      "episode 12, val func loss 3.331367254257202\n",
      "\n",
      "episode 13, val func loss 3.060347318649292\n",
      "\n",
      "episode 14, val func loss 2.8409557342529297\n",
      "\n",
      "episode 15, val func loss 3.030604600906372\n",
      "\n",
      "episode 16, val func loss 2.9057962894439697\n",
      "\n",
      "Val func train loss in epoch 8:2.915833316743374\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 2.2592933177948\n",
      "\n",
      "episode 2, val func loss 3.3110756874084473\n",
      "\n",
      "episode 3, val func loss 3.739550828933716\n",
      "\n",
      "episode 4, val func loss 3.501539945602417\n",
      "\n",
      "episode 5, val func loss 3.3023860454559326\n",
      "\n",
      "episode 6, val func loss 2.980119466781616\n",
      "\n",
      "episode 7, val func loss 2.7322521209716797\n",
      "\n",
      "episode 8, val func loss 2.730048179626465\n",
      "\n",
      "episode 9, val func loss 2.8321585655212402\n",
      "\n",
      "episode 10, val func loss 3.411813259124756\n",
      "\n",
      "episode 11, val func loss 3.1466522216796875\n",
      "\n",
      "episode 12, val func loss 3.093675374984741\n",
      "\n",
      "episode 13, val func loss 3.034461736679077\n",
      "\n",
      "episode 14, val func loss 2.6874940395355225\n",
      "\n",
      "episode 15, val func loss 2.245072841644287\n",
      "\n",
      "episode 16, val func loss 2.8596646785736084\n",
      "\n",
      "Val func train loss in epoch 9:2.9917036443948746\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.8911120891571045\n",
      "\n",
      "episode 2, val func loss 3.2570018768310547\n",
      "\n",
      "episode 3, val func loss 3.814521551132202\n",
      "\n",
      "episode 4, val func loss 3.04034686088562\n",
      "\n",
      "episode 5, val func loss 2.87992000579834\n",
      "\n",
      "episode 6, val func loss 3.3017008304595947\n",
      "\n",
      "episode 7, val func loss 2.735250234603882\n",
      "\n",
      "episode 8, val func loss 3.250108242034912\n",
      "\n",
      "episode 9, val func loss 2.329535722732544\n",
      "\n",
      "episode 10, val func loss 2.7326440811157227\n",
      "\n",
      "episode 11, val func loss 1.8954946994781494\n",
      "\n",
      "episode 12, val func loss 2.316373825073242\n",
      "\n",
      "episode 13, val func loss 3.741215944290161\n",
      "\n",
      "episode 14, val func loss 3.352567672729492\n",
      "\n",
      "episode 15, val func loss 3.1890830993652344\n",
      "\n",
      "episode 16, val func loss 3.7013511657714844\n",
      "\n",
      "Val func train loss in epoch 10:3.0267642438411713\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 3.6260430812835693\n",
      "\n",
      "episode 2, val func loss 2.129802942276001\n",
      "\n",
      "episode 3, val func loss 2.960216522216797\n",
      "\n",
      "episode 4, val func loss 3.410346031188965\n",
      "\n",
      "episode 5, val func loss 3.4045159816741943\n",
      "\n",
      "episode 6, val func loss 3.0795233249664307\n",
      "\n",
      "episode 7, val func loss 3.68111515045166\n",
      "\n",
      "episode 8, val func loss 3.4149436950683594\n",
      "\n",
      "episode 9, val func loss 3.3043293952941895\n",
      "\n",
      "episode 10, val func loss 3.2216668128967285\n",
      "\n",
      "episode 11, val func loss 3.2679576873779297\n",
      "\n",
      "episode 12, val func loss 2.5543222427368164\n",
      "\n",
      "episode 13, val func loss 2.8023722171783447\n",
      "\n",
      "episode 14, val func loss 3.6402502059936523\n",
      "\n",
      "episode 15, val func loss 2.7512524127960205\n",
      "\n",
      "episode 16, val func loss 2.2474212646484375\n",
      "\n",
      "Val func train loss in epoch 11:3.093504935503006\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 3.3808462619781494\n",
      "\n",
      "episode 2, val func loss 3.1482372283935547\n",
      "\n",
      "episode 3, val func loss 3.6943249702453613\n",
      "\n",
      "episode 4, val func loss 3.1603188514709473\n",
      "\n",
      "episode 5, val func loss 2.7269651889801025\n",
      "\n",
      "episode 6, val func loss 2.761690616607666\n",
      "\n",
      "episode 7, val func loss 1.8774198293685913\n",
      "\n",
      "episode 8, val func loss 3.4904680252075195\n",
      "\n",
      "episode 9, val func loss 3.405867338180542\n",
      "\n",
      "episode 10, val func loss 3.1732521057128906\n",
      "\n",
      "episode 11, val func loss 3.2334651947021484\n",
      "\n",
      "episode 12, val func loss 3.1141672134399414\n",
      "\n",
      "episode 13, val func loss 2.3673653602600098\n",
      "\n",
      "episode 14, val func loss 2.221532106399536\n",
      "\n",
      "episode 15, val func loss 3.4697821140289307\n",
      "\n",
      "episode 16, val func loss 2.6604764461517334\n",
      "\n",
      "Val func train loss in epoch 12:2.9928861781954765\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 3.5384740829467773\n",
      "\n",
      "episode 2, val func loss 3.7421557903289795\n",
      "\n",
      "episode 3, val func loss 3.314185857772827\n",
      "\n",
      "episode 4, val func loss 2.823362350463867\n",
      "\n",
      "episode 5, val func loss 3.351820707321167\n",
      "\n",
      "episode 6, val func loss 2.8834919929504395\n",
      "\n",
      "episode 7, val func loss 3.200551748275757\n",
      "\n",
      "episode 8, val func loss 3.1440343856811523\n",
      "\n",
      "episode 9, val func loss 3.1629884243011475\n",
      "\n",
      "episode 10, val func loss 2.796818256378174\n",
      "\n",
      "episode 11, val func loss 3.287994146347046\n",
      "\n",
      "episode 12, val func loss 1.8340685367584229\n",
      "\n",
      "episode 13, val func loss 2.780251979827881\n",
      "\n",
      "episode 14, val func loss 2.3876051902770996\n",
      "\n",
      "episode 15, val func loss 2.5804643630981445\n",
      "\n",
      "episode 16, val func loss 2.2698185443878174\n",
      "\n",
      "Val func train loss in epoch 13:2.9436303973197937\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.172832727432251\n",
      "\n",
      "episode 2, val func loss 2.3460381031036377\n",
      "\n",
      "episode 3, val func loss 3.511733293533325\n",
      "\n",
      "episode 4, val func loss 3.415153980255127\n",
      "\n",
      "episode 5, val func loss 2.524418354034424\n",
      "\n",
      "episode 6, val func loss 3.1608433723449707\n",
      "\n",
      "episode 7, val func loss 2.687920570373535\n",
      "\n",
      "episode 8, val func loss 3.0971169471740723\n",
      "\n",
      "episode 9, val func loss 3.1509361267089844\n",
      "\n",
      "episode 10, val func loss 2.73464298248291\n",
      "\n",
      "episode 11, val func loss 3.2827484607696533\n",
      "\n",
      "episode 12, val func loss 2.3564324378967285\n",
      "\n",
      "episode 13, val func loss 2.7766642570495605\n",
      "\n",
      "episode 14, val func loss 3.5661461353302\n",
      "\n",
      "episode 15, val func loss 3.258502244949341\n",
      "\n",
      "episode 16, val func loss 3.6002566814422607\n",
      "\n",
      "Val func train loss in epoch 14:2.9776491671800613\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 3.236679792404175\n",
      "\n",
      "episode 2, val func loss 3.729830503463745\n",
      "\n",
      "episode 3, val func loss 2.68890643119812\n",
      "\n",
      "episode 4, val func loss 1.9908288717269897\n",
      "\n",
      "episode 5, val func loss 2.84201979637146\n",
      "\n",
      "episode 6, val func loss 3.7113680839538574\n",
      "\n",
      "episode 7, val func loss 3.1235013008117676\n",
      "\n",
      "episode 8, val func loss 3.371013641357422\n",
      "\n",
      "episode 9, val func loss 3.2678349018096924\n",
      "\n",
      "episode 10, val func loss 2.5473577976226807\n",
      "\n",
      "episode 11, val func loss 2.8575708866119385\n",
      "\n",
      "episode 12, val func loss 3.2594223022460938\n",
      "\n",
      "episode 13, val func loss 2.175999641418457\n",
      "\n",
      "episode 14, val func loss 2.7950613498687744\n",
      "\n",
      "episode 15, val func loss 3.187391996383667\n",
      "\n",
      "episode 16, val func loss 2.9262795448303223\n",
      "\n",
      "Val func train loss in epoch 15:2.9819416776299477\n",
      "***********************TIME WAS 4.9162954966227215 min*****************************\n",
      "\n",
      "**********************ROUND 120 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.5434719920158386\n",
      "\n",
      "episode 2, policy loss 0.5433962345123291\n",
      "\n",
      "episode 3, policy loss 0.5433204770088196\n",
      "\n",
      "episode 4, policy loss 0.5432326197624207\n",
      "\n",
      "episode 5, policy loss 0.5430122017860413\n",
      "\n",
      "episode 6, policy loss 0.5426726341247559\n",
      "\n",
      "episode 7, policy loss 0.5420917868614197\n",
      "\n",
      "episode 8, policy loss 0.5409290194511414\n",
      "\n",
      "episode 9, policy loss 0.5400600433349609\n",
      "\n",
      "episode 10, policy loss 0.5363495945930481\n",
      "\n",
      "episode 11, policy loss 0.5289347767829895\n",
      "\n",
      "episode 12, policy loss 0.5127757787704468\n",
      "\n",
      "episode 13, policy loss 0.5174449682235718\n",
      "\n",
      "episode 14, policy loss 0.5038496255874634\n",
      "\n",
      "episode 15, policy loss 0.5053830742835999\n",
      "\n",
      "episode 16, policy loss 0.5124098062515259\n",
      "\n",
      "Policy train loss in epoch 0:0.5312084145843983\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.505643367767334\n",
      "\n",
      "episode 2, policy loss 0.49921920895576477\n",
      "\n",
      "episode 3, policy loss 0.5124068856239319\n",
      "\n",
      "episode 4, policy loss 0.5017285346984863\n",
      "\n",
      "episode 5, policy loss 0.5008105635643005\n",
      "\n",
      "episode 6, policy loss 0.5055168271064758\n",
      "\n",
      "episode 7, policy loss 0.5014556050300598\n",
      "\n",
      "episode 8, policy loss 0.49617093801498413\n",
      "\n",
      "episode 9, policy loss 0.5029923915863037\n",
      "\n",
      "episode 10, policy loss 0.4998234510421753\n",
      "\n",
      "episode 11, policy loss 0.5025796294212341\n",
      "\n",
      "episode 12, policy loss 0.500835120677948\n",
      "\n",
      "episode 13, policy loss 0.49981775879859924\n",
      "\n",
      "episode 14, policy loss 0.5003483295440674\n",
      "\n",
      "episode 15, policy loss 0.5035054683685303\n",
      "\n",
      "episode 16, policy loss 0.49809256196022034\n",
      "\n",
      "Policy train loss in epoch 1:0.501934165135026\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.5020195245742798\n",
      "\n",
      "episode 2, policy loss 0.49909457564353943\n",
      "\n",
      "episode 3, policy loss 0.4987732470035553\n",
      "\n",
      "episode 4, policy loss 0.49689361453056335\n",
      "\n",
      "episode 5, policy loss 0.494687557220459\n",
      "\n",
      "episode 6, policy loss 0.49886980652809143\n",
      "\n",
      "episode 7, policy loss 0.49951523542404175\n",
      "\n",
      "episode 8, policy loss 0.49941185116767883\n",
      "\n",
      "episode 9, policy loss 0.49696558713912964\n",
      "\n",
      "episode 10, policy loss 0.5001882910728455\n",
      "\n",
      "episode 11, policy loss 0.5000414252281189\n",
      "\n",
      "episode 12, policy loss 0.49838751554489136\n",
      "\n",
      "episode 13, policy loss 0.4999973475933075\n",
      "\n",
      "episode 14, policy loss 0.4998471736907959\n",
      "\n",
      "episode 15, policy loss 0.5015378594398499\n",
      "\n",
      "episode 16, policy loss 0.4998651444911957\n",
      "\n",
      "Policy train loss in epoch 2:0.49913098476827145\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.5011044144630432\n",
      "\n",
      "episode 2, policy loss 0.500511646270752\n",
      "\n",
      "episode 3, policy loss 0.5019603967666626\n",
      "\n",
      "episode 4, policy loss 0.49887216091156006\n",
      "\n",
      "episode 5, policy loss 0.49762314558029175\n",
      "\n",
      "episode 6, policy loss 0.5042261481285095\n",
      "\n",
      "episode 7, policy loss 0.4999036192893982\n",
      "\n",
      "episode 8, policy loss 0.49615582823753357\n",
      "\n",
      "episode 9, policy loss 0.5005126595497131\n",
      "\n",
      "episode 10, policy loss 0.49759310483932495\n",
      "\n",
      "episode 11, policy loss 0.49710962176322937\n",
      "\n",
      "episode 12, policy loss 0.4971727728843689\n",
      "\n",
      "episode 13, policy loss 0.4971903860569\n",
      "\n",
      "episode 14, policy loss 0.4985375702381134\n",
      "\n",
      "episode 15, policy loss 0.4993807375431061\n",
      "\n",
      "episode 16, policy loss 0.49880340695381165\n",
      "\n",
      "Policy train loss in epoch 3:0.4991661012172699\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.3732001781463623\n",
      "\n",
      "episode 2, val func loss 0.8834823966026306\n",
      "\n",
      "episode 3, val func loss 0.6265290379524231\n",
      "\n",
      "episode 4, val func loss 0.9046980142593384\n",
      "\n",
      "episode 5, val func loss 1.00323486328125\n",
      "\n",
      "episode 6, val func loss 0.8531506061553955\n",
      "\n",
      "episode 7, val func loss 0.677538275718689\n",
      "\n",
      "episode 8, val func loss 0.7298461198806763\n",
      "\n",
      "episode 9, val func loss 0.9064434170722961\n",
      "\n",
      "episode 10, val func loss 0.809478759765625\n",
      "\n",
      "episode 11, val func loss 0.6607455015182495\n",
      "\n",
      "episode 12, val func loss 0.6699763536453247\n",
      "\n",
      "episode 13, val func loss 0.865373969078064\n",
      "\n",
      "episode 14, val func loss 0.7243601083755493\n",
      "\n",
      "episode 15, val func loss 0.8063018918037415\n",
      "\n",
      "episode 16, val func loss 0.7266286611557007\n",
      "\n",
      "Val func train loss in epoch 0:0.8263117596507072\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.6664600372314453\n",
      "\n",
      "episode 2, val func loss 0.7133620977401733\n",
      "\n",
      "episode 3, val func loss 0.7035854458808899\n",
      "\n",
      "episode 4, val func loss 0.7757551670074463\n",
      "\n",
      "episode 5, val func loss 0.70524662733078\n",
      "\n",
      "episode 6, val func loss 0.6808164715766907\n",
      "\n",
      "episode 7, val func loss 0.6170430183410645\n",
      "\n",
      "episode 8, val func loss 0.6996312737464905\n",
      "\n",
      "episode 9, val func loss 0.7273438572883606\n",
      "\n",
      "episode 10, val func loss 0.6456201672554016\n",
      "\n",
      "episode 11, val func loss 0.6326272487640381\n",
      "\n",
      "episode 12, val func loss 0.5903467535972595\n",
      "\n",
      "episode 13, val func loss 0.7158974409103394\n",
      "\n",
      "episode 14, val func loss 0.6816273331642151\n",
      "\n",
      "episode 15, val func loss 0.7102870345115662\n",
      "\n",
      "episode 16, val func loss 0.6060017943382263\n",
      "\n",
      "Val func train loss in epoch 1:0.6794782355427742\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6899293661117554\n",
      "\n",
      "episode 2, val func loss 0.7605575323104858\n",
      "\n",
      "episode 3, val func loss 0.6979066729545593\n",
      "\n",
      "episode 4, val func loss 0.6117673516273499\n",
      "\n",
      "episode 5, val func loss 0.6237062215805054\n",
      "\n",
      "episode 6, val func loss 0.6290674805641174\n",
      "\n",
      "episode 7, val func loss 0.6663731932640076\n",
      "\n",
      "episode 8, val func loss 0.6161388754844666\n",
      "\n",
      "episode 9, val func loss 0.6600345969200134\n",
      "\n",
      "episode 10, val func loss 0.6882168650627136\n",
      "\n",
      "episode 11, val func loss 0.6690311431884766\n",
      "\n",
      "episode 12, val func loss 0.6556700468063354\n",
      "\n",
      "episode 13, val func loss 0.6850017309188843\n",
      "\n",
      "episode 14, val func loss 0.6170800924301147\n",
      "\n",
      "episode 15, val func loss 0.5817012190818787\n",
      "\n",
      "episode 16, val func loss 0.7113075256347656\n",
      "\n",
      "Val func train loss in epoch 2:0.6602181196212769\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6079751253128052\n",
      "\n",
      "episode 2, val func loss 0.7013363242149353\n",
      "\n",
      "episode 3, val func loss 0.6426503658294678\n",
      "\n",
      "episode 4, val func loss 0.6835761666297913\n",
      "\n",
      "episode 5, val func loss 0.6633934378623962\n",
      "\n",
      "episode 6, val func loss 0.6402029395103455\n",
      "\n",
      "episode 7, val func loss 0.6416078805923462\n",
      "\n",
      "episode 8, val func loss 0.6415624618530273\n",
      "\n",
      "episode 9, val func loss 0.6046043038368225\n",
      "\n",
      "episode 10, val func loss 0.6425353288650513\n",
      "\n",
      "episode 11, val func loss 0.6053064465522766\n",
      "\n",
      "episode 12, val func loss 0.6450870633125305\n",
      "\n",
      "episode 13, val func loss 0.5800334215164185\n",
      "\n",
      "episode 14, val func loss 0.5669741034507751\n",
      "\n",
      "episode 15, val func loss 0.5638272762298584\n",
      "\n",
      "episode 16, val func loss 0.6293966770172119\n",
      "\n",
      "Val func train loss in epoch 3:0.6287543326616287\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6435146331787109\n",
      "\n",
      "episode 2, val func loss 0.67494797706604\n",
      "\n",
      "episode 3, val func loss 0.6420102715492249\n",
      "\n",
      "episode 4, val func loss 0.6201958060264587\n",
      "\n",
      "episode 5, val func loss 0.6614330410957336\n",
      "\n",
      "episode 6, val func loss 0.57951819896698\n",
      "\n",
      "episode 7, val func loss 0.6327515840530396\n",
      "\n",
      "episode 8, val func loss 0.5782615542411804\n",
      "\n",
      "episode 9, val func loss 0.689495861530304\n",
      "\n",
      "episode 10, val func loss 0.6597445011138916\n",
      "\n",
      "episode 11, val func loss 0.7004724144935608\n",
      "\n",
      "episode 12, val func loss 0.7045263051986694\n",
      "\n",
      "episode 13, val func loss 0.6002799272537231\n",
      "\n",
      "episode 14, val func loss 0.6893642544746399\n",
      "\n",
      "episode 15, val func loss 0.5315167307853699\n",
      "\n",
      "episode 16, val func loss 0.6912618279457092\n",
      "\n",
      "Val func train loss in epoch 4:0.6437059305608273\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6316145062446594\n",
      "\n",
      "episode 2, val func loss 0.6297216415405273\n",
      "\n",
      "episode 3, val func loss 0.64713054895401\n",
      "\n",
      "episode 4, val func loss 0.6511956453323364\n",
      "\n",
      "episode 5, val func loss 0.7150933742523193\n",
      "\n",
      "episode 6, val func loss 0.5886046886444092\n",
      "\n",
      "episode 7, val func loss 0.6880002617835999\n",
      "\n",
      "episode 8, val func loss 0.6688796877861023\n",
      "\n",
      "episode 9, val func loss 0.7253246307373047\n",
      "\n",
      "episode 10, val func loss 0.6650116443634033\n",
      "\n",
      "episode 11, val func loss 0.6167742609977722\n",
      "\n",
      "episode 12, val func loss 0.6432717442512512\n",
      "\n",
      "episode 13, val func loss 0.6289610862731934\n",
      "\n",
      "episode 14, val func loss 0.71653151512146\n",
      "\n",
      "episode 15, val func loss 0.6893049478530884\n",
      "\n",
      "episode 16, val func loss 0.6456733345985413\n",
      "\n",
      "Val func train loss in epoch 5:0.6594433449208736\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7136359810829163\n",
      "\n",
      "episode 2, val func loss 0.6326901912689209\n",
      "\n",
      "episode 3, val func loss 0.506197452545166\n",
      "\n",
      "episode 4, val func loss 0.5997035503387451\n",
      "\n",
      "episode 5, val func loss 0.6839024424552917\n",
      "\n",
      "episode 6, val func loss 0.6516648530960083\n",
      "\n",
      "episode 7, val func loss 0.6865242123603821\n",
      "\n",
      "episode 8, val func loss 0.6432405710220337\n",
      "\n",
      "episode 9, val func loss 0.5674166083335876\n",
      "\n",
      "episode 10, val func loss 0.7105555534362793\n",
      "\n",
      "episode 11, val func loss 0.6572167277336121\n",
      "\n",
      "episode 12, val func loss 0.6227476596832275\n",
      "\n",
      "episode 13, val func loss 0.7223032116889954\n",
      "\n",
      "episode 14, val func loss 0.5316292643547058\n",
      "\n",
      "episode 15, val func loss 0.6289016008377075\n",
      "\n",
      "episode 16, val func loss 0.6933929920196533\n",
      "\n",
      "Val func train loss in epoch 6:0.640732679516077\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6361420154571533\n",
      "\n",
      "episode 2, val func loss 0.6820061802864075\n",
      "\n",
      "episode 3, val func loss 0.6595200300216675\n",
      "\n",
      "episode 4, val func loss 0.6068340539932251\n",
      "\n",
      "episode 5, val func loss 0.7438507080078125\n",
      "\n",
      "episode 6, val func loss 0.6759946942329407\n",
      "\n",
      "episode 7, val func loss 0.6224290728569031\n",
      "\n",
      "episode 8, val func loss 0.7120738625526428\n",
      "\n",
      "episode 9, val func loss 0.5840597748756409\n",
      "\n",
      "episode 10, val func loss 0.6624454855918884\n",
      "\n",
      "episode 11, val func loss 0.6429406404495239\n",
      "\n",
      "episode 12, val func loss 0.5980299115180969\n",
      "\n",
      "episode 13, val func loss 0.5689999461174011\n",
      "\n",
      "episode 14, val func loss 0.671076238155365\n",
      "\n",
      "episode 15, val func loss 0.5823163390159607\n",
      "\n",
      "episode 16, val func loss 0.6534716486930847\n",
      "\n",
      "Val func train loss in epoch 7:0.6438869126141071\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.59223473072052\n",
      "\n",
      "episode 2, val func loss 0.6073980927467346\n",
      "\n",
      "episode 3, val func loss 0.6537179946899414\n",
      "\n",
      "episode 4, val func loss 0.675665020942688\n",
      "\n",
      "episode 5, val func loss 0.5463771820068359\n",
      "\n",
      "episode 6, val func loss 0.6897245049476624\n",
      "\n",
      "episode 7, val func loss 0.6362601518630981\n",
      "\n",
      "episode 8, val func loss 0.6629118919372559\n",
      "\n",
      "episode 9, val func loss 0.648571252822876\n",
      "\n",
      "episode 10, val func loss 0.620174765586853\n",
      "\n",
      "episode 11, val func loss 0.6221158504486084\n",
      "\n",
      "episode 12, val func loss 0.5797942876815796\n",
      "\n",
      "episode 13, val func loss 0.7145814895629883\n",
      "\n",
      "episode 14, val func loss 0.6666616201400757\n",
      "\n",
      "episode 15, val func loss 0.6982211470603943\n",
      "\n",
      "episode 16, val func loss 0.6135403513908386\n",
      "\n",
      "Val func train loss in epoch 8:0.6392468959093094\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6291213631629944\n",
      "\n",
      "episode 2, val func loss 0.6080256700515747\n",
      "\n",
      "episode 3, val func loss 0.7058752179145813\n",
      "\n",
      "episode 4, val func loss 0.6815807223320007\n",
      "\n",
      "episode 5, val func loss 0.7958784103393555\n",
      "\n",
      "episode 6, val func loss 0.6282935738563538\n",
      "\n",
      "episode 7, val func loss 0.6399881839752197\n",
      "\n",
      "episode 8, val func loss 0.6846070885658264\n",
      "\n",
      "episode 9, val func loss 0.6208375096321106\n",
      "\n",
      "episode 10, val func loss 0.689052164554596\n",
      "\n",
      "episode 11, val func loss 0.5892392992973328\n",
      "\n",
      "episode 12, val func loss 0.86423259973526\n",
      "\n",
      "episode 13, val func loss 0.6409744024276733\n",
      "\n",
      "episode 14, val func loss 0.6790125370025635\n",
      "\n",
      "episode 15, val func loss 0.7130434513092041\n",
      "\n",
      "episode 16, val func loss 0.6546714901924133\n",
      "\n",
      "Val func train loss in epoch 9:0.6765271052718163\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6661192774772644\n",
      "\n",
      "episode 2, val func loss 0.5478025078773499\n",
      "\n",
      "episode 3, val func loss 0.5565444827079773\n",
      "\n",
      "episode 4, val func loss 0.6413164138793945\n",
      "\n",
      "episode 5, val func loss 0.5866451263427734\n",
      "\n",
      "episode 6, val func loss 0.6396692395210266\n",
      "\n",
      "episode 7, val func loss 0.7321842908859253\n",
      "\n",
      "episode 8, val func loss 0.6260764002799988\n",
      "\n",
      "episode 9, val func loss 0.6391915082931519\n",
      "\n",
      "episode 10, val func loss 0.6675949096679688\n",
      "\n",
      "episode 11, val func loss 0.524660050868988\n",
      "\n",
      "episode 12, val func loss 0.7291280627250671\n",
      "\n",
      "episode 13, val func loss 0.6250225901603699\n",
      "\n",
      "episode 14, val func loss 0.5914142727851868\n",
      "\n",
      "episode 15, val func loss 0.6704338192939758\n",
      "\n",
      "episode 16, val func loss 0.5760896801948547\n",
      "\n",
      "Val func train loss in epoch 10:0.6262432895600796\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6546786427497864\n",
      "\n",
      "episode 2, val func loss 0.66220623254776\n",
      "\n",
      "episode 3, val func loss 0.7040612697601318\n",
      "\n",
      "episode 4, val func loss 0.6562365889549255\n",
      "\n",
      "episode 5, val func loss 0.5604747533798218\n",
      "\n",
      "episode 6, val func loss 0.6134321689605713\n",
      "\n",
      "episode 7, val func loss 0.6748446226119995\n",
      "\n",
      "episode 8, val func loss 0.6655074954032898\n",
      "\n",
      "episode 9, val func loss 0.6218130588531494\n",
      "\n",
      "episode 10, val func loss 0.6751962900161743\n",
      "\n",
      "episode 11, val func loss 0.6433279514312744\n",
      "\n",
      "episode 12, val func loss 0.734294593334198\n",
      "\n",
      "episode 13, val func loss 0.5900754928588867\n",
      "\n",
      "episode 14, val func loss 0.5931657552719116\n",
      "\n",
      "episode 15, val func loss 0.612472653388977\n",
      "\n",
      "episode 16, val func loss 0.5305176973342896\n",
      "\n",
      "Val func train loss in epoch 11:0.6370190791785717\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.5992700457572937\n",
      "\n",
      "episode 2, val func loss 0.5877642035484314\n",
      "\n",
      "episode 3, val func loss 0.6381340026855469\n",
      "\n",
      "episode 4, val func loss 0.6137959361076355\n",
      "\n",
      "episode 5, val func loss 0.6087177991867065\n",
      "\n",
      "episode 6, val func loss 0.6182560324668884\n",
      "\n",
      "episode 7, val func loss 0.5572847127914429\n",
      "\n",
      "episode 8, val func loss 0.6729192733764648\n",
      "\n",
      "episode 9, val func loss 0.688240647315979\n",
      "\n",
      "episode 10, val func loss 0.6654272079467773\n",
      "\n",
      "episode 11, val func loss 0.6887026429176331\n",
      "\n",
      "episode 12, val func loss 0.7260420322418213\n",
      "\n",
      "episode 13, val func loss 0.62074214220047\n",
      "\n",
      "episode 14, val func loss 0.7221041917800903\n",
      "\n",
      "episode 15, val func loss 0.6808323264122009\n",
      "\n",
      "episode 16, val func loss 0.7251853942871094\n",
      "\n",
      "Val func train loss in epoch 12:0.6508386619389057\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.7028727531433105\n",
      "\n",
      "episode 2, val func loss 0.6692225337028503\n",
      "\n",
      "episode 3, val func loss 0.7374926805496216\n",
      "\n",
      "episode 4, val func loss 0.6333771347999573\n",
      "\n",
      "episode 5, val func loss 0.6537125706672668\n",
      "\n",
      "episode 6, val func loss 0.6291598677635193\n",
      "\n",
      "episode 7, val func loss 0.7419889569282532\n",
      "\n",
      "episode 8, val func loss 0.6373664140701294\n",
      "\n",
      "episode 9, val func loss 0.6278345584869385\n",
      "\n",
      "episode 10, val func loss 0.5891006588935852\n",
      "\n",
      "episode 11, val func loss 0.6798073649406433\n",
      "\n",
      "episode 12, val func loss 0.6677771806716919\n",
      "\n",
      "episode 13, val func loss 0.6529640555381775\n",
      "\n",
      "episode 14, val func loss 0.656127393245697\n",
      "\n",
      "episode 15, val func loss 0.5938644409179688\n",
      "\n",
      "episode 16, val func loss 0.7207465171813965\n",
      "\n",
      "Val func train loss in epoch 13:0.6620884425938129\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6924441456794739\n",
      "\n",
      "episode 2, val func loss 0.5936221480369568\n",
      "\n",
      "episode 3, val func loss 0.6747230887413025\n",
      "\n",
      "episode 4, val func loss 0.7129844427108765\n",
      "\n",
      "episode 5, val func loss 0.5822501182556152\n",
      "\n",
      "episode 6, val func loss 0.6815617084503174\n",
      "\n",
      "episode 7, val func loss 0.6088656783103943\n",
      "\n",
      "episode 8, val func loss 0.6262487173080444\n",
      "\n",
      "episode 9, val func loss 0.617167055606842\n",
      "\n",
      "episode 10, val func loss 0.6233193278312683\n",
      "\n",
      "episode 11, val func loss 0.644632875919342\n",
      "\n",
      "episode 12, val func loss 0.6746760606765747\n",
      "\n",
      "episode 13, val func loss 0.614252507686615\n",
      "\n",
      "episode 14, val func loss 0.5782482624053955\n",
      "\n",
      "episode 15, val func loss 0.659643292427063\n",
      "\n",
      "episode 16, val func loss 0.6461628079414368\n",
      "\n",
      "Val func train loss in epoch 14:0.6394251398742199\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.619859516620636\n",
      "\n",
      "episode 2, val func loss 0.6278150677680969\n",
      "\n",
      "episode 3, val func loss 0.6373628377914429\n",
      "\n",
      "episode 4, val func loss 0.6494454145431519\n",
      "\n",
      "episode 5, val func loss 0.74058997631073\n",
      "\n",
      "episode 6, val func loss 0.6802536249160767\n",
      "\n",
      "episode 7, val func loss 0.7136236429214478\n",
      "\n",
      "episode 8, val func loss 0.6093589067459106\n",
      "\n",
      "episode 9, val func loss 0.5978101491928101\n",
      "\n",
      "episode 10, val func loss 0.7606980800628662\n",
      "\n",
      "episode 11, val func loss 0.550573468208313\n",
      "\n",
      "episode 12, val func loss 0.6226841807365417\n",
      "\n",
      "episode 13, val func loss 0.5613544583320618\n",
      "\n",
      "episode 14, val func loss 0.6434699296951294\n",
      "\n",
      "episode 15, val func loss 0.6953462958335876\n",
      "\n",
      "episode 16, val func loss 0.5971866846084595\n",
      "\n",
      "Val func train loss in epoch 15:0.6442145146429539\n",
      "***********************TIME WAS 4.913443211714426 min*****************************\n",
      "\n",
      "**********************ROUND 121 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.0048569440841675\n",
      "\n",
      "episode 2, policy loss 1.219023585319519\n",
      "\n",
      "episode 3, policy loss 1.4071067571640015\n",
      "\n",
      "episode 4, policy loss 0.9908823370933533\n",
      "\n",
      "episode 5, policy loss 0.7946219444274902\n",
      "\n",
      "episode 6, policy loss 0.9924906492233276\n",
      "\n",
      "episode 7, policy loss 0.6784950494766235\n",
      "\n",
      "episode 8, policy loss 0.9676364064216614\n",
      "\n",
      "episode 9, policy loss 1.2425795793533325\n",
      "\n",
      "episode 10, policy loss 1.0213154554367065\n",
      "\n",
      "episode 11, policy loss 1.6341954469680786\n",
      "\n",
      "episode 12, policy loss 1.3477013111114502\n",
      "\n",
      "episode 13, policy loss 1.069296956062317\n",
      "\n",
      "episode 14, policy loss 1.3669739961624146\n",
      "\n",
      "episode 15, policy loss 0.8408052921295166\n",
      "\n",
      "episode 16, policy loss 0.7973083853721619\n",
      "\n",
      "Policy train loss in epoch 0:1.0859556309878826\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.7998783588409424\n",
      "\n",
      "episode 2, policy loss 0.8560548424720764\n",
      "\n",
      "episode 3, policy loss 1.6527678966522217\n",
      "\n",
      "episode 4, policy loss 0.801258385181427\n",
      "\n",
      "episode 5, policy loss 1.2655142545700073\n",
      "\n",
      "episode 6, policy loss 0.9780590534210205\n",
      "\n",
      "episode 7, policy loss 1.005459189414978\n",
      "\n",
      "episode 8, policy loss 1.3743019104003906\n",
      "\n",
      "episode 9, policy loss 0.6853474974632263\n",
      "\n",
      "episode 10, policy loss 1.3600726127624512\n",
      "\n",
      "episode 11, policy loss 1.100372552871704\n",
      "\n",
      "episode 12, policy loss 1.0332051515579224\n",
      "\n",
      "episode 13, policy loss 1.4404927492141724\n",
      "\n",
      "episode 14, policy loss 1.2584283351898193\n",
      "\n",
      "episode 15, policy loss 1.0045225620269775\n",
      "\n",
      "episode 16, policy loss 1.0602384805679321\n",
      "\n",
      "Policy train loss in epoch 1:1.1047483645379543\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.2586209774017334\n",
      "\n",
      "episode 2, policy loss 0.8067193031311035\n",
      "\n",
      "episode 3, policy loss 0.8615964651107788\n",
      "\n",
      "episode 4, policy loss 1.0602493286132812\n",
      "\n",
      "episode 5, policy loss 1.2678322792053223\n",
      "\n",
      "episode 6, policy loss 1.0067241191864014\n",
      "\n",
      "episode 7, policy loss 1.3753130435943604\n",
      "\n",
      "episode 8, policy loss 1.0334230661392212\n",
      "\n",
      "episode 9, policy loss 0.685774028301239\n",
      "\n",
      "episode 10, policy loss 1.6598728895187378\n",
      "\n",
      "episode 11, policy loss 1.4407310485839844\n",
      "\n",
      "episode 12, policy loss 1.10067880153656\n",
      "\n",
      "episode 13, policy loss 0.8034680485725403\n",
      "\n",
      "episode 14, policy loss 1.3603472709655762\n",
      "\n",
      "episode 15, policy loss 0.9795346856117249\n",
      "\n",
      "episode 16, policy loss 1.0043824911117554\n",
      "\n",
      "Policy train loss in epoch 2:1.10657924041152\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.1004440784454346\n",
      "\n",
      "episode 2, policy loss 1.4403254985809326\n",
      "\n",
      "episode 3, policy loss 1.2581239938735962\n",
      "\n",
      "episode 4, policy loss 0.8031484484672546\n",
      "\n",
      "episode 5, policy loss 0.9790942668914795\n",
      "\n",
      "episode 6, policy loss 1.0037965774536133\n",
      "\n",
      "episode 7, policy loss 1.005911946296692\n",
      "\n",
      "episode 8, policy loss 0.8059325814247131\n",
      "\n",
      "episode 9, policy loss 0.8605927228927612\n",
      "\n",
      "episode 10, policy loss 1.3588579893112183\n",
      "\n",
      "episode 11, policy loss 1.0584605932235718\n",
      "\n",
      "episode 12, policy loss 1.6567695140838623\n",
      "\n",
      "episode 13, policy loss 1.2647063732147217\n",
      "\n",
      "episode 14, policy loss 1.0305548906326294\n",
      "\n",
      "episode 15, policy loss 1.3701488971710205\n",
      "\n",
      "episode 16, policy loss 0.682068407535553\n",
      "\n",
      "Policy train loss in epoch 3:1.1049335487186909\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.8160619735717773\n",
      "\n",
      "episode 2, val func loss 2.440945863723755\n",
      "\n",
      "episode 3, val func loss 2.100463390350342\n",
      "\n",
      "episode 4, val func loss 2.503915548324585\n",
      "\n",
      "episode 5, val func loss 2.2331204414367676\n",
      "\n",
      "episode 6, val func loss 1.8235963582992554\n",
      "\n",
      "episode 7, val func loss 2.593406915664673\n",
      "\n",
      "episode 8, val func loss 1.8940794467926025\n",
      "\n",
      "episode 9, val func loss 1.6146565675735474\n",
      "\n",
      "episode 10, val func loss 2.223435878753662\n",
      "\n",
      "episode 11, val func loss 2.151623249053955\n",
      "\n",
      "episode 12, val func loss 2.6962764263153076\n",
      "\n",
      "episode 13, val func loss 2.103032112121582\n",
      "\n",
      "episode 14, val func loss 2.367494583129883\n",
      "\n",
      "episode 15, val func loss 1.751663088798523\n",
      "\n",
      "episode 16, val func loss 2.020695924758911\n",
      "\n",
      "Val func train loss in epoch 0:2.2084042355418205\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.1606733798980713\n",
      "\n",
      "episode 2, val func loss 1.7562255859375\n",
      "\n",
      "episode 3, val func loss 2.275742530822754\n",
      "\n",
      "episode 4, val func loss 2.4239304065704346\n",
      "\n",
      "episode 5, val func loss 2.2790160179138184\n",
      "\n",
      "episode 6, val func loss 2.4699578285217285\n",
      "\n",
      "episode 7, val func loss 2.8164594173431396\n",
      "\n",
      "episode 8, val func loss 2.352182149887085\n",
      "\n",
      "episode 9, val func loss 2.011420488357544\n",
      "\n",
      "episode 10, val func loss 2.259321451187134\n",
      "\n",
      "episode 11, val func loss 1.6600017547607422\n",
      "\n",
      "episode 12, val func loss 2.133042812347412\n",
      "\n",
      "episode 13, val func loss 2.0119059085845947\n",
      "\n",
      "episode 14, val func loss 2.738712787628174\n",
      "\n",
      "episode 15, val func loss 1.8094913959503174\n",
      "\n",
      "episode 16, val func loss 2.1284797191619873\n",
      "\n",
      "Val func train loss in epoch 1:2.2054102271795273\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.520159959793091\n",
      "\n",
      "episode 2, val func loss 1.966224193572998\n",
      "\n",
      "episode 3, val func loss 2.716226100921631\n",
      "\n",
      "episode 4, val func loss 2.5111923217773438\n",
      "\n",
      "episode 5, val func loss 2.6882259845733643\n",
      "\n",
      "episode 6, val func loss 1.9067840576171875\n",
      "\n",
      "episode 7, val func loss 1.5063652992248535\n",
      "\n",
      "episode 8, val func loss 2.1993048191070557\n",
      "\n",
      "episode 9, val func loss 2.308994770050049\n",
      "\n",
      "episode 10, val func loss 1.9699621200561523\n",
      "\n",
      "episode 11, val func loss 2.45015811920166\n",
      "\n",
      "episode 12, val func loss 2.1521849632263184\n",
      "\n",
      "episode 13, val func loss 2.4485015869140625\n",
      "\n",
      "episode 14, val func loss 2.2667813301086426\n",
      "\n",
      "episode 15, val func loss 1.8785722255706787\n",
      "\n",
      "episode 16, val func loss 2.3353867530822754\n",
      "\n",
      "Val func train loss in epoch 2:2.239064037799835\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.346848964691162\n",
      "\n",
      "episode 2, val func loss 2.2403981685638428\n",
      "\n",
      "episode 3, val func loss 1.5667659044265747\n",
      "\n",
      "episode 4, val func loss 2.937666893005371\n",
      "\n",
      "episode 5, val func loss 2.5134799480438232\n",
      "\n",
      "episode 6, val func loss 2.0208144187927246\n",
      "\n",
      "episode 7, val func loss 2.487271785736084\n",
      "\n",
      "episode 8, val func loss 1.9080992937088013\n",
      "\n",
      "episode 9, val func loss 1.8446327447891235\n",
      "\n",
      "episode 10, val func loss 2.0741307735443115\n",
      "\n",
      "episode 11, val func loss 2.2366161346435547\n",
      "\n",
      "episode 12, val func loss 2.741016387939453\n",
      "\n",
      "episode 13, val func loss 2.659615993499756\n",
      "\n",
      "episode 14, val func loss 2.6503889560699463\n",
      "\n",
      "episode 15, val func loss 2.1639153957366943\n",
      "\n",
      "episode 16, val func loss 2.0889382362365723\n",
      "\n",
      "Val func train loss in epoch 3:2.280037499964237\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.27841854095459\n",
      "\n",
      "episode 2, val func loss 2.6660025119781494\n",
      "\n",
      "episode 3, val func loss 2.4855105876922607\n",
      "\n",
      "episode 4, val func loss 2.7147104740142822\n",
      "\n",
      "episode 5, val func loss 2.4235174655914307\n",
      "\n",
      "episode 6, val func loss 3.106187343597412\n",
      "\n",
      "episode 7, val func loss 1.9586795568466187\n",
      "\n",
      "episode 8, val func loss 2.1644184589385986\n",
      "\n",
      "episode 9, val func loss 3.060802459716797\n",
      "\n",
      "episode 10, val func loss 2.487241268157959\n",
      "\n",
      "episode 11, val func loss 1.4794182777404785\n",
      "\n",
      "episode 12, val func loss 2.532381772994995\n",
      "\n",
      "episode 13, val func loss 1.7903107404708862\n",
      "\n",
      "episode 14, val func loss 2.1925113201141357\n",
      "\n",
      "episode 15, val func loss 2.0586600303649902\n",
      "\n",
      "episode 16, val func loss 2.294675827026367\n",
      "\n",
      "Val func train loss in epoch 4:2.355840414762497\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 2.7248575687408447\n",
      "\n",
      "episode 2, val func loss 1.8714284896850586\n",
      "\n",
      "episode 3, val func loss 2.466933488845825\n",
      "\n",
      "episode 4, val func loss 1.5630780458450317\n",
      "\n",
      "episode 5, val func loss 2.3104147911071777\n",
      "\n",
      "episode 6, val func loss 2.220757007598877\n",
      "\n",
      "episode 7, val func loss 2.597177505493164\n",
      "\n",
      "episode 8, val func loss 2.4222943782806396\n",
      "\n",
      "episode 9, val func loss 2.1944193840026855\n",
      "\n",
      "episode 10, val func loss 1.9290350675582886\n",
      "\n",
      "episode 11, val func loss 2.5567007064819336\n",
      "\n",
      "episode 12, val func loss 2.287855386734009\n",
      "\n",
      "episode 13, val func loss 2.5851709842681885\n",
      "\n",
      "episode 14, val func loss 2.0277700424194336\n",
      "\n",
      "episode 15, val func loss 2.382395029067993\n",
      "\n",
      "episode 16, val func loss 2.147756338119507\n",
      "\n",
      "Val func train loss in epoch 5:2.268002763390541\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.2430217266082764\n",
      "\n",
      "episode 2, val func loss 2.7528281211853027\n",
      "\n",
      "episode 3, val func loss 2.5539064407348633\n",
      "\n",
      "episode 4, val func loss 2.403209924697876\n",
      "\n",
      "episode 5, val func loss 2.249774217605591\n",
      "\n",
      "episode 6, val func loss 2.2258870601654053\n",
      "\n",
      "episode 7, val func loss 1.9009439945220947\n",
      "\n",
      "episode 8, val func loss 2.382952928543091\n",
      "\n",
      "episode 9, val func loss 2.4443774223327637\n",
      "\n",
      "episode 10, val func loss 1.9934026002883911\n",
      "\n",
      "episode 11, val func loss 2.0176126956939697\n",
      "\n",
      "episode 12, val func loss 1.9222042560577393\n",
      "\n",
      "episode 13, val func loss 1.5807743072509766\n",
      "\n",
      "episode 14, val func loss 2.1198909282684326\n",
      "\n",
      "episode 15, val func loss 1.9855217933654785\n",
      "\n",
      "episode 16, val func loss 2.372588872909546\n",
      "\n",
      "Val func train loss in epoch 6:2.1968060806393623\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 2.373405933380127\n",
      "\n",
      "episode 2, val func loss 2.5358691215515137\n",
      "\n",
      "episode 3, val func loss 1.8600462675094604\n",
      "\n",
      "episode 4, val func loss 1.5578769445419312\n",
      "\n",
      "episode 5, val func loss 2.032770872116089\n",
      "\n",
      "episode 6, val func loss 2.665236473083496\n",
      "\n",
      "episode 7, val func loss 2.054145574569702\n",
      "\n",
      "episode 8, val func loss 2.705327033996582\n",
      "\n",
      "episode 9, val func loss 2.2210276126861572\n",
      "\n",
      "episode 10, val func loss 2.5718681812286377\n",
      "\n",
      "episode 11, val func loss 2.1253297328948975\n",
      "\n",
      "episode 12, val func loss 2.4580941200256348\n",
      "\n",
      "episode 13, val func loss 2.274066686630249\n",
      "\n",
      "episode 14, val func loss 1.7964600324630737\n",
      "\n",
      "episode 15, val func loss 2.1577773094177246\n",
      "\n",
      "episode 16, val func loss 2.2862966060638428\n",
      "\n",
      "Val func train loss in epoch 7:2.229724906384945\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.3440358638763428\n",
      "\n",
      "episode 2, val func loss 2.4322569370269775\n",
      "\n",
      "episode 3, val func loss 1.8020267486572266\n",
      "\n",
      "episode 4, val func loss 2.6218760013580322\n",
      "\n",
      "episode 5, val func loss 2.0448803901672363\n",
      "\n",
      "episode 6, val func loss 2.2861835956573486\n",
      "\n",
      "episode 7, val func loss 2.6478137969970703\n",
      "\n",
      "episode 8, val func loss 1.98897385597229\n",
      "\n",
      "episode 9, val func loss 1.9775251150131226\n",
      "\n",
      "episode 10, val func loss 2.1521928310394287\n",
      "\n",
      "episode 11, val func loss 1.7225149869918823\n",
      "\n",
      "episode 12, val func loss 2.0532066822052\n",
      "\n",
      "episode 13, val func loss 2.5926074981689453\n",
      "\n",
      "episode 14, val func loss 2.4618256092071533\n",
      "\n",
      "episode 15, val func loss 1.9313963651657104\n",
      "\n",
      "episode 16, val func loss 2.3946876525878906\n",
      "\n",
      "Val func train loss in epoch 8:2.215875245630741\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 2.00881028175354\n",
      "\n",
      "episode 2, val func loss 2.7100400924682617\n",
      "\n",
      "episode 3, val func loss 2.746192216873169\n",
      "\n",
      "episode 4, val func loss 1.5126099586486816\n",
      "\n",
      "episode 5, val func loss 2.0685670375823975\n",
      "\n",
      "episode 6, val func loss 1.9300408363342285\n",
      "\n",
      "episode 7, val func loss 2.609373092651367\n",
      "\n",
      "episode 8, val func loss 2.0018045902252197\n",
      "\n",
      "episode 9, val func loss 2.474078416824341\n",
      "\n",
      "episode 10, val func loss 1.9451589584350586\n",
      "\n",
      "episode 11, val func loss 2.534266710281372\n",
      "\n",
      "episode 12, val func loss 2.0701193809509277\n",
      "\n",
      "episode 13, val func loss 2.3185875415802\n",
      "\n",
      "episode 14, val func loss 1.817763328552246\n",
      "\n",
      "episode 15, val func loss 2.0542314052581787\n",
      "\n",
      "episode 16, val func loss 2.2406258583068848\n",
      "\n",
      "Val func train loss in epoch 9:2.1901418566703796\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.1893625259399414\n",
      "\n",
      "episode 2, val func loss 2.7284579277038574\n",
      "\n",
      "episode 3, val func loss 2.123307704925537\n",
      "\n",
      "episode 4, val func loss 2.1368486881256104\n",
      "\n",
      "episode 5, val func loss 2.001317024230957\n",
      "\n",
      "episode 6, val func loss 2.0178799629211426\n",
      "\n",
      "episode 7, val func loss 2.5731277465820312\n",
      "\n",
      "episode 8, val func loss 2.5028014183044434\n",
      "\n",
      "episode 9, val func loss 2.4479565620422363\n",
      "\n",
      "episode 10, val func loss 2.4392361640930176\n",
      "\n",
      "episode 11, val func loss 2.0986249446868896\n",
      "\n",
      "episode 12, val func loss 1.6354941129684448\n",
      "\n",
      "episode 13, val func loss 2.117893934249878\n",
      "\n",
      "episode 14, val func loss 2.5492920875549316\n",
      "\n",
      "episode 15, val func loss 1.8331657648086548\n",
      "\n",
      "episode 16, val func loss 2.2909610271453857\n",
      "\n",
      "Val func train loss in epoch 10:2.230357974767685\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 2.0044374465942383\n",
      "\n",
      "episode 2, val func loss 1.8811970949172974\n",
      "\n",
      "episode 3, val func loss 2.36275315284729\n",
      "\n",
      "episode 4, val func loss 2.167576789855957\n",
      "\n",
      "episode 5, val func loss 2.057230234146118\n",
      "\n",
      "episode 6, val func loss 1.716695785522461\n",
      "\n",
      "episode 7, val func loss 2.7360434532165527\n",
      "\n",
      "episode 8, val func loss 2.1557652950286865\n",
      "\n",
      "episode 9, val func loss 1.9995747804641724\n",
      "\n",
      "episode 10, val func loss 2.73736834526062\n",
      "\n",
      "episode 11, val func loss 1.9546257257461548\n",
      "\n",
      "episode 12, val func loss 2.599548101425171\n",
      "\n",
      "episode 13, val func loss 2.086254358291626\n",
      "\n",
      "episode 14, val func loss 2.864326238632202\n",
      "\n",
      "episode 15, val func loss 2.5788686275482178\n",
      "\n",
      "episode 16, val func loss 2.4398655891418457\n",
      "\n",
      "Val func train loss in epoch 11:2.271383188664913\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 2.1582913398742676\n",
      "\n",
      "episode 2, val func loss 1.6795077323913574\n",
      "\n",
      "episode 3, val func loss 2.007784605026245\n",
      "\n",
      "episode 4, val func loss 1.8935635089874268\n",
      "\n",
      "episode 5, val func loss 2.236168622970581\n",
      "\n",
      "episode 6, val func loss 2.5531904697418213\n",
      "\n",
      "episode 7, val func loss 2.6259524822235107\n",
      "\n",
      "episode 8, val func loss 2.1692800521850586\n",
      "\n",
      "episode 9, val func loss 2.0282232761383057\n",
      "\n",
      "episode 10, val func loss 1.969053864479065\n",
      "\n",
      "episode 11, val func loss 2.471907377243042\n",
      "\n",
      "episode 12, val func loss 2.00820255279541\n",
      "\n",
      "episode 13, val func loss 2.240138292312622\n",
      "\n",
      "episode 14, val func loss 1.7874013185501099\n",
      "\n",
      "episode 15, val func loss 2.5056498050689697\n",
      "\n",
      "episode 16, val func loss 2.5395612716674805\n",
      "\n",
      "Val func train loss in epoch 12:2.1796172857284546\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.9114506244659424\n",
      "\n",
      "episode 2, val func loss 2.0049922466278076\n",
      "\n",
      "episode 3, val func loss 2.4641358852386475\n",
      "\n",
      "episode 4, val func loss 1.6789478063583374\n",
      "\n",
      "episode 5, val func loss 2.5746960639953613\n",
      "\n",
      "episode 6, val func loss 1.5138798952102661\n",
      "\n",
      "episode 7, val func loss 1.9655561447143555\n",
      "\n",
      "episode 8, val func loss 2.2852118015289307\n",
      "\n",
      "episode 9, val func loss 2.1564459800720215\n",
      "\n",
      "episode 10, val func loss 2.475001811981201\n",
      "\n",
      "episode 11, val func loss 2.423701763153076\n",
      "\n",
      "episode 12, val func loss 2.022751569747925\n",
      "\n",
      "episode 13, val func loss 2.4345805644989014\n",
      "\n",
      "episode 14, val func loss 2.6662704944610596\n",
      "\n",
      "episode 15, val func loss 2.2067906856536865\n",
      "\n",
      "episode 16, val func loss 2.2252309322357178\n",
      "\n",
      "Val func train loss in epoch 13:2.1881027668714523\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.0631468296051025\n",
      "\n",
      "episode 2, val func loss 2.2376441955566406\n",
      "\n",
      "episode 3, val func loss 2.6706743240356445\n",
      "\n",
      "episode 4, val func loss 2.55198335647583\n",
      "\n",
      "episode 5, val func loss 2.1769745349884033\n",
      "\n",
      "episode 6, val func loss 2.2288765907287598\n",
      "\n",
      "episode 7, val func loss 2.5958657264709473\n",
      "\n",
      "episode 8, val func loss 1.6642142534255981\n",
      "\n",
      "episode 9, val func loss 2.035841703414917\n",
      "\n",
      "episode 10, val func loss 2.0966010093688965\n",
      "\n",
      "episode 11, val func loss 2.284909248352051\n",
      "\n",
      "episode 12, val func loss 2.6154980659484863\n",
      "\n",
      "episode 13, val func loss 2.0368001461029053\n",
      "\n",
      "episode 14, val func loss 2.294318199157715\n",
      "\n",
      "episode 15, val func loss 1.8945837020874023\n",
      "\n",
      "episode 16, val func loss 2.327070951461792\n",
      "\n",
      "Val func train loss in epoch 14:2.235937677323818\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.8231955766677856\n",
      "\n",
      "episode 2, val func loss 2.6405646800994873\n",
      "\n",
      "episode 3, val func loss 1.9067548513412476\n",
      "\n",
      "episode 4, val func loss 2.283398151397705\n",
      "\n",
      "episode 5, val func loss 2.1681671142578125\n",
      "\n",
      "episode 6, val func loss 1.8763669729232788\n",
      "\n",
      "episode 7, val func loss 2.6147830486297607\n",
      "\n",
      "episode 8, val func loss 2.437373399734497\n",
      "\n",
      "episode 9, val func loss 2.0317890644073486\n",
      "\n",
      "episode 10, val func loss 2.4532785415649414\n",
      "\n",
      "episode 11, val func loss 2.2508349418640137\n",
      "\n",
      "episode 12, val func loss 1.9461877346038818\n",
      "\n",
      "episode 13, val func loss 2.2235989570617676\n",
      "\n",
      "episode 14, val func loss 1.4291244745254517\n",
      "\n",
      "episode 15, val func loss 2.5960872173309326\n",
      "\n",
      "episode 16, val func loss 1.9075878858566284\n",
      "\n",
      "Val func train loss in epoch 15:2.161818288266659\n",
      "***********************TIME WAS 4.91459592183431 min*****************************\n",
      "\n",
      "**********************ROUND 122 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.47972261905670166\n",
      "\n",
      "episode 2, policy loss 0.5421724319458008\n",
      "\n",
      "episode 3, policy loss 0.5874056816101074\n",
      "\n",
      "episode 4, policy loss 0.5297016501426697\n",
      "\n",
      "episode 5, policy loss 0.5069950222969055\n",
      "\n",
      "episode 6, policy loss 0.4822469651699066\n",
      "\n",
      "episode 7, policy loss 0.48264840245246887\n",
      "\n",
      "episode 8, policy loss 0.5089797973632812\n",
      "\n",
      "episode 9, policy loss 0.482851505279541\n",
      "\n",
      "episode 10, policy loss 0.4829714298248291\n",
      "\n",
      "episode 11, policy loss 0.4830000102519989\n",
      "\n",
      "episode 12, policy loss 0.5336304306983948\n",
      "\n",
      "episode 13, policy loss 0.48308485746383667\n",
      "\n",
      "episode 14, policy loss 0.5100188255310059\n",
      "\n",
      "episode 15, policy loss 0.5328259468078613\n",
      "\n",
      "episode 16, policy loss 0.507649838924408\n",
      "\n",
      "Policy train loss in epoch 0:0.5084940884262323\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.5076758861541748\n",
      "\n",
      "episode 2, policy loss 0.483168363571167\n",
      "\n",
      "episode 3, policy loss 0.4831750690937042\n",
      "\n",
      "episode 4, policy loss 0.5344226956367493\n",
      "\n",
      "episode 5, policy loss 0.48319879174232483\n",
      "\n",
      "episode 6, policy loss 0.5083917379379272\n",
      "\n",
      "episode 7, policy loss 0.5566977858543396\n",
      "\n",
      "episode 8, policy loss 0.483203649520874\n",
      "\n",
      "episode 9, policy loss 0.5094287991523743\n",
      "\n",
      "episode 10, policy loss 0.5329066514968872\n",
      "\n",
      "episode 11, policy loss 0.5337538123130798\n",
      "\n",
      "episode 12, policy loss 0.4832119941711426\n",
      "\n",
      "episode 13, policy loss 0.4832080006599426\n",
      "\n",
      "episode 14, policy loss 0.5101251602172852\n",
      "\n",
      "episode 15, policy loss 0.5320606231689453\n",
      "\n",
      "episode 16, policy loss 0.4832179844379425\n",
      "\n",
      "Policy train loss in epoch 1:0.5067404378205538\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.48321881890296936\n",
      "\n",
      "episode 2, policy loss 0.534457802772522\n",
      "\n",
      "episode 3, policy loss 0.5337705016136169\n",
      "\n",
      "episode 4, policy loss 0.5329142212867737\n",
      "\n",
      "episode 5, policy loss 0.4832245409488678\n",
      "\n",
      "episode 6, policy loss 0.5101242065429688\n",
      "\n",
      "episode 7, policy loss 0.48322680592536926\n",
      "\n",
      "episode 8, policy loss 0.4832248091697693\n",
      "\n",
      "episode 9, policy loss 0.4832232892513275\n",
      "\n",
      "episode 10, policy loss 0.5084095001220703\n",
      "\n",
      "episode 11, policy loss 0.483227401971817\n",
      "\n",
      "episode 12, policy loss 0.5077180862426758\n",
      "\n",
      "episode 13, policy loss 0.48322793841362\n",
      "\n",
      "episode 14, policy loss 0.5320605039596558\n",
      "\n",
      "episode 15, policy loss 0.556726336479187\n",
      "\n",
      "episode 16, policy loss 0.5094375014305115\n",
      "\n",
      "Policy train loss in epoch 2:0.5067620165646076\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.5329153537750244\n",
      "\n",
      "episode 2, policy loss 0.48322176933288574\n",
      "\n",
      "episode 3, policy loss 0.483219176530838\n",
      "\n",
      "episode 4, policy loss 0.5094422101974487\n",
      "\n",
      "episode 5, policy loss 0.5320533514022827\n",
      "\n",
      "episode 6, policy loss 0.4832177460193634\n",
      "\n",
      "episode 7, policy loss 0.5337677001953125\n",
      "\n",
      "episode 8, policy loss 0.48322415351867676\n",
      "\n",
      "episode 9, policy loss 0.508409321308136\n",
      "\n",
      "episode 10, policy loss 0.5101253390312195\n",
      "\n",
      "episode 11, policy loss 0.48322147130966187\n",
      "\n",
      "episode 12, policy loss 0.5567378997802734\n",
      "\n",
      "episode 13, policy loss 0.4832231104373932\n",
      "\n",
      "episode 14, policy loss 0.5344619750976562\n",
      "\n",
      "episode 15, policy loss 0.507719874382019\n",
      "\n",
      "episode 16, policy loss 0.48322269320487976\n",
      "\n",
      "Policy train loss in epoch 3:0.506761446595192\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.8625938892364502\n",
      "\n",
      "episode 2, val func loss 0.8843318223953247\n",
      "\n",
      "episode 3, val func loss 0.7023556232452393\n",
      "\n",
      "episode 4, val func loss 0.901991069316864\n",
      "\n",
      "episode 5, val func loss 0.8623365759849548\n",
      "\n",
      "episode 6, val func loss 0.6865549087524414\n",
      "\n",
      "episode 7, val func loss 0.8986320495605469\n",
      "\n",
      "episode 8, val func loss 0.8153412938117981\n",
      "\n",
      "episode 9, val func loss 0.6255854964256287\n",
      "\n",
      "episode 10, val func loss 0.895624577999115\n",
      "\n",
      "episode 11, val func loss 1.0807490348815918\n",
      "\n",
      "episode 12, val func loss 0.6499913930892944\n",
      "\n",
      "episode 13, val func loss 0.9185559153556824\n",
      "\n",
      "episode 14, val func loss 0.935799241065979\n",
      "\n",
      "episode 15, val func loss 0.7032496333122253\n",
      "\n",
      "episode 16, val func loss 0.5708695650100708\n",
      "\n",
      "Val func train loss in epoch 0:0.8121601305902004\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7684844732284546\n",
      "\n",
      "episode 2, val func loss 0.6073743104934692\n",
      "\n",
      "episode 3, val func loss 1.0313503742218018\n",
      "\n",
      "episode 4, val func loss 0.6963678598403931\n",
      "\n",
      "episode 5, val func loss 0.6042463183403015\n",
      "\n",
      "episode 6, val func loss 0.8595050573348999\n",
      "\n",
      "episode 7, val func loss 1.1245203018188477\n",
      "\n",
      "episode 8, val func loss 0.7742205858230591\n",
      "\n",
      "episode 9, val func loss 0.7103845477104187\n",
      "\n",
      "episode 10, val func loss 0.5802590847015381\n",
      "\n",
      "episode 11, val func loss 0.6533952355384827\n",
      "\n",
      "episode 12, val func loss 0.9248083829879761\n",
      "\n",
      "episode 13, val func loss 0.901495635509491\n",
      "\n",
      "episode 14, val func loss 0.9803004264831543\n",
      "\n",
      "episode 15, val func loss 0.8379926681518555\n",
      "\n",
      "episode 16, val func loss 0.7302170991897583\n",
      "\n",
      "Val func train loss in epoch 1:0.7990576475858688\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.8338987231254578\n",
      "\n",
      "episode 2, val func loss 0.6415883302688599\n",
      "\n",
      "episode 3, val func loss 1.1865726709365845\n",
      "\n",
      "episode 4, val func loss 0.8840547800064087\n",
      "\n",
      "episode 5, val func loss 0.8113570809364319\n",
      "\n",
      "episode 6, val func loss 1.1066279411315918\n",
      "\n",
      "episode 7, val func loss 0.8263424038887024\n",
      "\n",
      "episode 8, val func loss 0.6269092559814453\n",
      "\n",
      "episode 9, val func loss 0.9024163484573364\n",
      "\n",
      "episode 10, val func loss 0.691385805606842\n",
      "\n",
      "episode 11, val func loss 0.656408429145813\n",
      "\n",
      "episode 12, val func loss 0.6383596658706665\n",
      "\n",
      "episode 13, val func loss 0.6613683700561523\n",
      "\n",
      "episode 14, val func loss 0.6991188526153564\n",
      "\n",
      "episode 15, val func loss 1.048724889755249\n",
      "\n",
      "episode 16, val func loss 0.7938507795333862\n",
      "\n",
      "Val func train loss in epoch 2:0.8130615204572678\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6405522227287292\n",
      "\n",
      "episode 2, val func loss 0.9328954219818115\n",
      "\n",
      "episode 3, val func loss 0.9936772584915161\n",
      "\n",
      "episode 4, val func loss 0.6498412489891052\n",
      "\n",
      "episode 5, val func loss 1.1447356939315796\n",
      "\n",
      "episode 6, val func loss 0.7320641279220581\n",
      "\n",
      "episode 7, val func loss 0.8032720685005188\n",
      "\n",
      "episode 8, val func loss 0.8949475884437561\n",
      "\n",
      "episode 9, val func loss 0.6220790147781372\n",
      "\n",
      "episode 10, val func loss 0.9367976188659668\n",
      "\n",
      "episode 11, val func loss 0.6617081761360168\n",
      "\n",
      "episode 12, val func loss 0.6795416474342346\n",
      "\n",
      "episode 13, val func loss 0.7780491709709167\n",
      "\n",
      "episode 14, val func loss 0.7982141971588135\n",
      "\n",
      "episode 15, val func loss 0.6096317172050476\n",
      "\n",
      "episode 16, val func loss 1.0366618633270264\n",
      "\n",
      "Val func train loss in epoch 3:0.8071668148040771\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6405863761901855\n",
      "\n",
      "episode 2, val func loss 0.6727731823921204\n",
      "\n",
      "episode 3, val func loss 0.615328848361969\n",
      "\n",
      "episode 4, val func loss 0.9870931506156921\n",
      "\n",
      "episode 5, val func loss 0.657638669013977\n",
      "\n",
      "episode 6, val func loss 0.8130989074707031\n",
      "\n",
      "episode 7, val func loss 0.8980939984321594\n",
      "\n",
      "episode 8, val func loss 1.1359366178512573\n",
      "\n",
      "episode 9, val func loss 0.705539882183075\n",
      "\n",
      "episode 10, val func loss 0.7290579676628113\n",
      "\n",
      "episode 11, val func loss 0.901753842830658\n",
      "\n",
      "episode 12, val func loss 0.7959850430488586\n",
      "\n",
      "episode 13, val func loss 0.7223873138427734\n",
      "\n",
      "episode 14, val func loss 0.6950424313545227\n",
      "\n",
      "episode 15, val func loss 0.9389638900756836\n",
      "\n",
      "episode 16, val func loss 0.6305235028266907\n",
      "\n",
      "Val func train loss in epoch 4:0.7837377265095711\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.8196771740913391\n",
      "\n",
      "episode 2, val func loss 0.7582042813301086\n",
      "\n",
      "episode 3, val func loss 0.6720743179321289\n",
      "\n",
      "episode 4, val func loss 0.8510770797729492\n",
      "\n",
      "episode 5, val func loss 0.9209896922111511\n",
      "\n",
      "episode 6, val func loss 0.7366567254066467\n",
      "\n",
      "episode 7, val func loss 0.7826725840568542\n",
      "\n",
      "episode 8, val func loss 0.6577661037445068\n",
      "\n",
      "episode 9, val func loss 0.7918590307235718\n",
      "\n",
      "episode 10, val func loss 1.0259774923324585\n",
      "\n",
      "episode 11, val func loss 0.686852753162384\n",
      "\n",
      "episode 12, val func loss 0.8851683139801025\n",
      "\n",
      "episode 13, val func loss 0.8614935278892517\n",
      "\n",
      "episode 14, val func loss 0.666971743106842\n",
      "\n",
      "episode 15, val func loss 0.6178244948387146\n",
      "\n",
      "episode 16, val func loss 0.6467817425727844\n",
      "\n",
      "Val func train loss in epoch 5:0.7738779410719872\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.0915749073028564\n",
      "\n",
      "episode 2, val func loss 0.6757379174232483\n",
      "\n",
      "episode 3, val func loss 0.8574957251548767\n",
      "\n",
      "episode 4, val func loss 0.6986437439918518\n",
      "\n",
      "episode 5, val func loss 0.693400502204895\n",
      "\n",
      "episode 6, val func loss 0.9011659622192383\n",
      "\n",
      "episode 7, val func loss 0.8897342085838318\n",
      "\n",
      "episode 8, val func loss 0.6609521508216858\n",
      "\n",
      "episode 9, val func loss 0.6432946920394897\n",
      "\n",
      "episode 10, val func loss 0.9320701360702515\n",
      "\n",
      "episode 11, val func loss 0.7424404621124268\n",
      "\n",
      "episode 12, val func loss 0.5104851126670837\n",
      "\n",
      "episode 13, val func loss 0.7360793352127075\n",
      "\n",
      "episode 14, val func loss 0.7383286952972412\n",
      "\n",
      "episode 15, val func loss 0.7357768416404724\n",
      "\n",
      "episode 16, val func loss 0.6582875847816467\n",
      "\n",
      "Val func train loss in epoch 6:0.7603417485952377\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.9125878810882568\n",
      "\n",
      "episode 2, val func loss 0.956293523311615\n",
      "\n",
      "episode 3, val func loss 0.7024327516555786\n",
      "\n",
      "episode 4, val func loss 0.9194412231445312\n",
      "\n",
      "episode 5, val func loss 0.7069673538208008\n",
      "\n",
      "episode 6, val func loss 0.6990460157394409\n",
      "\n",
      "episode 7, val func loss 0.6102996468544006\n",
      "\n",
      "episode 8, val func loss 0.6211593151092529\n",
      "\n",
      "episode 9, val func loss 0.62575364112854\n",
      "\n",
      "episode 10, val func loss 0.5853254199028015\n",
      "\n",
      "episode 11, val func loss 0.9108021259307861\n",
      "\n",
      "episode 12, val func loss 0.7383467555046082\n",
      "\n",
      "episode 13, val func loss 0.6259201169013977\n",
      "\n",
      "episode 14, val func loss 0.81285560131073\n",
      "\n",
      "episode 15, val func loss 1.0903191566467285\n",
      "\n",
      "episode 16, val func loss 0.7507432103157043\n",
      "\n",
      "Val func train loss in epoch 7:0.7667683586478233\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8658154010772705\n",
      "\n",
      "episode 2, val func loss 0.7149304151535034\n",
      "\n",
      "episode 3, val func loss 0.9169421195983887\n",
      "\n",
      "episode 4, val func loss 0.9431917071342468\n",
      "\n",
      "episode 5, val func loss 0.7789426445960999\n",
      "\n",
      "episode 6, val func loss 0.7972780466079712\n",
      "\n",
      "episode 7, val func loss 0.6961241960525513\n",
      "\n",
      "episode 8, val func loss 0.8335320353507996\n",
      "\n",
      "episode 9, val func loss 0.6420196890830994\n",
      "\n",
      "episode 10, val func loss 0.6393485069274902\n",
      "\n",
      "episode 11, val func loss 0.763616681098938\n",
      "\n",
      "episode 12, val func loss 0.8305338025093079\n",
      "\n",
      "episode 13, val func loss 0.8085085153579712\n",
      "\n",
      "episode 14, val func loss 0.9635469317436218\n",
      "\n",
      "episode 15, val func loss 0.6725231409072876\n",
      "\n",
      "episode 16, val func loss 1.0001271963119507\n",
      "\n",
      "Val func train loss in epoch 8:0.8041863143444061\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6884897351264954\n",
      "\n",
      "episode 2, val func loss 0.9057419896125793\n",
      "\n",
      "episode 3, val func loss 0.6531593799591064\n",
      "\n",
      "episode 4, val func loss 0.8560523390769958\n",
      "\n",
      "episode 5, val func loss 0.609239935874939\n",
      "\n",
      "episode 6, val func loss 1.1008745431900024\n",
      "\n",
      "episode 7, val func loss 0.7607955932617188\n",
      "\n",
      "episode 8, val func loss 0.7213411927223206\n",
      "\n",
      "episode 9, val func loss 0.9844633340835571\n",
      "\n",
      "episode 10, val func loss 0.911081850528717\n",
      "\n",
      "episode 11, val func loss 0.7644506096839905\n",
      "\n",
      "episode 12, val func loss 0.846014142036438\n",
      "\n",
      "episode 13, val func loss 0.6337432265281677\n",
      "\n",
      "episode 14, val func loss 0.7111905813217163\n",
      "\n",
      "episode 15, val func loss 0.630972683429718\n",
      "\n",
      "episode 16, val func loss 0.6538995504379272\n",
      "\n",
      "Val func train loss in epoch 9:0.7769694179296494\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.8996027112007141\n",
      "\n",
      "episode 2, val func loss 0.7263368368148804\n",
      "\n",
      "episode 3, val func loss 0.8951110243797302\n",
      "\n",
      "episode 4, val func loss 0.8636202812194824\n",
      "\n",
      "episode 5, val func loss 0.6567927002906799\n",
      "\n",
      "episode 6, val func loss 0.7702056169509888\n",
      "\n",
      "episode 7, val func loss 0.6365312933921814\n",
      "\n",
      "episode 8, val func loss 0.6811966300010681\n",
      "\n",
      "episode 9, val func loss 0.7242563366889954\n",
      "\n",
      "episode 10, val func loss 0.6479198932647705\n",
      "\n",
      "episode 11, val func loss 0.8835586309432983\n",
      "\n",
      "episode 12, val func loss 0.7412503957748413\n",
      "\n",
      "episode 13, val func loss 0.7281744480133057\n",
      "\n",
      "episode 14, val func loss 1.0340896844863892\n",
      "\n",
      "episode 15, val func loss 0.9862027764320374\n",
      "\n",
      "episode 16, val func loss 1.0618743896484375\n",
      "\n",
      "Val func train loss in epoch 10:0.8085452280938625\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.9874669909477234\n",
      "\n",
      "episode 2, val func loss 0.6417477130889893\n",
      "\n",
      "episode 3, val func loss 0.7099401950836182\n",
      "\n",
      "episode 4, val func loss 1.3220829963684082\n",
      "\n",
      "episode 5, val func loss 0.7170060873031616\n",
      "\n",
      "episode 6, val func loss 0.7153061628341675\n",
      "\n",
      "episode 7, val func loss 1.085593342781067\n",
      "\n",
      "episode 8, val func loss 0.7419307827949524\n",
      "\n",
      "episode 9, val func loss 1.0269274711608887\n",
      "\n",
      "episode 10, val func loss 0.6914685964584351\n",
      "\n",
      "episode 11, val func loss 0.8235342502593994\n",
      "\n",
      "episode 12, val func loss 0.8286632299423218\n",
      "\n",
      "episode 13, val func loss 0.8109787702560425\n",
      "\n",
      "episode 14, val func loss 0.6190232634544373\n",
      "\n",
      "episode 15, val func loss 0.9249786138534546\n",
      "\n",
      "episode 16, val func loss 0.6550095081329346\n",
      "\n",
      "Val func train loss in epoch 11:0.8313536234200001\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.96320641040802\n",
      "\n",
      "episode 2, val func loss 0.6999902725219727\n",
      "\n",
      "episode 3, val func loss 0.6767126321792603\n",
      "\n",
      "episode 4, val func loss 0.6433454155921936\n",
      "\n",
      "episode 5, val func loss 0.8396207690238953\n",
      "\n",
      "episode 6, val func loss 0.6059995889663696\n",
      "\n",
      "episode 7, val func loss 0.6179398894309998\n",
      "\n",
      "episode 8, val func loss 0.8529878258705139\n",
      "\n",
      "episode 9, val func loss 0.9488705396652222\n",
      "\n",
      "episode 10, val func loss 0.9570713043212891\n",
      "\n",
      "episode 11, val func loss 0.7840141654014587\n",
      "\n",
      "episode 12, val func loss 0.642599880695343\n",
      "\n",
      "episode 13, val func loss 0.8989689946174622\n",
      "\n",
      "episode 14, val func loss 0.7002700567245483\n",
      "\n",
      "episode 15, val func loss 1.0018372535705566\n",
      "\n",
      "episode 16, val func loss 0.6014686226844788\n",
      "\n",
      "Val func train loss in epoch 12:0.777181476354599\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.7533265948295593\n",
      "\n",
      "episode 2, val func loss 0.68757164478302\n",
      "\n",
      "episode 3, val func loss 0.6729336977005005\n",
      "\n",
      "episode 4, val func loss 0.8378481864929199\n",
      "\n",
      "episode 5, val func loss 0.9173969626426697\n",
      "\n",
      "episode 6, val func loss 0.7996416687965393\n",
      "\n",
      "episode 7, val func loss 0.6298562288284302\n",
      "\n",
      "episode 8, val func loss 0.8461892604827881\n",
      "\n",
      "episode 9, val func loss 0.5933390259742737\n",
      "\n",
      "episode 10, val func loss 0.707826554775238\n",
      "\n",
      "episode 11, val func loss 0.694827139377594\n",
      "\n",
      "episode 12, val func loss 0.8184289932250977\n",
      "\n",
      "episode 13, val func loss 1.1314890384674072\n",
      "\n",
      "episode 14, val func loss 0.589212954044342\n",
      "\n",
      "episode 15, val func loss 0.6173089742660522\n",
      "\n",
      "episode 16, val func loss 0.885713517665863\n",
      "\n",
      "Val func train loss in epoch 13:0.7614319026470184\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.743310272693634\n",
      "\n",
      "episode 2, val func loss 0.7637162804603577\n",
      "\n",
      "episode 3, val func loss 0.8147363662719727\n",
      "\n",
      "episode 4, val func loss 0.7082680463790894\n",
      "\n",
      "episode 5, val func loss 0.6507622003555298\n",
      "\n",
      "episode 6, val func loss 0.8480924963951111\n",
      "\n",
      "episode 7, val func loss 0.6629523634910583\n",
      "\n",
      "episode 8, val func loss 0.6411274671554565\n",
      "\n",
      "episode 9, val func loss 0.72878497838974\n",
      "\n",
      "episode 10, val func loss 0.571006715297699\n",
      "\n",
      "episode 11, val func loss 1.106324315071106\n",
      "\n",
      "episode 12, val func loss 0.8837975263595581\n",
      "\n",
      "episode 13, val func loss 0.7283434867858887\n",
      "\n",
      "episode 14, val func loss 0.9134819507598877\n",
      "\n",
      "episode 15, val func loss 0.6214750409126282\n",
      "\n",
      "episode 16, val func loss 0.8823962807655334\n",
      "\n",
      "Val func train loss in epoch 14:0.7667859867215157\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.0696187019348145\n",
      "\n",
      "episode 2, val func loss 0.8223600387573242\n",
      "\n",
      "episode 3, val func loss 0.7021456360816956\n",
      "\n",
      "episode 4, val func loss 0.80344158411026\n",
      "\n",
      "episode 5, val func loss 0.7325613498687744\n",
      "\n",
      "episode 6, val func loss 0.7705798149108887\n",
      "\n",
      "episode 7, val func loss 0.8102548718452454\n",
      "\n",
      "episode 8, val func loss 0.9083327054977417\n",
      "\n",
      "episode 9, val func loss 0.6235242486000061\n",
      "\n",
      "episode 10, val func loss 0.9124789834022522\n",
      "\n",
      "episode 11, val func loss 0.7611159682273865\n",
      "\n",
      "episode 12, val func loss 0.7486521005630493\n",
      "\n",
      "episode 13, val func loss 0.6891828179359436\n",
      "\n",
      "episode 14, val func loss 0.8137258887290955\n",
      "\n",
      "episode 15, val func loss 0.879546046257019\n",
      "\n",
      "episode 16, val func loss 0.9231270551681519\n",
      "\n",
      "Val func train loss in epoch 15:0.810665488243103\n",
      "***********************TIME WAS 4.9210204164187115 min*****************************\n",
      "\n",
      "**********************ROUND 123 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.9257485866546631\n",
      "\n",
      "episode 2, policy loss 0.9257457852363586\n",
      "\n",
      "episode 3, policy loss 0.9257490038871765\n",
      "\n",
      "episode 4, policy loss 0.9613147377967834\n",
      "\n",
      "episode 5, policy loss 0.92577064037323\n",
      "\n",
      "episode 6, policy loss 0.9257909059524536\n",
      "\n",
      "episode 7, policy loss 0.9258058667182922\n",
      "\n",
      "episode 8, policy loss 0.9258167743682861\n",
      "\n",
      "episode 9, policy loss 0.925822913646698\n",
      "\n",
      "episode 10, policy loss 0.9258285760879517\n",
      "\n",
      "episode 11, policy loss 0.9258330464363098\n",
      "\n",
      "episode 12, policy loss 0.9258354306221008\n",
      "\n",
      "episode 13, policy loss 0.9258373975753784\n",
      "\n",
      "episode 14, policy loss 0.9258387684822083\n",
      "\n",
      "episode 15, policy loss 0.92584228515625\n",
      "\n",
      "episode 16, policy loss 0.9258420467376709\n",
      "\n",
      "Policy train loss in epoch 0:0.9280264228582382\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.9258448481559753\n",
      "\n",
      "episode 2, policy loss 0.9258445501327515\n",
      "\n",
      "episode 3, policy loss 0.9258480072021484\n",
      "\n",
      "episode 4, policy loss 0.9258475303649902\n",
      "\n",
      "episode 5, policy loss 0.9258471727371216\n",
      "\n",
      "episode 6, policy loss 0.9258478879928589\n",
      "\n",
      "episode 7, policy loss 0.9258484840393066\n",
      "\n",
      "episode 8, policy loss 0.9258484840393066\n",
      "\n",
      "episode 9, policy loss 0.9258502125740051\n",
      "\n",
      "episode 10, policy loss 0.9258499145507812\n",
      "\n",
      "episode 11, policy loss 0.9258499145507812\n",
      "\n",
      "episode 12, policy loss 0.9258498549461365\n",
      "\n",
      "episode 13, policy loss 0.9504601359367371\n",
      "\n",
      "episode 14, policy loss 0.9258502125740051\n",
      "\n",
      "episode 15, policy loss 0.9258515238761902\n",
      "\n",
      "episode 16, policy loss 0.9258502125740051\n",
      "\n",
      "Policy train loss in epoch 1:0.9273868091404438\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.9258504509925842\n",
      "\n",
      "episode 2, policy loss 0.9258504509925842\n",
      "\n",
      "episode 3, policy loss 0.9258504509925842\n",
      "\n",
      "episode 4, policy loss 0.9258513450622559\n",
      "\n",
      "episode 5, policy loss 0.9258520007133484\n",
      "\n",
      "episode 6, policy loss 0.9258513450622559\n",
      "\n",
      "episode 7, policy loss 0.9258526563644409\n",
      "\n",
      "episode 8, policy loss 0.9258511662483215\n",
      "\n",
      "episode 9, policy loss 0.9258522987365723\n",
      "\n",
      "episode 10, policy loss 0.925851583480835\n",
      "\n",
      "episode 11, policy loss 0.9504613280296326\n",
      "\n",
      "episode 12, policy loss 0.9258527159690857\n",
      "\n",
      "episode 13, policy loss 0.9258524775505066\n",
      "\n",
      "episode 14, policy loss 0.925852358341217\n",
      "\n",
      "episode 15, policy loss 0.9258519411087036\n",
      "\n",
      "episode 16, policy loss 0.9258517622947693\n",
      "\n",
      "Policy train loss in epoch 2:0.9273897707462311\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.9258527159690857\n",
      "\n",
      "episode 2, policy loss 0.9258522987365723\n",
      "\n",
      "episode 3, policy loss 0.9258521199226379\n",
      "\n",
      "episode 4, policy loss 0.9504611492156982\n",
      "\n",
      "episode 5, policy loss 0.9258509874343872\n",
      "\n",
      "episode 6, policy loss 0.9258519411087036\n",
      "\n",
      "episode 7, policy loss 0.9258521795272827\n",
      "\n",
      "episode 8, policy loss 0.925851047039032\n",
      "\n",
      "episode 9, policy loss 0.9258527159690857\n",
      "\n",
      "episode 10, policy loss 0.9258514046669006\n",
      "\n",
      "episode 11, policy loss 0.9258519411087036\n",
      "\n",
      "episode 12, policy loss 0.9258517026901245\n",
      "\n",
      "episode 13, policy loss 0.925852358341217\n",
      "\n",
      "episode 14, policy loss 0.9258527159690857\n",
      "\n",
      "episode 15, policy loss 0.9258530735969543\n",
      "\n",
      "episode 16, policy loss 0.9258514046669006\n",
      "\n",
      "Policy train loss in epoch 3:0.9273901097476482\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7016050815582275\n",
      "\n",
      "episode 2, val func loss 0.6818735003471375\n",
      "\n",
      "episode 3, val func loss 0.6136332750320435\n",
      "\n",
      "episode 4, val func loss 0.6460214257240295\n",
      "\n",
      "episode 5, val func loss 0.7283172011375427\n",
      "\n",
      "episode 6, val func loss 0.8259788155555725\n",
      "\n",
      "episode 7, val func loss 0.665583074092865\n",
      "\n",
      "episode 8, val func loss 0.5684251189231873\n",
      "\n",
      "episode 9, val func loss 0.713150680065155\n",
      "\n",
      "episode 10, val func loss 0.6071630716323853\n",
      "\n",
      "episode 11, val func loss 0.8083076477050781\n",
      "\n",
      "episode 12, val func loss 0.7000100612640381\n",
      "\n",
      "episode 13, val func loss 0.5825327038764954\n",
      "\n",
      "episode 14, val func loss 0.5771328210830688\n",
      "\n",
      "episode 15, val func loss 0.6482064127922058\n",
      "\n",
      "episode 16, val func loss 0.571241021156311\n",
      "\n",
      "Val func train loss in epoch 0:0.6649488694965839\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.5702304840087891\n",
      "\n",
      "episode 2, val func loss 0.5865676999092102\n",
      "\n",
      "episode 3, val func loss 0.6499077677726746\n",
      "\n",
      "episode 4, val func loss 0.6827538013458252\n",
      "\n",
      "episode 5, val func loss 0.6299874782562256\n",
      "\n",
      "episode 6, val func loss 0.6505073308944702\n",
      "\n",
      "episode 7, val func loss 0.6891989707946777\n",
      "\n",
      "episode 8, val func loss 0.64609694480896\n",
      "\n",
      "episode 9, val func loss 0.6025967001914978\n",
      "\n",
      "episode 10, val func loss 0.674007773399353\n",
      "\n",
      "episode 11, val func loss 0.6455705165863037\n",
      "\n",
      "episode 12, val func loss 0.7940942049026489\n",
      "\n",
      "episode 13, val func loss 0.637590229511261\n",
      "\n",
      "episode 14, val func loss 0.6601887345314026\n",
      "\n",
      "episode 15, val func loss 0.6659842729568481\n",
      "\n",
      "episode 16, val func loss 0.7719036936759949\n",
      "\n",
      "Val func train loss in epoch 1:0.6598241627216339\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7075574398040771\n",
      "\n",
      "episode 2, val func loss 0.6932567358016968\n",
      "\n",
      "episode 3, val func loss 0.6847183704376221\n",
      "\n",
      "episode 4, val func loss 0.7011207938194275\n",
      "\n",
      "episode 5, val func loss 0.6365589499473572\n",
      "\n",
      "episode 6, val func loss 0.6820846796035767\n",
      "\n",
      "episode 7, val func loss 0.600160539150238\n",
      "\n",
      "episode 8, val func loss 0.8347188234329224\n",
      "\n",
      "episode 9, val func loss 0.6660095453262329\n",
      "\n",
      "episode 10, val func loss 0.7183943390846252\n",
      "\n",
      "episode 11, val func loss 0.6701158285140991\n",
      "\n",
      "episode 12, val func loss 0.6500573754310608\n",
      "\n",
      "episode 13, val func loss 0.6334853768348694\n",
      "\n",
      "episode 14, val func loss 0.6343339681625366\n",
      "\n",
      "episode 15, val func loss 0.5586740970611572\n",
      "\n",
      "episode 16, val func loss 0.6067134141921997\n",
      "\n",
      "Val func train loss in epoch 2:0.6673725172877312\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.5925275087356567\n",
      "\n",
      "episode 2, val func loss 0.6261208653450012\n",
      "\n",
      "episode 3, val func loss 0.6085988283157349\n",
      "\n",
      "episode 4, val func loss 0.7794613242149353\n",
      "\n",
      "episode 5, val func loss 0.6718927621841431\n",
      "\n",
      "episode 6, val func loss 0.6293761134147644\n",
      "\n",
      "episode 7, val func loss 0.6949918866157532\n",
      "\n",
      "episode 8, val func loss 0.7046906352043152\n",
      "\n",
      "episode 9, val func loss 0.8407143354415894\n",
      "\n",
      "episode 10, val func loss 0.6092440485954285\n",
      "\n",
      "episode 11, val func loss 0.668864905834198\n",
      "\n",
      "episode 12, val func loss 0.7771679759025574\n",
      "\n",
      "episode 13, val func loss 0.6580617427825928\n",
      "\n",
      "episode 14, val func loss 0.6161311268806458\n",
      "\n",
      "episode 15, val func loss 0.6546145677566528\n",
      "\n",
      "episode 16, val func loss 0.6360744833946228\n",
      "\n",
      "Val func train loss in epoch 3:0.673033319413662\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7402448654174805\n",
      "\n",
      "episode 2, val func loss 0.719997227191925\n",
      "\n",
      "episode 3, val func loss 0.6018710136413574\n",
      "\n",
      "episode 4, val func loss 0.6631193161010742\n",
      "\n",
      "episode 5, val func loss 0.7605733871459961\n",
      "\n",
      "episode 6, val func loss 0.7530443668365479\n",
      "\n",
      "episode 7, val func loss 0.5897201895713806\n",
      "\n",
      "episode 8, val func loss 0.66753751039505\n",
      "\n",
      "episode 9, val func loss 0.5744745135307312\n",
      "\n",
      "episode 10, val func loss 0.6711230278015137\n",
      "\n",
      "episode 11, val func loss 0.639761745929718\n",
      "\n",
      "episode 12, val func loss 0.6102689504623413\n",
      "\n",
      "episode 13, val func loss 0.5490242838859558\n",
      "\n",
      "episode 14, val func loss 0.5954656004905701\n",
      "\n",
      "episode 15, val func loss 0.7085910439491272\n",
      "\n",
      "episode 16, val func loss 0.6208057999610901\n",
      "\n",
      "Val func train loss in epoch 4:0.6541014276444912\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6559606194496155\n",
      "\n",
      "episode 2, val func loss 0.6498326659202576\n",
      "\n",
      "episode 3, val func loss 0.6987105011940002\n",
      "\n",
      "episode 4, val func loss 0.7157416939735413\n",
      "\n",
      "episode 5, val func loss 0.627824068069458\n",
      "\n",
      "episode 6, val func loss 0.6679536700248718\n",
      "\n",
      "episode 7, val func loss 0.6403412818908691\n",
      "\n",
      "episode 8, val func loss 0.6514840126037598\n",
      "\n",
      "episode 9, val func loss 0.6197196841239929\n",
      "\n",
      "episode 10, val func loss 0.690834105014801\n",
      "\n",
      "episode 11, val func loss 0.6289629936218262\n",
      "\n",
      "episode 12, val func loss 0.6013070940971375\n",
      "\n",
      "episode 13, val func loss 0.7097600698471069\n",
      "\n",
      "episode 14, val func loss 0.6861814260482788\n",
      "\n",
      "episode 15, val func loss 0.6856667399406433\n",
      "\n",
      "episode 16, val func loss 0.6961137652397156\n",
      "\n",
      "Val func train loss in epoch 5:0.6641496494412422\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6067949533462524\n",
      "\n",
      "episode 2, val func loss 0.7698361873626709\n",
      "\n",
      "episode 3, val func loss 0.6425333619117737\n",
      "\n",
      "episode 4, val func loss 0.6416026949882507\n",
      "\n",
      "episode 5, val func loss 0.6944690346717834\n",
      "\n",
      "episode 6, val func loss 0.6738007664680481\n",
      "\n",
      "episode 7, val func loss 0.6325647830963135\n",
      "\n",
      "episode 8, val func loss 0.7582982182502747\n",
      "\n",
      "episode 9, val func loss 0.5682059526443481\n",
      "\n",
      "episode 10, val func loss 0.631110668182373\n",
      "\n",
      "episode 11, val func loss 0.681117057800293\n",
      "\n",
      "episode 12, val func loss 0.6192910075187683\n",
      "\n",
      "episode 13, val func loss 0.7942370772361755\n",
      "\n",
      "episode 14, val func loss 0.6719688773155212\n",
      "\n",
      "episode 15, val func loss 0.6017178297042847\n",
      "\n",
      "episode 16, val func loss 0.6475096940994263\n",
      "\n",
      "Val func train loss in epoch 6:0.6646911352872849\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6453270316123962\n",
      "\n",
      "episode 2, val func loss 0.5835564136505127\n",
      "\n",
      "episode 3, val func loss 0.6282162070274353\n",
      "\n",
      "episode 4, val func loss 0.5072813034057617\n",
      "\n",
      "episode 5, val func loss 0.6060347557067871\n",
      "\n",
      "episode 6, val func loss 0.6622089147567749\n",
      "\n",
      "episode 7, val func loss 0.638844907283783\n",
      "\n",
      "episode 8, val func loss 0.5261242985725403\n",
      "\n",
      "episode 9, val func loss 0.606472909450531\n",
      "\n",
      "episode 10, val func loss 0.5937961339950562\n",
      "\n",
      "episode 11, val func loss 0.5396257042884827\n",
      "\n",
      "episode 12, val func loss 0.7494891881942749\n",
      "\n",
      "episode 13, val func loss 0.71458899974823\n",
      "\n",
      "episode 14, val func loss 0.6691592931747437\n",
      "\n",
      "episode 15, val func loss 0.5956292748451233\n",
      "\n",
      "episode 16, val func loss 0.5488191843032837\n",
      "\n",
      "Val func train loss in epoch 7:0.6134484075009823\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7113242745399475\n",
      "\n",
      "episode 2, val func loss 0.692861795425415\n",
      "\n",
      "episode 3, val func loss 0.7189677953720093\n",
      "\n",
      "episode 4, val func loss 0.6301361322402954\n",
      "\n",
      "episode 5, val func loss 0.7470090985298157\n",
      "\n",
      "episode 6, val func loss 0.6508452296257019\n",
      "\n",
      "episode 7, val func loss 0.5884204506874084\n",
      "\n",
      "episode 8, val func loss 0.571879506111145\n",
      "\n",
      "episode 9, val func loss 0.6737159490585327\n",
      "\n",
      "episode 10, val func loss 0.7415555119514465\n",
      "\n",
      "episode 11, val func loss 0.5703868865966797\n",
      "\n",
      "episode 12, val func loss 0.6613509058952332\n",
      "\n",
      "episode 13, val func loss 0.7118765115737915\n",
      "\n",
      "episode 14, val func loss 0.620768666267395\n",
      "\n",
      "episode 15, val func loss 0.5321847200393677\n",
      "\n",
      "episode 16, val func loss 0.5296140313148499\n",
      "\n",
      "Val func train loss in epoch 8:0.6470560915768147\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.5204760432243347\n",
      "\n",
      "episode 2, val func loss 0.6646435260772705\n",
      "\n",
      "episode 3, val func loss 0.5396212935447693\n",
      "\n",
      "episode 4, val func loss 0.6752893924713135\n",
      "\n",
      "episode 5, val func loss 0.6539758443832397\n",
      "\n",
      "episode 6, val func loss 0.58598393201828\n",
      "\n",
      "episode 7, val func loss 0.773051917552948\n",
      "\n",
      "episode 8, val func loss 0.6133986115455627\n",
      "\n",
      "episode 9, val func loss 0.7946497201919556\n",
      "\n",
      "episode 10, val func loss 0.6076433658599854\n",
      "\n",
      "episode 11, val func loss 0.6081662178039551\n",
      "\n",
      "episode 12, val func loss 0.5869157314300537\n",
      "\n",
      "episode 13, val func loss 0.7126994132995605\n",
      "\n",
      "episode 14, val func loss 0.5786175727844238\n",
      "\n",
      "episode 15, val func loss 0.5715474486351013\n",
      "\n",
      "episode 16, val func loss 0.6788150072097778\n",
      "\n",
      "Val func train loss in epoch 9:0.6353434398770332\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7175865173339844\n",
      "\n",
      "episode 2, val func loss 0.6332906484603882\n",
      "\n",
      "episode 3, val func loss 0.5874786972999573\n",
      "\n",
      "episode 4, val func loss 0.7996377944946289\n",
      "\n",
      "episode 5, val func loss 0.5731609463691711\n",
      "\n",
      "episode 6, val func loss 0.772547721862793\n",
      "\n",
      "episode 7, val func loss 0.540310800075531\n",
      "\n",
      "episode 8, val func loss 0.7476446032524109\n",
      "\n",
      "episode 9, val func loss 0.5887904763221741\n",
      "\n",
      "episode 10, val func loss 0.6699934601783752\n",
      "\n",
      "episode 11, val func loss 0.5971983075141907\n",
      "\n",
      "episode 12, val func loss 0.6452847719192505\n",
      "\n",
      "episode 13, val func loss 0.6537956595420837\n",
      "\n",
      "episode 14, val func loss 0.6664854884147644\n",
      "\n",
      "episode 15, val func loss 0.574597179889679\n",
      "\n",
      "episode 16, val func loss 0.6919921636581421\n",
      "\n",
      "Val func train loss in epoch 10:0.6537372022867203\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.681527853012085\n",
      "\n",
      "episode 2, val func loss 0.7559993863105774\n",
      "\n",
      "episode 3, val func loss 0.6529008746147156\n",
      "\n",
      "episode 4, val func loss 0.8015398979187012\n",
      "\n",
      "episode 5, val func loss 0.5973925590515137\n",
      "\n",
      "episode 6, val func loss 0.6447172164916992\n",
      "\n",
      "episode 7, val func loss 0.6394305229187012\n",
      "\n",
      "episode 8, val func loss 0.6119069457054138\n",
      "\n",
      "episode 9, val func loss 0.6014999151229858\n",
      "\n",
      "episode 10, val func loss 0.7442548871040344\n",
      "\n",
      "episode 11, val func loss 0.6476512551307678\n",
      "\n",
      "episode 12, val func loss 0.634111762046814\n",
      "\n",
      "episode 13, val func loss 0.675312876701355\n",
      "\n",
      "episode 14, val func loss 0.5846413969993591\n",
      "\n",
      "episode 15, val func loss 0.6631834506988525\n",
      "\n",
      "episode 16, val func loss 0.5517999529838562\n",
      "\n",
      "Val func train loss in epoch 11:0.6554919220507145\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6602599024772644\n",
      "\n",
      "episode 2, val func loss 0.5502728819847107\n",
      "\n",
      "episode 3, val func loss 0.6256090402603149\n",
      "\n",
      "episode 4, val func loss 0.6117903590202332\n",
      "\n",
      "episode 5, val func loss 0.7037688493728638\n",
      "\n",
      "episode 6, val func loss 0.6518296003341675\n",
      "\n",
      "episode 7, val func loss 0.8204547166824341\n",
      "\n",
      "episode 8, val func loss 0.5954354405403137\n",
      "\n",
      "episode 9, val func loss 0.6079972982406616\n",
      "\n",
      "episode 10, val func loss 0.5936166048049927\n",
      "\n",
      "episode 11, val func loss 0.6403067111968994\n",
      "\n",
      "episode 12, val func loss 0.5732138156890869\n",
      "\n",
      "episode 13, val func loss 0.574225127696991\n",
      "\n",
      "episode 14, val func loss 0.6709443926811218\n",
      "\n",
      "episode 15, val func loss 0.5873749256134033\n",
      "\n",
      "episode 16, val func loss 0.7815430760383606\n",
      "\n",
      "Val func train loss in epoch 12:0.6405401714146137\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6533324122428894\n",
      "\n",
      "episode 2, val func loss 0.6166631579399109\n",
      "\n",
      "episode 3, val func loss 0.5816917419433594\n",
      "\n",
      "episode 4, val func loss 0.6740267276763916\n",
      "\n",
      "episode 5, val func loss 0.5411334037780762\n",
      "\n",
      "episode 6, val func loss 0.6230297088623047\n",
      "\n",
      "episode 7, val func loss 0.64187091588974\n",
      "\n",
      "episode 8, val func loss 0.6440726518630981\n",
      "\n",
      "episode 9, val func loss 0.6733742952346802\n",
      "\n",
      "episode 10, val func loss 0.5935722589492798\n",
      "\n",
      "episode 11, val func loss 0.6227814555168152\n",
      "\n",
      "episode 12, val func loss 0.6585773825645447\n",
      "\n",
      "episode 13, val func loss 0.6172816157341003\n",
      "\n",
      "episode 14, val func loss 0.6913166046142578\n",
      "\n",
      "episode 15, val func loss 0.5678751468658447\n",
      "\n",
      "episode 16, val func loss 0.7148256897926331\n",
      "\n",
      "Val func train loss in epoch 13:0.6322140730917454\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.5208438038825989\n",
      "\n",
      "episode 2, val func loss 0.7344174981117249\n",
      "\n",
      "episode 3, val func loss 0.6898184418678284\n",
      "\n",
      "episode 4, val func loss 0.6489847302436829\n",
      "\n",
      "episode 5, val func loss 0.6926984786987305\n",
      "\n",
      "episode 6, val func loss 0.6679206490516663\n",
      "\n",
      "episode 7, val func loss 0.6884708404541016\n",
      "\n",
      "episode 8, val func loss 0.5767199397087097\n",
      "\n",
      "episode 9, val func loss 0.5718631148338318\n",
      "\n",
      "episode 10, val func loss 0.6781893968582153\n",
      "\n",
      "episode 11, val func loss 0.6980546116828918\n",
      "\n",
      "episode 12, val func loss 0.5649803876876831\n",
      "\n",
      "episode 13, val func loss 0.6670643091201782\n",
      "\n",
      "episode 14, val func loss 0.6074907183647156\n",
      "\n",
      "episode 15, val func loss 0.6526636481285095\n",
      "\n",
      "episode 16, val func loss 0.5820646286010742\n",
      "\n",
      "Val func train loss in epoch 14:0.6401403248310089\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6480751037597656\n",
      "\n",
      "episode 2, val func loss 0.6370052099227905\n",
      "\n",
      "episode 3, val func loss 0.6405869722366333\n",
      "\n",
      "episode 4, val func loss 0.5920750498771667\n",
      "\n",
      "episode 5, val func loss 0.5788722634315491\n",
      "\n",
      "episode 6, val func loss 0.6511603593826294\n",
      "\n",
      "episode 7, val func loss 0.5930580496788025\n",
      "\n",
      "episode 8, val func loss 0.5755056142807007\n",
      "\n",
      "episode 9, val func loss 0.5907781720161438\n",
      "\n",
      "episode 10, val func loss 0.630182683467865\n",
      "\n",
      "episode 11, val func loss 0.5340980887413025\n",
      "\n",
      "episode 12, val func loss 0.6585878133773804\n",
      "\n",
      "episode 13, val func loss 0.5636746883392334\n",
      "\n",
      "episode 14, val func loss 0.6169179081916809\n",
      "\n",
      "episode 15, val func loss 0.8965170383453369\n",
      "\n",
      "episode 16, val func loss 0.6457271575927734\n",
      "\n",
      "Val func train loss in epoch 15:0.6283013857901096\n",
      "***********************TIME WAS 4.918293611208598 min*****************************\n",
      "\n",
      "**********************ROUND 124 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.1637568473815918\n",
      "\n",
      "episode 2, policy loss 1.163758397102356\n",
      "\n",
      "episode 3, policy loss 1.1637582778930664\n",
      "\n",
      "episode 4, policy loss 1.1637582778930664\n",
      "\n",
      "episode 5, policy loss 1.163757562637329\n",
      "\n",
      "episode 6, policy loss 1.1637576818466187\n",
      "\n",
      "episode 7, policy loss 1.1637580394744873\n",
      "\n",
      "episode 8, policy loss 1.1637579202651978\n",
      "\n",
      "episode 9, policy loss 1.1637572050094604\n",
      "\n",
      "episode 10, policy loss 1.163757562637329\n",
      "\n",
      "episode 11, policy loss 1.1637585163116455\n",
      "\n",
      "episode 12, policy loss 1.1637582778930664\n",
      "\n",
      "episode 13, policy loss 1.1637576818466187\n",
      "\n",
      "episode 14, policy loss 1.1637572050094604\n",
      "\n",
      "episode 15, policy loss 1.163758397102356\n",
      "\n",
      "episode 16, policy loss 1.1637582778930664\n",
      "\n",
      "Policy train loss in epoch 0:1.1637578830122948\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.1637578010559082\n",
      "\n",
      "episode 2, policy loss 1.1637568473815918\n",
      "\n",
      "episode 3, policy loss 1.1637579202651978\n",
      "\n",
      "episode 4, policy loss 1.1637567281723022\n",
      "\n",
      "episode 5, policy loss 1.1637579202651978\n",
      "\n",
      "episode 6, policy loss 1.16375732421875\n",
      "\n",
      "episode 7, policy loss 1.1637579202651978\n",
      "\n",
      "episode 8, policy loss 1.1637566089630127\n",
      "\n",
      "episode 9, policy loss 1.1637576818466187\n",
      "\n",
      "episode 10, policy loss 1.1637568473815918\n",
      "\n",
      "episode 11, policy loss 1.1637579202651978\n",
      "\n",
      "episode 12, policy loss 1.1637572050094604\n",
      "\n",
      "episode 13, policy loss 1.1637568473815918\n",
      "\n",
      "episode 14, policy loss 1.163757562637329\n",
      "\n",
      "episode 15, policy loss 1.1637582778930664\n",
      "\n",
      "episode 16, policy loss 1.163756251335144\n",
      "\n",
      "Policy train loss in epoch 1:1.1637573540210724\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.1637576818466187\n",
      "\n",
      "episode 2, policy loss 1.16375732421875\n",
      "\n",
      "episode 3, policy loss 1.163757085800171\n",
      "\n",
      "episode 4, policy loss 1.1637572050094604\n",
      "\n",
      "episode 5, policy loss 1.1637572050094604\n",
      "\n",
      "episode 6, policy loss 1.163756251335144\n",
      "\n",
      "episode 7, policy loss 1.1637566089630127\n",
      "\n",
      "episode 8, policy loss 1.16375732421875\n",
      "\n",
      "episode 9, policy loss 1.1637566089630127\n",
      "\n",
      "episode 10, policy loss 1.1637569665908813\n",
      "\n",
      "episode 11, policy loss 1.1637561321258545\n",
      "\n",
      "episode 12, policy loss 1.1637576818466187\n",
      "\n",
      "episode 13, policy loss 1.1637563705444336\n",
      "\n",
      "episode 14, policy loss 1.1637552976608276\n",
      "\n",
      "episode 15, policy loss 1.1637569665908813\n",
      "\n",
      "episode 16, policy loss 1.1637563705444336\n",
      "\n",
      "Policy train loss in epoch 2:1.1637568175792694\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.1637569665908813\n",
      "\n",
      "episode 2, policy loss 1.1637563705444336\n",
      "\n",
      "episode 3, policy loss 1.1637567281723022\n",
      "\n",
      "episode 4, policy loss 1.163756012916565\n",
      "\n",
      "episode 5, policy loss 1.1637566089630127\n",
      "\n",
      "episode 6, policy loss 1.163756012916565\n",
      "\n",
      "episode 7, policy loss 1.1637566089630127\n",
      "\n",
      "episode 8, policy loss 1.1637563705444336\n",
      "\n",
      "episode 9, policy loss 1.163754940032959\n",
      "\n",
      "episode 10, policy loss 1.1637552976608276\n",
      "\n",
      "episode 11, policy loss 1.163756012916565\n",
      "\n",
      "episode 12, policy loss 1.1637550592422485\n",
      "\n",
      "episode 13, policy loss 1.1637557744979858\n",
      "\n",
      "episode 14, policy loss 1.1637547016143799\n",
      "\n",
      "episode 15, policy loss 1.1637544631958008\n",
      "\n",
      "episode 16, policy loss 1.1637550592422485\n",
      "\n",
      "Policy train loss in epoch 3:1.1637558117508888\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.6612855792045593\n",
      "\n",
      "episode 2, val func loss 0.6260484457015991\n",
      "\n",
      "episode 3, val func loss 0.6278945803642273\n",
      "\n",
      "episode 4, val func loss 0.6584237813949585\n",
      "\n",
      "episode 5, val func loss 0.5541410446166992\n",
      "\n",
      "episode 6, val func loss 0.6688767671585083\n",
      "\n",
      "episode 7, val func loss 0.7310401201248169\n",
      "\n",
      "episode 8, val func loss 0.6514770984649658\n",
      "\n",
      "episode 9, val func loss 0.6231119632720947\n",
      "\n",
      "episode 10, val func loss 0.5902968645095825\n",
      "\n",
      "episode 11, val func loss 0.655315101146698\n",
      "\n",
      "episode 12, val func loss 0.6410661935806274\n",
      "\n",
      "episode 13, val func loss 0.6446588039398193\n",
      "\n",
      "episode 14, val func loss 0.6328814029693604\n",
      "\n",
      "episode 15, val func loss 0.6192737221717834\n",
      "\n",
      "episode 16, val func loss 0.6930490732192993\n",
      "\n",
      "Val func train loss in epoch 0:0.642427533864975\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.7277344465255737\n",
      "\n",
      "episode 2, val func loss 0.6780333518981934\n",
      "\n",
      "episode 3, val func loss 0.5544947385787964\n",
      "\n",
      "episode 4, val func loss 0.6022291779518127\n",
      "\n",
      "episode 5, val func loss 0.5896222591400146\n",
      "\n",
      "episode 6, val func loss 0.5319846272468567\n",
      "\n",
      "episode 7, val func loss 0.6625949144363403\n",
      "\n",
      "episode 8, val func loss 0.7857515811920166\n",
      "\n",
      "episode 9, val func loss 0.6578621864318848\n",
      "\n",
      "episode 10, val func loss 0.5845608711242676\n",
      "\n",
      "episode 11, val func loss 0.5385035872459412\n",
      "\n",
      "episode 12, val func loss 0.7019974589347839\n",
      "\n",
      "episode 13, val func loss 0.6443290710449219\n",
      "\n",
      "episode 14, val func loss 0.5707330703735352\n",
      "\n",
      "episode 15, val func loss 0.6531068682670593\n",
      "\n",
      "episode 16, val func loss 0.609636664390564\n",
      "\n",
      "Val func train loss in epoch 1:0.6308234296739101\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.5437468886375427\n",
      "\n",
      "episode 2, val func loss 0.6398156881332397\n",
      "\n",
      "episode 3, val func loss 0.7015159726142883\n",
      "\n",
      "episode 4, val func loss 0.6153249144554138\n",
      "\n",
      "episode 5, val func loss 0.5355382561683655\n",
      "\n",
      "episode 6, val func loss 0.6596217155456543\n",
      "\n",
      "episode 7, val func loss 0.6756218671798706\n",
      "\n",
      "episode 8, val func loss 0.550961434841156\n",
      "\n",
      "episode 9, val func loss 0.6611272096633911\n",
      "\n",
      "episode 10, val func loss 0.6403272747993469\n",
      "\n",
      "episode 11, val func loss 0.589115560054779\n",
      "\n",
      "episode 12, val func loss 0.6452821493148804\n",
      "\n",
      "episode 13, val func loss 0.5755951404571533\n",
      "\n",
      "episode 14, val func loss 0.6662217378616333\n",
      "\n",
      "episode 15, val func loss 0.6634078025817871\n",
      "\n",
      "episode 16, val func loss 0.6102937459945679\n",
      "\n",
      "Val func train loss in epoch 2:0.6233448348939419\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6380269527435303\n",
      "\n",
      "episode 2, val func loss 0.5951272249221802\n",
      "\n",
      "episode 3, val func loss 0.600418746471405\n",
      "\n",
      "episode 4, val func loss 0.6721000075340271\n",
      "\n",
      "episode 5, val func loss 0.6447643041610718\n",
      "\n",
      "episode 6, val func loss 0.7152253985404968\n",
      "\n",
      "episode 7, val func loss 0.631441056728363\n",
      "\n",
      "episode 8, val func loss 0.7081453204154968\n",
      "\n",
      "episode 9, val func loss 0.6208943724632263\n",
      "\n",
      "episode 10, val func loss 0.6301254630088806\n",
      "\n",
      "episode 11, val func loss 0.6127733588218689\n",
      "\n",
      "episode 12, val func loss 0.6470671892166138\n",
      "\n",
      "episode 13, val func loss 0.6773250699043274\n",
      "\n",
      "episode 14, val func loss 0.6629209518432617\n",
      "\n",
      "episode 15, val func loss 0.6314501762390137\n",
      "\n",
      "episode 16, val func loss 0.6020228862762451\n",
      "\n",
      "Val func train loss in epoch 3:0.6431142799556255\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.72099369764328\n",
      "\n",
      "episode 2, val func loss 0.7082499861717224\n",
      "\n",
      "episode 3, val func loss 0.7420689463615417\n",
      "\n",
      "episode 4, val func loss 0.617415726184845\n",
      "\n",
      "episode 5, val func loss 0.6901431679725647\n",
      "\n",
      "episode 6, val func loss 0.5698820948600769\n",
      "\n",
      "episode 7, val func loss 0.6315543055534363\n",
      "\n",
      "episode 8, val func loss 0.7686203718185425\n",
      "\n",
      "episode 9, val func loss 0.6157314777374268\n",
      "\n",
      "episode 10, val func loss 0.7904853820800781\n",
      "\n",
      "episode 11, val func loss 0.7722049355506897\n",
      "\n",
      "episode 12, val func loss 0.6595713496208191\n",
      "\n",
      "episode 13, val func loss 0.62718266248703\n",
      "\n",
      "episode 14, val func loss 0.6068242192268372\n",
      "\n",
      "episode 15, val func loss 0.6273573040962219\n",
      "\n",
      "episode 16, val func loss 0.6578222513198853\n",
      "\n",
      "Val func train loss in epoch 4:0.6753817424178123\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6842135787010193\n",
      "\n",
      "episode 2, val func loss 0.6306213140487671\n",
      "\n",
      "episode 3, val func loss 0.6691346764564514\n",
      "\n",
      "episode 4, val func loss 0.5957118272781372\n",
      "\n",
      "episode 5, val func loss 0.6207818388938904\n",
      "\n",
      "episode 6, val func loss 0.6210923790931702\n",
      "\n",
      "episode 7, val func loss 0.5980151295661926\n",
      "\n",
      "episode 8, val func loss 0.7068365216255188\n",
      "\n",
      "episode 9, val func loss 0.6317083835601807\n",
      "\n",
      "episode 10, val func loss 0.6141656637191772\n",
      "\n",
      "episode 11, val func loss 0.6444039940834045\n",
      "\n",
      "episode 12, val func loss 0.5780853033065796\n",
      "\n",
      "episode 13, val func loss 0.6277090311050415\n",
      "\n",
      "episode 14, val func loss 0.7258063554763794\n",
      "\n",
      "episode 15, val func loss 0.6498939394950867\n",
      "\n",
      "episode 16, val func loss 0.6177716255187988\n",
      "\n",
      "Val func train loss in epoch 5:0.6384969726204872\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.5265734195709229\n",
      "\n",
      "episode 2, val func loss 0.5883117318153381\n",
      "\n",
      "episode 3, val func loss 0.6713488101959229\n",
      "\n",
      "episode 4, val func loss 0.6790277361869812\n",
      "\n",
      "episode 5, val func loss 0.6515498757362366\n",
      "\n",
      "episode 6, val func loss 0.6238605976104736\n",
      "\n",
      "episode 7, val func loss 0.6110210418701172\n",
      "\n",
      "episode 8, val func loss 0.68741375207901\n",
      "\n",
      "episode 9, val func loss 0.5841693878173828\n",
      "\n",
      "episode 10, val func loss 0.6671645045280457\n",
      "\n",
      "episode 11, val func loss 0.7047742009162903\n",
      "\n",
      "episode 12, val func loss 0.6969617605209351\n",
      "\n",
      "episode 13, val func loss 0.6826715469360352\n",
      "\n",
      "episode 14, val func loss 0.632892370223999\n",
      "\n",
      "episode 15, val func loss 0.607443630695343\n",
      "\n",
      "episode 16, val func loss 0.7511562705039978\n",
      "\n",
      "Val func train loss in epoch 6:0.6478962898254395\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6824601888656616\n",
      "\n",
      "episode 2, val func loss 0.8484201431274414\n",
      "\n",
      "episode 3, val func loss 0.6989465355873108\n",
      "\n",
      "episode 4, val func loss 0.7057968974113464\n",
      "\n",
      "episode 5, val func loss 0.7315014600753784\n",
      "\n",
      "episode 6, val func loss 0.7428562641143799\n",
      "\n",
      "episode 7, val func loss 0.7374196648597717\n",
      "\n",
      "episode 8, val func loss 0.658028781414032\n",
      "\n",
      "episode 9, val func loss 0.7480301260948181\n",
      "\n",
      "episode 10, val func loss 0.6240473985671997\n",
      "\n",
      "episode 11, val func loss 0.692306637763977\n",
      "\n",
      "episode 12, val func loss 0.9340857863426208\n",
      "\n",
      "episode 13, val func loss 0.7292376160621643\n",
      "\n",
      "episode 14, val func loss 0.6941543221473694\n",
      "\n",
      "episode 15, val func loss 0.8676454424858093\n",
      "\n",
      "episode 16, val func loss 0.5715407729148865\n",
      "\n",
      "Val func train loss in epoch 7:0.7291548773646355\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.5891568660736084\n",
      "\n",
      "episode 2, val func loss 0.7936755418777466\n",
      "\n",
      "episode 3, val func loss 0.8481290936470032\n",
      "\n",
      "episode 4, val func loss 0.6974554657936096\n",
      "\n",
      "episode 5, val func loss 0.7425327301025391\n",
      "\n",
      "episode 6, val func loss 0.7146349549293518\n",
      "\n",
      "episode 7, val func loss 0.6795184016227722\n",
      "\n",
      "episode 8, val func loss 0.7230489253997803\n",
      "\n",
      "episode 9, val func loss 0.6627101302146912\n",
      "\n",
      "episode 10, val func loss 0.6976597905158997\n",
      "\n",
      "episode 11, val func loss 0.6326411962509155\n",
      "\n",
      "episode 12, val func loss 0.8195505738258362\n",
      "\n",
      "episode 13, val func loss 0.7252843379974365\n",
      "\n",
      "episode 14, val func loss 0.6315469145774841\n",
      "\n",
      "episode 15, val func loss 0.7533606886863708\n",
      "\n",
      "episode 16, val func loss 0.6541721224784851\n",
      "\n",
      "Val func train loss in epoch 8:0.7103173583745956\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.7405433654785156\n",
      "\n",
      "episode 2, val func loss 0.8034605383872986\n",
      "\n",
      "episode 3, val func loss 0.6684906482696533\n",
      "\n",
      "episode 4, val func loss 0.6042467951774597\n",
      "\n",
      "episode 5, val func loss 0.6804177761077881\n",
      "\n",
      "episode 6, val func loss 0.7909849286079407\n",
      "\n",
      "episode 7, val func loss 0.7304407358169556\n",
      "\n",
      "episode 8, val func loss 0.6519437432289124\n",
      "\n",
      "episode 9, val func loss 0.7193422317504883\n",
      "\n",
      "episode 10, val func loss 0.6678167581558228\n",
      "\n",
      "episode 11, val func loss 0.6151759028434753\n",
      "\n",
      "episode 12, val func loss 0.6187098026275635\n",
      "\n",
      "episode 13, val func loss 0.5996111035346985\n",
      "\n",
      "episode 14, val func loss 0.6736237406730652\n",
      "\n",
      "episode 15, val func loss 0.6353205442428589\n",
      "\n",
      "episode 16, val func loss 0.5562264323234558\n",
      "\n",
      "Val func train loss in epoch 9:0.672272190451622\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6811159253120422\n",
      "\n",
      "episode 2, val func loss 0.5914685726165771\n",
      "\n",
      "episode 3, val func loss 0.6527490019798279\n",
      "\n",
      "episode 4, val func loss 0.7135835886001587\n",
      "\n",
      "episode 5, val func loss 0.5498780012130737\n",
      "\n",
      "episode 6, val func loss 0.6658675670623779\n",
      "\n",
      "episode 7, val func loss 0.6822057962417603\n",
      "\n",
      "episode 8, val func loss 0.6291532516479492\n",
      "\n",
      "episode 9, val func loss 0.5842796564102173\n",
      "\n",
      "episode 10, val func loss 0.6893256902694702\n",
      "\n",
      "episode 11, val func loss 0.6497365832328796\n",
      "\n",
      "episode 12, val func loss 0.6583264470100403\n",
      "\n",
      "episode 13, val func loss 0.6338317394256592\n",
      "\n",
      "episode 14, val func loss 0.5518061518669128\n",
      "\n",
      "episode 15, val func loss 0.6058171987533569\n",
      "\n",
      "episode 16, val func loss 0.5702584385871887\n",
      "\n",
      "Val func train loss in epoch 10:0.6318377256393433\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.632454514503479\n",
      "\n",
      "episode 2, val func loss 0.5852206945419312\n",
      "\n",
      "episode 3, val func loss 0.5713719129562378\n",
      "\n",
      "episode 4, val func loss 0.6976361870765686\n",
      "\n",
      "episode 5, val func loss 0.5931538939476013\n",
      "\n",
      "episode 6, val func loss 0.5894086956977844\n",
      "\n",
      "episode 7, val func loss 0.6226484775543213\n",
      "\n",
      "episode 8, val func loss 0.6361737847328186\n",
      "\n",
      "episode 9, val func loss 0.6521649956703186\n",
      "\n",
      "episode 10, val func loss 0.6320557594299316\n",
      "\n",
      "episode 11, val func loss 0.6527225971221924\n",
      "\n",
      "episode 12, val func loss 0.7174848318099976\n",
      "\n",
      "episode 13, val func loss 0.560053288936615\n",
      "\n",
      "episode 14, val func loss 0.5512910485267639\n",
      "\n",
      "episode 15, val func loss 0.6328660249710083\n",
      "\n",
      "episode 16, val func loss 0.5567851662635803\n",
      "\n",
      "Val func train loss in epoch 11:0.6177182421088219\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6226881146430969\n",
      "\n",
      "episode 2, val func loss 0.5967682003974915\n",
      "\n",
      "episode 3, val func loss 0.6776311993598938\n",
      "\n",
      "episode 4, val func loss 0.6596705317497253\n",
      "\n",
      "episode 5, val func loss 0.6581776142120361\n",
      "\n",
      "episode 6, val func loss 0.6761937737464905\n",
      "\n",
      "episode 7, val func loss 0.7033898830413818\n",
      "\n",
      "episode 8, val func loss 0.6526301503181458\n",
      "\n",
      "episode 9, val func loss 0.6399036049842834\n",
      "\n",
      "episode 10, val func loss 0.7035403251647949\n",
      "\n",
      "episode 11, val func loss 0.7156638503074646\n",
      "\n",
      "episode 12, val func loss 0.7056623101234436\n",
      "\n",
      "episode 13, val func loss 0.6476089358329773\n",
      "\n",
      "episode 14, val func loss 0.6152103543281555\n",
      "\n",
      "episode 15, val func loss 0.6175520420074463\n",
      "\n",
      "episode 16, val func loss 0.6014760732650757\n",
      "\n",
      "Val func train loss in epoch 12:0.6558604352176189\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6834537982940674\n",
      "\n",
      "episode 2, val func loss 0.7099760174751282\n",
      "\n",
      "episode 3, val func loss 0.6672502160072327\n",
      "\n",
      "episode 4, val func loss 0.6428605318069458\n",
      "\n",
      "episode 5, val func loss 0.659302830696106\n",
      "\n",
      "episode 6, val func loss 0.6206192970275879\n",
      "\n",
      "episode 7, val func loss 0.6976945400238037\n",
      "\n",
      "episode 8, val func loss 0.5811164975166321\n",
      "\n",
      "episode 9, val func loss 0.7879953980445862\n",
      "\n",
      "episode 10, val func loss 0.6736896634101868\n",
      "\n",
      "episode 11, val func loss 0.6307262182235718\n",
      "\n",
      "episode 12, val func loss 0.6313025951385498\n",
      "\n",
      "episode 13, val func loss 0.71144700050354\n",
      "\n",
      "episode 14, val func loss 0.618133544921875\n",
      "\n",
      "episode 15, val func loss 0.6065706014633179\n",
      "\n",
      "episode 16, val func loss 0.6805457472801208\n",
      "\n",
      "Val func train loss in epoch 13:0.6626677811145782\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6240131855010986\n",
      "\n",
      "episode 2, val func loss 0.5883730053901672\n",
      "\n",
      "episode 3, val func loss 0.6953192949295044\n",
      "\n",
      "episode 4, val func loss 0.6888249516487122\n",
      "\n",
      "episode 5, val func loss 0.7067578434944153\n",
      "\n",
      "episode 6, val func loss 0.5913363099098206\n",
      "\n",
      "episode 7, val func loss 0.5753619074821472\n",
      "\n",
      "episode 8, val func loss 0.703207790851593\n",
      "\n",
      "episode 9, val func loss 0.7406103014945984\n",
      "\n",
      "episode 10, val func loss 0.6198891997337341\n",
      "\n",
      "episode 11, val func loss 0.6685950756072998\n",
      "\n",
      "episode 12, val func loss 0.6956589221954346\n",
      "\n",
      "episode 13, val func loss 0.5995097160339355\n",
      "\n",
      "episode 14, val func loss 0.6499597430229187\n",
      "\n",
      "episode 15, val func loss 0.5978361368179321\n",
      "\n",
      "episode 16, val func loss 0.7327612042427063\n",
      "\n",
      "Val func train loss in epoch 14:0.6548759117722511\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.7047126889228821\n",
      "\n",
      "episode 2, val func loss 0.5844231843948364\n",
      "\n",
      "episode 3, val func loss 0.6541340351104736\n",
      "\n",
      "episode 4, val func loss 0.6407442092895508\n",
      "\n",
      "episode 5, val func loss 0.6807418465614319\n",
      "\n",
      "episode 6, val func loss 0.5972650647163391\n",
      "\n",
      "episode 7, val func loss 0.573988676071167\n",
      "\n",
      "episode 8, val func loss 0.6868633031845093\n",
      "\n",
      "episode 9, val func loss 0.6654679179191589\n",
      "\n",
      "episode 10, val func loss 0.7146809101104736\n",
      "\n",
      "episode 11, val func loss 0.6319211721420288\n",
      "\n",
      "episode 12, val func loss 0.624511182308197\n",
      "\n",
      "episode 13, val func loss 0.6267424821853638\n",
      "\n",
      "episode 14, val func loss 0.5818402171134949\n",
      "\n",
      "episode 15, val func loss 0.6994662880897522\n",
      "\n",
      "episode 16, val func loss 0.7382352352142334\n",
      "\n",
      "Val func train loss in epoch 15:0.6503586508333683\n",
      "***********************TIME WAS 4.923317650953929 min*****************************\n",
      "\n",
      "**********************ROUND 125 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.1911708116531372\n",
      "\n",
      "episode 2, policy loss 1.191170573234558\n",
      "\n",
      "episode 3, policy loss 1.1911704540252686\n",
      "\n",
      "episode 4, policy loss 1.1911720037460327\n",
      "\n",
      "episode 5, policy loss 1.1911710500717163\n",
      "\n",
      "episode 6, policy loss 1.1911700963974\n",
      "\n",
      "episode 7, policy loss 1.1911712884902954\n",
      "\n",
      "episode 8, policy loss 1.1911711692810059\n",
      "\n",
      "episode 9, policy loss 1.1911704540252686\n",
      "\n",
      "episode 10, policy loss 1.1911700963974\n",
      "\n",
      "episode 11, policy loss 1.1911697387695312\n",
      "\n",
      "episode 12, policy loss 1.1911711692810059\n",
      "\n",
      "episode 13, policy loss 1.1911678314208984\n",
      "\n",
      "episode 14, policy loss 1.1911700963974\n",
      "\n",
      "episode 15, policy loss 1.0429182052612305\n",
      "\n",
      "episode 16, policy loss 1.1911747455596924\n",
      "\n",
      "Policy train loss in epoch 0:1.18190498650074\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.1911792755126953\n",
      "\n",
      "episode 2, policy loss 1.19118070602417\n",
      "\n",
      "episode 3, policy loss 1.1911818981170654\n",
      "\n",
      "episode 4, policy loss 1.19118332862854\n",
      "\n",
      "episode 5, policy loss 1.0306594371795654\n",
      "\n",
      "episode 6, policy loss 1.1911842823028564\n",
      "\n",
      "episode 7, policy loss 1.191184639930725\n",
      "\n",
      "episode 8, policy loss 1.1911845207214355\n",
      "\n",
      "episode 9, policy loss 1.1911849975585938\n",
      "\n",
      "episode 10, policy loss 1.1911849975585938\n",
      "\n",
      "episode 11, policy loss 1.1911851167678833\n",
      "\n",
      "episode 12, policy loss 1.1911855936050415\n",
      "\n",
      "episode 13, policy loss 1.191185712814331\n",
      "\n",
      "episode 14, policy loss 1.1911861896514893\n",
      "\n",
      "episode 15, policy loss 1.1911861896514893\n",
      "\n",
      "episode 16, policy loss 1.1911866664886475\n",
      "\n",
      "Policy train loss in epoch 1:1.1811514720320702\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.1911863088607788\n",
      "\n",
      "episode 2, policy loss 1.191186547279358\n",
      "\n",
      "episode 3, policy loss 1.191186547279358\n",
      "\n",
      "episode 4, policy loss 1.1911866664886475\n",
      "\n",
      "episode 5, policy loss 1.191186785697937\n",
      "\n",
      "episode 6, policy loss 1.1911871433258057\n",
      "\n",
      "episode 7, policy loss 1.191186785697937\n",
      "\n",
      "episode 8, policy loss 1.1911869049072266\n",
      "\n",
      "episode 9, policy loss 1.1911869049072266\n",
      "\n",
      "episode 10, policy loss 1.1911871433258057\n",
      "\n",
      "episode 11, policy loss 1.1911869049072266\n",
      "\n",
      "episode 12, policy loss 1.1911869049072266\n",
      "\n",
      "episode 13, policy loss 1.030662178993225\n",
      "\n",
      "episode 14, policy loss 1.1911870241165161\n",
      "\n",
      "episode 15, policy loss 1.1911869049072266\n",
      "\n",
      "episode 16, policy loss 1.1911869049072266\n",
      "\n",
      "Policy train loss in epoch 2:1.1811540350317955\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.1911869049072266\n",
      "\n",
      "episode 2, policy loss 1.1911869049072266\n",
      "\n",
      "episode 3, policy loss 1.030662178993225\n",
      "\n",
      "episode 4, policy loss 1.1911871433258057\n",
      "\n",
      "episode 5, policy loss 1.1911870241165161\n",
      "\n",
      "episode 6, policy loss 1.1911870241165161\n",
      "\n",
      "episode 7, policy loss 1.1911869049072266\n",
      "\n",
      "episode 8, policy loss 1.1911869049072266\n",
      "\n",
      "episode 9, policy loss 1.1911870241165161\n",
      "\n",
      "episode 10, policy loss 1.1911869049072266\n",
      "\n",
      "episode 11, policy loss 1.1911870241165161\n",
      "\n",
      "episode 12, policy loss 1.1911871433258057\n",
      "\n",
      "episode 13, policy loss 1.1911869049072266\n",
      "\n",
      "episode 14, policy loss 1.1911870241165161\n",
      "\n",
      "episode 15, policy loss 1.1911870241165161\n",
      "\n",
      "episode 16, policy loss 1.1911869049072266\n",
      "\n",
      "Policy train loss in epoch 3:1.1811541840434074\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.6656238436698914\n",
      "\n",
      "episode 2, val func loss 0.6588168144226074\n",
      "\n",
      "episode 3, val func loss 0.592210590839386\n",
      "\n",
      "episode 4, val func loss 0.5765922665596008\n",
      "\n",
      "episode 5, val func loss 0.6678460836410522\n",
      "\n",
      "episode 6, val func loss 0.5850875377655029\n",
      "\n",
      "episode 7, val func loss 0.6606364250183105\n",
      "\n",
      "episode 8, val func loss 0.7113975286483765\n",
      "\n",
      "episode 9, val func loss 0.6725456714630127\n",
      "\n",
      "episode 10, val func loss 0.5877098441123962\n",
      "\n",
      "episode 11, val func loss 0.559744656085968\n",
      "\n",
      "episode 12, val func loss 0.6597086787223816\n",
      "\n",
      "episode 13, val func loss 0.6404274106025696\n",
      "\n",
      "episode 14, val func loss 0.7085310816764832\n",
      "\n",
      "episode 15, val func loss 0.588106632232666\n",
      "\n",
      "episode 16, val func loss 0.5795945525169373\n",
      "\n",
      "Val func train loss in epoch 0:0.6321612261235714\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.553046703338623\n",
      "\n",
      "episode 2, val func loss 0.6936371922492981\n",
      "\n",
      "episode 3, val func loss 0.6710282564163208\n",
      "\n",
      "episode 4, val func loss 0.6601881980895996\n",
      "\n",
      "episode 5, val func loss 0.7014020681381226\n",
      "\n",
      "episode 6, val func loss 0.5934751629829407\n",
      "\n",
      "episode 7, val func loss 0.6481779217720032\n",
      "\n",
      "episode 8, val func loss 0.6397620439529419\n",
      "\n",
      "episode 9, val func loss 0.5996602773666382\n",
      "\n",
      "episode 10, val func loss 0.689119279384613\n",
      "\n",
      "episode 11, val func loss 0.7646925449371338\n",
      "\n",
      "episode 12, val func loss 0.6266379356384277\n",
      "\n",
      "episode 13, val func loss 0.6672373414039612\n",
      "\n",
      "episode 14, val func loss 0.604106068611145\n",
      "\n",
      "episode 15, val func loss 0.7304930686950684\n",
      "\n",
      "episode 16, val func loss 0.6738505363464355\n",
      "\n",
      "Val func train loss in epoch 1:0.6572821624577045\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.7080709934234619\n",
      "\n",
      "episode 2, val func loss 0.6102097630500793\n",
      "\n",
      "episode 3, val func loss 0.6241709589958191\n",
      "\n",
      "episode 4, val func loss 0.6089309453964233\n",
      "\n",
      "episode 5, val func loss 0.7023738622665405\n",
      "\n",
      "episode 6, val func loss 0.6860345005989075\n",
      "\n",
      "episode 7, val func loss 0.9426908493041992\n",
      "\n",
      "episode 8, val func loss 0.6483536958694458\n",
      "\n",
      "episode 9, val func loss 0.6793875098228455\n",
      "\n",
      "episode 10, val func loss 0.5960056781768799\n",
      "\n",
      "episode 11, val func loss 0.6276524066925049\n",
      "\n",
      "episode 12, val func loss 0.6544383764266968\n",
      "\n",
      "episode 13, val func loss 0.6821362376213074\n",
      "\n",
      "episode 14, val func loss 0.6768086552619934\n",
      "\n",
      "episode 15, val func loss 0.6896967887878418\n",
      "\n",
      "episode 16, val func loss 0.775169312953949\n",
      "\n",
      "Val func train loss in epoch 2:0.682008158415556\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6548265814781189\n",
      "\n",
      "episode 2, val func loss 0.6232960820198059\n",
      "\n",
      "episode 3, val func loss 0.6907521486282349\n",
      "\n",
      "episode 4, val func loss 0.6008738875389099\n",
      "\n",
      "episode 5, val func loss 0.5574375987052917\n",
      "\n",
      "episode 6, val func loss 0.5825679898262024\n",
      "\n",
      "episode 7, val func loss 0.6934693455696106\n",
      "\n",
      "episode 8, val func loss 0.5685619711875916\n",
      "\n",
      "episode 9, val func loss 0.6383763551712036\n",
      "\n",
      "episode 10, val func loss 0.5840140581130981\n",
      "\n",
      "episode 11, val func loss 0.5819544196128845\n",
      "\n",
      "episode 12, val func loss 0.7188463807106018\n",
      "\n",
      "episode 13, val func loss 0.6156548857688904\n",
      "\n",
      "episode 14, val func loss 0.6499202847480774\n",
      "\n",
      "episode 15, val func loss 0.6198186278343201\n",
      "\n",
      "episode 16, val func loss 0.6798756122589111\n",
      "\n",
      "Val func train loss in epoch 3:0.6287653893232346\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6872442364692688\n",
      "\n",
      "episode 2, val func loss 0.6358110904693604\n",
      "\n",
      "episode 3, val func loss 0.6700136661529541\n",
      "\n",
      "episode 4, val func loss 0.6610667705535889\n",
      "\n",
      "episode 5, val func loss 0.6886221766471863\n",
      "\n",
      "episode 6, val func loss 0.6724391579627991\n",
      "\n",
      "episode 7, val func loss 0.5521326661109924\n",
      "\n",
      "episode 8, val func loss 0.6563317179679871\n",
      "\n",
      "episode 9, val func loss 0.6883082985877991\n",
      "\n",
      "episode 10, val func loss 0.6194877624511719\n",
      "\n",
      "episode 11, val func loss 0.6329064965248108\n",
      "\n",
      "episode 12, val func loss 0.7472540736198425\n",
      "\n",
      "episode 13, val func loss 0.6414082646369934\n",
      "\n",
      "episode 14, val func loss 0.7470388412475586\n",
      "\n",
      "episode 15, val func loss 0.7234248518943787\n",
      "\n",
      "episode 16, val func loss 0.6784799695014954\n",
      "\n",
      "Val func train loss in epoch 4:0.6688731275498867\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.5929896235466003\n",
      "\n",
      "episode 2, val func loss 0.6104508638381958\n",
      "\n",
      "episode 3, val func loss 0.6515008211135864\n",
      "\n",
      "episode 4, val func loss 0.7802254557609558\n",
      "\n",
      "episode 5, val func loss 0.6652659773826599\n",
      "\n",
      "episode 6, val func loss 0.5910919308662415\n",
      "\n",
      "episode 7, val func loss 0.6689706444740295\n",
      "\n",
      "episode 8, val func loss 0.5822184085845947\n",
      "\n",
      "episode 9, val func loss 0.7005348205566406\n",
      "\n",
      "episode 10, val func loss 0.7665771842002869\n",
      "\n",
      "episode 11, val func loss 0.5599673986434937\n",
      "\n",
      "episode 12, val func loss 0.6711991429328918\n",
      "\n",
      "episode 13, val func loss 0.6837036609649658\n",
      "\n",
      "episode 14, val func loss 0.6944188475608826\n",
      "\n",
      "episode 15, val func loss 0.6234923005104065\n",
      "\n",
      "episode 16, val func loss 0.633740246295929\n",
      "\n",
      "Val func train loss in epoch 5:0.6547717079520226\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6824409365653992\n",
      "\n",
      "episode 2, val func loss 0.6044213175773621\n",
      "\n",
      "episode 3, val func loss 0.6862277388572693\n",
      "\n",
      "episode 4, val func loss 0.6134779453277588\n",
      "\n",
      "episode 5, val func loss 0.6989362835884094\n",
      "\n",
      "episode 6, val func loss 0.6880460381507874\n",
      "\n",
      "episode 7, val func loss 0.557024359703064\n",
      "\n",
      "episode 8, val func loss 0.5817402005195618\n",
      "\n",
      "episode 9, val func loss 0.6151830554008484\n",
      "\n",
      "episode 10, val func loss 0.6131414175033569\n",
      "\n",
      "episode 11, val func loss 0.668473482131958\n",
      "\n",
      "episode 12, val func loss 0.7161670327186584\n",
      "\n",
      "episode 13, val func loss 0.726019024848938\n",
      "\n",
      "episode 14, val func loss 0.6183310747146606\n",
      "\n",
      "episode 15, val func loss 0.7378659844398499\n",
      "\n",
      "episode 16, val func loss 0.6078736186027527\n",
      "\n",
      "Val func train loss in epoch 6:0.6509605944156647\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6108859777450562\n",
      "\n",
      "episode 2, val func loss 0.6288715600967407\n",
      "\n",
      "episode 3, val func loss 0.6430326700210571\n",
      "\n",
      "episode 4, val func loss 0.6714326739311218\n",
      "\n",
      "episode 5, val func loss 0.5972630381584167\n",
      "\n",
      "episode 6, val func loss 0.6676202416419983\n",
      "\n",
      "episode 7, val func loss 0.5234637260437012\n",
      "\n",
      "episode 8, val func loss 0.692887544631958\n",
      "\n",
      "episode 9, val func loss 0.62256920337677\n",
      "\n",
      "episode 10, val func loss 0.6027105450630188\n",
      "\n",
      "episode 11, val func loss 0.6416467428207397\n",
      "\n",
      "episode 12, val func loss 0.5845729112625122\n",
      "\n",
      "episode 13, val func loss 0.6426799893379211\n",
      "\n",
      "episode 14, val func loss 0.5660321712493896\n",
      "\n",
      "episode 15, val func loss 0.7070536613464355\n",
      "\n",
      "episode 16, val func loss 0.5900807976722717\n",
      "\n",
      "Val func train loss in epoch 7:0.6245502158999443\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6067395806312561\n",
      "\n",
      "episode 2, val func loss 0.6861422657966614\n",
      "\n",
      "episode 3, val func loss 0.7636411190032959\n",
      "\n",
      "episode 4, val func loss 0.6516419053077698\n",
      "\n",
      "episode 5, val func loss 0.6209028959274292\n",
      "\n",
      "episode 6, val func loss 0.6966934204101562\n",
      "\n",
      "episode 7, val func loss 0.6700778007507324\n",
      "\n",
      "episode 8, val func loss 0.5989354252815247\n",
      "\n",
      "episode 9, val func loss 0.6503745317459106\n",
      "\n",
      "episode 10, val func loss 0.6607823371887207\n",
      "\n",
      "episode 11, val func loss 0.6102196574211121\n",
      "\n",
      "episode 12, val func loss 0.7104311585426331\n",
      "\n",
      "episode 13, val func loss 0.7060142159461975\n",
      "\n",
      "episode 14, val func loss 0.6278104186058044\n",
      "\n",
      "episode 15, val func loss 0.7002571821212769\n",
      "\n",
      "episode 16, val func loss 0.6404741406440735\n",
      "\n",
      "Val func train loss in epoch 8:0.6625711284577847\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6568737626075745\n",
      "\n",
      "episode 2, val func loss 0.6355100274085999\n",
      "\n",
      "episode 3, val func loss 0.5975162386894226\n",
      "\n",
      "episode 4, val func loss 0.6209757328033447\n",
      "\n",
      "episode 5, val func loss 0.6493436098098755\n",
      "\n",
      "episode 6, val func loss 0.7084987759590149\n",
      "\n",
      "episode 7, val func loss 0.656617283821106\n",
      "\n",
      "episode 8, val func loss 0.666627824306488\n",
      "\n",
      "episode 9, val func loss 0.5801888704299927\n",
      "\n",
      "episode 10, val func loss 0.6869497895240784\n",
      "\n",
      "episode 11, val func loss 0.627170741558075\n",
      "\n",
      "episode 12, val func loss 0.7351071238517761\n",
      "\n",
      "episode 13, val func loss 0.6782556772232056\n",
      "\n",
      "episode 14, val func loss 0.6118174195289612\n",
      "\n",
      "episode 15, val func loss 0.8109060525894165\n",
      "\n",
      "episode 16, val func loss 0.6468880772590637\n",
      "\n",
      "Val func train loss in epoch 9:0.6605779379606247\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.5910358428955078\n",
      "\n",
      "episode 2, val func loss 0.6786121129989624\n",
      "\n",
      "episode 3, val func loss 0.7038040161132812\n",
      "\n",
      "episode 4, val func loss 0.6266142129898071\n",
      "\n",
      "episode 5, val func loss 0.7905620336532593\n",
      "\n",
      "episode 6, val func loss 0.6718910336494446\n",
      "\n",
      "episode 7, val func loss 0.6172917485237122\n",
      "\n",
      "episode 8, val func loss 0.5496679544448853\n",
      "\n",
      "episode 9, val func loss 0.5668989419937134\n",
      "\n",
      "episode 10, val func loss 0.6324896812438965\n",
      "\n",
      "episode 11, val func loss 0.7206268310546875\n",
      "\n",
      "episode 12, val func loss 0.5909531116485596\n",
      "\n",
      "episode 13, val func loss 0.5773184299468994\n",
      "\n",
      "episode 14, val func loss 0.5630425810813904\n",
      "\n",
      "episode 15, val func loss 0.6985620260238647\n",
      "\n",
      "episode 16, val func loss 0.5868639945983887\n",
      "\n",
      "Val func train loss in epoch 10:0.6353896595537663\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6397020816802979\n",
      "\n",
      "episode 2, val func loss 0.5205824971199036\n",
      "\n",
      "episode 3, val func loss 0.6500759124755859\n",
      "\n",
      "episode 4, val func loss 0.6425049304962158\n",
      "\n",
      "episode 5, val func loss 0.5874087810516357\n",
      "\n",
      "episode 6, val func loss 0.7463889718055725\n",
      "\n",
      "episode 7, val func loss 0.7024241089820862\n",
      "\n",
      "episode 8, val func loss 0.6003248691558838\n",
      "\n",
      "episode 9, val func loss 0.5922985076904297\n",
      "\n",
      "episode 10, val func loss 0.5858082175254822\n",
      "\n",
      "episode 11, val func loss 0.6346591114997864\n",
      "\n",
      "episode 12, val func loss 0.6440054774284363\n",
      "\n",
      "episode 13, val func loss 0.62449049949646\n",
      "\n",
      "episode 14, val func loss 0.7563900351524353\n",
      "\n",
      "episode 15, val func loss 0.5794759392738342\n",
      "\n",
      "episode 16, val func loss 0.7357152700424194\n",
      "\n",
      "Val func train loss in epoch 11:0.640140950679779\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6857107281684875\n",
      "\n",
      "episode 2, val func loss 0.7050647139549255\n",
      "\n",
      "episode 3, val func loss 0.6520605087280273\n",
      "\n",
      "episode 4, val func loss 0.6015616655349731\n",
      "\n",
      "episode 5, val func loss 0.6005656123161316\n",
      "\n",
      "episode 6, val func loss 0.6620580554008484\n",
      "\n",
      "episode 7, val func loss 0.6669533848762512\n",
      "\n",
      "episode 8, val func loss 0.6025797724723816\n",
      "\n",
      "episode 9, val func loss 0.6519327163696289\n",
      "\n",
      "episode 10, val func loss 0.6911830902099609\n",
      "\n",
      "episode 11, val func loss 0.6145570278167725\n",
      "\n",
      "episode 12, val func loss 0.7127536535263062\n",
      "\n",
      "episode 13, val func loss 0.641074538230896\n",
      "\n",
      "episode 14, val func loss 0.6892487406730652\n",
      "\n",
      "episode 15, val func loss 0.6240641474723816\n",
      "\n",
      "episode 16, val func loss 0.6226942539215088\n",
      "\n",
      "Val func train loss in epoch 12:0.6515039131045341\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.644024133682251\n",
      "\n",
      "episode 2, val func loss 0.6403415203094482\n",
      "\n",
      "episode 3, val func loss 0.626679539680481\n",
      "\n",
      "episode 4, val func loss 0.6361573934555054\n",
      "\n",
      "episode 5, val func loss 0.6578275561332703\n",
      "\n",
      "episode 6, val func loss 0.6264032125473022\n",
      "\n",
      "episode 7, val func loss 0.7036526203155518\n",
      "\n",
      "episode 8, val func loss 0.6459721326828003\n",
      "\n",
      "episode 9, val func loss 0.7400591373443604\n",
      "\n",
      "episode 10, val func loss 0.7567195892333984\n",
      "\n",
      "episode 11, val func loss 0.5410085916519165\n",
      "\n",
      "episode 12, val func loss 0.6287926435470581\n",
      "\n",
      "episode 13, val func loss 0.6305623650550842\n",
      "\n",
      "episode 14, val func loss 0.7017408013343811\n",
      "\n",
      "episode 15, val func loss 0.5889245271682739\n",
      "\n",
      "episode 16, val func loss 0.6182133555412292\n",
      "\n",
      "Val func train loss in epoch 13:0.6491924449801445\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6720109581947327\n",
      "\n",
      "episode 2, val func loss 0.6516998410224915\n",
      "\n",
      "episode 3, val func loss 0.6500574946403503\n",
      "\n",
      "episode 4, val func loss 0.6680867075920105\n",
      "\n",
      "episode 5, val func loss 0.5933405756950378\n",
      "\n",
      "episode 6, val func loss 0.6375780701637268\n",
      "\n",
      "episode 7, val func loss 0.5915493369102478\n",
      "\n",
      "episode 8, val func loss 0.7478768825531006\n",
      "\n",
      "episode 9, val func loss 0.5764563083648682\n",
      "\n",
      "episode 10, val func loss 0.5544488430023193\n",
      "\n",
      "episode 11, val func loss 0.6000764966011047\n",
      "\n",
      "episode 12, val func loss 0.6023088097572327\n",
      "\n",
      "episode 13, val func loss 0.6401360034942627\n",
      "\n",
      "episode 14, val func loss 0.5746857523918152\n",
      "\n",
      "episode 15, val func loss 0.6929894685745239\n",
      "\n",
      "episode 16, val func loss 0.5525652766227722\n",
      "\n",
      "Val func train loss in epoch 14:0.6253666765987873\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6260349154472351\n",
      "\n",
      "episode 2, val func loss 0.5852201581001282\n",
      "\n",
      "episode 3, val func loss 0.6404393315315247\n",
      "\n",
      "episode 4, val func loss 0.5889506340026855\n",
      "\n",
      "episode 5, val func loss 0.5340608954429626\n",
      "\n",
      "episode 6, val func loss 0.6171907186508179\n",
      "\n",
      "episode 7, val func loss 0.6326015591621399\n",
      "\n",
      "episode 8, val func loss 0.663600504398346\n",
      "\n",
      "episode 9, val func loss 0.7280610203742981\n",
      "\n",
      "episode 10, val func loss 0.5044500231742859\n",
      "\n",
      "episode 11, val func loss 0.5851069688796997\n",
      "\n",
      "episode 12, val func loss 0.7463042140007019\n",
      "\n",
      "episode 13, val func loss 0.6529659628868103\n",
      "\n",
      "episode 14, val func loss 0.7152690887451172\n",
      "\n",
      "episode 15, val func loss 0.7273416519165039\n",
      "\n",
      "episode 16, val func loss 0.6239354014396667\n",
      "\n",
      "Val func train loss in epoch 15:0.6357208155095577\n",
      "***********************TIME WAS 4.921091028054556 min*****************************\n",
      "\n",
      "**********************ROUND 126 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.0250083208084106\n",
      "\n",
      "episode 2, policy loss 1.0250084400177002\n",
      "\n",
      "episode 3, policy loss 1.0250084400177002\n",
      "\n",
      "episode 4, policy loss 1.0250084400177002\n",
      "\n",
      "episode 5, policy loss 1.0250084400177002\n",
      "\n",
      "episode 6, policy loss 1.0250084400177002\n",
      "\n",
      "episode 7, policy loss 1.0250083208084106\n",
      "\n",
      "episode 8, policy loss 1.0250084400177002\n",
      "\n",
      "episode 9, policy loss 1.0250084400177002\n",
      "\n",
      "episode 10, policy loss 1.0250083208084106\n",
      "\n",
      "episode 11, policy loss 1.0250083208084106\n",
      "\n",
      "episode 12, policy loss 1.0250084400177002\n",
      "\n",
      "episode 13, policy loss 1.0250084400177002\n",
      "\n",
      "episode 14, policy loss 1.0250083208084106\n",
      "\n",
      "episode 15, policy loss 1.0250083208084106\n",
      "\n",
      "episode 16, policy loss 1.0250084400177002\n",
      "\n",
      "Policy train loss in epoch 0:1.0250083953142166\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.0250084400177002\n",
      "\n",
      "episode 2, policy loss 1.0250084400177002\n",
      "\n",
      "episode 3, policy loss 1.0250083208084106\n",
      "\n",
      "episode 4, policy loss 1.0250084400177002\n",
      "\n",
      "episode 5, policy loss 1.0250084400177002\n",
      "\n",
      "episode 6, policy loss 1.0250084400177002\n",
      "\n",
      "episode 7, policy loss 1.0250084400177002\n",
      "\n",
      "episode 8, policy loss 1.0250084400177002\n",
      "\n",
      "episode 9, policy loss 1.0250084400177002\n",
      "\n",
      "episode 10, policy loss 1.0250084400177002\n",
      "\n",
      "episode 11, policy loss 1.0250084400177002\n",
      "\n",
      "episode 12, policy loss 1.0250083208084106\n",
      "\n",
      "episode 13, policy loss 1.0250084400177002\n",
      "\n",
      "episode 14, policy loss 1.0250084400177002\n",
      "\n",
      "episode 15, policy loss 1.0250083208084106\n",
      "\n",
      "episode 16, policy loss 1.0250084400177002\n",
      "\n",
      "Policy train loss in epoch 1:1.0250084176659584\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.0250084400177002\n",
      "\n",
      "episode 2, policy loss 1.0250084400177002\n",
      "\n",
      "episode 3, policy loss 1.0250083208084106\n",
      "\n",
      "episode 4, policy loss 1.0250083208084106\n",
      "\n",
      "episode 5, policy loss 1.0250084400177002\n",
      "\n",
      "episode 6, policy loss 1.0250084400177002\n",
      "\n",
      "episode 7, policy loss 1.0250084400177002\n",
      "\n",
      "episode 8, policy loss 1.0250084400177002\n",
      "\n",
      "episode 9, policy loss 1.0250083208084106\n",
      "\n",
      "episode 10, policy loss 1.0250083208084106\n",
      "\n",
      "episode 11, policy loss 1.0250084400177002\n",
      "\n",
      "episode 12, policy loss 1.0250084400177002\n",
      "\n",
      "episode 13, policy loss 1.0250084400177002\n",
      "\n",
      "episode 14, policy loss 1.0250084400177002\n",
      "\n",
      "episode 15, policy loss 1.0250084400177002\n",
      "\n",
      "episode 16, policy loss 1.0250083208084106\n",
      "\n",
      "Policy train loss in epoch 2:1.0250084027647972\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.0250084400177002\n",
      "\n",
      "episode 2, policy loss 1.0250084400177002\n",
      "\n",
      "episode 3, policy loss 1.0250084400177002\n",
      "\n",
      "episode 4, policy loss 1.0250084400177002\n",
      "\n",
      "episode 5, policy loss 1.0250084400177002\n",
      "\n",
      "episode 6, policy loss 1.0250083208084106\n",
      "\n",
      "episode 7, policy loss 1.0250083208084106\n",
      "\n",
      "episode 8, policy loss 1.0250084400177002\n",
      "\n",
      "episode 9, policy loss 1.0250083208084106\n",
      "\n",
      "episode 10, policy loss 1.0250084400177002\n",
      "\n",
      "episode 11, policy loss 1.0250084400177002\n",
      "\n",
      "episode 12, policy loss 1.0250084400177002\n",
      "\n",
      "episode 13, policy loss 1.0250084400177002\n",
      "\n",
      "episode 14, policy loss 1.0250083208084106\n",
      "\n",
      "episode 15, policy loss 1.0250083208084106\n",
      "\n",
      "episode 16, policy loss 1.0250084400177002\n",
      "\n",
      "Policy train loss in epoch 3:1.0250084027647972\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.6769492626190186\n",
      "\n",
      "episode 2, val func loss 0.6638386249542236\n",
      "\n",
      "episode 3, val func loss 0.5745861530303955\n",
      "\n",
      "episode 4, val func loss 0.5812956690788269\n",
      "\n",
      "episode 5, val func loss 0.7433465123176575\n",
      "\n",
      "episode 6, val func loss 0.5971167683601379\n",
      "\n",
      "episode 7, val func loss 0.6942880749702454\n",
      "\n",
      "episode 8, val func loss 0.49743661284446716\n",
      "\n",
      "episode 9, val func loss 0.6821432113647461\n",
      "\n",
      "episode 10, val func loss 0.7273706197738647\n",
      "\n",
      "episode 11, val func loss 0.6212378740310669\n",
      "\n",
      "episode 12, val func loss 0.593568742275238\n",
      "\n",
      "episode 13, val func loss 0.6425796151161194\n",
      "\n",
      "episode 14, val func loss 0.6388124823570251\n",
      "\n",
      "episode 15, val func loss 0.6001039147377014\n",
      "\n",
      "episode 16, val func loss 0.6253133416175842\n",
      "\n",
      "Val func train loss in epoch 0:0.6349992174655199\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.780667781829834\n",
      "\n",
      "episode 2, val func loss 0.610194206237793\n",
      "\n",
      "episode 3, val func loss 0.5215355157852173\n",
      "\n",
      "episode 4, val func loss 0.630430281162262\n",
      "\n",
      "episode 5, val func loss 0.640545129776001\n",
      "\n",
      "episode 6, val func loss 0.5915483236312866\n",
      "\n",
      "episode 7, val func loss 0.5623456835746765\n",
      "\n",
      "episode 8, val func loss 0.6470341682434082\n",
      "\n",
      "episode 9, val func loss 0.6839274168014526\n",
      "\n",
      "episode 10, val func loss 0.5291544795036316\n",
      "\n",
      "episode 11, val func loss 0.6828222870826721\n",
      "\n",
      "episode 12, val func loss 0.5806824564933777\n",
      "\n",
      "episode 13, val func loss 0.7186499238014221\n",
      "\n",
      "episode 14, val func loss 0.6146461963653564\n",
      "\n",
      "episode 15, val func loss 0.6298704147338867\n",
      "\n",
      "episode 16, val func loss 0.5169255137443542\n",
      "\n",
      "Val func train loss in epoch 1:0.6213112361729145\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6190414428710938\n",
      "\n",
      "episode 2, val func loss 0.6015906929969788\n",
      "\n",
      "episode 3, val func loss 0.667258083820343\n",
      "\n",
      "episode 4, val func loss 0.5838736891746521\n",
      "\n",
      "episode 5, val func loss 0.6029972434043884\n",
      "\n",
      "episode 6, val func loss 0.6139264702796936\n",
      "\n",
      "episode 7, val func loss 0.7308594584465027\n",
      "\n",
      "episode 8, val func loss 0.6419141888618469\n",
      "\n",
      "episode 9, val func loss 0.7780121564865112\n",
      "\n",
      "episode 10, val func loss 0.6857706904411316\n",
      "\n",
      "episode 11, val func loss 0.6046911478042603\n",
      "\n",
      "episode 12, val func loss 0.6997901201248169\n",
      "\n",
      "episode 13, val func loss 0.6407158374786377\n",
      "\n",
      "episode 14, val func loss 0.5975133180618286\n",
      "\n",
      "episode 15, val func loss 0.6447597146034241\n",
      "\n",
      "episode 16, val func loss 0.6466297507286072\n",
      "\n",
      "Val func train loss in epoch 2:0.6474590003490448\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.5751392841339111\n",
      "\n",
      "episode 2, val func loss 0.5464797616004944\n",
      "\n",
      "episode 3, val func loss 0.6893057227134705\n",
      "\n",
      "episode 4, val func loss 0.6348752379417419\n",
      "\n",
      "episode 5, val func loss 0.755803108215332\n",
      "\n",
      "episode 6, val func loss 0.6599431037902832\n",
      "\n",
      "episode 7, val func loss 0.5978581309318542\n",
      "\n",
      "episode 8, val func loss 0.6800022125244141\n",
      "\n",
      "episode 9, val func loss 0.6061424612998962\n",
      "\n",
      "episode 10, val func loss 0.67447429895401\n",
      "\n",
      "episode 11, val func loss 0.6776854395866394\n",
      "\n",
      "episode 12, val func loss 0.5378556847572327\n",
      "\n",
      "episode 13, val func loss 0.6161491870880127\n",
      "\n",
      "episode 14, val func loss 0.6507478952407837\n",
      "\n",
      "episode 15, val func loss 0.658464789390564\n",
      "\n",
      "episode 16, val func loss 0.6521097421646118\n",
      "\n",
      "Val func train loss in epoch 3:0.6383147537708282\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6471372246742249\n",
      "\n",
      "episode 2, val func loss 0.547898530960083\n",
      "\n",
      "episode 3, val func loss 0.6505303382873535\n",
      "\n",
      "episode 4, val func loss 0.5956605672836304\n",
      "\n",
      "episode 5, val func loss 0.6708784103393555\n",
      "\n",
      "episode 6, val func loss 0.6776283979415894\n",
      "\n",
      "episode 7, val func loss 0.7784989476203918\n",
      "\n",
      "episode 8, val func loss 0.7520276308059692\n",
      "\n",
      "episode 9, val func loss 0.6771100163459778\n",
      "\n",
      "episode 10, val func loss 0.673412561416626\n",
      "\n",
      "episode 11, val func loss 0.613476574420929\n",
      "\n",
      "episode 12, val func loss 0.6826983690261841\n",
      "\n",
      "episode 13, val func loss 0.6498954892158508\n",
      "\n",
      "episode 14, val func loss 0.7104672193527222\n",
      "\n",
      "episode 15, val func loss 0.5556273460388184\n",
      "\n",
      "episode 16, val func loss 0.7154354453086853\n",
      "\n",
      "Val func train loss in epoch 4:0.6623989418148994\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.576339066028595\n",
      "\n",
      "episode 2, val func loss 0.6110361218452454\n",
      "\n",
      "episode 3, val func loss 0.6368610858917236\n",
      "\n",
      "episode 4, val func loss 0.7272853851318359\n",
      "\n",
      "episode 5, val func loss 0.617912232875824\n",
      "\n",
      "episode 6, val func loss 0.5822412967681885\n",
      "\n",
      "episode 7, val func loss 0.7197154760360718\n",
      "\n",
      "episode 8, val func loss 0.5571118593215942\n",
      "\n",
      "episode 9, val func loss 0.5728046894073486\n",
      "\n",
      "episode 10, val func loss 0.6335290670394897\n",
      "\n",
      "episode 11, val func loss 0.5892073512077332\n",
      "\n",
      "episode 12, val func loss 0.6007624864578247\n",
      "\n",
      "episode 13, val func loss 0.5824243426322937\n",
      "\n",
      "episode 14, val func loss 0.7293850779533386\n",
      "\n",
      "episode 15, val func loss 0.6679570078849792\n",
      "\n",
      "episode 16, val func loss 0.6351334452629089\n",
      "\n",
      "Val func train loss in epoch 5:0.6274816244840622\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6137452721595764\n",
      "\n",
      "episode 2, val func loss 0.7505425214767456\n",
      "\n",
      "episode 3, val func loss 0.6669928431510925\n",
      "\n",
      "episode 4, val func loss 0.5664074420928955\n",
      "\n",
      "episode 5, val func loss 0.5983321070671082\n",
      "\n",
      "episode 6, val func loss 0.6155295372009277\n",
      "\n",
      "episode 7, val func loss 0.595456063747406\n",
      "\n",
      "episode 8, val func loss 0.660442054271698\n",
      "\n",
      "episode 9, val func loss 0.7114049792289734\n",
      "\n",
      "episode 10, val func loss 0.5640738010406494\n",
      "\n",
      "episode 11, val func loss 0.7038065791130066\n",
      "\n",
      "episode 12, val func loss 0.6234391927719116\n",
      "\n",
      "episode 13, val func loss 0.7414670586585999\n",
      "\n",
      "episode 14, val func loss 0.6261484622955322\n",
      "\n",
      "episode 15, val func loss 0.545859694480896\n",
      "\n",
      "episode 16, val func loss 0.6598718762397766\n",
      "\n",
      "Val func train loss in epoch 6:0.6402199678122997\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6640180945396423\n",
      "\n",
      "episode 2, val func loss 0.7280691266059875\n",
      "\n",
      "episode 3, val func loss 0.6092508435249329\n",
      "\n",
      "episode 4, val func loss 0.6577016711235046\n",
      "\n",
      "episode 5, val func loss 0.5801160931587219\n",
      "\n",
      "episode 6, val func loss 0.5868557095527649\n",
      "\n",
      "episode 7, val func loss 0.7051185965538025\n",
      "\n",
      "episode 8, val func loss 0.7088186740875244\n",
      "\n",
      "episode 9, val func loss 0.5860487222671509\n",
      "\n",
      "episode 10, val func loss 0.710303008556366\n",
      "\n",
      "episode 11, val func loss 0.6359977722167969\n",
      "\n",
      "episode 12, val func loss 0.5854270458221436\n",
      "\n",
      "episode 13, val func loss 0.796200156211853\n",
      "\n",
      "episode 14, val func loss 0.6511953473091125\n",
      "\n",
      "episode 15, val func loss 0.6737156510353088\n",
      "\n",
      "episode 16, val func loss 0.6944857239723206\n",
      "\n",
      "Val func train loss in epoch 7:0.6608326397836208\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6424707174301147\n",
      "\n",
      "episode 2, val func loss 0.6455671191215515\n",
      "\n",
      "episode 3, val func loss 0.7100498676300049\n",
      "\n",
      "episode 4, val func loss 0.5721988677978516\n",
      "\n",
      "episode 5, val func loss 0.5530182719230652\n",
      "\n",
      "episode 6, val func loss 0.5975795388221741\n",
      "\n",
      "episode 7, val func loss 0.5518088340759277\n",
      "\n",
      "episode 8, val func loss 0.6087239980697632\n",
      "\n",
      "episode 9, val func loss 0.6010897755622864\n",
      "\n",
      "episode 10, val func loss 0.5561298131942749\n",
      "\n",
      "episode 11, val func loss 0.49874624609947205\n",
      "\n",
      "episode 12, val func loss 0.6937676668167114\n",
      "\n",
      "episode 13, val func loss 0.5225303769111633\n",
      "\n",
      "episode 14, val func loss 0.6697001457214355\n",
      "\n",
      "episode 15, val func loss 0.6758614778518677\n",
      "\n",
      "episode 16, val func loss 0.6406885981559753\n",
      "\n",
      "Val func train loss in epoch 8:0.6087457071989775\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6631736159324646\n",
      "\n",
      "episode 2, val func loss 0.6353079676628113\n",
      "\n",
      "episode 3, val func loss 0.7222567200660706\n",
      "\n",
      "episode 4, val func loss 0.5447633266448975\n",
      "\n",
      "episode 5, val func loss 0.6001448631286621\n",
      "\n",
      "episode 6, val func loss 0.642503023147583\n",
      "\n",
      "episode 7, val func loss 0.6311055421829224\n",
      "\n",
      "episode 8, val func loss 0.694991409778595\n",
      "\n",
      "episode 9, val func loss 0.6603270769119263\n",
      "\n",
      "episode 10, val func loss 0.565081000328064\n",
      "\n",
      "episode 11, val func loss 0.6384404301643372\n",
      "\n",
      "episode 12, val func loss 0.6579501032829285\n",
      "\n",
      "episode 13, val func loss 0.68524569272995\n",
      "\n",
      "episode 14, val func loss 0.5564591288566589\n",
      "\n",
      "episode 15, val func loss 0.6434294581413269\n",
      "\n",
      "episode 16, val func loss 0.5692365765571594\n",
      "\n",
      "Val func train loss in epoch 9:0.6319009959697723\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6461734771728516\n",
      "\n",
      "episode 2, val func loss 0.5212951302528381\n",
      "\n",
      "episode 3, val func loss 0.5300036072731018\n",
      "\n",
      "episode 4, val func loss 0.6469884514808655\n",
      "\n",
      "episode 5, val func loss 0.5927380919456482\n",
      "\n",
      "episode 6, val func loss 0.6761088967323303\n",
      "\n",
      "episode 7, val func loss 0.7740175127983093\n",
      "\n",
      "episode 8, val func loss 0.6013004779815674\n",
      "\n",
      "episode 9, val func loss 0.5957407355308533\n",
      "\n",
      "episode 10, val func loss 0.6276580095291138\n",
      "\n",
      "episode 11, val func loss 0.612379789352417\n",
      "\n",
      "episode 12, val func loss 0.6740743517875671\n",
      "\n",
      "episode 13, val func loss 0.6365403532981873\n",
      "\n",
      "episode 14, val func loss 0.6075338125228882\n",
      "\n",
      "episode 15, val func loss 0.5796012282371521\n",
      "\n",
      "episode 16, val func loss 0.7120765447616577\n",
      "\n",
      "Val func train loss in epoch 10:0.6271394044160843\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6381146907806396\n",
      "\n",
      "episode 2, val func loss 0.6235548853874207\n",
      "\n",
      "episode 3, val func loss 0.6212551593780518\n",
      "\n",
      "episode 4, val func loss 0.7088257670402527\n",
      "\n",
      "episode 5, val func loss 0.5635321140289307\n",
      "\n",
      "episode 6, val func loss 0.6581653952598572\n",
      "\n",
      "episode 7, val func loss 0.6543938517570496\n",
      "\n",
      "episode 8, val func loss 0.7115043997764587\n",
      "\n",
      "episode 9, val func loss 0.6408637762069702\n",
      "\n",
      "episode 10, val func loss 0.636206328868866\n",
      "\n",
      "episode 11, val func loss 0.7538560032844543\n",
      "\n",
      "episode 12, val func loss 0.7232582569122314\n",
      "\n",
      "episode 13, val func loss 0.6453704833984375\n",
      "\n",
      "episode 14, val func loss 0.8083705306053162\n",
      "\n",
      "episode 15, val func loss 0.6793566942214966\n",
      "\n",
      "episode 16, val func loss 0.6115474700927734\n",
      "\n",
      "Val func train loss in epoch 11:0.6673859879374504\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6293805837631226\n",
      "\n",
      "episode 2, val func loss 0.6086761951446533\n",
      "\n",
      "episode 3, val func loss 0.6998300552368164\n",
      "\n",
      "episode 4, val func loss 0.6548347473144531\n",
      "\n",
      "episode 5, val func loss 0.6985481381416321\n",
      "\n",
      "episode 6, val func loss 0.7161222100257874\n",
      "\n",
      "episode 7, val func loss 0.6780600547790527\n",
      "\n",
      "episode 8, val func loss 0.6483720541000366\n",
      "\n",
      "episode 9, val func loss 0.5922579169273376\n",
      "\n",
      "episode 10, val func loss 0.6449936032295227\n",
      "\n",
      "episode 11, val func loss 0.7437031865119934\n",
      "\n",
      "episode 12, val func loss 0.6716250777244568\n",
      "\n",
      "episode 13, val func loss 0.6906561851501465\n",
      "\n",
      "episode 14, val func loss 0.5592442750930786\n",
      "\n",
      "episode 15, val func loss 0.7211995720863342\n",
      "\n",
      "episode 16, val func loss 0.6338090896606445\n",
      "\n",
      "Val func train loss in epoch 12:0.6619570590555668\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6477441787719727\n",
      "\n",
      "episode 2, val func loss 0.5702877044677734\n",
      "\n",
      "episode 3, val func loss 0.6482505798339844\n",
      "\n",
      "episode 4, val func loss 0.7164406180381775\n",
      "\n",
      "episode 5, val func loss 0.5965664386749268\n",
      "\n",
      "episode 6, val func loss 0.6638975143432617\n",
      "\n",
      "episode 7, val func loss 0.5607478022575378\n",
      "\n",
      "episode 8, val func loss 0.6891465783119202\n",
      "\n",
      "episode 9, val func loss 0.7246496081352234\n",
      "\n",
      "episode 10, val func loss 0.6197428703308105\n",
      "\n",
      "episode 11, val func loss 0.6340402960777283\n",
      "\n",
      "episode 12, val func loss 0.6192730665206909\n",
      "\n",
      "episode 13, val func loss 0.6106836795806885\n",
      "\n",
      "episode 14, val func loss 0.5360338687896729\n",
      "\n",
      "episode 15, val func loss 0.6439527273178101\n",
      "\n",
      "episode 16, val func loss 0.48951804637908936\n",
      "\n",
      "Val func train loss in epoch 13:0.6231859736144543\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6906552910804749\n",
      "\n",
      "episode 2, val func loss 0.6348211765289307\n",
      "\n",
      "episode 3, val func loss 0.6706735491752625\n",
      "\n",
      "episode 4, val func loss 0.5390629172325134\n",
      "\n",
      "episode 5, val func loss 0.6734559535980225\n",
      "\n",
      "episode 6, val func loss 0.6438975930213928\n",
      "\n",
      "episode 7, val func loss 0.6583234071731567\n",
      "\n",
      "episode 8, val func loss 0.5954685807228088\n",
      "\n",
      "episode 9, val func loss 0.6609640717506409\n",
      "\n",
      "episode 10, val func loss 0.5550471544265747\n",
      "\n",
      "episode 11, val func loss 0.6604751348495483\n",
      "\n",
      "episode 12, val func loss 0.7347158193588257\n",
      "\n",
      "episode 13, val func loss 0.6140543818473816\n",
      "\n",
      "episode 14, val func loss 0.6721407771110535\n",
      "\n",
      "episode 15, val func loss 0.5822726488113403\n",
      "\n",
      "episode 16, val func loss 0.7391893863677979\n",
      "\n",
      "Val func train loss in epoch 14:0.6453261151909828\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.5927956104278564\n",
      "\n",
      "episode 2, val func loss 0.7274744510650635\n",
      "\n",
      "episode 3, val func loss 0.5945110321044922\n",
      "\n",
      "episode 4, val func loss 0.5515136122703552\n",
      "\n",
      "episode 5, val func loss 0.8059952855110168\n",
      "\n",
      "episode 6, val func loss 0.6978449821472168\n",
      "\n",
      "episode 7, val func loss 0.6335410475730896\n",
      "\n",
      "episode 8, val func loss 0.7183662056922913\n",
      "\n",
      "episode 9, val func loss 0.7017014622688293\n",
      "\n",
      "episode 10, val func loss 0.689090371131897\n",
      "\n",
      "episode 11, val func loss 0.623186469078064\n",
      "\n",
      "episode 12, val func loss 0.6213091015815735\n",
      "\n",
      "episode 13, val func loss 0.6806144714355469\n",
      "\n",
      "episode 14, val func loss 0.5732080340385437\n",
      "\n",
      "episode 15, val func loss 0.5877466797828674\n",
      "\n",
      "episode 16, val func loss 0.575268566608429\n",
      "\n",
      "Val func train loss in epoch 15:0.6483854614198208\n",
      "***********************TIME WAS 4.931253671646118 min*****************************\n",
      "\n",
      "**********************ROUND 127 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.2660744190216064\n",
      "\n",
      "episode 2, policy loss 1.266074538230896\n",
      "\n",
      "episode 3, policy loss 1.266074299812317\n",
      "\n",
      "episode 4, policy loss 1.2660744190216064\n",
      "\n",
      "episode 5, policy loss 1.266074538230896\n",
      "\n",
      "episode 6, policy loss 1.2660744190216064\n",
      "\n",
      "episode 7, policy loss 1.2660744190216064\n",
      "\n",
      "episode 8, policy loss 1.266074538230896\n",
      "\n",
      "episode 9, policy loss 1.266074538230896\n",
      "\n",
      "episode 10, policy loss 1.266074538230896\n",
      "\n",
      "episode 11, policy loss 1.2660744190216064\n",
      "\n",
      "episode 12, policy loss 1.266074538230896\n",
      "\n",
      "episode 13, policy loss 1.2660744190216064\n",
      "\n",
      "episode 14, policy loss 1.266074538230896\n",
      "\n",
      "episode 15, policy loss 1.2660744190216064\n",
      "\n",
      "episode 16, policy loss 1.266074538230896\n",
      "\n",
      "Policy train loss in epoch 0:1.2660744711756706\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.266074538230896\n",
      "\n",
      "episode 2, policy loss 1.266074538230896\n",
      "\n",
      "episode 3, policy loss 1.2660744190216064\n",
      "\n",
      "episode 4, policy loss 1.2660744190216064\n",
      "\n",
      "episode 5, policy loss 1.2660744190216064\n",
      "\n",
      "episode 6, policy loss 1.2660744190216064\n",
      "\n",
      "episode 7, policy loss 1.2660744190216064\n",
      "\n",
      "episode 8, policy loss 1.2660744190216064\n",
      "\n",
      "episode 9, policy loss 1.266074538230896\n",
      "\n",
      "episode 10, policy loss 1.266074538230896\n",
      "\n",
      "episode 11, policy loss 1.266074538230896\n",
      "\n",
      "episode 12, policy loss 1.266074538230896\n",
      "\n",
      "episode 13, policy loss 1.2660744190216064\n",
      "\n",
      "episode 14, policy loss 1.2660744190216064\n",
      "\n",
      "episode 15, policy loss 1.266074538230896\n",
      "\n",
      "episode 16, policy loss 1.2660744190216064\n",
      "\n",
      "Policy train loss in epoch 1:1.2660744711756706\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.2660744190216064\n",
      "\n",
      "episode 2, policy loss 1.2660744190216064\n",
      "\n",
      "episode 3, policy loss 1.266074538230896\n",
      "\n",
      "episode 4, policy loss 1.266074299812317\n",
      "\n",
      "episode 5, policy loss 1.2660746574401855\n",
      "\n",
      "episode 6, policy loss 1.2660744190216064\n",
      "\n",
      "episode 7, policy loss 1.266074538230896\n",
      "\n",
      "episode 8, policy loss 1.2660744190216064\n",
      "\n",
      "episode 9, policy loss 1.266074538230896\n",
      "\n",
      "episode 10, policy loss 1.2660744190216064\n",
      "\n",
      "episode 11, policy loss 1.2660744190216064\n",
      "\n",
      "episode 12, policy loss 1.266074538230896\n",
      "\n",
      "episode 13, policy loss 1.266074538230896\n",
      "\n",
      "episode 14, policy loss 1.266074538230896\n",
      "\n",
      "episode 15, policy loss 1.266074538230896\n",
      "\n",
      "episode 16, policy loss 1.2660744190216064\n",
      "\n",
      "Policy train loss in epoch 2:1.2660744786262512\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.2660744190216064\n",
      "\n",
      "episode 2, policy loss 1.2660744190216064\n",
      "\n",
      "episode 3, policy loss 1.266074538230896\n",
      "\n",
      "episode 4, policy loss 1.2660746574401855\n",
      "\n",
      "episode 5, policy loss 1.2660744190216064\n",
      "\n",
      "episode 6, policy loss 1.266074538230896\n",
      "\n",
      "episode 7, policy loss 1.2660744190216064\n",
      "\n",
      "episode 8, policy loss 1.2660744190216064\n",
      "\n",
      "episode 9, policy loss 1.266074538230896\n",
      "\n",
      "episode 10, policy loss 1.2660744190216064\n",
      "\n",
      "episode 11, policy loss 1.266074538230896\n",
      "\n",
      "episode 12, policy loss 1.2660744190216064\n",
      "\n",
      "episode 13, policy loss 1.2660744190216064\n",
      "\n",
      "episode 14, policy loss 1.2660744190216064\n",
      "\n",
      "episode 15, policy loss 1.266074538230896\n",
      "\n",
      "episode 16, policy loss 1.2660744190216064\n",
      "\n",
      "Policy train loss in epoch 3:1.2660744711756706\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.6437364220619202\n",
      "\n",
      "episode 2, val func loss 0.5802186131477356\n",
      "\n",
      "episode 3, val func loss 0.5960820913314819\n",
      "\n",
      "episode 4, val func loss 0.6362015604972839\n",
      "\n",
      "episode 5, val func loss 0.5896537899971008\n",
      "\n",
      "episode 6, val func loss 0.6287972927093506\n",
      "\n",
      "episode 7, val func loss 0.6893391609191895\n",
      "\n",
      "episode 8, val func loss 0.8613117337226868\n",
      "\n",
      "episode 9, val func loss 0.649237871170044\n",
      "\n",
      "episode 10, val func loss 0.5707846283912659\n",
      "\n",
      "episode 11, val func loss 0.6877122521400452\n",
      "\n",
      "episode 12, val func loss 0.7863599061965942\n",
      "\n",
      "episode 13, val func loss 0.6600570678710938\n",
      "\n",
      "episode 14, val func loss 0.6063268184661865\n",
      "\n",
      "episode 15, val func loss 0.534501850605011\n",
      "\n",
      "episode 16, val func loss 0.618800938129425\n",
      "\n",
      "Val func train loss in epoch 0:0.6461951248347759\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.5658785104751587\n",
      "\n",
      "episode 2, val func loss 0.5851925015449524\n",
      "\n",
      "episode 3, val func loss 0.7288953065872192\n",
      "\n",
      "episode 4, val func loss 0.5943729281425476\n",
      "\n",
      "episode 5, val func loss 0.6304329633712769\n",
      "\n",
      "episode 6, val func loss 0.7481766939163208\n",
      "\n",
      "episode 7, val func loss 0.6344166398048401\n",
      "\n",
      "episode 8, val func loss 0.5677067637443542\n",
      "\n",
      "episode 9, val func loss 0.5316528677940369\n",
      "\n",
      "episode 10, val func loss 0.6669394373893738\n",
      "\n",
      "episode 11, val func loss 0.577758252620697\n",
      "\n",
      "episode 12, val func loss 0.6329470872879028\n",
      "\n",
      "episode 13, val func loss 0.6247974038124084\n",
      "\n",
      "episode 14, val func loss 0.6102451682090759\n",
      "\n",
      "episode 15, val func loss 0.7055318355560303\n",
      "\n",
      "episode 16, val func loss 0.5608862042427063\n",
      "\n",
      "Val func train loss in epoch 1:0.6228644102811813\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.652751088142395\n",
      "\n",
      "episode 2, val func loss 0.5692000389099121\n",
      "\n",
      "episode 3, val func loss 0.5637028217315674\n",
      "\n",
      "episode 4, val func loss 0.6716710925102234\n",
      "\n",
      "episode 5, val func loss 0.6311641335487366\n",
      "\n",
      "episode 6, val func loss 0.7141589522361755\n",
      "\n",
      "episode 7, val func loss 0.6342960000038147\n",
      "\n",
      "episode 8, val func loss 0.7633730173110962\n",
      "\n",
      "episode 9, val func loss 0.6655429601669312\n",
      "\n",
      "episode 10, val func loss 0.6108663082122803\n",
      "\n",
      "episode 11, val func loss 0.5295208692550659\n",
      "\n",
      "episode 12, val func loss 0.5835141539573669\n",
      "\n",
      "episode 13, val func loss 0.6601341366767883\n",
      "\n",
      "episode 14, val func loss 0.6392908692359924\n",
      "\n",
      "episode 15, val func loss 0.6648731231689453\n",
      "\n",
      "episode 16, val func loss 0.590734601020813\n",
      "\n",
      "Val func train loss in epoch 2:0.6340496353805065\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.7407355904579163\n",
      "\n",
      "episode 2, val func loss 0.6933781504631042\n",
      "\n",
      "episode 3, val func loss 0.6197391152381897\n",
      "\n",
      "episode 4, val func loss 0.7541011571884155\n",
      "\n",
      "episode 5, val func loss 0.6804055571556091\n",
      "\n",
      "episode 6, val func loss 0.6435239911079407\n",
      "\n",
      "episode 7, val func loss 0.6764360070228577\n",
      "\n",
      "episode 8, val func loss 0.6400766372680664\n",
      "\n",
      "episode 9, val func loss 0.6024641394615173\n",
      "\n",
      "episode 10, val func loss 0.6574841737747192\n",
      "\n",
      "episode 11, val func loss 0.6071428656578064\n",
      "\n",
      "episode 12, val func loss 0.638496994972229\n",
      "\n",
      "episode 13, val func loss 0.6089553833007812\n",
      "\n",
      "episode 14, val func loss 0.7019988298416138\n",
      "\n",
      "episode 15, val func loss 0.7336384654045105\n",
      "\n",
      "episode 16, val func loss 0.6583623886108398\n",
      "\n",
      "Val func train loss in epoch 3:0.6660587154328823\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7186380624771118\n",
      "\n",
      "episode 2, val func loss 0.5936223864555359\n",
      "\n",
      "episode 3, val func loss 0.6923103332519531\n",
      "\n",
      "episode 4, val func loss 0.533880889415741\n",
      "\n",
      "episode 5, val func loss 0.6666680574417114\n",
      "\n",
      "episode 6, val func loss 0.6758078336715698\n",
      "\n",
      "episode 7, val func loss 0.6417164206504822\n",
      "\n",
      "episode 8, val func loss 0.7102177143096924\n",
      "\n",
      "episode 9, val func loss 0.6415265798568726\n",
      "\n",
      "episode 10, val func loss 0.5564334392547607\n",
      "\n",
      "episode 11, val func loss 0.6514102220535278\n",
      "\n",
      "episode 12, val func loss 0.6059038639068604\n",
      "\n",
      "episode 13, val func loss 0.7422190308570862\n",
      "\n",
      "episode 14, val func loss 0.6159587502479553\n",
      "\n",
      "episode 15, val func loss 0.6748799085617065\n",
      "\n",
      "episode 16, val func loss 0.6756143569946289\n",
      "\n",
      "Val func train loss in epoch 4:0.6498004905879498\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.5824750661849976\n",
      "\n",
      "episode 2, val func loss 0.6044754385948181\n",
      "\n",
      "episode 3, val func loss 0.6032993793487549\n",
      "\n",
      "episode 4, val func loss 0.7540327310562134\n",
      "\n",
      "episode 5, val func loss 0.6418396830558777\n",
      "\n",
      "episode 6, val func loss 0.571015477180481\n",
      "\n",
      "episode 7, val func loss 0.6118047833442688\n",
      "\n",
      "episode 8, val func loss 0.6938765645027161\n",
      "\n",
      "episode 9, val func loss 0.6499322056770325\n",
      "\n",
      "episode 10, val func loss 0.662675678730011\n",
      "\n",
      "episode 11, val func loss 0.7401118874549866\n",
      "\n",
      "episode 12, val func loss 0.6916579008102417\n",
      "\n",
      "episode 13, val func loss 0.650592029094696\n",
      "\n",
      "episode 14, val func loss 0.7186077237129211\n",
      "\n",
      "episode 15, val func loss 0.6789170503616333\n",
      "\n",
      "episode 16, val func loss 0.6319307088851929\n",
      "\n",
      "Val func train loss in epoch 5:0.6554527692496777\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6238588690757751\n",
      "\n",
      "episode 2, val func loss 0.6823629140853882\n",
      "\n",
      "episode 3, val func loss 0.6680896878242493\n",
      "\n",
      "episode 4, val func loss 0.6371893882751465\n",
      "\n",
      "episode 5, val func loss 0.5365170240402222\n",
      "\n",
      "episode 6, val func loss 0.6382449865341187\n",
      "\n",
      "episode 7, val func loss 0.6911637187004089\n",
      "\n",
      "episode 8, val func loss 0.63099205493927\n",
      "\n",
      "episode 9, val func loss 0.5960000157356262\n",
      "\n",
      "episode 10, val func loss 0.6604285836219788\n",
      "\n",
      "episode 11, val func loss 0.6890230178833008\n",
      "\n",
      "episode 12, val func loss 0.5420522093772888\n",
      "\n",
      "episode 13, val func loss 0.6976507306098938\n",
      "\n",
      "episode 14, val func loss 0.6867480278015137\n",
      "\n",
      "episode 15, val func loss 0.6666873693466187\n",
      "\n",
      "episode 16, val func loss 0.6163939833641052\n",
      "\n",
      "Val func train loss in epoch 6:0.6414626613259315\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7434070706367493\n",
      "\n",
      "episode 2, val func loss 0.6791063547134399\n",
      "\n",
      "episode 3, val func loss 0.6975911259651184\n",
      "\n",
      "episode 4, val func loss 0.6858003735542297\n",
      "\n",
      "episode 5, val func loss 0.7184613347053528\n",
      "\n",
      "episode 6, val func loss 0.8150606751441956\n",
      "\n",
      "episode 7, val func loss 0.6671797633171082\n",
      "\n",
      "episode 8, val func loss 0.6487886905670166\n",
      "\n",
      "episode 9, val func loss 0.6252263784408569\n",
      "\n",
      "episode 10, val func loss 0.5937141180038452\n",
      "\n",
      "episode 11, val func loss 0.6384719014167786\n",
      "\n",
      "episode 12, val func loss 0.6198753118515015\n",
      "\n",
      "episode 13, val func loss 0.647131621837616\n",
      "\n",
      "episode 14, val func loss 0.6488426327705383\n",
      "\n",
      "episode 15, val func loss 0.6473804116249084\n",
      "\n",
      "episode 16, val func loss 0.61931312084198\n",
      "\n",
      "Val func train loss in epoch 7:0.6684594303369522\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6207457184791565\n",
      "\n",
      "episode 2, val func loss 0.6989955306053162\n",
      "\n",
      "episode 3, val func loss 0.5586177110671997\n",
      "\n",
      "episode 4, val func loss 0.6618024110794067\n",
      "\n",
      "episode 5, val func loss 0.6353185772895813\n",
      "\n",
      "episode 6, val func loss 0.6180210113525391\n",
      "\n",
      "episode 7, val func loss 0.6650170087814331\n",
      "\n",
      "episode 8, val func loss 0.6383249759674072\n",
      "\n",
      "episode 9, val func loss 0.626470685005188\n",
      "\n",
      "episode 10, val func loss 0.6351890563964844\n",
      "\n",
      "episode 11, val func loss 0.6459557414054871\n",
      "\n",
      "episode 12, val func loss 0.5510812401771545\n",
      "\n",
      "episode 13, val func loss 0.587566614151001\n",
      "\n",
      "episode 14, val func loss 0.6032148003578186\n",
      "\n",
      "episode 15, val func loss 0.5846007466316223\n",
      "\n",
      "episode 16, val func loss 0.6127817630767822\n",
      "\n",
      "Val func train loss in epoch 8:0.6214814744889736\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.5883690714836121\n",
      "\n",
      "episode 2, val func loss 0.6588939428329468\n",
      "\n",
      "episode 3, val func loss 0.626546323299408\n",
      "\n",
      "episode 4, val func loss 0.6225424408912659\n",
      "\n",
      "episode 5, val func loss 0.637161135673523\n",
      "\n",
      "episode 6, val func loss 0.5820854902267456\n",
      "\n",
      "episode 7, val func loss 0.5441526174545288\n",
      "\n",
      "episode 8, val func loss 0.6332588195800781\n",
      "\n",
      "episode 9, val func loss 0.6545503735542297\n",
      "\n",
      "episode 10, val func loss 0.5359330773353577\n",
      "\n",
      "episode 11, val func loss 0.5583227276802063\n",
      "\n",
      "episode 12, val func loss 0.594192624092102\n",
      "\n",
      "episode 13, val func loss 0.5814293026924133\n",
      "\n",
      "episode 14, val func loss 0.6271176934242249\n",
      "\n",
      "episode 15, val func loss 0.5131633877754211\n",
      "\n",
      "episode 16, val func loss 0.6714450120925903\n",
      "\n",
      "Val func train loss in epoch 9:0.6018227525055408\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6047346591949463\n",
      "\n",
      "episode 2, val func loss 0.6440582871437073\n",
      "\n",
      "episode 3, val func loss 0.6562216281890869\n",
      "\n",
      "episode 4, val func loss 0.6291844248771667\n",
      "\n",
      "episode 5, val func loss 0.7045958042144775\n",
      "\n",
      "episode 6, val func loss 0.779019832611084\n",
      "\n",
      "episode 7, val func loss 0.6701999306678772\n",
      "\n",
      "episode 8, val func loss 0.7171584367752075\n",
      "\n",
      "episode 9, val func loss 0.6726022362709045\n",
      "\n",
      "episode 10, val func loss 0.6036455035209656\n",
      "\n",
      "episode 11, val func loss 0.6855848431587219\n",
      "\n",
      "episode 12, val func loss 0.6221680045127869\n",
      "\n",
      "episode 13, val func loss 0.6230570077896118\n",
      "\n",
      "episode 14, val func loss 0.6591252684593201\n",
      "\n",
      "episode 15, val func loss 0.6114528775215149\n",
      "\n",
      "episode 16, val func loss 0.6134946346282959\n",
      "\n",
      "Val func train loss in epoch 10:0.6560189612209797\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.679908037185669\n",
      "\n",
      "episode 2, val func loss 0.662381112575531\n",
      "\n",
      "episode 3, val func loss 0.6492465138435364\n",
      "\n",
      "episode 4, val func loss 0.5715060234069824\n",
      "\n",
      "episode 5, val func loss 0.6727243065834045\n",
      "\n",
      "episode 6, val func loss 0.5427649021148682\n",
      "\n",
      "episode 7, val func loss 0.6103729009628296\n",
      "\n",
      "episode 8, val func loss 0.7039444446563721\n",
      "\n",
      "episode 9, val func loss 0.669663667678833\n",
      "\n",
      "episode 10, val func loss 0.6026893258094788\n",
      "\n",
      "episode 11, val func loss 0.5894923806190491\n",
      "\n",
      "episode 12, val func loss 0.6450794339179993\n",
      "\n",
      "episode 13, val func loss 0.6213906407356262\n",
      "\n",
      "episode 14, val func loss 0.578381359577179\n",
      "\n",
      "episode 15, val func loss 0.5693420171737671\n",
      "\n",
      "episode 16, val func loss 0.6491639614105225\n",
      "\n",
      "Val func train loss in epoch 11:0.626128189265728\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.5774624347686768\n",
      "\n",
      "episode 2, val func loss 0.5630855560302734\n",
      "\n",
      "episode 3, val func loss 0.584384024143219\n",
      "\n",
      "episode 4, val func loss 0.5732394456863403\n",
      "\n",
      "episode 5, val func loss 0.6879575848579407\n",
      "\n",
      "episode 6, val func loss 0.5756470561027527\n",
      "\n",
      "episode 7, val func loss 0.6163178086280823\n",
      "\n",
      "episode 8, val func loss 0.6248624324798584\n",
      "\n",
      "episode 9, val func loss 0.5905742645263672\n",
      "\n",
      "episode 10, val func loss 0.5744202136993408\n",
      "\n",
      "episode 11, val func loss 0.6324464678764343\n",
      "\n",
      "episode 12, val func loss 0.6134655475616455\n",
      "\n",
      "episode 13, val func loss 0.6091020107269287\n",
      "\n",
      "episode 14, val func loss 0.6471334099769592\n",
      "\n",
      "episode 15, val func loss 0.6080637574195862\n",
      "\n",
      "episode 16, val func loss 0.7126824855804443\n",
      "\n",
      "Val func train loss in epoch 12:0.6119277812540531\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.643189549446106\n",
      "\n",
      "episode 2, val func loss 0.5712304711341858\n",
      "\n",
      "episode 3, val func loss 0.7386248111724854\n",
      "\n",
      "episode 4, val func loss 0.7215795516967773\n",
      "\n",
      "episode 5, val func loss 0.5844296216964722\n",
      "\n",
      "episode 6, val func loss 0.6840267777442932\n",
      "\n",
      "episode 7, val func loss 0.6019404530525208\n",
      "\n",
      "episode 8, val func loss 0.5029423832893372\n",
      "\n",
      "episode 9, val func loss 0.6470113396644592\n",
      "\n",
      "episode 10, val func loss 0.6774658560752869\n",
      "\n",
      "episode 11, val func loss 0.6414868831634521\n",
      "\n",
      "episode 12, val func loss 0.6380602121353149\n",
      "\n",
      "episode 13, val func loss 0.7421437501907349\n",
      "\n",
      "episode 14, val func loss 0.5671142935752869\n",
      "\n",
      "episode 15, val func loss 0.6021623611450195\n",
      "\n",
      "episode 16, val func loss 0.6409389972686768\n",
      "\n",
      "Val func train loss in epoch 13:0.6377717070281506\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.5948362350463867\n",
      "\n",
      "episode 2, val func loss 0.5731931328773499\n",
      "\n",
      "episode 3, val func loss 0.6420066952705383\n",
      "\n",
      "episode 4, val func loss 0.7234944105148315\n",
      "\n",
      "episode 5, val func loss 0.644731879234314\n",
      "\n",
      "episode 6, val func loss 0.6910273432731628\n",
      "\n",
      "episode 7, val func loss 0.6091426014900208\n",
      "\n",
      "episode 8, val func loss 0.6461114883422852\n",
      "\n",
      "episode 9, val func loss 0.6879571080207825\n",
      "\n",
      "episode 10, val func loss 0.6974136829376221\n",
      "\n",
      "episode 11, val func loss 0.7222039699554443\n",
      "\n",
      "episode 12, val func loss 0.7231917977333069\n",
      "\n",
      "episode 13, val func loss 0.6170293092727661\n",
      "\n",
      "episode 14, val func loss 0.5951731204986572\n",
      "\n",
      "episode 15, val func loss 0.6645689606666565\n",
      "\n",
      "episode 16, val func loss 0.5623412728309631\n",
      "\n",
      "Val func train loss in epoch 14:0.649651437997818\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6169084310531616\n",
      "\n",
      "episode 2, val func loss 0.6134238243103027\n",
      "\n",
      "episode 3, val func loss 0.6349184513092041\n",
      "\n",
      "episode 4, val func loss 0.6777998805046082\n",
      "\n",
      "episode 5, val func loss 0.7124875783920288\n",
      "\n",
      "episode 6, val func loss 0.6010267734527588\n",
      "\n",
      "episode 7, val func loss 0.6646352410316467\n",
      "\n",
      "episode 8, val func loss 0.6597512364387512\n",
      "\n",
      "episode 9, val func loss 0.5732383131980896\n",
      "\n",
      "episode 10, val func loss 0.6347323656082153\n",
      "\n",
      "episode 11, val func loss 0.6488187909126282\n",
      "\n",
      "episode 12, val func loss 0.6123203635215759\n",
      "\n",
      "episode 13, val func loss 0.5532984733581543\n",
      "\n",
      "episode 14, val func loss 0.6002525091171265\n",
      "\n",
      "episode 15, val func loss 0.6742671132087708\n",
      "\n",
      "episode 16, val func loss 0.6403099298477173\n",
      "\n",
      "Val func train loss in epoch 15:0.6323868297040462\n",
      "***********************TIME WAS 4.924087981383006 min*****************************\n",
      "\n",
      "**********************ROUND 128 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.509736180305481\n",
      "\n",
      "episode 2, policy loss 1.509736180305481\n",
      "\n",
      "episode 3, policy loss 1.509736180305481\n",
      "\n",
      "episode 4, policy loss 1.509736180305481\n",
      "\n",
      "episode 5, policy loss 1.509736180305481\n",
      "\n",
      "episode 6, policy loss 1.5097360610961914\n",
      "\n",
      "episode 7, policy loss 1.509736180305481\n",
      "\n",
      "episode 8, policy loss 1.5097360610961914\n",
      "\n",
      "episode 9, policy loss 1.5097358226776123\n",
      "\n",
      "episode 10, policy loss 1.509736180305481\n",
      "\n",
      "episode 11, policy loss 1.5097360610961914\n",
      "\n",
      "episode 12, policy loss 1.5097360610961914\n",
      "\n",
      "episode 13, policy loss 1.509736180305481\n",
      "\n",
      "episode 14, policy loss 1.5097358226776123\n",
      "\n",
      "episode 15, policy loss 1.509736180305481\n",
      "\n",
      "episode 16, policy loss 1.509736180305481\n",
      "\n",
      "Policy train loss in epoch 0:1.509736105799675\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.5097360610961914\n",
      "\n",
      "episode 2, policy loss 1.5097360610961914\n",
      "\n",
      "episode 3, policy loss 1.5097360610961914\n",
      "\n",
      "episode 4, policy loss 1.5097360610961914\n",
      "\n",
      "episode 5, policy loss 1.509736180305481\n",
      "\n",
      "episode 6, policy loss 1.509736180305481\n",
      "\n",
      "episode 7, policy loss 1.509736180305481\n",
      "\n",
      "episode 8, policy loss 1.5097358226776123\n",
      "\n",
      "episode 9, policy loss 1.5097360610961914\n",
      "\n",
      "episode 10, policy loss 1.509736180305481\n",
      "\n",
      "episode 11, policy loss 1.509736180305481\n",
      "\n",
      "episode 12, policy loss 1.5097360610961914\n",
      "\n",
      "episode 13, policy loss 1.5097358226776123\n",
      "\n",
      "episode 14, policy loss 1.509736180305481\n",
      "\n",
      "episode 15, policy loss 1.5097360610961914\n",
      "\n",
      "episode 16, policy loss 1.509736180305481\n",
      "\n",
      "Policy train loss in epoch 1:1.5097360834479332\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.509736180305481\n",
      "\n",
      "episode 2, policy loss 1.509736180305481\n",
      "\n",
      "episode 3, policy loss 1.5097358226776123\n",
      "\n",
      "episode 4, policy loss 1.5097358226776123\n",
      "\n",
      "episode 5, policy loss 1.5097360610961914\n",
      "\n",
      "episode 6, policy loss 1.509736180305481\n",
      "\n",
      "episode 7, policy loss 1.5097360610961914\n",
      "\n",
      "episode 8, policy loss 1.509736180305481\n",
      "\n",
      "episode 9, policy loss 1.5097360610961914\n",
      "\n",
      "episode 10, policy loss 1.509736180305481\n",
      "\n",
      "episode 11, policy loss 1.5097360610961914\n",
      "\n",
      "episode 12, policy loss 1.5097360610961914\n",
      "\n",
      "episode 13, policy loss 1.509736180305481\n",
      "\n",
      "episode 14, policy loss 1.5097358226776123\n",
      "\n",
      "episode 15, policy loss 1.509736180305481\n",
      "\n",
      "episode 16, policy loss 1.509736180305481\n",
      "\n",
      "Policy train loss in epoch 2:1.5097360759973526\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.5097360610961914\n",
      "\n",
      "episode 2, policy loss 1.5097360610961914\n",
      "\n",
      "episode 3, policy loss 1.509736180305481\n",
      "\n",
      "episode 4, policy loss 1.509736180305481\n",
      "\n",
      "episode 5, policy loss 1.5097360610961914\n",
      "\n",
      "episode 6, policy loss 1.5097360610961914\n",
      "\n",
      "episode 7, policy loss 1.509736180305481\n",
      "\n",
      "episode 8, policy loss 1.5097360610961914\n",
      "\n",
      "episode 9, policy loss 1.509736180305481\n",
      "\n",
      "episode 10, policy loss 1.5097358226776123\n",
      "\n",
      "episode 11, policy loss 1.5097358226776123\n",
      "\n",
      "episode 12, policy loss 1.509736180305481\n",
      "\n",
      "episode 13, policy loss 1.5097360610961914\n",
      "\n",
      "episode 14, policy loss 1.5097358226776123\n",
      "\n",
      "episode 15, policy loss 1.5097360610961914\n",
      "\n",
      "episode 16, policy loss 1.5097360610961914\n",
      "\n",
      "Policy train loss in epoch 3:1.5097360536456108\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7288678288459778\n",
      "\n",
      "episode 2, val func loss 0.7156505584716797\n",
      "\n",
      "episode 3, val func loss 0.6093032956123352\n",
      "\n",
      "episode 4, val func loss 0.5774210691452026\n",
      "\n",
      "episode 5, val func loss 0.5904560685157776\n",
      "\n",
      "episode 6, val func loss 0.7570671439170837\n",
      "\n",
      "episode 7, val func loss 0.6724572777748108\n",
      "\n",
      "episode 8, val func loss 0.5356346964836121\n",
      "\n",
      "episode 9, val func loss 0.6453843712806702\n",
      "\n",
      "episode 10, val func loss 0.6869617104530334\n",
      "\n",
      "episode 11, val func loss 0.6267407536506653\n",
      "\n",
      "episode 12, val func loss 0.6759783625602722\n",
      "\n",
      "episode 13, val func loss 0.6019818782806396\n",
      "\n",
      "episode 14, val func loss 0.7205522060394287\n",
      "\n",
      "episode 15, val func loss 0.5796738862991333\n",
      "\n",
      "episode 16, val func loss 0.5864185094833374\n",
      "\n",
      "Val func train loss in epoch 0:0.6444093510508537\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.5667770504951477\n",
      "\n",
      "episode 2, val func loss 0.6314719319343567\n",
      "\n",
      "episode 3, val func loss 0.5464376211166382\n",
      "\n",
      "episode 4, val func loss 0.5503709316253662\n",
      "\n",
      "episode 5, val func loss 0.6003748774528503\n",
      "\n",
      "episode 6, val func loss 0.6441157460212708\n",
      "\n",
      "episode 7, val func loss 0.6740471720695496\n",
      "\n",
      "episode 8, val func loss 0.6779897212982178\n",
      "\n",
      "episode 9, val func loss 0.6757348775863647\n",
      "\n",
      "episode 10, val func loss 0.628800630569458\n",
      "\n",
      "episode 11, val func loss 0.675842821598053\n",
      "\n",
      "episode 12, val func loss 0.6914725303649902\n",
      "\n",
      "episode 13, val func loss 0.5580697655677795\n",
      "\n",
      "episode 14, val func loss 0.6288206577301025\n",
      "\n",
      "episode 15, val func loss 0.5799877047538757\n",
      "\n",
      "episode 16, val func loss 0.5227027535438538\n",
      "\n",
      "Val func train loss in epoch 1:0.6158135496079922\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6308048367500305\n",
      "\n",
      "episode 2, val func loss 0.5943493247032166\n",
      "\n",
      "episode 3, val func loss 0.7264441847801208\n",
      "\n",
      "episode 4, val func loss 0.5988145470619202\n",
      "\n",
      "episode 5, val func loss 0.7058918476104736\n",
      "\n",
      "episode 6, val func loss 0.5974671244621277\n",
      "\n",
      "episode 7, val func loss 0.5961877703666687\n",
      "\n",
      "episode 8, val func loss 0.6311206221580505\n",
      "\n",
      "episode 9, val func loss 0.5866835117340088\n",
      "\n",
      "episode 10, val func loss 0.6406723260879517\n",
      "\n",
      "episode 11, val func loss 0.7320792078971863\n",
      "\n",
      "episode 12, val func loss 0.6172090172767639\n",
      "\n",
      "episode 13, val func loss 0.6404950022697449\n",
      "\n",
      "episode 14, val func loss 0.6075302958488464\n",
      "\n",
      "episode 15, val func loss 0.5597928762435913\n",
      "\n",
      "episode 16, val func loss 0.6589775085449219\n",
      "\n",
      "Val func train loss in epoch 2:0.6327825002372265\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.7175251841545105\n",
      "\n",
      "episode 2, val func loss 0.611701488494873\n",
      "\n",
      "episode 3, val func loss 0.577103853225708\n",
      "\n",
      "episode 4, val func loss 0.6165254712104797\n",
      "\n",
      "episode 5, val func loss 0.7003752589225769\n",
      "\n",
      "episode 6, val func loss 0.723179817199707\n",
      "\n",
      "episode 7, val func loss 0.580977201461792\n",
      "\n",
      "episode 8, val func loss 0.5794625878334045\n",
      "\n",
      "episode 9, val func loss 0.7613719701766968\n",
      "\n",
      "episode 10, val func loss 0.5991334915161133\n",
      "\n",
      "episode 11, val func loss 0.7445365190505981\n",
      "\n",
      "episode 12, val func loss 0.6655645370483398\n",
      "\n",
      "episode 13, val func loss 0.6079843640327454\n",
      "\n",
      "episode 14, val func loss 0.7013960480690002\n",
      "\n",
      "episode 15, val func loss 0.5712203979492188\n",
      "\n",
      "episode 16, val func loss 0.6580646634101868\n",
      "\n",
      "Val func train loss in epoch 3:0.6510076783597469\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7483885288238525\n",
      "\n",
      "episode 2, val func loss 0.6050357222557068\n",
      "\n",
      "episode 3, val func loss 0.7567362785339355\n",
      "\n",
      "episode 4, val func loss 0.6811171770095825\n",
      "\n",
      "episode 5, val func loss 0.6604969501495361\n",
      "\n",
      "episode 6, val func loss 0.7289153337478638\n",
      "\n",
      "episode 7, val func loss 0.7043806910514832\n",
      "\n",
      "episode 8, val func loss 0.6199442148208618\n",
      "\n",
      "episode 9, val func loss 0.6667472124099731\n",
      "\n",
      "episode 10, val func loss 0.6656259298324585\n",
      "\n",
      "episode 11, val func loss 0.61430424451828\n",
      "\n",
      "episode 12, val func loss 0.6166194677352905\n",
      "\n",
      "episode 13, val func loss 0.5974152088165283\n",
      "\n",
      "episode 14, val func loss 0.612686276435852\n",
      "\n",
      "episode 15, val func loss 0.6822545528411865\n",
      "\n",
      "episode 16, val func loss 0.7206645011901855\n",
      "\n",
      "Val func train loss in epoch 4:0.6675832681357861\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.688992977142334\n",
      "\n",
      "episode 2, val func loss 0.6681529879570007\n",
      "\n",
      "episode 3, val func loss 0.688298761844635\n",
      "\n",
      "episode 4, val func loss 0.6918931007385254\n",
      "\n",
      "episode 5, val func loss 0.606144368648529\n",
      "\n",
      "episode 6, val func loss 0.6451548933982849\n",
      "\n",
      "episode 7, val func loss 0.5977575182914734\n",
      "\n",
      "episode 8, val func loss 0.6279022693634033\n",
      "\n",
      "episode 9, val func loss 0.5792679786682129\n",
      "\n",
      "episode 10, val func loss 0.5858575701713562\n",
      "\n",
      "episode 11, val func loss 0.5520904660224915\n",
      "\n",
      "episode 12, val func loss 0.6600203514099121\n",
      "\n",
      "episode 13, val func loss 0.5350525975227356\n",
      "\n",
      "episode 14, val func loss 0.6093776822090149\n",
      "\n",
      "episode 15, val func loss 0.7058088779449463\n",
      "\n",
      "episode 16, val func loss 0.6567156314849854\n",
      "\n",
      "Val func train loss in epoch 5:0.631155502051115\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6424327492713928\n",
      "\n",
      "episode 2, val func loss 0.5889214873313904\n",
      "\n",
      "episode 3, val func loss 0.6487982273101807\n",
      "\n",
      "episode 4, val func loss 0.6563363671302795\n",
      "\n",
      "episode 5, val func loss 0.6751492023468018\n",
      "\n",
      "episode 6, val func loss 0.7134825587272644\n",
      "\n",
      "episode 7, val func loss 0.6303159594535828\n",
      "\n",
      "episode 8, val func loss 0.6671295762062073\n",
      "\n",
      "episode 9, val func loss 0.669669508934021\n",
      "\n",
      "episode 10, val func loss 0.5675556063652039\n",
      "\n",
      "episode 11, val func loss 0.6182813048362732\n",
      "\n",
      "episode 12, val func loss 0.6455780267715454\n",
      "\n",
      "episode 13, val func loss 0.7259398102760315\n",
      "\n",
      "episode 14, val func loss 0.720850944519043\n",
      "\n",
      "episode 15, val func loss 0.6037960052490234\n",
      "\n",
      "episode 16, val func loss 0.7151577472686768\n",
      "\n",
      "Val func train loss in epoch 6:0.6555871926248074\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.5787042379379272\n",
      "\n",
      "episode 2, val func loss 0.6934496164321899\n",
      "\n",
      "episode 3, val func loss 0.5808254480361938\n",
      "\n",
      "episode 4, val func loss 0.5892799496650696\n",
      "\n",
      "episode 5, val func loss 0.5814030170440674\n",
      "\n",
      "episode 6, val func loss 0.6181017756462097\n",
      "\n",
      "episode 7, val func loss 0.6671828627586365\n",
      "\n",
      "episode 8, val func loss 0.6675099730491638\n",
      "\n",
      "episode 9, val func loss 0.589061975479126\n",
      "\n",
      "episode 10, val func loss 0.8204072117805481\n",
      "\n",
      "episode 11, val func loss 0.656143069267273\n",
      "\n",
      "episode 12, val func loss 0.6235434412956238\n",
      "\n",
      "episode 13, val func loss 0.652902364730835\n",
      "\n",
      "episode 14, val func loss 0.7358567714691162\n",
      "\n",
      "episode 15, val func loss 0.6615711450576782\n",
      "\n",
      "episode 16, val func loss 0.5961557626724243\n",
      "\n",
      "Val func train loss in epoch 7:0.6445061638951302\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.7101514935493469\n",
      "\n",
      "episode 2, val func loss 0.6602948307991028\n",
      "\n",
      "episode 3, val func loss 0.6908562183380127\n",
      "\n",
      "episode 4, val func loss 0.6587144732475281\n",
      "\n",
      "episode 5, val func loss 0.6444695591926575\n",
      "\n",
      "episode 6, val func loss 0.6494423747062683\n",
      "\n",
      "episode 7, val func loss 0.7236897349357605\n",
      "\n",
      "episode 8, val func loss 0.5428287982940674\n",
      "\n",
      "episode 9, val func loss 0.6448132395744324\n",
      "\n",
      "episode 10, val func loss 0.6716175675392151\n",
      "\n",
      "episode 11, val func loss 0.66546630859375\n",
      "\n",
      "episode 12, val func loss 0.6386416554450989\n",
      "\n",
      "episode 13, val func loss 0.5866856575012207\n",
      "\n",
      "episode 14, val func loss 0.5667679309844971\n",
      "\n",
      "episode 15, val func loss 0.5951855182647705\n",
      "\n",
      "episode 16, val func loss 0.7014766335487366\n",
      "\n",
      "Val func train loss in epoch 8:0.6469438746571541\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6923630237579346\n",
      "\n",
      "episode 2, val func loss 0.67093425989151\n",
      "\n",
      "episode 3, val func loss 0.6165404319763184\n",
      "\n",
      "episode 4, val func loss 0.6579087376594543\n",
      "\n",
      "episode 5, val func loss 0.6036705374717712\n",
      "\n",
      "episode 6, val func loss 0.6228816509246826\n",
      "\n",
      "episode 7, val func loss 0.6082196831703186\n",
      "\n",
      "episode 8, val func loss 0.5605790615081787\n",
      "\n",
      "episode 9, val func loss 0.5804153084754944\n",
      "\n",
      "episode 10, val func loss 0.5609983205795288\n",
      "\n",
      "episode 11, val func loss 0.6571491956710815\n",
      "\n",
      "episode 12, val func loss 0.584097683429718\n",
      "\n",
      "episode 13, val func loss 0.6602922677993774\n",
      "\n",
      "episode 14, val func loss 0.5734773278236389\n",
      "\n",
      "episode 15, val func loss 0.6494787335395813\n",
      "\n",
      "episode 16, val func loss 0.6817172765731812\n",
      "\n",
      "Val func train loss in epoch 9:0.6237952187657356\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6570758819580078\n",
      "\n",
      "episode 2, val func loss 0.588608980178833\n",
      "\n",
      "episode 3, val func loss 0.653306245803833\n",
      "\n",
      "episode 4, val func loss 0.6700973510742188\n",
      "\n",
      "episode 5, val func loss 0.6117405295372009\n",
      "\n",
      "episode 6, val func loss 0.6896228790283203\n",
      "\n",
      "episode 7, val func loss 0.5941445827484131\n",
      "\n",
      "episode 8, val func loss 0.5807256698608398\n",
      "\n",
      "episode 9, val func loss 0.5697261691093445\n",
      "\n",
      "episode 10, val func loss 0.5341779589653015\n",
      "\n",
      "episode 11, val func loss 0.5886110663414001\n",
      "\n",
      "episode 12, val func loss 0.6089184284210205\n",
      "\n",
      "episode 13, val func loss 0.5904585719108582\n",
      "\n",
      "episode 14, val func loss 0.586017906665802\n",
      "\n",
      "episode 15, val func loss 0.5515938401222229\n",
      "\n",
      "episode 16, val func loss 0.6105116009712219\n",
      "\n",
      "Val func train loss in epoch 10:0.6053336039185524\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6282846927642822\n",
      "\n",
      "episode 2, val func loss 0.5710886120796204\n",
      "\n",
      "episode 3, val func loss 0.5989084839820862\n",
      "\n",
      "episode 4, val func loss 0.6054772734642029\n",
      "\n",
      "episode 5, val func loss 0.7085838317871094\n",
      "\n",
      "episode 6, val func loss 0.5865359306335449\n",
      "\n",
      "episode 7, val func loss 0.66724693775177\n",
      "\n",
      "episode 8, val func loss 0.6192376017570496\n",
      "\n",
      "episode 9, val func loss 0.630851149559021\n",
      "\n",
      "episode 10, val func loss 0.5700047016143799\n",
      "\n",
      "episode 11, val func loss 0.6558982133865356\n",
      "\n",
      "episode 12, val func loss 0.6430819034576416\n",
      "\n",
      "episode 13, val func loss 0.6116724014282227\n",
      "\n",
      "episode 14, val func loss 0.6623939275741577\n",
      "\n",
      "episode 15, val func loss 0.5946663022041321\n",
      "\n",
      "episode 16, val func loss 0.5894585847854614\n",
      "\n",
      "Val func train loss in epoch 11:0.6214619092643261\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7373682260513306\n",
      "\n",
      "episode 2, val func loss 0.6519492864608765\n",
      "\n",
      "episode 3, val func loss 0.6836087107658386\n",
      "\n",
      "episode 4, val func loss 0.6489827632904053\n",
      "\n",
      "episode 5, val func loss 0.7549561262130737\n",
      "\n",
      "episode 6, val func loss 0.593842089176178\n",
      "\n",
      "episode 7, val func loss 0.6788938641548157\n",
      "\n",
      "episode 8, val func loss 0.7449329495429993\n",
      "\n",
      "episode 9, val func loss 0.6397439241409302\n",
      "\n",
      "episode 10, val func loss 0.6905918717384338\n",
      "\n",
      "episode 11, val func loss 0.642920196056366\n",
      "\n",
      "episode 12, val func loss 0.6501118540763855\n",
      "\n",
      "episode 13, val func loss 0.558307409286499\n",
      "\n",
      "episode 14, val func loss 0.7189241647720337\n",
      "\n",
      "episode 15, val func loss 0.6480717062950134\n",
      "\n",
      "episode 16, val func loss 0.5539330840110779\n",
      "\n",
      "Val func train loss in epoch 12:0.6623211391270161\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.7033002376556396\n",
      "\n",
      "episode 2, val func loss 0.6262456178665161\n",
      "\n",
      "episode 3, val func loss 0.6714545488357544\n",
      "\n",
      "episode 4, val func loss 0.6003096699714661\n",
      "\n",
      "episode 5, val func loss 0.5889355540275574\n",
      "\n",
      "episode 6, val func loss 0.54644376039505\n",
      "\n",
      "episode 7, val func loss 0.6535739898681641\n",
      "\n",
      "episode 8, val func loss 0.5732024908065796\n",
      "\n",
      "episode 9, val func loss 0.5761211514472961\n",
      "\n",
      "episode 10, val func loss 0.5537862181663513\n",
      "\n",
      "episode 11, val func loss 0.5313892960548401\n",
      "\n",
      "episode 12, val func loss 0.532082200050354\n",
      "\n",
      "episode 13, val func loss 0.6935705542564392\n",
      "\n",
      "episode 14, val func loss 0.5686122179031372\n",
      "\n",
      "episode 15, val func loss 0.6451006531715393\n",
      "\n",
      "episode 16, val func loss 0.6602844595909119\n",
      "\n",
      "Val func train loss in epoch 13:0.6077757887542248\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.5064857602119446\n",
      "\n",
      "episode 2, val func loss 0.6654983162879944\n",
      "\n",
      "episode 3, val func loss 0.6655247211456299\n",
      "\n",
      "episode 4, val func loss 0.5904853940010071\n",
      "\n",
      "episode 5, val func loss 0.708429753780365\n",
      "\n",
      "episode 6, val func loss 0.6670434474945068\n",
      "\n",
      "episode 7, val func loss 0.6036539673805237\n",
      "\n",
      "episode 8, val func loss 0.559311032295227\n",
      "\n",
      "episode 9, val func loss 0.5358287692070007\n",
      "\n",
      "episode 10, val func loss 0.7686002254486084\n",
      "\n",
      "episode 11, val func loss 0.5944549441337585\n",
      "\n",
      "episode 12, val func loss 0.5533331632614136\n",
      "\n",
      "episode 13, val func loss 0.553432822227478\n",
      "\n",
      "episode 14, val func loss 0.5869278311729431\n",
      "\n",
      "episode 15, val func loss 0.5586503744125366\n",
      "\n",
      "episode 16, val func loss 0.7126643061637878\n",
      "\n",
      "Val func train loss in epoch 14:0.6143953017890453\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.5896232724189758\n",
      "\n",
      "episode 2, val func loss 0.5341817736625671\n",
      "\n",
      "episode 3, val func loss 0.7026207447052002\n",
      "\n",
      "episode 4, val func loss 0.6736102104187012\n",
      "\n",
      "episode 5, val func loss 0.6462490558624268\n",
      "\n",
      "episode 6, val func loss 0.607300877571106\n",
      "\n",
      "episode 7, val func loss 0.5846230387687683\n",
      "\n",
      "episode 8, val func loss 0.6066710352897644\n",
      "\n",
      "episode 9, val func loss 0.7028695940971375\n",
      "\n",
      "episode 10, val func loss 0.6914027333259583\n",
      "\n",
      "episode 11, val func loss 0.6833183765411377\n",
      "\n",
      "episode 12, val func loss 0.6307603120803833\n",
      "\n",
      "episode 13, val func loss 0.5822978615760803\n",
      "\n",
      "episode 14, val func loss 0.6881086826324463\n",
      "\n",
      "episode 15, val func loss 0.6927428841590881\n",
      "\n",
      "episode 16, val func loss 0.5965641140937805\n",
      "\n",
      "Val func train loss in epoch 15:0.6383090354502201\n",
      "***********************TIME WAS 4.924849911530813 min*****************************\n",
      "\n",
      "**********************ROUND 129 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.1176319122314453\n",
      "\n",
      "episode 2, policy loss 1.1176319122314453\n",
      "\n",
      "episode 3, policy loss 1.1176317930221558\n",
      "\n",
      "episode 4, policy loss 1.1176319122314453\n",
      "\n",
      "episode 5, policy loss 1.1176319122314453\n",
      "\n",
      "episode 6, policy loss 1.1176319122314453\n",
      "\n",
      "episode 7, policy loss 1.1176319122314453\n",
      "\n",
      "episode 8, policy loss 1.1176319122314453\n",
      "\n",
      "episode 9, policy loss 1.1176319122314453\n",
      "\n",
      "episode 10, policy loss 1.1176319122314453\n",
      "\n",
      "episode 11, policy loss 1.1176319122314453\n",
      "\n",
      "episode 12, policy loss 1.1176319122314453\n",
      "\n",
      "episode 13, policy loss 1.1176319122314453\n",
      "\n",
      "episode 14, policy loss 1.1176319122314453\n",
      "\n",
      "episode 15, policy loss 1.1176319122314453\n",
      "\n",
      "episode 16, policy loss 1.1176319122314453\n",
      "\n",
      "Policy train loss in epoch 0:1.1176319047808647\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.1176319122314453\n",
      "\n",
      "episode 2, policy loss 1.1176319122314453\n",
      "\n",
      "episode 3, policy loss 1.1176319122314453\n",
      "\n",
      "episode 4, policy loss 1.1176319122314453\n",
      "\n",
      "episode 5, policy loss 1.1176317930221558\n",
      "\n",
      "episode 6, policy loss 1.1176317930221558\n",
      "\n",
      "episode 7, policy loss 1.1176319122314453\n",
      "\n",
      "episode 8, policy loss 1.1176319122314453\n",
      "\n",
      "episode 9, policy loss 1.1176319122314453\n",
      "\n",
      "episode 10, policy loss 1.1176319122314453\n",
      "\n",
      "episode 11, policy loss 1.1176319122314453\n",
      "\n",
      "episode 12, policy loss 1.1176320314407349\n",
      "\n",
      "episode 13, policy loss 1.1176319122314453\n",
      "\n",
      "episode 14, policy loss 1.1176319122314453\n",
      "\n",
      "episode 15, policy loss 1.1176316738128662\n",
      "\n",
      "episode 16, policy loss 1.1176317930221558\n",
      "\n",
      "Policy train loss in epoch 1:1.117631882429123\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.1176319122314453\n",
      "\n",
      "episode 2, policy loss 1.1176317930221558\n",
      "\n",
      "episode 3, policy loss 1.1176319122314453\n",
      "\n",
      "episode 4, policy loss 1.1176319122314453\n",
      "\n",
      "episode 5, policy loss 1.1176319122314453\n",
      "\n",
      "episode 6, policy loss 1.1176316738128662\n",
      "\n",
      "episode 7, policy loss 1.1176319122314453\n",
      "\n",
      "episode 8, policy loss 1.1176319122314453\n",
      "\n",
      "episode 9, policy loss 1.1176317930221558\n",
      "\n",
      "episode 10, policy loss 1.1176319122314453\n",
      "\n",
      "episode 11, policy loss 1.1176319122314453\n",
      "\n",
      "episode 12, policy loss 1.1176319122314453\n",
      "\n",
      "episode 13, policy loss 1.1176317930221558\n",
      "\n",
      "episode 14, policy loss 1.1176319122314453\n",
      "\n",
      "episode 15, policy loss 1.1176319122314453\n",
      "\n",
      "episode 16, policy loss 1.1176317930221558\n",
      "\n",
      "Policy train loss in epoch 2:1.1176318675279617\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.1176317930221558\n",
      "\n",
      "episode 2, policy loss 1.1176319122314453\n",
      "\n",
      "episode 3, policy loss 1.1176319122314453\n",
      "\n",
      "episode 4, policy loss 1.1176319122314453\n",
      "\n",
      "episode 5, policy loss 1.1176317930221558\n",
      "\n",
      "episode 6, policy loss 1.1176319122314453\n",
      "\n",
      "episode 7, policy loss 1.1176319122314453\n",
      "\n",
      "episode 8, policy loss 1.1176319122314453\n",
      "\n",
      "episode 9, policy loss 1.1176319122314453\n",
      "\n",
      "episode 10, policy loss 1.1176319122314453\n",
      "\n",
      "episode 11, policy loss 1.1176319122314453\n",
      "\n",
      "episode 12, policy loss 1.1176317930221558\n",
      "\n",
      "episode 13, policy loss 1.1176319122314453\n",
      "\n",
      "episode 14, policy loss 1.1176319122314453\n",
      "\n",
      "episode 15, policy loss 1.1176317930221558\n",
      "\n",
      "episode 16, policy loss 1.1176317930221558\n",
      "\n",
      "Policy train loss in epoch 3:1.1176318749785423\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.6720514893531799\n",
      "\n",
      "episode 2, val func loss 0.6590451598167419\n",
      "\n",
      "episode 3, val func loss 0.5986074805259705\n",
      "\n",
      "episode 4, val func loss 0.6465916633605957\n",
      "\n",
      "episode 5, val func loss 0.6346139907836914\n",
      "\n",
      "episode 6, val func loss 0.6138047575950623\n",
      "\n",
      "episode 7, val func loss 0.6804745197296143\n",
      "\n",
      "episode 8, val func loss 0.5898903608322144\n",
      "\n",
      "episode 9, val func loss 0.6574851274490356\n",
      "\n",
      "episode 10, val func loss 0.6217318773269653\n",
      "\n",
      "episode 11, val func loss 0.581439733505249\n",
      "\n",
      "episode 12, val func loss 0.6258519291877747\n",
      "\n",
      "episode 13, val func loss 0.711894690990448\n",
      "\n",
      "episode 14, val func loss 0.5917865037918091\n",
      "\n",
      "episode 15, val func loss 0.6041022539138794\n",
      "\n",
      "episode 16, val func loss 0.6139779686927795\n",
      "\n",
      "Val func train loss in epoch 0:0.6314593441784382\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.6306339502334595\n",
      "\n",
      "episode 2, val func loss 0.5313953757286072\n",
      "\n",
      "episode 3, val func loss 0.6572490930557251\n",
      "\n",
      "episode 4, val func loss 0.5335294008255005\n",
      "\n",
      "episode 5, val func loss 0.5800188183784485\n",
      "\n",
      "episode 6, val func loss 0.5661010146141052\n",
      "\n",
      "episode 7, val func loss 0.5700103640556335\n",
      "\n",
      "episode 8, val func loss 0.637824535369873\n",
      "\n",
      "episode 9, val func loss 0.7098934650421143\n",
      "\n",
      "episode 10, val func loss 0.530746579170227\n",
      "\n",
      "episode 11, val func loss 0.5637218952178955\n",
      "\n",
      "episode 12, val func loss 0.4947184920310974\n",
      "\n",
      "episode 13, val func loss 0.7420840263366699\n",
      "\n",
      "episode 14, val func loss 0.6944712996482849\n",
      "\n",
      "episode 15, val func loss 0.5384542346000671\n",
      "\n",
      "episode 16, val func loss 0.6742498874664307\n",
      "\n",
      "Val func train loss in epoch 1:0.6034439019858837\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6797560453414917\n",
      "\n",
      "episode 2, val func loss 0.7446019053459167\n",
      "\n",
      "episode 3, val func loss 0.6719278693199158\n",
      "\n",
      "episode 4, val func loss 0.7025992274284363\n",
      "\n",
      "episode 5, val func loss 0.7238160967826843\n",
      "\n",
      "episode 6, val func loss 0.623214840888977\n",
      "\n",
      "episode 7, val func loss 0.6650753021240234\n",
      "\n",
      "episode 8, val func loss 0.5937865972518921\n",
      "\n",
      "episode 9, val func loss 0.5453032851219177\n",
      "\n",
      "episode 10, val func loss 0.7003900408744812\n",
      "\n",
      "episode 11, val func loss 0.6258145570755005\n",
      "\n",
      "episode 12, val func loss 0.6215188503265381\n",
      "\n",
      "episode 13, val func loss 0.7013800144195557\n",
      "\n",
      "episode 14, val func loss 0.5722639560699463\n",
      "\n",
      "episode 15, val func loss 0.6201553344726562\n",
      "\n",
      "episode 16, val func loss 0.6165261268615723\n",
      "\n",
      "Val func train loss in epoch 2:0.6505081281065941\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.635890543460846\n",
      "\n",
      "episode 2, val func loss 0.7092517614364624\n",
      "\n",
      "episode 3, val func loss 0.6482072472572327\n",
      "\n",
      "episode 4, val func loss 0.6196874380111694\n",
      "\n",
      "episode 5, val func loss 0.5957297682762146\n",
      "\n",
      "episode 6, val func loss 0.6159799695014954\n",
      "\n",
      "episode 7, val func loss 0.6646506786346436\n",
      "\n",
      "episode 8, val func loss 0.6297281384468079\n",
      "\n",
      "episode 9, val func loss 0.6308683156967163\n",
      "\n",
      "episode 10, val func loss 0.6964051127433777\n",
      "\n",
      "episode 11, val func loss 0.6048845648765564\n",
      "\n",
      "episode 12, val func loss 0.5653130412101746\n",
      "\n",
      "episode 13, val func loss 0.6797803044319153\n",
      "\n",
      "episode 14, val func loss 0.6768287420272827\n",
      "\n",
      "episode 15, val func loss 0.6030941009521484\n",
      "\n",
      "episode 16, val func loss 0.7553277611732483\n",
      "\n",
      "Val func train loss in epoch 3:0.6457267180085182\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7093051671981812\n",
      "\n",
      "episode 2, val func loss 0.6553654670715332\n",
      "\n",
      "episode 3, val func loss 0.6680278778076172\n",
      "\n",
      "episode 4, val func loss 0.5661414861679077\n",
      "\n",
      "episode 5, val func loss 0.5807815790176392\n",
      "\n",
      "episode 6, val func loss 0.6173499822616577\n",
      "\n",
      "episode 7, val func loss 0.6214900016784668\n",
      "\n",
      "episode 8, val func loss 0.5795488953590393\n",
      "\n",
      "episode 9, val func loss 0.6756647229194641\n",
      "\n",
      "episode 10, val func loss 0.6536178588867188\n",
      "\n",
      "episode 11, val func loss 0.5835893750190735\n",
      "\n",
      "episode 12, val func loss 0.5412576794624329\n",
      "\n",
      "episode 13, val func loss 0.5816906094551086\n",
      "\n",
      "episode 14, val func loss 0.584169328212738\n",
      "\n",
      "episode 15, val func loss 0.7868403792381287\n",
      "\n",
      "episode 16, val func loss 0.6318972110748291\n",
      "\n",
      "Val func train loss in epoch 4:0.6272961013019085\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6739131212234497\n",
      "\n",
      "episode 2, val func loss 0.6149379014968872\n",
      "\n",
      "episode 3, val func loss 0.6720302700996399\n",
      "\n",
      "episode 4, val func loss 0.5973446369171143\n",
      "\n",
      "episode 5, val func loss 0.6158871054649353\n",
      "\n",
      "episode 6, val func loss 0.7046399712562561\n",
      "\n",
      "episode 7, val func loss 0.752350926399231\n",
      "\n",
      "episode 8, val func loss 0.5640448927879333\n",
      "\n",
      "episode 9, val func loss 0.5920491814613342\n",
      "\n",
      "episode 10, val func loss 0.6808233261108398\n",
      "\n",
      "episode 11, val func loss 0.620456874370575\n",
      "\n",
      "episode 12, val func loss 0.7041259407997131\n",
      "\n",
      "episode 13, val func loss 0.5306370258331299\n",
      "\n",
      "episode 14, val func loss 0.7035301923751831\n",
      "\n",
      "episode 15, val func loss 0.5762441158294678\n",
      "\n",
      "episode 16, val func loss 0.5086977481842041\n",
      "\n",
      "Val func train loss in epoch 5:0.6319820769131184\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7005530595779419\n",
      "\n",
      "episode 2, val func loss 0.6510114073753357\n",
      "\n",
      "episode 3, val func loss 0.7398837804794312\n",
      "\n",
      "episode 4, val func loss 0.7863149642944336\n",
      "\n",
      "episode 5, val func loss 0.616482675075531\n",
      "\n",
      "episode 6, val func loss 0.667263388633728\n",
      "\n",
      "episode 7, val func loss 0.7138140201568604\n",
      "\n",
      "episode 8, val func loss 0.70368891954422\n",
      "\n",
      "episode 9, val func loss 0.8029698133468628\n",
      "\n",
      "episode 10, val func loss 0.7440623641014099\n",
      "\n",
      "episode 11, val func loss 0.649017870426178\n",
      "\n",
      "episode 12, val func loss 0.6249740719795227\n",
      "\n",
      "episode 13, val func loss 0.6358403563499451\n",
      "\n",
      "episode 14, val func loss 0.6279565691947937\n",
      "\n",
      "episode 15, val func loss 0.6821776628494263\n",
      "\n",
      "episode 16, val func loss 0.565090537071228\n",
      "\n",
      "Val func train loss in epoch 6:0.681943841278553\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.5782283544540405\n",
      "\n",
      "episode 2, val func loss 0.6284639239311218\n",
      "\n",
      "episode 3, val func loss 0.6679784655570984\n",
      "\n",
      "episode 4, val func loss 0.6435232758522034\n",
      "\n",
      "episode 5, val func loss 0.7132440805435181\n",
      "\n",
      "episode 6, val func loss 0.710456132888794\n",
      "\n",
      "episode 7, val func loss 0.5456966757774353\n",
      "\n",
      "episode 8, val func loss 0.7762050628662109\n",
      "\n",
      "episode 9, val func loss 0.7270113229751587\n",
      "\n",
      "episode 10, val func loss 0.5907756686210632\n",
      "\n",
      "episode 11, val func loss 0.611230194568634\n",
      "\n",
      "episode 12, val func loss 0.67995285987854\n",
      "\n",
      "episode 13, val func loss 0.7359470129013062\n",
      "\n",
      "episode 14, val func loss 0.6626612544059753\n",
      "\n",
      "episode 15, val func loss 0.7985025644302368\n",
      "\n",
      "episode 16, val func loss 0.6287624835968018\n",
      "\n",
      "Val func train loss in epoch 7:0.6686649583280087\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6324348449707031\n",
      "\n",
      "episode 2, val func loss 0.6978123784065247\n",
      "\n",
      "episode 3, val func loss 0.6232627630233765\n",
      "\n",
      "episode 4, val func loss 0.7919580340385437\n",
      "\n",
      "episode 5, val func loss 0.7153703570365906\n",
      "\n",
      "episode 6, val func loss 0.6490052938461304\n",
      "\n",
      "episode 7, val func loss 0.5664293766021729\n",
      "\n",
      "episode 8, val func loss 0.5694606900215149\n",
      "\n",
      "episode 9, val func loss 0.6877434253692627\n",
      "\n",
      "episode 10, val func loss 0.7217040657997131\n",
      "\n",
      "episode 11, val func loss 0.6191564202308655\n",
      "\n",
      "episode 12, val func loss 0.6798821091651917\n",
      "\n",
      "episode 13, val func loss 0.5835487842559814\n",
      "\n",
      "episode 14, val func loss 0.6461036801338196\n",
      "\n",
      "episode 15, val func loss 0.5838907361030579\n",
      "\n",
      "episode 16, val func loss 0.6885014772415161\n",
      "\n",
      "Val func train loss in epoch 8:0.6535165272653103\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6922626495361328\n",
      "\n",
      "episode 2, val func loss 0.6261478066444397\n",
      "\n",
      "episode 3, val func loss 0.6710658073425293\n",
      "\n",
      "episode 4, val func loss 0.5919367074966431\n",
      "\n",
      "episode 5, val func loss 0.5842350721359253\n",
      "\n",
      "episode 6, val func loss 0.6734243035316467\n",
      "\n",
      "episode 7, val func loss 0.6446384787559509\n",
      "\n",
      "episode 8, val func loss 0.724609911441803\n",
      "\n",
      "episode 9, val func loss 0.7211540341377258\n",
      "\n",
      "episode 10, val func loss 0.6892860531806946\n",
      "\n",
      "episode 11, val func loss 0.5910342931747437\n",
      "\n",
      "episode 12, val func loss 0.7510244846343994\n",
      "\n",
      "episode 13, val func loss 0.6902195811271667\n",
      "\n",
      "episode 14, val func loss 0.7341089248657227\n",
      "\n",
      "episode 15, val func loss 0.6826716661453247\n",
      "\n",
      "episode 16, val func loss 0.6625609397888184\n",
      "\n",
      "Val func train loss in epoch 9:0.6706487946212292\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.5874801278114319\n",
      "\n",
      "episode 2, val func loss 0.6015586256980896\n",
      "\n",
      "episode 3, val func loss 0.7479228377342224\n",
      "\n",
      "episode 4, val func loss 0.6017090678215027\n",
      "\n",
      "episode 5, val func loss 0.6326612234115601\n",
      "\n",
      "episode 6, val func loss 0.6101601123809814\n",
      "\n",
      "episode 7, val func loss 0.6726403832435608\n",
      "\n",
      "episode 8, val func loss 0.5721138119697571\n",
      "\n",
      "episode 9, val func loss 0.6314699649810791\n",
      "\n",
      "episode 10, val func loss 0.6641590595245361\n",
      "\n",
      "episode 11, val func loss 0.5840725302696228\n",
      "\n",
      "episode 12, val func loss 0.6885363459587097\n",
      "\n",
      "episode 13, val func loss 0.6402322053909302\n",
      "\n",
      "episode 14, val func loss 0.6153682470321655\n",
      "\n",
      "episode 15, val func loss 0.6331031918525696\n",
      "\n",
      "episode 16, val func loss 0.6559111475944519\n",
      "\n",
      "Val func train loss in epoch 10:0.6336936801671982\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6384573578834534\n",
      "\n",
      "episode 2, val func loss 0.6882800459861755\n",
      "\n",
      "episode 3, val func loss 0.6530324220657349\n",
      "\n",
      "episode 4, val func loss 0.6583635807037354\n",
      "\n",
      "episode 5, val func loss 0.6520957350730896\n",
      "\n",
      "episode 6, val func loss 0.6330150365829468\n",
      "\n",
      "episode 7, val func loss 0.6669735312461853\n",
      "\n",
      "episode 8, val func loss 0.5935546159744263\n",
      "\n",
      "episode 9, val func loss 0.613663911819458\n",
      "\n",
      "episode 10, val func loss 0.6302639842033386\n",
      "\n",
      "episode 11, val func loss 0.6655034422874451\n",
      "\n",
      "episode 12, val func loss 0.618583619594574\n",
      "\n",
      "episode 13, val func loss 0.6668974757194519\n",
      "\n",
      "episode 14, val func loss 0.6035967469215393\n",
      "\n",
      "episode 15, val func loss 0.6046865582466125\n",
      "\n",
      "episode 16, val func loss 0.6380693912506104\n",
      "\n",
      "Val func train loss in epoch 11:0.6390648409724236\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.5987196564674377\n",
      "\n",
      "episode 2, val func loss 0.5060480237007141\n",
      "\n",
      "episode 3, val func loss 0.5651372075080872\n",
      "\n",
      "episode 4, val func loss 0.6911182403564453\n",
      "\n",
      "episode 5, val func loss 0.6170216798782349\n",
      "\n",
      "episode 6, val func loss 0.6199454665184021\n",
      "\n",
      "episode 7, val func loss 0.6323168277740479\n",
      "\n",
      "episode 8, val func loss 0.5814226269721985\n",
      "\n",
      "episode 9, val func loss 0.583613395690918\n",
      "\n",
      "episode 10, val func loss 0.6211117506027222\n",
      "\n",
      "episode 11, val func loss 0.636361837387085\n",
      "\n",
      "episode 12, val func loss 0.7403379678726196\n",
      "\n",
      "episode 13, val func loss 0.5584646463394165\n",
      "\n",
      "episode 14, val func loss 0.5846341848373413\n",
      "\n",
      "episode 15, val func loss 0.6116018295288086\n",
      "\n",
      "episode 16, val func loss 0.5617178082466125\n",
      "\n",
      "Val func train loss in epoch 12:0.6068483218550682\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.5758068561553955\n",
      "\n",
      "episode 2, val func loss 0.5908152461051941\n",
      "\n",
      "episode 3, val func loss 0.5938082933425903\n",
      "\n",
      "episode 4, val func loss 0.6233885884284973\n",
      "\n",
      "episode 5, val func loss 0.6236555576324463\n",
      "\n",
      "episode 6, val func loss 0.6326215863227844\n",
      "\n",
      "episode 7, val func loss 0.5467745661735535\n",
      "\n",
      "episode 8, val func loss 0.611396849155426\n",
      "\n",
      "episode 9, val func loss 0.5413126945495605\n",
      "\n",
      "episode 10, val func loss 0.6182774901390076\n",
      "\n",
      "episode 11, val func loss 0.6122186183929443\n",
      "\n",
      "episode 12, val func loss 0.6285406947135925\n",
      "\n",
      "episode 13, val func loss 0.6436206102371216\n",
      "\n",
      "episode 14, val func loss 0.585297167301178\n",
      "\n",
      "episode 15, val func loss 0.605042040348053\n",
      "\n",
      "episode 16, val func loss 0.6416991949081421\n",
      "\n",
      "Val func train loss in epoch 13:0.6046422533690929\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.5888254642486572\n",
      "\n",
      "episode 2, val func loss 0.6758142113685608\n",
      "\n",
      "episode 3, val func loss 0.6183488368988037\n",
      "\n",
      "episode 4, val func loss 0.6176713705062866\n",
      "\n",
      "episode 5, val func loss 0.6366184949874878\n",
      "\n",
      "episode 6, val func loss 0.548908531665802\n",
      "\n",
      "episode 7, val func loss 0.5793436169624329\n",
      "\n",
      "episode 8, val func loss 0.6777220964431763\n",
      "\n",
      "episode 9, val func loss 0.631791889667511\n",
      "\n",
      "episode 10, val func loss 0.5518500208854675\n",
      "\n",
      "episode 11, val func loss 0.7025858759880066\n",
      "\n",
      "episode 12, val func loss 0.5752105712890625\n",
      "\n",
      "episode 13, val func loss 0.6208024024963379\n",
      "\n",
      "episode 14, val func loss 0.5895641446113586\n",
      "\n",
      "episode 15, val func loss 0.6359408497810364\n",
      "\n",
      "episode 16, val func loss 0.5965366363525391\n",
      "\n",
      "Val func train loss in epoch 14:0.6154709383845329\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.5997483730316162\n",
      "\n",
      "episode 2, val func loss 0.6908032894134521\n",
      "\n",
      "episode 3, val func loss 0.7189093828201294\n",
      "\n",
      "episode 4, val func loss 0.5909819602966309\n",
      "\n",
      "episode 5, val func loss 0.6013979315757751\n",
      "\n",
      "episode 6, val func loss 0.6218642592430115\n",
      "\n",
      "episode 7, val func loss 0.5941414833068848\n",
      "\n",
      "episode 8, val func loss 0.6245148777961731\n",
      "\n",
      "episode 9, val func loss 0.7019091844558716\n",
      "\n",
      "episode 10, val func loss 0.6645662784576416\n",
      "\n",
      "episode 11, val func loss 0.6758979558944702\n",
      "\n",
      "episode 12, val func loss 0.751287043094635\n",
      "\n",
      "episode 13, val func loss 0.544037401676178\n",
      "\n",
      "episode 14, val func loss 0.6495190858840942\n",
      "\n",
      "episode 15, val func loss 0.6203374266624451\n",
      "\n",
      "episode 16, val func loss 0.6032522916793823\n",
      "\n",
      "Val func train loss in epoch 15:0.6408230140805244\n",
      "***********************TIME WAS 4.924449626604716 min*****************************\n",
      "\n",
      "**********************ROUND 130 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.0860671997070312\n",
      "\n",
      "episode 2, policy loss 1.0860671997070312\n",
      "\n",
      "episode 3, policy loss 1.0860671997070312\n",
      "\n",
      "episode 4, policy loss 1.0860671997070312\n",
      "\n",
      "episode 5, policy loss 1.0860671997070312\n",
      "\n",
      "episode 6, policy loss 1.0860673189163208\n",
      "\n",
      "episode 7, policy loss 1.0860671997070312\n",
      "\n",
      "episode 8, policy loss 1.0860674381256104\n",
      "\n",
      "episode 9, policy loss 1.0860671997070312\n",
      "\n",
      "episode 10, policy loss 1.0860671997070312\n",
      "\n",
      "episode 11, policy loss 1.0860671997070312\n",
      "\n",
      "episode 12, policy loss 1.0860671997070312\n",
      "\n",
      "episode 13, policy loss 1.0860673189163208\n",
      "\n",
      "episode 14, policy loss 1.0860671997070312\n",
      "\n",
      "episode 15, policy loss 1.0860671997070312\n",
      "\n",
      "episode 16, policy loss 1.0860670804977417\n",
      "\n",
      "Policy train loss in epoch 0:1.086067222058773\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.0860671997070312\n",
      "\n",
      "episode 2, policy loss 1.0860671997070312\n",
      "\n",
      "episode 3, policy loss 1.0860671997070312\n",
      "\n",
      "episode 4, policy loss 1.0860670804977417\n",
      "\n",
      "episode 5, policy loss 1.0860670804977417\n",
      "\n",
      "episode 6, policy loss 1.0860670804977417\n",
      "\n",
      "episode 7, policy loss 1.0860671997070312\n",
      "\n",
      "episode 8, policy loss 1.0860671997070312\n",
      "\n",
      "episode 9, policy loss 1.0860668420791626\n",
      "\n",
      "episode 10, policy loss 1.0860670804977417\n",
      "\n",
      "episode 11, policy loss 1.0860671997070312\n",
      "\n",
      "episode 12, policy loss 1.0860671997070312\n",
      "\n",
      "episode 13, policy loss 1.0860671997070312\n",
      "\n",
      "episode 14, policy loss 1.0860670804977417\n",
      "\n",
      "episode 15, policy loss 1.0860671997070312\n",
      "\n",
      "episode 16, policy loss 1.0860669612884521\n",
      "\n",
      "Policy train loss in epoch 1:1.0860671252012253\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.0860671997070312\n",
      "\n",
      "episode 2, policy loss 1.0860670804977417\n",
      "\n",
      "episode 3, policy loss 1.0860670804977417\n",
      "\n",
      "episode 4, policy loss 1.086066722869873\n",
      "\n",
      "episode 5, policy loss 1.0860671997070312\n",
      "\n",
      "episode 6, policy loss 1.0860669612884521\n",
      "\n",
      "episode 7, policy loss 1.0860670804977417\n",
      "\n",
      "episode 8, policy loss 1.0860668420791626\n",
      "\n",
      "episode 9, policy loss 1.0860668420791626\n",
      "\n",
      "episode 10, policy loss 1.086066484451294\n",
      "\n",
      "episode 11, policy loss 1.086066484451294\n",
      "\n",
      "episode 12, policy loss 1.0860662460327148\n",
      "\n",
      "episode 13, policy loss 1.086066484451294\n",
      "\n",
      "episode 14, policy loss 1.0860662460327148\n",
      "\n",
      "episode 15, policy loss 1.0860658884048462\n",
      "\n",
      "episode 16, policy loss 1.086065649986267\n",
      "\n",
      "Policy train loss in epoch 2:1.0860666558146477\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.086065649986267\n",
      "\n",
      "episode 2, policy loss 1.086065649986267\n",
      "\n",
      "episode 3, policy loss 1.086065649986267\n",
      "\n",
      "episode 4, policy loss 1.0860652923583984\n",
      "\n",
      "episode 5, policy loss 1.0860650539398193\n",
      "\n",
      "episode 6, policy loss 1.0860649347305298\n",
      "\n",
      "episode 7, policy loss 1.0860649347305298\n",
      "\n",
      "episode 8, policy loss 1.0860645771026611\n",
      "\n",
      "episode 9, policy loss 1.0860644578933716\n",
      "\n",
      "episode 10, policy loss 1.0860636234283447\n",
      "\n",
      "episode 11, policy loss 1.0860625505447388\n",
      "\n",
      "episode 12, policy loss 1.0860611200332642\n",
      "\n",
      "episode 13, policy loss 1.0860594511032104\n",
      "\n",
      "episode 14, policy loss 1.0860563516616821\n",
      "\n",
      "episode 15, policy loss 1.0860503911972046\n",
      "\n",
      "episode 16, policy loss 1.0860414505004883\n",
      "\n",
      "Policy train loss in epoch 3:1.0860613211989403\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.581742525100708\n",
      "\n",
      "episode 2, val func loss 0.5928878784179688\n",
      "\n",
      "episode 3, val func loss 0.6050287485122681\n",
      "\n",
      "episode 4, val func loss 0.6797817349433899\n",
      "\n",
      "episode 5, val func loss 0.62047278881073\n",
      "\n",
      "episode 6, val func loss 0.6122915744781494\n",
      "\n",
      "episode 7, val func loss 0.6431018114089966\n",
      "\n",
      "episode 8, val func loss 0.5976135730743408\n",
      "\n",
      "episode 9, val func loss 0.5835146903991699\n",
      "\n",
      "episode 10, val func loss 0.6005040407180786\n",
      "\n",
      "episode 11, val func loss 0.6107011437416077\n",
      "\n",
      "episode 12, val func loss 0.5767611861228943\n",
      "\n",
      "episode 13, val func loss 0.7715504169464111\n",
      "\n",
      "episode 14, val func loss 0.6058138012886047\n",
      "\n",
      "episode 15, val func loss 0.4856868088245392\n",
      "\n",
      "episode 16, val func loss 0.6178910732269287\n",
      "\n",
      "Val func train loss in epoch 0:0.6115839872509241\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.5885382294654846\n",
      "\n",
      "episode 2, val func loss 0.5278051495552063\n",
      "\n",
      "episode 3, val func loss 0.5724461078643799\n",
      "\n",
      "episode 4, val func loss 0.6223859190940857\n",
      "\n",
      "episode 5, val func loss 0.7378481030464172\n",
      "\n",
      "episode 6, val func loss 0.5422008633613586\n",
      "\n",
      "episode 7, val func loss 0.790503978729248\n",
      "\n",
      "episode 8, val func loss 0.5969125628471375\n",
      "\n",
      "episode 9, val func loss 0.48611730337142944\n",
      "\n",
      "episode 10, val func loss 0.5718981623649597\n",
      "\n",
      "episode 11, val func loss 0.6493073105812073\n",
      "\n",
      "episode 12, val func loss 0.6731381416320801\n",
      "\n",
      "episode 13, val func loss 0.5871723890304565\n",
      "\n",
      "episode 14, val func loss 0.6537015438079834\n",
      "\n",
      "episode 15, val func loss 0.5678552389144897\n",
      "\n",
      "episode 16, val func loss 0.6925864219665527\n",
      "\n",
      "Val func train loss in epoch 1:0.6162760891020298\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.8070682287216187\n",
      "\n",
      "episode 2, val func loss 0.6865122318267822\n",
      "\n",
      "episode 3, val func loss 0.6866342425346375\n",
      "\n",
      "episode 4, val func loss 0.5370261073112488\n",
      "\n",
      "episode 5, val func loss 0.673228919506073\n",
      "\n",
      "episode 6, val func loss 0.6630657315254211\n",
      "\n",
      "episode 7, val func loss 0.6736913919448853\n",
      "\n",
      "episode 8, val func loss 0.5697831511497498\n",
      "\n",
      "episode 9, val func loss 0.6052459478378296\n",
      "\n",
      "episode 10, val func loss 0.6847234964370728\n",
      "\n",
      "episode 11, val func loss 0.5983472466468811\n",
      "\n",
      "episode 12, val func loss 0.6472570300102234\n",
      "\n",
      "episode 13, val func loss 0.6531808972358704\n",
      "\n",
      "episode 14, val func loss 0.7103535532951355\n",
      "\n",
      "episode 15, val func loss 0.5744145512580872\n",
      "\n",
      "episode 16, val func loss 0.5717765092849731\n",
      "\n",
      "Val func train loss in epoch 2:0.6463943272829056\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6988549828529358\n",
      "\n",
      "episode 2, val func loss 0.6452609300613403\n",
      "\n",
      "episode 3, val func loss 0.5637000799179077\n",
      "\n",
      "episode 4, val func loss 0.7142181396484375\n",
      "\n",
      "episode 5, val func loss 0.6772238612174988\n",
      "\n",
      "episode 6, val func loss 0.6674505472183228\n",
      "\n",
      "episode 7, val func loss 0.5811501741409302\n",
      "\n",
      "episode 8, val func loss 0.5454941391944885\n",
      "\n",
      "episode 9, val func loss 0.7206013202667236\n",
      "\n",
      "episode 10, val func loss 0.6161571145057678\n",
      "\n",
      "episode 11, val func loss 0.625192403793335\n",
      "\n",
      "episode 12, val func loss 0.540584921836853\n",
      "\n",
      "episode 13, val func loss 0.5731271505355835\n",
      "\n",
      "episode 14, val func loss 0.608912467956543\n",
      "\n",
      "episode 15, val func loss 0.6769719123840332\n",
      "\n",
      "episode 16, val func loss 0.6782853007316589\n",
      "\n",
      "Val func train loss in epoch 3:0.6333240903913975\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6755667328834534\n",
      "\n",
      "episode 2, val func loss 0.6677161455154419\n",
      "\n",
      "episode 3, val func loss 0.5972184538841248\n",
      "\n",
      "episode 4, val func loss 0.7064091563224792\n",
      "\n",
      "episode 5, val func loss 0.5921498537063599\n",
      "\n",
      "episode 6, val func loss 0.5935347676277161\n",
      "\n",
      "episode 7, val func loss 0.5521686673164368\n",
      "\n",
      "episode 8, val func loss 0.6608112454414368\n",
      "\n",
      "episode 9, val func loss 0.6314346194267273\n",
      "\n",
      "episode 10, val func loss 0.6040233969688416\n",
      "\n",
      "episode 11, val func loss 0.6147900819778442\n",
      "\n",
      "episode 12, val func loss 0.6458479762077332\n",
      "\n",
      "episode 13, val func loss 0.6343335509300232\n",
      "\n",
      "episode 14, val func loss 0.6081947684288025\n",
      "\n",
      "episode 15, val func loss 0.5986706614494324\n",
      "\n",
      "episode 16, val func loss 0.5717061161994934\n",
      "\n",
      "Val func train loss in epoch 4:0.6221610121428967\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6130161285400391\n",
      "\n",
      "episode 2, val func loss 0.6661292314529419\n",
      "\n",
      "episode 3, val func loss 0.6244264841079712\n",
      "\n",
      "episode 4, val func loss 0.6756917238235474\n",
      "\n",
      "episode 5, val func loss 0.5996118783950806\n",
      "\n",
      "episode 6, val func loss 0.6055986881256104\n",
      "\n",
      "episode 7, val func loss 0.630252480506897\n",
      "\n",
      "episode 8, val func loss 0.6202728748321533\n",
      "\n",
      "episode 9, val func loss 0.5689288377761841\n",
      "\n",
      "episode 10, val func loss 0.6736878752708435\n",
      "\n",
      "episode 11, val func loss 0.5543434619903564\n",
      "\n",
      "episode 12, val func loss 0.5398885011672974\n",
      "\n",
      "episode 13, val func loss 0.5591903328895569\n",
      "\n",
      "episode 14, val func loss 0.6127203106880188\n",
      "\n",
      "episode 15, val func loss 0.6197189092636108\n",
      "\n",
      "episode 16, val func loss 0.5658264756202698\n",
      "\n",
      "Val func train loss in epoch 5:0.6080815121531487\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.666650116443634\n",
      "\n",
      "episode 2, val func loss 0.7011988162994385\n",
      "\n",
      "episode 3, val func loss 0.5825250744819641\n",
      "\n",
      "episode 4, val func loss 0.6182070970535278\n",
      "\n",
      "episode 5, val func loss 0.7206575274467468\n",
      "\n",
      "episode 6, val func loss 0.6617897152900696\n",
      "\n",
      "episode 7, val func loss 0.551657497882843\n",
      "\n",
      "episode 8, val func loss 0.7167837619781494\n",
      "\n",
      "episode 9, val func loss 0.7388388514518738\n",
      "\n",
      "episode 10, val func loss 0.5340850353240967\n",
      "\n",
      "episode 11, val func loss 0.6700331568717957\n",
      "\n",
      "episode 12, val func loss 0.7288110256195068\n",
      "\n",
      "episode 13, val func loss 0.582537055015564\n",
      "\n",
      "episode 14, val func loss 0.5638908743858337\n",
      "\n",
      "episode 15, val func loss 0.7617850303649902\n",
      "\n",
      "episode 16, val func loss 0.7399084568023682\n",
      "\n",
      "Val func train loss in epoch 6:0.6587099432945251\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7037955522537231\n",
      "\n",
      "episode 2, val func loss 0.6348836421966553\n",
      "\n",
      "episode 3, val func loss 0.6485106348991394\n",
      "\n",
      "episode 4, val func loss 0.5669293403625488\n",
      "\n",
      "episode 5, val func loss 0.6588325500488281\n",
      "\n",
      "episode 6, val func loss 0.7476227879524231\n",
      "\n",
      "episode 7, val func loss 0.660037636756897\n",
      "\n",
      "episode 8, val func loss 0.6579828858375549\n",
      "\n",
      "episode 9, val func loss 0.5462913513183594\n",
      "\n",
      "episode 10, val func loss 0.7688804268836975\n",
      "\n",
      "episode 11, val func loss 0.5965373516082764\n",
      "\n",
      "episode 12, val func loss 0.6092978119850159\n",
      "\n",
      "episode 13, val func loss 0.60785311460495\n",
      "\n",
      "episode 14, val func loss 0.5926161408424377\n",
      "\n",
      "episode 15, val func loss 0.5390228033065796\n",
      "\n",
      "episode 16, val func loss 0.7620080709457397\n",
      "\n",
      "Val func train loss in epoch 7:0.6438188813626766\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6459158062934875\n",
      "\n",
      "episode 2, val func loss 0.6414334774017334\n",
      "\n",
      "episode 3, val func loss 0.5656025409698486\n",
      "\n",
      "episode 4, val func loss 0.5486636161804199\n",
      "\n",
      "episode 5, val func loss 0.6777450442314148\n",
      "\n",
      "episode 6, val func loss 0.6974122524261475\n",
      "\n",
      "episode 7, val func loss 0.6363130211830139\n",
      "\n",
      "episode 8, val func loss 0.5683874487876892\n",
      "\n",
      "episode 9, val func loss 0.7983114123344421\n",
      "\n",
      "episode 10, val func loss 0.5872484445571899\n",
      "\n",
      "episode 11, val func loss 0.6656039953231812\n",
      "\n",
      "episode 12, val func loss 0.5726722478866577\n",
      "\n",
      "episode 13, val func loss 0.6041461825370789\n",
      "\n",
      "episode 14, val func loss 0.6151542663574219\n",
      "\n",
      "episode 15, val func loss 0.614855170249939\n",
      "\n",
      "episode 16, val func loss 0.6427643895149231\n",
      "\n",
      "Val func train loss in epoch 8:0.6301393322646618\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6648396849632263\n",
      "\n",
      "episode 2, val func loss 0.6090877652168274\n",
      "\n",
      "episode 3, val func loss 0.6952999830245972\n",
      "\n",
      "episode 4, val func loss 0.5860629677772522\n",
      "\n",
      "episode 5, val func loss 0.637964129447937\n",
      "\n",
      "episode 6, val func loss 0.5642762780189514\n",
      "\n",
      "episode 7, val func loss 0.6086327433586121\n",
      "\n",
      "episode 8, val func loss 0.6808268427848816\n",
      "\n",
      "episode 9, val func loss 0.5467506051063538\n",
      "\n",
      "episode 10, val func loss 0.6525146961212158\n",
      "\n",
      "episode 11, val func loss 0.6110860705375671\n",
      "\n",
      "episode 12, val func loss 0.5357034802436829\n",
      "\n",
      "episode 13, val func loss 0.5372005105018616\n",
      "\n",
      "episode 14, val func loss 0.6509256362915039\n",
      "\n",
      "episode 15, val func loss 0.6207765936851501\n",
      "\n",
      "episode 16, val func loss 0.5678094625473022\n",
      "\n",
      "Val func train loss in epoch 9:0.6106098406016827\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.5784262418746948\n",
      "\n",
      "episode 2, val func loss 0.48587021231651306\n",
      "\n",
      "episode 3, val func loss 0.7009008526802063\n",
      "\n",
      "episode 4, val func loss 0.5547226667404175\n",
      "\n",
      "episode 5, val func loss 0.5960090756416321\n",
      "\n",
      "episode 6, val func loss 0.5946967005729675\n",
      "\n",
      "episode 7, val func loss 0.6050732135772705\n",
      "\n",
      "episode 8, val func loss 0.5799611210823059\n",
      "\n",
      "episode 9, val func loss 0.608369767665863\n",
      "\n",
      "episode 10, val func loss 0.9108139872550964\n",
      "\n",
      "episode 11, val func loss 0.5802300572395325\n",
      "\n",
      "episode 12, val func loss 0.5770148634910583\n",
      "\n",
      "episode 13, val func loss 0.6433947086334229\n",
      "\n",
      "episode 14, val func loss 0.5498241186141968\n",
      "\n",
      "episode 15, val func loss 0.6651841998100281\n",
      "\n",
      "episode 16, val func loss 0.6297720670700073\n",
      "\n",
      "Val func train loss in epoch 10:0.6162664908915758\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.5444556474685669\n",
      "\n",
      "episode 2, val func loss 0.6234509944915771\n",
      "\n",
      "episode 3, val func loss 0.6224371194839478\n",
      "\n",
      "episode 4, val func loss 0.614625871181488\n",
      "\n",
      "episode 5, val func loss 0.8073490262031555\n",
      "\n",
      "episode 6, val func loss 0.6039310097694397\n",
      "\n",
      "episode 7, val func loss 0.5478865504264832\n",
      "\n",
      "episode 8, val func loss 0.6806913018226624\n",
      "\n",
      "episode 9, val func loss 0.637949526309967\n",
      "\n",
      "episode 10, val func loss 0.6399557590484619\n",
      "\n",
      "episode 11, val func loss 0.6248425841331482\n",
      "\n",
      "episode 12, val func loss 0.6640681624412537\n",
      "\n",
      "episode 13, val func loss 0.5876954197883606\n",
      "\n",
      "episode 14, val func loss 0.6060525178909302\n",
      "\n",
      "episode 15, val func loss 0.6642685532569885\n",
      "\n",
      "episode 16, val func loss 0.60029137134552\n",
      "\n",
      "Val func train loss in epoch 11:0.6293719634413719\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.7067451477050781\n",
      "\n",
      "episode 2, val func loss 0.646223247051239\n",
      "\n",
      "episode 3, val func loss 0.6628454327583313\n",
      "\n",
      "episode 4, val func loss 0.6712361574172974\n",
      "\n",
      "episode 5, val func loss 0.6254273653030396\n",
      "\n",
      "episode 6, val func loss 0.5011853575706482\n",
      "\n",
      "episode 7, val func loss 0.6248503923416138\n",
      "\n",
      "episode 8, val func loss 0.6419808268547058\n",
      "\n",
      "episode 9, val func loss 0.6838024854660034\n",
      "\n",
      "episode 10, val func loss 0.6051232814788818\n",
      "\n",
      "episode 11, val func loss 0.5926930904388428\n",
      "\n",
      "episode 12, val func loss 0.658656895160675\n",
      "\n",
      "episode 13, val func loss 0.5862313508987427\n",
      "\n",
      "episode 14, val func loss 0.641685426235199\n",
      "\n",
      "episode 15, val func loss 0.5318898558616638\n",
      "\n",
      "episode 16, val func loss 0.6377996206283569\n",
      "\n",
      "Val func train loss in epoch 12:0.6261484958231449\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6757718324661255\n",
      "\n",
      "episode 2, val func loss 0.6318281292915344\n",
      "\n",
      "episode 3, val func loss 0.5724874138832092\n",
      "\n",
      "episode 4, val func loss 0.5517441630363464\n",
      "\n",
      "episode 5, val func loss 0.6807317733764648\n",
      "\n",
      "episode 6, val func loss 0.7549269199371338\n",
      "\n",
      "episode 7, val func loss 0.6080001592636108\n",
      "\n",
      "episode 8, val func loss 0.6607412695884705\n",
      "\n",
      "episode 9, val func loss 0.6246945261955261\n",
      "\n",
      "episode 10, val func loss 0.6610171794891357\n",
      "\n",
      "episode 11, val func loss 0.5863952040672302\n",
      "\n",
      "episode 12, val func loss 0.5235860347747803\n",
      "\n",
      "episode 13, val func loss 0.5829448103904724\n",
      "\n",
      "episode 14, val func loss 0.6422706246376038\n",
      "\n",
      "episode 15, val func loss 0.7050958871841431\n",
      "\n",
      "episode 16, val func loss 0.6026590466499329\n",
      "\n",
      "Val func train loss in epoch 13:0.6290559358894825\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.5484692454338074\n",
      "\n",
      "episode 2, val func loss 0.5426220297813416\n",
      "\n",
      "episode 3, val func loss 0.7253822684288025\n",
      "\n",
      "episode 4, val func loss 0.4336276650428772\n",
      "\n",
      "episode 5, val func loss 0.6376904845237732\n",
      "\n",
      "episode 6, val func loss 0.7287510633468628\n",
      "\n",
      "episode 7, val func loss 0.752226710319519\n",
      "\n",
      "episode 8, val func loss 0.5505430698394775\n",
      "\n",
      "episode 9, val func loss 0.5912185311317444\n",
      "\n",
      "episode 10, val func loss 0.5283616781234741\n",
      "\n",
      "episode 11, val func loss 0.6856894493103027\n",
      "\n",
      "episode 12, val func loss 0.6937589645385742\n",
      "\n",
      "episode 13, val func loss 0.652880072593689\n",
      "\n",
      "episode 14, val func loss 0.7168323993682861\n",
      "\n",
      "episode 15, val func loss 0.6237725615501404\n",
      "\n",
      "episode 16, val func loss 0.6832056641578674\n",
      "\n",
      "Val func train loss in epoch 14:0.6309394910931587\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6722225546836853\n",
      "\n",
      "episode 2, val func loss 0.6030289530754089\n",
      "\n",
      "episode 3, val func loss 0.5688455700874329\n",
      "\n",
      "episode 4, val func loss 0.6413756012916565\n",
      "\n",
      "episode 5, val func loss 0.6774564385414124\n",
      "\n",
      "episode 6, val func loss 0.508665919303894\n",
      "\n",
      "episode 7, val func loss 0.6136077642440796\n",
      "\n",
      "episode 8, val func loss 0.5650855302810669\n",
      "\n",
      "episode 9, val func loss 0.5717463493347168\n",
      "\n",
      "episode 10, val func loss 0.5585325956344604\n",
      "\n",
      "episode 11, val func loss 0.623649001121521\n",
      "\n",
      "episode 12, val func loss 0.5823133587837219\n",
      "\n",
      "episode 13, val func loss 0.5438452363014221\n",
      "\n",
      "episode 14, val func loss 0.5830500721931458\n",
      "\n",
      "episode 15, val func loss 0.7140006422996521\n",
      "\n",
      "episode 16, val func loss 0.5919436812400818\n",
      "\n",
      "Val func train loss in epoch 15:0.6012105792760849\n",
      "***********************TIME WAS 4.925160487492879 min*****************************\n",
      "\n",
      "**********************ROUND 131 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.8346571326255798\n",
      "\n",
      "episode 2, policy loss 0.8346405625343323\n",
      "\n",
      "episode 3, policy loss 0.834609866142273\n",
      "\n",
      "episode 4, policy loss 0.8345583081245422\n",
      "\n",
      "episode 5, policy loss 0.8344690799713135\n",
      "\n",
      "episode 6, policy loss 0.8342767357826233\n",
      "\n",
      "episode 7, policy loss 0.8337355256080627\n",
      "\n",
      "episode 8, policy loss 0.8323537707328796\n",
      "\n",
      "episode 9, policy loss 0.828982949256897\n",
      "\n",
      "episode 10, policy loss 0.819076418876648\n",
      "\n",
      "episode 11, policy loss 0.7872552871704102\n",
      "\n",
      "episode 12, policy loss 0.7718756198883057\n",
      "\n",
      "episode 13, policy loss 0.7724625468254089\n",
      "\n",
      "episode 14, policy loss 0.7593963742256165\n",
      "\n",
      "episode 15, policy loss 0.7740403413772583\n",
      "\n",
      "episode 16, policy loss 0.7650214433670044\n",
      "\n",
      "Policy train loss in epoch 0:0.8094632476568222\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.7682979702949524\n",
      "\n",
      "episode 2, policy loss 0.7726879119873047\n",
      "\n",
      "episode 3, policy loss 0.7610282301902771\n",
      "\n",
      "episode 4, policy loss 0.7638939619064331\n",
      "\n",
      "episode 5, policy loss 0.7707566618919373\n",
      "\n",
      "episode 6, policy loss 0.7612903118133545\n",
      "\n",
      "episode 7, policy loss 0.7615775465965271\n",
      "\n",
      "episode 8, policy loss 0.7688700556755066\n",
      "\n",
      "episode 9, policy loss 0.7636082172393799\n",
      "\n",
      "episode 10, policy loss 0.7602360844612122\n",
      "\n",
      "episode 11, policy loss 0.7659801244735718\n",
      "\n",
      "episode 12, policy loss 0.7613798379898071\n",
      "\n",
      "episode 13, policy loss 0.7595559358596802\n",
      "\n",
      "episode 14, policy loss 0.7623680830001831\n",
      "\n",
      "episode 15, policy loss 0.7635746598243713\n",
      "\n",
      "episode 16, policy loss 0.7569069862365723\n",
      "\n",
      "Policy train loss in epoch 1:0.7638757862150669\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.7606407999992371\n",
      "\n",
      "episode 2, policy loss 0.7613279819488525\n",
      "\n",
      "episode 3, policy loss 0.7598884105682373\n",
      "\n",
      "episode 4, policy loss 0.7605113387107849\n",
      "\n",
      "episode 5, policy loss 0.7607169151306152\n",
      "\n",
      "episode 6, policy loss 0.7585992813110352\n",
      "\n",
      "episode 7, policy loss 0.7574535012245178\n",
      "\n",
      "episode 8, policy loss 0.7591919898986816\n",
      "\n",
      "episode 9, policy loss 0.7558753490447998\n",
      "\n",
      "episode 10, policy loss 0.7581759691238403\n",
      "\n",
      "episode 11, policy loss 0.7612529993057251\n",
      "\n",
      "episode 12, policy loss 0.7573912143707275\n",
      "\n",
      "episode 13, policy loss 0.7598811388015747\n",
      "\n",
      "episode 14, policy loss 0.7582630515098572\n",
      "\n",
      "episode 15, policy loss 0.7553672790527344\n",
      "\n",
      "episode 16, policy loss 0.7575936317443848\n",
      "\n",
      "Policy train loss in epoch 2:0.7588831782341003\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.758629560470581\n",
      "\n",
      "episode 2, policy loss 0.7570118308067322\n",
      "\n",
      "episode 3, policy loss 0.7581139802932739\n",
      "\n",
      "episode 4, policy loss 0.7591590285301208\n",
      "\n",
      "episode 5, policy loss 0.7567481398582458\n",
      "\n",
      "episode 6, policy loss 0.758203387260437\n",
      "\n",
      "episode 7, policy loss 0.7564652562141418\n",
      "\n",
      "episode 8, policy loss 0.7575118541717529\n",
      "\n",
      "episode 9, policy loss 0.7556738257408142\n",
      "\n",
      "episode 10, policy loss 0.7583942413330078\n",
      "\n",
      "episode 11, policy loss 0.7578181028366089\n",
      "\n",
      "episode 12, policy loss 0.7583640813827515\n",
      "\n",
      "episode 13, policy loss 0.7590271234512329\n",
      "\n",
      "episode 14, policy loss 0.7567870020866394\n",
      "\n",
      "episode 15, policy loss 0.7593202590942383\n",
      "\n",
      "episode 16, policy loss 0.7559605836868286\n",
      "\n",
      "Policy train loss in epoch 3:0.757699266076088\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.920750081539154\n",
      "\n",
      "episode 2, val func loss 0.6224126219749451\n",
      "\n",
      "episode 3, val func loss 0.8304339051246643\n",
      "\n",
      "episode 4, val func loss 0.5879697203636169\n",
      "\n",
      "episode 5, val func loss 0.6995235085487366\n",
      "\n",
      "episode 6, val func loss 0.7194616198539734\n",
      "\n",
      "episode 7, val func loss 0.6909980773925781\n",
      "\n",
      "episode 8, val func loss 0.6581576466560364\n",
      "\n",
      "episode 9, val func loss 0.5921165943145752\n",
      "\n",
      "episode 10, val func loss 0.7773542404174805\n",
      "\n",
      "episode 11, val func loss 0.7574876546859741\n",
      "\n",
      "episode 12, val func loss 0.6223986148834229\n",
      "\n",
      "episode 13, val func loss 0.6356059312820435\n",
      "\n",
      "episode 14, val func loss 0.6779503226280212\n",
      "\n",
      "episode 15, val func loss 0.5953590273857117\n",
      "\n",
      "episode 16, val func loss 0.6161996722221375\n",
      "\n",
      "Val func train loss in epoch 0:0.687761202454567\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.6640345454216003\n",
      "\n",
      "episode 2, val func loss 0.672256588935852\n",
      "\n",
      "episode 3, val func loss 0.5320074558258057\n",
      "\n",
      "episode 4, val func loss 0.5965135097503662\n",
      "\n",
      "episode 5, val func loss 0.6811764240264893\n",
      "\n",
      "episode 6, val func loss 0.6210967302322388\n",
      "\n",
      "episode 7, val func loss 0.5845804810523987\n",
      "\n",
      "episode 8, val func loss 0.6226235628128052\n",
      "\n",
      "episode 9, val func loss 0.6369665265083313\n",
      "\n",
      "episode 10, val func loss 0.6231712698936462\n",
      "\n",
      "episode 11, val func loss 0.6539574265480042\n",
      "\n",
      "episode 12, val func loss 0.5839583277702332\n",
      "\n",
      "episode 13, val func loss 0.49477818608283997\n",
      "\n",
      "episode 14, val func loss 0.6140615344047546\n",
      "\n",
      "episode 15, val func loss 0.6696692109107971\n",
      "\n",
      "episode 16, val func loss 0.6302471160888672\n",
      "\n",
      "Val func train loss in epoch 1:0.6175686810165644\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.5950480699539185\n",
      "\n",
      "episode 2, val func loss 0.5995345711708069\n",
      "\n",
      "episode 3, val func loss 0.690131425857544\n",
      "\n",
      "episode 4, val func loss 0.6892688870429993\n",
      "\n",
      "episode 5, val func loss 0.6425054669380188\n",
      "\n",
      "episode 6, val func loss 0.6575621366500854\n",
      "\n",
      "episode 7, val func loss 0.5176112651824951\n",
      "\n",
      "episode 8, val func loss 0.782110869884491\n",
      "\n",
      "episode 9, val func loss 0.6147085428237915\n",
      "\n",
      "episode 10, val func loss 0.6010741591453552\n",
      "\n",
      "episode 11, val func loss 0.6758241653442383\n",
      "\n",
      "episode 12, val func loss 0.593890905380249\n",
      "\n",
      "episode 13, val func loss 0.6615471839904785\n",
      "\n",
      "episode 14, val func loss 0.7684380412101746\n",
      "\n",
      "episode 15, val func loss 0.7446997165679932\n",
      "\n",
      "episode 16, val func loss 0.6140375137329102\n",
      "\n",
      "Val func train loss in epoch 2:0.6529995575547218\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6230801939964294\n",
      "\n",
      "episode 2, val func loss 0.5245119333267212\n",
      "\n",
      "episode 3, val func loss 0.5318837761878967\n",
      "\n",
      "episode 4, val func loss 0.5340434312820435\n",
      "\n",
      "episode 5, val func loss 0.5829745531082153\n",
      "\n",
      "episode 6, val func loss 0.6081258654594421\n",
      "\n",
      "episode 7, val func loss 0.5935655236244202\n",
      "\n",
      "episode 8, val func loss 0.5659692287445068\n",
      "\n",
      "episode 9, val func loss 0.5913693308830261\n",
      "\n",
      "episode 10, val func loss 0.6348266005516052\n",
      "\n",
      "episode 11, val func loss 0.6248731017112732\n",
      "\n",
      "episode 12, val func loss 0.55369633436203\n",
      "\n",
      "episode 13, val func loss 0.6019198298454285\n",
      "\n",
      "episode 14, val func loss 0.546597421169281\n",
      "\n",
      "episode 15, val func loss 0.5816043615341187\n",
      "\n",
      "episode 16, val func loss 0.6198316216468811\n",
      "\n",
      "Val func train loss in epoch 3:0.5824295692145824\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7484217286109924\n",
      "\n",
      "episode 2, val func loss 0.623599648475647\n",
      "\n",
      "episode 3, val func loss 0.5612931847572327\n",
      "\n",
      "episode 4, val func loss 0.5974718928337097\n",
      "\n",
      "episode 5, val func loss 0.6356098055839539\n",
      "\n",
      "episode 6, val func loss 0.6309793591499329\n",
      "\n",
      "episode 7, val func loss 0.6820513606071472\n",
      "\n",
      "episode 8, val func loss 0.6506902575492859\n",
      "\n",
      "episode 9, val func loss 0.6433496475219727\n",
      "\n",
      "episode 10, val func loss 0.6296949982643127\n",
      "\n",
      "episode 11, val func loss 0.6451013684272766\n",
      "\n",
      "episode 12, val func loss 0.6525130867958069\n",
      "\n",
      "episode 13, val func loss 0.58522629737854\n",
      "\n",
      "episode 14, val func loss 0.6179038882255554\n",
      "\n",
      "episode 15, val func loss 0.5874049067497253\n",
      "\n",
      "episode 16, val func loss 0.5894420742988586\n",
      "\n",
      "Val func train loss in epoch 4:0.6300470940768719\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.5636445879936218\n",
      "\n",
      "episode 2, val func loss 0.5157701969146729\n",
      "\n",
      "episode 3, val func loss 0.5138712525367737\n",
      "\n",
      "episode 4, val func loss 0.6183059811592102\n",
      "\n",
      "episode 5, val func loss 0.6122798323631287\n",
      "\n",
      "episode 6, val func loss 0.6523024439811707\n",
      "\n",
      "episode 7, val func loss 0.5761515498161316\n",
      "\n",
      "episode 8, val func loss 0.581717312335968\n",
      "\n",
      "episode 9, val func loss 0.5774590969085693\n",
      "\n",
      "episode 10, val func loss 0.48820066452026367\n",
      "\n",
      "episode 11, val func loss 0.6265520453453064\n",
      "\n",
      "episode 12, val func loss 0.6623679399490356\n",
      "\n",
      "episode 13, val func loss 0.7110800743103027\n",
      "\n",
      "episode 14, val func loss 0.525858461856842\n",
      "\n",
      "episode 15, val func loss 0.6001480221748352\n",
      "\n",
      "episode 16, val func loss 0.7059895396232605\n",
      "\n",
      "Val func train loss in epoch 5:0.5957311876118183\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.5588446259498596\n",
      "\n",
      "episode 2, val func loss 0.6465381383895874\n",
      "\n",
      "episode 3, val func loss 0.6699168086051941\n",
      "\n",
      "episode 4, val func loss 0.5931858420372009\n",
      "\n",
      "episode 5, val func loss 0.6312992572784424\n",
      "\n",
      "episode 6, val func loss 0.5686589479446411\n",
      "\n",
      "episode 7, val func loss 0.5735942125320435\n",
      "\n",
      "episode 8, val func loss 0.6190648674964905\n",
      "\n",
      "episode 9, val func loss 0.6629204750061035\n",
      "\n",
      "episode 10, val func loss 0.5965314507484436\n",
      "\n",
      "episode 11, val func loss 0.6811538338661194\n",
      "\n",
      "episode 12, val func loss 0.6080167293548584\n",
      "\n",
      "episode 13, val func loss 0.6162329912185669\n",
      "\n",
      "episode 14, val func loss 0.6466979384422302\n",
      "\n",
      "episode 15, val func loss 0.5836181640625\n",
      "\n",
      "episode 16, val func loss 0.5200867652893066\n",
      "\n",
      "Val func train loss in epoch 6:0.6110225655138493\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6766927242279053\n",
      "\n",
      "episode 2, val func loss 0.5972647666931152\n",
      "\n",
      "episode 3, val func loss 0.5772706270217896\n",
      "\n",
      "episode 4, val func loss 0.6098605990409851\n",
      "\n",
      "episode 5, val func loss 0.7157630920410156\n",
      "\n",
      "episode 6, val func loss 0.6591851711273193\n",
      "\n",
      "episode 7, val func loss 0.6978292465209961\n",
      "\n",
      "episode 8, val func loss 0.8159517645835876\n",
      "\n",
      "episode 9, val func loss 0.6200272440910339\n",
      "\n",
      "episode 10, val func loss 0.5639733076095581\n",
      "\n",
      "episode 11, val func loss 0.6011314988136292\n",
      "\n",
      "episode 12, val func loss 0.6883358955383301\n",
      "\n",
      "episode 13, val func loss 0.733188807964325\n",
      "\n",
      "episode 14, val func loss 0.5312319993972778\n",
      "\n",
      "episode 15, val func loss 0.6438727974891663\n",
      "\n",
      "episode 16, val func loss 0.6411302089691162\n",
      "\n",
      "Val func train loss in epoch 7:0.6482943594455719\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6228988170623779\n",
      "\n",
      "episode 2, val func loss 0.6158025860786438\n",
      "\n",
      "episode 3, val func loss 0.5777171850204468\n",
      "\n",
      "episode 4, val func loss 0.6927940845489502\n",
      "\n",
      "episode 5, val func loss 0.6758509874343872\n",
      "\n",
      "episode 6, val func loss 0.5756219625473022\n",
      "\n",
      "episode 7, val func loss 0.6243277192115784\n",
      "\n",
      "episode 8, val func loss 0.6732320785522461\n",
      "\n",
      "episode 9, val func loss 0.5233216881752014\n",
      "\n",
      "episode 10, val func loss 0.669355034828186\n",
      "\n",
      "episode 11, val func loss 0.722818911075592\n",
      "\n",
      "episode 12, val func loss 0.6563761234283447\n",
      "\n",
      "episode 13, val func loss 0.6574507355690002\n",
      "\n",
      "episode 14, val func loss 0.6019065976142883\n",
      "\n",
      "episode 15, val func loss 0.5968166589736938\n",
      "\n",
      "episode 16, val func loss 0.6433398127555847\n",
      "\n",
      "Val func train loss in epoch 8:0.633101936429739\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.5646744966506958\n",
      "\n",
      "episode 2, val func loss 0.6210999488830566\n",
      "\n",
      "episode 3, val func loss 0.6197340488433838\n",
      "\n",
      "episode 4, val func loss 0.5807234644889832\n",
      "\n",
      "episode 5, val func loss 0.6000195741653442\n",
      "\n",
      "episode 6, val func loss 0.6418195366859436\n",
      "\n",
      "episode 7, val func loss 0.5577994585037231\n",
      "\n",
      "episode 8, val func loss 0.6445272564888\n",
      "\n",
      "episode 9, val func loss 0.6157346963882446\n",
      "\n",
      "episode 10, val func loss 0.7217614054679871\n",
      "\n",
      "episode 11, val func loss 0.5776350498199463\n",
      "\n",
      "episode 12, val func loss 0.7034907341003418\n",
      "\n",
      "episode 13, val func loss 0.5978987216949463\n",
      "\n",
      "episode 14, val func loss 0.5652830004692078\n",
      "\n",
      "episode 15, val func loss 0.49870818853378296\n",
      "\n",
      "episode 16, val func loss 0.5926415324211121\n",
      "\n",
      "Val func train loss in epoch 9:0.6064719446003437\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.604715883731842\n",
      "\n",
      "episode 2, val func loss 0.5399792194366455\n",
      "\n",
      "episode 3, val func loss 0.5624490976333618\n",
      "\n",
      "episode 4, val func loss 0.5689863562583923\n",
      "\n",
      "episode 5, val func loss 0.6434615850448608\n",
      "\n",
      "episode 6, val func loss 0.6569803357124329\n",
      "\n",
      "episode 7, val func loss 0.6514676213264465\n",
      "\n",
      "episode 8, val func loss 0.5317417979240417\n",
      "\n",
      "episode 9, val func loss 0.6732915043830872\n",
      "\n",
      "episode 10, val func loss 0.5173047184944153\n",
      "\n",
      "episode 11, val func loss 0.6567351222038269\n",
      "\n",
      "episode 12, val func loss 0.5259313583374023\n",
      "\n",
      "episode 13, val func loss 0.5896786451339722\n",
      "\n",
      "episode 14, val func loss 0.49153709411621094\n",
      "\n",
      "episode 15, val func loss 0.6683357954025269\n",
      "\n",
      "episode 16, val func loss 0.7466603517532349\n",
      "\n",
      "Val func train loss in epoch 10:0.6018285304307938\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.641236424446106\n",
      "\n",
      "episode 2, val func loss 0.668339729309082\n",
      "\n",
      "episode 3, val func loss 0.6214900016784668\n",
      "\n",
      "episode 4, val func loss 0.5662537813186646\n",
      "\n",
      "episode 5, val func loss 0.690288245677948\n",
      "\n",
      "episode 6, val func loss 0.539573073387146\n",
      "\n",
      "episode 7, val func loss 0.6369488835334778\n",
      "\n",
      "episode 8, val func loss 0.6417131423950195\n",
      "\n",
      "episode 9, val func loss 0.5593729019165039\n",
      "\n",
      "episode 10, val func loss 0.5792683959007263\n",
      "\n",
      "episode 11, val func loss 0.5523211359977722\n",
      "\n",
      "episode 12, val func loss 0.5482746958732605\n",
      "\n",
      "episode 13, val func loss 0.6608789563179016\n",
      "\n",
      "episode 14, val func loss 0.5751122832298279\n",
      "\n",
      "episode 15, val func loss 0.5920839309692383\n",
      "\n",
      "episode 16, val func loss 0.6384602189064026\n",
      "\n",
      "Val func train loss in epoch 11:0.6069759875535965\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6206457018852234\n",
      "\n",
      "episode 2, val func loss 0.6142706274986267\n",
      "\n",
      "episode 3, val func loss 0.5793412923812866\n",
      "\n",
      "episode 4, val func loss 0.5456271171569824\n",
      "\n",
      "episode 5, val func loss 0.5674084424972534\n",
      "\n",
      "episode 6, val func loss 0.6114106774330139\n",
      "\n",
      "episode 7, val func loss 0.6575118899345398\n",
      "\n",
      "episode 8, val func loss 0.5698078870773315\n",
      "\n",
      "episode 9, val func loss 0.6081050038337708\n",
      "\n",
      "episode 10, val func loss 0.5968849062919617\n",
      "\n",
      "episode 11, val func loss 0.7529622912406921\n",
      "\n",
      "episode 12, val func loss 0.6145802736282349\n",
      "\n",
      "episode 13, val func loss 0.7568041086196899\n",
      "\n",
      "episode 14, val func loss 0.6197692155838013\n",
      "\n",
      "episode 15, val func loss 0.637604832649231\n",
      "\n",
      "episode 16, val func loss 0.651252269744873\n",
      "\n",
      "Val func train loss in epoch 12:0.625249158591032\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6541251540184021\n",
      "\n",
      "episode 2, val func loss 0.6082042455673218\n",
      "\n",
      "episode 3, val func loss 0.6292293667793274\n",
      "\n",
      "episode 4, val func loss 0.6811140179634094\n",
      "\n",
      "episode 5, val func loss 0.7640308141708374\n",
      "\n",
      "episode 6, val func loss 0.6257485151290894\n",
      "\n",
      "episode 7, val func loss 0.8265625834465027\n",
      "\n",
      "episode 8, val func loss 0.5767097473144531\n",
      "\n",
      "episode 9, val func loss 0.6652886271476746\n",
      "\n",
      "episode 10, val func loss 0.7472631931304932\n",
      "\n",
      "episode 11, val func loss 0.7558882236480713\n",
      "\n",
      "episode 12, val func loss 0.614008903503418\n",
      "\n",
      "episode 13, val func loss 0.7531335353851318\n",
      "\n",
      "episode 14, val func loss 0.7170050144195557\n",
      "\n",
      "episode 15, val func loss 0.6035263538360596\n",
      "\n",
      "episode 16, val func loss 0.6608825922012329\n",
      "\n",
      "Val func train loss in epoch 13:0.6801700554788113\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6056596040725708\n",
      "\n",
      "episode 2, val func loss 0.580970048904419\n",
      "\n",
      "episode 3, val func loss 0.5546308755874634\n",
      "\n",
      "episode 4, val func loss 0.5426985025405884\n",
      "\n",
      "episode 5, val func loss 0.6032431721687317\n",
      "\n",
      "episode 6, val func loss 0.5968630313873291\n",
      "\n",
      "episode 7, val func loss 0.6542001366615295\n",
      "\n",
      "episode 8, val func loss 0.5897344350814819\n",
      "\n",
      "episode 9, val func loss 0.6135378479957581\n",
      "\n",
      "episode 10, val func loss 0.5369163751602173\n",
      "\n",
      "episode 11, val func loss 0.616576075553894\n",
      "\n",
      "episode 12, val func loss 0.5765446424484253\n",
      "\n",
      "episode 13, val func loss 0.6691105365753174\n",
      "\n",
      "episode 14, val func loss 0.6198717951774597\n",
      "\n",
      "episode 15, val func loss 0.6005194187164307\n",
      "\n",
      "episode 16, val func loss 0.6438602805137634\n",
      "\n",
      "Val func train loss in epoch 14:0.6003085486590862\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6228182911872864\n",
      "\n",
      "episode 2, val func loss 0.6712336540222168\n",
      "\n",
      "episode 3, val func loss 0.5927867293357849\n",
      "\n",
      "episode 4, val func loss 0.5682476162910461\n",
      "\n",
      "episode 5, val func loss 0.6407270431518555\n",
      "\n",
      "episode 6, val func loss 0.6211391091346741\n",
      "\n",
      "episode 7, val func loss 0.6702611446380615\n",
      "\n",
      "episode 8, val func loss 0.6014835834503174\n",
      "\n",
      "episode 9, val func loss 0.6849242448806763\n",
      "\n",
      "episode 10, val func loss 0.6173511147499084\n",
      "\n",
      "episode 11, val func loss 0.6293317079544067\n",
      "\n",
      "episode 12, val func loss 0.48974063992500305\n",
      "\n",
      "episode 13, val func loss 0.7794390916824341\n",
      "\n",
      "episode 14, val func loss 0.594464898109436\n",
      "\n",
      "episode 15, val func loss 0.6329078078269958\n",
      "\n",
      "episode 16, val func loss 0.5907652378082275\n",
      "\n",
      "Val func train loss in epoch 15:0.6254763696342707\n",
      "***********************TIME WAS 4.924453075726827 min*****************************\n",
      "\n",
      "**********************ROUND 132 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.610342264175415\n",
      "\n",
      "episode 2, policy loss 1.7146332263946533\n",
      "\n",
      "episode 3, policy loss 1.8196460008621216\n",
      "\n",
      "episode 4, policy loss 1.730992317199707\n",
      "\n",
      "episode 5, policy loss 1.78702974319458\n",
      "\n",
      "episode 6, policy loss 1.6865346431732178\n",
      "\n",
      "episode 7, policy loss 1.755691409111023\n",
      "\n",
      "episode 8, policy loss 1.8000694513320923\n",
      "\n",
      "episode 9, policy loss 1.832703709602356\n",
      "\n",
      "episode 10, policy loss 1.7696233987808228\n",
      "\n",
      "episode 11, policy loss 1.5513033866882324\n",
      "\n",
      "episode 12, policy loss 1.664090871810913\n",
      "\n",
      "episode 13, policy loss 1.7978010177612305\n",
      "\n",
      "episode 14, policy loss 1.797280192375183\n",
      "\n",
      "episode 15, policy loss 1.725982904434204\n",
      "\n",
      "episode 16, policy loss 1.8264294862747192\n",
      "\n",
      "Policy train loss in epoch 0:1.7418846264481544\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.6376298666000366\n",
      "\n",
      "episode 2, policy loss 1.810163140296936\n",
      "\n",
      "episode 3, policy loss 1.6656534671783447\n",
      "\n",
      "episode 4, policy loss 1.8238136768341064\n",
      "\n",
      "episode 5, policy loss 1.759381890296936\n",
      "\n",
      "episode 6, policy loss 1.79226553440094\n",
      "\n",
      "episode 7, policy loss 1.6731305122375488\n",
      "\n",
      "episode 8, policy loss 1.676740050315857\n",
      "\n",
      "episode 9, policy loss 1.5190576314926147\n",
      "\n",
      "episode 10, policy loss 1.661320686340332\n",
      "\n",
      "episode 11, policy loss 1.6531347036361694\n",
      "\n",
      "episode 12, policy loss 1.646234154701233\n",
      "\n",
      "episode 13, policy loss 1.4556645154953003\n",
      "\n",
      "episode 14, policy loss 1.6638200283050537\n",
      "\n",
      "episode 15, policy loss 1.5882127285003662\n",
      "\n",
      "episode 16, policy loss 1.6117321252822876\n",
      "\n",
      "Policy train loss in epoch 1:1.664872169494629\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.5783331394195557\n",
      "\n",
      "episode 2, policy loss 1.6364890336990356\n",
      "\n",
      "episode 3, policy loss 1.660025715827942\n",
      "\n",
      "episode 4, policy loss 1.506856083869934\n",
      "\n",
      "episode 5, policy loss 1.6637637615203857\n",
      "\n",
      "episode 6, policy loss 1.5535129308700562\n",
      "\n",
      "episode 7, policy loss 1.557308316230774\n",
      "\n",
      "episode 8, policy loss 1.711823582649231\n",
      "\n",
      "episode 9, policy loss 1.6803098917007446\n",
      "\n",
      "episode 10, policy loss 1.679409146308899\n",
      "\n",
      "episode 11, policy loss 1.616960883140564\n",
      "\n",
      "episode 12, policy loss 1.630772590637207\n",
      "\n",
      "episode 13, policy loss 1.4538202285766602\n",
      "\n",
      "episode 14, policy loss 1.6039897203445435\n",
      "\n",
      "episode 15, policy loss 1.5804778337478638\n",
      "\n",
      "episode 16, policy loss 1.4280742406845093\n",
      "\n",
      "Policy train loss in epoch 2:1.596370443701744\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.6040170192718506\n",
      "\n",
      "episode 2, policy loss 1.4493166208267212\n",
      "\n",
      "episode 3, policy loss 1.6324697732925415\n",
      "\n",
      "episode 4, policy loss 1.629715085029602\n",
      "\n",
      "episode 5, policy loss 1.6785575151443481\n",
      "\n",
      "episode 6, policy loss 1.5829769372940063\n",
      "\n",
      "episode 7, policy loss 1.6052632331848145\n",
      "\n",
      "episode 8, policy loss 1.5547465085983276\n",
      "\n",
      "episode 9, policy loss 1.6586545705795288\n",
      "\n",
      "episode 10, policy loss 1.6537196636199951\n",
      "\n",
      "episode 11, policy loss 1.4300239086151123\n",
      "\n",
      "episode 12, policy loss 1.5503265857696533\n",
      "\n",
      "episode 13, policy loss 1.5024528503417969\n",
      "\n",
      "episode 14, policy loss 1.7102645635604858\n",
      "\n",
      "episode 15, policy loss 1.577930212020874\n",
      "\n",
      "episode 16, policy loss 1.683093786239624\n",
      "\n",
      "Policy train loss in epoch 3:1.5939705520868301\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 3.274859666824341\n",
      "\n",
      "episode 2, val func loss 2.9371683597564697\n",
      "\n",
      "episode 3, val func loss 3.299863576889038\n",
      "\n",
      "episode 4, val func loss 3.245842933654785\n",
      "\n",
      "episode 5, val func loss 2.8555245399475098\n",
      "\n",
      "episode 6, val func loss 3.1083905696868896\n",
      "\n",
      "episode 7, val func loss 2.3513553142547607\n",
      "\n",
      "episode 8, val func loss 2.0827155113220215\n",
      "\n",
      "episode 9, val func loss 2.8329102993011475\n",
      "\n",
      "episode 10, val func loss 3.3502256870269775\n",
      "\n",
      "episode 11, val func loss 2.9575693607330322\n",
      "\n",
      "episode 12, val func loss 2.8513903617858887\n",
      "\n",
      "episode 13, val func loss 2.1814942359924316\n",
      "\n",
      "episode 14, val func loss 2.8454365730285645\n",
      "\n",
      "episode 15, val func loss 2.969259262084961\n",
      "\n",
      "episode 16, val func loss 3.144906759262085\n",
      "\n",
      "Val func train loss in epoch 0:2.8930570632219315\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 3.2851943969726562\n",
      "\n",
      "episode 2, val func loss 2.930368185043335\n",
      "\n",
      "episode 3, val func loss 2.272343158721924\n",
      "\n",
      "episode 4, val func loss 2.9150819778442383\n",
      "\n",
      "episode 5, val func loss 2.633273124694824\n",
      "\n",
      "episode 6, val func loss 2.8890295028686523\n",
      "\n",
      "episode 7, val func loss 3.0556674003601074\n",
      "\n",
      "episode 8, val func loss 2.6674790382385254\n",
      "\n",
      "episode 9, val func loss 2.969444751739502\n",
      "\n",
      "episode 10, val func loss 2.762639045715332\n",
      "\n",
      "episode 11, val func loss 3.4750864505767822\n",
      "\n",
      "episode 12, val func loss 3.25125789642334\n",
      "\n",
      "episode 13, val func loss 2.9343063831329346\n",
      "\n",
      "episode 14, val func loss 3.1818668842315674\n",
      "\n",
      "episode 15, val func loss 3.0363426208496094\n",
      "\n",
      "episode 16, val func loss 2.6818220615386963\n",
      "\n",
      "Val func train loss in epoch 1:2.9338251799345016\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 3.2330708503723145\n",
      "\n",
      "episode 2, val func loss 3.0583748817443848\n",
      "\n",
      "episode 3, val func loss 2.6191518306732178\n",
      "\n",
      "episode 4, val func loss 3.1428163051605225\n",
      "\n",
      "episode 5, val func loss 3.423441171646118\n",
      "\n",
      "episode 6, val func loss 2.3785958290100098\n",
      "\n",
      "episode 7, val func loss 2.43137788772583\n",
      "\n",
      "episode 8, val func loss 2.5261452198028564\n",
      "\n",
      "episode 9, val func loss 3.29709529876709\n",
      "\n",
      "episode 10, val func loss 2.5485620498657227\n",
      "\n",
      "episode 11, val func loss 3.11688232421875\n",
      "\n",
      "episode 12, val func loss 3.307201862335205\n",
      "\n",
      "episode 13, val func loss 3.2232131958007812\n",
      "\n",
      "episode 14, val func loss 3.0484726428985596\n",
      "\n",
      "episode 15, val func loss 2.5419256687164307\n",
      "\n",
      "episode 16, val func loss 2.5683157444000244\n",
      "\n",
      "Val func train loss in epoch 2:2.9040401726961136\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.529716968536377\n",
      "\n",
      "episode 2, val func loss 2.8725812435150146\n",
      "\n",
      "episode 3, val func loss 2.960033416748047\n",
      "\n",
      "episode 4, val func loss 2.9175500869750977\n",
      "\n",
      "episode 5, val func loss 3.0035910606384277\n",
      "\n",
      "episode 6, val func loss 3.077362060546875\n",
      "\n",
      "episode 7, val func loss 2.966845989227295\n",
      "\n",
      "episode 8, val func loss 3.1683390140533447\n",
      "\n",
      "episode 9, val func loss 3.236436367034912\n",
      "\n",
      "episode 10, val func loss 2.3017501831054688\n",
      "\n",
      "episode 11, val func loss 2.5191049575805664\n",
      "\n",
      "episode 12, val func loss 3.2188284397125244\n",
      "\n",
      "episode 13, val func loss 2.9501562118530273\n",
      "\n",
      "episode 14, val func loss 2.861579656600952\n",
      "\n",
      "episode 15, val func loss 3.105415105819702\n",
      "\n",
      "episode 16, val func loss 3.472501754760742\n",
      "\n",
      "Val func train loss in epoch 3:2.9476120322942734\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.922950029373169\n",
      "\n",
      "episode 2, val func loss 2.6963658332824707\n",
      "\n",
      "episode 3, val func loss 3.080177068710327\n",
      "\n",
      "episode 4, val func loss 2.8578848838806152\n",
      "\n",
      "episode 5, val func loss 3.259566307067871\n",
      "\n",
      "episode 6, val func loss 2.296603202819824\n",
      "\n",
      "episode 7, val func loss 2.536318778991699\n",
      "\n",
      "episode 8, val func loss 3.5484840869903564\n",
      "\n",
      "episode 9, val func loss 2.6617767810821533\n",
      "\n",
      "episode 10, val func loss 3.13206148147583\n",
      "\n",
      "episode 11, val func loss 3.26542067527771\n",
      "\n",
      "episode 12, val func loss 3.5396499633789062\n",
      "\n",
      "episode 13, val func loss 2.671131134033203\n",
      "\n",
      "episode 14, val func loss 3.274712085723877\n",
      "\n",
      "episode 15, val func loss 2.8523623943328857\n",
      "\n",
      "episode 16, val func loss 3.2175254821777344\n",
      "\n",
      "Val func train loss in epoch 4:2.9883118867874146\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 3.116830587387085\n",
      "\n",
      "episode 2, val func loss 2.9573540687561035\n",
      "\n",
      "episode 3, val func loss 3.151867389678955\n",
      "\n",
      "episode 4, val func loss 2.440460681915283\n",
      "\n",
      "episode 5, val func loss 3.050095319747925\n",
      "\n",
      "episode 6, val func loss 3.058213949203491\n",
      "\n",
      "episode 7, val func loss 2.76355242729187\n",
      "\n",
      "episode 8, val func loss 2.5549654960632324\n",
      "\n",
      "episode 9, val func loss 2.5172905921936035\n",
      "\n",
      "episode 10, val func loss 3.0496573448181152\n",
      "\n",
      "episode 11, val func loss 2.9431052207946777\n",
      "\n",
      "episode 12, val func loss 3.152486801147461\n",
      "\n",
      "episode 13, val func loss 3.243345260620117\n",
      "\n",
      "episode 14, val func loss 2.627105474472046\n",
      "\n",
      "episode 15, val func loss 2.6979448795318604\n",
      "\n",
      "episode 16, val func loss 2.946932077407837\n",
      "\n",
      "Val func train loss in epoch 5:2.891950473189354\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 3.199979066848755\n",
      "\n",
      "episode 2, val func loss 3.4519577026367188\n",
      "\n",
      "episode 3, val func loss 3.298201322555542\n",
      "\n",
      "episode 4, val func loss 2.9181113243103027\n",
      "\n",
      "episode 5, val func loss 2.6724765300750732\n",
      "\n",
      "episode 6, val func loss 3.168093204498291\n",
      "\n",
      "episode 7, val func loss 2.8724162578582764\n",
      "\n",
      "episode 8, val func loss 2.7513415813446045\n",
      "\n",
      "episode 9, val func loss 2.697484254837036\n",
      "\n",
      "episode 10, val func loss 2.1349127292633057\n",
      "\n",
      "episode 11, val func loss 3.0674335956573486\n",
      "\n",
      "episode 12, val func loss 3.038217067718506\n",
      "\n",
      "episode 13, val func loss 3.1081509590148926\n",
      "\n",
      "episode 14, val func loss 2.6993930339813232\n",
      "\n",
      "episode 15, val func loss 2.7761030197143555\n",
      "\n",
      "episode 16, val func loss 3.0348973274230957\n",
      "\n",
      "Val func train loss in epoch 6:2.930573061108589\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 2.7601773738861084\n",
      "\n",
      "episode 2, val func loss 2.661280393600464\n",
      "\n",
      "episode 3, val func loss 2.21357798576355\n",
      "\n",
      "episode 4, val func loss 2.9083428382873535\n",
      "\n",
      "episode 5, val func loss 2.791247844696045\n",
      "\n",
      "episode 6, val func loss 3.377169132232666\n",
      "\n",
      "episode 7, val func loss 2.8743715286254883\n",
      "\n",
      "episode 8, val func loss 3.0368309020996094\n",
      "\n",
      "episode 9, val func loss 2.9042837619781494\n",
      "\n",
      "episode 10, val func loss 2.874437093734741\n",
      "\n",
      "episode 11, val func loss 2.5597822666168213\n",
      "\n",
      "episode 12, val func loss 3.369434356689453\n",
      "\n",
      "episode 13, val func loss 3.042161464691162\n",
      "\n",
      "episode 14, val func loss 3.26114821434021\n",
      "\n",
      "episode 15, val func loss 3.129065752029419\n",
      "\n",
      "episode 16, val func loss 3.187588930130005\n",
      "\n",
      "Val func train loss in epoch 7:2.934431239962578\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.942513942718506\n",
      "\n",
      "episode 2, val func loss 3.0227959156036377\n",
      "\n",
      "episode 3, val func loss 2.382606267929077\n",
      "\n",
      "episode 4, val func loss 3.4799537658691406\n",
      "\n",
      "episode 5, val func loss 2.860480308532715\n",
      "\n",
      "episode 6, val func loss 2.868232488632202\n",
      "\n",
      "episode 7, val func loss 2.713606834411621\n",
      "\n",
      "episode 8, val func loss 2.145153045654297\n",
      "\n",
      "episode 9, val func loss 2.8922295570373535\n",
      "\n",
      "episode 10, val func loss 3.0483007431030273\n",
      "\n",
      "episode 11, val func loss 3.200162172317505\n",
      "\n",
      "episode 12, val func loss 3.2171595096588135\n",
      "\n",
      "episode 13, val func loss 2.5657567977905273\n",
      "\n",
      "episode 14, val func loss 2.870148181915283\n",
      "\n",
      "episode 15, val func loss 2.7754647731781006\n",
      "\n",
      "episode 16, val func loss 2.45944881439209\n",
      "\n",
      "Val func train loss in epoch 8:2.8402508199214935\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 3.0134994983673096\n",
      "\n",
      "episode 2, val func loss 2.6440727710723877\n",
      "\n",
      "episode 3, val func loss 3.4842000007629395\n",
      "\n",
      "episode 4, val func loss 3.1593289375305176\n",
      "\n",
      "episode 5, val func loss 2.2378475666046143\n",
      "\n",
      "episode 6, val func loss 2.5563371181488037\n",
      "\n",
      "episode 7, val func loss 3.2623493671417236\n",
      "\n",
      "episode 8, val func loss 3.0621795654296875\n",
      "\n",
      "episode 9, val func loss 3.0494749546051025\n",
      "\n",
      "episode 10, val func loss 2.2551534175872803\n",
      "\n",
      "episode 11, val func loss 3.2328882217407227\n",
      "\n",
      "episode 12, val func loss 2.7931907176971436\n",
      "\n",
      "episode 13, val func loss 3.1858036518096924\n",
      "\n",
      "episode 14, val func loss 3.177821636199951\n",
      "\n",
      "episode 15, val func loss 3.10689377784729\n",
      "\n",
      "episode 16, val func loss 3.113560676574707\n",
      "\n",
      "Val func train loss in epoch 9:2.958412617444992\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 3.34295916557312\n",
      "\n",
      "episode 2, val func loss 3.1638967990875244\n",
      "\n",
      "episode 3, val func loss 3.0725457668304443\n",
      "\n",
      "episode 4, val func loss 2.8745343685150146\n",
      "\n",
      "episode 5, val func loss 3.0380561351776123\n",
      "\n",
      "episode 6, val func loss 3.1390581130981445\n",
      "\n",
      "episode 7, val func loss 2.6299962997436523\n",
      "\n",
      "episode 8, val func loss 3.5452346801757812\n",
      "\n",
      "episode 9, val func loss 2.4950685501098633\n",
      "\n",
      "episode 10, val func loss 3.0604257583618164\n",
      "\n",
      "episode 11, val func loss 2.7282347679138184\n",
      "\n",
      "episode 12, val func loss 2.621483564376831\n",
      "\n",
      "episode 13, val func loss 2.5888752937316895\n",
      "\n",
      "episode 14, val func loss 2.2362847328186035\n",
      "\n",
      "episode 15, val func loss 2.6248953342437744\n",
      "\n",
      "episode 16, val func loss 3.1045210361480713\n",
      "\n",
      "Val func train loss in epoch 10:2.89162939786911\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 2.9899072647094727\n",
      "\n",
      "episode 2, val func loss 2.484821319580078\n",
      "\n",
      "episode 3, val func loss 2.9798970222473145\n",
      "\n",
      "episode 4, val func loss 2.797156572341919\n",
      "\n",
      "episode 5, val func loss 2.460545063018799\n",
      "\n",
      "episode 6, val func loss 3.113765001296997\n",
      "\n",
      "episode 7, val func loss 2.6316041946411133\n",
      "\n",
      "episode 8, val func loss 2.8186516761779785\n",
      "\n",
      "episode 9, val func loss 2.89397931098938\n",
      "\n",
      "episode 10, val func loss 2.2558882236480713\n",
      "\n",
      "episode 11, val func loss 3.2678050994873047\n",
      "\n",
      "episode 12, val func loss 3.250725269317627\n",
      "\n",
      "episode 13, val func loss 2.5972392559051514\n",
      "\n",
      "episode 14, val func loss 2.9524638652801514\n",
      "\n",
      "episode 15, val func loss 3.0038256645202637\n",
      "\n",
      "episode 16, val func loss 3.372896909713745\n",
      "\n",
      "Val func train loss in epoch 11:2.8669482320547104\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 3.2201194763183594\n",
      "\n",
      "episode 2, val func loss 3.2453439235687256\n",
      "\n",
      "episode 3, val func loss 3.1766626834869385\n",
      "\n",
      "episode 4, val func loss 2.494948148727417\n",
      "\n",
      "episode 5, val func loss 3.2083840370178223\n",
      "\n",
      "episode 6, val func loss 3.2249746322631836\n",
      "\n",
      "episode 7, val func loss 2.795389413833618\n",
      "\n",
      "episode 8, val func loss 3.1565704345703125\n",
      "\n",
      "episode 9, val func loss 3.22737979888916\n",
      "\n",
      "episode 10, val func loss 2.402204990386963\n",
      "\n",
      "episode 11, val func loss 2.9009780883789062\n",
      "\n",
      "episode 12, val func loss 2.912889242172241\n",
      "\n",
      "episode 13, val func loss 2.5886542797088623\n",
      "\n",
      "episode 14, val func loss 2.865799903869629\n",
      "\n",
      "episode 15, val func loss 2.236994981765747\n",
      "\n",
      "episode 16, val func loss 2.324587821960449\n",
      "\n",
      "Val func train loss in epoch 12:2.873867616057396\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 2.884401559829712\n",
      "\n",
      "episode 2, val func loss 2.9195218086242676\n",
      "\n",
      "episode 3, val func loss 2.729339122772217\n",
      "\n",
      "episode 4, val func loss 2.4881749153137207\n",
      "\n",
      "episode 5, val func loss 2.7787680625915527\n",
      "\n",
      "episode 6, val func loss 2.1953413486480713\n",
      "\n",
      "episode 7, val func loss 2.6927130222320557\n",
      "\n",
      "episode 8, val func loss 3.2189152240753174\n",
      "\n",
      "episode 9, val func loss 3.04899525642395\n",
      "\n",
      "episode 10, val func loss 2.9658091068267822\n",
      "\n",
      "episode 11, val func loss 2.3524746894836426\n",
      "\n",
      "episode 12, val func loss 3.307828903198242\n",
      "\n",
      "episode 13, val func loss 2.9596920013427734\n",
      "\n",
      "episode 14, val func loss 2.9815053939819336\n",
      "\n",
      "episode 15, val func loss 3.247697353363037\n",
      "\n",
      "episode 16, val func loss 3.2531328201293945\n",
      "\n",
      "Val func train loss in epoch 13:2.876519411802292\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.7757949829101562\n",
      "\n",
      "episode 2, val func loss 2.163081645965576\n",
      "\n",
      "episode 3, val func loss 3.0962610244750977\n",
      "\n",
      "episode 4, val func loss 3.4104957580566406\n",
      "\n",
      "episode 5, val func loss 2.804757833480835\n",
      "\n",
      "episode 6, val func loss 2.9003608226776123\n",
      "\n",
      "episode 7, val func loss 2.4214911460876465\n",
      "\n",
      "episode 8, val func loss 3.1176507472991943\n",
      "\n",
      "episode 9, val func loss 3.2084593772888184\n",
      "\n",
      "episode 10, val func loss 2.6394684314727783\n",
      "\n",
      "episode 11, val func loss 2.8112986087799072\n",
      "\n",
      "episode 12, val func loss 2.5480051040649414\n",
      "\n",
      "episode 13, val func loss 2.924147844314575\n",
      "\n",
      "episode 14, val func loss 2.86606502532959\n",
      "\n",
      "episode 15, val func loss 3.068187952041626\n",
      "\n",
      "episode 16, val func loss 3.441964864730835\n",
      "\n",
      "Val func train loss in epoch 14:2.8873431980609894\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.8350107669830322\n",
      "\n",
      "episode 2, val func loss 3.1004457473754883\n",
      "\n",
      "episode 3, val func loss 2.8113081455230713\n",
      "\n",
      "episode 4, val func loss 3.0316460132598877\n",
      "\n",
      "episode 5, val func loss 2.1373696327209473\n",
      "\n",
      "episode 6, val func loss 2.6371679306030273\n",
      "\n",
      "episode 7, val func loss 2.8711488246917725\n",
      "\n",
      "episode 8, val func loss 3.1534736156463623\n",
      "\n",
      "episode 9, val func loss 2.4841580390930176\n",
      "\n",
      "episode 10, val func loss 2.807905435562134\n",
      "\n",
      "episode 11, val func loss 2.918083667755127\n",
      "\n",
      "episode 12, val func loss 3.2396392822265625\n",
      "\n",
      "episode 13, val func loss 2.2286181449890137\n",
      "\n",
      "episode 14, val func loss 3.3052427768707275\n",
      "\n",
      "episode 15, val func loss 2.9173686504364014\n",
      "\n",
      "episode 16, val func loss 3.0098307132720947\n",
      "\n",
      "Val func train loss in epoch 15:2.8430260866880417\n",
      "***********************TIME WAS 4.931019349892934 min*****************************\n",
      "\n",
      "**********************ROUND 133 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 2.036281108856201\n",
      "\n",
      "episode 2, policy loss 1.8771755695343018\n",
      "\n",
      "episode 3, policy loss 2.0759925842285156\n",
      "\n",
      "episode 4, policy loss 2.281219720840454\n",
      "\n",
      "episode 5, policy loss 2.3678200244903564\n",
      "\n",
      "episode 6, policy loss 2.199892282485962\n",
      "\n",
      "episode 7, policy loss 1.989920973777771\n",
      "\n",
      "episode 8, policy loss 2.174283266067505\n",
      "\n",
      "episode 9, policy loss 1.9633384943008423\n",
      "\n",
      "episode 10, policy loss 2.0739386081695557\n",
      "\n",
      "episode 11, policy loss 2.0943684577941895\n",
      "\n",
      "episode 12, policy loss 2.261439800262451\n",
      "\n",
      "episode 13, policy loss 2.1127872467041016\n",
      "\n",
      "episode 14, policy loss 1.9378591775894165\n",
      "\n",
      "episode 15, policy loss 2.0126633644104004\n",
      "\n",
      "episode 16, policy loss 1.927499532699585\n",
      "\n",
      "Policy train loss in epoch 0:2.0866550132632256\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.828187108039856\n",
      "\n",
      "episode 2, policy loss 1.9102180004119873\n",
      "\n",
      "episode 3, policy loss 2.1263298988342285\n",
      "\n",
      "episode 4, policy loss 2.1474454402923584\n",
      "\n",
      "episode 5, policy loss 1.9521780014038086\n",
      "\n",
      "episode 6, policy loss 2.1459531784057617\n",
      "\n",
      "episode 7, policy loss 2.0261285305023193\n",
      "\n",
      "episode 8, policy loss 2.0074007511138916\n",
      "\n",
      "episode 9, policy loss 1.8707687854766846\n",
      "\n",
      "episode 10, policy loss 1.719537615776062\n",
      "\n",
      "episode 11, policy loss 1.753991961479187\n",
      "\n",
      "episode 12, policy loss 1.8487422466278076\n",
      "\n",
      "episode 13, policy loss 1.936300277709961\n",
      "\n",
      "episode 14, policy loss 1.8302803039550781\n",
      "\n",
      "episode 15, policy loss 1.8698694705963135\n",
      "\n",
      "episode 16, policy loss 1.966667652130127\n",
      "\n",
      "Policy train loss in epoch 1:1.9337499514222145\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.921114206314087\n",
      "\n",
      "episode 2, policy loss 1.8546679019927979\n",
      "\n",
      "episode 3, policy loss 1.8274729251861572\n",
      "\n",
      "episode 4, policy loss 2.0702030658721924\n",
      "\n",
      "episode 5, policy loss 1.8229666948318481\n",
      "\n",
      "episode 6, policy loss 1.8862005472183228\n",
      "\n",
      "episode 7, policy loss 1.719931960105896\n",
      "\n",
      "episode 8, policy loss 1.7374882698059082\n",
      "\n",
      "episode 9, policy loss 1.9432590007781982\n",
      "\n",
      "episode 10, policy loss 2.1245949268341064\n",
      "\n",
      "episode 11, policy loss 1.946454644203186\n",
      "\n",
      "episode 12, policy loss 1.8399206399917603\n",
      "\n",
      "episode 13, policy loss 2.128002643585205\n",
      "\n",
      "episode 14, policy loss 1.8966805934906006\n",
      "\n",
      "episode 15, policy loss 1.9458458423614502\n",
      "\n",
      "episode 16, policy loss 1.715613842010498\n",
      "\n",
      "Policy train loss in epoch 2:1.8987761065363884\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.8151835203170776\n",
      "\n",
      "episode 2, policy loss 1.8419075012207031\n",
      "\n",
      "episode 3, policy loss 1.8474150896072388\n",
      "\n",
      "episode 4, policy loss 1.8939852714538574\n",
      "\n",
      "episode 5, policy loss 2.121506929397583\n",
      "\n",
      "episode 6, policy loss 2.0718328952789307\n",
      "\n",
      "episode 7, policy loss 1.8940643072128296\n",
      "\n",
      "episode 8, policy loss 2.1223042011260986\n",
      "\n",
      "episode 9, policy loss 1.8145352602005005\n",
      "\n",
      "episode 10, policy loss 1.9496604204177856\n",
      "\n",
      "episode 11, policy loss 1.9481948614120483\n",
      "\n",
      "episode 12, policy loss 1.8732662200927734\n",
      "\n",
      "episode 13, policy loss 1.7145185470581055\n",
      "\n",
      "episode 14, policy loss 1.7391088008880615\n",
      "\n",
      "episode 15, policy loss 1.939971923828125\n",
      "\n",
      "episode 16, policy loss 1.7211979627609253\n",
      "\n",
      "Policy train loss in epoch 3:1.8942908570170403\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 4.1402459144592285\n",
      "\n",
      "episode 2, val func loss 4.168805122375488\n",
      "\n",
      "episode 3, val func loss 4.08840274810791\n",
      "\n",
      "episode 4, val func loss 4.627023696899414\n",
      "\n",
      "episode 5, val func loss 3.964440107345581\n",
      "\n",
      "episode 6, val func loss 4.787288665771484\n",
      "\n",
      "episode 7, val func loss 5.056099891662598\n",
      "\n",
      "episode 8, val func loss 5.068150997161865\n",
      "\n",
      "episode 9, val func loss 4.322850227355957\n",
      "\n",
      "episode 10, val func loss 4.278326511383057\n",
      "\n",
      "episode 11, val func loss 4.439910888671875\n",
      "\n",
      "episode 12, val func loss 4.465282917022705\n",
      "\n",
      "episode 13, val func loss 3.6290535926818848\n",
      "\n",
      "episode 14, val func loss 5.09547758102417\n",
      "\n",
      "episode 15, val func loss 3.932879686355591\n",
      "\n",
      "episode 16, val func loss 4.283242225646973\n",
      "\n",
      "Val func train loss in epoch 0:4.396717548370361\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 3.911472797393799\n",
      "\n",
      "episode 2, val func loss 4.405642509460449\n",
      "\n",
      "episode 3, val func loss 4.3919172286987305\n",
      "\n",
      "episode 4, val func loss 4.9541754722595215\n",
      "\n",
      "episode 5, val func loss 5.177473545074463\n",
      "\n",
      "episode 6, val func loss 4.636451244354248\n",
      "\n",
      "episode 7, val func loss 4.1770548820495605\n",
      "\n",
      "episode 8, val func loss 4.5387067794799805\n",
      "\n",
      "episode 9, val func loss 4.04985237121582\n",
      "\n",
      "episode 10, val func loss 4.602199077606201\n",
      "\n",
      "episode 11, val func loss 4.183565616607666\n",
      "\n",
      "episode 12, val func loss 4.293668270111084\n",
      "\n",
      "episode 13, val func loss 4.360084056854248\n",
      "\n",
      "episode 14, val func loss 5.00492525100708\n",
      "\n",
      "episode 15, val func loss 4.226710796356201\n",
      "\n",
      "episode 16, val func loss 4.138826370239258\n",
      "\n",
      "Val func train loss in epoch 1:4.440795391798019\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 4.312775611877441\n",
      "\n",
      "episode 2, val func loss 5.037035942077637\n",
      "\n",
      "episode 3, val func loss 3.9412670135498047\n",
      "\n",
      "episode 4, val func loss 4.772882461547852\n",
      "\n",
      "episode 5, val func loss 4.450684547424316\n",
      "\n",
      "episode 6, val func loss 4.072702407836914\n",
      "\n",
      "episode 7, val func loss 4.753653049468994\n",
      "\n",
      "episode 8, val func loss 4.179844856262207\n",
      "\n",
      "episode 9, val func loss 4.626748085021973\n",
      "\n",
      "episode 10, val func loss 4.942115783691406\n",
      "\n",
      "episode 11, val func loss 3.816478729248047\n",
      "\n",
      "episode 12, val func loss 3.8085403442382812\n",
      "\n",
      "episode 13, val func loss 4.217859745025635\n",
      "\n",
      "episode 14, val func loss 3.904465675354004\n",
      "\n",
      "episode 15, val func loss 5.157662868499756\n",
      "\n",
      "episode 16, val func loss 4.471464157104492\n",
      "\n",
      "Val func train loss in epoch 2:4.4041363298892975\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 4.904191970825195\n",
      "\n",
      "episode 2, val func loss 4.466773986816406\n",
      "\n",
      "episode 3, val func loss 4.265185356140137\n",
      "\n",
      "episode 4, val func loss 3.977828025817871\n",
      "\n",
      "episode 5, val func loss 3.833137273788452\n",
      "\n",
      "episode 6, val func loss 4.426894664764404\n",
      "\n",
      "episode 7, val func loss 4.421730995178223\n",
      "\n",
      "episode 8, val func loss 5.097706317901611\n",
      "\n",
      "episode 9, val func loss 4.5422682762146\n",
      "\n",
      "episode 10, val func loss 5.2922468185424805\n",
      "\n",
      "episode 11, val func loss 4.771770000457764\n",
      "\n",
      "episode 12, val func loss 4.349342346191406\n",
      "\n",
      "episode 13, val func loss 4.729734420776367\n",
      "\n",
      "episode 14, val func loss 4.4944071769714355\n",
      "\n",
      "episode 15, val func loss 4.348179340362549\n",
      "\n",
      "episode 16, val func loss 4.045612812042236\n",
      "\n",
      "Val func train loss in epoch 3:4.497938111424446\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 4.336599826812744\n",
      "\n",
      "episode 2, val func loss 4.466915130615234\n",
      "\n",
      "episode 3, val func loss 4.051063060760498\n",
      "\n",
      "episode 4, val func loss 5.08905029296875\n",
      "\n",
      "episode 5, val func loss 4.1463623046875\n",
      "\n",
      "episode 6, val func loss 4.500777721405029\n",
      "\n",
      "episode 7, val func loss 4.239631175994873\n",
      "\n",
      "episode 8, val func loss 5.04623556137085\n",
      "\n",
      "episode 9, val func loss 4.921740531921387\n",
      "\n",
      "episode 10, val func loss 4.515658378601074\n",
      "\n",
      "episode 11, val func loss 5.153666019439697\n",
      "\n",
      "episode 12, val func loss 4.829135417938232\n",
      "\n",
      "episode 13, val func loss 3.659135580062866\n",
      "\n",
      "episode 14, val func loss 4.513635635375977\n",
      "\n",
      "episode 15, val func loss 4.77468729019165\n",
      "\n",
      "episode 16, val func loss 4.401769638061523\n",
      "\n",
      "Val func train loss in epoch 4:4.540378972887993\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 4.810082912445068\n",
      "\n",
      "episode 2, val func loss 4.253392219543457\n",
      "\n",
      "episode 3, val func loss 5.111509799957275\n",
      "\n",
      "episode 4, val func loss 3.8766980171203613\n",
      "\n",
      "episode 5, val func loss 4.624512672424316\n",
      "\n",
      "episode 6, val func loss 4.316805362701416\n",
      "\n",
      "episode 7, val func loss 4.396135330200195\n",
      "\n",
      "episode 8, val func loss 4.253769874572754\n",
      "\n",
      "episode 9, val func loss 3.7958831787109375\n",
      "\n",
      "episode 10, val func loss 4.346654891967773\n",
      "\n",
      "episode 11, val func loss 4.350943088531494\n",
      "\n",
      "episode 12, val func loss 5.185878753662109\n",
      "\n",
      "episode 13, val func loss 4.305308818817139\n",
      "\n",
      "episode 14, val func loss 4.440541744232178\n",
      "\n",
      "episode 15, val func loss 4.576243877410889\n",
      "\n",
      "episode 16, val func loss 4.5108160972595215\n",
      "\n",
      "Val func train loss in epoch 5:4.447198539972305\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 4.276599407196045\n",
      "\n",
      "episode 2, val func loss 3.823323965072632\n",
      "\n",
      "episode 3, val func loss 4.229407787322998\n",
      "\n",
      "episode 4, val func loss 5.123404502868652\n",
      "\n",
      "episode 5, val func loss 4.801046371459961\n",
      "\n",
      "episode 6, val func loss 4.259183883666992\n",
      "\n",
      "episode 7, val func loss 4.906637668609619\n",
      "\n",
      "episode 8, val func loss 4.415567874908447\n",
      "\n",
      "episode 9, val func loss 4.9915771484375\n",
      "\n",
      "episode 10, val func loss 5.310490131378174\n",
      "\n",
      "episode 11, val func loss 5.110607624053955\n",
      "\n",
      "episode 12, val func loss 4.4576334953308105\n",
      "\n",
      "episode 13, val func loss 4.12224006652832\n",
      "\n",
      "episode 14, val func loss 4.2149434089660645\n",
      "\n",
      "episode 15, val func loss 4.00813627243042\n",
      "\n",
      "episode 16, val func loss 3.860349655151367\n",
      "\n",
      "Val func train loss in epoch 6:4.494446828961372\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 4.863494873046875\n",
      "\n",
      "episode 2, val func loss 4.346302509307861\n",
      "\n",
      "episode 3, val func loss 3.949857711791992\n",
      "\n",
      "episode 4, val func loss 4.514124870300293\n",
      "\n",
      "episode 5, val func loss 4.11240291595459\n",
      "\n",
      "episode 6, val func loss 3.945096254348755\n",
      "\n",
      "episode 7, val func loss 4.141232013702393\n",
      "\n",
      "episode 8, val func loss 3.4925100803375244\n",
      "\n",
      "episode 9, val func loss 4.544724464416504\n",
      "\n",
      "episode 10, val func loss 5.288994789123535\n",
      "\n",
      "episode 11, val func loss 4.781439304351807\n",
      "\n",
      "episode 12, val func loss 5.009061336517334\n",
      "\n",
      "episode 13, val func loss 4.377119064331055\n",
      "\n",
      "episode 14, val func loss 4.596436977386475\n",
      "\n",
      "episode 15, val func loss 4.529215335845947\n",
      "\n",
      "episode 16, val func loss 4.553642272949219\n",
      "\n",
      "Val func train loss in epoch 7:4.44035342335701\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 4.83213996887207\n",
      "\n",
      "episode 2, val func loss 4.43602991104126\n",
      "\n",
      "episode 3, val func loss 4.458849906921387\n",
      "\n",
      "episode 4, val func loss 4.103840351104736\n",
      "\n",
      "episode 5, val func loss 3.7339091300964355\n",
      "\n",
      "episode 6, val func loss 4.537825107574463\n",
      "\n",
      "episode 7, val func loss 4.676815509796143\n",
      "\n",
      "episode 8, val func loss 4.08098840713501\n",
      "\n",
      "episode 9, val func loss 4.939052581787109\n",
      "\n",
      "episode 10, val func loss 4.543911457061768\n",
      "\n",
      "episode 11, val func loss 4.758562088012695\n",
      "\n",
      "episode 12, val func loss 3.8324878215789795\n",
      "\n",
      "episode 13, val func loss 3.643428087234497\n",
      "\n",
      "episode 14, val func loss 4.361764430999756\n",
      "\n",
      "episode 15, val func loss 4.749955177307129\n",
      "\n",
      "episode 16, val func loss 3.68985652923584\n",
      "\n",
      "Val func train loss in epoch 8:4.336213529109955\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 5.2413177490234375\n",
      "\n",
      "episode 2, val func loss 4.111275672912598\n",
      "\n",
      "episode 3, val func loss 4.693509578704834\n",
      "\n",
      "episode 4, val func loss 3.750131368637085\n",
      "\n",
      "episode 5, val func loss 4.258577823638916\n",
      "\n",
      "episode 6, val func loss 4.201220512390137\n",
      "\n",
      "episode 7, val func loss 4.567910194396973\n",
      "\n",
      "episode 8, val func loss 4.551126480102539\n",
      "\n",
      "episode 9, val func loss 4.972981929779053\n",
      "\n",
      "episode 10, val func loss 4.59311056137085\n",
      "\n",
      "episode 11, val func loss 4.475183963775635\n",
      "\n",
      "episode 12, val func loss 4.615283489227295\n",
      "\n",
      "episode 13, val func loss 4.488311767578125\n",
      "\n",
      "episode 14, val func loss 4.352725505828857\n",
      "\n",
      "episode 15, val func loss 4.286222457885742\n",
      "\n",
      "episode 16, val func loss 3.954192638397217\n",
      "\n",
      "Val func train loss in epoch 9:4.444567605853081\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 4.781086444854736\n",
      "\n",
      "episode 2, val func loss 4.186010360717773\n",
      "\n",
      "episode 3, val func loss 4.357914447784424\n",
      "\n",
      "episode 4, val func loss 5.217742443084717\n",
      "\n",
      "episode 5, val func loss 3.9465458393096924\n",
      "\n",
      "episode 6, val func loss 4.097146987915039\n",
      "\n",
      "episode 7, val func loss 4.354060173034668\n",
      "\n",
      "episode 8, val func loss 4.643040180206299\n",
      "\n",
      "episode 9, val func loss 3.901273727416992\n",
      "\n",
      "episode 10, val func loss 4.743812084197998\n",
      "\n",
      "episode 11, val func loss 4.410240173339844\n",
      "\n",
      "episode 12, val func loss 3.900583028793335\n",
      "\n",
      "episode 13, val func loss 4.234561443328857\n",
      "\n",
      "episode 14, val func loss 4.898469924926758\n",
      "\n",
      "episode 15, val func loss 4.529802322387695\n",
      "\n",
      "episode 16, val func loss 4.501638889312744\n",
      "\n",
      "Val func train loss in epoch 10:4.418995529413223\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 4.156619071960449\n",
      "\n",
      "episode 2, val func loss 5.217276573181152\n",
      "\n",
      "episode 3, val func loss 4.717226028442383\n",
      "\n",
      "episode 4, val func loss 4.833258152008057\n",
      "\n",
      "episode 5, val func loss 4.292162895202637\n",
      "\n",
      "episode 6, val func loss 4.39603328704834\n",
      "\n",
      "episode 7, val func loss 4.291465759277344\n",
      "\n",
      "episode 8, val func loss 4.069554328918457\n",
      "\n",
      "episode 9, val func loss 4.761353492736816\n",
      "\n",
      "episode 10, val func loss 4.103297233581543\n",
      "\n",
      "episode 11, val func loss 4.862964630126953\n",
      "\n",
      "episode 12, val func loss 3.88254451751709\n",
      "\n",
      "episode 13, val func loss 4.4134135246276855\n",
      "\n",
      "episode 14, val func loss 4.75606632232666\n",
      "\n",
      "episode 15, val func loss 4.538863658905029\n",
      "\n",
      "episode 16, val func loss 4.149855136871338\n",
      "\n",
      "Val func train loss in epoch 11:4.465122163295746\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 3.970899820327759\n",
      "\n",
      "episode 2, val func loss 4.217144966125488\n",
      "\n",
      "episode 3, val func loss 4.468631744384766\n",
      "\n",
      "episode 4, val func loss 5.262258052825928\n",
      "\n",
      "episode 5, val func loss 5.14111328125\n",
      "\n",
      "episode 6, val func loss 5.005543231964111\n",
      "\n",
      "episode 7, val func loss 4.52925443649292\n",
      "\n",
      "episode 8, val func loss 4.293027400970459\n",
      "\n",
      "episode 9, val func loss 4.371542453765869\n",
      "\n",
      "episode 10, val func loss 4.599312782287598\n",
      "\n",
      "episode 11, val func loss 4.149595737457275\n",
      "\n",
      "episode 12, val func loss 3.6982972621917725\n",
      "\n",
      "episode 13, val func loss 4.494777679443359\n",
      "\n",
      "episode 14, val func loss 4.4821624755859375\n",
      "\n",
      "episode 15, val func loss 3.7445666790008545\n",
      "\n",
      "episode 16, val func loss 5.0072922706604\n",
      "\n",
      "Val func train loss in epoch 12:4.464713767170906\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 5.016520977020264\n",
      "\n",
      "episode 2, val func loss 4.967340469360352\n",
      "\n",
      "episode 3, val func loss 4.623819828033447\n",
      "\n",
      "episode 4, val func loss 4.580625534057617\n",
      "\n",
      "episode 5, val func loss 3.975327253341675\n",
      "\n",
      "episode 6, val func loss 3.9996931552886963\n",
      "\n",
      "episode 7, val func loss 5.537003993988037\n",
      "\n",
      "episode 8, val func loss 3.8979692459106445\n",
      "\n",
      "episode 9, val func loss 4.359251022338867\n",
      "\n",
      "episode 10, val func loss 4.276336669921875\n",
      "\n",
      "episode 11, val func loss 4.790150165557861\n",
      "\n",
      "episode 12, val func loss 4.38332986831665\n",
      "\n",
      "episode 13, val func loss 4.213749408721924\n",
      "\n",
      "episode 14, val func loss 4.469274520874023\n",
      "\n",
      "episode 15, val func loss 4.293712615966797\n",
      "\n",
      "episode 16, val func loss 4.89726448059082\n",
      "\n",
      "Val func train loss in epoch 13:4.517585575580597\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 4.510237216949463\n",
      "\n",
      "episode 2, val func loss 4.142868995666504\n",
      "\n",
      "episode 3, val func loss 4.667513370513916\n",
      "\n",
      "episode 4, val func loss 4.209687232971191\n",
      "\n",
      "episode 5, val func loss 4.641292572021484\n",
      "\n",
      "episode 6, val func loss 4.928603649139404\n",
      "\n",
      "episode 7, val func loss 4.543957233428955\n",
      "\n",
      "episode 8, val func loss 4.72912073135376\n",
      "\n",
      "episode 9, val func loss 3.919401168823242\n",
      "\n",
      "episode 10, val func loss 3.901115894317627\n",
      "\n",
      "episode 11, val func loss 4.192575454711914\n",
      "\n",
      "episode 12, val func loss 3.7968428134918213\n",
      "\n",
      "episode 13, val func loss 5.017706871032715\n",
      "\n",
      "episode 14, val func loss 4.874858856201172\n",
      "\n",
      "episode 15, val func loss 3.7075467109680176\n",
      "\n",
      "episode 16, val func loss 4.3430070877075195\n",
      "\n",
      "Val func train loss in epoch 14:4.382895991206169\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 4.266909599304199\n",
      "\n",
      "episode 2, val func loss 4.827733039855957\n",
      "\n",
      "episode 3, val func loss 4.447409629821777\n",
      "\n",
      "episode 4, val func loss 4.050799369812012\n",
      "\n",
      "episode 5, val func loss 4.564492225646973\n",
      "\n",
      "episode 6, val func loss 4.559443473815918\n",
      "\n",
      "episode 7, val func loss 4.0192670822143555\n",
      "\n",
      "episode 8, val func loss 3.817136526107788\n",
      "\n",
      "episode 9, val func loss 4.270639419555664\n",
      "\n",
      "episode 10, val func loss 4.903946876525879\n",
      "\n",
      "episode 11, val func loss 3.5709784030914307\n",
      "\n",
      "episode 12, val func loss 4.160559177398682\n",
      "\n",
      "episode 13, val func loss 4.34633207321167\n",
      "\n",
      "episode 14, val func loss 4.7623372077941895\n",
      "\n",
      "episode 15, val func loss 4.728743076324463\n",
      "\n",
      "episode 16, val func loss 4.117127895355225\n",
      "\n",
      "Val func train loss in epoch 15:4.338365942239761\n",
      "***********************TIME WAS 4.931861778100331 min*****************************\n",
      "\n",
      "**********************ROUND 134 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.0\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.2368292808532715\n",
      "\n",
      "episode 2, policy loss 0.8436429500579834\n",
      "\n",
      "episode 3, policy loss 0.8705834150314331\n",
      "\n",
      "episode 4, policy loss 1.1246062517166138\n",
      "\n",
      "episode 5, policy loss 0.9551541209220886\n",
      "\n",
      "episode 6, policy loss 1.1373562812805176\n",
      "\n",
      "episode 7, policy loss 1.1616721153259277\n",
      "\n",
      "episode 8, policy loss 1.1009345054626465\n",
      "\n",
      "episode 9, policy loss 0.952982485294342\n",
      "\n",
      "episode 10, policy loss 1.182072639465332\n",
      "\n",
      "episode 11, policy loss 0.8291804790496826\n",
      "\n",
      "episode 12, policy loss 0.9322429299354553\n",
      "\n",
      "episode 13, policy loss 0.9860390424728394\n",
      "\n",
      "episode 14, policy loss 1.0084385871887207\n",
      "\n",
      "episode 15, policy loss 0.9777632355690002\n",
      "\n",
      "episode 16, policy loss 0.8751072883605957\n",
      "\n",
      "Policy train loss in epoch 0:1.0109128504991531\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.9582011103630066\n",
      "\n",
      "episode 2, policy loss 1.106231689453125\n",
      "\n",
      "episode 3, policy loss 1.1344521045684814\n",
      "\n",
      "episode 4, policy loss 0.9729767441749573\n",
      "\n",
      "episode 5, policy loss 1.142997145652771\n",
      "\n",
      "episode 6, policy loss 0.8601455688476562\n",
      "\n",
      "episode 7, policy loss 0.9009694457054138\n",
      "\n",
      "episode 8, policy loss 1.1538254022598267\n",
      "\n",
      "episode 9, policy loss 0.9122774004936218\n",
      "\n",
      "episode 10, policy loss 1.0984766483306885\n",
      "\n",
      "episode 11, policy loss 0.8507900834083557\n",
      "\n",
      "episode 12, policy loss 0.9150087237358093\n",
      "\n",
      "episode 13, policy loss 0.9633721709251404\n",
      "\n",
      "episode 14, policy loss 0.7478991746902466\n",
      "\n",
      "episode 15, policy loss 1.0958738327026367\n",
      "\n",
      "episode 16, policy loss 0.9297655820846558\n",
      "\n",
      "Policy train loss in epoch 1:0.9839539267122746\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.964128851890564\n",
      "\n",
      "episode 2, policy loss 1.1343954801559448\n",
      "\n",
      "episode 3, policy loss 0.8918166160583496\n",
      "\n",
      "episode 4, policy loss 1.069104790687561\n",
      "\n",
      "episode 5, policy loss 1.0832264423370361\n",
      "\n",
      "episode 6, policy loss 1.1072771549224854\n",
      "\n",
      "episode 7, policy loss 0.9176117181777954\n",
      "\n",
      "episode 8, policy loss 0.8919318318367004\n",
      "\n",
      "episode 9, policy loss 1.0452077388763428\n",
      "\n",
      "episode 10, policy loss 0.7925151586532593\n",
      "\n",
      "episode 11, policy loss 0.7584691047668457\n",
      "\n",
      "episode 12, policy loss 1.1040964126586914\n",
      "\n",
      "episode 13, policy loss 0.9087838530540466\n",
      "\n",
      "episode 14, policy loss 0.8252944946289062\n",
      "\n",
      "episode 15, policy loss 0.8642148971557617\n",
      "\n",
      "episode 16, policy loss 0.8546561598777771\n",
      "\n",
      "Policy train loss in epoch 2:0.9507956691086292\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.7413370609283447\n",
      "\n",
      "episode 2, policy loss 1.080658197402954\n",
      "\n",
      "episode 3, policy loss 0.9383735656738281\n",
      "\n",
      "episode 4, policy loss 0.8753960132598877\n",
      "\n",
      "episode 5, policy loss 0.9015515446662903\n",
      "\n",
      "episode 6, policy loss 0.8450631499290466\n",
      "\n",
      "episode 7, policy loss 0.8812721967697144\n",
      "\n",
      "episode 8, policy loss 1.108431339263916\n",
      "\n",
      "episode 9, policy loss 1.061752200126648\n",
      "\n",
      "episode 10, policy loss 1.0998783111572266\n",
      "\n",
      "episode 11, policy loss 1.0337616205215454\n",
      "\n",
      "episode 12, policy loss 0.7924176454544067\n",
      "\n",
      "episode 13, policy loss 0.8351531624794006\n",
      "\n",
      "episode 14, policy loss 1.089465856552124\n",
      "\n",
      "episode 15, policy loss 0.9053529500961304\n",
      "\n",
      "episode 16, policy loss 0.8595736026763916\n",
      "\n",
      "Policy train loss in epoch 3:0.940589901059866\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 5.383442401885986\n",
      "\n",
      "episode 2, val func loss 5.858076095581055\n",
      "\n",
      "episode 3, val func loss 4.8664960861206055\n",
      "\n",
      "episode 4, val func loss 5.28006649017334\n",
      "\n",
      "episode 5, val func loss 5.437137603759766\n",
      "\n",
      "episode 6, val func loss 5.290428638458252\n",
      "\n",
      "episode 7, val func loss 5.768527030944824\n",
      "\n",
      "episode 8, val func loss 5.59519624710083\n",
      "\n",
      "episode 9, val func loss 5.078384876251221\n",
      "\n",
      "episode 10, val func loss 5.291991710662842\n",
      "\n",
      "episode 11, val func loss 5.487443923950195\n",
      "\n",
      "episode 12, val func loss 6.09344482421875\n",
      "\n",
      "episode 13, val func loss 5.894806861877441\n",
      "\n",
      "episode 14, val func loss 5.485427379608154\n",
      "\n",
      "episode 15, val func loss 5.692885875701904\n",
      "\n",
      "episode 16, val func loss 5.487452507019043\n",
      "\n",
      "Val func train loss in epoch 0:5.499450534582138\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 5.291993618011475\n",
      "\n",
      "episode 2, val func loss 5.528366565704346\n",
      "\n",
      "episode 3, val func loss 5.554842472076416\n",
      "\n",
      "episode 4, val func loss 5.249399185180664\n",
      "\n",
      "episode 5, val func loss 5.0077056884765625\n",
      "\n",
      "episode 6, val func loss 5.114489555358887\n",
      "\n",
      "episode 7, val func loss 5.522642135620117\n",
      "\n",
      "episode 8, val func loss 5.7435503005981445\n",
      "\n",
      "episode 9, val func loss 5.251245498657227\n",
      "\n",
      "episode 10, val func loss 5.263803958892822\n",
      "\n",
      "episode 11, val func loss 5.922998905181885\n",
      "\n",
      "episode 12, val func loss 5.516406536102295\n",
      "\n",
      "episode 13, val func loss 5.660998821258545\n",
      "\n",
      "episode 14, val func loss 5.840947151184082\n",
      "\n",
      "episode 15, val func loss 5.7695393562316895\n",
      "\n",
      "episode 16, val func loss 5.749231338500977\n",
      "\n",
      "Val func train loss in epoch 1:5.499260067939758\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 5.029207229614258\n",
      "\n",
      "episode 2, val func loss 5.230759620666504\n",
      "\n",
      "episode 3, val func loss 5.077106952667236\n",
      "\n",
      "episode 4, val func loss 4.926150321960449\n",
      "\n",
      "episode 5, val func loss 5.627635955810547\n",
      "\n",
      "episode 6, val func loss 5.749290943145752\n",
      "\n",
      "episode 7, val func loss 5.6134748458862305\n",
      "\n",
      "episode 8, val func loss 5.6576128005981445\n",
      "\n",
      "episode 9, val func loss 5.332232475280762\n",
      "\n",
      "episode 10, val func loss 5.40458869934082\n",
      "\n",
      "episode 11, val func loss 5.141057014465332\n",
      "\n",
      "episode 12, val func loss 5.22243595123291\n",
      "\n",
      "episode 13, val func loss 5.373447418212891\n",
      "\n",
      "episode 14, val func loss 5.770588397979736\n",
      "\n",
      "episode 15, val func loss 5.551220417022705\n",
      "\n",
      "episode 16, val func loss 5.738522052764893\n",
      "\n",
      "Val func train loss in epoch 2:5.402833193540573\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 4.948879241943359\n",
      "\n",
      "episode 2, val func loss 4.94410514831543\n",
      "\n",
      "episode 3, val func loss 5.171360015869141\n",
      "\n",
      "episode 4, val func loss 5.281559467315674\n",
      "\n",
      "episode 5, val func loss 5.9670867919921875\n",
      "\n",
      "episode 6, val func loss 5.438912391662598\n",
      "\n",
      "episode 7, val func loss 5.638697624206543\n",
      "\n",
      "episode 8, val func loss 5.46771764755249\n",
      "\n",
      "episode 9, val func loss 5.31825065612793\n",
      "\n",
      "episode 10, val func loss 5.78232479095459\n",
      "\n",
      "episode 11, val func loss 5.554297924041748\n",
      "\n",
      "episode 12, val func loss 5.8663835525512695\n",
      "\n",
      "episode 13, val func loss 5.766594886779785\n",
      "\n",
      "episode 14, val func loss 5.729517459869385\n",
      "\n",
      "episode 15, val func loss 5.395288944244385\n",
      "\n",
      "episode 16, val func loss 5.61330509185791\n",
      "\n",
      "Val func train loss in epoch 3:5.4927676022052765\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 5.448124885559082\n",
      "\n",
      "episode 2, val func loss 5.534299373626709\n",
      "\n",
      "episode 3, val func loss 5.091585159301758\n",
      "\n",
      "episode 4, val func loss 5.48642110824585\n",
      "\n",
      "episode 5, val func loss 5.175853729248047\n",
      "\n",
      "episode 6, val func loss 5.2200117111206055\n",
      "\n",
      "episode 7, val func loss 5.814000606536865\n",
      "\n",
      "episode 8, val func loss 5.516777038574219\n",
      "\n",
      "episode 9, val func loss 5.388956069946289\n",
      "\n",
      "episode 10, val func loss 5.402332782745361\n",
      "\n",
      "episode 11, val func loss 5.64054536819458\n",
      "\n",
      "episode 12, val func loss 5.251339912414551\n",
      "\n",
      "episode 13, val func loss 5.6793904304504395\n",
      "\n",
      "episode 14, val func loss 6.301300048828125\n",
      "\n",
      "episode 15, val func loss 5.922637939453125\n",
      "\n",
      "episode 16, val func loss 5.715634822845459\n",
      "\n",
      "Val func train loss in epoch 4:5.5368256866931915\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 5.6522908210754395\n",
      "\n",
      "episode 2, val func loss 5.275444507598877\n",
      "\n",
      "episode 3, val func loss 5.744377136230469\n",
      "\n",
      "episode 4, val func loss 5.5213623046875\n",
      "\n",
      "episode 5, val func loss 5.17748498916626\n",
      "\n",
      "episode 6, val func loss 5.8699727058410645\n",
      "\n",
      "episode 7, val func loss 5.17570686340332\n",
      "\n",
      "episode 8, val func loss 6.09964656829834\n",
      "\n",
      "episode 9, val func loss 6.6281867027282715\n",
      "\n",
      "episode 10, val func loss 5.15351676940918\n",
      "\n",
      "episode 11, val func loss 5.330357074737549\n",
      "\n",
      "episode 12, val func loss 5.488461017608643\n",
      "\n",
      "episode 13, val func loss 6.308516979217529\n",
      "\n",
      "episode 14, val func loss 6.040866374969482\n",
      "\n",
      "episode 15, val func loss 6.159996032714844\n",
      "\n",
      "episode 16, val func loss 5.466921806335449\n",
      "\n",
      "Val func train loss in epoch 5:5.6933192908763885\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 5.171164035797119\n",
      "\n",
      "episode 2, val func loss 5.525156497955322\n",
      "\n",
      "episode 3, val func loss 5.683106899261475\n",
      "\n",
      "episode 4, val func loss 5.743515968322754\n",
      "\n",
      "episode 5, val func loss 5.854274749755859\n",
      "\n",
      "episode 6, val func loss 5.390026092529297\n",
      "\n",
      "episode 7, val func loss 5.3207221031188965\n",
      "\n",
      "episode 8, val func loss 5.3496246337890625\n",
      "\n",
      "episode 9, val func loss 5.453278541564941\n",
      "\n",
      "episode 10, val func loss 6.214256286621094\n",
      "\n",
      "episode 11, val func loss 5.746006965637207\n",
      "\n",
      "episode 12, val func loss 5.323009967803955\n",
      "\n",
      "episode 13, val func loss 5.397691249847412\n",
      "\n",
      "episode 14, val func loss 5.068699836730957\n",
      "\n",
      "episode 15, val func loss 5.391788959503174\n",
      "\n",
      "episode 16, val func loss 5.423448085784912\n",
      "\n",
      "Val func train loss in epoch 6:5.503485679626465\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 5.693221569061279\n",
      "\n",
      "episode 2, val func loss 5.052799701690674\n",
      "\n",
      "episode 3, val func loss 5.464757442474365\n",
      "\n",
      "episode 4, val func loss 5.537603855133057\n",
      "\n",
      "episode 5, val func loss 5.236283779144287\n",
      "\n",
      "episode 6, val func loss 4.998337268829346\n",
      "\n",
      "episode 7, val func loss 4.794897556304932\n",
      "\n",
      "episode 8, val func loss 5.787871837615967\n",
      "\n",
      "episode 9, val func loss 5.825321674346924\n",
      "\n",
      "episode 10, val func loss 5.355452060699463\n",
      "\n",
      "episode 11, val func loss 5.951233863830566\n",
      "\n",
      "episode 12, val func loss 5.67228364944458\n",
      "\n",
      "episode 13, val func loss 5.066934585571289\n",
      "\n",
      "episode 14, val func loss 5.526764869689941\n",
      "\n",
      "episode 15, val func loss 5.8980712890625\n",
      "\n",
      "episode 16, val func loss 5.1291961669921875\n",
      "\n",
      "Val func train loss in epoch 7:5.43693944811821\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 5.558899402618408\n",
      "\n",
      "episode 2, val func loss 5.232028961181641\n",
      "\n",
      "episode 3, val func loss 5.178514003753662\n",
      "\n",
      "episode 4, val func loss 5.800227165222168\n",
      "\n",
      "episode 5, val func loss 5.499849319458008\n",
      "\n",
      "episode 6, val func loss 5.7069292068481445\n",
      "\n",
      "episode 7, val func loss 5.474752426147461\n",
      "\n",
      "episode 8, val func loss 5.262732028961182\n",
      "\n",
      "episode 9, val func loss 5.857443332672119\n",
      "\n",
      "episode 10, val func loss 6.21432638168335\n",
      "\n",
      "episode 11, val func loss 5.129491329193115\n",
      "\n",
      "episode 12, val func loss 5.445433139801025\n",
      "\n",
      "episode 13, val func loss 5.0474395751953125\n",
      "\n",
      "episode 14, val func loss 5.032721042633057\n",
      "\n",
      "episode 15, val func loss 5.192028045654297\n",
      "\n",
      "episode 16, val func loss 5.181149005889893\n",
      "\n",
      "Val func train loss in epoch 8:5.425872772932053\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 5.653464317321777\n",
      "\n",
      "episode 2, val func loss 5.2292938232421875\n",
      "\n",
      "episode 3, val func loss 5.212815284729004\n",
      "\n",
      "episode 4, val func loss 5.49004602432251\n",
      "\n",
      "episode 5, val func loss 5.845232963562012\n",
      "\n",
      "episode 6, val func loss 5.699110507965088\n",
      "\n",
      "episode 7, val func loss 5.3382720947265625\n",
      "\n",
      "episode 8, val func loss 5.356619358062744\n",
      "\n",
      "episode 9, val func loss 5.0030341148376465\n",
      "\n",
      "episode 10, val func loss 6.11796760559082\n",
      "\n",
      "episode 11, val func loss 5.616534233093262\n",
      "\n",
      "episode 12, val func loss 6.397265911102295\n",
      "\n",
      "episode 13, val func loss 5.52737283706665\n",
      "\n",
      "episode 14, val func loss 5.4368791580200195\n",
      "\n",
      "episode 15, val func loss 5.572593688964844\n",
      "\n",
      "episode 16, val func loss 5.427157402038574\n",
      "\n",
      "Val func train loss in epoch 9:5.557728707790375\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 5.488877773284912\n",
      "\n",
      "episode 2, val func loss 5.574338436126709\n",
      "\n",
      "episode 3, val func loss 5.4143147468566895\n",
      "\n",
      "episode 4, val func loss 5.608596324920654\n",
      "\n",
      "episode 5, val func loss 5.770909309387207\n",
      "\n",
      "episode 6, val func loss 5.36714506149292\n",
      "\n",
      "episode 7, val func loss 5.319293022155762\n",
      "\n",
      "episode 8, val func loss 5.8299560546875\n",
      "\n",
      "episode 9, val func loss 5.581040382385254\n",
      "\n",
      "episode 10, val func loss 5.7055511474609375\n",
      "\n",
      "episode 11, val func loss 5.371602535247803\n",
      "\n",
      "episode 12, val func loss 6.029871463775635\n",
      "\n",
      "episode 13, val func loss 5.236856460571289\n",
      "\n",
      "episode 14, val func loss 6.25299596786499\n",
      "\n",
      "episode 15, val func loss 5.309584140777588\n",
      "\n",
      "episode 16, val func loss 5.666891574859619\n",
      "\n",
      "Val func train loss in epoch 10:5.595489025115967\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 5.513237953186035\n",
      "\n",
      "episode 2, val func loss 5.392591953277588\n",
      "\n",
      "episode 3, val func loss 5.793520927429199\n",
      "\n",
      "episode 4, val func loss 5.69957971572876\n",
      "\n",
      "episode 5, val func loss 5.715304374694824\n",
      "\n",
      "episode 6, val func loss 5.671050548553467\n",
      "\n",
      "episode 7, val func loss 5.705423355102539\n",
      "\n",
      "episode 8, val func loss 4.890026092529297\n",
      "\n",
      "episode 9, val func loss 5.338578701019287\n",
      "\n",
      "episode 10, val func loss 5.5384602546691895\n",
      "\n",
      "episode 11, val func loss 5.867046356201172\n",
      "\n",
      "episode 12, val func loss 6.1232991218566895\n",
      "\n",
      "episode 13, val func loss 6.15400505065918\n",
      "\n",
      "episode 14, val func loss 4.875397205352783\n",
      "\n",
      "episode 15, val func loss 5.023895263671875\n",
      "\n",
      "episode 16, val func loss 5.272125244140625\n",
      "\n",
      "Val func train loss in epoch 11:5.535846382379532\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 5.334752082824707\n",
      "\n",
      "episode 2, val func loss 5.803461074829102\n",
      "\n",
      "episode 3, val func loss 5.569249629974365\n",
      "\n",
      "episode 4, val func loss 5.384969234466553\n",
      "\n",
      "episode 5, val func loss 5.768269062042236\n",
      "\n",
      "episode 6, val func loss 5.681153774261475\n",
      "\n",
      "episode 7, val func loss 5.291889190673828\n",
      "\n",
      "episode 8, val func loss 5.218884468078613\n",
      "\n",
      "episode 9, val func loss 5.863302707672119\n",
      "\n",
      "episode 10, val func loss 5.167686939239502\n",
      "\n",
      "episode 11, val func loss 5.670365333557129\n",
      "\n",
      "episode 12, val func loss 5.581391334533691\n",
      "\n",
      "episode 13, val func loss 5.245196342468262\n",
      "\n",
      "episode 14, val func loss 4.982001304626465\n",
      "\n",
      "episode 15, val func loss 4.804040908813477\n",
      "\n",
      "episode 16, val func loss 5.415553569793701\n",
      "\n",
      "Val func train loss in epoch 12:5.4238854348659515\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 6.017806529998779\n",
      "\n",
      "episode 2, val func loss 5.324994087219238\n",
      "\n",
      "episode 3, val func loss 5.762716770172119\n",
      "\n",
      "episode 4, val func loss 5.554314136505127\n",
      "\n",
      "episode 5, val func loss 5.49178409576416\n",
      "\n",
      "episode 6, val func loss 5.88370943069458\n",
      "\n",
      "episode 7, val func loss 5.427334308624268\n",
      "\n",
      "episode 8, val func loss 4.993775367736816\n",
      "\n",
      "episode 9, val func loss 5.438048362731934\n",
      "\n",
      "episode 10, val func loss 5.343873977661133\n",
      "\n",
      "episode 11, val func loss 5.6588335037231445\n",
      "\n",
      "episode 12, val func loss 4.940929889678955\n",
      "\n",
      "episode 13, val func loss 5.423661708831787\n",
      "\n",
      "episode 14, val func loss 5.9703168869018555\n",
      "\n",
      "episode 15, val func loss 5.396227836608887\n",
      "\n",
      "episode 16, val func loss 5.700021743774414\n",
      "\n",
      "Val func train loss in epoch 13:5.5205217897892\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 5.059117317199707\n",
      "\n",
      "episode 2, val func loss 5.481233596801758\n",
      "\n",
      "episode 3, val func loss 5.7363362312316895\n",
      "\n",
      "episode 4, val func loss 5.138728141784668\n",
      "\n",
      "episode 5, val func loss 5.321237564086914\n",
      "\n",
      "episode 6, val func loss 5.794743061065674\n",
      "\n",
      "episode 7, val func loss 5.336325168609619\n",
      "\n",
      "episode 8, val func loss 5.480615615844727\n",
      "\n",
      "episode 9, val func loss 5.445174217224121\n",
      "\n",
      "episode 10, val func loss 5.308479309082031\n",
      "\n",
      "episode 11, val func loss 5.097558498382568\n",
      "\n",
      "episode 12, val func loss 5.850099086761475\n",
      "\n",
      "episode 13, val func loss 5.3943257331848145\n",
      "\n",
      "episode 14, val func loss 5.3305344581604\n",
      "\n",
      "episode 15, val func loss 5.6542067527771\n",
      "\n",
      "episode 16, val func loss 5.797879695892334\n",
      "\n",
      "Val func train loss in epoch 14:5.4516621530056\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 5.23911714553833\n",
      "\n",
      "episode 2, val func loss 5.3273606300354\n",
      "\n",
      "episode 3, val func loss 5.331625461578369\n",
      "\n",
      "episode 4, val func loss 4.8530659675598145\n",
      "\n",
      "episode 5, val func loss 5.205477714538574\n",
      "\n",
      "episode 6, val func loss 5.925865173339844\n",
      "\n",
      "episode 7, val func loss 5.308807373046875\n",
      "\n",
      "episode 8, val func loss 5.849761962890625\n",
      "\n",
      "episode 9, val func loss 5.648942470550537\n",
      "\n",
      "episode 10, val func loss 5.346625328063965\n",
      "\n",
      "episode 11, val func loss 5.4315185546875\n",
      "\n",
      "episode 12, val func loss 5.706265926361084\n",
      "\n",
      "episode 13, val func loss 5.754900932312012\n",
      "\n",
      "episode 14, val func loss 5.417064666748047\n",
      "\n",
      "episode 15, val func loss 5.0029497146606445\n",
      "\n",
      "episode 16, val func loss 5.4634175300598145\n",
      "\n",
      "Val func train loss in epoch 15:5.425797909498215\n",
      "***********************TIME WAS 4.92894215186437 min*****************************\n",
      "\n",
      "**********************ROUND 135 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.033611081540584564\n",
      "\n",
      "episode 2, policy loss -0.016741739585995674\n",
      "\n",
      "episode 3, policy loss -0.1370384842157364\n",
      "\n",
      "episode 4, policy loss -0.0411088690161705\n",
      "\n",
      "episode 5, policy loss 0.06574258953332901\n",
      "\n",
      "episode 6, policy loss 0.08421023190021515\n",
      "\n",
      "episode 7, policy loss -0.037505604326725006\n",
      "\n",
      "episode 8, policy loss 0.219013512134552\n",
      "\n",
      "episode 9, policy loss 0.028676703572273254\n",
      "\n",
      "episode 10, policy loss 0.2805691361427307\n",
      "\n",
      "episode 11, policy loss 0.16309195756912231\n",
      "\n",
      "episode 12, policy loss 0.30995407700538635\n",
      "\n",
      "episode 13, policy loss -0.028245270252227783\n",
      "\n",
      "episode 14, policy loss 0.04964856803417206\n",
      "\n",
      "episode 15, policy loss 0.4838544726371765\n",
      "\n",
      "episode 16, policy loss -0.20318900048732758\n",
      "\n",
      "Policy train loss in epoch 0:0.07840896013658494\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.20318852365016937\n",
      "\n",
      "episode 2, policy loss 0.16599410772323608\n",
      "\n",
      "episode 3, policy loss 0.31185421347618103\n",
      "\n",
      "episode 4, policy loss 0.28424835205078125\n",
      "\n",
      "episode 5, policy loss -0.015362593345344067\n",
      "\n",
      "episode 6, policy loss 0.2259829193353653\n",
      "\n",
      "episode 7, policy loss 0.029567891731858253\n",
      "\n",
      "episode 8, policy loss -0.0190903190523386\n",
      "\n",
      "episode 9, policy loss -0.02233307436108589\n",
      "\n",
      "episode 10, policy loss -0.03668385371565819\n",
      "\n",
      "episode 11, policy loss 0.4849662482738495\n",
      "\n",
      "episode 12, policy loss 0.09081918001174927\n",
      "\n",
      "episode 13, policy loss 0.07002730667591095\n",
      "\n",
      "episode 14, policy loss -0.14043226838111877\n",
      "\n",
      "episode 15, policy loss 0.04973733425140381\n",
      "\n",
      "episode 16, policy loss -0.028211263939738274\n",
      "\n",
      "Policy train loss in epoch 1:0.07799347856780514\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.02327674813568592\n",
      "\n",
      "episode 2, policy loss 0.3103114068508148\n",
      "\n",
      "episode 3, policy loss -0.020146803930401802\n",
      "\n",
      "episode 4, policy loss 0.049165062606334686\n",
      "\n",
      "episode 5, policy loss 0.06966033577919006\n",
      "\n",
      "episode 6, policy loss -0.01668580248951912\n",
      "\n",
      "episode 7, policy loss 0.1628471314907074\n",
      "\n",
      "episode 8, policy loss -0.20319519937038422\n",
      "\n",
      "episode 9, policy loss 0.27903300523757935\n",
      "\n",
      "episode 10, policy loss 0.08691911399364471\n",
      "\n",
      "episode 11, policy loss 0.47588419914245605\n",
      "\n",
      "episode 12, policy loss -0.0377102866768837\n",
      "\n",
      "episode 13, policy loss 0.027057956904172897\n",
      "\n",
      "episode 14, policy loss -0.14205893874168396\n",
      "\n",
      "episode 15, policy loss -0.02840675599873066\n",
      "\n",
      "episode 16, policy loss 0.20651918649673462\n",
      "\n",
      "Policy train loss in epoch 2:0.07474480394739658\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -0.038848843425512314\n",
      "\n",
      "episode 2, policy loss 0.05200246348977089\n",
      "\n",
      "episode 3, policy loss 0.255776584148407\n",
      "\n",
      "episode 4, policy loss 0.07619275897741318\n",
      "\n",
      "episode 5, policy loss 0.02410752698779106\n",
      "\n",
      "episode 6, policy loss -0.040709614753723145\n",
      "\n",
      "episode 7, policy loss -0.03232955187559128\n",
      "\n",
      "episode 8, policy loss -0.02844066731631756\n",
      "\n",
      "episode 9, policy loss 0.20659489929676056\n",
      "\n",
      "episode 10, policy loss -0.02405662275850773\n",
      "\n",
      "episode 11, policy loss -0.14271847903728485\n",
      "\n",
      "episode 12, policy loss 0.06477193534374237\n",
      "\n",
      "episode 13, policy loss 0.1464911252260208\n",
      "\n",
      "episode 14, policy loss 0.28372934460639954\n",
      "\n",
      "episode 15, policy loss 0.45621371269226074\n",
      "\n",
      "episode 16, policy loss -0.19923943281173706\n",
      "\n",
      "Policy train loss in epoch 3:0.06622107117436826\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.5281476974487305\n",
      "\n",
      "episode 2, val func loss 2.4384496212005615\n",
      "\n",
      "episode 3, val func loss 1.8737797737121582\n",
      "\n",
      "episode 4, val func loss 3.2554876804351807\n",
      "\n",
      "episode 5, val func loss 2.311419725418091\n",
      "\n",
      "episode 6, val func loss 2.442272424697876\n",
      "\n",
      "episode 7, val func loss 2.358947515487671\n",
      "\n",
      "episode 8, val func loss 3.0374503135681152\n",
      "\n",
      "episode 9, val func loss 1.6714872121810913\n",
      "\n",
      "episode 10, val func loss 2.4277889728546143\n",
      "\n",
      "episode 11, val func loss 2.3393208980560303\n",
      "\n",
      "episode 12, val func loss 2.6334688663482666\n",
      "\n",
      "episode 13, val func loss 2.282684803009033\n",
      "\n",
      "episode 14, val func loss 2.3422293663024902\n",
      "\n",
      "episode 15, val func loss 1.9107505083084106\n",
      "\n",
      "episode 16, val func loss 1.7951024770736694\n",
      "\n",
      "Val func train loss in epoch 0:2.2905492410063744\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.460547685623169\n",
      "\n",
      "episode 2, val func loss 1.7019630670547485\n",
      "\n",
      "episode 3, val func loss 2.9116709232330322\n",
      "\n",
      "episode 4, val func loss 1.9348911046981812\n",
      "\n",
      "episode 5, val func loss 2.2511205673217773\n",
      "\n",
      "episode 6, val func loss 3.0606300830841064\n",
      "\n",
      "episode 7, val func loss 1.9622374773025513\n",
      "\n",
      "episode 8, val func loss 1.6650910377502441\n",
      "\n",
      "episode 9, val func loss 2.2354636192321777\n",
      "\n",
      "episode 10, val func loss 2.4038662910461426\n",
      "\n",
      "episode 11, val func loss 2.5371463298797607\n",
      "\n",
      "episode 12, val func loss 2.7466678619384766\n",
      "\n",
      "episode 13, val func loss 2.3358185291290283\n",
      "\n",
      "episode 14, val func loss 1.4651641845703125\n",
      "\n",
      "episode 15, val func loss 2.2649152278900146\n",
      "\n",
      "episode 16, val func loss 2.4157612323760986\n",
      "\n",
      "Val func train loss in epoch 1:2.272059701383114\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.493582010269165\n",
      "\n",
      "episode 2, val func loss 2.374610424041748\n",
      "\n",
      "episode 3, val func loss 2.849968433380127\n",
      "\n",
      "episode 4, val func loss 2.5305838584899902\n",
      "\n",
      "episode 5, val func loss 1.6571743488311768\n",
      "\n",
      "episode 6, val func loss 1.6865241527557373\n",
      "\n",
      "episode 7, val func loss 2.5822505950927734\n",
      "\n",
      "episode 8, val func loss 1.529672384262085\n",
      "\n",
      "episode 9, val func loss 2.448585271835327\n",
      "\n",
      "episode 10, val func loss 3.4436254501342773\n",
      "\n",
      "episode 11, val func loss 2.233567476272583\n",
      "\n",
      "episode 12, val func loss 2.381190061569214\n",
      "\n",
      "episode 13, val func loss 2.4747071266174316\n",
      "\n",
      "episode 14, val func loss 2.1457366943359375\n",
      "\n",
      "episode 15, val func loss 2.3103585243225098\n",
      "\n",
      "episode 16, val func loss 1.723745584487915\n",
      "\n",
      "Val func train loss in epoch 2:2.304117649793625\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.4551260471343994\n",
      "\n",
      "episode 2, val func loss 2.4163365364074707\n",
      "\n",
      "episode 3, val func loss 3.589262008666992\n",
      "\n",
      "episode 4, val func loss 2.563229560852051\n",
      "\n",
      "episode 5, val func loss 2.2117116451263428\n",
      "\n",
      "episode 6, val func loss 1.9305219650268555\n",
      "\n",
      "episode 7, val func loss 1.974433422088623\n",
      "\n",
      "episode 8, val func loss 1.7752821445465088\n",
      "\n",
      "episode 9, val func loss 2.680826425552368\n",
      "\n",
      "episode 10, val func loss 2.555753231048584\n",
      "\n",
      "episode 11, val func loss 2.2364165782928467\n",
      "\n",
      "episode 12, val func loss 2.82254958152771\n",
      "\n",
      "episode 13, val func loss 2.3918278217315674\n",
      "\n",
      "episode 14, val func loss 1.6469924449920654\n",
      "\n",
      "episode 15, val func loss 2.217999219894409\n",
      "\n",
      "episode 16, val func loss 1.5663187503814697\n",
      "\n",
      "Val func train loss in epoch 3:2.3146617114543915\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.5635747909545898\n",
      "\n",
      "episode 2, val func loss 1.9709025621414185\n",
      "\n",
      "episode 3, val func loss 2.1680333614349365\n",
      "\n",
      "episode 4, val func loss 2.180379629135132\n",
      "\n",
      "episode 5, val func loss 1.5590146780014038\n",
      "\n",
      "episode 6, val func loss 2.402066230773926\n",
      "\n",
      "episode 7, val func loss 2.1811904907226562\n",
      "\n",
      "episode 8, val func loss 2.719081163406372\n",
      "\n",
      "episode 9, val func loss 2.379119634628296\n",
      "\n",
      "episode 10, val func loss 2.3938748836517334\n",
      "\n",
      "episode 11, val func loss 2.8840525150299072\n",
      "\n",
      "episode 12, val func loss 2.11014461517334\n",
      "\n",
      "episode 13, val func loss 2.8154616355895996\n",
      "\n",
      "episode 14, val func loss 2.340240955352783\n",
      "\n",
      "episode 15, val func loss 2.892354965209961\n",
      "\n",
      "episode 16, val func loss 1.803305983543396\n",
      "\n",
      "Val func train loss in epoch 4:2.2726748809218407\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 2.5111913681030273\n",
      "\n",
      "episode 2, val func loss 1.5520633459091187\n",
      "\n",
      "episode 3, val func loss 3.304737091064453\n",
      "\n",
      "episode 4, val func loss 2.0212740898132324\n",
      "\n",
      "episode 5, val func loss 2.4241271018981934\n",
      "\n",
      "episode 6, val func loss 1.603477954864502\n",
      "\n",
      "episode 7, val func loss 2.2563223838806152\n",
      "\n",
      "episode 8, val func loss 2.800661563873291\n",
      "\n",
      "episode 9, val func loss 1.7260987758636475\n",
      "\n",
      "episode 10, val func loss 2.293602705001831\n",
      "\n",
      "episode 11, val func loss 2.860116720199585\n",
      "\n",
      "episode 12, val func loss 2.3477349281311035\n",
      "\n",
      "episode 13, val func loss 1.707907795906067\n",
      "\n",
      "episode 14, val func loss 2.222665309906006\n",
      "\n",
      "episode 15, val func loss 2.2279748916625977\n",
      "\n",
      "episode 16, val func loss 2.723313331604004\n",
      "\n",
      "Val func train loss in epoch 5:2.2864543348550797\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 1.3772447109222412\n",
      "\n",
      "episode 2, val func loss 2.041497230529785\n",
      "\n",
      "episode 3, val func loss 2.2914953231811523\n",
      "\n",
      "episode 4, val func loss 2.418517827987671\n",
      "\n",
      "episode 5, val func loss 2.667843818664551\n",
      "\n",
      "episode 6, val func loss 1.9867887496948242\n",
      "\n",
      "episode 7, val func loss 1.6611928939819336\n",
      "\n",
      "episode 8, val func loss 2.5861270427703857\n",
      "\n",
      "episode 9, val func loss 2.5805554389953613\n",
      "\n",
      "episode 10, val func loss 2.3224430084228516\n",
      "\n",
      "episode 11, val func loss 2.783099412918091\n",
      "\n",
      "episode 12, val func loss 2.8108415603637695\n",
      "\n",
      "episode 13, val func loss 2.27397084236145\n",
      "\n",
      "episode 14, val func loss 1.7708015441894531\n",
      "\n",
      "episode 15, val func loss 2.263355016708374\n",
      "\n",
      "episode 16, val func loss 3.1376357078552246\n",
      "\n",
      "Val func train loss in epoch 6:2.310838133096695\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 2.4169833660125732\n",
      "\n",
      "episode 2, val func loss 2.3048555850982666\n",
      "\n",
      "episode 3, val func loss 2.6104321479797363\n",
      "\n",
      "episode 4, val func loss 2.3922064304351807\n",
      "\n",
      "episode 5, val func loss 2.3445656299591064\n",
      "\n",
      "episode 6, val func loss 2.6188559532165527\n",
      "\n",
      "episode 7, val func loss 2.906008005142212\n",
      "\n",
      "episode 8, val func loss 2.817410707473755\n",
      "\n",
      "episode 9, val func loss 1.8089934587478638\n",
      "\n",
      "episode 10, val func loss 2.2849996089935303\n",
      "\n",
      "episode 11, val func loss 3.059109687805176\n",
      "\n",
      "episode 12, val func loss 1.5658586025238037\n",
      "\n",
      "episode 13, val func loss 3.280128240585327\n",
      "\n",
      "episode 14, val func loss 1.7285103797912598\n",
      "\n",
      "episode 15, val func loss 1.9584424495697021\n",
      "\n",
      "episode 16, val func loss 1.851789116859436\n",
      "\n",
      "Val func train loss in epoch 7:2.3718218356370926\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.6863640546798706\n",
      "\n",
      "episode 2, val func loss 1.4061647653579712\n",
      "\n",
      "episode 3, val func loss 1.9402234554290771\n",
      "\n",
      "episode 4, val func loss 2.7560949325561523\n",
      "\n",
      "episode 5, val func loss 2.331329822540283\n",
      "\n",
      "episode 6, val func loss 2.32875919342041\n",
      "\n",
      "episode 7, val func loss 1.8561803102493286\n",
      "\n",
      "episode 8, val func loss 2.289719581604004\n",
      "\n",
      "episode 9, val func loss 1.8054684400558472\n",
      "\n",
      "episode 10, val func loss 2.5764801502227783\n",
      "\n",
      "episode 11, val func loss 2.8580081462860107\n",
      "\n",
      "episode 12, val func loss 2.1731958389282227\n",
      "\n",
      "episode 13, val func loss 3.165555238723755\n",
      "\n",
      "episode 14, val func loss 2.286726236343384\n",
      "\n",
      "episode 15, val func loss 2.5918288230895996\n",
      "\n",
      "episode 16, val func loss 2.4165985584259033\n",
      "\n",
      "Val func train loss in epoch 8:2.2792935967445374\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.2945594787597656\n",
      "\n",
      "episode 2, val func loss 2.6072235107421875\n",
      "\n",
      "episode 3, val func loss 2.4876887798309326\n",
      "\n",
      "episode 4, val func loss 1.9682748317718506\n",
      "\n",
      "episode 5, val func loss 2.469451665878296\n",
      "\n",
      "episode 6, val func loss 1.8885269165039062\n",
      "\n",
      "episode 7, val func loss 2.8825247287750244\n",
      "\n",
      "episode 8, val func loss 2.409468412399292\n",
      "\n",
      "episode 9, val func loss 1.6613471508026123\n",
      "\n",
      "episode 10, val func loss 2.73580002784729\n",
      "\n",
      "episode 11, val func loss 2.2434616088867188\n",
      "\n",
      "episode 12, val func loss 1.833668828010559\n",
      "\n",
      "episode 13, val func loss 2.571826934814453\n",
      "\n",
      "episode 14, val func loss 2.2713725566864014\n",
      "\n",
      "episode 15, val func loss 2.394169807434082\n",
      "\n",
      "episode 16, val func loss 3.312551736831665\n",
      "\n",
      "Val func train loss in epoch 9:2.31449481099844\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.5872812271118164\n",
      "\n",
      "episode 2, val func loss 2.5902040004730225\n",
      "\n",
      "episode 3, val func loss 2.5364108085632324\n",
      "\n",
      "episode 4, val func loss 1.8705172538757324\n",
      "\n",
      "episode 5, val func loss 1.4628087282180786\n",
      "\n",
      "episode 6, val func loss 1.726024866104126\n",
      "\n",
      "episode 7, val func loss 2.2918612957000732\n",
      "\n",
      "episode 8, val func loss 2.328134059906006\n",
      "\n",
      "episode 9, val func loss 2.3574025630950928\n",
      "\n",
      "episode 10, val func loss 1.851442813873291\n",
      "\n",
      "episode 11, val func loss 1.7458791732788086\n",
      "\n",
      "episode 12, val func loss 2.9106526374816895\n",
      "\n",
      "episode 13, val func loss 2.361065149307251\n",
      "\n",
      "episode 14, val func loss 3.159108877182007\n",
      "\n",
      "episode 15, val func loss 2.5893213748931885\n",
      "\n",
      "episode 16, val func loss 2.1656363010406494\n",
      "\n",
      "Val func train loss in epoch 10:2.283359445631504\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 2.450770616531372\n",
      "\n",
      "episode 2, val func loss 2.2866852283477783\n",
      "\n",
      "episode 3, val func loss 1.7104144096374512\n",
      "\n",
      "episode 4, val func loss 2.724919080734253\n",
      "\n",
      "episode 5, val func loss 1.9342083930969238\n",
      "\n",
      "episode 6, val func loss 1.7891494035720825\n",
      "\n",
      "episode 7, val func loss 3.2321128845214844\n",
      "\n",
      "episode 8, val func loss 2.549546718597412\n",
      "\n",
      "episode 9, val func loss 2.50110125541687\n",
      "\n",
      "episode 10, val func loss 1.4524532556533813\n",
      "\n",
      "episode 11, val func loss 2.34409761428833\n",
      "\n",
      "episode 12, val func loss 2.7013003826141357\n",
      "\n",
      "episode 13, val func loss 1.7345783710479736\n",
      "\n",
      "episode 14, val func loss 2.262326240539551\n",
      "\n",
      "episode 15, val func loss 2.5390350818634033\n",
      "\n",
      "episode 16, val func loss 2.6145312786102295\n",
      "\n",
      "Val func train loss in epoch 11:2.3017018884420395\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 2.4956772327423096\n",
      "\n",
      "episode 2, val func loss 3.275161027908325\n",
      "\n",
      "episode 3, val func loss 2.1094510555267334\n",
      "\n",
      "episode 4, val func loss 1.8009076118469238\n",
      "\n",
      "episode 5, val func loss 2.26143479347229\n",
      "\n",
      "episode 6, val func loss 2.8572189807891846\n",
      "\n",
      "episode 7, val func loss 2.4103505611419678\n",
      "\n",
      "episode 8, val func loss 2.304978370666504\n",
      "\n",
      "episode 9, val func loss 2.297043800354004\n",
      "\n",
      "episode 10, val func loss 2.53678297996521\n",
      "\n",
      "episode 11, val func loss 1.937501311302185\n",
      "\n",
      "episode 12, val func loss 1.4267979860305786\n",
      "\n",
      "episode 13, val func loss 2.47605562210083\n",
      "\n",
      "episode 14, val func loss 1.8471072912216187\n",
      "\n",
      "episode 15, val func loss 1.7950204610824585\n",
      "\n",
      "episode 16, val func loss 2.9340834617614746\n",
      "\n",
      "Val func train loss in epoch 12:2.2978482842445374\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.7932298183441162\n",
      "\n",
      "episode 2, val func loss 1.5612601041793823\n",
      "\n",
      "episode 3, val func loss 2.430551767349243\n",
      "\n",
      "episode 4, val func loss 3.1386473178863525\n",
      "\n",
      "episode 5, val func loss 1.7055875062942505\n",
      "\n",
      "episode 6, val func loss 2.629608154296875\n",
      "\n",
      "episode 7, val func loss 2.8101468086242676\n",
      "\n",
      "episode 8, val func loss 2.433852195739746\n",
      "\n",
      "episode 9, val func loss 2.608482837677002\n",
      "\n",
      "episode 10, val func loss 2.303781032562256\n",
      "\n",
      "episode 11, val func loss 2.373621702194214\n",
      "\n",
      "episode 12, val func loss 2.8663339614868164\n",
      "\n",
      "episode 13, val func loss 2.3651344776153564\n",
      "\n",
      "episode 14, val func loss 1.5433326959609985\n",
      "\n",
      "episode 15, val func loss 1.8563880920410156\n",
      "\n",
      "episode 16, val func loss 2.303208351135254\n",
      "\n",
      "Val func train loss in epoch 13:2.2951979264616966\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.5420459508895874\n",
      "\n",
      "episode 2, val func loss 1.7581294775009155\n",
      "\n",
      "episode 3, val func loss 1.9234485626220703\n",
      "\n",
      "episode 4, val func loss 2.469083547592163\n",
      "\n",
      "episode 5, val func loss 2.548935890197754\n",
      "\n",
      "episode 6, val func loss 1.6625730991363525\n",
      "\n",
      "episode 7, val func loss 2.256551742553711\n",
      "\n",
      "episode 8, val func loss 2.964524269104004\n",
      "\n",
      "episode 9, val func loss 2.3369927406311035\n",
      "\n",
      "episode 10, val func loss 2.309664487838745\n",
      "\n",
      "episode 11, val func loss 2.277634859085083\n",
      "\n",
      "episode 12, val func loss 2.2833123207092285\n",
      "\n",
      "episode 13, val func loss 2.308760643005371\n",
      "\n",
      "episode 14, val func loss 2.045257806777954\n",
      "\n",
      "episode 15, val func loss 2.8808481693267822\n",
      "\n",
      "episode 16, val func loss 3.0121991634368896\n",
      "\n",
      "Val func train loss in epoch 14:2.286247670650482\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.8653309345245361\n",
      "\n",
      "episode 2, val func loss 1.8397245407104492\n",
      "\n",
      "episode 3, val func loss 2.355168104171753\n",
      "\n",
      "episode 4, val func loss 2.7771310806274414\n",
      "\n",
      "episode 5, val func loss 2.8043763637542725\n",
      "\n",
      "episode 6, val func loss 2.980046510696411\n",
      "\n",
      "episode 7, val func loss 1.4559177160263062\n",
      "\n",
      "episode 8, val func loss 2.3468048572540283\n",
      "\n",
      "episode 9, val func loss 1.8674713373184204\n",
      "\n",
      "episode 10, val func loss 2.241765022277832\n",
      "\n",
      "episode 11, val func loss 2.402238130569458\n",
      "\n",
      "episode 12, val func loss 2.4422340393066406\n",
      "\n",
      "episode 13, val func loss 1.6164313554763794\n",
      "\n",
      "episode 14, val func loss 2.2909817695617676\n",
      "\n",
      "episode 15, val func loss 3.160184144973755\n",
      "\n",
      "episode 16, val func loss 2.339529037475586\n",
      "\n",
      "Val func train loss in epoch 15:2.299083434045315\n",
      "***********************TIME WAS 4.932065999507904 min*****************************\n",
      "\n",
      "**********************ROUND 136 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.49375832080841064\n",
      "\n",
      "episode 2, policy loss 0.1370636224746704\n",
      "\n",
      "episode 3, policy loss 0.3848174512386322\n",
      "\n",
      "episode 4, policy loss 0.2800690829753876\n",
      "\n",
      "episode 5, policy loss 0.14263495802879333\n",
      "\n",
      "episode 6, policy loss 0.4420139491558075\n",
      "\n",
      "episode 7, policy loss 0.4571210741996765\n",
      "\n",
      "episode 8, policy loss 0.10152208060026169\n",
      "\n",
      "episode 9, policy loss 0.38247472047805786\n",
      "\n",
      "episode 10, policy loss 0.3507418930530548\n",
      "\n",
      "episode 11, policy loss 0.3940208852291107\n",
      "\n",
      "episode 12, policy loss 0.1600448340177536\n",
      "\n",
      "episode 13, policy loss 0.3779192268848419\n",
      "\n",
      "episode 14, policy loss 0.22029553353786469\n",
      "\n",
      "episode 15, policy loss 0.1352699249982834\n",
      "\n",
      "episode 16, policy loss 0.27535519003868103\n",
      "\n",
      "Policy train loss in epoch 0:0.2959451717324555\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.46270886063575745\n",
      "\n",
      "episode 2, policy loss 0.15456463396549225\n",
      "\n",
      "episode 3, policy loss 0.29194822907447815\n",
      "\n",
      "episode 4, policy loss 0.35204803943634033\n",
      "\n",
      "episode 5, policy loss 0.415628045797348\n",
      "\n",
      "episode 6, policy loss 0.3957585096359253\n",
      "\n",
      "episode 7, policy loss 0.38603460788726807\n",
      "\n",
      "episode 8, policy loss 0.3787233829498291\n",
      "\n",
      "episode 9, policy loss 0.1367264986038208\n",
      "\n",
      "episode 10, policy loss 0.4487404525279999\n",
      "\n",
      "episode 11, policy loss 0.1612316370010376\n",
      "\n",
      "episode 12, policy loss 0.1355525404214859\n",
      "\n",
      "episode 13, policy loss 0.10399957746267319\n",
      "\n",
      "episode 14, policy loss 0.4026104211807251\n",
      "\n",
      "episode 15, policy loss 0.2204664945602417\n",
      "\n",
      "episode 16, policy loss 0.27516403794288635\n",
      "\n",
      "Policy train loss in epoch 1:0.2951191230677068\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.35153236985206604\n",
      "\n",
      "episode 2, policy loss 0.2912924587726593\n",
      "\n",
      "episode 3, policy loss 0.1602698564529419\n",
      "\n",
      "episode 4, policy loss 0.10325802117586136\n",
      "\n",
      "episode 5, policy loss 0.13562515377998352\n",
      "\n",
      "episode 6, policy loss 0.4132869243621826\n",
      "\n",
      "episode 7, policy loss 0.3933379650115967\n",
      "\n",
      "episode 8, policy loss 0.38256046175956726\n",
      "\n",
      "episode 9, policy loss 0.13237152993679047\n",
      "\n",
      "episode 10, policy loss 0.14967389404773712\n",
      "\n",
      "episode 11, policy loss 0.21589243412017822\n",
      "\n",
      "episode 12, policy loss 0.3705368638038635\n",
      "\n",
      "episode 13, policy loss 0.45310312509536743\n",
      "\n",
      "episode 14, policy loss 0.26213639974594116\n",
      "\n",
      "episode 15, policy loss 0.3839774429798126\n",
      "\n",
      "episode 16, policy loss 0.4341678321361542\n",
      "\n",
      "Policy train loss in epoch 2:0.28956392081454396\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.3063284754753113\n",
      "\n",
      "episode 2, policy loss 0.38388481736183167\n",
      "\n",
      "episode 3, policy loss 0.12173952907323837\n",
      "\n",
      "episode 4, policy loss 0.34395769238471985\n",
      "\n",
      "episode 5, policy loss 0.3674350380897522\n",
      "\n",
      "episode 6, policy loss 0.26512065529823303\n",
      "\n",
      "episode 7, policy loss 0.14384225010871887\n",
      "\n",
      "episode 8, policy loss 0.15094377100467682\n",
      "\n",
      "episode 9, policy loss 0.4378558397293091\n",
      "\n",
      "episode 10, policy loss 0.38180074095726013\n",
      "\n",
      "episode 11, policy loss 0.36816176772117615\n",
      "\n",
      "episode 12, policy loss 0.44576936960220337\n",
      "\n",
      "episode 13, policy loss 0.09533493220806122\n",
      "\n",
      "episode 14, policy loss 0.126871719956398\n",
      "\n",
      "episode 15, policy loss 0.22311370074748993\n",
      "\n",
      "episode 16, policy loss 0.39577433466911316\n",
      "\n",
      "Policy train loss in epoch 3:0.2848709146492183\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 3.3034698963165283\n",
      "\n",
      "episode 2, val func loss 3.1287567615509033\n",
      "\n",
      "episode 3, val func loss 2.8679192066192627\n",
      "\n",
      "episode 4, val func loss 3.4577510356903076\n",
      "\n",
      "episode 5, val func loss 3.2544729709625244\n",
      "\n",
      "episode 6, val func loss 2.3361899852752686\n",
      "\n",
      "episode 7, val func loss 2.8583035469055176\n",
      "\n",
      "episode 8, val func loss 2.75378680229187\n",
      "\n",
      "episode 9, val func loss 3.427525520324707\n",
      "\n",
      "episode 10, val func loss 2.4565975666046143\n",
      "\n",
      "episode 11, val func loss 2.368140935897827\n",
      "\n",
      "episode 12, val func loss 2.2504701614379883\n",
      "\n",
      "episode 13, val func loss 2.4589836597442627\n",
      "\n",
      "episode 14, val func loss 3.2027740478515625\n",
      "\n",
      "episode 15, val func loss 3.094744920730591\n",
      "\n",
      "episode 16, val func loss 2.933723211288452\n",
      "\n",
      "Val func train loss in epoch 0:2.8846006393432617\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 2.4394359588623047\n",
      "\n",
      "episode 2, val func loss 3.4301910400390625\n",
      "\n",
      "episode 3, val func loss 2.2826197147369385\n",
      "\n",
      "episode 4, val func loss 3.210552215576172\n",
      "\n",
      "episode 5, val func loss 2.4723756313323975\n",
      "\n",
      "episode 6, val func loss 2.8301303386688232\n",
      "\n",
      "episode 7, val func loss 3.2700881958007812\n",
      "\n",
      "episode 8, val func loss 2.4435336589813232\n",
      "\n",
      "episode 9, val func loss 2.9768664836883545\n",
      "\n",
      "episode 10, val func loss 3.133246421813965\n",
      "\n",
      "episode 11, val func loss 3.145092487335205\n",
      "\n",
      "episode 12, val func loss 2.36820650100708\n",
      "\n",
      "episode 13, val func loss 2.363313913345337\n",
      "\n",
      "episode 14, val func loss 3.179037094116211\n",
      "\n",
      "episode 15, val func loss 3.4486656188964844\n",
      "\n",
      "episode 16, val func loss 3.630585193634033\n",
      "\n",
      "Val func train loss in epoch 1:2.9139962792396545\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 3.1482722759246826\n",
      "\n",
      "episode 2, val func loss 2.7294795513153076\n",
      "\n",
      "episode 3, val func loss 2.361097574234009\n",
      "\n",
      "episode 4, val func loss 2.9721972942352295\n",
      "\n",
      "episode 5, val func loss 3.3170342445373535\n",
      "\n",
      "episode 6, val func loss 3.294184923171997\n",
      "\n",
      "episode 7, val func loss 2.559809446334839\n",
      "\n",
      "episode 8, val func loss 2.626169443130493\n",
      "\n",
      "episode 9, val func loss 2.62333345413208\n",
      "\n",
      "episode 10, val func loss 3.088304042816162\n",
      "\n",
      "episode 11, val func loss 3.0429322719573975\n",
      "\n",
      "episode 12, val func loss 2.2332584857940674\n",
      "\n",
      "episode 13, val func loss 3.1553378105163574\n",
      "\n",
      "episode 14, val func loss 2.375664710998535\n",
      "\n",
      "episode 15, val func loss 3.16917085647583\n",
      "\n",
      "episode 16, val func loss 2.7922589778900146\n",
      "\n",
      "Val func train loss in epoch 2:2.843031585216522\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.140873432159424\n",
      "\n",
      "episode 2, val func loss 2.532681941986084\n",
      "\n",
      "episode 3, val func loss 3.133471965789795\n",
      "\n",
      "episode 4, val func loss 2.593142032623291\n",
      "\n",
      "episode 5, val func loss 2.7856857776641846\n",
      "\n",
      "episode 6, val func loss 2.8978776931762695\n",
      "\n",
      "episode 7, val func loss 3.2461893558502197\n",
      "\n",
      "episode 8, val func loss 3.208974599838257\n",
      "\n",
      "episode 9, val func loss 2.9231483936309814\n",
      "\n",
      "episode 10, val func loss 3.197713851928711\n",
      "\n",
      "episode 11, val func loss 2.7214322090148926\n",
      "\n",
      "episode 12, val func loss 2.4668824672698975\n",
      "\n",
      "episode 13, val func loss 2.231837749481201\n",
      "\n",
      "episode 14, val func loss 2.9673831462860107\n",
      "\n",
      "episode 15, val func loss 3.179933786392212\n",
      "\n",
      "episode 16, val func loss 2.3530054092407227\n",
      "\n",
      "Val func train loss in epoch 3:2.7862646132707596\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.2198894023895264\n",
      "\n",
      "episode 2, val func loss 3.1652865409851074\n",
      "\n",
      "episode 3, val func loss 2.510784387588501\n",
      "\n",
      "episode 4, val func loss 2.792844295501709\n",
      "\n",
      "episode 5, val func loss 3.175089120864868\n",
      "\n",
      "episode 6, val func loss 3.0959079265594482\n",
      "\n",
      "episode 7, val func loss 2.458892822265625\n",
      "\n",
      "episode 8, val func loss 2.120915651321411\n",
      "\n",
      "episode 9, val func loss 2.8032748699188232\n",
      "\n",
      "episode 10, val func loss 2.7653238773345947\n",
      "\n",
      "episode 11, val func loss 2.6209163665771484\n",
      "\n",
      "episode 12, val func loss 2.9843146800994873\n",
      "\n",
      "episode 13, val func loss 2.981044054031372\n",
      "\n",
      "episode 14, val func loss 2.2834367752075195\n",
      "\n",
      "episode 15, val func loss 2.8483030796051025\n",
      "\n",
      "episode 16, val func loss 2.778430223464966\n",
      "\n",
      "Val func train loss in epoch 4:2.7252908796072006\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 2.9929850101470947\n",
      "\n",
      "episode 2, val func loss 2.6545677185058594\n",
      "\n",
      "episode 3, val func loss 3.3358864784240723\n",
      "\n",
      "episode 4, val func loss 2.5426552295684814\n",
      "\n",
      "episode 5, val func loss 2.820964813232422\n",
      "\n",
      "episode 6, val func loss 2.4896459579467773\n",
      "\n",
      "episode 7, val func loss 2.170290470123291\n",
      "\n",
      "episode 8, val func loss 2.721651792526245\n",
      "\n",
      "episode 9, val func loss 2.8634517192840576\n",
      "\n",
      "episode 10, val func loss 2.5674071311950684\n",
      "\n",
      "episode 11, val func loss 3.0992093086242676\n",
      "\n",
      "episode 12, val func loss 2.97403621673584\n",
      "\n",
      "episode 13, val func loss 2.96885347366333\n",
      "\n",
      "episode 14, val func loss 2.4372379779815674\n",
      "\n",
      "episode 15, val func loss 2.2714157104492188\n",
      "\n",
      "episode 16, val func loss 2.5041749477386475\n",
      "\n",
      "Val func train loss in epoch 5:2.71340212225914\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.9278883934020996\n",
      "\n",
      "episode 2, val func loss 3.0135090351104736\n",
      "\n",
      "episode 3, val func loss 2.4658267498016357\n",
      "\n",
      "episode 4, val func loss 3.166687488555908\n",
      "\n",
      "episode 5, val func loss 2.6043379306793213\n",
      "\n",
      "episode 6, val func loss 2.8621978759765625\n",
      "\n",
      "episode 7, val func loss 2.9104793071746826\n",
      "\n",
      "episode 8, val func loss 2.9119303226470947\n",
      "\n",
      "episode 9, val func loss 3.0349228382110596\n",
      "\n",
      "episode 10, val func loss 2.396437406539917\n",
      "\n",
      "episode 11, val func loss 3.1232950687408447\n",
      "\n",
      "episode 12, val func loss 2.3334524631500244\n",
      "\n",
      "episode 13, val func loss 2.3772482872009277\n",
      "\n",
      "episode 14, val func loss 3.0076189041137695\n",
      "\n",
      "episode 15, val func loss 2.478285074234009\n",
      "\n",
      "episode 16, val func loss 3.033937692642212\n",
      "\n",
      "Val func train loss in epoch 6:2.790503427386284\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 3.200791120529175\n",
      "\n",
      "episode 2, val func loss 3.097360134124756\n",
      "\n",
      "episode 3, val func loss 3.177319049835205\n",
      "\n",
      "episode 4, val func loss 2.764803171157837\n",
      "\n",
      "episode 5, val func loss 3.329850673675537\n",
      "\n",
      "episode 6, val func loss 2.45055890083313\n",
      "\n",
      "episode 7, val func loss 3.008082628250122\n",
      "\n",
      "episode 8, val func loss 2.8765053749084473\n",
      "\n",
      "episode 9, val func loss 2.4024579524993896\n",
      "\n",
      "episode 10, val func loss 2.7911877632141113\n",
      "\n",
      "episode 11, val func loss 2.2093498706817627\n",
      "\n",
      "episode 12, val func loss 2.9917304515838623\n",
      "\n",
      "episode 13, val func loss 2.290260076522827\n",
      "\n",
      "episode 14, val func loss 2.4971747398376465\n",
      "\n",
      "episode 15, val func loss 2.3946828842163086\n",
      "\n",
      "episode 16, val func loss 2.817902088165283\n",
      "\n",
      "Val func train loss in epoch 7:2.7687510550022125\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.988215208053589\n",
      "\n",
      "episode 2, val func loss 2.3421173095703125\n",
      "\n",
      "episode 3, val func loss 2.373917579650879\n",
      "\n",
      "episode 4, val func loss 2.778675079345703\n",
      "\n",
      "episode 5, val func loss 3.0166361331939697\n",
      "\n",
      "episode 6, val func loss 2.2583539485931396\n",
      "\n",
      "episode 7, val func loss 3.33015513420105\n",
      "\n",
      "episode 8, val func loss 2.988344669342041\n",
      "\n",
      "episode 9, val func loss 3.1929945945739746\n",
      "\n",
      "episode 10, val func loss 2.788618803024292\n",
      "\n",
      "episode 11, val func loss 2.6596078872680664\n",
      "\n",
      "episode 12, val func loss 3.1252005100250244\n",
      "\n",
      "episode 13, val func loss 2.692107677459717\n",
      "\n",
      "episode 14, val func loss 2.394515037536621\n",
      "\n",
      "episode 15, val func loss 3.2644004821777344\n",
      "\n",
      "episode 16, val func loss 2.4288313388824463\n",
      "\n",
      "Val func train loss in epoch 8:2.78891821205616\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 2.401520252227783\n",
      "\n",
      "episode 2, val func loss 2.7396788597106934\n",
      "\n",
      "episode 3, val func loss 2.254328489303589\n",
      "\n",
      "episode 4, val func loss 3.121375799179077\n",
      "\n",
      "episode 5, val func loss 2.8390235900878906\n",
      "\n",
      "episode 6, val func loss 3.166329860687256\n",
      "\n",
      "episode 7, val func loss 2.6157426834106445\n",
      "\n",
      "episode 8, val func loss 2.8811943531036377\n",
      "\n",
      "episode 9, val func loss 3.0430307388305664\n",
      "\n",
      "episode 10, val func loss 2.266343832015991\n",
      "\n",
      "episode 11, val func loss 3.0135810375213623\n",
      "\n",
      "episode 12, val func loss 2.5735397338867188\n",
      "\n",
      "episode 13, val func loss 3.0976197719573975\n",
      "\n",
      "episode 14, val func loss 2.9111809730529785\n",
      "\n",
      "episode 15, val func loss 2.1329410076141357\n",
      "\n",
      "episode 16, val func loss 2.6694459915161133\n",
      "\n",
      "Val func train loss in epoch 9:2.7329298108816147\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.964885711669922\n",
      "\n",
      "episode 2, val func loss 3.2350573539733887\n",
      "\n",
      "episode 3, val func loss 2.9318177700042725\n",
      "\n",
      "episode 4, val func loss 2.519493818283081\n",
      "\n",
      "episode 5, val func loss 2.79839825630188\n",
      "\n",
      "episode 6, val func loss 2.5451674461364746\n",
      "\n",
      "episode 7, val func loss 2.75305438041687\n",
      "\n",
      "episode 8, val func loss 2.5192573070526123\n",
      "\n",
      "episode 9, val func loss 2.7998085021972656\n",
      "\n",
      "episode 10, val func loss 2.8986194133758545\n",
      "\n",
      "episode 11, val func loss 3.109837532043457\n",
      "\n",
      "episode 12, val func loss 2.274807929992676\n",
      "\n",
      "episode 13, val func loss 3.123117685317993\n",
      "\n",
      "episode 14, val func loss 2.252828598022461\n",
      "\n",
      "episode 15, val func loss 3.05311918258667\n",
      "\n",
      "episode 16, val func loss 3.168456792831421\n",
      "\n",
      "Val func train loss in epoch 10:2.8092329800128937\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 3.072042226791382\n",
      "\n",
      "episode 2, val func loss 2.813849449157715\n",
      "\n",
      "episode 3, val func loss 2.4063448905944824\n",
      "\n",
      "episode 4, val func loss 2.6622612476348877\n",
      "\n",
      "episode 5, val func loss 2.8416390419006348\n",
      "\n",
      "episode 6, val func loss 2.136957883834839\n",
      "\n",
      "episode 7, val func loss 3.1447064876556396\n",
      "\n",
      "episode 8, val func loss 2.8971879482269287\n",
      "\n",
      "episode 9, val func loss 2.792613983154297\n",
      "\n",
      "episode 10, val func loss 2.185089588165283\n",
      "\n",
      "episode 11, val func loss 3.1510372161865234\n",
      "\n",
      "episode 12, val func loss 2.656677484512329\n",
      "\n",
      "episode 13, val func loss 2.7665553092956543\n",
      "\n",
      "episode 14, val func loss 2.498196840286255\n",
      "\n",
      "episode 15, val func loss 2.1482999324798584\n",
      "\n",
      "episode 16, val func loss 3.379796028137207\n",
      "\n",
      "Val func train loss in epoch 11:2.7220784723758698\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 2.9521591663360596\n",
      "\n",
      "episode 2, val func loss 3.089486837387085\n",
      "\n",
      "episode 3, val func loss 3.0379080772399902\n",
      "\n",
      "episode 4, val func loss 2.4024834632873535\n",
      "\n",
      "episode 5, val func loss 2.7941336631774902\n",
      "\n",
      "episode 6, val func loss 3.20584774017334\n",
      "\n",
      "episode 7, val func loss 2.384927988052368\n",
      "\n",
      "episode 8, val func loss 2.406010150909424\n",
      "\n",
      "episode 9, val func loss 2.575230121612549\n",
      "\n",
      "episode 10, val func loss 2.4667906761169434\n",
      "\n",
      "episode 11, val func loss 3.041877508163452\n",
      "\n",
      "episode 12, val func loss 3.1415786743164062\n",
      "\n",
      "episode 13, val func loss 2.739075183868408\n",
      "\n",
      "episode 14, val func loss 3.1099345684051514\n",
      "\n",
      "episode 15, val func loss 2.191589832305908\n",
      "\n",
      "episode 16, val func loss 3.1952919960021973\n",
      "\n",
      "Val func train loss in epoch 12:2.795895352959633\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 2.2920117378234863\n",
      "\n",
      "episode 2, val func loss 2.5631794929504395\n",
      "\n",
      "episode 3, val func loss 2.886314868927002\n",
      "\n",
      "episode 4, val func loss 2.932050943374634\n",
      "\n",
      "episode 5, val func loss 3.2040066719055176\n",
      "\n",
      "episode 6, val func loss 3.3009192943573\n",
      "\n",
      "episode 7, val func loss 3.3645410537719727\n",
      "\n",
      "episode 8, val func loss 2.6118016242980957\n",
      "\n",
      "episode 9, val func loss 2.4045915603637695\n",
      "\n",
      "episode 10, val func loss 2.832430124282837\n",
      "\n",
      "episode 11, val func loss 2.1458847522735596\n",
      "\n",
      "episode 12, val func loss 2.8777854442596436\n",
      "\n",
      "episode 13, val func loss 2.998569965362549\n",
      "\n",
      "episode 14, val func loss 3.0906381607055664\n",
      "\n",
      "episode 15, val func loss 2.417177677154541\n",
      "\n",
      "episode 16, val func loss 3.1727261543273926\n",
      "\n",
      "Val func train loss in epoch 13:2.818414345383644\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.3529105186462402\n",
      "\n",
      "episode 2, val func loss 3.0249826908111572\n",
      "\n",
      "episode 3, val func loss 2.154984474182129\n",
      "\n",
      "episode 4, val func loss 3.1885814666748047\n",
      "\n",
      "episode 5, val func loss 2.816664457321167\n",
      "\n",
      "episode 6, val func loss 2.5529062747955322\n",
      "\n",
      "episode 7, val func loss 3.325671672821045\n",
      "\n",
      "episode 8, val func loss 2.7729475498199463\n",
      "\n",
      "episode 9, val func loss 2.781233549118042\n",
      "\n",
      "episode 10, val func loss 2.96514892578125\n",
      "\n",
      "episode 11, val func loss 3.205397844314575\n",
      "\n",
      "episode 12, val func loss 3.1588478088378906\n",
      "\n",
      "episode 13, val func loss 2.921384811401367\n",
      "\n",
      "episode 14, val func loss 2.5265274047851562\n",
      "\n",
      "episode 15, val func loss 3.9387261867523193\n",
      "\n",
      "episode 16, val func loss 3.169004440307617\n",
      "\n",
      "Val func train loss in epoch 14:2.92849500477314\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.2981677055358887\n",
      "\n",
      "episode 2, val func loss 2.5623114109039307\n",
      "\n",
      "episode 3, val func loss 3.131378650665283\n",
      "\n",
      "episode 4, val func loss 3.0249521732330322\n",
      "\n",
      "episode 5, val func loss 3.628072738647461\n",
      "\n",
      "episode 6, val func loss 2.8338682651519775\n",
      "\n",
      "episode 7, val func loss 3.3232522010803223\n",
      "\n",
      "episode 8, val func loss 3.31954026222229\n",
      "\n",
      "episode 9, val func loss 3.081817626953125\n",
      "\n",
      "episode 10, val func loss 3.2145419120788574\n",
      "\n",
      "episode 11, val func loss 2.7693464756011963\n",
      "\n",
      "episode 12, val func loss 2.9050519466400146\n",
      "\n",
      "episode 13, val func loss 2.6462607383728027\n",
      "\n",
      "episode 14, val func loss 3.45824933052063\n",
      "\n",
      "episode 15, val func loss 3.5184011459350586\n",
      "\n",
      "episode 16, val func loss 3.173839569091797\n",
      "\n",
      "Val func train loss in epoch 15:3.055565759539604\n",
      "***********************TIME WAS 4.930010362466176 min*****************************\n",
      "\n",
      "**********************ROUND 137 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -1.1821911334991455\n",
      "\n",
      "episode 2, policy loss -1.1461604833602905\n",
      "\n",
      "episode 3, policy loss -1.0032621622085571\n",
      "\n",
      "episode 4, policy loss -1.1983376741409302\n",
      "\n",
      "episode 5, policy loss -1.1742150783538818\n",
      "\n",
      "episode 6, policy loss -1.181864619255066\n",
      "\n",
      "episode 7, policy loss -0.9691518545150757\n",
      "\n",
      "episode 8, policy loss -1.126072883605957\n",
      "\n",
      "episode 9, policy loss -1.0775741338729858\n",
      "\n",
      "episode 10, policy loss -1.0557438135147095\n",
      "\n",
      "episode 11, policy loss -1.2128244638442993\n",
      "\n",
      "episode 12, policy loss -1.188424825668335\n",
      "\n",
      "episode 13, policy loss -1.1338673830032349\n",
      "\n",
      "episode 14, policy loss -1.1603645086288452\n",
      "\n",
      "episode 15, policy loss -1.0302515029907227\n",
      "\n",
      "episode 16, policy loss -1.1059428453445435\n",
      "\n",
      "Policy train loss in epoch 0:-1.1216405853629112\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -1.1294339895248413\n",
      "\n",
      "episode 2, policy loss -1.057477593421936\n",
      "\n",
      "episode 3, policy loss -1.185353398323059\n",
      "\n",
      "episode 4, policy loss -1.1346039772033691\n",
      "\n",
      "episode 5, policy loss -1.2158769369125366\n",
      "\n",
      "episode 6, policy loss -1.1063340902328491\n",
      "\n",
      "episode 7, policy loss -1.1896072626113892\n",
      "\n",
      "episode 8, policy loss -1.1610932350158691\n",
      "\n",
      "episode 9, policy loss -1.214424729347229\n",
      "\n",
      "episode 10, policy loss -1.1898345947265625\n",
      "\n",
      "episode 11, policy loss -1.030873417854309\n",
      "\n",
      "episode 12, policy loss -0.9742817878723145\n",
      "\n",
      "episode 13, policy loss -1.2397457361221313\n",
      "\n",
      "episode 14, policy loss -1.0287119150161743\n",
      "\n",
      "episode 15, policy loss -1.0804753303527832\n",
      "\n",
      "episode 16, policy loss -1.1863133907318115\n",
      "\n",
      "Policy train loss in epoch 1:-1.1327775865793228\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -1.2145475149154663\n",
      "\n",
      "episode 2, policy loss -1.1298824548721313\n",
      "\n",
      "episode 3, policy loss -1.0309580564498901\n",
      "\n",
      "episode 4, policy loss -1.189795970916748\n",
      "\n",
      "episode 5, policy loss -1.161257266998291\n",
      "\n",
      "episode 6, policy loss -1.0287632942199707\n",
      "\n",
      "episode 7, policy loss -1.185730218887329\n",
      "\n",
      "episode 8, policy loss -1.1863718032836914\n",
      "\n",
      "episode 9, policy loss -0.9743713140487671\n",
      "\n",
      "episode 10, policy loss -1.0579584836959839\n",
      "\n",
      "episode 11, policy loss -1.106564998626709\n",
      "\n",
      "episode 12, policy loss -1.0805412530899048\n",
      "\n",
      "episode 13, policy loss -1.1899895668029785\n",
      "\n",
      "episode 14, policy loss -1.2161809206008911\n",
      "\n",
      "episode 15, policy loss -1.2398532629013062\n",
      "\n",
      "episode 16, policy loss -1.1349667310714722\n",
      "\n",
      "Policy train loss in epoch 2:-1.1329833194613457\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -1.0805566310882568\n",
      "\n",
      "episode 2, policy loss -1.1349669694900513\n",
      "\n",
      "episode 3, policy loss -1.1613041162490845\n",
      "\n",
      "episode 4, policy loss -1.0288193225860596\n",
      "\n",
      "episode 5, policy loss -1.0579761266708374\n",
      "\n",
      "episode 6, policy loss -1.1857808828353882\n",
      "\n",
      "episode 7, policy loss -1.2398746013641357\n",
      "\n",
      "episode 8, policy loss -1.1065952777862549\n",
      "\n",
      "episode 9, policy loss -0.9744145274162292\n",
      "\n",
      "episode 10, policy loss -1.216205358505249\n",
      "\n",
      "episode 11, policy loss -1.1900241374969482\n",
      "\n",
      "episode 12, policy loss -1.1898671388626099\n",
      "\n",
      "episode 13, policy loss -1.1299644708633423\n",
      "\n",
      "episode 14, policy loss -1.2146424055099487\n",
      "\n",
      "episode 15, policy loss -1.0310320854187012\n",
      "\n",
      "episode 16, policy loss -1.186421513557434\n",
      "\n",
      "Policy train loss in epoch 3:-1.1330278478562832\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.4614689350128174\n",
      "\n",
      "episode 2, val func loss 1.63371741771698\n",
      "\n",
      "episode 3, val func loss 1.788007140159607\n",
      "\n",
      "episode 4, val func loss 1.2362910509109497\n",
      "\n",
      "episode 5, val func loss 1.1164766550064087\n",
      "\n",
      "episode 6, val func loss 1.68540358543396\n",
      "\n",
      "episode 7, val func loss 1.842750906944275\n",
      "\n",
      "episode 8, val func loss 1.5946154594421387\n",
      "\n",
      "episode 9, val func loss 1.3862683773040771\n",
      "\n",
      "episode 10, val func loss 1.0992460250854492\n",
      "\n",
      "episode 11, val func loss 1.8470959663391113\n",
      "\n",
      "episode 12, val func loss 1.7956784963607788\n",
      "\n",
      "episode 13, val func loss 1.6220020055770874\n",
      "\n",
      "episode 14, val func loss 1.3197969198226929\n",
      "\n",
      "episode 15, val func loss 2.3200743198394775\n",
      "\n",
      "episode 16, val func loss 1.3102707862854004\n",
      "\n",
      "Val func train loss in epoch 0:1.6286977529525757\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.2284537553787231\n",
      "\n",
      "episode 2, val func loss 1.3041207790374756\n",
      "\n",
      "episode 3, val func loss 1.4005475044250488\n",
      "\n",
      "episode 4, val func loss 1.2862169742584229\n",
      "\n",
      "episode 5, val func loss 1.8499014377593994\n",
      "\n",
      "episode 6, val func loss 1.781984567642212\n",
      "\n",
      "episode 7, val func loss 1.8590391874313354\n",
      "\n",
      "episode 8, val func loss 1.1518073081970215\n",
      "\n",
      "episode 9, val func loss 1.245704174041748\n",
      "\n",
      "episode 10, val func loss 1.4392873048782349\n",
      "\n",
      "episode 11, val func loss 1.3034299612045288\n",
      "\n",
      "episode 12, val func loss 1.1020485162734985\n",
      "\n",
      "episode 13, val func loss 1.5129115581512451\n",
      "\n",
      "episode 14, val func loss 0.9065366983413696\n",
      "\n",
      "episode 15, val func loss 2.1458213329315186\n",
      "\n",
      "episode 16, val func loss 1.6585617065429688\n",
      "\n",
      "Val func train loss in epoch 1:1.448523297905922\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.993820309638977\n",
      "\n",
      "episode 2, val func loss 2.016425371170044\n",
      "\n",
      "episode 3, val func loss 1.3432899713516235\n",
      "\n",
      "episode 4, val func loss 1.5580389499664307\n",
      "\n",
      "episode 5, val func loss 1.190293550491333\n",
      "\n",
      "episode 6, val func loss 1.1155314445495605\n",
      "\n",
      "episode 7, val func loss 1.3987361192703247\n",
      "\n",
      "episode 8, val func loss 1.1342488527297974\n",
      "\n",
      "episode 9, val func loss 1.4475568532943726\n",
      "\n",
      "episode 10, val func loss 1.6657193899154663\n",
      "\n",
      "episode 11, val func loss 1.3026340007781982\n",
      "\n",
      "episode 12, val func loss 2.005817413330078\n",
      "\n",
      "episode 13, val func loss 1.215558648109436\n",
      "\n",
      "episode 14, val func loss 1.0844968557357788\n",
      "\n",
      "episode 15, val func loss 2.55251407623291\n",
      "\n",
      "episode 16, val func loss 1.2850592136383057\n",
      "\n",
      "Val func train loss in epoch 2:1.4568588137626648\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.6900238990783691\n",
      "\n",
      "episode 2, val func loss 0.9486837983131409\n",
      "\n",
      "episode 3, val func loss 1.0743212699890137\n",
      "\n",
      "episode 4, val func loss 1.3448739051818848\n",
      "\n",
      "episode 5, val func loss 1.7922871112823486\n",
      "\n",
      "episode 6, val func loss 2.2450480461120605\n",
      "\n",
      "episode 7, val func loss 1.3983891010284424\n",
      "\n",
      "episode 8, val func loss 1.425825834274292\n",
      "\n",
      "episode 9, val func loss 1.258322834968567\n",
      "\n",
      "episode 10, val func loss 1.9932907819747925\n",
      "\n",
      "episode 11, val func loss 1.1860934495925903\n",
      "\n",
      "episode 12, val func loss 1.0914061069488525\n",
      "\n",
      "episode 13, val func loss 1.276743769645691\n",
      "\n",
      "episode 14, val func loss 1.7312923669815063\n",
      "\n",
      "episode 15, val func loss 1.2974441051483154\n",
      "\n",
      "episode 16, val func loss 1.7937722206115723\n",
      "\n",
      "Val func train loss in epoch 3:1.471738662570715\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.9278292655944824\n",
      "\n",
      "episode 2, val func loss 1.5799589157104492\n",
      "\n",
      "episode 3, val func loss 1.2043581008911133\n",
      "\n",
      "episode 4, val func loss 1.138956069946289\n",
      "\n",
      "episode 5, val func loss 1.9677459001541138\n",
      "\n",
      "episode 6, val func loss 1.0960028171539307\n",
      "\n",
      "episode 7, val func loss 1.1971369981765747\n",
      "\n",
      "episode 8, val func loss 1.4023391008377075\n",
      "\n",
      "episode 9, val func loss 1.1713032722473145\n",
      "\n",
      "episode 10, val func loss 0.9067999720573425\n",
      "\n",
      "episode 11, val func loss 1.6396713256835938\n",
      "\n",
      "episode 12, val func loss 2.476792812347412\n",
      "\n",
      "episode 13, val func loss 1.2143067121505737\n",
      "\n",
      "episode 14, val func loss 1.7271672487258911\n",
      "\n",
      "episode 15, val func loss 1.5437580347061157\n",
      "\n",
      "episode 16, val func loss 1.5095192193984985\n",
      "\n",
      "Val func train loss in epoch 4:1.4814778603613377\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 2.116339921951294\n",
      "\n",
      "episode 2, val func loss 1.4636650085449219\n",
      "\n",
      "episode 3, val func loss 1.5426561832427979\n",
      "\n",
      "episode 4, val func loss 1.4874966144561768\n",
      "\n",
      "episode 5, val func loss 1.315600872039795\n",
      "\n",
      "episode 6, val func loss 1.2593687772750854\n",
      "\n",
      "episode 7, val func loss 1.0951446294784546\n",
      "\n",
      "episode 8, val func loss 1.6274036169052124\n",
      "\n",
      "episode 9, val func loss 1.0741721391677856\n",
      "\n",
      "episode 10, val func loss 2.1810567378997803\n",
      "\n",
      "episode 11, val func loss 1.274619221687317\n",
      "\n",
      "episode 12, val func loss 1.1266041994094849\n",
      "\n",
      "episode 13, val func loss 1.1653170585632324\n",
      "\n",
      "episode 14, val func loss 1.5300588607788086\n",
      "\n",
      "episode 15, val func loss 0.9746135473251343\n",
      "\n",
      "episode 16, val func loss 1.9916388988494873\n",
      "\n",
      "Val func train loss in epoch 5:1.451609767973423\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.0536725521087646\n",
      "\n",
      "episode 2, val func loss 1.1295922994613647\n",
      "\n",
      "episode 3, val func loss 1.0450273752212524\n",
      "\n",
      "episode 4, val func loss 2.2725939750671387\n",
      "\n",
      "episode 5, val func loss 1.1305843591690063\n",
      "\n",
      "episode 6, val func loss 1.4272328615188599\n",
      "\n",
      "episode 7, val func loss 1.383373737335205\n",
      "\n",
      "episode 8, val func loss 1.165951132774353\n",
      "\n",
      "episode 9, val func loss 2.0352232456207275\n",
      "\n",
      "episode 10, val func loss 1.8180838823318481\n",
      "\n",
      "episode 11, val func loss 1.2382113933563232\n",
      "\n",
      "episode 12, val func loss 1.0274474620819092\n",
      "\n",
      "episode 13, val func loss 1.487447738647461\n",
      "\n",
      "episode 14, val func loss 1.3404279947280884\n",
      "\n",
      "episode 15, val func loss 1.4086374044418335\n",
      "\n",
      "episode 16, val func loss 2.1677865982055664\n",
      "\n",
      "Val func train loss in epoch 6:1.5082058757543564\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 2.0155694484710693\n",
      "\n",
      "episode 2, val func loss 1.345213770866394\n",
      "\n",
      "episode 3, val func loss 1.952497959136963\n",
      "\n",
      "episode 4, val func loss 1.3178576231002808\n",
      "\n",
      "episode 5, val func loss 1.1659854650497437\n",
      "\n",
      "episode 6, val func loss 2.567781925201416\n",
      "\n",
      "episode 7, val func loss 1.500075101852417\n",
      "\n",
      "episode 8, val func loss 1.1101678609848022\n",
      "\n",
      "episode 9, val func loss 1.4563241004943848\n",
      "\n",
      "episode 10, val func loss 1.5187925100326538\n",
      "\n",
      "episode 11, val func loss 1.1491426229476929\n",
      "\n",
      "episode 12, val func loss 1.765839695930481\n",
      "\n",
      "episode 13, val func loss 1.4318733215332031\n",
      "\n",
      "episode 14, val func loss 1.3351478576660156\n",
      "\n",
      "episode 15, val func loss 1.1814311742782593\n",
      "\n",
      "episode 16, val func loss 0.9102290868759155\n",
      "\n",
      "Val func train loss in epoch 7:1.4827455952763557\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.324912190437317\n",
      "\n",
      "episode 2, val func loss 0.9299145936965942\n",
      "\n",
      "episode 3, val func loss 2.4948174953460693\n",
      "\n",
      "episode 4, val func loss 1.2097290754318237\n",
      "\n",
      "episode 5, val func loss 1.568637490272522\n",
      "\n",
      "episode 6, val func loss 1.42628812789917\n",
      "\n",
      "episode 7, val func loss 1.9223610162734985\n",
      "\n",
      "episode 8, val func loss 1.218861699104309\n",
      "\n",
      "episode 9, val func loss 1.1356197595596313\n",
      "\n",
      "episode 10, val func loss 2.008981943130493\n",
      "\n",
      "episode 11, val func loss 1.5722520351409912\n",
      "\n",
      "episode 12, val func loss 1.2630903720855713\n",
      "\n",
      "episode 13, val func loss 1.4121063947677612\n",
      "\n",
      "episode 14, val func loss 1.7435734272003174\n",
      "\n",
      "episode 15, val func loss 1.1204599142074585\n",
      "\n",
      "episode 16, val func loss 1.1152234077453613\n",
      "\n",
      "Val func train loss in epoch 8:1.4666768088936806\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 2.224473714828491\n",
      "\n",
      "episode 2, val func loss 1.19807767868042\n",
      "\n",
      "episode 3, val func loss 1.2878806591033936\n",
      "\n",
      "episode 4, val func loss 1.414255142211914\n",
      "\n",
      "episode 5, val func loss 1.045113444328308\n",
      "\n",
      "episode 6, val func loss 1.262892246246338\n",
      "\n",
      "episode 7, val func loss 1.243364930152893\n",
      "\n",
      "episode 8, val func loss 1.0381439924240112\n",
      "\n",
      "episode 9, val func loss 1.7180436849594116\n",
      "\n",
      "episode 10, val func loss 0.8573217391967773\n",
      "\n",
      "episode 11, val func loss 1.729261040687561\n",
      "\n",
      "episode 12, val func loss 1.1892740726470947\n",
      "\n",
      "episode 13, val func loss 1.3258920907974243\n",
      "\n",
      "episode 14, val func loss 1.94107985496521\n",
      "\n",
      "episode 15, val func loss 1.5576069355010986\n",
      "\n",
      "episode 16, val func loss 1.889627456665039\n",
      "\n",
      "Val func train loss in epoch 9:1.4326442927122116\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.6229664087295532\n",
      "\n",
      "episode 2, val func loss 1.3822288513183594\n",
      "\n",
      "episode 3, val func loss 1.2652456760406494\n",
      "\n",
      "episode 4, val func loss 1.1351118087768555\n",
      "\n",
      "episode 5, val func loss 1.0758036375045776\n",
      "\n",
      "episode 6, val func loss 1.066489338874817\n",
      "\n",
      "episode 7, val func loss 1.5961333513259888\n",
      "\n",
      "episode 8, val func loss 1.7186803817749023\n",
      "\n",
      "episode 9, val func loss 1.198306918144226\n",
      "\n",
      "episode 10, val func loss 1.274155855178833\n",
      "\n",
      "episode 11, val func loss 1.848695158958435\n",
      "\n",
      "episode 12, val func loss 1.1081637144088745\n",
      "\n",
      "episode 13, val func loss 0.9623809456825256\n",
      "\n",
      "episode 14, val func loss 2.3496220111846924\n",
      "\n",
      "episode 15, val func loss 1.1960394382476807\n",
      "\n",
      "episode 16, val func loss 1.7128808498382568\n",
      "\n",
      "Val func train loss in epoch 10:1.4070565216243267\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 1.2827380895614624\n",
      "\n",
      "episode 2, val func loss 1.3153553009033203\n",
      "\n",
      "episode 3, val func loss 1.1954461336135864\n",
      "\n",
      "episode 4, val func loss 1.2632561922073364\n",
      "\n",
      "episode 5, val func loss 1.1014504432678223\n",
      "\n",
      "episode 6, val func loss 1.751301884651184\n",
      "\n",
      "episode 7, val func loss 1.9518566131591797\n",
      "\n",
      "episode 8, val func loss 1.0883185863494873\n",
      "\n",
      "episode 9, val func loss 2.1733624935150146\n",
      "\n",
      "episode 10, val func loss 1.4177894592285156\n",
      "\n",
      "episode 11, val func loss 1.1218243837356567\n",
      "\n",
      "episode 12, val func loss 1.2149107456207275\n",
      "\n",
      "episode 13, val func loss 1.8780324459075928\n",
      "\n",
      "episode 14, val func loss 0.8377854824066162\n",
      "\n",
      "episode 15, val func loss 1.4372375011444092\n",
      "\n",
      "episode 16, val func loss 1.9658880233764648\n",
      "\n",
      "Val func train loss in epoch 11:1.4372846111655235\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.1234710216522217\n",
      "\n",
      "episode 2, val func loss 1.3353393077850342\n",
      "\n",
      "episode 3, val func loss 1.9389315843582153\n",
      "\n",
      "episode 4, val func loss 1.1047815084457397\n",
      "\n",
      "episode 5, val func loss 1.1665040254592896\n",
      "\n",
      "episode 6, val func loss 2.3291656970977783\n",
      "\n",
      "episode 7, val func loss 1.4086023569107056\n",
      "\n",
      "episode 8, val func loss 0.9139689803123474\n",
      "\n",
      "episode 9, val func loss 1.9896340370178223\n",
      "\n",
      "episode 10, val func loss 1.6108136177062988\n",
      "\n",
      "episode 11, val func loss 1.1102557182312012\n",
      "\n",
      "episode 12, val func loss 1.1673558950424194\n",
      "\n",
      "episode 13, val func loss 1.8864829540252686\n",
      "\n",
      "episode 14, val func loss 1.3667343854904175\n",
      "\n",
      "episode 15, val func loss 1.2221025228500366\n",
      "\n",
      "episode 16, val func loss 1.416273593902588\n",
      "\n",
      "Val func train loss in epoch 12:1.4431510753929615\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 1.6686756610870361\n",
      "\n",
      "episode 2, val func loss 1.0707621574401855\n",
      "\n",
      "episode 3, val func loss 2.110302448272705\n",
      "\n",
      "episode 4, val func loss 1.303871512413025\n",
      "\n",
      "episode 5, val func loss 1.8631505966186523\n",
      "\n",
      "episode 6, val func loss 1.9762784242630005\n",
      "\n",
      "episode 7, val func loss 0.9280596375465393\n",
      "\n",
      "episode 8, val func loss 1.956385612487793\n",
      "\n",
      "episode 9, val func loss 1.5144143104553223\n",
      "\n",
      "episode 10, val func loss 1.0795273780822754\n",
      "\n",
      "episode 11, val func loss 1.49807870388031\n",
      "\n",
      "episode 12, val func loss 1.1149718761444092\n",
      "\n",
      "episode 13, val func loss 1.0735541582107544\n",
      "\n",
      "episode 14, val func loss 1.1209862232208252\n",
      "\n",
      "episode 15, val func loss 1.3682162761688232\n",
      "\n",
      "episode 16, val func loss 1.0530868768692017\n",
      "\n",
      "Val func train loss in epoch 13:1.4187701158225536\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 1.5593039989471436\n",
      "\n",
      "episode 2, val func loss 1.3095347881317139\n",
      "\n",
      "episode 3, val func loss 1.0900522470474243\n",
      "\n",
      "episode 4, val func loss 1.4258027076721191\n",
      "\n",
      "episode 5, val func loss 0.8966183066368103\n",
      "\n",
      "episode 6, val func loss 1.2986234426498413\n",
      "\n",
      "episode 7, val func loss 2.419733762741089\n",
      "\n",
      "episode 8, val func loss 1.4346752166748047\n",
      "\n",
      "episode 9, val func loss 1.2892411947250366\n",
      "\n",
      "episode 10, val func loss 1.1413671970367432\n",
      "\n",
      "episode 11, val func loss 1.8772163391113281\n",
      "\n",
      "episode 12, val func loss 1.2947396039962769\n",
      "\n",
      "episode 13, val func loss 1.3238481283187866\n",
      "\n",
      "episode 14, val func loss 1.9658246040344238\n",
      "\n",
      "episode 15, val func loss 1.943422794342041\n",
      "\n",
      "episode 16, val func loss 1.1879712343215942\n",
      "\n",
      "Val func train loss in epoch 14:1.4661234728991985\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 1.3488818407058716\n",
      "\n",
      "episode 2, val func loss 1.8270037174224854\n",
      "\n",
      "episode 3, val func loss 1.115795612335205\n",
      "\n",
      "episode 4, val func loss 1.3408674001693726\n",
      "\n",
      "episode 5, val func loss 1.494274377822876\n",
      "\n",
      "episode 6, val func loss 2.1065640449523926\n",
      "\n",
      "episode 7, val func loss 1.096599817276001\n",
      "\n",
      "episode 8, val func loss 1.8998287916183472\n",
      "\n",
      "episode 9, val func loss 1.8066084384918213\n",
      "\n",
      "episode 10, val func loss 1.4439843893051147\n",
      "\n",
      "episode 11, val func loss 1.64234459400177\n",
      "\n",
      "episode 12, val func loss 1.2488503456115723\n",
      "\n",
      "episode 13, val func loss 1.0227981805801392\n",
      "\n",
      "episode 14, val func loss 1.325399398803711\n",
      "\n",
      "episode 15, val func loss 2.1419100761413574\n",
      "\n",
      "episode 16, val func loss 1.2558668851852417\n",
      "\n",
      "Val func train loss in epoch 15:1.507348619401455\n",
      "***********************TIME WAS 4.932077121734619 min*****************************\n",
      "\n",
      "**********************ROUND 138 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.8157957196235657\n",
      "\n",
      "episode 2, policy loss 0.8157956600189209\n",
      "\n",
      "episode 3, policy loss 0.8157986998558044\n",
      "\n",
      "episode 4, policy loss 0.8157919049263\n",
      "\n",
      "episode 5, policy loss 0.8157938122749329\n",
      "\n",
      "episode 6, policy loss 0.8157853484153748\n",
      "\n",
      "episode 7, policy loss 0.8157971501350403\n",
      "\n",
      "episode 8, policy loss 0.8157951235771179\n",
      "\n",
      "episode 9, policy loss 0.8157991766929626\n",
      "\n",
      "episode 10, policy loss 0.8157957196235657\n",
      "\n",
      "episode 11, policy loss 0.8157995939254761\n",
      "\n",
      "episode 12, policy loss 0.8157883882522583\n",
      "\n",
      "episode 13, policy loss 0.8157934546470642\n",
      "\n",
      "episode 14, policy loss 0.8158060908317566\n",
      "\n",
      "episode 15, policy loss 0.8157949447631836\n",
      "\n",
      "episode 16, policy loss 0.8157984018325806\n",
      "\n",
      "Policy train loss in epoch 0:0.815795574337244\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.8157947659492493\n",
      "\n",
      "episode 2, policy loss 0.8157992362976074\n",
      "\n",
      "episode 3, policy loss 0.8157978653907776\n",
      "\n",
      "episode 4, policy loss 0.8157857060432434\n",
      "\n",
      "episode 5, policy loss 0.8157936334609985\n",
      "\n",
      "episode 6, policy loss 0.815788745880127\n",
      "\n",
      "episode 7, policy loss 0.8158021569252014\n",
      "\n",
      "episode 8, policy loss 0.8157985210418701\n",
      "\n",
      "episode 9, policy loss 0.8157968521118164\n",
      "\n",
      "episode 10, policy loss 0.8157960772514343\n",
      "\n",
      "episode 11, policy loss 0.8157979249954224\n",
      "\n",
      "episode 12, policy loss 0.8157990574836731\n",
      "\n",
      "episode 13, policy loss 0.8157808184623718\n",
      "\n",
      "episode 14, policy loss 0.8157919049263\n",
      "\n",
      "episode 15, policy loss 0.8157877922058105\n",
      "\n",
      "episode 16, policy loss 0.8157920837402344\n",
      "\n",
      "Policy train loss in epoch 1:0.8157939463853836\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.8157891631126404\n",
      "\n",
      "episode 2, policy loss 0.8157808184623718\n",
      "\n",
      "episode 3, policy loss 0.8157867193222046\n",
      "\n",
      "episode 4, policy loss 0.8157852292060852\n",
      "\n",
      "episode 5, policy loss 0.8157863020896912\n",
      "\n",
      "episode 6, policy loss 0.8157851696014404\n",
      "\n",
      "episode 7, policy loss 0.815792441368103\n",
      "\n",
      "episode 8, policy loss 0.8157855272293091\n",
      "\n",
      "episode 9, policy loss 0.8157809376716614\n",
      "\n",
      "episode 10, policy loss 0.815779447555542\n",
      "\n",
      "episode 11, policy loss 0.8157745599746704\n",
      "\n",
      "episode 12, policy loss 0.8158017992973328\n",
      "\n",
      "episode 13, policy loss 0.8157860040664673\n",
      "\n",
      "episode 14, policy loss 0.8157740831375122\n",
      "\n",
      "episode 15, policy loss 0.8157770037651062\n",
      "\n",
      "episode 16, policy loss 0.8157888650894165\n",
      "\n",
      "Policy train loss in epoch 2:0.8157846294343472\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.8157796263694763\n",
      "\n",
      "episode 2, policy loss 0.8157811760902405\n",
      "\n",
      "episode 3, policy loss 0.8157777190208435\n",
      "\n",
      "episode 4, policy loss 0.8157764673233032\n",
      "\n",
      "episode 5, policy loss 0.8157739639282227\n",
      "\n",
      "episode 6, policy loss 0.8157727718353271\n",
      "\n",
      "episode 7, policy loss 0.8157678246498108\n",
      "\n",
      "episode 8, policy loss 0.8157702684402466\n",
      "\n",
      "episode 9, policy loss 0.8157744407653809\n",
      "\n",
      "episode 10, policy loss 0.8157770037651062\n",
      "\n",
      "episode 11, policy loss 0.8157649040222168\n",
      "\n",
      "episode 12, policy loss 0.8157671093940735\n",
      "\n",
      "episode 13, policy loss 0.8157687783241272\n",
      "\n",
      "episode 14, policy loss 0.8157593011856079\n",
      "\n",
      "episode 15, policy loss 0.8157561421394348\n",
      "\n",
      "episode 16, policy loss 0.8157641887664795\n",
      "\n",
      "Policy train loss in epoch 3:0.8157707303762436\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.7521345615386963\n",
      "\n",
      "episode 2, val func loss 0.6064061522483826\n",
      "\n",
      "episode 3, val func loss 0.6793773770332336\n",
      "\n",
      "episode 4, val func loss 0.8034845590591431\n",
      "\n",
      "episode 5, val func loss 0.7744922041893005\n",
      "\n",
      "episode 6, val func loss 0.6949084997177124\n",
      "\n",
      "episode 7, val func loss 0.7307444214820862\n",
      "\n",
      "episode 8, val func loss 0.7574124932289124\n",
      "\n",
      "episode 9, val func loss 0.722955048084259\n",
      "\n",
      "episode 10, val func loss 0.6901183724403381\n",
      "\n",
      "episode 11, val func loss 0.6772645115852356\n",
      "\n",
      "episode 12, val func loss 0.7864623069763184\n",
      "\n",
      "episode 13, val func loss 0.6726477146148682\n",
      "\n",
      "episode 14, val func loss 0.6745864152908325\n",
      "\n",
      "episode 15, val func loss 0.6930660605430603\n",
      "\n",
      "episode 16, val func loss 0.6225153803825378\n",
      "\n",
      "Val func train loss in epoch 0:0.7086610049009323\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.639348566532135\n",
      "\n",
      "episode 2, val func loss 0.7175649404525757\n",
      "\n",
      "episode 3, val func loss 0.6124169826507568\n",
      "\n",
      "episode 4, val func loss 0.6407971382141113\n",
      "\n",
      "episode 5, val func loss 0.6579994559288025\n",
      "\n",
      "episode 6, val func loss 0.5765506625175476\n",
      "\n",
      "episode 7, val func loss 0.597914457321167\n",
      "\n",
      "episode 8, val func loss 0.6385393738746643\n",
      "\n",
      "episode 9, val func loss 0.6631327271461487\n",
      "\n",
      "episode 10, val func loss 0.6445214748382568\n",
      "\n",
      "episode 11, val func loss 0.5992429256439209\n",
      "\n",
      "episode 12, val func loss 0.6644168496131897\n",
      "\n",
      "episode 13, val func loss 0.5853578448295593\n",
      "\n",
      "episode 14, val func loss 0.592525839805603\n",
      "\n",
      "episode 15, val func loss 0.5873147249221802\n",
      "\n",
      "episode 16, val func loss 0.6302086114883423\n",
      "\n",
      "Val func train loss in epoch 1:0.6279907859861851\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6237584352493286\n",
      "\n",
      "episode 2, val func loss 0.6641587615013123\n",
      "\n",
      "episode 3, val func loss 0.6741881370544434\n",
      "\n",
      "episode 4, val func loss 0.6945479512214661\n",
      "\n",
      "episode 5, val func loss 0.6001177430152893\n",
      "\n",
      "episode 6, val func loss 0.6227347254753113\n",
      "\n",
      "episode 7, val func loss 0.5799350738525391\n",
      "\n",
      "episode 8, val func loss 0.5402182936668396\n",
      "\n",
      "episode 9, val func loss 0.6363316774368286\n",
      "\n",
      "episode 10, val func loss 0.5719706416130066\n",
      "\n",
      "episode 11, val func loss 0.6470386385917664\n",
      "\n",
      "episode 12, val func loss 0.5881982445716858\n",
      "\n",
      "episode 13, val func loss 0.6037330031394958\n",
      "\n",
      "episode 14, val func loss 0.5810587406158447\n",
      "\n",
      "episode 15, val func loss 0.649993896484375\n",
      "\n",
      "episode 16, val func loss 0.6638601422309875\n",
      "\n",
      "Val func train loss in epoch 2:0.6213652566075325\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6997538208961487\n",
      "\n",
      "episode 2, val func loss 0.5973926186561584\n",
      "\n",
      "episode 3, val func loss 0.6073310971260071\n",
      "\n",
      "episode 4, val func loss 0.6299476623535156\n",
      "\n",
      "episode 5, val func loss 0.53618323802948\n",
      "\n",
      "episode 6, val func loss 0.5769365429878235\n",
      "\n",
      "episode 7, val func loss 0.5824862122535706\n",
      "\n",
      "episode 8, val func loss 0.5880523324012756\n",
      "\n",
      "episode 9, val func loss 0.598642110824585\n",
      "\n",
      "episode 10, val func loss 0.617443323135376\n",
      "\n",
      "episode 11, val func loss 0.6091123223304749\n",
      "\n",
      "episode 12, val func loss 0.6816961765289307\n",
      "\n",
      "episode 13, val func loss 0.605740487575531\n",
      "\n",
      "episode 14, val func loss 0.6198722124099731\n",
      "\n",
      "episode 15, val func loss 0.6260406374931335\n",
      "\n",
      "episode 16, val func loss 0.5505625605583191\n",
      "\n",
      "Val func train loss in epoch 3:0.6079495847225189\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.6496302485466003\n",
      "\n",
      "episode 2, val func loss 0.6244694590568542\n",
      "\n",
      "episode 3, val func loss 0.5651312470436096\n",
      "\n",
      "episode 4, val func loss 0.7143322825431824\n",
      "\n",
      "episode 5, val func loss 0.6237136721611023\n",
      "\n",
      "episode 6, val func loss 0.6002081632614136\n",
      "\n",
      "episode 7, val func loss 0.5469099879264832\n",
      "\n",
      "episode 8, val func loss 0.6992630362510681\n",
      "\n",
      "episode 9, val func loss 0.5191795825958252\n",
      "\n",
      "episode 10, val func loss 0.591037392616272\n",
      "\n",
      "episode 11, val func loss 0.6193358302116394\n",
      "\n",
      "episode 12, val func loss 0.6359419226646423\n",
      "\n",
      "episode 13, val func loss 0.5828720927238464\n",
      "\n",
      "episode 14, val func loss 0.6451807022094727\n",
      "\n",
      "episode 15, val func loss 0.5923208594322205\n",
      "\n",
      "episode 16, val func loss 0.6787978410720825\n",
      "\n",
      "Val func train loss in epoch 4:0.6180202700197697\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.7761340141296387\n",
      "\n",
      "episode 2, val func loss 0.5866026282310486\n",
      "\n",
      "episode 3, val func loss 0.6844074130058289\n",
      "\n",
      "episode 4, val func loss 0.6448659896850586\n",
      "\n",
      "episode 5, val func loss 0.6718932390213013\n",
      "\n",
      "episode 6, val func loss 0.5516872406005859\n",
      "\n",
      "episode 7, val func loss 0.6066530346870422\n",
      "\n",
      "episode 8, val func loss 0.6900712847709656\n",
      "\n",
      "episode 9, val func loss 0.5481150150299072\n",
      "\n",
      "episode 10, val func loss 0.6141449809074402\n",
      "\n",
      "episode 11, val func loss 0.5722931623458862\n",
      "\n",
      "episode 12, val func loss 0.5867006778717041\n",
      "\n",
      "episode 13, val func loss 0.6470829844474792\n",
      "\n",
      "episode 14, val func loss 0.5729749202728271\n",
      "\n",
      "episode 15, val func loss 0.7027184367179871\n",
      "\n",
      "episode 16, val func loss 0.6004192233085632\n",
      "\n",
      "Val func train loss in epoch 5:0.628547765314579\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6555230021476746\n",
      "\n",
      "episode 2, val func loss 0.6236199736595154\n",
      "\n",
      "episode 3, val func loss 0.6203110218048096\n",
      "\n",
      "episode 4, val func loss 0.6461226344108582\n",
      "\n",
      "episode 5, val func loss 0.5967580676078796\n",
      "\n",
      "episode 6, val func loss 0.6234221458435059\n",
      "\n",
      "episode 7, val func loss 0.647982656955719\n",
      "\n",
      "episode 8, val func loss 0.6926320791244507\n",
      "\n",
      "episode 9, val func loss 0.5990381240844727\n",
      "\n",
      "episode 10, val func loss 0.6804586052894592\n",
      "\n",
      "episode 11, val func loss 0.6841527223587036\n",
      "\n",
      "episode 12, val func loss 0.7395826578140259\n",
      "\n",
      "episode 13, val func loss 0.5866184830665588\n",
      "\n",
      "episode 14, val func loss 0.5997225642204285\n",
      "\n",
      "episode 15, val func loss 0.6421371698379517\n",
      "\n",
      "episode 16, val func loss 0.6677846312522888\n",
      "\n",
      "Val func train loss in epoch 6:0.6441166587173939\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6664782762527466\n",
      "\n",
      "episode 2, val func loss 0.5669529438018799\n",
      "\n",
      "episode 3, val func loss 0.620753824710846\n",
      "\n",
      "episode 4, val func loss 0.6059086918830872\n",
      "\n",
      "episode 5, val func loss 0.6836321949958801\n",
      "\n",
      "episode 6, val func loss 0.5878608226776123\n",
      "\n",
      "episode 7, val func loss 0.6151162385940552\n",
      "\n",
      "episode 8, val func loss 0.6366797685623169\n",
      "\n",
      "episode 9, val func loss 0.5961517691612244\n",
      "\n",
      "episode 10, val func loss 0.5834547281265259\n",
      "\n",
      "episode 11, val func loss 0.5559133291244507\n",
      "\n",
      "episode 12, val func loss 0.6477389335632324\n",
      "\n",
      "episode 13, val func loss 0.6151783466339111\n",
      "\n",
      "episode 14, val func loss 0.6992398500442505\n",
      "\n",
      "episode 15, val func loss 0.6040345430374146\n",
      "\n",
      "episode 16, val func loss 0.6356134414672852\n",
      "\n",
      "Val func train loss in epoch 7:0.6200442314147949\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.5858820080757141\n",
      "\n",
      "episode 2, val func loss 0.5949137806892395\n",
      "\n",
      "episode 3, val func loss 0.639298141002655\n",
      "\n",
      "episode 4, val func loss 0.6126392483711243\n",
      "\n",
      "episode 5, val func loss 0.5665024518966675\n",
      "\n",
      "episode 6, val func loss 0.5669543743133545\n",
      "\n",
      "episode 7, val func loss 0.6736071705818176\n",
      "\n",
      "episode 8, val func loss 0.6760631203651428\n",
      "\n",
      "episode 9, val func loss 0.6310936808586121\n",
      "\n",
      "episode 10, val func loss 0.6147577166557312\n",
      "\n",
      "episode 11, val func loss 0.7398511171340942\n",
      "\n",
      "episode 12, val func loss 0.5478227138519287\n",
      "\n",
      "episode 13, val func loss 0.6561474204063416\n",
      "\n",
      "episode 14, val func loss 0.6797956228256226\n",
      "\n",
      "episode 15, val func loss 0.6169602870941162\n",
      "\n",
      "episode 16, val func loss 0.6456701159477234\n",
      "\n",
      "Val func train loss in epoch 8:0.6279974356293678\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6001338958740234\n",
      "\n",
      "episode 2, val func loss 0.7536819577217102\n",
      "\n",
      "episode 3, val func loss 0.5726888179779053\n",
      "\n",
      "episode 4, val func loss 0.6237008571624756\n",
      "\n",
      "episode 5, val func loss 0.5755609273910522\n",
      "\n",
      "episode 6, val func loss 0.6580522656440735\n",
      "\n",
      "episode 7, val func loss 0.5984414219856262\n",
      "\n",
      "episode 8, val func loss 0.5974806547164917\n",
      "\n",
      "episode 9, val func loss 0.6300764083862305\n",
      "\n",
      "episode 10, val func loss 0.7098478078842163\n",
      "\n",
      "episode 11, val func loss 0.5551353096961975\n",
      "\n",
      "episode 12, val func loss 0.7032695412635803\n",
      "\n",
      "episode 13, val func loss 0.6931275129318237\n",
      "\n",
      "episode 14, val func loss 0.7182353734970093\n",
      "\n",
      "episode 15, val func loss 0.5342844128608704\n",
      "\n",
      "episode 16, val func loss 0.727497935295105\n",
      "\n",
      "Val func train loss in epoch 9:0.6407009437680244\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6888787150382996\n",
      "\n",
      "episode 2, val func loss 0.6197500228881836\n",
      "\n",
      "episode 3, val func loss 0.644087016582489\n",
      "\n",
      "episode 4, val func loss 0.5799837708473206\n",
      "\n",
      "episode 5, val func loss 0.6422591805458069\n",
      "\n",
      "episode 6, val func loss 0.6560053825378418\n",
      "\n",
      "episode 7, val func loss 0.5940846800804138\n",
      "\n",
      "episode 8, val func loss 0.6040860414505005\n",
      "\n",
      "episode 9, val func loss 0.5381383895874023\n",
      "\n",
      "episode 10, val func loss 0.5778558850288391\n",
      "\n",
      "episode 11, val func loss 0.6089451909065247\n",
      "\n",
      "episode 12, val func loss 0.6870371699333191\n",
      "\n",
      "episode 13, val func loss 0.674981951713562\n",
      "\n",
      "episode 14, val func loss 0.5978485941886902\n",
      "\n",
      "episode 15, val func loss 0.6446139216423035\n",
      "\n",
      "episode 16, val func loss 0.561127245426178\n",
      "\n",
      "Val func train loss in epoch 10:0.6199801973998547\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6870070099830627\n",
      "\n",
      "episode 2, val func loss 0.656419038772583\n",
      "\n",
      "episode 3, val func loss 0.6595360040664673\n",
      "\n",
      "episode 4, val func loss 0.6647518277168274\n",
      "\n",
      "episode 5, val func loss 0.6847538352012634\n",
      "\n",
      "episode 6, val func loss 0.6573142409324646\n",
      "\n",
      "episode 7, val func loss 0.6162967085838318\n",
      "\n",
      "episode 8, val func loss 0.654205322265625\n",
      "\n",
      "episode 9, val func loss 0.6677777171134949\n",
      "\n",
      "episode 10, val func loss 0.6769946813583374\n",
      "\n",
      "episode 11, val func loss 0.5824452042579651\n",
      "\n",
      "episode 12, val func loss 0.6064718961715698\n",
      "\n",
      "episode 13, val func loss 0.5376575589179993\n",
      "\n",
      "episode 14, val func loss 0.6923912167549133\n",
      "\n",
      "episode 15, val func loss 0.7432447075843811\n",
      "\n",
      "episode 16, val func loss 0.5576551556587219\n",
      "\n",
      "Val func train loss in epoch 11:0.6465576328337193\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6880599856376648\n",
      "\n",
      "episode 2, val func loss 0.678605854511261\n",
      "\n",
      "episode 3, val func loss 0.6432780027389526\n",
      "\n",
      "episode 4, val func loss 0.6167335510253906\n",
      "\n",
      "episode 5, val func loss 0.6927469372749329\n",
      "\n",
      "episode 6, val func loss 0.6657412052154541\n",
      "\n",
      "episode 7, val func loss 0.7537556886672974\n",
      "\n",
      "episode 8, val func loss 0.6257759928703308\n",
      "\n",
      "episode 9, val func loss 0.5738824605941772\n",
      "\n",
      "episode 10, val func loss 0.7693684101104736\n",
      "\n",
      "episode 11, val func loss 0.6142769455909729\n",
      "\n",
      "episode 12, val func loss 0.7169644236564636\n",
      "\n",
      "episode 13, val func loss 0.6778024435043335\n",
      "\n",
      "episode 14, val func loss 0.6215999126434326\n",
      "\n",
      "episode 15, val func loss 0.6713552474975586\n",
      "\n",
      "episode 16, val func loss 0.6428764462471008\n",
      "\n",
      "Val func train loss in epoch 12:0.6658014692366123\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6498645544052124\n",
      "\n",
      "episode 2, val func loss 0.7076680064201355\n",
      "\n",
      "episode 3, val func loss 0.8523653149604797\n",
      "\n",
      "episode 4, val func loss 0.5717028975486755\n",
      "\n",
      "episode 5, val func loss 0.700219452381134\n",
      "\n",
      "episode 6, val func loss 0.6697005033493042\n",
      "\n",
      "episode 7, val func loss 0.6776453852653503\n",
      "\n",
      "episode 8, val func loss 0.6939113736152649\n",
      "\n",
      "episode 9, val func loss 0.6913867592811584\n",
      "\n",
      "episode 10, val func loss 0.5890951752662659\n",
      "\n",
      "episode 11, val func loss 0.583593487739563\n",
      "\n",
      "episode 12, val func loss 0.6049705147743225\n",
      "\n",
      "episode 13, val func loss 0.6950919032096863\n",
      "\n",
      "episode 14, val func loss 0.6047300696372986\n",
      "\n",
      "episode 15, val func loss 0.7027078866958618\n",
      "\n",
      "episode 16, val func loss 0.632610023021698\n",
      "\n",
      "Val func train loss in epoch 13:0.6642039567232132\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6823202967643738\n",
      "\n",
      "episode 2, val func loss 0.7145993113517761\n",
      "\n",
      "episode 3, val func loss 0.5573480725288391\n",
      "\n",
      "episode 4, val func loss 0.6112713813781738\n",
      "\n",
      "episode 5, val func loss 0.6773931980133057\n",
      "\n",
      "episode 6, val func loss 0.662011981010437\n",
      "\n",
      "episode 7, val func loss 0.5844998359680176\n",
      "\n",
      "episode 8, val func loss 0.6563280820846558\n",
      "\n",
      "episode 9, val func loss 0.7122582197189331\n",
      "\n",
      "episode 10, val func loss 0.6905708312988281\n",
      "\n",
      "episode 11, val func loss 0.5887419581413269\n",
      "\n",
      "episode 12, val func loss 0.5488446950912476\n",
      "\n",
      "episode 13, val func loss 0.6621385216712952\n",
      "\n",
      "episode 14, val func loss 0.7136719822883606\n",
      "\n",
      "episode 15, val func loss 0.6074178814888\n",
      "\n",
      "episode 16, val func loss 0.5340954661369324\n",
      "\n",
      "Val func train loss in epoch 14:0.6377194821834564\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.5787760615348816\n",
      "\n",
      "episode 2, val func loss 0.583843469619751\n",
      "\n",
      "episode 3, val func loss 0.6247727274894714\n",
      "\n",
      "episode 4, val func loss 0.6879041790962219\n",
      "\n",
      "episode 5, val func loss 0.6653363704681396\n",
      "\n",
      "episode 6, val func loss 0.5993109941482544\n",
      "\n",
      "episode 7, val func loss 0.5794498920440674\n",
      "\n",
      "episode 8, val func loss 0.6677181720733643\n",
      "\n",
      "episode 9, val func loss 0.49207109212875366\n",
      "\n",
      "episode 10, val func loss 0.5325575470924377\n",
      "\n",
      "episode 11, val func loss 0.6888577342033386\n",
      "\n",
      "episode 12, val func loss 0.7141149640083313\n",
      "\n",
      "episode 13, val func loss 0.6727055907249451\n",
      "\n",
      "episode 14, val func loss 0.6108876466751099\n",
      "\n",
      "episode 15, val func loss 0.6064269542694092\n",
      "\n",
      "episode 16, val func loss 0.5399463772773743\n",
      "\n",
      "Val func train loss in epoch 15:0.6152924858033657\n",
      "***********************TIME WAS 4.936432933807373 min*****************************\n",
      "\n",
      "**********************ROUND 139 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.7594391107559204\n",
      "\n",
      "episode 2, policy loss 0.7594552636146545\n",
      "\n",
      "episode 3, policy loss 0.759447455406189\n",
      "\n",
      "episode 4, policy loss 0.7594524621963501\n",
      "\n",
      "episode 5, policy loss 0.759443461894989\n",
      "\n",
      "episode 6, policy loss 0.7594486474990845\n",
      "\n",
      "episode 7, policy loss 0.7594436407089233\n",
      "\n",
      "episode 8, policy loss 0.7594344019889832\n",
      "\n",
      "episode 9, policy loss 0.7594286799430847\n",
      "\n",
      "episode 10, policy loss 0.7594387531280518\n",
      "\n",
      "episode 11, policy loss 0.7594292163848877\n",
      "\n",
      "episode 12, policy loss 0.7594449520111084\n",
      "\n",
      "episode 13, policy loss 0.7594318985939026\n",
      "\n",
      "episode 14, policy loss 0.7594306468963623\n",
      "\n",
      "episode 15, policy loss 0.7594370245933533\n",
      "\n",
      "episode 16, policy loss 0.7594175934791565\n",
      "\n",
      "Policy train loss in epoch 0:0.7594389505684376\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.75942462682724\n",
      "\n",
      "episode 2, policy loss 0.7594065070152283\n",
      "\n",
      "episode 3, policy loss 0.7594290375709534\n",
      "\n",
      "episode 4, policy loss 0.7594084143638611\n",
      "\n",
      "episode 5, policy loss 0.759418249130249\n",
      "\n",
      "episode 6, policy loss 0.7594292163848877\n",
      "\n",
      "episode 7, policy loss 0.7594094276428223\n",
      "\n",
      "episode 8, policy loss 0.7593980431556702\n",
      "\n",
      "episode 9, policy loss 0.7594122290611267\n",
      "\n",
      "episode 10, policy loss 0.7593947052955627\n",
      "\n",
      "episode 11, policy loss 0.7594037652015686\n",
      "\n",
      "episode 12, policy loss 0.759395182132721\n",
      "\n",
      "episode 13, policy loss 0.7593929767608643\n",
      "\n",
      "episode 14, policy loss 0.7593966722488403\n",
      "\n",
      "episode 15, policy loss 0.759390115737915\n",
      "\n",
      "episode 16, policy loss 0.7593876719474792\n",
      "\n",
      "Policy train loss in epoch 1:0.7594060525298119\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.7593738436698914\n",
      "\n",
      "episode 2, policy loss 0.7593852877616882\n",
      "\n",
      "episode 3, policy loss 0.7593792080879211\n",
      "\n",
      "episode 4, policy loss 0.7593699097633362\n",
      "\n",
      "episode 5, policy loss 0.7593689560890198\n",
      "\n",
      "episode 6, policy loss 0.7593781352043152\n",
      "\n",
      "episode 7, policy loss 0.7593485116958618\n",
      "\n",
      "episode 8, policy loss 0.7593523859977722\n",
      "\n",
      "episode 9, policy loss 0.7593544125556946\n",
      "\n",
      "episode 10, policy loss 0.7593278288841248\n",
      "\n",
      "episode 11, policy loss 0.7593410015106201\n",
      "\n",
      "episode 12, policy loss 0.7593382000923157\n",
      "\n",
      "episode 13, policy loss 0.7593154907226562\n",
      "\n",
      "episode 14, policy loss 0.7593151330947876\n",
      "\n",
      "episode 15, policy loss 0.7593101859092712\n",
      "\n",
      "episode 16, policy loss 0.7592833638191223\n",
      "\n",
      "Policy train loss in epoch 2:0.7593463659286499\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.7592703700065613\n",
      "\n",
      "episode 2, policy loss 0.7592794895172119\n",
      "\n",
      "episode 3, policy loss 0.7592572569847107\n",
      "\n",
      "episode 4, policy loss 0.7592567801475525\n",
      "\n",
      "episode 5, policy loss 0.759225070476532\n",
      "\n",
      "episode 6, policy loss 0.7592161893844604\n",
      "\n",
      "episode 7, policy loss 0.759202778339386\n",
      "\n",
      "episode 8, policy loss 0.7591941952705383\n",
      "\n",
      "episode 9, policy loss 0.7591632604598999\n",
      "\n",
      "episode 10, policy loss 0.7591122388839722\n",
      "\n",
      "episode 11, policy loss 0.7591230273246765\n",
      "\n",
      "episode 12, policy loss 0.7590943574905396\n",
      "\n",
      "episode 13, policy loss 0.7589860558509827\n",
      "\n",
      "episode 14, policy loss 0.7589759230613708\n",
      "\n",
      "episode 15, policy loss 0.7588948607444763\n",
      "\n",
      "episode 16, policy loss 0.7588794231414795\n",
      "\n",
      "Policy train loss in epoch 3:0.7591332048177719\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.567162275314331\n",
      "\n",
      "episode 2, val func loss 0.6187347173690796\n",
      "\n",
      "episode 3, val func loss 0.6038792133331299\n",
      "\n",
      "episode 4, val func loss 0.7015916705131531\n",
      "\n",
      "episode 5, val func loss 0.6202771663665771\n",
      "\n",
      "episode 6, val func loss 0.6192753314971924\n",
      "\n",
      "episode 7, val func loss 0.581830620765686\n",
      "\n",
      "episode 8, val func loss 0.5893324613571167\n",
      "\n",
      "episode 9, val func loss 0.6318981647491455\n",
      "\n",
      "episode 10, val func loss 0.626883327960968\n",
      "\n",
      "episode 11, val func loss 0.6012651920318604\n",
      "\n",
      "episode 12, val func loss 0.5633333325386047\n",
      "\n",
      "episode 13, val func loss 0.6295939683914185\n",
      "\n",
      "episode 14, val func loss 0.610653281211853\n",
      "\n",
      "episode 15, val func loss 0.5719189643859863\n",
      "\n",
      "episode 16, val func loss 0.6281639933586121\n",
      "\n",
      "Val func train loss in epoch 0:0.6103621050715446\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.5952593684196472\n",
      "\n",
      "episode 2, val func loss 0.5807493925094604\n",
      "\n",
      "episode 3, val func loss 0.5842615962028503\n",
      "\n",
      "episode 4, val func loss 0.687857449054718\n",
      "\n",
      "episode 5, val func loss 0.6428803205490112\n",
      "\n",
      "episode 6, val func loss 0.5998132824897766\n",
      "\n",
      "episode 7, val func loss 0.6887540817260742\n",
      "\n",
      "episode 8, val func loss 0.6364881992340088\n",
      "\n",
      "episode 9, val func loss 0.6356421113014221\n",
      "\n",
      "episode 10, val func loss 0.5592934489250183\n",
      "\n",
      "episode 11, val func loss 0.6665574312210083\n",
      "\n",
      "episode 12, val func loss 0.6267421841621399\n",
      "\n",
      "episode 13, val func loss 0.6516498327255249\n",
      "\n",
      "episode 14, val func loss 0.6583288311958313\n",
      "\n",
      "episode 15, val func loss 0.6099596619606018\n",
      "\n",
      "episode 16, val func loss 0.5876567959785461\n",
      "\n",
      "Val func train loss in epoch 1:0.6257433742284775\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6443586945533752\n",
      "\n",
      "episode 2, val func loss 0.6608002185821533\n",
      "\n",
      "episode 3, val func loss 0.5701104998588562\n",
      "\n",
      "episode 4, val func loss 0.6592356562614441\n",
      "\n",
      "episode 5, val func loss 0.6516475081443787\n",
      "\n",
      "episode 6, val func loss 0.6845717430114746\n",
      "\n",
      "episode 7, val func loss 0.6834036111831665\n",
      "\n",
      "episode 8, val func loss 0.6595863103866577\n",
      "\n",
      "episode 9, val func loss 0.6654750108718872\n",
      "\n",
      "episode 10, val func loss 0.62525874376297\n",
      "\n",
      "episode 11, val func loss 0.5879754424095154\n",
      "\n",
      "episode 12, val func loss 0.6180453300476074\n",
      "\n",
      "episode 13, val func loss 0.5714085102081299\n",
      "\n",
      "episode 14, val func loss 0.5673695802688599\n",
      "\n",
      "episode 15, val func loss 0.6374614834785461\n",
      "\n",
      "episode 16, val func loss 0.614618718624115\n",
      "\n",
      "Val func train loss in epoch 2:0.6313329413533211\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6731092929840088\n",
      "\n",
      "episode 2, val func loss 0.549982488155365\n",
      "\n",
      "episode 3, val func loss 0.6340993642807007\n",
      "\n",
      "episode 4, val func loss 0.7000249624252319\n",
      "\n",
      "episode 5, val func loss 0.5547988414764404\n",
      "\n",
      "episode 6, val func loss 0.7232419848442078\n",
      "\n",
      "episode 7, val func loss 0.7113038301467896\n",
      "\n",
      "episode 8, val func loss 0.5648019909858704\n",
      "\n",
      "episode 9, val func loss 0.6986554861068726\n",
      "\n",
      "episode 10, val func loss 0.6711588501930237\n",
      "\n",
      "episode 11, val func loss 0.6308563351631165\n",
      "\n",
      "episode 12, val func loss 0.7375509738922119\n",
      "\n",
      "episode 13, val func loss 0.5595168471336365\n",
      "\n",
      "episode 14, val func loss 0.5408403873443604\n",
      "\n",
      "episode 15, val func loss 0.7445923686027527\n",
      "\n",
      "episode 16, val func loss 0.6760813593864441\n",
      "\n",
      "Val func train loss in epoch 3:0.6481634601950645\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.5661363005638123\n",
      "\n",
      "episode 2, val func loss 0.5673143863677979\n",
      "\n",
      "episode 3, val func loss 0.6723861694335938\n",
      "\n",
      "episode 4, val func loss 0.5608469247817993\n",
      "\n",
      "episode 5, val func loss 0.7172791957855225\n",
      "\n",
      "episode 6, val func loss 0.6944674253463745\n",
      "\n",
      "episode 7, val func loss 0.6128404140472412\n",
      "\n",
      "episode 8, val func loss 0.5754086375236511\n",
      "\n",
      "episode 9, val func loss 0.5991127490997314\n",
      "\n",
      "episode 10, val func loss 0.7405516505241394\n",
      "\n",
      "episode 11, val func loss 0.5906854271888733\n",
      "\n",
      "episode 12, val func loss 0.6262363195419312\n",
      "\n",
      "episode 13, val func loss 0.6556431651115417\n",
      "\n",
      "episode 14, val func loss 0.6022022366523743\n",
      "\n",
      "episode 15, val func loss 0.599228024482727\n",
      "\n",
      "episode 16, val func loss 0.5881354212760925\n",
      "\n",
      "Val func train loss in epoch 4:0.6230296529829502\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6381148099899292\n",
      "\n",
      "episode 2, val func loss 0.6271583437919617\n",
      "\n",
      "episode 3, val func loss 0.6197019219398499\n",
      "\n",
      "episode 4, val func loss 0.5852063894271851\n",
      "\n",
      "episode 5, val func loss 0.5751005411148071\n",
      "\n",
      "episode 6, val func loss 0.5879533886909485\n",
      "\n",
      "episode 7, val func loss 0.6396735310554504\n",
      "\n",
      "episode 8, val func loss 0.6749480366706848\n",
      "\n",
      "episode 9, val func loss 0.5378621220588684\n",
      "\n",
      "episode 10, val func loss 0.6486479640007019\n",
      "\n",
      "episode 11, val func loss 0.5747685432434082\n",
      "\n",
      "episode 12, val func loss 0.5728273987770081\n",
      "\n",
      "episode 13, val func loss 0.575396716594696\n",
      "\n",
      "episode 14, val func loss 0.5525014996528625\n",
      "\n",
      "episode 15, val func loss 0.6342116594314575\n",
      "\n",
      "episode 16, val func loss 0.6430339813232422\n",
      "\n",
      "Val func train loss in epoch 5:0.6054441779851913\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.49252697825431824\n",
      "\n",
      "episode 2, val func loss 0.6536415219306946\n",
      "\n",
      "episode 3, val func loss 0.6797320246696472\n",
      "\n",
      "episode 4, val func loss 0.5561589598655701\n",
      "\n",
      "episode 5, val func loss 0.7212851047515869\n",
      "\n",
      "episode 6, val func loss 0.6609137058258057\n",
      "\n",
      "episode 7, val func loss 0.6991981267929077\n",
      "\n",
      "episode 8, val func loss 0.5566980838775635\n",
      "\n",
      "episode 9, val func loss 0.8123847246170044\n",
      "\n",
      "episode 10, val func loss 0.5771253705024719\n",
      "\n",
      "episode 11, val func loss 0.5835970044136047\n",
      "\n",
      "episode 12, val func loss 0.5978993773460388\n",
      "\n",
      "episode 13, val func loss 0.6764495968818665\n",
      "\n",
      "episode 14, val func loss 0.6868570446968079\n",
      "\n",
      "episode 15, val func loss 0.5626798272132874\n",
      "\n",
      "episode 16, val func loss 0.7170167565345764\n",
      "\n",
      "Val func train loss in epoch 6:0.6396352630108595\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6261346936225891\n",
      "\n",
      "episode 2, val func loss 0.7302703261375427\n",
      "\n",
      "episode 3, val func loss 0.6430040597915649\n",
      "\n",
      "episode 4, val func loss 0.6965634822845459\n",
      "\n",
      "episode 5, val func loss 0.6003732681274414\n",
      "\n",
      "episode 6, val func loss 0.6201124787330627\n",
      "\n",
      "episode 7, val func loss 0.585602343082428\n",
      "\n",
      "episode 8, val func loss 0.5749820470809937\n",
      "\n",
      "episode 9, val func loss 0.6745323538780212\n",
      "\n",
      "episode 10, val func loss 0.5759336352348328\n",
      "\n",
      "episode 11, val func loss 0.6115060448646545\n",
      "\n",
      "episode 12, val func loss 0.695713222026825\n",
      "\n",
      "episode 13, val func loss 0.5526536703109741\n",
      "\n",
      "episode 14, val func loss 0.6021018624305725\n",
      "\n",
      "episode 15, val func loss 0.7096685171127319\n",
      "\n",
      "episode 16, val func loss 0.6161013245582581\n",
      "\n",
      "Val func train loss in epoch 7:0.6322033330798149\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6115862727165222\n",
      "\n",
      "episode 2, val func loss 0.6036801934242249\n",
      "\n",
      "episode 3, val func loss 0.6693703532218933\n",
      "\n",
      "episode 4, val func loss 0.6254498362541199\n",
      "\n",
      "episode 5, val func loss 0.7311572432518005\n",
      "\n",
      "episode 6, val func loss 0.6453726291656494\n",
      "\n",
      "episode 7, val func loss 0.6167065501213074\n",
      "\n",
      "episode 8, val func loss 0.6957669854164124\n",
      "\n",
      "episode 9, val func loss 0.6172440648078918\n",
      "\n",
      "episode 10, val func loss 0.5605171918869019\n",
      "\n",
      "episode 11, val func loss 0.6473117470741272\n",
      "\n",
      "episode 12, val func loss 0.7154051065444946\n",
      "\n",
      "episode 13, val func loss 0.6038888692855835\n",
      "\n",
      "episode 14, val func loss 0.5657608509063721\n",
      "\n",
      "episode 15, val func loss 0.5905454754829407\n",
      "\n",
      "episode 16, val func loss 0.7788997292518616\n",
      "\n",
      "Val func train loss in epoch 8:0.6424164436757565\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.6231443285942078\n",
      "\n",
      "episode 2, val func loss 0.6010242104530334\n",
      "\n",
      "episode 3, val func loss 0.632291316986084\n",
      "\n",
      "episode 4, val func loss 0.7079917192459106\n",
      "\n",
      "episode 5, val func loss 0.5956423282623291\n",
      "\n",
      "episode 6, val func loss 0.5304569005966187\n",
      "\n",
      "episode 7, val func loss 0.656484067440033\n",
      "\n",
      "episode 8, val func loss 0.589682936668396\n",
      "\n",
      "episode 9, val func loss 0.6729999780654907\n",
      "\n",
      "episode 10, val func loss 0.5493250489234924\n",
      "\n",
      "episode 11, val func loss 0.6044175624847412\n",
      "\n",
      "episode 12, val func loss 0.65175861120224\n",
      "\n",
      "episode 13, val func loss 0.6356489658355713\n",
      "\n",
      "episode 14, val func loss 0.5186547040939331\n",
      "\n",
      "episode 15, val func loss 0.577217161655426\n",
      "\n",
      "episode 16, val func loss 0.5071665644645691\n",
      "\n",
      "Val func train loss in epoch 9:0.6033691503107548\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.553904116153717\n",
      "\n",
      "episode 2, val func loss 0.5490024089813232\n",
      "\n",
      "episode 3, val func loss 0.6526832580566406\n",
      "\n",
      "episode 4, val func loss 0.6798281669616699\n",
      "\n",
      "episode 5, val func loss 0.5636711120605469\n",
      "\n",
      "episode 6, val func loss 0.6080975532531738\n",
      "\n",
      "episode 7, val func loss 0.6368392705917358\n",
      "\n",
      "episode 8, val func loss 0.5571748614311218\n",
      "\n",
      "episode 9, val func loss 0.545993983745575\n",
      "\n",
      "episode 10, val func loss 0.635161817073822\n",
      "\n",
      "episode 11, val func loss 0.5699540972709656\n",
      "\n",
      "episode 12, val func loss 0.5781485438346863\n",
      "\n",
      "episode 13, val func loss 0.5592188835144043\n",
      "\n",
      "episode 14, val func loss 0.6283226609230042\n",
      "\n",
      "episode 15, val func loss 0.5097833275794983\n",
      "\n",
      "episode 16, val func loss 0.5561206936836243\n",
      "\n",
      "Val func train loss in epoch 10:0.5864940471947193\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6050164699554443\n",
      "\n",
      "episode 2, val func loss 0.5961031317710876\n",
      "\n",
      "episode 3, val func loss 0.6772078275680542\n",
      "\n",
      "episode 4, val func loss 0.619629979133606\n",
      "\n",
      "episode 5, val func loss 0.7988340854644775\n",
      "\n",
      "episode 6, val func loss 0.648791491985321\n",
      "\n",
      "episode 7, val func loss 0.6405180096626282\n",
      "\n",
      "episode 8, val func loss 0.5343989729881287\n",
      "\n",
      "episode 9, val func loss 0.6371490359306335\n",
      "\n",
      "episode 10, val func loss 0.5553690791130066\n",
      "\n",
      "episode 11, val func loss 0.5925273895263672\n",
      "\n",
      "episode 12, val func loss 0.6634012460708618\n",
      "\n",
      "episode 13, val func loss 0.6682780981063843\n",
      "\n",
      "episode 14, val func loss 0.6150544285774231\n",
      "\n",
      "episode 15, val func loss 0.5469552278518677\n",
      "\n",
      "episode 16, val func loss 0.5717815160751343\n",
      "\n",
      "Val func train loss in epoch 11:0.6231884993612766\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6382662057876587\n",
      "\n",
      "episode 2, val func loss 0.5619474053382874\n",
      "\n",
      "episode 3, val func loss 0.49837201833724976\n",
      "\n",
      "episode 4, val func loss 0.5582097768783569\n",
      "\n",
      "episode 5, val func loss 0.5270503759384155\n",
      "\n",
      "episode 6, val func loss 0.6084862947463989\n",
      "\n",
      "episode 7, val func loss 0.5033970475196838\n",
      "\n",
      "episode 8, val func loss 0.6002667546272278\n",
      "\n",
      "episode 9, val func loss 0.5666123628616333\n",
      "\n",
      "episode 10, val func loss 0.5535513758659363\n",
      "\n",
      "episode 11, val func loss 0.5984959602355957\n",
      "\n",
      "episode 12, val func loss 0.5166096687316895\n",
      "\n",
      "episode 13, val func loss 0.6267795562744141\n",
      "\n",
      "episode 14, val func loss 0.6425611972808838\n",
      "\n",
      "episode 15, val func loss 0.5874277353286743\n",
      "\n",
      "episode 16, val func loss 0.7401703596115112\n",
      "\n",
      "Val func train loss in epoch 12:0.5830127559602261\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.7118661999702454\n",
      "\n",
      "episode 2, val func loss 0.6622050404548645\n",
      "\n",
      "episode 3, val func loss 0.6600946187973022\n",
      "\n",
      "episode 4, val func loss 0.6163929104804993\n",
      "\n",
      "episode 5, val func loss 0.6106744408607483\n",
      "\n",
      "episode 6, val func loss 0.5802401900291443\n",
      "\n",
      "episode 7, val func loss 0.5836618542671204\n",
      "\n",
      "episode 8, val func loss 0.6778544187545776\n",
      "\n",
      "episode 9, val func loss 0.5848391056060791\n",
      "\n",
      "episode 10, val func loss 0.5244680047035217\n",
      "\n",
      "episode 11, val func loss 0.672760546207428\n",
      "\n",
      "episode 12, val func loss 0.5931425094604492\n",
      "\n",
      "episode 13, val func loss 0.6553652286529541\n",
      "\n",
      "episode 14, val func loss 0.6667268872261047\n",
      "\n",
      "episode 15, val func loss 0.627763569355011\n",
      "\n",
      "episode 16, val func loss 0.5449070334434509\n",
      "\n",
      "Val func train loss in epoch 13:0.6233101598918438\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6392165422439575\n",
      "\n",
      "episode 2, val func loss 0.6519783735275269\n",
      "\n",
      "episode 3, val func loss 0.73421710729599\n",
      "\n",
      "episode 4, val func loss 0.62241131067276\n",
      "\n",
      "episode 5, val func loss 0.6173986196517944\n",
      "\n",
      "episode 6, val func loss 0.5850764513015747\n",
      "\n",
      "episode 7, val func loss 0.6619332432746887\n",
      "\n",
      "episode 8, val func loss 0.5810371041297913\n",
      "\n",
      "episode 9, val func loss 0.6708041429519653\n",
      "\n",
      "episode 10, val func loss 0.5941990613937378\n",
      "\n",
      "episode 11, val func loss 0.6046218276023865\n",
      "\n",
      "episode 12, val func loss 0.5574771165847778\n",
      "\n",
      "episode 13, val func loss 0.7012519240379333\n",
      "\n",
      "episode 14, val func loss 0.6069713234901428\n",
      "\n",
      "episode 15, val func loss 0.5990829467773438\n",
      "\n",
      "episode 16, val func loss 0.6048570275306702\n",
      "\n",
      "Val func train loss in epoch 14:0.6270333826541901\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6127043962478638\n",
      "\n",
      "episode 2, val func loss 0.6316371560096741\n",
      "\n",
      "episode 3, val func loss 0.5448428392410278\n",
      "\n",
      "episode 4, val func loss 0.6732797026634216\n",
      "\n",
      "episode 5, val func loss 0.6551151275634766\n",
      "\n",
      "episode 6, val func loss 0.5177723169326782\n",
      "\n",
      "episode 7, val func loss 0.6113920211791992\n",
      "\n",
      "episode 8, val func loss 0.6684925556182861\n",
      "\n",
      "episode 9, val func loss 0.6234270930290222\n",
      "\n",
      "episode 10, val func loss 0.700236439704895\n",
      "\n",
      "episode 11, val func loss 0.6506507992744446\n",
      "\n",
      "episode 12, val func loss 0.6188540458679199\n",
      "\n",
      "episode 13, val func loss 0.6114222407341003\n",
      "\n",
      "episode 14, val func loss 0.6991235613822937\n",
      "\n",
      "episode 15, val func loss 0.598593533039093\n",
      "\n",
      "episode 16, val func loss 0.5260768532752991\n",
      "\n",
      "Val func train loss in epoch 15:0.6214762926101685\n",
      "***********************TIME WAS 4.933456889788309 min*****************************\n",
      "\n",
      "**********************ROUND 140 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.3360404968261719\n",
      "\n",
      "episode 2, policy loss 1.3358370065689087\n",
      "\n",
      "episode 3, policy loss 1.3355278968811035\n",
      "\n",
      "episode 4, policy loss 1.3348287343978882\n",
      "\n",
      "episode 5, policy loss 1.334043264389038\n",
      "\n",
      "episode 6, policy loss 1.3321645259857178\n",
      "\n",
      "episode 7, policy loss 1.487810492515564\n",
      "\n",
      "episode 8, policy loss 1.4135611057281494\n",
      "\n",
      "episode 9, policy loss 1.3321056365966797\n",
      "\n",
      "episode 10, policy loss 1.3326867818832397\n",
      "\n",
      "episode 11, policy loss 1.3329356908798218\n",
      "\n",
      "episode 12, policy loss 1.55113685131073\n",
      "\n",
      "episode 13, policy loss 1.3348089456558228\n",
      "\n",
      "episode 14, policy loss 1.3359310626983643\n",
      "\n",
      "episode 15, policy loss 1.3365265130996704\n",
      "\n",
      "episode 16, policy loss 1.3368796110153198\n",
      "\n",
      "Policy train loss in epoch 0:1.3626765385270119\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.3370722532272339\n",
      "\n",
      "episode 2, policy loss 1.3371890783309937\n",
      "\n",
      "episode 3, policy loss 1.3372670412063599\n",
      "\n",
      "episode 4, policy loss 1.337294340133667\n",
      "\n",
      "episode 5, policy loss 1.3373392820358276\n",
      "\n",
      "episode 6, policy loss 1.3373712301254272\n",
      "\n",
      "episode 7, policy loss 1.3634155988693237\n",
      "\n",
      "episode 8, policy loss 1.3619306087493896\n",
      "\n",
      "episode 9, policy loss 1.3632452487945557\n",
      "\n",
      "episode 10, policy loss 1.337432622909546\n",
      "\n",
      "episode 11, policy loss 1.3374390602111816\n",
      "\n",
      "episode 12, policy loss 1.3374475240707397\n",
      "\n",
      "episode 13, policy loss 1.3374569416046143\n",
      "\n",
      "episode 14, policy loss 1.3374556303024292\n",
      "\n",
      "episode 15, policy loss 1.3374661207199097\n",
      "\n",
      "episode 16, policy loss 1.3374663591384888\n",
      "\n",
      "Policy train loss in epoch 1:1.3421430587768555\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.337468147277832\n",
      "\n",
      "episode 2, policy loss 1.3374695777893066\n",
      "\n",
      "episode 3, policy loss 1.3374741077423096\n",
      "\n",
      "episode 4, policy loss 1.3619961738586426\n",
      "\n",
      "episode 5, policy loss 1.3634860515594482\n",
      "\n",
      "episode 6, policy loss 1.337475299835205\n",
      "\n",
      "episode 7, policy loss 1.33747398853302\n",
      "\n",
      "episode 8, policy loss 1.3374745845794678\n",
      "\n",
      "episode 9, policy loss 1.3374760150909424\n",
      "\n",
      "episode 10, policy loss 1.3374756574630737\n",
      "\n",
      "episode 11, policy loss 1.3374775648117065\n",
      "\n",
      "episode 12, policy loss 1.3374714851379395\n",
      "\n",
      "episode 13, policy loss 1.3374758958816528\n",
      "\n",
      "episode 14, policy loss 1.363302230834961\n",
      "\n",
      "episode 15, policy loss 1.3374775648117065\n",
      "\n",
      "episode 16, policy loss 1.3374725580215454\n",
      "\n",
      "Policy train loss in epoch 2:1.3422466814517975\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.337471842765808\n",
      "\n",
      "episode 2, policy loss 1.3374704122543335\n",
      "\n",
      "episode 3, policy loss 1.3374717235565186\n",
      "\n",
      "episode 4, policy loss 1.3374756574630737\n",
      "\n",
      "episode 5, policy loss 1.3374699354171753\n",
      "\n",
      "episode 6, policy loss 1.3632982969284058\n",
      "\n",
      "episode 7, policy loss 1.363485336303711\n",
      "\n",
      "episode 8, policy loss 1.3374621868133545\n",
      "\n",
      "episode 9, policy loss 1.3374645709991455\n",
      "\n",
      "episode 10, policy loss 1.3374677896499634\n",
      "\n",
      "episode 11, policy loss 1.3374634981155396\n",
      "\n",
      "episode 12, policy loss 1.3619829416275024\n",
      "\n",
      "episode 13, policy loss 1.3374580144882202\n",
      "\n",
      "episode 14, policy loss 1.337458848953247\n",
      "\n",
      "episode 15, policy loss 1.3374526500701904\n",
      "\n",
      "episode 16, policy loss 1.3374520540237427\n",
      "\n",
      "Policy train loss in epoch 3:1.3422378599643707\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.5675801634788513\n",
      "\n",
      "episode 2, val func loss 0.8405174612998962\n",
      "\n",
      "episode 3, val func loss 0.7613406777381897\n",
      "\n",
      "episode 4, val func loss 0.750290036201477\n",
      "\n",
      "episode 5, val func loss 0.6162377595901489\n",
      "\n",
      "episode 6, val func loss 0.604305624961853\n",
      "\n",
      "episode 7, val func loss 0.681620717048645\n",
      "\n",
      "episode 8, val func loss 0.7238197326660156\n",
      "\n",
      "episode 9, val func loss 0.5999417901039124\n",
      "\n",
      "episode 10, val func loss 0.7336618304252625\n",
      "\n",
      "episode 11, val func loss 0.7641482353210449\n",
      "\n",
      "episode 12, val func loss 0.6283257007598877\n",
      "\n",
      "episode 13, val func loss 0.7016459703445435\n",
      "\n",
      "episode 14, val func loss 0.5888788104057312\n",
      "\n",
      "episode 15, val func loss 0.6331168413162231\n",
      "\n",
      "episode 16, val func loss 0.6413602828979492\n",
      "\n",
      "Val func train loss in epoch 0:0.677299477159977\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.5539582371711731\n",
      "\n",
      "episode 2, val func loss 0.6718591451644897\n",
      "\n",
      "episode 3, val func loss 0.5735242962837219\n",
      "\n",
      "episode 4, val func loss 0.727546215057373\n",
      "\n",
      "episode 5, val func loss 0.6298993825912476\n",
      "\n",
      "episode 6, val func loss 0.5941154956817627\n",
      "\n",
      "episode 7, val func loss 0.6310033798217773\n",
      "\n",
      "episode 8, val func loss 0.5700032114982605\n",
      "\n",
      "episode 9, val func loss 0.644241988658905\n",
      "\n",
      "episode 10, val func loss 0.7560088038444519\n",
      "\n",
      "episode 11, val func loss 0.6217362284660339\n",
      "\n",
      "episode 12, val func loss 0.6622559428215027\n",
      "\n",
      "episode 13, val func loss 0.5411335229873657\n",
      "\n",
      "episode 14, val func loss 0.7347509860992432\n",
      "\n",
      "episode 15, val func loss 0.6009076833724976\n",
      "\n",
      "episode 16, val func loss 0.6516092419624329\n",
      "\n",
      "Val func train loss in epoch 1:0.6352846100926399\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6425676941871643\n",
      "\n",
      "episode 2, val func loss 0.6058561205863953\n",
      "\n",
      "episode 3, val func loss 0.6352307796478271\n",
      "\n",
      "episode 4, val func loss 0.6056622266769409\n",
      "\n",
      "episode 5, val func loss 0.8293849229812622\n",
      "\n",
      "episode 6, val func loss 0.6546911001205444\n",
      "\n",
      "episode 7, val func loss 0.5304770469665527\n",
      "\n",
      "episode 8, val func loss 0.608546793460846\n",
      "\n",
      "episode 9, val func loss 0.5411027669906616\n",
      "\n",
      "episode 10, val func loss 0.644493043422699\n",
      "\n",
      "episode 11, val func loss 0.5490307211875916\n",
      "\n",
      "episode 12, val func loss 0.5816760063171387\n",
      "\n",
      "episode 13, val func loss 0.6781312823295593\n",
      "\n",
      "episode 14, val func loss 0.5926049947738647\n",
      "\n",
      "episode 15, val func loss 0.6137555837631226\n",
      "\n",
      "episode 16, val func loss 0.682474672794342\n",
      "\n",
      "Val func train loss in epoch 2:0.624730359762907\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.5176751613616943\n",
      "\n",
      "episode 2, val func loss 0.5235565304756165\n",
      "\n",
      "episode 3, val func loss 0.6574492454528809\n",
      "\n",
      "episode 4, val func loss 0.5531955361366272\n",
      "\n",
      "episode 5, val func loss 0.6210426092147827\n",
      "\n",
      "episode 6, val func loss 0.6113036870956421\n",
      "\n",
      "episode 7, val func loss 0.660605788230896\n",
      "\n",
      "episode 8, val func loss 0.6185512542724609\n",
      "\n",
      "episode 9, val func loss 0.7162149548530579\n",
      "\n",
      "episode 10, val func loss 0.6220086216926575\n",
      "\n",
      "episode 11, val func loss 0.7113702297210693\n",
      "\n",
      "episode 12, val func loss 0.6081176400184631\n",
      "\n",
      "episode 13, val func loss 0.6091605424880981\n",
      "\n",
      "episode 14, val func loss 0.6506531238555908\n",
      "\n",
      "episode 15, val func loss 0.7489528656005859\n",
      "\n",
      "episode 16, val func loss 0.6392724514007568\n",
      "\n",
      "Val func train loss in epoch 3:0.62932064011693\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7638662457466125\n",
      "\n",
      "episode 2, val func loss 0.5883303880691528\n",
      "\n",
      "episode 3, val func loss 0.5822870135307312\n",
      "\n",
      "episode 4, val func loss 0.6265764236450195\n",
      "\n",
      "episode 5, val func loss 0.7720445990562439\n",
      "\n",
      "episode 6, val func loss 0.4792700707912445\n",
      "\n",
      "episode 7, val func loss 0.6120694279670715\n",
      "\n",
      "episode 8, val func loss 0.6185457706451416\n",
      "\n",
      "episode 9, val func loss 0.51218181848526\n",
      "\n",
      "episode 10, val func loss 0.5975002646446228\n",
      "\n",
      "episode 11, val func loss 0.732631266117096\n",
      "\n",
      "episode 12, val func loss 0.6418900489807129\n",
      "\n",
      "episode 13, val func loss 0.6575971841812134\n",
      "\n",
      "episode 14, val func loss 0.5986230969429016\n",
      "\n",
      "episode 15, val func loss 0.5669268369674683\n",
      "\n",
      "episode 16, val func loss 0.6453946828842163\n",
      "\n",
      "Val func train loss in epoch 4:0.6247334461659193\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6394035816192627\n",
      "\n",
      "episode 2, val func loss 0.6868497133255005\n",
      "\n",
      "episode 3, val func loss 0.6215904355049133\n",
      "\n",
      "episode 4, val func loss 0.6191534399986267\n",
      "\n",
      "episode 5, val func loss 0.528172492980957\n",
      "\n",
      "episode 6, val func loss 0.563995361328125\n",
      "\n",
      "episode 7, val func loss 0.6830784678459167\n",
      "\n",
      "episode 8, val func loss 0.6704774498939514\n",
      "\n",
      "episode 9, val func loss 0.6301883459091187\n",
      "\n",
      "episode 10, val func loss 0.5384357571601868\n",
      "\n",
      "episode 11, val func loss 0.605977475643158\n",
      "\n",
      "episode 12, val func loss 0.6526924967765808\n",
      "\n",
      "episode 13, val func loss 0.6697142720222473\n",
      "\n",
      "episode 14, val func loss 0.8378425240516663\n",
      "\n",
      "episode 15, val func loss 0.922971248626709\n",
      "\n",
      "episode 16, val func loss 0.6453197598457336\n",
      "\n",
      "Val func train loss in epoch 5:0.6572414264082909\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6648571491241455\n",
      "\n",
      "episode 2, val func loss 0.8640238046646118\n",
      "\n",
      "episode 3, val func loss 0.6088594198226929\n",
      "\n",
      "episode 4, val func loss 0.7850939035415649\n",
      "\n",
      "episode 5, val func loss 0.825175940990448\n",
      "\n",
      "episode 6, val func loss 0.6737266778945923\n",
      "\n",
      "episode 7, val func loss 0.7984256744384766\n",
      "\n",
      "episode 8, val func loss 0.9763927459716797\n",
      "\n",
      "episode 9, val func loss 0.8114538192749023\n",
      "\n",
      "episode 10, val func loss 0.7107102870941162\n",
      "\n",
      "episode 11, val func loss 0.709844708442688\n",
      "\n",
      "episode 12, val func loss 0.6849867701530457\n",
      "\n",
      "episode 13, val func loss 0.5676944851875305\n",
      "\n",
      "episode 14, val func loss 0.6372572779655457\n",
      "\n",
      "episode 15, val func loss 0.8131559491157532\n",
      "\n",
      "episode 16, val func loss 0.7192987203598022\n",
      "\n",
      "Val func train loss in epoch 6:0.7406848333775997\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7631383538246155\n",
      "\n",
      "episode 2, val func loss 0.5904133915901184\n",
      "\n",
      "episode 3, val func loss 0.544551432132721\n",
      "\n",
      "episode 4, val func loss 0.7054319381713867\n",
      "\n",
      "episode 5, val func loss 0.7032865285873413\n",
      "\n",
      "episode 6, val func loss 0.6574673652648926\n",
      "\n",
      "episode 7, val func loss 0.7038912773132324\n",
      "\n",
      "episode 8, val func loss 0.7250380516052246\n",
      "\n",
      "episode 9, val func loss 0.7325302958488464\n",
      "\n",
      "episode 10, val func loss 0.6484284996986389\n",
      "\n",
      "episode 11, val func loss 0.7657541632652283\n",
      "\n",
      "episode 12, val func loss 0.6188033819198608\n",
      "\n",
      "episode 13, val func loss 0.8114127516746521\n",
      "\n",
      "episode 14, val func loss 0.6685961484909058\n",
      "\n",
      "episode 15, val func loss 0.6356431841850281\n",
      "\n",
      "episode 16, val func loss 0.5767722725868225\n",
      "\n",
      "Val func train loss in epoch 7:0.6781974397599697\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6103305816650391\n",
      "\n",
      "episode 2, val func loss 0.5779402852058411\n",
      "\n",
      "episode 3, val func loss 0.5947837233543396\n",
      "\n",
      "episode 4, val func loss 0.6390106678009033\n",
      "\n",
      "episode 5, val func loss 0.7320278286933899\n",
      "\n",
      "episode 6, val func loss 0.6105901002883911\n",
      "\n",
      "episode 7, val func loss 0.6536533236503601\n",
      "\n",
      "episode 8, val func loss 0.5024799108505249\n",
      "\n",
      "episode 9, val func loss 0.5259618759155273\n",
      "\n",
      "episode 10, val func loss 0.6478703618049622\n",
      "\n",
      "episode 11, val func loss 0.6250512003898621\n",
      "\n",
      "episode 12, val func loss 0.594965398311615\n",
      "\n",
      "episode 13, val func loss 0.6731851100921631\n",
      "\n",
      "episode 14, val func loss 0.6160279512405396\n",
      "\n",
      "episode 15, val func loss 0.6068720817565918\n",
      "\n",
      "episode 16, val func loss 0.6708461046218872\n",
      "\n",
      "Val func train loss in epoch 8:0.6175997816026211\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.665360152721405\n",
      "\n",
      "episode 2, val func loss 0.5922126173973083\n",
      "\n",
      "episode 3, val func loss 0.6855950355529785\n",
      "\n",
      "episode 4, val func loss 0.5904317498207092\n",
      "\n",
      "episode 5, val func loss 0.6614477634429932\n",
      "\n",
      "episode 6, val func loss 0.6574471592903137\n",
      "\n",
      "episode 7, val func loss 0.6272069811820984\n",
      "\n",
      "episode 8, val func loss 0.7499475479125977\n",
      "\n",
      "episode 9, val func loss 0.5328810811042786\n",
      "\n",
      "episode 10, val func loss 0.8159576058387756\n",
      "\n",
      "episode 11, val func loss 0.5830804109573364\n",
      "\n",
      "episode 12, val func loss 0.5995816588401794\n",
      "\n",
      "episode 13, val func loss 0.7008549571037292\n",
      "\n",
      "episode 14, val func loss 0.6818223595619202\n",
      "\n",
      "episode 15, val func loss 0.6464699506759644\n",
      "\n",
      "episode 16, val func loss 0.6236949563026428\n",
      "\n",
      "Val func train loss in epoch 9:0.6508744992315769\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6905801296234131\n",
      "\n",
      "episode 2, val func loss 0.8586645126342773\n",
      "\n",
      "episode 3, val func loss 0.6952268481254578\n",
      "\n",
      "episode 4, val func loss 0.6581298112869263\n",
      "\n",
      "episode 5, val func loss 0.6474788784980774\n",
      "\n",
      "episode 6, val func loss 0.5709702968597412\n",
      "\n",
      "episode 7, val func loss 0.6993975639343262\n",
      "\n",
      "episode 8, val func loss 0.5835770964622498\n",
      "\n",
      "episode 9, val func loss 0.7065646052360535\n",
      "\n",
      "episode 10, val func loss 0.6995800733566284\n",
      "\n",
      "episode 11, val func loss 0.5582423806190491\n",
      "\n",
      "episode 12, val func loss 0.6017237305641174\n",
      "\n",
      "episode 13, val func loss 0.5637749433517456\n",
      "\n",
      "episode 14, val func loss 0.7245224714279175\n",
      "\n",
      "episode 15, val func loss 0.5109425187110901\n",
      "\n",
      "episode 16, val func loss 0.572209894657135\n",
      "\n",
      "Val func train loss in epoch 10:0.6463491097092628\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.5597926378250122\n",
      "\n",
      "episode 2, val func loss 0.6165658235549927\n",
      "\n",
      "episode 3, val func loss 0.6117803454399109\n",
      "\n",
      "episode 4, val func loss 0.584602952003479\n",
      "\n",
      "episode 5, val func loss 0.7027795314788818\n",
      "\n",
      "episode 6, val func loss 0.504767656326294\n",
      "\n",
      "episode 7, val func loss 0.5804747343063354\n",
      "\n",
      "episode 8, val func loss 0.7009698748588562\n",
      "\n",
      "episode 9, val func loss 0.6395398378372192\n",
      "\n",
      "episode 10, val func loss 0.6041858792304993\n",
      "\n",
      "episode 11, val func loss 0.7685481309890747\n",
      "\n",
      "episode 12, val func loss 0.6119851469993591\n",
      "\n",
      "episode 13, val func loss 0.5427656769752502\n",
      "\n",
      "episode 14, val func loss 0.6638990640640259\n",
      "\n",
      "episode 15, val func loss 0.5851359963417053\n",
      "\n",
      "episode 16, val func loss 0.66202712059021\n",
      "\n",
      "Val func train loss in epoch 11:0.6212387755513191\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6531326770782471\n",
      "\n",
      "episode 2, val func loss 0.585311233997345\n",
      "\n",
      "episode 3, val func loss 0.7396348714828491\n",
      "\n",
      "episode 4, val func loss 0.628441333770752\n",
      "\n",
      "episode 5, val func loss 0.6236264109611511\n",
      "\n",
      "episode 6, val func loss 0.5456382632255554\n",
      "\n",
      "episode 7, val func loss 0.6015123128890991\n",
      "\n",
      "episode 8, val func loss 0.6861920952796936\n",
      "\n",
      "episode 9, val func loss 0.6958332061767578\n",
      "\n",
      "episode 10, val func loss 0.6282334923744202\n",
      "\n",
      "episode 11, val func loss 0.7737241387367249\n",
      "\n",
      "episode 12, val func loss 0.7697534561157227\n",
      "\n",
      "episode 13, val func loss 0.6720110774040222\n",
      "\n",
      "episode 14, val func loss 0.62827068567276\n",
      "\n",
      "episode 15, val func loss 0.5867703557014465\n",
      "\n",
      "episode 16, val func loss 0.6698282361030579\n",
      "\n",
      "Val func train loss in epoch 12:0.6554946154356003\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.5890638828277588\n",
      "\n",
      "episode 2, val func loss 0.7183061242103577\n",
      "\n",
      "episode 3, val func loss 0.5238122344017029\n",
      "\n",
      "episode 4, val func loss 0.6022614240646362\n",
      "\n",
      "episode 5, val func loss 0.5115855932235718\n",
      "\n",
      "episode 6, val func loss 0.6380331516265869\n",
      "\n",
      "episode 7, val func loss 0.5853152871131897\n",
      "\n",
      "episode 8, val func loss 0.5952383875846863\n",
      "\n",
      "episode 9, val func loss 0.7789753079414368\n",
      "\n",
      "episode 10, val func loss 0.5880497097969055\n",
      "\n",
      "episode 11, val func loss 0.5996167063713074\n",
      "\n",
      "episode 12, val func loss 0.6067671775817871\n",
      "\n",
      "episode 13, val func loss 0.6140870451927185\n",
      "\n",
      "episode 14, val func loss 0.5679511427879333\n",
      "\n",
      "episode 15, val func loss 0.6002646684646606\n",
      "\n",
      "episode 16, val func loss 0.7180028557777405\n",
      "\n",
      "Val func train loss in epoch 13:0.6148331686854362\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6589815020561218\n",
      "\n",
      "episode 2, val func loss 0.7940811514854431\n",
      "\n",
      "episode 3, val func loss 0.7210885882377625\n",
      "\n",
      "episode 4, val func loss 0.6764003038406372\n",
      "\n",
      "episode 5, val func loss 0.6491773724555969\n",
      "\n",
      "episode 6, val func loss 0.5981987118721008\n",
      "\n",
      "episode 7, val func loss 0.5866380333900452\n",
      "\n",
      "episode 8, val func loss 0.5410292148590088\n",
      "\n",
      "episode 9, val func loss 0.8201518654823303\n",
      "\n",
      "episode 10, val func loss 0.5376694202423096\n",
      "\n",
      "episode 11, val func loss 0.7567341327667236\n",
      "\n",
      "episode 12, val func loss 0.7285383343696594\n",
      "\n",
      "episode 13, val func loss 0.5676512122154236\n",
      "\n",
      "episode 14, val func loss 0.5346408486366272\n",
      "\n",
      "episode 15, val func loss 0.6146445870399475\n",
      "\n",
      "episode 16, val func loss 0.6625297665596008\n",
      "\n",
      "Val func train loss in epoch 14:0.6530096903443336\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6853381395339966\n",
      "\n",
      "episode 2, val func loss 0.560974657535553\n",
      "\n",
      "episode 3, val func loss 0.667410671710968\n",
      "\n",
      "episode 4, val func loss 0.614308774471283\n",
      "\n",
      "episode 5, val func loss 0.7954537868499756\n",
      "\n",
      "episode 6, val func loss 0.6856558322906494\n",
      "\n",
      "episode 7, val func loss 0.7652605175971985\n",
      "\n",
      "episode 8, val func loss 0.603324294090271\n",
      "\n",
      "episode 9, val func loss 0.5534060597419739\n",
      "\n",
      "episode 10, val func loss 0.6109103560447693\n",
      "\n",
      "episode 11, val func loss 0.5622134804725647\n",
      "\n",
      "episode 12, val func loss 0.5864656567573547\n",
      "\n",
      "episode 13, val func loss 0.6556355953216553\n",
      "\n",
      "episode 14, val func loss 0.5978681445121765\n",
      "\n",
      "episode 15, val func loss 0.6297447085380554\n",
      "\n",
      "episode 16, val func loss 0.7072376608848572\n",
      "\n",
      "Val func train loss in epoch 15:0.6425755210220814\n",
      "***********************TIME WAS 4.929863921801249 min*****************************\n",
      "\n",
      "**********************ROUND 141 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.5776780843734741\n",
      "\n",
      "episode 2, policy loss 1.5776671171188354\n",
      "\n",
      "episode 3, policy loss 1.5776658058166504\n",
      "\n",
      "episode 4, policy loss 1.577669620513916\n",
      "\n",
      "episode 5, policy loss 1.577666997909546\n",
      "\n",
      "episode 6, policy loss 1.5776623487472534\n",
      "\n",
      "episode 7, policy loss 1.5776455402374268\n",
      "\n",
      "episode 8, policy loss 1.5776532888412476\n",
      "\n",
      "episode 9, policy loss 1.5776342153549194\n",
      "\n",
      "episode 10, policy loss 1.5776398181915283\n",
      "\n",
      "episode 11, policy loss 1.577631950378418\n",
      "\n",
      "episode 12, policy loss 1.577624797821045\n",
      "\n",
      "episode 13, policy loss 1.5776101350784302\n",
      "\n",
      "episode 14, policy loss 1.5775933265686035\n",
      "\n",
      "episode 15, policy loss 1.577578067779541\n",
      "\n",
      "episode 16, policy loss 1.5775837898254395\n",
      "\n",
      "Policy train loss in epoch 0:1.5776378065347672\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.5775582790374756\n",
      "\n",
      "episode 2, policy loss 1.5775450468063354\n",
      "\n",
      "episode 3, policy loss 1.5775192975997925\n",
      "\n",
      "episode 4, policy loss 1.577505111694336\n",
      "\n",
      "episode 5, policy loss 1.5774494409561157\n",
      "\n",
      "episode 6, policy loss 1.5774415731430054\n",
      "\n",
      "episode 7, policy loss 1.5773595571517944\n",
      "\n",
      "episode 8, policy loss 1.5773212909698486\n",
      "\n",
      "episode 9, policy loss 1.577247142791748\n",
      "\n",
      "episode 10, policy loss 1.5771589279174805\n",
      "\n",
      "episode 11, policy loss 1.5770163536071777\n",
      "\n",
      "episode 12, policy loss 1.5767583847045898\n",
      "\n",
      "episode 13, policy loss 1.5765776634216309\n",
      "\n",
      "episode 14, policy loss 1.5761170387268066\n",
      "\n",
      "episode 15, policy loss 1.575481653213501\n",
      "\n",
      "episode 16, policy loss 1.5739808082580566\n",
      "\n",
      "Policy train loss in epoch 1:1.576877348124981\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.5719740390777588\n",
      "\n",
      "episode 2, policy loss 1.566605567932129\n",
      "\n",
      "episode 3, policy loss 1.5536720752716064\n",
      "\n",
      "episode 4, policy loss 1.52155339717865\n",
      "\n",
      "episode 5, policy loss 1.4357978105545044\n",
      "\n",
      "episode 6, policy loss 1.482586145401001\n",
      "\n",
      "episode 7, policy loss 1.502785086631775\n",
      "\n",
      "episode 8, policy loss 1.4950542449951172\n",
      "\n",
      "episode 9, policy loss 1.4584332704544067\n",
      "\n",
      "episode 10, policy loss 1.433557152748108\n",
      "\n",
      "episode 11, policy loss 1.4775937795639038\n",
      "\n",
      "episode 12, policy loss 1.4793606996536255\n",
      "\n",
      "episode 13, policy loss 1.4461404085159302\n",
      "\n",
      "episode 14, policy loss 1.4345965385437012\n",
      "\n",
      "episode 15, policy loss 1.4524362087249756\n",
      "\n",
      "episode 16, policy loss 1.4578688144683838\n",
      "\n",
      "Policy train loss in epoch 2:1.4856259524822235\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.4586678743362427\n",
      "\n",
      "episode 2, policy loss 1.4479466676712036\n",
      "\n",
      "episode 3, policy loss 1.4298250675201416\n",
      "\n",
      "episode 4, policy loss 1.4368767738342285\n",
      "\n",
      "episode 5, policy loss 1.4535835981369019\n",
      "\n",
      "episode 6, policy loss 1.4397141933441162\n",
      "\n",
      "episode 7, policy loss 1.4307047128677368\n",
      "\n",
      "episode 8, policy loss 1.4364032745361328\n",
      "\n",
      "episode 9, policy loss 1.4396929740905762\n",
      "\n",
      "episode 10, policy loss 1.4412806034088135\n",
      "\n",
      "episode 11, policy loss 1.4340553283691406\n",
      "\n",
      "episode 12, policy loss 1.4306541681289673\n",
      "\n",
      "episode 13, policy loss 1.4419139623641968\n",
      "\n",
      "episode 14, policy loss 1.4376029968261719\n",
      "\n",
      "episode 15, policy loss 1.4287264347076416\n",
      "\n",
      "episode 16, policy loss 1.4331638813018799\n",
      "\n",
      "Policy train loss in epoch 3:1.4388007819652557\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.5363606214523315\n",
      "\n",
      "episode 2, val func loss 0.6369072794914246\n",
      "\n",
      "episode 3, val func loss 0.6216095089912415\n",
      "\n",
      "episode 4, val func loss 0.6738554835319519\n",
      "\n",
      "episode 5, val func loss 0.5217058658599854\n",
      "\n",
      "episode 6, val func loss 0.5636781454086304\n",
      "\n",
      "episode 7, val func loss 0.808681845664978\n",
      "\n",
      "episode 8, val func loss 0.5994179844856262\n",
      "\n",
      "episode 9, val func loss 0.6988310813903809\n",
      "\n",
      "episode 10, val func loss 0.6277313232421875\n",
      "\n",
      "episode 11, val func loss 0.6287288665771484\n",
      "\n",
      "episode 12, val func loss 0.5771986842155457\n",
      "\n",
      "episode 13, val func loss 0.6925371885299683\n",
      "\n",
      "episode 14, val func loss 0.7166624665260315\n",
      "\n",
      "episode 15, val func loss 0.5835322737693787\n",
      "\n",
      "episode 16, val func loss 0.5733428001403809\n",
      "\n",
      "Val func train loss in epoch 0:0.6287988387048244\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.6333518028259277\n",
      "\n",
      "episode 2, val func loss 0.5025521516799927\n",
      "\n",
      "episode 3, val func loss 0.6668796539306641\n",
      "\n",
      "episode 4, val func loss 0.5865304470062256\n",
      "\n",
      "episode 5, val func loss 0.6749877333641052\n",
      "\n",
      "episode 6, val func loss 0.7178376317024231\n",
      "\n",
      "episode 7, val func loss 0.5685165524482727\n",
      "\n",
      "episode 8, val func loss 0.6833201050758362\n",
      "\n",
      "episode 9, val func loss 0.525025486946106\n",
      "\n",
      "episode 10, val func loss 0.6262044906616211\n",
      "\n",
      "episode 11, val func loss 0.6796901822090149\n",
      "\n",
      "episode 12, val func loss 0.6653167009353638\n",
      "\n",
      "episode 13, val func loss 0.6787331700325012\n",
      "\n",
      "episode 14, val func loss 0.6523094177246094\n",
      "\n",
      "episode 15, val func loss 0.6413736343383789\n",
      "\n",
      "episode 16, val func loss 0.5552944540977478\n",
      "\n",
      "Val func train loss in epoch 1:0.6286202259361744\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.59469074010849\n",
      "\n",
      "episode 2, val func loss 0.6262798309326172\n",
      "\n",
      "episode 3, val func loss 0.5846546292304993\n",
      "\n",
      "episode 4, val func loss 0.5327548384666443\n",
      "\n",
      "episode 5, val func loss 0.5403558015823364\n",
      "\n",
      "episode 6, val func loss 0.6391352415084839\n",
      "\n",
      "episode 7, val func loss 0.5475730895996094\n",
      "\n",
      "episode 8, val func loss 0.48459485173225403\n",
      "\n",
      "episode 9, val func loss 0.6738160848617554\n",
      "\n",
      "episode 10, val func loss 0.6576040983200073\n",
      "\n",
      "episode 11, val func loss 0.6296818256378174\n",
      "\n",
      "episode 12, val func loss 0.6526179313659668\n",
      "\n",
      "episode 13, val func loss 0.6770417094230652\n",
      "\n",
      "episode 14, val func loss 0.5495392680168152\n",
      "\n",
      "episode 15, val func loss 0.6928533315658569\n",
      "\n",
      "episode 16, val func loss 0.5590221881866455\n",
      "\n",
      "Val func train loss in epoch 2:0.602638466283679\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.606517493724823\n",
      "\n",
      "episode 2, val func loss 0.6429471373558044\n",
      "\n",
      "episode 3, val func loss 0.6375623345375061\n",
      "\n",
      "episode 4, val func loss 0.5835055708885193\n",
      "\n",
      "episode 5, val func loss 0.5590441226959229\n",
      "\n",
      "episode 6, val func loss 0.5558714866638184\n",
      "\n",
      "episode 7, val func loss 0.6153295040130615\n",
      "\n",
      "episode 8, val func loss 0.6813021898269653\n",
      "\n",
      "episode 9, val func loss 0.6260292530059814\n",
      "\n",
      "episode 10, val func loss 0.7264739274978638\n",
      "\n",
      "episode 11, val func loss 0.6220796704292297\n",
      "\n",
      "episode 12, val func loss 0.6054264903068542\n",
      "\n",
      "episode 13, val func loss 0.5126791596412659\n",
      "\n",
      "episode 14, val func loss 0.6459409594535828\n",
      "\n",
      "episode 15, val func loss 0.6405084133148193\n",
      "\n",
      "episode 16, val func loss 0.5770655870437622\n",
      "\n",
      "Val func train loss in epoch 3:0.6148927062749863\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.524929404258728\n",
      "\n",
      "episode 2, val func loss 0.5719153881072998\n",
      "\n",
      "episode 3, val func loss 0.6281015872955322\n",
      "\n",
      "episode 4, val func loss 0.6053094267845154\n",
      "\n",
      "episode 5, val func loss 0.5553082823753357\n",
      "\n",
      "episode 6, val func loss 0.7232572436332703\n",
      "\n",
      "episode 7, val func loss 0.5751450657844543\n",
      "\n",
      "episode 8, val func loss 0.6464759111404419\n",
      "\n",
      "episode 9, val func loss 0.6684390306472778\n",
      "\n",
      "episode 10, val func loss 0.6531481742858887\n",
      "\n",
      "episode 11, val func loss 0.604032039642334\n",
      "\n",
      "episode 12, val func loss 0.524616003036499\n",
      "\n",
      "episode 13, val func loss 0.6072485446929932\n",
      "\n",
      "episode 14, val func loss 0.6433764696121216\n",
      "\n",
      "episode 15, val func loss 0.6598487496376038\n",
      "\n",
      "episode 16, val func loss 0.5520146489143372\n",
      "\n",
      "Val func train loss in epoch 4:0.6089478731155396\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6332999467849731\n",
      "\n",
      "episode 2, val func loss 0.6108531355857849\n",
      "\n",
      "episode 3, val func loss 0.6686784625053406\n",
      "\n",
      "episode 4, val func loss 0.5805771946907043\n",
      "\n",
      "episode 5, val func loss 0.729076623916626\n",
      "\n",
      "episode 6, val func loss 0.6841714978218079\n",
      "\n",
      "episode 7, val func loss 0.7300387620925903\n",
      "\n",
      "episode 8, val func loss 0.7084676027297974\n",
      "\n",
      "episode 9, val func loss 0.7127887010574341\n",
      "\n",
      "episode 10, val func loss 0.7562032341957092\n",
      "\n",
      "episode 11, val func loss 0.5936033725738525\n",
      "\n",
      "episode 12, val func loss 0.7281652688980103\n",
      "\n",
      "episode 13, val func loss 0.6787739992141724\n",
      "\n",
      "episode 14, val func loss 0.6346173286437988\n",
      "\n",
      "episode 15, val func loss 0.5393352508544922\n",
      "\n",
      "episode 16, val func loss 0.7046837210655212\n",
      "\n",
      "Val func train loss in epoch 5:0.6683333814144135\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7217609882354736\n",
      "\n",
      "episode 2, val func loss 0.6567466855049133\n",
      "\n",
      "episode 3, val func loss 0.5294349193572998\n",
      "\n",
      "episode 4, val func loss 0.5431700348854065\n",
      "\n",
      "episode 5, val func loss 0.605266273021698\n",
      "\n",
      "episode 6, val func loss 0.6449163556098938\n",
      "\n",
      "episode 7, val func loss 0.5792462229728699\n",
      "\n",
      "episode 8, val func loss 0.5989657640457153\n",
      "\n",
      "episode 9, val func loss 0.6904203295707703\n",
      "\n",
      "episode 10, val func loss 0.6463963389396667\n",
      "\n",
      "episode 11, val func loss 0.6036555171012878\n",
      "\n",
      "episode 12, val func loss 0.6860427856445312\n",
      "\n",
      "episode 13, val func loss 0.588420569896698\n",
      "\n",
      "episode 14, val func loss 0.5185496807098389\n",
      "\n",
      "episode 15, val func loss 0.6244519352912903\n",
      "\n",
      "episode 16, val func loss 0.5740888118743896\n",
      "\n",
      "Val func train loss in epoch 6:0.613220825791359\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.5648104548454285\n",
      "\n",
      "episode 2, val func loss 0.6000213027000427\n",
      "\n",
      "episode 3, val func loss 0.6156929135322571\n",
      "\n",
      "episode 4, val func loss 0.5749598145484924\n",
      "\n",
      "episode 5, val func loss 0.6405562162399292\n",
      "\n",
      "episode 6, val func loss 0.5659058094024658\n",
      "\n",
      "episode 7, val func loss 0.6380429863929749\n",
      "\n",
      "episode 8, val func loss 0.5812612175941467\n",
      "\n",
      "episode 9, val func loss 0.6114699840545654\n",
      "\n",
      "episode 10, val func loss 0.5630651116371155\n",
      "\n",
      "episode 11, val func loss 0.6797982454299927\n",
      "\n",
      "episode 12, val func loss 0.5919768214225769\n",
      "\n",
      "episode 13, val func loss 0.6424332857131958\n",
      "\n",
      "episode 14, val func loss 0.7274863123893738\n",
      "\n",
      "episode 15, val func loss 0.48453399538993835\n",
      "\n",
      "episode 16, val func loss 0.5538026690483093\n",
      "\n",
      "Val func train loss in epoch 7:0.6022385712713003\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6392735838890076\n",
      "\n",
      "episode 2, val func loss 0.6514112949371338\n",
      "\n",
      "episode 3, val func loss 0.5831817388534546\n",
      "\n",
      "episode 4, val func loss 0.5673218369483948\n",
      "\n",
      "episode 5, val func loss 0.5949867367744446\n",
      "\n",
      "episode 6, val func loss 0.6710228323936462\n",
      "\n",
      "episode 7, val func loss 0.5074911117553711\n",
      "\n",
      "episode 8, val func loss 0.7102701663970947\n",
      "\n",
      "episode 9, val func loss 0.5999096632003784\n",
      "\n",
      "episode 10, val func loss 0.5416551232337952\n",
      "\n",
      "episode 11, val func loss 0.5265246033668518\n",
      "\n",
      "episode 12, val func loss 0.5375339984893799\n",
      "\n",
      "episode 13, val func loss 0.5299974679946899\n",
      "\n",
      "episode 14, val func loss 0.5914227366447449\n",
      "\n",
      "episode 15, val func loss 0.6287675499916077\n",
      "\n",
      "episode 16, val func loss 0.6402397155761719\n",
      "\n",
      "Val func train loss in epoch 8:0.5950631350278854\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.5349436402320862\n",
      "\n",
      "episode 2, val func loss 0.5912334322929382\n",
      "\n",
      "episode 3, val func loss 0.6264395713806152\n",
      "\n",
      "episode 4, val func loss 0.6802096366882324\n",
      "\n",
      "episode 5, val func loss 0.5832087397575378\n",
      "\n",
      "episode 6, val func loss 0.5280377268791199\n",
      "\n",
      "episode 7, val func loss 0.5991551280021667\n",
      "\n",
      "episode 8, val func loss 0.6017720103263855\n",
      "\n",
      "episode 9, val func loss 0.5756108164787292\n",
      "\n",
      "episode 10, val func loss 0.6000880599021912\n",
      "\n",
      "episode 11, val func loss 0.6574512720108032\n",
      "\n",
      "episode 12, val func loss 0.648911714553833\n",
      "\n",
      "episode 13, val func loss 0.5417755842208862\n",
      "\n",
      "episode 14, val func loss 0.550115168094635\n",
      "\n",
      "episode 15, val func loss 0.6167057156562805\n",
      "\n",
      "episode 16, val func loss 0.6566822528839111\n",
      "\n",
      "Val func train loss in epoch 9:0.599521279335022\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7026126980781555\n",
      "\n",
      "episode 2, val func loss 0.5377546548843384\n",
      "\n",
      "episode 3, val func loss 0.6409378051757812\n",
      "\n",
      "episode 4, val func loss 0.6841956377029419\n",
      "\n",
      "episode 5, val func loss 0.6680375337600708\n",
      "\n",
      "episode 6, val func loss 0.5511876940727234\n",
      "\n",
      "episode 7, val func loss 0.676459550857544\n",
      "\n",
      "episode 8, val func loss 0.5698415040969849\n",
      "\n",
      "episode 9, val func loss 0.6897649765014648\n",
      "\n",
      "episode 10, val func loss 0.715231716632843\n",
      "\n",
      "episode 11, val func loss 0.6441493630409241\n",
      "\n",
      "episode 12, val func loss 0.5342338681221008\n",
      "\n",
      "episode 13, val func loss 0.5064957737922668\n",
      "\n",
      "episode 14, val func loss 0.5897528529167175\n",
      "\n",
      "episode 15, val func loss 0.6686080098152161\n",
      "\n",
      "episode 16, val func loss 0.6267673373222351\n",
      "\n",
      "Val func train loss in epoch 10:0.6253769360482693\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6389639973640442\n",
      "\n",
      "episode 2, val func loss 0.6731253862380981\n",
      "\n",
      "episode 3, val func loss 0.6283630728721619\n",
      "\n",
      "episode 4, val func loss 0.542378306388855\n",
      "\n",
      "episode 5, val func loss 0.7157878279685974\n",
      "\n",
      "episode 6, val func loss 0.7311086654663086\n",
      "\n",
      "episode 7, val func loss 0.6422643661499023\n",
      "\n",
      "episode 8, val func loss 0.6520246267318726\n",
      "\n",
      "episode 9, val func loss 0.5707278847694397\n",
      "\n",
      "episode 10, val func loss 0.5727124214172363\n",
      "\n",
      "episode 11, val func loss 0.5522730350494385\n",
      "\n",
      "episode 12, val func loss 0.47914567589759827\n",
      "\n",
      "episode 13, val func loss 0.7329342365264893\n",
      "\n",
      "episode 14, val func loss 0.5217462182044983\n",
      "\n",
      "episode 15, val func loss 0.6268996000289917\n",
      "\n",
      "episode 16, val func loss 0.6142433285713196\n",
      "\n",
      "Val func train loss in epoch 11:0.6184186656028032\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.5982469320297241\n",
      "\n",
      "episode 2, val func loss 0.5782420039176941\n",
      "\n",
      "episode 3, val func loss 0.5340821743011475\n",
      "\n",
      "episode 4, val func loss 0.5817708969116211\n",
      "\n",
      "episode 5, val func loss 0.5041512846946716\n",
      "\n",
      "episode 6, val func loss 0.6232993006706238\n",
      "\n",
      "episode 7, val func loss 0.6969425678253174\n",
      "\n",
      "episode 8, val func loss 0.640163004398346\n",
      "\n",
      "episode 9, val func loss 0.6207529902458191\n",
      "\n",
      "episode 10, val func loss 0.5797864198684692\n",
      "\n",
      "episode 11, val func loss 0.6631652116775513\n",
      "\n",
      "episode 12, val func loss 0.6809497475624084\n",
      "\n",
      "episode 13, val func loss 0.6025703549385071\n",
      "\n",
      "episode 14, val func loss 0.7192378640174866\n",
      "\n",
      "episode 15, val func loss 0.5888604521751404\n",
      "\n",
      "episode 16, val func loss 0.5484716892242432\n",
      "\n",
      "Val func train loss in epoch 12:0.6100433059036732\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.5519703030586243\n",
      "\n",
      "episode 2, val func loss 0.6278015971183777\n",
      "\n",
      "episode 3, val func loss 0.6771321296691895\n",
      "\n",
      "episode 4, val func loss 0.5792557597160339\n",
      "\n",
      "episode 5, val func loss 0.6521415710449219\n",
      "\n",
      "episode 6, val func loss 0.6725733280181885\n",
      "\n",
      "episode 7, val func loss 0.6063809990882874\n",
      "\n",
      "episode 8, val func loss 0.6394065618515015\n",
      "\n",
      "episode 9, val func loss 0.6169472932815552\n",
      "\n",
      "episode 10, val func loss 0.671334445476532\n",
      "\n",
      "episode 11, val func loss 0.7325142025947571\n",
      "\n",
      "episode 12, val func loss 0.6139664053916931\n",
      "\n",
      "episode 13, val func loss 0.6615137457847595\n",
      "\n",
      "episode 14, val func loss 0.6485253572463989\n",
      "\n",
      "episode 15, val func loss 0.6632688641548157\n",
      "\n",
      "episode 16, val func loss 0.7068092823028564\n",
      "\n",
      "Val func train loss in epoch 13:0.6450963653624058\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.6527054905891418\n",
      "\n",
      "episode 2, val func loss 0.6924439668655396\n",
      "\n",
      "episode 3, val func loss 0.6599845886230469\n",
      "\n",
      "episode 4, val func loss 0.5535873174667358\n",
      "\n",
      "episode 5, val func loss 0.6747905015945435\n",
      "\n",
      "episode 6, val func loss 0.6365131139755249\n",
      "\n",
      "episode 7, val func loss 0.6447267532348633\n",
      "\n",
      "episode 8, val func loss 0.6258735060691833\n",
      "\n",
      "episode 9, val func loss 0.6443243026733398\n",
      "\n",
      "episode 10, val func loss 0.6407573819160461\n",
      "\n",
      "episode 11, val func loss 0.7685404419898987\n",
      "\n",
      "episode 12, val func loss 0.7184926271438599\n",
      "\n",
      "episode 13, val func loss 0.7242898941040039\n",
      "\n",
      "episode 14, val func loss 0.5091179013252258\n",
      "\n",
      "episode 15, val func loss 0.5909116864204407\n",
      "\n",
      "episode 16, val func loss 0.6810975074768066\n",
      "\n",
      "Val func train loss in epoch 14:0.6511348113417625\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.591721773147583\n",
      "\n",
      "episode 2, val func loss 0.6005330681800842\n",
      "\n",
      "episode 3, val func loss 0.6253656148910522\n",
      "\n",
      "episode 4, val func loss 0.6981870532035828\n",
      "\n",
      "episode 5, val func loss 0.5864482522010803\n",
      "\n",
      "episode 6, val func loss 0.6695646047592163\n",
      "\n",
      "episode 7, val func loss 0.6078196167945862\n",
      "\n",
      "episode 8, val func loss 0.684988260269165\n",
      "\n",
      "episode 9, val func loss 0.7763274908065796\n",
      "\n",
      "episode 10, val func loss 0.6246516108512878\n",
      "\n",
      "episode 11, val func loss 0.586537778377533\n",
      "\n",
      "episode 12, val func loss 0.7060598134994507\n",
      "\n",
      "episode 13, val func loss 0.5838539600372314\n",
      "\n",
      "episode 14, val func loss 0.6560051441192627\n",
      "\n",
      "episode 15, val func loss 0.6822915077209473\n",
      "\n",
      "episode 16, val func loss 0.6323755979537964\n",
      "\n",
      "Val func train loss in epoch 15:0.6445456966757774\n",
      "***********************TIME WAS 4.934761583805084 min*****************************\n",
      "\n",
      "**********************ROUND 142 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.6248304843902588\n",
      "\n",
      "episode 2, policy loss 1.7079501152038574\n",
      "\n",
      "episode 3, policy loss 1.4795857667922974\n",
      "\n",
      "episode 4, policy loss 1.7953393459320068\n",
      "\n",
      "episode 5, policy loss 1.5576642751693726\n",
      "\n",
      "episode 6, policy loss 1.3990384340286255\n",
      "\n",
      "episode 7, policy loss 1.4238836765289307\n",
      "\n",
      "episode 8, policy loss 1.488734245300293\n",
      "\n",
      "episode 9, policy loss 1.097346305847168\n",
      "\n",
      "episode 10, policy loss 1.7257179021835327\n",
      "\n",
      "episode 11, policy loss 1.7318423986434937\n",
      "\n",
      "episode 12, policy loss 1.7533000707626343\n",
      "\n",
      "episode 13, policy loss 1.6432298421859741\n",
      "\n",
      "episode 14, policy loss 1.832059383392334\n",
      "\n",
      "episode 15, policy loss 1.653922438621521\n",
      "\n",
      "episode 16, policy loss 1.7518669366836548\n",
      "\n",
      "Policy train loss in epoch 0:1.6041444763541222\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.4320151805877686\n",
      "\n",
      "episode 2, policy loss 1.0948246717453003\n",
      "\n",
      "episode 3, policy loss 1.6939644813537598\n",
      "\n",
      "episode 4, policy loss 1.72356379032135\n",
      "\n",
      "episode 5, policy loss 1.677217721939087\n",
      "\n",
      "episode 6, policy loss 1.6531763076782227\n",
      "\n",
      "episode 7, policy loss 1.34430730342865\n",
      "\n",
      "episode 8, policy loss 1.631439447402954\n",
      "\n",
      "episode 9, policy loss 1.5933756828308105\n",
      "\n",
      "episode 10, policy loss 1.6815463304519653\n",
      "\n",
      "episode 11, policy loss 1.4016120433807373\n",
      "\n",
      "episode 12, policy loss 1.2358261346817017\n",
      "\n",
      "episode 13, policy loss 1.4999207258224487\n",
      "\n",
      "episode 14, policy loss 1.6624491214752197\n",
      "\n",
      "episode 15, policy loss 1.4084895849227905\n",
      "\n",
      "episode 16, policy loss 1.452391266822815\n",
      "\n",
      "Policy train loss in epoch 1:1.5116324871778488\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.4399737119674683\n",
      "\n",
      "episode 2, policy loss 1.2278223037719727\n",
      "\n",
      "episode 3, policy loss 1.4318393468856812\n",
      "\n",
      "episode 4, policy loss 0.9883074760437012\n",
      "\n",
      "episode 5, policy loss 1.5480353832244873\n",
      "\n",
      "episode 6, policy loss 1.635149359703064\n",
      "\n",
      "episode 7, policy loss 1.6198171377182007\n",
      "\n",
      "episode 8, policy loss 1.294294834136963\n",
      "\n",
      "episode 9, policy loss 1.370998740196228\n",
      "\n",
      "episode 10, policy loss 1.3203248977661133\n",
      "\n",
      "episode 11, policy loss 1.5341492891311646\n",
      "\n",
      "episode 12, policy loss 1.5088547468185425\n",
      "\n",
      "episode 13, policy loss 1.5596786737442017\n",
      "\n",
      "episode 14, policy loss 1.52033269405365\n",
      "\n",
      "episode 15, policy loss 1.5869860649108887\n",
      "\n",
      "episode 16, policy loss 1.471793532371521\n",
      "\n",
      "Policy train loss in epoch 2:1.4411473870277405\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.5526014566421509\n",
      "\n",
      "episode 2, policy loss 0.9645795822143555\n",
      "\n",
      "episode 3, policy loss 1.639724612236023\n",
      "\n",
      "episode 4, policy loss 1.3676457405090332\n",
      "\n",
      "episode 5, policy loss 1.272323727607727\n",
      "\n",
      "episode 6, policy loss 1.4683043956756592\n",
      "\n",
      "episode 7, policy loss 1.527660846710205\n",
      "\n",
      "episode 8, policy loss 1.5821540355682373\n",
      "\n",
      "episode 9, policy loss 1.4104514122009277\n",
      "\n",
      "episode 10, policy loss 1.4267297983169556\n",
      "\n",
      "episode 11, policy loss 1.53085458278656\n",
      "\n",
      "episode 12, policy loss 1.6059786081314087\n",
      "\n",
      "episode 13, policy loss 1.5129212141036987\n",
      "\n",
      "episode 14, policy loss 1.2249374389648438\n",
      "\n",
      "episode 15, policy loss 1.5271598100662231\n",
      "\n",
      "episode 16, policy loss 1.3249603509902954\n",
      "\n",
      "Policy train loss in epoch 3:1.433686725795269\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 3.7723541259765625\n",
      "\n",
      "episode 2, val func loss 2.8076603412628174\n",
      "\n",
      "episode 3, val func loss 3.443877935409546\n",
      "\n",
      "episode 4, val func loss 3.6821396350860596\n",
      "\n",
      "episode 5, val func loss 3.9366061687469482\n",
      "\n",
      "episode 6, val func loss 3.706413745880127\n",
      "\n",
      "episode 7, val func loss 4.309114456176758\n",
      "\n",
      "episode 8, val func loss 3.312507390975952\n",
      "\n",
      "episode 9, val func loss 2.7897262573242188\n",
      "\n",
      "episode 10, val func loss 3.776050567626953\n",
      "\n",
      "episode 11, val func loss 3.514352321624756\n",
      "\n",
      "episode 12, val func loss 3.633631467819214\n",
      "\n",
      "episode 13, val func loss 3.620020627975464\n",
      "\n",
      "episode 14, val func loss 3.198173999786377\n",
      "\n",
      "episode 15, val func loss 3.16996169090271\n",
      "\n",
      "episode 16, val func loss 2.9067769050598145\n",
      "\n",
      "Val func train loss in epoch 0:3.4737104773521423\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 3.8273422718048096\n",
      "\n",
      "episode 2, val func loss 3.9917078018188477\n",
      "\n",
      "episode 3, val func loss 3.3719496726989746\n",
      "\n",
      "episode 4, val func loss 3.3252620697021484\n",
      "\n",
      "episode 5, val func loss 3.9602725505828857\n",
      "\n",
      "episode 6, val func loss 3.2020888328552246\n",
      "\n",
      "episode 7, val func loss 3.6893250942230225\n",
      "\n",
      "episode 8, val func loss 3.6445655822753906\n",
      "\n",
      "episode 9, val func loss 3.910653829574585\n",
      "\n",
      "episode 10, val func loss 2.5232419967651367\n",
      "\n",
      "episode 11, val func loss 2.8999733924865723\n",
      "\n",
      "episode 12, val func loss 3.1862308979034424\n",
      "\n",
      "episode 13, val func loss 3.58847975730896\n",
      "\n",
      "episode 14, val func loss 3.2199814319610596\n",
      "\n",
      "episode 15, val func loss 3.6975436210632324\n",
      "\n",
      "episode 16, val func loss 3.410607099533081\n",
      "\n",
      "Val func train loss in epoch 1:3.465576618909836\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 3.2573416233062744\n",
      "\n",
      "episode 2, val func loss 3.7870101928710938\n",
      "\n",
      "episode 3, val func loss 3.9999873638153076\n",
      "\n",
      "episode 4, val func loss 3.424672842025757\n",
      "\n",
      "episode 5, val func loss 3.433135986328125\n",
      "\n",
      "episode 6, val func loss 3.755361318588257\n",
      "\n",
      "episode 7, val func loss 3.378424644470215\n",
      "\n",
      "episode 8, val func loss 2.5213844776153564\n",
      "\n",
      "episode 9, val func loss 3.673896312713623\n",
      "\n",
      "episode 10, val func loss 2.671689510345459\n",
      "\n",
      "episode 11, val func loss 3.690845012664795\n",
      "\n",
      "episode 12, val func loss 3.4742326736450195\n",
      "\n",
      "episode 13, val func loss 3.9255380630493164\n",
      "\n",
      "episode 14, val func loss 3.6122543811798096\n",
      "\n",
      "episode 15, val func loss 3.7830283641815186\n",
      "\n",
      "episode 16, val func loss 3.105618476867676\n",
      "\n",
      "Val func train loss in epoch 2:3.468401327729225\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.5223653316497803\n",
      "\n",
      "episode 2, val func loss 3.4476230144500732\n",
      "\n",
      "episode 3, val func loss 3.2154455184936523\n",
      "\n",
      "episode 4, val func loss 3.5827319622039795\n",
      "\n",
      "episode 5, val func loss 3.642918586730957\n",
      "\n",
      "episode 6, val func loss 3.456230640411377\n",
      "\n",
      "episode 7, val func loss 3.39388108253479\n",
      "\n",
      "episode 8, val func loss 3.354879379272461\n",
      "\n",
      "episode 9, val func loss 2.8603675365448\n",
      "\n",
      "episode 10, val func loss 3.248041868209839\n",
      "\n",
      "episode 11, val func loss 4.060339450836182\n",
      "\n",
      "episode 12, val func loss 3.5988245010375977\n",
      "\n",
      "episode 13, val func loss 3.353581428527832\n",
      "\n",
      "episode 14, val func loss 3.6515703201293945\n",
      "\n",
      "episode 15, val func loss 3.4499764442443848\n",
      "\n",
      "episode 16, val func loss 3.939425230026245\n",
      "\n",
      "Val func train loss in epoch 3:3.423637643456459\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 3.956062078475952\n",
      "\n",
      "episode 2, val func loss 2.7123682498931885\n",
      "\n",
      "episode 3, val func loss 2.6566922664642334\n",
      "\n",
      "episode 4, val func loss 3.2567203044891357\n",
      "\n",
      "episode 5, val func loss 3.4681243896484375\n",
      "\n",
      "episode 6, val func loss 3.6810216903686523\n",
      "\n",
      "episode 7, val func loss 3.5705082416534424\n",
      "\n",
      "episode 8, val func loss 3.71331524848938\n",
      "\n",
      "episode 9, val func loss 3.709012746810913\n",
      "\n",
      "episode 10, val func loss 3.5384628772735596\n",
      "\n",
      "episode 11, val func loss 3.9645748138427734\n",
      "\n",
      "episode 12, val func loss 2.9917802810668945\n",
      "\n",
      "episode 13, val func loss 3.150505542755127\n",
      "\n",
      "episode 14, val func loss 3.114980459213257\n",
      "\n",
      "episode 15, val func loss 3.0853793621063232\n",
      "\n",
      "episode 16, val func loss 3.065031051635742\n",
      "\n",
      "Val func train loss in epoch 4:3.3521587252616882\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 3.5076286792755127\n",
      "\n",
      "episode 2, val func loss 2.500459909439087\n",
      "\n",
      "episode 3, val func loss 4.224379062652588\n",
      "\n",
      "episode 4, val func loss 4.071639537811279\n",
      "\n",
      "episode 5, val func loss 3.840725898742676\n",
      "\n",
      "episode 6, val func loss 3.1350457668304443\n",
      "\n",
      "episode 7, val func loss 3.032957077026367\n",
      "\n",
      "episode 8, val func loss 3.5455424785614014\n",
      "\n",
      "episode 9, val func loss 3.8396501541137695\n",
      "\n",
      "episode 10, val func loss 3.6280999183654785\n",
      "\n",
      "episode 11, val func loss 3.2340691089630127\n",
      "\n",
      "episode 12, val func loss 3.2699034214019775\n",
      "\n",
      "episode 13, val func loss 3.6332991123199463\n",
      "\n",
      "episode 14, val func loss 3.790569305419922\n",
      "\n",
      "episode 15, val func loss 3.326542854309082\n",
      "\n",
      "episode 16, val func loss 3.72533917427063\n",
      "\n",
      "Val func train loss in epoch 5:3.5191157162189484\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 3.191148281097412\n",
      "\n",
      "episode 2, val func loss 3.5095956325531006\n",
      "\n",
      "episode 3, val func loss 3.203920602798462\n",
      "\n",
      "episode 4, val func loss 3.0499446392059326\n",
      "\n",
      "episode 5, val func loss 3.5462839603424072\n",
      "\n",
      "episode 6, val func loss 3.5194668769836426\n",
      "\n",
      "episode 7, val func loss 3.4896137714385986\n",
      "\n",
      "episode 8, val func loss 4.4418840408325195\n",
      "\n",
      "episode 9, val func loss 3.650099515914917\n",
      "\n",
      "episode 10, val func loss 4.279036998748779\n",
      "\n",
      "episode 11, val func loss 3.3448033332824707\n",
      "\n",
      "episode 12, val func loss 2.9991226196289062\n",
      "\n",
      "episode 13, val func loss 3.413465738296509\n",
      "\n",
      "episode 14, val func loss 3.813741683959961\n",
      "\n",
      "episode 15, val func loss 2.890282392501831\n",
      "\n",
      "episode 16, val func loss 2.565390110015869\n",
      "\n",
      "Val func train loss in epoch 6:3.4317375123500824\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 3.176600694656372\n",
      "\n",
      "episode 2, val func loss 4.240359306335449\n",
      "\n",
      "episode 3, val func loss 3.0110981464385986\n",
      "\n",
      "episode 4, val func loss 3.5433356761932373\n",
      "\n",
      "episode 5, val func loss 3.6496167182922363\n",
      "\n",
      "episode 6, val func loss 3.4911859035491943\n",
      "\n",
      "episode 7, val func loss 3.631895065307617\n",
      "\n",
      "episode 8, val func loss 3.3815884590148926\n",
      "\n",
      "episode 9, val func loss 3.4943184852600098\n",
      "\n",
      "episode 10, val func loss 3.215829610824585\n",
      "\n",
      "episode 11, val func loss 3.312342882156372\n",
      "\n",
      "episode 12, val func loss 4.0638251304626465\n",
      "\n",
      "episode 13, val func loss 3.938138008117676\n",
      "\n",
      "episode 14, val func loss 2.66276478767395\n",
      "\n",
      "episode 15, val func loss 3.630723714828491\n",
      "\n",
      "episode 16, val func loss 3.8473384380340576\n",
      "\n",
      "Val func train loss in epoch 7:3.5181850641965866\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 3.842402696609497\n",
      "\n",
      "episode 2, val func loss 3.39776611328125\n",
      "\n",
      "episode 3, val func loss 3.563380718231201\n",
      "\n",
      "episode 4, val func loss 4.375848770141602\n",
      "\n",
      "episode 5, val func loss 3.389439582824707\n",
      "\n",
      "episode 6, val func loss 3.6522467136383057\n",
      "\n",
      "episode 7, val func loss 3.1960601806640625\n",
      "\n",
      "episode 8, val func loss 3.7421059608459473\n",
      "\n",
      "episode 9, val func loss 3.477872848510742\n",
      "\n",
      "episode 10, val func loss 3.377002716064453\n",
      "\n",
      "episode 11, val func loss 2.730494499206543\n",
      "\n",
      "episode 12, val func loss 3.4435925483703613\n",
      "\n",
      "episode 13, val func loss 2.4588122367858887\n",
      "\n",
      "episode 14, val func loss 3.735639810562134\n",
      "\n",
      "episode 15, val func loss 3.774019479751587\n",
      "\n",
      "episode 16, val func loss 3.197136402130127\n",
      "\n",
      "Val func train loss in epoch 8:3.4596138298511505\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 3.5907771587371826\n",
      "\n",
      "episode 2, val func loss 3.934406280517578\n",
      "\n",
      "episode 3, val func loss 3.5161709785461426\n",
      "\n",
      "episode 4, val func loss 3.16449236869812\n",
      "\n",
      "episode 5, val func loss 3.2770047187805176\n",
      "\n",
      "episode 6, val func loss 3.7404561042785645\n",
      "\n",
      "episode 7, val func loss 3.194779396057129\n",
      "\n",
      "episode 8, val func loss 4.220418930053711\n",
      "\n",
      "episode 9, val func loss 3.347214460372925\n",
      "\n",
      "episode 10, val func loss 3.1310245990753174\n",
      "\n",
      "episode 11, val func loss 3.306938648223877\n",
      "\n",
      "episode 12, val func loss 2.5561671257019043\n",
      "\n",
      "episode 13, val func loss 3.7517857551574707\n",
      "\n",
      "episode 14, val func loss 3.8450915813446045\n",
      "\n",
      "episode 15, val func loss 3.4861955642700195\n",
      "\n",
      "episode 16, val func loss 3.296858787536621\n",
      "\n",
      "Val func train loss in epoch 9:3.4599864035844803\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 2.6682868003845215\n",
      "\n",
      "episode 2, val func loss 3.495518684387207\n",
      "\n",
      "episode 3, val func loss 3.2706973552703857\n",
      "\n",
      "episode 4, val func loss 3.0160887241363525\n",
      "\n",
      "episode 5, val func loss 3.382528066635132\n",
      "\n",
      "episode 6, val func loss 3.4650795459747314\n",
      "\n",
      "episode 7, val func loss 4.035025119781494\n",
      "\n",
      "episode 8, val func loss 3.249526262283325\n",
      "\n",
      "episode 9, val func loss 3.5369911193847656\n",
      "\n",
      "episode 10, val func loss 3.2844133377075195\n",
      "\n",
      "episode 11, val func loss 3.449242115020752\n",
      "\n",
      "episode 12, val func loss 3.8214235305786133\n",
      "\n",
      "episode 13, val func loss 3.8394949436187744\n",
      "\n",
      "episode 14, val func loss 2.9567580223083496\n",
      "\n",
      "episode 15, val func loss 2.6707770824432373\n",
      "\n",
      "episode 16, val func loss 3.5106616020202637\n",
      "\n",
      "Val func train loss in epoch 10:3.353282019495964\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 3.110670804977417\n",
      "\n",
      "episode 2, val func loss 3.063701629638672\n",
      "\n",
      "episode 3, val func loss 2.699134588241577\n",
      "\n",
      "episode 4, val func loss 3.3557205200195312\n",
      "\n",
      "episode 5, val func loss 3.384523630142212\n",
      "\n",
      "episode 6, val func loss 3.5271036624908447\n",
      "\n",
      "episode 7, val func loss 2.5502095222473145\n",
      "\n",
      "episode 8, val func loss 3.5960075855255127\n",
      "\n",
      "episode 9, val func loss 3.6176645755767822\n",
      "\n",
      "episode 10, val func loss 3.803323268890381\n",
      "\n",
      "episode 11, val func loss 3.514681577682495\n",
      "\n",
      "episode 12, val func loss 3.492624044418335\n",
      "\n",
      "episode 13, val func loss 3.3084709644317627\n",
      "\n",
      "episode 14, val func loss 3.3033506870269775\n",
      "\n",
      "episode 15, val func loss 3.5270559787750244\n",
      "\n",
      "episode 16, val func loss 3.3703346252441406\n",
      "\n",
      "Val func train loss in epoch 11:3.326536104083061\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 3.0295569896698\n",
      "\n",
      "episode 2, val func loss 3.0909416675567627\n",
      "\n",
      "episode 3, val func loss 3.4285404682159424\n",
      "\n",
      "episode 4, val func loss 2.5875227451324463\n",
      "\n",
      "episode 5, val func loss 3.408757209777832\n",
      "\n",
      "episode 6, val func loss 3.5022189617156982\n",
      "\n",
      "episode 7, val func loss 3.0692622661590576\n",
      "\n",
      "episode 8, val func loss 3.611199378967285\n",
      "\n",
      "episode 9, val func loss 3.110473394393921\n",
      "\n",
      "episode 10, val func loss 4.065958499908447\n",
      "\n",
      "episode 11, val func loss 3.212578535079956\n",
      "\n",
      "episode 12, val func loss 2.7218263149261475\n",
      "\n",
      "episode 13, val func loss 4.012508392333984\n",
      "\n",
      "episode 14, val func loss 3.1533043384552\n",
      "\n",
      "episode 15, val func loss 3.727616786956787\n",
      "\n",
      "episode 16, val func loss 3.3188788890838623\n",
      "\n",
      "Val func train loss in epoch 12:3.3156965523958206\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 3.8533170223236084\n",
      "\n",
      "episode 2, val func loss 3.296430826187134\n",
      "\n",
      "episode 3, val func loss 3.1244633197784424\n",
      "\n",
      "episode 4, val func loss 3.513141632080078\n",
      "\n",
      "episode 5, val func loss 3.55765438079834\n",
      "\n",
      "episode 6, val func loss 3.6840226650238037\n",
      "\n",
      "episode 7, val func loss 3.9762189388275146\n",
      "\n",
      "episode 8, val func loss 2.632197141647339\n",
      "\n",
      "episode 9, val func loss 3.128153085708618\n",
      "\n",
      "episode 10, val func loss 3.605686664581299\n",
      "\n",
      "episode 11, val func loss 3.221630334854126\n",
      "\n",
      "episode 12, val func loss 3.212092638015747\n",
      "\n",
      "episode 13, val func loss 3.009322166442871\n",
      "\n",
      "episode 14, val func loss 3.393934965133667\n",
      "\n",
      "episode 15, val func loss 3.532827138900757\n",
      "\n",
      "episode 16, val func loss 3.2008867263793945\n",
      "\n",
      "Val func train loss in epoch 13:3.371373727917671\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 3.5627150535583496\n",
      "\n",
      "episode 2, val func loss 3.5900375843048096\n",
      "\n",
      "episode 3, val func loss 3.3113553524017334\n",
      "\n",
      "episode 4, val func loss 3.455622911453247\n",
      "\n",
      "episode 5, val func loss 3.292309284210205\n",
      "\n",
      "episode 6, val func loss 2.6563315391540527\n",
      "\n",
      "episode 7, val func loss 3.8614861965179443\n",
      "\n",
      "episode 8, val func loss 3.7300126552581787\n",
      "\n",
      "episode 9, val func loss 3.8324508666992188\n",
      "\n",
      "episode 10, val func loss 3.774153470993042\n",
      "\n",
      "episode 11, val func loss 3.87123966217041\n",
      "\n",
      "episode 12, val func loss 3.058178186416626\n",
      "\n",
      "episode 13, val func loss 2.9910888671875\n",
      "\n",
      "episode 14, val func loss 3.3276901245117188\n",
      "\n",
      "episode 15, val func loss 3.2326016426086426\n",
      "\n",
      "episode 16, val func loss 3.26108717918396\n",
      "\n",
      "Val func train loss in epoch 14:3.4255225360393524\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.989931344985962\n",
      "\n",
      "episode 2, val func loss 3.23077130317688\n",
      "\n",
      "episode 3, val func loss 3.8548386096954346\n",
      "\n",
      "episode 4, val func loss 3.5588784217834473\n",
      "\n",
      "episode 5, val func loss 3.6651697158813477\n",
      "\n",
      "episode 6, val func loss 3.5563888549804688\n",
      "\n",
      "episode 7, val func loss 3.384852647781372\n",
      "\n",
      "episode 8, val func loss 3.6381425857543945\n",
      "\n",
      "episode 9, val func loss 3.5597167015075684\n",
      "\n",
      "episode 10, val func loss 3.5286781787872314\n",
      "\n",
      "episode 11, val func loss 3.5991132259368896\n",
      "\n",
      "episode 12, val func loss 3.7603087425231934\n",
      "\n",
      "episode 13, val func loss 2.69655704498291\n",
      "\n",
      "episode 14, val func loss 3.8222579956054688\n",
      "\n",
      "episode 15, val func loss 3.425161123275757\n",
      "\n",
      "episode 16, val func loss 3.761399030685425\n",
      "\n",
      "Val func train loss in epoch 15:3.5020103454589844\n",
      "***********************TIME WAS 4.932312071323395 min*****************************\n",
      "\n",
      "**********************ROUND 143 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.9038481116294861\n",
      "\n",
      "episode 2, policy loss 0.7824479937553406\n",
      "\n",
      "episode 3, policy loss 1.3759171962738037\n",
      "\n",
      "episode 4, policy loss 1.213346004486084\n",
      "\n",
      "episode 5, policy loss 1.285080075263977\n",
      "\n",
      "episode 6, policy loss 1.5301477909088135\n",
      "\n",
      "episode 7, policy loss 1.1721177101135254\n",
      "\n",
      "episode 8, policy loss 1.1489789485931396\n",
      "\n",
      "episode 9, policy loss 0.9262471199035645\n",
      "\n",
      "episode 10, policy loss 1.5189625024795532\n",
      "\n",
      "episode 11, policy loss 1.2121496200561523\n",
      "\n",
      "episode 12, policy loss 1.2381737232208252\n",
      "\n",
      "episode 13, policy loss 1.1414463520050049\n",
      "\n",
      "episode 14, policy loss 1.0471001863479614\n",
      "\n",
      "episode 15, policy loss 0.9398138523101807\n",
      "\n",
      "episode 16, policy loss 1.1368449926376343\n",
      "\n",
      "Policy train loss in epoch 0:1.1607888862490654\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.0476208925247192\n",
      "\n",
      "episode 2, policy loss 1.2378370761871338\n",
      "\n",
      "episode 3, policy loss 1.1533377170562744\n",
      "\n",
      "episode 4, policy loss 1.177932620048523\n",
      "\n",
      "episode 5, policy loss 1.5209511518478394\n",
      "\n",
      "episode 6, policy loss 1.2138481140136719\n",
      "\n",
      "episode 7, policy loss 0.9402512311935425\n",
      "\n",
      "episode 8, policy loss 1.1372954845428467\n",
      "\n",
      "episode 9, policy loss 1.4141385555267334\n",
      "\n",
      "episode 10, policy loss 1.5367345809936523\n",
      "\n",
      "episode 11, policy loss 0.8473941683769226\n",
      "\n",
      "episode 12, policy loss 1.2979928255081177\n",
      "\n",
      "episode 13, policy loss 1.142301082611084\n",
      "\n",
      "episode 14, policy loss 0.8703709244728088\n",
      "\n",
      "episode 15, policy loss 1.2394309043884277\n",
      "\n",
      "episode 16, policy loss 0.9294412136077881\n",
      "\n",
      "Policy train loss in epoch 1:1.1691799089312553\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.4141007661819458\n",
      "\n",
      "episode 2, policy loss 1.1423276662826538\n",
      "\n",
      "episode 3, policy loss 1.2979681491851807\n",
      "\n",
      "episode 4, policy loss 1.213853120803833\n",
      "\n",
      "episode 5, policy loss 0.929410457611084\n",
      "\n",
      "episode 6, policy loss 1.1372414827346802\n",
      "\n",
      "episode 7, policy loss 1.5366593599319458\n",
      "\n",
      "episode 8, policy loss 1.0478332042694092\n",
      "\n",
      "episode 9, policy loss 1.5210227966308594\n",
      "\n",
      "episode 10, policy loss 1.1534186601638794\n",
      "\n",
      "episode 11, policy loss 1.1779054403305054\n",
      "\n",
      "episode 12, policy loss 1.2379471063613892\n",
      "\n",
      "episode 13, policy loss 0.9400489926338196\n",
      "\n",
      "episode 14, policy loss 0.8470810055732727\n",
      "\n",
      "episode 15, policy loss 1.2390466928482056\n",
      "\n",
      "episode 16, policy loss 0.869853138923645\n",
      "\n",
      "Policy train loss in epoch 2:1.1691073775291443\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.2975300550460815\n",
      "\n",
      "episode 2, policy loss 1.5205856561660767\n",
      "\n",
      "episode 3, policy loss 0.9287176132202148\n",
      "\n",
      "episode 4, policy loss 1.1366914510726929\n",
      "\n",
      "episode 5, policy loss 1.1527646780014038\n",
      "\n",
      "episode 6, policy loss 1.1771502494812012\n",
      "\n",
      "episode 7, policy loss 1.2370758056640625\n",
      "\n",
      "episode 8, policy loss 1.2381359338760376\n",
      "\n",
      "episode 9, policy loss 1.5356812477111816\n",
      "\n",
      "episode 10, policy loss 1.0464191436767578\n",
      "\n",
      "episode 11, policy loss 0.938639760017395\n",
      "\n",
      "episode 12, policy loss 1.1402556896209717\n",
      "\n",
      "episode 13, policy loss 0.8452700972557068\n",
      "\n",
      "episode 14, policy loss 1.2109153270721436\n",
      "\n",
      "episode 15, policy loss 0.866173267364502\n",
      "\n",
      "episode 16, policy loss 1.4102028608322144\n",
      "\n",
      "Policy train loss in epoch 3:1.1676380522549152\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 5.760438442230225\n",
      "\n",
      "episode 2, val func loss 5.644274711608887\n",
      "\n",
      "episode 3, val func loss 4.781234264373779\n",
      "\n",
      "episode 4, val func loss 5.190908908843994\n",
      "\n",
      "episode 5, val func loss 4.831579685211182\n",
      "\n",
      "episode 6, val func loss 4.138699054718018\n",
      "\n",
      "episode 7, val func loss 5.937800407409668\n",
      "\n",
      "episode 8, val func loss 5.94660758972168\n",
      "\n",
      "episode 9, val func loss 4.984959602355957\n",
      "\n",
      "episode 10, val func loss 4.53542423248291\n",
      "\n",
      "episode 11, val func loss 4.576101779937744\n",
      "\n",
      "episode 12, val func loss 5.363064289093018\n",
      "\n",
      "episode 13, val func loss 5.8279924392700195\n",
      "\n",
      "episode 14, val func loss 5.3563337326049805\n",
      "\n",
      "episode 15, val func loss 4.809051036834717\n",
      "\n",
      "episode 16, val func loss 5.202123165130615\n",
      "\n",
      "Val func train loss in epoch 0:5.180412083864212\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 4.902464389801025\n",
      "\n",
      "episode 2, val func loss 6.08217191696167\n",
      "\n",
      "episode 3, val func loss 5.418631553649902\n",
      "\n",
      "episode 4, val func loss 5.0679931640625\n",
      "\n",
      "episode 5, val func loss 4.467660903930664\n",
      "\n",
      "episode 6, val func loss 5.611526012420654\n",
      "\n",
      "episode 7, val func loss 4.929920673370361\n",
      "\n",
      "episode 8, val func loss 4.4508442878723145\n",
      "\n",
      "episode 9, val func loss 4.638808727264404\n",
      "\n",
      "episode 10, val func loss 4.9639573097229\n",
      "\n",
      "episode 11, val func loss 4.748917579650879\n",
      "\n",
      "episode 12, val func loss 5.020005702972412\n",
      "\n",
      "episode 13, val func loss 6.236577033996582\n",
      "\n",
      "episode 14, val func loss 4.377895355224609\n",
      "\n",
      "episode 15, val func loss 4.913362503051758\n",
      "\n",
      "episode 16, val func loss 4.596146583557129\n",
      "\n",
      "Val func train loss in epoch 1:5.02668023109436\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 5.845268249511719\n",
      "\n",
      "episode 2, val func loss 5.80175256729126\n",
      "\n",
      "episode 3, val func loss 4.875296592712402\n",
      "\n",
      "episode 4, val func loss 4.9278564453125\n",
      "\n",
      "episode 5, val func loss 4.994743347167969\n",
      "\n",
      "episode 6, val func loss 5.361830234527588\n",
      "\n",
      "episode 7, val func loss 4.7342329025268555\n",
      "\n",
      "episode 8, val func loss 6.217283248901367\n",
      "\n",
      "episode 9, val func loss 4.480823040008545\n",
      "\n",
      "episode 10, val func loss 4.833955764770508\n",
      "\n",
      "episode 11, val func loss 4.362696647644043\n",
      "\n",
      "episode 12, val func loss 4.696485996246338\n",
      "\n",
      "episode 13, val func loss 5.072105407714844\n",
      "\n",
      "episode 14, val func loss 4.593154430389404\n",
      "\n",
      "episode 15, val func loss 4.6051344871521\n",
      "\n",
      "episode 16, val func loss 5.092878341674805\n",
      "\n",
      "Val func train loss in epoch 2:5.030968606472015\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 4.84890604019165\n",
      "\n",
      "episode 2, val func loss 5.9356184005737305\n",
      "\n",
      "episode 3, val func loss 4.702166557312012\n",
      "\n",
      "episode 4, val func loss 4.1103620529174805\n",
      "\n",
      "episode 5, val func loss 5.966242790222168\n",
      "\n",
      "episode 6, val func loss 4.850072383880615\n",
      "\n",
      "episode 7, val func loss 5.2199177742004395\n",
      "\n",
      "episode 8, val func loss 4.403010368347168\n",
      "\n",
      "episode 9, val func loss 4.387954235076904\n",
      "\n",
      "episode 10, val func loss 4.9752678871154785\n",
      "\n",
      "episode 11, val func loss 5.052850246429443\n",
      "\n",
      "episode 12, val func loss 4.605042934417725\n",
      "\n",
      "episode 13, val func loss 5.442403316497803\n",
      "\n",
      "episode 14, val func loss 5.066577911376953\n",
      "\n",
      "episode 15, val func loss 4.739928722381592\n",
      "\n",
      "episode 16, val func loss 5.725095272064209\n",
      "\n",
      "Val func train loss in epoch 3:5.001963555812836\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 5.667661190032959\n",
      "\n",
      "episode 2, val func loss 4.826591491699219\n",
      "\n",
      "episode 3, val func loss 5.280966758728027\n",
      "\n",
      "episode 4, val func loss 4.776659965515137\n",
      "\n",
      "episode 5, val func loss 5.035059452056885\n",
      "\n",
      "episode 6, val func loss 5.9929518699646\n",
      "\n",
      "episode 7, val func loss 5.455288410186768\n",
      "\n",
      "episode 8, val func loss 4.627792835235596\n",
      "\n",
      "episode 9, val func loss 4.735568523406982\n",
      "\n",
      "episode 10, val func loss 4.713719844818115\n",
      "\n",
      "episode 11, val func loss 4.5073699951171875\n",
      "\n",
      "episode 12, val func loss 5.223527908325195\n",
      "\n",
      "episode 13, val func loss 5.166113376617432\n",
      "\n",
      "episode 14, val func loss 6.188582897186279\n",
      "\n",
      "episode 15, val func loss 5.008370399475098\n",
      "\n",
      "episode 16, val func loss 4.196406364440918\n",
      "\n",
      "Val func train loss in epoch 4:5.0876644551754\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 4.686346530914307\n",
      "\n",
      "episode 2, val func loss 5.031986713409424\n",
      "\n",
      "episode 3, val func loss 6.251043796539307\n",
      "\n",
      "episode 4, val func loss 4.723627090454102\n",
      "\n",
      "episode 5, val func loss 4.865318775177002\n",
      "\n",
      "episode 6, val func loss 5.17038106918335\n",
      "\n",
      "episode 7, val func loss 4.805232048034668\n",
      "\n",
      "episode 8, val func loss 5.108520030975342\n",
      "\n",
      "episode 9, val func loss 4.871235370635986\n",
      "\n",
      "episode 10, val func loss 6.122775077819824\n",
      "\n",
      "episode 11, val func loss 5.297792434692383\n",
      "\n",
      "episode 12, val func loss 4.9714579582214355\n",
      "\n",
      "episode 13, val func loss 4.408320426940918\n",
      "\n",
      "episode 14, val func loss 4.7605814933776855\n",
      "\n",
      "episode 15, val func loss 5.085983753204346\n",
      "\n",
      "episode 16, val func loss 4.053431510925293\n",
      "\n",
      "Val func train loss in epoch 5:5.013377130031586\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 4.525686740875244\n",
      "\n",
      "episode 2, val func loss 5.022053241729736\n",
      "\n",
      "episode 3, val func loss 5.69019079208374\n",
      "\n",
      "episode 4, val func loss 4.369036674499512\n",
      "\n",
      "episode 5, val func loss 4.395355224609375\n",
      "\n",
      "episode 6, val func loss 4.73059606552124\n",
      "\n",
      "episode 7, val func loss 4.7701873779296875\n",
      "\n",
      "episode 8, val func loss 5.368042945861816\n",
      "\n",
      "episode 9, val func loss 5.104764938354492\n",
      "\n",
      "episode 10, val func loss 5.352015018463135\n",
      "\n",
      "episode 11, val func loss 4.964549541473389\n",
      "\n",
      "episode 12, val func loss 5.862951755523682\n",
      "\n",
      "episode 13, val func loss 5.996501922607422\n",
      "\n",
      "episode 14, val func loss 5.077877044677734\n",
      "\n",
      "episode 15, val func loss 4.776659965515137\n",
      "\n",
      "episode 16, val func loss 5.159287452697754\n",
      "\n",
      "Val func train loss in epoch 6:5.0728597939014435\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 5.687455177307129\n",
      "\n",
      "episode 2, val func loss 5.107707977294922\n",
      "\n",
      "episode 3, val func loss 5.043039798736572\n",
      "\n",
      "episode 4, val func loss 4.561032295227051\n",
      "\n",
      "episode 5, val func loss 4.953520774841309\n",
      "\n",
      "episode 6, val func loss 5.214082717895508\n",
      "\n",
      "episode 7, val func loss 4.513142108917236\n",
      "\n",
      "episode 8, val func loss 6.112217426300049\n",
      "\n",
      "episode 9, val func loss 4.7741851806640625\n",
      "\n",
      "episode 10, val func loss 4.699799537658691\n",
      "\n",
      "episode 11, val func loss 5.04478645324707\n",
      "\n",
      "episode 12, val func loss 6.46102237701416\n",
      "\n",
      "episode 13, val func loss 4.22134256362915\n",
      "\n",
      "episode 14, val func loss 5.066577911376953\n",
      "\n",
      "episode 15, val func loss 4.9889726638793945\n",
      "\n",
      "episode 16, val func loss 4.766924858093262\n",
      "\n",
      "Val func train loss in epoch 7:5.0759881138801575\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 4.7621049880981445\n",
      "\n",
      "episode 2, val func loss 4.854310512542725\n",
      "\n",
      "episode 3, val func loss 6.102974891662598\n",
      "\n",
      "episode 4, val func loss 5.156125545501709\n",
      "\n",
      "episode 5, val func loss 5.303669452667236\n",
      "\n",
      "episode 6, val func loss 4.9675703048706055\n",
      "\n",
      "episode 7, val func loss 4.9930009841918945\n",
      "\n",
      "episode 8, val func loss 5.068016052246094\n",
      "\n",
      "episode 9, val func loss 4.0658674240112305\n",
      "\n",
      "episode 10, val func loss 6.115138053894043\n",
      "\n",
      "episode 11, val func loss 4.745065689086914\n",
      "\n",
      "episode 12, val func loss 6.125893592834473\n",
      "\n",
      "episode 13, val func loss 4.397348880767822\n",
      "\n",
      "episode 14, val func loss 5.13288688659668\n",
      "\n",
      "episode 15, val func loss 5.1300883293151855\n",
      "\n",
      "episode 16, val func loss 4.602611541748047\n",
      "\n",
      "Val func train loss in epoch 8:5.0951670706272125\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 4.768959999084473\n",
      "\n",
      "episode 2, val func loss 4.784657001495361\n",
      "\n",
      "episode 3, val func loss 5.226680755615234\n",
      "\n",
      "episode 4, val func loss 6.31032133102417\n",
      "\n",
      "episode 5, val func loss 5.208254814147949\n",
      "\n",
      "episode 6, val func loss 5.231204032897949\n",
      "\n",
      "episode 7, val func loss 4.403961181640625\n",
      "\n",
      "episode 8, val func loss 5.649639129638672\n",
      "\n",
      "episode 9, val func loss 4.135040283203125\n",
      "\n",
      "episode 10, val func loss 4.645860195159912\n",
      "\n",
      "episode 11, val func loss 4.970212936401367\n",
      "\n",
      "episode 12, val func loss 5.384665012359619\n",
      "\n",
      "episode 13, val func loss 6.619051933288574\n",
      "\n",
      "episode 14, val func loss 4.715051174163818\n",
      "\n",
      "episode 15, val func loss 5.01591157913208\n",
      "\n",
      "episode 16, val func loss 5.000000953674316\n",
      "\n",
      "Val func train loss in epoch 9:5.129342019557953\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 4.99780797958374\n",
      "\n",
      "episode 2, val func loss 4.5887861251831055\n",
      "\n",
      "episode 3, val func loss 5.7705979347229\n",
      "\n",
      "episode 4, val func loss 6.001177787780762\n",
      "\n",
      "episode 5, val func loss 5.2554030418396\n",
      "\n",
      "episode 6, val func loss 5.101078510284424\n",
      "\n",
      "episode 7, val func loss 4.676796913146973\n",
      "\n",
      "episode 8, val func loss 4.495274543762207\n",
      "\n",
      "episode 9, val func loss 4.341592788696289\n",
      "\n",
      "episode 10, val func loss 5.29158353805542\n",
      "\n",
      "episode 11, val func loss 5.320415496826172\n",
      "\n",
      "episode 12, val func loss 4.905203342437744\n",
      "\n",
      "episode 13, val func loss 4.962307453155518\n",
      "\n",
      "episode 14, val func loss 4.799112319946289\n",
      "\n",
      "episode 15, val func loss 6.341156005859375\n",
      "\n",
      "episode 16, val func loss 4.86353063583374\n",
      "\n",
      "Val func train loss in epoch 10:5.106989026069641\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 4.693082332611084\n",
      "\n",
      "episode 2, val func loss 4.777985572814941\n",
      "\n",
      "episode 3, val func loss 4.579190731048584\n",
      "\n",
      "episode 4, val func loss 5.358804702758789\n",
      "\n",
      "episode 5, val func loss 5.798807144165039\n",
      "\n",
      "episode 6, val func loss 5.4480791091918945\n",
      "\n",
      "episode 7, val func loss 4.796322822570801\n",
      "\n",
      "episode 8, val func loss 6.685519218444824\n",
      "\n",
      "episode 9, val func loss 5.097742557525635\n",
      "\n",
      "episode 10, val func loss 4.894837379455566\n",
      "\n",
      "episode 11, val func loss 4.890008926391602\n",
      "\n",
      "episode 12, val func loss 5.274603843688965\n",
      "\n",
      "episode 13, val func loss 6.044501304626465\n",
      "\n",
      "episode 14, val func loss 5.206324577331543\n",
      "\n",
      "episode 15, val func loss 5.296564102172852\n",
      "\n",
      "episode 16, val func loss 5.5493879318237305\n",
      "\n",
      "Val func train loss in epoch 11:5.274485141038895\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 5.054605484008789\n",
      "\n",
      "episode 2, val func loss 5.42154598236084\n",
      "\n",
      "episode 3, val func loss 5.492236614227295\n",
      "\n",
      "episode 4, val func loss 6.098875522613525\n",
      "\n",
      "episode 5, val func loss 5.1331329345703125\n",
      "\n",
      "episode 6, val func loss 6.304368495941162\n",
      "\n",
      "episode 7, val func loss 5.848824501037598\n",
      "\n",
      "episode 8, val func loss 5.4589643478393555\n",
      "\n",
      "episode 9, val func loss 5.416899681091309\n",
      "\n",
      "episode 10, val func loss 4.417291164398193\n",
      "\n",
      "episode 11, val func loss 4.365757465362549\n",
      "\n",
      "episode 12, val func loss 5.363051414489746\n",
      "\n",
      "episode 13, val func loss 4.9116387367248535\n",
      "\n",
      "episode 14, val func loss 5.8956804275512695\n",
      "\n",
      "episode 15, val func loss 5.280064105987549\n",
      "\n",
      "episode 16, val func loss 5.6076130867004395\n",
      "\n",
      "Val func train loss in epoch 12:5.379409372806549\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 5.189178466796875\n",
      "\n",
      "episode 2, val func loss 5.640856742858887\n",
      "\n",
      "episode 3, val func loss 4.7480854988098145\n",
      "\n",
      "episode 4, val func loss 5.180999755859375\n",
      "\n",
      "episode 5, val func loss 5.230000019073486\n",
      "\n",
      "episode 6, val func loss 4.669025897979736\n",
      "\n",
      "episode 7, val func loss 4.344180107116699\n",
      "\n",
      "episode 8, val func loss 4.597920894622803\n",
      "\n",
      "episode 9, val func loss 4.498846530914307\n",
      "\n",
      "episode 10, val func loss 5.583468437194824\n",
      "\n",
      "episode 11, val func loss 4.685999870300293\n",
      "\n",
      "episode 12, val func loss 5.073392868041992\n",
      "\n",
      "episode 13, val func loss 6.188479423522949\n",
      "\n",
      "episode 14, val func loss 5.513276100158691\n",
      "\n",
      "episode 15, val func loss 6.392009258270264\n",
      "\n",
      "episode 16, val func loss 5.4446234703063965\n",
      "\n",
      "Val func train loss in epoch 13:5.186271458864212\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 5.941661834716797\n",
      "\n",
      "episode 2, val func loss 5.248330116271973\n",
      "\n",
      "episode 3, val func loss 5.333764553070068\n",
      "\n",
      "episode 4, val func loss 5.31100606918335\n",
      "\n",
      "episode 5, val func loss 5.242336750030518\n",
      "\n",
      "episode 6, val func loss 4.87841272354126\n",
      "\n",
      "episode 7, val func loss 5.469147205352783\n",
      "\n",
      "episode 8, val func loss 5.1307806968688965\n",
      "\n",
      "episode 9, val func loss 5.229037284851074\n",
      "\n",
      "episode 10, val func loss 6.689121723175049\n",
      "\n",
      "episode 11, val func loss 5.250629901885986\n",
      "\n",
      "episode 12, val func loss 4.27316951751709\n",
      "\n",
      "episode 13, val func loss 4.829195022583008\n",
      "\n",
      "episode 14, val func loss 5.135799407958984\n",
      "\n",
      "episode 15, val func loss 5.5995635986328125\n",
      "\n",
      "episode 16, val func loss 5.893174171447754\n",
      "\n",
      "Val func train loss in epoch 14:5.340945661067963\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 5.480490207672119\n",
      "\n",
      "episode 2, val func loss 5.876496315002441\n",
      "\n",
      "episode 3, val func loss 5.066070556640625\n",
      "\n",
      "episode 4, val func loss 5.626467704772949\n",
      "\n",
      "episode 5, val func loss 4.837810516357422\n",
      "\n",
      "episode 6, val func loss 4.4937872886657715\n",
      "\n",
      "episode 7, val func loss 4.692529678344727\n",
      "\n",
      "episode 8, val func loss 4.068436622619629\n",
      "\n",
      "episode 9, val func loss 4.797106742858887\n",
      "\n",
      "episode 10, val func loss 5.209540843963623\n",
      "\n",
      "episode 11, val func loss 5.133986949920654\n",
      "\n",
      "episode 12, val func loss 4.786679744720459\n",
      "\n",
      "episode 13, val func loss 6.295330047607422\n",
      "\n",
      "episode 14, val func loss 4.490673542022705\n",
      "\n",
      "episode 15, val func loss 5.104303359985352\n",
      "\n",
      "episode 16, val func loss 5.371890544891357\n",
      "\n",
      "Val func train loss in epoch 15:5.083225041627884\n",
      "***********************TIME WAS 4.935288862387339 min*****************************\n",
      "\n",
      "**********************ROUND 144 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss -0.8561671376228333\n",
      "\n",
      "episode 2, policy loss -1.0076967477798462\n",
      "\n",
      "episode 3, policy loss -0.95575350522995\n",
      "\n",
      "episode 4, policy loss -0.9836583733558655\n",
      "\n",
      "episode 5, policy loss -0.9858396053314209\n",
      "\n",
      "episode 6, policy loss -1.0123813152313232\n",
      "\n",
      "episode 7, policy loss -0.9876267910003662\n",
      "\n",
      "episode 8, policy loss -0.9619191288948059\n",
      "\n",
      "episode 9, policy loss -0.9625095725059509\n",
      "\n",
      "episode 10, policy loss -0.9873164892196655\n",
      "\n",
      "episode 11, policy loss -1.0140830278396606\n",
      "\n",
      "episode 12, policy loss -0.9875469207763672\n",
      "\n",
      "episode 13, policy loss -0.9335660338401794\n",
      "\n",
      "episode 14, policy loss -0.9367037415504456\n",
      "\n",
      "episode 15, policy loss -0.9637900590896606\n",
      "\n",
      "episode 16, policy loss -0.9601759910583496\n",
      "\n",
      "Policy train loss in epoch 0:-0.9685459025204182\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss -0.9892796277999878\n",
      "\n",
      "episode 2, policy loss -0.9608076214790344\n",
      "\n",
      "episode 3, policy loss -0.963370680809021\n",
      "\n",
      "episode 4, policy loss -1.0147373676300049\n",
      "\n",
      "episode 5, policy loss -1.0148144960403442\n",
      "\n",
      "episode 6, policy loss -0.9640984535217285\n",
      "\n",
      "episode 7, policy loss -0.9371065497398376\n",
      "\n",
      "episode 8, policy loss -0.8826011419296265\n",
      "\n",
      "episode 9, policy loss -0.9891707301139832\n",
      "\n",
      "episode 10, policy loss -1.0149098634719849\n",
      "\n",
      "episode 11, policy loss -0.9605374932289124\n",
      "\n",
      "episode 12, policy loss -0.988275945186615\n",
      "\n",
      "episode 13, policy loss -0.9341689944267273\n",
      "\n",
      "episode 14, policy loss -0.9638591408729553\n",
      "\n",
      "episode 15, policy loss -0.9884748458862305\n",
      "\n",
      "episode 16, policy loss -0.9879842400550842\n",
      "\n",
      "Policy train loss in epoch 1:-0.9721373245120049\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss -0.9883683919906616\n",
      "\n",
      "episode 2, policy loss -0.8827418088912964\n",
      "\n",
      "episode 3, policy loss -0.9896514415740967\n",
      "\n",
      "episode 4, policy loss -0.9885238409042358\n",
      "\n",
      "episode 5, policy loss -0.9643062353134155\n",
      "\n",
      "episode 6, policy loss -0.9606330394744873\n",
      "\n",
      "episode 7, policy loss -0.9636863470077515\n",
      "\n",
      "episode 8, policy loss -0.9880504012107849\n",
      "\n",
      "episode 9, policy loss -1.0150651931762695\n",
      "\n",
      "episode 10, policy loss -0.9611560106277466\n",
      "\n",
      "episode 11, policy loss -0.9372997283935547\n",
      "\n",
      "episode 12, policy loss -0.9342875480651855\n",
      "\n",
      "episode 13, policy loss -1.0150699615478516\n",
      "\n",
      "episode 14, policy loss -0.9893354773521423\n",
      "\n",
      "episode 15, policy loss -0.9639663696289062\n",
      "\n",
      "episode 16, policy loss -1.0150855779647827\n",
      "\n",
      "Policy train loss in epoch 2:-0.9723267108201981\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss -1.0150889158248901\n",
      "\n",
      "episode 2, policy loss -0.9637329578399658\n",
      "\n",
      "episode 3, policy loss -0.9606756567955017\n",
      "\n",
      "episode 4, policy loss -0.9884783625602722\n",
      "\n",
      "episode 5, policy loss -0.9880785346031189\n",
      "\n",
      "episode 6, policy loss -0.9343210458755493\n",
      "\n",
      "episode 7, policy loss -1.015113353729248\n",
      "\n",
      "episode 8, policy loss -0.9640140533447266\n",
      "\n",
      "episode 9, policy loss -1.015107274055481\n",
      "\n",
      "episode 10, policy loss -0.9643869996070862\n",
      "\n",
      "episode 11, policy loss -0.8828469514846802\n",
      "\n",
      "episode 12, policy loss -0.9886218905448914\n",
      "\n",
      "episode 13, policy loss -0.98977130651474\n",
      "\n",
      "episode 14, policy loss -0.9893862009048462\n",
      "\n",
      "episode 15, policy loss -0.9612289667129517\n",
      "\n",
      "episode 16, policy loss -0.9373776912689209\n",
      "\n",
      "Policy train loss in epoch 3:-0.9723893851041794\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 3.566441059112549\n",
      "\n",
      "episode 2, val func loss 2.735927104949951\n",
      "\n",
      "episode 3, val func loss 2.1659786701202393\n",
      "\n",
      "episode 4, val func loss 1.5566426515579224\n",
      "\n",
      "episode 5, val func loss 1.063929796218872\n",
      "\n",
      "episode 6, val func loss 1.4207687377929688\n",
      "\n",
      "episode 7, val func loss 1.910394310951233\n",
      "\n",
      "episode 8, val func loss 1.47236168384552\n",
      "\n",
      "episode 9, val func loss 1.5433217287063599\n",
      "\n",
      "episode 10, val func loss 1.3908787965774536\n",
      "\n",
      "episode 11, val func loss 1.7484244108200073\n",
      "\n",
      "episode 12, val func loss 1.0987956523895264\n",
      "\n",
      "episode 13, val func loss 1.2080127000808716\n",
      "\n",
      "episode 14, val func loss 1.0957635641098022\n",
      "\n",
      "episode 15, val func loss 1.0523484945297241\n",
      "\n",
      "episode 16, val func loss 1.1811693906784058\n",
      "\n",
      "Val func train loss in epoch 0:1.638197422027588\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.5081274509429932\n",
      "\n",
      "episode 2, val func loss 1.3290008306503296\n",
      "\n",
      "episode 3, val func loss 1.0969232320785522\n",
      "\n",
      "episode 4, val func loss 1.3746085166931152\n",
      "\n",
      "episode 5, val func loss 0.9206808805465698\n",
      "\n",
      "episode 6, val func loss 0.8480854034423828\n",
      "\n",
      "episode 7, val func loss 0.9688311219215393\n",
      "\n",
      "episode 8, val func loss 1.0650321245193481\n",
      "\n",
      "episode 9, val func loss 0.8443016409873962\n",
      "\n",
      "episode 10, val func loss 1.107273817062378\n",
      "\n",
      "episode 11, val func loss 0.9500699639320374\n",
      "\n",
      "episode 12, val func loss 1.1775314807891846\n",
      "\n",
      "episode 13, val func loss 1.18453049659729\n",
      "\n",
      "episode 14, val func loss 0.9583907723426819\n",
      "\n",
      "episode 15, val func loss 0.9914823770523071\n",
      "\n",
      "episode 16, val func loss 0.8953593969345093\n",
      "\n",
      "Val func train loss in epoch 1:1.0762643441557884\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.01716148853302\n",
      "\n",
      "episode 2, val func loss 1.0939068794250488\n",
      "\n",
      "episode 3, val func loss 0.9289064407348633\n",
      "\n",
      "episode 4, val func loss 1.214942455291748\n",
      "\n",
      "episode 5, val func loss 0.9080770015716553\n",
      "\n",
      "episode 6, val func loss 0.8066670298576355\n",
      "\n",
      "episode 7, val func loss 0.7968101501464844\n",
      "\n",
      "episode 8, val func loss 0.9375789761543274\n",
      "\n",
      "episode 9, val func loss 0.8761534094810486\n",
      "\n",
      "episode 10, val func loss 0.8690641522407532\n",
      "\n",
      "episode 11, val func loss 1.0136938095092773\n",
      "\n",
      "episode 12, val func loss 0.7065544128417969\n",
      "\n",
      "episode 13, val func loss 0.8734571933746338\n",
      "\n",
      "episode 14, val func loss 0.8357241153717041\n",
      "\n",
      "episode 15, val func loss 1.371191143989563\n",
      "\n",
      "episode 16, val func loss 0.7093569040298462\n",
      "\n",
      "Val func train loss in epoch 2:0.9349528476595879\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6703718900680542\n",
      "\n",
      "episode 2, val func loss 0.6499102115631104\n",
      "\n",
      "episode 3, val func loss 0.7784783840179443\n",
      "\n",
      "episode 4, val func loss 0.8654269576072693\n",
      "\n",
      "episode 5, val func loss 1.0899202823638916\n",
      "\n",
      "episode 6, val func loss 1.2144410610198975\n",
      "\n",
      "episode 7, val func loss 0.7872148752212524\n",
      "\n",
      "episode 8, val func loss 0.822327196598053\n",
      "\n",
      "episode 9, val func loss 0.7298394441604614\n",
      "\n",
      "episode 10, val func loss 0.9116278886795044\n",
      "\n",
      "episode 11, val func loss 0.7775685787200928\n",
      "\n",
      "episode 12, val func loss 0.7430434226989746\n",
      "\n",
      "episode 13, val func loss 1.0277293920516968\n",
      "\n",
      "episode 14, val func loss 0.9939788579940796\n",
      "\n",
      "episode 15, val func loss 0.8867121338844299\n",
      "\n",
      "episode 16, val func loss 0.8393586277961731\n",
      "\n",
      "Val func train loss in epoch 3:0.8617468252778053\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.8499684929847717\n",
      "\n",
      "episode 2, val func loss 0.8483350276947021\n",
      "\n",
      "episode 3, val func loss 0.7849519848823547\n",
      "\n",
      "episode 4, val func loss 0.6772357225418091\n",
      "\n",
      "episode 5, val func loss 0.7025951743125916\n",
      "\n",
      "episode 6, val func loss 0.7221600413322449\n",
      "\n",
      "episode 7, val func loss 0.7722496390342712\n",
      "\n",
      "episode 8, val func loss 0.78593510389328\n",
      "\n",
      "episode 9, val func loss 0.6015884876251221\n",
      "\n",
      "episode 10, val func loss 0.8354467749595642\n",
      "\n",
      "episode 11, val func loss 0.971717357635498\n",
      "\n",
      "episode 12, val func loss 0.729820191860199\n",
      "\n",
      "episode 13, val func loss 1.1699541807174683\n",
      "\n",
      "episode 14, val func loss 1.0457042455673218\n",
      "\n",
      "episode 15, val func loss 1.1619292497634888\n",
      "\n",
      "episode 16, val func loss 0.6628196239471436\n",
      "\n",
      "Val func train loss in epoch 4:0.8326507061719894\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.6205078959465027\n",
      "\n",
      "episode 2, val func loss 0.933942973613739\n",
      "\n",
      "episode 3, val func loss 1.2084966897964478\n",
      "\n",
      "episode 4, val func loss 0.9720447659492493\n",
      "\n",
      "episode 5, val func loss 0.7585673928260803\n",
      "\n",
      "episode 6, val func loss 0.8335264325141907\n",
      "\n",
      "episode 7, val func loss 0.603248119354248\n",
      "\n",
      "episode 8, val func loss 0.8062413334846497\n",
      "\n",
      "episode 9, val func loss 0.8323286175727844\n",
      "\n",
      "episode 10, val func loss 0.7814794182777405\n",
      "\n",
      "episode 11, val func loss 0.8909820914268494\n",
      "\n",
      "episode 12, val func loss 0.9895422458648682\n",
      "\n",
      "episode 13, val func loss 0.6932621598243713\n",
      "\n",
      "episode 14, val func loss 1.0166536569595337\n",
      "\n",
      "episode 15, val func loss 0.8969660401344299\n",
      "\n",
      "episode 16, val func loss 0.7754920721054077\n",
      "\n",
      "Val func train loss in epoch 5:0.8508301191031933\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7234905362129211\n",
      "\n",
      "episode 2, val func loss 1.2214027643203735\n",
      "\n",
      "episode 3, val func loss 0.7353326678276062\n",
      "\n",
      "episode 4, val func loss 0.8389283418655396\n",
      "\n",
      "episode 5, val func loss 0.9154461026191711\n",
      "\n",
      "episode 6, val func loss 0.8270441889762878\n",
      "\n",
      "episode 7, val func loss 0.7819598913192749\n",
      "\n",
      "episode 8, val func loss 1.022993803024292\n",
      "\n",
      "episode 9, val func loss 0.706614077091217\n",
      "\n",
      "episode 10, val func loss 0.9504407048225403\n",
      "\n",
      "episode 11, val func loss 0.7344788312911987\n",
      "\n",
      "episode 12, val func loss 0.887521505355835\n",
      "\n",
      "episode 13, val func loss 0.9177489280700684\n",
      "\n",
      "episode 14, val func loss 0.6202385425567627\n",
      "\n",
      "episode 15, val func loss 0.6670164465904236\n",
      "\n",
      "episode 16, val func loss 0.7657052874565125\n",
      "\n",
      "Val func train loss in epoch 6:0.8322726637125015\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6946791410446167\n",
      "\n",
      "episode 2, val func loss 0.7957015633583069\n",
      "\n",
      "episode 3, val func loss 0.811583399772644\n",
      "\n",
      "episode 4, val func loss 0.9514734745025635\n",
      "\n",
      "episode 5, val func loss 0.6077688336372375\n",
      "\n",
      "episode 6, val func loss 1.042980432510376\n",
      "\n",
      "episode 7, val func loss 0.7476445436477661\n",
      "\n",
      "episode 8, val func loss 0.9956545233726501\n",
      "\n",
      "episode 9, val func loss 0.9719064235687256\n",
      "\n",
      "episode 10, val func loss 0.7479773759841919\n",
      "\n",
      "episode 11, val func loss 0.5903325080871582\n",
      "\n",
      "episode 12, val func loss 1.3167641162872314\n",
      "\n",
      "episode 13, val func loss 0.955295979976654\n",
      "\n",
      "episode 14, val func loss 0.79850172996521\n",
      "\n",
      "episode 15, val func loss 0.5771687030792236\n",
      "\n",
      "episode 16, val func loss 0.8652070164680481\n",
      "\n",
      "Val func train loss in epoch 7:0.8419149853289127\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.8516300320625305\n",
      "\n",
      "episode 2, val func loss 0.8037260174751282\n",
      "\n",
      "episode 3, val func loss 0.8759193420410156\n",
      "\n",
      "episode 4, val func loss 1.0599054098129272\n",
      "\n",
      "episode 5, val func loss 0.6133477687835693\n",
      "\n",
      "episode 6, val func loss 0.7241401672363281\n",
      "\n",
      "episode 7, val func loss 0.8742380738258362\n",
      "\n",
      "episode 8, val func loss 0.9939894080162048\n",
      "\n",
      "episode 9, val func loss 0.8364903330802917\n",
      "\n",
      "episode 10, val func loss 0.5485222935676575\n",
      "\n",
      "episode 11, val func loss 0.7695027589797974\n",
      "\n",
      "episode 12, val func loss 0.9513254761695862\n",
      "\n",
      "episode 13, val func loss 1.1833446025848389\n",
      "\n",
      "episode 14, val func loss 0.7113858461380005\n",
      "\n",
      "episode 15, val func loss 0.7315176129341125\n",
      "\n",
      "episode 16, val func loss 0.6617257595062256\n",
      "\n",
      "Val func train loss in epoch 8:0.8244194313883781\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.8614464998245239\n",
      "\n",
      "episode 2, val func loss 1.009595274925232\n",
      "\n",
      "episode 3, val func loss 0.7480648159980774\n",
      "\n",
      "episode 4, val func loss 0.7630401253700256\n",
      "\n",
      "episode 5, val func loss 0.9657807946205139\n",
      "\n",
      "episode 6, val func loss 0.732295036315918\n",
      "\n",
      "episode 7, val func loss 0.6898149251937866\n",
      "\n",
      "episode 8, val func loss 0.7766218781471252\n",
      "\n",
      "episode 9, val func loss 0.5266388654708862\n",
      "\n",
      "episode 10, val func loss 0.7788856625556946\n",
      "\n",
      "episode 11, val func loss 1.0429712533950806\n",
      "\n",
      "episode 12, val func loss 0.8676361441612244\n",
      "\n",
      "episode 13, val func loss 0.6679718494415283\n",
      "\n",
      "episode 14, val func loss 1.1996119022369385\n",
      "\n",
      "episode 15, val func loss 0.7033735513687134\n",
      "\n",
      "episode 16, val func loss 1.1059980392456055\n",
      "\n",
      "Val func train loss in epoch 9:0.8399841636419296\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.9809445142745972\n",
      "\n",
      "episode 2, val func loss 0.8974261283874512\n",
      "\n",
      "episode 3, val func loss 0.8270109295845032\n",
      "\n",
      "episode 4, val func loss 0.7333487868309021\n",
      "\n",
      "episode 5, val func loss 0.755946159362793\n",
      "\n",
      "episode 6, val func loss 0.8432199358940125\n",
      "\n",
      "episode 7, val func loss 0.9508681893348694\n",
      "\n",
      "episode 8, val func loss 0.9085809588432312\n",
      "\n",
      "episode 9, val func loss 0.7237223982810974\n",
      "\n",
      "episode 10, val func loss 0.8381272554397583\n",
      "\n",
      "episode 11, val func loss 1.2545950412750244\n",
      "\n",
      "episode 12, val func loss 0.9741612672805786\n",
      "\n",
      "episode 13, val func loss 1.1435550451278687\n",
      "\n",
      "episode 14, val func loss 0.7641482353210449\n",
      "\n",
      "episode 15, val func loss 0.8225159049034119\n",
      "\n",
      "episode 16, val func loss 0.6123226284980774\n",
      "\n",
      "Val func train loss in epoch 10:0.8769058361649513\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.949804425239563\n",
      "\n",
      "episode 2, val func loss 1.0820209980010986\n",
      "\n",
      "episode 3, val func loss 0.8213614821434021\n",
      "\n",
      "episode 4, val func loss 1.137988567352295\n",
      "\n",
      "episode 5, val func loss 0.8570918440818787\n",
      "\n",
      "episode 6, val func loss 0.6371361613273621\n",
      "\n",
      "episode 7, val func loss 0.8650436401367188\n",
      "\n",
      "episode 8, val func loss 0.7279995083808899\n",
      "\n",
      "episode 9, val func loss 0.8818895816802979\n",
      "\n",
      "episode 10, val func loss 0.9102742075920105\n",
      "\n",
      "episode 11, val func loss 0.8156736493110657\n",
      "\n",
      "episode 12, val func loss 0.9705203771591187\n",
      "\n",
      "episode 13, val func loss 1.0294969081878662\n",
      "\n",
      "episode 14, val func loss 1.1140711307525635\n",
      "\n",
      "episode 15, val func loss 0.9140351414680481\n",
      "\n",
      "episode 16, val func loss 1.2556651830673218\n",
      "\n",
      "Val func train loss in epoch 11:0.9356295503675938\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.332570195198059\n",
      "\n",
      "episode 2, val func loss 0.6019569039344788\n",
      "\n",
      "episode 3, val func loss 0.7218097448348999\n",
      "\n",
      "episode 4, val func loss 0.9400153160095215\n",
      "\n",
      "episode 5, val func loss 0.9272031784057617\n",
      "\n",
      "episode 6, val func loss 0.7150743007659912\n",
      "\n",
      "episode 7, val func loss 0.8842170834541321\n",
      "\n",
      "episode 8, val func loss 0.7065779566764832\n",
      "\n",
      "episode 9, val func loss 0.8809205889701843\n",
      "\n",
      "episode 10, val func loss 0.8591068387031555\n",
      "\n",
      "episode 11, val func loss 0.84587562084198\n",
      "\n",
      "episode 12, val func loss 0.767410397529602\n",
      "\n",
      "episode 13, val func loss 0.6144896745681763\n",
      "\n",
      "episode 14, val func loss 1.0127204656600952\n",
      "\n",
      "episode 15, val func loss 0.8967872262001038\n",
      "\n",
      "episode 16, val func loss 0.880656898021698\n",
      "\n",
      "Val func train loss in epoch 12:0.8492120243608952\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.903408408164978\n",
      "\n",
      "episode 2, val func loss 0.7899584770202637\n",
      "\n",
      "episode 3, val func loss 0.8197888135910034\n",
      "\n",
      "episode 4, val func loss 0.790054976940155\n",
      "\n",
      "episode 5, val func loss 0.7663587927818298\n",
      "\n",
      "episode 6, val func loss 0.9462928175926208\n",
      "\n",
      "episode 7, val func loss 0.914638102054596\n",
      "\n",
      "episode 8, val func loss 0.5844114422798157\n",
      "\n",
      "episode 9, val func loss 0.9115666151046753\n",
      "\n",
      "episode 10, val func loss 1.1453109979629517\n",
      "\n",
      "episode 11, val func loss 0.633710503578186\n",
      "\n",
      "episode 12, val func loss 0.9515709280967712\n",
      "\n",
      "episode 13, val func loss 0.6912719011306763\n",
      "\n",
      "episode 14, val func loss 0.6400310397148132\n",
      "\n",
      "episode 15, val func loss 0.7963330149650574\n",
      "\n",
      "episode 16, val func loss 0.6926313042640686\n",
      "\n",
      "Val func train loss in epoch 13:0.8110836334526539\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.901707649230957\n",
      "\n",
      "episode 2, val func loss 0.7494029998779297\n",
      "\n",
      "episode 3, val func loss 0.9934888482093811\n",
      "\n",
      "episode 4, val func loss 0.9235767126083374\n",
      "\n",
      "episode 5, val func loss 0.5592561960220337\n",
      "\n",
      "episode 6, val func loss 0.8050680756568909\n",
      "\n",
      "episode 7, val func loss 0.7973248958587646\n",
      "\n",
      "episode 8, val func loss 0.8498612642288208\n",
      "\n",
      "episode 9, val func loss 0.791144609451294\n",
      "\n",
      "episode 10, val func loss 0.693869948387146\n",
      "\n",
      "episode 11, val func loss 0.8341640830039978\n",
      "\n",
      "episode 12, val func loss 0.5792689323425293\n",
      "\n",
      "episode 13, val func loss 0.8544079661369324\n",
      "\n",
      "episode 14, val func loss 0.7056763768196106\n",
      "\n",
      "episode 15, val func loss 0.6750248670578003\n",
      "\n",
      "episode 16, val func loss 1.1507933139801025\n",
      "\n",
      "Val func train loss in epoch 14:0.804002296179533\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.9554651975631714\n",
      "\n",
      "episode 2, val func loss 0.557123601436615\n",
      "\n",
      "episode 3, val func loss 0.7980780005455017\n",
      "\n",
      "episode 4, val func loss 0.8255578875541687\n",
      "\n",
      "episode 5, val func loss 0.8328812122344971\n",
      "\n",
      "episode 6, val func loss 0.8393863439559937\n",
      "\n",
      "episode 7, val func loss 0.8088709712028503\n",
      "\n",
      "episode 8, val func loss 0.8015522360801697\n",
      "\n",
      "episode 9, val func loss 0.5443007349967957\n",
      "\n",
      "episode 10, val func loss 0.9575906991958618\n",
      "\n",
      "episode 11, val func loss 0.8748461008071899\n",
      "\n",
      "episode 12, val func loss 0.8325130939483643\n",
      "\n",
      "episode 13, val func loss 0.6592290997505188\n",
      "\n",
      "episode 14, val func loss 1.1819881200790405\n",
      "\n",
      "episode 15, val func loss 0.8781000375747681\n",
      "\n",
      "episode 16, val func loss 0.9403252005577087\n",
      "\n",
      "Val func train loss in epoch 15:0.830488033592701\n",
      "***********************TIME WAS 4.932689611117045 min*****************************\n",
      "\n",
      "**********************ROUND 145 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.0303523540496826\n",
      "\n",
      "episode 2, policy loss 1.030340313911438\n",
      "\n",
      "episode 3, policy loss 1.030354380607605\n",
      "\n",
      "episode 4, policy loss 1.0303574800491333\n",
      "\n",
      "episode 5, policy loss 1.0303540229797363\n",
      "\n",
      "episode 6, policy loss 1.0303599834442139\n",
      "\n",
      "episode 7, policy loss 1.0303529500961304\n",
      "\n",
      "episode 8, policy loss 1.030340552330017\n",
      "\n",
      "episode 9, policy loss 1.0303659439086914\n",
      "\n",
      "episode 10, policy loss 1.030351996421814\n",
      "\n",
      "episode 11, policy loss 1.0303462743759155\n",
      "\n",
      "episode 12, policy loss 1.0303552150726318\n",
      "\n",
      "episode 13, policy loss 1.0303415060043335\n",
      "\n",
      "episode 14, policy loss 1.0303555727005005\n",
      "\n",
      "episode 15, policy loss 1.0303524732589722\n",
      "\n",
      "episode 16, policy loss 1.0303380489349365\n",
      "\n",
      "Policy train loss in epoch 0:1.0303511917591095\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.0303477048873901\n",
      "\n",
      "episode 2, policy loss 1.030335783958435\n",
      "\n",
      "episode 3, policy loss 1.0303442478179932\n",
      "\n",
      "episode 4, policy loss 1.0303387641906738\n",
      "\n",
      "episode 5, policy loss 1.0303447246551514\n",
      "\n",
      "episode 6, policy loss 1.0303469896316528\n",
      "\n",
      "episode 7, policy loss 1.0303425788879395\n",
      "\n",
      "episode 8, policy loss 1.030334234237671\n",
      "\n",
      "episode 9, policy loss 1.0303363800048828\n",
      "\n",
      "episode 10, policy loss 1.0303243398666382\n",
      "\n",
      "episode 11, policy loss 1.0303170680999756\n",
      "\n",
      "episode 12, policy loss 1.0303138494491577\n",
      "\n",
      "episode 13, policy loss 1.0303316116333008\n",
      "\n",
      "episode 14, policy loss 1.0303239822387695\n",
      "\n",
      "episode 15, policy loss 1.030310034751892\n",
      "\n",
      "episode 16, policy loss 1.0303051471710205\n",
      "\n",
      "Policy train loss in epoch 1:1.030331090092659\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.0303258895874023\n",
      "\n",
      "episode 2, policy loss 1.0303089618682861\n",
      "\n",
      "episode 3, policy loss 1.0303019285202026\n",
      "\n",
      "episode 4, policy loss 1.030298113822937\n",
      "\n",
      "episode 5, policy loss 1.0302963256835938\n",
      "\n",
      "episode 6, policy loss 1.030280590057373\n",
      "\n",
      "episode 7, policy loss 1.0302906036376953\n",
      "\n",
      "episode 8, policy loss 1.030275583267212\n",
      "\n",
      "episode 9, policy loss 1.0302479267120361\n",
      "\n",
      "episode 10, policy loss 1.0302796363830566\n",
      "\n",
      "episode 11, policy loss 1.0302501916885376\n",
      "\n",
      "episode 12, policy loss 1.0302478075027466\n",
      "\n",
      "episode 13, policy loss 1.0302424430847168\n",
      "\n",
      "episode 14, policy loss 1.0302469730377197\n",
      "\n",
      "episode 15, policy loss 1.0302470922470093\n",
      "\n",
      "episode 16, policy loss 1.0302454233169556\n",
      "\n",
      "Policy train loss in epoch 2:1.0302740931510925\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.0302406549453735\n",
      "\n",
      "episode 2, policy loss 1.0302172899246216\n",
      "\n",
      "episode 3, policy loss 1.0302339792251587\n",
      "\n",
      "episode 4, policy loss 1.0302250385284424\n",
      "\n",
      "episode 5, policy loss 1.03021240234375\n",
      "\n",
      "episode 6, policy loss 1.0302083492279053\n",
      "\n",
      "episode 7, policy loss 1.0302196741104126\n",
      "\n",
      "episode 8, policy loss 1.0301657915115356\n",
      "\n",
      "episode 9, policy loss 1.0301735401153564\n",
      "\n",
      "episode 10, policy loss 1.030164122581482\n",
      "\n",
      "episode 11, policy loss 1.0301457643508911\n",
      "\n",
      "episode 12, policy loss 1.0301594734191895\n",
      "\n",
      "episode 13, policy loss 1.0301237106323242\n",
      "\n",
      "episode 14, policy loss 1.0301473140716553\n",
      "\n",
      "episode 15, policy loss 1.0301107168197632\n",
      "\n",
      "episode 16, policy loss 1.0300908088684082\n",
      "\n",
      "Policy train loss in epoch 3:1.0301774144172668\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.6012135744094849\n",
      "\n",
      "episode 2, val func loss 0.6354257464408875\n",
      "\n",
      "episode 3, val func loss 0.6577979922294617\n",
      "\n",
      "episode 4, val func loss 0.6358712315559387\n",
      "\n",
      "episode 5, val func loss 0.7755152583122253\n",
      "\n",
      "episode 6, val func loss 0.681252121925354\n",
      "\n",
      "episode 7, val func loss 0.6648944020271301\n",
      "\n",
      "episode 8, val func loss 0.6575788259506226\n",
      "\n",
      "episode 9, val func loss 0.645797848701477\n",
      "\n",
      "episode 10, val func loss 0.6657693386077881\n",
      "\n",
      "episode 11, val func loss 0.6611599922180176\n",
      "\n",
      "episode 12, val func loss 0.6545333862304688\n",
      "\n",
      "episode 13, val func loss 0.6123822927474976\n",
      "\n",
      "episode 14, val func loss 0.5950796604156494\n",
      "\n",
      "episode 15, val func loss 0.6554642915725708\n",
      "\n",
      "episode 16, val func loss 0.6837549209594727\n",
      "\n",
      "Val func train loss in epoch 0:0.6552181802690029\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.5124070644378662\n",
      "\n",
      "episode 2, val func loss 0.6438103318214417\n",
      "\n",
      "episode 3, val func loss 0.6433752179145813\n",
      "\n",
      "episode 4, val func loss 0.5335147976875305\n",
      "\n",
      "episode 5, val func loss 0.6623852252960205\n",
      "\n",
      "episode 6, val func loss 0.5908634662628174\n",
      "\n",
      "episode 7, val func loss 0.68243008852005\n",
      "\n",
      "episode 8, val func loss 0.6726808547973633\n",
      "\n",
      "episode 9, val func loss 0.6203014254570007\n",
      "\n",
      "episode 10, val func loss 0.5964374542236328\n",
      "\n",
      "episode 11, val func loss 0.5698380470275879\n",
      "\n",
      "episode 12, val func loss 0.6415246725082397\n",
      "\n",
      "episode 13, val func loss 0.6540670990943909\n",
      "\n",
      "episode 14, val func loss 0.5256911516189575\n",
      "\n",
      "episode 15, val func loss 0.6216917037963867\n",
      "\n",
      "episode 16, val func loss 0.6545386910438538\n",
      "\n",
      "Val func train loss in epoch 1:0.6140973307192326\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.6282578110694885\n",
      "\n",
      "episode 2, val func loss 0.6999964714050293\n",
      "\n",
      "episode 3, val func loss 0.6922826766967773\n",
      "\n",
      "episode 4, val func loss 0.6980755925178528\n",
      "\n",
      "episode 5, val func loss 0.6880291700363159\n",
      "\n",
      "episode 6, val func loss 0.617613673210144\n",
      "\n",
      "episode 7, val func loss 0.6652069091796875\n",
      "\n",
      "episode 8, val func loss 0.700761616230011\n",
      "\n",
      "episode 9, val func loss 0.5737103223800659\n",
      "\n",
      "episode 10, val func loss 0.5842612385749817\n",
      "\n",
      "episode 11, val func loss 0.6801279187202454\n",
      "\n",
      "episode 12, val func loss 0.6158783435821533\n",
      "\n",
      "episode 13, val func loss 0.7324844002723694\n",
      "\n",
      "episode 14, val func loss 0.7138286232948303\n",
      "\n",
      "episode 15, val func loss 0.6929380297660828\n",
      "\n",
      "episode 16, val func loss 0.6330701112747192\n",
      "\n",
      "Val func train loss in epoch 2:0.6635326817631721\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6586979031562805\n",
      "\n",
      "episode 2, val func loss 0.583139181137085\n",
      "\n",
      "episode 3, val func loss 0.7013273239135742\n",
      "\n",
      "episode 4, val func loss 0.6548731327056885\n",
      "\n",
      "episode 5, val func loss 0.6029828190803528\n",
      "\n",
      "episode 6, val func loss 0.5832192897796631\n",
      "\n",
      "episode 7, val func loss 0.5550521612167358\n",
      "\n",
      "episode 8, val func loss 0.5903952121734619\n",
      "\n",
      "episode 9, val func loss 0.7096972465515137\n",
      "\n",
      "episode 10, val func loss 0.7185024619102478\n",
      "\n",
      "episode 11, val func loss 0.6825237274169922\n",
      "\n",
      "episode 12, val func loss 0.5872780680656433\n",
      "\n",
      "episode 13, val func loss 0.5853849053382874\n",
      "\n",
      "episode 14, val func loss 0.5491478443145752\n",
      "\n",
      "episode 15, val func loss 0.633570671081543\n",
      "\n",
      "episode 16, val func loss 0.5475327372550964\n",
      "\n",
      "Val func train loss in epoch 3:0.6214577928185463\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.56918865442276\n",
      "\n",
      "episode 2, val func loss 0.6367976069450378\n",
      "\n",
      "episode 3, val func loss 0.6670970916748047\n",
      "\n",
      "episode 4, val func loss 0.6441410183906555\n",
      "\n",
      "episode 5, val func loss 0.629581868648529\n",
      "\n",
      "episode 6, val func loss 0.6142292022705078\n",
      "\n",
      "episode 7, val func loss 0.5827897787094116\n",
      "\n",
      "episode 8, val func loss 0.5340821743011475\n",
      "\n",
      "episode 9, val func loss 0.6208775043487549\n",
      "\n",
      "episode 10, val func loss 0.6202738285064697\n",
      "\n",
      "episode 11, val func loss 0.6541261672973633\n",
      "\n",
      "episode 12, val func loss 0.6325852870941162\n",
      "\n",
      "episode 13, val func loss 0.5841714143753052\n",
      "\n",
      "episode 14, val func loss 0.7067724466323853\n",
      "\n",
      "episode 15, val func loss 0.6894376873970032\n",
      "\n",
      "episode 16, val func loss 0.5743314623832703\n",
      "\n",
      "Val func train loss in epoch 4:0.6225301995873451\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.5438176989555359\n",
      "\n",
      "episode 2, val func loss 0.693824052810669\n",
      "\n",
      "episode 3, val func loss 0.5652484893798828\n",
      "\n",
      "episode 4, val func loss 0.592059314250946\n",
      "\n",
      "episode 5, val func loss 0.7451906800270081\n",
      "\n",
      "episode 6, val func loss 0.6678811311721802\n",
      "\n",
      "episode 7, val func loss 0.6369214653968811\n",
      "\n",
      "episode 8, val func loss 0.5940130352973938\n",
      "\n",
      "episode 9, val func loss 0.6495600938796997\n",
      "\n",
      "episode 10, val func loss 0.5999969244003296\n",
      "\n",
      "episode 11, val func loss 0.6768316030502319\n",
      "\n",
      "episode 12, val func loss 0.6391121745109558\n",
      "\n",
      "episode 13, val func loss 0.6413745880126953\n",
      "\n",
      "episode 14, val func loss 0.5514662265777588\n",
      "\n",
      "episode 15, val func loss 0.6297116875648499\n",
      "\n",
      "episode 16, val func loss 0.5425114035606384\n",
      "\n",
      "Val func train loss in epoch 5:0.6230950355529785\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.7375761866569519\n",
      "\n",
      "episode 2, val func loss 0.5509744882583618\n",
      "\n",
      "episode 3, val func loss 0.5688390135765076\n",
      "\n",
      "episode 4, val func loss 0.5898405313491821\n",
      "\n",
      "episode 5, val func loss 0.5523159503936768\n",
      "\n",
      "episode 6, val func loss 0.6528828144073486\n",
      "\n",
      "episode 7, val func loss 0.5592678189277649\n",
      "\n",
      "episode 8, val func loss 0.48640280961990356\n",
      "\n",
      "episode 9, val func loss 0.6459823250770569\n",
      "\n",
      "episode 10, val func loss 0.5748960971832275\n",
      "\n",
      "episode 11, val func loss 0.5642392039299011\n",
      "\n",
      "episode 12, val func loss 0.6063947677612305\n",
      "\n",
      "episode 13, val func loss 0.5954788327217102\n",
      "\n",
      "episode 14, val func loss 0.5209554433822632\n",
      "\n",
      "episode 15, val func loss 0.6385466456413269\n",
      "\n",
      "episode 16, val func loss 0.6108392477035522\n",
      "\n",
      "Val func train loss in epoch 6:0.5909645110368729\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6147990226745605\n",
      "\n",
      "episode 2, val func loss 0.6201848387718201\n",
      "\n",
      "episode 3, val func loss 0.5801096558570862\n",
      "\n",
      "episode 4, val func loss 0.6125954389572144\n",
      "\n",
      "episode 5, val func loss 0.5680248737335205\n",
      "\n",
      "episode 6, val func loss 0.5872529745101929\n",
      "\n",
      "episode 7, val func loss 0.6087720990180969\n",
      "\n",
      "episode 8, val func loss 0.5744597315788269\n",
      "\n",
      "episode 9, val func loss 0.5086959600448608\n",
      "\n",
      "episode 10, val func loss 0.5633220076560974\n",
      "\n",
      "episode 11, val func loss 0.6298215389251709\n",
      "\n",
      "episode 12, val func loss 0.6512423753738403\n",
      "\n",
      "episode 13, val func loss 0.6376684308052063\n",
      "\n",
      "episode 14, val func loss 0.5442572832107544\n",
      "\n",
      "episode 15, val func loss 0.5852068066596985\n",
      "\n",
      "episode 16, val func loss 0.5174077153205872\n",
      "\n",
      "Val func train loss in epoch 7:0.5877387970685959\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.613775908946991\n",
      "\n",
      "episode 2, val func loss 0.5668869614601135\n",
      "\n",
      "episode 3, val func loss 0.4776577353477478\n",
      "\n",
      "episode 4, val func loss 0.7982718348503113\n",
      "\n",
      "episode 5, val func loss 0.6519063711166382\n",
      "\n",
      "episode 6, val func loss 0.6202551126480103\n",
      "\n",
      "episode 7, val func loss 0.6720877289772034\n",
      "\n",
      "episode 8, val func loss 0.4951588213443756\n",
      "\n",
      "episode 9, val func loss 0.5682837963104248\n",
      "\n",
      "episode 10, val func loss 0.618042528629303\n",
      "\n",
      "episode 11, val func loss 0.6860020756721497\n",
      "\n",
      "episode 12, val func loss 0.6142538189888\n",
      "\n",
      "episode 13, val func loss 0.6170634627342224\n",
      "\n",
      "episode 14, val func loss 0.5498208999633789\n",
      "\n",
      "episode 15, val func loss 0.5568605661392212\n",
      "\n",
      "episode 16, val func loss 0.6173394322395325\n",
      "\n",
      "Val func train loss in epoch 8:0.6077291909605265\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.61761474609375\n",
      "\n",
      "episode 2, val func loss 0.5097296237945557\n",
      "\n",
      "episode 3, val func loss 0.46968722343444824\n",
      "\n",
      "episode 4, val func loss 0.5266311764717102\n",
      "\n",
      "episode 5, val func loss 0.5727232694625854\n",
      "\n",
      "episode 6, val func loss 0.5498256087303162\n",
      "\n",
      "episode 7, val func loss 0.5547021627426147\n",
      "\n",
      "episode 8, val func loss 0.5859212279319763\n",
      "\n",
      "episode 9, val func loss 0.5926819443702698\n",
      "\n",
      "episode 10, val func loss 0.6636053919792175\n",
      "\n",
      "episode 11, val func loss 0.5678182244300842\n",
      "\n",
      "episode 12, val func loss 0.7174961566925049\n",
      "\n",
      "episode 13, val func loss 0.637559711933136\n",
      "\n",
      "episode 14, val func loss 0.6709832549095154\n",
      "\n",
      "episode 15, val func loss 0.5766786336898804\n",
      "\n",
      "episode 16, val func loss 0.5653145909309387\n",
      "\n",
      "Val func train loss in epoch 9:0.586185809224844\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.7408502697944641\n",
      "\n",
      "episode 2, val func loss 0.5915419459342957\n",
      "\n",
      "episode 3, val func loss 0.5718151926994324\n",
      "\n",
      "episode 4, val func loss 0.5712367296218872\n",
      "\n",
      "episode 5, val func loss 0.6102288365364075\n",
      "\n",
      "episode 6, val func loss 0.6623027324676514\n",
      "\n",
      "episode 7, val func loss 0.6580315232276917\n",
      "\n",
      "episode 8, val func loss 0.6567140221595764\n",
      "\n",
      "episode 9, val func loss 0.5208824276924133\n",
      "\n",
      "episode 10, val func loss 0.6461426615715027\n",
      "\n",
      "episode 11, val func loss 0.6846849322319031\n",
      "\n",
      "episode 12, val func loss 0.6660244464874268\n",
      "\n",
      "episode 13, val func loss 0.5478457808494568\n",
      "\n",
      "episode 14, val func loss 0.6915757060050964\n",
      "\n",
      "episode 15, val func loss 0.574771523475647\n",
      "\n",
      "episode 16, val func loss 0.5043622255325317\n",
      "\n",
      "Val func train loss in epoch 10:0.6186881847679615\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6297645568847656\n",
      "\n",
      "episode 2, val func loss 0.6091492772102356\n",
      "\n",
      "episode 3, val func loss 0.5620710849761963\n",
      "\n",
      "episode 4, val func loss 0.5649901628494263\n",
      "\n",
      "episode 5, val func loss 0.6059340834617615\n",
      "\n",
      "episode 6, val func loss 0.48368147015571594\n",
      "\n",
      "episode 7, val func loss 0.6788385510444641\n",
      "\n",
      "episode 8, val func loss 0.5977159738540649\n",
      "\n",
      "episode 9, val func loss 0.6741926670074463\n",
      "\n",
      "episode 10, val func loss 0.6662193536758423\n",
      "\n",
      "episode 11, val func loss 0.6325975060462952\n",
      "\n",
      "episode 12, val func loss 0.6099068522453308\n",
      "\n",
      "episode 13, val func loss 0.585558295249939\n",
      "\n",
      "episode 14, val func loss 0.6726415753364563\n",
      "\n",
      "episode 15, val func loss 0.6435204744338989\n",
      "\n",
      "episode 16, val func loss 0.6605777144432068\n",
      "\n",
      "Val func train loss in epoch 11:0.6173349749296904\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.6349480152130127\n",
      "\n",
      "episode 2, val func loss 0.7244911193847656\n",
      "\n",
      "episode 3, val func loss 0.6108930110931396\n",
      "\n",
      "episode 4, val func loss 0.5944196581840515\n",
      "\n",
      "episode 5, val func loss 0.6952781081199646\n",
      "\n",
      "episode 6, val func loss 0.6677300930023193\n",
      "\n",
      "episode 7, val func loss 0.6694938540458679\n",
      "\n",
      "episode 8, val func loss 0.6390529870986938\n",
      "\n",
      "episode 9, val func loss 0.5825238823890686\n",
      "\n",
      "episode 10, val func loss 0.6284393668174744\n",
      "\n",
      "episode 11, val func loss 0.7232879400253296\n",
      "\n",
      "episode 12, val func loss 0.6829999089241028\n",
      "\n",
      "episode 13, val func loss 0.885651171207428\n",
      "\n",
      "episode 14, val func loss 0.6361595988273621\n",
      "\n",
      "episode 15, val func loss 0.6055215001106262\n",
      "\n",
      "episode 16, val func loss 0.5843896865844727\n",
      "\n",
      "Val func train loss in epoch 12:0.66032999381423\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.6136041283607483\n",
      "\n",
      "episode 2, val func loss 0.6212823987007141\n",
      "\n",
      "episode 3, val func loss 0.5754479765892029\n",
      "\n",
      "episode 4, val func loss 0.5919817090034485\n",
      "\n",
      "episode 5, val func loss 0.5887378454208374\n",
      "\n",
      "episode 6, val func loss 0.5475019216537476\n",
      "\n",
      "episode 7, val func loss 0.67046058177948\n",
      "\n",
      "episode 8, val func loss 0.5475816130638123\n",
      "\n",
      "episode 9, val func loss 0.6417149305343628\n",
      "\n",
      "episode 10, val func loss 0.6428182721138\n",
      "\n",
      "episode 11, val func loss 0.765774130821228\n",
      "\n",
      "episode 12, val func loss 0.5958446264266968\n",
      "\n",
      "episode 13, val func loss 0.5854154229164124\n",
      "\n",
      "episode 14, val func loss 0.6180553436279297\n",
      "\n",
      "episode 15, val func loss 0.5928739905357361\n",
      "\n",
      "episode 16, val func loss 0.597235918045044\n",
      "\n",
      "Val func train loss in epoch 13:0.612270675599575\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.5454078912734985\n",
      "\n",
      "episode 2, val func loss 0.5817381739616394\n",
      "\n",
      "episode 3, val func loss 0.5941227674484253\n",
      "\n",
      "episode 4, val func loss 0.6229590773582458\n",
      "\n",
      "episode 5, val func loss 0.5882580280303955\n",
      "\n",
      "episode 6, val func loss 0.6132193803787231\n",
      "\n",
      "episode 7, val func loss 0.6699026226997375\n",
      "\n",
      "episode 8, val func loss 0.6255722045898438\n",
      "\n",
      "episode 9, val func loss 0.7977142333984375\n",
      "\n",
      "episode 10, val func loss 0.6867435574531555\n",
      "\n",
      "episode 11, val func loss 0.6093930006027222\n",
      "\n",
      "episode 12, val func loss 0.6193779706954956\n",
      "\n",
      "episode 13, val func loss 0.606624960899353\n",
      "\n",
      "episode 14, val func loss 0.5835440158843994\n",
      "\n",
      "episode 15, val func loss 0.6329072117805481\n",
      "\n",
      "episode 16, val func loss 0.6032402515411377\n",
      "\n",
      "Val func train loss in epoch 14:0.6237953342497349\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.6141656041145325\n",
      "\n",
      "episode 2, val func loss 0.7271314263343811\n",
      "\n",
      "episode 3, val func loss 0.7219318151473999\n",
      "\n",
      "episode 4, val func loss 0.6035552024841309\n",
      "\n",
      "episode 5, val func loss 0.5636039972305298\n",
      "\n",
      "episode 6, val func loss 0.737361490726471\n",
      "\n",
      "episode 7, val func loss 0.6542302966117859\n",
      "\n",
      "episode 8, val func loss 0.5829082131385803\n",
      "\n",
      "episode 9, val func loss 0.6755579113960266\n",
      "\n",
      "episode 10, val func loss 0.5942299365997314\n",
      "\n",
      "episode 11, val func loss 0.7199677228927612\n",
      "\n",
      "episode 12, val func loss 0.6265267729759216\n",
      "\n",
      "episode 13, val func loss 0.6170870661735535\n",
      "\n",
      "episode 14, val func loss 0.6678001880645752\n",
      "\n",
      "episode 15, val func loss 0.5821071267127991\n",
      "\n",
      "episode 16, val func loss 0.6151602268218994\n",
      "\n",
      "Val func train loss in epoch 15:0.6439578123390675\n",
      "***********************TIME WAS 4.933270263671875 min*****************************\n",
      "\n",
      "**********************ROUND 146 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.875\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.5186586380004883\n",
      "\n",
      "episode 2, policy loss 1.5186604261398315\n",
      "\n",
      "episode 3, policy loss 1.5186171531677246\n",
      "\n",
      "episode 4, policy loss 1.5185543298721313\n",
      "\n",
      "episode 5, policy loss 1.5185298919677734\n",
      "\n",
      "episode 6, policy loss 1.518511176109314\n",
      "\n",
      "episode 7, policy loss 1.518518090248108\n",
      "\n",
      "episode 8, policy loss 1.5184601545333862\n",
      "\n",
      "episode 9, policy loss 1.5183862447738647\n",
      "\n",
      "episode 10, policy loss 1.5183062553405762\n",
      "\n",
      "episode 11, policy loss 1.518154501914978\n",
      "\n",
      "episode 12, policy loss 1.5181056261062622\n",
      "\n",
      "episode 13, policy loss 1.5180550813674927\n",
      "\n",
      "episode 14, policy loss 1.5179098844528198\n",
      "\n",
      "episode 15, policy loss 1.5178388357162476\n",
      "\n",
      "episode 16, policy loss 1.5751408338546753\n",
      "\n",
      "Policy train loss in epoch 0:1.5219004452228546\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.5179334878921509\n",
      "\n",
      "episode 2, policy loss 1.5181750059127808\n",
      "\n",
      "episode 3, policy loss 1.518275499343872\n",
      "\n",
      "episode 4, policy loss 1.5183892250061035\n",
      "\n",
      "episode 5, policy loss 1.5184719562530518\n",
      "\n",
      "episode 6, policy loss 1.5185120105743408\n",
      "\n",
      "episode 7, policy loss 1.5185461044311523\n",
      "\n",
      "episode 8, policy loss 1.5185149908065796\n",
      "\n",
      "episode 9, policy loss 1.518486738204956\n",
      "\n",
      "episode 10, policy loss 1.5446348190307617\n",
      "\n",
      "episode 11, policy loss 1.518509030342102\n",
      "\n",
      "episode 12, policy loss 1.5183982849121094\n",
      "\n",
      "episode 13, policy loss 1.5183382034301758\n",
      "\n",
      "episode 14, policy loss 1.5182064771652222\n",
      "\n",
      "episode 15, policy loss 1.518058180809021\n",
      "\n",
      "episode 16, policy loss 1.518049716949463\n",
      "\n",
      "Policy train loss in epoch 1:1.5199687331914902\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.5178215503692627\n",
      "\n",
      "episode 2, policy loss 1.5174956321716309\n",
      "\n",
      "episode 3, policy loss 1.5170419216156006\n",
      "\n",
      "episode 4, policy loss 1.5164003372192383\n",
      "\n",
      "episode 5, policy loss 1.5157697200775146\n",
      "\n",
      "episode 6, policy loss 1.5141905546188354\n",
      "\n",
      "episode 7, policy loss 1.5108671188354492\n",
      "\n",
      "episode 8, policy loss 1.506693959236145\n",
      "\n",
      "episode 9, policy loss 1.5450037717819214\n",
      "\n",
      "episode 10, policy loss 1.4805691242218018\n",
      "\n",
      "episode 11, policy loss 1.4314614534378052\n",
      "\n",
      "episode 12, policy loss 1.386152982711792\n",
      "\n",
      "episode 13, policy loss 1.41716730594635\n",
      "\n",
      "episode 14, policy loss 1.4206496477127075\n",
      "\n",
      "episode 15, policy loss 1.4009727239608765\n",
      "\n",
      "episode 16, policy loss 1.375842809677124\n",
      "\n",
      "Policy train loss in epoch 2:1.4733812883496284\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.416346788406372\n",
      "\n",
      "episode 2, policy loss 1.4140716791152954\n",
      "\n",
      "episode 3, policy loss 1.3836431503295898\n",
      "\n",
      "episode 4, policy loss 1.3869141340255737\n",
      "\n",
      "episode 5, policy loss 1.4015470743179321\n",
      "\n",
      "episode 6, policy loss 1.4087653160095215\n",
      "\n",
      "episode 7, policy loss 1.3934119939804077\n",
      "\n",
      "episode 8, policy loss 1.3808451890945435\n",
      "\n",
      "episode 9, policy loss 1.3856810331344604\n",
      "\n",
      "episode 10, policy loss 1.3922964334487915\n",
      "\n",
      "episode 11, policy loss 1.3841195106506348\n",
      "\n",
      "episode 12, policy loss 1.3766075372695923\n",
      "\n",
      "episode 13, policy loss 1.412078857421875\n",
      "\n",
      "episode 14, policy loss 1.385541558265686\n",
      "\n",
      "episode 15, policy loss 1.383126139640808\n",
      "\n",
      "episode 16, policy loss 1.3784347772598267\n",
      "\n",
      "Policy train loss in epoch 3:1.392714448273182\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.6115405559539795\n",
      "\n",
      "episode 2, val func loss 0.618895411491394\n",
      "\n",
      "episode 3, val func loss 0.6434950828552246\n",
      "\n",
      "episode 4, val func loss 0.6826587319374084\n",
      "\n",
      "episode 5, val func loss 0.6113654375076294\n",
      "\n",
      "episode 6, val func loss 0.6617423295974731\n",
      "\n",
      "episode 7, val func loss 0.6580972075462341\n",
      "\n",
      "episode 8, val func loss 0.6390452980995178\n",
      "\n",
      "episode 9, val func loss 0.7128098011016846\n",
      "\n",
      "episode 10, val func loss 0.5747875571250916\n",
      "\n",
      "episode 11, val func loss 0.5904138088226318\n",
      "\n",
      "episode 12, val func loss 0.60099858045578\n",
      "\n",
      "episode 13, val func loss 0.7399758100509644\n",
      "\n",
      "episode 14, val func loss 0.579389750957489\n",
      "\n",
      "episode 15, val func loss 0.5574778914451599\n",
      "\n",
      "episode 16, val func loss 0.6775941848754883\n",
      "\n",
      "Val func train loss in epoch 0:0.6350179649889469\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.615632951259613\n",
      "\n",
      "episode 2, val func loss 0.6711716055870056\n",
      "\n",
      "episode 3, val func loss 0.5839012861251831\n",
      "\n",
      "episode 4, val func loss 0.5835808515548706\n",
      "\n",
      "episode 5, val func loss 0.6023267507553101\n",
      "\n",
      "episode 6, val func loss 0.5060862898826599\n",
      "\n",
      "episode 7, val func loss 0.5885019898414612\n",
      "\n",
      "episode 8, val func loss 0.5273414254188538\n",
      "\n",
      "episode 9, val func loss 0.6571499705314636\n",
      "\n",
      "episode 10, val func loss 0.749114990234375\n",
      "\n",
      "episode 11, val func loss 0.6541637182235718\n",
      "\n",
      "episode 12, val func loss 0.651842474937439\n",
      "\n",
      "episode 13, val func loss 0.6361443400382996\n",
      "\n",
      "episode 14, val func loss 0.6530329585075378\n",
      "\n",
      "episode 15, val func loss 0.6250424981117249\n",
      "\n",
      "episode 16, val func loss 0.539412796497345\n",
      "\n",
      "Val func train loss in epoch 1:0.6152779310941696\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.5655463337898254\n",
      "\n",
      "episode 2, val func loss 0.5736055970191956\n",
      "\n",
      "episode 3, val func loss 0.5884877443313599\n",
      "\n",
      "episode 4, val func loss 0.7192245125770569\n",
      "\n",
      "episode 5, val func loss 0.6212466955184937\n",
      "\n",
      "episode 6, val func loss 0.631038248538971\n",
      "\n",
      "episode 7, val func loss 0.6366813778877258\n",
      "\n",
      "episode 8, val func loss 0.6011992692947388\n",
      "\n",
      "episode 9, val func loss 0.8460214138031006\n",
      "\n",
      "episode 10, val func loss 0.5919346213340759\n",
      "\n",
      "episode 11, val func loss 0.5964013338088989\n",
      "\n",
      "episode 12, val func loss 0.5294772386550903\n",
      "\n",
      "episode 13, val func loss 0.6021673679351807\n",
      "\n",
      "episode 14, val func loss 0.6544600129127502\n",
      "\n",
      "episode 15, val func loss 0.5741273164749146\n",
      "\n",
      "episode 16, val func loss 0.584637463092804\n",
      "\n",
      "Val func train loss in epoch 2:0.6197660341858864\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6054621934890747\n",
      "\n",
      "episode 2, val func loss 0.6141979098320007\n",
      "\n",
      "episode 3, val func loss 0.6128722429275513\n",
      "\n",
      "episode 4, val func loss 0.6444485783576965\n",
      "\n",
      "episode 5, val func loss 0.5805879235267639\n",
      "\n",
      "episode 6, val func loss 0.644100546836853\n",
      "\n",
      "episode 7, val func loss 0.655941367149353\n",
      "\n",
      "episode 8, val func loss 0.6380912065505981\n",
      "\n",
      "episode 9, val func loss 0.6506481170654297\n",
      "\n",
      "episode 10, val func loss 0.6673732995986938\n",
      "\n",
      "episode 11, val func loss 0.6213104724884033\n",
      "\n",
      "episode 12, val func loss 0.589870274066925\n",
      "\n",
      "episode 13, val func loss 0.6325243711471558\n",
      "\n",
      "episode 14, val func loss 0.5833247900009155\n",
      "\n",
      "episode 15, val func loss 0.7025112509727478\n",
      "\n",
      "episode 16, val func loss 0.5893847346305847\n",
      "\n",
      "Val func train loss in epoch 3:0.6270405799150467\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.627905011177063\n",
      "\n",
      "episode 2, val func loss 0.5778638124465942\n",
      "\n",
      "episode 3, val func loss 0.6324706673622131\n",
      "\n",
      "episode 4, val func loss 0.7061488032341003\n",
      "\n",
      "episode 5, val func loss 0.6904328465461731\n",
      "\n",
      "episode 6, val func loss 0.5839120149612427\n",
      "\n",
      "episode 7, val func loss 0.6309136152267456\n",
      "\n",
      "episode 8, val func loss 0.6264775991439819\n",
      "\n",
      "episode 9, val func loss 0.6325386166572571\n",
      "\n",
      "episode 10, val func loss 0.9461351037025452\n",
      "\n",
      "episode 11, val func loss 0.786872386932373\n",
      "\n",
      "episode 12, val func loss 0.5720567107200623\n",
      "\n",
      "episode 13, val func loss 0.6895908713340759\n",
      "\n",
      "episode 14, val func loss 0.6957827210426331\n",
      "\n",
      "episode 15, val func loss 0.6441550850868225\n",
      "\n",
      "episode 16, val func loss 0.544649600982666\n",
      "\n",
      "Val func train loss in epoch 4:0.6617440916597843\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.5794143080711365\n",
      "\n",
      "episode 2, val func loss 0.6066051125526428\n",
      "\n",
      "episode 3, val func loss 0.6627224087715149\n",
      "\n",
      "episode 4, val func loss 0.6829861998558044\n",
      "\n",
      "episode 5, val func loss 0.6410515904426575\n",
      "\n",
      "episode 6, val func loss 0.7153323888778687\n",
      "\n",
      "episode 7, val func loss 0.6156643629074097\n",
      "\n",
      "episode 8, val func loss 0.6230807304382324\n",
      "\n",
      "episode 9, val func loss 0.6449440717697144\n",
      "\n",
      "episode 10, val func loss 0.7386955618858337\n",
      "\n",
      "episode 11, val func loss 0.6360223889350891\n",
      "\n",
      "episode 12, val func loss 0.5772517919540405\n",
      "\n",
      "episode 13, val func loss 0.6660569906234741\n",
      "\n",
      "episode 14, val func loss 0.5690505504608154\n",
      "\n",
      "episode 15, val func loss 0.7211957573890686\n",
      "\n",
      "episode 16, val func loss 0.6387525200843811\n",
      "\n",
      "Val func train loss in epoch 5:0.6449266709387302\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6447478532791138\n",
      "\n",
      "episode 2, val func loss 0.6091626882553101\n",
      "\n",
      "episode 3, val func loss 0.6019270420074463\n",
      "\n",
      "episode 4, val func loss 0.7134371995925903\n",
      "\n",
      "episode 5, val func loss 0.5664053559303284\n",
      "\n",
      "episode 6, val func loss 0.6528365015983582\n",
      "\n",
      "episode 7, val func loss 0.5759508013725281\n",
      "\n",
      "episode 8, val func loss 0.6654594540596008\n",
      "\n",
      "episode 9, val func loss 0.6734790802001953\n",
      "\n",
      "episode 10, val func loss 0.5774069428443909\n",
      "\n",
      "episode 11, val func loss 0.6449873447418213\n",
      "\n",
      "episode 12, val func loss 0.8285199403762817\n",
      "\n",
      "episode 13, val func loss 0.7210572361946106\n",
      "\n",
      "episode 14, val func loss 0.6095542311668396\n",
      "\n",
      "episode 15, val func loss 0.6535521745681763\n",
      "\n",
      "episode 16, val func loss 0.6136049032211304\n",
      "\n",
      "Val func train loss in epoch 6:0.6470055468380451\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6370694041252136\n",
      "\n",
      "episode 2, val func loss 0.6379204988479614\n",
      "\n",
      "episode 3, val func loss 0.5656425952911377\n",
      "\n",
      "episode 4, val func loss 0.6653627157211304\n",
      "\n",
      "episode 5, val func loss 0.5983920693397522\n",
      "\n",
      "episode 6, val func loss 0.6525857448577881\n",
      "\n",
      "episode 7, val func loss 0.5206678509712219\n",
      "\n",
      "episode 8, val func loss 0.7120458483695984\n",
      "\n",
      "episode 9, val func loss 0.5910756587982178\n",
      "\n",
      "episode 10, val func loss 0.6791141629219055\n",
      "\n",
      "episode 11, val func loss 0.7954538464546204\n",
      "\n",
      "episode 12, val func loss 0.6039975881576538\n",
      "\n",
      "episode 13, val func loss 0.6057074666023254\n",
      "\n",
      "episode 14, val func loss 0.5797774195671082\n",
      "\n",
      "episode 15, val func loss 0.5613187551498413\n",
      "\n",
      "episode 16, val func loss 0.7455435991287231\n",
      "\n",
      "Val func train loss in epoch 7:0.6344797015190125\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.6158828139305115\n",
      "\n",
      "episode 2, val func loss 0.6092332601547241\n",
      "\n",
      "episode 3, val func loss 0.6802150011062622\n",
      "\n",
      "episode 4, val func loss 0.6226781606674194\n",
      "\n",
      "episode 5, val func loss 0.613414466381073\n",
      "\n",
      "episode 6, val func loss 0.5275505781173706\n",
      "\n",
      "episode 7, val func loss 0.6634465456008911\n",
      "\n",
      "episode 8, val func loss 0.6255434155464172\n",
      "\n",
      "episode 9, val func loss 0.6733189821243286\n",
      "\n",
      "episode 10, val func loss 0.6230827569961548\n",
      "\n",
      "episode 11, val func loss 0.5979840159416199\n",
      "\n",
      "episode 12, val func loss 0.5646370649337769\n",
      "\n",
      "episode 13, val func loss 0.6188424825668335\n",
      "\n",
      "episode 14, val func loss 0.767268180847168\n",
      "\n",
      "episode 15, val func loss 0.7185971736907959\n",
      "\n",
      "episode 16, val func loss 0.6076846718788147\n",
      "\n",
      "Val func train loss in epoch 8:0.6330862231552601\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.559973955154419\n",
      "\n",
      "episode 2, val func loss 0.5517303943634033\n",
      "\n",
      "episode 3, val func loss 0.63812255859375\n",
      "\n",
      "episode 4, val func loss 0.5858122706413269\n",
      "\n",
      "episode 5, val func loss 0.7865451574325562\n",
      "\n",
      "episode 6, val func loss 0.5188876986503601\n",
      "\n",
      "episode 7, val func loss 0.6409560441970825\n",
      "\n",
      "episode 8, val func loss 0.6786119937896729\n",
      "\n",
      "episode 9, val func loss 0.5733052492141724\n",
      "\n",
      "episode 10, val func loss 0.5213471055030823\n",
      "\n",
      "episode 11, val func loss 0.5530158281326294\n",
      "\n",
      "episode 12, val func loss 0.5805906057357788\n",
      "\n",
      "episode 13, val func loss 0.5189566612243652\n",
      "\n",
      "episode 14, val func loss 0.6354177594184875\n",
      "\n",
      "episode 15, val func loss 0.612228274345398\n",
      "\n",
      "episode 16, val func loss 0.6031107902526855\n",
      "\n",
      "Val func train loss in epoch 9:0.5974132716655731\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.5566208958625793\n",
      "\n",
      "episode 2, val func loss 0.5863752961158752\n",
      "\n",
      "episode 3, val func loss 0.6176788210868835\n",
      "\n",
      "episode 4, val func loss 0.5482864379882812\n",
      "\n",
      "episode 5, val func loss 0.5245029926300049\n",
      "\n",
      "episode 6, val func loss 0.633973240852356\n",
      "\n",
      "episode 7, val func loss 0.604895293712616\n",
      "\n",
      "episode 8, val func loss 0.8721587061882019\n",
      "\n",
      "episode 9, val func loss 0.6484048366546631\n",
      "\n",
      "episode 10, val func loss 0.5726600289344788\n",
      "\n",
      "episode 11, val func loss 0.6102271676063538\n",
      "\n",
      "episode 12, val func loss 0.5654139518737793\n",
      "\n",
      "episode 13, val func loss 0.7095531225204468\n",
      "\n",
      "episode 14, val func loss 0.6109405159950256\n",
      "\n",
      "episode 15, val func loss 0.5405017137527466\n",
      "\n",
      "episode 16, val func loss 0.628434956073761\n",
      "\n",
      "Val func train loss in epoch 10:0.6144142486155033\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.5664685964584351\n",
      "\n",
      "episode 2, val func loss 0.5853129029273987\n",
      "\n",
      "episode 3, val func loss 0.6978368759155273\n",
      "\n",
      "episode 4, val func loss 0.6380380392074585\n",
      "\n",
      "episode 5, val func loss 0.7996576428413391\n",
      "\n",
      "episode 6, val func loss 0.6222525238990784\n",
      "\n",
      "episode 7, val func loss 0.591460645198822\n",
      "\n",
      "episode 8, val func loss 0.7065035700798035\n",
      "\n",
      "episode 9, val func loss 0.706558883190155\n",
      "\n",
      "episode 10, val func loss 0.569342315196991\n",
      "\n",
      "episode 11, val func loss 0.7918201088905334\n",
      "\n",
      "episode 12, val func loss 0.5863629579544067\n",
      "\n",
      "episode 13, val func loss 0.62923663854599\n",
      "\n",
      "episode 14, val func loss 0.5193565487861633\n",
      "\n",
      "episode 15, val func loss 0.6189708113670349\n",
      "\n",
      "episode 16, val func loss 0.6355983018875122\n",
      "\n",
      "Val func train loss in epoch 11:0.6415485851466656\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.53724205493927\n",
      "\n",
      "episode 2, val func loss 0.5799795389175415\n",
      "\n",
      "episode 3, val func loss 0.6466880440711975\n",
      "\n",
      "episode 4, val func loss 0.6355757713317871\n",
      "\n",
      "episode 5, val func loss 0.5911831855773926\n",
      "\n",
      "episode 6, val func loss 0.6099230647087097\n",
      "\n",
      "episode 7, val func loss 0.6665318012237549\n",
      "\n",
      "episode 8, val func loss 0.5673360824584961\n",
      "\n",
      "episode 9, val func loss 0.6606321334838867\n",
      "\n",
      "episode 10, val func loss 0.7540314197540283\n",
      "\n",
      "episode 11, val func loss 0.5791499018669128\n",
      "\n",
      "episode 12, val func loss 0.5521149039268494\n",
      "\n",
      "episode 13, val func loss 0.539206862449646\n",
      "\n",
      "episode 14, val func loss 0.6612468361854553\n",
      "\n",
      "episode 15, val func loss 0.5520961880683899\n",
      "\n",
      "episode 16, val func loss 0.5828315019607544\n",
      "\n",
      "Val func train loss in epoch 12:0.6072355806827545\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.60390305519104\n",
      "\n",
      "episode 2, val func loss 0.633091926574707\n",
      "\n",
      "episode 3, val func loss 0.5761569738388062\n",
      "\n",
      "episode 4, val func loss 0.589489221572876\n",
      "\n",
      "episode 5, val func loss 0.5985816717147827\n",
      "\n",
      "episode 6, val func loss 0.6894717812538147\n",
      "\n",
      "episode 7, val func loss 0.6154950857162476\n",
      "\n",
      "episode 8, val func loss 0.6430695652961731\n",
      "\n",
      "episode 9, val func loss 0.5932705998420715\n",
      "\n",
      "episode 10, val func loss 0.589799165725708\n",
      "\n",
      "episode 11, val func loss 0.6434476971626282\n",
      "\n",
      "episode 12, val func loss 0.63810795545578\n",
      "\n",
      "episode 13, val func loss 0.644638180732727\n",
      "\n",
      "episode 14, val func loss 0.6107387542724609\n",
      "\n",
      "episode 15, val func loss 0.5820767879486084\n",
      "\n",
      "episode 16, val func loss 0.78291255235672\n",
      "\n",
      "Val func train loss in epoch 13:0.627140685915947\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.5925852656364441\n",
      "\n",
      "episode 2, val func loss 0.6210016012191772\n",
      "\n",
      "episode 3, val func loss 0.5979524254798889\n",
      "\n",
      "episode 4, val func loss 0.5804588794708252\n",
      "\n",
      "episode 5, val func loss 0.5961025357246399\n",
      "\n",
      "episode 6, val func loss 0.6360637545585632\n",
      "\n",
      "episode 7, val func loss 0.6017417907714844\n",
      "\n",
      "episode 8, val func loss 0.6606943607330322\n",
      "\n",
      "episode 9, val func loss 0.6065326929092407\n",
      "\n",
      "episode 10, val func loss 0.5815144777297974\n",
      "\n",
      "episode 11, val func loss 0.6636551022529602\n",
      "\n",
      "episode 12, val func loss 0.5503312945365906\n",
      "\n",
      "episode 13, val func loss 0.6292349100112915\n",
      "\n",
      "episode 14, val func loss 0.7034764885902405\n",
      "\n",
      "episode 15, val func loss 0.5579384565353394\n",
      "\n",
      "episode 16, val func loss 0.5711219906806946\n",
      "\n",
      "Val func train loss in epoch 14:0.6094003766775131\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.47282153367996216\n",
      "\n",
      "episode 2, val func loss 0.6135794520378113\n",
      "\n",
      "episode 3, val func loss 0.6385976672172546\n",
      "\n",
      "episode 4, val func loss 0.6822153925895691\n",
      "\n",
      "episode 5, val func loss 0.7342267632484436\n",
      "\n",
      "episode 6, val func loss 0.6510735154151917\n",
      "\n",
      "episode 7, val func loss 0.7628707885742188\n",
      "\n",
      "episode 8, val func loss 0.7090832591056824\n",
      "\n",
      "episode 9, val func loss 0.5955513119697571\n",
      "\n",
      "episode 10, val func loss 0.6501468420028687\n",
      "\n",
      "episode 11, val func loss 0.8057453632354736\n",
      "\n",
      "episode 12, val func loss 0.6049432158470154\n",
      "\n",
      "episode 13, val func loss 0.6261892318725586\n",
      "\n",
      "episode 14, val func loss 0.6354668140411377\n",
      "\n",
      "episode 15, val func loss 0.6396453976631165\n",
      "\n",
      "episode 16, val func loss 0.7368863821029663\n",
      "\n",
      "Val func train loss in epoch 15:0.6599401831626892\n",
      "***********************TIME WAS 4.932536892096201 min*****************************\n",
      "\n",
      "**********************ROUND 147 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 0.625\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 1.637897253036499\n",
      "\n",
      "episode 2, policy loss 1.6754730939865112\n",
      "\n",
      "episode 3, policy loss 1.6984955072402954\n",
      "\n",
      "episode 4, policy loss 1.8322031497955322\n",
      "\n",
      "episode 5, policy loss 1.75144362449646\n",
      "\n",
      "episode 6, policy loss 1.82179594039917\n",
      "\n",
      "episode 7, policy loss 1.8445227146148682\n",
      "\n",
      "episode 8, policy loss 1.5439157485961914\n",
      "\n",
      "episode 9, policy loss 1.686156153678894\n",
      "\n",
      "episode 10, policy loss 1.858720302581787\n",
      "\n",
      "episode 11, policy loss 1.7960418462753296\n",
      "\n",
      "episode 12, policy loss 1.7339482307434082\n",
      "\n",
      "episode 13, policy loss 1.6373032331466675\n",
      "\n",
      "episode 14, policy loss 1.7851320505142212\n",
      "\n",
      "episode 15, policy loss 1.8535962104797363\n",
      "\n",
      "episode 16, policy loss 1.8793975114822388\n",
      "\n",
      "Policy train loss in epoch 0:1.7522526606917381\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 1.7703967094421387\n",
      "\n",
      "episode 2, policy loss 1.8673368692398071\n",
      "\n",
      "episode 3, policy loss 1.6422147750854492\n",
      "\n",
      "episode 4, policy loss 1.8518717288970947\n",
      "\n",
      "episode 5, policy loss 1.772047519683838\n",
      "\n",
      "episode 6, policy loss 1.6717599630355835\n",
      "\n",
      "episode 7, policy loss 1.8179987668991089\n",
      "\n",
      "episode 8, policy loss 1.8549590110778809\n",
      "\n",
      "episode 9, policy loss 1.8574014902114868\n",
      "\n",
      "episode 10, policy loss 1.7264126539230347\n",
      "\n",
      "episode 11, policy loss 1.7356631755828857\n",
      "\n",
      "episode 12, policy loss 1.84916090965271\n",
      "\n",
      "episode 13, policy loss 1.5463876724243164\n",
      "\n",
      "episode 14, policy loss 1.641319990158081\n",
      "\n",
      "episode 15, policy loss 1.7280213832855225\n",
      "\n",
      "episode 16, policy loss 1.7618613243103027\n",
      "\n",
      "Policy train loss in epoch 1:1.7559258714318275\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 1.7968955039978027\n",
      "\n",
      "episode 2, policy loss 1.7606611251831055\n",
      "\n",
      "episode 3, policy loss 1.8239959478378296\n",
      "\n",
      "episode 4, policy loss 1.8547096252441406\n",
      "\n",
      "episode 5, policy loss 1.8403902053833008\n",
      "\n",
      "episode 6, policy loss 1.675388216972351\n",
      "\n",
      "episode 7, policy loss 1.718066692352295\n",
      "\n",
      "episode 8, policy loss 1.6979235410690308\n",
      "\n",
      "episode 9, policy loss 1.6221758127212524\n",
      "\n",
      "episode 10, policy loss 1.9050350189208984\n",
      "\n",
      "episode 11, policy loss 1.9560211896896362\n",
      "\n",
      "episode 12, policy loss 1.8223377466201782\n",
      "\n",
      "episode 13, policy loss 1.7566677331924438\n",
      "\n",
      "episode 14, policy loss 1.8710449934005737\n",
      "\n",
      "episode 15, policy loss 1.7156504392623901\n",
      "\n",
      "episode 16, policy loss 1.6325888633728027\n",
      "\n",
      "Policy train loss in epoch 2:1.778097040951252\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 1.5396982431411743\n",
      "\n",
      "episode 2, policy loss 1.72112238407135\n",
      "\n",
      "episode 3, policy loss 1.853832483291626\n",
      "\n",
      "episode 4, policy loss 1.880779504776001\n",
      "\n",
      "episode 5, policy loss 1.8513654470443726\n",
      "\n",
      "episode 6, policy loss 1.6772618293762207\n",
      "\n",
      "episode 7, policy loss 1.6558369398117065\n",
      "\n",
      "episode 8, policy loss 1.7651153802871704\n",
      "\n",
      "episode 9, policy loss 1.8247871398925781\n",
      "\n",
      "episode 10, policy loss 1.7966091632843018\n",
      "\n",
      "episode 11, policy loss 1.5921716690063477\n",
      "\n",
      "episode 12, policy loss 1.7379701137542725\n",
      "\n",
      "episode 13, policy loss 1.6923651695251465\n",
      "\n",
      "episode 14, policy loss 1.7660114765167236\n",
      "\n",
      "episode 15, policy loss 1.8267549276351929\n",
      "\n",
      "episode 16, policy loss 1.718438982963562\n",
      "\n",
      "Policy train loss in epoch 3:1.7437575533986092\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 2.929232120513916\n",
      "\n",
      "episode 2, val func loss 3.114067792892456\n",
      "\n",
      "episode 3, val func loss 3.066155195236206\n",
      "\n",
      "episode 4, val func loss 3.10329270362854\n",
      "\n",
      "episode 5, val func loss 2.7602758407592773\n",
      "\n",
      "episode 6, val func loss 2.823309898376465\n",
      "\n",
      "episode 7, val func loss 2.698779344558716\n",
      "\n",
      "episode 8, val func loss 2.63468861579895\n",
      "\n",
      "episode 9, val func loss 2.6172983646392822\n",
      "\n",
      "episode 10, val func loss 2.6933205127716064\n",
      "\n",
      "episode 11, val func loss 1.9386556148529053\n",
      "\n",
      "episode 12, val func loss 2.9280591011047363\n",
      "\n",
      "episode 13, val func loss 2.7609589099884033\n",
      "\n",
      "episode 14, val func loss 2.454791784286499\n",
      "\n",
      "episode 15, val func loss 3.0436551570892334\n",
      "\n",
      "episode 16, val func loss 2.9983978271484375\n",
      "\n",
      "Val func train loss in epoch 0:2.785308673977852\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 1.9270890951156616\n",
      "\n",
      "episode 2, val func loss 2.351898193359375\n",
      "\n",
      "episode 3, val func loss 2.559019088745117\n",
      "\n",
      "episode 4, val func loss 3.0307936668395996\n",
      "\n",
      "episode 5, val func loss 3.0428154468536377\n",
      "\n",
      "episode 6, val func loss 3.093759298324585\n",
      "\n",
      "episode 7, val func loss 2.7404119968414307\n",
      "\n",
      "episode 8, val func loss 2.766739845275879\n",
      "\n",
      "episode 9, val func loss 2.648766040802002\n",
      "\n",
      "episode 10, val func loss 2.9647209644317627\n",
      "\n",
      "episode 11, val func loss 3.116997480392456\n",
      "\n",
      "episode 12, val func loss 3.22230863571167\n",
      "\n",
      "episode 13, val func loss 3.3342037200927734\n",
      "\n",
      "episode 14, val func loss 2.196089744567871\n",
      "\n",
      "episode 15, val func loss 3.077239990234375\n",
      "\n",
      "episode 16, val func loss 2.64395809173584\n",
      "\n",
      "Val func train loss in epoch 1:2.7948007062077522\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 2.088634967803955\n",
      "\n",
      "episode 2, val func loss 3.2507169246673584\n",
      "\n",
      "episode 3, val func loss 2.565793991088867\n",
      "\n",
      "episode 4, val func loss 3.251563787460327\n",
      "\n",
      "episode 5, val func loss 2.9417243003845215\n",
      "\n",
      "episode 6, val func loss 3.3421390056610107\n",
      "\n",
      "episode 7, val func loss 2.887497663497925\n",
      "\n",
      "episode 8, val func loss 2.5567262172698975\n",
      "\n",
      "episode 9, val func loss 2.7596147060394287\n",
      "\n",
      "episode 10, val func loss 3.125699758529663\n",
      "\n",
      "episode 11, val func loss 3.098466396331787\n",
      "\n",
      "episode 12, val func loss 2.958897829055786\n",
      "\n",
      "episode 13, val func loss 2.35121750831604\n",
      "\n",
      "episode 14, val func loss 2.8861141204833984\n",
      "\n",
      "episode 15, val func loss 2.723900556564331\n",
      "\n",
      "episode 16, val func loss 2.676509380340576\n",
      "\n",
      "Val func train loss in epoch 2:2.8415760695934296\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 2.9763927459716797\n",
      "\n",
      "episode 2, val func loss 3.208250045776367\n",
      "\n",
      "episode 3, val func loss 2.977241277694702\n",
      "\n",
      "episode 4, val func loss 2.6515212059020996\n",
      "\n",
      "episode 5, val func loss 2.4572877883911133\n",
      "\n",
      "episode 6, val func loss 3.162407636642456\n",
      "\n",
      "episode 7, val func loss 3.0399160385131836\n",
      "\n",
      "episode 8, val func loss 2.249586820602417\n",
      "\n",
      "episode 9, val func loss 2.597080945968628\n",
      "\n",
      "episode 10, val func loss 2.6723883152008057\n",
      "\n",
      "episode 11, val func loss 3.187821388244629\n",
      "\n",
      "episode 12, val func loss 3.2605230808258057\n",
      "\n",
      "episode 13, val func loss 3.0781173706054688\n",
      "\n",
      "episode 14, val func loss 3.0016746520996094\n",
      "\n",
      "episode 15, val func loss 3.1252522468566895\n",
      "\n",
      "episode 16, val func loss 2.5025904178619385\n",
      "\n",
      "Val func train loss in epoch 3:2.8842532485723495\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 2.5483882427215576\n",
      "\n",
      "episode 2, val func loss 3.323058843612671\n",
      "\n",
      "episode 3, val func loss 2.9015889167785645\n",
      "\n",
      "episode 4, val func loss 3.3748302459716797\n",
      "\n",
      "episode 5, val func loss 2.4083826541900635\n",
      "\n",
      "episode 6, val func loss 2.6151437759399414\n",
      "\n",
      "episode 7, val func loss 2.365569829940796\n",
      "\n",
      "episode 8, val func loss 3.182809352874756\n",
      "\n",
      "episode 9, val func loss 2.819119691848755\n",
      "\n",
      "episode 10, val func loss 2.9846086502075195\n",
      "\n",
      "episode 11, val func loss 2.483356237411499\n",
      "\n",
      "episode 12, val func loss 2.4192721843719482\n",
      "\n",
      "episode 13, val func loss 2.964362144470215\n",
      "\n",
      "episode 14, val func loss 2.7078843116760254\n",
      "\n",
      "episode 15, val func loss 3.08001446723938\n",
      "\n",
      "episode 16, val func loss 2.4504168033599854\n",
      "\n",
      "Val func train loss in epoch 4:2.7893003970384598\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 3.174954652786255\n",
      "\n",
      "episode 2, val func loss 3.2820823192596436\n",
      "\n",
      "episode 3, val func loss 2.9128763675689697\n",
      "\n",
      "episode 4, val func loss 2.5880634784698486\n",
      "\n",
      "episode 5, val func loss 2.5124826431274414\n",
      "\n",
      "episode 6, val func loss 2.314523220062256\n",
      "\n",
      "episode 7, val func loss 2.607516050338745\n",
      "\n",
      "episode 8, val func loss 3.101038694381714\n",
      "\n",
      "episode 9, val func loss 2.0838065147399902\n",
      "\n",
      "episode 10, val func loss 2.8917410373687744\n",
      "\n",
      "episode 11, val func loss 2.9718210697174072\n",
      "\n",
      "episode 12, val func loss 2.489353656768799\n",
      "\n",
      "episode 13, val func loss 2.4998369216918945\n",
      "\n",
      "episode 14, val func loss 3.0816895961761475\n",
      "\n",
      "episode 15, val func loss 2.8699541091918945\n",
      "\n",
      "episode 16, val func loss 2.9200706481933594\n",
      "\n",
      "Val func train loss in epoch 5:2.7688631862401962\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 2.697659492492676\n",
      "\n",
      "episode 2, val func loss 2.932690143585205\n",
      "\n",
      "episode 3, val func loss 3.42874813079834\n",
      "\n",
      "episode 4, val func loss 2.7492587566375732\n",
      "\n",
      "episode 5, val func loss 2.6170332431793213\n",
      "\n",
      "episode 6, val func loss 2.285277843475342\n",
      "\n",
      "episode 7, val func loss 2.322356939315796\n",
      "\n",
      "episode 8, val func loss 2.9809908866882324\n",
      "\n",
      "episode 9, val func loss 3.237078905105591\n",
      "\n",
      "episode 10, val func loss 2.8719067573547363\n",
      "\n",
      "episode 11, val func loss 3.055431842803955\n",
      "\n",
      "episode 12, val func loss 2.7709097862243652\n",
      "\n",
      "episode 13, val func loss 2.366497278213501\n",
      "\n",
      "episode 14, val func loss 2.9563851356506348\n",
      "\n",
      "episode 15, val func loss 2.439375162124634\n",
      "\n",
      "episode 16, val func loss 2.995173692703247\n",
      "\n",
      "Val func train loss in epoch 6:2.794173374772072\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 3.117379903793335\n",
      "\n",
      "episode 2, val func loss 3.085944890975952\n",
      "\n",
      "episode 3, val func loss 3.2302255630493164\n",
      "\n",
      "episode 4, val func loss 2.4335365295410156\n",
      "\n",
      "episode 5, val func loss 2.9938571453094482\n",
      "\n",
      "episode 6, val func loss 2.783766508102417\n",
      "\n",
      "episode 7, val func loss 2.8426103591918945\n",
      "\n",
      "episode 8, val func loss 2.2147414684295654\n",
      "\n",
      "episode 9, val func loss 2.771925210952759\n",
      "\n",
      "episode 10, val func loss 3.265557289123535\n",
      "\n",
      "episode 11, val func loss 2.382807493209839\n",
      "\n",
      "episode 12, val func loss 2.6668214797973633\n",
      "\n",
      "episode 13, val func loss 2.667882204055786\n",
      "\n",
      "episode 14, val func loss 2.991913318634033\n",
      "\n",
      "episode 15, val func loss 2.971065044403076\n",
      "\n",
      "episode 16, val func loss 2.7757835388183594\n",
      "\n",
      "Val func train loss in epoch 7:2.824738621711731\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 2.853940963745117\n",
      "\n",
      "episode 2, val func loss 3.264756679534912\n",
      "\n",
      "episode 3, val func loss 3.2471301555633545\n",
      "\n",
      "episode 4, val func loss 2.6459879875183105\n",
      "\n",
      "episode 5, val func loss 3.2511730194091797\n",
      "\n",
      "episode 6, val func loss 2.8457562923431396\n",
      "\n",
      "episode 7, val func loss 3.221545696258545\n",
      "\n",
      "episode 8, val func loss 2.4425179958343506\n",
      "\n",
      "episode 9, val func loss 3.133260726928711\n",
      "\n",
      "episode 10, val func loss 2.7368738651275635\n",
      "\n",
      "episode 11, val func loss 2.759706735610962\n",
      "\n",
      "episode 12, val func loss 3.6001205444335938\n",
      "\n",
      "episode 13, val func loss 2.9074926376342773\n",
      "\n",
      "episode 14, val func loss 2.6965811252593994\n",
      "\n",
      "episode 15, val func loss 2.453369617462158\n",
      "\n",
      "episode 16, val func loss 2.2380826473236084\n",
      "\n",
      "Val func train loss in epoch 8:2.893643543124199\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 3.0282540321350098\n",
      "\n",
      "episode 2, val func loss 3.1964547634124756\n",
      "\n",
      "episode 3, val func loss 2.7091410160064697\n",
      "\n",
      "episode 4, val func loss 3.30751371383667\n",
      "\n",
      "episode 5, val func loss 2.6576220989227295\n",
      "\n",
      "episode 6, val func loss 3.17992901802063\n",
      "\n",
      "episode 7, val func loss 2.6508710384368896\n",
      "\n",
      "episode 8, val func loss 3.2197635173797607\n",
      "\n",
      "episode 9, val func loss 2.320077419281006\n",
      "\n",
      "episode 10, val func loss 2.619152545928955\n",
      "\n",
      "episode 11, val func loss 3.2006094455718994\n",
      "\n",
      "episode 12, val func loss 2.985016345977783\n",
      "\n",
      "episode 13, val func loss 3.2397780418395996\n",
      "\n",
      "episode 14, val func loss 2.6998419761657715\n",
      "\n",
      "episode 15, val func loss 2.596482753753662\n",
      "\n",
      "episode 16, val func loss 2.8000850677490234\n",
      "\n",
      "Val func train loss in epoch 9:2.900662049651146\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 3.3212270736694336\n",
      "\n",
      "episode 2, val func loss 2.145540237426758\n",
      "\n",
      "episode 3, val func loss 2.734377861022949\n",
      "\n",
      "episode 4, val func loss 2.8200318813323975\n",
      "\n",
      "episode 5, val func loss 3.006077289581299\n",
      "\n",
      "episode 6, val func loss 3.016674518585205\n",
      "\n",
      "episode 7, val func loss 2.9219460487365723\n",
      "\n",
      "episode 8, val func loss 3.0539441108703613\n",
      "\n",
      "episode 9, val func loss 2.3151004314422607\n",
      "\n",
      "episode 10, val func loss 3.119927167892456\n",
      "\n",
      "episode 11, val func loss 2.5714433193206787\n",
      "\n",
      "episode 12, val func loss 3.2826249599456787\n",
      "\n",
      "episode 13, val func loss 2.7994847297668457\n",
      "\n",
      "episode 14, val func loss 2.667658805847168\n",
      "\n",
      "episode 15, val func loss 2.449185848236084\n",
      "\n",
      "episode 16, val func loss 3.143406867980957\n",
      "\n",
      "Val func train loss in epoch 10:2.835540696978569\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 2.1627187728881836\n",
      "\n",
      "episode 2, val func loss 3.37495493888855\n",
      "\n",
      "episode 3, val func loss 2.469513177871704\n",
      "\n",
      "episode 4, val func loss 3.1273140907287598\n",
      "\n",
      "episode 5, val func loss 2.7073895931243896\n",
      "\n",
      "episode 6, val func loss 2.8693575859069824\n",
      "\n",
      "episode 7, val func loss 2.914202928543091\n",
      "\n",
      "episode 8, val func loss 3.082233428955078\n",
      "\n",
      "episode 9, val func loss 2.238560676574707\n",
      "\n",
      "episode 10, val func loss 2.5527565479278564\n",
      "\n",
      "episode 11, val func loss 3.406379461288452\n",
      "\n",
      "episode 12, val func loss 3.0243709087371826\n",
      "\n",
      "episode 13, val func loss 2.833669900894165\n",
      "\n",
      "episode 14, val func loss 3.055980682373047\n",
      "\n",
      "episode 15, val func loss 2.6039538383483887\n",
      "\n",
      "episode 16, val func loss 2.4612226486206055\n",
      "\n",
      "Val func train loss in epoch 11:2.8052861988544464\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 3.0295746326446533\n",
      "\n",
      "episode 2, val func loss 2.960320472717285\n",
      "\n",
      "episode 3, val func loss 3.450673818588257\n",
      "\n",
      "episode 4, val func loss 2.409345865249634\n",
      "\n",
      "episode 5, val func loss 3.1733973026275635\n",
      "\n",
      "episode 6, val func loss 2.949826717376709\n",
      "\n",
      "episode 7, val func loss 2.757351875305176\n",
      "\n",
      "episode 8, val func loss 3.261446237564087\n",
      "\n",
      "episode 9, val func loss 3.3653690814971924\n",
      "\n",
      "episode 10, val func loss 2.968660831451416\n",
      "\n",
      "episode 11, val func loss 1.949558138847351\n",
      "\n",
      "episode 12, val func loss 2.576857328414917\n",
      "\n",
      "episode 13, val func loss 2.6422641277313232\n",
      "\n",
      "episode 14, val func loss 2.4394490718841553\n",
      "\n",
      "episode 15, val func loss 2.349837303161621\n",
      "\n",
      "episode 16, val func loss 2.8634021282196045\n",
      "\n",
      "Val func train loss in epoch 12:2.821708433330059\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 3.084552049636841\n",
      "\n",
      "episode 2, val func loss 2.806774616241455\n",
      "\n",
      "episode 3, val func loss 3.2644402980804443\n",
      "\n",
      "episode 4, val func loss 2.747490644454956\n",
      "\n",
      "episode 5, val func loss 2.9246132373809814\n",
      "\n",
      "episode 6, val func loss 2.384852886199951\n",
      "\n",
      "episode 7, val func loss 2.0557968616485596\n",
      "\n",
      "episode 8, val func loss 2.7433061599731445\n",
      "\n",
      "episode 9, val func loss 3.1396424770355225\n",
      "\n",
      "episode 10, val func loss 2.7076148986816406\n",
      "\n",
      "episode 11, val func loss 3.066951036453247\n",
      "\n",
      "episode 12, val func loss 2.7990882396698\n",
      "\n",
      "episode 13, val func loss 2.606283664703369\n",
      "\n",
      "episode 14, val func loss 3.153660297393799\n",
      "\n",
      "episode 15, val func loss 2.968505859375\n",
      "\n",
      "episode 16, val func loss 2.780323028564453\n",
      "\n",
      "Val func train loss in epoch 13:2.8271185159683228\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 2.950408935546875\n",
      "\n",
      "episode 2, val func loss 2.302014112472534\n",
      "\n",
      "episode 3, val func loss 3.235917091369629\n",
      "\n",
      "episode 4, val func loss 2.6390552520751953\n",
      "\n",
      "episode 5, val func loss 2.7049262523651123\n",
      "\n",
      "episode 6, val func loss 3.2407777309417725\n",
      "\n",
      "episode 7, val func loss 2.705098867416382\n",
      "\n",
      "episode 8, val func loss 2.3534178733825684\n",
      "\n",
      "episode 9, val func loss 2.9852750301361084\n",
      "\n",
      "episode 10, val func loss 2.922036647796631\n",
      "\n",
      "episode 11, val func loss 2.1295299530029297\n",
      "\n",
      "episode 12, val func loss 2.449746608734131\n",
      "\n",
      "episode 13, val func loss 2.5809924602508545\n",
      "\n",
      "episode 14, val func loss 3.23667311668396\n",
      "\n",
      "episode 15, val func loss 3.038795232772827\n",
      "\n",
      "episode 16, val func loss 3.1308467388153076\n",
      "\n",
      "Val func train loss in epoch 14:2.787844493985176\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 2.4175572395324707\n",
      "\n",
      "episode 2, val func loss 2.715704917907715\n",
      "\n",
      "episode 3, val func loss 2.834817409515381\n",
      "\n",
      "episode 4, val func loss 2.8114655017852783\n",
      "\n",
      "episode 5, val func loss 2.710726737976074\n",
      "\n",
      "episode 6, val func loss 3.149900197982788\n",
      "\n",
      "episode 7, val func loss 2.450617551803589\n",
      "\n",
      "episode 8, val func loss 2.5190629959106445\n",
      "\n",
      "episode 9, val func loss 2.6919336318969727\n",
      "\n",
      "episode 10, val func loss 2.5431313514709473\n",
      "\n",
      "episode 11, val func loss 3.331117868423462\n",
      "\n",
      "episode 12, val func loss 2.995488166809082\n",
      "\n",
      "episode 13, val func loss 3.03707218170166\n",
      "\n",
      "episode 14, val func loss 3.1209139823913574\n",
      "\n",
      "episode 15, val func loss 2.5619096755981445\n",
      "\n",
      "episode 16, val func loss 2.8586952686309814\n",
      "\n",
      "Val func train loss in epoch 15:2.7968821674585342\n",
      "***********************TIME WAS 4.937300463517507 min*****************************\n",
      "\n",
      "**********************ROUND 148 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 1.25\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.5243759751319885\n",
      "\n",
      "episode 2, policy loss 0.4543319046497345\n",
      "\n",
      "episode 3, policy loss 0.41089245676994324\n",
      "\n",
      "episode 4, policy loss 0.40902140736579895\n",
      "\n",
      "episode 5, policy loss 0.5167473554611206\n",
      "\n",
      "episode 6, policy loss 0.41067492961883545\n",
      "\n",
      "episode 7, policy loss 0.4364100694656372\n",
      "\n",
      "episode 8, policy loss 0.4822247326374054\n",
      "\n",
      "episode 9, policy loss 0.4623242914676666\n",
      "\n",
      "episode 10, policy loss 0.5119450092315674\n",
      "\n",
      "episode 11, policy loss 0.48725664615631104\n",
      "\n",
      "episode 12, policy loss 0.4874979555606842\n",
      "\n",
      "episode 13, policy loss 0.4386965334415436\n",
      "\n",
      "episode 14, policy loss 0.3868340253829956\n",
      "\n",
      "episode 15, policy loss 0.5132076740264893\n",
      "\n",
      "episode 16, policy loss 0.43548381328582764\n",
      "\n",
      "Policy train loss in epoch 0:0.4604952987283468\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.4875224828720093\n",
      "\n",
      "episode 2, policy loss 0.4876919984817505\n",
      "\n",
      "episode 3, policy loss 0.43561050295829773\n",
      "\n",
      "episode 4, policy loss 0.38699859380722046\n",
      "\n",
      "episode 5, policy loss 0.43895307183265686\n",
      "\n",
      "episode 6, policy loss 0.4373141825199127\n",
      "\n",
      "episode 7, policy loss 0.4870357811450958\n",
      "\n",
      "episode 8, policy loss 0.4830005168914795\n",
      "\n",
      "episode 9, policy loss 0.5185727477073669\n",
      "\n",
      "episode 10, policy loss 0.5124908685684204\n",
      "\n",
      "episode 11, policy loss 0.4087637662887573\n",
      "\n",
      "episode 12, policy loss 0.41208362579345703\n",
      "\n",
      "episode 13, policy loss 0.4629295766353607\n",
      "\n",
      "episode 14, policy loss 0.4119488596916199\n",
      "\n",
      "episode 15, policy loss 0.5134265422821045\n",
      "\n",
      "episode 16, policy loss 0.45927417278289795\n",
      "\n",
      "Policy train loss in epoch 1:0.4589760806411505\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.5124898552894592\n",
      "\n",
      "episode 2, policy loss 0.4373794198036194\n",
      "\n",
      "episode 3, policy loss 0.38707664608955383\n",
      "\n",
      "episode 4, policy loss 0.5134475231170654\n",
      "\n",
      "episode 5, policy loss 0.48709920048713684\n",
      "\n",
      "episode 6, policy loss 0.48782238364219666\n",
      "\n",
      "episode 7, policy loss 0.43904823064804077\n",
      "\n",
      "episode 8, policy loss 0.41213440895080566\n",
      "\n",
      "episode 9, policy loss 0.5186032652854919\n",
      "\n",
      "episode 10, policy loss 0.40879419445991516\n",
      "\n",
      "episode 11, policy loss 0.4830697476863861\n",
      "\n",
      "episode 12, policy loss 0.45927682518959045\n",
      "\n",
      "episode 13, policy loss 0.48765435814857483\n",
      "\n",
      "episode 14, policy loss 0.43568289279937744\n",
      "\n",
      "episode 15, policy loss 0.41193732619285583\n",
      "\n",
      "episode 16, policy loss 0.4629858136177063\n",
      "\n",
      "Policy train loss in epoch 2:0.459031380712986\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.5125424861907959\n",
      "\n",
      "episode 2, policy loss 0.45923876762390137\n",
      "\n",
      "episode 3, policy loss 0.43570348620414734\n",
      "\n",
      "episode 4, policy loss 0.387057900428772\n",
      "\n",
      "episode 5, policy loss 0.41211387515068054\n",
      "\n",
      "episode 6, policy loss 0.48709335923194885\n",
      "\n",
      "episode 7, policy loss 0.40877822041511536\n",
      "\n",
      "episode 8, policy loss 0.4119134843349457\n",
      "\n",
      "episode 9, policy loss 0.5186066627502441\n",
      "\n",
      "episode 10, policy loss 0.4390329420566559\n",
      "\n",
      "episode 11, policy loss 0.46295520663261414\n",
      "\n",
      "episode 12, policy loss 0.5134580135345459\n",
      "\n",
      "episode 13, policy loss 0.4829956889152527\n",
      "\n",
      "episode 14, policy loss 0.4878414273262024\n",
      "\n",
      "episode 15, policy loss 0.4373556673526764\n",
      "\n",
      "episode 16, policy loss 0.48762741684913635\n",
      "\n",
      "Policy train loss in epoch 3:0.4590196628123522\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 1.3066478967666626\n",
      "\n",
      "episode 2, val func loss 1.4028493165969849\n",
      "\n",
      "episode 3, val func loss 0.8463104367256165\n",
      "\n",
      "episode 4, val func loss 1.5162211656570435\n",
      "\n",
      "episode 5, val func loss 1.066098928451538\n",
      "\n",
      "episode 6, val func loss 1.45984947681427\n",
      "\n",
      "episode 7, val func loss 1.249890685081482\n",
      "\n",
      "episode 8, val func loss 1.1556426286697388\n",
      "\n",
      "episode 9, val func loss 1.3434633016586304\n",
      "\n",
      "episode 10, val func loss 1.0087980031967163\n",
      "\n",
      "episode 11, val func loss 0.9793576002120972\n",
      "\n",
      "episode 12, val func loss 0.8847406506538391\n",
      "\n",
      "episode 13, val func loss 1.4595451354980469\n",
      "\n",
      "episode 14, val func loss 0.9551687240600586\n",
      "\n",
      "episode 15, val func loss 0.8796312212944031\n",
      "\n",
      "episode 16, val func loss 1.3684577941894531\n",
      "\n",
      "Val func train loss in epoch 0:1.1801670603454113\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.9072360396385193\n",
      "\n",
      "episode 2, val func loss 1.0233327150344849\n",
      "\n",
      "episode 3, val func loss 1.1547189950942993\n",
      "\n",
      "episode 4, val func loss 1.2958556413650513\n",
      "\n",
      "episode 5, val func loss 0.994016170501709\n",
      "\n",
      "episode 6, val func loss 1.3952194452285767\n",
      "\n",
      "episode 7, val func loss 1.3881131410598755\n",
      "\n",
      "episode 8, val func loss 1.3530986309051514\n",
      "\n",
      "episode 9, val func loss 1.00956392288208\n",
      "\n",
      "episode 10, val func loss 1.0429240465164185\n",
      "\n",
      "episode 11, val func loss 0.9401193857192993\n",
      "\n",
      "episode 12, val func loss 1.4180768728256226\n",
      "\n",
      "episode 13, val func loss 1.4548625946044922\n",
      "\n",
      "episode 14, val func loss 0.8636791706085205\n",
      "\n",
      "episode 15, val func loss 1.2823562622070312\n",
      "\n",
      "episode 16, val func loss 1.0735200643539429\n",
      "\n",
      "Val func train loss in epoch 1:1.1622933186590672\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 1.2089259624481201\n",
      "\n",
      "episode 2, val func loss 0.901326596736908\n",
      "\n",
      "episode 3, val func loss 1.289023518562317\n",
      "\n",
      "episode 4, val func loss 0.9147459864616394\n",
      "\n",
      "episode 5, val func loss 1.4670436382293701\n",
      "\n",
      "episode 6, val func loss 1.0867366790771484\n",
      "\n",
      "episode 7, val func loss 1.3239816427230835\n",
      "\n",
      "episode 8, val func loss 1.3556268215179443\n",
      "\n",
      "episode 9, val func loss 1.2679688930511475\n",
      "\n",
      "episode 10, val func loss 0.7438165545463562\n",
      "\n",
      "episode 11, val func loss 0.8774621486663818\n",
      "\n",
      "episode 12, val func loss 1.3216922283172607\n",
      "\n",
      "episode 13, val func loss 0.8656337857246399\n",
      "\n",
      "episode 14, val func loss 0.9019400477409363\n",
      "\n",
      "episode 15, val func loss 1.0640063285827637\n",
      "\n",
      "episode 16, val func loss 1.2011667490005493\n",
      "\n",
      "Val func train loss in epoch 2:1.1119435988366604\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 1.1636098623275757\n",
      "\n",
      "episode 2, val func loss 1.2154003381729126\n",
      "\n",
      "episode 3, val func loss 1.3401597738265991\n",
      "\n",
      "episode 4, val func loss 0.8999983668327332\n",
      "\n",
      "episode 5, val func loss 1.4591715335845947\n",
      "\n",
      "episode 6, val func loss 0.9881656765937805\n",
      "\n",
      "episode 7, val func loss 0.8994911909103394\n",
      "\n",
      "episode 8, val func loss 0.9042194485664368\n",
      "\n",
      "episode 9, val func loss 1.294894814491272\n",
      "\n",
      "episode 10, val func loss 1.3342347145080566\n",
      "\n",
      "episode 11, val func loss 1.447754979133606\n",
      "\n",
      "episode 12, val func loss 0.7787595987319946\n",
      "\n",
      "episode 13, val func loss 1.0646235942840576\n",
      "\n",
      "episode 14, val func loss 1.29853093624115\n",
      "\n",
      "episode 15, val func loss 0.9527385830879211\n",
      "\n",
      "episode 16, val func loss 1.4781386852264404\n",
      "\n",
      "Val func train loss in epoch 3:1.1574932560324669\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 1.2394473552703857\n",
      "\n",
      "episode 2, val func loss 0.9629276990890503\n",
      "\n",
      "episode 3, val func loss 1.1970696449279785\n",
      "\n",
      "episode 4, val func loss 1.2981470823287964\n",
      "\n",
      "episode 5, val func loss 0.9251778721809387\n",
      "\n",
      "episode 6, val func loss 0.760176956653595\n",
      "\n",
      "episode 7, val func loss 1.0166077613830566\n",
      "\n",
      "episode 8, val func loss 1.2954286336898804\n",
      "\n",
      "episode 9, val func loss 1.235034465789795\n",
      "\n",
      "episode 10, val func loss 1.3991550207138062\n",
      "\n",
      "episode 11, val func loss 0.8951582908630371\n",
      "\n",
      "episode 12, val func loss 0.977152943611145\n",
      "\n",
      "episode 13, val func loss 1.1374679803848267\n",
      "\n",
      "episode 14, val func loss 1.3771657943725586\n",
      "\n",
      "episode 15, val func loss 0.8840781450271606\n",
      "\n",
      "episode 16, val func loss 1.4518605470657349\n",
      "\n",
      "Val func train loss in epoch 4:1.128253512084484\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 1.3144679069519043\n",
      "\n",
      "episode 2, val func loss 1.421146273612976\n",
      "\n",
      "episode 3, val func loss 1.3058360815048218\n",
      "\n",
      "episode 4, val func loss 1.2939809560775757\n",
      "\n",
      "episode 5, val func loss 0.8828423619270325\n",
      "\n",
      "episode 6, val func loss 0.7598792314529419\n",
      "\n",
      "episode 7, val func loss 1.2345633506774902\n",
      "\n",
      "episode 8, val func loss 0.9491453766822815\n",
      "\n",
      "episode 9, val func loss 1.3078391551971436\n",
      "\n",
      "episode 10, val func loss 1.3741633892059326\n",
      "\n",
      "episode 11, val func loss 1.137728214263916\n",
      "\n",
      "episode 12, val func loss 1.201143741607666\n",
      "\n",
      "episode 13, val func loss 1.043465495109558\n",
      "\n",
      "episode 14, val func loss 0.8616721034049988\n",
      "\n",
      "episode 15, val func loss 0.9844071865081787\n",
      "\n",
      "episode 16, val func loss 0.7815472483634949\n",
      "\n",
      "Val func train loss in epoch 5:1.1158642545342445\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.9489116072654724\n",
      "\n",
      "episode 2, val func loss 1.2613111734390259\n",
      "\n",
      "episode 3, val func loss 1.391398549079895\n",
      "\n",
      "episode 4, val func loss 1.4932072162628174\n",
      "\n",
      "episode 5, val func loss 1.2549129724502563\n",
      "\n",
      "episode 6, val func loss 0.9711540937423706\n",
      "\n",
      "episode 7, val func loss 1.405043363571167\n",
      "\n",
      "episode 8, val func loss 1.0786869525909424\n",
      "\n",
      "episode 9, val func loss 0.8522945046424866\n",
      "\n",
      "episode 10, val func loss 0.937595546245575\n",
      "\n",
      "episode 11, val func loss 0.9862624406814575\n",
      "\n",
      "episode 12, val func loss 1.2635904550552368\n",
      "\n",
      "episode 13, val func loss 0.7445652484893799\n",
      "\n",
      "episode 14, val func loss 1.1686593294143677\n",
      "\n",
      "episode 15, val func loss 1.3357861042022705\n",
      "\n",
      "episode 16, val func loss 0.8917651176452637\n",
      "\n",
      "Val func train loss in epoch 6:1.124071542173624\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.7351264357566833\n",
      "\n",
      "episode 2, val func loss 0.9335524439811707\n",
      "\n",
      "episode 3, val func loss 1.3920092582702637\n",
      "\n",
      "episode 4, val func loss 1.1255801916122437\n",
      "\n",
      "episode 5, val func loss 1.29646897315979\n",
      "\n",
      "episode 6, val func loss 1.214105248451233\n",
      "\n",
      "episode 7, val func loss 1.2489413022994995\n",
      "\n",
      "episode 8, val func loss 1.0925251245498657\n",
      "\n",
      "episode 9, val func loss 1.3643276691436768\n",
      "\n",
      "episode 10, val func loss 1.4111756086349487\n",
      "\n",
      "episode 11, val func loss 0.9407978057861328\n",
      "\n",
      "episode 12, val func loss 1.0152511596679688\n",
      "\n",
      "episode 13, val func loss 0.9301539063453674\n",
      "\n",
      "episode 14, val func loss 1.2927114963531494\n",
      "\n",
      "episode 15, val func loss 1.2943869829177856\n",
      "\n",
      "episode 16, val func loss 0.9172086715698242\n",
      "\n",
      "Val func train loss in epoch 7:1.1377701424062252\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 1.0486217737197876\n",
      "\n",
      "episode 2, val func loss 0.9285848140716553\n",
      "\n",
      "episode 3, val func loss 0.7900011539459229\n",
      "\n",
      "episode 4, val func loss 1.177422046661377\n",
      "\n",
      "episode 5, val func loss 0.680970311164856\n",
      "\n",
      "episode 6, val func loss 0.7733861207962036\n",
      "\n",
      "episode 7, val func loss 1.4121730327606201\n",
      "\n",
      "episode 8, val func loss 0.9739843606948853\n",
      "\n",
      "episode 9, val func loss 0.9383435845375061\n",
      "\n",
      "episode 10, val func loss 1.2927439212799072\n",
      "\n",
      "episode 11, val func loss 1.364497184753418\n",
      "\n",
      "episode 12, val func loss 0.964931845664978\n",
      "\n",
      "episode 13, val func loss 1.4066253900527954\n",
      "\n",
      "episode 14, val func loss 1.2258387804031372\n",
      "\n",
      "episode 15, val func loss 1.2061851024627686\n",
      "\n",
      "episode 16, val func loss 1.4201596975326538\n",
      "\n",
      "Val func train loss in epoch 8:1.1002793200314045\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 1.227258324623108\n",
      "\n",
      "episode 2, val func loss 1.0600669384002686\n",
      "\n",
      "episode 3, val func loss 1.165070652961731\n",
      "\n",
      "episode 4, val func loss 1.0417994260787964\n",
      "\n",
      "episode 5, val func loss 1.2428066730499268\n",
      "\n",
      "episode 6, val func loss 1.0388635396957397\n",
      "\n",
      "episode 7, val func loss 0.735427975654602\n",
      "\n",
      "episode 8, val func loss 0.8854770660400391\n",
      "\n",
      "episode 9, val func loss 1.2434619665145874\n",
      "\n",
      "episode 10, val func loss 1.4708484411239624\n",
      "\n",
      "episode 11, val func loss 1.074040174484253\n",
      "\n",
      "episode 12, val func loss 1.3827178478240967\n",
      "\n",
      "episode 13, val func loss 1.251965880393982\n",
      "\n",
      "episode 14, val func loss 1.0807112455368042\n",
      "\n",
      "episode 15, val func loss 1.2032932043075562\n",
      "\n",
      "episode 16, val func loss 1.2752861976623535\n",
      "\n",
      "Val func train loss in epoch 9:1.148693472146988\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 1.0367145538330078\n",
      "\n",
      "episode 2, val func loss 1.3952327966690063\n",
      "\n",
      "episode 3, val func loss 1.4515658617019653\n",
      "\n",
      "episode 4, val func loss 1.1937962770462036\n",
      "\n",
      "episode 5, val func loss 1.3151558637619019\n",
      "\n",
      "episode 6, val func loss 1.0015000104904175\n",
      "\n",
      "episode 7, val func loss 1.029104471206665\n",
      "\n",
      "episode 8, val func loss 1.3556205034255981\n",
      "\n",
      "episode 9, val func loss 0.8037782907485962\n",
      "\n",
      "episode 10, val func loss 0.8767051696777344\n",
      "\n",
      "episode 11, val func loss 1.0282337665557861\n",
      "\n",
      "episode 12, val func loss 1.087276816368103\n",
      "\n",
      "episode 13, val func loss 1.3852591514587402\n",
      "\n",
      "episode 14, val func loss 1.3939746618270874\n",
      "\n",
      "episode 15, val func loss 1.5268491506576538\n",
      "\n",
      "episode 16, val func loss 0.901759147644043\n",
      "\n",
      "Val func train loss in epoch 10:1.1739079058170319\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.8575409054756165\n",
      "\n",
      "episode 2, val func loss 1.035373568534851\n",
      "\n",
      "episode 3, val func loss 1.3614027500152588\n",
      "\n",
      "episode 4, val func loss 1.35164213180542\n",
      "\n",
      "episode 5, val func loss 1.5300804376602173\n",
      "\n",
      "episode 6, val func loss 1.01580011844635\n",
      "\n",
      "episode 7, val func loss 0.8468301296234131\n",
      "\n",
      "episode 8, val func loss 1.4010268449783325\n",
      "\n",
      "episode 9, val func loss 1.1357002258300781\n",
      "\n",
      "episode 10, val func loss 1.1032013893127441\n",
      "\n",
      "episode 11, val func loss 1.1309579610824585\n",
      "\n",
      "episode 12, val func loss 1.2834628820419312\n",
      "\n",
      "episode 13, val func loss 0.7804310917854309\n",
      "\n",
      "episode 14, val func loss 1.2641184329986572\n",
      "\n",
      "episode 15, val func loss 1.3644038438796997\n",
      "\n",
      "episode 16, val func loss 0.9613173007965088\n",
      "\n",
      "Val func train loss in epoch 11:1.1514556258916855\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 1.3758602142333984\n",
      "\n",
      "episode 2, val func loss 0.8647730350494385\n",
      "\n",
      "episode 3, val func loss 1.4765933752059937\n",
      "\n",
      "episode 4, val func loss 1.409263014793396\n",
      "\n",
      "episode 5, val func loss 1.288466453552246\n",
      "\n",
      "episode 6, val func loss 1.1289387941360474\n",
      "\n",
      "episode 7, val func loss 1.0228716135025024\n",
      "\n",
      "episode 8, val func loss 1.0916523933410645\n",
      "\n",
      "episode 9, val func loss 1.36150324344635\n",
      "\n",
      "episode 10, val func loss 1.236163854598999\n",
      "\n",
      "episode 11, val func loss 0.8419403433799744\n",
      "\n",
      "episode 12, val func loss 1.2007986307144165\n",
      "\n",
      "episode 13, val func loss 1.000767469406128\n",
      "\n",
      "episode 14, val func loss 0.9369927644729614\n",
      "\n",
      "episode 15, val func loss 1.353026270866394\n",
      "\n",
      "episode 16, val func loss 1.272743582725525\n",
      "\n",
      "Val func train loss in epoch 12:1.1788971908390522\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.8740498423576355\n",
      "\n",
      "episode 2, val func loss 0.899042546749115\n",
      "\n",
      "episode 3, val func loss 1.3122673034667969\n",
      "\n",
      "episode 4, val func loss 1.0384845733642578\n",
      "\n",
      "episode 5, val func loss 1.1829588413238525\n",
      "\n",
      "episode 6, val func loss 1.0895473957061768\n",
      "\n",
      "episode 7, val func loss 1.3217792510986328\n",
      "\n",
      "episode 8, val func loss 0.7341458201408386\n",
      "\n",
      "episode 9, val func loss 0.8410648107528687\n",
      "\n",
      "episode 10, val func loss 1.321718454360962\n",
      "\n",
      "episode 11, val func loss 1.2448601722717285\n",
      "\n",
      "episode 12, val func loss 0.9517447352409363\n",
      "\n",
      "episode 13, val func loss 1.3739573955535889\n",
      "\n",
      "episode 14, val func loss 1.4690898656845093\n",
      "\n",
      "episode 15, val func loss 0.9852606654167175\n",
      "\n",
      "episode 16, val func loss 1.5538893938064575\n",
      "\n",
      "Val func train loss in epoch 13:1.1371163167059422\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.8537171483039856\n",
      "\n",
      "episode 2, val func loss 0.9504110813140869\n",
      "\n",
      "episode 3, val func loss 0.9710231423377991\n",
      "\n",
      "episode 4, val func loss 1.2944377660751343\n",
      "\n",
      "episode 5, val func loss 0.9207584857940674\n",
      "\n",
      "episode 6, val func loss 1.1198391914367676\n",
      "\n",
      "episode 7, val func loss 1.2194613218307495\n",
      "\n",
      "episode 8, val func loss 0.8947092294692993\n",
      "\n",
      "episode 9, val func loss 1.389122486114502\n",
      "\n",
      "episode 10, val func loss 0.8537302017211914\n",
      "\n",
      "episode 11, val func loss 1.3281877040863037\n",
      "\n",
      "episode 12, val func loss 1.3711202144622803\n",
      "\n",
      "episode 13, val func loss 1.20622718334198\n",
      "\n",
      "episode 14, val func loss 0.944015383720398\n",
      "\n",
      "episode 15, val func loss 1.2002519369125366\n",
      "\n",
      "episode 16, val func loss 1.0953043699264526\n",
      "\n",
      "Val func train loss in epoch 14:1.1007698029279709\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.9874438643455505\n",
      "\n",
      "episode 2, val func loss 0.9296005368232727\n",
      "\n",
      "episode 3, val func loss 1.070360541343689\n",
      "\n",
      "episode 4, val func loss 0.8597273826599121\n",
      "\n",
      "episode 5, val func loss 0.902767539024353\n",
      "\n",
      "episode 6, val func loss 0.87075275182724\n",
      "\n",
      "episode 7, val func loss 0.9910563826560974\n",
      "\n",
      "episode 8, val func loss 1.5264859199523926\n",
      "\n",
      "episode 9, val func loss 1.063114047050476\n",
      "\n",
      "episode 10, val func loss 1.2506396770477295\n",
      "\n",
      "episode 11, val func loss 1.2757842540740967\n",
      "\n",
      "episode 12, val func loss 1.3805313110351562\n",
      "\n",
      "episode 13, val func loss 1.307546615600586\n",
      "\n",
      "episode 14, val func loss 1.3139212131500244\n",
      "\n",
      "episode 15, val func loss 1.3097496032714844\n",
      "\n",
      "episode 16, val func loss 0.6349347829818726\n",
      "\n",
      "Val func train loss in epoch 15:1.1046510264277458\n",
      "***********************TIME WAS 4.937274845441182 min*****************************\n",
      "\n",
      "**********************ROUND 149 ***************************\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Return before training was 2.5\n",
      "==========Epoch 0=====================\n",
      "episode 1, policy loss 0.8893749117851257\n",
      "\n",
      "episode 2, policy loss 0.88942950963974\n",
      "\n",
      "episode 3, policy loss 0.889430820941925\n",
      "\n",
      "episode 4, policy loss 0.8893830180168152\n",
      "\n",
      "episode 5, policy loss 0.8893623948097229\n",
      "\n",
      "episode 6, policy loss 0.8892839550971985\n",
      "\n",
      "episode 7, policy loss 0.8893470764160156\n",
      "\n",
      "episode 8, policy loss 0.8893406391143799\n",
      "\n",
      "episode 9, policy loss 0.8892955780029297\n",
      "\n",
      "episode 10, policy loss 0.8893027901649475\n",
      "\n",
      "episode 11, policy loss 0.8892702460289001\n",
      "\n",
      "episode 12, policy loss 0.8892436623573303\n",
      "\n",
      "episode 13, policy loss 0.8892598748207092\n",
      "\n",
      "episode 14, policy loss 0.8891834020614624\n",
      "\n",
      "episode 15, policy loss 0.8891567587852478\n",
      "\n",
      "episode 16, policy loss 0.9543495774269104\n",
      "\n",
      "Policy train loss in epoch 0:0.893375888466835\n",
      "==========Epoch 1=====================\n",
      "episode 1, policy loss 0.8893468976020813\n",
      "\n",
      "episode 2, policy loss 0.889464259147644\n",
      "\n",
      "episode 3, policy loss 0.8895163536071777\n",
      "\n",
      "episode 4, policy loss 0.8896485567092896\n",
      "\n",
      "episode 5, policy loss 0.889706552028656\n",
      "\n",
      "episode 6, policy loss 0.9131430983543396\n",
      "\n",
      "episode 7, policy loss 0.8897613883018494\n",
      "\n",
      "episode 8, policy loss 0.8897915482521057\n",
      "\n",
      "episode 9, policy loss 0.8897961378097534\n",
      "\n",
      "episode 10, policy loss 0.8898205161094666\n",
      "\n",
      "episode 11, policy loss 0.8898271918296814\n",
      "\n",
      "episode 12, policy loss 0.8898497223854065\n",
      "\n",
      "episode 13, policy loss 0.8898566365242004\n",
      "\n",
      "episode 14, policy loss 0.8898736238479614\n",
      "\n",
      "episode 15, policy loss 0.8898784518241882\n",
      "\n",
      "episode 16, policy loss 0.8898782730102539\n",
      "\n",
      "Policy train loss in epoch 1:0.8911974504590034\n",
      "==========Epoch 2=====================\n",
      "episode 1, policy loss 0.8898900151252747\n",
      "\n",
      "episode 2, policy loss 0.8898859024047852\n",
      "\n",
      "episode 3, policy loss 0.9133187532424927\n",
      "\n",
      "episode 4, policy loss 0.8898916244506836\n",
      "\n",
      "episode 5, policy loss 0.8898925185203552\n",
      "\n",
      "episode 6, policy loss 0.8899005651473999\n",
      "\n",
      "episode 7, policy loss 0.8898954391479492\n",
      "\n",
      "episode 8, policy loss 0.889904797077179\n",
      "\n",
      "episode 9, policy loss 0.8899075984954834\n",
      "\n",
      "episode 10, policy loss 0.8899021148681641\n",
      "\n",
      "episode 11, policy loss 0.889906644821167\n",
      "\n",
      "episode 12, policy loss 0.8899142742156982\n",
      "\n",
      "episode 13, policy loss 0.8899156451225281\n",
      "\n",
      "episode 14, policy loss 0.8899050951004028\n",
      "\n",
      "episode 15, policy loss 0.8899205327033997\n",
      "\n",
      "episode 16, policy loss 0.8899052739143372\n",
      "\n",
      "Policy train loss in epoch 2:0.8913660496473312\n",
      "==========Epoch 3=====================\n",
      "episode 1, policy loss 0.8899131417274475\n",
      "\n",
      "episode 2, policy loss 0.8899124264717102\n",
      "\n",
      "episode 3, policy loss 0.8899016380310059\n",
      "\n",
      "episode 4, policy loss 0.8899078369140625\n",
      "\n",
      "episode 5, policy loss 0.8899024724960327\n",
      "\n",
      "episode 6, policy loss 0.9133368730545044\n",
      "\n",
      "episode 7, policy loss 0.8898984789848328\n",
      "\n",
      "episode 8, policy loss 0.8899177312850952\n",
      "\n",
      "episode 9, policy loss 0.8899104595184326\n",
      "\n",
      "episode 10, policy loss 0.889910876750946\n",
      "\n",
      "episode 11, policy loss 0.8899042010307312\n",
      "\n",
      "episode 12, policy loss 0.8899070024490356\n",
      "\n",
      "episode 13, policy loss 0.8899030089378357\n",
      "\n",
      "episode 14, policy loss 0.889906644821167\n",
      "\n",
      "episode 15, policy loss 0.8899064660072327\n",
      "\n",
      "episode 16, policy loss 0.889897346496582\n",
      "\n",
      "Policy train loss in epoch 3:0.8913710378110409\n",
      "==========Epoch 0=====================\n",
      "episode 1, val func loss 0.6491930484771729\n",
      "\n",
      "episode 2, val func loss 0.6838168501853943\n",
      "\n",
      "episode 3, val func loss 0.6045204401016235\n",
      "\n",
      "episode 4, val func loss 0.6066661477088928\n",
      "\n",
      "episode 5, val func loss 0.6638036966323853\n",
      "\n",
      "episode 6, val func loss 0.5970814824104309\n",
      "\n",
      "episode 7, val func loss 0.6636537909507751\n",
      "\n",
      "episode 8, val func loss 0.6407699584960938\n",
      "\n",
      "episode 9, val func loss 0.5937017202377319\n",
      "\n",
      "episode 10, val func loss 0.6350719928741455\n",
      "\n",
      "episode 11, val func loss 0.5928160548210144\n",
      "\n",
      "episode 12, val func loss 0.6564255356788635\n",
      "\n",
      "episode 13, val func loss 0.6229791045188904\n",
      "\n",
      "episode 14, val func loss 0.6256740093231201\n",
      "\n",
      "episode 15, val func loss 0.735804557800293\n",
      "\n",
      "episode 16, val func loss 0.5708919167518616\n",
      "\n",
      "Val func train loss in epoch 0:0.6339293941855431\n",
      "==========Epoch 1=====================\n",
      "episode 1, val func loss 0.6169489622116089\n",
      "\n",
      "episode 2, val func loss 0.5789960622787476\n",
      "\n",
      "episode 3, val func loss 0.5866170525550842\n",
      "\n",
      "episode 4, val func loss 0.5955939888954163\n",
      "\n",
      "episode 5, val func loss 0.6089969277381897\n",
      "\n",
      "episode 6, val func loss 0.5828683972358704\n",
      "\n",
      "episode 7, val func loss 0.5682597756385803\n",
      "\n",
      "episode 8, val func loss 0.5895253419876099\n",
      "\n",
      "episode 9, val func loss 0.6584120392799377\n",
      "\n",
      "episode 10, val func loss 0.5984936952590942\n",
      "\n",
      "episode 11, val func loss 0.6832469701766968\n",
      "\n",
      "episode 12, val func loss 0.6707461476325989\n",
      "\n",
      "episode 13, val func loss 0.5752137899398804\n",
      "\n",
      "episode 14, val func loss 0.5932086706161499\n",
      "\n",
      "episode 15, val func loss 0.8586622476577759\n",
      "\n",
      "episode 16, val func loss 0.6155630350112915\n",
      "\n",
      "Val func train loss in epoch 1:0.6238345690071583\n",
      "==========Epoch 2=====================\n",
      "episode 1, val func loss 0.5443560481071472\n",
      "\n",
      "episode 2, val func loss 0.7094453573226929\n",
      "\n",
      "episode 3, val func loss 0.6882179975509644\n",
      "\n",
      "episode 4, val func loss 0.6973537802696228\n",
      "\n",
      "episode 5, val func loss 0.6554453372955322\n",
      "\n",
      "episode 6, val func loss 0.6719194054603577\n",
      "\n",
      "episode 7, val func loss 0.5531138181686401\n",
      "\n",
      "episode 8, val func loss 0.5916053056716919\n",
      "\n",
      "episode 9, val func loss 0.645233154296875\n",
      "\n",
      "episode 10, val func loss 0.6922739148139954\n",
      "\n",
      "episode 11, val func loss 0.6457080245018005\n",
      "\n",
      "episode 12, val func loss 0.7221446633338928\n",
      "\n",
      "episode 13, val func loss 0.6149442195892334\n",
      "\n",
      "episode 14, val func loss 0.6306805610656738\n",
      "\n",
      "episode 15, val func loss 0.5905922651290894\n",
      "\n",
      "episode 16, val func loss 0.5459306836128235\n",
      "\n",
      "Val func train loss in epoch 2:0.6374352835118771\n",
      "==========Epoch 3=====================\n",
      "episode 1, val func loss 0.6092844009399414\n",
      "\n",
      "episode 2, val func loss 0.6752733588218689\n",
      "\n",
      "episode 3, val func loss 0.619049608707428\n",
      "\n",
      "episode 4, val func loss 0.5936326384544373\n",
      "\n",
      "episode 5, val func loss 0.617509663105011\n",
      "\n",
      "episode 6, val func loss 0.6288378238677979\n",
      "\n",
      "episode 7, val func loss 0.6482440233230591\n",
      "\n",
      "episode 8, val func loss 0.61742103099823\n",
      "\n",
      "episode 9, val func loss 0.7221885323524475\n",
      "\n",
      "episode 10, val func loss 0.5720828771591187\n",
      "\n",
      "episode 11, val func loss 0.5395964980125427\n",
      "\n",
      "episode 12, val func loss 0.6369383335113525\n",
      "\n",
      "episode 13, val func loss 0.6500277519226074\n",
      "\n",
      "episode 14, val func loss 0.7349029183387756\n",
      "\n",
      "episode 15, val func loss 0.5428553819656372\n",
      "\n",
      "episode 16, val func loss 0.7790209054946899\n",
      "\n",
      "Val func train loss in epoch 3:0.6366791091859341\n",
      "==========Epoch 4=====================\n",
      "episode 1, val func loss 0.7025347352027893\n",
      "\n",
      "episode 2, val func loss 0.5727927088737488\n",
      "\n",
      "episode 3, val func loss 0.5765224099159241\n",
      "\n",
      "episode 4, val func loss 0.5950296521186829\n",
      "\n",
      "episode 5, val func loss 0.5990065336227417\n",
      "\n",
      "episode 6, val func loss 0.6264625191688538\n",
      "\n",
      "episode 7, val func loss 0.6389244198799133\n",
      "\n",
      "episode 8, val func loss 0.7905251979827881\n",
      "\n",
      "episode 9, val func loss 0.5632308721542358\n",
      "\n",
      "episode 10, val func loss 0.6730148792266846\n",
      "\n",
      "episode 11, val func loss 0.5945652723312378\n",
      "\n",
      "episode 12, val func loss 0.6584073305130005\n",
      "\n",
      "episode 13, val func loss 0.6266608834266663\n",
      "\n",
      "episode 14, val func loss 0.6772199273109436\n",
      "\n",
      "episode 15, val func loss 0.6967709064483643\n",
      "\n",
      "episode 16, val func loss 0.5966358184814453\n",
      "\n",
      "Val func train loss in epoch 4:0.6367690041661263\n",
      "==========Epoch 5=====================\n",
      "episode 1, val func loss 0.5891503691673279\n",
      "\n",
      "episode 2, val func loss 0.7352373600006104\n",
      "\n",
      "episode 3, val func loss 0.5908944010734558\n",
      "\n",
      "episode 4, val func loss 0.6626984477043152\n",
      "\n",
      "episode 5, val func loss 0.6049168109893799\n",
      "\n",
      "episode 6, val func loss 0.5645555257797241\n",
      "\n",
      "episode 7, val func loss 0.6629468202590942\n",
      "\n",
      "episode 8, val func loss 0.637263834476471\n",
      "\n",
      "episode 9, val func loss 0.7317082285881042\n",
      "\n",
      "episode 10, val func loss 0.6095696687698364\n",
      "\n",
      "episode 11, val func loss 0.6026828289031982\n",
      "\n",
      "episode 12, val func loss 0.6256424784660339\n",
      "\n",
      "episode 13, val func loss 0.6643327474594116\n",
      "\n",
      "episode 14, val func loss 0.6227434277534485\n",
      "\n",
      "episode 15, val func loss 0.5514008402824402\n",
      "\n",
      "episode 16, val func loss 0.5909044146537781\n",
      "\n",
      "Val func train loss in epoch 5:0.6279155127704144\n",
      "==========Epoch 6=====================\n",
      "episode 1, val func loss 0.6390079855918884\n",
      "\n",
      "episode 2, val func loss 0.5469256639480591\n",
      "\n",
      "episode 3, val func loss 0.6059843897819519\n",
      "\n",
      "episode 4, val func loss 0.7504093647003174\n",
      "\n",
      "episode 5, val func loss 0.6964219808578491\n",
      "\n",
      "episode 6, val func loss 0.6696307063102722\n",
      "\n",
      "episode 7, val func loss 0.5560709834098816\n",
      "\n",
      "episode 8, val func loss 0.6833021640777588\n",
      "\n",
      "episode 9, val func loss 0.6296300888061523\n",
      "\n",
      "episode 10, val func loss 0.6348235011100769\n",
      "\n",
      "episode 11, val func loss 0.6396110653877258\n",
      "\n",
      "episode 12, val func loss 0.6358316540718079\n",
      "\n",
      "episode 13, val func loss 0.6008474826812744\n",
      "\n",
      "episode 14, val func loss 0.6240756511688232\n",
      "\n",
      "episode 15, val func loss 0.5117986798286438\n",
      "\n",
      "episode 16, val func loss 0.6129785180091858\n",
      "\n",
      "Val func train loss in epoch 6:0.6273343674838543\n",
      "==========Epoch 7=====================\n",
      "episode 1, val func loss 0.6195292472839355\n",
      "\n",
      "episode 2, val func loss 0.6468459367752075\n",
      "\n",
      "episode 3, val func loss 0.5136815905570984\n",
      "\n",
      "episode 4, val func loss 0.6581758260726929\n",
      "\n",
      "episode 5, val func loss 0.6752998232841492\n",
      "\n",
      "episode 6, val func loss 0.6431772708892822\n",
      "\n",
      "episode 7, val func loss 0.5772832632064819\n",
      "\n",
      "episode 8, val func loss 0.6742011308670044\n",
      "\n",
      "episode 9, val func loss 0.6663540601730347\n",
      "\n",
      "episode 10, val func loss 0.6952565312385559\n",
      "\n",
      "episode 11, val func loss 0.6257225275039673\n",
      "\n",
      "episode 12, val func loss 0.6290561556816101\n",
      "\n",
      "episode 13, val func loss 0.6273393630981445\n",
      "\n",
      "episode 14, val func loss 0.5659030675888062\n",
      "\n",
      "episode 15, val func loss 0.5304242372512817\n",
      "\n",
      "episode 16, val func loss 0.7504544854164124\n",
      "\n",
      "Val func train loss in epoch 7:0.631169032305479\n",
      "==========Epoch 8=====================\n",
      "episode 1, val func loss 0.58558189868927\n",
      "\n",
      "episode 2, val func loss 0.7205145359039307\n",
      "\n",
      "episode 3, val func loss 0.6737291812896729\n",
      "\n",
      "episode 4, val func loss 0.6159102320671082\n",
      "\n",
      "episode 5, val func loss 0.5751971006393433\n",
      "\n",
      "episode 6, val func loss 0.5267205834388733\n",
      "\n",
      "episode 7, val func loss 0.6902023553848267\n",
      "\n",
      "episode 8, val func loss 0.6076874136924744\n",
      "\n",
      "episode 9, val func loss 0.5222345590591431\n",
      "\n",
      "episode 10, val func loss 0.6360127329826355\n",
      "\n",
      "episode 11, val func loss 0.5525205135345459\n",
      "\n",
      "episode 12, val func loss 0.5834106802940369\n",
      "\n",
      "episode 13, val func loss 0.6881408095359802\n",
      "\n",
      "episode 14, val func loss 0.6025582551956177\n",
      "\n",
      "episode 15, val func loss 0.5438937544822693\n",
      "\n",
      "episode 16, val func loss 0.5943001508712769\n",
      "\n",
      "Val func train loss in epoch 8:0.6074134223163128\n",
      "==========Epoch 9=====================\n",
      "episode 1, val func loss 0.7353345155715942\n",
      "\n",
      "episode 2, val func loss 0.702389121055603\n",
      "\n",
      "episode 3, val func loss 0.6361507177352905\n",
      "\n",
      "episode 4, val func loss 0.6397783160209656\n",
      "\n",
      "episode 5, val func loss 0.6250706911087036\n",
      "\n",
      "episode 6, val func loss 0.5417150259017944\n",
      "\n",
      "episode 7, val func loss 0.6352050304412842\n",
      "\n",
      "episode 8, val func loss 0.6976019740104675\n",
      "\n",
      "episode 9, val func loss 0.6035088896751404\n",
      "\n",
      "episode 10, val func loss 0.6153789758682251\n",
      "\n",
      "episode 11, val func loss 0.7093076705932617\n",
      "\n",
      "episode 12, val func loss 0.678447961807251\n",
      "\n",
      "episode 13, val func loss 0.6079199314117432\n",
      "\n",
      "episode 14, val func loss 0.577400267124176\n",
      "\n",
      "episode 15, val func loss 0.6386125683784485\n",
      "\n",
      "episode 16, val func loss 0.6853863596916199\n",
      "\n",
      "Val func train loss in epoch 9:0.645575501024723\n",
      "==========Epoch 10=====================\n",
      "episode 1, val func loss 0.6050052642822266\n",
      "\n",
      "episode 2, val func loss 0.6368933916091919\n",
      "\n",
      "episode 3, val func loss 0.616774320602417\n",
      "\n",
      "episode 4, val func loss 0.641058623790741\n",
      "\n",
      "episode 5, val func loss 0.6880603432655334\n",
      "\n",
      "episode 6, val func loss 0.6537203788757324\n",
      "\n",
      "episode 7, val func loss 0.7226291298866272\n",
      "\n",
      "episode 8, val func loss 0.6612139344215393\n",
      "\n",
      "episode 9, val func loss 0.622056782245636\n",
      "\n",
      "episode 10, val func loss 0.5795758962631226\n",
      "\n",
      "episode 11, val func loss 0.6361079812049866\n",
      "\n",
      "episode 12, val func loss 0.638920247554779\n",
      "\n",
      "episode 13, val func loss 0.6707509160041809\n",
      "\n",
      "episode 14, val func loss 0.5485159158706665\n",
      "\n",
      "episode 15, val func loss 0.6338468194007874\n",
      "\n",
      "episode 16, val func loss 0.5890775322914124\n",
      "\n",
      "Val func train loss in epoch 10:0.6340129673480988\n",
      "==========Epoch 11=====================\n",
      "episode 1, val func loss 0.6340270638465881\n",
      "\n",
      "episode 2, val func loss 0.5368906855583191\n",
      "\n",
      "episode 3, val func loss 0.6920663118362427\n",
      "\n",
      "episode 4, val func loss 0.7015745639801025\n",
      "\n",
      "episode 5, val func loss 0.8554829359054565\n",
      "\n",
      "episode 6, val func loss 0.6771073937416077\n",
      "\n",
      "episode 7, val func loss 0.626577615737915\n",
      "\n",
      "episode 8, val func loss 0.5710985064506531\n",
      "\n",
      "episode 9, val func loss 0.5954787731170654\n",
      "\n",
      "episode 10, val func loss 0.6694684624671936\n",
      "\n",
      "episode 11, val func loss 0.5320213437080383\n",
      "\n",
      "episode 12, val func loss 0.7147805690765381\n",
      "\n",
      "episode 13, val func loss 0.5548480749130249\n",
      "\n",
      "episode 14, val func loss 0.6146751046180725\n",
      "\n",
      "episode 15, val func loss 0.6137974858283997\n",
      "\n",
      "episode 16, val func loss 0.6675006151199341\n",
      "\n",
      "Val func train loss in epoch 11:0.641087219119072\n",
      "==========Epoch 12=====================\n",
      "episode 1, val func loss 0.5741108655929565\n",
      "\n",
      "episode 2, val func loss 0.5564666390419006\n",
      "\n",
      "episode 3, val func loss 0.6165822744369507\n",
      "\n",
      "episode 4, val func loss 0.6408350467681885\n",
      "\n",
      "episode 5, val func loss 0.5223422646522522\n",
      "\n",
      "episode 6, val func loss 0.6020094156265259\n",
      "\n",
      "episode 7, val func loss 0.5787362456321716\n",
      "\n",
      "episode 8, val func loss 0.6942920684814453\n",
      "\n",
      "episode 9, val func loss 0.6051609516143799\n",
      "\n",
      "episode 10, val func loss 0.5890809297561646\n",
      "\n",
      "episode 11, val func loss 0.6739529371261597\n",
      "\n",
      "episode 12, val func loss 0.5295647978782654\n",
      "\n",
      "episode 13, val func loss 0.585830569267273\n",
      "\n",
      "episode 14, val func loss 0.5607134103775024\n",
      "\n",
      "episode 15, val func loss 0.5642136335372925\n",
      "\n",
      "episode 16, val func loss 0.5956774950027466\n",
      "\n",
      "Val func train loss in epoch 12:0.593098096549511\n",
      "==========Epoch 13=====================\n",
      "episode 1, val func loss 0.5955994725227356\n",
      "\n",
      "episode 2, val func loss 0.5498256683349609\n",
      "\n",
      "episode 3, val func loss 0.6444185376167297\n",
      "\n",
      "episode 4, val func loss 0.5581395030021667\n",
      "\n",
      "episode 5, val func loss 0.5823419094085693\n",
      "\n",
      "episode 6, val func loss 0.711097240447998\n",
      "\n",
      "episode 7, val func loss 0.6399440765380859\n",
      "\n",
      "episode 8, val func loss 0.5467701554298401\n",
      "\n",
      "episode 9, val func loss 0.5800574421882629\n",
      "\n",
      "episode 10, val func loss 0.5855810642242432\n",
      "\n",
      "episode 11, val func loss 0.5570233464241028\n",
      "\n",
      "episode 12, val func loss 0.5098215341567993\n",
      "\n",
      "episode 13, val func loss 0.5077020525932312\n",
      "\n",
      "episode 14, val func loss 0.5804436206817627\n",
      "\n",
      "episode 15, val func loss 0.6067894697189331\n",
      "\n",
      "episode 16, val func loss 0.6935833692550659\n",
      "\n",
      "Val func train loss in epoch 13:0.590571153908968\n",
      "==========Epoch 14=====================\n",
      "episode 1, val func loss 0.660971999168396\n",
      "\n",
      "episode 2, val func loss 0.6683052182197571\n",
      "\n",
      "episode 3, val func loss 0.573991060256958\n",
      "\n",
      "episode 4, val func loss 0.5738957524299622\n",
      "\n",
      "episode 5, val func loss 0.6118263006210327\n",
      "\n",
      "episode 6, val func loss 0.5448096990585327\n",
      "\n",
      "episode 7, val func loss 0.6812881231307983\n",
      "\n",
      "episode 8, val func loss 0.6613943576812744\n",
      "\n",
      "episode 9, val func loss 0.681833028793335\n",
      "\n",
      "episode 10, val func loss 0.7129796147346497\n",
      "\n",
      "episode 11, val func loss 0.6604176759719849\n",
      "\n",
      "episode 12, val func loss 0.6115701198577881\n",
      "\n",
      "episode 13, val func loss 0.6448785066604614\n",
      "\n",
      "episode 14, val func loss 0.557857871055603\n",
      "\n",
      "episode 15, val func loss 0.5772795081138611\n",
      "\n",
      "episode 16, val func loss 0.6526025533676147\n",
      "\n",
      "Val func train loss in epoch 14:0.6297438368201256\n",
      "==========Epoch 15=====================\n",
      "episode 1, val func loss 0.5639463067054749\n",
      "\n",
      "episode 2, val func loss 0.49167609214782715\n",
      "\n",
      "episode 3, val func loss 0.5924110412597656\n",
      "\n",
      "episode 4, val func loss 0.61098313331604\n",
      "\n",
      "episode 5, val func loss 0.5568877458572388\n",
      "\n",
      "episode 6, val func loss 0.5834185481071472\n",
      "\n",
      "episode 7, val func loss 0.5562577247619629\n",
      "\n",
      "episode 8, val func loss 0.5000520944595337\n",
      "\n",
      "episode 9, val func loss 0.7477781176567078\n",
      "\n",
      "episode 10, val func loss 0.5902472734451294\n",
      "\n",
      "episode 11, val func loss 0.70583176612854\n",
      "\n",
      "episode 12, val func loss 0.5374972224235535\n",
      "\n",
      "episode 13, val func loss 0.6808310151100159\n",
      "\n",
      "episode 14, val func loss 0.5588871836662292\n",
      "\n",
      "episode 15, val func loss 0.6869323253631592\n",
      "\n",
      "episode 16, val func loss 0.6692631840705872\n",
      "\n",
      "Val func train loss in epoch 15:0.602056298404932\n",
      "***********************TIME WAS 4.934969552357992 min*****************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_buffers=16 # keep it simpler\n",
    "num_rounds = 150 # give it more of a chance to learn policy, which can only change a little over each round.\n",
    "for i in range(num_rounds):\n",
    "    start = time.time()\n",
    "    print(f\"**********************ROUND {i} ***************************\\n\")\n",
    "    run_round(i, policy_optimizer, val_optimizer, num_buffers, policy_epochs, val_epochs, policy_clip_range, entropy_loss_weight)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"***********************TIME WAS {elapsed / 60} min*****************************\\n\")\n",
    "    # I think the entropy was too low last time, let's see if this fixes the issue.\n",
    "    if i > 40:\n",
    "        entropy_loss_weight = max(entropy_loss_weight / 2, 1e-4)#1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d3d395a-839a-45f7-8f79-cfbfa0e90751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "bb = get_bb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96ce72c0-29f1-48dd-bd1a-18cdca882626",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = bb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71843156-cf00-48a4-b862-03ec2e501a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ppo_helper.SentenceOutputSingleEpisode at 0x7f29a38eb950>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a388eee-55cb-4e0e-9068-35a92241ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "055b7571-6ce4-4df1-ba5b-157892cbdfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.traces[0, b.seed_offset - 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a0eb8bf-7528-4f0b-bc92-56cc5d79222f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6, 5, 5, 3, 6, 4, 4, 5, 3], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.traces[0, :b.seed_offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c61e4553-3585-4124-8f6d-be73751f6268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.terminated[0, :b.seed_offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6deb2f4-56f3-4cff-97f2-8c52065b13e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right, this only includes the seed_offset and forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ae178a9-18b3-4c94-96ec-8bd3a94cb181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.]], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba255e87-4340-4977-a554-242c130580f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.],\n",
       "        [0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "         5., 5., 5., 5., 5.]], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33253a1b-47c7-4103-9238-5870e4fb0889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4634, 4.3715, 4.5108, 5.0831, 4.1181, 4.8333, 4.9635, 3.9916, 4.2776,\n",
       "         4.1128, 4.3017, 5.3786, 3.9250, 5.1134, 4.1784, 4.1687, 5.1195, 4.5503,\n",
       "         5.3096, 4.7779, 5.1868, 4.6155, 4.4610],\n",
       "        [2.1432, 4.2237, 4.3687, 4.2824, 4.4731, 4.2677, 4.8788, 4.7567, 4.2276,\n",
       "         4.3233, 4.9661, 4.9824, 4.4496, 4.8898, 4.9468, 4.0156, 6.0770, 5.4565,\n",
       "         4.9377, 4.0246, 5.2688, 5.3207, 4.9316],\n",
       "        [2.7244, 3.8690, 4.6356, 4.1560, 4.4666, 4.2487, 4.4653, 4.2932, 4.2075,\n",
       "         4.6175, 4.4669, 5.2189, 5.4922, 4.6494, 5.1375, 3.8699, 3.9895, 5.3308,\n",
       "         4.7931, 4.4217, 4.6379, 5.6374, 5.4216],\n",
       "        [2.7236, 4.2479, 4.6708, 4.0291, 4.5579, 4.2675, 4.5704, 4.5645, 4.6824,\n",
       "         4.2967, 4.7550, 5.3980, 5.3288, 6.5061, 5.0135, 4.7007, 5.2294, 5.0667,\n",
       "         5.0433, 5.0298, 4.7801, 4.7716, 5.0897],\n",
       "        [2.9831, 4.6749, 4.4412, 4.3566, 3.6912, 4.2229, 4.0773, 4.4642, 4.6372,\n",
       "         4.5166, 4.2040, 5.0360, 4.5983, 4.7178, 4.5089, 4.9249, 4.6426, 5.8348,\n",
       "         4.7000, 3.7906, 5.0078, 5.6434, 5.2988],\n",
       "        [2.7764, 3.8130, 4.2383, 4.0945, 4.5614, 4.6357, 4.8396, 4.9836, 5.1211,\n",
       "         4.7672, 4.6260, 4.9786, 4.6633, 3.8152, 5.7756, 4.4864, 4.8101, 4.5802,\n",
       "         5.2047, 3.8900, 4.7064, 5.0505, 5.8962],\n",
       "        [2.7374, 3.7604, 4.4656, 4.0099, 4.2678, 4.6542, 4.6077, 5.0299, 4.9698,\n",
       "         5.4895, 4.6728, 4.7050, 5.3133, 4.8364, 5.2012, 4.1857, 5.3266, 4.5123,\n",
       "         5.3491, 5.7357, 4.5275, 5.0045, 5.3275],\n",
       "        [2.7899, 4.1166, 4.8157, 4.3603, 4.4808, 4.6595, 4.5402, 4.7170, 4.1082,\n",
       "         4.7961, 5.9984, 4.4014, 5.3707, 4.8209, 3.6540, 4.1592, 4.7707, 5.6385,\n",
       "         4.5687, 5.7455, 4.5701, 3.7725, 5.9081]], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2346e9e3-67b0-4680-bee4-209488e7266a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.traces[1, b.seed_offset - 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bde46aeb-6e91-4f8b-8650-92bb66f07007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5.], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.rewards[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e2b5f67-19fb-4b6b-a953-2456ad47eecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.25"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_return(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d285fe1c-b5b7-4117-a08a-8c7b0882aaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3379200"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*64*22*150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4991324-e181-4e02-918b-81132f5bf832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1865bc87-bcf7-4316-a33c-5be1e5f78d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
