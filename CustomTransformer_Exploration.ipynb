{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f505036-1e27-4a6e-b669-0ad82021caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "# from https://medium.com/towards-data-science/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cfca2b3-c989-49c7-859f-b10f8cdd4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(36, 6).cuda()\n",
    "\n",
    "x = torch.randn(1, 10, 36).cuda()\n",
    "y = torch.randn(1, 5, 36).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "344eccd5-40f9-474a-bf03-f05fd7e67c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mha(x, x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d43b5cb-f1f5-46c8-9c95-4d7fe0da676f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 36])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "605a42ca-1545-4690-87d2-d788665d2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = mha(x, y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c63f0dcc-f97e-4b1a-ad92-6396228b7dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 36])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "447ba12a-0745-475d-9a06-4c79cf89a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = mha.split_heads(mha.W_q(x))\n",
    "K = mha.split_heads(mha.W_k(y))\n",
    "V = mha.split_heads(mha.W_v(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b76e64e-8fa1-432a-bcf4-bb2f08436957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 10, 6])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d5c36d1-8e90-438f-880d-a8663c0c7af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 5, 6])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7abda78-f7e9-4953-b42a-a9ce1388b4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 5, 6])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "095fc0c0-7cce-47f5-b708-67aca42becde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 6, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.transpose(-2, -1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40d29654-68f6-4182-bb9f-721b05b2757c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 10, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.matmul(Q, K.transpose(-2, -1))\n",
    "scores.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d410cfb8-59aa-473b-963a-c6bf9526d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(scores, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c08df08-44b4-4850-b295-29ce00c9f81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 10, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e396df7b-0055-42c0-8ede-277c771c41b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 10, 6])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.matmul(probs, V)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8289dcbf-7c05-4d01-b6ba-07ffb1c279c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 36])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = mha.W_o(mha.combine_heads(out))\n",
    "final.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83add79b-024d-4cc4-8e48-7856959b1191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, I finally understand decoders.\n",
    "# No need to code up the full implementation. Boring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c17599-d987-4ee9-b0ed-eecc2fa43108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
