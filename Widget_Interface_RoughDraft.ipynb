{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e490d674-0492-4826-9e34-47944bb4e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FIRST 4 CELLS: specify frameworks, external imports, and the exact brain checkpoint used.\n",
    "# The other cells specify funcs for the widget, which is at the bottom\n",
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "from control_framework import *\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c995e3-9282-41fe-bcec-b779896818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e76133-fa47-472e-ba9f-1959fc6ed499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedAgentBrain()\n",
    "model.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_v2_batch160799.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v2_batch55900.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v2_batch24800.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v3_batch155466.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v4_batch399.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v5_batch133.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_v2_batch29398.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_v3_batch35249.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_de_novo_v1_batch41200.pth'\n",
    "#fname = 'brain_checkpoints/super_brain_retraining_control_arrow_v1_batch33400.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_transferred.pth'\n",
    "#fname = 'brain_checkpoints/super_brain_retraining_control_arrow_RESTART_v1_batch31799.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_canvases_v1_batch33597.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_canvases_v2_batch25999.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_canvases_v3_batch19998.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v1_batch4665.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v2_batch2244.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v2_batch9996.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v3_batch1799.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v3_batch6595.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v3_batch19198.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v4_batch10000.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v6_batch10993.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v7_batch115487.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v7_batch1100.pth'\n",
    "fname = 'brain_checkpoints/frankenstein_tutorialQA_v8_batch13196.pth'\n",
    "\n",
    "# A little extra code to avoid weird error\n",
    "#model.memory.remember(torch.randn(16, 1, 768).to(device))\n",
    "model.memory.remember(torch.randn(8, 1, 768).to(device))\n",
    "\n",
    "model.load_state_dict(torch.load(fname, weights_only=True, map_location=device))\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1361e168-adf8-453b-ac4a-5825ef046c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other elements to use\n",
    "\n",
    "from game import *\n",
    "\n",
    "game_settings = BIG_tool_use_advanced_2_5\n",
    "game_settings.gameSize = 224 # for compatibility with brain's expected size\n",
    "G = discreteGame(game_settings)\n",
    "\n",
    "####\n",
    "\n",
    "#For this time:\n",
    "def reset_G():\n",
    "    global G\n",
    "    G = discreteGame(G.random_bare_settings(gameSize=224, max_agent_offset=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b1ce00-688f-4a7b-aba0-4700d9341a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f371e5eac60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reset_G()\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e8492d-8c1e-4389-b871-31e9d30340b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis notebook is to show the EnhancedBrain input, output, and state of mind at once.\n",
    "# I'll start with a rough version and make it cleaner over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a6d7d3-7701-4ad6-aedf-9d1da7612150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79f707fd-090f-42d3-92ed-b2ed1d87c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8946d87-c09e-4eba-897f-5f81c5211bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_imshow_numpy(torch_img, imshow=False):\n",
    "    clean = torch_img.detach()[0].cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b95dcd9-2119-47fb-a2b8-6713e5b28b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output(layout={'border': '1px solid black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a55bbb-7aae-4acf-8232-baed2cc9f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = EnhancedAgentBrain()\n",
    "#model.move_to(device)\n",
    "#2+2\n",
    "# commment to prevent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37dd7bcf-415e-4a8a-8078-7716f8ce17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "# tokenizer.save_model(\".\", \"tokenizer/eng_sentences_tokenizer_vc10000\")\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-vocab.json\",\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-merges.txt\",\n",
    ")   \n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")   \n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b38a1d-479c-46d6-a3f7-b7e77181f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = widgets.Textarea(\n",
    "    value='Hello World',\n",
    "    placeholder='Type something',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ee3f89-d4b9-45f4-9e54-0ca7a6c40866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(game=None):\n",
    "    if game is None:\n",
    "        game = G\n",
    "    img = torch.FloatTensor(G.getData()).unsqueeze(0)\n",
    "    img = torch.permute(img, (0, 3, 1, 2)).contiguous().to(device)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aed9588-a3c7-4fe3-8e5f-9fc29fe9a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a475188-3a0a-4aac-8a2e-36456c557cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this for other inputs\n",
    "# inp_tensor = get_image()\n",
    "inp_tensor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab32506-2f60-4969-afdf-4fc35ccf8b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   32,   87,   34, 5411, 4226,    5,   32,   19,   87,   34,    2]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.tensor(tokenizer.encode(\"<s>Hello World!</s>\").ids).unsqueeze(0).contiguous().to(device)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1930a98-8161-4c7a-b1c0-4dca5f2bf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Hello World!</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tt[0][1:-1].cpu().numpy(), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b88d78ff-8c78-4c99-88be-0a7340a40b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"<s>Hello World!</s>\".find('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2da1651-dd24-4a73-a246-cbc3f5feb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def display_innards(b):\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    print(\"Canvases:\\n\")\n",
    "    if model.canvases.is_empty():\n",
    "        print(\"################\\nCanvases object is empty, nothing to show\\n################\")\n",
    "    else:\n",
    "        for i in range(model.canvases.num_canvases):\n",
    "            print(f\"##########\\nCanvas {i}:\\n\")\n",
    "            plt.imshow(pre_imshow_numpy(model.canvases.tw.L[i][:1]))\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b5eebc-b0a8-4252-bee8-eda5c4f1de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def forward_wrapper(b):\n",
    "    output.clear_output()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "    tt = torch.tensor(tokenizer.encode(T.value).ids).unsqueeze(0).contiguous().to(device)\n",
    "    _, recon = model(tt, local_tensor, create_context=True, ret_imgs=True)\n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b)\n",
    "\n",
    "# wrapper for extending input text without changing what is displayed, much\n",
    "\n",
    "temp=1.0\n",
    "temp_eps = 1e-4\n",
    "\n",
    "special_symbols = set([1, 3, 4, 108])\n",
    "symbol_action_map = { 1:1, 3:3, 4:4, 108:2}\n",
    "\n",
    "@output.capture()\n",
    "def extend_wrapper(b):\n",
    "    output.clear_output()\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "\n",
    "    # in this case, we abridge the end-of-sentence token in order to continue the extension\n",
    "    inp_ids = tokenizer.encode(T.value).ids[:-1]\n",
    "    if len(inp_ids) > 32:\n",
    "        inp_ids = inp_ids[-32:] # the rest should be in memory\n",
    "    tt = torch.tensor(inp_ids).unsqueeze(0).contiguous().to(device)\n",
    "    logits, recon = model(tt, local_tensor, return_full=False, create_context=True, ret_imgs=True)\n",
    "\n",
    "    s = tt.size()\n",
    "    output_text = torch.zeros((s[0], s[1] +1), dtype = torch.long, device=device)\n",
    "    output_text[:, :-1] += tt\n",
    "    \n",
    "    preds = model.select(logits, temp, ret_all=False, temp_eps=temp_eps)\n",
    "    output_text[:, -1] += preds\n",
    "\n",
    "    predval = preds[0].item()\n",
    "    if predval in special_symbols:\n",
    "        action = symbol_action_map[predval]\n",
    "        print(f\"Detected special token {predval} which is action {action}\")\n",
    "        reward = G.actions[action]()\n",
    "        print(f\"Reward was {reward}\")\n",
    "    \n",
    "    T.value = tokenizer.decode(output_text[0][1:].cpu().numpy(), skip_special_tokens=False) # update the string, cut off start token\n",
    "    print(\"updated input string (also in text box):\\n\")\n",
    "    print(T.value)\n",
    "    \n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b) # including game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3fcd589-cd91-488f-a7fd-74ca60b781e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def soft_reset_wrapper(b):\n",
    "    print(\"soft reset (removing internal gradients)\\n\")\n",
    "    model.soft_reset()\n",
    "\n",
    "@output.capture()\n",
    "def reset_wrapper(b):\n",
    "    print(\"hard reset (clering memory and canvaases)\\n\")\n",
    "    model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7217f2f9-400e-49bc-ac6f-0852225ee038",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32 # max len of the model input. Make this a text box or a selector or a knob.\n",
    "\n",
    "@output.capture()\n",
    "def generate_wrapper(b):\n",
    "    # while the string is not too long nor contains the stop codon\n",
    "    while (T.value.find('</s>') == -1) and (len(tokenizer.encode(T.value).ids[:-1]) < max_len):\n",
    "        extend_wrapper(b)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62c779c1-427b-4e9f-8eeb-0c9ec08ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_clear_button_clicked(b):\n",
    "    output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63bf60f2-d3b4-475c-b3d1-0ea1f2ea80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_G_wrapper(b):\n",
    "    reset_G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e6978ff-0314-4b5e-af6b-ad9a57deb475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedAgentBrain(\n",
       "  (img_enc): ImageTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): PatchEmbedding(\n",
       "        (linear_project): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (1): PositionalEncoding_2D()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (img_dec): ImageTransformerDecoder(\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.01, inplace=False)\n",
       "          (dropout2): Dropout(p=0.01, inplace=False)\n",
       "          (dropout3): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): PatchEmbeddingTranspose(\n",
       "        (linear_project): ConvTranspose2d(768, 3, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (img_weight): VisionWeightedSum(\n",
       "    (pe): PositionalEncoding()\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (text_enc): SentenceTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): Embedding(10000, 768, padding_idx=0)\n",
       "      (1): PositionalEncoding()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_dec): SentenceTransformerDecoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=3072, out_features=10000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dopamine): DopamineWrapper(\n",
       "    (dopamine): IntermediateTransformerScorer(\n",
       "      (decoder): TransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=3072, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (memory): Memory()\n",
       "  (mem_enc): MemoryEncoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_prep): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (fcs): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4256368e-b469-4e71-8f44-44339c70847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dc4c8e1f2341f791fd534028b9360b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset Game', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b3bf506dc24cd28bfa688e214e0d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Forward', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a9748d8c1b4058bdbb50ceb8f95d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Soft Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cc1f02c9f84b938594d40fe7993dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c1b138ae4f49f0a2a405a7dc8da57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Extend by One Character', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3d0ca7d3564a8eb5037b05f141d4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Text', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc80d992a3c45e7beaa1a7f2f961ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Canvases', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b300f82442d74816b13d41cd6ecb709a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clear Output', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dbe824e2584f3aba53e6fc391ebb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Hello World', description='String:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd8bb1d0e754e1ba6f1a64407bfcfc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bGameReset = widgets.Button(description=\"Reset Game\")\n",
    "bForward = widgets.Button(description=\"Forward\")\n",
    "bSoftReset = widgets.Button(description=\"Soft Reset\")\n",
    "bReset = widgets.Button(description=\"Reset\")\n",
    "bExtend = widgets.Button(description=\"Extend by One Character\")\n",
    "bGenerate = widgets.Button(description=\"Generate Text\")\n",
    "bDisplayInnards = widgets.Button(description=\"Show Canvases\")\n",
    "bClear = widgets.Button(description=\"Clear Output\")\n",
    "\n",
    "display(bGameReset)\n",
    "display(bForward)\n",
    "display(bSoftReset)\n",
    "display(bReset)\n",
    "display(bExtend)\n",
    "display(bGenerate)\n",
    "display(bDisplayInnards)\n",
    "display(bClear)\n",
    "\n",
    "display(T) # expand me by hand; prettier that way\n",
    "\n",
    "bGameReset.on_click(reset_G_wrapper)\n",
    "bForward.on_click(forward_wrapper)\n",
    "bSoftReset.on_click(soft_reset_wrapper)\n",
    "bReset.on_click(reset_wrapper)\n",
    "bExtend.on_click(extend_wrapper)\n",
    "bGenerate.on_click(generate_wrapper)\n",
    "bDisplayInnards.on_click(display_innards)\n",
    "bClear.on_click(on_clear_button_clicked)\n",
    "\n",
    "display(output)\n",
    "display_innards(bDisplayInnards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513eec8-92db-4672-bdf4-9bde727c09a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
