{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e490d674-0492-4826-9e34-47944bb4e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FIRST 4 CELLS: specify frameworks, external imports, and the exact brain checkpoint used.\n",
    "# The other cells specify funcs for the widget, which is at the bottom\n",
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c995e3-9282-41fe-bcec-b779896818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e76133-fa47-472e-ba9f-1959fc6ed499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedAgentBrain()\n",
    "model.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "# A little extra code to avoid weird error\n",
    "model.memory.remember(torch.randn(16, 1, 768).to(device))\n",
    "model.load_state_dict(torch.load('brain_checkpoints/enhanced_brain_first_training_v2_batch160799.pth', weights_only=True, map_location=device))\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1361e168-adf8-453b-ac4a-5825ef046c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other elements to use\n",
    "\n",
    "from game import *\n",
    "\n",
    "game_settings = BIG_tool_use_advanced_2_5\n",
    "game_settings.gameSize = 224 # for compatibility with brain's expected size\n",
    "G = discreteGame(game_settings)\n",
    "\n",
    "####\n",
    "\n",
    "#For this time:\n",
    "def reset_G():\n",
    "    global G\n",
    "    G = discreteGame(G.random_bare_settings(gameSize=224, max_agent_offset=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b1ce00-688f-4a7b-aba0-4700d9341a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc3d01ac260>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reset_G()\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e8492d-8c1e-4389-b871-31e9d30340b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis notebook is to show the EnhancedBrain input, output, and state of mind at once.\n",
    "# I'll start with a rough version and make it cleaner over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a6d7d3-7701-4ad6-aedf-9d1da7612150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79f707fd-090f-42d3-92ed-b2ed1d87c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8946d87-c09e-4eba-897f-5f81c5211bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_imshow_numpy(torch_img, imshow=False):\n",
    "    clean = torch_img.detach()[0].cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b95dcd9-2119-47fb-a2b8-6713e5b28b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output(layout={'border': '1px solid black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a55bbb-7aae-4acf-8232-baed2cc9f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = EnhancedAgentBrain()\n",
    "#model.move_to(device)\n",
    "#2+2\n",
    "# commment to prevent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37dd7bcf-415e-4a8a-8078-7716f8ce17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "# tokenizer.save_model(\".\", \"tokenizer/eng_sentences_tokenizer_vc10000\")\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-vocab.json\",\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-merges.txt\",\n",
    ")   \n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")   \n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b38a1d-479c-46d6-a3f7-b7e77181f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = widgets.Textarea(\n",
    "    value='Hello World',\n",
    "    placeholder='Type something',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ee3f89-d4b9-45f4-9e54-0ca7a6c40866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(game=None):\n",
    "    if game is None:\n",
    "        game = G\n",
    "    img = torch.FloatTensor(G.getData()).unsqueeze(0)\n",
    "    img = torch.permute(img, (0, 3, 1, 2)).contiguous().to(device)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aed9588-a3c7-4fe3-8e5f-9fc29fe9a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a475188-3a0a-4aac-8a2e-36456c557cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this for other inputs\n",
    "# inp_tensor = get_image()\n",
    "inp_tensor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab32506-2f60-4969-afdf-4fc35ccf8b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   32,   87,   34, 5411, 4226,    5,   32,   19,   87,   34,    2]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.tensor(tokenizer.encode(\"<s>Hello World!</s>\").ids).unsqueeze(0).contiguous().to(device)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1930a98-8161-4c7a-b1c0-4dca5f2bf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Hello World!</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tt[0][1:-1].cpu().numpy(), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b88d78ff-8c78-4c99-88be-0a7340a40b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"<s>Hello World!</s>\".find('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2da1651-dd24-4a73-a246-cbc3f5feb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def display_innards(b):\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    print(\"Canvases:\\n\")\n",
    "    if model.canvases.is_empty():\n",
    "        print(\"################\\nCanvases object is empty, nothing to show\\n################\")\n",
    "    else:\n",
    "        for i in range(model.canvases.num_canvases):\n",
    "            print(f\"##########\\nCanvas {i}:\\n\")\n",
    "            plt.imshow(pre_imshow_numpy(model.canvases.tw.L[i][:1]))\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b5eebc-b0a8-4252-bee8-eda5c4f1de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def forward_wrapper(b):\n",
    "    output.clear_output()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "    tt = torch.tensor(tokenizer.encode(T.value).ids).unsqueeze(0).contiguous().to(device)\n",
    "    _, recon = model(tt, local_tensor, create_context=True, ret_imgs=True)\n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b)\n",
    "\n",
    "# wrapper for extending input text without changing what is displayed, much\n",
    "\n",
    "temp=1.0\n",
    "temp_eps = 1e-4\n",
    "\n",
    "special_symbols = set([1, 3, 4, 108])\n",
    "symbol_action_map = { 1:1, 3:3, 4:4, 108:2}\n",
    "\n",
    "@output.capture()\n",
    "def extend_wrapper(b):\n",
    "    output.clear_output()\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "\n",
    "    # in this case, we abridge the end-of-sentence token in order to continue the extension\n",
    "    inp_ids = tokenizer.encode(T.value).ids[:-1]\n",
    "    if len(inp_ids) > 32:\n",
    "        inp_ids = inp_ids[-32:] # the rest should be in memory\n",
    "    tt = torch.tensor(inp_ids).unsqueeze(0).contiguous().to(device)\n",
    "    logits, recon = model(tt, local_tensor, return_full=False, create_context=True, ret_imgs=True)\n",
    "\n",
    "    s = tt.size()\n",
    "    output_text = torch.zeros((s[0], s[1] +1), dtype = torch.long, device=device)\n",
    "    output_text[:, :-1] += tt\n",
    "    \n",
    "    preds = model.select(logits, temp, ret_all=False, temp_eps=temp_eps)\n",
    "    output_text[:, -1] += preds\n",
    "\n",
    "    predval = preds[0].item()\n",
    "    if predval in special_symbols:\n",
    "        action = symbol_action_map[predval]\n",
    "        print(f\"Detected special token {predval} which is action {action}\")\n",
    "        reward = G.actions[action]()\n",
    "        print(f\"Reward was {reward}\")\n",
    "    \n",
    "    T.value = tokenizer.decode(output_text[0][1:].cpu().numpy(), skip_special_tokens=False) # update the string, cut off start token\n",
    "    print(\"updated input string (also in text box):\\n\")\n",
    "    print(T.value)\n",
    "    \n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b) # including game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3fcd589-cd91-488f-a7fd-74ca60b781e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def soft_reset_wrapper(b):\n",
    "    print(\"soft reset (removing internal gradients)\\n\")\n",
    "    model.soft_reset()\n",
    "\n",
    "@output.capture()\n",
    "def reset_wrapper(b):\n",
    "    print(\"hard reset (clering memory and canvaases)\\n\")\n",
    "    model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7217f2f9-400e-49bc-ac6f-0852225ee038",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32 # max len of the model input. Make this a text box or a selector or a knob.\n",
    "\n",
    "@output.capture()\n",
    "def generate_wrapper(b):\n",
    "    # while the string is not too long nor contains the stop codon\n",
    "    while (T.value.find('</s>') == -1) and (len(tokenizer.encode(T.value).ids[:-1]) < max_len):\n",
    "        extend_wrapper(b)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62c779c1-427b-4e9f-8eeb-0c9ec08ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_clear_button_clicked(b):\n",
    "    output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63bf60f2-d3b4-475c-b3d1-0ea1f2ea80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_G_wrapper(b):\n",
    "    reset_G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e6978ff-0314-4b5e-af6b-ad9a57deb475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedAgentBrain(\n",
       "  (img_enc): ImageTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): PatchEmbedding(\n",
       "        (linear_project): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (1): PositionalEncoding_2D()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (img_dec): ImageTransformerDecoder(\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.01, inplace=False)\n",
       "          (dropout2): Dropout(p=0.01, inplace=False)\n",
       "          (dropout3): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): PatchEmbeddingTranspose(\n",
       "        (linear_project): ConvTranspose2d(768, 3, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_enc): SentenceTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): Embedding(10000, 768, padding_idx=0)\n",
       "      (1): PositionalEncoding()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_dec): SentenceTransformerDecoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=3072, out_features=10000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dopamine): IntermediateTransformerScorer(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=3072, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (memory): Memory()\n",
       "  (mem_enc): MemoryEncoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_prep): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (fcs): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4256368e-b469-4e71-8f44-44339c70847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034adc601d624aafa17bd8a7577f3e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset Game', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7003acffc84c189254ccdfd1c4e578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Forward', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95f1c01eb754afc90ca23c8e029af26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Soft Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cda6b0a8a184e1491986584cc01855e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003614b2ef234e98be3185431d5a0416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Extend by One Character', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efc32d506854789beeb89a6b7aeb34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Text', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed57ba2d91a43fcaa67f52fc30435c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Canvases', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafe036a296549fbab2325c2eeb836f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clear Output', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc7a5374f7e4b69b9cb620b8c670f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value=\"Which side is it on? It's on us.</s>\", description='String:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f25ee58e3ca4919b9d5e62aa99f1a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bGameReset = widgets.Button(description=\"Reset Game\")\n",
    "bForward = widgets.Button(description=\"Forward\")\n",
    "bSoftReset = widgets.Button(description=\"Soft Reset\")\n",
    "bReset = widgets.Button(description=\"Reset\")\n",
    "bExtend = widgets.Button(description=\"Extend by One Character\")\n",
    "bGenerate = widgets.Button(description=\"Generate Text\")\n",
    "bDisplayInnards = widgets.Button(description=\"Show Canvases\")\n",
    "bClear = widgets.Button(description=\"Clear Output\")\n",
    "\n",
    "display(bGameReset)\n",
    "display(bForward)\n",
    "display(bSoftReset)\n",
    "display(bReset)\n",
    "display(bExtend)\n",
    "display(bGenerate)\n",
    "display(bDisplayInnards)\n",
    "display(bClear)\n",
    "\n",
    "display(T) # expand me by hand; prettier that way\n",
    "\n",
    "bGameReset.on_click(reset_G_wrapper)\n",
    "bForward.on_click(forward_wrapper)\n",
    "bSoftReset.on_click(soft_reset_wrapper)\n",
    "bReset.on_click(reset_wrapper)\n",
    "bExtend.on_click(extend_wrapper)\n",
    "bGenerate.on_click(generate_wrapper)\n",
    "bDisplayInnards.on_click(display_innards)\n",
    "bClear.on_click(on_clear_button_clicked)\n",
    "\n",
    "display(output)\n",
    "display_innards(bDisplayInnards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1acbc-0080-4704-9720-f4240733e8af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
