{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e490d674-0492-4826-9e34-47944bb4e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FIRST 4 CELLS: specify frameworks, external imports, and the exact brain checkpoint used.\n",
    "# The other cells specify funcs for the widget, which is at the bottom\n",
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "from control_framework import *\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c995e3-9282-41fe-bcec-b779896818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e76133-fa47-472e-ba9f-1959fc6ed499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedAgentBrain()\n",
    "model.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_v2_batch160799.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v2_batch55900.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v2_batch24800.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v3_batch155466.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v4_batch399.pth'\n",
    "fname = 'brain_checkpoints/enhanced_brain_arrow_task_v5_batch133.pth'\n",
    "# A little extra code to avoid weird error\n",
    "model.memory.remember(torch.randn(16, 1, 768).to(device))\n",
    "\n",
    "model.load_state_dict(torch.load(fname, weights_only=True, map_location=device))\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1361e168-adf8-453b-ac4a-5825ef046c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other elements to use\n",
    "\n",
    "from game import *\n",
    "\n",
    "game_settings = BIG_tool_use_advanced_2_5\n",
    "game_settings.gameSize = 224 # for compatibility with brain's expected size\n",
    "G = discreteGame(game_settings)\n",
    "\n",
    "####\n",
    "\n",
    "#For this time:\n",
    "def reset_G():\n",
    "    global G\n",
    "    G = discreteGame(G.random_bare_settings(gameSize=224, max_agent_offset=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b1ce00-688f-4a7b-aba0-4700d9341a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5d58491d30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reset_G()\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80e8492d-8c1e-4389-b871-31e9d30340b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis notebook is to show the EnhancedBrain input, output, and state of mind at once.\n",
    "# I'll start with a rough version and make it cleaner over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a6d7d3-7701-4ad6-aedf-9d1da7612150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f707fd-090f-42d3-92ed-b2ed1d87c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8946d87-c09e-4eba-897f-5f81c5211bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_imshow_numpy(torch_img, imshow=False):\n",
    "    clean = torch_img.detach()[0].cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b95dcd9-2119-47fb-a2b8-6713e5b28b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output(layout={'border': '1px solid black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22a55bbb-7aae-4acf-8232-baed2cc9f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = EnhancedAgentBrain()\n",
    "#model.move_to(device)\n",
    "#2+2\n",
    "# commment to prevent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37dd7bcf-415e-4a8a-8078-7716f8ce17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "# tokenizer.save_model(\".\", \"tokenizer/eng_sentences_tokenizer_vc10000\")\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-vocab.json\",\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-merges.txt\",\n",
    ")   \n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")   \n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60b38a1d-479c-46d6-a3f7-b7e77181f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = widgets.Textarea(\n",
    "    value='Hello World',\n",
    "    placeholder='Type something',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2ee3f89-d4b9-45f4-9e54-0ca7a6c40866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(game=None):\n",
    "    if game is None:\n",
    "        game = G\n",
    "    img = torch.FloatTensor(G.getData()).unsqueeze(0)\n",
    "    img = torch.permute(img, (0, 3, 1, 2)).contiguous().to(device)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aed9588-a3c7-4fe3-8e5f-9fc29fe9a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a475188-3a0a-4aac-8a2e-36456c557cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this for other inputs\n",
    "# inp_tensor = get_image()\n",
    "inp_tensor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab32506-2f60-4969-afdf-4fc35ccf8b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   32,   87,   34, 5411, 4226,    5,   32,   19,   87,   34,    2]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.tensor(tokenizer.encode(\"<s>Hello World!</s>\").ids).unsqueeze(0).contiguous().to(device)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1930a98-8161-4c7a-b1c0-4dca5f2bf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Hello World!</s>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tt[0][1:-1].cpu().numpy(), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b88d78ff-8c78-4c99-88be-0a7340a40b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"<s>Hello World!</s>\".find('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2da1651-dd24-4a73-a246-cbc3f5feb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def display_innards(b):\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    print(\"Canvases:\\n\")\n",
    "    if model.canvases.is_empty():\n",
    "        print(\"################\\nCanvases object is empty, nothing to show\\n################\")\n",
    "    else:\n",
    "        for i in range(model.canvases.num_canvases):\n",
    "            print(f\"##########\\nCanvas {i}:\\n\")\n",
    "            plt.imshow(pre_imshow_numpy(model.canvases.tw.L[i][:1]))\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77b5eebc-b0a8-4252-bee8-eda5c4f1de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def forward_wrapper(b):\n",
    "    output.clear_output()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "    tt = torch.tensor(tokenizer.encode(T.value).ids).unsqueeze(0).contiguous().to(device)\n",
    "    _, recon = model(tt, local_tensor, create_context=True, ret_imgs=True)\n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b)\n",
    "\n",
    "# wrapper for extending input text without changing what is displayed, much\n",
    "\n",
    "temp=1.0\n",
    "temp_eps = 1e-4\n",
    "\n",
    "special_symbols = set([1, 3, 4, 108])\n",
    "symbol_action_map = { 1:1, 3:3, 4:4, 108:2}\n",
    "\n",
    "@output.capture()\n",
    "def extend_wrapper(b):\n",
    "    output.clear_output()\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "\n",
    "    # in this case, we abridge the end-of-sentence token in order to continue the extension\n",
    "    inp_ids = tokenizer.encode(T.value).ids[:-1]\n",
    "    if len(inp_ids) > 32:\n",
    "        inp_ids = inp_ids[-32:] # the rest should be in memory\n",
    "    tt = torch.tensor(inp_ids).unsqueeze(0).contiguous().to(device)\n",
    "    logits, recon = model(tt, local_tensor, return_full=False, create_context=True, ret_imgs=True)\n",
    "\n",
    "    s = tt.size()\n",
    "    output_text = torch.zeros((s[0], s[1] +1), dtype = torch.long, device=device)\n",
    "    output_text[:, :-1] += tt\n",
    "    \n",
    "    preds = model.select(logits, temp, ret_all=False, temp_eps=temp_eps)\n",
    "    output_text[:, -1] += preds\n",
    "\n",
    "    predval = preds[0].item()\n",
    "    if predval in special_symbols:\n",
    "        action = symbol_action_map[predval]\n",
    "        print(f\"Detected special token {predval} which is action {action}\")\n",
    "        reward = G.actions[action]()\n",
    "        print(f\"Reward was {reward}\")\n",
    "    \n",
    "    T.value = tokenizer.decode(output_text[0][1:].cpu().numpy(), skip_special_tokens=False) # update the string, cut off start token\n",
    "    print(\"updated input string (also in text box):\\n\")\n",
    "    print(T.value)\n",
    "    \n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b) # including game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3fcd589-cd91-488f-a7fd-74ca60b781e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def soft_reset_wrapper(b):\n",
    "    print(\"soft reset (removing internal gradients)\\n\")\n",
    "    model.soft_reset()\n",
    "\n",
    "@output.capture()\n",
    "def reset_wrapper(b):\n",
    "    print(\"hard reset (clering memory and canvaases)\\n\")\n",
    "    model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7217f2f9-400e-49bc-ac6f-0852225ee038",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32 # max len of the model input. Make this a text box or a selector or a knob.\n",
    "\n",
    "@output.capture()\n",
    "def generate_wrapper(b):\n",
    "    # while the string is not too long nor contains the stop codon\n",
    "    while (T.value.find('</s>') == -1) and (len(tokenizer.encode(T.value).ids[:-1]) < max_len):\n",
    "        extend_wrapper(b)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62c779c1-427b-4e9f-8eeb-0c9ec08ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_clear_button_clicked(b):\n",
    "    output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63bf60f2-d3b4-475c-b3d1-0ea1f2ea80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_G_wrapper(b):\n",
    "    reset_G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e6978ff-0314-4b5e-af6b-ad9a57deb475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedAgentBrain(\n",
       "  (img_enc): ImageTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): PatchEmbedding(\n",
       "        (linear_project): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (1): PositionalEncoding_2D()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (img_dec): ImageTransformerDecoder(\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.01, inplace=False)\n",
       "          (dropout2): Dropout(p=0.01, inplace=False)\n",
       "          (dropout3): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): PatchEmbeddingTranspose(\n",
       "        (linear_project): ConvTranspose2d(768, 3, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_enc): SentenceTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): Embedding(10000, 768, padding_idx=0)\n",
       "      (1): PositionalEncoding()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_dec): SentenceTransformerDecoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=3072, out_features=10000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dopamine): DopamineWrapper(\n",
       "    (dopamine): IntermediateTransformerScorer(\n",
       "      (decoder): TransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=3072, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (memory): Memory()\n",
       "  (mem_enc): MemoryEncoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_prep): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (fcs): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4256368e-b469-4e71-8f44-44339c70847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3782bd9caeb40afbdb7ebd86d729a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset Game', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d13754945174a1b8c3ebc5ba2982fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Forward', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50d52bd6ca8442290de40f102a35e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Soft Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c636afeecb4cd899698d09a927aef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494a5aceed3449faa7ab1dffefc6143d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Extend by One Character', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e24c6740a2488599671cbd0f19be77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Text', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d577c8516148e7ad589816ef30f5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Canvases', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6e62fdb8b5498fab357d580da9325b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clear Output', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba25e075428c4bdaa6f3d8a937bb3b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Hello World', description='String:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98b3124d4d84e929a4408cd30367a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bGameReset = widgets.Button(description=\"Reset Game\")\n",
    "bForward = widgets.Button(description=\"Forward\")\n",
    "bSoftReset = widgets.Button(description=\"Soft Reset\")\n",
    "bReset = widgets.Button(description=\"Reset\")\n",
    "bExtend = widgets.Button(description=\"Extend by One Character\")\n",
    "bGenerate = widgets.Button(description=\"Generate Text\")\n",
    "bDisplayInnards = widgets.Button(description=\"Show Canvases\")\n",
    "bClear = widgets.Button(description=\"Clear Output\")\n",
    "\n",
    "display(bGameReset)\n",
    "display(bForward)\n",
    "display(bSoftReset)\n",
    "display(bReset)\n",
    "display(bExtend)\n",
    "display(bGenerate)\n",
    "display(bDisplayInnards)\n",
    "display(bClear)\n",
    "\n",
    "display(T) # expand me by hand; prettier that way\n",
    "\n",
    "bGameReset.on_click(reset_G_wrapper)\n",
    "bForward.on_click(forward_wrapper)\n",
    "bSoftReset.on_click(soft_reset_wrapper)\n",
    "bReset.on_click(reset_wrapper)\n",
    "bExtend.on_click(extend_wrapper)\n",
    "bGenerate.on_click(generate_wrapper)\n",
    "bDisplayInnards.on_click(display_innards)\n",
    "bClear.on_click(on_clear_button_clicked)\n",
    "\n",
    "display(output)\n",
    "display_innards(bDisplayInnards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1acbc-0080-4704-9720-f4240733e8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee39b28-2d5e-4d18-97f2-e32acef0d9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59cb5e-b270-4a7d-bc3d-31977cf2a55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
