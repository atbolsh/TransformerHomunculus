{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e490d674-0492-4826-9e34-47944bb4e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FIRST 4 CELLS: specify frameworks, external imports, and the exact brain checkpoint used.\n",
    "# The other cells specify funcs for the widget, which is at the bottom\n",
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "from control_framework import *\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c995e3-9282-41fe-bcec-b779896818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e76133-fa47-472e-ba9f-1959fc6ed499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedAgentBrain()\n",
    "model.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_v2_batch160799.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v2_batch55900.pth'\n",
    "fname = 'brain_checkpoints/enhanced_brain_arrow_task_v2_batch24800.pth'\n",
    "# A little extra code to avoid weird error\n",
    "model.memory.remember(torch.randn(16, 1, 768).to(device))\n",
    "\n",
    "model.load_state_dict(torch.load(fname, weights_only=True, map_location=device))\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1361e168-adf8-453b-ac4a-5825ef046c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other elements to use\n",
    "\n",
    "from game import *\n",
    "\n",
    "game_settings = BIG_tool_use_advanced_2_5\n",
    "game_settings.gameSize = 224 # for compatibility with brain's expected size\n",
    "G = discreteGame(game_settings)\n",
    "\n",
    "####\n",
    "\n",
    "#For this time:\n",
    "def reset_G():\n",
    "    global G\n",
    "    G = discreteGame(G.random_bare_settings(gameSize=224, max_agent_offset=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b1ce00-688f-4a7b-aba0-4700d9341a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0c482fac60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reset_G()\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e8492d-8c1e-4389-b871-31e9d30340b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis notebook is to show the EnhancedBrain input, output, and state of mind at once.\n",
    "# I'll start with a rough version and make it cleaner over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a6d7d3-7701-4ad6-aedf-9d1da7612150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79f707fd-090f-42d3-92ed-b2ed1d87c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8946d87-c09e-4eba-897f-5f81c5211bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_imshow_numpy(torch_img, imshow=False):\n",
    "    clean = torch_img.detach()[0].cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b95dcd9-2119-47fb-a2b8-6713e5b28b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output(layout={'border': '1px solid black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a55bbb-7aae-4acf-8232-baed2cc9f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = EnhancedAgentBrain()\n",
    "#model.move_to(device)\n",
    "#2+2\n",
    "# commment to prevent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37dd7bcf-415e-4a8a-8078-7716f8ce17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "# tokenizer.save_model(\".\", \"tokenizer/eng_sentences_tokenizer_vc10000\")\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-vocab.json\",\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-merges.txt\",\n",
    ")   \n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")   \n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b38a1d-479c-46d6-a3f7-b7e77181f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = widgets.Textarea(\n",
    "    value='Hello World',\n",
    "    placeholder='Type something',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ee3f89-d4b9-45f4-9e54-0ca7a6c40866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(game=None):\n",
    "    if game is None:\n",
    "        game = G\n",
    "    img = torch.FloatTensor(G.getData()).unsqueeze(0)\n",
    "    img = torch.permute(img, (0, 3, 1, 2)).contiguous().to(device)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aed9588-a3c7-4fe3-8e5f-9fc29fe9a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a475188-3a0a-4aac-8a2e-36456c557cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this for other inputs\n",
    "# inp_tensor = get_image()\n",
    "inp_tensor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab32506-2f60-4969-afdf-4fc35ccf8b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   32,   87,   34, 5411, 4226,    5,   32,   19,   87,   34,    2]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.tensor(tokenizer.encode(\"<s>Hello World!</s>\").ids).unsqueeze(0).contiguous().to(device)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1930a98-8161-4c7a-b1c0-4dca5f2bf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Hello World!</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tt[0][1:-1].cpu().numpy(), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b88d78ff-8c78-4c99-88be-0a7340a40b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"<s>Hello World!</s>\".find('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2da1651-dd24-4a73-a246-cbc3f5feb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def display_innards(b):\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    print(\"Canvases:\\n\")\n",
    "    if model.canvases.is_empty():\n",
    "        print(\"################\\nCanvases object is empty, nothing to show\\n################\")\n",
    "    else:\n",
    "        for i in range(model.canvases.num_canvases):\n",
    "            print(f\"##########\\nCanvas {i}:\\n\")\n",
    "            plt.imshow(pre_imshow_numpy(model.canvases.tw.L[i][:1]))\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b5eebc-b0a8-4252-bee8-eda5c4f1de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def forward_wrapper(b):\n",
    "    output.clear_output()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "    tt = torch.tensor(tokenizer.encode(T.value).ids).unsqueeze(0).contiguous().to(device)\n",
    "    _, recon = model(tt, local_tensor, create_context=True, ret_imgs=True)\n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b)\n",
    "\n",
    "# wrapper for extending input text without changing what is displayed, much\n",
    "\n",
    "temp=1.0\n",
    "temp_eps = 1e-4\n",
    "\n",
    "special_symbols = set([1, 3, 4, 108])\n",
    "symbol_action_map = { 1:1, 3:3, 4:4, 108:2}\n",
    "\n",
    "@output.capture()\n",
    "def extend_wrapper(b):\n",
    "    output.clear_output()\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "\n",
    "    # in this case, we abridge the end-of-sentence token in order to continue the extension\n",
    "    inp_ids = tokenizer.encode(T.value).ids[:-1]\n",
    "    if len(inp_ids) > 32:\n",
    "        inp_ids = inp_ids[-32:] # the rest should be in memory\n",
    "    tt = torch.tensor(inp_ids).unsqueeze(0).contiguous().to(device)\n",
    "    logits, recon = model(tt, local_tensor, return_full=False, create_context=True, ret_imgs=True)\n",
    "\n",
    "    s = tt.size()\n",
    "    output_text = torch.zeros((s[0], s[1] +1), dtype = torch.long, device=device)\n",
    "    output_text[:, :-1] += tt\n",
    "    \n",
    "    preds = model.select(logits, temp, ret_all=False, temp_eps=temp_eps)\n",
    "    output_text[:, -1] += preds\n",
    "\n",
    "    predval = preds[0].item()\n",
    "    if predval in special_symbols:\n",
    "        action = symbol_action_map[predval]\n",
    "        print(f\"Detected special token {predval} which is action {action}\")\n",
    "        reward = G.actions[action]()\n",
    "        print(f\"Reward was {reward}\")\n",
    "    \n",
    "    T.value = tokenizer.decode(output_text[0][1:].cpu().numpy(), skip_special_tokens=False) # update the string, cut off start token\n",
    "    print(\"updated input string (also in text box):\\n\")\n",
    "    print(T.value)\n",
    "    \n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b) # including game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3fcd589-cd91-488f-a7fd-74ca60b781e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def soft_reset_wrapper(b):\n",
    "    print(\"soft reset (removing internal gradients)\\n\")\n",
    "    model.soft_reset()\n",
    "\n",
    "@output.capture()\n",
    "def reset_wrapper(b):\n",
    "    print(\"hard reset (clering memory and canvaases)\\n\")\n",
    "    model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7217f2f9-400e-49bc-ac6f-0852225ee038",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32 # max len of the model input. Make this a text box or a selector or a knob.\n",
    "\n",
    "@output.capture()\n",
    "def generate_wrapper(b):\n",
    "    # while the string is not too long nor contains the stop codon\n",
    "    while (T.value.find('</s>') == -1) and (len(tokenizer.encode(T.value).ids[:-1]) < max_len):\n",
    "        extend_wrapper(b)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62c779c1-427b-4e9f-8eeb-0c9ec08ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_clear_button_clicked(b):\n",
    "    output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63bf60f2-d3b4-475c-b3d1-0ea1f2ea80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_G_wrapper(b):\n",
    "    reset_G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e6978ff-0314-4b5e-af6b-ad9a57deb475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedAgentBrain(\n",
       "  (img_enc): ImageTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): PatchEmbedding(\n",
       "        (linear_project): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (1): PositionalEncoding_2D()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (img_dec): ImageTransformerDecoder(\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.01, inplace=False)\n",
       "          (dropout2): Dropout(p=0.01, inplace=False)\n",
       "          (dropout3): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): PatchEmbeddingTranspose(\n",
       "        (linear_project): ConvTranspose2d(768, 3, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_enc): SentenceTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): Embedding(10000, 768, padding_idx=0)\n",
       "      (1): PositionalEncoding()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_dec): SentenceTransformerDecoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=3072, out_features=10000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dopamine): DopamineWrapper(\n",
       "    (dopamine): IntermediateTransformerScorer(\n",
       "      (decoder): TransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=3072, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (memory): Memory()\n",
       "  (mem_enc): MemoryEncoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_prep): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (fcs): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4256368e-b469-4e71-8f44-44339c70847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebf6363af8047dd8f5508afb2ff3254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset Game', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aac689fed334fe7889a7dcb5d7fbf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Forward', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c5c7070b7d4659946df80351104666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Soft Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27e984b66204b70841589ab303a9b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d482217fbbd4ca7a365157dc4cca4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Extend by One Character', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71002c053add4cfbbb1bedc4b37cd8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Text', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b738b097b4f4eaa8fb7f790587a6222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Canvases', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093ce76c863f4bb5a3c644e3fe692d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clear Output', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731c14b824f140c9b18055efd0392edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Hello World', description='String:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838961de9ab14634afa4da5e8930ae89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bGameReset = widgets.Button(description=\"Reset Game\")\n",
    "bForward = widgets.Button(description=\"Forward\")\n",
    "bSoftReset = widgets.Button(description=\"Soft Reset\")\n",
    "bReset = widgets.Button(description=\"Reset\")\n",
    "bExtend = widgets.Button(description=\"Extend by One Character\")\n",
    "bGenerate = widgets.Button(description=\"Generate Text\")\n",
    "bDisplayInnards = widgets.Button(description=\"Show Canvases\")\n",
    "bClear = widgets.Button(description=\"Clear Output\")\n",
    "\n",
    "display(bGameReset)\n",
    "display(bForward)\n",
    "display(bSoftReset)\n",
    "display(bReset)\n",
    "display(bExtend)\n",
    "display(bGenerate)\n",
    "display(bDisplayInnards)\n",
    "display(bClear)\n",
    "\n",
    "display(T) # expand me by hand; prettier that way\n",
    "\n",
    "bGameReset.on_click(reset_G_wrapper)\n",
    "bForward.on_click(forward_wrapper)\n",
    "bSoftReset.on_click(soft_reset_wrapper)\n",
    "bReset.on_click(reset_wrapper)\n",
    "bExtend.on_click(extend_wrapper)\n",
    "bGenerate.on_click(generate_wrapper)\n",
    "bDisplayInnards.on_click(display_innards)\n",
    "bClear.on_click(on_clear_button_clicked)\n",
    "\n",
    "display(output)\n",
    "display_innards(bDisplayInnards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1acbc-0080-4704-9720-f4240733e8af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
