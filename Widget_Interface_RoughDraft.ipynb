{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e490d674-0492-4826-9e34-47944bb4e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FIRST 4 CELLS: specify frameworks, external imports, and the exact brain checkpoint used.\n",
    "# The other cells specify funcs for the widget, which is at the bottom\n",
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "from control_framework import *\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c995e3-9282-41fe-bcec-b779896818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e76133-fa47-472e-ba9f-1959fc6ed499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedAgentBrain()\n",
    "model.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_v2_batch160799.pth'\n",
    "fname = 'brain_checkpoints/enhanced_brain_control_training_v2_batch55900.pth'\n",
    "# A little extra code to avoid weird error\n",
    "model.memory.remember(torch.randn(16, 1, 768).to(device))\n",
    "\n",
    "model.load_state_dict(torch.load(fname, weights_only=True, map_location=device))\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1361e168-adf8-453b-ac4a-5825ef046c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other elements to use\n",
    "\n",
    "from game import *\n",
    "\n",
    "game_settings = BIG_tool_use_advanced_2_5\n",
    "game_settings.gameSize = 224 # for compatibility with brain's expected size\n",
    "G = discreteGame(game_settings)\n",
    "\n",
    "####\n",
    "\n",
    "#For this time:\n",
    "def reset_G():\n",
    "    global G\n",
    "    G = discreteGame(G.random_bare_settings(gameSize=224, max_agent_offset=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b1ce00-688f-4a7b-aba0-4700d9341a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbff395c530>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reset_G()\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e8492d-8c1e-4389-b871-31e9d30340b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis notebook is to show the EnhancedBrain input, output, and state of mind at once.\n",
    "# I'll start with a rough version and make it cleaner over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a6d7d3-7701-4ad6-aedf-9d1da7612150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79f707fd-090f-42d3-92ed-b2ed1d87c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8946d87-c09e-4eba-897f-5f81c5211bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_imshow_numpy(torch_img, imshow=False):\n",
    "    clean = torch_img.detach()[0].cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b95dcd9-2119-47fb-a2b8-6713e5b28b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output(layout={'border': '1px solid black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a55bbb-7aae-4acf-8232-baed2cc9f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = EnhancedAgentBrain()\n",
    "#model.move_to(device)\n",
    "#2+2\n",
    "# commment to prevent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37dd7bcf-415e-4a8a-8078-7716f8ce17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "# tokenizer.save_model(\".\", \"tokenizer/eng_sentences_tokenizer_vc10000\")\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-vocab.json\",\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-merges.txt\",\n",
    ")   \n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")   \n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b38a1d-479c-46d6-a3f7-b7e77181f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = widgets.Textarea(\n",
    "    value='Hello World',\n",
    "    placeholder='Type something',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ee3f89-d4b9-45f4-9e54-0ca7a6c40866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(game=None):\n",
    "    if game is None:\n",
    "        game = G\n",
    "    img = torch.FloatTensor(G.getData()).unsqueeze(0)\n",
    "    img = torch.permute(img, (0, 3, 1, 2)).contiguous().to(device)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aed9588-a3c7-4fe3-8e5f-9fc29fe9a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a475188-3a0a-4aac-8a2e-36456c557cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this for other inputs\n",
    "# inp_tensor = get_image()\n",
    "inp_tensor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab32506-2f60-4969-afdf-4fc35ccf8b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   32,   87,   34, 5411, 4226,    5,   32,   19,   87,   34,    2]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.tensor(tokenizer.encode(\"<s>Hello World!</s>\").ids).unsqueeze(0).contiguous().to(device)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1930a98-8161-4c7a-b1c0-4dca5f2bf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Hello World!</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tt[0][1:-1].cpu().numpy(), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b88d78ff-8c78-4c99-88be-0a7340a40b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"<s>Hello World!</s>\".find('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2da1651-dd24-4a73-a246-cbc3f5feb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def display_innards(b):\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    print(\"Canvases:\\n\")\n",
    "    if model.canvases.is_empty():\n",
    "        print(\"################\\nCanvases object is empty, nothing to show\\n################\")\n",
    "    else:\n",
    "        for i in range(model.canvases.num_canvases):\n",
    "            print(f\"##########\\nCanvas {i}:\\n\")\n",
    "            plt.imshow(pre_imshow_numpy(model.canvases.tw.L[i][:1]))\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b5eebc-b0a8-4252-bee8-eda5c4f1de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def forward_wrapper(b):\n",
    "    output.clear_output()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "    tt = torch.tensor(tokenizer.encode(T.value).ids).unsqueeze(0).contiguous().to(device)\n",
    "    _, recon = model(tt, local_tensor, create_context=True, ret_imgs=True)\n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b)\n",
    "\n",
    "# wrapper for extending input text without changing what is displayed, much\n",
    "\n",
    "temp=1.0\n",
    "temp_eps = 1e-4\n",
    "\n",
    "special_symbols = set([1, 3, 4, 108])\n",
    "symbol_action_map = { 1:1, 3:3, 4:4, 108:2}\n",
    "\n",
    "@output.capture()\n",
    "def extend_wrapper(b):\n",
    "    output.clear_output()\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "\n",
    "    # in this case, we abridge the end-of-sentence token in order to continue the extension\n",
    "    inp_ids = tokenizer.encode(T.value).ids[:-1]\n",
    "    if len(inp_ids) > 32:\n",
    "        inp_ids = inp_ids[-32:] # the rest should be in memory\n",
    "    tt = torch.tensor(inp_ids).unsqueeze(0).contiguous().to(device)\n",
    "    logits, recon = model(tt, local_tensor, return_full=False, create_context=True, ret_imgs=True)\n",
    "\n",
    "    s = tt.size()\n",
    "    output_text = torch.zeros((s[0], s[1] +1), dtype = torch.long, device=device)\n",
    "    output_text[:, :-1] += tt\n",
    "    \n",
    "    preds = model.select(logits, temp, ret_all=False, temp_eps=temp_eps)\n",
    "    output_text[:, -1] += preds\n",
    "\n",
    "    predval = preds[0].item()\n",
    "    if predval in special_symbols:\n",
    "        action = symbol_action_map[predval]\n",
    "        print(f\"Detected special token {predval} which is action {action}\")\n",
    "        reward = G.actions[action]()\n",
    "        print(f\"Reward was {reward}\")\n",
    "    \n",
    "    T.value = tokenizer.decode(output_text[0][1:].cpu().numpy(), skip_special_tokens=False) # update the string, cut off start token\n",
    "    print(\"updated input string (also in text box):\\n\")\n",
    "    print(T.value)\n",
    "    \n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b) # including game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3fcd589-cd91-488f-a7fd-74ca60b781e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def soft_reset_wrapper(b):\n",
    "    print(\"soft reset (removing internal gradients)\\n\")\n",
    "    model.soft_reset()\n",
    "\n",
    "@output.capture()\n",
    "def reset_wrapper(b):\n",
    "    print(\"hard reset (clering memory and canvaases)\\n\")\n",
    "    model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7217f2f9-400e-49bc-ac6f-0852225ee038",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32 # max len of the model input. Make this a text box or a selector or a knob.\n",
    "\n",
    "@output.capture()\n",
    "def generate_wrapper(b):\n",
    "    # while the string is not too long nor contains the stop codon\n",
    "    while (T.value.find('</s>') == -1) and (len(tokenizer.encode(T.value).ids[:-1]) < max_len):\n",
    "        extend_wrapper(b)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62c779c1-427b-4e9f-8eeb-0c9ec08ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_clear_button_clicked(b):\n",
    "    output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63bf60f2-d3b4-475c-b3d1-0ea1f2ea80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_G_wrapper(b):\n",
    "    reset_G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e6978ff-0314-4b5e-af6b-ad9a57deb475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedAgentBrain(\n",
       "  (img_enc): ImageTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): PatchEmbedding(\n",
       "        (linear_project): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (1): PositionalEncoding_2D()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (img_dec): ImageTransformerDecoder(\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.01, inplace=False)\n",
       "          (dropout2): Dropout(p=0.01, inplace=False)\n",
       "          (dropout3): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): PatchEmbeddingTranspose(\n",
       "        (linear_project): ConvTranspose2d(768, 3, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_enc): SentenceTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): Embedding(10000, 768, padding_idx=0)\n",
       "      (1): PositionalEncoding()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_dec): SentenceTransformerDecoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=3072, out_features=10000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dopamine): DopamineWrapper(\n",
       "    (dopamine): IntermediateTransformerScorer(\n",
       "      (decoder): TransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=3072, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (memory): Memory()\n",
       "  (mem_enc): MemoryEncoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_prep): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (fcs): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4256368e-b469-4e71-8f44-44339c70847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9c2f52b3954491bbfbedb6ea6e105f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset Game', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb9e72f4fd540eb807982cc24b68175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Forward', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e387560c307c45e985e0723cffc8ee17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Soft Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906c5dff492a452a95f8120f1ac434d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0ffa49c2734f8481265dfd4fc7a76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Extend by One Character', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa977713c6e4499f8b33681e5e4f08f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Text', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d6ea28e6184be9bb98ac306e38a49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Canvases', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcc27b54f0640c3b474984c9de18128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clear Output', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c24ba5ed9d423f809cb613fe0d1aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Hello World', description='String:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9323c378474b4fa3ad4ced4de60c9bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bGameReset = widgets.Button(description=\"Reset Game\")\n",
    "bForward = widgets.Button(description=\"Forward\")\n",
    "bSoftReset = widgets.Button(description=\"Soft Reset\")\n",
    "bReset = widgets.Button(description=\"Reset\")\n",
    "bExtend = widgets.Button(description=\"Extend by One Character\")\n",
    "bGenerate = widgets.Button(description=\"Generate Text\")\n",
    "bDisplayInnards = widgets.Button(description=\"Show Canvases\")\n",
    "bClear = widgets.Button(description=\"Clear Output\")\n",
    "\n",
    "display(bGameReset)\n",
    "display(bForward)\n",
    "display(bSoftReset)\n",
    "display(bReset)\n",
    "display(bExtend)\n",
    "display(bGenerate)\n",
    "display(bDisplayInnards)\n",
    "display(bClear)\n",
    "\n",
    "display(T) # expand me by hand; prettier that way\n",
    "\n",
    "bGameReset.on_click(reset_G_wrapper)\n",
    "bForward.on_click(forward_wrapper)\n",
    "bSoftReset.on_click(soft_reset_wrapper)\n",
    "bReset.on_click(reset_wrapper)\n",
    "bExtend.on_click(extend_wrapper)\n",
    "bGenerate.on_click(generate_wrapper)\n",
    "bDisplayInnards.on_click(display_innards)\n",
    "bClear.on_click(on_clear_button_clicked)\n",
    "\n",
    "display(output)\n",
    "display_innards(bDisplayInnards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1acbc-0080-4704-9720-f4240733e8af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
