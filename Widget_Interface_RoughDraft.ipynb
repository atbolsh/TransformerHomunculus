{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e490d674-0492-4826-9e34-47944bb4e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FIRST 4 CELLS: specify frameworks, external imports, and the exact brain checkpoint used.\n",
    "# The other cells specify funcs for the widget, which is at the bottom\n",
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "from control_framework import *\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c995e3-9282-41fe-bcec-b779896818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3e76133-fa47-472e-ba9f-1959fc6ed499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedAgentBrain()\n",
    "model.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_v2_batch160799.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v2_batch55900.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v2_batch24800.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v3_batch155466.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v4_batch399.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v5_batch133.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_v2_batch29398.pth'\n",
    "fname = 'brain_checkpoints/enhanced_brain_canvas_use_v3_batch35249.pth'\n",
    "# -- that is the correct v3 version; the others come from the older tasks\n",
    "\n",
    "# A little extra code to avoid weird error\n",
    "#model.memory.remember(torch.randn(16, 1, 768).to(device))\n",
    "#model.memory.remember(torch.randn(8, 1, 768).to(device))\n",
    "\n",
    "model.load_state_dict(torch.load(fname, weights_only=True, map_location=device))\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1361e168-adf8-453b-ac4a-5825ef046c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other elements to use\n",
    "\n",
    "from game import *\n",
    "\n",
    "game_settings = BIG_tool_use_advanced_2_5\n",
    "game_settings.gameSize = 224 # for compatibility with brain's expected size\n",
    "G = discreteGame(game_settings)\n",
    "\n",
    "####\n",
    "\n",
    "#For this time:\n",
    "def reset_G():\n",
    "    global G\n",
    "    G = discreteGame(G.random_bare_settings(gameSize=224, max_agent_offset=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07b1ce00-688f-4a7b-aba0-4700d9341a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f51801362a0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGhCAYAAADbf0s2AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJ7NJREFUeJzt3X90VPWd//HX5NcQYjISApmZEtKUL2y3hkMl2ABaCSgpUUClXUFtC18tq+XHfrOB45p69oB7WuLRA2rLqq2L/BA8YbcL6Fn8qkEgyCKHyA/5oUujRAmaNF8QMklIJiH5fP+gjh0TfgRmmE8mzwfnHufez+fe+56Pc3jxuXd+OIwxRgAAWCgm0gUAAHAhhBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBaEQ2p559/XllZWerTp49ycnL07rvvRrIcAIBlIhZS69evV2FhoR5//HHt379fP/zhD1VQUKDjx49HqiQAgGUckfqC2dzcXI0cOVIvvPBCYNvf/u3f6u6771ZJSclF9+3o6NAXX3yh5ORkORyOcJcKAAgxY4waGhrk9XoVE3Ph+VLcNawpoLW1VXv37tVjjz0WtD0/P1+7du3q1N/v98vv9wfWP//8c33ve98Le50AgPCqrq7WoEGDLtgekZA6efKk2tvblZ6eHrQ9PT1dtbW1nfqXlJToiSeeuFblAd0WFxent99+Wzk5OZEuJUhra6smTpyoAwcORLoUoEvJyckXbY9ISH3lm5fqjDFdXr4rLi5WUVFRYN3n8ykjIyPs9QGXy+Fw6LrrrlNKSkqkSwnS2tqq2NjYSJcBXNClbtlEJKTS0tIUGxvbadZUV1fXaXYlSU6nU06n81qVBwCwRETe3ZeQkKCcnByVlZUFbS8rK9PYsWMjURIAwEIRu9xXVFSkn/3sZxo1apTGjBmjP/zhDzp+/LgeeeSRSJUEALBMxEJq+vTpOnXqlP7lX/5FNTU1ys7O1htvvKHMzMxIlQQAsExE3zgxZ84czZkzJ5IlAAAsxnf3AQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCsFdFvQbdVnz59LvmTxsBfS0hIUEyMnf/m69OnjxITEyNdBnqgjo4O+f3+iNZASH1Dnz59VFpaqiFDhkS6FPQgDodD3/nOdyJdRidxcXFavXq1mpubI10KeqDKykrdd999EQ0qQuobHA6HhgwZouzs7EiXAly1mJgY/sGFK9bR0RHxq0p2Xp8AAECEFADAYoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWiEPqZKSEt10001KTk7WwIEDdffdd+vo0aNBfWbNmiWHwxG0jB49OtSlAAB6uJCHVHl5uebOnavdu3errKxM586dU35+vpqamoL6TZo0STU1NYHljTfeCHUpAIAeLuQ/evjmm28Gra9cuVIDBw7U3r17deuttwa2O51Oud3uUJ8eABBFwn5Pqr6+XpKUmpoatH379u0aOHCghg0bptmzZ6uuru6Cx/D7/fL5fEELACD6hTWkjDEqKirSLbfcEvRz7AUFBVq3bp22bt2qpUuXqqKiQhMmTJDf7+/yOCUlJXK5XIElIyMjnGUDACzhMMaYcB187ty52rx5s3bu3KlBgwZdsF9NTY0yMzNVWlqqadOmdWr3+/1BAebz+cIWVImJidqzZ09QqAJAb3Tw4EHl5uaqpaUlbOeor69XSkrKBdtDfk/qK/Pnz9frr7+uHTt2XDSgJMnj8SgzM1OVlZVdtjudTjmdznCUCQCwWMhDyhij+fPna+PGjdq+fbuysrIuuc+pU6dUXV0tj8cT6nIAAD1YyO9JzZ07V2vXrtWrr76q5ORk1dbWqra2Vs3NzZKkxsZGLVy4UO+9954+/fRTbd++XVOmTFFaWpruueeeUJcDAOjBQj6TeuGFFyRJeXl5QdtXrlypWbNmKTY2VocOHdKaNWt05swZeTwejR8/XuvXr1dycnKoywEA9GBhudx3MYmJiXrrrbdCfVoAQBTiu/sAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYKeUgtXrxYDocjaHG73YF2Y4wWL14sr9erxMRE5eXl6ciRI6EuAwAQBcIyk7rhhhtUU1MTWA4dOhRoe+qpp7Rs2TItX75cFRUVcrvdmjhxohoaGsJRCgCgB4sLy0Hj4oJmT18xxujZZ5/V448/rmnTpkmSVq9erfT0dL366qt6+OGHuzye3++X3+8PrPt8vnCUDQCwTFhmUpWVlfJ6vcrKytKMGTN07NgxSVJVVZVqa2uVn58f6Ot0OjVu3Djt2rXrgscrKSmRy+UKLBkZGeEoGwBgmZCHVG5urtasWaO33npLL730kmprazV27FidOnVKtbW1kqT09PSgfdLT0wNtXSkuLlZ9fX1gqa6uDnXZAAALhfxyX0FBQeDx8OHDNWbMGA0ZMkSrV6/W6NGjJUkOhyNoH2NMp21/zel0yul0hrpUAIDlwv4W9KSkJA0fPlyVlZWB+1TfnDXV1dV1ml0BABD2kPL7/froo4/k8XiUlZUlt9utsrKyQHtra6vKy8s1duzYcJcCAOhhQn65b+HChZoyZYoGDx6suro6/frXv5bP59PMmTPlcDhUWFioJUuWaOjQoRo6dKiWLFmivn376v777w91KQCAHi7kIXXixAndd999OnnypAYMGKDRo0dr9+7dyszMlCQ9+uijam5u1pw5c3T69Gnl5ubq7bffVnJycqhLAQD0cA5jjIl0Ed3l8/nkcrnCcuzExETt2bNH2dnZYTk+APQUBw8eVG5urlpaWsJ2jvr6eqWkpFywne/uAwBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWCvkIfXtb39bDoej0zJ37lxJ0qxZszq1jR49OtRlAACiQFyoD1hRUaH29vbA+uHDhzVx4kT93d/9XWDbpEmTtHLlysB6QkJCqMsAAESBkIfUgAEDgtaffPJJDRkyROPGjQtsczqdcrvdl31Mv98vv98fWPf5fFdfKADAemG9J9Xa2qq1a9fqwQcflMPhCGzfvn27Bg4cqGHDhmn27Nmqq6u76HFKSkrkcrkCS0ZGRjjLBgBYIqwhtWnTJp05c0azZs0KbCsoKNC6deu0detWLV26VBUVFZowYULQTOmbiouLVV9fH1iqq6vDWTYAwBIhv9z311asWKGCggJ5vd7AtunTpwceZ2dna9SoUcrMzNTmzZs1bdq0Lo/jdDrldDrDWSoAwEJhC6nPPvtMW7Zs0YYNGy7az+PxKDMzU5WVleEqBQDQQ4Xtct/KlSs1cOBA3XnnnRftd+rUKVVXV8vj8YSrFABADxWWkOro6NDKlSs1c+ZMxcV9PVlrbGzUwoUL9d577+nTTz/V9u3bNWXKFKWlpemee+4JRykAgB4sLJf7tmzZouPHj+vBBx8M2h4bG6tDhw5pzZo1OnPmjDwej8aPH6/169crOTk5HKUAAHqwsIRUfn6+jDGdticmJuqtt94KxykBAFGI7+4DAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYi5ACAFiLkAIAWIuQAgBYq9shtWPHDk2ZMkVer1cOh0ObNm0KajfGaPHixfJ6vUpMTFReXp6OHDkS1Mfv92v+/PlKS0tTUlKSpk6dqhMnTlzVEwEARJ9uh1RTU5NGjBih5cuXd9n+1FNPadmyZVq+fLkqKirkdrs1ceJENTQ0BPoUFhZq48aNKi0t1c6dO9XY2KjJkyervb39yp8JgCtmZNSmNrVe4k+b2mRkIl0uepG47u5QUFCggoKCLtuMMXr22Wf1+OOPa9q0aZKk1atXKz09Xa+++qoefvhh1dfXa8WKFXrllVd0++23S5LWrl2rjIwMbdmyRT/60Y+u4ukAuBJNatLP9DOd0MWvaAzQAK3VWqUq9RpVht6u2yF1MVVVVaqtrVV+fn5gm9Pp1Lhx47Rr1y49/PDD2rt3r9ra2oL6eL1eZWdna9euXV2GlN/vl9/vD6z7fL5Qlg30Sj759D/6HxkZNalJFarQ5/r8ovukKU17tEf91E+SNEzDAo+BcAhpSNXW1kqS0tPTg7anp6frs88+C/RJSEhQv379OvX5av9vKikp0RNPPBHKUoFeb5/2aZImqUMdMjI6p3OX3OekTmqKpsghhyRpgzZosiaHu1T0YmF5d5/D4QhaN8Z02vZNF+tTXFys+vr6wFJdXR2yWoHeplWtelbP6iW9FLjPdDkB9ZVzOqe2v/xZrdV6Wk+rWc1hrBi9WUhnUm63W9L52ZLH4wlsr6urC8yu3G63Wltbdfr06aDZVF1dncaOHdvlcZ1Op5xOZyhLBXqVDnXIL7+MjJrVrD/oD/pIH131cf+oP6pCFfqpfhp4Q4VTTsUq9qqPDUghnkllZWXJ7XarrKwssK21tVXl5eWBAMrJyVF8fHxQn5qaGh0+fPiCIQXg6hzWYY3VWOUqV7fqVh3TsZAd+wt9odt0m3KVq9EarQpVhOzYQLdnUo2Njfr4448D61VVVTpw4IBSU1M1ePBgFRYWasmSJRo6dKiGDh2qJUuWqG/fvrr//vslSS6XSw899JAWLFig/v37KzU1VQsXLtTw4cMD7/YDEFpndVaHdbhbl/UuV5vaArMyhxxqVGPIz4Heq9sh9f7772v8+PGB9aKiIknSzJkztWrVKj366KNqbm7WnDlzdPr0aeXm5urtt99WcnJyYJ9nnnlGcXFxuvfee9Xc3KzbbrtNq1atUmwslwgAAF9zGGN63CfzfD6fXC5XWI6dmJioPXv2KDs7OyzHB66lczqnZ/WsKlShP+qP6lBH2M95j+7RKI3SAi2QU9xL7skOHjyo3NxctbS0hO0c9fX1SklJuWA7390HRCm//DqjM1qndfp3/fs1CShJ2qiNWq3VOq3TalH4/nJD70BIAVHq3/RvGq3RIXkXX3dVqUo362Y9p+eu+bkRXUL6FnQA9vhSX+oTfRKRc7epTcd0TCd1MiLnR/RgJgUAsBYhBUSZalXrl/qlXtNrkS5Fb+kt/b3+Xh/r40t3BrpASAFR5kt9qZVaqb3aG+lSdEiH9LJeVp3qIl0KeihCCgBgLUIKAGAtQgoAYC1CCgBgLT4nBfRyKfVSUtP5xy19pNP9JF3859+Aa4aZFNDLPfqUtG/k+eV38yNdDRCMmRTQy8Sekwr+r+SqP79+U4Xk/vP5xzcckX66VjIOye+U3rhDOpsUuVoBQgqIQo6LXK9LaJVKiqXsI53bvv+B9MrPzz8+2V/6/gFCCpHF5T4gynxb39Z6rdd9ui/Spegu3aX/1H/qb/Q3kS4FPRQzKSDKuOTSVE3VB/qgU9v1p6X0P5+fTV1KTIc06MT5y34nB1xZLUM1VHfprivbGRAzKaBX+YffSu+NkYZcxpejX39GenOS9NSjknrcT6MiWhBSQJQaqZH6hX6hNKUFtiU2S/3OSLGX8fuHMUa6vl66rrH7575e1+tBPajRGt39nYG/wuU+IErdqTs1URN1QAcCv+tkHFKHQ3KYS38Uyvylv7mCz0x55NFv9VsliXdd4OowkwKiWJzi9Dv9Ts/qWcUqViv/t3T3JumzzEvv60uRfvaK9JvHddkf7nXIoRKV6CW9JKecV1M6IImZFBDVYhQTuOTmkEOVw6QTg6TG6y69b1u8VD5O+nxQ9845SqN0s26+gmqBzphJAQCsxUwK6AU88qhQhWpXuxxx57T556/q7dpTkqTx26QbD5zvdyxL2nT3+cdNSZc340pRin6qn8oppxxyaLAGh+U5oHcipIBeIFOZelpPS5LOJpzV6Ee364hOq0Mdevb/SMMPne935AZpwVJd9j2oGMVogAboN/qNrtf1YakdvRshBfQyTjm1Uiv13/pvFapQv/0Hoz/+5Hzbl6ndO9Zv9Bvdptt0nS5jygVcAUIK6GViFasc5ahDHRqhEeoY0qHTQ9pVqUq16uJfRRGnOA3TMMX95a+O0Rqtm3TTtSgbvRQhBfRSIzVS7+k9SZJPPo3RGB3TsYvuM0AD9Kbe1ACd/56keMWHvU70boQU0EvF/uXPV+Zpnr7UlxfdJ1nJ6qd+6qM+4S4PkERIAZDUR330j/rHSJcBdMLnpAAA1up2SO3YsUNTpkyR1+uVw+HQpk2bAm1tbW36p3/6Jw0fPlxJSUnyer36+c9/ri+++CLoGHl5eXI4HEHLjBkzrvrJAACiS7dDqqmpSSNGjNDy5cs7tZ09e1b79u3TP//zP2vfvn3asGGD/vSnP2nq1Kmd+s6ePVs1NTWB5fe///2VPQMAQNTq9j2pgoICFRQUdNnmcrlUVlYWtO13v/udfvCDH+j48eMaPPjrT6L37dtXbre7u6cHAPQiYb8nVV9fL4fDoeuvvz5o+7p165SWlqYbbrhBCxcuVENDwwWP4ff75fP5ghYAQPQL67v7Wlpa9Nhjj+n+++9XSkpKYPsDDzygrKwsud1uHT58WMXFxfrggw86zcK+UlJSoieeeCKcpQIALBS2kGpra9OMGTPU0dGh559/Pqht9uzZgcfZ2dkaOnSoRo0apX379mnkyJGdjlVcXKyioqLAus/nU0ZGRrhKBwBYIiwh1dbWpnvvvVdVVVXaunVr0CyqKyNHjlR8fLwqKyu7DCmn0ymnkx9QA4DeJuQh9VVAVVZWatu2berfv/8l9zly5Ija2trk8XhCXQ4AoAfrdkg1Njbq448/DqxXVVXpwIEDSk1Nldfr1U9+8hPt27dP//Vf/6X29nbV1tZKklJTU5WQkKBPPvlE69at0x133KG0tDR9+OGHWrBggW688UbdfDO/5gkA+Fq3Q+r999/X+PHjA+tf3SuaOXOmFi9erNdff12S9P3vfz9ov23btikvL08JCQl655139Nxzz6mxsVEZGRm68847tWjRIsXGxgoAgK90O6Ty8vJkjLlg+8XaJCkjI0Pl5eXdPS0AoBfiu/sAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADW6nZI7dixQ1OmTJHX65XD4dCmTZuC2mfNmiWHwxG0jB49OqiP3+/X/PnzlZaWpqSkJE2dOlUnTpy4qicCAIg+3Q6ppqYmjRgxQsuXL79gn0mTJqmmpiawvPHGG0HthYWF2rhxo0pLS7Vz5041NjZq8uTJam9v7/4zAABErbju7lBQUKCCgoKL9nE6nXK73V221dfXa8WKFXrllVd0++23S5LWrl2rjIwMbdmyRT/60Y+6WxIAIEqF5Z7U9u3bNXDgQA0bNkyzZ89WXV1doG3v3r1qa2tTfn5+YJvX61V2drZ27drV5fH8fr98Pl/QAgCIfiEPqYKCAq1bt05bt27V0qVLVVFRoQkTJsjv90uSamtrlZCQoH79+gXtl56ertra2i6PWVJSIpfLFVgyMjJCXTYAwELdvtx3KdOnTw88zs7O1qhRo5SZmanNmzdr2rRpF9zPGCOHw9FlW3FxsYqKigLrPp+PoAKAXiDsb0H3eDzKzMxUZWWlJMntdqu1tVWnT58O6ldXV6f09PQuj+F0OpWSkhK0AACiX9hD6tSpU6qurpbH45Ek5eTkKD4+XmVlZYE+NTU1Onz4sMaOHRvucgAAPUi3L/c1Njbq448/DqxXVVXpwIEDSk1NVWpqqhYvXqwf//jH8ng8+vTTT/WrX/1KaWlpuueeeyRJLpdLDz30kBYsWKD+/fsrNTVVCxcu1PDhwwPv9gMAQLqCkHr//fc1fvz4wPpX94pmzpypF154QYcOHdKaNWt05swZeTwejR8/XuvXr1dycnJgn2eeeUZxcXG699571dzcrNtuu02rVq1SbGxsCJ4SACBaOIwxJtJFdJfP55PL5QrLsRMTE7Vnzx5lZ2eH5fgA0FMcPHhQubm5amlpCds56uvrL/o+A767DwBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgrW6H1I4dOzRlyhR5vV45HA5t2rQpqN3hcHS5PP3004E+eXl5ndpnzJhx1U8GABBduh1STU1NGjFihJYvX95le01NTdDy8ssvy+Fw6Mc//nFQv9mzZwf1+/3vf39lzwAAELXiurtDQUGBCgoKLtjudruD1l977TWNHz9e3/nOd4K29+3bt1PfC/H7/fL7/YF1n8/XjYoBAD1VWO9J/fnPf9bmzZv10EMPdWpbt26d0tLSdMMNN2jhwoVqaGi44HFKSkrkcrkCS0ZGRjjLBgBYotszqe5YvXq1kpOTNW3atKDtDzzwgLKysuR2u3X48GEVFxfrgw8+UFlZWZfHKS4uVlFRUWDd5/MRVADQC4Q1pF5++WU98MAD6tOnT9D22bNnBx5nZ2dr6NChGjVqlPbt26eRI0d2Oo7T6ZTT6QxnqQAAC4Xtct+7776ro0eP6he/+MUl+44cOVLx8fGqrKwMVzkAgB4obCG1YsUK5eTkaMSIEZfse+TIEbW1tcnj8YSrHABAD9Tty32NjY36+OOPA+tVVVU6cOCAUlNTNXjwYEnn7xn9x3/8h5YuXdpp/08++UTr1q3THXfcobS0NH344YdasGCBbrzxRt18881X8VQAANGm2yH1/vvva/z48YH1r97QMHPmTK1atUqSVFpaKmOM7rvvvk77JyQk6J133tFzzz2nxsZGZWRk6M4779SiRYsUGxt7hU8DABCNHMYYE+kiusvn88nlcoXl2ImJidqzZ4+ys7PDcnwA6CkOHjyo3NxctbS0hO0c9fX1SklJuWA7390HALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwFiEFALBWXKQLAIAeq61Oatp//nFMgnTdWCnGGdmaogwhBQBXqvE96U/3nH8cP1DK3i8leCJbU5Thch8AdFf7Wan6V9Kfn5dkzi/n6qXjj0p1/xbp6qIKMykA6I72pvOX+U6ulVqrz2eUQ1JHi3RqrdRxVkqdJsVcd/4SIK4KMykA6I4vlkgf3Sq1fvF1QOmv/lv/pnToRsn3ToQKjC7dCqmSkhLddNNNSk5O1sCBA3X33Xfr6NGjQX2MMVq8eLG8Xq8SExOVl5enI0eOBPXx+/2aP3++0tLSlJSUpKlTp+rEiRNX/2wAINzOfSm1npDU/nUw/eWKn6TzM6nW41JHU2TqizLdCqny8nLNnTtXu3fvVllZmc6dO6f8/Hw1NX39P+Opp57SsmXLtHz5clVUVMjtdmvixIlqaGgI9CksLNTGjRtVWlqqnTt3qrGxUZMnT1Z7e3vonhkAXCsOfR1YCC1zFerq6owkU15ebowxpqOjw7jdbvPkk08G+rS0tBiXy2VefPFFY4wxZ86cMfHx8aa0tDTQ5/PPPzcxMTHmzTffvKzz1tfXf/XvlpAviYmJ5tChQ1czLACiWcNuY2pfNOb9NGN2y5j3/mrZLWMOjzbm/71iTMtnka70qn3wwQemT58+Yfv7VpKpr6+/aA1XdU+qvr5ekpSamipJqqqqUm1trfLz8wN9nE6nxo0bp127dkmS9u7dq7a2tqA+Xq9X2dnZgT7f5Pf75fP5ghYAiIjrcqX+0yXnt6XY67+eRTlipLg0qe/3pbSfSs7BES0zWlxxSBljVFRUpFtuuUXZ2dmSpNraWklSenp6UN/09PRAW21trRISEtSvX78L9vmmkpISuVyuwJKRkXGlZQPA1YtNkf5ms5T5zNfb4lKl726RMkoiV1cUuuK3oM+bN08HDx7Uzp07O7U5HMEXZ40xnbZ908X6FBcXq6ioKLDu8/kIKgCR44g5/+HdvsOl/vef3xabcn72FHd9REuLNlcUUvPnz9frr7+uHTt2aNCgQYHtbrdb0vnZksfz9aeu6+rqArMrt9ut1tZWnT59Omg2VVdXp7Fjx3Z5PqfTKaeTrxoBYJmkHOl/rYt0FVGtW5f7jDGaN2+eNmzYoK1btyorKyuoPSsrS263W2VlZYFtra2tKi8vDwRQTk6O4uPjg/rU1NTo8OHDFwwpAEDv1K2Z1Ny5c/Xqq6/qtddeU3JycuAeksvlUmJiohwOhwoLC7VkyRINHTpUQ4cO1ZIlS9S3b1/df//9gb4PPfSQFixYoP79+ys1NVULFy7U8OHDdfvtt4f+GQIAeqxuhdQLL7wgScrLywvavnLlSs2aNUuS9Oijj6q5uVlz5szR6dOnlZubq7ffflvJycmB/s8884zi4uJ07733qrm5WbfddptWrVql2NjYq3s2AICo4jDGmEt3s4vP55PL5QrLsRMTE7Vnz57AOxYBoLc6ePCgcnNz1dLSErZz1NfXKyUl5YLtfHcfAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBaV/wFs9Gqo6NDlZWV6ujoiHQpABBRlZWVivRHafkwbxecTuclv7UdAKKdMUZ+vz+s57jUh3mZSXUh3P9TAACXh3tSAABrEVIAAGsRUgAAaxFSAABrEVIAAGsRUgAAaxFSAABrEVIAAGsRUgAAaxFSAABrEVIAAGsRUgAAaxFSAABrEVIAAGsRUgAAaxFSAABrEVIAAGsRUgAAaxFSAABrEVIAAGv1yJAyxkS6BABACFzq7/MeGVINDQ2RLgEAEAKX+vvcYXrgtKSjo0NHjx7V9773PVVXVyslJSXSJfVoPp9PGRkZjOVVYhxDh7EMDZvH0RijhoYGeb1excRceL4Udw1rCpmYmBh961vfkiSlpKRYN/g9FWMZGoxj6DCWoWHrOLpcrkv26ZGX+wAAvQMhBQCwVo8NKafTqUWLFsnpdEa6lB6PsQwNxjF0GMvQiIZx7JFvnAAA9A49diYFAIh+hBQAwFqEFADAWoQUAMBahBQAwFo9NqSef/55ZWVlqU+fPsrJydG7774b6ZKstnjxYjkcjqDF7XYH2o0xWrx4sbxerxITE5WXl6cjR45EsGI77NixQ1OmTJHX65XD4dCmTZuC2i9n3Px+v+bPn6+0tDQlJSVp6tSpOnHixDV8Fna41FjOmjWr02t09OjRQX0YS6mkpEQ33XSTkpOTNXDgQN199906evRoUJ9oel32yJBav369CgsL9fjjj2v//v364Q9/qIKCAh0/fjzSpVnthhtuUE1NTWA5dOhQoO2pp57SsmXLtHz5clVUVMjtdmvixIm9/st8m5qaNGLECC1fvrzL9ssZt8LCQm3cuFGlpaXauXOnGhsbNXnyZLW3t1+rp2GFS42lJE2aNCnoNfrGG28EtTOWUnl5uebOnavdu3errKxM586dU35+vpqamgJ9oup1aXqgH/zgB+aRRx4J2vbd737XPPbYYxGqyH6LFi0yI0aM6LKto6PDuN1u8+STTwa2tbS0GJfLZV588cVrVKH9JJmNGzcG1i9n3M6cOWPi4+NNaWlpoM/nn39uYmJizJtvvnnNarfNN8fSGGNmzpxp7rrrrgvuw1h2ra6uzkgy5eXlxpjoe132uJlUa2ur9u7dq/z8/KDt+fn52rVrV4Sq6hkqKyvl9XqVlZWlGTNm6NixY5Kkqqoq1dbWBo2p0+nUuHHjGNOLuJxx27t3r9ra2oL6eL1eZWdnM7Zd2L59uwYOHKhhw4Zp9uzZqqurC7Qxll2rr6+XJKWmpkqKvtdljwupkydPqr29Xenp6UHb09PTVVtbG6Gq7Jebm6s1a9borbfe0ksvvaTa2lqNHTtWp06dCowbY9o9lzNutbW1SkhIUL9+/S7YB+cVFBRo3bp12rp1q5YuXaqKigpNmDBBfr9fEmPZFWOMioqKdMsttyg7O1tS9L0ue+RPdUiSw+EIWjfGdNqGrxUUFAQeDx8+XGPGjNGQIUO0evXqwM1pxvTKXMm4MbadTZ8+PfA4Oztbo0aNUmZmpjZv3qxp06ZdcL/ePJbz5s3TwYMHtXPnzk5t0fK67HEzqbS0NMXGxnZK+7q6uk7/csCFJSUlafjw4aqsrAy8y48x7Z7LGTe3263W1ladPn36gn3QNY/Ho8zMTFVWVkpiLL9p/vz5ev3117Vt2zYNGjQosD3aXpc9LqQSEhKUk5OjsrKyoO1lZWUaO3ZshKrqefx+vz766CN5PB5lZWXJ7XYHjWlra6vKy8sZ04u4nHHLyclRfHx8UJ+amhodPnyYsb2EU6dOqbq6Wh6PRxJj+RVjjObNm6cNGzZo69atysrKCmqPutdlxN6ycRVKS0tNfHy8WbFihfnwww9NYWGhSUpKMp9++mmkS7PWggULzPbt282xY8fM7t27zeTJk01ycnJgzJ588knjcrnMhg0bzKFDh8x9991nPB6P8fl8Ea48shoaGsz+/fvN/v37jSSzbNkys3//fvPZZ58ZYy5v3B555BEzaNAgs2XLFrNv3z4zYcIEM2LECHPu3LlIPa2IuNhYNjQ0mAULFphdu3aZqqoqs23bNjNmzBjzrW99i7H8hl/+8pfG5XKZ7du3m5qamsBy9uzZQJ9oel32yJAyxph//dd/NZmZmSYhIcGMHDky8PZLdG369OnG4/GY+Ph44/V6zbRp08yRI0cC7R0dHWbRokXG7XYbp9Npbr31VnPo0KEIVmyHbdu2GUmdlpkzZxpjLm/cmpubzbx580xqaqpJTEw0kydPNsePH4/As4msi43l2bNnTX5+vhkwYICJj483gwcPNjNnzuw0Toyl6XIMJZmVK1cG+kTT65LfkwIAWKvH3ZMCAPQehBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFr/H+0CnQDYROUAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reset_G()\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80e8492d-8c1e-4389-b871-31e9d30340b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis notebook is to show the EnhancedBrain input, output, and state of mind at once.\n",
    "# I'll start with a rough version and make it cleaner over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9a6d7d3-7701-4ad6-aedf-9d1da7612150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79f707fd-090f-42d3-92ed-b2ed1d87c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8946d87-c09e-4eba-897f-5f81c5211bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_imshow_numpy(torch_img, imshow=False):\n",
    "    clean = torch_img.detach()[0].cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b95dcd9-2119-47fb-a2b8-6713e5b28b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output(layout={'border': '1px solid black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22a55bbb-7aae-4acf-8232-baed2cc9f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = EnhancedAgentBrain()\n",
    "#model.move_to(device)\n",
    "#2+2\n",
    "# commment to prevent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37dd7bcf-415e-4a8a-8078-7716f8ce17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "# tokenizer.save_model(\".\", \"tokenizer/eng_sentences_tokenizer_vc10000\")\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-vocab.json\",\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-merges.txt\",\n",
    ")   \n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")   \n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60b38a1d-479c-46d6-a3f7-b7e77181f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = widgets.Textarea(\n",
    "    value='Hello World',\n",
    "    placeholder='Type something',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2ee3f89-d4b9-45f4-9e54-0ca7a6c40866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(game=None):\n",
    "    if game is None:\n",
    "        game = G\n",
    "    img = torch.FloatTensor(G.getData()).unsqueeze(0)\n",
    "    img = torch.permute(img, (0, 3, 1, 2)).contiguous().to(device)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8aed9588-a3c7-4fe3-8e5f-9fc29fe9a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:1')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a475188-3a0a-4aac-8a2e-36456c557cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this for other inputs\n",
    "# inp_tensor = get_image()\n",
    "inp_tensor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fab32506-2f60-4969-afdf-4fc35ccf8b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   32,   87,   34, 5411, 4226,    5,   32,   19,   87,   34,    2]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.tensor(tokenizer.encode(\"<s>Hello World!</s>\").ids).unsqueeze(0).contiguous().to(device)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1930a98-8161-4c7a-b1c0-4dca5f2bf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Hello World!</s>'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tt[0][1:-1].cpu().numpy(), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b88d78ff-8c78-4c99-88be-0a7340a40b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"<s>Hello World!</s>\".find('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2da1651-dd24-4a73-a246-cbc3f5feb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def display_innards(b):\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    print(\"Canvases:\\n\")\n",
    "    if model.canvases.is_empty():\n",
    "        print(\"################\\nCanvases object is empty, nothing to show\\n################\")\n",
    "    else:\n",
    "        for i in range(model.canvases.num_canvases):\n",
    "            print(f\"##########\\nCanvas {i}:\\n\")\n",
    "            plt.imshow(pre_imshow_numpy(model.canvases.tw.L[i][:1]))\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77b5eebc-b0a8-4252-bee8-eda5c4f1de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def forward_wrapper(b):\n",
    "    output.clear_output()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "    tt = torch.tensor(tokenizer.encode(T.value).ids).unsqueeze(0).contiguous().to(device)\n",
    "    _, recon = model(tt, local_tensor, create_context=True, ret_imgs=True)\n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b)\n",
    "\n",
    "# wrapper for extending input text without changing what is displayed, much\n",
    "\n",
    "temp=1.0\n",
    "temp_eps = 1e-4\n",
    "\n",
    "special_symbols = set([1, 3, 4, 108])\n",
    "symbol_action_map = { 1:1, 3:3, 4:4, 108:2}\n",
    "\n",
    "@output.capture()\n",
    "def extend_wrapper(b):\n",
    "    output.clear_output()\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "\n",
    "    # in this case, we abridge the end-of-sentence token in order to continue the extension\n",
    "    inp_ids = tokenizer.encode(T.value).ids[:-1]\n",
    "    if len(inp_ids) > 32:\n",
    "        inp_ids = inp_ids[-32:] # the rest should be in memory\n",
    "    tt = torch.tensor(inp_ids).unsqueeze(0).contiguous().to(device)\n",
    "    logits, recon = model(tt, local_tensor, return_full=False, create_context=True, ret_imgs=True)\n",
    "\n",
    "    s = tt.size()\n",
    "    output_text = torch.zeros((s[0], s[1] +1), dtype = torch.long, device=device)\n",
    "    output_text[:, :-1] += tt\n",
    "    \n",
    "    preds = model.select(logits, temp, ret_all=False, temp_eps=temp_eps)\n",
    "    output_text[:, -1] += preds\n",
    "\n",
    "    predval = preds[0].item()\n",
    "    if predval in special_symbols:\n",
    "        action = symbol_action_map[predval]\n",
    "        print(f\"Detected special token {predval} which is action {action}\")\n",
    "        reward = G.actions[action]()\n",
    "        print(f\"Reward was {reward}\")\n",
    "    \n",
    "    T.value = tokenizer.decode(output_text[0][1:].cpu().numpy(), skip_special_tokens=False) # update the string, cut off start token\n",
    "    print(\"updated input string (also in text box):\\n\")\n",
    "    print(T.value)\n",
    "    \n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b) # including game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3fcd589-cd91-488f-a7fd-74ca60b781e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def soft_reset_wrapper(b):\n",
    "    print(\"soft reset (removing internal gradients)\\n\")\n",
    "    model.soft_reset()\n",
    "\n",
    "@output.capture()\n",
    "def reset_wrapper(b):\n",
    "    print(\"hard reset (clering memory and canvaases)\\n\")\n",
    "    model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7217f2f9-400e-49bc-ac6f-0852225ee038",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32 # max len of the model input. Make this a text box or a selector or a knob.\n",
    "\n",
    "@output.capture()\n",
    "def generate_wrapper(b):\n",
    "    # while the string is not too long nor contains the stop codon\n",
    "    while (T.value.find('</s>') == -1) and (len(tokenizer.encode(T.value).ids[:-1]) < max_len):\n",
    "        extend_wrapper(b)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62c779c1-427b-4e9f-8eeb-0c9ec08ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_clear_button_clicked(b):\n",
    "    output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63bf60f2-d3b4-475c-b3d1-0ea1f2ea80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_G_wrapper(b):\n",
    "    reset_G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e6978ff-0314-4b5e-af6b-ad9a57deb475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedAgentBrain(\n",
       "  (img_enc): ImageTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): PatchEmbedding(\n",
       "        (linear_project): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (1): PositionalEncoding_2D()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (img_dec): ImageTransformerDecoder(\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.01, inplace=False)\n",
       "          (dropout2): Dropout(p=0.01, inplace=False)\n",
       "          (dropout3): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): PatchEmbeddingTranspose(\n",
       "        (linear_project): ConvTranspose2d(768, 3, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_enc): SentenceTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): Embedding(10000, 768, padding_idx=0)\n",
       "      (1): PositionalEncoding()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_dec): SentenceTransformerDecoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=3072, out_features=10000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dopamine): DopamineWrapper(\n",
       "    (dopamine): IntermediateTransformerScorer(\n",
       "      (decoder): TransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=3072, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (memory): Memory()\n",
       "  (mem_enc): MemoryEncoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_prep): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (fcs): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4256368e-b469-4e71-8f44-44339c70847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dfaf1f44bc44dcba3f584e45b1889bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset Game', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b02223143944880a9fecef465ea46f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Forward', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91132df8bfc945b3a0b6418881e487b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Soft Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d1b7b217a54ef09103f709b3366251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de1747045974b3eb359d535ea90c5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Extend by One Character', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9157beda22a642e08912447a106c1fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Text', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0b830e0dc94f538ffead6a21064a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Canvases', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3db6e87c5c4099959fd305bf14c061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clear Output', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25af562c09af4c5ba6769383e51155f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Hello World', description='String:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e9dd3b03794a6998efa9d726b47bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bGameReset = widgets.Button(description=\"Reset Game\")\n",
    "bForward = widgets.Button(description=\"Forward\")\n",
    "bSoftReset = widgets.Button(description=\"Soft Reset\")\n",
    "bReset = widgets.Button(description=\"Reset\")\n",
    "bExtend = widgets.Button(description=\"Extend by One Character\")\n",
    "bGenerate = widgets.Button(description=\"Generate Text\")\n",
    "bDisplayInnards = widgets.Button(description=\"Show Canvases\")\n",
    "bClear = widgets.Button(description=\"Clear Output\")\n",
    "\n",
    "display(bGameReset)\n",
    "display(bForward)\n",
    "display(bSoftReset)\n",
    "display(bReset)\n",
    "display(bExtend)\n",
    "display(bGenerate)\n",
    "display(bDisplayInnards)\n",
    "display(bClear)\n",
    "\n",
    "display(T) # expand me by hand; prettier that way\n",
    "\n",
    "bGameReset.on_click(reset_G_wrapper)\n",
    "bForward.on_click(forward_wrapper)\n",
    "bSoftReset.on_click(soft_reset_wrapper)\n",
    "bReset.on_click(reset_wrapper)\n",
    "bExtend.on_click(extend_wrapper)\n",
    "bGenerate.on_click(generate_wrapper)\n",
    "bDisplayInnards.on_click(display_innards)\n",
    "bClear.on_click(on_clear_button_clicked)\n",
    "\n",
    "display(output)\n",
    "display_innards(bDisplayInnards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1acbc-0080-4704-9720-f4240733e8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee39b28-2d5e-4d18-97f2-e32acef0d9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59cb5e-b270-4a7d-bc3d-31977cf2a55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
