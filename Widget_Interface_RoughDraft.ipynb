{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e490d674-0492-4826-9e34-47944bb4e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FIRST 4 CELLS: specify frameworks, external imports, and the exact brain checkpoint used.\n",
    "# The other cells specify funcs for the widget, which is at the bottom\n",
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "from control_framework import *\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c995e3-9282-41fe-bcec-b779896818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e76133-fa47-472e-ba9f-1959fc6ed499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedAgentBrain()\n",
    "model.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_v2_batch160799.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v2_batch55900.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v2_batch24800.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v3_batch155466.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v4_batch399.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v5_batch133.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_v2_batch29398.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_v3_batch35249.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_de_novo_v1_batch41200.pth'\n",
    "#fname = 'brain_checkpoints/super_brain_retraining_control_arrow_v1_batch33400.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_transferred.pth'\n",
    "#fname = 'brain_checkpoints/super_brain_retraining_control_arrow_RESTART_v1_batch31799.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_canvases_v1_batch33597.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_canvases_v2_batch25999.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_canvases_v3_batch19998.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v1_batch4665.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v2_batch2244.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v2_batch9996.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v3_batch1799.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v3_batch6595.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v3_batch19198.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v4_batch10000.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v6_batch10993.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v7_batch115487.pth'\n",
    "fname = 'brain_checkpoints/frankenstein_tutorialQA_v7_batch1100.pth'\n",
    "\n",
    "# A little extra code to avoid weird error\n",
    "#model.memory.remember(torch.randn(16, 1, 768).to(device))\n",
    "model.memory.remember(torch.randn(8, 1, 768).to(device))\n",
    "\n",
    "model.load_state_dict(torch.load(fname, weights_only=True, map_location=device))\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1361e168-adf8-453b-ac4a-5825ef046c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other elements to use\n",
    "\n",
    "from game import *\n",
    "\n",
    "game_settings = BIG_tool_use_advanced_2_5\n",
    "game_settings.gameSize = 224 # for compatibility with brain's expected size\n",
    "G = discreteGame(game_settings)\n",
    "\n",
    "####\n",
    "\n",
    "#For this time:\n",
    "def reset_G():\n",
    "    global G\n",
    "    G = discreteGame(G.random_bare_settings(gameSize=224, max_agent_offset=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b1ce00-688f-4a7b-aba0-4700d9341a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f677d1b2f00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reset_G()\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e8492d-8c1e-4389-b871-31e9d30340b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis notebook is to show the EnhancedBrain input, output, and state of mind at once.\n",
    "# I'll start with a rough version and make it cleaner over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a6d7d3-7701-4ad6-aedf-9d1da7612150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79f707fd-090f-42d3-92ed-b2ed1d87c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8946d87-c09e-4eba-897f-5f81c5211bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_imshow_numpy(torch_img, imshow=False):\n",
    "    clean = torch_img.detach()[0].cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b95dcd9-2119-47fb-a2b8-6713e5b28b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output(layout={'border': '1px solid black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a55bbb-7aae-4acf-8232-baed2cc9f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = EnhancedAgentBrain()\n",
    "#model.move_to(device)\n",
    "#2+2\n",
    "# commment to prevent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37dd7bcf-415e-4a8a-8078-7716f8ce17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "# tokenizer.save_model(\".\", \"tokenizer/eng_sentences_tokenizer_vc10000\")\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-vocab.json\",\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-merges.txt\",\n",
    ")   \n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")   \n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b38a1d-479c-46d6-a3f7-b7e77181f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = widgets.Textarea(\n",
    "    value='Hello World',\n",
    "    placeholder='Type something',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ee3f89-d4b9-45f4-9e54-0ca7a6c40866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(game=None):\n",
    "    if game is None:\n",
    "        game = G\n",
    "    img = torch.FloatTensor(G.getData()).unsqueeze(0)\n",
    "    img = torch.permute(img, (0, 3, 1, 2)).contiguous().to(device)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aed9588-a3c7-4fe3-8e5f-9fc29fe9a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a475188-3a0a-4aac-8a2e-36456c557cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this for other inputs\n",
    "# inp_tensor = get_image()\n",
    "inp_tensor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab32506-2f60-4969-afdf-4fc35ccf8b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   32,   87,   34, 5411, 4226,    5,   32,   19,   87,   34,    2]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.tensor(tokenizer.encode(\"<s>Hello World!</s>\").ids).unsqueeze(0).contiguous().to(device)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1930a98-8161-4c7a-b1c0-4dca5f2bf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Hello World!</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tt[0][1:-1].cpu().numpy(), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b88d78ff-8c78-4c99-88be-0a7340a40b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"<s>Hello World!</s>\".find('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2da1651-dd24-4a73-a246-cbc3f5feb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def display_innards(b):\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    print(\"Canvases:\\n\")\n",
    "    if model.canvases.is_empty():\n",
    "        print(\"################\\nCanvases object is empty, nothing to show\\n################\")\n",
    "    else:\n",
    "        for i in range(model.canvases.num_canvases):\n",
    "            print(f\"##########\\nCanvas {i}:\\n\")\n",
    "            plt.imshow(pre_imshow_numpy(model.canvases.tw.L[i][:1]))\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b5eebc-b0a8-4252-bee8-eda5c4f1de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def forward_wrapper(b):\n",
    "    output.clear_output()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "    tt = torch.tensor(tokenizer.encode(T.value).ids).unsqueeze(0).contiguous().to(device)\n",
    "    _, recon = model(tt, local_tensor, create_context=True, ret_imgs=True)\n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b)\n",
    "\n",
    "# wrapper for extending input text without changing what is displayed, much\n",
    "\n",
    "temp=1.0\n",
    "temp_eps = 1e-4\n",
    "\n",
    "special_symbols = set([1, 3, 4, 108])\n",
    "symbol_action_map = { 1:1, 3:3, 4:4, 108:2}\n",
    "\n",
    "@output.capture()\n",
    "def extend_wrapper(b):\n",
    "    output.clear_output()\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "\n",
    "    # in this case, we abridge the end-of-sentence token in order to continue the extension\n",
    "    inp_ids = tokenizer.encode(T.value).ids[:-1]\n",
    "    if len(inp_ids) > 32:\n",
    "        inp_ids = inp_ids[-32:] # the rest should be in memory\n",
    "    tt = torch.tensor(inp_ids).unsqueeze(0).contiguous().to(device)\n",
    "    logits, recon = model(tt, local_tensor, return_full=False, create_context=True, ret_imgs=True)\n",
    "\n",
    "    s = tt.size()\n",
    "    output_text = torch.zeros((s[0], s[1] +1), dtype = torch.long, device=device)\n",
    "    output_text[:, :-1] += tt\n",
    "    \n",
    "    preds = model.select(logits, temp, ret_all=False, temp_eps=temp_eps)\n",
    "    output_text[:, -1] += preds\n",
    "\n",
    "    predval = preds[0].item()\n",
    "    if predval in special_symbols:\n",
    "        action = symbol_action_map[predval]\n",
    "        print(f\"Detected special token {predval} which is action {action}\")\n",
    "        reward = G.actions[action]()\n",
    "        print(f\"Reward was {reward}\")\n",
    "    \n",
    "    T.value = tokenizer.decode(output_text[0][1:].cpu().numpy(), skip_special_tokens=False) # update the string, cut off start token\n",
    "    print(\"updated input string (also in text box):\\n\")\n",
    "    print(T.value)\n",
    "    \n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b) # including game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3fcd589-cd91-488f-a7fd-74ca60b781e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def soft_reset_wrapper(b):\n",
    "    print(\"soft reset (removing internal gradients)\\n\")\n",
    "    model.soft_reset()\n",
    "\n",
    "@output.capture()\n",
    "def reset_wrapper(b):\n",
    "    print(\"hard reset (clering memory and canvaases)\\n\")\n",
    "    model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7217f2f9-400e-49bc-ac6f-0852225ee038",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32 # max len of the model input. Make this a text box or a selector or a knob.\n",
    "\n",
    "@output.capture()\n",
    "def generate_wrapper(b):\n",
    "    # while the string is not too long nor contains the stop codon\n",
    "    while (T.value.find('</s>') == -1) and (len(tokenizer.encode(T.value).ids[:-1]) < max_len):\n",
    "        extend_wrapper(b)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62c779c1-427b-4e9f-8eeb-0c9ec08ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_clear_button_clicked(b):\n",
    "    output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63bf60f2-d3b4-475c-b3d1-0ea1f2ea80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_G_wrapper(b):\n",
    "    reset_G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e6978ff-0314-4b5e-af6b-ad9a57deb475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedAgentBrain(\n",
       "  (img_enc): ImageTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): PatchEmbedding(\n",
       "        (linear_project): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (1): PositionalEncoding_2D()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (img_dec): ImageTransformerDecoder(\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.01, inplace=False)\n",
       "          (dropout2): Dropout(p=0.01, inplace=False)\n",
       "          (dropout3): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): PatchEmbeddingTranspose(\n",
       "        (linear_project): ConvTranspose2d(768, 3, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (img_weight): VisionWeightedSum(\n",
       "    (pe): PositionalEncoding()\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (text_enc): SentenceTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): Embedding(10000, 768, padding_idx=0)\n",
       "      (1): PositionalEncoding()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_dec): SentenceTransformerDecoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=3072, out_features=10000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dopamine): DopamineWrapper(\n",
       "    (dopamine): IntermediateTransformerScorer(\n",
       "      (decoder): TransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=3072, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (memory): Memory()\n",
       "  (mem_enc): MemoryEncoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_prep): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (fcs): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4256368e-b469-4e71-8f44-44339c70847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476408dfbc5d42819805fca13b9814c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset Game', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b857a5e825a84df1bd5b1c00dc8b2d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Forward', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a469429c4345e3864f3f1036e9e256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Soft Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d51714370d422fbe0f91615b67815d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230b0db56284431bb8a5a1acb7247267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Extend by One Character', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d345c7ec158d416d88c598a427cc9f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Text', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc3c0e2c7fe4cf59c9679dc73083fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Canvases', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38db623d488e44e096d803c56b2bbe5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clear Output', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6404506fb3e4c74ba0e2a0cd2fd477c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Hello World', description='String:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac87a1eabaa4e2c95e9375c1f65b9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bGameReset = widgets.Button(description=\"Reset Game\")\n",
    "bForward = widgets.Button(description=\"Forward\")\n",
    "bSoftReset = widgets.Button(description=\"Soft Reset\")\n",
    "bReset = widgets.Button(description=\"Reset\")\n",
    "bExtend = widgets.Button(description=\"Extend by One Character\")\n",
    "bGenerate = widgets.Button(description=\"Generate Text\")\n",
    "bDisplayInnards = widgets.Button(description=\"Show Canvases\")\n",
    "bClear = widgets.Button(description=\"Clear Output\")\n",
    "\n",
    "display(bGameReset)\n",
    "display(bForward)\n",
    "display(bSoftReset)\n",
    "display(bReset)\n",
    "display(bExtend)\n",
    "display(bGenerate)\n",
    "display(bDisplayInnards)\n",
    "display(bClear)\n",
    "\n",
    "display(T) # expand me by hand; prettier that way\n",
    "\n",
    "bGameReset.on_click(reset_G_wrapper)\n",
    "bForward.on_click(forward_wrapper)\n",
    "bSoftReset.on_click(soft_reset_wrapper)\n",
    "bReset.on_click(reset_wrapper)\n",
    "bExtend.on_click(extend_wrapper)\n",
    "bGenerate.on_click(generate_wrapper)\n",
    "bDisplayInnards.on_click(display_innards)\n",
    "bClear.on_click(on_clear_button_clicked)\n",
    "\n",
    "display(output)\n",
    "display_innards(bDisplayInnards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513eec8-92db-4672-bdf4-9bde727c09a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
