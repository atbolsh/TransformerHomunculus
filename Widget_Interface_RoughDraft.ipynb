{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e490d674-0492-4826-9e34-47944bb4e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FIRST 4 CELLS: specify frameworks, external imports, and the exact brain checkpoint used.\n",
    "# The other cells specify funcs for the widget, which is at the bottom\n",
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "from control_framework import *\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c995e3-9282-41fe-bcec-b779896818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e76133-fa47-472e-ba9f-1959fc6ed499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedAgentBrain()\n",
    "model.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_v2_batch160799.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v2_batch55900.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v2_batch24800.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v3_batch155466.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v4_batch399.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v5_batch133.pth'\n",
    "fname = 'brain_checkpoints/enhanced_brain_canvas_use_v2_batch29398.pth'\n",
    "# A little extra code to avoid weird error\n",
    "#model.memory.remember(torch.randn(16, 1, 768).to(device))\n",
    "model.memory.remember(torch.randn(8, 1, 768).to(device))\n",
    "\n",
    "model.load_state_dict(torch.load(fname, weights_only=True, map_location=device))\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1361e168-adf8-453b-ac4a-5825ef046c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other elements to use\n",
    "\n",
    "from game import *\n",
    "\n",
    "game_settings = BIG_tool_use_advanced_2_5\n",
    "game_settings.gameSize = 224 # for compatibility with brain's expected size\n",
    "G = discreteGame(game_settings)\n",
    "\n",
    "####\n",
    "\n",
    "#For this time:\n",
    "def reset_G():\n",
    "    global G\n",
    "    G = discreteGame(G.random_bare_settings(gameSize=224, max_agent_offset=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b1ce00-688f-4a7b-aba0-4700d9341a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f27cc7a4da0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reset_G()\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80e8492d-8c1e-4389-b871-31e9d30340b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis notebook is to show the EnhancedBrain input, output, and state of mind at once.\n",
    "# I'll start with a rough version and make it cleaner over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a6d7d3-7701-4ad6-aedf-9d1da7612150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f707fd-090f-42d3-92ed-b2ed1d87c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8946d87-c09e-4eba-897f-5f81c5211bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_imshow_numpy(torch_img, imshow=False):\n",
    "    clean = torch_img.detach()[0].cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b95dcd9-2119-47fb-a2b8-6713e5b28b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output(layout={'border': '1px solid black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22a55bbb-7aae-4acf-8232-baed2cc9f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = EnhancedAgentBrain()\n",
    "#model.move_to(device)\n",
    "#2+2\n",
    "# commment to prevent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37dd7bcf-415e-4a8a-8078-7716f8ce17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "# tokenizer.save_model(\".\", \"tokenizer/eng_sentences_tokenizer_vc10000\")\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-vocab.json\",\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-merges.txt\",\n",
    ")   \n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")   \n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60b38a1d-479c-46d6-a3f7-b7e77181f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = widgets.Textarea(\n",
    "    value='Hello World',\n",
    "    placeholder='Type something',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2ee3f89-d4b9-45f4-9e54-0ca7a6c40866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(game=None):\n",
    "    if game is None:\n",
    "        game = G\n",
    "    img = torch.FloatTensor(G.getData()).unsqueeze(0)\n",
    "    img = torch.permute(img, (0, 3, 1, 2)).contiguous().to(device)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aed9588-a3c7-4fe3-8e5f-9fc29fe9a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a475188-3a0a-4aac-8a2e-36456c557cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this for other inputs\n",
    "# inp_tensor = get_image()\n",
    "inp_tensor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab32506-2f60-4969-afdf-4fc35ccf8b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   32,   87,   34, 5411, 4226,    5,   32,   19,   87,   34,    2]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.tensor(tokenizer.encode(\"<s>Hello World!</s>\").ids).unsqueeze(0).contiguous().to(device)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1930a98-8161-4c7a-b1c0-4dca5f2bf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Hello World!</s>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tt[0][1:-1].cpu().numpy(), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b88d78ff-8c78-4c99-88be-0a7340a40b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"<s>Hello World!</s>\".find('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2da1651-dd24-4a73-a246-cbc3f5feb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def display_innards(b):\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    print(\"Canvases:\\n\")\n",
    "    if model.canvases.is_empty():\n",
    "        print(\"################\\nCanvases object is empty, nothing to show\\n################\")\n",
    "    else:\n",
    "        for i in range(model.canvases.num_canvases):\n",
    "            print(f\"##########\\nCanvas {i}:\\n\")\n",
    "            plt.imshow(pre_imshow_numpy(model.canvases.tw.L[i][:1]))\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77b5eebc-b0a8-4252-bee8-eda5c4f1de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def forward_wrapper(b):\n",
    "    output.clear_output()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "    tt = torch.tensor(tokenizer.encode(T.value).ids).unsqueeze(0).contiguous().to(device)\n",
    "    _, recon = model(tt, local_tensor, create_context=True, ret_imgs=True)\n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b)\n",
    "\n",
    "# wrapper for extending input text without changing what is displayed, much\n",
    "\n",
    "temp=1.0\n",
    "temp_eps = 1e-4\n",
    "\n",
    "special_symbols = set([1, 3, 4, 108])\n",
    "symbol_action_map = { 1:1, 3:3, 4:4, 108:2}\n",
    "\n",
    "@output.capture()\n",
    "def extend_wrapper(b):\n",
    "    output.clear_output()\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "\n",
    "    # in this case, we abridge the end-of-sentence token in order to continue the extension\n",
    "    inp_ids = tokenizer.encode(T.value).ids[:-1]\n",
    "    if len(inp_ids) > 32:\n",
    "        inp_ids = inp_ids[-32:] # the rest should be in memory\n",
    "    tt = torch.tensor(inp_ids).unsqueeze(0).contiguous().to(device)\n",
    "    logits, recon = model(tt, local_tensor, return_full=False, create_context=True, ret_imgs=True)\n",
    "\n",
    "    s = tt.size()\n",
    "    output_text = torch.zeros((s[0], s[1] +1), dtype = torch.long, device=device)\n",
    "    output_text[:, :-1] += tt\n",
    "    \n",
    "    preds = model.select(logits, temp, ret_all=False, temp_eps=temp_eps)\n",
    "    output_text[:, -1] += preds\n",
    "\n",
    "    predval = preds[0].item()\n",
    "    if predval in special_symbols:\n",
    "        action = symbol_action_map[predval]\n",
    "        print(f\"Detected special token {predval} which is action {action}\")\n",
    "        reward = G.actions[action]()\n",
    "        print(f\"Reward was {reward}\")\n",
    "    \n",
    "    T.value = tokenizer.decode(output_text[0][1:].cpu().numpy(), skip_special_tokens=False) # update the string, cut off start token\n",
    "    print(\"updated input string (also in text box):\\n\")\n",
    "    print(T.value)\n",
    "    \n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b) # including game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3fcd589-cd91-488f-a7fd-74ca60b781e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def soft_reset_wrapper(b):\n",
    "    print(\"soft reset (removing internal gradients)\\n\")\n",
    "    model.soft_reset()\n",
    "\n",
    "@output.capture()\n",
    "def reset_wrapper(b):\n",
    "    print(\"hard reset (clering memory and canvaases)\\n\")\n",
    "    model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7217f2f9-400e-49bc-ac6f-0852225ee038",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32 # max len of the model input. Make this a text box or a selector or a knob.\n",
    "\n",
    "@output.capture()\n",
    "def generate_wrapper(b):\n",
    "    # while the string is not too long nor contains the stop codon\n",
    "    while (T.value.find('</s>') == -1) and (len(tokenizer.encode(T.value).ids[:-1]) < max_len):\n",
    "        extend_wrapper(b)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62c779c1-427b-4e9f-8eeb-0c9ec08ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_clear_button_clicked(b):\n",
    "    output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63bf60f2-d3b4-475c-b3d1-0ea1f2ea80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_G_wrapper(b):\n",
    "    reset_G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e6978ff-0314-4b5e-af6b-ad9a57deb475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedAgentBrain(\n",
       "  (img_enc): ImageTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): PatchEmbedding(\n",
       "        (linear_project): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (1): PositionalEncoding_2D()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (img_dec): ImageTransformerDecoder(\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.01, inplace=False)\n",
       "          (dropout2): Dropout(p=0.01, inplace=False)\n",
       "          (dropout3): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): PatchEmbeddingTranspose(\n",
       "        (linear_project): ConvTranspose2d(768, 3, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_enc): SentenceTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): Embedding(10000, 768, padding_idx=0)\n",
       "      (1): PositionalEncoding()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_dec): SentenceTransformerDecoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=3072, out_features=10000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dopamine): DopamineWrapper(\n",
       "    (dopamine): IntermediateTransformerScorer(\n",
       "      (decoder): TransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=3072, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (memory): Memory()\n",
       "  (mem_enc): MemoryEncoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_prep): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (fcs): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4256368e-b469-4e71-8f44-44339c70847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b508ac54498f45ec9d9ce13d5dcdb66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset Game', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45484149db34b8391879aacbeec8095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Forward', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0c13d6066a47c2b207265b49a66bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Soft Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55be6e6cbb9a4e459e090234ed4f773f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc3d73e9c66427582b09588f79da607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Extend by One Character', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3786abacce19416d927faf8314c7236e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Text', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96a8b5d0c7d438ba0c6fbe6ab49ab2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Canvases', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c62080724a4244818a8d376e4a531c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clear Output', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac07e1e16fca4e96a45ec15cdbc086ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Hello World', description='String:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86643e7dd0de4afb86701bfa31a07895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bGameReset = widgets.Button(description=\"Reset Game\")\n",
    "bForward = widgets.Button(description=\"Forward\")\n",
    "bSoftReset = widgets.Button(description=\"Soft Reset\")\n",
    "bReset = widgets.Button(description=\"Reset\")\n",
    "bExtend = widgets.Button(description=\"Extend by One Character\")\n",
    "bGenerate = widgets.Button(description=\"Generate Text\")\n",
    "bDisplayInnards = widgets.Button(description=\"Show Canvases\")\n",
    "bClear = widgets.Button(description=\"Clear Output\")\n",
    "\n",
    "display(bGameReset)\n",
    "display(bForward)\n",
    "display(bSoftReset)\n",
    "display(bReset)\n",
    "display(bExtend)\n",
    "display(bGenerate)\n",
    "display(bDisplayInnards)\n",
    "display(bClear)\n",
    "\n",
    "display(T) # expand me by hand; prettier that way\n",
    "\n",
    "bGameReset.on_click(reset_G_wrapper)\n",
    "bForward.on_click(forward_wrapper)\n",
    "bSoftReset.on_click(soft_reset_wrapper)\n",
    "bReset.on_click(reset_wrapper)\n",
    "bExtend.on_click(extend_wrapper)\n",
    "bGenerate.on_click(generate_wrapper)\n",
    "bDisplayInnards.on_click(display_innards)\n",
    "bClear.on_click(on_clear_button_clicked)\n",
    "\n",
    "display(output)\n",
    "display_innards(bDisplayInnards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1acbc-0080-4704-9720-f4240733e8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee39b28-2d5e-4d18-97f2-e32acef0d9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59cb5e-b270-4a7d-bc3d-31977cf2a55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
