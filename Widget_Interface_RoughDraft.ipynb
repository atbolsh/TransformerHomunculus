{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e490d674-0492-4826-9e34-47944bb4e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FIRST 4 CELLS: specify frameworks, external imports, and the exact brain checkpoint used.\n",
    "# The other cells specify funcs for the widget, which is at the bottom\n",
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "from control_framework import *\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c995e3-9282-41fe-bcec-b779896818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e76133-fa47-472e-ba9f-1959fc6ed499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedAgentBrain()\n",
    "model.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_v2_batch160799.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v2_batch55900.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v2_batch24800.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v3_batch155466.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v4_batch399.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v5_batch133.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_v2_batch29398.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_v3_batch35249.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_de_novo_v1_batch41200.pth'\n",
    "#fname = 'brain_checkpoints/super_brain_retraining_control_arrow_v1_batch33400.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_transferred.pth'\n",
    "#fname = 'brain_checkpoints/super_brain_retraining_control_arrow_RESTART_v1_batch31799.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_canvases_v1_batch33597.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_canvases_v2_batch25999.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_canvases_v3_batch19998.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v1_batch4665.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v2_batch2244.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v2_batch9996.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v3_batch1799.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v3_batch6595.pth'\n",
    "#fname = 'brain_checkpoints/frankenstein_tutorialQA_v3_batch19198.pth'\n",
    "fname = 'brain_checkpoints/frankenstein_tutorialQA_v4_batch10000.pth'\n",
    "\n",
    "# A little extra code to avoid weird error\n",
    "#model.memory.remember(torch.randn(16, 1, 768).to(device))\n",
    "#model.memory.remember(torch.randn(8, 1, 768).to(device))\n",
    "\n",
    "model.load_state_dict(torch.load(fname, weights_only=True, map_location=device))\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1361e168-adf8-453b-ac4a-5825ef046c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other elements to use\n",
    "\n",
    "from game import *\n",
    "\n",
    "game_settings = BIG_tool_use_advanced_2_5\n",
    "game_settings.gameSize = 224 # for compatibility with brain's expected size\n",
    "G = discreteGame(game_settings)\n",
    "\n",
    "####\n",
    "\n",
    "#For this time:\n",
    "def reset_G():\n",
    "    global G\n",
    "    G = discreteGame(G.random_bare_settings(gameSize=224, max_agent_offset=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b1ce00-688f-4a7b-aba0-4700d9341a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f06214de5a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reset_G()\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e8492d-8c1e-4389-b871-31e9d30340b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis notebook is to show the EnhancedBrain input, output, and state of mind at once.\n",
    "# I'll start with a rough version and make it cleaner over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a6d7d3-7701-4ad6-aedf-9d1da7612150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79f707fd-090f-42d3-92ed-b2ed1d87c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8946d87-c09e-4eba-897f-5f81c5211bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_imshow_numpy(torch_img, imshow=False):\n",
    "    clean = torch_img.detach()[0].cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b95dcd9-2119-47fb-a2b8-6713e5b28b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output(layout={'border': '1px solid black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a55bbb-7aae-4acf-8232-baed2cc9f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = EnhancedAgentBrain()\n",
    "#model.move_to(device)\n",
    "#2+2\n",
    "# commment to prevent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37dd7bcf-415e-4a8a-8078-7716f8ce17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "# tokenizer.save_model(\".\", \"tokenizer/eng_sentences_tokenizer_vc10000\")\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-vocab.json\",\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-merges.txt\",\n",
    ")   \n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")   \n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b38a1d-479c-46d6-a3f7-b7e77181f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = widgets.Textarea(\n",
    "    value='Hello World',\n",
    "    placeholder='Type something',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ee3f89-d4b9-45f4-9e54-0ca7a6c40866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(game=None):\n",
    "    if game is None:\n",
    "        game = G\n",
    "    img = torch.FloatTensor(G.getData()).unsqueeze(0)\n",
    "    img = torch.permute(img, (0, 3, 1, 2)).contiguous().to(device)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aed9588-a3c7-4fe3-8e5f-9fc29fe9a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a475188-3a0a-4aac-8a2e-36456c557cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this for other inputs\n",
    "# inp_tensor = get_image()\n",
    "inp_tensor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab32506-2f60-4969-afdf-4fc35ccf8b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   32,   87,   34, 5411, 4226,    5,   32,   19,   87,   34,    2]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.tensor(tokenizer.encode(\"<s>Hello World!</s>\").ids).unsqueeze(0).contiguous().to(device)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1930a98-8161-4c7a-b1c0-4dca5f2bf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Hello World!</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tt[0][1:-1].cpu().numpy(), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b88d78ff-8c78-4c99-88be-0a7340a40b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"<s>Hello World!</s>\".find('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2da1651-dd24-4a73-a246-cbc3f5feb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def display_innards(b):\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    print(\"Canvases:\\n\")\n",
    "    if model.canvases.is_empty():\n",
    "        print(\"################\\nCanvases object is empty, nothing to show\\n################\")\n",
    "    else:\n",
    "        for i in range(model.canvases.num_canvases):\n",
    "            print(f\"##########\\nCanvas {i}:\\n\")\n",
    "            plt.imshow(pre_imshow_numpy(model.canvases.tw.L[i][:1]))\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b5eebc-b0a8-4252-bee8-eda5c4f1de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def forward_wrapper(b):\n",
    "    output.clear_output()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "    tt = torch.tensor(tokenizer.encode(T.value).ids).unsqueeze(0).contiguous().to(device)\n",
    "    _, recon = model(tt, local_tensor, create_context=True, ret_imgs=True)\n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b)\n",
    "\n",
    "# wrapper for extending input text without changing what is displayed, much\n",
    "\n",
    "temp=1.0\n",
    "temp_eps = 1e-4\n",
    "\n",
    "special_symbols = set([1, 3, 4, 108])\n",
    "symbol_action_map = { 1:1, 3:3, 4:4, 108:2}\n",
    "\n",
    "@output.capture()\n",
    "def extend_wrapper(b):\n",
    "    output.clear_output()\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "\n",
    "    # in this case, we abridge the end-of-sentence token in order to continue the extension\n",
    "    inp_ids = tokenizer.encode(T.value).ids[:-1]\n",
    "    if len(inp_ids) > 32:\n",
    "        inp_ids = inp_ids[-32:] # the rest should be in memory\n",
    "    tt = torch.tensor(inp_ids).unsqueeze(0).contiguous().to(device)\n",
    "    logits, recon = model(tt, local_tensor, return_full=False, create_context=True, ret_imgs=True)\n",
    "\n",
    "    s = tt.size()\n",
    "    output_text = torch.zeros((s[0], s[1] +1), dtype = torch.long, device=device)\n",
    "    output_text[:, :-1] += tt\n",
    "    \n",
    "    preds = model.select(logits, temp, ret_all=False, temp_eps=temp_eps)\n",
    "    output_text[:, -1] += preds\n",
    "\n",
    "    predval = preds[0].item()\n",
    "    if predval in special_symbols:\n",
    "        action = symbol_action_map[predval]\n",
    "        print(f\"Detected special token {predval} which is action {action}\")\n",
    "        reward = G.actions[action]()\n",
    "        print(f\"Reward was {reward}\")\n",
    "    \n",
    "    T.value = tokenizer.decode(output_text[0][1:].cpu().numpy(), skip_special_tokens=False) # update the string, cut off start token\n",
    "    print(\"updated input string (also in text box):\\n\")\n",
    "    print(T.value)\n",
    "    \n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b) # including game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3fcd589-cd91-488f-a7fd-74ca60b781e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def soft_reset_wrapper(b):\n",
    "    print(\"soft reset (removing internal gradients)\\n\")\n",
    "    model.soft_reset()\n",
    "\n",
    "@output.capture()\n",
    "def reset_wrapper(b):\n",
    "    print(\"hard reset (clering memory and canvaases)\\n\")\n",
    "    model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7217f2f9-400e-49bc-ac6f-0852225ee038",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32 # max len of the model input. Make this a text box or a selector or a knob.\n",
    "\n",
    "@output.capture()\n",
    "def generate_wrapper(b):\n",
    "    # while the string is not too long nor contains the stop codon\n",
    "    while (T.value.find('</s>') == -1) and (len(tokenizer.encode(T.value).ids[:-1]) < max_len):\n",
    "        extend_wrapper(b)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62c779c1-427b-4e9f-8eeb-0c9ec08ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_clear_button_clicked(b):\n",
    "    output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63bf60f2-d3b4-475c-b3d1-0ea1f2ea80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_G_wrapper(b):\n",
    "    reset_G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e6978ff-0314-4b5e-af6b-ad9a57deb475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedAgentBrain(\n",
       "  (img_enc): ImageTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): PatchEmbedding(\n",
       "        (linear_project): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (1): PositionalEncoding_2D()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (img_dec): ImageTransformerDecoder(\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.01, inplace=False)\n",
       "          (dropout2): Dropout(p=0.01, inplace=False)\n",
       "          (dropout3): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): PatchEmbeddingTranspose(\n",
       "        (linear_project): ConvTranspose2d(768, 3, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (img_weight): VisionWeightedSum(\n",
       "    (pe): PositionalEncoding()\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (text_enc): SentenceTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): Embedding(10000, 768, padding_idx=0)\n",
       "      (1): PositionalEncoding()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_dec): SentenceTransformerDecoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=3072, out_features=10000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dopamine): DopamineWrapper(\n",
       "    (dopamine): IntermediateTransformerScorer(\n",
       "      (decoder): TransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=3072, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (memory): Memory()\n",
       "  (mem_enc): MemoryEncoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_prep): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (fcs): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4256368e-b469-4e71-8f44-44339c70847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a62b76fe8534c34a98d19755af1845d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset Game', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf20f6ac6f94bf9ac881aeef3acca25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Forward', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad1e092124e41129af5fa61b4775056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Soft Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ca329b44a948b7a3b22b0d30050e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38472e287978472ba6463f7e49068ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Extend by One Character', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a72a600b2240598d0bbcf83d7069f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Text', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d8c585faeb472eba57ea5dc58a3c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Canvases', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85351977633646fda0441822a0923687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clear Output', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798eba2950b44b00852dae90d88f25b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Hello World', description='String:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02400d280f574109adaa3b28099a2381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bGameReset = widgets.Button(description=\"Reset Game\")\n",
    "bForward = widgets.Button(description=\"Forward\")\n",
    "bSoftReset = widgets.Button(description=\"Soft Reset\")\n",
    "bReset = widgets.Button(description=\"Reset\")\n",
    "bExtend = widgets.Button(description=\"Extend by One Character\")\n",
    "bGenerate = widgets.Button(description=\"Generate Text\")\n",
    "bDisplayInnards = widgets.Button(description=\"Show Canvases\")\n",
    "bClear = widgets.Button(description=\"Clear Output\")\n",
    "\n",
    "display(bGameReset)\n",
    "display(bForward)\n",
    "display(bSoftReset)\n",
    "display(bReset)\n",
    "display(bExtend)\n",
    "display(bGenerate)\n",
    "display(bDisplayInnards)\n",
    "display(bClear)\n",
    "\n",
    "display(T) # expand me by hand; prettier that way\n",
    "\n",
    "bGameReset.on_click(reset_G_wrapper)\n",
    "bForward.on_click(forward_wrapper)\n",
    "bSoftReset.on_click(soft_reset_wrapper)\n",
    "bReset.on_click(reset_wrapper)\n",
    "bExtend.on_click(extend_wrapper)\n",
    "bGenerate.on_click(generate_wrapper)\n",
    "bDisplayInnards.on_click(display_innards)\n",
    "bClear.on_click(on_clear_button_clicked)\n",
    "\n",
    "display(output)\n",
    "display_innards(bDisplayInnards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513eec8-92db-4672-bdf4-9bde727c09a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
