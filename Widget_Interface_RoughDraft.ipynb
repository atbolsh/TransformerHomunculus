{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e490d674-0492-4826-9e34-47944bb4e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FIRST 4 CELLS: specify frameworks, external imports, and the exact brain checkpoint used.\n",
    "# The other cells specify funcs for the widget, which is at the bottom\n",
    "# did you remember to change the 'device' in general_framework.py ?\n",
    "from tutorialQA_framework import *\n",
    "from tutorial1_framework import *\n",
    "from control_framework import *\n",
    "# add more here, or comment out\n",
    "\n",
    "device = torch.device('cuda:1') # let's use the alligator GPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c995e3-9282-41fe-bcec-b779896818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "from visual_transformer.enhanced_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e76133-fa47-472e-ba9f-1959fc6ed499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedAgentBrain()\n",
    "model.move_to(device) # special function that wraps 'to'. Dumb? yes. Needed? Also yes.\n",
    "#fname = 'brain_checkpoints/enhanced_brain_first_training_v2_batch160799.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_control_training_v2_batch55900.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v2_batch24800.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v3_batch155466.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v4_batch399.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_arrow_task_v5_batch133.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_v2_batch29398.pth'\n",
    "#fname = 'brain_checkpoints/enhanced_brain_canvas_use_v3_batch35249.pth'\n",
    "fname = 'brain_checkpoints/enhanced_brain_canvas_use_de_novo_v1_batch41200.pth'\n",
    "# -- that is the correct v3 version; the others come from the older tasks\n",
    "\n",
    "# A little extra code to avoid weird error\n",
    "#model.memory.remember(torch.randn(16, 1, 768).to(device))\n",
    "model.memory.remember(torch.randn(8, 1, 768).to(device))\n",
    "\n",
    "model.load_state_dict(torch.load(fname, weights_only=True, map_location=device))\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1361e168-adf8-453b-ac4a-5825ef046c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other elements to use\n",
    "\n",
    "from game import *\n",
    "\n",
    "game_settings = BIG_tool_use_advanced_2_5\n",
    "game_settings.gameSize = 224 # for compatibility with brain's expected size\n",
    "G = discreteGame(game_settings)\n",
    "\n",
    "####\n",
    "\n",
    "#For this time:\n",
    "def reset_G():\n",
    "    global G\n",
    "    G = discreteGame(G.random_bare_settings(gameSize=224, max_agent_offset=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b1ce00-688f-4a7b-aba0-4700d9341a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc054633830>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reset_G()\n",
    "plt.imshow(G.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80e8492d-8c1e-4389-b871-31e9d30340b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis notebook is to show the EnhancedBrain input, output, and state of mind at once.\n",
    "# I'll start with a rough version and make it cleaner over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a6d7d3-7701-4ad6-aedf-9d1da7612150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f707fd-090f-42d3-92ed-b2ed1d87c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8946d87-c09e-4eba-897f-5f81c5211bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_imshow_numpy(torch_img, imshow=False):\n",
    "    clean = torch_img.detach()[0].cpu()\n",
    "    right_order = torch.permute(clean, (1, 2, 0))\n",
    "    array = right_order.numpy()\n",
    "    plt.imshow(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b95dcd9-2119-47fb-a2b8-6713e5b28b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output(layout={'border': '1px solid black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22a55bbb-7aae-4acf-8232-baed2cc9f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = EnhancedAgentBrain()\n",
    "#model.move_to(device)\n",
    "#2+2\n",
    "# commment to prevent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37dd7bcf-415e-4a8a-8078-7716f8ce17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "# tokenizer.save_model(\".\", \"tokenizer/eng_sentences_tokenizer_vc10000\")\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-vocab.json\",\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-merges.txt\",\n",
    ")   \n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")   \n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60b38a1d-479c-46d6-a3f7-b7e77181f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = widgets.Textarea(\n",
    "    value='Hello World',\n",
    "    placeholder='Type something',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2ee3f89-d4b9-45f4-9e54-0ca7a6c40866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(game=None):\n",
    "    if game is None:\n",
    "        game = G\n",
    "    img = torch.FloatTensor(G.getData()).unsqueeze(0)\n",
    "    img = torch.permute(img, (0, 3, 1, 2)).contiguous().to(device)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aed9588-a3c7-4fe3-8e5f-9fc29fe9a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a475188-3a0a-4aac-8a2e-36456c557cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this for other inputs\n",
    "# inp_tensor = get_image()\n",
    "inp_tensor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab32506-2f60-4969-afdf-4fc35ccf8b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   32,   87,   34, 5411, 4226,    5,   32,   19,   87,   34,    2]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.tensor(tokenizer.encode(\"<s>Hello World!</s>\").ids).unsqueeze(0).contiguous().to(device)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1930a98-8161-4c7a-b1c0-4dca5f2bf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Hello World!</s>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tt[0][1:-1].cpu().numpy(), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b88d78ff-8c78-4c99-88be-0a7340a40b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"<s>Hello World!</s>\".find('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2da1651-dd24-4a73-a246-cbc3f5feb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def display_innards(b):\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    print(\"Canvases:\\n\")\n",
    "    if model.canvases.is_empty():\n",
    "        print(\"################\\nCanvases object is empty, nothing to show\\n################\")\n",
    "    else:\n",
    "        for i in range(model.canvases.num_canvases):\n",
    "            print(f\"##########\\nCanvas {i}:\\n\")\n",
    "            plt.imshow(pre_imshow_numpy(model.canvases.tw.L[i][:1]))\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77b5eebc-b0a8-4252-bee8-eda5c4f1de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def forward_wrapper(b):\n",
    "    output.clear_output()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "    tt = torch.tensor(tokenizer.encode(T.value).ids).unsqueeze(0).contiguous().to(device)\n",
    "    _, recon = model(tt, local_tensor, create_context=True, ret_imgs=True)\n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b)\n",
    "\n",
    "# wrapper for extending input text without changing what is displayed, much\n",
    "\n",
    "temp=1.0\n",
    "temp_eps = 1e-4\n",
    "\n",
    "special_symbols = set([1, 3, 4, 108])\n",
    "symbol_action_map = { 1:1, 3:3, 4:4, 108:2}\n",
    "\n",
    "@output.capture()\n",
    "def extend_wrapper(b):\n",
    "    output.clear_output()\n",
    "    print(\"Game status:\\n\")\n",
    "    plt.imshow(G.getData())\n",
    "    plt.show()\n",
    "    if inp_tensor is None:\n",
    "        print(\"input tensor is None; using input from the game\\n\\n\")\n",
    "        local_tensor = get_image()\n",
    "    else:\n",
    "        print(\"using global variable inp_tensor as image input\\n\\n\")\n",
    "        local_tensor = inp_tensor\n",
    "\n",
    "    # in this case, we abridge the end-of-sentence token in order to continue the extension\n",
    "    inp_ids = tokenizer.encode(T.value).ids[:-1]\n",
    "    if len(inp_ids) > 32:\n",
    "        inp_ids = inp_ids[-32:] # the rest should be in memory\n",
    "    tt = torch.tensor(inp_ids).unsqueeze(0).contiguous().to(device)\n",
    "    logits, recon = model(tt, local_tensor, return_full=False, create_context=True, ret_imgs=True)\n",
    "\n",
    "    s = tt.size()\n",
    "    output_text = torch.zeros((s[0], s[1] +1), dtype = torch.long, device=device)\n",
    "    output_text[:, :-1] += tt\n",
    "    \n",
    "    preds = model.select(logits, temp, ret_all=False, temp_eps=temp_eps)\n",
    "    output_text[:, -1] += preds\n",
    "\n",
    "    predval = preds[0].item()\n",
    "    if predval in special_symbols:\n",
    "        action = symbol_action_map[predval]\n",
    "        print(f\"Detected special token {predval} which is action {action}\")\n",
    "        reward = G.actions[action]()\n",
    "        print(f\"Reward was {reward}\")\n",
    "    \n",
    "    T.value = tokenizer.decode(output_text[0][1:].cpu().numpy(), skip_special_tokens=False) # update the string, cut off start token\n",
    "    print(\"updated input string (also in text box):\\n\")\n",
    "    print(T.value)\n",
    "    \n",
    "    print(\"output image:\\n\")\n",
    "    plt.imshow(pre_imshow_numpy(recon[:1]))\n",
    "    plt.show()\n",
    "    display_innards(b) # including game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3fcd589-cd91-488f-a7fd-74ca60b781e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "def soft_reset_wrapper(b):\n",
    "    print(\"soft reset (removing internal gradients)\\n\")\n",
    "    model.soft_reset()\n",
    "\n",
    "@output.capture()\n",
    "def reset_wrapper(b):\n",
    "    print(\"hard reset (clering memory and canvaases)\\n\")\n",
    "    model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7217f2f9-400e-49bc-ac6f-0852225ee038",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32 # max len of the model input. Make this a text box or a selector or a knob.\n",
    "\n",
    "@output.capture()\n",
    "def generate_wrapper(b):\n",
    "    # while the string is not too long nor contains the stop codon\n",
    "    while (T.value.find('</s>') == -1) and (len(tokenizer.encode(T.value).ids[:-1]) < max_len):\n",
    "        extend_wrapper(b)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62c779c1-427b-4e9f-8eeb-0c9ec08ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_clear_button_clicked(b):\n",
    "    output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63bf60f2-d3b4-475c-b3d1-0ea1f2ea80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_G_wrapper(b):\n",
    "    reset_G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e6978ff-0314-4b5e-af6b-ad9a57deb475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedAgentBrain(\n",
       "  (img_enc): ImageTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): PatchEmbedding(\n",
       "        (linear_project): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (1): PositionalEncoding_2D()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (img_dec): ImageTransformerDecoder(\n",
       "    (pe): PositionalEncoding_2D()\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.01, inplace=False)\n",
       "          (dropout2): Dropout(p=0.01, inplace=False)\n",
       "          (dropout3): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): PatchEmbeddingTranspose(\n",
       "        (linear_project): ConvTranspose2d(768, 3, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_enc): SentenceTransformerEncoder(\n",
       "    (embed): Sequential(\n",
       "      (0): Embedding(10000, 768, padding_idx=0)\n",
       "      (1): PositionalEncoding()\n",
       "      (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_dec): SentenceTransformerDecoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=3072, out_features=10000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dopamine): DopamineWrapper(\n",
       "    (dopamine): IntermediateTransformerScorer(\n",
       "      (decoder): TransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=3072, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (memory): Memory()\n",
       "  (mem_enc): MemoryEncoder(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_prep): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (fcs): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4256368e-b469-4e71-8f44-44339c70847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f3d7f8dab1486d8c9b8bba54a196d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset Game', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821bd229e83d46f8a3c5d152632c3215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Forward', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81648ebb1b9142adb772634f44f624ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Soft Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88469741c2334591aaef89430d257501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4252574115fd4f0e993d13659dd7929e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Extend by One Character', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f3562920c54fb8b299189e4172cb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Text', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fa4a57f6964365b4580f08de947fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Canvases', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81240d856f1419593535f79f703fefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clear Output', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9148f5976e8c430e9a2a006ba29de5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Hello World', description='String:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78d9d42a51a4e3bb851bfadb405aa89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bGameReset = widgets.Button(description=\"Reset Game\")\n",
    "bForward = widgets.Button(description=\"Forward\")\n",
    "bSoftReset = widgets.Button(description=\"Soft Reset\")\n",
    "bReset = widgets.Button(description=\"Reset\")\n",
    "bExtend = widgets.Button(description=\"Extend by One Character\")\n",
    "bGenerate = widgets.Button(description=\"Generate Text\")\n",
    "bDisplayInnards = widgets.Button(description=\"Show Canvases\")\n",
    "bClear = widgets.Button(description=\"Clear Output\")\n",
    "\n",
    "display(bGameReset)\n",
    "display(bForward)\n",
    "display(bSoftReset)\n",
    "display(bReset)\n",
    "display(bExtend)\n",
    "display(bGenerate)\n",
    "display(bDisplayInnards)\n",
    "display(bClear)\n",
    "\n",
    "display(T) # expand me by hand; prettier that way\n",
    "\n",
    "bGameReset.on_click(reset_G_wrapper)\n",
    "bForward.on_click(forward_wrapper)\n",
    "bSoftReset.on_click(soft_reset_wrapper)\n",
    "bReset.on_click(reset_wrapper)\n",
    "bExtend.on_click(extend_wrapper)\n",
    "bGenerate.on_click(generate_wrapper)\n",
    "bDisplayInnards.on_click(display_innards)\n",
    "bClear.on_click(on_clear_button_clicked)\n",
    "\n",
    "display(output)\n",
    "display_innards(bDisplayInnards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1acbc-0080-4704-9720-f4240733e8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee39b28-2d5e-4d18-97f2-e32acef0d9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59cb5e-b270-4a7d-bc3d-31977cf2a55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513eec8-92db-4672-bdf4-9bde727c09a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
