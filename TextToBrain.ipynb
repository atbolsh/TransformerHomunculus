{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caa87693-8924-4b86-ba7a-f01373e7ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "brain = DefaultAgentBrain().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a4be585-7ba5-44ba-9e0f-fcf0b8a94458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9fcacab-fafe-4ce9-a3dd-2bc28dccf45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad0172dc-0ff6-42ff-86a7-8a451a48ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"text_pretraining_data/eng_sentences_pruned-train.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88921ab7-ba46-488a-ae95-5284f3c0ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722afbe0-fddc-4062-bae9-ce89f13f53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.save_model(\".\", \"tokenizer/eng_sentences_tokenizer_vc10000\")\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-vocab.json\",\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-merges.txt\",\n",
    ")   \n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")   \n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34ff7b51-9e4e-46e8-b0a7-f625332514d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset structure\n",
    "# Note: This really belongs in a python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa9ebadd-7157-4f00-b1ab-7b349eb8d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset\n",
    "class SampleDataset(Dataset):\n",
    "    def __init__(self, seq_length = 32, evaluate: bool = False, tokenizer=None, device = None):\n",
    "        if device is None:\n",
    "            device = 'cpu'\n",
    "        self.device = device\n",
    "        self.seq_length = seq_length\n",
    "        if tokenizer is None:\n",
    "            tokenizer = ByteLevelBPETokenizer(\n",
    "                \"./text_pretraining_tokenizer/eng_sentences_tokenizer_v2-vocab.json\",\n",
    "                \"./text_pretraining_tokenizer/eng_sentences_tokenizer_v2-merges.txt\",\n",
    "            )   \n",
    "        tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "            (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "            (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "        )   \n",
    "        tokenizer.enable_truncation(max_length=self.seq_length)\n",
    "        tokenizer.enable_padding()#length=seq_length)\n",
    "        # or use the RobertaTokenizer from `transformers` directly.\n",
    "\n",
    "        self.examples = []\n",
    "\n",
    "        src_files = Path(\"./text_pretraining_data/\").glob(\"*-eval.txt\") if evaluate else Path(\"./text_pretraining_data/\").glob(\"*-train.txt\")\n",
    "        for src_file in src_files:\n",
    "            print(\"ðŸ”¥\", src_file)\n",
    "            lines = src_file.read_text(encoding=\"utf-8\").splitlines()\n",
    "            self.examples += [x.ids for x in tokenizer.encode_batch(lines)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        # Weâ€™ll pad at the batch level.\n",
    "        return torch.tensor(self.examples[i]).to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a5313d2-79ec-4684-8b43-abdbcc2d9c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "ðŸ”¥ text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    }
   ],
   "source": [
    "sdt = SampleDataset(tokenizer=tokenizer)\n",
    "sdv = SampleDataset(tokenizer=tokenizer, evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83cf03bd-bad3-4381-a044-cb125e5608fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,  843,  325, 1083,  711,   18,    2,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "908cb054-a263-4e23-85cd-e320e725fbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  843,  325, 1083,  711,   18,    2,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,   45,  363,  271,  346,  271, 1014,   18,    2,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0, 2529,  307, 5221, 3927,  601,  326,  360,  307,  614,   89,  584,\n",
       "          574,  325, 2027,    5,    2,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,   49,   89,  584,  574,  307, 1485,  616,   18,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdt[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd0acd51-ff1b-44a2-abde-1244dfcc3617",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = brain(sdt[0:64].cuda(), return_full=True, use_masks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df1a4445-4b92-4f9f-90b6-2770b2c4a62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10000, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51562591-fbc0-43bf-ad5a-c4e82740afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At least in inference, batchsize64 is very doable. 16 is a piece of cake.\n",
    "# most likely I will use much smaller batches because the images will be a bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fd4a82-ece6-4eaa-837b-bf1153b3b159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
