{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35fcd4aa-7533-4182-9e01-962a2ffc9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the brain, using text alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95177782-9045-4f95-841c-f6080981f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import *\n",
    "brain = DefaultAgentBrain().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b928dd60-7533-4516-b1a1-55ad1eefcc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71488f80-d08b-4f75-9830-8ad80dc11d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "paths = [\"text_pretraining_data/eng_sentences_pruned-train.txt\"]\n",
    "vocab_size = 10000\n",
    "# tokenizer.save_model(\".\", \"tokenizer/eng_sentences_tokenizer_vc10000\")\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-vocab.json\",\n",
    "    \"./text_pretraining_tokenizer/eng_sentences_tokenizer_vc10000_v2-merges.txt\",\n",
    ")   \n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")   \n",
    "tokenizer.enable_truncation(max_length=32)\n",
    "tokenizer.enable_padding()\n",
    "\n",
    "## Dataset\n",
    "class SampleDataset(Dataset):\n",
    "    def __init__(self, seq_length = 32, evaluate: bool = False, tokenizer=None, device = None):\n",
    "        if device is None:\n",
    "            device = 'cpu'\n",
    "        self.device = device\n",
    "        self.seq_length = seq_length\n",
    "        if tokenizer is None:\n",
    "            tokenizer = ByteLevelBPETokenizer(\n",
    "                \"./text_pretraining_tokenizer/eng_sentences_tokenizer_v2-vocab.json\",\n",
    "                \"./text_pretraining_tokenizer/eng_sentences_tokenizer_v2-merges.txt\",\n",
    "            )   \n",
    "        tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "            (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "            (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "        )   \n",
    "        tokenizer.enable_truncation(max_length=self.seq_length)\n",
    "        tokenizer.enable_padding()#length=seq_length)\n",
    "        # or use the RobertaTokenizer from `transformers` directly.\n",
    "\n",
    "        self.examples = []\n",
    "\n",
    "        src_files = Path(\"./text_pretraining_data/\").glob(\"*-eval.txt\") if evaluate else Path(\"./text_pretraining_data/\").glob(\"*-train.txt\")\n",
    "        for src_file in src_files:\n",
    "            print(\"🔥\", src_file)\n",
    "            lines = src_file.read_text(encoding=\"utf-8\").splitlines()\n",
    "            self.examples += [x.ids for x in tokenizer.encode_batch(lines)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        # We’ll pad at the batch level.\n",
    "        return torch.tensor(self.examples[i]).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1773ac06-3515-41a6-8abf-9449265107d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 text_pretraining_data/eng_sentences_pruned-train.txt\n",
      "🔥 text_pretraining_data/eng_sentences_pruned-eval.txt\n"
     ]
    }
   ],
   "source": [
    "sdt = SampleDataset(tokenizer=tokenizer)\n",
    "sdv = SampleDataset(tokenizer=tokenizer, evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "206c4e99-fb84-433d-84c7-99f3625cb136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 80 #32*4*2#8\n",
    "num_workers = 0\n",
    "\n",
    "train_loader = DataLoader(sdt, batch_size=batch_size,\n",
    "                          num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05667868-c9d4-427c-a582-cf3263b95cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "def get_loss(res, inputs):\n",
    "    return torch.sum(criterion(res[:, :, :-1], inputs[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ff7ab3a-d550-4e2d-a33c-c60267941926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:   0%|                                                                                                                                                                       | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1: 9.272705078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:   5%|███████▋                                                                                                                                                  | 1000/20000 [16:17<5:09:09,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1001: 4.7953915281610175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  10%|███████████████▍                                                                                                                                          | 2000/20000 [32:41<4:53:04,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 2001: 4.463658342714133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  15%|███████████████████████                                                                                                                                   | 3000/20000 [49:04<4:36:14,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 3001: 4.296980200748132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  20%|██████████████████████████████▍                                                                                                                         | 4000/20000 [1:05:26<4:19:47,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 4001: 4.185086747402848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  25%|██████████████████████████████████████                                                                                                                  | 5000/20000 [1:21:51<4:04:38,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 5001: 4.101664095109903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  30%|█████████████████████████████████████████████▌                                                                                                          | 6000/20000 [1:38:18<3:48:02,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 6001: 4.0330391909515555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  35%|█████████████████████████████████████████████████████▏                                                                                                  | 7000/20000 [1:54:47<3:32:01,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 7001: 3.979179816592712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  40%|████████████████████████████████████████████████████████████▊                                                                                           | 8000/20000 [2:11:14<3:16:04,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 8001: 3.9335583499812614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  45%|████████████████████████████████████████████████████████████████████▍                                                                                   | 9000/20000 [2:27:39<2:58:17,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 9001: 3.8925628928843636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  50%|███████████████████████████████████████████████████████████████████████████▌                                                                           | 10000/20000 [2:44:00<2:42:30,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 10001: 3.85664019638533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  55%|███████████████████████████████████████████████████████████████████████████████████                                                                    | 11000/20000 [3:00:23<2:26:03,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 11001: 3.8258677660015623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  60%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 12000/20000 [3:16:47<2:10:04,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 12001: 3.7970306248716907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  65%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 13000/20000 [3:33:09<1:53:38,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 13001: 3.770603746627351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 14000/20000 [3:49:31<1:37:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 14001: 3.746779536904629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 15000/20000 [4:05:53<1:21:09,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 15001: 3.725424042352636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 16000/20000 [4:22:14<1:05:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 16001: 3.7051318852232886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 17000/20000 [4:38:36<48:42,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 17001: 3.6865961545215313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 18000/20000 [4:55:00<32:28,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 18001: 3.668931382794187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 19000/20000 [5:11:22<16:16,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 19001: 3.652422341188188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [5:27:43<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss after epoch 0: 3.6364555095791817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:   0%|                                                                                                                                                                       | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1: 3.248002767562866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:   5%|███████▋                                                                                                                                                  | 1000/20000 [16:22<5:08:54,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1001: 3.289244535086038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  10%|███████████████▍                                                                                                                                          | 2000/20000 [32:45<4:51:41,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 2001: 3.2809787302956113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  15%|███████████████████████                                                                                                                                   | 3000/20000 [49:08<4:36:02,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 3001: 3.2768868855816726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  20%|██████████████████████████████▍                                                                                                                         | 4000/20000 [1:05:29<4:19:38,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 4001: 3.2731534249482825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  25%|██████████████████████████████████████                                                                                                                  | 5000/20000 [1:21:51<4:03:31,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 5001: 3.2648995723087437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  30%|█████████████████████████████████████████████▌                                                                                                          | 6000/20000 [1:38:13<3:47:08,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 6001: 3.2596631492699926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  35%|█████████████████████████████████████████████████████▏                                                                                                  | 7000/20000 [1:54:35<3:31:07,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 7001: 3.2533026084850865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  40%|████████████████████████████████████████████████████████████▊                                                                                           | 8000/20000 [2:10:58<3:15:09,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 8001: 3.24745299574465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  45%|████████████████████████████████████████████████████████████████████▍                                                                                   | 9000/20000 [2:27:19<2:58:42,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 9001: 3.2410369217892434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  50%|███████████████████████████████████████████████████████████████████████████▌                                                                           | 10000/20000 [2:43:41<2:42:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 10001: 3.236295720742066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  55%|███████████████████████████████████████████████████████████████████████████████████                                                                    | 11000/20000 [3:00:02<2:25:57,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 11001: 3.2315737024327538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  60%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 12000/20000 [3:16:25<2:09:58,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 12001: 3.226836702643052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  65%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 13000/20000 [3:32:47<1:53:29,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 13001: 3.2218281782257514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 14000/20000 [3:49:08<1:37:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 14001: 3.2164572482193874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 15000/20000 [4:05:29<1:21:11,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 15001: 3.2108862442967414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 16000/20000 [4:21:51<1:04:53,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 16001: 3.206527235373714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 17000/20000 [4:38:14<48:40,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 17001: 3.2019728333744872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 18000/20000 [4:54:36<32:25,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 18001: 3.1976699054681568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 19000/20000 [5:10:57<16:12,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 19001: 3.1928321555579164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [5:27:18<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss after epoch 1: 3.188260354137421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:   0%|                                                                                                                                                                       | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1: 2.926788568496704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:   5%|███████▋                                                                                                                                                  | 1000/20000 [16:22<5:08:34,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1001: 3.058787497130784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  10%|███████████████▍                                                                                                                                          | 2000/20000 [32:45<4:52:26,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 2001: 3.0589513995539006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  15%|███████████████████████                                                                                                                                   | 3000/20000 [49:06<4:35:56,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 3001: 3.0543040839166333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  20%|██████████████████████████████▍                                                                                                                         | 4000/20000 [1:05:27<4:19:34,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 4001: 3.054232844827295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  25%|██████████████████████████████████████                                                                                                                  | 5000/20000 [1:21:49<4:03:12,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 5001: 3.0535841679911546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  30%|█████████████████████████████████████████████▌                                                                                                          | 6000/20000 [1:38:11<3:47:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 6001: 3.0513037437002892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  35%|█████████████████████████████████████████████████████▏                                                                                                  | 7000/20000 [1:54:33<3:30:42,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 7001: 3.049199909810389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  40%|████████████████████████████████████████████████████████████▊                                                                                           | 8000/20000 [2:10:54<3:14:40,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 8001: 3.046996507357395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  45%|████████████████████████████████████████████████████████████████████▍                                                                                   | 9000/20000 [2:27:15<2:58:02,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 9001: 3.044235893387673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  50%|███████████████████████████████████████████████████████████████████████████▌                                                                           | 10000/20000 [2:43:37<2:42:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 10001: 3.0418109289944955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  55%|███████████████████████████████████████████████████████████████████████████████████                                                                    | 11000/20000 [2:59:59<2:26:14,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 11001: 3.0399402837386598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  60%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 12000/20000 [3:16:20<2:09:44,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 12001: 3.038440912428046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  65%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 13000/20000 [3:32:40<1:53:40,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 13001: 3.036228129830913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 14000/20000 [3:49:01<1:37:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 14001: 3.0340645200022203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 15000/20000 [4:05:23<1:21:13,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 15001: 3.031592088924647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 16000/20000 [4:21:45<1:04:48,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 16001: 3.0294835937745077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 17000/20000 [4:38:06<48:41,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 17001: 3.027429769000028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 18000/20000 [4:54:26<32:26,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 18001: 3.0249233229823473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 19000/20000 [5:10:48<16:13,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 19001: 3.023165461603111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [5:27:10<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss after epoch 2: 3.0211149790406227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:   0%|                                                                                                                                                                       | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1: 2.8632798194885254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:   5%|███████▋                                                                                                                                                  | 1000/20000 [16:20<5:08:37,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1001: 2.93395313897452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  10%|███████████████▍                                                                                                                                          | 2000/20000 [32:41<4:51:46,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 2001: 2.9381897224300446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  15%|███████████████████████                                                                                                                                   | 3000/20000 [49:03<4:35:54,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 3001: 2.9379653870284814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  20%|██████████████████████████████▍                                                                                                                         | 4000/20000 [1:05:27<4:19:44,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 4001: 2.9370259778018712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  25%|██████████████████████████████████████                                                                                                                  | 5000/20000 [1:21:48<4:03:40,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 5001: 2.934725530336819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  30%|█████████████████████████████████████████████▌                                                                                                          | 6000/20000 [1:38:10<3:47:32,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 6001: 2.9337294300761427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  35%|█████████████████████████████████████████████████████▏                                                                                                  | 7000/20000 [1:54:32<3:30:48,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 7001: 2.9321762998518546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  40%|████████████████████████████████████████████████████████████▊                                                                                           | 8000/20000 [2:10:53<3:15:20,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 8001: 2.930373188853636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  45%|████████████████████████████████████████████████████████████████████▍                                                                                   | 9000/20000 [2:27:16<2:58:38,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 9001: 2.928537774040969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  50%|███████████████████████████████████████████████████████████████████████████▌                                                                           | 10000/20000 [2:43:39<2:42:25,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 10001: 2.927146129495632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  55%|███████████████████████████████████████████████████████████████████████████████████                                                                    | 11000/20000 [3:00:00<2:26:09,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 11001: 2.926005132479425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  60%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 12000/20000 [3:16:21<2:09:38,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 12001: 2.925346053468119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  65%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 13000/20000 [3:32:44<1:53:46,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 13001: 2.9246228303682638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 14000/20000 [3:49:06<1:37:18,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 14001: 2.923632108725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 15000/20000 [4:05:27<1:21:06,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 15001: 2.9229064195301206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 16000/20000 [4:21:49<1:04:53,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 16001: 2.9217879315643236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 17000/20000 [4:38:11<48:43,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 17001: 2.9208049302689854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 18000/20000 [4:54:32<32:24,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 18001: 2.9196327590232465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 19000/20000 [5:10:53<16:15,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 19001: 2.918702696782715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [5:27:16<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss after epoch 3: 2.917339228081703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:   0%|                                                                                                                                                                       | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1: 2.8893654346466064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:   5%|███████▋                                                                                                                                                  | 1000/20000 [16:21<5:08:54,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1001: 2.849735642527486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  10%|███████████████▍                                                                                                                                          | 2000/20000 [32:42<4:52:02,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 2001: 2.8462311450628444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  15%|███████████████████████                                                                                                                                   | 3000/20000 [49:05<4:35:46,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 3001: 2.8442357889376892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  20%|██████████████████████████████▍                                                                                                                         | 4000/20000 [1:05:26<4:19:39,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 4001: 2.8450047693917586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  25%|██████████████████████████████████████                                                                                                                  | 5000/20000 [1:21:47<4:03:05,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 5001: 2.8449294314911735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  30%|█████████████████████████████████████████████▌                                                                                                          | 6000/20000 [1:38:09<3:47:13,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 6001: 2.8443716382050668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  35%|█████████████████████████████████████████████████████▏                                                                                                  | 7000/20000 [1:54:31<3:31:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 7001: 2.844856884765244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  40%|████████████████████████████████████████████████████████████▊                                                                                           | 8000/20000 [2:10:52<3:14:26,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 8001: 2.845060530818562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  45%|████████████████████████████████████████████████████████████████████▍                                                                                   | 9000/20000 [2:27:14<2:58:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 9001: 2.8445416866256297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  50%|███████████████████████████████████████████████████████████████████████████▌                                                                           | 10000/20000 [2:43:36<2:41:55,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 10001: 2.8446251600816863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  55%|███████████████████████████████████████████████████████████████████████████████████                                                                    | 11000/20000 [2:59:57<2:25:57,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 11001: 2.8442557559383097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  60%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 12000/20000 [3:16:18<2:09:56,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 12001: 2.8436961968077608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  65%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 13000/20000 [3:32:40<1:53:50,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 13001: 2.8433486685442215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 14000/20000 [3:49:03<1:37:13,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 14001: 2.8431701086459946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 15000/20000 [4:05:23<1:21:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 15001: 2.8430456862466493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 16000/20000 [4:21:44<1:04:52,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 16001: 2.842785927915743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 17000/20000 [4:38:06<48:38,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 17001: 2.841990756046126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 18000/20000 [4:54:28<32:29,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 18001: 2.841983047579866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 19000/20000 [5:10:49<16:13,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 19001: 2.8412712482105875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [5:27:10<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss after epoch 4: 2.8408657442212104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:   0%|                                                                                                                                                                       | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1: 2.8598129749298096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:   5%|███████▋                                                                                                                                                  | 1000/20000 [16:21<5:08:18,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1001: 2.775339959741949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  10%|███████████████▍                                                                                                                                          | 2000/20000 [32:42<4:52:04,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 2001: 2.7760292154023314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  15%|███████████████████████                                                                                                                                   | 3000/20000 [49:04<4:36:19,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 3001: 2.7776176583087673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  20%|██████████████████████████████▍                                                                                                                         | 4000/20000 [1:05:25<4:19:31,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 4001: 2.7786764189828133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  25%|██████████████████████████████████████                                                                                                                  | 5000/20000 [1:21:46<4:03:05,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 5001: 2.7801226462108852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  30%|█████████████████████████████████████████████▌                                                                                                          | 6000/20000 [1:38:08<3:46:56,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 6001: 2.7806213013312555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  35%|█████████████████████████████████████████████████████▏                                                                                                  | 7000/20000 [1:54:30<3:31:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 7001: 2.781123907731918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  40%|████████████████████████████████████████████████████████████▊                                                                                           | 8000/20000 [2:10:51<3:14:57,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 8001: 2.7811975561370104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  45%|████████████████████████████████████████████████████████████████████▍                                                                                   | 9000/20000 [2:27:12<2:58:22,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 9001: 2.781866372737497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  50%|███████████████████████████████████████████████████████████████████████████▌                                                                           | 10000/20000 [2:43:34<2:42:20,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 10001: 2.781950200465831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  55%|███████████████████████████████████████████████████████████████████████████████████                                                                    | 11000/20000 [2:59:56<2:25:54,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 11001: 2.781780516816295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  60%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 12000/20000 [3:16:17<2:10:04,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 12001: 2.7812136197604693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  65%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 13000/20000 [3:32:37<1:53:30,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 13001: 2.7810732685651294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 14000/20000 [3:48:59<1:37:19,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 14001: 2.7809611944528694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 15000/20000 [4:05:22<1:21:13,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 15001: 2.780804612717464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 16000/20000 [4:21:42<1:04:52,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 16001: 2.7811541697523174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 17000/20000 [4:38:03<48:40,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 17001: 2.7811923818681934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 18000/20000 [4:54:25<32:26,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 18001: 2.7815737638213385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 19000/20000 [5:10:47<16:14,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 19001: 2.7813359175561057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [5:27:07<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss after epoch 5: 2.7808235165834425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:   0%|                                                                                                                                                                       | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1: 2.6091525554656982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:   5%|███████▋                                                                                                                                                  | 1000/20000 [16:22<5:08:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1001: 2.720584365395042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  10%|███████████████▍                                                                                                                                          | 2000/20000 [32:44<4:52:02,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 2001: 2.7236581847168457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  15%|███████████████████████                                                                                                                                   | 3000/20000 [49:05<4:35:54,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 3001: 2.7258282983672495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  20%|██████████████████████████████▍                                                                                                                         | 4000/20000 [1:05:26<4:19:20,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 4001: 2.7266233326702887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  25%|██████████████████████████████████████                                                                                                                  | 5000/20000 [1:21:47<4:03:15,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 5001: 2.727698160729106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  30%|█████████████████████████████████████████████▌                                                                                                          | 6000/20000 [1:38:09<3:47:04,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 6001: 2.7285180830832343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  35%|█████████████████████████████████████████████████████▏                                                                                                  | 7000/20000 [1:54:32<3:30:51,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 7001: 2.729376290869907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  40%|████████████████████████████████████████████████████████████▊                                                                                           | 8000/20000 [2:10:54<3:14:52,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 8001: 2.728842949691437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  45%|████████████████████████████████████████████████████████████████████▍                                                                                   | 9000/20000 [2:27:15<2:58:19,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 9001: 2.729000490594607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  50%|███████████████████████████████████████████████████████████████████████████▌                                                                           | 10000/20000 [2:43:36<2:42:09,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 10001: 2.7294953208889394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  55%|███████████████████████████████████████████████████████████████████████████████████                                                                    | 11000/20000 [2:59:57<2:25:55,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 11001: 2.7296327685520936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  60%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 12000/20000 [3:16:19<2:09:48,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 12001: 2.7297591299685267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  65%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 13000/20000 [3:32:41<1:53:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 13001: 2.7297959817701942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 14000/20000 [3:49:03<1:37:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 14001: 2.7300153665990115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 15000/20000 [4:05:23<1:21:05,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 15001: 2.730483273698222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 16000/20000 [4:21:44<1:04:51,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 16001: 2.730856462595098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 17000/20000 [4:38:05<48:36,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 17001: 2.730676302579731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 18000/20000 [4:54:27<32:24,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 18001: 2.7312014774046807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 19000/20000 [5:10:49<16:13,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 19001: 2.731145710237691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [5:27:11<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss after epoch 6: 2.7312168785214426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:   0%|                                                                                                                                                                       | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1: 2.6444339752197266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:   5%|███████▋                                                                                                                                                  | 1000/20000 [16:21<5:07:41,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1001: 2.6709736901206096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  10%|███████████████▍                                                                                                                                          | 2000/20000 [32:43<4:51:52,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 2001: 2.6708659060533972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  15%|███████████████████████                                                                                                                                   | 3000/20000 [49:05<4:35:47,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 3001: 2.675140197576582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  20%|██████████████████████████████▍                                                                                                                         | 4000/20000 [1:05:27<4:19:39,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 4001: 2.6769058719869556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  25%|██████████████████████████████████████                                                                                                                  | 5000/20000 [1:21:47<4:03:18,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 5001: 2.678746323327116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  30%|█████████████████████████████████████████████▌                                                                                                          | 6000/20000 [1:38:08<3:47:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 6001: 2.6799828261658463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  35%|█████████████████████████████████████████████████████▏                                                                                                  | 7000/20000 [1:54:30<3:31:06,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 7001: 2.6802218466413956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  40%|████████████████████████████████████████████████████████████▊                                                                                           | 8000/20000 [2:10:52<3:14:45,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 8001: 2.6820450688791104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  45%|████████████████████████████████████████████████████████████████████▍                                                                                   | 9000/20000 [2:27:14<2:58:30,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 9001: 2.682193008903238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  50%|███████████████████████████████████████████████████████████████████████████▌                                                                           | 10000/20000 [2:43:35<2:42:06,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 10001: 2.682828442548087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  55%|███████████████████████████████████████████████████████████████████████████████████                                                                    | 11000/20000 [2:59:56<2:25:55,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 11001: 2.68351738377708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  60%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 12000/20000 [3:16:17<2:09:47,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 12001: 2.6843052604140643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  65%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 13000/20000 [3:32:38<1:53:38,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 13001: 2.6855243360544203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 14000/20000 [3:49:01<1:37:29,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 14001: 2.686315037916238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 15000/20000 [4:05:23<1:21:15,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 15001: 2.687177589850206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 16000/20000 [4:21:44<1:04:53,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 16001: 2.68786418841009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 17000/20000 [4:38:06<48:41,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 17001: 2.68772293093569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 18000/20000 [4:54:29<32:25,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 18001: 2.688192935713357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 19000/20000 [5:10:51<16:17,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 19001: 2.688121114779219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [5:27:16<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss after epoch 7: 2.68897922847271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:   0%|                                                                                                                                                                       | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1: 2.468172788619995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:   5%|███████▋                                                                                                                                                  | 1000/20000 [16:21<5:08:03,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1001: 2.6370529399646983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  10%|███████████████▍                                                                                                                                          | 2000/20000 [32:43<4:51:47,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 2001: 2.635202786494707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  15%|███████████████████████                                                                                                                                   | 3000/20000 [49:05<4:36:14,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 3001: 2.6392807418685957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  20%|██████████████████████████████▍                                                                                                                         | 4000/20000 [1:05:28<4:19:51,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 4001: 2.642011969544178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  25%|██████████████████████████████████████                                                                                                                  | 5000/20000 [1:21:49<4:03:45,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 5001: 2.642751240105754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  30%|█████████████████████████████████████████████▌                                                                                                          | 6000/20000 [1:38:10<3:47:02,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 6001: 2.6433199517549304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  35%|█████████████████████████████████████████████████████▏                                                                                                  | 7000/20000 [1:54:32<3:30:55,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 7001: 2.644491301930099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  40%|████████████████████████████████████████████████████████████▊                                                                                           | 8000/20000 [2:10:54<3:14:36,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 8001: 2.644362455814306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  45%|████████████████████████████████████████████████████████████████████▍                                                                                   | 9000/20000 [2:27:17<2:58:37,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 9001: 2.6455500714978353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  50%|███████████████████████████████████████████████████████████████████████████▌                                                                           | 10000/20000 [2:43:39<2:42:13,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 10001: 2.6466384603433424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  55%|███████████████████████████████████████████████████████████████████████████████████                                                                    | 11000/20000 [3:00:00<2:26:12,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 11001: 2.6475993979899366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  60%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 12000/20000 [3:16:21<2:09:46,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 12001: 2.648284917612412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  65%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 13000/20000 [3:32:43<1:53:34,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 13001: 2.649090777671426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 14000/20000 [3:49:06<1:37:20,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 14001: 2.6497357768098353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 15000/20000 [4:05:28<1:21:09,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 15001: 2.6501604212688514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 16000/20000 [4:21:49<1:04:48,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 16001: 2.6510966643937848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 17000/20000 [4:38:10<48:43,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 17001: 2.651246438467617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 18000/20000 [4:54:33<32:25,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 18001: 2.6514528971977693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 19000/20000 [5:10:55<16:12,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 19001: 2.6518299739728834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [5:27:18<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss after epoch 8: 2.652281855225563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:   0%|                                                                                                                                                                      | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1: 2.6133623123168945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:   5%|███████▋                                                                                                                                                 | 1000/20000 [16:21<5:08:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1001: 2.5978472890196502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  10%|███████████████▎                                                                                                                                         | 2000/20000 [32:43<4:52:24,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 2001: 2.6007518994695005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  15%|██████████████████████▉                                                                                                                                  | 3000/20000 [49:05<4:36:05,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 3001: 2.6019843651111505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  20%|██████████████████████████████▏                                                                                                                        | 4000/20000 [1:05:28<4:19:35,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 4001: 2.6045996493263504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  25%|█████████████████████████████████████▊                                                                                                                 | 5000/20000 [1:21:49<4:03:09,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 5001: 2.6059967249637843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  30%|█████████████████████████████████████████████▎                                                                                                         | 6000/20000 [1:38:10<3:47:02,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 6001: 2.6087325584330254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  35%|████████████████████████████████████████████████████▊                                                                                                  | 7000/20000 [1:54:32<3:31:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 7001: 2.6099941045654584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  40%|████████████████████████████████████████████████████████████▍                                                                                          | 8000/20000 [2:10:54<3:14:33,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 8001: 2.6113984443860985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  45%|███████████████████████████████████████████████████████████████████▉                                                                                   | 9000/20000 [2:27:17<2:58:32,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 9001: 2.6121261687215704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  50%|███████████████████████████████████████████████████████████████████████████                                                                           | 10000/20000 [2:43:39<2:42:20,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 10001: 2.613678457355299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  55%|██████████████████████████████████████████████████████████████████████████████████▌                                                                   | 11000/20000 [3:00:00<2:26:04,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 11001: 2.6144042322824417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  60%|██████████████████████████████████████████████████████████████████████████████████████████                                                            | 12000/20000 [3:16:21<2:09:40,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 12001: 2.6152037469240716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  65%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 13000/20000 [3:32:43<1:53:36,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 13001: 2.6163331294332997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                             | 14000/20000 [3:49:06<1:37:13,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 14001: 2.6166153192503114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                     | 15000/20000 [4:05:29<1:21:07,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 15001: 2.616744744524178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 16000/20000 [4:21:50<1:04:59,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 16001: 2.617118644025965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                      | 17000/20000 [4:38:11<48:42,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 17001: 2.617377187131356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊               | 18000/20000 [4:54:33<32:26,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 18001: 2.617904178341669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16:  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 19000/20000 [5:10:55<16:14,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 19001: 2.618842199698077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/16: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [5:27:18<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss after epoch 9: 2.619703551268578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:   0%|                                                                                                                                                                      | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1: 2.648392915725708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:   5%|███████▋                                                                                                                                                 | 1000/20000 [16:21<5:09:17,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1001: 2.567990868956178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  10%|███████████████▎                                                                                                                                         | 2000/20000 [32:43<4:51:57,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 2001: 2.5719781327045066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  15%|██████████████████████▉                                                                                                                                  | 3000/20000 [49:05<4:36:18,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 3001: 2.5724283427009977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  20%|██████████████████████████████▏                                                                                                                        | 4000/20000 [1:05:28<4:19:31,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 4001: 2.5738445136940977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  25%|█████████████████████████████████████▊                                                                                                                 | 5000/20000 [1:21:49<4:03:26,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 5001: 2.5751377688100687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  30%|█████████████████████████████████████████████▎                                                                                                         | 6000/20000 [1:38:10<3:47:08,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 6001: 2.5766672598205194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  35%|████████████████████████████████████████████████████▊                                                                                                  | 7000/20000 [1:54:33<3:31:13,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 7001: 2.5781938268906424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  40%|████████████████████████████████████████████████████████████▍                                                                                          | 8000/20000 [2:10:55<3:14:34,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 8001: 2.5791861564274834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  45%|███████████████████████████████████████████████████████████████████▉                                                                                   | 9000/20000 [2:27:17<2:58:25,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 9001: 2.5804307572299434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  50%|███████████████████████████████████████████████████████████████████████████                                                                           | 10000/20000 [2:43:40<2:42:39,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 10001: 2.582304183369505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  55%|██████████████████████████████████████████████████████████████████████████████████▌                                                                   | 11000/20000 [3:00:01<2:26:12,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 11001: 2.582937375338183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  60%|██████████████████████████████████████████████████████████████████████████████████████████                                                            | 12000/20000 [3:16:23<2:09:56,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 12001: 2.5841015975144135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  65%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 13000/20000 [3:32:46<1:53:36,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 13001: 2.58511831472309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                             | 14000/20000 [3:49:08<1:37:09,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 14001: 2.5857381685981835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                     | 15000/20000 [4:05:29<1:21:14,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 15001: 2.587105433103776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 16000/20000 [4:21:50<1:04:49,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 16001: 2.588266213278004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                      | 17000/20000 [4:38:12<48:46,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 17001: 2.5890794625794715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊               | 18000/20000 [4:54:35<32:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 18001: 2.58998632240306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16:  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 19000/20000 [5:10:57<16:16,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 19001: 2.590529698672078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/16: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [5:27:19<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss after epoch 10: 2.5907963575363158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:   0%|                                                                                                                                                                      | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1: 2.468482732772827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:   5%|███████▋                                                                                                                                                 | 1000/20000 [16:22<5:07:51,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1001: 2.5437905185825223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  10%|███████████████▎                                                                                                                                         | 2000/20000 [32:44<4:52:28,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 2001: 2.5429452887062785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  15%|██████████████████████▉                                                                                                                                  | 3000/20000 [49:06<4:36:21,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 3001: 2.543699292014814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  20%|██████████████████████████████▏                                                                                                                        | 4000/20000 [1:05:28<4:19:37,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 4001: 2.5456794919564825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  25%|█████████████████████████████████████▊                                                                                                                 | 5000/20000 [1:21:49<4:03:24,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 5001: 2.54777427392825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  30%|█████████████████████████████████████████████▎                                                                                                         | 6000/20000 [1:38:11<3:47:19,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 6001: 2.549315553529126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  35%|████████████████████████████████████████████████████▊                                                                                                  | 7000/20000 [1:54:34<3:31:08,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 7001: 2.5503789978765656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  40%|████████████████████████████████████████████████████████████▍                                                                                          | 8000/20000 [2:10:56<3:14:38,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 8001: 2.5519559688231985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  45%|███████████████████████████████████████████████████████████████████▉                                                                                   | 9000/20000 [2:27:18<2:58:17,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 9001: 2.553141315146799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  50%|███████████████████████████████████████████████████████████████████████████                                                                           | 10000/20000 [2:43:39<2:42:17,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 10001: 2.5550134805616955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  55%|██████████████████████████████████████████████████████████████████████████████████▌                                                                   | 11000/20000 [3:00:00<2:26:17,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 11001: 2.5555824442848643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  60%|██████████████████████████████████████████████████████████████████████████████████████████                                                            | 12000/20000 [3:16:23<2:09:54,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 12001: 2.5573704360912326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  65%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 13000/20000 [3:32:45<1:53:31,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 13001: 2.558717810367678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                             | 14000/20000 [3:49:07<1:37:15,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 14001: 2.559738452175193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                     | 15000/20000 [4:05:28<1:21:13,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 15001: 2.5604008916902283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 16000/20000 [4:21:50<1:04:57,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 16001: 2.561312396111663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                      | 17000/20000 [4:38:13<48:42,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 17001: 2.5618241329304183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊               | 18000/20000 [4:54:35<32:24,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 18001: 2.5627084873059176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16:  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 19000/20000 [5:10:57<16:15,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 19001: 2.563560036268807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/16: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [5:27:18<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss after epoch 11: 2.564489268016815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/16:   0%|                                                                                                                                                                      | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1: 2.5219664573669434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/16:   5%|███████▋                                                                                                                                                 | 1000/20000 [16:22<5:08:26,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 1001: 2.50878961817487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/16:  10%|███████████████▎                                                                                                                                         | 2000/20000 [32:44<4:52:30,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 2001: 2.5113272427440227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/16:  15%|██████████████████████▉                                                                                                                                  | 3000/20000 [49:05<4:36:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss at batch 3001: 2.5165742098272186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/16:  19%|█████████████████████████████▎                                                                                                                         | 3880/20000 [1:03:33<4:24:03,  1.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     25\u001b[0m     avg_train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(brain.parameters(), lr=0.0001*80/256, eps=1e-9)#, #betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "epochs = 16\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    brain.train()\n",
    "    train_loss = 0\n",
    "    i = -1\n",
    "    for inputs in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}/{epochs}\"):\n",
    "        i += 1\n",
    "        inputs = inputs.to(device)\n",
    "        img_context = torch.randn((batch_size, 256, 768), device=inputs.device) # easier for pretraining\n",
    "        src_attention_mask, src_key_padding_mask = brain.get_masks(inputs, use_masks=True)\n",
    "        text_encoding = brain.get_text_encoding(inputs, src_attention_mask, src_key_padding_mask)\n",
    "        res = brain.get_text_decoding(text_encoding, src_attention_mask, src_key_padding_mask, img_context, return_full=True)\n",
    "        loss = get_loss(res, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "        if i % 1000 == 0:\n",
    "            avg_train_loss = train_loss / (i + 1)\n",
    "            print(f\"Average Training Loss at batch {i + 1}: {avg_train_loss}\")\n",
    "            torch.save(brain.text_enc.state_dict(), 'brain_checkpoints/text_encoder_weights_v2.pth')\n",
    "            torch.save(brain.text_dec.state_dict(), 'brain_checkpoints/text_decoder_weights_v2.pth')\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Average Training Loss after epoch {epoch}: {avg_train_loss}\")\n",
    "    torch.save(brain.text_enc.state_dict(), 'brain_checkpoints/text_encoder_weights_v2.pth')\n",
    "    torch.save(brain.text_dec.state_dict(), 'brain_checkpoints/text_decoder_weights_v2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea61b830-ed6a-4c1f-af57-7cc66c0b79d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
